{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dmSz5jcVVt4p"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = 100*np.sin(0.01*x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(-600,600,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "             \n",
    "      \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - torch.cos(0.01*g)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "   \n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 47.768353 Test MSE 5220.105863394234 Test RE 0.9997532392787468\n",
      "1 Train Loss 47.76812 Test MSE 5219.8305264904575 Test RE 0.9997268727070199\n",
      "2 Train Loss 47.767845 Test MSE 5219.027356350406 Test RE 0.9996499562575324\n",
      "3 Train Loss 47.754787 Test MSE 5174.039218655153 Test RE 0.9953321281895083\n",
      "4 Train Loss 47.749775 Test MSE 5176.750970057812 Test RE 0.9955929244088394\n",
      "5 Train Loss 47.749603 Test MSE 5177.166464431725 Test RE 0.9956328775533122\n",
      "6 Train Loss 47.748775 Test MSE 5177.350398462318 Test RE 0.9956505637860111\n",
      "7 Train Loss 47.73847 Test MSE 5158.3516045364795 Test RE 0.9938220661940962\n",
      "8 Train Loss 47.713306 Test MSE 5097.2794738520015 Test RE 0.9879213874713575\n",
      "9 Train Loss 47.65779 Test MSE 4965.167265955414 Test RE 0.9750347776692443\n",
      "10 Train Loss 47.559498 Test MSE 4930.2078480949085 Test RE 0.9715961361269951\n",
      "11 Train Loss 47.505768 Test MSE 4880.4612400255655 Test RE 0.9666819259939089\n",
      "12 Train Loss 47.353508 Test MSE 4739.922008089618 Test RE 0.9526618250016391\n",
      "13 Train Loss 45.634396 Test MSE 4679.24886323929 Test RE 0.9465449361682823\n",
      "14 Train Loss 43.86798 Test MSE 5061.459385828533 Test RE 0.9844440599941195\n",
      "15 Train Loss 42.752037 Test MSE 4849.759005935456 Test RE 0.9636365049062722\n",
      "16 Train Loss 41.735355 Test MSE 4823.0613524531 Test RE 0.9609804618485348\n",
      "17 Train Loss 39.843853 Test MSE 5115.255246023008 Test RE 0.9896618277163414\n",
      "18 Train Loss 39.008717 Test MSE 5165.867691884298 Test RE 0.9945458375706704\n",
      "19 Train Loss 38.6994 Test MSE 5246.905837799056 Test RE 1.0023163156513961\n",
      "20 Train Loss 38.3458 Test MSE 5230.455370165841 Test RE 1.0007438158818913\n",
      "21 Train Loss 38.223244 Test MSE 5217.832548367262 Test RE 0.9995355232383903\n",
      "22 Train Loss 38.187622 Test MSE 5191.813411579041 Test RE 0.997040276993035\n",
      "23 Train Loss 37.629566 Test MSE 5100.899749227055 Test RE 0.9882721542545425\n",
      "24 Train Loss 37.35336 Test MSE 5178.244020265296 Test RE 0.9957364857918869\n",
      "25 Train Loss 37.290558 Test MSE 5225.763797645676 Test RE 1.0002948955526507\n",
      "26 Train Loss 37.005272 Test MSE 5164.2993905368385 Test RE 0.9943948594515245\n",
      "27 Train Loss 36.952663 Test MSE 5081.03051742597 Test RE 0.9863454973161495\n",
      "28 Train Loss 36.36906 Test MSE 5172.60015668508 Test RE 0.9951937020816323\n",
      "29 Train Loss 35.99315 Test MSE 5219.15783099238 Test RE 0.999662451704104\n",
      "30 Train Loss 34.734417 Test MSE 5358.216300901309 Test RE 1.012892336538725\n",
      "31 Train Loss 34.290894 Test MSE 5754.12026101046 Test RE 1.049645460492665\n",
      "32 Train Loss 34.225624 Test MSE 6067.024305885973 Test RE 1.0778070799762416\n",
      "33 Train Loss 34.067738 Test MSE 6708.97792121314 Test RE 1.133395139861947\n",
      "34 Train Loss 33.81438 Test MSE 7149.028251119745 Test RE 1.1699752410377688\n",
      "35 Train Loss 33.30445 Test MSE 7633.269135264897 Test RE 1.2089503135318176\n",
      "36 Train Loss 32.485874 Test MSE 8254.776408990669 Test RE 1.2572041960513376\n",
      "37 Train Loss 31.671293 Test MSE 9156.80543127696 Test RE 1.3241133302523502\n",
      "38 Train Loss 31.637331 Test MSE 9354.806187538163 Test RE 1.33835264572141\n",
      "39 Train Loss 31.63 Test MSE 9448.046451301976 Test RE 1.3450058540725083\n",
      "40 Train Loss 31.590395 Test MSE 9503.953598484204 Test RE 1.348979401916585\n",
      "41 Train Loss 31.562105 Test MSE 9419.01183774234 Test RE 1.3429376078017794\n",
      "42 Train Loss 31.478075 Test MSE 9323.949471480308 Test RE 1.3361435524714222\n",
      "43 Train Loss 31.368723 Test MSE 9359.657107775412 Test RE 1.338699601093131\n",
      "44 Train Loss 31.001476 Test MSE 9775.890473435225 Test RE 1.3681424818644865\n",
      "45 Train Loss 30.59278 Test MSE 10173.087376032636 Test RE 1.3956597439498566\n",
      "46 Train Loss 29.767591 Test MSE 10373.721548523088 Test RE 1.4093551860824913\n",
      "47 Train Loss 29.141373 Test MSE 10664.786417570926 Test RE 1.4289901849253803\n",
      "48 Train Loss 28.773746 Test MSE 10806.25704096573 Test RE 1.4384368869226816\n",
      "49 Train Loss 28.434301 Test MSE 10856.257328483187 Test RE 1.441760852562861\n",
      "50 Train Loss 28.127104 Test MSE 10853.917269101354 Test RE 1.441605458869973\n",
      "51 Train Loss 27.91926 Test MSE 10893.895860348817 Test RE 1.4442579750425864\n",
      "52 Train Loss 27.748688 Test MSE 10946.00155971461 Test RE 1.4477078107112713\n",
      "53 Train Loss 27.644165 Test MSE 10979.146094642767 Test RE 1.4498979864157724\n",
      "54 Train Loss 27.593565 Test MSE 11002.425358695658 Test RE 1.4514342937570472\n",
      "55 Train Loss 27.564194 Test MSE 11016.695342682859 Test RE 1.452375233233353\n",
      "56 Train Loss 27.49972 Test MSE 11049.013994559966 Test RE 1.4545040220170544\n",
      "57 Train Loss 27.49584 Test MSE 11051.51034700207 Test RE 1.4546683239901974\n",
      "58 Train Loss 27.460089 Test MSE 11073.596106209616 Test RE 1.4561211308083961\n",
      "59 Train Loss 27.446825 Test MSE 11086.905947539268 Test RE 1.4569959559726091\n",
      "60 Train Loss 27.440346 Test MSE 11090.73449083708 Test RE 1.4572475000303686\n",
      "61 Train Loss 27.384836 Test MSE 11136.330183587961 Test RE 1.4602399104423127\n",
      "62 Train Loss 27.348349 Test MSE 11187.291727620817 Test RE 1.4635772369528213\n",
      "63 Train Loss 27.3358 Test MSE 11210.703977230118 Test RE 1.465107890116054\n",
      "64 Train Loss 27.328035 Test MSE 11229.593147934675 Test RE 1.466341667472137\n",
      "65 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "66 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "67 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "68 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "69 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "70 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "71 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "72 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "73 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "74 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "75 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "76 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "77 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "78 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "79 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "80 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "81 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "82 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "83 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "84 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "85 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "86 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "87 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "88 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "89 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "90 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "91 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "92 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "93 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "94 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "95 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "96 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "98 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "99 Train Loss 27.326359 Test MSE 11234.040242414449 Test RE 1.4666319858468215\n",
      "Training time: 31.28\n",
      "Training time: 31.28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 47.76849 Test MSE 5220.349065676375 Test RE 0.9997765280245909\n",
      "1 Train Loss 47.768284 Test MSE 5220.213195234967 Test RE 0.9997635173082234\n",
      "2 Train Loss 47.767117 Test MSE 5216.174404625749 Test RE 0.9993766924164403\n",
      "3 Train Loss 47.74727 Test MSE 5169.276578429005 Test RE 0.9948739271587221\n",
      "4 Train Loss 47.746365 Test MSE 5171.095569851756 Test RE 0.9950489524201916\n",
      "5 Train Loss 47.74595 Test MSE 5172.48756079911 Test RE 0.9951828704570137\n",
      "6 Train Loss 47.743546 Test MSE 5171.033598390022 Test RE 0.9950429899677483\n",
      "7 Train Loss 47.716278 Test MSE 5129.996047384809 Test RE 0.9910867725976101\n",
      "8 Train Loss 47.51487 Test MSE 4963.8283198468325 Test RE 0.9749033010263275\n",
      "9 Train Loss 46.86917 Test MSE 4833.805106281412 Test RE 0.9620501967610935\n",
      "10 Train Loss 46.048035 Test MSE 5081.361404074255 Test RE 0.9863776131675767\n",
      "11 Train Loss 35.524776 Test MSE 4428.638568909231 Test RE 0.9208487092184732\n",
      "12 Train Loss 35.288326 Test MSE 4407.43654197393 Test RE 0.9186417913964068\n",
      "13 Train Loss 34.90674 Test MSE 4456.963240344479 Test RE 0.9237887961766011\n",
      "14 Train Loss 34.428898 Test MSE 4507.129733345098 Test RE 0.9289732192254061\n",
      "15 Train Loss 33.102173 Test MSE 4525.555889540263 Test RE 0.9308702077051478\n",
      "16 Train Loss 31.569172 Test MSE 4365.799732714576 Test RE 0.9142923156073457\n",
      "17 Train Loss 31.14898 Test MSE 4295.283467508889 Test RE 0.9068784456734441\n",
      "18 Train Loss 30.725225 Test MSE 4323.860968954825 Test RE 0.9098902790362408\n",
      "19 Train Loss 30.512077 Test MSE 4375.820917059082 Test RE 0.915341039859774\n",
      "20 Train Loss 29.93246 Test MSE 4836.81694094254 Test RE 0.9623498659510897\n",
      "21 Train Loss 29.467978 Test MSE 5114.851775452431 Test RE 0.9896227966927471\n",
      "22 Train Loss 28.762444 Test MSE 4881.664425098027 Test RE 0.9668010771898636\n",
      "23 Train Loss 28.38113 Test MSE 4944.54289792956 Test RE 0.973007615114471\n",
      "24 Train Loss 28.044134 Test MSE 5011.229413371343 Test RE 0.9795470640010372\n",
      "25 Train Loss 27.792116 Test MSE 5047.298126782354 Test RE 0.9830659266166227\n",
      "26 Train Loss 27.717558 Test MSE 5050.660907343762 Test RE 0.9833933576953721\n",
      "27 Train Loss 27.408155 Test MSE 5002.254002726753 Test RE 0.9786694572677348\n",
      "28 Train Loss 27.304148 Test MSE 4979.622305512298 Test RE 0.9764530504465115\n",
      "29 Train Loss 27.270164 Test MSE 4972.2200551262185 Test RE 0.975727027705585\n",
      "30 Train Loss 26.91508 Test MSE 5071.435439756966 Test RE 0.9854137440175091\n",
      "31 Train Loss 26.083836 Test MSE 5209.726578542027 Test RE 0.9987588258375177\n",
      "32 Train Loss 25.199778 Test MSE 5527.912454997043 Test RE 1.028806603019675\n",
      "33 Train Loss 24.662224 Test MSE 5778.460092934924 Test RE 1.051863109135161\n",
      "34 Train Loss 24.58174 Test MSE 5820.6576559858395 Test RE 1.0556967707593938\n",
      "35 Train Loss 24.518002 Test MSE 5879.570927992098 Test RE 1.0610258909325245\n",
      "36 Train Loss 24.490854 Test MSE 5922.497133069714 Test RE 1.0648920731918081\n",
      "37 Train Loss 24.369392 Test MSE 6095.351372215642 Test RE 1.0803203019823973\n",
      "38 Train Loss 24.273098 Test MSE 6112.943780032359 Test RE 1.0818781893414722\n",
      "39 Train Loss 23.681372 Test MSE 6036.65956797254 Test RE 1.0751065484018854\n",
      "40 Train Loss 23.348986 Test MSE 6160.469435823476 Test RE 1.086075628608842\n",
      "41 Train Loss 23.015965 Test MSE 6352.119601943685 Test RE 1.1028399706505077\n",
      "42 Train Loss 22.619822 Test MSE 6433.24365605678 Test RE 1.1098599116603827\n",
      "43 Train Loss 22.585907 Test MSE 6471.690102181376 Test RE 1.1131713521902786\n",
      "44 Train Loss 22.454363 Test MSE 6482.354597765513 Test RE 1.1140881547701473\n",
      "45 Train Loss 22.385553 Test MSE 6423.787768799999 Test RE 1.1090439492936908\n",
      "46 Train Loss 22.226952 Test MSE 6375.263668398054 Test RE 1.1048472529397049\n",
      "47 Train Loss 22.117477 Test MSE 6385.044658590866 Test RE 1.1056944617003994\n",
      "48 Train Loss 21.790802 Test MSE 6418.003220777144 Test RE 1.1085444960819733\n",
      "49 Train Loss 21.32685 Test MSE 6482.992439416623 Test RE 1.114142964665056\n",
      "50 Train Loss 21.17698 Test MSE 6506.333385390255 Test RE 1.1161468067344837\n",
      "51 Train Loss 21.029062 Test MSE 6482.796924019222 Test RE 1.1141261642639364\n",
      "52 Train Loss 20.928188 Test MSE 6448.342864120125 Test RE 1.111161602155447\n",
      "53 Train Loss 20.862003 Test MSE 6449.823493784097 Test RE 1.1112891639518505\n",
      "54 Train Loss 20.816963 Test MSE 6458.938081355113 Test RE 1.1120740975629124\n",
      "55 Train Loss 20.714563 Test MSE 6429.293419438488 Test RE 1.1095191129342803\n",
      "56 Train Loss 20.647598 Test MSE 6400.816042520164 Test RE 1.1070591801701737\n",
      "57 Train Loss 20.424765 Test MSE 6349.4389233315205 Test RE 1.102607239556102\n",
      "58 Train Loss 19.68676 Test MSE 6276.521101623972 Test RE 1.0962577113186915\n",
      "59 Train Loss 19.124353 Test MSE 6260.260425801293 Test RE 1.094836744878631\n",
      "60 Train Loss 18.778961 Test MSE 6182.379075394928 Test RE 1.0880052223052195\n",
      "61 Train Loss 18.390348 Test MSE 6054.457774379057 Test RE 1.0766902789927244\n",
      "62 Train Loss 18.35097 Test MSE 6072.466141595603 Test RE 1.0782903427865234\n",
      "63 Train Loss 18.245996 Test MSE 6087.2946074973315 Test RE 1.0796060884745724\n",
      "64 Train Loss 17.930954 Test MSE 6121.116974039742 Test RE 1.0826011999715226\n",
      "65 Train Loss 16.90465 Test MSE 6236.887616763167 Test RE 1.09279103609335\n",
      "66 Train Loss 16.66564 Test MSE 6160.129720991237 Test RE 1.0860456827507858\n",
      "67 Train Loss 16.483847 Test MSE 6072.73638769626 Test RE 1.0783143363759211\n",
      "68 Train Loss 16.422829 Test MSE 6055.011743789801 Test RE 1.0767395352480917\n",
      "69 Train Loss 16.282793 Test MSE 6181.75299838788 Test RE 1.0879501308678372\n",
      "70 Train Loss 16.18583 Test MSE 6172.720534915582 Test RE 1.0871550115808846\n",
      "71 Train Loss 16.117413 Test MSE 6108.126783688216 Test RE 1.0814518456255098\n",
      "72 Train Loss 16.03716 Test MSE 6042.245308112371 Test RE 1.075603833133937\n",
      "73 Train Loss 15.857879 Test MSE 6030.283584258178 Test RE 1.0745386289451448\n",
      "74 Train Loss 15.758313 Test MSE 6046.073951935295 Test RE 1.0759445551348967\n",
      "75 Train Loss 15.516019 Test MSE 5908.656624027784 Test RE 1.063647051966835\n",
      "76 Train Loss 15.402489 Test MSE 5963.703607880496 Test RE 1.0685902081107976\n",
      "77 Train Loss 15.211557 Test MSE 6063.727259556202 Test RE 1.0775141799797943\n",
      "78 Train Loss 15.106889 Test MSE 6067.835535825824 Test RE 1.077879135081259\n",
      "79 Train Loss 15.068075 Test MSE 6038.0031511315665 Test RE 1.0752261853194331\n",
      "80 Train Loss 14.993973 Test MSE 5910.463966916451 Test RE 1.0638097139791973\n",
      "81 Train Loss 14.82873 Test MSE 5759.011662226608 Test RE 1.0500915014336138\n",
      "82 Train Loss 14.592644 Test MSE 5764.071409959639 Test RE 1.0505526944213595\n",
      "83 Train Loss 14.2952585 Test MSE 5821.969058504205 Test RE 1.0558156890599653\n",
      "84 Train Loss 14.155958 Test MSE 5818.005583590098 Test RE 1.0554562392405056\n",
      "85 Train Loss 14.013278 Test MSE 5745.808704147076 Test RE 1.0488871047203787\n",
      "86 Train Loss 13.973509 Test MSE 5729.306820934582 Test RE 1.0473798270855859\n",
      "87 Train Loss 13.847591 Test MSE 5781.898006765246 Test RE 1.0521759673155917\n",
      "88 Train Loss 13.609724 Test MSE 6058.965167611775 Test RE 1.0770909889941256\n",
      "89 Train Loss 13.076456 Test MSE 6231.5458780598565 Test RE 1.09232296171361\n",
      "90 Train Loss 12.953537 Test MSE 6282.747383723948 Test RE 1.0968013180197294\n",
      "91 Train Loss 12.90052 Test MSE 6403.1109585878585 Test RE 1.1072576220719752\n",
      "92 Train Loss 12.862621 Test MSE 6479.89299091256 Test RE 1.1138766029799294\n",
      "93 Train Loss 12.808091 Test MSE 6512.363483749902 Test RE 1.116663911829906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 12.751297 Test MSE 6541.316756318631 Test RE 1.1191434432029481\n",
      "95 Train Loss 12.652051 Test MSE 6727.820361266276 Test RE 1.1349856173160506\n",
      "96 Train Loss 12.607227 Test MSE 6829.567591965474 Test RE 1.1435358081960225\n",
      "97 Train Loss 12.556284 Test MSE 6853.400357444191 Test RE 1.145529337463977\n",
      "98 Train Loss 12.483355 Test MSE 6900.011212000621 Test RE 1.1494181824854632\n",
      "99 Train Loss 12.302089 Test MSE 6900.5755994715855 Test RE 1.1494651899421342\n",
      "Training time: 44.73\n",
      "Training time: 44.73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 47.769997 Test MSE 5223.730936830013 Test RE 1.0001003155666162\n",
      "1 Train Loss 47.769867 Test MSE 5223.454045033593 Test RE 1.0000738092968582\n",
      "2 Train Loss 47.756756 Test MSE 5195.852468571271 Test RE 0.9974280335676584\n",
      "3 Train Loss 47.746403 Test MSE 5169.509463660325 Test RE 0.9948963373385291\n",
      "4 Train Loss 47.727173 Test MSE 5123.32288467033 Test RE 0.9904419538270871\n",
      "5 Train Loss 47.678192 Test MSE 5039.231962845133 Test RE 0.9822800862172711\n",
      "6 Train Loss 47.53368 Test MSE 4974.707640046516 Test RE 0.9759710736557825\n",
      "7 Train Loss 47.084316 Test MSE 4752.149974027401 Test RE 0.9538898634542171\n",
      "8 Train Loss 46.85247 Test MSE 4689.196200570502 Test RE 0.9475505038725103\n",
      "9 Train Loss 45.825058 Test MSE 4540.998307325657 Test RE 0.932457045336959\n",
      "10 Train Loss 45.309254 Test MSE 4533.291258015392 Test RE 0.9316654193786179\n",
      "11 Train Loss 44.806816 Test MSE 4547.29430137736 Test RE 0.933103237001093\n",
      "12 Train Loss 44.205658 Test MSE 4572.471672749375 Test RE 0.9356828652227535\n",
      "13 Train Loss 43.707714 Test MSE 4588.159244874308 Test RE 0.9372865956487212\n",
      "14 Train Loss 43.358646 Test MSE 4596.268087147502 Test RE 0.938114482568395\n",
      "15 Train Loss 42.56269 Test MSE 4590.121704102406 Test RE 0.9374870235312438\n",
      "16 Train Loss 41.971737 Test MSE 4665.829626015201 Test RE 0.9451867020596441\n",
      "17 Train Loss 40.527042 Test MSE 5083.594651822685 Test RE 0.9865943448096915\n",
      "18 Train Loss 40.251667 Test MSE 5140.324959818742 Test RE 0.9920840151654701\n",
      "19 Train Loss 39.95736 Test MSE 5204.124044796428 Test RE 0.9982216493542081\n",
      "20 Train Loss 39.698254 Test MSE 5132.0205080940295 Test RE 0.9912823105962799\n",
      "21 Train Loss 39.387028 Test MSE 5190.128087366086 Test RE 0.9968784383084288\n",
      "22 Train Loss 39.26493 Test MSE 5223.790958060643 Test RE 1.0001060611802393\n",
      "23 Train Loss 39.23264 Test MSE 5238.800953037681 Test RE 1.001541878482241\n",
      "24 Train Loss 39.079895 Test MSE 5296.586350119422 Test RE 1.0070503695439432\n",
      "25 Train Loss 38.752075 Test MSE 5271.963964807749 Test RE 1.0047068915750001\n",
      "26 Train Loss 38.68051 Test MSE 5272.365336126807 Test RE 1.0047451366064486\n",
      "27 Train Loss 38.368706 Test MSE 5354.932204580822 Test RE 1.0125818837998724\n",
      "28 Train Loss 37.990685 Test MSE 5336.799673774788 Test RE 1.0108660598822454\n",
      "29 Train Loss 37.558807 Test MSE 5390.759695771828 Test RE 1.0159636063698665\n",
      "30 Train Loss 36.961876 Test MSE 5451.306887591093 Test RE 1.0216531552147798\n",
      "31 Train Loss 36.58174 Test MSE 5433.291024623558 Test RE 1.0199635424176425\n",
      "32 Train Loss 36.48337 Test MSE 5444.9705638563755 Test RE 1.0210592235679046\n",
      "33 Train Loss 36.31391 Test MSE 5334.156043271952 Test RE 1.0106156581865344\n",
      "34 Train Loss 35.006084 Test MSE 5133.655144280633 Test RE 0.9914401682006951\n",
      "35 Train Loss 34.40946 Test MSE 5143.902801443857 Test RE 0.9924292172763277\n",
      "36 Train Loss 34.22421 Test MSE 5198.223444016496 Test RE 0.997655581180503\n",
      "37 Train Loss 34.16463 Test MSE 5284.508028947701 Test RE 1.0059014767190855\n",
      "38 Train Loss 34.078953 Test MSE 5312.027623424378 Test RE 1.0085172410363679\n",
      "39 Train Loss 33.996876 Test MSE 5234.868289184651 Test RE 1.0011658891063484\n",
      "40 Train Loss 33.72852 Test MSE 5034.133806385133 Test RE 0.9817830774628814\n",
      "41 Train Loss 33.23568 Test MSE 5228.619832001594 Test RE 1.0005682035764263\n",
      "42 Train Loss 32.957966 Test MSE 5202.008180878779 Test RE 0.9980187030104282\n",
      "43 Train Loss 32.78868 Test MSE 5141.215923804902 Test RE 0.9921699895773285\n",
      "44 Train Loss 32.736607 Test MSE 5143.081183463681 Test RE 0.9923499554508994\n",
      "45 Train Loss 32.376045 Test MSE 5344.4913180464355 Test RE 1.0115942512261162\n",
      "46 Train Loss 31.629562 Test MSE 5222.687025113146 Test RE 1.0000003804230928\n",
      "47 Train Loss 31.348888 Test MSE 5211.707444744672 Test RE 0.9989486841293881\n",
      "48 Train Loss 30.724518 Test MSE 5271.935059532678 Test RE 1.0047041372533596\n",
      "49 Train Loss 30.60119 Test MSE 5222.013966113046 Test RE 0.9999359422384033\n",
      "50 Train Loss 30.57454 Test MSE 5214.104460412115 Test RE 0.9991783804823574\n",
      "51 Train Loss 30.456163 Test MSE 5208.230129602058 Test RE 0.9986153731144025\n",
      "52 Train Loss 30.324423 Test MSE 5097.933200189438 Test RE 0.9879847359230178\n",
      "53 Train Loss 30.055471 Test MSE 5006.480514718814 Test RE 0.979082819408039\n",
      "54 Train Loss 29.810387 Test MSE 5073.823590160498 Test RE 0.9856457334885477\n",
      "55 Train Loss 29.440073 Test MSE 5062.990080378567 Test RE 0.9845929073058644\n",
      "56 Train Loss 28.205835 Test MSE 5150.135233361702 Test RE 0.9930302565423745\n",
      "57 Train Loss 27.31952 Test MSE 5135.437242487557 Test RE 0.9916122376509547\n",
      "58 Train Loss 26.717665 Test MSE 5252.233479492276 Test RE 1.0028250561842258\n",
      "59 Train Loss 26.27871 Test MSE 5430.0480955591365 Test RE 1.0196591078581017\n",
      "60 Train Loss 25.918612 Test MSE 5518.2992225724365 Test RE 1.0279116484911683\n",
      "61 Train Loss 25.623587 Test MSE 5613.32565723439 Test RE 1.036724313802464\n",
      "62 Train Loss 25.321093 Test MSE 5656.670575606842 Test RE 1.040719299914078\n",
      "63 Train Loss 25.093906 Test MSE 5717.166895186716 Test RE 1.0462695831729032\n",
      "64 Train Loss 25.039537 Test MSE 5724.825067818398 Test RE 1.0469700902448196\n",
      "65 Train Loss 25.027163 Test MSE 5735.024737290823 Test RE 1.047902345511098\n",
      "66 Train Loss 25.01677 Test MSE 5749.536409272933 Test RE 1.0492272925060266\n",
      "67 Train Loss 24.91632 Test MSE 5822.330597623764 Test RE 1.0558484711603928\n",
      "68 Train Loss 24.72109 Test MSE 5856.967121171425 Test RE 1.0589843882745356\n",
      "69 Train Loss 24.467318 Test MSE 5923.06220943568 Test RE 1.064942873637686\n",
      "70 Train Loss 24.351805 Test MSE 6023.609373687407 Test RE 1.0739438242024368\n",
      "71 Train Loss 24.266495 Test MSE 6106.425992516024 Test RE 1.0813012714909327\n",
      "72 Train Loss 24.05807 Test MSE 6137.010905177483 Test RE 1.0840058156486219\n",
      "73 Train Loss 23.976763 Test MSE 6158.491381682427 Test RE 1.0859012515670836\n",
      "74 Train Loss 23.96765 Test MSE 6177.16696489399 Test RE 1.0875464992889927\n",
      "75 Train Loss 23.959276 Test MSE 6206.472348100922 Test RE 1.0901231866576482\n",
      "76 Train Loss 23.953554 Test MSE 6218.352285636178 Test RE 1.0911660015861964\n",
      "77 Train Loss 23.94871 Test MSE 6214.988754913653 Test RE 1.0908708537208376\n",
      "78 Train Loss 23.947935 Test MSE 6214.076102440195 Test RE 1.0907907552223108\n",
      "79 Train Loss 23.94624 Test MSE 6212.181118150873 Test RE 1.0906244240638658\n",
      "80 Train Loss 23.941635 Test MSE 6205.889365705813 Test RE 1.0900719870779794\n",
      "81 Train Loss 23.941635 Test MSE 6205.889365705813 Test RE 1.0900719870779794\n",
      "82 Train Loss 23.941635 Test MSE 6205.889365705813 Test RE 1.0900719870779794\n",
      "83 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "84 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "85 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "86 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "87 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "88 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "89 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "90 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "92 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "93 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "94 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "95 Train Loss 23.941534 Test MSE 6205.943079803036 Test RE 1.090076704540904\n",
      "96 Train Loss 23.941534 Test MSE 6205.943120786554 Test RE 1.0900767081402911\n",
      "97 Train Loss 23.941534 Test MSE 6205.943120786554 Test RE 1.0900767081402911\n",
      "98 Train Loss 23.941534 Test MSE 6205.943120786554 Test RE 1.0900767081402911\n",
      "99 Train Loss 23.941534 Test MSE 6205.943120786554 Test RE 1.0900767081402911\n",
      "Training time: 39.54\n",
      "Training time: 39.54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 47.768887 Test MSE 5221.366153653331 Test RE 0.9998739172172701\n",
      "1 Train Loss 47.76875 Test MSE 5221.176532877651 Test RE 0.9998557611845785\n",
      "2 Train Loss 47.76869 Test MSE 5221.027785204837 Test RE 0.9998415184869814\n",
      "3 Train Loss 47.74352 Test MSE 5163.059056397074 Test RE 0.9942754380290829\n",
      "4 Train Loss 47.74185 Test MSE 5165.412055121956 Test RE 0.9945019764359052\n",
      "5 Train Loss 47.72796 Test MSE 5145.696040836749 Test RE 0.9926021898380846\n",
      "6 Train Loss 47.678997 Test MSE 5016.311170379543 Test RE 0.9800436047116002\n",
      "7 Train Loss 46.476784 Test MSE 4701.736715523977 Test RE 0.9488166949969317\n",
      "8 Train Loss 45.437595 Test MSE 4560.436820492303 Test RE 0.934450684326767\n",
      "9 Train Loss 45.098713 Test MSE 4808.66138950641 Test RE 0.959544814819599\n",
      "10 Train Loss 44.215897 Test MSE 4829.864227874777 Test RE 0.9616579492644962\n",
      "11 Train Loss 42.039898 Test MSE 4665.58819053629 Test RE 0.9451622471851051\n",
      "12 Train Loss 29.341755 Test MSE 1964.0956799443509 Test RE 0.6132456621708184\n",
      "13 Train Loss 21.577574 Test MSE 1332.9195176706298 Test RE 0.5051904455378302\n",
      "14 Train Loss 21.502691 Test MSE 1305.3972251142156 Test RE 0.4999476223093392\n",
      "15 Train Loss 21.24971 Test MSE 1239.773577152904 Test RE 0.48721915334617877\n",
      "16 Train Loss 21.096523 Test MSE 1181.2817120463626 Test RE 0.4755869234620081\n",
      "17 Train Loss 20.719671 Test MSE 1173.5217947387312 Test RE 0.4740222687486998\n",
      "18 Train Loss 20.669594 Test MSE 1196.8424135697608 Test RE 0.47870906368325605\n",
      "19 Train Loss 20.219316 Test MSE 1181.8567884399367 Test RE 0.4757026729617395\n",
      "20 Train Loss 19.84218 Test MSE 1057.879681020445 Test RE 0.4500609188198423\n",
      "21 Train Loss 19.51498 Test MSE 988.4309811795295 Test RE 0.4350371442414964\n",
      "22 Train Loss 18.920033 Test MSE 1004.510020422278 Test RE 0.4385612957789202\n",
      "23 Train Loss 18.121454 Test MSE 840.9007408467794 Test RE 0.4012596890149916\n",
      "24 Train Loss 17.905674 Test MSE 805.5897263336155 Test RE 0.39274451113017755\n",
      "25 Train Loss 17.466942 Test MSE 838.9825974295795 Test RE 0.4008017794113145\n",
      "26 Train Loss 17.110834 Test MSE 877.8209506545288 Test RE 0.4099738304140149\n",
      "27 Train Loss 16.393106 Test MSE 781.0228446678656 Test RE 0.3867096709710198\n",
      "28 Train Loss 14.996486 Test MSE 590.1046885279592 Test RE 0.3361380662344531\n",
      "29 Train Loss 14.328055 Test MSE 602.8270180664322 Test RE 0.33974221900513024\n",
      "30 Train Loss 13.401459 Test MSE 489.31338439894057 Test RE 0.3060882880424561\n",
      "31 Train Loss 13.153459 Test MSE 486.13436099651307 Test RE 0.3050923542605617\n",
      "32 Train Loss 13.060641 Test MSE 494.66239712856617 Test RE 0.30775676878291003\n",
      "33 Train Loss 12.939419 Test MSE 487.4678232305902 Test RE 0.3055105005229169\n",
      "34 Train Loss 12.85293 Test MSE 470.2430067247283 Test RE 0.3000643061859856\n",
      "35 Train Loss 12.801583 Test MSE 459.9003438683545 Test RE 0.2967461081306679\n",
      "36 Train Loss 12.706047 Test MSE 443.90978954817615 Test RE 0.2915415953710319\n",
      "37 Train Loss 12.44471 Test MSE 477.57079012312664 Test RE 0.3023932152021194\n",
      "38 Train Loss 12.299147 Test MSE 520.935235593366 Test RE 0.3158239286157549\n",
      "39 Train Loss 12.240375 Test MSE 542.9700558048593 Test RE 0.3224342029583722\n",
      "40 Train Loss 12.160323 Test MSE 557.5753146743898 Test RE 0.3267419779601841\n",
      "41 Train Loss 11.917042 Test MSE 606.8095297240665 Test RE 0.34086260677904306\n",
      "42 Train Loss 11.822026 Test MSE 619.3187402913162 Test RE 0.34435807829648446\n",
      "43 Train Loss 11.609721 Test MSE 596.5070823417825 Test RE 0.3379566269508528\n",
      "44 Train Loss 11.520794 Test MSE 587.0541234214514 Test RE 0.33526810219576847\n",
      "45 Train Loss 11.454736 Test MSE 639.8558832972175 Test RE 0.3500211186374218\n",
      "46 Train Loss 11.359404 Test MSE 678.0929804282464 Test RE 0.3603278156770585\n",
      "47 Train Loss 11.200119 Test MSE 710.0290529210229 Test RE 0.36871535537161015\n",
      "48 Train Loss 11.124181 Test MSE 760.4006057345116 Test RE 0.3815701491093648\n",
      "49 Train Loss 11.117484 Test MSE 784.5682657175513 Test RE 0.38758640344040796\n",
      "50 Train Loss 11.089546 Test MSE 815.0707204591552 Test RE 0.3950488581717303\n",
      "51 Train Loss 11.054362 Test MSE 805.1637572869288 Test RE 0.39264066228463645\n",
      "52 Train Loss 10.99727 Test MSE 802.6106292814638 Test RE 0.3920176475180213\n",
      "53 Train Loss 10.974284 Test MSE 812.1372279355604 Test RE 0.3943373141068275\n",
      "54 Train Loss 10.962557 Test MSE 819.7306657514289 Test RE 0.3961765408964157\n",
      "55 Train Loss 10.951888 Test MSE 826.4703389981081 Test RE 0.3978018519430949\n",
      "56 Train Loss 10.929578 Test MSE 850.587406278667 Test RE 0.4035642052268849\n",
      "57 Train Loss 10.906114 Test MSE 877.6165100165493 Test RE 0.40992608708321104\n",
      "58 Train Loss 10.889247 Test MSE 893.128263403742 Test RE 0.4135329134851019\n",
      "59 Train Loss 10.844839 Test MSE 867.0830729530269 Test RE 0.40745862821566436\n",
      "60 Train Loss 10.821147 Test MSE 846.4096671768737 Test RE 0.4025719137429742\n",
      "61 Train Loss 10.788901 Test MSE 830.2691406341472 Test RE 0.39871503523728874\n",
      "62 Train Loss 10.747695 Test MSE 800.2390680735953 Test RE 0.39143805039135454\n",
      "63 Train Loss 10.676291 Test MSE 706.0967943079701 Test RE 0.3676929344377986\n",
      "64 Train Loss 9.139308 Test MSE 747.1124107719668 Test RE 0.3782214367811591\n",
      "65 Train Loss 7.278056 Test MSE 738.724811937693 Test RE 0.3760923570255083\n",
      "66 Train Loss 6.725176 Test MSE 990.8845308270121 Test RE 0.4355767487709198\n",
      "67 Train Loss 6.604537 Test MSE 905.0141426941683 Test RE 0.41627549669295866\n",
      "68 Train Loss 6.5484695 Test MSE 853.9950167652046 Test RE 0.40437177364583177\n",
      "69 Train Loss 6.53095 Test MSE 849.3701763367482 Test RE 0.40327534231891476\n",
      "70 Train Loss 6.509123 Test MSE 881.4162202273626 Test RE 0.4108125323713004\n",
      "71 Train Loss 6.4817953 Test MSE 909.3946808625519 Test RE 0.4172817292788677\n",
      "72 Train Loss 6.4387307 Test MSE 888.9335390843567 Test RE 0.4125606577562408\n",
      "73 Train Loss 6.384297 Test MSE 872.1519253247305 Test RE 0.40864786720094476\n",
      "74 Train Loss 6.296748 Test MSE 928.8676223441422 Test RE 0.42172570908653023\n",
      "75 Train Loss 6.267441 Test MSE 994.9788899452271 Test RE 0.436475727967259\n",
      "76 Train Loss 6.196929 Test MSE 1037.577126908017 Test RE 0.4457212700316322\n",
      "77 Train Loss 6.0008397 Test MSE 1057.1309411903608 Test RE 0.44990161989898625\n",
      "78 Train Loss 5.76402 Test MSE 1034.245765905487 Test RE 0.44500515351424086\n",
      "79 Train Loss 5.6880245 Test MSE 1007.3234223800661 Test RE 0.43917502110704965\n",
      "80 Train Loss 5.683067 Test MSE 995.8032520074023 Test RE 0.4366565054376231\n",
      "81 Train Loss 5.68245 Test MSE 994.7064456530202 Test RE 0.4364159661655708\n",
      "82 Train Loss 5.680558 Test MSE 993.8963200956379 Test RE 0.43623821334960117\n",
      "83 Train Loss 5.680558 Test MSE 993.8963200956379 Test RE 0.43623821334960117\n",
      "84 Train Loss 5.680558 Test MSE 993.8963200956379 Test RE 0.43623821334960117\n",
      "85 Train Loss 5.675424 Test MSE 1007.3278701503292 Test RE 0.43917599068017754\n",
      "86 Train Loss 5.673514 Test MSE 1010.5910659434993 Test RE 0.4398867614893645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 5.6655455 Test MSE 1048.3424249231873 Test RE 0.4480275758372697\n",
      "88 Train Loss 5.6536736 Test MSE 1094.0348363791893 Test RE 0.4576871719672252\n",
      "89 Train Loss 5.636524 Test MSE 1103.8532776765778 Test RE 0.45973634677411235\n",
      "90 Train Loss 5.625115 Test MSE 1089.8443711365164 Test RE 0.456809794851271\n",
      "91 Train Loss 5.622587 Test MSE 1090.7069944380573 Test RE 0.4569905439747523\n",
      "92 Train Loss 5.618053 Test MSE 1088.6586771553434 Test RE 0.45656123458112857\n",
      "93 Train Loss 5.612553 Test MSE 1071.2985558233893 Test RE 0.45290636525745825\n",
      "94 Train Loss 5.611529 Test MSE 1064.3047899355702 Test RE 0.4514255886561702\n",
      "95 Train Loss 5.6104326 Test MSE 1057.6595518247757 Test RE 0.4500140908562239\n",
      "96 Train Loss 5.610236 Test MSE 1058.4628738834253 Test RE 0.45018495757216764\n",
      "97 Train Loss 5.610236 Test MSE 1058.4628738834253 Test RE 0.45018495757216764\n",
      "98 Train Loss 5.610234 Test MSE 1058.4638021248672 Test RE 0.45018515497174244\n",
      "99 Train Loss 5.609895 Test MSE 1061.185105333673 Test RE 0.4507634949632604\n",
      "Training time: 41.86\n",
      "Training time: 41.86\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 47.77018 Test MSE 5224.001814674089 Test RE 1.0001262454535826\n",
      "1 Train Loss 47.769997 Test MSE 5223.650698475078 Test RE 1.0000926345898187\n",
      "2 Train Loss 47.76942 Test MSE 5221.7443972391475 Test RE 0.9999101327435962\n",
      "3 Train Loss 47.749393 Test MSE 5180.347856845367 Test RE 0.9959387410448574\n",
      "4 Train Loss 47.74522 Test MSE 5162.194469497546 Test RE 0.9941921856878061\n",
      "5 Train Loss 47.727657 Test MSE 5117.637173405376 Test RE 0.9898922197629484\n",
      "6 Train Loss 47.703564 Test MSE 5085.058586785507 Test RE 0.986736390555765\n",
      "7 Train Loss 47.613197 Test MSE 4914.6236714509405 Test RE 0.9700593337591539\n",
      "8 Train Loss 47.51545 Test MSE 4741.618281538358 Test RE 0.9528322740517977\n",
      "9 Train Loss 47.4782 Test MSE 4678.081394229488 Test RE 0.94642684768354\n",
      "10 Train Loss 47.357468 Test MSE 4699.948527677864 Test RE 0.9486362485006361\n",
      "11 Train Loss 47.289013 Test MSE 4799.944659296924 Test RE 0.9586747299389484\n",
      "12 Train Loss 47.2597 Test MSE 4812.7743073498195 Test RE 0.9599550834110677\n",
      "13 Train Loss 46.510715 Test MSE 4655.293397090314 Test RE 0.9441189035401453\n",
      "14 Train Loss 45.80246 Test MSE 4564.359819374473 Test RE 0.9348525165535984\n",
      "15 Train Loss 45.056892 Test MSE 4515.524570776949 Test RE 0.9298379548383363\n",
      "16 Train Loss 44.7797 Test MSE 4550.447815577036 Test RE 0.9334267309438301\n",
      "17 Train Loss 44.37912 Test MSE 4585.334655728 Test RE 0.9369980423325923\n",
      "18 Train Loss 43.09126 Test MSE 4736.074559316041 Test RE 0.9522751032727763\n",
      "19 Train Loss 41.550404 Test MSE 5713.1631485555245 Test RE 1.0459031663755427\n",
      "20 Train Loss 40.479694 Test MSE 5264.139272560756 Test RE 1.0039610176010663\n",
      "21 Train Loss 40.349186 Test MSE 4945.395526396409 Test RE 0.9730915033774523\n",
      "22 Train Loss 40.249367 Test MSE 4620.126428706683 Test RE 0.9405461168299392\n",
      "23 Train Loss 40.184834 Test MSE 4472.658656163196 Test RE 0.9254139505670466\n",
      "24 Train Loss 40.130505 Test MSE 4410.422318676377 Test RE 0.9189529013646061\n",
      "25 Train Loss 39.98498 Test MSE 4335.907751076968 Test RE 0.9111569277341987\n",
      "26 Train Loss 39.685253 Test MSE 4217.550676725267 Test RE 0.8986349793610896\n",
      "27 Train Loss 39.396797 Test MSE 4321.082779252196 Test RE 0.9095979183424207\n",
      "28 Train Loss 35.58934 Test MSE 2740.883961040387 Test RE 0.7244334403288815\n",
      "29 Train Loss 27.329336 Test MSE 2288.5856319513623 Test RE 0.6619676225375705\n",
      "30 Train Loss 25.390287 Test MSE 1822.818699559181 Test RE 0.590778799915035\n",
      "31 Train Loss 21.173588 Test MSE 1233.5680117826325 Test RE 0.4859982597567194\n",
      "32 Train Loss 19.972925 Test MSE 1052.4106808261783 Test RE 0.4488960544472959\n",
      "33 Train Loss 19.486227 Test MSE 989.2457421248278 Test RE 0.43521640726967725\n",
      "34 Train Loss 19.005354 Test MSE 918.618178833594 Test RE 0.4193925219723505\n",
      "35 Train Loss 18.79362 Test MSE 873.3916865227666 Test RE 0.4089382098814054\n",
      "36 Train Loss 18.748053 Test MSE 847.9573327781707 Test RE 0.4029397983359498\n",
      "37 Train Loss 18.732803 Test MSE 834.9544853955135 Test RE 0.39983845967728215\n",
      "38 Train Loss 18.729067 Test MSE 832.0521948558984 Test RE 0.39914293819645513\n",
      "39 Train Loss 18.72408 Test MSE 829.0855198692179 Test RE 0.3984307324219382\n",
      "40 Train Loss 18.68164 Test MSE 802.5031606383519 Test RE 0.3919914012826187\n",
      "41 Train Loss 18.475647 Test MSE 770.9641265242068 Test RE 0.3842114028246998\n",
      "42 Train Loss 18.406124 Test MSE 774.3383895915824 Test RE 0.3850512700005413\n",
      "43 Train Loss 18.353022 Test MSE 762.3450312863063 Test RE 0.38205769544086166\n",
      "44 Train Loss 18.324957 Test MSE 755.6929297314169 Test RE 0.38038715588279787\n",
      "45 Train Loss 18.304237 Test MSE 753.0884435050951 Test RE 0.3797310903279877\n",
      "46 Train Loss 18.281593 Test MSE 743.9910507569545 Test RE 0.3774305243925669\n",
      "47 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "48 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "49 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "50 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "51 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "52 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "53 Train Loss 18.281422 Test MSE 743.8316583837179 Test RE 0.377390091937473\n",
      "54 Train Loss 18.281364 Test MSE 743.7836844215543 Test RE 0.3773779217174246\n",
      "55 Train Loss 18.281046 Test MSE 743.6138747513456 Test RE 0.37733484059062805\n",
      "56 Train Loss 18.281006 Test MSE 743.5105457013909 Test RE 0.3773086233517724\n",
      "57 Train Loss 18.281006 Test MSE 743.5105457013909 Test RE 0.3773086233517724\n",
      "58 Train Loss 18.281006 Test MSE 743.5105457013909 Test RE 0.3773086233517724\n",
      "59 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "60 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "61 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "62 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "63 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "64 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "65 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "66 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "67 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "68 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "69 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "70 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "71 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "72 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "73 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "74 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "75 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "76 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "77 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "78 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "79 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "80 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "81 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "82 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "83 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "85 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "86 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "87 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "88 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "89 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "90 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "91 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "92 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "93 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "94 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "95 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "96 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "97 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "98 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "99 Train Loss 18.280952 Test MSE 743.510397319773 Test RE 0.3773085857022279\n",
      "Training time: 37.28\n",
      "Training time: 37.28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 47.768307 Test MSE 5219.2780242106055 Test RE 0.9996739623691724\n",
      "1 Train Loss 47.752342 Test MSE 5176.87116300936 Test RE 0.9956044820980391\n",
      "2 Train Loss 47.749977 Test MSE 5179.412104672885 Test RE 0.9958487862815937\n",
      "3 Train Loss 47.74965 Test MSE 5179.591580658897 Test RE 0.9958660401118463\n",
      "4 Train Loss 47.728874 Test MSE 5131.569184688275 Test RE 0.9912387216487739\n",
      "5 Train Loss 47.661312 Test MSE 5033.373874581776 Test RE 0.9817089717306968\n",
      "6 Train Loss 47.62482 Test MSE 4985.857683125473 Test RE 0.9770642061045702\n",
      "7 Train Loss 47.56251 Test MSE 4921.11678429495 Test RE 0.9706999347572781\n",
      "8 Train Loss 46.041237 Test MSE 4545.07596875619 Test RE 0.9328756086884297\n",
      "9 Train Loss 40.05349 Test MSE 7044.77427490914 Test RE 1.1614130612258011\n",
      "10 Train Loss 39.873432 Test MSE 7189.907321894585 Test RE 1.173315507912072\n",
      "11 Train Loss 39.250473 Test MSE 7581.806430260539 Test RE 1.2048681129418313\n",
      "12 Train Loss 37.47445 Test MSE 9116.675654199169 Test RE 1.3212086754172838\n",
      "13 Train Loss 36.99178 Test MSE 10516.101788542172 Test RE 1.4189939873452602\n",
      "14 Train Loss 36.954117 Test MSE 10696.871766024295 Test RE 1.4311381517468846\n",
      "15 Train Loss 36.92454 Test MSE 10669.245911957687 Test RE 1.429288920756702\n",
      "16 Train Loss 36.825405 Test MSE 10455.341259490875 Test RE 1.4148886768307833\n",
      "17 Train Loss 36.579655 Test MSE 10753.725446815703 Test RE 1.4349363483496949\n",
      "18 Train Loss 36.500256 Test MSE 11254.065989362705 Test RE 1.467938609427918\n",
      "19 Train Loss 36.478127 Test MSE 11299.30196005469 Test RE 1.4708858568507273\n",
      "20 Train Loss 36.391224 Test MSE 11201.076808963831 Test RE 1.4644786758561217\n",
      "21 Train Loss 36.088352 Test MSE 10577.893519308627 Test RE 1.4231568259172238\n",
      "22 Train Loss 35.806454 Test MSE 11019.39854769406 Test RE 1.4525534094957344\n",
      "23 Train Loss 35.594234 Test MSE 11798.725097365706 Test RE 1.5030405793840638\n",
      "24 Train Loss 35.50001 Test MSE 12146.029431533914 Test RE 1.5250017050454314\n",
      "25 Train Loss 35.490723 Test MSE 12306.715344565877 Test RE 1.5350560668323865\n",
      "26 Train Loss 35.317135 Test MSE 13633.922309321862 Test RE 1.615710592275481\n",
      "27 Train Loss 34.987404 Test MSE 14189.809322881052 Test RE 1.6483196822751374\n",
      "28 Train Loss 34.94177 Test MSE 14537.203982238521 Test RE 1.668374744138312\n",
      "29 Train Loss 34.938557 Test MSE 14652.54402502551 Test RE 1.6749802175647726\n",
      "30 Train Loss 34.879753 Test MSE 15056.372601572239 Test RE 1.6979048213590102\n",
      "31 Train Loss 34.86054 Test MSE 15353.278379247611 Test RE 1.714564103101681\n",
      "32 Train Loss 34.840393 Test MSE 15750.331877922416 Test RE 1.7365928929781211\n",
      "33 Train Loss 34.78196 Test MSE 16259.227489583503 Test RE 1.7644246578846308\n",
      "34 Train Loss 34.493595 Test MSE 16168.255003348202 Test RE 1.7594816415995642\n",
      "35 Train Loss 34.075733 Test MSE 14873.616589100513 Test RE 1.6875686765624687\n",
      "36 Train Loss 33.936886 Test MSE 14316.46261991616 Test RE 1.6556595042499656\n",
      "37 Train Loss 33.836933 Test MSE 13778.593528556641 Test RE 1.6242602233060566\n",
      "38 Train Loss 33.748886 Test MSE 13789.65121943782 Test RE 1.6249118487933976\n",
      "39 Train Loss 33.627678 Test MSE 13706.625004278618 Test RE 1.6200127413812717\n",
      "40 Train Loss 33.50244 Test MSE 14141.12164215611 Test RE 1.6454894179882575\n",
      "41 Train Loss 33.211327 Test MSE 15702.99341336015 Test RE 1.7339812177249518\n",
      "42 Train Loss 33.100647 Test MSE 16187.915240471642 Test RE 1.7605510617982036\n",
      "43 Train Loss 32.794838 Test MSE 18197.417028655134 Test RE 1.866629128364832\n",
      "44 Train Loss 32.585995 Test MSE 19224.48628601843 Test RE 1.9185827544650138\n",
      "45 Train Loss 32.401882 Test MSE 18984.257565559565 Test RE 1.906557788360529\n",
      "46 Train Loss 32.06823 Test MSE 18949.805243825 Test RE 1.9048270077295804\n",
      "47 Train Loss 32.022408 Test MSE 18794.945527997595 Test RE 1.897027822092074\n",
      "48 Train Loss 31.954529 Test MSE 18572.055300730342 Test RE 1.8857457984726347\n",
      "49 Train Loss 31.81456 Test MSE 18090.581433335894 Test RE 1.8611416464173358\n",
      "50 Train Loss 31.705202 Test MSE 17425.728288940732 Test RE 1.8266217882543503\n",
      "51 Train Loss 31.608355 Test MSE 17198.798868642494 Test RE 1.8146890702661282\n",
      "52 Train Loss 31.594543 Test MSE 17196.72189488388 Test RE 1.8145794935623951\n",
      "53 Train Loss 31.51015 Test MSE 17331.50357225204 Test RE 1.82167662292655\n",
      "54 Train Loss 31.443302 Test MSE 17184.86310296082 Test RE 1.8139537222130768\n",
      "55 Train Loss 31.400175 Test MSE 17566.067001686988 Test RE 1.8339624196394386\n",
      "56 Train Loss 31.377907 Test MSE 17685.234232562907 Test RE 1.840172654982009\n",
      "57 Train Loss 31.364107 Test MSE 17565.441992669916 Test RE 1.8339297927217204\n",
      "58 Train Loss 31.339012 Test MSE 17510.73324918192 Test RE 1.8310716170145647\n",
      "59 Train Loss 31.322544 Test MSE 17441.249872797096 Test RE 1.8274351187535534\n",
      "60 Train Loss 31.306057 Test MSE 17297.00154952383 Test RE 1.8198625033675286\n",
      "61 Train Loss 31.19127 Test MSE 17350.200347020433 Test RE 1.8226589467252223\n",
      "62 Train Loss 31.039871 Test MSE 17981.152659052383 Test RE 1.85550414465407\n",
      "63 Train Loss 30.766266 Test MSE 17998.386281785555 Test RE 1.856393114364889\n",
      "64 Train Loss 30.484175 Test MSE 16622.94717227153 Test RE 1.7840506376556424\n",
      "65 Train Loss 30.239672 Test MSE 15704.542062226934 Test RE 1.734066719316044\n",
      "66 Train Loss 30.117191 Test MSE 15136.252614306315 Test RE 1.7024028916125051\n",
      "67 Train Loss 30.01448 Test MSE 14931.622411185548 Test RE 1.6908561606116825\n",
      "68 Train Loss 29.907778 Test MSE 14461.717143548545 Test RE 1.664037450229832\n",
      "69 Train Loss 29.208954 Test MSE 12545.251149885038 Test RE 1.5498613380092203\n",
      "70 Train Loss 28.42962 Test MSE 11481.23741619456 Test RE 1.48268028725649\n",
      "71 Train Loss 28.24204 Test MSE 11206.440651324854 Test RE 1.46482928020924\n",
      "72 Train Loss 28.06087 Test MSE 10924.560911744928 Test RE 1.4462892558085807\n",
      "73 Train Loss 27.87404 Test MSE 10488.004836309376 Test RE 1.4170970832681267\n",
      "74 Train Loss 27.827229 Test MSE 10398.825631881446 Test RE 1.4110594534853929\n",
      "75 Train Loss 27.703789 Test MSE 10548.019629327693 Test RE 1.4211457785140398\n",
      "76 Train Loss 27.36338 Test MSE 11179.657491449208 Test RE 1.463077777325947\n",
      "77 Train Loss 27.230505 Test MSE 11240.153916197716 Test RE 1.4670310092500032\n",
      "78 Train Loss 26.994429 Test MSE 11629.765750269364 Test RE 1.4922399004616826\n",
      "79 Train Loss 26.914434 Test MSE 11541.88852412994 Test RE 1.4865913531923245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 26.772367 Test MSE 11446.251031630949 Test RE 1.480419503016038\n",
      "81 Train Loss 26.574667 Test MSE 11420.77307050527 Test RE 1.4787709683651127\n",
      "82 Train Loss 26.494192 Test MSE 11648.502836157435 Test RE 1.493441514274924\n",
      "83 Train Loss 26.306349 Test MSE 11973.455241569052 Test RE 1.5141291209041656\n",
      "84 Train Loss 26.24879 Test MSE 12127.579672340215 Test RE 1.5238430298138128\n",
      "85 Train Loss 26.166367 Test MSE 12517.137525569153 Test RE 1.5481237618794923\n",
      "86 Train Loss 26.01021 Test MSE 12976.879673062373 Test RE 1.5762979237874548\n",
      "87 Train Loss 25.93947 Test MSE 12839.011904239118 Test RE 1.567902185385709\n",
      "88 Train Loss 25.775723 Test MSE 13046.914025160528 Test RE 1.58054572682899\n",
      "89 Train Loss 25.572521 Test MSE 14034.488359390885 Test RE 1.6392736462115836\n",
      "90 Train Loss 25.487604 Test MSE 14255.253999166554 Test RE 1.6521164088807407\n",
      "91 Train Loss 25.441498 Test MSE 14369.014129020625 Test RE 1.6586954395015756\n",
      "92 Train Loss 25.395893 Test MSE 14414.818987348473 Test RE 1.6613370910732843\n",
      "93 Train Loss 25.337269 Test MSE 14382.66665622944 Test RE 1.6594832460941846\n",
      "94 Train Loss 25.30317 Test MSE 14296.452692469311 Test RE 1.654502053148318\n",
      "95 Train Loss 25.279737 Test MSE 14162.466897105396 Test RE 1.6467308381461796\n",
      "96 Train Loss 25.255798 Test MSE 14038.858103536222 Test RE 1.6395288264768657\n",
      "97 Train Loss 25.220022 Test MSE 13859.054449767193 Test RE 1.6289958023177546\n",
      "98 Train Loss 25.201918 Test MSE 13887.611766873655 Test RE 1.6306732547880916\n",
      "99 Train Loss 25.178453 Test MSE 13785.306869472646 Test RE 1.6246558690844881\n",
      "Training time: 48.31\n",
      "Training time: 48.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 47.772133 Test MSE 5227.646920622149 Test RE 1.0004751092694382\n",
      "1 Train Loss 47.77177 Test MSE 5227.410366793044 Test RE 1.0004524729955087\n",
      "2 Train Loss 47.771645 Test MSE 5227.115299500276 Test RE 1.0004242367420013\n",
      "3 Train Loss 47.7705 Test MSE 5223.0546423940605 Test RE 1.0000355740839624\n",
      "4 Train Loss 47.764606 Test MSE 5212.477100107623 Test RE 0.9990224428578713\n",
      "5 Train Loss 47.755875 Test MSE 5188.322815928903 Test RE 0.9967050521550552\n",
      "6 Train Loss 47.740993 Test MSE 5154.915478073878 Test RE 0.9934910043120639\n",
      "7 Train Loss 47.72287 Test MSE 5105.220436485344 Test RE 0.988690620728544\n",
      "8 Train Loss 47.672127 Test MSE 5034.8384088542425 Test RE 0.9818517826863646\n",
      "9 Train Loss 47.22776 Test MSE 4882.21335251358 Test RE 0.9668554324929227\n",
      "10 Train Loss 46.158115 Test MSE 4762.476968263831 Test RE 0.9549257597570573\n",
      "11 Train Loss 42.873257 Test MSE 4342.842823984462 Test RE 0.911885312122928\n",
      "12 Train Loss 41.07366 Test MSE 4266.808309607082 Test RE 0.9038674164611926\n",
      "13 Train Loss 39.643253 Test MSE 4578.127676220349 Test RE 0.9362613914930521\n",
      "14 Train Loss 37.46355 Test MSE 4448.960189904562 Test RE 0.9229590327543011\n",
      "15 Train Loss 35.784615 Test MSE 4407.783095766128 Test RE 0.9186779067818026\n",
      "16 Train Loss 34.82863 Test MSE 4412.070456503751 Test RE 0.9191245878223459\n",
      "17 Train Loss 34.605915 Test MSE 4373.8250388635915 Test RE 0.9151322655948662\n",
      "18 Train Loss 34.36312 Test MSE 4373.1027931635235 Test RE 0.915056705001366\n",
      "19 Train Loss 33.389484 Test MSE 4416.462498281079 Test RE 0.919581950131121\n",
      "20 Train Loss 29.8856 Test MSE 4582.69391020649 Test RE 0.9367281896471059\n",
      "21 Train Loss 28.183475 Test MSE 4830.4047142104155 Test RE 0.9617117549634143\n",
      "22 Train Loss 27.067701 Test MSE 4906.956805373128 Test RE 0.9693023869068126\n",
      "23 Train Loss 26.554829 Test MSE 5055.628151425398 Test RE 0.9838768146623138\n",
      "24 Train Loss 25.732382 Test MSE 5160.6402271546685 Test RE 0.9940425078785295\n",
      "25 Train Loss 25.423338 Test MSE 5262.639075815352 Test RE 1.0038179508721203\n",
      "26 Train Loss 24.490395 Test MSE 5712.41185861018 Test RE 1.045834395158383\n",
      "27 Train Loss 23.796522 Test MSE 6142.563367150349 Test RE 1.084496082032186\n",
      "28 Train Loss 23.545856 Test MSE 6456.325168377963 Test RE 1.111849134361622\n",
      "29 Train Loss 23.38616 Test MSE 6676.356614313941 Test RE 1.1306363080165418\n",
      "30 Train Loss 23.368446 Test MSE 6724.184303650276 Test RE 1.1346788737780085\n",
      "31 Train Loss 23.335718 Test MSE 6696.076524019152 Test RE 1.1323048532681073\n",
      "32 Train Loss 23.29564 Test MSE 6623.8962439610605 Test RE 1.1261854840818428\n",
      "33 Train Loss 22.932928 Test MSE 7052.003580969843 Test RE 1.1620088260597023\n",
      "34 Train Loss 22.843596 Test MSE 7217.917896180764 Test RE 1.1755987984102123\n",
      "35 Train Loss 22.641365 Test MSE 7534.481158488822 Test RE 1.2011018620920242\n",
      "36 Train Loss 22.501087 Test MSE 7603.390075097024 Test RE 1.2065818841975577\n",
      "37 Train Loss 22.496065 Test MSE 7593.960563172803 Test RE 1.2058334675144138\n",
      "38 Train Loss 22.485859 Test MSE 7592.64168298707 Test RE 1.2057287514764963\n",
      "39 Train Loss 22.417767 Test MSE 7338.327845129259 Test RE 1.1853639629289017\n",
      "40 Train Loss 22.374832 Test MSE 7146.113363223766 Test RE 1.1697366985221511\n",
      "41 Train Loss 22.353106 Test MSE 7172.95263466987 Test RE 1.1719312801284563\n",
      "42 Train Loss 22.343779 Test MSE 7156.801110350509 Test RE 1.170611102442527\n",
      "43 Train Loss 22.336308 Test MSE 7153.94026472711 Test RE 1.1703771101644944\n",
      "44 Train Loss 22.311504 Test MSE 7285.321997740619 Test RE 1.1810751730220301\n",
      "45 Train Loss 22.279697 Test MSE 7430.578688169365 Test RE 1.19279135684537\n",
      "46 Train Loss 22.241175 Test MSE 7515.564680304682 Test RE 1.1995931386957144\n",
      "47 Train Loss 22.214254 Test MSE 7553.37940684686 Test RE 1.2026072415074973\n",
      "48 Train Loss 22.101967 Test MSE 7790.704953384312 Test RE 1.2213539555879573\n",
      "49 Train Loss 22.04701 Test MSE 7783.202892867203 Test RE 1.2207657624652506\n",
      "50 Train Loss 22.018766 Test MSE 7620.577814937592 Test RE 1.2079448754790514\n",
      "51 Train Loss 22.01079 Test MSE 7538.412846258718 Test RE 1.2014152042784854\n",
      "52 Train Loss 22.00814 Test MSE 7529.235373654203 Test RE 1.2006836634874105\n",
      "53 Train Loss 22.006308 Test MSE 7561.081936009677 Test RE 1.2032202622857928\n",
      "54 Train Loss 22.000683 Test MSE 7634.335180783577 Test RE 1.209034730250706\n",
      "55 Train Loss 21.98966 Test MSE 7714.934227026527 Test RE 1.2154001304292807\n",
      "56 Train Loss 21.982319 Test MSE 7738.493814405689 Test RE 1.2172544883168097\n",
      "57 Train Loss 21.93596 Test MSE 7583.586453241633 Test RE 1.2050095414446784\n",
      "58 Train Loss 21.900928 Test MSE 7488.056505714356 Test RE 1.1973957743359789\n",
      "59 Train Loss 21.888735 Test MSE 7492.045640166913 Test RE 1.1977146779622454\n",
      "60 Train Loss 21.881304 Test MSE 7532.948927775128 Test RE 1.2009797263603474\n",
      "61 Train Loss 21.865078 Test MSE 7577.394384431611 Test RE 1.2045174902389642\n",
      "62 Train Loss 21.843872 Test MSE 7622.812334234974 Test RE 1.2081219603645208\n",
      "63 Train Loss 21.789762 Test MSE 7659.3150799724235 Test RE 1.2110111237458463\n",
      "64 Train Loss 21.727623 Test MSE 7662.682761476168 Test RE 1.2112773258492326\n",
      "65 Train Loss 21.72124 Test MSE 7695.859343365636 Test RE 1.2138966850787796\n",
      "66 Train Loss 21.71915 Test MSE 7737.198055515682 Test RE 1.2171525735001967\n",
      "67 Train Loss 21.718761 Test MSE 7755.192829971087 Test RE 1.2185671466964432\n",
      "68 Train Loss 21.717165 Test MSE 7785.994471630752 Test RE 1.220984667092774\n",
      "69 Train Loss 21.713884 Test MSE 7847.754053837696 Test RE 1.2258176115330086\n",
      "70 Train Loss 21.710226 Test MSE 7923.423616929278 Test RE 1.2317132192792837\n",
      "71 Train Loss 21.703032 Test MSE 7975.537675399679 Test RE 1.235757201802205\n",
      "72 Train Loss 21.699253 Test MSE 8001.561177742527 Test RE 1.2377716453201768\n",
      "73 Train Loss 21.69432 Test MSE 8083.711522044026 Test RE 1.2441093902537717\n",
      "74 Train Loss 21.68935 Test MSE 8150.26078171045 Test RE 1.2492199669146389\n",
      "75 Train Loss 21.687815 Test MSE 8143.8720017215755 Test RE 1.248730255212341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 21.684729 Test MSE 8118.840683782053 Test RE 1.2468097056583807\n",
      "77 Train Loss 21.679007 Test MSE 8059.915206249171 Test RE 1.2422768756055622\n",
      "78 Train Loss 21.67668 Test MSE 8095.975626684126 Test RE 1.2450527752948037\n",
      "79 Train Loss 21.661037 Test MSE 8063.800666931364 Test RE 1.2425762730715777\n",
      "80 Train Loss 21.629932 Test MSE 8121.667350743365 Test RE 1.2470267322780046\n",
      "81 Train Loss 21.592283 Test MSE 8249.863025471903 Test RE 1.256829985683493\n",
      "82 Train Loss 21.563751 Test MSE 8574.226658327592 Test RE 1.2812994643683235\n",
      "83 Train Loss 21.547974 Test MSE 8878.841722718711 Test RE 1.3038610795538736\n",
      "84 Train Loss 21.53125 Test MSE 8956.430668967643 Test RE 1.3095456699189512\n",
      "85 Train Loss 21.407747 Test MSE 8819.668620334958 Test RE 1.2995090207363227\n",
      "86 Train Loss 21.224045 Test MSE 9043.013203983615 Test RE 1.3158601874993436\n",
      "87 Train Loss 21.163725 Test MSE 9193.257987777426 Test RE 1.3267463104211716\n",
      "88 Train Loss 21.103327 Test MSE 8973.69724965508 Test RE 1.310807360513807\n",
      "89 Train Loss 21.072363 Test MSE 8949.477199014254 Test RE 1.3090372277243432\n",
      "90 Train Loss 21.045353 Test MSE 9011.669355629623 Test RE 1.3135777666836226\n",
      "91 Train Loss 21.028503 Test MSE 9063.916710709196 Test RE 1.3173801573633186\n",
      "92 Train Loss 20.967926 Test MSE 9375.204067301309 Test RE 1.3398109704869594\n",
      "93 Train Loss 20.8498 Test MSE 9498.07922696752 Test RE 1.3485624369668987\n",
      "94 Train Loss 20.670424 Test MSE 9304.013688349383 Test RE 1.3347143661715333\n",
      "95 Train Loss 20.608957 Test MSE 9085.055361819135 Test RE 1.3189154440897266\n",
      "96 Train Loss 20.585594 Test MSE 9050.858249797886 Test RE 1.3164308349887759\n",
      "97 Train Loss 20.552977 Test MSE 9146.20667475536 Test RE 1.3233467955567546\n",
      "98 Train Loss 20.436506 Test MSE 9355.914293923332 Test RE 1.338431909426483\n",
      "99 Train Loss 20.380098 Test MSE 9508.936229810897 Test RE 1.349332969840898\n",
      "Training time: 49.80\n",
      "Training time: 49.80\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 47.768837 Test MSE 5221.1988262884715 Test RE 0.9998578957773578\n",
      "1 Train Loss 47.76871 Test MSE 5221.060587381292 Test RE 0.999844659336614\n",
      "2 Train Loss 47.768017 Test MSE 5218.710748889738 Test RE 0.9996196343783067\n",
      "3 Train Loss 47.750675 Test MSE 5179.946065272395 Test RE 0.9959001174269193\n",
      "4 Train Loss 47.717365 Test MSE 5087.67201439984 Test RE 0.9869899208581351\n",
      "5 Train Loss 47.690716 Test MSE 5052.852217260237 Test RE 0.9836066650199143\n",
      "6 Train Loss 47.63662 Test MSE 4963.633647894074 Test RE 0.9748841839076505\n",
      "7 Train Loss 47.45092 Test MSE 4719.415588598141 Test RE 0.9505988313260028\n",
      "8 Train Loss 47.06787 Test MSE 4539.114868949607 Test RE 0.9322636509106162\n",
      "9 Train Loss 46.85013 Test MSE 4584.259149429296 Test RE 0.936888147802349\n",
      "10 Train Loss 46.324333 Test MSE 5002.557906548324 Test RE 0.978699185553299\n",
      "11 Train Loss 45.515865 Test MSE 5077.150188630527 Test RE 0.9859687946150805\n",
      "12 Train Loss 43.98898 Test MSE 5052.265072994765 Test RE 0.9835495155362168\n",
      "13 Train Loss 43.708427 Test MSE 5016.094547026926 Test RE 0.9800224434821445\n",
      "14 Train Loss 42.972378 Test MSE 5008.802847670372 Test RE 0.9793098743889848\n",
      "15 Train Loss 41.74245 Test MSE 4863.939084844469 Test RE 0.965044251968074\n",
      "16 Train Loss 40.04714 Test MSE 4341.589160848473 Test RE 0.9117536841132414\n",
      "17 Train Loss 37.05182 Test MSE 3761.052586560823 Test RE 0.8486094574922552\n",
      "18 Train Loss 27.145794 Test MSE 2821.0446300356725 Test RE 0.7349505904409198\n",
      "19 Train Loss 24.041986 Test MSE 2102.2815211409666 Test RE 0.6344517522020053\n",
      "20 Train Loss 20.571384 Test MSE 1041.69441359094 Test RE 0.4466047442545318\n",
      "21 Train Loss 19.551298 Test MSE 857.9928894224145 Test RE 0.40531717685734786\n",
      "22 Train Loss 19.190239 Test MSE 845.5775916752732 Test RE 0.4023739879601671\n",
      "23 Train Loss 18.88868 Test MSE 923.2554971127505 Test RE 0.4204497666192756\n",
      "24 Train Loss 18.056108 Test MSE 902.2201149353381 Test RE 0.4156324214537622\n",
      "25 Train Loss 16.729343 Test MSE 823.5740818641732 Test RE 0.39710421795218215\n",
      "26 Train Loss 16.377308 Test MSE 712.631871108594 Test RE 0.3693905538887567\n",
      "27 Train Loss 15.438256 Test MSE 617.8652594778882 Test RE 0.34395375348039364\n",
      "28 Train Loss 15.17868 Test MSE 597.2843983326652 Test RE 0.3381767530584963\n",
      "29 Train Loss 14.511052 Test MSE 570.1818620641282 Test RE 0.33041508269229364\n",
      "30 Train Loss 13.381426 Test MSE 999.2313636705665 Test RE 0.43740746762360866\n",
      "31 Train Loss 11.921822 Test MSE 900.5413073987581 Test RE 0.41524554705079414\n",
      "32 Train Loss 10.950888 Test MSE 850.257530365492 Test RE 0.4034859422409002\n",
      "33 Train Loss 9.161793 Test MSE 835.1060437019652 Test RE 0.39987474673914297\n",
      "34 Train Loss 8.163219 Test MSE 724.4504145593229 Test RE 0.3724410113756227\n",
      "35 Train Loss 7.782684 Test MSE 695.2893320549307 Test RE 0.36486814411906726\n",
      "36 Train Loss 7.5029573 Test MSE 650.4450100932313 Test RE 0.35290552518561175\n",
      "37 Train Loss 7.2697268 Test MSE 623.7798439771778 Test RE 0.34559610039654715\n",
      "38 Train Loss 7.2343874 Test MSE 586.7426846248181 Test RE 0.3351791586535947\n",
      "39 Train Loss 7.1855493 Test MSE 553.4297109047845 Test RE 0.3255250392625553\n",
      "40 Train Loss 7.127911 Test MSE 534.2916709323544 Test RE 0.3198470626564317\n",
      "41 Train Loss 7.0307508 Test MSE 534.7163213704044 Test RE 0.31997414326202206\n",
      "42 Train Loss 6.885021 Test MSE 522.7393651541265 Test RE 0.31637034472471665\n",
      "43 Train Loss 6.679878 Test MSE 473.49745144031635 Test RE 0.3011008542003209\n",
      "44 Train Loss 6.4626026 Test MSE 498.9324118443994 Test RE 0.3090822204151236\n",
      "45 Train Loss 6.345257 Test MSE 569.8226443225457 Test RE 0.33031098462501934\n",
      "46 Train Loss 6.231686 Test MSE 562.4681703950399 Test RE 0.32817246579982856\n",
      "47 Train Loss 6.1533704 Test MSE 539.9966248888318 Test RE 0.32155012842344716\n",
      "48 Train Loss 6.0932093 Test MSE 525.2242478796039 Test RE 0.3171213989042327\n",
      "49 Train Loss 6.0524716 Test MSE 528.0847976300056 Test RE 0.3179838017197737\n",
      "50 Train Loss 5.980511 Test MSE 543.7798257012035 Test RE 0.32267454792078276\n",
      "51 Train Loss 5.9469485 Test MSE 545.117454854976 Test RE 0.32307117331600466\n",
      "52 Train Loss 5.920414 Test MSE 549.7504012405033 Test RE 0.32444115752228914\n",
      "53 Train Loss 5.8942575 Test MSE 563.9189552939149 Test RE 0.32859542399511577\n",
      "54 Train Loss 5.875464 Test MSE 573.970426044675 Test RE 0.3315109840658893\n",
      "55 Train Loss 5.8665347 Test MSE 577.2457618232219 Test RE 0.33245551457744\n",
      "56 Train Loss 5.8328876 Test MSE 594.3377827597377 Test RE 0.33734154882074097\n",
      "57 Train Loss 5.7766376 Test MSE 599.6928075915368 Test RE 0.3388578763548783\n",
      "58 Train Loss 5.6856766 Test MSE 586.1442206808058 Test RE 0.3350081775552695\n",
      "59 Train Loss 5.527797 Test MSE 531.9200186284705 Test RE 0.3191363930613205\n",
      "60 Train Loss 5.467108 Test MSE 451.40196678967607 Test RE 0.29399157722513825\n",
      "61 Train Loss 5.3245792 Test MSE 385.9057401301281 Test RE 0.27182774598029263\n",
      "62 Train Loss 5.2548947 Test MSE 388.8955725197627 Test RE 0.27287871676548925\n",
      "63 Train Loss 5.224159 Test MSE 392.1309729932669 Test RE 0.27401146722150527\n",
      "64 Train Loss 5.217542 Test MSE 396.6172728097666 Test RE 0.27557446735027374\n",
      "65 Train Loss 5.192592 Test MSE 388.472757515782 Test RE 0.2727303368390631\n",
      "66 Train Loss 5.1552706 Test MSE 371.2425160587466 Test RE 0.2666134276826404\n",
      "67 Train Loss 5.147984 Test MSE 368.9984101231272 Test RE 0.2658063869144542\n",
      "68 Train Loss 5.134448 Test MSE 377.57221478245873 Test RE 0.2688767056491114\n",
      "69 Train Loss 5.107785 Test MSE 377.32991680720613 Test RE 0.2687904191931505\n",
      "70 Train Loss 5.0982194 Test MSE 375.9975327601486 Test RE 0.2683154386009969\n",
      "71 Train Loss 5.087879 Test MSE 381.1794512251208 Test RE 0.27015804503247653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Train Loss 5.078482 Test MSE 392.09577428076966 Test RE 0.27399916894877696\n",
      "73 Train Loss 5.0713663 Test MSE 398.5503137536228 Test RE 0.276245201172213\n",
      "74 Train Loss 5.0616093 Test MSE 407.5429920109178 Test RE 0.2793443420715422\n",
      "75 Train Loss 5.0464563 Test MSE 419.3728677727991 Test RE 0.283369647148724\n",
      "76 Train Loss 5.039766 Test MSE 428.2954035138225 Test RE 0.2863682538993751\n",
      "77 Train Loss 5.029401 Test MSE 424.8998966776101 Test RE 0.2852308377018109\n",
      "78 Train Loss 5.023629 Test MSE 427.7270762778772 Test RE 0.28617819243321424\n",
      "79 Train Loss 5.013468 Test MSE 429.02332550172673 Test RE 0.28661150336132474\n",
      "80 Train Loss 5.00403 Test MSE 427.61443613086783 Test RE 0.2861405080335323\n",
      "81 Train Loss 4.9932055 Test MSE 429.7609204427242 Test RE 0.28685777483079855\n",
      "82 Train Loss 4.974072 Test MSE 430.60592278306234 Test RE 0.2871396483634267\n",
      "83 Train Loss 4.9537706 Test MSE 442.98552047643636 Test RE 0.29123792636537493\n",
      "84 Train Loss 4.933272 Test MSE 437.814101530116 Test RE 0.28953297811855794\n",
      "85 Train Loss 4.923121 Test MSE 428.8947982024318 Test RE 0.2865685684442174\n",
      "86 Train Loss 4.915504 Test MSE 420.19542926816166 Test RE 0.28364741282563083\n",
      "87 Train Loss 4.9023676 Test MSE 419.916588638736 Test RE 0.28355328335234775\n",
      "88 Train Loss 4.895365 Test MSE 419.27161157881585 Test RE 0.2833354357507912\n",
      "89 Train Loss 4.881974 Test MSE 416.5077646922054 Test RE 0.2824000151817484\n",
      "90 Train Loss 4.866653 Test MSE 409.42715702896356 Test RE 0.27998933402659676\n",
      "91 Train Loss 4.850999 Test MSE 406.7853052573899 Test RE 0.2790845486526694\n",
      "92 Train Loss 4.8276014 Test MSE 414.79023831961865 Test RE 0.28181715626565124\n",
      "93 Train Loss 4.7969017 Test MSE 415.16939980715506 Test RE 0.281945931962977\n",
      "94 Train Loss 4.7735434 Test MSE 413.2059444636893 Test RE 0.28127844018890713\n",
      "95 Train Loss 4.758017 Test MSE 409.8705959889016 Test RE 0.2801409172534109\n",
      "96 Train Loss 4.7520604 Test MSE 397.1770745435628 Test RE 0.27576887727498683\n",
      "97 Train Loss 4.746024 Test MSE 392.92637152642845 Test RE 0.274289228893558\n",
      "98 Train Loss 4.743848 Test MSE 392.58573223254956 Test RE 0.2741703084610052\n",
      "99 Train Loss 4.739689 Test MSE 390.3015360614972 Test RE 0.2733715372331489\n",
      "Training time: 64.10\n",
      "Training time: 64.10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 47.767757 Test MSE 5218.450015506711 Test RE 0.9995946629364089\n",
      "1 Train Loss 47.767387 Test MSE 5218.334573306732 Test RE 0.9995836063923359\n",
      "2 Train Loss 47.767166 Test MSE 5217.901358738758 Test RE 0.9995421139236307\n",
      "3 Train Loss 47.7652 Test MSE 5210.103791869791 Test RE 0.9987949830441657\n",
      "4 Train Loss 47.74571 Test MSE 5160.343299147659 Test RE 0.9940139103311786\n",
      "5 Train Loss 47.7446 Test MSE 5164.007981163658 Test RE 0.9943668033640735\n",
      "6 Train Loss 47.744118 Test MSE 5165.690730175699 Test RE 0.99452880286823\n",
      "7 Train Loss 47.737877 Test MSE 5159.988911658652 Test RE 0.9939797777045793\n",
      "8 Train Loss 47.668346 Test MSE 5048.051316837188 Test RE 0.9831392735677547\n",
      "9 Train Loss 47.442333 Test MSE 4832.750724268478 Test RE 0.9619452666157995\n",
      "10 Train Loss 47.398487 Test MSE 4786.480888730291 Test RE 0.9573292518664589\n",
      "11 Train Loss 47.14812 Test MSE 4765.497813551913 Test RE 0.9552285670678888\n",
      "12 Train Loss 45.067192 Test MSE 4602.948092436368 Test RE 0.9387959413452344\n",
      "13 Train Loss 41.218853 Test MSE 4357.059828046033 Test RE 0.9133766951724621\n",
      "14 Train Loss 36.833855 Test MSE 3756.6878725816937 Test RE 0.8481169075067642\n",
      "15 Train Loss 30.712894 Test MSE 3817.979223581101 Test RE 0.8550075408345695\n",
      "16 Train Loss 23.82666 Test MSE 1811.666802625875 Test RE 0.5889688525117888\n",
      "17 Train Loss 22.073502 Test MSE 1623.4294527778757 Test RE 0.5575320975230189\n",
      "18 Train Loss 21.264008 Test MSE 1579.2734424872885 Test RE 0.5498976083005876\n",
      "19 Train Loss 20.280136 Test MSE 1632.45109757564 Test RE 0.5590790966759909\n",
      "20 Train Loss 11.876451 Test MSE 818.246823768477 Test RE 0.3958178074239094\n",
      "21 Train Loss 10.879457 Test MSE 808.2434927519222 Test RE 0.3933908669779458\n",
      "22 Train Loss 10.262865 Test MSE 731.4812511144942 Test RE 0.3742439292276122\n",
      "23 Train Loss 9.28285 Test MSE 560.2458703230459 Test RE 0.3275235228734552\n",
      "24 Train Loss 8.380102 Test MSE 626.7983320299011 Test RE 0.34643126585026046\n",
      "25 Train Loss 7.804391 Test MSE 661.7649486837395 Test RE 0.35596315294834513\n",
      "26 Train Loss 7.197648 Test MSE 456.7449580552765 Test RE 0.295726365394934\n",
      "27 Train Loss 6.5153193 Test MSE 473.537072284614 Test RE 0.30111345154426894\n",
      "28 Train Loss 6.150534 Test MSE 484.17843479681835 Test RE 0.304477977227591\n",
      "29 Train Loss 5.6345496 Test MSE 434.8182280341274 Test RE 0.28854066980898946\n",
      "30 Train Loss 5.1833215 Test MSE 422.30967829150484 Test RE 0.284360115479822\n",
      "31 Train Loss 4.5260267 Test MSE 414.94815959623395 Test RE 0.2818707986681757\n",
      "32 Train Loss 4.2952924 Test MSE 481.3631813960114 Test RE 0.30359149379907574\n",
      "33 Train Loss 4.0109363 Test MSE 451.51708961824 Test RE 0.29402906375243987\n",
      "34 Train Loss 3.8513086 Test MSE 416.25285882722835 Test RE 0.28231358649599747\n",
      "35 Train Loss 3.7520409 Test MSE 415.3334900033821 Test RE 0.28200164415282314\n",
      "36 Train Loss 3.6256988 Test MSE 457.8605674199931 Test RE 0.2960873041270303\n",
      "37 Train Loss 3.5882852 Test MSE 485.3307259686921 Test RE 0.3048400738882153\n",
      "38 Train Loss 3.5390968 Test MSE 526.5855344261528 Test RE 0.3175320937073863\n",
      "39 Train Loss 3.4373913 Test MSE 504.011750753353 Test RE 0.31065152908101734\n",
      "40 Train Loss 3.3409262 Test MSE 468.8530710687736 Test RE 0.29962051571954795\n",
      "41 Train Loss 3.1337235 Test MSE 455.8659307342564 Test RE 0.2954416586423884\n",
      "42 Train Loss 3.0828762 Test MSE 445.88167478775335 Test RE 0.29218840421865705\n",
      "43 Train Loss 2.9774435 Test MSE 459.14379735234064 Test RE 0.29650193062451957\n",
      "44 Train Loss 2.8748293 Test MSE 484.14219543767786 Test RE 0.3044665823652332\n",
      "45 Train Loss 2.8345923 Test MSE 502.89921376107793 Test RE 0.3103084792905049\n",
      "46 Train Loss 2.7244368 Test MSE 510.68157091505753 Test RE 0.3127002709155897\n",
      "47 Train Loss 2.6781452 Test MSE 509.7036574778473 Test RE 0.31240072972688054\n",
      "48 Train Loss 2.6679695 Test MSE 512.0763420113319 Test RE 0.31312700249450165\n",
      "49 Train Loss 2.609527 Test MSE 511.5483920560208 Test RE 0.3129655441284659\n",
      "50 Train Loss 2.5860212 Test MSE 505.0976105858581 Test RE 0.31098598807600786\n",
      "51 Train Loss 2.4658797 Test MSE 532.9914797067619 Test RE 0.3194576539550399\n",
      "52 Train Loss 2.3313065 Test MSE 539.5906131438317 Test RE 0.32142922241035954\n",
      "53 Train Loss 2.3068454 Test MSE 539.09884563315 Test RE 0.3212827183052985\n",
      "54 Train Loss 2.1811893 Test MSE 572.0911626140195 Test RE 0.3309678312979707\n",
      "55 Train Loss 2.0857148 Test MSE 588.1718336111761 Test RE 0.33558711398921515\n",
      "56 Train Loss 1.9627403 Test MSE 618.9599770390682 Test RE 0.34425832278048923\n",
      "57 Train Loss 1.9244791 Test MSE 633.3800333432226 Test RE 0.34824536829048053\n",
      "58 Train Loss 1.9039992 Test MSE 634.5976683697772 Test RE 0.3485799479549789\n",
      "59 Train Loss 1.8678697 Test MSE 635.845901834941 Test RE 0.34892260238525363\n",
      "60 Train Loss 1.8412696 Test MSE 642.7016802433549 Test RE 0.3507986249254272\n",
      "61 Train Loss 1.8144939 Test MSE 649.6272536599522 Test RE 0.35268361439983936\n",
      "62 Train Loss 1.7991244 Test MSE 649.0851850235885 Test RE 0.3525364387519396\n",
      "63 Train Loss 1.781261 Test MSE 645.0466167826648 Test RE 0.35143799741920284\n",
      "64 Train Loss 1.7178497 Test MSE 647.5613478706662 Test RE 0.35212237615823616\n",
      "65 Train Loss 1.679927 Test MSE 679.9640192821098 Test RE 0.3608245933592347\n",
      "66 Train Loss 1.5971622 Test MSE 704.3027541215805 Test RE 0.3672255229935933\n",
      "67 Train Loss 1.5665253 Test MSE 687.9500125841977 Test RE 0.36293730174684813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Train Loss 1.5452679 Test MSE 688.5733353541343 Test RE 0.3631016856843253\n",
      "69 Train Loss 1.5097741 Test MSE 701.7494487591914 Test RE 0.3665592681479985\n",
      "70 Train Loss 1.4764057 Test MSE 707.9247398086103 Test RE 0.3681685690918646\n",
      "71 Train Loss 1.4517562 Test MSE 724.0051435523372 Test RE 0.3723265365468953\n",
      "72 Train Loss 1.4425689 Test MSE 737.9691095068071 Test RE 0.375899939884848\n",
      "73 Train Loss 1.4309882 Test MSE 755.2619840820296 Test RE 0.3802786795688804\n",
      "74 Train Loss 1.4117553 Test MSE 768.0617296215254 Test RE 0.38348751344720833\n",
      "75 Train Loss 1.3875026 Test MSE 768.1797556746443 Test RE 0.38351697708093435\n",
      "76 Train Loss 1.3681312 Test MSE 748.904661715881 Test RE 0.3786748234933206\n",
      "77 Train Loss 1.3483976 Test MSE 725.2585284939004 Test RE 0.37264867975332383\n",
      "78 Train Loss 1.3312672 Test MSE 739.0958279695192 Test RE 0.3761867891983033\n",
      "79 Train Loss 1.3222561 Test MSE 746.4522987306582 Test RE 0.3780543108612804\n",
      "80 Train Loss 1.2811786 Test MSE 772.1462377018001 Test RE 0.3845058436514393\n",
      "81 Train Loss 1.2481319 Test MSE 772.0948334368761 Test RE 0.38449304454146715\n",
      "82 Train Loss 1.2383541 Test MSE 756.7453877177526 Test RE 0.38065194743493014\n",
      "83 Train Loss 1.2277395 Test MSE 750.93272476148 Test RE 0.3791872099360387\n",
      "84 Train Loss 1.2173452 Test MSE 735.3257191856673 Test RE 0.3752261029613488\n",
      "85 Train Loss 1.2095532 Test MSE 732.3279127957278 Test RE 0.3744604531365221\n",
      "86 Train Loss 1.2029251 Test MSE 721.6589637097275 Test RE 0.3717227743604223\n",
      "87 Train Loss 1.1910081 Test MSE 710.7639317490426 Test RE 0.36890611589915806\n",
      "88 Train Loss 1.1850742 Test MSE 720.1661231835766 Test RE 0.3713380981291572\n",
      "89 Train Loss 1.1742978 Test MSE 718.5494487426747 Test RE 0.3709210623315816\n",
      "90 Train Loss 1.1683639 Test MSE 704.8365019766443 Test RE 0.3673646454895232\n",
      "91 Train Loss 1.160425 Test MSE 698.3859176170201 Test RE 0.365679741665939\n",
      "92 Train Loss 1.146934 Test MSE 702.0149717143427 Test RE 0.3666286096311174\n",
      "93 Train Loss 1.134241 Test MSE 705.8973707808544 Test RE 0.36764100685461976\n",
      "94 Train Loss 1.1234308 Test MSE 692.4979512550735 Test RE 0.3641349887462082\n",
      "95 Train Loss 1.1179172 Test MSE 684.2092179318308 Test RE 0.36194920337602904\n",
      "96 Train Loss 1.1094093 Test MSE 680.1833768207724 Test RE 0.36088278997701545\n",
      "97 Train Loss 1.09241 Test MSE 669.7989091762466 Test RE 0.3581173669058256\n",
      "98 Train Loss 1.0730767 Test MSE 671.6670434923224 Test RE 0.3586164312504482\n",
      "99 Train Loss 1.0609032 Test MSE 664.5958754832997 Test RE 0.35672371772939215\n",
      "Training time: 60.34\n",
      "Training time: 60.34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 47.77018 Test MSE 5223.9835716084735 Test RE 1.0001244991501457\n",
      "1 Train Loss 47.770084 Test MSE 5223.835612711392 Test RE 1.000110335785769\n",
      "2 Train Loss 47.769745 Test MSE 5222.778425740657 Test RE 1.0000091307332255\n",
      "3 Train Loss 47.748062 Test MSE 5176.219511280739 Test RE 0.9955418180119942\n",
      "4 Train Loss 47.74654 Test MSE 5169.261305764282 Test RE 0.9948724574765602\n",
      "5 Train Loss 47.729385 Test MSE 5103.607387301094 Test RE 0.9885344146828839\n",
      "6 Train Loss 47.706917 Test MSE 5081.113173311441 Test RE 0.9863535199927128\n",
      "7 Train Loss 47.610516 Test MSE 4958.692002951945 Test RE 0.9743987803219774\n",
      "8 Train Loss 45.761307 Test MSE 5128.657062730387 Test RE 0.9909574219536363\n",
      "9 Train Loss 37.21355 Test MSE 4426.86483243294 Test RE 0.920664283858778\n",
      "10 Train Loss 36.69102 Test MSE 4333.26855939345 Test RE 0.9108795828316985\n",
      "11 Train Loss 35.908928 Test MSE 4360.295412275888 Test RE 0.9137157723131153\n",
      "12 Train Loss 35.309002 Test MSE 4349.845480487551 Test RE 0.9126202048884887\n",
      "13 Train Loss 34.12261 Test MSE 4362.948317622676 Test RE 0.913993693031327\n",
      "14 Train Loss 33.439354 Test MSE 4373.704275245443 Test RE 0.9151196318651956\n",
      "15 Train Loss 32.962574 Test MSE 4398.877692465128 Test RE 0.9177493976480399\n",
      "16 Train Loss 31.837751 Test MSE 4529.081491123007 Test RE 0.9312327309648123\n",
      "17 Train Loss 31.247131 Test MSE 4645.159343868791 Test RE 0.9430907230308035\n",
      "18 Train Loss 30.992422 Test MSE 4850.720081440229 Test RE 0.9637319819764909\n",
      "19 Train Loss 30.899084 Test MSE 4987.719762050485 Test RE 0.9772466422011095\n",
      "20 Train Loss 30.7444 Test MSE 5177.757888120812 Test RE 0.9956897449592165\n",
      "21 Train Loss 30.438358 Test MSE 5325.358307438287 Test RE 1.009781899422625\n",
      "22 Train Loss 30.090818 Test MSE 5420.646515934551 Test RE 1.0187760070831873\n",
      "23 Train Loss 29.80794 Test MSE 5464.044916860456 Test RE 1.0228461034922054\n",
      "24 Train Loss 29.603895 Test MSE 5483.362369629982 Test RE 1.0246525809935372\n",
      "25 Train Loss 29.434326 Test MSE 5486.27349938781 Test RE 1.024924540114356\n",
      "26 Train Loss 29.351896 Test MSE 5480.636217447802 Test RE 1.0243978371010303\n",
      "27 Train Loss 29.31647 Test MSE 5475.6912486241745 Test RE 1.0239355952818296\n",
      "28 Train Loss 29.294523 Test MSE 5470.305332455383 Test RE 1.023431897410736\n",
      "29 Train Loss 29.286531 Test MSE 5469.341858664408 Test RE 1.023341765948995\n",
      "30 Train Loss 29.274042 Test MSE 5477.152871523528 Test RE 1.0240722454129967\n",
      "31 Train Loss 29.16356 Test MSE 5568.639252890204 Test RE 1.032589505475622\n",
      "32 Train Loss 28.74623 Test MSE 5820.684518715332 Test RE 1.055699206812649\n",
      "33 Train Loss 28.549212 Test MSE 6001.963883154744 Test RE 1.0720125102371296\n",
      "34 Train Loss 28.475082 Test MSE 6095.114327424834 Test RE 1.0802992952533226\n",
      "35 Train Loss 28.406324 Test MSE 6207.0035051551 Test RE 1.0901698326588007\n",
      "36 Train Loss 28.346724 Test MSE 6275.583107944755 Test RE 1.096175793229983\n",
      "37 Train Loss 27.992514 Test MSE 6672.4226485794725 Test RE 1.1303031517638076\n",
      "38 Train Loss 27.085386 Test MSE 7039.798637170618 Test RE 1.1610028428737915\n",
      "39 Train Loss 26.96391 Test MSE 7176.951759087423 Test RE 1.1722579270601228\n",
      "40 Train Loss 26.93802 Test MSE 7235.186100529066 Test RE 1.1770042143015387\n",
      "41 Train Loss 26.915855 Test MSE 7255.054118205601 Test RE 1.1786191491789169\n",
      "42 Train Loss 26.892048 Test MSE 7296.4851391917855 Test RE 1.1819796946413976\n",
      "43 Train Loss 26.848825 Test MSE 7386.377233343549 Test RE 1.189238352658586\n",
      "44 Train Loss 26.826017 Test MSE 7425.18384133828 Test RE 1.1923582751596418\n",
      "45 Train Loss 26.75756 Test MSE 7588.6553218091385 Test RE 1.205412188313298\n",
      "46 Train Loss 26.628178 Test MSE 8031.463745908987 Test RE 1.2400823216254695\n",
      "47 Train Loss 26.415928 Test MSE 8666.257335197506 Test RE 1.2881574663004716\n",
      "48 Train Loss 25.916302 Test MSE 9140.725016705479 Test RE 1.3229501709168405\n",
      "49 Train Loss 25.723116 Test MSE 9318.964858851867 Test RE 1.3357863514581187\n",
      "50 Train Loss 25.690739 Test MSE 9371.366732069542 Test RE 1.3395367455205238\n",
      "51 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "52 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "53 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "54 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "55 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "56 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "57 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "58 Train Loss 25.686344 Test MSE 9388.12251276068 Test RE 1.3407337406207034\n",
      "59 Train Loss 25.686308 Test MSE 9388.142191471985 Test RE 1.3407351457950802\n",
      "60 Train Loss 25.686169 Test MSE 9388.219967179077 Test RE 1.3407406994182514\n",
      "61 Train Loss 25.686169 Test MSE 9388.219967179077 Test RE 1.3407406994182514\n",
      "62 Train Loss 25.686169 Test MSE 9388.219967179077 Test RE 1.3407406994182514\n",
      "63 Train Loss 25.686033 Test MSE 9388.864792235727 Test RE 1.3407867426701037\n",
      "64 Train Loss 25.686033 Test MSE 9388.864792235727 Test RE 1.3407867426701037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 25.686033 Test MSE 9388.864792235727 Test RE 1.3407867426701037\n",
      "66 Train Loss 25.686033 Test MSE 9388.864792235727 Test RE 1.3407867426701037\n",
      "67 Train Loss 25.686033 Test MSE 9388.864792235727 Test RE 1.3407867426701037\n",
      "68 Train Loss 25.686031 Test MSE 9388.898572648563 Test RE 1.3407891546916821\n",
      "69 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "70 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "71 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "72 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "73 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "74 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "75 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "76 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "77 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "78 Train Loss 25.68585 Test MSE 9388.946107163862 Test RE 1.3407925487895858\n",
      "79 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "80 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "81 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "82 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "83 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "84 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "85 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "86 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "87 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "88 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "89 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "90 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "91 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "92 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "93 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "94 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "95 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "96 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "97 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "98 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "99 Train Loss 25.68585 Test MSE 9388.94609290195 Test RE 1.3407925477712461\n",
      "Training time: 40.62\n",
      "Training time: 40.62\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 47.768238 Test MSE 5220.068788337598 Test RE 0.9997496889701177\n",
      "1 Train Loss 47.755825 Test MSE 5175.219209371696 Test RE 0.9954456193775385\n",
      "2 Train Loss 47.74972 Test MSE 5177.422053439038 Test RE 0.9956574537070743\n",
      "3 Train Loss 47.7481 Test MSE 5177.212999571514 Test RE 0.9956373521835313\n",
      "4 Train Loss 47.705 Test MSE 5092.523206424844 Test RE 0.9874603655706032\n",
      "5 Train Loss 47.652637 Test MSE 4977.374802431253 Test RE 0.9762326693828258\n",
      "6 Train Loss 47.490166 Test MSE 4895.556028037973 Test RE 0.9681756980626556\n",
      "7 Train Loss 47.239502 Test MSE 4651.880263554649 Test RE 0.9437727390261622\n",
      "8 Train Loss 47.100952 Test MSE 4573.337829489097 Test RE 0.9357714835566753\n",
      "9 Train Loss 46.89359 Test MSE 4503.735919858743 Test RE 0.9286234006326709\n",
      "10 Train Loss 46.649967 Test MSE 4493.677908764541 Test RE 0.927585892530227\n",
      "11 Train Loss 46.54398 Test MSE 4462.630777018185 Test RE 0.9243759609386324\n",
      "12 Train Loss 46.08943 Test MSE 4468.34278314668 Test RE 0.924967355671091\n",
      "13 Train Loss 45.738262 Test MSE 4343.394453365191 Test RE 0.9119432242760837\n",
      "14 Train Loss 45.23858 Test MSE 4310.753169874953 Test RE 0.9085100644893911\n",
      "15 Train Loss 45.180523 Test MSE 4310.244947647002 Test RE 0.9084565078833151\n",
      "16 Train Loss 45.162434 Test MSE 4314.89762897895 Test RE 0.9089466910006421\n",
      "17 Train Loss 44.47525 Test MSE 4201.153940244436 Test RE 0.8968864490961953\n",
      "18 Train Loss 42.772568 Test MSE 3919.88736607508 Test RE 0.8663431757532781\n",
      "19 Train Loss 42.063507 Test MSE 3915.7178197054045 Test RE 0.8658822927229578\n",
      "20 Train Loss 41.919415 Test MSE 3871.7791295408024 Test RE 0.8610105083666311\n",
      "21 Train Loss 41.074356 Test MSE 3933.748877927883 Test RE 0.8678736060183314\n",
      "22 Train Loss 40.07871 Test MSE 3935.463196113463 Test RE 0.8680626940220272\n",
      "23 Train Loss 39.779583 Test MSE 3928.2638146829963 Test RE 0.8672683307032184\n",
      "24 Train Loss 38.112514 Test MSE 4551.669911275993 Test RE 0.9335520658843572\n",
      "25 Train Loss 33.98636 Test MSE 4470.141096733298 Test RE 0.9251534665087783\n",
      "26 Train Loss 29.497108 Test MSE 3689.60396617908 Test RE 0.8405103020484208\n",
      "27 Train Loss 26.123837 Test MSE 3567.182848030711 Test RE 0.8264486036877686\n",
      "28 Train Loss 23.843658 Test MSE 3323.0423260046286 Test RE 0.7976660371827043\n",
      "29 Train Loss 20.760452 Test MSE 3548.6529952401997 Test RE 0.8242993011883997\n",
      "30 Train Loss 19.952023 Test MSE 3467.2195502435657 Test RE 0.8147865214018046\n",
      "31 Train Loss 15.511239 Test MSE 2295.7109255303317 Test RE 0.6629973083025996\n",
      "32 Train Loss 14.1233 Test MSE 1828.6973338976354 Test RE 0.591730671031315\n",
      "33 Train Loss 11.528084 Test MSE 1446.9716440347554 Test RE 0.5263603595301587\n",
      "34 Train Loss 9.641204 Test MSE 940.2910106317287 Test RE 0.4243110156753868\n",
      "35 Train Loss 8.65325 Test MSE 658.720912881855 Test RE 0.35514351636640556\n",
      "36 Train Loss 8.064081 Test MSE 558.8804117530233 Test RE 0.3271241512279391\n",
      "37 Train Loss 7.9223175 Test MSE 522.1706665684845 Test RE 0.31619820508813606\n",
      "38 Train Loss 7.8919764 Test MSE 507.7947744937878 Test RE 0.3118151975172474\n",
      "39 Train Loss 7.6526346 Test MSE 444.4770879120412 Test RE 0.29172782494621224\n",
      "40 Train Loss 7.364816 Test MSE 402.9390227745169 Test RE 0.2777619990332443\n",
      "41 Train Loss 6.9979877 Test MSE 379.2060074491955 Test RE 0.2694578058817628\n",
      "42 Train Loss 6.770653 Test MSE 404.41485275281633 Test RE 0.2782702084511356\n",
      "43 Train Loss 6.6859884 Test MSE 416.3814739365808 Test RE 0.28235719819461264\n",
      "44 Train Loss 6.648163 Test MSE 419.22763004610783 Test RE 0.28332057443749104\n",
      "45 Train Loss 6.356483 Test MSE 393.10548548016897 Test RE 0.2743517386081917\n",
      "46 Train Loss 5.968015 Test MSE 353.35280372815186 Test RE 0.2601102314308056\n",
      "47 Train Loss 5.8636475 Test MSE 362.35559593236866 Test RE 0.26340295995688007\n",
      "48 Train Loss 5.772039 Test MSE 388.8589635380242 Test RE 0.27286587264000217\n",
      "49 Train Loss 5.6558948 Test MSE 425.4924172596367 Test RE 0.28542964483867656\n",
      "50 Train Loss 5.395857 Test MSE 421.8362654789516 Test RE 0.2842006857087328\n",
      "51 Train Loss 5.158617 Test MSE 398.538575189081 Test RE 0.27624113299576347\n",
      "52 Train Loss 4.98054 Test MSE 420.2383332715386 Test RE 0.2836618933483612\n",
      "53 Train Loss 4.928588 Test MSE 434.8852386949868 Test RE 0.28856290272705676\n",
      "54 Train Loss 4.8789353 Test MSE 431.66703024555966 Test RE 0.287493218222967\n",
      "55 Train Loss 4.8361115 Test MSE 416.4361192970739 Test RE 0.2823757256815987\n",
      "56 Train Loss 4.7739615 Test MSE 436.007867168081 Test RE 0.2889351160239363\n",
      "57 Train Loss 4.7537246 Test MSE 445.4505979331582 Test RE 0.2920471266965452\n",
      "58 Train Loss 4.6487455 Test MSE 436.7085816761446 Test RE 0.2891671987037675\n",
      "59 Train Loss 4.4941597 Test MSE 415.9812857634583 Test RE 0.2822214774891693\n",
      "60 Train Loss 4.205266 Test MSE 360.58031901742254 Test RE 0.2627569269616452\n",
      "61 Train Loss 4.118984 Test MSE 358.975188242532 Test RE 0.26217144070155324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 4.067054 Test MSE 363.66254000798324 Test RE 0.26387755326737716\n",
      "63 Train Loss 4.017815 Test MSE 372.86307365352417 Test RE 0.2671947079916128\n",
      "64 Train Loss 3.9511697 Test MSE 361.2756421212428 Test RE 0.26301014789411337\n",
      "65 Train Loss 3.892887 Test MSE 343.5832804565529 Test RE 0.256489254722568\n",
      "66 Train Loss 3.8726754 Test MSE 333.09966929703506 Test RE 0.252545866948677\n",
      "67 Train Loss 3.8387446 Test MSE 310.35511649382977 Test RE 0.24377132586220912\n",
      "68 Train Loss 3.7987008 Test MSE 282.9261213651368 Test RE 0.23274999890692424\n",
      "69 Train Loss 3.7519236 Test MSE 252.04165857912196 Test RE 0.21967939766436942\n",
      "70 Train Loss 3.7034488 Test MSE 241.40750318804615 Test RE 0.21499509252010532\n",
      "71 Train Loss 3.6793375 Test MSE 231.24928339335656 Test RE 0.21042307482617278\n",
      "72 Train Loss 3.537526 Test MSE 255.92592434342168 Test RE 0.22136568772156198\n",
      "73 Train Loss 3.2427058 Test MSE 231.9393259913462 Test RE 0.21073678980374336\n",
      "74 Train Loss 3.0898292 Test MSE 218.19765264232623 Test RE 0.20439873409973142\n",
      "75 Train Loss 2.9386806 Test MSE 181.7156830318879 Test RE 0.18653029200821222\n",
      "76 Train Loss 2.7859175 Test MSE 131.0671791824786 Test RE 0.15841640045932365\n",
      "77 Train Loss 2.7534587 Test MSE 117.85610734780279 Test RE 0.1502205027264408\n",
      "78 Train Loss 2.7451847 Test MSE 113.3567083013139 Test RE 0.14732511127101988\n",
      "79 Train Loss 2.7429883 Test MSE 116.50978263204237 Test RE 0.14936001917110925\n",
      "80 Train Loss 2.7373397 Test MSE 121.2688285322983 Test RE 0.1523799251161097\n",
      "81 Train Loss 2.7261014 Test MSE 124.3712530563834 Test RE 0.15431678603060514\n",
      "82 Train Loss 2.7235422 Test MSE 125.57345680524195 Test RE 0.15506082473195412\n",
      "83 Train Loss 2.7099633 Test MSE 131.58726297775564 Test RE 0.1587303929970519\n",
      "84 Train Loss 2.7070208 Test MSE 133.29244484630456 Test RE 0.15975554149189686\n",
      "85 Train Loss 2.701174 Test MSE 129.24842616667001 Test RE 0.15731342857668287\n",
      "86 Train Loss 2.6971786 Test MSE 123.45144254036504 Test RE 0.15374508793320477\n",
      "87 Train Loss 2.6968482 Test MSE 122.89739602986513 Test RE 0.1533996982143799\n",
      "88 Train Loss 2.6964867 Test MSE 120.73983997144983 Test RE 0.15204721251789996\n",
      "89 Train Loss 2.6932523 Test MSE 126.89203858441687 Test RE 0.15587280542377524\n",
      "90 Train Loss 2.688671 Test MSE 131.23137115870375 Test RE 0.1585155960055028\n",
      "91 Train Loss 2.666778 Test MSE 141.72648493295162 Test RE 0.16473226607516953\n",
      "92 Train Loss 2.6131957 Test MSE 144.15494369635277 Test RE 0.16613760102058184\n",
      "93 Train Loss 2.5148997 Test MSE 175.12085146706278 Test RE 0.18311422986180853\n",
      "94 Train Loss 2.3512592 Test MSE 144.0031084983704 Test RE 0.16605008344827146\n",
      "95 Train Loss 2.2821438 Test MSE 152.7623326845511 Test RE 0.17102567194232624\n",
      "96 Train Loss 2.262764 Test MSE 167.79712960308808 Test RE 0.1792443307234412\n",
      "97 Train Loss 2.2428498 Test MSE 166.9061437616853 Test RE 0.17876781265312106\n",
      "98 Train Loss 2.2232559 Test MSE 158.65377860700337 Test RE 0.1742923697096909\n",
      "99 Train Loss 2.2136862 Test MSE 153.36106847050598 Test RE 0.17136050268483605\n",
      "Training time: 98.85\n",
      "Training time: 98.85\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 47.768356 Test MSE 5220.366514106654 Test RE 0.9997781988435581\n",
      "1 Train Loss 47.767323 Test MSE 5217.045658441462 Test RE 0.9994601515124709\n",
      "2 Train Loss 47.74744 Test MSE 5169.69621969594 Test RE 0.9949143082136234\n",
      "3 Train Loss 47.74605 Test MSE 5172.489926323523 Test RE 0.995183098019582\n",
      "4 Train Loss 47.736244 Test MSE 5163.334424000233 Test RE 0.9943019521160561\n",
      "5 Train Loss 47.63951 Test MSE 5038.827198709913 Test RE 0.9822406357874444\n",
      "6 Train Loss 46.45764 Test MSE 4897.921107926333 Test RE 0.9684095362997329\n",
      "7 Train Loss 39.593452 Test MSE 4716.923908830468 Test RE 0.9503478573923307\n",
      "8 Train Loss 36.249645 Test MSE 4356.18404985447 Test RE 0.9132848952406167\n",
      "9 Train Loss 35.586166 Test MSE 4361.608137027359 Test RE 0.9138533050869502\n",
      "10 Train Loss 33.894627 Test MSE 4369.092356352163 Test RE 0.9146370237117294\n",
      "11 Train Loss 32.73203 Test MSE 4559.3206693924485 Test RE 0.9343363255465807\n",
      "12 Train Loss 30.667503 Test MSE 4807.877589355123 Test RE 0.9594666098931273\n",
      "13 Train Loss 29.766525 Test MSE 5027.574258959833 Test RE 0.9811432303567537\n",
      "14 Train Loss 29.67418 Test MSE 5076.827947980179 Test RE 0.9859375049884919\n",
      "15 Train Loss 29.499239 Test MSE 5163.599414810238 Test RE 0.9943274663939977\n",
      "16 Train Loss 29.284065 Test MSE 5165.065907872605 Test RE 0.9944686538386659\n",
      "17 Train Loss 28.966005 Test MSE 5348.249527322845 Test RE 1.0119498617567313\n",
      "18 Train Loss 28.65129 Test MSE 5552.28195069915 Test RE 1.031071827682316\n",
      "19 Train Loss 28.232494 Test MSE 5795.898334490159 Test RE 1.053449070179836\n",
      "20 Train Loss 27.992142 Test MSE 6012.120358241484 Test RE 1.072919152326869\n",
      "21 Train Loss 27.56641 Test MSE 6167.495215296688 Test RE 1.0866947659648343\n",
      "22 Train Loss 27.267633 Test MSE 6297.083074766887 Test RE 1.0980519210480855\n",
      "23 Train Loss 26.865826 Test MSE 6505.247832875672 Test RE 1.116053690808497\n",
      "24 Train Loss 26.549408 Test MSE 6693.374650849577 Test RE 1.1320763871830661\n",
      "25 Train Loss 26.146692 Test MSE 6850.933837110475 Test RE 1.145323182451721\n",
      "26 Train Loss 25.378862 Test MSE 7459.327402682347 Test RE 1.195096568571195\n",
      "27 Train Loss 24.551966 Test MSE 7695.701390500714 Test RE 1.21388422776671\n",
      "28 Train Loss 24.186579 Test MSE 7921.704256480637 Test RE 1.2315795728913659\n",
      "29 Train Loss 24.158468 Test MSE 7997.017064362414 Test RE 1.2374201280755663\n",
      "30 Train Loss 24.157574 Test MSE 8006.800728124004 Test RE 1.2381768353461802\n",
      "31 Train Loss 24.1572 Test MSE 8012.125246848288 Test RE 1.2385884604319655\n",
      "32 Train Loss 24.157114 Test MSE 8023.559002535209 Test RE 1.2394719132379233\n",
      "33 Train Loss 24.157005 Test MSE 8023.551418491056 Test RE 1.2394713274497506\n",
      "34 Train Loss 24.157005 Test MSE 8023.551418491056 Test RE 1.2394713274497506\n",
      "35 Train Loss 24.144037 Test MSE 8014.881553304326 Test RE 1.2388014897907709\n",
      "36 Train Loss 24.127491 Test MSE 8035.088138250154 Test RE 1.2403620986410577\n",
      "37 Train Loss 24.097727 Test MSE 8097.114044487548 Test RE 1.2451403089342177\n",
      "38 Train Loss 24.074362 Test MSE 8154.733978585973 Test RE 1.2495627314273994\n",
      "39 Train Loss 24.056463 Test MSE 8221.683986395159 Test RE 1.2546816739029116\n",
      "40 Train Loss 24.040728 Test MSE 8278.107454415336 Test RE 1.2589796040276091\n",
      "41 Train Loss 24.016321 Test MSE 8339.244019489812 Test RE 1.2636200426552264\n",
      "42 Train Loss 23.98276 Test MSE 8399.069738934151 Test RE 1.2681445462556244\n",
      "43 Train Loss 23.955202 Test MSE 8420.155044069408 Test RE 1.2697353446905337\n",
      "44 Train Loss 23.931402 Test MSE 8435.624833954684 Test RE 1.2709012095223389\n",
      "45 Train Loss 23.909388 Test MSE 8455.15526211616 Test RE 1.2723715745002497\n",
      "46 Train Loss 23.875208 Test MSE 8500.71958383801 Test RE 1.2757953349231947\n",
      "47 Train Loss 23.536392 Test MSE 9140.316980711159 Test RE 1.322920642771547\n",
      "48 Train Loss 23.437086 Test MSE 9497.143062067145 Test RE 1.348495975743562\n",
      "49 Train Loss 23.432161 Test MSE 9594.951239488355 Test RE 1.3554220632209857\n",
      "50 Train Loss 23.404232 Test MSE 9742.136198442722 Test RE 1.3657784726780688\n",
      "51 Train Loss 23.355568 Test MSE 9729.749810667545 Test RE 1.3649099546218437\n",
      "52 Train Loss 23.341301 Test MSE 9698.9999827164 Test RE 1.3627514222544679\n",
      "53 Train Loss 23.327318 Test MSE 9763.862357312662 Test RE 1.3673005513177783\n",
      "54 Train Loss 23.319971 Test MSE 9813.979802349353 Test RE 1.37080520439482\n",
      "55 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "56 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "57 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "59 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "60 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "61 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "62 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "63 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "64 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "65 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "66 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "67 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "68 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "69 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "70 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "71 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "72 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "73 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "74 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "75 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "76 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "77 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "78 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "79 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "80 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "81 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "82 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "83 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "84 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "85 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "86 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "87 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "88 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "89 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "90 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "91 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "92 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "93 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "94 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "95 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "96 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "97 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "98 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "99 Train Loss 23.318695 Test MSE 9832.655957790574 Test RE 1.3721089162026938\n",
      "Training time: 60.07\n",
      "Training time: 60.07\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 47.769978 Test MSE 5223.71381366602 Test RE 1.0000986764224915\n",
      "1 Train Loss 47.769466 Test MSE 5221.885474986312 Test RE 0.9999236401182755\n",
      "2 Train Loss 47.747696 Test MSE 5174.515360777203 Test RE 0.9953779249673249\n",
      "3 Train Loss 47.74728 Test MSE 5171.750311154076 Test RE 0.9951119447800296\n",
      "4 Train Loss 47.731403 Test MSE 5133.021237375345 Test RE 0.9913789544890574\n",
      "5 Train Loss 47.712494 Test MSE 5080.319091541623 Test RE 0.9862764427926879\n",
      "6 Train Loss 47.66345 Test MSE 5012.000123898111 Test RE 0.9796223866560736\n",
      "7 Train Loss 47.295338 Test MSE 4807.660946469204 Test RE 0.9594449928746964\n",
      "8 Train Loss 47.07942 Test MSE 4701.101042920978 Test RE 0.9487525530423622\n",
      "9 Train Loss 46.873013 Test MSE 4610.748580624135 Test RE 0.9395910803062799\n",
      "10 Train Loss 46.517845 Test MSE 4575.688599879109 Test RE 0.9360119535775637\n",
      "11 Train Loss 45.798714 Test MSE 4524.058096694395 Test RE 0.9307161530263293\n",
      "12 Train Loss 43.814632 Test MSE 4382.819022664815 Test RE 0.916072684771909\n",
      "13 Train Loss 43.11912 Test MSE 4234.731334868285 Test RE 0.9004634635028725\n",
      "14 Train Loss 40.715374 Test MSE 4287.154366073189 Test RE 0.9060198762353348\n",
      "15 Train Loss 34.88591 Test MSE 4022.7648045751384 Test RE 0.8776381344042565\n",
      "16 Train Loss 32.672005 Test MSE 4024.505578735115 Test RE 0.8778280043839709\n",
      "17 Train Loss 30.715668 Test MSE 3626.3697613017557 Test RE 0.8332766399836364\n",
      "18 Train Loss 28.00728 Test MSE 4175.394766594531 Test RE 0.8941326132550476\n",
      "19 Train Loss 25.754864 Test MSE 4013.4491382974575 Test RE 0.8766213557581811\n",
      "20 Train Loss 21.72045 Test MSE 4052.770503257911 Test RE 0.88090519357318\n",
      "21 Train Loss 18.386257 Test MSE 3498.7955793478513 Test RE 0.8184882501288647\n",
      "22 Train Loss 15.626502 Test MSE 3601.196811461287 Test RE 0.8303794505973892\n",
      "23 Train Loss 15.161721 Test MSE 3909.035618371623 Test RE 0.8651431599956823\n",
      "24 Train Loss 14.7699795 Test MSE 3733.7029807040967 Test RE 0.8455183705180422\n",
      "25 Train Loss 13.410143 Test MSE 3206.7702328898326 Test RE 0.7835867549581467\n",
      "26 Train Loss 13.15247 Test MSE 2998.927856278552 Test RE 0.7577678472171383\n",
      "27 Train Loss 13.026667 Test MSE 3135.927998385215 Test RE 0.7748831300583068\n",
      "28 Train Loss 12.03328 Test MSE 3090.6675656131392 Test RE 0.7692709136577607\n",
      "29 Train Loss 11.7011175 Test MSE 2789.7716927986053 Test RE 0.7308655580854565\n",
      "30 Train Loss 11.623111 Test MSE 2985.203222525926 Test RE 0.7560318914003649\n",
      "31 Train Loss 11.549285 Test MSE 2940.034670978697 Test RE 0.7502904017045317\n",
      "32 Train Loss 11.12837 Test MSE 2769.3316603888197 Test RE 0.728183191646634\n",
      "33 Train Loss 10.53143 Test MSE 3014.4677066722334 Test RE 0.7597286119025162\n",
      "34 Train Loss 10.475911 Test MSE 2937.116485549418 Test RE 0.749917951999573\n",
      "35 Train Loss 10.470806 Test MSE 2922.94349885985 Test RE 0.7481064082250156\n",
      "36 Train Loss 10.422359 Test MSE 2933.702952252504 Test RE 0.7494820458790591\n",
      "37 Train Loss 10.335796 Test MSE 3075.0982400991975 Test RE 0.7673308552760489\n",
      "38 Train Loss 10.117421 Test MSE 3007.002638402307 Test RE 0.7587873277256996\n",
      "39 Train Loss 9.737912 Test MSE 3136.224068738024 Test RE 0.7749197084662067\n",
      "40 Train Loss 9.67113 Test MSE 3153.8416834161044 Test RE 0.7770932007723954\n",
      "41 Train Loss 9.648184 Test MSE 3145.6220021390427 Test RE 0.7760798928251861\n",
      "42 Train Loss 9.532178 Test MSE 3256.7938897451213 Test RE 0.7896748415984521\n",
      "43 Train Loss 9.460517 Test MSE 3325.9120077248112 Test RE 0.7980103833338955\n",
      "44 Train Loss 9.438959 Test MSE 3294.431344716306 Test RE 0.7942247111172188\n",
      "45 Train Loss 9.375129 Test MSE 3331.0670276108103 Test RE 0.7986285846847722\n",
      "46 Train Loss 9.333571 Test MSE 3416.8405255913913 Test RE 0.8088453989497306\n",
      "47 Train Loss 9.290142 Test MSE 3446.411249939726 Test RE 0.8123378969970281\n",
      "48 Train Loss 9.260795 Test MSE 3489.4198324171757 Test RE 0.817390860126895\n",
      "49 Train Loss 9.235307 Test MSE 3523.006788872425 Test RE 0.8213152839060188\n",
      "50 Train Loss 9.21739 Test MSE 3558.246188568472 Test RE 0.8254127272568287\n",
      "51 Train Loss 9.199752 Test MSE 3510.558844805687 Test RE 0.8198630111413018\n",
      "52 Train Loss 9.144442 Test MSE 3517.058600366663 Test RE 0.8206216431825378\n",
      "53 Train Loss 9.115726 Test MSE 3520.4981215281955 Test RE 0.82102281019244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 9.031581 Test MSE 3393.2683317691162 Test RE 0.8060505277806722\n",
      "55 Train Loss 8.937646 Test MSE 3464.1004660487006 Test RE 0.8144199510801486\n",
      "56 Train Loss 8.731656 Test MSE 3437.012827489001 Test RE 0.811229511161792\n",
      "57 Train Loss 8.384837 Test MSE 3547.4228903406024 Test RE 0.8241564212707594\n",
      "58 Train Loss 8.306013 Test MSE 3456.2805499824494 Test RE 0.8135001893722967\n",
      "59 Train Loss 8.169439 Test MSE 3436.488910688721 Test RE 0.8111676794216915\n",
      "60 Train Loss 7.8320403 Test MSE 3448.670017050004 Test RE 0.8126040552476845\n",
      "61 Train Loss 7.710149 Test MSE 3447.82305775626 Test RE 0.812504265355508\n",
      "62 Train Loss 7.6896086 Test MSE 3430.7589744864576 Test RE 0.8104911345147408\n",
      "63 Train Loss 7.644461 Test MSE 3397.025682923907 Test RE 0.8064966724200285\n",
      "64 Train Loss 7.600901 Test MSE 3308.7584153314137 Test RE 0.7959498296263627\n",
      "65 Train Loss 7.5980873 Test MSE 3293.3935686876016 Test RE 0.7940996072373124\n",
      "66 Train Loss 7.532204 Test MSE 3248.549855079897 Test RE 0.7886747427242319\n",
      "67 Train Loss 7.4774795 Test MSE 3184.3172048708643 Test RE 0.7808386939149273\n",
      "68 Train Loss 7.466213 Test MSE 3123.4403868499753 Test RE 0.7733387559672833\n",
      "69 Train Loss 7.459063 Test MSE 3073.8917893944054 Test RE 0.767180317375134\n",
      "70 Train Loss 7.4519596 Test MSE 3067.151030270692 Test RE 0.7663386781309891\n",
      "71 Train Loss 7.4285746 Test MSE 3051.3372837655324 Test RE 0.7643605645038137\n",
      "72 Train Loss 7.388572 Test MSE 2955.3651719247196 Test RE 0.752244013404093\n",
      "73 Train Loss 7.249145 Test MSE 3050.0916197308065 Test RE 0.7642045290396853\n",
      "74 Train Loss 7.182815 Test MSE 3060.1008456598897 Test RE 0.7654574144721661\n",
      "75 Train Loss 7.136755 Test MSE 3102.3783419860483 Test RE 0.770726948941075\n",
      "76 Train Loss 7.117028 Test MSE 3131.3093940622866 Test RE 0.7743122946798798\n",
      "77 Train Loss 7.0777063 Test MSE 3189.4117293614477 Test RE 0.781463068275881\n",
      "78 Train Loss 7.0072613 Test MSE 3162.3046288323444 Test RE 0.7781351191857997\n",
      "79 Train Loss 6.9247694 Test MSE 3258.042047384167 Test RE 0.7898261474995169\n",
      "80 Train Loss 6.8593497 Test MSE 3234.669389095736 Test RE 0.7869880067497126\n",
      "81 Train Loss 6.752919 Test MSE 3211.7655262506632 Test RE 0.7841968271302573\n",
      "82 Train Loss 6.6573095 Test MSE 3221.702169607054 Test RE 0.7854089745366223\n",
      "83 Train Loss 6.5808864 Test MSE 3194.5306680082494 Test RE 0.7820899327329445\n",
      "84 Train Loss 6.5576925 Test MSE 3227.715703225379 Test RE 0.7861416433382032\n",
      "85 Train Loss 6.5300565 Test MSE 3203.317870853029 Test RE 0.7831648423385136\n",
      "86 Train Loss 6.4826746 Test MSE 3138.269236725471 Test RE 0.7751723343399953\n",
      "87 Train Loss 6.4401493 Test MSE 3100.4132225156022 Test RE 0.7704828119784085\n",
      "88 Train Loss 6.3749986 Test MSE 3016.8373874999165 Test RE 0.7600271655498065\n",
      "89 Train Loss 6.2569675 Test MSE 2982.7775044247524 Test RE 0.7557246605670302\n",
      "90 Train Loss 6.140041 Test MSE 2920.6276624154357 Test RE 0.7478099886427022\n",
      "91 Train Loss 6.0190454 Test MSE 2906.7558578756048 Test RE 0.7460319768606775\n",
      "92 Train Loss 5.991494 Test MSE 2896.9827775081744 Test RE 0.7447767683714988\n",
      "93 Train Loss 5.9741096 Test MSE 2871.6313519390637 Test RE 0.7415108460097627\n",
      "94 Train Loss 5.960203 Test MSE 2860.3349723553233 Test RE 0.7400509368285593\n",
      "95 Train Loss 5.9490237 Test MSE 2823.7465427802067 Test RE 0.7353024631293019\n",
      "96 Train Loss 5.9388213 Test MSE 2820.577158941728 Test RE 0.7348896941355103\n",
      "97 Train Loss 5.9266562 Test MSE 2809.532003793366 Test RE 0.7334493980223281\n",
      "98 Train Loss 5.9081554 Test MSE 2784.2976266059854 Test RE 0.7301481569145813\n",
      "99 Train Loss 5.8906674 Test MSE 2797.773805736941 Test RE 0.7319130059566405\n",
      "Training time: 70.14\n",
      "Training time: 70.14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 47.768814 Test MSE 5221.293831947554 Test RE 0.9998669925125541\n",
      "1 Train Loss 47.745224 Test MSE 5159.6734702312515 Test RE 0.993949395159453\n",
      "2 Train Loss 47.708588 Test MSE 5113.044127725564 Test RE 0.9894479091731356\n",
      "3 Train Loss 46.84166 Test MSE 4861.624042184849 Test RE 0.9648145631835248\n",
      "4 Train Loss 45.376648 Test MSE 4723.081591899249 Test RE 0.9509679683399883\n",
      "5 Train Loss 38.733814 Test MSE 4558.047981223014 Test RE 0.9342059111857334\n",
      "6 Train Loss 34.727528 Test MSE 4337.656403989326 Test RE 0.9113406420446347\n",
      "7 Train Loss 32.479855 Test MSE 4398.909211386628 Test RE 0.9177526855798062\n",
      "8 Train Loss 30.726915 Test MSE 4540.814260533653 Test RE 0.9324381488900553\n",
      "9 Train Loss 30.204185 Test MSE 4944.4972358972545 Test RE 0.9730031223222506\n",
      "10 Train Loss 25.983158 Test MSE 4666.3665441181865 Test RE 0.9452410839480562\n",
      "11 Train Loss 22.0006 Test MSE 2926.3444962793824 Test RE 0.7485415121342025\n",
      "12 Train Loss 21.602789 Test MSE 2729.323117492486 Test RE 0.7229040228482749\n",
      "13 Train Loss 20.725477 Test MSE 2792.0782796653048 Test RE 0.7311676359561133\n",
      "14 Train Loss 15.475347 Test MSE 1328.1997529251337 Test RE 0.5042952322505746\n",
      "15 Train Loss 14.311389 Test MSE 1296.8390894311165 Test RE 0.49830610844547063\n",
      "16 Train Loss 13.240322 Test MSE 1331.9374465784044 Test RE 0.5050043036345924\n",
      "17 Train Loss 6.892596 Test MSE 746.2021121981217 Test RE 0.3779909497972093\n",
      "18 Train Loss 5.8087792 Test MSE 846.1223871551715 Test RE 0.4025035894506503\n",
      "19 Train Loss 5.094028 Test MSE 829.4089861855615 Test RE 0.3985084483814047\n",
      "20 Train Loss 4.670199 Test MSE 747.1795741844419 Test RE 0.378238436948147\n",
      "21 Train Loss 4.426053 Test MSE 667.1749023200465 Test RE 0.35741519751895073\n",
      "22 Train Loss 4.2948613 Test MSE 702.2535371747904 Test RE 0.3666908999647027\n",
      "23 Train Loss 3.9296584 Test MSE 682.858473509625 Test RE 0.3615917524776553\n",
      "24 Train Loss 3.4572122 Test MSE 614.0640748270266 Test RE 0.34289409784452657\n",
      "25 Train Loss 3.416479 Test MSE 601.902069452128 Test RE 0.3394814769364549\n",
      "26 Train Loss 3.393235 Test MSE 587.3608202582232 Test RE 0.33535566843193104\n",
      "27 Train Loss 3.3455215 Test MSE 607.2567374355255 Test RE 0.34098818845126455\n",
      "28 Train Loss 3.337272 Test MSE 605.7505789842068 Test RE 0.34056505515287233\n",
      "29 Train Loss 3.3268118 Test MSE 619.7886372871769 Test RE 0.3444886912865811\n",
      "30 Train Loss 3.1189468 Test MSE 557.4086272913199 Test RE 0.3266931344811851\n",
      "31 Train Loss 3.0223315 Test MSE 554.5916855487786 Test RE 0.3258665943860096\n",
      "32 Train Loss 2.9745 Test MSE 571.3857733731827 Test RE 0.3307637264529683\n",
      "33 Train Loss 2.9466715 Test MSE 569.0064434312217 Test RE 0.33007433491110016\n",
      "34 Train Loss 2.9213579 Test MSE 557.63659760981 Test RE 0.3267599335231707\n",
      "35 Train Loss 2.8639698 Test MSE 555.841705666717 Test RE 0.32623363065531696\n",
      "36 Train Loss 2.8166556 Test MSE 516.9388099637229 Test RE 0.3146101530753425\n",
      "37 Train Loss 2.6988287 Test MSE 520.4965161475926 Test RE 0.31569091084853396\n",
      "38 Train Loss 2.6825953 Test MSE 518.338131083384 Test RE 0.3150356803328704\n",
      "39 Train Loss 2.6682625 Test MSE 499.0775755180408 Test RE 0.3091271806606878\n",
      "40 Train Loss 2.6301527 Test MSE 519.6818045247354 Test RE 0.3154437451422002\n",
      "41 Train Loss 2.5930865 Test MSE 471.9697505324903 Test RE 0.30061472309404275\n",
      "42 Train Loss 2.577525 Test MSE 477.2470056516377 Test RE 0.30229068922024815\n",
      "43 Train Loss 2.5622618 Test MSE 498.1990995122533 Test RE 0.3088549981084648\n",
      "44 Train Loss 2.543904 Test MSE 484.74075375141587 Test RE 0.304654734434241\n",
      "45 Train Loss 2.4691153 Test MSE 436.92911822258446 Test RE 0.2892402037795706\n",
      "46 Train Loss 2.2057188 Test MSE 433.7371733710181 Test RE 0.28818175850010797\n",
      "47 Train Loss 2.1011076 Test MSE 409.2321389109921 Test RE 0.2799226439015009\n",
      "48 Train Loss 2.0588598 Test MSE 390.7365187233834 Test RE 0.2735238281611016\n",
      "49 Train Loss 2.0473535 Test MSE 377.0958166246132 Test RE 0.2687070257937292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 2.020523 Test MSE 370.43857800819154 Test RE 0.2663245910915795\n",
      "51 Train Loss 2.0043635 Test MSE 382.5148510478131 Test RE 0.2706308585364017\n",
      "52 Train Loss 1.9951319 Test MSE 369.55795665716704 Test RE 0.2660078440176336\n",
      "53 Train Loss 1.9925104 Test MSE 363.8288912111472 Test RE 0.26393789950170826\n",
      "54 Train Loss 1.9866843 Test MSE 372.68122398066413 Test RE 0.2671295430564052\n",
      "55 Train Loss 1.9784639 Test MSE 352.063910986052 Test RE 0.2596354078780238\n",
      "56 Train Loss 1.9464362 Test MSE 318.5480756479764 Test RE 0.24696798456682117\n",
      "57 Train Loss 1.9170853 Test MSE 356.09587784755985 Test RE 0.2611178960919306\n",
      "58 Train Loss 1.8825866 Test MSE 319.94238477222257 Test RE 0.2475078932207675\n",
      "59 Train Loss 1.8182993 Test MSE 324.88357503445167 Test RE 0.24941182627981048\n",
      "60 Train Loss 1.778602 Test MSE 346.69599245243177 Test RE 0.2576484745309975\n",
      "61 Train Loss 1.7247155 Test MSE 336.1153113314782 Test RE 0.2536864744680641\n",
      "62 Train Loss 1.6886717 Test MSE 323.11267980799215 Test RE 0.2487311428293795\n",
      "63 Train Loss 1.6772053 Test MSE 319.9498034427445 Test RE 0.24751076275127484\n",
      "64 Train Loss 1.6683459 Test MSE 324.99526440644564 Test RE 0.2494546943387675\n",
      "65 Train Loss 1.586557 Test MSE 283.11702560709 Test RE 0.23282850963110224\n",
      "66 Train Loss 1.4595479 Test MSE 257.30506780932683 Test RE 0.22196133830023865\n",
      "67 Train Loss 1.4145274 Test MSE 233.5705170652836 Test RE 0.21147653002944472\n",
      "68 Train Loss 1.396324 Test MSE 223.12306118898346 Test RE 0.20669282188608054\n",
      "69 Train Loss 1.3599688 Test MSE 200.9424773121809 Test RE 0.1961503289310355\n",
      "70 Train Loss 1.3070685 Test MSE 193.8291841738466 Test RE 0.19264722101618637\n",
      "71 Train Loss 1.2863269 Test MSE 185.79450922375182 Test RE 0.1886121224727321\n",
      "72 Train Loss 1.243801 Test MSE 200.4135887705921 Test RE 0.1958920211411376\n",
      "73 Train Loss 1.205335 Test MSE 164.1472548636655 Test RE 0.17728417747120406\n",
      "74 Train Loss 1.160939 Test MSE 148.44000923458893 Test RE 0.16858877345775938\n",
      "75 Train Loss 1.1451961 Test MSE 159.3362940784165 Test RE 0.17466686308233273\n",
      "76 Train Loss 1.1383648 Test MSE 158.40008215720096 Test RE 0.17415296223236082\n",
      "77 Train Loss 1.132168 Test MSE 150.1429720815253 Test RE 0.1695530743773859\n",
      "78 Train Loss 1.1195284 Test MSE 153.6263318277739 Test RE 0.17150863683617493\n",
      "79 Train Loss 1.1077601 Test MSE 164.21449570330506 Test RE 0.17732048485999707\n",
      "80 Train Loss 1.0956296 Test MSE 172.34361524636586 Test RE 0.18165642546201405\n",
      "81 Train Loss 1.0846176 Test MSE 170.90416468265167 Test RE 0.18089621821183327\n",
      "82 Train Loss 1.039348 Test MSE 157.12109261722702 Test RE 0.1734484447143685\n",
      "83 Train Loss 0.99147797 Test MSE 141.53678447759972 Test RE 0.16462198234859704\n",
      "84 Train Loss 0.9657519 Test MSE 173.56827252500017 Test RE 0.18230069956003506\n",
      "85 Train Loss 0.9532413 Test MSE 187.19444486417163 Test RE 0.1893213719371843\n",
      "86 Train Loss 0.9475337 Test MSE 186.58765479570422 Test RE 0.18901428062919548\n",
      "87 Train Loss 0.94692373 Test MSE 190.23657568447757 Test RE 0.19085352016792825\n",
      "88 Train Loss 0.9454903 Test MSE 194.6645098926141 Test RE 0.1930618906984634\n",
      "89 Train Loss 0.94498193 Test MSE 191.11679382156495 Test RE 0.19129454696177445\n",
      "90 Train Loss 0.94439656 Test MSE 186.26619838942307 Test RE 0.18885139192268258\n",
      "91 Train Loss 0.9401594 Test MSE 176.8470708714444 Test RE 0.18401452296790666\n",
      "92 Train Loss 0.9375273 Test MSE 187.43696788883005 Test RE 0.18944397154206724\n",
      "93 Train Loss 0.93439555 Test MSE 181.81731311396015 Test RE 0.1865824461171113\n",
      "94 Train Loss 0.93021625 Test MSE 179.70115362791944 Test RE 0.18549345790355545\n",
      "95 Train Loss 0.92633545 Test MSE 188.08727705338637 Test RE 0.18977232319982337\n",
      "96 Train Loss 0.92096746 Test MSE 181.85401331097722 Test RE 0.1866012761913734\n",
      "97 Train Loss 0.90920943 Test MSE 170.17053768046057 Test RE 0.18050754109601805\n",
      "98 Train Loss 0.8944034 Test MSE 171.19852612212804 Test RE 0.1810519369514893\n",
      "99 Train Loss 0.8330413 Test MSE 198.26327541810443 Test RE 0.19483828717097887\n",
      "Training time: 69.47\n",
      "Training time: 69.47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 47.770172 Test MSE 5224.029118438183 Test RE 1.0001288590797222\n",
      "1 Train Loss 47.749302 Test MSE 5178.337276373296 Test RE 0.9957454519675655\n",
      "2 Train Loss 47.740303 Test MSE 5162.041068160818 Test RE 0.9941774137197817\n",
      "3 Train Loss 47.726974 Test MSE 5128.560365414511 Test RE 0.9909480799979012\n",
      "4 Train Loss 47.72315 Test MSE 5098.951991298682 Test RE 0.9880834523775388\n",
      "5 Train Loss 47.62518 Test MSE 4983.418682608525 Test RE 0.9768251949087915\n",
      "6 Train Loss 47.510685 Test MSE 4860.954305138598 Test RE 0.9647481044954597\n",
      "7 Train Loss 47.414356 Test MSE 4743.617972938979 Test RE 0.953033172726578\n",
      "8 Train Loss 47.33083 Test MSE 4644.991485330371 Test RE 0.9430736830060363\n",
      "9 Train Loss 47.017715 Test MSE 4653.166869543903 Test RE 0.9439032432139104\n",
      "10 Train Loss 43.08071 Test MSE 4785.128383176014 Test RE 0.957193987082145\n",
      "11 Train Loss 41.53255 Test MSE 4344.603008502969 Test RE 0.9120700901437854\n",
      "12 Train Loss 36.965675 Test MSE 3693.5355334662477 Test RE 0.8409579981966931\n",
      "13 Train Loss 35.092815 Test MSE 3378.4616020081503 Test RE 0.8042899802206123\n",
      "14 Train Loss 24.252485 Test MSE 1088.348626095242 Test RE 0.456496215407487\n",
      "15 Train Loss 21.021818 Test MSE 888.6083682672663 Test RE 0.4124851937587932\n",
      "16 Train Loss 17.955637 Test MSE 795.6549615118084 Test RE 0.39031527911295527\n",
      "17 Train Loss 16.055498 Test MSE 842.9429624193058 Test RE 0.40174664557136686\n",
      "18 Train Loss 15.238213 Test MSE 926.4415451173027 Test RE 0.42117460359879266\n",
      "19 Train Loss 14.665988 Test MSE 825.4481715274235 Test RE 0.3975557778270439\n",
      "20 Train Loss 13.763015 Test MSE 985.6932401901547 Test RE 0.43443424686926263\n",
      "21 Train Loss 13.5049715 Test MSE 1103.882344531673 Test RE 0.4597423996626961\n",
      "22 Train Loss 13.384548 Test MSE 1138.859499090526 Test RE 0.46696920247975765\n",
      "23 Train Loss 13.28045 Test MSE 1107.5962494276841 Test RE 0.46051512958252594\n",
      "24 Train Loss 13.146095 Test MSE 1124.3293305297216 Test RE 0.4639807203615141\n",
      "25 Train Loss 12.998591 Test MSE 1106.5507416924945 Test RE 0.46029772824850235\n",
      "26 Train Loss 12.838326 Test MSE 1076.5705732378074 Test RE 0.45401940692312825\n",
      "27 Train Loss 12.732231 Test MSE 1071.3589002895435 Test RE 0.45291912080903746\n",
      "28 Train Loss 12.606735 Test MSE 1022.4678147361458 Test RE 0.4424640474729821\n",
      "29 Train Loss 12.534479 Test MSE 1022.6044566555718 Test RE 0.44249361178594016\n",
      "30 Train Loss 12.472104 Test MSE 1072.500122798336 Test RE 0.45316028365445876\n",
      "31 Train Loss 12.3860235 Test MSE 1025.8063427164873 Test RE 0.4431858182404562\n",
      "32 Train Loss 12.2574215 Test MSE 1099.4787904614213 Test RE 0.45882449225509614\n",
      "33 Train Loss 12.174542 Test MSE 1080.327217177962 Test RE 0.4548108571041129\n",
      "34 Train Loss 12.049265 Test MSE 1083.1751370976892 Test RE 0.4554099405899518\n",
      "35 Train Loss 11.910912 Test MSE 1133.5656147387974 Test RE 0.4658826064322167\n",
      "36 Train Loss 11.772523 Test MSE 1132.554037301164 Test RE 0.4656746866108603\n",
      "37 Train Loss 11.713023 Test MSE 1183.3490275274237 Test RE 0.476002894697112\n",
      "38 Train Loss 11.656997 Test MSE 1172.1463696238116 Test RE 0.47374439862852447\n",
      "39 Train Loss 11.587347 Test MSE 1173.606887224317 Test RE 0.474039454199404\n",
      "40 Train Loss 11.546421 Test MSE 1155.7140808927616 Test RE 0.4704119730576355\n",
      "41 Train Loss 11.300248 Test MSE 938.5906658019138 Test RE 0.4239271975314153\n",
      "42 Train Loss 11.179358 Test MSE 912.3702899284067 Test RE 0.4179638606314487\n",
      "43 Train Loss 11.165765 Test MSE 900.9694041119257 Test RE 0.41534423443527435\n",
      "44 Train Loss 11.132434 Test MSE 892.5377119360985 Test RE 0.41339617340997026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 11.077275 Test MSE 877.9697072763607 Test RE 0.4100085662781572\n",
      "46 Train Loss 11.040499 Test MSE 893.5220763608539 Test RE 0.4136240743396008\n",
      "47 Train Loss 11.022927 Test MSE 903.8215456315518 Test RE 0.4160011293820373\n",
      "48 Train Loss 11.015726 Test MSE 909.2168802916773 Test RE 0.417240934804224\n",
      "49 Train Loss 10.994367 Test MSE 909.6394641212097 Test RE 0.41733788570412866\n",
      "50 Train Loss 10.867003 Test MSE 906.0019122337427 Test RE 0.4165026048129644\n",
      "51 Train Loss 10.323208 Test MSE 962.3743189739259 Test RE 0.4292647009905654\n",
      "52 Train Loss 9.833624 Test MSE 1112.868171279387 Test RE 0.4616098054080839\n",
      "53 Train Loss 9.771933 Test MSE 1169.6262843342809 Test RE 0.47323485531861675\n",
      "54 Train Loss 9.747011 Test MSE 1201.8087808963805 Test RE 0.4797012510393716\n",
      "55 Train Loss 9.73517 Test MSE 1215.850054680328 Test RE 0.48249539641106526\n",
      "56 Train Loss 9.72349 Test MSE 1217.6907271887264 Test RE 0.4828604826045466\n",
      "57 Train Loss 9.710937 Test MSE 1228.7725057212729 Test RE 0.4850526787041035\n",
      "58 Train Loss 9.704243 Test MSE 1235.1757894563257 Test RE 0.4863148708826397\n",
      "59 Train Loss 9.699607 Test MSE 1237.8630920630403 Test RE 0.4868436074316387\n",
      "60 Train Loss 9.692753 Test MSE 1250.774991063397 Test RE 0.48937610406718896\n",
      "61 Train Loss 9.692753 Test MSE 1250.774991063397 Test RE 0.48937610406718896\n",
      "62 Train Loss 9.689039 Test MSE 1258.001809691337 Test RE 0.49078784419732496\n",
      "63 Train Loss 9.686312 Test MSE 1258.6382310048018 Test RE 0.4909119729338413\n",
      "64 Train Loss 9.686312 Test MSE 1258.6382310048018 Test RE 0.4909119729338413\n",
      "65 Train Loss 9.686312 Test MSE 1258.6382310048018 Test RE 0.4909119729338413\n",
      "66 Train Loss 9.67749 Test MSE 1270.5754910959804 Test RE 0.4932344491110538\n",
      "67 Train Loss 9.657669 Test MSE 1267.9995364092272 Test RE 0.4927342056273207\n",
      "68 Train Loss 9.6518755 Test MSE 1229.0790897391369 Test RE 0.48511318629345346\n",
      "69 Train Loss 9.637878 Test MSE 1207.3539974624296 Test RE 0.4808066623248479\n",
      "70 Train Loss 9.62828 Test MSE 1210.7693126914523 Test RE 0.4814862255174782\n",
      "71 Train Loss 9.61385 Test MSE 1216.954597704652 Test RE 0.48271450893246126\n",
      "72 Train Loss 9.609707 Test MSE 1216.3795043430478 Test RE 0.4826004378262735\n",
      "73 Train Loss 9.59897 Test MSE 1229.2171602363978 Test RE 0.4851404334976626\n",
      "74 Train Loss 9.597829 Test MSE 1229.1733499938505 Test RE 0.4851317880320239\n",
      "75 Train Loss 9.595736 Test MSE 1224.7439971435442 Test RE 0.48425690769328134\n",
      "76 Train Loss 9.594745 Test MSE 1219.9592396864302 Test RE 0.4833100488732678\n",
      "77 Train Loss 9.594745 Test MSE 1219.9592396864302 Test RE 0.4833100488732678\n",
      "78 Train Loss 9.593353 Test MSE 1211.572111512794 Test RE 0.48164582343526163\n",
      "79 Train Loss 9.590872 Test MSE 1209.2916798257381 Test RE 0.48119233093979713\n",
      "80 Train Loss 9.585942 Test MSE 1215.0673496661523 Test RE 0.4823400678972311\n",
      "81 Train Loss 9.5840025 Test MSE 1224.745364163155 Test RE 0.4842571779491495\n",
      "82 Train Loss 9.578619 Test MSE 1221.3178622623036 Test RE 0.4835790960701943\n",
      "83 Train Loss 9.564256 Test MSE 1223.2607923284725 Test RE 0.48396359343031764\n",
      "84 Train Loss 9.54974 Test MSE 1273.323892692064 Test RE 0.4937676224900409\n",
      "85 Train Loss 9.520232 Test MSE 1359.626549961808 Test RE 0.5102264669533645\n",
      "86 Train Loss 9.477166 Test MSE 1384.8776468428546 Test RE 0.514942654432739\n",
      "87 Train Loss 9.450686 Test MSE 1430.912266135272 Test RE 0.5234312747678511\n",
      "88 Train Loss 9.398666 Test MSE 1427.0525526888964 Test RE 0.5227248516721608\n",
      "89 Train Loss 9.299289 Test MSE 1432.6391660741544 Test RE 0.5237470316803133\n",
      "90 Train Loss 9.160872 Test MSE 1406.2958624616922 Test RE 0.5189093715706028\n",
      "91 Train Loss 8.926437 Test MSE 1374.5089248401341 Test RE 0.5130113181880673\n",
      "92 Train Loss 8.875862 Test MSE 1393.21736512017 Test RE 0.5164908167370938\n",
      "93 Train Loss 8.814248 Test MSE 1456.1699403941222 Test RE 0.528030726914982\n",
      "94 Train Loss 8.709387 Test MSE 1505.84224872559 Test RE 0.5369611977657104\n",
      "95 Train Loss 8.612431 Test MSE 1521.8117330628718 Test RE 0.5398009303841798\n",
      "96 Train Loss 8.541266 Test MSE 1530.678564595176 Test RE 0.5413712206403594\n",
      "97 Train Loss 8.455207 Test MSE 1540.6906980133829 Test RE 0.543138883166534\n",
      "98 Train Loss 8.393093 Test MSE 1572.2561957070145 Test RE 0.5486745575231144\n",
      "99 Train Loss 8.340437 Test MSE 1597.696457977131 Test RE 0.5530957239132539\n",
      "Training time: 67.22\n",
      "Training time: 67.22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 47.768257 Test MSE 5218.9531713368815 Test RE 0.9996428515516173\n",
      "1 Train Loss 47.75034 Test MSE 5178.670868058138 Test RE 0.9957775247194695\n",
      "2 Train Loss 47.72687 Test MSE 5121.725907327731 Test RE 0.9902875777832421\n",
      "3 Train Loss 47.706898 Test MSE 5091.826461877614 Test RE 0.9873928124999692\n",
      "4 Train Loss 47.631504 Test MSE 4956.050708187223 Test RE 0.9741392343358515\n",
      "5 Train Loss 47.58722 Test MSE 4829.203262696383 Test RE 0.961592145741285\n",
      "6 Train Loss 47.354763 Test MSE 4743.140875430466 Test RE 0.9529852450489904\n",
      "7 Train Loss 47.210117 Test MSE 4741.703836366843 Test RE 0.952840870171226\n",
      "8 Train Loss 47.0271 Test MSE 4772.895070018319 Test RE 0.9559696576124072\n",
      "9 Train Loss 46.7091 Test MSE 5023.91177111296 Test RE 0.9807857935845382\n",
      "10 Train Loss 46.633358 Test MSE 5070.971487699709 Test RE 0.9853686684963968\n",
      "11 Train Loss 46.587284 Test MSE 5077.25768483045 Test RE 0.9859792322950511\n",
      "12 Train Loss 46.54761 Test MSE 5090.838649199369 Test RE 0.9872970309120335\n",
      "13 Train Loss 46.515636 Test MSE 5097.345433849254 Test RE 0.9879277794184277\n",
      "14 Train Loss 46.49768 Test MSE 5133.204583560799 Test RE 0.9913966598440668\n",
      "15 Train Loss 46.488476 Test MSE 5186.181527310844 Test RE 0.996499354330209\n",
      "16 Train Loss 46.472023 Test MSE 5274.026505765899 Test RE 1.0049034071892673\n",
      "17 Train Loss 45.47261 Test MSE 5823.6600037077 Test RE 1.0559690046171726\n",
      "18 Train Loss 44.14689 Test MSE 6271.066917627632 Test RE 1.0957812936754443\n",
      "19 Train Loss 43.03631 Test MSE 5727.267454300319 Test RE 1.0471934012533033\n",
      "20 Train Loss 42.570175 Test MSE 5844.884953195224 Test RE 1.0578915502635888\n",
      "21 Train Loss 41.994747 Test MSE 6339.729249713215 Test RE 1.1017638538159389\n",
      "22 Train Loss 41.76059 Test MSE 6629.37172017001 Test RE 1.1266508542959364\n",
      "23 Train Loss 41.68613 Test MSE 6590.259197719778 Test RE 1.12332238310433\n",
      "24 Train Loss 41.649055 Test MSE 6626.141339572264 Test RE 1.1263763219050944\n",
      "25 Train Loss 41.51654 Test MSE 7027.3655641646865 Test RE 1.1599771592664052\n",
      "26 Train Loss 41.385143 Test MSE 7205.943884491552 Test RE 1.1746232763249511\n",
      "27 Train Loss 41.188698 Test MSE 7466.827393659873 Test RE 1.1956972233696055\n",
      "28 Train Loss 40.631374 Test MSE 8059.521451194505 Test RE 1.242246530449261\n",
      "29 Train Loss 40.30225 Test MSE 8463.682708293974 Test RE 1.2730130379299724\n",
      "30 Train Loss 39.99081 Test MSE 8767.514448581822 Test RE 1.2956610695422075\n",
      "31 Train Loss 39.81106 Test MSE 9269.455886507945 Test RE 1.3322333022959598\n",
      "32 Train Loss 39.47774 Test MSE 9641.56612870995 Test RE 1.3587105789059895\n",
      "33 Train Loss 39.23004 Test MSE 10124.860616519738 Test RE 1.3923476664751306\n",
      "34 Train Loss 39.18034 Test MSE 10184.279380741835 Test RE 1.3964272561135818\n",
      "35 Train Loss 39.157986 Test MSE 10154.83026578697 Test RE 1.3944068226209627\n",
      "36 Train Loss 39.023262 Test MSE 10309.29181452984 Test RE 1.404971715203972\n",
      "37 Train Loss 38.768784 Test MSE 10785.195189908463 Test RE 1.4370344161193382\n",
      "38 Train Loss 38.421013 Test MSE 10900.224536556681 Test RE 1.4446774261787694\n",
      "39 Train Loss 37.642063 Test MSE 11416.585460249693 Test RE 1.478499835921403\n",
      "40 Train Loss 37.19078 Test MSE 11979.288758874327 Test RE 1.5144979209990903\n",
      "41 Train Loss 36.91304 Test MSE 11907.797137612093 Test RE 1.5099719453454066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 36.661488 Test MSE 11758.775753211421 Test RE 1.500493846657764\n",
      "43 Train Loss 36.574726 Test MSE 11629.675949743938 Test RE 1.4922341392026564\n",
      "44 Train Loss 36.531208 Test MSE 11572.262174231384 Test RE 1.4885461259413812\n",
      "45 Train Loss 36.20083 Test MSE 10974.822013602818 Test RE 1.4496124408113675\n",
      "46 Train Loss 35.83604 Test MSE 10644.833646445471 Test RE 1.427652808750644\n",
      "47 Train Loss 34.823807 Test MSE 10481.172326807218 Test RE 1.4166354174478375\n",
      "48 Train Loss 23.362387 Test MSE 6976.725055710341 Test RE 1.1557900964342895\n",
      "49 Train Loss 19.856405 Test MSE 7978.919866314937 Test RE 1.23601919816769\n",
      "50 Train Loss 19.48556 Test MSE 8501.833745132684 Test RE 1.2758789393283985\n",
      "51 Train Loss 19.483574 Test MSE 8507.927445680696 Test RE 1.2763361013813155\n",
      "52 Train Loss 19.48084 Test MSE 8561.107057887359 Test RE 1.2803188177750333\n",
      "53 Train Loss 19.48084 Test MSE 8561.107057887359 Test RE 1.2803188177750333\n",
      "54 Train Loss 19.480837 Test MSE 8561.107296195794 Test RE 1.2803188355946196\n",
      "55 Train Loss 19.480837 Test MSE 8561.107296195794 Test RE 1.2803188355946196\n",
      "56 Train Loss 19.478817 Test MSE 8561.152044191995 Test RE 1.280322181635356\n",
      "57 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "58 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "59 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "60 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "61 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "62 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "63 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "64 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "65 Train Loss 19.47872 Test MSE 8561.159739895857 Test RE 1.2803227570823337\n",
      "66 Train Loss 19.47869 Test MSE 8561.185514439912 Test RE 1.2803246843743994\n",
      "67 Train Loss 19.47869 Test MSE 8561.185226215977 Test RE 1.2803246628224643\n",
      "68 Train Loss 19.478685 Test MSE 8561.182659932656 Test RE 1.280324470928703\n",
      "69 Train Loss 19.478685 Test MSE 8561.182659932656 Test RE 1.280324470928703\n",
      "70 Train Loss 19.478685 Test MSE 8561.180796769455 Test RE 1.28032433161071\n",
      "71 Train Loss 19.478685 Test MSE 8561.180796769455 Test RE 1.28032433161071\n",
      "72 Train Loss 19.478685 Test MSE 8561.179860854978 Test RE 1.280324261627717\n",
      "73 Train Loss 19.478685 Test MSE 8561.179860854978 Test RE 1.280324261627717\n",
      "74 Train Loss 19.478685 Test MSE 8561.179860854978 Test RE 1.280324261627717\n",
      "75 Train Loss 19.478685 Test MSE 8561.179860854978 Test RE 1.280324261627717\n",
      "76 Train Loss 19.478685 Test MSE 8561.179860854978 Test RE 1.280324261627717\n",
      "77 Train Loss 19.478685 Test MSE 8561.179860854978 Test RE 1.280324261627717\n",
      "78 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "79 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "80 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "81 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "82 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "83 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "84 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "85 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "86 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "87 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "88 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "89 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "90 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "91 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "92 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "93 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "94 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "95 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "96 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "97 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "98 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "99 Train Loss 19.478685 Test MSE 8561.179739635763 Test RE 1.2803242525635514\n",
      "Training time: 42.72\n",
      "Training time: 42.72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 47.771805 Test MSE 5227.4489098651975 Test RE 1.000456161288379\n",
      "1 Train Loss 47.771564 Test MSE 5226.850963882661 Test RE 1.0003989406573817\n",
      "2 Train Loss 47.762463 Test MSE 5206.1879893247105 Test RE 0.9984195760234111\n",
      "3 Train Loss 47.741455 Test MSE 5154.156924111751 Test RE 0.9934179047368263\n",
      "4 Train Loss 47.741016 Test MSE 5155.588034881813 Test RE 0.9935558121007332\n",
      "5 Train Loss 47.73469 Test MSE 5148.694773196199 Test RE 0.9928913746978453\n",
      "6 Train Loss 47.708122 Test MSE 5063.457467095094 Test RE 0.9846383522918126\n",
      "7 Train Loss 47.600094 Test MSE 5012.1900005588805 Test RE 0.9796409426877309\n",
      "8 Train Loss 47.103024 Test MSE 4896.5672641752435 Test RE 0.9682756870826827\n",
      "9 Train Loss 46.810654 Test MSE 4786.006685424531 Test RE 0.957281828722935\n",
      "10 Train Loss 45.52093 Test MSE 4734.737987338262 Test RE 0.9521407225727572\n",
      "11 Train Loss 43.464245 Test MSE 4723.2274529561655 Test RE 0.9509826524100544\n",
      "12 Train Loss 41.95327 Test MSE 4811.298214601936 Test RE 0.9598078615270431\n",
      "13 Train Loss 35.324303 Test MSE 4593.2157923604 Test RE 0.9378029387864353\n",
      "14 Train Loss 32.25612 Test MSE 4570.532826097178 Test RE 0.9354844672803941\n",
      "15 Train Loss 31.043644 Test MSE 4584.983688280809 Test RE 0.9369621821251444\n",
      "16 Train Loss 29.148691 Test MSE 4666.393653724431 Test RE 0.9452438296685363\n",
      "17 Train Loss 28.33763 Test MSE 4779.80177855878 Test RE 0.956661084599872\n",
      "18 Train Loss 26.377113 Test MSE 4946.498591558532 Test RE 0.9732000208341078\n",
      "19 Train Loss 25.107924 Test MSE 5435.33356265125 Test RE 1.0201552419377327\n",
      "20 Train Loss 22.92082 Test MSE 5298.802318163924 Test RE 1.0072610106935431\n",
      "21 Train Loss 15.318207 Test MSE 2279.844358051503 Test RE 0.6607022173592839\n",
      "22 Train Loss 8.88616 Test MSE 501.23099354889047 Test RE 0.30979337320653727\n",
      "23 Train Loss 7.4282317 Test MSE 410.11542215801586 Test RE 0.2802245724232326\n",
      "24 Train Loss 7.2045465 Test MSE 379.69836605659583 Test RE 0.2696326802652942\n",
      "25 Train Loss 6.647214 Test MSE 419.36691867347827 Test RE 0.28336763724264336\n",
      "26 Train Loss 6.451747 Test MSE 426.33195567171 Test RE 0.2857110964633898\n",
      "27 Train Loss 6.367162 Test MSE 425.0152434199171 Test RE 0.2852695506029432\n",
      "28 Train Loss 6.1645417 Test MSE 412.70869937129436 Test RE 0.28110914636728346\n",
      "29 Train Loss 6.0109124 Test MSE 355.10910715022845 Test RE 0.2607558556221666\n",
      "30 Train Loss 5.756557 Test MSE 354.49910065448313 Test RE 0.2605317961278086\n",
      "31 Train Loss 5.49646 Test MSE 405.91817067393487 Test RE 0.2787869310066632\n",
      "32 Train Loss 5.46163 Test MSE 418.7473763969235 Test RE 0.2831582464795099\n",
      "33 Train Loss 5.402923 Test MSE 443.7683962126889 Test RE 0.29149516102492334\n",
      "34 Train Loss 5.323687 Test MSE 411.91345553095425 Test RE 0.28083818271847955\n",
      "35 Train Loss 5.280829 Test MSE 407.7065054555735 Test RE 0.2794003753930213\n",
      "36 Train Loss 5.165157 Test MSE 403.6218523209966 Test RE 0.27799725028077904\n",
      "37 Train Loss 5.121912 Test MSE 417.25367323798565 Test RE 0.28265277200638683\n",
      "38 Train Loss 5.0279737 Test MSE 416.18291482693905 Test RE 0.28228986657344945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 4.9796467 Test MSE 423.39323764954025 Test RE 0.2847246864207879\n",
      "40 Train Loss 4.9684935 Test MSE 406.7101037953347 Test RE 0.27905875060159074\n",
      "41 Train Loss 4.963262 Test MSE 410.47125254712836 Test RE 0.28034611235339135\n",
      "42 Train Loss 4.920312 Test MSE 415.86837699446625 Test RE 0.2821831735518661\n",
      "43 Train Loss 4.8602643 Test MSE 414.1303877876567 Test RE 0.2815929089261503\n",
      "44 Train Loss 4.8439617 Test MSE 425.6308444697242 Test RE 0.2854760710671395\n",
      "45 Train Loss 4.795335 Test MSE 419.77732741659696 Test RE 0.28350626061933026\n",
      "46 Train Loss 4.7719693 Test MSE 431.72114701869936 Test RE 0.28751123873019724\n",
      "47 Train Loss 4.767348 Test MSE 424.6845787453476 Test RE 0.28515855821057884\n",
      "48 Train Loss 4.734679 Test MSE 428.7688556395316 Test RE 0.2865264907249373\n",
      "49 Train Loss 4.702058 Test MSE 416.29742663903494 Test RE 0.2823286996198549\n",
      "50 Train Loss 4.6704264 Test MSE 400.80000793808887 Test RE 0.2770237637146505\n",
      "51 Train Loss 4.6487784 Test MSE 396.3282415324149 Test RE 0.2754740378404603\n",
      "52 Train Loss 4.6427913 Test MSE 398.1933066580219 Test RE 0.27612144817436257\n",
      "53 Train Loss 4.638817 Test MSE 398.7126937339925 Test RE 0.2763014702564097\n",
      "54 Train Loss 4.597576 Test MSE 377.61598020494915 Test RE 0.2688922883127435\n",
      "55 Train Loss 4.5651207 Test MSE 366.5778123898101 Test RE 0.26493311893516436\n",
      "56 Train Loss 4.5388722 Test MSE 344.2437020723611 Test RE 0.2567356429153103\n",
      "57 Train Loss 4.5037055 Test MSE 343.95632902019264 Test RE 0.25662845967729697\n",
      "58 Train Loss 4.4804997 Test MSE 350.9355810063192 Test RE 0.25921902110175943\n",
      "59 Train Loss 4.434542 Test MSE 321.0766364604226 Test RE 0.24794623444153374\n",
      "60 Train Loss 4.4239507 Test MSE 310.0670540652418 Test RE 0.24365816893595219\n",
      "61 Train Loss 4.4145484 Test MSE 311.6841965845465 Test RE 0.24429273741627558\n",
      "62 Train Loss 4.4094396 Test MSE 311.9403996102246 Test RE 0.24439312056462134\n",
      "63 Train Loss 4.4061913 Test MSE 312.1751143678774 Test RE 0.24448504819852107\n",
      "64 Train Loss 4.3936424 Test MSE 315.6944980083321 Test RE 0.24585931720203452\n",
      "65 Train Loss 4.3800774 Test MSE 329.1297152455601 Test RE 0.2510364077638847\n",
      "66 Train Loss 4.357054 Test MSE 327.12441416077183 Test RE 0.2502704898312418\n",
      "67 Train Loss 4.3484793 Test MSE 325.2465418720376 Test RE 0.24955111148518408\n",
      "68 Train Loss 4.344546 Test MSE 327.209321165751 Test RE 0.25030296728953294\n",
      "69 Train Loss 4.338281 Test MSE 334.52775745355353 Test RE 0.25308665407925607\n",
      "70 Train Loss 4.333107 Test MSE 334.49779308492447 Test RE 0.25307531906825026\n",
      "71 Train Loss 4.3198314 Test MSE 340.74951797725004 Test RE 0.25542934502479314\n",
      "72 Train Loss 4.309098 Test MSE 341.0323503717096 Test RE 0.2555353300732881\n",
      "73 Train Loss 4.296709 Test MSE 351.89427327456053 Test RE 0.2595728492603556\n",
      "74 Train Loss 4.283326 Test MSE 361.0131875710048 Test RE 0.2629145965432256\n",
      "75 Train Loss 4.2789702 Test MSE 362.3673817290719 Test RE 0.2634072435784513\n",
      "76 Train Loss 4.2719197 Test MSE 361.7858460246305 Test RE 0.26319579763844053\n",
      "77 Train Loss 4.261903 Test MSE 371.31757308827565 Test RE 0.26664037799098994\n",
      "78 Train Loss 4.241572 Test MSE 366.70330715254715 Test RE 0.26497846384250406\n",
      "79 Train Loss 4.2250886 Test MSE 377.3723201931379 Test RE 0.26880552176411177\n",
      "80 Train Loss 4.215772 Test MSE 391.1767262226108 Test RE 0.27367786206976963\n",
      "81 Train Loss 4.1998444 Test MSE 389.7106627727695 Test RE 0.2731645317457373\n",
      "82 Train Loss 4.1728196 Test MSE 387.3858874880265 Test RE 0.27234854680819753\n",
      "83 Train Loss 4.1531086 Test MSE 385.23767196673543 Test RE 0.2715923541383467\n",
      "84 Train Loss 4.1382046 Test MSE 393.0982815508208 Test RE 0.27434922475418894\n",
      "85 Train Loss 4.0949025 Test MSE 397.3088566867892 Test RE 0.27581462311735655\n",
      "86 Train Loss 4.0611424 Test MSE 401.06407043608283 Test RE 0.2771150056567632\n",
      "87 Train Loss 4.031447 Test MSE 405.3848779532643 Test RE 0.2786037365652038\n",
      "88 Train Loss 4.0029864 Test MSE 393.2210779965706 Test RE 0.2743920721548597\n",
      "89 Train Loss 3.964758 Test MSE 370.79196419274575 Test RE 0.26645159324744344\n",
      "90 Train Loss 3.9295235 Test MSE 353.8046968239054 Test RE 0.26027650216671516\n",
      "91 Train Loss 3.9106483 Test MSE 358.5574701079093 Test RE 0.262018859623575\n",
      "92 Train Loss 3.8897753 Test MSE 376.2366452379656 Test RE 0.26840074151776677\n",
      "93 Train Loss 3.8517363 Test MSE 365.3062950216943 Test RE 0.26447324428646646\n",
      "94 Train Loss 3.8232765 Test MSE 363.8952934816433 Test RE 0.2639619840049238\n",
      "95 Train Loss 3.806389 Test MSE 356.0633428001436 Test RE 0.261105967173741\n",
      "96 Train Loss 3.7912014 Test MSE 352.69781224717525 Test RE 0.2598690432916003\n",
      "97 Train Loss 3.7604587 Test MSE 356.23986810778183 Test RE 0.26117068332720333\n",
      "98 Train Loss 3.7087684 Test MSE 377.1023439914349 Test RE 0.26870935138533963\n",
      "99 Train Loss 3.6658323 Test MSE 380.05683736878063 Test RE 0.26975992966520224\n",
      "Training time: 67.67\n",
      "Training time: 67.67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 47.768696 Test MSE 5221.028373914218 Test RE 0.9998415748567319\n",
      "1 Train Loss 47.75219 Test MSE 5178.108559445785 Test RE 0.995723461670004\n",
      "2 Train Loss 47.751133 Test MSE 5180.8631100982775 Test RE 0.9959882693710148\n",
      "3 Train Loss 47.74814 Test MSE 5177.2928094355475 Test RE 0.9956450263293964\n",
      "4 Train Loss 47.71013 Test MSE 5080.348587634325 Test RE 0.9862793059257547\n",
      "5 Train Loss 47.675407 Test MSE 5027.147603806837 Test RE 0.9811015980829176\n",
      "6 Train Loss 47.382336 Test MSE 4678.561305602649 Test RE 0.9464753920889901\n",
      "7 Train Loss 47.143353 Test MSE 4536.293708310217 Test RE 0.9319738946055328\n",
      "8 Train Loss 46.50798 Test MSE 4408.082444405746 Test RE 0.9187091016372071\n",
      "9 Train Loss 44.81634 Test MSE 4184.457181047779 Test RE 0.8951024147684862\n",
      "10 Train Loss 39.99403 Test MSE 3494.3391810000776 Test RE 0.8179668318583846\n",
      "11 Train Loss 24.182049 Test MSE 1320.042992959989 Test RE 0.5027443548467226\n",
      "12 Train Loss 18.22111 Test MSE 1353.586408588928 Test RE 0.509091864813735\n",
      "13 Train Loss 17.978851 Test MSE 1478.117816798632 Test RE 0.531995171568689\n",
      "14 Train Loss 17.254072 Test MSE 1506.5033492857638 Test RE 0.5370790541997865\n",
      "15 Train Loss 17.203161 Test MSE 1565.3675580605723 Test RE 0.5474712646702066\n",
      "16 Train Loss 16.739069 Test MSE 1520.2004889539062 Test RE 0.5395150929878418\n",
      "17 Train Loss 15.499379 Test MSE 1305.8584139833877 Test RE 0.5000359287316952\n",
      "18 Train Loss 13.897008 Test MSE 1292.8185694503188 Test RE 0.49753307311278483\n",
      "19 Train Loss 13.719399 Test MSE 1314.6793649487204 Test RE 0.5017219341939341\n",
      "20 Train Loss 13.683434 Test MSE 1291.0927253556638 Test RE 0.49720087210030856\n",
      "21 Train Loss 12.840429 Test MSE 1363.899948064236 Test RE 0.5110276760119075\n",
      "22 Train Loss 12.40446 Test MSE 1274.1624002782016 Test RE 0.49393017333856365\n",
      "23 Train Loss 11.922508 Test MSE 1293.432849918152 Test RE 0.49765126005737265\n",
      "24 Train Loss 11.75505 Test MSE 1502.2319141530202 Test RE 0.5363171153751892\n",
      "25 Train Loss 11.434796 Test MSE 1620.090477038468 Test RE 0.556958452536269\n",
      "26 Train Loss 11.110118 Test MSE 1709.4896876803311 Test RE 0.5721190480313719\n",
      "27 Train Loss 10.609866 Test MSE 1670.828089435384 Test RE 0.5656125649126417\n",
      "28 Train Loss 9.773522 Test MSE 1610.7177624008302 Test RE 0.5553450288534088\n",
      "29 Train Loss 9.234395 Test MSE 2069.0248391011783 Test RE 0.6294134467662342\n",
      "30 Train Loss 8.861905 Test MSE 2116.866851868968 Test RE 0.636648816150425\n",
      "31 Train Loss 8.680181 Test MSE 1984.4891626861397 Test RE 0.6164211487209995\n",
      "32 Train Loss 8.43948 Test MSE 1882.5432694310748 Test RE 0.6003792143878088\n",
      "33 Train Loss 8.341934 Test MSE 1667.092692023461 Test RE 0.5649799534808742\n",
      "34 Train Loss 8.22201 Test MSE 1573.5556612651649 Test RE 0.5489012497228809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 7.99013 Test MSE 1781.7270710340872 Test RE 0.5840819077894673\n",
      "36 Train Loss 7.92794 Test MSE 1811.1874072491444 Test RE 0.5888909221701052\n",
      "37 Train Loss 7.869459 Test MSE 1900.873430554957 Test RE 0.6032950540249494\n",
      "38 Train Loss 7.8274865 Test MSE 1839.636068210213 Test RE 0.5934978125205168\n",
      "39 Train Loss 7.7801576 Test MSE 1851.17843208927 Test RE 0.5953567823880103\n",
      "40 Train Loss 7.690363 Test MSE 1860.1125900223576 Test RE 0.5967917087069469\n",
      "41 Train Loss 7.5129013 Test MSE 1881.9392270548697 Test RE 0.600282886301058\n",
      "42 Train Loss 7.432674 Test MSE 1866.360380630289 Test RE 0.597793127639088\n",
      "43 Train Loss 7.3821 Test MSE 1861.1211124008848 Test RE 0.5969534720961185\n",
      "44 Train Loss 7.3399324 Test MSE 1853.7667189391013 Test RE 0.5957728459738418\n",
      "45 Train Loss 7.2920475 Test MSE 1934.6845867869788 Test RE 0.6086368602488781\n",
      "46 Train Loss 7.2151227 Test MSE 2022.692324634584 Test RE 0.6223261895468087\n",
      "47 Train Loss 7.073108 Test MSE 1994.6905748760107 Test RE 0.6180034968617388\n",
      "48 Train Loss 6.9979506 Test MSE 1953.49451419045 Test RE 0.6115884325492409\n",
      "49 Train Loss 6.8666325 Test MSE 1961.4384297037832 Test RE 0.6128306878057842\n",
      "50 Train Loss 6.8103023 Test MSE 1953.2146034336424 Test RE 0.6115446145828874\n",
      "51 Train Loss 6.785483 Test MSE 1980.4026327625302 Test RE 0.6157861435847728\n",
      "52 Train Loss 6.7654185 Test MSE 1969.9552240172334 Test RE 0.6141597377891457\n",
      "53 Train Loss 6.6787577 Test MSE 2025.6336535974472 Test RE 0.6227785077409133\n",
      "54 Train Loss 6.6196675 Test MSE 2033.8829325919996 Test RE 0.6240453344838593\n",
      "55 Train Loss 6.582359 Test MSE 1996.3756350086771 Test RE 0.6182644779957276\n",
      "56 Train Loss 6.5550923 Test MSE 1965.2768314595235 Test RE 0.6134300287432767\n",
      "57 Train Loss 6.45372 Test MSE 1897.7645438654736 Test RE 0.6028015063118218\n",
      "58 Train Loss 6.2050967 Test MSE 1934.3151179181223 Test RE 0.608578741444683\n",
      "59 Train Loss 6.0898514 Test MSE 1965.8842559808481 Test RE 0.6135248203900439\n",
      "60 Train Loss 6.0618997 Test MSE 1967.1884010255274 Test RE 0.61372828931182\n",
      "61 Train Loss 6.043888 Test MSE 1914.7786183144442 Test RE 0.6054976323599339\n",
      "62 Train Loss 6.0039983 Test MSE 1915.9831241400682 Test RE 0.6056880488283863\n",
      "63 Train Loss 5.9986615 Test MSE 1935.5571024016858 Test RE 0.6087740881225834\n",
      "64 Train Loss 5.987045 Test MSE 1975.5241947479792 Test RE 0.6150272254761838\n",
      "65 Train Loss 5.9403086 Test MSE 1917.9855156404867 Test RE 0.6060044680783062\n",
      "66 Train Loss 5.9240723 Test MSE 1873.035528284626 Test RE 0.598861194627754\n",
      "67 Train Loss 5.8966928 Test MSE 1906.5310933102887 Test RE 0.6041921952882858\n",
      "68 Train Loss 5.76331 Test MSE 1858.6989513915346 Test RE 0.5965648922854012\n",
      "69 Train Loss 5.679274 Test MSE 1767.436772488255 Test RE 0.5817348849026855\n",
      "70 Train Loss 5.619217 Test MSE 1696.7538420027063 Test RE 0.5699838956928033\n",
      "71 Train Loss 5.584458 Test MSE 1654.4507404473754 Test RE 0.5628336896448032\n",
      "72 Train Loss 5.576116 Test MSE 1613.4284316834471 Test RE 0.5558121261745648\n",
      "73 Train Loss 5.5478544 Test MSE 1608.5319011505358 Test RE 0.5549680791086282\n",
      "74 Train Loss 5.497292 Test MSE 1604.325382606589 Test RE 0.5542419474859795\n",
      "75 Train Loss 5.4144015 Test MSE 1502.8946355460946 Test RE 0.536435402582069\n",
      "76 Train Loss 5.3634243 Test MSE 1312.6917051351477 Test RE 0.5013425147804338\n",
      "77 Train Loss 5.3112836 Test MSE 1171.2860874383234 Test RE 0.4735705173264957\n",
      "78 Train Loss 5.263018 Test MSE 1113.7668081461486 Test RE 0.46179614189086776\n",
      "79 Train Loss 5.239916 Test MSE 1072.8634242677983 Test RE 0.4532370294998417\n",
      "80 Train Loss 5.2056227 Test MSE 1071.5929342442498 Test RE 0.4529685872692857\n",
      "81 Train Loss 5.166921 Test MSE 1118.6332341723096 Test RE 0.46280391447602554\n",
      "82 Train Loss 5.150063 Test MSE 1147.3131808695612 Test RE 0.4686991394879437\n",
      "83 Train Loss 5.1243463 Test MSE 1156.7953739321013 Test RE 0.47063198174376947\n",
      "84 Train Loss 5.1099796 Test MSE 1165.969712561172 Test RE 0.4724945454457947\n",
      "85 Train Loss 5.088653 Test MSE 1173.6938120269153 Test RE 0.4740570090652907\n",
      "86 Train Loss 5.045359 Test MSE 1168.021889175162 Test RE 0.4729101720113433\n",
      "87 Train Loss 5.0303407 Test MSE 1177.6646607975197 Test RE 0.4748582483729962\n",
      "88 Train Loss 5.0247946 Test MSE 1179.6153391707833 Test RE 0.4752513621708536\n",
      "89 Train Loss 5.0247946 Test MSE 1179.6153391707833 Test RE 0.4752513621708536\n",
      "90 Train Loss 5.0247946 Test MSE 1179.6153391707833 Test RE 0.4752513621708536\n",
      "91 Train Loss 5.0247946 Test MSE 1179.6153391707833 Test RE 0.4752513621708536\n",
      "92 Train Loss 5.0247946 Test MSE 1179.6153391707833 Test RE 0.4752513621708536\n",
      "93 Train Loss 5.0247927 Test MSE 1179.6117467505426 Test RE 0.4752506385010876\n",
      "94 Train Loss 5.0220447 Test MSE 1183.8976102522665 Test RE 0.47611321578679744\n",
      "95 Train Loss 5.0131545 Test MSE 1168.2254218068967 Test RE 0.4729513734905431\n",
      "96 Train Loss 4.994759 Test MSE 1167.8680621725473 Test RE 0.47287903015079713\n",
      "97 Train Loss 4.98511 Test MSE 1159.625653027539 Test RE 0.4712073670437621\n",
      "98 Train Loss 4.97955 Test MSE 1147.8094442632876 Test RE 0.46880049502132165\n",
      "99 Train Loss 4.965694 Test MSE 1166.2088262485006 Test RE 0.47254299186767973\n",
      "Training time: 83.31\n",
      "Training time: 83.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 47.766144 Test MSE 5214.606641901972 Test RE 0.999226495821293\n",
      "1 Train Loss 47.745907 Test MSE 5164.315572373559 Test RE 0.994396417370753\n",
      "2 Train Loss 47.74453 Test MSE 5163.202441247924 Test RE 0.9942892440928955\n",
      "3 Train Loss 47.74294 Test MSE 5161.823922536074 Test RE 0.9941565030428698\n",
      "4 Train Loss 47.708233 Test MSE 5110.393135053475 Test RE 0.9891913732257975\n",
      "5 Train Loss 47.320423 Test MSE 4897.10292907293 Test RE 0.9683286483803129\n",
      "6 Train Loss 47.23811 Test MSE 4863.707037629692 Test RE 0.9650212316857648\n",
      "7 Train Loss 47.174114 Test MSE 4852.764852996868 Test RE 0.9639350862664552\n",
      "8 Train Loss 46.79134 Test MSE 4880.744343195415 Test RE 0.9667099629698632\n",
      "9 Train Loss 43.54945 Test MSE 4561.34220167356 Test RE 0.9345434377307932\n",
      "10 Train Loss 39.279427 Test MSE 4346.108111717546 Test RE 0.9122280609354816\n",
      "11 Train Loss 35.77416 Test MSE 3880.9465315394445 Test RE 0.8620292341794418\n",
      "12 Train Loss 32.755527 Test MSE 3233.6605926807206 Test RE 0.7868652781964582\n",
      "13 Train Loss 24.185955 Test MSE 2185.967257236699 Test RE 0.6469563664447758\n",
      "14 Train Loss 19.675493 Test MSE 1274.1670382275504 Test RE 0.4939310722903145\n",
      "15 Train Loss 16.103706 Test MSE 1386.4306301956121 Test RE 0.5152312984529891\n",
      "16 Train Loss 13.522422 Test MSE 1330.668700760073 Test RE 0.5047637237357939\n",
      "17 Train Loss 11.371726 Test MSE 1081.407115232098 Test RE 0.45503811541739214\n",
      "18 Train Loss 9.969234 Test MSE 1015.1917681513418 Test RE 0.4408869137636397\n",
      "19 Train Loss 8.817586 Test MSE 911.5953452406028 Test RE 0.417786318856904\n",
      "20 Train Loss 7.8554583 Test MSE 809.2373345316539 Test RE 0.3936326556035059\n",
      "21 Train Loss 7.5863357 Test MSE 822.8065498455109 Test RE 0.39691913366264864\n",
      "22 Train Loss 6.9065266 Test MSE 682.7064979158847 Test RE 0.3615515126759172\n",
      "23 Train Loss 6.726544 Test MSE 658.7331820642238 Test RE 0.3551468237612331\n",
      "24 Train Loss 5.954947 Test MSE 764.6400081599185 Test RE 0.382632339884736\n",
      "25 Train Loss 5.6459465 Test MSE 767.2477947375427 Test RE 0.38328426376645114\n",
      "26 Train Loss 5.250632 Test MSE 790.4496524595672 Test RE 0.3890364298513543\n",
      "27 Train Loss 4.999744 Test MSE 844.9627483273788 Test RE 0.40222767261253495\n",
      "28 Train Loss 4.659358 Test MSE 880.3727022985225 Test RE 0.41056927771421176\n",
      "29 Train Loss 4.550431 Test MSE 843.25644342963 Test RE 0.4018213411576797\n",
      "30 Train Loss 4.3247705 Test MSE 921.581732140674 Test RE 0.42006847816094967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 4.2203608 Test MSE 943.6258342650385 Test RE 0.425062777629739\n",
      "32 Train Loss 3.9123616 Test MSE 941.9428889812064 Test RE 0.42468356130610535\n",
      "33 Train Loss 3.8058822 Test MSE 951.3838568576373 Test RE 0.4268065283462094\n",
      "34 Train Loss 3.5542688 Test MSE 957.82163911338 Test RE 0.4282481414779589\n",
      "35 Train Loss 3.460531 Test MSE 942.4535353013871 Test RE 0.4247986604893219\n",
      "36 Train Loss 3.4342844 Test MSE 924.0854165276229 Test RE 0.4206386964684463\n",
      "37 Train Loss 3.3716125 Test MSE 949.8702474936487 Test RE 0.4264668781069979\n",
      "38 Train Loss 3.2638721 Test MSE 996.6261727209471 Test RE 0.4368368922136378\n",
      "39 Train Loss 3.130464 Test MSE 1003.636905393979 Test RE 0.4383706567144028\n",
      "40 Train Loss 3.0969405 Test MSE 994.4206834549477 Test RE 0.4363532742304543\n",
      "41 Train Loss 2.847115 Test MSE 945.6836188132204 Test RE 0.4255259968639573\n",
      "42 Train Loss 2.6457002 Test MSE 910.8196501808127 Test RE 0.417608529580618\n",
      "43 Train Loss 2.5557024 Test MSE 903.4366624700799 Test RE 0.41591254503717806\n",
      "44 Train Loss 2.4857206 Test MSE 939.1742478763504 Test RE 0.42405896842940405\n",
      "45 Train Loss 2.3705385 Test MSE 956.606474209583 Test RE 0.42797640128784764\n",
      "46 Train Loss 2.329474 Test MSE 957.6110297996894 Test RE 0.4282010565082621\n",
      "47 Train Loss 2.2628632 Test MSE 944.1395062203043 Test RE 0.42517845543019195\n",
      "48 Train Loss 2.1399007 Test MSE 949.2971670464942 Test RE 0.42633820963669783\n",
      "49 Train Loss 2.042632 Test MSE 966.0677723853014 Test RE 0.43008764007714906\n",
      "50 Train Loss 1.9482911 Test MSE 965.8059733691368 Test RE 0.4300293604442146\n",
      "51 Train Loss 1.8864412 Test MSE 1012.7306799380008 Test RE 0.44035217735374954\n",
      "52 Train Loss 1.8473012 Test MSE 1061.3131264023289 Test RE 0.45079068413304113\n",
      "53 Train Loss 1.8037149 Test MSE 1065.1521692760273 Test RE 0.4516052611573939\n",
      "54 Train Loss 1.7575375 Test MSE 1032.9803568780687 Test RE 0.444732836282617\n",
      "55 Train Loss 1.7234088 Test MSE 1030.7257360397139 Test RE 0.44424722605488554\n",
      "56 Train Loss 1.7069238 Test MSE 1027.176708914471 Test RE 0.44348174357455455\n",
      "57 Train Loss 1.6832002 Test MSE 1058.0344097324544 Test RE 0.4500938312584624\n",
      "58 Train Loss 1.6399626 Test MSE 1097.125044218236 Test RE 0.4583331071360404\n",
      "59 Train Loss 1.587696 Test MSE 1157.3424256820597 Test RE 0.4707432501771512\n",
      "60 Train Loss 1.5657319 Test MSE 1181.3625545351058 Test RE 0.47560319687601843\n",
      "61 Train Loss 1.5531396 Test MSE 1183.4557038215482 Test RE 0.4760243495169847\n",
      "62 Train Loss 1.5232185 Test MSE 1149.412088620375 Test RE 0.469127665351862\n",
      "63 Train Loss 1.4921072 Test MSE 1161.049151974208 Test RE 0.47149649374005387\n",
      "64 Train Loss 1.4743773 Test MSE 1182.2575373770383 Test RE 0.47578331775078814\n",
      "65 Train Loss 1.4583714 Test MSE 1184.2249411755245 Test RE 0.476179030518703\n",
      "66 Train Loss 1.4436038 Test MSE 1188.1234356944424 Test RE 0.47696218242405597\n",
      "67 Train Loss 1.434742 Test MSE 1211.2911713877565 Test RE 0.48158997802513837\n",
      "68 Train Loss 1.4226283 Test MSE 1221.1349835476774 Test RE 0.4835428894293688\n",
      "69 Train Loss 1.41131 Test MSE 1222.890261411267 Test RE 0.4838902905594944\n",
      "70 Train Loss 1.3912483 Test MSE 1197.666685501535 Test RE 0.4788738800889624\n",
      "71 Train Loss 1.3501877 Test MSE 1150.5825060778063 Test RE 0.46936645503768215\n",
      "72 Train Loss 1.335002 Test MSE 1135.9498877345359 Test RE 0.4663723036425063\n",
      "73 Train Loss 1.326408 Test MSE 1146.4714787645114 Test RE 0.46852718232726986\n",
      "74 Train Loss 1.3221217 Test MSE 1139.9030293957921 Test RE 0.4671830940700625\n",
      "75 Train Loss 1.3109379 Test MSE 1155.6302715927945 Test RE 0.47039491623814067\n",
      "76 Train Loss 1.295827 Test MSE 1182.042792553101 Test RE 0.475740105235065\n",
      "77 Train Loss 1.2841445 Test MSE 1170.2374841754652 Test RE 0.47335848595846647\n",
      "78 Train Loss 1.2568135 Test MSE 1176.2922606830452 Test RE 0.4745814779512586\n",
      "79 Train Loss 1.234876 Test MSE 1148.659844941357 Test RE 0.4689741276943388\n",
      "80 Train Loss 1.2224369 Test MSE 1116.5013332872882 Test RE 0.46236269630651816\n",
      "81 Train Loss 1.217231 Test MSE 1101.8984407581138 Test RE 0.459329088019606\n",
      "82 Train Loss 1.2077935 Test MSE 1109.8561583118708 Test RE 0.46098470137316255\n",
      "83 Train Loss 1.2023039 Test MSE 1100.763372644166 Test RE 0.45909244908919944\n",
      "84 Train Loss 1.1944087 Test MSE 1080.1050215778876 Test RE 0.45476408323484024\n",
      "85 Train Loss 1.1898366 Test MSE 1081.6546657100464 Test RE 0.4550901949975871\n",
      "86 Train Loss 1.1783509 Test MSE 1074.6068313861883 Test RE 0.4536051359597239\n",
      "87 Train Loss 1.169895 Test MSE 1090.014287585181 Test RE 0.45684540382212707\n",
      "88 Train Loss 1.1665369 Test MSE 1073.5857163103428 Test RE 0.45338957194446344\n",
      "89 Train Loss 1.1636565 Test MSE 1071.2307139927452 Test RE 0.4528920244916549\n",
      "90 Train Loss 1.1610087 Test MSE 1067.6527669968461 Test RE 0.4521350545088068\n",
      "91 Train Loss 1.1530678 Test MSE 1050.2756686154264 Test RE 0.44844048841138623\n",
      "92 Train Loss 1.1467475 Test MSE 1044.4173825943035 Test RE 0.4471880713737879\n",
      "93 Train Loss 1.1444056 Test MSE 1037.9975778267872 Test RE 0.44581156931221366\n",
      "94 Train Loss 1.1387985 Test MSE 1043.0814870861007 Test RE 0.4469019847488944\n",
      "95 Train Loss 1.1333932 Test MSE 1034.9694187094383 Test RE 0.44516080941690944\n",
      "96 Train Loss 1.1302797 Test MSE 1026.7228196254166 Test RE 0.443383749795503\n",
      "97 Train Loss 1.1271974 Test MSE 1016.4750629371546 Test RE 0.4411654863478498\n",
      "98 Train Loss 1.1199331 Test MSE 1023.3806967365898 Test RE 0.4426615242749715\n",
      "99 Train Loss 1.1141477 Test MSE 1021.7879758146229 Test RE 0.44231692582556326\n",
      "Training time: 74.38\n",
      "Training time: 74.38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 47.770096 Test MSE 5223.857510655304 Test RE 1.0001124319789412\n",
      "1 Train Loss 47.767952 Test MSE 5214.508051863682 Test RE 0.999217049831318\n",
      "2 Train Loss 47.747444 Test MSE 5172.041674317263 Test RE 0.995139975414053\n",
      "3 Train Loss 47.7421 Test MSE 5152.622583819056 Test RE 0.9932700285083916\n",
      "4 Train Loss 47.72097 Test MSE 5104.857466170046 Test RE 0.9886554732036065\n",
      "5 Train Loss 47.67034 Test MSE 5034.324018851814 Test RE 0.9818016254022176\n",
      "6 Train Loss 47.601357 Test MSE 4887.51474870566 Test RE 0.9673802244930241\n",
      "7 Train Loss 47.563557 Test MSE 4810.637724669077 Test RE 0.9597419785615725\n",
      "8 Train Loss 47.46309 Test MSE 4725.163776338941 Test RE 0.9511775637581157\n",
      "9 Train Loss 47.235973 Test MSE 4942.238641274324 Test RE 0.9727808681136769\n",
      "10 Train Loss 46.92695 Test MSE 4819.7992854593385 Test RE 0.9606554283638554\n",
      "11 Train Loss 46.466965 Test MSE 5005.700607568893 Test RE 0.9790065559102225\n",
      "12 Train Loss 46.23423 Test MSE 5111.081628082234 Test RE 0.9892580049319711\n",
      "13 Train Loss 45.51182 Test MSE 4919.009915651594 Test RE 0.9704921205266492\n",
      "14 Train Loss 43.763275 Test MSE 5062.696868282992 Test RE 0.9845643966111015\n",
      "15 Train Loss 41.19223 Test MSE 4385.074567630672 Test RE 0.9163083752431302\n",
      "16 Train Loss 39.679283 Test MSE 4270.027347178759 Test RE 0.904208307637338\n",
      "17 Train Loss 38.786106 Test MSE 4490.6279693826045 Test RE 0.9272710545510624\n",
      "18 Train Loss 38.347034 Test MSE 4396.097035140537 Test RE 0.9174592838757998\n",
      "19 Train Loss 37.93355 Test MSE 4381.498829468732 Test RE 0.9159347046264382\n",
      "20 Train Loss 36.918118 Test MSE 4356.030353424677 Test RE 0.9132687836777978\n",
      "21 Train Loss 30.114895 Test MSE 3960.487140176487 Test RE 0.8708181423335224\n",
      "22 Train Loss 18.441965 Test MSE 2216.9490227397146 Test RE 0.6515248998369416\n",
      "23 Train Loss 16.043829 Test MSE 1812.2697121399556 Test RE 0.5890668466312996\n",
      "24 Train Loss 15.150324 Test MSE 1450.4076003649664 Test RE 0.5269849325306742\n",
      "25 Train Loss 14.3706 Test MSE 1478.3443641477677 Test RE 0.5320359387784566\n",
      "26 Train Loss 13.36303 Test MSE 1343.9126511581176 Test RE 0.5072694241074628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 12.651995 Test MSE 1403.3820606191757 Test RE 0.5183715106767043\n",
      "28 Train Loss 12.283594 Test MSE 1412.9019264388487 Test RE 0.5201267299997813\n",
      "29 Train Loss 11.721323 Test MSE 1615.9062010651066 Test RE 0.5562387474951324\n",
      "30 Train Loss 10.372732 Test MSE 1338.7135783823883 Test RE 0.5062872597172668\n",
      "31 Train Loss 9.627602 Test MSE 1290.699199825375 Test RE 0.49712509282253575\n",
      "32 Train Loss 9.177069 Test MSE 1304.3480186577026 Test RE 0.49974666672804563\n",
      "33 Train Loss 8.640385 Test MSE 1239.2120462809876 Test RE 0.487108802719586\n",
      "34 Train Loss 8.434471 Test MSE 1268.7789410628113 Test RE 0.49288561748723503\n",
      "35 Train Loss 8.204075 Test MSE 1292.6795043280113 Test RE 0.49750631322549926\n",
      "36 Train Loss 8.040787 Test MSE 1283.6103765233652 Test RE 0.4957580492934133\n",
      "37 Train Loss 7.9524207 Test MSE 1301.761537430617 Test RE 0.49925092986239317\n",
      "38 Train Loss 7.430832 Test MSE 1277.0813707716725 Test RE 0.49449562041655526\n",
      "39 Train Loss 7.296971 Test MSE 1352.8088265626457 Test RE 0.50894561720471\n",
      "40 Train Loss 7.124827 Test MSE 1405.1159980752584 Test RE 0.5186916467043393\n",
      "41 Train Loss 7.0964017 Test MSE 1456.0102219851478 Test RE 0.5280017678841842\n",
      "42 Train Loss 7.056815 Test MSE 1463.9882595930942 Test RE 0.5294463536741736\n",
      "43 Train Loss 7.0089855 Test MSE 1414.1943347325919 Test RE 0.5203645605367503\n",
      "44 Train Loss 6.7929673 Test MSE 1472.9765088635736 Test RE 0.5310691514921192\n",
      "45 Train Loss 6.6984544 Test MSE 1491.4362032695265 Test RE 0.5343865331999639\n",
      "46 Train Loss 6.5663505 Test MSE 1428.240742544061 Test RE 0.5229424214926963\n",
      "47 Train Loss 6.538425 Test MSE 1395.3441954742154 Test RE 0.5168848935935176\n",
      "48 Train Loss 6.532776 Test MSE 1387.2135513188962 Test RE 0.5153767541743247\n",
      "49 Train Loss 6.5154624 Test MSE 1433.1711295832233 Test RE 0.5238442607861017\n",
      "50 Train Loss 6.4581923 Test MSE 1455.8258573133407 Test RE 0.5279683381894937\n",
      "51 Train Loss 6.418336 Test MSE 1433.3120260837854 Test RE 0.523870009982314\n",
      "52 Train Loss 6.4033785 Test MSE 1440.7743912329051 Test RE 0.5252319723816137\n",
      "53 Train Loss 6.3851056 Test MSE 1416.9588877862545 Test RE 0.5208729323468351\n",
      "54 Train Loss 6.356218 Test MSE 1417.0064048256104 Test RE 0.5208816658860876\n",
      "55 Train Loss 6.2877846 Test MSE 1451.1911146930436 Test RE 0.5271272526956398\n",
      "56 Train Loss 6.196448 Test MSE 1521.5349903553583 Test RE 0.5397518465323948\n",
      "57 Train Loss 6.01853 Test MSE 1555.2560613137298 Test RE 0.5457002038008886\n",
      "58 Train Loss 5.9327364 Test MSE 1576.9024474493917 Test RE 0.5494846670738756\n",
      "59 Train Loss 5.895239 Test MSE 1625.1285764184277 Test RE 0.5578237850441096\n",
      "60 Train Loss 5.8812923 Test MSE 1624.2388728146068 Test RE 0.5576710691961841\n",
      "61 Train Loss 5.865157 Test MSE 1632.3209776867939 Test RE 0.5590568146120066\n",
      "62 Train Loss 5.8483734 Test MSE 1675.8055667630845 Test RE 0.5664544319206918\n",
      "63 Train Loss 5.7984443 Test MSE 1710.6124748383586 Test RE 0.572306900138046\n",
      "64 Train Loss 5.7169476 Test MSE 1698.5557841076813 Test RE 0.5702864750689244\n",
      "65 Train Loss 5.6295786 Test MSE 1721.2920290524937 Test RE 0.5740906100265442\n",
      "66 Train Loss 5.5916758 Test MSE 1756.6428610543385 Test RE 0.5799558082120566\n",
      "67 Train Loss 5.5700564 Test MSE 1786.2453676769258 Test RE 0.5848220279749333\n",
      "68 Train Loss 5.518303 Test MSE 1835.7931120872772 Test RE 0.5928775870137583\n",
      "69 Train Loss 5.47193 Test MSE 1873.820699532622 Test RE 0.5989867019438879\n",
      "70 Train Loss 5.440043 Test MSE 1875.1251946150571 Test RE 0.5991951635278658\n",
      "71 Train Loss 5.4097757 Test MSE 1900.2444795861177 Test RE 0.6031952382258425\n",
      "72 Train Loss 5.376345 Test MSE 1939.8319820455254 Test RE 0.6094459878564202\n",
      "73 Train Loss 5.3047295 Test MSE 2001.6619495791213 Test RE 0.6190825053538095\n",
      "74 Train Loss 5.2521477 Test MSE 2049.498184998606 Test RE 0.6264363258684896\n",
      "75 Train Loss 5.214351 Test MSE 2140.067242386202 Test RE 0.6401280739640439\n",
      "76 Train Loss 5.209658 Test MSE 2162.6840125022522 Test RE 0.6435017014826049\n",
      "77 Train Loss 5.2039113 Test MSE 2149.9376630338234 Test RE 0.6416025754726263\n",
      "78 Train Loss 5.1915793 Test MSE 2167.512843619246 Test RE 0.644219704767018\n",
      "79 Train Loss 5.189127 Test MSE 2191.310855770721 Test RE 0.6477466264435365\n",
      "80 Train Loss 5.1670847 Test MSE 2176.2930336720374 Test RE 0.6455231929577897\n",
      "81 Train Loss 5.128051 Test MSE 2043.0472930987667 Test RE 0.6254496799834134\n",
      "82 Train Loss 5.0944667 Test MSE 1984.116045681205 Test RE 0.6163631972771325\n",
      "83 Train Loss 5.0209517 Test MSE 1809.1917418720057 Test RE 0.588566396632046\n",
      "84 Train Loss 4.985995 Test MSE 1676.0881965568942 Test RE 0.5665021970531245\n",
      "85 Train Loss 4.942294 Test MSE 1568.0915925537438 Test RE 0.5479474091917109\n",
      "86 Train Loss 4.921808 Test MSE 1544.2155170873389 Test RE 0.5437598295255549\n",
      "87 Train Loss 4.9010277 Test MSE 1564.303348722758 Test RE 0.547285134873911\n",
      "88 Train Loss 4.8362837 Test MSE 1419.3876465261235 Test RE 0.5213191460856182\n",
      "89 Train Loss 4.6862082 Test MSE 1363.1354926799957 Test RE 0.510884442406502\n",
      "90 Train Loss 4.503036 Test MSE 1189.0753780922837 Test RE 0.477153218809825\n",
      "91 Train Loss 4.3881135 Test MSE 1135.6755311845798 Test RE 0.4663159807252937\n",
      "92 Train Loss 4.280701 Test MSE 1054.0859299902281 Test RE 0.4492531934065613\n",
      "93 Train Loss 4.181859 Test MSE 1030.1669312079568 Test RE 0.4441267860854963\n",
      "94 Train Loss 3.934932 Test MSE 1252.5433750441748 Test RE 0.48972192933602576\n",
      "95 Train Loss 3.8248153 Test MSE 1316.4901476261105 Test RE 0.5020673403786514\n",
      "96 Train Loss 3.8120725 Test MSE 1303.1527883463955 Test RE 0.49951764454454917\n",
      "97 Train Loss 3.7741823 Test MSE 1262.6212288178647 Test RE 0.491688112100394\n",
      "98 Train Loss 3.7520194 Test MSE 1291.6652356762615 Test RE 0.4973110969804253\n",
      "99 Train Loss 3.6944692 Test MSE 1532.70635951215 Test RE 0.541729697755037\n",
      "Training time: 70.22\n",
      "Training time: 70.22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 47.768238 Test MSE 5220.0045811306 Test RE 0.9997435404560636\n",
      "1 Train Loss 47.76683 Test MSE 5215.485107216673 Test RE 0.9993106583394861\n",
      "2 Train Loss 47.749943 Test MSE 5174.956820242627 Test RE 0.9954203839808021\n",
      "3 Train Loss 47.748604 Test MSE 5177.407936872666 Test RE 0.9956560963448615\n",
      "4 Train Loss 47.726677 Test MSE 5129.951429002209 Test RE 0.9910824625762618\n",
      "5 Train Loss 47.689312 Test MSE 5052.146933828339 Test RE 0.9835380161000731\n",
      "6 Train Loss 47.611176 Test MSE 4977.759345948416 Test RE 0.9762703796928455\n",
      "7 Train Loss 47.42509 Test MSE 4759.141742506148 Test RE 0.9545913276104164\n",
      "8 Train Loss 47.19505 Test MSE 4656.25354308514 Test RE 0.9442162599440046\n",
      "9 Train Loss 47.147163 Test MSE 4614.400936822851 Test RE 0.9399631502548936\n",
      "10 Train Loss 47.11147 Test MSE 4594.9320684103595 Test RE 0.9379781295974399\n",
      "11 Train Loss 47.072968 Test MSE 4565.8603625553515 Test RE 0.9350061713213\n",
      "12 Train Loss 47.001945 Test MSE 4543.726011325697 Test RE 0.9327370592017726\n",
      "13 Train Loss 46.83106 Test MSE 4539.636071750976 Test RE 0.9323171728518984\n",
      "14 Train Loss 46.53701 Test MSE 4519.407874616005 Test RE 0.9302376943652642\n",
      "15 Train Loss 46.012806 Test MSE 4484.844733944661 Test RE 0.926673771216601\n",
      "16 Train Loss 45.196274 Test MSE 4400.269145255301 Test RE 0.9178945373950093\n",
      "17 Train Loss 44.260212 Test MSE 4296.4967134037215 Test RE 0.9070065150867075\n",
      "18 Train Loss 43.510643 Test MSE 4228.163261924577 Test RE 0.8997648826132079\n",
      "19 Train Loss 42.34856 Test MSE 4163.408006231978 Test RE 0.8928482488795131\n",
      "20 Train Loss 40.844093 Test MSE 4189.237519697283 Test RE 0.8956135529072606\n",
      "21 Train Loss 40.668472 Test MSE 4275.351390975167 Test RE 0.9047718338852689\n",
      "22 Train Loss 40.644276 Test MSE 4305.959146571882 Test RE 0.9080047432791137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Train Loss 40.584545 Test MSE 4219.042585568859 Test RE 0.8987939060740114\n",
      "24 Train Loss 40.4001 Test MSE 4155.4971196750685 Test RE 0.891999595613393\n",
      "25 Train Loss 39.39905 Test MSE 3884.601545567106 Test RE 0.8624350613971105\n",
      "26 Train Loss 34.6337 Test MSE 6113.0384817808035 Test RE 1.0818865695395414\n",
      "27 Train Loss 31.447853 Test MSE 6691.494507537935 Test RE 1.1319173780547012\n",
      "28 Train Loss 30.61373 Test MSE 7053.319629809399 Test RE 1.1621172483689322\n",
      "29 Train Loss 29.949873 Test MSE 7076.657753161195 Test RE 1.1640382755619167\n",
      "30 Train Loss 28.876999 Test MSE 6487.517385169393 Test RE 1.114531717014748\n",
      "31 Train Loss 28.861336 Test MSE 6447.974075150447 Test RE 1.1111298273250578\n",
      "32 Train Loss 28.861336 Test MSE 6447.974075150447 Test RE 1.1111298273250578\n",
      "33 Train Loss 28.861336 Test MSE 6447.974075150447 Test RE 1.1111298273250578\n",
      "34 Train Loss 28.861336 Test MSE 6447.974075150447 Test RE 1.1111298273250578\n",
      "35 Train Loss 28.861336 Test MSE 6447.974075150447 Test RE 1.1111298273250578\n",
      "36 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "37 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "38 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "39 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "40 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "41 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "42 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "43 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "44 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "45 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "46 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "47 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "48 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "49 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "50 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "51 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "52 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "53 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "54 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "55 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "56 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "57 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "58 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "59 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "60 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "61 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "62 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "63 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "64 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "65 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "66 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "67 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "68 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "69 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "70 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "71 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "72 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "73 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "74 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "75 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "76 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "77 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "78 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "79 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "80 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "81 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "82 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "83 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "84 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "85 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "86 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "87 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "88 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "89 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "90 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "91 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "92 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "93 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "94 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "95 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "96 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "97 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "98 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "99 Train Loss 28.861221 Test MSE 6447.9030267502 Test RE 1.111123705695749\n",
      "Training time: 30.99\n",
      "Training time: 30.99\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 47.76833 Test MSE 5220.246779464616 Test RE 0.9997667332912018\n",
      "1 Train Loss 47.76683 Test MSE 5215.403358712495 Test RE 0.9993028266162653\n",
      "2 Train Loss 47.74634 Test MSE 5169.998287146971 Test RE 0.9949433744127183\n",
      "3 Train Loss 47.745472 Test MSE 5172.130720942068 Test RE 0.9951485419995706\n",
      "4 Train Loss 47.73545 Test MSE 5162.088103227977 Test RE 0.994181943042029\n",
      "5 Train Loss 47.320904 Test MSE 4937.630695207722 Test RE 0.9723272713310455\n",
      "6 Train Loss 45.09703 Test MSE 5032.301825908832 Test RE 0.981604420005369\n",
      "7 Train Loss 39.49209 Test MSE 3591.2789506052623 Test RE 0.8292352107240546\n",
      "8 Train Loss 37.12409 Test MSE 3384.402134727949 Test RE 0.8049967830551102\n",
      "9 Train Loss 34.81187 Test MSE 2953.7969472592463 Test RE 0.752044402850827\n",
      "10 Train Loss 34.250458 Test MSE 2713.4698363884495 Test RE 0.7208014701928259\n",
      "11 Train Loss 30.888367 Test MSE 2432.6465318995424 Test RE 0.6824843067592082\n",
      "12 Train Loss 25.50415 Test MSE 1805.3650509191475 Test RE 0.5879436174441085\n",
      "13 Train Loss 22.681288 Test MSE 1489.208111729003 Test RE 0.5339872177168826\n",
      "14 Train Loss 19.136766 Test MSE 1012.282215347087 Test RE 0.44025466661843515\n",
      "15 Train Loss 18.868792 Test MSE 930.339672449641 Test RE 0.42205974786452577\n",
      "16 Train Loss 18.777885 Test MSE 964.000541811404 Test RE 0.42962723425376964\n",
      "17 Train Loss 18.472532 Test MSE 1017.0572626959625 Test RE 0.4412918099939361\n",
      "18 Train Loss 16.54806 Test MSE 840.7784046437664 Test RE 0.4012304998551407\n",
      "19 Train Loss 15.491176 Test MSE 663.8790283563154 Test RE 0.3565312809613511\n",
      "20 Train Loss 15.242416 Test MSE 634.524871857559 Test RE 0.34855995408053836\n",
      "21 Train Loss 14.99356 Test MSE 640.6911151833444 Test RE 0.3502494930769082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 14.7611475 Test MSE 667.141329793163 Test RE 0.3574062047628966\n",
      "23 Train Loss 14.596642 Test MSE 701.4024116835386 Test RE 0.3664686194215364\n",
      "24 Train Loss 14.509479 Test MSE 725.1385152211334 Test RE 0.3726178461704093\n",
      "25 Train Loss 14.422575 Test MSE 731.7709642630928 Test RE 0.3743180341027539\n",
      "26 Train Loss 14.298174 Test MSE 709.8174051820397 Test RE 0.3686603973475154\n",
      "27 Train Loss 14.239183 Test MSE 700.1225556290096 Test RE 0.36613411726657735\n",
      "28 Train Loss 14.201435 Test MSE 696.742816103989 Test RE 0.36524931864032645\n",
      "29 Train Loss 14.039855 Test MSE 710.8911422958205 Test RE 0.3689391273161776\n",
      "30 Train Loss 13.901506 Test MSE 706.6179558651322 Test RE 0.3678286042761143\n",
      "31 Train Loss 13.748828 Test MSE 674.1893897626363 Test RE 0.3592891657451451\n",
      "32 Train Loss 13.592473 Test MSE 576.4853891341601 Test RE 0.3322364801455933\n",
      "33 Train Loss 12.328708 Test MSE 428.3758358548294 Test RE 0.28639514210267164\n",
      "34 Train Loss 10.39299 Test MSE 686.8481488011264 Test RE 0.3626465337269537\n",
      "35 Train Loss 9.837425 Test MSE 618.5959651009312 Test RE 0.34415707829477515\n",
      "36 Train Loss 9.27075 Test MSE 606.021048180561 Test RE 0.34064107825558376\n",
      "37 Train Loss 9.166477 Test MSE 594.6351258407539 Test RE 0.33742592309064795\n",
      "38 Train Loss 9.09017 Test MSE 565.6837990569994 Test RE 0.3291092093165113\n",
      "39 Train Loss 9.065787 Test MSE 576.7103471595872 Test RE 0.3323012970291857\n",
      "40 Train Loss 9.037477 Test MSE 563.2578280014327 Test RE 0.3284027481582301\n",
      "41 Train Loss 8.885834 Test MSE 600.4247909144514 Test RE 0.339064617763675\n",
      "42 Train Loss 8.504222 Test MSE 661.1019466577437 Test RE 0.35578479397583473\n",
      "43 Train Loss 8.45256 Test MSE 752.5031328136897 Test RE 0.3795834955323516\n",
      "44 Train Loss 8.365433 Test MSE 716.0819846270314 Test RE 0.370283652141999\n",
      "45 Train Loss 8.242164 Test MSE 710.3483183763793 Test RE 0.36879824271635997\n",
      "46 Train Loss 8.150846 Test MSE 736.0186537629139 Test RE 0.3754028585872049\n",
      "47 Train Loss 8.096612 Test MSE 768.6786535160198 Test RE 0.38364149529082714\n",
      "48 Train Loss 8.0462265 Test MSE 783.6542205910208 Test RE 0.38736056285840886\n",
      "49 Train Loss 7.9759254 Test MSE 786.7782635789105 Test RE 0.38813190267094916\n",
      "50 Train Loss 7.9048862 Test MSE 808.5136190218677 Test RE 0.3934565998487541\n",
      "51 Train Loss 7.8546247 Test MSE 821.7922722332735 Test RE 0.3966744161557008\n",
      "52 Train Loss 7.7316885 Test MSE 794.5933184077301 Test RE 0.3900547931848599\n",
      "53 Train Loss 7.6278863 Test MSE 696.1619627605645 Test RE 0.3650970382590174\n",
      "54 Train Loss 7.5740876 Test MSE 665.6220827688117 Test RE 0.35699902132873423\n",
      "55 Train Loss 7.556916 Test MSE 627.5162268040675 Test RE 0.3466295991991161\n",
      "56 Train Loss 7.5137463 Test MSE 579.9959862762704 Test RE 0.33324654751317423\n",
      "57 Train Loss 7.415029 Test MSE 462.9957026541941 Test RE 0.2977430581370461\n",
      "58 Train Loss 7.2461743 Test MSE 439.86911177843467 Test RE 0.29021168704399625\n",
      "59 Train Loss 7.2098827 Test MSE 460.11533789733693 Test RE 0.29681546140233184\n",
      "60 Train Loss 6.9019837 Test MSE 405.85363799639225 Test RE 0.2787647694190289\n",
      "61 Train Loss 6.8087673 Test MSE 444.32625290441075 Test RE 0.29167832126687837\n",
      "62 Train Loss 6.7670245 Test MSE 429.8033582138103 Test RE 0.2868719377100768\n",
      "63 Train Loss 6.755929 Test MSE 423.9633443308238 Test RE 0.28491631541425844\n",
      "64 Train Loss 6.5661616 Test MSE 503.16665853317875 Test RE 0.3103909802643516\n",
      "65 Train Loss 6.28125 Test MSE 466.0675544110604 Test RE 0.29872914772099257\n",
      "66 Train Loss 5.9888744 Test MSE 464.5062459870402 Test RE 0.2982283623749981\n",
      "67 Train Loss 5.9620404 Test MSE 451.60909705870887 Test RE 0.2940590199647011\n",
      "68 Train Loss 5.9013476 Test MSE 461.2456622181229 Test RE 0.29717981780718367\n",
      "69 Train Loss 5.8751717 Test MSE 457.26998327141666 Test RE 0.2958962842994876\n",
      "70 Train Loss 5.7046647 Test MSE 449.19653254763057 Test RE 0.2932725141360254\n",
      "71 Train Loss 5.623982 Test MSE 438.162839279819 Test RE 0.2896482678956049\n",
      "72 Train Loss 5.554071 Test MSE 501.9094822275866 Test RE 0.31000297737724775\n",
      "73 Train Loss 5.5362225 Test MSE 500.25792765308944 Test RE 0.3094925180946932\n",
      "74 Train Loss 5.535263 Test MSE 501.40285664938176 Test RE 0.30984647994491027\n",
      "75 Train Loss 5.535263 Test MSE 501.40285664938176 Test RE 0.30984647994491027\n",
      "76 Train Loss 5.5348554 Test MSE 502.0096758265888 Test RE 0.31003391798024166\n",
      "77 Train Loss 5.5346956 Test MSE 501.996940704168 Test RE 0.31002998544155663\n",
      "78 Train Loss 5.5335245 Test MSE 503.4193998021297 Test RE 0.31046892537474025\n",
      "79 Train Loss 5.533327 Test MSE 504.0629011315937 Test RE 0.3106672921461212\n",
      "80 Train Loss 5.533327 Test MSE 504.0629011315937 Test RE 0.3106672921461212\n",
      "81 Train Loss 5.533327 Test MSE 504.0629011315937 Test RE 0.3106672921461212\n",
      "82 Train Loss 5.533327 Test MSE 504.0629011315937 Test RE 0.3106672921461212\n",
      "83 Train Loss 5.5332303 Test MSE 504.17970921259 Test RE 0.31070328601521646\n",
      "84 Train Loss 5.530014 Test MSE 506.9912611083923 Test RE 0.3115683981308368\n",
      "85 Train Loss 5.530014 Test MSE 506.9912611083923 Test RE 0.3115683981308368\n",
      "86 Train Loss 5.529721 Test MSE 506.9285569598005 Test RE 0.31154913030835485\n",
      "87 Train Loss 5.529721 Test MSE 506.9285569598005 Test RE 0.31154913030835485\n",
      "88 Train Loss 5.529721 Test MSE 506.9285569598005 Test RE 0.31154913030835485\n",
      "89 Train Loss 5.529721 Test MSE 506.928857434222 Test RE 0.3115492226414159\n",
      "90 Train Loss 5.519842 Test MSE 504.06004951811303 Test RE 0.31066641338248946\n",
      "91 Train Loss 5.465199 Test MSE 512.2454721637829 Test RE 0.3131787085011676\n",
      "92 Train Loss 5.3678975 Test MSE 569.9619047814609 Test RE 0.3303513449455815\n",
      "93 Train Loss 5.34777 Test MSE 603.480193408691 Test RE 0.33992622797846533\n",
      "94 Train Loss 5.327325 Test MSE 585.0977682826859 Test RE 0.3347089963061706\n",
      "95 Train Loss 5.296159 Test MSE 585.0514135330807 Test RE 0.33469573727505564\n",
      "96 Train Loss 5.2567267 Test MSE 604.3251398377845 Test RE 0.34016411398558627\n",
      "97 Train Loss 5.142667 Test MSE 633.1165328707203 Test RE 0.3481729217654089\n",
      "98 Train Loss 4.979185 Test MSE 653.9318635761229 Test RE 0.35385017470601965\n",
      "99 Train Loss 4.886111 Test MSE 775.2444808495654 Test RE 0.38527648780596074\n",
      "Training time: 62.08\n",
      "Training time: 62.08\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 47.76986 Test MSE 5223.414372220588 Test RE 1.0000700114443049\n",
      "1 Train Loss 47.749126 Test MSE 5172.878094242078 Test RE 0.9952204389240698\n",
      "2 Train Loss 47.74749 Test MSE 5173.7957546073485 Test RE 0.9953087102727373\n",
      "3 Train Loss 47.73213 Test MSE 5139.70777402239 Test RE 0.9920244548703359\n",
      "4 Train Loss 47.716015 Test MSE 5102.915274790106 Test RE 0.9884673836417674\n",
      "5 Train Loss 47.53399 Test MSE 4933.081081836458 Test RE 0.9718792089993209\n",
      "6 Train Loss 47.374886 Test MSE 4816.201787099489 Test RE 0.960296844816548\n",
      "7 Train Loss 47.25087 Test MSE 4739.830773552604 Test RE 0.9526526564880398\n",
      "8 Train Loss 47.08384 Test MSE 4661.3479504694715 Test RE 0.9447326522802131\n",
      "9 Train Loss 46.953 Test MSE 4605.147642990859 Test RE 0.9390202196192485\n",
      "10 Train Loss 46.585182 Test MSE 4560.609716291024 Test RE 0.9344683976591216\n",
      "11 Train Loss 44.498814 Test MSE 4478.251681154761 Test RE 0.9259923812799068\n",
      "12 Train Loss 42.410885 Test MSE 4417.653240630643 Test RE 0.9197059080925345\n",
      "13 Train Loss 40.864193 Test MSE 4602.477086325784 Test RE 0.9387479080056905\n",
      "14 Train Loss 40.196873 Test MSE 5017.173723435953 Test RE 0.9801278601776293\n",
      "15 Train Loss 39.26086 Test MSE 5671.690841494181 Test RE 1.0421001048625076\n",
      "16 Train Loss 37.772537 Test MSE 5410.147165676652 Test RE 1.017788885834932\n",
      "17 Train Loss 27.362692 Test MSE 4585.438384365037 Test RE 0.9370086405754106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 21.516733 Test MSE 3129.5044605613984 Test RE 0.774089099926537\n",
      "19 Train Loss 16.961082 Test MSE 2353.4379496933516 Test RE 0.6712812871328134\n",
      "20 Train Loss 15.843013 Test MSE 2302.249051797064 Test RE 0.6639407367921096\n",
      "21 Train Loss 11.058365 Test MSE 4331.444434056744 Test RE 0.9106878414935515\n",
      "22 Train Loss 9.914853 Test MSE 3653.8372442788987 Test RE 0.8364264614579675\n",
      "23 Train Loss 9.041231 Test MSE 2820.6979513505757 Test RE 0.734905429947902\n",
      "24 Train Loss 8.596731 Test MSE 2603.966374675685 Test RE 0.7061075425495218\n",
      "25 Train Loss 7.864435 Test MSE 2434.534989853701 Test RE 0.6827491608731079\n",
      "26 Train Loss 7.239247 Test MSE 2477.668773245923 Test RE 0.6887708969767734\n",
      "27 Train Loss 6.6401267 Test MSE 2679.3568331633173 Test RE 0.7162562799735449\n",
      "28 Train Loss 5.8083444 Test MSE 2312.191010570947 Test RE 0.6653727626899433\n",
      "29 Train Loss 5.3759565 Test MSE 2141.1304281421503 Test RE 0.6402870620860721\n",
      "30 Train Loss 5.0812125 Test MSE 1878.4043612184084 Test RE 0.5997188625591761\n",
      "31 Train Loss 5.0020895 Test MSE 1722.1152129977863 Test RE 0.5742278690382014\n",
      "32 Train Loss 4.9733653 Test MSE 1749.4784788357363 Test RE 0.5787719391541462\n",
      "33 Train Loss 4.857356 Test MSE 1855.6717819733612 Test RE 0.5960788967206714\n",
      "34 Train Loss 4.7304616 Test MSE 1704.7417609909373 Test RE 0.5713239955501989\n",
      "35 Train Loss 4.5154047 Test MSE 1437.2904164633776 Test RE 0.5245965493341307\n",
      "36 Train Loss 4.3508835 Test MSE 1193.0679371996807 Test RE 0.47795361632299477\n",
      "37 Train Loss 4.3264 Test MSE 1090.8418381186589 Test RE 0.45701879188312594\n",
      "38 Train Loss 4.189759 Test MSE 909.9954900819488 Test RE 0.41741954914983403\n",
      "39 Train Loss 4.118834 Test MSE 949.2392884415127 Test RE 0.42632521252798755\n",
      "40 Train Loss 4.0813346 Test MSE 991.4696397466605 Test RE 0.43570533198164185\n",
      "41 Train Loss 4.0190344 Test MSE 972.2263118565386 Test RE 0.4314563348510622\n",
      "42 Train Loss 3.9254112 Test MSE 1029.9089933770067 Test RE 0.4440711813732271\n",
      "43 Train Loss 3.8801131 Test MSE 1068.430746525544 Test RE 0.4522997558855104\n",
      "44 Train Loss 3.866562 Test MSE 1097.3369774603902 Test RE 0.45837737343520574\n",
      "45 Train Loss 3.8162036 Test MSE 1139.5372417398808 Test RE 0.46710813000907736\n",
      "46 Train Loss 3.778903 Test MSE 1083.7725328651534 Test RE 0.4555355077582591\n",
      "47 Train Loss 3.7707937 Test MSE 1103.427061461186 Test RE 0.45964758225801794\n",
      "48 Train Loss 3.7551255 Test MSE 1101.5404882562234 Test RE 0.4592544752671232\n",
      "49 Train Loss 3.7246704 Test MSE 1028.5177758325558 Test RE 0.44377115078949625\n",
      "50 Train Loss 3.682619 Test MSE 952.6821116304837 Test RE 0.4270976383463758\n",
      "51 Train Loss 3.0648017 Test MSE 1140.6466047873205 Test RE 0.467335444406181\n",
      "52 Train Loss 2.9289575 Test MSE 1161.0571414103151 Test RE 0.47149811597311125\n",
      "53 Train Loss 2.8749063 Test MSE 1185.2850318244305 Test RE 0.4763921150437452\n",
      "54 Train Loss 2.8303516 Test MSE 1230.2125500881796 Test RE 0.4853368211492721\n",
      "55 Train Loss 2.5882723 Test MSE 1058.4239201121845 Test RE 0.45017667359564206\n",
      "56 Train Loss 2.355774 Test MSE 1088.3537238546223 Test RE 0.45649728450661725\n",
      "57 Train Loss 2.3111024 Test MSE 1119.5865151874018 Test RE 0.46300106945938657\n",
      "58 Train Loss 2.2848477 Test MSE 1130.6458946144357 Test RE 0.46528223366630994\n",
      "59 Train Loss 2.2444487 Test MSE 1136.4889009978108 Test RE 0.46648293838385424\n",
      "60 Train Loss 2.109244 Test MSE 1116.424647728604 Test RE 0.4623468176194683\n",
      "61 Train Loss 2.0749521 Test MSE 1093.711427373512 Test RE 0.4576195182285152\n",
      "62 Train Loss 2.0435853 Test MSE 1064.870893796533 Test RE 0.4515456293615468\n",
      "63 Train Loss 2.030922 Test MSE 1042.0246624792376 Test RE 0.44667553230449303\n",
      "64 Train Loss 2.0070126 Test MSE 1018.9011073694704 Test RE 0.4416916424987269\n",
      "65 Train Loss 1.9672426 Test MSE 1047.1401812395889 Test RE 0.44777060214855463\n",
      "66 Train Loss 1.9290314 Test MSE 1042.398222734572 Test RE 0.44675559052190533\n",
      "67 Train Loss 1.9017985 Test MSE 1044.6973837961916 Test RE 0.44724801139798914\n",
      "68 Train Loss 1.8840988 Test MSE 1044.3532746259127 Test RE 0.4471743466124224\n",
      "69 Train Loss 1.874794 Test MSE 1073.751752035728 Test RE 0.4534246301400843\n",
      "70 Train Loss 1.8712976 Test MSE 1089.0066190310886 Test RE 0.456634188613838\n",
      "71 Train Loss 1.856122 Test MSE 1080.048037232061 Test RE 0.4547520868201032\n",
      "72 Train Loss 1.8443543 Test MSE 1105.714233406137 Test RE 0.4601237119805869\n",
      "73 Train Loss 1.8196052 Test MSE 1154.567611068124 Test RE 0.4701785905292985\n",
      "74 Train Loss 1.772023 Test MSE 1122.9172599038877 Test RE 0.4636892668836595\n",
      "75 Train Loss 1.731652 Test MSE 1089.3691779431929 Test RE 0.45671019504690386\n",
      "76 Train Loss 1.6852574 Test MSE 1090.7046592828913 Test RE 0.45699005477627547\n",
      "77 Train Loss 1.6553116 Test MSE 1082.1677604680472 Test RE 0.45519812071366633\n",
      "78 Train Loss 1.6512111 Test MSE 1071.9931290473567 Test RE 0.45305316171320775\n",
      "79 Train Loss 1.6484373 Test MSE 1059.611485791083 Test RE 0.450429154893454\n",
      "80 Train Loss 1.6431918 Test MSE 1062.6144194428553 Test RE 0.45106696031503624\n",
      "81 Train Loss 1.6256658 Test MSE 1069.3157201206704 Test RE 0.4524870354498436\n",
      "82 Train Loss 1.5811868 Test MSE 1073.4830767105466 Test RE 0.45336789839021524\n",
      "83 Train Loss 1.5507648 Test MSE 1087.185867364127 Test RE 0.4562522968713874\n",
      "84 Train Loss 1.5385772 Test MSE 1066.3665996926904 Test RE 0.45186263608646016\n",
      "85 Train Loss 1.5311002 Test MSE 1069.289652095056 Test RE 0.45248151999949654\n",
      "86 Train Loss 1.5190449 Test MSE 1098.0941696078924 Test RE 0.4585354925462602\n",
      "87 Train Loss 1.5067333 Test MSE 1104.0925653148422 Test RE 0.45978617371475117\n",
      "88 Train Loss 1.4938176 Test MSE 1149.8588821386195 Test RE 0.4692188349320212\n",
      "89 Train Loss 1.4846501 Test MSE 1161.9548591144448 Test RE 0.471680359553225\n",
      "90 Train Loss 1.4779655 Test MSE 1153.600663438106 Test RE 0.4699816625629777\n",
      "91 Train Loss 1.4774157 Test MSE 1152.9917312507878 Test RE 0.46985760544900995\n",
      "92 Train Loss 1.47703 Test MSE 1158.909750358882 Test RE 0.47106189307493557\n",
      "93 Train Loss 1.4769887 Test MSE 1159.6809174987736 Test RE 0.47121859511364\n",
      "94 Train Loss 1.4769887 Test MSE 1159.6809174987736 Test RE 0.47121859511364\n",
      "95 Train Loss 1.4769887 Test MSE 1159.6809174987736 Test RE 0.47121859511364\n",
      "96 Train Loss 1.4769887 Test MSE 1159.6809174987736 Test RE 0.47121859511364\n",
      "97 Train Loss 1.475735 Test MSE 1164.0870783888704 Test RE 0.4721129344442519\n",
      "98 Train Loss 1.4663056 Test MSE 1162.8212226547694 Test RE 0.4718561712548441\n",
      "99 Train Loss 1.456817 Test MSE 1189.822989906221 Test RE 0.47730319640431157\n",
      "Training time: 65.82\n",
      "Training time: 65.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 47.768715 Test MSE 5221.043838829687 Test RE 0.9998430556429755\n",
      "1 Train Loss 47.743134 Test MSE 5164.947947156842 Test RE 0.9944572978457233\n",
      "2 Train Loss 47.74143 Test MSE 5163.230824017293 Test RE 0.9942919769552846\n",
      "3 Train Loss 47.720394 Test MSE 5126.454117811679 Test RE 0.9907445729501702\n",
      "4 Train Loss 47.36402 Test MSE 4996.093078703556 Test RE 0.9780665924550836\n",
      "5 Train Loss 45.78136 Test MSE 4709.86349938025 Test RE 0.9496363388402131\n",
      "6 Train Loss 44.16574 Test MSE 4562.935694415078 Test RE 0.9347066636060455\n",
      "7 Train Loss 43.278908 Test MSE 4443.833509434002 Test RE 0.9224271017232776\n",
      "8 Train Loss 41.14781 Test MSE 4647.806940145601 Test RE 0.9433594509270246\n",
      "9 Train Loss 35.73835 Test MSE 4810.049962617007 Test RE 0.9596833462992305\n",
      "10 Train Loss 33.18985 Test MSE 5604.415137707833 Test RE 1.0359011457118938\n",
      "11 Train Loss 23.761715 Test MSE 3857.932682287492 Test RE 0.8594695353092996\n",
      "12 Train Loss 14.251568 Test MSE 1675.505427599507 Test RE 0.566403703251464\n",
      "13 Train Loss 13.20132 Test MSE 1296.4286280985882 Test RE 0.49822724300339893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 12.984649 Test MSE 1227.8874740535603 Test RE 0.48487796601065436\n",
      "15 Train Loss 12.407527 Test MSE 1146.4255466638342 Test RE 0.4685177967238512\n",
      "16 Train Loss 11.987143 Test MSE 1149.0897554741603 Test RE 0.4690618812867813\n",
      "17 Train Loss 11.686062 Test MSE 1144.651537912682 Test RE 0.46815515805948527\n",
      "18 Train Loss 11.427096 Test MSE 1137.1194905773975 Test RE 0.46661233625431514\n",
      "19 Train Loss 11.203027 Test MSE 1174.2785971988942 Test RE 0.4741750922418346\n",
      "20 Train Loss 10.95072 Test MSE 1228.7489392642262 Test RE 0.48504802730285806\n",
      "21 Train Loss 10.229216 Test MSE 1154.517742115348 Test RE 0.47016843626596366\n",
      "22 Train Loss 9.859428 Test MSE 1006.086898536089 Test RE 0.43890538717975786\n",
      "23 Train Loss 9.257697 Test MSE 868.8272096043027 Test RE 0.4078682236360788\n",
      "24 Train Loss 8.959707 Test MSE 816.6383329325881 Test RE 0.39542857125896763\n",
      "25 Train Loss 8.357288 Test MSE 737.729386633088 Test RE 0.3758388810059203\n",
      "26 Train Loss 8.065607 Test MSE 663.3938631648015 Test RE 0.35640097997702513\n",
      "27 Train Loss 7.5249467 Test MSE 556.8678978072329 Test RE 0.32653463722811255\n",
      "28 Train Loss 7.3666234 Test MSE 548.6474191830696 Test RE 0.3241155257011695\n",
      "29 Train Loss 7.2261863 Test MSE 535.5067580353563 Test RE 0.3202105545001076\n",
      "30 Train Loss 7.0181684 Test MSE 600.206805880014 Test RE 0.339003063241702\n",
      "31 Train Loss 6.8580933 Test MSE 618.0030496931001 Test RE 0.34399210392895585\n",
      "32 Train Loss 6.6345315 Test MSE 553.6120897300897 Test RE 0.3255786720751389\n",
      "33 Train Loss 6.5165634 Test MSE 557.8710939645007 Test RE 0.32682863055618755\n",
      "34 Train Loss 6.3625584 Test MSE 529.8505015876162 Test RE 0.31851496330021345\n",
      "35 Train Loss 6.0633397 Test MSE 528.570217801215 Test RE 0.31812991489815806\n",
      "36 Train Loss 5.924265 Test MSE 558.8446405883425 Test RE 0.3271136822627678\n",
      "37 Train Loss 5.796882 Test MSE 594.142991386213 Test RE 0.33728626324865935\n",
      "38 Train Loss 5.679658 Test MSE 632.8727268090917 Test RE 0.3481058765705568\n",
      "39 Train Loss 5.6165776 Test MSE 648.0783085955284 Test RE 0.3522629011630945\n",
      "40 Train Loss 5.58569 Test MSE 661.2070159227126 Test RE 0.3558130653807295\n",
      "41 Train Loss 5.5490847 Test MSE 645.940053771199 Test RE 0.3516812969336255\n",
      "42 Train Loss 5.4975257 Test MSE 652.928513089338 Test RE 0.35357860815961367\n",
      "43 Train Loss 5.446078 Test MSE 663.6990598144348 Test RE 0.3564829523042145\n",
      "44 Train Loss 5.402498 Test MSE 674.0517242502953 Test RE 0.3592524815040116\n",
      "45 Train Loss 5.36024 Test MSE 683.0434226106606 Test RE 0.3616407169003727\n",
      "46 Train Loss 5.300119 Test MSE 694.4579282067451 Test RE 0.3646499302732906\n",
      "47 Train Loss 5.252525 Test MSE 688.2101444263403 Test RE 0.3630059132912762\n",
      "48 Train Loss 5.233634 Test MSE 686.3827880623937 Test RE 0.3625236608225964\n",
      "49 Train Loss 5.2146473 Test MSE 697.9312297579357 Test RE 0.3655606834158862\n",
      "50 Train Loss 5.2027645 Test MSE 719.5278461074481 Test RE 0.3711735047613023\n",
      "51 Train Loss 5.189824 Test MSE 737.0905964064573 Test RE 0.3756761287814271\n",
      "52 Train Loss 5.179868 Test MSE 744.0297860453696 Test RE 0.377440349571187\n",
      "53 Train Loss 5.1735215 Test MSE 745.1255134147387 Test RE 0.37771817417919884\n",
      "54 Train Loss 5.164313 Test MSE 742.2577486941146 Test RE 0.3769906114533203\n",
      "55 Train Loss 5.1577544 Test MSE 735.6217885714511 Test RE 0.37530163532656485\n",
      "56 Train Loss 5.133648 Test MSE 733.7598059539798 Test RE 0.37482635856679886\n",
      "57 Train Loss 5.1174774 Test MSE 727.2170374452858 Test RE 0.373151496123727\n",
      "58 Train Loss 5.0834284 Test MSE 749.4930334793885 Test RE 0.37882354591530243\n",
      "59 Train Loss 5.07041 Test MSE 762.4607284163483 Test RE 0.38208668579304617\n",
      "60 Train Loss 5.057334 Test MSE 755.009690697528 Test RE 0.3802151586908523\n",
      "61 Train Loss 5.0444283 Test MSE 758.2381842810767 Test RE 0.38102720969028425\n",
      "62 Train Loss 5.037984 Test MSE 759.7005929522265 Test RE 0.3813944749443667\n",
      "63 Train Loss 5.023293 Test MSE 771.2610965292791 Test RE 0.3842853934767134\n",
      "64 Train Loss 5.003379 Test MSE 758.4988865340252 Test RE 0.3810927076545523\n",
      "65 Train Loss 4.9544144 Test MSE 766.5031455980047 Test RE 0.3830982211448728\n",
      "66 Train Loss 4.9281955 Test MSE 775.6187424806096 Test RE 0.38536947576748604\n",
      "67 Train Loss 4.9063225 Test MSE 768.0759222785583 Test RE 0.3834910565749296\n",
      "68 Train Loss 4.890374 Test MSE 755.4878280702679 Test RE 0.3803355321816262\n",
      "69 Train Loss 4.886763 Test MSE 754.0458185655184 Test RE 0.379972383108087\n",
      "70 Train Loss 4.8837814 Test MSE 754.0600232843099 Test RE 0.37997596205203105\n",
      "71 Train Loss 4.882194 Test MSE 758.0363961578093 Test RE 0.3809765053843979\n",
      "72 Train Loss 4.8814845 Test MSE 758.3276303554878 Test RE 0.38104968309231546\n",
      "73 Train Loss 4.879284 Test MSE 760.2938310528311 Test RE 0.3815433583222181\n",
      "74 Train Loss 4.8775973 Test MSE 761.6666781763012 Test RE 0.3818876755057437\n",
      "75 Train Loss 4.8725443 Test MSE 768.2061690967051 Test RE 0.3835235705303395\n",
      "76 Train Loss 4.8607793 Test MSE 757.0294063989564 Test RE 0.3807233731242698\n",
      "77 Train Loss 4.8510723 Test MSE 752.3556615593983 Test RE 0.3795462994101249\n",
      "78 Train Loss 4.807148 Test MSE 766.188738577748 Test RE 0.38301964278226003\n",
      "79 Train Loss 4.7624683 Test MSE 759.840327319105 Test RE 0.3814295489363928\n",
      "80 Train Loss 4.755613 Test MSE 760.9363738761417 Test RE 0.38170455006237153\n",
      "81 Train Loss 4.742447 Test MSE 762.437039687743 Test RE 0.38208075026235644\n",
      "82 Train Loss 4.729192 Test MSE 763.1915874702 Test RE 0.38226976710856153\n",
      "83 Train Loss 4.721772 Test MSE 762.7345267408695 Test RE 0.38215528296824525\n",
      "84 Train Loss 4.7112966 Test MSE 767.5638995853731 Test RE 0.3833632118833752\n",
      "85 Train Loss 4.7015224 Test MSE 769.5051710916363 Test RE 0.3838476941013232\n",
      "86 Train Loss 4.695543 Test MSE 778.943532894899 Test RE 0.38619456064392654\n",
      "87 Train Loss 4.6878304 Test MSE 778.0251534954598 Test RE 0.3859668305737533\n",
      "88 Train Loss 4.6820946 Test MSE 766.9536130814922 Test RE 0.3832107764194835\n",
      "89 Train Loss 4.6795564 Test MSE 756.5196118850723 Test RE 0.38059515923181153\n",
      "90 Train Loss 4.6769686 Test MSE 749.0419445257664 Test RE 0.3787095296210102\n",
      "91 Train Loss 4.6748724 Test MSE 743.5625265159797 Test RE 0.37732181244970964\n",
      "92 Train Loss 4.6734653 Test MSE 743.1064508753299 Test RE 0.377206076598718\n",
      "93 Train Loss 4.6728215 Test MSE 745.1432877500531 Test RE 0.3777226792252109\n",
      "94 Train Loss 4.6706624 Test MSE 743.4892790322567 Test RE 0.3773032272245218\n",
      "95 Train Loss 4.666827 Test MSE 745.1257116632095 Test RE 0.3777182244271397\n",
      "96 Train Loss 4.6631646 Test MSE 740.9889136515907 Test RE 0.37666825476822097\n",
      "97 Train Loss 4.657728 Test MSE 734.7587807539019 Test RE 0.3750814248190463\n",
      "98 Train Loss 4.6531844 Test MSE 725.5595044526989 Test RE 0.37272599470758727\n",
      "99 Train Loss 4.6496196 Test MSE 724.5965743889737 Test RE 0.3724785799712867\n",
      "Training time: 66.35\n",
      "Training time: 66.35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 47.770046 Test MSE 5223.777237876034 Test RE 1.0001047477998886\n",
      "1 Train Loss 47.75167 Test MSE 5184.9343322450695 Test RE 0.9963795259169129\n",
      "2 Train Loss 47.74747 Test MSE 5169.320956164997 Test RE 0.9948781975974441\n",
      "3 Train Loss 47.720303 Test MSE 5107.116251177536 Test RE 0.9888741779567803\n",
      "4 Train Loss 47.675224 Test MSE 5041.676962192721 Test RE 0.9825183549593651\n",
      "5 Train Loss 47.543373 Test MSE 4774.745057925337 Test RE 0.9561549079626939\n",
      "6 Train Loss 47.478046 Test MSE 4716.798159766254 Test RE 0.950335189586729\n",
      "7 Train Loss 47.421055 Test MSE 4784.9206953069415 Test RE 0.9571732144172671\n",
      "8 Train Loss 46.043327 Test MSE 4844.739039419056 Test RE 0.9631376475990987\n",
      "9 Train Loss 44.891804 Test MSE 4452.242083434956 Test RE 0.9232993926069077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 40.512493 Test MSE 4682.353928472449 Test RE 0.9468589391674554\n",
      "11 Train Loss 35.58157 Test MSE 4399.0527433530115 Test RE 0.9177676581294515\n",
      "12 Train Loss 34.7577 Test MSE 4282.309447173213 Test RE 0.9055077843767687\n",
      "13 Train Loss 32.85485 Test MSE 4250.452984659881 Test RE 0.9021334225876727\n",
      "14 Train Loss 31.656115 Test MSE 4368.884396745483 Test RE 0.9146152560534133\n",
      "15 Train Loss 30.17976 Test MSE 4417.500493403681 Test RE 0.9196900078244737\n",
      "16 Train Loss 28.87459 Test MSE 4528.099956859109 Test RE 0.9311318179692787\n",
      "17 Train Loss 27.937164 Test MSE 4636.93027198965 Test RE 0.9422549926563921\n",
      "18 Train Loss 26.500393 Test MSE 4990.911409551337 Test RE 0.9775592628117756\n",
      "19 Train Loss 25.235666 Test MSE 5719.219519298839 Test RE 1.0464573864578248\n",
      "20 Train Loss 24.90303 Test MSE 6023.277889474522 Test RE 1.0739142737868157\n",
      "21 Train Loss 23.850737 Test MSE 7055.091836115162 Test RE 1.16226323510089\n",
      "22 Train Loss 14.810964 Test MSE 1213.8966959608886 Test RE 0.48210765721776155\n",
      "23 Train Loss 13.73105 Test MSE 763.5668937091597 Test RE 0.38236374783195287\n",
      "24 Train Loss 12.736686 Test MSE 673.4793035712296 Test RE 0.35909990624909494\n",
      "25 Train Loss 12.228172 Test MSE 712.9465305300331 Test RE 0.36947209626362154\n",
      "26 Train Loss 11.880885 Test MSE 643.0783438706081 Test RE 0.35090140490302546\n",
      "27 Train Loss 11.783964 Test MSE 587.4064296746207 Test RE 0.33536868860528934\n",
      "28 Train Loss 10.513829 Test MSE 1259.8447743800316 Test RE 0.4911472131698347\n",
      "29 Train Loss 9.671461 Test MSE 1466.6274786153629 Test RE 0.5299233710564867\n",
      "30 Train Loss 9.317682 Test MSE 1506.6763092369324 Test RE 0.5371098840352945\n",
      "31 Train Loss 9.245513 Test MSE 1438.210364118039 Test RE 0.5247644083003132\n",
      "32 Train Loss 8.809707 Test MSE 1238.0882976366706 Test RE 0.48688789137075716\n",
      "33 Train Loss 8.506209 Test MSE 1162.4552756926385 Test RE 0.47178191739852254\n",
      "34 Train Loss 7.8503456 Test MSE 687.5763438172854 Test RE 0.36283872136147394\n",
      "35 Train Loss 7.674722 Test MSE 621.0344642843783 Test RE 0.34483474301611444\n",
      "36 Train Loss 7.626928 Test MSE 676.194519255872 Test RE 0.35982305611148707\n",
      "37 Train Loss 7.2646317 Test MSE 614.1176861626855 Test RE 0.34290906583411457\n",
      "38 Train Loss 7.0243115 Test MSE 598.5012870229466 Test RE 0.3385210731798897\n",
      "39 Train Loss 6.811865 Test MSE 511.8881148134538 Test RE 0.31306944815097126\n",
      "40 Train Loss 6.8080063 Test MSE 509.7342969951827 Test RE 0.312410119166795\n",
      "41 Train Loss 6.7965703 Test MSE 510.38613269869506 Test RE 0.31260980654326126\n",
      "42 Train Loss 6.6611075 Test MSE 579.9611539506708 Test RE 0.33323654061070673\n",
      "43 Train Loss 6.5641007 Test MSE 562.0475449912669 Test RE 0.32804973575063034\n",
      "44 Train Loss 6.2935905 Test MSE 627.5929823967986 Test RE 0.34665079781173924\n",
      "45 Train Loss 5.8809924 Test MSE 675.2231163868073 Test RE 0.35956450715712857\n",
      "46 Train Loss 5.638452 Test MSE 647.5980747015087 Test RE 0.35213236143270193\n",
      "47 Train Loss 5.62169 Test MSE 684.4733374023424 Test RE 0.36201905672316176\n",
      "48 Train Loss 5.593192 Test MSE 668.2768410515084 Test RE 0.35771023796247686\n",
      "49 Train Loss 5.561335 Test MSE 643.4259826028738 Test RE 0.35099623816796316\n",
      "50 Train Loss 5.411452 Test MSE 684.3061900493046 Test RE 0.3619748517714349\n",
      "51 Train Loss 5.261351 Test MSE 704.74739911255 Test RE 0.36734142430520733\n",
      "52 Train Loss 5.0099134 Test MSE 760.0390607619582 Test RE 0.3814794264230848\n",
      "53 Train Loss 4.7522144 Test MSE 737.7292621031548 Test RE 0.3758388492848086\n",
      "54 Train Loss 4.5961957 Test MSE 719.7986842067057 Test RE 0.3712433550588948\n",
      "55 Train Loss 4.5329204 Test MSE 778.8064822365947 Test RE 0.3861605847876264\n",
      "56 Train Loss 4.5235386 Test MSE 772.2062570572633 Test RE 0.384520787287331\n",
      "57 Train Loss 4.5107236 Test MSE 758.5722487157449 Test RE 0.3811111368948445\n",
      "58 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "59 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "60 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "61 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "62 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "63 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "64 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "65 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "66 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "67 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "68 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "69 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "70 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "71 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "72 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "73 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "74 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "75 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "76 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "77 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "78 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "79 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "80 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "81 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "82 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "83 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "84 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "85 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "86 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "87 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "88 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "89 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "90 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "91 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "92 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "93 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "94 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "95 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "96 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "97 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "98 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "99 Train Loss 4.510475 Test MSE 759.6680097649494 Test RE 0.3813862959453181\n",
      "Training time: 45.75\n",
      "Training time: 45.75\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 47.75011 Test MSE 5179.706530058572 Test RE 0.995877090555358\n",
      "1 Train Loss 47.731953 Test MSE 5127.2764005706385 Test RE 0.9908240274323943\n",
      "2 Train Loss 47.70203 Test MSE 5076.085420727557 Test RE 0.9858654016747049\n",
      "3 Train Loss 47.57816 Test MSE 4879.338052336487 Test RE 0.9665706836684679\n",
      "4 Train Loss 47.49621 Test MSE 4769.664598588262 Test RE 0.9556460850892353\n",
      "5 Train Loss 47.12491 Test MSE 4758.507697402498 Test RE 0.9545277369305885\n",
      "6 Train Loss 46.760616 Test MSE 4909.5187491123315 Test RE 0.9695553924079181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 46.378582 Test MSE 5303.801386254313 Test RE 1.0077360406155358\n",
      "8 Train Loss 44.463696 Test MSE 5068.146490214029 Test RE 0.9850941597740579\n",
      "9 Train Loss 39.483383 Test MSE 4238.979809227507 Test RE 0.9009150431441624\n",
      "10 Train Loss 32.64055 Test MSE 3309.9336824622346 Test RE 0.7960911773015125\n",
      "11 Train Loss 31.083952 Test MSE 3026.8683233693296 Test RE 0.7612896560410621\n",
      "12 Train Loss 30.02726 Test MSE 3076.8176312568517 Test RE 0.7675453455807418\n",
      "13 Train Loss 29.292418 Test MSE 3164.938610841763 Test RE 0.7784591182197879\n",
      "14 Train Loss 26.606174 Test MSE 3283.661590652767 Test RE 0.7929254570176526\n",
      "15 Train Loss 20.98048 Test MSE 2384.851519118553 Test RE 0.6757465501505413\n",
      "16 Train Loss 18.783815 Test MSE 1976.8762115520346 Test RE 0.6152376468225124\n",
      "17 Train Loss 16.973984 Test MSE 1597.7052375338126 Test RE 0.5530972435788208\n",
      "18 Train Loss 16.359808 Test MSE 1899.3557953972463 Test RE 0.6030541740720337\n",
      "19 Train Loss 16.064512 Test MSE 1919.7047891774732 Test RE 0.6062760170695681\n",
      "20 Train Loss 15.584814 Test MSE 1608.4601952149108 Test RE 0.5549557091491544\n",
      "21 Train Loss 15.136657 Test MSE 1533.1653581722885 Test RE 0.5418108074179102\n",
      "22 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "23 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "24 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "25 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "26 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "27 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "28 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "29 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "30 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "31 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "32 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "33 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "34 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "35 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "36 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "37 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "38 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "39 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "40 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "41 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "42 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "43 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "44 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "45 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "46 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "47 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "48 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "49 Train Loss 14.63501 Test MSE 1241.934508930985 Test RE 0.48764358123790946\n",
      "50 Train Loss 14.634953 Test MSE 1241.9115607524254 Test RE 0.4876390759344535\n",
      "51 Train Loss 13.600334 Test MSE 844.346022282961 Test RE 0.4020808557480443\n",
      "52 Train Loss 13.226161 Test MSE 737.0889523390681 Test RE 0.3756757098117512\n",
      "53 Train Loss 13.184877 Test MSE 708.8045690719065 Test RE 0.36839728330343074\n",
      "54 Train Loss 13.163035 Test MSE 681.7410535375523 Test RE 0.3612957795254368\n",
      "55 Train Loss 13.130938 Test MSE 688.0879469287671 Test RE 0.36297368448457024\n",
      "56 Train Loss 13.114 Test MSE 709.0714934394556 Test RE 0.3684666430113928\n",
      "57 Train Loss 13.101501 Test MSE 700.2166690868436 Test RE 0.36615872509388203\n",
      "58 Train Loss 13.087245 Test MSE 687.4459569287889 Test RE 0.3628043167056171\n",
      "59 Train Loss 13.08493 Test MSE 686.9047476062999 Test RE 0.36266147512100216\n",
      "60 Train Loss 13.084598 Test MSE 685.9720185694382 Test RE 0.36241516746499314\n",
      "61 Train Loss 13.084598 Test MSE 685.9719262501607 Test RE 0.36241514307776845\n",
      "62 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "63 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "64 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "65 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "66 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "67 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "68 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "69 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "70 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "71 Train Loss 13.084566 Test MSE 685.9678088348724 Test RE 0.36241405541234584\n",
      "72 Train Loss 13.084515 Test MSE 685.9682738724586 Test RE 0.3624141782578546\n",
      "73 Train Loss 13.084515 Test MSE 685.9682738724586 Test RE 0.3624141782578546\n",
      "74 Train Loss 13.084515 Test MSE 685.9682738724586 Test RE 0.3624141782578546\n",
      "75 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "76 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "77 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "78 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "79 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "80 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "81 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "82 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "83 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "84 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "85 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "86 Train Loss 13.084395 Test MSE 685.9652450723189 Test RE 0.36241337816157676\n",
      "87 Train Loss 13.084286 Test MSE 685.8128872388905 Test RE 0.3623731286126119\n",
      "88 Train Loss 13.084286 Test MSE 685.8128872388905 Test RE 0.3623731286126119\n",
      "89 Train Loss 13.084286 Test MSE 685.8128872388905 Test RE 0.3623731286126119\n",
      "90 Train Loss 13.084066 Test MSE 686.9672563290962 Test RE 0.36267797594588747\n",
      "91 Train Loss 13.084066 Test MSE 686.9672563290962 Test RE 0.36267797594588747\n",
      "92 Train Loss 13.084066 Test MSE 686.9672563290962 Test RE 0.36267797594588747\n",
      "93 Train Loss 13.084066 Test MSE 686.9672563290962 Test RE 0.36267797594588747\n",
      "94 Train Loss 13.08398 Test MSE 687.0990951434243 Test RE 0.36271277581445066\n",
      "95 Train Loss 13.08398 Test MSE 687.0990951434243 Test RE 0.36271277581445066\n",
      "96 Train Loss 13.083699 Test MSE 686.6323267843007 Test RE 0.36258955369745516\n",
      "97 Train Loss 13.083245 Test MSE 686.6189196361926 Test RE 0.36258601372752525\n",
      "98 Train Loss 13.083245 Test MSE 686.6189196361926 Test RE 0.36258601372752525\n",
      "99 Train Loss 13.083245 Test MSE 686.6189196361926 Test RE 0.36258601372752525\n",
      "Training time: 33.32\n",
      "Training time: 33.32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 47.771984 Test MSE 5227.58558683834 Test RE 1.000469240175276\n",
      "1 Train Loss 47.771347 Test MSE 5226.127185446533 Test RE 1.0003296740709156\n",
      "2 Train Loss 47.76545 Test MSE 5214.164662883707 Test RE 0.9991841487628828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 47.756462 Test MSE 5190.605182057624 Test RE 0.9969242555285143\n",
      "4 Train Loss 47.741104 Test MSE 5155.810820645249 Test RE 0.9935772788759486\n",
      "5 Train Loss 47.71278 Test MSE 5081.400992166431 Test RE 0.9863814555169698\n",
      "6 Train Loss 47.6619 Test MSE 5016.245645161774 Test RE 0.9800372038147908\n",
      "7 Train Loss 47.2341 Test MSE 4802.566804995854 Test RE 0.9589365497910671\n",
      "8 Train Loss 45.791756 Test MSE 4781.2672367997675 Test RE 0.9568077266045586\n",
      "9 Train Loss 38.93052 Test MSE 3489.666396036463 Test RE 0.8174197381780395\n",
      "10 Train Loss 36.10155 Test MSE 3155.4872480754625 Test RE 0.7772959044077303\n",
      "11 Train Loss 33.2497 Test MSE 2589.51977967251 Test RE 0.7041461045003778\n",
      "12 Train Loss 29.505274 Test MSE 1986.6335872715947 Test RE 0.6167541089063078\n",
      "13 Train Loss 26.860283 Test MSE 1698.3285031166397 Test RE 0.5702483192389431\n",
      "14 Train Loss 24.528496 Test MSE 1417.2835589589831 Test RE 0.5209326033581368\n",
      "15 Train Loss 23.288141 Test MSE 1283.7749258427486 Test RE 0.4957898245255513\n",
      "16 Train Loss 22.811083 Test MSE 1218.1159591253556 Test RE 0.48294478552768316\n",
      "17 Train Loss 21.628643 Test MSE 938.773224623276 Test RE 0.42396842311008376\n",
      "18 Train Loss 20.01544 Test MSE 797.155673080934 Test RE 0.3906831990923821\n",
      "19 Train Loss 16.915678 Test MSE 878.9825140088374 Test RE 0.41024498659159425\n",
      "20 Train Loss 15.484927 Test MSE 1168.0386786806569 Test RE 0.4729135708771833\n",
      "21 Train Loss 15.411634 Test MSE 1184.4561842813332 Test RE 0.4762255198887538\n",
      "22 Train Loss 15.357718 Test MSE 1202.5904790482946 Test RE 0.479857232852756\n",
      "23 Train Loss 15.346052 Test MSE 1213.7979322426718 Test RE 0.48208804446426273\n",
      "24 Train Loss 15.323456 Test MSE 1216.502822879514 Test RE 0.4826249006157066\n",
      "25 Train Loss 15.282187 Test MSE 1232.6152153645594 Test RE 0.4858105332404211\n",
      "26 Train Loss 15.239538 Test MSE 1205.6748507209231 Test RE 0.48047220124535\n",
      "27 Train Loss 15.14114 Test MSE 1219.3042296653914 Test RE 0.48318028411584996\n",
      "28 Train Loss 15.050866 Test MSE 1160.667891217077 Test RE 0.47141907330105626\n",
      "29 Train Loss 14.970978 Test MSE 1130.4939943799461 Test RE 0.4652509777024806\n",
      "30 Train Loss 14.795349 Test MSE 1073.2022676531278 Test RE 0.4533085969714479\n",
      "31 Train Loss 14.786325 Test MSE 1087.4866610323909 Test RE 0.4563154085779525\n",
      "32 Train Loss 14.775383 Test MSE 1099.3561522874645 Test RE 0.458798902417632\n",
      "33 Train Loss 14.769856 Test MSE 1095.3084756768267 Test RE 0.4579535066354862\n",
      "34 Train Loss 14.768934 Test MSE 1100.0871391531293 Test RE 0.4589514099738519\n",
      "35 Train Loss 14.767558 Test MSE 1106.5248991651852 Test RE 0.4602923532911614\n",
      "36 Train Loss 14.705564 Test MSE 1088.0625768450711 Test RE 0.45643622131267736\n",
      "37 Train Loss 14.535123 Test MSE 973.5334124800207 Test RE 0.43174627116172043\n",
      "38 Train Loss 14.530127 Test MSE 955.2729770358421 Test RE 0.4276780004487046\n",
      "39 Train Loss 14.504994 Test MSE 948.6572919861871 Test RE 0.42619449848732616\n",
      "40 Train Loss 14.377689 Test MSE 952.4101567921202 Test RE 0.4270366738556135\n",
      "41 Train Loss 14.33962 Test MSE 988.977745385458 Test RE 0.4351574509994197\n",
      "42 Train Loss 14.280596 Test MSE 938.2900338508475 Test RE 0.4238592998460493\n",
      "43 Train Loss 14.231099 Test MSE 940.5297178220231 Test RE 0.42436487116362376\n",
      "44 Train Loss 14.18762 Test MSE 956.5894759595275 Test RE 0.4279725988453592\n",
      "45 Train Loss 14.145727 Test MSE 916.3282088111438 Test RE 0.4188694561320729\n",
      "46 Train Loss 14.095336 Test MSE 943.5495660384678 Test RE 0.4250455995077866\n",
      "47 Train Loss 13.728211 Test MSE 789.1620676263789 Test RE 0.3887194447272121\n",
      "48 Train Loss 13.638564 Test MSE 764.51877292129 Test RE 0.3826020051118805\n",
      "49 Train Loss 13.59345 Test MSE 703.5288706988874 Test RE 0.36702371499812225\n",
      "50 Train Loss 13.423891 Test MSE 621.3935003981334 Test RE 0.3449344075630428\n",
      "51 Train Loss 12.610405 Test MSE 633.9065037838493 Test RE 0.34839007036511976\n",
      "52 Train Loss 12.083905 Test MSE 618.5373754654179 Test RE 0.34414077967953144\n",
      "53 Train Loss 11.476819 Test MSE 618.8202734543363 Test RE 0.3442194698355078\n",
      "54 Train Loss 10.508005 Test MSE 473.18635261412476 Test RE 0.3010019228193084\n",
      "55 Train Loss 6.903248 Test MSE 661.1563130259838 Test RE 0.35579942283116534\n",
      "56 Train Loss 6.797167 Test MSE 697.7856511568011 Test RE 0.36552255602878636\n",
      "57 Train Loss 6.7574725 Test MSE 681.3237570276559 Test RE 0.361185187281164\n",
      "58 Train Loss 6.7272015 Test MSE 686.4073701863746 Test RE 0.3625301524785228\n",
      "59 Train Loss 6.638941 Test MSE 670.8027637697155 Test RE 0.3583856288880768\n",
      "60 Train Loss 6.6143384 Test MSE 651.6741983833605 Test RE 0.3532388220721445\n",
      "61 Train Loss 6.577913 Test MSE 626.115467708507 Test RE 0.34624250496356607\n",
      "62 Train Loss 6.561783 Test MSE 618.7856876535726 Test RE 0.3442098505059045\n",
      "63 Train Loss 6.5451107 Test MSE 614.1391971138999 Test RE 0.34291507138953203\n",
      "64 Train Loss 6.5224657 Test MSE 590.3760931028417 Test RE 0.3362153566910919\n",
      "65 Train Loss 6.489898 Test MSE 569.8222579516913 Test RE 0.33031087264056214\n",
      "66 Train Loss 6.48098 Test MSE 549.5252232702574 Test RE 0.32437470510704175\n",
      "67 Train Loss 6.480946 Test MSE 548.1444535598168 Test RE 0.3239669272204137\n",
      "68 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "69 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "70 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "71 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "72 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "73 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "74 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "75 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "76 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "77 Train Loss 6.480945 Test MSE 548.1444344046813 Test RE 0.3239669215598342\n",
      "78 Train Loss 6.4809413 Test MSE 548.1419281041664 Test RE 0.32396618091618307\n",
      "79 Train Loss 6.4809413 Test MSE 548.1419281041664 Test RE 0.32396618091618307\n",
      "80 Train Loss 6.4809413 Test MSE 548.1419281041664 Test RE 0.32396618091618307\n",
      "81 Train Loss 6.4809413 Test MSE 548.1419281041664 Test RE 0.32396618091618307\n",
      "82 Train Loss 6.4809413 Test MSE 548.1419281041664 Test RE 0.32396618091618307\n",
      "83 Train Loss 6.4809413 Test MSE 548.1419281041664 Test RE 0.32396618091618307\n",
      "84 Train Loss 6.48094 Test MSE 548.142124398126 Test RE 0.32396623892360377\n",
      "85 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "86 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "87 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "88 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "89 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "90 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "91 Train Loss 6.480936 Test MSE 547.3404170963911 Test RE 0.32372923730903946\n",
      "92 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "93 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "94 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "95 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "96 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "97 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "98 Train Loss 6.480897 Test MSE 547.325610022004 Test RE 0.32372485839313253\n",
      "99 Train Loss 6.4752445 Test MSE 550.9043655962763 Test RE 0.32478149130548745\n",
      "Training time: 52.36\n",
      "Training time: 52.36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.76869 Test MSE 5221.031392931627 Test RE 0.9998418639318398\n",
      "1 Train Loss 47.75109 Test MSE 5181.3665632642505 Test RE 0.9960366610439519\n",
      "2 Train Loss 47.70971 Test MSE 5078.335452534758 Test RE 0.986083875416609\n",
      "3 Train Loss 47.18677 Test MSE 4822.618018010473 Test RE 0.9609362943066958\n",
      "4 Train Loss 44.538017 Test MSE 4538.495665130863 Test RE 0.9322000613212892\n",
      "5 Train Loss 44.161808 Test MSE 4502.4953993159515 Test RE 0.928495500622295\n",
      "6 Train Loss 40.594315 Test MSE 3861.237711087328 Test RE 0.8598376033515814\n",
      "7 Train Loss 34.202084 Test MSE 4467.473206075826 Test RE 0.9248773480800233\n",
      "8 Train Loss 30.040089 Test MSE 4747.219161893507 Test RE 0.9533948588307345\n",
      "9 Train Loss 28.254715 Test MSE 5112.279887506996 Test RE 0.9893739606479761\n",
      "10 Train Loss 27.01249 Test MSE 5122.20619912383 Test RE 0.9903340089919782\n",
      "11 Train Loss 26.623402 Test MSE 5133.765956602048 Test RE 0.9914508684903169\n",
      "12 Train Loss 25.611406 Test MSE 5809.3420270039605 Test RE 1.054670109756035\n",
      "13 Train Loss 24.234552 Test MSE 5981.07898452334 Test RE 1.070145755994849\n",
      "14 Train Loss 20.414042 Test MSE 5624.897157352697 Test RE 1.0377923330250223\n",
      "15 Train Loss 17.995472 Test MSE 5338.20032259089 Test RE 1.0109987026222484\n",
      "16 Train Loss 13.990035 Test MSE 3395.723155005144 Test RE 0.8063420393311311\n",
      "17 Train Loss 12.011932 Test MSE 3087.1594664532986 Test RE 0.7688342046272088\n",
      "18 Train Loss 9.850984 Test MSE 1977.4981551631272 Test RE 0.615334418949789\n",
      "19 Train Loss 7.1867123 Test MSE 601.1516033314065 Test RE 0.33926977405098085\n",
      "20 Train Loss 6.9022155 Test MSE 558.1892879693069 Test RE 0.32692182420544663\n",
      "21 Train Loss 6.6120625 Test MSE 581.992205032081 Test RE 0.33381953561191524\n",
      "22 Train Loss 6.2406225 Test MSE 456.25902162201265 Test RE 0.29556901011909337\n",
      "23 Train Loss 6.058621 Test MSE 397.8138662413149 Test RE 0.2759898580561215\n",
      "24 Train Loss 5.9038053 Test MSE 466.53045015135064 Test RE 0.29887745898066503\n",
      "25 Train Loss 5.637033 Test MSE 512.256605186183 Test RE 0.313182111758807\n",
      "26 Train Loss 5.3884215 Test MSE 433.458291797203 Test RE 0.2880890969643147\n",
      "27 Train Loss 5.3197646 Test MSE 402.06226462622146 Test RE 0.2774596422233468\n",
      "28 Train Loss 5.292876 Test MSE 423.7542663952744 Test RE 0.2848460533717316\n",
      "29 Train Loss 5.2179337 Test MSE 427.2098541660711 Test RE 0.2860051118973601\n",
      "30 Train Loss 5.090407 Test MSE 363.3021722050033 Test RE 0.2637467774337362\n",
      "31 Train Loss 5.0092616 Test MSE 352.3540776250235 Test RE 0.2597423799570182\n",
      "32 Train Loss 4.9748135 Test MSE 358.246718790141 Test RE 0.2619052929543259\n",
      "33 Train Loss 4.932986 Test MSE 375.3607196921311 Test RE 0.26808812436118196\n",
      "34 Train Loss 4.8831797 Test MSE 371.8707882319334 Test RE 0.2668389338957961\n",
      "35 Train Loss 4.8395915 Test MSE 363.52950810711445 Test RE 0.2638292841447626\n",
      "36 Train Loss 4.803593 Test MSE 384.4560923032464 Test RE 0.2713167076339276\n",
      "37 Train Loss 4.7930374 Test MSE 380.416799748443 Test RE 0.2698876479894354\n",
      "38 Train Loss 4.786065 Test MSE 374.43765850257563 Test RE 0.26775828954822933\n",
      "39 Train Loss 4.7508526 Test MSE 370.60760906371416 Test RE 0.26638534609289505\n",
      "40 Train Loss 4.6993246 Test MSE 377.6034136843159 Test RE 0.26888781409981394\n",
      "41 Train Loss 4.6884747 Test MSE 382.4161434288551 Test RE 0.2705959382566406\n",
      "42 Train Loss 4.6614323 Test MSE 385.16187108292746 Test RE 0.271565633032431\n",
      "43 Train Loss 4.578229 Test MSE 395.07865153737094 Test RE 0.2750394216235279\n",
      "44 Train Loss 4.4902153 Test MSE 398.3791613816944 Test RE 0.2761858798057204\n",
      "45 Train Loss 4.454058 Test MSE 401.58468210636846 Test RE 0.2772948055052367\n",
      "46 Train Loss 4.38544 Test MSE 384.9188441281887 Test RE 0.27147994414710674\n",
      "47 Train Loss 4.335386 Test MSE 381.9921096620732 Test RE 0.27044587445594737\n",
      "48 Train Loss 4.2632513 Test MSE 423.11089418364577 Test RE 0.2846297350206129\n",
      "49 Train Loss 4.2401342 Test MSE 420.4410724748096 Test RE 0.28373030982442793\n",
      "50 Train Loss 4.1893406 Test MSE 428.1115714829196 Test RE 0.28630679012066007\n",
      "51 Train Loss 4.0497465 Test MSE 450.5734822885666 Test RE 0.2937216633299795\n",
      "52 Train Loss 3.9761508 Test MSE 424.548908264931 Test RE 0.28511300594565164\n",
      "53 Train Loss 3.9410877 Test MSE 433.4786973870337 Test RE 0.28809587796132674\n",
      "54 Train Loss 3.8342776 Test MSE 456.4935154861839 Test RE 0.2956449540599008\n",
      "55 Train Loss 3.8084638 Test MSE 436.4234908926149 Test RE 0.2890727966637323\n",
      "56 Train Loss 3.7627892 Test MSE 450.5224122878938 Test RE 0.293705016999015\n",
      "57 Train Loss 3.7211812 Test MSE 442.93496946795534 Test RE 0.29122130867671747\n",
      "58 Train Loss 3.6526625 Test MSE 451.96518386427323 Test RE 0.29417492762158964\n",
      "59 Train Loss 3.5909426 Test MSE 444.2913474913586 Test RE 0.2916668641988158\n",
      "60 Train Loss 3.5523605 Test MSE 438.21128139600336 Test RE 0.2896642788235034\n",
      "61 Train Loss 3.4854393 Test MSE 472.43012080980213 Test RE 0.3007613006570389\n",
      "62 Train Loss 3.4051692 Test MSE 504.64438811359594 Test RE 0.3108464333967183\n",
      "63 Train Loss 3.364383 Test MSE 490.9647291901327 Test RE 0.30660434950469856\n",
      "64 Train Loss 3.339666 Test MSE 500.3341479016525 Test RE 0.309516094630799\n",
      "65 Train Loss 3.3242638 Test MSE 520.4435628359058 Test RE 0.31567485185113464\n",
      "66 Train Loss 3.3095357 Test MSE 532.771128359555 Test RE 0.319391611434534\n",
      "67 Train Loss 3.2876 Test MSE 574.994058947615 Test RE 0.3318064647832398\n",
      "68 Train Loss 3.2390258 Test MSE 619.8744506351276 Test RE 0.34451253869437026\n",
      "69 Train Loss 3.2147336 Test MSE 612.1295268985622 Test RE 0.34235354485570046\n",
      "70 Train Loss 3.184844 Test MSE 617.9571977231775 Test RE 0.34397934265845653\n",
      "71 Train Loss 3.172249 Test MSE 621.2758985752448 Test RE 0.34490176573902936\n",
      "72 Train Loss 3.1653228 Test MSE 619.9404521117827 Test RE 0.34453087928819515\n",
      "73 Train Loss 3.1529078 Test MSE 619.7154735543054 Test RE 0.34446835788505836\n",
      "74 Train Loss 3.1166072 Test MSE 651.785201844995 Test RE 0.35326890540406486\n",
      "75 Train Loss 3.1066525 Test MSE 665.2287202099751 Test RE 0.3568935179163771\n",
      "76 Train Loss 3.0879097 Test MSE 703.7655081095544 Test RE 0.36708543544991706\n",
      "77 Train Loss 3.0615416 Test MSE 711.1523134799102 Test RE 0.36900689255803687\n",
      "78 Train Loss 3.0383174 Test MSE 689.0288007615252 Test RE 0.3632217548981173\n",
      "79 Train Loss 3.025973 Test MSE 689.7653212581698 Test RE 0.363415831557456\n",
      "80 Train Loss 3.0142365 Test MSE 699.5313003386341 Test RE 0.36597948401301345\n",
      "81 Train Loss 3.0019991 Test MSE 708.756063785807 Test RE 0.3683846779096989\n",
      "82 Train Loss 2.9840734 Test MSE 712.9434970657891 Test RE 0.369471310242835\n",
      "83 Train Loss 2.9735494 Test MSE 711.2194404204531 Test RE 0.3690243077578235\n",
      "84 Train Loss 2.9604495 Test MSE 687.9685887923097 Test RE 0.3629422017782558\n",
      "85 Train Loss 2.9306047 Test MSE 661.1192513616684 Test RE 0.3557894503758524\n",
      "86 Train Loss 2.9088767 Test MSE 631.429468033167 Test RE 0.3477087243468042\n",
      "87 Train Loss 2.8619466 Test MSE 563.7614212100156 Test RE 0.32854952325501413\n",
      "88 Train Loss 2.8252194 Test MSE 554.9658985415352 Test RE 0.3259765157508339\n",
      "89 Train Loss 2.802707 Test MSE 557.8891572343625 Test RE 0.32683392169425596\n",
      "90 Train Loss 2.7913127 Test MSE 562.6825734731791 Test RE 0.32823500665697714\n",
      "91 Train Loss 2.7744122 Test MSE 585.1965843125483 Test RE 0.33473725929024617\n",
      "92 Train Loss 2.7391372 Test MSE 584.5849293562884 Test RE 0.3345622777222209\n",
      "93 Train Loss 2.7031887 Test MSE 591.8660842460633 Test RE 0.33663935948218177\n",
      "94 Train Loss 2.687899 Test MSE 599.5547255240684 Test RE 0.33881886230528646\n",
      "95 Train Loss 2.6734264 Test MSE 616.7222652865659 Test RE 0.3436354647260253\n",
      "96 Train Loss 2.666289 Test MSE 627.0812999893308 Test RE 0.3465094551833216\n",
      "97 Train Loss 2.6604528 Test MSE 619.4894071067556 Test RE 0.3444055227257052\n",
      "98 Train Loss 2.65878 Test MSE 621.8680571902207 Test RE 0.34506609523369997\n",
      "99 Train Loss 2.6309462 Test MSE 625.8599276218187 Test RE 0.34617184078580354\n",
      "Training time: 68.51\n",
      "Training time: 68.51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.767467 Test MSE 5218.289043795572 Test RE 0.9995792457432063\n",
      "1 Train Loss 47.766663 Test MSE 5216.33249022413 Test RE 0.9993918362606806\n",
      "2 Train Loss 47.747005 Test MSE 5158.200718315839 Test RE 0.99380753101274\n",
      "3 Train Loss 47.74459 Test MSE 5165.172852814558 Test RE 0.9944789492389414\n",
      "4 Train Loss 47.740337 Test MSE 5163.230642010044 Test RE 0.9942919594305646\n",
      "5 Train Loss 47.681576 Test MSE 5047.218339712777 Test RE 0.9830581564931334\n",
      "6 Train Loss 47.381878 Test MSE 4781.069252124668 Test RE 0.9567879164560587\n",
      "7 Train Loss 46.850075 Test MSE 4766.767900612809 Test RE 0.9553558510018285\n",
      "8 Train Loss 45.469128 Test MSE 4682.011958122483 Test RE 0.9468243621576856\n",
      "9 Train Loss 44.557312 Test MSE 4510.282043583845 Test RE 0.9292980268198218\n",
      "10 Train Loss 39.7893 Test MSE 4236.105512733144 Test RE 0.9006095526515957\n",
      "11 Train Loss 33.873573 Test MSE 2845.718831575284 Test RE 0.7381577071267779\n",
      "12 Train Loss 29.52197 Test MSE 2361.4629235268803 Test RE 0.6724248121385549\n",
      "13 Train Loss 27.62345 Test MSE 2157.2211197732927 Test RE 0.6426884519515162\n",
      "14 Train Loss 20.380768 Test MSE 1094.647441006994 Test RE 0.4578152949626885\n",
      "15 Train Loss 18.840288 Test MSE 832.1734135150275 Test RE 0.39917201197931995\n",
      "16 Train Loss 17.188715 Test MSE 708.9292180237667 Test RE 0.3684296746836141\n",
      "17 Train Loss 14.281705 Test MSE 598.1238044060386 Test RE 0.33841430149972895\n",
      "18 Train Loss 13.228987 Test MSE 627.4501991216368 Test RE 0.3466113624187737\n",
      "19 Train Loss 13.181516 Test MSE 602.8227552439998 Test RE 0.3397410177788503\n",
      "20 Train Loss 12.48356 Test MSE 579.186347503784 Test RE 0.33301387042821184\n",
      "21 Train Loss 12.136172 Test MSE 594.5537414821426 Test RE 0.3374028315082514\n",
      "22 Train Loss 12.028487 Test MSE 573.0254458743748 Test RE 0.33123797317540205\n",
      "23 Train Loss 11.785509 Test MSE 643.7506363212009 Test RE 0.35108477816037426\n",
      "24 Train Loss 11.520156 Test MSE 623.1550532472496 Test RE 0.34542297895169866\n",
      "25 Train Loss 11.44222 Test MSE 589.9657112916982 Test RE 0.33609848148685906\n",
      "26 Train Loss 11.246924 Test MSE 578.8069453507039 Test RE 0.3329047804281875\n",
      "27 Train Loss 10.942809 Test MSE 528.3065636656426 Test RE 0.3180505624043943\n",
      "28 Train Loss 10.519712 Test MSE 490.2935354142945 Test RE 0.3063946997063772\n",
      "29 Train Loss 10.435237 Test MSE 501.0268829788098 Test RE 0.3097302899759919\n",
      "30 Train Loss 10.047144 Test MSE 503.26265627686604 Test RE 0.310420588160844\n",
      "31 Train Loss 9.736235 Test MSE 521.8339430576913 Test RE 0.31609623790893265\n",
      "32 Train Loss 9.664168 Test MSE 539.3893734994313 Test RE 0.3213692785075661\n",
      "33 Train Loss 8.3727 Test MSE 777.5040567182772 Test RE 0.3858375547020997\n",
      "34 Train Loss 6.062158 Test MSE 971.1826307085753 Test RE 0.4312246893216955\n",
      "35 Train Loss 5.57493 Test MSE 742.8404770209431 Test RE 0.3771385654548731\n",
      "36 Train Loss 5.506714 Test MSE 745.1850795175778 Test RE 0.3777332714678892\n",
      "37 Train Loss 5.3981175 Test MSE 808.0590679590523 Test RE 0.39334598250380465\n",
      "38 Train Loss 5.250253 Test MSE 791.9784892660788 Test RE 0.389412472712501\n",
      "39 Train Loss 5.2108784 Test MSE 784.6248940207305 Test RE 0.38760039072825153\n",
      "40 Train Loss 5.1772604 Test MSE 781.9653597228387 Test RE 0.38694293546179537\n",
      "41 Train Loss 5.1380796 Test MSE 750.9263414139057 Test RE 0.37918559828107895\n",
      "42 Train Loss 5.0777845 Test MSE 727.9367011366814 Test RE 0.3733360883180794\n",
      "43 Train Loss 4.962826 Test MSE 745.4926802308756 Test RE 0.37781122460929606\n",
      "44 Train Loss 4.904591 Test MSE 695.6217608347483 Test RE 0.3649553582987138\n",
      "45 Train Loss 4.893704 Test MSE 697.8539744677696 Test RE 0.36554045056411266\n",
      "46 Train Loss 4.8580523 Test MSE 713.5646978907297 Test RE 0.36963223878070106\n",
      "47 Train Loss 4.8039002 Test MSE 711.9900251181336 Test RE 0.36922416696097404\n",
      "48 Train Loss 4.673528 Test MSE 708.6979569068617 Test RE 0.36836957671781584\n",
      "49 Train Loss 4.5484567 Test MSE 726.8250979758157 Test RE 0.3730509260715735\n",
      "50 Train Loss 4.4841475 Test MSE 732.508135958659 Test RE 0.3745065269612036\n",
      "51 Train Loss 4.453277 Test MSE 703.6391785165918 Test RE 0.36705248709256066\n",
      "52 Train Loss 4.397931 Test MSE 700.4894550481508 Test RE 0.366230041043771\n",
      "53 Train Loss 4.3148284 Test MSE 713.4088495582128 Test RE 0.36959187123308557\n",
      "54 Train Loss 4.1908393 Test MSE 730.7906902483621 Test RE 0.3740672334917308\n",
      "55 Train Loss 4.0602646 Test MSE 817.1371912295241 Test RE 0.3955493301674533\n",
      "56 Train Loss 3.9942596 Test MSE 832.0977140068611 Test RE 0.39915385602065545\n",
      "57 Train Loss 3.9740195 Test MSE 824.862008375992 Test RE 0.3974145975928911\n",
      "58 Train Loss 3.947112 Test MSE 823.3218258039791 Test RE 0.3970433979121806\n",
      "59 Train Loss 3.9321728 Test MSE 839.2516379004821 Test RE 0.40086603775019297\n",
      "60 Train Loss 3.8434458 Test MSE 940.1442610695101 Test RE 0.42427790364689066\n",
      "61 Train Loss 3.7397397 Test MSE 872.1717960754866 Test RE 0.4086525224068955\n",
      "62 Train Loss 3.6900423 Test MSE 870.5614746559751 Test RE 0.4082750933588725\n",
      "63 Train Loss 3.634031 Test MSE 850.8470180423284 Test RE 0.4036257873883295\n",
      "64 Train Loss 3.5672746 Test MSE 837.4614761218285 Test RE 0.4004382768071367\n",
      "65 Train Loss 3.5390904 Test MSE 842.9618340175048 Test RE 0.40175114264838013\n",
      "66 Train Loss 3.485767 Test MSE 896.5123054010555 Test RE 0.41431560602975986\n",
      "67 Train Loss 3.4448707 Test MSE 860.603964782729 Test RE 0.4059334463828558\n",
      "68 Train Loss 3.429355 Test MSE 834.6526492514005 Test RE 0.39976618231965755\n",
      "69 Train Loss 3.4004145 Test MSE 827.3822584113916 Test RE 0.39802125680381345\n",
      "70 Train Loss 3.1890454 Test MSE 854.0810813981615 Test RE 0.40439214919300054\n",
      "71 Train Loss 2.954903 Test MSE 894.0889354324634 Test RE 0.41375525709926847\n",
      "72 Train Loss 2.9247377 Test MSE 908.7725363114132 Test RE 0.4171389672985544\n",
      "73 Train Loss 2.9094913 Test MSE 935.2825617890451 Test RE 0.42317946308346566\n",
      "74 Train Loss 2.8999588 Test MSE 934.9553510074679 Test RE 0.423105431447704\n",
      "75 Train Loss 2.8924992 Test MSE 942.7775199590005 Test RE 0.4248716701483823\n",
      "76 Train Loss 2.8862271 Test MSE 936.2779517053084 Test RE 0.4234045910673824\n",
      "77 Train Loss 2.8814282 Test MSE 925.680248476911 Test RE 0.42100151944137193\n",
      "78 Train Loss 2.8454907 Test MSE 943.0079829521345 Test RE 0.4249235971467817\n",
      "79 Train Loss 2.7787187 Test MSE 968.548883514753 Test RE 0.4306395739038426\n",
      "80 Train Loss 2.763823 Test MSE 945.1378692830008 Test RE 0.4254031946271777\n",
      "81 Train Loss 2.6993716 Test MSE 1031.126370166111 Test RE 0.44433355518278794\n",
      "82 Train Loss 2.6736436 Test MSE 1050.1527920107865 Test RE 0.4484142550814024\n",
      "83 Train Loss 2.6406653 Test MSE 1049.832891896001 Test RE 0.448345951355135\n",
      "84 Train Loss 2.6319652 Test MSE 1071.45584517648 Test RE 0.4529396121680501\n",
      "85 Train Loss 2.604759 Test MSE 1055.8326809041605 Test RE 0.44962527341105796\n",
      "86 Train Loss 2.5558312 Test MSE 1018.9862618572475 Test RE 0.44171009926527594\n",
      "87 Train Loss 2.5331569 Test MSE 1045.890120359621 Test RE 0.4475032512841211\n",
      "88 Train Loss 2.4930134 Test MSE 1039.8818258290667 Test RE 0.44621602049129633\n",
      "89 Train Loss 2.4816504 Test MSE 1030.3737382499623 Test RE 0.44417136329668133\n",
      "90 Train Loss 2.4739358 Test MSE 1021.3811661452861 Test RE 0.44222886611055806\n",
      "91 Train Loss 2.4543736 Test MSE 1015.0427569411058 Test RE 0.4408545555897399\n",
      "92 Train Loss 2.424786 Test MSE 1037.0419573754095 Test RE 0.44560630642842347\n",
      "93 Train Loss 2.3400307 Test MSE 1091.3971735865616 Test RE 0.4571351086773906\n",
      "94 Train Loss 2.3286414 Test MSE 1088.6700155443825 Test RE 0.4565636121194368\n",
      "95 Train Loss 2.3144684 Test MSE 1119.1726748191454 Test RE 0.46291549043527697\n",
      "96 Train Loss 2.293931 Test MSE 1148.0813547147957 Test RE 0.4688560200069544\n",
      "97 Train Loss 2.2714639 Test MSE 1172.9502562368966 Test RE 0.4739068235250812\n",
      "98 Train Loss 2.2675147 Test MSE 1162.5851255582181 Test RE 0.47180826641563217\n",
      "99 Train Loss 2.2458022 Test MSE 1157.1307961889563 Test RE 0.47070020858986944\n",
      "Training time: 67.74\n",
      "Training time: 67.74\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.770065 Test MSE 5223.797661906716 Test RE 1.0001067029129378\n",
      "1 Train Loss 47.748383 Test MSE 5177.246390263638 Test RE 0.9956405628846065\n",
      "2 Train Loss 47.700153 Test MSE 5067.736903803895 Test RE 0.9850543533740684\n",
      "3 Train Loss 47.497715 Test MSE 4858.461411834619 Test RE 0.9645006919129846\n",
      "4 Train Loss 46.063244 Test MSE 4991.506745467653 Test RE 0.9776175646666522\n",
      "5 Train Loss 37.97675 Test MSE 4543.129478206785 Test RE 0.9326758289681283\n",
      "6 Train Loss 34.745377 Test MSE 4297.908440096958 Test RE 0.9071555132391553\n",
      "7 Train Loss 32.70767 Test MSE 4457.632074008714 Test RE 0.9238581077048926\n",
      "8 Train Loss 31.650553 Test MSE 4585.611131915883 Test RE 0.9370262904062169\n",
      "9 Train Loss 30.22256 Test MSE 4893.29248752734 Test RE 0.9679518462387207\n",
      "10 Train Loss 28.689322 Test MSE 5267.418083209872 Test RE 1.0042736314477345\n",
      "11 Train Loss 28.43971 Test MSE 5405.078831682399 Test RE 1.017312031642028\n",
      "12 Train Loss 27.473633 Test MSE 5509.997162846097 Test RE 1.027138131538264\n",
      "13 Train Loss 27.44064 Test MSE 5541.842695556303 Test RE 1.0301020745153078\n",
      "14 Train Loss 27.193054 Test MSE 5799.260540313773 Test RE 1.0537545792550929\n",
      "15 Train Loss 27.063557 Test MSE 5901.452412038618 Test RE 1.062998420942723\n",
      "16 Train Loss 25.932892 Test MSE 6157.974625998586 Test RE 1.0858556919177385\n",
      "17 Train Loss 23.183594 Test MSE 6822.505875707709 Test RE 1.1429444520205336\n",
      "18 Train Loss 20.559244 Test MSE 6780.659094907469 Test RE 1.139433856840562\n",
      "19 Train Loss 20.405586 Test MSE 6838.867894911741 Test RE 1.1443141599057751\n",
      "20 Train Loss 20.373219 Test MSE 6918.269736563955 Test RE 1.1509379492141907\n",
      "21 Train Loss 20.01209 Test MSE 7291.646791615328 Test RE 1.1815877403754322\n",
      "22 Train Loss 19.699028 Test MSE 7686.425693066235 Test RE 1.2131524544608798\n",
      "23 Train Loss 19.347872 Test MSE 8646.641300891943 Test RE 1.2866987710941848\n",
      "24 Train Loss 19.197716 Test MSE 9027.003116962282 Test RE 1.3146948475643119\n",
      "25 Train Loss 19.120443 Test MSE 9388.897029878395 Test RE 1.340789044533415\n",
      "26 Train Loss 19.116999 Test MSE 9474.226490697692 Test RE 1.3468680351754445\n",
      "27 Train Loss 19.112684 Test MSE 9522.609220621067 Test RE 1.350302730782926\n",
      "28 Train Loss 19.01309 Test MSE 9661.552248666037 Test RE 1.360118093730592\n",
      "29 Train Loss 18.586708 Test MSE 8273.999416299766 Test RE 1.2586671788727402\n",
      "30 Train Loss 18.274101 Test MSE 5288.650075477159 Test RE 1.0062956169667745\n",
      "31 Train Loss 14.812373 Test MSE 1196.385114949431 Test RE 0.4786176005520788\n",
      "32 Train Loss 14.001662 Test MSE 1075.9213210226585 Test RE 0.4538824825221957\n",
      "33 Train Loss 13.46605 Test MSE 1141.1267760611343 Test RE 0.46743379977912025\n",
      "34 Train Loss 10.1252365 Test MSE 772.5118838106993 Test RE 0.3845968733154878\n",
      "35 Train Loss 7.8039465 Test MSE 441.93794088311614 Test RE 0.2908933603679202\n",
      "36 Train Loss 7.0669723 Test MSE 555.955331403305 Test RE 0.3262669734595737\n",
      "37 Train Loss 6.555941 Test MSE 495.80622662790995 Test RE 0.3081123830454787\n",
      "38 Train Loss 6.485987 Test MSE 527.5723924605554 Test RE 0.31782949308563035\n",
      "39 Train Loss 6.422828 Test MSE 435.77883406963946 Test RE 0.2888592178548969\n",
      "40 Train Loss 6.323515 Test MSE 318.78218884193257 Test RE 0.2470587210187754\n",
      "41 Train Loss 6.2739983 Test MSE 318.10266281338323 Test RE 0.24679526151736728\n",
      "42 Train Loss 6.2576733 Test MSE 295.2557111495689 Test RE 0.23776740513554107\n",
      "43 Train Loss 6.253178 Test MSE 286.7313357965204 Test RE 0.23430995663826254\n",
      "44 Train Loss 6.2527905 Test MSE 285.4934448432653 Test RE 0.2338036221855348\n",
      "45 Train Loss 6.241014 Test MSE 282.1114570468116 Test RE 0.23241466435156147\n",
      "46 Train Loss 6.2190194 Test MSE 283.15475094525044 Test RE 0.23284402131157858\n",
      "47 Train Loss 6.214115 Test MSE 292.07775236502846 Test RE 0.23648434904109544\n",
      "48 Train Loss 6.1968846 Test MSE 338.39862763879404 Test RE 0.2545466942051\n",
      "49 Train Loss 6.1861706 Test MSE 348.8089934562057 Test RE 0.2584324243197631\n",
      "50 Train Loss 6.1774874 Test MSE 330.68208252212384 Test RE 0.25162772822700913\n",
      "51 Train Loss 6.170683 Test MSE 326.2101256385626 Test RE 0.24992050136575775\n",
      "52 Train Loss 6.16384 Test MSE 337.5730301108676 Test RE 0.2542359933931918\n",
      "53 Train Loss 6.1567082 Test MSE 332.7740050041586 Test RE 0.2524223824620167\n",
      "54 Train Loss 6.1478724 Test MSE 327.29195668548164 Test RE 0.25033457184464075\n",
      "55 Train Loss 6.1384115 Test MSE 326.8994848010782 Test RE 0.25018443257189793\n",
      "56 Train Loss 6.125722 Test MSE 327.33962363611346 Test RE 0.25035280060186343\n",
      "57 Train Loss 6.1068497 Test MSE 330.42810988162415 Test RE 0.2515310812704036\n",
      "58 Train Loss 6.084893 Test MSE 337.5306777193696 Test RE 0.25422004448864033\n",
      "59 Train Loss 6.0615287 Test MSE 343.69780828589023 Test RE 0.2565319993957507\n",
      "60 Train Loss 6.0018363 Test MSE 325.63358913524104 Test RE 0.24969955173610683\n",
      "61 Train Loss 5.9179387 Test MSE 321.0115446731734 Test RE 0.2479211001281505\n",
      "62 Train Loss 5.8324943 Test MSE 293.271118057945 Test RE 0.23696696818917204\n",
      "63 Train Loss 5.7601595 Test MSE 297.9774709543288 Test RE 0.23886079838475607\n",
      "64 Train Loss 5.730144 Test MSE 324.1507794145393 Test RE 0.24913038534918303\n",
      "65 Train Loss 5.7050095 Test MSE 329.7286837309854 Test RE 0.2512647289127788\n",
      "66 Train Loss 5.6638165 Test MSE 357.9365720729663 Test RE 0.2617918981193079\n",
      "67 Train Loss 5.601243 Test MSE 400.3512527060299 Test RE 0.27686863562342234\n",
      "68 Train Loss 5.567822 Test MSE 434.7769039192778 Test RE 0.28852695836553727\n",
      "69 Train Loss 5.5302916 Test MSE 450.5571929738897 Test RE 0.2937163539098369\n",
      "70 Train Loss 5.514811 Test MSE 448.2729438415139 Test RE 0.2929708615904755\n",
      "71 Train Loss 5.5066214 Test MSE 461.7968813756371 Test RE 0.2973573395815044\n",
      "72 Train Loss 5.504865 Test MSE 468.74016461505005 Test RE 0.2995844371174693\n",
      "73 Train Loss 5.5046597 Test MSE 472.5066911199686 Test RE 0.30078567299487474\n",
      "74 Train Loss 5.5045567 Test MSE 473.8621889260142 Test RE 0.3012168016326159\n",
      "75 Train Loss 5.5045567 Test MSE 473.8621889260142 Test RE 0.3012168016326159\n",
      "76 Train Loss 5.5045524 Test MSE 473.9630916339593 Test RE 0.3012488699996086\n",
      "77 Train Loss 5.5045524 Test MSE 473.9630916339593 Test RE 0.3012488699996086\n",
      "78 Train Loss 5.5045524 Test MSE 473.9630916339593 Test RE 0.3012488699996086\n",
      "79 Train Loss 5.5045524 Test MSE 473.9630916339593 Test RE 0.3012488699996086\n",
      "80 Train Loss 5.5045395 Test MSE 474.0084349400999 Test RE 0.3012632796586043\n",
      "81 Train Loss 5.504375 Test MSE 473.69332312409796 Test RE 0.3011631259539648\n",
      "82 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "83 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "84 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "85 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "86 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "87 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "88 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "89 Train Loss 5.5043015 Test MSE 473.71229674706814 Test RE 0.30116915738623007\n",
      "90 Train Loss 5.504216 Test MSE 473.7973075900761 Test RE 0.30119617958471934\n",
      "91 Train Loss 5.504216 Test MSE 473.7973075900761 Test RE 0.30119617958471934\n",
      "92 Train Loss 5.504216 Test MSE 473.7973075900761 Test RE 0.30119617958471934\n",
      "93 Train Loss 5.504216 Test MSE 473.7973075900761 Test RE 0.30119617958471934\n",
      "94 Train Loss 5.504216 Test MSE 473.7973075900761 Test RE 0.30119617958471934\n",
      "95 Train Loss 5.5027666 Test MSE 482.4213260030075 Test RE 0.303924991838172\n",
      "96 Train Loss 5.4887075 Test MSE 496.02217986814844 Test RE 0.3081794764180265\n",
      "97 Train Loss 5.459278 Test MSE 512.2403951951485 Test RE 0.31317715650851347\n",
      "98 Train Loss 5.4543676 Test MSE 508.44606354985683 Test RE 0.3120150979103262\n",
      "99 Train Loss 5.4432793 Test MSE 523.0089434203162 Test RE 0.3164519107802774\n",
      "Training time: 58.73\n",
      "Training time: 58.73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.76783 Test MSE 5218.842629749033 Test RE 0.9996322648793863\n",
      "1 Train Loss 47.74979 Test MSE 5177.001587399461 Test RE 0.9956170234850491\n",
      "2 Train Loss 47.739014 Test MSE 5164.190977830743 Test RE 0.9943844218688755\n",
      "3 Train Loss 47.64729 Test MSE 4970.496479927702 Test RE 0.9755578995644333\n",
      "4 Train Loss 47.545902 Test MSE 4894.786233307367 Test RE 0.9680995753661755\n",
      "5 Train Loss 47.230297 Test MSE 4654.717446847316 Test RE 0.9440604988076011\n",
      "6 Train Loss 47.112965 Test MSE 4592.096841578183 Test RE 0.9376887029987686\n",
      "7 Train Loss 47.047855 Test MSE 4546.755807049152 Test RE 0.933047985939243\n",
      "8 Train Loss 46.99589 Test MSE 4528.787941698181 Test RE 0.9312025518586636\n",
      "9 Train Loss 46.888954 Test MSE 4496.264857673266 Test RE 0.9278528533698556\n",
      "10 Train Loss 46.289936 Test MSE 4421.333215466782 Test RE 0.9200888931157114\n",
      "11 Train Loss 45.411118 Test MSE 4265.6225295377535 Test RE 0.9037418117509579\n",
      "12 Train Loss 44.627354 Test MSE 4211.957559461773 Test RE 0.8980389179648331\n",
      "13 Train Loss 41.63641 Test MSE 4365.195547333608 Test RE 0.9142290487149126\n",
      "14 Train Loss 40.102932 Test MSE 4230.14271349407 Test RE 0.8999754743636974\n",
      "15 Train Loss 38.37288 Test MSE 4206.5061501819455 Test RE 0.8974575774957799\n",
      "16 Train Loss 37.54294 Test MSE 4194.6808726262125 Test RE 0.8961952289298645\n",
      "17 Train Loss 35.624012 Test MSE 4152.893314088377 Test RE 0.8917200914520672\n",
      "18 Train Loss 31.147007 Test MSE 3415.13162607376 Test RE 0.808643105577697\n",
      "19 Train Loss 30.477072 Test MSE 3627.6508702151245 Test RE 0.833423815249205\n",
      "20 Train Loss 29.516848 Test MSE 3227.1045361882575 Test RE 0.7860672119679756\n",
      "21 Train Loss 28.975222 Test MSE 3250.180449075038 Test RE 0.7888726536415694\n",
      "22 Train Loss 27.067604 Test MSE 2574.837990273042 Test RE 0.7021471199612492\n",
      "23 Train Loss 20.498167 Test MSE 1344.2993388504226 Test RE 0.5073423978735784\n",
      "24 Train Loss 18.842113 Test MSE 1014.0055178350283 Test RE 0.4406292505671296\n",
      "25 Train Loss 16.37319 Test MSE 1005.0288300941052 Test RE 0.43867453530178524\n",
      "26 Train Loss 15.779198 Test MSE 845.8968808180388 Test RE 0.40244994877166745\n",
      "27 Train Loss 14.999826 Test MSE 869.1512738683869 Test RE 0.40794428202347816\n",
      "28 Train Loss 14.1654625 Test MSE 672.4909687338378 Test RE 0.3588363188978048\n",
      "29 Train Loss 13.448771 Test MSE 641.6161545288084 Test RE 0.3505022495858238\n",
      "30 Train Loss 12.599315 Test MSE 597.0824214294778 Test RE 0.3381195695217519\n",
      "31 Train Loss 12.46375 Test MSE 585.8814759813911 Test RE 0.33493308384441295\n",
      "32 Train Loss 12.457456 Test MSE 597.4259167408109 Test RE 0.33821681387491365\n",
      "33 Train Loss 12.429571 Test MSE 573.5353510971818 Test RE 0.33138531603481286\n",
      "34 Train Loss 12.370407 Test MSE 606.0403406982671 Test RE 0.34064650032116306\n",
      "35 Train Loss 12.26639 Test MSE 606.9892914499155 Test RE 0.3409130917419307\n",
      "36 Train Loss 12.239992 Test MSE 597.0108468400296 Test RE 0.33809930306120317\n",
      "37 Train Loss 12.235617 Test MSE 599.5264551307725 Test RE 0.33881087416425365\n",
      "38 Train Loss 12.226459 Test MSE 588.5902915954324 Test RE 0.3357064703837762\n",
      "39 Train Loss 12.208303 Test MSE 577.8025723004922 Test RE 0.3326158189981474\n",
      "40 Train Loss 12.166685 Test MSE 571.5426169277977 Test RE 0.330809120126913\n",
      "41 Train Loss 12.11825 Test MSE 580.8517241421921 Test RE 0.3334922962654408\n",
      "42 Train Loss 12.0507 Test MSE 551.8205741287007 Test RE 0.325051451006089\n",
      "43 Train Loss 12.016214 Test MSE 517.9276435821297 Test RE 0.31491091252750003\n",
      "44 Train Loss 12.009875 Test MSE 513.4732343680653 Test RE 0.3135538009890328\n",
      "45 Train Loss 11.986104 Test MSE 508.93642747035443 Test RE 0.312165521018584\n",
      "46 Train Loss 11.93986 Test MSE 511.66697535528345 Test RE 0.3130018166852948\n",
      "47 Train Loss 11.917421 Test MSE 492.9193754656985 Test RE 0.307214075323084\n",
      "48 Train Loss 11.907521 Test MSE 493.83754651686877 Test RE 0.3075000691893707\n",
      "49 Train Loss 11.840413 Test MSE 496.5168526154366 Test RE 0.3083331086597599\n",
      "50 Train Loss 11.677523 Test MSE 535.2875380760012 Test RE 0.32014500562585396\n",
      "51 Train Loss 11.62 Test MSE 573.2069586610161 Test RE 0.33129043085201376\n",
      "52 Train Loss 11.561966 Test MSE 553.2325176408928 Test RE 0.3254670399694652\n",
      "53 Train Loss 11.50158 Test MSE 550.4443478559128 Test RE 0.3246458630011005\n",
      "54 Train Loss 11.463706 Test MSE 550.5413881587078 Test RE 0.32467447837757607\n",
      "55 Train Loss 11.41198 Test MSE 562.9298858519356 Test RE 0.32830713228012065\n",
      "56 Train Loss 11.230243 Test MSE 594.5994505288036 Test RE 0.33741580095431495\n",
      "57 Train Loss 11.098245 Test MSE 637.6415781692833 Test RE 0.3494149467755227\n",
      "58 Train Loss 10.959179 Test MSE 672.5064718358282 Test RE 0.35884045504553536\n",
      "59 Train Loss 10.860621 Test MSE 717.6609942037248 Test RE 0.3706916776786302\n",
      "60 Train Loss 10.784295 Test MSE 728.4558916274292 Test RE 0.3734692029122803\n",
      "61 Train Loss 10.6997595 Test MSE 671.0118308112504 Test RE 0.3584414730125189\n",
      "62 Train Loss 10.655542 Test MSE 624.6666999891756 Test RE 0.3458416879388534\n",
      "63 Train Loss 10.573332 Test MSE 687.9584108941962 Test RE 0.36293951706090577\n",
      "64 Train Loss 10.445717 Test MSE 626.334849305473 Test RE 0.3463031587766494\n",
      "65 Train Loss 10.395414 Test MSE 605.9895903677258 Test RE 0.3406322370095735\n",
      "66 Train Loss 10.343239 Test MSE 589.7326447615344 Test RE 0.33603208691229747\n",
      "67 Train Loss 10.214344 Test MSE 697.1879325585113 Test RE 0.36536597038061963\n",
      "68 Train Loss 10.118928 Test MSE 740.292855398792 Test RE 0.37649129891724464\n",
      "69 Train Loss 10.066875 Test MSE 795.5720468669718 Test RE 0.39029494134251524\n",
      "70 Train Loss 10.038779 Test MSE 788.7969994116294 Test RE 0.3886295230652265\n",
      "71 Train Loss 10.021184 Test MSE 762.2173826017819 Test RE 0.3820257078224553\n",
      "72 Train Loss 10.015144 Test MSE 738.3321579937692 Test RE 0.3759923916707626\n",
      "73 Train Loss 9.965184 Test MSE 782.2197044040415 Test RE 0.38700585952536826\n",
      "74 Train Loss 9.834389 Test MSE 781.3494384643454 Test RE 0.3867905160961412\n",
      "75 Train Loss 9.7520685 Test MSE 790.0717871794748 Test RE 0.3889434315613384\n",
      "76 Train Loss 9.669594 Test MSE 780.5521057616999 Test RE 0.3865931143768329\n",
      "77 Train Loss 9.597829 Test MSE 775.8671031955381 Test RE 0.38543117036860064\n",
      "78 Train Loss 9.561552 Test MSE 731.7031462470155 Test RE 0.3743006884468847\n",
      "79 Train Loss 9.55682 Test MSE 733.0624277163919 Test RE 0.37464819543934963\n",
      "80 Train Loss 9.547777 Test MSE 725.6433804881801 Test RE 0.3727475379959795\n",
      "81 Train Loss 9.525792 Test MSE 735.2624026877291 Test RE 0.37520994786598927\n",
      "82 Train Loss 9.489252 Test MSE 714.811394816628 Test RE 0.3699549973714018\n",
      "83 Train Loss 9.389946 Test MSE 743.6996437123346 Test RE 0.3773566009996012\n",
      "84 Train Loss 9.263099 Test MSE 730.4030372198299 Test RE 0.3739680070421187\n",
      "85 Train Loss 9.214835 Test MSE 732.2075494967174 Test RE 0.3744296792531291\n",
      "86 Train Loss 9.16847 Test MSE 760.3168768897867 Test RE 0.38154914090195013\n",
      "87 Train Loss 9.116611 Test MSE 760.4294427960343 Test RE 0.3815773842808406\n",
      "88 Train Loss 9.07915 Test MSE 775.1552188475564 Test RE 0.3852543067124664\n",
      "89 Train Loss 9.054575 Test MSE 792.3761703355594 Test RE 0.38951022949197495\n",
      "90 Train Loss 9.035237 Test MSE 817.0289901169249 Test RE 0.3955231409944679\n",
      "91 Train Loss 9.005077 Test MSE 851.3276122272604 Test RE 0.4037397637071524\n",
      "92 Train Loss 8.996671 Test MSE 879.7786165755388 Test RE 0.41043072587796775\n",
      "93 Train Loss 8.996395 Test MSE 880.3611030138724 Test RE 0.4105665729929075\n",
      "94 Train Loss 8.995381 Test MSE 885.044474883541 Test RE 0.4116571967274862\n",
      "95 Train Loss 8.992374 Test MSE 891.9342892690923 Test RE 0.41325640631968513\n",
      "96 Train Loss 8.988243 Test MSE 909.6394175501954 Test RE 0.4173378750208583\n",
      "97 Train Loss 8.980107 Test MSE 927.8085284194136 Test RE 0.42148521490041785\n",
      "98 Train Loss 8.961601 Test MSE 966.0105797679953 Test RE 0.430074908981786\n",
      "99 Train Loss 8.94393 Test MSE 961.8568262286229 Test RE 0.4291492722873201\n",
      "Training time: 70.22\n",
      "Training time: 70.22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.767876 Test MSE 5218.908471292913 Test RE 0.9996385705997071\n",
      "1 Train Loss 47.746582 Test MSE 5171.829691958542 Test RE 0.9951195816997226\n",
      "2 Train Loss 47.741287 Test MSE 5170.917134317157 Test RE 0.9950317845279074\n",
      "3 Train Loss 47.628555 Test MSE 5023.769856755143 Test RE 0.9807719409757207\n",
      "4 Train Loss 46.75833 Test MSE 4828.66510305399 Test RE 0.961538565008085\n",
      "5 Train Loss 42.615795 Test MSE 5353.112755856615 Test RE 1.0124098463896714\n",
      "6 Train Loss 32.20848 Test MSE 4514.121198102381 Test RE 0.9296934521830459\n",
      "7 Train Loss 30.400911 Test MSE 4498.321350509616 Test RE 0.9280650188753421\n",
      "8 Train Loss 29.884811 Test MSE 4431.282521023376 Test RE 0.9211235472503629\n",
      "9 Train Loss 28.537762 Test MSE 4803.81419301845 Test RE 0.9590610757325235\n",
      "10 Train Loss 28.198483 Test MSE 4739.111839702071 Test RE 0.9525804049406429\n",
      "11 Train Loss 27.232977 Test MSE 5036.601042293502 Test RE 0.9820236346110255\n",
      "12 Train Loss 26.788567 Test MSE 5052.623025744843 Test RE 0.9835843571382633\n",
      "13 Train Loss 25.985365 Test MSE 5464.031160264386 Test RE 1.022844815903088\n",
      "14 Train Loss 25.244469 Test MSE 5662.158152988174 Test RE 1.0412239822363234\n",
      "15 Train Loss 24.940573 Test MSE 5828.228557944614 Test RE 1.056383117555064\n",
      "16 Train Loss 24.519806 Test MSE 5855.140844018667 Test RE 1.0588192729735337\n",
      "17 Train Loss 24.16183 Test MSE 6127.046343016617 Test RE 1.0831254170576012\n",
      "18 Train Loss 23.966682 Test MSE 6049.654005348507 Test RE 1.0762630567746045\n",
      "19 Train Loss 23.75285 Test MSE 6262.601103533743 Test RE 1.095041402538112\n",
      "20 Train Loss 23.693659 Test MSE 6341.009470238039 Test RE 1.101875091176639\n",
      "21 Train Loss 22.859663 Test MSE 7141.246602664503 Test RE 1.1693383142728977\n",
      "22 Train Loss 22.26724 Test MSE 7178.623329589958 Test RE 1.1723944333203524\n",
      "23 Train Loss 22.0172 Test MSE 7018.9962789629 Test RE 1.1592862124377745\n",
      "24 Train Loss 21.628202 Test MSE 6646.48476841046 Test RE 1.1281040843039771\n",
      "25 Train Loss 21.401419 Test MSE 6687.053136844124 Test RE 1.131541669822908\n",
      "26 Train Loss 21.228651 Test MSE 6634.839489768159 Test RE 1.1271153777724363\n",
      "27 Train Loss 21.193245 Test MSE 6570.670777240456 Test RE 1.1216516987105294\n",
      "28 Train Loss 21.032066 Test MSE 6812.95799252209 Test RE 1.1421444145428232\n",
      "29 Train Loss 20.860231 Test MSE 6695.232130665718 Test RE 1.1322334576655733\n",
      "30 Train Loss 20.652308 Test MSE 6768.240572444466 Test RE 1.138389963501796\n",
      "31 Train Loss 20.520128 Test MSE 6911.4550806320785 Test RE 1.150370959286204\n",
      "32 Train Loss 20.232327 Test MSE 6929.13691277052 Test RE 1.151841537695987\n",
      "33 Train Loss 19.99226 Test MSE 7021.645347584032 Test RE 1.1595049573194118\n",
      "34 Train Loss 19.84117 Test MSE 7037.895479978433 Test RE 1.1608458980249468\n",
      "35 Train Loss 19.028238 Test MSE 6918.756466961505 Test RE 1.1509784352500196\n",
      "36 Train Loss 18.532724 Test MSE 7098.426980885869 Test RE 1.1658273091140139\n",
      "37 Train Loss 18.011612 Test MSE 7433.783872155404 Test RE 1.1930485846959331\n",
      "38 Train Loss 17.755133 Test MSE 7270.264319641052 Test RE 1.179853988245878\n",
      "39 Train Loss 17.668724 Test MSE 7353.800061990255 Test RE 1.186612922615665\n",
      "40 Train Loss 17.398018 Test MSE 7564.511288447618 Test RE 1.2034930935162025\n",
      "41 Train Loss 17.271288 Test MSE 7739.8684936268355 Test RE 1.2173626010959353\n",
      "42 Train Loss 17.15913 Test MSE 7746.116414312486 Test RE 1.217853853023641\n",
      "43 Train Loss 17.07513 Test MSE 7716.331862294014 Test RE 1.2155102162129057\n",
      "44 Train Loss 16.921139 Test MSE 7741.385815137662 Test RE 1.2174819209489653\n",
      "45 Train Loss 16.718676 Test MSE 8109.772769080542 Test RE 1.2461132316686823\n",
      "46 Train Loss 16.411121 Test MSE 8200.432167696483 Test RE 1.2530590427856112\n",
      "47 Train Loss 16.160257 Test MSE 8482.179321323205 Test RE 1.274403306194092\n",
      "48 Train Loss 16.14359 Test MSE 8544.328381720668 Test RE 1.279063571780793\n",
      "49 Train Loss 16.047754 Test MSE 8428.422970832726 Test RE 1.2703585816129717\n",
      "50 Train Loss 15.987565 Test MSE 8546.277801444643 Test RE 1.279209474971687\n",
      "51 Train Loss 15.883227 Test MSE 8661.839297617644 Test RE 1.2878290746204988\n",
      "52 Train Loss 15.772438 Test MSE 8716.128251652202 Test RE 1.2918585701663636\n",
      "53 Train Loss 15.729604 Test MSE 8838.327521892423 Test RE 1.3008829158915196\n",
      "54 Train Loss 15.690253 Test MSE 8908.030636371237 Test RE 1.3060025222163798\n",
      "55 Train Loss 15.517297 Test MSE 8832.490686969857 Test RE 1.3004532931580108\n",
      "56 Train Loss 15.3422985 Test MSE 8675.624166208307 Test RE 1.288853423866545\n",
      "57 Train Loss 15.154608 Test MSE 8793.83521872947 Test RE 1.297604450469917\n",
      "58 Train Loss 15.082426 Test MSE 8749.138564933288 Test RE 1.2943025656239318\n",
      "59 Train Loss 15.040638 Test MSE 8741.58700971972 Test RE 1.293743875922182\n",
      "60 Train Loss 14.976691 Test MSE 8743.317041815904 Test RE 1.2938718908751643\n",
      "61 Train Loss 14.859118 Test MSE 8608.028281037652 Test RE 1.2838225724087597\n",
      "62 Train Loss 14.637525 Test MSE 8652.120743502865 Test RE 1.2871064019424183\n",
      "63 Train Loss 14.459309 Test MSE 8820.219874378918 Test RE 1.2995496315823991\n",
      "64 Train Loss 14.39956 Test MSE 8893.503828326591 Test RE 1.304937203195797\n",
      "65 Train Loss 14.393667 Test MSE 8874.855555912702 Test RE 1.303568361686278\n",
      "66 Train Loss 14.388884 Test MSE 8888.36706675487 Test RE 1.3045602921605526\n",
      "67 Train Loss 14.376731 Test MSE 8890.341097736455 Test RE 1.3047051500093412\n",
      "68 Train Loss 14.35335 Test MSE 8947.642330635303 Test RE 1.3089030280337746\n",
      "69 Train Loss 14.291838 Test MSE 9034.606192991392 Test RE 1.3152483879192798\n",
      "70 Train Loss 14.229695 Test MSE 9211.84536434166 Test RE 1.3280868733003672\n",
      "71 Train Loss 14.221972 Test MSE 9253.375144124999 Test RE 1.3310772150241537\n",
      "72 Train Loss 14.218912 Test MSE 9220.91719423044 Test RE 1.3287406626830818\n",
      "73 Train Loss 14.201719 Test MSE 9247.142812201115 Test RE 1.330628886052621\n",
      "74 Train Loss 14.142966 Test MSE 9195.362945187626 Test RE 1.3268981926286356\n",
      "75 Train Loss 14.09708 Test MSE 9111.20668174772 Test RE 1.3208123282129332\n",
      "76 Train Loss 14.077863 Test MSE 8931.76783018145 Test RE 1.3077414144457917\n",
      "77 Train Loss 14.057521 Test MSE 8677.612606834055 Test RE 1.2890011170831008\n",
      "78 Train Loss 14.037047 Test MSE 8608.645393814912 Test RE 1.2838685904449691\n",
      "79 Train Loss 14.0266695 Test MSE 8640.935302158949 Test RE 1.2862741488073843\n",
      "80 Train Loss 13.973789 Test MSE 8670.347210591844 Test RE 1.288461391160282\n",
      "81 Train Loss 13.958568 Test MSE 8737.710811558909 Test RE 1.2934570078931193\n",
      "82 Train Loss 13.938687 Test MSE 8740.82844708226 Test RE 1.2936877415465355\n",
      "83 Train Loss 13.933649 Test MSE 8724.874890219673 Test RE 1.2925065979572345\n",
      "84 Train Loss 13.927166 Test MSE 8740.40111571201 Test RE 1.2936561175353984\n",
      "85 Train Loss 13.854409 Test MSE 8711.708920828021 Test RE 1.2915310236861683\n",
      "86 Train Loss 13.818627 Test MSE 8745.046304314472 Test RE 1.293999836225199\n",
      "87 Train Loss 13.809322 Test MSE 8737.893388679058 Test RE 1.2934705214109623\n",
      "88 Train Loss 13.791385 Test MSE 8772.692042913442 Test RE 1.296043584868544\n",
      "89 Train Loss 13.720547 Test MSE 8957.530905294598 Test RE 1.3096261018189685\n",
      "90 Train Loss 13.610751 Test MSE 9265.187355909473 Test RE 1.331926524125472\n",
      "91 Train Loss 13.469997 Test MSE 9469.725173037037 Test RE 1.3465480406532893\n",
      "92 Train Loss 13.380174 Test MSE 9616.719897671028 Test RE 1.3569587569699693\n",
      "93 Train Loss 13.321858 Test MSE 9574.434861373966 Test RE 1.3539721740002866\n",
      "94 Train Loss 13.287058 Test MSE 9643.87413977922 Test RE 1.3588731941578331\n",
      "95 Train Loss 13.270186 Test MSE 9687.374078523155 Test RE 1.3619344324591731\n",
      "96 Train Loss 13.258739 Test MSE 9647.07743237994 Test RE 1.3590988559087425\n",
      "97 Train Loss 13.238722 Test MSE 9624.494009031363 Test RE 1.3575071257220508\n",
      "98 Train Loss 13.196133 Test MSE 9553.553841866244 Test RE 1.3524949196508327\n",
      "99 Train Loss 13.096418 Test MSE 9401.141027899745 Test RE 1.3416630167179262\n",
      "Training time: 70.96\n",
      "Training time: 70.96\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.748055 Test MSE 5176.235659271663 Test RE 0.9955433708815806\n",
      "1 Train Loss 47.734097 Test MSE 5135.865900082283 Test RE 0.9916536219797814\n",
      "2 Train Loss 47.584446 Test MSE 4950.0832327021535 Test RE 0.9735525875005132\n",
      "3 Train Loss 47.429935 Test MSE 4855.986230518676 Test RE 0.9642549743878361\n",
      "4 Train Loss 47.161415 Test MSE 4714.638594422149 Test RE 0.9501176112809193\n",
      "5 Train Loss 47.041985 Test MSE 4653.2322226295 Test RE 0.9439098716859365\n",
      "6 Train Loss 46.899723 Test MSE 4622.492242135443 Test RE 0.9407868972375304\n",
      "7 Train Loss 46.0813 Test MSE 4683.961930586013 Test RE 0.9470215091593291\n",
      "8 Train Loss 44.091442 Test MSE 5315.461062671174 Test RE 1.0088431169141623\n",
      "9 Train Loss 42.41078 Test MSE 4719.685265680019 Test RE 0.9506259905210346\n",
      "10 Train Loss 42.20351 Test MSE 4282.8184962426185 Test RE 0.9055616027898192\n",
      "11 Train Loss 41.940872 Test MSE 4068.6551619913034 Test RE 0.8826298402129478\n",
      "12 Train Loss 41.488747 Test MSE 4326.300408159144 Test RE 0.9101469141426323\n",
      "13 Train Loss 40.981377 Test MSE 4364.5202330036345 Test RE 0.9141583284171712\n",
      "14 Train Loss 40.628902 Test MSE 4777.506492732497 Test RE 0.9564313601883764\n",
      "15 Train Loss 40.274326 Test MSE 4652.098505898151 Test RE 0.9437948772527404\n",
      "16 Train Loss 39.37813 Test MSE 4548.63257304058 Test RE 0.9332405333442629\n",
      "17 Train Loss 37.576977 Test MSE 4491.363323152915 Test RE 0.9273469731484546\n",
      "18 Train Loss 30.179516 Test MSE 2524.15554236595 Test RE 0.6952023337239925\n",
      "19 Train Loss 22.823792 Test MSE 1949.7086276586226 Test RE 0.6109955137314559\n",
      "20 Train Loss 21.696127 Test MSE 2098.075438242511 Test RE 0.6338167533363582\n",
      "21 Train Loss 21.536386 Test MSE 2172.5367823919605 Test RE 0.6449658703784752\n",
      "22 Train Loss 21.114592 Test MSE 2295.690970379784 Test RE 0.6629944267900139\n",
      "23 Train Loss 20.009687 Test MSE 1903.120910815691 Test RE 0.6036515988527533\n",
      "24 Train Loss 19.6052 Test MSE 1735.4093902460377 Test RE 0.576440035453546\n",
      "25 Train Loss 17.720974 Test MSE 1699.563165171761 Test RE 0.5704555630217849\n",
      "26 Train Loss 16.866142 Test MSE 1340.23311773842 Test RE 0.5065745150506787\n",
      "27 Train Loss 16.659292 Test MSE 1445.267042841538 Test RE 0.5260502294379166\n",
      "28 Train Loss 16.556246 Test MSE 1289.2397125171426 Test RE 0.4968439456012822\n",
      "29 Train Loss 16.238316 Test MSE 1527.799177094407 Test RE 0.5408617892899663\n",
      "30 Train Loss 15.64806 Test MSE 1569.2380410981702 Test RE 0.5481476777011771\n",
      "31 Train Loss 15.242011 Test MSE 1621.0776821592417 Test RE 0.5571281185238735\n",
      "32 Train Loss 15.229611 Test MSE 1606.938757138352 Test RE 0.5546931815136448\n",
      "33 Train Loss 15.211891 Test MSE 1602.4408080729524 Test RE 0.5539163223997079\n",
      "34 Train Loss 15.080557 Test MSE 1398.0493268085934 Test RE 0.5173856892020462\n",
      "35 Train Loss 14.775119 Test MSE 1090.419500049774 Test RE 0.45693031199847023\n",
      "36 Train Loss 14.771825 Test MSE 1089.382816515738 Test RE 0.4567130539746932\n",
      "37 Train Loss 14.742036 Test MSE 1064.3945883054764 Test RE 0.4514446322738226\n",
      "38 Train Loss 14.660706 Test MSE 959.6596427037045 Test RE 0.4286588360902257\n",
      "39 Train Loss 14.629918 Test MSE 989.0546478998616 Test RE 0.4351743695053083\n",
      "40 Train Loss 14.435219 Test MSE 1128.3809156177767 Test RE 0.4648159591202549\n",
      "41 Train Loss 14.393597 Test MSE 1136.7689221030678 Test RE 0.4665404035393178\n",
      "42 Train Loss 14.178138 Test MSE 1058.0881733289632 Test RE 0.450105266782444\n",
      "43 Train Loss 13.278509 Test MSE 1162.5417464174232 Test RE 0.4717994641233583\n",
      "44 Train Loss 13.196795 Test MSE 1165.8189402254984 Test RE 0.4724639951628047\n",
      "45 Train Loss 12.962339 Test MSE 1238.7258931402594 Test RE 0.4870132449394768\n",
      "46 Train Loss 12.757689 Test MSE 1175.2738928563188 Test RE 0.47437600046366923\n",
      "47 Train Loss 12.593056 Test MSE 1166.5651527109567 Test RE 0.47261517735840974\n",
      "48 Train Loss 12.538071 Test MSE 1150.1718459469982 Test RE 0.46928268560319014\n",
      "49 Train Loss 12.491931 Test MSE 1131.1655172665426 Test RE 0.4653891386740785\n",
      "50 Train Loss 12.424109 Test MSE 1103.8209099943708 Test RE 0.4597296064267501\n",
      "51 Train Loss 12.392566 Test MSE 1104.682059107168 Test RE 0.45990890116306865\n",
      "52 Train Loss 12.305977 Test MSE 1090.267208885694 Test RE 0.4568984027750266\n",
      "53 Train Loss 12.287801 Test MSE 1082.1675875621652 Test RE 0.4551980843484933\n",
      "54 Train Loss 12.274868 Test MSE 1085.498078118173 Test RE 0.45589800748892795\n",
      "55 Train Loss 12.240482 Test MSE 1090.4691912729784 Test RE 0.4569407232060154\n",
      "56 Train Loss 11.728163 Test MSE 1003.6454245079192 Test RE 0.4383725172087846\n",
      "57 Train Loss 11.347034 Test MSE 986.1576861573346 Test RE 0.4345365847282096\n",
      "58 Train Loss 11.041902 Test MSE 948.8838248421755 Test RE 0.426245381611695\n",
      "59 Train Loss 10.8743 Test MSE 945.8062382356696 Test RE 0.4255535832890965\n",
      "60 Train Loss 10.827965 Test MSE 941.0036617437595 Test RE 0.42447177890748816\n",
      "61 Train Loss 10.803535 Test MSE 917.2916332981948 Test RE 0.4190895972726667\n",
      "62 Train Loss 10.791632 Test MSE 930.0322854253166 Test RE 0.4219900171995538\n",
      "63 Train Loss 10.785878 Test MSE 934.9002640194012 Test RE 0.42309296670959895\n",
      "64 Train Loss 10.785622 Test MSE 932.8812887647841 Test RE 0.4226358720098121\n",
      "65 Train Loss 10.785599 Test MSE 932.871816637094 Test RE 0.4226337263610803\n",
      "66 Train Loss 10.782611 Test MSE 936.9013347494572 Test RE 0.42354552107808335\n",
      "67 Train Loss 10.772947 Test MSE 945.0086067920441 Test RE 0.42537410333867043\n",
      "68 Train Loss 10.659309 Test MSE 930.4198726114142 Test RE 0.42207793935500754\n",
      "69 Train Loss 10.569113 Test MSE 867.6157734401421 Test RE 0.4075837719818988\n",
      "70 Train Loss 10.357752 Test MSE 843.4883273340246 Test RE 0.40187658502657686\n",
      "71 Train Loss 10.232011 Test MSE 882.3847476791472 Test RE 0.41103817717135055\n",
      "72 Train Loss 10.106965 Test MSE 873.2624031502635 Test RE 0.40890794232313055\n",
      "73 Train Loss 9.94832 Test MSE 902.7480285524927 Test RE 0.41575400260890616\n",
      "74 Train Loss 9.852853 Test MSE 938.6530444205714 Test RE 0.4239412843717203\n",
      "75 Train Loss 9.83392 Test MSE 936.1803283627926 Test RE 0.42338251682711536\n",
      "76 Train Loss 9.7853565 Test MSE 966.9652080325454 Test RE 0.43028736021764596\n",
      "77 Train Loss 9.64767 Test MSE 1009.1985512700535 Test RE 0.4395835924098335\n",
      "78 Train Loss 9.378759 Test MSE 1037.727475725971 Test RE 0.44575356220389173\n",
      "79 Train Loss 9.329119 Test MSE 1046.2419189197378 Test RE 0.4475785066862551\n",
      "80 Train Loss 9.272847 Test MSE 1084.883282207424 Test RE 0.45576888522979453\n",
      "81 Train Loss 9.180115 Test MSE 1038.6380112425354 Test RE 0.44594907859269445\n",
      "82 Train Loss 9.164548 Test MSE 1064.565225015897 Test RE 0.45148081713455257\n",
      "83 Train Loss 9.046173 Test MSE 1027.3760285436126 Test RE 0.44352476943765656\n",
      "84 Train Loss 9.022271 Test MSE 978.5154496961578 Test RE 0.4328495877445965\n",
      "85 Train Loss 8.949021 Test MSE 985.6343545456341 Test RE 0.43442127005169645\n",
      "86 Train Loss 8.842423 Test MSE 989.1958237861485 Test RE 0.43520542640154286\n",
      "87 Train Loss 8.825421 Test MSE 976.8296702985867 Test RE 0.43247657193569466\n",
      "88 Train Loss 8.815634 Test MSE 980.06800242824 Test RE 0.4331928400954738\n",
      "89 Train Loss 8.805434 Test MSE 981.3809930977895 Test RE 0.43348291577703796\n",
      "90 Train Loss 8.799419 Test MSE 989.3399995000582 Test RE 0.4352371409343939\n",
      "91 Train Loss 8.798681 Test MSE 993.7707892977078 Test RE 0.4362106636650294\n",
      "92 Train Loss 8.793333 Test MSE 998.3279504743595 Test RE 0.4372096910876087\n",
      "93 Train Loss 8.781617 Test MSE 983.0402268112142 Test RE 0.43384920864326787\n",
      "94 Train Loss 8.754297 Test MSE 1001.6935762797572 Test RE 0.437946045365845\n",
      "95 Train Loss 8.644238 Test MSE 1316.765539077232 Test RE 0.502119850389323\n",
      "96 Train Loss 8.170805 Test MSE 1100.4542767661103 Test RE 0.4590279876662149\n",
      "97 Train Loss 8.037576 Test MSE 973.8544459125355 Test RE 0.4318174518530458\n",
      "98 Train Loss 7.9746637 Test MSE 916.4469804447791 Test RE 0.4188966015353829\n",
      "99 Train Loss 7.950545 Test MSE 967.5713335270153 Test RE 0.4304221982029434\n",
      "Training time: 68.22\n",
      "Training time: 68.22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.767017 Test MSE 5214.459798909392 Test RE 0.9992124266448453\n",
      "1 Train Loss 47.744377 Test MSE 5166.351542753524 Test RE 0.9945924125730977\n",
      "2 Train Loss 47.728687 Test MSE 5132.713383280917 Test RE 0.9913492249562539\n",
      "3 Train Loss 47.645927 Test MSE 5051.870480645865 Test RE 0.9835111061608023\n",
      "4 Train Loss 45.32066 Test MSE 4630.559713185652 Test RE 0.9416075002810648\n",
      "5 Train Loss 41.172493 Test MSE 4225.97801548516 Test RE 0.8995323393078435\n",
      "6 Train Loss 37.35904 Test MSE 3612.094631754318 Test RE 0.8316349346279873\n",
      "7 Train Loss 30.193478 Test MSE 3007.2405839895696 Test RE 0.7588173487377176\n",
      "8 Train Loss 20.818918 Test MSE 1257.863740070536 Test RE 0.49076091071025874\n",
      "9 Train Loss 16.449286 Test MSE 849.1001664486735 Test RE 0.4032112377693345\n",
      "10 Train Loss 14.183064 Test MSE 1254.9463436488727 Test RE 0.4901914629975537\n",
      "11 Train Loss 11.310751 Test MSE 1147.83391771084 Test RE 0.4688054928470619\n",
      "12 Train Loss 9.773356 Test MSE 873.0495507807957 Test RE 0.4088581048811224\n",
      "13 Train Loss 8.756239 Test MSE 728.9067739680834 Test RE 0.37358476558515613\n",
      "14 Train Loss 7.8098583 Test MSE 561.6605123300932 Test RE 0.3279367668137001\n",
      "15 Train Loss 7.1970835 Test MSE 429.72364273636407 Test RE 0.2868453334578322\n",
      "16 Train Loss 6.882797 Test MSE 360.26750467513267 Test RE 0.2626429274375926\n",
      "17 Train Loss 6.4206514 Test MSE 281.39467249857006 Test RE 0.2321192187239522\n",
      "18 Train Loss 6.134497 Test MSE 312.5398260768005 Test RE 0.2446278214813482\n",
      "19 Train Loss 6.054485 Test MSE 316.5244025170927 Test RE 0.2461822652373869\n",
      "20 Train Loss 5.803785 Test MSE 308.3100903528763 Test RE 0.242966856002111\n",
      "21 Train Loss 5.4062414 Test MSE 252.97692509636204 Test RE 0.22008660918844294\n",
      "22 Train Loss 4.927877 Test MSE 225.7609597409363 Test RE 0.20791105684526942\n",
      "23 Train Loss 4.6316237 Test MSE 227.27194260437804 Test RE 0.20860565469947448\n",
      "24 Train Loss 4.2545 Test MSE 216.98283712268918 Test RE 0.20382894489986\n",
      "25 Train Loss 3.9028516 Test MSE 195.71657928011695 Test RE 0.19358289170143558\n",
      "26 Train Loss 2.6524775 Test MSE 143.55539233491356 Test RE 0.16579175159081286\n",
      "27 Train Loss 1.5663229 Test MSE 95.14633442479594 Test RE 0.13497371310204773\n",
      "28 Train Loss 1.1954455 Test MSE 95.79960577201376 Test RE 0.13543628281962627\n",
      "29 Train Loss 1.0208634 Test MSE 81.94877301373747 Test RE 0.1252634567923489\n",
      "30 Train Loss 0.75702477 Test MSE 47.692776615421366 Test RE 0.09556073211085166\n",
      "31 Train Loss 0.63035256 Test MSE 16.17383271772184 Test RE 0.055649291332850424\n",
      "32 Train Loss 0.42907244 Test MSE 8.445973694362568 Test RE 0.040214069754029975\n",
      "33 Train Loss 0.39293092 Test MSE 10.987386727940708 Test RE 0.0458670036669798\n",
      "34 Train Loss 0.33722597 Test MSE 14.84529218963217 Test RE 0.05331476995652227\n",
      "35 Train Loss 0.30896103 Test MSE 16.174052196025 Test RE 0.05564966891096724\n",
      "36 Train Loss 0.29250145 Test MSE 16.133772597629473 Test RE 0.055580331196288454\n",
      "37 Train Loss 0.2710887 Test MSE 16.291840766676312 Test RE 0.05585193745898055\n",
      "38 Train Loss 0.22083886 Test MSE 16.021337266504702 Test RE 0.0553863245380814\n",
      "39 Train Loss 0.19488059 Test MSE 10.119872088855114 Test RE 0.04401905108754561\n",
      "40 Train Loss 0.16114047 Test MSE 7.094444312691147 Test RE 0.03685635282251631\n",
      "41 Train Loss 0.15444411 Test MSE 6.957199071495877 Test RE 0.036498110343936616\n",
      "42 Train Loss 0.15328135 Test MSE 6.756424049692266 Test RE 0.03596761279620174\n",
      "43 Train Loss 0.14595391 Test MSE 5.028101269680883 Test RE 0.031028099305580276\n",
      "44 Train Loss 0.14073767 Test MSE 3.8823103769074123 Test RE 0.02726454729892025\n",
      "45 Train Loss 0.12976225 Test MSE 3.4660235639117323 Test RE 0.02576136791799848\n",
      "46 Train Loss 0.12086713 Test MSE 3.864805247739435 Test RE 0.027203010663815645\n",
      "47 Train Loss 0.10965127 Test MSE 3.495448174661431 Test RE 0.025870486655084866\n",
      "48 Train Loss 0.104196355 Test MSE 5.5308079278929085 Test RE 0.03254224069960194\n",
      "49 Train Loss 0.10324175 Test MSE 5.812520028712457 Test RE 0.033360718520965046\n",
      "50 Train Loss 0.09790207 Test MSE 7.889608962148751 Test RE 0.03886698958279356\n",
      "51 Train Loss 0.09026404 Test MSE 5.517338322165824 Test RE 0.03250259022191845\n",
      "52 Train Loss 0.082357965 Test MSE 4.820906799055982 Test RE 0.030382082061698554\n",
      "53 Train Loss 0.08056905 Test MSE 5.017609674265109 Test RE 0.030995710910970278\n",
      "54 Train Loss 0.07950069 Test MSE 6.123829561811061 Test RE 0.03424244068474149\n",
      "55 Train Loss 0.0763268 Test MSE 5.628663028561051 Test RE 0.03282885905922194\n",
      "56 Train Loss 0.073957585 Test MSE 3.8043924741616575 Test RE 0.02698956106489161\n",
      "57 Train Loss 0.07337363 Test MSE 2.7531736834518625 Test RE 0.02295989880021827\n",
      "58 Train Loss 0.07099716 Test MSE 3.055417183194605 Test RE 0.024187357461512054\n",
      "59 Train Loss 0.06496629 Test MSE 3.59192236380924 Test RE 0.026225068743799717\n",
      "60 Train Loss 0.05547044 Test MSE 1.8753096742605972 Test RE 0.018949146861210887\n",
      "61 Train Loss 0.050096013 Test MSE 2.9562838914654592 Test RE 0.023791741533519515\n",
      "62 Train Loss 0.048394922 Test MSE 4.508627351439074 Test RE 0.029381592786415337\n",
      "63 Train Loss 0.04647761 Test MSE 2.950637578445581 Test RE 0.02376901032275671\n",
      "64 Train Loss 0.04396886 Test MSE 1.5640489991564412 Test RE 0.017305268501685032\n",
      "65 Train Loss 0.038788736 Test MSE 0.6055089082905412 Test RE 0.010767464116854147\n",
      "66 Train Loss 0.034995407 Test MSE 0.2587365336563764 Test RE 0.007038531238471598\n",
      "67 Train Loss 0.033985913 Test MSE 0.1862000518201836 Test RE 0.005970944898794737\n",
      "68 Train Loss 0.033335116 Test MSE 0.29128386695002595 Test RE 0.007468121594063293\n",
      "69 Train Loss 0.032980494 Test MSE 0.2870405691359355 Test RE 0.007413525844678373\n",
      "70 Train Loss 0.03265813 Test MSE 0.26507597999952076 Test RE 0.007124236900587855\n",
      "71 Train Loss 0.032313876 Test MSE 0.28708047038164725 Test RE 0.00741404110047983\n",
      "72 Train Loss 0.031933397 Test MSE 0.19336868976947857 Test RE 0.006084799073621098\n",
      "73 Train Loss 0.031593755 Test MSE 0.20989504149696064 Test RE 0.006339489023264959\n",
      "74 Train Loss 0.030439416 Test MSE 0.32859954597708046 Test RE 0.007932071936516117\n",
      "75 Train Loss 0.029564748 Test MSE 0.3938603172060073 Test RE 0.008684089242336554\n",
      "76 Train Loss 0.028439665 Test MSE 0.22889695968390716 Test RE 0.006620231506463578\n",
      "77 Train Loss 0.02804401 Test MSE 0.20485654883264065 Test RE 0.006262937686392002\n",
      "78 Train Loss 0.027860865 Test MSE 0.20972741251969287 Test RE 0.006336957057022134\n",
      "79 Train Loss 0.027652135 Test MSE 0.2494682659972857 Test RE 0.0069113170912661216\n",
      "80 Train Loss 0.026831938 Test MSE 0.09160047700950223 Test RE 0.004187955248948925\n",
      "81 Train Loss 0.026072845 Test MSE 0.12117695510096307 Test RE 0.00481685066677246\n",
      "82 Train Loss 0.023985596 Test MSE 0.11616625651701407 Test RE 0.004716210293722223\n",
      "83 Train Loss 0.022145355 Test MSE 0.28925850344972903 Test RE 0.007442112522726928\n",
      "84 Train Loss 0.021658896 Test MSE 0.21245495719584723 Test RE 0.006378030608757319\n",
      "85 Train Loss 0.020615935 Test MSE 0.06071285770574923 Test RE 0.003409522040986436\n",
      "86 Train Loss 0.020333963 Test MSE 0.13846273021246003 Test RE 0.005148961091655526\n",
      "87 Train Loss 0.020176904 Test MSE 0.1982603624408003 Test RE 0.0061612823659344396\n",
      "88 Train Loss 0.01984905 Test MSE 0.250832558416102 Test RE 0.006930189634419815\n",
      "89 Train Loss 0.019518903 Test MSE 0.197540777985609 Test RE 0.006150091038599107\n",
      "90 Train Loss 0.019354222 Test MSE 0.1714395432719996 Test RE 0.005729393687100048\n",
      "91 Train Loss 0.019293696 Test MSE 0.11317487614688011 Test RE 0.004655091036716172\n",
      "92 Train Loss 0.018984413 Test MSE 0.14174445815377312 Test RE 0.005209621950119105\n",
      "93 Train Loss 0.01884169 Test MSE 0.12466343890442577 Test RE 0.004885654101090539\n",
      "94 Train Loss 0.018583603 Test MSE 0.03761399616342108 Test RE 0.002683662530932491\n",
      "95 Train Loss 0.018486505 Test MSE 0.029994166356151607 Test RE 0.0023964676047481337\n",
      "96 Train Loss 0.018443786 Test MSE 0.03204890641287889 Test RE 0.00247719258942017\n",
      "97 Train Loss 0.018442973 Test MSE 0.03175650110294074 Test RE 0.0024658660870940908\n",
      "98 Train Loss 0.018441273 Test MSE 0.03114155704892886 Test RE 0.002441874424568155\n",
      "99 Train Loss 0.018439544 Test MSE 0.031091896267906132 Test RE 0.002439926645041335\n",
      "Training time: 64.59\n",
      "Training time: 64.59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.769188 Test MSE 5220.6269031726915 Test RE 0.9998031327312958\n",
      "1 Train Loss 47.734737 Test MSE 5145.060933565721 Test RE 0.9925409320105477\n",
      "2 Train Loss 47.72692 Test MSE 5125.398318554391 Test RE 0.9906425451914667\n",
      "3 Train Loss 47.660137 Test MSE 4982.736261710885 Test RE 0.976758310226675\n",
      "4 Train Loss 47.549152 Test MSE 4847.869424395467 Test RE 0.963448758757772\n",
      "5 Train Loss 47.42383 Test MSE 4742.620361126379 Test RE 0.9529329531105487\n",
      "6 Train Loss 47.246426 Test MSE 4751.970156055464 Test RE 0.953871816026813\n",
      "7 Train Loss 47.130432 Test MSE 4877.9034911613335 Test RE 0.9664285837879165\n",
      "8 Train Loss 46.414024 Test MSE 5257.310262579873 Test RE 1.0033096020098238\n",
      "9 Train Loss 38.91095 Test MSE 4995.163947545695 Test RE 0.9779756419477937\n",
      "10 Train Loss 34.871048 Test MSE 5190.044045213183 Test RE 0.9968703672022936\n",
      "11 Train Loss 29.267492 Test MSE 5027.115975517402 Test RE 0.9810985117786593\n",
      "12 Train Loss 29.118162 Test MSE 5053.964299287902 Test RE 0.983714900039229\n",
      "13 Train Loss 25.670454 Test MSE 6036.864239333724 Test RE 1.0751247738503396\n",
      "14 Train Loss 23.993608 Test MSE 6149.691181314977 Test RE 1.085125122782788\n",
      "15 Train Loss 23.847874 Test MSE 6136.266859768094 Test RE 1.0839401017358428\n",
      "16 Train Loss 23.231087 Test MSE 6651.287525999114 Test RE 1.1285115953589742\n",
      "17 Train Loss 21.26854 Test MSE 8361.961692019222 Test RE 1.2653400416362162\n",
      "18 Train Loss 21.219395 Test MSE 8621.8964336572 Test RE 1.284856321461358\n",
      "19 Train Loss 21.165077 Test MSE 8493.189051947944 Test RE 1.2752301153536278\n",
      "20 Train Loss 20.405529 Test MSE 9364.466205167926 Test RE 1.3390434764043795\n",
      "21 Train Loss 20.399645 Test MSE 9365.785964601406 Test RE 1.3391378305811632\n",
      "22 Train Loss 20.243343 Test MSE 8936.36637267451 Test RE 1.3080780180574831\n",
      "23 Train Loss 19.780834 Test MSE 9422.82818974033 Test RE 1.3432096428980673\n",
      "24 Train Loss 18.853624 Test MSE 11386.697652680581 Test RE 1.476563264008076\n",
      "25 Train Loss 18.612984 Test MSE 11870.317316543656 Test RE 1.5075937523041465\n",
      "26 Train Loss 18.37006 Test MSE 12178.698266787087 Test RE 1.5270512050419236\n",
      "27 Train Loss 18.285818 Test MSE 12559.984338103874 Test RE 1.5507711523392407\n",
      "28 Train Loss 17.971388 Test MSE 12574.818838288335 Test RE 1.5516866839833534\n",
      "29 Train Loss 17.547064 Test MSE 12238.944620136826 Test RE 1.5308236020615784\n",
      "30 Train Loss 17.464722 Test MSE 11887.940994301303 Test RE 1.5087124878573202\n",
      "31 Train Loss 17.42859 Test MSE 11443.610579196891 Test RE 1.480248739561316\n",
      "32 Train Loss 17.35985 Test MSE 11064.786803938516 Test RE 1.4555418265244708\n",
      "33 Train Loss 17.27499 Test MSE 11300.590908222837 Test RE 1.470969748827983\n",
      "34 Train Loss 17.228231 Test MSE 10881.603410278512 Test RE 1.44344290941936\n",
      "35 Train Loss 17.175669 Test MSE 10960.988890166404 Test RE 1.4486985767599068\n",
      "36 Train Loss 17.125954 Test MSE 10756.126681756028 Test RE 1.435096545250266\n",
      "37 Train Loss 16.952904 Test MSE 10447.924882611165 Test RE 1.414386770250019\n",
      "38 Train Loss 16.767904 Test MSE 10243.602301793902 Test RE 1.4004884103651174\n",
      "39 Train Loss 16.62126 Test MSE 10152.847068996693 Test RE 1.3942706549996056\n",
      "40 Train Loss 16.429642 Test MSE 10419.758458238008 Test RE 1.4124789701589613\n",
      "41 Train Loss 16.023708 Test MSE 10610.435367127588 Test RE 1.425344245782821\n",
      "42 Train Loss 15.977729 Test MSE 10715.18850848162 Test RE 1.4323629292963302\n",
      "43 Train Loss 15.977214 Test MSE 10720.535201562068 Test RE 1.4327202468480553\n",
      "44 Train Loss 15.97487 Test MSE 10708.192744688193 Test RE 1.4318952702908474\n",
      "45 Train Loss 15.959691 Test MSE 10613.28346928427 Test RE 1.425535531696044\n",
      "46 Train Loss 15.957475 Test MSE 10595.50114992491 Test RE 1.4243408045826658\n",
      "47 Train Loss 15.95174 Test MSE 10505.442073974633 Test RE 1.4182746187861566\n",
      "48 Train Loss 15.93603 Test MSE 10518.439802879117 Test RE 1.4191517189826095\n",
      "49 Train Loss 15.7831545 Test MSE 10816.080304897107 Test RE 1.4390905330184365\n",
      "50 Train Loss 15.554173 Test MSE 11417.280582317093 Test RE 1.4785448459737813\n",
      "51 Train Loss 15.419528 Test MSE 11635.404780379171 Test RE 1.4926016345722082\n",
      "52 Train Loss 15.319588 Test MSE 11477.33721648322 Test RE 1.4824284311104545\n",
      "53 Train Loss 15.237321 Test MSE 11309.113117087189 Test RE 1.4715243016373163\n",
      "54 Train Loss 15.157837 Test MSE 11195.162453981926 Test RE 1.464091990247713\n",
      "55 Train Loss 15.088429 Test MSE 11032.593031953644 Test RE 1.4534227835935725\n",
      "56 Train Loss 15.050553 Test MSE 10970.515873186248 Test RE 1.4493280240280526\n",
      "57 Train Loss 14.957667 Test MSE 10986.702323995016 Test RE 1.4503968356542665\n",
      "58 Train Loss 14.826753 Test MSE 11002.228742249516 Test RE 1.4514213249288892\n",
      "59 Train Loss 14.72036 Test MSE 10921.796165853471 Test RE 1.4461062335648873\n",
      "60 Train Loss 14.708146 Test MSE 10859.785592394539 Test RE 1.4419951183594792\n",
      "61 Train Loss 14.63433 Test MSE 10813.819342611203 Test RE 1.4389401134863709\n",
      "62 Train Loss 14.550324 Test MSE 10649.948781813839 Test RE 1.42799578077583\n",
      "63 Train Loss 14.495512 Test MSE 10397.940513892221 Test RE 1.4109993995558276\n",
      "64 Train Loss 14.474985 Test MSE 10271.368065264705 Test RE 1.4023851706122683\n",
      "65 Train Loss 14.448773 Test MSE 10309.029489830013 Test RE 1.4049538400126078\n",
      "66 Train Loss 14.416038 Test MSE 10276.402607718399 Test RE 1.4027288201962276\n",
      "67 Train Loss 14.382998 Test MSE 9980.363497281389 Test RE 1.3823765061195283\n",
      "68 Train Loss 14.362904 Test MSE 10022.438644541819 Test RE 1.385287348116031\n",
      "69 Train Loss 14.331931 Test MSE 9758.011596905011 Test RE 1.366890828893819\n",
      "70 Train Loss 14.234001 Test MSE 9757.43354694441 Test RE 1.366850342013688\n",
      "71 Train Loss 14.13673 Test MSE 10143.517380754798 Test RE 1.3936298938325409\n",
      "72 Train Loss 14.113495 Test MSE 10100.396367038009 Test RE 1.3906645153219666\n",
      "73 Train Loss 14.098081 Test MSE 10231.110868896976 Test RE 1.3996342458347955\n",
      "74 Train Loss 14.019567 Test MSE 9872.76305537068 Test RE 1.3749044631455933\n",
      "75 Train Loss 13.9938545 Test MSE 9839.7582854661 Test RE 1.3726043778573733\n",
      "76 Train Loss 13.958601 Test MSE 9723.069524173134 Test RE 1.364441311783313\n",
      "77 Train Loss 13.868041 Test MSE 9589.78366956612 Test RE 1.3550570180302242\n",
      "78 Train Loss 13.844981 Test MSE 9589.907321164457 Test RE 1.3550657541202018\n",
      "79 Train Loss 13.836034 Test MSE 9552.59188913284 Test RE 1.3524268261979366\n",
      "80 Train Loss 13.810948 Test MSE 9421.037056252562 Test RE 1.3430819751711152\n",
      "81 Train Loss 13.777486 Test MSE 9319.428489652082 Test RE 1.3358195796117665\n",
      "82 Train Loss 13.746442 Test MSE 9470.844959091053 Test RE 1.346627652316602\n",
      "83 Train Loss 13.671982 Test MSE 9423.783449056618 Test RE 1.3432777265445757\n",
      "84 Train Loss 13.612532 Test MSE 8956.810433599432 Test RE 1.3095734328680484\n",
      "85 Train Loss 13.533854 Test MSE 8923.157117766114 Test RE 1.3071108953418769\n",
      "86 Train Loss 13.356804 Test MSE 8940.814062544288 Test RE 1.3084034971941985\n",
      "87 Train Loss 13.2884865 Test MSE 9065.4131583514 Test RE 1.3174889022432164\n",
      "88 Train Loss 13.191354 Test MSE 9188.791775318694 Test RE 1.326423995374632\n",
      "89 Train Loss 13.179068 Test MSE 9251.071521317463 Test RE 1.3309115192296166\n",
      "90 Train Loss 13.105449 Test MSE 8951.668215364756 Test RE 1.3091974575558316\n",
      "91 Train Loss 13.050789 Test MSE 8961.44513874551 Test RE 1.3099122086974557\n",
      "92 Train Loss 12.992502 Test MSE 8970.558363388365 Test RE 1.3105780885109417\n",
      "93 Train Loss 12.982907 Test MSE 9039.712530604997 Test RE 1.3156200230220116\n",
      "94 Train Loss 12.951611 Test MSE 8916.479840088079 Test RE 1.3066217424725857\n",
      "95 Train Loss 12.914017 Test MSE 8637.030231549752 Test RE 1.2859834650542585\n",
      "96 Train Loss 12.889957 Test MSE 8677.362108444155 Test RE 1.288982512021471\n",
      "97 Train Loss 12.837585 Test MSE 8814.228090626979 Test RE 1.2991081492080119\n",
      "98 Train Loss 12.829806 Test MSE 8864.583238647936 Test RE 1.3028137271602283\n",
      "99 Train Loss 12.813245 Test MSE 8795.466472921822 Test RE 1.2977247975365507\n",
      "Training time: 69.65\n",
      "Training time: 69.65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.74456 Test MSE 5169.722307534279 Test RE 0.9949168185285225\n",
      "1 Train Loss 47.72015 Test MSE 5109.897951119091 Test RE 0.989143447016449\n",
      "2 Train Loss 47.543694 Test MSE 4892.572892643785 Test RE 0.9678806713797347\n",
      "3 Train Loss 47.25839 Test MSE 4730.066457682779 Test RE 0.9516708917902904\n",
      "4 Train Loss 45.449593 Test MSE 4773.7613279822735 Test RE 0.9560564056705213\n",
      "5 Train Loss 42.431667 Test MSE 4234.223959391029 Test RE 0.900409518313785\n",
      "6 Train Loss 39.756996 Test MSE 3640.8269641658158 Test RE 0.8349359945636331\n",
      "7 Train Loss 34.548145 Test MSE 2951.5370868610257 Test RE 0.7517566646311101\n",
      "8 Train Loss 24.442091 Test MSE 1822.2759876555879 Test RE 0.5906908464187101\n",
      "9 Train Loss 18.562006 Test MSE 928.1538258376364 Test RE 0.42156363852640777\n",
      "10 Train Loss 15.684265 Test MSE 426.1281888140319 Test RE 0.2856428099912559\n",
      "11 Train Loss 15.00846 Test MSE 447.9331677943653 Test RE 0.29285980943725504\n",
      "12 Train Loss 14.511672 Test MSE 445.8532046320166 Test RE 0.29217907575481067\n",
      "13 Train Loss 10.788733 Test MSE 669.396303381683 Test RE 0.3580097213142149\n",
      "14 Train Loss 9.28301 Test MSE 486.52979860080677 Test RE 0.30521641509143693\n",
      "15 Train Loss 8.2894745 Test MSE 434.94137414613124 Test RE 0.28858152612995386\n",
      "16 Train Loss 7.6069474 Test MSE 462.7736623268115 Test RE 0.29767165478072066\n",
      "17 Train Loss 6.7995424 Test MSE 430.3980630968346 Test RE 0.28707033677426097\n",
      "18 Train Loss 6.225617 Test MSE 488.89952924114664 Test RE 0.3059588178323506\n",
      "19 Train Loss 6.1781096 Test MSE 526.552656370487 Test RE 0.31752218078713745\n",
      "20 Train Loss 6.159408 Test MSE 508.90600056076795 Test RE 0.3121561894267198\n",
      "21 Train Loss 5.713172 Test MSE 391.30366962475154 Test RE 0.2737222649936561\n",
      "22 Train Loss 5.6654024 Test MSE 410.87761682215915 Test RE 0.280484848576998\n",
      "23 Train Loss 5.6604753 Test MSE 423.84187843381676 Test RE 0.284875498094294\n",
      "24 Train Loss 5.632293 Test MSE 410.65204493058917 Test RE 0.28040784488856907\n",
      "25 Train Loss 5.5996466 Test MSE 423.3662141517072 Test RE 0.2847155998565261\n",
      "26 Train Loss 5.571772 Test MSE 416.1025623177224 Test RE 0.28226261438067385\n",
      "27 Train Loss 5.5477858 Test MSE 431.4536519560131 Test RE 0.28742215373389485\n",
      "28 Train Loss 5.523822 Test MSE 444.48909134900254 Test RE 0.29173176408392076\n",
      "29 Train Loss 5.499883 Test MSE 460.2432865372008 Test RE 0.29685672768020893\n",
      "30 Train Loss 5.4768414 Test MSE 493.0403417207261 Test RE 0.3072517693744024\n",
      "31 Train Loss 5.4384036 Test MSE 538.4137824266926 Test RE 0.32107851740739174\n",
      "32 Train Loss 5.4168177 Test MSE 537.7925929358681 Test RE 0.3208932433960303\n",
      "33 Train Loss 5.3819847 Test MSE 536.7206440712922 Test RE 0.320573275500802\n",
      "34 Train Loss 5.3116655 Test MSE 483.42534889092457 Test RE 0.3042410942024868\n",
      "35 Train Loss 5.229911 Test MSE 418.4214874417472 Test RE 0.28304804148350526\n",
      "36 Train Loss 5.204589 Test MSE 395.77010966870546 Test RE 0.27528000043619255\n",
      "37 Train Loss 5.1687036 Test MSE 391.44701642227756 Test RE 0.2737723969248735\n",
      "38 Train Loss 5.060455 Test MSE 409.4891601687468 Test RE 0.2800105338423817\n",
      "39 Train Loss 4.9777923 Test MSE 455.032637133184 Test RE 0.29517151095785754\n",
      "40 Train Loss 4.9657803 Test MSE 463.9131031598739 Test RE 0.2980378929019026\n",
      "41 Train Loss 4.9490337 Test MSE 457.88986409101244 Test RE 0.2960967766981623\n",
      "42 Train Loss 4.928216 Test MSE 498.5561431998 Test RE 0.30896565163736106\n",
      "43 Train Loss 4.899515 Test MSE 519.7587628370469 Test RE 0.31546710089505475\n",
      "44 Train Loss 4.897951 Test MSE 534.1486451741837 Test RE 0.3198042494955484\n",
      "45 Train Loss 4.8785515 Test MSE 577.9968091635556 Test RE 0.3326717211589462\n",
      "46 Train Loss 4.8750243 Test MSE 574.9684880964053 Test RE 0.33179908673476965\n",
      "47 Train Loss 4.868727 Test MSE 588.9298450153524 Test RE 0.33580328972180884\n",
      "48 Train Loss 4.8625026 Test MSE 581.9819700091548 Test RE 0.3338166002928575\n",
      "49 Train Loss 4.8372774 Test MSE 617.3232761607007 Test RE 0.34380286451873815\n",
      "50 Train Loss 4.807926 Test MSE 709.3653351845735 Test RE 0.36854298204614877\n",
      "51 Train Loss 4.796973 Test MSE 718.4833738953956 Test RE 0.3709040077530545\n",
      "52 Train Loss 4.784371 Test MSE 756.7993197371085 Test RE 0.38066551141746\n",
      "53 Train Loss 4.7481055 Test MSE 808.6334783588062 Test RE 0.39348576305540023\n",
      "54 Train Loss 4.7379394 Test MSE 784.7759457465675 Test RE 0.3876376982944849\n",
      "55 Train Loss 4.73505 Test MSE 763.2097134607326 Test RE 0.3822743065827592\n",
      "56 Train Loss 4.733297 Test MSE 760.2219142730875 Test RE 0.3815253126552332\n",
      "57 Train Loss 4.732435 Test MSE 757.2518074864192 Test RE 0.3807792937222978\n",
      "58 Train Loss 4.7277756 Test MSE 780.4364541971181 Test RE 0.3865644732685327\n",
      "59 Train Loss 4.659397 Test MSE 710.5773863165322 Test RE 0.3688577016058176\n",
      "60 Train Loss 4.624487 Test MSE 600.8822910114582 Test RE 0.3391937701237061\n",
      "61 Train Loss 4.6153064 Test MSE 548.2998349699785 Test RE 0.32401284109479644\n",
      "62 Train Loss 4.6121683 Test MSE 545.5460663458576 Test RE 0.32319815953474873\n",
      "63 Train Loss 4.610558 Test MSE 533.6724797362475 Test RE 0.31966167337524026\n",
      "64 Train Loss 4.6071377 Test MSE 532.3211503225677 Test RE 0.3192567040026238\n",
      "65 Train Loss 4.5982265 Test MSE 524.1546308107047 Test RE 0.31679832610942527\n",
      "66 Train Loss 4.587179 Test MSE 545.8014743550168 Test RE 0.3232738064363584\n",
      "67 Train Loss 4.576763 Test MSE 556.6143862712179 Test RE 0.3264603020749695\n",
      "68 Train Loss 4.573401 Test MSE 566.2759195875 Test RE 0.3292814091848239\n",
      "69 Train Loss 4.5724726 Test MSE 563.5274080320141 Test RE 0.3284813269441096\n",
      "70 Train Loss 4.570837 Test MSE 572.7142210562744 Test RE 0.3311480090384434\n",
      "71 Train Loss 4.5701427 Test MSE 568.1789740895185 Test RE 0.32983424469282274\n",
      "72 Train Loss 4.5670977 Test MSE 568.4976939119047 Test RE 0.3299267419325951\n",
      "73 Train Loss 4.559935 Test MSE 574.914096373257 Test RE 0.3317833923521447\n",
      "74 Train Loss 4.55033 Test MSE 602.4237153368719 Test RE 0.339628552990746\n",
      "75 Train Loss 4.5452476 Test MSE 618.2922052648578 Test RE 0.3440725692287685\n",
      "76 Train Loss 4.5429854 Test MSE 630.4031485160036 Test RE 0.34742602818242596\n",
      "77 Train Loss 4.537536 Test MSE 621.9192196920384 Test RE 0.34508028962865045\n",
      "78 Train Loss 4.534278 Test MSE 600.1960048061252 Test RE 0.339000012948393\n",
      "79 Train Loss 4.522122 Test MSE 585.4196427347623 Test RE 0.334801048838233\n",
      "80 Train Loss 4.4887033 Test MSE 572.0368164562861 Test RE 0.33095211067656655\n",
      "81 Train Loss 4.453619 Test MSE 549.7832926478347 Test RE 0.3244508629873805\n",
      "82 Train Loss 4.3907294 Test MSE 579.9074463521054 Test RE 0.3332211104835372\n",
      "83 Train Loss 4.347191 Test MSE 651.1001747792509 Test RE 0.3530832135690178\n",
      "84 Train Loss 4.2982574 Test MSE 714.1918807728935 Test RE 0.3697946459844356\n",
      "85 Train Loss 4.2440457 Test MSE 782.2822359051479 Test RE 0.3870213280526703\n",
      "86 Train Loss 4.172618 Test MSE 829.3343434207824 Test RE 0.3984905160692739\n",
      "87 Train Loss 4.136743 Test MSE 855.0577585965788 Test RE 0.40462330273977076\n",
      "88 Train Loss 4.1245937 Test MSE 890.9515550289905 Test RE 0.4130286803800069\n",
      "89 Train Loss 4.121365 Test MSE 936.1884278106476 Test RE 0.42338434828901267\n",
      "90 Train Loss 4.0995617 Test MSE 1041.771209079235 Test RE 0.44662120618274853\n",
      "91 Train Loss 4.0843186 Test MSE 1071.008479692919 Test RE 0.4528450442467708\n",
      "92 Train Loss 4.0666895 Test MSE 1070.3800589707869 Test RE 0.45271216996439184\n",
      "93 Train Loss 3.9862764 Test MSE 1074.9653913154436 Test RE 0.45368080598885496\n",
      "94 Train Loss 3.932585 Test MSE 1151.7266534323921 Test RE 0.4695997677058983\n",
      "95 Train Loss 3.891152 Test MSE 1213.2414981944173 Test RE 0.4819775314434385\n",
      "96 Train Loss 3.8744168 Test MSE 1190.7297576457308 Test RE 0.4774850388781049\n",
      "97 Train Loss 3.8597453 Test MSE 1211.9233617338348 Test RE 0.48171563601198936\n",
      "98 Train Loss 3.835998 Test MSE 1195.0734325957642 Test RE 0.47835515728809386\n",
      "99 Train Loss 3.8165386 Test MSE 1187.8358302255297 Test RE 0.47690445052915553\n",
      "Training time: 69.32\n",
      "Training time: 69.32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.77162 Test MSE 5226.957671282876 Test RE 1.0004091522959042\n",
      "1 Train Loss 47.764214 Test MSE 5211.677793100559 Test RE 0.9989458424010953\n",
      "2 Train Loss 47.741993 Test MSE 5160.704262855753 Test RE 0.9940486751376911\n",
      "3 Train Loss 47.71883 Test MSE 5097.410515374386 Test RE 0.9879340861953777\n",
      "4 Train Loss 47.6904 Test MSE 5064.082375537765 Test RE 0.9846991101672222\n",
      "5 Train Loss 47.52949 Test MSE 4865.9524251054745 Test RE 0.965243962674792\n",
      "6 Train Loss 46.81365 Test MSE 4851.36096471629 Test RE 0.9637956446183255\n",
      "7 Train Loss 38.670063 Test MSE 4506.173428290193 Test RE 0.9288746610557598\n",
      "8 Train Loss 35.01753 Test MSE 4440.095511915822 Test RE 0.9220390633769503\n",
      "9 Train Loss 30.040783 Test MSE 4643.75549644258 Test RE 0.9429482031050196\n",
      "10 Train Loss 28.488832 Test MSE 5065.58057802371 Test RE 0.9848447604002419\n",
      "11 Train Loss 26.200226 Test MSE 5562.766653502766 Test RE 1.0320448855235018\n",
      "12 Train Loss 25.688887 Test MSE 5909.086478340581 Test RE 1.0636857413836023\n",
      "13 Train Loss 25.108034 Test MSE 5992.60234943133 Test RE 1.0711761508560214\n",
      "14 Train Loss 24.956398 Test MSE 5824.756899741054 Test RE 1.0560684466927341\n",
      "15 Train Loss 24.683975 Test MSE 5759.748595732432 Test RE 1.0501586850844573\n",
      "16 Train Loss 24.11227 Test MSE 5947.4493945085305 Test RE 1.0671329807303256\n",
      "17 Train Loss 23.276999 Test MSE 6271.616539666523 Test RE 1.0958293120079738\n",
      "18 Train Loss 23.129955 Test MSE 6302.451632861459 Test RE 1.0985198916594732\n",
      "19 Train Loss 23.088507 Test MSE 6201.907296769497 Test RE 1.0897222033414762\n",
      "20 Train Loss 22.786633 Test MSE 6264.6058190120575 Test RE 1.0952166548622908\n",
      "21 Train Loss 22.39979 Test MSE 6305.054942236531 Test RE 1.0987467471787358\n",
      "22 Train Loss 21.691519 Test MSE 6846.06072907544 Test RE 1.1449157725577817\n",
      "23 Train Loss 21.28735 Test MSE 7057.874954873229 Test RE 1.1624924594496804\n",
      "24 Train Loss 21.075396 Test MSE 7159.222914154448 Test RE 1.170809148369975\n",
      "25 Train Loss 20.836462 Test MSE 6914.179097999186 Test RE 1.15059763527056\n",
      "26 Train Loss 19.256485 Test MSE 7260.990993461443 Test RE 1.1791012878261968\n",
      "27 Train Loss 18.865261 Test MSE 7275.584384603272 Test RE 1.1802855923606994\n",
      "28 Train Loss 18.356636 Test MSE 7367.7651327053245 Test RE 1.1877390936725758\n",
      "29 Train Loss 17.310915 Test MSE 7444.953893561759 Test RE 1.1939445870652894\n",
      "30 Train Loss 16.007912 Test MSE 7663.832253932551 Test RE 1.2113681753583758\n",
      "31 Train Loss 15.6003685 Test MSE 7213.696030579643 Test RE 1.1752549356663815\n",
      "32 Train Loss 15.171999 Test MSE 7004.182795899498 Test RE 1.1580622384935215\n",
      "33 Train Loss 15.021136 Test MSE 7068.387504050282 Test RE 1.1633578907568416\n",
      "34 Train Loss 14.771078 Test MSE 6986.27466971701 Test RE 1.1565808381402949\n",
      "35 Train Loss 14.3689375 Test MSE 6970.75714098175 Test RE 1.1552956572536093\n",
      "36 Train Loss 14.2384815 Test MSE 6941.213608286843 Test RE 1.152844864943486\n",
      "37 Train Loss 13.69372 Test MSE 6628.154157873499 Test RE 1.1265473881870398\n",
      "38 Train Loss 13.500753 Test MSE 6486.595801942462 Test RE 1.1144525518923118\n",
      "39 Train Loss 13.355482 Test MSE 6570.767094393909 Test RE 1.1216599196294081\n",
      "40 Train Loss 13.052132 Test MSE 7027.448952784182 Test RE 1.159984041547263\n",
      "41 Train Loss 12.830182 Test MSE 7148.4187565575185 Test RE 1.1699253665148441\n",
      "42 Train Loss 12.701054 Test MSE 7129.457328569104 Test RE 1.1683727024584043\n",
      "43 Train Loss 12.415521 Test MSE 7109.487484583069 Test RE 1.1667352298562763\n",
      "44 Train Loss 12.206699 Test MSE 6918.184537266738 Test RE 1.150930862224954\n",
      "45 Train Loss 12.154981 Test MSE 6901.864478463435 Test RE 1.1495725326080615\n",
      "46 Train Loss 12.070241 Test MSE 6967.259163469981 Test RE 1.1550057529254416\n",
      "47 Train Loss 11.955273 Test MSE 7262.988808508091 Test RE 1.1792634877438726\n",
      "48 Train Loss 11.875772 Test MSE 7135.5460559129815 Test RE 1.1688715051218388\n",
      "49 Train Loss 11.807398 Test MSE 7000.994695066414 Test RE 1.157798650326597\n",
      "50 Train Loss 11.683666 Test MSE 6832.903916041357 Test RE 1.1438150894365746\n",
      "51 Train Loss 11.635231 Test MSE 6815.881920024732 Test RE 1.1423894761765911\n",
      "52 Train Loss 11.60542 Test MSE 6888.483648651044 Test RE 1.1484576384235028\n",
      "53 Train Loss 11.371291 Test MSE 6875.079628782097 Test RE 1.1473397258538396\n",
      "54 Train Loss 11.303458 Test MSE 6762.368190668941 Test RE 1.13789600121678\n",
      "55 Train Loss 11.216936 Test MSE 6822.6834935757515 Test RE 1.142959329694463\n",
      "56 Train Loss 11.1928625 Test MSE 6923.581552103138 Test RE 1.15137970685545\n",
      "57 Train Loss 11.149414 Test MSE 6961.0693717918875 Test RE 1.154492578849162\n",
      "58 Train Loss 11.11391 Test MSE 6999.551166924371 Test RE 1.1576792814963133\n",
      "59 Train Loss 11.074317 Test MSE 6808.612521281069 Test RE 1.141780112622134\n",
      "60 Train Loss 11.041123 Test MSE 6675.090795698058 Test RE 1.1305291201884684\n",
      "61 Train Loss 10.991452 Test MSE 6676.041102298402 Test RE 1.1306095918316765\n",
      "62 Train Loss 10.962835 Test MSE 6735.505999552574 Test RE 1.135633717192892\n",
      "63 Train Loss 10.95237 Test MSE 6763.529224705596 Test RE 1.1379936799624941\n",
      "64 Train Loss 10.922349 Test MSE 6713.516204754201 Test RE 1.1337784172408163\n",
      "65 Train Loss 10.912365 Test MSE 6673.503841861537 Test RE 1.1303947247004102\n",
      "66 Train Loss 10.896076 Test MSE 6636.450143475986 Test RE 1.1272521770426913\n",
      "67 Train Loss 10.87604 Test MSE 6635.448051596338 Test RE 1.1271670673173106\n",
      "68 Train Loss 10.854791 Test MSE 6614.736615938471 Test RE 1.125406561202122\n",
      "69 Train Loss 10.831386 Test MSE 6561.055617058973 Test RE 1.1208307163862001\n",
      "70 Train Loss 10.817092 Test MSE 6492.668002096303 Test RE 1.1149740577938583\n",
      "71 Train Loss 10.777487 Test MSE 6459.5853606204255 Test RE 1.1121298191430324\n",
      "72 Train Loss 10.761256 Test MSE 6483.448382558641 Test RE 1.1141821423224019\n",
      "73 Train Loss 10.720435 Test MSE 6374.564660216098 Test RE 1.104786681449618\n",
      "74 Train Loss 10.685628 Test MSE 6284.897241162962 Test RE 1.096988956058345\n",
      "75 Train Loss 10.659319 Test MSE 6325.769563990043 Test RE 1.1005501779261875\n",
      "76 Train Loss 10.612077 Test MSE 6318.891462178602 Test RE 1.099951693040233\n",
      "77 Train Loss 10.551422 Test MSE 6226.366873715001 Test RE 1.0918689554870729\n",
      "78 Train Loss 10.4829445 Test MSE 6070.2852631631695 Test RE 1.0780966956523086\n",
      "79 Train Loss 10.421634 Test MSE 6037.231348078273 Test RE 1.0751574631481393\n",
      "80 Train Loss 10.36828 Test MSE 6107.709287363606 Test RE 1.0814148858584491\n",
      "81 Train Loss 10.349009 Test MSE 6154.093354448953 Test RE 1.0855134393629378\n",
      "82 Train Loss 10.318537 Test MSE 6105.8733784488495 Test RE 1.0812523430495016\n",
      "83 Train Loss 10.301897 Test MSE 6067.376788728288 Test RE 1.07783838881613\n",
      "84 Train Loss 10.279349 Test MSE 6084.5619592343155 Test RE 1.079363738214002\n",
      "85 Train Loss 10.206113 Test MSE 5993.197914437242 Test RE 1.0712293780804956\n",
      "86 Train Loss 10.055668 Test MSE 6059.976408676759 Test RE 1.0771808684674065\n",
      "87 Train Loss 9.983792 Test MSE 5915.308789410554 Test RE 1.0642456284448618\n",
      "88 Train Loss 9.97189 Test MSE 5910.838748171714 Test RE 1.063843441417694\n",
      "89 Train Loss 9.926294 Test MSE 5930.292689687793 Test RE 1.0655926810896261\n",
      "90 Train Loss 9.888629 Test MSE 5970.711077769807 Test RE 1.0692178311300191\n",
      "91 Train Loss 9.856025 Test MSE 5914.3249121428835 Test RE 1.0641571182198055\n",
      "92 Train Loss 9.817045 Test MSE 5792.97255062077 Test RE 1.0531831447625744\n",
      "93 Train Loss 9.786915 Test MSE 5762.015860248058 Test RE 1.0503653567139846\n",
      "94 Train Loss 9.740257 Test MSE 5761.92636923519 Test RE 1.0503571999658157\n",
      "95 Train Loss 9.713314 Test MSE 5645.278574575639 Test RE 1.039670816503988\n",
      "96 Train Loss 9.700807 Test MSE 5604.240285430079 Test RE 1.035884986033926\n",
      "97 Train Loss 9.6586275 Test MSE 5546.478019706182 Test RE 1.0305327849533783\n",
      "98 Train Loss 9.607703 Test MSE 5429.285728304362 Test RE 1.0195875263557064\n",
      "99 Train Loss 9.56321 Test MSE 5355.132632268335 Test RE 1.012600833390515\n",
      "Training time: 70.06\n",
      "Training time: 70.06\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.76714 Test MSE 5215.541779505042 Test RE 0.9993160876587911\n",
      "1 Train Loss 47.72175 Test MSE 5109.7412605913205 Test RE 0.9891282812931402\n",
      "2 Train Loss 47.68555 Test MSE 5031.230159000844 Test RE 0.9814998943805796\n",
      "3 Train Loss 47.65736 Test MSE 4973.899426517693 Test RE 0.9758917900955346\n",
      "4 Train Loss 47.588406 Test MSE 4840.21843190006 Test RE 0.9626881926957661\n",
      "5 Train Loss 47.531067 Test MSE 4747.815186159076 Test RE 0.9534547074090401\n",
      "6 Train Loss 47.05415 Test MSE 4716.392981751491 Test RE 0.9502943713047136\n",
      "7 Train Loss 46.698326 Test MSE 5106.590960492604 Test RE 0.9888233214923629\n",
      "8 Train Loss 46.34038 Test MSE 4920.218954220888 Test RE 0.9706113813468138\n",
      "9 Train Loss 45.750107 Test MSE 4755.5425599001455 Test RE 0.9542302963026945\n",
      "10 Train Loss 44.897205 Test MSE 5064.5087358931005 Test RE 0.9847405616874503\n",
      "11 Train Loss 44.303677 Test MSE 5158.504593496663 Test RE 0.993836803719651\n",
      "12 Train Loss 43.95353 Test MSE 5215.16735275497 Test RE 0.9992802162760529\n",
      "13 Train Loss 41.803833 Test MSE 5045.648197378832 Test RE 0.9829052345083568\n",
      "14 Train Loss 39.040012 Test MSE 4870.643817425355 Test RE 0.9657091590815026\n",
      "15 Train Loss 37.954006 Test MSE 4172.382162387224 Test RE 0.8938099906195806\n",
      "16 Train Loss 33.05656 Test MSE 2908.4419852165447 Test RE 0.7462483215777723\n",
      "17 Train Loss 23.439066 Test MSE 1531.5480684713525 Test RE 0.5415249621102445\n",
      "18 Train Loss 21.929157 Test MSE 1150.7442449210719 Test RE 0.4693994435975779\n",
      "19 Train Loss 20.744427 Test MSE 1240.0738783673823 Test RE 0.48727815752532333\n",
      "20 Train Loss 17.082277 Test MSE 920.1105192496944 Test RE 0.419733045619539\n",
      "21 Train Loss 14.948167 Test MSE 831.6052978019496 Test RE 0.39903573352694627\n",
      "22 Train Loss 14.711791 Test MSE 800.3768928363719 Test RE 0.3914717575270407\n",
      "23 Train Loss 14.577605 Test MSE 802.4042189205335 Test RE 0.39196723595839855\n",
      "24 Train Loss 14.55601 Test MSE 822.3728997617663 Test RE 0.3968145242009683\n",
      "25 Train Loss 14.536897 Test MSE 808.4081442041199 Test RE 0.39343093477908936\n",
      "26 Train Loss 14.190652 Test MSE 828.657900261047 Test RE 0.3983279693388868\n",
      "27 Train Loss 14.118194 Test MSE 839.0132913154844 Test RE 0.4008091109409612\n",
      "28 Train Loss 13.624479 Test MSE 784.3542782448413 Test RE 0.38753354360997017\n",
      "29 Train Loss 13.124461 Test MSE 925.4956487886996 Test RE 0.4209595391656129\n",
      "30 Train Loss 12.497373 Test MSE 967.953332923388 Test RE 0.4305071556572186\n",
      "31 Train Loss 12.343698 Test MSE 963.8710207853576 Test RE 0.42959837139165435\n",
      "32 Train Loss 12.218033 Test MSE 989.0759325445015 Test RE 0.4351790519978272\n",
      "33 Train Loss 12.158561 Test MSE 1001.8321675598318 Test RE 0.4379763407601662\n",
      "34 Train Loss 11.810071 Test MSE 977.702886071527 Test RE 0.4326698302980504\n",
      "35 Train Loss 10.645411 Test MSE 1013.6471367649752 Test RE 0.4405513776488564\n",
      "36 Train Loss 10.627495 Test MSE 1023.0304489722699 Test RE 0.4425857682647478\n",
      "37 Train Loss 10.379415 Test MSE 1007.5534339431862 Test RE 0.4392251587118438\n",
      "38 Train Loss 10.329028 Test MSE 1005.6045761011436 Test RE 0.4388001679918365\n",
      "39 Train Loss 10.054682 Test MSE 994.302407095376 Test RE 0.4363273235375815\n",
      "40 Train Loss 9.7175255 Test MSE 1020.1770221873243 Test RE 0.44196810926702745\n",
      "41 Train Loss 9.296704 Test MSE 1006.357941164129 Test RE 0.4389645043686784\n",
      "42 Train Loss 8.988725 Test MSE 1011.8567501509875 Test RE 0.4401621367283417\n",
      "43 Train Loss 8.590262 Test MSE 1168.0587054454168 Test RE 0.47291762506152346\n",
      "44 Train Loss 8.406582 Test MSE 1119.5317143767595 Test RE 0.46298973797937976\n",
      "45 Train Loss 8.395226 Test MSE 1139.1695876714089 Test RE 0.46703277132302284\n",
      "46 Train Loss 8.325615 Test MSE 1144.4597276878183 Test RE 0.4681159318385277\n",
      "47 Train Loss 7.638079 Test MSE 1279.081993814207 Test RE 0.4948827970716864\n",
      "48 Train Loss 7.2732716 Test MSE 1289.7781275221334 Test RE 0.4969476812795062\n",
      "49 Train Loss 7.1375933 Test MSE 1339.8071091760087 Test RE 0.5064939983742087\n",
      "50 Train Loss 6.9508247 Test MSE 1268.8115775029516 Test RE 0.49289195662480567\n",
      "51 Train Loss 6.8338485 Test MSE 1316.9668598565745 Test RE 0.5021582335688208\n",
      "52 Train Loss 6.736805 Test MSE 1326.6522786253233 Test RE 0.5040013715767975\n",
      "53 Train Loss 6.648285 Test MSE 1403.1849536883406 Test RE 0.5183351064043887\n",
      "54 Train Loss 6.629599 Test MSE 1449.0526563459505 Test RE 0.5267387252163298\n",
      "55 Train Loss 6.61937 Test MSE 1461.077940821162 Test RE 0.5289198384523319\n",
      "56 Train Loss 6.618704 Test MSE 1458.4023504271854 Test RE 0.528435325862339\n",
      "57 Train Loss 6.6186986 Test MSE 1458.3990183203434 Test RE 0.5284347221866901\n",
      "58 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "59 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "60 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "61 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "62 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "63 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "64 Train Loss 6.61856 Test MSE 1458.5408987890328 Test RE 0.5284604259693056\n",
      "65 Train Loss 6.618555 Test MSE 1459.147524766057 Test RE 0.5285703112993315\n",
      "66 Train Loss 6.618555 Test MSE 1459.147524766057 Test RE 0.5285703112993315\n",
      "67 Train Loss 6.618555 Test MSE 1459.147524766057 Test RE 0.5285703112993315\n",
      "68 Train Loss 6.6185417 Test MSE 1459.1398653080814 Test RE 0.5285689239936168\n",
      "69 Train Loss 6.6185417 Test MSE 1459.1398653080814 Test RE 0.5285689239936168\n",
      "70 Train Loss 6.6185417 Test MSE 1459.1398653080814 Test RE 0.5285689239936168\n",
      "71 Train Loss 6.618532 Test MSE 1459.1614528397376 Test RE 0.5285728339875957\n",
      "72 Train Loss 6.618532 Test MSE 1459.1614528397376 Test RE 0.5285728339875957\n",
      "73 Train Loss 6.618532 Test MSE 1459.1614528397376 Test RE 0.5285728339875957\n",
      "74 Train Loss 6.618532 Test MSE 1459.1614528397376 Test RE 0.5285728339875957\n",
      "75 Train Loss 6.618532 Test MSE 1459.1614528397376 Test RE 0.5285728339875957\n",
      "76 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "77 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "78 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "79 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "80 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "81 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "82 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "83 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "84 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "85 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "86 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "87 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "88 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "89 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "90 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "91 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "92 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "93 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "94 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "95 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "96 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "97 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "98 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "99 Train Loss 6.6184764 Test MSE 1459.4115000365753 Test RE 0.5286181211261394\n",
      "Training time: 45.89\n",
      "Training time: 45.89\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.76719 Test MSE 5217.821152246706 Test RE 0.9995344317091552\n",
      "1 Train Loss 47.744877 Test MSE 5165.063532319705 Test RE 0.9944684251471826\n",
      "2 Train Loss 47.70521 Test MSE 5072.636084816854 Test RE 0.9855303837874927\n",
      "3 Train Loss 47.694565 Test MSE 5070.870365199956 Test RE 0.9853588436097909\n",
      "4 Train Loss 47.548065 Test MSE 4934.752134429881 Test RE 0.9720438042830505\n",
      "5 Train Loss 46.566303 Test MSE 4795.346844852702 Test RE 0.9582154679174771\n",
      "6 Train Loss 39.47982 Test MSE 4419.245470750683 Test RE 0.9198716353964413\n",
      "7 Train Loss 37.13611 Test MSE 4317.351998586187 Test RE 0.9092051645700112\n",
      "8 Train Loss 36.21975 Test MSE 4264.862117034532 Test RE 0.9036612552556248\n",
      "9 Train Loss 35.88174 Test MSE 4262.853366520834 Test RE 0.9034484179170873\n",
      "10 Train Loss 35.106228 Test MSE 4273.2955053124715 Test RE 0.9045542691821437\n",
      "11 Train Loss 32.032703 Test MSE 4339.380130921173 Test RE 0.9115217013805477\n",
      "12 Train Loss 29.822142 Test MSE 4595.960944472175 Test RE 0.9380831375945765\n",
      "13 Train Loss 28.820253 Test MSE 4989.478331378754 Test RE 0.9774189057401383\n",
      "14 Train Loss 28.523808 Test MSE 5267.301481804862 Test RE 1.0042625159104221\n",
      "15 Train Loss 28.48084 Test MSE 5213.174796950025 Test RE 0.9990893008476487\n",
      "16 Train Loss 28.431965 Test MSE 5125.7776488248155 Test RE 0.9906792031962295\n",
      "17 Train Loss 27.78796 Test MSE 5741.993612793388 Test RE 1.048538827846343\n",
      "18 Train Loss 27.65263 Test MSE 5608.121610316051 Test RE 1.036243635027759\n",
      "19 Train Loss 27.218588 Test MSE 5707.842383459249 Test RE 1.0454160193068829\n",
      "20 Train Loss 26.963234 Test MSE 5643.660101825848 Test RE 1.03952177164427\n",
      "21 Train Loss 26.815401 Test MSE 5630.118112987276 Test RE 1.0382738539194514\n",
      "22 Train Loss 26.760311 Test MSE 5666.034381863894 Test RE 1.041580324451003\n",
      "23 Train Loss 26.747143 Test MSE 5699.403896079586 Test RE 1.0446429607480252\n",
      "24 Train Loss 26.746891 Test MSE 5701.324555422125 Test RE 1.0448189646153823\n",
      "25 Train Loss 26.746891 Test MSE 5701.324555422125 Test RE 1.0448189646153823\n",
      "26 Train Loss 26.745731 Test MSE 5713.406948456338 Test RE 1.0459254822416675\n",
      "27 Train Loss 26.732805 Test MSE 5691.9499151517975 Test RE 1.0439596176744188\n",
      "28 Train Loss 26.629482 Test MSE 5764.490811550661 Test RE 1.050590913539906\n",
      "29 Train Loss 26.591114 Test MSE 5742.345665967036 Test RE 1.0485709713655542\n",
      "30 Train Loss 26.570822 Test MSE 5706.350185170284 Test RE 1.0452793590893095\n",
      "31 Train Loss 26.570822 Test MSE 5706.350185170284 Test RE 1.0452793590893095\n",
      "32 Train Loss 26.570822 Test MSE 5706.350185170284 Test RE 1.0452793590893095\n",
      "33 Train Loss 26.57082 Test MSE 5706.348032102664 Test RE 1.0452791618916888\n",
      "34 Train Loss 26.57082 Test MSE 5706.348032102664 Test RE 1.0452791618916888\n",
      "35 Train Loss 26.57082 Test MSE 5706.348032102664 Test RE 1.0452791618916888\n",
      "36 Train Loss 26.569275 Test MSE 5684.049540821855 Test RE 1.0432348629068036\n",
      "37 Train Loss 26.568054 Test MSE 5670.045627841469 Test RE 1.0419489504962385\n",
      "38 Train Loss 26.506872 Test MSE 5650.818442069471 Test RE 1.0401808202313896\n",
      "39 Train Loss 26.2958 Test MSE 5662.9511149855625 Test RE 1.041296889255267\n",
      "40 Train Loss 26.12711 Test MSE 5764.151848877106 Test RE 1.0505600247457647\n",
      "41 Train Loss 26.020506 Test MSE 5855.695124991806 Test RE 1.058869388718301\n",
      "42 Train Loss 25.938292 Test MSE 5919.760708933498 Test RE 1.0646460339807473\n",
      "43 Train Loss 25.835 Test MSE 5982.270592454818 Test RE 1.0702523530374735\n",
      "44 Train Loss 25.727806 Test MSE 6050.760217361079 Test RE 1.0763614525423817\n",
      "45 Train Loss 25.485611 Test MSE 6240.191361685582 Test RE 1.0930804292234904\n",
      "46 Train Loss 25.359653 Test MSE 6268.441344063719 Test RE 1.0955518785185805\n",
      "47 Train Loss 25.337109 Test MSE 6264.422080726243 Test RE 1.0952005936198026\n",
      "48 Train Loss 25.30392 Test MSE 6239.535224261105 Test RE 1.093022960646796\n",
      "49 Train Loss 25.284668 Test MSE 6236.199052471052 Test RE 1.0927307113206624\n",
      "50 Train Loss 25.197067 Test MSE 6387.341315773237 Test RE 1.1058932992146588\n",
      "51 Train Loss 25.155634 Test MSE 6541.639695401776 Test RE 1.1191710684281388\n",
      "52 Train Loss 25.114088 Test MSE 6486.58703996367 Test RE 1.1144517992006675\n",
      "53 Train Loss 25.068464 Test MSE 6483.267941825829 Test RE 1.114166637823159\n",
      "54 Train Loss 24.857311 Test MSE 6662.536386491359 Test RE 1.1294654788488843\n",
      "55 Train Loss 24.828482 Test MSE 6687.241158198324 Test RE 1.1315575776149691\n",
      "56 Train Loss 24.701311 Test MSE 6797.479735574832 Test RE 1.1408462664413561\n",
      "57 Train Loss 24.524544 Test MSE 6893.436888411711 Test RE 1.148870469758062\n",
      "58 Train Loss 24.497742 Test MSE 6915.5050431699265 Test RE 1.1507079561213895\n",
      "59 Train Loss 24.484226 Test MSE 6937.877426839274 Test RE 1.15256778357704\n",
      "60 Train Loss 24.480043 Test MSE 6958.126408533481 Test RE 1.1542485079856262\n",
      "61 Train Loss 24.479752 Test MSE 6958.836734256025 Test RE 1.1543074226584507\n",
      "62 Train Loss 24.450537 Test MSE 7001.591647648855 Test RE 1.1578480101812985\n",
      "63 Train Loss 24.439623 Test MSE 7028.3731098627495 Test RE 1.160060311914254\n",
      "64 Train Loss 24.421705 Test MSE 7051.909216199088 Test RE 1.162001051456212\n",
      "65 Train Loss 24.366959 Test MSE 7069.163152188209 Test RE 1.163421719432588\n",
      "66 Train Loss 24.194563 Test MSE 7190.356020426866 Test RE 1.1733521187270142\n",
      "67 Train Loss 24.166983 Test MSE 7210.974494816622 Test RE 1.1750332185286936\n",
      "68 Train Loss 23.995583 Test MSE 7333.529020898752 Test RE 1.1849763212418842\n",
      "69 Train Loss 23.842787 Test MSE 7440.2249038408745 Test RE 1.1935653336376992\n",
      "70 Train Loss 23.696224 Test MSE 7445.7835106401835 Test RE 1.1940111079089128\n",
      "71 Train Loss 23.620436 Test MSE 7483.612930095789 Test RE 1.197040441262811\n",
      "72 Train Loss 23.559322 Test MSE 7521.7642209728765 Test RE 1.200087805013484\n",
      "73 Train Loss 23.512403 Test MSE 7538.943155638468 Test RE 1.2014574618836464\n",
      "74 Train Loss 23.471167 Test MSE 7558.960063323532 Test RE 1.203051420089996\n",
      "75 Train Loss 23.193163 Test MSE 7508.622313349578 Test RE 1.1990389594542161\n",
      "76 Train Loss 22.477823 Test MSE 7319.92920314164 Test RE 1.1838770591867436\n",
      "77 Train Loss 22.358618 Test MSE 7182.998255224784 Test RE 1.1727516297485607\n",
      "78 Train Loss 22.299261 Test MSE 7143.195274194199 Test RE 1.1694978453031364\n",
      "79 Train Loss 22.284695 Test MSE 7104.311093415649 Test RE 1.1663104047417836\n",
      "80 Train Loss 22.247885 Test MSE 7116.1258451537715 Test RE 1.1672798121498702\n",
      "81 Train Loss 22.197762 Test MSE 7139.703757033357 Test RE 1.1692119913727428\n",
      "82 Train Loss 22.098272 Test MSE 7084.341176015395 Test RE 1.1646700266126728\n",
      "83 Train Loss 21.99977 Test MSE 7058.813425200063 Test RE 1.162569743931337\n",
      "84 Train Loss 21.914923 Test MSE 7028.619922613051 Test RE 1.160080680437527\n",
      "85 Train Loss 21.846529 Test MSE 6999.582131706466 Test RE 1.1576818421781476\n",
      "86 Train Loss 21.795197 Test MSE 6970.322960733445 Test RE 1.1552596773481132\n",
      "87 Train Loss 21.782639 Test MSE 6963.896531992426 Test RE 1.1547269971519414\n",
      "88 Train Loss 21.754728 Test MSE 6944.340224295635 Test RE 1.1531044807398014\n",
      "89 Train Loss 21.75264 Test MSE 6942.560925229982 Test RE 1.1529567453826606\n",
      "90 Train Loss 21.729824 Test MSE 6927.835686977154 Test RE 1.1517333801931438\n",
      "91 Train Loss 21.68867 Test MSE 6912.6179310609405 Test RE 1.150467730015752\n",
      "92 Train Loss 21.605392 Test MSE 6910.660874436793 Test RE 1.1503048619173937\n",
      "93 Train Loss 21.541248 Test MSE 6924.467507280667 Test RE 1.1514533709102772\n",
      "94 Train Loss 21.493492 Test MSE 6939.151009480387 Test RE 1.1526735668644041\n",
      "95 Train Loss 21.469074 Test MSE 6937.86435119409 Test RE 1.1525666974685975\n",
      "96 Train Loss 21.462027 Test MSE 6945.026455719851 Test RE 1.1531614535375587\n",
      "97 Train Loss 21.46202 Test MSE 6945.026745864363 Test RE 1.1531614776255494\n",
      "98 Train Loss 21.461985 Test MSE 6945.088246209046 Test RE 1.153166583413759\n",
      "99 Train Loss 21.461435 Test MSE 6946.427619018106 Test RE 1.153277773182175\n",
      "Training time: 65.96\n",
      "Training time: 65.96\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.769474 Test MSE 5221.558345238787 Test RE 0.9998923190664633\n",
      "1 Train Loss 47.746746 Test MSE 5168.874195217598 Test RE 0.994835205265015\n",
      "2 Train Loss 47.712307 Test MSE 5090.159285406726 Test RE 0.9872311521560785\n",
      "3 Train Loss 47.678967 Test MSE 5049.66491124868 Test RE 0.9832963897683638\n",
      "4 Train Loss 47.52794 Test MSE 5005.905893697379 Test RE 0.9790266304633057\n",
      "5 Train Loss 47.299805 Test MSE 4953.738489384686 Test RE 0.9739119681150411\n",
      "6 Train Loss 44.72633 Test MSE 4605.135040997745 Test RE 0.9390189348032824\n",
      "7 Train Loss 40.016666 Test MSE 4434.530932338 Test RE 0.9214611064077635\n",
      "8 Train Loss 36.070805 Test MSE 4119.127967480358 Test RE 0.8880876011623434\n",
      "9 Train Loss 34.026894 Test MSE 4087.2301503815183 Test RE 0.8846423196166152\n",
      "10 Train Loss 33.034378 Test MSE 4176.740183761996 Test RE 0.8942766576559971\n",
      "11 Train Loss 32.12367 Test MSE 3937.488625338552 Test RE 0.8682860442734602\n",
      "12 Train Loss 30.263584 Test MSE 4149.671361257627 Test RE 0.8913741112727545\n",
      "13 Train Loss 26.781857 Test MSE 3640.26470017303 Test RE 0.8348715212205075\n",
      "14 Train Loss 19.16786 Test MSE 483.8992339957213 Test RE 0.3043901761733951\n",
      "15 Train Loss 14.608973 Test MSE 364.35524069506044 Test RE 0.26412874933776975\n",
      "16 Train Loss 14.137893 Test MSE 401.60682610418786 Test RE 0.2773024506311545\n",
      "17 Train Loss 12.267608 Test MSE 321.15239411221614 Test RE 0.24797548402634442\n",
      "18 Train Loss 10.874605 Test MSE 405.98663055468626 Test RE 0.27881043933515864\n",
      "19 Train Loss 7.2701936 Test MSE 247.64776534708398 Test RE 0.2177561208972634\n",
      "20 Train Loss 7.1016397 Test MSE 233.99896888202025 Test RE 0.21167040293569955\n",
      "21 Train Loss 7.0776677 Test MSE 235.99414181849522 Test RE 0.21257088267224966\n",
      "22 Train Loss 6.514712 Test MSE 284.2894507300899 Test RE 0.23331009842239647\n",
      "23 Train Loss 6.3567195 Test MSE 271.4074938014187 Test RE 0.22796285217821183\n",
      "24 Train Loss 6.2755394 Test MSE 275.3528881738506 Test RE 0.2296137982804873\n",
      "25 Train Loss 5.8221374 Test MSE 239.8134575946797 Test RE 0.21428409639533552\n",
      "26 Train Loss 5.688376 Test MSE 207.07784249256068 Test RE 0.1991223368613603\n",
      "27 Train Loss 5.675053 Test MSE 199.30343464527346 Test RE 0.1953487138411267\n",
      "28 Train Loss 5.596424 Test MSE 203.34490081444036 Test RE 0.19731940981750423\n",
      "29 Train Loss 5.535848 Test MSE 195.22755839599435 Test RE 0.19334089563556392\n",
      "30 Train Loss 5.4923487 Test MSE 193.46178425933033 Test RE 0.19246455465313514\n",
      "31 Train Loss 5.4689584 Test MSE 195.38020054572343 Test RE 0.19341646438165122\n",
      "32 Train Loss 5.444553 Test MSE 189.82146231438216 Test RE 0.19064517665046338\n",
      "33 Train Loss 5.3924303 Test MSE 179.07375501746736 Test RE 0.18516936400568548\n",
      "34 Train Loss 5.385251 Test MSE 180.3962634988001 Test RE 0.18585186930923644\n",
      "35 Train Loss 5.3041925 Test MSE 181.55857454711293 Test RE 0.1864496390121197\n",
      "36 Train Loss 5.232308 Test MSE 184.44855895938602 Test RE 0.1879276997363883\n",
      "37 Train Loss 5.170227 Test MSE 181.1748777832169 Test RE 0.1862525181638912\n",
      "38 Train Loss 5.153321 Test MSE 178.21936085851945 Test RE 0.18472709711953686\n",
      "39 Train Loss 5.1326714 Test MSE 174.67072389786003 Test RE 0.18287874163623233\n",
      "40 Train Loss 5.1032815 Test MSE 180.75321825116674 Test RE 0.18603565338993125\n",
      "41 Train Loss 4.9667606 Test MSE 183.13119259178077 Test RE 0.1872553896205275\n",
      "42 Train Loss 4.923559 Test MSE 182.45255206671544 Test RE 0.18690810567619423\n",
      "43 Train Loss 4.913053 Test MSE 182.07288788010638 Test RE 0.18671353654628098\n",
      "44 Train Loss 4.8868847 Test MSE 186.4510862520149 Test RE 0.1889450956389513\n",
      "45 Train Loss 4.8631425 Test MSE 181.10428646249127 Test RE 0.1862162297657581\n",
      "46 Train Loss 4.856465 Test MSE 181.3041505450183 Test RE 0.18631895420704023\n",
      "47 Train Loss 4.829456 Test MSE 183.66687657271888 Test RE 0.18752906354604065\n",
      "48 Train Loss 4.8177304 Test MSE 186.62901807487887 Test RE 0.1890352300784537\n",
      "49 Train Loss 4.786534 Test MSE 194.4308498444235 Test RE 0.1929459877130562\n",
      "50 Train Loss 4.7207365 Test MSE 199.5126349454735 Test RE 0.19545121155068226\n",
      "51 Train Loss 4.6832867 Test MSE 203.3309921494682 Test RE 0.1973126614395417\n",
      "52 Train Loss 4.654661 Test MSE 203.35311930346325 Test RE 0.19732339725710044\n",
      "53 Train Loss 4.603611 Test MSE 195.58282490045073 Test RE 0.19351673229634053\n",
      "54 Train Loss 4.576609 Test MSE 201.34009952759877 Test RE 0.19634430280924273\n",
      "55 Train Loss 4.570624 Test MSE 202.62051099640777 Test RE 0.19696763385475308\n",
      "56 Train Loss 4.56307 Test MSE 204.25927419039658 Test RE 0.19776255159999923\n",
      "57 Train Loss 4.55616 Test MSE 207.75870630207237 Test RE 0.19944942143148853\n",
      "58 Train Loss 4.5504746 Test MSE 205.7834904857235 Test RE 0.19849904852983788\n",
      "59 Train Loss 4.5439925 Test MSE 206.24113360580424 Test RE 0.19871964755337612\n",
      "60 Train Loss 4.5364013 Test MSE 205.7563230196974 Test RE 0.1984859452091043\n",
      "61 Train Loss 4.53393 Test MSE 205.68813962959834 Test RE 0.1984530554155017\n",
      "62 Train Loss 4.5278487 Test MSE 204.05760037202933 Test RE 0.19766489782489893\n",
      "63 Train Loss 4.519197 Test MSE 202.8736593010226 Test RE 0.19709063832750418\n",
      "64 Train Loss 4.5156817 Test MSE 204.30575558065493 Test RE 0.19778505181568082\n",
      "65 Train Loss 4.5132775 Test MSE 205.62039967280467 Test RE 0.19842037412325647\n",
      "66 Train Loss 4.498956 Test MSE 213.5974713537674 Test RE 0.20223262459070795\n",
      "67 Train Loss 4.4946055 Test MSE 219.24019443927338 Test RE 0.2048864577021716\n",
      "68 Train Loss 4.4860635 Test MSE 226.41139066960508 Test RE 0.2082103435759577\n",
      "69 Train Loss 4.4647236 Test MSE 249.27087394846762 Test RE 0.218468553329271\n",
      "70 Train Loss 4.4239516 Test MSE 240.33864151193058 Test RE 0.214518605783749\n",
      "71 Train Loss 4.4076 Test MSE 228.2276499729798 Test RE 0.2090438011965154\n",
      "72 Train Loss 4.4025846 Test MSE 226.81564362775282 Test RE 0.20839613835810541\n",
      "73 Train Loss 4.397726 Test MSE 226.33193955058772 Test RE 0.208173808319825\n",
      "74 Train Loss 4.3892837 Test MSE 229.36874503508326 Test RE 0.20956573933616762\n",
      "75 Train Loss 4.386777 Test MSE 229.76490698885786 Test RE 0.20974664052020406\n",
      "76 Train Loss 4.3856516 Test MSE 230.75218072508676 Test RE 0.21019678624050772\n",
      "77 Train Loss 4.3816514 Test MSE 230.68496133185164 Test RE 0.21016616826428214\n",
      "78 Train Loss 4.3780856 Test MSE 229.1806749570515 Test RE 0.2094798053799004\n",
      "79 Train Loss 4.374175 Test MSE 230.75385913122963 Test RE 0.21019755068601512\n",
      "80 Train Loss 4.362258 Test MSE 228.7594066945665 Test RE 0.20928718926197387\n",
      "81 Train Loss 4.3527145 Test MSE 225.75897285601698 Test RE 0.2079101419478204\n",
      "82 Train Loss 4.34741 Test MSE 226.86770279293222 Test RE 0.2084200527283196\n",
      "83 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "84 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "85 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "86 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "87 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "88 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "89 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "90 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "91 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "92 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "93 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "94 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "95 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "96 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "97 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "98 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "99 Train Loss 4.3430786 Test MSE 221.91648767684916 Test RE 0.20613320211490693\n",
      "Training time: 60.44\n",
      "Training time: 60.44\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.763878 Test MSE 5205.808076428595 Test RE 0.9983831463560979\n",
      "1 Train Loss 47.718338 Test MSE 5110.552162140885 Test RE 0.9892067641159934\n",
      "2 Train Loss 47.680172 Test MSE 5035.45267532396 Test RE 0.9819116753964063\n",
      "3 Train Loss 47.657352 Test MSE 4993.592110055114 Test RE 0.9778217591379471\n",
      "4 Train Loss 47.588024 Test MSE 4975.694822289029 Test RE 0.9760679048255912\n",
      "5 Train Loss 47.41076 Test MSE 4827.109121125343 Test RE 0.9613836301403156\n",
      "6 Train Loss 47.119053 Test MSE 4873.641866280873 Test RE 0.9660063269667214\n",
      "7 Train Loss 46.873013 Test MSE 4994.345641214064 Test RE 0.9778955328215834\n",
      "8 Train Loss 40.78449 Test MSE 8162.680016735074 Test RE 1.250171375167053\n",
      "9 Train Loss 39.131527 Test MSE 8727.605525342897 Test RE 1.2927088408463085\n",
      "10 Train Loss 39.072136 Test MSE 8759.939390361827 Test RE 1.2951012284968808\n",
      "11 Train Loss 39.06588 Test MSE 8696.653612543261 Test RE 1.2904145489527048\n",
      "12 Train Loss 39.04423 Test MSE 8597.166289535595 Test RE 1.2830123246227647\n",
      "13 Train Loss 39.017956 Test MSE 8551.432653535157 Test RE 1.2795952067337604\n",
      "14 Train Loss 38.750626 Test MSE 8347.726764046422 Test RE 1.2642625614222027\n",
      "15 Train Loss 38.593487 Test MSE 8286.731562936377 Test RE 1.2596352339777335\n",
      "16 Train Loss 38.52666 Test MSE 8290.987738445783 Test RE 1.2599586751541536\n",
      "17 Train Loss 38.31909 Test MSE 7929.318624324105 Test RE 1.232171329867291\n",
      "18 Train Loss 38.28571 Test MSE 7782.544333181411 Test RE 1.2207141150821088\n",
      "19 Train Loss 38.191113 Test MSE 7844.462646992305 Test RE 1.2255605260292461\n",
      "20 Train Loss 38.08685 Test MSE 7716.256145415659 Test RE 1.2155042525719817\n",
      "21 Train Loss 38.01915 Test MSE 7639.315838484679 Test RE 1.2094290544558084\n",
      "22 Train Loss 37.858265 Test MSE 7728.772425855276 Test RE 1.2164896674835783\n",
      "23 Train Loss 37.748924 Test MSE 7886.688554651083 Test RE 1.2288546299727061\n",
      "24 Train Loss 37.720524 Test MSE 7874.761757993153 Test RE 1.2279250988739618\n",
      "25 Train Loss 37.710056 Test MSE 7869.9507358632445 Test RE 1.227549946102478\n",
      "26 Train Loss 37.68939 Test MSE 7934.576935725149 Test RE 1.2325798181030159\n",
      "27 Train Loss 37.65603 Test MSE 8027.348204991066 Test RE 1.239764554922385\n",
      "28 Train Loss 37.647697 Test MSE 8035.583989777254 Test RE 1.2404003699046644\n",
      "29 Train Loss 37.639374 Test MSE 8084.977824175504 Test RE 1.2442068304380507\n",
      "30 Train Loss 37.624973 Test MSE 8189.815590013633 Test RE 1.25224765218525\n",
      "31 Train Loss 37.46113 Test MSE 8312.942015628925 Test RE 1.2616257379568279\n",
      "32 Train Loss 37.24057 Test MSE 8438.295183527847 Test RE 1.2711023494517137\n",
      "33 Train Loss 37.142693 Test MSE 8500.992087615748 Test RE 1.2758157835604436\n",
      "34 Train Loss 36.986935 Test MSE 8495.922771438602 Test RE 1.275435329256441\n",
      "35 Train Loss 36.95944 Test MSE 8520.383933624127 Test RE 1.277270103833301\n",
      "36 Train Loss 36.932224 Test MSE 8593.757135329237 Test RE 1.2827579140169052\n",
      "37 Train Loss 36.89717 Test MSE 8629.046160177468 Test RE 1.2853889460249646\n",
      "38 Train Loss 36.842785 Test MSE 8686.48790168428 Test RE 1.289660131363235\n",
      "39 Train Loss 36.755817 Test MSE 8738.264803290724 Test RE 1.29349801137479\n",
      "40 Train Loss 36.489414 Test MSE 8857.729001812786 Test RE 1.3023099516058714\n",
      "41 Train Loss 36.280994 Test MSE 9090.661006015041 Test RE 1.3193222787374173\n",
      "42 Train Loss 36.100792 Test MSE 9471.492943423318 Test RE 1.3466737188871623\n",
      "43 Train Loss 36.08528 Test MSE 9620.078296276868 Test RE 1.357195678219772\n",
      "44 Train Loss 36.078613 Test MSE 9826.21635970209 Test RE 1.3716595321728267\n",
      "45 Train Loss 36.064743 Test MSE 10002.266809600813 Test RE 1.3838925846618397\n",
      "46 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "47 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "48 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "49 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "50 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "51 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "52 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "53 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "54 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "55 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "56 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "57 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "58 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "59 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "60 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "61 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "62 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "63 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "64 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "65 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "66 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "67 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "68 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "69 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "70 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "71 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "72 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "73 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "74 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "75 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "76 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "77 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "78 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "79 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "80 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "81 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "82 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "83 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "84 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "85 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "86 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "87 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "88 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "89 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "90 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "91 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "92 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "93 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "94 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "95 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "96 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "97 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "98 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "99 Train Loss 36.046238 Test MSE 10017.288974696015 Test RE 1.3849314123337808\n",
      "Training time: 39.40\n",
      "Training time: 39.40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.746964 Test MSE 5173.022731127143 Test RE 0.9952343523176802\n",
      "1 Train Loss 47.67645 Test MSE 5064.632287525129 Test RE 0.9847525732731582\n",
      "2 Train Loss 47.485855 Test MSE 4807.946851016335 Test RE 0.9594735208440315\n",
      "3 Train Loss 47.47515 Test MSE 4744.176502542874 Test RE 0.9530892777476615\n",
      "4 Train Loss 47.165813 Test MSE 4533.102151399759 Test RE 0.9316459869263712\n",
      "5 Train Loss 44.306366 Test MSE 4325.823955822828 Test RE 0.9100967958518825\n",
      "6 Train Loss 43.407944 Test MSE 4253.084721562733 Test RE 0.9024126646401247\n",
      "7 Train Loss 43.054363 Test MSE 4214.877806578354 Test RE 0.8983501795483276\n",
      "8 Train Loss 42.192604 Test MSE 4134.048445619134 Test RE 0.8896945813439859\n",
      "9 Train Loss 40.43099 Test MSE 3929.322704487827 Test RE 0.8673852118190004\n",
      "10 Train Loss 35.622643 Test MSE 3364.535945995601 Test RE 0.8026306701054208\n",
      "11 Train Loss 31.412506 Test MSE 2701.876464382755 Test RE 0.719260000216618\n",
      "12 Train Loss 18.845022 Test MSE 1911.514578098473 Test RE 0.6049813294359458\n",
      "13 Train Loss 15.376511 Test MSE 1166.8640452074605 Test RE 0.4726757192333068\n",
      "14 Train Loss 14.757306 Test MSE 859.9018658334503 Test RE 0.4057678280439093\n",
      "15 Train Loss 13.898969 Test MSE 786.5407576289132 Test RE 0.38807331526552025\n",
      "16 Train Loss 13.2028675 Test MSE 843.7966372671063 Test RE 0.4019500248235169\n",
      "17 Train Loss 13.102006 Test MSE 826.0843245851585 Test RE 0.39770894166213905\n",
      "18 Train Loss 11.483113 Test MSE 874.36979854179 Test RE 0.4091671309144388\n",
      "19 Train Loss 11.087807 Test MSE 840.3927849892012 Test RE 0.40113847792006907\n",
      "20 Train Loss 10.92027 Test MSE 792.5493362935439 Test RE 0.38955278896677686\n",
      "21 Train Loss 10.703055 Test MSE 811.1498901479184 Test RE 0.39409753779563084\n",
      "22 Train Loss 10.516126 Test MSE 761.3558303873324 Test RE 0.381809740460683\n",
      "23 Train Loss 10.290387 Test MSE 739.828543407768 Test RE 0.37637321264769336\n",
      "24 Train Loss 10.121999 Test MSE 706.7215606055784 Test RE 0.36785556891094817\n",
      "25 Train Loss 10.006835 Test MSE 662.3824304620381 Test RE 0.3561291858516701\n",
      "26 Train Loss 9.97337 Test MSE 614.2357555072756 Test RE 0.3429420278410405\n",
      "27 Train Loss 9.969883 Test MSE 606.6005628832019 Test RE 0.3408039103414042\n",
      "28 Train Loss 9.969854 Test MSE 606.5556517802187 Test RE 0.34079129399733604\n",
      "29 Train Loss 9.969854 Test MSE 606.5556517802187 Test RE 0.34079129399733604\n",
      "30 Train Loss 9.969797 Test MSE 606.0327512668775 Test RE 0.3406443673597391\n",
      "31 Train Loss 9.969797 Test MSE 606.0327512668775 Test RE 0.3406443673597391\n",
      "32 Train Loss 9.969797 Test MSE 606.0327512668775 Test RE 0.3406443673597391\n",
      "33 Train Loss 9.969795 Test MSE 606.0325948871821 Test RE 0.3406443234100797\n",
      "34 Train Loss 9.969795 Test MSE 606.0325948871821 Test RE 0.3406443234100797\n",
      "35 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "36 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "37 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "38 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "39 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "40 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "41 Train Loss 9.969783 Test MSE 606.0176481232587 Test RE 0.34064012267754434\n",
      "42 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "43 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "44 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "45 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "46 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "47 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "48 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "49 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "50 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "51 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "52 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "53 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "54 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "55 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "56 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "57 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "58 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "59 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "60 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "61 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "62 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "63 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "64 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "65 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "66 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "67 Train Loss 9.96977 Test MSE 606.0239806558317 Test RE 0.3406419024186493\n",
      "68 Train Loss 9.969756 Test MSE 606.0239133649659 Test RE 0.34064188350678276\n",
      "69 Train Loss 9.969756 Test MSE 606.0239133649659 Test RE 0.34064188350678276\n",
      "70 Train Loss 9.969756 Test MSE 606.0239133649659 Test RE 0.34064188350678276\n",
      "71 Train Loss 9.969756 Test MSE 606.0239133649659 Test RE 0.34064188350678276\n",
      "72 Train Loss 9.969756 Test MSE 606.0239133649659 Test RE 0.34064188350678276\n",
      "73 Train Loss 9.969756 Test MSE 606.0239133649659 Test RE 0.34064188350678276\n",
      "74 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "75 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "76 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "77 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "78 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "79 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "80 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "81 Train Loss 9.969755 Test MSE 606.0087353665293 Test RE 0.3406376177556844\n",
      "82 Train Loss 9.969721 Test MSE 604.7183562377859 Test RE 0.34027476332686374\n",
      "83 Train Loss 9.969721 Test MSE 604.7183562377859 Test RE 0.34027476332686374\n",
      "84 Train Loss 9.969721 Test MSE 604.7183562377859 Test RE 0.34027476332686374\n",
      "85 Train Loss 9.967864 Test MSE 603.348023964982 Test RE 0.3398890019674462\n",
      "86 Train Loss 9.944504 Test MSE 584.2368507969061 Test RE 0.3344626589243613\n",
      "87 Train Loss 9.905741 Test MSE 565.0715717471304 Test RE 0.3289310672230848\n",
      "88 Train Loss 9.84387 Test MSE 542.3326045741834 Test RE 0.32224487719539385\n",
      "89 Train Loss 9.747138 Test MSE 528.7492634730642 Test RE 0.31818379133658287\n",
      "90 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "91 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "92 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "93 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "94 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "95 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "96 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "97 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "98 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "99 Train Loss 9.255114 Test MSE 661.2702343945615 Test RE 0.3558300747439663\n",
      "Training time: 38.42\n",
      "Training time: 38.42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.74698 Test MSE 5174.847570142771 Test RE 0.9954098766129057\n",
      "1 Train Loss 47.730698 Test MSE 5133.889928437766 Test RE 0.9914628393556824\n",
      "2 Train Loss 47.67023 Test MSE 5048.425645354147 Test RE 0.9831757242911123\n",
      "3 Train Loss 47.505806 Test MSE 4860.886575919497 Test RE 0.9647413834012823\n",
      "4 Train Loss 47.376923 Test MSE 4780.610420159211 Test RE 0.9567420046118408\n",
      "5 Train Loss 47.07408 Test MSE 4650.598829951044 Test RE 0.9436427415487191\n",
      "6 Train Loss 46.342236 Test MSE 4558.371647076617 Test RE 0.9342390794616385\n",
      "7 Train Loss 43.146633 Test MSE 4480.99946663179 Test RE 0.9262764249662085\n",
      "8 Train Loss 38.122364 Test MSE 5425.149444813516 Test RE 1.0191990676518772\n",
      "9 Train Loss 35.773 Test MSE 5588.929298887128 Test RE 1.0344689806606218\n",
      "10 Train Loss 34.58192 Test MSE 5537.713652896716 Test RE 1.029718255613088\n",
      "11 Train Loss 33.81655 Test MSE 5639.173655650784 Test RE 1.0391085038687258\n",
      "12 Train Loss 31.993017 Test MSE 5838.254763564219 Test RE 1.0572913663528178\n",
      "13 Train Loss 30.735855 Test MSE 6069.96907865855 Test RE 1.0780686177372\n",
      "14 Train Loss 29.950043 Test MSE 6280.500615472804 Test RE 1.096605187363952\n",
      "15 Train Loss 29.749865 Test MSE 6369.250133029887 Test RE 1.1043260505328771\n",
      "16 Train Loss 27.04525 Test MSE 6508.67140362056 Test RE 1.1163473295969997\n",
      "17 Train Loss 25.320467 Test MSE 6889.348412512883 Test RE 1.148529723482125\n",
      "18 Train Loss 25.161287 Test MSE 6943.405596421081 Test RE 1.1530268808656678\n",
      "19 Train Loss 24.884764 Test MSE 7042.672040580036 Test RE 1.1612397593933776\n",
      "20 Train Loss 24.568144 Test MSE 7121.782763217327 Test RE 1.167743680736906\n",
      "21 Train Loss 24.533518 Test MSE 7155.872275731396 Test RE 1.1705351369810364\n",
      "22 Train Loss 24.513823 Test MSE 7126.576714746936 Test RE 1.168136641673175\n",
      "23 Train Loss 24.483904 Test MSE 7173.370974767803 Test RE 1.1719654542491689\n",
      "24 Train Loss 24.365131 Test MSE 7244.412421660306 Test RE 1.1777544340555004\n",
      "25 Train Loss 24.284863 Test MSE 7337.463116072084 Test RE 1.18529412080125\n",
      "26 Train Loss 24.256897 Test MSE 7400.65468472515 Test RE 1.1903871631742935\n",
      "27 Train Loss 24.213835 Test MSE 7354.261214881186 Test RE 1.1866501279650439\n",
      "28 Train Loss 24.136183 Test MSE 7386.51952636677 Test RE 1.1892498074963378\n",
      "29 Train Loss 24.092262 Test MSE 7488.638196658742 Test RE 1.197442281781004\n",
      "30 Train Loss 24.070498 Test MSE 7462.937994752817 Test RE 1.1953857691875143\n",
      "31 Train Loss 24.063978 Test MSE 7496.769370388576 Test RE 1.1980921976533168\n",
      "32 Train Loss 24.063742 Test MSE 7500.628425941104 Test RE 1.198400524431883\n",
      "33 Train Loss 24.063742 Test MSE 7500.628425941104 Test RE 1.198400524431883\n",
      "34 Train Loss 24.063189 Test MSE 7496.76692739707 Test RE 1.1980920024406085\n",
      "35 Train Loss 24.063189 Test MSE 7496.76692739707 Test RE 1.1980920024406085\n",
      "36 Train Loss 24.063189 Test MSE 7496.76692739707 Test RE 1.1980920024406085\n",
      "37 Train Loss 24.063189 Test MSE 7496.76692739707 Test RE 1.1980920024406085\n",
      "38 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "39 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "40 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "41 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "42 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "43 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "44 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "45 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "46 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "47 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "48 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "49 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "50 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "51 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "52 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "53 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "54 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "55 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "56 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "57 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "58 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "59 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "60 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "61 Train Loss 24.063147 Test MSE 7496.773674843082 Test RE 1.1980925416103174\n",
      "62 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "63 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "64 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "65 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "66 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "67 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "68 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "69 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "70 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "71 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "72 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "73 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "74 Train Loss 24.063147 Test MSE 7496.773792136425 Test RE 1.1980925509829015\n",
      "75 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "76 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "77 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "78 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "79 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "80 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "81 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "82 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "83 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "84 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "85 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "86 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "87 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "88 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "89 Train Loss 24.063147 Test MSE 7496.773812750408 Test RE 1.1980925526301074\n",
      "90 Train Loss 24.06312 Test MSE 7495.398316128663 Test RE 1.1979826354911725\n",
      "91 Train Loss 24.06312 Test MSE 7495.398316128663 Test RE 1.1979826354911725\n",
      "92 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "93 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "94 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "95 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "96 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "97 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "98 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "99 Train Loss 24.06312 Test MSE 7495.3981347719955 Test RE 1.1979826209981375\n",
      "Training time: 33.12\n",
      "Training time: 33.12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.744205 Test MSE 5166.136952063831 Test RE 0.9945717565563396\n",
      "1 Train Loss 47.71878 Test MSE 5105.670860055057 Test RE 0.9887342348821408\n",
      "2 Train Loss 47.675278 Test MSE 5032.274546221516 Test RE 0.9816017594040317\n",
      "3 Train Loss 44.217945 Test MSE 4515.036997256779 Test RE 0.9297877528522072\n",
      "4 Train Loss 42.04139 Test MSE 4418.186041324228 Test RE 0.9197613679877488\n",
      "5 Train Loss 41.328552 Test MSE 4549.734704391044 Test RE 0.9333535883487997\n",
      "6 Train Loss 40.53642 Test MSE 4283.96363095167 Test RE 0.9056826586687264\n",
      "7 Train Loss 39.997746 Test MSE 4422.203947802706 Test RE 0.9201794892856392\n",
      "8 Train Loss 38.81901 Test MSE 4590.906519725999 Test RE 0.9375671655256623\n",
      "9 Train Loss 34.11898 Test MSE 4834.476998727666 Test RE 0.9621170562833009\n",
      "10 Train Loss 25.95452 Test MSE 3260.926721574783 Test RE 0.7901757266286762\n",
      "11 Train Loss 22.388552 Test MSE 2643.337011551825 Test RE 0.7114255087873834\n",
      "12 Train Loss 17.353624 Test MSE 1864.1891295906403 Test RE 0.5974453018167459\n",
      "13 Train Loss 14.100782 Test MSE 1536.66385064414 Test RE 0.5424286275757458\n",
      "14 Train Loss 12.931049 Test MSE 1167.228886375007 Test RE 0.47274960876828115\n",
      "15 Train Loss 12.133363 Test MSE 1219.8881059317146 Test RE 0.4832959581731364\n",
      "16 Train Loss 11.644 Test MSE 1093.8561713152062 Test RE 0.45764979836450265\n",
      "17 Train Loss 10.62559 Test MSE 902.778786150235 Test RE 0.4157610851419317\n",
      "18 Train Loss 10.243353 Test MSE 864.902241872169 Test RE 0.40694589886576027\n",
      "19 Train Loss 9.663763 Test MSE 834.3542043749262 Test RE 0.3996947041807552\n",
      "20 Train Loss 9.0246105 Test MSE 717.6122698311914 Test RE 0.3706790937245614\n",
      "21 Train Loss 8.107663 Test MSE 591.4039120882584 Test RE 0.3365078975448681\n",
      "22 Train Loss 7.757986 Test MSE 646.2702676141877 Test RE 0.35177117771578686\n",
      "23 Train Loss 7.5949507 Test MSE 646.5089772265117 Test RE 0.35183613769700267\n",
      "24 Train Loss 7.1631756 Test MSE 700.9503777043693 Test RE 0.3663505110686745\n",
      "25 Train Loss 6.8411856 Test MSE 762.3830328535886 Test RE 0.38206721777634856\n",
      "26 Train Loss 6.75824 Test MSE 800.7233207997743 Test RE 0.3915564689256905\n",
      "27 Train Loss 6.676907 Test MSE 794.0924914164739 Test RE 0.3899318493117947\n",
      "28 Train Loss 6.4825716 Test MSE 753.6795660907073 Test RE 0.37988009247724264\n",
      "29 Train Loss 6.3211823 Test MSE 758.0649991070791 Test RE 0.38098369300026924\n",
      "30 Train Loss 6.206976 Test MSE 713.0020113514198 Test RE 0.3694864719676346\n",
      "31 Train Loss 6.1420736 Test MSE 665.9173090479612 Test RE 0.357078183222108\n",
      "32 Train Loss 6.060954 Test MSE 621.9500890683433 Test RE 0.34508885366783515\n",
      "33 Train Loss 5.813139 Test MSE 608.7428557798665 Test RE 0.3414051777676793\n",
      "34 Train Loss 5.6602254 Test MSE 606.9459882956733 Test RE 0.3409009310039188\n",
      "35 Train Loss 5.5508265 Test MSE 576.1863015760887 Test RE 0.33215028482211345\n",
      "36 Train Loss 5.443076 Test MSE 598.6247800216898 Test RE 0.3385559961007876\n",
      "37 Train Loss 5.3554726 Test MSE 577.848296959817 Test RE 0.33262897958695664\n",
      "38 Train Loss 5.2853384 Test MSE 576.7609347783823 Test RE 0.332315871037436\n",
      "39 Train Loss 5.270903 Test MSE 593.230930464652 Test RE 0.33702728201582427\n",
      "40 Train Loss 5.1535363 Test MSE 680.7557716168428 Test RE 0.36103460491259726\n",
      "41 Train Loss 4.7870007 Test MSE 832.7822220496467 Test RE 0.399318000118595\n",
      "42 Train Loss 4.605802 Test MSE 808.1292913231183 Test RE 0.39336307375315693\n",
      "43 Train Loss 4.471357 Test MSE 796.804841807608 Test RE 0.39059721904310274\n",
      "44 Train Loss 4.3882723 Test MSE 869.1589675760306 Test RE 0.4079460875763142\n",
      "45 Train Loss 4.28429 Test MSE 881.5512794548997 Test RE 0.4108440055259364\n",
      "46 Train Loss 4.240978 Test MSE 918.8814219444085 Test RE 0.4194526091154548\n",
      "47 Train Loss 4.1945367 Test MSE 890.1569306765538 Test RE 0.4128444527090093\n",
      "48 Train Loss 4.1724167 Test MSE 893.5648655238729 Test RE 0.41363397807702945\n",
      "49 Train Loss 4.159044 Test MSE 933.306255413666 Test RE 0.422732125253664\n",
      "50 Train Loss 4.14238 Test MSE 947.5092510613503 Test RE 0.4259365355479324\n",
      "51 Train Loss 4.1157184 Test MSE 912.6814255379219 Test RE 0.4180351213668307\n",
      "52 Train Loss 4.0875216 Test MSE 885.8109358173695 Test RE 0.411835408606624\n",
      "53 Train Loss 4.077507 Test MSE 889.2801269171975 Test RE 0.4126410769120093\n",
      "54 Train Loss 4.0452456 Test MSE 931.6325829134487 Test RE 0.4223529182112363\n",
      "55 Train Loss 4.0190554 Test MSE 957.3501525615953 Test RE 0.4281427261870048\n",
      "56 Train Loss 3.933121 Test MSE 992.4960904623119 Test RE 0.43593081259116867\n",
      "57 Train Loss 3.9091542 Test MSE 1035.8989359306036 Test RE 0.4453606664207227\n",
      "58 Train Loss 3.8811247 Test MSE 1011.1775050157667 Test RE 0.44001437461586435\n",
      "59 Train Loss 3.8595705 Test MSE 1015.8564294287288 Test RE 0.44103121778563653\n",
      "60 Train Loss 3.8069415 Test MSE 986.9784532737594 Test RE 0.43471737689052503\n",
      "61 Train Loss 3.7000046 Test MSE 834.0052119049694 Test RE 0.3996111035763442\n",
      "62 Train Loss 3.620935 Test MSE 829.5647222221393 Test RE 0.3985458600891921\n",
      "63 Train Loss 3.5486522 Test MSE 852.8057985116171 Test RE 0.4040901245644737\n",
      "64 Train Loss 3.531416 Test MSE 848.4742823016951 Test RE 0.4030626039249806\n",
      "65 Train Loss 3.5099626 Test MSE 839.0752427473374 Test RE 0.4008239082273878\n",
      "66 Train Loss 3.4997692 Test MSE 824.4906571931436 Test RE 0.39732512990421426\n",
      "67 Train Loss 3.4917397 Test MSE 838.6960287743887 Test RE 0.4007333232616833\n",
      "68 Train Loss 3.4737895 Test MSE 851.0186826153142 Test RE 0.4036665025536116\n",
      "69 Train Loss 3.4394183 Test MSE 838.5994158771512 Test RE 0.4007102415246295\n",
      "70 Train Loss 3.4343538 Test MSE 833.5976099739947 Test RE 0.3995134410190321\n",
      "71 Train Loss 3.382333 Test MSE 825.3118338734772 Test RE 0.3975229447175778\n",
      "72 Train Loss 3.346496 Test MSE 811.9776324633995 Test RE 0.39429856601116514\n",
      "73 Train Loss 3.310151 Test MSE 828.750111565591 Test RE 0.39835013127079844\n",
      "74 Train Loss 3.294634 Test MSE 844.6270492912998 Test RE 0.4021477632577577\n",
      "75 Train Loss 3.273121 Test MSE 905.1727164725138 Test RE 0.4163119643479648\n",
      "76 Train Loss 3.258269 Test MSE 958.4325654482819 Test RE 0.4283846942303882\n",
      "77 Train Loss 3.2441044 Test MSE 980.9424755105033 Test RE 0.4333860567980842\n",
      "78 Train Loss 3.208637 Test MSE 990.7785489279222 Test RE 0.4355534541871246\n",
      "79 Train Loss 3.1913018 Test MSE 1011.8973285491178 Test RE 0.4401709625306882\n",
      "80 Train Loss 3.1752956 Test MSE 982.4469360057816 Test RE 0.43371826914156975\n",
      "81 Train Loss 3.1396544 Test MSE 901.9771990315483 Test RE 0.41557646475291166\n",
      "82 Train Loss 3.117142 Test MSE 889.980443319417 Test RE 0.41280352428632905\n",
      "83 Train Loss 3.0895338 Test MSE 956.9764626414785 Test RE 0.428059157893545\n",
      "84 Train Loss 3.0742714 Test MSE 958.8924160348724 Test RE 0.4284874501970918\n",
      "85 Train Loss 3.0138073 Test MSE 957.8827218385072 Test RE 0.4282617964975407\n",
      "86 Train Loss 2.963574 Test MSE 944.6743328763641 Test RE 0.4252988637892358\n",
      "87 Train Loss 2.9284766 Test MSE 950.5523220523905 Test RE 0.42661996744139347\n",
      "88 Train Loss 2.90557 Test MSE 971.3234033173669 Test RE 0.4312559411290035\n",
      "89 Train Loss 2.8980029 Test MSE 988.0544675906661 Test RE 0.4349542790738707\n",
      "90 Train Loss 2.8841944 Test MSE 1007.7853195586124 Test RE 0.4392756990273044\n",
      "91 Train Loss 2.8685973 Test MSE 1037.8133634716585 Test RE 0.44577200826866126\n",
      "92 Train Loss 2.8444688 Test MSE 1031.0347712938967 Test RE 0.44431381882570625\n",
      "93 Train Loss 2.812892 Test MSE 1024.6465926201001 Test RE 0.44293522018375275\n",
      "94 Train Loss 2.7709293 Test MSE 992.7777246958923 Test RE 0.4359926588458212\n",
      "95 Train Loss 2.747461 Test MSE 973.5994992395172 Test RE 0.4317609251157665\n",
      "96 Train Loss 2.6799667 Test MSE 923.2180958587652 Test RE 0.4204412502834285\n",
      "97 Train Loss 2.6516688 Test MSE 904.8670037293928 Test RE 0.41624165587627543\n",
      "98 Train Loss 2.623171 Test MSE 906.14031584695 Test RE 0.4165344167017044\n",
      "99 Train Loss 2.5830462 Test MSE 907.6959021204747 Test RE 0.4168917991949513\n",
      "Training time: 70.33\n",
      "Training time: 70.33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.745537 Test MSE 5158.319997493133 Test RE 0.9938190214399142\n",
      "1 Train Loss 47.723614 Test MSE 5119.13929153131 Test RE 0.9900374846480058\n",
      "2 Train Loss 47.69228 Test MSE 5070.156298577066 Test RE 0.9852894633473258\n",
      "3 Train Loss 47.29258 Test MSE 4730.184287626796 Test RE 0.9516827451786695\n",
      "4 Train Loss 47.10735 Test MSE 4623.867456202147 Test RE 0.9409268311838386\n",
      "5 Train Loss 46.40752 Test MSE 4516.0934220705 Test RE 0.929896521994559\n",
      "6 Train Loss 43.293175 Test MSE 4121.152611871661 Test RE 0.8883058319022221\n",
      "7 Train Loss 37.644314 Test MSE 2860.0546964732816 Test RE 0.7400146782238134\n",
      "8 Train Loss 29.120779 Test MSE 2432.8651053942135 Test RE 0.6825149667065906\n",
      "9 Train Loss 25.171867 Test MSE 1458.6793504978184 Test RE 0.5284855073752578\n",
      "10 Train Loss 23.35606 Test MSE 1234.1307170026419 Test RE 0.4861090937663508\n",
      "11 Train Loss 18.524166 Test MSE 743.48745218365 Test RE 0.37730276368300364\n",
      "12 Train Loss 17.21886 Test MSE 684.131300788827 Test RE 0.36192859356103946\n",
      "13 Train Loss 16.416979 Test MSE 740.4222781341554 Test RE 0.37652420778831236\n",
      "14 Train Loss 15.695555 Test MSE 792.2855654075631 Test RE 0.3894879594158821\n",
      "15 Train Loss 14.9663315 Test MSE 715.7044847434778 Test RE 0.370186037297755\n",
      "16 Train Loss 13.454443 Test MSE 641.3770537061102 Test RE 0.3504369354687314\n",
      "17 Train Loss 12.956048 Test MSE 537.9100828319864 Test RE 0.32092829376247956\n",
      "18 Train Loss 12.773906 Test MSE 617.836057159763 Test RE 0.34394562519881505\n",
      "19 Train Loss 12.330529 Test MSE 588.4825847065522 Test RE 0.33567575330067545\n",
      "20 Train Loss 12.261534 Test MSE 604.7648447979435 Test RE 0.34028784262206696\n",
      "21 Train Loss 12.232565 Test MSE 638.8465728707732 Test RE 0.34974494754958335\n",
      "22 Train Loss 12.132 Test MSE 638.740307185682 Test RE 0.3497158580672975\n",
      "23 Train Loss 11.960565 Test MSE 661.389181426308 Test RE 0.3558620760543617\n",
      "24 Train Loss 11.82928 Test MSE 688.6432030676493 Test RE 0.3631201067004676\n",
      "25 Train Loss 11.787977 Test MSE 712.9732270944924 Test RE 0.3694790137131611\n",
      "26 Train Loss 11.525865 Test MSE 760.4256487373099 Test RE 0.3815764323655621\n",
      "27 Train Loss 10.7134285 Test MSE 670.4047254677388 Test RE 0.35827928438368983\n",
      "28 Train Loss 10.521665 Test MSE 682.3692273045571 Test RE 0.3614621948181819\n",
      "29 Train Loss 10.2965765 Test MSE 670.6580395878236 Test RE 0.35834696635745183\n",
      "30 Train Loss 10.188824 Test MSE 681.5308028259329 Test RE 0.3612400629509159\n",
      "31 Train Loss 10.055702 Test MSE 670.8477832622075 Test RE 0.3583976548287139\n",
      "32 Train Loss 9.926014 Test MSE 671.8112781624984 Test RE 0.35865493406714194\n",
      "33 Train Loss 9.711665 Test MSE 692.4536194775598 Test RE 0.364123333109077\n",
      "34 Train Loss 9.544294 Test MSE 700.2131014964433 Test RE 0.36615779230687895\n",
      "35 Train Loss 9.3619175 Test MSE 726.7898892961639 Test RE 0.37304189034230634\n",
      "36 Train Loss 9.195834 Test MSE 743.6626940260917 Test RE 0.3773472266632559\n",
      "37 Train Loss 9.118656 Test MSE 767.1239942049993 Test RE 0.38325333978688736\n",
      "38 Train Loss 9.09825 Test MSE 756.5402358786108 Test RE 0.3806003470276633\n",
      "39 Train Loss 9.095728 Test MSE 750.7870395139792 Test RE 0.37915042590713555\n",
      "40 Train Loss 9.074241 Test MSE 745.9693702545923 Test RE 0.3779319971302521\n",
      "41 Train Loss 9.050082 Test MSE 722.8872696906053 Test RE 0.3720389868718943\n",
      "42 Train Loss 8.991414 Test MSE 712.2731975212765 Test RE 0.36929758350982417\n",
      "43 Train Loss 8.905741 Test MSE 699.9174768988205 Test RE 0.3660804896419641\n",
      "44 Train Loss 8.80911 Test MSE 714.483306064073 Test RE 0.36987008545939976\n",
      "45 Train Loss 8.685922 Test MSE 727.1630407416324 Test RE 0.3731376424021067\n",
      "46 Train Loss 8.540993 Test MSE 772.3193612222761 Test RE 0.3845489464156596\n",
      "47 Train Loss 8.513927 Test MSE 765.5618887132956 Test RE 0.3828629288244704\n",
      "48 Train Loss 8.484998 Test MSE 849.1422619646311 Test RE 0.4032212325705364\n",
      "49 Train Loss 8.482481 Test MSE 845.3889481104823 Test RE 0.40232910177929143\n",
      "50 Train Loss 8.465667 Test MSE 833.4998312778278 Test RE 0.39949000942056917\n",
      "51 Train Loss 8.349342 Test MSE 875.1248246874788 Test RE 0.4093437525336494\n",
      "52 Train Loss 8.347935 Test MSE 880.0259864955472 Test RE 0.4104884228247755\n",
      "53 Train Loss 8.303227 Test MSE 923.3910241046602 Test RE 0.4204806249251872\n",
      "54 Train Loss 8.268259 Test MSE 1009.5642094386994 Test RE 0.43966322132626506\n",
      "55 Train Loss 8.235923 Test MSE 1057.410961992472 Test RE 0.44996120261760647\n",
      "56 Train Loss 8.153726 Test MSE 1165.1524951222173 Test RE 0.4723289328827978\n",
      "57 Train Loss 8.085838 Test MSE 1168.7830619321928 Test RE 0.4730642392066874\n",
      "58 Train Loss 7.971112 Test MSE 1146.2188603230697 Test RE 0.46847556083934183\n",
      "59 Train Loss 7.903481 Test MSE 1203.563306660917 Test RE 0.4800512822840153\n",
      "60 Train Loss 7.816283 Test MSE 1403.7639587204703 Test RE 0.5184420373120266\n",
      "61 Train Loss 7.7958016 Test MSE 1504.5161423762468 Test RE 0.5367247106793768\n",
      "62 Train Loss 7.734733 Test MSE 1641.4612147523676 Test RE 0.5606198584510241\n",
      "63 Train Loss 7.692819 Test MSE 1500.7001729774302 Test RE 0.5360436194798698\n",
      "64 Train Loss 7.6341653 Test MSE 1490.120078962693 Test RE 0.5341506953095163\n",
      "65 Train Loss 7.6113415 Test MSE 1568.1310480796972 Test RE 0.5479543027358551\n",
      "66 Train Loss 7.598391 Test MSE 1650.91645352982 Test RE 0.5622321972010815\n",
      "67 Train Loss 7.57107 Test MSE 1768.7105982839187 Test RE 0.5819444809243917\n",
      "68 Train Loss 7.3993354 Test MSE 1957.6578665808559 Test RE 0.6122398044677145\n",
      "69 Train Loss 7.210964 Test MSE 1922.893112286846 Test RE 0.606779272025722\n",
      "70 Train Loss 7.19631 Test MSE 1930.2766293739528 Test RE 0.6079431101511455\n",
      "71 Train Loss 7.1713557 Test MSE 1884.8060623497352 Test RE 0.6007399300927205\n",
      "72 Train Loss 7.0896006 Test MSE 1737.2831768120677 Test RE 0.5767511534510921\n",
      "73 Train Loss 7.016566 Test MSE 1709.1701637100518 Test RE 0.5720655776027529\n",
      "74 Train Loss 6.9668183 Test MSE 1718.520947405165 Test RE 0.573628314055137\n",
      "75 Train Loss 6.9348164 Test MSE 1782.2314823738056 Test RE 0.5841645794549584\n",
      "76 Train Loss 6.874324 Test MSE 1802.593346482461 Test RE 0.5874921209780944\n",
      "77 Train Loss 6.7320995 Test MSE 1953.40246658343 Test RE 0.6115740235210981\n",
      "78 Train Loss 6.65815 Test MSE 2039.3294899609743 Test RE 0.6248803447529719\n",
      "79 Train Loss 6.6348896 Test MSE 2051.1136549177622 Test RE 0.6266831642671238\n",
      "80 Train Loss 6.618397 Test MSE 2055.71835800148 Test RE 0.6273862145663136\n",
      "81 Train Loss 6.5970287 Test MSE 1974.1314883098662 Test RE 0.6148103960910329\n",
      "82 Train Loss 6.569189 Test MSE 1799.2625697724927 Test RE 0.5869490950524577\n",
      "83 Train Loss 6.5366573 Test MSE 1774.488906541678 Test RE 0.5828943007153732\n",
      "84 Train Loss 6.5229745 Test MSE 1690.4699244242718 Test RE 0.568927450698126\n",
      "85 Train Loss 6.517089 Test MSE 1684.9103221823957 Test RE 0.5679911384958651\n",
      "86 Train Loss 6.509877 Test MSE 1660.1385635448814 Test RE 0.5638003402895111\n",
      "87 Train Loss 6.5031767 Test MSE 1624.9425129576568 Test RE 0.5577918510801119\n",
      "88 Train Loss 6.4941177 Test MSE 1668.1383440656368 Test RE 0.5651571121464755\n",
      "89 Train Loss 6.4820614 Test MSE 1682.9658904747396 Test RE 0.5676633053817305\n",
      "90 Train Loss 6.4710836 Test MSE 1662.0086170284223 Test RE 0.5641177957320089\n",
      "91 Train Loss 6.44985 Test MSE 1566.252057448286 Test RE 0.5476259151264014\n",
      "92 Train Loss 6.422619 Test MSE 1539.6959806534114 Test RE 0.5429635212627771\n",
      "93 Train Loss 6.3505545 Test MSE 1523.668134582627 Test RE 0.540130071574833\n",
      "94 Train Loss 6.300168 Test MSE 1551.2461794838953 Test RE 0.5449962664718965\n",
      "95 Train Loss 6.282993 Test MSE 1625.8170403435577 Test RE 0.5579419298153157\n",
      "96 Train Loss 6.248894 Test MSE 1626.3709550942456 Test RE 0.558036966937665\n",
      "97 Train Loss 6.1654673 Test MSE 1525.3054989305026 Test RE 0.5404202109543298\n",
      "98 Train Loss 6.102759 Test MSE 1368.0839490548308 Test RE 0.5118109090622674\n",
      "99 Train Loss 6.0428157 Test MSE 1359.0795196535496 Test RE 0.510123814713573\n",
      "Training time: 71.80\n",
      "Training time: 71.80\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.73836 Test MSE 5159.785795960272 Test RE 0.9939602142048287\n",
      "1 Train Loss 47.714077 Test MSE 5092.171118947609 Test RE 0.9874262294042616\n",
      "2 Train Loss 47.714077 Test MSE 5092.1710985499385 Test RE 0.987426227426599\n",
      "3 Train Loss 47.637928 Test MSE 5004.1403709048645 Test RE 0.9788539697802152\n",
      "4 Train Loss 47.603718 Test MSE 4952.048452262594 Test RE 0.9737458221031218\n",
      "5 Train Loss 47.483997 Test MSE 4825.7110203141465 Test RE 0.9612443947782153\n",
      "6 Train Loss 46.13164 Test MSE 4776.21786705038 Test RE 0.9563023634894048\n",
      "7 Train Loss 44.235855 Test MSE 4802.805744452829 Test RE 0.9589604042149552\n",
      "8 Train Loss 37.359215 Test MSE 4222.013126326932 Test RE 0.8991102615132225\n",
      "9 Train Loss 35.42304 Test MSE 4307.52052214835 Test RE 0.9081693532862972\n",
      "10 Train Loss 32.967896 Test MSE 4491.787275171967 Test RE 0.9273907395191688\n",
      "11 Train Loss 31.445593 Test MSE 4600.635541952069 Test RE 0.9385600831825492\n",
      "12 Train Loss 26.898378 Test MSE 4261.405585344708 Test RE 0.9032949870367365\n",
      "13 Train Loss 24.425926 Test MSE 4596.779392362241 Test RE 0.9381666607136595\n",
      "14 Train Loss 24.13328 Test MSE 4653.11115287199 Test RE 0.9438975920835918\n",
      "15 Train Loss 24.073818 Test MSE 4850.977825940595 Test RE 0.9637575857337105\n",
      "16 Train Loss 23.838955 Test MSE 5087.710376870045 Test RE 0.9869936419411717\n",
      "17 Train Loss 22.981995 Test MSE 5447.454405741478 Test RE 1.0212920862136163\n",
      "18 Train Loss 22.569939 Test MSE 5565.881911748238 Test RE 1.032333827747554\n",
      "19 Train Loss 22.277977 Test MSE 5714.127912176224 Test RE 1.045991471811981\n",
      "20 Train Loss 22.116316 Test MSE 5834.833488802614 Test RE 1.0569815293801046\n",
      "21 Train Loss 22.03946 Test MSE 5874.020940135464 Test RE 1.060524997994467\n",
      "22 Train Loss 21.971935 Test MSE 5964.214987927101 Test RE 1.0686360222585476\n",
      "23 Train Loss 21.909286 Test MSE 6052.137109310573 Test RE 1.0764839122882144\n",
      "24 Train Loss 21.823761 Test MSE 6149.056681390822 Test RE 1.0850691419580458\n",
      "25 Train Loss 21.607529 Test MSE 6397.966636755177 Test RE 1.1068127419090534\n",
      "26 Train Loss 21.420265 Test MSE 6436.880117168962 Test RE 1.110173547552529\n",
      "27 Train Loss 21.362394 Test MSE 6480.816805988814 Test RE 1.1139560008439986\n",
      "28 Train Loss 21.356934 Test MSE 6483.587324156351 Test RE 1.1141940808317017\n",
      "29 Train Loss 21.356922 Test MSE 6483.351673266512 Test RE 1.1141738325340185\n",
      "30 Train Loss 21.356915 Test MSE 6483.333195424271 Test RE 1.11417224481026\n",
      "31 Train Loss 21.356915 Test MSE 6483.333195424271 Test RE 1.11417224481026\n",
      "32 Train Loss 21.355976 Test MSE 6484.392176452675 Test RE 1.1142632349736221\n",
      "33 Train Loss 21.355915 Test MSE 6482.057681776904 Test RE 1.114062639784132\n",
      "34 Train Loss 21.333057 Test MSE 6472.1928787508905 Test RE 1.1132145917146685\n",
      "35 Train Loss 21.331478 Test MSE 6476.547565086118 Test RE 1.1135890308974934\n",
      "36 Train Loss 21.331333 Test MSE 6476.556423503259 Test RE 1.11358979246318\n",
      "37 Train Loss 21.331333 Test MSE 6476.556423503259 Test RE 1.11358979246318\n",
      "38 Train Loss 21.331333 Test MSE 6476.556423503259 Test RE 1.11358979246318\n",
      "39 Train Loss 21.331333 Test MSE 6476.556423503259 Test RE 1.11358979246318\n",
      "40 Train Loss 21.33128 Test MSE 6476.553520910499 Test RE 1.113589542924859\n",
      "41 Train Loss 21.331148 Test MSE 6476.723677323864 Test RE 1.1136041713192222\n",
      "42 Train Loss 21.331148 Test MSE 6476.723677323864 Test RE 1.1136041713192222\n",
      "43 Train Loss 21.331148 Test MSE 6476.723677323864 Test RE 1.1136041713192222\n",
      "44 Train Loss 21.331148 Test MSE 6476.723677323864 Test RE 1.1136041713192222\n",
      "45 Train Loss 21.331148 Test MSE 6476.723677323864 Test RE 1.1136041713192222\n",
      "46 Train Loss 21.331148 Test MSE 6476.723677323864 Test RE 1.1136041713192222\n",
      "47 Train Loss 21.331148 Test MSE 6476.723735297725 Test RE 1.1136041763032185\n",
      "48 Train Loss 21.33112 Test MSE 6476.79475739598 Test RE 1.1136102820359652\n",
      "49 Train Loss 21.33112 Test MSE 6476.79475739598 Test RE 1.1136102820359652\n",
      "50 Train Loss 21.33112 Test MSE 6476.79475739598 Test RE 1.1136102820359652\n",
      "51 Train Loss 21.33112 Test MSE 6476.79475739598 Test RE 1.1136102820359652\n",
      "52 Train Loss 21.33112 Test MSE 6476.79475739598 Test RE 1.1136102820359652\n",
      "53 Train Loss 21.33112 Test MSE 6476.79475739598 Test RE 1.1136102820359652\n",
      "54 Train Loss 21.310692 Test MSE 6481.075042232714 Test RE 1.113978194107334\n",
      "55 Train Loss 21.20321 Test MSE 6520.550515739208 Test RE 1.1173655996059573\n",
      "56 Train Loss 20.820742 Test MSE 6670.607124613987 Test RE 1.1301493671358163\n",
      "57 Train Loss 20.56323 Test MSE 6767.72321267221 Test RE 1.1383464537874723\n",
      "58 Train Loss 20.43305 Test MSE 6821.839244439328 Test RE 1.1428886117518322\n",
      "59 Train Loss 20.298044 Test MSE 6843.205952161265 Test RE 1.1446770352713402\n",
      "60 Train Loss 20.197544 Test MSE 6952.69782906211 Test RE 1.1537981602914353\n",
      "61 Train Loss 20.039356 Test MSE 7087.545863124211 Test RE 1.1649334230897521\n",
      "62 Train Loss 19.902037 Test MSE 7259.683475399537 Test RE 1.1789951201113997\n",
      "63 Train Loss 19.71843 Test MSE 7440.718433917939 Test RE 1.1936049191764795\n",
      "64 Train Loss 19.681002 Test MSE 7614.025896614765 Test RE 1.2074254884843039\n",
      "65 Train Loss 19.662605 Test MSE 7633.396742327355 Test RE 1.2089604186355871\n",
      "66 Train Loss 19.662605 Test MSE 7633.396742327355 Test RE 1.2089604186355871\n",
      "67 Train Loss 19.659853 Test MSE 7669.349775239749 Test RE 1.21180415483642\n",
      "68 Train Loss 19.659853 Test MSE 7669.349775239749 Test RE 1.21180415483642\n",
      "69 Train Loss 19.658628 Test MSE 7685.511255490081 Test RE 1.2130802892419252\n",
      "70 Train Loss 19.657906 Test MSE 7709.460245055823 Test RE 1.2149688721213745\n",
      "71 Train Loss 19.65752 Test MSE 7707.766851639064 Test RE 1.2148354300115891\n",
      "72 Train Loss 19.65752 Test MSE 7707.766851639064 Test RE 1.2148354300115891\n",
      "73 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "74 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "75 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "76 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "77 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "78 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "79 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "80 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "81 Train Loss 19.657492 Test MSE 7707.766168690628 Test RE 1.2148353761912027\n",
      "82 Train Loss 19.657492 Test MSE 7707.766203850277 Test RE 1.214835378961992\n",
      "83 Train Loss 19.657492 Test MSE 7707.766203850277 Test RE 1.214835378961992\n",
      "84 Train Loss 19.657492 Test MSE 7707.766203850277 Test RE 1.214835378961992\n",
      "85 Train Loss 19.657492 Test MSE 7707.766203850277 Test RE 1.214835378961992\n",
      "86 Train Loss 19.657452 Test MSE 7707.770851321259 Test RE 1.2148357452102128\n",
      "87 Train Loss 19.657452 Test MSE 7707.770628903327 Test RE 1.2148357276823658\n",
      "88 Train Loss 19.657452 Test MSE 7707.770628903327 Test RE 1.2148357276823658\n",
      "89 Train Loss 19.657452 Test MSE 7707.770382760386 Test RE 1.214835708284848\n",
      "90 Train Loss 19.657452 Test MSE 7707.770382760386 Test RE 1.214835708284848\n",
      "91 Train Loss 19.657452 Test MSE 7707.770382760386 Test RE 1.214835708284848\n",
      "92 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "93 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "94 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "95 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "96 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "97 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "98 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "99 Train Loss 19.657452 Test MSE 7707.770403171864 Test RE 1.2148357098933928\n",
      "Training time: 41.08\n",
      "Training time: 41.08\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.76583 Test MSE 5214.98781471073 Test RE 0.9992630154512607\n",
      "1 Train Loss 47.742302 Test MSE 5162.3241380639565 Test RE 0.9942046721087143\n",
      "2 Train Loss 47.69255 Test MSE 5068.744492109965 Test RE 0.9851522747871525\n",
      "3 Train Loss 47.298847 Test MSE 4909.220542268585 Test RE 0.969525946299372\n",
      "4 Train Loss 46.911057 Test MSE 4862.337782899487 Test RE 0.9648853833618384\n",
      "5 Train Loss 45.416103 Test MSE 4974.459778173365 Test RE 0.9759467597614553\n",
      "6 Train Loss 37.406406 Test MSE 4388.3973319208735 Test RE 0.9166554731257424\n",
      "7 Train Loss 35.60563 Test MSE 4439.170200786083 Test RE 0.9219429823962798\n",
      "8 Train Loss 34.07308 Test MSE 4309.674775746945 Test RE 0.9083964192444437\n",
      "9 Train Loss 33.02846 Test MSE 4381.337225690991 Test RE 0.9159178131608612\n",
      "10 Train Loss 31.7486 Test MSE 4477.082672865965 Test RE 0.9258715123003154\n",
      "11 Train Loss 31.044117 Test MSE 4530.981063312852 Test RE 0.9314279977489548\n",
      "12 Train Loss 30.75769 Test MSE 4602.943099289895 Test RE 0.9387954321555998\n",
      "13 Train Loss 29.974695 Test MSE 4751.6969204160805 Test RE 0.953844392083308\n",
      "14 Train Loss 28.908163 Test MSE 5184.154147705444 Test RE 0.9963045597652976\n",
      "15 Train Loss 28.089247 Test MSE 5526.826004046841 Test RE 1.028705497688665\n",
      "16 Train Loss 27.895355 Test MSE 5656.3717051717 Test RE 1.040691806326248\n",
      "17 Train Loss 27.736345 Test MSE 5715.6602041695405 Test RE 1.0461317081654236\n",
      "18 Train Loss 27.657999 Test MSE 5761.156146857304 Test RE 1.050286994655465\n",
      "19 Train Loss 27.591795 Test MSE 5799.114941875388 Test RE 1.0537413511906601\n",
      "20 Train Loss 27.51796 Test MSE 5837.698045779904 Test RE 1.057240955145751\n",
      "21 Train Loss 27.419765 Test MSE 5908.05251578468 Test RE 1.0635926762925025\n",
      "22 Train Loss 27.371042 Test MSE 5966.3738412786115 Test RE 1.068829410636832\n",
      "23 Train Loss 27.359016 Test MSE 5999.445735360516 Test RE 1.071787603090484\n",
      "24 Train Loss 27.323936 Test MSE 6022.764035548678 Test RE 1.0738684642753105\n",
      "25 Train Loss 27.230915 Test MSE 6100.387788180997 Test RE 1.0807665288382753\n",
      "26 Train Loss 27.066809 Test MSE 6128.620558911083 Test RE 1.0832645512868169\n",
      "27 Train Loss 26.669365 Test MSE 6454.01302080903 Test RE 1.1116500281047248\n",
      "28 Train Loss 26.583158 Test MSE 6508.160503435884 Test RE 1.1163035147218727\n",
      "29 Train Loss 26.506365 Test MSE 6502.86681640259 Test RE 1.1158494260754666\n",
      "30 Train Loss 26.435038 Test MSE 6602.1232619131815 Test RE 1.124333054750359\n",
      "31 Train Loss 26.357298 Test MSE 6647.36998488593 Test RE 1.1281792054475692\n",
      "32 Train Loss 26.219807 Test MSE 6776.503307375429 Test RE 1.1390846304072462\n",
      "33 Train Loss 25.98338 Test MSE 6898.855122391111 Test RE 1.1493218865489332\n",
      "34 Train Loss 25.844372 Test MSE 6956.154918364704 Test RE 1.154084976119118\n",
      "35 Train Loss 25.698257 Test MSE 7032.3437173277225 Test RE 1.160387947748146\n",
      "36 Train Loss 25.51079 Test MSE 7219.76970134865 Test RE 1.175749592610824\n",
      "37 Train Loss 25.427647 Test MSE 7340.46424263145 Test RE 1.1855364970794384\n",
      "38 Train Loss 25.42501 Test MSE 7356.701367698616 Test RE 1.1868469776156587\n",
      "39 Train Loss 25.411036 Test MSE 7362.90535658378 Test RE 1.1873473128460525\n",
      "40 Train Loss 25.304214 Test MSE 7542.769932271429 Test RE 1.2017623538255977\n",
      "41 Train Loss 25.128824 Test MSE 7803.7029432182435 Test RE 1.2223723827007194\n",
      "42 Train Loss 24.721695 Test MSE 8203.679438267509 Test RE 1.253307116236452\n",
      "43 Train Loss 24.613247 Test MSE 8232.149515740404 Test RE 1.2554799733701583\n",
      "44 Train Loss 24.536785 Test MSE 8293.37525181596 Test RE 1.2601400740264697\n",
      "45 Train Loss 24.51317 Test MSE 8350.106160056699 Test RE 1.2644427282538904\n",
      "46 Train Loss 24.45322 Test MSE 8342.494358769087 Test RE 1.2638662756301675\n",
      "47 Train Loss 24.428642 Test MSE 8311.371312774603 Test RE 1.261506542324352\n",
      "48 Train Loss 24.420303 Test MSE 8335.885910586936 Test RE 1.2633655950710365\n",
      "49 Train Loss 24.409338 Test MSE 8405.533168828812 Test RE 1.2686323971328028\n",
      "50 Train Loss 24.366177 Test MSE 8511.597373941653 Test RE 1.2766113480230843\n",
      "51 Train Loss 24.333353 Test MSE 8547.003376724984 Test RE 1.279263775984108\n",
      "52 Train Loss 24.225634 Test MSE 8554.352912442158 Test RE 1.279813674824824\n",
      "53 Train Loss 24.080366 Test MSE 8578.615443525878 Test RE 1.2816273440094408\n",
      "54 Train Loss 23.986137 Test MSE 8521.035781372299 Test RE 1.2773189613568559\n",
      "55 Train Loss 23.965446 Test MSE 8480.800098940494 Test RE 1.2742996914887976\n",
      "56 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "57 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "58 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "59 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "60 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "61 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "62 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "63 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "64 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "65 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "66 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "67 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "68 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "69 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "70 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "71 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "72 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "73 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "74 Train Loss 23.962246 Test MSE 8476.2527409093 Test RE 1.273958009463043\n",
      "75 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "76 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "77 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "78 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "79 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "80 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "81 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "82 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "83 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "84 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "85 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "86 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "87 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "88 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "89 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "90 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "91 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "92 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "93 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "94 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "95 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "96 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "97 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "98 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "99 Train Loss 23.962246 Test MSE 8476.252714548453 Test RE 1.2739580074820607\n",
      "Training time: 45.38\n",
      "Training time: 45.38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.751633 Test MSE 5181.869014985734 Test RE 0.9960849541145849\n",
      "1 Train Loss 47.71429 Test MSE 5087.182608926411 Test RE 0.986942448272926\n",
      "2 Train Loss 47.6972 Test MSE 5050.805382790205 Test RE 0.9834074227039887\n",
      "3 Train Loss 47.66997 Test MSE 5001.76657452839 Test RE 0.9786217744919964\n",
      "4 Train Loss 47.652348 Test MSE 4953.37899420787 Test RE 0.973876628844691\n",
      "5 Train Loss 47.62155 Test MSE 4885.037676549369 Test RE 0.9671350513901202\n",
      "6 Train Loss 47.607903 Test MSE 4826.584731272694 Test RE 0.961331409080053\n",
      "7 Train Loss 47.59375 Test MSE 4794.399872207773 Test RE 0.9581208502946245\n",
      "8 Train Loss 47.56113 Test MSE 4704.162587786598 Test RE 0.9490614355497924\n",
      "9 Train Loss 47.493576 Test MSE 4626.660611037221 Test RE 0.9412109826623615\n",
      "10 Train Loss 47.399414 Test MSE 4525.729789285038 Test RE 0.930888092418146\n",
      "11 Train Loss 47.331947 Test MSE 4485.334125483996 Test RE 0.9267243297040348\n",
      "12 Train Loss 47.231884 Test MSE 4474.137383089818 Test RE 0.9255669156762467\n",
      "13 Train Loss 47.132008 Test MSE 4503.316127609078 Test RE 0.9285801212311062\n",
      "14 Train Loss 46.98238 Test MSE 4529.137969683516 Test RE 0.9312385372767853\n",
      "15 Train Loss 46.190598 Test MSE 4686.24700620373 Test RE 0.9472524836983123\n",
      "16 Train Loss 40.723312 Test MSE 3638.133790668443 Test RE 0.8346271301896443\n",
      "17 Train Loss 39.97359 Test MSE 3738.245760044989 Test RE 0.8460325833227534\n",
      "18 Train Loss 37.751247 Test MSE 3359.3245609650508 Test RE 0.8020088252967006\n",
      "19 Train Loss 29.34891 Test MSE 1979.7135145104055 Test RE 0.6156789970920741\n",
      "20 Train Loss 20.962639 Test MSE 1804.5549385218126 Test RE 0.5878116901485325\n",
      "21 Train Loss 19.318644 Test MSE 1874.0142132051035 Test RE 0.5990176304964484\n",
      "22 Train Loss 19.272285 Test MSE 1882.1231090871033 Test RE 0.6003122120463553\n",
      "23 Train Loss 19.262901 Test MSE 1872.2682077693664 Test RE 0.5987385152803786\n",
      "24 Train Loss 19.262074 Test MSE 1872.3941461229276 Test RE 0.5987586520520602\n",
      "25 Train Loss 19.262072 Test MSE 1872.3951416422155 Test RE 0.5987588112268015\n",
      "26 Train Loss 19.262072 Test MSE 1872.3951416422155 Test RE 0.5987588112268015\n",
      "27 Train Loss 19.262072 Test MSE 1872.3951416422155 Test RE 0.5987588112268015\n",
      "28 Train Loss 19.245085 Test MSE 1862.584896493635 Test RE 0.5971881798869609\n",
      "29 Train Loss 19.241587 Test MSE 1879.20920059393 Test RE 0.5998473294837403\n",
      "30 Train Loss 19.241587 Test MSE 1879.20920059393 Test RE 0.5998473294837403\n",
      "31 Train Loss 19.219208 Test MSE 1861.4639780863174 Test RE 0.5970084565445541\n",
      "32 Train Loss 19.210907 Test MSE 1860.6819412237835 Test RE 0.5968830359958202\n",
      "33 Train Loss 19.181135 Test MSE 1851.946927696639 Test RE 0.595480347353308\n",
      "34 Train Loss 19.147741 Test MSE 1843.3012100911026 Test RE 0.5940887368219568\n",
      "35 Train Loss 19.104223 Test MSE 1833.5034728706366 Test RE 0.5925077470527372\n",
      "36 Train Loss 19.0517 Test MSE 1817.2144098285635 Test RE 0.5898699206243413\n",
      "37 Train Loss 18.996231 Test MSE 1799.6656012277767 Test RE 0.5870148291221325\n",
      "38 Train Loss 18.942957 Test MSE 1792.9223838364524 Test RE 0.5859140458723162\n",
      "39 Train Loss 18.878141 Test MSE 1791.2406119113948 Test RE 0.5856391859615371\n",
      "40 Train Loss 18.796719 Test MSE 1758.8786449261863 Test RE 0.5803247629810416\n",
      "41 Train Loss 18.681946 Test MSE 1751.1132114759325 Test RE 0.5790422815660193\n",
      "42 Train Loss 18.579268 Test MSE 1731.333652412283 Test RE 0.5757627314286909\n",
      "43 Train Loss 18.35512 Test MSE 1707.5672563779638 Test RE 0.5717972651729345\n",
      "44 Train Loss 17.75657 Test MSE 1578.554048718674 Test RE 0.5497723488101397\n",
      "45 Train Loss 17.080574 Test MSE 1354.3269505136946 Test RE 0.5092311068735026\n",
      "46 Train Loss 16.869291 Test MSE 1272.6874378338805 Test RE 0.4936442053125295\n",
      "47 Train Loss 16.86714 Test MSE 1270.158180332577 Test RE 0.4931534429253913\n",
      "48 Train Loss 16.86714 Test MSE 1270.158180332577 Test RE 0.4931534429253913\n",
      "49 Train Loss 16.866308 Test MSE 1269.627281418587 Test RE 0.49305036836535643\n",
      "50 Train Loss 16.866308 Test MSE 1269.627281418587 Test RE 0.49305036836535643\n",
      "51 Train Loss 16.866308 Test MSE 1269.627281418587 Test RE 0.49305036836535643\n",
      "52 Train Loss 16.866308 Test MSE 1269.627281418587 Test RE 0.49305036836535643\n",
      "53 Train Loss 16.8663 Test MSE 1269.6272379972313 Test RE 0.4930503599341751\n",
      "54 Train Loss 16.8663 Test MSE 1269.6272379972313 Test RE 0.4930503599341751\n",
      "55 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "56 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "57 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "58 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "59 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "60 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "61 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "62 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "63 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "64 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "65 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "66 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "67 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "68 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "69 Train Loss 16.866302 Test MSE 1269.6272604823482 Test RE 0.4930503643001396\n",
      "70 Train Loss 16.8663 Test MSE 1269.6275009921587 Test RE 0.49305041100024116\n",
      "71 Train Loss 16.866282 Test MSE 1269.627924736053 Test RE 0.49305049327913136\n",
      "72 Train Loss 16.866282 Test MSE 1269.627924736053 Test RE 0.49305049327913136\n",
      "73 Train Loss 16.866282 Test MSE 1269.627924736053 Test RE 0.49305049327913136\n",
      "74 Train Loss 16.866282 Test MSE 1269.627924736053 Test RE 0.49305049327913136\n",
      "75 Train Loss 16.866282 Test MSE 1269.627924736053 Test RE 0.49305049327913136\n",
      "76 Train Loss 16.865982 Test MSE 1270.1188587202362 Test RE 0.4931458093334139\n",
      "77 Train Loss 16.86103 Test MSE 1264.2298012700235 Test RE 0.49200121637459465\n",
      "78 Train Loss 16.859911 Test MSE 1264.2192432362276 Test RE 0.4919991619315217\n",
      "79 Train Loss 16.859911 Test MSE 1264.2192432362276 Test RE 0.4919991619315217\n",
      "80 Train Loss 16.859911 Test MSE 1264.2192432362276 Test RE 0.4919991619315217\n",
      "81 Train Loss 16.859653 Test MSE 1264.2168108439002 Test RE 0.49199868862138646\n",
      "82 Train Loss 16.859653 Test MSE 1264.2168108439002 Test RE 0.49199868862138646\n",
      "83 Train Loss 16.859653 Test MSE 1264.2168108439002 Test RE 0.49199868862138646\n",
      "84 Train Loss 16.859653 Test MSE 1264.2168108439002 Test RE 0.49199868862138646\n",
      "85 Train Loss 16.859653 Test MSE 1264.2168108439002 Test RE 0.49199868862138646\n",
      "86 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "87 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "88 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "89 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "90 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "91 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "92 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "93 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "94 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "95 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "96 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "97 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "98 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "99 Train Loss 16.859653 Test MSE 1264.2166132112786 Test RE 0.491998650164773\n",
      "Training time: 39.48\n",
      "Training time: 39.48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.744625 Test MSE 5163.296482666238 Test RE 0.9942982989329904\n",
      "1 Train Loss 47.72692 Test MSE 5140.856801341405 Test RE 0.9921353366120979\n",
      "2 Train Loss 47.61168 Test MSE 5051.423681470567 Test RE 0.9834676131942528\n",
      "3 Train Loss 42.8095 Test MSE 4710.22470383142 Test RE 0.9496727524535138\n",
      "4 Train Loss 39.690334 Test MSE 4469.416237361765 Test RE 0.9250784539606656\n",
      "5 Train Loss 37.853188 Test MSE 4384.505510963143 Test RE 0.9162489180662677\n",
      "6 Train Loss 35.900105 Test MSE 4389.558024955104 Test RE 0.9167766888224448\n",
      "7 Train Loss 35.59297 Test MSE 4334.369322795839 Test RE 0.9109952690887891\n",
      "8 Train Loss 34.86344 Test MSE 4324.913724417946 Test RE 0.9100010404217472\n",
      "9 Train Loss 34.051926 Test MSE 4276.3843735068895 Test RE 0.9048811298199358\n",
      "10 Train Loss 33.71763 Test MSE 4307.643915388633 Test RE 0.9081823609035715\n",
      "11 Train Loss 33.01332 Test MSE 4278.614720708336 Test RE 0.9051170693239744\n",
      "12 Train Loss 32.438885 Test MSE 4277.8341637481435 Test RE 0.9050345043234799\n",
      "13 Train Loss 31.437284 Test MSE 4326.621332271946 Test RE 0.9101806707761094\n",
      "14 Train Loss 30.480152 Test MSE 4458.549411422568 Test RE 0.9239531633304379\n",
      "15 Train Loss 29.557446 Test MSE 4671.325027883443 Test RE 0.9457431574664468\n",
      "16 Train Loss 28.204803 Test MSE 5087.211675721386 Test RE 0.9869452678309233\n",
      "17 Train Loss 27.30404 Test MSE 5312.895943454538 Test RE 1.0085996653006388\n",
      "18 Train Loss 26.714304 Test MSE 5402.896317938432 Test RE 1.0171066209774902\n",
      "19 Train Loss 25.721163 Test MSE 5404.112168286706 Test RE 1.0172210577352498\n",
      "20 Train Loss 25.222504 Test MSE 5515.352756198204 Test RE 1.0276371878843538\n",
      "21 Train Loss 24.478153 Test MSE 6011.919025272743 Test RE 1.072901187300075\n",
      "22 Train Loss 24.163685 Test MSE 6175.214839954394 Test RE 1.087374641023387\n",
      "23 Train Loss 23.184591 Test MSE 6625.8085488477 Test RE 1.126348036038571\n",
      "24 Train Loss 22.98102 Test MSE 6605.4564553693945 Test RE 1.1246168382044952\n",
      "25 Train Loss 22.87533 Test MSE 6572.398841973348 Test RE 1.1217991843619064\n",
      "26 Train Loss 22.733276 Test MSE 6609.061663937695 Test RE 1.124923700055263\n",
      "27 Train Loss 22.572304 Test MSE 6717.330008904019 Test RE 1.134100409083917\n",
      "28 Train Loss 22.548538 Test MSE 6723.375513471505 Test RE 1.1346106316920304\n",
      "29 Train Loss 22.527552 Test MSE 6767.4580711899725 Test RE 1.1383241548685608\n",
      "30 Train Loss 22.452902 Test MSE 6806.662065884867 Test RE 1.1416165586903508\n",
      "31 Train Loss 22.347904 Test MSE 6984.7954610812885 Test RE 1.1564583898389713\n",
      "32 Train Loss 22.261997 Test MSE 6959.7723842626 Test RE 1.1543850212203597\n",
      "33 Train Loss 22.165934 Test MSE 7153.674135612775 Test RE 1.1703553407403027\n",
      "34 Train Loss 22.011501 Test MSE 7083.478559996555 Test RE 1.1645991171532466\n",
      "35 Train Loss 21.562357 Test MSE 7485.595952375031 Test RE 1.1971990278076015\n",
      "36 Train Loss 21.435614 Test MSE 7368.057611884134 Test RE 1.1877626683591314\n",
      "37 Train Loss 21.392078 Test MSE 7343.786790559482 Test RE 1.1858047741304893\n",
      "38 Train Loss 21.360676 Test MSE 7457.406028615436 Test RE 1.194942642130177\n",
      "39 Train Loss 21.338434 Test MSE 7575.163282768442 Test RE 1.2043401470330175\n",
      "40 Train Loss 21.279669 Test MSE 7684.282207806641 Test RE 1.2129832889851364\n",
      "41 Train Loss 21.122423 Test MSE 7753.354193617019 Test RE 1.218422686415587\n",
      "42 Train Loss 20.933014 Test MSE 7853.599534304163 Test RE 1.22627405799071\n",
      "43 Train Loss 20.60027 Test MSE 7975.3356346136925 Test RE 1.2357415492563986\n",
      "44 Train Loss 20.45897 Test MSE 7951.1041442697215 Test RE 1.2338628421998534\n",
      "45 Train Loss 20.416597 Test MSE 7968.1489579515755 Test RE 1.235184652535762\n",
      "46 Train Loss 20.330326 Test MSE 8368.933633884133 Test RE 1.2658674321845957\n",
      "47 Train Loss 20.251457 Test MSE 8402.672288673135 Test RE 1.26841648494421\n",
      "48 Train Loss 20.087582 Test MSE 8346.003146162591 Test RE 1.2641320337876736\n",
      "49 Train Loss 19.928926 Test MSE 8316.786254432964 Test RE 1.2619174174868202\n",
      "50 Train Loss 19.732704 Test MSE 8299.376118026736 Test RE 1.2605958935422188\n",
      "51 Train Loss 19.600954 Test MSE 8403.325674484237 Test RE 1.268465799566686\n",
      "52 Train Loss 19.546438 Test MSE 8547.38197412889 Test RE 1.2792921087552476\n",
      "53 Train Loss 19.43393 Test MSE 8517.974399517387 Test RE 1.2770894873541112\n",
      "54 Train Loss 19.386211 Test MSE 8293.571519504329 Test RE 1.2601549849227325\n",
      "55 Train Loss 19.343357 Test MSE 8297.130596196208 Test RE 1.2604253453554661\n",
      "56 Train Loss 19.322401 Test MSE 8324.61692889178 Test RE 1.2625113572167117\n",
      "57 Train Loss 19.311155 Test MSE 8366.093041362183 Test RE 1.2656525829042398\n",
      "58 Train Loss 19.278942 Test MSE 8385.787064585593 Test RE 1.2671413985001498\n",
      "59 Train Loss 19.157597 Test MSE 8461.18237341902 Test RE 1.2728249877562898\n",
      "60 Train Loss 19.053185 Test MSE 8640.073795435019 Test RE 1.286210026035309\n",
      "61 Train Loss 18.935694 Test MSE 8854.153365426355 Test RE 1.3020470706304401\n",
      "62 Train Loss 18.794527 Test MSE 8838.1922023775 Test RE 1.3008729572472788\n",
      "63 Train Loss 18.75595 Test MSE 8795.150197726196 Test RE 1.2977014649563365\n",
      "64 Train Loss 18.712774 Test MSE 8870.825819760144 Test RE 1.303272377545577\n",
      "65 Train Loss 18.680927 Test MSE 8981.596504333109 Test RE 1.31138416421177\n",
      "66 Train Loss 18.661371 Test MSE 9065.95800472554 Test RE 1.3175284932829994\n",
      "67 Train Loss 18.612125 Test MSE 9060.630322805362 Test RE 1.3171413083721537\n",
      "68 Train Loss 18.545538 Test MSE 9220.79023002785 Test RE 1.3287315148360799\n",
      "69 Train Loss 18.478205 Test MSE 9602.746148151902 Test RE 1.3559725217886291\n",
      "70 Train Loss 18.434319 Test MSE 9626.946571720651 Test RE 1.3576800781520193\n",
      "71 Train Loss 18.40269 Test MSE 9509.2340632074 Test RE 1.3493541011885546\n",
      "72 Train Loss 18.357264 Test MSE 9268.217581925175 Test RE 1.3321443129462314\n",
      "73 Train Loss 18.324484 Test MSE 9293.988299687982 Test RE 1.3339950724724692\n",
      "74 Train Loss 18.282682 Test MSE 9428.329306470423 Test RE 1.3436016735466132\n",
      "75 Train Loss 18.21531 Test MSE 9358.713712609233 Test RE 1.3386321331002662\n",
      "76 Train Loss 18.188189 Test MSE 9092.457205820958 Test RE 1.3194526130097008\n",
      "77 Train Loss 18.136688 Test MSE 8915.863814019902 Test RE 1.3065766054357681\n",
      "78 Train Loss 18.111092 Test MSE 8941.46540566112 Test RE 1.3084511552757427\n",
      "79 Train Loss 18.096823 Test MSE 8832.22115922146 Test RE 1.3004334510243227\n",
      "80 Train Loss 18.0801 Test MSE 8876.647823541964 Test RE 1.3036999821627386\n",
      "81 Train Loss 18.061317 Test MSE 8923.418227790877 Test RE 1.307130019585516\n",
      "82 Train Loss 18.03047 Test MSE 9031.71938381621 Test RE 1.3150382418219926\n",
      "83 Train Loss 18.01071 Test MSE 9218.466145486223 Test RE 1.3285640520206543\n",
      "84 Train Loss 17.973116 Test MSE 9264.32186771367 Test RE 1.3318643131003682\n",
      "85 Train Loss 17.954237 Test MSE 9336.739692163734 Test RE 1.3370596725272026\n",
      "86 Train Loss 17.913803 Test MSE 9070.781982857663 Test RE 1.3178789738055194\n",
      "87 Train Loss 17.90365 Test MSE 8991.006244586388 Test RE 1.3120709326521625\n",
      "88 Train Loss 17.891127 Test MSE 9039.80983639926 Test RE 1.3156271038393692\n",
      "89 Train Loss 17.848534 Test MSE 9091.38065258425 Test RE 1.3193744986453744\n",
      "90 Train Loss 17.814032 Test MSE 9200.633245142955 Test RE 1.327278392398189\n",
      "91 Train Loss 17.727264 Test MSE 8851.83093411064 Test RE 1.3018762969220645\n",
      "92 Train Loss 17.701838 Test MSE 8771.110270233772 Test RE 1.2959267371129384\n",
      "93 Train Loss 17.661243 Test MSE 8600.5388764081 Test RE 1.2832639567358117\n",
      "94 Train Loss 17.575254 Test MSE 8875.643029688188 Test RE 1.3036261937897298\n",
      "95 Train Loss 17.328377 Test MSE 9449.412193452265 Test RE 1.3451030627821678\n",
      "96 Train Loss 17.131905 Test MSE 9502.253539682135 Test RE 1.3488587444002529\n",
      "97 Train Loss 17.023478 Test MSE 9381.178817753564 Test RE 1.3402378284605336\n",
      "98 Train Loss 16.99304 Test MSE 9344.358450806752 Test RE 1.3376050801336745\n",
      "99 Train Loss 16.957674 Test MSE 9440.18952873839 Test RE 1.3444464895098678\n",
      "Training time: 70.13\n",
      "Training time: 70.13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.74756 Test MSE 5173.162802658763 Test RE 0.9952478263601927\n",
      "1 Train Loss 47.701866 Test MSE 5098.5612423312705 Test RE 0.9880455916576739\n",
      "2 Train Loss 47.43044 Test MSE 4900.245232464416 Test RE 0.968639270240231\n",
      "3 Train Loss 46.979095 Test MSE 4831.307689837614 Test RE 0.9618016399468081\n",
      "4 Train Loss 46.08977 Test MSE 5147.024356050879 Test RE 0.9927302972410346\n",
      "5 Train Loss 37.927357 Test MSE 4629.265242187205 Test RE 0.9414758780935707\n",
      "6 Train Loss 35.55877 Test MSE 4485.511774929395 Test RE 0.9267426817853404\n",
      "7 Train Loss 34.420235 Test MSE 4523.035491178015 Test RE 0.9306109588355115\n",
      "8 Train Loss 32.40288 Test MSE 4748.233803296734 Test RE 0.9534967397615344\n",
      "9 Train Loss 29.678894 Test MSE 5123.584013964463 Test RE 0.9904671942929559\n",
      "10 Train Loss 28.031248 Test MSE 6098.612906591757 Test RE 1.080609295214234\n",
      "11 Train Loss 27.558409 Test MSE 6574.914127922804 Test RE 1.1220138225695047\n",
      "12 Train Loss 27.158045 Test MSE 6902.07685118339 Test RE 1.1495902188411276\n",
      "13 Train Loss 26.515364 Test MSE 7383.478097051005 Test RE 1.1890049430765917\n",
      "14 Train Loss 26.09555 Test MSE 8086.781022368154 Test RE 1.2443455708573476\n",
      "15 Train Loss 25.97779 Test MSE 8417.879122620267 Test RE 1.2695637318643778\n",
      "16 Train Loss 25.90035 Test MSE 8748.984044220419 Test RE 1.2942911360736578\n",
      "17 Train Loss 25.848114 Test MSE 8976.086609740356 Test RE 1.3109818583960235\n",
      "18 Train Loss 25.795452 Test MSE 9231.613537020467 Test RE 1.3295111145802887\n",
      "19 Train Loss 25.751465 Test MSE 9479.386927362164 Test RE 1.3472347923462276\n",
      "20 Train Loss 25.715925 Test MSE 9681.482476663332 Test RE 1.361520223421041\n",
      "21 Train Loss 25.67518 Test MSE 9915.36335193249 Test RE 1.3778675794822366\n",
      "22 Train Loss 25.641624 Test MSE 10148.175644253382 Test RE 1.3939498592777204\n",
      "23 Train Loss 25.618155 Test MSE 10289.979807261609 Test RE 1.403655158106584\n",
      "24 Train Loss 25.590603 Test MSE 10499.861956571282 Test RE 1.4178979002228727\n",
      "25 Train Loss 25.570599 Test MSE 10686.164942559379 Test RE 1.4304217376353663\n",
      "26 Train Loss 25.550276 Test MSE 10887.339591867596 Test RE 1.443823311068227\n",
      "27 Train Loss 25.53717 Test MSE 11059.9136769893 Test RE 1.4552212681001098\n",
      "28 Train Loss 25.524782 Test MSE 11282.35884280645 Test RE 1.4697826585764229\n",
      "29 Train Loss 25.51781 Test MSE 11499.820023556416 Test RE 1.4838796756693597\n",
      "30 Train Loss 25.515162 Test MSE 11737.867803297511 Test RE 1.4991592600990709\n",
      "31 Train Loss 25.51458 Test MSE 11768.415845183 Test RE 1.5011087888739256\n",
      "32 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "33 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "34 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "35 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "36 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "37 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "38 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "39 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "40 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "41 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "42 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "43 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "44 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "45 Train Loss 25.51433 Test MSE 11760.874930803413 Test RE 1.5006277748218304\n",
      "46 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "47 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "48 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "49 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "50 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "51 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "52 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "53 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "54 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "55 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "56 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "57 Train Loss 25.514326 Test MSE 11760.69973657608 Test RE 1.5006165978343975\n",
      "58 Train Loss 25.51431 Test MSE 11756.83344775336 Test RE 1.5003699163350175\n",
      "59 Train Loss 25.51431 Test MSE 11756.83344775336 Test RE 1.5003699163350175\n",
      "60 Train Loss 25.51431 Test MSE 11756.83344775336 Test RE 1.5003699163350175\n",
      "61 Train Loss 25.51431 Test MSE 11756.83344775336 Test RE 1.5003699163350175\n",
      "62 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "63 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "64 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "65 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "66 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "67 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "68 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "69 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "70 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "71 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "72 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "73 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "74 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "75 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "76 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "77 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "78 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "79 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "80 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "81 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "82 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "83 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "84 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "85 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "86 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "87 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "88 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "89 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "90 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "91 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "92 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "93 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "94 Train Loss 25.514145 Test MSE 11749.308424614539 Test RE 1.4998896796465966\n",
      "95 Train Loss 25.514114 Test MSE 11749.129227431751 Test RE 1.499878241652963\n",
      "96 Train Loss 25.514114 Test MSE 11749.129227431751 Test RE 1.499878241652963\n",
      "97 Train Loss 25.514114 Test MSE 11749.129227431751 Test RE 1.499878241652963\n",
      "98 Train Loss 25.514114 Test MSE 11749.129227431751 Test RE 1.499878241652963\n",
      "99 Train Loss 25.514114 Test MSE 11749.129227431751 Test RE 1.499878241652963\n",
      "Training time: 33.10\n",
      "Training time: 33.10\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "  label = \"1D_FODE_tanh_tune\"+str(tune_reps)  \n",
    "  max_reps = 10\n",
    "  max_iter = 100\n",
    "\n",
    "  train_loss_full = []\n",
    "  test_mse_full = []\n",
    "  test_re_full = []\n",
    "\n",
    "  elapsed_time= np.zeros((max_reps,1))\n",
    "  time_threshold = np.empty((max_reps,1))\n",
    "  time_threshold[:] = np.nan\n",
    "  epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "  for reps in range(max_reps):   \n",
    "      train_loss = []\n",
    "      test_mse_loss = []\n",
    "      test_re_loss = []   \n",
    "\n",
    "      \n",
    "      torch.manual_seed(reps*36)\n",
    "      N_f = 10000 #Total number of collocation points\n",
    "    \n",
    "      layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "      PINN = Sequentialmodel(layers)\n",
    "    \n",
    "      PINN.to(device)\n",
    "\n",
    "      'Neural Network Summary'\n",
    "      print(PINN)\n",
    "\n",
    "      params = list(PINN.parameters())\n",
    "      \n",
    "      optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "    \n",
    "\n",
    "      \n",
    "      train_model(max_iter,reps)\n",
    "\n",
    "      \n",
    "      torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "      train_loss_full.append(train_loss)\n",
    "      test_mse_full.append(test_mse_loss)\n",
    "      test_re_full.append(test_re_loss)\n",
    "      \n",
    "      \n",
    "      print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "  mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label}\n",
    "  savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479122606253909\n",
      "0.6029990233605438\n",
      "0.45482597310115896\n",
      "0.6878933591732673\n",
      "0.9690876820687466\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
