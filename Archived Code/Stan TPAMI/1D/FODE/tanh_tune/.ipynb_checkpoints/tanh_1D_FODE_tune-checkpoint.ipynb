{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting smt\n",
      "  Downloading smt-1.2.0.tar.gz (252 kB)\n",
      "\u001b[K     |████████████████████████████████| 252 kB 5.5 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pyDOE2\n",
      "  Downloading pyDOE2-1.3.0.tar.gz (19 kB)\n",
      "Collecting numpydoc\n",
      "  Downloading numpydoc-1.4.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 852 kB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from smt) (1.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from smt) (21.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from smt) (3.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from smt) (1.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->smt) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->smt) (1.15.0)\n",
      "Collecting sphinx>=3.0\n",
      "  Downloading Sphinx-5.1.1-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 33.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc->smt) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc->smt) (2.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (1.1.5)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (0.7.12)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.2.0)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 13.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (1.4.1)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 12.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.23.0)\n",
      "Requirement already satisfied: docutils<0.20,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (0.17.1)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.6.1)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 75.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (4.12.0)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 4.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.10.3)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx>=3.0->numpydoc->smt) (2022.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc->smt) (3.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (2022.6.15)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->smt) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->smt) (3.1.0)\n",
      "Building wheels for collected packages: smt, pyDOE2\n",
      "  Building wheel for smt (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for smt: filename=smt-1.2.0-cp37-cp37m-linux_x86_64.whl size=527836 sha256=13d984fa1c3ad3fa0eed2d03bbeeb49e496b8808366027ece3400fa614b1fa46\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/69/1e/ae0014b43757c2db9bdd61fdae3a4f532f9d64c451a1bc678e\n",
      "  Building wheel for pyDOE2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyDOE2: filename=pyDOE2-1.3.0-py3-none-any.whl size=25539 sha256=1ffe237368dda3b714c72d89df5f780535c3361f204aebacd88b6ac2139233d4\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/91/2d/d08e80806bf7756193541f6c03c0492af288fcd6158d3d0998\n",
      "Successfully built smt pyDOE2\n",
      "Installing collected packages: sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, pyDOE2, numpydoc, smt\n",
      "  Attempting uninstall: sphinx\n",
      "    Found existing installation: Sphinx 1.8.6\n",
      "    Uninstalling Sphinx-1.8.6:\n",
      "      Successfully uninstalled Sphinx-1.8.6\n",
      "Successfully installed numpydoc-1.4.0 pyDOE2-1.3.0 smt-1.2.0 sphinx-5.1.1 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "sphinxcontrib"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmSz5jcVVt4p"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = 100*np.sin(0.01*x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(-100,100,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "             \n",
    "      \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - torch.cos(0.01*g)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "   \n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Training time: 19.39\n",
      "Training time: 19.39\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 58.834743 Test MSE 2031.5285718040855 Test RE 0.8630162020621794\n",
      "1 Train Loss 52.796383 Test MSE 1635.746606389627 Test RE 0.7744002700727087\n",
      "2 Train Loss 43.094284 Test MSE 1331.1797949945947 Test RE 0.6985955909736586\n",
      "3 Train Loss 35.73412 Test MSE 1035.5402085671724 Test RE 0.6161564017522493\n",
      "4 Train Loss 34.742348 Test MSE 1082.7200543241006 Test RE 0.630036299823849\n",
      "5 Train Loss 31.59826 Test MSE 966.3916564996781 Test RE 0.5952289800549657\n",
      "6 Train Loss 27.529795 Test MSE 798.0666266969653 Test RE 0.5409125486580131\n",
      "7 Train Loss 23.887865 Test MSE 581.6222698436651 Test RE 0.46177242504311267\n",
      "8 Train Loss 20.432135 Test MSE 446.8210150126269 Test RE 0.404738275735842\n",
      "9 Train Loss 16.843819 Test MSE 388.1343240511222 Test RE 0.3772232974458872\n",
      "10 Train Loss 11.512944 Test MSE 262.1711085950903 Test RE 0.31002727069124436\n",
      "11 Train Loss 7.2585144 Test MSE 168.17486173025998 Test RE 0.24830646172348628\n",
      "12 Train Loss 6.515878 Test MSE 143.73900208616695 Test RE 0.22955924857942764\n",
      "13 Train Loss 5.01333 Test MSE 90.76463158284083 Test RE 0.1824172088619657\n",
      "14 Train Loss 3.0967824 Test MSE 44.3230352605014 Test RE 0.12747418044424955\n",
      "15 Train Loss 2.90737 Test MSE 33.756096947928064 Test RE 0.1112457925794911\n",
      "16 Train Loss 1.8772494 Test MSE 15.360193987674045 Test RE 0.07504224740584242\n",
      "17 Train Loss 1.2440512 Test MSE 5.893417548880541 Test RE 0.04648267229684612\n",
      "18 Train Loss 0.9363936 Test MSE 3.521387755791848 Test RE 0.035930594804475066\n",
      "19 Train Loss 0.7462388 Test MSE 0.8660856417245505 Test RE 0.0178191876437556\n",
      "20 Train Loss 0.69931066 Test MSE 2.205588644494931 Test RE 0.028436080849655803\n",
      "21 Train Loss 0.6705644 Test MSE 2.6639619849138207 Test RE 0.03125154504778737\n",
      "22 Train Loss 0.62563986 Test MSE 2.4858784347089875 Test RE 0.03018890947883964\n",
      "23 Train Loss 0.5988083 Test MSE 2.919636002037263 Test RE 0.032716876673895806\n",
      "24 Train Loss 0.59131503 Test MSE 3.0817471388201687 Test RE 0.033612899926624536\n",
      "25 Train Loss 0.54628676 Test MSE 3.2019209860323063 Test RE 0.034262006022251795\n",
      "26 Train Loss 0.3311722 Test MSE 1.2807239919381785 Test RE 0.021668819623524113\n",
      "27 Train Loss 0.17756227 Test MSE 0.28704895976511036 Test RE 0.010258537975118791\n",
      "28 Train Loss 0.11467282 Test MSE 0.5204829824100431 Test RE 0.013813723189810433\n",
      "29 Train Loss 0.096386805 Test MSE 0.2651592241293555 Test RE 0.009859635312165363\n",
      "30 Train Loss 0.08780409 Test MSE 0.14365061068151352 Test RE 0.00725706846049672\n",
      "31 Train Loss 0.07906707 Test MSE 0.17601956461414675 Test RE 0.008033188409816922\n",
      "32 Train Loss 0.07361688 Test MSE 0.36492216049024695 Test RE 0.01156665016501793\n",
      "33 Train Loss 0.06992912 Test MSE 0.49294462754313045 Test RE 0.013443320436418302\n",
      "34 Train Loss 0.06410413 Test MSE 0.41569615636160934 Test RE 0.012345124844294652\n",
      "35 Train Loss 0.060692713 Test MSE 0.195639760465032 Test RE 0.008469076250023832\n",
      "36 Train Loss 0.057863396 Test MSE 0.08635984429952327 Test RE 0.00562682498379652\n",
      "37 Train Loss 0.05106775 Test MSE 0.04456931830246814 Test RE 0.004042271480426839\n",
      "38 Train Loss 0.04424794 Test MSE 0.06295553472283631 Test RE 0.004804237184284882\n",
      "39 Train Loss 0.036751658 Test MSE 0.05228982843049679 Test RE 0.004378406604234951\n",
      "40 Train Loss 0.033888295 Test MSE 0.03784243537941833 Test RE 0.003724749073302533\n",
      "41 Train Loss 0.032505468 Test MSE 0.039840119223071936 Test RE 0.003821798595405152\n",
      "42 Train Loss 0.031592317 Test MSE 0.04913496049618294 Test RE 0.004244267884796128\n",
      "43 Train Loss 0.028540878 Test MSE 0.03674440498378568 Test RE 0.0036703129100957867\n",
      "44 Train Loss 0.023599552 Test MSE 0.02823742037852145 Test RE 0.003217510637803587\n",
      "45 Train Loss 0.016357623 Test MSE 0.02610252317518176 Test RE 0.003093490073600064\n",
      "46 Train Loss 0.014696088 Test MSE 0.0246463497864504 Test RE 0.0030059640732902444\n",
      "47 Train Loss 0.013955376 Test MSE 0.018180868670732497 Test RE 0.00258175363186018\n",
      "48 Train Loss 0.013337857 Test MSE 0.012323542112151463 Test RE 0.002125569249492907\n",
      "49 Train Loss 0.012415392 Test MSE 0.018689744559166735 Test RE 0.0026176354564472625\n",
      "50 Train Loss 0.009596544 Test MSE 0.007817260231360703 Test RE 0.0016929134934388654\n",
      "51 Train Loss 0.009274814 Test MSE 0.005789084313766506 Test RE 0.0014568418850257545\n",
      "52 Train Loss 0.009170752 Test MSE 0.007110912587480285 Test RE 0.0016146193459610375\n",
      "53 Train Loss 0.008826014 Test MSE 0.006337844471071635 Test RE 0.001524327450318803\n",
      "54 Train Loss 0.008759898 Test MSE 0.005003903319095808 Test RE 0.0013544467542668348\n",
      "55 Train Loss 0.008723853 Test MSE 0.004910582417274969 Test RE 0.001341757353185446\n",
      "56 Train Loss 0.008474772 Test MSE 0.004497653660825118 Test RE 0.0012841048511639298\n",
      "57 Train Loss 0.008319349 Test MSE 0.00439524357108908 Test RE 0.001269401348872565\n",
      "58 Train Loss 0.008153523 Test MSE 0.004694465542316195 Test RE 0.001311899479055096\n",
      "59 Train Loss 0.007895034 Test MSE 0.004340173148541164 Test RE 0.0012614237676151117\n",
      "60 Train Loss 0.007612914 Test MSE 0.004108403409756443 Test RE 0.0012272810324470028\n",
      "61 Train Loss 0.0073329695 Test MSE 0.0037035658234194535 Test RE 0.0011652457179589547\n",
      "62 Train Loss 0.006895905 Test MSE 0.003300675557343429 Test RE 0.001100041071250451\n",
      "63 Train Loss 0.004634099 Test MSE 0.0045201307002488735 Test RE 0.0012873095115028886\n",
      "64 Train Loss 0.003939739 Test MSE 0.002763109826553101 Test RE 0.0010064832586862578\n",
      "65 Train Loss 0.0033994503 Test MSE 0.0023735692828353605 Test RE 0.0009328427450742433\n",
      "66 Train Loss 0.0031472174 Test MSE 0.002042502763434609 Test RE 0.0008653440426429266\n",
      "67 Train Loss 0.002927094 Test MSE 0.0027856072428061344 Test RE 0.0010105723775027029\n",
      "68 Train Loss 0.0027236375 Test MSE 0.0023804430258742414 Test RE 0.0009341925025433726\n",
      "69 Train Loss 0.0025437092 Test MSE 0.0031129423086411574 Test RE 0.0010682994820331087\n",
      "70 Train Loss 0.0023022797 Test MSE 0.001266219511060014 Test RE 0.0006813370132776013\n",
      "71 Train Loss 0.0021654426 Test MSE 0.0012528667449907755 Test RE 0.0006777350130943563\n",
      "72 Train Loss 0.002054937 Test MSE 0.001488782109251596 Test RE 0.000738793477179733\n",
      "73 Train Loss 0.0017421742 Test MSE 0.001306294335519163 Test RE 0.0006920349106539735\n",
      "74 Train Loss 0.0013059784 Test MSE 0.0011852499078935255 Test RE 0.0006591927874721568\n",
      "75 Train Loss 0.0011216911 Test MSE 0.0008205281129977534 Test RE 0.0005484716882834071\n",
      "76 Train Loss 0.0009918301 Test MSE 0.0008681987716584953 Test RE 0.000564179193038738\n",
      "77 Train Loss 0.0008890671 Test MSE 0.0008103004083681979 Test RE 0.0005450426791063072\n",
      "78 Train Loss 0.00078610197 Test MSE 0.0007610583919961387 Test RE 0.0005282219831205025\n",
      "79 Train Loss 0.0007491656 Test MSE 0.0006878837481132158 Test RE 0.000502186468346377\n",
      "80 Train Loss 0.00074862444 Test MSE 0.0007021768488701122 Test RE 0.0005073769518190468\n",
      "81 Train Loss 0.00071096455 Test MSE 0.0006883854384363536 Test RE 0.0005023695633621725\n",
      "82 Train Loss 0.0007077535 Test MSE 0.0006467970036727026 Test RE 0.00048695797354695263\n",
      "83 Train Loss 0.0007077535 Test MSE 0.0006467970036727026 Test RE 0.00048695797354695263\n",
      "84 Train Loss 0.0007077535 Test MSE 0.0006467970036727026 Test RE 0.00048695797354695263\n",
      "85 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "86 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "87 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "88 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "89 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "90 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "91 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "92 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "93 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "94 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "95 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "96 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "97 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "98 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "99 Train Loss 0.0007076414 Test MSE 0.0006468114401856125 Test RE 0.0004869634079690394\n",
      "Training time: 17.73\n",
      "Training time: 17.73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 63.457348 Test MSE 2288.225333357266 Test RE 0.9159185957161738\n",
      "1 Train Loss 62.329887 Test MSE 2173.833285112293 Test RE 0.8927309651393612\n",
      "2 Train Loss 57.633224 Test MSE 1983.9981920410469 Test RE 0.8528607300849604\n",
      "3 Train Loss 44.574764 Test MSE 1280.6939793089039 Test RE 0.6852202132722126\n",
      "4 Train Loss 41.7319 Test MSE 1054.5289474252543 Test RE 0.6217799802122612\n",
      "5 Train Loss 37.05736 Test MSE 695.2354108565294 Test RE 0.5048628607878966\n",
      "6 Train Loss 31.349182 Test MSE 722.4662100743902 Test RE 0.5146550655227268\n",
      "7 Train Loss 22.36304 Test MSE 668.0157234046374 Test RE 0.49488105007381056\n",
      "8 Train Loss 15.416282 Test MSE 278.26321992553324 Test RE 0.31940034794788186\n",
      "9 Train Loss 13.086582 Test MSE 152.8108355277461 Test RE 0.23669253278285113\n",
      "10 Train Loss 5.479177 Test MSE 138.67652686699728 Test RE 0.22548048480304844\n",
      "11 Train Loss 4.1317225 Test MSE 99.20676303498408 Test RE 0.19071204430961378\n",
      "12 Train Loss 3.1354384 Test MSE 36.811774169762465 Test RE 0.11617183686819019\n",
      "13 Train Loss 2.5372279 Test MSE 27.293853619538126 Test RE 0.10003222084253473\n",
      "14 Train Loss 1.2970146 Test MSE 16.116078377788803 Test RE 0.07686651072994781\n",
      "15 Train Loss 0.81309617 Test MSE 8.161994076158086 Test RE 0.05470230408566175\n",
      "16 Train Loss 0.32321224 Test MSE 0.3427711287549888 Test RE 0.011210102899984257\n",
      "17 Train Loss 0.2749228 Test MSE 0.6003383145458862 Test RE 0.014835613571574454\n",
      "18 Train Loss 0.21932818 Test MSE 0.4109580863749063 Test RE 0.012274568870655322\n",
      "19 Train Loss 0.10741037 Test MSE 0.6696357109009768 Test RE 0.015668477013141516\n",
      "20 Train Loss 0.08723374 Test MSE 0.4532558293075902 Test RE 0.012890779534259366\n",
      "21 Train Loss 0.056192793 Test MSE 0.21760495087970197 Test RE 0.008931859189555745\n",
      "22 Train Loss 0.040995404 Test MSE 0.34986449199248293 Test RE 0.011325500816101577\n",
      "23 Train Loss 0.01635891 Test MSE 0.026364377745961787 Test RE 0.003108967946965438\n",
      "24 Train Loss 0.014139842 Test MSE 0.036272211755766726 Test RE 0.0036466535139653006\n",
      "25 Train Loss 0.012132776 Test MSE 0.04499087214243131 Test RE 0.0040613431727660465\n",
      "26 Train Loss 0.009991228 Test MSE 0.01533676042206959 Test RE 0.0023712333721986815\n",
      "27 Train Loss 0.00946026 Test MSE 0.01030645745682911 Test RE 0.0019438474949245866\n",
      "28 Train Loss 0.00532861 Test MSE 0.004634725255953129 Test RE 0.001303525342809725\n",
      "29 Train Loss 0.0045817317 Test MSE 0.005929966137218318 Test RE 0.0014744620139603027\n",
      "30 Train Loss 0.004234687 Test MSE 0.0035067478291142366 Test RE 0.0011338608238163999\n",
      "31 Train Loss 0.0027762193 Test MSE 0.005070091696067051 Test RE 0.0013633751965052242\n",
      "32 Train Loss 0.0013028487 Test MSE 0.0007221913975603706 Test RE 0.0005145571736748669\n",
      "33 Train Loss 0.0011802405 Test MSE 0.0005340351942311938 Test RE 0.00044247875277128595\n",
      "34 Train Loss 0.0011504262 Test MSE 0.0006229359363609753 Test RE 0.0004778913552925803\n",
      "35 Train Loss 0.001036313 Test MSE 0.0005460500903160462 Test RE 0.000447428581777945\n",
      "36 Train Loss 0.00068385864 Test MSE 0.0004120127501369008 Test RE 0.00038865370283818905\n",
      "37 Train Loss 0.0005356706 Test MSE 0.0002035232269102347 Test RE 0.0002731583443364352\n",
      "38 Train Loss 0.0004955628 Test MSE 0.00019776250282000932 Test RE 0.0002692647214161811\n",
      "39 Train Loss 0.00044482984 Test MSE 0.00030045383815066417 Test RE 0.0003318916757619389\n",
      "40 Train Loss 0.00041750885 Test MSE 0.0002146618997277424 Test RE 0.000280533652391303\n",
      "41 Train Loss 0.0004078468 Test MSE 0.00015650441121611435 Test RE 0.00023953598912293306\n",
      "42 Train Loss 0.00040708826 Test MSE 0.00015301911045801782 Test RE 0.0002368537789881272\n",
      "43 Train Loss 0.00040615594 Test MSE 0.00015081968275994502 Test RE 0.00023514540320163427\n",
      "44 Train Loss 0.00040527043 Test MSE 0.00014639703715926076 Test RE 0.00023167204138127117\n",
      "45 Train Loss 0.0004050254 Test MSE 0.00014590156785488343 Test RE 0.00023127967117523196\n",
      "46 Train Loss 0.00040485928 Test MSE 0.00014659149964710693 Test RE 0.00023182585791880247\n",
      "47 Train Loss 0.00040456865 Test MSE 0.0001478082019998662 Test RE 0.00023278594157422305\n",
      "48 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "49 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "50 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "51 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "52 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "53 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "54 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "55 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "56 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "57 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "58 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "59 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "60 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "61 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "62 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "63 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "64 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "65 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "66 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "67 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "68 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "69 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "70 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "71 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "72 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "73 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "74 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "75 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "76 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "77 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "78 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "79 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "80 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "81 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "82 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "83 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "84 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "85 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "86 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "87 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "88 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "89 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "90 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "91 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "92 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "93 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "94 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "95 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "96 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "97 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "98 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "99 Train Loss 0.00040431027 Test MSE 0.00014943613982525968 Test RE 0.00023406436620177515\n",
      "Training time: 9.41\n",
      "Training time: 9.41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 63.24175 Test MSE 2252.0803297708803 Test RE 0.9086558364194298\n",
      "1 Train Loss 55.223644 Test MSE 1801.615626826786 Test RE 0.8127155172647254\n",
      "2 Train Loss 48.70262 Test MSE 1474.4685012780333 Test RE 0.7352334060291045\n",
      "3 Train Loss 39.380516 Test MSE 1252.1165629511947 Test RE 0.6775320781984839\n",
      "4 Train Loss 37.167305 Test MSE 1105.5999458994017 Test RE 0.6366584185967133\n",
      "5 Train Loss 34.26499 Test MSE 977.66092527279 Test RE 0.5986894576479209\n",
      "6 Train Loss 29.456509 Test MSE 821.6670931829559 Test RE 0.5488522247565689\n",
      "7 Train Loss 23.93544 Test MSE 558.8312492863226 Test RE 0.4526346777029128\n",
      "8 Train Loss 18.726097 Test MSE 341.0375569889445 Test RE 0.35359701170703617\n",
      "9 Train Loss 17.15017 Test MSE 289.4967473026858 Test RE 0.3257836809848187\n",
      "10 Train Loss 8.403013 Test MSE 151.1089617996057 Test RE 0.23537080498204974\n",
      "11 Train Loss 6.5424876 Test MSE 90.3001791710703 Test RE 0.1819498859910874\n",
      "12 Train Loss 4.6313405 Test MSE 39.38542924711893 Test RE 0.12016424809999389\n",
      "13 Train Loss 2.6432517 Test MSE 15.907160694858053 Test RE 0.07636666341190501\n",
      "14 Train Loss 1.1457661 Test MSE 8.945761079542025 Test RE 0.05726854235997242\n",
      "15 Train Loss 0.76394916 Test MSE 8.384279408333747 Test RE 0.05544218698385865\n",
      "16 Train Loss 0.3651126 Test MSE 1.3867656664431245 Test RE 0.022548051714092084\n",
      "17 Train Loss 0.18938974 Test MSE 0.4841305113760482 Test RE 0.01332259141225159\n",
      "18 Train Loss 0.14186576 Test MSE 0.3846475365604734 Test RE 0.011875146045729609\n",
      "19 Train Loss 0.114542335 Test MSE 0.30345492901897986 Test RE 0.010547622545419627\n",
      "20 Train Loss 0.080591634 Test MSE 0.23076573770296227 Test RE 0.009197994511397748\n",
      "21 Train Loss 0.055061918 Test MSE 0.14950638933984334 Test RE 0.007403504733025694\n",
      "22 Train Loss 0.037195943 Test MSE 0.0859398001953392 Test RE 0.005613124196968283\n",
      "23 Train Loss 0.029790688 Test MSE 0.09700702525076156 Test RE 0.005963607816345893\n",
      "24 Train Loss 0.025180634 Test MSE 0.10890457639984852 Test RE 0.006318740890593205\n",
      "25 Train Loss 0.01923107 Test MSE 0.07994267201513314 Test RE 0.005413732736219993\n",
      "26 Train Loss 0.012920356 Test MSE 0.019058301542519928 Test RE 0.002643319007232736\n",
      "27 Train Loss 0.0111655565 Test MSE 0.013313021548130431 Test RE 0.0022092547593285986\n",
      "28 Train Loss 0.01063399 Test MSE 0.0209132687140607 Test RE 0.0027689712125174687\n",
      "29 Train Loss 0.010465256 Test MSE 0.02566482109237138 Test RE 0.0030674437138085617\n",
      "30 Train Loss 0.009501432 Test MSE 0.01632216975403353 Test RE 0.002446225150146238\n",
      "31 Train Loss 0.009217111 Test MSE 0.012073840914918848 Test RE 0.0021039247686643987\n",
      "32 Train Loss 0.008990352 Test MSE 0.012946308137938643 Test RE 0.0021786148097837923\n",
      "33 Train Loss 0.008782566 Test MSE 0.013145654917841495 Test RE 0.0021953238498412606\n",
      "34 Train Loss 0.008782001 Test MSE 0.013130664936138958 Test RE 0.0021940718296451374\n",
      "35 Train Loss 0.008696505 Test MSE 0.013246494213464155 Test RE 0.0022037278432203425\n",
      "36 Train Loss 0.007866449 Test MSE 0.015897135177430893 Test RE 0.002414164811179062\n",
      "37 Train Loss 0.0073081027 Test MSE 0.017334330219797238 Test RE 0.0025209313236973724\n",
      "38 Train Loss 0.0072173346 Test MSE 0.019351415134676194 Test RE 0.0026635683555753195\n",
      "39 Train Loss 0.0071851085 Test MSE 0.019946869650478653 Test RE 0.0027042376599470852\n",
      "40 Train Loss 0.0071851076 Test MSE 0.019946996975534086 Test RE 0.002704246290791586\n",
      "41 Train Loss 0.007184968 Test MSE 0.019988558466501338 Test RE 0.0027070621037102597\n",
      "42 Train Loss 0.007135366 Test MSE 0.021767164213057022 Test RE 0.0028249346693592086\n",
      "43 Train Loss 0.007061297 Test MSE 0.021062112324089076 Test RE 0.0027788073827807423\n",
      "44 Train Loss 0.0070168166 Test MSE 0.019878668784010883 Test RE 0.00269961063642445\n",
      "45 Train Loss 0.0069847307 Test MSE 0.0185637078502536 Test RE 0.0026087943443646026\n",
      "46 Train Loss 0.0068624862 Test MSE 0.017700351104148644 Test RE 0.002547407495450459\n",
      "47 Train Loss 0.0066864006 Test MSE 0.01962323011262896 Test RE 0.0026822097082619084\n",
      "48 Train Loss 0.0064919167 Test MSE 0.019323000864061534 Test RE 0.002661612138058783\n",
      "49 Train Loss 0.0062230555 Test MSE 0.019934339634424664 Test RE 0.002703388166648007\n",
      "50 Train Loss 0.006000313 Test MSE 0.01773177289767928 Test RE 0.00254966758113072\n",
      "51 Train Loss 0.0057426835 Test MSE 0.020772776880533354 Test RE 0.0027596547974010222\n",
      "52 Train Loss 0.005499642 Test MSE 0.021782535278297696 Test RE 0.002825931918969599\n",
      "53 Train Loss 0.0052536223 Test MSE 0.021666046448825874 Test RE 0.002818365517984365\n",
      "54 Train Loss 0.0050809793 Test MSE 0.016838438750163543 Test RE 0.0024846109365762306\n",
      "55 Train Loss 0.004675756 Test MSE 0.017137236903491556 Test RE 0.0025065587136724257\n",
      "56 Train Loss 0.0043269987 Test MSE 0.02305899086455376 Test RE 0.0029075529360482843\n",
      "57 Train Loss 0.0041826214 Test MSE 0.02007832835527113 Test RE 0.002713134088065308\n",
      "58 Train Loss 0.004047615 Test MSE 0.018697011512894518 Test RE 0.002618144302006363\n",
      "59 Train Loss 0.0037555443 Test MSE 0.023444856203958482 Test RE 0.0029317792616747763\n",
      "60 Train Loss 0.0036001476 Test MSE 0.022628118110194096 Test RE 0.00288026004718036\n",
      "61 Train Loss 0.003157637 Test MSE 0.022363503109170665 Test RE 0.002863369527920404\n",
      "62 Train Loss 0.0028096247 Test MSE 0.014385032855135796 Test RE 0.002296481286778331\n",
      "63 Train Loss 0.002648813 Test MSE 0.012325326878056021 Test RE 0.002125723162472852\n",
      "64 Train Loss 0.002401441 Test MSE 0.008967312239182535 Test RE 0.001813170430087204\n",
      "65 Train Loss 0.0019262274 Test MSE 0.003576605228683319 Test RE 0.0011450988679881956\n",
      "66 Train Loss 0.001415688 Test MSE 0.0010655166720418563 Test RE 0.0006250109217912131\n",
      "67 Train Loss 0.0011120464 Test MSE 0.0005941752623668766 Test RE 0.0004667289770775815\n",
      "68 Train Loss 0.0010482647 Test MSE 0.0007317786605237316 Test RE 0.0005179613476899416\n",
      "69 Train Loss 0.0010482328 Test MSE 0.0007304232761396168 Test RE 0.0005174814470480024\n",
      "70 Train Loss 0.0010475201 Test MSE 0.00074173750237756 Test RE 0.0005214739286877086\n",
      "71 Train Loss 0.0010470935 Test MSE 0.0007502960297679854 Test RE 0.0005244738096595185\n",
      "72 Train Loss 0.0010198271 Test MSE 0.001371874830966339 Test RE 0.0007091934665178494\n",
      "73 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "74 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "75 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "76 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "77 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "78 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "79 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "80 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "81 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "82 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "83 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "84 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "85 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "86 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "87 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "88 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "89 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "90 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "91 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "92 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "93 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "94 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "95 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "96 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "97 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "98 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "99 Train Loss 0.0010127366 Test MSE 0.0012614993455950763 Test RE 0.0006800658963211377\n",
      "Training time: 15.73\n",
      "Training time: 15.73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 63.999176 Test MSE 2283.3059349344962 Test RE 0.9149335107365882\n",
      "1 Train Loss 55.321426 Test MSE 1850.0440370420047 Test RE 0.8235662008158556\n",
      "2 Train Loss 46.952087 Test MSE 1625.3534628175432 Test RE 0.7719361725095094\n",
      "3 Train Loss 40.970913 Test MSE 1312.6201339875706 Test RE 0.6937084945755295\n",
      "4 Train Loss 39.691948 Test MSE 1189.530162699486 Test RE 0.6603819756581996\n",
      "5 Train Loss 38.698105 Test MSE 1109.9860877196777 Test RE 0.6379200458363447\n",
      "6 Train Loss 37.22617 Test MSE 1044.8547162615125 Test RE 0.6189213091160723\n",
      "7 Train Loss 34.78089 Test MSE 932.7751013205607 Test RE 0.5847846364207898\n",
      "8 Train Loss 33.261806 Test MSE 915.1579437824856 Test RE 0.5792359505310186\n",
      "9 Train Loss 32.279587 Test MSE 773.5260085394493 Test RE 0.5325310587274928\n",
      "10 Train Loss 30.310667 Test MSE 825.7708879120693 Test RE 0.5502211316579634\n",
      "11 Train Loss 28.761341 Test MSE 796.1675113555827 Test RE 0.5402685753736368\n",
      "12 Train Loss 26.041893 Test MSE 654.8642012799222 Test RE 0.4899853629313667\n",
      "13 Train Loss 21.77776 Test MSE 558.858583761123 Test RE 0.45264574757410786\n",
      "14 Train Loss 18.4371 Test MSE 464.8946447681382 Test RE 0.4128428367282541\n",
      "15 Train Loss 15.114402 Test MSE 361.60367450674966 Test RE 0.36410269985392774\n",
      "16 Train Loss 10.986211 Test MSE 241.07221297272312 Test RE 0.2972905189301987\n",
      "17 Train Loss 7.271087 Test MSE 143.04950239511757 Test RE 0.22900800187763015\n",
      "18 Train Loss 5.50185 Test MSE 103.43074930634461 Test RE 0.19472975491694708\n",
      "19 Train Loss 4.0438056 Test MSE 88.0761148863452 Test RE 0.17969523309596386\n",
      "20 Train Loss 1.9512962 Test MSE 23.403742064280504 Test RE 0.09262967351007233\n",
      "21 Train Loss 1.3811783 Test MSE 12.868718480472287 Test RE 0.06868709228888009\n",
      "22 Train Loss 1.3733207 Test MSE 12.222019846702409 Test RE 0.06693896207273585\n",
      "23 Train Loss 1.1609389 Test MSE 10.249854968003891 Test RE 0.0613008281828986\n",
      "24 Train Loss 0.64778274 Test MSE 4.590243139275195 Test RE 0.041022802566350366\n",
      "25 Train Loss 0.40687287 Test MSE 3.247325650041719 Test RE 0.03450407612144618\n",
      "26 Train Loss 0.26281294 Test MSE 1.5774297251249647 Test RE 0.024048195396717802\n",
      "27 Train Loss 0.15728867 Test MSE 0.7288580294529116 Test RE 0.016346657116070175\n",
      "28 Train Loss 0.094901584 Test MSE 0.16564603302711797 Test RE 0.007792880230943592\n",
      "29 Train Loss 0.07070743 Test MSE 0.22638514559041878 Test RE 0.009110274131451983\n",
      "30 Train Loss 0.07033069 Test MSE 0.23006497131877623 Test RE 0.009184018116467978\n",
      "31 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "32 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "33 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "34 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "35 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "36 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "37 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "38 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "39 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "40 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "41 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "42 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "43 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "44 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "45 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "46 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "47 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "48 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "49 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "50 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "51 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "52 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "53 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "54 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "55 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "56 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "57 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "58 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "59 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "60 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "61 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "62 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "63 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "64 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "65 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "66 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "67 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "68 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "69 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "70 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "71 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "72 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "73 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "74 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "75 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "76 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "77 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "78 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "79 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "80 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "81 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "82 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "83 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "84 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "85 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "86 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "87 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "88 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "89 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "90 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "91 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "92 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "93 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "94 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "95 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "96 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "97 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "98 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "99 Train Loss 0.07031366 Test MSE 0.23198441720414859 Test RE 0.009222249947094408\n",
      "Training time: 10.22\n",
      "Training time: 10.22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 59.43965 Test MSE 2026.9214935424388 Test RE 0.8620370772859901\n",
      "1 Train Loss 57.577827 Test MSE 1908.7993012113295 Test RE 0.8365417401878577\n",
      "2 Train Loss 50.198788 Test MSE 1688.3910315235005 Test RE 0.7867631311697398\n",
      "3 Train Loss 49.97664 Test MSE 1659.8820740993508 Test RE 0.7800924940189028\n",
      "4 Train Loss 49.593094 Test MSE 1631.1085996067134 Test RE 0.7733016209081796\n",
      "5 Train Loss 46.5659 Test MSE 1485.8965352406015 Test RE 0.7380771610590441\n",
      "6 Train Loss 41.97489 Test MSE 1267.9265915646683 Test RE 0.6817961380078964\n",
      "7 Train Loss 35.42269 Test MSE 889.8651800821218 Test RE 0.5711755235981695\n",
      "8 Train Loss 31.305573 Test MSE 713.3265522745874 Test RE 0.5113893470764589\n",
      "9 Train Loss 30.370321 Test MSE 656.8496525444718 Test RE 0.49072758230599595\n",
      "10 Train Loss 29.48105 Test MSE 586.0995623360842 Test RE 0.4635463655427196\n",
      "11 Train Loss 20.474936 Test MSE 355.3524870134562 Test RE 0.36094178472338145\n",
      "12 Train Loss 15.711063 Test MSE 393.6035277062683 Test RE 0.37987172846641354\n",
      "13 Train Loss 12.5030575 Test MSE 262.0114988203488 Test RE 0.30993288401994323\n",
      "14 Train Loss 10.148061 Test MSE 172.88061372219067 Test RE 0.2517564636779093\n",
      "15 Train Loss 7.91548 Test MSE 129.41963290169326 Test RE 0.21782492019241032\n",
      "16 Train Loss 6.770606 Test MSE 93.26526609795147 Test RE 0.184913001716729\n",
      "17 Train Loss 5.4984875 Test MSE 54.77145267313629 Test RE 0.14170481636100155\n",
      "18 Train Loss 3.7436528 Test MSE 37.465406048495616 Test RE 0.11719867552306945\n",
      "19 Train Loss 3.1515813 Test MSE 67.56687989530509 Test RE 0.15738901378267472\n",
      "20 Train Loss 2.854103 Test MSE 59.89108745372749 Test RE 0.14817965562873353\n",
      "21 Train Loss 2.4561648 Test MSE 39.448873334195426 Test RE 0.12026099254925957\n",
      "22 Train Loss 1.8894422 Test MSE 18.04481805535212 Test RE 0.08133617322955765\n",
      "23 Train Loss 1.3026141 Test MSE 22.182296773224508 Test RE 0.09018010517014322\n",
      "24 Train Loss 0.7829004 Test MSE 15.394506678752688 Test RE 0.0751260179968804\n",
      "25 Train Loss 0.35081854 Test MSE 4.294638079166605 Test RE 0.039679918095864894\n",
      "26 Train Loss 0.2589003 Test MSE 2.0457029372973983 Test RE 0.02738601023635431\n",
      "27 Train Loss 0.23993775 Test MSE 1.0667755126541683 Test RE 0.019776252608609005\n",
      "28 Train Loss 0.19761528 Test MSE 0.351162627982507 Test RE 0.01134649241169482\n",
      "29 Train Loss 0.17098159 Test MSE 0.4689413570396671 Test RE 0.013111933855358129\n",
      "30 Train Loss 0.14516792 Test MSE 0.7165587745099538 Test RE 0.01620814790078001\n",
      "31 Train Loss 0.11481108 Test MSE 0.5608185393507769 Test RE 0.014338993331022213\n",
      "32 Train Loss 0.096968085 Test MSE 0.23425799352881727 Test RE 0.009267331350275873\n",
      "33 Train Loss 0.08727559 Test MSE 0.2502983632606535 Test RE 0.009579359822026075\n",
      "34 Train Loss 0.062889636 Test MSE 0.12394962711730173 Test RE 0.006741089513491061\n",
      "35 Train Loss 0.015643133 Test MSE 0.12115087247122323 Test RE 0.00666454883776404\n",
      "36 Train Loss 0.008377011 Test MSE 0.01047712725123598 Test RE 0.0019598759838752094\n",
      "37 Train Loss 0.0070107 Test MSE 0.016298955176099198 Test RE 0.002444484931423545\n",
      "38 Train Loss 0.006710712 Test MSE 0.013679000536191217 Test RE 0.0022394154238815685\n",
      "39 Train Loss 0.0066957464 Test MSE 0.015863541315682902 Test RE 0.0024116126529098096\n",
      "40 Train Loss 0.0066407 Test MSE 0.017925787928192806 Test RE 0.0025635784306188795\n",
      "41 Train Loss 0.0058432235 Test MSE 0.01018697945315456 Test RE 0.0019325475874586015\n",
      "42 Train Loss 0.0054019853 Test MSE 0.008150993505179071 Test RE 0.001728672627767958\n",
      "43 Train Loss 0.004182264 Test MSE 0.005696947590661761 Test RE 0.0014452021329421146\n",
      "44 Train Loss 0.0033755815 Test MSE 0.0015269433341178645 Test RE 0.0007482021330255234\n",
      "45 Train Loss 0.003066567 Test MSE 0.0011835682650613005 Test RE 0.0006587249872661539\n",
      "46 Train Loss 0.0026945383 Test MSE 0.0005575110017776932 Test RE 0.0004520996833037393\n",
      "47 Train Loss 0.0023468337 Test MSE 0.0005725392234403149 Test RE 0.00045815254575152446\n",
      "48 Train Loss 0.0020822415 Test MSE 0.0007989594275198544 Test RE 0.0005412150247700844\n",
      "49 Train Loss 0.0020270064 Test MSE 0.0008378574428911332 Test RE 0.000554233212982224\n",
      "50 Train Loss 0.0019935542 Test MSE 0.0012788908919560199 Test RE 0.0006847376830597863\n",
      "51 Train Loss 0.0019544712 Test MSE 0.0015367442305883451 Test RE 0.000750599511514839\n",
      "52 Train Loss 0.001843882 Test MSE 0.0005651438318653147 Test RE 0.000455183989333443\n",
      "53 Train Loss 0.0017251887 Test MSE 0.0012750434483094302 Test RE 0.0006837069172356003\n",
      "54 Train Loss 0.0016095495 Test MSE 0.0022441548909346784 Test RE 0.0009070555730666934\n",
      "55 Train Loss 0.0012038021 Test MSE 0.0004965225863902029 Test RE 0.00042665514415732113\n",
      "56 Train Loss 0.00077025814 Test MSE 0.000249047740471949 Test RE 0.0003021682189259383\n",
      "57 Train Loss 0.00069654285 Test MSE 0.00017993724573674676 Test RE 0.0002568431668291349\n",
      "58 Train Loss 0.0006245526 Test MSE 0.00013357011495999856 Test RE 0.00022129017470577295\n",
      "59 Train Loss 0.0005594479 Test MSE 0.00011188342870356523 Test RE 0.00020253046754206835\n",
      "60 Train Loss 0.00052341743 Test MSE 0.00012046410178660874 Test RE 0.00021015334408991455\n",
      "61 Train Loss 0.00046930264 Test MSE 7.172769052031207e-05 Test RE 0.0001621626771878081\n",
      "62 Train Loss 0.00046864105 Test MSE 7.18840137940014e-05 Test RE 0.00016233928962005524\n",
      "63 Train Loss 0.0004669024 Test MSE 7.218252977721019e-05 Test RE 0.00016267601723779496\n",
      "64 Train Loss 0.00046624738 Test MSE 7.494764591232979e-05 Test RE 0.00016576257323412628\n",
      "65 Train Loss 0.00046372562 Test MSE 7.769766189690467e-05 Test RE 0.0001687762980516429\n",
      "66 Train Loss 0.00046345667 Test MSE 7.791108842638376e-05 Test RE 0.0001690079436119526\n",
      "67 Train Loss 0.00046248248 Test MSE 7.967816335307283e-05 Test RE 0.00017091380353600352\n",
      "68 Train Loss 0.00046171263 Test MSE 7.981494207635396e-05 Test RE 0.0001710604393696148\n",
      "69 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "70 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "71 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "72 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "73 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "74 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "75 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "76 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "77 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "78 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "79 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "80 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "81 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "82 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "83 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "84 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "85 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "86 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "87 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "88 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "89 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "90 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "91 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "92 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "93 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "94 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "95 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "96 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "97 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "98 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "99 Train Loss 0.00046116018 Test MSE 7.867304285370302e-05 Test RE 0.00016983236432130102\n",
      "Training time: 13.81\n",
      "Training time: 13.81\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 63.65251 Test MSE 2291.033688843835 Test RE 0.9164804801233601\n",
      "1 Train Loss 61.272663 Test MSE 2125.120513502918 Test RE 0.882671823899733\n",
      "2 Train Loss 54.95703 Test MSE 1845.861305396271 Test RE 0.8226346809188275\n",
      "3 Train Loss 42.63809 Test MSE 1292.2299108573914 Test RE 0.6882993769554349\n",
      "4 Train Loss 32.17514 Test MSE 767.497910426951 Test RE 0.5304519895641596\n",
      "5 Train Loss 29.158525 Test MSE 570.9226484297253 Test RE 0.45750528747929775\n",
      "6 Train Loss 25.138071 Test MSE 715.8929581142903 Test RE 0.5123084592656706\n",
      "7 Train Loss 19.542051 Test MSE 555.7225620331939 Test RE 0.45137395545167075\n",
      "8 Train Loss 13.135913 Test MSE 293.81155083119705 Test RE 0.32820252243531295\n",
      "9 Train Loss 11.65458 Test MSE 153.81021855456567 Test RE 0.23746525614690772\n",
      "10 Train Loss 7.518043 Test MSE 119.04331374947354 Test RE 0.2089103639092453\n",
      "11 Train Loss 4.233824 Test MSE 36.483541991492174 Test RE 0.11565275409487001\n",
      "12 Train Loss 2.3712034 Test MSE 42.137991269404 Test RE 0.1242923491050173\n",
      "13 Train Loss 0.6441808 Test MSE 1.338109344313676 Test RE 0.02214895717953429\n",
      "14 Train Loss 0.49685323 Test MSE 2.424417474327379 Test RE 0.029813377868716965\n",
      "15 Train Loss 0.31358543 Test MSE 1.169730728868175 Test RE 0.020708585302350462\n",
      "16 Train Loss 0.28982002 Test MSE 0.9653282367156598 Test RE 0.01881243388835953\n",
      "17 Train Loss 0.21498504 Test MSE 1.0644715286528428 Test RE 0.019754885039870756\n",
      "18 Train Loss 0.08684605 Test MSE 0.43524795931977733 Test RE 0.012632108683377892\n",
      "19 Train Loss 0.063728586 Test MSE 0.3348042070993672 Test RE 0.011079060529254683\n",
      "20 Train Loss 0.03222835 Test MSE 0.15326768513925595 Test RE 0.0074960552840133325\n",
      "21 Train Loss 0.011897382 Test MSE 0.054925538882510304 Test RE 0.0044873985683532925\n",
      "22 Train Loss 0.006655928 Test MSE 0.017818377193447737 Test RE 0.0025558864517461117\n",
      "23 Train Loss 0.0038323612 Test MSE 0.008735851446018825 Test RE 0.0017896170218725121\n",
      "24 Train Loss 0.0034061067 Test MSE 0.0031979404591049934 Test RE 0.0010827860914713484\n",
      "25 Train Loss 0.003230383 Test MSE 0.0027357193828085827 Test RE 0.0010014822479876468\n",
      "26 Train Loss 0.0031914576 Test MSE 0.002723810169138038 Test RE 0.0009993000295592971\n",
      "27 Train Loss 0.003190857 Test MSE 0.0027242270657919466 Test RE 0.0009993765012795922\n",
      "28 Train Loss 0.0031882303 Test MSE 0.0027351002283461127 Test RE 0.001001368912662605\n",
      "29 Train Loss 0.0031877684 Test MSE 0.0027429652317123533 Test RE 0.001002807638026119\n",
      "30 Train Loss 0.0031873374 Test MSE 0.0028211892164656965 Test RE 0.001017006173838024\n",
      "31 Train Loss 0.0031270601 Test MSE 0.0026549825916272053 Test RE 0.0009865936608978703\n",
      "32 Train Loss 0.0029882235 Test MSE 0.0021835050542804223 Test RE 0.0008947147201310051\n",
      "33 Train Loss 0.0029306521 Test MSE 0.002422555694146277 Test RE 0.0009424197238823186\n",
      "34 Train Loss 0.0026440392 Test MSE 0.0025184852668455092 Test RE 0.0009608977779020498\n",
      "35 Train Loss 0.002545254 Test MSE 0.0018512400424609814 Test RE 0.0008238323648849872\n",
      "36 Train Loss 0.002535966 Test MSE 0.0017775015176404569 Test RE 0.0008072582124124363\n",
      "37 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "38 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "39 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "40 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "41 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "42 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "43 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "44 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "45 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "46 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "47 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "48 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "49 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "50 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "51 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "52 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "53 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "54 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "55 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "56 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "57 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "58 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "59 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "60 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "61 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "62 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "63 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "64 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "65 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "66 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "67 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "68 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "69 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "70 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "71 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "72 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "73 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "74 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "75 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "76 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "77 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "78 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "79 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "80 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "81 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "82 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "83 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "84 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "85 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "86 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "87 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "88 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "89 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "90 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "91 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "92 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "93 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "94 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "95 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "96 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "97 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "98 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "99 Train Loss 0.0025344305 Test MSE 0.0017598610333453603 Test RE 0.000803242481987142\n",
      "Training time: 8.40\n",
      "Training time: 8.40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 61.673946 Test MSE 2105.2945890213005 Test RE 0.878544812847566\n",
      "1 Train Loss 51.924442 Test MSE 1748.1932412626006 Test RE 0.8005753247832299\n",
      "2 Train Loss 38.089626 Test MSE 1158.4917086844173 Test RE 0.6517093423687383\n",
      "3 Train Loss 33.700985 Test MSE 840.8364761734908 Test RE 0.5552176371146373\n",
      "4 Train Loss 27.820984 Test MSE 624.1684806945282 Test RE 0.4783639008425268\n",
      "5 Train Loss 20.6027 Test MSE 624.4216095023683 Test RE 0.4784608902079961\n",
      "6 Train Loss 18.720148 Test MSE 550.9586831961066 Test RE 0.44943511120573865\n",
      "7 Train Loss 14.965315 Test MSE 403.93769185762216 Test RE 0.3848262347763078\n",
      "8 Train Loss 11.226851 Test MSE 225.74483499689367 Test RE 0.2876844533918668\n",
      "9 Train Loss 9.448162 Test MSE 183.64560597306644 Test RE 0.2594763335121022\n",
      "10 Train Loss 5.5154614 Test MSE 89.50144705653534 Test RE 0.1811433980204387\n",
      "11 Train Loss 1.2552552 Test MSE 16.904122788276357 Test RE 0.0787233924716794\n",
      "12 Train Loss 0.8224908 Test MSE 8.777562218423514 Test RE 0.056727603919702926\n",
      "13 Train Loss 0.552025 Test MSE 2.6575044898855857 Test RE 0.031213644893395072\n",
      "14 Train Loss 0.5359099 Test MSE 1.8083278462370755 Test RE 0.02574815215006605\n",
      "15 Train Loss 0.5359099 Test MSE 1.8083278462370755 Test RE 0.02574815215006605\n",
      "16 Train Loss 0.53581893 Test MSE 1.7891348910945137 Test RE 0.025611146737335264\n",
      "17 Train Loss 0.5357785 Test MSE 1.786343391222188 Test RE 0.02559115902653161\n",
      "18 Train Loss 0.53569233 Test MSE 1.7624163977918332 Test RE 0.025419192159001507\n",
      "19 Train Loss 0.53569233 Test MSE 1.7624163977918332 Test RE 0.025419192159001507\n",
      "20 Train Loss 0.53569233 Test MSE 1.7624163977918332 Test RE 0.025419192159001507\n",
      "21 Train Loss 0.5356923 Test MSE 1.762416374116175 Test RE 0.02541919198826544\n",
      "22 Train Loss 0.5356923 Test MSE 1.762416374116175 Test RE 0.02541919198826544\n",
      "23 Train Loss 0.5356923 Test MSE 1.762416374116175 Test RE 0.02541919198826544\n",
      "24 Train Loss 0.5356923 Test MSE 1.762416374116175 Test RE 0.02541919198826544\n",
      "25 Train Loss 0.5356923 Test MSE 1.762416374116175 Test RE 0.02541919198826544\n",
      "26 Train Loss 0.5356923 Test MSE 1.762416374116175 Test RE 0.02541919198826544\n",
      "27 Train Loss 0.53547364 Test MSE 1.7228458403390148 Test RE 0.02513221064645788\n",
      "28 Train Loss 0.5174323 Test MSE 1.4820736623872992 Test RE 0.02331000553132203\n",
      "29 Train Loss 0.3669003 Test MSE 2.8313386352975756 Test RE 0.03221835699357113\n",
      "30 Train Loss 0.279477 Test MSE 1.923440154209509 Test RE 0.02655503149877649\n",
      "31 Train Loss 0.1909887 Test MSE 1.388744137773781 Test RE 0.022564130412535757\n",
      "32 Train Loss 0.17371422 Test MSE 1.381540843597965 Test RE 0.022505535247943326\n",
      "33 Train Loss 0.13991572 Test MSE 0.9474404728329034 Test RE 0.018637319409489116\n",
      "34 Train Loss 0.1205381 Test MSE 0.7563170889598788 Test RE 0.016651732993704108\n",
      "35 Train Loss 0.103147835 Test MSE 0.6518148152700817 Test RE 0.015458579916994853\n",
      "36 Train Loss 0.06718108 Test MSE 0.5490857826825705 Test RE 0.014188209128671863\n",
      "37 Train Loss 0.035156753 Test MSE 0.2613404025675087 Test RE 0.009788378617656203\n",
      "38 Train Loss 0.016610812 Test MSE 0.14787052449461915 Test RE 0.0073628895961465\n",
      "39 Train Loss 0.013960011 Test MSE 0.09727397802570514 Test RE 0.0059718077786771765\n",
      "40 Train Loss 0.013947509 Test MSE 0.09786512646331562 Test RE 0.0059899260756757534\n",
      "41 Train Loss 0.013946866 Test MSE 0.09791020724873051 Test RE 0.005991305522533544\n",
      "42 Train Loss 0.013939714 Test MSE 0.09769584084930011 Test RE 0.005984743191669902\n",
      "43 Train Loss 0.013939714 Test MSE 0.09769584084930011 Test RE 0.005984743191669902\n",
      "44 Train Loss 0.013939714 Test MSE 0.09769584084930011 Test RE 0.005984743191669902\n",
      "45 Train Loss 0.013939706 Test MSE 0.09769604508549748 Test RE 0.005984749447312631\n",
      "46 Train Loss 0.013939706 Test MSE 0.09769604508549748 Test RE 0.005984749447312631\n",
      "47 Train Loss 0.013939615 Test MSE 0.0976665651406 Test RE 0.005983846425110941\n",
      "48 Train Loss 0.013927221 Test MSE 0.09685346329692124 Test RE 0.0059588857564032175\n",
      "49 Train Loss 0.013926982 Test MSE 0.09690343334859128 Test RE 0.005960422755814442\n",
      "50 Train Loss 0.013926946 Test MSE 0.09678048291987926 Test RE 0.005956640283357536\n",
      "51 Train Loss 0.013926946 Test MSE 0.09678048291987926 Test RE 0.005956640283357536\n",
      "52 Train Loss 0.013926349 Test MSE 0.09672950753204633 Test RE 0.0059550713614378884\n",
      "53 Train Loss 0.013923881 Test MSE 0.09675992951159106 Test RE 0.005956007739703665\n",
      "54 Train Loss 0.013923839 Test MSE 0.09684576582537648 Test RE 0.005958648959166573\n",
      "55 Train Loss 0.013918555 Test MSE 0.09723637527042607 Test RE 0.005970653419943906\n",
      "56 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "57 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "58 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "59 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "60 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "61 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "62 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "63 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "64 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "65 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "66 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "67 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "68 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "69 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "70 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "71 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "72 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "73 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "74 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "75 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "76 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "77 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "78 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "79 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "80 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "81 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "82 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "83 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "84 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "85 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "86 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "87 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "88 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "89 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "90 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "91 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "92 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "93 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "94 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "95 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "96 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "97 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "98 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "99 Train Loss 0.01391447 Test MSE 0.09820878962750244 Test RE 0.006000433970657693\n",
      "Training time: 10.75\n",
      "Training time: 10.75\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 63.81464 Test MSE 2303.8639397540014 Test RE 0.9190431350879282\n",
      "1 Train Loss 60.36874 Test MSE 2137.5690019520484 Test RE 0.8852532976733091\n",
      "2 Train Loss 51.216427 Test MSE 1656.3892297182945 Test RE 0.779271298152968\n",
      "3 Train Loss 41.546265 Test MSE 1170.3334649663761 Test RE 0.655031663149047\n",
      "4 Train Loss 21.114801 Test MSE 468.43579032310134 Test RE 0.41441218498655125\n",
      "5 Train Loss 16.995068 Test MSE 312.9848019048757 Test RE 0.3387420460890352\n",
      "6 Train Loss 11.36292 Test MSE 185.18459227383573 Test RE 0.26056129656011523\n",
      "7 Train Loss 7.2032375 Test MSE 76.62930795240327 Test RE 0.16761193255158965\n",
      "8 Train Loss 4.6830173 Test MSE 85.30318952076279 Test RE 0.17684391333697208\n",
      "9 Train Loss 3.8951116 Test MSE 64.9994277533766 Test RE 0.15436976690185605\n",
      "10 Train Loss 1.4842513 Test MSE 23.081739682217123 Test RE 0.09199023983342668\n",
      "11 Train Loss 0.78336555 Test MSE 5.704696873369359 Test RE 0.0457323762700475\n",
      "12 Train Loss 0.49271607 Test MSE 1.1414159703548334 Test RE 0.020456411632811318\n",
      "13 Train Loss 0.47872642 Test MSE 2.0143362021881366 Test RE 0.02717524453868009\n",
      "14 Train Loss 0.4645348 Test MSE 1.7936747213880109 Test RE 0.025643619581190557\n",
      "15 Train Loss 0.40524083 Test MSE 1.774361109978315 Test RE 0.02550518551988378\n",
      "16 Train Loss 0.37575912 Test MSE 1.4677331916528662 Test RE 0.023196958181832494\n",
      "17 Train Loss 0.3447077 Test MSE 1.280736609751659 Test RE 0.021668926364887844\n",
      "18 Train Loss 0.3220994 Test MSE 1.3595271897538126 Test RE 0.022325512158273855\n",
      "19 Train Loss 0.30654848 Test MSE 1.0664124681032565 Test RE 0.019772887199668458\n",
      "20 Train Loss 0.28926376 Test MSE 1.1510776531934 Test RE 0.020542807338614896\n",
      "21 Train Loss 0.27321082 Test MSE 0.8995888780367013 Test RE 0.01816057188355132\n",
      "22 Train Loss 0.25050825 Test MSE 0.9143908963490766 Test RE 0.018309371158720115\n",
      "23 Train Loss 0.22370264 Test MSE 0.6832303916566631 Test RE 0.015826725502099424\n",
      "24 Train Loss 0.19356503 Test MSE 0.4265511625520283 Test RE 0.012505269245027293\n",
      "25 Train Loss 0.15979363 Test MSE 0.3999082086539044 Test RE 0.01210842458316504\n",
      "26 Train Loss 0.12935294 Test MSE 0.14769366337886855 Test RE 0.007358485072376117\n",
      "27 Train Loss 0.102955915 Test MSE 0.13428140251147117 Test RE 0.007016417387042212\n",
      "28 Train Loss 0.08566251 Test MSE 0.10676113119963582 Test RE 0.006256249572667914\n",
      "29 Train Loss 0.07421993 Test MSE 0.1405156944918223 Test RE 0.007177445424022299\n",
      "30 Train Loss 0.06887493 Test MSE 0.2087624213691533 Test RE 0.008748500974005724\n",
      "31 Train Loss 0.06558047 Test MSE 0.21372367780930646 Test RE 0.008851845013690041\n",
      "32 Train Loss 0.06378008 Test MSE 0.27898362912402247 Test RE 0.010113392010901901\n",
      "33 Train Loss 0.06246337 Test MSE 0.282920743967168 Test RE 0.01018450386894169\n",
      "34 Train Loss 0.059591312 Test MSE 0.2951068007518615 Test RE 0.010401526760922274\n",
      "35 Train Loss 0.055139787 Test MSE 0.2817375514007732 Test RE 0.01016318543498579\n",
      "36 Train Loss 0.050250906 Test MSE 0.28735873663490574 Test RE 0.010264071875814894\n",
      "37 Train Loss 0.046177346 Test MSE 0.30898795822357744 Test RE 0.010643347921194991\n",
      "38 Train Loss 0.04161462 Test MSE 0.3386986098649013 Test RE 0.011143309393631616\n",
      "39 Train Loss 0.035961635 Test MSE 0.2501344119350238 Test RE 0.009576221954898385\n",
      "40 Train Loss 0.031688746 Test MSE 0.21113524204486897 Test RE 0.008798078791737787\n",
      "41 Train Loss 0.026782146 Test MSE 0.2048057684487627 Test RE 0.008665199661381436\n",
      "42 Train Loss 0.019992564 Test MSE 0.14427572692673438 Test RE 0.007272841406936113\n",
      "43 Train Loss 0.010465307 Test MSE 0.07507604665658066 Test RE 0.005246361104339071\n",
      "44 Train Loss 0.004755394 Test MSE 0.027951361162302367 Test RE 0.003201171654531708\n",
      "45 Train Loss 0.0036091756 Test MSE 0.0076644377045491366 Test RE 0.0016762841211875412\n",
      "46 Train Loss 0.003453708 Test MSE 0.004078118528186802 Test RE 0.0012227492464662918\n",
      "47 Train Loss 0.0034533793 Test MSE 0.004046816940339052 Test RE 0.0012180476029403945\n",
      "48 Train Loss 0.0034527616 Test MSE 0.00400040244745485 Test RE 0.001211042331322509\n",
      "49 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "50 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "51 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "52 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "53 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "54 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "55 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "56 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "57 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "58 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "59 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "60 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "61 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "62 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "63 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "64 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "65 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "66 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "67 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "68 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "69 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "70 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "71 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "72 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "73 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "74 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "75 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "76 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "77 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "78 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "79 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "80 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "81 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "82 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "83 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "84 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "85 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "86 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "87 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "88 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "89 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "90 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "91 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "92 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "93 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "94 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "95 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "96 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "97 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "98 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "99 Train Loss 0.0034516011 Test MSE 0.0038589702009758226 Test RE 0.0011894417934775337\n",
      "Training time: 11.31\n",
      "Training time: 11.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 62.49294 Test MSE 2230.226873793401 Test RE 0.9042364386447408\n",
      "1 Train Loss 54.52386 Test MSE 1759.088822844898 Test RE 0.803066235020876\n",
      "2 Train Loss 47.27357 Test MSE 1572.6569272542517 Test RE 0.7593193685637128\n",
      "3 Train Loss 35.630608 Test MSE 968.0998141321138 Test RE 0.5957548000085443\n",
      "4 Train Loss 30.956495 Test MSE 764.5376766399048 Test RE 0.5294280265476197\n",
      "5 Train Loss 17.863794 Test MSE 301.2941781019485 Test RE 0.3323554859321188\n",
      "6 Train Loss 14.698981 Test MSE 229.79850358297364 Test RE 0.29025591575347337\n",
      "7 Train Loss 10.347739 Test MSE 279.352649532608 Test RE 0.32002498005283225\n",
      "8 Train Loss 8.759544 Test MSE 197.73496266771707 Test RE 0.2692459720336682\n",
      "9 Train Loss 5.777864 Test MSE 170.8647183727177 Test RE 0.25028434124982224\n",
      "10 Train Loss 3.3097048 Test MSE 83.08965220567848 Test RE 0.17453436583268225\n",
      "11 Train Loss 1.9307939 Test MSE 36.74620644511908 Test RE 0.11606833034019616\n",
      "12 Train Loss 1.8478776 Test MSE 27.522098755401565 Test RE 0.10044961029892557\n",
      "13 Train Loss 1.3550899 Test MSE 20.923979648353576 Test RE 0.08758497820816911\n",
      "14 Train Loss 0.9664652 Test MSE 7.580282588170816 Test RE 0.05271693836599191\n",
      "15 Train Loss 0.9358429 Test MSE 5.483515352164537 Test RE 0.04483704820906471\n",
      "16 Train Loss 0.91710293 Test MSE 4.973638465636581 Test RE 0.04270164329343071\n",
      "17 Train Loss 0.47995785 Test MSE 3.6307326888698372 Test RE 0.03648418249829614\n",
      "18 Train Loss 0.3824542 Test MSE 5.306246274936285 Test RE 0.04410635646949881\n",
      "19 Train Loss 0.2845695 Test MSE 2.894499519578195 Test RE 0.03257573494699284\n",
      "20 Train Loss 0.25990152 Test MSE 1.6781885400260097 Test RE 0.024804350372063837\n",
      "21 Train Loss 0.19355425 Test MSE 1.8555918458868625 Test RE 0.026082469576980145\n",
      "22 Train Loss 0.07630802 Test MSE 0.40350956896970863 Test RE 0.012162823397091876\n",
      "23 Train Loss 0.049348906 Test MSE 0.373159338021704 Test RE 0.011696465354758902\n",
      "24 Train Loss 0.038224213 Test MSE 0.2522958021279688 Test RE 0.009617506622386123\n",
      "25 Train Loss 0.03295807 Test MSE 0.20465034132170273 Test RE 0.008661911026693555\n",
      "26 Train Loss 0.030435922 Test MSE 0.16278061131797922 Test RE 0.007725183768957174\n",
      "27 Train Loss 0.028478613 Test MSE 0.14285444906081016 Test RE 0.007236929919960879\n",
      "28 Train Loss 0.025507005 Test MSE 0.12205906338823884 Test RE 0.0066894821363818815\n",
      "29 Train Loss 0.016214788 Test MSE 0.06875176403869787 Test RE 0.005020528129024307\n",
      "30 Train Loss 0.010232028 Test MSE 0.027921003160064174 Test RE 0.0031994327843355135\n",
      "31 Train Loss 0.008883121 Test MSE 0.015630522986099474 Test RE 0.0023938351325163824\n",
      "32 Train Loss 0.008240244 Test MSE 0.01186899326846296 Test RE 0.0020860005737667045\n",
      "33 Train Loss 0.0059984126 Test MSE 0.005704876972792222 Test RE 0.001446207546369042\n",
      "34 Train Loss 0.004936317 Test MSE 0.005486934317152045 Test RE 0.001418313910815422\n",
      "35 Train Loss 0.0046357685 Test MSE 0.007076483730002789 Test RE 0.0016107058574411455\n",
      "36 Train Loss 0.0044085616 Test MSE 0.0053450594594971566 Test RE 0.0013998572540668882\n",
      "37 Train Loss 0.0041389195 Test MSE 0.0041019634860410045 Test RE 0.001226318773499908\n",
      "38 Train Loss 0.0040981555 Test MSE 0.005018321357344281 Test RE 0.001356396673856379\n",
      "39 Train Loss 0.0040972442 Test MSE 0.005035622409627339 Test RE 0.0013587328034840756\n",
      "40 Train Loss 0.004096413 Test MSE 0.005043100083511105 Test RE 0.0013597412579436597\n",
      "41 Train Loss 0.0040934873 Test MSE 0.00505430861413453 Test RE 0.001361251464203527\n",
      "42 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "43 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "44 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "45 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "46 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "47 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "48 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "49 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "50 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "51 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "52 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "53 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "54 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "55 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "56 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "57 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "58 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "59 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "60 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "61 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "62 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "63 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "64 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "65 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "66 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "67 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "68 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "69 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "70 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "71 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "72 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "73 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "74 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "75 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "76 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "77 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "78 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "79 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "80 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "81 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "82 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "83 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "84 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "85 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "86 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "87 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "88 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "89 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "90 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "91 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "92 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "93 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "94 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "95 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "96 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "97 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "98 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "99 Train Loss 0.0040930184 Test MSE 0.005056501308753897 Test RE 0.0013615467058811419\n",
      "Training time: 9.69\n",
      "Training time: 9.69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 62.46157 Test MSE 2197.389148111657 Test RE 0.8975547910616404\n",
      "1 Train Loss 54.47339 Test MSE 1889.4781604336247 Test RE 0.8322971739986024\n",
      "2 Train Loss 51.224926 Test MSE 1633.1539454432652 Test RE 0.7737863138722259\n",
      "3 Train Loss 47.850525 Test MSE 1372.0547818325404 Test RE 0.709239977974643\n",
      "4 Train Loss 38.235615 Test MSE 891.9002957731225 Test RE 0.5718282878878086\n",
      "5 Train Loss 31.858114 Test MSE 732.1858186685001 Test RE 0.5181054232595572\n",
      "6 Train Loss 27.834677 Test MSE 664.3747171726905 Test RE 0.49353053773149824\n",
      "7 Train Loss 25.304846 Test MSE 563.6306582458537 Test RE 0.4545742029114768\n",
      "8 Train Loss 24.411608 Test MSE 466.0562853128881 Test RE 0.4133583038090308\n",
      "9 Train Loss 23.168274 Test MSE 366.98594477708167 Test RE 0.36680242442326616\n",
      "10 Train Loss 19.760448 Test MSE 195.37810486815442 Test RE 0.26763655321449215\n",
      "11 Train Loss 14.931923 Test MSE 244.55895291638143 Test RE 0.2994327265725936\n",
      "12 Train Loss 10.809123 Test MSE 133.01864116049683 Test RE 0.22083287946024774\n",
      "13 Train Loss 8.741237 Test MSE 100.75573968411565 Test RE 0.1921951302932555\n",
      "14 Train Loss 7.901029 Test MSE 109.92053084437242 Test RE 0.2007459953292432\n",
      "15 Train Loss 7.4722466 Test MSE 75.75535015736885 Test RE 0.16665338401740806\n",
      "16 Train Loss 5.007735 Test MSE 102.4702264291599 Test RE 0.19382345450769436\n",
      "17 Train Loss 3.9118881 Test MSE 60.76055241821137 Test RE 0.14925137424643725\n",
      "18 Train Loss 3.665091 Test MSE 60.01539378467401 Test RE 0.1483333522997395\n",
      "19 Train Loss 2.925699 Test MSE 41.115938928835206 Test RE 0.12277574778124889\n",
      "20 Train Loss 2.8524513 Test MSE 32.8914741474585 Test RE 0.10981183553582811\n",
      "21 Train Loss 2.6620328 Test MSE 23.764045890894746 Test RE 0.09333997343954203\n",
      "22 Train Loss 2.3501005 Test MSE 26.437374682493008 Test RE 0.09845020954182478\n",
      "23 Train Loss 1.7585547 Test MSE 10.909065580424425 Test RE 0.06324136833342658\n",
      "24 Train Loss 1.1755843 Test MSE 11.072349377576503 Test RE 0.06371289987462124\n",
      "25 Train Loss 1.0834222 Test MSE 10.979467636974093 Test RE 0.0634451054058678\n",
      "26 Train Loss 0.9679301 Test MSE 9.32602687666438 Test RE 0.0584730588282374\n",
      "27 Train Loss 0.530125 Test MSE 1.2537486018622477 Test RE 0.02143940422340845\n",
      "28 Train Loss 0.29905522 Test MSE 0.8021373519606665 Test RE 0.01714872562332955\n",
      "29 Train Loss 0.2679292 Test MSE 0.6496482589346808 Test RE 0.01543286727546097\n",
      "30 Train Loss 0.2224641 Test MSE 0.7656890645830068 Test RE 0.016754586118004622\n",
      "31 Train Loss 0.21186 Test MSE 0.7722431556250816 Test RE 0.016826140682347345\n",
      "32 Train Loss 0.18294054 Test MSE 0.6633362161254572 Test RE 0.015594603472433107\n",
      "33 Train Loss 0.13434319 Test MSE 0.11107863986635072 Test RE 0.006381499777281459\n",
      "34 Train Loss 0.09631253 Test MSE 0.32594557461395623 Test RE 0.010931506724351527\n",
      "35 Train Loss 0.07563048 Test MSE 0.23260244129518132 Test RE 0.009234526163173952\n",
      "36 Train Loss 0.06610912 Test MSE 0.22891139718467307 Test RE 0.009160964281828433\n",
      "37 Train Loss 0.060201574 Test MSE 0.13600826391865772 Test RE 0.007061388896261952\n",
      "38 Train Loss 0.052744295 Test MSE 0.11954084080413487 Test RE 0.006620116541109994\n",
      "39 Train Loss 0.03957854 Test MSE 0.1165882053864015 Test RE 0.0065378475652111455\n",
      "40 Train Loss 0.029310703 Test MSE 0.062398876663202006 Test RE 0.004782950292864678\n",
      "41 Train Loss 0.023975305 Test MSE 0.028225072172180295 Test RE 0.0032168070531771067\n",
      "42 Train Loss 0.022198394 Test MSE 0.009470099331006761 Test RE 0.0018633084305262504\n",
      "43 Train Loss 0.021570077 Test MSE 0.010429470640311739 Test RE 0.0019554135248914693\n",
      "44 Train Loss 0.020699829 Test MSE 0.01988439957509949 Test RE 0.002699999741698195\n",
      "45 Train Loss 0.018649211 Test MSE 0.006931206741569582 Test RE 0.0015940865897361698\n",
      "46 Train Loss 0.016198702 Test MSE 0.008012556629540877 Test RE 0.0017139298310199327\n",
      "47 Train Loss 0.015717084 Test MSE 0.007214825326574436 Test RE 0.0016263738858004562\n",
      "48 Train Loss 0.015511449 Test MSE 0.007414772586333164 Test RE 0.0016487560401733316\n",
      "49 Train Loss 0.015288307 Test MSE 0.0073812723478199 Test RE 0.001645027250900057\n",
      "50 Train Loss 0.014785346 Test MSE 0.011423022847301413 Test RE 0.0020464352337107934\n",
      "51 Train Loss 0.013048476 Test MSE 0.012602249964220618 Test RE 0.0021494706853663025\n",
      "52 Train Loss 0.012403245 Test MSE 0.005194081521317284 Test RE 0.0013799452712603092\n",
      "53 Train Loss 0.012333511 Test MSE 0.00607858873212538 Test RE 0.0014928248715493483\n",
      "54 Train Loss 0.0122469505 Test MSE 0.006530856084721307 Test RE 0.001547364178135763\n",
      "55 Train Loss 0.011644612 Test MSE 0.008617057570715314 Test RE 0.0017774073797809356\n",
      "56 Train Loss 0.010377722 Test MSE 0.009646698967868192 Test RE 0.001880601789003358\n",
      "57 Train Loss 0.008735237 Test MSE 0.005549416912563279 Test RE 0.0014263665924298314\n",
      "58 Train Loss 0.0074692313 Test MSE 0.004340676728284775 Test RE 0.0012614969454597317\n",
      "59 Train Loss 0.0065968535 Test MSE 0.005232940453208072 Test RE 0.0013850976045979692\n",
      "60 Train Loss 0.006247154 Test MSE 0.002332565059800454 Test RE 0.0009247500526970825\n",
      "61 Train Loss 0.005681278 Test MSE 0.003069986884662976 Test RE 0.0010609031571766122\n",
      "62 Train Loss 0.004926443 Test MSE 0.0014835698649732422 Test RE 0.0007374990807858004\n",
      "63 Train Loss 0.004643932 Test MSE 0.0017518735450199245 Test RE 0.0008014175690111133\n",
      "64 Train Loss 0.004637598 Test MSE 0.0017914538578641067 Test RE 0.0008104202702732584\n",
      "65 Train Loss 0.004633731 Test MSE 0.0017394247643713594 Test RE 0.0007985650633848389\n",
      "66 Train Loss 0.0045809406 Test MSE 0.001419827211900492 Test RE 0.0007214815497973455\n",
      "67 Train Loss 0.004512944 Test MSE 0.0013903834581917615 Test RE 0.0007139614746465154\n",
      "68 Train Loss 0.004425515 Test MSE 0.0014308479210209928 Test RE 0.0007242762097495808\n",
      "69 Train Loss 0.0042742467 Test MSE 0.0017995278744778582 Test RE 0.000812244484335312\n",
      "70 Train Loss 0.00416627 Test MSE 0.0018663339126913127 Test RE 0.0008271840574982234\n",
      "71 Train Loss 0.0039933864 Test MSE 0.0015632671556060369 Test RE 0.0007570491627517519\n",
      "72 Train Loss 0.0039924113 Test MSE 0.0016021508886788205 Test RE 0.0007664065174546158\n",
      "73 Train Loss 0.00389895 Test MSE 0.002460935349105445 Test RE 0.0009498555924583321\n",
      "74 Train Loss 0.0038317256 Test MSE 0.0012690748453799067 Test RE 0.0006821047906760354\n",
      "75 Train Loss 0.0037832316 Test MSE 0.0013613109656492354 Test RE 0.0007064576839817254\n",
      "76 Train Loss 0.0037593555 Test MSE 0.001887671191938318 Test RE 0.0008318991025784253\n",
      "77 Train Loss 0.0036878719 Test MSE 0.001935709891185422 Test RE 0.0008424179583498814\n",
      "78 Train Loss 0.0035831328 Test MSE 0.0015440221775982043 Test RE 0.0007523748137137969\n",
      "79 Train Loss 0.0035537153 Test MSE 0.0014512831693285367 Test RE 0.0007294298994581588\n",
      "80 Train Loss 0.003532444 Test MSE 0.0017372438938072661 Test RE 0.0007980642905697257\n",
      "81 Train Loss 0.0034977477 Test MSE 0.0016664570800179683 Test RE 0.0007816359902743598\n",
      "82 Train Loss 0.0034824712 Test MSE 0.0020810408241484554 Test RE 0.0008734695743174243\n",
      "83 Train Loss 0.003452716 Test MSE 0.0030067336453020463 Test RE 0.001049916982341443\n",
      "84 Train Loss 0.0033118848 Test MSE 0.001587497081606842 Test RE 0.0007628935613589238\n",
      "85 Train Loss 0.0030849904 Test MSE 0.0022443992403362117 Test RE 0.0009071049530035501\n",
      "86 Train Loss 0.0025557734 Test MSE 0.0025623480834150785 Test RE 0.0009692293234022031\n",
      "87 Train Loss 0.0021394081 Test MSE 0.0014136065559572006 Test RE 0.0007198993096694588\n",
      "88 Train Loss 0.002001924 Test MSE 0.0004509409522578264 Test RE 0.000406599949706582\n",
      "89 Train Loss 0.001964757 Test MSE 0.0004285240161030849 Test RE 0.00039636478713233323\n",
      "90 Train Loss 0.0019632338 Test MSE 0.00043122889434850283 Test RE 0.0003976137626197983\n",
      "91 Train Loss 0.0019582615 Test MSE 0.00044234836844114816 Test RE 0.00040270748025188793\n",
      "92 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "93 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "94 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "95 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "96 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "97 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "98 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "99 Train Loss 0.0019580992 Test MSE 0.0004423484499208878 Test RE 0.0004027075173408676\n",
      "Training time: 19.13\n",
      "Training time: 19.13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 62.614384 Test MSE 2202.5993929634765 Test RE 0.8986182602714997\n",
      "1 Train Loss 58.816128 Test MSE 1997.2031985951658 Test RE 0.8556942392958055\n",
      "2 Train Loss 47.352974 Test MSE 1532.8800807573407 Test RE 0.7496552247236619\n",
      "3 Train Loss 37.584408 Test MSE 990.4684708615862 Test RE 0.6025981714225025\n",
      "4 Train Loss 35.46915 Test MSE 899.7564855169151 Test RE 0.5743412045323985\n",
      "5 Train Loss 29.14757 Test MSE 705.5855012446257 Test RE 0.5086069680489155\n",
      "6 Train Loss 21.289717 Test MSE 508.4357969939704 Test RE 0.43174323543597953\n",
      "7 Train Loss 15.575138 Test MSE 458.52914429352273 Test RE 0.4100067004888923\n",
      "8 Train Loss 10.197163 Test MSE 268.0875190781368 Test RE 0.31350594419014366\n",
      "9 Train Loss 7.482737 Test MSE 151.5676835630028 Test RE 0.23572779206145\n",
      "10 Train Loss 3.794767 Test MSE 64.63030897677454 Test RE 0.15393082530184984\n",
      "11 Train Loss 2.949029 Test MSE 59.501671165903005 Test RE 0.1476971324496275\n",
      "12 Train Loss 2.131211 Test MSE 25.916912393242317 Test RE 0.09747631710815607\n",
      "13 Train Loss 1.6512514 Test MSE 18.762756157466267 Test RE 0.08293842789505573\n",
      "14 Train Loss 1.2167376 Test MSE 14.824064832606595 Test RE 0.07372098590799303\n",
      "15 Train Loss 0.8662376 Test MSE 11.53727990144992 Test RE 0.06503680475110145\n",
      "16 Train Loss 0.62815636 Test MSE 10.553694646100018 Test RE 0.0622027727162561\n",
      "17 Train Loss 0.6087534 Test MSE 8.57451254599565 Test RE 0.056067630407026094\n",
      "18 Train Loss 0.5709412 Test MSE 10.287153952941207 Test RE 0.06141226304503806\n",
      "19 Train Loss 0.12586841 Test MSE 0.5795690335282583 Test RE 0.0145767286142678\n",
      "20 Train Loss 0.06825027 Test MSE 0.11728461546207107 Test RE 0.006557344580588582\n",
      "21 Train Loss 0.057849612 Test MSE 0.056904790177559755 Test RE 0.004567535115745888\n",
      "22 Train Loss 0.026878837 Test MSE 0.09957444148674466 Test RE 0.0060420097442432\n",
      "23 Train Loss 0.014418842 Test MSE 0.04950573671943222 Test RE 0.004260251575266657\n",
      "24 Train Loss 0.010445662 Test MSE 0.01794946274735722 Test RE 0.0025652707475748424\n",
      "25 Train Loss 0.006654448 Test MSE 0.003390319588946201 Test RE 0.0011148791698150048\n",
      "26 Train Loss 0.0046028164 Test MSE 0.0024233906097497473 Test RE 0.0009425821088279704\n",
      "27 Train Loss 0.0039374903 Test MSE 0.001965706756775637 Test RE 0.0008489201595506574\n",
      "28 Train Loss 0.0035480713 Test MSE 0.003253714226777553 Test RE 0.0010921874576199418\n",
      "29 Train Loss 0.0021549931 Test MSE 0.0019361867860345893 Test RE 0.0008425217239104916\n",
      "30 Train Loss 0.0017088114 Test MSE 0.0013175363646609338 Test RE 0.0006950063733513889\n",
      "31 Train Loss 0.0012722908 Test MSE 0.0007831461357706055 Test RE 0.0005358322964275258\n",
      "32 Train Loss 0.00076685083 Test MSE 0.000810777474664267 Test RE 0.00054520310308526\n",
      "33 Train Loss 0.00069244456 Test MSE 0.0007163709251290019 Test RE 0.0005124794524877511\n",
      "34 Train Loss 0.0005024926 Test MSE 0.0005147520348945073 Test RE 0.00043441670564255467\n",
      "35 Train Loss 0.00040738445 Test MSE 0.000259152588464306 Test RE 0.0003082373464604526\n",
      "36 Train Loss 0.00035056268 Test MSE 0.00022313494851266142 Test RE 0.00028601662672170464\n",
      "37 Train Loss 0.00028036916 Test MSE 0.00010422382113259463 Test RE 0.0001954748900666929\n",
      "38 Train Loss 0.0002650055 Test MSE 8.870217119340527e-05 Test RE 0.0001803327505808319\n",
      "39 Train Loss 0.0002612765 Test MSE 8.874136556181249e-05 Test RE 0.00018037258752936017\n",
      "40 Train Loss 0.00024978042 Test MSE 0.00012064362266488568 Test RE 0.00021030987565090904\n",
      "41 Train Loss 0.0002483412 Test MSE 0.00011226135618614654 Test RE 0.00020287223978892325\n",
      "42 Train Loss 0.00024834074 Test MSE 0.00011225943158802767 Test RE 0.00020287050077018247\n",
      "43 Train Loss 0.00024830498 Test MSE 0.0001122442707815138 Test RE 0.00020285680132321008\n",
      "44 Train Loss 0.00024827532 Test MSE 0.00011129942425817698 Test RE 0.00020200119593574822\n",
      "45 Train Loss 0.00024395876 Test MSE 9.75630439222867e-05 Test RE 0.0001891255276111781\n",
      "46 Train Loss 0.00024349074 Test MSE 9.195815375741681e-05 Test RE 0.00018361265204268958\n",
      "47 Train Loss 0.00024144308 Test MSE 8.093827999929457e-05 Test RE 0.00017226000969066175\n",
      "48 Train Loss 0.00023571815 Test MSE 6.918356956483353e-05 Test RE 0.00015926082632812053\n",
      "49 Train Loss 0.00023484211 Test MSE 6.349775238975868e-05 Test RE 0.00015257615219765218\n",
      "50 Train Loss 0.00023165606 Test MSE 5.1440669025926146e-05 Test RE 0.00013732853463062087\n",
      "51 Train Loss 0.00023110985 Test MSE 5.0356263969933026e-05 Test RE 0.00013587333414278907\n",
      "52 Train Loss 0.0002307475 Test MSE 4.9859613174506604e-05 Test RE 0.00013520163207289326\n",
      "53 Train Loss 0.00023048016 Test MSE 5.006496202020725e-05 Test RE 0.00013547976270566147\n",
      "54 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "55 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "56 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "57 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "58 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "59 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "60 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "61 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "62 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "63 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "64 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "65 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "66 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "67 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "68 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "69 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "70 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "71 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "72 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "73 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "74 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "75 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "76 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "77 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "78 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "79 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "80 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "81 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "82 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "83 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "84 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "85 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "86 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "87 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "88 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "89 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "90 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "91 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "92 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "93 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "94 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "95 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "96 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "97 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "98 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "99 Train Loss 0.00022956297 Test MSE 4.9917569508386396e-05 Test RE 0.00013528018778854412\n",
      "Training time: 9.98\n",
      "Training time: 9.98\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 63.883278 Test MSE 2311.163599997339 Test RE 0.9204979512528301\n",
      "1 Train Loss 59.441772 Test MSE 1962.1000033569642 Test RE 0.8481409864962933\n",
      "2 Train Loss 44.94092 Test MSE 1401.8135890721874 Test RE 0.7168901522445167\n",
      "3 Train Loss 35.52311 Test MSE 908.6686129258169 Test RE 0.5771786330289832\n",
      "4 Train Loss 24.500246 Test MSE 595.4041975867711 Test RE 0.467211396522131\n",
      "5 Train Loss 14.5213995 Test MSE 392.8495404046146 Test RE 0.3795077127288057\n",
      "6 Train Loss 12.547272 Test MSE 311.4577328532328 Test RE 0.3379146656573066\n",
      "7 Train Loss 5.181452 Test MSE 98.07669340679 Test RE 0.18962272767901678\n",
      "8 Train Loss 3.5003276 Test MSE 38.176761684179105 Test RE 0.1183060692999454\n",
      "9 Train Loss 2.956514 Test MSE 36.663481117207915 Test RE 0.11593760663094309\n",
      "10 Train Loss 2.394925 Test MSE 26.488597381813214 Test RE 0.09854553756217663\n",
      "11 Train Loss 1.133334 Test MSE 11.590128252400175 Test RE 0.06518559029103173\n",
      "12 Train Loss 0.50060725 Test MSE 1.728795700401499 Test RE 0.02517557037485838\n",
      "13 Train Loss 0.24612544 Test MSE 1.7482670076450566 Test RE 0.025316948765774224\n",
      "14 Train Loss 0.21285544 Test MSE 2.36669793142808 Test RE 0.02945634768746163\n",
      "15 Train Loss 0.13406503 Test MSE 1.08105958079204 Test RE 0.019908213831400814\n",
      "16 Train Loss 0.12645191 Test MSE 0.7412398929380787 Test RE 0.016484921147156533\n",
      "17 Train Loss 0.10420498 Test MSE 0.9544220673945696 Test RE 0.018705861647058737\n",
      "18 Train Loss 0.06287369 Test MSE 0.31228191016079615 Test RE 0.010699928986829072\n",
      "19 Train Loss 0.05249175 Test MSE 0.07890939416761014 Test RE 0.005378632061438483\n",
      "20 Train Loss 0.03466597 Test MSE 0.058600840237104206 Test RE 0.004635103149154503\n",
      "21 Train Loss 0.024511348 Test MSE 0.06998136604067814 Test RE 0.005065224392421057\n",
      "22 Train Loss 0.020929717 Test MSE 0.03460968130524081 Test RE 0.0035621014312600253\n",
      "23 Train Loss 0.017426765 Test MSE 0.024417627055184885 Test RE 0.0029919836082185633\n",
      "24 Train Loss 0.017097969 Test MSE 0.02122460564165733 Test RE 0.002789505979114381\n",
      "25 Train Loss 0.01436144 Test MSE 0.014391610651207924 Test RE 0.0022970062789452457\n",
      "26 Train Loss 0.010737989 Test MSE 0.013188619006309051 Test RE 0.0021989084238897157\n",
      "27 Train Loss 0.0097974995 Test MSE 0.006078204143345343 Test RE 0.0014927776457208817\n",
      "28 Train Loss 0.009564326 Test MSE 0.0077901669169461825 Test RE 0.0016899772698301784\n",
      "29 Train Loss 0.009070782 Test MSE 0.0048593651109449555 Test RE 0.0013347417568244067\n",
      "30 Train Loss 0.0056013605 Test MSE 0.006163589689370504 Test RE 0.0015032262180747305\n",
      "31 Train Loss 0.0041474737 Test MSE 0.0025057609677378995 Test RE 0.0009584673024237476\n",
      "32 Train Loss 0.0038711294 Test MSE 0.0031844233168467147 Test RE 0.0010804952932624919\n",
      "33 Train Loss 0.0038678905 Test MSE 0.003584177577427603 Test RE 0.0011463104223379688\n",
      "34 Train Loss 0.003779801 Test MSE 0.0029484182766060735 Test RE 0.0010396856005040233\n",
      "35 Train Loss 0.00365577 Test MSE 0.0026206890127435413 Test RE 0.0009802011907101827\n",
      "36 Train Loss 0.003477839 Test MSE 0.0032030675147548906 Test RE 0.0010836537250790944\n",
      "37 Train Loss 0.0030286696 Test MSE 0.002083085937868594 Test RE 0.000873898663917462\n",
      "38 Train Loss 0.0025421097 Test MSE 0.0014152882136113393 Test RE 0.0007203273864730369\n",
      "39 Train Loss 0.0021272863 Test MSE 0.0012400284900662478 Test RE 0.0006742536613509757\n",
      "40 Train Loss 0.0017129641 Test MSE 0.0014967410196918766 Test RE 0.0007407656104848167\n",
      "41 Train Loss 0.0015934191 Test MSE 0.0016216431151450997 Test RE 0.0007710545833407193\n",
      "42 Train Loss 0.0015457572 Test MSE 0.0016625923176425402 Test RE 0.0007807290989779534\n",
      "43 Train Loss 0.0015258815 Test MSE 0.0021602264928732608 Test RE 0.0008899326197029371\n",
      "44 Train Loss 0.0015253957 Test MSE 0.002185582467716034 Test RE 0.0008951402402120121\n",
      "45 Train Loss 0.001524828 Test MSE 0.0022139303511025986 Test RE 0.0009009267018954895\n",
      "46 Train Loss 0.0015243574 Test MSE 0.0022489573369661488 Test RE 0.0009080255946684526\n",
      "47 Train Loss 0.0015239945 Test MSE 0.002269567962195549 Test RE 0.0009121769166660067\n",
      "48 Train Loss 0.0015227136 Test MSE 0.002393579296015747 Test RE 0.0009367665867101871\n",
      "49 Train Loss 0.0015225698 Test MSE 0.002412985138779484 Test RE 0.0009405563186562459\n",
      "50 Train Loss 0.0015224956 Test MSE 0.0024142832410733134 Test RE 0.0009408092779749012\n",
      "51 Train Loss 0.0015222707 Test MSE 0.002428159982299395 Test RE 0.0009435091809079224\n",
      "52 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "53 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "54 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "55 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "56 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "57 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "58 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "59 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "60 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "61 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "62 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "63 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "64 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "65 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "66 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "67 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "68 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "69 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "70 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "71 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "72 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "73 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "74 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "75 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "76 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "77 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "78 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "79 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "80 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "81 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "82 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "83 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "84 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "85 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "86 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "87 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "88 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "89 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "90 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "91 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "92 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "93 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "94 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "95 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "96 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "97 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "98 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "99 Train Loss 0.0015218689 Test MSE 0.0024667198133736163 Test RE 0.00095097126192428\n",
      "Training time: 11.16\n",
      "Training time: 11.16\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 64.33328 Test MSE 2308.8098980857662 Test RE 0.9200291117292553\n",
      "1 Train Loss 59.849285 Test MSE 2071.7505835667766 Test RE 0.8715177098516499\n",
      "2 Train Loss 47.38932 Test MSE 1686.2137003356695 Test RE 0.7862556668122097\n",
      "3 Train Loss 26.93263 Test MSE 624.0414949342926 Test RE 0.4783152373042017\n",
      "4 Train Loss 20.554377 Test MSE 460.4056440858701 Test RE 0.4108448063628879\n",
      "5 Train Loss 12.741779 Test MSE 254.1749352157116 Test RE 0.3052627712599838\n",
      "6 Train Loss 9.860437 Test MSE 211.8615990182029 Test RE 0.27869784120049035\n",
      "7 Train Loss 8.456727 Test MSE 117.3704495468466 Test RE 0.20743730704611452\n",
      "8 Train Loss 7.9967623 Test MSE 147.0915946323283 Test RE 0.23222095667940246\n",
      "9 Train Loss 5.1573453 Test MSE 96.78800063093598 Test RE 0.1883728207597805\n",
      "10 Train Loss 4.1449246 Test MSE 42.888741461201555 Test RE 0.1253946862011684\n",
      "11 Train Loss 3.8888824 Test MSE 52.612367892997085 Test RE 0.13888374089816968\n",
      "12 Train Loss 1.650902 Test MSE 18.249502873744852 Test RE 0.08179617606106124\n",
      "13 Train Loss 1.0572704 Test MSE 10.7979422312917 Test RE 0.06291844513344512\n",
      "14 Train Loss 0.9620918 Test MSE 6.655132492262725 Test RE 0.04939532357944031\n",
      "15 Train Loss 0.8504433 Test MSE 5.258680496356565 Test RE 0.043908224321134844\n",
      "16 Train Loss 0.8368745 Test MSE 5.999926247346945 Test RE 0.046900820205368676\n",
      "17 Train Loss 0.80977935 Test MSE 7.781933720049902 Test RE 0.053413525685578646\n",
      "18 Train Loss 0.71818507 Test MSE 6.975481089234123 Test RE 0.050570187585761275\n",
      "19 Train Loss 0.6860273 Test MSE 5.788595268587365 Test RE 0.04606743952850967\n",
      "20 Train Loss 0.68455726 Test MSE 5.478623370185392 Test RE 0.044817043617145426\n",
      "21 Train Loss 0.6771842 Test MSE 5.4162545073177295 Test RE 0.04456121395007864\n",
      "22 Train Loss 0.62825876 Test MSE 4.932308857615093 Test RE 0.04252385354795541\n",
      "23 Train Loss 0.62106454 Test MSE 4.417553357879678 Test RE 0.040243744559249645\n",
      "24 Train Loss 0.6170155 Test MSE 3.953625337440304 Test RE 0.038071960169566696\n",
      "25 Train Loss 0.5966823 Test MSE 4.642358321793822 Test RE 0.04125502086147737\n",
      "26 Train Loss 0.58621925 Test MSE 5.100463889570758 Test RE 0.04324265197151474\n",
      "27 Train Loss 0.53385 Test MSE 3.3014798127873908 Test RE 0.03479059087973509\n",
      "28 Train Loss 0.45382735 Test MSE 3.413197074810975 Test RE 0.035374325211692134\n",
      "29 Train Loss 0.40437707 Test MSE 2.1184876319291464 Test RE 0.027868939849308175\n",
      "30 Train Loss 0.39741984 Test MSE 2.0718611790804973 Test RE 0.02756054544092423\n",
      "31 Train Loss 0.37927505 Test MSE 1.9709056701808287 Test RE 0.026880689308565024\n",
      "32 Train Loss 0.37563816 Test MSE 2.023440152595654 Test RE 0.027236585632080864\n",
      "33 Train Loss 0.36085472 Test MSE 2.0832588132748526 Test RE 0.027636248917039617\n",
      "34 Train Loss 0.3438796 Test MSE 2.317773568046492 Test RE 0.02915029705010558\n",
      "35 Train Loss 0.33166814 Test MSE 2.8582012737811433 Test RE 0.03237083380006981\n",
      "36 Train Loss 0.27828887 Test MSE 2.691885492253958 Test RE 0.03141490659058766\n",
      "37 Train Loss 0.19667222 Test MSE 2.68866719224242 Test RE 0.03139612183338565\n",
      "38 Train Loss 0.16012351 Test MSE 2.1676317027668413 Test RE 0.02819033448234564\n",
      "39 Train Loss 0.14256153 Test MSE 1.413132151773987 Test RE 0.022761394739279257\n",
      "40 Train Loss 0.121781364 Test MSE 1.697177679716408 Test RE 0.02494428946082301\n",
      "41 Train Loss 0.086688 Test MSE 1.2830690128022397 Test RE 0.021688648484201076\n",
      "42 Train Loss 0.04120293 Test MSE 0.12807703025863337 Test RE 0.006852406309028582\n",
      "43 Train Loss 0.0386317 Test MSE 0.05645974826356478 Test RE 0.004549639130079964\n",
      "44 Train Loss 0.036174487 Test MSE 0.07294550763327298 Test RE 0.00517138364074759\n",
      "45 Train Loss 0.034349095 Test MSE 0.0761944352302985 Test RE 0.005285293495443837\n",
      "46 Train Loss 0.031532265 Test MSE 0.0434833304201989 Test RE 0.003992720242463354\n",
      "47 Train Loss 0.030634904 Test MSE 0.0433015199017293 Test RE 0.003984364409145021\n",
      "48 Train Loss 0.029998237 Test MSE 0.03210739613603455 Test RE 0.003430915523666633\n",
      "49 Train Loss 0.02960775 Test MSE 0.03404811395891457 Test RE 0.0035330843961015415\n",
      "50 Train Loss 0.029390268 Test MSE 0.03928326952076889 Test RE 0.0037949957608865385\n",
      "51 Train Loss 0.029327158 Test MSE 0.03881383179578137 Test RE 0.003772252382569451\n",
      "52 Train Loss 0.029327158 Test MSE 0.03881383179578137 Test RE 0.003772252382569451\n",
      "53 Train Loss 0.029327158 Test MSE 0.03881383179578137 Test RE 0.003772252382569451\n",
      "54 Train Loss 0.029325262 Test MSE 0.03804913659131029 Test RE 0.003734907796694787\n",
      "55 Train Loss 0.029274002 Test MSE 0.03450150760964227 Test RE 0.0035565303421913504\n",
      "56 Train Loss 0.029274002 Test MSE 0.03450150760964227 Test RE 0.0035565303421913504\n",
      "57 Train Loss 0.02926438 Test MSE 0.03367312990225456 Test RE 0.0035135749702640824\n",
      "58 Train Loss 0.02926438 Test MSE 0.03367312990225456 Test RE 0.0035135749702640824\n",
      "59 Train Loss 0.02926438 Test MSE 0.03367312990225456 Test RE 0.0035135749702640824\n",
      "60 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "61 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "62 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "63 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "64 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "65 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "66 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "67 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "68 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "69 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "70 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "71 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "72 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "73 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "74 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "75 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "76 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "77 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "78 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "79 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "80 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "81 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "82 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "83 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "84 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "85 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "86 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "87 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "88 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "89 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "90 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "91 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "92 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "93 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "94 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "95 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "96 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "97 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "98 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "99 Train Loss 0.029256083 Test MSE 0.033638198444699056 Test RE 0.003511752060691914\n",
      "Training time: 12.91\n",
      "Training time: 12.91\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 63.909763 Test MSE 2272.9830437840437 Test RE 0.912862947589067\n",
      "1 Train Loss 50.426983 Test MSE 1509.7613619456492 Test RE 0.7439806411994585\n",
      "2 Train Loss 47.001774 Test MSE 1347.279833368652 Test RE 0.702807498273582\n",
      "3 Train Loss 39.380604 Test MSE 1204.576569414163 Test RE 0.6645454478777294\n",
      "4 Train Loss 23.733027 Test MSE 693.2337248619592 Test RE 0.5041355493253934\n",
      "5 Train Loss 18.52578 Test MSE 474.9351061632677 Test RE 0.4172771641395177\n",
      "6 Train Loss 9.161597 Test MSE 101.93863867844703 Test RE 0.1933200490118066\n",
      "7 Train Loss 5.2759194 Test MSE 19.67014486446152 Test RE 0.08492024940084388\n",
      "8 Train Loss 4.4301796 Test MSE 11.245501325928366 Test RE 0.0642091457961137\n",
      "9 Train Loss 3.3400824 Test MSE 37.67513345329971 Test RE 0.11752625066304048\n",
      "10 Train Loss 2.3330324 Test MSE 48.87816918387903 Test RE 0.1338643541233201\n",
      "11 Train Loss 1.8045777 Test MSE 29.135942565542837 Test RE 0.1033527455190619\n",
      "12 Train Loss 1.0872238 Test MSE 14.084652170269575 Test RE 0.0718588967036558\n",
      "13 Train Loss 0.7723627 Test MSE 9.383904747431268 Test RE 0.05865422180536213\n",
      "14 Train Loss 0.5037282 Test MSE 1.6352041640262447 Test RE 0.024484625964349915\n",
      "15 Train Loss 0.49627522 Test MSE 1.0072798457022925 Test RE 0.019216865654018322\n",
      "16 Train Loss 0.35702783 Test MSE 0.5984082637964909 Test RE 0.014811746580920639\n",
      "17 Train Loss 0.16034245 Test MSE 1.8449850182004004 Test RE 0.026007817184811974\n",
      "18 Train Loss 0.055351935 Test MSE 0.06422134938561327 Test RE 0.004852294985206132\n",
      "19 Train Loss 0.03450992 Test MSE 0.1060049325018251 Test RE 0.0062340534091598915\n",
      "20 Train Loss 0.025841942 Test MSE 0.05416642534523228 Test RE 0.004456281013187031\n",
      "21 Train Loss 0.02560683 Test MSE 0.05757205725991019 Test RE 0.004594236587428037\n",
      "22 Train Loss 0.024471456 Test MSE 0.07735220447623692 Test RE 0.005325296943020658\n",
      "23 Train Loss 0.018468246 Test MSE 0.0551637001778825 Test RE 0.004497116894880238\n",
      "24 Train Loss 0.016433192 Test MSE 0.07755256013386402 Test RE 0.005332189205322327\n",
      "25 Train Loss 0.016284635 Test MSE 0.07831278202671091 Test RE 0.005358260306137579\n",
      "26 Train Loss 0.016229276 Test MSE 0.08656943323643969 Test RE 0.005633648789538525\n",
      "27 Train Loss 0.015962057 Test MSE 0.09826442373168437 Test RE 0.006002133317049252\n",
      "28 Train Loss 0.006158286 Test MSE 0.03973057348971348 Test RE 0.0038165407055444855\n",
      "29 Train Loss 0.004252517 Test MSE 0.005555594967967229 Test RE 0.0014271603443440928\n",
      "30 Train Loss 0.0028430056 Test MSE 0.00518057959779688 Test RE 0.0013781505324276752\n",
      "31 Train Loss 0.002395748 Test MSE 0.00455685837012098 Test RE 0.0012925288545537323\n",
      "32 Train Loss 0.0018401507 Test MSE 0.009129812709194041 Test RE 0.0018295252847890084\n",
      "33 Train Loss 0.0009125937 Test MSE 0.0011497662096120716 Test RE 0.0006492504395243473\n",
      "34 Train Loss 0.0008034096 Test MSE 0.001644933446274279 Test RE 0.0007765718564963377\n",
      "35 Train Loss 0.0007565751 Test MSE 0.0011067925077705458 Test RE 0.000637001693722825\n",
      "36 Train Loss 0.0007561842 Test MSE 0.0011186897803740345 Test RE 0.000640416211491334\n",
      "37 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "38 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "39 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "40 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "41 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "42 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "43 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "44 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "45 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "46 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "47 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "48 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "49 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "50 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "51 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "52 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "53 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "54 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "55 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "56 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "57 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "58 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "59 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "60 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "61 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "62 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "63 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "64 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "65 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "66 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "67 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "68 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "69 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "70 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "71 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "72 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "73 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "74 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "75 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "76 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "77 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "78 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "79 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "80 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "81 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "82 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "83 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "84 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "85 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "86 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "87 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "88 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "89 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "90 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "91 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "92 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "93 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "94 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "95 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "96 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "97 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "98 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "99 Train Loss 0.0007560171 Test MSE 0.0011306152531330843 Test RE 0.0006438206495514049\n",
      "Training time: 8.40\n",
      "Training time: 8.40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 59.817352 Test MSE 2064.4406486586236 Test RE 0.8699788259431132\n",
      "1 Train Loss 58.152138 Test MSE 1985.9723227798254 Test RE 0.8532849340930415\n",
      "2 Train Loss 56.643375 Test MSE 1780.6901702439238 Test RE 0.8079819565577551\n",
      "3 Train Loss 50.497242 Test MSE 1677.854003670085 Test RE 0.784304245811038\n",
      "4 Train Loss 49.742947 Test MSE 1676.638491334525 Test RE 0.7840201018375251\n",
      "5 Train Loss 48.171005 Test MSE 1535.019013771457 Test RE 0.7501780651480656\n",
      "6 Train Loss 45.366974 Test MSE 1316.0198579727441 Test RE 0.6946062761304683\n",
      "7 Train Loss 41.67636 Test MSE 1217.124950712808 Test RE 0.6679978497317042\n",
      "8 Train Loss 39.290985 Test MSE 1024.0375593084318 Test RE 0.6127247519886085\n",
      "9 Train Loss 32.392033 Test MSE 664.9658178927547 Test RE 0.493750038406048\n",
      "10 Train Loss 30.10866 Test MSE 582.6535534715604 Test RE 0.46218163171883603\n",
      "11 Train Loss 27.401838 Test MSE 594.6425795123217 Test RE 0.46691248150642656\n",
      "12 Train Loss 22.0841 Test MSE 665.973440143072 Test RE 0.4941239863471259\n",
      "13 Train Loss 17.552206 Test MSE 479.6781921960773 Test RE 0.41935562134167825\n",
      "14 Train Loss 12.639434 Test MSE 241.0199848295805 Test RE 0.29725831328390645\n",
      "15 Train Loss 7.917898 Test MSE 106.26286459709168 Test RE 0.19737777158033898\n",
      "16 Train Loss 4.327124 Test MSE 81.91041652252602 Test RE 0.1732914154094097\n",
      "17 Train Loss 2.9210942 Test MSE 34.50554416737387 Test RE 0.11247394344322575\n",
      "18 Train Loss 1.18696 Test MSE 10.204568311818402 Test RE 0.06116525637560453\n",
      "19 Train Loss 0.69313884 Test MSE 8.61594450325345 Test RE 0.05620292627634752\n",
      "20 Train Loss 0.23227744 Test MSE 0.9052116319162693 Test RE 0.018217238526155272\n",
      "21 Train Loss 0.10863343 Test MSE 0.08220614729000181 Test RE 0.005489839266463868\n",
      "22 Train Loss 0.07884781 Test MSE 0.09962028010630451 Test RE 0.006043400289423467\n",
      "23 Train Loss 0.04380409 Test MSE 0.021350330205024966 Test RE 0.00279775563991739\n",
      "24 Train Loss 0.031213488 Test MSE 0.050058726248763695 Test RE 0.004283979452625491\n",
      "25 Train Loss 0.024318691 Test MSE 0.047953189277868576 Test RE 0.004192916657952654\n",
      "26 Train Loss 0.020431262 Test MSE 0.01822505331412861 Test RE 0.0025848889231873794\n",
      "27 Train Loss 0.014717229 Test MSE 0.020665985073371924 Test RE 0.0027525520332434515\n",
      "28 Train Loss 0.011993365 Test MSE 0.004913479556061929 Test RE 0.0013421530989198318\n",
      "29 Train Loss 0.011258896 Test MSE 0.004827052454642508 Test RE 0.0013302966300055303\n",
      "30 Train Loss 0.009622024 Test MSE 0.003243381751826886 Test RE 0.0010904519067759576\n",
      "31 Train Loss 0.008154274 Test MSE 0.00634007297353501 Test RE 0.0015245954175225564\n",
      "32 Train Loss 0.0068109767 Test MSE 0.002875479390824072 Test RE 0.0010267450349683137\n",
      "33 Train Loss 0.00569278 Test MSE 0.0028904717978517377 Test RE 0.0010294182182387492\n",
      "34 Train Loss 0.0053350106 Test MSE 0.00206997082098524 Test RE 0.0008711432854671969\n",
      "35 Train Loss 0.0047244458 Test MSE 0.0006070698743305698 Test RE 0.00047176620028760446\n",
      "36 Train Loss 0.0039611906 Test MSE 0.002093676581818568 Test RE 0.0008761173471898607\n",
      "37 Train Loss 0.0027810126 Test MSE 0.001502027212804889 Test RE 0.0007420725762941719\n",
      "38 Train Loss 0.0022400264 Test MSE 0.0025122110111537393 Test RE 0.0009597000980804975\n",
      "39 Train Loss 0.0018380522 Test MSE 0.0018863205230644422 Test RE 0.0008316014285729267\n",
      "40 Train Loss 0.0017025193 Test MSE 0.0013054493661320485 Test RE 0.0006918110549388687\n",
      "41 Train Loss 0.0016112607 Test MSE 0.0009229415253606157 Test RE 0.0005816939876342296\n",
      "42 Train Loss 0.0014461809 Test MSE 0.0007228217888851462 Test RE 0.0005147816997667504\n",
      "43 Train Loss 0.0011872512 Test MSE 0.0005344547139265531 Test RE 0.00044265251670297997\n",
      "44 Train Loss 0.00109753 Test MSE 0.00029273155365166045 Test RE 0.0003275987610651585\n",
      "45 Train Loss 0.0010234225 Test MSE 0.00031500843380648957 Test RE 0.00033983536555854847\n",
      "46 Train Loss 0.0009149735 Test MSE 0.000206534493939425 Test RE 0.00027517170780274697\n",
      "47 Train Loss 0.0008294939 Test MSE 0.00016086209928507653 Test RE 0.00024284789747729599\n",
      "48 Train Loss 0.0007924448 Test MSE 0.00015348599282997 Test RE 0.00023721484052929465\n",
      "49 Train Loss 0.00075477007 Test MSE 0.00013309116200624946 Test RE 0.00022089306953897815\n",
      "50 Train Loss 0.0006911053 Test MSE 0.00024413728565721824 Test RE 0.0002991744750401732\n",
      "51 Train Loss 0.00054436986 Test MSE 0.00012948232862208394 Test RE 0.00021787767508141628\n",
      "52 Train Loss 0.00048382024 Test MSE 0.00034063395133717317 Test RE 0.00035338771510817524\n",
      "53 Train Loss 0.0003804855 Test MSE 0.0001755814450710828 Test RE 0.00025371537809261674\n",
      "54 Train Loss 0.00034439238 Test MSE 8.73387678698826e-05 Test RE 0.00017894147471910808\n",
      "55 Train Loss 0.00033362926 Test MSE 8.079833113301929e-05 Test RE 0.00017211101947813687\n",
      "56 Train Loss 0.00033275125 Test MSE 8.145351883222297e-05 Test RE 0.00017280742831885028\n",
      "57 Train Loss 0.00031824445 Test MSE 5.644938376892652e-05 Test RE 0.0001438590156831961\n",
      "58 Train Loss 0.0002817937 Test MSE 4.3000594468297506e-05 Test RE 0.00012555809318651296\n",
      "59 Train Loss 0.00024463522 Test MSE 2.5610723485621202e-05 Test RE 9.689880147411207e-05\n",
      "60 Train Loss 0.00013095308 Test MSE 6.610443135863627e-05 Test RE 0.00015567639591632676\n",
      "61 Train Loss 0.00010221784 Test MSE 1.693351578720027e-05 Test RE 7.879180511957048e-05\n",
      "62 Train Loss 0.000101246944 Test MSE 1.3367226978227853e-05 Test RE 7.000485220302686e-05\n",
      "63 Train Loss 0.00010043064 Test MSE 1.1721624196663122e-05 Test RE 6.55543293202928e-05\n",
      "64 Train Loss 9.9742996e-05 Test MSE 1.167394679757584e-05 Test RE 6.542087321685334e-05\n",
      "65 Train Loss 9.919036e-05 Test MSE 1.227567591142961e-05 Test RE 6.708573600957478e-05\n",
      "66 Train Loss 9.8853816e-05 Test MSE 1.349274353526715e-05 Test RE 7.033275258420569e-05\n",
      "67 Train Loss 9.856832e-05 Test MSE 1.5104312111791776e-05 Test RE 7.441456671465072e-05\n",
      "68 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "69 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "70 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "71 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "72 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "73 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "74 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "75 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "76 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "77 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "78 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "79 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "80 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "81 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "82 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "83 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "84 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "85 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "86 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "87 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "88 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "89 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "90 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "91 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "92 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "93 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "94 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "95 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "96 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "97 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "98 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "99 Train Loss 9.833993e-05 Test MSE 1.6354735928582718e-05 Test RE 7.743356419163249e-05\n",
      "Training time: 12.57\n",
      "Training time: 12.57\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 63.24228 Test MSE 2229.0352205332456 Test RE 0.9039948308764233\n",
      "1 Train Loss 56.647167 Test MSE 1818.9785599450624 Test RE 0.816622368728403\n",
      "2 Train Loss 35.96185 Test MSE 959.6758720488139 Test RE 0.5931571499574113\n",
      "3 Train Loss 20.72721 Test MSE 588.4843502026672 Test RE 0.4644884729902462\n",
      "4 Train Loss 17.053198 Test MSE 359.8020656264069 Test RE 0.3631945374070289\n",
      "5 Train Loss 16.534847 Test MSE 334.1432289160465 Test RE 0.3500046500448896\n",
      "6 Train Loss 16.428057 Test MSE 320.9567426132547 Test RE 0.3430289181483311\n",
      "7 Train Loss 16.357279 Test MSE 303.2827890599498 Test RE 0.33345049344950795\n",
      "8 Train Loss 15.937162 Test MSE 293.26377296906367 Test RE 0.32789643176335653\n",
      "9 Train Loss 15.514321 Test MSE 295.3131516375227 Test RE 0.32904013602093396\n",
      "10 Train Loss 14.787113 Test MSE 258.6446436393756 Test RE 0.3079351222763024\n",
      "11 Train Loss 9.390105 Test MSE 144.85653481621964 Test RE 0.2304499020083658\n",
      "12 Train Loss 6.198739 Test MSE 117.46686808925202 Test RE 0.2075224932958867\n",
      "13 Train Loss 5.6909676 Test MSE 118.09988965358662 Test RE 0.2080809048279175\n",
      "14 Train Loss 4.676273 Test MSE 85.04430460388797 Test RE 0.17657535942500835\n",
      "15 Train Loss 4.084526 Test MSE 66.856761645582 Test RE 0.15655976117712841\n",
      "16 Train Loss 3.4012382 Test MSE 55.913482959612864 Test RE 0.14317452628437735\n",
      "17 Train Loss 2.708783 Test MSE 49.69917983250624 Test RE 0.13498393757936547\n",
      "18 Train Loss 2.0379472 Test MSE 31.927163642527542 Test RE 0.10819013205809859\n",
      "19 Train Loss 1.6063066 Test MSE 20.365810367736554 Test RE 0.08640887076310542\n",
      "20 Train Loss 1.3731107 Test MSE 13.650799736536372 Test RE 0.07074349787695847\n",
      "21 Train Loss 0.74081355 Test MSE 6.767934421512483 Test RE 0.04981218045366364\n",
      "22 Train Loss 0.495481 Test MSE 4.663530533922241 Test RE 0.041348988880397494\n",
      "23 Train Loss 0.30719596 Test MSE 1.7954146756459133 Test RE 0.025656054363593507\n",
      "24 Train Loss 0.23675413 Test MSE 0.5344019600747857 Test RE 0.013997210792844413\n",
      "25 Train Loss 0.22118175 Test MSE 0.7269771452187477 Test RE 0.016325551475559436\n",
      "26 Train Loss 0.19780134 Test MSE 0.8873578636250679 Test RE 0.018036691739781337\n",
      "27 Train Loss 0.16242905 Test MSE 0.32759131906870237 Test RE 0.010959069323804665\n",
      "28 Train Loss 0.11264059 Test MSE 0.22074829940790106 Test RE 0.00899613916427738\n",
      "29 Train Loss 0.059639115 Test MSE 0.16662856502069218 Test RE 0.00781595785471618\n",
      "30 Train Loss 0.04950194 Test MSE 0.13134577299555966 Test RE 0.006939297904247719\n",
      "31 Train Loss 0.04627045 Test MSE 0.15249971634786216 Test RE 0.007477251692556857\n",
      "32 Train Loss 0.045629088 Test MSE 0.15534682387133897 Test RE 0.007546727540805977\n",
      "33 Train Loss 0.0456111 Test MSE 0.15648573083619102 Test RE 0.007574340994632631\n",
      "34 Train Loss 0.045605976 Test MSE 0.15619192622002415 Test RE 0.007567227177085357\n",
      "35 Train Loss 0.04559072 Test MSE 0.15765074443730986 Test RE 0.007602483648095434\n",
      "36 Train Loss 0.04558804 Test MSE 0.1581367436739696 Test RE 0.007614192942898365\n",
      "37 Train Loss 0.04558804 Test MSE 0.1581367436739696 Test RE 0.007614192942898365\n",
      "38 Train Loss 0.04558804 Test MSE 0.1581367436739696 Test RE 0.007614192942898365\n",
      "39 Train Loss 0.04558804 Test MSE 0.1581367436739696 Test RE 0.007614192942898365\n",
      "40 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "41 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "42 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "43 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "44 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "45 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "46 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "47 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "48 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "49 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "50 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "51 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "52 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "53 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "54 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "55 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "56 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "57 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "58 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "59 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "60 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "61 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "62 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "63 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "64 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "65 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "66 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "67 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "68 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "69 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "70 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "71 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "72 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "73 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "74 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "75 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "76 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "77 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "78 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "79 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "80 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "81 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "82 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "83 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "84 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "85 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "86 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "87 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "88 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "89 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "90 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "91 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "92 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "93 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "94 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "95 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "96 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "97 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "98 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "99 Train Loss 0.045574803 Test MSE 0.1581884643285681 Test RE 0.00761543800093839\n",
      "Training time: 10.61\n",
      "Training time: 10.61\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 61.383717 Test MSE 2038.9658054411302 Test RE 0.8645944691875456\n",
      "1 Train Loss 50.32254 Test MSE 1655.0789561266156 Test RE 0.7789630189787898\n",
      "2 Train Loss 43.396194 Test MSE 1239.9204784151543 Test RE 0.6742242955590768\n",
      "3 Train Loss 31.931063 Test MSE 870.8498980224472 Test RE 0.5650399234950106\n",
      "4 Train Loss 12.157813 Test MSE 292.0067841256645 Test RE 0.3271929613784324\n",
      "5 Train Loss 5.4384108 Test MSE 92.89697761878233 Test RE 0.1845475457747336\n",
      "6 Train Loss 3.352215 Test MSE 44.93334455818175 Test RE 0.1283488124674417\n",
      "7 Train Loss 1.7435788 Test MSE 12.273973400140711 Test RE 0.0670810837939222\n",
      "8 Train Loss 1.4230653 Test MSE 15.945032402080047 Test RE 0.07645751609841767\n",
      "9 Train Loss 0.5498397 Test MSE 8.826008955857917 Test RE 0.056883939215746845\n",
      "10 Train Loss 0.24816936 Test MSE 0.40132339480063417 Test RE 0.012129830172357768\n",
      "11 Train Loss 0.15264864 Test MSE 0.5910885169271034 Test RE 0.014720878999921578\n",
      "12 Train Loss 0.06152185 Test MSE 0.19949839658322296 Test RE 0.008552186961689606\n",
      "13 Train Loss 0.040066555 Test MSE 0.09281092814432249 Test RE 0.0058332023177289204\n",
      "14 Train Loss 0.034023367 Test MSE 0.08966407669511603 Test RE 0.005733459144459118\n",
      "15 Train Loss 0.028684225 Test MSE 0.15004300924670377 Test RE 0.007416779448206383\n",
      "16 Train Loss 0.012970137 Test MSE 0.0192203598616568 Test RE 0.0026545336750977326\n",
      "17 Train Loss 0.010905832 Test MSE 0.01859581583742178 Test RE 0.002611049468930622\n",
      "18 Train Loss 0.01071184 Test MSE 0.014799612921958612 Test RE 0.0023293387963794136\n",
      "19 Train Loss 0.010436443 Test MSE 0.022742073223350385 Test RE 0.0028875034283165767\n",
      "20 Train Loss 0.010069054 Test MSE 0.022184979908698804 Test RE 0.002851917785794568\n",
      "21 Train Loss 0.009703915 Test MSE 0.025768248707595514 Test RE 0.0030736183019073144\n",
      "22 Train Loss 0.009522318 Test MSE 0.02879397038037787 Test RE 0.0032490639432298713\n",
      "23 Train Loss 0.009479734 Test MSE 0.030104714077655102 Test RE 0.003322192054246741\n",
      "24 Train Loss 0.009404487 Test MSE 0.03396234203350677 Test RE 0.003528631424902811\n",
      "25 Train Loss 0.008044374 Test MSE 0.03183019302953499 Test RE 0.003416072804550157\n",
      "26 Train Loss 0.0073868735 Test MSE 0.021383177198148876 Test RE 0.002799906954226359\n",
      "27 Train Loss 0.007201839 Test MSE 0.02466058698066305 Test RE 0.0030068321595588844\n",
      "28 Train Loss 0.005849191 Test MSE 0.010412924969674378 Test RE 0.001953861841628997\n",
      "29 Train Loss 0.0050848606 Test MSE 0.005318142260377357 Test RE 0.0013963280328244767\n",
      "30 Train Loss 0.0047388086 Test MSE 0.005885788040920299 Test RE 0.001468959394029945\n",
      "31 Train Loss 0.004659118 Test MSE 0.007134690189275806 Test RE 0.001617316590171969\n",
      "32 Train Loss 0.0044583473 Test MSE 0.004947418765841032 Test RE 0.0013467804943453252\n",
      "33 Train Loss 0.004319456 Test MSE 0.004010137079151879 Test RE 0.0012125149191464521\n",
      "34 Train Loss 0.004279206 Test MSE 0.0049257095602257 Test RE 0.0013438224186200303\n",
      "35 Train Loss 0.0042549297 Test MSE 0.00439702914569917 Test RE 0.0012696591708368204\n",
      "36 Train Loss 0.0042525176 Test MSE 0.0042507108888823015 Test RE 0.001248355461277875\n",
      "37 Train Loss 0.0042517283 Test MSE 0.004208032927223002 Test RE 0.0012420727862142882\n",
      "38 Train Loss 0.0042513874 Test MSE 0.004156658765134614 Test RE 0.0012344675218639767\n",
      "39 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "40 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "41 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "42 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "43 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "44 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "45 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "46 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "47 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "48 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "49 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "50 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "51 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "52 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "53 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "54 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "55 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "56 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "57 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "58 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "59 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "60 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "61 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "62 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "63 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "64 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "65 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "66 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "67 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "68 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "69 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "70 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "71 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "72 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "73 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "74 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "75 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "76 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "77 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "78 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "79 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "80 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "81 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "82 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "83 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "84 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "85 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "86 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "87 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "88 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "89 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "90 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "91 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "92 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "93 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "94 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "95 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "96 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "97 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "98 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "99 Train Loss 0.00425058 Test MSE 0.004095992253602127 Test RE 0.0012254258716860968\n",
      "Training time: 8.60\n",
      "Training time: 8.60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 64.8157 Test MSE 2357.339990055418 Test RE 0.9296481162329217\n",
      "1 Train Loss 60.745842 Test MSE 2037.3607645316317 Test RE 0.8642541047997204\n",
      "2 Train Loss 40.350754 Test MSE 1366.110782603196 Test RE 0.7077020300442242\n",
      "3 Train Loss 15.719641 Test MSE 243.07753786786543 Test RE 0.2985244426260327\n",
      "4 Train Loss 12.977665 Test MSE 257.9017109702048 Test RE 0.307492546742471\n",
      "5 Train Loss 7.497563 Test MSE 103.41767542997525 Test RE 0.1947174473913109\n",
      "6 Train Loss 5.372981 Test MSE 105.82082622212421 Test RE 0.19696681204930355\n",
      "7 Train Loss 2.8029664 Test MSE 51.87652259027019 Test RE 0.13790909549369174\n",
      "8 Train Loss 0.7322954 Test MSE 19.46888749860132 Test RE 0.08448469674990725\n",
      "9 Train Loss 0.43770322 Test MSE 10.047180809025411 Test RE 0.06069174028861897\n",
      "10 Train Loss 0.3680767 Test MSE 5.406482075562914 Test RE 0.044520995379571035\n",
      "11 Train Loss 0.18767579 Test MSE 0.49685478654696097 Test RE 0.013496532996432605\n",
      "12 Train Loss 0.00717994 Test MSE 0.019961329426512527 Test RE 0.002705217652989449\n",
      "13 Train Loss 0.0041859783 Test MSE 0.0181534069379621 Test RE 0.0025798030589040764\n",
      "14 Train Loss 0.0041125813 Test MSE 0.01711176918832338 Test RE 0.002504695517807661\n",
      "15 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "16 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "17 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "18 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "19 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "20 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "21 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "22 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "23 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "24 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "25 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "26 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "27 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "28 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "29 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "30 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "31 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "32 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "33 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "34 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "35 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "36 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "37 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "38 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "39 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "40 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "41 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "42 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "43 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "44 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "45 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "46 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "47 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "48 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "49 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "50 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "51 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "52 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "53 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "54 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "55 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "56 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "57 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "58 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "59 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "60 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "61 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "62 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "63 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "64 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "65 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "66 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "67 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "68 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "69 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "70 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "71 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "72 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "73 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "74 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "75 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "76 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "77 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "78 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "79 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "80 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "81 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "82 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "83 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "84 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "85 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "86 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "87 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "88 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "89 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "90 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "91 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "92 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "93 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "94 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "95 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "96 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "97 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "98 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "99 Train Loss 0.0041117063 Test MSE 0.01760097136851279 Test RE 0.0025402461394501102\n",
      "Training time: 4.78\n",
      "Training time: 4.78\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 62.305126 Test MSE 2212.4908836335258 Test RE 0.9006337691149624\n",
      "1 Train Loss 42.952473 Test MSE 1411.4650196023683 Test RE 0.7193537990131093\n",
      "2 Train Loss 37.25311 Test MSE 974.0251966269925 Test RE 0.5975752166158504\n",
      "3 Train Loss 31.458786 Test MSE 775.901679815258 Test RE 0.533348192766241\n",
      "4 Train Loss 26.939243 Test MSE 625.0468267948477 Test RE 0.4787003655676281\n",
      "5 Train Loss 23.071556 Test MSE 477.3608490480936 Test RE 0.41834143367938936\n",
      "6 Train Loss 16.42905 Test MSE 394.1807965849158 Test RE 0.38015019114118814\n",
      "7 Train Loss 6.031757 Test MSE 165.23137532959893 Test RE 0.2461238730906621\n",
      "8 Train Loss 3.6738942 Test MSE 56.77518992009111 Test RE 0.14427357040469196\n",
      "9 Train Loss 2.722429 Test MSE 32.26845717873627 Test RE 0.10876685785790388\n",
      "10 Train Loss 2.2924063 Test MSE 24.326178578800754 Test RE 0.09443748812450074\n",
      "11 Train Loss 1.7855425 Test MSE 19.766408565661695 Test RE 0.08512779134790059\n",
      "12 Train Loss 1.0409433 Test MSE 11.139719583620906 Test RE 0.06390643792078594\n",
      "13 Train Loss 0.6475821 Test MSE 6.245933857930295 Test RE 0.0478526697175633\n",
      "14 Train Loss 0.45432192 Test MSE 3.856278781821746 Test RE 0.03760033317250514\n",
      "15 Train Loss 0.35682666 Test MSE 2.7519404807251995 Test RE 0.03176340119798345\n",
      "16 Train Loss 0.3028687 Test MSE 2.1709851355634675 Test RE 0.02821213197174317\n",
      "17 Train Loss 0.2658531 Test MSE 1.7705089675675314 Test RE 0.02547748456620477\n",
      "18 Train Loss 0.23045632 Test MSE 1.3493985586933661 Test RE 0.02224219289055343\n",
      "19 Train Loss 0.19341332 Test MSE 0.9018903314007471 Test RE 0.018183787494879644\n",
      "20 Train Loss 0.15742996 Test MSE 0.5294177305340256 Test RE 0.013931783688746894\n",
      "21 Train Loss 0.12981552 Test MSE 0.3457795996828257 Test RE 0.011259190451307893\n",
      "22 Train Loss 0.10900303 Test MSE 0.40071526066233826 Test RE 0.01212063638936177\n",
      "23 Train Loss 0.099446595 Test MSE 0.5801570060167048 Test RE 0.014584120781771915\n",
      "24 Train Loss 0.09454769 Test MSE 0.8402426508373774 Test RE 0.017551322369403648\n",
      "25 Train Loss 0.09309759 Test MSE 1.0682871624318744 Test RE 0.019790259391000507\n",
      "26 Train Loss 0.092919655 Test MSE 1.179214302481587 Test RE 0.020792363104271742\n",
      "27 Train Loss 0.09153644 Test MSE 1.2338983268668422 Test RE 0.021269004809080148\n",
      "28 Train Loss 0.09038694 Test MSE 1.0790280633730276 Test RE 0.019889499367268693\n",
      "29 Train Loss 0.088746354 Test MSE 1.1003074251382405 Test RE 0.02008466089639382\n",
      "30 Train Loss 0.08747552 Test MSE 1.1246265563175935 Test RE 0.020305404669099494\n",
      "31 Train Loss 0.08666337 Test MSE 1.1080015631844358 Test RE 0.020154761732342732\n",
      "32 Train Loss 0.08560822 Test MSE 1.0910038156196833 Test RE 0.019999568078929088\n",
      "33 Train Loss 0.08239167 Test MSE 0.9703220415309673 Test RE 0.018861031056406324\n",
      "34 Train Loss 0.07086924 Test MSE 0.9544101120006948 Test RE 0.0187057444889105\n",
      "35 Train Loss 0.065517046 Test MSE 1.1750621286538172 Test RE 0.020755724455209387\n",
      "36 Train Loss 0.044836428 Test MSE 0.4130749257173149 Test RE 0.012306141331649664\n",
      "37 Train Loss 0.042575587 Test MSE 0.32198325212170187 Test RE 0.01086485971245027\n",
      "38 Train Loss 0.039598394 Test MSE 0.2402348763149238 Test RE 0.009384810553288839\n",
      "39 Train Loss 0.030272719 Test MSE 0.32890779999057945 Test RE 0.01098106767839912\n",
      "40 Train Loss 0.02644773 Test MSE 0.4160378205346393 Test RE 0.012350197083336484\n",
      "41 Train Loss 0.024157492 Test MSE 0.3512448567820683 Test RE 0.011347820790291532\n",
      "42 Train Loss 0.022137815 Test MSE 0.28975321364020573 Test RE 0.0103067469274814\n",
      "43 Train Loss 0.020387176 Test MSE 0.22490826899162752 Test RE 0.009080509001954121\n",
      "44 Train Loss 0.01639686 Test MSE 0.23624412935158717 Test RE 0.009306534557866227\n",
      "45 Train Loss 0.015605533 Test MSE 0.26107235620502045 Test RE 0.00978335755629601\n",
      "46 Train Loss 0.010837399 Test MSE 0.21418393814095535 Test RE 0.008861371244170108\n",
      "47 Train Loss 0.0065829894 Test MSE 0.061239979139042666 Test RE 0.004738326672721257\n",
      "48 Train Loss 0.0058091376 Test MSE 0.020869873420284218 Test RE 0.002766096895757956\n",
      "49 Train Loss 0.0057032863 Test MSE 0.015537939603094537 Test RE 0.002386734969526503\n",
      "50 Train Loss 0.0055938694 Test MSE 0.015851678871455645 Test RE 0.0024107108060246146\n",
      "51 Train Loss 0.0047229347 Test MSE 0.009364656677323823 Test RE 0.0018529061032491376\n",
      "52 Train Loss 0.004444135 Test MSE 0.012107708312934324 Test RE 0.0021068734806940362\n",
      "53 Train Loss 0.004199535 Test MSE 0.00819248580570914 Test RE 0.0017330669114462198\n",
      "54 Train Loss 0.004122248 Test MSE 0.0041824080028786195 Test RE 0.0012382851942191776\n",
      "55 Train Loss 0.004116827 Test MSE 0.004186372203234662 Test RE 0.0012388718954663067\n",
      "56 Train Loss 0.0041160877 Test MSE 0.004240974957851833 Test RE 0.001246925009952205\n",
      "57 Train Loss 0.004114108 Test MSE 0.004375561853966619 Test RE 0.001266555996847979\n",
      "58 Train Loss 0.004113508 Test MSE 0.004433511984239216 Test RE 0.0012749155704285316\n",
      "59 Train Loss 0.0041130465 Test MSE 0.004481869213920165 Test RE 0.0012818495975380664\n",
      "60 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "61 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "62 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "63 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "64 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "65 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "66 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "67 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "68 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "69 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "70 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "71 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "72 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "73 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "74 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "75 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "76 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "77 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "78 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "79 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "80 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "81 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "82 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "83 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "84 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "85 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "86 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "87 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "88 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "89 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "90 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "91 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "92 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "93 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "94 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "95 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "96 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "97 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "98 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "99 Train Loss 0.0041127102 Test MSE 0.004531770954106791 Test RE 0.001288965987366058\n",
      "Training time: 11.98\n",
      "Training time: 11.98\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 63.451164 Test MSE 2278.5938770949706 Test RE 0.9139889491428745\n",
      "1 Train Loss 62.060333 Test MSE 2159.4757784435233 Test RE 0.889777973115168\n",
      "2 Train Loss 53.711475 Test MSE 1662.2306457609386 Test RE 0.7806441764394769\n",
      "3 Train Loss 50.772816 Test MSE 1624.2985493251877 Test RE 0.771685624528125\n",
      "4 Train Loss 43.39595 Test MSE 1140.0320265021187 Test RE 0.6464962465362287\n",
      "5 Train Loss 42.07788 Test MSE 1199.9402449627542 Test RE 0.6632653222355535\n",
      "6 Train Loss 36.343254 Test MSE 1154.4613199430796 Test RE 0.6505747073607197\n",
      "7 Train Loss 33.17591 Test MSE 845.7753686217774 Test RE 0.5568458640890943\n",
      "8 Train Loss 22.863806 Test MSE 411.5305520049694 Test RE 0.3884262062926614\n",
      "9 Train Loss 19.221651 Test MSE 248.6382703716724 Test RE 0.3019197128573795\n",
      "10 Train Loss 17.54439 Test MSE 208.10151156659174 Test RE 0.2762136260288782\n",
      "11 Train Loss 16.257843 Test MSE 312.807977233566 Test RE 0.3386463442961553\n",
      "12 Train Loss 13.380659 Test MSE 294.9892330521345 Test RE 0.32885963024695614\n",
      "13 Train Loss 11.819386 Test MSE 249.11824459283076 Test RE 0.3022109870254128\n",
      "14 Train Loss 10.555671 Test MSE 203.7114271274895 Test RE 0.2732846114498398\n",
      "15 Train Loss 7.729754 Test MSE 46.23438664181304 Test RE 0.1301937187580619\n",
      "16 Train Loss 4.3433604 Test MSE 49.788521341717576 Test RE 0.1351052097397588\n",
      "17 Train Loss 3.9865808 Test MSE 49.452144003891725 Test RE 0.1346480426036935\n",
      "18 Train Loss 3.262885 Test MSE 35.194591086910485 Test RE 0.11359139775264408\n",
      "19 Train Loss 2.310049 Test MSE 16.431909109046316 Test RE 0.07761604226799551\n",
      "20 Train Loss 2.1435766 Test MSE 12.479751167496943 Test RE 0.06764106623495991\n",
      "21 Train Loss 1.5035578 Test MSE 14.06408513613599 Test RE 0.0718064117615213\n",
      "22 Train Loss 1.2532367 Test MSE 15.077989130790561 Test RE 0.07434969559095002\n",
      "23 Train Loss 0.8715883 Test MSE 3.6913512484218924 Test RE 0.036787490917449386\n",
      "24 Train Loss 0.8207864 Test MSE 3.9873927924210335 Test RE 0.03823419858700182\n",
      "25 Train Loss 0.7552354 Test MSE 5.148811492143055 Test RE 0.0434471184203974\n",
      "26 Train Loss 0.6772651 Test MSE 4.953464962902123 Test RE 0.042614954542322885\n",
      "27 Train Loss 0.6292555 Test MSE 5.951893886471105 Test RE 0.04671271090424996\n",
      "28 Train Loss 0.60129905 Test MSE 4.953997572195426 Test RE 0.04261724551550151\n",
      "29 Train Loss 0.55404246 Test MSE 2.772422853899716 Test RE 0.03188138771681349\n",
      "30 Train Loss 0.46483022 Test MSE 1.519758382950788 Test RE 0.023604497289327852\n",
      "31 Train Loss 0.4209253 Test MSE 1.022291785596389 Test RE 0.019359534805728752\n",
      "32 Train Loss 0.40794405 Test MSE 0.9771121237576675 Test RE 0.018926908507159067\n",
      "33 Train Loss 0.380706 Test MSE 0.6058562462087957 Test RE 0.014903637428845085\n",
      "34 Train Loss 0.37820414 Test MSE 0.507696374641241 Test RE 0.013642988494617515\n",
      "35 Train Loss 0.37112457 Test MSE 0.42192896419398956 Test RE 0.012437329824765954\n",
      "36 Train Loss 0.3344177 Test MSE 0.8538157963505953 Test RE 0.017692515081051085\n",
      "37 Train Loss 0.30863172 Test MSE 0.6536702187892969 Test RE 0.015480565856105372\n",
      "38 Train Loss 0.26303467 Test MSE 1.0360369219018715 Test RE 0.01948924872754896\n",
      "39 Train Loss 0.23846975 Test MSE 1.3806743333420393 Test RE 0.022498476341221516\n",
      "40 Train Loss 0.15567592 Test MSE 0.4245172243492332 Test RE 0.01247541897128547\n",
      "41 Train Loss 0.09955655 Test MSE 0.3111610840046319 Test RE 0.010680709909144487\n",
      "42 Train Loss 0.0782627 Test MSE 0.1971286008605601 Test RE 0.008501240480041559\n",
      "43 Train Loss 0.07265972 Test MSE 0.2661600221855108 Test RE 0.009878224540234336\n",
      "44 Train Loss 0.06949198 Test MSE 0.19531074918671304 Test RE 0.008461951946462432\n",
      "45 Train Loss 0.066504724 Test MSE 0.09995581382039766 Test RE 0.006053569202671765\n",
      "46 Train Loss 0.0629221 Test MSE 0.120030750443026 Test RE 0.006633668155533736\n",
      "47 Train Loss 0.051980417 Test MSE 0.35012503357186614 Test RE 0.011329717040938242\n",
      "48 Train Loss 0.03337956 Test MSE 0.025881450019576334 Test RE 0.0030803621892800457\n",
      "49 Train Loss 0.03142268 Test MSE 0.020133427546837415 Test RE 0.002716854245281807\n",
      "50 Train Loss 0.03096379 Test MSE 0.02795269449266718 Test RE 0.0032012480044533807\n",
      "51 Train Loss 0.030555291 Test MSE 0.03476105598297056 Test RE 0.003569882832661334\n",
      "52 Train Loss 0.02987099 Test MSE 0.04508425925793516 Test RE 0.004065556033002632\n",
      "53 Train Loss 0.026437718 Test MSE 0.06237658163154763 Test RE 0.004782095745789379\n",
      "54 Train Loss 0.025374923 Test MSE 0.06544625433177559 Test RE 0.004898350747427354\n",
      "55 Train Loss 0.02394413 Test MSE 0.05930318187955654 Test RE 0.0046627966920075765\n",
      "56 Train Loss 0.023377342 Test MSE 0.041457142933237656 Test RE 0.0038985864249387356\n",
      "57 Train Loss 0.022683531 Test MSE 0.038756961822430554 Test RE 0.003769487820019769\n",
      "58 Train Loss 0.01991059 Test MSE 0.05573633319195112 Test RE 0.004520398047387182\n",
      "59 Train Loss 0.019613309 Test MSE 0.052815175099392264 Test RE 0.00440034617504445\n",
      "60 Train Loss 0.019578652 Test MSE 0.050172981935483564 Test RE 0.004288865614081657\n",
      "61 Train Loss 0.019275524 Test MSE 0.03580536550865741 Test RE 0.0036231101485584226\n",
      "62 Train Loss 0.015522811 Test MSE 0.006780001591512583 Test RE 0.0015766031128018414\n",
      "63 Train Loss 0.015315641 Test MSE 0.009231959308576773 Test RE 0.001839731407400768\n",
      "64 Train Loss 0.015310383 Test MSE 0.009188458106648494 Test RE 0.0018353918612677475\n",
      "65 Train Loss 0.015310383 Test MSE 0.009188458106648494 Test RE 0.0018353918612677475\n",
      "66 Train Loss 0.015310383 Test MSE 0.009188458106648494 Test RE 0.0018353918612677475\n",
      "67 Train Loss 0.015310383 Test MSE 0.009188458106648494 Test RE 0.0018353918612677475\n",
      "68 Train Loss 0.015309071 Test MSE 0.009260008777440445 Test RE 0.0018425241163918444\n",
      "69 Train Loss 0.0153090665 Test MSE 0.009259921055148217 Test RE 0.001842515389033931\n",
      "70 Train Loss 0.015307298 Test MSE 0.00944085505006448 Test RE 0.00186042919735124\n",
      "71 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "72 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "73 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "74 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "75 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "76 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "77 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "78 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "79 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "80 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "81 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "82 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "83 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "84 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "85 Train Loss 0.01530678 Test MSE 0.009470762557192113 Test RE 0.0018633736765845674\n",
      "86 Train Loss 0.015306744 Test MSE 0.009469415130261831 Test RE 0.0018632411186639628\n",
      "87 Train Loss 0.015306684 Test MSE 0.009469567377124462 Test RE 0.0018632560969636016\n",
      "88 Train Loss 0.015306684 Test MSE 0.009469567377124462 Test RE 0.0018632560969636016\n",
      "89 Train Loss 0.015306659 Test MSE 0.009468480520448234 Test RE 0.001863149167557115\n",
      "90 Train Loss 0.015306639 Test MSE 0.009468355743831139 Test RE 0.001863136891130307\n",
      "91 Train Loss 0.015306158 Test MSE 0.009483338788833496 Test RE 0.0018646104536884226\n",
      "92 Train Loss 0.015306158 Test MSE 0.009483338691590905 Test RE 0.001864610444128522\n",
      "93 Train Loss 0.015306158 Test MSE 0.009483338691590905 Test RE 0.001864610444128522\n",
      "94 Train Loss 0.015306158 Test MSE 0.009483338691590905 Test RE 0.001864610444128522\n",
      "95 Train Loss 0.015306155 Test MSE 0.009483768957711981 Test RE 0.0018646527430292263\n",
      "96 Train Loss 0.015306155 Test MSE 0.009483768957711981 Test RE 0.0018646527430292263\n",
      "97 Train Loss 0.015306155 Test MSE 0.009483768957711981 Test RE 0.0018646527430292263\n",
      "98 Train Loss 0.015306155 Test MSE 0.009483768957711981 Test RE 0.0018646527430292263\n",
      "99 Train Loss 0.015306155 Test MSE 0.009483768957711981 Test RE 0.0018646527430292263\n",
      "Training time: 15.22\n",
      "Training time: 15.22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 59.137474 Test MSE 2065.405138195215 Test RE 0.870182025655991\n",
      "1 Train Loss 50.713184 Test MSE 1503.1982099381764 Test RE 0.7423617839578023\n",
      "2 Train Loss 41.95475 Test MSE 1333.7571410880498 Test RE 0.6992715522345797\n",
      "3 Train Loss 37.53026 Test MSE 1054.596524139083 Test RE 0.6217999024603708\n",
      "4 Train Loss 31.75407 Test MSE 1017.5624295927145 Test RE 0.6107845087632546\n",
      "5 Train Loss 12.813647 Test MSE 355.41016807288827 Test RE 0.3609710776937509\n",
      "6 Train Loss 7.468172 Test MSE 133.59591128027128 Test RE 0.22131154249687554\n",
      "7 Train Loss 6.071643 Test MSE 42.39232436686843 Test RE 0.12466688169215441\n",
      "8 Train Loss 2.9189153 Test MSE 6.478540884664719 Test RE 0.04873557380051737\n",
      "9 Train Loss 1.1235503 Test MSE 3.4123729085284955 Test RE 0.03537005413012068\n",
      "10 Train Loss 0.66699606 Test MSE 3.25241950747097 Test RE 0.03453112760814847\n",
      "11 Train Loss 0.31758413 Test MSE 1.7571371940987695 Test RE 0.025381092838162825\n",
      "12 Train Loss 0.2031935 Test MSE 0.7844501509980051 Test RE 0.01695860627080037\n",
      "13 Train Loss 0.13250579 Test MSE 0.15786090994327331 Test RE 0.007607549427135895\n",
      "14 Train Loss 0.1127221 Test MSE 0.07000325194153617 Test RE 0.005066016377053371\n",
      "15 Train Loss 0.102472186 Test MSE 0.22777609940301935 Test RE 0.00913821890962584\n",
      "16 Train Loss 0.08063929 Test MSE 0.03550320949005782 Test RE 0.0036077903226850692\n",
      "17 Train Loss 0.06550209 Test MSE 0.1028538062587013 Test RE 0.006140696961194917\n",
      "18 Train Loss 0.047331832 Test MSE 0.05417569123617636 Test RE 0.004456662150098967\n",
      "19 Train Loss 0.036537506 Test MSE 0.052198376496179616 Test RE 0.004374576136688095\n",
      "20 Train Loss 0.030175364 Test MSE 0.05409634280814705 Test RE 0.004453397228983609\n",
      "21 Train Loss 0.010536888 Test MSE 0.007787929526570633 Test RE 0.001689734565761697\n",
      "22 Train Loss 0.009189854 Test MSE 0.004673007739694443 Test RE 0.0013088977825234634\n",
      "23 Train Loss 0.0046177907 Test MSE 0.005033968720349117 Test RE 0.0013585096824686518\n",
      "24 Train Loss 0.0036292446 Test MSE 0.0019140000958449502 Test RE 0.0008376806033224683\n",
      "25 Train Loss 0.003180953 Test MSE 0.0017907767022621276 Test RE 0.000810267089522309\n",
      "26 Train Loss 0.0025202604 Test MSE 0.0039100046449600905 Test RE 0.0011972810767225822\n",
      "27 Train Loss 0.0020940076 Test MSE 0.002036703734771005 Test RE 0.0008641147366363369\n",
      "28 Train Loss 0.001847662 Test MSE 0.0010062153720933602 Test RE 0.0006073694668971932\n",
      "29 Train Loss 0.0013993183 Test MSE 0.0004038232864593958 Test RE 0.00038477173464262305\n",
      "30 Train Loss 0.0013082813 Test MSE 0.000256741261096098 Test RE 0.0003067999728399583\n",
      "31 Train Loss 0.0011313658 Test MSE 0.00018119120486483162 Test RE 0.00025773656625163976\n",
      "32 Train Loss 0.0011054225 Test MSE 0.0001891362393387538 Test RE 0.0002633266757166007\n",
      "33 Train Loss 0.0010830145 Test MSE 0.00027549857987387456 Test RE 0.0003178097114778286\n",
      "34 Train Loss 0.0008545877 Test MSE 0.000244081813154543 Test RE 0.0002991404841246592\n",
      "35 Train Loss 0.0006627572 Test MSE 0.00019742937316612164 Test RE 0.00026903783849142795\n",
      "36 Train Loss 0.00066098437 Test MSE 0.00019435957808372362 Test RE 0.00026693803278960863\n",
      "37 Train Loss 0.0006605128 Test MSE 0.00019215086507380166 Test RE 0.00026541694972963286\n",
      "38 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "39 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "40 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "41 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "42 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "43 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "44 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "45 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "46 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "47 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "48 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "49 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "50 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "51 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "52 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "53 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "54 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "55 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "56 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "57 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "58 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "59 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "60 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "61 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "62 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "63 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "64 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "65 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "66 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "67 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "68 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "69 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "70 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "71 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "72 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "73 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "74 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "75 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "76 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "77 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "78 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "79 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "80 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "81 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "82 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "83 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "84 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "85 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "86 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "87 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "88 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "89 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "90 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "91 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "92 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "93 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "94 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "95 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "96 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "97 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "98 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "99 Train Loss 0.0006601926 Test MSE 0.0001885895679645986 Test RE 0.0002629458461997579\n",
      "Training time: 8.39\n",
      "Training time: 8.39\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 62.813675 Test MSE 2233.343608994044 Test RE 0.9048680518741357\n",
      "1 Train Loss 60.50414 Test MSE 2127.3334955024807 Test RE 0.8831312869245319\n",
      "2 Train Loss 48.56929 Test MSE 1395.451672368242 Test RE 0.7152615541684922\n",
      "3 Train Loss 32.564785 Test MSE 884.4028935986471 Test RE 0.5694197930982579\n",
      "4 Train Loss 12.958345 Test MSE 226.12818203892874 Test RE 0.28792861447064894\n",
      "5 Train Loss 10.73516 Test MSE 130.02687746286358 Test RE 0.21833534585146194\n",
      "6 Train Loss 4.683308 Test MSE 40.05034812264519 Test RE 0.12117433066412867\n",
      "7 Train Loss 1.5421054 Test MSE 23.120171259091126 Test RE 0.09206679081369994\n",
      "8 Train Loss 1.3365762 Test MSE 7.212157420800268 Test RE 0.05142094817754477\n",
      "9 Train Loss 0.7237436 Test MSE 3.6446990546071274 Test RE 0.0365542871295716\n",
      "10 Train Loss 0.41044945 Test MSE 4.04177122928195 Test RE 0.038494026932860255\n",
      "11 Train Loss 0.38383922 Test MSE 3.9546964591304334 Test RE 0.03807711707458343\n",
      "12 Train Loss 0.13865264 Test MSE 2.0716930470220927 Test RE 0.02755942714562166\n",
      "13 Train Loss 0.12692264 Test MSE 1.1763457522166936 Test RE 0.02076705801124077\n",
      "14 Train Loss 0.10739 Test MSE 0.7842769202273796 Test RE 0.01695673367594283\n",
      "15 Train Loss 0.048085075 Test MSE 0.5760165575179587 Test RE 0.01453198582115879\n",
      "16 Train Loss 0.026107188 Test MSE 0.12036776601918962 Test RE 0.006642974447479007\n",
      "17 Train Loss 0.02514415 Test MSE 0.1260917780725349 Test RE 0.006799091193759025\n",
      "18 Train Loss 0.01964579 Test MSE 0.08649575151217301 Test RE 0.005631250799254658\n",
      "19 Train Loss 0.017742692 Test MSE 0.053059931188213304 Test RE 0.004410530432015909\n",
      "20 Train Loss 0.017264651 Test MSE 0.04841846575149556 Test RE 0.00421320890700752\n",
      "21 Train Loss 0.01713389 Test MSE 0.05058031120418786 Test RE 0.004306239995996739\n",
      "22 Train Loss 0.016303496 Test MSE 0.04945780755840206 Test RE 0.004258188786758233\n",
      "23 Train Loss 0.015431106 Test MSE 0.05412141404274728 Test RE 0.004454429084627185\n",
      "24 Train Loss 0.015120856 Test MSE 0.03976594639140465 Test RE 0.0038182392977360756\n",
      "25 Train Loss 0.015015233 Test MSE 0.038084118066558655 Test RE 0.0037366242951546776\n",
      "26 Train Loss 0.014944979 Test MSE 0.03784589265970634 Test RE 0.0037249192157274525\n",
      "27 Train Loss 0.0147154555 Test MSE 0.03934914913191244 Test RE 0.0037981766075356207\n",
      "28 Train Loss 0.014671448 Test MSE 0.04092013074029689 Test RE 0.003873254089494391\n",
      "29 Train Loss 0.01460487 Test MSE 0.03730649538218747 Test RE 0.003698279312795484\n",
      "30 Train Loss 0.014604398 Test MSE 0.03717274497574021 Test RE 0.0036916438663210332\n",
      "31 Train Loss 0.01459725 Test MSE 0.03669510241669467 Test RE 0.0036678497243448236\n",
      "32 Train Loss 0.014592588 Test MSE 0.03668776445702899 Test RE 0.0036674829740534895\n",
      "33 Train Loss 0.014565752 Test MSE 0.037515130023052325 Test RE 0.003708606112541886\n",
      "34 Train Loss 0.01456318 Test MSE 0.03761496403980822 Test RE 0.003713537443591634\n",
      "35 Train Loss 0.014561167 Test MSE 0.03762821933486249 Test RE 0.0037141917004806712\n",
      "36 Train Loss 0.0145606 Test MSE 0.03762745719347675 Test RE 0.0037141540857118416\n",
      "37 Train Loss 0.0145606 Test MSE 0.03762745719347675 Test RE 0.0037141540857118416\n",
      "38 Train Loss 0.0145606 Test MSE 0.03762745719347675 Test RE 0.0037141540857118416\n",
      "39 Train Loss 0.0145606 Test MSE 0.03762745719347675 Test RE 0.0037141540857118416\n",
      "40 Train Loss 0.014560595 Test MSE 0.037606779986840345 Test RE 0.0037131334362874822\n",
      "41 Train Loss 0.01456024 Test MSE 0.0376178847398181 Test RE 0.0037136816138519293\n",
      "42 Train Loss 0.014560221 Test MSE 0.03761790670022095 Test RE 0.0037136826978301086\n",
      "43 Train Loss 0.014560221 Test MSE 0.03761790670022095 Test RE 0.0037136826978301086\n",
      "44 Train Loss 0.014560219 Test MSE 0.03761789767417203 Test RE 0.0037136822522991545\n",
      "45 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "46 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "47 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "48 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "49 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "50 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "51 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "52 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "53 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "54 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "55 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "56 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "57 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "58 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "59 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "60 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "61 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "62 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "63 Train Loss 0.014560218 Test MSE 0.037617915430566966 Test RE 0.003713683128764947\n",
      "64 Train Loss 0.01455973 Test MSE 0.03779129149442249 Test RE 0.0037222312313056785\n",
      "65 Train Loss 0.014559513 Test MSE 0.03797181353214878 Test RE 0.0037311108463172443\n",
      "66 Train Loss 0.014559513 Test MSE 0.03797181353214878 Test RE 0.0037311108463172443\n",
      "67 Train Loss 0.014558938 Test MSE 0.03792007844557443 Test RE 0.0037285682348612626\n",
      "68 Train Loss 0.014558936 Test MSE 0.037920070004890144 Test RE 0.0037285678198875813\n",
      "69 Train Loss 0.014558936 Test MSE 0.037920070004890144 Test RE 0.0037285678198875813\n",
      "70 Train Loss 0.014558887 Test MSE 0.03790746063052799 Test RE 0.003727947847185415\n",
      "71 Train Loss 0.01455875 Test MSE 0.03783445739178757 Test RE 0.0037243564245724448\n",
      "72 Train Loss 0.014556651 Test MSE 0.037677285385734345 Test RE 0.003716612507945929\n",
      "73 Train Loss 0.014556651 Test MSE 0.037677285385734345 Test RE 0.003716612507945929\n",
      "74 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "75 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "76 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "77 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "78 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "79 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "80 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "81 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "82 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "83 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "84 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "85 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "86 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "87 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "88 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "89 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "90 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "91 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "92 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "93 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "94 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "95 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "96 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "97 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "98 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "99 Train Loss 0.014554972 Test MSE 0.03758623069287089 Test RE 0.0037121188227420346\n",
      "Training time: 10.06\n",
      "Training time: 10.06\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 62.964638 Test MSE 2187.0925329237853 Test RE 0.8954494224895909\n",
      "1 Train Loss 51.346203 Test MSE 1820.9505420820349 Test RE 0.8170649051443006\n",
      "2 Train Loss 44.187675 Test MSE 1347.441339733306 Test RE 0.702849621847236\n",
      "3 Train Loss 26.596294 Test MSE 832.7005449695222 Test RE 0.5525249656213842\n",
      "4 Train Loss 8.405367 Test MSE 192.24239877385685 Test RE 0.2654801597049817\n",
      "5 Train Loss 3.788508 Test MSE 81.89383635906476 Test RE 0.17327387584895051\n",
      "6 Train Loss 1.2936513 Test MSE 9.01618991767382 Test RE 0.05749353436648546\n",
      "7 Train Loss 0.80805993 Test MSE 16.89595812834244 Test RE 0.0787043785492503\n",
      "8 Train Loss 0.15661179 Test MSE 1.4720531000616575 Test RE 0.0232310703449637\n",
      "9 Train Loss 0.07954491 Test MSE 0.4317706820974359 Test RE 0.01258154735734629\n",
      "10 Train Loss 0.0731661 Test MSE 0.3103306102898511 Test RE 0.010666447240009674\n",
      "11 Train Loss 0.054617506 Test MSE 0.33380311518491124 Test RE 0.011062484481275638\n",
      "12 Train Loss 0.039372038 Test MSE 0.11129486922101219 Test RE 0.006387707976756698\n",
      "13 Train Loss 0.033116203 Test MSE 0.07751102198877766 Test RE 0.005330761019621417\n",
      "14 Train Loss 0.03267078 Test MSE 0.05982214939798947 Test RE 0.004683154528891822\n",
      "15 Train Loss 0.028596727 Test MSE 0.08260889399647751 Test RE 0.005503270824220436\n",
      "16 Train Loss 0.023286832 Test MSE 0.04135396724561316 Test RE 0.0038937321358465658\n",
      "17 Train Loss 0.015818404 Test MSE 0.029039155030548863 Test RE 0.0032628677352044663\n",
      "18 Train Loss 0.009925216 Test MSE 0.01719096755084193 Test RE 0.0025104850648957813\n",
      "19 Train Loss 0.0062124175 Test MSE 0.013953845662773887 Test RE 0.0022618012479081427\n",
      "20 Train Loss 0.004685504 Test MSE 0.01100844850737936 Test RE 0.002008956529536744\n",
      "21 Train Loss 0.0041465485 Test MSE 0.009935295301673093 Test RE 0.001908525081550213\n",
      "22 Train Loss 0.0040922775 Test MSE 0.009052751032926647 Test RE 0.0018217877190581642\n",
      "23 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "24 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "25 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "26 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "27 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "28 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "29 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "30 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "31 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "32 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "33 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "34 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "35 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "36 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "37 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "38 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "39 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "40 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "41 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "42 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "43 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "44 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "45 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "46 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "47 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "48 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "49 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "50 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "51 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "52 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "53 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "54 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "55 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "56 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "57 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "58 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "59 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "60 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "61 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "62 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "63 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "64 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "65 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "66 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "67 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "68 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "69 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "70 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "71 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "72 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "73 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "74 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "75 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "76 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "77 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "78 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "79 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "80 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "81 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "82 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "83 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "84 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "85 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "86 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "87 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "88 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "89 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "90 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "91 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "92 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "93 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "94 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "95 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "96 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "97 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "98 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "99 Train Loss 0.004091987 Test MSE 0.009259609163473613 Test RE 0.001842484359069108\n",
      "Training time: 6.31\n",
      "Training time: 6.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 65.1463 Test MSE 2372.289740639356 Test RE 0.9325912730465644\n",
      "1 Train Loss 47.32491 Test MSE 1600.6133743861842 Test RE 0.7660386857403817\n",
      "2 Train Loss 38.455227 Test MSE 1167.2011266081104 Test RE 0.6541544962654141\n",
      "3 Train Loss 34.837593 Test MSE 1079.2300428366357 Test RE 0.6290200589716601\n",
      "4 Train Loss 31.456207 Test MSE 934.1353459967601 Test RE 0.5852108701409132\n",
      "5 Train Loss 31.024178 Test MSE 879.961968490523 Test RE 0.5679883566309322\n",
      "6 Train Loss 30.799965 Test MSE 888.8019561108399 Test RE 0.5708341971649342\n",
      "7 Train Loss 28.602156 Test MSE 814.0104856653625 Test RE 0.546289032345121\n",
      "8 Train Loss 25.993599 Test MSE 681.4630241744483 Test RE 0.4998372631439043\n",
      "9 Train Loss 25.696331 Test MSE 632.9361099556446 Test RE 0.481711948227274\n",
      "10 Train Loss 24.145987 Test MSE 628.8534985705659 Test RE 0.48015584780204407\n",
      "11 Train Loss 23.262203 Test MSE 532.5388137595153 Test RE 0.44185839943143146\n",
      "12 Train Loss 22.305752 Test MSE 522.839054235708 Test RE 0.437815862037417\n",
      "13 Train Loss 21.593878 Test MSE 454.9066189254455 Test RE 0.40838389761709115\n",
      "14 Train Loss 21.169132 Test MSE 419.42184638665435 Test RE 0.39213265122535584\n",
      "15 Train Loss 20.504704 Test MSE 355.5486227930461 Test RE 0.36104138137042135\n",
      "16 Train Loss 19.328468 Test MSE 312.0736792196125 Test RE 0.3382486347417011\n",
      "17 Train Loss 16.570541 Test MSE 242.47423142368402 Test RE 0.29815375101184266\n",
      "18 Train Loss 14.83761 Test MSE 201.0130606279146 Test RE 0.271468610411588\n",
      "19 Train Loss 14.066469 Test MSE 160.13391168358942 Test RE 0.2422976143132666\n",
      "20 Train Loss 11.957933 Test MSE 195.4254242716206 Test RE 0.2676689612351727\n",
      "21 Train Loss 10.450929 Test MSE 203.966988357997 Test RE 0.27345597901123875\n",
      "22 Train Loss 9.770296 Test MSE 205.99744441995335 Test RE 0.2748137118477415\n",
      "23 Train Loss 9.312057 Test MSE 179.8717175392575 Test RE 0.2567963949607859\n",
      "24 Train Loss 8.380197 Test MSE 147.91669115088865 Test RE 0.23287135671482945\n",
      "25 Train Loss 6.911923 Test MSE 162.7251857624393 Test RE 0.24425016725202725\n",
      "26 Train Loss 5.286839 Test MSE 116.55657814446194 Test RE 0.20671684894622433\n",
      "27 Train Loss 5.253609 Test MSE 123.77191061410464 Test RE 0.2130190920620784\n",
      "28 Train Loss 5.017866 Test MSE 112.44371195609318 Test RE 0.20303694433831107\n",
      "29 Train Loss 4.3107986 Test MSE 106.85303937006123 Test RE 0.1979251221969021\n",
      "30 Train Loss 3.7514071 Test MSE 101.36620947664278 Test RE 0.19277649735061178\n",
      "31 Train Loss 3.3674867 Test MSE 80.61329189394313 Test RE 0.1719138276165763\n",
      "32 Train Loss 2.5413764 Test MSE 61.237280540383885 Test RE 0.14983574439996364\n",
      "33 Train Loss 1.4919622 Test MSE 22.39307264066635 Test RE 0.09060753724369529\n",
      "34 Train Loss 0.9804932 Test MSE 6.94656868974461 Test RE 0.05046527556241835\n",
      "35 Train Loss 0.679521 Test MSE 6.4252169165613715 Test RE 0.048534591520123516\n",
      "36 Train Loss 0.51252794 Test MSE 3.303494723671532 Test RE 0.034801205702765015\n",
      "37 Train Loss 0.412203 Test MSE 5.1483121327540164 Test RE 0.043445011501877406\n",
      "38 Train Loss 0.37544414 Test MSE 5.1738737677261355 Test RE 0.043552731318986786\n",
      "39 Train Loss 0.31833348 Test MSE 2.4168336278509823 Test RE 0.029766711571201414\n",
      "40 Train Loss 0.2462075 Test MSE 2.4800313992031233 Test RE 0.030153384905110634\n",
      "41 Train Loss 0.21524198 Test MSE 1.6205414327375385 Test RE 0.024374603028413242\n",
      "42 Train Loss 0.09319031 Test MSE 0.7580914182230631 Test RE 0.016671254137178102\n",
      "43 Train Loss 0.07773867 Test MSE 0.6935585630351332 Test RE 0.015945900537080893\n",
      "44 Train Loss 0.03954841 Test MSE 0.33197148164158014 Test RE 0.011032091879967974\n",
      "45 Train Loss 0.029015725 Test MSE 0.14892568044223053 Test RE 0.007389112491971805\n",
      "46 Train Loss 0.015465281 Test MSE 0.019922281450379258 Test RE 0.0027025704098591124\n",
      "47 Train Loss 0.013218091 Test MSE 0.011391567650271914 Test RE 0.002043615691127845\n",
      "48 Train Loss 0.01262 Test MSE 0.004806966900247131 Test RE 0.0013275260366639448\n",
      "49 Train Loss 0.011534885 Test MSE 0.008609199323258253 Test RE 0.0017765967496615356\n",
      "50 Train Loss 0.011376977 Test MSE 0.010470588304709505 Test RE 0.0019592642930859054\n",
      "51 Train Loss 0.011013301 Test MSE 0.005109342107835238 Test RE 0.0013686423466320735\n",
      "52 Train Loss 0.010487023 Test MSE 0.005461163447156607 Test RE 0.0014149792433575839\n",
      "53 Train Loss 0.010400879 Test MSE 0.005079384702172507 Test RE 0.0013646240943983093\n",
      "54 Train Loss 0.010242019 Test MSE 0.004681098778351668 Test RE 0.0013100304323040294\n",
      "55 Train Loss 0.01022956 Test MSE 0.004678517534408742 Test RE 0.0013096691950642725\n",
      "56 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "57 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "58 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "59 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "60 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "61 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "62 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "63 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "64 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "65 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "66 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "67 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "68 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "69 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "70 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "71 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "72 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "73 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "74 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "75 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "76 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "77 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "78 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "79 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "80 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "81 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "82 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "83 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "84 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "85 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "86 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "87 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "88 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "89 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "90 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "91 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "92 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "93 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "94 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "95 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "96 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "97 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "98 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "99 Train Loss 0.010229013 Test MSE 0.004614903026798212 Test RE 0.0013007348360058095\n",
      "Training time: 12.75\n",
      "Training time: 12.75\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 61.28449 Test MSE 2194.2971206019456 Test RE 0.8969230774915843\n",
      "1 Train Loss 55.94181 Test MSE 1873.1697272746853 Test RE 0.8286975349652921\n",
      "2 Train Loss 33.797222 Test MSE 958.3009056581659 Test RE 0.5927320775427471\n",
      "3 Train Loss 25.192556 Test MSE 655.259324132345 Test RE 0.4901331609168809\n",
      "4 Train Loss 20.470934 Test MSE 362.7376544941183 Test RE 0.36467316139962225\n",
      "5 Train Loss 8.3757105 Test MSE 137.00070121932302 Test RE 0.22411394314245367\n",
      "6 Train Loss 7.3257966 Test MSE 97.08140318291797 Test RE 0.18865812081641728\n",
      "7 Train Loss 4.2473516 Test MSE 30.50738796305425 Test RE 0.1057572122401945\n",
      "8 Train Loss 2.235286 Test MSE 28.99181596397442 Test RE 0.10309680138775716\n",
      "9 Train Loss 0.8001895 Test MSE 16.311201027206202 Test RE 0.07733043476919597\n",
      "10 Train Loss 0.46383664 Test MSE 6.3772409098957406 Test RE 0.04835305221634844\n",
      "11 Train Loss 0.25599453 Test MSE 1.5198283052776225 Test RE 0.023605040290902643\n",
      "12 Train Loss 0.08569184 Test MSE 0.3322003257360471 Test RE 0.011035893703736616\n",
      "13 Train Loss 0.05820561 Test MSE 0.35788954732546296 Test RE 0.011454654358088755\n",
      "14 Train Loss 0.053961743 Test MSE 0.23968539531584893 Test RE 0.009374071631313995\n",
      "15 Train Loss 0.046597786 Test MSE 0.14810193501950936 Test RE 0.007368648634539797\n",
      "16 Train Loss 0.033145808 Test MSE 0.021606714498545485 Test RE 0.0028145038591073303\n",
      "17 Train Loss 0.022294147 Test MSE 0.023232784736769683 Test RE 0.002918489371376658\n",
      "18 Train Loss 0.013649703 Test MSE 0.013631168585070727 Test RE 0.0022354966649113218\n",
      "19 Train Loss 0.010064544 Test MSE 0.012161437395131359 Test RE 0.0021115430295910297\n",
      "20 Train Loss 0.009952819 Test MSE 0.013229001369426148 Test RE 0.0022022722806385505\n",
      "21 Train Loss 0.009310424 Test MSE 0.02221456833852986 Test RE 0.0028538189741755923\n",
      "22 Train Loss 0.0045738085 Test MSE 0.004493221992791149 Test RE 0.0012834720624533336\n",
      "23 Train Loss 0.0030468889 Test MSE 0.001645757813458806 Test RE 0.0007767664236896224\n",
      "24 Train Loss 0.0026613744 Test MSE 0.003051465924668792 Test RE 0.0010576981484110585\n",
      "25 Train Loss 0.002509543 Test MSE 0.0017094227014584661 Test RE 0.0007916481758208496\n",
      "26 Train Loss 0.0019598966 Test MSE 0.0014045429958539095 Test RE 0.0007175877247826423\n",
      "27 Train Loss 0.0014562497 Test MSE 0.001124767029785171 Test RE 0.0006421533765522949\n",
      "28 Train Loss 0.0011876951 Test MSE 0.0004468970717180446 Test RE 0.00040477272101586807\n",
      "29 Train Loss 0.0011617038 Test MSE 0.0004384470360308658 Test RE 0.00040092768934075394\n",
      "30 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "31 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "32 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "33 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "34 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "35 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "36 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "37 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "38 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "39 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "40 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "41 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "42 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "43 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "44 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "45 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "46 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "47 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "48 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "49 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "50 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "51 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "52 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "53 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "54 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "55 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "56 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "57 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "58 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "59 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "60 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "61 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "62 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "63 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "64 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "65 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "66 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "67 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "68 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "69 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "70 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "71 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "72 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "73 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "74 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "75 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "76 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "77 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "78 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "79 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "80 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "81 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "82 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "83 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "84 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "85 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "86 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "87 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "88 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "89 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "90 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "91 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "92 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "93 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "94 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "95 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "96 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "97 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "98 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "99 Train Loss 0.001161095 Test MSE 0.0004421989877523319 Test RE 0.0004026394775139326\n",
      "Training time: 7.67\n",
      "Training time: 7.67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 64.36476 Test MSE 2325.321808503657 Test RE 0.9233131356404414\n",
      "1 Train Loss 58.514557 Test MSE 1839.6731935808632 Test RE 0.8212546127179379\n",
      "2 Train Loss 32.001778 Test MSE 1053.9832270234335 Test RE 0.6216190733295058\n",
      "3 Train Loss 19.976648 Test MSE 508.23700330877864 Test RE 0.43165882338194217\n",
      "4 Train Loss 14.059513 Test MSE 284.7194406196096 Test RE 0.3230844400726119\n",
      "5 Train Loss 12.878315 Test MSE 287.69376394338565 Test RE 0.32476760744770905\n",
      "6 Train Loss 4.154141 Test MSE 46.305302758248274 Test RE 0.13029352861692675\n",
      "7 Train Loss 2.0508914 Test MSE 19.883665981188607 Test RE 0.08537991365483662\n",
      "8 Train Loss 1.2105199 Test MSE 12.817559732510531 Test RE 0.06855042580680873\n",
      "9 Train Loss 1.0700334 Test MSE 16.245735957507694 Test RE 0.07717509574647245\n",
      "10 Train Loss 0.7080089 Test MSE 8.337970789183169 Test RE 0.05528886396102991\n",
      "11 Train Loss 0.36391717 Test MSE 2.4692108890137963 Test RE 0.03008753257838918\n",
      "12 Train Loss 0.117970854 Test MSE 0.6581022432071514 Test RE 0.015532957978660807\n",
      "13 Train Loss 0.045561906 Test MSE 0.22418507968835702 Test RE 0.009065898124201494\n",
      "14 Train Loss 0.035556927 Test MSE 0.07202906033826809 Test RE 0.005138795751219714\n",
      "15 Train Loss 0.0352658 Test MSE 0.07382832497592913 Test RE 0.005202582663203869\n",
      "16 Train Loss 0.035265796 Test MSE 0.0743855670477935 Test RE 0.005222179803137577\n",
      "17 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "18 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "19 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "20 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "21 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "22 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "23 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "24 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "25 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "26 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "27 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "28 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "29 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "30 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "31 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "32 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "33 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "34 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "35 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "36 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "37 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "38 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "39 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "40 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "41 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "42 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "43 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "44 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "45 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "46 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "47 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "48 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "49 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "50 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "51 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "52 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "53 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "54 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "55 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "56 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "57 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "58 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "59 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "60 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "61 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "62 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "63 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "64 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "65 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "66 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "67 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "68 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "69 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "70 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "71 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "72 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "73 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "74 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "75 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "76 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "77 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "78 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "79 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "80 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "81 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "82 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "83 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "84 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "85 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "86 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "87 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "88 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "89 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "90 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "91 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "92 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "93 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "94 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "95 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "96 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "97 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "98 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "99 Train Loss 0.035264112 Test MSE 0.07512320267412684 Test RE 0.005248008491696884\n",
      "Training time: 5.15\n",
      "Training time: 5.15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 62.864742 Test MSE 2221.3126870997116 Test RE 0.9024275188615004\n",
      "1 Train Loss 58.47581 Test MSE 1944.606723416794 Test RE 0.8443516828012096\n",
      "2 Train Loss 51.68674 Test MSE 1607.861790233835 Test RE 0.7677712387100547\n",
      "3 Train Loss 34.894073 Test MSE 1027.227489868137 Test RE 0.6136783447687484\n",
      "4 Train Loss 27.858458 Test MSE 735.629074565476 Test RE 0.5193222435351155\n",
      "5 Train Loss 16.797579 Test MSE 237.2332408926731 Test RE 0.2949139070249626\n",
      "6 Train Loss 7.861762 Test MSE 167.9682530453406 Test RE 0.24815388827306228\n",
      "7 Train Loss 5.5259666 Test MSE 114.53074502011326 Test RE 0.20491253434688\n",
      "8 Train Loss 1.9521211 Test MSE 16.202496980402934 Test RE 0.07707232430068366\n",
      "9 Train Loss 1.774415 Test MSE 10.133034203408373 Test RE 0.060950494866732596\n",
      "10 Train Loss 0.6690425 Test MSE 6.805560127240192 Test RE 0.049950451649611115\n",
      "11 Train Loss 0.65964264 Test MSE 7.595390052543021 Test RE 0.05276944451196796\n",
      "12 Train Loss 0.63647896 Test MSE 8.032964249981662 Test RE 0.054268197749451456\n",
      "13 Train Loss 0.60575396 Test MSE 8.36289729018234 Test RE 0.055371445771873015\n",
      "14 Train Loss 0.52686256 Test MSE 6.795860887322802 Test RE 0.049914844429299596\n",
      "15 Train Loss 0.18834804 Test MSE 0.8194689683889941 Test RE 0.017333000037948843\n",
      "16 Train Loss 0.13911086 Test MSE 0.5242347686034322 Test RE 0.013863420373470095\n",
      "17 Train Loss 0.13356812 Test MSE 0.47494262278500193 Test RE 0.013195566962000164\n",
      "18 Train Loss 0.13234586 Test MSE 0.5741042695797193 Test RE 0.014507843768895485\n",
      "19 Train Loss 0.1321103 Test MSE 0.5947304205090664 Test RE 0.014766159607850294\n",
      "20 Train Loss 0.108776145 Test MSE 0.643498096624941 Test RE 0.015359642769665048\n",
      "21 Train Loss 0.099263825 Test MSE 0.34524274934476407 Test RE 0.011250446661664795\n",
      "22 Train Loss 0.09655604 Test MSE 0.3004321442291258 Test RE 0.010494957409934435\n",
      "23 Train Loss 0.064354435 Test MSE 0.5101265792421649 Test RE 0.013675602152547085\n",
      "24 Train Loss 0.013604724 Test MSE 0.06841664561399699 Test RE 0.005008277339961504\n",
      "25 Train Loss 0.012741257 Test MSE 0.028122726524058145 Test RE 0.003210969597898197\n",
      "26 Train Loss 0.011307708 Test MSE 0.019841656943220095 Test RE 0.002697096280148522\n",
      "27 Train Loss 0.010326096 Test MSE 0.013573629144084155 Test RE 0.002230773472756425\n",
      "28 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "29 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "30 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "31 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "32 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "33 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "34 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "35 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "36 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "37 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "38 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "39 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "40 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "41 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "42 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "43 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "44 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "45 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "46 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "47 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "48 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "49 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "50 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "51 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "52 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "53 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "54 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "55 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "56 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "57 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "58 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "59 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "60 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "61 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "62 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "63 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "64 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "65 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "66 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "67 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "68 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "69 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "70 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "71 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "72 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "73 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "74 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "75 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "76 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "77 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "78 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "79 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "80 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "81 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "82 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "83 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "84 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "85 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "86 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "87 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "88 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "89 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "90 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "91 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "92 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "93 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "94 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "95 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "96 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "97 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "98 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "99 Train Loss 0.0102744065 Test MSE 0.012563684404312818 Test RE 0.0021461792470344942\n",
      "Training time: 7.53\n",
      "Training time: 7.53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 62.14723 Test MSE 2176.8633932710545 Test RE 0.8933529377178523\n",
      "1 Train Loss 57.266277 Test MSE 1678.317875980486 Test RE 0.7844126556844043\n",
      "2 Train Loss 48.668774 Test MSE 1295.439194818255 Test RE 0.6891535509451779\n",
      "3 Train Loss 45.793575 Test MSE 1292.3594814045243 Test RE 0.6883338836212559\n",
      "4 Train Loss 40.426422 Test MSE 1259.2189446184182 Test RE 0.6794509437942448\n",
      "5 Train Loss 19.879326 Test MSE 406.4524657116485 Test RE 0.38602227246267296\n",
      "6 Train Loss 9.225222 Test MSE 196.1868056784891 Test RE 0.2681898761988533\n",
      "7 Train Loss 7.1673346 Test MSE 141.11627429864075 Test RE 0.22745528523320407\n",
      "8 Train Loss 5.9058046 Test MSE 126.73770601993571 Test RE 0.21555614237714213\n",
      "9 Train Loss 2.879113 Test MSE 50.17931786990222 Test RE 0.13563440245588998\n",
      "10 Train Loss 2.3542185 Test MSE 31.724920231629174 Test RE 0.10784692113606824\n",
      "11 Train Loss 2.1126077 Test MSE 26.028569383790963 Test RE 0.09768606845770605\n",
      "12 Train Loss 1.1255969 Test MSE 22.94043530976067 Test RE 0.09170822949699282\n",
      "13 Train Loss 0.7760845 Test MSE 19.858410945831288 Test RE 0.08532567421359567\n",
      "14 Train Loss 0.70885843 Test MSE 20.6834957274805 Test RE 0.08708020690224906\n",
      "15 Train Loss 0.6966915 Test MSE 21.42780171023132 Test RE 0.08863317181583197\n",
      "16 Train Loss 0.57938415 Test MSE 18.110794488669523 Test RE 0.08148473040613657\n",
      "17 Train Loss 0.46579468 Test MSE 13.839614584332367 Test RE 0.07123107188416093\n",
      "18 Train Loss 0.44782585 Test MSE 12.27838658057275 Test RE 0.06709314241221438\n",
      "19 Train Loss 0.4159593 Test MSE 10.09789669003893 Test RE 0.060844726514560486\n",
      "20 Train Loss 0.3035577 Test MSE 7.617679403839611 Test RE 0.05284681611688656\n",
      "21 Train Loss 0.19863662 Test MSE 5.746369496818265 Test RE 0.04589910908359985\n",
      "22 Train Loss 0.15313911 Test MSE 4.0435023951475895 Test RE 0.038502269904501334\n",
      "23 Train Loss 0.12336979 Test MSE 2.9977707346285825 Test RE 0.03315176762252691\n",
      "24 Train Loss 0.09998759 Test MSE 2.176527103145972 Test RE 0.02824811818477732\n",
      "25 Train Loss 0.085507184 Test MSE 1.4023451292860483 Test RE 0.022674354745496558\n",
      "26 Train Loss 0.07327833 Test MSE 0.9988934933479526 Test RE 0.01913670111293095\n",
      "27 Train Loss 0.06460174 Test MSE 0.6959692823847264 Test RE 0.015973589435242304\n",
      "28 Train Loss 0.0597894 Test MSE 0.4762390490003967 Test RE 0.013213564315728867\n",
      "29 Train Loss 0.057727538 Test MSE 0.33145425052778427 Test RE 0.011023494205400417\n",
      "30 Train Loss 0.05740319 Test MSE 0.2703521637828501 Test RE 0.00995571387747445\n",
      "31 Train Loss 0.057400446 Test MSE 0.2685589379217262 Test RE 0.00992264118799082\n",
      "32 Train Loss 0.057400446 Test MSE 0.2685589379217262 Test RE 0.00992264118799082\n",
      "33 Train Loss 0.057399526 Test MSE 0.2684304218340566 Test RE 0.009920266715497155\n",
      "34 Train Loss 0.057397746 Test MSE 0.2656509134536201 Test RE 0.009868772524241653\n",
      "35 Train Loss 0.057397746 Test MSE 0.2656509134536201 Test RE 0.009868772524241653\n",
      "36 Train Loss 0.057397746 Test MSE 0.2656509134536201 Test RE 0.009868772524241653\n",
      "37 Train Loss 0.057397746 Test MSE 0.2656509134536201 Test RE 0.009868772524241653\n",
      "38 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "39 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "40 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "41 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "42 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "43 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "44 Train Loss 0.057397746 Test MSE 0.26565096853148507 Test RE 0.00986877354729647\n",
      "45 Train Loss 0.057397746 Test MSE 0.2656509136789183 Test RE 0.0098687725284265\n",
      "46 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "47 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "48 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "49 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "50 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "51 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "52 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "53 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "54 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "55 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "56 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "57 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "58 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "59 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "60 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "61 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "62 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "63 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "64 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "65 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "66 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "67 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "68 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "69 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "70 Train Loss 0.057396386 Test MSE 0.26567514645648754 Test RE 0.009869222634757237\n",
      "71 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "72 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "73 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "74 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "75 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "76 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "77 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "78 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "79 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "80 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "81 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "82 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "83 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "84 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "85 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "86 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "87 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "88 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "89 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "90 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "91 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "92 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "93 Train Loss 0.057396386 Test MSE 0.26567513815485894 Test RE 0.009869222480563999\n",
      "94 Train Loss 0.057396386 Test MSE 0.2656750770023008 Test RE 0.009869221344725244\n",
      "95 Train Loss 0.057396386 Test MSE 0.2656750770023008 Test RE 0.009869221344725244\n",
      "96 Train Loss 0.057396386 Test MSE 0.2656750770023008 Test RE 0.009869221344725244\n",
      "97 Train Loss 0.057396386 Test MSE 0.2656750770023008 Test RE 0.009869221344725244\n",
      "98 Train Loss 0.057396386 Test MSE 0.2656750770023008 Test RE 0.009869221344725244\n",
      "99 Train Loss 0.057396386 Test MSE 0.2656750770023008 Test RE 0.009869221344725244\n",
      "Training time: 10.42\n",
      "Training time: 10.42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 61.822124 Test MSE 2189.5611212450026 Test RE 0.8959546303292468\n",
      "1 Train Loss 51.270405 Test MSE 1576.271332305661 Test RE 0.76019143182919\n",
      "2 Train Loss 40.491875 Test MSE 1249.939666563261 Test RE 0.6769428524034782\n",
      "3 Train Loss 37.397724 Test MSE 1175.0453032382197 Test RE 0.6563489385560137\n",
      "4 Train Loss 27.20569 Test MSE 665.7798529904533 Test RE 0.49405216440784205\n",
      "5 Train Loss 13.498688 Test MSE 352.902888766788 Test RE 0.3596955694888203\n",
      "6 Train Loss 8.893059 Test MSE 186.38270361398494 Test RE 0.2614028302094725\n",
      "7 Train Loss 5.3135476 Test MSE 94.48456622111509 Test RE 0.18611780352958424\n",
      "8 Train Loss 3.288951 Test MSE 54.003244530122295 Test RE 0.1407075523272106\n",
      "9 Train Loss 1.4880943 Test MSE 33.8049255696681 Test RE 0.11132622272811513\n",
      "10 Train Loss 1.4124787 Test MSE 32.694266043081704 Test RE 0.10948214003456902\n",
      "11 Train Loss 0.3222721 Test MSE 4.311420513378792 Test RE 0.039757372388944744\n",
      "12 Train Loss 0.049928658 Test MSE 0.3068416499475204 Test RE 0.010606317814711545\n",
      "13 Train Loss 0.029007915 Test MSE 0.09003308629824511 Test RE 0.005745244963562268\n",
      "14 Train Loss 0.029001081 Test MSE 0.09160891091707316 Test RE 0.005795305594247601\n",
      "15 Train Loss 0.029001081 Test MSE 0.09160891091707316 Test RE 0.005795305594247601\n",
      "16 Train Loss 0.029001081 Test MSE 0.09160891091707316 Test RE 0.005795305594247601\n",
      "17 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "18 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "19 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "20 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "21 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "22 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "23 Train Loss 0.028999532 Test MSE 0.09157768572137581 Test RE 0.005794317835675393\n",
      "24 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "25 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "26 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "27 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "28 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "29 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "30 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "31 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "32 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "33 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "34 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "35 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "36 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "37 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "38 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "39 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "40 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "41 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "42 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "43 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "44 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "45 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "46 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "47 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "48 Train Loss 0.028999154 Test MSE 0.09154977742986874 Test RE 0.0057934348594782656\n",
      "49 Train Loss 0.028967405 Test MSE 0.10012427686202674 Test RE 0.0060586683225519805\n",
      "50 Train Loss 0.024522128 Test MSE 0.08247136759733549 Test RE 0.005498688023006985\n",
      "51 Train Loss 0.009270767 Test MSE 0.020532689613186907 Test RE 0.0027436607020455634\n",
      "52 Train Loss 0.0023391207 Test MSE 0.004318757042893926 Test RE 0.0012583077407204639\n",
      "53 Train Loss 0.0016572961 Test MSE 0.002078364840895469 Test RE 0.0008729078020989153\n",
      "54 Train Loss 0.0016565841 Test MSE 0.0020878891916878833 Test RE 0.0008749056171317757\n",
      "55 Train Loss 0.0016563578 Test MSE 0.002100511060924778 Test RE 0.0008775461560020814\n",
      "56 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "57 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "58 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "59 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "60 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "61 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "62 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "63 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "64 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "65 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "66 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "67 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "68 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "69 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "70 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "71 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "72 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "73 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "74 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "75 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "76 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "77 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "78 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "79 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "80 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "81 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "82 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "83 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "84 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "85 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "86 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "87 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "88 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "89 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "90 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "91 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "92 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "93 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "94 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "95 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "96 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "97 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "98 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "99 Train Loss 0.001655971 Test MSE 0.0021287478377202064 Test RE 0.0008834248098557236\n",
      "Training time: 5.91\n",
      "Training time: 5.91\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 63.044037 Test MSE 2267.925350849513 Test RE 0.9118467605777071\n",
      "1 Train Loss 58.277573 Test MSE 1961.5108199662216 Test RE 0.8480136361827114\n",
      "2 Train Loss 49.934666 Test MSE 1608.5244469458232 Test RE 0.7679294352534677\n",
      "3 Train Loss 41.87315 Test MSE 1148.5974177922908 Test RE 0.6489203587030077\n",
      "4 Train Loss 31.570213 Test MSE 689.1409052017526 Test RE 0.5026451498419371\n",
      "5 Train Loss 19.348421 Test MSE 475.39978761688843 Test RE 0.41748124839354317\n",
      "6 Train Loss 14.936861 Test MSE 278.5270809826546 Test RE 0.3195517465842301\n",
      "7 Train Loss 13.125524 Test MSE 289.3011946280416 Test RE 0.3256736302969671\n",
      "8 Train Loss 9.13703 Test MSE 132.50830845688577 Test RE 0.2204088541491934\n",
      "9 Train Loss 7.2359023 Test MSE 120.43007426409429 Test RE 0.2101236609619172\n",
      "10 Train Loss 4.823686 Test MSE 54.02447841323827 Test RE 0.14073521246234205\n",
      "11 Train Loss 4.005525 Test MSE 42.86585410769822 Test RE 0.1253612236256913\n",
      "12 Train Loss 3.5902905 Test MSE 69.74045551973369 Test RE 0.1599005183615754\n",
      "13 Train Loss 2.2996974 Test MSE 16.638031504165074 Test RE 0.07810133419389537\n",
      "14 Train Loss 2.075287 Test MSE 15.686938031132735 Test RE 0.07583620157174456\n",
      "15 Train Loss 1.2281766 Test MSE 24.036028421178656 Test RE 0.09387259772603516\n",
      "16 Train Loss 1.030119 Test MSE 7.014566450910722 Test RE 0.05071166836645321\n",
      "17 Train Loss 0.74684334 Test MSE 5.315953759429775 Test RE 0.04414668310566115\n",
      "18 Train Loss 0.6217484 Test MSE 4.327669384331286 Test RE 0.03983222067655049\n",
      "19 Train Loss 0.5864046 Test MSE 3.675216559996329 Test RE 0.036707004845568596\n",
      "20 Train Loss 0.58364826 Test MSE 3.757307161648193 Test RE 0.03711468952690264\n",
      "21 Train Loss 0.54684854 Test MSE 4.063676176740545 Test RE 0.03859819787696107\n",
      "22 Train Loss 0.45768252 Test MSE 1.8589788234788325 Test RE 0.026106262650134483\n",
      "23 Train Loss 0.4377325 Test MSE 1.6685215293358568 Test RE 0.024732805898807213\n",
      "24 Train Loss 0.34170422 Test MSE 1.8209567599318115 Test RE 0.025837905077623975\n",
      "25 Train Loss 0.31453693 Test MSE 1.533746616531872 Test RE 0.023712879294404653\n",
      "26 Train Loss 0.3045332 Test MSE 1.2116960673791557 Test RE 0.021076783328815768\n",
      "27 Train Loss 0.29930642 Test MSE 1.1974049095727857 Test RE 0.020952121266483652\n",
      "28 Train Loss 0.29206067 Test MSE 1.0393015726855546 Test RE 0.019519930813308783\n",
      "29 Train Loss 0.27988082 Test MSE 1.312878634774856 Test RE 0.021939148724262458\n",
      "30 Train Loss 0.24509786 Test MSE 1.5768690250665829 Test RE 0.024043921031028738\n",
      "31 Train Loss 0.20881899 Test MSE 0.9787425793839402 Test RE 0.018942693093719314\n",
      "32 Train Loss 0.20393708 Test MSE 1.0327980954635056 Test RE 0.019458761539926532\n",
      "33 Train Loss 0.18940213 Test MSE 1.0167554393568778 Test RE 0.019307041673836324\n",
      "34 Train Loss 0.18008062 Test MSE 0.674322202461082 Test RE 0.015723209873977323\n",
      "35 Train Loss 0.1757146 Test MSE 0.405561103454566 Test RE 0.012193703477681499\n",
      "36 Train Loss 0.16858982 Test MSE 0.5309660633300262 Test RE 0.013952141232260197\n",
      "37 Train Loss 0.16113198 Test MSE 0.7870198950655115 Test RE 0.01698636051771047\n",
      "38 Train Loss 0.12926687 Test MSE 0.8453010240791793 Test RE 0.017604073751073618\n",
      "39 Train Loss 0.07081026 Test MSE 0.47069789685437025 Test RE 0.013136467953385033\n",
      "40 Train Loss 0.06850531 Test MSE 0.4506965441005819 Test RE 0.01285433446072608\n",
      "41 Train Loss 0.0652696 Test MSE 0.30100260275103485 Test RE 0.010504916561630093\n",
      "42 Train Loss 0.06458384 Test MSE 0.26091576917573067 Test RE 0.009780423165430723\n",
      "43 Train Loss 0.06454851 Test MSE 0.25773141301890573 Test RE 0.009720557177357238\n",
      "44 Train Loss 0.06454851 Test MSE 0.25773141301890573 Test RE 0.009720557177357238\n",
      "45 Train Loss 0.0639574 Test MSE 0.23299085351831228 Test RE 0.009242233104480852\n",
      "46 Train Loss 0.06343591 Test MSE 0.24013455687498172 Test RE 0.009382850851888593\n",
      "47 Train Loss 0.06312997 Test MSE 0.26769665046990465 Test RE 0.009906698601749057\n",
      "48 Train Loss 0.06308566 Test MSE 0.2731322095264015 Test RE 0.010006770527449737\n",
      "49 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "50 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "51 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "52 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "53 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "54 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "55 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "56 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "57 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "58 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "59 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "60 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "61 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "62 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "63 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "64 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "65 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "66 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "67 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "68 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "69 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "70 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "71 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "72 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "73 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "74 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "75 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "76 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "77 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "78 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "79 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "80 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "81 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "82 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "83 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "84 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "85 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "86 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "87 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "88 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "89 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "90 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "91 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "92 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "93 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "94 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "95 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "96 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "97 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "98 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "99 Train Loss 0.06302813 Test MSE 0.2847577160279675 Test RE 0.01021751378314758\n",
      "Training time: 12.60\n",
      "Training time: 12.60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 58.39013 Test MSE 1956.3984067248546 Test RE 0.8469077986079346\n",
      "1 Train Loss 44.56556 Test MSE 1434.5672286548652 Test RE 0.7252169308828785\n",
      "2 Train Loss 37.322266 Test MSE 1067.0079742491175 Test RE 0.6254481529879408\n",
      "3 Train Loss 34.23342 Test MSE 1097.2198300792477 Test RE 0.6342409891539904\n",
      "4 Train Loss 19.753231 Test MSE 591.1467279881413 Test RE 0.4655379896539881\n",
      "5 Train Loss 8.1593685 Test MSE 183.1271835677284 Test RE 0.2591098302867261\n",
      "6 Train Loss 7.3101315 Test MSE 118.71798507875695 Test RE 0.20862470725711316\n",
      "7 Train Loss 4.9116507 Test MSE 86.32190101214685 Test RE 0.17789673596881922\n",
      "8 Train Loss 1.9313773 Test MSE 7.671526256260372 Test RE 0.05303326552887201\n",
      "9 Train Loss 1.2802628 Test MSE 13.84946182597797 Test RE 0.07125640874763785\n",
      "10 Train Loss 0.63223267 Test MSE 2.342637808408632 Test RE 0.029306236894957514\n",
      "11 Train Loss 0.5857278 Test MSE 1.1675105334040012 Test RE 0.020688923108588185\n",
      "12 Train Loss 0.33556283 Test MSE 1.195944962915534 Test RE 0.020939344339973257\n",
      "13 Train Loss 0.17970172 Test MSE 1.1226945503564878 Test RE 0.020287955754350002\n",
      "14 Train Loss 0.15484884 Test MSE 0.5400758112520831 Test RE 0.014071320179731015\n",
      "15 Train Loss 0.1116984 Test MSE 0.8456537124732667 Test RE 0.017607745877826753\n",
      "16 Train Loss 0.09040771 Test MSE 0.4256694500068106 Test RE 0.012492337904598779\n",
      "17 Train Loss 0.06721264 Test MSE 0.19273613101080259 Test RE 0.008405993505464246\n",
      "18 Train Loss 0.04887484 Test MSE 0.03077916917174803 Test RE 0.003359200514205418\n",
      "19 Train Loss 0.03229574 Test MSE 0.022346905412392017 Test RE 0.002862306765966363\n",
      "20 Train Loss 0.029762417 Test MSE 0.019483242602982353 Test RE 0.0026726254580238494\n",
      "21 Train Loss 0.025174607 Test MSE 0.00872510773079767 Test RE 0.0017885162104073397\n",
      "22 Train Loss 0.023174362 Test MSE 0.009223183111826927 Test RE 0.0018388567456267652\n",
      "23 Train Loss 0.01597612 Test MSE 0.009203691368510713 Test RE 0.0018369126510466502\n",
      "24 Train Loss 0.015670858 Test MSE 0.005093413988033078 Test RE 0.001366507344183341\n",
      "25 Train Loss 0.01419326 Test MSE 0.008671787518155762 Test RE 0.0017830429136935833\n",
      "26 Train Loss 0.01308975 Test MSE 0.004255678675397074 Test RE 0.0012490847219487982\n",
      "27 Train Loss 0.011684524 Test MSE 0.007586239041278651 Test RE 0.0016677108081262085\n",
      "28 Train Loss 0.01143763 Test MSE 0.006719008258630755 Test RE 0.001569495479713842\n",
      "29 Train Loss 0.010686257 Test MSE 0.004738866096318539 Test RE 0.0013180888929310716\n",
      "30 Train Loss 0.0101097245 Test MSE 0.008387505696561312 Test RE 0.0017535731852715579\n",
      "31 Train Loss 0.009865391 Test MSE 0.010217202740564323 Test RE 0.001935412258169642\n",
      "32 Train Loss 0.0077947117 Test MSE 0.0025291628722537473 Test RE 0.0009629325794415083\n",
      "33 Train Loss 0.0061065736 Test MSE 0.0011392084338197694 Test RE 0.0006462626803887451\n",
      "34 Train Loss 0.0052640256 Test MSE 0.0013439664591825533 Test RE 0.0007019427567206677\n",
      "35 Train Loss 0.004889955 Test MSE 0.0009939141112486783 Test RE 0.000603645420276255\n",
      "36 Train Loss 0.003972199 Test MSE 0.001049385096347844 Test RE 0.0006202616466266415\n",
      "37 Train Loss 0.0034066006 Test MSE 0.0010021476676982841 Test RE 0.0006061405543422009\n",
      "38 Train Loss 0.003091593 Test MSE 0.0008287192840248832 Test RE 0.0005512025324190718\n",
      "39 Train Loss 0.0030654904 Test MSE 0.0006917356556860644 Test RE 0.0005035905395027251\n",
      "40 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "41 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "42 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "43 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "44 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "45 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "46 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "47 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "48 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "49 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "50 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "51 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "52 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "53 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "54 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "55 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "56 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "57 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "58 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "59 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "60 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "61 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "62 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "63 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "64 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "65 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "66 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "67 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "68 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "69 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "70 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "71 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "72 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "73 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "74 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "75 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "76 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "77 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "78 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "79 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "80 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "81 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "82 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "83 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "84 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "85 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "86 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "87 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "88 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "89 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "90 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "91 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "92 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "93 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "94 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "95 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "96 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "97 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "98 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "99 Train Loss 0.0030649293 Test MSE 0.0006988828166178159 Test RE 0.000506185456567625\n",
      "Training time: 9.11\n",
      "Training time: 9.11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 62.506157 Test MSE 2203.183998698286 Test RE 0.8987375063169649\n",
      "1 Train Loss 54.181267 Test MSE 1813.3251263664183 Test RE 0.8153523391552379\n",
      "2 Train Loss 35.547802 Test MSE 1204.4491412910163 Test RE 0.6645102969288451\n",
      "3 Train Loss 13.669431 Test MSE 240.9441822064503 Test RE 0.2972115646047758\n",
      "4 Train Loss 7.276478 Test MSE 196.76518753499758 Test RE 0.2685849129623692\n",
      "5 Train Loss 2.942182 Test MSE 33.011985687639076 Test RE 0.1100128221781275\n",
      "6 Train Loss 2.8225317 Test MSE 27.093293117940835 Test RE 0.09966401515586358\n",
      "7 Train Loss 2.4694424 Test MSE 22.391329109550384 Test RE 0.09060400981049717\n",
      "8 Train Loss 1.8964597 Test MSE 14.174750361041253 Test RE 0.0720883676032041\n",
      "9 Train Loss 1.6624357 Test MSE 12.359603234876214 Test RE 0.0673146739351248\n",
      "10 Train Loss 1.3234344 Test MSE 10.281147975140163 Test RE 0.06139433318118597\n",
      "11 Train Loss 0.83807653 Test MSE 4.675399576749703 Test RE 0.041401573617367016\n",
      "12 Train Loss 0.33142352 Test MSE 3.5713146160502927 Test RE 0.036184413472888165\n",
      "13 Train Loss 0.22780795 Test MSE 1.4292870207415065 Test RE 0.022891128681568805\n",
      "14 Train Loss 0.20770739 Test MSE 0.9546520792336054 Test RE 0.018708115529586677\n",
      "15 Train Loss 0.20328736 Test MSE 0.5712291536052332 Test RE 0.01447147050894208\n",
      "16 Train Loss 0.10679015 Test MSE 0.47579184250989 Test RE 0.013207358840109519\n",
      "17 Train Loss 0.09232453 Test MSE 0.5351503717717655 Test RE 0.014007008671523845\n",
      "18 Train Loss 0.04479617 Test MSE 0.128699638078506 Test RE 0.006869041569079389\n",
      "19 Train Loss 0.044138722 Test MSE 0.15465332597863962 Test RE 0.0075298636823065085\n",
      "20 Train Loss 0.042344995 Test MSE 0.14082884065114165 Test RE 0.00718543861885275\n",
      "21 Train Loss 0.042074718 Test MSE 0.12730747904682416 Test RE 0.006831788940789317\n",
      "22 Train Loss 0.038442925 Test MSE 0.13045351055178125 Test RE 0.006915687604477954\n",
      "23 Train Loss 0.02504055 Test MSE 0.18766917325025992 Test RE 0.008294762434678669\n",
      "24 Train Loss 0.02118874 Test MSE 0.12664622014750057 Test RE 0.0068140230450027634\n",
      "25 Train Loss 0.019014059 Test MSE 0.09809009459263615 Test RE 0.005996806815441746\n",
      "26 Train Loss 0.011075988 Test MSE 0.03003020546819941 Test RE 0.003318078325434747\n",
      "27 Train Loss 0.005401928 Test MSE 0.010346947624405555 Test RE 0.0019476620723582914\n",
      "28 Train Loss 0.005285891 Test MSE 0.011364508113988692 Test RE 0.0020411870450803378\n",
      "29 Train Loss 0.005232358 Test MSE 0.011687553124387611 Test RE 0.0020699949251938876\n",
      "30 Train Loss 0.005217352 Test MSE 0.013311364831043594 Test RE 0.0022091172915128998\n",
      "31 Train Loss 0.0052133673 Test MSE 0.013758055786437618 Test RE 0.0022458772444593094\n",
      "32 Train Loss 0.0052127955 Test MSE 0.013692391804402576 Test RE 0.0022405113108447767\n",
      "33 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "34 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "35 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "36 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "37 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "38 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "39 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "40 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "41 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "42 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "43 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "44 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "45 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "46 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "47 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "48 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "49 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "50 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "51 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "52 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "53 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "54 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "55 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "56 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "57 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "58 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "59 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "60 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "61 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "62 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "63 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "64 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "65 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "66 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "67 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "68 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "69 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "70 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "71 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "72 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "73 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "74 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "75 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "76 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "77 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "78 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "79 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "80 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "81 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "82 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "83 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "84 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "85 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "86 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "87 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "88 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "89 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "90 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "91 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "92 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "93 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "94 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "95 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "96 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "97 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "98 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "99 Train Loss 0.005212464 Test MSE 0.01365258148203497 Test RE 0.0022372518216805123\n",
      "Training time: 7.82\n",
      "Training time: 7.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 62.92569 Test MSE 2204.4516005576306 Test RE 0.8989960134403482\n",
      "1 Train Loss 60.47538 Test MSE 2125.247563029063 Test RE 0.8826982086059644\n",
      "2 Train Loss 55.030666 Test MSE 1659.4714556280273 Test RE 0.779995999151919\n",
      "3 Train Loss 48.116333 Test MSE 1126.5203560840107 Test RE 0.6426536872566591\n",
      "4 Train Loss 36.49654 Test MSE 898.4406271952016 Test RE 0.5739210752073386\n",
      "5 Train Loss 23.779287 Test MSE 697.0689400025713 Test RE 0.5055281543270468\n",
      "6 Train Loss 21.57709 Test MSE 442.9446129639988 Test RE 0.40297879499927713\n",
      "7 Train Loss 14.02883 Test MSE 274.59173398860014 Test RE 0.31728622059865236\n",
      "8 Train Loss 10.339022 Test MSE 161.44083389264352 Test RE 0.24328435299013634\n",
      "9 Train Loss 8.625403 Test MSE 180.6370177189758 Test RE 0.25734211091125947\n",
      "10 Train Loss 5.6676235 Test MSE 80.06278757857228 Test RE 0.17132582638491264\n",
      "11 Train Loss 3.1699286 Test MSE 11.656574829894303 Test RE 0.0653721787850793\n",
      "12 Train Loss 1.6604561 Test MSE 22.172297887280806 Test RE 0.09015977809962632\n",
      "13 Train Loss 1.617842 Test MSE 23.28022069736002 Test RE 0.09238490750700037\n",
      "14 Train Loss 1.4535698 Test MSE 23.230252939837886 Test RE 0.09228570856849778\n",
      "15 Train Loss 1.4250993 Test MSE 23.870537678359256 Test RE 0.09354887788680426\n",
      "16 Train Loss 1.4178356 Test MSE 23.438350531685067 Test RE 0.09269813663796125\n",
      "17 Train Loss 1.4018724 Test MSE 21.267645958676532 Test RE 0.08830131938607282\n",
      "18 Train Loss 1.2067944 Test MSE 22.514829788209898 Test RE 0.09085353206417893\n",
      "19 Train Loss 1.1371074 Test MSE 16.560058800171678 Test RE 0.07791811168416031\n",
      "20 Train Loss 0.9689376 Test MSE 11.894929855904113 Test RE 0.06603716559179608\n",
      "21 Train Loss 0.829649 Test MSE 12.176639284592524 Test RE 0.06681457376398982\n",
      "22 Train Loss 0.5809416 Test MSE 5.023183517891647 Test RE 0.04291380310886176\n",
      "23 Train Loss 0.39427984 Test MSE 7.195516946330736 Test RE 0.05136159262948697\n",
      "24 Train Loss 0.20664483 Test MSE 2.920111916544812 Test RE 0.03271954306823022\n",
      "25 Train Loss 0.09311673 Test MSE 0.6146155163112293 Test RE 0.015010986757030558\n",
      "26 Train Loss 0.06351874 Test MSE 0.04660248864120319 Test RE 0.004133443792945254\n",
      "27 Train Loss 0.049808312 Test MSE 0.05472147810991169 Test RE 0.004479054962346192\n",
      "28 Train Loss 0.042021558 Test MSE 0.18117533873680544 Test RE 0.008149989003628226\n",
      "29 Train Loss 0.034631852 Test MSE 0.1887651303991166 Test RE 0.008318947202450412\n",
      "30 Train Loss 0.025552383 Test MSE 0.047497623511684094 Test RE 0.004172952316621615\n",
      "31 Train Loss 0.019841831 Test MSE 0.018546366140591432 Test RE 0.0026075755273828956\n",
      "32 Train Loss 0.014431277 Test MSE 0.016797790484741445 Test RE 0.0024816101788762857\n",
      "33 Train Loss 0.0122063495 Test MSE 0.012472860982586542 Test RE 0.002138407764840281\n",
      "34 Train Loss 0.011031054 Test MSE 0.0065235538732467575 Test RE 0.0015464988749881229\n",
      "35 Train Loss 0.010293056 Test MSE 0.007492503224312509 Test RE 0.0016573756389093848\n",
      "36 Train Loss 0.009050592 Test MSE 0.014720327200147302 Test RE 0.002323090953149084\n",
      "37 Train Loss 0.008004456 Test MSE 0.008913655128142356 Test RE 0.0018077376171262284\n",
      "38 Train Loss 0.0073876637 Test MSE 0.008132839765054904 Test RE 0.0017267465210675983\n",
      "39 Train Loss 0.0070968475 Test MSE 0.006084952873807419 Test RE 0.0014936061436500595\n",
      "40 Train Loss 0.006493518 Test MSE 0.009812190412416289 Test RE 0.0018966642813169426\n",
      "41 Train Loss 0.005680514 Test MSE 0.010033112957016388 Test RE 0.0019178972332958703\n",
      "42 Train Loss 0.0050388197 Test MSE 0.00689671506942545 Test RE 0.001590115327066013\n",
      "43 Train Loss 0.0040675146 Test MSE 0.004620978985278837 Test RE 0.001301590824873936\n",
      "44 Train Loss 0.0029831876 Test MSE 0.00589640539888584 Test RE 0.001470283723104034\n",
      "45 Train Loss 0.001589313 Test MSE 0.0021737575819718406 Test RE 0.0008927154204500558\n",
      "46 Train Loss 0.001399374 Test MSE 0.0006606422309862371 Test RE 0.0004921422470545129\n",
      "47 Train Loss 0.0010342487 Test MSE 0.0009536466654863156 Test RE 0.0005912909460577963\n",
      "48 Train Loss 0.0008261966 Test MSE 0.0006383112237649835 Test RE 0.000483753056726507\n",
      "49 Train Loss 0.0007314459 Test MSE 0.0005152844864035813 Test RE 0.00043464132451818483\n",
      "50 Train Loss 0.0006973677 Test MSE 0.0005934190819687721 Test RE 0.00046643188993212735\n",
      "51 Train Loss 0.0006916753 Test MSE 0.0005619358576227468 Test RE 0.00045389025088671655\n",
      "52 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "53 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "54 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "55 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "56 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "57 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "58 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "59 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "60 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "61 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "62 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "63 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "64 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "65 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "66 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "67 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "68 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "69 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "70 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "71 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "72 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "73 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "74 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "75 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "76 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "77 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "78 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "79 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "80 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "81 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "82 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "83 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "84 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "85 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "86 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "87 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "88 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "89 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "90 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "91 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "92 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "93 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "94 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "95 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "96 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "97 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "98 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "99 Train Loss 0.00069134566 Test MSE 0.0005822503147454593 Test RE 0.00046202167235037515\n",
      "Training time: 12.09\n",
      "Training time: 12.09\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 63.220863 Test MSE 2182.0396744265427 Test RE 0.8944144421511453\n",
      "1 Train Loss 46.7125 Test MSE 1354.8773470679205 Test RE 0.7047863310769462\n",
      "2 Train Loss 28.164444 Test MSE 877.6438791309828 Test RE 0.5672397356277479\n",
      "3 Train Loss 21.167225 Test MSE 524.8638600040449 Test RE 0.43866281049244643\n",
      "4 Train Loss 16.970474 Test MSE 491.83956443158314 Test RE 0.4246383487485828\n",
      "5 Train Loss 15.360649 Test MSE 438.3504917040907 Test RE 0.40088354555404176\n",
      "6 Train Loss 13.256567 Test MSE 346.3353670118185 Test RE 0.35633288436362526\n",
      "7 Train Loss 10.735482 Test MSE 249.36096257106828 Test RE 0.302358174522087\n",
      "8 Train Loss 9.789374 Test MSE 202.71086056515375 Test RE 0.2726126412089725\n",
      "9 Train Loss 9.15816 Test MSE 197.02376628193835 Test RE 0.2687613352987242\n",
      "10 Train Loss 8.3501625 Test MSE 182.83371529502884 Test RE 0.2589021303654472\n",
      "11 Train Loss 6.7413936 Test MSE 142.82803176303509 Test RE 0.22883065700041544\n",
      "12 Train Loss 4.9613667 Test MSE 91.03998243989263 Test RE 0.1826936970552267\n",
      "13 Train Loss 3.4327304 Test MSE 56.66103123247961 Test RE 0.1441284509522623\n",
      "14 Train Loss 2.2778547 Test MSE 26.752057757276656 Test RE 0.0990344008499838\n",
      "15 Train Loss 1.7076542 Test MSE 27.56839088553363 Test RE 0.10053405285509227\n",
      "16 Train Loss 0.82365304 Test MSE 10.203485393068023 Test RE 0.061162010831140805\n",
      "17 Train Loss 0.6089074 Test MSE 5.724730783860582 Test RE 0.0458126079966237\n",
      "18 Train Loss 0.5508469 Test MSE 11.484047301484274 Test RE 0.06488659252794338\n",
      "19 Train Loss 0.5231698 Test MSE 9.234398954803666 Test RE 0.05818510180472942\n",
      "20 Train Loss 0.39694908 Test MSE 8.773687082062166 Test RE 0.05671508042724741\n",
      "21 Train Loss 0.2810863 Test MSE 4.751813708576146 Test RE 0.04173853339867981\n",
      "22 Train Loss 0.20066328 Test MSE 0.9155455097046681 Test RE 0.0183209272531929\n",
      "23 Train Loss 0.18242778 Test MSE 0.3315222553328633 Test RE 0.011024624998150602\n",
      "24 Train Loss 0.17945075 Test MSE 0.48006648410898295 Test RE 0.013266555406060334\n",
      "25 Train Loss 0.17515458 Test MSE 0.8297624941010708 Test RE 0.01744152207738142\n",
      "26 Train Loss 0.17515458 Test MSE 0.8297624941010708 Test RE 0.01744152207738142\n",
      "27 Train Loss 0.17515458 Test MSE 0.8297624941010708 Test RE 0.01744152207738142\n",
      "28 Train Loss 0.17515461 Test MSE 0.8297620151643718 Test RE 0.017441517043780674\n",
      "29 Train Loss 0.17515461 Test MSE 0.8297620151643718 Test RE 0.017441517043780674\n",
      "30 Train Loss 0.17515461 Test MSE 0.8297620151643718 Test RE 0.017441517043780674\n",
      "31 Train Loss 0.17515461 Test MSE 0.8297620151643718 Test RE 0.017441517043780674\n",
      "32 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "33 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "34 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "35 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "36 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "37 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "38 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "39 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "40 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "41 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "42 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "43 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "44 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "45 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "46 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "47 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "48 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "49 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "50 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "51 Train Loss 0.17515461 Test MSE 0.8297630725287026 Test RE 0.017441528156624957\n",
      "52 Train Loss 0.17515413 Test MSE 0.8297717977993878 Test RE 0.017441619858497036\n",
      "53 Train Loss 0.17515413 Test MSE 0.8297717977993878 Test RE 0.017441619858497036\n",
      "54 Train Loss 0.17515413 Test MSE 0.8297717977993878 Test RE 0.017441619858497036\n",
      "55 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "56 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "57 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "58 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "59 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "60 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "61 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "62 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "63 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "64 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "65 Train Loss 0.17515378 Test MSE 0.8297776363749441 Test RE 0.0174416812211732\n",
      "66 Train Loss 0.17515361 Test MSE 0.8297824064824421 Test RE 0.017441731354227618\n",
      "67 Train Loss 0.1751536 Test MSE 0.82978455821387 Test RE 0.017441753968527998\n",
      "68 Train Loss 0.1751536 Test MSE 0.82978455821387 Test RE 0.017441753968527998\n",
      "69 Train Loss 0.1751536 Test MSE 0.82978455821387 Test RE 0.017441753968527998\n",
      "70 Train Loss 0.1751536 Test MSE 0.82978455821387 Test RE 0.017441753968527998\n",
      "71 Train Loss 0.1751536 Test MSE 0.82978455821387 Test RE 0.017441753968527998\n",
      "72 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "73 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "74 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "75 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "76 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "77 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "78 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "79 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "80 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "81 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "82 Train Loss 0.17515245 Test MSE 0.8298147231561533 Test RE 0.01744207099342024\n",
      "83 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "84 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "85 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "86 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "87 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "88 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "89 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "90 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "91 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "92 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "93 Train Loss 0.17511305 Test MSE 0.8806145905862995 Test RE 0.01796802818691371\n",
      "94 Train Loss 0.17507891 Test MSE 0.8809852518139826 Test RE 0.017971809268207167\n",
      "95 Train Loss 0.17507891 Test MSE 0.8809852518139826 Test RE 0.017971809268207167\n",
      "96 Train Loss 0.17507891 Test MSE 0.8809852518139826 Test RE 0.017971809268207167\n",
      "97 Train Loss 0.17507891 Test MSE 0.8809852518139826 Test RE 0.017971809268207167\n",
      "98 Train Loss 0.17507891 Test MSE 0.8809852518139826 Test RE 0.017971809268207167\n",
      "99 Train Loss 0.17507891 Test MSE 0.8809852518139826 Test RE 0.017971809268207167\n",
      "Training time: 10.58\n",
      "Training time: 10.58\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 58.851223 Test MSE 1995.0052438906953 Test RE 0.8552232569436855\n",
      "1 Train Loss 51.436485 Test MSE 1625.4988247755246 Test RE 0.7719706904304723\n",
      "2 Train Loss 47.921295 Test MSE 1528.6301056307875 Test RE 0.7486152779246682\n",
      "3 Train Loss 45.4298 Test MSE 1388.670815259235 Test RE 0.7135216183461197\n",
      "4 Train Loss 38.837486 Test MSE 989.848834119282 Test RE 0.602409649326347\n",
      "5 Train Loss 31.22667 Test MSE 741.2918416250833 Test RE 0.5213172456416857\n",
      "6 Train Loss 22.984352 Test MSE 723.1223333932593 Test RE 0.5148887100534594\n",
      "7 Train Loss 16.444548 Test MSE 395.7654647797855 Test RE 0.38091355618700407\n",
      "8 Train Loss 14.3426 Test MSE 367.64068891420607 Test RE 0.36712948696729975\n",
      "9 Train Loss 8.629021 Test MSE 203.7582978269143 Test RE 0.2733160488226908\n",
      "10 Train Loss 3.304104 Test MSE 77.652924592706 Test RE 0.16872770145555513\n",
      "11 Train Loss 1.3111713 Test MSE 9.474209631464305 Test RE 0.058935772002210646\n",
      "12 Train Loss 1.234454 Test MSE 6.162088553590021 Test RE 0.04753039782933434\n",
      "13 Train Loss 0.6617242 Test MSE 4.924922846263088 Test RE 0.04249200240636819\n",
      "14 Train Loss 0.60363835 Test MSE 2.569774041290029 Test RE 0.03069410331907387\n",
      "15 Train Loss 0.39847508 Test MSE 2.7858683925441423 Test RE 0.03195860248237051\n",
      "16 Train Loss 0.15453498 Test MSE 0.390281855908508 Test RE 0.011961803463903119\n",
      "17 Train Loss 0.12814987 Test MSE 0.34677240596335335 Test RE 0.011275342622752392\n",
      "18 Train Loss 0.08417547 Test MSE 0.2754274224611684 Test RE 0.010048727533893412\n",
      "19 Train Loss 0.06078095 Test MSE 0.08423156390542023 Test RE 0.0055570577986302815\n",
      "20 Train Loss 0.052034777 Test MSE 0.10525143064773283 Test RE 0.006211857517292607\n",
      "21 Train Loss 0.045231417 Test MSE 0.12567072492241937 Test RE 0.006787729736661553\n",
      "22 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "23 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "24 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "25 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "26 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "27 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "28 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "29 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "30 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "31 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "32 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "33 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "34 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "35 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "36 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "37 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "38 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "39 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "40 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "41 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "42 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "43 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "44 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "45 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "46 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "47 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "48 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "49 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "50 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "51 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "52 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "53 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "54 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "55 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "56 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "57 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "58 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "59 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "60 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "61 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "62 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "63 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "64 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "65 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "66 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "67 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "68 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "69 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "70 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "71 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "72 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "73 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "74 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "75 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "76 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "77 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "78 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "79 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "80 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "81 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "82 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "83 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "84 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "85 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "86 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "87 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "88 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "89 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "90 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "91 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "92 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "93 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "94 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "95 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "96 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "97 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "98 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "99 Train Loss 0.04393925 Test MSE 0.17069082080143033 Test RE 0.007910657199113897\n",
      "Training time: 6.59\n",
      "Training time: 6.59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 64.556755 Test MSE 2350.9815848149806 Test RE 0.9283935091710874\n",
      "1 Train Loss 61.507927 Test MSE 2184.8059658779575 Test RE 0.894981211714901\n",
      "2 Train Loss 57.01083 Test MSE 1916.2315485529937 Test RE 0.8381687694812956\n",
      "3 Train Loss 47.07711 Test MSE 1389.3212261508118 Test RE 0.713688694624779\n",
      "4 Train Loss 36.821278 Test MSE 1171.9991914388363 Test RE 0.6554976481227752\n",
      "5 Train Loss 31.57625 Test MSE 964.0032138560738 Test RE 0.5944929690531651\n",
      "6 Train Loss 23.984138 Test MSE 562.8868285887897 Test RE 0.45427415056401044\n",
      "7 Train Loss 22.027058 Test MSE 518.9128971913584 Test RE 0.4361689183085425\n",
      "8 Train Loss 18.712046 Test MSE 463.21309535569355 Test RE 0.4120955227623572\n",
      "9 Train Loss 14.95667 Test MSE 347.869321054601 Test RE 0.35712112954813446\n",
      "10 Train Loss 10.66754 Test MSE 267.52781679549645 Test RE 0.3131785106831577\n",
      "11 Train Loss 6.5474133 Test MSE 122.24290849835778 Test RE 0.21169924979232876\n",
      "12 Train Loss 5.520556 Test MSE 81.23822522092875 Test RE 0.1725788995056765\n",
      "13 Train Loss 3.6689663 Test MSE 44.64057486047463 Test RE 0.12792999151573403\n",
      "14 Train Loss 3.0611043 Test MSE 26.552583486388635 Test RE 0.09866448953309258\n",
      "15 Train Loss 2.9174101 Test MSE 32.53059832884133 Test RE 0.10920776205701775\n",
      "16 Train Loss 2.7654033 Test MSE 25.604006564886834 Test RE 0.0968860938235441\n",
      "17 Train Loss 2.0020733 Test MSE 22.280423093135752 Test RE 0.09037934687399414\n",
      "18 Train Loss 1.8582146 Test MSE 10.714709141497938 Test RE 0.06267548090129998\n",
      "19 Train Loss 1.176456 Test MSE 1.8739288222699084 Test RE 0.02621102636491844\n",
      "20 Train Loss 0.7509971 Test MSE 3.0674477537411233 Test RE 0.03353482690097593\n",
      "21 Train Loss 0.5057639 Test MSE 3.863535361733083 Test RE 0.03763569389188595\n",
      "22 Train Loss 0.37105682 Test MSE 2.967422235808378 Test RE 0.03298353165346622\n",
      "23 Train Loss 0.32313868 Test MSE 2.064029223521821 Test RE 0.027508404557859006\n",
      "24 Train Loss 0.32032502 Test MSE 1.792558128520837 Test RE 0.02563563654503415\n",
      "25 Train Loss 0.31071874 Test MSE 1.4706846173962538 Test RE 0.02322026954262229\n",
      "26 Train Loss 0.23410279 Test MSE 1.3608831461525275 Test RE 0.022336642820767364\n",
      "27 Train Loss 0.16246139 Test MSE 0.5190414224813242 Test RE 0.013794580280356182\n",
      "28 Train Loss 0.13552457 Test MSE 0.690609623124142 Test RE 0.015911964258051452\n",
      "29 Train Loss 0.12525862 Test MSE 0.4638478128669234 Test RE 0.013040529873336888\n",
      "30 Train Loss 0.10437203 Test MSE 0.20575412976765425 Test RE 0.008685238767358881\n",
      "31 Train Loss 0.05618921 Test MSE 0.09664734089995397 Test RE 0.0059525415640437306\n",
      "32 Train Loss 0.02660697 Test MSE 0.06345149167953416 Test RE 0.004823123693656592\n",
      "33 Train Loss 0.015898192 Test MSE 0.026215442015856807 Test RE 0.0031001740317992167\n",
      "34 Train Loss 0.010444356 Test MSE 0.018014428122105772 Test RE 0.0025699088600217106\n",
      "35 Train Loss 0.00980565 Test MSE 0.0234687689109678 Test RE 0.002933274022626926\n",
      "36 Train Loss 0.009219201 Test MSE 0.014584228665556845 Test RE 0.002312326808328749\n",
      "37 Train Loss 0.0083150165 Test MSE 0.012359619568967818 Test RE 0.0021286783024638627\n",
      "38 Train Loss 0.007716691 Test MSE 0.01784899378079995 Test RE 0.0025580813467774135\n",
      "39 Train Loss 0.006285335 Test MSE 0.025903114030135396 Test RE 0.00308165112479386\n",
      "40 Train Loss 0.0039093276 Test MSE 0.005462842368251849 Test RE 0.0014151967296099997\n",
      "41 Train Loss 0.0033707428 Test MSE 0.0023698164220151553 Test RE 0.0009321049924617968\n",
      "42 Train Loss 0.0032715255 Test MSE 0.002891040051428579 Test RE 0.001029519402730015\n",
      "43 Train Loss 0.0031230107 Test MSE 0.002180696561898381 Test RE 0.0008941391299804328\n",
      "44 Train Loss 0.0031230107 Test MSE 0.002180696561898381 Test RE 0.0008941391299804328\n",
      "45 Train Loss 0.0031230107 Test MSE 0.002180696561898381 Test RE 0.0008941391299804328\n",
      "46 Train Loss 0.0031230107 Test MSE 0.002180696561898381 Test RE 0.0008941391299804328\n",
      "47 Train Loss 0.0031230107 Test MSE 0.002180696561898381 Test RE 0.0008941391299804328\n",
      "48 Train Loss 0.0031208121 Test MSE 0.0019575660820711173 Test RE 0.0008471604991416064\n",
      "49 Train Loss 0.003120679 Test MSE 0.0019024206442523545 Test RE 0.000835142829860498\n",
      "50 Train Loss 0.0029750003 Test MSE 0.0025655097889106283 Test RE 0.0009698271096626569\n",
      "51 Train Loss 0.0028542336 Test MSE 0.0020251292570576413 Test RE 0.0008616558794991198\n",
      "52 Train Loss 0.0028488631 Test MSE 0.0020205923369705256 Test RE 0.0008606901495827879\n",
      "53 Train Loss 0.0028447711 Test MSE 0.002004212948019334 Test RE 0.0008571945744456325\n",
      "54 Train Loss 0.0028447711 Test MSE 0.002004212948019334 Test RE 0.0008571945744456325\n",
      "55 Train Loss 0.002844371 Test MSE 0.0020433878125697452 Test RE 0.0008655315060486236\n",
      "56 Train Loss 0.0028418386 Test MSE 0.0021605507977035666 Test RE 0.0008899994179338357\n",
      "57 Train Loss 0.0028239533 Test MSE 0.0022133274916036243 Test RE 0.0009008040310989598\n",
      "58 Train Loss 0.002823555 Test MSE 0.002236302530124077 Test RE 0.0009054672760492042\n",
      "59 Train Loss 0.0028091408 Test MSE 0.0021997480639680033 Test RE 0.0008980364281699477\n",
      "60 Train Loss 0.0028067878 Test MSE 0.0022352080771627435 Test RE 0.0009052456797744375\n",
      "61 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "62 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "63 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "64 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "65 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "66 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "67 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "68 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "69 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "70 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "71 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "72 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "73 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "74 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "75 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "76 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "77 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "78 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "79 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "80 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "81 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "82 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "83 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "84 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "85 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "86 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "87 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "88 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "89 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "90 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "91 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "92 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "93 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "94 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "95 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "96 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "97 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "98 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "99 Train Loss 0.0028052868 Test MSE 0.002262999391408048 Test RE 0.0009108559515489062\n",
      "Training time: 11.92\n",
      "Training time: 11.92\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 59.520786 Test MSE 2044.2891192275256 Test RE 0.8657223712626474\n",
      "1 Train Loss 53.525085 Test MSE 1648.8213610160562 Test RE 0.7774890556790645\n",
      "2 Train Loss 43.984165 Test MSE 1379.579529655512 Test RE 0.7111821579935087\n",
      "3 Train Loss 33.009285 Test MSE 1036.8753328352768 Test RE 0.6165534797069738\n",
      "4 Train Loss 23.050608 Test MSE 746.7078818806781 Test RE 0.5232182086313384\n",
      "5 Train Loss 16.140638 Test MSE 417.92105802830093 Test RE 0.39143045185079006\n",
      "6 Train Loss 14.089187 Test MSE 381.40047019707686 Test RE 0.3739367023947001\n",
      "7 Train Loss 8.149407 Test MSE 191.2761627099368 Test RE 0.2648121498373528\n",
      "8 Train Loss 6.6400204 Test MSE 116.19451670043179 Test RE 0.20639553540523162\n",
      "9 Train Loss 5.9231644 Test MSE 95.89468659393572 Test RE 0.18750150320938397\n",
      "10 Train Loss 5.665651 Test MSE 99.03335973077189 Test RE 0.19054529881234517\n",
      "11 Train Loss 2.7423968 Test MSE 38.224779318681875 Test RE 0.11838044690804166\n",
      "12 Train Loss 1.656042 Test MSE 15.975522103932608 Test RE 0.07653058128497743\n",
      "13 Train Loss 1.4660763 Test MSE 12.696106501531043 Test RE 0.06822487681711974\n",
      "14 Train Loss 1.3343817 Test MSE 9.953277195430092 Test RE 0.06040745393359001\n",
      "15 Train Loss 1.2475458 Test MSE 8.466582717753647 Test RE 0.05571364333991497\n",
      "16 Train Loss 1.0662264 Test MSE 5.282781517095753 Test RE 0.044008727032911296\n",
      "17 Train Loss 0.7137435 Test MSE 2.2355172570131523 Test RE 0.028628361670842702\n",
      "18 Train Loss 0.48265058 Test MSE 3.494902402868298 Test RE 0.03579521769049578\n",
      "19 Train Loss 0.4306707 Test MSE 5.903765266746751 Test RE 0.04652346175629417\n",
      "20 Train Loss 0.42562142 Test MSE 6.841351305220096 Test RE 0.050081626827921444\n",
      "21 Train Loss 0.39519024 Test MSE 6.26811328976973 Test RE 0.04793755730246953\n",
      "22 Train Loss 0.25496578 Test MSE 1.9776125083854663 Test RE 0.02692638690933987\n",
      "23 Train Loss 0.15182996 Test MSE 0.569626912474434 Test RE 0.014451160737349365\n",
      "24 Train Loss 0.13983317 Test MSE 0.3865434264810481 Test RE 0.011904375786504646\n",
      "25 Train Loss 0.11081198 Test MSE 0.28613205562365074 Test RE 0.010242140738699498\n",
      "26 Train Loss 0.10930235 Test MSE 0.30121354636479525 Test RE 0.010508596856986505\n",
      "27 Train Loss 0.09936869 Test MSE 0.32840714242631236 Test RE 0.010972706903226246\n",
      "28 Train Loss 0.085781686 Test MSE 0.28554683924504043 Test RE 0.010231661422772488\n",
      "29 Train Loss 0.06488658 Test MSE 0.326029231735281 Test RE 0.010932909473436515\n",
      "30 Train Loss 0.041762307 Test MSE 0.13412410818836001 Test RE 0.00701230674331902\n",
      "31 Train Loss 0.023855476 Test MSE 0.11979073678680413 Test RE 0.006627032490648406\n",
      "32 Train Loss 0.010722653 Test MSE 0.04447026802108081 Test RE 0.004037777235902442\n",
      "33 Train Loss 0.0065792575 Test MSE 0.01673048431106465 Test RE 0.0024766334726993716\n",
      "34 Train Loss 0.0057531632 Test MSE 0.012549379877858927 Test RE 0.002144957120615004\n",
      "35 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "36 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "37 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "38 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "39 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "40 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "41 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "42 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "43 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "44 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "45 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "46 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "47 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "48 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "49 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "50 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "51 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "52 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "53 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "54 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "55 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "56 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "57 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "58 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "59 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "60 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "61 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "62 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "63 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "64 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "65 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "66 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "67 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "68 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "69 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "70 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "71 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "72 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "73 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "74 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "75 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "76 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "77 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "78 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "79 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "80 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "81 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "82 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "83 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "84 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "85 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "86 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "87 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "88 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "89 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "90 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "91 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "92 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "93 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "94 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "95 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "96 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "97 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "98 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "99 Train Loss 0.00575132 Test MSE 0.012530843360992182 Test RE 0.0021433723918341608\n",
      "Training time: 8.98\n",
      "Training time: 8.98\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 63.053455 Test MSE 2251.700781474878 Test RE 0.9085792642603833\n",
      "1 Train Loss 55.3739 Test MSE 1946.6980451610289 Test RE 0.8448055885984012\n",
      "2 Train Loss 50.025303 Test MSE 1622.2345314764575 Test RE 0.7711951730607874\n",
      "3 Train Loss 32.458164 Test MSE 876.6695859813458 Test RE 0.5669247950997207\n",
      "4 Train Loss 23.203825 Test MSE 590.6465806979271 Test RE 0.46534101078001355\n",
      "5 Train Loss 19.80296 Test MSE 454.1459468903623 Test RE 0.4080423152263238\n",
      "6 Train Loss 12.831103 Test MSE 281.89801704012046 Test RE 0.32147965400235234\n",
      "7 Train Loss 11.901272 Test MSE 180.30245733211945 Test RE 0.2571036869731446\n",
      "8 Train Loss 11.264319 Test MSE 134.5364412349957 Test RE 0.22208920502786256\n",
      "9 Train Loss 8.755077 Test MSE 118.70562351421775 Test RE 0.20861384540278655\n",
      "10 Train Loss 5.931202 Test MSE 36.7372273188967 Test RE 0.11605414852439229\n",
      "11 Train Loss 4.3528614 Test MSE 86.31994970004284 Test RE 0.17789472527389794\n",
      "12 Train Loss 4.164509 Test MSE 83.79604882894495 Test RE 0.17527470803657222\n",
      "13 Train Loss 3.7923057 Test MSE 52.8902483642573 Test RE 0.13925002601510647\n",
      "14 Train Loss 3.2916934 Test MSE 59.930498769136975 Test RE 0.14822840240362284\n",
      "15 Train Loss 2.9977038 Test MSE 69.00291141509858 Test RE 0.15905275254854603\n",
      "16 Train Loss 2.4813895 Test MSE 32.70386510752403 Test RE 0.10949821087997676\n",
      "17 Train Loss 2.0377355 Test MSE 39.305773811624235 Test RE 0.12004267293617864\n",
      "18 Train Loss 0.88938916 Test MSE 11.277662123155919 Test RE 0.0643008955073852\n",
      "19 Train Loss 0.8393492 Test MSE 10.837103142394932 Test RE 0.06303243507842071\n",
      "20 Train Loss 0.72184813 Test MSE 9.629027347637313 Test RE 0.059415354388732404\n",
      "21 Train Loss 0.68991226 Test MSE 7.5174892192781595 Test RE 0.052498136622500656\n",
      "22 Train Loss 0.6712497 Test MSE 7.54477848827923 Test RE 0.05259333715627119\n",
      "23 Train Loss 0.65877575 Test MSE 6.738338047705521 Test RE 0.04970314606443578\n",
      "24 Train Loss 0.6497349 Test MSE 6.45125083432119 Test RE 0.04863281919457494\n",
      "25 Train Loss 0.63991827 Test MSE 5.4727672450314655 Test RE 0.04479308464325326\n",
      "26 Train Loss 0.6295403 Test MSE 5.680071696048319 Test RE 0.045633564199208686\n",
      "27 Train Loss 0.60510397 Test MSE 3.4215468687663875 Test RE 0.03541756735375808\n",
      "28 Train Loss 0.533542 Test MSE 1.658132599384465 Test RE 0.0246556871443772\n",
      "29 Train Loss 0.50702286 Test MSE 1.1642279776380227 Test RE 0.020659818297708996\n",
      "30 Train Loss 0.48203906 Test MSE 0.8923225421891984 Test RE 0.01808707810525964\n",
      "31 Train Loss 0.48052493 Test MSE 0.9843893593537754 Test RE 0.018997258708696115\n",
      "32 Train Loss 0.48052493 Test MSE 0.9843892465320989 Test RE 0.01899725762005034\n",
      "33 Train Loss 0.4805249 Test MSE 0.9843893045184846 Test RE 0.018997258179576103\n",
      "34 Train Loss 0.48035303 Test MSE 0.9649714774393636 Test RE 0.018808957283067678\n",
      "35 Train Loss 0.48033884 Test MSE 0.9769258792895307 Test RE 0.01892510462001414\n",
      "36 Train Loss 0.48033884 Test MSE 0.9769258792895307 Test RE 0.01892510462001414\n",
      "37 Train Loss 0.48033884 Test MSE 0.9769258792895307 Test RE 0.01892510462001414\n",
      "38 Train Loss 0.48029223 Test MSE 0.9791684972682965 Test RE 0.0189468142765457\n",
      "39 Train Loss 0.46778712 Test MSE 1.448432669845299 Test RE 0.02304393479780185\n",
      "40 Train Loss 0.45180234 Test MSE 1.328797052634188 Test RE 0.022071752107984306\n",
      "41 Train Loss 0.39851415 Test MSE 1.7575637767947843 Test RE 0.025384173553202345\n",
      "42 Train Loss 0.32490188 Test MSE 1.6999752234435295 Test RE 0.024964839462279557\n",
      "43 Train Loss 0.27619538 Test MSE 1.2772723523349188 Test RE 0.02163960044066118\n",
      "44 Train Loss 0.2561403 Test MSE 1.4619495675136627 Test RE 0.023151209091868945\n",
      "45 Train Loss 0.24205661 Test MSE 1.2348233734893759 Test RE 0.0212769759419081\n",
      "46 Train Loss 0.2412236 Test MSE 1.0747389232965878 Test RE 0.019849929593142798\n",
      "47 Train Loss 0.24120341 Test MSE 1.0747347249178514 Test RE 0.019849890822050627\n",
      "48 Train Loss 0.24120341 Test MSE 1.0747347249178514 Test RE 0.019849890822050627\n",
      "49 Train Loss 0.24120341 Test MSE 1.0747347249178514 Test RE 0.019849890822050627\n",
      "50 Train Loss 0.24118829 Test MSE 1.083117670555822 Test RE 0.01992715515971439\n",
      "51 Train Loss 0.24118829 Test MSE 1.083117670555822 Test RE 0.01992715515971439\n",
      "52 Train Loss 0.24118829 Test MSE 1.083117670555822 Test RE 0.01992715515971439\n",
      "53 Train Loss 0.2411869 Test MSE 1.0831794655165303 Test RE 0.0199277236022024\n",
      "54 Train Loss 0.23472676 Test MSE 0.8725774011505196 Test RE 0.01788584497879196\n",
      "55 Train Loss 0.21304095 Test MSE 0.7953999866387589 Test RE 0.017076555401933147\n",
      "56 Train Loss 0.19657384 Test MSE 0.543440502713718 Test RE 0.014115084534124918\n",
      "57 Train Loss 0.18775569 Test MSE 0.4966355878849271 Test RE 0.013493555518484706\n",
      "58 Train Loss 0.17606917 Test MSE 0.3468232267376287 Test RE 0.011276168813993945\n",
      "59 Train Loss 0.14762747 Test MSE 0.3688102875694822 Test RE 0.011628106349935474\n",
      "60 Train Loss 0.09274492 Test MSE 0.2097200409688365 Test RE 0.008768543255764602\n",
      "61 Train Loss 0.05005143 Test MSE 0.12790579507533947 Test RE 0.0068478240451301355\n",
      "62 Train Loss 0.038658936 Test MSE 0.16551123936873877 Test RE 0.007789708876341299\n",
      "63 Train Loss 0.03417487 Test MSE 0.1518222097698604 Test RE 0.00746062370667092\n",
      "64 Train Loss 0.030404331 Test MSE 0.13510951874655255 Test RE 0.007038019330162099\n",
      "65 Train Loss 0.02795097 Test MSE 0.09586311615478926 Test RE 0.005928342043360894\n",
      "66 Train Loss 0.02744757 Test MSE 0.08647537454743456 Test RE 0.005630587445529595\n",
      "67 Train Loss 0.027435385 Test MSE 0.08406699551347994 Test RE 0.005551626561532839\n",
      "68 Train Loss 0.027428482 Test MSE 0.08431541905950901 Test RE 0.005559823222882716\n",
      "69 Train Loss 0.027428474 Test MSE 0.08431549333518647 Test RE 0.0055598256717796675\n",
      "70 Train Loss 0.027428474 Test MSE 0.08431549333518647 Test RE 0.0055598256717796675\n",
      "71 Train Loss 0.027428474 Test MSE 0.08431549333518647 Test RE 0.0055598256717796675\n",
      "72 Train Loss 0.027421175 Test MSE 0.08422519491838473 Test RE 0.005556847702221659\n",
      "73 Train Loss 0.027421175 Test MSE 0.08422519491838473 Test RE 0.005556847702221659\n",
      "74 Train Loss 0.027421175 Test MSE 0.08422519491838473 Test RE 0.005556847702221659\n",
      "75 Train Loss 0.027421175 Test MSE 0.08422519491838473 Test RE 0.005556847702221659\n",
      "76 Train Loss 0.027421175 Test MSE 0.08422519491838473 Test RE 0.005556847702221659\n",
      "77 Train Loss 0.027421175 Test MSE 0.08422519491838473 Test RE 0.005556847702221659\n",
      "78 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "79 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "80 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "81 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "82 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "83 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "84 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "85 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "86 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "87 Train Loss 0.02742117 Test MSE 0.08422524317892402 Test RE 0.0055568492942418895\n",
      "88 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "89 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "90 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "91 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "92 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "93 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "94 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "95 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "96 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "97 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "98 Train Loss 0.027421165 Test MSE 0.08422503220790377 Test RE 0.005556842334719691\n",
      "99 Train Loss 0.02742116 Test MSE 0.08422500163951087 Test RE 0.005556841326327348\n",
      "Training time: 16.06\n",
      "Training time: 16.06\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 62.429115 Test MSE 2212.901535814024 Test RE 0.9007173468743005\n",
      "1 Train Loss 43.009293 Test MSE 1426.7733551112237 Test RE 0.7232442289758572\n",
      "2 Train Loss 38.96141 Test MSE 1114.3693853712384 Test RE 0.6391783671740945\n",
      "3 Train Loss 26.09484 Test MSE 532.1389997007917 Test RE 0.4416925013166662\n",
      "4 Train Loss 13.525694 Test MSE 365.07744584412 Test RE 0.3658474089021479\n",
      "5 Train Loss 7.756263 Test MSE 166.39742192025645 Test RE 0.24699080091234513\n",
      "6 Train Loss 4.2920513 Test MSE 68.57415829629338 Test RE 0.15855784135572726\n",
      "7 Train Loss 1.3382529 Test MSE 11.692931353169286 Test RE 0.06547404639369557\n",
      "8 Train Loss 0.28012493 Test MSE 1.7350049357986852 Test RE 0.025220740816750777\n",
      "9 Train Loss 0.25856745 Test MSE 0.668983253596599 Test RE 0.015660841888914603\n",
      "10 Train Loss 0.25854942 Test MSE 0.6689753527571792 Test RE 0.015660749409647293\n",
      "11 Train Loss 0.25854927 Test MSE 0.6689743931672241 Test RE 0.01566073817761673\n",
      "12 Train Loss 0.25854927 Test MSE 0.6689743931672241 Test RE 0.01566073817761673\n",
      "13 Train Loss 0.25854927 Test MSE 0.6689743931672241 Test RE 0.01566073817761673\n",
      "14 Train Loss 0.25148 Test MSE 0.672167380907361 Test RE 0.01569806772271324\n",
      "15 Train Loss 0.23748092 Test MSE 0.5991312688313896 Test RE 0.014820691757043543\n",
      "16 Train Loss 0.2213052 Test MSE 0.565127173401092 Test RE 0.014393969460717996\n",
      "17 Train Loss 0.19218907 Test MSE 0.4078127118134994 Test RE 0.012227505342350356\n",
      "18 Train Loss 0.10380153 Test MSE 0.24445794087225162 Test RE 0.009466938512978241\n",
      "19 Train Loss 0.028427882 Test MSE 0.05539212093186529 Test RE 0.00450641806246072\n",
      "20 Train Loss 0.008615808 Test MSE 0.024574094123450227 Test RE 0.003001554549112603\n",
      "21 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "22 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "23 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "24 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "25 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "26 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "27 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "28 Train Loss 0.007904758 Test MSE 0.04702087159415765 Test RE 0.004151956734785152\n",
      "29 Train Loss 0.0077821244 Test MSE 0.047243297681811784 Test RE 0.004161765293289964\n",
      "30 Train Loss 0.007773776 Test MSE 0.047242612179973616 Test RE 0.004161735099503251\n",
      "31 Train Loss 0.007773776 Test MSE 0.047242612179973616 Test RE 0.004161735099503251\n",
      "32 Train Loss 0.007773776 Test MSE 0.047242612179973616 Test RE 0.004161735099503251\n",
      "33 Train Loss 0.007773776 Test MSE 0.047242612179973616 Test RE 0.004161735099503251\n",
      "34 Train Loss 0.007773773 Test MSE 0.04724264287767011 Test RE 0.0041617364516264126\n",
      "35 Train Loss 0.007773773 Test MSE 0.04724264287767011 Test RE 0.0041617364516264126\n",
      "36 Train Loss 0.007772766 Test MSE 0.047222420880529616 Test RE 0.004160845650166611\n",
      "37 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "38 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "39 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "40 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "41 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "42 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "43 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "44 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "45 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "46 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "47 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "48 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "49 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "50 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "51 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "52 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "53 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "54 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "55 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "56 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "57 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "58 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "59 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "60 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "61 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "62 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "63 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "64 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "65 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "66 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "67 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "68 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "69 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "70 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "71 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "72 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "73 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "74 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "75 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "76 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "77 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "78 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "79 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "80 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "81 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "82 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "83 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "84 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "85 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "86 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "87 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "88 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "89 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "90 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "91 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "92 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "93 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "94 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "95 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "96 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "97 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "98 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "99 Train Loss 0.007772734 Test MSE 0.047222642420648164 Test RE 0.004160855410288395\n",
      "Training time: 9.05\n",
      "Training time: 9.05\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 62.429897 Test MSE 2185.3419303713963 Test RE 0.8950909808991846\n",
      "1 Train Loss 51.172318 Test MSE 1676.6533724538094 Test RE 0.7840235811417486\n",
      "2 Train Loss 44.334217 Test MSE 1103.189026894451 Test RE 0.6359638773274889\n",
      "3 Train Loss 36.816116 Test MSE 955.4527219162298 Test RE 0.5918505871287917\n",
      "4 Train Loss 33.423042 Test MSE 563.2607019160868 Test RE 0.454424991538185\n",
      "5 Train Loss 26.029938 Test MSE 401.21866400268885 Test RE 0.3835288564244734\n",
      "6 Train Loss 24.132998 Test MSE 479.1252301188265 Test RE 0.41911383984469414\n",
      "7 Train Loss 18.090847 Test MSE 323.6813302017976 Test RE 0.3444818199148008\n",
      "8 Train Loss 14.853352 Test MSE 184.03579197692628 Test RE 0.25975183782566563\n",
      "9 Train Loss 12.247462 Test MSE 68.20805222930184 Test RE 0.15813401789853881\n",
      "10 Train Loss 5.374357 Test MSE 34.75552087039194 Test RE 0.11288061906950479\n",
      "11 Train Loss 2.598839 Test MSE 29.518456667218935 Test RE 0.10402897164819216\n",
      "12 Train Loss 2.1692145 Test MSE 24.213400939051247 Test RE 0.0942183248536434\n",
      "13 Train Loss 1.5942265 Test MSE 17.449653114072827 Test RE 0.07998358770707678\n",
      "14 Train Loss 1.0331007 Test MSE 8.963767306052114 Test RE 0.057326149083276205\n",
      "15 Train Loss 0.9335595 Test MSE 5.516350321790753 Test RE 0.04497108866477331\n",
      "16 Train Loss 0.8618723 Test MSE 5.731995486087288 Test RE 0.045841666955813966\n",
      "17 Train Loss 0.7651364 Test MSE 5.106785383358962 Test RE 0.04326944105525756\n",
      "18 Train Loss 0.54216856 Test MSE 1.8782773872376612 Test RE 0.026241420876627217\n",
      "19 Train Loss 0.33852103 Test MSE 1.9479441597282443 Test RE 0.02672364742692189\n",
      "20 Train Loss 0.28306836 Test MSE 2.410125343880651 Test RE 0.02972537188043341\n",
      "21 Train Loss 0.1943551 Test MSE 0.7469747775985863 Test RE 0.016548569209556496\n",
      "22 Train Loss 0.11731915 Test MSE 0.370243250360283 Test RE 0.011650674172117853\n",
      "23 Train Loss 0.10606731 Test MSE 0.3156921932846897 Test RE 0.010758194778753932\n",
      "24 Train Loss 0.09435705 Test MSE 0.233508009788831 Test RE 0.009252484643064987\n",
      "25 Train Loss 0.06354289 Test MSE 0.2795371993123488 Test RE 0.010123420731785647\n",
      "26 Train Loss 0.03703593 Test MSE 0.1019635110301935 Test RE 0.00611406248140701\n",
      "27 Train Loss 0.028403394 Test MSE 0.10753255311227003 Test RE 0.006278811722172352\n",
      "28 Train Loss 0.024641488 Test MSE 0.08038127966392801 Test RE 0.005428563717503036\n",
      "29 Train Loss 0.02199776 Test MSE 0.05043136236703761 Test RE 0.004299894816157012\n",
      "30 Train Loss 0.018080743 Test MSE 0.027447891420517487 Test RE 0.0031722103320250697\n",
      "31 Train Loss 0.013254426 Test MSE 0.006154336109432803 Test RE 0.0015020973751799652\n",
      "32 Train Loss 0.007290758 Test MSE 0.006152576465559085 Test RE 0.0015018826204642349\n",
      "33 Train Loss 0.0062604556 Test MSE 0.010068870439585256 Test RE 0.0019213118356574083\n",
      "34 Train Loss 0.004352577 Test MSE 0.0015481452985888963 Test RE 0.0007533787060889221\n",
      "35 Train Loss 0.003548152 Test MSE 0.002481274050497513 Test RE 0.0009537726148330567\n",
      "36 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "37 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "38 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "39 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "40 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "41 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "42 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "43 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "44 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "45 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "46 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "47 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "48 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "49 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "50 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "51 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "52 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "53 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "54 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "55 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "56 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "57 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "58 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "59 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "60 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "61 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "62 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "63 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "64 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "65 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "66 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "67 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "68 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "69 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "70 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "71 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "72 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "73 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "74 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "75 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "76 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "77 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "78 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "79 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "80 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "81 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "82 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "83 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "84 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "85 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "86 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "87 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "88 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "89 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "90 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "91 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "92 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "93 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "94 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "95 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "96 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "97 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "98 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "99 Train Loss 0.0032599275 Test MSE 0.001038984584346472 Test RE 0.0006171802694592505\n",
      "Training time: 9.28\n",
      "Training time: 9.28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.27575 Test MSE 1949.258266479277 Test RE 0.8453609337412771\n",
      "1 Train Loss 47.206314 Test MSE 1519.3521942488765 Test RE 0.7463399867271406\n",
      "2 Train Loss 32.504074 Test MSE 954.1025736598708 Test RE 0.5914322678774886\n",
      "3 Train Loss 30.215189 Test MSE 698.7204689094119 Test RE 0.506126660715223\n",
      "4 Train Loss 25.949423 Test MSE 689.2415673791629 Test RE 0.5026818589585513\n",
      "5 Train Loss 15.803143 Test MSE 451.6287515344672 Test RE 0.4069099155606051\n",
      "6 Train Loss 12.432146 Test MSE 279.99347535739855 Test RE 0.3203918331952469\n",
      "7 Train Loss 8.015617 Test MSE 195.6386918578857 Test RE 0.26781497485584865\n",
      "8 Train Loss 4.850401 Test MSE 24.840396741114603 Test RE 0.0954304003427478\n",
      "9 Train Loss 3.3706896 Test MSE 14.809768782742799 Test RE 0.07368542976600541\n",
      "10 Train Loss 1.5222346 Test MSE 1.8975734363227996 Test RE 0.026375869042813044\n",
      "11 Train Loss 1.2642921 Test MSE 5.508535291734924 Test RE 0.044939222036249685\n",
      "12 Train Loss 0.75692225 Test MSE 8.784395957219457 Test RE 0.05674968215704754\n",
      "13 Train Loss 0.13721184 Test MSE 0.2246766279161128 Test RE 0.009075831626692323\n",
      "14 Train Loss 0.039691705 Test MSE 0.02356077455379265 Test RE 0.0029390181197471907\n",
      "15 Train Loss 0.021942878 Test MSE 0.023828662334260654 Test RE 0.0029556793224699107\n",
      "16 Train Loss 0.015255051 Test MSE 0.010271654826926246 Test RE 0.0019405627478380836\n",
      "17 Train Loss 0.009104578 Test MSE 0.003513864193055194 Test RE 0.00113501073210243\n",
      "18 Train Loss 0.005190257 Test MSE 0.001632694809006781 Test RE 0.0007736775370893663\n",
      "19 Train Loss 0.0035250266 Test MSE 0.003460558794127593 Test RE 0.0011263687629545795\n",
      "20 Train Loss 0.0028241228 Test MSE 0.0009559791652775298 Test RE 0.0005920136160775219\n",
      "21 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "22 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "23 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "24 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "25 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "26 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "27 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "28 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "29 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "30 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "31 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "32 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "33 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "34 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "35 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "36 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "37 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "38 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "39 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "40 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "41 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "42 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "43 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "44 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "45 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "46 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "47 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "48 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "49 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "50 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "51 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "52 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "53 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "54 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "55 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "56 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "57 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "58 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "59 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "60 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "61 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "62 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "63 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "64 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "65 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "66 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "67 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "68 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "69 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "70 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "71 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "72 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "73 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "74 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "75 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "76 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "77 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "78 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "79 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "80 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "81 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "82 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "83 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "84 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "85 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "86 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "87 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "88 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "89 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "90 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "91 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "92 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "93 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "94 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "95 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "96 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "97 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "98 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "99 Train Loss 0.0027645328 Test MSE 0.0013926110667412776 Test RE 0.0007145331838962992\n",
      "Training time: 6.27\n",
      "Training time: 6.27\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 63.826786 Test MSE 2316.976993421653 Test RE 0.9216549130343319\n",
      "1 Train Loss 53.094593 Test MSE 1765.503095903152 Test RE 0.8045290374985148\n",
      "2 Train Loss 29.123625 Test MSE 917.7438104326743 Test RE 0.5800537166696283\n",
      "3 Train Loss 19.669455 Test MSE 450.05437698014396 Test RE 0.40620005386921293\n",
      "4 Train Loss 4.644088 Test MSE 57.50058004237291 Test RE 0.14519230322418342\n",
      "5 Train Loss 3.215414 Test MSE 48.56143914957578 Test RE 0.13342992939263654\n",
      "6 Train Loss 2.426743 Test MSE 24.587967293154605 Test RE 0.09494427775724425\n",
      "7 Train Loss 1.8731973 Test MSE 18.77647687708063 Test RE 0.08296874771955173\n",
      "8 Train Loss 1.0126734 Test MSE 4.355779040839119 Test RE 0.03996137307535639\n",
      "9 Train Loss 0.4418079 Test MSE 1.446927233369056 Test RE 0.02303195626420207\n",
      "10 Train Loss 0.35022658 Test MSE 1.718427845521299 Test RE 0.025099965959224306\n",
      "11 Train Loss 0.15262239 Test MSE 1.1773851378211169 Test RE 0.020776230576041152\n",
      "12 Train Loss 0.055965792 Test MSE 0.12861713583590179 Test RE 0.006866839534196371\n",
      "13 Train Loss 0.044304583 Test MSE 0.2227831562433444 Test RE 0.009037507235556741\n",
      "14 Train Loss 0.041871406 Test MSE 0.19872590999668363 Test RE 0.008535613251022693\n",
      "15 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "16 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "17 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "18 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "19 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "20 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "21 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "22 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "23 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "24 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "25 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "26 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "27 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "28 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "29 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "30 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "31 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "32 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "33 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "34 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "35 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "36 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "37 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "38 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "39 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "40 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "41 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "42 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "43 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "44 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "45 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "46 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "47 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "48 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "49 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "50 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "51 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "52 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "53 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "54 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "55 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "56 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "57 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "58 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "59 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "60 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "61 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "62 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "63 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "64 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "65 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "66 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "67 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "68 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "69 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "70 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "71 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "72 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "73 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "74 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "75 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "76 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "77 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "78 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "79 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "80 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "81 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "82 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "83 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "84 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "85 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "86 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "87 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "88 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "89 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "90 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "91 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "92 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "93 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "94 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "95 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "96 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "97 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "98 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "99 Train Loss 0.041864138 Test MSE 0.1967710599981263 Test RE 0.008493527443149802\n",
      "Training time: 5.02\n",
      "Training time: 5.02\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "  label = \"1D_FODE_tanh_tune\"+str(tune_reps)  \n",
    "  max_reps = 10\n",
    "  max_iter = 100\n",
    "\n",
    "  train_loss_full = []\n",
    "  test_mse_full = []\n",
    "  test_re_full = []\n",
    "\n",
    "  elapsed_time= np.zeros((max_reps,1))\n",
    "  time_threshold = np.empty((max_reps,1))\n",
    "  time_threshold[:] = np.nan\n",
    "  epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "  for reps in range(max_reps):   \n",
    "      train_loss = []\n",
    "      test_mse_loss = []\n",
    "      test_re_loss = []   \n",
    "\n",
    "      \n",
    "      torch.manual_seed(reps*36)\n",
    "      N_f = 10000 #Total number of collocation points\n",
    "    \n",
    "      layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "      PINN = Sequentialmodel(layers)\n",
    "    \n",
    "      PINN.to(device)\n",
    "\n",
    "      'Neural Network Summary'\n",
    "      print(PINN)\n",
    "\n",
    "      params = list(PINN.parameters())\n",
    "      \n",
    "      optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "    \n",
    "\n",
    "      \n",
    "      train_model(max_iter,reps)\n",
    "\n",
    "      \n",
    "      torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "      train_loss_full.append(train_loss)\n",
    "      test_mse_full.append(test_mse_loss)\n",
    "      test_re_full.append(test_re_loss)\n",
    "      \n",
    "      \n",
    "      print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "  mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label}\n",
    "  savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013785277793989682\n",
      "0.0020915772126794047\n",
      "0.0022742799685846623\n",
      "0.0034653643627296908\n",
      "0.00489416541161756\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
