{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "84a34ebd-2e54-4cae-ca1c-79397867998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "94a6280c-bfd4-43c8-a396-40f22c70c38f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "150eeb9e-6cdc-4ff0-fd50-61a1c228e3a0"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "30d0ca6b-cde8-4b85-ccae-4eac06a2c482"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = 100*np.sin(0.01*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "label = \"1D_FODE_rowdy\"\n",
    "\n",
    "x = np.linspace(-600,600,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "                      \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - torch.cos(0.01*g)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "\n",
    "  x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "  f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    \n",
    "    train_step(i)\n",
    "\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "509236d6-c6b5-4579-8ffe-6c945b3ae573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 47.768845 Test MSE 5220.596547879134 Test RE 0.9998002260533937\n",
      "1 Train Loss 47.768456 Test MSE 5220.482907142386 Test RE 0.9997893442842742\n",
      "2 Train Loss 47.768326 Test MSE 5220.224729839918 Test RE 0.9997646218484422\n",
      "3 Train Loss 47.710194 Test MSE 5167.751736326571 Test RE 0.9947271815244016\n",
      "4 Train Loss 47.413536 Test MSE 5137.403445100986 Test RE 0.9918020485565923\n",
      "5 Train Loss 46.100494 Test MSE 5028.951015554952 Test RE 0.9812775598445348\n",
      "6 Train Loss 44.36725 Test MSE 4900.022274421381 Test RE 0.9686172337540463\n",
      "7 Train Loss 41.814682 Test MSE 4641.97881299302 Test RE 0.9427678016238233\n",
      "8 Train Loss 37.93653 Test MSE 4247.702545444706 Test RE 0.9018414931528792\n",
      "9 Train Loss 33.408875 Test MSE 3685.9288956635924 Test RE 0.840091598004237\n",
      "10 Train Loss 30.672926 Test MSE 3345.1884062292243 Test RE 0.800319605816878\n",
      "11 Train Loss 28.41322 Test MSE 3157.2128636002467 Test RE 0.777508412088216\n",
      "12 Train Loss 25.738401 Test MSE 3033.118542167401 Test RE 0.7620752490389888\n",
      "13 Train Loss 24.131485 Test MSE 2850.063266928854 Test RE 0.7387209488966002\n",
      "14 Train Loss 23.302544 Test MSE 2815.5622926618776 Test RE 0.7342361021743616\n",
      "15 Train Loss 21.891129 Test MSE 2637.897878940481 Test RE 0.7106931900774869\n",
      "16 Train Loss 19.04912 Test MSE 2307.1873713737214 Test RE 0.6646524311220513\n",
      "17 Train Loss 17.184206 Test MSE 2123.641598520546 Test RE 0.6376667566603665\n",
      "18 Train Loss 16.252779 Test MSE 2077.928328940685 Test RE 0.6307662484000045\n",
      "19 Train Loss 13.699041 Test MSE 1764.6214346742447 Test RE 0.5812713795126038\n",
      "20 Train Loss 11.050276 Test MSE 1447.183371842435 Test RE 0.5263988679034688\n",
      "21 Train Loss 9.254939 Test MSE 1161.2395602436875 Test RE 0.4715351540977186\n",
      "22 Train Loss 8.243718 Test MSE 1127.5421012795 Test RE 0.464643159858722\n",
      "23 Train Loss 7.222868 Test MSE 899.8273921198776 Test RE 0.4150809188904746\n",
      "24 Train Loss 6.4779525 Test MSE 738.4311319012813 Test RE 0.37601759183897804\n",
      "25 Train Loss 5.882314 Test MSE 693.6481565595243 Test RE 0.36443726850390906\n",
      "26 Train Loss 5.480094 Test MSE 692.7768083417072 Test RE 0.36420829683449063\n",
      "27 Train Loss 5.10871 Test MSE 625.2293447445544 Test RE 0.3459974047516347\n",
      "28 Train Loss 4.5205293 Test MSE 563.7781923514295 Test RE 0.3285544101711186\n",
      "29 Train Loss 3.8638375 Test MSE 430.3677056349762 Test RE 0.2870602125645795\n",
      "30 Train Loss 3.2714036 Test MSE 329.4647465110042 Test RE 0.2511641441077622\n",
      "31 Train Loss 2.817514 Test MSE 298.1069116451355 Test RE 0.23891267302761116\n",
      "32 Train Loss 2.2817929 Test MSE 329.91440677384946 Test RE 0.25133548266115513\n",
      "33 Train Loss 1.9331183 Test MSE 243.4127937072576 Test RE 0.215886191608767\n",
      "34 Train Loss 1.6142316 Test MSE 161.55419848307298 Test RE 0.1758783121463841\n",
      "35 Train Loss 1.4217395 Test MSE 143.39147087208138 Test RE 0.16569706831723097\n",
      "36 Train Loss 1.0952607 Test MSE 100.94086354406576 Test RE 0.1390230053084838\n",
      "37 Train Loss 0.89463496 Test MSE 64.41243465300622 Test RE 0.11105497587724952\n",
      "38 Train Loss 0.65158737 Test MSE 45.97396829900511 Test RE 0.09382296656801668\n",
      "39 Train Loss 0.50335824 Test MSE 47.65534155459938 Test RE 0.09552322093696906\n",
      "40 Train Loss 0.40675816 Test MSE 32.513815307754584 Test RE 0.0789018401393687\n",
      "41 Train Loss 0.32425657 Test MSE 16.325914394974482 Test RE 0.05591031281917613\n",
      "42 Train Loss 0.2909266 Test MSE 14.151399895611924 Test RE 0.05205385122390842\n",
      "43 Train Loss 0.26063526 Test MSE 11.036074848164647 Test RE 0.04596851596259085\n",
      "44 Train Loss 0.20314577 Test MSE 8.107519045736712 Test RE 0.039400084519893304\n",
      "45 Train Loss 0.16501655 Test MSE 17.48954159912518 Test RE 0.057868520364301054\n",
      "46 Train Loss 0.14352843 Test MSE 18.653777583528576 Test RE 0.0597635740516312\n",
      "47 Train Loss 0.1212415 Test MSE 18.708156673628825 Test RE 0.05985062139922959\n",
      "48 Train Loss 0.10821976 Test MSE 17.052002041892404 Test RE 0.05714008112882589\n",
      "49 Train Loss 0.09058512 Test MSE 17.99194782526273 Test RE 0.05869380382900234\n",
      "50 Train Loss 0.07656358 Test MSE 17.929656028432092 Test RE 0.05859211076589098\n",
      "51 Train Loss 0.0653307 Test MSE 13.793974664077835 Test RE 0.05139227896244273\n",
      "52 Train Loss 0.058486156 Test MSE 12.824115916384637 Test RE 0.04955264969119038\n",
      "53 Train Loss 0.05291135 Test MSE 12.388074024647103 Test RE 0.04870292676398274\n",
      "54 Train Loss 0.044759843 Test MSE 8.410443523289505 Test RE 0.04012939517024429\n",
      "55 Train Loss 0.040582348 Test MSE 5.892906895481062 Test RE 0.03359061493636443\n",
      "56 Train Loss 0.037380315 Test MSE 5.076094648008292 Test RE 0.031175829692077456\n",
      "57 Train Loss 0.03544804 Test MSE 4.696353016608597 Test RE 0.029987035375316138\n",
      "58 Train Loss 0.032270983 Test MSE 2.8848953170076825 Test RE 0.023502723647337676\n",
      "59 Train Loss 0.030016301 Test MSE 1.7578135922501594 Test RE 0.018345923314658077\n",
      "60 Train Loss 0.027469132 Test MSE 2.0901274942218246 Test RE 0.020005045972782316\n",
      "61 Train Loss 0.025138175 Test MSE 2.4768630537588017 Test RE 0.02177730643182366\n",
      "62 Train Loss 0.022846896 Test MSE 3.3278624894939823 Test RE 0.02524270261802056\n",
      "63 Train Loss 0.020819271 Test MSE 3.0834883893041076 Test RE 0.02429821236248108\n",
      "64 Train Loss 0.019202534 Test MSE 2.913229967081983 Test RE 0.023617860278819337\n",
      "65 Train Loss 0.017954629 Test MSE 2.6390674337301423 Test RE 0.022479073556566826\n",
      "66 Train Loss 0.017101962 Test MSE 2.5465888562623085 Test RE 0.022081703891110728\n",
      "67 Train Loss 0.015839702 Test MSE 1.929438804396557 Test RE 0.019220676490858235\n",
      "68 Train Loss 0.014851998 Test MSE 1.6217370575688599 Test RE 0.017621520725671545\n",
      "69 Train Loss 0.014511789 Test MSE 1.0425599523875613 Test RE 0.014128748155373376\n",
      "70 Train Loss 0.0142465485 Test MSE 0.6540907104306339 Test RE 0.011191083992998134\n",
      "71 Train Loss 0.014076632 Test MSE 0.632930256344514 Test RE 0.011008574686349627\n",
      "72 Train Loss 0.0139181 Test MSE 0.6899042727274572 Test RE 0.011493375135572501\n",
      "73 Train Loss 0.013768351 Test MSE 0.7504471132244985 Test RE 0.011987074661519898\n",
      "74 Train Loss 0.013526189 Test MSE 0.753329161923466 Test RE 0.012010070437375512\n",
      "75 Train Loss 0.013259648 Test MSE 0.5828812699310043 Test RE 0.010564360548763717\n",
      "76 Train Loss 0.012996299 Test MSE 0.41596835223011114 Test RE 0.008924487993193396\n",
      "77 Train Loss 0.0127402125 Test MSE 0.2743508196684192 Test RE 0.007247801586241976\n",
      "78 Train Loss 0.012600159 Test MSE 0.2432838891384395 Test RE 0.0068251128966296945\n",
      "79 Train Loss 0.012477519 Test MSE 0.2829080075606706 Test RE 0.007359965604292851\n",
      "80 Train Loss 0.012326051 Test MSE 0.37105164009741254 Test RE 0.008428889151589273\n",
      "81 Train Loss 0.012246366 Test MSE 0.3962355445419351 Test RE 0.00871023516346273\n",
      "82 Train Loss 0.012166563 Test MSE 0.38216507551105405 Test RE 0.008554185478920883\n",
      "83 Train Loss 0.011853976 Test MSE 0.3785488093571422 Test RE 0.00851361696411432\n",
      "84 Train Loss 0.010744475 Test MSE 0.27888703669874426 Test RE 0.0073074748369074145\n",
      "85 Train Loss 0.010222242 Test MSE 0.14051691087137183 Test RE 0.005187014493769469\n",
      "86 Train Loss 0.009718665 Test MSE 0.10229876123514277 Test RE 0.004425765021293989\n",
      "87 Train Loss 0.009345681 Test MSE 0.23384619746410218 Test RE 0.006691420473929733\n",
      "88 Train Loss 0.0090248175 Test MSE 0.34612349696563705 Test RE 0.008140830381837487\n",
      "89 Train Loss 0.008131322 Test MSE 0.13978174175514407 Test RE 0.005173427752987898\n",
      "90 Train Loss 0.0076737837 Test MSE 0.0675175087394706 Test RE 0.0035955171891901613\n",
      "91 Train Loss 0.007360895 Test MSE 0.05206305255964398 Test RE 0.003157315478566216\n",
      "92 Train Loss 0.00723107 Test MSE 0.15124229134995182 Test RE 0.00538133202854453\n",
      "93 Train Loss 0.0070772707 Test MSE 0.1720908042963374 Test RE 0.005740265723444138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 0.00681278 Test MSE 0.09827661630497116 Test RE 0.004337887275809401\n",
      "95 Train Loss 0.006591435 Test MSE 0.1356136487557375 Test RE 0.005095711890664989\n",
      "96 Train Loss 0.006361981 Test MSE 0.12137844602176098 Test RE 0.0048208536909298974\n",
      "97 Train Loss 0.006285482 Test MSE 0.0720870439005142 Test RE 0.0037151963637064083\n",
      "98 Train Loss 0.0062803477 Test MSE 0.0690009523502315 Test RE 0.0036348015713701105\n",
      "99 Train Loss 0.0062803477 Test MSE 0.0690009523502315 Test RE 0.0036348015713701105\n",
      "Training time: 70.23\n",
      "Training time: 70.23\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 47.768642 Test MSE 5220.649878404435 Test RE 0.9998053327241152\n",
      "1 Train Loss 47.76841 Test MSE 5220.440963480496 Test RE 0.9997853279019592\n",
      "2 Train Loss 47.639095 Test MSE 5140.824981462127 Test RE 0.992132266143817\n",
      "3 Train Loss 47.639095 Test MSE 5140.824981462127 Test RE 0.992132266143817\n",
      "4 Train Loss 47.639095 Test MSE 5140.824981462127 Test RE 0.992132266143817\n",
      "5 Train Loss 47.639095 Test MSE 5140.824645884944 Test RE 0.9921322337621511\n",
      "6 Train Loss 47.639095 Test MSE 5140.824645884944 Test RE 0.9921322337621511\n",
      "7 Train Loss 47.639095 Test MSE 5140.824567549855 Test RE 0.9921322262031722\n",
      "8 Train Loss 47.639095 Test MSE 5140.824567549855 Test RE 0.9921322262031722\n",
      "9 Train Loss 47.639095 Test MSE 5140.824567549855 Test RE 0.9921322262031722\n",
      "10 Train Loss 47.04275 Test MSE 5087.518113711523 Test RE 0.9869749926575266\n",
      "11 Train Loss 45.29528 Test MSE 4902.548106294181 Test RE 0.9688668498721984\n",
      "12 Train Loss 42.101307 Test MSE 4559.022044751473 Test RE 0.9343057266439299\n",
      "13 Train Loss 39.52779 Test MSE 4317.979191241472 Test RE 0.9092712034397576\n",
      "14 Train Loss 35.709835 Test MSE 3998.763643162132 Test RE 0.8750160760876056\n",
      "15 Train Loss 34.36204 Test MSE 3923.165084920142 Test RE 0.8667053080964213\n",
      "16 Train Loss 32.20851 Test MSE 3653.100203519994 Test RE 0.836342096522631\n",
      "17 Train Loss 29.174263 Test MSE 3349.360183632704 Test RE 0.8008184887722907\n",
      "18 Train Loss 26.55692 Test MSE 3129.3765266743158 Test RE 0.7740732774151973\n",
      "19 Train Loss 24.137436 Test MSE 2972.9761525526196 Test RE 0.754481990230177\n",
      "20 Train Loss 22.659103 Test MSE 2811.630750588093 Test RE 0.7337232936757606\n",
      "21 Train Loss 19.891865 Test MSE 2490.771884857503 Test RE 0.6905897723013346\n",
      "22 Train Loss 17.999367 Test MSE 2306.083304617558 Test RE 0.664493382820819\n",
      "23 Train Loss 16.322655 Test MSE 2063.3610170184643 Test RE 0.6285513670275804\n",
      "24 Train Loss 14.798645 Test MSE 1947.5832673043824 Test RE 0.6106624024884951\n",
      "25 Train Loss 13.053704 Test MSE 1612.8441687798386 Test RE 0.5557114803061743\n",
      "26 Train Loss 11.002137 Test MSE 1435.9486659657466 Test RE 0.5243516294410738\n",
      "27 Train Loss 9.502627 Test MSE 1251.523510674147 Test RE 0.4895225144232594\n",
      "28 Train Loss 6.496033 Test MSE 810.2542758227189 Test RE 0.39387991039612813\n",
      "29 Train Loss 4.5224056 Test MSE 547.5348093107542 Test RE 0.32378671968633316\n",
      "30 Train Loss 2.747148 Test MSE 397.34218813404397 Test RE 0.27582619233813077\n",
      "31 Train Loss 2.0064902 Test MSE 348.01415720385097 Test RE 0.25813780947963016\n",
      "32 Train Loss 1.2256718 Test MSE 227.64342829897245 Test RE 0.2087760725140954\n",
      "33 Train Loss 0.88600844 Test MSE 173.23797428248352 Test RE 0.1821271589885969\n",
      "34 Train Loss 0.75485396 Test MSE 159.21715013959903 Test RE 0.17460154717331813\n",
      "35 Train Loss 0.5754226 Test MSE 138.00460175085135 Test RE 0.1625548563942538\n",
      "36 Train Loss 0.32748762 Test MSE 73.3144603328681 Test RE 0.11848080212129053\n",
      "37 Train Loss 0.23807468 Test MSE 48.205053614642935 Test RE 0.0960725791346516\n",
      "38 Train Loss 0.13986452 Test MSE 28.408797351837798 Test RE 0.0737529827786068\n",
      "39 Train Loss 0.086212516 Test MSE 17.930747952214254 Test RE 0.058593894881131314\n",
      "40 Train Loss 0.06494109 Test MSE 16.543732505744778 Test RE 0.05628205087078591\n",
      "41 Train Loss 0.05538717 Test MSE 15.127099973462355 Test RE 0.05381842738935306\n",
      "42 Train Loss 0.04933012 Test MSE 14.129881479058513 Test RE 0.05201425999638223\n",
      "43 Train Loss 0.042328544 Test MSE 11.082946004012319 Test RE 0.04606602864986828\n",
      "44 Train Loss 0.033721708 Test MSE 4.975185180986865 Test RE 0.030864396520165618\n",
      "45 Train Loss 0.026195845 Test MSE 2.935026157179746 Test RE 0.023706047633562682\n",
      "46 Train Loss 0.025057644 Test MSE 2.907827139893367 Test RE 0.023595949472478492\n",
      "47 Train Loss 0.021144805 Test MSE 1.4329517490894415 Test RE 0.016564142121900743\n",
      "48 Train Loss 0.018823659 Test MSE 0.8722720367412982 Test RE 0.012923470021512685\n",
      "49 Train Loss 0.018043542 Test MSE 0.47756870545448094 Test RE 0.00956249221927161\n",
      "50 Train Loss 0.017348284 Test MSE 0.34297618296692 Test RE 0.008103733419544628\n",
      "51 Train Loss 0.016618386 Test MSE 0.6112912754874656 Test RE 0.010818754438979316\n",
      "52 Train Loss 0.015699307 Test MSE 0.8889157869373188 Test RE 0.013046183245719881\n",
      "53 Train Loss 0.014170535 Test MSE 0.8918855551869569 Test RE 0.013067957993864374\n",
      "54 Train Loss 0.011791994 Test MSE 0.6538370363416783 Test RE 0.011188913679848997\n",
      "55 Train Loss 0.0110772215 Test MSE 0.7841381752508201 Test RE 0.012253198343691717\n",
      "56 Train Loss 0.01012229 Test MSE 0.7251318570736597 Test RE 0.01178315681100624\n",
      "57 Train Loss 0.008323954 Test MSE 0.22748041543450223 Test RE 0.006599714840760512\n",
      "58 Train Loss 0.007574593 Test MSE 0.10185083948866545 Test RE 0.004416065142476217\n",
      "59 Train Loss 0.007364114 Test MSE 0.09555123697127814 Test RE 0.004277315854292979\n",
      "60 Train Loss 0.007036359 Test MSE 0.060779825726303034 Test RE 0.0034114019229595977\n",
      "61 Train Loss 0.006837937 Test MSE 0.03684962422357331 Test RE 0.0026562545811924633\n",
      "62 Train Loss 0.006747714 Test MSE 0.04539532974126479 Test RE 0.0029482122895717914\n",
      "63 Train Loss 0.0065883766 Test MSE 0.06866002829667898 Test RE 0.0036258109291823154\n",
      "64 Train Loss 0.006221485 Test MSE 0.14907957860392002 Test RE 0.0053427178907320605\n",
      "65 Train Loss 0.0060251527 Test MSE 0.17673193799630602 Test RE 0.005817155652692468\n",
      "66 Train Loss 0.005876832 Test MSE 0.13520343178733238 Test RE 0.005087999058408373\n",
      "67 Train Loss 0.0056501697 Test MSE 0.0762240286379487 Test RE 0.0038203144750142332\n",
      "68 Train Loss 0.0055493605 Test MSE 0.07394254567542285 Test RE 0.0037627066747676777\n",
      "69 Train Loss 0.0055077695 Test MSE 0.08234563072430778 Test RE 0.003970758231350134\n",
      "70 Train Loss 0.005457993 Test MSE 0.08962509521672554 Test RE 0.004142552105306395\n",
      "71 Train Loss 0.0053563835 Test MSE 0.0795515881860557 Test RE 0.003902811642717446\n",
      "72 Train Loss 0.005141631 Test MSE 0.09081180513456769 Test RE 0.004169887314891502\n",
      "73 Train Loss 0.0048051733 Test MSE 0.15745149969375458 Test RE 0.0054906854609757276\n",
      "74 Train Loss 0.0047043855 Test MSE 0.18543301906487863 Test RE 0.005958633847764287\n",
      "75 Train Loss 0.004563569 Test MSE 0.21399961697581474 Test RE 0.006401174444003214\n",
      "76 Train Loss 0.004447699 Test MSE 0.20623866318097267 Test RE 0.00628402938451157\n",
      "77 Train Loss 0.0043009045 Test MSE 0.1683369308610103 Test RE 0.0056773133764297995\n",
      "78 Train Loss 0.00418225 Test MSE 0.1750565971868203 Test RE 0.005789517963736795\n",
      "79 Train Loss 0.004026819 Test MSE 0.19486572701826818 Test RE 0.0061083075544049285\n",
      "80 Train Loss 0.0039231237 Test MSE 0.1911241906390557 Test RE 0.00604938178528945\n",
      "81 Train Loss 0.0038857341 Test MSE 0.16709703688608554 Test RE 0.005656366467790357\n",
      "82 Train Loss 0.0038851053 Test MSE 0.16667564224157216 Test RE 0.005649229694962041\n",
      "83 Train Loss 0.003844628 Test MSE 0.13097526723451347 Test RE 0.005007809633683155\n",
      "84 Train Loss 0.0038049577 Test MSE 0.11986039061846814 Test RE 0.004790612121496667\n",
      "85 Train Loss 0.0037309693 Test MSE 0.09502073366695457 Test RE 0.004265425435028802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.0036849594 Test MSE 0.0796252285874429 Test RE 0.003904617628877303\n",
      "87 Train Loss 0.0036455337 Test MSE 0.07083970311281544 Test RE 0.0036829136027132564\n",
      "88 Train Loss 0.0035323144 Test MSE 0.045773090271117534 Test RE 0.0029604537564997782\n",
      "89 Train Loss 0.0033703179 Test MSE 0.031742567235333675 Test RE 0.0024653250510829356\n",
      "90 Train Loss 0.0032933443 Test MSE 0.041253670227172475 Test RE 0.0028105056388956435\n",
      "91 Train Loss 0.0032645513 Test MSE 0.042487441429250865 Test RE 0.002852222845448379\n",
      "92 Train Loss 0.0032455744 Test MSE 0.03903321185460508 Test RE 0.0027338224717953293\n",
      "93 Train Loss 0.0032133423 Test MSE 0.032672827871446306 Test RE 0.0025011890982055396\n",
      "94 Train Loss 0.003150333 Test MSE 0.03922173842604975 Test RE 0.0027404165659121846\n",
      "95 Train Loss 0.003031833 Test MSE 0.02982378135672937 Test RE 0.0023896512182107845\n",
      "96 Train Loss 0.0029407812 Test MSE 0.042467112129674106 Test RE 0.002851540401079266\n",
      "97 Train Loss 0.0028038672 Test MSE 0.09932286716604394 Test RE 0.004360916675362266\n",
      "98 Train Loss 0.0026270887 Test MSE 0.1857163180287805 Test RE 0.005963183820979622\n",
      "99 Train Loss 0.0025774494 Test MSE 0.1963677481113441 Test RE 0.006131803720033226\n",
      "Training time: 67.15\n",
      "Training time: 67.15\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 47.770046 Test MSE 5223.737401096173 Test RE 1.0001009343688387\n",
      "1 Train Loss 47.769947 Test MSE 5223.619268037195 Test RE 1.0000896258322918\n",
      "2 Train Loss 47.769135 Test MSE 5221.8883448500965 Test RE 0.9999239148891665\n",
      "3 Train Loss 47.739037 Test MSE 5158.220872286813 Test RE 0.993809472498702\n",
      "4 Train Loss 47.707706 Test MSE 5084.83529858909 Test RE 0.9867147262028427\n",
      "5 Train Loss 47.704895 Test MSE 5082.7874317697015 Test RE 0.986516011424436\n",
      "6 Train Loss 47.67869 Test MSE 5039.701929906118 Test RE 0.9823258896775781\n",
      "7 Train Loss 47.676636 Test MSE 5041.1828096061145 Test RE 0.9824702037303742\n",
      "8 Train Loss 47.666588 Test MSE 5016.670889174926 Test RE 0.980078743459279\n",
      "9 Train Loss 47.62065 Test MSE 4947.603365718577 Test RE 0.9733086942916264\n",
      "10 Train Loss 47.555645 Test MSE 4881.143183317089 Test RE 0.9667494605152886\n",
      "11 Train Loss 47.520683 Test MSE 4842.581233820892 Test RE 0.9629231370493367\n",
      "12 Train Loss 47.432472 Test MSE 4809.655324231256 Test RE 0.9596439770974531\n",
      "13 Train Loss 47.175983 Test MSE 4817.264665731199 Test RE 0.9604028020349996\n",
      "14 Train Loss 46.892548 Test MSE 4843.138525580203 Test RE 0.9629785427993982\n",
      "15 Train Loss 45.697403 Test MSE 4759.016886642569 Test RE 0.9545788056986158\n",
      "16 Train Loss 43.41942 Test MSE 4481.314987169129 Test RE 0.9263090353350535\n",
      "17 Train Loss 37.2544 Test MSE 4037.799159412256 Test RE 0.879276611736793\n",
      "18 Train Loss 35.40195 Test MSE 3768.6543363322185 Test RE 0.8494666191885233\n",
      "19 Train Loss 34.483105 Test MSE 3663.940988393618 Test RE 0.8375821238677285\n",
      "20 Train Loss 32.608444 Test MSE 3534.1330094243162 Test RE 0.8226111842526622\n",
      "21 Train Loss 31.489956 Test MSE 3353.6053954802865 Test RE 0.801325834563099\n",
      "22 Train Loss 29.855122 Test MSE 3205.241182205489 Test RE 0.7833999179483914\n",
      "23 Train Loss 28.272043 Test MSE 3143.9684360589504 Test RE 0.7758758841937624\n",
      "24 Train Loss 26.145622 Test MSE 2967.2850690658465 Test RE 0.7537595026237027\n",
      "25 Train Loss 25.055788 Test MSE 2832.205513440025 Test RE 0.7364029958190142\n",
      "26 Train Loss 24.28908 Test MSE 2587.5378330113394 Test RE 0.7038765859648266\n",
      "27 Train Loss 22.270617 Test MSE 2351.780024094682 Test RE 0.6710447968301496\n",
      "28 Train Loss 20.6518 Test MSE 2156.723687900808 Test RE 0.6426143491743944\n",
      "29 Train Loss 19.129461 Test MSE 1957.8200358391873 Test RE 0.6122651624275011\n",
      "30 Train Loss 17.361736 Test MSE 1652.0881684207006 Test RE 0.5624316800363303\n",
      "31 Train Loss 16.458862 Test MSE 1554.9377338342297 Test RE 0.5456443543930594\n",
      "32 Train Loss 15.001362 Test MSE 1440.251727374619 Test RE 0.5251366956082435\n",
      "33 Train Loss 14.453609 Test MSE 1375.8056982340781 Test RE 0.5132532600850146\n",
      "34 Train Loss 14.105707 Test MSE 1367.021597323819 Test RE 0.5116121534229405\n",
      "35 Train Loss 13.703194 Test MSE 1332.742547573822 Test RE 0.5051569076653005\n",
      "36 Train Loss 12.720054 Test MSE 1244.3721184356366 Test RE 0.48812190836320274\n",
      "37 Train Loss 12.042684 Test MSE 1142.6553755113607 Test RE 0.46774677110732704\n",
      "38 Train Loss 11.815911 Test MSE 1136.657756076447 Test RE 0.46651759120256214\n",
      "39 Train Loss 11.575968 Test MSE 1112.7490677634935 Test RE 0.4615851031013241\n",
      "40 Train Loss 10.911509 Test MSE 991.3834262325479 Test RE 0.43568638813156946\n",
      "41 Train Loss 10.302524 Test MSE 951.4346296387656 Test RE 0.4268179169488118\n",
      "42 Train Loss 10.04206 Test MSE 964.9787646112528 Test RE 0.4298451618243089\n",
      "43 Train Loss 9.696518 Test MSE 922.7292774838485 Test RE 0.42032992955594045\n",
      "44 Train Loss 9.051336 Test MSE 881.2624872295266 Test RE 0.4107767046914999\n",
      "45 Train Loss 8.845135 Test MSE 892.417137936773 Test RE 0.4133682493722626\n",
      "46 Train Loss 8.558975 Test MSE 832.2077884080563 Test RE 0.39918025626668374\n",
      "47 Train Loss 8.346044 Test MSE 786.5435974912352 Test RE 0.38807401584828133\n",
      "48 Train Loss 8.197758 Test MSE 777.0684006080745 Test RE 0.385729442056213\n",
      "49 Train Loss 7.9637947 Test MSE 737.4411409968802 Test RE 0.375765449946066\n",
      "50 Train Loss 7.6169405 Test MSE 681.2497537652226 Test RE 0.3611655713439777\n",
      "51 Train Loss 7.417477 Test MSE 656.5327303026404 Test RE 0.35455315610476684\n",
      "52 Train Loss 7.130036 Test MSE 602.6999375757008 Test RE 0.3397064070041394\n",
      "53 Train Loss 6.751108 Test MSE 505.27674676333015 Test RE 0.31104112979662096\n",
      "54 Train Loss 6.289984 Test MSE 510.39137120640333 Test RE 0.3126114108234076\n",
      "55 Train Loss 6.167201 Test MSE 517.2660344790266 Test RE 0.3147097121202067\n",
      "56 Train Loss 5.860578 Test MSE 507.41805753317595 Test RE 0.311699513117207\n",
      "57 Train Loss 5.2357316 Test MSE 459.3295551831335 Test RE 0.29656190310608266\n",
      "58 Train Loss 5.077553 Test MSE 473.6795980365306 Test RE 0.30115876287767046\n",
      "59 Train Loss 4.887714 Test MSE 450.00980500510474 Test RE 0.2935378797193997\n",
      "60 Train Loss 4.736758 Test MSE 434.2255457119599 Test RE 0.28834395396536494\n",
      "61 Train Loss 4.439104 Test MSE 393.81644732682054 Test RE 0.27459971976486003\n",
      "62 Train Loss 3.9005897 Test MSE 359.8607257280262 Test RE 0.26249461016390924\n",
      "63 Train Loss 3.316962 Test MSE 327.03537834088945 Test RE 0.2502364285479347\n",
      "64 Train Loss 3.1005468 Test MSE 314.2430128587741 Test RE 0.2452934659034677\n",
      "65 Train Loss 3.0265982 Test MSE 295.28201085147003 Test RE 0.23777799438478645\n",
      "66 Train Loss 2.952036 Test MSE 271.010364162228 Test RE 0.2277960109003573\n",
      "67 Train Loss 2.7435997 Test MSE 254.64973576304334 Test RE 0.22081307191062455\n",
      "68 Train Loss 2.4838626 Test MSE 235.90715210661628 Test RE 0.21253170122468595\n",
      "69 Train Loss 2.291807 Test MSE 172.76570626578814 Test RE 0.1818787390536871\n",
      "70 Train Loss 2.2080612 Test MSE 160.71232438764545 Test RE 0.17541945437958473\n",
      "71 Train Loss 2.026948 Test MSE 166.04884502657404 Test RE 0.17830810900899358\n",
      "72 Train Loss 1.8766161 Test MSE 183.77249867538924 Test RE 0.18758297736963425\n",
      "73 Train Loss 1.8190852 Test MSE 203.94642739203852 Test RE 0.19761104540880328\n",
      "74 Train Loss 1.7729275 Test MSE 193.1110670007104 Test RE 0.19229002080101365\n",
      "75 Train Loss 1.6995941 Test MSE 176.2056438315876 Test RE 0.18368050807419392\n",
      "76 Train Loss 1.6334486 Test MSE 165.96027711292732 Test RE 0.1782605492574831\n",
      "77 Train Loss 1.6015556 Test MSE 160.66170150470603 Test RE 0.17539182445777748\n",
      "78 Train Loss 1.5809761 Test MSE 165.0672803688509 Test RE 0.17778031143344847\n",
      "79 Train Loss 1.5615396 Test MSE 168.89878160960862 Test RE 0.17983177172631162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 1.5392646 Test MSE 160.02750682840426 Test RE 0.1750453120434716\n",
      "81 Train Loss 1.5002371 Test MSE 136.61273506101566 Test RE 0.1617330429773379\n",
      "82 Train Loss 1.4150976 Test MSE 122.7234274321095 Test RE 0.153291086550862\n",
      "83 Train Loss 1.2532039 Test MSE 109.53100441655815 Test RE 0.14481771803275562\n",
      "84 Train Loss 1.1913095 Test MSE 99.35220711333517 Test RE 0.13792466074453835\n",
      "85 Train Loss 1.1107763 Test MSE 84.5686659832421 Test RE 0.12725003329505155\n",
      "86 Train Loss 1.0823014 Test MSE 81.37482351833495 Test RE 0.12482402846669383\n",
      "87 Train Loss 1.0576624 Test MSE 82.94803634306257 Test RE 0.12602485874161592\n",
      "88 Train Loss 1.0262613 Test MSE 90.79885014004057 Test RE 0.13185400901812344\n",
      "89 Train Loss 0.9890606 Test MSE 98.6241956801348 Test RE 0.13741840450799478\n",
      "90 Train Loss 0.97098464 Test MSE 95.18833421315307 Test RE 0.1350035000715833\n",
      "91 Train Loss 0.95126206 Test MSE 89.50477785597654 Test RE 0.13091104034221981\n",
      "92 Train Loss 0.91846174 Test MSE 86.80882915076705 Test RE 0.12892439853741436\n",
      "93 Train Loss 0.87285644 Test MSE 88.96360494159273 Test RE 0.13051467645955953\n",
      "94 Train Loss 0.8508797 Test MSE 89.82712813728088 Test RE 0.1311465656682415\n",
      "95 Train Loss 0.8265547 Test MSE 89.25815402724805 Test RE 0.1307305580610856\n",
      "96 Train Loss 0.79367834 Test MSE 82.42840655706594 Test RE 0.12562949583840066\n",
      "97 Train Loss 0.7497902 Test MSE 93.97050295560318 Test RE 0.134137108505522\n",
      "98 Train Loss 0.7014243 Test MSE 88.15905602683506 Test RE 0.12992317655860755\n",
      "99 Train Loss 0.6841594 Test MSE 77.64031007303437 Test RE 0.12192613167863595\n",
      "Training time: 70.62\n",
      "Training time: 70.62\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 47.76895 Test MSE 5221.471763859316 Test RE 0.9998840291643437\n",
      "1 Train Loss 47.7501 Test MSE 5189.411630020544 Test RE 0.9968096302253144\n",
      "2 Train Loss 47.59823 Test MSE 5098.821720128412 Test RE 0.988070830214196\n",
      "3 Train Loss 46.93286 Test MSE 5046.016722294716 Test RE 0.9829411286532592\n",
      "4 Train Loss 45.88805 Test MSE 4899.620366085197 Test RE 0.968577509105666\n",
      "5 Train Loss 43.787567 Test MSE 4621.90268171445 Test RE 0.9407269005542973\n",
      "6 Train Loss 39.718575 Test MSE 4218.989032354598 Test RE 0.8987882017638043\n",
      "7 Train Loss 37.03173 Test MSE 4011.608293287896 Test RE 0.876420293146424\n",
      "8 Train Loss 35.074635 Test MSE 3790.1531681834595 Test RE 0.8518861258724162\n",
      "9 Train Loss 32.20032 Test MSE 3549.144789347598 Test RE 0.8243564174372087\n",
      "10 Train Loss 28.958017 Test MSE 3260.0254797990096 Test RE 0.7900665262928205\n",
      "11 Train Loss 26.780043 Test MSE 3086.011829724759 Test RE 0.7686912861291753\n",
      "12 Train Loss 24.43529 Test MSE 2756.295377143328 Test RE 0.7264672541165732\n",
      "13 Train Loss 23.029058 Test MSE 2554.560356590833 Test RE 0.6993768437371519\n",
      "14 Train Loss 19.036041 Test MSE 1980.7959307070155 Test RE 0.6158472865557532\n",
      "15 Train Loss 17.451944 Test MSE 1779.2676664012988 Test RE 0.5836786502335543\n",
      "16 Train Loss 15.721701 Test MSE 1603.3278217987715 Test RE 0.5540696083758486\n",
      "17 Train Loss 12.242466 Test MSE 1361.3692928934802 Test RE 0.5105533614280133\n",
      "18 Train Loss 10.2824545 Test MSE 1098.3716912682944 Test RE 0.4585934317902599\n",
      "19 Train Loss 9.12516 Test MSE 1019.884654645652 Test RE 0.44190477398989086\n",
      "20 Train Loss 7.6954775 Test MSE 936.6648982517975 Test RE 0.42349207471472433\n",
      "21 Train Loss 6.0543146 Test MSE 667.1081733912965 Test RE 0.3573973232482408\n",
      "22 Train Loss 4.068333 Test MSE 382.1532037092777 Test RE 0.2705028947804916\n",
      "23 Train Loss 2.7384648 Test MSE 183.1694226350231 Test RE 0.18727493410109242\n",
      "24 Train Loss 2.466143 Test MSE 181.27412830945852 Test RE 0.18630352724880153\n",
      "25 Train Loss 1.7585386 Test MSE 71.30073381272149 Test RE 0.11684231806070261\n",
      "26 Train Loss 1.2263573 Test MSE 40.918561582507174 Test RE 0.08851428058728496\n",
      "27 Train Loss 0.924435 Test MSE 49.53285866539692 Test RE 0.09738674739540665\n",
      "28 Train Loss 0.72285795 Test MSE 39.21734646664836 Test RE 0.08665472875401142\n",
      "29 Train Loss 0.54023415 Test MSE 40.85158116100398 Test RE 0.08844180550759986\n",
      "30 Train Loss 0.4050631 Test MSE 53.21201690869235 Test RE 0.1009387738571882\n",
      "31 Train Loss 0.33713004 Test MSE 70.26702875155239 Test RE 0.11599224643575577\n",
      "32 Train Loss 0.30074787 Test MSE 68.79150444352946 Test RE 0.11476793522652608\n",
      "33 Train Loss 0.2748991 Test MSE 79.70312595114252 Test RE 0.12353523395378808\n",
      "34 Train Loss 0.24744053 Test MSE 84.66302018314035 Test RE 0.12732100064352908\n",
      "35 Train Loss 0.22402906 Test MSE 67.84290104239416 Test RE 0.11397388966001513\n",
      "36 Train Loss 0.18007882 Test MSE 63.894281218951996 Test RE 0.11060739374747608\n",
      "37 Train Loss 0.15602972 Test MSE 54.2660906357313 Test RE 0.10193361645232354\n",
      "38 Train Loss 0.14465246 Test MSE 31.522717109733545 Test RE 0.07768997594235838\n",
      "39 Train Loss 0.117827505 Test MSE 24.672782077759678 Test RE 0.06873251350958201\n",
      "40 Train Loss 0.10209625 Test MSE 29.446162437320872 Test RE 0.0750874777789591\n",
      "41 Train Loss 0.084356815 Test MSE 19.3653464668807 Test RE 0.06089277980056911\n",
      "42 Train Loss 0.06782401 Test MSE 18.780896710860222 Test RE 0.05996686248368999\n",
      "43 Train Loss 0.059487514 Test MSE 13.262183864228092 Test RE 0.05039189460037681\n",
      "44 Train Loss 0.053809524 Test MSE 8.929969991874671 Test RE 0.04135025236348195\n",
      "45 Train Loss 0.04667442 Test MSE 7.660613362859984 Test RE 0.03829877970982207\n",
      "46 Train Loss 0.04299068 Test MSE 7.600995988919003 Test RE 0.03814946187943915\n",
      "47 Train Loss 0.038163293 Test MSE 5.287433354165353 Test RE 0.03181820076775608\n",
      "48 Train Loss 0.03492349 Test MSE 3.471234159732511 Test RE 0.025780724633621608\n",
      "49 Train Loss 0.033327494 Test MSE 3.019136439359837 Test RE 0.0240433254251868\n",
      "50 Train Loss 0.030513972 Test MSE 2.061620710964592 Test RE 0.01986815543279017\n",
      "51 Train Loss 0.02868522 Test MSE 1.425395684245349 Test RE 0.016520412400116112\n",
      "52 Train Loss 0.026847295 Test MSE 1.7071871655449842 Test RE 0.018079804631974613\n",
      "53 Train Loss 0.025395805 Test MSE 1.4443082402116487 Test RE 0.016629650014004595\n",
      "54 Train Loss 0.02319154 Test MSE 2.5115832116915007 Test RE 0.02192941015314591\n",
      "55 Train Loss 0.022528276 Test MSE 3.8589101076805696 Test RE 0.027182255833071798\n",
      "56 Train Loss 0.016863087 Test MSE 1.8989113256822057 Test RE 0.019068015973182854\n",
      "57 Train Loss 0.014608159 Test MSE 1.1408790538113647 Test RE 0.014779950107698009\n",
      "58 Train Loss 0.013798573 Test MSE 1.5438570795474813 Test RE 0.01719319985593731\n",
      "59 Train Loss 0.013113623 Test MSE 0.9309150972162026 Test RE 0.013350828017999028\n",
      "60 Train Loss 0.011667663 Test MSE 0.05582242688058277 Test RE 0.0032693206788081863\n",
      "61 Train Loss 0.010390301 Test MSE 0.05697568034669359 Test RE 0.0033029190098002757\n",
      "62 Train Loss 0.009874015 Test MSE 0.12203553382824443 Test RE 0.004833885035006636\n",
      "63 Train Loss 0.0081663625 Test MSE 0.06715855253237256 Test RE 0.0035859466850204176\n",
      "64 Train Loss 0.0062752976 Test MSE 0.08637864517299927 Test RE 0.0040668331846074185\n",
      "65 Train Loss 0.0054371445 Test MSE 0.12668686248949987 Test RE 0.004925144251485218\n",
      "66 Train Loss 0.0053155757 Test MSE 0.16366053657133442 Test RE 0.005597900180446313\n",
      "67 Train Loss 0.0050357347 Test MSE 0.38368960795608975 Test RE 0.008571230669726121\n",
      "68 Train Loss 0.00470811 Test MSE 0.45149270925156343 Test RE 0.00929776436366403\n",
      "69 Train Loss 0.004607264 Test MSE 0.28977308121714124 Test RE 0.0074487291717922404\n",
      "70 Train Loss 0.0044197566 Test MSE 0.11553357776777487 Test RE 0.004703349761039684\n",
      "71 Train Loss 0.004179086 Test MSE 0.08189087366357087 Test RE 0.003959778715565518\n",
      "72 Train Loss 0.0039088903 Test MSE 0.13760229166499097 Test RE 0.005132937758569753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 0.0036992757 Test MSE 0.06775201763961948 Test RE 0.0036017559405153677\n",
      "74 Train Loss 0.0036548642 Test MSE 0.06154679767668017 Test RE 0.003432858443079713\n",
      "75 Train Loss 0.003606281 Test MSE 0.045113790517095353 Test RE 0.0029390557488785957\n",
      "76 Train Loss 0.0034700644 Test MSE 0.027649858827025305 Test RE 0.0023009099587530404\n",
      "77 Train Loss 0.0033087377 Test MSE 0.04136134260706184 Test RE 0.002814170968917827\n",
      "78 Train Loss 0.0031373685 Test MSE 0.03606197318054644 Test RE 0.002627712867305388\n",
      "79 Train Loss 0.0029860928 Test MSE 0.031165970066867242 Test RE 0.0024428313748789967\n",
      "80 Train Loss 0.002763576 Test MSE 0.006587404697821466 Test RE 0.001123079079250479\n",
      "81 Train Loss 0.0025239324 Test MSE 0.013485998614430306 Test RE 0.001606921716648135\n",
      "82 Train Loss 0.0024186773 Test MSE 0.020832058896081987 Test RE 0.001997189444376921\n",
      "83 Train Loss 0.002389711 Test MSE 0.02067069165663377 Test RE 0.001989439190715432\n",
      "84 Train Loss 0.002342626 Test MSE 0.019490706714762596 Test RE 0.0019318213342773057\n",
      "85 Train Loss 0.0022542246 Test MSE 0.03553819957911393 Test RE 0.002608560271531216\n",
      "86 Train Loss 0.0021624484 Test MSE 0.043152238786037626 Test RE 0.002874450477745309\n",
      "87 Train Loss 0.0021172669 Test MSE 0.020908340953264222 Test RE 0.002000842720027499\n",
      "88 Train Loss 0.0020959952 Test MSE 0.014078164892125017 Test RE 0.0016418224448970353\n",
      "89 Train Loss 0.0020480708 Test MSE 0.01977149338133579 Test RE 0.001945686661021358\n",
      "90 Train Loss 0.0020400204 Test MSE 0.02469126745022763 Test RE 0.0021743269885612024\n",
      "91 Train Loss 0.0020180359 Test MSE 0.022582977182175654 Test RE 0.0020794274014084404\n",
      "92 Train Loss 0.0019969037 Test MSE 0.011798039745606979 Test RE 0.0015029969252411178\n",
      "93 Train Loss 0.0019815073 Test MSE 0.009733349138862991 Test RE 0.0013651623919773293\n",
      "94 Train Loss 0.0018892719 Test MSE 0.02184913585586018 Test RE 0.002045362537485034\n",
      "95 Train Loss 0.0017078841 Test MSE 0.05296876777939269 Test RE 0.0031846601949490415\n",
      "96 Train Loss 0.0015736109 Test MSE 0.047282739620397016 Test RE 0.0030088773200662084\n",
      "97 Train Loss 0.0015140116 Test MSE 0.020793870039636494 Test RE 0.0019953580035259794\n",
      "98 Train Loss 0.0014790902 Test MSE 0.02588874569000311 Test RE 0.002226428072956618\n",
      "99 Train Loss 0.0014756444 Test MSE 0.027105701802720743 Test RE 0.0022781561735900585\n",
      "Training time: 70.08\n",
      "Training time: 70.08\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 47.770115 Test MSE 5223.9056110625825 Test RE 1.000117036402441\n",
      "1 Train Loss 47.77009 Test MSE 5223.875936627537 Test RE 1.00011419581224\n",
      "2 Train Loss 47.769524 Test MSE 5222.636624137263 Test RE 0.9999955552137308\n",
      "3 Train Loss 47.764553 Test MSE 5211.630057201595 Test RE 0.9989412675128454\n",
      "4 Train Loss 47.7355 Test MSE 5142.760865301213 Test RE 0.9923190525103877\n",
      "5 Train Loss 47.71071 Test MSE 5089.859408445966 Test RE 0.9872020713138812\n",
      "6 Train Loss 47.694656 Test MSE 5046.576171467325 Test RE 0.9829956162214065\n",
      "7 Train Loss 47.670975 Test MSE 5040.297177513879 Test RE 0.9823839000400212\n",
      "8 Train Loss 47.588978 Test MSE 5002.310814218111 Test RE 0.9786750147137899\n",
      "9 Train Loss 47.0735 Test MSE 4973.848697478646 Test RE 0.9758868134992356\n",
      "10 Train Loss 46.258 Test MSE 4938.097118830946 Test RE 0.9723731947432261\n",
      "11 Train Loss 44.292843 Test MSE 4781.167949242883 Test RE 0.956797792042227\n",
      "12 Train Loss 42.01339 Test MSE 4539.748643883779 Test RE 0.9323287323998776\n",
      "13 Train Loss 39.943626 Test MSE 4384.37143951699 Test RE 0.9162349092166635\n",
      "14 Train Loss 35.037018 Test MSE 3565.845294002787 Test RE 0.8262936462118631\n",
      "15 Train Loss 32.56503 Test MSE 3240.489567526637 Test RE 0.7876957069079841\n",
      "16 Train Loss 29.55359 Test MSE 3168.1454286243143 Test RE 0.7788533983019695\n",
      "17 Train Loss 26.287903 Test MSE 2862.0964015390978 Test RE 0.7402787679579355\n",
      "18 Train Loss 24.111607 Test MSE 2719.541340461512 Test RE 0.7216074315622393\n",
      "19 Train Loss 19.568222 Test MSE 2228.3743263326774 Test RE 0.6532015968709208\n",
      "20 Train Loss 18.746021 Test MSE 2107.8100875572504 Test RE 0.6352854430208454\n",
      "21 Train Loss 15.772127 Test MSE 1663.1378045229865 Test RE 0.5643093972060477\n",
      "22 Train Loss 13.193499 Test MSE 1440.6612432161116 Test RE 0.5252113480134895\n",
      "23 Train Loss 12.024561 Test MSE 1327.7518838683116 Test RE 0.5042102008866574\n",
      "24 Train Loss 10.186098 Test MSE 1150.7415342490226 Test RE 0.46939889074289\n",
      "25 Train Loss 9.486151 Test MSE 1070.642573008913 Test RE 0.4527676810947943\n",
      "26 Train Loss 8.660254 Test MSE 978.4383853223592 Test RE 0.4328325425670065\n",
      "27 Train Loss 7.28456 Test MSE 906.4456320401274 Test RE 0.4166045846378448\n",
      "28 Train Loss 6.6253424 Test MSE 811.2757160680615 Test RE 0.3941281029002156\n",
      "29 Train Loss 5.539359 Test MSE 703.6278663341847 Test RE 0.3670495365878829\n",
      "30 Train Loss 3.715384 Test MSE 527.0632127729621 Test RE 0.31767608154366994\n",
      "31 Train Loss 3.1949728 Test MSE 453.1606566163548 Test RE 0.29456372511963863\n",
      "32 Train Loss 2.5775194 Test MSE 356.77930807032675 Test RE 0.2613683487516727\n",
      "33 Train Loss 1.9848975 Test MSE 155.78169622203578 Test RE 0.17270757205132464\n",
      "34 Train Loss 1.4617032 Test MSE 104.39032105210373 Test RE 0.1413784712693155\n",
      "35 Train Loss 1.2652906 Test MSE 93.39135590448426 Test RE 0.13372312127863414\n",
      "36 Train Loss 1.230316 Test MSE 97.65887573085001 Test RE 0.1367442346386439\n",
      "37 Train Loss 1.0821463 Test MSE 96.20004807253493 Test RE 0.1357190494313138\n",
      "38 Train Loss 0.9360102 Test MSE 104.78615423905097 Test RE 0.14164626113897552\n",
      "39 Train Loss 0.862628 Test MSE 97.85409610604492 Test RE 0.13688084246324775\n",
      "40 Train Loss 0.76441664 Test MSE 109.63278183694744 Test RE 0.14488498552238374\n",
      "41 Train Loss 0.7219934 Test MSE 96.9607595610473 Test RE 0.1362545987580701\n",
      "42 Train Loss 0.68448025 Test MSE 81.75466259058676 Test RE 0.1251150143119647\n",
      "43 Train Loss 0.61516654 Test MSE 85.22928714813666 Test RE 0.12774608305833343\n",
      "44 Train Loss 0.56646657 Test MSE 95.18311963494172 Test RE 0.13499980216071325\n",
      "45 Train Loss 0.5058259 Test MSE 120.84865824800583 Test RE 0.1521157143038122\n",
      "46 Train Loss 0.47326213 Test MSE 123.10747833736679 Test RE 0.1535307538886673\n",
      "47 Train Loss 0.4593802 Test MSE 103.93150364961674 Test RE 0.14106743507703745\n",
      "48 Train Loss 0.444151 Test MSE 97.7529186880893 Test RE 0.13681005936621418\n",
      "49 Train Loss 0.43188557 Test MSE 93.77568095480697 Test RE 0.13399798815433953\n",
      "50 Train Loss 0.41539615 Test MSE 77.89458353965065 Test RE 0.12212562365720588\n",
      "51 Train Loss 0.40743956 Test MSE 70.88387242836916 Test RE 0.11650025670699436\n",
      "52 Train Loss 0.4004058 Test MSE 67.6513981078032 Test RE 0.11381291660093276\n",
      "53 Train Loss 0.3805409 Test MSE 55.20888992365574 Test RE 0.10281528226440897\n",
      "54 Train Loss 0.36276156 Test MSE 48.19815915590115 Test RE 0.0960657085674739\n",
      "55 Train Loss 0.34438953 Test MSE 51.26620681429289 Test RE 0.09907606679600926\n",
      "56 Train Loss 0.3171261 Test MSE 37.207308606249825 Test RE 0.08440482871673495\n",
      "57 Train Loss 0.23760344 Test MSE 23.268848992875668 Test RE 0.06674836240904437\n",
      "58 Train Loss 0.21409257 Test MSE 21.32826510903341 Test RE 0.06390442475825958\n",
      "59 Train Loss 0.20774928 Test MSE 23.069072407551026 Test RE 0.0664612080010787\n",
      "60 Train Loss 0.18997692 Test MSE 8.873053870655415 Test RE 0.04121826658741624\n",
      "61 Train Loss 0.17797643 Test MSE 2.2657021942362654 Test RE 0.020828336108564067\n",
      "62 Train Loss 0.1706038 Test MSE 3.791560678489039 Test RE 0.0269440062151536\n",
      "63 Train Loss 0.14052875 Test MSE 16.690638791271777 Test RE 0.056531387378147294\n",
      "64 Train Loss 0.10585771 Test MSE 8.628321379536434 Test RE 0.040645860392258114\n",
      "65 Train Loss 0.09072808 Test MSE 3.8602007328298127 Test RE 0.027186801050396347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.075928114 Test MSE 1.1569094928276398 Test RE 0.014883424097510232\n",
      "67 Train Loss 0.06790282 Test MSE 1.074889587657118 Test RE 0.014346140923933137\n",
      "68 Train Loss 0.06329013 Test MSE 1.1709225029821138 Test RE 0.014973290168452077\n",
      "69 Train Loss 0.060899206 Test MSE 0.8475959429737575 Test RE 0.012739359673318953\n",
      "70 Train Loss 0.059141837 Test MSE 0.7756833889725353 Test RE 0.012186960690693027\n",
      "71 Train Loss 0.057073966 Test MSE 1.4277274575022025 Test RE 0.016533919566884738\n",
      "72 Train Loss 0.051306464 Test MSE 0.9671111307706229 Test RE 0.013607907721229287\n",
      "73 Train Loss 0.04698165 Test MSE 0.8740275545929233 Test RE 0.012936468247867611\n",
      "74 Train Loss 0.04309773 Test MSE 1.4640001599211472 Test RE 0.01674263181235345\n",
      "75 Train Loss 0.036124617 Test MSE 0.8147731813960629 Test RE 0.012490261398578374\n",
      "76 Train Loss 0.033080123 Test MSE 0.34303231765415165 Test RE 0.008104396558782439\n",
      "77 Train Loss 0.032241166 Test MSE 0.46867558118371383 Test RE 0.00947303905904369\n",
      "78 Train Loss 0.029880341 Test MSE 0.3903087723798327 Test RE 0.00864484718921782\n",
      "79 Train Loss 0.021673018 Test MSE 1.099390528479009 Test RE 0.014508722030343365\n",
      "80 Train Loss 0.016003428 Test MSE 0.8450373414390635 Test RE 0.012720117261342154\n",
      "81 Train Loss 0.0126556 Test MSE 0.4998305320740974 Test RE 0.009782831096945926\n",
      "82 Train Loss 0.011458993 Test MSE 0.18244627947409672 Test RE 0.005910451669601068\n",
      "83 Train Loss 0.010481985 Test MSE 0.27355642598473795 Test RE 0.007237300830862186\n",
      "84 Train Loss 0.009755439 Test MSE 0.34346674093976687 Test RE 0.008109526723523377\n",
      "85 Train Loss 0.007839639 Test MSE 0.2444376394987958 Test RE 0.0068412774741070425\n",
      "86 Train Loss 0.0065016216 Test MSE 0.2313071510645937 Test RE 0.006654994401574006\n",
      "87 Train Loss 0.0055083707 Test MSE 0.2847078394386589 Test RE 0.0073833401617021815\n",
      "88 Train Loss 0.004490811 Test MSE 0.046636021711860466 Test RE 0.0029882292507145813\n",
      "89 Train Loss 0.0040635346 Test MSE 0.09831137756450045 Test RE 0.004338654381451981\n",
      "90 Train Loss 0.0037876845 Test MSE 0.24294848664704788 Test RE 0.00682040656484672\n",
      "91 Train Loss 0.0032599538 Test MSE 0.1958338599359239 Test RE 0.006123462417276998\n",
      "92 Train Loss 0.0028659499 Test MSE 0.03399399102274785 Test RE 0.002551257194167576\n",
      "93 Train Loss 0.0026716925 Test MSE 0.045866509446707775 Test RE 0.0029634732400077393\n",
      "94 Train Loss 0.0025500185 Test MSE 0.04278926709185074 Test RE 0.0028623358405058716\n",
      "95 Train Loss 0.0024130973 Test MSE 0.040558037403968954 Test RE 0.002786709065290858\n",
      "96 Train Loss 0.0023044155 Test MSE 0.045517685677224425 Test RE 0.0029521828359876066\n",
      "97 Train Loss 0.0021876441 Test MSE 0.03212720446100694 Test RE 0.0024802167335519934\n",
      "98 Train Loss 0.0019731068 Test MSE 0.024342895833350746 Test RE 0.0021589335980566424\n",
      "99 Train Loss 0.0019386448 Test MSE 0.02173478573697985 Test RE 0.002040003188861099\n",
      "Training time: 70.99\n",
      "Training time: 70.99\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 47.76869 Test MSE 5219.652503260229 Test RE 0.9997098246320095\n",
      "1 Train Loss 47.74966 Test MSE 5167.0460681092745 Test RE 0.9946592630796446\n",
      "2 Train Loss 47.741867 Test MSE 5166.0381185762435 Test RE 0.9945622429229992\n",
      "3 Train Loss 47.74035 Test MSE 5165.228384771639 Test RE 0.9944842951601202\n",
      "4 Train Loss 47.70047 Test MSE 5090.356689899132 Test RE 0.9872502951695002\n",
      "5 Train Loss 46.78964 Test MSE 4993.04145095839 Test RE 0.9777678439122295\n",
      "6 Train Loss 44.936993 Test MSE 4765.146676106875 Test RE 0.9551933742390948\n",
      "7 Train Loss 41.36858 Test MSE 4438.462346828726 Test RE 0.921869474626083\n",
      "8 Train Loss 35.984768 Test MSE 3777.9944644696975 Test RE 0.8505186150093698\n",
      "9 Train Loss 30.48196 Test MSE 3244.2881406727806 Test RE 0.788157248806773\n",
      "10 Train Loss 25.346468 Test MSE 2761.3899278045596 Test RE 0.7271383207334193\n",
      "11 Train Loss 20.086397 Test MSE 2328.9407788591357 Test RE 0.6677784308878955\n",
      "12 Train Loss 15.849758 Test MSE 1801.012578711807 Test RE 0.5872344665540562\n",
      "13 Train Loss 13.888876 Test MSE 1625.05322013077 Test RE 0.5578108519083811\n",
      "14 Train Loss 6.549782 Test MSE 653.1255575346655 Test RE 0.35363195660719776\n",
      "15 Train Loss 3.8901374 Test MSE 441.4464339571938 Test RE 0.2907315549837348\n",
      "16 Train Loss 2.2824037 Test MSE 334.84812563886436 Test RE 0.25320781220041083\n",
      "17 Train Loss 0.99329597 Test MSE 214.83054442803558 Test RE 0.20281551713423368\n",
      "18 Train Loss 0.47396868 Test MSE 115.04865108229528 Test RE 0.14842051363154776\n",
      "19 Train Loss 0.20865472 Test MSE 76.37432080184045 Test RE 0.12092799303369679\n",
      "20 Train Loss 0.16193824 Test MSE 58.48429053152469 Test RE 0.10582122328132615\n",
      "21 Train Loss 0.12579095 Test MSE 55.934732941685546 Test RE 0.10348894249766223\n",
      "22 Train Loss 0.08582892 Test MSE 50.47799009615609 Test RE 0.0983114704063352\n",
      "23 Train Loss 0.06296135 Test MSE 33.75586179779098 Test RE 0.08039476401482473\n",
      "24 Train Loss 0.047622208 Test MSE 17.293883921167364 Test RE 0.05754391880273217\n",
      "25 Train Loss 0.035201106 Test MSE 11.622836001347137 Test RE 0.04717470788906881\n",
      "26 Train Loss 0.030521093 Test MSE 9.136750849234769 Test RE 0.04182626221747845\n",
      "27 Train Loss 0.024158275 Test MSE 3.7153007062314156 Test RE 0.026671666352531417\n",
      "28 Train Loss 0.020110153 Test MSE 1.498373242461846 Test RE 0.016938040585096785\n",
      "29 Train Loss 0.017699648 Test MSE 0.7996198919871175 Test RE 0.012373568285760335\n",
      "30 Train Loss 0.016460164 Test MSE 0.09572494499633104 Test RE 0.004281202076661088\n",
      "31 Train Loss 0.01392592 Test MSE 0.2779863074899802 Test RE 0.007295664716100366\n",
      "32 Train Loss 0.0132398 Test MSE 0.27811183330077643 Test RE 0.007297311723245732\n",
      "33 Train Loss 0.011564056 Test MSE 0.7354950502447298 Test RE 0.011867057368147867\n",
      "34 Train Loss 0.010215782 Test MSE 0.8748171090687412 Test RE 0.01294231002063232\n",
      "35 Train Loss 0.008994538 Test MSE 0.8380873538104835 Test RE 0.01266770112831728\n",
      "36 Train Loss 0.007365447 Test MSE 0.2968680746728263 Test RE 0.00753936749096696\n",
      "37 Train Loss 0.0066729784 Test MSE 0.11640761431546075 Test RE 0.004721107169650973\n",
      "38 Train Loss 0.005938479 Test MSE 0.09471094300955991 Test RE 0.004258466597362644\n",
      "39 Train Loss 0.0057834964 Test MSE 0.03262788315882481 Test RE 0.0024994681894452554\n",
      "40 Train Loss 0.0052700327 Test MSE 0.038313066300688446 Test RE 0.0027084861569923514\n",
      "41 Train Loss 0.0043371124 Test MSE 0.09863634792605315 Test RE 0.004345819222886444\n",
      "42 Train Loss 0.0037260407 Test MSE 0.034094261160972895 Test RE 0.002555017072617393\n",
      "43 Train Loss 0.0036066603 Test MSE 0.008892436884613308 Test RE 0.0013048589249191713\n",
      "44 Train Loss 0.0035367403 Test MSE 0.019655083300857645 Test RE 0.001939950323530699\n",
      "45 Train Loss 0.0031932418 Test MSE 0.03170225456389915 Test RE 0.0024637590874331864\n",
      "46 Train Loss 0.003026418 Test MSE 0.019008685773852837 Test RE 0.001907784036421848\n",
      "47 Train Loss 0.0029018442 Test MSE 0.04146539711274177 Test RE 0.002817708610740492\n",
      "48 Train Loss 0.0025390205 Test MSE 0.030251183346302765 Test RE 0.0024067132478481613\n",
      "49 Train Loss 0.0022697556 Test MSE 0.0632453425573957 Test RE 0.0034799054105206415\n",
      "50 Train Loss 0.00219756 Test MSE 0.02933173496632174 Test RE 0.00236985645329438\n",
      "51 Train Loss 0.0021713157 Test MSE 0.024522204956346202 Test RE 0.0021668703331466557\n",
      "52 Train Loss 0.0021383194 Test MSE 0.044274993099890775 Test RE 0.0029116047268733574\n",
      "53 Train Loss 0.0020965731 Test MSE 0.07257515828007059 Test RE 0.00372775327570922\n",
      "54 Train Loss 0.0019441615 Test MSE 0.0572558846107212 Test RE 0.00331103086463359\n",
      "55 Train Loss 0.0016874347 Test MSE 0.029663889565249735 Test RE 0.002383236889018865\n",
      "56 Train Loss 0.0016211814 Test MSE 0.01801827407793449 Test RE 0.001857418466695617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 0.0015305344 Test MSE 0.012695760919925268 Test RE 0.0015591307333883263\n",
      "58 Train Loss 0.001488349 Test MSE 0.022106127276163238 Test RE 0.002057356238133287\n",
      "59 Train Loss 0.0014574736 Test MSE 0.012479742539519322 Test RE 0.0015458095199352288\n",
      "60 Train Loss 0.0014271166 Test MSE 0.003675782809692951 Test RE 0.0008389345605838936\n",
      "61 Train Loss 0.0014131673 Test MSE 0.0036581015295781183 Test RE 0.0008369144034168714\n",
      "62 Train Loss 0.0014102001 Test MSE 0.003985065738687 Test RE 0.0008735160913633638\n",
      "63 Train Loss 0.0014083314 Test MSE 0.004094010632163467 Test RE 0.0008853758011264092\n",
      "64 Train Loss 0.0014080742 Test MSE 0.004104775305815994 Test RE 0.0008865390278064388\n",
      "65 Train Loss 0.0014066682 Test MSE 0.004036358252436008 Test RE 0.000879119710810845\n",
      "66 Train Loss 0.0014061476 Test MSE 0.003979464661844252 Test RE 0.0008729020047397115\n",
      "67 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "68 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "69 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "70 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "71 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "72 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "73 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "74 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "75 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "76 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "77 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "78 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "79 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "80 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "81 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "82 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "83 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "84 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "85 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "86 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "87 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "88 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "89 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "90 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "91 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "92 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "93 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "94 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "95 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "96 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "97 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "98 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "99 Train Loss 0.0014054743 Test MSE 0.0038779157546707777 Test RE 0.0008616925729404862\n",
      "Training time: 46.34\n",
      "Training time: 46.34\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 47.773193 Test MSE 5225.408286306659 Test RE 1.0002608696915618\n",
      "1 Train Loss 47.770443 Test MSE 5224.660364812941 Test RE 1.0001892826179315\n",
      "2 Train Loss 47.77015 Test MSE 5223.981636663176 Test RE 1.0001243139288152\n",
      "3 Train Loss 47.76964 Test MSE 5222.980671074815 Test RE 1.000028492575373\n",
      "4 Train Loss 47.769634 Test MSE 5222.967422569308 Test RE 1.0000272242487003\n",
      "5 Train Loss 47.76958 Test MSE 5222.853240226193 Test RE 1.0000162930991756\n",
      "6 Train Loss 47.76958 Test MSE 5222.84399266929 Test RE 1.0000154077869485\n",
      "7 Train Loss 47.769566 Test MSE 5222.826431361535 Test RE 1.0000137265579931\n",
      "8 Train Loss 47.769566 Test MSE 5222.81848968295 Test RE 1.0000129662617512\n",
      "9 Train Loss 47.769558 Test MSE 5222.8030113442 Test RE 1.0000114844420265\n",
      "10 Train Loss 47.76955 Test MSE 5222.786847267916 Test RE 1.0000099369708322\n",
      "11 Train Loss 47.76955 Test MSE 5222.78094824321 Test RE 1.0000093722258825\n",
      "12 Train Loss 47.76955 Test MSE 5222.775360801587 Test RE 1.0000088373101415\n",
      "13 Train Loss 47.76954 Test MSE 5222.763983765665 Test RE 1.0000077481246152\n",
      "14 Train Loss 47.76954 Test MSE 5222.758526129554 Test RE 1.000007225635006\n",
      "15 Train Loss 47.769535 Test MSE 5222.749905682288 Test RE 1.000006400351483\n",
      "16 Train Loss 47.769527 Test MSE 5222.7421244679435 Test RE 1.0000056554118264\n",
      "17 Train Loss 47.769527 Test MSE 5222.738609510154 Test RE 1.0000053189048559\n",
      "18 Train Loss 47.769527 Test MSE 5222.7352780348765 Test RE 1.000004999963609\n",
      "19 Train Loss 47.76952 Test MSE 5222.732118264456 Test RE 1.0000046974605594\n",
      "20 Train Loss 47.76952 Test MSE 5222.726201245591 Test RE 1.0000041309899652\n",
      "21 Train Loss 47.76952 Test MSE 5222.720856767871 Test RE 1.000003619331785\n",
      "22 Train Loss 47.76952 Test MSE 5222.718389846518 Test RE 1.0000033831588553\n",
      "23 Train Loss 47.76952 Test MSE 5222.716025198159 Test RE 1.0000031567770697\n",
      "24 Train Loss 47.769512 Test MSE 5222.711526807557 Test RE 1.0000027261193674\n",
      "25 Train Loss 47.769512 Test MSE 5222.709404613573 Test RE 1.000002522949043\n",
      "26 Train Loss 47.769512 Test MSE 5222.707337988856 Test RE 1.000002325098658\n",
      "27 Train Loss 47.769512 Test MSE 5222.7053254298335 Test RE 1.0000021324242685\n",
      "28 Train Loss 47.769512 Test MSE 5222.703336900847 Test RE 1.0000019420503825\n",
      "29 Train Loss 47.769512 Test MSE 5222.701370687061 Test RE 1.0000017538128296\n",
      "30 Train Loss 47.769512 Test MSE 5222.699612960477 Test RE 1.0000015855349895\n",
      "31 Train Loss 47.769512 Test MSE 5222.699612960477 Test RE 1.0000015855349895\n",
      "32 Train Loss 47.769512 Test MSE 5222.697891029381 Test RE 1.0000014206840413\n",
      "33 Train Loss 47.769512 Test MSE 5222.696204434069 Test RE 1.0000012592159762\n",
      "34 Train Loss 47.769505 Test MSE 5222.694606772584 Test RE 1.0000011062620653\n",
      "35 Train Loss 47.769505 Test MSE 5222.694606772584 Test RE 1.0000011062620653\n",
      "36 Train Loss 47.769505 Test MSE 5222.693095074093 Test RE 1.0000009615378966\n",
      "37 Train Loss 47.769505 Test MSE 5222.6915312225965 Test RE 1.0000008118207784\n",
      "38 Train Loss 47.7695 Test MSE 5222.68993190617 Test RE 1.0000006587083614\n",
      "39 Train Loss 47.7695 Test MSE 5222.688305651012 Test RE 1.0000005030169097\n",
      "40 Train Loss 47.769505 Test MSE 5222.686628521252 Test RE 1.0000003424548924\n",
      "41 Train Loss 47.7695 Test MSE 5222.684861479363 Test RE 1.0000001732850026\n",
      "42 Train Loss 47.7695 Test MSE 5222.682722603746 Test RE 0.9999999685171234\n",
      "43 Train Loss 47.7695 Test MSE 5222.680090272674 Test RE 0.9999997165076233\n",
      "44 Train Loss 47.7695 Test MSE 5222.676623862362 Test RE 0.99999938464641\n",
      "45 Train Loss 47.769497 Test MSE 5222.672104827507 Test RE 0.9999989520106777\n",
      "46 Train Loss 47.769497 Test MSE 5222.666208996102 Test RE 0.9999983875652395\n",
      "47 Train Loss 47.76948 Test MSE 5222.644389301959 Test RE 0.9999962986243731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "49 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "50 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "51 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "52 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "53 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "54 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "55 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "56 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "57 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "58 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "59 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "60 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "61 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "62 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "63 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "64 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "65 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "66 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "67 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "68 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "69 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "70 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "71 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "72 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "73 Train Loss 47.769028 Test MSE 5221.510300863163 Test RE 0.999887718973015\n",
      "74 Train Loss 47.769024 Test MSE 5221.508838054385 Test RE 0.9998875789134778\n",
      "75 Train Loss 47.769024 Test MSE 5221.504676546067 Test RE 0.9998871804614751\n",
      "76 Train Loss 47.766693 Test MSE 5217.486784671464 Test RE 0.9995024051937811\n",
      "77 Train Loss 47.7431 Test MSE 5188.075880683994 Test RE 0.9966813330705395\n",
      "78 Train Loss 47.480846 Test MSE 5223.87954837802 Test RE 1.0001145415480834\n",
      "79 Train Loss 46.594357 Test MSE 5099.439119976787 Test RE 0.9881306495556608\n",
      "80 Train Loss 43.69213 Test MSE 4718.013504237684 Test RE 0.9504576148198985\n",
      "81 Train Loss 37.435265 Test MSE 4057.271642651771 Test RE 0.8813942388745061\n",
      "82 Train Loss 29.754389 Test MSE 3332.196260937633 Test RE 0.7987639409517248\n",
      "83 Train Loss 25.505035 Test MSE 2616.124592345237 Test RE 0.7077540713819302\n",
      "84 Train Loss 19.503416 Test MSE 2066.246842438125 Test RE 0.6289907607430584\n",
      "85 Train Loss 14.600631 Test MSE 1655.1855055819863 Test RE 0.5629586569997975\n",
      "86 Train Loss 11.543726 Test MSE 1402.9737628632856 Test RE 0.5182960980976998\n",
      "87 Train Loss 10.129461 Test MSE 1171.4897331999582 Test RE 0.4736116842276365\n",
      "88 Train Loss 8.127861 Test MSE 710.4745865045036 Test RE 0.3688310191679542\n",
      "89 Train Loss 6.106648 Test MSE 680.2334521059103 Test RE 0.3608960738770885\n",
      "90 Train Loss 5.7060556 Test MSE 609.3912184874013 Test RE 0.34158694209920054\n",
      "91 Train Loss 5.295346 Test MSE 492.674314965902 Test RE 0.307137698335035\n",
      "92 Train Loss 4.0300364 Test MSE 403.9480687123162 Test RE 0.27810956945129095\n",
      "93 Train Loss 3.5620172 Test MSE 395.44250246671646 Test RE 0.2751660423844011\n",
      "94 Train Loss 3.2940135 Test MSE 284.0623082953722 Test RE 0.2332168743978233\n",
      "95 Train Loss 2.747026 Test MSE 186.42749396488136 Test RE 0.1889331413294924\n",
      "96 Train Loss 2.6899788 Test MSE 185.79340285857484 Test RE 0.18861156090017597\n",
      "97 Train Loss 2.6442957 Test MSE 184.4174418217562 Test RE 0.18791184702713967\n",
      "98 Train Loss 2.6177833 Test MSE 189.8410005577912 Test RE 0.19065498791199248\n",
      "99 Train Loss 2.5931594 Test MSE 188.81105039394853 Test RE 0.19013710137315445\n",
      "Training time: 46.67\n",
      "Training time: 46.67\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 47.76888 Test MSE 5221.231363247126 Test RE 0.9998610111810625\n",
      "1 Train Loss 47.76862 Test MSE 5220.851336604863 Test RE 0.9998246231424264\n",
      "2 Train Loss 47.742615 Test MSE 5184.445560435109 Test RE 0.9963325616092892\n",
      "3 Train Loss 47.580387 Test MSE 5128.137360307481 Test RE 0.9909072123164689\n",
      "4 Train Loss 45.85344 Test MSE 4985.24761797162 Test RE 0.9770044279181518\n",
      "5 Train Loss 44.92744 Test MSE 4928.069236077672 Test RE 0.9713853851182737\n",
      "6 Train Loss 41.115845 Test MSE 4683.854642951767 Test RE 0.9470106631831419\n",
      "7 Train Loss 37.84352 Test MSE 4381.820973009203 Test RE 0.9159683754131664\n",
      "8 Train Loss 35.60023 Test MSE 4126.5833381195935 Test RE 0.8888909300556754\n",
      "9 Train Loss 30.900696 Test MSE 3475.4145261819795 Test RE 0.8157488508757382\n",
      "10 Train Loss 27.502861 Test MSE 3008.74294959696 Test RE 0.7590068711099769\n",
      "11 Train Loss 24.280418 Test MSE 2820.490513175368 Test RE 0.734878406451081\n",
      "12 Train Loss 21.113375 Test MSE 2582.1443337625196 Test RE 0.7031426183009074\n",
      "13 Train Loss 18.132874 Test MSE 2079.243149185393 Test RE 0.6309657771975135\n",
      "14 Train Loss 14.346163 Test MSE 1920.8824163333907 Test RE 0.6064619460845299\n",
      "15 Train Loss 10.461636 Test MSE 1267.705662539828 Test RE 0.49267710383261026\n",
      "16 Train Loss 9.210869 Test MSE 1172.777367494883 Test RE 0.47387189613856046\n",
      "17 Train Loss 8.597436 Test MSE 1181.9634662889869 Test RE 0.475724141634317\n",
      "18 Train Loss 8.163546 Test MSE 1139.7728212066054 Test RE 0.46715641074684466\n",
      "19 Train Loss 7.9564695 Test MSE 1236.3076936754817 Test RE 0.4865376471898821\n",
      "20 Train Loss 6.472787 Test MSE 1018.1312361391185 Test RE 0.4415247421274229\n",
      "21 Train Loss 5.9795294 Test MSE 1036.3975330375995 Test RE 0.4454678336446315\n",
      "22 Train Loss 5.4198966 Test MSE 1030.6548774507921 Test RE 0.4442319556141174\n",
      "23 Train Loss 3.8089788 Test MSE 600.7947203650027 Test RE 0.33916905272025893\n",
      "24 Train Loss 3.1558871 Test MSE 437.16918308449556 Test RE 0.28931965244936225\n",
      "25 Train Loss 2.7033594 Test MSE 349.8349949769629 Test RE 0.2588122272623537\n",
      "26 Train Loss 1.7028555 Test MSE 283.64634354698035 Test RE 0.2330460570530753\n",
      "27 Train Loss 1.0028516 Test MSE 356.1934948927014 Test RE 0.26115368394065797\n",
      "28 Train Loss 0.9131062 Test MSE 312.71940234614414 Test RE 0.24469808939534768\n",
      "29 Train Loss 0.8758112 Test MSE 244.57035750338716 Test RE 0.2163989124770962\n",
      "30 Train Loss 0.75855076 Test MSE 230.61745865686586 Test RE 0.2101354167656851\n",
      "31 Train Loss 0.6964186 Test MSE 231.23519688071679 Test RE 0.2104166657848107\n",
      "32 Train Loss 0.53019446 Test MSE 108.4800141223039 Test RE 0.14412125364926284\n",
      "33 Train Loss 0.41740954 Test MSE 47.6017023278092 Test RE 0.09546944696171622\n",
      "34 Train Loss 0.27412504 Test MSE 50.748655806589355 Test RE 0.09857469373190375\n",
      "35 Train Loss 0.18811207 Test MSE 50.87972359672212 Test RE 0.09870190533750235\n",
      "36 Train Loss 0.16499405 Test MSE 19.103030529899996 Test RE 0.06047895793303978\n",
      "37 Train Loss 0.14812455 Test MSE 10.539194375614946 Test RE 0.04492177123290985\n",
      "38 Train Loss 0.13779391 Test MSE 12.798727499575637 Test RE 0.04950357470585484\n",
      "39 Train Loss 0.111086264 Test MSE 8.290754662244233 Test RE 0.03984283166921332\n",
      "40 Train Loss 0.0918177 Test MSE 4.35534610559837 Test RE 0.028877826383266095\n",
      "41 Train Loss 0.07548737 Test MSE 5.6917096488995 Test RE 0.033012205000018294\n",
      "42 Train Loss 0.07176375 Test MSE 7.84549860668549 Test RE 0.03875818572530994\n",
      "43 Train Loss 0.064470075 Test MSE 9.178943643422928 Test RE 0.04192272616865082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 0.044472314 Test MSE 6.257381909226535 Test RE 0.03461381720167681\n",
      "45 Train Loss 0.03756629 Test MSE 6.340841158644173 Test RE 0.034843887405392765\n",
      "46 Train Loss 0.031897917 Test MSE 7.5869054129025955 Test RE 0.03811408511773105\n",
      "47 Train Loss 0.028029533 Test MSE 4.5492852616111135 Test RE 0.02951377415659407\n",
      "48 Train Loss 0.0258028 Test MSE 2.890506410077403 Test RE 0.023525568827701474\n",
      "49 Train Loss 0.02422102 Test MSE 2.9832565179016775 Test RE 0.023900030972376415\n",
      "50 Train Loss 0.0223454 Test MSE 3.1101756133418688 Test RE 0.024403134892757368\n",
      "51 Train Loss 0.021040883 Test MSE 2.496625161680457 Test RE 0.021864010952963784\n",
      "52 Train Loss 0.019329445 Test MSE 2.1628860431749986 Test RE 0.02035026100869495\n",
      "53 Train Loss 0.01687193 Test MSE 1.2309180988081476 Test RE 0.015352098329419693\n",
      "54 Train Loss 0.014289323 Test MSE 1.0513369211541441 Test RE 0.014188096147357838\n",
      "55 Train Loss 0.012994511 Test MSE 0.546850851762112 Test RE 0.010232638017986899\n",
      "56 Train Loss 0.012436617 Test MSE 0.45438601145312196 Test RE 0.009327508234677439\n",
      "57 Train Loss 0.011964828 Test MSE 0.46419420281761475 Test RE 0.009427640661899666\n",
      "58 Train Loss 0.011592524 Test MSE 0.35465795157177 Test RE 0.008240584467763806\n",
      "59 Train Loss 0.011326315 Test MSE 0.34256693063016974 Test RE 0.008098897133631565\n",
      "60 Train Loss 0.011027769 Test MSE 0.40430222357194245 Test RE 0.008798451200324839\n",
      "61 Train Loss 0.010824423 Test MSE 0.4198364301132417 Test RE 0.008965886255657916\n",
      "62 Train Loss 0.010753492 Test MSE 0.35950843981204045 Test RE 0.008296744380311718\n",
      "63 Train Loss 0.010631424 Test MSE 0.2830522021493159 Test RE 0.007361841005466146\n",
      "64 Train Loss 0.010417554 Test MSE 0.3093255681862997 Test RE 0.0076959293889628105\n",
      "65 Train Loss 0.010092858 Test MSE 0.5005425533307921 Test RE 0.009789796562586333\n",
      "66 Train Loss 0.009560022 Test MSE 0.44582799284756586 Test RE 0.009239252401921314\n",
      "67 Train Loss 0.009101953 Test MSE 0.2685067221369293 Test RE 0.007170191355255999\n",
      "68 Train Loss 0.008605821 Test MSE 0.29206435314226875 Test RE 0.0074781202022416084\n",
      "69 Train Loss 0.00769818 Test MSE 0.4858760423748494 Test RE 0.009645303713460595\n",
      "70 Train Loss 0.0062543363 Test MSE 0.20767869978899833 Test RE 0.006305929960366442\n",
      "71 Train Loss 0.0054364796 Test MSE 0.03674895161376355 Test RE 0.0026526236761562714\n",
      "72 Train Loss 0.005180863 Test MSE 0.05410147314210494 Test RE 0.003218531100625335\n",
      "73 Train Loss 0.0049025575 Test MSE 0.09368656626745231 Test RE 0.004235374578536952\n",
      "74 Train Loss 0.004671351 Test MSE 0.054718958362973684 Test RE 0.0032368462835445757\n",
      "75 Train Loss 0.004618505 Test MSE 0.03581453010197946 Test RE 0.002618682183216685\n",
      "76 Train Loss 0.004499695 Test MSE 0.026752001809580997 Test RE 0.0022632436328329526\n",
      "77 Train Loss 0.0042178044 Test MSE 0.022847157312459815 Test RE 0.002091554813670994\n",
      "78 Train Loss 0.004049436 Test MSE 0.04998234111334983 Test RE 0.0030935807861977613\n",
      "79 Train Loss 0.0036680324 Test MSE 0.06428964600107431 Test RE 0.0035085177812268164\n",
      "80 Train Loss 0.0035138386 Test MSE 0.026492623309317516 Test RE 0.0022522450800556717\n",
      "81 Train Loss 0.0034580214 Test MSE 0.019827764834808154 Test RE 0.001948453493621517\n",
      "82 Train Loss 0.003382738 Test MSE 0.030792485158052694 Test RE 0.0024281501291730538\n",
      "83 Train Loss 0.0033452292 Test MSE 0.04168018971195559 Test RE 0.0028249971121344216\n",
      "84 Train Loss 0.0033448513 Test MSE 0.04031863787045909 Test RE 0.0027784724212544013\n",
      "85 Train Loss 0.0033264067 Test MSE 0.04057031147791006 Test RE 0.002787130704106388\n",
      "86 Train Loss 0.003302057 Test MSE 0.03785394363937403 Test RE 0.002692208742784337\n",
      "87 Train Loss 0.0032585454 Test MSE 0.03159012718704627 Test RE 0.0024593982059889856\n",
      "88 Train Loss 0.0032185062 Test MSE 0.03489098823631939 Test RE 0.0025846979589024574\n",
      "89 Train Loss 0.0031487152 Test MSE 0.03993064437214983 Test RE 0.0027650712330753433\n",
      "90 Train Loss 0.0030871562 Test MSE 0.033733468770263335 Test RE 0.0025414622627161496\n",
      "91 Train Loss 0.003052908 Test MSE 0.022938504547176046 Test RE 0.0020957318575693944\n",
      "92 Train Loss 0.0030099188 Test MSE 0.018785086724925598 Test RE 0.0018965302181776734\n",
      "93 Train Loss 0.0029985947 Test MSE 0.019674456081145722 Test RE 0.001940906131622747\n",
      "94 Train Loss 0.0029970538 Test MSE 0.01995452198266805 Test RE 0.001954671716789545\n",
      "95 Train Loss 0.0029960745 Test MSE 0.02012984816053695 Test RE 0.0019632400912642464\n",
      "96 Train Loss 0.0029951392 Test MSE 0.020378263800023045 Test RE 0.0019753167874773914\n",
      "97 Train Loss 0.0029935094 Test MSE 0.020772657753415545 Test RE 0.0019943399894439104\n",
      "98 Train Loss 0.0029914815 Test MSE 0.020641428488599622 Test RE 0.0019880304833238354\n",
      "99 Train Loss 0.002982676 Test MSE 0.022709580056205946 Test RE 0.002085248014541399\n",
      "Training time: 67.47\n",
      "Training time: 67.47\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 47.770424 Test MSE 5220.102444583627 Test RE 0.9997529118938597\n",
      "1 Train Loss 47.768414 Test MSE 5220.253445555174 Test RE 0.9997673716262973\n",
      "2 Train Loss 47.768257 Test MSE 5220.065478553252 Test RE 0.9997493720244482\n",
      "3 Train Loss 47.40671 Test MSE 5142.749863361934 Test RE 0.9923179910727588\n",
      "4 Train Loss 47.035168 Test MSE 5135.400575842525 Test RE 0.9916086976253335\n",
      "5 Train Loss 44.78515 Test MSE 4939.031668671705 Test RE 0.972465202676796\n",
      "6 Train Loss 43.04296 Test MSE 4817.249138051295 Test RE 0.9604012541815662\n",
      "7 Train Loss 41.590797 Test MSE 4639.346220326872 Test RE 0.9425004290557999\n",
      "8 Train Loss 38.993954 Test MSE 4352.016996517458 Test RE 0.9128479741439237\n",
      "9 Train Loss 35.23503 Test MSE 3913.9082873539714 Test RE 0.8656821987488071\n",
      "10 Train Loss 31.912619 Test MSE 3660.546454325491 Test RE 0.8371940362996971\n",
      "11 Train Loss 29.06723 Test MSE 3381.8312315492176 Test RE 0.8046909739515369\n",
      "12 Train Loss 25.94436 Test MSE 3092.5252791145003 Test RE 0.7695020725014368\n",
      "13 Train Loss 23.939615 Test MSE 2857.2576160480617 Test RE 0.7396527293951419\n",
      "14 Train Loss 22.755466 Test MSE 2664.690481581509 Test RE 0.7142932563767973\n",
      "15 Train Loss 20.914713 Test MSE 2447.6166389470027 Test RE 0.6845810341198945\n",
      "16 Train Loss 18.95013 Test MSE 2294.2617889046096 Test RE 0.6627880212058951\n",
      "17 Train Loss 15.533179 Test MSE 1823.4439519393907 Test RE 0.5908801139349683\n",
      "18 Train Loss 12.832468 Test MSE 1583.620216019415 Test RE 0.5506538541221254\n",
      "19 Train Loss 10.772501 Test MSE 1358.2505873503956 Test RE 0.5099682231533369\n",
      "20 Train Loss 9.456019 Test MSE 1272.065718182787 Test RE 0.493523615690516\n",
      "21 Train Loss 7.9290667 Test MSE 1034.3306324172827 Test RE 0.4450234109060765\n",
      "22 Train Loss 6.7307296 Test MSE 909.7607340926949 Test RE 0.4173657037951426\n",
      "23 Train Loss 5.7379146 Test MSE 744.5406163797388 Test RE 0.377569897407031\n",
      "24 Train Loss 4.8558235 Test MSE 658.9303582449289 Test RE 0.35519997218065097\n",
      "25 Train Loss 4.3463273 Test MSE 607.3395554064545 Test RE 0.3410114397265148\n",
      "26 Train Loss 3.8949108 Test MSE 538.3688985680325 Test RE 0.32106513407321774\n",
      "27 Train Loss 3.0832374 Test MSE 457.6121729943053 Test RE 0.29600697791121083\n",
      "28 Train Loss 2.7779994 Test MSE 431.3721163654602 Test RE 0.2873949941047818\n",
      "29 Train Loss 2.1611137 Test MSE 341.9253132963154 Test RE 0.25586965964797875\n",
      "30 Train Loss 1.8496459 Test MSE 305.8150489379906 Test RE 0.2419817377086598\n",
      "31 Train Loss 1.5898802 Test MSE 260.4322599565952 Test RE 0.2233060834154121\n",
      "32 Train Loss 1.1270212 Test MSE 197.08861584796327 Test RE 0.19426024602010003\n",
      "33 Train Loss 0.8553074 Test MSE 164.6034611560078 Test RE 0.1775303650792702\n",
      "34 Train Loss 0.67568314 Test MSE 142.2087692490994 Test RE 0.16501231364146587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.48499677 Test MSE 123.48761475637124 Test RE 0.1537676105262987\n",
      "36 Train Loss 0.40205735 Test MSE 114.75568059134099 Test RE 0.14823141733267076\n",
      "37 Train Loss 0.33818722 Test MSE 112.83095051687297 Test RE 0.1469830611730978\n",
      "38 Train Loss 0.25215483 Test MSE 98.49279630539262 Test RE 0.13732683108295177\n",
      "39 Train Loss 0.22478573 Test MSE 96.66151613736152 Test RE 0.13604417961319432\n",
      "40 Train Loss 0.20536625 Test MSE 94.23003465583979 Test RE 0.13432221354907262\n",
      "41 Train Loss 0.18392608 Test MSE 84.76229831459922 Test RE 0.127395628784754\n",
      "42 Train Loss 0.17228144 Test MSE 79.92933879087937 Test RE 0.12371041814718986\n",
      "43 Train Loss 0.16653372 Test MSE 76.83424696302313 Test RE 0.12129156069221528\n",
      "44 Train Loss 0.15718101 Test MSE 72.00767263159763 Test RE 0.11742012863369672\n",
      "45 Train Loss 0.1491108 Test MSE 71.05867905696073 Test RE 0.1166438188201364\n",
      "46 Train Loss 0.13461535 Test MSE 67.37851487523469 Test RE 0.11358314293898364\n",
      "47 Train Loss 0.12480894 Test MSE 59.28638215231516 Test RE 0.1065444027478051\n",
      "48 Train Loss 0.120557845 Test MSE 57.36644210405258 Test RE 0.10480502899372587\n",
      "49 Train Loss 0.110433705 Test MSE 52.67492789015459 Test RE 0.10042807530397053\n",
      "50 Train Loss 0.10320623 Test MSE 45.16706189780032 Test RE 0.0929959606521517\n",
      "51 Train Loss 0.09917041 Test MSE 42.60432146230255 Test RE 0.09031918106462833\n",
      "52 Train Loss 0.09572902 Test MSE 41.015617485830326 Test RE 0.0886191931862282\n",
      "53 Train Loss 0.091913104 Test MSE 39.56261653403919 Test RE 0.08703534756909048\n",
      "54 Train Loss 0.082677715 Test MSE 38.149608418622016 Test RE 0.08546695021437607\n",
      "55 Train Loss 0.078521974 Test MSE 35.96440719983025 Test RE 0.08298309294147137\n",
      "56 Train Loss 0.07233401 Test MSE 31.844736578737088 Test RE 0.07808578759012086\n",
      "57 Train Loss 0.06326032 Test MSE 24.71835514569317 Test RE 0.06879596209821563\n",
      "58 Train Loss 0.058836274 Test MSE 23.065327216496925 Test RE 0.06645581289848186\n",
      "59 Train Loss 0.055150684 Test MSE 20.697554200914674 Test RE 0.06295245611678349\n",
      "60 Train Loss 0.05280273 Test MSE 18.77735852881414 Test RE 0.05996121356092034\n",
      "61 Train Loss 0.050796065 Test MSE 17.642581525205262 Test RE 0.05812115433393145\n",
      "62 Train Loss 0.047006458 Test MSE 15.984728543528515 Test RE 0.055323009529429375\n",
      "63 Train Loss 0.04496898 Test MSE 15.41978551242959 Test RE 0.054336583886030555\n",
      "64 Train Loss 0.042536683 Test MSE 15.097834207947729 Test RE 0.05376634205883272\n",
      "65 Train Loss 0.041442472 Test MSE 14.424938760319382 Test RE 0.05255452966259078\n",
      "66 Train Loss 0.04022115 Test MSE 13.182164623688479 Test RE 0.050239641321847196\n",
      "67 Train Loss 0.039321437 Test MSE 12.967336242644325 Test RE 0.049828584571367025\n",
      "68 Train Loss 0.036644034 Test MSE 12.875735368889616 Test RE 0.04965227885256521\n",
      "69 Train Loss 0.034342296 Test MSE 12.560687045568843 Test RE 0.04904106153070471\n",
      "70 Train Loss 0.033416085 Test MSE 12.425897358713026 Test RE 0.048777220117613276\n",
      "71 Train Loss 0.032792483 Test MSE 12.526180529507355 Test RE 0.04897365279775255\n",
      "72 Train Loss 0.030851085 Test MSE 11.63338341643181 Test RE 0.047196107932636816\n",
      "73 Train Loss 0.029629944 Test MSE 10.126342630312344 Test RE 0.04403312150158568\n",
      "74 Train Loss 0.028364439 Test MSE 9.243507707839381 Test RE 0.042069908604647765\n",
      "75 Train Loss 0.02708856 Test MSE 8.43108740633814 Test RE 0.04017861485806737\n",
      "76 Train Loss 0.026414849 Test MSE 8.535155666574914 Test RE 0.040425824645553395\n",
      "77 Train Loss 0.025933173 Test MSE 8.07633902457431 Test RE 0.03932424881228806\n",
      "78 Train Loss 0.025273105 Test MSE 7.342504998550924 Test RE 0.03749516681486587\n",
      "79 Train Loss 0.023925748 Test MSE 6.551566588282505 Test RE 0.03541813952003231\n",
      "80 Train Loss 0.023560682 Test MSE 6.265724714698077 Test RE 0.034636884369170715\n",
      "81 Train Loss 0.023386724 Test MSE 5.910477807712703 Test RE 0.0336406563207064\n",
      "82 Train Loss 0.023126032 Test MSE 5.773116099973077 Test RE 0.03324744761409309\n",
      "83 Train Loss 0.022942124 Test MSE 5.691065039628872 Test RE 0.03301033556383438\n",
      "84 Train Loss 0.019940125 Test MSE 3.3788456301348138 Test RE 0.025435327855081367\n",
      "85 Train Loss 0.018012721 Test MSE 2.9082287226867116 Test RE 0.02359757876467991\n",
      "86 Train Loss 0.017393576 Test MSE 2.705266144311236 Test RE 0.02275926137387855\n",
      "87 Train Loss 0.017131187 Test MSE 2.5434439962090925 Test RE 0.02206806499507571\n",
      "88 Train Loss 0.016809667 Test MSE 2.338618749565839 Test RE 0.021160838775214744\n",
      "89 Train Loss 0.01661235 Test MSE 2.099270839738559 Test RE 0.020048754656623043\n",
      "90 Train Loss 0.016462158 Test MSE 1.8251962779896236 Test RE 0.018694245939135105\n",
      "91 Train Loss 0.016304843 Test MSE 1.6045117624923135 Test RE 0.017527687325180032\n",
      "92 Train Loss 0.016225737 Test MSE 1.5920894356045365 Test RE 0.01745970473443774\n",
      "93 Train Loss 0.016079618 Test MSE 1.544043700905049 Test RE 0.01719423898105518\n",
      "94 Train Loss 0.015637344 Test MSE 1.4232733843183596 Test RE 0.01650810903376023\n",
      "95 Train Loss 0.014949577 Test MSE 1.1161770693753656 Test RE 0.014619068893919653\n",
      "96 Train Loss 0.014329218 Test MSE 0.8456047711474189 Test RE 0.012724387227191311\n",
      "97 Train Loss 0.014023943 Test MSE 0.7593754903433767 Test RE 0.012058171392050135\n",
      "98 Train Loss 0.013750259 Test MSE 0.6182915109727073 Test RE 0.010880523882509329\n",
      "99 Train Loss 0.013568201 Test MSE 0.6026879144352487 Test RE 0.01074235266872753\n",
      "Training time: 71.45\n",
      "Training time: 71.45\n",
      "1D_FODE_rowdy\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 47.770218 Test MSE 5223.967816410568 Test RE 1.0001229909934795\n",
      "1 Train Loss 47.76999 Test MSE 5223.6714634419695 Test RE 1.0000946223634086\n",
      "2 Train Loss 47.769398 Test MSE 5222.441581382224 Test RE 0.9999768822978095\n",
      "3 Train Loss 47.760742 Test MSE 5203.63946263553 Test RE 0.9981751735534133\n",
      "4 Train Loss 47.732384 Test MSE 5135.99828323337 Test RE 0.9916664024327634\n",
      "5 Train Loss 47.71716 Test MSE 5105.419747674726 Test RE 0.9887099201087303\n",
      "6 Train Loss 47.670055 Test MSE 5028.972936695406 Test RE 0.9812796985310827\n",
      "7 Train Loss 47.6334 Test MSE 4967.419848468294 Test RE 0.9752559280475194\n",
      "8 Train Loss 47.545467 Test MSE 4932.150498273138 Test RE 0.9717875363246806\n",
      "9 Train Loss 47.444138 Test MSE 4926.02625967836 Test RE 0.971184015876185\n",
      "10 Train Loss 45.346092 Test MSE 4684.774684755922 Test RE 0.9471036684836094\n",
      "11 Train Loss 43.35308 Test MSE 4515.011402619692 Test RE 0.9297851174791367\n",
      "12 Train Loss 40.665302 Test MSE 4328.2036840944675 Test RE 0.9103470932886409\n",
      "13 Train Loss 29.91927 Test MSE 3592.003300021356 Test RE 0.8293188335453965\n",
      "14 Train Loss 24.163273 Test MSE 3076.3406620482438 Test RE 0.7674858507180157\n",
      "15 Train Loss 10.839025 Test MSE 2242.9943062270017 Test RE 0.6553408653132843\n",
      "16 Train Loss 7.8117905 Test MSE 1756.3842668755797 Test RE 0.5799131191945464\n",
      "17 Train Loss 7.1038847 Test MSE 1537.4616889963406 Test RE 0.5425694242122516\n",
      "18 Train Loss 6.72074 Test MSE 1426.1424491723296 Test RE 0.5225581410633392\n",
      "19 Train Loss 6.262417 Test MSE 1297.7912244863578 Test RE 0.49848900224630294\n",
      "20 Train Loss 6.055393 Test MSE 1234.9015360233557 Test RE 0.4862608781925975\n",
      "21 Train Loss 5.954396 Test MSE 1192.4409801244672 Test RE 0.4778280175327952\n",
      "22 Train Loss 5.89815 Test MSE 1152.0588645225735 Test RE 0.46966748993933205\n",
      "23 Train Loss 5.8814726 Test MSE 1148.2651089481103 Test RE 0.46889353948721324\n",
      "24 Train Loss 5.8405643 Test MSE 1171.4581903006665 Test RE 0.47360530807861984\n",
      "25 Train Loss 5.8072476 Test MSE 1179.703566504298 Test RE 0.4752691346493248\n",
      "26 Train Loss 5.7400093 Test MSE 1168.7963558063884 Test RE 0.47306692954281776\n",
      "27 Train Loss 5.718232 Test MSE 1161.0281753934776 Test RE 0.47149223447638666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 5.598738 Test MSE 1085.4651678861237 Test RE 0.45589109645737363\n",
      "29 Train Loss 5.430292 Test MSE 955.5600270417932 Test RE 0.42774225211000866\n",
      "30 Train Loss 5.1832943 Test MSE 780.4955115044132 Test RE 0.3865790990749594\n",
      "31 Train Loss 4.9928284 Test MSE 719.6081335363687 Test RE 0.371194212601364\n",
      "32 Train Loss 4.6261077 Test MSE 670.9985255171288 Test RE 0.35843791928019497\n",
      "33 Train Loss 4.5390496 Test MSE 713.8982941747188 Test RE 0.36971863146044665\n",
      "34 Train Loss 4.4587264 Test MSE 717.8194694289788 Test RE 0.37073260382961437\n",
      "35 Train Loss 4.326223 Test MSE 652.3596390588157 Test RE 0.3534245441886411\n",
      "36 Train Loss 4.1411095 Test MSE 579.6099600789314 Test RE 0.3331356300994037\n",
      "37 Train Loss 3.9633157 Test MSE 548.3846068863256 Test RE 0.32403788772633313\n",
      "38 Train Loss 3.828769 Test MSE 501.20426432451484 Test RE 0.3097851128963345\n",
      "39 Train Loss 3.6774795 Test MSE 430.60936419242574 Test RE 0.2871407957734458\n",
      "40 Train Loss 3.4770453 Test MSE 376.652817531975 Test RE 0.2685491455627126\n",
      "41 Train Loss 3.2536533 Test MSE 383.47805200855106 Test RE 0.2709713786635093\n",
      "42 Train Loss 3.126836 Test MSE 407.40359461898515 Test RE 0.27929656404094094\n",
      "43 Train Loss 3.0072608 Test MSE 422.24619376071996 Test RE 0.2843387411804306\n",
      "44 Train Loss 2.9277027 Test MSE 442.31783503283907 Test RE 0.29101836089083627\n",
      "45 Train Loss 2.8563027 Test MSE 471.0002166069286 Test RE 0.3003057986284424\n",
      "46 Train Loss 2.7688282 Test MSE 517.7472884780506 Test RE 0.31485607790302006\n",
      "47 Train Loss 2.7398548 Test MSE 568.2919479683565 Test RE 0.3298670343626272\n",
      "48 Train Loss 2.714631 Test MSE 634.2127515275937 Test RE 0.34847421588912286\n",
      "49 Train Loss 2.6777284 Test MSE 658.9141632151861 Test RE 0.3551956071446587\n",
      "50 Train Loss 2.652564 Test MSE 651.6825660384899 Test RE 0.3532410899010386\n",
      "51 Train Loss 2.6295357 Test MSE 638.6260570821704 Test RE 0.3496845802072943\n",
      "52 Train Loss 2.5302508 Test MSE 607.7712253715441 Test RE 0.34113260608862417\n",
      "53 Train Loss 2.135827 Test MSE 503.9149288880001 Test RE 0.3106216891962116\n",
      "54 Train Loss 1.8702838 Test MSE 611.9852616089465 Test RE 0.3423131999274729\n",
      "55 Train Loss 1.8303548 Test MSE 655.6273267244807 Test RE 0.35430859522249164\n",
      "56 Train Loss 1.788117 Test MSE 663.6633982080958 Test RE 0.3564733749774899\n",
      "57 Train Loss 1.6902122 Test MSE 655.0953301359733 Test RE 0.3541648174934035\n",
      "58 Train Loss 1.6500564 Test MSE 616.4625982911996 Test RE 0.34356311434389875\n",
      "59 Train Loss 1.6199162 Test MSE 554.4456036168119 Test RE 0.32582367419981667\n",
      "60 Train Loss 1.5734887 Test MSE 448.67337591157343 Test RE 0.29310168450003055\n",
      "61 Train Loss 1.5443907 Test MSE 444.92509601805585 Test RE 0.29187481060282894\n",
      "62 Train Loss 1.4710163 Test MSE 506.3234407388581 Test RE 0.3113631280373435\n",
      "63 Train Loss 1.4411675 Test MSE 472.9484523445425 Test RE 0.3009262470935004\n",
      "64 Train Loss 1.423119 Test MSE 459.8610027365298 Test RE 0.2967334156228362\n",
      "65 Train Loss 1.4182589 Test MSE 462.31066296658366 Test RE 0.29752270910116946\n",
      "66 Train Loss 1.4045334 Test MSE 472.2766722930733 Test RE 0.300712452032003\n",
      "67 Train Loss 1.3856302 Test MSE 476.08024324809907 Test RE 0.30192094646658896\n",
      "68 Train Loss 1.3735806 Test MSE 478.8942088762604 Test RE 0.30281191332529944\n",
      "69 Train Loss 1.3659384 Test MSE 479.13221753711684 Test RE 0.3028871521818242\n",
      "70 Train Loss 1.3579459 Test MSE 472.98258998467605 Test RE 0.30093710739604485\n",
      "71 Train Loss 1.3495274 Test MSE 475.44178058427747 Test RE 0.3017184281659915\n",
      "72 Train Loss 1.3448738 Test MSE 472.76000678886714 Test RE 0.3008662893290552\n",
      "73 Train Loss 1.3350633 Test MSE 451.87810693003416 Test RE 0.29414658795554127\n",
      "74 Train Loss 1.3219917 Test MSE 420.11701020974124 Test RE 0.2836209437122401\n",
      "75 Train Loss 1.2946198 Test MSE 400.2603764621367 Test RE 0.27683721045681076\n",
      "76 Train Loss 1.2748629 Test MSE 394.7314454654954 Test RE 0.2749185389245547\n",
      "77 Train Loss 1.2636068 Test MSE 393.4446521697439 Test RE 0.2744700667824832\n",
      "78 Train Loss 1.2508533 Test MSE 404.68250882068304 Test RE 0.27836227775803085\n",
      "79 Train Loss 1.2222406 Test MSE 342.0999710531065 Test RE 0.25593500127897917\n",
      "80 Train Loss 1.2013774 Test MSE 290.58930524131273 Test RE 0.2358810096234046\n",
      "81 Train Loss 1.1934311 Test MSE 267.3514559705022 Test RE 0.2262530495040429\n",
      "82 Train Loss 1.1681191 Test MSE 284.3559239923387 Test RE 0.2333373734001392\n",
      "83 Train Loss 1.135256 Test MSE 348.09412946180555 Test RE 0.2581674672927209\n",
      "84 Train Loss 1.1287793 Test MSE 339.41485820417245 Test RE 0.25492861687644813\n",
      "85 Train Loss 1.112922 Test MSE 295.4347422663401 Test RE 0.23783948047833584\n",
      "86 Train Loss 1.0551119 Test MSE 196.04165477663548 Test RE 0.19374359077465683\n",
      "87 Train Loss 1.0196807 Test MSE 150.55231544162865 Test RE 0.1697840481705748\n",
      "88 Train Loss 0.94540703 Test MSE 160.98955430539593 Test RE 0.17557068909892878\n",
      "89 Train Loss 0.9183984 Test MSE 168.61928904120086 Test RE 0.17968291791676524\n",
      "90 Train Loss 0.8886654 Test MSE 147.85312391135992 Test RE 0.16825516977564395\n",
      "91 Train Loss 0.86984676 Test MSE 129.69605223887058 Test RE 0.15758560492057727\n",
      "92 Train Loss 0.845149 Test MSE 119.31645092516416 Test RE 0.15114832127586098\n",
      "93 Train Loss 0.8090874 Test MSE 135.46168378714825 Test RE 0.1610502485731407\n",
      "94 Train Loss 0.7797969 Test MSE 140.55704970184513 Test RE 0.16405122626607996\n",
      "95 Train Loss 0.7660275 Test MSE 127.94089021446219 Test RE 0.15651567869753133\n",
      "96 Train Loss 0.7504143 Test MSE 136.56620237309866 Test RE 0.16170549607923373\n",
      "97 Train Loss 0.741194 Test MSE 154.0215377061768 Test RE 0.17172909932009647\n",
      "98 Train Loss 0.73569095 Test MSE 170.7716842297745 Test RE 0.18082609160298205\n",
      "99 Train Loss 0.73063385 Test MSE 178.87156918602804 Test RE 0.1850648003988067\n",
      "Training time: 71.69\n",
      "Training time: 71.69\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 100\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val =8.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):  \n",
    "  print(label) \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  alpha_val = []\n",
    "  omega_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  alpha_full.append(alpha_val)\n",
    "  omega_full.append(omega_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,\"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "77a1e198-62ae-4129-82a3-1a1f3e433466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_rowdy'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d2yA4xTDHldi"
   },
   "outputs": [],
   "source": [
    "#3,4,8,9,13,14,18,19,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "1986cfc6-aa7b-43ff-e3e8-c586ef7bafd1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c7a36e1a22f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  if tune_reps not in s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_rowdy_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(70):\n",
    "#  if tune_reps not in s:\n",
    "    label = \"1D_FODE_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2eNXAFRRtWs",
    "outputId": "737b4c47-e8bf-4e68-c774-00d25a78ecb3"
   },
   "outputs": [],
   "source": [
    "lrnr_tune[2]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "atanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
