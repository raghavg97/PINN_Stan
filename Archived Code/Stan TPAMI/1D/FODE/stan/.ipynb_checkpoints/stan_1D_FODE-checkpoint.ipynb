{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "4c900037-3d26-473d-c9aa-392edcfda7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "a1b70a95-2d46-4fe5-8a51-d369c604c433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/stan\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "2d3abfaa-8287-4fe9-d053-d79e6506dc03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting smt\n",
      "  Downloading smt-1.2.0.tar.gz (252 kB)\n",
      "\u001b[K     |████████████████████████████████| 252 kB 8.8 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting numpydoc\n",
      "  Downloading numpydoc-1.4.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 840 kB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from smt) (21.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from smt) (3.2.2)\n",
      "Collecting pyDOE2\n",
      "  Downloading pyDOE2-1.3.0.tar.gz (19 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from smt) (1.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from smt) (1.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smt) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->smt) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->smt) (1.15.0)\n",
      "Collecting sphinx>=3.0\n",
      "  Downloading Sphinx-5.1.1-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 47.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc->smt) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc->smt) (2.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (1.1.5)\n",
      "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.10.3)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.2.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (0.7.12)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (4.12.0)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 4.3 MB/s \n",
      "\u001b[?25hCollecting sphinxcontrib-qthelp\n",
      "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 12.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: docutils<0.20,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (0.17.1)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc->smt) (2.6.1)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 12.1 MB/s \n",
      "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
      "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 51.5 MB/s \n",
      "\u001b[?25hCollecting sphinxcontrib-jsmath\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx>=3.0->numpydoc->smt) (2022.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc->smt) (3.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.0->numpydoc->smt) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->smt) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->smt) (1.1.0)\n",
      "Building wheels for collected packages: smt, pyDOE2\n",
      "  Building wheel for smt (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for smt: filename=smt-1.2.0-cp37-cp37m-linux_x86_64.whl size=527851 sha256=3bf92c13644b76c21e3040a5f2bec7239da9a2b8cfb54bb2b90140b8e8573143\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/69/1e/ae0014b43757c2db9bdd61fdae3a4f532f9d64c451a1bc678e\n",
      "  Building wheel for pyDOE2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyDOE2: filename=pyDOE2-1.3.0-py3-none-any.whl size=25539 sha256=0e083244d6627933016f7cc8e65d769afb98854b81fa4f4a036916fa4c984f83\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/91/2d/d08e80806bf7756193541f6c03c0492af288fcd6158d3d0998\n",
      "Successfully built smt pyDOE2\n",
      "Installing collected packages: sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, pyDOE2, numpydoc, smt\n",
      "  Attempting uninstall: sphinx\n",
      "    Found existing installation: Sphinx 1.8.6\n",
      "    Uninstalling Sphinx-1.8.6:\n",
      "      Successfully uninstalled Sphinx-1.8.6\n",
      "Successfully installed numpydoc-1.4.0 pyDOE2-1.3.0 smt-1.2.0 sphinx-5.1.1 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "sphinxcontrib"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmSz5jcVVt4p"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = 100*np.sin(0.01*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(-100,100,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.iter = 0\n",
    "        \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - torch.cos(0.01*g)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "\n",
    "  x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "  f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    train_step(i)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Training time: 19.24\n",
      "Training time: 19.24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 69.48927 Test MSE 2556.1104611780397 Test RE 0.9680488885080645\n",
      "1 Train Loss 51.31179 Test MSE 1674.8617158269062 Test RE 0.7836045689203713\n",
      "2 Train Loss 29.049488 Test MSE 861.3493835406105 Test RE 0.5619493269538826\n",
      "3 Train Loss 16.672113 Test MSE 473.18177722600865 Test RE 0.4165062160616057\n",
      "4 Train Loss 3.3105488 Test MSE 33.86898462921281 Test RE 0.1114316523030815\n",
      "5 Train Loss 1.3175329 Test MSE 11.648955376631147 Test RE 0.06535080965683714\n",
      "6 Train Loss 0.44540986 Test MSE 1.6197644499403718 Test RE 0.02436875901928219\n",
      "7 Train Loss 0.1672262 Test MSE 1.512933275752688 Test RE 0.023551434740465296\n",
      "8 Train Loss 0.021725506 Test MSE 0.038504983611651056 Test RE 0.0037572141842949305\n",
      "9 Train Loss 0.015589047 Test MSE 0.019751699957626878 Test RE 0.0026909753630726015\n",
      "10 Train Loss 0.012285544 Test MSE 0.03899810422390693 Test RE 0.0037811963464440593\n",
      "11 Train Loss 0.0073222667 Test MSE 0.015016922991675207 Test RE 0.0023463778953664804\n",
      "12 Train Loss 0.005829876 Test MSE 0.0037094240968061102 Test RE 0.001166166942392071\n",
      "13 Train Loss 0.005736463 Test MSE 0.0041092452825371335 Test RE 0.0012274067700471856\n",
      "14 Train Loss 0.005022851 Test MSE 0.0027410177699520744 Test RE 0.0010024515860671411\n",
      "15 Train Loss 0.0035918225 Test MSE 0.001962229467385037 Test RE 0.0008481689672151861\n",
      "16 Train Loss 0.0034317009 Test MSE 0.0023954028069206722 Test RE 0.0009371233492521289\n",
      "17 Train Loss 0.003388114 Test MSE 0.0024982032912560285 Test RE 0.0009570207845458547\n",
      "18 Train Loss 0.0030465445 Test MSE 0.002272962651184477 Test RE 0.0009128588525980475\n",
      "19 Train Loss 0.0027682383 Test MSE 0.0028163932942830584 Test RE 0.0010161413688310873\n",
      "20 Train Loss 0.0027430374 Test MSE 0.0028877745058028923 Test RE 0.0010289377967299077\n",
      "21 Train Loss 0.0026851597 Test MSE 0.002695849449341654 Test RE 0.0009941577430480563\n",
      "22 Train Loss 0.0020378674 Test MSE 0.001168235545707026 Test RE 0.0006544443006670492\n",
      "23 Train Loss 0.0016057417 Test MSE 0.0014369083086023516 Test RE 0.000725808432865531\n",
      "24 Train Loss 0.0014842087 Test MSE 0.0015119358254888804 Test RE 0.0007445162148135356\n",
      "25 Train Loss 0.0014071043 Test MSE 0.001458270103625815 Test RE 0.0007311836438676887\n",
      "26 Train Loss 0.0013418868 Test MSE 0.000922655976739771 Test RE 0.0005816039956028265\n",
      "27 Train Loss 0.0009421331 Test MSE 0.0010979219612546284 Test RE 0.0006344438879440014\n",
      "28 Train Loss 0.0006139291 Test MSE 0.0005669928422722421 Test RE 0.00045592800581254\n",
      "29 Train Loss 0.00055677467 Test MSE 0.0003666781699431082 Test RE 0.00036664858169943695\n",
      "30 Train Loss 0.00052792364 Test MSE 0.0002941564822902086 Test RE 0.0003283951189619598\n",
      "31 Train Loss 0.0005151084 Test MSE 0.00033266014811641494 Test RE 0.00034922704571600734\n",
      "32 Train Loss 0.00050197635 Test MSE 0.0003085003894967675 Test RE 0.00033630656106382775\n",
      "33 Train Loss 0.0005012606 Test MSE 0.00030410325100271033 Test RE 0.00033390122568703286\n",
      "34 Train Loss 0.0005002749 Test MSE 0.00030268017958099466 Test RE 0.00033311905304209203\n",
      "35 Train Loss 0.00049633486 Test MSE 0.0002768073880986498 Test RE 0.00031856372465605565\n",
      "36 Train Loss 0.0004774167 Test MSE 0.00022194481547834033 Test RE 0.00028525284465417717\n",
      "37 Train Loss 0.00044281164 Test MSE 0.0001864783594249218 Test RE 0.00026146990052178964\n",
      "38 Train Loss 0.00044198165 Test MSE 0.00018707897793368927 Test RE 0.0002618906394536541\n",
      "39 Train Loss 0.000437924 Test MSE 0.00019319054215577165 Test RE 0.0002661340312165576\n",
      "40 Train Loss 0.00043743168 Test MSE 0.00019151812333024769 Test RE 0.00026497958800845886\n",
      "41 Train Loss 0.00043694623 Test MSE 0.00019304928321461145 Test RE 0.00026603671618859984\n",
      "42 Train Loss 0.00043504935 Test MSE 0.0001960849704543705 Test RE 0.0002681202621361325\n",
      "43 Train Loss 0.0004344909 Test MSE 0.00020061870118336548 Test RE 0.00027120218799861587\n",
      "44 Train Loss 0.00043429653 Test MSE 0.00020020203434040706 Test RE 0.00027092041044496807\n",
      "45 Train Loss 0.00043359865 Test MSE 0.00020202360661018264 Test RE 0.00027215012730489604\n",
      "46 Train Loss 0.0004334554 Test MSE 0.0002028843062808732 Test RE 0.0002727292441984585\n",
      "47 Train Loss 0.0004329849 Test MSE 0.00020261803816401825 Test RE 0.0002725502186596737\n",
      "48 Train Loss 0.00043264535 Test MSE 0.0002037342351982804 Test RE 0.0002732999098560049\n",
      "49 Train Loss 0.00043222864 Test MSE 0.0002052895110932147 Test RE 0.0002743410913701419\n",
      "50 Train Loss 0.00043201123 Test MSE 0.00020489520825675935 Test RE 0.0002740774990841114\n",
      "51 Train Loss 0.00043146336 Test MSE 0.00020557586139462064 Test RE 0.0002745323585192125\n",
      "52 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "53 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "54 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "55 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "56 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "57 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "58 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "59 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "60 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "61 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "62 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "63 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "64 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "65 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "66 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "67 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "68 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "69 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "70 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "71 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "72 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "73 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "74 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "75 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "76 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "77 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "78 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "79 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "80 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "81 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "82 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "83 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "84 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "85 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "86 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "87 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "88 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "89 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "90 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "91 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "92 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "93 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "94 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "95 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "96 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "97 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "98 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "99 Train Loss 0.00043070051 Test MSE 0.00020469876139609454 Test RE 0.00027394607928095556\n",
      "Training time: 14.58\n",
      "Training time: 14.58\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 63.757977 Test MSE 2291.3202488815423 Test RE 0.9165377945291824\n",
      "1 Train Loss 44.70966 Test MSE 1398.6583370668966 Test RE 0.716082896781758\n",
      "2 Train Loss 28.930223 Test MSE 938.4551654507214 Test RE 0.5865624352117348\n",
      "3 Train Loss 23.878204 Test MSE 750.7928938268644 Test RE 0.5246474404980029\n",
      "4 Train Loss 18.94446 Test MSE 583.4580501021672 Test RE 0.4625005993997826\n",
      "5 Train Loss 12.397768 Test MSE 371.3995195303066 Test RE 0.3690015161308861\n",
      "6 Train Loss 3.772188 Test MSE 109.02541497455286 Test RE 0.19992695706025204\n",
      "7 Train Loss 1.3321401 Test MSE 15.553019980541192 Test RE 0.07551180416065498\n",
      "8 Train Loss 0.5261675 Test MSE 1.5827622947061737 Test RE 0.024088809085213134\n",
      "9 Train Loss 0.40372357 Test MSE 1.4288982756188746 Test RE 0.022888015444106194\n",
      "10 Train Loss 0.28417337 Test MSE 0.45460177400067325 Test RE 0.012909904952892523\n",
      "11 Train Loss 0.17891808 Test MSE 0.3790940131467935 Test RE 0.011789107957351648\n",
      "12 Train Loss 0.08651475 Test MSE 0.6197433633923877 Test RE 0.015073476359734642\n",
      "13 Train Loss 0.022081858 Test MSE 0.06999494022897661 Test RE 0.005065715615869156\n",
      "14 Train Loss 0.016430708 Test MSE 0.022930423264196108 Test RE 0.0028994359367611293\n",
      "15 Train Loss 0.015861303 Test MSE 0.024939513748924603 Test RE 0.0030237889290510044\n",
      "16 Train Loss 0.012980781 Test MSE 0.026234451911481653 Test RE 0.0031012978599752844\n",
      "17 Train Loss 0.010314456 Test MSE 0.020723409730094858 Test RE 0.0027563736440651635\n",
      "18 Train Loss 0.0058346107 Test MSE 0.018790532664270127 Test RE 0.002624684022265504\n",
      "19 Train Loss 0.0047782306 Test MSE 0.00891135514523922 Test RE 0.0018075043775744525\n",
      "20 Train Loss 0.0047179875 Test MSE 0.007233029333112249 Test RE 0.001628424376816711\n",
      "21 Train Loss 0.004629917 Test MSE 0.005667500592661243 Test RE 0.0014414622354480494\n",
      "22 Train Loss 0.0038161671 Test MSE 0.0032303686999742057 Test RE 0.0010882621600461148\n",
      "23 Train Loss 0.0027104835 Test MSE 0.0018251556661120552 Test RE 0.0008180077857623044\n",
      "24 Train Loss 0.00077885634 Test MSE 0.00046029374056254024 Test RE 0.00041079487455176984\n",
      "25 Train Loss 0.00043577678 Test MSE 0.00032225421101277047 Test RE 0.00034372156645718835\n",
      "26 Train Loss 0.00025595617 Test MSE 0.00025167958453510737 Test RE 0.00030376062377557295\n",
      "27 Train Loss 0.00024172736 Test MSE 0.00018075405183525466 Test RE 0.0002574254629566635\n",
      "28 Train Loss 0.00024108026 Test MSE 0.00017057681314015365 Test RE 0.0002500733891232668\n",
      "29 Train Loss 0.00024064702 Test MSE 0.0001599851240794508 Test RE 0.0002421850233599866\n",
      "30 Train Loss 0.00024048793 Test MSE 0.00015649487263684193 Test RE 0.00023952868943144843\n",
      "31 Train Loss 0.00024043734 Test MSE 0.00015474801637558458 Test RE 0.00023818808192762816\n",
      "32 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "33 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "34 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "35 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "36 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "37 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "38 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "39 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "40 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "41 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "42 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "43 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "44 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "45 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "46 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "47 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "48 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "49 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "50 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "51 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "52 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "53 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "54 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "55 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "56 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "57 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "58 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "59 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "60 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "61 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "62 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "63 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "64 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "65 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "66 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "67 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "68 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "69 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "70 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "71 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "72 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "73 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "74 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "75 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "76 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "77 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "78 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "79 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "80 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "81 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "82 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "83 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "84 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "85 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "86 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "87 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "88 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "89 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "90 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "91 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "92 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "93 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "94 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "95 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "96 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "97 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "98 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "99 Train Loss 0.00024029793 Test MSE 0.00015126003225085583 Test RE 0.0002354884310004145\n",
      "Training time: 11.76\n",
      "Training time: 11.76\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 62.19864 Test MSE 2230.068729777996 Test RE 0.9042043786516397\n",
      "1 Train Loss 46.461193 Test MSE 1391.2200228990982 Test RE 0.7141762302067947\n",
      "2 Train Loss 34.53982 Test MSE 1206.8384945265532 Test RE 0.6651690890355545\n",
      "3 Train Loss 32.281315 Test MSE 1138.6629281788462 Test RE 0.6461079316437335\n",
      "4 Train Loss 30.501757 Test MSE 1068.3694708894395 Test RE 0.6258470600770975\n",
      "5 Train Loss 28.830273 Test MSE 1005.8651537447696 Test RE 0.6072637586911427\n",
      "6 Train Loss 20.237135 Test MSE 544.0886481319561 Test RE 0.4466242647101558\n",
      "7 Train Loss 3.2982502 Test MSE 61.51947984724045 Test RE 0.1501805910442447\n",
      "8 Train Loss 0.6172745 Test MSE 10.474577893067766 Test RE 0.06196917967053579\n",
      "9 Train Loss 0.22995652 Test MSE 1.167542745896637 Test RE 0.020689208518084444\n",
      "10 Train Loss 0.05302083 Test MSE 0.09234043359770326 Test RE 0.00581839815080807\n",
      "11 Train Loss 0.04874246 Test MSE 0.19489209230494883 Test RE 0.008452877804549409\n",
      "12 Train Loss 0.022883466 Test MSE 0.02303078293485017 Test RE 0.002905773995523438\n",
      "13 Train Loss 0.019616041 Test MSE 0.02712483831906874 Test RE 0.0031534871153929577\n",
      "14 Train Loss 0.014255994 Test MSE 0.02842645692620432 Test RE 0.0032282625502998395\n",
      "15 Train Loss 0.01180055 Test MSE 0.014257458906651059 Test RE 0.0022862754137753867\n",
      "16 Train Loss 0.005043924 Test MSE 0.012491743387302768 Test RE 0.0021400257982055674\n",
      "17 Train Loss 0.0035766696 Test MSE 0.005080849376472491 Test RE 0.0013648208294254247\n",
      "18 Train Loss 0.0016716656 Test MSE 0.0021359864449763894 Test RE 0.0008849255367499501\n",
      "19 Train Loss 0.0013428135 Test MSE 0.00034173689468450555 Test RE 0.0003539593722051274\n",
      "20 Train Loss 0.0013349835 Test MSE 0.00033372553141831104 Test RE 0.00034978581906054977\n",
      "21 Train Loss 0.0012566699 Test MSE 0.0006991967430606239 Test RE 0.0005062991288139908\n",
      "22 Train Loss 0.0009823793 Test MSE 0.0003824191088727515 Test RE 0.00037443572170163677\n",
      "23 Train Loss 0.0008019801 Test MSE 0.0004835407087709011 Test RE 0.00042104062642333597\n",
      "24 Train Loss 0.0005508008 Test MSE 0.000555122927494273 Test RE 0.0004511303694582694\n",
      "25 Train Loss 0.0005139745 Test MSE 0.0006154160930373288 Test RE 0.00047499813689651964\n",
      "26 Train Loss 0.0003957351 Test MSE 0.0005577739754214603 Test RE 0.00045220629670157474\n",
      "27 Train Loss 0.00037256678 Test MSE 0.00020092817949763546 Test RE 0.0002714112882767582\n",
      "28 Train Loss 0.00037189142 Test MSE 0.00019975137867074276 Test RE 0.0002706153171322468\n",
      "29 Train Loss 0.0003714679 Test MSE 0.00015575200644310548 Test RE 0.00023895950326939018\n",
      "30 Train Loss 0.00031625008 Test MSE 0.00029274849927880836 Test RE 0.0003276082429369501\n",
      "31 Train Loss 0.0002906264 Test MSE 5.136743585428329e-05 Test RE 0.00013723074637975088\n",
      "32 Train Loss 0.00025818116 Test MSE 5.1749486330539305e-05 Test RE 0.00013774013472445115\n",
      "33 Train Loss 0.00025408005 Test MSE 6.943114739099103e-05 Test RE 0.00015954553436788727\n",
      "34 Train Loss 0.00025374308 Test MSE 6.86091778511408e-05 Test RE 0.00015859832246723486\n",
      "35 Train Loss 0.00025304517 Test MSE 6.739512705217102e-05 Test RE 0.00015718884758340822\n",
      "36 Train Loss 0.00025176624 Test MSE 6.01346754624525e-05 Test RE 0.00014848068673537404\n",
      "37 Train Loss 0.00025142048 Test MSE 5.848588898855205e-05 Test RE 0.0001464310004472648\n",
      "38 Train Loss 0.0002511518 Test MSE 5.760806269090283e-05 Test RE 0.00014532793983339145\n",
      "39 Train Loss 0.0002508589 Test MSE 5.652647576650615e-05 Test RE 0.00014395721511643056\n",
      "40 Train Loss 0.00025039332 Test MSE 5.5550419551535056e-05 Test RE 0.00014270893116640924\n",
      "41 Train Loss 0.00025005444 Test MSE 5.358231416361885e-05 Test RE 0.00014015810434515462\n",
      "42 Train Loss 0.00024949905 Test MSE 5.596239672157013e-05 Test RE 0.00014323713796026352\n",
      "43 Train Loss 0.00024915027 Test MSE 5.388209000402098e-05 Test RE 0.00014054962728948653\n",
      "44 Train Loss 0.00024860067 Test MSE 5.256017246885221e-05 Test RE 0.0001388148322474307\n",
      "45 Train Loss 0.0002460975 Test MSE 4.9170849200259806e-05 Test RE 0.00013426454244722458\n",
      "46 Train Loss 0.00022893219 Test MSE 4.816775690042456e-05 Test RE 0.00013288797788686086\n",
      "47 Train Loss 0.00019519651 Test MSE 6.417503704204324e-05 Test RE 0.00015338770367458328\n",
      "48 Train Loss 0.00017235754 Test MSE 7.17774437003548e-05 Test RE 0.00016221890868090732\n",
      "49 Train Loss 0.00013324773 Test MSE 2.5114106469689934e-05 Test RE 9.595472106894979e-05\n",
      "50 Train Loss 0.00012764864 Test MSE 2.0181397191685556e-05 Test RE 8.601676332628986e-05\n",
      "51 Train Loss 0.00012599038 Test MSE 2.7836644728560662e-05 Test RE 0.0001010219913584768\n",
      "52 Train Loss 0.00012545985 Test MSE 3.1971734254104745e-05 Test RE 0.00010826562292625193\n",
      "53 Train Loss 0.00012479734 Test MSE 3.453963170812189e-05 Test RE 0.00011252948544106006\n",
      "54 Train Loss 0.00012403644 Test MSE 3.044923782854793e-05 Test RE 0.0001056563722493664\n",
      "55 Train Loss 0.00012345525 Test MSE 3.0418908958766184e-05 Test RE 0.00010560373978752948\n",
      "56 Train Loss 0.0001232481 Test MSE 2.9136857710300333e-05 Test RE 0.00010335436863422861\n",
      "57 Train Loss 0.00012290568 Test MSE 2.805324689645854e-05 Test RE 0.0001014142653048592\n",
      "58 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "59 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "60 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "61 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "62 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "63 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "64 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "65 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "66 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "67 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "68 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "69 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "70 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "71 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "72 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "73 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "74 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "75 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "76 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "77 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "78 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "79 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "80 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "81 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "82 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "83 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "84 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "85 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "86 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "87 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "88 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "89 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "90 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "91 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "92 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "93 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "94 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "95 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "96 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "97 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "98 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "99 Train Loss 0.00012200516 Test MSE 2.33744202901362e-05 Test RE 9.257162899716881e-05\n",
      "Training time: 14.57\n",
      "Training time: 14.57\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 62.070045 Test MSE 2124.9042576786865 Test RE 0.882626911675231\n",
      "1 Train Loss 32.669075 Test MSE 937.9600037197778 Test RE 0.5864076693776624\n",
      "2 Train Loss 19.01249 Test MSE 564.3371104335864 Test RE 0.4548589943535056\n",
      "3 Train Loss 3.3795886 Test MSE 66.57972545703959 Test RE 0.15623505397504042\n",
      "4 Train Loss 2.0644941 Test MSE 39.97216147515397 Test RE 0.12105599407591515\n",
      "5 Train Loss 0.43671128 Test MSE 0.9313853066510513 Test RE 0.018478732258129384\n",
      "6 Train Loss 0.049840763 Test MSE 0.195536547166762 Test RE 0.008466841948031647\n",
      "7 Train Loss 0.018031215 Test MSE 0.07209019342609038 Test RE 0.00514097600889403\n",
      "8 Train Loss 0.014010332 Test MSE 0.014343057352889028 Test RE 0.0022931282746587304\n",
      "9 Train Loss 0.008252239 Test MSE 0.025029633698040416 Test RE 0.003029247294741997\n",
      "10 Train Loss 0.004953705 Test MSE 0.01816493804243324 Test RE 0.002580622278574104\n",
      "11 Train Loss 0.0021810061 Test MSE 0.004470099757585926 Test RE 0.0012801654129235105\n",
      "12 Train Loss 0.0017481239 Test MSE 0.006813645431165153 Test RE 0.0015805099955413745\n",
      "13 Train Loss 0.001243828 Test MSE 0.0009353483556973849 Test RE 0.0005855907059794204\n",
      "14 Train Loss 0.0010448854 Test MSE 0.0011862341619157718 Test RE 0.0006594664337755205\n",
      "15 Train Loss 0.0010205607 Test MSE 0.00082373857070221 Test RE 0.0005495436357817786\n",
      "16 Train Loss 0.0010181951 Test MSE 0.0007777241071906723 Test RE 0.0005339741859129399\n",
      "17 Train Loss 0.0010177566 Test MSE 0.0007743377110742859 Test RE 0.0005328103922388056\n",
      "18 Train Loss 0.0010172011 Test MSE 0.0007709676296705392 Test RE 0.0005316496762131225\n",
      "19 Train Loss 0.0009591353 Test MSE 0.001018400091311612 Test RE 0.0006110358572484996\n",
      "20 Train Loss 0.00085271045 Test MSE 0.0010373595637281267 Test RE 0.0006166974311463205\n",
      "21 Train Loss 0.00085022976 Test MSE 0.0010234891984290532 Test RE 0.0006125606763289203\n",
      "22 Train Loss 0.0008492802 Test MSE 0.0010568422183694832 Test RE 0.0006224615914764919\n",
      "23 Train Loss 0.0008269601 Test MSE 0.0018769590427430316 Test RE 0.0008295353153962102\n",
      "24 Train Loss 0.0006596941 Test MSE 0.0016096270057357686 Test RE 0.0007681925777597293\n",
      "25 Train Loss 0.0005638643 Test MSE 0.0006351916038237044 Test RE 0.00048256948511271895\n",
      "26 Train Loss 0.0005630362 Test MSE 0.0006409902573454088 Test RE 0.00048476716523845263\n",
      "27 Train Loss 0.0005623019 Test MSE 0.0006523217996241196 Test RE 0.0004890332945157235\n",
      "28 Train Loss 0.0005615504 Test MSE 0.0006524833409049605 Test RE 0.0004890938429862632\n",
      "29 Train Loss 0.0005608672 Test MSE 0.000665026179866822 Test RE 0.0004937724478667209\n",
      "30 Train Loss 0.00055671285 Test MSE 0.0007547845384792511 Test RE 0.0005260402547099671\n",
      "31 Train Loss 0.00055604323 Test MSE 0.0007706576017202172 Test RE 0.0005315427697577003\n",
      "32 Train Loss 0.00048801742 Test MSE 0.0007227495500134913 Test RE 0.0005147559754603707\n",
      "33 Train Loss 0.00036498648 Test MSE 0.0003316056482533783 Test RE 0.0003486730987309271\n",
      "34 Train Loss 0.00023674776 Test MSE 0.00034435040892349846 Test RE 0.00035531028853351507\n",
      "35 Train Loss 0.00018689886 Test MSE 0.0001400378363453143 Test RE 0.0002265844896302268\n",
      "36 Train Loss 0.00018652964 Test MSE 0.00013855727570762872 Test RE 0.00022538351600486872\n",
      "37 Train Loss 0.00018035527 Test MSE 0.0001124920832785704 Test RE 0.00020308061111763633\n",
      "38 Train Loss 0.0001432543 Test MSE 0.00011590039086289061 Test RE 0.00020613414301372124\n",
      "39 Train Loss 0.00011572045 Test MSE 9.713019268540169e-05 Test RE 0.0001887055211391288\n",
      "40 Train Loss 0.00011520679 Test MSE 9.900815711451645e-05 Test RE 0.0001905210517019621\n",
      "41 Train Loss 0.00011492691 Test MSE 0.00010063503725856792 Test RE 0.00019207997372550659\n",
      "42 Train Loss 0.00011461764 Test MSE 0.00010178142516395385 Test RE 0.0001931709188493724\n",
      "43 Train Loss 0.00011437411 Test MSE 0.00010346476198196233 Test RE 0.000194761770229671\n",
      "44 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "45 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "46 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "47 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "48 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "49 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "50 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "51 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "52 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "53 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "54 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "55 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "56 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "57 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "58 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "59 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "60 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "61 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "62 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "63 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "64 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "65 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "66 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "67 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "68 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "69 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "70 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "71 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "72 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "73 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "74 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "75 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "76 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "77 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "78 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "79 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "80 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "81 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "82 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "83 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "84 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "85 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "86 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "87 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "88 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "89 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "90 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "91 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "92 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "93 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "94 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "95 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "96 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "97 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "98 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "99 Train Loss 0.00011349629 Test MSE 0.00011091338078054978 Test RE 0.00020165056976699313\n",
      "Training time: 12.47\n",
      "Training time: 12.47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 62.63293 Test MSE 2236.4000517399945 Test RE 0.9054870188317814\n",
      "1 Train Loss 39.267853 Test MSE 1308.6456685148337 Test RE 0.6926574628960688\n",
      "2 Train Loss 31.679409 Test MSE 1071.4312032097955 Test RE 0.6267431944871644\n",
      "3 Train Loss 27.840849 Test MSE 978.3990342233976 Test RE 0.5989154126093736\n",
      "4 Train Loss 26.052608 Test MSE 901.0471760488253 Test RE 0.5747529998968947\n",
      "5 Train Loss 20.815216 Test MSE 626.9134236544297 Test RE 0.47941461164725163\n",
      "6 Train Loss 6.296974 Test MSE 190.4529978430485 Test RE 0.2642417204465799\n",
      "7 Train Loss 0.8796522 Test MSE 17.259401735596377 Test RE 0.07954636719021684\n",
      "8 Train Loss 0.09619014 Test MSE 0.16125310364091483 Test RE 0.0076888523807816115\n",
      "9 Train Loss 0.08411802 Test MSE 0.28227852240331336 Test RE 0.01017293804324193\n",
      "10 Train Loss 0.037370995 Test MSE 0.11058809655784126 Test RE 0.006367393258803787\n",
      "11 Train Loss 0.023515737 Test MSE 0.10932337216840869 Test RE 0.006330878685189569\n",
      "12 Train Loss 0.016772471 Test MSE 0.015937672130179117 Test RE 0.00241724085528239\n",
      "13 Train Loss 0.011216439 Test MSE 0.006141623389264406 Test RE 0.0015005451675374403\n",
      "14 Train Loss 0.0076275794 Test MSE 0.008826627155707036 Test RE 0.0017988910985684196\n",
      "15 Train Loss 0.0048216577 Test MSE 0.013792254978381074 Test RE 0.002248666865186817\n",
      "16 Train Loss 0.0020401704 Test MSE 0.001988296687891374 Test RE 0.0008537841267869386\n",
      "17 Train Loss 0.001575327 Test MSE 0.001691093376451428 Test RE 0.0007873925041247934\n",
      "18 Train Loss 0.0004956573 Test MSE 0.0006770065875643224 Test RE 0.0004982002361622732\n",
      "19 Train Loss 0.00036739674 Test MSE 0.00012204624598268346 Test RE 0.00021152889199496666\n",
      "20 Train Loss 0.0003667221 Test MSE 0.00012235471278679747 Test RE 0.000211796038533759\n",
      "21 Train Loss 0.00036271728 Test MSE 0.00014490468515490198 Test RE 0.0002304881996208974\n",
      "22 Train Loss 0.0003620079 Test MSE 0.00015423842950917753 Test RE 0.0002377955805878347\n",
      "23 Train Loss 0.00036152205 Test MSE 0.000160657892621803 Test RE 0.00024269370669077804\n",
      "24 Train Loss 0.0003307864 Test MSE 0.0002625481915954728 Test RE 0.0003102501480470427\n",
      "25 Train Loss 0.00030648403 Test MSE 0.0002084742133450049 Test RE 0.00027646085935584415\n",
      "26 Train Loss 0.00024516752 Test MSE 0.00023877658765199898 Test RE 0.00029587164919246727\n",
      "27 Train Loss 0.00020271748 Test MSE 0.00012257550502747206 Test RE 0.00021198704811417057\n",
      "28 Train Loss 0.00018183714 Test MSE 5.47705188026923e-05 Test RE 0.00014170360830007377\n",
      "29 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "30 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "31 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "32 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "33 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "34 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "35 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "36 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "37 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "38 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "39 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "40 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "41 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "42 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "43 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "44 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "45 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "46 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "47 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "48 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "49 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "50 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "51 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "52 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "53 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "54 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "55 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "56 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "57 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "58 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "59 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "60 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "61 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "62 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "63 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "64 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "65 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "66 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "67 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "68 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "69 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "70 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "71 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "72 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "73 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "74 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "75 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "76 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "77 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "78 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "79 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "80 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "81 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "82 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "83 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "84 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "85 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "86 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "87 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "88 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "89 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "90 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "91 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "92 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "93 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "94 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "95 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "96 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "97 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "98 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "99 Train Loss 0.00018099778 Test MSE 5.936656933079555e-05 Test RE 0.00014752935990750829\n",
      "Training time: 10.84\n",
      "Training time: 10.84\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 51.69734 Test MSE 1854.327809220139 Test RE 0.824519132210182\n",
      "1 Train Loss 35.293182 Test MSE 1252.2493762002864 Test RE 0.6775680104963436\n",
      "2 Train Loss 33.080418 Test MSE 1188.1188268120425 Test RE 0.6599900993411756\n",
      "3 Train Loss 31.166002 Test MSE 1082.2623387777337 Test RE 0.6299031130910026\n",
      "4 Train Loss 18.001406 Test MSE 487.0214018565458 Test RE 0.4225533070546875\n",
      "5 Train Loss 2.6466157 Test MSE 24.341053640195895 Test RE 0.09446635720369988\n",
      "6 Train Loss 0.19119148 Test MSE 0.6851821070574028 Test RE 0.015849314687367253\n",
      "7 Train Loss 0.12512451 Test MSE 0.4433757055924594 Test RE 0.012749508067593472\n",
      "8 Train Loss 0.07155533 Test MSE 0.17648375308465675 Test RE 0.008043773762268386\n",
      "9 Train Loss 0.04440929 Test MSE 0.038799914406323105 Test RE 0.0037715760178542016\n",
      "10 Train Loss 0.03598396 Test MSE 0.026384985950720027 Test RE 0.0031101828008323067\n",
      "11 Train Loss 0.0279698 Test MSE 0.0526924613911227 Test RE 0.00439523119798337\n",
      "12 Train Loss 0.023536079 Test MSE 0.021039889073656053 Test RE 0.002777340995419653\n",
      "13 Train Loss 0.02154891 Test MSE 0.017016814428169273 Test RE 0.002497736458897844\n",
      "14 Train Loss 0.020944182 Test MSE 0.011439495304002649 Test RE 0.002047910222960916\n",
      "15 Train Loss 0.01860795 Test MSE 0.009993857281486399 Test RE 0.0019141415624608327\n",
      "16 Train Loss 0.01319978 Test MSE 0.007384401945166006 Test RE 0.0016453759527962665\n",
      "17 Train Loss 0.010034539 Test MSE 0.01313317077762131 Test RE 0.0021942811767707354\n",
      "18 Train Loss 0.007786023 Test MSE 0.004084741693986595 Test RE 0.001223741761209737\n",
      "19 Train Loss 0.007322806 Test MSE 0.005281023767186684 Test RE 0.0013914465963703712\n",
      "20 Train Loss 0.0062112184 Test MSE 0.0031788072562612944 Test RE 0.001079542090087263\n",
      "21 Train Loss 0.0056041265 Test MSE 0.0021749727801738334 Test RE 0.0008929649134506269\n",
      "22 Train Loss 0.005182677 Test MSE 0.0030170434273034674 Test RE 0.0010517154709015586\n",
      "23 Train Loss 0.003989053 Test MSE 0.0009712388232549297 Test RE 0.0005967198690388735\n",
      "24 Train Loss 0.0035800098 Test MSE 0.0008199126781704557 Test RE 0.0005482659598680734\n",
      "25 Train Loss 0.0030067118 Test MSE 0.0008958997677617164 Test RE 0.0005731089540681286\n",
      "26 Train Loss 0.0016865304 Test MSE 0.0014280627304828592 Test RE 0.0007235709531558712\n",
      "27 Train Loss 0.0015528753 Test MSE 0.0017099431716047142 Test RE 0.0007917686837219963\n",
      "28 Train Loss 0.0011162952 Test MSE 0.0006594248637583433 Test RE 0.0004916886020493074\n",
      "29 Train Loss 0.0006780405 Test MSE 0.0002398161695043544 Test RE 0.0002965150303958939\n",
      "30 Train Loss 0.0004918835 Test MSE 0.00019914176008195285 Test RE 0.00027020205793390424\n",
      "31 Train Loss 0.0004427698 Test MSE 0.00010507955058922837 Test RE 0.00019627572269817343\n",
      "32 Train Loss 0.0003757143 Test MSE 0.00018835566809444874 Test RE 0.00026278273516002626\n",
      "33 Train Loss 0.00027663962 Test MSE 6.010927342913488e-05 Test RE 0.00014844932288650227\n",
      "34 Train Loss 0.00027591476 Test MSE 5.833027510793896e-05 Test RE 0.00014623606561767587\n",
      "35 Train Loss 0.00027036926 Test MSE 5.1784473563686885e-05 Test RE 0.00013778668911833917\n",
      "36 Train Loss 0.00026064503 Test MSE 0.00011600975679969376 Test RE 0.0002062313762402111\n",
      "37 Train Loss 0.0002463484 Test MSE 0.0001400022899508193 Test RE 0.0002265557303568699\n",
      "38 Train Loss 0.00024440067 Test MSE 0.00012810139577089976 Test RE 0.0002167127247848059\n",
      "39 Train Loss 0.00024342454 Test MSE 0.00012321746439575195 Test RE 0.0002125414384705502\n",
      "40 Train Loss 0.00024248907 Test MSE 0.00011813081634568183 Test RE 0.0002081081480067649\n",
      "41 Train Loss 0.00022821032 Test MSE 6.989374861139667e-05 Test RE 0.0001600761566618705\n",
      "42 Train Loss 0.00021003098 Test MSE 4.627550320020354e-05 Test RE 0.00013025159697832106\n",
      "43 Train Loss 0.00020924683 Test MSE 4.49609959113342e-05 Test RE 0.00012838829842757855\n",
      "44 Train Loss 0.00020865788 Test MSE 4.3994309952463414e-05 Test RE 0.00012700058951671024\n",
      "45 Train Loss 0.00020801391 Test MSE 4.281065303633712e-05 Test RE 0.00012528047983456444\n",
      "46 Train Loss 0.00020748607 Test MSE 4.2114076326588255e-05 Test RE 0.00012425707373716287\n",
      "47 Train Loss 0.00020698749 Test MSE 4.162402694631771e-05 Test RE 0.0001235320159392467\n",
      "48 Train Loss 0.00020651156 Test MSE 4.130590819839445e-05 Test RE 0.00012305905324717781\n",
      "49 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "50 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "51 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "52 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "53 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "54 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "55 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "56 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "57 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "58 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "59 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "60 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "61 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "62 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "63 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "64 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "65 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "66 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "67 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "68 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "69 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "70 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "71 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "72 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "73 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "74 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "75 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "76 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "77 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "78 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "79 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "80 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "81 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "82 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "83 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "84 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "85 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "86 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "87 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "88 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "89 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "90 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "91 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "92 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "93 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "94 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "95 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "96 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "97 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "98 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "99 Train Loss 0.00020413398 Test MSE 4.336819884931588e-05 Test RE 0.00012609363787943322\n",
      "Training time: 15.31\n",
      "Training time: 15.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 46.972893 Test MSE 1734.8698013392602 Test RE 0.7975187925597114\n",
      "1 Train Loss 33.510582 Test MSE 1150.5306500439185 Test RE 0.6494662359245968\n",
      "2 Train Loss 30.06 Test MSE 1033.74531576271 Test RE 0.6156221809053511\n",
      "3 Train Loss 27.807016 Test MSE 940.4744072922962 Test RE 0.5871931392802913\n",
      "4 Train Loss 15.645627 Test MSE 388.896766828182 Test RE 0.3775936203662105\n",
      "5 Train Loss 8.503073 Test MSE 71.72235182828805 Test RE 0.16215664219145723\n",
      "6 Train Loss 1.1015873 Test MSE 4.457138533844999 Test RE 0.0404236521557964\n",
      "7 Train Loss 0.1459249 Test MSE 0.06237932500598232 Test RE 0.004782200904926242\n",
      "8 Train Loss 0.033015385 Test MSE 0.022247672039261385 Test RE 0.002855944534280301\n",
      "9 Train Loss 0.025498679 Test MSE 0.01700182131155818 Test RE 0.002496635867873211\n",
      "10 Train Loss 0.008431589 Test MSE 0.005499208782722624 Test RE 0.001419899433711605\n",
      "11 Train Loss 0.004962394 Test MSE 0.001070264417022666 Test RE 0.0006264018405589868\n",
      "12 Train Loss 0.003153611 Test MSE 0.0005112236755492175 Test RE 0.00043292529445758355\n",
      "13 Train Loss 0.0020741106 Test MSE 0.00023564736296743146 Test RE 0.00029392652072286047\n",
      "14 Train Loss 0.0016097053 Test MSE 0.0006260605689603134 Test RE 0.00047908840220707485\n",
      "15 Train Loss 0.0014363475 Test MSE 0.00023950716959319723 Test RE 0.0002963239410063483\n",
      "16 Train Loss 0.00097160833 Test MSE 0.00022463498410004262 Test RE 0.00028697639676816247\n",
      "17 Train Loss 0.0009309923 Test MSE 0.0002705921291803165 Test RE 0.00031496700570566693\n",
      "18 Train Loss 0.00077917706 Test MSE 0.0001992540543200585 Test RE 0.00027027822944612143\n",
      "19 Train Loss 0.0007223209 Test MSE 0.00012206479458689914 Test RE 0.00021154496547842996\n",
      "20 Train Loss 0.0006373028 Test MSE 5.873174230270968e-05 Test RE 0.00014673844890535022\n",
      "21 Train Loss 0.0006059703 Test MSE 3.9927304103220964e-05 Test RE 0.00012098804956297856\n",
      "22 Train Loss 0.0006055023 Test MSE 4.0379880984440565e-05 Test RE 0.00012167181850695082\n",
      "23 Train Loss 0.0006048171 Test MSE 3.995489463241659e-05 Test RE 0.00012102984486961156\n",
      "24 Train Loss 0.0005167847 Test MSE 4.3108044215037916e-05 Test RE 0.00012571486739000544\n",
      "25 Train Loss 0.00050902006 Test MSE 3.8938454547910385e-05 Test RE 0.00011948044654271123\n",
      "26 Train Loss 0.00050821906 Test MSE 3.8472387566917524e-05 Test RE 0.00011876324388243335\n",
      "27 Train Loss 0.00050398364 Test MSE 3.71429356293628e-05 Test RE 0.00011669321215524955\n",
      "28 Train Loss 0.0005031442 Test MSE 3.709887698506195e-05 Test RE 0.00011662398135537252\n",
      "29 Train Loss 0.0004037073 Test MSE 8.68591409043169e-05 Test RE 0.00017844946348519555\n",
      "30 Train Loss 0.00033936274 Test MSE 6.549974029958146e-05 Test RE 0.00015496273428353935\n",
      "31 Train Loss 0.00030552148 Test MSE 3.0348853101087665e-05 Test RE 0.00010548206505808082\n",
      "32 Train Loss 0.00030284602 Test MSE 2.4814066027605675e-05 Test RE 9.53798090259707e-05\n",
      "33 Train Loss 0.00029688008 Test MSE 2.2919912849208145e-05 Test RE 9.166719933320264e-05\n",
      "34 Train Loss 0.0002962648 Test MSE 2.8561076707343836e-05 Test RE 0.0001023280668372585\n",
      "35 Train Loss 0.00025892037 Test MSE 4.899574641777495e-05 Test RE 0.0001340252638582689\n",
      "36 Train Loss 0.00018772623 Test MSE 1.5972442934163226e-05 Test RE 7.652320556332997e-05\n",
      "37 Train Loss 0.0001648883 Test MSE 2.4807924809315616e-05 Test RE 9.53680055498063e-05\n",
      "38 Train Loss 0.00012729752 Test MSE 5.6884672836398284e-05 Test RE 0.00014441260898604436\n",
      "39 Train Loss 8.781552e-05 Test MSE 1.0373652625112493e-05 Test RE 6.166991250720376e-05\n",
      "40 Train Loss 8.587337e-05 Test MSE 1.0491167148327766e-05 Test RE 6.201823252193145e-05\n",
      "41 Train Loss 8.506065e-05 Test MSE 9.765727887060278e-06 Test RE 5.983561942215646e-05\n",
      "42 Train Loss 8.4235726e-05 Test MSE 1.0257384457097856e-05 Test RE 6.132333968107165e-05\n",
      "43 Train Loss 8.200808e-05 Test MSE 1.0296775927039247e-05 Test RE 6.14409769681017e-05\n",
      "44 Train Loss 6.984432e-05 Test MSE 1.6707887048686662e-05 Test RE 7.826511849127374e-05\n",
      "45 Train Loss 6.5128865e-05 Test MSE 1.1960972290453884e-05 Test RE 6.622023595877609e-05\n",
      "46 Train Loss 6.0057027e-05 Test MSE 8.16163650952877e-06 Test RE 5.470110585318746e-05\n",
      "47 Train Loss 5.9337195e-05 Test MSE 7.640104659029606e-06 Test RE 5.292454532852699e-05\n",
      "48 Train Loss 5.834278e-05 Test MSE 6.869993990897935e-06 Test RE 5.018635569945925e-05\n",
      "49 Train Loss 5.4962922e-05 Test MSE 6.569535526537407e-06 Test RE 4.907663922780535e-05\n",
      "50 Train Loss 5.0803672e-05 Test MSE 7.745234207462787e-06 Test RE 5.3287428045565694e-05\n",
      "51 Train Loss 5.025132e-05 Test MSE 6.8115647869419854e-06 Test RE 4.9972482851169104e-05\n",
      "52 Train Loss 4.975439e-05 Test MSE 6.704619980869636e-06 Test RE 4.957863496403957e-05\n",
      "53 Train Loss 4.9248014e-05 Test MSE 6.224504319463564e-06 Test RE 4.777050892783267e-05\n",
      "54 Train Loss 4.789619e-05 Test MSE 5.798998859646226e-06 Test RE 4.610881844962044e-05\n",
      "55 Train Loss 4.7534395e-05 Test MSE 5.345684701895029e-06 Test RE 4.4269962248727455e-05\n",
      "56 Train Loss 4.691633e-05 Test MSE 5.52012467132011e-06 Test RE 4.498647089880821e-05\n",
      "57 Train Loss 4.6689864e-05 Test MSE 5.1818881245265e-06 Test RE 4.358644996769446e-05\n",
      "58 Train Loss 4.648737e-05 Test MSE 5.166136992238899e-06 Test RE 4.35201557497633e-05\n",
      "59 Train Loss 4.6345696e-05 Test MSE 4.4882053129965345e-06 Test RE 4.056428632417246e-05\n",
      "60 Train Loss 4.6164085e-05 Test MSE 4.936265226469672e-06 Test RE 4.2540905027333535e-05\n",
      "61 Train Loss 4.6008463e-05 Test MSE 5.014919698373223e-06 Test RE 4.2878489059812706e-05\n",
      "62 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "63 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "64 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "65 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "66 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "67 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "68 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "69 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "70 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "71 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "72 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "73 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "74 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "75 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "76 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "77 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "78 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "79 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "80 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "81 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "82 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "83 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "84 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "85 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "86 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "87 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "88 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "89 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "90 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "91 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "92 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "93 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "94 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "95 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "96 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "97 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "98 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "99 Train Loss 4.5479173e-05 Test MSE 6.012817976469413e-06 Test RE 4.695117984376837e-05\n",
      "Training time: 14.31\n",
      "Training time: 14.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 44.55301 Test MSE 1592.9891065277798 Test RE 0.7642120560581092\n",
      "1 Train Loss 34.885334 Test MSE 1271.1687456010116 Test RE 0.6826672755154272\n",
      "2 Train Loss 33.881313 Test MSE 1231.8644933054327 Test RE 0.6720304483806356\n",
      "3 Train Loss 29.508404 Test MSE 948.276780855549 Test RE 0.5896238471931047\n",
      "4 Train Loss 20.071577 Test MSE 118.29385875301482 Test RE 0.20825171238302428\n",
      "5 Train Loss 2.9966438 Test MSE 38.71600519172882 Test RE 0.11913867107894228\n",
      "6 Train Loss 0.8065597 Test MSE 5.453422555994449 Test RE 0.04471384910056389\n",
      "7 Train Loss 0.14222038 Test MSE 0.2395567157564615 Test RE 0.009371554971196487\n",
      "8 Train Loss 0.11968948 Test MSE 0.20232407988823203 Test RE 0.008612540333928623\n",
      "9 Train Loss 0.095778316 Test MSE 0.03525369730135525 Test RE 0.0035950904167193396\n",
      "10 Train Loss 0.080277495 Test MSE 0.12078930325838035 Test RE 0.006654596386648983\n",
      "11 Train Loss 0.04799918 Test MSE 0.02156030328829368 Test RE 0.00281147945780005\n",
      "12 Train Loss 0.042520758 Test MSE 0.01032181497426037 Test RE 0.0019452952066830074\n",
      "13 Train Loss 0.034879923 Test MSE 0.006679145974160751 Test RE 0.00156483283137138\n",
      "14 Train Loss 0.034329757 Test MSE 0.005036637561295385 Test RE 0.0013588697528272766\n",
      "15 Train Loss 0.032722536 Test MSE 0.006130281095317953 Test RE 0.001499158930668379\n",
      "16 Train Loss 0.030230153 Test MSE 0.005662278646414392 Test RE 0.0014407980120521818\n",
      "17 Train Loss 0.022532072 Test MSE 0.0037923079446880764 Test RE 0.0011791234585954895\n",
      "18 Train Loss 0.02159528 Test MSE 0.0035334431756713705 Test RE 0.0011381684360998903\n",
      "19 Train Loss 0.016128715 Test MSE 0.007092436325230398 Test RE 0.0016125203513874349\n",
      "20 Train Loss 0.009419593 Test MSE 0.0016112768155281084 Test RE 0.0007685861618156666\n",
      "21 Train Loss 0.0083281025 Test MSE 0.0013483122475417503 Test RE 0.0007030767257398063\n",
      "22 Train Loss 0.0066824164 Test MSE 0.008781547561142222 Test RE 0.001794291545099714\n",
      "23 Train Loss 0.0063600964 Test MSE 0.0007995178554272074 Test RE 0.0005414041312324165\n",
      "24 Train Loss 0.0052853664 Test MSE 0.0013347623099025246 Test RE 0.0006995350010871324\n",
      "25 Train Loss 0.004498966 Test MSE 0.001275531350767364 Test RE 0.0006838377168488186\n",
      "26 Train Loss 0.003492054 Test MSE 0.005251016374063892 Test RE 0.0013874877838078923\n",
      "27 Train Loss 0.0025540988 Test MSE 0.0011734107196402946 Test RE 0.0006558922623009915\n",
      "28 Train Loss 0.0023640378 Test MSE 0.0007359383002567061 Test RE 0.0005194313820349647\n",
      "29 Train Loss 0.0016616331 Test MSE 0.0003798407045110534 Test RE 0.00037317129802312207\n",
      "30 Train Loss 0.0011345788 Test MSE 0.001198953232387451 Test RE 0.0006629924811949156\n",
      "31 Train Loss 0.0008184065 Test MSE 0.0006218199510869797 Test RE 0.00047746309392753184\n",
      "32 Train Loss 0.0006507473 Test MSE 0.00022347938639808858 Test RE 0.0002862372935746644\n",
      "33 Train Loss 0.00048321855 Test MSE 0.00020306880884052504 Test RE 0.0002728532257170738\n",
      "34 Train Loss 0.00044270905 Test MSE 5.460766194915894e-05 Test RE 0.0001414927778692331\n",
      "35 Train Loss 0.0004359005 Test MSE 4.004515163319546e-05 Test RE 0.00012116646928979822\n",
      "36 Train Loss 0.00043506065 Test MSE 3.8712675156179334e-05 Test RE 0.00011913354729952064\n",
      "37 Train Loss 0.00043319585 Test MSE 4.0559988349845144e-05 Test RE 0.00012194286449086308\n",
      "38 Train Loss 0.00043221662 Test MSE 4.270582399634817e-05 Test RE 0.00012512700072407528\n",
      "39 Train Loss 0.00043130005 Test MSE 4.5717902821771894e-05 Test RE 0.00012946448016572153\n",
      "40 Train Loss 0.00042986334 Test MSE 5.901931016147917e-05 Test RE 0.00014709724751594421\n",
      "41 Train Loss 0.00038772816 Test MSE 4.4126712802925704e-05 Test RE 0.00012719155293365676\n",
      "42 Train Loss 0.00038708525 Test MSE 4.4868065976233935e-05 Test RE 0.0001282555468338065\n",
      "43 Train Loss 0.00035234794 Test MSE 7.908473865378685e-05 Test RE 0.00017027615062533785\n",
      "44 Train Loss 0.00026294054 Test MSE 0.0001606561476851766 Test RE 0.00024269238871541812\n",
      "45 Train Loss 0.00015227981 Test MSE 9.056166088208008e-05 Test RE 0.0001822131311801965\n",
      "46 Train Loss 8.0274855e-05 Test MSE 3.3617582489907064e-05 Test RE 0.0001110173154743426\n",
      "47 Train Loss 5.3230848e-05 Test MSE 8.511645900973076e-06 Test RE 5.586171384041722e-05\n",
      "48 Train Loss 4.9165432e-05 Test MSE 5.188038584274009e-06 Test RE 4.3612308998297003e-05\n",
      "49 Train Loss 4.8981496e-05 Test MSE 5.408706030400408e-06 Test RE 4.4530151287381774e-05\n",
      "50 Train Loss 4.8788723e-05 Test MSE 5.380064167797788e-06 Test RE 4.441208982665253e-05\n",
      "51 Train Loss 4.8633363e-05 Test MSE 5.38750343437893e-06 Test RE 4.444278455738842e-05\n",
      "52 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "53 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "54 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "55 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "56 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "57 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "58 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "59 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "60 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "61 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "62 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "63 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "64 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "65 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "66 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "67 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "68 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "69 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "70 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "71 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "72 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "73 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "74 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "75 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "76 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "77 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "78 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "79 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "80 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "81 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "82 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "83 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "84 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "85 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "86 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "87 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "88 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "89 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "90 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "91 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "92 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "93 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "94 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "95 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "96 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "97 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "98 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "99 Train Loss 4.8351372e-05 Test MSE 5.674584803708876e-06 Test RE 4.5611518090976906e-05\n",
      "Training time: 17.51\n",
      "Training time: 17.51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 63.8631 Test MSE 2267.581167590474 Test RE 0.9117775664356099\n",
      "1 Train Loss 49.895523 Test MSE 1785.683602989956 Test RE 0.80911403981272\n",
      "2 Train Loss 33.134594 Test MSE 1117.8347740641125 Test RE 0.640171432029054\n",
      "3 Train Loss 29.786392 Test MSE 970.9372632489037 Test RE 0.5966272240513123\n",
      "4 Train Loss 26.2951 Test MSE 894.4894045233157 Test RE 0.5726576702348686\n",
      "5 Train Loss 22.21842 Test MSE 735.1747923883221 Test RE 0.5191618670075145\n",
      "6 Train Loss 16.760424 Test MSE 347.1231387408134 Test RE 0.35673791017936196\n",
      "7 Train Loss 9.809302 Test MSE 93.51370849944963 Test RE 0.18515912590972444\n",
      "8 Train Loss 0.60699004 Test MSE 2.8394444132573846 Test RE 0.03226444265040616\n",
      "9 Train Loss 0.14598261 Test MSE 0.5509445083532444 Test RE 0.014212203292166147\n",
      "10 Train Loss 0.03576373 Test MSE 0.054343843058043295 Test RE 0.004463573139560595\n",
      "11 Train Loss 0.021449367 Test MSE 0.010562297562838817 Test RE 0.001967825939021619\n",
      "12 Train Loss 0.009510346 Test MSE 0.006643049310365317 Test RE 0.0015605986247282783\n",
      "13 Train Loss 0.006682216 Test MSE 0.0028338981995163566 Test RE 0.0010192943207086363\n",
      "14 Train Loss 0.006047817 Test MSE 0.0033688481481101446 Test RE 0.0011113432076585391\n",
      "15 Train Loss 0.0043816604 Test MSE 0.0011711708197506552 Test RE 0.000655265953562356\n",
      "16 Train Loss 0.0043230075 Test MSE 0.0007646486401512169 Test RE 0.0005294664452306675\n",
      "17 Train Loss 0.0035211383 Test MSE 0.0011874190595378305 Test RE 0.0006597957132726608\n",
      "18 Train Loss 0.0031588005 Test MSE 0.0007289604085586299 Test RE 0.0005169629899666913\n",
      "19 Train Loss 0.0025069271 Test MSE 0.0010453468090543413 Test RE 0.0006190670379236175\n",
      "20 Train Loss 0.0023123736 Test MSE 0.0006865454126935347 Test RE 0.0005016977075914755\n",
      "21 Train Loss 0.0015484949 Test MSE 0.0009379201910485805 Test RE 0.0005863952239091018\n",
      "22 Train Loss 0.0014258106 Test MSE 0.00020614994275981594 Test RE 0.00027491541427821333\n",
      "23 Train Loss 0.001379394 Test MSE 0.00019957491450896844 Test RE 0.00027049575736560913\n",
      "24 Train Loss 0.0013675509 Test MSE 0.0002081461789286727 Test RE 0.00027624326798576305\n",
      "25 Train Loss 0.0013643078 Test MSE 0.00020991071932765566 Test RE 0.0002774117105254466\n",
      "26 Train Loss 0.0013638325 Test MSE 0.00021085162797693452 Test RE 0.00027803275368350596\n",
      "27 Train Loss 0.0011896915 Test MSE 0.0003018785186826944 Test RE 0.0003326776208074695\n",
      "28 Train Loss 0.001144106 Test MSE 0.00020838058208287773 Test RE 0.00027639876945542144\n",
      "29 Train Loss 0.0010491043 Test MSE 0.00026576895560258225 Test RE 0.0003121473171906923\n",
      "30 Train Loss 0.00096778333 Test MSE 0.00014910756594743176 Test RE 0.0002338068991717077\n",
      "31 Train Loss 0.00075993733 Test MSE 0.00032406259958680324 Test RE 0.00034468464551077666\n",
      "32 Train Loss 0.0006683236 Test MSE 0.00011019825794217606 Test RE 0.00020099943947793431\n",
      "33 Train Loss 0.0006614955 Test MSE 8.989251430836507e-05 Test RE 0.000181538710278453\n",
      "34 Train Loss 0.000655849 Test MSE 0.00010849343171024319 Test RE 0.0001994385945327664\n",
      "35 Train Loss 0.0006483929 Test MSE 0.0001042186534697758 Test RE 0.00019547004395362524\n",
      "36 Train Loss 0.0006400107 Test MSE 8.703706850589148e-05 Test RE 0.00017863214340307348\n",
      "37 Train Loss 0.0006175128 Test MSE 8.389499839399833e-05 Test RE 0.00017537816302916573\n",
      "38 Train Loss 0.0006090421 Test MSE 8.687384277266392e-05 Test RE 0.00017846456511690082\n",
      "39 Train Loss 0.00048349574 Test MSE 0.00014366673635679534 Test RE 0.00022950153511298204\n",
      "40 Train Loss 0.0003558941 Test MSE 8.810118118123643e-05 Test RE 0.00017972080173779363\n",
      "41 Train Loss 0.00032517294 Test MSE 9.082674699009362e-05 Test RE 0.00018247961742951852\n",
      "42 Train Loss 0.00030599913 Test MSE 7.408994109823064e-05 Test RE 0.0001648113461128331\n",
      "43 Train Loss 0.0002922319 Test MSE 6.539919420287725e-05 Test RE 0.00015484374997920046\n",
      "44 Train Loss 0.00029178782 Test MSE 6.635423770150425e-05 Test RE 0.00015597026638457237\n",
      "45 Train Loss 0.00029155545 Test MSE 6.593657068103871e-05 Test RE 0.00015547861374618226\n",
      "46 Train Loss 0.0002910894 Test MSE 6.762359526572639e-05 Test RE 0.00015745505578302564\n",
      "47 Train Loss 0.00029017765 Test MSE 6.83183669542078e-05 Test RE 0.00015826184344436004\n",
      "48 Train Loss 0.00028856104 Test MSE 6.907085128466651e-05 Test RE 0.00015913103449681883\n",
      "49 Train Loss 0.00028079835 Test MSE 5.5158264957213473e-05 Test RE 0.00014220431678072722\n",
      "50 Train Loss 0.00026288725 Test MSE 4.5833085486958915e-05 Test RE 0.00012962746536760618\n",
      "51 Train Loss 0.0002341133 Test MSE 0.00013050928891863064 Test RE 0.00021873999280326892\n",
      "52 Train Loss 0.00021110676 Test MSE 4.9890089470533296e-05 Test RE 0.00013524294622722593\n",
      "53 Train Loss 0.00021073126 Test MSE 4.947292801286135e-05 Test RE 0.0001346763349274998\n",
      "54 Train Loss 0.0002101447 Test MSE 4.911044180337546e-05 Test RE 0.00013418204372931324\n",
      "55 Train Loss 0.00020960846 Test MSE 4.819987863764674e-05 Test RE 0.00013293228015009731\n",
      "56 Train Loss 0.00020948611 Test MSE 4.8995987522134684e-05 Test RE 0.00013402559362195294\n",
      "57 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "58 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "59 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "60 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "61 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "62 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "63 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "64 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "65 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "66 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "67 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "68 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "69 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "70 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "71 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "72 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "73 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "74 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "75 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "76 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "77 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "78 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "79 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "80 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "81 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "82 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "83 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "84 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "85 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "86 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "87 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "88 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "89 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "90 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "91 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "92 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "93 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "94 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "95 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "96 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "97 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "98 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "99 Train Loss 0.00020928396 Test MSE 4.9155247967291875e-05 Test RE 0.00013424324061269514\n",
      "Training time: 16.61\n",
      "Training time: 16.61\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 62.53118 Test MSE 2300.519314540145 Test RE 0.9183757842053936\n",
      "1 Train Loss 39.03818 Test MSE 1332.1005346686127 Test RE 0.6988371486852689\n",
      "2 Train Loss 33.01679 Test MSE 1183.614023129228 Test RE 0.6587377206640819\n",
      "3 Train Loss 31.802038 Test MSE 1140.2979200970872 Test RE 0.6465716344135588\n",
      "4 Train Loss 24.495571 Test MSE 848.0394997921485 Test RE 0.5575907010068131\n",
      "5 Train Loss 3.3573177 Test MSE 18.99013586718087 Test RE 0.08343946633670467\n",
      "6 Train Loss 0.53631204 Test MSE 3.3708927147441092 Test RE 0.03515442080556938\n",
      "7 Train Loss 0.19289336 Test MSE 0.47992788596423824 Test RE 0.013264640199772349\n",
      "8 Train Loss 0.031191915 Test MSE 0.03369238373410527 Test RE 0.003514579333599612\n",
      "9 Train Loss 0.018296333 Test MSE 0.016552125525140092 Test RE 0.0024633967685087706\n",
      "10 Train Loss 0.0073415707 Test MSE 0.0026134380616739655 Test RE 0.0009788442357544036\n",
      "11 Train Loss 0.003617852 Test MSE 0.002694539380286817 Test RE 0.0009939161543415197\n",
      "12 Train Loss 0.0016651428 Test MSE 0.0026101817548326986 Test RE 0.000978234232648459\n",
      "13 Train Loss 0.0014734134 Test MSE 0.0006486913861007232 Test RE 0.00048767056973376884\n",
      "14 Train Loss 0.0013978981 Test MSE 0.0006313597397927688 Test RE 0.00048111170617510943\n",
      "15 Train Loss 0.001119604 Test MSE 0.0004151830951256631 Test RE 0.00039014613855079016\n",
      "16 Train Loss 0.00091426197 Test MSE 0.00045501670714950517 Test RE 0.00040843330944853866\n",
      "17 Train Loss 0.0006212999 Test MSE 0.00019887702018148783 Test RE 0.0002700223943217466\n",
      "18 Train Loss 0.0004889644 Test MSE 0.0001878166989309053 Test RE 0.00026240649680344373\n",
      "19 Train Loss 0.00017744488 Test MSE 9.129299444143986e-05 Test RE 0.00018294738574150355\n",
      "20 Train Loss 9.567378e-05 Test MSE 8.306847745791005e-05 Test RE 0.00017451212505683513\n",
      "21 Train Loss 8.7428125e-05 Test MSE 5.0627761183302365e-05 Test RE 0.0001362391242148075\n",
      "22 Train Loss 8.7311404e-05 Test MSE 4.8820872606591446e-05 Test RE 0.0001337858710448275\n",
      "23 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "24 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "25 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "26 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "27 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "28 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "29 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "30 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "31 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "32 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "33 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "34 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "35 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "36 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "37 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "38 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "39 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "40 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "41 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "42 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "43 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "44 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "45 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "46 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "47 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "48 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "49 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "50 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "51 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "52 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "53 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "54 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "55 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "56 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "57 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "58 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "59 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "60 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "61 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "62 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "63 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "64 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "65 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "66 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "67 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "68 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "69 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "70 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "71 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "72 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "73 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "74 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "75 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "76 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "77 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "78 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "79 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "80 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "81 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "82 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "83 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "84 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "85 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "86 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "87 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "88 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "89 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "90 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "91 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "92 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "93 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "94 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "95 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "96 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "97 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "98 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "99 Train Loss 8.720568e-05 Test MSE 4.7159471252170174e-05 Test RE 0.00013148976384104035\n",
      "Training time: 10.20\n",
      "Training time: 10.20\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 65.96733 Test MSE 2422.3218413344325 Test RE 0.9423742362137093\n",
      "1 Train Loss 43.930374 Test MSE 1309.9762735112636 Test RE 0.6930095136239287\n",
      "2 Train Loss 19.564835 Test MSE 548.0402176809572 Test RE 0.44824318654938555\n",
      "3 Train Loss 6.0341897 Test MSE 139.29930853025442 Test RE 0.22598622217965134\n",
      "4 Train Loss 2.0499265 Test MSE 13.5540556198638 Test RE 0.07049237023223846\n",
      "5 Train Loss 1.0548563 Test MSE 5.018939294898332 Test RE 0.04289566976390751\n",
      "6 Train Loss 0.109783255 Test MSE 0.3711724330452834 Test RE 0.01166528459523315\n",
      "7 Train Loss 0.041985195 Test MSE 0.051369582434435394 Test RE 0.004339707908258731\n",
      "8 Train Loss 0.022218874 Test MSE 0.02471950580315379 Test RE 0.0030104219629971092\n",
      "9 Train Loss 0.010483471 Test MSE 0.04847201673947565 Test RE 0.004215538174839266\n",
      "10 Train Loss 0.007672191 Test MSE 0.004526700757458726 Test RE 0.0012882447307024842\n",
      "11 Train Loss 0.0046938513 Test MSE 0.0026742005953881245 Test RE 0.0009901579353642548\n",
      "12 Train Loss 0.0033427365 Test MSE 0.0026747945367003984 Test RE 0.0009902678865500484\n",
      "13 Train Loss 0.0031390234 Test MSE 0.0011837898581287278 Test RE 0.0006587866491335878\n",
      "14 Train Loss 0.003138236 Test MSE 0.0012016766634165678 Test RE 0.0006637450502038669\n",
      "15 Train Loss 0.003030442 Test MSE 0.0022897585095842266 Test RE 0.0009162253901237768\n",
      "16 Train Loss 0.0027214384 Test MSE 0.000679502625357958 Test RE 0.0004991177918904859\n",
      "17 Train Loss 0.0019579446 Test MSE 0.0016309510765210255 Test RE 0.0007732642794955166\n",
      "18 Train Loss 0.001598775 Test MSE 0.0008680987219443257 Test RE 0.000564146684588413\n",
      "19 Train Loss 0.0014804566 Test MSE 0.0008041236910946358 Test RE 0.0005429613431570794\n",
      "20 Train Loss 0.0012472803 Test MSE 0.0016016984325616097 Test RE 0.0007662982911305215\n",
      "21 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "22 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "23 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "24 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "25 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "26 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "27 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "28 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "29 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "30 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "31 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "32 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "33 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "34 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "35 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "36 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "37 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "38 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "39 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "40 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "41 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "42 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "43 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "44 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "45 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "46 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "47 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "48 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "49 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "50 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "51 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "52 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "53 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "54 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "55 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "56 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "57 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "58 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "59 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "60 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "61 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "62 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "63 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "64 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "65 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "66 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "67 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "68 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "69 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "70 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "71 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "72 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "73 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "74 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "75 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "76 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "77 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "78 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "79 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "80 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "81 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "82 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "83 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "84 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "85 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "86 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "87 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "88 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "89 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "90 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "91 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "92 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "93 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "94 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "95 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "96 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "97 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "98 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "99 Train Loss 0.00068591244 Test MSE 0.00029315526149708735 Test RE 0.0003278357631440599\n",
      "Training time: 9.91\n",
      "Training time: 9.91\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 62.868572 Test MSE 2279.5874610162386 Test RE 0.9141882004788716\n",
      "1 Train Loss 35.18173 Test MSE 1221.1343562713168 Test RE 0.6690971913600965\n",
      "2 Train Loss 20.045818 Test MSE 615.9856149311132 Test RE 0.47521787382207636\n",
      "3 Train Loss 13.474763 Test MSE 383.2051244676454 Test RE 0.374820327536198\n",
      "4 Train Loss 6.73767 Test MSE 107.10522322068074 Test RE 0.19815854608555405\n",
      "5 Train Loss 1.7762774 Test MSE 14.57437908366439 Test RE 0.07309749807409914\n",
      "6 Train Loss 0.32490346 Test MSE 1.792352316982331 Test RE 0.0256341648322997\n",
      "7 Train Loss 0.053092442 Test MSE 0.042106482688821154 Test RE 0.0039289994148472155\n",
      "8 Train Loss 0.022246893 Test MSE 0.00911236113345071 Test RE 0.001827775885744037\n",
      "9 Train Loss 0.018545149 Test MSE 0.012922160450478285 Test RE 0.002176582065643429\n",
      "10 Train Loss 0.011804219 Test MSE 0.0030262249830791984 Test RE 0.001053314561036951\n",
      "11 Train Loss 0.0074094054 Test MSE 0.010318063241515957 Test RE 0.0019449416404232944\n",
      "12 Train Loss 0.005521553 Test MSE 0.001544023556758477 Test RE 0.0007523751497339774\n",
      "13 Train Loss 0.0036875573 Test MSE 0.0010496468681727726 Test RE 0.0006203390047382061\n",
      "14 Train Loss 0.0013936175 Test MSE 0.0008299690446018284 Test RE 0.0005516179998087101\n",
      "15 Train Loss 0.0011730603 Test MSE 0.00022762369396808876 Test RE 0.0002888791617834834\n",
      "16 Train Loss 0.0009196265 Test MSE 0.00026403471914984575 Test RE 0.0003111272144999365\n",
      "17 Train Loss 0.0007340046 Test MSE 0.00016479689510824275 Test RE 0.00024580006550585157\n",
      "18 Train Loss 0.00066326506 Test MSE 0.0001388060890778767 Test RE 0.0002255857907641118\n",
      "19 Train Loss 0.0005616346 Test MSE 0.0001504449897743136 Test RE 0.00023485312661473647\n",
      "20 Train Loss 0.00041438133 Test MSE 6.903319893924807e-05 Test RE 0.0001590876553191959\n",
      "21 Train Loss 0.0003166916 Test MSE 8.850919738348151e-05 Test RE 0.00018013648455443505\n",
      "22 Train Loss 0.00031603058 Test MSE 7.758046387362369e-05 Test RE 0.00016864896015809558\n",
      "23 Train Loss 0.00030102336 Test MSE 8.802866163533947e-05 Test RE 0.00017964681888132497\n",
      "24 Train Loss 0.00024488525 Test MSE 8.11766467170702e-05 Test RE 0.00017251347977865453\n",
      "25 Train Loss 0.0002346153 Test MSE 7.540144737537079e-05 Test RE 0.00016626365484341847\n",
      "26 Train Loss 0.00023158621 Test MSE 8.542623721731117e-05 Test RE 0.000176971413813881\n",
      "27 Train Loss 0.00021014405 Test MSE 6.491042711275636e-05 Test RE 0.00015426404509100549\n",
      "28 Train Loss 0.00020812338 Test MSE 6.385704888284315e-05 Test RE 0.00015300721270236175\n",
      "29 Train Loss 0.00020547019 Test MSE 5.635951582824632e-05 Test RE 0.0001437444576293896\n",
      "30 Train Loss 0.00019243125 Test MSE 9.097341112195345e-05 Test RE 0.00018262688913183657\n",
      "31 Train Loss 0.00014785289 Test MSE 5.077791715444311e-05 Test RE 0.00013644100922441624\n",
      "32 Train Loss 0.00011313909 Test MSE 5.3920728512507534e-05 Test RE 0.0001406000118861866\n",
      "33 Train Loss 0.00011273719 Test MSE 5.842502496786562e-05 Test RE 0.00014635478805232106\n",
      "34 Train Loss 0.00010643065 Test MSE 6.464086311234786e-05 Test RE 0.00015394339324795495\n",
      "35 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "36 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "37 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "38 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "39 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "40 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "41 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "42 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "43 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "44 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "45 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "46 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "47 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "48 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "49 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "50 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "51 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "52 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "53 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "54 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "55 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "56 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "57 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "58 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "59 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "60 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "61 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "62 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "63 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "64 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "65 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "66 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "67 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "68 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "69 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "70 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "71 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "72 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "73 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "74 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "75 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "76 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "77 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "78 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "79 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "80 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "81 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "82 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "83 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "84 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "85 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "86 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "87 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "88 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "89 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "90 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "91 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "92 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "93 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "94 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "95 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "96 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "97 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "98 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "99 Train Loss 0.00010581455 Test MSE 6.165668839676099e-05 Test RE 0.00015034797367123045\n",
      "Training time: 12.54\n",
      "Training time: 12.54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 56.384052 Test MSE 1831.8204060261123 Test RE 0.8194999437599717\n",
      "1 Train Loss 37.81505 Test MSE 1283.798138048906 Test RE 0.6860501324517138\n",
      "2 Train Loss 33.369614 Test MSE 1203.4229554799242 Test RE 0.6642271565608039\n",
      "3 Train Loss 32.44577 Test MSE 1156.2598150964136 Test RE 0.6510812640098242\n",
      "4 Train Loss 31.791336 Test MSE 1132.6682472259292 Test RE 0.6444049157335656\n",
      "5 Train Loss 29.280588 Test MSE 1026.7873635672747 Test RE 0.6135468622490416\n",
      "6 Train Loss 13.508641 Test MSE 113.23662776161883 Test RE 0.2037515613747501\n",
      "7 Train Loss 4.2763414 Test MSE 81.22652109215979 Test RE 0.17256646719062743\n",
      "8 Train Loss 2.5808945 Test MSE 18.65705965456228 Test RE 0.08270448885002886\n",
      "9 Train Loss 1.2750914 Test MSE 5.8683539444665485 Test RE 0.04638372592163672\n",
      "10 Train Loss 0.1964519 Test MSE 1.9723421620057626 Test RE 0.026890483500561977\n",
      "11 Train Loss 0.054709084 Test MSE 0.4738080394382146 Test RE 0.013179796191190913\n",
      "12 Train Loss 0.031235417 Test MSE 0.36221675129910225 Test RE 0.011523694791120883\n",
      "13 Train Loss 0.009397823 Test MSE 0.007977461550080597 Test RE 0.00171017219684722\n",
      "14 Train Loss 0.0056032767 Test MSE 0.0035886191084382583 Test RE 0.001147020459276898\n",
      "15 Train Loss 0.0052999337 Test MSE 0.003650087514208907 Test RE 0.0011568022385868343\n",
      "16 Train Loss 0.004277847 Test MSE 0.0076284337084882355 Test RE 0.0016723422813716374\n",
      "17 Train Loss 0.0015137743 Test MSE 0.0033432430632334346 Test RE 0.0011071117444516553\n",
      "18 Train Loss 0.00096822175 Test MSE 0.00047592038421876294 Test RE 0.00041770977168801074\n",
      "19 Train Loss 0.00090210966 Test MSE 0.0008397254261439977 Test RE 0.0005548506938961298\n",
      "20 Train Loss 0.00078807 Test MSE 0.0007697519197977872 Test RE 0.0005312303416454418\n",
      "21 Train Loss 0.0007757167 Test MSE 0.0005100106913873664 Test RE 0.0004324113869289219\n",
      "22 Train Loss 0.00077503524 Test MSE 0.0004987550308748473 Test RE 0.0004276132231247541\n",
      "23 Train Loss 0.0007744286 Test MSE 0.0004901495264982212 Test RE 0.00042390815894230763\n",
      "24 Train Loss 0.0007739074 Test MSE 0.00048479005966350057 Test RE 0.00042158420851433223\n",
      "25 Train Loss 0.000773344 Test MSE 0.00048139907645565873 Test RE 0.00042010718395437535\n",
      "26 Train Loss 0.0005673014 Test MSE 0.001027548137138797 Test RE 0.0006137741166084638\n",
      "27 Train Loss 0.0003451214 Test MSE 0.00018200842384260326 Test RE 0.0002583171414834886\n",
      "28 Train Loss 0.0003435397 Test MSE 0.0001822006028592138 Test RE 0.00025845348142807553\n",
      "29 Train Loss 0.00034311044 Test MSE 0.00018135288327375911 Test RE 0.0002578515308450125\n",
      "30 Train Loss 0.0003427354 Test MSE 0.00018118453419438703 Test RE 0.0002577318218394576\n",
      "31 Train Loss 0.00034237438 Test MSE 0.00017941454316278734 Test RE 0.00025646984160721344\n",
      "32 Train Loss 0.00034192274 Test MSE 0.00017648316381497874 Test RE 0.00025436603606043736\n",
      "33 Train Loss 0.0003414017 Test MSE 0.00017326722408563447 Test RE 0.0002520378061062167\n",
      "34 Train Loss 0.0003407886 Test MSE 0.0001674079016112941 Test RE 0.00024773961488823296\n",
      "35 Train Loss 0.00034032812 Test MSE 0.0001645213724069392 Test RE 0.0002455945039014452\n",
      "36 Train Loss 0.00033989793 Test MSE 0.00016170762838384293 Test RE 0.00024348529388505026\n",
      "37 Train Loss 0.0003395176 Test MSE 0.00015792847192912273 Test RE 0.00024062331099402023\n",
      "38 Train Loss 0.00033921568 Test MSE 0.0001562930760835936 Test RE 0.00023937420623582387\n",
      "39 Train Loss 0.0003389554 Test MSE 0.00015465187807978906 Test RE 0.00023811408242037233\n",
      "40 Train Loss 0.00033872158 Test MSE 0.00015263420024474309 Test RE 0.00023655569582040498\n",
      "41 Train Loss 0.00033849492 Test MSE 0.0001512875472541256 Test RE 0.0002355098483246643\n",
      "42 Train Loss 0.00033828523 Test MSE 0.00015014493316576827 Test RE 0.000234618807064132\n",
      "43 Train Loss 0.0003380122 Test MSE 0.0001494861500469713 Test RE 0.0002341035288557277\n",
      "44 Train Loss 0.00033774256 Test MSE 0.00014857673102336707 Test RE 0.00023339034241688306\n",
      "45 Train Loss 0.00033737576 Test MSE 0.0001479913436923447 Test RE 0.00023293011359201948\n",
      "46 Train Loss 0.00033680117 Test MSE 0.00014700793840679603 Test RE 0.00023215491112551603\n",
      "47 Train Loss 0.0003358958 Test MSE 0.00014638924492755588 Test RE 0.0002316658757296862\n",
      "48 Train Loss 0.0002804517 Test MSE 0.00022101935183975954 Test RE 0.0002846575009259973\n",
      "49 Train Loss 0.0002109009 Test MSE 0.00013487063064777975 Test RE 0.00022236486947547349\n",
      "50 Train Loss 0.00020656781 Test MSE 0.0001242116218828985 Test RE 0.0002133971417024568\n",
      "51 Train Loss 0.00020560334 Test MSE 0.00011823678444046655 Test RE 0.0002082014677741417\n",
      "52 Train Loss 0.00020480594 Test MSE 0.00011694876929805578 Test RE 0.00020706433870941015\n",
      "53 Train Loss 0.00020409924 Test MSE 0.000116037029329324 Test RE 0.00020625561610137716\n",
      "54 Train Loss 0.00020354273 Test MSE 0.00011571038598473659 Test RE 0.00020596510752641365\n",
      "55 Train Loss 0.00020314711 Test MSE 0.00011582896567228893 Test RE 0.000206070616741798\n",
      "56 Train Loss 0.00020285696 Test MSE 0.00011700655064825185 Test RE 0.0002071154849492251\n",
      "57 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "58 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "59 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "60 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "61 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "62 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "63 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "64 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "65 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "66 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "67 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "68 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "69 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "70 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "71 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "72 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "73 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "74 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "75 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "76 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "77 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "78 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "79 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "80 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "81 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "82 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "83 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "84 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "85 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "86 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "87 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "88 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "89 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "90 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "91 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "92 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "93 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "94 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "95 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "96 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "97 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "98 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "99 Train Loss 0.00020261947 Test MSE 0.00011580431756891694 Test RE 0.00020604868992895177\n",
      "Training time: 11.23\n",
      "Training time: 11.23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 62.29281 Test MSE 2184.940414887413 Test RE 0.8950087490541706\n",
      "1 Train Loss 29.927076 Test MSE 910.5246651615075 Test RE 0.5777678066767716\n",
      "2 Train Loss 15.798116 Test MSE 471.547537023613 Test RE 0.41578634479259646\n",
      "3 Train Loss 2.3041928 Test MSE 77.91424061359916 Test RE 0.1690113625045741\n",
      "4 Train Loss 0.33506092 Test MSE 0.5841070836547491 Test RE 0.014633685539688026\n",
      "5 Train Loss 0.092111304 Test MSE 0.18245095307339457 Test RE 0.008178629787832719\n",
      "6 Train Loss 0.032021485 Test MSE 0.18312443317099875 Test RE 0.00819371074687951\n",
      "7 Train Loss 0.010232202 Test MSE 0.016930127679294856 Test RE 0.0024913663739567255\n",
      "8 Train Loss 0.0055823284 Test MSE 0.0055491774541785235 Test RE 0.0014263358181043212\n",
      "9 Train Loss 0.003615202 Test MSE 0.004058812839490684 Test RE 0.0012198515842224617\n",
      "10 Train Loss 0.0019504563 Test MSE 0.0020808400312943235 Test RE 0.0008734274341831198\n",
      "11 Train Loss 0.0013650813 Test MSE 0.0007670703670507946 Test RE 0.0005303042218475442\n",
      "12 Train Loss 0.001130057 Test MSE 0.0009055304281277405 Test RE 0.0005761810967619158\n",
      "13 Train Loss 0.0008677075 Test MSE 0.0005350208421423806 Test RE 0.00044288689741455107\n",
      "14 Train Loss 0.0007759666 Test MSE 0.0008657125199158168 Test RE 0.0005633707968474467\n",
      "15 Train Loss 0.00054426014 Test MSE 0.00032039531287711485 Test RE 0.00034272876721966935\n",
      "16 Train Loss 0.00019083303 Test MSE 0.00021566296934921194 Test RE 0.00028118702186160163\n",
      "17 Train Loss 7.43358e-05 Test MSE 3.594435943296841e-05 Test RE 0.00011479496923448457\n",
      "18 Train Loss 7.0998256e-05 Test MSE 2.8300381854207475e-05 Test RE 0.0001018599900715294\n",
      "19 Train Loss 7.019679e-05 Test MSE 2.621535188678883e-05 Test RE 9.803594230900119e-05\n",
      "20 Train Loss 6.9453665e-05 Test MSE 2.396191863189891e-05 Test RE 9.372776828297004e-05\n",
      "21 Train Loss 6.885999e-05 Test MSE 2.2438983924829257e-05 Test RE 9.070037350675746e-05\n",
      "22 Train Loss 6.8457426e-05 Test MSE 2.1463709793834403e-05 Test RE 8.870740516827223e-05\n",
      "23 Train Loss 6.804429e-05 Test MSE 2.0514799901821216e-05 Test RE 8.67243641656273e-05\n",
      "24 Train Loss 6.759835e-05 Test MSE 1.972633491271167e-05 Test RE 8.504145516962526e-05\n",
      "25 Train Loss 6.709564e-05 Test MSE 1.8695497716902038e-05 Test RE 8.278964065486524e-05\n",
      "26 Train Loss 6.66473e-05 Test MSE 1.8097967400966547e-05 Test RE 8.145586925045671e-05\n",
      "27 Train Loss 6.616242e-05 Test MSE 1.7796341470822474e-05 Test RE 8.077423376125442e-05\n",
      "28 Train Loss 6.5516455e-05 Test MSE 1.7809618454536093e-05 Test RE 8.080435900466437e-05\n",
      "29 Train Loss 6.3524254e-05 Test MSE 2.072067437815874e-05 Test RE 8.715843524132918e-05\n",
      "30 Train Loss 3.7237925e-05 Test MSE 1.0579819021587728e-05 Test RE 6.227971279556894e-05\n",
      "31 Train Loss 3.3854576e-05 Test MSE 6.985675741420303e-06 Test RE 5.0607128209438575e-05\n",
      "32 Train Loss 3.3324934e-05 Test MSE 6.367696041143779e-06 Test RE 4.831685346170235e-05\n",
      "33 Train Loss 3.289996e-05 Test MSE 5.576202148431901e-06 Test RE 4.5214396294515186e-05\n",
      "34 Train Loss 3.2543365e-05 Test MSE 5.115015091644638e-06 Test RE 4.330429189609486e-05\n",
      "35 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "36 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "37 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "38 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "39 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "40 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "41 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "42 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "43 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "44 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "45 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "46 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "47 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "48 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "49 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "50 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "51 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "52 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "53 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "54 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "55 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "56 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "57 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "58 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "59 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "60 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "61 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "62 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "63 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "64 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "65 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "66 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "67 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "68 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "69 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "70 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "71 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "72 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "73 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "74 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "75 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "76 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "77 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "78 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "79 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "80 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "81 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "82 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "83 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "84 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "85 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "86 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "87 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "88 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "89 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "90 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "91 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "92 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "93 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "94 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "95 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "96 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "97 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "98 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "99 Train Loss 3.2275668e-05 Test MSE 4.792572362353895e-06 Test RE 4.191715719121031e-05\n",
      "Training time: 8.96\n",
      "Training time: 8.96\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 60.68463 Test MSE 2142.6074217930673 Test RE 0.8862959897597528\n",
      "1 Train Loss 36.115597 Test MSE 1203.638066342926 Test RE 0.6642865189370015\n",
      "2 Train Loss 31.532028 Test MSE 1087.1177340937911 Test RE 0.6313145111883074\n",
      "3 Train Loss 28.37116 Test MSE 999.729322099418 Test RE 0.6054087546304662\n",
      "4 Train Loss 18.378038 Test MSE 496.14431213173725 Test RE 0.42649259021360775\n",
      "5 Train Loss 3.9896967 Test MSE 72.33891228904119 Test RE 0.16285213963533393\n",
      "6 Train Loss 0.39286685 Test MSE 1.1033734870863556 Test RE 0.020112624887759986\n",
      "7 Train Loss 0.061687853 Test MSE 0.0734559296009177 Test RE 0.005189444975045605\n",
      "8 Train Loss 0.02054388 Test MSE 0.0498300623971795 Test RE 0.004274183833068478\n",
      "9 Train Loss 0.009433909 Test MSE 0.006103261227966958 Test RE 0.001495851430713196\n",
      "10 Train Loss 0.0036400114 Test MSE 0.003957050564363067 Test RE 0.0012044624960570716\n",
      "11 Train Loss 0.0009549919 Test MSE 0.001842679271088623 Test RE 0.0008219253153588907\n",
      "12 Train Loss 0.0008480076 Test MSE 0.0008433709138497365 Test RE 0.000556053772183099\n",
      "13 Train Loss 0.00070551515 Test MSE 0.0005757502895926541 Test RE 0.0004594355156351756\n",
      "14 Train Loss 0.00038808363 Test MSE 0.00013954931725798054 Test RE 0.00022618892670451792\n",
      "15 Train Loss 0.00033645928 Test MSE 0.0006580986323171166 Test RE 0.0004911939125701414\n",
      "16 Train Loss 0.0002586198 Test MSE 0.0004603789308937606 Test RE 0.0004108328873784229\n",
      "17 Train Loss 0.00023949376 Test MSE 0.00017976582819534198 Test RE 0.00025672079662528147\n",
      "18 Train Loss 0.00020822023 Test MSE 0.00023119539451942818 Test RE 0.0002911367777906341\n",
      "19 Train Loss 0.00015764359 Test MSE 6.198842063410303e-05 Test RE 0.00015075189062425788\n",
      "20 Train Loss 0.00015670269 Test MSE 5.6662574072801774e-05 Test RE 0.00014413041319745232\n",
      "21 Train Loss 0.00015608825 Test MSE 5.276784444840359e-05 Test RE 0.00013908879949331023\n",
      "22 Train Loss 0.00015569483 Test MSE 5.0546634385007084e-05 Test RE 0.00013612992448940365\n",
      "23 Train Loss 0.00015540839 Test MSE 4.983776374986422e-05 Test RE 0.00013517200487176274\n",
      "24 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "25 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "26 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "27 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "28 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "29 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "30 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "31 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "32 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "33 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "34 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "35 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "36 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "37 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "38 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "39 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "40 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "41 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "42 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "43 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "44 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "45 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "46 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "47 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "48 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "49 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "50 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "51 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "52 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "53 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "54 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "55 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "56 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "57 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "58 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "59 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "60 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "61 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "62 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "63 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "64 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "65 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "66 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "67 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "68 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "69 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "70 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "71 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "72 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "73 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "74 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "75 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "76 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "77 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "78 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "79 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "80 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "81 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "82 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "83 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "84 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "85 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "86 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "87 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "88 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "89 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "90 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "91 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "92 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "93 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "94 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "95 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "96 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "97 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "98 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "99 Train Loss 0.00015516854 Test MSE 4.8504545419119566e-05 Test RE 0.00013335174440326733\n",
      "Training time: 8.84\n",
      "Training time: 8.84\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 43.769047 Test MSE 1482.9346621290479 Test RE 0.737341180683003\n",
      "1 Train Loss 33.53784 Test MSE 1200.4805480461084 Test RE 0.6634146313235058\n",
      "2 Train Loss 31.717249 Test MSE 1108.1156122374912 Test RE 0.6373823287767048\n",
      "3 Train Loss 23.698807 Test MSE 710.6290655936454 Test RE 0.5104215066442824\n",
      "4 Train Loss 8.126126 Test MSE 132.16086782615383 Test RE 0.22011970527921004\n",
      "5 Train Loss 0.741434 Test MSE 11.781173098247214 Test RE 0.06572063489601825\n",
      "6 Train Loss 0.24674542 Test MSE 1.9802617553072417 Test RE 0.026944416420432483\n",
      "7 Train Loss 0.10761385 Test MSE 0.0724763791637728 Test RE 0.0051547276699532955\n",
      "8 Train Loss 0.06510293 Test MSE 0.46782829019221844 Test RE 0.013096363540211023\n",
      "9 Train Loss 0.030534038 Test MSE 0.03967818559827902 Test RE 0.0038140236707348766\n",
      "10 Train Loss 0.024593355 Test MSE 0.014602303577935738 Test RE 0.002313759251681584\n",
      "11 Train Loss 0.017947482 Test MSE 0.03586542626637134 Test RE 0.00362614762017071\n",
      "12 Train Loss 0.012972405 Test MSE 0.04331576732779272 Test RE 0.003985019839586532\n",
      "13 Train Loss 0.008837268 Test MSE 0.017840663238395033 Test RE 0.0025574843189429776\n",
      "14 Train Loss 0.0077344677 Test MSE 0.009813153111695084 Test RE 0.0018967573223442173\n",
      "15 Train Loss 0.0066335467 Test MSE 0.004277296021248713 Test RE 0.0012522531582051738\n",
      "16 Train Loss 0.0044093286 Test MSE 0.001986230382847231 Test RE 0.0008533403708210142\n",
      "17 Train Loss 0.0040571997 Test MSE 0.002780165791765174 Test RE 0.0010095848606506033\n",
      "18 Train Loss 0.0038258487 Test MSE 0.0035837503866835733 Test RE 0.0011462421071130838\n",
      "19 Train Loss 0.0032385269 Test MSE 0.002569499414141933 Test RE 0.0009705809059695721\n",
      "20 Train Loss 0.002280672 Test MSE 0.0011839577725590163 Test RE 0.0006588333702056088\n",
      "21 Train Loss 0.0022325187 Test MSE 0.0014730123182703423 Test RE 0.0007348702586097183\n",
      "22 Train Loss 0.0021963236 Test MSE 0.0017181384474563575 Test RE 0.000793663777884723\n",
      "23 Train Loss 0.001991296 Test MSE 0.0010549854583700921 Test RE 0.0006219145515076395\n",
      "24 Train Loss 0.0017701854 Test MSE 0.0013088834392234025 Test RE 0.0006927203852666929\n",
      "25 Train Loss 0.0015262546 Test MSE 0.0008513428484192497 Test RE 0.0005586756305816974\n",
      "26 Train Loss 0.0011481231 Test MSE 0.0005401248871542304 Test RE 0.0004449944311544479\n",
      "27 Train Loss 0.0007883724 Test MSE 0.0003680600166688907 Test RE 0.00036733879964036525\n",
      "28 Train Loss 0.0007375064 Test MSE 0.0004952763556324102 Test RE 0.00042611937314195595\n",
      "29 Train Loss 0.0007141554 Test MSE 0.0008425158582790406 Test RE 0.0005557718218336865\n",
      "30 Train Loss 0.0006087239 Test MSE 0.0005999370975095869 Test RE 0.00046898649901475927\n",
      "31 Train Loss 0.00050330115 Test MSE 0.0002516726684088595 Test RE 0.00030375645009326964\n",
      "32 Train Loss 0.00045351547 Test MSE 0.00013861264712874063 Test RE 0.00022542854633236532\n",
      "33 Train Loss 0.00044847623 Test MSE 0.00013619044495298405 Test RE 0.00022345022750518292\n",
      "34 Train Loss 0.00044658303 Test MSE 0.00013724408268066067 Test RE 0.00022431292378688624\n",
      "35 Train Loss 0.00044588398 Test MSE 0.0001365933463042658 Test RE 0.00022378050733017123\n",
      "36 Train Loss 0.0004451643 Test MSE 0.00014485056408212126 Test RE 0.0002304451525876077\n",
      "37 Train Loss 0.00044425955 Test MSE 0.00014802999051483553 Test RE 0.00023296052557728579\n",
      "38 Train Loss 0.00044370926 Test MSE 0.00014568421496099907 Test RE 0.0002311073356672693\n",
      "39 Train Loss 0.00044279968 Test MSE 0.00014247417849997955 Test RE 0.00022854701979081783\n",
      "40 Train Loss 0.00041457906 Test MSE 0.0001474942190300375 Test RE 0.00023253856126132522\n",
      "41 Train Loss 0.000381194 Test MSE 0.00012640452163500474 Test RE 0.000215272615053287\n",
      "42 Train Loss 0.00035369428 Test MSE 0.00012900633512224373 Test RE 0.00021747683334080405\n",
      "43 Train Loss 0.0003530218 Test MSE 0.00012749017082888087 Test RE 0.00021619509339755537\n",
      "44 Train Loss 0.00035238915 Test MSE 0.0001237521185535064 Test RE 0.0002130020597026471\n",
      "45 Train Loss 0.00035179293 Test MSE 0.00011815379576114169 Test RE 0.00020812838815747006\n",
      "46 Train Loss 0.0003512016 Test MSE 0.00011357528521484622 Test RE 0.00020405601441291952\n",
      "47 Train Loss 0.00035065165 Test MSE 0.0001039785350981828 Test RE 0.00019524473392886992\n",
      "48 Train Loss 0.00035021603 Test MSE 0.00011605627937274243 Test RE 0.00020627272385108667\n",
      "49 Train Loss 0.00034986582 Test MSE 0.00010857951421087334 Test RE 0.00019951769963876863\n",
      "50 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "51 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "52 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "53 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "54 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "55 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "56 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "57 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "58 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "59 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "60 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "61 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "62 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "63 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "64 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "65 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "66 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "67 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "68 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "69 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "70 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "71 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "72 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "73 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "74 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "75 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "76 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "77 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "78 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "79 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "80 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "81 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "82 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "83 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "84 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "85 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "86 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "87 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "88 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "89 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "90 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "91 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "92 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "93 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "94 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "95 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "96 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "97 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "98 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "99 Train Loss 0.0003494223 Test MSE 9.865507608970312e-05 Test RE 0.00019018103199544724\n",
      "Training time: 13.41\n",
      "Training time: 13.41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 48.43337 Test MSE 1734.5972103594988 Test RE 0.7974561351288383\n",
      "1 Train Loss 32.380733 Test MSE 1122.7320768778993 Test RE 0.641572214661811\n",
      "2 Train Loss 28.842001 Test MSE 1005.9334125652581 Test RE 0.6072843630457805\n",
      "3 Train Loss 23.196743 Test MSE 742.378585470448 Test RE 0.5216992347519402\n",
      "4 Train Loss 14.20432 Test MSE 340.111550586359 Test RE 0.3531166310876416\n",
      "5 Train Loss 0.8227584 Test MSE 7.85043169068791 Test RE 0.053648088347830074\n",
      "6 Train Loss 0.054838557 Test MSE 0.06058619293314929 Test RE 0.0047129660740473055\n",
      "7 Train Loss 0.022304047 Test MSE 0.017952312375516512 Test RE 0.002565474368645587\n",
      "8 Train Loss 0.006214589 Test MSE 0.003547118858402652 Test RE 0.0011403688675180874\n",
      "9 Train Loss 0.0034907912 Test MSE 0.0011442956802297434 Test RE 0.0006477040475662305\n",
      "10 Train Loss 0.002440424 Test MSE 0.0006984857387086101 Test RE 0.0005060416387375948\n",
      "11 Train Loss 0.0013732661 Test MSE 0.0008632615489570189 Test RE 0.0005625727350563406\n",
      "12 Train Loss 0.0009847623 Test MSE 0.0003695748293882616 Test RE 0.0003680939456705189\n",
      "13 Train Loss 0.0005683069 Test MSE 0.00011450973445402815 Test RE 0.00020489373797122505\n",
      "14 Train Loss 0.00043666048 Test MSE 0.00015317690861326352 Test RE 0.0002369758730803174\n",
      "15 Train Loss 0.00030300414 Test MSE 0.0003052658683115971 Test RE 0.0003345388857900334\n",
      "16 Train Loss 0.00026732808 Test MSE 4.641685144608645e-05 Test RE 0.00013045037166437197\n",
      "17 Train Loss 0.00024143749 Test MSE 6.638080578247499e-05 Test RE 0.00015600148832380236\n",
      "18 Train Loss 0.00019677695 Test MSE 3.78007390695075e-05 Test RE 0.00011772199879291129\n",
      "19 Train Loss 0.00014133363 Test MSE 2.5300035928905218e-05 Test RE 9.63092610658765e-05\n",
      "20 Train Loss 0.00013799476 Test MSE 1.8509124309738486e-05 Test RE 8.237594654008848e-05\n",
      "21 Train Loss 0.00011443361 Test MSE 1.328545713192667e-05 Test RE 6.979040731380232e-05\n",
      "22 Train Loss 0.00010177736 Test MSE 2.288031385330741e-05 Test RE 9.158797786543588e-05\n",
      "23 Train Loss 0.00010090649 Test MSE 2.110874571745299e-05 Test RE 8.797083129335883e-05\n",
      "24 Train Loss 0.000100090896 Test MSE 1.887114785152657e-05 Test RE 8.317764889522608e-05\n",
      "25 Train Loss 9.945852e-05 Test MSE 1.852944318632964e-05 Test RE 8.242114931562181e-05\n",
      "26 Train Loss 9.886352e-05 Test MSE 1.866555447383543e-05 Test RE 8.272331496051364e-05\n",
      "27 Train Loss 9.826447e-05 Test MSE 1.9460686600577642e-05 Test RE 8.446690109105064e-05\n",
      "28 Train Loss 9.7599026e-05 Test MSE 2.125652879046518e-05 Test RE 8.827823763688859e-05\n",
      "29 Train Loss 9.691238e-05 Test MSE 2.349826403470911e-05 Test RE 9.281653928296541e-05\n",
      "30 Train Loss 9.2422095e-05 Test MSE 5.1071062350146814e-05 Test RE 0.00013683428516078283\n",
      "31 Train Loss 7.358773e-05 Test MSE 2.357389086174041e-05 Test RE 9.296577970334727e-05\n",
      "32 Train Loss 7.25886e-05 Test MSE 2.283280902844824e-05 Test RE 9.14928495473389e-05\n",
      "33 Train Loss 7.1659466e-05 Test MSE 2.1533567422813114e-05 Test RE 8.88516452603787e-05\n",
      "34 Train Loss 7.0833485e-05 Test MSE 2.0733079946947187e-05 Test RE 8.718452242737271e-05\n",
      "35 Train Loss 7.0151145e-05 Test MSE 1.9005344122008905e-05 Test RE 8.34728709082637e-05\n",
      "36 Train Loss 6.958567e-05 Test MSE 1.765035231299027e-05 Test RE 8.044224289059398e-05\n",
      "37 Train Loss 6.910087e-05 Test MSE 1.591639287380562e-05 Test RE 7.638882099392813e-05\n",
      "38 Train Loss 6.8650465e-05 Test MSE 1.44957695051652e-05 Test RE 7.290009917661215e-05\n",
      "39 Train Loss 6.829119e-05 Test MSE 1.3036932314281468e-05 Test RE 6.913455745095361e-05\n",
      "40 Train Loss 6.780884e-05 Test MSE 1.376202575810713e-05 Test RE 7.103112039245294e-05\n",
      "41 Train Loss 6.7440786e-05 Test MSE 1.2202512067545177e-05 Test RE 6.688551951633038e-05\n",
      "42 Train Loss 6.693643e-05 Test MSE 1.0214083975250013e-05 Test RE 6.119376774202998e-05\n",
      "43 Train Loss 6.6382796e-05 Test MSE 8.662334674878008e-06 Test RE 5.635402771907746e-05\n",
      "44 Train Loss 6.587971e-05 Test MSE 7.2610563952513e-06 Test RE 5.1594972665839745e-05\n",
      "45 Train Loss 6.5415246e-05 Test MSE 6.3360934152150995e-06 Test RE 4.81968070047761e-05\n",
      "46 Train Loss 6.501003e-05 Test MSE 5.542042925438112e-06 Test RE 4.507569425138893e-05\n",
      "47 Train Loss 6.4861844e-05 Test MSE 6.052455277153712e-06 Test RE 4.7105679870868e-05\n",
      "48 Train Loss 6.451497e-05 Test MSE 5.664760515721796e-06 Test RE 4.55720178614774e-05\n",
      "49 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "50 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "51 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "52 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "53 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "54 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "55 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "56 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "57 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "58 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "59 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "60 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "61 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "62 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "63 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "64 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "65 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "66 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "67 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "68 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "69 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "70 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "71 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "72 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "73 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "74 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "75 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "76 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "77 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "78 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "79 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "80 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "81 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "82 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "83 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "84 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "85 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "86 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "87 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "88 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "89 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "90 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "91 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "92 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "93 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "94 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "95 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "96 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "97 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "98 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "99 Train Loss 6.421607e-05 Test MSE 5.282756106647396e-06 Test RE 4.4008621190673955e-05\n",
      "Training time: 10.14\n",
      "Training time: 10.14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 41.793007 Test MSE 1450.5555678322496 Test RE 0.7292470265236579\n",
      "1 Train Loss 35.623005 Test MSE 1276.978553483294 Test RE 0.6842255439484126\n",
      "2 Train Loss 30.801636 Test MSE 1024.4853880469607 Test RE 0.6128587147311614\n",
      "3 Train Loss 28.58994 Test MSE 964.7056860786611 Test RE 0.5947095340706252\n",
      "4 Train Loss 11.604191 Test MSE 251.07942523691923 Test RE 0.30339823130215726\n",
      "5 Train Loss 1.5876256 Test MSE 7.804533507157449 Test RE 0.05349102950420389\n",
      "6 Train Loss 0.46965188 Test MSE 0.7258801766629498 Test RE 0.016313229645620222\n",
      "7 Train Loss 0.40963238 Test MSE 1.1365227636861324 Test RE 0.02041251661054278\n",
      "8 Train Loss 0.33676305 Test MSE 0.636552121466059 Test RE 0.015276521186900564\n",
      "9 Train Loss 0.31356066 Test MSE 0.3537339718099627 Test RE 0.011387958269182315\n",
      "10 Train Loss 0.27404237 Test MSE 0.16416078406178944 Test RE 0.007757864513484711\n",
      "11 Train Loss 0.24744295 Test MSE 0.25842042373136576 Test RE 0.009733541814457815\n",
      "12 Train Loss 0.19391885 Test MSE 0.23663554929538905 Test RE 0.009314241110445234\n",
      "13 Train Loss 0.1159232 Test MSE 0.12230399109887621 Test RE 0.006696190439667944\n",
      "14 Train Loss 0.07563186 Test MSE 0.12433213893336728 Test RE 0.006751483090907012\n",
      "15 Train Loss 0.04322929 Test MSE 0.16574829175801267 Test RE 0.007795285260147207\n",
      "16 Train Loss 0.019886602 Test MSE 0.04186278900945442 Test RE 0.003917613261904111\n",
      "17 Train Loss 0.014276322 Test MSE 0.02226375240335783 Test RE 0.0028569764699456933\n",
      "18 Train Loss 0.008855036 Test MSE 0.009183013677348003 Test RE 0.0018348480191026177\n",
      "19 Train Loss 0.004968453 Test MSE 0.004508985902408667 Test RE 0.0012857215420971806\n",
      "20 Train Loss 0.004167585 Test MSE 0.00482478217087382 Test RE 0.0013299837572874772\n",
      "21 Train Loss 0.002271519 Test MSE 0.0017400482311012886 Test RE 0.0007987081664821639\n",
      "22 Train Loss 0.0017218736 Test MSE 0.00104884246934058 Test RE 0.0006201012602047118\n",
      "23 Train Loss 0.0014222508 Test MSE 0.0010393417433963346 Test RE 0.0006172863406086434\n",
      "24 Train Loss 0.0011803326 Test MSE 0.0007387248172255079 Test RE 0.0005204138263879583\n",
      "25 Train Loss 0.0009996502 Test MSE 0.0005789067644060591 Test RE 0.00046069319145550106\n",
      "26 Train Loss 0.0007978024 Test MSE 0.0009839026473601972 Test RE 0.0006005975362776476\n",
      "27 Train Loss 0.000661897 Test MSE 0.002135717027769284 Test RE 0.0008848697260762486\n",
      "28 Train Loss 0.0005506483 Test MSE 0.002113426152102192 Test RE 0.0008802398387216509\n",
      "29 Train Loss 0.00047466593 Test MSE 0.0010658647378177294 Test RE 0.000625112997692049\n",
      "30 Train Loss 0.00040629238 Test MSE 0.0010632677846178632 Test RE 0.0006243509970434522\n",
      "31 Train Loss 0.00023399983 Test MSE 0.0004443491460095748 Test RE 0.00040361719204447586\n",
      "32 Train Loss 0.00016969393 Test MSE 0.00015318154298049502 Test RE 0.00023697945790561575\n",
      "33 Train Loss 0.00013697903 Test MSE 0.00016138284279066948 Test RE 0.00024324065402447776\n",
      "34 Train Loss 0.00013494933 Test MSE 0.00014393147235592353 Test RE 0.0002297128900723233\n",
      "35 Train Loss 0.00013476353 Test MSE 0.0001630300140438842 Test RE 0.0002444788335236636\n",
      "36 Train Loss 0.00013378753 Test MSE 0.00015075991041728123 Test RE 0.0002350988025716264\n",
      "37 Train Loss 0.0001330943 Test MSE 0.00014418245980975567 Test RE 0.00022991308930479036\n",
      "38 Train Loss 0.00013248283 Test MSE 0.0001360385866328598 Test RE 0.00022332561435554947\n",
      "39 Train Loss 0.00013192257 Test MSE 0.00012986871519395652 Test RE 0.00021820251592470356\n",
      "40 Train Loss 0.00013130464 Test MSE 0.0001236003071893594 Test RE 0.0002128713708033301\n",
      "41 Train Loss 0.00013054478 Test MSE 0.00011610702666443618 Test RE 0.0002063178167926105\n",
      "42 Train Loss 0.00012988671 Test MSE 0.00010912086590165994 Test RE 0.0002000144551836696\n",
      "43 Train Loss 0.00012894032 Test MSE 0.00010398847770474206 Test RE 0.00019525406852454583\n",
      "44 Train Loss 0.00010898852 Test MSE 0.00010759523081437677 Test RE 0.00019861131759972062\n",
      "45 Train Loss 5.4523734e-05 Test MSE 1.8359868732361138e-05 Test RE 8.204313888725501e-05\n",
      "46 Train Loss 4.3524476e-05 Test MSE 2.1343066444328167e-05 Test RE 8.845775029943311e-05\n",
      "47 Train Loss 4.1553078e-05 Test MSE 1.4896255631069668e-05 Test RE 7.39002725386596e-05\n",
      "48 Train Loss 4.073482e-05 Test MSE 1.2437223525684505e-05 Test RE 6.75257165831313e-05\n",
      "49 Train Loss 4.005421e-05 Test MSE 1.1604804589314122e-05 Test RE 6.522684880854124e-05\n",
      "50 Train Loss 3.9505372e-05 Test MSE 1.066245000543906e-05 Test RE 6.252244968188364e-05\n",
      "51 Train Loss 3.8972397e-05 Test MSE 1.0354606089175236e-05 Test RE 6.161327200178997e-05\n",
      "52 Train Loss 3.8467115e-05 Test MSE 1.018021726870154e-05 Test RE 6.109223381509461e-05\n",
      "53 Train Loss 3.7935442e-05 Test MSE 1.0973252152182397e-05 Test RE 6.342714470294768e-05\n",
      "54 Train Loss 3.74919e-05 Test MSE 1.1424957278440886e-05 Test RE 6.471944348474291e-05\n",
      "55 Train Loss 3.695741e-05 Test MSE 1.2915919483120586e-05 Test RE 6.881294523049314e-05\n",
      "56 Train Loss 3.6628706e-05 Test MSE 1.3620870310972315e-05 Test RE 7.066590263996325e-05\n",
      "57 Train Loss 3.6269495e-05 Test MSE 1.4261680588215086e-05 Test RE 7.230907976381381e-05\n",
      "58 Train Loss 3.5914705e-05 Test MSE 1.5978912775459974e-05 Test RE 7.653870234337095e-05\n",
      "59 Train Loss 3.5595094e-05 Test MSE 1.663391006600849e-05 Test RE 7.809166028039184e-05\n",
      "60 Train Loss 3.5277073e-05 Test MSE 1.787351522902779e-05 Test RE 8.094918285848512e-05\n",
      "61 Train Loss 3.4986522e-05 Test MSE 1.8106408299811915e-05 Test RE 8.14748625602167e-05\n",
      "62 Train Loss 3.471683e-05 Test MSE 1.7202084045536005e-05 Test RE 7.94141724076176e-05\n",
      "63 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "64 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "65 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "66 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "67 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "68 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "69 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "70 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "71 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "72 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "73 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "74 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "75 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "76 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "77 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "78 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "79 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "80 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "81 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "82 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "83 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "84 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "85 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "86 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "87 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "88 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "89 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "90 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "91 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "92 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "93 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "94 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "95 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "96 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "97 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "98 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "99 Train Loss 3.44591e-05 Test MSE 2.4553744993640858e-05 Test RE 9.48781815475063e-05\n",
      "Training time: 13.87\n",
      "Training time: 13.87\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.81319 Test MSE 2114.2583502489065 Test RE 0.8804131265046025\n",
      "1 Train Loss 33.503418 Test MSE 1095.6850135723264 Test RE 0.6337972384260293\n",
      "2 Train Loss 28.82712 Test MSE 927.7795621814806 Test RE 0.5832166076604213\n",
      "3 Train Loss 24.774912 Test MSE 834.901227962015 Test RE 0.553254597652644\n",
      "4 Train Loss 15.921445 Test MSE 446.229012762992 Test RE 0.404470063880288\n",
      "5 Train Loss 7.080535 Test MSE 118.60439803001967 Test RE 0.2085248793510436\n",
      "6 Train Loss 0.70534897 Test MSE 4.907805564097975 Test RE 0.04241809457889239\n",
      "7 Train Loss 0.26085654 Test MSE 1.2706072177971692 Test RE 0.021583066100535234\n",
      "8 Train Loss 0.049782522 Test MSE 0.13834072214695223 Test RE 0.007121680745284459\n",
      "9 Train Loss 0.03592772 Test MSE 0.08018007435431973 Test RE 0.005421765242651462\n",
      "10 Train Loss 0.021595147 Test MSE 0.06948909551328596 Test RE 0.005047377776543129\n",
      "11 Train Loss 0.013596417 Test MSE 0.03260835044446626 Test RE 0.003457577287069272\n",
      "12 Train Loss 0.0024987971 Test MSE 0.0014741204942616325 Test RE 0.0007351466352764316\n",
      "13 Train Loss 0.0015213144 Test MSE 0.001179946497216174 Test RE 0.0006577163522052927\n",
      "14 Train Loss 0.0010597565 Test MSE 0.0013549673401498325 Test RE 0.0007048097371959515\n",
      "15 Train Loss 0.0002720762 Test MSE 0.0002666811198960735 Test RE 0.00031268252971132016\n",
      "16 Train Loss 0.00013373414 Test MSE 6.737647466035137e-05 Test RE 0.00015716709414963725\n",
      "17 Train Loss 0.00012940165 Test MSE 8.567168680658189e-05 Test RE 0.00017722547161520683\n",
      "18 Train Loss 0.00012865356 Test MSE 8.361851134747655e-05 Test RE 0.00017508893358555\n",
      "19 Train Loss 0.00012806567 Test MSE 7.836552252834791e-05 Test RE 0.00016950011556951818\n",
      "20 Train Loss 0.00012750515 Test MSE 7.521443865466586e-05 Test RE 0.0001660573454337164\n",
      "21 Train Loss 0.00012715858 Test MSE 7.244913713645395e-05 Test RE 0.00016297616361505676\n",
      "22 Train Loss 0.0001268644 Test MSE 6.958408326252257e-05 Test RE 0.00015972115305238696\n",
      "23 Train Loss 0.00012661837 Test MSE 6.797882175747276e-05 Test RE 0.00015786806951165495\n",
      "24 Train Loss 0.00012608708 Test MSE 5.8161583877457445e-05 Test RE 0.00014602445506767177\n",
      "25 Train Loss 0.00012511872 Test MSE 5.429525323557335e-05 Test RE 0.00014108745947207597\n",
      "26 Train Loss 0.00012429066 Test MSE 5.198521091442197e-05 Test RE 0.0001380534889966516\n",
      "27 Train Loss 9.0138215e-05 Test MSE 3.380605932686526e-05 Test RE 0.00011132808955441144\n",
      "28 Train Loss 8.9145804e-05 Test MSE 3.625273405696381e-05 Test RE 0.0001152863433219174\n",
      "29 Train Loss 8.850332e-05 Test MSE 3.964497637977743e-05 Test RE 0.00012055953479748564\n",
      "30 Train Loss 8.809334e-05 Test MSE 4.295589254105417e-05 Test RE 0.00012549281329604037\n",
      "31 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "32 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "33 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "34 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "35 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "36 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "37 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "38 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "39 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "40 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "41 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "42 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "43 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "44 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "45 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "46 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "47 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "48 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "49 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "50 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "51 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "52 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "53 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "54 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "55 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "56 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "57 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "58 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "59 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "60 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "61 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "62 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "63 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "64 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "65 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "66 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "67 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "68 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "69 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "70 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "71 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "72 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "73 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "74 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "75 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "76 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "77 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "78 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "79 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "80 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "81 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "82 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "83 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "84 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "85 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "86 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "87 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "88 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "89 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "90 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "91 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "92 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "93 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "94 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "95 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "96 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "97 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "98 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "99 Train Loss 8.784009e-05 Test MSE 4.596234563520965e-05 Test RE 0.00012981012673664633\n",
      "Training time: 9.34\n",
      "Training time: 9.34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 51.16168 Test MSE 1739.1735803596898 Test RE 0.7985074023631226\n",
      "1 Train Loss 33.148354 Test MSE 1186.8187718578956 Test RE 0.6596289156689117\n",
      "2 Train Loss 31.469225 Test MSE 1108.3410605660467 Test RE 0.63744716383136\n",
      "3 Train Loss 28.058697 Test MSE 874.7035754352484 Test RE 0.566288748331302\n",
      "4 Train Loss 21.390997 Test MSE 661.7053930307311 Test RE 0.49253808658522663\n",
      "5 Train Loss 8.56121 Test MSE 173.2184405145206 Test RE 0.25200232285234886\n",
      "6 Train Loss 3.0057678 Test MSE 19.316560105229268 Test RE 0.08415353747125723\n",
      "7 Train Loss 0.5074306 Test MSE 1.7884636461751149 Test RE 0.02560634191099939\n",
      "8 Train Loss 0.24465175 Test MSE 2.13772384177984 Test RE 0.027995181161472236\n",
      "9 Train Loss 0.16665804 Test MSE 0.5476121065224133 Test RE 0.014169156665267432\n",
      "10 Train Loss 0.11108471 Test MSE 0.24706340915751315 Test RE 0.009517254802460365\n",
      "11 Train Loss 0.075717896 Test MSE 0.13909336098877953 Test RE 0.007141027120392331\n",
      "12 Train Loss 0.051986422 Test MSE 0.0655589737717074 Test RE 0.004902567198183208\n",
      "13 Train Loss 0.03694158 Test MSE 0.08204880230119488 Test RE 0.005484582892965625\n",
      "14 Train Loss 0.016620697 Test MSE 0.0159697963476637 Test RE 0.002419675742904985\n",
      "15 Train Loss 0.010909132 Test MSE 0.015005412796259316 Test RE 0.002345478495228446\n",
      "16 Train Loss 0.00380506 Test MSE 0.0032183128589078195 Test RE 0.001086229546938597\n",
      "17 Train Loss 0.0029849212 Test MSE 0.0006811425961783182 Test RE 0.0004997197360891475\n",
      "18 Train Loss 0.0020064467 Test MSE 0.0005765776147329279 Test RE 0.0004597654903743025\n",
      "19 Train Loss 0.0017463315 Test MSE 0.0003036068173981232 Test RE 0.00033362857570311066\n",
      "20 Train Loss 0.0013371545 Test MSE 0.0005975397750305264 Test RE 0.0004680485362632118\n",
      "21 Train Loss 0.0012211743 Test MSE 0.0005622533262496626 Test RE 0.0004540184466287884\n",
      "22 Train Loss 0.0010085739 Test MSE 0.00023863445945718738 Test RE 0.00029578357949657647\n",
      "23 Train Loss 0.0006132192 Test MSE 0.00017389050700416123 Test RE 0.0002524907187691291\n",
      "24 Train Loss 0.0005112397 Test MSE 8.040136991832238e-05 Test RE 0.00017168770923942892\n",
      "25 Train Loss 0.0003995659 Test MSE 0.00015421565596029224 Test RE 0.000237778024492343\n",
      "26 Train Loss 0.00018580214 Test MSE 3.853023015257904e-05 Test RE 0.00011885248961696406\n",
      "27 Train Loss 0.00016682982 Test MSE 2.789660498582349e-05 Test RE 0.00010113073374271726\n",
      "28 Train Loss 0.00015970062 Test MSE 6.600873279812724e-05 Test RE 0.00015556366971545592\n",
      "29 Train Loss 0.00015886677 Test MSE 4.8291335404624324e-05 Test RE 0.00013305833643171837\n",
      "30 Train Loss 0.00015795883 Test MSE 3.699462545270121e-05 Test RE 0.0001164600035852183\n",
      "31 Train Loss 0.00015710949 Test MSE 2.8678861838819e-05 Test RE 0.00010253884887825266\n",
      "32 Train Loss 0.00015626982 Test MSE 2.5064403770070553e-05 Test RE 9.585972325014714e-05\n",
      "33 Train Loss 0.00015548128 Test MSE 2.3437842357644293e-05 Test RE 9.269713172419948e-05\n",
      "34 Train Loss 0.00015478219 Test MSE 2.3601790533986366e-05 Test RE 9.30207758819204e-05\n",
      "35 Train Loss 0.00015411543 Test MSE 2.447772525726224e-05 Test RE 9.473119367107206e-05\n",
      "36 Train Loss 0.00015344688 Test MSE 2.5777256893114587e-05 Test RE 9.721333261311934e-05\n",
      "37 Train Loss 0.00015277021 Test MSE 2.689614261182655e-05 Test RE 9.930073915337483e-05\n",
      "38 Train Loss 0.00015206923 Test MSE 2.7657154255050498e-05 Test RE 0.00010069577012402472\n",
      "39 Train Loss 0.00015129274 Test MSE 2.8203898570621117e-05 Test RE 0.00010168620837079123\n",
      "40 Train Loss 0.00015046819 Test MSE 3.0282148977898047e-05 Test RE 0.00010536608111842637\n",
      "41 Train Loss 0.00014960447 Test MSE 2.9849366256266714e-05 Test RE 0.00010461044251618475\n",
      "42 Train Loss 0.00013578152 Test MSE 3.365092945719764e-05 Test RE 0.00011107236364997462\n",
      "43 Train Loss 0.00012581162 Test MSE 3.7533644040462963e-05 Test RE 0.00011730535745845181\n",
      "44 Train Loss 0.00011480251 Test MSE 3.1653087188375535e-05 Test RE 0.00010772475593076693\n",
      "45 Train Loss 0.000114067196 Test MSE 2.8583209324316578e-05 Test RE 0.00010236770731270861\n",
      "46 Train Loss 0.000113284594 Test MSE 2.5765409085758485e-05 Test RE 9.719098932778253e-05\n",
      "47 Train Loss 0.00011245601 Test MSE 2.3816626733402908e-05 Test RE 9.344317940532285e-05\n",
      "48 Train Loss 0.00011154413 Test MSE 2.3386278877937473e-05 Test RE 9.259510828732418e-05\n",
      "49 Train Loss 0.00011076509 Test MSE 2.275760405782572e-05 Test RE 9.134204917495523e-05\n",
      "50 Train Loss 0.00010984344 Test MSE 2.3416854006545e-05 Test RE 9.265561775569336e-05\n",
      "51 Train Loss 0.000106487336 Test MSE 2.2503174069576063e-05 Test RE 9.083001200415763e-05\n",
      "52 Train Loss 0.00010419532 Test MSE 2.581370801624826e-05 Test RE 9.728204208336503e-05\n",
      "53 Train Loss 0.000103234204 Test MSE 2.3492195250723807e-05 Test RE 9.280455286771e-05\n",
      "54 Train Loss 0.000102313235 Test MSE 2.136199168453257e-05 Test RE 8.849696006415527e-05\n",
      "55 Train Loss 0.00010140188 Test MSE 1.881726635207808e-05 Test RE 8.305881828267945e-05\n",
      "56 Train Loss 0.000100544974 Test MSE 1.782506817476811e-05 Test RE 8.083940001677531e-05\n",
      "57 Train Loss 9.990323e-05 Test MSE 1.7049913662630327e-05 Test RE 7.906214154833422e-05\n",
      "58 Train Loss 9.91799e-05 Test MSE 1.7579381811372377e-05 Test RE 8.028035442891163e-05\n",
      "59 Train Loss 9.866017e-05 Test MSE 1.817737069822387e-05 Test RE 8.163436404146619e-05\n",
      "60 Train Loss 9.799705e-05 Test MSE 1.8905259874462955e-05 Test RE 8.325279209331436e-05\n",
      "61 Train Loss 9.702e-05 Test MSE 1.891848683752278e-05 Test RE 8.328191068441979e-05\n",
      "62 Train Loss 9.602542e-05 Test MSE 1.9523406006729826e-05 Test RE 8.460290482973226e-05\n",
      "63 Train Loss 9.385483e-05 Test MSE 2.1266553662684455e-05 Test RE 8.829905180046647e-05\n",
      "64 Train Loss 9.296165e-05 Test MSE 2.1844300101852243e-05 Test RE 8.949042053896726e-05\n",
      "65 Train Loss 9.218416e-05 Test MSE 2.1632634502174426e-05 Test RE 8.905579564875468e-05\n",
      "66 Train Loss 9.1387534e-05 Test MSE 2.249993552687598e-05 Test RE 9.082347587161987e-05\n",
      "67 Train Loss 9.085388e-05 Test MSE 2.188242889933731e-05 Test RE 8.956848837447184e-05\n",
      "68 Train Loss 9.043009e-05 Test MSE 2.2130561772277876e-05 Test RE 9.00748818173029e-05\n",
      "69 Train Loss 9.013612e-05 Test MSE 2.196938979053132e-05 Test RE 8.974628473811651e-05\n",
      "70 Train Loss 8.982956e-05 Test MSE 2.184577719389022e-05 Test RE 8.949344611892505e-05\n",
      "71 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "72 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "73 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "74 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "75 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "76 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "77 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "78 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "79 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "80 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "81 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "82 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "83 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "84 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "85 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "86 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "87 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "88 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "89 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "90 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "91 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "92 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "93 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "94 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "95 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "96 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "97 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "98 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "99 Train Loss 8.9558955e-05 Test MSE 2.1853994005672557e-05 Test RE 8.95102750388223e-05\n",
      "Training time: 12.47\n",
      "Training time: 12.47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 64.69773 Test MSE 2352.0943432643035 Test RE 0.9286131951767178\n",
      "1 Train Loss 37.362892 Test MSE 1043.8616640014668 Test RE 0.6186271211768485\n",
      "2 Train Loss 18.27235 Test MSE 556.9195911706404 Test RE 0.45185982481346204\n",
      "3 Train Loss 3.325383 Test MSE 37.75692241285817 Test RE 0.11765375039129104\n",
      "4 Train Loss 0.6833774 Test MSE 2.3524518772979963 Test RE 0.0293675593985051\n",
      "5 Train Loss 0.22040962 Test MSE 0.32632737300023773 Test RE 0.010937907194958997\n",
      "6 Train Loss 0.029730733 Test MSE 0.07700222118985 Test RE 0.005313236020574285\n",
      "7 Train Loss 0.010179447 Test MSE 0.00337690800813528 Test RE 0.0011126718397613123\n",
      "8 Train Loss 0.0073636724 Test MSE 0.002396277907115423 Test RE 0.0009372945108492792\n",
      "9 Train Loss 0.006133744 Test MSE 0.0021238556936972863 Test RE 0.0008824091124526183\n",
      "10 Train Loss 0.0032939878 Test MSE 0.0030004056430405486 Test RE 0.001048811567429611\n",
      "11 Train Loss 0.001491348 Test MSE 0.0004592631334834243 Test RE 0.0004103347277839761\n",
      "12 Train Loss 0.0009563826 Test MSE 0.0002914400704682046 Test RE 0.0003268753064756646\n",
      "13 Train Loss 0.0007072706 Test MSE 0.0001714329578552561 Test RE 0.0002507001772303806\n",
      "14 Train Loss 0.0005982538 Test MSE 0.00026133298410928026 Test RE 0.00030953131701797593\n",
      "15 Train Loss 0.00056154287 Test MSE 0.00014998554488058303 Test RE 0.0002344942426908017\n",
      "16 Train Loss 0.00046774463 Test MSE 0.00015554575895568553 Test RE 0.00023880123524810457\n",
      "17 Train Loss 0.00037235825 Test MSE 0.00017005528700170713 Test RE 0.0002496908059148624\n",
      "18 Train Loss 0.00029780905 Test MSE 6.403237357713938e-05 Test RE 0.00015321711556583745\n",
      "19 Train Loss 0.00028994927 Test MSE 5.6790632908080765e-05 Test RE 0.0001442931904494013\n",
      "20 Train Loss 0.00028930933 Test MSE 5.763392684876048e-05 Test RE 0.0001453605599459494\n",
      "21 Train Loss 0.00028885985 Test MSE 5.8374243847062104e-05 Test RE 0.0001462911708283279\n",
      "22 Train Loss 0.00028850636 Test MSE 5.917544718728056e-05 Test RE 0.00014729169367747876\n",
      "23 Train Loss 0.0002882255 Test MSE 6.046119279844959e-05 Test RE 0.000148883248860498\n",
      "24 Train Loss 0.00028797318 Test MSE 6.171380676556448e-05 Test RE 0.00015041759825917958\n",
      "25 Train Loss 0.00028760135 Test MSE 6.24085607806528e-05 Test RE 0.00015126190493785854\n",
      "26 Train Loss 0.00028701595 Test MSE 6.47570610465206e-05 Test RE 0.00015408169487203847\n",
      "27 Train Loss 0.0002862471 Test MSE 6.689953829464609e-05 Test RE 0.0001566098386180284\n",
      "28 Train Loss 0.00023892242 Test MSE 0.00010304661569512863 Test RE 0.00019436781310494953\n",
      "29 Train Loss 0.00021362162 Test MSE 4.840920654679277e-05 Test RE 0.0001332206241306392\n",
      "30 Train Loss 0.00021314059 Test MSE 4.8560362289563776e-05 Test RE 0.0001334284499662186\n",
      "31 Train Loss 0.00021224012 Test MSE 5.1159515974341096e-05 Test RE 0.000136952730437707\n",
      "32 Train Loss 0.00021178373 Test MSE 5.122470421402638e-05 Test RE 0.0001370399562949341\n",
      "33 Train Loss 0.00021121383 Test MSE 5.119576510334696e-05 Test RE 0.0001370012408470068\n",
      "34 Train Loss 0.00021057158 Test MSE 5.2577345315311456e-05 Test RE 0.00013883750769733293\n",
      "35 Train Loss 0.00020984026 Test MSE 5.329248359575104e-05 Test RE 0.0001397785277568442\n",
      "36 Train Loss 0.00020909196 Test MSE 5.5633311996409374e-05 Test RE 0.0001428153667486862\n",
      "37 Train Loss 0.00016024928 Test MSE 6.911876506011657e-05 Test RE 0.00015918621875109134\n",
      "38 Train Loss 0.0001455668 Test MSE 3.510519605354618e-05 Test RE 0.0001134470437077758\n",
      "39 Train Loss 0.00014489653 Test MSE 2.8560525054451104e-05 Test RE 0.00010232707860689101\n",
      "40 Train Loss 0.00014466913 Test MSE 4.446026091036104e-05 Test RE 0.00012767136017873622\n",
      "41 Train Loss 0.00014436805 Test MSE 3.7522967016539676e-05 Test RE 0.00011728867161267452\n",
      "42 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "43 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "44 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "45 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "46 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "47 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "48 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "49 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "50 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "51 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "52 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "53 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "54 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "55 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "56 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "57 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "58 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "59 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "60 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "61 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "62 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "63 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "64 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "65 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "66 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "67 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "68 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "69 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "70 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "71 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "72 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "73 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "74 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "75 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "76 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "77 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "78 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "79 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "80 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "81 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "82 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "83 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "84 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "85 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "86 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "87 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "88 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "89 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "90 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "91 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "92 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "93 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "94 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "95 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "96 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "97 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "98 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "99 Train Loss 0.00014411437 Test MSE 3.2195514638427535e-05 Test RE 0.0001086438550834755\n",
      "Training time: 9.82\n",
      "Training time: 9.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 61.026833 Test MSE 2182.067965283485 Test RE 0.8944202403200123\n",
      "1 Train Loss 37.66688 Test MSE 1242.9770606458783 Test RE 0.6750548139449669\n",
      "2 Train Loss 27.176176 Test MSE 898.8657080445904 Test RE 0.5740568293133554\n",
      "3 Train Loss 21.632719 Test MSE 719.0736443394325 Test RE 0.5134452818218507\n",
      "4 Train Loss 8.778924 Test MSE 151.3243889739496 Test RE 0.23553852239545323\n",
      "5 Train Loss 4.502114 Test MSE 50.32189840064991 Test RE 0.13582696293658286\n",
      "6 Train Loss 1.32364 Test MSE 2.087532819933424 Test RE 0.027664583608541207\n",
      "7 Train Loss 0.70857793 Test MSE 2.06286654658087 Test RE 0.027500655662479334\n",
      "8 Train Loss 0.38342503 Test MSE 1.368911755694273 Test RE 0.0224024340925434\n",
      "9 Train Loss 0.19663018 Test MSE 0.6149361978352569 Test RE 0.015014902309308282\n",
      "10 Train Loss 0.116601236 Test MSE 0.30366356512342174 Test RE 0.010551247856047719\n",
      "11 Train Loss 0.07995477 Test MSE 0.13376931261585065 Test RE 0.007003025850721556\n",
      "12 Train Loss 0.05569223 Test MSE 0.16898356344170895 Test RE 0.007870996400902832\n",
      "13 Train Loss 0.025209077 Test MSE 0.019473161301944077 Test RE 0.0026719339143050943\n",
      "14 Train Loss 0.016988927 Test MSE 0.00793502228909545 Test RE 0.0017056171620919332\n",
      "15 Train Loss 0.0112279095 Test MSE 0.005097182445715758 Test RE 0.0013670127687327978\n",
      "16 Train Loss 0.0063576405 Test MSE 0.003387651185443806 Test RE 0.001114440341998997\n",
      "17 Train Loss 0.004258572 Test MSE 0.0010498862026917801 Test RE 0.0006204097237959903\n",
      "18 Train Loss 0.0022459137 Test MSE 0.00028657629257758627 Test RE 0.00032413625625236106\n",
      "19 Train Loss 0.0021113302 Test MSE 0.00032828085046714394 Test RE 0.000346920734106302\n",
      "20 Train Loss 0.0018367897 Test MSE 0.0003404959542119907 Test RE 0.000353316125901314\n",
      "21 Train Loss 0.0018016846 Test MSE 0.00024459821637221426 Test RE 0.0002994567622737018\n",
      "22 Train Loss 0.0015943485 Test MSE 0.0008084855654157276 Test RE 0.0005444319664995187\n",
      "23 Train Loss 0.0013731566 Test MSE 0.00033475858350426736 Test RE 0.0003503267842090679\n",
      "24 Train Loss 0.0010289849 Test MSE 0.0023149071525859896 Test RE 0.000921243146922459\n",
      "25 Train Loss 0.00077855866 Test MSE 0.0002743268168678896 Test RE 0.0003171331299832929\n",
      "26 Train Loss 0.000761521 Test MSE 0.00010965401093106815 Test RE 0.00020050247723592016\n",
      "27 Train Loss 0.0007340237 Test MSE 0.00018553733274085155 Test RE 0.0002608093376796525\n",
      "28 Train Loss 0.0006275429 Test MSE 0.00015209320376246852 Test RE 0.00023613609981955265\n",
      "29 Train Loss 0.00038207675 Test MSE 0.0002850865798323291 Test RE 0.00032329267796616594\n",
      "30 Train Loss 0.0003042506 Test MSE 7.405681794960892e-05 Test RE 0.00016477450115851417\n",
      "31 Train Loss 0.00028507278 Test MSE 8.091533550724493e-05 Test RE 0.00017223559171086416\n",
      "32 Train Loss 0.0002766226 Test MSE 8.483714340488135e-05 Test RE 0.00017636016649264473\n",
      "33 Train Loss 0.00027012598 Test MSE 0.00011298424288382636 Test RE 0.0002035243711995844\n",
      "34 Train Loss 0.00026924003 Test MSE 0.0001052339471523418 Test RE 0.00019641986669789943\n",
      "35 Train Loss 0.00026862175 Test MSE 0.00010690780794936225 Test RE 0.00019797583993559853\n",
      "36 Train Loss 0.0002681091 Test MSE 0.0001078486763084366 Test RE 0.0001988450990374928\n",
      "37 Train Loss 0.00026771738 Test MSE 0.00010710839561950718 Test RE 0.0001981614807383433\n",
      "38 Train Loss 0.00026734764 Test MSE 0.00010652994595029757 Test RE 0.00019762566081240888\n",
      "39 Train Loss 0.000267106 Test MSE 0.000105246513154764 Test RE 0.00019643159361164481\n",
      "40 Train Loss 0.00026681894 Test MSE 0.00010469584198800188 Test RE 0.00019591703463101972\n",
      "41 Train Loss 0.00026650066 Test MSE 0.00010252006825002904 Test RE 0.00019387058692750252\n",
      "42 Train Loss 0.00026615686 Test MSE 0.00010023213015304779 Test RE 0.00019169507794397685\n",
      "43 Train Loss 0.00026586198 Test MSE 9.793000745760126e-05 Test RE 0.0001894808723777539\n",
      "44 Train Loss 0.00026553642 Test MSE 9.553073128276597e-05 Test RE 0.00018714534665619054\n",
      "45 Train Loss 0.0002651819 Test MSE 9.359267842060587e-05 Test RE 0.0001852372904704917\n",
      "46 Train Loss 0.00026485464 Test MSE 9.213373213949049e-05 Test RE 0.00018378785694456924\n",
      "47 Train Loss 0.00026451395 Test MSE 9.106656731115102e-05 Test RE 0.00018272036958837495\n",
      "48 Train Loss 0.0002641474 Test MSE 9.027076898765449e-05 Test RE 0.00018192025362850128\n",
      "49 Train Loss 0.00026380847 Test MSE 9.011067783547337e-05 Test RE 0.00018175886834705533\n",
      "50 Train Loss 0.0002634833 Test MSE 9.050983333068778e-05 Test RE 0.00018216098432332606\n",
      "51 Train Loss 0.00026319412 Test MSE 9.129531823331321e-05 Test RE 0.00018294971411809768\n",
      "52 Train Loss 0.00026291207 Test MSE 9.233852387281452e-05 Test RE 0.00018399200227158164\n",
      "53 Train Loss 0.00026265215 Test MSE 9.337311587044337e-05 Test RE 0.00018501988536150365\n",
      "54 Train Loss 0.0002623702 Test MSE 9.456031588940601e-05 Test RE 0.00018619239527435376\n",
      "55 Train Loss 0.00026208634 Test MSE 9.615497091599006e-05 Test RE 0.00018775579586943232\n",
      "56 Train Loss 0.00026178136 Test MSE 9.828845117876722e-05 Test RE 0.0001898273248880541\n",
      "57 Train Loss 0.00026153412 Test MSE 9.991500204359727e-05 Test RE 0.00019139158215268227\n",
      "58 Train Loss 0.00026119003 Test MSE 0.00010116775746807382 Test RE 0.00019258769860680557\n",
      "59 Train Loss 0.00026080868 Test MSE 0.00010144185912949918 Test RE 0.0001928484185326303\n",
      "60 Train Loss 0.0002603993 Test MSE 0.00010108080620705039 Test RE 0.00019250491856225927\n",
      "61 Train Loss 0.00025997616 Test MSE 9.940645168835479e-05 Test RE 0.00019090388549825843\n",
      "62 Train Loss 0.00025945852 Test MSE 9.598457309961279e-05 Test RE 0.00018758935952294795\n",
      "63 Train Loss 0.0002589967 Test MSE 9.145221507707988e-05 Test RE 0.00018310685202691456\n",
      "64 Train Loss 0.00025851716 Test MSE 8.62880195441722e-05 Test RE 0.00017786182018239105\n",
      "65 Train Loss 0.00025813628 Test MSE 8.123399979468874e-05 Test RE 0.00017257441129282545\n",
      "66 Train Loss 0.00025770077 Test MSE 7.548589770677663e-05 Test RE 0.00016635673721731274\n",
      "67 Train Loss 0.00025738333 Test MSE 7.079055484021946e-05 Test RE 0.00016109985142982833\n",
      "68 Train Loss 0.00025706406 Test MSE 6.637898150578246e-05 Test RE 0.00015599934469334254\n",
      "69 Train Loss 0.00025668688 Test MSE 6.194540164325452e-05 Test RE 0.00015069957182275317\n",
      "70 Train Loss 0.00025629418 Test MSE 5.7949923315999216e-05 Test RE 0.00014575850814037937\n",
      "71 Train Loss 0.00025577453 Test MSE 5.458613539666315e-05 Test RE 0.00014146488661887855\n",
      "72 Train Loss 0.00025516545 Test MSE 5.181069338608775e-05 Test RE 0.0001378215671916179\n",
      "73 Train Loss 0.00025420322 Test MSE 4.889403959303743e-05 Test RE 0.00013388608478226156\n",
      "74 Train Loss 0.00018238566 Test MSE 0.0005249814800561677 Test RE 0.00043871195909677714\n",
      "75 Train Loss 0.00014209397 Test MSE 2.5680000369424395e-05 Test RE 9.702976836360306e-05\n",
      "76 Train Loss 0.00014137838 Test MSE 2.5748624790897524e-05 Test RE 9.715932773123367e-05\n",
      "77 Train Loss 0.00014084492 Test MSE 2.6588720403434613e-05 Test RE 9.873160575553301e-05\n",
      "78 Train Loss 0.00014049749 Test MSE 2.7106382520077893e-05 Test RE 9.968808725447533e-05\n",
      "79 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "80 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "81 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "82 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "83 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "84 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "85 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "86 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "87 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "88 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "89 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "90 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "91 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "92 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "93 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "94 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "95 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "96 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "97 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "98 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "99 Train Loss 0.0001402753 Test MSE 2.7322020052527385e-05 Test RE 0.00010008382264916069\n",
      "Training time: 13.53\n",
      "Training time: 13.53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 57.063198 Test MSE 1849.3883925264395 Test RE 0.8234202544219662\n",
      "1 Train Loss 35.57001 Test MSE 1261.8054865659858 Test RE 0.6801484105946394\n",
      "2 Train Loss 32.787395 Test MSE 1177.7507740010901 Test RE 0.6571041059968906\n",
      "3 Train Loss 31.26631 Test MSE 1127.4834216122265 Test RE 0.642928331823591\n",
      "4 Train Loss 29.079214 Test MSE 989.8765926575193 Test RE 0.6024180960171325\n",
      "5 Train Loss 21.496998 Test MSE 602.815085488805 Test RE 0.47011005235062875\n",
      "6 Train Loss 2.7964563 Test MSE 21.281083644319487 Test RE 0.08832921100144682\n",
      "7 Train Loss 0.18407193 Test MSE 2.395543461431503 Test RE 0.02963531235416711\n",
      "8 Train Loss 0.031692218 Test MSE 0.045140228417829664 Test RE 0.004068078811267405\n",
      "9 Train Loss 0.015334127 Test MSE 0.022498221848046857 Test RE 0.0028719811110435927\n",
      "10 Train Loss 0.009291131 Test MSE 0.011167853797583121 Test RE 0.0020234493680334415\n",
      "11 Train Loss 0.006093836 Test MSE 0.011819991004394296 Test RE 0.002081689994429554\n",
      "12 Train Loss 0.0027405578 Test MSE 0.007190593647400539 Test RE 0.001623640422792973\n",
      "13 Train Loss 0.0022938594 Test MSE 0.0011361310872284687 Test RE 0.0006453892146186524\n",
      "14 Train Loss 0.0014161322 Test MSE 0.002378611140952242 Test RE 0.0009338329764993553\n",
      "15 Train Loss 0.0010475259 Test MSE 0.0005535913239149183 Test RE 0.0004505075973624214\n",
      "16 Train Loss 0.00075408246 Test MSE 0.00028357481440397956 Test RE 0.00032243435564970887\n",
      "17 Train Loss 0.00022585467 Test MSE 0.0001684463598497961 Test RE 0.000248506811378672\n",
      "18 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "19 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "20 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "21 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "22 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "23 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "24 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "25 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "26 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "27 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "28 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "29 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "30 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "31 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "32 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "33 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "34 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "35 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "36 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "37 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "38 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "39 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "40 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "41 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "42 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "43 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "44 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "45 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "46 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "47 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "48 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "49 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "50 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "51 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "52 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "53 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "54 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "55 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "56 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "57 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "58 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "59 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "60 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "61 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "62 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "63 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "64 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "65 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "66 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "67 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "68 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "69 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "70 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "71 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "72 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "73 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "74 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "75 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "76 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "77 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "78 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "79 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "80 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "81 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "82 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "83 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "84 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "85 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "86 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "87 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "88 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "89 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "90 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "91 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "92 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "93 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "94 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "95 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "96 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "97 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "98 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "99 Train Loss 0.00015664446 Test MSE 2.230442839315394e-05 Test RE 9.04280218757291e-05\n",
      "Training time: 8.55\n",
      "Training time: 8.55\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 58.960083 Test MSE 2023.9784002164163 Test RE 0.8614110103173237\n",
      "1 Train Loss 31.788551 Test MSE 999.6394979069086 Test RE 0.6053815564814903\n",
      "2 Train Loss 15.513651 Test MSE 454.3482280622203 Test RE 0.4081331781849683\n",
      "3 Train Loss 0.25738847 Test MSE 2.5405843792469835 Test RE 0.030519280692289496\n",
      "4 Train Loss 0.05071184 Test MSE 0.08718163248365103 Test RE 0.005653533634563214\n",
      "5 Train Loss 0.016001249 Test MSE 0.013787494252166615 Test RE 0.0022482787411539687\n",
      "6 Train Loss 0.0068088877 Test MSE 0.008005100311994334 Test RE 0.0017131321717860574\n",
      "7 Train Loss 0.004810823 Test MSE 0.008581104374808546 Test RE 0.0017736955401418339\n",
      "8 Train Loss 0.0019953346 Test MSE 0.001018602770985629 Test RE 0.0006110966577080707\n",
      "9 Train Loss 0.00084445946 Test MSE 0.0004509254073519533 Test RE 0.0004065929414581779\n",
      "10 Train Loss 0.00043440645 Test MSE 0.0005324690821523555 Test RE 0.0004418294696105173\n",
      "11 Train Loss 0.00033099102 Test MSE 9.581336324659961e-05 Test RE 0.00018742198115973387\n",
      "12 Train Loss 0.00032001032 Test MSE 0.00014872842089765456 Test RE 0.0002335094523201594\n",
      "13 Train Loss 0.00031917955 Test MSE 0.00014649904923684794 Test RE 0.00023175274393891072\n",
      "14 Train Loss 0.00031823784 Test MSE 0.0001416919054622343 Test RE 0.00022791872257383992\n",
      "15 Train Loss 0.00028413848 Test MSE 0.00015277436466761625 Test RE 0.00023666428578271526\n",
      "16 Train Loss 0.00023296253 Test MSE 0.00011167802691041888 Test RE 0.00020234447381547405\n",
      "17 Train Loss 0.00020946596 Test MSE 5.5464065116720985e-05 Test RE 0.00014259796582869188\n",
      "18 Train Loss 0.00020896061 Test MSE 5.516741451588521e-05 Test RE 0.0001422161105961137\n",
      "19 Train Loss 0.00020845403 Test MSE 5.470417958082022e-05 Test RE 0.00014161776508034922\n",
      "20 Train Loss 0.00020749023 Test MSE 5.232220456050392e-05 Test RE 0.000138500231394322\n",
      "21 Train Loss 0.0001571792 Test MSE 4.021017666818231e-05 Test RE 0.00012141587455012423\n",
      "22 Train Loss 0.00012832988 Test MSE 5.209370392649466e-05 Test RE 0.00013819747256477128\n",
      "23 Train Loss 0.000106809166 Test MSE 6.346378795652355e-05 Test RE 0.00015253534086576154\n",
      "24 Train Loss 0.000106159176 Test MSE 6.112217432986017e-05 Test RE 0.0001496948568808351\n",
      "25 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "26 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "27 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "28 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "29 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "30 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "31 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "32 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "33 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "34 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "35 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "36 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "37 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "38 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "39 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "40 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "41 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "42 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "43 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "44 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "45 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "46 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "47 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "48 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "49 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "50 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "51 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "52 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "53 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "54 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "55 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "56 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "57 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "58 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "59 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "60 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "61 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "62 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "63 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "64 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "65 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "66 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "67 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "68 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "69 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "70 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "71 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "72 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "73 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "74 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "75 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "76 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "77 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "78 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "79 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "80 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "81 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "82 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "83 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "84 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "85 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "86 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "87 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "88 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "89 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "90 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "91 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "92 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "93 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "94 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "95 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "96 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "97 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "98 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "99 Train Loss 0.00010571339 Test MSE 6.151741741817351e-05 Test RE 0.0001501780736350189\n",
      "Training time: 8.40\n",
      "Training time: 8.40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 63.227444 Test MSE 2293.9308437392997 Test RE 0.9170597703888895\n",
      "1 Train Loss 38.07269 Test MSE 1260.9117560826078 Test RE 0.6799074950771195\n",
      "2 Train Loss 34.402077 Test MSE 1182.708438612523 Test RE 0.6584856719318534\n",
      "3 Train Loss 32.149487 Test MSE 1114.4734988668195 Test RE 0.6392082251102101\n",
      "4 Train Loss 30.197643 Test MSE 1056.6393928727 Test RE 0.6224018582744469\n",
      "5 Train Loss 27.435478 Test MSE 958.7676078561275 Test RE 0.592876393221484\n",
      "6 Train Loss 14.121382 Test MSE 429.45595612707046 Test RE 0.39679555364726493\n",
      "7 Train Loss 4.886887 Test MSE 128.46894087222447 Test RE 0.2170233952817756\n",
      "8 Train Loss 0.3808066 Test MSE 0.2601463825123217 Test RE 0.009765992296174501\n",
      "9 Train Loss 0.110778295 Test MSE 0.3636335331431058 Test RE 0.011546209801310738\n",
      "10 Train Loss 0.08757942 Test MSE 0.054847473566324155 Test RE 0.004484208479032706\n",
      "11 Train Loss 0.058662735 Test MSE 0.024853875287497783 Test RE 0.0030185928511009146\n",
      "12 Train Loss 0.012315418 Test MSE 0.004065192379026138 Test RE 0.0012208098737757985\n",
      "13 Train Loss 0.0066761817 Test MSE 0.008301063721341756 Test RE 0.001744513584340842\n",
      "14 Train Loss 0.0020980365 Test MSE 0.0012271933816224976 Test RE 0.0006707551008199705\n",
      "15 Train Loss 0.0011002418 Test MSE 0.0005617040792429086 Test RE 0.00045379663451058325\n",
      "16 Train Loss 0.00085694593 Test MSE 0.00020982914038287582 Test RE 0.00027735779914369994\n",
      "17 Train Loss 0.00055216637 Test MSE 0.00016632518685116406 Test RE 0.00024693718429354947\n",
      "18 Train Loss 0.0005238735 Test MSE 0.00012442532515465082 Test RE 0.0002135806352778189\n",
      "19 Train Loss 0.00047188756 Test MSE 0.0002008020040009562 Test RE 0.00027132605674751734\n",
      "20 Train Loss 0.0003654763 Test MSE 0.00014632934940163209 Test RE 0.00023161847754450145\n",
      "21 Train Loss 0.00020561612 Test MSE 4.241708367899929e-05 Test RE 0.00012470328233449518\n",
      "22 Train Loss 0.000171365 Test MSE 4.621194246027651e-05 Test RE 0.00013016211407608543\n",
      "23 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "24 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "25 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "26 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "27 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "28 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "29 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "30 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "31 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "32 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "33 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "34 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "35 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "36 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "37 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "38 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "39 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "40 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "41 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "42 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "43 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "44 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "45 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "46 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "47 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "48 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "49 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "50 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "51 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "52 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "53 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "54 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "55 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "56 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "57 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "58 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "59 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "60 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "61 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "62 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "63 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "64 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "65 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "66 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "67 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "68 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "69 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "70 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "71 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "72 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "73 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "74 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "75 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "76 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "77 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "78 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "79 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "80 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "81 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "82 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "83 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "84 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "85 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "86 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "87 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "88 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "89 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "90 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "91 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "92 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "93 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "94 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "95 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "96 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "97 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "98 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "99 Train Loss 0.00016186158 Test MSE 2.9061355791996974e-05 Test RE 0.00010322037143077614\n",
      "Training time: 9.94\n",
      "Training time: 9.94\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 41.240334 Test MSE 1419.9788450869876 Test RE 0.7215200747758506\n",
      "1 Train Loss 32.9291 Test MSE 1180.9694364854186 Test RE 0.6580013897598819\n",
      "2 Train Loss 23.556849 Test MSE 476.67775265902367 Test RE 0.41804200628728905\n",
      "3 Train Loss 5.0678577 Test MSE 40.553993819458626 Test RE 0.12193385293480287\n",
      "4 Train Loss 0.92262036 Test MSE 6.602201055795666 Test RE 0.049198499178648894\n",
      "5 Train Loss 0.036962345 Test MSE 0.062020687648435206 Test RE 0.0047684339386408125\n",
      "6 Train Loss 0.014945342 Test MSE 0.01931387985393792 Test RE 0.0026609838853118325\n",
      "7 Train Loss 0.0041856393 Test MSE 0.0026887340858059994 Test RE 0.0009928448975685495\n",
      "8 Train Loss 0.0026927877 Test MSE 0.0031399388440954217 Test RE 0.001072921817296908\n",
      "9 Train Loss 0.0023878114 Test MSE 0.002701366943583354 Test RE 0.0009951745757709389\n",
      "10 Train Loss 0.0019297284 Test MSE 0.0022739528822812534 Test RE 0.0009130576774207514\n",
      "11 Train Loss 0.0013426709 Test MSE 0.0028702199527424993 Test RE 0.001025805613614937\n",
      "12 Train Loss 0.0010570372 Test MSE 0.0005030470913378298 Test RE 0.00042944920478233306\n",
      "13 Train Loss 0.0008222954 Test MSE 0.0003989567940961115 Test RE 0.0003824462566641053\n",
      "14 Train Loss 0.00082147407 Test MSE 0.0004036085634876217 Test RE 0.00038466942464874545\n",
      "15 Train Loss 0.0008208496 Test MSE 0.00040714704886174056 Test RE 0.0003863519667534547\n",
      "16 Train Loss 0.0008201769 Test MSE 0.00041130206236041767 Test RE 0.0003883183604864223\n",
      "17 Train Loss 0.0007272733 Test MSE 0.0005670372801556437 Test RE 0.0004559458720685928\n",
      "18 Train Loss 0.00067602424 Test MSE 0.0006094626571496849 Test RE 0.000472695025749393\n",
      "19 Train Loss 0.00067542435 Test MSE 0.0005968162786944798 Test RE 0.0004677650957456289\n",
      "20 Train Loss 0.0006747439 Test MSE 0.0005816356594836325 Test RE 0.00046177774028915324\n",
      "21 Train Loss 0.00067396817 Test MSE 0.0005677863004391407 Test RE 0.0004562469104778591\n",
      "22 Train Loss 0.0006730135 Test MSE 0.0005519729759561528 Test RE 0.0004498486169565201\n",
      "23 Train Loss 0.00032971113 Test MSE 0.00023396622473390423 Test RE 0.00029287618949514583\n",
      "24 Train Loss 0.00019180802 Test MSE 0.00015848004268932518 Test RE 0.00024104313745047158\n",
      "25 Train Loss 0.00019093545 Test MSE 0.00015109229637336644 Test RE 0.0002353578253979777\n",
      "26 Train Loss 0.000190299 Test MSE 0.00013951782546180576 Test RE 0.0002261634034786593\n",
      "27 Train Loss 0.00018962547 Test MSE 0.0001270572227051519 Test RE 0.00021582768914762517\n",
      "28 Train Loss 0.00018867206 Test MSE 0.00011449321215846906 Test RE 0.0002048789556601999\n",
      "29 Train Loss 0.0001879619 Test MSE 0.00011103424406381088 Test RE 0.00020176041004839497\n",
      "30 Train Loss 0.00016850723 Test MSE 6.487376405230699e-05 Test RE 0.00015422047280900576\n",
      "31 Train Loss 0.000141239 Test MSE 4.493790652864821e-05 Test RE 0.00012835532776957095\n",
      "32 Train Loss 0.00012212836 Test MSE 2.6250914831199646e-05 Test RE 9.810241605273e-05\n",
      "33 Train Loss 0.000121245386 Test MSE 2.4958621738147725e-05 Test RE 9.565722575567926e-05\n",
      "34 Train Loss 0.000120544915 Test MSE 2.4325985455778688e-05 Test RE 9.443711325901908e-05\n",
      "35 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "36 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "37 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "38 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "39 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "40 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "41 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "42 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "43 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "44 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "45 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "46 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "47 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "48 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "49 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "50 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "51 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "52 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "53 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "54 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "55 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "56 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "57 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "58 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "59 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "60 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "61 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "62 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "63 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "64 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "65 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "66 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "67 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "68 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "69 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "70 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "71 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "72 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "73 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "74 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "75 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "76 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "77 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "78 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "79 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "80 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "81 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "82 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "83 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "84 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "85 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "86 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "87 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "88 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "89 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "90 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "91 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "92 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "93 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "94 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "95 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "96 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "97 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "98 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "99 Train Loss 0.000120272445 Test MSE 2.514791204639828e-05 Test RE 9.601928067844852e-05\n",
      "Training time: 9.32\n",
      "Training time: 9.32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 62.463215 Test MSE 2285.2029243482493 Test RE 0.9153134989842412\n",
      "1 Train Loss 36.248547 Test MSE 1268.8157234334003 Test RE 0.6820351504397477\n",
      "2 Train Loss 30.009863 Test MSE 1036.6376786590636 Test RE 0.6164828179303431\n",
      "3 Train Loss 27.094967 Test MSE 884.1734523938278 Test RE 0.5693459258376642\n",
      "4 Train Loss 15.810623 Test MSE 480.97907082161635 Test RE 0.4199238787759923\n",
      "5 Train Loss 3.7006466 Test MSE 25.354961988158912 Test RE 0.09641374748314877\n",
      "6 Train Loss 1.5336586 Test MSE 12.597418333016925 Test RE 0.06795919996195438\n",
      "7 Train Loss 0.24545154 Test MSE 1.0489955734877718 Test RE 0.01961075479924663\n",
      "8 Train Loss 0.041475423 Test MSE 0.1401699371209848 Test RE 0.0071686094603288855\n",
      "9 Train Loss 0.010518042 Test MSE 0.030085571283981847 Test RE 0.0033211356391309966\n",
      "10 Train Loss 0.004957579 Test MSE 0.0023365071284200648 Test RE 0.0009255311432913126\n",
      "11 Train Loss 0.0030498402 Test MSE 0.004968726100466955 Test RE 0.0013496775072489326\n",
      "12 Train Loss 0.0022135784 Test MSE 0.003561698252106909 Test RE 0.0011427100405108654\n",
      "13 Train Loss 0.0018834651 Test MSE 0.0037379653852850454 Test RE 0.001170644743741795\n",
      "14 Train Loss 0.0014111995 Test MSE 0.0009156393504638382 Test RE 0.0005793882801901351\n",
      "15 Train Loss 0.0012584585 Test MSE 0.0005358959541263498 Test RE 0.00044324895552984707\n",
      "16 Train Loss 0.00086319685 Test MSE 0.0010371339379004736 Test RE 0.0006166303616171524\n",
      "17 Train Loss 0.0007641464 Test MSE 0.0006667162132501788 Test RE 0.000494399462595017\n",
      "18 Train Loss 0.00072141475 Test MSE 0.0004884320734251453 Test RE 0.0004231648334831211\n",
      "19 Train Loss 0.0007150397 Test MSE 0.00046598240792073965 Test RE 0.0004133255405519408\n",
      "20 Train Loss 0.0007143197 Test MSE 0.0004457362061383382 Test RE 0.0004042466577542092\n",
      "21 Train Loss 0.00071353023 Test MSE 0.00042810603932090643 Test RE 0.0003961714354295268\n",
      "22 Train Loss 0.0006843213 Test MSE 0.000777184236030417 Test RE 0.0005337888198517552\n",
      "23 Train Loss 0.00066309125 Test MSE 0.0006558336930555397 Test RE 0.0004903479274843918\n",
      "24 Train Loss 0.000662394 Test MSE 0.0006260324625481844 Test RE 0.0004790776479702809\n",
      "25 Train Loss 0.0006616452 Test MSE 0.0006114825273087984 Test RE 0.0004734776764935041\n",
      "26 Train Loss 0.00066071004 Test MSE 0.0005892542309723847 Test RE 0.00046479220567423844\n",
      "27 Train Loss 0.00065975747 Test MSE 0.0005906328214511669 Test RE 0.0004653355906359774\n",
      "28 Train Loss 0.000586807 Test MSE 0.0008538257731871788 Test RE 0.0005594897207197196\n",
      "29 Train Loss 0.0005490676 Test MSE 0.00046707087535515467 Test RE 0.00041380799328960213\n",
      "30 Train Loss 0.000548308 Test MSE 0.0004488257979689344 Test RE 0.00040564524323594343\n",
      "31 Train Loss 0.00054766244 Test MSE 0.00044241481835487136 Test RE 0.00040273772663045596\n",
      "32 Train Loss 0.00047652688 Test MSE 0.00029822086854800655 Test RE 0.000330656068092804\n",
      "33 Train Loss 0.0004716505 Test MSE 0.0003131911239955629 Test RE 0.00033885367843110997\n",
      "34 Train Loss 0.00047149544 Test MSE 0.00030314147048958863 Test RE 0.00033337279659468395\n",
      "35 Train Loss 0.0004709785 Test MSE 0.0003173684664449727 Test RE 0.00034110600768733225\n",
      "36 Train Loss 0.00047037142 Test MSE 0.0003367810646701506 Test RE 0.0003513834596966894\n",
      "37 Train Loss 0.00046967005 Test MSE 0.00035377699980281257 Test RE 0.00036014076195311427\n",
      "38 Train Loss 0.00046771675 Test MSE 0.00038019867315398643 Test RE 0.0003733470982513152\n",
      "39 Train Loss 0.0003743655 Test MSE 0.00018591696283344565 Test RE 0.0002610760238402557\n",
      "40 Train Loss 0.00021887223 Test MSE 0.00010670947709382012 Test RE 0.00019779211647358983\n",
      "41 Train Loss 0.00012011007 Test MSE 4.1053955855274483e-05 Test RE 0.0001226831694693968\n",
      "42 Train Loss 0.000100150595 Test MSE 2.2255127523172102e-05 Test RE 9.032802723911552e-05\n",
      "43 Train Loss 9.1686976e-05 Test MSE 1.6368855121715055e-05 Test RE 7.746698153295999e-05\n",
      "44 Train Loss 8.923934e-05 Test MSE 1.8997179636672627e-05 Test RE 8.345493947186164e-05\n",
      "45 Train Loss 8.369227e-05 Test MSE 2.0929567203213873e-05 Test RE 8.759667180593997e-05\n",
      "46 Train Loss 8.292816e-05 Test MSE 2.1124708144531305e-05 Test RE 8.800408676550924e-05\n",
      "47 Train Loss 8.282456e-05 Test MSE 1.6296267083289358e-05 Test RE 7.729502619231137e-05\n",
      "48 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "49 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "50 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "51 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "52 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "53 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "54 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "55 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "56 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "57 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "58 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "59 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "60 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "61 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "62 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "63 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "64 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "65 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "66 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "67 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "68 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "69 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "70 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "71 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "72 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "73 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "74 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "75 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "76 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "77 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "78 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "79 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "80 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "81 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "82 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "83 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "84 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "85 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "86 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "87 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "88 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "89 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "90 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "91 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "92 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "93 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "94 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "95 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "96 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "97 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "98 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "99 Train Loss 8.2309234e-05 Test MSE 1.7479691933305703e-05 Test RE 8.00524022390279e-05\n",
      "Training time: 11.63\n",
      "Training time: 11.63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 44.46914 Test MSE 1523.7954468586202 Test RE 0.7474305028549013\n",
      "1 Train Loss 34.705112 Test MSE 1267.4222839103586 Test RE 0.6816605350441401\n",
      "2 Train Loss 32.786842 Test MSE 1147.4761071212372 Test RE 0.648603529243397\n",
      "3 Train Loss 25.315184 Test MSE 713.4884268746531 Test RE 0.5114473683641511\n",
      "4 Train Loss 18.076275 Test MSE 346.38643917114257 Test RE 0.3563591566140369\n",
      "5 Train Loss 1.9540863 Test MSE 3.3777410612540932 Test RE 0.03519011276048611\n",
      "6 Train Loss 0.29239622 Test MSE 2.652322365770157 Test RE 0.031183196795573007\n",
      "7 Train Loss 0.13073997 Test MSE 0.04195327199094575 Test RE 0.0039218447763345035\n",
      "8 Train Loss 0.09178676 Test MSE 0.17854606239792056 Test RE 0.008090635210421023\n",
      "9 Train Loss 0.06982986 Test MSE 0.033900775727197706 Test RE 0.0035254316551898758\n",
      "10 Train Loss 0.03967873 Test MSE 0.011836935867268026 Test RE 0.002083181591105198\n",
      "11 Train Loss 0.034711678 Test MSE 0.0047085174767650855 Test RE 0.0013138614650115667\n",
      "12 Train Loss 0.018716509 Test MSE 0.0037601083128466213 Test RE 0.0011741069516521695\n",
      "13 Train Loss 0.013312771 Test MSE 0.0060025159151965496 Test RE 0.0014834541979322812\n",
      "14 Train Loss 0.0070050447 Test MSE 0.0011510736172868157 Test RE 0.0006496194683900958\n",
      "15 Train Loss 0.006038929 Test MSE 0.0036054853843837877 Test RE 0.0011497127602799542\n",
      "16 Train Loss 0.0024514315 Test MSE 0.0008365984661476657 Test RE 0.0005538166570112524\n",
      "17 Train Loss 0.0021519563 Test MSE 0.0006462403363889998 Test RE 0.00048674837770698804\n",
      "18 Train Loss 0.0010953662 Test MSE 0.0004680266956523397 Test RE 0.0004142311880917805\n",
      "19 Train Loss 0.0009473324 Test MSE 0.00016702172198520776 Test RE 0.00024745370475755474\n",
      "20 Train Loss 0.00044658734 Test MSE 7.026965670382663e-05 Test RE 0.00016050604654969155\n",
      "21 Train Loss 0.0004196633 Test MSE 6.26800689118715e-05 Test RE 0.0001515905799311436\n",
      "22 Train Loss 0.00026154675 Test MSE 3.8375493665754425e-05 Test RE 0.00011861359514292864\n",
      "23 Train Loss 0.0002607165 Test MSE 3.503658493530675e-05 Test RE 0.00011333612657383949\n",
      "24 Train Loss 0.0002589891 Test MSE 3.770737860945288e-05 Test RE 0.00011757653372030284\n",
      "25 Train Loss 0.00025847222 Test MSE 4.326388174152353e-05 Test RE 0.0001259418948577538\n",
      "26 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "27 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "28 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "29 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "30 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "31 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "32 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "33 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "34 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "35 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "36 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "37 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "38 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "39 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "40 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "41 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "42 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "43 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "44 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "45 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "46 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "47 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "48 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "49 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "50 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "51 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "52 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "53 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "54 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "55 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "56 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "57 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "58 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "59 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "60 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "61 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "62 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "63 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "64 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "65 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "66 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "67 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "68 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "69 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "70 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "71 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "72 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "73 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "74 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "75 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "76 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "77 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "78 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "79 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "80 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "81 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "82 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "83 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "84 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "85 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "86 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "87 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "88 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "89 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "90 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "91 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "92 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "93 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "94 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "95 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "96 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "97 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "98 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "99 Train Loss 0.0002580507 Test MSE 5.0980871599501154e-05 Test RE 0.00013671340809527923\n",
      "Training time: 9.66\n",
      "Training time: 9.66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.314007 Test MSE 2091.8842436109776 Test RE 0.8757422570671808\n",
      "1 Train Loss 36.966694 Test MSE 1259.3771753176113 Test RE 0.6794936316132328\n",
      "2 Train Loss 30.084143 Test MSE 998.5613476711018 Test RE 0.6050550045831635\n",
      "3 Train Loss 25.631039 Test MSE 874.8305960227523 Test RE 0.5663298638133741\n",
      "4 Train Loss 22.846645 Test MSE 723.5183828198348 Test RE 0.5150296913611785\n",
      "5 Train Loss 10.734376 Test MSE 303.67841797813105 Test RE 0.3336679137382415\n",
      "6 Train Loss 1.1129589 Test MSE 6.102528449826059 Test RE 0.047300135860064124\n",
      "7 Train Loss 0.09489336 Test MSE 0.24984338476735962 Test RE 0.00957064944721651\n",
      "8 Train Loss 0.026739646 Test MSE 0.046739652675934884 Test RE 0.004139522258681164\n",
      "9 Train Loss 0.015862571 Test MSE 0.07183270955851122 Test RE 0.0051317868084173445\n",
      "10 Train Loss 0.009670274 Test MSE 0.024749877948644472 Test RE 0.0030122708046881794\n",
      "11 Train Loss 0.00464086 Test MSE 0.0014134324386635144 Test RE 0.0007198549724459733\n",
      "12 Train Loss 0.0042155357 Test MSE 0.0035434898837051086 Test RE 0.001139785375825173\n",
      "13 Train Loss 0.0031271325 Test MSE 0.0010081260874120913 Test RE 0.0006079458642432535\n",
      "14 Train Loss 0.0020860233 Test MSE 0.0034315179514391473 Test RE 0.0011216325893869824\n",
      "15 Train Loss 0.0020059433 Test MSE 0.002123038975030762 Test RE 0.0008822394330123825\n",
      "16 Train Loss 0.0016024195 Test MSE 0.0012128084843640349 Test RE 0.0006668122889447988\n",
      "17 Train Loss 0.0012198504 Test MSE 0.000685758838883703 Test RE 0.0005014102281587648\n",
      "18 Train Loss 0.0010132956 Test MSE 0.0003738396766465009 Test RE 0.0003702117324701254\n",
      "19 Train Loss 0.00061217253 Test MSE 0.00045483808628233896 Test RE 0.0004083531345099833\n",
      "20 Train Loss 0.00055293576 Test MSE 0.00030689015895283753 Test RE 0.0003354277297861437\n",
      "21 Train Loss 0.00055245135 Test MSE 0.0002905429763557428 Test RE 0.0003263718343253168\n",
      "22 Train Loss 0.0005516278 Test MSE 0.0002943632933986292 Test RE 0.00032851054022502553\n",
      "23 Train Loss 0.0005509077 Test MSE 0.00030209519328825183 Test RE 0.00033279698978871887\n",
      "24 Train Loss 0.000472338 Test MSE 0.0003409960046045544 Test RE 0.00035357546972988093\n",
      "25 Train Loss 0.00039819843 Test MSE 0.0003516152973252123 Test RE 0.0003590387823460299\n",
      "26 Train Loss 0.00036576524 Test MSE 0.00045544065977597283 Test RE 0.0004086235398912872\n",
      "27 Train Loss 0.00035372627 Test MSE 0.0004084083527214201 Test RE 0.0003869499453013938\n",
      "28 Train Loss 0.00035315202 Test MSE 0.0004178087916985068 Test RE 0.0003913778732465819\n",
      "29 Train Loss 0.00033174705 Test MSE 0.0004137670736775614 Test RE 0.00038948025503829684\n",
      "30 Train Loss 0.00032697985 Test MSE 0.0003032654990170429 Test RE 0.00033344098836758467\n",
      "31 Train Loss 0.0003239604 Test MSE 0.00021825343607112516 Test RE 0.00028287074004171975\n",
      "32 Train Loss 0.00032306204 Test MSE 0.00021753949794313724 Test RE 0.00028240770579460644\n",
      "33 Train Loss 0.0002737826 Test MSE 0.00018075723671065203 Test RE 0.000257427730857172\n",
      "34 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "35 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "36 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "37 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "38 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "39 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "40 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "41 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "42 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "43 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "44 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "45 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "46 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "47 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "48 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "49 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "50 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "51 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "52 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "53 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "54 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "55 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "56 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "57 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "58 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "59 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "60 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "61 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "62 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "63 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "64 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "65 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "66 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "67 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "68 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "69 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "70 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "71 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "72 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "73 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "74 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "75 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "76 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "77 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "78 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "79 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "80 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "81 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "82 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "83 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "84 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "85 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "86 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "87 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "88 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "89 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "90 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "91 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "92 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "93 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "94 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "95 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "96 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "97 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "98 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "99 Train Loss 0.00027257056 Test MSE 0.0001877271133425961 Test RE 0.00026234390746923735\n",
      "Training time: 10.94\n",
      "Training time: 10.94\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 41.25305 Test MSE 1337.4437262525628 Test RE 0.7002372997175051\n",
      "1 Train Loss 33.056705 Test MSE 1193.2491779250306 Test RE 0.6614134980492478\n",
      "2 Train Loss 29.248167 Test MSE 982.4719633856771 Test RE 0.6001607156926154\n",
      "3 Train Loss 19.373796 Test MSE 565.6798834661704 Test RE 0.4553998142787653\n",
      "4 Train Loss 4.036708 Test MSE 27.529018864496464 Test RE 0.10046223794368467\n",
      "5 Train Loss 0.72960275 Test MSE 15.194182820326498 Test RE 0.07463562184538913\n",
      "6 Train Loss 0.18610734 Test MSE 1.0341513934153599 Test RE 0.019471505987054768\n",
      "7 Train Loss 0.012717391 Test MSE 0.02068061736477998 Test RE 0.0027535263157804704\n",
      "8 Train Loss 0.008614151 Test MSE 0.01614029119951087 Test RE 0.0024325577798242435\n",
      "9 Train Loss 0.0053620194 Test MSE 0.010879982884494151 Test RE 0.0019972001401726766\n",
      "10 Train Loss 0.0038440905 Test MSE 0.004192177383851034 Test RE 0.0012397305605915117\n",
      "11 Train Loss 0.0028983909 Test MSE 0.010051771529979709 Test RE 0.0019196797609933888\n",
      "12 Train Loss 0.0022483135 Test MSE 0.0022572195977462526 Test RE 0.0009096920260855287\n",
      "13 Train Loss 0.0011439179 Test MSE 0.0008614476736587327 Test RE 0.0005619813885604476\n",
      "14 Train Loss 0.0010242679 Test MSE 0.00037453032303600315 Test RE 0.00037055354666273795\n",
      "15 Train Loss 0.00086984254 Test MSE 0.00043672937293459067 Test RE 0.00040014158014453155\n",
      "16 Train Loss 0.00065884786 Test MSE 0.00022769955660944423 Test RE 0.0002889272967341849\n",
      "17 Train Loss 0.00065231655 Test MSE 0.0002355378148732366 Test RE 0.00029385819228320973\n",
      "18 Train Loss 0.00054714043 Test MSE 0.0003365148240730487 Test RE 0.00035124454001173125\n",
      "19 Train Loss 0.00051170186 Test MSE 0.0003041227228442482 Test RE 0.00033391191542425484\n",
      "20 Train Loss 0.00051077077 Test MSE 0.0002962076179537723 Test RE 0.00032953806981190185\n",
      "21 Train Loss 0.0005091385 Test MSE 0.0002603715162608335 Test RE 0.0003089613953841961\n",
      "22 Train Loss 0.00045654093 Test MSE 0.0005072489770144625 Test RE 0.0004312390411310108\n",
      "23 Train Loss 0.0003481853 Test MSE 0.00011263546322646028 Test RE 0.00020320999095623248\n",
      "24 Train Loss 0.00034387066 Test MSE 0.0001052767573036082 Test RE 0.00019645981535237626\n",
      "25 Train Loss 0.0003418653 Test MSE 0.00010724619413050866 Test RE 0.00019828891043158437\n",
      "26 Train Loss 0.0003203095 Test MSE 0.00012668554926648638 Test RE 0.0002155117835756057\n",
      "27 Train Loss 0.00031728853 Test MSE 0.00013140965965278156 Test RE 0.00021949322874752935\n",
      "28 Train Loss 0.00028117234 Test MSE 8.330616295286212e-05 Test RE 0.00017476161423304122\n",
      "29 Train Loss 0.00023788933 Test MSE 0.00011556455636968496 Test RE 0.00020583527785909952\n",
      "30 Train Loss 0.00022213711 Test MSE 7.801181602942964e-05 Test RE 0.00016911715955698678\n",
      "31 Train Loss 0.00022176732 Test MSE 7.468289735659447e-05 Test RE 0.00016546954050683898\n",
      "32 Train Loss 0.00022126077 Test MSE 7.304618518293224e-05 Test RE 0.00016364632309328502\n",
      "33 Train Loss 0.00022074486 Test MSE 7.177770936199979e-05 Test RE 0.00016221920888177842\n",
      "34 Train Loss 0.00022016067 Test MSE 6.986078899405695e-05 Test RE 0.00016003840885807144\n",
      "35 Train Loss 0.00021954894 Test MSE 6.823965249751078e-05 Test RE 0.0001581706447964809\n",
      "36 Train Loss 0.00021937939 Test MSE 7.320155696736148e-05 Test RE 0.00016382027136328909\n",
      "37 Train Loss 0.000218617 Test MSE 6.912413071685665e-05 Test RE 0.00015919239740627187\n",
      "38 Train Loss 0.00021784425 Test MSE 6.951679014296308e-05 Test RE 0.00015964390309831426\n",
      "39 Train Loss 0.00021583933 Test MSE 7.247793440472496e-05 Test RE 0.00016300855048818235\n",
      "40 Train Loss 0.00021498647 Test MSE 7.387362480859476e-05 Test RE 0.0001645705749720563\n",
      "41 Train Loss 0.00021426314 Test MSE 7.484770027398841e-05 Test RE 0.00016565201090126084\n",
      "42 Train Loss 0.00021338397 Test MSE 7.648012471252138e-05 Test RE 0.00016744869818567266\n",
      "43 Train Loss 0.00021243528 Test MSE 7.676799415479528e-05 Test RE 0.0001677635387381207\n",
      "44 Train Loss 0.00021169234 Test MSE 7.764987395810032e-05 Test RE 0.00016872438714625438\n",
      "45 Train Loss 0.00021161007 Test MSE 7.174171960224649e-05 Test RE 0.00016217853495653685\n",
      "46 Train Loss 0.00021107643 Test MSE 7.0463714102908e-05 Test RE 0.00016072752131417612\n",
      "47 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "48 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "49 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "50 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "51 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "52 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "53 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "54 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "55 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "56 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "57 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "58 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "59 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "60 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "61 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "62 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "63 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "64 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "65 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "66 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "67 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "68 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "69 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "70 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "71 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "72 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "73 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "74 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "75 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "76 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "77 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "78 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "79 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "80 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "81 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "82 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "83 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "84 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "85 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "86 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "87 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "88 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "89 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "90 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "91 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "92 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "93 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "94 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "95 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "96 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "97 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "98 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "99 Train Loss 0.00021053116 Test MSE 7.383472568718817e-05 Test RE 0.00016452724087458572\n",
      "Training time: 10.64\n",
      "Training time: 10.64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 66.37797 Test MSE 2450.622975042372 Test RE 0.9478633521244529\n",
      "1 Train Loss 39.4586 Test MSE 1118.3482723782465 Test RE 0.6403184525081445\n",
      "2 Train Loss 21.486294 Test MSE 690.7939641620544 Test RE 0.5032476422952411\n",
      "3 Train Loss 9.23906 Test MSE 260.30859793035177 Test RE 0.3089240631330103\n",
      "4 Train Loss 4.557703 Test MSE 24.096453390857263 Test RE 0.09399051838106576\n",
      "5 Train Loss 0.7143652 Test MSE 2.679677116571588 Test RE 0.03134358839797702\n",
      "6 Train Loss 0.46946934 Test MSE 1.1712648022818049 Test RE 0.020722160256092522\n",
      "7 Train Loss 0.34282485 Test MSE 1.0821555284548088 Test RE 0.019918302467539742\n",
      "8 Train Loss 0.15185702 Test MSE 0.2167052680354931 Test RE 0.008913375778072528\n",
      "9 Train Loss 0.028912505 Test MSE 0.028552111536229427 Test RE 0.003235389692234757\n",
      "10 Train Loss 0.016411131 Test MSE 0.007005934506696361 Test RE 0.0016026567548259008\n",
      "11 Train Loss 0.016144997 Test MSE 0.00622455934111631 Test RE 0.0015106428086106988\n",
      "12 Train Loss 0.009818695 Test MSE 0.008524581310657474 Test RE 0.0017678442918136138\n",
      "13 Train Loss 0.0070068883 Test MSE 0.015427260114960916 Test RE 0.002378219210241284\n",
      "14 Train Loss 0.003990376 Test MSE 0.0019802972746188695 Test RE 0.0008520649026289216\n",
      "15 Train Loss 0.0036160976 Test MSE 0.001925755809589564 Test RE 0.0008402491661115566\n",
      "16 Train Loss 0.0014454018 Test MSE 0.0018777499097523461 Test RE 0.0008297100616229085\n",
      "17 Train Loss 0.001331347 Test MSE 0.0010284551675870887 Test RE 0.0006140449501548337\n",
      "18 Train Loss 0.0013308706 Test MSE 0.0010023015712030496 Test RE 0.000606187096172992\n",
      "19 Train Loss 0.0013304119 Test MSE 0.0009938278288334115 Test RE 0.0006036192182560564\n",
      "20 Train Loss 0.0013296205 Test MSE 0.0009933147589363275 Test RE 0.0006034633870232611\n",
      "21 Train Loss 0.0013278346 Test MSE 0.0009893882289455324 Test RE 0.0006022694737368085\n",
      "22 Train Loss 0.0012533265 Test MSE 0.0011516593028901546 Test RE 0.0006497847160246283\n",
      "23 Train Loss 0.0012046635 Test MSE 0.0012116515766109118 Test RE 0.0006664941742649132\n",
      "24 Train Loss 0.00057907676 Test MSE 0.0005078136499765876 Test RE 0.0004314790034636077\n",
      "25 Train Loss 0.0002867068 Test MSE 0.00022460134169272191 Test RE 0.00028695490648610316\n",
      "26 Train Loss 0.00013295749 Test MSE 0.0001910072681985548 Test RE 0.00026462594896519483\n",
      "27 Train Loss 6.903543e-05 Test MSE 1.5425987918950783e-05 Test RE 7.520279383598012e-05\n",
      "28 Train Loss 6.8389825e-05 Test MSE 1.563374050443147e-05 Test RE 7.570750454882072e-05\n",
      "29 Train Loss 6.791089e-05 Test MSE 1.6331721719305575e-05 Test RE 7.737906317037157e-05\n",
      "30 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "31 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "32 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "33 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "34 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "35 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "36 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "37 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "38 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "39 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "40 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "41 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "42 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "43 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "44 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "45 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "46 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "47 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "48 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "49 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "50 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "51 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "52 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "53 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "54 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "55 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "56 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "57 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "58 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "59 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "60 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "61 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "62 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "63 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "64 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "65 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "66 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "67 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "68 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "69 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "70 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "71 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "72 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "73 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "74 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "75 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "76 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "77 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "78 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "79 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "80 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "81 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "82 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "83 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "84 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "85 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "86 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "87 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "88 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "89 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "90 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "91 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "92 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "93 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "94 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "95 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "96 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "97 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "98 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "99 Train Loss 6.7531924e-05 Test MSE 1.6199716014759238e-05 Test RE 7.706570974355576e-05\n",
      "Training time: 10.81\n",
      "Training time: 10.81\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 51.62614 Test MSE 1574.6892829144808 Test RE 0.7598098470455257\n",
      "1 Train Loss 27.954533 Test MSE 929.3501999660954 Test RE 0.5837100625296421\n",
      "2 Train Loss 18.759125 Test MSE 589.471225452845 Test RE 0.46487777829667615\n",
      "3 Train Loss 7.3853393 Test MSE 139.1867330844032 Test RE 0.22589488776445596\n",
      "4 Train Loss 0.6703559 Test MSE 4.192973007659597 Test RE 0.03920744258002947\n",
      "5 Train Loss 0.1002242 Test MSE 0.17306985172487352 Test RE 0.00796559446934913\n",
      "6 Train Loss 0.025620628 Test MSE 0.018656492184957418 Test RE 0.0026153058006297926\n",
      "7 Train Loss 0.018466217 Test MSE 0.00490148986380029 Test RE 0.001340514562398587\n",
      "8 Train Loss 0.01234052 Test MSE 0.00886722102753804 Test RE 0.0018030229252665568\n",
      "9 Train Loss 0.009579206 Test MSE 0.0044438068847938205 Test RE 0.0012763949301939205\n",
      "10 Train Loss 0.0062126713 Test MSE 0.01822638855224987 Test RE 0.0025849836109492134\n",
      "11 Train Loss 0.004263289 Test MSE 0.0016832175510239572 Test RE 0.0007855568269337719\n",
      "12 Train Loss 0.0032827875 Test MSE 0.0008836570778538956 Test RE 0.0005691796469943722\n",
      "13 Train Loss 0.003072064 Test MSE 0.000814220774752364 Test RE 0.0005463595911434904\n",
      "14 Train Loss 0.002049928 Test MSE 0.0007580110593950139 Test RE 0.0005271634029724857\n",
      "15 Train Loss 0.0017048507 Test MSE 0.000535813466678688 Test RE 0.0004432148408086862\n",
      "16 Train Loss 0.0014394949 Test MSE 0.0003792656983976184 Test RE 0.00037288873609208213\n",
      "17 Train Loss 0.0011123003 Test MSE 0.0003209169874539448 Test RE 0.0003430076729308379\n",
      "18 Train Loss 0.00069366646 Test MSE 0.00023946548780946905 Test RE 0.00029629815503954524\n",
      "19 Train Loss 0.00043306715 Test MSE 0.00025024804932516326 Test RE 0.0003028955076513038\n",
      "20 Train Loss 0.00033743164 Test MSE 0.00010985342895280152 Test RE 0.00020068471245369344\n",
      "21 Train Loss 0.00028057015 Test MSE 0.0001130961027946221 Test RE 0.00020362509580195974\n",
      "22 Train Loss 0.00019741862 Test MSE 6.730614284915274e-05 Test RE 0.0001570850422715143\n",
      "23 Train Loss 8.492355e-05 Test MSE 0.00013245892845970168 Test RE 0.00022036778199722849\n",
      "24 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "25 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "26 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "27 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "28 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "29 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "30 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "31 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "32 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "33 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "34 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "35 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "36 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "37 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "38 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "39 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "40 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "41 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "42 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "43 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "44 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "45 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "46 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "47 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "48 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "49 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "50 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "51 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "52 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "53 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "54 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "55 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "56 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "57 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "58 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "59 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "60 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "61 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "62 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "63 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "64 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "65 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "66 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "67 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "68 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "69 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "70 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "71 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "72 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "73 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "74 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "75 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "76 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "77 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "78 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "79 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "80 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "81 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "82 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "83 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "84 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "85 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "86 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "87 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "88 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "89 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "90 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "91 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "92 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "93 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "94 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "95 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "96 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "97 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "98 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "99 Train Loss 5.170797e-05 Test MSE 1.0522379239833014e-05 Test RE 6.211041869759195e-05\n",
      "Training time: 10.33\n",
      "Training time: 10.33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 56.306454 Test MSE 1855.3745884601974 Test RE 0.8247518223893118\n",
      "1 Train Loss 35.131145 Test MSE 1256.4985359085101 Test RE 0.6787166061865438\n",
      "2 Train Loss 32.956444 Test MSE 1169.7986869164577 Test RE 0.654881989320325\n",
      "3 Train Loss 31.741217 Test MSE 1128.3318682141576 Test RE 0.6431701924861662\n",
      "4 Train Loss 29.832544 Test MSE 1024.8631035651217 Test RE 0.6129716811614658\n",
      "5 Train Loss 25.985394 Test MSE 870.9458823613995 Test RE 0.565071061748176\n",
      "6 Train Loss 22.853075 Test MSE 689.3609479510112 Test RE 0.5027253907566228\n",
      "7 Train Loss 18.171404 Test MSE 367.993411780992 Test RE 0.3673055609490615\n",
      "8 Train Loss 6.2114916 Test MSE 129.91307115840726 Test RE 0.21823977569411374\n",
      "9 Train Loss 0.13844109 Test MSE 0.7236730424027287 Test RE 0.016288409502605496\n",
      "10 Train Loss 0.03525831 Test MSE 0.19997019818983855 Test RE 0.008562293691467748\n",
      "11 Train Loss 0.019999499 Test MSE 0.07386341359335291 Test RE 0.005203818840155265\n",
      "12 Train Loss 0.0042385617 Test MSE 0.01238231128450235 Test RE 0.0021306314860490695\n",
      "13 Train Loss 0.0032623492 Test MSE 0.013960446296589615 Test RE 0.002262336138326992\n",
      "14 Train Loss 0.0024846746 Test MSE 0.006269950367414735 Test RE 0.0015161407941510735\n",
      "15 Train Loss 0.0011008437 Test MSE 0.0008358402710149319 Test RE 0.000553565642760552\n",
      "16 Train Loss 0.0009356218 Test MSE 0.001828942756541365 Test RE 0.0008188560049594247\n",
      "17 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "18 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "19 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "20 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "21 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "22 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "23 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "24 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "25 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "26 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "27 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "28 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "29 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "30 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "31 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "32 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "33 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "34 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "35 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "36 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "37 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "38 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "39 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "40 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "41 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "42 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "43 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "44 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "45 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "46 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "47 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "48 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "49 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "50 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "51 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "52 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "53 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "54 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "55 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "56 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "57 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "58 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "59 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "60 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "61 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "62 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "63 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "64 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "65 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "66 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "67 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "68 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "69 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "70 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "71 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "72 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "73 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "74 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "75 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "76 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "77 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "78 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "79 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "80 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "81 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "82 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "83 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "84 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "85 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "86 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "87 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "88 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "89 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "90 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "91 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "92 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "93 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "94 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "95 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "96 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "97 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "98 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "99 Train Loss 0.00039950167 Test MSE 0.000665932026479874 Test RE 0.0004941086225193392\n",
      "Training time: 8.78\n",
      "Training time: 8.78\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 55.373737 Test MSE 1924.113077544036 Test RE 0.8398907097820497\n",
      "1 Train Loss 24.161556 Test MSE 764.4235780547968 Test RE 0.5293885195066167\n",
      "2 Train Loss 3.101486 Test MSE 13.86403912219353 Test RE 0.0712938994677041\n",
      "3 Train Loss 0.24388228 Test MSE 0.39398639128396745 Test RE 0.01201843979676487\n",
      "4 Train Loss 0.041104753 Test MSE 0.12238083175443626 Test RE 0.006698293637060243\n",
      "5 Train Loss 0.007437014 Test MSE 0.009706138042641178 Test RE 0.0018863866471934534\n",
      "6 Train Loss 0.0026958582 Test MSE 0.004332984422594315 Test RE 0.0012603786724696181\n",
      "7 Train Loss 0.001025412 Test MSE 0.0004932079355077407 Test RE 0.0004252286420948205\n",
      "8 Train Loss 0.00035783777 Test MSE 0.0005924128080677331 Test RE 0.0004660362526869707\n",
      "9 Train Loss 0.0002554539 Test MSE 0.00020286147561859944 Test RE 0.0002727138985944522\n",
      "10 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "11 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "12 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "13 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "14 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "15 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "16 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "17 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "18 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "19 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "20 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "21 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "22 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "23 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "24 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "25 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "26 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "27 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "28 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "29 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "30 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "31 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "32 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "33 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "34 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "35 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "36 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "37 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "38 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "39 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "40 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "41 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "42 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "43 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "44 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "45 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "46 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "47 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "48 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "49 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "50 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "51 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "52 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "53 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "54 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "55 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "56 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "57 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "58 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "59 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "60 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "61 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "62 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "63 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "64 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "65 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "66 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "67 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "68 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "69 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "70 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "71 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "72 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "73 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "74 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "75 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "76 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "77 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "78 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "79 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "80 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "81 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "82 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "83 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "84 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "85 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "86 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "87 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "88 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "89 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "90 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "91 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "92 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "93 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "94 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "95 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "96 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "97 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "98 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "99 Train Loss 0.00019122285 Test MSE 0.00013066470167473815 Test RE 0.00021887019376826876\n",
      "Training time: 6.56\n",
      "Training time: 6.56\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 57.739273 Test MSE 1821.5401705109753 Test RE 0.8171971782874706\n",
      "1 Train Loss 32.8937 Test MSE 1193.359283222891 Test RE 0.6614440128200426\n",
      "2 Train Loss 24.045195 Test MSE 758.8717710729037 Test RE 0.527462611646162\n",
      "3 Train Loss 10.75102 Test MSE 185.09824798066984 Test RE 0.26050054473461487\n",
      "4 Train Loss 0.39248887 Test MSE 0.5338748968815619 Test RE 0.013990306594234251\n",
      "5 Train Loss 0.033980437 Test MSE 0.05642477317044649 Test RE 0.004548229730393597\n",
      "6 Train Loss 0.008120856 Test MSE 0.0035294883409152916 Test RE 0.0011375313056734176\n",
      "7 Train Loss 0.00457933 Test MSE 0.001997776629843065 Test RE 0.0008558170727160783\n",
      "8 Train Loss 0.0026434867 Test MSE 0.0005313064827119099 Test RE 0.00044134685812508836\n",
      "9 Train Loss 0.0012091042 Test MSE 0.0008466815766391136 Test RE 0.0005571441011322575\n",
      "10 Train Loss 0.000554447 Test MSE 0.00011093451113439397 Test RE 0.00020166977730056912\n",
      "11 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "12 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "13 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "14 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "15 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "16 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "17 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "18 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "19 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "20 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "21 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "22 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "23 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "24 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "25 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "26 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "27 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "28 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "29 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "30 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "31 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "32 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "33 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "34 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "35 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "36 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "37 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "38 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "39 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "40 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "41 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "42 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "43 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "44 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "45 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "46 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "47 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "48 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "49 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "50 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "51 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "52 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "53 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "54 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "55 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "56 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "57 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "58 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "59 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "60 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "61 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "62 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "63 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "64 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "65 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "66 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "67 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "68 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "69 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "70 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "71 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "72 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "73 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "74 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "75 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "76 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "77 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "78 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "79 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "80 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "81 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "82 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "83 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "84 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "85 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "86 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "87 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "88 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "89 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "90 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "91 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "92 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "93 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "94 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "95 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "96 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "97 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "98 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "99 Train Loss 0.00031629147 Test MSE 6.942933437073008e-05 Test RE 0.00015954345128856647\n",
      "Training time: 6.83\n",
      "Training time: 6.83\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 52.257065 Test MSE 1865.2758963468611 Test RE 0.8269495607891908\n",
      "1 Train Loss 34.481647 Test MSE 1243.9201107975225 Test RE 0.6753108483727321\n",
      "2 Train Loss 32.48788 Test MSE 1155.4388672895159 Test RE 0.6508500881800859\n",
      "3 Train Loss 30.621496 Test MSE 993.2488165871542 Test RE 0.6034433558833412\n",
      "4 Train Loss 20.452105 Test MSE 608.6809652039121 Test RE 0.4723917910506081\n",
      "5 Train Loss 13.472052 Test MSE 152.6684312724962 Test RE 0.2365822203169493\n",
      "6 Train Loss 1.8418865 Test MSE 18.451591400179574 Test RE 0.08224782009783044\n",
      "7 Train Loss 0.2965899 Test MSE 0.32952363638951 Test RE 0.010991343169957053\n",
      "8 Train Loss 0.16373122 Test MSE 0.2937995547913499 Test RE 0.010378463169314582\n",
      "9 Train Loss 0.05578533 Test MSE 0.041722931410906515 Test RE 0.0039110636938697735\n",
      "10 Train Loss 0.03687114 Test MSE 0.0264513890863727 Test RE 0.0031140940424956537\n",
      "11 Train Loss 0.022234505 Test MSE 0.027618070012282288 Test RE 0.003182029084567495\n",
      "12 Train Loss 0.018935084 Test MSE 0.05179921391158406 Test RE 0.004357817778399906\n",
      "13 Train Loss 0.015301335 Test MSE 0.01721493327594974 Test RE 0.002512234374245057\n",
      "14 Train Loss 0.010356522 Test MSE 0.002287650433300968 Test RE 0.0009158035295287617\n",
      "15 Train Loss 0.009813504 Test MSE 0.005798072929280372 Test RE 0.0014579724534980452\n",
      "16 Train Loss 0.007834974 Test MSE 0.004750583907362031 Test RE 0.0013197175083276365\n",
      "17 Train Loss 0.005429287 Test MSE 0.0015665522478701757 Test RE 0.0007578441871851099\n",
      "18 Train Loss 0.0047217053 Test MSE 0.000503504616328668 Test RE 0.0004296444539859586\n",
      "19 Train Loss 0.0047176317 Test MSE 0.000478405894763209 Test RE 0.0004187991030835821\n",
      "20 Train Loss 0.0040595303 Test MSE 0.0012191089021087872 Test RE 0.0006685420566537128\n",
      "21 Train Loss 0.0027065144 Test MSE 0.0011137624172968068 Test RE 0.0006390042715329722\n",
      "22 Train Loss 0.0018470145 Test MSE 0.0003132186493662644 Test RE 0.0003388685684894084\n",
      "23 Train Loss 0.0014869637 Test MSE 0.00013671375439908796 Test RE 0.00022387911773044826\n",
      "24 Train Loss 0.0013070287 Test MSE 0.00045520097789111027 Test RE 0.00040851600387418894\n",
      "25 Train Loss 0.00085426396 Test MSE 0.0005862805589351875 Test RE 0.0004636179351570418\n",
      "26 Train Loss 0.0005151369 Test MSE 0.00021747904540894583 Test RE 0.00028236846361587834\n",
      "27 Train Loss 0.00034297144 Test MSE 0.0002667577656898121 Test RE 0.0003127274599241432\n",
      "28 Train Loss 0.00022653383 Test MSE 0.00019991827213197436 Test RE 0.0002707283438795356\n",
      "29 Train Loss 0.00022305855 Test MSE 0.0002161738680906962 Test RE 0.0002815198864147565\n",
      "30 Train Loss 0.00022234551 Test MSE 0.00021415984435168732 Test RE 0.00028020540160064256\n",
      "31 Train Loss 0.00022148606 Test MSE 0.00021231764560304597 Test RE 0.00027899763803804266\n",
      "32 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "33 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "34 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "35 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "36 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "37 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "38 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "39 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "40 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "41 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "42 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "43 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "44 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "45 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "46 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "47 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "48 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "49 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "50 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "51 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "52 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "53 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "54 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "55 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "56 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "57 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "58 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "59 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "60 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "61 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "62 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "63 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "64 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "65 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "66 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "67 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "68 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "69 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "70 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "71 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "72 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "73 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "74 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "75 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "76 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "77 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "78 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "79 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "80 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "81 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "82 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "83 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "84 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "85 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "86 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "87 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "88 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "89 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "90 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "91 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "92 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "93 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "94 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "95 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "96 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "97 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "98 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "99 Train Loss 0.00020470172 Test MSE 0.00019380790860267522 Test RE 0.0002665589256401045\n",
      "Training time: 11.93\n",
      "Training time: 11.93\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 55.792408 Test MSE 2066.113140747873 Test RE 0.870331158214891\n",
      "1 Train Loss 34.29925 Test MSE 1106.4104148805727 Test RE 0.6368917296480675\n",
      "2 Train Loss 27.202784 Test MSE 872.6540656684513 Test RE 0.5656249263195166\n",
      "3 Train Loss 14.232748 Test MSE 341.4999265539377 Test RE 0.35383662918608677\n",
      "4 Train Loss 3.830157 Test MSE 87.83474108240102 Test RE 0.17944883553756458\n",
      "5 Train Loss 0.15615682 Test MSE 0.22574990814075327 Test RE 0.009097483423138772\n",
      "6 Train Loss 0.013670439 Test MSE 0.015540427712645393 Test RE 0.002386926057293305\n",
      "7 Train Loss 0.0029554705 Test MSE 0.0007512105740447168 Test RE 0.0005247933558298526\n",
      "8 Train Loss 0.0016443558 Test MSE 0.0003352081443859998 Test RE 0.00035056193931072723\n",
      "9 Train Loss 0.0007590515 Test MSE 0.00024843040180288193 Test RE 0.00030179347979359186\n",
      "10 Train Loss 0.0002671522 Test MSE 0.00016262893990478354 Test RE 0.0002441779241515404\n",
      "11 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "12 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "13 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "14 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "15 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "16 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "17 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "18 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "19 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "20 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "21 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "22 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "23 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "24 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "25 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "26 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "27 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "28 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "29 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "30 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "31 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "32 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "33 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "34 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "35 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "36 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "37 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "38 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "39 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "40 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "41 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "42 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "43 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "44 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "45 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "46 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "47 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "48 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "49 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "50 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "51 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "52 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "53 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "54 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "55 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "56 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "57 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "58 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "59 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "60 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "61 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "62 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "63 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "64 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "65 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "66 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "67 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "68 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "69 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "70 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "71 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "72 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "73 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "74 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "75 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "76 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "77 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "78 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "79 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "80 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "81 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "82 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "83 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "84 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "85 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "86 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "87 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "88 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "89 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "90 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "91 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "92 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "93 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "94 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "95 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "96 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "97 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "98 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "99 Train Loss 0.00014994649 Test MSE 3.274264905783443e-05 Test RE 0.00010956311933690777\n",
      "Training time: 6.79\n",
      "Training time: 6.79\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 40.9015 Test MSE 1427.6393391788115 Test RE 0.7234636832323771\n",
      "1 Train Loss 34.971756 Test MSE 1285.8004093409968 Test RE 0.6865849218614741\n",
      "2 Train Loss 33.357662 Test MSE 1189.839164184066 Test RE 0.6604677430338426\n",
      "3 Train Loss 29.712395 Test MSE 1037.3928027423888 Test RE 0.616707311158626\n",
      "4 Train Loss 19.497276 Test MSE 607.5224496258656 Test RE 0.471942020203869\n",
      "5 Train Loss 5.985896 Test MSE 89.73530492856239 Test RE 0.18137989796171927\n",
      "6 Train Loss 1.7196679 Test MSE 7.770742162531421 Test RE 0.053375103640036343\n",
      "7 Train Loss 0.17570701 Test MSE 0.34017005354878554 Test RE 0.011167488681347487\n",
      "8 Train Loss 0.057633147 Test MSE 0.03850445536094692 Test RE 0.00375718841155515\n",
      "9 Train Loss 0.018780738 Test MSE 0.003505369364005921 Test RE 0.0011336379476233976\n",
      "10 Train Loss 0.01396009 Test MSE 0.004896230612551557 Test RE 0.0013397951897924463\n",
      "11 Train Loss 0.007981109 Test MSE 0.0022340950235843976 Test RE 0.0009050202617428357\n",
      "12 Train Loss 0.0044803135 Test MSE 0.0011090015478604314 Test RE 0.0006376370706485621\n",
      "13 Train Loss 0.0029319508 Test MSE 0.0005430623750603882 Test RE 0.0004462028491896125\n",
      "14 Train Loss 0.001991448 Test MSE 0.0002700775472233256 Test RE 0.0003146673786124684\n",
      "15 Train Loss 0.0007165358 Test MSE 9.147622498237361e-05 Test RE 0.00018313088692674281\n",
      "16 Train Loss 0.0006374601 Test MSE 0.00011470549229661986 Test RE 0.00020506879919553943\n",
      "17 Train Loss 0.0006299554 Test MSE 8.932690056006111e-05 Test RE 0.0001809666781071193\n",
      "18 Train Loss 0.0005134445 Test MSE 6.425777075289778e-05 Test RE 0.00015348654464987364\n",
      "19 Train Loss 0.0005014392 Test MSE 5.829381729016645e-05 Test RE 0.00014619035795426045\n",
      "20 Train Loss 0.00049949833 Test MSE 4.077438388482165e-05 Test RE 0.00012226472784897276\n",
      "21 Train Loss 0.000498529 Test MSE 3.845521103485084e-05 Test RE 0.00011873672917231626\n",
      "22 Train Loss 0.0004975763 Test MSE 3.883927986130565e-05 Test RE 0.00011932819357565742\n",
      "23 Train Loss 0.00036049623 Test MSE 9.32734819351249e-05 Test RE 0.00018492114612954778\n",
      "24 Train Loss 0.000268183 Test MSE 3.577194673520587e-05 Test RE 0.00011451932234964508\n",
      "25 Train Loss 0.0002617982 Test MSE 5.004691444662085e-05 Test RE 0.00013545534142098898\n",
      "26 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "27 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "28 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "29 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "30 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "31 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "32 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "33 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "34 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "35 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "36 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "37 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "38 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "39 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "40 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "41 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "42 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "43 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "44 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "45 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "46 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "47 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "48 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "49 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "50 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "51 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "52 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "53 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "54 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "55 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "56 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "57 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "58 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "59 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "60 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "61 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "62 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "63 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "64 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "65 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "66 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "67 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "68 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "69 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "70 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "71 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "72 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "73 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "74 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "75 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "76 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "77 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "78 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "79 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "80 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "81 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "82 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "83 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "84 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "85 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "86 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "87 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "88 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "89 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "90 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "91 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "92 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "93 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "94 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "95 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "96 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "97 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "98 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "99 Train Loss 0.000259755 Test MSE 3.306823802879593e-05 Test RE 0.00011010651306995903\n",
      "Training time: 9.46\n",
      "Training time: 9.46\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 65.69132 Test MSE 2396.8073380508768 Test RE 0.9373980475262971\n",
      "1 Train Loss 47.182297 Test MSE 1643.8046736215767 Test RE 0.7763053644061075\n",
      "2 Train Loss 29.775726 Test MSE 940.9769790002958 Test RE 0.5873500107710645\n",
      "3 Train Loss 24.686234 Test MSE 789.5263639514856 Test RE 0.5380105600671063\n",
      "4 Train Loss 21.910463 Test MSE 714.8233896588475 Test RE 0.5119256130748344\n",
      "5 Train Loss 14.499 Test MSE 365.45596833848185 Test RE 0.36603702017310014\n",
      "6 Train Loss 7.1969867 Test MSE 172.8362290495705 Test RE 0.25172414413301647\n",
      "7 Train Loss 3.6147094 Test MSE 42.683351798402306 Test RE 0.12509407490188104\n",
      "8 Train Loss 2.205497 Test MSE 19.220915254137385 Test RE 0.0839449382015462\n",
      "9 Train Loss 0.89149654 Test MSE 14.464761841713486 Test RE 0.07282208773113946\n",
      "10 Train Loss 0.23006193 Test MSE 0.6603439833853981 Test RE 0.015559390993863895\n",
      "11 Train Loss 0.07789594 Test MSE 0.1300964129820964 Test RE 0.0069062157720646165\n",
      "12 Train Loss 0.05925333 Test MSE 0.0755797884770251 Test RE 0.005263932575318331\n",
      "13 Train Loss 0.037643623 Test MSE 0.06490851839561496 Test RE 0.004878185711499516\n",
      "14 Train Loss 0.010695454 Test MSE 0.024583274974323915 Test RE 0.003002115185269689\n",
      "15 Train Loss 0.0067372588 Test MSE 0.017057545729902496 Test RE 0.0025007239525882043\n",
      "16 Train Loss 0.0021647417 Test MSE 0.0027702425764011855 Test RE 0.0010077814999307217\n",
      "17 Train Loss 0.0017497151 Test MSE 0.0029599546347136964 Test RE 0.001041717618129077\n",
      "18 Train Loss 0.0008446954 Test MSE 0.0033751364381551918 Test RE 0.0011123799403938643\n",
      "19 Train Loss 0.00043910297 Test MSE 0.0005460133870705682 Test RE 0.00044741354436898974\n",
      "20 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "21 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "22 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "23 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "24 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "25 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "26 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "27 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "28 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "29 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "30 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "31 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "32 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "33 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "34 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "35 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "36 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "37 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "38 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "39 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "40 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "41 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "42 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "43 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "44 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "45 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "46 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "47 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "48 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "49 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "50 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "51 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "52 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "53 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "54 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "55 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "56 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "57 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "58 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "59 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "60 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "61 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "62 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "63 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "64 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "65 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "66 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "67 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "68 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "69 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "70 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "71 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "72 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "73 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "74 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "75 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "76 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "77 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "78 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "79 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "80 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "81 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "82 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "83 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "84 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "85 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "86 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "87 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "88 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "89 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "90 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "91 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "92 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "93 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "94 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "95 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "96 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "97 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "98 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "99 Train Loss 0.00037517044 Test MSE 0.0003158303280101286 Test RE 0.0003402784120568624\n",
      "Training time: 9.45\n",
      "Training time: 9.45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 52.78251 Test MSE 1593.8341617074925 Test RE 0.7644147303041597\n",
      "1 Train Loss 33.057007 Test MSE 1189.7649434276912 Test RE 0.6604471431152116\n",
      "2 Train Loss 31.52536 Test MSE 1099.3472438750312 Test RE 0.6348555604486629\n",
      "3 Train Loss 18.629349 Test MSE 507.2022348571969 Test RE 0.4312191716897956\n",
      "4 Train Loss 7.4134736 Test MSE 157.5439767276255 Test RE 0.24033021979985267\n",
      "5 Train Loss 0.71447283 Test MSE 4.481977784769925 Test RE 0.040536134433914864\n",
      "6 Train Loss 0.17623453 Test MSE 0.30665799010953027 Test RE 0.010603143137828841\n",
      "7 Train Loss 0.097301014 Test MSE 0.06503732468991734 Test RE 0.00488302351726402\n",
      "8 Train Loss 0.037172142 Test MSE 0.034368430089056774 Test RE 0.0035496646782423483\n",
      "9 Train Loss 0.018515667 Test MSE 0.013125569138721864 Test RE 0.0021936460465422137\n",
      "10 Train Loss 0.011015339 Test MSE 0.01428250579951972 Test RE 0.002288282747902085\n",
      "11 Train Loss 0.0073451963 Test MSE 0.019984944762242867 Test RE 0.002706817389614176\n",
      "12 Train Loss 0.0025099677 Test MSE 0.0011484392218304368 Test RE 0.0006488756693655257\n",
      "13 Train Loss 0.0015531416 Test MSE 0.0009374095972741024 Test RE 0.0005862355885192596\n",
      "14 Train Loss 0.0005742686 Test MSE 0.00020476955166280798 Test RE 0.00027399344410022945\n",
      "15 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "16 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "17 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "18 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "19 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "20 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "21 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "22 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "23 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "24 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "25 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "26 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "27 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "28 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "29 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "30 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "31 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "32 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "33 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "34 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "35 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "36 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "37 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "38 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "39 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "40 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "41 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "42 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "43 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "44 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "45 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "46 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "47 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "48 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "49 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "50 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "51 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "52 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "53 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "54 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "55 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "56 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "57 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "58 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "59 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "60 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "61 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "62 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "63 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "64 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "65 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "66 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "67 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "68 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "69 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "70 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "71 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "72 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "73 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "74 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "75 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "76 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "77 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "78 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "79 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "80 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "81 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "82 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "83 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "84 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "85 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "86 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "87 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "88 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "89 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "90 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "91 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "92 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "93 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "94 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "95 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "96 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "97 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "98 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "99 Train Loss 0.00036219557 Test MSE 0.00011462124684487826 Test RE 0.00020499347897086538\n",
      "Training time: 8.04\n",
      "Training time: 8.04\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 65.928345 Test MSE 2395.253789005666 Test RE 0.937094199595305\n",
      "1 Train Loss 24.471535 Test MSE 696.2153485125675 Test RE 0.505218538815021\n",
      "2 Train Loss 16.936691 Test MSE 487.045915969927 Test RE 0.4225639414839899\n",
      "3 Train Loss 1.8490887 Test MSE 15.953233602767554 Test RE 0.0764771762286014\n",
      "4 Train Loss 0.49133757 Test MSE 4.314330083704123 Test RE 0.039770785295543676\n",
      "5 Train Loss 0.20450148 Test MSE 0.5497708592902895 Test RE 0.014197057454871601\n",
      "6 Train Loss 0.082638524 Test MSE 0.28298370947701046 Test RE 0.010185637113528021\n",
      "7 Train Loss 0.031184234 Test MSE 0.2354468105719402 Test RE 0.009290816609232859\n",
      "8 Train Loss 0.019066678 Test MSE 0.015954820805117346 Test RE 0.002418540961495636\n",
      "9 Train Loss 0.009022568 Test MSE 0.010536883401997 Test RE 0.001965457100055427\n",
      "10 Train Loss 0.006401739 Test MSE 0.010465640293998388 Test RE 0.0019588013006538152\n",
      "11 Train Loss 0.0041427896 Test MSE 0.002653329490878484 Test RE 0.0009862864662902647\n",
      "12 Train Loss 0.0028435197 Test MSE 0.005378191156122981 Test RE 0.001404189104469634\n",
      "13 Train Loss 0.0019658993 Test MSE 0.0013909387409795594 Test RE 0.0007141040291844728\n",
      "14 Train Loss 0.00036073133 Test MSE 0.0001588208701602643 Test RE 0.00024130219215149793\n",
      "15 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "16 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "17 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "18 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "19 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "20 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "21 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "22 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "23 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "24 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "25 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "26 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "27 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "28 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "29 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "30 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "31 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "32 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "33 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "34 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "35 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "36 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "37 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "38 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "39 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "40 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "41 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "42 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "43 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "44 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "45 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "46 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "47 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "48 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "49 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "50 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "51 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "52 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "53 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "54 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "55 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "56 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "57 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "58 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "59 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "60 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "61 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "62 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "63 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "64 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "65 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "66 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "67 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "68 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "69 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "70 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "71 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "72 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "73 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "74 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "75 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "76 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "77 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "78 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "79 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "80 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "81 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "82 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "83 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "84 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "85 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "86 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "87 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "88 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "89 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "90 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "91 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "92 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "93 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "94 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "95 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "96 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "97 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "98 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "99 Train Loss 0.00033562878 Test MSE 0.00012423233771462208 Test RE 0.00021341493599137573\n",
      "Training time: 7.90\n",
      "Training time: 7.90\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 48.57568 Test MSE 1497.9323002472595 Test RE 0.7410603455575837\n",
      "1 Train Loss 27.927814 Test MSE 945.6767583330204 Test RE 0.5888149654453582\n",
      "2 Train Loss 24.032904 Test MSE 727.7251427894439 Test RE 0.516524792337602\n",
      "3 Train Loss 18.895021 Test MSE 576.8066902311575 Test RE 0.45985681420226454\n",
      "4 Train Loss 3.2396572 Test MSE 45.93370289222653 Test RE 0.1297696729968659\n",
      "5 Train Loss 0.68294656 Test MSE 3.7494055572769205 Test RE 0.03707564295353797\n",
      "6 Train Loss 0.26613465 Test MSE 0.35142773292929125 Test RE 0.01135077453560026\n",
      "7 Train Loss 0.15386003 Test MSE 0.3609135500771191 Test RE 0.0115029458538029\n",
      "8 Train Loss 0.10104084 Test MSE 0.17227915776848135 Test RE 0.007947377669760862\n",
      "9 Train Loss 0.06500038 Test MSE 0.1556751504067761 Test RE 0.007554698360615737\n",
      "10 Train Loss 0.021846646 Test MSE 0.014429830788607071 Test RE 0.002300054363250606\n",
      "11 Train Loss 0.012980762 Test MSE 0.0052313862436076195 Test RE 0.0013848918988498648\n",
      "12 Train Loss 0.010112289 Test MSE 0.0030134308983694722 Test RE 0.0010510856340010793\n",
      "13 Train Loss 0.0030668278 Test MSE 0.0008707563944135247 Test RE 0.0005650095883646901\n",
      "14 Train Loss 0.0016168668 Test MSE 0.00035729121149668066 Test RE 0.0003619250546488271\n",
      "15 Train Loss 0.0011504656 Test MSE 0.00034349686037363057 Test RE 0.0003548696577977802\n",
      "16 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "17 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "18 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "19 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "20 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "21 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "22 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "23 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "24 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "25 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "26 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "27 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "28 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "29 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "30 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "31 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "32 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "33 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "34 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "35 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "36 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "37 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "38 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "39 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "40 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "41 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "42 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "43 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "44 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "45 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "46 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "47 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "48 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "49 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "50 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "51 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "52 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "53 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "54 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "55 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "56 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "57 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "58 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "59 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "60 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "61 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "62 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "63 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "64 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "65 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "66 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "67 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "68 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "69 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "70 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "71 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "72 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "73 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "74 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "75 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "76 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "77 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "78 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "79 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "80 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "81 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "82 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "83 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "84 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "85 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "86 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "87 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "88 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "89 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "90 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "91 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "92 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "93 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "94 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "95 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "96 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "97 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "98 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "99 Train Loss 0.0011110348 Test MSE 0.00044665671613690377 Test RE 0.0004046638564991771\n",
      "Training time: 8.25\n",
      "Training time: 8.25\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "#for tune_reps in range(4,5):\n",
    "  label = \"1D_FODE_stan_tune\"+str(tune_reps)  \n",
    "  max_reps = 10\n",
    "  max_iter = 100\n",
    "\n",
    "  train_loss_full = []\n",
    "  test_mse_full = []\n",
    "  test_re_full = []\n",
    "  beta_full = []\n",
    "  elapsed_time= np.zeros((max_reps,1))\n",
    "  time_threshold = np.empty((max_reps,1))\n",
    "  time_threshold[:] = np.nan\n",
    "  epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "  for reps in range(max_reps):   \n",
    "      train_loss = []\n",
    "      test_mse_loss = []\n",
    "      test_re_loss = []   \n",
    "      beta_val = []\n",
    "      \n",
    "      torch.manual_seed(reps*36)\n",
    "      N_f = 10000 #Total number of collocation points\n",
    "    \n",
    "      layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "      PINN = Sequentialmodel(layers)\n",
    "    \n",
    "      PINN.to(device)\n",
    "\n",
    "      'Neural Network Summary'\n",
    "      print(PINN)\n",
    "\n",
    "      params = list(PINN.parameters())\n",
    "      \n",
    "      optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "    \n",
    "\n",
    "      \n",
    "      train_model(max_iter,reps)\n",
    "\n",
    "      \n",
    "      torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "      train_loss_full.append(train_loss)\n",
    "      test_mse_full.append(test_mse_loss)\n",
    "      test_re_full.append(test_re_loss)\n",
    "      beta_full.append(beta_val)\n",
    "      \n",
    "      \n",
    "      print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "  mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label}\n",
    "  savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1D_FODE_stan_tune4'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "aefc6a9f-3ad4-417a-b9f7-438009e620af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00022409146000691927\n",
      "0.00014043246357548747\n",
      "0.00011384335057651618\n",
      "0.00012226588347392505\n",
      "0.00025221015091414267\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_stan_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
