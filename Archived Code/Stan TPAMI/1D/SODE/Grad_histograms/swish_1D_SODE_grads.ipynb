{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(2*x) + np.exp(-3*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "label = \"1D_SODE_swish\"\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(-1.0,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((layers[1],len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - 6*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat,i):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        #loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss = PINN.loss_PDE(x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        grads_layer1 = PINN.linears[0].weight.grad\n",
    "        if(i%20==0):\n",
    "            #print(i)\n",
    "            plt.hist(grads_layer1.flatten().cpu().detach().numpy(),color = 'b')\n",
    "            plt.savefig(label + 'grad_PDE_hist_' + str(i)+'.eps', format='eps',pad_inches=0, bbox_inches='tight')\n",
    "        return loss\n",
    "\n",
    "    if(i%20==0):\n",
    "        plt.figure()\n",
    "        plt.xlabel(\"Gradients\",fontsize=14)\n",
    "        plt.title(\"Gradients of Weights Histogram\", fontsize=14, math_fontfamily='cm')\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat,i)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.998853 Test MSE 384.83940084439246 Test RE 1.000005405198826\n",
      "Training time: 0.40\n",
      "Training time: 0.40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 1\n",
    "\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    beta_val = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "\n",
    "\n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "#     torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)    \n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "# mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "# savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_SODE_swish_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_SODE_swish_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0b19103404f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_SODE_swish_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m \u001b[0;31m#WRONGLY SAVED AS STAN - DOESN'T MATTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_SODE_swish_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_SODE_swish_tune\"+str(tune_reps)+\".mat\" #WRONGLY SAVED AS STAN - DOESN'T MATTER\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
