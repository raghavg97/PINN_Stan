{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(2*x) + np.exp(-3*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(-1.0,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - 6*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.5381145 Test MSE 383.21158026227056 Test RE 0.9978882176082347\n",
      "1 Train Loss 3.5556834 Test MSE 381.8524086850851 Test RE 0.996116994947617\n",
      "2 Train Loss 2.3911674 Test MSE 380.9360460972038 Test RE 0.9949210451283584\n",
      "3 Train Loss 2.3821518 Test MSE 381.45662908104964 Test RE 0.9956006370704462\n",
      "4 Train Loss 2.3702505 Test MSE 381.55345995600675 Test RE 0.9957269931962117\n",
      "5 Train Loss 2.340914 Test MSE 375.5920615594917 Test RE 0.9879177415531054\n",
      "6 Train Loss 2.3032722 Test MSE 367.30736758469016 Test RE 0.9769613941392613\n",
      "7 Train Loss 2.292344 Test MSE 364.570796204425 Test RE 0.973315234079516\n",
      "8 Train Loss 2.2046983 Test MSE 344.84173080579683 Test RE 0.9466130571483348\n",
      "9 Train Loss 2.1254497 Test MSE 338.88124644675736 Test RE 0.9383964376527025\n",
      "10 Train Loss 2.0314167 Test MSE 321.81560035594424 Test RE 0.9144629808193827\n",
      "11 Train Loss 1.9353342 Test MSE 296.6648188655893 Test RE 0.8780022037659513\n",
      "12 Train Loss 1.7825527 Test MSE 268.5533672508603 Test RE 0.835368093558723\n",
      "13 Train Loss 1.5700336 Test MSE 241.08866567039803 Test RE 0.7915001093336501\n",
      "14 Train Loss 1.3491262 Test MSE 189.28784674893453 Test RE 0.7013324729739684\n",
      "15 Train Loss 1.0769838 Test MSE 152.11723785533522 Test RE 0.6287120699563047\n",
      "16 Train Loss 0.7002226 Test MSE 105.13973054640091 Test RE 0.5226921916726971\n",
      "17 Train Loss 0.5942718 Test MSE 85.95536181080296 Test RE 0.4726058236541298\n",
      "18 Train Loss 0.50744957 Test MSE 72.59709292545755 Test RE 0.4343323698750725\n",
      "19 Train Loss 0.44573465 Test MSE 56.6481678272449 Test RE 0.38366794554622907\n",
      "20 Train Loss 0.43476093 Test MSE 55.0556455704477 Test RE 0.37823656627650787\n",
      "21 Train Loss 0.38391846 Test MSE 48.557479207027114 Test RE 0.35521447007905443\n",
      "22 Train Loss 0.2677391 Test MSE 33.83357692886201 Test RE 0.2965080848522678\n",
      "23 Train Loss 0.24777934 Test MSE 27.395718385494202 Test RE 0.26681112199441964\n",
      "24 Train Loss 0.24000698 Test MSE 24.10637122570733 Test RE 0.25028135792858663\n",
      "25 Train Loss 0.20963377 Test MSE 20.52038293911502 Test RE 0.2309166843854735\n",
      "26 Train Loss 0.17698175 Test MSE 16.911009637562923 Test RE 0.20962706367561879\n",
      "27 Train Loss 0.13307777 Test MSE 13.148533247368986 Test RE 0.18484224600547994\n",
      "28 Train Loss 0.10488255 Test MSE 13.417508798879382 Test RE 0.18672330548717828\n",
      "29 Train Loss 0.094105184 Test MSE 12.218343601457532 Test RE 0.17818401867649764\n",
      "30 Train Loss 0.090159774 Test MSE 10.764337349755635 Test RE 0.16724618980826586\n",
      "31 Train Loss 0.05869241 Test MSE 4.034748520079653 Test RE 0.10239312978775458\n",
      "32 Train Loss 0.0350262 Test MSE 1.2049465720428558 Test RE 0.055955976328206196\n",
      "33 Train Loss 0.02912874 Test MSE 0.6539322958552574 Test RE 0.0412219921029594\n",
      "34 Train Loss 0.028433757 Test MSE 0.7075876681609 Test RE 0.04287979597025771\n",
      "35 Train Loss 0.028057862 Test MSE 0.5966109614714736 Test RE 0.03937387849013868\n",
      "36 Train Loss 0.023903677 Test MSE 0.015223143217431597 Test RE 0.006289480125705343\n",
      "37 Train Loss 0.013283735 Test MSE 0.028299590009725484 Test RE 0.008575365791171392\n",
      "38 Train Loss 0.010437886 Test MSE 0.15756041539295476 Test RE 0.02023420478628632\n",
      "39 Train Loss 0.009117392 Test MSE 0.12155913202601157 Test RE 0.017772821443818834\n",
      "40 Train Loss 0.008518423 Test MSE 0.08707898472714583 Test RE 0.015042473703820981\n",
      "41 Train Loss 0.008413162 Test MSE 0.08322502616449752 Test RE 0.014705830389692687\n",
      "42 Train Loss 0.008239063 Test MSE 0.0793482019853749 Test RE 0.014359229196997664\n",
      "43 Train Loss 0.007937762 Test MSE 0.06455479624186675 Test RE 0.012951701895508353\n",
      "44 Train Loss 0.0067492086 Test MSE 0.019242680934254054 Test RE 0.007071236651724359\n",
      "45 Train Loss 0.006028674 Test MSE 0.0015111948728737808 Test RE 0.001981631139915421\n",
      "46 Train Loss 0.005219214 Test MSE 0.004560667766111395 Test RE 0.003442522603967184\n",
      "47 Train Loss 0.0045730453 Test MSE 0.00025488093707300136 Test RE 0.0008138254370520738\n",
      "48 Train Loss 0.004070472 Test MSE 0.006794002653827894 Test RE 0.0042017038498213454\n",
      "49 Train Loss 0.004041062 Test MSE 0.0071224398751142445 Test RE 0.0043020651045405185\n",
      "50 Train Loss 0.0040324377 Test MSE 0.007249540966274819 Test RE 0.004340280890406498\n",
      "51 Train Loss 0.0040131593 Test MSE 0.0071987146406239525 Test RE 0.004325039335915182\n",
      "52 Train Loss 0.003875623 Test MSE 0.003465334683453971 Test RE 0.0030007870379250207\n",
      "53 Train Loss 0.0037048175 Test MSE 0.00010517059608972338 Test RE 0.000522768908602323\n",
      "54 Train Loss 0.0036828658 Test MSE 4.5745573580738546e-05 Test RE 0.0003447760749622961\n",
      "55 Train Loss 0.0036783835 Test MSE 3.707849867522996e-05 Test RE 0.00031040138690044807\n",
      "56 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "57 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "58 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "59 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "60 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "61 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "62 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "63 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "64 Train Loss 0.0036745453 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "65 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "66 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "67 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "68 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "69 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "70 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "71 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "72 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "73 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "74 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "75 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "76 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "77 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "78 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "79 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "80 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "81 Train Loss 0.0036745458 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "82 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "83 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "84 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "85 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "86 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "87 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "88 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "89 Train Loss 0.0036745458 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "90 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "91 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "93 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "94 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "95 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "96 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "97 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "98 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "99 Train Loss 0.0036745456 Test MSE 3.177721073552541e-05 Test RE 0.0002873561322819831\n",
      "Training time: 47.05\n",
      "Training time: 47.05\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 3.8715718 Test MSE 385.00996808157356 Test RE 1.0002269901811343\n",
      "1 Train Loss 2.6707232 Test MSE 381.67475359877716 Test RE 0.9958852485522263\n",
      "2 Train Loss 2.3899648 Test MSE 384.01707689563204 Test RE 0.9989364292193684\n",
      "3 Train Loss 2.3844354 Test MSE 384.0788467163293 Test RE 0.9990167663277009\n",
      "4 Train Loss 2.3833241 Test MSE 384.00050799562763 Test RE 0.9989148788022939\n",
      "5 Train Loss 2.3798003 Test MSE 383.34793055276793 Test RE 0.9980657308338893\n",
      "6 Train Loss 2.3794963 Test MSE 383.2396340903838 Test RE 0.9979247432165964\n",
      "7 Train Loss 2.3758688 Test MSE 381.6322921328072 Test RE 0.9958298506992608\n",
      "8 Train Loss 2.3479755 Test MSE 375.9027923416805 Test RE 0.9883263138035846\n",
      "9 Train Loss 2.3204534 Test MSE 369.7265073015969 Test RE 0.9801733191466182\n",
      "10 Train Loss 2.279922 Test MSE 359.05762611334137 Test RE 0.9659277880840712\n",
      "11 Train Loss 2.2350872 Test MSE 356.90350844219074 Test RE 0.9630259526751144\n",
      "12 Train Loss 2.1135685 Test MSE 329.1207273915511 Test RE 0.9247837707868083\n",
      "13 Train Loss 1.9002006 Test MSE 285.82295577509205 Test RE 0.8618092190511446\n",
      "14 Train Loss 1.6457206 Test MSE 253.01486813043738 Test RE 0.8108408194948397\n",
      "15 Train Loss 1.5551263 Test MSE 227.09291342545112 Test RE 0.7681824368033434\n",
      "16 Train Loss 1.2130361 Test MSE 175.55212775703498 Test RE 0.6754071150025865\n",
      "17 Train Loss 1.0781503 Test MSE 162.117439207196 Test RE 0.6490489475763586\n",
      "18 Train Loss 1.0343301 Test MSE 158.59075002344392 Test RE 0.6419504520886453\n",
      "19 Train Loss 0.9569984 Test MSE 138.08537030380734 Test RE 0.599013233488573\n",
      "20 Train Loss 0.805764 Test MSE 121.1521666146115 Test RE 0.5610843755634904\n",
      "21 Train Loss 0.6397002 Test MSE 84.78597742196808 Test RE 0.4693800188738666\n",
      "22 Train Loss 0.62854546 Test MSE 85.90539626666478 Test RE 0.4724684416495262\n",
      "23 Train Loss 0.5312525 Test MSE 74.00164110361382 Test RE 0.43851379282789893\n",
      "24 Train Loss 0.4280206 Test MSE 58.01541010118714 Test RE 0.388270384501663\n",
      "25 Train Loss 0.35658306 Test MSE 38.25166765987864 Test RE 0.3152737187763219\n",
      "26 Train Loss 0.27706173 Test MSE 29.54950312660842 Test RE 0.2771007325207347\n",
      "27 Train Loss 0.24689868 Test MSE 21.761645145234425 Test RE 0.23779813523364343\n",
      "28 Train Loss 0.20356667 Test MSE 11.3176487183868 Test RE 0.17149074519516427\n",
      "29 Train Loss 0.14093885 Test MSE 7.152576791857589 Test RE 0.13633075728734625\n",
      "30 Train Loss 0.10405001 Test MSE 4.352542659431382 Test RE 0.10634916899439117\n",
      "31 Train Loss 0.06295362 Test MSE 1.2952282817808114 Test RE 0.05801439157438012\n",
      "32 Train Loss 0.03176084 Test MSE 0.020638398862497288 Test RE 0.007323194742063243\n",
      "33 Train Loss 0.027086096 Test MSE 0.0015576103418819443 Test RE 0.0020118333056226697\n",
      "34 Train Loss 0.024694458 Test MSE 0.0020741182386700393 Test RE 0.002321556928459467\n",
      "35 Train Loss 0.020256523 Test MSE 0.16644274713302046 Test RE 0.020796728402377555\n",
      "36 Train Loss 0.017109733 Test MSE 0.3303679196652308 Test RE 0.029299588223573272\n",
      "37 Train Loss 0.013932897 Test MSE 0.21834560124827998 Test RE 0.023819618754563402\n",
      "38 Train Loss 0.010807143 Test MSE 0.04159333536531533 Test RE 0.010396195945985526\n",
      "39 Train Loss 0.009523045 Test MSE 4.455383162013242e-05 Test RE 0.00034025546719408857\n",
      "40 Train Loss 0.007881299 Test MSE 0.0102039142969639 Test RE 0.005149273784514669\n",
      "41 Train Loss 0.007005489 Test MSE 0.00010362805570022315 Test RE 0.0005189210132990148\n",
      "42 Train Loss 0.0065892385 Test MSE 0.005023059632470399 Test RE 0.00361282353636408\n",
      "43 Train Loss 0.0065449504 Test MSE 0.0035805680888780058 Test RE 0.003050271879026393\n",
      "44 Train Loss 0.0065374807 Test MSE 0.0030061655176932267 Test RE 0.0027949177189187935\n",
      "45 Train Loss 0.0065299305 Test MSE 0.0024380071824239642 Test RE 0.002516981786466953\n",
      "46 Train Loss 0.006519947 Test MSE 0.0019032865754692778 Test RE 0.002223897029373603\n",
      "47 Train Loss 0.006189523 Test MSE 0.0009288176921580425 Test RE 0.0015535592536991337\n",
      "48 Train Loss 0.0043369904 Test MSE 3.326860937268522e-07 Test RE 2.9402205347009075e-05\n",
      "49 Train Loss 0.003608652 Test MSE 0.00917004412590176 Test RE 0.004881443818233348\n",
      "50 Train Loss 0.003059139 Test MSE 0.020095086174488887 Test RE 0.007226159094967181\n",
      "51 Train Loss 0.0026520214 Test MSE 0.004933437081506099 Test RE 0.0035804480719199725\n",
      "52 Train Loss 0.0024073082 Test MSE 0.003424084249034787 Test RE 0.0029828732775554006\n",
      "53 Train Loss 0.0023723473 Test MSE 0.004386613477466697 Test RE 0.0033761930135382547\n",
      "54 Train Loss 0.0023013959 Test MSE 0.011958243781524745 Test RE 0.0055743763172474235\n",
      "55 Train Loss 0.0022952943 Test MSE 0.012490075402860821 Test RE 0.005696985481029796\n",
      "56 Train Loss 0.0022225985 Test MSE 0.019145088794749975 Test RE 0.007053282440335337\n",
      "57 Train Loss 0.0022129118 Test MSE 0.019440545297554568 Test RE 0.007107498943088738\n",
      "58 Train Loss 0.0021959743 Test MSE 0.01827384663592981 Test RE 0.006890925750120087\n",
      "59 Train Loss 0.0021935524 Test MSE 0.017934076563888263 Test RE 0.006826562838879009\n",
      "60 Train Loss 0.0021887333 Test MSE 0.01702985236782523 Test RE 0.006652241757304985\n",
      "61 Train Loss 0.0021887333 Test MSE 0.01702985236782523 Test RE 0.006652241757304985\n",
      "62 Train Loss 0.0021879515 Test MSE 0.01687933393863861 Test RE 0.006622778575373608\n",
      "63 Train Loss 0.0021828602 Test MSE 0.01555011362406248 Test RE 0.006356665606622185\n",
      "64 Train Loss 0.002180128 Test MSE 0.014789114564169916 Test RE 0.006199171755124798\n",
      "65 Train Loss 0.0021789547 Test MSE 0.014566236985674448 Test RE 0.00615228248723825\n",
      "66 Train Loss 0.0021789547 Test MSE 0.014566236985674448 Test RE 0.00615228248723825\n",
      "67 Train Loss 0.0021789547 Test MSE 0.014566236985674448 Test RE 0.00615228248723825\n",
      "68 Train Loss 0.0021788504 Test MSE 0.014566332173404209 Test RE 0.006152302589233247\n",
      "69 Train Loss 0.0021756627 Test MSE 0.01385691727569077 Test RE 0.00600061681532192\n",
      "70 Train Loss 0.0021727823 Test MSE 0.01327588923852497 Test RE 0.005873465102785435\n",
      "71 Train Loss 0.0021713953 Test MSE 0.013119428669084053 Test RE 0.005838752198551833\n",
      "72 Train Loss 0.0021692314 Test MSE 0.013016453325088417 Test RE 0.005815792662996101\n",
      "73 Train Loss 0.0021610318 Test MSE 0.01240434858233198 Test RE 0.005677400917178171\n",
      "74 Train Loss 0.0021537468 Test MSE 0.012105454755230272 Test RE 0.005608582815120263\n",
      "75 Train Loss 0.0021443274 Test MSE 0.011984873644073017 Test RE 0.005580579666443002\n",
      "76 Train Loss 0.0021375578 Test MSE 0.012085073135203182 Test RE 0.005603859318040622\n",
      "77 Train Loss 0.0021321203 Test MSE 0.012457090291169017 Test RE 0.005689457907042354\n",
      "78 Train Loss 0.002130582 Test MSE 0.01258813145663137 Test RE 0.005719304473501689\n",
      "79 Train Loss 0.0021230509 Test MSE 0.013592641989773106 Test RE 0.00594312030582328\n",
      "80 Train Loss 0.0021219486 Test MSE 0.013759882127372572 Test RE 0.005979569793264244\n",
      "81 Train Loss 0.0021156278 Test MSE 0.015008329937123638 Test RE 0.006244947141621352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 0.0021151747 Test MSE 0.015241962893968149 Test RE 0.006293366623383254\n",
      "83 Train Loss 0.0021118089 Test MSE 0.016197362005483388 Test RE 0.00648760988484637\n",
      "84 Train Loss 0.0021101297 Test MSE 0.016422260622358534 Test RE 0.006532494497701262\n",
      "85 Train Loss 0.0020966444 Test MSE 0.02111766532050515 Test RE 0.00740773664012248\n",
      "86 Train Loss 0.0020935407 Test MSE 0.021785136002244614 Test RE 0.00752389489932145\n",
      "87 Train Loss 0.0020641575 Test MSE 0.030413752394873986 Test RE 0.008889914528534144\n",
      "88 Train Loss 0.0017808839 Test MSE 0.045043976207407646 Test RE 0.0108188460952481\n",
      "89 Train Loss 0.001399251 Test MSE 0.011305534907696637 Test RE 0.005420110494572929\n",
      "90 Train Loss 0.0009459902 Test MSE 0.0006958143994999097 Test RE 0.0013446501000930157\n",
      "91 Train Loss 0.0007300763 Test MSE 0.002653228442877915 Test RE 0.002625729023676897\n",
      "92 Train Loss 0.00072229997 Test MSE 0.00249754450234307 Test RE 0.002547529373688065\n",
      "93 Train Loss 0.0006974945 Test MSE 0.002165614739453602 Test RE 0.0023722102704600706\n",
      "94 Train Loss 0.00066435477 Test MSE 0.0015287894036392013 Test RE 0.0019931336182387053\n",
      "95 Train Loss 0.00065563753 Test MSE 0.0013648246522609251 Test RE 0.001883219800266121\n",
      "96 Train Loss 0.0006473637 Test MSE 0.0012245377044337261 Test RE 0.0017838102844284552\n",
      "97 Train Loss 0.00063829473 Test MSE 0.0010767337550087477 Test RE 0.0016726949533556726\n",
      "98 Train Loss 0.00062905415 Test MSE 0.0009646781409267681 Test RE 0.001583265693195834\n",
      "99 Train Loss 0.00062288647 Test MSE 0.0008807506248150756 Test RE 0.001512826287912957\n",
      "Training time: 59.80\n",
      "Training time: 59.80\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 3.8136115 Test MSE 385.6369128819573 Test RE 1.0010410366803841\n",
      "1 Train Loss 2.4210725 Test MSE 383.4570099014431 Test RE 0.9982077175355517\n",
      "2 Train Loss 2.3878238 Test MSE 382.96506011372446 Test RE 0.9975671950453209\n",
      "3 Train Loss 2.3825078 Test MSE 382.9502283273505 Test RE 0.9975478775561694\n",
      "4 Train Loss 2.3701441 Test MSE 381.2979791407229 Test RE 0.9953935776090144\n",
      "5 Train Loss 2.365741 Test MSE 380.38781757144403 Test RE 0.9942048612829352\n",
      "6 Train Loss 2.3577967 Test MSE 376.74947977949756 Test RE 0.9894387460800579\n",
      "7 Train Loss 2.3207502 Test MSE 371.0186554730545 Test RE 0.9818846171953862\n",
      "8 Train Loss 2.238808 Test MSE 356.57420412918543 Test RE 0.962581572363194\n",
      "9 Train Loss 2.1512976 Test MSE 342.1134872013878 Test RE 0.9428610178938281\n",
      "10 Train Loss 2.097694 Test MSE 330.79719196700074 Test RE 0.9271360959557975\n",
      "11 Train Loss 1.9828191 Test MSE 308.1462764034159 Test RE 0.8948310483650399\n",
      "12 Train Loss 1.8571296 Test MSE 286.4466586619648 Test RE 0.8627489965877723\n",
      "13 Train Loss 1.7968326 Test MSE 278.79269838764924 Test RE 0.8511444668327436\n",
      "14 Train Loss 1.7152302 Test MSE 267.2391495181789 Test RE 0.8333215692278406\n",
      "15 Train Loss 1.6517683 Test MSE 262.2134233792766 Test RE 0.8254486143179901\n",
      "16 Train Loss 1.5957224 Test MSE 247.42153673859116 Test RE 0.8018282117440073\n",
      "17 Train Loss 1.5544168 Test MSE 225.92245034809986 Test RE 0.7662002289163534\n",
      "18 Train Loss 1.2987779 Test MSE 191.92701638861027 Test RE 0.70620475681481\n",
      "19 Train Loss 1.141659 Test MSE 167.0547723152871 Test RE 0.6588583069429611\n",
      "20 Train Loss 1.0281134 Test MSE 144.47176250190475 Test RE 0.6127087296640387\n",
      "21 Train Loss 0.90587366 Test MSE 129.67884923960227 Test RE 0.5804932264758468\n",
      "22 Train Loss 0.80417764 Test MSE 117.37085973349366 Test RE 0.5522589023986348\n",
      "23 Train Loss 0.7512208 Test MSE 104.14635848120035 Test RE 0.5202171041003487\n",
      "24 Train Loss 0.6717939 Test MSE 96.01733734961881 Test RE 0.4995022073235858\n",
      "25 Train Loss 0.6512652 Test MSE 89.45399157298952 Test RE 0.4821281003506462\n",
      "26 Train Loss 0.5636041 Test MSE 65.3337428448538 Test RE 0.4120323848050792\n",
      "27 Train Loss 0.4247045 Test MSE 51.87200368618207 Test RE 0.3671377944034388\n",
      "28 Train Loss 0.3212765 Test MSE 36.414561055767706 Test RE 0.3076097680131258\n",
      "29 Train Loss 0.28855437 Test MSE 32.36700198833641 Test RE 0.2900105652467527\n",
      "30 Train Loss 0.2527326 Test MSE 31.13656304813766 Test RE 0.2844447474932202\n",
      "31 Train Loss 0.22851494 Test MSE 28.991398010891896 Test RE 0.27447144051689487\n",
      "32 Train Loss 0.15512128 Test MSE 21.574526101365272 Test RE 0.23677356598435337\n",
      "33 Train Loss 0.14527002 Test MSE 19.72324182292761 Test RE 0.2263871292298503\n",
      "34 Train Loss 0.13605167 Test MSE 17.245582446317506 Test RE 0.21169057173411807\n",
      "35 Train Loss 0.12958772 Test MSE 15.997729241822876 Test RE 0.20388804124431814\n",
      "36 Train Loss 0.11809281 Test MSE 13.687736744302006 Test RE 0.1885942313000585\n",
      "37 Train Loss 0.099341676 Test MSE 9.174599691230918 Test RE 0.15440314586720819\n",
      "38 Train Loss 0.09244574 Test MSE 7.153867659459455 Test RE 0.1363430589391354\n",
      "39 Train Loss 0.07320244 Test MSE 4.1758548525622725 Test RE 0.10416822882252631\n",
      "40 Train Loss 0.03149984 Test MSE 2.092069412201102 Test RE 0.07373108543206539\n",
      "41 Train Loss 0.028634898 Test MSE 1.9647757890819022 Test RE 0.07145277194033925\n",
      "42 Train Loss 0.02622674 Test MSE 1.555810420146868 Test RE 0.06358298614145612\n",
      "43 Train Loss 0.018268693 Test MSE 0.5708859587536737 Test RE 0.038515652813225276\n",
      "44 Train Loss 0.012053985 Test MSE 0.1990237708617121 Test RE 0.02274128797625268\n",
      "45 Train Loss 0.009841785 Test MSE 0.07629039709554057 Test RE 0.014079833536401489\n",
      "46 Train Loss 0.009217473 Test MSE 0.04322215835747253 Test RE 0.010597802154691754\n",
      "47 Train Loss 0.0074968976 Test MSE 0.03729894015504422 Test RE 0.009844889100362438\n",
      "48 Train Loss 0.0063791266 Test MSE 0.055590101410402985 Test RE 0.01201880573866943\n",
      "49 Train Loss 0.0052765487 Test MSE 0.027455334324077083 Test RE 0.00844648374816797\n",
      "50 Train Loss 0.0048671905 Test MSE 0.012588798517173793 Test RE 0.005719456007977512\n",
      "51 Train Loss 0.0048608007 Test MSE 0.01263528477711457 Test RE 0.005730006304830192\n",
      "52 Train Loss 0.0048594247 Test MSE 0.01267523715466622 Test RE 0.005739058205896441\n",
      "53 Train Loss 0.0048578475 Test MSE 0.012736910841472581 Test RE 0.005753003482326433\n",
      "54 Train Loss 0.0048489794 Test MSE 0.013355380940774497 Test RE 0.005891023057526168\n",
      "55 Train Loss 0.004847544 Test MSE 0.013410269988329566 Test RE 0.005903116351300776\n",
      "56 Train Loss 0.0048471703 Test MSE 0.013473107821308344 Test RE 0.005916930596587995\n",
      "57 Train Loss 0.004845412 Test MSE 0.013676755572319801 Test RE 0.005961480465764482\n",
      "58 Train Loss 0.0048431475 Test MSE 0.013844351320282158 Test RE 0.005997895409679015\n",
      "59 Train Loss 0.004834802 Test MSE 0.014795591236124036 Test RE 0.006200529023907179\n",
      "60 Train Loss 0.004815078 Test MSE 0.01708074726844975 Test RE 0.006662174685575126\n",
      "61 Train Loss 0.0046219947 Test MSE 0.04114014807505393 Test RE 0.010339404061493515\n",
      "62 Train Loss 0.0037043504 Test MSE 0.14028000607159305 Test RE 0.01909239762387622\n",
      "63 Train Loss 0.0023440155 Test MSE 0.10379583782185789 Test RE 0.016423002232836305\n",
      "64 Train Loss 0.0019827494 Test MSE 0.05001763772787093 Test RE 0.011400507138772142\n",
      "65 Train Loss 0.0019503711 Test MSE 0.045289240409827666 Test RE 0.010848260388147084\n",
      "66 Train Loss 0.001872744 Test MSE 0.033753735434916006 Test RE 0.009365339027139104\n",
      "67 Train Loss 0.001863716 Test MSE 0.03235523334255521 Test RE 0.009169271888028569\n",
      "68 Train Loss 0.0018608386 Test MSE 0.03206570360671266 Test RE 0.009128154233159165\n",
      "69 Train Loss 0.0018315435 Test MSE 0.028290828864820358 Test RE 0.008574038283635448\n",
      "70 Train Loss 0.0018220238 Test MSE 0.026908771427284844 Test RE 0.008361987564485411\n",
      "71 Train Loss 0.0017530654 Test MSE 0.014315740363101091 Test RE 0.006099152454736858\n",
      "72 Train Loss 0.0017373967 Test MSE 0.010699317279038978 Test RE 0.005272791708465841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 0.0017348675 Test MSE 0.010318758711716579 Test RE 0.005178170082079465\n",
      "74 Train Loss 0.0017275182 Test MSE 0.009050265733401642 Test RE 0.004849458510616591\n",
      "75 Train Loss 0.0017209906 Test MSE 0.007953697096407426 Test RE 0.00454618501694931\n",
      "76 Train Loss 0.0017151776 Test MSE 0.007052058059132141 Test RE 0.004280756473535283\n",
      "77 Train Loss 0.0017076759 Test MSE 0.006186679190343591 Test RE 0.004009510735878244\n",
      "78 Train Loss 0.0016996835 Test MSE 0.005309905758855689 Test RE 0.0037145481230884277\n",
      "79 Train Loss 0.0016932914 Test MSE 0.004808568573443891 Test RE 0.003534845930393575\n",
      "80 Train Loss 0.0014077824 Test MSE 0.00013529166807864295 Test RE 0.0005929227418570655\n",
      "81 Train Loss 0.00048756608 Test MSE 0.0013564104260112408 Test RE 0.0018774057436172758\n",
      "82 Train Loss 0.0004055222 Test MSE 0.0001654723089264442 Test RE 0.0006557302908758978\n",
      "83 Train Loss 0.0004011307 Test MSE 0.00012667928919588543 Test RE 0.00057374034662862\n",
      "84 Train Loss 0.00039225936 Test MSE 5.8961208132982786e-05 Test RE 0.00039142248465905437\n",
      "85 Train Loss 0.00038849935 Test MSE 4.1424149823388655e-05 Test RE 0.0003280872735153036\n",
      "86 Train Loss 0.00038012135 Test MSE 4.878324667462308e-06 Test RE 0.00011258951097655023\n",
      "87 Train Loss 0.00037382016 Test MSE 4.1450494511330255e-08 Test RE 1.0378329157410087e-05\n",
      "88 Train Loss 0.00036853284 Test MSE 1.5235732271947103e-05 Test RE 0.00019897304614918345\n",
      "89 Train Loss 0.00036464352 Test MSE 2.6135839359191895e-05 Test RE 0.00026060383870433047\n",
      "90 Train Loss 0.00036055467 Test MSE 5.152494975964047e-05 Test RE 0.00036590755031358757\n",
      "91 Train Loss 0.00035684707 Test MSE 7.257789916101675e-05 Test RE 0.0004342749500532303\n",
      "92 Train Loss 0.00035586036 Test MSE 8.333925008862774e-05 Test RE 0.00046535820610311176\n",
      "93 Train Loss 0.00035185833 Test MSE 0.0001099188447829683 Test RE 0.0005344396368741342\n",
      "94 Train Loss 0.00035098533 Test MSE 0.0001156347597384277 Test RE 0.0005481592962407553\n",
      "95 Train Loss 0.00034322886 Test MSE 0.00018852605770881676 Test RE 0.000699919793753355\n",
      "96 Train Loss 0.00034211163 Test MSE 0.00019672052707456127 Test RE 0.0007149693463069936\n",
      "97 Train Loss 0.0003402508 Test MSE 0.0002057039110582542 Test RE 0.0007311119071662299\n",
      "98 Train Loss 0.00033399524 Test MSE 0.00023301323184445443 Test RE 0.0007781312808228726\n",
      "99 Train Loss 0.00033135482 Test MSE 0.00022954012112493086 Test RE 0.0007723104046978996\n",
      "Training time: 61.14\n",
      "Training time: 61.14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.623303 Test MSE 382.06787805417275 Test RE 0.9963979967511758\n",
      "1 Train Loss 2.8492115 Test MSE 378.74016347517085 Test RE 0.9920493198105389\n",
      "2 Train Loss 2.3886578 Test MSE 381.34750979844574 Test RE 0.9954582263880437\n",
      "3 Train Loss 2.3622234 Test MSE 379.74658400699906 Test RE 0.9933665242018884\n",
      "4 Train Loss 2.347236 Test MSE 375.20610948895546 Test RE 0.9874100272817251\n",
      "5 Train Loss 2.3343453 Test MSE 373.2074480615479 Test RE 0.9847766300191406\n",
      "6 Train Loss 2.3103595 Test MSE 367.4933505593715 Test RE 0.9772087009015953\n",
      "7 Train Loss 2.2855592 Test MSE 366.8252099488025 Test RE 0.9763199639315494\n",
      "8 Train Loss 2.2444637 Test MSE 357.6567064095666 Test RE 0.9640415869959718\n",
      "9 Train Loss 2.211029 Test MSE 349.69505880785664 Test RE 0.9532511336185717\n",
      "10 Train Loss 2.1075478 Test MSE 333.05503363606454 Test RE 0.9302947785603329\n",
      "11 Train Loss 1.9692762 Test MSE 311.5379314840683 Test RE 0.8997421132968\n",
      "12 Train Loss 1.8889757 Test MSE 293.257743688571 Test RE 0.8729458947439205\n",
      "13 Train Loss 1.7461363 Test MSE 274.9379632092213 Test RE 0.845239798928564\n",
      "14 Train Loss 1.6791643 Test MSE 258.96993095090306 Test RE 0.8203274665499362\n",
      "15 Train Loss 1.4952896 Test MSE 219.72073486048902 Test RE 0.7556107082433596\n",
      "16 Train Loss 1.3475004 Test MSE 196.93069364680792 Test RE 0.7153511634643532\n",
      "17 Train Loss 1.1335258 Test MSE 168.86852425719107 Test RE 0.6624253388650361\n",
      "18 Train Loss 1.1028308 Test MSE 161.39520735755562 Test RE 0.647601579929989\n",
      "19 Train Loss 1.0127285 Test MSE 149.7869538820048 Test RE 0.6238778645931851\n",
      "20 Train Loss 0.8408086 Test MSE 111.04613427849335 Test RE 0.5371731598843369\n",
      "21 Train Loss 0.6537404 Test MSE 83.02407190305786 Test RE 0.46447741049871805\n",
      "22 Train Loss 0.49909452 Test MSE 65.07068356790285 Test RE 0.4112020461408319\n",
      "23 Train Loss 0.4689749 Test MSE 63.559332368997545 Test RE 0.4063986399586563\n",
      "24 Train Loss 0.45296764 Test MSE 59.057070392734516 Test RE 0.3917405531475941\n",
      "25 Train Loss 0.38792226 Test MSE 41.95640775494056 Test RE 0.33018833877169346\n",
      "26 Train Loss 0.35171318 Test MSE 39.12499774883941 Test RE 0.3188524404133161\n",
      "27 Train Loss 0.27260417 Test MSE 34.32865957511379 Test RE 0.29866958981191044\n",
      "28 Train Loss 0.19822803 Test MSE 20.392811086434165 Test RE 0.2301977797524633\n",
      "29 Train Loss 0.1594066 Test MSE 10.844937883073378 Test RE 0.1678711698588946\n",
      "30 Train Loss 0.13991591 Test MSE 7.054605663882854 Test RE 0.13539385500794127\n",
      "31 Train Loss 0.12211974 Test MSE 6.618784703575475 Test RE 0.131144991653283\n",
      "32 Train Loss 0.10878289 Test MSE 5.387455136378032 Test RE 0.11831897967021643\n",
      "33 Train Loss 0.081717655 Test MSE 2.529214797381798 Test RE 0.08106911640422668\n",
      "34 Train Loss 0.03606086 Test MSE 2.1486078748456974 Test RE 0.07472073996494483\n",
      "35 Train Loss 0.027262826 Test MSE 2.6800360986660245 Test RE 0.08345126117285992\n",
      "36 Train Loss 0.023912933 Test MSE 1.9625827784455796 Test RE 0.07141288432595512\n",
      "37 Train Loss 0.018218137 Test MSE 0.5950343876952909 Test RE 0.03932182037171307\n",
      "38 Train Loss 0.01552957 Test MSE 0.3224974537211858 Test RE 0.028948477494146124\n",
      "39 Train Loss 0.014050535 Test MSE 0.2649211792347765 Test RE 0.02623740760944757\n",
      "40 Train Loss 0.013082093 Test MSE 0.3591001811749878 Test RE 0.0305471286988309\n",
      "41 Train Loss 0.010184838 Test MSE 0.23303663501003644 Test RE 0.024607907340182814\n",
      "42 Train Loss 0.008385675 Test MSE 0.04074695311532146 Test RE 0.010289876262348906\n",
      "43 Train Loss 0.007993784 Test MSE 0.012348076438143632 Test RE 0.00566450855634096\n",
      "44 Train Loss 0.007815315 Test MSE 0.01799035081899871 Test RE 0.0068372647797157425\n",
      "45 Train Loss 0.0075955335 Test MSE 0.04688592514018263 Test RE 0.011037833214379896\n",
      "46 Train Loss 0.006868604 Test MSE 0.054230844184276136 Test RE 0.011870957905998077\n",
      "47 Train Loss 0.005858274 Test MSE 0.01323028816969991 Test RE 0.005863369105684253\n",
      "48 Train Loss 0.005581201 Test MSE 0.01602483461314315 Test RE 0.0064529657573994675\n",
      "49 Train Loss 0.0055323616 Test MSE 0.01733924720730671 Test RE 0.00671239803737574\n",
      "50 Train Loss 0.0048833373 Test MSE 0.004393015555017448 Test RE 0.0033786558210026118\n",
      "51 Train Loss 0.0038217744 Test MSE 5.940053201765671e-05 Test RE 0.00039287803582667674\n",
      "52 Train Loss 0.003038316 Test MSE 0.0004418095241873777 Test RE 0.001071470255761677\n",
      "53 Train Loss 0.0027733527 Test MSE 0.0010115693986599151 Test RE 0.0016212889545482471\n",
      "54 Train Loss 0.0027679745 Test MSE 0.001081992446672679 Test RE 0.0016767746402441006\n",
      "55 Train Loss 0.002762825 Test MSE 0.00126954320053723 Test RE 0.0018162947366968608\n",
      "56 Train Loss 0.0027591246 Test MSE 0.0014618340772183992 Test RE 0.0019489990316548039\n",
      "57 Train Loss 0.002757902 Test MSE 0.001506772762465451 Test RE 0.0019787296571598463\n",
      "58 Train Loss 0.002754428 Test MSE 0.0017496617853493485 Test RE 0.0021322574267063042\n",
      "59 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "60 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "61 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "62 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "63 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "64 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "66 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "67 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "68 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "69 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "70 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "71 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "72 Train Loss 0.0027492063 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "73 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "74 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "75 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "76 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "77 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "78 Train Loss 0.0027492063 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "79 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "80 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "81 Train Loss 0.0027492063 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "82 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "83 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "84 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "85 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "86 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "87 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "88 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "89 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "90 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "91 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "92 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "93 Train Loss 0.0027492063 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "94 Train Loss 0.0027492063 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "95 Train Loss 0.0027492063 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "96 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "97 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "98 Train Loss 0.002749206 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "99 Train Loss 0.0027492058 Test MSE 0.0022870868771376228 Test RE 0.002437832786160767\n",
      "Training time: 51.45\n",
      "Training time: 51.45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3.770248 Test MSE 383.1239353696976 Test RE 0.997774096830739\n",
      "1 Train Loss 2.4887984 Test MSE 385.20345781862954 Test RE 1.0004782945161097\n",
      "2 Train Loss 2.3821566 Test MSE 382.294828283158 Test RE 0.9966938855126809\n",
      "3 Train Loss 2.3794088 Test MSE 382.0104698421778 Test RE 0.9963231362622437\n",
      "4 Train Loss 2.3687794 Test MSE 380.76769029017714 Test RE 0.9947011666892501\n",
      "5 Train Loss 2.3551264 Test MSE 377.5768666126338 Test RE 0.9905246130353783\n",
      "6 Train Loss 2.3475454 Test MSE 376.9813893877766 Test RE 0.9897432256664858\n",
      "7 Train Loss 2.3313708 Test MSE 374.51971268520157 Test RE 0.9865064367986012\n",
      "8 Train Loss 2.32174 Test MSE 371.24036282264717 Test RE 0.9821779427755304\n",
      "9 Train Loss 2.3158753 Test MSE 369.6275121958165 Test RE 0.9800420885538371\n",
      "10 Train Loss 2.2547374 Test MSE 356.0306926457948 Test RE 0.9618476807250127\n",
      "11 Train Loss 2.2240849 Test MSE 351.34762793550937 Test RE 0.9555008889520039\n",
      "12 Train Loss 2.167844 Test MSE 340.888829954495 Test RE 0.9411719339738756\n",
      "13 Train Loss 2.1322978 Test MSE 340.51615569574614 Test RE 0.9406573285683362\n",
      "14 Train Loss 2.0493522 Test MSE 328.0630230169666 Test RE 0.9232965733863504\n",
      "15 Train Loss 1.9678113 Test MSE 306.4505879520056 Test RE 0.8923655830890167\n",
      "16 Train Loss 1.7932495 Test MSE 271.52374474123394 Test RE 0.8399752502777447\n",
      "17 Train Loss 1.6751145 Test MSE 259.9384416178927 Test RE 0.8218599889923487\n",
      "18 Train Loss 1.6145978 Test MSE 243.6721889287217 Test RE 0.7957296940793573\n",
      "19 Train Loss 1.5210196 Test MSE 234.39607440863637 Test RE 0.7804368179543772\n",
      "20 Train Loss 1.4101051 Test MSE 217.92705968943358 Test RE 0.7525201998962834\n",
      "21 Train Loss 1.3496741 Test MSE 210.12901891030012 Test RE 0.738933913323875\n",
      "22 Train Loss 1.2437615 Test MSE 184.99983238503887 Test RE 0.693343183150669\n",
      "23 Train Loss 1.0978271 Test MSE 157.91822063158793 Test RE 0.6405878592964316\n",
      "24 Train Loss 0.84356666 Test MSE 121.58801904173107 Test RE 0.5620927373722377\n",
      "25 Train Loss 0.741064 Test MSE 113.9411424636845 Test RE 0.5441302461743325\n",
      "26 Train Loss 0.6798764 Test MSE 101.43024680813836 Test RE 0.5133887216326701\n",
      "27 Train Loss 0.6454534 Test MSE 91.78371252784153 Test RE 0.48836596842466695\n",
      "28 Train Loss 0.52379334 Test MSE 73.65812409923005 Test RE 0.4374948143022089\n",
      "29 Train Loss 0.4685092 Test MSE 60.57771753774715 Test RE 0.3967519184861424\n",
      "30 Train Loss 0.37953728 Test MSE 51.107336683606654 Test RE 0.3644216811495296\n",
      "31 Train Loss 0.32358754 Test MSE 43.84301578692862 Test RE 0.33753032103641967\n",
      "32 Train Loss 0.28560027 Test MSE 37.76574893124562 Test RE 0.3132648253943114\n",
      "33 Train Loss 0.2576967 Test MSE 31.67026844373032 Test RE 0.2868721939314826\n",
      "34 Train Loss 0.18634032 Test MSE 22.708230741452 Test RE 0.2429149432082414\n",
      "35 Train Loss 0.13699003 Test MSE 13.432791628483258 Test RE 0.18682961614331303\n",
      "36 Train Loss 0.09422067 Test MSE 6.503293455800552 Test RE 0.12999578123777783\n",
      "37 Train Loss 0.025641283 Test MSE 1.7042611921088187 Test RE 0.06654733374325608\n",
      "38 Train Loss 0.020302853 Test MSE 1.215706072540445 Test RE 0.056205248920515184\n",
      "39 Train Loss 0.01172824 Test MSE 0.14908232328081594 Test RE 0.019682291457263513\n",
      "40 Train Loss 0.0057981396 Test MSE 0.14724849765154624 Test RE 0.0195608633320671\n",
      "41 Train Loss 0.0032597643 Test MSE 0.08298317998482573 Test RE 0.014684447780428258\n",
      "42 Train Loss 0.0019475068 Test MSE 0.0002968088331362879 Test RE 0.000878215288529033\n",
      "43 Train Loss 0.0013006091 Test MSE 0.0006359679061125348 Test RE 0.0012855239801360476\n",
      "44 Train Loss 0.0012828194 Test MSE 0.00039706872501438033 Test RE 0.001015770096087921\n",
      "45 Train Loss 0.0012760344 Test MSE 0.00030656976983909945 Test RE 0.000892539091445387\n",
      "46 Train Loss 0.001251834 Test MSE 9.515538117667323e-05 Test RE 0.0004972551150081209\n",
      "47 Train Loss 0.0010299789 Test MSE 7.324914443298514e-07 Test RE 4.362785496655341e-05\n",
      "48 Train Loss 0.00096921594 Test MSE 4.2324173921158843e-05 Test RE 0.0003316323036457807\n",
      "49 Train Loss 0.00096197653 Test MSE 6.227191373295941e-05 Test RE 0.0004022617038808932\n",
      "50 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "51 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "52 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "53 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "54 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "55 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "57 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "58 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "59 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "60 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "61 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "62 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "63 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "64 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "65 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "66 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "67 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "68 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "69 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "70 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "71 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "72 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "73 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "74 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "75 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "76 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "77 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "78 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "79 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "80 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "81 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "82 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "83 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "84 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "85 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "86 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "87 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "88 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "89 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "90 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "91 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "92 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "93 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "94 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "95 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "96 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "97 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "98 Train Loss 0.0009585166 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "99 Train Loss 0.00095851655 Test MSE 7.572407867696396e-05 Test RE 0.0004435877880657743\n",
      "Training time: 45.79\n",
      "Training time: 45.79\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.416309 Test MSE 376.58813579171874 Test RE 0.9892268584773534\n",
      "1 Train Loss 3.0944161 Test MSE 382.73120194495726 Test RE 0.9972625656061923\n",
      "2 Train Loss 2.4122791 Test MSE 385.479749852273 Test RE 1.000837033031542\n",
      "3 Train Loss 2.3963618 Test MSE 385.3485310121061 Test RE 1.0006666740790624\n",
      "4 Train Loss 2.3888137 Test MSE 384.1226144520278 Test RE 0.9990736862239266\n",
      "5 Train Loss 2.3786497 Test MSE 382.73835769486175 Test RE 0.997271888243225\n",
      "6 Train Loss 2.3711908 Test MSE 381.7244481964595 Test RE 0.9959500792824251\n",
      "7 Train Loss 2.3606308 Test MSE 379.80838123871706 Test RE 0.9934473475807329\n",
      "8 Train Loss 2.3232162 Test MSE 372.40146769385626 Test RE 0.983712691420072\n",
      "9 Train Loss 2.2772236 Test MSE 363.9132659180313 Test RE 0.9724371151016914\n",
      "10 Train Loss 2.239468 Test MSE 354.73950991354684 Test RE 0.9601019756806867\n",
      "11 Train Loss 2.1970453 Test MSE 341.05809171388546 Test RE 0.941405565342026\n",
      "12 Train Loss 2.0489368 Test MSE 323.99989721325056 Test RE 0.917561153609266\n",
      "13 Train Loss 2.0209014 Test MSE 322.56301838634613 Test RE 0.9155242869363032\n",
      "14 Train Loss 1.9373282 Test MSE 306.5236852375024 Test RE 0.892472004181102\n",
      "15 Train Loss 1.9063224 Test MSE 299.30363630388194 Test RE 0.8818984496627181\n",
      "16 Train Loss 1.8253771 Test MSE 284.8485795051489 Test RE 0.8603390024032574\n",
      "17 Train Loss 1.7328584 Test MSE 270.27058479393855 Test RE 0.838034645245482\n",
      "18 Train Loss 1.6131085 Test MSE 247.78516766047338 Test RE 0.8024172115653516\n",
      "19 Train Loss 1.4827667 Test MSE 224.02994395377146 Test RE 0.7629843283138548\n",
      "20 Train Loss 1.404967 Test MSE 210.83008311836716 Test RE 0.7401655584098356\n",
      "21 Train Loss 1.3614709 Test MSE 210.30760136643065 Test RE 0.7392478457078668\n",
      "22 Train Loss 1.320883 Test MSE 203.48723025331583 Test RE 0.7271619787331346\n",
      "23 Train Loss 1.2681246 Test MSE 195.0616445024694 Test RE 0.711948407918705\n",
      "24 Train Loss 1.1970716 Test MSE 180.57415182620792 Test RE 0.6849996890325225\n",
      "25 Train Loss 1.0758103 Test MSE 166.37255926237336 Test RE 0.6575116181742002\n",
      "26 Train Loss 1.0043209 Test MSE 150.24557678150356 Test RE 0.624832240077235\n",
      "27 Train Loss 0.9392825 Test MSE 137.7380507212904 Test RE 0.5982594243976171\n",
      "28 Train Loss 0.8699427 Test MSE 123.41361831185874 Test RE 0.5662968230574453\n",
      "29 Train Loss 0.7693919 Test MSE 102.53459708081895 Test RE 0.5161759872675239\n",
      "30 Train Loss 0.73844296 Test MSE 97.92479080298915 Test RE 0.5044392934849024\n",
      "31 Train Loss 0.68143916 Test MSE 85.12100276614906 Test RE 0.47030646431216516\n",
      "32 Train Loss 0.43976995 Test MSE 56.801818295519915 Test RE 0.3841879168170678\n",
      "33 Train Loss 0.3628187 Test MSE 44.199030215553194 Test RE 0.338897958562113\n",
      "34 Train Loss 0.32289225 Test MSE 40.42171970723169 Test RE 0.32409324233588865\n",
      "35 Train Loss 0.30097362 Test MSE 40.70137853388609 Test RE 0.3252124340768279\n",
      "36 Train Loss 0.27818912 Test MSE 36.692626383425846 Test RE 0.3087820043283488\n",
      "37 Train Loss 0.23257554 Test MSE 29.46021866896014 Test RE 0.27668178291091444\n",
      "38 Train Loss 0.22675735 Test MSE 28.85633096816918 Test RE 0.27383133124951214\n",
      "39 Train Loss 0.21448416 Test MSE 27.70452078167916 Test RE 0.2683106452638167\n",
      "40 Train Loss 0.17141828 Test MSE 22.781551339048903 Test RE 0.24330679044953238\n",
      "41 Train Loss 0.14136201 Test MSE 17.026750658570535 Test RE 0.21034319708699611\n",
      "42 Train Loss 0.11855523 Test MSE 11.167729950433522 Test RE 0.17035113611852357\n",
      "43 Train Loss 0.09149343 Test MSE 5.75233450565687 Test RE 0.12226007249604565\n",
      "44 Train Loss 0.05422737 Test MSE 2.148933683820733 Test RE 0.07472640497370853\n",
      "45 Train Loss 0.041219223 Test MSE 1.196334636931772 Test RE 0.05575565484798992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 0.031010913 Test MSE 0.50317982228174 Test RE 0.036159647757829996\n",
      "47 Train Loss 0.019519001 Test MSE 0.23661170702691078 Test RE 0.024795946857813972\n",
      "48 Train Loss 0.008444232 Test MSE 0.20031551788929997 Test RE 0.022814968822215714\n",
      "49 Train Loss 0.0074210307 Test MSE 0.21554217624999733 Test RE 0.02366621002107211\n",
      "50 Train Loss 0.0068432493 Test MSE 0.2461306413059627 Test RE 0.025289801709201414\n",
      "51 Train Loss 0.0064890874 Test MSE 0.26508868473177616 Test RE 0.026245701048888147\n",
      "52 Train Loss 0.0063210926 Test MSE 0.23721828256365285 Test RE 0.02482770984157497\n",
      "53 Train Loss 0.006291479 Test MSE 0.22456676313598006 Test RE 0.024156572971909263\n",
      "54 Train Loss 0.0061557326 Test MSE 0.15232394287252027 Test RE 0.01989512485305008\n",
      "55 Train Loss 0.005726125 Test MSE 0.07036878613478996 Test RE 0.013522363689171488\n",
      "56 Train Loss 0.004227804 Test MSE 0.013628889290572791 Test RE 0.005951039246269923\n",
      "57 Train Loss 0.0036531962 Test MSE 0.02284193400858213 Test RE 0.007704226082390317\n",
      "58 Train Loss 0.003498489 Test MSE 0.021535379191169577 Test RE 0.0074806415320061844\n",
      "59 Train Loss 0.0034952054 Test MSE 0.02118839834552276 Test RE 0.0074201322716794214\n",
      "60 Train Loss 0.003385155 Test MSE 0.008796029625517697 Test RE 0.004780858877050807\n",
      "61 Train Loss 0.0032288863 Test MSE 0.002810552467573098 Test RE 0.002702454751596742\n",
      "62 Train Loss 0.003000038 Test MSE 0.0007404693631888596 Test RE 0.0013871266949328225\n",
      "63 Train Loss 0.002991093 Test MSE 0.0006896800728222078 Test RE 0.0013387097348225498\n",
      "64 Train Loss 0.0028045806 Test MSE 0.00010317013214782505 Test RE 0.0005177732100025653\n",
      "65 Train Loss 0.002642522 Test MSE 0.0006796884711737489 Test RE 0.0013289772124165497\n",
      "66 Train Loss 0.002607781 Test MSE 0.0010044305214607404 Test RE 0.0016155579213849051\n",
      "67 Train Loss 0.0025979122 Test MSE 0.0010228907269338396 Test RE 0.0016303363184345155\n",
      "68 Train Loss 0.002517579 Test MSE 0.00014135521084926238 Test RE 0.000606064008472044\n",
      "69 Train Loss 0.0024992237 Test MSE 1.196779191755459e-06 Test RE 5.576601321358787e-05\n",
      "70 Train Loss 0.0024798224 Test MSE 0.00018701914869658092 Test RE 0.0006971169145735845\n",
      "71 Train Loss 0.0024762396 Test MSE 0.00030406816193387457 Test RE 0.0008888900747767114\n",
      "72 Train Loss 0.0024759762 Test MSE 0.0003194011298335378 Test RE 0.0009110260733540429\n",
      "73 Train Loss 0.002473799 Test MSE 0.00036372675810435797 Test RE 0.0009721878931288184\n",
      "74 Train Loss 0.0024735813 Test MSE 0.0003782769632921418 Test RE 0.0009914424947962362\n",
      "75 Train Loss 0.0024719436 Test MSE 0.0003865219722747476 Test RE 0.0010021891023614896\n",
      "76 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "77 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "78 Train Loss 0.0024631792 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "79 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "80 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "81 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "82 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "83 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "84 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "85 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "86 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "87 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "88 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "89 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "90 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "91 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "92 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "93 Train Loss 0.0024631792 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "94 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "95 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "96 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "97 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "98 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "99 Train Loss 0.0024631794 Test MSE 0.0004622994394325286 Test RE 0.0010960346040893474\n",
      "Training time: 62.46\n",
      "Training time: 62.46\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 4.137315 Test MSE 385.40992126078294 Test RE 1.0007463794944857\n",
      "1 Train Loss 2.524317 Test MSE 381.0863974705327 Test RE 0.9951173680935431\n",
      "2 Train Loss 2.381302 Test MSE 382.7772608488488 Test RE 0.9973225704328094\n",
      "3 Train Loss 2.375904 Test MSE 382.7135362970106 Test RE 0.9972395501156875\n",
      "4 Train Loss 2.3717322 Test MSE 381.00641191792573 Test RE 0.995012930897573\n",
      "5 Train Loss 2.3359916 Test MSE 373.62542881472075 Test RE 0.9853279353245389\n",
      "6 Train Loss 2.3038082 Test MSE 365.0235675342696 Test RE 0.9739194411308025\n",
      "7 Train Loss 2.2275782 Test MSE 356.5244708193703 Test RE 0.962514441824338\n",
      "8 Train Loss 2.174364 Test MSE 344.89622191153205 Test RE 0.9466878450148012\n",
      "9 Train Loss 2.129599 Test MSE 340.10455654124485 Test RE 0.9400886465476108\n",
      "10 Train Loss 2.0092344 Test MSE 312.1271006593851 Test RE 0.9005924911728985\n",
      "11 Train Loss 1.9386706 Test MSE 305.04180491484783 Test RE 0.8903120748140779\n",
      "12 Train Loss 1.8566326 Test MSE 286.8198192310194 Test RE 0.8633107750448008\n",
      "13 Train Loss 1.6377095 Test MSE 249.70422828980713 Test RE 0.8055185215270936\n",
      "14 Train Loss 1.5037146 Test MSE 231.6795238738227 Test RE 0.7759011731729427\n",
      "15 Train Loss 1.239629 Test MSE 157.33464291627664 Test RE 0.639403135941133\n",
      "16 Train Loss 1.0563304 Test MSE 145.83592291883946 Test RE 0.6155946541332423\n",
      "17 Train Loss 0.9527472 Test MSE 128.6912876214379 Test RE 0.5782786462241808\n",
      "18 Train Loss 0.7547063 Test MSE 98.63291180721622 Test RE 0.5062598775288883\n",
      "19 Train Loss 0.6759436 Test MSE 77.5610640044207 Test RE 0.4489360299150528\n",
      "20 Train Loss 0.57130396 Test MSE 59.35343631462338 Test RE 0.392722258297179\n",
      "21 Train Loss 0.4506266 Test MSE 39.35983447527222 Test RE 0.31980791957841553\n",
      "22 Train Loss 0.27717373 Test MSE 17.3691168538359 Test RE 0.21244741496530886\n",
      "23 Train Loss 0.15378498 Test MSE 9.373633362237099 Test RE 0.15606896987607558\n",
      "24 Train Loss 0.09761286 Test MSE 3.3800328321895416 Test RE 0.09371800648294733\n",
      "25 Train Loss 0.077448815 Test MSE 0.6913408190993404 Test RE 0.04238465792706285\n",
      "26 Train Loss 0.061277762 Test MSE 0.005197065250597576 Test RE 0.0036748673510774888\n",
      "27 Train Loss 0.055874433 Test MSE 0.10390135628086465 Test RE 0.016431347893536435\n",
      "28 Train Loss 0.044842843 Test MSE 0.02483191285694691 Test RE 0.008032813247214258\n",
      "29 Train Loss 0.038435586 Test MSE 0.16670255880682747 Test RE 0.020812953578859338\n",
      "30 Train Loss 0.024588631 Test MSE 0.9612215136201864 Test RE 0.04997747651342586\n",
      "31 Train Loss 0.021841519 Test MSE 0.6013519182252238 Test RE 0.039530010786814805\n",
      "32 Train Loss 0.019690746 Test MSE 0.17153766460034625 Test RE 0.021112629627352917\n",
      "33 Train Loss 0.016485794 Test MSE 0.12243870184906477 Test RE 0.017837005273324963\n",
      "34 Train Loss 0.015296131 Test MSE 0.18361940361932919 Test RE 0.021843481986359665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.015132345 Test MSE 0.23898916411741805 Test RE 0.024920209421064234\n",
      "36 Train Loss 0.015124432 Test MSE 0.24247635566524686 Test RE 0.02510136163275527\n",
      "37 Train Loss 0.01509163 Test MSE 0.2604350163377034 Test RE 0.026014307566743333\n",
      "38 Train Loss 0.015082947 Test MSE 0.26442727056374715 Test RE 0.026212938201590916\n",
      "39 Train Loss 0.015081329 Test MSE 0.26517637257469034 Test RE 0.026250041555960255\n",
      "40 Train Loss 0.015077793 Test MSE 0.26686116681109484 Test RE 0.026333299150484775\n",
      "41 Train Loss 0.015058844 Test MSE 0.2715173740417086 Test RE 0.026562038075480722\n",
      "42 Train Loss 0.01505522 Test MSE 0.27214577330325546 Test RE 0.026592757874902995\n",
      "43 Train Loss 0.015047659 Test MSE 0.2729172539104213 Test RE 0.02663042386128971\n",
      "44 Train Loss 0.01504368 Test MSE 0.27335799541843303 Test RE 0.026651918285280716\n",
      "45 Train Loss 0.0150083 Test MSE 0.27463103343474543 Test RE 0.026713905670749983\n",
      "46 Train Loss 0.014934859 Test MSE 0.26595852789761276 Test RE 0.026288726171751986\n",
      "47 Train Loss 0.013847068 Test MSE 0.13147267016819403 Test RE 0.01848333454486819\n",
      "48 Train Loss 0.010361498 Test MSE 0.1541918297874675 Test RE 0.020016736107073194\n",
      "49 Train Loss 0.00974797 Test MSE 0.20295913476406482 Test RE 0.022965022958058783\n",
      "50 Train Loss 0.008978506 Test MSE 0.1834840968604752 Test RE 0.021835432413785796\n",
      "51 Train Loss 0.007837655 Test MSE 0.06976674110517948 Test RE 0.013464393671062513\n",
      "52 Train Loss 0.007642989 Test MSE 0.03280666178655703 Test RE 0.0092330163202154\n",
      "53 Train Loss 0.0074679866 Test MSE 0.018714515999571017 Test RE 0.006973517296085155\n",
      "54 Train Loss 0.00738632 Test MSE 0.020189736727448483 Test RE 0.007243157192252194\n",
      "55 Train Loss 0.007277241 Test MSE 0.028338881042157264 Test RE 0.008581316727326961\n",
      "56 Train Loss 0.0072519216 Test MSE 0.02917717022292128 Test RE 0.00870731321756837\n",
      "57 Train Loss 0.0072423667 Test MSE 0.028804954840835676 Test RE 0.008651595018015695\n",
      "58 Train Loss 0.007240432 Test MSE 0.02733796098272838 Test RE 0.00842840977671789\n",
      "59 Train Loss 0.007238772 Test MSE 0.027277052970857 Test RE 0.008419015441534455\n",
      "60 Train Loss 0.0072315624 Test MSE 0.026599634085645567 Test RE 0.008313816098879224\n",
      "61 Train Loss 0.0072261738 Test MSE 0.025866131175664185 Test RE 0.008198385212266804\n",
      "62 Train Loss 0.007217174 Test MSE 0.024508627139746948 Test RE 0.007980352498556425\n",
      "63 Train Loss 0.00721098 Test MSE 0.023013601162386293 Test RE 0.007733122211497411\n",
      "64 Train Loss 0.0072088097 Test MSE 0.022681607027840344 Test RE 0.007677140582582599\n",
      "65 Train Loss 0.0072039454 Test MSE 0.021706291408312726 Test RE 0.007510267347158454\n",
      "66 Train Loss 0.007181564 Test MSE 0.017456597394506824 Test RE 0.006735074133932304\n",
      "67 Train Loss 0.0070522153 Test MSE 0.008723395930426573 Test RE 0.00476107885709652\n",
      "68 Train Loss 0.00681005 Test MSE 0.013425691017268404 Test RE 0.005906509495987193\n",
      "69 Train Loss 0.006202382 Test MSE 0.012107016044112429 Test RE 0.0056089444841300245\n",
      "70 Train Loss 0.005489165 Test MSE 0.0023281985405770615 Test RE 0.0024596458996947166\n",
      "71 Train Loss 0.0038151608 Test MSE 0.0001103506460184778 Test RE 0.0005354883446786329\n",
      "72 Train Loss 0.0028531498 Test MSE 0.0103334475194426 Test RE 0.00518185434768353\n",
      "73 Train Loss 0.002332478 Test MSE 0.02010049566883586 Test RE 0.007227131652041363\n",
      "74 Train Loss 0.0016998985 Test MSE 0.0035359498077990824 Test RE 0.0030312072314776914\n",
      "75 Train Loss 0.0014722239 Test MSE 7.969778997789216e-05 Test RE 0.0004550778753601779\n",
      "76 Train Loss 0.0013950525 Test MSE 0.0003183222053103353 Test RE 0.0009094860665126862\n",
      "77 Train Loss 0.0013418588 Test MSE 0.0014666609753259533 Test RE 0.0019522141252192073\n",
      "78 Train Loss 0.0012707367 Test MSE 0.005078408718667611 Test RE 0.0036326738519628205\n",
      "79 Train Loss 0.0012656287 Test MSE 0.005290312687603863 Test RE 0.0037076886164551714\n",
      "80 Train Loss 0.0012494605 Test MSE 0.005806721403390872 Test RE 0.0038844369573691347\n",
      "81 Train Loss 0.0012342148 Test MSE 0.0057901017168577 Test RE 0.0038788740605099005\n",
      "82 Train Loss 0.0012305712 Test MSE 0.005648707442026149 Test RE 0.00383122028688017\n",
      "83 Train Loss 0.0012231768 Test MSE 0.005215639841215759 Test RE 0.003681428580503018\n",
      "84 Train Loss 0.0012198718 Test MSE 0.004908745639864425 Test RE 0.0035714769106852365\n",
      "85 Train Loss 0.001215108 Test MSE 0.004455936844276598 Test RE 0.0034027660876123013\n",
      "86 Train Loss 0.001210444 Test MSE 0.003957530070658168 Test RE 0.0032068208178474404\n",
      "87 Train Loss 0.001209263 Test MSE 0.003845401346901065 Test RE 0.0031610649517985587\n",
      "88 Train Loss 0.0012014349 Test MSE 0.002935054179808315 Test RE 0.0027616627607662957\n",
      "89 Train Loss 0.0012002494 Test MSE 0.0029209084350610443 Test RE 0.002754999687773249\n",
      "90 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "91 Train Loss 0.0011958918 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "92 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "93 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "94 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "95 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "96 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "97 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "98 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "99 Train Loss 0.0011958919 Test MSE 0.0025939024333923133 Test RE 0.002596207503770348\n",
      "Training time: 59.01\n",
      "Training time: 59.01\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.2939425 Test MSE 383.26796832668236 Test RE 0.9979616325547044\n",
      "1 Train Loss 2.702107 Test MSE 381.0380541453537 Test RE 0.9950542474880655\n",
      "2 Train Loss 2.4269361 Test MSE 383.2838264660019 Test RE 0.9979822782285057\n",
      "3 Train Loss 2.3686855 Test MSE 380.8898173638188 Test RE 0.9948606736622078\n",
      "4 Train Loss 2.3613527 Test MSE 379.0359265210651 Test RE 0.9924365962297634\n",
      "5 Train Loss 2.2908907 Test MSE 364.80804133194806 Test RE 0.9736318759286078\n",
      "6 Train Loss 2.2682571 Test MSE 363.16724201830186 Test RE 0.9714398534212413\n",
      "7 Train Loss 2.2034943 Test MSE 350.0039926216707 Test RE 0.9536721096779999\n",
      "8 Train Loss 2.159219 Test MSE 339.99653032261637 Test RE 0.9399393361589852\n",
      "9 Train Loss 2.0131156 Test MSE 316.6437331992603 Test RE 0.9070850957085284\n",
      "10 Train Loss 1.9649491 Test MSE 310.18223978520405 Test RE 0.8977823153396518\n",
      "11 Train Loss 1.8240312 Test MSE 280.00905344658497 Test RE 0.8529991909883916\n",
      "12 Train Loss 1.6930414 Test MSE 262.32762589322806 Test RE 0.8256283496718877\n",
      "13 Train Loss 1.568339 Test MSE 231.19832136373265 Test RE 0.7750949740336813\n",
      "14 Train Loss 1.3102919 Test MSE 200.68216090781644 Test RE 0.722132626048391\n",
      "15 Train Loss 1.2638516 Test MSE 187.17383892066357 Test RE 0.6974051601428243\n",
      "16 Train Loss 1.0833048 Test MSE 166.1944846620037 Test RE 0.6571596446686987\n",
      "17 Train Loss 1.0086726 Test MSE 154.09444890357292 Test RE 0.6327848597504929\n",
      "18 Train Loss 0.83776546 Test MSE 115.54899083559621 Test RE 0.5479559674891702\n",
      "19 Train Loss 0.6064602 Test MSE 80.26598922554203 Test RE 0.4566972155551998\n",
      "20 Train Loss 0.5440756 Test MSE 62.26640295981376 Test RE 0.4022439043472987\n",
      "21 Train Loss 0.37251735 Test MSE 41.229762812320324 Test RE 0.32731657695877714\n",
      "22 Train Loss 0.2761088 Test MSE 31.734491888599564 Test RE 0.2871629175427519\n",
      "23 Train Loss 0.18392994 Test MSE 15.838058775283374 Test RE 0.20286800467385865\n",
      "24 Train Loss 0.090929374 Test MSE 2.7694043575879346 Test RE 0.0848312307994004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 0.059730724 Test MSE 0.10036330472231861 Test RE 0.01614916452601225\n",
      "26 Train Loss 0.04257008 Test MSE 0.0030954827714465578 Test RE 0.00283613420794047\n",
      "27 Train Loss 0.037649658 Test MSE 0.19818998592929568 Test RE 0.02269360210455604\n",
      "28 Train Loss 0.029111575 Test MSE 0.2604737096968901 Test RE 0.026016239994218256\n",
      "29 Train Loss 0.019442352 Test MSE 0.08122169546959172 Test RE 0.014527758373055923\n",
      "30 Train Loss 0.01223373 Test MSE 0.1156231495840448 Test RE 0.01733344873068329\n",
      "31 Train Loss 0.0068172556 Test MSE 0.011006113784850217 Test RE 0.005347854486367721\n",
      "32 Train Loss 0.006187152 Test MSE 0.0036791175871765305 Test RE 0.003091963914464836\n",
      "33 Train Loss 0.005919063 Test MSE 0.003146063057409916 Test RE 0.0028592115798133193\n",
      "34 Train Loss 0.0058999397 Test MSE 0.003256158980224313 Test RE 0.002908810190344968\n",
      "35 Train Loss 0.0058994265 Test MSE 0.0032561952449403657 Test RE 0.002908826388399569\n",
      "36 Train Loss 0.0058897743 Test MSE 0.003225104052306969 Test RE 0.002894905877426645\n",
      "37 Train Loss 0.005883757 Test MSE 0.003259830639172746 Test RE 0.0029104497217648764\n",
      "38 Train Loss 0.0058794473 Test MSE 0.003246853612401926 Test RE 0.0029046508549393796\n",
      "39 Train Loss 0.0056378464 Test MSE 0.002553190502485931 Test RE 0.0025757528714651663\n",
      "40 Train Loss 0.003487497 Test MSE 0.003283360278332641 Test RE 0.0029209347295585907\n",
      "41 Train Loss 0.0026973546 Test MSE 0.016084463081224062 Test RE 0.0064649603643331405\n",
      "42 Train Loss 0.0026642398 Test MSE 0.020068330078657874 Test RE 0.007221346769094924\n",
      "43 Train Loss 0.0026560582 Test MSE 0.02186654663020707 Test RE 0.007537940114064759\n",
      "44 Train Loss 0.0026546987 Test MSE 0.022332021993404547 Test RE 0.007617748072818582\n",
      "45 Train Loss 0.0026518656 Test MSE 0.022814936469426526 Test RE 0.0076996718130264855\n",
      "46 Train Loss 0.002631482 Test MSE 0.027867479570927157 Test RE 0.008509644714006535\n",
      "47 Train Loss 0.0026269061 Test MSE 0.028594287045243087 Test RE 0.008619899825891637\n",
      "48 Train Loss 0.0025971567 Test MSE 0.03504845488659125 Test RE 0.009543265820489895\n",
      "49 Train Loss 0.0024297035 Test MSE 0.047755255306866716 Test RE 0.011139691612357092\n",
      "50 Train Loss 0.002059749 Test MSE 0.024631871915023414 Test RE 0.008000392449869213\n",
      "51 Train Loss 0.0013481479 Test MSE 2.5993092717116777e-05 Test RE 0.00025989119167582576\n",
      "52 Train Loss 0.00076507044 Test MSE 0.0018535697031308394 Test RE 0.0021946589661033756\n",
      "53 Train Loss 0.0007343558 Test MSE 0.003049918600678831 Test RE 0.002815183489836124\n",
      "54 Train Loss 0.00069443276 Test MSE 0.005031082427186984 Test RE 0.0036157075731163613\n",
      "55 Train Loss 0.0006845077 Test MSE 0.004956450802692222 Test RE 0.0035887894737274347\n",
      "56 Train Loss 0.0005852588 Test MSE 0.002246849889471722 Test RE 0.002416293089106375\n",
      "57 Train Loss 0.0005776556 Test MSE 0.001883342633584979 Test RE 0.00221221458557689\n",
      "58 Train Loss 0.00054204656 Test MSE 0.0005274992040330572 Test RE 0.00117077512574468\n",
      "59 Train Loss 0.0005353001 Test MSE 0.00035056817736440896 Test RE 0.0009544404303472853\n",
      "60 Train Loss 0.00052883965 Test MSE 0.00023580343024409277 Test RE 0.0007827762525372851\n",
      "61 Train Loss 0.0005204459 Test MSE 0.00011563307869009678 Test RE 0.0005481553117744013\n",
      "62 Train Loss 0.00049849786 Test MSE 4.455596558740761e-08 Test RE 1.0760080301774523e-05\n",
      "63 Train Loss 0.0004802333 Test MSE 2.4506504922772845e-05 Test RE 0.00025234997798568627\n",
      "64 Train Loss 0.00047351982 Test MSE 2.189607332576851e-05 Test RE 0.00023853147950196965\n",
      "65 Train Loss 0.000430742 Test MSE 5.608168981545464e-06 Test RE 0.00012071830476057686\n",
      "66 Train Loss 0.00042678305 Test MSE 1.047050540514372e-05 Test RE 0.00016494775354862108\n",
      "67 Train Loss 0.00041225695 Test MSE 3.9431634026853645e-05 Test RE 0.00032009948080206414\n",
      "68 Train Loss 0.0004082304 Test MSE 4.2417283994957925e-05 Test RE 0.00033199688659636673\n",
      "69 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "70 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "71 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "72 Train Loss 0.00040540795 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "73 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "74 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "75 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "76 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "77 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "78 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "79 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "80 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "81 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "82 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "83 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "84 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "85 Train Loss 0.00040540795 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "86 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "87 Train Loss 0.00040540795 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "88 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "89 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "90 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "91 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "92 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "93 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "94 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "95 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "96 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "97 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "98 Train Loss 0.000405408 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "99 Train Loss 0.00040540798 Test MSE 4.2047891187683687e-05 Test RE 0.0003305481207003217\n",
      "Training time: 47.78\n",
      "Training time: 47.78\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.6160994 Test MSE 386.55956649150437 Test RE 1.0022378390452507\n",
      "1 Train Loss 3.1788125 Test MSE 384.470844312841 Test RE 0.9995264433172317\n",
      "2 Train Loss 2.4217758 Test MSE 382.8694235975951 Test RE 0.9974426277961945\n",
      "3 Train Loss 2.383907 Test MSE 383.76484339874537 Test RE 0.9986083101955371\n",
      "4 Train Loss 2.3777308 Test MSE 382.94039049992784 Test RE 0.9975350641849168\n",
      "5 Train Loss 2.377418 Test MSE 382.88957908051185 Test RE 0.9974688817512362\n",
      "6 Train Loss 2.3720732 Test MSE 380.23376510516863 Test RE 0.9940035204225204\n",
      "7 Train Loss 2.3548112 Test MSE 377.26096428213265 Test RE 0.9901101616506022\n",
      "8 Train Loss 2.3384545 Test MSE 370.4963509269781 Test RE 0.9811932457393535\n",
      "9 Train Loss 2.2404613 Test MSE 357.3275026096998 Test RE 0.9635978105879853\n",
      "10 Train Loss 2.1212156 Test MSE 336.63268300090624 Test RE 0.9352780063732444\n",
      "11 Train Loss 2.0709984 Test MSE 325.38235008390535 Test RE 0.9195166092095061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 1.9793038 Test MSE 313.99278119885554 Test RE 0.9032800414709854\n",
      "13 Train Loss 1.9388372 Test MSE 306.02588278537354 Test RE 0.8917470108141856\n",
      "14 Train Loss 1.8461099 Test MSE 283.457900750235 Test RE 0.8582362728155465\n",
      "15 Train Loss 1.6910188 Test MSE 253.35786250724223 Test RE 0.8113902331570441\n",
      "16 Train Loss 1.4013679 Test MSE 213.48754761337386 Test RE 0.7448157585640367\n",
      "17 Train Loss 1.2820225 Test MSE 196.82997023478742 Test RE 0.7151682010624042\n",
      "18 Train Loss 1.1604869 Test MSE 161.53355647738064 Test RE 0.6478790848134396\n",
      "19 Train Loss 0.91647977 Test MSE 131.23289731726828 Test RE 0.5839611311023166\n",
      "20 Train Loss 0.8010816 Test MSE 117.72870260829451 Test RE 0.5531001312794002\n",
      "21 Train Loss 0.76986116 Test MSE 109.1428755222531 Test RE 0.5325498643240275\n",
      "22 Train Loss 0.60234874 Test MSE 79.30505279688 Test RE 0.45395521732287103\n",
      "23 Train Loss 0.48117417 Test MSE 59.4963292307657 Test RE 0.3931947119355633\n",
      "24 Train Loss 0.42722505 Test MSE 45.232981219836965 Test RE 0.3428389754989907\n",
      "25 Train Loss 0.3764287 Test MSE 32.71313296357271 Test RE 0.291557120227254\n",
      "26 Train Loss 0.35452354 Test MSE 30.05926944659083 Test RE 0.27948068126452796\n",
      "27 Train Loss 0.3034138 Test MSE 28.176487286170364 Test RE 0.27058642653532916\n",
      "28 Train Loss 0.2567721 Test MSE 27.98689092737243 Test RE 0.26967451736202425\n",
      "29 Train Loss 0.21430776 Test MSE 28.364895752461948 Test RE 0.27148958797683126\n",
      "30 Train Loss 0.19664598 Test MSE 25.91376524025176 Test RE 0.2594943118877121\n",
      "31 Train Loss 0.14460781 Test MSE 16.92429838688015 Test RE 0.20970941045808633\n",
      "32 Train Loss 0.09137004 Test MSE 8.093684472475742 Test RE 0.14502261014069523\n",
      "33 Train Loss 0.054388385 Test MSE 3.5607153090843418 Test RE 0.09619028431908876\n",
      "34 Train Loss 0.045479402 Test MSE 2.3219894083207877 Test RE 0.07767704571444364\n",
      "35 Train Loss 0.031486772 Test MSE 0.9450948716323334 Test RE 0.04955646116937725\n",
      "36 Train Loss 0.01999713 Test MSE 0.5880654373944033 Test RE 0.03909087666047668\n",
      "37 Train Loss 0.01758389 Test MSE 0.5427976158850527 Test RE 0.03755619179258791\n",
      "38 Train Loss 0.014861822 Test MSE 0.7855084068950983 Test RE 0.0451791443196029\n",
      "39 Train Loss 0.013609571 Test MSE 1.0438686755655135 Test RE 0.052081743610185326\n",
      "40 Train Loss 0.01112714 Test MSE 0.9465083689636637 Test RE 0.0495935059974226\n",
      "41 Train Loss 0.0078679845 Test MSE 0.31194272530129546 Test RE 0.02847082248711782\n",
      "42 Train Loss 0.006776765 Test MSE 0.1405774095644125 Test RE 0.019112625522232224\n",
      "43 Train Loss 0.006180272 Test MSE 0.14608600450535347 Test RE 0.01948349606351009\n",
      "44 Train Loss 0.00550303 Test MSE 0.18528913315759352 Test RE 0.021942573274556922\n",
      "45 Train Loss 0.0051082624 Test MSE 0.1273009751316395 Test RE 0.018187727877451283\n",
      "46 Train Loss 0.0048788544 Test MSE 0.053423714795081324 Test RE 0.011782287727171962\n",
      "47 Train Loss 0.0048697097 Test MSE 0.05153744408104357 Test RE 0.011572415566914082\n",
      "48 Train Loss 0.0046408353 Test MSE 0.022365398638931527 Test RE 0.007623438555034379\n",
      "49 Train Loss 0.004434736 Test MSE 0.032012782432597565 Test RE 0.009120618578778586\n",
      "50 Train Loss 0.0043594358 Test MSE 0.034558308019102604 Test RE 0.009476300370828543\n",
      "51 Train Loss 0.0039852527 Test MSE 0.04324481831690367 Test RE 0.010600579830646877\n",
      "52 Train Loss 0.002964636 Test MSE 0.024187095284245976 Test RE 0.007927832034868135\n",
      "53 Train Loss 0.0026393551 Test MSE 0.003945941684328308 Test RE 0.003202122290989188\n",
      "54 Train Loss 0.0023079528 Test MSE 0.0012915635902890385 Test RE 0.0018319789505660284\n",
      "55 Train Loss 0.0019480732 Test MSE 0.010259492934673814 Test RE 0.005163278261984391\n",
      "56 Train Loss 0.0016515215 Test MSE 0.022952547680476196 Test RE 0.007722857681742797\n",
      "57 Train Loss 0.0012718848 Test MSE 0.009955613503169845 Test RE 0.005086237043672445\n",
      "58 Train Loss 0.0011079484 Test MSE 0.00012835136113258742 Test RE 0.0005775144056445708\n",
      "59 Train Loss 0.0011046275 Test MSE 6.346419798991701e-05 Test RE 0.000406094381252804\n",
      "60 Train Loss 0.0010975299 Test MSE 5.378502492821003e-07 Test RE 3.738464574528918e-05\n",
      "61 Train Loss 0.0010919182 Test MSE 4.1681779490547795e-05 Test RE 0.00032910593051481304\n",
      "62 Train Loss 0.0010903579 Test MSE 6.048052832869944e-05 Test RE 0.0003964335218439155\n",
      "63 Train Loss 0.0010868516 Test MSE 0.00011811768825393939 Test RE 0.0005540131226870527\n",
      "64 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "65 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "66 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "67 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "68 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "69 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "70 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "71 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "72 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "73 Train Loss 0.0010844679 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "74 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "75 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "76 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "77 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "78 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "79 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "80 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "81 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "82 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "83 Train Loss 0.0010844679 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "84 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "85 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "86 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "87 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "88 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "89 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "90 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "91 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "92 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "93 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "94 Train Loss 0.0010844679 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "95 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "96 Train Loss 0.0010844679 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "97 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "98 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "99 Train Loss 0.0010844677 Test MSE 0.00015186186573824727 Test RE 0.00062818411212661\n",
      "Training time: 62.86\n",
      "Training time: 62.86\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 3.0820105 Test MSE 381.8867048072554 Test RE 0.9961617271299008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 2.3988862 Test MSE 383.2586006649557 Test RE 0.9979494366175445\n",
      "2 Train Loss 2.379083 Test MSE 382.9189518944452 Test RE 0.9975071407005427\n",
      "3 Train Loss 2.3748853 Test MSE 381.05642498745544 Test RE 0.9950782342840536\n",
      "4 Train Loss 2.363305 Test MSE 379.1142061831994 Test RE 0.9925390714641023\n",
      "5 Train Loss 2.3431747 Test MSE 374.04687510959434 Test RE 0.9858834994515155\n",
      "6 Train Loss 2.280586 Test MSE 364.517420142188 Test RE 0.9732439809282387\n",
      "7 Train Loss 2.2202034 Test MSE 348.8107525642334 Test RE 0.9520450835124492\n",
      "8 Train Loss 2.0821009 Test MSE 321.1163710093001 Test RE 0.9134689844802071\n",
      "9 Train Loss 1.988815 Test MSE 316.52629768233675 Test RE 0.906916872126998\n",
      "10 Train Loss 1.8049664 Test MSE 279.79965670446944 Test RE 0.8526801858437603\n",
      "11 Train Loss 1.777154 Test MSE 271.2507714414319 Test RE 0.8395529143348016\n",
      "12 Train Loss 1.6368129 Test MSE 246.01401719917075 Test RE 0.7995442583396406\n",
      "13 Train Loss 1.4798735 Test MSE 221.986845740726 Test RE 0.7594972446761366\n",
      "14 Train Loss 1.377922 Test MSE 204.66767479918394 Test RE 0.7292680890650797\n",
      "15 Train Loss 1.2626302 Test MSE 187.44951911532783 Test RE 0.697918560013144\n",
      "16 Train Loss 1.1281432 Test MSE 170.41645537099305 Test RE 0.6654544696704424\n",
      "17 Train Loss 1.0122161 Test MSE 155.84142975551782 Test RE 0.6363617163363473\n",
      "18 Train Loss 0.9596407 Test MSE 144.99227609935065 Test RE 0.6138114935391146\n",
      "19 Train Loss 0.9101365 Test MSE 124.88358825538658 Test RE 0.5696593984109444\n",
      "20 Train Loss 0.83335996 Test MSE 111.97431227009609 Test RE 0.5394134664463158\n",
      "21 Train Loss 0.82403165 Test MSE 113.56505461837354 Test RE 0.5432314930454016\n",
      "22 Train Loss 0.7477202 Test MSE 108.23523829733804 Test RE 0.530330886702471\n",
      "23 Train Loss 0.60192543 Test MSE 85.61612700789308 Test RE 0.4716722993307534\n",
      "24 Train Loss 0.4751183 Test MSE 56.86929254848022 Test RE 0.38441603538510344\n",
      "25 Train Loss 0.43678296 Test MSE 51.02315758165526 Test RE 0.36412143724932716\n",
      "26 Train Loss 0.23084387 Test MSE 24.617516627309598 Test RE 0.2529208906494066\n",
      "27 Train Loss 0.2048434 Test MSE 22.284326539730497 Test RE 0.24063696384207092\n",
      "28 Train Loss 0.20165637 Test MSE 21.513862149451803 Test RE 0.23644044785704116\n",
      "29 Train Loss 0.2014706 Test MSE 21.464496654997298 Test RE 0.2361690251147446\n",
      "30 Train Loss 0.20098238 Test MSE 21.62924911220528 Test RE 0.2370736596351534\n",
      "31 Train Loss 0.19971149 Test MSE 22.19369625538725 Test RE 0.24014713041803873\n",
      "32 Train Loss 0.1969616 Test MSE 21.64124442682389 Test RE 0.23713938958604724\n",
      "33 Train Loss 0.18589005 Test MSE 16.06272198291416 Test RE 0.20430178156474788\n",
      "34 Train Loss 0.17824067 Test MSE 14.325234041003563 Test RE 0.19293607782624267\n",
      "35 Train Loss 0.1743449 Test MSE 13.752024904713437 Test RE 0.18903660440387154\n",
      "36 Train Loss 0.15976682 Test MSE 13.666239639076446 Test RE 0.18844607594054302\n",
      "37 Train Loss 0.11616853 Test MSE 14.567598807729139 Test RE 0.19456134898098562\n",
      "38 Train Loss 0.09775518 Test MSE 10.76998705026852 Test RE 0.16729007392782821\n",
      "39 Train Loss 0.070151836 Test MSE 5.46284487029657 Test RE 0.1191439561042793\n",
      "40 Train Loss 0.056532964 Test MSE 4.569134121289193 Test RE 0.10896312140607113\n",
      "41 Train Loss 0.053176004 Test MSE 3.6141644758920615 Test RE 0.0969095415266217\n",
      "42 Train Loss 0.0416321 Test MSE 2.786648380027878 Test RE 0.08509492677829204\n",
      "43 Train Loss 0.037998993 Test MSE 2.4122530606996677 Test RE 0.07917243744836268\n",
      "44 Train Loss 0.033586185 Test MSE 1.1284425968211802 Test RE 0.054150480963202685\n",
      "45 Train Loss 0.031366214 Test MSE 0.6221663605371962 Test RE 0.04020831239325449\n",
      "46 Train Loss 0.028553776 Test MSE 0.5920164534296356 Test RE 0.03922197612341931\n",
      "47 Train Loss 0.026162285 Test MSE 0.3945575014179047 Test RE 0.03201973511555856\n",
      "48 Train Loss 0.019880958 Test MSE 0.02749632786397349 Test RE 0.008452787115556413\n",
      "49 Train Loss 0.018503182 Test MSE 0.02144076724168418 Test RE 0.007464190994084371\n",
      "50 Train Loss 0.017473621 Test MSE 0.0719118337563448 Test RE 0.013669819002098094\n",
      "51 Train Loss 0.0155131575 Test MSE 0.06233727668013417 Test RE 0.012727306273645095\n",
      "52 Train Loss 0.014486835 Test MSE 0.005852276072100512 Test RE 0.003899644207942889\n",
      "53 Train Loss 0.013745445 Test MSE 0.008574621985369573 Test RE 0.004720305139692421\n",
      "54 Train Loss 0.012802827 Test MSE 0.08721844920649618 Test RE 0.015054514791884317\n",
      "55 Train Loss 0.012350476 Test MSE 0.19170586954616567 Test RE 0.022319285500303144\n",
      "56 Train Loss 0.011984907 Test MSE 0.22827997882141993 Test RE 0.024355468852035437\n",
      "57 Train Loss 0.011956929 Test MSE 0.23585343886889887 Test RE 0.024756183261543524\n",
      "58 Train Loss 0.011944273 Test MSE 0.24021501099840528 Test RE 0.02498403927780592\n",
      "59 Train Loss 0.0119442735 Test MSE 0.24021501099840528 Test RE 0.02498403927780592\n",
      "60 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "61 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "62 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "63 Train Loss 0.011943428 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "64 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "65 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "66 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "67 Train Loss 0.011943428 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "68 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "69 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "70 Train Loss 0.011943428 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "71 Train Loss 0.011943428 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "72 Train Loss 0.011943427 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "73 Train Loss 0.011943428 Test MSE 0.2402132296541057 Test RE 0.0249839466415084\n",
      "74 Train Loss 0.011943423 Test MSE 0.24021137599029369 Test RE 0.024983850243971963\n",
      "75 Train Loss 0.011943423 Test MSE 0.24021137599029369 Test RE 0.024983850243971963\n",
      "76 Train Loss 0.011943423 Test MSE 0.24021137599029369 Test RE 0.024983850243971963\n",
      "77 Train Loss 0.011943423 Test MSE 0.24021137599029369 Test RE 0.024983850243971963\n",
      "78 Train Loss 0.011939421 Test MSE 0.2435167561653109 Test RE 0.025155155569606034\n",
      "79 Train Loss 0.011938582 Test MSE 0.2440327652840746 Test RE 0.02518179320405037\n",
      "80 Train Loss 0.01193351 Test MSE 0.24805717154138038 Test RE 0.025388583802139125\n",
      "81 Train Loss 0.011931245 Test MSE 0.24942518961546503 Test RE 0.025458495683124336\n",
      "82 Train Loss 0.011930998 Test MSE 0.2494248797635331 Test RE 0.025458479870033173\n",
      "83 Train Loss 0.011930413 Test MSE 0.2502585138157598 Test RE 0.025500988364521276\n",
      "84 Train Loss 0.011922321 Test MSE 0.2557873851061273 Test RE 0.025781141566301066\n",
      "85 Train Loss 0.011921899 Test MSE 0.25595939267944123 Test RE 0.025789808542447574\n",
      "86 Train Loss 0.011903181 Test MSE 0.26770582443939606 Test RE 0.026374940745850218\n",
      "87 Train Loss 0.0118877925 Test MSE 0.27701882899390723 Test RE 0.026829787137841142\n",
      "88 Train Loss 0.011871318 Test MSE 0.285783172372722 Test RE 0.027250903696735464\n",
      "89 Train Loss 0.011727481 Test MSE 0.2920367851839558 Test RE 0.02754744737035533\n",
      "90 Train Loss 0.011481467 Test MSE 0.20340206979361294 Test RE 0.02299006856482352\n",
      "91 Train Loss 0.011349253 Test MSE 0.15576064703248244 Test RE 0.02011830805339964\n",
      "92 Train Loss 0.010572334 Test MSE 0.061193594040552614 Test RE 0.012610013835070068\n",
      "93 Train Loss 0.009329687 Test MSE 0.05885222259096867 Test RE 0.012366420701726819\n",
      "94 Train Loss 0.008627735 Test MSE 0.06566454284830307 Test RE 0.013062552383598802\n",
      "95 Train Loss 0.0076598017 Test MSE 0.05124880597362425 Test RE 0.011539964112188635\n",
      "96 Train Loss 0.0067813266 Test MSE 0.01957179369319571 Test RE 0.00713145091136909\n",
      "97 Train Loss 0.005922675 Test MSE 0.007931134682536594 Test RE 0.004539732309946375\n",
      "98 Train Loss 0.0048952424 Test MSE 0.010029303299265999 Test RE 0.005105026079964165\n",
      "99 Train Loss 0.0042378623 Test MSE 0.01637977294254641 Test RE 0.0065240385885758905\n",
      "Training time: 80.04\n",
      "Training time: 80.04\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 3.9519536 Test MSE 380.9617632476982 Test RE 0.9949546283278021\n",
      "1 Train Loss 2.4262605 Test MSE 380.5889016592397 Test RE 0.9944676093976711\n",
      "2 Train Loss 2.3796227 Test MSE 381.7984921767634 Test RE 0.9960466679770582\n",
      "3 Train Loss 2.3607337 Test MSE 380.15548551194706 Test RE 0.99390119626889\n",
      "4 Train Loss 2.3237433 Test MSE 372.0211025798393 Test RE 0.9832101885915553\n",
      "5 Train Loss 2.298262 Test MSE 363.6714192712287 Test RE 0.9721139340525727\n",
      "6 Train Loss 2.2327154 Test MSE 354.25271340099454 Test RE 0.959442992496107\n",
      "7 Train Loss 2.0995111 Test MSE 322.24698063423625 Test RE 0.9150756751493786\n",
      "8 Train Loss 1.9432217 Test MSE 302.1502175575553 Test RE 0.8860822526884555\n",
      "9 Train Loss 1.8747851 Test MSE 281.24853426762553 Test RE 0.8548850383909479\n",
      "10 Train Loss 1.7822778 Test MSE 271.8933196720152 Test RE 0.8405467071739215\n",
      "11 Train Loss 1.662439 Test MSE 254.17917394527126 Test RE 0.812704312923235\n",
      "12 Train Loss 1.5217332 Test MSE 221.39444629695424 Test RE 0.7584831613513994\n",
      "13 Train Loss 1.3802149 Test MSE 216.0770703669497 Test RE 0.749319309070512\n",
      "14 Train Loss 1.2559336 Test MSE 189.60737429000966 Test RE 0.7019241658723344\n",
      "15 Train Loss 1.1421113 Test MSE 165.01255000155726 Test RE 0.6548186955814744\n",
      "16 Train Loss 1.0924476 Test MSE 136.2422364582669 Test RE 0.5950020534800575\n",
      "17 Train Loss 0.94851863 Test MSE 110.00706188465867 Test RE 0.5346540553393921\n",
      "18 Train Loss 0.8042471 Test MSE 97.18346529384968 Test RE 0.5025262735777907\n",
      "19 Train Loss 0.7437331 Test MSE 91.46089962289994 Test RE 0.487506394892954\n",
      "20 Train Loss 0.63878584 Test MSE 92.86111599233101 Test RE 0.4912239486957278\n",
      "21 Train Loss 0.5895263 Test MSE 77.2915795414055 Test RE 0.44815544137965646\n",
      "22 Train Loss 0.5196102 Test MSE 60.32606462565114 Test RE 0.3959269642882968\n",
      "23 Train Loss 0.48525912 Test MSE 41.1742918086854 Test RE 0.3270963150785077\n",
      "24 Train Loss 0.39712277 Test MSE 28.743980663346417 Test RE 0.2732977388562707\n",
      "25 Train Loss 0.24963634 Test MSE 17.601004924924904 Test RE 0.2138608628734146\n",
      "26 Train Loss 0.16417047 Test MSE 8.220631627762295 Test RE 0.14615550448519923\n",
      "27 Train Loss 0.06493242 Test MSE 2.344708032490636 Test RE 0.07805612152825234\n",
      "28 Train Loss 0.042051665 Test MSE 0.8796793673085098 Test RE 0.04781066511883275\n",
      "29 Train Loss 0.031703215 Test MSE 0.22052574908612368 Test RE 0.023938241030800545\n",
      "30 Train Loss 0.022068985 Test MSE 0.1647331519082803 Test RE 0.020689647267465232\n",
      "31 Train Loss 0.014601328 Test MSE 0.21031211465656535 Test RE 0.023377320317652595\n",
      "32 Train Loss 0.013000271 Test MSE 0.5938593791587452 Test RE 0.03928297698089384\n",
      "33 Train Loss 0.012097631 Test MSE 0.5438472828767853 Test RE 0.03759248750732612\n",
      "34 Train Loss 0.008218042 Test MSE 0.2505604555552287 Test RE 0.02551636744508546\n",
      "35 Train Loss 0.0075876773 Test MSE 0.16111042855031057 Test RE 0.02046088474218551\n",
      "36 Train Loss 0.006133299 Test MSE 0.0192572375437031 Test RE 0.007073910753409177\n",
      "37 Train Loss 0.0048544696 Test MSE 0.011024347439111334 Test RE 0.0053522825060513535\n",
      "38 Train Loss 0.0044957446 Test MSE 0.021846644950366412 Test RE 0.007534509032256011\n",
      "39 Train Loss 0.0044889683 Test MSE 0.0226485488929466 Test RE 0.00767154387837423\n",
      "40 Train Loss 0.0044545336 Test MSE 0.027127396122130696 Test RE 0.008395888011104947\n",
      "41 Train Loss 0.004446537 Test MSE 0.02753941677182989 Test RE 0.008459407613896552\n",
      "42 Train Loss 0.0043899417 Test MSE 0.02859341580913958 Test RE 0.008619768505514054\n",
      "43 Train Loss 0.0043327203 Test MSE 0.024438275475801546 Test RE 0.00796889052338737\n",
      "44 Train Loss 0.0043107723 Test MSE 0.02122070601632176 Test RE 0.007425787155865032\n",
      "45 Train Loss 0.0043028626 Test MSE 0.019793262123078782 Test RE 0.007171686067777298\n",
      "46 Train Loss 0.004293215 Test MSE 0.018280834145955837 Test RE 0.00689224309210332\n",
      "47 Train Loss 0.00426835 Test MSE 0.01421526294600238 Test RE 0.006077710804945869\n",
      "48 Train Loss 0.004169111 Test MSE 0.002934632190932804 Test RE 0.0027614642239108854\n",
      "49 Train Loss 0.0038318085 Test MSE 0.00017662083516227227 Test RE 0.0006774598311456198\n",
      "50 Train Loss 0.003365564 Test MSE 0.010161712438131243 Test RE 0.005138614439770184\n",
      "51 Train Loss 0.002723664 Test MSE 0.001639220213147577 Test RE 0.0020638647468864493\n",
      "52 Train Loss 0.0020101431 Test MSE 0.0018130971909681188 Test RE 0.0021705666455632835\n",
      "53 Train Loss 0.0019168486 Test MSE 0.0007363748435216605 Test RE 0.0013832862316121442\n",
      "54 Train Loss 0.0019119851 Test MSE 0.0005907484138949923 Test RE 0.0012389787696943536\n",
      "55 Train Loss 0.0019070596 Test MSE 0.00044157844648088696 Test RE 0.0010711900159088173\n",
      "56 Train Loss 0.0019033861 Test MSE 0.0003307592702498241 Test RE 0.0009270829522149364\n",
      "57 Train Loss 0.0018968398 Test MSE 0.00018362207115249051 Test RE 0.0006907565684901918\n",
      "58 Train Loss 0.0018918243 Test MSE 0.00011096709621229015 Test RE 0.000536981956986784\n",
      "59 Train Loss 0.0018855395 Test MSE 4.9900946338893364e-05 Test RE 0.0003600949024085329\n",
      "60 Train Loss 0.0018791805 Test MSE 8.883647452909465e-06 Test RE 0.00015193514342622946\n",
      "61 Train Loss 0.0018359623 Test MSE 0.0012489682516428507 Test RE 0.00180151665687345\n",
      "62 Train Loss 0.0018339967 Test MSE 0.0013537334520689812 Test RE 0.0018755522307400535\n",
      "63 Train Loss 0.0018309096 Test MSE 0.001482731173142112 Test RE 0.0019628801885795077\n",
      "64 Train Loss 0.0018219467 Test MSE 0.0016953708026433748 Test RE 0.0020989153916511744\n",
      "65 Train Loss 0.0018146683 Test MSE 0.00174804459558581 Test RE 0.0021312717899170442\n",
      "66 Train Loss 0.0018085706 Test MSE 0.0018083656136397256 Test RE 0.00216773256882769\n",
      "67 Train Loss 0.0017820378 Test MSE 0.00150647432403428 Test RE 0.0019785336892498427\n",
      "68 Train Loss 0.0017758134 Test MSE 0.0012858426308596206 Test RE 0.0018279170874480762\n",
      "69 Train Loss 0.0017125616 Test MSE 0.00014283342087192342 Test RE 0.0006092246980583469\n",
      "70 Train Loss 0.0017050948 Test MSE 0.0001281640122584855 Test RE 0.0005770927654529469\n",
      "71 Train Loss 0.0016588825 Test MSE 0.00019670604931289797 Test RE 0.0007149430365303701\n",
      "72 Train Loss 0.0015442637 Test MSE 0.0047139809120737095 Test RE 0.003499906903109989\n",
      "73 Train Loss 0.0015371346 Test MSE 0.005292938602582787 Test RE 0.0037086086818457356\n",
      "74 Train Loss 0.0015048154 Test MSE 0.007988804560724073 Test RE 0.004556207355654678\n",
      "75 Train Loss 0.0014682134 Test MSE 0.009045669164120338 Test RE 0.004848226850478499\n",
      "76 Train Loss 0.0014487846 Test MSE 0.007507039656431672 Test RE 0.004416690199605064\n",
      "77 Train Loss 0.0014338178 Test MSE 0.005567889513395607 Test RE 0.003803714279134494\n",
      "78 Train Loss 0.0014304054 Test MSE 0.00524582674703808 Test RE 0.0036920668343806105\n",
      "79 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "80 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "81 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "82 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "83 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "84 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "85 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "86 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "87 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "88 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "89 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "90 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "91 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "92 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "93 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "94 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "95 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "96 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "97 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 Train Loss 0.0014224015 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "99 Train Loss 0.0014224014 Test MSE 0.004437229624880144 Test RE 0.0033956157120403683\n",
      "Training time: 56.82\n",
      "Training time: 56.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 2.9424214 Test MSE 384.64250407884174 Test RE 0.999749554289699\n",
      "1 Train Loss 2.478117 Test MSE 382.79963927710565 Test RE 0.997351723399404\n",
      "2 Train Loss 2.384405 Test MSE 384.0682474185495 Test RE 0.9990029814638125\n",
      "3 Train Loss 2.3803966 Test MSE 383.4768394374386 Test RE 0.9982335271301893\n",
      "4 Train Loss 2.3794637 Test MSE 383.1624684991177 Test RE 0.9978242717065202\n",
      "5 Train Loss 2.3671296 Test MSE 380.5936749873898 Test RE 0.9944738456611694\n",
      "6 Train Loss 2.3508258 Test MSE 375.9997193191455 Test RE 0.9884537261424252\n",
      "7 Train Loss 2.332339 Test MSE 369.93961452674034 Test RE 0.9804557602501014\n",
      "8 Train Loss 2.254864 Test MSE 358.5340346046007 Test RE 0.9652232547971903\n",
      "9 Train Loss 2.1140213 Test MSE 331.2000241220724 Test RE 0.9277004396191391\n",
      "10 Train Loss 2.050278 Test MSE 325.0868426187497 Test RE 0.9190989686333396\n",
      "11 Train Loss 1.9893206 Test MSE 311.8121935600569 Test RE 0.9001380696619039\n",
      "12 Train Loss 1.9420035 Test MSE 300.61845678498946 Test RE 0.8838333868799535\n",
      "13 Train Loss 1.7565341 Test MSE 266.45572185670824 Test RE 0.8320992065290717\n",
      "14 Train Loss 1.6066347 Test MSE 243.99521112579828 Test RE 0.7962569459302309\n",
      "15 Train Loss 1.3877838 Test MSE 191.83719830110854 Test RE 0.7060394924748349\n",
      "16 Train Loss 1.0864615 Test MSE 144.70681806077587 Test RE 0.6132069656432141\n",
      "17 Train Loss 0.8430576 Test MSE 113.0917698864301 Test RE 0.5420983469258622\n",
      "18 Train Loss 0.8231296 Test MSE 105.36337476237622 Test RE 0.523247809360983\n",
      "19 Train Loss 0.67638034 Test MSE 93.964243809337 Test RE 0.4941330403193584\n",
      "20 Train Loss 0.58662796 Test MSE 82.45755211473426 Test RE 0.462890003034925\n",
      "21 Train Loss 0.53807104 Test MSE 67.94376770103914 Test RE 0.42018195330377167\n",
      "22 Train Loss 0.45713764 Test MSE 52.07962723131735 Test RE 0.3678718158509036\n",
      "23 Train Loss 0.29145488 Test MSE 22.573915404776226 Test RE 0.24219547738857267\n",
      "24 Train Loss 0.16305017 Test MSE 18.011307446712344 Test RE 0.21633919148294542\n",
      "25 Train Loss 0.120573804 Test MSE 12.927835102004108 Test RE 0.18328439254462026\n",
      "26 Train Loss 0.11382156 Test MSE 9.59880864641023 Test RE 0.15793240524585112\n",
      "27 Train Loss 0.108069666 Test MSE 8.232892894715938 Test RE 0.14626446107237775\n",
      "28 Train Loss 0.09264913 Test MSE 4.190048985574168 Test RE 0.1043451175580727\n",
      "29 Train Loss 0.060175784 Test MSE 0.4025421007672212 Test RE 0.03234210158655313\n",
      "30 Train Loss 0.043413676 Test MSE 0.26748073160472685 Test RE 0.02636385010435295\n",
      "31 Train Loss 0.03721422 Test MSE 0.07048180061158776 Test RE 0.013533218002852912\n",
      "32 Train Loss 0.01604752 Test MSE 0.018833598885335104 Test RE 0.006995668809967496\n",
      "33 Train Loss 0.009172648 Test MSE 0.13211584197730541 Test RE 0.018528490150260608\n",
      "34 Train Loss 0.008942681 Test MSE 0.09596552396303419 Test RE 0.015791384273661717\n",
      "35 Train Loss 0.008926803 Test MSE 0.0884424513760738 Test RE 0.015159782424386635\n",
      "36 Train Loss 0.008919398 Test MSE 0.08692569163544242 Test RE 0.015029227551335386\n",
      "37 Train Loss 0.008911275 Test MSE 0.08521241339320525 Test RE 0.01488037977421516\n",
      "38 Train Loss 0.008688321 Test MSE 0.10138883328303995 Test RE 0.01623146222153407\n",
      "39 Train Loss 0.00821088 Test MSE 0.13650581407405432 Test RE 0.01883380880051311\n",
      "40 Train Loss 0.0066948817 Test MSE 0.009797737754314634 Test RE 0.005045747201602535\n",
      "41 Train Loss 0.003346662 Test MSE 0.0008531441191807648 Test RE 0.0014889282953964842\n",
      "42 Train Loss 0.002389391 Test MSE 0.02410349955190979 Test RE 0.007914120042065525\n",
      "43 Train Loss 0.0014249684 Test MSE 0.0021696463035397124 Test RE 0.002374417327578651\n",
      "44 Train Loss 0.00075320667 Test MSE 4.959587039699649e-07 Test RE 3.589924712923714e-05\n",
      "45 Train Loss 0.0004970605 Test MSE 0.006925086272834376 Test RE 0.00424204407595777\n",
      "46 Train Loss 0.00020352629 Test MSE 6.739961442905078e-05 Test RE 0.0004184959780547522\n",
      "47 Train Loss 0.00019815518 Test MSE 2.3277654300570607e-05 Test RE 0.0002459417107337758\n",
      "48 Train Loss 0.00019398131 Test MSE 1.0058881720672278e-05 Test RE 0.00016167297621325094\n",
      "49 Train Loss 0.00017934159 Test MSE 3.1237916903840714e-05 Test RE 0.00028490732502443276\n",
      "50 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "51 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "52 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "53 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "54 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "55 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "56 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "57 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "58 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "59 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "60 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "61 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "62 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "63 Train Loss 0.00017821016 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "64 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "65 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "66 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "67 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "68 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "69 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "70 Train Loss 0.00017821016 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "71 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "72 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "73 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "74 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "75 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "76 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "77 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "78 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "79 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "80 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "81 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "82 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "83 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "84 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "85 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "86 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "88 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "89 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "90 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "91 Train Loss 0.00017821016 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "92 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "93 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "94 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "95 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "96 Train Loss 0.00017821013 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "97 Train Loss 0.00017821015 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "98 Train Loss 0.00017821016 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "99 Train Loss 0.00017821016 Test MSE 3.393385355691128e-05 Test RE 0.00029694715803833767\n",
      "Training time: 51.62\n",
      "Training time: 51.62\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 3.2178693 Test MSE 383.12935529850495 Test RE 0.997781154397424\n",
      "1 Train Loss 2.3864899 Test MSE 383.3224362528547 Test RE 0.9980325424322941\n",
      "2 Train Loss 2.3842072 Test MSE 382.94029360702115 Test RE 0.997534937985017\n",
      "3 Train Loss 2.3774886 Test MSE 383.12356417431255 Test RE 0.9977736134764041\n",
      "4 Train Loss 2.370514 Test MSE 381.45941826016906 Test RE 0.9956042769382849\n",
      "5 Train Loss 2.3440442 Test MSE 374.1656854704408 Test RE 0.9860400625485438\n",
      "6 Train Loss 2.303669 Test MSE 368.4896895396763 Test RE 0.9785324964083312\n",
      "7 Train Loss 2.2536926 Test MSE 359.32258809791557 Test RE 0.9662841193894899\n",
      "8 Train Loss 2.1763775 Test MSE 346.8919781356476 Test RE 0.9494229182140982\n",
      "9 Train Loss 2.0500796 Test MSE 319.2992927296473 Test RE 0.9108808270719656\n",
      "10 Train Loss 1.9720271 Test MSE 307.90676669576357 Test RE 0.8944832226713364\n",
      "11 Train Loss 1.8816519 Test MSE 291.08095678336537 Test RE 0.8697000187115758\n",
      "12 Train Loss 1.798467 Test MSE 276.1671171989211 Test RE 0.8471270815576597\n",
      "13 Train Loss 1.6732463 Test MSE 255.26105081696386 Test RE 0.814432055554616\n",
      "14 Train Loss 1.6233206 Test MSE 251.3469645734154 Test RE 0.808163821744788\n",
      "15 Train Loss 1.5392174 Test MSE 232.9671492748088 Test RE 0.7780543322699099\n",
      "16 Train Loss 1.4074446 Test MSE 205.05738365120644 Test RE 0.7299620605751714\n",
      "17 Train Loss 1.2485454 Test MSE 182.98255753401773 Test RE 0.6895526458679024\n",
      "18 Train Loss 1.0883486 Test MSE 164.61438764439185 Test RE 0.654028205336575\n",
      "19 Train Loss 1.0053524 Test MSE 147.21447536933715 Test RE 0.6184973459102264\n",
      "20 Train Loss 0.96537256 Test MSE 127.53666008183563 Test RE 0.5756786222655987\n",
      "21 Train Loss 0.8495954 Test MSE 112.3453292982611 Test RE 0.5403063769349126\n",
      "22 Train Loss 0.69622326 Test MSE 96.32911361482296 Test RE 0.5003125126410801\n",
      "23 Train Loss 0.53057784 Test MSE 73.06284819416402 Test RE 0.43572339780824204\n",
      "24 Train Loss 0.28447166 Test MSE 39.19502442721981 Test RE 0.319137656984047\n",
      "25 Train Loss 0.23306781 Test MSE 28.18304652855046 Test RE 0.2706179197917177\n",
      "26 Train Loss 0.18961269 Test MSE 22.789510232723693 Test RE 0.2433492871993791\n",
      "27 Train Loss 0.13367483 Test MSE 11.550222546655196 Test RE 0.17324382292356116\n",
      "28 Train Loss 0.10561387 Test MSE 4.3256043044881185 Test RE 0.10601955497251489\n",
      "29 Train Loss 0.056214944 Test MSE 2.0539555469119133 Test RE 0.07305637222525309\n",
      "30 Train Loss 0.015930286 Test MSE 1.5717243166885067 Test RE 0.06390734401874146\n",
      "31 Train Loss 0.010611088 Test MSE 0.39737545003328834 Test RE 0.03213387492278511\n",
      "32 Train Loss 0.010013327 Test MSE 0.3380036727521223 Test RE 0.02963625290284535\n",
      "33 Train Loss 0.00847157 Test MSE 0.21346481086583055 Test RE 0.023551888086401074\n",
      "34 Train Loss 0.007834515 Test MSE 0.28019628665893653 Test RE 0.026983219749818085\n",
      "35 Train Loss 0.006591371 Test MSE 0.35625411485084973 Test RE 0.03042583650095627\n",
      "36 Train Loss 0.005847021 Test MSE 0.30383671806724794 Test RE 0.028098472463193067\n",
      "37 Train Loss 0.0028313447 Test MSE 0.03800344612990705 Test RE 0.009937429772118585\n",
      "38 Train Loss 0.0010383148 Test MSE 1.9788977336867267e-05 Test RE 0.00022676407778818468\n",
      "39 Train Loss 0.0010211462 Test MSE 3.020927808332642e-07 Test RE 2.8017717757902876e-05\n",
      "40 Train Loss 0.0010183951 Test MSE 6.442894752754101e-07 Test RE 4.091693564597798e-05\n",
      "41 Train Loss 0.0010144536 Test MSE 6.554729889390345e-06 Test RE 0.00013050885588508927\n",
      "42 Train Loss 0.0010060791 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "43 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "44 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "45 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "46 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "47 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "48 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "49 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "50 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "51 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "52 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "53 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "54 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "55 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "56 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "57 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "58 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "59 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "60 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "61 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "62 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "63 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "64 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "65 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "66 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "67 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "68 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "69 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "70 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "71 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "72 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "73 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "74 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "75 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "77 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "78 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "79 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "80 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "81 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "82 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "83 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "84 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "85 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "86 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "87 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "88 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "89 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "90 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "91 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "92 Train Loss 0.0010060791 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "93 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "94 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "95 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "96 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "97 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "98 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "99 Train Loss 0.0010060793 Test MSE 7.473684738824918e-05 Test RE 0.0004406867263505038\n",
      "Training time: 38.99\n",
      "Training time: 38.99\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 3.701905 Test MSE 380.42075998957023 Test RE 0.994247910510162\n",
      "1 Train Loss 2.3893788 Test MSE 382.05008812441497 Test RE 0.9963747992282556\n",
      "2 Train Loss 2.3547199 Test MSE 377.71421940665823 Test RE 0.9907047603966611\n",
      "3 Train Loss 2.328548 Test MSE 370.60688524223093 Test RE 0.9813395999953353\n",
      "4 Train Loss 2.3016055 Test MSE 366.54591512780956 Test RE 0.975948215990454\n",
      "5 Train Loss 2.255905 Test MSE 359.0393858948756 Test RE 0.9659032530841712\n",
      "6 Train Loss 2.2184913 Test MSE 351.6431068028259 Test RE 0.9559025865355975\n",
      "7 Train Loss 2.116652 Test MSE 335.2000942112134 Test RE 0.933285779537755\n",
      "8 Train Loss 2.02118 Test MSE 318.01145269904987 Test RE 0.9090420287183084\n",
      "9 Train Loss 1.9604695 Test MSE 308.3525936955529 Test RE 0.8951305623307579\n",
      "10 Train Loss 1.7004492 Test MSE 251.73874527015437 Test RE 0.8087934289090446\n",
      "11 Train Loss 1.4429609 Test MSE 217.4581728491769 Test RE 0.7517102114120939\n",
      "12 Train Loss 1.3245769 Test MSE 199.57390134639786 Test RE 0.7201358905981705\n",
      "13 Train Loss 1.2307415 Test MSE 188.88643126350547 Test RE 0.7005884338462756\n",
      "14 Train Loss 1.0669348 Test MSE 152.87523154471359 Test RE 0.6302765461243107\n",
      "15 Train Loss 0.97625446 Test MSE 140.69368995535427 Test RE 0.6046442016998597\n",
      "16 Train Loss 0.87477976 Test MSE 119.55906873732216 Test RE 0.5573831611846425\n",
      "17 Train Loss 0.7443629 Test MSE 93.02871364538942 Test RE 0.49166703440885673\n",
      "18 Train Loss 0.59265685 Test MSE 74.57240865233496 Test RE 0.44020165188438065\n",
      "19 Train Loss 0.5041952 Test MSE 69.53906007999296 Test RE 0.42508618473919413\n",
      "20 Train Loss 0.3895511 Test MSE 57.68799140640675 Test RE 0.38717320312101505\n",
      "21 Train Loss 0.30189392 Test MSE 35.17345670987217 Test RE 0.3023222479179647\n",
      "22 Train Loss 0.22270823 Test MSE 19.719451627310008 Test RE 0.22636537589083333\n",
      "23 Train Loss 0.15554878 Test MSE 15.79201877064203 Test RE 0.20257292932440416\n",
      "24 Train Loss 0.10595173 Test MSE 7.4390557099282875 Test RE 0.13903415062566407\n",
      "25 Train Loss 0.07361634 Test MSE 3.063436404490562 Test RE 0.08922098571701287\n",
      "26 Train Loss 0.036993846 Test MSE 2.210265337426152 Test RE 0.07578526769111156\n",
      "27 Train Loss 0.01786881 Test MSE 0.6389963432440663 Test RE 0.04074851336766261\n",
      "28 Train Loss 0.014088897 Test MSE 0.5056573488752187 Test RE 0.036248558799643976\n",
      "29 Train Loss 0.011742385 Test MSE 0.5785817115921366 Test RE 0.03877438636408282\n",
      "30 Train Loss 0.007411723 Test MSE 0.21981258122188574 Test RE 0.023899502223375887\n",
      "31 Train Loss 0.0058621075 Test MSE 0.04565247122854221 Test RE 0.010891676365134571\n",
      "32 Train Loss 0.0054171025 Test MSE 1.83732254612611e-05 Test RE 0.0002185019336858672\n",
      "33 Train Loss 0.0052358806 Test MSE 0.0002009122346177559 Test RE 0.0007225464549100542\n",
      "34 Train Loss 0.0047442513 Test MSE 0.0019796610056942044 Test RE 0.0022680780566340744\n",
      "35 Train Loss 0.00471286 Test MSE 0.0013301654521397338 Test RE 0.001859154210331576\n",
      "36 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "37 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "38 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "39 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "40 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "41 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "42 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "43 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "44 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "45 Train Loss 0.0047076396 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "46 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "47 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "48 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "49 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "50 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "51 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "52 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "53 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "54 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "55 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "56 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "57 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "58 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "59 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "60 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "61 Train Loss 0.0047076396 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "62 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "63 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "64 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "65 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "66 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "68 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "69 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "70 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "71 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "72 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "73 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "74 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "75 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "76 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "77 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "78 Train Loss 0.0047076396 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "79 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "80 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "81 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "82 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "83 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "84 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "85 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "86 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "87 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "88 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "89 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "90 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "91 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "92 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "93 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "94 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "95 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "96 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "97 Train Loss 0.00470764 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "98 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "99 Train Loss 0.0047076405 Test MSE 0.001071580424987739 Test RE 0.0016686873294800098\n",
      "Training time: 35.70\n",
      "Training time: 35.70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3.3056178 Test MSE 384.4522712647249 Test RE 0.9995023004242067\n",
      "1 Train Loss 2.5399349 Test MSE 385.7055980517775 Test RE 1.001130179615153\n",
      "2 Train Loss 2.4176784 Test MSE 383.1434025710608 Test RE 0.9977994458375888\n",
      "3 Train Loss 2.3800442 Test MSE 382.13452368125223 Test RE 0.9964848958043725\n",
      "4 Train Loss 2.364737 Test MSE 381.1048596703999 Test RE 0.9951414726448394\n",
      "5 Train Loss 2.3596785 Test MSE 379.76265390363585 Test RE 0.9933875423349816\n",
      "6 Train Loss 2.3438718 Test MSE 375.31150697373215 Test RE 0.9875487020303703\n",
      "7 Train Loss 2.3171642 Test MSE 369.5904634005802 Test RE 0.9799929711486699\n",
      "8 Train Loss 2.277399 Test MSE 364.50374237317885 Test RE 0.9732257212642255\n",
      "9 Train Loss 2.2118905 Test MSE 351.46974772815236 Test RE 0.9556669288276931\n",
      "10 Train Loss 2.1368325 Test MSE 337.49647602650214 Test RE 0.9364771903326726\n",
      "11 Train Loss 2.0730124 Test MSE 328.0105723136938 Test RE 0.9232227621259993\n",
      "12 Train Loss 1.988318 Test MSE 315.2862173074835 Test RE 0.9051385783190475\n",
      "13 Train Loss 1.8958199 Test MSE 290.0559504422141 Test RE 0.8681673966357117\n",
      "14 Train Loss 1.826164 Test MSE 285.4452526232059 Test RE 0.8612396082847007\n",
      "15 Train Loss 1.788494 Test MSE 279.37169887793016 Test RE 0.8520278426556573\n",
      "16 Train Loss 1.6392586 Test MSE 254.6270581856403 Test RE 0.8134200231072719\n",
      "17 Train Loss 1.5708108 Test MSE 239.38738751975376 Test RE 0.7887024958269809\n",
      "18 Train Loss 1.4989523 Test MSE 220.04048907109464 Test RE 0.7561603192471236\n",
      "19 Train Loss 1.2585944 Test MSE 189.42645540149576 Test RE 0.7015892062013739\n",
      "20 Train Loss 1.171668 Test MSE 177.20572212835359 Test RE 0.6785806217022057\n",
      "21 Train Loss 1.1161528 Test MSE 165.96320546315243 Test RE 0.6567022279549417\n",
      "22 Train Loss 1.0580083 Test MSE 158.07526383093557 Test RE 0.6409062993354501\n",
      "23 Train Loss 0.99565274 Test MSE 153.2481401399885 Test RE 0.6310447947904223\n",
      "24 Train Loss 0.9086186 Test MSE 135.7198017858577 Test RE 0.5938601598944853\n",
      "25 Train Loss 0.8748998 Test MSE 130.57816400647715 Test RE 0.5825025910297196\n",
      "26 Train Loss 0.7960278 Test MSE 121.29810769716443 Test RE 0.5614222177100907\n",
      "27 Train Loss 0.70491374 Test MSE 109.15558604068684 Test RE 0.532580873163457\n",
      "28 Train Loss 0.55767566 Test MSE 74.28695828839983 Test RE 0.43935833595943086\n",
      "29 Train Loss 0.50726444 Test MSE 69.82599850088928 Test RE 0.4259622966162548\n",
      "30 Train Loss 0.47052187 Test MSE 59.95500311156664 Test RE 0.394707426178344\n",
      "31 Train Loss 0.42671335 Test MSE 55.235539704110835 Test RE 0.378854005661122\n",
      "32 Train Loss 0.3728384 Test MSE 47.77923457646377 Test RE 0.3523564100468513\n",
      "33 Train Loss 0.33588904 Test MSE 42.70033749572324 Test RE 0.33310276397890026\n",
      "34 Train Loss 0.2634469 Test MSE 35.398800316870194 Test RE 0.30328913637658284\n",
      "35 Train Loss 0.21399835 Test MSE 23.949783905314018 Test RE 0.24946715953173\n",
      "36 Train Loss 0.16222371 Test MSE 20.403909622716842 Test RE 0.23026041238515801\n",
      "37 Train Loss 0.114961065 Test MSE 15.095514914045236 Test RE 0.19805533630539224\n",
      "38 Train Loss 0.10076512 Test MSE 13.490633688323525 Test RE 0.18723143140656417\n",
      "39 Train Loss 0.090313315 Test MSE 11.13696121688631 Test RE 0.17011630307772393\n",
      "40 Train Loss 0.0811358 Test MSE 10.28659298228255 Test RE 0.16349269794294666\n",
      "41 Train Loss 0.05456297 Test MSE 5.115955901066886 Test RE 0.11529911628991091\n",
      "42 Train Loss 0.034439195 Test MSE 2.877744574903071 Test RE 0.08647462840535702\n",
      "43 Train Loss 0.029916948 Test MSE 2.042923686495537 Test RE 0.07285991402759727\n",
      "44 Train Loss 0.028349657 Test MSE 1.4700140690591104 Test RE 0.061804959783190366\n",
      "45 Train Loss 0.022646036 Test MSE 0.45867369050917506 Test RE 0.03452347450310107\n",
      "46 Train Loss 0.011368476 Test MSE 0.3440422800035627 Test RE 0.029899814303170902\n",
      "47 Train Loss 0.008525607 Test MSE 0.24955321718199153 Test RE 0.025465028646191795\n",
      "48 Train Loss 0.0067519145 Test MSE 0.015479511025062247 Test RE 0.006342218519455269\n",
      "49 Train Loss 0.006389527 Test MSE 0.005433176958432147 Test RE 0.003757417966287255\n",
      "50 Train Loss 0.0063717654 Test MSE 0.005199564561434548 Test RE 0.0036757508816256095\n",
      "51 Train Loss 0.00626772 Test MSE 0.0027735053618671646 Test RE 0.002684584556039882\n",
      "52 Train Loss 0.0058205565 Test MSE 0.0026930608830491305 Test RE 0.0026453653970701122\n",
      "53 Train Loss 0.0053907777 Test MSE 0.0011026893910290653 Test RE 0.0016927358053511693\n",
      "54 Train Loss 0.0044348687 Test MSE 0.005861261521612265 Test RE 0.003902636771528832\n",
      "55 Train Loss 0.0042547383 Test MSE 0.01852995332701096 Test RE 0.006939045660274539\n",
      "56 Train Loss 0.004175662 Test MSE 0.031448338771412315 Test RE 0.009039854432034098\n",
      "57 Train Loss 0.0034082222 Test MSE 0.0009148200617448469 Test RE 0.0015418084535520273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.003147871 Test MSE 0.0025639771061076676 Test RE 0.0025811880989381163\n",
      "59 Train Loss 0.0031433697 Test MSE 0.002704720563400675 Test RE 0.002651085802818091\n",
      "60 Train Loss 0.0031101126 Test MSE 0.0032377267152212813 Test RE 0.0029005654988842554\n",
      "61 Train Loss 0.0031051165 Test MSE 0.003204594604000818 Test RE 0.0028856863893769536\n",
      "62 Train Loss 0.0030978085 Test MSE 0.0028952584731513943 Test RE 0.00274287649713593\n",
      "63 Train Loss 0.002729591 Test MSE 1.4575618622024473e-05 Test RE 0.00019461489696839096\n",
      "64 Train Loss 0.0025019043 Test MSE 0.005942580879557584 Test RE 0.003929616178611611\n",
      "65 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "66 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "67 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "68 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "69 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "70 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "71 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "72 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "73 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "74 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "75 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "76 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "77 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "78 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "79 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "80 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "81 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "82 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "83 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "84 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "85 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "86 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "87 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "88 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "89 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "90 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "91 Train Loss 0.002496194 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "92 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "93 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "94 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "95 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "96 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "97 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "98 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "99 Train Loss 0.0024961943 Test MSE 0.007303432264689491 Test RE 0.004356383308960135\n",
      "Training time: 52.43\n",
      "Training time: 52.43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 3.7618747 Test MSE 378.9771003766898 Test RE 0.9923595804645466\n",
      "1 Train Loss 2.4562166 Test MSE 384.9961049828206 Test RE 1.0002089823741773\n",
      "2 Train Loss 2.399452 Test MSE 384.33625618249346 Test RE 0.9993514805440911\n",
      "3 Train Loss 2.380534 Test MSE 383.0501726272452 Test RE 0.9976780416254208\n",
      "4 Train Loss 2.3651834 Test MSE 380.9312998411372 Test RE 0.9949148470213489\n",
      "5 Train Loss 2.3534389 Test MSE 378.2690554901381 Test RE 0.991432131791504\n",
      "6 Train Loss 2.3411992 Test MSE 375.0497764472576 Test RE 0.9872042991608463\n",
      "7 Train Loss 2.2795403 Test MSE 364.63253009830527 Test RE 0.973397637821881\n",
      "8 Train Loss 2.2311091 Test MSE 352.50287980798464 Test RE 0.9570704716327959\n",
      "9 Train Loss 2.1955383 Test MSE 346.66875613347133 Test RE 0.9491173963179923\n",
      "10 Train Loss 2.1599877 Test MSE 345.8451824982708 Test RE 0.947989326870103\n",
      "11 Train Loss 2.1055107 Test MSE 332.54688708405416 Test RE 0.9295848260222531\n",
      "12 Train Loss 2.0520387 Test MSE 323.32636848636366 Test RE 0.9166069475883571\n",
      "13 Train Loss 1.9616036 Test MSE 311.96068715850066 Test RE 0.9003523794834828\n",
      "14 Train Loss 1.8302222 Test MSE 290.04688158333636 Test RE 0.8681538245143112\n",
      "15 Train Loss 1.7568288 Test MSE 275.107284366439 Test RE 0.8455000302754201\n",
      "16 Train Loss 1.6448916 Test MSE 256.3791550202108 Test RE 0.8162138097561122\n",
      "17 Train Loss 1.5775455 Test MSE 245.12264591135047 Test RE 0.7980944679161519\n",
      "18 Train Loss 1.4999257 Test MSE 229.2076896128917 Test RE 0.7717509527429194\n",
      "19 Train Loss 1.3899335 Test MSE 210.4097941737983 Test RE 0.7394274317929964\n",
      "20 Train Loss 1.2604537 Test MSE 183.27935737466308 Test RE 0.6901116504952742\n",
      "21 Train Loss 1.088276 Test MSE 143.67544948711398 Test RE 0.611017803663249\n",
      "22 Train Loss 0.8978939 Test MSE 111.78809389951077 Test RE 0.5389647452521152\n",
      "23 Train Loss 0.7679569 Test MSE 100.64030339610835 Test RE 0.5113856665888101\n",
      "24 Train Loss 0.68769693 Test MSE 93.18768307330923 Test RE 0.4920869405982929\n",
      "25 Train Loss 0.60654014 Test MSE 83.15938395774714 Test RE 0.4648557574305301\n",
      "26 Train Loss 0.50254536 Test MSE 73.10415424432587 Test RE 0.4358465484237598\n",
      "27 Train Loss 0.46265456 Test MSE 67.03013592046274 Test RE 0.4173473233899078\n",
      "28 Train Loss 0.40975484 Test MSE 55.709337093871454 Test RE 0.38047539611766695\n",
      "29 Train Loss 0.34096053 Test MSE 49.33215866077331 Test RE 0.35803677973343834\n",
      "30 Train Loss 0.29210752 Test MSE 38.35458616608802 Test RE 0.3156975657086497\n",
      "31 Train Loss 0.24425079 Test MSE 31.682381012233694 Test RE 0.2869270470649898\n",
      "32 Train Loss 0.2060098 Test MSE 25.289400925454594 Test RE 0.25634913321538544\n",
      "33 Train Loss 0.18080562 Test MSE 17.98270012002911 Test RE 0.21616731763797256\n",
      "34 Train Loss 0.1645439 Test MSE 17.05594647377053 Test RE 0.21052345786988508\n",
      "35 Train Loss 0.14460626 Test MSE 16.132513179507825 Test RE 0.20474513765997898\n",
      "36 Train Loss 0.14197856 Test MSE 15.792018049614805 Test RE 0.20257292469989727\n",
      "37 Train Loss 0.12389861 Test MSE 13.005882038391688 Test RE 0.18383681528980708\n",
      "38 Train Loss 0.08763687 Test MSE 8.974039059341056 Test RE 0.1527061613656012\n",
      "39 Train Loss 0.04996971 Test MSE 3.6039820851965754 Test RE 0.09677293086284666\n",
      "40 Train Loss 0.0338171 Test MSE 2.0891680982299734 Test RE 0.07367994199381499\n",
      "41 Train Loss 0.025608944 Test MSE 0.6927247954045717 Test RE 0.04242706106084342\n",
      "42 Train Loss 0.023902446 Test MSE 0.3762001758868822 Test RE 0.0312659824417416\n",
      "43 Train Loss 0.014709565 Test MSE 0.11546816281896558 Test RE 0.017321827545725834\n",
      "44 Train Loss 0.011797677 Test MSE 0.08856485806616776 Test RE 0.015170269566782546\n",
      "45 Train Loss 0.009429643 Test MSE 0.0002989831026730252 Test RE 0.0008814260968400617\n",
      "46 Train Loss 0.007670126 Test MSE 0.04137981914940189 Test RE 0.010369477573056592\n",
      "47 Train Loss 0.0064829346 Test MSE 0.1916759771924946 Test RE 0.02231754532931267\n",
      "48 Train Loss 0.0059435423 Test MSE 0.15353923522348512 Test RE 0.01997433222571168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 0.0055468115 Test MSE 0.20958023885543356 Test RE 0.02333660890667285\n",
      "50 Train Loss 0.004886654 Test MSE 0.15504974457747905 Test RE 0.020072344868175048\n",
      "51 Train Loss 0.003969135 Test MSE 0.019897147807071035 Test RE 0.007190481870061162\n",
      "52 Train Loss 0.0037256987 Test MSE 0.005705365019417192 Test RE 0.003850386270224192\n",
      "53 Train Loss 0.0037178197 Test MSE 0.005947038010460005 Test RE 0.003931089573010349\n",
      "54 Train Loss 0.0037095393 Test MSE 0.006419377325914736 Test RE 0.004084219123534417\n",
      "55 Train Loss 0.0036560062 Test MSE 0.012360254090815448 Test RE 0.005667301032537092\n",
      "56 Train Loss 0.0036497014 Test MSE 0.013846183485213905 Test RE 0.005998292278041698\n",
      "57 Train Loss 0.0036057183 Test MSE 0.01875342759007617 Test RE 0.00698076326884912\n",
      "58 Train Loss 0.0028532075 Test MSE 0.00030673210723092156 Test RE 0.0008927753725571695\n",
      "59 Train Loss 0.001246723 Test MSE 0.0009301368926580961 Test RE 0.0015546621229526598\n",
      "60 Train Loss 0.0008767529 Test MSE 0.0007543833468144927 Test RE 0.0014000986242777185\n",
      "61 Train Loss 0.0008290745 Test MSE 0.0010077035671631409 Test RE 0.0016181880157965184\n",
      "62 Train Loss 0.00080833404 Test MSE 0.0011881396118332032 Test RE 0.0017570993583111345\n",
      "63 Train Loss 0.0007994282 Test MSE 0.0012586051775837295 Test RE 0.0018084534713302082\n",
      "64 Train Loss 0.00074566354 Test MSE 0.0013883078199000691 Test RE 0.0018993520396725925\n",
      "65 Train Loss 0.000740807 Test MSE 0.0013651787150169977 Test RE 0.001883464056828089\n",
      "66 Train Loss 0.0007123185 Test MSE 0.0009700033437039541 Test RE 0.0015876296395996889\n",
      "67 Train Loss 0.0007051779 Test MSE 0.00078135426994043 Test RE 0.0014249071884971081\n",
      "68 Train Loss 0.0007005514 Test MSE 0.0006754936827804865 Test RE 0.0013248698849864747\n",
      "69 Train Loss 0.0006748032 Test MSE 5.033791683170651e-05 Test RE 0.0003616680977855359\n",
      "70 Train Loss 0.0006657784 Test MSE 1.2540412250900997e-07 Test RE 1.8051715875990754e-05\n",
      "71 Train Loss 0.00064261013 Test MSE 0.0007905783043242285 Test RE 0.0014332931605418068\n",
      "72 Train Loss 0.0006409128 Test MSE 0.0009030463454065437 Test RE 0.0015318548016628982\n",
      "73 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "74 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "75 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "76 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "77 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "78 Train Loss 0.00063542824 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "79 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "80 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "81 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "82 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "83 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "84 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "85 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "86 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "87 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "88 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "89 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "90 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "91 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "92 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "93 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "94 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "95 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "96 Train Loss 0.00063542824 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "97 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "98 Train Loss 0.00063542824 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "99 Train Loss 0.0006354282 Test MSE 0.0017169420287418287 Test RE 0.0021122260692817262\n",
      "Training time: 54.27\n",
      "Training time: 54.27\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 3.3713846 Test MSE 387.7727531991528 Test RE 1.0038093292123753\n",
      "1 Train Loss 2.50155 Test MSE 382.6342834510584 Test RE 0.997136289900159\n",
      "2 Train Loss 2.3788357 Test MSE 383.2935816422092 Test RE 0.9979949782569945\n",
      "3 Train Loss 2.3768237 Test MSE 382.6292987697914 Test RE 0.997129794895676\n",
      "4 Train Loss 2.3686492 Test MSE 380.4236797059914 Test RE 0.994251725912325\n",
      "5 Train Loss 2.3289995 Test MSE 372.65678421898633 Test RE 0.9840498478150639\n",
      "6 Train Loss 2.2667637 Test MSE 362.37405509048267 Test RE 0.970378421537047\n",
      "7 Train Loss 2.2127237 Test MSE 355.0621607058251 Test RE 0.9605385033967505\n",
      "8 Train Loss 2.1589901 Test MSE 341.29100643692664 Test RE 0.9417269619006184\n",
      "9 Train Loss 2.1191537 Test MSE 331.54623630744345 Test RE 0.9281851879316623\n",
      "10 Train Loss 1.9655735 Test MSE 306.8442740389935 Test RE 0.8929385941572537\n",
      "11 Train Loss 1.8977962 Test MSE 294.8993367639389 Test RE 0.8753857656832679\n",
      "12 Train Loss 1.7798047 Test MSE 281.3095624480634 Test RE 0.8549777842049159\n",
      "13 Train Loss 1.7055955 Test MSE 259.64640698556485 Test RE 0.821398189214043\n",
      "14 Train Loss 1.5938879 Test MSE 240.9644080698786 Test RE 0.7912961126425856\n",
      "15 Train Loss 1.4403318 Test MSE 223.68317861824934 Test RE 0.7623936059920734\n",
      "16 Train Loss 1.2215666 Test MSE 182.56374238226272 Test RE 0.688763060948716\n",
      "17 Train Loss 1.1410031 Test MSE 170.84684644851552 Test RE 0.6662942508477213\n",
      "18 Train Loss 0.9644482 Test MSE 132.41821445700228 Test RE 0.5865924194517458\n",
      "19 Train Loss 0.8332587 Test MSE 118.53906188930756 Test RE 0.555000437533629\n",
      "20 Train Loss 0.6358893 Test MSE 77.48113129418563 Test RE 0.44870463853132114\n",
      "21 Train Loss 0.4122421 Test MSE 53.319832034695764 Test RE 0.37222622585461995\n",
      "22 Train Loss 0.28534955 Test MSE 33.64516324724454 Test RE 0.2956813296033222\n",
      "23 Train Loss 0.14652586 Test MSE 11.76020300998067 Test RE 0.17481149700626364\n",
      "24 Train Loss 0.06415404 Test MSE 5.0243366730146555 Test RE 0.11426203356073311\n",
      "25 Train Loss 0.024297653 Test MSE 0.24717955614371795 Test RE 0.025343632159468405\n",
      "26 Train Loss 0.008928525 Test MSE 0.30266413921044055 Test RE 0.02804420067428049\n",
      "27 Train Loss 0.0050324854 Test MSE 0.023140921643563284 Test RE 0.007754484075039608\n",
      "28 Train Loss 0.0029989635 Test MSE 0.0003728217197936574 Test RE 0.0009842675908955916\n",
      "29 Train Loss 0.0021573459 Test MSE 0.0007064999699190305 Test RE 0.001354935608309307\n",
      "30 Train Loss 0.0019989426 Test MSE 0.001439454130941005 Test RE 0.0019340223907022666\n",
      "31 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "32 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "33 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "34 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "35 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "36 Train Loss 0.0019932122 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "37 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "39 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "40 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "41 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "42 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "43 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "44 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "45 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "46 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "47 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "48 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "49 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "50 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "51 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "52 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "53 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "54 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "55 Train Loss 0.0019932122 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "56 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "57 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "58 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "59 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "60 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "61 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "62 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "63 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "64 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "65 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "66 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "67 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "68 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "69 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "70 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "71 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "72 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "73 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "74 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "75 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "76 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "77 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "78 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "79 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "80 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "81 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "82 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "83 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "84 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "85 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "86 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "87 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "88 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "89 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "90 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "91 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "92 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "93 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "94 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "95 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "96 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "97 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "98 Train Loss 0.0019932122 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "99 Train Loss 0.001993212 Test MSE 0.001410525194586339 Test RE 0.0019144895778262525\n",
      "Training time: 31.53\n",
      "Training time: 31.53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 3.1917727 Test MSE 382.9276783666757 Test RE 0.9975185069031383\n",
      "1 Train Loss 2.4511237 Test MSE 384.3323826854177 Test RE 0.9993464445961044\n",
      "2 Train Loss 2.3694522 Test MSE 381.4582221456431 Test RE 0.9956027160151375\n",
      "3 Train Loss 2.3369195 Test MSE 373.04512592270703 Test RE 0.9845624482888395\n",
      "4 Train Loss 2.2741315 Test MSE 362.1496343728481 Test RE 0.9700778940210701\n",
      "5 Train Loss 2.2297547 Test MSE 351.9690353274637 Test RE 0.9563454841126308\n",
      "6 Train Loss 2.137164 Test MSE 339.29606342575505 Test RE 0.9389705970821927\n",
      "7 Train Loss 2.081425 Test MSE 329.2827294494259 Test RE 0.9250113444855357\n",
      "8 Train Loss 1.9905696 Test MSE 311.06554846608304 Test RE 0.8990597178497732\n",
      "9 Train Loss 1.8557694 Test MSE 294.3005441483532 Test RE 0.8744965794063507\n",
      "10 Train Loss 1.724313 Test MSE 269.7260590290016 Test RE 0.8371900073873183\n",
      "11 Train Loss 1.6361357 Test MSE 248.37770379924316 Test RE 0.8033760609062832\n",
      "12 Train Loss 1.4334546 Test MSE 217.69231455301687 Test RE 0.7521147934872651\n",
      "13 Train Loss 1.3284458 Test MSE 207.85206299903066 Test RE 0.7349194683975959\n",
      "14 Train Loss 1.2855743 Test MSE 192.0074177359777 Test RE 0.706352661653279\n",
      "15 Train Loss 1.128668 Test MSE 162.87878786669938 Test RE 0.6505712197558049\n",
      "16 Train Loss 0.9809437 Test MSE 143.87703750091615 Test RE 0.6114463065511607\n",
      "17 Train Loss 0.9089451 Test MSE 132.1907947715925 Test RE 0.5860884857939629\n",
      "18 Train Loss 0.67730343 Test MSE 103.81489269447489 Test RE 0.5193885989361648\n",
      "19 Train Loss 0.5172228 Test MSE 69.3947896401097 Test RE 0.42464499950957396\n",
      "20 Train Loss 0.3953364 Test MSE 41.41544093457415 Test RE 0.32805278366106727\n",
      "21 Train Loss 0.29559094 Test MSE 30.66594561434986 Test RE 0.28228692511903203\n",
      "22 Train Loss 0.24412617 Test MSE 28.77282080275222 Test RE 0.27343481049038476\n",
      "23 Train Loss 0.19861975 Test MSE 21.71456014931481 Test RE 0.2375407377066057\n",
      "24 Train Loss 0.089891344 Test MSE 5.451810177723348 Test RE 0.11902356265114732\n",
      "25 Train Loss 0.06858959 Test MSE 1.843843397653402 Test RE 0.06921888492666899\n",
      "26 Train Loss 0.05023832 Test MSE 0.24363615110014294 Test RE 0.02516132153157104\n",
      "27 Train Loss 0.042885657 Test MSE 0.7861504633469094 Test RE 0.04519760474328302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 0.037573468 Test MSE 0.2755800174123078 Test RE 0.026760020645133817\n",
      "29 Train Loss 0.016807215 Test MSE 2.9743188736187953e-05 Test RE 0.00027800739352074316\n",
      "30 Train Loss 0.01175621 Test MSE 0.015990090901032216 Test RE 0.0064459665700504695\n",
      "31 Train Loss 0.005997033 Test MSE 0.014965584199633467 Test RE 0.006236047576608511\n",
      "32 Train Loss 0.0043513393 Test MSE 0.0058762270396819334 Test RE 0.003907615882866052\n",
      "33 Train Loss 0.0038332902 Test MSE 0.014156011409117666 Test RE 0.006065031132941725\n",
      "34 Train Loss 0.003341969 Test MSE 0.01928432265550358 Test RE 0.007078883697749589\n",
      "35 Train Loss 0.003272128 Test MSE 0.009268298546692741 Test RE 0.004907525781870529\n",
      "36 Train Loss 0.0030554966 Test MSE 0.0025147329809421404 Test RE 0.00255628058373539\n",
      "37 Train Loss 0.0030290133 Test MSE 0.003487208452013503 Test RE 0.003010242872997293\n",
      "38 Train Loss 0.0026817245 Test MSE 6.155798928672706e-06 Test RE 0.0001264750312497411\n",
      "39 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "40 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "41 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "42 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "43 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "44 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "45 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "46 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "47 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "48 Train Loss 0.0026441035 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "49 Train Loss 0.0026441035 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "50 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "51 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "52 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "53 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "54 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "55 Train Loss 0.0026441035 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "56 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "57 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "58 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "59 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "60 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "61 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "62 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "63 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "64 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "65 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "66 Train Loss 0.0026441035 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "67 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "68 Train Loss 0.0026441035 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "69 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "70 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "71 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "72 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "73 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "74 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "75 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "76 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "77 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "78 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "79 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "80 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "81 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "82 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "83 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "84 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "85 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "86 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "87 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "88 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "89 Train Loss 0.0026441035 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "90 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "91 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "92 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "93 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "94 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "95 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "96 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "97 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "98 Train Loss 0.0026441037 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "99 Train Loss 0.002644104 Test MSE 0.00022700695172663264 Test RE 0.0007680370326239248\n",
      "Training time: 37.57\n",
      "Training time: 37.57\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.149167 Test MSE 384.1865003742847 Test RE 0.9991567639806198\n",
      "1 Train Loss 2.8040404 Test MSE 381.3702638311944 Test RE 0.9954879241710817\n",
      "2 Train Loss 2.3828533 Test MSE 383.68506835310234 Test RE 0.9985045120423683\n",
      "3 Train Loss 2.3780637 Test MSE 383.0999208427847 Test RE 0.9977428256855871\n",
      "4 Train Loss 2.3776686 Test MSE 382.91111564186036 Test RE 0.9974969338958617\n",
      "5 Train Loss 2.3752315 Test MSE 381.3871245641733 Test RE 0.9955099296499469\n",
      "6 Train Loss 2.3567946 Test MSE 377.6287443114172 Test RE 0.9905926579516721\n",
      "7 Train Loss 2.3470235 Test MSE 375.2488495258996 Test RE 0.9874662640249864\n",
      "8 Train Loss 2.2844925 Test MSE 363.06004849369674 Test RE 0.971296476300596\n",
      "9 Train Loss 2.186066 Test MSE 339.4958911711449 Test RE 0.939247058820668\n",
      "10 Train Loss 2.019913 Test MSE 307.4139890215027 Test RE 0.8937671652327958\n",
      "11 Train Loss 1.7309592 Test MSE 263.2603986232548 Test RE 0.8270949131510926\n",
      "12 Train Loss 1.6184121 Test MSE 247.1567564908312 Test RE 0.8013990552795943\n",
      "13 Train Loss 1.4211057 Test MSE 213.80948183178248 Test RE 0.7453771293642937\n",
      "14 Train Loss 0.90314263 Test MSE 130.43735702675912 Test RE 0.5821884399063438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 0.71097744 Test MSE 95.35547193335279 Test RE 0.49777764931624663\n",
      "16 Train Loss 0.6558091 Test MSE 78.23600327913378 Test RE 0.45088512786580504\n",
      "17 Train Loss 0.572475 Test MSE 72.17440268421905 Test RE 0.4330660928179787\n",
      "18 Train Loss 0.47643292 Test MSE 64.73292232987824 Test RE 0.41013344808058494\n",
      "19 Train Loss 0.41928807 Test MSE 54.23424231232955 Test RE 0.37540441085769666\n",
      "20 Train Loss 0.37180823 Test MSE 41.358772235250974 Test RE 0.3278282697144085\n",
      "21 Train Loss 0.33961803 Test MSE 33.49469147377359 Test RE 0.2950193986373497\n",
      "22 Train Loss 0.27761722 Test MSE 32.957787629419244 Test RE 0.29264533668228215\n",
      "23 Train Loss 0.27148348 Test MSE 32.51676356756181 Test RE 0.29068072796154576\n",
      "24 Train Loss 0.23498343 Test MSE 24.950615539700333 Test RE 0.2546262738239936\n",
      "25 Train Loss 0.2181705 Test MSE 23.360733543821148 Test RE 0.24638020964978719\n",
      "26 Train Loss 0.20484126 Test MSE 22.650608672181683 Test RE 0.2426065494669975\n",
      "27 Train Loss 0.19886944 Test MSE 22.108734228364227 Test RE 0.2396870233834903\n",
      "28 Train Loss 0.13899773 Test MSE 12.47388893322049 Test RE 0.18003772602712034\n",
      "29 Train Loss 0.08510845 Test MSE 8.501476890919195 Test RE 0.14863112733983322\n",
      "30 Train Loss 0.07863076 Test MSE 6.501354355877969 Test RE 0.1299763992427732\n",
      "31 Train Loss 0.07331307 Test MSE 3.5282185510010713 Test RE 0.09575033940578145\n",
      "32 Train Loss 0.06452859 Test MSE 1.8178821303998531 Test RE 0.06872985739773665\n",
      "33 Train Loss 0.059332825 Test MSE 1.464569300717377 Test RE 0.06169039425752923\n",
      "34 Train Loss 0.05301904 Test MSE 0.9992457285097447 Test RE 0.050956399372909654\n",
      "35 Train Loss 0.044092752 Test MSE 0.3985383630385918 Test RE 0.03218086021227883\n",
      "36 Train Loss 0.030029308 Test MSE 0.0512656553703874 Test RE 0.011541860990086122\n",
      "37 Train Loss 0.021933394 Test MSE 0.036168054525359955 Test RE 0.009694494239168482\n",
      "38 Train Loss 0.015410403 Test MSE 0.49167724097288895 Test RE 0.03574395753469725\n",
      "39 Train Loss 0.010124715 Test MSE 0.534374322189617 Test RE 0.0372636483737709\n",
      "40 Train Loss 0.005693637 Test MSE 0.002954916080792279 Test RE 0.0027709912746780273\n",
      "41 Train Loss 0.004340269 Test MSE 0.006439049434579203 Test RE 0.004090472357939265\n",
      "42 Train Loss 0.0026655928 Test MSE 2.3959102238647016e-07 Test RE 2.4951568590021192e-05\n",
      "43 Train Loss 0.002534892 Test MSE 0.0011238983759208746 Test RE 0.0017089372030851936\n",
      "44 Train Loss 0.0025315904 Test MSE 0.00122368422324065 Test RE 0.0017831885339112206\n",
      "45 Train Loss 0.0025130378 Test MSE 0.001999966537888025 Test RE 0.0022796803050667584\n",
      "46 Train Loss 0.0025109022 Test MSE 0.002070757156512168 Test RE 0.00231967513909671\n",
      "47 Train Loss 0.0025087865 Test MSE 0.002108862137412486 Test RE 0.0023409205670002434\n",
      "48 Train Loss 0.0025065972 Test MSE 0.0021365394021946563 Test RE 0.0023562319236979513\n",
      "49 Train Loss 0.002504416 Test MSE 0.002117187602371829 Test RE 0.002345536813490913\n",
      "50 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "51 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "52 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "53 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "54 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "55 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "56 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "57 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "58 Train Loss 0.0024990197 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "59 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "60 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "61 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "62 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "63 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "64 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "65 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "66 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "67 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "68 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "69 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "70 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "71 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "72 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "73 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "74 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "75 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "76 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "77 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "78 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "79 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "80 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "81 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "82 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "83 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "84 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "85 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "86 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "87 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "88 Train Loss 0.0024990197 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "89 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "90 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "91 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "92 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "93 Train Loss 0.0024990197 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "94 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "95 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "96 Train Loss 0.0024990197 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "97 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "98 Train Loss 0.00249902 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "99 Train Loss 0.0024990197 Test MSE 0.0020784196151712665 Test RE 0.0023239629432961445\n",
      "Training time: 43.96\n",
      "Training time: 43.96\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 3.047493 Test MSE 382.20266372254855 Test RE 0.9965737355860534\n",
      "1 Train Loss 2.4384336 Test MSE 383.4560556439703 Test RE 0.9982064754826722\n",
      "2 Train Loss 2.385863 Test MSE 382.97038143035473 Test RE 0.9975741256416308\n",
      "3 Train Loss 2.3786345 Test MSE 382.82306862544743 Test RE 0.9973822445141202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 2.375842 Test MSE 380.5235754010794 Test RE 0.994382257939095\n",
      "5 Train Loss 2.3551216 Test MSE 377.1526071692534 Test RE 0.9899679614318372\n",
      "6 Train Loss 2.3339481 Test MSE 372.33512360514607 Test RE 0.983625062295735\n",
      "7 Train Loss 2.2792778 Test MSE 360.9938176943908 Test RE 0.9685286335098194\n",
      "8 Train Loss 2.21186 Test MSE 352.2311013450334 Test RE 0.9567014515309099\n",
      "9 Train Loss 2.131096 Test MSE 337.4509449477443 Test RE 0.9364140189250928\n",
      "10 Train Loss 2.0384529 Test MSE 303.49243575448446 Test RE 0.8880481586833106\n",
      "11 Train Loss 1.7406809 Test MSE 268.45177102482694 Test RE 0.8352100648681099\n",
      "12 Train Loss 1.4291912 Test MSE 221.0588138846519 Test RE 0.7579080157396701\n",
      "13 Train Loss 1.1997032 Test MSE 172.66569498860648 Test RE 0.6698315707999684\n",
      "14 Train Loss 1.0737002 Test MSE 159.33140462572376 Test RE 0.6434477327266745\n",
      "15 Train Loss 0.9869662 Test MSE 149.6768549044934 Test RE 0.623648535736565\n",
      "16 Train Loss 0.9107255 Test MSE 137.74669349948275 Test RE 0.5982781938747895\n",
      "17 Train Loss 0.77488196 Test MSE 113.54820547768415 Test RE 0.5431911931335757\n",
      "18 Train Loss 0.6836523 Test MSE 92.49797337528246 Test RE 0.49026251781239794\n",
      "19 Train Loss 0.5753217 Test MSE 70.4961871775196 Test RE 0.42800160421975575\n",
      "20 Train Loss 0.53484386 Test MSE 60.26373740481196 Test RE 0.39572238103980534\n",
      "21 Train Loss 0.4839598 Test MSE 56.35881969746636 Test RE 0.3826868394567909\n",
      "22 Train Loss 0.4447505 Test MSE 44.73781762061285 Test RE 0.3409572895071463\n",
      "23 Train Loss 0.38273 Test MSE 29.06006744561695 Test RE 0.27479630672495314\n",
      "24 Train Loss 0.25533247 Test MSE 8.679155865211586 Test RE 0.1501762745147444\n",
      "25 Train Loss 0.15510838 Test MSE 3.298928194957193 Test RE 0.09258678714229711\n",
      "26 Train Loss 0.1285553 Test MSE 0.19364027480840018 Test RE 0.02243160907299993\n",
      "27 Train Loss 0.11311504 Test MSE 0.5752143392669078 Test RE 0.03866138734816044\n",
      "28 Train Loss 0.080621995 Test MSE 0.1695805949156068 Test RE 0.02099184736007383\n",
      "29 Train Loss 0.077848315 Test MSE 0.25860191453621906 Test RE 0.02592259354966904\n",
      "30 Train Loss 0.049931727 Test MSE 0.3130897596587023 Test RE 0.028523119020248483\n",
      "31 Train Loss 0.042501114 Test MSE 0.1516961981085141 Test RE 0.019854087462534073\n",
      "32 Train Loss 0.035156965 Test MSE 0.419730889747967 Test RE 0.03302539711411941\n",
      "33 Train Loss 0.014728455 Test MSE 0.02760061082803519 Test RE 0.008468801026586556\n",
      "34 Train Loss 0.009821758 Test MSE 0.02285441712289261 Test RE 0.007706330974183109\n",
      "35 Train Loss 0.009369218 Test MSE 0.031214086000727722 Test RE 0.009006123411455683\n",
      "36 Train Loss 0.008851243 Test MSE 0.016304386097964113 Test RE 0.006509008041724364\n",
      "37 Train Loss 0.007448438 Test MSE 0.0026412630245360134 Test RE 0.0026198016320425664\n",
      "38 Train Loss 0.0073278015 Test MSE 0.00612247261585487 Test RE 0.003988650726555312\n",
      "39 Train Loss 0.007318747 Test MSE 0.0065948816387001764 Test RE 0.0041396734620181685\n",
      "40 Train Loss 0.0073004104 Test MSE 0.007762314096804996 Test RE 0.004491156497536055\n",
      "41 Train Loss 0.0069342414 Test MSE 0.014308041482801417 Test RE 0.006097512198682892\n",
      "42 Train Loss 0.0038297854 Test MSE 0.002742046427328799 Test RE 0.0026693159680187956\n",
      "43 Train Loss 0.003108495 Test MSE 0.0001540991972514632 Test RE 0.0006327946091591464\n",
      "44 Train Loss 0.0025051842 Test MSE 0.005970924528888589 Test RE 0.003938976351598106\n",
      "45 Train Loss 0.0017761732 Test MSE 0.0049720810827530645 Test RE 0.0035944436840809543\n",
      "46 Train Loss 0.0014065143 Test MSE 0.0011570113130568392 Test RE 0.0017339292994329291\n",
      "47 Train Loss 0.0014007493 Test MSE 0.0012136366533240593 Test RE 0.0017758526375020848\n",
      "48 Train Loss 0.001394584 Test MSE 0.0012408389492879408 Test RE 0.0017956442169739927\n",
      "49 Train Loss 0.0013866075 Test MSE 0.001217109007801435 Test RE 0.0017783912825942558\n",
      "50 Train Loss 0.0013803374 Test MSE 0.0011791862102106092 Test RE 0.001750466397832173\n",
      "51 Train Loss 0.0013724563 Test MSE 0.0011229230341449155 Test RE 0.0017081955169774422\n",
      "52 Train Loss 0.0013405214 Test MSE 0.0007160700960782521 Test RE 0.0013640816014553092\n",
      "53 Train Loss 0.0013363648 Test MSE 0.0006259029491570595 Test RE 0.0012753109290211167\n",
      "54 Train Loss 0.0013318185 Test MSE 0.0005032001966271592 Test RE 0.0011434916130015282\n",
      "55 Train Loss 0.0013107011 Test MSE 8.60660956696236e-05 Test RE 0.00047291014802302043\n",
      "56 Train Loss 0.0013072307 Test MSE 4.810475256496132e-05 Test RE 0.000353554667560928\n",
      "57 Train Loss 0.0013036785 Test MSE 2.679908942470907e-05 Test RE 0.00026388979847861716\n",
      "58 Train Loss 0.0012796851 Test MSE 7.351236230804347e-05 Test RE 0.00043706172149424974\n",
      "59 Train Loss 0.0012767549 Test MSE 9.33348438659997e-05 Test RE 0.0004924753360109111\n",
      "60 Train Loss 0.0012667676 Test MSE 0.0001580179510088461 Test RE 0.000640790103170767\n",
      "61 Train Loss 0.0012636039 Test MSE 0.00012597059919282227 Test RE 0.0005721332397385382\n",
      "62 Train Loss 0.0012430344 Test MSE 1.940101019394192e-05 Test RE 0.00022453019547750383\n",
      "63 Train Loss 0.001239996 Test MSE 4.71358354267265e-06 Test RE 0.00011067210922467207\n",
      "64 Train Loss 0.0012366178 Test MSE 4.361467348099601e-08 Test RE 1.0645814520178167e-05\n",
      "65 Train Loss 0.0012315186 Test MSE 3.709868150850555e-06 Test RE 9.818424841954677e-05\n",
      "66 Train Loss 0.0012261095 Test MSE 2.4858296246571804e-05 Test RE 0.0002541547683761875\n",
      "67 Train Loss 0.0012206744 Test MSE 4.0352834227384786e-05 Test RE 0.00032381696960030607\n",
      "68 Train Loss 0.0012180485 Test MSE 6.235850482551027e-05 Test RE 0.00040254128562091014\n",
      "69 Train Loss 0.001214898 Test MSE 7.721692272190634e-05 Test RE 0.0004479389498593008\n",
      "70 Train Loss 0.0011961983 Test MSE 0.000354019175369898 Test RE 0.0009591266881184985\n",
      "71 Train Loss 0.0011946292 Test MSE 0.0003815192960603377 Test RE 0.0009956824140242254\n",
      "72 Train Loss 0.0011922966 Test MSE 0.00042275199283643353 Test RE 0.0010481064998829523\n",
      "73 Train Loss 0.0011864417 Test MSE 0.0004882981754650281 Test RE 0.0011264323988191725\n",
      "74 Train Loss 0.0011673633 Test MSE 0.0006556103621582466 Test RE 0.0013052253111100664\n",
      "75 Train Loss 0.001157386 Test MSE 0.0006638828336342598 Test RE 0.0013134341440884665\n",
      "76 Train Loss 0.0011553484 Test MSE 0.0006559526258837062 Test RE 0.0013055659654179655\n",
      "77 Train Loss 0.0011544023 Test MSE 0.0006531023773098198 Test RE 0.0013027264016134022\n",
      "78 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "79 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "80 Train Loss 0.0011498096 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "81 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "82 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "83 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "84 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "85 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "86 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "87 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "88 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "89 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "90 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "91 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "92 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "93 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "94 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "95 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "96 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "97 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "98 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "99 Train Loss 0.0011498097 Test MSE 0.0006585186143286754 Test RE 0.0013081170622514203\n",
      "Training time: 46.06\n",
      "Training time: 46.06\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 4.5392222 Test MSE 383.8337105765937 Test RE 0.9986979070571033\n",
      "1 Train Loss 3.5665224 Test MSE 381.6059268769784 Test RE 0.9957954514060173\n",
      "2 Train Loss 2.4127011 Test MSE 380.3217062182602 Test RE 0.9941184611909466\n",
      "3 Train Loss 2.3828702 Test MSE 381.0137061167559 Test RE 0.9950224553926905\n",
      "4 Train Loss 2.3628602 Test MSE 380.7015127865436 Test RE 0.994614723298464\n",
      "5 Train Loss 2.3323653 Test MSE 372.678718648852 Test RE 0.9840788077799428\n",
      "6 Train Loss 2.2985966 Test MSE 366.26978964803834 Test RE 0.9755805472630672\n",
      "7 Train Loss 2.1998205 Test MSE 346.0223509331676 Test RE 0.9482321122111212\n",
      "8 Train Loss 2.0061905 Test MSE 315.76690324988465 Test RE 0.9058283034944367\n",
      "9 Train Loss 1.9272654 Test MSE 292.5397202191263 Test RE 0.8718765627458848\n",
      "10 Train Loss 1.6475215 Test MSE 256.6637069810299 Test RE 0.8166666368033227\n",
      "11 Train Loss 1.2378795 Test MSE 188.29800497421672 Test RE 0.6994963326009427\n",
      "12 Train Loss 0.96975905 Test MSE 143.86584468599145 Test RE 0.6114225225666837\n",
      "13 Train Loss 0.9007818 Test MSE 136.964354783057 Test RE 0.5965768003129709\n",
      "14 Train Loss 0.79728204 Test MSE 114.98594679809165 Test RE 0.5466193045826302\n",
      "15 Train Loss 0.37493083 Test MSE 45.162628890549314 Test RE 0.34257225743602365\n",
      "16 Train Loss 0.28557432 Test MSE 34.9949133760018 Test RE 0.3015539655225091\n",
      "17 Train Loss 0.19831626 Test MSE 19.938778267486818 Test RE 0.22762075231360632\n",
      "18 Train Loss 0.17290905 Test MSE 15.282798467616512 Test RE 0.19928014274272227\n",
      "19 Train Loss 0.1674062 Test MSE 13.106740458173256 Test RE 0.18454825042386117\n",
      "20 Train Loss 0.11761969 Test MSE 8.225953770462624 Test RE 0.1462028083073413\n",
      "21 Train Loss 0.08057544 Test MSE 5.957944487603887 Test RE 0.12442590514587205\n",
      "22 Train Loss 0.038332433 Test MSE 2.4389007905458486 Test RE 0.07960853828062614\n",
      "23 Train Loss 0.02214738 Test MSE 1.6150720947185806 Test RE 0.06478262463497363\n",
      "24 Train Loss 0.01683158 Test MSE 1.1332846541953345 Test RE 0.05426653430463505\n",
      "25 Train Loss 0.007353333 Test MSE 0.3635447689610505 Test RE 0.030735588461850233\n",
      "26 Train Loss 0.004813715 Test MSE 0.10597209684131277 Test RE 0.01659427742398723\n",
      "27 Train Loss 0.0041790167 Test MSE 0.011662074248934817 Test RE 0.0055049133022328995\n",
      "28 Train Loss 0.0041296165 Test MSE 0.006072864492803182 Test RE 0.003972458581949376\n",
      "29 Train Loss 0.004119682 Test MSE 0.005125206493675328 Test RE 0.003649373099231521\n",
      "30 Train Loss 0.003649708 Test MSE 0.002806220037499852 Test RE 0.002700371048861862\n",
      "31 Train Loss 0.003365665 Test MSE 0.0018247347957837416 Test RE 0.00217752153815219\n",
      "32 Train Loss 0.0033612114 Test MSE 0.0014784737438454413 Test RE 0.001960060111944545\n",
      "33 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "34 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "35 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "36 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "37 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "38 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "39 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "40 Train Loss 0.0033583613 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "41 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "42 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "43 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "44 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "45 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "46 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "47 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "48 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "49 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "50 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "51 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "52 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "53 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "54 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "55 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "56 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "57 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "58 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "59 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "60 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "61 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "62 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "63 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "64 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "65 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "66 Train Loss 0.0033583613 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "67 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "68 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "69 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "70 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "71 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "72 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "73 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "74 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "75 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "76 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "77 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "78 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "79 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "80 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "81 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "82 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "83 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "84 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "85 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "86 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "87 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "88 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "89 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "90 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "91 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "92 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "93 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "94 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "95 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "96 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "98 Train Loss 0.0033583618 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "99 Train Loss 0.0033583615 Test MSE 0.0012093350123514618 Test RE 0.0017727026578518072\n",
      "Training time: 26.96\n",
      "Training time: 26.96\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 3.9200773 Test MSE 384.88307610634837 Test RE 1.0000621486856227\n",
      "1 Train Loss 2.6503117 Test MSE 381.89040623036834 Test RE 0.996166554749009\n",
      "2 Train Loss 2.386058 Test MSE 383.7736433353764 Test RE 0.998619759445806\n",
      "3 Train Loss 2.3813949 Test MSE 383.7634389737318 Test RE 0.9986064829414297\n",
      "4 Train Loss 2.3790898 Test MSE 382.8650115847891 Test RE 0.997436880742429\n",
      "5 Train Loss 2.3685143 Test MSE 380.75039873011445 Test RE 0.9946785805682588\n",
      "6 Train Loss 2.3362226 Test MSE 372.0196156543643 Test RE 0.9832082237006832\n",
      "7 Train Loss 2.3122933 Test MSE 367.4170779108699 Test RE 0.9771072865992514\n",
      "8 Train Loss 2.2476885 Test MSE 348.55634432683837 Test RE 0.951697828890693\n",
      "9 Train Loss 2.1516166 Test MSE 343.2274501725663 Test RE 0.9443948052236262\n",
      "10 Train Loss 2.0176117 Test MSE 314.62824428482907 Test RE 0.904193615018828\n",
      "11 Train Loss 1.9150697 Test MSE 299.73490739491865 Test RE 0.8825335912892193\n",
      "12 Train Loss 1.7757602 Test MSE 267.2934995734184 Test RE 0.8334063037640325\n",
      "13 Train Loss 1.5096735 Test MSE 236.57944282090443 Test RE 0.7840632254891452\n",
      "14 Train Loss 1.2668052 Test MSE 179.13476124203564 Test RE 0.6822640958559392\n",
      "15 Train Loss 1.136042 Test MSE 148.36042878131747 Test RE 0.6208999465258346\n",
      "16 Train Loss 0.9812847 Test MSE 139.3996683649819 Test RE 0.6018571895597699\n",
      "17 Train Loss 0.8110618 Test MSE 117.52140703687694 Test RE 0.552612970032166\n",
      "18 Train Loss 0.7398005 Test MSE 106.36216883785714 Test RE 0.5257220282726599\n",
      "19 Train Loss 0.6234881 Test MSE 89.10338448424993 Test RE 0.4811823432970747\n",
      "20 Train Loss 0.59134036 Test MSE 81.33799303904578 Test RE 0.4597368424225861\n",
      "21 Train Loss 0.55890304 Test MSE 74.56355174641425 Test RE 0.4401755099073457\n",
      "22 Train Loss 0.5346898 Test MSE 74.28282188468253 Test RE 0.43934610373997407\n",
      "23 Train Loss 0.5054335 Test MSE 74.69271766311141 Test RE 0.4405566014094719\n",
      "24 Train Loss 0.4495501 Test MSE 66.20974840567024 Test RE 0.4147854859892955\n",
      "25 Train Loss 0.36308485 Test MSE 52.10830063663095 Test RE 0.36797307124357176\n",
      "26 Train Loss 0.3104709 Test MSE 40.56792372460163 Test RE 0.32467883054612623\n",
      "27 Train Loss 0.23594841 Test MSE 28.886427636573345 Test RE 0.2739740947732435\n",
      "28 Train Loss 0.1909082 Test MSE 23.67555660995583 Test RE 0.24803483635961207\n",
      "29 Train Loss 0.16798525 Test MSE 19.469603916944983 Test RE 0.22492676691182079\n",
      "30 Train Loss 0.12683006 Test MSE 10.627713045971001 Test RE 0.1661814302327509\n",
      "31 Train Loss 0.11332757 Test MSE 6.938588751703616 Test RE 0.13427592610423797\n",
      "32 Train Loss 0.08436499 Test MSE 3.597353215317169 Test RE 0.0966838917942006\n",
      "33 Train Loss 0.061583664 Test MSE 1.0965245856342336 Test RE 0.05337916419122948\n",
      "34 Train Loss 0.051669363 Test MSE 0.06848214845679657 Test RE 0.013339859974846331\n",
      "35 Train Loss 0.04617839 Test MSE 0.13396945141769734 Test RE 0.018658016467021792\n",
      "36 Train Loss 0.044018723 Test MSE 0.1567999942958599 Test RE 0.020185318377307724\n",
      "37 Train Loss 0.031450912 Test MSE 0.014525603564870659 Test RE 0.00614369540786778\n",
      "38 Train Loss 0.026307214 Test MSE 0.00528581535147377 Test RE 0.0037061123138532512\n",
      "39 Train Loss 0.025878465 Test MSE 0.028173622313762414 Test RE 0.008556259086333453\n",
      "40 Train Loss 0.024190392 Test MSE 0.16559615317582527 Test RE 0.02074377076293326\n",
      "41 Train Loss 0.013792755 Test MSE 0.08735372304890232 Test RE 0.015066184874632474\n",
      "42 Train Loss 0.010425638 Test MSE 4.316018750393663e-05 Test RE 0.00033489159192327356\n",
      "43 Train Loss 0.009236121 Test MSE 0.01796187547032237 Test RE 0.00683185158343064\n",
      "44 Train Loss 0.008169514 Test MSE 0.02528317803025248 Test RE 0.008105473941485605\n",
      "45 Train Loss 0.008081146 Test MSE 0.021136685289828164 Test RE 0.0074110718386627\n",
      "46 Train Loss 0.0080753565 Test MSE 0.02064105150582783 Test RE 0.007323665350264551\n",
      "47 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "48 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "49 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "50 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "51 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "52 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "53 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "54 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "55 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "56 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "57 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "58 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "59 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "60 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "61 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "62 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "63 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "64 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "65 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "66 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "67 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "68 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "69 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "70 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "71 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "72 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "73 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "74 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "75 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "76 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "77 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "78 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "79 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "80 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "81 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "82 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "83 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "84 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "85 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "86 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "87 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "88 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "90 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "91 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "92 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "93 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "94 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "95 Train Loss 0.008072698 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "96 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "97 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "98 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "99 Train Loss 0.008072697 Test MSE 0.020121137722163406 Test RE 0.007230841624136789\n",
      "Training time: 35.98\n",
      "Training time: 35.98\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 3.676158 Test MSE 385.3957381927743 Test RE 1.0007279656138865\n",
      "1 Train Loss 2.4262211 Test MSE 383.4261166217336 Test RE 0.998167506337725\n",
      "2 Train Loss 2.3908823 Test MSE 382.6680012030711 Test RE 0.9971802227819696\n",
      "3 Train Loss 2.3801436 Test MSE 383.1949879953703 Test RE 0.9978666141289514\n",
      "4 Train Loss 2.3686612 Test MSE 381.1283009066218 Test RE 0.9951720770664904\n",
      "5 Train Loss 2.3572412 Test MSE 377.3937479707241 Test RE 0.9902843897387368\n",
      "6 Train Loss 2.298946 Test MSE 366.26954087074455 Test RE 0.9755802159467309\n",
      "7 Train Loss 2.2036572 Test MSE 351.27640897421884 Test RE 0.9554040429450533\n",
      "8 Train Loss 2.0994716 Test MSE 328.89967213728124 Test RE 0.9244731512597087\n",
      "9 Train Loss 2.0086083 Test MSE 315.6496882304402 Test RE 0.9056601627926453\n",
      "10 Train Loss 1.8070997 Test MSE 278.5024226229219 Test RE 0.8507012504991279\n",
      "11 Train Loss 1.636416 Test MSE 258.736768881014 Test RE 0.8199580948610767\n",
      "12 Train Loss 1.5020901 Test MSE 222.46590298576052 Test RE 0.7603163170200301\n",
      "13 Train Loss 1.3433039 Test MSE 203.63841152598607 Test RE 0.7274320518528012\n",
      "14 Train Loss 1.1876109 Test MSE 172.34893193274857 Test RE 0.6692168705343755\n",
      "15 Train Loss 1.0029559 Test MSE 156.69678470727055 Test RE 0.6381057015637304\n",
      "16 Train Loss 0.80673164 Test MSE 117.08398521638809 Test RE 0.5515835817453323\n",
      "17 Train Loss 0.6850418 Test MSE 96.03854781359786 Test RE 0.49955737490496027\n",
      "18 Train Loss 0.5738833 Test MSE 81.56992703953804 Test RE 0.460391841991618\n",
      "19 Train Loss 0.46209273 Test MSE 57.135776990702695 Test RE 0.3853156523955364\n",
      "20 Train Loss 0.2902337 Test MSE 32.53956619569136 Test RE 0.2907826311368706\n",
      "21 Train Loss 0.23868981 Test MSE 26.171436170118785 Test RE 0.2607812485228612\n",
      "22 Train Loss 0.20199594 Test MSE 19.141026431432504 Test RE 0.22302070996358223\n",
      "23 Train Loss 0.17562056 Test MSE 16.835601887397015 Test RE 0.20915916829965253\n",
      "24 Train Loss 0.1237566 Test MSE 11.060656720682092 Test RE 0.1695325285120209\n",
      "25 Train Loss 0.095716655 Test MSE 6.9466795527967085 Test RE 0.13435419009505922\n",
      "26 Train Loss 0.057412483 Test MSE 1.9569488021924193 Test RE 0.07131030835773548\n",
      "27 Train Loss 0.019060815 Test MSE 0.6874314244757503 Test RE 0.042264649631807226\n",
      "28 Train Loss 0.013987965 Test MSE 0.10094597113856285 Test RE 0.01619597425568746\n",
      "29 Train Loss 0.01139035 Test MSE 0.00016892404118260893 Test RE 0.0006625342188241716\n",
      "30 Train Loss 0.010701243 Test MSE 0.00028782308860329244 Test RE 0.0008648193478655882\n",
      "31 Train Loss 0.008326522 Test MSE 0.00013336807889779146 Test RE 0.0005886925370658968\n",
      "32 Train Loss 0.0080271205 Test MSE 0.00587980361250224 Test RE 0.00390880488957932\n",
      "33 Train Loss 0.0068035196 Test MSE 0.04121360912367377 Test RE 0.010348631115072901\n",
      "34 Train Loss 0.005526499 Test MSE 0.0004776310394721541 Test RE 0.0011140606986386878\n",
      "35 Train Loss 0.0030473112 Test MSE 0.04787055031464247 Test RE 0.011153130725586923\n",
      "36 Train Loss 0.002246978 Test MSE 0.004317710385610598 Test RE 0.0033495721477432992\n",
      "37 Train Loss 0.0021368216 Test MSE 0.0016441297154813873 Test RE 0.0020669530974466994\n",
      "38 Train Loss 0.002131251 Test MSE 0.001622941507206026 Test RE 0.0020535913025759005\n",
      "39 Train Loss 0.0021257398 Test MSE 0.0014503538920677482 Test RE 0.0019413309342839605\n",
      "40 Train Loss 0.0021217512 Test MSE 0.0014239889931181296 Test RE 0.0019236050064826836\n",
      "41 Train Loss 0.0021175926 Test MSE 0.0014445043261086558 Test RE 0.001937412091870899\n",
      "42 Train Loss 0.0021138296 Test MSE 0.0014342241126528033 Test RE 0.0019305057183908116\n",
      "43 Train Loss 0.0021103153 Test MSE 0.0014485733188187746 Test RE 0.0019401388998687337\n",
      "44 Train Loss 0.0021061257 Test MSE 0.0014319914343323332 Test RE 0.0019290025094531203\n",
      "45 Train Loss 0.002102534 Test MSE 0.001433508328879485 Test RE 0.0019300239257942044\n",
      "46 Train Loss 0.0020989042 Test MSE 0.0013936674177742908 Test RE 0.001903014756657336\n",
      "47 Train Loss 0.002095342 Test MSE 0.0013628979243840485 Test RE 0.0018818900567123024\n",
      "48 Train Loss 0.0020910348 Test MSE 0.0012847656015039439 Test RE 0.0018271513900208211\n",
      "49 Train Loss 0.0020866056 Test MSE 0.0012152036208609223 Test RE 0.001776998699543899\n",
      "50 Train Loss 0.0020816908 Test MSE 0.001120370603910929 Test RE 0.0017062530284034023\n",
      "51 Train Loss 0.0020766174 Test MSE 0.0010184030664096406 Test RE 0.0016267560541499287\n",
      "52 Train Loss 0.0020697778 Test MSE 0.0009269383339432013 Test RE 0.0015519867315643967\n",
      "53 Train Loss 0.0020602879 Test MSE 0.0007774465856892318 Test RE 0.0014213396220339788\n",
      "54 Train Loss 0.0016697468 Test MSE 0.0011063403128050507 Test RE 0.0016955357502390057\n",
      "55 Train Loss 0.0012717155 Test MSE 0.00034894556437037495 Test RE 0.0009522290436075646\n",
      "56 Train Loss 0.0012250626 Test MSE 0.00021816526483124283 Test RE 0.00075293135862182\n",
      "57 Train Loss 0.0012195405 Test MSE 0.0003671154009201919 Test RE 0.0009767060650235505\n",
      "58 Train Loss 0.0012149512 Test MSE 0.00048732906741604404 Test RE 0.0011253140484653167\n",
      "59 Train Loss 0.0012106918 Test MSE 0.0005622898327453741 Test RE 0.0012087672863289585\n",
      "60 Train Loss 0.0012067585 Test MSE 0.0006132212456068622 Test RE 0.001262324987301881\n",
      "61 Train Loss 0.0012026401 Test MSE 0.0005999145185764519 Test RE 0.0012485538229487405\n",
      "62 Train Loss 0.0011982213 Test MSE 0.0005554777410144568 Test RE 0.0012014229199270943\n",
      "63 Train Loss 0.0011954214 Test MSE 0.00047995391955847345 Test RE 0.0011167664384830198\n",
      "64 Train Loss 0.001192069 Test MSE 0.0003459990133592453 Test RE 0.000948200134782353\n",
      "65 Train Loss 0.0011888444 Test MSE 0.00022549346052500827 Test RE 0.0007654724387352196\n",
      "66 Train Loss 0.0011843195 Test MSE 9.744756328812425e-05 Test RE 0.0005032086228751337\n",
      "67 Train Loss 0.0011811979 Test MSE 2.246982990740663e-05 Test RE 0.00024163646575086408\n",
      "68 Train Loss 0.0011782921 Test MSE 3.517817183314194e-08 Test RE 9.560909679676664e-06\n",
      "69 Train Loss 0.0011755738 Test MSE 2.617997240763314e-05 Test RE 0.00026082377406813373\n",
      "70 Train Loss 0.0011726213 Test MSE 9.130464295601194e-05 Test RE 0.00048708977594253165\n",
      "71 Train Loss 0.0011706316 Test MSE 0.00017680298908827615 Test RE 0.0006778090826007921\n",
      "72 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "73 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "74 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "75 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "76 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "77 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "78 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "79 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "81 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "82 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "83 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "84 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "85 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "86 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "87 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "88 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "89 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "90 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "91 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "92 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "93 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "94 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "95 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "96 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "97 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "98 Train Loss 0.0011683096 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "99 Train Loss 0.0011683097 Test MSE 0.0002836364377047753 Test RE 0.0008585065118351516\n",
      "Training time: 33.43\n",
      "Training time: 33.43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.6535034 Test MSE 382.8176228210283 Test RE 0.9973751504171384\n",
      "1 Train Loss 3.507279 Test MSE 380.72735235102147 Test RE 0.9946484767435256\n",
      "2 Train Loss 2.417998 Test MSE 381.0431964579873 Test RE 0.9950609618604344\n",
      "3 Train Loss 2.3832045 Test MSE 381.24670176057276 Test RE 0.9953266445359267\n",
      "4 Train Loss 2.3384087 Test MSE 374.39377780928015 Test RE 0.986340563004737\n",
      "5 Train Loss 2.293934 Test MSE 365.0114012681461 Test RE 0.9739032105872281\n",
      "6 Train Loss 2.2292273 Test MSE 352.80426221521134 Test RE 0.9574795215896681\n",
      "7 Train Loss 2.19748 Test MSE 350.4707532035859 Test RE 0.9543077999131219\n",
      "8 Train Loss 2.13034 Test MSE 339.3779078529377 Test RE 0.9390838387096739\n",
      "9 Train Loss 2.0584407 Test MSE 324.70469527007805 Test RE 0.9185585983862855\n",
      "10 Train Loss 1.9246863 Test MSE 299.2708912189918 Test RE 0.8818502066312636\n",
      "11 Train Loss 1.6955874 Test MSE 257.83349852594694 Test RE 0.8185255744950493\n",
      "12 Train Loss 1.6026372 Test MSE 247.5265514331935 Test RE 0.8019983562128411\n",
      "13 Train Loss 1.3434682 Test MSE 206.8648303224836 Test RE 0.7331720715384215\n",
      "14 Train Loss 1.2301123 Test MSE 183.17575274185592 Test RE 0.689916568866119\n",
      "15 Train Loss 0.91180986 Test MSE 128.66016122829066 Test RE 0.578208708245674\n",
      "16 Train Loss 0.61324686 Test MSE 86.25639569769855 Test RE 0.4734326831860885\n",
      "17 Train Loss 0.5269269 Test MSE 78.25529190442131 Test RE 0.4509407059752112\n",
      "18 Train Loss 0.4329471 Test MSE 55.30868468451597 Test RE 0.37910476903703827\n",
      "19 Train Loss 0.32881916 Test MSE 43.89252337375845 Test RE 0.3377208370936756\n",
      "20 Train Loss 0.29237482 Test MSE 39.1166335778051 Test RE 0.3188183563360007\n",
      "21 Train Loss 0.2614818 Test MSE 30.281307379994228 Test RE 0.2805109980317952\n",
      "22 Train Loss 0.17786103 Test MSE 13.026649026004243 Test RE 0.1839835263736299\n",
      "23 Train Loss 0.12935227 Test MSE 9.008548029582746 Test RE 0.15299948948542003\n",
      "24 Train Loss 0.10590484 Test MSE 7.455567710080164 Test RE 0.1391883677397002\n",
      "25 Train Loss 0.09311977 Test MSE 6.3803961815721335 Test RE 0.12876161219659502\n",
      "26 Train Loss 0.06444222 Test MSE 2.941593633907177 Test RE 0.08742867991284493\n",
      "27 Train Loss 0.033562675 Test MSE 1.4804299429575507 Test RE 0.06202353468187293\n",
      "28 Train Loss 0.024202053 Test MSE 0.8130581815220799 Test RE 0.04596459043293683\n",
      "29 Train Loss 0.01909526 Test MSE 0.16708656151090054 Test RE 0.020836911319036356\n",
      "30 Train Loss 0.0149302045 Test MSE 2.5974338260080934e-06 Test RE 8.215515673397209e-05\n",
      "31 Train Loss 0.014178024 Test MSE 0.0031243738019051757 Test RE 0.0028493386970589027\n",
      "32 Train Loss 0.012041057 Test MSE 0.04265088074990642 Test RE 0.01052753234586312\n",
      "33 Train Loss 0.010889177 Test MSE 0.11027176208216367 Test RE 0.016927574729554907\n",
      "34 Train Loss 0.008545666 Test MSE 0.0024065441417114143 Test RE 0.002500687933758425\n",
      "35 Train Loss 0.0080904225 Test MSE 0.0005577488545022109 Test RE 0.0012038764696319724\n",
      "36 Train Loss 0.0076881014 Test MSE 0.0010060954258184426 Test RE 0.001616896309497968\n",
      "37 Train Loss 0.0054091224 Test MSE 9.595463275217686e-05 Test RE 0.0004993390794918624\n",
      "38 Train Loss 0.0013588674 Test MSE 0.000217190625772215 Test RE 0.0007512476402289124\n",
      "39 Train Loss 0.000803168 Test MSE 0.001073185466896234 Test RE 0.0016699365641952258\n",
      "40 Train Loss 0.0006071757 Test MSE 0.004847189291478997 Test RE 0.0035490128560160994\n",
      "41 Train Loss 0.0006018771 Test MSE 0.004626571123039395 Test RE 0.003467306262140313\n",
      "42 Train Loss 0.0005965369 Test MSE 0.00429753250793593 Test RE 0.003341736234766\n",
      "43 Train Loss 0.0005905805 Test MSE 0.003869237524121273 Test RE 0.003170846934896351\n",
      "44 Train Loss 0.0005841517 Test MSE 0.003311667867114298 Test RE 0.0029334991695447493\n",
      "45 Train Loss 0.00057635107 Test MSE 0.002653836087004668 Test RE 0.0026260296795596024\n",
      "46 Train Loss 0.00056769006 Test MSE 0.0019952979262695867 Test RE 0.0022770179704498946\n",
      "47 Train Loss 0.00054774067 Test MSE 0.0007960250571398169 Test RE 0.0014382220798237783\n",
      "48 Train Loss 0.00037144558 Test MSE 0.001098500975827547 Test RE 0.0016895179337821252\n",
      "49 Train Loss 0.00031581084 Test MSE 6.066914639628977e-05 Test RE 0.00039705121086363725\n",
      "50 Train Loss 0.0003084975 Test MSE 4.001480419265226e-06 Test RE 0.00010197012004161448\n",
      "51 Train Loss 0.00030364902 Test MSE 8.84642776762162e-06 Test RE 0.00015161652914996373\n",
      "52 Train Loss 0.0002993466 Test MSE 4.800555583637824e-05 Test RE 0.00035318994720176587\n",
      "53 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "54 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "55 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "56 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "57 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "58 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "59 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "60 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "61 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "62 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "63 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "64 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "65 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "66 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "67 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "68 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 0.00029676282 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "70 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "71 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "72 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "73 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "74 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "75 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "76 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "77 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "78 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "79 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "80 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "81 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "82 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "83 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "84 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "85 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "86 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "87 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "88 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "89 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "90 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "91 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "92 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "93 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "94 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "95 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "96 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "97 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "98 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "99 Train Loss 0.0002967628 Test MSE 0.00010020776247345763 Test RE 0.0005102855436715048\n",
      "Training time: 34.26\n",
      "Training time: 34.26\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3.0016615 Test MSE 386.6259007817617 Test RE 1.0023238282298308\n",
      "1 Train Loss 2.3869839 Test MSE 382.4433944258593 Test RE 0.9968875326297296\n",
      "2 Train Loss 2.365529 Test MSE 379.63256745189733 Test RE 0.9932173869396854\n",
      "3 Train Loss 2.3438282 Test MSE 375.9915074299172 Test RE 0.9884429320960344\n",
      "4 Train Loss 2.3266006 Test MSE 371.89902368596466 Test RE 0.9830488549199391\n",
      "5 Train Loss 2.2948225 Test MSE 366.46057841220085 Test RE 0.9758346025795559\n",
      "6 Train Loss 2.2679365 Test MSE 360.4530124708467 Test RE 0.9678028847069368\n",
      "7 Train Loss 2.200415 Test MSE 347.00768056356947 Test RE 0.9495812403796704\n",
      "8 Train Loss 2.1087165 Test MSE 334.474388904659 Test RE 0.9322749543115767\n",
      "9 Train Loss 2.0583804 Test MSE 323.4553953279189 Test RE 0.9167898202432923\n",
      "10 Train Loss 1.98094 Test MSE 311.01552111604576 Test RE 0.8989874189662026\n",
      "11 Train Loss 1.9029678 Test MSE 296.1363698410367 Test RE 0.8772198625773902\n",
      "12 Train Loss 1.7286384 Test MSE 271.39314665960427 Test RE 0.8397732194196051\n",
      "13 Train Loss 1.6105511 Test MSE 253.81225728831723 Test RE 0.812117517324725\n",
      "14 Train Loss 1.5055928 Test MSE 232.01332017243666 Test RE 0.7764599185367198\n",
      "15 Train Loss 1.3688384 Test MSE 203.0949222531131 Test RE 0.7264606838914395\n",
      "16 Train Loss 1.312128 Test MSE 198.82292260717398 Test RE 0.7187797101285792\n",
      "17 Train Loss 1.010894 Test MSE 151.84982505500702 Test RE 0.6281592081923436\n",
      "18 Train Loss 0.9222398 Test MSE 130.24603048230009 Test RE 0.5817613039186468\n",
      "19 Train Loss 0.7984632 Test MSE 106.3603283392808 Test RE 0.5257174796871948\n",
      "20 Train Loss 0.6658246 Test MSE 86.81162558395368 Test RE 0.4749539751250524\n",
      "21 Train Loss 0.5405065 Test MSE 70.83053037719569 Test RE 0.4290153481030629\n",
      "22 Train Loss 0.32169953 Test MSE 39.88864105917185 Test RE 0.3219490907982771\n",
      "23 Train Loss 0.2761056 Test MSE 30.043948647223225 Test RE 0.2794094484424226\n",
      "24 Train Loss 0.22827348 Test MSE 23.993720898427533 Test RE 0.2496958842350148\n",
      "25 Train Loss 0.1835202 Test MSE 16.74868126055048 Test RE 0.20861853504408612\n",
      "26 Train Loss 0.1321896 Test MSE 8.644429439336179 Test RE 0.14987553603474377\n",
      "27 Train Loss 0.09506941 Test MSE 3.8936091816248988 Test RE 0.10058628332402234\n",
      "28 Train Loss 0.052512188 Test MSE 3.0453185399212868 Test RE 0.08895675778884257\n",
      "29 Train Loss 0.027364332 Test MSE 1.76253308209831 Test RE 0.06767546074137601\n",
      "30 Train Loss 0.015839644 Test MSE 0.6285937024343504 Test RE 0.04041546643820177\n",
      "31 Train Loss 0.010918634 Test MSE 0.6937029208277556 Test RE 0.042457003938989456\n",
      "32 Train Loss 0.009401626 Test MSE 0.4244985598987693 Test RE 0.0332124331410337\n",
      "33 Train Loss 0.0074277064 Test MSE 0.11108492214479236 Test RE 0.016989873293755866\n",
      "34 Train Loss 0.0023119906 Test MSE 0.02825980105945847 Test RE 0.008569335229952662\n",
      "35 Train Loss 0.0018991425 Test MSE 0.03480307352504236 Test RE 0.009509799969738851\n",
      "36 Train Loss 0.0018900181 Test MSE 0.0336167826753247 Test RE 0.009346320203420088\n",
      "37 Train Loss 0.001880443 Test MSE 0.03199394971083778 Test RE 0.009117935410863904\n",
      "38 Train Loss 0.0017998423 Test MSE 0.014323686514044635 Test RE 0.00610084492964232\n",
      "39 Train Loss 0.001791186 Test MSE 0.012578820831120415 Test RE 0.005717188982715296\n",
      "40 Train Loss 0.001783154 Test MSE 0.011122824343173717 Test RE 0.005376134457002794\n",
      "41 Train Loss 0.0017757172 Test MSE 0.009990617316238683 Test RE 0.0050951707708898385\n",
      "42 Train Loss 0.0017688656 Test MSE 0.009073133393000473 Test RE 0.004855581303411849\n",
      "43 Train Loss 0.0017625976 Test MSE 0.008445819815911852 Test RE 0.004684718379054911\n",
      "44 Train Loss 0.0017563523 Test MSE 0.007930665986912822 Test RE 0.004539598168730263\n",
      "45 Train Loss 0.0017510871 Test MSE 0.007498305459788082 Test RE 0.004414120114087613\n",
      "46 Train Loss 0.0017450897 Test MSE 0.007062265517126704 Test RE 0.004283853430566008\n",
      "47 Train Loss 0.001738534 Test MSE 0.006677170859323669 Test RE 0.004165420280740677\n",
      "48 Train Loss 0.0017310069 Test MSE 0.005781060176500753 Test RE 0.003875844347038291\n",
      "49 Train Loss 0.0017241323 Test MSE 0.005236693495428892 Test RE 0.0036888513959870187\n",
      "50 Train Loss 0.0017158856 Test MSE 0.004799684767418304 Test RE 0.0035315791158855043\n",
      "51 Train Loss 0.0017081441 Test MSE 0.004313939488133297 Test RE 0.0033481091440845778\n",
      "52 Train Loss 0.001699432 Test MSE 0.003542214686939573 Test RE 0.0030338913395534972\n",
      "53 Train Loss 0.0016896997 Test MSE 0.0032169334541465285 Test RE 0.002891236521000049\n",
      "54 Train Loss 0.0016825882 Test MSE 0.0026359734045727653 Test RE 0.0026171769975358323\n",
      "55 Train Loss 0.0016763167 Test MSE 0.0022877192043914193 Test RE 0.0024381697653969034\n",
      "56 Train Loss 0.001670696 Test MSE 0.001964810260337413 Test RE 0.0022595548659016087\n",
      "57 Train Loss 0.0016657886 Test MSE 0.0016844791987935088 Test RE 0.0020921624768271046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.0016616588 Test MSE 0.0014606078311996992 Test RE 0.0019481814102338961\n",
      "59 Train Loss 0.0016577903 Test MSE 0.0012748943297782797 Test RE 0.0018201185560651626\n",
      "60 Train Loss 0.0016543239 Test MSE 0.0011171440814131102 Test RE 0.0017037943628986508\n",
      "61 Train Loss 0.0016509368 Test MSE 0.0009718765518300327 Test RE 0.0015891618643933444\n",
      "62 Train Loss 0.0016477337 Test MSE 0.0008398940766438769 Test RE 0.0014773208993142924\n",
      "63 Train Loss 0.0016439391 Test MSE 0.0007085968235909456 Test RE 0.0013569448063913017\n",
      "64 Train Loss 0.0016396008 Test MSE 0.0005878863699877143 Test RE 0.0012359738382384541\n",
      "65 Train Loss 0.0016336696 Test MSE 0.00044264761057509244 Test RE 0.0010724860319442063\n",
      "66 Train Loss 0.0016258874 Test MSE 0.00031892747311122705 Test RE 0.0009103503185103485\n",
      "67 Train Loss 0.0011813644 Test MSE 0.0011062674352520891 Test RE 0.001695479904614479\n",
      "68 Train Loss 0.00097211264 Test MSE 3.2225502740607023e-06 Test RE 9.1508710017373e-05\n",
      "69 Train Loss 0.00096584734 Test MSE 6.904360177268215e-07 Test RE 4.235691310750987e-05\n",
      "70 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "71 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "72 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "73 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "74 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "75 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "76 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "77 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "78 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "79 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "80 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "81 Train Loss 0.0009615079 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "82 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "83 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "84 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "85 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "86 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "87 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "88 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "89 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "90 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "91 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "92 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "93 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "94 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "95 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "96 Train Loss 0.0009615079 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "97 Train Loss 0.0009615079 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "98 Train Loss 0.00096150785 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "99 Train Loss 0.0009615078 Test MSE 5.275684049468902e-06 Test RE 0.00011708519183265489\n",
      "Training time: 32.72\n",
      "Training time: 32.72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.5275993 Test MSE 376.437552868361 Test RE 0.9890290620627498\n",
      "1 Train Loss 2.9101045 Test MSE 383.78916148277233 Test RE 0.9986399491751381\n",
      "2 Train Loss 2.417865 Test MSE 386.20147736854256 Test RE 1.001773520408631\n",
      "3 Train Loss 2.3906286 Test MSE 383.9385784322307 Test RE 0.9988343257099981\n",
      "4 Train Loss 2.3583524 Test MSE 379.73562929429534 Test RE 0.993352196063307\n",
      "5 Train Loss 2.3158653 Test MSE 370.353964782622 Test RE 0.9810046855170312\n",
      "6 Train Loss 2.2704358 Test MSE 361.99591036028636 Test RE 0.9698719845288225\n",
      "7 Train Loss 2.1807628 Test MSE 346.40488553816976 Test RE 0.948756112176935\n",
      "8 Train Loss 2.1112015 Test MSE 331.6929012756435 Test RE 0.9283904642768681\n",
      "9 Train Loss 1.8965017 Test MSE 297.9672518170427 Test RE 0.8799274179653158\n",
      "10 Train Loss 1.837358 Test MSE 292.37526893824605 Test RE 0.8716314654758138\n",
      "11 Train Loss 1.6866465 Test MSE 259.9950155190588 Test RE 0.8219494203513608\n",
      "12 Train Loss 1.5155609 Test MSE 234.93210760518755 Test RE 0.7813286868649858\n",
      "13 Train Loss 1.3440953 Test MSE 201.81406311453452 Test RE 0.7241662751323048\n",
      "14 Train Loss 1.272655 Test MSE 187.9359197449387 Test RE 0.6988234652323009\n",
      "15 Train Loss 0.88849807 Test MSE 124.95720959946266 Test RE 0.5698272864096913\n",
      "16 Train Loss 0.6114154 Test MSE 82.6165916733406 Test RE 0.46333618629271234\n",
      "17 Train Loss 0.38034764 Test MSE 45.277506229222396 Test RE 0.3430076704815137\n",
      "18 Train Loss 0.2826567 Test MSE 26.206865863706184 Test RE 0.2609577056881087\n",
      "19 Train Loss 0.1801784 Test MSE 16.556502212089857 Test RE 0.20741820820836399\n",
      "20 Train Loss 0.14796275 Test MSE 12.772985242150341 Test RE 0.1821833936595783\n",
      "21 Train Loss 0.078348905 Test MSE 3.993547846950888 Test RE 0.10186899663856532\n",
      "22 Train Loss 0.04259397 Test MSE 0.643964578686596 Test RE 0.0409066177301455\n",
      "23 Train Loss 0.025698217 Test MSE 0.011928985513497924 Test RE 0.00556755271991122\n",
      "24 Train Loss 0.020231219 Test MSE 0.02053808014960828 Test RE 0.007305374842390048\n",
      "25 Train Loss 0.0127229085 Test MSE 0.12821560642269852 Test RE 0.018252948477664524\n",
      "26 Train Loss 0.007995748 Test MSE 0.00011238240712798943 Test RE 0.0005403955294404769\n",
      "27 Train Loss 0.00603002 Test MSE 0.011888000548868292 Test RE 0.005557980142020668\n",
      "28 Train Loss 0.004800629 Test MSE 0.006381621982043162 Test RE 0.0040721908152632795\n",
      "29 Train Loss 0.0040106634 Test MSE 0.011966184475340732 Test RE 0.005576226800918607\n",
      "30 Train Loss 0.0036570665 Test MSE 0.00022132284452554447 Test RE 0.0007583604998967208\n",
      "31 Train Loss 0.0036480336 Test MSE 0.00010999392536798439 Test RE 0.0005346221314724918\n",
      "32 Train Loss 0.0036398282 Test MSE 3.936766920978853e-05 Test RE 0.00031983974752566126\n",
      "33 Train Loss 0.0036312107 Test MSE 8.256156249021292e-06 Test RE 0.00014647096210213505\n",
      "34 Train Loss 0.003621774 Test MSE 1.2758768793922942e-06 Test RE 5.7579377624911245e-05\n",
      "35 Train Loss 0.0033941043 Test MSE 0.0004987302605693987 Test RE 0.0011384014559007252\n",
      "36 Train Loss 0.0030073945 Test MSE 0.00512417211613205 Test RE 0.0036490048194299817\n",
      "37 Train Loss 0.0019495923 Test MSE 6.952117287026936e-06 Test RE 0.00013440676481490837\n",
      "38 Train Loss 0.0015306604 Test MSE 0.0012828853663364283 Test RE 0.0018258138961784688\n",
      "39 Train Loss 0.0011764545 Test MSE 8.531683631419713e-05 Test RE 0.0004708471585472278\n",
      "40 Train Loss 0.0010748565 Test MSE 0.0005585075665315432 Test RE 0.0012046950146971077\n",
      "41 Train Loss 0.0010654134 Test MSE 0.0006843785254051432 Test RE 0.0013335545004323167\n",
      "42 Train Loss 0.0010579512 Test MSE 0.0007566743115070996 Test RE 0.0014022229719120424\n",
      "43 Train Loss 0.0010494319 Test MSE 0.0006967826324223465 Test RE 0.0013455853221134445\n",
      "44 Train Loss 0.0010420653 Test MSE 0.0006533225341043995 Test RE 0.0013029459536414282\n",
      "45 Train Loss 0.0010352127 Test MSE 0.0006241595667025521 Test RE 0.0012735335727337433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 0.0010304648 Test MSE 0.0005741114577783043 Test RE 0.0012214078016819058\n",
      "47 Train Loss 0.0010257656 Test MSE 0.0005015195592702783 Test RE 0.00114158044318295\n",
      "48 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "49 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "50 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "51 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "52 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "53 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "54 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "55 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "56 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "57 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "58 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "59 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "60 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "61 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "62 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "63 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "64 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "65 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "66 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "67 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "68 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "69 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "70 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "71 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "72 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "73 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "74 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "75 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "76 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "77 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "78 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "79 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "80 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "81 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "82 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "83 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "84 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "85 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "86 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "87 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "88 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "89 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "90 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "91 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "92 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "93 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "94 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "95 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "96 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "97 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "98 Train Loss 0.0010231987 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "99 Train Loss 0.0010231988 Test MSE 0.0004413160311583185 Test RE 0.0010708716823830285\n",
      "Training time: 30.72\n",
      "Training time: 30.72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 3.3116913 Test MSE 387.03823999324857 Test RE 1.0028581784618413\n",
      "1 Train Loss 2.45448 Test MSE 381.67900353818294 Test RE 0.9958907931162034\n",
      "2 Train Loss 2.3766768 Test MSE 382.6826441312117 Test RE 0.9971993013286706\n",
      "3 Train Loss 2.368923 Test MSE 380.6075432492921 Test RE 0.994491964062786\n",
      "4 Train Loss 2.319558 Test MSE 369.54733629853143 Test RE 0.9799357923330977\n",
      "5 Train Loss 2.2615404 Test MSE 358.2958499504568 Test RE 0.9649025885003222\n",
      "6 Train Loss 2.189945 Test MSE 351.64094738768 Test RE 0.9558996514664143\n",
      "7 Train Loss 2.132112 Test MSE 338.74783557936075 Test RE 0.9382117053786662\n",
      "8 Train Loss 2.0628152 Test MSE 329.5174199231707 Test RE 0.9253409285526804\n",
      "9 Train Loss 1.9812491 Test MSE 309.4528362096921 Test RE 0.8967261119650297\n",
      "10 Train Loss 1.862166 Test MSE 290.6989902928195 Test RE 0.8691292061804784\n",
      "11 Train Loss 1.598791 Test MSE 249.03733893316746 Test RE 0.804442146321502\n",
      "12 Train Loss 1.5284005 Test MSE 231.27921804502867 Test RE 0.7752305656909667\n",
      "13 Train Loss 1.4866186 Test MSE 230.8601834578841 Test RE 0.7745279610701524\n",
      "14 Train Loss 1.4194529 Test MSE 220.18492408685262 Test RE 0.7564084511058605\n",
      "15 Train Loss 1.2642965 Test MSE 186.49885191244815 Test RE 0.6961465318328897\n",
      "16 Train Loss 1.1235405 Test MSE 164.93423802286677 Test RE 0.6546632945730774\n",
      "17 Train Loss 1.016374 Test MSE 150.906572195984 Test RE 0.6262051856140288\n",
      "18 Train Loss 0.96363246 Test MSE 142.26009734367182 Test RE 0.6080007756184783\n",
      "19 Train Loss 0.83389485 Test MSE 119.59886206266665 Test RE 0.5574759115064726\n",
      "20 Train Loss 0.64890945 Test MSE 89.01221251600153 Test RE 0.4809361036647216\n",
      "21 Train Loss 0.48889768 Test MSE 56.13840702457874 Test RE 0.3819377849073515\n",
      "22 Train Loss 0.24202496 Test MSE 20.611347432556116 Test RE 0.23142793196569808\n",
      "23 Train Loss 0.17236903 Test MSE 12.942259648346214 Test RE 0.18338661604665712\n",
      "24 Train Loss 0.15884173 Test MSE 7.568994309258337 Test RE 0.1402431545231082\n",
      "25 Train Loss 0.09856069 Test MSE 2.352254715780225 Test RE 0.07818163643025793\n",
      "26 Train Loss 0.06499033 Test MSE 1.3169093839399835 Test RE 0.0584979340724019\n",
      "27 Train Loss 0.033036713 Test MSE 0.3832390039372755 Test RE 0.0315571252756306\n",
      "28 Train Loss 0.02038151 Test MSE 0.07133879410271286 Test RE 0.013615245118280446\n",
      "29 Train Loss 0.010702049 Test MSE 0.11672686729955956 Test RE 0.017415983220081397\n",
      "30 Train Loss 0.00983985 Test MSE 0.17805922675018368 Test RE 0.021510218603956355\n",
      "31 Train Loss 0.008465944 Test MSE 0.03617329513289584 Test RE 0.009695196560595556\n",
      "32 Train Loss 0.0059551504 Test MSE 0.016596902777447884 Test RE 0.006567137470482118\n",
      "33 Train Loss 0.0042876187 Test MSE 0.0003021414423444374 Test RE 0.0008860693855505024\n",
      "34 Train Loss 0.0037858945 Test MSE 0.017725777356827635 Test RE 0.006786802756655862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.0033020682 Test MSE 0.00023604890461503215 Test RE 0.0007831835865738392\n",
      "36 Train Loss 0.0030429333 Test MSE 0.0007819688884567433 Test RE 0.0014254674991148212\n",
      "37 Train Loss 0.0027188722 Test MSE 0.0021125902886300297 Test RE 0.0023429888511170083\n",
      "38 Train Loss 0.0026563045 Test MSE 0.0006739995413350977 Test RE 0.0013234038173399975\n",
      "39 Train Loss 0.0025752236 Test MSE 6.055342980423263e-05 Test RE 0.0003966723746264019\n",
      "40 Train Loss 0.0025658829 Test MSE 0.00011563439855105781 Test RE 0.0005481584401470965\n",
      "41 Train Loss 0.0025571513 Test MSE 0.00017340233702455393 Test RE 0.000671258898147612\n",
      "42 Train Loss 0.0025487079 Test MSE 0.00019899750375736692 Test RE 0.0007190952116125664\n",
      "43 Train Loss 0.0025418059 Test MSE 0.00020061703563595292 Test RE 0.0007220154434860176\n",
      "44 Train Loss 0.002535178 Test MSE 0.0001784932073313193 Test RE 0.0006810412684088777\n",
      "45 Train Loss 0.0025292013 Test MSE 0.00012689652271486736 Test RE 0.00057423206965922\n",
      "46 Train Loss 0.0025251457 Test MSE 9.842981689278291e-05 Test RE 0.0005057383893779915\n",
      "47 Train Loss 0.0025215144 Test MSE 5.920580925098835e-05 Test RE 0.0003922335542486093\n",
      "48 Train Loss 0.0025170376 Test MSE 2.452631260898877e-05 Test RE 0.0002524519398848962\n",
      "49 Train Loss 0.00251162 Test MSE 8.557255345311935e-07 Test RE 4.7155225737634204e-05\n",
      "50 Train Loss 0.0025052135 Test MSE 1.13004914717369e-05 Test RE 0.00017136070824809964\n",
      "51 Train Loss 0.0022775508 Test MSE 0.002386761070098396 Test RE 0.0024903882310153246\n",
      "52 Train Loss 0.0020282057 Test MSE 5.572590906196045e-05 Test RE 0.00038053198229885915\n",
      "53 Train Loss 0.0011468867 Test MSE 0.01250190272200288 Test RE 0.005699682186999592\n",
      "54 Train Loss 0.00071329926 Test MSE 1.9509374850913702e-05 Test RE 0.00022515638082647063\n",
      "55 Train Loss 0.00043236147 Test MSE 6.039466773258274e-05 Test RE 0.0003961520253981548\n",
      "56 Train Loss 0.00038933527 Test MSE 0.00024176306511174782 Test RE 0.0007926063713376051\n",
      "57 Train Loss 0.00038233414 Test MSE 0.0002867127167745609 Test RE 0.0008631495739495192\n",
      "58 Train Loss 0.00037746227 Test MSE 0.00028595041560701916 Test RE 0.000862001355148931\n",
      "59 Train Loss 0.00037446772 Test MSE 0.00026807592351300353 Test RE 0.0008346251896520202\n",
      "60 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "61 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "62 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "63 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "64 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "65 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "66 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "67 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "68 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "69 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "70 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "71 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "72 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "73 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "74 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "75 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "76 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "77 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "78 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "79 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "80 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "81 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "82 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "83 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "84 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "85 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "86 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "87 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "88 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "89 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "90 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "91 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "92 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "93 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "94 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "95 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "96 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "97 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "98 Train Loss 0.00037198156 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "99 Train Loss 0.0003719816 Test MSE 0.00023778736668462436 Test RE 0.0007860623063009975\n",
      "Training time: 35.25\n",
      "Training time: 35.25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.325357 Test MSE 383.410643919823 Test RE 0.9981473662071684\n",
      "1 Train Loss 2.5120623 Test MSE 384.2834047128461 Test RE 0.9992827659621498\n",
      "2 Train Loss 2.3939257 Test MSE 383.3049755486993 Test RE 0.9980098115042765\n",
      "3 Train Loss 2.3697937 Test MSE 381.66334850940666 Test RE 0.9958703690704072\n",
      "4 Train Loss 2.362521 Test MSE 378.9905168912324 Test RE 0.9923771460231203\n",
      "5 Train Loss 2.3192854 Test MSE 369.63531641026367 Test RE 0.9800524346698629\n",
      "6 Train Loss 2.251377 Test MSE 358.5874831811014 Test RE 0.9652951975996115\n",
      "7 Train Loss 2.101353 Test MSE 328.1108953669471 Test RE 0.923363936608105\n",
      "8 Train Loss 2.0506537 Test MSE 320.94498826826975 Test RE 0.9132251885754581\n",
      "9 Train Loss 1.8636837 Test MSE 289.13079036616466 Test RE 0.8667817410371637\n",
      "10 Train Loss 1.7555761 Test MSE 273.2392260930625 Test RE 0.8426245453679799\n",
      "11 Train Loss 1.4795203 Test MSE 230.6585352874814 Test RE 0.774189625841167\n",
      "12 Train Loss 1.2545573 Test MSE 188.057642696274 Test RE 0.6990497367342507\n",
      "13 Train Loss 1.1454612 Test MSE 167.1921211166972 Test RE 0.6591291007811737\n",
      "14 Train Loss 1.0113294 Test MSE 151.56864297237388 Test RE 0.6275773538644549\n",
      "15 Train Loss 0.908794 Test MSE 133.52914803455084 Test RE 0.58904791291048\n",
      "16 Train Loss 0.8004043 Test MSE 102.06707828280865 Test RE 0.5149978596058987\n",
      "17 Train Loss 0.6165535 Test MSE 69.55125924338276 Test RE 0.4251234693128285\n",
      "18 Train Loss 0.47557086 Test MSE 57.16911590007281 Test RE 0.3854280524617998\n",
      "19 Train Loss 0.35445285 Test MSE 39.95688070761546 Test RE 0.3222243609508064\n",
      "20 Train Loss 0.21782956 Test MSE 22.229511150815828 Test RE 0.24034082003998972\n",
      "21 Train Loss 0.13624588 Test MSE 8.604549962771461 Test RE 0.14952942485915202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 0.06695484 Test MSE 4.2883917459732945 Test RE 0.105562534353467\n",
      "23 Train Loss 0.044596396 Test MSE 1.3038216259671496 Test RE 0.05820652506609801\n",
      "24 Train Loss 0.032436747 Test MSE 0.04555454116436019 Test RE 0.010879988113002096\n",
      "25 Train Loss 0.029035434 Test MSE 0.0073279990164190146 Test RE 0.0043637039998359346\n",
      "26 Train Loss 0.023101475 Test MSE 0.03195416922485941 Test RE 0.009112265140028521\n",
      "27 Train Loss 0.012233591 Test MSE 0.25372684070074697 Test RE 0.025677089120339672\n",
      "28 Train Loss 0.010269556 Test MSE 0.04672524476384963 Test RE 0.011018903382869372\n",
      "29 Train Loss 0.008681533 Test MSE 0.005595376445918442 Test RE 0.0038130915951995205\n",
      "30 Train Loss 0.008069792 Test MSE 0.0020693522133481256 Test RE 0.0023188880925106604\n",
      "31 Train Loss 0.0059511014 Test MSE 0.01900637898526073 Test RE 0.007027684804748583\n",
      "32 Train Loss 0.004397056 Test MSE 0.00153600146507429 Test RE 0.001997829388924667\n",
      "33 Train Loss 0.0036883627 Test MSE 0.002332069153085297 Test RE 0.002461689622004752\n",
      "34 Train Loss 0.0036694584 Test MSE 0.002035769138201195 Test RE 0.0022999947551566916\n",
      "35 Train Loss 0.0036628807 Test MSE 0.001999845106822723 Test RE 0.0022796110968563146\n",
      "36 Train Loss 0.0036557373 Test MSE 0.00196169729664018 Test RE 0.002257764183951219\n",
      "37 Train Loss 0.0036472976 Test MSE 0.0020481372013682196 Test RE 0.0023069708421955414\n",
      "38 Train Loss 0.0036376824 Test MSE 0.0021853288905639106 Test RE 0.0023829832305762256\n",
      "39 Train Loss 0.00345518 Test MSE 0.011130607200785674 Test RE 0.005378015021277146\n",
      "40 Train Loss 0.0032436298 Test MSE 0.013967147729319862 Test RE 0.006024436704782406\n",
      "41 Train Loss 0.0032225852 Test MSE 0.01342939767324095 Test RE 0.005907324794349156\n",
      "42 Train Loss 0.003058138 Test MSE 0.01372246551338206 Test RE 0.005971434274438396\n",
      "43 Train Loss 0.002441186 Test MSE 0.0014048193496392061 Test RE 0.0019106134151303936\n",
      "44 Train Loss 0.0022557317 Test MSE 0.0008423946261033663 Test RE 0.0014795184195831015\n",
      "45 Train Loss 0.0022488993 Test MSE 0.0008323667435732834 Test RE 0.0014706859469302278\n",
      "46 Train Loss 0.0022436015 Test MSE 0.0008263252020814345 Test RE 0.001465338909805087\n",
      "47 Train Loss 0.0022397817 Test MSE 0.000820122111830988 Test RE 0.0014598285172813922\n",
      "48 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "49 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "50 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "51 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "52 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "53 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "54 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "55 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "56 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "57 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "58 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "59 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "60 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "61 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "62 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "63 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "64 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "65 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "66 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "67 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "68 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "69 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "70 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "71 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "72 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "73 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "74 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "75 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "76 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "77 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "78 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "79 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "80 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "81 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "82 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "83 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "84 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "85 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "86 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "87 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "88 Train Loss 0.0022372142 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "89 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "90 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "91 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "92 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "93 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "94 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "95 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "96 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "97 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "98 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "99 Train Loss 0.0022372145 Test MSE 0.0008182810682469604 Test RE 0.0014581890553676995\n",
      "Training time: 32.02\n",
      "Training time: 32.02\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.5134106 Test MSE 386.13077311366885 Test RE 1.001681815823636\n",
      "1 Train Loss 2.9902544 Test MSE 383.1364470701348 Test RE 0.9977903888808191\n",
      "2 Train Loss 2.3957307 Test MSE 383.46006804107225 Test RE 0.9982116979719683\n",
      "3 Train Loss 2.3792596 Test MSE 383.33978294029157 Test RE 0.9980551244168965\n",
      "4 Train Loss 2.3766868 Test MSE 382.60102481606083 Test RE 0.9970929533330815\n",
      "5 Train Loss 2.3622336 Test MSE 377.63482576488315 Test RE 0.9906006343292518\n",
      "6 Train Loss 2.3453226 Test MSE 374.7263979197447 Test RE 0.9867786096431648\n",
      "7 Train Loss 2.2620313 Test MSE 357.30329393358755 Test RE 0.9635651685127941\n",
      "8 Train Loss 2.142282 Test MSE 336.5399768942706 Test RE 0.9351492132445057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 2.0145466 Test MSE 320.15181891848783 Test RE 0.912096038197248\n",
      "10 Train Loss 1.9018601 Test MSE 297.377765916376 Test RE 0.8790565813156962\n",
      "11 Train Loss 1.7330425 Test MSE 258.44984449493654 Test RE 0.8195033252619653\n",
      "12 Train Loss 1.577172 Test MSE 231.41989288355336 Test RE 0.7754662955966991\n",
      "13 Train Loss 1.2508267 Test MSE 164.90833900615732 Test RE 0.6546118928706129\n",
      "14 Train Loss 0.93710494 Test MSE 121.6696643378525 Test RE 0.5622814258913852\n",
      "15 Train Loss 0.78923756 Test MSE 103.15227483994137 Test RE 0.5177283984105038\n",
      "16 Train Loss 0.66887635 Test MSE 96.31410216515573 Test RE 0.5002735280161893\n",
      "17 Train Loss 0.5188033 Test MSE 65.66785421865089 Test RE 0.41308459111728224\n",
      "18 Train Loss 0.3621712 Test MSE 44.90272460733728 Test RE 0.34158510869829184\n",
      "19 Train Loss 0.27944475 Test MSE 37.26265570599157 Test RE 0.3111712643015109\n",
      "20 Train Loss 0.16303068 Test MSE 19.95162795508207 Test RE 0.22769408640745054\n",
      "21 Train Loss 0.09766354 Test MSE 10.704373203988883 Test RE 0.16677970588707416\n",
      "22 Train Loss 0.061551586 Test MSE 5.769036712751299 Test RE 0.12243743813107998\n",
      "23 Train Loss 0.050306506 Test MSE 3.8881752561983927 Test RE 0.10051606965188144\n",
      "24 Train Loss 0.033751816 Test MSE 1.8257734326912323 Test RE 0.06887887166837385\n",
      "25 Train Loss 0.019978411 Test MSE 0.9818491498668024 Test RE 0.050510883709013354\n",
      "26 Train Loss 0.013751969 Test MSE 0.12599578622619179 Test RE 0.018094250271515115\n",
      "27 Train Loss 0.010353723 Test MSE 8.31150151136836e-05 Test RE 0.0004647317313528603\n",
      "28 Train Loss 0.007116828 Test MSE 0.02146531318324371 Test RE 0.00746846237081214\n",
      "29 Train Loss 0.0049615907 Test MSE 0.012772655860235814 Test RE 0.005761070475319634\n",
      "30 Train Loss 0.0046696262 Test MSE 0.03141379684727434 Test RE 0.00903488851383364\n",
      "31 Train Loss 0.004436217 Test MSE 0.09196804544070687 Test RE 0.01545898802913245\n",
      "32 Train Loss 0.0038067093 Test MSE 0.08507733284736377 Test RE 0.014868580747713644\n",
      "33 Train Loss 0.0026840083 Test MSE 0.04497296374699853 Test RE 0.01081031470013287\n",
      "34 Train Loss 0.002510261 Test MSE 0.03830656292170494 Test RE 0.009976981702479742\n",
      "35 Train Loss 0.0025026454 Test MSE 0.0382737550821053 Test RE 0.009972708370381722\n",
      "36 Train Loss 0.002495372 Test MSE 0.03831631638915313 Test RE 0.0099782517716983\n",
      "37 Train Loss 0.002487929 Test MSE 0.03849742770588391 Test RE 0.010001806278079683\n",
      "38 Train Loss 0.0024820294 Test MSE 0.03866511812723581 Test RE 0.010023565974052266\n",
      "39 Train Loss 0.0024766065 Test MSE 0.03895198140595254 Test RE 0.010060680556532739\n",
      "40 Train Loss 0.0024715257 Test MSE 0.03922791853198576 Test RE 0.010096252766125517\n",
      "41 Train Loss 0.0024641105 Test MSE 0.039494464827693775 Test RE 0.010130495761041537\n",
      "42 Train Loss 0.002459066 Test MSE 0.03988454712063027 Test RE 0.010180401706547397\n",
      "43 Train Loss 0.0024503358 Test MSE 0.0400115828270121 Test RE 0.010196601544009263\n",
      "44 Train Loss 0.0024430025 Test MSE 0.040568351139542304 Test RE 0.010267300212264827\n",
      "45 Train Loss 0.002435229 Test MSE 0.04070028414176721 Test RE 0.010283981888561037\n",
      "46 Train Loss 0.0020262944 Test MSE 0.046933275417205246 Test RE 0.01104340538310955\n",
      "47 Train Loss 0.00091680157 Test MSE 0.016820227539346155 Test RE 0.006611172907705564\n",
      "48 Train Loss 0.0004951026 Test MSE 0.0008936888442844774 Test RE 0.0015238974801086444\n",
      "49 Train Loss 0.00047113627 Test MSE 0.0005538225345359175 Test RE 0.0011996315910679932\n",
      "50 Train Loss 0.0004663584 Test MSE 0.0004948716300364563 Test RE 0.0011339890506235181\n",
      "51 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "52 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "53 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "54 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "55 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "56 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "57 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "58 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "59 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "60 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "61 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "62 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "63 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "64 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "65 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "66 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "67 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "68 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "69 Train Loss 0.00046324308 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "70 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "71 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "72 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "73 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "74 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "75 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "76 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "77 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "78 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "79 Train Loss 0.00046324308 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "80 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "81 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "82 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "83 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "84 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "85 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "86 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "87 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "88 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "89 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "90 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "91 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "92 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "93 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "94 Train Loss 0.00046324308 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "95 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "96 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "97 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "98 Train Loss 0.0004632431 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "99 Train Loss 0.00046324314 Test MSE 0.0004536837683119849 Test RE 0.0010857734137339583\n",
      "Training time: 31.69\n",
      "Training time: 31.69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 3.0932853 Test MSE 381.860613044024 Test RE 0.9961276960159988\n",
      "1 Train Loss 2.4086845 Test MSE 384.13636410309476 Test RE 0.9990915669619164\n",
      "2 Train Loss 2.3791702 Test MSE 382.9381162418836 Test RE 0.9975321020326229\n",
      "3 Train Loss 2.3786314 Test MSE 382.7453632698695 Test RE 0.9972810151453323\n",
      "4 Train Loss 2.3724198 Test MSE 380.08313109232154 Test RE 0.9938066079108792\n",
      "5 Train Loss 2.354477 Test MSE 376.8677015948314 Test RE 0.9895939739915187\n",
      "6 Train Loss 2.3251743 Test MSE 367.84660440194455 Test RE 0.9776782601618902\n",
      "7 Train Loss 2.2418063 Test MSE 355.8178761833359 Test RE 0.9615601667220139\n",
      "8 Train Loss 2.1942058 Test MSE 351.6744379407953 Test RE 0.9559451706900349\n",
      "9 Train Loss 2.1476235 Test MSE 338.97487495935843 Test RE 0.938526062109286\n",
      "10 Train Loss 2.047821 Test MSE 327.3947788148916 Test RE 0.9223557448709537\n",
      "11 Train Loss 1.9988261 Test MSE 313.77240494104404 Test RE 0.9029630016736229\n",
      "12 Train Loss 1.9578217 Test MSE 307.16184959691856 Test RE 0.8934005583536224\n",
      "13 Train Loss 1.8733889 Test MSE 289.85328369815113 Test RE 0.8678640423956262\n",
      "14 Train Loss 1.7550633 Test MSE 269.7691510095227 Test RE 0.8372568803005901\n",
      "15 Train Loss 1.6245216 Test MSE 247.73318547132786 Test RE 0.8023330386676767\n",
      "16 Train Loss 1.4902574 Test MSE 232.09999678274843 Test RE 0.7766049417389627\n",
      "17 Train Loss 1.2948015 Test MSE 184.09480573455934 Test RE 0.691645172495576\n",
      "18 Train Loss 0.8866793 Test MSE 127.63428811852692 Test RE 0.5758989182265676\n",
      "19 Train Loss 0.7568979 Test MSE 92.51216913663397 Test RE 0.4903001369214595\n",
      "20 Train Loss 0.63988537 Test MSE 83.7486648526025 Test RE 0.4664998716381193\n",
      "21 Train Loss 0.57509404 Test MSE 80.62188938039512 Test RE 0.45770859556318755\n",
      "22 Train Loss 0.52293825 Test MSE 73.80160226317432 Test RE 0.437920703607799\n",
      "23 Train Loss 0.49144793 Test MSE 65.3868017643103 Test RE 0.41219966097296246\n",
      "24 Train Loss 0.46162862 Test MSE 60.063868097162164 Test RE 0.39506561421779834\n",
      "25 Train Loss 0.33753985 Test MSE 47.83294260969108 Test RE 0.35255439411641765\n",
      "26 Train Loss 0.30235934 Test MSE 40.397753873768835 Test RE 0.3239971514675619\n",
      "27 Train Loss 0.2375345 Test MSE 25.80163798491589 Test RE 0.258932295377577\n",
      "28 Train Loss 0.20781699 Test MSE 16.8833335394278 Test RE 0.2094554584620863\n",
      "29 Train Loss 0.194634 Test MSE 11.153219626217368 Test RE 0.1702404308242262\n",
      "30 Train Loss 0.18195699 Test MSE 7.321304033889471 Test RE 0.1379293862386961\n",
      "31 Train Loss 0.1672114 Test MSE 7.540621377664249 Test RE 0.13998005183939824\n",
      "32 Train Loss 0.13790977 Test MSE 12.501318201052195 Test RE 0.18023556293518478\n",
      "33 Train Loss 0.0989321 Test MSE 11.014523193109465 Test RE 0.16917860260000964\n",
      "34 Train Loss 0.051855747 Test MSE 3.1065338669293117 Test RE 0.08984638934680252\n",
      "35 Train Loss 0.024027787 Test MSE 0.5961593830298342 Test RE 0.03935897450610696\n",
      "36 Train Loss 0.013751953 Test MSE 0.43554370433362677 Test RE 0.03364174021167408\n",
      "37 Train Loss 0.011155008 Test MSE 0.17048904518124686 Test RE 0.021047999355942645\n",
      "38 Train Loss 0.009153347 Test MSE 4.073370237292977e-05 Test RE 0.0003253415455280606\n",
      "39 Train Loss 0.008199596 Test MSE 0.003358614400133658 Test RE 0.0029542187851018227\n",
      "40 Train Loss 0.00794875 Test MSE 0.0028527217346100892 Test RE 0.0027226529601558805\n",
      "41 Train Loss 0.007942731 Test MSE 0.0025753867089583654 Test RE 0.0025869248195385906\n",
      "42 Train Loss 0.007938294 Test MSE 0.002303735424485682 Test RE 0.0024466896384724574\n",
      "43 Train Loss 0.007935086 Test MSE 0.002067601457467366 Test RE 0.002317906948268429\n",
      "44 Train Loss 0.007933831 Test MSE 0.0018403813174237382 Test RE 0.002186837388648326\n",
      "45 Train Loss 0.007931725 Test MSE 0.0016081015670902656 Test RE 0.0020441808717984915\n",
      "46 Train Loss 0.007926863 Test MSE 0.0013704265080723014 Test RE 0.0018870806343009394\n",
      "47 Train Loss 0.007924485 Test MSE 0.001130548452630214 Test RE 0.001713985614192525\n",
      "48 Train Loss 0.007919863 Test MSE 0.0008729743280255857 Test RE 0.0015061329810092245\n",
      "49 Train Loss 0.007912394 Test MSE 0.0005838834723188627 Test RE 0.0012317587997188499\n",
      "50 Train Loss 0.007904061 Test MSE 0.00030765660956183407 Test RE 0.0008941197898883848\n",
      "51 Train Loss 0.0069262 Test MSE 0.03729222051512051 Test RE 0.009844002250905632\n",
      "52 Train Loss 0.004387613 Test MSE 0.00021771320298637938 Test RE 0.0007521508768072572\n",
      "53 Train Loss 0.0029768012 Test MSE 0.0015663773305645428 Test RE 0.002017487149376691\n",
      "54 Train Loss 0.0021763537 Test MSE 0.003841331879629478 Test RE 0.0031593918812451898\n",
      "55 Train Loss 0.0019533262 Test MSE 0.00022727438535138404 Test RE 0.0007684893061495659\n",
      "56 Train Loss 0.0019489505 Test MSE 0.00021299868815297454 Test RE 0.0007439625029187311\n",
      "57 Train Loss 0.0019421913 Test MSE 0.00044684833154297706 Test RE 0.001077562955736565\n",
      "58 Train Loss 0.0019390862 Test MSE 0.000711027609132222 Test RE 0.001359270259869469\n",
      "59 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "60 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "61 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "62 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "63 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "64 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "65 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "66 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "67 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "68 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "69 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "70 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "71 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "72 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "73 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "74 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "75 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "76 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "77 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "78 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "79 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "80 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "81 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "82 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "83 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "84 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "85 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "86 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "87 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "88 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "89 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "90 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "91 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "92 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "93 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "94 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "95 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "96 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "97 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "98 Train Loss 0.0019361972 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0019361973 Test MSE 0.0007355321033917763 Test RE 0.001382494457861302\n",
      "Training time: 37.08\n",
      "Training time: 37.08\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.063854 Test MSE 380.91411672340735 Test RE 0.9948924073691745\n",
      "1 Train Loss 2.3884227 Test MSE 380.9466836955339 Test RE 0.9949349365632479\n",
      "2 Train Loss 2.3684883 Test MSE 381.350355721982 Test RE 0.9954619408382992\n",
      "3 Train Loss 2.3249598 Test MSE 372.4359661056394 Test RE 0.983758254800637\n",
      "4 Train Loss 2.2866821 Test MSE 360.9000303792605 Test RE 0.9684028119634011\n",
      "5 Train Loss 2.1637175 Test MSE 342.31826402828824 Test RE 0.9431431570248738\n",
      "6 Train Loss 1.9367772 Test MSE 307.25005321783027 Test RE 0.8935288221793775\n",
      "7 Train Loss 1.7508439 Test MSE 263.3530317908006 Test RE 0.8272404148739436\n",
      "8 Train Loss 1.4802221 Test MSE 209.89013541561746 Test RE 0.7385137683253563\n",
      "9 Train Loss 1.283247 Test MSE 171.31605984198205 Test RE 0.6672085780149597\n",
      "10 Train Loss 0.8893032 Test MSE 134.58102604815443 Test RE 0.5913634788382511\n",
      "11 Train Loss 0.6285645 Test MSE 84.3208179650269 Test RE 0.46809067333942156\n",
      "12 Train Loss 0.54723865 Test MSE 72.37142911103729 Test RE 0.4336567960954213\n",
      "13 Train Loss 0.47169587 Test MSE 65.00438864560024 Test RE 0.41099252356387556\n",
      "14 Train Loss 0.4246261 Test MSE 52.82294439363701 Test RE 0.37048777768358276\n",
      "15 Train Loss 0.3131685 Test MSE 33.829612878180434 Test RE 0.29649071442306424\n",
      "16 Train Loss 0.25497308 Test MSE 17.077606138711264 Test RE 0.21065708929338525\n",
      "17 Train Loss 0.16520259 Test MSE 20.622002670226344 Test RE 0.23148774370323055\n",
      "18 Train Loss 0.12051645 Test MSE 11.750896050979902 Test RE 0.17474231089383008\n",
      "19 Train Loss 0.09922999 Test MSE 7.04042827439218 Test RE 0.13525773848475492\n",
      "20 Train Loss 0.06335932 Test MSE 1.8732599283738791 Test RE 0.06976885634517199\n",
      "21 Train Loss 0.059714824 Test MSE 1.6305448755545393 Test RE 0.06509220154403764\n",
      "22 Train Loss 0.046600256 Test MSE 0.0018475661603547335 Test RE 0.002191101933687051\n",
      "23 Train Loss 0.03571898 Test MSE 1.2235484850890384 Test RE 0.05638624504168235\n",
      "24 Train Loss 0.012233648 Test MSE 0.00393336349113506 Test RE 0.003197014630481374\n",
      "25 Train Loss 0.0096254395 Test MSE 0.020276703345473965 Test RE 0.0072587402584944095\n",
      "26 Train Loss 0.008635713 Test MSE 0.0004403440776819606 Test RE 0.0010696917896333997\n",
      "27 Train Loss 0.007204166 Test MSE 0.014845586764176522 Test RE 0.006210996239495056\n",
      "28 Train Loss 0.0064068027 Test MSE 0.0013821300050078527 Test RE 0.0018951213756051657\n",
      "29 Train Loss 0.0045233388 Test MSE 0.011066742540466926 Test RE 0.005362563968418491\n",
      "30 Train Loss 0.0034099366 Test MSE 0.002783072703637358 Test RE 0.002689210872359514\n",
      "31 Train Loss 0.0034031274 Test MSE 0.003411442688924028 Test RE 0.002977361871045316\n",
      "32 Train Loss 0.0033958596 Test MSE 0.004145985699291983 Test RE 0.00328228646898564\n",
      "33 Train Loss 0.0030523734 Test MSE 0.02568265394826057 Test RE 0.008169256504138066\n",
      "34 Train Loss 0.0030189005 Test MSE 0.026158373799766297 Test RE 0.008244568928741891\n",
      "35 Train Loss 0.003014934 Test MSE 0.026199529768865668 Test RE 0.00825105212735237\n",
      "36 Train Loss 0.0030106904 Test MSE 0.0263045969930459 Test RE 0.00826758005263142\n",
      "37 Train Loss 0.0030035106 Test MSE 0.026056715594755787 Test RE 0.008228533070271663\n",
      "38 Train Loss 0.0019568044 Test MSE 0.007252544557827121 Test RE 0.004341179918431927\n",
      "39 Train Loss 0.0013125286 Test MSE 0.0006112573640972265 Test RE 0.0012603020267963365\n",
      "40 Train Loss 0.00088018016 Test MSE 0.0006112867886879674 Test RE 0.0012603323605209287\n",
      "41 Train Loss 0.00047173124 Test MSE 0.00047242209433492844 Test RE 0.0011079691873622608\n",
      "42 Train Loss 0.000308818 Test MSE 0.003183106300003747 Test RE 0.0028759951783139783\n",
      "43 Train Loss 0.0003038242 Test MSE 0.003269525315729838 Test RE 0.0029147743208893075\n",
      "44 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "45 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "46 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "47 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "48 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "49 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "50 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "51 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "52 Train Loss 0.00030048788 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "53 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "54 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "55 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "56 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "57 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "58 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "59 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "60 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "61 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "62 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "63 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "64 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "65 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "66 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "67 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "68 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "69 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "70 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "71 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "72 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "73 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "74 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "75 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "76 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "77 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "78 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "79 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "80 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "81 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "82 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "83 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "84 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "85 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "86 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "87 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "89 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "90 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "91 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "92 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "93 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "94 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "95 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "96 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "97 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "98 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "99 Train Loss 0.00030048785 Test MSE 0.0035303285474813833 Test RE 0.003028796849085452\n",
      "Training time: 32.11\n",
      "Training time: 32.11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 2.882927 Test MSE 384.1214845906878 Test RE 0.9990722168811679\n",
      "1 Train Loss 2.389953 Test MSE 383.91722821701063 Test RE 0.9988065535278102\n",
      "2 Train Loss 2.3815782 Test MSE 383.77252905661766 Test RE 0.9986183097089454\n",
      "3 Train Loss 2.3789926 Test MSE 383.1871105872026 Test RE 0.9978563574146663\n",
      "4 Train Loss 2.3665144 Test MSE 380.5273943119898 Test RE 0.99438724770579\n",
      "5 Train Loss 2.3235724 Test MSE 370.84193725538137 Test RE 0.9816507508336333\n",
      "6 Train Loss 2.2486405 Test MSE 353.05717594893343 Test RE 0.9578226528428424\n",
      "7 Train Loss 2.1143706 Test MSE 333.3152286814072 Test RE 0.9306580981470349\n",
      "8 Train Loss 2.0301673 Test MSE 320.9125500329616 Test RE 0.9131790371115093\n",
      "9 Train Loss 1.8794613 Test MSE 292.67600417397296 Test RE 0.8720796273936609\n",
      "10 Train Loss 1.6647005 Test MSE 254.53587330498914 Test RE 0.8132743625284812\n",
      "11 Train Loss 1.4156952 Test MSE 209.67956139814527 Test RE 0.7381432153333035\n",
      "12 Train Loss 1.0716484 Test MSE 164.446501114358 Test RE 0.6536946058922005\n",
      "13 Train Loss 1.0013455 Test MSE 149.45053174850105 Test RE 0.6231768545895252\n",
      "14 Train Loss 0.8457782 Test MSE 129.23236203111662 Test RE 0.5794930391681233\n",
      "15 Train Loss 0.725224 Test MSE 104.77497998149121 Test RE 0.5217847425510898\n",
      "16 Train Loss 0.65996253 Test MSE 93.58797320952637 Test RE 0.4931426942372864\n",
      "17 Train Loss 0.50580657 Test MSE 71.08243301382888 Test RE 0.4297775489631142\n",
      "18 Train Loss 0.40694886 Test MSE 43.83648429453521 Test RE 0.3375051783905799\n",
      "19 Train Loss 0.38180178 Test MSE 36.685526412478474 Test RE 0.3087521284440093\n",
      "20 Train Loss 0.32022163 Test MSE 37.277415149100314 Test RE 0.31123288443822816\n",
      "21 Train Loss 0.2539131 Test MSE 23.285749329927913 Test RE 0.24598447132047016\n",
      "22 Train Loss 0.14058298 Test MSE 13.41815932044055 Test RE 0.1867278318886799\n",
      "23 Train Loss 0.062246438 Test MSE 6.419119059745599 Test RE 0.1291517508229262\n",
      "24 Train Loss 0.028826848 Test MSE 1.2292510877383698 Test RE 0.056517492214990556\n",
      "25 Train Loss 0.018723933 Test MSE 0.16213841539556578 Test RE 0.020526057665372147\n",
      "26 Train Loss 0.015417039 Test MSE 0.2197615185745867 Test RE 0.023896726124920886\n",
      "27 Train Loss 0.013379253 Test MSE 0.02073430995795269 Test RE 0.007340191251880854\n",
      "28 Train Loss 0.0062391367 Test MSE 0.08172717657309557 Test RE 0.014572894818284153\n",
      "29 Train Loss 0.0039602984 Test MSE 0.12731971089318336 Test RE 0.018189066234816864\n",
      "30 Train Loss 0.0017116711 Test MSE 0.006786486823580071 Test RE 0.004199379150160647\n",
      "31 Train Loss 0.0016301776 Test MSE 0.0011990600402955415 Test RE 0.0017651558140915717\n",
      "32 Train Loss 0.0014076263 Test MSE 0.0004273153916939603 Test RE 0.0010537482117454324\n",
      "33 Train Loss 0.0011858045 Test MSE 0.0019241636403429321 Test RE 0.002236060677979651\n",
      "34 Train Loss 0.0011520025 Test MSE 0.000602198969356225 Test RE 0.0012509287859649113\n",
      "35 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "36 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "37 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "38 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "39 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "40 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "41 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "42 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "43 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "44 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "45 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "46 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "47 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "48 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "49 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "50 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "51 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "52 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "53 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "54 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "55 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "56 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "57 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "58 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "59 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "60 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "61 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "62 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "63 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "64 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "65 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "66 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "67 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "68 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "69 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "70 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "71 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "72 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "73 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "74 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "75 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "76 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "77 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "79 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "80 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "81 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "82 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "83 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "84 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "85 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "86 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "87 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "88 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "89 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "90 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "91 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "92 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "93 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "94 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "95 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "96 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "97 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "98 Train Loss 0.0011468957 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "99 Train Loss 0.0011468956 Test MSE 0.0002918527347826913 Test RE 0.0008708522256752432\n",
      "Training time: 29.44\n",
      "Training time: 29.44\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 2.7658355 Test MSE 382.2349575116303 Test RE 0.9966158368915713\n",
      "1 Train Loss 2.3875961 Test MSE 383.0433364846624 Test RE 0.9976691390060494\n",
      "2 Train Loss 2.3802395 Test MSE 383.1837370661105 Test RE 0.9978519649171308\n",
      "3 Train Loss 2.368202 Test MSE 381.0807428455449 Test RE 0.9951099852055071\n",
      "4 Train Loss 2.339085 Test MSE 375.3975757080763 Test RE 0.9876619308987293\n",
      "5 Train Loss 2.292937 Test MSE 365.21293246180244 Test RE 0.9741720306730873\n",
      "6 Train Loss 2.237275 Test MSE 356.93895841780085 Test RE 0.9630737784852225\n",
      "7 Train Loss 2.1566665 Test MSE 341.85652826781654 Test RE 0.9425068633795227\n",
      "8 Train Loss 2.0883334 Test MSE 329.1089050050006 Test RE 0.9247671610012668\n",
      "9 Train Loss 1.9838798 Test MSE 311.60170703166256 Test RE 0.8998342025799957\n",
      "10 Train Loss 1.769708 Test MSE 278.23387630221606 Test RE 0.8502910066910002\n",
      "11 Train Loss 1.5588088 Test MSE 241.49258588285193 Test RE 0.7921628719231822\n",
      "12 Train Loss 1.4485474 Test MSE 217.7864443847956 Test RE 0.7522773825702102\n",
      "13 Train Loss 1.3445183 Test MSE 206.92718158930612 Test RE 0.7332825561558878\n",
      "14 Train Loss 1.2395322 Test MSE 178.77996369194648 Test RE 0.6815881086640019\n",
      "15 Train Loss 0.91396 Test MSE 125.9173799572516 Test RE 0.5720123714150634\n",
      "16 Train Loss 0.8603211 Test MSE 116.42451378814994 Test RE 0.5500280006523123\n",
      "17 Train Loss 0.7287494 Test MSE 96.83478807758236 Test RE 0.5016239754945535\n",
      "18 Train Loss 0.584582 Test MSE 81.38744021565573 Test RE 0.45987656332123994\n",
      "19 Train Loss 0.5643201 Test MSE 75.61114458856169 Test RE 0.44325688357992693\n",
      "20 Train Loss 0.48153925 Test MSE 68.58033971776813 Test RE 0.4221457278902017\n",
      "21 Train Loss 0.39828408 Test MSE 45.17478587777026 Test RE 0.3426183615538913\n",
      "22 Train Loss 0.32753623 Test MSE 20.065792978590537 Test RE 0.2283446002599883\n",
      "23 Train Loss 0.2109605 Test MSE 10.759059472094252 Test RE 0.1672051834217569\n",
      "24 Train Loss 0.09615259 Test MSE 1.1855788151842854 Test RE 0.05550444925805332\n",
      "25 Train Loss 0.06658539 Test MSE 0.8442471657570123 Test RE 0.04683789710549063\n",
      "26 Train Loss 0.04242993 Test MSE 0.8899746674001676 Test RE 0.04808962660425702\n",
      "27 Train Loss 0.02900657 Test MSE 1.5332977445705942 Test RE 0.06312128492027842\n",
      "28 Train Loss 0.016850922 Test MSE 0.12544879369151463 Test RE 0.018054930761109044\n",
      "29 Train Loss 0.0146418605 Test MSE 0.13143549292178075 Test RE 0.018480721043267943\n",
      "30 Train Loss 0.013065918 Test MSE 0.08156501577906679 Test RE 0.014558430072995001\n",
      "31 Train Loss 0.00827974 Test MSE 0.3723460170105746 Test RE 0.031105410620173215\n",
      "32 Train Loss 0.008148951 Test MSE 0.3891276639291771 Test RE 0.03179864658689132\n",
      "33 Train Loss 0.0075615514 Test MSE 0.33028680738349453 Test RE 0.02929599116979649\n",
      "34 Train Loss 0.0032286148 Test MSE 0.03397383743028046 Test RE 0.009395824250520091\n",
      "35 Train Loss 0.0027411021 Test MSE 0.00867042429229669 Test RE 0.004746601342774708\n",
      "36 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "37 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "38 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "39 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "40 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "41 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "42 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "43 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "44 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "45 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "46 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "47 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "48 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "49 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "50 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "51 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "52 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "53 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "54 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "55 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "56 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "57 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "58 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "59 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "60 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "61 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "62 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "63 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "64 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "65 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "66 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Train Loss 0.0027378644 Test MSE 0.008618076480575013 Test RE 0.004732250812564089\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 71.19\n",
      "Training time: 71.19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 3.9353828 Test MSE 381.4635294600286 Test RE 0.9956096420137545\n",
      "1 Train Loss 2.3896577 Test MSE 381.8183204870505 Test RE 0.9960725319686422\n",
      "2 Train Loss 2.3516226 Test MSE 377.5272046119303 Test RE 0.9904594699400237\n",
      "3 Train Loss 2.3082643 Test MSE 368.3644378134779 Test RE 0.9783661779135121\n",
      "4 Train Loss 2.2447622 Test MSE 357.6658301721642 Test RE 0.9640538831871557\n",
      "5 Train Loss 2.2164063 Test MSE 351.84703618870947 Test RE 0.9561797260121294\n",
      "6 Train Loss 2.1392226 Test MSE 334.7458850717769 Test RE 0.9326532459584721\n",
      "7 Train Loss 2.051133 Test MSE 326.27962424743777 Test RE 0.9207835655823368\n",
      "8 Train Loss 1.9835997 Test MSE 313.03111307391185 Test RE 0.9018957393374913\n",
      "9 Train Loss 1.9094367 Test MSE 296.4221740813641 Test RE 0.877643067424322\n",
      "10 Train Loss 1.7546451 Test MSE 274.2942669804832 Test RE 0.8442497637725129\n",
      "11 Train Loss 1.5590293 Test MSE 235.30860266962904 Test RE 0.7819545030552808\n",
      "12 Train Loss 1.3181927 Test MSE 202.85863333059078 Test RE 0.7260379638969973\n",
      "13 Train Loss 1.0130157 Test MSE 131.76255542135954 Test RE 0.5851383827495248\n",
      "14 Train Loss 0.749321 Test MSE 92.49406857064807 Test RE 0.49025216947996386\n",
      "15 Train Loss 0.6166289 Test MSE 74.94269162829588 Test RE 0.441293190576574\n",
      "16 Train Loss 0.43368456 Test MSE 62.723020928250925 Test RE 0.4037160970935653\n",
      "17 Train Loss 0.27733716 Test MSE 25.00074601312232 Test RE 0.25488194147431015\n",
      "18 Train Loss 0.2334126 Test MSE 25.322988611190276 Test RE 0.25651930959052804\n",
      "19 Train Loss 0.13745171 Test MSE 15.999586283946753 Test RE 0.20389987472668622\n",
      "20 Train Loss 0.09139603 Test MSE 7.828993066745607 Test RE 0.1426315286455539\n",
      "21 Train Loss 0.0636353 Test MSE 2.9855425250467387 Test RE 0.08807937277009657\n",
      "22 Train Loss 0.05804749 Test MSE 0.6404465681903101 Test RE 0.04079472726227468\n",
      "23 Train Loss 0.02282122 Test MSE 0.12164872745169049 Test RE 0.017779369985958634\n",
      "24 Train Loss 0.018142745 Test MSE 0.13096004720196952 Test RE 0.01844726531559432\n",
      "25 Train Loss 0.015640918 Test MSE 0.043538889111049535 Test RE 0.010636561474676379\n",
      "26 Train Loss 0.00452606 Test MSE 0.09081110747287821 Test RE 0.015361444940436963\n",
      "27 Train Loss 0.0034073577 Test MSE 0.08322068355731532 Test RE 0.014705446716171055\n",
      "28 Train Loss 0.0029369404 Test MSE 0.0844781395093947 Test RE 0.01481612907613978\n",
      "29 Train Loss 0.00150258 Test MSE 0.010215686599158334 Test RE 0.0051522432985334965\n",
      "30 Train Loss 0.0013276988 Test MSE 0.004669945279756747 Test RE 0.00348352136435937\n",
      "31 Train Loss 0.0012865021 Test MSE 0.0032019799883063428 Test RE 0.0028845089392686863\n",
      "32 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "33 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "34 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "35 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "36 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "37 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "38 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "39 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "40 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "41 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "42 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "43 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "44 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "45 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "46 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "47 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "48 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "49 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "50 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "51 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "52 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "53 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "54 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "55 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "56 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "57 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "58 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "59 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "60 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "61 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "62 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "63 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "64 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "65 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "66 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "67 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "68 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "69 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "70 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "71 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "72 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "73 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "75 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "76 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "77 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "78 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "79 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "80 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "81 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "82 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "83 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "84 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "85 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "86 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "87 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "88 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "89 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "90 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "91 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "92 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "93 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "94 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "95 Train Loss 0.0012817673 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "96 Train Loss 0.001281767 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "97 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "98 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "99 Train Loss 0.0012817672 Test MSE 0.0035427424171226053 Test RE 0.0030341173304299033\n",
      "Training time: 27.83\n",
      "Training time: 27.83\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 2.8281963 Test MSE 384.73491746844445 Test RE 0.9998696459272348\n",
      "1 Train Loss 2.3836403 Test MSE 382.20735487491976 Test RE 0.9965798515362297\n",
      "2 Train Loss 2.3685174 Test MSE 381.2693229860877 Test RE 0.9953561728890957\n",
      "3 Train Loss 2.3585515 Test MSE 379.94607014327613 Test RE 0.9936274045370592\n",
      "4 Train Loss 2.3449018 Test MSE 376.27555477861546 Test RE 0.988816227212971\n",
      "5 Train Loss 2.331341 Test MSE 373.3928572634543 Test RE 0.9850212178192732\n",
      "6 Train Loss 2.2772014 Test MSE 363.3805248970462 Test RE 0.9717250678531657\n",
      "7 Train Loss 2.2182822 Test MSE 351.00016758679755 Test RE 0.9550283074292542\n",
      "8 Train Loss 2.1480954 Test MSE 342.53322278882916 Test RE 0.9434392339336732\n",
      "9 Train Loss 2.0803986 Test MSE 329.6796050697731 Test RE 0.9255686222694367\n",
      "10 Train Loss 2.0243204 Test MSE 317.8766406624947 Test RE 0.9088493268567754\n",
      "11 Train Loss 1.8980104 Test MSE 300.277206868844 Test RE 0.8833315984762701\n",
      "12 Train Loss 1.7682498 Test MSE 276.2320234034726 Test RE 0.8472266237731313\n",
      "13 Train Loss 1.6889284 Test MSE 263.2101363812245 Test RE 0.8270159540114906\n",
      "14 Train Loss 1.5541193 Test MSE 242.53361107055787 Test RE 0.793868461916884\n",
      "15 Train Loss 1.3417538 Test MSE 202.25928693716222 Test RE 0.7249646299319724\n",
      "16 Train Loss 1.1854316 Test MSE 183.58009191007176 Test RE 0.6906776044125625\n",
      "17 Train Loss 1.0283768 Test MSE 155.8014528743396 Test RE 0.6362800904540675\n",
      "18 Train Loss 0.9006602 Test MSE 132.86582412735876 Test RE 0.5875830042061021\n",
      "19 Train Loss 0.698191 Test MSE 91.31486711527076 Test RE 0.4871170469764767\n",
      "20 Train Loss 0.61072314 Test MSE 79.30341564409784 Test RE 0.4539505316322599\n",
      "21 Train Loss 0.5611332 Test MSE 70.96642048913465 Test RE 0.42942668914603505\n",
      "22 Train Loss 0.5128995 Test MSE 71.56592187357384 Test RE 0.4312367035221243\n",
      "23 Train Loss 0.4076877 Test MSE 49.15627116950885 Test RE 0.357397942668836\n",
      "24 Train Loss 0.33199644 Test MSE 36.551844323139846 Test RE 0.3081890685192887\n",
      "25 Train Loss 0.25447872 Test MSE 35.41383093393985 Test RE 0.3033535190537517\n",
      "26 Train Loss 0.183175 Test MSE 20.2318210972561 Test RE 0.22928733711655452\n",
      "27 Train Loss 0.1227964 Test MSE 8.668125862613365 Test RE 0.15008081757536387\n",
      "28 Train Loss 0.07664378 Test MSE 5.462799761501137 Test RE 0.11914346419470057\n",
      "29 Train Loss 0.055891424 Test MSE 3.3050964906233866 Test RE 0.09267330554058076\n",
      "30 Train Loss 0.042595558 Test MSE 1.4800160285325359 Test RE 0.06201486347439304\n",
      "31 Train Loss 0.033596188 Test MSE 2.3092570717426644 Test RE 0.07746378681775315\n",
      "32 Train Loss 0.02938091 Test MSE 1.819902186397287 Test RE 0.068768033583642\n",
      "33 Train Loss 0.023846764 Test MSE 1.1163363345488657 Test RE 0.05385922659124584\n",
      "34 Train Loss 0.016514558 Test MSE 0.7442404287513108 Test RE 0.04397635315487033\n",
      "35 Train Loss 0.012746147 Test MSE 0.1205471917641297 Test RE 0.017698690361329598\n",
      "36 Train Loss 0.011588521 Test MSE 0.16132349276031693 Test RE 0.020474409757017243\n",
      "37 Train Loss 0.0072422978 Test MSE 0.11862073905661825 Test RE 0.01755670028724375\n",
      "38 Train Loss 0.0042010066 Test MSE 0.22174097642571247 Test RE 0.02400410734979213\n",
      "39 Train Loss 0.003631868 Test MSE 0.11566689265611105 Test RE 0.017336727254924023\n",
      "40 Train Loss 0.0033174849 Test MSE 0.08950562037923111 Test RE 0.01525062829380109\n",
      "41 Train Loss 0.003003447 Test MSE 0.05692995695866219 Test RE 0.012162784451684047\n",
      "42 Train Loss 0.0029572796 Test MSE 0.04168026451454035 Test RE 0.010407054185153105\n",
      "43 Train Loss 0.002950885 Test MSE 0.040812197214203545 Test RE 0.010298111052005197\n",
      "44 Train Loss 0.0021693998 Test MSE 0.035485972114158354 Test RE 0.009602646376597473\n",
      "45 Train Loss 0.0015458134 Test MSE 0.000845816101842764 Test RE 0.0014825199859108806\n",
      "46 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "47 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "48 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "49 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "50 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "51 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "52 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "53 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "54 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "55 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "56 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "57 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "58 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "59 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "60 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "61 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "62 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "63 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "64 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "66 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "67 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "68 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "69 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "70 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "71 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "72 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "73 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "74 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "75 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "76 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "77 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "78 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "79 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "80 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "81 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "82 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "83 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "84 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "85 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "86 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "87 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "88 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "89 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "90 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "91 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "92 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "93 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "94 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "95 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "96 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "97 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "98 Train Loss 0.001540985 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "99 Train Loss 0.0015409851 Test MSE 0.00110438813442229 Test RE 0.0016940391719984286\n",
      "Training time: 35.78\n",
      "Training time: 35.78\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.009883 Test MSE 379.8915089251102 Test RE 0.9935560582693987\n",
      "1 Train Loss 2.4465685 Test MSE 386.08313156136444 Test RE 1.001620019209596\n",
      "2 Train Loss 2.396288 Test MSE 384.99430149863764 Test RE 1.0002066396710063\n",
      "3 Train Loss 2.3689897 Test MSE 381.38533772174486 Test RE 0.9955075976081065\n",
      "4 Train Loss 2.3187284 Test MSE 370.04442805378955 Test RE 0.9805946447387333\n",
      "5 Train Loss 2.2693672 Test MSE 360.37340882938423 Test RE 0.9676960124030273\n",
      "6 Train Loss 2.1257539 Test MSE 339.75415832302593 Test RE 0.9396042509875964\n",
      "7 Train Loss 2.08035 Test MSE 328.08210590839997 Test RE 0.9233234263243877\n",
      "8 Train Loss 1.9670769 Test MSE 302.10918274921863 Test RE 0.886022081541962\n",
      "9 Train Loss 1.7991072 Test MSE 283.40165057353425 Test RE 0.8581511131902372\n",
      "10 Train Loss 1.6706185 Test MSE 260.14881363717484 Test RE 0.8221924934434657\n",
      "11 Train Loss 1.5338988 Test MSE 233.18748779393667 Test RE 0.778422184182748\n",
      "12 Train Loss 1.4198326 Test MSE 218.35868255222388 Test RE 0.7532650460311622\n",
      "13 Train Loss 1.2664671 Test MSE 185.412046788572 Test RE 0.6941152028134148\n",
      "14 Train Loss 0.90772367 Test MSE 110.12910865823551 Test RE 0.534950557730929\n",
      "15 Train Loss 0.6347092 Test MSE 76.94599941050785 Test RE 0.44715244001883186\n",
      "16 Train Loss 0.47947776 Test MSE 56.840597121958005 Test RE 0.3843190377483047\n",
      "17 Train Loss 0.37737355 Test MSE 46.288358675740284 Test RE 0.34681547957475894\n",
      "18 Train Loss 0.31154838 Test MSE 38.5601134760324 Test RE 0.31654228582385435\n",
      "19 Train Loss 0.23580666 Test MSE 29.034891539524615 Test RE 0.27467724738237365\n",
      "20 Train Loss 0.208736 Test MSE 23.69567956094879 Test RE 0.24814022211310993\n",
      "21 Train Loss 0.18420692 Test MSE 14.394556871841441 Test RE 0.19340234361708916\n",
      "22 Train Loss 0.1331468 Test MSE 7.674787339535157 Test RE 0.1412198538688184\n",
      "23 Train Loss 0.11056669 Test MSE 6.974156289745261 Test RE 0.13461963860759707\n",
      "24 Train Loss 0.06221679 Test MSE 4.7141170107237835 Test RE 0.11067837180212438\n",
      "25 Train Loss 0.051593415 Test MSE 2.4085959497583262 Test RE 0.07911239975665979\n",
      "26 Train Loss 0.032299865 Test MSE 1.5388183050858546 Test RE 0.06323481530937317\n",
      "27 Train Loss 0.02421509 Test MSE 2.252898272886116 Test RE 0.0765126728405714\n",
      "28 Train Loss 0.014948433 Test MSE 0.8258063028906619 Test RE 0.0463235334733212\n",
      "29 Train Loss 0.011440198 Test MSE 0.3846123427210758 Test RE 0.03161361726492654\n",
      "30 Train Loss 0.010539284 Test MSE 0.07510700948102236 Test RE 0.013970206240149352\n",
      "31 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "32 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "33 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "34 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "35 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "36 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "37 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "38 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "39 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "40 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "41 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "42 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "43 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "44 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "45 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "46 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "47 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "48 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "49 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "50 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "51 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "52 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "53 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "54 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "55 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "56 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "58 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "59 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "60 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "61 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "62 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "63 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "64 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "65 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "66 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "67 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "68 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "69 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "70 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "71 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "72 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "73 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "74 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "75 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "76 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "77 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "78 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "79 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "80 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "81 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "82 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "83 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "84 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "85 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "86 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "87 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "88 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "89 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "90 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "91 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "92 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "93 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "94 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "95 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "96 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "97 Train Loss 0.01051368 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "98 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "99 Train Loss 0.010513681 Test MSE 0.0720262567730076 Test RE 0.013680690093415483\n",
      "Training time: 28.66\n",
      "Training time: 28.66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 3.192528 Test MSE 386.54147429610947 Test RE 1.0022143848397933\n",
      "1 Train Loss 2.391243 Test MSE 382.78266533784534 Test RE 0.9973296110807056\n",
      "2 Train Loss 2.3763933 Test MSE 382.77502186158233 Test RE 0.9973196535983608\n",
      "3 Train Loss 2.3688164 Test MSE 380.6023533036434 Test RE 0.9944851836180363\n",
      "4 Train Loss 2.3036222 Test MSE 364.2587645058398 Test RE 0.9728986205971261\n",
      "5 Train Loss 2.206641 Test MSE 353.9982822493338 Test RE 0.9590983853504618\n",
      "6 Train Loss 2.1541815 Test MSE 341.62494909379654 Test RE 0.9421875745559045\n",
      "7 Train Loss 2.0782506 Test MSE 327.389585354639 Test RE 0.922348429181751\n",
      "8 Train Loss 1.9816935 Test MSE 313.8523843037719 Test RE 0.9030780752155319\n",
      "9 Train Loss 1.7058864 Test MSE 259.9688866381954 Test RE 0.8219081173324325\n",
      "10 Train Loss 1.3630153 Test MSE 190.69072859446453 Test RE 0.7039265917956921\n",
      "11 Train Loss 1.1389253 Test MSE 166.15949071367476 Test RE 0.6570904551845637\n",
      "12 Train Loss 0.93505275 Test MSE 112.27763642198059 Test RE 0.5401435735317737\n",
      "13 Train Loss 0.61947083 Test MSE 69.79308883665036 Test RE 0.42586190472363955\n",
      "14 Train Loss 0.4677729 Test MSE 57.62838307853784 Test RE 0.38697312064715\n",
      "15 Train Loss 0.31032616 Test MSE 37.15201795507714 Test RE 0.31070896658037367\n",
      "16 Train Loss 0.27825 Test MSE 36.34019329759813 Test RE 0.3072954989420432\n",
      "17 Train Loss 0.22423689 Test MSE 27.788648364338787 Test RE 0.2687177126941697\n",
      "18 Train Loss 0.15871611 Test MSE 18.964002617799064 Test RE 0.22198702237832396\n",
      "19 Train Loss 0.14468196 Test MSE 15.12076137730856 Test RE 0.19822088573861074\n",
      "20 Train Loss 0.07265612 Test MSE 1.1055797664598501 Test RE 0.0535991155667649\n",
      "21 Train Loss 0.026238319 Test MSE 0.0630551838869804 Test RE 0.012800383484794058\n",
      "22 Train Loss 0.009134119 Test MSE 0.0007990772912593833 Test RE 0.001440976761049174\n",
      "23 Train Loss 0.0079427995 Test MSE 0.02119360703648092 Test RE 0.007421044251912093\n",
      "24 Train Loss 0.0029985353 Test MSE 0.07550932593942865 Test RE 0.014007572508909905\n",
      "25 Train Loss 0.0015789996 Test MSE 0.008716912677062167 Test RE 0.004759309304386762\n",
      "26 Train Loss 0.0015742262 Test MSE 0.00711578950040787 Test RE 0.0043000561703058346\n",
      "27 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "28 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "29 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "30 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "31 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "32 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "33 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "34 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "35 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "36 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "37 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "38 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "39 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "40 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "41 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "42 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "43 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "44 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "45 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "46 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "48 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "49 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "50 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "51 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "52 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "53 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "54 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "55 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "56 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "57 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "58 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "59 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "60 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "61 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "62 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "63 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "64 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "65 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "66 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "67 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "68 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "69 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "70 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "71 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "72 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "73 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "74 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "75 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "76 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "77 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "78 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "79 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "80 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "81 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "82 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "83 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "84 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "85 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "86 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "87 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "88 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "89 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "90 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "91 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "92 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "93 Train Loss 0.0015699578 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "94 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "95 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "96 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "97 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "98 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "99 Train Loss 0.0015699579 Test MSE 0.0063499640134850035 Test RE 0.0040620775893249585\n",
      "Training time: 25.50\n",
      "Training time: 25.50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 3.0475125 Test MSE 380.8134173206661 Test RE 0.9947608925617888\n",
      "1 Train Loss 2.4199665 Test MSE 382.8319811214206 Test RE 0.9973938544642903\n",
      "2 Train Loss 2.3659117 Test MSE 380.30896713874034 Test RE 0.9941018117860189\n",
      "3 Train Loss 2.2809284 Test MSE 364.2837100870689 Test RE 0.9729319335993561\n",
      "4 Train Loss 2.2088916 Test MSE 350.58828612845787 Test RE 0.9544678035423372\n",
      "5 Train Loss 2.1178353 Test MSE 334.1922282977176 Test RE 0.9318816405389733\n",
      "6 Train Loss 2.0144606 Test MSE 312.73941408821605 Test RE 0.9014754242659128\n",
      "7 Train Loss 1.7794523 Test MSE 276.65193821796345 Test RE 0.8478703360866555\n",
      "8 Train Loss 1.5924621 Test MSE 244.32510987010772 Test RE 0.7967950618905637\n",
      "9 Train Loss 1.3823018 Test MSE 181.8290360376981 Test RE 0.6873757407326901\n",
      "10 Train Loss 1.1519313 Test MSE 162.25281319656165 Test RE 0.649319880829825\n",
      "11 Train Loss 1.0257062 Test MSE 158.9208611962152 Test RE 0.6426182238672732\n",
      "12 Train Loss 0.8769032 Test MSE 126.87185930113304 Test RE 0.5741762635148554\n",
      "13 Train Loss 0.8048613 Test MSE 109.28439646659523 Test RE 0.5328950199005522\n",
      "14 Train Loss 0.72353375 Test MSE 85.44089311245493 Test RE 0.471189356964159\n",
      "15 Train Loss 0.4167749 Test MSE 62.10618973822173 Test RE 0.40172607854796566\n",
      "16 Train Loss 0.29946464 Test MSE 38.93305565037199 Test RE 0.3180693547136805\n",
      "17 Train Loss 0.13057816 Test MSE 13.879503465356056 Test RE 0.18991074932303614\n",
      "18 Train Loss 0.060477044 Test MSE 5.278129571369873 Test RE 0.11711232587097327\n",
      "19 Train Loss 0.047212303 Test MSE 3.0204236727421376 Test RE 0.08859240983239697\n",
      "20 Train Loss 0.018319704 Test MSE 0.2730896386858134 Test RE 0.026638832920972886\n",
      "21 Train Loss 0.012101966 Test MSE 2.4361106232888632e-05 Test RE 0.00025160025987191044\n",
      "22 Train Loss 0.011853992 Test MSE 0.022382931338931676 Test RE 0.007626426055480236\n",
      "23 Train Loss 0.010528184 Test MSE 0.0026482392614459813 Test RE 0.0026232591265206357\n",
      "24 Train Loss 0.010508769 Test MSE 0.003772020008893198 Test RE 0.0031307585581857983\n",
      "25 Train Loss 0.009212925 Test MSE 0.00042495126722661244 Test RE 0.0010508292352988515\n",
      "26 Train Loss 0.008131507 Test MSE 0.0028363329982573253 Test RE 0.002714820946285009\n",
      "27 Train Loss 0.007555769 Test MSE 0.0008846933329155907 Test RE 0.0015162086142916237\n",
      "28 Train Loss 0.006644602 Test MSE 0.00019705948699822823 Test RE 0.0007155850462920227\n",
      "29 Train Loss 0.006021177 Test MSE 0.0012198782474713797 Test RE 0.0017804132845446123\n",
      "30 Train Loss 0.005707121 Test MSE 0.0013554736126849742 Test RE 0.0018767573106398794\n",
      "31 Train Loss 0.005697248 Test MSE 0.0010921665123875151 Test RE 0.0016846396210158726\n",
      "32 Train Loss 0.0053406763 Test MSE 0.020844382230400648 Test RE 0.007359648906278164\n",
      "33 Train Loss 0.0036588633 Test MSE 0.0008753762439697049 Test RE 0.001508203557278214\n",
      "34 Train Loss 0.002526127 Test MSE 0.0012169482270284295 Test RE 0.0017782738154788096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.0017716304 Test MSE 0.0005393034830142924 Test RE 0.0011838023427092254\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    max_reps = 10\n",
    "    max_iter = 100\n",
    "    label = \"1D_SODE_Stan_tune\"+str(tune_reps)\n",
    "\n",
    "    N_f = 1000\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "    beta_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "    for reps in range(max_reps):\n",
    "\n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss =[]\n",
    "        beta_val = []\n",
    "\n",
    "        'Generate Training data'\n",
    "        torch.manual_seed(reps*36)\n",
    "         #Total number of collocation points \n",
    "\n",
    "\n",
    "        layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "        PINN = Sequentialmodel(layers)\n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                  max_iter = 10, \n",
    "                                  max_eval = 15, \n",
    "                                  tolerance_grad = 1e-5, \n",
    "                                  tolerance_change = 1e-5, \n",
    "                                  history_size = 100, \n",
    "                                  line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "        train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        beta_full.append(beta_val)    \n",
    "\n",
    "        print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"beta\": beta_full, \"label\": label}\n",
    "    savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
