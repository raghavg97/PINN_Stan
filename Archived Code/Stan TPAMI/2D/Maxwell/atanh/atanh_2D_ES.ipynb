{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "label = \"ES_atanh\"\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = 1000*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = 1000*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = 1000*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)   \n",
    "        \n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = (xy - lbxy)/(ubxy - lbxy)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "     \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "     \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_atanh\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 250210.73 Test MSE 75326.19274752481 Test RE 0.480185509699624\n",
      "1 Train Loss 249999.9 Test MSE 75080.89192752894 Test RE 0.47940300664482344\n",
      "2 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "3 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "4 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "5 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "6 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "7 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "8 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "9 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "10 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "11 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "12 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "13 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "14 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "15 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "16 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "17 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "18 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "19 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "20 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "21 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "22 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "23 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "24 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "25 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "26 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "27 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "28 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "29 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "30 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "31 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "32 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "33 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "34 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "35 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "36 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "37 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "38 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "39 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "40 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "41 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "42 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "43 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "44 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "45 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "46 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "47 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "48 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "49 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "50 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "51 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "52 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "53 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "54 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "55 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "56 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "57 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "58 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "59 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "60 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "61 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "62 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "63 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "64 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "65 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "66 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "67 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "68 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "69 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "70 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "71 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "72 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "73 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "74 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "75 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "76 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "77 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "78 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "79 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "80 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "81 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "82 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "83 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "84 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "85 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "86 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "87 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "88 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "89 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "90 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "91 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "92 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "93 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "94 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "95 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "96 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "98 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "99 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "100 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "101 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "102 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "103 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "104 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "105 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "106 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "107 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "108 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "109 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "110 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "111 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "112 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "113 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "114 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "115 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "116 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "117 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "118 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "119 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "120 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "121 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "122 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "123 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "124 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "125 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "126 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "127 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "128 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "129 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "130 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "131 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "132 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "133 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "134 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "135 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "136 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "137 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "138 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "139 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "140 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "141 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "142 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "143 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "144 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "145 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "146 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "147 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "148 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "149 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "150 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "151 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "152 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "153 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "154 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "155 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "156 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "157 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "158 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "159 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "160 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "161 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "162 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "163 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "164 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "165 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "166 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "167 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "168 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "169 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "170 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "171 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "172 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "173 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "174 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "175 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "176 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "177 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "178 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "179 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "180 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "181 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "182 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "183 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "184 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "185 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "186 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "187 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "188 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "189 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "190 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "191 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "192 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "193 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "194 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "195 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "196 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "197 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "198 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "199 Train Loss 249999.86 Test MSE 75080.83482581443 Test RE 0.4794028243431876\n",
      "Training time: 82.78\n",
      "Training time: 82.78\n",
      "ES_atanh\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 250006.81 Test MSE 75093.67583589551 Test RE 0.4794438185151526\n",
      "1 Train Loss 250000.06 Test MSE 75081.66317682955 Test RE 0.4794054689110178\n",
      "2 Train Loss 249999.9 Test MSE 75081.02359651825 Test RE 0.47940342700798144\n",
      "3 Train Loss 249999.9 Test MSE 75080.95152059062 Test RE 0.4794031969002036\n",
      "4 Train Loss 249999.9 Test MSE 75080.87547857949 Test RE 0.4794029541302884\n",
      "5 Train Loss 249999.86 Test MSE 75080.77156503631 Test RE 0.4794026223781845\n",
      "6 Train Loss 249999.86 Test MSE 75080.72797833559 Test RE 0.47940248322416923\n",
      "7 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "8 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "9 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "10 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "11 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "12 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "13 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "14 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "15 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "16 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "17 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "18 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "19 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "20 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "21 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "22 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "23 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "24 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "25 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "26 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "27 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "28 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "29 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "30 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "31 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "32 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "33 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "34 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "35 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "36 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "37 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "38 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "39 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "40 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "41 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "42 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "43 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "44 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "45 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "46 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "47 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "48 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "49 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "50 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "51 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "52 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "53 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "54 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "55 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "56 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "57 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "58 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "59 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "60 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "61 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "62 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "63 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "64 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "65 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "66 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "67 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "68 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "69 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "70 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "71 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "72 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "73 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "74 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "75 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "76 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "77 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "78 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "79 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "80 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "81 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "82 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "83 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "84 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "85 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "86 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "87 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "88 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "89 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "90 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "91 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "92 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "93 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "94 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "95 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "96 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "97 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "98 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "99 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "100 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "101 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "102 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "103 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "105 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "106 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "107 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "108 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "109 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "110 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "111 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "112 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "113 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "114 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "115 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "116 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "117 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "118 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "119 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "120 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "121 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "122 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "123 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "124 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "125 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "126 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "127 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "128 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "129 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "130 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "131 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "132 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "133 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "134 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "135 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "136 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "137 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "138 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "139 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "140 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "141 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "142 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "143 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "144 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "145 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "146 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "147 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "148 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "149 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "150 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "151 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "152 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "153 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "154 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "155 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "156 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "157 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "158 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "159 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "160 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "161 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "162 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "163 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "164 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "165 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "166 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "167 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "168 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "169 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "170 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "171 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "172 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "173 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "174 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "175 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "176 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "177 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "178 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "179 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "180 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "181 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "182 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "183 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "184 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "185 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "186 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "187 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "188 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "189 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "190 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "191 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "192 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "193 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "194 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "195 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "196 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "197 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "198 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "199 Train Loss 249999.83 Test MSE 75080.68913567287 Test RE 0.47940235921583935\n",
      "Training time: 81.93\n",
      "Training time: 81.93\n",
      "ES_atanh\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 251984.34 Test MSE 77172.01952966109 Test RE 0.48603324309716783\n",
      "1 Train Loss 249999.9 Test MSE 75081.04582001522 Test RE 0.4794034979581317\n",
      "2 Train Loss 249999.89 Test MSE 75080.8777020218 Test RE 0.4794029612287991\n",
      "3 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "4 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "5 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "6 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "7 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "8 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "9 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "10 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "11 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "12 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "13 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "14 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "15 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "16 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "17 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "18 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "19 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "20 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "21 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "22 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "23 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "24 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "25 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "26 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "27 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "28 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "29 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "30 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "31 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "32 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "33 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "34 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "35 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "36 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "37 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "38 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "39 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "40 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "41 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "42 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "43 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "44 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "45 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "46 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "47 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "48 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "49 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "50 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "51 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "52 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "53 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "54 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "55 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "56 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "57 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "58 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "59 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "60 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "61 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "62 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "63 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "64 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "65 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "66 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "67 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "68 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "69 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "70 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "71 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "72 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "73 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "74 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "75 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "76 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "77 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "78 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "79 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "80 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "81 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "82 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "83 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "84 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "85 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "86 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "87 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "88 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "89 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "90 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "91 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "92 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "93 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "94 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "95 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "96 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "97 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "98 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "99 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "100 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "101 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "102 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "103 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "104 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "105 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "106 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "108 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "109 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "110 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "111 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "112 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "113 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "114 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "115 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "116 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "117 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "118 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "119 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "120 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "121 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "122 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "123 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "124 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "125 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "126 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "127 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "128 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "129 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "130 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "131 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "132 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "133 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "134 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "135 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "136 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "137 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "138 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "139 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "140 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "141 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "142 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "143 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "144 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "145 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "146 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "147 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "148 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "149 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "150 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "151 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "152 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "153 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "154 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "155 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "156 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "157 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "158 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "159 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "160 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "161 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "162 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "163 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "164 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "165 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "166 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "167 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "168 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "169 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "170 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "171 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "172 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "173 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "174 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "175 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "176 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "177 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "178 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "179 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "180 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "181 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "182 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "183 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "184 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "185 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "186 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "187 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "188 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "189 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "190 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "191 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "192 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "193 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "194 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "195 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "196 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "197 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "198 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "199 Train Loss 249999.86 Test MSE 75080.82004890683 Test RE 0.479402777166757\n",
      "Training time: 94.62\n",
      "Training time: 94.62\n",
      "ES_atanh\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 250038.12 Test MSE 75133.55177733279 Test RE 0.4795710977837678\n",
      "1 Train Loss 249999.97 Test MSE 75081.29862168238 Test RE 0.4794043050453278\n",
      "2 Train Loss 249999.9 Test MSE 75081.10206866034 Test RE 0.47940367753602575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "4 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "5 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "6 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "7 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "8 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "9 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "10 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "11 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "12 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "13 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "14 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "15 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "16 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "17 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "18 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "19 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "20 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "21 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "22 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "23 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "24 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "25 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "26 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "27 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "28 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "29 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "30 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "31 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "32 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "33 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "34 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "35 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "36 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "37 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "38 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "39 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "40 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "41 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "42 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "43 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "44 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "45 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "46 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "47 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "48 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "49 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "50 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "51 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "52 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "53 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "54 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "55 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "56 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "57 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "58 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "59 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "60 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "61 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "62 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "63 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "64 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "65 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "66 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "67 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "68 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "69 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "70 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "71 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "72 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "73 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "74 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "75 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "76 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "77 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "78 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "79 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "80 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "81 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "82 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "83 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "84 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "85 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "86 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "87 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "88 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "89 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "90 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "91 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "92 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "93 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "94 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "95 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "96 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "97 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "98 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "99 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "100 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "101 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "102 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "103 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "104 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "105 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "106 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "108 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "109 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "110 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "111 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "112 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "113 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "114 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "115 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "116 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "117 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "118 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "119 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "120 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "121 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "122 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "123 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "124 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "125 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "126 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "127 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "128 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "129 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "130 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "131 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "132 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "133 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "134 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "135 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "136 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "137 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "138 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "139 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "140 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "141 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "142 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "143 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "144 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "145 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "146 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "147 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "148 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "149 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "150 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "151 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "152 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "153 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "154 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "155 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "156 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "157 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "158 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "159 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "160 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "161 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "162 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "163 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "164 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "165 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "166 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "167 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "168 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "169 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "170 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "171 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "172 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "173 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "174 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "175 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "176 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "177 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "178 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "179 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "180 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "181 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "182 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "183 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "184 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "185 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "186 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "187 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "188 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "189 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "190 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "191 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "192 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "193 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "194 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "195 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "196 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "197 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "198 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "199 Train Loss 249999.89 Test MSE 75081.02031733042 Test RE 0.47940341653893204\n",
      "Training time: 78.35\n",
      "Training time: 78.35\n",
      "ES_atanh\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 254417.5 Test MSE 79657.95666963012 Test RE 0.4937994738419553\n",
      "1 Train Loss 249999.86 Test MSE 75080.001109678 Test RE 0.47940016263210655\n",
      "2 Train Loss 249999.86 Test MSE 75080.0347843476 Test RE 0.47940027014169656\n",
      "3 Train Loss 249999.86 Test MSE 75080.06562876904 Test RE 0.4794003686154287\n",
      "4 Train Loss 249999.86 Test MSE 75080.09377308232 Test RE 0.4794004584687923\n",
      "5 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "6 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "7 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "8 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "9 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "10 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "11 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "12 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "13 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "14 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "15 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "16 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "17 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "18 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "19 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "20 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "21 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "22 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "23 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "24 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "25 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "26 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "27 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "28 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "29 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "30 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "31 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "32 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "33 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "34 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "35 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "36 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "37 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "38 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "39 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "40 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "41 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "42 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "43 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "44 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "45 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "46 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "47 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "48 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "49 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "50 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "51 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "52 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "53 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "54 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "55 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "56 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "57 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "58 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "59 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "60 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "61 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "62 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "63 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "64 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "65 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "66 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "67 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "68 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "69 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "70 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "71 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "72 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "73 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "74 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "75 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "76 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "77 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "78 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "79 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "80 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "81 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "82 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "83 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "84 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "85 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "86 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "87 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "88 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "89 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "90 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "91 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "92 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "93 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "94 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "95 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "96 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "97 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "98 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "99 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "100 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "101 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "102 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "103 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "105 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "106 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "107 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "108 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "109 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "110 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "111 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "112 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "113 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "114 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "115 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "116 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "117 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "118 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "119 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "120 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "121 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "122 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "123 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "124 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "125 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "126 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "127 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "128 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "129 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "130 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "131 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "132 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "133 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "134 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "135 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "136 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "137 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "138 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "139 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "140 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "141 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "142 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "143 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "144 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "145 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "146 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "147 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "148 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "149 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "150 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "151 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "152 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "153 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "154 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "155 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "156 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "157 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "158 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "159 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "160 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "161 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "162 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "163 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "164 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "165 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "166 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "167 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "168 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "169 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "170 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "171 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "172 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "173 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "174 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "175 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "176 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "177 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "178 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "179 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "180 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "181 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "182 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "183 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "184 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "185 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "186 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "187 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "188 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "189 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "190 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "191 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "192 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "193 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "194 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "195 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "196 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "197 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "198 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "199 Train Loss 249999.83 Test MSE 75080.11923918132 Test RE 0.47940053977169095\n",
      "Training time: 82.06\n",
      "Training time: 82.06\n",
      "ES_atanh\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "1 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "2 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "3 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "4 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "5 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "6 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "7 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "8 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "9 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "10 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "11 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "12 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "13 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "14 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "15 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "16 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "17 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "18 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "19 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "20 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "21 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "22 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "23 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "24 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "25 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "26 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "27 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "28 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "29 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "30 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "31 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "32 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "33 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "34 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "35 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "36 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "37 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "38 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "39 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "40 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "41 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "42 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "43 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "44 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "45 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "46 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "47 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "48 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "49 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "50 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "51 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "52 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "53 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "54 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "55 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "56 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "57 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "58 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "59 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "60 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "61 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "62 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "63 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "64 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "65 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "66 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "67 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "68 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "69 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "70 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "71 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "72 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "73 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "74 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "75 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "76 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "77 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "78 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "79 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "80 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "81 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "82 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "83 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "84 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "85 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "86 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "87 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "88 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "89 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "90 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "91 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "92 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "93 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "94 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "95 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "96 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "97 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "98 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "99 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "100 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "101 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "102 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "103 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "104 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "105 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "107 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "108 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "109 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "110 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "111 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "112 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "113 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "114 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "115 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "116 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "117 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "118 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "119 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "120 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "121 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "122 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "123 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "124 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "125 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "126 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "127 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "128 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "129 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "130 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "131 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "132 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "133 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "134 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "135 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "136 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "137 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "138 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "139 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "140 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "141 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "142 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "143 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "144 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "145 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "146 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "147 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "148 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "149 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "150 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "151 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "152 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "153 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "154 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "155 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "156 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "157 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "158 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "159 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "160 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "161 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "162 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "163 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "164 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "165 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "166 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "167 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "168 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "169 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "170 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "171 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "172 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "173 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "174 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "175 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "176 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "177 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "178 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "179 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "180 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "181 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "182 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "183 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "184 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "185 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "186 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "187 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "188 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "189 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "190 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "191 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "192 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "193 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "194 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "195 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "196 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "197 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "198 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "199 Train Loss 249999.9 Test MSE 75081.19615245254 Test RE 0.47940397790523065\n",
      "Training time: 77.48\n",
      "Training time: 77.48\n",
      "ES_atanh\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 250000.11 Test MSE 75081.90869770758 Test RE 0.47940625275057636\n",
      "1 Train Loss 249999.89 Test MSE 75080.91914926161 Test RE 0.47940309355228394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 249999.89 Test MSE 75080.85909829456 Test RE 0.47940290183496437\n",
      "3 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "4 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "5 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "6 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "7 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "8 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "9 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "10 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "11 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "12 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "13 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "14 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "15 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "16 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "17 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "18 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "19 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "20 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "21 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "22 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "23 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "24 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "25 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "26 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "27 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "28 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "29 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "30 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "31 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "32 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "33 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "34 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "35 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "36 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "37 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "38 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "39 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "40 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "41 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "42 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "43 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "44 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "45 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "46 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "47 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "48 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "49 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "50 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "51 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "52 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "53 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "54 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "55 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "56 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "57 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "58 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "59 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "60 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "61 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "62 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "63 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "64 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "65 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "66 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "67 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "68 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "69 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "70 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "71 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "72 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "73 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "74 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "75 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "76 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "77 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "78 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "79 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "80 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "81 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "82 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "83 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "84 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "85 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "86 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "87 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "88 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "89 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "90 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "91 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "92 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "93 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "94 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "95 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "96 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "97 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "98 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "99 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "100 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "101 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "102 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "103 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "104 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "105 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "106 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "107 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "108 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "110 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "111 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "112 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "113 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "114 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "115 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "116 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "117 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "118 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "119 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "120 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "121 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "122 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "123 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "124 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "125 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "126 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "127 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "128 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "129 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "130 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "131 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "132 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "133 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "134 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "135 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "136 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "137 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "138 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "139 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "140 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "141 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "142 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "143 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "144 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "145 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "146 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "147 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "148 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "149 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "150 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "151 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "152 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "153 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "154 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "155 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "156 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "157 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "158 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "159 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "160 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "161 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "162 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "163 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "164 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "165 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "166 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "167 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "168 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "169 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "170 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "171 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "172 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "173 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "174 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "175 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "176 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "177 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "178 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "179 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "180 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "181 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "182 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "183 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "184 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "185 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "186 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "187 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "188 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "189 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "190 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "191 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "192 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "193 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "194 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "195 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "196 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "197 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "198 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "199 Train Loss 249999.86 Test MSE 75080.8036504047 Test RE 0.4794027248132539\n",
      "Training time: 84.11\n",
      "Training time: 84.11\n",
      "ES_atanh\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 250064.25 Test MSE 75164.07086664192 Test RE 0.4796684882759879\n",
      "1 Train Loss 250000.7 Test MSE 75083.49517892621 Test RE 0.47941131765243883\n",
      "2 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "3 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "4 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "6 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "7 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "8 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "9 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "10 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "11 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "12 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "13 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "14 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "15 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "16 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "17 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "18 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "19 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "20 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "21 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "22 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "23 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "24 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "25 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "26 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "27 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "28 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "29 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "30 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "31 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "32 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "33 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "34 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "35 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "36 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "37 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "38 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "39 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "40 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "41 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "42 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "43 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "44 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "45 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "46 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "47 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "48 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "49 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "50 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "51 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "52 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "53 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "54 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "55 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "56 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "57 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "58 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "59 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "60 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "61 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "62 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "63 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "64 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "65 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "66 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "67 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "68 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "69 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "70 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "71 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "72 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "73 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "74 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "75 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "76 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "77 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "78 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "79 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "80 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "81 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "82 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "83 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "84 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "85 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "86 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "87 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "88 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "89 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "90 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "91 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "92 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "93 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "94 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "95 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "96 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "97 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "98 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "99 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "100 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "101 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "102 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "103 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "104 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "105 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "106 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "107 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "108 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "110 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "111 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "112 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "113 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "114 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "115 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "116 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "117 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "118 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "119 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "120 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "121 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "122 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "123 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "124 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "125 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "126 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "127 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "128 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "129 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "130 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "131 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "132 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "133 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "134 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "135 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "136 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "137 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "138 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "139 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "140 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "141 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "142 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "143 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "144 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "145 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "146 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "147 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "148 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "149 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "150 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "151 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "152 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "153 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "154 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "155 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "156 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "157 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "158 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "159 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "160 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "161 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "162 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "163 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "164 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "165 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "166 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "167 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "168 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "169 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "170 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "171 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "172 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "173 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "174 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "175 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "176 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "177 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "178 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "179 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "180 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "181 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "182 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "183 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "184 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "185 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "186 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "187 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "188 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "189 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "190 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "191 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "192 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "193 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "194 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "195 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "196 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "197 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "198 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "199 Train Loss 249999.86 Test MSE 75080.88300915784 Test RE 0.47940297817223904\n",
      "Training time: 46.93\n",
      "Training time: 46.93\n",
      "ES_atanh\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 249999.89 Test MSE 75080.89536303609 Test RE 0.4794030176129432\n",
      "1 Train Loss 249999.86 Test MSE 75080.78654670568 Test RE 0.47940267020834837\n",
      "2 Train Loss 249999.86 Test MSE 75080.74123931762 Test RE 0.4794025255609152\n",
      "3 Train Loss 249999.86 Test MSE 75080.70094834296 Test RE 0.4794023969287437\n",
      "4 Train Loss 249999.86 Test MSE 75080.66506232426 Test RE 0.4794022823597185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 249999.86 Test MSE 75080.63314006725 Test RE 0.4794021804453008\n",
      "6 Train Loss 249999.86 Test MSE 75080.60665991357 Test RE 0.47940209590522703\n",
      "7 Train Loss 249999.86 Test MSE 75080.57914420927 Test RE 0.4794020080590568\n",
      "8 Train Loss 249999.86 Test MSE 75080.55669148873 Test RE 0.4794019363768707\n",
      "9 Train Loss 249999.86 Test MSE 75080.53648989147 Test RE 0.47940187188157424\n",
      "10 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "11 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "12 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "13 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "14 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "15 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "16 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "17 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "18 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "19 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "20 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "21 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "22 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "23 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "24 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "25 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "26 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "27 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "28 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "29 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "30 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "31 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "32 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "33 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "34 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "35 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "36 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "37 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "38 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "39 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "40 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "41 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "42 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "43 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "44 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "45 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "46 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "47 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "48 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "49 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "50 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "51 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "52 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "53 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "54 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "55 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "56 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "57 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "58 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "59 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "60 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "61 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "62 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "63 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "64 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "65 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "66 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "67 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "68 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "69 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "70 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "71 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "72 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "73 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "74 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "75 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "76 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "77 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "78 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "79 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "80 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "81 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "82 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "83 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "84 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "85 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "86 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "87 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "88 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "89 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "90 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "91 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "92 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "93 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "94 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "95 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "96 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "97 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "98 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "99 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "100 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "101 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "102 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "103 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "104 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "105 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "106 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "107 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "108 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "110 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "111 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "112 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "113 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "114 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "115 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "116 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "117 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "118 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "119 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "120 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "121 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "122 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "123 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "124 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "125 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "126 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "127 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "128 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "129 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "130 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "131 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "132 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "133 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "134 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "135 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "136 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "137 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "138 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "139 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "140 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "141 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "142 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "143 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "144 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "145 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "146 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "147 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "148 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "149 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "150 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "151 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "152 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "153 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "154 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "155 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "156 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "157 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "158 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "159 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "160 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "161 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "162 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "163 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "164 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "165 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "166 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "167 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "168 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "169 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "170 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "171 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "172 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "173 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "174 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "175 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "176 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "177 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "178 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "179 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "180 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "181 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "182 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "183 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "184 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "185 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "186 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "187 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "188 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "189 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "190 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "191 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "192 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "193 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "194 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "195 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "196 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "197 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "198 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "199 Train Loss 249999.81 Test MSE 75080.50199542074 Test RE 0.47940176175505866\n",
      "Training time: 67.27\n",
      "Training time: 67.27\n",
      "ES_atanh\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 250000.17 Test MSE 75082.04392014437 Test RE 0.4794066844554547\n",
      "1 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "2 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "4 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "5 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "6 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "7 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "8 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "9 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "10 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "11 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "12 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "13 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "14 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "15 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "16 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "17 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "18 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "19 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "20 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "21 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "22 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "23 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "24 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "25 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "26 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "27 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "28 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "29 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "30 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "31 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "32 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "33 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "34 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "35 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "36 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "37 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "38 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "39 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "40 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "41 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "42 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "43 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "44 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "45 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "46 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "47 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "48 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "49 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "50 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "51 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "52 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "53 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "54 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "55 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "56 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "57 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "58 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "59 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "60 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "61 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "62 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "63 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "64 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "65 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "66 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "67 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "68 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "69 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "70 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "71 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "72 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "73 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "74 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "75 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "76 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "77 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "78 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "79 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "80 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "81 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "82 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "83 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "84 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "85 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "86 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "87 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "88 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "89 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "90 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "91 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "92 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "93 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "94 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "95 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "96 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "97 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "98 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "99 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "100 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "101 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "102 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "103 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "104 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "105 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "106 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "107 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "108 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "109 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "111 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "112 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "113 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "114 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "115 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "116 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "117 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "118 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "119 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "120 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "121 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "122 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "123 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "124 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "125 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "126 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "127 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "128 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "129 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "130 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "131 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "132 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "133 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "134 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "135 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "136 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "137 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "138 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "139 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "140 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "141 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "142 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "143 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "144 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "145 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "146 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "147 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "148 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "149 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "150 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "151 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "152 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "153 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "154 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "155 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "156 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "157 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "158 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "159 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "160 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "161 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "162 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "163 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "164 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "165 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "166 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "167 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "168 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "169 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "170 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "171 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "172 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "173 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "174 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "175 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "176 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "177 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "178 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "179 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "180 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "181 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "182 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "183 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "184 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "185 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "186 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "187 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "188 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "189 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "190 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "191 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "192 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "193 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "194 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "195 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "196 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "197 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "198 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "199 Train Loss 249999.83 Test MSE 75080.59098102016 Test RE 0.4794020458490602\n",
      "Training time: 40.24\n",
      "Training time: 40.24\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 1.0\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    alpha_val = []\n",
    "\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers,n_val)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    alpha_full.append(alpha_val)  \n",
    "\n",
    "\n",
    "    if(nan_flag == 1):\n",
    "        nan_tune.append(tune_reps)\n",
    "        break\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30981/1090202970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_tune\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_tune' is not defined"
     ]
    }
   ],
   "source": [
    "lr_tune[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(np.flipud(np.transpose(u_pred.reshape(500,500)))),vmin = 0,vmax = 1000,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "for tune_reps in range(25):\n",
    "    label = \"MW_atanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_tune[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
