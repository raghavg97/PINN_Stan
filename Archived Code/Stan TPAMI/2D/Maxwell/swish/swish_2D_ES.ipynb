{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "label = \"ES_swish\"\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "# xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = 1000*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = 1000*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = 1000*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = (xy - lbxy)/(ubxy - lbxy)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "       \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "     \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    " \n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    " \n",
    "            \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_swish\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 249999.86 Test MSE 75079.56998066008 Test RE 0.47939878620952425\n",
      "1 Train Loss 249999.81 Test MSE 75079.70032997068 Test RE 0.47939920236317424\n",
      "2 Train Loss 249999.75 Test MSE 75079.85961746961 Test RE 0.4793997109044915\n",
      "3 Train Loss 249999.75 Test MSE 75079.90435713038 Test RE 0.4793998537402491\n",
      "4 Train Loss 249999.73 Test MSE 75079.98951120782 Test RE 0.4794001256028802\n",
      "5 Train Loss 249999.7 Test MSE 75080.05978490473 Test RE 0.4794003499583407\n",
      "6 Train Loss 249999.7 Test MSE 75080.09163511592 Test RE 0.4794004516431345\n",
      "7 Train Loss 249999.7 Test MSE 75080.12226048074 Test RE 0.47940054941747057\n",
      "8 Train Loss 249999.7 Test MSE 75080.15141448192 Test RE 0.4794006424943224\n",
      "9 Train Loss 249999.7 Test MSE 75080.17970063235 Test RE 0.47940073280046297\n",
      "10 Train Loss 249999.7 Test MSE 75080.20745829355 Test RE 0.4794008214193364\n",
      "11 Train Loss 249999.7 Test MSE 75080.23576498376 Test RE 0.4794009117910183\n",
      "12 Train Loss 249999.7 Test MSE 75080.26343875272 Test RE 0.4794010001420251\n",
      "13 Train Loss 249999.7 Test MSE 75080.29079513764 Test RE 0.4794010874797387\n",
      "14 Train Loss 249999.69 Test MSE 75080.34722529013 Test RE 0.47940126763801405\n",
      "15 Train Loss 249999.69 Test MSE 75080.37762156868 Test RE 0.4794013646808057\n",
      "16 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "17 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "18 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "19 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "20 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "21 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "22 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "23 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "24 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "25 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "26 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "27 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "28 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "29 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "30 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "31 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "32 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "33 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "34 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "35 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "36 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "37 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "38 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "39 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "40 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "41 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "42 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "43 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "44 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "45 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "46 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "47 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "48 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "49 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "50 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "51 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "52 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "53 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "54 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "55 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "56 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "57 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "58 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "59 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "60 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "61 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "62 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "63 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "64 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "65 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "66 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "67 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "68 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "69 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "70 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "71 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "72 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "73 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "74 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "75 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "76 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "77 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "78 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "79 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "80 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "81 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "82 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "83 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "84 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "85 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "86 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "87 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "88 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "89 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "90 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "91 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "92 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "93 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "94 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "95 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "97 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "98 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "99 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "100 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "101 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "102 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "103 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "104 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "105 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "106 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "107 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "108 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "109 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "110 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "111 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "112 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "113 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "114 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "115 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "116 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "117 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "118 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "119 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "120 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "121 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "122 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "123 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "124 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "125 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "126 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "127 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "128 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "129 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "130 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "131 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "132 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "133 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "134 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "135 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "136 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "137 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "138 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "139 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "140 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "141 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "142 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "143 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "144 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "145 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "146 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "147 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "148 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "149 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "150 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "151 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "152 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "153 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "154 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "155 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "156 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "157 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "158 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "159 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "160 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "161 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "162 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "163 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "164 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "165 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "166 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "167 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "168 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "169 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "170 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "171 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "172 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "173 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "174 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "175 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "176 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "177 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "178 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "179 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "180 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "181 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "182 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "183 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "184 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "185 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "186 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "187 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "188 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "189 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "190 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "191 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "192 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "193 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "194 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "195 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "196 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "197 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "198 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Train Loss 249999.66 Test MSE 75080.44153277494 Test RE 0.47940156872288664\n",
      "Training time: 95.42\n",
      "Training time: 95.42\n",
      "ES_swish\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 250000.11 Test MSE 75079.80702441267 Test RE 0.4793995429959417\n",
      "1 Train Loss 250000.1 Test MSE 75079.88842941263 Test RE 0.479399802889452\n",
      "2 Train Loss 250000.1 Test MSE 75079.92934315634 Test RE 0.4793999335105706\n",
      "3 Train Loss 250000.06 Test MSE 75080.01515062564 Test RE 0.47940020745917217\n",
      "4 Train Loss 250000.06 Test MSE 75080.05972757017 Test RE 0.4794003497752947\n",
      "5 Train Loss 250000.06 Test MSE 75080.10665914668 Test RE 0.47940049960875764\n",
      "6 Train Loss 250000.03 Test MSE 75080.22324799946 Test RE 0.47940087182941005\n",
      "7 Train Loss 250000.02 Test MSE 75080.35541591924 Test RE 0.47940129378731955\n",
      "8 Train Loss 249999.97 Test MSE 75080.48993941065 Test RE 0.4794017232652207\n",
      "9 Train Loss 249999.2 Test MSE 75082.56303477238 Test RE 0.4794083417531222\n",
      "10 Train Loss 249994.77 Test MSE 75078.79639658303 Test RE 0.4793963164549495\n",
      "11 Train Loss 249994.77 Test MSE 75078.74098948904 Test RE 0.47939613956105315\n",
      "12 Train Loss 249994.5 Test MSE 75078.3865308784 Test RE 0.4793950079072195\n",
      "13 Train Loss 248601.27 Test MSE 74625.69719241039 Test RE 0.4779475531999132\n",
      "14 Train Loss 232588.69 Test MSE 66744.34294294416 Test RE 0.452005035328401\n",
      "15 Train Loss 163488.12 Test MSE 43185.727348829016 Test RE 0.3635851702572981\n",
      "16 Train Loss 93235.3 Test MSE 24080.664236842054 Test RE 0.27150027447072067\n",
      "17 Train Loss 69288.97 Test MSE 16011.333686508642 Test RE 0.22138581782666647\n",
      "18 Train Loss 59828.055 Test MSE 11321.450409420424 Test RE 0.18616030256646848\n",
      "19 Train Loss 55148.043 Test MSE 10156.959311087565 Test RE 0.1763266263189072\n",
      "20 Train Loss 53796.2 Test MSE 10439.004663467902 Test RE 0.17875804142810897\n",
      "21 Train Loss 50377.703 Test MSE 9566.56842972356 Test RE 0.1711252647426945\n",
      "22 Train Loss 49402.56 Test MSE 9377.500659533529 Test RE 0.16942581893848155\n",
      "23 Train Loss 48502.402 Test MSE 8779.7350893632 Test RE 0.1639369111266913\n",
      "24 Train Loss 47569.348 Test MSE 8471.29559845791 Test RE 0.16103154509901685\n",
      "25 Train Loss 47285.703 Test MSE 8499.10630333437 Test RE 0.16129565648386401\n",
      "26 Train Loss 46864.637 Test MSE 8111.647896777237 Test RE 0.15757618700614393\n",
      "27 Train Loss 46528.496 Test MSE 8183.791992772708 Test RE 0.15827536839515843\n",
      "28 Train Loss 46296.973 Test MSE 7891.053184885815 Test RE 0.15541879129407515\n",
      "29 Train Loss 45967.39 Test MSE 7514.642738454207 Test RE 0.1516666907589263\n",
      "30 Train Loss 45869.25 Test MSE 7435.305548134467 Test RE 0.15086394218296803\n",
      "31 Train Loss 45624.957 Test MSE 7330.155038185981 Test RE 0.14979338053501767\n",
      "32 Train Loss 45490.22 Test MSE 7362.697125561731 Test RE 0.15012551478498068\n",
      "33 Train Loss 45310.094 Test MSE 7250.376209222222 Test RE 0.14897600120217927\n",
      "34 Train Loss 45136.37 Test MSE 7326.054543141397 Test RE 0.14975147740096323\n",
      "35 Train Loss 44959.785 Test MSE 7248.124791569945 Test RE 0.14895286907556587\n",
      "36 Train Loss 44651.473 Test MSE 7100.083840412752 Test RE 0.1474238607554042\n",
      "37 Train Loss 44553.043 Test MSE 7018.438330968611 Test RE 0.14657377929897564\n",
      "38 Train Loss 44326.832 Test MSE 6995.846537853104 Test RE 0.1463376845016855\n",
      "39 Train Loss 44132.02 Test MSE 6644.791091932091 Test RE 0.14261877690110517\n",
      "40 Train Loss 43950.664 Test MSE 6671.005244863434 Test RE 0.14289982037895574\n",
      "41 Train Loss 43678.88 Test MSE 6527.135517809775 Test RE 0.14135050248539935\n",
      "42 Train Loss 43499.33 Test MSE 6436.155699190104 Test RE 0.14036192401967645\n",
      "43 Train Loss 43098.81 Test MSE 6409.836407588519 Test RE 0.1400746398852341\n",
      "44 Train Loss 42744.895 Test MSE 6209.309055628983 Test RE 0.1378661602490913\n",
      "45 Train Loss 42533.523 Test MSE 6107.456309821538 Test RE 0.1367307595329703\n",
      "46 Train Loss 42375.83 Test MSE 6027.999402595688 Test RE 0.13583842647369254\n",
      "47 Train Loss 42250.44 Test MSE 6020.629273770666 Test RE 0.13575535970181338\n",
      "48 Train Loss 41989.125 Test MSE 5930.890708320666 Test RE 0.13473983227664563\n",
      "49 Train Loss 41834.668 Test MSE 5940.634837489563 Test RE 0.13485047194040586\n",
      "50 Train Loss 41714.86 Test MSE 5922.216517887349 Test RE 0.1346412647363847\n",
      "51 Train Loss 41577.67 Test MSE 5864.311463379248 Test RE 0.13398141373021036\n",
      "52 Train Loss 41513.566 Test MSE 5895.145098099918 Test RE 0.13433317863990876\n",
      "53 Train Loss 41444.652 Test MSE 5905.7156392558945 Test RE 0.13445356061553895\n",
      "54 Train Loss 41410.973 Test MSE 5919.141683881213 Test RE 0.13460630710779917\n",
      "55 Train Loss 41396.055 Test MSE 5900.746641667136 Test RE 0.13439698491403562\n",
      "56 Train Loss 41373.95 Test MSE 5910.906697056618 Test RE 0.13451263922182002\n",
      "57 Train Loss 41342.71 Test MSE 5927.37566373914 Test RE 0.13469989841715424\n",
      "58 Train Loss 41322.562 Test MSE 5910.575594726756 Test RE 0.13450887177342005\n",
      "59 Train Loss 41309.746 Test MSE 5921.263481328717 Test RE 0.1346304306837932\n",
      "60 Train Loss 41292.14 Test MSE 5938.369439860567 Test RE 0.13482475759529408\n",
      "61 Train Loss 41275.96 Test MSE 5934.114537723319 Test RE 0.1347764472845854\n",
      "62 Train Loss 41247.016 Test MSE 5931.273975867222 Test RE 0.1347441858023815\n",
      "63 Train Loss 41242.727 Test MSE 5944.448233646799 Test RE 0.1348937464209481\n",
      "64 Train Loss 41235.266 Test MSE 5941.962293458496 Test RE 0.13486553750746288\n",
      "65 Train Loss 41217.402 Test MSE 5948.758373414062 Test RE 0.134942641248969\n",
      "66 Train Loss 41185.746 Test MSE 5946.1033492522565 Test RE 0.1349125243795778\n",
      "67 Train Loss 41167.305 Test MSE 5964.48057771048 Test RE 0.13512084615143588\n",
      "68 Train Loss 41147.816 Test MSE 5933.441365624203 Test RE 0.1347688024778867\n",
      "69 Train Loss 41087.008 Test MSE 5962.038276629556 Test RE 0.13509317906681334\n",
      "70 Train Loss 40990.57 Test MSE 5924.59954761034 Test RE 0.13466835103628239\n",
      "71 Train Loss 40921.105 Test MSE 5941.963913291149 Test RE 0.13486555589024413\n",
      "72 Train Loss 40867.33 Test MSE 5905.269079018453 Test RE 0.13444847717157768\n",
      "73 Train Loss 40831.164 Test MSE 5921.13548170237 Test RE 0.13462897552662895\n",
      "74 Train Loss 40779.97 Test MSE 5926.985851099027 Test RE 0.1346954690887868\n",
      "75 Train Loss 40722.215 Test MSE 5932.528318831807 Test RE 0.1347584328669487\n",
      "76 Train Loss 40638.64 Test MSE 5891.613982638193 Test RE 0.1342929406975617\n",
      "77 Train Loss 40598.96 Test MSE 5881.37664206666 Test RE 0.1341762154409341\n",
      "78 Train Loss 40558.54 Test MSE 5858.976497263063 Test RE 0.13392045610992268\n",
      "79 Train Loss 40465.117 Test MSE 5834.366990143698 Test RE 0.13363890655403587\n",
      "80 Train Loss 40401.406 Test MSE 5792.641417498811 Test RE 0.13316017720238113\n",
      "81 Train Loss 40305.793 Test MSE 5740.352999745961 Test RE 0.1325578165162802\n",
      "82 Train Loss 40238.312 Test MSE 5745.6017413615555 Test RE 0.13261840536480382\n",
      "83 Train Loss 40172.61 Test MSE 5722.907735749168 Test RE 0.13235623782079134\n",
      "84 Train Loss 40115.805 Test MSE 5671.894892533382 Test RE 0.13176501898998358\n",
      "85 Train Loss 40017.97 Test MSE 5605.30592263961 Test RE 0.13098926400266064\n",
      "86 Train Loss 39948.4 Test MSE 5576.690488063787 Test RE 0.13065448202458316\n",
      "87 Train Loss 39898.973 Test MSE 5551.604439846465 Test RE 0.13036028433413563\n",
      "88 Train Loss 39882.844 Test MSE 5543.285145028596 Test RE 0.13026257274032227\n",
      "89 Train Loss 39862.117 Test MSE 5535.4510868461575 Test RE 0.1301704932826929\n",
      "90 Train Loss 39842.777 Test MSE 5524.930166374129 Test RE 0.13004673058074184\n",
      "91 Train Loss 39825.31 Test MSE 5519.524492044107 Test RE 0.12998309517809858\n",
      "92 Train Loss 39794.72 Test MSE 5503.020810242208 Test RE 0.12978862139565286\n",
      "93 Train Loss 39704.06 Test MSE 5488.52016094114 Test RE 0.12961750985713463\n",
      "94 Train Loss 39549.957 Test MSE 5485.500317938715 Test RE 0.12958184647474996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 39470.1 Test MSE 5502.796406045326 Test RE 0.1297859750847195\n",
      "96 Train Loss 39395.242 Test MSE 5535.214929942795 Test RE 0.13016771654526021\n",
      "97 Train Loss 39338.52 Test MSE 5527.153319643369 Test RE 0.13007289242601125\n",
      "98 Train Loss 39179.15 Test MSE 5471.318434719842 Test RE 0.12941423150578082\n",
      "99 Train Loss 39024.855 Test MSE 5421.221641700844 Test RE 0.12882039412205876\n",
      "100 Train Loss 38797.656 Test MSE 5375.125695439045 Test RE 0.12827155337827081\n",
      "101 Train Loss 38691.043 Test MSE 5368.001046765268 Test RE 0.12818651417713153\n",
      "102 Train Loss 38549.605 Test MSE 5338.549250603914 Test RE 0.12783437977171644\n",
      "103 Train Loss 38370.414 Test MSE 5308.834933533591 Test RE 0.12747812084296922\n",
      "104 Train Loss 38218.656 Test MSE 5204.684888751172 Test RE 0.12622147828472272\n",
      "105 Train Loss 37703.96 Test MSE 5094.642091570614 Test RE 0.12487999755135128\n",
      "106 Train Loss 37166.16 Test MSE 5243.052109760355 Test RE 0.12668585560826398\n",
      "107 Train Loss 36599.293 Test MSE 5123.268044419357 Test RE 0.12523034614802636\n",
      "108 Train Loss 36086.08 Test MSE 4940.894301505353 Test RE 0.12298122749669792\n",
      "109 Train Loss 35420.832 Test MSE 4819.75493097119 Test RE 0.12146426317617362\n",
      "110 Train Loss 35021.85 Test MSE 4656.5820562442 Test RE 0.11939047278325916\n",
      "111 Train Loss 34391.96 Test MSE 4424.672270007368 Test RE 0.11637952924204459\n",
      "112 Train Loss 33912.62 Test MSE 4379.436384106241 Test RE 0.11578309457232006\n",
      "113 Train Loss 33247.05 Test MSE 4298.002475075498 Test RE 0.1147015726510332\n",
      "114 Train Loss 32572.742 Test MSE 4470.065892462129 Test RE 0.11697498666715135\n",
      "115 Train Loss 32407.889 Test MSE 4481.929851686971 Test RE 0.11713011490214371\n",
      "116 Train Loss 32041.172 Test MSE 4623.3123583244405 Test RE 0.11896320604831384\n",
      "117 Train Loss 31379.557 Test MSE 4318.589925534574 Test RE 0.11497595498515462\n",
      "118 Train Loss 30853.625 Test MSE 4273.366136173335 Test RE 0.11437236298663313\n",
      "119 Train Loss 30566.143 Test MSE 4248.061106343806 Test RE 0.11403322830422855\n",
      "120 Train Loss 29944.578 Test MSE 4157.336243592751 Test RE 0.11280896575520845\n",
      "121 Train Loss 29478.893 Test MSE 4202.233376201137 Test RE 0.11341646991458643\n",
      "122 Train Loss 28635.785 Test MSE 4289.0349290637 Test RE 0.11458185090566807\n",
      "123 Train Loss 27849.527 Test MSE 4072.2467385467776 Test RE 0.11164854916065649\n",
      "124 Train Loss 27606.98 Test MSE 3938.397167196602 Test RE 0.10979834576659968\n",
      "125 Train Loss 27014.877 Test MSE 3686.5835887765284 Test RE 0.10623022089927352\n",
      "126 Train Loss 26629.115 Test MSE 3750.0622491080517 Test RE 0.10714089755224283\n",
      "127 Train Loss 26382.055 Test MSE 3657.8671933049486 Test RE 0.10581567546413208\n",
      "128 Train Loss 26206.623 Test MSE 3588.5998788921383 Test RE 0.10480899603864337\n",
      "129 Train Loss 25981.152 Test MSE 3629.8585081245687 Test RE 0.10540977592434493\n",
      "130 Train Loss 25375.69 Test MSE 3693.665184639569 Test RE 0.10633220130416283\n",
      "131 Train Loss 24483.162 Test MSE 3513.1704915195146 Test RE 0.10370164724722651\n",
      "132 Train Loss 24127.898 Test MSE 3481.9163631390584 Test RE 0.10323933759180524\n",
      "133 Train Loss 23886.178 Test MSE 3606.1442973805206 Test RE 0.10506488565707875\n",
      "134 Train Loss 23595.33 Test MSE 3610.742324226024 Test RE 0.1051318459935591\n",
      "135 Train Loss 23030.467 Test MSE 3759.4342194134183 Test RE 0.10727469462863941\n",
      "136 Train Loss 22699.637 Test MSE 3928.5264334083245 Test RE 0.10966066663995155\n",
      "137 Train Loss 22424.477 Test MSE 3936.753582224932 Test RE 0.1097754326708492\n",
      "138 Train Loss 22002.295 Test MSE 3833.821908833019 Test RE 0.10833081470569517\n",
      "139 Train Loss 21885.348 Test MSE 3848.3047980070737 Test RE 0.10853524050820905\n",
      "140 Train Loss 21622.764 Test MSE 3954.0728515148126 Test RE 0.1100166395141671\n",
      "141 Train Loss 21473.066 Test MSE 3916.469922308195 Test RE 0.10949226494843584\n",
      "142 Train Loss 21235.379 Test MSE 3970.2776697117442 Test RE 0.11024184740083791\n",
      "143 Train Loss 21116.705 Test MSE 3843.1054767322908 Test RE 0.10846189648419252\n",
      "144 Train Loss 21047.41 Test MSE 3913.502128835352 Test RE 0.10945077196896023\n",
      "145 Train Loss 20961.877 Test MSE 3871.6826614175334 Test RE 0.1088644088511905\n",
      "146 Train Loss 20900.29 Test MSE 3773.3732541726963 Test RE 0.10747338439410381\n",
      "147 Train Loss 20808.752 Test MSE 3922.9555962894206 Test RE 0.10958288703885123\n",
      "148 Train Loss 20691.37 Test MSE 3999.7111806906096 Test RE 0.1106497298304082\n",
      "149 Train Loss 20616.506 Test MSE 4027.9846849726955 Test RE 0.11104012631775169\n",
      "150 Train Loss 20560.182 Test MSE 4108.9542670492665 Test RE 0.11215062433766698\n",
      "151 Train Loss 20520.672 Test MSE 4132.004703916535 Test RE 0.11246475602970706\n",
      "152 Train Loss 20496.01 Test MSE 4188.366048991968 Test RE 0.11322917867611097\n",
      "153 Train Loss 20466.697 Test MSE 4149.692882410522 Test RE 0.11270521706902276\n",
      "154 Train Loss 20422.068 Test MSE 4204.005832678905 Test RE 0.11344038631161141\n",
      "155 Train Loss 20370.88 Test MSE 4303.8166275032945 Test RE 0.11477912810238021\n",
      "156 Train Loss 20320.83 Test MSE 4257.924306133707 Test RE 0.11416553341798749\n",
      "157 Train Loss 20300.117 Test MSE 4227.409890961551 Test RE 0.11375571419929656\n",
      "158 Train Loss 20283.463 Test MSE 4262.700745455695 Test RE 0.11422954957492752\n",
      "159 Train Loss 20272.88 Test MSE 4239.481290547254 Test RE 0.11391801355336707\n",
      "160 Train Loss 20256.557 Test MSE 4268.451944134617 Test RE 0.1143065823568509\n",
      "161 Train Loss 20255.338 Test MSE 4286.098797560532 Test RE 0.11454262471793794\n",
      "162 Train Loss 20244.191 Test MSE 4320.439982475376 Test RE 0.11500057983851665\n",
      "163 Train Loss 20183.59 Test MSE 4254.564812613068 Test RE 0.11412048634518594\n",
      "164 Train Loss 20167.53 Test MSE 4234.970732924427 Test RE 0.11385739640776223\n",
      "165 Train Loss 20156.992 Test MSE 4238.799968234913 Test RE 0.11390885936707716\n",
      "166 Train Loss 20150.092 Test MSE 4240.5875672751445 Test RE 0.11393287582286307\n",
      "167 Train Loss 20147.838 Test MSE 4260.514944024314 Test RE 0.1142002588571608\n",
      "168 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "169 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "170 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "171 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "172 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "173 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "174 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "175 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "176 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "177 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "178 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "179 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "180 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "181 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "182 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "183 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "184 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "185 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "186 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "187 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "188 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "189 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "190 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "191 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "192 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "193 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "194 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "195 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "196 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "197 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "198 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Train Loss 20145.69 Test MSE 4235.557404457776 Test RE 0.11386528248116849\n",
      "Training time: 244.08\n",
      "Training time: 244.08\n",
      "ES_swish\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 249998.78 Test MSE 75079.5889168691 Test RE 0.47939884666535176\n",
      "1 Train Loss 249998.78 Test MSE 75079.63109720482 Test RE 0.4793989813304567\n",
      "2 Train Loss 249998.78 Test MSE 75079.6700130031 Test RE 0.4793991055731532\n",
      "3 Train Loss 249998.78 Test MSE 75079.70698702507 Test RE 0.4793992236164988\n",
      "4 Train Loss 249998.78 Test MSE 75079.74399227776 Test RE 0.4793993417595227\n",
      "5 Train Loss 249998.73 Test MSE 75079.83833586852 Test RE 0.4793996429608767\n",
      "6 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "7 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "8 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "9 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "10 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "11 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "12 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "13 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "14 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "15 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "16 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "17 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "18 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "19 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "20 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "21 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "22 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "23 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "24 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "25 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "26 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "27 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "28 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "29 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "30 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "31 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "32 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "33 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "34 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "35 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "36 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "37 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "38 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "39 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "40 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "41 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "42 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "43 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "44 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "45 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "46 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "47 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "48 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "49 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "50 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "51 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "52 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "53 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "54 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "55 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "56 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "57 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "58 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "59 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "60 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "61 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "62 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "63 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "64 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "65 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "66 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "67 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "68 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "69 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "70 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "71 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "72 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "73 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "74 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "75 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "76 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "77 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "78 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "79 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "80 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "81 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "82 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "83 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "84 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "85 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "86 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "87 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "88 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "89 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "90 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "91 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "92 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "93 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "95 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "96 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "97 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "98 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "99 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "100 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "101 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "102 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "103 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "104 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "105 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "106 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "107 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "108 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "109 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "110 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "111 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "112 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "113 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "114 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "115 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "116 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "117 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "118 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "119 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "120 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "121 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "122 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "123 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "124 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "125 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "126 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "127 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "128 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "129 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "130 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "131 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "132 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "133 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "134 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "135 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "136 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "137 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "138 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "139 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "140 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "141 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "142 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "143 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "144 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "145 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "146 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "147 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "148 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "149 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "150 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "151 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "152 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "153 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "154 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "155 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "156 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "157 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "158 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "159 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "160 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "161 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "162 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "163 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "164 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "165 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "166 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "167 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "168 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "169 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "170 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "171 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "172 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "173 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "174 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "175 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "176 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "177 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "178 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "179 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "180 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "181 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "182 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "183 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "184 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "185 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "186 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "187 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "188 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "189 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "190 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "191 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "192 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "193 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "194 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "195 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "196 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "198 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "199 Train Loss 249998.73 Test MSE 75079.86641823636 Test RE 0.47939973261660956\n",
      "Training time: 56.17\n",
      "Training time: 56.17\n",
      "ES_swish\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 250065.22 Test MSE 75166.14715528398 Test RE 0.4796751132721133\n",
      "1 Train Loss 249999.75 Test MSE 75083.46213648924 Test RE 0.47941121216374294\n",
      "2 Train Loss 249998.89 Test MSE 75080.89910725092 Test RE 0.4794030295666357\n",
      "3 Train Loss 249998.89 Test MSE 75080.82540688729 Test RE 0.47940279427252813\n",
      "4 Train Loss 249998.83 Test MSE 75080.63995292735 Test RE 0.47940220219591606\n",
      "5 Train Loss 249998.83 Test MSE 75080.59217864314 Test RE 0.47940204967257105\n",
      "6 Train Loss 249998.83 Test MSE 75080.5484244485 Test RE 0.4794019099836512\n",
      "7 Train Loss 249998.83 Test MSE 75080.50843554463 Test RE 0.4794017823157009\n",
      "8 Train Loss 249998.83 Test MSE 75080.47136931763 Test RE 0.4794016639786129\n",
      "9 Train Loss 249998.83 Test MSE 75080.4373486924 Test RE 0.4794015553648422\n",
      "10 Train Loss 249998.83 Test MSE 75080.40367659584 Test RE 0.47940144786375505\n",
      "11 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "12 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "13 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "14 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "15 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "16 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "17 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "18 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "19 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "20 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "21 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "22 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "23 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "24 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "25 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "26 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "27 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "28 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "29 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "30 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "31 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "32 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "33 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "34 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "35 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "36 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "37 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "38 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "39 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "40 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "41 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "42 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "43 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "44 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "45 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "46 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "47 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "48 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "49 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "50 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "51 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "52 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "53 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "54 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "55 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "56 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "57 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "58 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "59 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "60 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "61 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "62 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "63 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "64 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "65 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "66 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "67 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "68 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "69 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "70 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "71 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "72 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "73 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "74 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "75 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "76 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "77 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "78 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "79 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "80 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "81 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "82 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "83 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "84 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "85 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "86 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "87 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "88 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "89 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "90 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "91 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "93 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "94 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "95 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "96 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "97 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "98 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "99 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "100 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "101 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "102 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "103 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "104 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "105 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "106 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "107 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "108 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "109 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "110 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "111 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "112 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "113 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "114 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "115 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "116 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "117 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "118 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "119 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "120 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "121 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "122 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "123 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "124 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "125 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "126 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "127 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "128 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "129 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "130 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "131 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "132 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "133 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "134 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "135 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "136 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "137 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "138 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "139 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "140 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "141 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "142 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "143 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "144 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "145 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "146 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "147 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "148 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "149 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "150 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "151 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "152 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "153 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "154 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "155 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "156 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "157 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "158 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "159 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "160 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "161 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "162 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "163 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "164 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "165 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "166 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "167 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "168 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "169 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "170 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "171 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "172 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "173 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "174 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "175 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "176 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "177 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "178 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "179 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "180 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "181 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "182 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "183 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "184 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "185 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "186 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "187 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "188 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "189 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "190 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "191 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "192 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "193 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "194 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "196 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "197 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "198 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "199 Train Loss 249998.81 Test MSE 75080.37289701386 Test RE 0.47940134959725034\n",
      "Training time: 57.43\n",
      "Training time: 57.43\n",
      "ES_swish\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 250043.52 Test MSE 75139.76046267476 Test RE 0.47959091213079114\n",
      "1 Train Loss 250000.67 Test MSE 75082.93457081393 Test RE 0.4794095278957498\n",
      "2 Train Loss 250000.06 Test MSE 75080.8127606406 Test RE 0.47940275389839665\n",
      "3 Train Loss 250000.06 Test MSE 75080.77113358674 Test RE 0.4794026210007475\n",
      "4 Train Loss 250000.06 Test MSE 75080.73478120514 Test RE 0.479402504942875\n",
      "5 Train Loss 250000.06 Test MSE 75080.7014111517 Test RE 0.4794023984062979\n",
      "6 Train Loss 250000.06 Test MSE 75080.67207580604 Test RE 0.47940230475083\n",
      "7 Train Loss 250000.06 Test MSE 75080.64543393493 Test RE 0.47940221969448205\n",
      "8 Train Loss 250000.06 Test MSE 75080.62149881195 Test RE 0.4794021432796354\n",
      "9 Train Loss 250000.06 Test MSE 75080.59969160774 Test RE 0.47940207365833376\n",
      "10 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "11 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "12 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "13 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "14 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "15 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "16 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "17 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "18 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "19 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "20 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "21 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "22 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "23 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "24 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "25 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "26 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "27 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "28 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "29 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "30 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "31 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "32 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "33 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "34 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "35 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "36 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "37 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "38 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "39 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "40 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "41 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "42 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "43 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "44 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "45 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "46 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "47 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "48 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "49 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "50 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "51 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "52 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "53 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "54 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "55 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "56 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "57 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "58 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "59 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "60 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "61 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "62 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "63 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "64 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "65 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "66 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "67 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "68 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "69 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "70 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "71 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "72 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "73 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "74 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "75 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "76 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "77 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "78 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "79 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "80 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "81 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "82 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "83 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "84 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "85 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "86 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "87 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "88 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "89 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "91 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "92 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "93 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "94 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "95 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "96 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "97 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "98 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "99 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "100 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "101 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "102 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "103 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "104 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "105 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "106 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "107 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "108 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "109 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "110 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "111 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "112 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "113 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "114 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "115 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "116 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "117 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "118 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "119 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "120 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "121 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "122 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "123 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "124 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "125 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "126 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "127 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "128 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "129 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "130 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "131 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "132 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "133 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "134 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "135 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "136 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "137 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "138 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "139 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "140 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "141 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "142 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "143 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "144 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "145 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "146 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "147 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "148 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "149 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "150 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "151 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "152 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "153 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "154 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "155 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "156 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "157 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "158 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "159 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "160 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "161 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "162 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "163 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "164 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "165 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "166 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "167 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "168 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "169 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "170 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "171 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "172 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "173 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "174 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "175 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "176 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "177 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "178 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "179 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "180 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "181 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "182 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "183 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "184 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "185 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "186 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "187 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "188 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "189 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "190 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "191 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "192 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "194 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "195 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "196 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "197 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "198 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "199 Train Loss 250000.03 Test MSE 75080.58079580488 Test RE 0.47940201333191323\n",
      "Training time: 57.78\n",
      "Training time: 57.78\n",
      "ES_swish\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 250134.2 Test MSE 75242.57009040647 Test RE 0.4799188989948409\n",
      "1 Train Loss 250001.5 Test MSE 75085.23393415936 Test RE 0.47941686863344696\n",
      "2 Train Loss 249999.81 Test MSE 75080.99121448473 Test RE 0.4794033236259364\n",
      "3 Train Loss 249999.75 Test MSE 75080.830128966 Test RE 0.479402809348133\n",
      "4 Train Loss 249999.75 Test MSE 75080.76450327573 Test RE 0.47940259983295386\n",
      "5 Train Loss 249999.73 Test MSE 75080.64646377676 Test RE 0.47940222298233637\n",
      "6 Train Loss 249999.73 Test MSE 75080.59826914434 Test RE 0.47940206911700145\n",
      "7 Train Loss 249999.73 Test MSE 75080.55705168308 Test RE 0.47940193752682114\n",
      "8 Train Loss 249999.7 Test MSE 75080.48511078647 Test RE 0.4794017078494263\n",
      "9 Train Loss 249999.7 Test MSE 75080.45428483962 Test RE 0.47940160943495114\n",
      "10 Train Loss 249999.7 Test MSE 75080.42434295431 Test RE 0.47940151384289886\n",
      "11 Train Loss 249999.7 Test MSE 75080.39768175535 Test RE 0.47940142872470454\n",
      "12 Train Loss 249999.7 Test MSE 75080.3729174102 Test RE 0.47940134966236736\n",
      "13 Train Loss 249999.7 Test MSE 75080.34943105269 Test RE 0.47940127468010557\n",
      "14 Train Loss 249999.7 Test MSE 75080.32693856429 Test RE 0.4794012028708472\n",
      "15 Train Loss 249999.7 Test MSE 75080.30590804905 Test RE 0.4794011357290578\n",
      "16 Train Loss 249999.7 Test MSE 75080.28489685354 Test RE 0.4794010686489389\n",
      "17 Train Loss 249999.7 Test MSE 75080.26541691375 Test RE 0.47940100645748235\n",
      "18 Train Loss 249999.7 Test MSE 75080.2449567002 Test RE 0.4794009411364051\n",
      "19 Train Loss 249999.7 Test MSE 75080.22455849573 Test RE 0.4794008760132885\n",
      "20 Train Loss 249999.7 Test MSE 75080.2047426221 Test RE 0.4794008127493074\n",
      "21 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "22 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "23 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "24 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "25 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "26 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "27 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "28 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "29 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "30 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "31 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "32 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "33 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "34 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "35 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "36 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "37 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "38 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "39 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "40 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "41 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "42 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "43 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "44 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "45 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "46 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "47 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "48 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "49 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "50 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "51 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "52 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "53 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "54 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "55 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "56 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "57 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "58 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "59 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "60 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "61 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "62 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "63 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "64 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "65 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "66 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "67 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "68 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "69 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "70 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "71 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "72 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "73 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "74 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "75 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "76 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "77 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "78 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "79 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "80 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "81 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "82 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "83 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "84 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "85 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "86 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "87 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "88 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "90 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "91 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "92 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "93 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "94 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "95 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "96 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "97 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "98 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "99 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "100 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "101 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "102 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "103 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "104 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "105 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "106 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "107 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "108 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "109 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "110 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "111 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "112 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "113 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "114 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "115 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "116 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "117 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "118 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "119 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "120 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "121 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "122 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "123 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "124 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "125 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "126 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "127 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "128 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "129 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "130 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "131 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "132 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "133 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "134 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "135 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "136 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "137 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "138 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "139 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "140 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "141 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "142 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "143 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "144 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "145 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "146 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "147 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "148 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "149 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "150 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "151 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "152 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "153 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "154 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "155 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "156 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "157 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "158 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "159 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "160 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "161 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "162 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "163 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "164 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "165 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "166 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "167 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "168 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "169 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "170 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "171 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "172 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "173 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "174 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "175 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "176 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "177 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "178 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "179 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "180 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "181 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "182 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "183 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "184 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "185 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "186 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "187 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "188 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "189 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "190 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "191 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "192 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "194 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "195 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "196 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "197 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "198 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "199 Train Loss 249999.69 Test MSE 75080.16222451883 Test RE 0.4794006770063629\n",
      "Training time: 52.01\n",
      "Training time: 52.01\n",
      "ES_swish\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 250000.11 Test MSE 75080.05162570778 Test RE 0.4794003239093339\n",
      "1 Train Loss 250000.11 Test MSE 75080.08864230227 Test RE 0.4794004420882964\n",
      "2 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "3 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "4 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "5 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "6 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "7 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "8 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "9 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "10 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "11 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "12 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "13 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "14 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "15 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "16 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "17 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "18 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "19 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "20 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "21 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "22 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "23 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "24 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "25 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "26 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "27 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "28 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "29 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "30 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "31 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "32 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "33 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "34 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "35 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "36 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "37 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "38 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "39 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "40 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "41 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "42 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "43 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "44 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "45 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "46 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "47 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "48 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "49 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "50 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "51 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "52 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "53 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "54 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "55 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "56 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "57 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "58 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "59 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "60 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "61 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "62 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "63 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "64 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "65 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "66 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "67 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "68 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "69 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "70 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "71 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "72 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "73 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "74 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "75 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "76 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "77 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "78 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "79 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "80 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "81 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "82 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "83 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "84 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "85 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "86 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "87 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "88 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "89 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "91 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "92 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "93 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "94 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "95 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "96 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "97 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "98 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "99 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "100 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "101 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "102 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "103 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "104 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "105 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "106 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "107 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "108 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "109 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "110 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "111 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "112 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "113 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "114 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "115 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "116 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "117 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "118 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "119 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "120 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "121 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "122 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "123 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "124 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "125 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "126 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "127 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "128 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "129 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "130 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "131 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "132 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "133 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "134 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "135 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "136 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "137 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "138 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "139 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "140 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "141 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "142 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "143 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "144 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "145 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "146 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "147 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "148 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "149 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "150 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "151 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "152 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "153 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "154 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "155 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "156 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "157 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "158 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "159 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "160 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "161 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "162 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "163 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "164 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "165 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "166 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "167 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "168 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "169 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "170 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "171 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "172 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "173 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "174 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "175 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "176 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "177 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "178 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "179 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "180 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "181 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "182 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "183 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "184 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "185 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "186 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "187 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "188 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "189 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "190 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "191 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "192 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "193 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "194 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "195 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "197 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "198 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "199 Train Loss 250000.1 Test MSE 75080.12290634436 Test RE 0.4794005514794502\n",
      "Training time: 68.22\n",
      "Training time: 68.22\n",
      "ES_swish\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 250000.22 Test MSE 75079.76462808553 Test RE 0.4793994076414201\n",
      "1 Train Loss 250000.17 Test MSE 75079.88336825334 Test RE 0.4793997867312046\n",
      "2 Train Loss 250000.14 Test MSE 75079.98459784256 Test RE 0.4794001099164905\n",
      "3 Train Loss 250000.11 Test MSE 75080.06873782488 Test RE 0.4794003785413822\n",
      "4 Train Loss 250000.11 Test MSE 75080.10530004092 Test RE 0.47940049526968553\n",
      "5 Train Loss 250000.11 Test MSE 75080.13842612098 Test RE 0.47940060102777804\n",
      "6 Train Loss 250000.11 Test MSE 75080.16875182716 Test RE 0.47940069784539585\n",
      "7 Train Loss 250000.11 Test MSE 75080.19705720241 Test RE 0.479400788212903\n",
      "8 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "9 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "10 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "11 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "12 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "13 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "14 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "15 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "16 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "17 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "18 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "19 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "20 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "21 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "22 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "23 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "24 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "25 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "26 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "27 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "28 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "29 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "30 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "31 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "32 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "33 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "34 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "35 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "36 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "37 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "38 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "39 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "40 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "41 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "42 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "43 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "44 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "45 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "46 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "47 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "48 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "49 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "50 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "51 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "52 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "53 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "54 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "55 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "56 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "57 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "58 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "59 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "60 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "61 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "62 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "63 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "64 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "65 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "66 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "67 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "68 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "69 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "70 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "71 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "72 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "73 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "74 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "75 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "76 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "77 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "78 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "79 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "80 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "81 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "82 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "83 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "84 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "85 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "86 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "87 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "88 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "89 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "90 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "91 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "92 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "94 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "95 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "96 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "97 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "98 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "99 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "100 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "101 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "102 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "103 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "104 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "105 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "106 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "107 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "108 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "109 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "110 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "111 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "112 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "113 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "114 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "115 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "116 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "117 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "118 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "119 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "120 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "121 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "122 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "123 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "124 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "125 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "126 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "127 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "128 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "129 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "130 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "131 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "132 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "133 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "134 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "135 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "136 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "137 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "138 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "139 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "140 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "141 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "142 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "143 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "144 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "145 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "146 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "147 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "148 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "149 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "150 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "151 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "152 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "153 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "154 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "155 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "156 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "157 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "158 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "159 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "160 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "161 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "162 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "163 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "164 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "165 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "166 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "167 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "168 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "169 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "170 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "171 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "172 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "173 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "174 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "175 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "176 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "177 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "178 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "179 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "180 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "181 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "182 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "183 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "184 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "185 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "186 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "187 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "188 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "189 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "190 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "191 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "192 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "193 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "194 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "195 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "196 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "197 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "198 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Train Loss 250000.1 Test MSE 75080.22313722059 Test RE 0.4794008714757384\n",
      "Training time: 64.34\n",
      "Training time: 64.34\n",
      "ES_swish\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 249998.62 Test MSE 75079.53828743522 Test RE 0.4793986850255728\n",
      "1 Train Loss 249998.62 Test MSE 75079.57398151432 Test RE 0.4793987989826704\n",
      "2 Train Loss 249998.62 Test MSE 75079.60824611265 Test RE 0.479398908375975\n",
      "3 Train Loss 249998.62 Test MSE 75079.6397362323 Test RE 0.479399008911445\n",
      "4 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "5 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "6 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "7 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "8 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "9 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "10 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "11 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "12 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "13 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "14 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "15 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "16 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "17 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "18 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "19 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "20 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "21 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "22 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "23 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "24 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "25 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "26 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "27 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "28 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "29 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "30 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "31 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "32 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "33 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "34 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "35 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "36 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "37 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "38 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "39 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "40 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "41 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "42 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "43 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "44 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "45 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "46 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "47 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "48 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "49 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "50 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "51 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "52 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "53 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "54 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "55 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "56 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "57 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "58 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "59 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "60 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "61 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "62 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "63 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "64 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "65 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "66 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "67 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "68 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "69 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "70 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "71 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "72 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "73 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "74 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "75 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "76 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "77 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "78 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "79 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "80 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "81 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "82 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "83 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "84 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "85 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "86 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "87 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "88 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "89 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "90 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "91 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "92 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "93 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "94 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "96 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "97 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "98 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "99 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "100 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "101 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "102 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "103 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "104 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "105 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "106 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "107 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "108 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "109 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "110 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "111 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "112 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "113 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "114 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "115 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "116 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "117 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "118 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "119 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "120 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "121 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "122 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "123 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "124 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "125 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "126 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "127 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "128 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "129 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "130 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "131 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "132 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "133 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "134 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "135 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "136 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "137 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "138 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "139 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "140 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "141 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "142 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "143 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "144 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "145 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "146 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "147 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "148 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "149 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "150 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "151 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "152 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "153 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "154 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "155 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "156 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "157 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "158 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "159 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "160 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "161 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "162 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "163 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "164 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "165 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "166 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "167 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "168 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "169 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "170 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "171 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "172 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "173 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "174 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "175 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "176 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "177 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "178 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "179 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "180 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "181 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "182 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "183 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "184 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "185 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "186 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "187 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "188 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "189 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "190 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "191 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "192 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "193 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "194 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "195 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "196 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "197 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "198 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Train Loss 249998.61 Test MSE 75079.67039575972 Test RE 0.4793991067951428\n",
      "Training time: 73.52\n",
      "Training time: 73.52\n",
      "ES_swish\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 250000.02 Test MSE 75080.79913740508 Test RE 0.479402710405148\n",
      "1 Train Loss 250000.02 Test MSE 75080.8269899704 Test RE 0.47940279932664454\n",
      "2 Train Loss 250000.02 Test MSE 75080.85745076413 Test RE 0.4794028965750961\n",
      "3 Train Loss 250000.02 Test MSE 75080.890684522 Test RE 0.4794030026764285\n",
      "4 Train Loss 250000.02 Test MSE 75080.9290232712 Test RE 0.4794031250758098\n",
      "5 Train Loss 249999.97 Test MSE 75081.0625593037 Test RE 0.4794035513995358\n",
      "6 Train Loss 249999.97 Test MSE 75081.11680607076 Test RE 0.4794037245862702\n",
      "7 Train Loss 249999.97 Test MSE 75081.17600750182 Test RE 0.4794039135910571\n",
      "8 Train Loss 249999.81 Test MSE 75081.6733529582 Test RE 0.47940550139892063\n",
      "9 Train Loss 249999.5 Test MSE 75082.54106525381 Test RE 0.4794082716145252\n",
      "10 Train Loss 248540.66 Test MSE 74432.26030327711 Test RE 0.4773277085575864\n",
      "11 Train Loss 222932.11 Test MSE 64829.0914581978 Test RE 0.44547261306827945\n",
      "12 Train Loss 183416.34 Test MSE 55277.80691158803 Test RE 0.4113499455085303\n",
      "13 Train Loss 138342.05 Test MSE 35166.34784636902 Test RE 0.3280950480694882\n",
      "14 Train Loss 97058.375 Test MSE 26295.20296408243 Test RE 0.28370977903786815\n",
      "15 Train Loss 80379.17 Test MSE 15900.531457493793 Test RE 0.2206184667590726\n",
      "16 Train Loss 67614.945 Test MSE 12197.009576749808 Test RE 0.19322473673416732\n",
      "17 Train Loss 56245.613 Test MSE 9426.279159660116 Test RE 0.1698658945214145\n",
      "18 Train Loss 53431.08 Test MSE 9539.073299751737 Test RE 0.17087917352307092\n",
      "19 Train Loss 51183.844 Test MSE 9043.399834203738 Test RE 0.1663803019656462\n",
      "20 Train Loss 49916.5 Test MSE 8616.147782832702 Test RE 0.16240246300754965\n",
      "21 Train Loss 48867.445 Test MSE 8082.361661121172 Test RE 0.15729147382185946\n",
      "22 Train Loss 48354.367 Test MSE 8026.2153946025965 Test RE 0.15674418825251785\n",
      "23 Train Loss 47878.38 Test MSE 8069.211492664689 Test RE 0.15716346350225519\n",
      "24 Train Loss 47393.43 Test MSE 7801.124171927454 Test RE 0.15453065207235486\n",
      "25 Train Loss 46788.617 Test MSE 7641.5510042909 Test RE 0.15294201227228924\n",
      "26 Train Loss 46628.207 Test MSE 7453.5280232890045 Test RE 0.1510486980141989\n",
      "27 Train Loss 46353.81 Test MSE 7302.054349196252 Test RE 0.1495059828544046\n",
      "28 Train Loss 46050.887 Test MSE 7025.408318085044 Test RE 0.14664654219791753\n",
      "29 Train Loss 45666.332 Test MSE 6901.301955411033 Test RE 0.14534548876705602\n",
      "30 Train Loss 45284.27 Test MSE 6742.423409392778 Test RE 0.1436627094014204\n",
      "31 Train Loss 44781.766 Test MSE 6515.844899689147 Test RE 0.14122819574773882\n",
      "32 Train Loss 44178.16 Test MSE 6543.131280602161 Test RE 0.14152359721877486\n",
      "33 Train Loss 43850.31 Test MSE 6364.502915298086 Test RE 0.13957842283799032\n",
      "34 Train Loss 43645.33 Test MSE 6372.148004300804 Test RE 0.1396622290065936\n",
      "35 Train Loss 43279.16 Test MSE 6181.854251366223 Test RE 0.13756103115338383\n",
      "36 Train Loss 42876.992 Test MSE 6094.5880832409575 Test RE 0.13658663978191007\n",
      "37 Train Loss 42353.887 Test MSE 5937.136695611972 Test RE 0.13481076275439927\n",
      "38 Train Loss 42081.316 Test MSE 5895.943633529961 Test RE 0.13434227647960897\n",
      "39 Train Loss 41792.98 Test MSE 5960.766151939397 Test RE 0.13507876583019907\n",
      "40 Train Loss 41611.566 Test MSE 6051.390368120928 Test RE 0.1361017240727498\n",
      "41 Train Loss 41537.63 Test MSE 6068.988610366484 Test RE 0.13629948129366928\n",
      "42 Train Loss 41491.62 Test MSE 6045.035207837439 Test RE 0.13603023839509146\n",
      "43 Train Loss 41471.16 Test MSE 6058.947927195468 Test RE 0.13618668602405096\n",
      "44 Train Loss 41431.5 Test MSE 6055.111621679855 Test RE 0.13614356496847377\n",
      "45 Train Loss 41407.46 Test MSE 6045.252870607563 Test RE 0.13603268738430052\n",
      "46 Train Loss 41387.98 Test MSE 6056.371177656024 Test RE 0.13615772420573266\n",
      "47 Train Loss 41381.453 Test MSE 6071.2406049718375 Test RE 0.13632476699177343\n",
      "48 Train Loss 41372.613 Test MSE 6065.024147346333 Test RE 0.13625495636858878\n",
      "49 Train Loss 41356.27 Test MSE 6049.557188587407 Test RE 0.13608110750546243\n",
      "50 Train Loss 41333.83 Test MSE 6056.05066257066 Test RE 0.13615412129066043\n",
      "51 Train Loss 41304.016 Test MSE 6038.889024454807 Test RE 0.13596106763064036\n",
      "52 Train Loss 41259.98 Test MSE 6013.664740728808 Test RE 0.13567681755704156\n",
      "53 Train Loss 41222.465 Test MSE 5995.613561457199 Test RE 0.13547303439753172\n",
      "54 Train Loss 41170.926 Test MSE 5998.258993048666 Test RE 0.1355029183383255\n",
      "55 Train Loss 41159.484 Test MSE 5965.491712221038 Test RE 0.13513229891408324\n",
      "56 Train Loss 41150.71 Test MSE 5970.285799283972 Test RE 0.13518658663531036\n",
      "57 Train Loss 41141.65 Test MSE 5966.14718981337 Test RE 0.135139722758185\n",
      "58 Train Loss 41103.098 Test MSE 5965.73992108918 Test RE 0.13513511013968701\n",
      "59 Train Loss 41054.023 Test MSE 5964.646334824304 Test RE 0.1351227236901064\n",
      "60 Train Loss 41027.1 Test MSE 5936.3301646537175 Test RE 0.13480160575228944\n",
      "61 Train Loss 40988.816 Test MSE 5932.9512645960585 Test RE 0.13476323642535679\n",
      "62 Train Loss 40972.242 Test MSE 5928.330010250706 Test RE 0.13471074176600764\n",
      "63 Train Loss 40923.5 Test MSE 5912.992330599866 Test RE 0.13453636818117898\n",
      "64 Train Loss 40882.242 Test MSE 5891.69328614888 Test RE 0.13429384451320983\n",
      "65 Train Loss 40845.234 Test MSE 5894.117825353962 Test RE 0.13432147385374457\n",
      "66 Train Loss 40812.59 Test MSE 5824.889035676724 Test RE 0.13353031394231296\n",
      "67 Train Loss 40779.75 Test MSE 5865.204775806608 Test RE 0.13399161805726695\n",
      "68 Train Loss 40756.23 Test MSE 5832.059313144246 Test RE 0.13361247472925686\n",
      "69 Train Loss 40713.793 Test MSE 5833.913822785201 Test RE 0.13363371644803176\n",
      "70 Train Loss 40700.78 Test MSE 5802.613796029724 Test RE 0.1332747495160338\n",
      "71 Train Loss 40578.285 Test MSE 5770.514000210932 Test RE 0.1329056033542625\n",
      "72 Train Loss 40541.273 Test MSE 5787.600244018765 Test RE 0.13310222180527295\n",
      "73 Train Loss 40511.98 Test MSE 5799.049818824153 Test RE 0.133233814418237\n",
      "74 Train Loss 40485.438 Test MSE 5768.571533737918 Test RE 0.13288323217484557\n",
      "75 Train Loss 40445.01 Test MSE 5778.768939765806 Test RE 0.1330006326386407\n",
      "76 Train Loss 40389.242 Test MSE 5799.080861485804 Test RE 0.1332341710220614\n",
      "77 Train Loss 40367.508 Test MSE 5803.167061865538 Test RE 0.1332811030845041\n",
      "78 Train Loss 40363.086 Test MSE 5799.709027068799 Test RE 0.13324138689440337\n",
      "79 Train Loss 40339.87 Test MSE 5775.698164310615 Test RE 0.13296529039241572\n",
      "80 Train Loss 40326.133 Test MSE 5749.58968177112 Test RE 0.13266442165538686\n",
      "81 Train Loss 40306.156 Test MSE 5721.8118170106045 Test RE 0.1323435643134773\n",
      "82 Train Loss 40291.137 Test MSE 5706.520813218212 Test RE 0.13216660814711068\n",
      "83 Train Loss 40278.312 Test MSE 5697.667391834061 Test RE 0.13206404294881804\n",
      "84 Train Loss 40237.855 Test MSE 5643.406184324401 Test RE 0.13143368874003428\n",
      "85 Train Loss 40229.566 Test MSE 5640.826203131792 Test RE 0.13140364170826238\n",
      "86 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "87 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "88 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "89 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "90 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "91 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "92 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "93 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "94 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "96 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "97 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "98 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "99 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "100 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "101 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "102 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "103 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "104 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "105 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "106 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "107 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "108 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "109 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "110 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "111 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "112 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "113 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "114 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "115 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "116 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "117 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "118 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "119 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "120 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "121 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "122 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "123 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "124 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "125 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "126 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "127 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "128 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "129 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "130 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "131 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "132 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "133 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "134 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "135 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "136 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "137 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "138 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "139 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "140 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "141 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "142 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "143 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "144 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "145 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "146 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "147 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "148 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "149 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "150 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "151 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "152 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "153 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "154 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "155 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "156 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "157 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "158 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "159 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "160 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "161 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "162 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "163 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "164 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "165 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "166 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "167 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "168 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "169 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "170 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "171 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "172 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "173 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "174 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "175 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "176 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "177 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "178 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "179 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "180 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "181 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "182 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "183 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "184 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "185 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "186 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "187 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "188 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "189 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "190 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "191 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "192 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "193 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "194 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "195 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "196 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "197 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "199 Train Loss 40229.098 Test MSE 5638.513144759318 Test RE 0.13137669747636568\n",
      "Training time: 120.68\n",
      "Training time: 120.68\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1541 into shape (500,500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_876/3689713413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1541 into shape (500,500)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(np.flipud(np.transpose(u_pred.reshape(500,500)))),vmin = 0,vmax = 1000,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "for tune_reps in range(5):\n",
    "    label = \"MW_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
