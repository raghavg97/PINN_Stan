{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "label = \"KG_atanh\"\n",
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "\n",
    "  xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "  xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "  xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "  y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "  f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    " \n",
    "  for i in range(max_iter):\n",
    "    train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    \n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_atanh\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 56.616932 Test MSE 7.951808284558346 Test RE 1.3478482859691505\n",
      "1 Train Loss 45.676773 Test MSE 8.089870267254938 Test RE 1.359498832126889\n",
      "2 Train Loss 37.604042 Test MSE 7.597744013822945 Test RE 1.317499286841015\n",
      "3 Train Loss 33.48955 Test MSE 6.608636222178596 Test RE 1.2287512806983496\n",
      "4 Train Loss 29.58458 Test MSE 6.334931074950105 Test RE 1.203037063209381\n",
      "5 Train Loss 27.407467 Test MSE 6.0707025127751395 Test RE 1.1776806406521012\n",
      "6 Train Loss 25.455597 Test MSE 6.028567846571892 Test RE 1.1735865855087526\n",
      "7 Train Loss 24.177952 Test MSE 5.947628048241919 Test RE 1.1656816521237972\n",
      "8 Train Loss 23.4338 Test MSE 5.913485745519226 Test RE 1.1623310444044672\n",
      "9 Train Loss 22.704634 Test MSE 5.710512540572854 Test RE 1.142209071614665\n",
      "10 Train Loss 21.62101 Test MSE 5.776997236585897 Test RE 1.1488389203719354\n",
      "11 Train Loss 19.553932 Test MSE 5.294619237669034 Test RE 1.0998296586119547\n",
      "12 Train Loss 16.302143 Test MSE 4.306760451656008 Test RE 0.991935465989812\n",
      "13 Train Loss 12.264147 Test MSE 4.301911317336998 Test RE 0.9913768810542776\n",
      "14 Train Loss 10.692729 Test MSE 4.326587528634975 Test RE 0.9942161358246971\n",
      "15 Train Loss 10.086377 Test MSE 4.252510820325331 Test RE 0.9856682647660404\n",
      "16 Train Loss 9.50172 Test MSE 4.254928302806657 Test RE 0.9859483930606668\n",
      "17 Train Loss 9.3267565 Test MSE 4.242846160037891 Test RE 0.9845475659595099\n",
      "18 Train Loss 9.128649 Test MSE 4.249912863188973 Test RE 0.9853671350062813\n",
      "19 Train Loss 8.942232 Test MSE 4.243312214270141 Test RE 0.9846016381486395\n",
      "20 Train Loss 8.791636 Test MSE 4.218128051664576 Test RE 0.9816754724727421\n",
      "21 Train Loss 8.690283 Test MSE 4.203621866831463 Test RE 0.9799860227970543\n",
      "22 Train Loss 8.572602 Test MSE 4.24301516477983 Test RE 0.984567174442128\n",
      "23 Train Loss 8.511526 Test MSE 4.280743380877424 Test RE 0.9889347942562418\n",
      "24 Train Loss 8.418276 Test MSE 4.2801730870713035 Test RE 0.9888689175938508\n",
      "25 Train Loss 8.288913 Test MSE 4.230713422165183 Test RE 0.9831388642398998\n",
      "26 Train Loss 8.09278 Test MSE 4.1619095785355364 Test RE 0.9751117294829713\n",
      "27 Train Loss 6.809003 Test MSE 3.2539176084403354 Test RE 0.862206586828227\n",
      "28 Train Loss 5.790745 Test MSE 2.992843367283986 Test RE 0.826894407001941\n",
      "29 Train Loss 5.4182043 Test MSE 3.042238747691273 Test RE 0.8336902203442565\n",
      "30 Train Loss 5.12485 Test MSE 2.808427005941517 Test RE 0.8010131218512413\n",
      "31 Train Loss 4.850327 Test MSE 2.5666346626826084 Test RE 0.7657554348915269\n",
      "32 Train Loss 4.618728 Test MSE 2.198182554505128 Test RE 0.7086632941960457\n",
      "33 Train Loss 4.3254156 Test MSE 2.187386498449739 Test RE 0.7069209034916094\n",
      "34 Train Loss 4.209194 Test MSE 2.124152159562 Test RE 0.6966279127842387\n",
      "35 Train Loss 4.13447 Test MSE 2.1581296644077157 Test RE 0.70217736786597\n",
      "36 Train Loss 4.092052 Test MSE 2.1744014140843624 Test RE 0.7048195164641803\n",
      "37 Train Loss 4.0525436 Test MSE 2.1717572397301637 Test RE 0.7043908392662332\n",
      "38 Train Loss 4.0231824 Test MSE 2.169364936091612 Test RE 0.7040027707810383\n",
      "39 Train Loss 3.9885375 Test MSE 2.1622682300920246 Test RE 0.7028503152229773\n",
      "40 Train Loss 3.9464047 Test MSE 2.157243244330446 Test RE 0.7020331485326813\n",
      "41 Train Loss 3.9241064 Test MSE 2.1631762037789892 Test RE 0.7029978692134299\n",
      "42 Train Loss 3.8962984 Test MSE 2.142909319859422 Test RE 0.699696911814712\n",
      "43 Train Loss 3.8682308 Test MSE 2.14159185453795 Test RE 0.6994817911520909\n",
      "44 Train Loss 3.8456786 Test MSE 2.117730362525922 Test RE 0.6955740830604501\n",
      "45 Train Loss 3.827533 Test MSE 2.12581840213257 Test RE 0.6969010861388363\n",
      "46 Train Loss 3.8123374 Test MSE 2.1260684587499195 Test RE 0.6969420726134415\n",
      "47 Train Loss 3.7888486 Test MSE 2.135538931680285 Test RE 0.6984925958502423\n",
      "48 Train Loss 3.7679825 Test MSE 2.1288580299807025 Test RE 0.6973991445009842\n",
      "49 Train Loss 3.7473912 Test MSE 2.1209089680558835 Test RE 0.6960958979843612\n",
      "50 Train Loss 3.7241445 Test MSE 2.1148509888471763 Test RE 0.6951010533045868\n",
      "51 Train Loss 3.7119234 Test MSE 2.114845981740117 Test RE 0.695100230445797\n",
      "52 Train Loss 3.6859393 Test MSE 2.1219756639136818 Test RE 0.6962709241839921\n",
      "53 Train Loss 3.6699824 Test MSE 2.120766912890217 Test RE 0.6960725858867117\n",
      "54 Train Loss 3.63045 Test MSE 2.1042757303319184 Test RE 0.6933609576942189\n",
      "55 Train Loss 3.5772057 Test MSE 2.1121956026225597 Test RE 0.6946645351963322\n",
      "56 Train Loss 3.51505 Test MSE 2.1239359435542102 Test RE 0.6965924572405613\n",
      "57 Train Loss 3.2157762 Test MSE 2.027566696366468 Test RE 0.6806057829106703\n",
      "58 Train Loss 2.005445 Test MSE 1.4669977114113224 Test RE 0.5789256320131099\n",
      "59 Train Loss 1.512927 Test MSE 1.158101484019349 Test RE 0.5143767964750668\n",
      "60 Train Loss 1.0026157 Test MSE 0.8279347104210085 Test RE 0.43491672140771437\n",
      "61 Train Loss 0.7616028 Test MSE 0.5573317854417028 Test RE 0.3568329631628669\n",
      "62 Train Loss 0.59816134 Test MSE 0.3642945062433126 Test RE 0.28849239639556556\n",
      "63 Train Loss 0.47470236 Test MSE 0.16686132034995105 Test RE 0.19524768720306135\n",
      "64 Train Loss 0.35615078 Test MSE 0.05115329207458252 Test RE 0.10810476939802252\n",
      "65 Train Loss 0.27464 Test MSE 0.03556542746950734 Test RE 0.09014093878097862\n",
      "66 Train Loss 0.21709247 Test MSE 0.04058999637796904 Test RE 0.09629806633093589\n",
      "67 Train Loss 0.1838809 Test MSE 0.04224357561450273 Test RE 0.09824000949472828\n",
      "68 Train Loss 0.16592063 Test MSE 0.03515798262051165 Test RE 0.08962311487119246\n",
      "69 Train Loss 0.14087029 Test MSE 0.03407611380937914 Test RE 0.08823341535633558\n",
      "70 Train Loss 0.11166048 Test MSE 0.03408388944573131 Test RE 0.08824348152500959\n",
      "71 Train Loss 0.07821851 Test MSE 0.013365583855406989 Test RE 0.055258873574044354\n",
      "72 Train Loss 0.06552715 Test MSE 0.012372966714123919 Test RE 0.053167346093859265\n",
      "73 Train Loss 0.057071976 Test MSE 0.011123407066553724 Test RE 0.05041119303977823\n",
      "74 Train Loss 0.05215668 Test MSE 0.010086016366944875 Test RE 0.04800294635179897\n",
      "75 Train Loss 0.04624791 Test MSE 0.007071504900172042 Test RE 0.0401942550162787\n",
      "76 Train Loss 0.03836242 Test MSE 0.006063721090498283 Test RE 0.03722011141558314\n",
      "77 Train Loss 0.035549488 Test MSE 0.005755649357553587 Test RE 0.03626228980249141\n",
      "78 Train Loss 0.032415733 Test MSE 0.004862763632759229 Test RE 0.03333109951957225\n",
      "79 Train Loss 0.030960103 Test MSE 0.004610153306827009 Test RE 0.032453814100973304\n",
      "80 Train Loss 0.029173365 Test MSE 0.004538537144985832 Test RE 0.03220075150176626\n",
      "81 Train Loss 0.02449808 Test MSE 0.003630572545789446 Test RE 0.02880020770609822\n",
      "82 Train Loss 0.022057226 Test MSE 0.0035765161016119078 Test RE 0.028584997105725964\n",
      "83 Train Loss 0.019869894 Test MSE 0.003519255047192285 Test RE 0.028355246778526827\n",
      "84 Train Loss 0.018640399 Test MSE 0.003468991122920856 Test RE 0.02815202597426528\n",
      "85 Train Loss 0.017167613 Test MSE 0.0035530731128920346 Test RE 0.028491160049707313\n",
      "86 Train Loss 0.016483687 Test MSE 0.003208482567917398 Test RE 0.027074341484980675\n",
      "87 Train Loss 0.015728138 Test MSE 0.0032474871515900537 Test RE 0.027238411775964328\n",
      "88 Train Loss 0.014511719 Test MSE 0.0032436198795901035 Test RE 0.027222188505245944\n",
      "89 Train Loss 0.014019962 Test MSE 0.0030981181503767657 Test RE 0.026604619273398328\n",
      "90 Train Loss 0.013097051 Test MSE 0.0031667632189535853 Test RE 0.02689774402883538\n",
      "91 Train Loss 0.011912247 Test MSE 0.0027539641240599292 Test RE 0.025083445954816867\n",
      "92 Train Loss 0.011688172 Test MSE 0.002588485337569137 Test RE 0.024318171387287778\n",
      "93 Train Loss 0.011226698 Test MSE 0.002417316896399571 Test RE 0.02350037833661146\n",
      "94 Train Loss 0.010701246 Test MSE 0.0022999868487609764 Test RE 0.022922962115601308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.010175719 Test MSE 0.00206056938187433 Test RE 0.021697099541836358\n",
      "96 Train Loss 0.009654796 Test MSE 0.0017844389717618153 Test RE 0.02019105027032558\n",
      "97 Train Loss 0.00900599 Test MSE 0.0016967827972814943 Test RE 0.019688887909677894\n",
      "98 Train Loss 0.008304529 Test MSE 0.0015525647162219459 Test RE 0.01883358152505673\n",
      "99 Train Loss 0.007865839 Test MSE 0.001581546197847251 Test RE 0.019008550524342072\n",
      "100 Train Loss 0.0075437035 Test MSE 0.0014823884748277694 Test RE 0.01840301902867505\n",
      "101 Train Loss 0.007120263 Test MSE 0.0013670987935097668 Test RE 0.017672907741317606\n",
      "102 Train Loss 0.006679426 Test MSE 0.0012115791179911635 Test RE 0.01663734222588711\n",
      "103 Train Loss 0.006238496 Test MSE 0.0009558494708189586 Test RE 0.014777562754639574\n",
      "104 Train Loss 0.005696956 Test MSE 0.0008038979245170463 Test RE 0.013552159799863487\n",
      "105 Train Loss 0.005502346 Test MSE 0.0007994200499999834 Test RE 0.013514362952708756\n",
      "106 Train Loss 0.0052876924 Test MSE 0.0007634236390511253 Test RE 0.013206595069849988\n",
      "107 Train Loss 0.005110063 Test MSE 0.0006980163114752675 Test RE 0.012628182395765582\n",
      "108 Train Loss 0.004840487 Test MSE 0.0006154739581823741 Test RE 0.011858039733086344\n",
      "109 Train Loss 0.0046427124 Test MSE 0.0006047300512328258 Test RE 0.011754085235013053\n",
      "110 Train Loss 0.0043903585 Test MSE 0.0006499673142424909 Test RE 0.012185793628937647\n",
      "111 Train Loss 0.0041501895 Test MSE 0.0006854733121058592 Test RE 0.01251420703590919\n",
      "112 Train Loss 0.0039682523 Test MSE 0.000707841220449272 Test RE 0.012716745655519661\n",
      "113 Train Loss 0.0038449778 Test MSE 0.000790970437759266 Test RE 0.013442751993773393\n",
      "114 Train Loss 0.0037512288 Test MSE 0.0006770108190656619 Test RE 0.012436720230768134\n",
      "115 Train Loss 0.0036724566 Test MSE 0.0006943005387614348 Test RE 0.012594525539289908\n",
      "116 Train Loss 0.0035510552 Test MSE 0.0007085496209510342 Test RE 0.012723107460931237\n",
      "117 Train Loss 0.0034021903 Test MSE 0.0007516856450254074 Test RE 0.013104673002236717\n",
      "118 Train Loss 0.0032894071 Test MSE 0.0007632104818216014 Test RE 0.013204751219593561\n",
      "119 Train Loss 0.0032213463 Test MSE 0.0006777557107571655 Test RE 0.01244356019734758\n",
      "120 Train Loss 0.003161054 Test MSE 0.0006931978921689799 Test RE 0.012584520629293734\n",
      "121 Train Loss 0.003090977 Test MSE 0.0007282276062493235 Test RE 0.0128985719192589\n",
      "122 Train Loss 0.0029984573 Test MSE 0.0007056464577260925 Test RE 0.012697015307071296\n",
      "123 Train Loss 0.0028798615 Test MSE 0.0005869589942914392 Test RE 0.011580090173970181\n",
      "124 Train Loss 0.0027662541 Test MSE 0.0005969597883544845 Test RE 0.011678326127554579\n",
      "125 Train Loss 0.0026549927 Test MSE 0.0004979597537111695 Test RE 0.01066608847960032\n",
      "126 Train Loss 0.002540377 Test MSE 0.0004551592196302648 Test RE 0.010197406509263752\n",
      "127 Train Loss 0.0024830129 Test MSE 0.0004098635058009099 Test RE 0.009676709099839144\n",
      "128 Train Loss 0.0024211956 Test MSE 0.00041966302407467343 Test RE 0.009791707083575334\n",
      "129 Train Loss 0.0023430383 Test MSE 0.0004135061029868058 Test RE 0.00971961409489739\n",
      "130 Train Loss 0.0022687607 Test MSE 0.0004146862105865094 Test RE 0.00973347364657277\n",
      "131 Train Loss 0.0021908183 Test MSE 0.0004804573624279246 Test RE 0.010476964845646303\n",
      "132 Train Loss 0.0021235524 Test MSE 0.0005286271666470718 Test RE 0.010989623131513084\n",
      "133 Train Loss 0.0020638974 Test MSE 0.00047659415522893696 Test RE 0.010434758836322377\n",
      "134 Train Loss 0.0019780048 Test MSE 0.0004326994889565754 Test RE 0.009942629389085541\n",
      "135 Train Loss 0.0019231797 Test MSE 0.00039770706701985393 Test RE 0.009532124682427973\n",
      "136 Train Loss 0.0018876048 Test MSE 0.00038772783996137865 Test RE 0.00941177536506566\n",
      "137 Train Loss 0.0018162953 Test MSE 0.00034982571447415357 Test RE 0.00893992602527884\n",
      "138 Train Loss 0.0016993489 Test MSE 0.0003979166222754909 Test RE 0.009534635630728436\n",
      "139 Train Loss 0.0016525137 Test MSE 0.0004351563607027057 Test RE 0.009970816605243949\n",
      "140 Train Loss 0.0015741591 Test MSE 0.00040679970726717224 Test RE 0.009640473743713587\n",
      "141 Train Loss 0.001526654 Test MSE 0.00038838428779780715 Test RE 0.009419739362063057\n",
      "142 Train Loss 0.0015117462 Test MSE 0.00037292464587644045 Test RE 0.00923035922824496\n",
      "143 Train Loss 0.0014877301 Test MSE 0.00032126019079038444 Test RE 0.008567152876820345\n",
      "144 Train Loss 0.001461502 Test MSE 0.0003291813968642279 Test RE 0.008672128454998028\n",
      "145 Train Loss 0.001447234 Test MSE 0.0003104400593537406 Test RE 0.008421645167690188\n",
      "146 Train Loss 0.0014261123 Test MSE 0.0003227683293575507 Test RE 0.008587238349484012\n",
      "147 Train Loss 0.0013836619 Test MSE 0.0003082627521147149 Test RE 0.008392060110952034\n",
      "148 Train Loss 0.0013408646 Test MSE 0.0002916743872067981 Test RE 0.008163139295257957\n",
      "149 Train Loss 0.001310115 Test MSE 0.0002517060233830636 Test RE 0.0075832411074119935\n",
      "150 Train Loss 0.0012692125 Test MSE 0.00026710137825940075 Test RE 0.007811710225068124\n",
      "151 Train Loss 0.001253111 Test MSE 0.00027535840888946955 Test RE 0.007931534762864213\n",
      "152 Train Loss 0.0012357057 Test MSE 0.0002419161423265631 Test RE 0.007434306883249058\n",
      "153 Train Loss 0.0012072447 Test MSE 0.00024079837872084607 Test RE 0.007417112043340521\n",
      "154 Train Loss 0.0011925203 Test MSE 0.00022615725053887924 Test RE 0.007188086887813474\n",
      "155 Train Loss 0.0011843534 Test MSE 0.0002123202027519642 Test RE 0.006964720947250895\n",
      "156 Train Loss 0.0011663483 Test MSE 0.00020663163366981162 Test RE 0.006870786678464744\n",
      "157 Train Loss 0.0011496198 Test MSE 0.00019181645507171182 Test RE 0.006619893316480417\n",
      "158 Train Loss 0.0011376843 Test MSE 0.00020742272437849357 Test RE 0.006883926542287184\n",
      "159 Train Loss 0.0011267341 Test MSE 0.0002161333469518163 Test RE 0.00702698375751259\n",
      "160 Train Loss 0.001109599 Test MSE 0.00018732586355401642 Test RE 0.0065419456534227495\n",
      "161 Train Loss 0.0010934235 Test MSE 0.00019456071428643844 Test RE 0.006667079538193412\n",
      "162 Train Loss 0.0010714149 Test MSE 0.00018244179370144472 Test RE 0.006456099677940808\n",
      "163 Train Loss 0.0010613066 Test MSE 0.00018924662297774362 Test RE 0.006575399276116994\n",
      "164 Train Loss 0.0010384776 Test MSE 0.0001911359492282086 Test RE 0.006608140209413292\n",
      "165 Train Loss 0.001018683 Test MSE 0.0002053512825704388 Test RE 0.006849466881631923\n",
      "166 Train Loss 0.001001482 Test MSE 0.00020320269451483769 Test RE 0.006813539712398622\n",
      "167 Train Loss 0.0009822368 Test MSE 0.00019974796520992686 Test RE 0.006755371577163271\n",
      "168 Train Loss 0.0009626928 Test MSE 0.00020251817796257626 Test RE 0.006802053852994938\n",
      "169 Train Loss 0.0009475636 Test MSE 0.00021340653120308255 Test RE 0.006982515583237329\n",
      "170 Train Loss 0.0009138165 Test MSE 0.00021453149089320264 Test RE 0.007000895348522844\n",
      "171 Train Loss 0.0008920489 Test MSE 0.0002300707294483176 Test RE 0.007250012327143101\n",
      "172 Train Loss 0.00087236316 Test MSE 0.00020032374857927748 Test RE 0.006765100916892518\n",
      "173 Train Loss 0.00085870654 Test MSE 0.0001939089582039711 Test RE 0.006655903194506699\n",
      "174 Train Loss 0.0008466965 Test MSE 0.00018227139917335682 Test RE 0.006453084083169381\n",
      "175 Train Loss 0.0008261065 Test MSE 0.00016065053820883213 Test RE 0.006058277365437765\n",
      "176 Train Loss 0.00081438496 Test MSE 0.00015990716698034346 Test RE 0.006044244511905346\n",
      "177 Train Loss 0.00080685184 Test MSE 0.0001702025054757776 Test RE 0.006235783588820059\n",
      "178 Train Loss 0.00079884176 Test MSE 0.0001675586844145459 Test RE 0.0061871626238852034\n",
      "179 Train Loss 0.0007935281 Test MSE 0.000171271688814278 Test RE 0.006255338994618784\n",
      "180 Train Loss 0.00078113924 Test MSE 0.00016606900263303712 Test RE 0.006159597711974948\n",
      "181 Train Loss 0.0007727285 Test MSE 0.00015009812450464041 Test RE 0.00585592752543026\n",
      "182 Train Loss 0.0007661433 Test MSE 0.000147693328742233 Test RE 0.005808827766303501\n",
      "183 Train Loss 0.0007577789 Test MSE 0.00015523175098833397 Test RE 0.005955227246103447\n",
      "184 Train Loss 0.00074957206 Test MSE 0.0001500680895937201 Test RE 0.005855341605180979\n",
      "185 Train Loss 0.0007317244 Test MSE 0.00014205546611295575 Test RE 0.005696879521400878\n",
      "186 Train Loss 0.0007193117 Test MSE 0.00011916271683880316 Test RE 0.005217689828890507\n",
      "187 Train Loss 0.0007086211 Test MSE 0.0001139195468527732 Test RE 0.005101609170600953\n",
      "188 Train Loss 0.00068921375 Test MSE 0.00011393441261341079 Test RE 0.005101942023166288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 Train Loss 0.00067690865 Test MSE 0.00011098162131342725 Test RE 0.00503539556222129\n",
      "190 Train Loss 0.00066357775 Test MSE 0.00011273019624664098 Test RE 0.005074908212824249\n",
      "191 Train Loss 0.0006561834 Test MSE 0.00011326874916413601 Test RE 0.0050870161050718355\n",
      "192 Train Loss 0.000641846 Test MSE 0.00012162884196710417 Test RE 0.005271404539006001\n",
      "193 Train Loss 0.00062519853 Test MSE 0.00012766888210729245 Test RE 0.00540070664669316\n",
      "194 Train Loss 0.00061385677 Test MSE 0.0001081705469381841 Test RE 0.004971215306178732\n",
      "195 Train Loss 0.00059660117 Test MSE 0.00011234709160359785 Test RE 0.005066277537117616\n",
      "196 Train Loss 0.000586597 Test MSE 0.00010827934722420047 Test RE 0.004973714756011482\n",
      "197 Train Loss 0.0005801586 Test MSE 0.00010142270645010457 Test RE 0.004813662728983865\n",
      "198 Train Loss 0.0005715263 Test MSE 0.00010336161468966679 Test RE 0.004859456544891105\n",
      "199 Train Loss 0.0005598957 Test MSE 0.00010434867180719876 Test RE 0.004882604230251462\n",
      "Training time: 280.95\n",
      "KG_atanh\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.277283 Test MSE 9.020183041963925 Test RE 1.4355414455959763\n",
      "1 Train Loss 50.02105 Test MSE 8.797698907193636 Test RE 1.4177269907985608\n",
      "2 Train Loss 46.044487 Test MSE 8.73952043686427 Test RE 1.4130315584112731\n",
      "3 Train Loss 45.08272 Test MSE 8.607797130240806 Test RE 1.402342421190791\n",
      "4 Train Loss 44.029068 Test MSE 8.540118243679963 Test RE 1.396818576651794\n",
      "5 Train Loss 42.93174 Test MSE 8.48062299870192 Test RE 1.3919445629228742\n",
      "6 Train Loss 41.86283 Test MSE 8.990518489178216 Test RE 1.4331789788695737\n",
      "7 Train Loss 40.964924 Test MSE 9.52135011966953 Test RE 1.4748821786007078\n",
      "8 Train Loss 40.104637 Test MSE 9.282379251522999 Test RE 1.4562559556872587\n",
      "9 Train Loss 38.66231 Test MSE 9.471301863660168 Test RE 1.4710007680434778\n",
      "10 Train Loss 36.03591 Test MSE 8.58587318559767 Test RE 1.400555408856716\n",
      "11 Train Loss 32.126934 Test MSE 8.377302239132423 Test RE 1.3834394393060576\n",
      "12 Train Loss 30.209122 Test MSE 9.309635539348943 Test RE 1.458392424992864\n",
      "13 Train Loss 29.382914 Test MSE 8.86573347637798 Test RE 1.4231982332041968\n",
      "14 Train Loss 28.225086 Test MSE 8.958381836211542 Test RE 1.4306152331010988\n",
      "15 Train Loss 27.456448 Test MSE 8.816398696558545 Test RE 1.4192329029545874\n",
      "16 Train Loss 26.163519 Test MSE 9.063709110087267 Test RE 1.4390008143641935\n",
      "17 Train Loss 24.723698 Test MSE 8.780479648426434 Test RE 1.416338891191486\n",
      "18 Train Loss 22.52702 Test MSE 7.967001179927384 Test RE 1.3491352854346117\n",
      "19 Train Loss 20.478136 Test MSE 7.554160416007401 Test RE 1.3137150093136876\n",
      "20 Train Loss 19.348421 Test MSE 7.735606103451837 Test RE 1.3293986517201177\n",
      "21 Train Loss 18.83843 Test MSE 7.656738187212433 Test RE 1.3226043869096278\n",
      "22 Train Loss 17.917313 Test MSE 7.482009155948168 Test RE 1.3074261826431373\n",
      "23 Train Loss 16.671616 Test MSE 6.934899366092555 Test RE 1.258717128094138\n",
      "24 Train Loss 15.196266 Test MSE 5.397780274099481 Test RE 1.1104925804063082\n",
      "25 Train Loss 12.610142 Test MSE 5.255631063551452 Test RE 1.0957727491177813\n",
      "26 Train Loss 11.78302 Test MSE 5.2406823153204165 Test RE 1.0942132698489229\n",
      "27 Train Loss 11.37332 Test MSE 5.294138937486883 Test RE 1.0997797720816702\n",
      "28 Train Loss 11.205915 Test MSE 5.2830956578668795 Test RE 1.0986321335476559\n",
      "29 Train Loss 11.006267 Test MSE 5.361658604585013 Test RE 1.1067706634597183\n",
      "30 Train Loss 10.744129 Test MSE 5.455547709082237 Test RE 1.1164190521881066\n",
      "31 Train Loss 10.630248 Test MSE 5.4620320499186565 Test RE 1.1170823303972077\n",
      "32 Train Loss 10.530231 Test MSE 5.456081909245005 Test RE 1.1164737100036415\n",
      "33 Train Loss 10.423981 Test MSE 5.420097200231346 Test RE 1.112785858065902\n",
      "34 Train Loss 10.267115 Test MSE 5.44700936741511 Test RE 1.1155450702839171\n",
      "35 Train Loss 10.10133 Test MSE 5.466735440463603 Test RE 1.1175631902521301\n",
      "36 Train Loss 9.979724 Test MSE 5.429307383685657 Test RE 1.1137309159946167\n",
      "37 Train Loss 9.863062 Test MSE 5.40204869668134 Test RE 1.1109315677918492\n",
      "38 Train Loss 9.700602 Test MSE 5.324173071412398 Test RE 1.1028949357458233\n",
      "39 Train Loss 9.55714 Test MSE 5.2574381918380215 Test RE 1.0959611215239413\n",
      "40 Train Loss 9.291036 Test MSE 5.14721960890123 Test RE 1.0844122359873383\n",
      "41 Train Loss 7.8686423 Test MSE 4.019252192701723 Test RE 0.9582541062949187\n",
      "42 Train Loss 5.25304 Test MSE 3.288441721311666 Test RE 0.8667685303602759\n",
      "43 Train Loss 4.337414 Test MSE 2.7298223409957503 Test RE 0.789723846461191\n",
      "44 Train Loss 3.5976057 Test MSE 2.3115159888644934 Test RE 0.7267022606103234\n",
      "45 Train Loss 2.8939097 Test MSE 2.1837168153551634 Test RE 0.7063276693653774\n",
      "46 Train Loss 2.5148542 Test MSE 2.2031646198745953 Test RE 0.7094659137576942\n",
      "47 Train Loss 2.2857587 Test MSE 2.183139521850835 Test RE 0.7062342998118747\n",
      "48 Train Loss 2.095531 Test MSE 2.1393007441974405 Test RE 0.6991075324412074\n",
      "49 Train Loss 1.9203578 Test MSE 2.133431019984616 Test RE 0.6981477826047556\n",
      "50 Train Loss 1.8243984 Test MSE 2.092737761605987 Test RE 0.6914574587182359\n",
      "51 Train Loss 1.7792958 Test MSE 2.075643280705025 Test RE 0.6886275906624855\n",
      "52 Train Loss 1.7345476 Test MSE 1.9982091337188383 Test RE 0.6756604998879371\n",
      "53 Train Loss 1.6724936 Test MSE 1.967824516760958 Test RE 0.6705038004700666\n",
      "54 Train Loss 1.6053404 Test MSE 1.8718447923595802 Test RE 0.6539476418539945\n",
      "55 Train Loss 1.5456632 Test MSE 1.7554399961840599 Test RE 0.6332877026440603\n",
      "56 Train Loss 1.4494039 Test MSE 1.7750983709106511 Test RE 0.6368237810583945\n",
      "57 Train Loss 1.3347542 Test MSE 1.6618994581931468 Test RE 0.6161840230981052\n",
      "58 Train Loss 1.2615376 Test MSE 1.5058617705012949 Test RE 0.5865440238784831\n",
      "59 Train Loss 1.2118392 Test MSE 1.3208209687213353 Test RE 0.5493258517292915\n",
      "60 Train Loss 1.1564084 Test MSE 1.3298548340375091 Test RE 0.5512012305096146\n",
      "61 Train Loss 1.0952368 Test MSE 1.2951796853910622 Test RE 0.5439676493658478\n",
      "62 Train Loss 1.0516357 Test MSE 1.236106642816506 Test RE 0.531417718381493\n",
      "63 Train Loss 0.9983617 Test MSE 1.1710338506768403 Test RE 0.517240812102107\n",
      "64 Train Loss 0.9539563 Test MSE 1.139563130920983 Test RE 0.5102432347384719\n",
      "65 Train Loss 0.9167757 Test MSE 1.0452019787903877 Test RE 0.4886615541696429\n",
      "66 Train Loss 0.87649184 Test MSE 0.8978636044602571 Test RE 0.4529113914449025\n",
      "67 Train Loss 0.83057314 Test MSE 0.7386881888902737 Test RE 0.4108077591742021\n",
      "68 Train Loss 0.64455664 Test MSE 0.2600880370311706 Test RE 0.2437632596570019\n",
      "69 Train Loss 0.49247938 Test MSE 0.11590784108743402 Test RE 0.16272881752107068\n",
      "70 Train Loss 0.4014007 Test MSE 0.07172096613028142 Test RE 0.12800623554285856\n",
      "71 Train Loss 0.30608836 Test MSE 0.06856342569748862 Test RE 0.12515676078661328\n",
      "72 Train Loss 0.245286 Test MSE 0.05865940711836089 Test RE 0.1157648983769334\n",
      "73 Train Loss 0.21464233 Test MSE 0.05456776804636927 Test RE 0.11165448056862155\n",
      "74 Train Loss 0.18823087 Test MSE 0.061840588509226004 Test RE 0.11886250186973182\n",
      "75 Train Loss 0.16827673 Test MSE 0.05663222770787408 Test RE 0.11374698213594135\n",
      "76 Train Loss 0.15108415 Test MSE 0.044319880868620924 Test RE 0.10062533806483936\n",
      "77 Train Loss 0.13677923 Test MSE 0.03825129650209829 Test RE 0.09348267693865543\n",
      "78 Train Loss 0.12584 Test MSE 0.03756692663538126 Test RE 0.09264263384892321\n",
      "79 Train Loss 0.11562045 Test MSE 0.0369989861182355 Test RE 0.09193967662998441\n",
      "80 Train Loss 0.10542613 Test MSE 0.035836437531782894 Test RE 0.09048372589110824\n",
      "81 Train Loss 0.09264387 Test MSE 0.03290202190856672 Test RE 0.0867000511882025\n",
      "82 Train Loss 0.084842384 Test MSE 0.030999956089365923 Test RE 0.0841566810621501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 Train Loss 0.078689225 Test MSE 0.03475032322415981 Test RE 0.08910200658769397\n",
      "84 Train Loss 0.07133535 Test MSE 0.035228413020928516 Test RE 0.08971283892995313\n",
      "85 Train Loss 0.066445746 Test MSE 0.03436144770991267 Test RE 0.08860205336882769\n",
      "86 Train Loss 0.062252484 Test MSE 0.03845308761824211 Test RE 0.09372893212566734\n",
      "87 Train Loss 0.057078764 Test MSE 0.037652205245602755 Test RE 0.09274772571117096\n",
      "88 Train Loss 0.051548183 Test MSE 0.03271589093426655 Test RE 0.08645446669341245\n",
      "89 Train Loss 0.04860953 Test MSE 0.03215769674950076 Test RE 0.0857137563124772\n",
      "90 Train Loss 0.04603374 Test MSE 0.03143641581467177 Test RE 0.08474704668557681\n",
      "91 Train Loss 0.04361316 Test MSE 0.030973255268526685 Test RE 0.08412043042163028\n",
      "92 Train Loss 0.04188542 Test MSE 0.028245331014629203 Test RE 0.08033067100160744\n",
      "93 Train Loss 0.04052292 Test MSE 0.02864302959534989 Test RE 0.08089422825964399\n",
      "94 Train Loss 0.03815218 Test MSE 0.026736026627347927 Test RE 0.0781549505829246\n",
      "95 Train Loss 0.0365456 Test MSE 0.027362013053319974 Test RE 0.07906460091732394\n",
      "96 Train Loss 0.035243735 Test MSE 0.026529155326703645 Test RE 0.07785199956309097\n",
      "97 Train Loss 0.033817936 Test MSE 0.026114906519825738 Test RE 0.07724178440043247\n",
      "98 Train Loss 0.0327215 Test MSE 0.026061321361949642 Test RE 0.07716249752649242\n",
      "99 Train Loss 0.031041233 Test MSE 0.022333116253307108 Test RE 0.07143034103102627\n",
      "100 Train Loss 0.030031996 Test MSE 0.02381810290419217 Test RE 0.07376691884991717\n",
      "101 Train Loss 0.028275568 Test MSE 0.021497479621956778 Test RE 0.07008124899210746\n",
      "102 Train Loss 0.026620705 Test MSE 0.02146339691354877 Test RE 0.07002567256432232\n",
      "103 Train Loss 0.025300257 Test MSE 0.020127221532183024 Test RE 0.06781097263386433\n",
      "104 Train Loss 0.024160782 Test MSE 0.01863304577080203 Test RE 0.06524541317067747\n",
      "105 Train Loss 0.023246452 Test MSE 0.017554270355321706 Test RE 0.0633285364815189\n",
      "106 Train Loss 0.022097085 Test MSE 0.016679420579225106 Test RE 0.06173032168739288\n",
      "107 Train Loss 0.020492598 Test MSE 0.015475089585023393 Test RE 0.05945996458397973\n",
      "108 Train Loss 0.019114748 Test MSE 0.014101175865019067 Test RE 0.0567591293173536\n",
      "109 Train Loss 0.018366791 Test MSE 0.013251805736919737 Test RE 0.05502316788144405\n",
      "110 Train Loss 0.017328253 Test MSE 0.011719693307103396 Test RE 0.05174473696905109\n",
      "111 Train Loss 0.016634125 Test MSE 0.010537134817234043 Test RE 0.049064720432930045\n",
      "112 Train Loss 0.0151968375 Test MSE 0.010518291384287292 Test RE 0.04902082987373074\n",
      "113 Train Loss 0.014681987 Test MSE 0.00942208495904847 Test RE 0.04639610987525411\n",
      "114 Train Loss 0.014269657 Test MSE 0.009604319605184519 Test RE 0.046842639859717566\n",
      "115 Train Loss 0.013588721 Test MSE 0.009068386889239338 Test RE 0.045516942381960586\n",
      "116 Train Loss 0.013181622 Test MSE 0.008640376156283554 Test RE 0.04442980275109404\n",
      "117 Train Loss 0.01275024 Test MSE 0.008114111495791027 Test RE 0.0430554909561697\n",
      "118 Train Loss 0.012193672 Test MSE 0.007347164711438461 Test RE 0.04097018720165063\n",
      "119 Train Loss 0.011338385 Test MSE 0.006157145235168929 Test RE 0.03750574177649474\n",
      "120 Train Loss 0.010663243 Test MSE 0.006776519894772405 Test RE 0.03934698131964589\n",
      "121 Train Loss 0.010291665 Test MSE 0.006032163566287466 Test RE 0.03712313245219699\n",
      "122 Train Loss 0.010066906 Test MSE 0.005709386136710854 Test RE 0.036116259794280896\n",
      "123 Train Loss 0.00977428 Test MSE 0.005071154478115229 Test RE 0.03403779986678073\n",
      "124 Train Loss 0.009539376 Test MSE 0.004664300644984875 Test RE 0.032643846587124575\n",
      "125 Train Loss 0.009200336 Test MSE 0.004318331256904367 Test RE 0.03140986263995194\n",
      "126 Train Loss 0.008770657 Test MSE 0.00375896675393925 Test RE 0.0293050389260151\n",
      "127 Train Loss 0.008469284 Test MSE 0.0033134797079391533 Test RE 0.027513777312320766\n",
      "128 Train Loss 0.007995547 Test MSE 0.003724550472124555 Test RE 0.02917057515756131\n",
      "129 Train Loss 0.0076613813 Test MSE 0.003534541334273668 Test RE 0.028416762180951172\n",
      "130 Train Loss 0.007329903 Test MSE 0.0031233015994856918 Test RE 0.0267125299487938\n",
      "131 Train Loss 0.006886069 Test MSE 0.003061725401973218 Test RE 0.02644789907551966\n",
      "132 Train Loss 0.0066299746 Test MSE 0.002958273031230522 Test RE 0.025997236645177065\n",
      "133 Train Loss 0.006239416 Test MSE 0.0027144809635200337 Test RE 0.02490298806504973\n",
      "134 Train Loss 0.005868911 Test MSE 0.0026720798889955932 Test RE 0.024707726168320402\n",
      "135 Train Loss 0.005468962 Test MSE 0.0022489050205313998 Test RE 0.022666977695324397\n",
      "136 Train Loss 0.0051931604 Test MSE 0.002266374581362097 Test RE 0.022754846261185162\n",
      "137 Train Loss 0.0050408207 Test MSE 0.002157497541851705 Test RE 0.02220154587514384\n",
      "138 Train Loss 0.0047789644 Test MSE 0.0018351220114197798 Test RE 0.020475783668687474\n",
      "139 Train Loss 0.004611129 Test MSE 0.0016949710607815011 Test RE 0.019678373716598828\n",
      "140 Train Loss 0.0043482548 Test MSE 0.0015757670247285843 Test RE 0.018973788895807694\n",
      "141 Train Loss 0.004154707 Test MSE 0.0014522712710735148 Test RE 0.018215115667022302\n",
      "142 Train Loss 0.0040001594 Test MSE 0.001506340023770531 Test RE 0.018551095794747872\n",
      "143 Train Loss 0.0037271334 Test MSE 0.001316621749324317 Test RE 0.017343573004870213\n",
      "144 Train Loss 0.0034667237 Test MSE 0.0011451359131767506 Test RE 0.016174712790891586\n",
      "145 Train Loss 0.0032693988 Test MSE 0.001113103107242857 Test RE 0.015946881161943722\n",
      "146 Train Loss 0.003148854 Test MSE 0.0010307793220047455 Test RE 0.01534584859907016\n",
      "147 Train Loss 0.0030884084 Test MSE 0.0010038507335473068 Test RE 0.015144070775281444\n",
      "148 Train Loss 0.002947262 Test MSE 0.0009591013700529183 Test RE 0.014802678813023384\n",
      "149 Train Loss 0.0028533796 Test MSE 0.0009336559819901656 Test RE 0.01460499801663124\n",
      "150 Train Loss 0.0028127676 Test MSE 0.0008945388965946642 Test RE 0.014295774037754483\n",
      "151 Train Loss 0.0027366672 Test MSE 0.0008910686264028168 Test RE 0.014268017611146624\n",
      "152 Train Loss 0.0025967725 Test MSE 0.0008587507993025432 Test RE 0.014006887400482953\n",
      "153 Train Loss 0.0024868706 Test MSE 0.000806417177956274 Test RE 0.013573378052811138\n",
      "154 Train Loss 0.0024088952 Test MSE 0.0007665469531151868 Test RE 0.013233582864929181\n",
      "155 Train Loss 0.0023435787 Test MSE 0.000735490369809951 Test RE 0.012962732398866604\n",
      "156 Train Loss 0.0023096073 Test MSE 0.000715779632940102 Test RE 0.012787855747709128\n",
      "157 Train Loss 0.0022756022 Test MSE 0.0007206323626355083 Test RE 0.012831131066070403\n",
      "158 Train Loss 0.0022326643 Test MSE 0.0007364287117021064 Test RE 0.012970998719042042\n",
      "159 Train Loss 0.0021881133 Test MSE 0.0007442454381270875 Test RE 0.013039656496513572\n",
      "160 Train Loss 0.0021303068 Test MSE 0.0007646680723290871 Test RE 0.013217354518189912\n",
      "161 Train Loss 0.002030897 Test MSE 0.0007159264359891081 Test RE 0.01278916704512619\n",
      "162 Train Loss 0.0019206252 Test MSE 0.0006742919090448925 Test RE 0.01241172185506715\n",
      "163 Train Loss 0.0018540539 Test MSE 0.0006360584060503927 Test RE 0.012054704213723231\n",
      "164 Train Loss 0.0018101058 Test MSE 0.0006110585871668168 Test RE 0.0118154287621522\n",
      "165 Train Loss 0.001721494 Test MSE 0.0005640952789295308 Test RE 0.01135231132786933\n",
      "166 Train Loss 0.0016362572 Test MSE 0.0005626374939827263 Test RE 0.011337633014633057\n",
      "167 Train Loss 0.001592467 Test MSE 0.0005525785201441207 Test RE 0.01123582741664736\n",
      "168 Train Loss 0.001546446 Test MSE 0.0005671324724901714 Test RE 0.011382831775491889\n",
      "169 Train Loss 0.0014674956 Test MSE 0.000527491712160764 Test RE 0.010977814312871917\n",
      "170 Train Loss 0.0014054461 Test MSE 0.00048642523645850677 Test RE 0.01054183245700111\n",
      "171 Train Loss 0.0013459503 Test MSE 0.00046795590278679426 Test RE 0.010339761592516754\n",
      "172 Train Loss 0.001305768 Test MSE 0.00043018577047537206 Test RE 0.009913707035162866\n",
      "173 Train Loss 0.0012893172 Test MSE 0.00043211004965264537 Test RE 0.00993585497181643\n",
      "174 Train Loss 0.0012586385 Test MSE 0.0004106365081834382 Test RE 0.009685829935836963\n",
      "175 Train Loss 0.0012417578 Test MSE 0.0003842078285698807 Test RE 0.009368955262237032\n",
      "176 Train Loss 0.0012311417 Test MSE 0.00038087871805591797 Test RE 0.009328276566491472\n",
      "177 Train Loss 0.0012226297 Test MSE 0.00038513919784504704 Test RE 0.009380304165892951\n",
      "178 Train Loss 0.0012078512 Test MSE 0.0003818522563331687 Test RE 0.00934019064591227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 Train Loss 0.0011967182 Test MSE 0.0003735756090753903 Test RE 0.009238411799208259\n",
      "180 Train Loss 0.0011716817 Test MSE 0.00033986359955525964 Test RE 0.008811713873674916\n",
      "181 Train Loss 0.0011533669 Test MSE 0.00033183849077411123 Test RE 0.008707058052448938\n",
      "182 Train Loss 0.0011083912 Test MSE 0.000331587380171125 Test RE 0.008703763003128572\n",
      "183 Train Loss 0.0010895303 Test MSE 0.00032099394760812315 Test RE 0.008563602143042012\n",
      "184 Train Loss 0.0010625337 Test MSE 0.0003192596384416435 Test RE 0.008540436520779624\n",
      "185 Train Loss 0.001049041 Test MSE 0.0003280640924735843 Test RE 0.00865739851703973\n",
      "186 Train Loss 0.0010412491 Test MSE 0.0003175607318059015 Test RE 0.008517682691880834\n",
      "187 Train Loss 0.0010259671 Test MSE 0.00030984556634903614 Test RE 0.008413577574281303\n",
      "188 Train Loss 0.0009909129 Test MSE 0.0002839758642991873 Test RE 0.008054688977331456\n",
      "189 Train Loss 0.00096142804 Test MSE 0.0002823603645949003 Test RE 0.008031745290046632\n",
      "190 Train Loss 0.0009439732 Test MSE 0.0002707738362775646 Test RE 0.007865229678173874\n",
      "191 Train Loss 0.000920907 Test MSE 0.0002635944572104957 Test RE 0.007760258660921342\n",
      "192 Train Loss 0.00090429594 Test MSE 0.0002469696987496654 Test RE 0.007511555774097835\n",
      "193 Train Loss 0.00089224044 Test MSE 0.0002486338082067707 Test RE 0.007536820138557807\n",
      "194 Train Loss 0.00088422804 Test MSE 0.0002497248047973314 Test RE 0.007553337692423856\n",
      "195 Train Loss 0.0008751237 Test MSE 0.00024882731521041606 Test RE 0.007539752450611953\n",
      "196 Train Loss 0.0008668458 Test MSE 0.0002541935832684547 Test RE 0.007620620802018891\n",
      "197 Train Loss 0.00086203637 Test MSE 0.0002547109425655931 Test RE 0.007628371971266905\n",
      "198 Train Loss 0.000856144 Test MSE 0.00025436892659304756 Test RE 0.0076232487098841836\n",
      "199 Train Loss 0.0008472395 Test MSE 0.00024423430217478055 Test RE 0.007469841557007549\n",
      "Training time: 282.22\n",
      "KG_atanh\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 52.05397 Test MSE 8.481854951021303 Test RE 1.3920456608646974\n",
      "1 Train Loss 46.752014 Test MSE 7.785510112003164 Test RE 1.3336798720604284\n",
      "2 Train Loss 38.29451 Test MSE 7.946292543727008 Test RE 1.3473807400214803\n",
      "3 Train Loss 35.758163 Test MSE 7.620300257451247 Test RE 1.3194535387139068\n",
      "4 Train Loss 33.255867 Test MSE 7.347901351256262 Test RE 1.29565602471336\n",
      "5 Train Loss 29.197826 Test MSE 6.7220133280392895 Test RE 1.2392466252449668\n",
      "6 Train Loss 26.424343 Test MSE 6.021305974168681 Test RE 1.1728795349883\n",
      "7 Train Loss 24.557991 Test MSE 6.374396617247405 Test RE 1.2067786030324\n",
      "8 Train Loss 23.504536 Test MSE 6.2434799643287535 Test RE 1.1943219702288488\n",
      "9 Train Loss 22.88633 Test MSE 6.238114674638789 Test RE 1.1938086939290973\n",
      "10 Train Loss 20.984642 Test MSE 6.033773991489394 Test RE 1.174093218549546\n",
      "11 Train Loss 19.268211 Test MSE 6.016750408864613 Test RE 1.1724357657844582\n",
      "12 Train Loss 18.26448 Test MSE 6.037886768849248 Test RE 1.1744932966299098\n",
      "13 Train Loss 15.525943 Test MSE 5.049055597190416 Test RE 1.074021899351816\n",
      "14 Train Loss 10.98592 Test MSE 3.7535739216355606 Test RE 0.9260417070051034\n",
      "15 Train Loss 7.341481 Test MSE 2.637651316193311 Test RE 0.7762770593923888\n",
      "16 Train Loss 6.0479 Test MSE 2.407262076275607 Test RE 0.7416000446984266\n",
      "17 Train Loss 5.361908 Test MSE 2.3332387891750885 Test RE 0.7301089196181658\n",
      "18 Train Loss 5.01238 Test MSE 2.3224274612410265 Test RE 0.7284154341427835\n",
      "19 Train Loss 4.7425056 Test MSE 2.262601814875175 Test RE 0.7189722458715221\n",
      "20 Train Loss 4.534495 Test MSE 2.1996254474549484 Test RE 0.7088958402889215\n",
      "21 Train Loss 4.412658 Test MSE 2.175270613864532 Test RE 0.7049603754044013\n",
      "22 Train Loss 4.323594 Test MSE 2.1652942125362613 Test RE 0.7033419445949336\n",
      "23 Train Loss 4.15829 Test MSE 2.1238153509322855 Test RE 0.6965726814315234\n",
      "24 Train Loss 3.978066 Test MSE 2.148230691828939 Test RE 0.7005651330845942\n",
      "25 Train Loss 3.3798058 Test MSE 2.134211650547023 Test RE 0.6982754983935978\n",
      "26 Train Loss 2.393633 Test MSE 1.941477218424114 Test RE 0.6659999701394642\n",
      "27 Train Loss 1.4057709 Test MSE 1.3773747538735426 Test RE 0.5609628740758433\n",
      "28 Train Loss 0.8369838 Test MSE 0.44642555194767747 Test RE 0.3193615168874673\n",
      "29 Train Loss 0.5656507 Test MSE 0.30324164256037367 Test RE 0.26321005775983897\n",
      "30 Train Loss 0.38856634 Test MSE 0.20688077402469635 Test RE 0.21740429840738792\n",
      "31 Train Loss 0.2802824 Test MSE 0.17496682975194663 Test RE 0.19993366249423014\n",
      "32 Train Loss 0.19625351 Test MSE 0.07766878689668512 Test RE 0.13320831085538962\n",
      "33 Train Loss 0.14560343 Test MSE 0.048566399349364596 Test RE 0.10533580379044527\n",
      "34 Train Loss 0.10954734 Test MSE 0.0419587229152895 Test RE 0.09790822808403113\n",
      "35 Train Loss 0.088719174 Test MSE 0.032755116613746374 Test RE 0.08650627972993594\n",
      "36 Train Loss 0.07109633 Test MSE 0.02263192228525066 Test RE 0.07190660457033174\n",
      "37 Train Loss 0.060574695 Test MSE 0.021156061117889466 Test RE 0.06952251376749918\n",
      "38 Train Loss 0.05295067 Test MSE 0.022941799442971124 Test RE 0.07239720495914238\n",
      "39 Train Loss 0.04749607 Test MSE 0.019794839538515616 Test RE 0.06724872474069936\n",
      "40 Train Loss 0.038325306 Test MSE 0.017736848615389853 Test RE 0.06365701794363071\n",
      "41 Train Loss 0.0339615 Test MSE 0.017154562255912543 Test RE 0.06260339423552694\n",
      "42 Train Loss 0.028559081 Test MSE 0.017177520167783875 Test RE 0.0626452712197058\n",
      "43 Train Loss 0.02535648 Test MSE 0.01743742077577502 Test RE 0.06311741211681729\n",
      "44 Train Loss 0.022170816 Test MSE 0.016362368525250758 Test RE 0.06114080397998133\n",
      "45 Train Loss 0.019008812 Test MSE 0.01491762530671746 Test RE 0.05837916884466751\n",
      "46 Train Loss 0.017460946 Test MSE 0.011919714661843352 Test RE 0.05218443550110797\n",
      "47 Train Loss 0.014820026 Test MSE 0.010484784699672895 Test RE 0.04894268811068152\n",
      "48 Train Loss 0.012836583 Test MSE 0.008800772524617338 Test RE 0.044840294698995295\n",
      "49 Train Loss 0.010406845 Test MSE 0.006934001791957641 Test RE 0.03980155456715443\n",
      "50 Train Loss 0.009218077 Test MSE 0.00568233329426348 Test RE 0.03603059317432628\n",
      "51 Train Loss 0.008153202 Test MSE 0.00423188237203277 Test RE 0.03109387541499654\n",
      "52 Train Loss 0.0068599866 Test MSE 0.004724055994934597 Test RE 0.03285228476420501\n",
      "53 Train Loss 0.005900331 Test MSE 0.003785219270304624 Test RE 0.029407193652038956\n",
      "54 Train Loss 0.005473012 Test MSE 0.003262561787470617 Test RE 0.027301558097642984\n",
      "55 Train Loss 0.0051220856 Test MSE 0.0035621648353249607 Test RE 0.028527588827890245\n",
      "56 Train Loss 0.0048257117 Test MSE 0.0029956600687170982 Test RE 0.02616099907790205\n",
      "57 Train Loss 0.0045400243 Test MSE 0.003030140357040638 Test RE 0.02631112592257518\n",
      "58 Train Loss 0.0043174378 Test MSE 0.002814552835718704 Test RE 0.025357869540175475\n",
      "59 Train Loss 0.0040964643 Test MSE 0.0028582521466295856 Test RE 0.025553966989939288\n",
      "60 Train Loss 0.0038905237 Test MSE 0.0028157089012552953 Test RE 0.025363076823729232\n",
      "61 Train Loss 0.0035564448 Test MSE 0.002477064841686801 Test RE 0.02378903075991554\n",
      "62 Train Loss 0.003452345 Test MSE 0.002421982363726155 Test RE 0.02352304549218935\n",
      "63 Train Loss 0.003155574 Test MSE 0.002326798536509138 Test RE 0.023056185162127703\n",
      "64 Train Loss 0.002885492 Test MSE 0.0021103203853572883 Test RE 0.02195746794271907\n",
      "65 Train Loss 0.0027701485 Test MSE 0.0019909590996115426 Test RE 0.021327464585159293\n",
      "66 Train Loss 0.0026177382 Test MSE 0.0018953259802619224 Test RE 0.020808942883949605\n",
      "67 Train Loss 0.0024461069 Test MSE 0.0016252136796336852 Test RE 0.019269182716489246\n",
      "68 Train Loss 0.002310364 Test MSE 0.001486040657225589 Test RE 0.01842567497781568\n",
      "69 Train Loss 0.0021946216 Test MSE 0.0014519455113173251 Test RE 0.0182130726312118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 0.002044197 Test MSE 0.0015148547824816395 Test RE 0.018603453002166835\n",
      "71 Train Loss 0.0019463106 Test MSE 0.0013874788467875296 Test RE 0.01780415004358206\n",
      "72 Train Loss 0.0018820999 Test MSE 0.0013957443274226818 Test RE 0.017857102686132317\n",
      "73 Train Loss 0.0017873852 Test MSE 0.0014711410168387297 Test RE 0.018333070662716996\n",
      "74 Train Loss 0.0017027572 Test MSE 0.0014275316667806354 Test RE 0.018059300965312674\n",
      "75 Train Loss 0.0016491795 Test MSE 0.0013413019299697972 Test RE 0.017505371629020022\n",
      "76 Train Loss 0.0016082758 Test MSE 0.001318629672129426 Test RE 0.017356792932512948\n",
      "77 Train Loss 0.0015822202 Test MSE 0.0012787227724047059 Test RE 0.017092132860526004\n",
      "78 Train Loss 0.0015076357 Test MSE 0.001205244439849604 Test RE 0.016593791488137506\n",
      "79 Train Loss 0.0014337676 Test MSE 0.0010981579676565486 Test RE 0.015839463546463727\n",
      "80 Train Loss 0.0013899364 Test MSE 0.0010656470019972531 Test RE 0.015603238397782833\n",
      "81 Train Loss 0.0013498554 Test MSE 0.0010333139186945127 Test RE 0.01536470406861486\n",
      "82 Train Loss 0.0013122716 Test MSE 0.0010275500422669047 Test RE 0.015321791601252873\n",
      "83 Train Loss 0.001280633 Test MSE 0.0010238929840327203 Test RE 0.01529450211367026\n",
      "84 Train Loss 0.0012569515 Test MSE 0.000994465523234422 Test RE 0.01507311199229345\n",
      "85 Train Loss 0.0012201393 Test MSE 0.0009620517422393239 Test RE 0.014825429211425422\n",
      "86 Train Loss 0.001174265 Test MSE 0.0009727492601290731 Test RE 0.014907626897421835\n",
      "87 Train Loss 0.0011089905 Test MSE 0.0009302662705613774 Test RE 0.014578461612472535\n",
      "88 Train Loss 0.0010798182 Test MSE 0.0009410557461358898 Test RE 0.014662760324593793\n",
      "89 Train Loss 0.0010417526 Test MSE 0.0009569018938839257 Test RE 0.014785695818383965\n",
      "90 Train Loss 0.0010154345 Test MSE 0.0009327029906216148 Test RE 0.0145975423847928\n",
      "91 Train Loss 0.0009916255 Test MSE 0.000943353410642791 Test RE 0.01468064957551767\n",
      "92 Train Loss 0.00096701935 Test MSE 0.0008704156637561922 Test RE 0.014101697985788243\n",
      "93 Train Loss 0.00092729914 Test MSE 0.0007423518668792343 Test RE 0.01302305764153633\n",
      "94 Train Loss 0.00089345966 Test MSE 0.0007489083200797804 Test RE 0.013080441053274624\n",
      "95 Train Loss 0.0008513116 Test MSE 0.0007125545647369149 Test RE 0.012759014282116064\n",
      "96 Train Loss 0.0008169881 Test MSE 0.0007328478812373249 Test RE 0.01293942502729339\n",
      "97 Train Loss 0.0007956432 Test MSE 0.0007542244784754556 Test RE 0.013126784995938234\n",
      "98 Train Loss 0.00077837845 Test MSE 0.0007632819559683197 Test RE 0.01320536951313973\n",
      "99 Train Loss 0.0007594586 Test MSE 0.0007286172500253715 Test RE 0.012902022197801778\n",
      "100 Train Loss 0.0007429561 Test MSE 0.0007726500143818434 Test RE 0.013286159712892081\n",
      "101 Train Loss 0.0007127146 Test MSE 0.0007058582175023982 Test RE 0.01269892030879383\n",
      "102 Train Loss 0.00068745593 Test MSE 0.0006699893352753372 Test RE 0.012372059648310627\n",
      "103 Train Loss 0.00066754903 Test MSE 0.0006617880216299887 Test RE 0.012296103535833408\n",
      "104 Train Loss 0.00065091264 Test MSE 0.0006341378107310512 Test RE 0.012036490703861114\n",
      "105 Train Loss 0.0006168599 Test MSE 0.000606476541932471 Test RE 0.011771046191481126\n",
      "106 Train Loss 0.0005971966 Test MSE 0.0006108397782537143 Test RE 0.011813313128185099\n",
      "107 Train Loss 0.00058136636 Test MSE 0.0005948109440447635 Test RE 0.011657288254425488\n",
      "108 Train Loss 0.00055793853 Test MSE 0.0006020443281837988 Test RE 0.011727955108223803\n",
      "109 Train Loss 0.0005303674 Test MSE 0.0005600602938836283 Test RE 0.01131163680356511\n",
      "110 Train Loss 0.000514538 Test MSE 0.0005135695817894436 Test RE 0.010831976441109776\n",
      "111 Train Loss 0.00050050736 Test MSE 0.0004992565594191284 Test RE 0.010679967965514833\n",
      "112 Train Loss 0.0004802066 Test MSE 0.0004860007919777357 Test RE 0.01053723216206767\n",
      "113 Train Loss 0.0004664125 Test MSE 0.0004415660651056623 Test RE 0.010043981526234846\n",
      "114 Train Loss 0.00044956268 Test MSE 0.00044082927405228163 Test RE 0.010035598403177755\n",
      "115 Train Loss 0.00043968888 Test MSE 0.00044948024875248523 Test RE 0.010133590876825051\n",
      "116 Train Loss 0.000433563 Test MSE 0.00044479598418723865 Test RE 0.010080648903675687\n",
      "117 Train Loss 0.0004231861 Test MSE 0.00041798188055122 Test RE 0.009772074923006564\n",
      "118 Train Loss 0.0004111555 Test MSE 0.00040685856200016566 Test RE 0.009641171097936592\n",
      "119 Train Loss 0.00040388916 Test MSE 0.00039776955064165745 Test RE 0.009532873447450237\n",
      "120 Train Loss 0.00039548476 Test MSE 0.00037595735219232007 Test RE 0.009267814901946725\n",
      "121 Train Loss 0.0003880942 Test MSE 0.0003413515644185307 Test RE 0.008830982193393727\n",
      "122 Train Loss 0.00037705127 Test MSE 0.000338059076144039 Test RE 0.008788289613264513\n",
      "123 Train Loss 0.0003649669 Test MSE 0.0003372808545064948 Test RE 0.008778168338340013\n",
      "124 Train Loss 0.0003569327 Test MSE 0.00035027872108448215 Test RE 0.008945712528642782\n",
      "125 Train Loss 0.00034713335 Test MSE 0.0003421465478086232 Test RE 0.00884125957614919\n",
      "126 Train Loss 0.00034148069 Test MSE 0.00033286862305477775 Test RE 0.008720562319762001\n",
      "127 Train Loss 0.00033498413 Test MSE 0.00033290405571549143 Test RE 0.00872102644356664\n",
      "128 Train Loss 0.00032625746 Test MSE 0.00031991805703643583 Test RE 0.008549238582343577\n",
      "129 Train Loss 0.00032165032 Test MSE 0.00032501388585765836 Test RE 0.008617058044091127\n",
      "130 Train Loss 0.0003172456 Test MSE 0.00031465120744961407 Test RE 0.008478572957826905\n",
      "131 Train Loss 0.00031417445 Test MSE 0.00031903624801273884 Test RE 0.008537448066552883\n",
      "132 Train Loss 0.00030966895 Test MSE 0.00029925588932874564 Test RE 0.008268551073263814\n",
      "133 Train Loss 0.00030403622 Test MSE 0.0002821214099439469 Test RE 0.008028346036198092\n",
      "134 Train Loss 0.0002985652 Test MSE 0.0002814154516116564 Test RE 0.008018294995034217\n",
      "135 Train Loss 0.00029381635 Test MSE 0.00026480786014893855 Test RE 0.007778099531149827\n",
      "136 Train Loss 0.00028811092 Test MSE 0.0002525027515345903 Test RE 0.0075952332880308854\n",
      "137 Train Loss 0.00027935405 Test MSE 0.0002320482522201195 Test RE 0.007281103610295922\n",
      "138 Train Loss 0.00027157576 Test MSE 0.0002106062316447545 Test RE 0.006936552362008588\n",
      "139 Train Loss 0.00026749485 Test MSE 0.0002131989891714023 Test RE 0.00697911944074559\n",
      "140 Train Loss 0.00026550947 Test MSE 0.0002135720374158068 Test RE 0.006985222683449823\n",
      "141 Train Loss 0.00026364488 Test MSE 0.0002048747095308221 Test RE 0.006841514247207205\n",
      "142 Train Loss 0.0002599857 Test MSE 0.000204132116947069 Test RE 0.00682910405320304\n",
      "143 Train Loss 0.00025554872 Test MSE 0.00022317504884542607 Test RE 0.007140537093001213\n",
      "144 Train Loss 0.00025132432 Test MSE 0.0002258884828165621 Test RE 0.007183814417977274\n",
      "145 Train Loss 0.00024749496 Test MSE 0.00021552772283909484 Test RE 0.007017131746557747\n",
      "146 Train Loss 0.00024069421 Test MSE 0.00020478682388907064 Test RE 0.006840046678644046\n",
      "147 Train Loss 0.00023815037 Test MSE 0.00019279903742286917 Test RE 0.006636826904480713\n",
      "148 Train Loss 0.00023462303 Test MSE 0.00019028917677410464 Test RE 0.006593486235887611\n",
      "149 Train Loss 0.00023247697 Test MSE 0.0001839804153472196 Test RE 0.006483266257610127\n",
      "150 Train Loss 0.00022870033 Test MSE 0.00019146998613350712 Test RE 0.0066139120151280035\n",
      "151 Train Loss 0.00022466721 Test MSE 0.00018938322777072657 Test RE 0.0065777720239305\n",
      "152 Train Loss 0.0002204992 Test MSE 0.0001772763133146086 Test RE 0.006364047551635923\n",
      "153 Train Loss 0.00021640689 Test MSE 0.00017324982538639928 Test RE 0.0062913589317791525\n",
      "154 Train Loss 0.00021218494 Test MSE 0.00018039320707846087 Test RE 0.006419750504620048\n",
      "155 Train Loss 0.00020874522 Test MSE 0.0001787711456293129 Test RE 0.006390822741044227\n",
      "156 Train Loss 0.00020617194 Test MSE 0.00017455200558065615 Test RE 0.00631495822394686\n",
      "157 Train Loss 0.00020446285 Test MSE 0.00017363070361059769 Test RE 0.006298270702292022\n",
      "158 Train Loss 0.00020216452 Test MSE 0.00017212691102761447 Test RE 0.006270937145312282\n",
      "159 Train Loss 0.00019977742 Test MSE 0.00016267660687525396 Test RE 0.006096360112698271\n",
      "160 Train Loss 0.00019670214 Test MSE 0.00016185851035568696 Test RE 0.006081011571523669\n",
      "161 Train Loss 0.0001944191 Test MSE 0.00015505213197851078 Test RE 0.00595178084540406\n",
      "162 Train Loss 0.00019229902 Test MSE 0.00015249710266928784 Test RE 0.005902538880940765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 Train Loss 0.00019043533 Test MSE 0.0001448251899519163 Test RE 0.005752148820754158\n",
      "164 Train Loss 0.00018869172 Test MSE 0.00013501502840467246 Test RE 0.005553913561886929\n",
      "165 Train Loss 0.00018692136 Test MSE 0.00012974104740987705 Test RE 0.005444359067189936\n",
      "166 Train Loss 0.00018494291 Test MSE 0.00012951291806015663 Test RE 0.005439570434090987\n",
      "167 Train Loss 0.00018233678 Test MSE 0.0001272222407473396 Test RE 0.005391251357615863\n",
      "168 Train Loss 0.00017940589 Test MSE 0.00012344710572028563 Test RE 0.005310660226400587\n",
      "169 Train Loss 0.00017681971 Test MSE 0.0001217200000033606 Test RE 0.005273379567606596\n",
      "170 Train Loss 0.00017418715 Test MSE 0.0001211837143967671 Test RE 0.005261749763750128\n",
      "171 Train Loss 0.00017194488 Test MSE 0.00012156060653455576 Test RE 0.005269925666783506\n",
      "172 Train Loss 0.00016957917 Test MSE 0.00012233606530841294 Test RE 0.00528670788594551\n",
      "173 Train Loss 0.00016592293 Test MSE 0.00011662770063984766 Test RE 0.005161892038545475\n",
      "174 Train Loss 0.00016199096 Test MSE 0.00011349234016022417 Test RE 0.005092034480622192\n",
      "175 Train Loss 0.00015834002 Test MSE 0.0001135476870823328 Test RE 0.005093275948036922\n",
      "176 Train Loss 0.0001546009 Test MSE 0.00010342959388851484 Test RE 0.004861054273731319\n",
      "177 Train Loss 0.00015153326 Test MSE 9.953768887805301e-05 Test RE 0.004768720148599178\n",
      "178 Train Loss 0.00014908401 Test MSE 9.168617490844076e-05 Test RE 0.004576779479795859\n",
      "179 Train Loss 0.00014726246 Test MSE 9.413601992730364e-05 Test RE 0.00463752193151506\n",
      "180 Train Loss 0.00014458112 Test MSE 8.512650373435739e-05 Test RE 0.004410018980113652\n",
      "181 Train Loss 0.00014136244 Test MSE 7.749755504299746e-05 Test RE 0.004207770658658357\n",
      "182 Train Loss 0.00013862888 Test MSE 7.284290633940036e-05 Test RE 0.00407945073613997\n",
      "183 Train Loss 0.00013628141 Test MSE 6.811686502515518e-05 Test RE 0.003944894437383939\n",
      "184 Train Loss 0.00013470331 Test MSE 6.738877728279596e-05 Test RE 0.003923754696497785\n",
      "185 Train Loss 0.00013274525 Test MSE 6.215673820963332e-05 Test RE 0.003768358117340113\n",
      "186 Train Loss 0.00013157533 Test MSE 6.301951655320406e-05 Test RE 0.003794421687232282\n",
      "187 Train Loss 0.00012963117 Test MSE 5.893707462854892e-05 Test RE 0.003669461606887871\n",
      "188 Train Loss 0.0001284625 Test MSE 5.5888346220736695e-05 Test RE 0.003573293502200597\n",
      "189 Train Loss 0.00012694405 Test MSE 5.7937015158595974e-05 Test RE 0.003638196224603762\n",
      "190 Train Loss 0.00012532056 Test MSE 5.937953229554836e-05 Test RE 0.0036832097072366046\n",
      "191 Train Loss 0.00012341469 Test MSE 5.180962998487198e-05 Test RE 0.0034404345916283965\n",
      "192 Train Loss 0.00012201065 Test MSE 5.2663631232739724e-05 Test RE 0.0034686738065924923\n",
      "193 Train Loss 0.0001212356 Test MSE 5.242812482195399e-05 Test RE 0.003460909337880793\n",
      "194 Train Loss 0.0001199196 Test MSE 5.17651076720782e-05 Test RE 0.0034389560148948618\n",
      "195 Train Loss 0.00011842681 Test MSE 4.9431903832108754e-05 Test RE 0.0033605605815816525\n",
      "196 Train Loss 0.00011774908 Test MSE 5.073005932498952e-05 Test RE 0.0034044012819183724\n",
      "197 Train Loss 0.00011637618 Test MSE 4.9551165113706304e-05 Test RE 0.003364612047182278\n",
      "198 Train Loss 0.00011477141 Test MSE 4.494823953490163e-05 Test RE 0.0032045304566665016\n",
      "199 Train Loss 0.00011465295 Test MSE 4.43161313450682e-05 Test RE 0.00318191798020943\n",
      "Training time: 278.60\n",
      "KG_atanh\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 55.72149 Test MSE 8.648566758339637 Test RE 1.40565949755812\n",
      "1 Train Loss 43.97393 Test MSE 8.603307935530385 Test RE 1.4019766941004994\n",
      "2 Train Loss 43.721947 Test MSE 8.53363840557347 Test RE 1.3962885561338119\n",
      "3 Train Loss 42.782738 Test MSE 8.482357998315928 Test RE 1.3920869404211802\n",
      "4 Train Loss 42.32188 Test MSE 8.319571104552436 Test RE 1.3786642980000348\n",
      "5 Train Loss 41.871677 Test MSE 8.32915267332143 Test RE 1.3794579666527476\n",
      "6 Train Loss 41.423325 Test MSE 8.594431198454366 Test RE 1.4012532403791846\n",
      "7 Train Loss 40.624466 Test MSE 8.627267793875541 Test RE 1.4039275604564407\n",
      "8 Train Loss 39.79142 Test MSE 8.70637296146291 Test RE 1.4103493216636662\n",
      "9 Train Loss 38.067703 Test MSE 9.232217391407115 Test RE 1.4523158309938993\n",
      "10 Train Loss 34.74102 Test MSE 9.275996148763127 Test RE 1.455755166518495\n",
      "11 Train Loss 32.23227 Test MSE 8.784410174521817 Test RE 1.4166558632892965\n",
      "12 Train Loss 27.5811 Test MSE 7.733325081642145 Test RE 1.3292026353477038\n",
      "13 Train Loss 26.857346 Test MSE 7.7520216555546435 Test RE 1.3308084473706674\n",
      "14 Train Loss 25.828035 Test MSE 7.408400811308593 Test RE 1.300979027626153\n",
      "15 Train Loss 23.5807 Test MSE 6.340838813614889 Test RE 1.20359788796599\n",
      "16 Train Loss 19.366035 Test MSE 5.741644615781086 Test RE 1.1453183376657905\n",
      "17 Train Loss 16.762518 Test MSE 5.512863929736534 Test RE 1.1222683026809532\n",
      "18 Train Loss 15.928559 Test MSE 5.076912058843596 Test RE 1.076980600883673\n",
      "19 Train Loss 15.200556 Test MSE 4.876595145068348 Test RE 1.0555198651682176\n",
      "20 Train Loss 14.375524 Test MSE 5.019650762401643 Test RE 1.0708898728269738\n",
      "21 Train Loss 13.400935 Test MSE 4.269508464782923 Test RE 0.9876361998253729\n",
      "22 Train Loss 12.367953 Test MSE 4.2364339105409545 Test RE 0.9838033070958454\n",
      "23 Train Loss 11.695862 Test MSE 4.186553717483157 Test RE 0.9779944591208276\n",
      "24 Train Loss 9.807074 Test MSE 3.483485610022683 Test RE 0.8921031455680487\n",
      "25 Train Loss 7.3998632 Test MSE 3.3338789981126653 Test RE 0.8727361729953854\n",
      "26 Train Loss 6.4318147 Test MSE 3.2298555241591673 Test RE 0.8590127468813056\n",
      "27 Train Loss 5.777217 Test MSE 2.828894889181702 Test RE 0.8039267242896995\n",
      "28 Train Loss 5.4545817 Test MSE 2.7445477715381057 Test RE 0.7918509781563746\n",
      "29 Train Loss 5.110211 Test MSE 2.7298116307796323 Test RE 0.789722297253897\n",
      "30 Train Loss 4.9598546 Test MSE 2.789295736940815 Test RE 0.7982801712431602\n",
      "31 Train Loss 4.838587 Test MSE 2.7236371346259713 Test RE 0.7888286645835308\n",
      "32 Train Loss 4.6061106 Test MSE 2.71964190274747 Test RE 0.7882498962210828\n",
      "33 Train Loss 4.3942738 Test MSE 2.565298738300426 Test RE 0.7655561224374313\n",
      "34 Train Loss 4.2589707 Test MSE 2.4814166972508103 Test RE 0.7529357363250647\n",
      "35 Train Loss 4.0258255 Test MSE 2.658380398895795 Test RE 0.7793214381977711\n",
      "36 Train Loss 3.8416936 Test MSE 2.7275304359880854 Test RE 0.7893922585635168\n",
      "37 Train Loss 3.6007044 Test MSE 2.7582181711499287 Test RE 0.7938206056013931\n",
      "38 Train Loss 3.4284153 Test MSE 2.8193871915879307 Test RE 0.8025746193876292\n",
      "39 Train Loss 3.274948 Test MSE 2.7177721427069397 Test RE 0.78797888782834\n",
      "40 Train Loss 3.1891806 Test MSE 2.650519358215856 Test RE 0.7781683276024649\n",
      "41 Train Loss 3.0582018 Test MSE 2.6349931955665817 Test RE 0.7758858101442647\n",
      "42 Train Loss 2.8844557 Test MSE 2.5480793007651705 Test RE 0.7629824178985468\n",
      "43 Train Loss 2.7459972 Test MSE 2.482148364717593 Test RE 0.7530467329948545\n",
      "44 Train Loss 2.5904782 Test MSE 2.4677449326659997 Test RE 0.7508586610802411\n",
      "45 Train Loss 2.349041 Test MSE 2.33897571252192 Test RE 0.7310059575439324\n",
      "46 Train Loss 2.1852527 Test MSE 2.365404137066151 Test RE 0.7351242279580658\n",
      "47 Train Loss 1.9453577 Test MSE 2.421669366409762 Test RE 0.7438159455680778\n",
      "48 Train Loss 1.7690947 Test MSE 2.5195597142757684 Test RE 0.7587005312076888\n",
      "49 Train Loss 1.6616493 Test MSE 2.5550925996447997 Test RE 0.7640317076071163\n",
      "50 Train Loss 1.5271926 Test MSE 2.5717340937810547 Test RE 0.7665157650373812\n",
      "51 Train Loss 1.4621589 Test MSE 2.596532362623062 Test RE 0.7702025111258435\n",
      "52 Train Loss 1.3883629 Test MSE 2.6702912007678488 Test RE 0.7810653513627189\n",
      "53 Train Loss 1.3346682 Test MSE 2.7680570381478273 Test RE 0.7952351678702535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 1.2764099 Test MSE 2.8488865620434076 Test RE 0.8067623802355474\n",
      "55 Train Loss 1.2231048 Test MSE 2.9050704899036726 Test RE 0.8146787674429968\n",
      "56 Train Loss 1.1381028 Test MSE 2.982219992824876 Test RE 0.8254255332623912\n",
      "57 Train Loss 1.1026711 Test MSE 3.0086150774261857 Test RE 0.8290703315039332\n",
      "58 Train Loss 1.0558048 Test MSE 3.04569998887495 Test RE 0.8341643420146544\n",
      "59 Train Loss 1.0117784 Test MSE 3.103415775892478 Test RE 0.842030925075872\n",
      "60 Train Loss 0.94580406 Test MSE 3.1134355332336074 Test RE 0.8433891295826734\n",
      "61 Train Loss 0.90647274 Test MSE 3.093932734233146 Test RE 0.8407434527928788\n",
      "62 Train Loss 0.86806244 Test MSE 3.196254140985487 Test RE 0.8545327507858268\n",
      "63 Train Loss 0.8367845 Test MSE 3.220315598883489 Test RE 0.8577431889123622\n",
      "64 Train Loss 0.8014157 Test MSE 3.260896171025604 Test RE 0.8631306636971103\n",
      "65 Train Loss 0.7800534 Test MSE 3.25621204200437 Test RE 0.862510516945347\n",
      "66 Train Loss 0.7500484 Test MSE 3.277095601437419 Test RE 0.8652719313454598\n",
      "67 Train Loss 0.7210784 Test MSE 3.346631369752967 Test RE 0.8744037250503297\n",
      "68 Train Loss 0.69547284 Test MSE 3.384073708722895 Test RE 0.8792815637214695\n",
      "69 Train Loss 0.6796419 Test MSE 3.368660740580952 Test RE 0.8772769080349768\n",
      "70 Train Loss 0.65965587 Test MSE 3.3887196393338215 Test RE 0.8798849311955602\n",
      "71 Train Loss 0.6427802 Test MSE 3.4095557204766145 Test RE 0.8825858419662278\n",
      "72 Train Loss 0.62389785 Test MSE 3.4151503859004197 Test RE 0.8833096530706152\n",
      "73 Train Loss 0.6087351 Test MSE 3.4133396229263484 Test RE 0.8830754501359305\n",
      "74 Train Loss 0.5921465 Test MSE 3.4164136118454134 Test RE 0.8834730011493124\n",
      "75 Train Loss 0.5774001 Test MSE 3.427222573605516 Test RE 0.8848694779371994\n",
      "76 Train Loss 0.57006264 Test MSE 3.4620228298446145 Test RE 0.8893506442431125\n",
      "77 Train Loss 0.5598219 Test MSE 3.4683003038927565 Test RE 0.8901565816073969\n",
      "78 Train Loss 0.5496231 Test MSE 3.439241117865323 Test RE 0.8864196450962774\n",
      "79 Train Loss 0.5384375 Test MSE 3.4119192499201674 Test RE 0.8828916965128969\n",
      "80 Train Loss 0.5278741 Test MSE 3.3882941796068833 Test RE 0.8798296939092988\n",
      "81 Train Loss 0.520037 Test MSE 3.386334885084398 Test RE 0.8795752746225128\n",
      "82 Train Loss 0.5135556 Test MSE 3.383938499522172 Test RE 0.8792639978888052\n",
      "83 Train Loss 0.5035595 Test MSE 3.35729982688351 Test RE 0.8757963367585307\n",
      "84 Train Loss 0.49595082 Test MSE 3.3475437302523163 Test RE 0.8745229071421518\n",
      "85 Train Loss 0.4864627 Test MSE 3.3483202508750627 Test RE 0.8746243316119069\n",
      "86 Train Loss 0.47787282 Test MSE 3.344951608393537 Test RE 0.8741842545171612\n",
      "87 Train Loss 0.47154343 Test MSE 3.3419150137165254 Test RE 0.8737873659674158\n",
      "88 Train Loss 0.46370128 Test MSE 3.331954772115945 Test RE 0.8724842766276624\n",
      "89 Train Loss 0.45618206 Test MSE 3.347900801387926 Test RE 0.8745695470946157\n",
      "90 Train Loss 0.45010927 Test MSE 3.311509038793357 Test RE 0.8698032632455927\n",
      "91 Train Loss 0.44318336 Test MSE 3.305963998338928 Test RE 0.8690747260506241\n",
      "92 Train Loss 0.43818772 Test MSE 3.307849003328241 Test RE 0.8693224566281652\n",
      "93 Train Loss 0.43353885 Test MSE 3.305186571514499 Test RE 0.8689725347184922\n",
      "94 Train Loss 0.42782027 Test MSE 3.3045292867877607 Test RE 0.8688861264686868\n",
      "95 Train Loss 0.42222092 Test MSE 3.3321728918038462 Test RE 0.8725128338705926\n",
      "96 Train Loss 0.41725913 Test MSE 3.3306056000998 Test RE 0.8723076159830958\n",
      "97 Train Loss 0.4134066 Test MSE 3.3389602414968667 Test RE 0.8734009986354808\n",
      "98 Train Loss 0.40942958 Test MSE 3.372541467349994 Test RE 0.8777820779395668\n",
      "99 Train Loss 0.4067673 Test MSE 3.388781190875205 Test RE 0.8798929221233429\n",
      "100 Train Loss 0.4027521 Test MSE 3.4077577210205177 Test RE 0.882353099307491\n",
      "101 Train Loss 0.3995939 Test MSE 3.43940899282464 Test RE 0.886441278625437\n",
      "102 Train Loss 0.3979482 Test MSE 3.4355774014534664 Test RE 0.8859473816753153\n",
      "103 Train Loss 0.39548123 Test MSE 3.4443838346148308 Test RE 0.8870821316951565\n",
      "104 Train Loss 0.39271507 Test MSE 3.4516879626247072 Test RE 0.8880222026011853\n",
      "105 Train Loss 0.38985506 Test MSE 3.464821505368218 Test RE 0.8897100441058591\n",
      "106 Train Loss 0.38546568 Test MSE 3.478746629551202 Test RE 0.8914961245151706\n",
      "107 Train Loss 0.3825815 Test MSE 3.4809472977759386 Test RE 0.8917780618371972\n",
      "108 Train Loss 0.38037637 Test MSE 3.4825753208893278 Test RE 0.8919865777177902\n",
      "109 Train Loss 0.37691736 Test MSE 3.4973309537709856 Test RE 0.8938742489228475\n",
      "110 Train Loss 0.3744802 Test MSE 3.507872148364657 Test RE 0.8952203344360393\n",
      "111 Train Loss 0.37226146 Test MSE 3.512316759905385 Test RE 0.8957872945334789\n",
      "112 Train Loss 0.36976767 Test MSE 3.5167815473659765 Test RE 0.8963564672390261\n",
      "113 Train Loss 0.36694682 Test MSE 3.531215216579838 Test RE 0.8981940088827935\n",
      "114 Train Loss 0.3647378 Test MSE 3.536211923289328 Test RE 0.8988292612295992\n",
      "115 Train Loss 0.36157495 Test MSE 3.5431637093231436 Test RE 0.8997123249306146\n",
      "116 Train Loss 0.35782525 Test MSE 3.548034055351055 Test RE 0.9003304738399988\n",
      "117 Train Loss 0.3559861 Test MSE 3.5562651164827632 Test RE 0.901374204260468\n",
      "118 Train Loss 0.3538285 Test MSE 3.565407743382128 Test RE 0.9025321098193713\n",
      "119 Train Loss 0.3516224 Test MSE 3.569138202713499 Test RE 0.9030041426629785\n",
      "120 Train Loss 0.34879807 Test MSE 3.5845042873020065 Test RE 0.904945890886437\n",
      "121 Train Loss 0.34702915 Test MSE 3.5800703802879865 Test RE 0.904386024417714\n",
      "122 Train Loss 0.3454281 Test MSE 3.570957334360562 Test RE 0.9032342366045878\n",
      "123 Train Loss 0.3436817 Test MSE 3.5787006914561843 Test RE 0.9042130046431496\n",
      "124 Train Loss 0.34176433 Test MSE 3.578856069577787 Test RE 0.9042326337495421\n",
      "125 Train Loss 0.33923474 Test MSE 3.5862828516033325 Test RE 0.9051703716967742\n",
      "126 Train Loss 0.33731252 Test MSE 3.573515971622714 Test RE 0.9035577681861794\n",
      "127 Train Loss 0.335794 Test MSE 3.5738653960769646 Test RE 0.9036019428120774\n",
      "128 Train Loss 0.3336538 Test MSE 3.577274438254905 Test RE 0.9040328044361361\n",
      "129 Train Loss 0.32934776 Test MSE 3.5968940513319505 Test RE 0.9065085050291817\n",
      "130 Train Loss 0.32699305 Test MSE 3.6019887823054795 Test RE 0.9071502785481173\n",
      "131 Train Loss 0.32442492 Test MSE 3.6235723514467724 Test RE 0.9098640984296411\n",
      "132 Train Loss 0.3222699 Test MSE 3.6280930163568033 Test RE 0.9104314816952132\n",
      "133 Train Loss 0.32007915 Test MSE 3.6242065372882366 Test RE 0.9099437156730621\n",
      "134 Train Loss 0.31717834 Test MSE 3.6469507940510417 Test RE 0.9127944948124802\n",
      "135 Train Loss 0.3144263 Test MSE 3.6498666002883358 Test RE 0.9131593201498491\n",
      "136 Train Loss 0.31221718 Test MSE 3.6529857473810483 Test RE 0.9135494261840366\n",
      "137 Train Loss 0.30889598 Test MSE 3.672013836684554 Test RE 0.9159256361204074\n",
      "138 Train Loss 0.30731022 Test MSE 3.6810451811309717 Test RE 0.9170513072418477\n",
      "139 Train Loss 0.30525684 Test MSE 3.6856356024863106 Test RE 0.9176229302607384\n",
      "140 Train Loss 0.30274314 Test MSE 3.681746966182239 Test RE 0.9171387202177694\n",
      "141 Train Loss 0.3005896 Test MSE 3.69353438418887 Test RE 0.9186056948024269\n",
      "142 Train Loss 0.29899842 Test MSE 3.698775489052038 Test RE 0.9192572119597245\n",
      "143 Train Loss 0.29795697 Test MSE 3.7020729170162996 Test RE 0.9196668758036095\n",
      "144 Train Loss 0.29648608 Test MSE 3.7140204366112797 Test RE 0.921149678478459\n",
      "145 Train Loss 0.29527253 Test MSE 3.715139488121226 Test RE 0.9212884413528993\n",
      "146 Train Loss 0.29292023 Test MSE 3.7161137178778416 Test RE 0.9214092292510573\n",
      "147 Train Loss 0.29123393 Test MSE 3.7224905873776994 Test RE 0.9221994617805106\n",
      "148 Train Loss 0.28952622 Test MSE 3.7243880631020287 Test RE 0.9224344695150255\n",
      "149 Train Loss 0.28817976 Test MSE 3.730157373910631 Test RE 0.9231486474826466\n",
      "150 Train Loss 0.2866648 Test MSE 3.7302596062456557 Test RE 0.9231612977525573\n",
      "151 Train Loss 0.28513485 Test MSE 3.7367084597951754 Test RE 0.9239589314080182\n",
      "152 Train Loss 0.2822672 Test MSE 3.7407577758350996 Test RE 0.9244594238480583\n",
      "153 Train Loss 0.28050357 Test MSE 3.763712887568575 Test RE 0.9272915523150864\n",
      "154 Train Loss 0.27767664 Test MSE 3.7660686381699437 Test RE 0.9275817080713064\n",
      "155 Train Loss 0.27629524 Test MSE 3.7604066866316654 Test RE 0.9268841772215859\n",
      "156 Train Loss 0.27496868 Test MSE 3.777912955900637 Test RE 0.9290391891832352\n",
      "157 Train Loss 0.2739612 Test MSE 3.770710607394974 Test RE 0.928153189922013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 Train Loss 0.27285042 Test MSE 3.7627499910272206 Test RE 0.927172927041213\n",
      "159 Train Loss 0.27178827 Test MSE 3.7538580449713543 Test RE 0.9260767542807916\n",
      "160 Train Loss 0.27052885 Test MSE 3.7518704482586016 Test RE 0.9258315517711835\n",
      "161 Train Loss 0.2696228 Test MSE 3.7550336817924235 Test RE 0.9262217577265008\n",
      "162 Train Loss 0.26894546 Test MSE 3.757245081600021 Test RE 0.9264944510387032\n",
      "163 Train Loss 0.26754117 Test MSE 3.7556344536963824 Test RE 0.9262958483740328\n",
      "164 Train Loss 0.26681802 Test MSE 3.76712606194703 Test RE 0.9277119205299063\n",
      "165 Train Loss 0.26533502 Test MSE 3.7719930096387957 Test RE 0.9283110069323119\n",
      "166 Train Loss 0.26372823 Test MSE 3.7748687851928397 Test RE 0.9286648126601412\n",
      "167 Train Loss 0.26262236 Test MSE 3.7873045997777197 Test RE 0.9301932376581565\n",
      "168 Train Loss 0.26157945 Test MSE 3.771634962512301 Test RE 0.9282669470711701\n",
      "169 Train Loss 0.2609506 Test MSE 3.767295886160608 Test RE 0.9277328311882158\n",
      "170 Train Loss 0.26021984 Test MSE 3.7701214801972105 Test RE 0.9280806808243673\n",
      "171 Train Loss 0.25935557 Test MSE 3.7763536880323687 Test RE 0.9288474470127435\n",
      "172 Train Loss 0.25858587 Test MSE 3.7872006154455344 Test RE 0.930180467865814\n",
      "173 Train Loss 0.25761253 Test MSE 3.794231099363451 Test RE 0.9310434518073886\n",
      "174 Train Loss 0.25671995 Test MSE 3.7975205868399846 Test RE 0.931446958100755\n",
      "175 Train Loss 0.25617012 Test MSE 3.8058630897409214 Test RE 0.9324695116043664\n",
      "176 Train Loss 0.2557109 Test MSE 3.8178691864274845 Test RE 0.9339391524547583\n",
      "177 Train Loss 0.25518537 Test MSE 3.8236939813070596 Test RE 0.934651320735145\n",
      "178 Train Loss 0.25438783 Test MSE 3.826484816811463 Test RE 0.9349923498958926\n",
      "179 Train Loss 0.25383353 Test MSE 3.8288694049153307 Test RE 0.9352836387018947\n",
      "180 Train Loss 0.2531757 Test MSE 3.8381364526922908 Test RE 0.9364147924692776\n",
      "181 Train Loss 0.25253284 Test MSE 3.840850855784112 Test RE 0.9367458591203042\n",
      "182 Train Loss 0.25168243 Test MSE 3.8464102402923084 Test RE 0.9374235536613945\n",
      "183 Train Loss 0.25106284 Test MSE 3.8502044243520617 Test RE 0.9378857873544593\n",
      "184 Train Loss 0.25039548 Test MSE 3.8604168398532015 Test RE 0.9391288040102114\n",
      "185 Train Loss 0.24985307 Test MSE 3.8638280081305285 Test RE 0.9395436321426873\n",
      "186 Train Loss 0.24950051 Test MSE 3.8745547412994417 Test RE 0.9408469055716319\n",
      "187 Train Loss 0.24914032 Test MSE 3.885059645802274 Test RE 0.9421214799994738\n",
      "188 Train Loss 0.24869494 Test MSE 3.8933435194219657 Test RE 0.9431253589867518\n",
      "189 Train Loss 0.24817365 Test MSE 3.8990182496001577 Test RE 0.943812433366236\n",
      "190 Train Loss 0.24747244 Test MSE 3.9063332535875155 Test RE 0.9446973685135255\n",
      "191 Train Loss 0.24691767 Test MSE 3.9072748929005856 Test RE 0.9448112234410867\n",
      "192 Train Loss 0.24612561 Test MSE 3.91344005323838 Test RE 0.945556322892441\n",
      "193 Train Loss 0.24564505 Test MSE 3.917511021782123 Test RE 0.9460480040534334\n",
      "194 Train Loss 0.24525407 Test MSE 3.920767054763871 Test RE 0.9464410755333156\n",
      "195 Train Loss 0.24474157 Test MSE 3.9160655971521474 Test RE 0.9458734586295202\n",
      "196 Train Loss 0.244169 Test MSE 3.920604309948545 Test RE 0.9464214326963014\n",
      "197 Train Loss 0.24376926 Test MSE 3.9272871552933943 Test RE 0.9472276980880069\n",
      "198 Train Loss 0.2433268 Test MSE 3.929932807971258 Test RE 0.947546698645595\n",
      "199 Train Loss 0.24299651 Test MSE 3.92803096824456 Test RE 0.9473173944667789\n",
      "Training time: 289.42\n",
      "KG_atanh\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.131058 Test MSE 8.030868320208034 Test RE 1.3545321351353266\n",
      "1 Train Loss 46.01455 Test MSE 8.294656086039103 Test RE 1.3765983740695733\n",
      "2 Train Loss 44.511017 Test MSE 8.052307898549346 Test RE 1.3563389909114942\n",
      "3 Train Loss 42.666687 Test MSE 8.05343192362677 Test RE 1.3564336535758337\n",
      "4 Train Loss 42.052124 Test MSE 8.088341253180541 Test RE 1.3593703510135249\n",
      "5 Train Loss 41.418472 Test MSE 8.298520711907303 Test RE 1.3769190273975085\n",
      "6 Train Loss 40.28566 Test MSE 8.157908118972513 Test RE 1.3652037265730683\n",
      "7 Train Loss 39.400295 Test MSE 8.024415409011658 Test RE 1.3539878333393944\n",
      "8 Train Loss 36.333527 Test MSE 6.422129031261721 Test RE 1.2112884435169913\n",
      "9 Train Loss 30.318804 Test MSE 6.339419118089846 Test RE 1.2034631393749853\n",
      "10 Train Loss 28.001358 Test MSE 6.041822805161439 Test RE 1.1748760543139771\n",
      "11 Train Loss 27.393559 Test MSE 6.287636073494662 Test RE 1.1985378639977702\n",
      "12 Train Loss 27.063934 Test MSE 6.199909042192497 Test RE 1.1901473099436692\n",
      "13 Train Loss 26.55167 Test MSE 6.088516031953514 Test RE 1.179407234036209\n",
      "14 Train Loss 25.748093 Test MSE 5.782227236917333 Test RE 1.1493588330899123\n",
      "15 Train Loss 24.958708 Test MSE 5.2298781915510295 Test RE 1.0930847798734051\n",
      "16 Train Loss 24.61701 Test MSE 5.431664649345799 Test RE 1.1139726664199783\n",
      "17 Train Loss 24.233902 Test MSE 5.399495211907751 Test RE 1.1106689746252922\n",
      "18 Train Loss 24.032795 Test MSE 5.2589995228364925 Test RE 1.096123846313613\n",
      "19 Train Loss 23.512703 Test MSE 4.578272911569593 Test RE 1.0227250631748002\n",
      "20 Train Loss 21.148212 Test MSE 4.183475064706807 Test RE 0.9776348006411258\n",
      "21 Train Loss 18.59108 Test MSE 3.669029766853374 Test RE 0.9155533960243675\n",
      "22 Train Loss 17.795504 Test MSE 3.552952753507524 Test RE 0.9009543291956847\n",
      "23 Train Loss 17.175262 Test MSE 3.975788364438127 Test RE 0.9530587862388932\n",
      "24 Train Loss 16.711657 Test MSE 3.805778175555228 Test RE 0.9324591091898479\n",
      "25 Train Loss 16.372765 Test MSE 3.6644052017567432 Test RE 0.9149762173736862\n",
      "26 Train Loss 16.177391 Test MSE 3.5991633750476084 Test RE 0.9067944234979953\n",
      "27 Train Loss 15.837046 Test MSE 3.3553812227305113 Test RE 0.8755460542835726\n",
      "28 Train Loss 15.639351 Test MSE 3.3089441131339656 Test RE 0.8694663454158852\n",
      "29 Train Loss 14.427464 Test MSE 2.431925343401514 Test RE 0.7453893435486854\n",
      "30 Train Loss 11.775099 Test MSE 2.3300597003283436 Test RE 0.7296113553945497\n",
      "31 Train Loss 8.860764 Test MSE 1.9743110529518877 Test RE 0.6716079814887768\n",
      "32 Train Loss 7.9688234 Test MSE 2.1036426126979104 Test RE 0.6932566434005135\n",
      "33 Train Loss 6.9029408 Test MSE 2.210828396543385 Test RE 0.7106987921629223\n",
      "34 Train Loss 6.280528 Test MSE 2.2845661820828522 Test RE 0.7224535544881516\n",
      "35 Train Loss 6.0202374 Test MSE 2.3036840307012754 Test RE 0.7254700971838178\n",
      "36 Train Loss 5.744686 Test MSE 2.3048622306828546 Test RE 0.7256555912843855\n",
      "37 Train Loss 5.62241 Test MSE 2.303298473748766 Test RE 0.7254093853543084\n",
      "38 Train Loss 5.493143 Test MSE 2.249618545716562 Test RE 0.7169064737026475\n",
      "39 Train Loss 5.40773 Test MSE 2.292988022732971 Test RE 0.7237839584154424\n",
      "40 Train Loss 5.350255 Test MSE 2.264154869695221 Test RE 0.7192189556020157\n",
      "41 Train Loss 5.270159 Test MSE 2.302978031045874 Test RE 0.7253589228909669\n",
      "42 Train Loss 5.2224693 Test MSE 2.269791419625392 Test RE 0.7201136368179201\n",
      "43 Train Loss 5.1705246 Test MSE 2.2410429999347667 Test RE 0.7155387452922966\n",
      "44 Train Loss 5.086193 Test MSE 2.247926018480499 Test RE 0.7166367364072794\n",
      "45 Train Loss 5.016819 Test MSE 2.2694801441582264 Test RE 0.720064257524228\n",
      "46 Train Loss 4.9450054 Test MSE 2.255769129086005 Test RE 0.7178858360203204\n",
      "47 Train Loss 4.894145 Test MSE 2.2341955459126415 Test RE 0.714444753107486\n",
      "48 Train Loss 4.805423 Test MSE 2.256860945114096 Test RE 0.7180595471579472\n",
      "49 Train Loss 4.6808443 Test MSE 2.2065237550466414 Test RE 0.7100065642768512\n",
      "50 Train Loss 4.583268 Test MSE 2.190371544108387 Test RE 0.7074030934798139\n",
      "51 Train Loss 4.4697385 Test MSE 2.1578969376012687 Test RE 0.702139506400812\n",
      "52 Train Loss 4.301305 Test MSE 2.1193386061322945 Test RE 0.6958381488477837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 3.4363415 Test MSE 1.6141935373096663 Test RE 0.6072756428212397\n",
      "54 Train Loss 2.4841304 Test MSE 1.4553165904884995 Test RE 0.5766161478534817\n",
      "55 Train Loss 1.982444 Test MSE 1.2310849845395864 Test RE 0.5303371829760952\n",
      "56 Train Loss 1.7095397 Test MSE 1.1551777315713168 Test RE 0.5137270862230449\n",
      "57 Train Loss 1.5405487 Test MSE 1.0817628909986312 Test RE 0.4971347251259984\n",
      "58 Train Loss 1.273617 Test MSE 0.9592087613564955 Test RE 0.4681280113331984\n",
      "59 Train Loss 1.2025828 Test MSE 0.8612919147548094 Test RE 0.44359153039391147\n",
      "60 Train Loss 1.1146497 Test MSE 0.712751787551944 Test RE 0.40353129196219184\n",
      "61 Train Loss 0.98333555 Test MSE 0.5371050592691745 Test RE 0.35029801947564143\n",
      "62 Train Loss 0.8413719 Test MSE 0.37157827244968406 Test RE 0.29136220550468134\n",
      "63 Train Loss 0.70122766 Test MSE 0.2979966014134563 Test RE 0.2609238126229931\n",
      "64 Train Loss 0.5067113 Test MSE 0.17893310292677445 Test RE 0.20218708311460545\n",
      "65 Train Loss 0.42301363 Test MSE 0.12087061055142569 Test RE 0.16617604488045895\n",
      "66 Train Loss 0.36771175 Test MSE 0.06578539812662489 Test RE 0.1225950158011235\n",
      "67 Train Loss 0.30194148 Test MSE 0.04210207816934196 Test RE 0.09807534102135831\n",
      "68 Train Loss 0.25611028 Test MSE 0.041209554866179735 Test RE 0.09703022132253225\n",
      "69 Train Loss 0.22778496 Test MSE 0.03374783362260914 Test RE 0.08780737820241348\n",
      "70 Train Loss 0.18481147 Test MSE 0.040629542152572216 Test RE 0.09634496525756991\n",
      "71 Train Loss 0.1565116 Test MSE 0.03895772267817346 Test RE 0.0943419483698466\n",
      "72 Train Loss 0.1356704 Test MSE 0.032995740606274415 Test RE 0.08682344235839838\n",
      "73 Train Loss 0.12342517 Test MSE 0.03100815577920293 Test RE 0.08416781032077254\n",
      "74 Train Loss 0.10291768 Test MSE 0.02093639483428519 Test RE 0.06916064107613193\n",
      "75 Train Loss 0.0912689 Test MSE 0.019238982596623405 Test RE 0.06629779908128836\n",
      "76 Train Loss 0.082680374 Test MSE 0.017480271331076176 Test RE 0.06319491660148097\n",
      "77 Train Loss 0.076465204 Test MSE 0.017337175050214607 Test RE 0.06293572324358078\n",
      "78 Train Loss 0.07111855 Test MSE 0.016305325445041072 Test RE 0.061034135291043005\n",
      "79 Train Loss 0.06810081 Test MSE 0.014946880470084162 Test RE 0.05843638490834882\n",
      "80 Train Loss 0.057766188 Test MSE 0.014790478206280142 Test RE 0.0581298454374648\n",
      "81 Train Loss 0.050763655 Test MSE 0.014378264197522026 Test RE 0.05731407530720778\n",
      "82 Train Loss 0.04729543 Test MSE 0.012154284963268282 Test RE 0.05269540751911893\n",
      "83 Train Loss 0.04336898 Test MSE 0.010369520245096051 Test RE 0.04867291897495989\n",
      "84 Train Loss 0.04078739 Test MSE 0.010082540720271795 Test RE 0.047994674718549984\n",
      "85 Train Loss 0.037949033 Test MSE 0.01000247296054485 Test RE 0.047803726532763734\n",
      "86 Train Loss 0.035009935 Test MSE 0.00895199785206603 Test RE 0.045223903416085905\n",
      "87 Train Loss 0.033227038 Test MSE 0.0079568178256615 Test RE 0.04263612901548773\n",
      "88 Train Loss 0.032148305 Test MSE 0.00782671654772809 Test RE 0.042286122456194175\n",
      "89 Train Loss 0.030311657 Test MSE 0.0068903121096003965 Test RE 0.03967596582851282\n",
      "90 Train Loss 0.026393283 Test MSE 0.004537457794699118 Test RE 0.03219692229910648\n",
      "91 Train Loss 0.024189496 Test MSE 0.003857969229068391 Test RE 0.029688444245247178\n",
      "92 Train Loss 0.022789642 Test MSE 0.0033110403780496093 Test RE 0.02750364784992566\n",
      "93 Train Loss 0.0216532 Test MSE 0.003136394900829623 Test RE 0.02676846265401378\n",
      "94 Train Loss 0.021017723 Test MSE 0.003172950374827235 Test RE 0.026924007332329355\n",
      "95 Train Loss 0.01980165 Test MSE 0.0029812745162973433 Test RE 0.026098109211887648\n",
      "96 Train Loss 0.018680044 Test MSE 0.003283748366125589 Test RE 0.027390060726685855\n",
      "97 Train Loss 0.018251874 Test MSE 0.003569093068035537 Test RE 0.028555317719415184\n",
      "98 Train Loss 0.017885255 Test MSE 0.004288304158353413 Test RE 0.03130046942412462\n",
      "99 Train Loss 0.016669806 Test MSE 0.003959911799234439 Test RE 0.030078128935536574\n",
      "100 Train Loss 0.015776549 Test MSE 0.0041464433938789595 Test RE 0.03077839229126108\n",
      "101 Train Loss 0.014533794 Test MSE 0.0034709419130668755 Test RE 0.028159940519761603\n",
      "102 Train Loss 0.01366271 Test MSE 0.003867324080347156 Test RE 0.029724416904251195\n",
      "103 Train Loss 0.013065192 Test MSE 0.0041559608526886005 Test RE 0.030813695339161257\n",
      "104 Train Loss 0.01248358 Test MSE 0.004239774041886421 Test RE 0.031122854045077825\n",
      "105 Train Loss 0.0116732605 Test MSE 0.00413608965959954 Test RE 0.030739941208537288\n",
      "106 Train Loss 0.01126586 Test MSE 0.00398525546867337 Test RE 0.03017422632452097\n",
      "107 Train Loss 0.010636477 Test MSE 0.0032876846329343104 Test RE 0.0274064721998889\n",
      "108 Train Loss 0.010263699 Test MSE 0.0030480071136881866 Test RE 0.026388581667884194\n",
      "109 Train Loss 0.009968556 Test MSE 0.0029782002005127035 Test RE 0.02608464944429744\n",
      "110 Train Loss 0.009639686 Test MSE 0.0029576083429590557 Test RE 0.0259943158483354\n",
      "111 Train Loss 0.00920308 Test MSE 0.0028990190809704648 Test RE 0.025735558480488266\n",
      "112 Train Loss 0.008804456 Test MSE 0.0027807980659451566 Test RE 0.025205353147596064\n",
      "113 Train Loss 0.008351014 Test MSE 0.0028020832747592335 Test RE 0.02530163458558277\n",
      "114 Train Loss 0.007943317 Test MSE 0.0023025552500806723 Test RE 0.02293575761023271\n",
      "115 Train Loss 0.007572283 Test MSE 0.002031697378001662 Test RE 0.02154455708950112\n",
      "116 Train Loss 0.0073129954 Test MSE 0.00216360532296928 Test RE 0.022232949467660728\n",
      "117 Train Loss 0.0069502285 Test MSE 0.0021781038350916606 Test RE 0.022307317576908386\n",
      "118 Train Loss 0.0066673746 Test MSE 0.0019457100914640742 Test RE 0.021083714465083832\n",
      "119 Train Loss 0.006282869 Test MSE 0.0020349216042413547 Test RE 0.021561645507663242\n",
      "120 Train Loss 0.0061039515 Test MSE 0.0021682509083270534 Test RE 0.02225680540864934\n",
      "121 Train Loss 0.0059660217 Test MSE 0.0021469566123193044 Test RE 0.02214724419656889\n",
      "122 Train Loss 0.0058444384 Test MSE 0.0021266481515297 Test RE 0.02204224786642809\n",
      "123 Train Loss 0.0057486165 Test MSE 0.0020152486432885083 Test RE 0.02145716688619272\n",
      "124 Train Loss 0.005596038 Test MSE 0.001980154767456056 Test RE 0.02126951701614546\n",
      "125 Train Loss 0.005489005 Test MSE 0.001957040443569757 Test RE 0.021145013202645484\n",
      "126 Train Loss 0.005450488 Test MSE 0.0019611075740430966 Test RE 0.02116697363096787\n",
      "127 Train Loss 0.0053459387 Test MSE 0.0020949364356252337 Test RE 0.021877288066924436\n",
      "128 Train Loss 0.005242078 Test MSE 0.002014200237175465 Test RE 0.021451584758261213\n",
      "129 Train Loss 0.0051139574 Test MSE 0.0018964139604445887 Test RE 0.02081491453992332\n",
      "130 Train Loss 0.004958403 Test MSE 0.0018497001850125518 Test RE 0.020556952400615378\n",
      "131 Train Loss 0.0047104545 Test MSE 0.0018008456477140993 Test RE 0.02028365922469493\n",
      "132 Train Loss 0.0045701996 Test MSE 0.0019615784791978106 Test RE 0.0211695148068916\n",
      "133 Train Loss 0.0044685313 Test MSE 0.00196543939519228 Test RE 0.021190338225430712\n",
      "134 Train Loss 0.004305112 Test MSE 0.0016117974304808633 Test RE 0.019189483690302767\n",
      "135 Train Loss 0.004127595 Test MSE 0.0014420405461179888 Test RE 0.018150842826921445\n",
      "136 Train Loss 0.003942828 Test MSE 0.0014022674368049958 Test RE 0.017898782258115826\n",
      "137 Train Loss 0.0037509943 Test MSE 0.0010915809015345564 Test RE 0.015791959610314592\n",
      "138 Train Loss 0.0036941306 Test MSE 0.0011374371998756543 Test RE 0.016120250051959516\n",
      "139 Train Loss 0.0036118752 Test MSE 0.0011447784790922998 Test RE 0.016172188267469644\n",
      "140 Train Loss 0.0034860864 Test MSE 0.0010669997204456306 Test RE 0.015613138530975519\n",
      "141 Train Loss 0.0034190603 Test MSE 0.000986675570398923 Test RE 0.015013959775241519\n",
      "142 Train Loss 0.0033165608 Test MSE 0.000980844363004745 Test RE 0.014969528123671146\n",
      "143 Train Loss 0.0032646866 Test MSE 0.0009012814048332301 Test RE 0.014349549465683719\n",
      "144 Train Loss 0.0031808815 Test MSE 0.0008965466666708727 Test RE 0.014311808298481409\n",
      "145 Train Loss 0.0031132356 Test MSE 0.0009314276451660025 Test RE 0.01458755888634087\n",
      "146 Train Loss 0.00303363 Test MSE 0.0009559583705336802 Test RE 0.014778404532860934\n",
      "147 Train Loss 0.002943497 Test MSE 0.0009255850665722385 Test RE 0.014541735126023834\n",
      "148 Train Loss 0.002883613 Test MSE 0.0009087995742165175 Test RE 0.014409274595546032\n",
      "149 Train Loss 0.002785421 Test MSE 0.0009841993397879053 Test RE 0.014995107893543922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 Train Loss 0.0027285272 Test MSE 0.0009158897736176438 Test RE 0.014465373949896535\n",
      "151 Train Loss 0.0026985323 Test MSE 0.0008903624913356799 Test RE 0.014262363083481198\n",
      "152 Train Loss 0.0026670285 Test MSE 0.0008821211360164681 Test RE 0.014196202129496622\n",
      "153 Train Loss 0.002620959 Test MSE 0.0008501815573370773 Test RE 0.01393682671260287\n",
      "154 Train Loss 0.0025708706 Test MSE 0.0008536916856077471 Test RE 0.013965567432262465\n",
      "155 Train Loss 0.0025412762 Test MSE 0.0008844450154983866 Test RE 0.014214889225013648\n",
      "156 Train Loss 0.002502429 Test MSE 0.0008151705215537336 Test RE 0.01364684608369728\n",
      "157 Train Loss 0.002479441 Test MSE 0.0008304396281994559 Test RE 0.013774063885201642\n",
      "158 Train Loss 0.0024521444 Test MSE 0.0008890178204560274 Test RE 0.014251589139755301\n",
      "159 Train Loss 0.0024265721 Test MSE 0.0008811969994201176 Test RE 0.01418876399701849\n",
      "160 Train Loss 0.0023896745 Test MSE 0.0008844886004975451 Test RE 0.014215239471943305\n",
      "161 Train Loss 0.0023246706 Test MSE 0.00080813239369641 Test RE 0.013587805390108305\n",
      "162 Train Loss 0.0022756443 Test MSE 0.0007990657280005834 Test RE 0.013511367677066833\n",
      "163 Train Loss 0.002235468 Test MSE 0.0008006768953146321 Test RE 0.0135249823966915\n",
      "164 Train Loss 0.0022097286 Test MSE 0.0007484607217640295 Test RE 0.013076531590465243\n",
      "165 Train Loss 0.002143782 Test MSE 0.000702494196249392 Test RE 0.012668623531685408\n",
      "166 Train Loss 0.0021032311 Test MSE 0.0007360354642940622 Test RE 0.012967535048577002\n",
      "167 Train Loss 0.0020470144 Test MSE 0.0006731640738737958 Test RE 0.012401337454297163\n",
      "168 Train Loss 0.0020201046 Test MSE 0.0006692071336321738 Test RE 0.012364835450034948\n",
      "169 Train Loss 0.0019885972 Test MSE 0.0006768954861301926 Test RE 0.012435660849954133\n",
      "170 Train Loss 0.0019710108 Test MSE 0.0006875851099579902 Test RE 0.012533469020296683\n",
      "171 Train Loss 0.0019404151 Test MSE 0.0007028998206587505 Test RE 0.012672280473905978\n",
      "172 Train Loss 0.0019185522 Test MSE 0.0007092761155500831 Test RE 0.0127296284585102\n",
      "173 Train Loss 0.0018798725 Test MSE 0.0007437650481290415 Test RE 0.0130354474470564\n",
      "174 Train Loss 0.0018511885 Test MSE 0.0007418104070301642 Test RE 0.013018307367834929\n",
      "175 Train Loss 0.0018089837 Test MSE 0.0007032316670892677 Test RE 0.012675271479664886\n",
      "176 Train Loss 0.0017944231 Test MSE 0.000700451239298311 Test RE 0.012650189004520583\n",
      "177 Train Loss 0.0017857321 Test MSE 0.0006834255730968681 Test RE 0.01249550098540295\n",
      "178 Train Loss 0.0017771301 Test MSE 0.000649428059383373 Test RE 0.01218073751932159\n",
      "179 Train Loss 0.0017581757 Test MSE 0.000605854679173002 Test RE 0.01176500980578165\n",
      "180 Train Loss 0.0017424125 Test MSE 0.0006011153759531311 Test RE 0.011718903518981296\n",
      "181 Train Loss 0.0017289171 Test MSE 0.0006010172338170837 Test RE 0.01171794682645825\n",
      "182 Train Loss 0.0016915738 Test MSE 0.0005954674299766274 Test RE 0.011663719487235285\n",
      "183 Train Loss 0.0016705246 Test MSE 0.0006223118968672587 Test RE 0.011923729415723592\n",
      "184 Train Loss 0.0016328744 Test MSE 0.0005729438425178002 Test RE 0.011441002709968378\n",
      "185 Train Loss 0.0015890587 Test MSE 0.000625955994415676 Test RE 0.0119585895952544\n",
      "186 Train Loss 0.0015618678 Test MSE 0.0006115548129318981 Test RE 0.011820225299226744\n",
      "187 Train Loss 0.0015386823 Test MSE 0.0005716546274183804 Test RE 0.011428123419613625\n",
      "188 Train Loss 0.0015185317 Test MSE 0.0005833363770333668 Test RE 0.01154429963069611\n",
      "189 Train Loss 0.0015025137 Test MSE 0.000612154875119635 Test RE 0.011826022924444719\n",
      "190 Train Loss 0.0014856843 Test MSE 0.0005796626732099307 Test RE 0.011507890688250672\n",
      "191 Train Loss 0.0014507027 Test MSE 0.000568298755289984 Test RE 0.011394529908991657\n",
      "192 Train Loss 0.0014230043 Test MSE 0.0005540447154298782 Test RE 0.011250723945569483\n",
      "193 Train Loss 0.0014040817 Test MSE 0.0005349920144375873 Test RE 0.011055584544228798\n",
      "194 Train Loss 0.0013654077 Test MSE 0.0005026056742528968 Test RE 0.01071572979310157\n",
      "195 Train Loss 0.0013539523 Test MSE 0.00048253469514642465 Test RE 0.010499589816263066\n",
      "196 Train Loss 0.0013353848 Test MSE 0.00046005923431938336 Test RE 0.010252149638161415\n",
      "197 Train Loss 0.0013117085 Test MSE 0.0004498424797318893 Test RE 0.010137673326846328\n",
      "198 Train Loss 0.0012929891 Test MSE 0.000450817461836505 Test RE 0.010148653503997575\n",
      "199 Train Loss 0.0012692838 Test MSE 0.00045988206264016194 Test RE 0.010250175364697234\n",
      "Training time: 281.83\n",
      "KG_atanh\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 56.59252 Test MSE 8.611391171317658 Test RE 1.4026351528966696\n",
      "1 Train Loss 47.85994 Test MSE 8.891860325620224 Test RE 1.4252937355944015\n",
      "2 Train Loss 45.612556 Test MSE 8.620962639594984 Test RE 1.4034144433250415\n",
      "3 Train Loss 44.625656 Test MSE 8.585172005352465 Test RE 1.4004982182941124\n",
      "4 Train Loss 44.262398 Test MSE 8.339478535578664 Test RE 1.3803127763527954\n",
      "5 Train Loss 44.069138 Test MSE 8.455260575376606 Test RE 1.3898616073761936\n",
      "6 Train Loss 40.382244 Test MSE 7.606566027616558 Test RE 1.3182639628321993\n",
      "7 Train Loss 39.89955 Test MSE 7.855731279483374 Test RE 1.3396809130477645\n",
      "8 Train Loss 39.63379 Test MSE 7.881872307318981 Test RE 1.3419080481908559\n",
      "9 Train Loss 38.75862 Test MSE 7.733547904218164 Test RE 1.329221784563514\n",
      "10 Train Loss 36.721767 Test MSE 7.965533823565158 Test RE 1.3490110383458103\n",
      "11 Train Loss 35.26961 Test MSE 8.206784070338006 Test RE 1.3692872481080693\n",
      "12 Train Loss 34.352528 Test MSE 8.293554999852416 Test RE 1.3765070017604233\n",
      "13 Train Loss 33.774727 Test MSE 8.201429290796673 Test RE 1.3688404575194986\n",
      "14 Train Loss 31.658756 Test MSE 8.61595478731141 Test RE 1.4030067676711337\n",
      "15 Train Loss 30.683441 Test MSE 8.970852903920962 Test RE 1.4316106748456157\n",
      "16 Train Loss 29.625772 Test MSE 8.525108106665842 Test RE 1.395590510576224\n",
      "17 Train Loss 29.138231 Test MSE 8.567534408471596 Test RE 1.3990588689806218\n",
      "18 Train Loss 28.389568 Test MSE 8.547742050346862 Test RE 1.3974419110666616\n",
      "19 Train Loss 28.131973 Test MSE 8.456520211650211 Test RE 1.3899651319737558\n",
      "20 Train Loss 27.892456 Test MSE 8.667445540659696 Test RE 1.407192854144773\n",
      "21 Train Loss 27.65784 Test MSE 8.703588513310132 Test RE 1.4101237766166521\n",
      "22 Train Loss 27.44673 Test MSE 8.741495543838983 Test RE 1.4131912199648589\n",
      "23 Train Loss 27.296965 Test MSE 8.802136785995156 Test RE 1.4180845222044818\n",
      "24 Train Loss 27.10595 Test MSE 8.774396312217839 Test RE 1.4158481686524456\n",
      "25 Train Loss 26.988102 Test MSE 8.670867135918934 Test RE 1.4074705812610258\n",
      "26 Train Loss 26.752037 Test MSE 8.587559680204949 Test RE 1.4006929553306262\n",
      "27 Train Loss 26.583874 Test MSE 8.498540262979798 Test RE 1.3934141884274047\n",
      "28 Train Loss 26.458538 Test MSE 8.482221581646089 Test RE 1.3920757463270317\n",
      "29 Train Loss 26.329243 Test MSE 8.564122296967295 Test RE 1.39878024621544\n",
      "30 Train Loss 26.105965 Test MSE 8.484777421235641 Test RE 1.392285458741074\n",
      "31 Train Loss 25.88727 Test MSE 8.601281703649553 Test RE 1.4018115891678766\n",
      "32 Train Loss 24.33908 Test MSE 7.777111921264216 Test RE 1.3329603610778769\n",
      "33 Train Loss 23.55654 Test MSE 7.696216464192913 Test RE 1.326009688863372\n",
      "34 Train Loss 22.858488 Test MSE 7.6478291644495044 Test RE 1.3218347026219803\n",
      "35 Train Loss 22.496407 Test MSE 7.892310914574641 Test RE 1.3427963533892782\n",
      "36 Train Loss 22.328224 Test MSE 7.9772214534248675 Test RE 1.350000360765626\n",
      "37 Train Loss 22.10646 Test MSE 7.799815013165415 Test RE 1.334904544759231\n",
      "38 Train Loss 21.93998 Test MSE 7.844858049399805 Test RE 1.3387534562484376\n",
      "39 Train Loss 21.806534 Test MSE 7.883106309639777 Test RE 1.3420130900370566\n",
      "40 Train Loss 21.695192 Test MSE 7.838711875594483 Test RE 1.3382289200723934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 21.50242 Test MSE 7.903614125614453 Test RE 1.3437575724949706\n",
      "42 Train Loss 21.339054 Test MSE 8.037047398100396 Test RE 1.355053134229046\n",
      "43 Train Loss 21.143486 Test MSE 7.835834305769391 Test RE 1.3379832674259924\n",
      "44 Train Loss 21.061478 Test MSE 7.848918310677946 Test RE 1.339099860582976\n",
      "45 Train Loss 20.954634 Test MSE 7.867595015529376 Test RE 1.3406921253752961\n",
      "46 Train Loss 20.843336 Test MSE 7.893260843843913 Test RE 1.3428771613549544\n",
      "47 Train Loss 20.706274 Test MSE 7.9535424938876025 Test RE 1.3479952540271416\n",
      "48 Train Loss 20.581894 Test MSE 7.963601664636249 Test RE 1.3488474170580584\n",
      "49 Train Loss 20.338303 Test MSE 8.073119739141562 Test RE 1.358090643693932\n",
      "50 Train Loss 19.85855 Test MSE 8.025213073428102 Test RE 1.3540551280282462\n",
      "51 Train Loss 19.599426 Test MSE 8.027330127290142 Test RE 1.3542337163463325\n",
      "52 Train Loss 19.133667 Test MSE 7.878655976213172 Test RE 1.3416342261328242\n",
      "53 Train Loss 18.783073 Test MSE 8.046874637695744 Test RE 1.3558813216839667\n",
      "54 Train Loss 18.530323 Test MSE 8.075815426545404 Test RE 1.3583173641193413\n",
      "55 Train Loss 18.0769 Test MSE 8.019014786542384 Test RE 1.3535321236391726\n",
      "56 Train Loss 17.765163 Test MSE 8.05412847988876 Test RE 1.3564923125385684\n",
      "57 Train Loss 17.666698 Test MSE 8.08841147693626 Test RE 1.3593762520927006\n",
      "58 Train Loss 17.49786 Test MSE 8.0858190814895 Test RE 1.3591583895845973\n",
      "59 Train Loss 17.386126 Test MSE 8.117395807163659 Test RE 1.3618096950490743\n",
      "60 Train Loss 17.139055 Test MSE 8.10642065681694 Test RE 1.3608887641317602\n",
      "61 Train Loss 17.093582 Test MSE 8.128359054602516 Test RE 1.3627290058348585\n",
      "62 Train Loss 16.880703 Test MSE 8.250666195562959 Test RE 1.3729431945524686\n",
      "63 Train Loss 16.752048 Test MSE 8.169376194552914 Test RE 1.3661629651984541\n",
      "64 Train Loss 16.616648 Test MSE 8.122763326661937 Test RE 1.362259859875956\n",
      "65 Train Loss 16.527945 Test MSE 8.081638649738618 Test RE 1.358806996397859\n",
      "66 Train Loss 16.461266 Test MSE 8.079364959525261 Test RE 1.3586158394039223\n",
      "67 Train Loss 16.399452 Test MSE 8.139651358696597 Test RE 1.3636752613693426\n",
      "68 Train Loss 16.194561 Test MSE 8.166180338333028 Test RE 1.3658957178964897\n",
      "69 Train Loss 16.115477 Test MSE 8.12437028784137 Test RE 1.362394604073472\n",
      "70 Train Loss 16.025106 Test MSE 8.12450601754469 Test RE 1.3624059844412137\n",
      "71 Train Loss 15.96003 Test MSE 8.13634846185885 Test RE 1.3633985581349244\n",
      "72 Train Loss 15.925512 Test MSE 8.143313593827935 Test RE 1.3639820028754144\n",
      "73 Train Loss 15.855818 Test MSE 8.118696794819098 Test RE 1.3619188203561254\n",
      "74 Train Loss 15.787106 Test MSE 8.140421477293994 Test RE 1.3637397706949872\n",
      "75 Train Loss 15.749645 Test MSE 8.112530527987223 Test RE 1.3614015236606318\n",
      "76 Train Loss 15.68391 Test MSE 8.128828167498304 Test RE 1.3627683289333126\n",
      "77 Train Loss 15.642542 Test MSE 8.07849445128375 Test RE 1.3585426456473637\n",
      "78 Train Loss 15.583764 Test MSE 8.08547518191602 Test RE 1.359129485959882\n",
      "79 Train Loss 15.550032 Test MSE 8.057236346741455 Test RE 1.3567540038496113\n",
      "80 Train Loss 15.537657 Test MSE 8.059380960689554 Test RE 1.3569345570715836\n",
      "81 Train Loss 15.52101 Test MSE 8.06954137948869 Test RE 1.3577896277575456\n",
      "82 Train Loss 15.487039 Test MSE 8.032543818124406 Test RE 1.3546734272919407\n",
      "83 Train Loss 15.474888 Test MSE 8.016356266646326 Test RE 1.353307738819658\n",
      "84 Train Loss 15.465524 Test MSE 8.017776942861651 Test RE 1.3534276515878643\n",
      "85 Train Loss 15.41942 Test MSE 8.030912708983472 Test RE 1.3545358785623938\n",
      "86 Train Loss 15.391373 Test MSE 8.024311127495823 Test RE 1.3539790354173522\n",
      "87 Train Loss 15.361626 Test MSE 8.012504403791244 Test RE 1.3529825672597486\n",
      "88 Train Loss 15.345331 Test MSE 8.057761365590883 Test RE 1.356798206960446\n",
      "89 Train Loss 15.281559 Test MSE 8.057915146678672 Test RE 1.3568111540371341\n",
      "90 Train Loss 15.24746 Test MSE 8.048922452237546 Test RE 1.3560538369140496\n",
      "91 Train Loss 15.203859 Test MSE 8.013571660543086 Test RE 1.3530726721524475\n",
      "92 Train Loss 15.147953 Test MSE 8.020285274746076 Test RE 1.3536393424518793\n",
      "93 Train Loss 15.103909 Test MSE 8.020843731639033 Test RE 1.3536864689590196\n",
      "94 Train Loss 15.087745 Test MSE 8.00954584126565 Test RE 1.3527327544111616\n",
      "95 Train Loss 15.057646 Test MSE 7.996154868404458 Test RE 1.3516014802065108\n",
      "96 Train Loss 15.019579 Test MSE 8.028243989901938 Test RE 1.3543107997800858\n",
      "97 Train Loss 14.995083 Test MSE 8.044515990191949 Test RE 1.355682593567723\n",
      "98 Train Loss 14.903875 Test MSE 8.044687129148896 Test RE 1.355697013880354\n",
      "99 Train Loss 14.846681 Test MSE 8.096036392341423 Test RE 1.3600168406256998\n",
      "100 Train Loss 14.819303 Test MSE 8.092095103380068 Test RE 1.359685760599507\n",
      "101 Train Loss 14.791285 Test MSE 8.086153219595998 Test RE 1.3591864722014888\n",
      "102 Train Loss 14.770809 Test MSE 8.052577112491358 Test RE 1.3563616640580698\n",
      "103 Train Loss 14.755863 Test MSE 8.045395318024047 Test RE 1.3557566848407783\n",
      "104 Train Loss 14.735586 Test MSE 8.035376501475177 Test RE 1.3549122696000315\n",
      "105 Train Loss 14.71472 Test MSE 8.000912391671688 Test RE 1.352003505893534\n",
      "106 Train Loss 14.705523 Test MSE 8.013122790920443 Test RE 1.353034776333283\n",
      "107 Train Loss 14.6858635 Test MSE 8.002070940479658 Test RE 1.352101388814533\n",
      "108 Train Loss 14.670969 Test MSE 8.007936249060844 Test RE 1.3525968255120464\n",
      "109 Train Loss 14.662159 Test MSE 8.027961056434181 Test RE 1.3542869350826767\n",
      "110 Train Loss 14.657568 Test MSE 8.03158386926613 Test RE 1.3545924780874288\n",
      "111 Train Loss 14.6446495 Test MSE 8.032244203513095 Test RE 1.3546481623356286\n",
      "112 Train Loss 14.62471 Test MSE 8.022010686156754 Test RE 1.3537849394653758\n",
      "113 Train Loss 14.605555 Test MSE 8.006714253503628 Test RE 1.3524936197471045\n",
      "114 Train Loss 14.586281 Test MSE 8.018009709507663 Test RE 1.3534472973407272\n",
      "115 Train Loss 14.570856 Test MSE 8.018600607323412 Test RE 1.3534971684650219\n",
      "116 Train Loss 14.554424 Test MSE 8.002405427051281 Test RE 1.352129647438793\n",
      "117 Train Loss 14.535084 Test MSE 8.003457618384255 Test RE 1.352218536482622\n",
      "118 Train Loss 14.510798 Test MSE 7.9676455932581085 Test RE 1.3491898469417287\n",
      "119 Train Loss 14.486532 Test MSE 7.990708312078432 Test RE 1.3511410821952865\n",
      "120 Train Loss 14.476173 Test MSE 7.987959929889057 Test RE 1.3509087015787355\n",
      "121 Train Loss 14.460994 Test MSE 8.02348800248821 Test RE 1.3539095887964216\n",
      "122 Train Loss 14.44046 Test MSE 7.999842352513896 Test RE 1.3519130946382067\n",
      "123 Train Loss 14.430345 Test MSE 8.007463965613924 Test RE 1.352556938923904\n",
      "124 Train Loss 14.42214 Test MSE 8.025413035668059 Test RE 1.3540719972507422\n",
      "125 Train Loss 14.416225 Test MSE 8.022872857140849 Test RE 1.3538576869833998\n",
      "126 Train Loss 14.408184 Test MSE 7.998423385255626 Test RE 1.351793191932281\n",
      "127 Train Loss 14.402879 Test MSE 8.000725198233633 Test RE 1.3519876897182972\n",
      "128 Train Loss 14.396353 Test MSE 7.997664518927662 Test RE 1.3517290633772274\n",
      "129 Train Loss 14.375366 Test MSE 8.009124142209853 Test RE 1.3526971435509945\n",
      "130 Train Loss 14.348916 Test MSE 7.951608648513904 Test RE 1.3478313664975303\n",
      "131 Train Loss 14.3442135 Test MSE 7.963188040097826 Test RE 1.3488123874534634\n",
      "132 Train Loss 14.334209 Test MSE 7.9516859198399015 Test RE 1.3478379153902444\n",
      "133 Train Loss 14.322174 Test MSE 7.92292307960273 Test RE 1.345398007165046\n",
      "134 Train Loss 14.311083 Test MSE 7.885720067686945 Test RE 1.3422355535347525\n",
      "135 Train Loss 14.29592 Test MSE 7.807422966020501 Test RE 1.3355554201655182\n",
      "136 Train Loss 14.052555 Test MSE 6.710755956001052 Test RE 1.2382085057617462\n",
      "137 Train Loss 12.317245 Test MSE 6.374005522550489 Test RE 1.2067415821204774\n",
      "138 Train Loss 11.505423 Test MSE 6.0924730509866745 Test RE 1.1797904291215517\n",
      "139 Train Loss 11.031666 Test MSE 6.109390094552963 Test RE 1.1814272628281408\n",
      "140 Train Loss 10.733827 Test MSE 5.891806122933595 Test RE 1.1601984581849254\n",
      "141 Train Loss 10.629734 Test MSE 5.982868817982993 Test RE 1.16912998876168\n",
      "142 Train Loss 10.495707 Test MSE 5.972480811463273 Test RE 1.1681145723550403\n",
      "143 Train Loss 10.414137 Test MSE 5.953702865363 Test RE 1.166276804976297\n",
      "144 Train Loss 10.350416 Test MSE 5.907198510257019 Test RE 1.1617129832043473\n",
      "145 Train Loss 10.2952175 Test MSE 5.902878485273015 Test RE 1.1612881162400188\n",
      "146 Train Loss 10.253717 Test MSE 5.876538127236229 Test RE 1.1586942169114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 Train Loss 10.226137 Test MSE 5.834915940981077 Test RE 1.1545835411072558\n",
      "148 Train Loss 10.099112 Test MSE 5.887675276277312 Test RE 1.159791669319157\n",
      "149 Train Loss 10.016837 Test MSE 5.878942277161823 Test RE 1.1589312093125015\n",
      "150 Train Loss 9.954044 Test MSE 5.898732459612584 Test RE 1.160880215579948\n",
      "151 Train Loss 9.906605 Test MSE 5.968796263415414 Test RE 1.1677541996380023\n",
      "152 Train Loss 9.875274 Test MSE 6.009432364457972 Test RE 1.1717225446184787\n",
      "153 Train Loss 9.819817 Test MSE 6.0057706605835195 Test RE 1.1713655096691773\n",
      "154 Train Loss 9.7469845 Test MSE 6.056698543454592 Test RE 1.1763215124774304\n",
      "155 Train Loss 9.717937 Test MSE 5.995545514765541 Test RE 1.1703679286593416\n",
      "156 Train Loss 9.691509 Test MSE 5.937158772275015 Test RE 1.164655258242619\n",
      "157 Train Loss 9.643773 Test MSE 6.005347226092605 Test RE 1.171324215609754\n",
      "158 Train Loss 9.620178 Test MSE 6.0000855321775575 Test RE 1.17081096468135\n",
      "159 Train Loss 9.598818 Test MSE 6.0039857017157034 Test RE 1.1711914275448028\n",
      "160 Train Loss 9.584185 Test MSE 6.000369869738118 Test RE 1.1708387060850243\n",
      "161 Train Loss 9.569039 Test MSE 5.980210779044185 Test RE 1.1688702523072827\n",
      "162 Train Loss 9.540314 Test MSE 5.96515548762544 Test RE 1.1673979988603649\n",
      "163 Train Loss 9.518516 Test MSE 5.9990042328350786 Test RE 1.1707054616712487\n",
      "164 Train Loss 9.4856415 Test MSE 6.005263943658593 Test RE 1.1713160935923062\n",
      "165 Train Loss 9.469711 Test MSE 6.030020842227516 Test RE 1.1737280049568626\n",
      "166 Train Loss 9.448029 Test MSE 6.017922798724823 Test RE 1.1725499873124703\n",
      "167 Train Loss 9.419388 Test MSE 6.028332342055745 Test RE 1.1735636623496135\n",
      "168 Train Loss 9.375922 Test MSE 6.019591062799385 Test RE 1.1727125008189205\n",
      "169 Train Loss 9.333956 Test MSE 5.958448027879193 Test RE 1.1667414797211242\n",
      "170 Train Loss 9.295806 Test MSE 5.965725473836336 Test RE 1.1674537714943656\n",
      "171 Train Loss 9.267814 Test MSE 5.967653739095403 Test RE 1.1676424307514137\n",
      "172 Train Loss 9.25239 Test MSE 5.983276808185907 Test RE 1.1691698513647408\n",
      "173 Train Loss 9.238968 Test MSE 5.98441223339073 Test RE 1.1692807807089372\n",
      "174 Train Loss 9.224447 Test MSE 5.978378179544396 Test RE 1.1686911419673485\n",
      "175 Train Loss 9.217209 Test MSE 5.9778810673631035 Test RE 1.1686425516420906\n",
      "176 Train Loss 9.208872 Test MSE 5.956572644214332 Test RE 1.1665578530367307\n",
      "177 Train Loss 9.190929 Test MSE 5.967330000589648 Test RE 1.1676107586773354\n",
      "178 Train Loss 9.173109 Test MSE 5.96607527778749 Test RE 1.1674879981745596\n",
      "179 Train Loss 9.157221 Test MSE 5.970429790418052 Test RE 1.1679139829039376\n",
      "180 Train Loss 9.151924 Test MSE 5.956703916738855 Test RE 1.166570707421274\n",
      "181 Train Loss 9.13846 Test MSE 5.959334878523787 Test RE 1.1668283049253936\n",
      "182 Train Loss 9.129298 Test MSE 5.98699188302927 Test RE 1.169532769512456\n",
      "183 Train Loss 9.11918 Test MSE 5.982515406353072 Test RE 1.1690954576488122\n",
      "184 Train Loss 9.105304 Test MSE 5.992098292291543 Test RE 1.1700314206043996\n",
      "185 Train Loss 9.097032 Test MSE 6.002944885398446 Test RE 1.1710899076509318\n",
      "186 Train Loss 9.08053 Test MSE 5.995138316111075 Test RE 1.1703281841242774\n",
      "187 Train Loss 9.047013 Test MSE 6.006942644826766 Test RE 1.1714797959973087\n",
      "188 Train Loss 9.02494 Test MSE 5.994049271583073 Test RE 1.1702218815400471\n",
      "189 Train Loss 9.006418 Test MSE 5.9784571955773504 Test RE 1.1686988652185282\n",
      "190 Train Loss 8.992207 Test MSE 5.933968524481724 Test RE 1.1643423107312572\n",
      "191 Train Loss 8.980995 Test MSE 5.950729277179057 Test RE 1.1659855190202084\n",
      "192 Train Loss 8.961755 Test MSE 5.971553656493108 Test RE 1.16802390104939\n",
      "193 Train Loss 8.932272 Test MSE 5.9797638704411105 Test RE 1.1688265759260652\n",
      "194 Train Loss 8.897936 Test MSE 5.999338948020292 Test RE 1.1707381210439138\n",
      "195 Train Loss 8.882011 Test MSE 6.011182685735502 Test RE 1.1718931715148113\n",
      "196 Train Loss 8.847586 Test MSE 6.026481567009174 Test RE 1.1733834990015846\n",
      "197 Train Loss 8.827496 Test MSE 6.061295432538339 Test RE 1.176767827730254\n",
      "198 Train Loss 8.812224 Test MSE 6.044403441955889 Test RE 1.1751269392526413\n",
      "199 Train Loss 8.796823 Test MSE 6.061248905628122 Test RE 1.176763311247206\n",
      "Training time: 282.45\n",
      "KG_atanh\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.80519 Test MSE 8.518829089593602 Test RE 1.3950764671956029\n",
      "1 Train Loss 56.288017 Test MSE 8.732777299166214 Test RE 1.412486327979261\n",
      "2 Train Loss 47.927624 Test MSE 9.047065752125174 Test RE 1.4376790149764074\n",
      "3 Train Loss 45.778496 Test MSE 8.45612145111785 Test RE 1.3899323602333578\n",
      "4 Train Loss 44.559746 Test MSE 8.578051314770118 Test RE 1.3999172990551327\n",
      "5 Train Loss 43.89246 Test MSE 8.686459217628496 Test RE 1.4087354800992342\n",
      "6 Train Loss 43.571632 Test MSE 8.635385632635293 Test RE 1.4045879188762223\n",
      "7 Train Loss 43.24385 Test MSE 8.703285460870092 Test RE 1.4100992266755217\n",
      "8 Train Loss 42.95889 Test MSE 8.816324883322848 Test RE 1.419226961844411\n",
      "9 Train Loss 42.451294 Test MSE 9.263369731624751 Test RE 1.454764047561546\n",
      "10 Train Loss 39.259506 Test MSE 8.313494543965762 Test RE 1.3781607223160397\n",
      "11 Train Loss 36.454605 Test MSE 7.909611267083764 Test RE 1.344267287165309\n",
      "12 Train Loss 32.063835 Test MSE 7.365489234134842 Test RE 1.2972057343116994\n",
      "13 Train Loss 28.645813 Test MSE 6.43585164707374 Test RE 1.212581875645703\n",
      "14 Train Loss 24.404903 Test MSE 5.365167513321079 Test RE 1.1071327642899575\n",
      "15 Train Loss 21.562023 Test MSE 5.350901732433365 Test RE 1.1056598721238478\n",
      "16 Train Loss 18.12339 Test MSE 3.3124058322224723 Test RE 0.8699210314652558\n",
      "17 Train Loss 15.6684065 Test MSE 2.1500410773152034 Test RE 0.7008602656926299\n",
      "18 Train Loss 12.988863 Test MSE 2.2995577780362417 Test RE 0.7248200916868627\n",
      "19 Train Loss 11.218495 Test MSE 1.9356295432202535 Test RE 0.6649962270955005\n",
      "20 Train Loss 9.351524 Test MSE 1.0965605507645915 Test RE 0.5005233806509753\n",
      "21 Train Loss 5.2707043 Test MSE 0.4503149711775015 Test RE 0.32074969580024115\n",
      "22 Train Loss 3.9642665 Test MSE 0.4400869155889493 Test RE 0.3170861614332651\n",
      "23 Train Loss 2.641647 Test MSE 0.22290655705032256 Test RE 0.22566774138299645\n",
      "24 Train Loss 1.7873439 Test MSE 0.14575184723752066 Test RE 0.18247992513998335\n",
      "25 Train Loss 1.2276963 Test MSE 0.06735236666681743 Test RE 0.1240464930380248\n",
      "26 Train Loss 0.9722223 Test MSE 0.07242746216814722 Test RE 0.12863516095259045\n",
      "27 Train Loss 0.7292552 Test MSE 0.04464458468869032 Test RE 0.10099327458498543\n",
      "28 Train Loss 0.57220423 Test MSE 0.05237549310987394 Test RE 0.10938861476133352\n",
      "29 Train Loss 0.47353572 Test MSE 0.06346438741893297 Test RE 0.12041292509747097\n",
      "30 Train Loss 0.38724443 Test MSE 0.044563440675300846 Test RE 0.10090145239885671\n",
      "31 Train Loss 0.32940292 Test MSE 0.03201985504315913 Test RE 0.08552985603668249\n",
      "32 Train Loss 0.29446524 Test MSE 0.03727162624171755 Test RE 0.0922777999007936\n",
      "33 Train Loss 0.272807 Test MSE 0.03357208066882061 Test RE 0.08757843682680189\n",
      "34 Train Loss 0.24364823 Test MSE 0.026451525528976835 Test RE 0.07773801058348682\n",
      "35 Train Loss 0.23047128 Test MSE 0.025263433989286335 Test RE 0.07597212106271946\n",
      "36 Train Loss 0.21292944 Test MSE 0.02319284107661843 Test RE 0.07279223202396874\n",
      "37 Train Loss 0.19079573 Test MSE 0.015144641403718294 Test RE 0.058821698061608134\n",
      "38 Train Loss 0.16455427 Test MSE 0.014025377496017361 Test RE 0.05660637444942018\n",
      "39 Train Loss 0.13829854 Test MSE 0.013188479337821038 Test RE 0.05489154084576653\n",
      "40 Train Loss 0.121801466 Test MSE 0.012755627618546234 Test RE 0.05398324368022836\n",
      "41 Train Loss 0.11605468 Test MSE 0.013732031399529717 Test RE 0.05601127441168508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 0.10728597 Test MSE 0.013703154744884977 Test RE 0.055952351249483376\n",
      "43 Train Loss 0.09852743 Test MSE 0.013243932942797201 Test RE 0.05500682103639765\n",
      "44 Train Loss 0.0937507 Test MSE 0.013025481856144551 Test RE 0.05455128176072169\n",
      "45 Train Loss 0.08423882 Test MSE 0.012136319147435563 Test RE 0.05265644734603376\n",
      "46 Train Loss 0.08092675 Test MSE 0.012974029283031556 Test RE 0.054443432348526284\n",
      "47 Train Loss 0.07670859 Test MSE 0.013638743220932122 Test RE 0.0558206946574377\n",
      "48 Train Loss 0.07271318 Test MSE 0.013426116232577964 Test RE 0.055383865204292185\n",
      "49 Train Loss 0.068944484 Test MSE 0.01357417707752679 Test RE 0.05568840964588866\n",
      "50 Train Loss 0.06596245 Test MSE 0.013060663587092545 Test RE 0.0546249033873202\n",
      "51 Train Loss 0.06400946 Test MSE 0.01094694253079704 Test RE 0.05000972649090621\n",
      "52 Train Loss 0.06139537 Test MSE 0.010686418488138597 Test RE 0.049411057524877657\n",
      "53 Train Loss 0.058508843 Test MSE 0.010322153870342627 Test RE 0.04856162653121197\n",
      "54 Train Loss 0.054652102 Test MSE 0.007483050550184646 Test RE 0.04134732328998585\n",
      "55 Train Loss 0.0503091 Test MSE 0.00726825497506249 Test RE 0.04074958004760747\n",
      "56 Train Loss 0.048071068 Test MSE 0.006814463242525455 Test RE 0.03945698410828425\n",
      "57 Train Loss 0.04717307 Test MSE 0.00744998003431614 Test RE 0.04125585715644825\n",
      "58 Train Loss 0.045369476 Test MSE 0.006898928413262318 Test RE 0.03970076538456698\n",
      "59 Train Loss 0.041825112 Test MSE 0.007825343738145883 Test RE 0.04228241379116809\n",
      "60 Train Loss 0.03971908 Test MSE 0.007397993203523836 Test RE 0.04111166106694133\n",
      "61 Train Loss 0.03803417 Test MSE 0.006810087567132911 Test RE 0.039444314095059094\n",
      "62 Train Loss 0.03664517 Test MSE 0.006418933286422862 Test RE 0.03829477227419437\n",
      "63 Train Loss 0.03529134 Test MSE 0.006362764028036167 Test RE 0.0381268537779755\n",
      "64 Train Loss 0.03359552 Test MSE 0.007036172664219207 Test RE 0.04009371550670862\n",
      "65 Train Loss 0.03114381 Test MSE 0.0066877076002521164 Test RE 0.03908829241944145\n",
      "66 Train Loss 0.029260002 Test MSE 0.006514663978853678 Test RE 0.03857927574576266\n",
      "67 Train Loss 0.027682612 Test MSE 0.005492009328146144 Test RE 0.035422050133620986\n",
      "68 Train Loss 0.02629913 Test MSE 0.004659245972051009 Test RE 0.03262615382801233\n",
      "69 Train Loss 0.02537442 Test MSE 0.004773247548543256 Test RE 0.033022887070739124\n",
      "70 Train Loss 0.024509229 Test MSE 0.0041713140352303965 Test RE 0.030870559706270822\n",
      "71 Train Loss 0.022282638 Test MSE 0.003762350149289525 Test RE 0.02931822449507588\n",
      "72 Train Loss 0.02107339 Test MSE 0.0036235010889927614 Test RE 0.02877214619676396\n",
      "73 Train Loss 0.02019255 Test MSE 0.0033609106490876547 Test RE 0.02771000114072038\n",
      "74 Train Loss 0.019764924 Test MSE 0.0033239976425389903 Test RE 0.027557411022107906\n",
      "75 Train Loss 0.019007681 Test MSE 0.002741197661114958 Test RE 0.02502523915764644\n",
      "76 Train Loss 0.018211655 Test MSE 0.002560130707034708 Test RE 0.024184612298063412\n",
      "77 Train Loss 0.016808625 Test MSE 0.002616469388869537 Test RE 0.02444926959121704\n",
      "78 Train Loss 0.016108828 Test MSE 0.0026103014301894437 Test RE 0.024420434730044065\n",
      "79 Train Loss 0.01448898 Test MSE 0.002253576530000008 Test RE 0.022690507828401266\n",
      "80 Train Loss 0.01392968 Test MSE 0.0022311983298713626 Test RE 0.022577567448414427\n",
      "81 Train Loss 0.0134586245 Test MSE 0.001844853138378117 Test RE 0.02053000050074521\n",
      "82 Train Loss 0.013048976 Test MSE 0.0018295747128187448 Test RE 0.020444812634282928\n",
      "83 Train Loss 0.012592697 Test MSE 0.0017981817449843204 Test RE 0.020268651360919994\n",
      "84 Train Loss 0.01223884 Test MSE 0.001750647116245485 Test RE 0.01999895792216306\n",
      "85 Train Loss 0.011740507 Test MSE 0.0016459128493207078 Test RE 0.019391503284585374\n",
      "86 Train Loss 0.011518026 Test MSE 0.001646822325531223 Test RE 0.01939686009169787\n",
      "87 Train Loss 0.011323679 Test MSE 0.0017742298831202638 Test RE 0.020133209150143203\n",
      "88 Train Loss 0.011168332 Test MSE 0.0017374387567103992 Test RE 0.019923370568855906\n",
      "89 Train Loss 0.011024838 Test MSE 0.001748800905462341 Test RE 0.019988409813692452\n",
      "90 Train Loss 0.010828339 Test MSE 0.0017919862019696185 Test RE 0.020233703932979245\n",
      "91 Train Loss 0.010691491 Test MSE 0.0018128182727715958 Test RE 0.020350973807822293\n",
      "92 Train Loss 0.010419931 Test MSE 0.0018371911402105543 Test RE 0.020487323799968527\n",
      "93 Train Loss 0.010207549 Test MSE 0.001777649228676811 Test RE 0.020152600454244864\n",
      "94 Train Loss 0.010034125 Test MSE 0.0016502423023109242 Test RE 0.01941699049835321\n",
      "95 Train Loss 0.009830557 Test MSE 0.001676496253478948 Test RE 0.019570834929708576\n",
      "96 Train Loss 0.009663779 Test MSE 0.0018238983701108907 Test RE 0.02041307249373687\n",
      "97 Train Loss 0.009540545 Test MSE 0.0018217708405632613 Test RE 0.020401163363324183\n",
      "98 Train Loss 0.009406576 Test MSE 0.0017267019884833813 Test RE 0.01986171541331054\n",
      "99 Train Loss 0.008996247 Test MSE 0.0015645199311892513 Test RE 0.01890595458791737\n",
      "100 Train Loss 0.008102566 Test MSE 0.0014486813849549616 Test RE 0.018192588659879105\n",
      "101 Train Loss 0.0076555097 Test MSE 0.0013659832849538755 Test RE 0.017665696008309594\n",
      "102 Train Loss 0.007376702 Test MSE 0.0012114587597758476 Test RE 0.016636515828947266\n",
      "103 Train Loss 0.007103256 Test MSE 0.001143211653963682 Test RE 0.016161117275330466\n",
      "104 Train Loss 0.0069419453 Test MSE 0.0011418329275349034 Test RE 0.016151369088501916\n",
      "105 Train Loss 0.006830275 Test MSE 0.0011100583096634914 Test RE 0.015925055566966384\n",
      "106 Train Loss 0.006598672 Test MSE 0.001101357819186523 Test RE 0.015862523554991615\n",
      "107 Train Loss 0.006522439 Test MSE 0.001072605122270494 Test RE 0.015654096027165144\n",
      "108 Train Loss 0.006450743 Test MSE 0.0009989989854888748 Test RE 0.015107429764990753\n",
      "109 Train Loss 0.006382677 Test MSE 0.0010216424482034875 Test RE 0.015277684066885424\n",
      "110 Train Loss 0.00630228 Test MSE 0.0010725729224896254 Test RE 0.015653861056142568\n",
      "111 Train Loss 0.0061652036 Test MSE 0.0011616929867455678 Test RE 0.016291225082928473\n",
      "112 Train Loss 0.0059854025 Test MSE 0.0012547642593810236 Test RE 0.016931254202510185\n",
      "113 Train Loss 0.0058566476 Test MSE 0.0012068500845442242 Test RE 0.016604841058040828\n",
      "114 Train Loss 0.0057131303 Test MSE 0.0011674287039723618 Test RE 0.016331393529255136\n",
      "115 Train Loss 0.0056481548 Test MSE 0.0011609073565947248 Test RE 0.016285715433475144\n",
      "116 Train Loss 0.0056225355 Test MSE 0.001140548710443193 Test RE 0.01614228382782043\n",
      "117 Train Loss 0.005584278 Test MSE 0.0011524324589357255 Test RE 0.016226161762502647\n",
      "118 Train Loss 0.0055420524 Test MSE 0.0011699780052903954 Test RE 0.016349215148235948\n",
      "119 Train Loss 0.0054985 Test MSE 0.0011753798639603601 Test RE 0.01638691433728528\n",
      "120 Train Loss 0.005439303 Test MSE 0.001116739233882077 Test RE 0.015972906425025905\n",
      "121 Train Loss 0.005359034 Test MSE 0.001156766764137302 Test RE 0.016256646470639204\n",
      "122 Train Loss 0.0052201585 Test MSE 0.0011102437599926425 Test RE 0.015926385759909276\n",
      "123 Train Loss 0.0051635187 Test MSE 0.0010148555237496884 Test RE 0.015226853530867269\n",
      "124 Train Loss 0.0050800643 Test MSE 0.0010219952823644384 Test RE 0.015280321987575979\n",
      "125 Train Loss 0.0050404365 Test MSE 0.0010182294958368061 Test RE 0.015252144002424889\n",
      "126 Train Loss 0.0049656713 Test MSE 0.0010122929004876666 Test RE 0.015207616628570233\n",
      "127 Train Loss 0.004818805 Test MSE 0.0009515372583299971 Test RE 0.014744191378611446\n",
      "128 Train Loss 0.004707336 Test MSE 0.0009195003276332099 Test RE 0.014493858077758548\n",
      "129 Train Loss 0.0045914454 Test MSE 0.0008419709782003389 Test RE 0.013869366395641326\n",
      "130 Train Loss 0.0045011896 Test MSE 0.0007718601214426638 Test RE 0.013279366645439366\n",
      "131 Train Loss 0.0044570523 Test MSE 0.0007334371328228703 Test RE 0.01294462600069833\n",
      "132 Train Loss 0.004403826 Test MSE 0.0007164322025193629 Test RE 0.01279368370377324\n",
      "133 Train Loss 0.004380233 Test MSE 0.0007316001040565854 Test RE 0.012928404733683334\n",
      "134 Train Loss 0.0043279408 Test MSE 0.0007376909379723412 Test RE 0.012982109995397851\n",
      "135 Train Loss 0.0042125448 Test MSE 0.000730754344155986 Test RE 0.012920929688092967\n",
      "136 Train Loss 0.00410119 Test MSE 0.000703372534507442 Test RE 0.01267654093569448\n",
      "137 Train Loss 0.0040636393 Test MSE 0.0006751527965447013 Test RE 0.012419642525430624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 Train Loss 0.003996616 Test MSE 0.0006870281145745743 Test RE 0.01252839146796573\n",
      "139 Train Loss 0.0038808282 Test MSE 0.0006499422012847382 Test RE 0.012185558213809919\n",
      "140 Train Loss 0.0037614843 Test MSE 0.0006292198188344092 Test RE 0.011989725962130028\n",
      "141 Train Loss 0.0036947122 Test MSE 0.0006086482456090342 Test RE 0.01179210255464291\n",
      "142 Train Loss 0.0036561345 Test MSE 0.0005790608071060138 Test RE 0.011501914791867473\n",
      "143 Train Loss 0.003580798 Test MSE 0.0005940585353179459 Test RE 0.011649912952238835\n",
      "144 Train Loss 0.0034997778 Test MSE 0.0006014831257259137 Test RE 0.011722487660517094\n",
      "145 Train Loss 0.0034571218 Test MSE 0.0005999410795009099 Test RE 0.011707451312960077\n",
      "146 Train Loss 0.0033709693 Test MSE 0.000596725522905403 Test RE 0.01167603443485876\n",
      "147 Train Loss 0.00333884 Test MSE 0.0005658717741215503 Test RE 0.011370173091695348\n",
      "148 Train Loss 0.0032963697 Test MSE 0.0005695603309465994 Test RE 0.011407170348903381\n",
      "149 Train Loss 0.0032467262 Test MSE 0.0005370890123128432 Test RE 0.011077230534330422\n",
      "150 Train Loss 0.0031655238 Test MSE 0.0005522456660409091 Test RE 0.011232442870843384\n",
      "151 Train Loss 0.0030953756 Test MSE 0.0005485261708836652 Test RE 0.011194552485240008\n",
      "152 Train Loss 0.0030694169 Test MSE 0.0005245496142467457 Test RE 0.010947156991319732\n",
      "153 Train Loss 0.00305391 Test MSE 0.000526938433146279 Test RE 0.01097205556097078\n",
      "154 Train Loss 0.003014932 Test MSE 0.0005345394996151025 Test RE 0.01105090795646773\n",
      "155 Train Loss 0.0029643723 Test MSE 0.0005537080406758877 Test RE 0.011247305078624599\n",
      "156 Train Loss 0.002943122 Test MSE 0.0005617348257127606 Test RE 0.011328534590011262\n",
      "157 Train Loss 0.0029021904 Test MSE 0.000553364902312294 Test RE 0.011243819505284858\n",
      "158 Train Loss 0.002850692 Test MSE 0.0005065417868525192 Test RE 0.010757607615051595\n",
      "159 Train Loss 0.002829093 Test MSE 0.0004857737899737802 Test RE 0.010534771001269927\n",
      "160 Train Loss 0.002804323 Test MSE 0.00048262136835434553 Test RE 0.010500532745630486\n",
      "161 Train Loss 0.0027459934 Test MSE 0.00045585498259850354 Test RE 0.010205197484612873\n",
      "162 Train Loss 0.0026751207 Test MSE 0.00043692839105996696 Test RE 0.009991097405967568\n",
      "163 Train Loss 0.0026371805 Test MSE 0.0003989607343663611 Test RE 0.009547136624458415\n",
      "164 Train Loss 0.002607734 Test MSE 0.0004045856822877074 Test RE 0.009614203603456335\n",
      "165 Train Loss 0.002547838 Test MSE 0.00039371232611627293 Test RE 0.009484131481318155\n",
      "166 Train Loss 0.0024807358 Test MSE 0.00039319663804357995 Test RE 0.009477918244226882\n",
      "167 Train Loss 0.0024604995 Test MSE 0.00041306969558940586 Test RE 0.009714483782177735\n",
      "168 Train Loss 0.0024434298 Test MSE 0.00042808308180146307 Test RE 0.009889448940424303\n",
      "169 Train Loss 0.0023870938 Test MSE 0.00047305490744550154 Test RE 0.010395941724983707\n",
      "170 Train Loss 0.0023681938 Test MSE 0.00045715751201784905 Test RE 0.01021976690765118\n",
      "171 Train Loss 0.0023584273 Test MSE 0.00044054737441739635 Test RE 0.01003238912907642\n",
      "172 Train Loss 0.0023448423 Test MSE 0.0004361038563352727 Test RE 0.00998166577242243\n",
      "173 Train Loss 0.0023316094 Test MSE 0.0004376336566876945 Test RE 0.009999157692907273\n",
      "174 Train Loss 0.0023230398 Test MSE 0.0004354007527531647 Test RE 0.009973616111920587\n",
      "175 Train Loss 0.0023004427 Test MSE 0.0004546703876393016 Test RE 0.010191929131864999\n",
      "176 Train Loss 0.0022854796 Test MSE 0.00045543663013297025 Test RE 0.010200513594258062\n",
      "177 Train Loss 0.0022777743 Test MSE 0.0004406995258621838 Test RE 0.010034121418060003\n",
      "178 Train Loss 0.002263175 Test MSE 0.00044169079890054387 Test RE 0.010045400040437365\n",
      "179 Train Loss 0.0022453426 Test MSE 0.0004270577808099085 Test RE 0.009877598740207572\n",
      "180 Train Loss 0.0022198372 Test MSE 0.0004344237373308694 Test RE 0.009962419703440114\n",
      "181 Train Loss 0.0021952412 Test MSE 0.00044725582376884434 Test RE 0.01010848480074328\n",
      "182 Train Loss 0.0021674791 Test MSE 0.0004515714690740154 Test RE 0.010157136938969621\n",
      "183 Train Loss 0.0021445823 Test MSE 0.0004919487795203315 Test RE 0.010601516753871417\n",
      "184 Train Loss 0.0021218844 Test MSE 0.000492427980114971 Test RE 0.010606678893503464\n",
      "185 Train Loss 0.0020715736 Test MSE 0.00048714540260340653 Test RE 0.010549633309378763\n",
      "186 Train Loss 0.0020353277 Test MSE 0.0004422256366859211 Test RE 0.01005148012415982\n",
      "187 Train Loss 0.0019726795 Test MSE 0.0004260197535194887 Test RE 0.009865586952117018\n",
      "188 Train Loss 0.0018922115 Test MSE 0.0003840734372123143 Test RE 0.00936731654401287\n",
      "189 Train Loss 0.0018339247 Test MSE 0.0004146678985922424 Test RE 0.009733258735542684\n",
      "190 Train Loss 0.001788286 Test MSE 0.000402478213053661 Test RE 0.009589130925855952\n",
      "191 Train Loss 0.0017583363 Test MSE 0.0003863815937625665 Test RE 0.009395421645857962\n",
      "192 Train Loss 0.0017292375 Test MSE 0.00037541190133024484 Test RE 0.00926108944164098\n",
      "193 Train Loss 0.001716957 Test MSE 0.0003764200433984693 Test RE 0.009273516104340834\n",
      "194 Train Loss 0.0016922082 Test MSE 0.00037511070357655526 Test RE 0.00925737355111129\n",
      "195 Train Loss 0.0016750142 Test MSE 0.0003800341690911425 Test RE 0.00931792870770419\n",
      "196 Train Loss 0.0016622839 Test MSE 0.0003824284315438882 Test RE 0.009347234676281907\n",
      "197 Train Loss 0.0016425092 Test MSE 0.0003820465177725727 Test RE 0.009342566182708024\n",
      "198 Train Loss 0.0016302118 Test MSE 0.0003952880142396025 Test RE 0.009503090896857311\n",
      "199 Train Loss 0.0016197282 Test MSE 0.0004080636014525726 Test RE 0.009655438220172462\n",
      "Training time: 289.55\n",
      "KG_atanh\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.308678 Test MSE 8.62038097877315 Test RE 1.4033670979761341\n",
      "1 Train Loss 50.102165 Test MSE 7.264110357026548 Test RE 1.2882474070035301\n",
      "2 Train Loss 44.45336 Test MSE 7.958257527331096 Test RE 1.3483947553196702\n",
      "3 Train Loss 43.190178 Test MSE 7.810753846458134 Test RE 1.3358402837542516\n",
      "4 Train Loss 40.62043 Test MSE 7.651524071739876 Test RE 1.3221539740653148\n",
      "5 Train Loss 39.240643 Test MSE 7.401984559644739 Test RE 1.3004155310482264\n",
      "6 Train Loss 37.192543 Test MSE 7.253830961667496 Test RE 1.2873355890455467\n",
      "7 Train Loss 34.927223 Test MSE 6.716527610447623 Test RE 1.2387408582811712\n",
      "8 Train Loss 32.075912 Test MSE 6.7469864467370595 Test RE 1.2415464691343243\n",
      "9 Train Loss 28.383125 Test MSE 5.986258196025938 Test RE 1.1694611060377256\n",
      "10 Train Loss 26.16091 Test MSE 5.917378322337163 Test RE 1.162713536115463\n",
      "11 Train Loss 19.03772 Test MSE 2.842427500416539 Test RE 0.8058473060906598\n",
      "12 Train Loss 15.803417 Test MSE 2.8811403113775946 Test RE 0.8113164183341592\n",
      "13 Train Loss 10.43847 Test MSE 2.387546728922113 Test RE 0.7385569689270965\n",
      "14 Train Loss 8.478136 Test MSE 2.0850246759407645 Test RE 0.6901820495577023\n",
      "15 Train Loss 7.578031 Test MSE 2.03993945914407 Test RE 0.6826792452024119\n",
      "16 Train Loss 7.1238165 Test MSE 2.0989058984809286 Test RE 0.6924757100922037\n",
      "17 Train Loss 6.628682 Test MSE 2.003409863237859 Test RE 0.6765391977172314\n",
      "18 Train Loss 6.2020144 Test MSE 2.1154166355116484 Test RE 0.6951940043700223\n",
      "19 Train Loss 5.949936 Test MSE 2.068143216270984 Test RE 0.6873823320636271\n",
      "20 Train Loss 5.7577534 Test MSE 2.0643210339789437 Test RE 0.6867468548942459\n",
      "21 Train Loss 5.574629 Test MSE 2.1150193293062363 Test RE 0.6951287174999766\n",
      "22 Train Loss 5.3393373 Test MSE 2.15727741140302 Test RE 0.7020387080175988\n",
      "23 Train Loss 5.215253 Test MSE 2.1491967723044945 Test RE 0.7007226408944963\n",
      "24 Train Loss 5.147135 Test MSE 2.174087084409199 Test RE 0.7047685705589258\n",
      "25 Train Loss 5.0623856 Test MSE 2.1400305966591446 Test RE 0.6992267774428776\n",
      "26 Train Loss 4.963978 Test MSE 2.154469159628808 Test RE 0.7015816171819431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 4.901616 Test MSE 2.15628107515237 Test RE 0.7018765713839209\n",
      "28 Train Loss 4.8557587 Test MSE 2.1526063153377177 Test RE 0.7012782431617475\n",
      "29 Train Loss 4.8175864 Test MSE 2.1533411014836497 Test RE 0.7013979226331376\n",
      "30 Train Loss 4.7758436 Test MSE 2.1555729290444865 Test RE 0.7017613099780038\n",
      "31 Train Loss 4.7155094 Test MSE 2.1507824259251724 Test RE 0.7009810859430273\n",
      "32 Train Loss 4.6875443 Test MSE 2.1587666172746633 Test RE 0.702280980938682\n",
      "33 Train Loss 4.663693 Test MSE 2.1531597977563126 Test RE 0.7013683943957214\n",
      "34 Train Loss 4.641127 Test MSE 2.1540197921462747 Test RE 0.7015084473236903\n",
      "35 Train Loss 4.6064224 Test MSE 2.141417145394013 Test RE 0.6994532590213919\n",
      "36 Train Loss 4.5799623 Test MSE 2.1445596309173456 Test RE 0.6999662874961768\n",
      "37 Train Loss 4.560196 Test MSE 2.1438454387317867 Test RE 0.6998497246193303\n",
      "38 Train Loss 4.5457487 Test MSE 2.137920424323362 Test RE 0.6988819569273231\n",
      "39 Train Loss 4.5272365 Test MSE 2.1295982830160898 Test RE 0.6975203848457976\n",
      "40 Train Loss 4.5136814 Test MSE 2.129762026411366 Test RE 0.6975472002695369\n",
      "41 Train Loss 4.5016303 Test MSE 2.1296659993744935 Test RE 0.697531474534702\n",
      "42 Train Loss 4.487621 Test MSE 2.127856376661132 Test RE 0.6972350578528957\n",
      "43 Train Loss 4.474169 Test MSE 2.119383167240342 Test RE 0.6958454641384731\n",
      "44 Train Loss 4.4186296 Test MSE 2.107933180240522 Test RE 0.6939632627920349\n",
      "45 Train Loss 4.1933727 Test MSE 2.0813404026148756 Test RE 0.6895719983580426\n",
      "46 Train Loss 2.731698 Test MSE 1.6200380355698958 Test RE 0.6083740286402636\n",
      "47 Train Loss 1.6960913 Test MSE 1.3108230681371247 Test RE 0.5472428526048526\n",
      "48 Train Loss 1.1635281 Test MSE 1.0111252306141099 Test RE 0.4806296224834675\n",
      "49 Train Loss 0.93246365 Test MSE 0.6374713221112952 Test RE 0.38162637868032784\n",
      "50 Train Loss 0.5011874 Test MSE 0.09427348479351673 Test RE 0.146758356895774\n",
      "51 Train Loss 0.3083568 Test MSE 0.06037294319654695 Test RE 0.1174435673432915\n",
      "52 Train Loss 0.17081602 Test MSE 0.029944790014318438 Test RE 0.0827120331285859\n",
      "53 Train Loss 0.13496569 Test MSE 0.019311611488480554 Test RE 0.06642282128089112\n",
      "54 Train Loss 0.10168146 Test MSE 0.009401692636250722 Test RE 0.04634587487233857\n",
      "55 Train Loss 0.08552521 Test MSE 0.0077891456572979885 Test RE 0.04218450650645139\n",
      "56 Train Loss 0.07026392 Test MSE 0.0069579934874039635 Test RE 0.03987035193943151\n",
      "57 Train Loss 0.06155081 Test MSE 0.00634860148399827 Test RE 0.03808439785373353\n",
      "58 Train Loss 0.051941633 Test MSE 0.005479943019378116 Test RE 0.03538311644007625\n",
      "59 Train Loss 0.04329242 Test MSE 0.005687859333195007 Test RE 0.03604810869711674\n",
      "60 Train Loss 0.037262112 Test MSE 0.004586853009372961 Test RE 0.03237169737343535\n",
      "61 Train Loss 0.033794556 Test MSE 0.005300670003236712 Test RE 0.03479953526696867\n",
      "62 Train Loss 0.031844065 Test MSE 0.005615620141733189 Test RE 0.035818461007147064\n",
      "63 Train Loss 0.027390296 Test MSE 0.004116988385706068 Test RE 0.030668877525963027\n",
      "64 Train Loss 0.02415821 Test MSE 0.003001442874428272 Test RE 0.026186237428107766\n",
      "65 Train Loss 0.021544332 Test MSE 0.0022395677794781344 Test RE 0.02261987317676583\n",
      "66 Train Loss 0.018765146 Test MSE 0.0014722127242206098 Test RE 0.01833974715054773\n",
      "67 Train Loss 0.017331215 Test MSE 0.0015071240309288626 Test RE 0.018555922825730656\n",
      "68 Train Loss 0.016383082 Test MSE 0.0014211693118657016 Test RE 0.018019011844271477\n",
      "69 Train Loss 0.014617143 Test MSE 0.001175461613043302 Test RE 0.01638748419217571\n",
      "70 Train Loss 0.013857134 Test MSE 0.0012325665316939552 Test RE 0.016780822582510232\n",
      "71 Train Loss 0.012561465 Test MSE 0.0015283285809959348 Test RE 0.01868600357947298\n",
      "72 Train Loss 0.011473957 Test MSE 0.0017234605153934274 Test RE 0.019843063827811466\n",
      "73 Train Loss 0.010506057 Test MSE 0.0014385086914024598 Test RE 0.018128601621418067\n",
      "74 Train Loss 0.009586342 Test MSE 0.0015246524998462948 Test RE 0.018663517374014206\n",
      "75 Train Loss 0.008697029 Test MSE 0.0014248844518733633 Test RE 0.018042548610295108\n",
      "76 Train Loss 0.008291198 Test MSE 0.0012240545188385904 Test RE 0.016722778640362448\n",
      "77 Train Loss 0.007903212 Test MSE 0.001289278318526499 Test RE 0.017162533578038038\n",
      "78 Train Loss 0.0075308215 Test MSE 0.001263056692236055 Test RE 0.016987109348773774\n",
      "79 Train Loss 0.0072814906 Test MSE 0.0011975666350338811 Test RE 0.016540853080770804\n",
      "80 Train Loss 0.006872314 Test MSE 0.0013012798220397347 Test RE 0.017242228970256707\n",
      "81 Train Loss 0.0064108726 Test MSE 0.0012483970279296263 Test RE 0.01688824121243808\n",
      "82 Train Loss 0.006210001 Test MSE 0.0012660548778233563 Test RE 0.017007259005725455\n",
      "83 Train Loss 0.0060094697 Test MSE 0.001404522573435833 Test RE 0.01791316895176483\n",
      "84 Train Loss 0.005751154 Test MSE 0.0015168844288916113 Test RE 0.01861591155365322\n",
      "85 Train Loss 0.005464508 Test MSE 0.001375570567209137 Test RE 0.01772758178547653\n",
      "86 Train Loss 0.0050660307 Test MSE 0.0012906056546276089 Test RE 0.017171365879748546\n",
      "87 Train Loss 0.0047809887 Test MSE 0.000974196006593738 Test RE 0.014918708655139652\n",
      "88 Train Loss 0.00451694 Test MSE 0.0010330380607452103 Test RE 0.015362653017817265\n",
      "89 Train Loss 0.0042946953 Test MSE 0.0011171572788385774 Test RE 0.01597589582844929\n",
      "90 Train Loss 0.004115372 Test MSE 0.0011276427622317039 Test RE 0.016050694497954147\n",
      "91 Train Loss 0.0039350586 Test MSE 0.0011666372476677835 Test RE 0.016325856670434687\n",
      "92 Train Loss 0.0037929427 Test MSE 0.0012070566095912128 Test RE 0.016606261768418944\n",
      "93 Train Loss 0.0036529037 Test MSE 0.0011827134909633225 Test RE 0.016437956833792514\n",
      "94 Train Loss 0.0035168126 Test MSE 0.0011157163081136155 Test RE 0.015965589210574865\n",
      "95 Train Loss 0.0032188215 Test MSE 0.0011453267145080876 Test RE 0.01617606024151149\n",
      "96 Train Loss 0.0031463748 Test MSE 0.0010465088061082399 Test RE 0.01546249256690541\n",
      "97 Train Loss 0.0030116267 Test MSE 0.0010085311436365029 Test RE 0.015179334003202132\n",
      "98 Train Loss 0.002907808 Test MSE 0.0009363441861291569 Test RE 0.014626008430013228\n",
      "99 Train Loss 0.0028025133 Test MSE 0.0009299060951344212 Test RE 0.014575639134573127\n",
      "100 Train Loss 0.002719345 Test MSE 0.0009291987816277069 Test RE 0.014570094753444942\n",
      "101 Train Loss 0.002622712 Test MSE 0.0008427433835059064 Test RE 0.013875726660233692\n",
      "102 Train Loss 0.002444979 Test MSE 0.0006713858262339084 Test RE 0.012384946775638058\n",
      "103 Train Loss 0.0023136856 Test MSE 0.0005609350498133241 Test RE 0.011320467156994377\n",
      "104 Train Loss 0.0022358615 Test MSE 0.00057162819471062 Test RE 0.011427859204365367\n",
      "105 Train Loss 0.00218429 Test MSE 0.0005737722088931078 Test RE 0.011449270465124598\n",
      "106 Train Loss 0.0021458417 Test MSE 0.0005560443026168945 Test RE 0.011271007995955274\n",
      "107 Train Loss 0.0020996595 Test MSE 0.00048593154196730284 Test RE 0.010536481412845834\n",
      "108 Train Loss 0.002029173 Test MSE 0.0005372454669319562 Test RE 0.011078843821560679\n",
      "109 Train Loss 0.0019641712 Test MSE 0.0004897347767066945 Test RE 0.010577633925986117\n",
      "110 Train Loss 0.0019405491 Test MSE 0.00048067033428510534 Test RE 0.010479286645272734\n",
      "111 Train Loss 0.0019098143 Test MSE 0.0004931084520215872 Test RE 0.010614004894048328\n",
      "112 Train Loss 0.0018826164 Test MSE 0.0004663661235770501 Test RE 0.010322183095517584\n",
      "113 Train Loss 0.0018195668 Test MSE 0.00041279104444223616 Test RE 0.0097112066006861\n",
      "114 Train Loss 0.0017693322 Test MSE 0.00039260350492726384 Test RE 0.009470766874787637\n",
      "115 Train Loss 0.0017215797 Test MSE 0.00037889760579672263 Test RE 0.009303984769726091\n",
      "116 Train Loss 0.0016412827 Test MSE 0.0003663142718646429 Test RE 0.009148185872170242\n",
      "117 Train Loss 0.0016008418 Test MSE 0.00032648615996591255 Test RE 0.008636553113642621\n",
      "118 Train Loss 0.0015721745 Test MSE 0.0003613209879392552 Test RE 0.009085621799422326\n",
      "119 Train Loss 0.0015449424 Test MSE 0.0003498413441785128 Test RE 0.00894012573449732\n",
      "120 Train Loss 0.0015181205 Test MSE 0.00035447922230824207 Test RE 0.008999190646836717\n",
      "121 Train Loss 0.001447982 Test MSE 0.0003586545717733559 Test RE 0.00905203544522611\n",
      "122 Train Loss 0.0013997131 Test MSE 0.00035957468206515076 Test RE 0.009063639278895046\n",
      "123 Train Loss 0.0013674578 Test MSE 0.00034298765049855 Test RE 0.008852120189265985\n",
      "124 Train Loss 0.0013315878 Test MSE 0.0003029909906594429 Test RE 0.008319992174777475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 Train Loss 0.0012900955 Test MSE 0.0002994712675213435 Test RE 0.00827152602770335\n",
      "126 Train Loss 0.0012650092 Test MSE 0.0003068534041514671 Test RE 0.008372854283951358\n",
      "127 Train Loss 0.0012371958 Test MSE 0.0003221591400717092 Test RE 0.008579130793993367\n",
      "128 Train Loss 0.0012075638 Test MSE 0.0003205168085152105 Test RE 0.00855723512439463\n",
      "129 Train Loss 0.0011903518 Test MSE 0.0003331064770755119 Test RE 0.008723677438252616\n",
      "130 Train Loss 0.0011611612 Test MSE 0.00032348166803815656 Test RE 0.008596722285724081\n",
      "131 Train Loss 0.0011256105 Test MSE 0.00029493062199432226 Test RE 0.008208579215804554\n",
      "132 Train Loss 0.0010846825 Test MSE 0.00027716504664593164 Test RE 0.007957511785059141\n",
      "133 Train Loss 0.00104857 Test MSE 0.00027609050196953283 Test RE 0.007942071516318802\n",
      "134 Train Loss 0.0010217758 Test MSE 0.000273027717085197 Test RE 0.007897896337136733\n",
      "135 Train Loss 0.000993774 Test MSE 0.0002717627832116421 Test RE 0.007879579671620361\n",
      "136 Train Loss 0.00097579625 Test MSE 0.00025770832984067175 Test RE 0.007673125269910191\n",
      "137 Train Loss 0.0009545568 Test MSE 0.00026455648483660754 Test RE 0.007774406879374257\n",
      "138 Train Loss 0.00092997815 Test MSE 0.0002571462008659982 Test RE 0.00766475215928554\n",
      "139 Train Loss 0.0009135759 Test MSE 0.0002546020553693652 Test RE 0.007626741258391492\n",
      "140 Train Loss 0.0008947361 Test MSE 0.0002577076413923767 Test RE 0.007673115020816687\n",
      "141 Train Loss 0.0008799088 Test MSE 0.00023909057112011197 Test RE 0.00739076315377875\n",
      "142 Train Loss 0.00086876185 Test MSE 0.00023654780770885811 Test RE 0.007351357174697917\n",
      "143 Train Loss 0.00084708823 Test MSE 0.00024129406343799837 Test RE 0.007424742200571735\n",
      "144 Train Loss 0.0008293417 Test MSE 0.0002442637416268496 Test RE 0.00747029174237078\n",
      "145 Train Loss 0.0008177678 Test MSE 0.0002488169588058762 Test RE 0.007539595543523702\n",
      "146 Train Loss 0.00080994086 Test MSE 0.0002511349304640588 Test RE 0.00757463345766057\n",
      "147 Train Loss 0.000799195 Test MSE 0.00025432487105647716 Test RE 0.007622588525364314\n",
      "148 Train Loss 0.00078976946 Test MSE 0.00025283573927384513 Test RE 0.0076002397409848255\n",
      "149 Train Loss 0.00077748206 Test MSE 0.0002566130953529956 Test RE 0.00765680290393311\n",
      "150 Train Loss 0.00076607 Test MSE 0.0002579287225185389 Test RE 0.007676405604743088\n",
      "151 Train Loss 0.00073941855 Test MSE 0.00023763111091630894 Test RE 0.00736817122157357\n",
      "152 Train Loss 0.00071746437 Test MSE 0.00022565656881900077 Test RE 0.007180125750597527\n",
      "153 Train Loss 0.0006994561 Test MSE 0.00021622187287006995 Test RE 0.007028422699057635\n",
      "154 Train Loss 0.0006865144 Test MSE 0.00022140410113053786 Test RE 0.00711214972566432\n",
      "155 Train Loss 0.0006715553 Test MSE 0.00020718755476492465 Test RE 0.006880023041665022\n",
      "156 Train Loss 0.0006615281 Test MSE 0.00020814662807600574 Test RE 0.006895928504809388\n",
      "157 Train Loss 0.0006508643 Test MSE 0.00020294474245941243 Test RE 0.006809213675507305\n",
      "158 Train Loss 0.0006331353 Test MSE 0.00020411625870266268 Test RE 0.006828838784547229\n",
      "159 Train Loss 0.0006186842 Test MSE 0.00019643329662791373 Test RE 0.006699086922085908\n",
      "160 Train Loss 0.0006052997 Test MSE 0.00020958155450463754 Test RE 0.00691965734160509\n",
      "161 Train Loss 0.00058721 Test MSE 0.00019449562939355451 Test RE 0.006665964301608405\n",
      "162 Train Loss 0.00057223724 Test MSE 0.00019500645290986262 Test RE 0.0066747123090981275\n",
      "163 Train Loss 0.000553979 Test MSE 0.0001933910728533557 Test RE 0.0066470090737845156\n",
      "164 Train Loss 0.00054562633 Test MSE 0.000195548581834296 Test RE 0.00668398390779255\n",
      "165 Train Loss 0.00053404196 Test MSE 0.00018649971288993983 Test RE 0.006527503961437858\n",
      "166 Train Loss 0.00052131625 Test MSE 0.00018332722549849051 Test RE 0.006471747180660473\n",
      "167 Train Loss 0.0005143477 Test MSE 0.00017871693295531943 Test RE 0.006389853653278408\n",
      "168 Train Loss 0.00050681893 Test MSE 0.00017889988141707016 Test RE 0.006393123390670232\n",
      "169 Train Loss 0.0005017405 Test MSE 0.00018289033651018675 Test RE 0.006464031137385418\n",
      "170 Train Loss 0.0004954865 Test MSE 0.0001785537989250262 Test RE 0.006386936636550135\n",
      "171 Train Loss 0.00048780435 Test MSE 0.00017581607177082813 Test RE 0.006337782726417693\n",
      "172 Train Loss 0.00048364844 Test MSE 0.00017751192229150566 Test RE 0.006368275214182273\n",
      "173 Train Loss 0.00047764843 Test MSE 0.00017004412440644082 Test RE 0.0062328815753165635\n",
      "174 Train Loss 0.00046171082 Test MSE 0.00015396697286164488 Test RE 0.00593091699355202\n",
      "175 Train Loss 0.00045233744 Test MSE 0.0001487634117993861 Test RE 0.0058298331487374455\n",
      "176 Train Loss 0.0004481977 Test MSE 0.00014805715061912172 Test RE 0.005815977983364051\n",
      "177 Train Loss 0.00044208742 Test MSE 0.00014464773562806692 Test RE 0.005748623686241791\n",
      "178 Train Loss 0.00043744454 Test MSE 0.00014585265780375404 Test RE 0.005772517178535983\n",
      "179 Train Loss 0.0004333389 Test MSE 0.00014626873786479863 Test RE 0.005780745066957942\n",
      "180 Train Loss 0.00042678072 Test MSE 0.00014423571306273184 Test RE 0.005740430499668155\n",
      "181 Train Loss 0.0004195706 Test MSE 0.00015366233677722513 Test RE 0.005925046689381254\n",
      "182 Train Loss 0.00040954014 Test MSE 0.00015194585154018305 Test RE 0.005891860884575521\n",
      "183 Train Loss 0.00039868825 Test MSE 0.00014785947571841978 Test RE 0.005812094155864474\n",
      "184 Train Loss 0.00039517973 Test MSE 0.00014835677064947882 Test RE 0.005821859843093554\n",
      "185 Train Loss 0.00038876562 Test MSE 0.00015238046026179875 Test RE 0.005900281073951229\n",
      "186 Train Loss 0.0003793209 Test MSE 0.00015797974578956757 Test RE 0.006007707303417009\n",
      "187 Train Loss 0.00037266166 Test MSE 0.00015546337353234928 Test RE 0.005959668511241897\n",
      "188 Train Loss 0.0003673656 Test MSE 0.00016400701123954787 Test RE 0.006121238025727773\n",
      "189 Train Loss 0.00034988608 Test MSE 0.00015464744500741237 Test RE 0.00594400867933681\n",
      "190 Train Loss 0.00034130146 Test MSE 0.00015114268779383794 Test RE 0.005876268491193405\n",
      "191 Train Loss 0.00033722576 Test MSE 0.00015085741417636972 Test RE 0.005870720303107719\n",
      "192 Train Loss 0.00032745895 Test MSE 0.00016070311330036084 Test RE 0.006059268611515275\n",
      "193 Train Loss 0.00032220242 Test MSE 0.00015344642495131937 Test RE 0.005920882567659215\n",
      "194 Train Loss 0.0003123097 Test MSE 0.00014067218799216122 Test RE 0.0056690747246430605\n",
      "195 Train Loss 0.0003012224 Test MSE 0.0001347984310548018 Test RE 0.005549456851316576\n",
      "196 Train Loss 0.0002949394 Test MSE 0.00012564230089580518 Test RE 0.005357670501147243\n",
      "197 Train Loss 0.00029062515 Test MSE 0.00011785882343278858 Test RE 0.005189065000852453\n",
      "198 Train Loss 0.0002877034 Test MSE 0.00011791567019165387 Test RE 0.0051903162689258524\n",
      "199 Train Loss 0.00028353924 Test MSE 0.00011491372466968758 Test RE 0.00512382172839823\n",
      "Training time: 218.27\n",
      "KG_atanh\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54.48372 Test MSE 8.401700233242618 Test RE 1.3854525341214248\n",
      "1 Train Loss 45.67131 Test MSE 8.455849178356354 Test RE 1.3899099833215223\n",
      "2 Train Loss 42.58535 Test MSE 8.176790723530136 Test RE 1.3667827896085447\n",
      "3 Train Loss 41.53782 Test MSE 8.378034626498174 Test RE 1.383499911722688\n",
      "4 Train Loss 39.528404 Test MSE 8.161629802143842 Test RE 1.3655150978409236\n",
      "5 Train Loss 38.792637 Test MSE 7.795536564945382 Test RE 1.3345383756007867\n",
      "6 Train Loss 37.64734 Test MSE 7.06948708337382 Test RE 1.270872589827222\n",
      "7 Train Loss 30.588627 Test MSE 6.500624985165487 Test RE 1.2186685868772582\n",
      "8 Train Loss 25.698547 Test MSE 6.114430275846849 Test RE 1.1819144947680356\n",
      "9 Train Loss 24.217426 Test MSE 5.772706234550151 Test RE 1.1484121774039464\n",
      "10 Train Loss 23.3522 Test MSE 5.7308041440495066 Test RE 1.1442366217272422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 22.622442 Test MSE 5.374758789878187 Test RE 1.1081219295807545\n",
      "12 Train Loss 21.39861 Test MSE 5.641940697248476 Test RE 1.1353305357431638\n",
      "13 Train Loss 19.032673 Test MSE 5.470059246437183 Test RE 1.1179028809871947\n",
      "14 Train Loss 17.039734 Test MSE 5.634328877214452 Test RE 1.1345644120843967\n",
      "15 Train Loss 15.999183 Test MSE 5.761827029036145 Test RE 1.147329521923315\n",
      "16 Train Loss 15.347544 Test MSE 5.656260314005761 Test RE 1.1367703945131018\n",
      "17 Train Loss 14.520413 Test MSE 5.606374150957509 Test RE 1.1317463412519129\n",
      "18 Train Loss 13.704258 Test MSE 5.593930734197772 Test RE 1.1304896810712457\n",
      "19 Train Loss 13.043776 Test MSE 5.846919028329187 Test RE 1.155770485991539\n",
      "20 Train Loss 12.380928 Test MSE 5.918792901064318 Test RE 1.1628525040383937\n",
      "21 Train Loss 11.92978 Test MSE 5.961085534888688 Test RE 1.16699968020819\n",
      "22 Train Loss 11.605602 Test MSE 5.998258153798639 Test RE 1.1706326607590178\n",
      "23 Train Loss 11.318169 Test MSE 5.89189444982034 Test RE 1.1602071546976427\n",
      "24 Train Loss 11.12064 Test MSE 5.903387422697087 Test RE 1.1613381774300993\n",
      "25 Train Loss 10.87907 Test MSE 5.801158306584102 Test RE 1.1512388017320345\n",
      "26 Train Loss 10.612556 Test MSE 5.809020306933577 Test RE 1.1520186438654287\n",
      "27 Train Loss 10.261461 Test MSE 5.78330342492978 Test RE 1.1494657874345515\n",
      "28 Train Loss 9.1812 Test MSE 5.496371552828995 Test RE 1.1205883468826778\n",
      "29 Train Loss 8.123506 Test MSE 4.677280296959485 Test RE 1.0337243790814474\n",
      "30 Train Loss 7.5802207 Test MSE 4.189718213915239 Test RE 0.9783640083464117\n",
      "31 Train Loss 7.2020073 Test MSE 3.898315535867943 Test RE 0.9437273786420713\n",
      "32 Train Loss 6.9554586 Test MSE 3.80325128998688 Test RE 0.932149499880532\n",
      "33 Train Loss 6.757804 Test MSE 3.722483367761856 Test RE 0.9221985674963051\n",
      "34 Train Loss 6.612742 Test MSE 3.733080102962531 Test RE 0.923510238802738\n",
      "35 Train Loss 6.4779763 Test MSE 3.7600361097334 Test RE 0.9268385052564545\n",
      "36 Train Loss 6.344904 Test MSE 3.6839724545044548 Test RE 0.9174158676131345\n",
      "37 Train Loss 6.200682 Test MSE 3.643646776730568 Test RE 0.9123809202436375\n",
      "38 Train Loss 5.433455 Test MSE 3.0465734305877374 Test RE 0.834283943699898\n",
      "39 Train Loss 3.2695594 Test MSE 2.5341734635081172 Test RE 0.7608976271030425\n",
      "40 Train Loss 2.9056797 Test MSE 2.3257134004894704 Test RE 0.7289305595595926\n",
      "41 Train Loss 2.511309 Test MSE 2.4244190201630405 Test RE 0.7442381039569977\n",
      "42 Train Loss 2.0459795 Test MSE 2.4218308658795733 Test RE 0.7438407474423145\n",
      "43 Train Loss 1.8619214 Test MSE 2.3313528422124197 Test RE 0.7298137880046963\n",
      "44 Train Loss 1.7534134 Test MSE 2.315598052307406 Test RE 0.7273436440659571\n",
      "45 Train Loss 1.6269069 Test MSE 2.1141514980578524 Test RE 0.6949860908325453\n",
      "46 Train Loss 1.4486172 Test MSE 1.850913489866039 Test RE 0.650281083397356\n",
      "47 Train Loss 1.2727199 Test MSE 1.6474285517890181 Test RE 0.6134954618940927\n",
      "48 Train Loss 0.89343077 Test MSE 0.8139749061732765 Test RE 0.43123456958042\n",
      "49 Train Loss 0.58941126 Test MSE 0.4367101363691966 Test RE 0.315867320604644\n",
      "50 Train Loss 0.33998436 Test MSE 0.05570233927393808 Test RE 0.1128092670120036\n",
      "51 Train Loss 0.22706114 Test MSE 0.04443543352065347 Test RE 0.10075642997403268\n",
      "52 Train Loss 0.1487733 Test MSE 0.021253168061630447 Test RE 0.06968188628881918\n",
      "53 Train Loss 0.10465523 Test MSE 0.020359634780018038 Test RE 0.06820136265042524\n",
      "54 Train Loss 0.07072458 Test MSE 0.009397938684749838 Test RE 0.04633662135046549\n",
      "55 Train Loss 0.048520286 Test MSE 0.006071872172734701 Test RE 0.037245119351949775\n",
      "56 Train Loss 0.040520042 Test MSE 0.0051155027257525 Test RE 0.03418630952870471\n",
      "57 Train Loss 0.032948345 Test MSE 0.003682953729367705 Test RE 0.0290072255311675\n",
      "58 Train Loss 0.0271318 Test MSE 0.002639695456251985 Test RE 0.024557546367111608\n",
      "59 Train Loss 0.021801203 Test MSE 0.0021835460585975567 Test RE 0.022335168790228184\n",
      "60 Train Loss 0.019503795 Test MSE 0.0019577544178250215 Test RE 0.021148869949300913\n",
      "61 Train Loss 0.016300445 Test MSE 0.0020576680295781263 Test RE 0.02168181903126212\n",
      "62 Train Loss 0.014814543 Test MSE 0.0016224786148594523 Test RE 0.019252961878762378\n",
      "63 Train Loss 0.0131073 Test MSE 0.001119587121762094 Test RE 0.015993260363002176\n",
      "64 Train Loss 0.011650078 Test MSE 0.0011533688145224917 Test RE 0.0162327523319406\n",
      "65 Train Loss 0.0101575125 Test MSE 0.001042318700794935 Test RE 0.015431506466020735\n",
      "66 Train Loss 0.008980433 Test MSE 0.0010803315321696464 Test RE 0.01571037625931644\n",
      "67 Train Loss 0.008348041 Test MSE 0.0008723648910200255 Test RE 0.014117478976156967\n",
      "68 Train Loss 0.0071427864 Test MSE 0.0008179097081366358 Test RE 0.013669755344182277\n",
      "69 Train Loss 0.0067117168 Test MSE 0.0008070785148278449 Test RE 0.013578942626565033\n",
      "70 Train Loss 0.006002214 Test MSE 0.0007249326279110557 Test RE 0.01286935804518268\n",
      "71 Train Loss 0.0054633804 Test MSE 0.0007178274040426879 Test RE 0.012806135046055604\n",
      "72 Train Loss 0.0048831366 Test MSE 0.0006171370296446118 Test RE 0.011874049722882545\n",
      "73 Train Loss 0.004252067 Test MSE 0.0006134575783603788 Test RE 0.011838599489299637\n",
      "74 Train Loss 0.0038264182 Test MSE 0.0007919426430432 Test RE 0.013451010899828593\n",
      "75 Train Loss 0.0034264163 Test MSE 0.0006421640070797466 Test RE 0.012112423308158395\n",
      "76 Train Loss 0.0031463215 Test MSE 0.0005548898141820326 Test RE 0.011259301186337075\n",
      "77 Train Loss 0.0029349094 Test MSE 0.0006094391483955406 Test RE 0.011799761641006356\n",
      "78 Train Loss 0.0027576727 Test MSE 0.0005782594988350598 Test RE 0.01149395382296687\n",
      "79 Train Loss 0.00243612 Test MSE 0.00046202588293529657 Test RE 0.010274039074274096\n",
      "80 Train Loss 0.0023392218 Test MSE 0.0004702584683229892 Test RE 0.010365168648760026\n",
      "81 Train Loss 0.0022840817 Test MSE 0.0004963572867725558 Test RE 0.010648912566254339\n",
      "82 Train Loss 0.002172944 Test MSE 0.00048528647247961617 Test RE 0.010529485551044694\n",
      "83 Train Loss 0.002060635 Test MSE 0.0005268814211130599 Test RE 0.010971461984873723\n",
      "84 Train Loss 0.001975657 Test MSE 0.0004859954306617447 Test RE 0.010537174041188008\n",
      "85 Train Loss 0.0018762175 Test MSE 0.0004526274039676173 Test RE 0.010169005506282604\n",
      "86 Train Loss 0.0018270089 Test MSE 0.0004314951394315162 Test RE 0.009928782891562741\n",
      "87 Train Loss 0.0017945195 Test MSE 0.0004173098884622171 Test RE 0.009764216450157641\n",
      "88 Train Loss 0.0017526168 Test MSE 0.0004159844721096406 Test RE 0.009748698072992949\n",
      "89 Train Loss 0.001671437 Test MSE 0.0003777090593925817 Test RE 0.009289380687905387\n",
      "90 Train Loss 0.0016090579 Test MSE 0.00035929101111747253 Test RE 0.009060063389712728\n",
      "91 Train Loss 0.0015257382 Test MSE 0.00035547223137174106 Test RE 0.009011786629514549\n",
      "92 Train Loss 0.0014930647 Test MSE 0.00036933990914550155 Test RE 0.009185888705629636\n",
      "93 Train Loss 0.0014469074 Test MSE 0.00033517448368591845 Test RE 0.008750714902664108\n",
      "94 Train Loss 0.0013881088 Test MSE 0.00032486419703069966 Test RE 0.008615073473711677\n",
      "95 Train Loss 0.00133232 Test MSE 0.0003106531736159846 Test RE 0.00842453536295437\n",
      "96 Train Loss 0.0012932624 Test MSE 0.00029078604843669104 Test RE 0.008150698773647795\n",
      "97 Train Loss 0.0012677591 Test MSE 0.00028062255243727535 Test RE 0.008006991095350427\n",
      "98 Train Loss 0.0012270889 Test MSE 0.0002690805337314444 Test RE 0.007840598235618076\n",
      "99 Train Loss 0.0011249002 Test MSE 0.00022434421819847225 Test RE 0.007159216581810301\n",
      "100 Train Loss 0.0010698603 Test MSE 0.00020533862665886283 Test RE 0.00684925581018941\n",
      "101 Train Loss 0.0010476134 Test MSE 0.00021252687310056973 Test RE 0.006968109817417613\n",
      "102 Train Loss 0.0010190619 Test MSE 0.00021045076361021745 Test RE 0.006933991632332368\n",
      "103 Train Loss 0.0009961074 Test MSE 0.00019548478672569227 Test RE 0.006682893538692841\n",
      "104 Train Loss 0.00096287765 Test MSE 0.00018110088402500423 Test RE 0.0064323304199260444\n",
      "105 Train Loss 0.00092446577 Test MSE 0.00019325555469643153 Test RE 0.006644679730792515\n",
      "106 Train Loss 0.00088384585 Test MSE 0.00017876375780597614 Test RE 0.006390690687414933\n",
      "107 Train Loss 0.00084711704 Test MSE 0.00017445584652165717 Test RE 0.006313218558761638\n",
      "108 Train Loss 0.00081933034 Test MSE 0.00017277420910777132 Test RE 0.006282717280385389\n",
      "109 Train Loss 0.00080415315 Test MSE 0.00017448339262859358 Test RE 0.0063137169591671715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Train Loss 0.0007768777 Test MSE 0.00017687549164635143 Test RE 0.006356848925920569\n",
      "111 Train Loss 0.00075655954 Test MSE 0.00017909695240874696 Test RE 0.006396643662400675\n",
      "112 Train Loss 0.0007413983 Test MSE 0.00017868302255052106 Test RE 0.006389247407412642\n",
      "113 Train Loss 0.00071198307 Test MSE 0.00018108713789094952 Test RE 0.006432086298107951\n",
      "114 Train Loss 0.0006593742 Test MSE 0.00014566234954838735 Test RE 0.005768749964853326\n",
      "115 Train Loss 0.00062501733 Test MSE 0.00014681698379005062 Test RE 0.005791568656996954\n",
      "116 Train Loss 0.00060971495 Test MSE 0.00013942647031712284 Test RE 0.005643917759471923\n",
      "117 Train Loss 0.0006001606 Test MSE 0.0001375524581596529 Test RE 0.005605859880016743\n",
      "118 Train Loss 0.0005870204 Test MSE 0.00013620809738085245 Test RE 0.005578398347584746\n",
      "119 Train Loss 0.0005782358 Test MSE 0.0001339109163768123 Test RE 0.005531157832158413\n",
      "120 Train Loss 0.000571889 Test MSE 0.00013146445791628475 Test RE 0.005480399749047373\n",
      "121 Train Loss 0.00055848673 Test MSE 0.00012800906458515328 Test RE 0.005407897136314878\n",
      "122 Train Loss 0.00054791215 Test MSE 0.00012350959501759168 Test RE 0.005312004192455556\n",
      "123 Train Loss 0.000527804 Test MSE 0.00011676273122564566 Test RE 0.005164879372041794\n",
      "124 Train Loss 0.00050837593 Test MSE 0.00010625833030803298 Test RE 0.0049270793200143935\n",
      "125 Train Loss 0.00049900706 Test MSE 0.0001011224975378847 Test RE 0.004806533283039398\n",
      "126 Train Loss 0.00049002987 Test MSE 0.00010222120385748493 Test RE 0.004832574477916103\n",
      "127 Train Loss 0.00048024728 Test MSE 8.949136084169383e-05 Test RE 0.004521667426668281\n",
      "128 Train Loss 0.0004734898 Test MSE 8.099389801817045e-05 Test RE 0.004301641474143523\n",
      "129 Train Loss 0.00046423823 Test MSE 8.027311701883113e-05 Test RE 0.004282458113003624\n",
      "130 Train Loss 0.00045167888 Test MSE 7.46039333816741e-05 Test RE 0.004128468003623708\n",
      "131 Train Loss 0.00043783936 Test MSE 6.356627563157467e-05 Test RE 0.00381084639291571\n",
      "132 Train Loss 0.00042901046 Test MSE 6.2788703424414e-05 Test RE 0.003787466653439783\n",
      "133 Train Loss 0.00042065172 Test MSE 5.8389295351638105e-05 Test RE 0.003652369247052303\n",
      "134 Train Loss 0.00040986264 Test MSE 5.47554705779576e-05 Test RE 0.003536892158200297\n",
      "135 Train Loss 0.00040048984 Test MSE 5.481341887772312e-05 Test RE 0.003538763228675251\n",
      "136 Train Loss 0.0003943861 Test MSE 5.014125435568653e-05 Test RE 0.0033845868082622663\n",
      "137 Train Loss 0.00038995378 Test MSE 4.913690116210853e-05 Test RE 0.0033505178986875167\n",
      "138 Train Loss 0.00038648205 Test MSE 5.0372042262027196e-05 Test RE 0.0033923670777030565\n",
      "139 Train Loss 0.00037984966 Test MSE 4.9599951266915524e-05 Test RE 0.0033662679728831356\n",
      "140 Train Loss 0.0003761874 Test MSE 4.9199037396537325e-05 Test RE 0.003352635683752115\n",
      "141 Train Loss 0.00037254387 Test MSE 4.645829829376038e-05 Test RE 0.0032579147006549067\n",
      "142 Train Loss 0.00036672875 Test MSE 4.658335413137018e-05 Test RE 0.0032622965598953194\n",
      "143 Train Loss 0.0003621371 Test MSE 4.899788522795311e-05 Test RE 0.0033457749736235704\n",
      "144 Train Loss 0.00035882363 Test MSE 4.795554136148624e-05 Test RE 0.003309995926415441\n",
      "145 Train Loss 0.00035318575 Test MSE 4.927661813844728e-05 Test RE 0.0033552779865483272\n",
      "146 Train Loss 0.0003482762 Test MSE 5.3170517344614015e-05 Test RE 0.0034853267800469072\n",
      "147 Train Loss 0.00034560874 Test MSE 5.4429853321465324e-05 Test RE 0.0035263599648164647\n",
      "148 Train Loss 0.0003421353 Test MSE 5.334578471990287e-05 Test RE 0.003491066441172994\n",
      "149 Train Loss 0.00033740775 Test MSE 5.752175733677582e-05 Test RE 0.003625134572316111\n",
      "150 Train Loss 0.00032792735 Test MSE 5.5637195692424514e-05 Test RE 0.0035652556454366514\n",
      "151 Train Loss 0.0003230868 Test MSE 5.5969880023370045e-05 Test RE 0.0035758990366813815\n",
      "152 Train Loss 0.0003191889 Test MSE 5.562173323692356e-05 Test RE 0.0035647601905811226\n",
      "153 Train Loss 0.00031585485 Test MSE 5.622448363976559e-05 Test RE 0.0035840230829890327\n",
      "154 Train Loss 0.0003105076 Test MSE 5.661256973686541e-05 Test RE 0.0035963710630950623\n",
      "155 Train Loss 0.00030666144 Test MSE 5.682579695644178e-05 Test RE 0.003603137435797079\n",
      "156 Train Loss 0.0003043394 Test MSE 5.945380355608566e-05 Test RE 0.003685512446330894\n",
      "157 Train Loss 0.00030239022 Test MSE 5.8369682435599414e-05 Test RE 0.0036517557816269923\n",
      "158 Train Loss 0.00029888327 Test MSE 5.7713524891366755e-05 Test RE 0.0036311723290097715\n",
      "159 Train Loss 0.00029446982 Test MSE 5.850647387011324e-05 Test RE 0.0036560322875758594\n",
      "160 Train Loss 0.00029005052 Test MSE 5.626058952360328e-05 Test RE 0.00358517368095264\n",
      "161 Train Loss 0.00028500412 Test MSE 5.0484968497961875e-05 Test RE 0.0033961675269475\n",
      "162 Train Loss 0.00028152484 Test MSE 4.708303801875581e-05 Test RE 0.0032797466653895083\n",
      "163 Train Loss 0.00027898717 Test MSE 4.933163200573336e-05 Test RE 0.003357150429646398\n",
      "164 Train Loss 0.00027847954 Test MSE 4.962749989572005e-05 Test RE 0.0033672026834147355\n",
      "165 Train Loss 0.00027817153 Test MSE 4.964306398089786e-05 Test RE 0.0033677306499771205\n",
      "166 Train Loss 0.0002780641 Test MSE 4.944640769490104e-05 Test RE 0.0033610535580910787\n",
      "167 Train Loss 0.00027764367 Test MSE 4.874966384412863e-05 Test RE 0.0033372894300749065\n",
      "168 Train Loss 0.00027764004 Test MSE 4.875098602134007e-05 Test RE 0.00333733468636763\n",
      "169 Train Loss 0.0002776376 Test MSE 4.877147076788359e-05 Test RE 0.0033380357724453564\n",
      "170 Train Loss 0.0002767399 Test MSE 4.8036212000399554e-05 Test RE 0.003312778788188595\n",
      "171 Train Loss 0.00027579349 Test MSE 4.88773774743073e-05 Test RE 0.003341658060852087\n",
      "172 Train Loss 0.00027500317 Test MSE 4.918989588672184e-05 Test RE 0.003352324198228995\n",
      "173 Train Loss 0.00027465093 Test MSE 4.900598192776575e-05 Test RE 0.003346051400008623\n",
      "174 Train Loss 0.000274404 Test MSE 4.901027733390097e-05 Test RE 0.0033461980385843413\n",
      "175 Train Loss 0.00027211398 Test MSE 5.1101690291615824e-05 Test RE 0.003416848264380565\n",
      "176 Train Loss 0.00026940397 Test MSE 5.1718781089438404e-05 Test RE 0.003437416843554945\n",
      "177 Train Loss 0.00026801764 Test MSE 5.09948601210106e-05 Test RE 0.0034132748653970387\n",
      "178 Train Loss 0.00026706865 Test MSE 5.202653103096209e-05 Test RE 0.003447628760604723\n",
      "179 Train Loss 0.0002660148 Test MSE 4.956372893488777e-05 Test RE 0.003365038573024621\n",
      "180 Train Loss 0.0002640774 Test MSE 4.992457734933669e-05 Test RE 0.003377265929092264\n",
      "181 Train Loss 0.00025895142 Test MSE 5.0559106409826895e-05 Test RE 0.003398660272874558\n",
      "182 Train Loss 0.00025618717 Test MSE 5.0030020686084356e-05 Test RE 0.0033808305296855992\n",
      "183 Train Loss 0.0002527505 Test MSE 5.205315336217482e-05 Test RE 0.0034485107353811884\n",
      "184 Train Loss 0.00025105695 Test MSE 5.1239636898685824e-05 Test RE 0.0034214569667450462\n",
      "185 Train Loss 0.00024740488 Test MSE 5.1764683645913135e-05 Test RE 0.003438941930018169\n",
      "186 Train Loss 0.00024415425 Test MSE 4.916024090035932e-05 Test RE 0.0033513135423377653\n",
      "187 Train Loss 0.00024130805 Test MSE 4.8653472323707005e-05 Test RE 0.003333995279593208\n",
      "188 Train Loss 0.00023939733 Test MSE 4.862364276108061e-05 Test RE 0.0033329730825698424\n",
      "189 Train Loss 0.00023736511 Test MSE 4.591450715870835e-05 Test RE 0.0032387917457750545\n",
      "190 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "191 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "192 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "193 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "194 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "195 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "196 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "197 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "198 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "199 Train Loss 0.00023619067 Test MSE 4.5883778594798044e-05 Test RE 0.003237707773817712\n",
      "Training time: 163.25\n",
      "KG_atanh\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.212776 Test MSE 8.970420120229615 Test RE 1.4315761416060302\n",
      "1 Train Loss 45.080498 Test MSE 8.635279540298061 Test RE 1.4045792906296564\n",
      "2 Train Loss 43.88714 Test MSE 8.62595726708734 Test RE 1.4038209244624071\n",
      "3 Train Loss 43.57166 Test MSE 8.457090803391571 Test RE 1.3900120241485108\n",
      "4 Train Loss 43.163174 Test MSE 8.491968952368945 Test RE 1.3928753707087151\n",
      "5 Train Loss 42.978767 Test MSE 8.293428543690633 Test RE 1.3764965075600684\n",
      "6 Train Loss 42.29155 Test MSE 8.117823520732557 Test RE 1.3618455721225973\n",
      "7 Train Loss 42.007114 Test MSE 8.063148130061006 Test RE 1.3572516537021326\n",
      "8 Train Loss 41.425804 Test MSE 8.389893398201657 Test RE 1.3844787097771847\n",
      "9 Train Loss 39.458046 Test MSE 7.618595721368498 Test RE 1.319305960411637\n",
      "10 Train Loss 38.677994 Test MSE 7.866899955305364 Test RE 1.3406329025537527\n",
      "11 Train Loss 38.499485 Test MSE 7.771518184323785 Test RE 1.332480904763962\n",
      "12 Train Loss 37.35615 Test MSE 7.4159876975048995 Test RE 1.301645018460468\n",
      "13 Train Loss 34.22886 Test MSE 7.17151931667012 Test RE 1.2800108370061007\n",
      "14 Train Loss 33.558064 Test MSE 7.236714743296942 Test RE 1.2858158865162082\n",
      "15 Train Loss 33.295853 Test MSE 7.367600338982162 Test RE 1.2973916242793637\n",
      "16 Train Loss 33.081676 Test MSE 7.212317366140613 Test RE 1.2836465996888136\n",
      "17 Train Loss 32.83718 Test MSE 7.2716117159394456 Test RE 1.2889123963948825\n",
      "18 Train Loss 32.518677 Test MSE 7.260303183228486 Test RE 1.287909772776309\n",
      "19 Train Loss 32.28978 Test MSE 7.25982953816801 Test RE 1.2878677619927315\n",
      "20 Train Loss 32.083633 Test MSE 7.165939785335158 Test RE 1.279512807933494\n",
      "21 Train Loss 31.841888 Test MSE 7.166461522315234 Test RE 1.279559386401758\n",
      "22 Train Loss 31.344048 Test MSE 7.285938949157803 Test RE 1.290181541532641\n",
      "23 Train Loss 30.759342 Test MSE 7.2264816008018045 Test RE 1.2849064550633258\n",
      "24 Train Loss 30.380192 Test MSE 7.259522817577237 Test RE 1.287840556138168\n",
      "25 Train Loss 29.916462 Test MSE 7.12731178114965 Test RE 1.2760595405239372\n",
      "26 Train Loss 29.329258 Test MSE 7.050127935472145 Test RE 1.2691313123824255\n",
      "27 Train Loss 29.011253 Test MSE 6.933585393652646 Test RE 1.2585978763300445\n",
      "28 Train Loss 28.620602 Test MSE 6.897948651586624 Test RE 1.2553592843096024\n",
      "29 Train Loss 27.812605 Test MSE 6.629256227269194 Test RE 1.2306667382768846\n",
      "30 Train Loss 25.30045 Test MSE 5.512648929000738 Test RE 1.1222464183331338\n",
      "31 Train Loss 20.829052 Test MSE 4.9909629452216855 Test RE 1.0678253655190668\n",
      "32 Train Loss 16.666271 Test MSE 4.1328662232552595 Test RE 0.9717034265407042\n",
      "33 Train Loss 13.599243 Test MSE 3.95851624904703 Test RE 0.9509863345496897\n",
      "34 Train Loss 9.749088 Test MSE 1.9975453304565969 Test RE 0.6755482636632835\n",
      "35 Train Loss 6.837244 Test MSE 1.908888558605006 Test RE 0.6603867450465687\n",
      "36 Train Loss 5.6320004 Test MSE 1.4975625232579757 Test RE 0.5849254823940512\n",
      "37 Train Loss 3.9521878 Test MSE 0.5883671281330741 Test RE 0.36663359788869276\n",
      "38 Train Loss 3.0538273 Test MSE 0.37648575239819154 Test RE 0.29327992263561026\n",
      "39 Train Loss 2.368588 Test MSE 0.2619781665512063 Test RE 0.244647402730933\n",
      "40 Train Loss 1.8839486 Test MSE 0.16670128008540863 Test RE 0.19515403162256031\n",
      "41 Train Loss 1.5317867 Test MSE 0.13904725432626255 Test RE 0.17823347273685547\n",
      "42 Train Loss 1.2079184 Test MSE 0.1034473414379887 Test RE 0.15373322124006447\n",
      "43 Train Loss 1.0010798 Test MSE 0.08244202648652846 Test RE 0.13724053094171348\n",
      "44 Train Loss 0.8127874 Test MSE 0.07363144183313057 Test RE 0.1296999213370123\n",
      "45 Train Loss 0.6765146 Test MSE 0.04790460200119007 Test RE 0.10461565498166948\n",
      "46 Train Loss 0.5304737 Test MSE 0.049043636572784995 Test RE 0.1058520791931957\n",
      "47 Train Loss 0.4485244 Test MSE 0.0430916046084517 Test RE 0.0992211813222075\n",
      "48 Train Loss 0.33732837 Test MSE 0.035356219785435156 Test RE 0.08987542824487542\n",
      "49 Train Loss 0.31129697 Test MSE 0.02938920414825246 Test RE 0.08194113459592976\n",
      "50 Train Loss 0.2755018 Test MSE 0.031021145458744296 Test RE 0.08418543791551135\n",
      "51 Train Loss 0.23898743 Test MSE 0.02836824893479408 Test RE 0.08050527259888604\n",
      "52 Train Loss 0.21402927 Test MSE 0.025116482492970296 Test RE 0.07575084276829672\n",
      "53 Train Loss 0.19512303 Test MSE 0.023248576361352743 Test RE 0.07287964393833196\n",
      "54 Train Loss 0.18216111 Test MSE 0.021973543355459903 Test RE 0.07085297785173747\n",
      "55 Train Loss 0.16637787 Test MSE 0.018051966831831308 Test RE 0.06422000332616362\n",
      "56 Train Loss 0.1613827 Test MSE 0.01695238317088731 Test RE 0.062233387369026054\n",
      "57 Train Loss 0.15372485 Test MSE 0.014453402286315815 Test RE 0.05746363642508242\n",
      "58 Train Loss 0.1469148 Test MSE 0.013618118050874326 Test RE 0.05577847130525445\n",
      "59 Train Loss 0.14262894 Test MSE 0.0117144463871933 Test RE 0.051733152583773104\n",
      "60 Train Loss 0.13000612 Test MSE 0.011049119808245777 Test RE 0.050242576409008574\n",
      "61 Train Loss 0.12193376 Test MSE 0.010696020854283261 Test RE 0.049433251889210085\n",
      "62 Train Loss 0.11780375 Test MSE 0.010275172609611753 Test RE 0.04845098642468933\n",
      "63 Train Loss 0.11302923 Test MSE 0.009716977241342153 Test RE 0.047116568477456156\n",
      "64 Train Loss 0.10584217 Test MSE 0.008466168008261641 Test RE 0.043979622939547075\n",
      "65 Train Loss 0.099982336 Test MSE 0.009171912339202217 Test RE 0.04577601765153414\n",
      "66 Train Loss 0.096000016 Test MSE 0.00852888099302384 Test RE 0.0441422115285716\n",
      "67 Train Loss 0.086826354 Test MSE 0.008818978014601537 Test RE 0.044886649595394436\n",
      "68 Train Loss 0.08262614 Test MSE 0.007437778162597277 Test RE 0.041222058074780465\n",
      "69 Train Loss 0.07932313 Test MSE 0.006710392621844386 Test RE 0.03915453096746821\n",
      "70 Train Loss 0.07514019 Test MSE 0.00727810006286376 Test RE 0.040777169024110056\n",
      "71 Train Loss 0.0714183 Test MSE 0.007655293285508529 Test RE 0.04182047653372932\n",
      "72 Train Loss 0.068493634 Test MSE 0.007597609405808519 Test RE 0.04166261655079307\n",
      "73 Train Loss 0.065985784 Test MSE 0.007846996367368912 Test RE 0.04234087083931058\n",
      "74 Train Loss 0.061620906 Test MSE 0.007323094322426975 Test RE 0.04090301997344706\n",
      "75 Train Loss 0.060086764 Test MSE 0.006629743263359691 Test RE 0.03891852888394219\n",
      "76 Train Loss 0.058504954 Test MSE 0.0058060544925867315 Test RE 0.03642072729350409\n",
      "77 Train Loss 0.056214932 Test MSE 0.005731445082463077 Test RE 0.036185962434309236\n",
      "78 Train Loss 0.054031253 Test MSE 0.006017018890143082 Test RE 0.03707650149304204\n",
      "79 Train Loss 0.050543606 Test MSE 0.005230014146858763 Test RE 0.03456682508946837\n",
      "80 Train Loss 0.04814657 Test MSE 0.004747364382467085 Test RE 0.03293323126230255\n",
      "81 Train Loss 0.045219682 Test MSE 0.003768833793782365 Test RE 0.029343475616427923\n",
      "82 Train Loss 0.04169613 Test MSE 0.003322615248677941 Test RE 0.02755168009785197\n",
      "83 Train Loss 0.038569618 Test MSE 0.003276251825969494 Test RE 0.027358778181613252\n",
      "84 Train Loss 0.03214883 Test MSE 0.003224782383007024 Test RE 0.027143026242536596\n",
      "85 Train Loss 0.030250682 Test MSE 0.0034199982953268216 Test RE 0.027952522457990285\n",
      "86 Train Loss 0.029292865 Test MSE 0.0038658419887448296 Test RE 0.029718720648991344\n",
      "87 Train Loss 0.028369522 Test MSE 0.0038933576497916554 Test RE 0.02982429665612189\n",
      "88 Train Loss 0.027414544 Test MSE 0.004058158059569827 Test RE 0.030448965307751687\n",
      "89 Train Loss 0.026197623 Test MSE 0.003950861663778042 Test RE 0.030043738415823286\n",
      "90 Train Loss 0.025660824 Test MSE 0.004002735691747162 Test RE 0.03024032937556521\n",
      "91 Train Loss 0.024208657 Test MSE 0.003611709630389843 Test RE 0.028725293440449412\n",
      "92 Train Loss 0.023281297 Test MSE 0.003298154523507056 Test RE 0.027450076546413155\n",
      "93 Train Loss 0.022710118 Test MSE 0.00339453247975949 Test RE 0.027848258686264536\n",
      "94 Train Loss 0.021966489 Test MSE 0.0033502296187241528 Test RE 0.02766593467788161\n",
      "95 Train Loss 0.021151664 Test MSE 0.003058760982380659 Test RE 0.026435092300445173\n",
      "96 Train Loss 0.020610087 Test MSE 0.0031899430577233974 Test RE 0.026996006599793287\n",
      "97 Train Loss 0.020030178 Test MSE 0.003263222772532168 Test RE 0.02730432356375757\n",
      "98 Train Loss 0.018799042 Test MSE 0.0028856417298066183 Test RE 0.025676112221242775\n",
      "99 Train Loss 0.018201914 Test MSE 0.0026703415770407235 Test RE 0.02469968809965618\n",
      "100 Train Loss 0.017507266 Test MSE 0.00231750537507824 Test RE 0.023010096251241653\n",
      "101 Train Loss 0.016301926 Test MSE 0.0017943107236071773 Test RE 0.020246823018296757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 Train Loss 0.014992008 Test MSE 0.0015655782561349628 Test RE 0.018912348006236618\n",
      "103 Train Loss 0.014403475 Test MSE 0.002008469725452264 Test RE 0.021421047546787832\n",
      "104 Train Loss 0.014094072 Test MSE 0.0019811045008628347 Test RE 0.021274617109737628\n",
      "105 Train Loss 0.013738486 Test MSE 0.0018397643783272294 Test RE 0.020501666432672833\n",
      "106 Train Loss 0.013275836 Test MSE 0.002010992978304079 Test RE 0.021434499020120762\n",
      "107 Train Loss 0.012727886 Test MSE 0.002013174850075799 Test RE 0.02144612378719351\n",
      "108 Train Loss 0.011987861 Test MSE 0.0016892780212963924 Test RE 0.019645298229239827\n",
      "109 Train Loss 0.011272298 Test MSE 0.0016195986932418974 Test RE 0.019235867154901616\n",
      "110 Train Loss 0.010672327 Test MSE 0.001846432941895565 Test RE 0.020538788849769556\n",
      "111 Train Loss 0.010501982 Test MSE 0.001785404207125877 Test RE 0.020196510384477832\n",
      "112 Train Loss 0.010101303 Test MSE 0.0017737108938920673 Test RE 0.020130264299815154\n",
      "113 Train Loss 0.009746361 Test MSE 0.0016745326375690287 Test RE 0.0195593702866668\n",
      "114 Train Loss 0.009538955 Test MSE 0.001652592095946149 Test RE 0.019430809587342817\n",
      "115 Train Loss 0.00931417 Test MSE 0.0015912606746564858 Test RE 0.019066840136871467\n",
      "116 Train Loss 0.009056326 Test MSE 0.0014541117961236593 Test RE 0.018226654407075965\n",
      "117 Train Loss 0.008820695 Test MSE 0.0013373050050483454 Test RE 0.017479270176300833\n",
      "118 Train Loss 0.008594289 Test MSE 0.0012787857221858488 Test RE 0.01709255356656352\n",
      "119 Train Loss 0.008188443 Test MSE 0.0013368110984121094 Test RE 0.01747604207023334\n",
      "120 Train Loss 0.0076147765 Test MSE 0.0012515658885443026 Test RE 0.016909661707465426\n",
      "121 Train Loss 0.006713426 Test MSE 0.0011735034099053358 Test RE 0.016373828536193624\n",
      "122 Train Loss 0.006339558 Test MSE 0.0011834916664449954 Test RE 0.016443363684936523\n",
      "123 Train Loss 0.006195094 Test MSE 0.001194441136295618 Test RE 0.01651925420284402\n",
      "124 Train Loss 0.006066264 Test MSE 0.0011391306295449955 Test RE 0.016132245596280743\n",
      "125 Train Loss 0.0059451815 Test MSE 0.0011109076684514595 Test RE 0.01593114691343093\n",
      "126 Train Loss 0.0058057923 Test MSE 0.0011878514363832756 Test RE 0.016473623036750564\n",
      "127 Train Loss 0.0055258432 Test MSE 0.0009132453967432888 Test RE 0.014444476483948612\n",
      "128 Train Loss 0.0053068832 Test MSE 0.0009166735629585668 Test RE 0.014471562129765343\n",
      "129 Train Loss 0.005199681 Test MSE 0.0008522139087623965 Test RE 0.013953474699263996\n",
      "130 Train Loss 0.0051102047 Test MSE 0.0008037633953521283 Test RE 0.013551025802022354\n",
      "131 Train Loss 0.0050232974 Test MSE 0.0007971081880743361 Test RE 0.013494807549875283\n",
      "132 Train Loss 0.0049709654 Test MSE 0.0008519286378291997 Test RE 0.013951139103778808\n",
      "133 Train Loss 0.0049050422 Test MSE 0.0008523548023849246 Test RE 0.013954628091814594\n",
      "134 Train Loss 0.0048685633 Test MSE 0.0008519165886497434 Test RE 0.013951040445061636\n",
      "135 Train Loss 0.0047749495 Test MSE 0.0008511264875943805 Test RE 0.01394456957171508\n",
      "136 Train Loss 0.004647944 Test MSE 0.0008845397230218676 Test RE 0.014215650279060913\n",
      "137 Train Loss 0.0045483685 Test MSE 0.0008941340042917936 Test RE 0.014292538346147911\n",
      "138 Train Loss 0.0044385167 Test MSE 0.0008465110941767022 Test RE 0.013906709651049025\n",
      "139 Train Loss 0.0043539824 Test MSE 0.0008561910618121233 Test RE 0.013985996175221078\n",
      "140 Train Loss 0.004238659 Test MSE 0.0008093580091629865 Test RE 0.013598105135051556\n",
      "141 Train Loss 0.0041089617 Test MSE 0.0008143450280219029 Test RE 0.013639934501194018\n",
      "142 Train Loss 0.0039528785 Test MSE 0.0008797789988722233 Test RE 0.014177343295588783\n",
      "143 Train Loss 0.0038725922 Test MSE 0.0007795777262345858 Test RE 0.013345589782517833\n",
      "144 Train Loss 0.0037724937 Test MSE 0.0008563671852874554 Test RE 0.013987434601583146\n",
      "145 Train Loss 0.0037048045 Test MSE 0.000846734990261128 Test RE 0.013908548641702392\n",
      "146 Train Loss 0.003636145 Test MSE 0.0007562407341948397 Test RE 0.01314431909305792\n",
      "147 Train Loss 0.0035642656 Test MSE 0.0007365898224328852 Test RE 0.012972417493708003\n",
      "148 Train Loss 0.0035145353 Test MSE 0.0006814537153095914 Test RE 0.012477461603874362\n",
      "149 Train Loss 0.0034838184 Test MSE 0.0006502211430846664 Test RE 0.012188172828548755\n",
      "150 Train Loss 0.0034341633 Test MSE 0.0006580042333303806 Test RE 0.01226090151862779\n",
      "151 Train Loss 0.0033907888 Test MSE 0.0006109372872761725 Test RE 0.011814255976612661\n",
      "152 Train Loss 0.0033340533 Test MSE 0.0006052657188896246 Test RE 0.011759289945440348\n",
      "153 Train Loss 0.0032620728 Test MSE 0.0005681723898241978 Test RE 0.01139326300921702\n",
      "154 Train Loss 0.0031737639 Test MSE 0.0005792375765387501 Test RE 0.011503670248103264\n",
      "155 Train Loss 0.0030708984 Test MSE 0.0005499187238296455 Test RE 0.011208753380646136\n",
      "156 Train Loss 0.0030205396 Test MSE 0.0005264995581539308 Test RE 0.010967485421874654\n",
      "157 Train Loss 0.0029434962 Test MSE 0.000488082839545594 Test RE 0.010559779009970665\n",
      "158 Train Loss 0.0028915175 Test MSE 0.00048628934725694894 Test RE 0.010540359855303574\n",
      "159 Train Loss 0.0028116172 Test MSE 0.0004404830555776921 Test RE 0.010031656750200211\n",
      "160 Train Loss 0.002747722 Test MSE 0.0004112622025397494 Test RE 0.00969320636509938\n",
      "161 Train Loss 0.0026887478 Test MSE 0.00042722614120586813 Test RE 0.009879545587496054\n",
      "162 Train Loss 0.0026661344 Test MSE 0.00042979332758154044 Test RE 0.00990918404549813\n",
      "163 Train Loss 0.0026507387 Test MSE 0.0004131456798498662 Test RE 0.00971537723179572\n",
      "164 Train Loss 0.0026426516 Test MSE 0.0004131793281771272 Test RE 0.009715772854396442\n",
      "165 Train Loss 0.002625815 Test MSE 0.0004126708895991747 Test RE 0.00970979313321337\n",
      "166 Train Loss 0.0026082506 Test MSE 0.00041721264675919256 Test RE 0.00976307875323075\n",
      "167 Train Loss 0.002567295 Test MSE 0.0003732829481051654 Test RE 0.009234792381572704\n",
      "168 Train Loss 0.0025074994 Test MSE 0.00038859266025447864 Test RE 0.009422265920289613\n",
      "169 Train Loss 0.0024567747 Test MSE 0.0004051014954492686 Test RE 0.009620330307093852\n",
      "170 Train Loss 0.0024039454 Test MSE 0.0003952025474516219 Test RE 0.009502063490848906\n",
      "171 Train Loss 0.002368424 Test MSE 0.000376112811216217 Test RE 0.009269730832757677\n",
      "172 Train Loss 0.0023293435 Test MSE 0.0003742147690957615 Test RE 0.009246311538659261\n",
      "173 Train Loss 0.0022524209 Test MSE 0.0003643793119546291 Test RE 0.009123992424165067\n",
      "174 Train Loss 0.002202759 Test MSE 0.0003499553083103477 Test RE 0.008941581781249635\n",
      "175 Train Loss 0.002145167 Test MSE 0.0003282848707941075 Test RE 0.008660311125402272\n",
      "176 Train Loss 0.0021274916 Test MSE 0.000342391634575771 Test RE 0.00884442559935645\n",
      "177 Train Loss 0.0021197242 Test MSE 0.00035616274730041684 Test RE 0.0090205352216814\n",
      "178 Train Loss 0.0021097732 Test MSE 0.0003398865139773946 Test RE 0.008812010922150254\n",
      "179 Train Loss 0.002099756 Test MSE 0.0003332580730840156 Test RE 0.008725662275445115\n",
      "180 Train Loss 0.002073292 Test MSE 0.00031025184091303424 Test RE 0.008419091777417448\n",
      "181 Train Loss 0.0020556273 Test MSE 0.0003005602255553142 Test RE 0.008286551127385695\n",
      "182 Train Loss 0.002035473 Test MSE 0.00028777377193094994 Test RE 0.008108371993365506\n",
      "183 Train Loss 0.002021345 Test MSE 0.0002881793054926125 Test RE 0.008114083179830651\n",
      "184 Train Loss 0.0020098295 Test MSE 0.00027957213001898214 Test RE 0.007991991216746543\n",
      "185 Train Loss 0.0020017116 Test MSE 0.0002776901146692993 Test RE 0.007965045667974392\n",
      "186 Train Loss 0.0019801229 Test MSE 0.00026523090498544523 Test RE 0.007784310018462368\n",
      "187 Train Loss 0.0019505346 Test MSE 0.0002702213740189946 Test RE 0.007857201832342954\n",
      "188 Train Loss 0.0019177085 Test MSE 0.0002695244095817121 Test RE 0.007847062505041113\n",
      "189 Train Loss 0.0018996984 Test MSE 0.0002901160325428085 Test RE 0.008141303124877475\n",
      "190 Train Loss 0.0018716053 Test MSE 0.00028291393803346826 Test RE 0.008039614637785767\n",
      "191 Train Loss 0.0018483925 Test MSE 0.0002728136012558832 Test RE 0.007894798856197788\n",
      "192 Train Loss 0.001828659 Test MSE 0.00027546266167831704 Test RE 0.007933036090480853\n",
      "193 Train Loss 0.0018047492 Test MSE 0.00029107377290177756 Test RE 0.008154730218120675\n",
      "194 Train Loss 0.0017858819 Test MSE 0.0002891938495325708 Test RE 0.008128353569764274\n",
      "195 Train Loss 0.0017552271 Test MSE 0.0002781957614714891 Test RE 0.007972294158115378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 Train Loss 0.0017150571 Test MSE 0.0002563765988828073 Test RE 0.007653273808384169\n",
      "197 Train Loss 0.0016710977 Test MSE 0.0002445792129058454 Test RE 0.007475114197899966\n",
      "198 Train Loss 0.001645196 Test MSE 0.00023580879666763808 Test RE 0.00733986481722459\n",
      "199 Train Loss 0.001621026 Test MSE 0.00022661442714905973 Test RE 0.007195348574296366\n",
      "Training time: 176.45\n"
     ]
    }
   ],
   "source": [
    "#for tune_reps in range(25):\n",
    "  \n",
    "max_reps = 10 #10\n",
    "max_iter = 100 #100\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "N_I = 200  #Total number of data points for 'y'\n",
    "N_B = 400\n",
    "N_f = 10000 #Total number of collocation points\n",
    "n_val = 1.0  \n",
    "\n",
    "for reps in range(max_reps):\n",
    "  print(label)\n",
    "  print(reps)\n",
    "\n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []\n",
    "  alpha_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "\n",
    "  layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "  PINN = Sequentialmodel(layers,n_val)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  #elapsed_time[reps] = time.time() - start_time\n",
    "  alpha_full.append(alpha_val)  \n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KG_atanh'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9429/775165135.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"KG_stan_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(25):\n",
    "    if tune_reps not in s:\n",
    "        label = \"KG_stan_tune\"+str(tune_reps)+\".mat\"\n",
    "        data = sio.loadmat(label)\n",
    "        re = np.array(data[\"test_re_loss\"])\n",
    "        print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004882604230251462\n",
      "0.007469841557007549\n",
      "0.00318191798020943\n",
      "0.9473173944667789\n",
      "0.010250175364697234\n",
      "1.176763311247206\n",
      "0.009655438220172462\n",
      "0.00512382172839823\n",
      "0.003237707773817712\n",
      "0.007195348574296366\n",
      "a =  0.21750775611428358\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a+ test_re_full[i][-1]\n",
    "    print(test_re_full[i][-1])\n",
    "    \n",
    "print(\"a = \",a/10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
