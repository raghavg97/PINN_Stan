{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660687406024,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "T7Wci76Yf-U8"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1]).reshape(-1,1)\n",
    "n_value = np.array([1.0,3.0,5.0,8.0,10.0]).reshape(-1,1)\n",
    "r_value = np.array([2,6,8]).reshape(-1,1)\n",
    "\n",
    "LR_tune,N_value,R_value = np.meshgrid(lr_tune,n_value,r_value)\n",
    "\n",
    "LR_tune = LR_tune.flatten('F').reshape(-1,1)\n",
    "N_value = N_value.flatten('F').reshape(-1,1)\n",
    "R_value = R_value.flatten('F').reshape(-1,1)\n",
    "\n",
    "\n",
    "lrnr_tune = np.hstack((LR_tune,N_value,R_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred1 = self.forward(xt_test_tensor[:250000])\n",
    "        y_pred1 = y_pred1.cpu().detach().numpy()\n",
    "        \n",
    "        y_pred2 = self.forward(xt_test_tensor[250000:])\n",
    "          \n",
    "        y_pred2 = y_pred2.cpu().detach().numpy()\n",
    "        \n",
    "        y_pred = np.vstack((y_pred1.reshape(-1,1),y_pred2.reshape(-1,1)))\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    nan_flag = 0\n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        \n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "    return nan_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.716927 Test MSE 8.624173895660407 Test RE 1.4036758006541614\n",
      "1 Train Loss 57.548935 Test MSE 8.65066979123216 Test RE 1.4058303911035586\n",
      "2 Train Loss 51.57218 Test MSE 7.858124119672325 Test RE 1.339884929589584\n",
      "3 Train Loss 38.055145 Test MSE 6.983411295410705 Test RE 1.2631120281764265\n",
      "4 Train Loss 34.26487 Test MSE 7.194038253152867 Test RE 1.2820189115391076\n",
      "5 Train Loss 29.751202 Test MSE 5.994304289866842 Test RE 1.170246774962526\n",
      "6 Train Loss 27.363495 Test MSE 6.242822551172175 Test RE 1.1942590899400825\n",
      "7 Train Loss 24.73497 Test MSE 6.140013691830373 Test RE 1.1843845406831264\n",
      "8 Train Loss 23.69953 Test MSE 6.027656938814059 Test RE 1.173497918553543\n",
      "9 Train Loss 22.728771 Test MSE 5.807186803534169 Test RE 1.1518368234649639\n",
      "10 Train Loss 20.959875 Test MSE 5.68186517602234 Test RE 1.1393404656798993\n",
      "11 Train Loss 18.853096 Test MSE 5.517809776350958 Test RE 1.1227716093647582\n",
      "12 Train Loss 15.811552 Test MSE 5.919093436761225 Test RE 1.1628820264644462\n",
      "13 Train Loss 14.090774 Test MSE 5.811823000039493 Test RE 1.1522965190653744\n",
      "14 Train Loss 12.8451605 Test MSE 6.065063572143002 Test RE 1.177133552892625\n",
      "15 Train Loss 12.066634 Test MSE 6.069308381902707 Test RE 1.1775454062860486\n",
      "16 Train Loss 11.197032 Test MSE 5.996741300296655 Test RE 1.170484635242352\n",
      "17 Train Loss 10.552682 Test MSE 6.004010076774381 Test RE 1.17119380495143\n",
      "18 Train Loss 10.121235 Test MSE 5.961910380271529 Test RE 1.1670804172648646\n",
      "19 Train Loss 9.51321 Test MSE 5.7875385064915355 Test RE 1.149886584175914\n",
      "20 Train Loss 8.701698 Test MSE 5.755642958067029 Test RE 1.146713651995628\n",
      "21 Train Loss 7.919718 Test MSE 5.539104839688322 Test RE 1.124936097562027\n",
      "22 Train Loss 6.743847 Test MSE 5.230364669898112 Test RE 1.0931356175499274\n",
      "23 Train Loss 5.718994 Test MSE 5.013224593326767 Test RE 1.0702041753931673\n",
      "24 Train Loss 4.937068 Test MSE 4.819275897771587 Test RE 1.0492982660686756\n",
      "25 Train Loss 4.2832546 Test MSE 4.704567257060188 Test RE 1.0367353356537738\n",
      "26 Train Loss 3.5269883 Test MSE 4.305407475006536 Test RE 0.9917796445832145\n",
      "27 Train Loss 2.9481795 Test MSE 3.902514508312407 Test RE 0.9442354979463177\n",
      "28 Train Loss 2.51939 Test MSE 3.585960428005955 Test RE 0.905129681257748\n",
      "29 Train Loss 2.1682324 Test MSE 3.1784751081191875 Test RE 0.852152784825678\n",
      "30 Train Loss 2.014334 Test MSE 2.87834721224788 Test RE 0.8109230607719538\n",
      "31 Train Loss 1.7992817 Test MSE 2.71623891337464 Test RE 0.7877565875906325\n",
      "32 Train Loss 1.6171685 Test MSE 2.3263207156807284 Test RE 0.7290257264244874\n",
      "33 Train Loss 1.4735483 Test MSE 2.0479655831695007 Test RE 0.684020924562121\n",
      "34 Train Loss 1.3298788 Test MSE 1.766102356966052 Test RE 0.6352080530244366\n",
      "35 Train Loss 1.174929 Test MSE 1.5894974372337607 Test RE 0.6026122783898673\n",
      "36 Train Loss 1.059467 Test MSE 1.4211527609485501 Test RE 0.5698078681184345\n",
      "37 Train Loss 0.87088126 Test MSE 1.001737777631466 Test RE 0.4783932975353407\n",
      "38 Train Loss 0.7488883 Test MSE 0.8131006817350528 Test RE 0.431002930327156\n",
      "39 Train Loss 0.6285552 Test MSE 0.7019445778255409 Test RE 0.4004603034542848\n",
      "40 Train Loss 0.5008348 Test MSE 0.5211360915714344 Test RE 0.34505127462631857\n",
      "41 Train Loss 0.38597742 Test MSE 0.4564220018776165 Test RE 0.3229173248660792\n",
      "42 Train Loss 0.320049 Test MSE 0.40852276715142494 Test RE 0.3055035018716834\n",
      "43 Train Loss 0.27264225 Test MSE 0.34072276407980734 Test RE 0.27900284731007463\n",
      "44 Train Loss 0.22454815 Test MSE 0.327763968156633 Test RE 0.2736457230477001\n",
      "45 Train Loss 0.19736522 Test MSE 0.3331906530627805 Test RE 0.2759017563483725\n",
      "46 Train Loss 0.18119799 Test MSE 0.32575218549016893 Test RE 0.2728046252896514\n",
      "47 Train Loss 0.16635038 Test MSE 0.30673674013724583 Test RE 0.2647225631383743\n",
      "48 Train Loss 0.15378809 Test MSE 0.25117096388655097 Test RE 0.23954812528250446\n",
      "49 Train Loss 0.13354051 Test MSE 0.15083688450268315 Test RE 0.1856358440706783\n",
      "50 Train Loss 0.120463446 Test MSE 0.10588014037071243 Test RE 0.15553040914648353\n",
      "51 Train Loss 0.09825672 Test MSE 0.05132334064073879 Test RE 0.10828430631493932\n",
      "52 Train Loss 0.08022902 Test MSE 0.027178036724123875 Test RE 0.07879834586070644\n",
      "53 Train Loss 0.0664179 Test MSE 0.018062724481613047 Test RE 0.0642391356848955\n",
      "54 Train Loss 0.057953853 Test MSE 0.016889353803883192 Test RE 0.06211758701863649\n",
      "55 Train Loss 0.049498886 Test MSE 0.012925671954371477 Test RE 0.054341875743042174\n",
      "56 Train Loss 0.043659147 Test MSE 0.012027002772472118 Test RE 0.052418762728905374\n",
      "57 Train Loss 0.03970921 Test MSE 0.012008543387376898 Test RE 0.05237852037954869\n",
      "58 Train Loss 0.035676982 Test MSE 0.010028058548945567 Test RE 0.04786482668936438\n",
      "59 Train Loss 0.032360494 Test MSE 0.009159084203034214 Test RE 0.045743994533766257\n",
      "60 Train Loss 0.028566916 Test MSE 0.008857541773774331 Test RE 0.04498468304864209\n",
      "61 Train Loss 0.025067285 Test MSE 0.008214496169302346 Test RE 0.04332100527563978\n",
      "62 Train Loss 0.0230611 Test MSE 0.0075564079246966615 Test RE 0.04154949576786331\n",
      "63 Train Loss 0.020642377 Test MSE 0.00659370967267206 Test RE 0.03881262093201417\n",
      "64 Train Loss 0.018664163 Test MSE 0.0056288203037223004 Test RE 0.03586053400650925\n",
      "65 Train Loss 0.01695454 Test MSE 0.005506130727507875 Test RE 0.035467560597720285\n",
      "66 Train Loss 0.015531233 Test MSE 0.004680977374841287 Test RE 0.03270215188467572\n",
      "67 Train Loss 0.013967541 Test MSE 0.004388969381858888 Test RE 0.031665717710408284\n",
      "68 Train Loss 0.012968197 Test MSE 0.004399615587227834 Test RE 0.03170409979018414\n",
      "69 Train Loss 0.012098209 Test MSE 0.003629542012714899 Test RE 0.028796119966128044\n",
      "70 Train Loss 0.010813594 Test MSE 0.00359643791719406 Test RE 0.028664498248841735\n",
      "71 Train Loss 0.009633979 Test MSE 0.004025936122287704 Test RE 0.030327841395298462\n",
      "72 Train Loss 0.00875869 Test MSE 0.0035777544874410535 Test RE 0.028589945523484515\n",
      "73 Train Loss 0.007982562 Test MSE 0.0033903443181294004 Test RE 0.027831073844648762\n",
      "74 Train Loss 0.0074143084 Test MSE 0.003443358534273764 Test RE 0.028047824604570084\n",
      "75 Train Loss 0.006424164 Test MSE 0.0033264378840231856 Test RE 0.027567524507043015\n",
      "76 Train Loss 0.00582968 Test MSE 0.003033613941027077 Test RE 0.026326202407108267\n",
      "77 Train Loss 0.005028552 Test MSE 0.0030305441255984566 Test RE 0.026312878853172312\n",
      "78 Train Loss 0.0043560686 Test MSE 0.002784931902199818 Test RE 0.025224080884357156\n",
      "79 Train Loss 0.0038329181 Test MSE 0.002384835778997558 Test RE 0.02334195887770396\n",
      "80 Train Loss 0.003364252 Test MSE 0.0025683405203340117 Test RE 0.024223358801838357\n",
      "81 Train Loss 0.003009249 Test MSE 0.002750213032598182 Test RE 0.025066357431339316\n",
      "82 Train Loss 0.0028152037 Test MSE 0.0028253040365326305 Test RE 0.025406255147013307\n",
      "83 Train Loss 0.0025255491 Test MSE 0.0029277517073636283 Test RE 0.025862778582997095\n",
      "84 Train Loss 0.0023085459 Test MSE 0.0029155213260988314 Test RE 0.02580870250245783\n",
      "85 Train Loss 0.0021034842 Test MSE 0.002836871672549927 Test RE 0.025458212406115985\n",
      "86 Train Loss 0.0019524498 Test MSE 0.0028202600927303223 Test RE 0.025383566443892523\n",
      "87 Train Loss 0.0018332303 Test MSE 0.0027701149539675744 Test RE 0.025156890310709147\n",
      "88 Train Loss 0.0017262571 Test MSE 0.002635944997162259 Test RE 0.02454009457915694\n",
      "89 Train Loss 0.0016559396 Test MSE 0.0025674236110542026 Test RE 0.024219034491067448\n",
      "90 Train Loss 0.0015827868 Test MSE 0.0025834604046775195 Test RE 0.02429455592782074\n",
      "91 Train Loss 0.0015406196 Test MSE 0.00257786022250177 Test RE 0.02426820991723748\n",
      "92 Train Loss 0.0014617079 Test MSE 0.0025023211388938366 Test RE 0.023910000359334417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 0.0014097315 Test MSE 0.0024671255724147195 Test RE 0.02374125582057991\n",
      "94 Train Loss 0.0013788482 Test MSE 0.002466451119873921 Test RE 0.023738010455814924\n",
      "95 Train Loss 0.0013214389 Test MSE 0.002421064881014461 Test RE 0.02351858963153364\n",
      "96 Train Loss 0.0012754087 Test MSE 0.002314903977948302 Test RE 0.02299717822175795\n",
      "97 Train Loss 0.0012498909 Test MSE 0.0022624091562496356 Test RE 0.022734930722153494\n",
      "98 Train Loss 0.0012161564 Test MSE 0.0022441765560646614 Test RE 0.022643135782237478\n",
      "99 Train Loss 0.0011835718 Test MSE 0.0022231198658695535 Test RE 0.022536657265979854\n",
      "Training time: 87.09\n",
      "1\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.916664 Test MSE 8.450399918746545 Test RE 1.3894620566375973\n",
      "1 Train Loss 57.5252 Test MSE 8.573752406572892 Test RE 1.3995664693667624\n",
      "2 Train Loss 57.08161 Test MSE 8.870907386527852 Test RE 1.4236134512913308\n",
      "3 Train Loss 56.139164 Test MSE 8.150893626149736 Test RE 1.3646166722088198\n",
      "4 Train Loss 47.14088 Test MSE 8.817520573032292 Test RE 1.4193231979498055\n",
      "5 Train Loss 44.07721 Test MSE 8.599211363151376 Test RE 1.4016428700125565\n",
      "6 Train Loss 41.630608 Test MSE 7.900198636113936 Test RE 1.3434671935775662\n",
      "7 Train Loss 39.962017 Test MSE 7.898378038419196 Test RE 1.3433123839126813\n",
      "8 Train Loss 39.519966 Test MSE 7.899376004862656 Test RE 1.343397245534429\n",
      "9 Train Loss 39.08209 Test MSE 7.850990591738851 Test RE 1.3392766243120617\n",
      "10 Train Loss 38.752766 Test MSE 7.911947517976889 Test RE 1.344465799688478\n",
      "11 Train Loss 38.178493 Test MSE 7.774923632212254 Test RE 1.332772816664893\n",
      "12 Train Loss 36.752373 Test MSE 8.209425692960242 Test RE 1.3695076053827935\n",
      "13 Train Loss 34.58149 Test MSE 7.9703158043705 Test RE 1.3494159061892312\n",
      "14 Train Loss 32.48125 Test MSE 7.75290944751313 Test RE 1.330884649893398\n",
      "15 Train Loss 28.906467 Test MSE 7.284015836731788 Test RE 1.2900112595746032\n",
      "16 Train Loss 24.56935 Test MSE 7.324627976194931 Test RE 1.293602499335424\n",
      "17 Train Loss 20.45439 Test MSE 6.706507348930058 Test RE 1.2378164862673935\n",
      "18 Train Loss 17.46183 Test MSE 6.75039662413856 Test RE 1.2418601913337666\n",
      "19 Train Loss 15.219045 Test MSE 6.128966591657774 Test RE 1.183318589872247\n",
      "20 Train Loss 11.953101 Test MSE 5.553984174627403 Test RE 1.126446005370819\n",
      "21 Train Loss 7.97219 Test MSE 4.932287988365174 Test RE 1.06153000287692\n",
      "22 Train Loss 5.35487 Test MSE 4.832055213166556 Test RE 1.0506885616377903\n",
      "23 Train Loss 3.9593356 Test MSE 4.468934360757329 Test RE 1.0104388786095595\n",
      "24 Train Loss 3.359335 Test MSE 4.469375295695871 Test RE 1.010488725707266\n",
      "25 Train Loss 2.9279761 Test MSE 4.698575384046773 Test RE 1.0360749172409587\n",
      "26 Train Loss 2.6634467 Test MSE 4.811640307115538 Test RE 1.0484666900963506\n",
      "27 Train Loss 2.3926322 Test MSE 4.895847458734081 Test RE 1.0576013566488636\n",
      "28 Train Loss 2.167007 Test MSE 5.015494318468267 Test RE 1.07044641413608\n",
      "29 Train Loss 1.961894 Test MSE 5.192353379746395 Test RE 1.0891562330861606\n",
      "30 Train Loss 1.8119845 Test MSE 5.3605673649100565 Test RE 1.1066580291419852\n",
      "31 Train Loss 1.669016 Test MSE 5.4232101078498625 Test RE 1.1131053636230113\n",
      "32 Train Loss 1.5748447 Test MSE 5.513403553358809 Test RE 1.122323227641494\n",
      "33 Train Loss 1.4666513 Test MSE 5.629252065136136 Test RE 1.1340531472535125\n",
      "34 Train Loss 1.3413898 Test MSE 5.729318162818015 Test RE 1.1440882634569645\n",
      "35 Train Loss 1.2388572 Test MSE 5.82554471659819 Test RE 1.1536560033868795\n",
      "36 Train Loss 1.1571398 Test MSE 5.844358713160643 Test RE 1.155517407343765\n",
      "37 Train Loss 1.0941706 Test MSE 5.840857444531547 Test RE 1.1551712288175913\n",
      "38 Train Loss 1.0456697 Test MSE 5.9701585663890055 Test RE 1.1678874546685565\n",
      "39 Train Loss 0.98526984 Test MSE 5.978919294649547 Test RE 1.168744031070543\n",
      "40 Train Loss 0.93614185 Test MSE 6.053969701414045 Test RE 1.1760564871323265\n",
      "41 Train Loss 0.9077092 Test MSE 6.0782073560532375 Test RE 1.178408363575547\n",
      "42 Train Loss 0.8798447 Test MSE 6.180498282247032 Test RE 1.1882827846992141\n",
      "43 Train Loss 0.8612864 Test MSE 6.215011283714396 Test RE 1.1915959569918542\n",
      "44 Train Loss 0.84058636 Test MSE 6.247120067433785 Test RE 1.1946700791082943\n",
      "45 Train Loss 0.82479197 Test MSE 6.256115679292692 Test RE 1.1955299090985878\n",
      "46 Train Loss 0.81204665 Test MSE 6.239010646498781 Test RE 1.1938944234040696\n",
      "47 Train Loss 0.79636467 Test MSE 6.301324082456806 Test RE 1.1998417465623399\n",
      "48 Train Loss 0.78532284 Test MSE 6.329344571000106 Test RE 1.2025064928235523\n",
      "49 Train Loss 0.7705986 Test MSE 6.325621235679996 Test RE 1.2021527442239648\n",
      "50 Train Loss 0.75450873 Test MSE 6.349025636804742 Test RE 1.2043746357171463\n",
      "51 Train Loss 0.74466413 Test MSE 6.371037543435453 Test RE 1.2064605970454112\n",
      "52 Train Loss 0.73442376 Test MSE 6.391057888872499 Test RE 1.2083547008166144\n",
      "53 Train Loss 0.72491413 Test MSE 6.427285922076185 Test RE 1.2117746708069355\n",
      "54 Train Loss 0.7112806 Test MSE 6.425044689858116 Test RE 1.2115633759254512\n",
      "55 Train Loss 0.7007943 Test MSE 6.450574008029408 Test RE 1.2139680069074392\n",
      "56 Train Loss 0.692408 Test MSE 6.469837741371638 Test RE 1.215779328081634\n",
      "57 Train Loss 0.68592346 Test MSE 6.489974062132675 Test RE 1.2176698162632087\n",
      "58 Train Loss 0.6799127 Test MSE 6.515574732140615 Test RE 1.2200690925571718\n",
      "59 Train Loss 0.67088425 Test MSE 6.524303771370529 Test RE 1.2208860938797736\n",
      "60 Train Loss 0.66403 Test MSE 6.534051515044406 Test RE 1.2217977959750739\n",
      "61 Train Loss 0.65930235 Test MSE 6.544934613895442 Test RE 1.2228148842185385\n",
      "62 Train Loss 0.65119267 Test MSE 6.5619259181782335 Test RE 1.224401130189298\n",
      "63 Train Loss 0.6442933 Test MSE 6.594070169466998 Test RE 1.2273963923028268\n",
      "64 Train Loss 0.6389288 Test MSE 6.595240210983897 Test RE 1.2275052811226594\n",
      "65 Train Loss 0.63345754 Test MSE 6.59848653283637 Test RE 1.227807346464507\n",
      "66 Train Loss 0.6272589 Test MSE 6.626678423598112 Test RE 1.2304274410173046\n",
      "67 Train Loss 0.62262565 Test MSE 6.650732952784856 Test RE 1.232658614788902\n",
      "68 Train Loss 0.61845684 Test MSE 6.66588986904067 Test RE 1.2340624202718693\n",
      "69 Train Loss 0.6141329 Test MSE 6.665550075770694 Test RE 1.2340309667482372\n",
      "70 Train Loss 0.6092107 Test MSE 6.6708738938593255 Test RE 1.2345236826535184\n",
      "71 Train Loss 0.60399985 Test MSE 6.700287037434363 Test RE 1.2372423133111894\n",
      "72 Train Loss 0.5998639 Test MSE 6.7192445390455795 Test RE 1.2389913768803893\n",
      "73 Train Loss 0.59434426 Test MSE 6.726274025136909 Test RE 1.23963930656128\n",
      "74 Train Loss 0.5900626 Test MSE 6.742735530357496 Test RE 1.2411552913969572\n",
      "75 Train Loss 0.5854756 Test MSE 6.763990323727392 Test RE 1.2431099685717453\n",
      "76 Train Loss 0.5815672 Test MSE 6.781210365138054 Test RE 1.2446913426648525\n",
      "77 Train Loss 0.5772746 Test MSE 6.80382497789205 Test RE 1.2467650715736285\n",
      "78 Train Loss 0.5730561 Test MSE 6.813482094076567 Test RE 1.2476495656540492\n",
      "79 Train Loss 0.568877 Test MSE 6.8168417417460025 Test RE 1.247957128388501\n",
      "80 Train Loss 0.5636578 Test MSE 6.823935086147495 Test RE 1.2486062477629987\n",
      "81 Train Loss 0.56053525 Test MSE 6.832262551915119 Test RE 1.2493678725014512\n",
      "82 Train Loss 0.55601376 Test MSE 6.8483686030149356 Test RE 1.2508396058924127\n",
      "83 Train Loss 0.55303264 Test MSE 6.860832543834953 Test RE 1.2519773442792972\n",
      "84 Train Loss 0.5497116 Test MSE 6.884691335749537 Test RE 1.25415235312297\n",
      "85 Train Loss 0.54692096 Test MSE 6.8910098119068595 Test RE 1.2547277249177886\n",
      "86 Train Loss 0.544585 Test MSE 6.9131089909539405 Test RE 1.2567380440135687\n",
      "87 Train Loss 0.54083174 Test MSE 6.932393449369167 Test RE 1.2584896896605415\n",
      "88 Train Loss 0.5378485 Test MSE 6.92767286821842 Test RE 1.2580611353354154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 Train Loss 0.5358621 Test MSE 6.928980427859229 Test RE 1.2581798557473183\n",
      "90 Train Loss 0.5327472 Test MSE 6.941093609086067 Test RE 1.2592791448657084\n",
      "91 Train Loss 0.5301152 Test MSE 6.94978885416281 Test RE 1.2600676599260312\n",
      "92 Train Loss 0.5271581 Test MSE 6.965054918651592 Test RE 1.2614508474182669\n",
      "93 Train Loss 0.5246218 Test MSE 6.9835430993518 Test RE 1.2631239480212397\n",
      "94 Train Loss 0.5226518 Test MSE 6.98619656571764 Test RE 1.2633638934580287\n",
      "95 Train Loss 0.52058893 Test MSE 6.987626155085014 Test RE 1.2634931482811855\n",
      "96 Train Loss 0.5190482 Test MSE 6.987892666034746 Test RE 1.2635172431268968\n",
      "97 Train Loss 0.51778287 Test MSE 6.986437515441216 Test RE 1.2633856796011314\n",
      "98 Train Loss 0.5162172 Test MSE 6.987586141442689 Test RE 1.2634895306695557\n",
      "99 Train Loss 0.5144913 Test MSE 6.992543216728881 Test RE 1.2639376183349407\n",
      "Training time: 88.05\n",
      "2\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.894188 Test MSE 8.503139876849533 Test RE 1.3937912120140976\n",
      "1 Train Loss 55.810417 Test MSE 8.87120165567874 Test RE 1.423637063421923\n",
      "2 Train Loss 46.985676 Test MSE 7.377366864302498 Test RE 1.2982512536810817\n",
      "3 Train Loss 39.870823 Test MSE 6.683179867718185 Test RE 1.2356618406043518\n",
      "4 Train Loss 33.433098 Test MSE 7.322003095603225 Test RE 1.293370688493285\n",
      "5 Train Loss 28.862398 Test MSE 6.292913303106218 Test RE 1.1990407265084475\n",
      "6 Train Loss 25.130234 Test MSE 6.009123023820458 Test RE 1.1716923865235387\n",
      "7 Train Loss 23.09478 Test MSE 6.016383849119381 Test RE 1.172400050965635\n",
      "8 Train Loss 22.205116 Test MSE 5.692464959561404 Test RE 1.140402716784676\n",
      "9 Train Loss 21.206255 Test MSE 6.098671561867788 Test RE 1.1803904387269184\n",
      "10 Train Loss 18.179783 Test MSE 5.36417263283329 Test RE 1.1070301099134972\n",
      "11 Train Loss 14.082846 Test MSE 5.70008446996241 Test RE 1.141165690702984\n",
      "12 Train Loss 11.192207 Test MSE 5.813773103431656 Test RE 1.152489824064858\n",
      "13 Train Loss 9.996989 Test MSE 5.775602429733011 Test RE 1.1487002233060533\n",
      "14 Train Loss 9.356305 Test MSE 5.66733215579202 Test RE 1.1378824356935486\n",
      "15 Train Loss 8.73038 Test MSE 5.450361443391158 Test RE 1.1158882693177317\n",
      "16 Train Loss 8.077426 Test MSE 5.115753173369053 Test RE 1.0810924924531378\n",
      "17 Train Loss 7.5006475 Test MSE 4.965725816625922 Test RE 1.0651221797895651\n",
      "18 Train Loss 6.730573 Test MSE 4.6929876656340115 Test RE 1.035458664797028\n",
      "19 Train Loss 6.006626 Test MSE 4.532683032838073 Test RE 1.0176202378587214\n",
      "20 Train Loss 5.352772 Test MSE 4.502470743972094 Test RE 1.0142231285327301\n",
      "21 Train Loss 4.8236494 Test MSE 4.157878988761771 Test RE 0.9746394429858638\n",
      "22 Train Loss 4.164895 Test MSE 3.865672623574986 Test RE 0.939767877359158\n",
      "23 Train Loss 3.6032856 Test MSE 3.686752934353466 Test RE 0.9177620123293505\n",
      "24 Train Loss 3.060268 Test MSE 3.5780491849027554 Test RE 0.9041306943910404\n",
      "25 Train Loss 2.7294784 Test MSE 3.3746427271045527 Test RE 0.87805548613416\n",
      "26 Train Loss 2.2368956 Test MSE 3.084014130223464 Test RE 0.839394733189703\n",
      "27 Train Loss 1.9502497 Test MSE 2.783404459131987 Test RE 0.7974367009599749\n",
      "28 Train Loss 1.7490062 Test MSE 2.4606599893709613 Test RE 0.749780021476405\n",
      "29 Train Loss 1.5237907 Test MSE 1.8503270868551953 Test RE 0.6501780648081877\n",
      "30 Train Loss 1.3066167 Test MSE 1.5091681840369133 Test RE 0.5871876067575986\n",
      "31 Train Loss 1.0913237 Test MSE 1.2646231729271338 Test RE 0.5375125739063388\n",
      "32 Train Loss 0.92628795 Test MSE 0.9749962724218266 Test RE 0.47196472238088394\n",
      "33 Train Loss 0.74083036 Test MSE 0.6579100267188972 Test RE 0.3876959934178531\n",
      "34 Train Loss 0.5570017 Test MSE 0.5057320916421174 Test RE 0.33991342441583866\n",
      "35 Train Loss 0.40046147 Test MSE 0.39821464377455756 Test RE 0.3016245406709236\n",
      "36 Train Loss 0.30125958 Test MSE 0.3167483083529703 Test RE 0.26900801035550476\n",
      "37 Train Loss 0.2500874 Test MSE 0.2558202229124043 Test RE 0.24175501771627\n",
      "38 Train Loss 0.21474785 Test MSE 0.16779634302875804 Test RE 0.19579396713137373\n",
      "39 Train Loss 0.16713291 Test MSE 0.10043314456553944 Test RE 0.15147696347600215\n",
      "40 Train Loss 0.13186361 Test MSE 0.08960957782771485 Test RE 0.1430820902137008\n",
      "41 Train Loss 0.108149745 Test MSE 0.05781790685669474 Test RE 0.11493154446616233\n",
      "42 Train Loss 0.086377345 Test MSE 0.047303481176554064 Test RE 0.10395720909457588\n",
      "43 Train Loss 0.0739431 Test MSE 0.03361175392985001 Test RE 0.08763016874558095\n",
      "44 Train Loss 0.061501287 Test MSE 0.030104987324987 Test RE 0.08293298260112718\n",
      "45 Train Loss 0.05316612 Test MSE 0.028316686080237588 Test RE 0.08043207510146812\n",
      "46 Train Loss 0.046979453 Test MSE 0.024993454370933796 Test RE 0.0755650897596922\n",
      "47 Train Loss 0.041370496 Test MSE 0.02274988694448283 Test RE 0.07209376086732483\n",
      "48 Train Loss 0.036308877 Test MSE 0.02017232380564798 Test RE 0.06788690754535837\n",
      "49 Train Loss 0.031648286 Test MSE 0.019044081715881612 Test RE 0.06596112868926297\n",
      "50 Train Loss 0.026731472 Test MSE 0.0173004182668788 Test RE 0.06286897239862674\n",
      "51 Train Loss 0.024162725 Test MSE 0.015409650600162023 Test RE 0.05933411323250191\n",
      "52 Train Loss 0.021350525 Test MSE 0.013410001347973275 Test RE 0.0553506175937248\n",
      "53 Train Loss 0.01835102 Test MSE 0.013203280403257389 Test RE 0.05492233383738119\n",
      "54 Train Loss 0.01630716 Test MSE 0.012185771405060138 Test RE 0.05276361875970241\n",
      "55 Train Loss 0.014703296 Test MSE 0.011708038255117806 Test RE 0.051719000902481334\n",
      "56 Train Loss 0.013579924 Test MSE 0.011731803080996882 Test RE 0.05177146357629473\n",
      "57 Train Loss 0.01223519 Test MSE 0.010687742698155811 Test RE 0.04941411882135276\n",
      "58 Train Loss 0.010836388 Test MSE 0.010259437119187946 Test RE 0.04841387307525266\n",
      "59 Train Loss 0.009668451 Test MSE 0.010654158770691629 Test RE 0.04933642112818688\n",
      "60 Train Loss 0.009367653 Test MSE 0.010570145804621033 Test RE 0.049141515896762654\n",
      "61 Train Loss 0.008727908 Test MSE 0.010074283659334384 Test RE 0.04797501815905046\n",
      "62 Train Loss 0.008195437 Test MSE 0.00942190996005941 Test RE 0.046395679009365046\n",
      "63 Train Loss 0.0075658616 Test MSE 0.008363681797206274 Test RE 0.04371261732551015\n",
      "64 Train Loss 0.007181814 Test MSE 0.00783837427786123 Test RE 0.04231760288442196\n",
      "65 Train Loss 0.0066527827 Test MSE 0.007243423892764263 Test RE 0.04067991257731233\n",
      "66 Train Loss 0.0061419657 Test MSE 0.006596441306273757 Test RE 0.03882065972098081\n",
      "67 Train Loss 0.005765547 Test MSE 0.006166211360139965 Test RE 0.037533344395137454\n",
      "68 Train Loss 0.005361663 Test MSE 0.00559271347626955 Test RE 0.03574533284854781\n",
      "69 Train Loss 0.0050411914 Test MSE 0.005414689251177899 Test RE 0.035171818959917056\n",
      "70 Train Loss 0.0046980125 Test MSE 0.0051543529067205 Test RE 0.034315879605497805\n",
      "71 Train Loss 0.0042974697 Test MSE 0.004282620969685188 Test RE 0.03127972165964164\n",
      "72 Train Loss 0.0041309986 Test MSE 0.004236355670077449 Test RE 0.03111030491640374\n",
      "73 Train Loss 0.00388719 Test MSE 0.004364712633582526 Test RE 0.031578092176450474\n",
      "74 Train Loss 0.0037542735 Test MSE 0.004147291460093524 Test RE 0.03078153966090304\n",
      "75 Train Loss 0.003627441 Test MSE 0.003891159770646177 Test RE 0.02981587725836016\n",
      "76 Train Loss 0.003454288 Test MSE 0.004004856960635915 Test RE 0.030248341317673465\n",
      "77 Train Loss 0.0032805467 Test MSE 0.004175519616477176 Test RE 0.030886117865950444\n",
      "78 Train Loss 0.003140137 Test MSE 0.003932817406698968 Test RE 0.02997505246976962\n",
      "79 Train Loss 0.0030197552 Test MSE 0.0036944636509267563 Test RE 0.02905251668461914\n",
      "80 Train Loss 0.0029074955 Test MSE 0.0035811596007436653 Test RE 0.02860354747012275\n",
      "81 Train Loss 0.002777946 Test MSE 0.003356185235249476 Test RE 0.02769051426729704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 0.0025924905 Test MSE 0.0032409065297921516 Test RE 0.027210800183570527\n",
      "83 Train Loss 0.0024981715 Test MSE 0.003200853485661404 Test RE 0.027042133844089572\n",
      "84 Train Loss 0.0024142582 Test MSE 0.0031408150664602244 Test RE 0.0267873185991067\n",
      "85 Train Loss 0.0023393198 Test MSE 0.003186619044371365 Test RE 0.02698193762213533\n",
      "86 Train Loss 0.0022716667 Test MSE 0.0032430821230434205 Test RE 0.027219931841792753\n",
      "87 Train Loss 0.002217558 Test MSE 0.0031485773916868397 Test RE 0.02682039975167643\n",
      "88 Train Loss 0.0021388999 Test MSE 0.0030475481654745114 Test RE 0.02638659488637447\n",
      "89 Train Loss 0.0020702838 Test MSE 0.0030161530598604718 Test RE 0.026250328867147794\n",
      "90 Train Loss 0.0019781548 Test MSE 0.0029608194849300774 Test RE 0.0260084233271727\n",
      "91 Train Loss 0.001910924 Test MSE 0.0029237769487409767 Test RE 0.025845216776826156\n",
      "92 Train Loss 0.001848984 Test MSE 0.0029639206101385956 Test RE 0.026022040210829274\n",
      "93 Train Loss 0.0017855342 Test MSE 0.0028483047296720297 Test RE 0.025509461204016076\n",
      "94 Train Loss 0.0017479538 Test MSE 0.0027396666163372915 Test RE 0.02501824949145799\n",
      "95 Train Loss 0.0016642186 Test MSE 0.0027459797289058735 Test RE 0.025047058132005407\n",
      "96 Train Loss 0.0015915872 Test MSE 0.0027899770320990998 Test RE 0.025246918279735683\n",
      "97 Train Loss 0.0015552783 Test MSE 0.002702225742755601 Test RE 0.024846709007138958\n",
      "98 Train Loss 0.0015091214 Test MSE 0.0025391801843092756 Test RE 0.02408545307922109\n",
      "99 Train Loss 0.001464062 Test MSE 0.0024399088518592404 Test RE 0.023609938813954654\n",
      "Training time: 87.41\n",
      "3\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.574448 Test MSE 8.580526613685487 Test RE 1.4001192658946098\n",
      "1 Train Loss 56.110435 Test MSE 8.526700396622461 Test RE 1.3957208362549398\n",
      "2 Train Loss 55.507317 Test MSE 8.92577580597736 Test RE 1.4280093380258283\n",
      "3 Train Loss 48.551586 Test MSE 9.363878770212589 Test RE 1.4626349659184859\n",
      "4 Train Loss 44.005543 Test MSE 8.603296849170782 Test RE 1.401975790795462\n",
      "5 Train Loss 42.16095 Test MSE 8.498696236042798 Test RE 1.3934269749810422\n",
      "6 Train Loss 41.79927 Test MSE 8.378636429092417 Test RE 1.3835495999205858\n",
      "7 Train Loss 41.44922 Test MSE 8.46715180624446 Test RE 1.3908385943272517\n",
      "8 Train Loss 41.18566 Test MSE 8.607739672849599 Test RE 1.402337740837018\n",
      "9 Train Loss 40.69735 Test MSE 8.823145385007983 Test RE 1.4197758282146273\n",
      "10 Train Loss 40.36332 Test MSE 8.83984246009055 Test RE 1.4211185975847453\n",
      "11 Train Loss 40.041496 Test MSE 8.77316154419448 Test RE 1.4157485432485049\n",
      "12 Train Loss 39.781433 Test MSE 8.836469243624942 Test RE 1.4208474277038579\n",
      "13 Train Loss 39.302246 Test MSE 8.75847763953776 Test RE 1.4145632565941628\n",
      "14 Train Loss 38.77861 Test MSE 8.747538307415745 Test RE 1.4136795863491807\n",
      "15 Train Loss 38.308857 Test MSE 8.590720093802917 Test RE 1.4009506747535425\n",
      "16 Train Loss 37.925625 Test MSE 8.794104280741688 Test RE 1.4174373287140074\n",
      "17 Train Loss 37.179337 Test MSE 8.806360973712168 Test RE 1.4184247541760093\n",
      "18 Train Loss 36.81937 Test MSE 8.756008082097964 Test RE 1.4143638160269494\n",
      "19 Train Loss 36.193863 Test MSE 8.799201761382323 Test RE 1.4178480762088503\n",
      "20 Train Loss 35.751633 Test MSE 8.797305500552794 Test RE 1.4176952922001966\n",
      "21 Train Loss 34.395454 Test MSE 8.582312296217514 Test RE 1.4002649468396868\n",
      "22 Train Loss 33.18457 Test MSE 8.187586278789587 Test RE 1.3676847517992248\n",
      "23 Train Loss 31.382938 Test MSE 7.31091857027076 Test RE 1.292391323288938\n",
      "24 Train Loss 28.84068 Test MSE 7.460827741304509 Test RE 1.3055742226294242\n",
      "25 Train Loss 27.70474 Test MSE 7.723677819563934 Test RE 1.3283732917122726\n",
      "26 Train Loss 26.21604 Test MSE 7.739538332478679 Test RE 1.3297364944013264\n",
      "27 Train Loss 25.458893 Test MSE 7.442490545897589 Test RE 1.3039688177845605\n",
      "28 Train Loss 23.907936 Test MSE 6.345751276268105 Test RE 1.2040640317296656\n",
      "29 Train Loss 21.566359 Test MSE 6.260672518629532 Test RE 1.1959652308167554\n",
      "30 Train Loss 19.895592 Test MSE 5.762743363878119 Test RE 1.147420751338411\n",
      "31 Train Loss 17.815647 Test MSE 5.707797416356628 Test RE 1.1419375015756075\n",
      "32 Train Loss 15.554624 Test MSE 4.787812353358657 Test RE 1.0458673870851685\n",
      "33 Train Loss 12.775671 Test MSE 4.46726581224496 Test RE 1.0102502291965592\n",
      "34 Train Loss 11.23395 Test MSE 3.92698116599545 Test RE 0.9471907963829949\n",
      "35 Train Loss 9.686797 Test MSE 3.5860010301209386 Test RE 0.9051348054185\n",
      "36 Train Loss 8.64897 Test MSE 3.8521983347608004 Test RE 0.9381286079916991\n",
      "37 Train Loss 7.4239917 Test MSE 3.708540737487781 Test RE 0.9204698913887251\n",
      "38 Train Loss 6.87421 Test MSE 3.666750212924888 Test RE 0.9152689369515933\n",
      "39 Train Loss 6.0295377 Test MSE 3.580344862251901 Test RE 0.9044206931347883\n",
      "40 Train Loss 5.381786 Test MSE 3.8003234695788426 Test RE 0.9317906369544191\n",
      "41 Train Loss 4.9098463 Test MSE 3.94647276034726 Test RE 0.9495385802523716\n",
      "42 Train Loss 4.6358004 Test MSE 4.08396227139705 Test RE 0.9659372646752947\n",
      "43 Train Loss 4.2904377 Test MSE 4.266916108175234 Test RE 0.9873363182337604\n",
      "44 Train Loss 3.9716656 Test MSE 4.347530970158843 Test RE 0.9966195507399029\n",
      "45 Train Loss 3.6412628 Test MSE 4.594160588565923 Test RE 1.024498073812345\n",
      "46 Train Loss 3.4472454 Test MSE 4.842933181733817 Test RE 1.0518705568142184\n",
      "47 Train Loss 3.294302 Test MSE 4.89617157491634 Test RE 1.0576363638711934\n",
      "48 Train Loss 3.0402143 Test MSE 5.087265776344317 Test RE 1.0780782241455733\n",
      "49 Train Loss 2.893773 Test MSE 5.019748505906974 Test RE 1.0709002990523628\n",
      "50 Train Loss 2.782734 Test MSE 5.075891278467356 Test RE 1.0768723248375216\n",
      "51 Train Loss 2.6249819 Test MSE 5.011091286108987 Test RE 1.0699764459962902\n",
      "52 Train Loss 2.5221267 Test MSE 5.048058185117423 Test RE 1.0739158106686817\n",
      "53 Train Loss 2.4372938 Test MSE 5.123752023786247 Test RE 1.0819373455211467\n",
      "54 Train Loss 2.3306913 Test MSE 5.117380289949558 Test RE 1.0812644049370104\n",
      "55 Train Loss 2.2137043 Test MSE 5.224800132064462 Test RE 1.0925539742416766\n",
      "56 Train Loss 2.1337304 Test MSE 5.176197720949798 Test RE 1.0874604947815443\n",
      "57 Train Loss 2.0843763 Test MSE 5.240661317683881 Test RE 1.0942110777760055\n",
      "58 Train Loss 2.0013645 Test MSE 5.323397023631669 Test RE 1.1028145542155021\n",
      "59 Train Loss 1.9377085 Test MSE 5.322786713441765 Test RE 1.102751335348946\n",
      "60 Train Loss 1.8781368 Test MSE 5.382579311302114 Test RE 1.1089278207407312\n",
      "61 Train Loss 1.8113725 Test MSE 5.466575217781476 Test RE 1.1175468129931834\n",
      "62 Train Loss 1.7713765 Test MSE 5.447500611619656 Test RE 1.1155953724459549\n",
      "63 Train Loss 1.706826 Test MSE 5.483256848321534 Test RE 1.1192506496497636\n",
      "64 Train Loss 1.6676366 Test MSE 5.5169511346405 Test RE 1.1226842471610876\n",
      "65 Train Loss 1.6010556 Test MSE 5.5431967288892 Test RE 1.1253515314818223\n",
      "66 Train Loss 1.580532 Test MSE 5.540878204279917 Test RE 1.1251161593460275\n",
      "67 Train Loss 1.5474577 Test MSE 5.564860848111077 Test RE 1.1275484565521747\n",
      "68 Train Loss 1.5114721 Test MSE 5.595095642877871 Test RE 1.1306073844136324\n",
      "69 Train Loss 1.4738762 Test MSE 5.584471355092645 Test RE 1.1295334433560185\n",
      "70 Train Loss 1.4394171 Test MSE 5.607940943692495 Test RE 1.1319044726953942\n",
      "71 Train Loss 1.410061 Test MSE 5.665197882118371 Test RE 1.137668156633662\n",
      "72 Train Loss 1.3748639 Test MSE 5.666033618807536 Test RE 1.1377520686148064\n",
      "73 Train Loss 1.3484094 Test MSE 5.718459536616066 Test RE 1.1430035690500309\n",
      "74 Train Loss 1.3002093 Test MSE 5.801474007842253 Test RE 1.1512701267342431\n",
      "75 Train Loss 1.2710907 Test MSE 5.788341628928334 Test RE 1.1499663648701388\n",
      "76 Train Loss 1.2515205 Test MSE 5.812490895937014 Test RE 1.1523627282400188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 1.21765 Test MSE 5.861464828075758 Test RE 1.1572072395267823\n",
      "78 Train Loss 1.2045202 Test MSE 5.865561472506863 Test RE 1.1576115615431513\n",
      "79 Train Loss 1.1808445 Test MSE 5.8650699917621685 Test RE 1.1575630618629775\n",
      "80 Train Loss 1.1597182 Test MSE 5.863059161245437 Test RE 1.1573646104654431\n",
      "81 Train Loss 1.1416435 Test MSE 5.890199116168755 Test RE 1.1600402236909026\n",
      "82 Train Loss 1.1199787 Test MSE 5.914999852683864 Test RE 1.1624798382969366\n",
      "83 Train Loss 1.103115 Test MSE 5.882089401810056 Test RE 1.1592413682504008\n",
      "84 Train Loss 1.0874566 Test MSE 5.896693065761611 Test RE 1.1606795202054987\n",
      "85 Train Loss 1.072503 Test MSE 5.946815621777354 Test RE 1.1656020352615548\n",
      "86 Train Loss 1.0571486 Test MSE 5.961457299855938 Test RE 1.1670360697912003\n",
      "87 Train Loss 1.0437306 Test MSE 5.973525823646056 Test RE 1.1682167610941612\n",
      "88 Train Loss 1.0342745 Test MSE 5.987830366375718 Test RE 1.1696146636787812\n",
      "89 Train Loss 1.0177202 Test MSE 6.000570842190824 Test RE 1.1708583135726731\n",
      "90 Train Loss 1.0090411 Test MSE 5.99585444839874 Test RE 1.1703980811582249\n",
      "91 Train Loss 1.0013101 Test MSE 5.984800993740349 Test RE 1.1693187595951804\n",
      "92 Train Loss 0.98936164 Test MSE 5.9904995906987075 Test RE 1.1698753270469866\n",
      "93 Train Loss 0.9788631 Test MSE 6.007122575661205 Test RE 1.171497341009077\n",
      "94 Train Loss 0.96935564 Test MSE 6.01577675167061 Test RE 1.1723408975726566\n",
      "95 Train Loss 0.9570248 Test MSE 6.016822049562466 Test RE 1.1724427457870106\n",
      "96 Train Loss 0.948569 Test MSE 6.019729845675996 Test RE 1.172726019301699\n",
      "97 Train Loss 0.9392637 Test MSE 6.036314065112882 Test RE 1.1743403250386888\n",
      "98 Train Loss 0.9321975 Test MSE 6.050305147066389 Test RE 1.1757004913554001\n",
      "99 Train Loss 0.92329997 Test MSE 6.078704176115352 Test RE 1.178456522919172\n",
      "Training time: 88.77\n",
      "4\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.84874 Test MSE 8.379067311570893 Test RE 1.3835851748987782\n",
      "1 Train Loss 57.009773 Test MSE 8.536542705886552 Test RE 1.3965261392209467\n",
      "2 Train Loss 56.21136 Test MSE 8.876604987556588 Test RE 1.4240705566988237\n",
      "3 Train Loss 52.538757 Test MSE 7.595747879963122 Test RE 1.3173262040356755\n",
      "4 Train Loss 45.261436 Test MSE 8.150903593274277 Test RE 1.3646175065529293\n",
      "5 Train Loss 44.232216 Test MSE 8.28784247699389 Test RE 1.3760328575468903\n",
      "6 Train Loss 43.007423 Test MSE 8.137579090194908 Test RE 1.3635016617242155\n",
      "7 Train Loss 40.32758 Test MSE 7.673895312074262 Test RE 1.324085395547949\n",
      "8 Train Loss 30.01476 Test MSE 6.602518884462442 Test RE 1.2281824472373724\n",
      "9 Train Loss 26.059383 Test MSE 5.787818028721151 Test RE 1.149914352024079\n",
      "10 Train Loss 23.502056 Test MSE 5.439546582721163 Test RE 1.1147806208812705\n",
      "11 Train Loss 21.307314 Test MSE 5.720209093507741 Test RE 1.1431784060692207\n",
      "12 Train Loss 18.476246 Test MSE 5.408561876820925 Test RE 1.1116010839464674\n",
      "13 Train Loss 16.129189 Test MSE 5.8593905901790295 Test RE 1.1570024668655616\n",
      "14 Train Loss 15.153332 Test MSE 5.919424521630509 Test RE 1.1629145489498627\n",
      "15 Train Loss 14.286867 Test MSE 5.8201118975084905 Test RE 1.1531179364236777\n",
      "16 Train Loss 13.20867 Test MSE 5.83041252565442 Test RE 1.154137898623472\n",
      "17 Train Loss 11.762245 Test MSE 5.837940259660041 Test RE 1.1548827207575212\n",
      "18 Train Loss 10.2790165 Test MSE 5.637340453032508 Test RE 1.1348675866386622\n",
      "19 Train Loss 9.060564 Test MSE 5.584932368205756 Test RE 1.1295800654039712\n",
      "20 Train Loss 8.091632 Test MSE 5.450290491388909 Test RE 1.1158810060595525\n",
      "21 Train Loss 7.0726395 Test MSE 5.147679572406411 Test RE 1.084460687282247\n",
      "22 Train Loss 6.124796 Test MSE 4.609981240149003 Test RE 1.0262605608756858\n",
      "23 Train Loss 5.2124286 Test MSE 4.464412263797343 Test RE 1.0099275196688977\n",
      "24 Train Loss 4.5884094 Test MSE 4.036030259827157 Test RE 0.9602521033277226\n",
      "25 Train Loss 3.9784722 Test MSE 3.6529442735918085 Test RE 0.9135442402256831\n",
      "26 Train Loss 3.3739357 Test MSE 3.220838833750331 Test RE 0.8578128688708484\n",
      "27 Train Loss 2.9469185 Test MSE 2.777415382815569 Test RE 0.7965783131135259\n",
      "28 Train Loss 2.6104965 Test MSE 2.506514066628505 Test RE 0.7567338016590465\n",
      "29 Train Loss 2.202684 Test MSE 2.185660751378912 Test RE 0.7066419844714223\n",
      "30 Train Loss 1.9373251 Test MSE 2.025090983315213 Test RE 0.68019013708023\n",
      "31 Train Loss 1.6793128 Test MSE 1.9534927383594498 Test RE 0.6680576797754026\n",
      "32 Train Loss 1.547279 Test MSE 1.8808630423255972 Test RE 0.6555210567875334\n",
      "33 Train Loss 1.428543 Test MSE 1.7591414439605468 Test RE 0.6339550131208688\n",
      "34 Train Loss 1.3395623 Test MSE 1.6531394651928366 Test RE 0.6145579019998004\n",
      "35 Train Loss 1.2137814 Test MSE 1.4826819235320894 Test RE 0.5820121575869093\n",
      "36 Train Loss 1.1087263 Test MSE 1.4035630497840643 Test RE 0.5662706120916288\n",
      "37 Train Loss 1.0495726 Test MSE 1.3448947344505096 Test RE 0.5543093533611795\n",
      "38 Train Loss 0.97324604 Test MSE 1.2520367960525072 Test RE 0.5348310425393442\n",
      "39 Train Loss 0.8789874 Test MSE 1.1070113519301554 Test RE 0.5029028507706463\n",
      "40 Train Loss 0.74928045 Test MSE 0.8900449259803472 Test RE 0.45093508263418847\n",
      "41 Train Loss 0.6558173 Test MSE 0.7572981619620576 Test RE 0.4159503668426429\n",
      "42 Train Loss 0.56433576 Test MSE 0.647992174764388 Test RE 0.3847626798711848\n",
      "43 Train Loss 0.4855761 Test MSE 0.5260886339576673 Test RE 0.346686970408996\n",
      "44 Train Loss 0.38800007 Test MSE 0.45007539850401757 Test RE 0.3206643632107214\n",
      "45 Train Loss 0.32863733 Test MSE 0.4118722609144873 Test RE 0.306753362624724\n",
      "46 Train Loss 0.28576097 Test MSE 0.3323488117871082 Test RE 0.2755529884870521\n",
      "47 Train Loss 0.25217214 Test MSE 0.290482063610642 Test RE 0.2576129677912439\n",
      "48 Train Loss 0.22578765 Test MSE 0.2630110592751698 Test RE 0.24512920994169846\n",
      "49 Train Loss 0.20798026 Test MSE 0.2506651660398624 Test RE 0.2393068076082682\n",
      "50 Train Loss 0.1958602 Test MSE 0.24112663477836416 Test RE 0.2347094916476207\n",
      "51 Train Loss 0.17540418 Test MSE 0.2012236878066689 Test RE 0.2144112715030394\n",
      "52 Train Loss 0.1574358 Test MSE 0.18605688353432362 Test RE 0.206172592228901\n",
      "53 Train Loss 0.13654083 Test MSE 0.12779871863474346 Test RE 0.17087216023377572\n",
      "54 Train Loss 0.12274637 Test MSE 0.09093017480836961 Test RE 0.1441325510017955\n",
      "55 Train Loss 0.10993883 Test MSE 0.059998262016138115 Test RE 0.11707856625130113\n",
      "56 Train Loss 0.09570195 Test MSE 0.0411284970570806 Test RE 0.0969347467588479\n",
      "57 Train Loss 0.086573124 Test MSE 0.03373844693631961 Test RE 0.08779516589802037\n",
      "58 Train Loss 0.07702136 Test MSE 0.02284435676332537 Test RE 0.07224329191284777\n",
      "59 Train Loss 0.07157597 Test MSE 0.021386395543947556 Test RE 0.06989994881434763\n",
      "60 Train Loss 0.06531306 Test MSE 0.019940347330733445 Test RE 0.06749543795513883\n",
      "61 Train Loss 0.060701653 Test MSE 0.01919479649309554 Test RE 0.0662216223566901\n",
      "62 Train Loss 0.056071784 Test MSE 0.017085769559560114 Test RE 0.062477743038197114\n",
      "63 Train Loss 0.05341635 Test MSE 0.01724761857473042 Test RE 0.06277296318941962\n",
      "64 Train Loss 0.048244838 Test MSE 0.016249713612791223 Test RE 0.06092996321613427\n",
      "65 Train Loss 0.04418545 Test MSE 0.014502541263387432 Test RE 0.0575612365716049\n",
      "66 Train Loss 0.03953532 Test MSE 0.011565254764250594 Test RE 0.05140266813363049\n",
      "67 Train Loss 0.035871785 Test MSE 0.009735970792301733 Test RE 0.04716259483079872\n",
      "68 Train Loss 0.032502647 Test MSE 0.009460937712308682 Test RE 0.04649167057804216\n",
      "69 Train Loss 0.030032698 Test MSE 0.009319048373136815 Test RE 0.046141726785379526\n",
      "70 Train Loss 0.028213661 Test MSE 0.008678050721270137 Test RE 0.044526560854192494\n",
      "71 Train Loss 0.026411945 Test MSE 0.007899759712186887 Test RE 0.04248298273762578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Train Loss 0.024046712 Test MSE 0.007301186158798842 Test RE 0.040841790305211026\n",
      "73 Train Loss 0.022640912 Test MSE 0.007073682723120895 Test RE 0.04020044388509875\n",
      "74 Train Loss 0.021560181 Test MSE 0.0074224595102998624 Test RE 0.04117958626169606\n",
      "75 Train Loss 0.019918306 Test MSE 0.007167491469755973 Test RE 0.040466128161017245\n",
      "76 Train Loss 0.018915573 Test MSE 0.007076137466575366 Test RE 0.04020741855590212\n",
      "77 Train Loss 0.018026734 Test MSE 0.006905784776955564 Test RE 0.039720488396083865\n",
      "78 Train Loss 0.017174983 Test MSE 0.006302446935198852 Test RE 0.03794570788962347\n",
      "79 Train Loss 0.016481888 Test MSE 0.006192493991912994 Test RE 0.03761324971040815\n",
      "80 Train Loss 0.015743632 Test MSE 0.006249296246552931 Test RE 0.03778536455570422\n",
      "81 Train Loss 0.014814469 Test MSE 0.00648315355696153 Test RE 0.038485861657050584\n",
      "82 Train Loss 0.014179082 Test MSE 0.0065822885866530685 Test RE 0.0387789923355883\n",
      "83 Train Loss 0.0134093445 Test MSE 0.006210204936355449 Test RE 0.037666999503047645\n",
      "84 Train Loss 0.012658082 Test MSE 0.005675993607507979 Test RE 0.036010488191923935\n",
      "85 Train Loss 0.012112996 Test MSE 0.005394765317232725 Test RE 0.03510705007057482\n",
      "86 Train Loss 0.011598764 Test MSE 0.005405344324275488 Test RE 0.03514145525883457\n",
      "87 Train Loss 0.011064932 Test MSE 0.005279968116470845 Test RE 0.03473151360033167\n",
      "88 Train Loss 0.010270192 Test MSE 0.004706398520784923 Test RE 0.032790830005258204\n",
      "89 Train Loss 0.009870534 Test MSE 0.004559999896151251 Test RE 0.03227680040783085\n",
      "90 Train Loss 0.009461227 Test MSE 0.0043877020463911915 Test RE 0.03166114556816932\n",
      "91 Train Loss 0.008902576 Test MSE 0.00414085284441951 Test RE 0.03075763641134279\n",
      "92 Train Loss 0.008269871 Test MSE 0.003888479067839868 Test RE 0.02980560509257477\n",
      "93 Train Loss 0.007844962 Test MSE 0.0035736121489038956 Test RE 0.028573389953104763\n",
      "94 Train Loss 0.0072148726 Test MSE 0.003259488505836222 Test RE 0.0272886962499209\n",
      "95 Train Loss 0.0067505874 Test MSE 0.00316474600992443 Test RE 0.02688917581396049\n",
      "96 Train Loss 0.0061471523 Test MSE 0.0031599702197906217 Test RE 0.026868879470432056\n",
      "97 Train Loss 0.0058762175 Test MSE 0.0031651011580267987 Test RE 0.02689068452458597\n",
      "98 Train Loss 0.0055768616 Test MSE 0.003039816795612591 Test RE 0.026353103360846196\n",
      "99 Train Loss 0.0051358016 Test MSE 0.002831868889559357 Test RE 0.025435754902481792\n",
      "Training time: 88.27\n",
      "5\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.229073 Test MSE 8.679627979706972 Test RE 1.4081814396234051\n",
      "1 Train Loss 57.7468 Test MSE 8.64411471379224 Test RE 1.405297653540896\n",
      "2 Train Loss 57.56211 Test MSE 8.661044467603777 Test RE 1.4066731388551947\n",
      "3 Train Loss 57.31504 Test MSE 8.260310377410018 Test RE 1.3737453750347894\n",
      "4 Train Loss 53.392693 Test MSE 9.118472951008252 Test RE 1.443341561167803\n",
      "5 Train Loss 48.049973 Test MSE 8.633280808028692 Test RE 1.4044167284098377\n",
      "6 Train Loss 46.087246 Test MSE 8.768414968838275 Test RE 1.415365507652456\n",
      "7 Train Loss 45.817062 Test MSE 8.758162307072247 Test RE 1.4145377920241413\n",
      "8 Train Loss 45.433174 Test MSE 8.397000393735384 Test RE 1.3850649747444357\n",
      "9 Train Loss 44.536766 Test MSE 8.46751757581165 Test RE 1.3908686351809154\n",
      "10 Train Loss 44.24372 Test MSE 8.447020752530133 Test RE 1.38918421814687\n",
      "11 Train Loss 43.875084 Test MSE 8.531035708618305 Test RE 1.3960756110254202\n",
      "12 Train Loss 43.36331 Test MSE 8.389870354675317 Test RE 1.3844768084840442\n",
      "13 Train Loss 42.61912 Test MSE 8.529604006347398 Test RE 1.3959584594533523\n",
      "14 Train Loss 41.339706 Test MSE 8.435130171691071 Test RE 1.3882061203740872\n",
      "15 Train Loss 38.767838 Test MSE 8.39053434409436 Test RE 1.3845315923916182\n",
      "16 Train Loss 36.912865 Test MSE 8.27700685860001 Test RE 1.3751330429327997\n",
      "17 Train Loss 34.555458 Test MSE 8.205327472564646 Test RE 1.3691657273487232\n",
      "18 Train Loss 32.05838 Test MSE 7.767500164136846 Test RE 1.3321364014605441\n",
      "19 Train Loss 29.496964 Test MSE 7.678499552408402 Test RE 1.324482553247428\n",
      "20 Train Loss 26.893635 Test MSE 8.224612651164982 Test RE 1.3707737746225435\n",
      "21 Train Loss 24.620584 Test MSE 7.842702685546651 Test RE 1.3385695332880867\n",
      "22 Train Loss 23.292307 Test MSE 8.065608708362635 Test RE 1.3574587297207752\n",
      "23 Train Loss 21.458805 Test MSE 8.116940510056791 Test RE 1.3617715032001472\n",
      "24 Train Loss 18.355303 Test MSE 8.10502462921739 Test RE 1.3607715780050995\n",
      "25 Train Loss 15.680487 Test MSE 8.005217679015663 Test RE 1.3523672132103417\n",
      "26 Train Loss 13.797407 Test MSE 7.707434433645056 Test RE 1.3269757297560982\n",
      "27 Train Loss 11.248179 Test MSE 7.202772593061545 Test RE 1.282796930215108\n",
      "28 Train Loss 9.999506 Test MSE 6.94069470142144 Test RE 1.259242958686076\n",
      "29 Train Loss 7.148234 Test MSE 6.099308424738981 Test RE 1.1804520691337834\n",
      "30 Train Loss 5.5527267 Test MSE 6.094051415379764 Test RE 1.1799432421581901\n",
      "31 Train Loss 4.1489167 Test MSE 6.07833647865135 Test RE 1.1784208802875094\n",
      "32 Train Loss 3.2228603 Test MSE 5.906799937427813 Test RE 1.1616737907647936\n",
      "33 Train Loss 2.8709424 Test MSE 5.711206916897108 Test RE 1.1422785136150395\n",
      "34 Train Loss 2.572163 Test MSE 5.8394858891306605 Test RE 1.1550355916808126\n",
      "35 Train Loss 2.3843617 Test MSE 5.719979151292239 Test RE 1.1431554289705834\n",
      "36 Train Loss 2.2097213 Test MSE 5.74208412049469 Test RE 1.1453621720729272\n",
      "37 Train Loss 2.093655 Test MSE 5.79965689844895 Test RE 1.151089815007035\n",
      "38 Train Loss 1.9567839 Test MSE 5.758650655038356 Test RE 1.1470132290145292\n",
      "39 Train Loss 1.8549018 Test MSE 5.688822974878831 Test RE 1.140037849035494\n",
      "40 Train Loss 1.7466013 Test MSE 5.5768425722892685 Test RE 1.1287616684091886\n",
      "41 Train Loss 1.6513554 Test MSE 5.528880226655213 Test RE 1.12389736030992\n",
      "42 Train Loss 1.5694637 Test MSE 5.604927778910549 Test RE 1.1316003438730158\n",
      "43 Train Loss 1.5171328 Test MSE 5.6172766667069345 Test RE 1.132846240139986\n",
      "44 Train Loss 1.4458345 Test MSE 5.718687439664429 Test RE 1.143026345411447\n",
      "45 Train Loss 1.4074225 Test MSE 5.752113227464693 Test RE 1.146361978772487\n",
      "46 Train Loss 1.365237 Test MSE 5.814215575193522 Test RE 1.152533679792596\n",
      "47 Train Loss 1.3218795 Test MSE 5.826844578158207 Test RE 1.1537847046090837\n",
      "48 Train Loss 1.275256 Test MSE 5.834767863835858 Test RE 1.1545688906374703\n",
      "49 Train Loss 1.2260485 Test MSE 5.881998173507237 Test RE 1.1592323785848742\n",
      "50 Train Loss 1.1880809 Test MSE 5.892999751211632 Test RE 1.1603159752524113\n",
      "51 Train Loss 1.1527518 Test MSE 5.939032432885119 Test RE 1.16483901588068\n",
      "52 Train Loss 1.1065896 Test MSE 5.9738826191380365 Test RE 1.1682516490533392\n",
      "53 Train Loss 1.0757748 Test MSE 5.96908374773904 Test RE 1.1677823214710477\n",
      "54 Train Loss 1.0439464 Test MSE 5.981770074861494 Test RE 1.1690226295202193\n",
      "55 Train Loss 1.0195211 Test MSE 5.996343979349191 Test RE 1.1704458587015212\n",
      "56 Train Loss 0.9907362 Test MSE 6.010739849369333 Test RE 1.1718500047622082\n",
      "57 Train Loss 0.9661715 Test MSE 6.044792587310129 Test RE 1.175164766627451\n",
      "58 Train Loss 0.9519547 Test MSE 6.06567671731388 Test RE 1.177193052311256\n",
      "59 Train Loss 0.93560433 Test MSE 6.1362373851522465 Test RE 1.1840202672967164\n",
      "60 Train Loss 0.92324746 Test MSE 6.1697422348413955 Test RE 1.1872483380348158\n",
      "61 Train Loss 0.9067134 Test MSE 6.178483391152457 Test RE 1.1880890741389871\n",
      "62 Train Loss 0.8949556 Test MSE 6.1712681065863055 Test RE 1.1873951413071153\n",
      "63 Train Loss 0.8857417 Test MSE 6.166394048730825 Test RE 1.1869261472775374\n",
      "64 Train Loss 0.87680894 Test MSE 6.178184429791136 Test RE 1.188060329461587\n",
      "65 Train Loss 0.8649703 Test MSE 6.17959246194993 Test RE 1.1881957035240962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.85628265 Test MSE 6.175338343035851 Test RE 1.1877866477422718\n",
      "67 Train Loss 0.8490481 Test MSE 6.194140736429622 Test RE 1.1895935331794931\n",
      "68 Train Loss 0.83856285 Test MSE 6.211749659968358 Test RE 1.1912832425383375\n",
      "69 Train Loss 0.8304849 Test MSE 6.19999583844864 Test RE 1.190155640708566\n",
      "70 Train Loss 0.8218896 Test MSE 6.208497189741681 Test RE 1.1909713239317103\n",
      "71 Train Loss 0.8131581 Test MSE 6.224974338244592 Test RE 1.1925506762112097\n",
      "72 Train Loss 0.80508476 Test MSE 6.215040533949128 Test RE 1.1915987610431136\n",
      "73 Train Loss 0.79746467 Test MSE 6.229911619823388 Test RE 1.1930235128152824\n",
      "74 Train Loss 0.79067475 Test MSE 6.25978846377779 Test RE 1.195880788115993\n",
      "75 Train Loss 0.78255033 Test MSE 6.252147057700124 Test RE 1.19515065152573\n",
      "76 Train Loss 0.7780347 Test MSE 6.231126269839268 Test RE 1.1931398094412067\n",
      "77 Train Loss 0.77167094 Test MSE 6.234246662617269 Test RE 1.1934385193931045\n",
      "78 Train Loss 0.76531637 Test MSE 6.241116840420258 Test RE 1.1940959265858595\n",
      "79 Train Loss 0.7608651 Test MSE 6.264949316911346 Test RE 1.1963736556946536\n",
      "80 Train Loss 0.7558748 Test MSE 6.2886107164156355 Test RE 1.1986307527373607\n",
      "81 Train Loss 0.75156844 Test MSE 6.29638358557706 Test RE 1.1993712917265225\n",
      "82 Train Loss 0.74751633 Test MSE 6.315459165996549 Test RE 1.2011867307825606\n",
      "83 Train Loss 0.7443151 Test MSE 6.31092909335386 Test RE 1.2007558484710774\n",
      "84 Train Loss 0.73947716 Test MSE 6.289611142232711 Test RE 1.198726091240298\n",
      "85 Train Loss 0.735092 Test MSE 6.310400839296453 Test RE 1.2007055930004777\n",
      "86 Train Loss 0.73235327 Test MSE 6.314038996006717 Test RE 1.2010516665524802\n",
      "87 Train Loss 0.72902244 Test MSE 6.315365704610048 Test RE 1.2011778426724715\n",
      "88 Train Loss 0.7261318 Test MSE 6.3418614687414605 Test RE 1.2036949426272037\n",
      "89 Train Loss 0.7225596 Test MSE 6.361692645722173 Test RE 1.2055754674226336\n",
      "90 Train Loss 0.71909016 Test MSE 6.366595600753834 Test RE 1.20603994631158\n",
      "91 Train Loss 0.71606255 Test MSE 6.380553157256826 Test RE 1.2073612297615268\n",
      "92 Train Loss 0.7124363 Test MSE 6.4024157826076005 Test RE 1.209427940361604\n",
      "93 Train Loss 0.709653 Test MSE 6.410583105344214 Test RE 1.2101991055340298\n",
      "94 Train Loss 0.70757794 Test MSE 6.417820035027764 Test RE 1.210882011855534\n",
      "95 Train Loss 0.7038939 Test MSE 6.434952117031177 Test RE 1.2124971322425004\n",
      "96 Train Loss 0.7014683 Test MSE 6.4451698034644975 Test RE 1.213459377280551\n",
      "97 Train Loss 0.6988994 Test MSE 6.453045885378561 Test RE 1.2142005825350854\n",
      "98 Train Loss 0.69628453 Test MSE 6.455813885684897 Test RE 1.2144609671124187\n",
      "99 Train Loss 0.69273233 Test MSE 6.453497413130721 Test RE 1.214243061364418\n",
      "Training time: 88.64\n",
      "6\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.289303 Test MSE 8.365121473090076 Test RE 1.3824332990432724\n",
      "1 Train Loss 58.88389 Test MSE 8.610668067044788 Test RE 1.4025762615546726\n",
      "2 Train Loss 58.609238 Test MSE 8.650338500125686 Test RE 1.4058034715946555\n",
      "3 Train Loss 58.55901 Test MSE 8.618363346211659 Test RE 1.403202856693843\n",
      "4 Train Loss 57.888313 Test MSE 7.720289668922646 Test RE 1.3280819005759499\n",
      "5 Train Loss 48.37423 Test MSE 8.384513179172657 Test RE 1.3840347236078163\n",
      "6 Train Loss 46.329178 Test MSE 8.604868528626097 Test RE 1.4021038437942908\n",
      "7 Train Loss 46.12177 Test MSE 8.449159757353742 Test RE 1.3893600957575052\n",
      "8 Train Loss 45.852234 Test MSE 8.454192687971863 Test RE 1.3897738358310026\n",
      "9 Train Loss 45.598408 Test MSE 8.459141709717926 Test RE 1.390180557968665\n",
      "10 Train Loss 45.34133 Test MSE 8.485097776720155 Test RE 1.3923117424047784\n",
      "11 Train Loss 44.666115 Test MSE 8.52273410286287 Test RE 1.3953961806144137\n",
      "12 Train Loss 44.54937 Test MSE 8.303313503728175 Test RE 1.3773165882343092\n",
      "13 Train Loss 43.99848 Test MSE 8.450296382130576 Test RE 1.3894535445765475\n",
      "14 Train Loss 43.193115 Test MSE 8.0495343329619 Test RE 1.3561053796789477\n",
      "15 Train Loss 42.05461 Test MSE 7.9587243781288795 Test RE 1.3484343048022907\n",
      "16 Train Loss 40.950653 Test MSE 8.023937885373178 Test RE 1.3539475456185461\n",
      "17 Train Loss 39.383858 Test MSE 7.490841747102167 Test RE 1.3081976702597848\n",
      "18 Train Loss 36.493942 Test MSE 7.290327630408785 Test RE 1.2905700531014874\n",
      "19 Train Loss 35.2909 Test MSE 6.997644451816355 Test RE 1.2643985713263484\n",
      "20 Train Loss 34.780354 Test MSE 7.152950961774558 Test RE 1.278352673714504\n",
      "21 Train Loss 34.33441 Test MSE 6.970372272743047 Test RE 1.2619322722737776\n",
      "22 Train Loss 34.10428 Test MSE 7.051931414778141 Test RE 1.2692936289901136\n",
      "23 Train Loss 33.83348 Test MSE 7.0979542403902665 Test RE 1.27342877120795\n",
      "24 Train Loss 33.68108 Test MSE 7.117717589932027 Test RE 1.2752003889649068\n",
      "25 Train Loss 33.51185 Test MSE 7.044554897249723 Test RE 1.268629596974287\n",
      "26 Train Loss 33.37897 Test MSE 7.041244956588383 Test RE 1.268331524057811\n",
      "27 Train Loss 33.118988 Test MSE 7.065297308316162 Test RE 1.2704959387792716\n",
      "28 Train Loss 32.8054 Test MSE 7.094764405643282 Test RE 1.2731425983419395\n",
      "29 Train Loss 32.371437 Test MSE 7.062467010017591 Test RE 1.2702414383294605\n",
      "30 Train Loss 32.055878 Test MSE 7.106841551113272 Test RE 1.27422574850631\n",
      "31 Train Loss 31.531708 Test MSE 7.005010526250289 Test RE 1.2650638812272759\n",
      "32 Train Loss 31.218994 Test MSE 7.142455699522571 Test RE 1.277414489482226\n",
      "33 Train Loss 30.73128 Test MSE 6.917364510325871 Test RE 1.257124791157319\n",
      "34 Train Loss 30.219234 Test MSE 7.082934869006004 Test RE 1.2720807610988998\n",
      "35 Train Loss 29.182854 Test MSE 7.023824721504975 Test RE 1.266761608789727\n",
      "36 Train Loss 28.45663 Test MSE 6.997577500993774 Test RE 1.2643925226675827\n",
      "37 Train Loss 27.347618 Test MSE 7.1160539540278105 Test RE 1.27505135290781\n",
      "38 Train Loss 25.72945 Test MSE 6.785272445267576 Test RE 1.2450640843111327\n",
      "39 Train Loss 24.60772 Test MSE 7.0185635885574165 Test RE 1.2662870917008486\n",
      "40 Train Loss 23.29248 Test MSE 7.102782177026417 Test RE 1.273861782475146\n",
      "41 Train Loss 22.501673 Test MSE 6.913402426546078 Test RE 1.256764715642747\n",
      "42 Train Loss 21.07412 Test MSE 6.8816102676854465 Test RE 1.253871689764652\n",
      "43 Train Loss 19.964983 Test MSE 6.861383497735234 Test RE 1.2520276128107728\n",
      "44 Train Loss 18.701027 Test MSE 6.889515821979177 Test RE 1.2545917033297247\n",
      "45 Train Loss 17.422676 Test MSE 6.58056943977423 Test RE 1.2261392599898457\n",
      "46 Train Loss 16.457706 Test MSE 6.743030683010022 Test RE 1.2411824559109745\n",
      "47 Train Loss 14.608074 Test MSE 6.558631156356945 Test RE 1.224093703935198\n",
      "48 Train Loss 13.077532 Test MSE 6.614387742845463 Test RE 1.229285857815814\n",
      "49 Train Loss 11.446158 Test MSE 6.566287732357363 Test RE 1.2248080018208414\n",
      "50 Train Loss 10.101141 Test MSE 6.297161481802587 Test RE 1.1994453785076993\n",
      "51 Train Loss 9.26147 Test MSE 5.935080789015475 Test RE 1.1644514279241849\n",
      "52 Train Loss 8.606652 Test MSE 5.904101572723817 Test RE 1.1614084205422124\n",
      "53 Train Loss 7.933245 Test MSE 6.156146173828895 Test RE 1.1859394662145635\n",
      "54 Train Loss 7.195958 Test MSE 6.072820766893559 Test RE 1.17788608716237\n",
      "55 Train Loss 6.7286706 Test MSE 6.138364538839811 Test RE 1.1842254724319758\n",
      "56 Train Loss 6.2790365 Test MSE 6.057409527413728 Test RE 1.1763905534885808\n",
      "57 Train Loss 5.7878213 Test MSE 6.0364261076219385 Test RE 1.1743512236950988\n",
      "58 Train Loss 5.405764 Test MSE 5.960138699739832 Test RE 1.1669069957307014\n",
      "59 Train Loss 4.6323295 Test MSE 5.6676763544906645 Test RE 1.13791698913918\n",
      "60 Train Loss 4.0743594 Test MSE 5.624196862006135 Test RE 1.1335438294440707\n",
      "61 Train Loss 3.7467608 Test MSE 5.4190465298357635 Test RE 1.1126779976549062\n",
      "62 Train Loss 3.5004854 Test MSE 5.501753243827907 Test RE 1.1211368164208315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Train Loss 3.2365804 Test MSE 5.264278851080714 Test RE 1.0966738887687177\n",
      "64 Train Loss 3.0742848 Test MSE 5.193304590046708 Test RE 1.0892559922038492\n",
      "65 Train Loss 2.8707047 Test MSE 5.088145419605766 Test RE 1.0781714258079735\n",
      "66 Train Loss 2.7364256 Test MSE 4.859362676877705 Test RE 1.0536532646754841\n",
      "67 Train Loss 2.4667568 Test MSE 4.486579156128946 Test RE 1.0124316829135245\n",
      "68 Train Loss 2.2329016 Test MSE 4.260674948659286 Test RE 0.9866139723679794\n",
      "69 Train Loss 2.0745075 Test MSE 4.1542163037062725 Test RE 0.9742100673547937\n",
      "70 Train Loss 1.8783988 Test MSE 4.2026402367707405 Test RE 0.9798715929153088\n",
      "71 Train Loss 1.7056029 Test MSE 4.227659351420652 Test RE 0.9827839456464486\n",
      "72 Train Loss 1.6071172 Test MSE 4.177672814220306 Test RE 0.976956602476875\n",
      "73 Train Loss 1.5436456 Test MSE 4.1699633982525 Test RE 0.976054755548224\n",
      "74 Train Loss 1.5035585 Test MSE 4.064608159125153 Test RE 0.9636457327459672\n",
      "75 Train Loss 1.464872 Test MSE 3.988735712738322 Test RE 0.9546093660404851\n",
      "76 Train Loss 1.4288834 Test MSE 4.0654235826003235 Test RE 0.9637423890429014\n",
      "77 Train Loss 1.3967423 Test MSE 4.055970460313704 Test RE 0.962621266408336\n",
      "78 Train Loss 1.3732281 Test MSE 3.9786519225356476 Test RE 0.9534019443394368\n",
      "79 Train Loss 1.3438569 Test MSE 3.880729754900155 Test RE 0.9415963374252376\n",
      "80 Train Loss 1.3140361 Test MSE 3.866872933225789 Test RE 0.939913767222686\n",
      "81 Train Loss 1.2877276 Test MSE 3.806172846056774 Test RE 0.9325074573261258\n",
      "82 Train Loss 1.2717065 Test MSE 3.7436523032893017 Test RE 0.9248170192749922\n",
      "83 Train Loss 1.2507275 Test MSE 3.7598755081433133 Test RE 0.9268187111211251\n",
      "84 Train Loss 1.220583 Test MSE 3.68836678041278 Test RE 0.9179628617734339\n",
      "85 Train Loss 1.1985971 Test MSE 3.5479411339119307 Test RE 0.9003186841348023\n",
      "86 Train Loss 1.1760484 Test MSE 3.4673647547404776 Test RE 0.8900365168307942\n",
      "87 Train Loss 1.1551589 Test MSE 3.450678111122285 Test RE 0.887892289908286\n",
      "88 Train Loss 1.1300251 Test MSE 3.4418995230147305 Test RE 0.886762163587974\n",
      "89 Train Loss 1.1076009 Test MSE 3.4453535742371506 Test RE 0.8872069984627403\n",
      "90 Train Loss 1.0936834 Test MSE 3.4581203214977863 Test RE 0.8888492499562166\n",
      "91 Train Loss 1.0774325 Test MSE 3.455235921688488 Test RE 0.8884784804045488\n",
      "92 Train Loss 1.0606632 Test MSE 3.461000511973824 Test RE 0.8892193241692592\n",
      "93 Train Loss 1.0437253 Test MSE 3.443459681725529 Test RE 0.8869631184621198\n",
      "94 Train Loss 1.0295495 Test MSE 3.365990998119569 Test RE 0.8769292078925337\n",
      "95 Train Loss 1.0134962 Test MSE 3.3129513607173373 Test RE 0.8699926632635911\n",
      "96 Train Loss 0.99539846 Test MSE 3.275814126048609 Test RE 0.8651027368452969\n",
      "97 Train Loss 0.97650105 Test MSE 3.27519770889056 Test RE 0.8650213388723537\n",
      "98 Train Loss 0.95545286 Test MSE 3.2319260873697524 Test RE 0.8592880463816966\n",
      "99 Train Loss 0.93914634 Test MSE 3.170808591565855 Test RE 0.8511244634750931\n",
      "Training time: 88.10\n",
      "7\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.888397 Test MSE 8.493400094491138 Test RE 1.3929927356358458\n",
      "1 Train Loss 55.575874 Test MSE 8.557718711894147 Test RE 1.39825719884427\n",
      "2 Train Loss 55.477375 Test MSE 8.492646765207626 Test RE 1.392930957933289\n",
      "3 Train Loss 55.215958 Test MSE 8.676583857103658 Test RE 1.4079344789885637\n",
      "4 Train Loss 52.1388 Test MSE 8.856429858310948 Test RE 1.4224512917147027\n",
      "5 Train Loss 48.187996 Test MSE 8.166405614090305 Test RE 1.3659145578594456\n",
      "6 Train Loss 45.529778 Test MSE 8.06583296278795 Test RE 1.3574776008328253\n",
      "7 Train Loss 43.29915 Test MSE 8.043635470251964 Test RE 1.3556083977911402\n",
      "8 Train Loss 42.90284 Test MSE 7.881076624725305 Test RE 1.341840313026979\n",
      "9 Train Loss 38.29384 Test MSE 6.652098069324737 Test RE 1.23278511485557\n",
      "10 Train Loss 30.302519 Test MSE 6.220097479371054 Test RE 1.1920834420852502\n",
      "11 Train Loss 27.856998 Test MSE 5.072010998287132 Test RE 1.076460637018165\n",
      "12 Train Loss 24.512608 Test MSE 2.391282111574991 Test RE 0.7391344894941055\n",
      "13 Train Loss 19.5555 Test MSE 2.970372028241327 Test RE 0.8237842483929438\n",
      "14 Train Loss 13.981009 Test MSE 2.605630774056289 Test RE 0.7715507499119062\n",
      "15 Train Loss 9.457204 Test MSE 1.9818024159898073 Test RE 0.6728809560684816\n",
      "16 Train Loss 6.953454 Test MSE 1.9678875664082405 Test RE 0.6705145419485729\n",
      "17 Train Loss 5.526116 Test MSE 1.809757786830861 Test RE 0.643010829405192\n",
      "18 Train Loss 5.2747984 Test MSE 1.8363644223522941 Test RE 0.6477202806274087\n",
      "19 Train Loss 5.021638 Test MSE 1.752706543818054 Test RE 0.632794454178962\n",
      "20 Train Loss 4.8041463 Test MSE 1.7711800949453103 Test RE 0.6361205440277319\n",
      "21 Train Loss 4.6491303 Test MSE 1.7550365206770326 Test RE 0.6332149201048385\n",
      "22 Train Loss 4.531458 Test MSE 1.7485367207937097 Test RE 0.6320412727220308\n",
      "23 Train Loss 4.3600554 Test MSE 1.7852699561595893 Test RE 0.6386457236328211\n",
      "24 Train Loss 4.2830024 Test MSE 1.7211708719496346 Test RE 0.6270758191551562\n",
      "25 Train Loss 4.054536 Test MSE 1.6841040932056814 Test RE 0.620286781025429\n",
      "26 Train Loss 3.896552 Test MSE 1.64535366514836 Test RE 0.6131090006437495\n",
      "27 Train Loss 3.819893 Test MSE 1.640874802030563 Test RE 0.6122739514204983\n",
      "28 Train Loss 3.7645774 Test MSE 1.6114908034826574 Test RE 0.6067670321770507\n",
      "29 Train Loss 3.6474447 Test MSE 1.4179132846627347 Test RE 0.5691580673952177\n",
      "30 Train Loss 3.5972905 Test MSE 1.4134560556535136 Test RE 0.5682627853334156\n",
      "31 Train Loss 3.505501 Test MSE 1.4004477406257259 Test RE 0.5656418238076772\n",
      "32 Train Loss 3.3995564 Test MSE 1.359072559019343 Test RE 0.5572234465519745\n",
      "33 Train Loss 3.3240728 Test MSE 1.3469132096350362 Test RE 0.5547251629232066\n",
      "34 Train Loss 3.0548806 Test MSE 1.102923274579152 Test RE 0.501973408030736\n",
      "35 Train Loss 2.570657 Test MSE 0.8594432621103588 Test RE 0.4431152185037269\n",
      "36 Train Loss 2.3641367 Test MSE 0.844205409836879 Test RE 0.4391694541515737\n",
      "37 Train Loss 2.205065 Test MSE 0.972030936855932 Test RE 0.4712464634669541\n",
      "38 Train Loss 2.1643348 Test MSE 0.9910950262183221 Test RE 0.4758452173108379\n",
      "39 Train Loss 2.0929172 Test MSE 1.001891266835281 Test RE 0.4784299465444342\n",
      "40 Train Loss 2.0717583 Test MSE 1.009878554814719 Test RE 0.4803332328234315\n",
      "41 Train Loss 2.0272398 Test MSE 1.063054148845759 Test RE 0.4928170828552789\n",
      "42 Train Loss 1.9970095 Test MSE 1.0862578260566957 Test RE 0.49816650013240626\n",
      "43 Train Loss 1.9559917 Test MSE 1.122022359631006 Test RE 0.5063010360469308\n",
      "44 Train Loss 1.9178557 Test MSE 1.1002078388860694 Test RE 0.5013550891682665\n",
      "45 Train Loss 1.8882868 Test MSE 1.0812035959504382 Test RE 0.49700619375350924\n",
      "46 Train Loss 1.8343157 Test MSE 1.075505023929227 Test RE 0.49569470749089856\n",
      "47 Train Loss 1.8023555 Test MSE 1.0943709354885458 Test RE 0.5000234076730651\n",
      "48 Train Loss 1.7222195 Test MSE 1.113149227051316 Test RE 0.5042951075202947\n",
      "49 Train Loss 1.7001693 Test MSE 1.1116653638423524 Test RE 0.5039588747478908\n",
      "50 Train Loss 1.6427289 Test MSE 1.0535413239815985 Test RE 0.4906071212485426\n",
      "51 Train Loss 1.5980403 Test MSE 1.0002574966165465 Test RE 0.4780397028430298\n",
      "52 Train Loss 1.5656631 Test MSE 0.9925294178024668 Test RE 0.47618943334259306\n",
      "53 Train Loss 1.5493559 Test MSE 0.9965106113614769 Test RE 0.47714351338442396\n",
      "54 Train Loss 1.5193247 Test MSE 0.9959639177706281 Test RE 0.4770126130790003\n",
      "55 Train Loss 1.4531602 Test MSE 0.9737979268605635 Test RE 0.47167459269659795\n",
      "56 Train Loss 1.4181693 Test MSE 0.947047123484844 Test RE 0.4651508885863948\n",
      "57 Train Loss 1.3742647 Test MSE 0.9258026002342231 Test RE 0.4599040757554967\n",
      "58 Train Loss 1.3347352 Test MSE 0.9024143576541546 Test RE 0.4540577141890605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Train Loss 1.3110088 Test MSE 0.8241984333757506 Test RE 0.4339342726904869\n",
      "60 Train Loss 1.2099342 Test MSE 0.5224828535539421 Test RE 0.34549684163216987\n",
      "61 Train Loss 0.9253193 Test MSE 0.2731076140365134 Test RE 0.24978995187888164\n",
      "62 Train Loss 0.7921263 Test MSE 0.21859105818448302 Test RE 0.22347258696933625\n",
      "63 Train Loss 0.72902584 Test MSE 0.17897290754246828 Test RE 0.20220957065738224\n",
      "64 Train Loss 0.5866244 Test MSE 0.07019318526697021 Test RE 0.1266355192723502\n",
      "65 Train Loss 0.40988183 Test MSE 0.03274054947514551 Test RE 0.08648704168052243\n",
      "66 Train Loss 0.25919536 Test MSE 0.03892452260450823 Test RE 0.09430174033126765\n",
      "67 Train Loss 0.19799364 Test MSE 0.02536483340098411 Test RE 0.076124432383072\n",
      "68 Train Loss 0.17195484 Test MSE 0.0216294413042357 Test RE 0.07029601581268197\n",
      "69 Train Loss 0.1490753 Test MSE 0.019312764626688142 Test RE 0.06642480437665052\n",
      "70 Train Loss 0.1367378 Test MSE 0.018125330499601734 Test RE 0.06435036690110679\n",
      "71 Train Loss 0.11552334 Test MSE 0.01497185489792113 Test RE 0.05848518459478097\n",
      "72 Train Loss 0.10247695 Test MSE 0.011645455111725694 Test RE 0.051580588534720355\n",
      "73 Train Loss 0.08306028 Test MSE 0.008959775363127287 Test RE 0.04524354445332995\n",
      "74 Train Loss 0.07528448 Test MSE 0.006432869223175356 Test RE 0.03833632000138494\n",
      "75 Train Loss 0.068857245 Test MSE 0.006009716400366579 Test RE 0.03705399591541558\n",
      "76 Train Loss 0.059940696 Test MSE 0.005735700439401496 Test RE 0.036199393219478855\n",
      "77 Train Loss 0.05370629 Test MSE 0.0043414274938564056 Test RE 0.03149374715119022\n",
      "78 Train Loss 0.04851886 Test MSE 0.003479207600130492 Test RE 0.028193450565805085\n",
      "79 Train Loss 0.04339205 Test MSE 0.0036910407476240725 Test RE 0.02903905505541181\n",
      "80 Train Loss 0.04075432 Test MSE 0.0029792651788496027 Test RE 0.02608931284865633\n",
      "81 Train Loss 0.038706325 Test MSE 0.0027396949877790226 Test RE 0.025018379033126637\n",
      "82 Train Loss 0.036186405 Test MSE 0.0024314793138743795 Test RE 0.023569119036878305\n",
      "83 Train Loss 0.033498064 Test MSE 0.0025642230626483735 Test RE 0.024203934068166816\n",
      "84 Train Loss 0.03177251 Test MSE 0.002831528746871238 Test RE 0.02543422728128945\n",
      "85 Train Loss 0.030276049 Test MSE 0.0026319126452172405 Test RE 0.024521317220152213\n",
      "86 Train Loss 0.028367281 Test MSE 0.0028954039110962214 Test RE 0.025719506940865982\n",
      "87 Train Loss 0.027113724 Test MSE 0.00292559010609794 Test RE 0.025853229389078237\n",
      "88 Train Loss 0.023983285 Test MSE 0.0024544782624553517 Test RE 0.023680324827403103\n",
      "89 Train Loss 0.023461554 Test MSE 0.0024720919294840818 Test RE 0.02376513954122875\n",
      "90 Train Loss 0.02268862 Test MSE 0.002422302019724947 Test RE 0.023524597740180404\n",
      "91 Train Loss 0.021387655 Test MSE 0.002124376353832842 Test RE 0.022030471374774256\n",
      "92 Train Loss 0.019902527 Test MSE 0.0017093021222648922 Test RE 0.01976138940658474\n",
      "93 Train Loss 0.018092923 Test MSE 0.0013642161864966655 Test RE 0.017654265734241115\n",
      "94 Train Loss 0.01680735 Test MSE 0.0012350760375783843 Test RE 0.016797896776451358\n",
      "95 Train Loss 0.015482215 Test MSE 0.0010343892936376395 Test RE 0.015372697051606701\n",
      "96 Train Loss 0.014776369 Test MSE 0.000959953342044853 Test RE 0.014809251980726069\n",
      "97 Train Loss 0.01409104 Test MSE 0.0009393969962597176 Test RE 0.01464983198366193\n",
      "98 Train Loss 0.0122685805 Test MSE 0.0007829295209183002 Test RE 0.013374248694580565\n",
      "99 Train Loss 0.011344305 Test MSE 0.0007835672336899435 Test RE 0.013379694391117842\n",
      "Training time: 88.14\n",
      "8\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.013752 Test MSE 8.338267283979757 Test RE 1.3802125322690182\n",
      "1 Train Loss 54.463226 Test MSE 8.028702728421456 Test RE 1.3543494922797972\n",
      "2 Train Loss 44.14547 Test MSE 7.960506121122886 Test RE 1.3485852353289143\n",
      "3 Train Loss 33.84926 Test MSE 7.15689236444478 Test RE 1.2787048226935542\n",
      "4 Train Loss 29.350246 Test MSE 6.706511072031617 Test RE 1.2378168298527807\n",
      "5 Train Loss 26.177563 Test MSE 6.3827999940318065 Test RE 1.2075737900812757\n",
      "6 Train Loss 23.651278 Test MSE 6.140488225569986 Test RE 1.184430307646741\n",
      "7 Train Loss 21.62698 Test MSE 5.8553506217500955 Test RE 1.1566035295228059\n",
      "8 Train Loss 20.719986 Test MSE 5.721277682765921 Test RE 1.143285179361876\n",
      "9 Train Loss 17.555367 Test MSE 5.770987993755543 Test RE 1.1482412527606476\n",
      "10 Train Loss 16.060982 Test MSE 5.616652236662297 Test RE 1.1327832734276473\n",
      "11 Train Loss 14.53697 Test MSE 5.897105254306504 Test RE 1.1607200862004483\n",
      "12 Train Loss 13.509039 Test MSE 5.922311937136573 Test RE 1.1631981413931738\n",
      "13 Train Loss 12.232969 Test MSE 5.945272092510447 Test RE 1.1654507561797025\n",
      "14 Train Loss 11.375728 Test MSE 5.930597021956629 Test RE 1.1640114915853068\n",
      "15 Train Loss 10.941066 Test MSE 5.889302805353408 Test RE 1.159951958749757\n",
      "16 Train Loss 10.319239 Test MSE 5.835977985378008 Test RE 1.1546886123028333\n",
      "17 Train Loss 9.641486 Test MSE 5.794129021110089 Test RE 1.150541110112673\n",
      "18 Train Loss 9.025792 Test MSE 5.8499480308741525 Test RE 1.1560698212860354\n",
      "19 Train Loss 8.374329 Test MSE 5.619433833851538 Test RE 1.1330637391404592\n",
      "20 Train Loss 7.6396995 Test MSE 5.574704837977781 Test RE 1.1285453072872602\n",
      "21 Train Loss 7.013417 Test MSE 5.504583356517343 Test RE 1.1214251368391566\n",
      "22 Train Loss 6.2600365 Test MSE 5.568530061025996 Test RE 1.1279201220550787\n",
      "23 Train Loss 5.51252 Test MSE 5.495622221654464 Test RE 1.1205119582692789\n",
      "24 Train Loss 5.0622206 Test MSE 5.398111742365338 Test RE 1.1105266765884767\n",
      "25 Train Loss 4.5838623 Test MSE 5.1772059579455645 Test RE 1.0875663992094269\n",
      "26 Train Loss 4.124289 Test MSE 5.033014216501843 Test RE 1.0723144017784643\n",
      "27 Train Loss 3.603704 Test MSE 4.709353251991625 Test RE 1.0372625412934826\n",
      "28 Train Loss 2.956477 Test MSE 4.087326106447444 Test RE 0.9663349893124439\n",
      "29 Train Loss 2.5461097 Test MSE 3.820519634506433 Test RE 0.9342632766781063\n",
      "30 Train Loss 2.2028236 Test MSE 3.5016694558519825 Test RE 0.89442851064131\n",
      "31 Train Loss 1.9596856 Test MSE 3.2253374872777876 Test RE 0.8584117278215956\n",
      "32 Train Loss 1.7937021 Test MSE 3.059293058802168 Test RE 0.8360237226162819\n",
      "33 Train Loss 1.6430645 Test MSE 2.810005047757866 Test RE 0.8012381329847855\n",
      "34 Train Loss 1.4716927 Test MSE 2.6663286184216486 Test RE 0.7804856046959414\n",
      "35 Train Loss 1.3430438 Test MSE 2.539407724039392 Test RE 0.761683027558103\n",
      "36 Train Loss 1.2361895 Test MSE 2.4050673465916677 Test RE 0.7412619047851988\n",
      "37 Train Loss 1.1508025 Test MSE 2.3058265831628915 Test RE 0.7258073822629183\n",
      "38 Train Loss 1.0628502 Test MSE 2.2134550209765593 Test RE 0.7111208476894612\n",
      "39 Train Loss 0.9909122 Test MSE 2.186122180882272 Test RE 0.7067165724998006\n",
      "40 Train Loss 0.9412115 Test MSE 2.161724409500243 Test RE 0.7027619245911227\n",
      "41 Train Loss 0.9097744 Test MSE 2.15460120724299 Test RE 0.7016031168536422\n",
      "42 Train Loss 0.8802675 Test MSE 2.113890932260725 Test RE 0.6949432615497307\n",
      "43 Train Loss 0.8557937 Test MSE 2.038921410563907 Test RE 0.6825088755950537\n",
      "44 Train Loss 0.83384556 Test MSE 2.0042128428236428 Test RE 0.6766747647700301\n",
      "45 Train Loss 0.8091075 Test MSE 1.9786592613392928 Test RE 0.6723471470105378\n",
      "46 Train Loss 0.7878258 Test MSE 1.9635399228331765 Test RE 0.6697734502871235\n",
      "47 Train Loss 0.772583 Test MSE 1.930685154789934 Test RE 0.6641463480283628\n",
      "48 Train Loss 0.7589183 Test MSE 1.9488645732083834 Test RE 0.6672658378898921\n",
      "49 Train Loss 0.74305975 Test MSE 1.9339047419994924 Test RE 0.6646998785673369\n",
      "50 Train Loss 0.71995586 Test MSE 1.8700876908860296 Test RE 0.6536406393315535\n",
      "51 Train Loss 0.68501234 Test MSE 1.8044714865034452 Test RE 0.6420710256806932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 0.6431184 Test MSE 1.6025869141707634 Test RE 0.605088440580696\n",
      "53 Train Loss 0.58534646 Test MSE 1.4535939538330884 Test RE 0.5762747808163594\n",
      "54 Train Loss 0.54678905 Test MSE 1.4077519198167143 Test RE 0.5671149869940925\n",
      "55 Train Loss 0.51935947 Test MSE 1.3355197183558223 Test RE 0.5523739799376538\n",
      "56 Train Loss 0.4465272 Test MSE 1.0803939589776244 Test RE 0.4968200724942365\n",
      "57 Train Loss 0.38630617 Test MSE 0.9413099326955284 Test RE 0.4637398113093693\n",
      "58 Train Loss 0.35372466 Test MSE 0.8640338981903182 Test RE 0.44429707173532723\n",
      "59 Train Loss 0.2921339 Test MSE 0.7744154993162994 Test RE 0.4206249970327788\n",
      "60 Train Loss 0.26962033 Test MSE 0.7175537966875883 Test RE 0.40488836192875055\n",
      "61 Train Loss 0.23130268 Test MSE 0.5837411717887352 Test RE 0.36518945034010664\n",
      "62 Train Loss 0.20379342 Test MSE 0.5201708375671525 Test RE 0.3447315726346196\n",
      "63 Train Loss 0.16900319 Test MSE 0.4097469542282669 Test RE 0.30596089826305006\n",
      "64 Train Loss 0.13535939 Test MSE 0.33775268748720993 Test RE 0.2777841532834084\n",
      "65 Train Loss 0.11095918 Test MSE 0.29531488063623207 Test RE 0.2597471110018723\n",
      "66 Train Loss 0.09348331 Test MSE 0.25819891055557737 Test RE 0.24287636981166855\n",
      "67 Train Loss 0.07869427 Test MSE 0.24522936857140762 Test RE 0.23669784297569038\n",
      "68 Train Loss 0.06904829 Test MSE 0.21492473441691778 Test RE 0.22159056235963726\n",
      "69 Train Loss 0.057372883 Test MSE 0.19963049659778598 Test RE 0.21356078267990827\n",
      "70 Train Loss 0.049385954 Test MSE 0.17783216732983426 Test RE 0.20156411731028723\n",
      "71 Train Loss 0.040965393 Test MSE 0.17595337759569613 Test RE 0.20049653165493733\n",
      "72 Train Loss 0.037219346 Test MSE 0.1608970544156108 Test RE 0.19172648356585545\n",
      "73 Train Loss 0.031294394 Test MSE 0.146029518472816 Test RE 0.18265366330393157\n",
      "74 Train Loss 0.02797704 Test MSE 0.14717260798760684 Test RE 0.1833671577072498\n",
      "75 Train Loss 0.024990173 Test MSE 0.13921334346338932 Test RE 0.17833988911009843\n",
      "76 Train Loss 0.022535412 Test MSE 0.14083795400012683 Test RE 0.17937747811375418\n",
      "77 Train Loss 0.020135026 Test MSE 0.1383352721107788 Test RE 0.17777657078223058\n",
      "78 Train Loss 0.018218398 Test MSE 0.12715384316883088 Test RE 0.1704405024522985\n",
      "79 Train Loss 0.016533338 Test MSE 0.12549030496242508 Test RE 0.16932190564816557\n",
      "80 Train Loss 0.014921774 Test MSE 0.12134293563043932 Test RE 0.16650041068290003\n",
      "81 Train Loss 0.013970496 Test MSE 0.11654519120246355 Test RE 0.16317560802203684\n",
      "82 Train Loss 0.012750701 Test MSE 0.11254726472505096 Test RE 0.1603524251789592\n",
      "83 Train Loss 0.011798387 Test MSE 0.10900076549866408 Test RE 0.15780575385731793\n",
      "84 Train Loss 0.011135876 Test MSE 0.1048891602582838 Test RE 0.15480085836970975\n",
      "85 Train Loss 0.01041818 Test MSE 0.1021010125231289 Test RE 0.15272955442964878\n",
      "86 Train Loss 0.0097189555 Test MSE 0.09732459893251717 Test RE 0.14911432661523408\n",
      "87 Train Loss 0.009261322 Test MSE 0.0958747217443598 Test RE 0.14799945581935717\n",
      "88 Train Loss 0.008815816 Test MSE 0.09678878651552518 Test RE 0.14870329189552428\n",
      "89 Train Loss 0.008300136 Test MSE 0.09633098212887395 Test RE 0.14835119681996492\n",
      "90 Train Loss 0.0076951943 Test MSE 0.09304868486548641 Test RE 0.14580189880374145\n",
      "91 Train Loss 0.007223052 Test MSE 0.09043600693640536 Test RE 0.14374036705114973\n",
      "92 Train Loss 0.006892104 Test MSE 0.08818114996763038 Test RE 0.1419371038222193\n",
      "93 Train Loss 0.006247525 Test MSE 0.08299747052110601 Test RE 0.13770207629260275\n",
      "94 Train Loss 0.005857925 Test MSE 0.07994276413107189 Test RE 0.13514427118903374\n",
      "95 Train Loss 0.0055456897 Test MSE 0.07539392390924528 Test RE 0.13124302558522144\n",
      "96 Train Loss 0.0052595935 Test MSE 0.07226981329638289 Test RE 0.1284950881503664\n",
      "97 Train Loss 0.0046964423 Test MSE 0.0680354740122088 Test RE 0.12467396390831405\n",
      "98 Train Loss 0.004303619 Test MSE 0.061277811395062644 Test RE 0.11832041468104382\n",
      "99 Train Loss 0.004153382 Test MSE 0.05886372517374625 Test RE 0.11596633493591409\n",
      "Training time: 87.54\n",
      "9\n",
      "KG_rowdy_tune0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.164062 Test MSE 8.463805935417081 Test RE 1.3905637660142427\n",
      "1 Train Loss 56.676308 Test MSE 8.619508235403812 Test RE 1.4032960564332013\n",
      "2 Train Loss 56.468323 Test MSE 8.688413549370429 Test RE 1.4088939440693573\n",
      "3 Train Loss 56.09508 Test MSE 8.591837599241911 Test RE 1.4010417916256768\n",
      "4 Train Loss 53.19526 Test MSE 8.226516514638673 Test RE 1.3709324213101628\n",
      "5 Train Loss 46.64205 Test MSE 8.6654557040398 Test RE 1.4070313160892014\n",
      "6 Train Loss 45.346066 Test MSE 8.641445143857526 Test RE 1.4050806370977957\n",
      "7 Train Loss 44.30468 Test MSE 8.645402518418573 Test RE 1.4054023306235248\n",
      "8 Train Loss 43.965714 Test MSE 8.361851766017827 Test RE 1.3821630941372256\n",
      "9 Train Loss 43.547035 Test MSE 8.547891552833756 Test RE 1.3974541318453328\n",
      "10 Train Loss 43.50506 Test MSE 8.504027846601696 Test RE 1.393863985845023\n",
      "11 Train Loss 43.477688 Test MSE 8.417911395254045 Test RE 1.3867885120311318\n",
      "12 Train Loss 43.38892 Test MSE 8.468776129123926 Test RE 1.3909719958927182\n",
      "13 Train Loss 43.26068 Test MSE 8.444214869254981 Test RE 1.3889534733300637\n",
      "14 Train Loss 43.09523 Test MSE 8.395879989162196 Test RE 1.3849725676450253\n",
      "15 Train Loss 43.03119 Test MSE 8.360749018291074 Test RE 1.3820719523956864\n",
      "16 Train Loss 42.893417 Test MSE 8.450751834223341 Test RE 1.3894909882926763\n",
      "17 Train Loss 42.83534 Test MSE 8.329563441935873 Test RE 1.379491981580425\n",
      "18 Train Loss 42.76134 Test MSE 8.383786138742673 Test RE 1.3839747158892077\n",
      "19 Train Loss 42.661064 Test MSE 8.412246849166099 Test RE 1.3863218375174788\n",
      "20 Train Loss 42.371883 Test MSE 8.342493221328494 Test RE 1.3805622423861061\n",
      "21 Train Loss 41.882812 Test MSE 8.061055992301958 Test RE 1.3570755598486102\n",
      "22 Train Loss 40.484528 Test MSE 7.910696099467718 Test RE 1.3443594696150543\n",
      "23 Train Loss 38.70227 Test MSE 6.688296057011925 Test RE 1.236134719575661\n",
      "24 Train Loss 35.320705 Test MSE 6.704257637254489 Test RE 1.237608854810995\n",
      "25 Train Loss 33.97081 Test MSE 6.87955039377294 Test RE 1.2536840148752966\n",
      "26 Train Loss 33.770653 Test MSE 6.91201951372688 Test RE 1.2566390117670112\n",
      "27 Train Loss 33.49401 Test MSE 7.063506538011516 Test RE 1.2703349186208666\n",
      "28 Train Loss 33.32292 Test MSE 7.057743096330389 Test RE 1.2698165503517185\n",
      "29 Train Loss 33.190254 Test MSE 6.9831602837358835 Test RE 1.2630893273285613\n",
      "30 Train Loss 32.949024 Test MSE 6.986393918548038 Test RE 1.2633817376939493\n",
      "31 Train Loss 32.871506 Test MSE 7.044605785057356 Test RE 1.2686341790709024\n",
      "32 Train Loss 32.83257 Test MSE 7.049289175554246 Test RE 1.2690558153029379\n",
      "33 Train Loss 32.728867 Test MSE 6.9733714763237575 Test RE 1.262203734442523\n",
      "34 Train Loss 32.56171 Test MSE 6.921918878371535 Test RE 1.2575385662939784\n",
      "35 Train Loss 32.499725 Test MSE 6.892130826201817 Test RE 1.2548297789385072\n",
      "36 Train Loss 32.363937 Test MSE 6.951716312076275 Test RE 1.26024238170973\n",
      "37 Train Loss 32.287884 Test MSE 6.92549428968133 Test RE 1.257863305519345\n",
      "38 Train Loss 32.22903 Test MSE 6.9140589158693535 Test RE 1.2568243847449623\n",
      "39 Train Loss 32.118393 Test MSE 6.952654528638088 Test RE 1.2603274211683306\n",
      "40 Train Loss 31.970755 Test MSE 6.953939875561836 Test RE 1.2604439150271145\n",
      "41 Train Loss 31.81266 Test MSE 7.005935193907217 Test RE 1.2651473732542051\n",
      "42 Train Loss 31.422405 Test MSE 6.928982486662645 Test RE 1.2581800426683827\n",
      "43 Train Loss 31.231577 Test MSE 6.964298595301545 Test RE 1.2613823561684883\n",
      "44 Train Loss 30.88668 Test MSE 6.995034031857386 Test RE 1.2641627120194021\n",
      "45 Train Loss 30.653732 Test MSE 6.945281681004931 Test RE 1.2596589954066215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 30.417828 Test MSE 6.938500931696565 Test RE 1.2590439362884787\n",
      "47 Train Loss 29.984482 Test MSE 6.695321562994943 Test RE 1.2367837782006064\n",
      "48 Train Loss 28.909266 Test MSE 6.611430717739215 Test RE 1.229011045116203\n",
      "49 Train Loss 28.415644 Test MSE 6.728210525070707 Test RE 1.239817740317478\n",
      "50 Train Loss 28.187233 Test MSE 6.612838122644478 Test RE 1.229141850701563\n",
      "51 Train Loss 27.932837 Test MSE 6.66028698012328 Test RE 1.2335436772136175\n",
      "52 Train Loss 27.726942 Test MSE 6.7718845846958615 Test RE 1.243835174580835\n",
      "53 Train Loss 27.594467 Test MSE 6.778606721144616 Test RE 1.2444523702622214\n",
      "54 Train Loss 27.357204 Test MSE 6.73153370390351 Test RE 1.2401238861663555\n",
      "55 Train Loss 27.21188 Test MSE 6.743382541202208 Test RE 1.2412148385693564\n",
      "56 Train Loss 27.06593 Test MSE 6.792651899987498 Test RE 1.2457409471303544\n",
      "57 Train Loss 26.905441 Test MSE 6.885430224914579 Test RE 1.2542196513268804\n",
      "58 Train Loss 26.721031 Test MSE 6.887619193539882 Test RE 1.254419001927173\n",
      "59 Train Loss 26.590317 Test MSE 6.805905701066715 Test RE 1.246955697778829\n",
      "60 Train Loss 26.485779 Test MSE 6.775377712918446 Test RE 1.2441559357766638\n",
      "61 Train Loss 26.411142 Test MSE 6.739026081813495 Test RE 1.2408138398411732\n",
      "62 Train Loss 26.344011 Test MSE 6.671701485773444 Test RE 1.2346002580878757\n",
      "63 Train Loss 26.225895 Test MSE 6.617532789307865 Test RE 1.2295780769766707\n",
      "64 Train Loss 26.091333 Test MSE 6.603596717115982 Test RE 1.228282690882909\n",
      "65 Train Loss 25.978376 Test MSE 6.609764982088487 Test RE 1.2288562120275708\n",
      "66 Train Loss 25.715485 Test MSE 6.5414444744108025 Test RE 1.2224888027622378\n",
      "67 Train Loss 25.507622 Test MSE 6.622409902449219 Test RE 1.2300310922535513\n",
      "68 Train Loss 25.350084 Test MSE 6.6005880023614845 Test RE 1.228002845410158\n",
      "69 Train Loss 25.230316 Test MSE 6.503720802341892 Test RE 1.2189587379072284\n",
      "70 Train Loss 24.93143 Test MSE 6.650676780116642 Test RE 1.2326534092070445\n",
      "71 Train Loss 24.799221 Test MSE 6.7059878486720725 Test RE 1.2377685433960968\n",
      "72 Train Loss 24.605679 Test MSE 6.671736774760233 Test RE 1.2346035232020809\n",
      "73 Train Loss 24.273874 Test MSE 6.5953781000655125 Test RE 1.22751811300488\n",
      "74 Train Loss 23.718708 Test MSE 6.518211971698682 Test RE 1.2203159847411125\n",
      "75 Train Loss 23.610863 Test MSE 6.4016702589668215 Test RE 1.2093575229284297\n",
      "76 Train Loss 23.245098 Test MSE 6.49911717937485 Test RE 1.218527244920089\n",
      "77 Train Loss 22.851679 Test MSE 6.584885022771331 Test RE 1.2265412494015329\n",
      "78 Train Loss 22.599937 Test MSE 6.526526508520748 Test RE 1.2210940454008123\n",
      "79 Train Loss 21.892475 Test MSE 6.468607405753327 Test RE 1.215663723348499\n",
      "80 Train Loss 21.348219 Test MSE 6.272974418684162 Test RE 1.1971396593137504\n",
      "81 Train Loss 19.822258 Test MSE 6.08909976531104 Test RE 1.1794637702135282\n",
      "82 Train Loss 19.076126 Test MSE 5.92090865933252 Test RE 1.1630603247048485\n",
      "83 Train Loss 18.11416 Test MSE 5.490157534864961 Test RE 1.1199547174691735\n",
      "84 Train Loss 16.463099 Test MSE 5.331492958719953 Test RE 1.1036528275015112\n",
      "85 Train Loss 15.270626 Test MSE 5.174649875051732 Test RE 1.0872978901816288\n",
      "86 Train Loss 14.593405 Test MSE 5.207581667500491 Test RE 1.0907522185813896\n",
      "87 Train Loss 13.441765 Test MSE 5.103193613702844 Test RE 1.079764595149419\n",
      "88 Train Loss 11.842063 Test MSE 4.610852402869294 Test RE 1.0263575241453793\n",
      "89 Train Loss 11.171357 Test MSE 4.586262535121484 Test RE 1.023617061816668\n",
      "90 Train Loss 9.996143 Test MSE 4.077624940596391 Test RE 0.9651875221241157\n",
      "91 Train Loss 9.1650305 Test MSE 3.813020749770857 Test RE 0.933345944159252\n",
      "92 Train Loss 8.776573 Test MSE 3.9210840104041678 Test RE 0.9464793300088491\n",
      "93 Train Loss 8.289575 Test MSE 4.036583782221344 Test RE 0.9603179480794207\n",
      "94 Train Loss 7.6671515 Test MSE 4.269654810320663 Test RE 0.987653126236622\n",
      "95 Train Loss 7.3036604 Test MSE 4.45135596992512 Test RE 1.0084496582543074\n",
      "96 Train Loss 6.999041 Test MSE 4.570597289155306 Test RE 1.021867387742666\n",
      "97 Train Loss 6.7887087 Test MSE 4.602378694466719 Test RE 1.0254139834397857\n",
      "98 Train Loss 6.494017 Test MSE 4.508753899040933 Test RE 1.0149305511796414\n",
      "99 Train Loss 6.3680077 Test MSE 4.487977019367386 Test RE 1.0125893900177383\n",
      "Training time: 89.45\n",
      "0\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 55.10288 Test MSE 7.619968024073301 Test RE 1.3194247753273254\n",
      "1 Train Loss 43.0766 Test MSE 7.373918128529056 Test RE 1.297947768101076\n",
      "2 Train Loss 30.492542 Test MSE 6.742034827153761 Test RE 1.2410907994648226\n",
      "3 Train Loss 25.937485 Test MSE 6.417998152363989 Test RE 1.210898814880612\n",
      "4 Train Loss 23.013166 Test MSE 5.9000253600856905 Test RE 1.1610074310755003\n",
      "5 Train Loss 21.20073 Test MSE 5.619578960150425 Test RE 1.1330783701771492\n",
      "6 Train Loss 17.638615 Test MSE 5.735714952806097 Test RE 1.1447267731805175\n",
      "7 Train Loss 15.138182 Test MSE 5.953138383912134 Test RE 1.1662215152479336\n",
      "8 Train Loss 13.661163 Test MSE 5.992405261212851 Test RE 1.1700613899628596\n",
      "9 Train Loss 12.242676 Test MSE 5.929865377013982 Test RE 1.1639396885791495\n",
      "10 Train Loss 10.987333 Test MSE 5.776902711047707 Test RE 1.1488295214526514\n",
      "11 Train Loss 9.770706 Test MSE 5.809432037601636 Test RE 1.152059469424333\n",
      "12 Train Loss 8.823233 Test MSE 5.662740571614345 Test RE 1.1374213949858387\n",
      "13 Train Loss 7.985483 Test MSE 5.664400975153829 Test RE 1.1375881375786159\n",
      "14 Train Loss 7.186922 Test MSE 5.363460508642691 Test RE 1.106956625227141\n",
      "15 Train Loss 6.387395 Test MSE 5.183438089530746 Test RE 1.0882207887059143\n",
      "16 Train Loss 5.5141754 Test MSE 5.081907512382048 Test RE 1.0775103208907022\n",
      "17 Train Loss 4.8138313 Test MSE 4.997622881611042 Test RE 1.0685375805990442\n",
      "18 Train Loss 4.064279 Test MSE 4.620582397407798 Test RE 1.0274398826049946\n",
      "19 Train Loss 3.5745146 Test MSE 4.417160152322899 Test RE 1.0045686784609202\n",
      "20 Train Loss 3.1539776 Test MSE 4.17684111094299 Test RE 0.9768593499527017\n",
      "21 Train Loss 2.6572042 Test MSE 3.644095645349608 Test RE 0.9124371175888495\n",
      "22 Train Loss 2.3362079 Test MSE 3.2595410523535633 Test RE 0.8629513010374443\n",
      "23 Train Loss 2.0861688 Test MSE 2.9586027715940264 Test RE 0.8221506228791323\n",
      "24 Train Loss 1.9071132 Test MSE 2.8298794007126777 Test RE 0.8040666033433305\n",
      "25 Train Loss 1.811721 Test MSE 2.780031896255854 Test RE 0.7969534401522207\n",
      "26 Train Loss 1.6987922 Test MSE 2.585936810832189 Test RE 0.7686294394757521\n",
      "27 Train Loss 1.5546105 Test MSE 2.1317950286524634 Test RE 0.697880048903218\n",
      "28 Train Loss 1.4132881 Test MSE 1.9318289279269796 Test RE 0.6643430451123727\n",
      "29 Train Loss 1.3211163 Test MSE 1.7460536432885334 Test RE 0.6315923359000437\n",
      "30 Train Loss 1.2394623 Test MSE 1.5818309810713465 Test RE 0.6011572635366988\n",
      "31 Train Loss 1.1430085 Test MSE 1.3023905186372464 Test RE 0.5454798008018351\n",
      "32 Train Loss 0.89022064 Test MSE 0.729663620812691 Test RE 0.4082906243556753\n",
      "33 Train Loss 0.7255837 Test MSE 0.6213060779872759 Test RE 0.376756593374094\n",
      "34 Train Loss 0.54478556 Test MSE 0.4613064565504522 Test RE 0.3246405958852589\n",
      "35 Train Loss 0.4403302 Test MSE 0.4295940369302104 Test RE 0.3132832550293249\n",
      "36 Train Loss 0.3676304 Test MSE 0.4055095523047382 Test RE 0.3043747380509816\n",
      "37 Train Loss 0.29740793 Test MSE 0.30813247629985535 Test RE 0.2653241596340878\n",
      "38 Train Loss 0.2449694 Test MSE 0.250901949386993 Test RE 0.23941980793585982\n",
      "39 Train Loss 0.20339045 Test MSE 0.1776590872270836 Test RE 0.20146600449016497\n",
      "40 Train Loss 0.16549456 Test MSE 0.1188114912635318 Test RE 0.16475449935158698\n",
      "41 Train Loss 0.13916902 Test MSE 0.09167102601720907 Test RE 0.1447185179705369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 0.12060724 Test MSE 0.07165377665780147 Test RE 0.1279462622382318\n",
      "43 Train Loss 0.10831754 Test MSE 0.06229005125837476 Test RE 0.1192936713190463\n",
      "44 Train Loss 0.094349645 Test MSE 0.050835205584283186 Test RE 0.10776813133635353\n",
      "45 Train Loss 0.08906035 Test MSE 0.04858432595599404 Test RE 0.10535524253126803\n",
      "46 Train Loss 0.08020488 Test MSE 0.04230117617361787 Test RE 0.09830696348424435\n",
      "47 Train Loss 0.07166451 Test MSE 0.03851627158907241 Test RE 0.09380590559819371\n",
      "48 Train Loss 0.06385308 Test MSE 0.03634041662359695 Test RE 0.09111775508324073\n",
      "49 Train Loss 0.060327612 Test MSE 0.03338341254153426 Test RE 0.08733200379197506\n",
      "50 Train Loss 0.056039676 Test MSE 0.030161839739442222 Test RE 0.08301125395762413\n",
      "51 Train Loss 0.051515117 Test MSE 0.026788310777566732 Test RE 0.07823133196601018\n",
      "52 Train Loss 0.045960322 Test MSE 0.02481401295654918 Test RE 0.07529333996699694\n",
      "53 Train Loss 0.040424574 Test MSE 0.020418031182838962 Test RE 0.06829910169457795\n",
      "54 Train Loss 0.036783315 Test MSE 0.01792717975144727 Test RE 0.06399765292858574\n",
      "55 Train Loss 0.034254573 Test MSE 0.016090065632299734 Test RE 0.06062991621597394\n",
      "56 Train Loss 0.032354053 Test MSE 0.0150237237377075 Test RE 0.058586405714307094\n",
      "57 Train Loss 0.030772509 Test MSE 0.01420616500523537 Test RE 0.056970035179470586\n",
      "58 Train Loss 0.028391965 Test MSE 0.013090253636168414 Test RE 0.054686747071603585\n",
      "59 Train Loss 0.025993109 Test MSE 0.012119355299452572 Test RE 0.052619633534597685\n",
      "60 Train Loss 0.024591126 Test MSE 0.01190056377136597 Test RE 0.05214249741053336\n",
      "61 Train Loss 0.022982927 Test MSE 0.012042295909387638 Test RE 0.052452079119339017\n",
      "62 Train Loss 0.02159603 Test MSE 0.010857135324233245 Test RE 0.049804167579389345\n",
      "63 Train Loss 0.020557897 Test MSE 0.009391945763554522 Test RE 0.04632184491844225\n",
      "64 Train Loss 0.019847753 Test MSE 0.009040782122907563 Test RE 0.04544761129598486\n",
      "65 Train Loss 0.019034976 Test MSE 0.008793618143261437 Test RE 0.04482206506110618\n",
      "66 Train Loss 0.01795604 Test MSE 0.008608941085868696 Test RE 0.04434890774250758\n",
      "67 Train Loss 0.017181998 Test MSE 0.00822018871938896 Test RE 0.043336013151844655\n",
      "68 Train Loss 0.01542379 Test MSE 0.006331204119850024 Test RE 0.03803217984328011\n",
      "69 Train Loss 0.0138829425 Test MSE 0.0054983230680690914 Test RE 0.03544240528586229\n",
      "70 Train Loss 0.012976378 Test MSE 0.006079185950996489 Test RE 0.037267544112908335\n",
      "71 Train Loss 0.0114973 Test MSE 0.005495338932492865 Test RE 0.03543278605326117\n",
      "72 Train Loss 0.010685839 Test MSE 0.005360383957796982 Test RE 0.03499500095301451\n",
      "73 Train Loss 0.0100744115 Test MSE 0.005417917599785581 Test RE 0.035182302476865136\n",
      "74 Train Loss 0.009339433 Test MSE 0.005165491785743709 Test RE 0.034352938975498785\n",
      "75 Train Loss 0.008849536 Test MSE 0.0049900378689817495 Test RE 0.03376447342153551\n",
      "76 Train Loss 0.0084373895 Test MSE 0.0045357664420713276 Test RE 0.03219092098435664\n",
      "77 Train Loss 0.0074957195 Test MSE 0.00423503120863218 Test RE 0.031105441346902213\n",
      "78 Train Loss 0.0068785623 Test MSE 0.005124434014609169 Test RE 0.034216139896117846\n",
      "79 Train Loss 0.006617737 Test MSE 0.0056632704469104355 Test RE 0.03597010545911233\n",
      "80 Train Loss 0.006144784 Test MSE 0.005342869572919548 Test RE 0.03493778328013495\n",
      "81 Train Loss 0.0058455835 Test MSE 0.005156625882733644 Test RE 0.03432344511133973\n",
      "82 Train Loss 0.0056214943 Test MSE 0.0052939563839576355 Test RE 0.0347774904259854\n",
      "83 Train Loss 0.005350584 Test MSE 0.004923095556977201 Test RE 0.033537230287693016\n",
      "84 Train Loss 0.005175864 Test MSE 0.00471873448931807 Test RE 0.03283377599978736\n",
      "85 Train Loss 0.0049881707 Test MSE 0.004947340754694405 Test RE 0.033619710723082216\n",
      "86 Train Loss 0.004817254 Test MSE 0.005198046883050708 Test RE 0.0344610222664734\n",
      "87 Train Loss 0.0045181345 Test MSE 0.0052390045237380835 Test RE 0.03459652246106165\n",
      "88 Train Loss 0.004299627 Test MSE 0.005233025775048453 Test RE 0.034576776060898685\n",
      "89 Train Loss 0.0042168237 Test MSE 0.005339088131453149 Test RE 0.03492541740022714\n",
      "90 Train Loss 0.00411863 Test MSE 0.005349725042278494 Test RE 0.03496019053881522\n",
      "91 Train Loss 0.0039945594 Test MSE 0.005107637137819402 Test RE 0.03416001701348663\n",
      "92 Train Loss 0.0038927228 Test MSE 0.005100615229943126 Test RE 0.03413652758141419\n",
      "93 Train Loss 0.0037925262 Test MSE 0.005226384086560899 Test RE 0.034554826896278173\n",
      "94 Train Loss 0.00370815 Test MSE 0.005149964161915251 Test RE 0.03430126713006941\n",
      "95 Train Loss 0.00356826 Test MSE 0.004849210806896192 Test RE 0.03328461918334069\n",
      "96 Train Loss 0.003410832 Test MSE 0.004751114085456385 Test RE 0.03294623484184651\n",
      "97 Train Loss 0.0033396531 Test MSE 0.004712627399521496 Test RE 0.03281252202376606\n",
      "98 Train Loss 0.0032618898 Test MSE 0.0044561576636881935 Test RE 0.03190717353848343\n",
      "99 Train Loss 0.003124879 Test MSE 0.004123828648210534 Test RE 0.030694344698617534\n",
      "Training time: 88.15\n",
      "1\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.48087 Test MSE 8.277278081391797 Test RE 1.3751555730801122\n",
      "1 Train Loss 55.152954 Test MSE 9.053200969628087 Test RE 1.4381664093878064\n",
      "2 Train Loss 46.261917 Test MSE 8.436679318161575 Test RE 1.3883335894135898\n",
      "3 Train Loss 43.83565 Test MSE 8.367227391067415 Test RE 1.382607301772347\n",
      "4 Train Loss 42.793587 Test MSE 8.525213360240988 Test RE 1.3955991257418885\n",
      "5 Train Loss 41.562683 Test MSE 8.608307153923073 Test RE 1.402383965922875\n",
      "6 Train Loss 39.72078 Test MSE 8.557353802304887 Test RE 1.3982273869915636\n",
      "7 Train Loss 37.406425 Test MSE 8.903410104579349 Test RE 1.426219103561945\n",
      "8 Train Loss 34.448395 Test MSE 8.928385140318303 Test RE 1.428218052741644\n",
      "9 Train Loss 31.984894 Test MSE 8.60013485709581 Test RE 1.4017181312136913\n",
      "10 Train Loss 28.058174 Test MSE 8.485010414584178 Test RE 1.3923045748008187\n",
      "11 Train Loss 25.49635 Test MSE 8.81398428029868 Test RE 1.4190385575224655\n",
      "12 Train Loss 23.351875 Test MSE 8.369902243683025 Test RE 1.3828282814986166\n",
      "13 Train Loss 20.867762 Test MSE 8.438021017298672 Test RE 1.3884439795242283\n",
      "14 Train Loss 18.54906 Test MSE 7.962533674338212 Test RE 1.3487569677665998\n",
      "15 Train Loss 17.140945 Test MSE 7.850745334635304 Test RE 1.3392557053167344\n",
      "16 Train Loss 15.333181 Test MSE 7.677700289316449 Test RE 1.324413618062702\n",
      "17 Train Loss 13.237728 Test MSE 7.288791044289884 Test RE 1.2904340388759343\n",
      "18 Train Loss 10.777878 Test MSE 6.55405502061036 Test RE 1.2236665876464659\n",
      "19 Train Loss 9.511347 Test MSE 6.2512917023599 Test RE 1.1950688945349273\n",
      "20 Train Loss 8.248261 Test MSE 6.462616024915591 Test RE 1.2151006043337509\n",
      "21 Train Loss 7.33924 Test MSE 6.323155725517057 Test RE 1.2019184424405736\n",
      "22 Train Loss 6.642443 Test MSE 6.063580914944905 Test RE 1.1769896638640822\n",
      "23 Train Loss 5.819929 Test MSE 5.775389977946373 Test RE 1.1486790960156967\n",
      "24 Train Loss 5.240572 Test MSE 5.616831040182315 Test RE 1.1328013040993186\n",
      "25 Train Loss 4.471436 Test MSE 5.468724526435459 Test RE 1.1177664859046013\n",
      "26 Train Loss 3.8101835 Test MSE 5.34577784519146 Test RE 1.1051303694645873\n",
      "27 Train Loss 3.2449965 Test MSE 5.331017388367096 Test RE 1.103603603365448\n",
      "28 Train Loss 2.8279643 Test MSE 5.172404122735318 Test RE 1.087061925739389\n",
      "29 Train Loss 2.5873065 Test MSE 5.269225679287058 Test RE 1.097189038478696\n",
      "30 Train Loss 2.4098492 Test MSE 5.288014623846554 Test RE 1.0991434698085105\n",
      "31 Train Loss 2.2696028 Test MSE 5.227761666006331 Test RE 1.0928635724290179\n",
      "32 Train Loss 2.1550524 Test MSE 5.24902531744319 Test RE 1.0950839001116721\n",
      "33 Train Loss 2.0379398 Test MSE 5.2450690819804 Test RE 1.094671135250608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 1.9610636 Test MSE 5.2287493779400425 Test RE 1.0929668081425223\n",
      "35 Train Loss 1.8691667 Test MSE 5.209201375419545 Test RE 1.0909218330748975\n",
      "36 Train Loss 1.7879424 Test MSE 5.214503089497166 Test RE 1.0914768399131485\n",
      "37 Train Loss 1.7220067 Test MSE 5.279154424435118 Test RE 1.0982222627234843\n",
      "38 Train Loss 1.6546574 Test MSE 5.273767141767432 Test RE 1.097661761603437\n",
      "39 Train Loss 1.5961945 Test MSE 5.330006560739959 Test RE 1.1034989698765532\n",
      "40 Train Loss 1.5368686 Test MSE 5.3320483340965 Test RE 1.1037103091157485\n",
      "41 Train Loss 1.4984355 Test MSE 5.371918026090841 Test RE 1.1078290486506186\n",
      "42 Train Loss 1.4689723 Test MSE 5.427602173920202 Test RE 1.1135560047359858\n",
      "43 Train Loss 1.4411118 Test MSE 5.419001205082458 Test RE 1.1126733444413814\n",
      "44 Train Loss 1.4118497 Test MSE 5.412328868445909 Test RE 1.111988124273171\n",
      "45 Train Loss 1.3844209 Test MSE 5.442706713624743 Test RE 1.1151043924614188\n",
      "46 Train Loss 1.3638002 Test MSE 5.485913696075001 Test RE 1.1195217766941745\n",
      "47 Train Loss 1.3380512 Test MSE 5.522470778243715 Test RE 1.1232457228372952\n",
      "48 Train Loss 1.3175681 Test MSE 5.4974205320197225 Test RE 1.120695273585748\n",
      "49 Train Loss 1.2955242 Test MSE 5.5230444686361055 Test RE 1.1233040643451828\n",
      "50 Train Loss 1.2771463 Test MSE 5.55144080944027 Test RE 1.126188056164246\n",
      "51 Train Loss 1.2591813 Test MSE 5.555288447656658 Test RE 1.1265782624004528\n",
      "52 Train Loss 1.2496746 Test MSE 5.553534128775462 Test RE 1.1264003658257316\n",
      "53 Train Loss 1.2383031 Test MSE 5.570615274690307 Test RE 1.1281312849908691\n",
      "54 Train Loss 1.2289797 Test MSE 5.57415336629177 Test RE 1.1284894858407628\n",
      "55 Train Loss 1.2182856 Test MSE 5.579720831106813 Test RE 1.1290529128811704\n",
      "56 Train Loss 1.202333 Test MSE 5.602106798220412 Test RE 1.1313155387327525\n",
      "57 Train Loss 1.1884409 Test MSE 5.6123511307169895 Test RE 1.1323494603853446\n",
      "58 Train Loss 1.1795409 Test MSE 5.618121651821509 Test RE 1.1329314417662468\n",
      "59 Train Loss 1.1688043 Test MSE 5.621136091172503 Test RE 1.1332353418372063\n",
      "60 Train Loss 1.157943 Test MSE 5.624528470348788 Test RE 1.1335772463975704\n",
      "61 Train Loss 1.1473131 Test MSE 5.642068943560802 Test RE 1.1353434392044803\n",
      "62 Train Loss 1.1368963 Test MSE 5.647094174610349 Test RE 1.135848935798349\n",
      "63 Train Loss 1.1303669 Test MSE 5.647845276152076 Test RE 1.1359244710642826\n",
      "64 Train Loss 1.122565 Test MSE 5.653483968740775 Test RE 1.1364913714212788\n",
      "65 Train Loss 1.1132983 Test MSE 5.650687622050553 Test RE 1.1362102689204885\n",
      "66 Train Loss 1.1032 Test MSE 5.648011045219325 Test RE 1.1359411411171212\n",
      "67 Train Loss 1.0925367 Test MSE 5.668495087973899 Test RE 1.1379991760036487\n",
      "68 Train Loss 1.0822086 Test MSE 5.678248557827021 Test RE 1.1389778017267707\n",
      "69 Train Loss 1.074573 Test MSE 5.678173785189789 Test RE 1.1389703025257858\n",
      "70 Train Loss 1.0657681 Test MSE 5.6876626492048565 Test RE 1.13992157870589\n",
      "71 Train Loss 1.0589011 Test MSE 5.694341839766839 Test RE 1.1405907041416667\n",
      "72 Train Loss 1.0507817 Test MSE 5.708854222530714 Test RE 1.142043212295415\n",
      "73 Train Loss 1.0428847 Test MSE 5.758116463426876 Test RE 1.1469600273973317\n",
      "74 Train Loss 1.0373876 Test MSE 5.777293458165934 Test RE 1.148868373953435\n",
      "75 Train Loss 1.0301661 Test MSE 5.762363862826159 Test RE 1.1473829694588507\n",
      "76 Train Loss 1.0202955 Test MSE 5.784741963960873 Test RE 1.1496087376193618\n",
      "77 Train Loss 1.01403 Test MSE 5.821438685156636 Test RE 1.1532493647774664\n",
      "78 Train Loss 1.0086346 Test MSE 5.822026066799487 Test RE 1.153307544589768\n",
      "79 Train Loss 1.0032566 Test MSE 5.824264895007751 Test RE 1.1535292723227524\n",
      "80 Train Loss 0.9983891 Test MSE 5.829004725553068 Test RE 1.153998552262015\n",
      "81 Train Loss 0.99216837 Test MSE 5.834156371741064 Test RE 1.154508388809062\n",
      "82 Train Loss 0.9880271 Test MSE 5.843622931552714 Test RE 1.1554446675224392\n",
      "83 Train Loss 0.98314124 Test MSE 5.851473522002315 Test RE 1.1562205456420256\n",
      "84 Train Loss 0.97716033 Test MSE 5.843110839205666 Test RE 1.1553940390559798\n",
      "85 Train Loss 0.9731976 Test MSE 5.854290176049736 Test RE 1.1564987902119748\n",
      "86 Train Loss 0.9688287 Test MSE 5.869412212511659 Test RE 1.1579914850847903\n",
      "87 Train Loss 0.9654338 Test MSE 5.86832480818002 Test RE 1.157884211712368\n",
      "88 Train Loss 0.96134025 Test MSE 5.873496176800424 Test RE 1.1583942829576903\n",
      "89 Train Loss 0.9562465 Test MSE 5.891105480570021 Test RE 1.1601294718383708\n",
      "90 Train Loss 0.9518725 Test MSE 5.8982820673956855 Test RE 1.160835895770712\n",
      "91 Train Loss 0.9476051 Test MSE 5.919447700562524 Test RE 1.162916825783598\n",
      "92 Train Loss 0.9436456 Test MSE 5.93519077877536 Test RE 1.1644622177637949\n",
      "93 Train Loss 0.9389596 Test MSE 5.945044829102634 Test RE 1.1654284807617246\n",
      "94 Train Loss 0.9338047 Test MSE 5.9613748518296505 Test RE 1.1670279996039619\n",
      "95 Train Loss 0.9297763 Test MSE 5.971239614566884 Test RE 1.1679931876605831\n",
      "96 Train Loss 0.9267125 Test MSE 5.967973258328743 Test RE 1.1676736892021238\n",
      "97 Train Loss 0.9226696 Test MSE 5.964831590994506 Test RE 1.167366304681356\n",
      "98 Train Loss 0.9187252 Test MSE 5.976193808941516 Test RE 1.168477615177154\n",
      "99 Train Loss 0.9143156 Test MSE 5.991164870342942 Test RE 1.1699402859558616\n",
      "Training time: 84.96\n",
      "2\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.58174 Test MSE 7.93414233051609 Test RE 1.3463502452380318\n",
      "1 Train Loss 53.299408 Test MSE 8.036544673818833 Test RE 1.355010753692223\n",
      "2 Train Loss 44.932613 Test MSE 7.068600244939948 Test RE 1.2707928744254984\n",
      "3 Train Loss 32.932236 Test MSE 6.637214232913377 Test RE 1.2314051857821724\n",
      "4 Train Loss 26.14502 Test MSE 6.185219295655149 Test RE 1.1887365367935165\n",
      "5 Train Loss 23.572256 Test MSE 6.163018008082015 Test RE 1.1866011875439868\n",
      "6 Train Loss 21.213902 Test MSE 5.750431494895437 Test RE 1.1461943868691034\n",
      "7 Train Loss 18.202621 Test MSE 6.141661778257905 Test RE 1.184543484719449\n",
      "8 Train Loss 15.724022 Test MSE 5.774586277216453 Test RE 1.1485991683959602\n",
      "9 Train Loss 13.768658 Test MSE 5.613033295928826 Test RE 1.132418275211849\n",
      "10 Train Loss 12.198586 Test MSE 5.601526899583557 Test RE 1.1312569835015793\n",
      "11 Train Loss 10.816595 Test MSE 5.874420591411962 Test RE 1.1584854377348544\n",
      "12 Train Loss 9.557056 Test MSE 5.7044819393963575 Test RE 1.1416057959139094\n",
      "13 Train Loss 8.698463 Test MSE 5.634213713099105 Test RE 1.1345528169346155\n",
      "14 Train Loss 7.9770484 Test MSE 5.480182612437934 Test RE 1.118936846829226\n",
      "15 Train Loss 7.159357 Test MSE 5.27095102519547 Test RE 1.097368654592735\n",
      "16 Train Loss 6.4974823 Test MSE 5.091272888812493 Test RE 1.0785027282439552\n",
      "17 Train Loss 5.9659586 Test MSE 4.951023710513361 Test RE 1.0635442485924782\n",
      "18 Train Loss 5.3046646 Test MSE 4.762780194206249 Test RE 1.0431297455074724\n",
      "19 Train Loss 4.790371 Test MSE 4.665914814343929 Test RE 1.0324676741604302\n",
      "20 Train Loss 4.397942 Test MSE 4.4488306995451286 Test RE 1.0081635691000825\n",
      "21 Train Loss 3.911209 Test MSE 4.184982581489714 Test RE 0.9778109303059943\n",
      "22 Train Loss 3.6392348 Test MSE 4.04766744187938 Test RE 0.9616354657404449\n",
      "23 Train Loss 3.3144917 Test MSE 3.837481652555765 Test RE 0.9363349111654506\n",
      "24 Train Loss 2.8292117 Test MSE 3.56978661920627 Test RE 0.9030861647303329\n",
      "25 Train Loss 2.5936518 Test MSE 3.395724630167315 Test RE 0.8807938886422478\n",
      "26 Train Loss 2.3904572 Test MSE 3.226657939429533 Test RE 0.8585874265862239\n",
      "27 Train Loss 2.2769804 Test MSE 3.0973635722238755 Test RE 0.841209470581843\n",
      "28 Train Loss 2.1778736 Test MSE 2.949026525004766 Test RE 0.8208189979773717\n",
      "29 Train Loss 2.0767858 Test MSE 2.825226351861094 Test RE 0.803405285339849\n",
      "30 Train Loss 1.9948677 Test MSE 2.7254127154726544 Test RE 0.7890857474474385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 1.8847148 Test MSE 2.3976895980251403 Test RE 0.7401240895709392\n",
      "32 Train Loss 1.7120237 Test MSE 2.0716608144575406 Test RE 0.687966650297481\n",
      "33 Train Loss 1.6111157 Test MSE 1.989090867739084 Test RE 0.6741171437754145\n",
      "34 Train Loss 1.5013375 Test MSE 1.8157709862068316 Test RE 0.644078194846835\n",
      "35 Train Loss 1.4075263 Test MSE 1.67349613127212 Test RE 0.6183301404097266\n",
      "36 Train Loss 1.285094 Test MSE 1.4131553053053136 Test RE 0.5682023256105967\n",
      "37 Train Loss 1.1632209 Test MSE 1.1302589403652368 Test RE 0.50815597419404\n",
      "38 Train Loss 1.0079446 Test MSE 0.9179179808033135 Test RE 0.45794149634016246\n",
      "39 Train Loss 0.7210807 Test MSE 0.4589720569191316 Test RE 0.3238181468858735\n",
      "40 Train Loss 0.5098728 Test MSE 0.26993227173093254 Test RE 0.24833358899037067\n",
      "41 Train Loss 0.40313828 Test MSE 0.20352628792726732 Test RE 0.21563453474794875\n",
      "42 Train Loss 0.28417468 Test MSE 0.12048309830536186 Test RE 0.1659094500980769\n",
      "43 Train Loss 0.2064302 Test MSE 0.07236858892498053 Test RE 0.1285828692631718\n",
      "44 Train Loss 0.16284245 Test MSE 0.06621889892809016 Test RE 0.1229982798611813\n",
      "45 Train Loss 0.13720776 Test MSE 0.053512416736092125 Test RE 0.11056949926854313\n",
      "46 Train Loss 0.116080366 Test MSE 0.048982795579486316 Test RE 0.10578640151655312\n",
      "47 Train Loss 0.08962793 Test MSE 0.03957484034419784 Test RE 0.09508623378369246\n",
      "48 Train Loss 0.068953715 Test MSE 0.03552487730468928 Test RE 0.09008953672197381\n",
      "49 Train Loss 0.05892915 Test MSE 0.03324549560945232 Test RE 0.08715141968134787\n",
      "50 Train Loss 0.050516948 Test MSE 0.030735967526757658 Test RE 0.08379758537308644\n",
      "51 Train Loss 0.044740237 Test MSE 0.02892088338933333 Test RE 0.08128564149285264\n",
      "52 Train Loss 0.04083717 Test MSE 0.02489895864593307 Test RE 0.07542210552204481\n",
      "53 Train Loss 0.03581638 Test MSE 0.01979178323154247 Test RE 0.06724353296634589\n",
      "54 Train Loss 0.032232497 Test MSE 0.019480399689905798 Test RE 0.06671246560839318\n",
      "55 Train Loss 0.028516317 Test MSE 0.018915508555746988 Test RE 0.06573808843806042\n",
      "56 Train Loss 0.024231434 Test MSE 0.015012255907418788 Test RE 0.0585640415112436\n",
      "57 Train Loss 0.022227004 Test MSE 0.013945986234361073 Test RE 0.0564459356575281\n",
      "58 Train Loss 0.020650456 Test MSE 0.013207912511892232 Test RE 0.05493196719741053\n",
      "59 Train Loss 0.018832702 Test MSE 0.011847010126649292 Test RE 0.052025042075576775\n",
      "60 Train Loss 0.016770288 Test MSE 0.00942978891825258 Test RE 0.046415073868110966\n",
      "61 Train Loss 0.015600007 Test MSE 0.007472140907778818 Test RE 0.04131717188054108\n",
      "62 Train Loss 0.014786093 Test MSE 0.007196367563186579 Test RE 0.040547560358209674\n",
      "63 Train Loss 0.013648434 Test MSE 0.007612880785093476 Test RE 0.04170446696643153\n",
      "64 Train Loss 0.012358462 Test MSE 0.007126066454606458 Test RE 0.040349020307356466\n",
      "65 Train Loss 0.011222256 Test MSE 0.005309614015339849 Test RE 0.03482888214956081\n",
      "66 Train Loss 0.010361165 Test MSE 0.004703865434448357 Test RE 0.0327820044476117\n",
      "67 Train Loss 0.0097399 Test MSE 0.004556007355470387 Test RE 0.03226266722126821\n",
      "68 Train Loss 0.009263049 Test MSE 0.004176772239349939 Test RE 0.03089075031413718\n",
      "69 Train Loss 0.008916309 Test MSE 0.003847562134547599 Test RE 0.029648374058707017\n",
      "70 Train Loss 0.008034177 Test MSE 0.0031754923440286955 Test RE 0.026934790087708903\n",
      "71 Train Loss 0.0076083927 Test MSE 0.0032576310784009988 Test RE 0.02728091987702549\n",
      "72 Train Loss 0.007069403 Test MSE 0.00297546875317338 Test RE 0.026072684971556247\n",
      "73 Train Loss 0.006592188 Test MSE 0.002547136591923179 Test RE 0.024123158910277987\n",
      "74 Train Loss 0.006130893 Test MSE 0.0024971813455941304 Test RE 0.02388543204389756\n",
      "75 Train Loss 0.0059257327 Test MSE 0.0025738682721809683 Test RE 0.024249412345992115\n",
      "76 Train Loss 0.0056557474 Test MSE 0.0024017646475328965 Test RE 0.02342465936837996\n",
      "77 Train Loss 0.0054654935 Test MSE 0.0022884390027748296 Test RE 0.022865343538332285\n",
      "78 Train Loss 0.0053594382 Test MSE 0.00231816133719747 Test RE 0.023013352486104175\n",
      "79 Train Loss 0.00519354 Test MSE 0.0024305842640340025 Test RE 0.023564780633126753\n",
      "80 Train Loss 0.005003397 Test MSE 0.002431797767739327 Test RE 0.023570662424738327\n",
      "81 Train Loss 0.004814664 Test MSE 0.0021450760430001175 Test RE 0.022137542427999316\n",
      "82 Train Loss 0.0046817334 Test MSE 0.001875748161805358 Test RE 0.020701190648937818\n",
      "83 Train Loss 0.0045369635 Test MSE 0.001715414961161552 Test RE 0.019796693400165436\n",
      "84 Train Loss 0.004396854 Test MSE 0.0017716510781578608 Test RE 0.02011857223643339\n",
      "85 Train Loss 0.004268664 Test MSE 0.001773658372537415 Test RE 0.02012996625897294\n",
      "86 Train Loss 0.0041244207 Test MSE 0.0016191743215818468 Test RE 0.019233346872650735\n",
      "87 Train Loss 0.004034167 Test MSE 0.0015217003749710438 Test RE 0.018645439900519842\n",
      "88 Train Loss 0.0039560455 Test MSE 0.001476247900651938 Test RE 0.018364863587286413\n",
      "89 Train Loss 0.0038739364 Test MSE 0.0013879883013599324 Test RE 0.017807418408070368\n",
      "90 Train Loss 0.0037364427 Test MSE 0.0012006313587355464 Test RE 0.016562004619190367\n",
      "91 Train Loss 0.003581667 Test MSE 0.001067507362950203 Test RE 0.015616852191861404\n",
      "92 Train Loss 0.0034675694 Test MSE 0.0010032333359124436 Test RE 0.015139413035227898\n",
      "93 Train Loss 0.0033556144 Test MSE 0.0009207536208927526 Test RE 0.014503732391279516\n",
      "94 Train Loss 0.0032096058 Test MSE 0.0008147278379051754 Test RE 0.01364314007626587\n",
      "95 Train Loss 0.0031249544 Test MSE 0.0007693381818631176 Test RE 0.01325765470573459\n",
      "96 Train Loss 0.0030307155 Test MSE 0.0007411492216235804 Test RE 0.013012504379887073\n",
      "97 Train Loss 0.0029804753 Test MSE 0.0007305460814394743 Test RE 0.012919088344491323\n",
      "98 Train Loss 0.0029191868 Test MSE 0.0007287271187984353 Test RE 0.01290299491421448\n",
      "99 Train Loss 0.0028348423 Test MSE 0.000751609946782462 Test RE 0.013104013134841861\n",
      "Training time: 90.94\n",
      "3\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 55.446056 Test MSE 8.586193330349142 Test RE 1.4005815201370686\n",
      "1 Train Loss 51.561794 Test MSE 9.245661777553227 Test RE 1.4533729113624207\n",
      "2 Train Loss 44.39693 Test MSE 8.289040860637662 Test RE 1.376132337940532\n",
      "3 Train Loss 40.407524 Test MSE 9.446507837290516 Test RE 1.4690741093421038\n",
      "4 Train Loss 36.65252 Test MSE 9.308547429783616 Test RE 1.4583071940988857\n",
      "5 Train Loss 33.194557 Test MSE 9.280178768468305 Test RE 1.456083335262993\n",
      "6 Train Loss 30.608719 Test MSE 9.13952199500513 Test RE 1.4450065026319217\n",
      "7 Train Loss 28.044434 Test MSE 9.200738860792693 Test RE 1.4498377803584244\n",
      "8 Train Loss 25.632538 Test MSE 9.128532681991791 Test RE 1.4441375072380827\n",
      "9 Train Loss 23.27112 Test MSE 8.943414000854954 Test RE 1.4294195838454202\n",
      "10 Train Loss 20.983978 Test MSE 8.934992160734899 Test RE 1.4287463969280731\n",
      "11 Train Loss 19.381695 Test MSE 9.142844735894444 Test RE 1.4452691501685784\n",
      "12 Train Loss 17.896189 Test MSE 9.09199644468614 Test RE 1.4412445860140006\n",
      "13 Train Loss 16.197363 Test MSE 8.989497632456219 Test RE 1.4330976091504217\n",
      "14 Train Loss 14.576105 Test MSE 8.788251086900678 Test RE 1.4169655401075474\n",
      "15 Train Loss 12.5248 Test MSE 8.276326832509834 Test RE 1.3750765523698127\n",
      "16 Train Loss 9.863263 Test MSE 7.3565932764569455 Test RE 1.2964221221517742\n",
      "17 Train Loss 8.466279 Test MSE 6.899562393942694 Test RE 1.2555061183962442\n",
      "18 Train Loss 7.130419 Test MSE 6.619756466131101 Test RE 1.2297846460037605\n",
      "19 Train Loss 6.622035 Test MSE 6.7631545328553635 Test RE 1.2430331639037724\n",
      "20 Train Loss 5.7314167 Test MSE 6.528098561177055 Test RE 1.2212410997760237\n",
      "21 Train Loss 4.968024 Test MSE 6.417163671614776 Test RE 1.2108200905981887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 4.077721 Test MSE 6.301470546858166 Test RE 1.1998556907016735\n",
      "23 Train Loss 3.5094583 Test MSE 6.146159558107741 Test RE 1.184977149167609\n",
      "24 Train Loss 3.0763621 Test MSE 5.947055311308613 Test RE 1.165625525126394\n",
      "25 Train Loss 2.66919 Test MSE 5.774255968072139 Test RE 1.1485663177105796\n",
      "26 Train Loss 2.275707 Test MSE 5.692759864287748 Test RE 1.1404322563424842\n",
      "27 Train Loss 2.0232382 Test MSE 5.59285573876928 Test RE 1.1303810517649793\n",
      "28 Train Loss 1.8365551 Test MSE 5.65954938488247 Test RE 1.137100858000515\n",
      "29 Train Loss 1.7312496 Test MSE 5.633460998444929 Test RE 1.1344770279160017\n",
      "30 Train Loss 1.643156 Test MSE 5.646962414299281 Test RE 1.1358356846750746\n",
      "31 Train Loss 1.5475187 Test MSE 5.706706057882785 Test RE 1.1418283243697072\n",
      "32 Train Loss 1.4974675 Test MSE 5.6804046965844375 Test RE 1.1391940269477583\n",
      "33 Train Loss 1.4161481 Test MSE 5.718911956156669 Test RE 1.1430487828806697\n",
      "34 Train Loss 1.3425429 Test MSE 5.710792490370733 Test RE 1.1422370688633878\n",
      "35 Train Loss 1.3034017 Test MSE 5.7323739877223465 Test RE 1.1443933318135542\n",
      "36 Train Loss 1.2698116 Test MSE 5.775621104107072 Test RE 1.1487020803625747\n",
      "37 Train Loss 1.2417147 Test MSE 5.752431194311846 Test RE 1.146393662786041\n",
      "38 Train Loss 1.2091163 Test MSE 5.742548171978397 Test RE 1.1454084528540918\n",
      "39 Train Loss 1.1772084 Test MSE 5.791807351473091 Test RE 1.1503105798650648\n",
      "40 Train Loss 1.1437166 Test MSE 5.817621043174413 Test RE 1.1528711579907467\n",
      "41 Train Loss 1.1102471 Test MSE 5.842144431752156 Test RE 1.1552984882771042\n",
      "42 Train Loss 1.0838 Test MSE 5.841330226109891 Test RE 1.1552179798837408\n",
      "43 Train Loss 1.0525146 Test MSE 5.814932213988935 Test RE 1.1526047061320868\n",
      "44 Train Loss 1.0335442 Test MSE 5.808914548920457 Test RE 1.152008157092191\n",
      "45 Train Loss 1.0106584 Test MSE 5.795512192759081 Test RE 1.150678430223749\n",
      "46 Train Loss 0.9936303 Test MSE 5.7830438604389895 Test RE 1.1494399921556526\n",
      "47 Train Loss 0.98378766 Test MSE 5.80072143955268 Test RE 1.1511954528247796\n",
      "48 Train Loss 0.9723045 Test MSE 5.836119252264988 Test RE 1.154702587533633\n",
      "49 Train Loss 0.9628476 Test MSE 5.827185618405661 Test RE 1.1538184691327846\n",
      "50 Train Loss 0.9546824 Test MSE 5.825046941721688 Test RE 1.153606714155547\n",
      "51 Train Loss 0.94219196 Test MSE 5.841660575473453 Test RE 1.15525064539949\n",
      "52 Train Loss 0.93137455 Test MSE 5.834435341242965 Test RE 1.1545359908100739\n",
      "53 Train Loss 0.9205837 Test MSE 5.846294998775707 Test RE 1.1557088078511535\n",
      "54 Train Loss 0.9101673 Test MSE 5.878840774019557 Test RE 1.1589212044798605\n",
      "55 Train Loss 0.9011215 Test MSE 5.88903106194459 Test RE 1.1599251972683116\n",
      "56 Train Loss 0.8935987 Test MSE 5.908406228048717 Test RE 1.161831732365405\n",
      "57 Train Loss 0.88771915 Test MSE 5.942592771120144 Test RE 1.1651881131093744\n",
      "58 Train Loss 0.8807565 Test MSE 5.951036693109074 Test RE 1.166015636160212\n",
      "59 Train Loss 0.86943436 Test MSE 5.947244154954686 Test RE 1.165644031699411\n",
      "60 Train Loss 0.85939956 Test MSE 5.971237953394831 Test RE 1.1679930251953412\n",
      "61 Train Loss 0.85097927 Test MSE 5.999502207525682 Test RE 1.1707540505344731\n",
      "62 Train Loss 0.8434173 Test MSE 6.003915964496278 Test RE 1.1711846257405683\n",
      "63 Train Loss 0.8355736 Test MSE 6.0325072979934 Test RE 1.1739699711169955\n",
      "64 Train Loss 0.83158934 Test MSE 6.039275746009188 Test RE 1.1746283811898461\n",
      "65 Train Loss 0.8267877 Test MSE 6.038392115439408 Test RE 1.1745424457599714\n",
      "66 Train Loss 0.82089376 Test MSE 6.047488440523051 Test RE 1.17542678707903\n",
      "67 Train Loss 0.8156642 Test MSE 6.050165283853967 Test RE 1.1756869021070984\n",
      "68 Train Loss 0.80900854 Test MSE 6.059091184858762 Test RE 1.176553836872324\n",
      "69 Train Loss 0.8045724 Test MSE 6.078159377434575 Test RE 1.1784037126551548\n",
      "70 Train Loss 0.7993453 Test MSE 6.097144774026863 Test RE 1.1802426755165452\n",
      "71 Train Loss 0.79453254 Test MSE 6.105543396535159 Test RE 1.1810552691081329\n",
      "72 Train Loss 0.79088306 Test MSE 6.112356547550016 Test RE 1.1817140527586893\n",
      "73 Train Loss 0.7876807 Test MSE 6.118306579614697 Test RE 1.1822890786227291\n",
      "74 Train Loss 0.7820156 Test MSE 6.142739230382667 Test RE 1.1846473843617258\n",
      "75 Train Loss 0.77719253 Test MSE 6.15028573175045 Test RE 1.1853748447603616\n",
      "76 Train Loss 0.7724772 Test MSE 6.14792687448006 Test RE 1.1851475058733267\n",
      "77 Train Loss 0.76960707 Test MSE 6.146789156842566 Test RE 1.1850378408077833\n",
      "78 Train Loss 0.7656602 Test MSE 6.1583582678387785 Test RE 1.1861525194697558\n",
      "79 Train Loss 0.7625596 Test MSE 6.1669546811623785 Test RE 1.1869801021628945\n",
      "80 Train Loss 0.7589245 Test MSE 6.163118139440563 Test RE 1.186610826937074\n",
      "81 Train Loss 0.7552772 Test MSE 6.152657982914523 Test RE 1.1856034305426069\n",
      "82 Train Loss 0.75261015 Test MSE 6.1572909752620815 Test RE 1.1860497301727304\n",
      "83 Train Loss 0.7505665 Test MSE 6.170377646593959 Test RE 1.1873094728518057\n",
      "84 Train Loss 0.74700224 Test MSE 6.179245459168518 Test RE 1.1881623426669876\n",
      "85 Train Loss 0.74423534 Test MSE 6.174729357230653 Test RE 1.1877280790451343\n",
      "86 Train Loss 0.74026763 Test MSE 6.180822251790399 Test RE 1.1883139280123338\n",
      "87 Train Loss 0.736874 Test MSE 6.200438101303162 Test RE 1.1901980884987196\n",
      "88 Train Loss 0.7330966 Test MSE 6.210246467378641 Test RE 1.1911390934186075\n",
      "89 Train Loss 0.73006374 Test MSE 6.220215296701367 Test RE 1.1920947318941364\n",
      "90 Train Loss 0.7261939 Test MSE 6.2248572021980335 Test RE 1.1925394559779128\n",
      "91 Train Loss 0.72354627 Test MSE 6.230364858301814 Test RE 1.1930669094443473\n",
      "92 Train Loss 0.71985555 Test MSE 6.252672137606641 Test RE 1.1952008371988376\n",
      "93 Train Loss 0.7167455 Test MSE 6.266248632050951 Test RE 1.1964977098359009\n",
      "94 Train Loss 0.7143564 Test MSE 6.263783136207203 Test RE 1.196262301816591\n",
      "95 Train Loss 0.7112675 Test MSE 6.26640625578494 Test RE 1.1965127583331607\n",
      "96 Train Loss 0.708267 Test MSE 6.268823130178713 Test RE 1.1967434760801745\n",
      "97 Train Loss 0.7064337 Test MSE 6.264837485186647 Test RE 1.1963629777849372\n",
      "98 Train Loss 0.70307124 Test MSE 6.263413989294554 Test RE 1.1962270513112463\n",
      "99 Train Loss 0.70056486 Test MSE 6.268980985894622 Test RE 1.1967585436299368\n",
      "Training time: 90.82\n",
      "4\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.823814 Test MSE 8.233530633266565 Test RE 1.3715167411622549\n",
      "1 Train Loss 56.138912 Test MSE 8.595485504440193 Test RE 1.401339185821057\n",
      "2 Train Loss 50.28071 Test MSE 8.462882866743035 Test RE 1.3904879360117255\n",
      "3 Train Loss 42.68762 Test MSE 8.241706550477753 Test RE 1.3721975320328115\n",
      "4 Train Loss 37.116398 Test MSE 7.3995798759511535 Test RE 1.3002042808076433\n",
      "5 Train Loss 29.824463 Test MSE 4.352011843126395 Test RE 0.9971330117772028\n",
      "6 Train Loss 19.677862 Test MSE 3.373940285527891 Test RE 0.8779640964924157\n",
      "7 Train Loss 14.412067 Test MSE 4.304900449687218 Test RE 0.991721244513128\n",
      "8 Train Loss 11.596102 Test MSE 3.826191105692666 Test RE 0.9349564654050035\n",
      "9 Train Loss 9.61702 Test MSE 4.0105086925195925 Test RE 0.9572112435721548\n",
      "10 Train Loss 8.892798 Test MSE 3.981588766918431 Test RE 0.9537537565469025\n",
      "11 Train Loss 8.422778 Test MSE 3.8618875329270015 Test RE 0.9393076757181891\n",
      "12 Train Loss 7.8321805 Test MSE 3.8878528523568665 Test RE 0.9424600934712496\n",
      "13 Train Loss 7.186816 Test MSE 3.6689723465984247 Test RE 0.9155462317986122\n",
      "14 Train Loss 6.5603485 Test MSE 3.6151323739633345 Test RE 0.9088038588972486\n",
      "15 Train Loss 5.782407 Test MSE 3.4971673033968216 Test RE 0.8938533351791216\n",
      "16 Train Loss 4.810512 Test MSE 3.229247187156281 Test RE 0.8589318463821176\n",
      "17 Train Loss 3.9280066 Test MSE 3.018082686923698 Test RE 0.8303737798546523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 3.455584 Test MSE 2.849230731953004 Test RE 0.8068111106682803\n",
      "19 Train Loss 2.7254086 Test MSE 2.5112629779022093 Test RE 0.7574503268877381\n",
      "20 Train Loss 2.1927676 Test MSE 2.2577826589413714 Test RE 0.7182061618293939\n",
      "21 Train Loss 1.8082981 Test MSE 1.922985842467257 Test RE 0.6628207620578395\n",
      "22 Train Loss 1.4904554 Test MSE 1.7007476576715157 Test RE 0.6233443121828086\n",
      "23 Train Loss 1.2771586 Test MSE 1.3936395110544693 Test RE 0.5642652243489736\n",
      "24 Train Loss 1.0540638 Test MSE 1.0551100245654006 Test RE 0.49097223716177646\n",
      "25 Train Loss 0.8872654 Test MSE 0.8473873624300888 Test RE 0.43999632760467694\n",
      "26 Train Loss 0.7244596 Test MSE 0.7365462735850139 Test RE 0.4102117335291763\n",
      "27 Train Loss 0.60629493 Test MSE 0.5918633792772462 Test RE 0.36772130693912114\n",
      "28 Train Loss 0.48012832 Test MSE 0.47833689359047105 Test RE 0.3305788006381118\n",
      "29 Train Loss 0.39953348 Test MSE 0.4229829693112133 Test RE 0.3108633344211347\n",
      "30 Train Loss 0.32257256 Test MSE 0.38329846891177494 Test RE 0.295921556418101\n",
      "31 Train Loss 0.2675755 Test MSE 0.3113709436326733 Test RE 0.26671479161379863\n",
      "32 Train Loss 0.24067852 Test MSE 0.26287020168285957 Test RE 0.2450635607354897\n",
      "33 Train Loss 0.2139245 Test MSE 0.23493427384471052 Test RE 0.23167610864008686\n",
      "34 Train Loss 0.19594812 Test MSE 0.22719927111424132 Test RE 0.22783032367948222\n",
      "35 Train Loss 0.17492998 Test MSE 0.1957710382730282 Test RE 0.211486321008455\n",
      "36 Train Loss 0.15741539 Test MSE 0.1655415631511324 Test RE 0.19447401754210478\n",
      "37 Train Loss 0.1367237 Test MSE 0.10980415548350218 Test RE 0.15838623974395322\n",
      "38 Train Loss 0.122337885 Test MSE 0.0769691236580317 Test RE 0.13260696372434222\n",
      "39 Train Loss 0.108550705 Test MSE 0.06419555585144429 Test RE 0.12110457282223139\n",
      "40 Train Loss 0.09859894 Test MSE 0.055792080187650965 Test RE 0.11290010280656398\n",
      "41 Train Loss 0.08811856 Test MSE 0.05094586803842358 Test RE 0.10788536704422226\n",
      "42 Train Loss 0.07557347 Test MSE 0.04310361806807835 Test RE 0.09923501123873033\n",
      "43 Train Loss 0.06445295 Test MSE 0.036481797332080505 Test RE 0.09129482773110126\n",
      "44 Train Loss 0.055581354 Test MSE 0.032210908607839546 Test RE 0.08578464296627529\n",
      "45 Train Loss 0.05084763 Test MSE 0.030412877134795367 Test RE 0.08335599002146425\n",
      "46 Train Loss 0.046842016 Test MSE 0.0290434780654685 Test RE 0.0814577428868156\n",
      "47 Train Loss 0.042042013 Test MSE 0.02831770296362283 Test RE 0.08043351929070516\n",
      "48 Train Loss 0.037150756 Test MSE 0.027925429892220934 Test RE 0.07987447084124441\n",
      "49 Train Loss 0.033377524 Test MSE 0.02622174871354292 Test RE 0.07739963022682975\n",
      "50 Train Loss 0.030914657 Test MSE 0.024668655995859372 Test RE 0.0750724872195066\n",
      "51 Train Loss 0.028658742 Test MSE 0.02247190025127184 Test RE 0.07165194098027261\n",
      "52 Train Loss 0.02678115 Test MSE 0.020935801626553098 Test RE 0.06915966127712686\n",
      "53 Train Loss 0.024253052 Test MSE 0.018660312784292372 Test RE 0.0652931347618815\n",
      "54 Train Loss 0.021987636 Test MSE 0.014789997942926677 Test RE 0.05812890165928705\n",
      "55 Train Loss 0.020692723 Test MSE 0.012827847520459594 Test RE 0.05413584933301542\n",
      "56 Train Loss 0.019510992 Test MSE 0.011573878678551388 Test RE 0.05142182938890485\n",
      "57 Train Loss 0.018333213 Test MSE 0.0108499602852995 Test RE 0.04978770808573453\n",
      "58 Train Loss 0.017493153 Test MSE 0.010044828350892526 Test RE 0.04790483185889075\n",
      "59 Train Loss 0.016742852 Test MSE 0.008629994368960291 Test RE 0.044403102559218977\n",
      "60 Train Loss 0.01610649 Test MSE 0.008492532718759554 Test RE 0.04404804874407687\n",
      "61 Train Loss 0.015106445 Test MSE 0.009100557905401905 Test RE 0.04559760887172375\n",
      "62 Train Loss 0.014370207 Test MSE 0.00881086757417961 Test RE 0.044866004672839646\n",
      "63 Train Loss 0.013688328 Test MSE 0.00816043367722944 Test RE 0.04317821455306915\n",
      "64 Train Loss 0.012586199 Test MSE 0.007257808434548446 Test RE 0.0407202851748755\n",
      "65 Train Loss 0.011978329 Test MSE 0.006840549344677108 Test RE 0.03953243361396662\n",
      "66 Train Loss 0.011334957 Test MSE 0.006551186543332522 Test RE 0.03868726633438904\n",
      "67 Train Loss 0.0109013 Test MSE 0.006834861320263353 Test RE 0.03951599427557425\n",
      "68 Train Loss 0.009906341 Test MSE 0.006859204488064674 Test RE 0.0395863021747821\n",
      "69 Train Loss 0.009473497 Test MSE 0.00607012618738712 Test RE 0.037239763993146734\n",
      "70 Train Loss 0.009112247 Test MSE 0.005536542509185652 Test RE 0.035565373968986756\n",
      "71 Train Loss 0.0087873675 Test MSE 0.005314178431014658 Test RE 0.03484384927752918\n",
      "72 Train Loss 0.008298657 Test MSE 0.004571895999661742 Test RE 0.032318874757608765\n",
      "73 Train Loss 0.0077575073 Test MSE 0.0037925789513957044 Test RE 0.029435768280429098\n",
      "74 Train Loss 0.0072882846 Test MSE 0.003822346185716063 Test RE 0.029551060382902745\n",
      "75 Train Loss 0.0070353863 Test MSE 0.003831103011741145 Test RE 0.029584891103870296\n",
      "76 Train Loss 0.006689135 Test MSE 0.003794619707225538 Test RE 0.02944368678887799\n",
      "77 Train Loss 0.0064433254 Test MSE 0.004116554677779514 Test RE 0.03066726206286669\n",
      "78 Train Loss 0.0062226765 Test MSE 0.004235308972102088 Test RE 0.031106461388223407\n",
      "79 Train Loss 0.0059611583 Test MSE 0.004028201228391202 Test RE 0.030336371848431836\n",
      "80 Train Loss 0.005648125 Test MSE 0.003878206232408758 Test RE 0.029766207867447717\n",
      "81 Train Loss 0.005243193 Test MSE 0.0037239412681828628 Test RE 0.029168189425883253\n",
      "82 Train Loss 0.0049143475 Test MSE 0.003804162762031553 Test RE 0.029480687371275092\n",
      "83 Train Loss 0.004740974 Test MSE 0.003960739676546432 Test RE 0.030081272906974824\n",
      "84 Train Loss 0.0045365742 Test MSE 0.004114305913768964 Test RE 0.03065888456500471\n",
      "85 Train Loss 0.004232877 Test MSE 0.00421406986551261 Test RE 0.03102836746185967\n",
      "86 Train Loss 0.0040550125 Test MSE 0.003976127841278211 Test RE 0.030139651755922207\n",
      "87 Train Loss 0.0038621482 Test MSE 0.0038307890455152338 Test RE 0.029583678809801325\n",
      "88 Train Loss 0.003698208 Test MSE 0.003963141659265807 Test RE 0.03009039288862473\n",
      "89 Train Loss 0.0035865835 Test MSE 0.004106727837820782 Test RE 0.030630636490730574\n",
      "90 Train Loss 0.0035244012 Test MSE 0.0039686879072225135 Test RE 0.030111440638970772\n",
      "91 Train Loss 0.0034370727 Test MSE 0.0036448592178443613 Test RE 0.028856817941610036\n",
      "92 Train Loss 0.0032570227 Test MSE 0.003372599423843834 Test RE 0.027758145061834247\n",
      "93 Train Loss 0.0031308862 Test MSE 0.003282976143032874 Test RE 0.02738683994380298\n",
      "94 Train Loss 0.0029225843 Test MSE 0.002941195325567732 Test RE 0.025922088787620468\n",
      "95 Train Loss 0.0027707526 Test MSE 0.002702653806887309 Test RE 0.02484867693371999\n",
      "96 Train Loss 0.002649751 Test MSE 0.0024946208435689347 Test RE 0.02387318335746475\n",
      "97 Train Loss 0.0025755898 Test MSE 0.0023497232780343384 Test RE 0.02316948709857309\n",
      "98 Train Loss 0.0025010235 Test MSE 0.0022303281434176768 Test RE 0.022573164296741173\n",
      "99 Train Loss 0.0024211414 Test MSE 0.0021654317767762733 Test RE 0.02224233169843702\n",
      "Training time: 89.98\n",
      "5\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.601334 Test MSE 8.559740174091015 Test RE 1.3984223338099613\n",
      "1 Train Loss 57.75831 Test MSE 8.635030440430494 Test RE 1.404559031700173\n",
      "2 Train Loss 56.621296 Test MSE 7.988208018919446 Test RE 1.3509296795900598\n",
      "3 Train Loss 49.96798 Test MSE 8.016161500358844 Test RE 1.3532912986617893\n",
      "4 Train Loss 43.94371 Test MSE 8.265862727382505 Test RE 1.3742069941160808\n",
      "5 Train Loss 42.226368 Test MSE 8.834364974962636 Test RE 1.4206782411967172\n",
      "6 Train Loss 40.52852 Test MSE 9.524912282472046 Test RE 1.4751580469949253\n",
      "7 Train Loss 38.43782 Test MSE 9.830696416046436 Test RE 1.4986499469763994\n",
      "8 Train Loss 36.264156 Test MSE 10.208583617181542 Test RE 1.5271820310483943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 34.129486 Test MSE 10.430226648923027 Test RE 1.543671667328374\n",
      "10 Train Loss 32.048267 Test MSE 9.990467918254868 Test RE 1.5107791237946653\n",
      "11 Train Loss 29.895834 Test MSE 9.829777291124415 Test RE 1.4985798868985019\n",
      "12 Train Loss 27.178669 Test MSE 9.72374678331697 Test RE 1.4904756340954917\n",
      "13 Train Loss 24.769518 Test MSE 9.492735429398703 Test RE 1.472664265567343\n",
      "14 Train Loss 22.620464 Test MSE 8.65793911885674 Test RE 1.4064209405029873\n",
      "15 Train Loss 20.861845 Test MSE 8.616158882101056 Test RE 1.4030233847891704\n",
      "16 Train Loss 18.798918 Test MSE 8.344958874206085 Test RE 1.3807662422994071\n",
      "17 Train Loss 16.350067 Test MSE 8.17646255818777 Test RE 1.3667553622683053\n",
      "18 Train Loss 13.230177 Test MSE 7.594994555162755 Test RE 1.317260878071609\n",
      "19 Train Loss 11.457765 Test MSE 7.4572871862812 Test RE 1.3052644040635453\n",
      "20 Train Loss 9.784825 Test MSE 7.384194685240351 Test RE 1.29885188648294\n",
      "21 Train Loss 7.0460973 Test MSE 6.858813781352706 Test RE 1.2517931369819921\n",
      "22 Train Loss 5.132376 Test MSE 7.2724713478081755 Test RE 1.2889885801538068\n",
      "23 Train Loss 4.201788 Test MSE 6.952571580559486 Test RE 1.2603199030290808\n",
      "24 Train Loss 3.6346471 Test MSE 6.968233427276765 Test RE 1.2617386466611702\n",
      "25 Train Loss 3.3159428 Test MSE 6.849571176280002 Test RE 1.2509494247650819\n",
      "26 Train Loss 2.9432712 Test MSE 6.842651500602633 Test RE 1.2503173887309944\n",
      "27 Train Loss 2.64922 Test MSE 6.927460617636043 Test RE 1.2580418629001384\n",
      "28 Train Loss 2.4195673 Test MSE 6.905384992325412 Test RE 1.2560357727293825\n",
      "29 Train Loss 2.2754831 Test MSE 6.773392522211534 Test RE 1.2439736531163836\n",
      "30 Train Loss 2.1245542 Test MSE 6.426367339769419 Test RE 1.211688074803577\n",
      "31 Train Loss 2.0285904 Test MSE 6.349848677461711 Test RE 1.2044526962909765\n",
      "32 Train Loss 1.9120455 Test MSE 6.23875077558577 Test RE 1.1938695587514623\n",
      "33 Train Loss 1.8182509 Test MSE 6.142796829729976 Test RE 1.1846529384601188\n",
      "34 Train Loss 1.7326858 Test MSE 6.061121636501432 Test RE 1.1767509568275603\n",
      "35 Train Loss 1.6718783 Test MSE 5.901415579429953 Test RE 1.1611442067520878\n",
      "36 Train Loss 1.6148667 Test MSE 5.891062707931289 Test RE 1.1601252602443826\n",
      "37 Train Loss 1.5760995 Test MSE 5.884353804471891 Test RE 1.159464480861974\n",
      "38 Train Loss 1.5274744 Test MSE 5.919765775326686 Test RE 1.1629480693678793\n",
      "39 Train Loss 1.4933964 Test MSE 5.931859958735282 Test RE 1.1641354246954452\n",
      "40 Train Loss 1.4673016 Test MSE 5.929394248959122 Test RE 1.1638934501319909\n",
      "41 Train Loss 1.4409539 Test MSE 5.944739949856176 Test RE 1.1653985970919845\n",
      "42 Train Loss 1.408827 Test MSE 5.903264687559928 Test RE 1.1613261048918133\n",
      "43 Train Loss 1.3685527 Test MSE 5.88462903996465 Test RE 1.1594915970124222\n",
      "44 Train Loss 1.3368111 Test MSE 5.8454774620811225 Test RE 1.1556279987753013\n",
      "45 Train Loss 1.316947 Test MSE 5.802972138796154 Test RE 1.151418765000848\n",
      "46 Train Loss 1.2893381 Test MSE 5.786865421351328 Test RE 1.1498197168819675\n",
      "47 Train Loss 1.2699888 Test MSE 5.789942494990266 Test RE 1.1501253754275134\n",
      "48 Train Loss 1.2423154 Test MSE 5.7662238242625605 Test RE 1.1477671965480776\n",
      "49 Train Loss 1.2216896 Test MSE 5.801835749270743 Test RE 1.1513060189581772\n",
      "50 Train Loss 1.199263 Test MSE 5.844190331037989 Test RE 1.1555007613878263\n",
      "51 Train Loss 1.1821532 Test MSE 5.8499974117792295 Test RE 1.1560747006160161\n",
      "52 Train Loss 1.1630312 Test MSE 5.861907086892274 Test RE 1.1572508954614158\n",
      "53 Train Loss 1.1520479 Test MSE 5.870999428620457 Test RE 1.1581480474824934\n",
      "54 Train Loss 1.1370401 Test MSE 5.8664509510103375 Test RE 1.157699330767909\n",
      "55 Train Loss 1.1241839 Test MSE 5.860942771605148 Test RE 1.1571557045438607\n",
      "56 Train Loss 1.1086317 Test MSE 5.846331199818626 Test RE 1.1557123859976033\n",
      "57 Train Loss 1.097985 Test MSE 5.863292992388116 Test RE 1.157387689303953\n",
      "58 Train Loss 1.0814798 Test MSE 5.906257032119669 Test RE 1.1616204037052675\n",
      "59 Train Loss 1.0670629 Test MSE 5.920355037740649 Test RE 1.1630059487300055\n",
      "60 Train Loss 1.0536256 Test MSE 5.92665145980303 Test RE 1.1636242250259874\n",
      "61 Train Loss 1.0396535 Test MSE 5.94628501464919 Test RE 1.1655500334353315\n",
      "62 Train Loss 1.0292935 Test MSE 5.950148790998606 Test RE 1.1659286474204544\n",
      "63 Train Loss 1.0202744 Test MSE 5.949518055929133 Test RE 1.1658668496737272\n",
      "64 Train Loss 1.0124811 Test MSE 5.959050499272461 Test RE 1.1668004640903618\n",
      "65 Train Loss 1.00433 Test MSE 5.9775408270003885 Test RE 1.1686092936181258\n",
      "66 Train Loss 0.9990665 Test MSE 5.9873248609978855 Test RE 1.1695652919576907\n",
      "67 Train Loss 0.9910258 Test MSE 6.001612205881806 Test RE 1.1709599069436685\n",
      "68 Train Loss 0.984416 Test MSE 6.0086245998200924 Test RE 1.1716437927674637\n",
      "69 Train Loss 0.97739184 Test MSE 6.013945325197205 Test RE 1.1721624318748631\n",
      "70 Train Loss 0.9698781 Test MSE 6.020724336898887 Test RE 1.1728228855729945\n",
      "71 Train Loss 0.96010065 Test MSE 6.042807865757846 Test RE 1.1749718264820224\n",
      "72 Train Loss 0.95186067 Test MSE 6.071081783500484 Test RE 1.1777174282243588\n",
      "73 Train Loss 0.9442636 Test MSE 6.077821268383082 Test RE 1.178370936737495\n",
      "74 Train Loss 0.9397774 Test MSE 6.058257614160092 Test RE 1.17647290274316\n",
      "75 Train Loss 0.9322692 Test MSE 6.0727758569732195 Test RE 1.1778817317836943\n",
      "76 Train Loss 0.9245507 Test MSE 6.115941831178718 Test RE 1.1820605769602386\n",
      "77 Train Loss 0.91983575 Test MSE 6.10929162288728 Test RE 1.1814177416175586\n",
      "78 Train Loss 0.91528654 Test MSE 6.097580744739455 Test RE 1.1802848708441565\n",
      "79 Train Loss 0.90893614 Test MSE 6.1226226376505934 Test RE 1.1827060182287301\n",
      "80 Train Loss 0.90258276 Test MSE 6.149951894724897 Test RE 1.1853426732971413\n",
      "81 Train Loss 0.898913 Test MSE 6.1476056426010555 Test RE 1.1851165432300534\n",
      "82 Train Loss 0.8950671 Test MSE 6.15047984096956 Test RE 1.1853935504254354\n",
      "83 Train Loss 0.89101535 Test MSE 6.153126602014794 Test RE 1.1856485806090946\n",
      "84 Train Loss 0.88638633 Test MSE 6.15495294673771 Test RE 1.1858245271246544\n",
      "85 Train Loss 0.88342434 Test MSE 6.160128337820596 Test RE 1.1863229725378603\n",
      "86 Train Loss 0.87738156 Test MSE 6.180586810465184 Test RE 1.188291295030913\n",
      "87 Train Loss 0.8690264 Test MSE 6.212161239529214 Test RE 1.191322708046382\n",
      "88 Train Loss 0.86435115 Test MSE 6.231760164588981 Test RE 1.1932004971719474\n",
      "89 Train Loss 0.86013246 Test MSE 6.244834432546413 Test RE 1.194451512041603\n",
      "90 Train Loss 0.85515666 Test MSE 6.240132206167287 Test RE 1.1940017291723561\n",
      "91 Train Loss 0.8499944 Test MSE 6.246752804768644 Test RE 1.1946349617933383\n",
      "92 Train Loss 0.84590626 Test MSE 6.272537067629048 Test RE 1.1970979263666426\n",
      "93 Train Loss 0.8418314 Test MSE 6.290591841588503 Test RE 1.1988195424932346\n",
      "94 Train Loss 0.83635855 Test MSE 6.307147867019856 Test RE 1.2003960749843068\n",
      "95 Train Loss 0.8321683 Test MSE 6.3381690006634575 Test RE 1.2033444735799603\n",
      "96 Train Loss 0.82772875 Test MSE 6.3513776326283535 Test RE 1.204597695284236\n",
      "97 Train Loss 0.8245865 Test MSE 6.339063549486494 Test RE 1.2034293886716396\n",
      "98 Train Loss 0.81985235 Test MSE 6.3637156768921805 Test RE 1.2057671399082373\n",
      "99 Train Loss 0.81557184 Test MSE 6.383960946162287 Test RE 1.207683606433249\n",
      "Training time: 88.77\n",
      "6\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.217598 Test MSE 8.513377982602886 Test RE 1.394630048566031\n",
      "1 Train Loss 58.817497 Test MSE 8.567904445318277 Test RE 1.3990890817418231\n",
      "2 Train Loss 58.68529 Test MSE 8.506168123779277 Test RE 1.3940393772977562\n",
      "3 Train Loss 57.25979 Test MSE 8.555056894751598 Test RE 1.3980397229859316\n",
      "4 Train Loss 51.234898 Test MSE 8.499895404016762 Test RE 1.3935252779452405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 47.41635 Test MSE 8.621716540446398 Test RE 1.4034758060902988\n",
      "6 Train Loss 46.15046 Test MSE 8.482648839062113 Test RE 1.3921108059627008\n",
      "7 Train Loss 45.88405 Test MSE 8.455493471027337 Test RE 1.389880748743372\n",
      "8 Train Loss 45.736187 Test MSE 8.456567685880595 Test RE 1.389969033545007\n",
      "9 Train Loss 45.58481 Test MSE 8.340758318779686 Test RE 1.38041868425392\n",
      "10 Train Loss 45.5437 Test MSE 8.380377828977993 Test RE 1.3836933696116107\n",
      "11 Train Loss 45.40074 Test MSE 8.42457466824968 Test RE 1.3873372658800605\n",
      "12 Train Loss 44.95614 Test MSE 8.568365051675855 Test RE 1.3991266884091922\n",
      "13 Train Loss 44.59417 Test MSE 8.544535807737512 Test RE 1.3971797975159606\n",
      "14 Train Loss 43.083317 Test MSE 8.197562276663568 Test RE 1.3685177119765055\n",
      "15 Train Loss 41.59039 Test MSE 7.573889656228542 Test RE 1.315429408843365\n",
      "16 Train Loss 39.22907 Test MSE 7.553610015768631 Test RE 1.313667149446657\n",
      "17 Train Loss 36.832333 Test MSE 7.198048688238519 Test RE 1.2823762030279116\n",
      "18 Train Loss 35.75907 Test MSE 6.88508167101877 Test RE 1.2541879054036742\n",
      "19 Train Loss 35.42443 Test MSE 7.036493373871692 Test RE 1.2679035032144983\n",
      "20 Train Loss 35.0364 Test MSE 7.026540657944582 Test RE 1.2670064975526871\n",
      "21 Train Loss 34.869663 Test MSE 7.0182904767302325 Test RE 1.2662624540850864\n",
      "22 Train Loss 34.739338 Test MSE 7.034351026252157 Test RE 1.267710474052734\n",
      "23 Train Loss 34.656235 Test MSE 7.03647474171312 Test RE 1.2679018245520235\n",
      "24 Train Loss 34.62095 Test MSE 7.03030385023044 Test RE 1.2673457363819178\n",
      "25 Train Loss 34.556477 Test MSE 7.007667879350952 Test RE 1.2653038096797486\n",
      "26 Train Loss 34.426086 Test MSE 6.937747164496456 Test RE 1.2589755460260945\n",
      "27 Train Loss 34.374607 Test MSE 6.905547876872684 Test RE 1.2560505863575857\n",
      "28 Train Loss 34.266308 Test MSE 6.981474492185044 Test RE 1.2629368581202907\n",
      "29 Train Loss 34.1619 Test MSE 7.013607838503437 Test RE 1.2658399553040907\n",
      "30 Train Loss 34.101982 Test MSE 7.031619652665018 Test RE 1.267464330017532\n",
      "31 Train Loss 33.922894 Test MSE 7.037541054627888 Test RE 1.2679978903323785\n",
      "32 Train Loss 33.82987 Test MSE 6.9918034424948265 Test RE 1.2638707575958583\n",
      "33 Train Loss 33.778725 Test MSE 6.967602214118713 Test RE 1.2616814984556122\n",
      "34 Train Loss 33.6727 Test MSE 6.917107028748822 Test RE 1.2571013942779543\n",
      "35 Train Loss 33.378777 Test MSE 6.905340467284354 Test RE 1.2560317233436813\n",
      "36 Train Loss 33.19514 Test MSE 6.93750352494957 Test RE 1.258953439503809\n",
      "37 Train Loss 32.903072 Test MSE 6.771799477637686 Test RE 1.2438273584785486\n",
      "38 Train Loss 32.023243 Test MSE 6.729668027954789 Test RE 1.2399520211989565\n",
      "39 Train Loss 31.5285 Test MSE 6.995058688812418 Test RE 1.26416494005543\n",
      "40 Train Loss 30.922838 Test MSE 6.92297445515764 Test RE 1.2576344485152195\n",
      "41 Train Loss 29.983505 Test MSE 6.704541560272439 Test RE 1.2376350606894027\n",
      "42 Train Loss 29.435091 Test MSE 6.812347527188059 Test RE 1.2475456833219842\n",
      "43 Train Loss 28.568195 Test MSE 6.459675593495603 Test RE 1.2148241430303373\n",
      "44 Train Loss 28.280731 Test MSE 6.2903188700430634 Test RE 1.1987935316518377\n",
      "45 Train Loss 27.54021 Test MSE 6.0901074931316765 Test RE 1.1795613650410073\n",
      "46 Train Loss 26.754406 Test MSE 6.0894491444036625 Test RE 1.1794976072409056\n",
      "47 Train Loss 25.888277 Test MSE 6.16043921896403 Test RE 1.1863529070431973\n",
      "48 Train Loss 24.96622 Test MSE 6.381996253542464 Test RE 1.2074977571093655\n",
      "49 Train Loss 24.302338 Test MSE 6.254607763628694 Test RE 1.1953858207367174\n",
      "50 Train Loss 22.829868 Test MSE 6.27396047642239 Test RE 1.1972337456562547\n",
      "51 Train Loss 21.60681 Test MSE 5.990290485919237 Test RE 1.169854908995592\n",
      "52 Train Loss 18.841923 Test MSE 3.8901722573599153 Test RE 0.9427411767342501\n",
      "53 Train Loss 16.380257 Test MSE 3.0192384738039815 Test RE 0.8305327621215448\n",
      "54 Train Loss 14.495346 Test MSE 2.7626727175451875 Test RE 0.7944613605992112\n",
      "55 Train Loss 12.293856 Test MSE 2.533031216373427 Test RE 0.7607261252096875\n",
      "56 Train Loss 10.748146 Test MSE 2.212563071524183 Test RE 0.7109775541152955\n",
      "57 Train Loss 8.948917 Test MSE 1.8659775616546066 Test RE 0.6529219497006586\n",
      "58 Train Loss 7.872527 Test MSE 1.7684827743777376 Test RE 0.6356359872107012\n",
      "59 Train Loss 7.124188 Test MSE 1.5602477666929984 Test RE 0.5970419472800281\n",
      "60 Train Loss 5.6971 Test MSE 1.6306845595078552 Test RE 0.6103698033945871\n",
      "61 Train Loss 4.805627 Test MSE 1.5799173472133723 Test RE 0.6007935258672124\n",
      "62 Train Loss 4.2498913 Test MSE 1.4230973908266062 Test RE 0.5701975822435459\n",
      "63 Train Loss 4.002815 Test MSE 1.4153470660361467 Test RE 0.5686427871202635\n",
      "64 Train Loss 3.7456343 Test MSE 1.3246097690489627 Test RE 0.5501131634092762\n",
      "65 Train Loss 3.4127195 Test MSE 1.253839908940688 Test RE 0.5352160207580829\n",
      "66 Train Loss 3.1575294 Test MSE 1.2092517179700615 Test RE 0.5256133857218668\n",
      "67 Train Loss 2.826563 Test MSE 1.1111495754988505 Test RE 0.5038419482519259\n",
      "68 Train Loss 2.5785906 Test MSE 1.0391818550322847 Test RE 0.48725223264001355\n",
      "69 Train Loss 2.5143604 Test MSE 1.0315565100064212 Test RE 0.485461252859872\n",
      "70 Train Loss 2.4666204 Test MSE 1.056825668526339 Test RE 0.4913712436144645\n",
      "71 Train Loss 2.374967 Test MSE 1.0279473924887674 Test RE 0.4846112645690598\n",
      "72 Train Loss 2.1983466 Test MSE 0.9270062247142651 Test RE 0.46020293644367694\n",
      "73 Train Loss 2.081396 Test MSE 0.8498754748451409 Test RE 0.4406418162785705\n",
      "74 Train Loss 1.9404192 Test MSE 0.7937686885810786 Test RE 0.42584842174723264\n",
      "75 Train Loss 1.7282717 Test MSE 0.663823784173486 Test RE 0.389434537303186\n",
      "76 Train Loss 1.5998458 Test MSE 0.618835793576148 Test RE 0.376006863959606\n",
      "77 Train Loss 1.4377642 Test MSE 0.5393485554719678 Test RE 0.35102885723394933\n",
      "78 Train Loss 1.2857932 Test MSE 0.3987322790309465 Test RE 0.30182051637572127\n",
      "79 Train Loss 1.1030577 Test MSE 0.32275411642135277 Test RE 0.27154634105244846\n",
      "80 Train Loss 1.0465935 Test MSE 0.28176720430034846 Test RE 0.25371916984588994\n",
      "81 Train Loss 0.9565238 Test MSE 0.2428196950339641 Test RE 0.23553205156216842\n",
      "82 Train Loss 0.8790227 Test MSE 0.2213927267411602 Test RE 0.22490014471244624\n",
      "83 Train Loss 0.8111857 Test MSE 0.21291661019854172 Test RE 0.22055293011992896\n",
      "84 Train Loss 0.78327143 Test MSE 0.20856390300960312 Test RE 0.21828687977162167\n",
      "85 Train Loss 0.7078486 Test MSE 0.17450245236415646 Test RE 0.19966816543279994\n",
      "86 Train Loss 0.66044617 Test MSE 0.1535919870008435 Test RE 0.1873235328017021\n",
      "87 Train Loss 0.62131494 Test MSE 0.1465436730703681 Test RE 0.18297493294574094\n",
      "88 Train Loss 0.6103485 Test MSE 0.14677918826215477 Test RE 0.183121906456174\n",
      "89 Train Loss 0.60413206 Test MSE 0.14995182738701746 Test RE 0.1850904202973084\n",
      "90 Train Loss 0.5996022 Test MSE 0.1505978828588867 Test RE 0.18548871539921924\n",
      "91 Train Loss 0.5932618 Test MSE 0.15285020550473724 Test RE 0.18687064033621517\n",
      "92 Train Loss 0.5789952 Test MSE 0.15004885667363171 Test RE 0.1851502938162938\n",
      "93 Train Loss 0.5509115 Test MSE 0.14036945469501963 Test RE 0.17907887881396248\n",
      "94 Train Loss 0.5404441 Test MSE 0.14680791076947014 Test RE 0.18313982269850015\n",
      "95 Train Loss 0.511141 Test MSE 0.1529806185442638 Test RE 0.18695034311479947\n",
      "96 Train Loss 0.4787406 Test MSE 0.14051667634111123 Test RE 0.1791727645463735\n",
      "97 Train Loss 0.46172613 Test MSE 0.13500206737537143 Test RE 0.1756217376511297\n",
      "98 Train Loss 0.4401702 Test MSE 0.13015754664277462 Test RE 0.17244187533911812\n",
      "99 Train Loss 0.4053038 Test MSE 0.11000528422730467 Test RE 0.15853123175693903\n",
      "Training time: 89.51\n",
      "7\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.62393 Test MSE 8.391371404952384 Test RE 1.384600652850225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 54.130127 Test MSE 8.341991177704614 Test RE 1.3805207012735963\n",
      "2 Train Loss 48.78389 Test MSE 8.108355585909042 Test RE 1.3610511703440342\n",
      "3 Train Loss 43.214798 Test MSE 7.433403962525738 Test RE 1.3031725628194097\n",
      "4 Train Loss 33.954445 Test MSE 6.3186948776645755 Test RE 1.2014944040736733\n",
      "5 Train Loss 28.18853 Test MSE 5.604363510249692 Test RE 1.131543381258388\n",
      "6 Train Loss 25.475906 Test MSE 4.981803165396576 Test RE 1.0668450399594254\n",
      "7 Train Loss 22.87193 Test MSE 4.923004080349852 Test RE 1.0605304881677085\n",
      "8 Train Loss 20.666487 Test MSE 5.116209574195942 Test RE 1.0811407160955195\n",
      "9 Train Loss 17.930311 Test MSE 4.94184639564113 Test RE 1.0625580881262469\n",
      "10 Train Loss 15.786582 Test MSE 5.823289643315425 Test RE 1.153432691166787\n",
      "11 Train Loss 13.948832 Test MSE 5.761587688589503 Test RE 1.147305692223936\n",
      "12 Train Loss 12.739258 Test MSE 5.722682350393303 Test RE 1.1434255183919455\n",
      "13 Train Loss 11.408981 Test MSE 5.9400256895330275 Test RE 1.1649364169084782\n",
      "14 Train Loss 10.4793 Test MSE 5.8448966639554065 Test RE 1.1555705865918724\n",
      "15 Train Loss 9.656716 Test MSE 5.73935758843091 Test RE 1.1450902118038444\n",
      "16 Train Loss 9.008204 Test MSE 5.723179583325714 Test RE 1.1434751923419568\n",
      "17 Train Loss 8.186959 Test MSE 5.227002246153776 Test RE 1.092784191186241\n",
      "18 Train Loss 7.278261 Test MSE 5.176095686106979 Test RE 1.087449776546514\n",
      "19 Train Loss 6.375809 Test MSE 4.778763876845491 Test RE 1.0448786284116318\n",
      "20 Train Loss 5.597703 Test MSE 4.579881226491977 Test RE 1.0229046854450825\n",
      "21 Train Loss 4.9247303 Test MSE 4.218501133311722 Test RE 0.9817188847399572\n",
      "22 Train Loss 4.2437534 Test MSE 3.7976340911700506 Test RE 0.9314608780349034\n",
      "23 Train Loss 3.7824175 Test MSE 3.7199230022441876 Test RE 0.9218813637202228\n",
      "24 Train Loss 3.409083 Test MSE 3.48888802188648 Test RE 0.8927946428216399\n",
      "25 Train Loss 3.0767999 Test MSE 3.166218129518992 Test RE 0.8505081428198853\n",
      "26 Train Loss 2.671337 Test MSE 2.7391975868073177 Test RE 0.7910787897945569\n",
      "27 Train Loss 2.365673 Test MSE 2.4268503904054106 Test RE 0.7446111964205642\n",
      "28 Train Loss 2.050989 Test MSE 2.1036674616355704 Test RE 0.6932607378793327\n",
      "29 Train Loss 1.8307048 Test MSE 2.023229605129609 Test RE 0.6798774641776745\n",
      "30 Train Loss 1.6900022 Test MSE 1.7414389214121506 Test RE 0.6307571521340659\n",
      "31 Train Loss 1.5304252 Test MSE 1.5043336433433707 Test RE 0.5862463400615272\n",
      "32 Train Loss 1.34233 Test MSE 1.2948424675504773 Test RE 0.5438968300271546\n",
      "33 Train Loss 1.0757227 Test MSE 1.1582546940877374 Test RE 0.5144108198741281\n",
      "34 Train Loss 0.884227 Test MSE 0.8922268378251648 Test RE 0.4514874695466052\n",
      "35 Train Loss 0.70014757 Test MSE 0.6466436901842565 Test RE 0.3843621219827148\n",
      "36 Train Loss 0.579765 Test MSE 0.3916357187696326 Test RE 0.299122586480507\n",
      "37 Train Loss 0.44779477 Test MSE 0.2837495675984358 Test RE 0.25461012169433916\n",
      "38 Train Loss 0.3788463 Test MSE 0.24178638930139085 Test RE 0.23503037048899603\n",
      "39 Train Loss 0.3046008 Test MSE 0.18026778566585175 Test RE 0.20293975059903782\n",
      "40 Train Loss 0.22569072 Test MSE 0.08974042005939067 Test RE 0.14318651181440636\n",
      "41 Train Loss 0.15306069 Test MSE 0.046797873721791866 Test RE 0.10340013859549146\n",
      "42 Train Loss 0.11962231 Test MSE 0.028165217537663045 Test RE 0.08021666739490499\n",
      "43 Train Loss 0.10192928 Test MSE 0.02197949859596197 Test RE 0.07086257844121903\n",
      "44 Train Loss 0.08273672 Test MSE 0.019973210277953377 Test RE 0.06755103342293442\n",
      "45 Train Loss 0.07359947 Test MSE 0.017813365515675045 Test RE 0.06379417860539581\n",
      "46 Train Loss 0.06493771 Test MSE 0.01806795047309282 Test RE 0.0642484279956177\n",
      "47 Train Loss 0.057987258 Test MSE 0.017695178299633928 Test RE 0.06358219721550384\n",
      "48 Train Loss 0.04917942 Test MSE 0.01385994581563301 Test RE 0.05627154333204065\n",
      "49 Train Loss 0.04289786 Test MSE 0.013540192477669227 Test RE 0.05561865461215905\n",
      "50 Train Loss 0.038537033 Test MSE 0.01466881584042689 Test RE 0.0578902717716696\n",
      "51 Train Loss 0.035034187 Test MSE 0.01369292027703059 Test RE 0.05593145279532602\n",
      "52 Train Loss 0.03284492 Test MSE 0.012374636004361566 Test RE 0.05317093249074284\n",
      "53 Train Loss 0.029530995 Test MSE 0.01180716910760537 Test RE 0.05193748934143575\n",
      "54 Train Loss 0.027588027 Test MSE 0.009334143779604571 Test RE 0.04617908286802515\n",
      "55 Train Loss 0.025336714 Test MSE 0.007970272052938154 Test RE 0.04267216062361233\n",
      "56 Train Loss 0.022817727 Test MSE 0.006948767256786478 Test RE 0.039843909324491215\n",
      "57 Train Loss 0.02134781 Test MSE 0.005927125531946363 Test RE 0.03679850058185215\n",
      "58 Train Loss 0.019406753 Test MSE 0.00574443093170767 Test RE 0.03622693286835819\n",
      "59 Train Loss 0.017148277 Test MSE 0.005059190981746635 Test RE 0.033997626416512244\n",
      "60 Train Loss 0.015452437 Test MSE 0.004870597282607465 Test RE 0.0333579360173788\n",
      "61 Train Loss 0.014209429 Test MSE 0.004604858429823071 Test RE 0.032435171735825316\n",
      "62 Train Loss 0.01273414 Test MSE 0.004516826536027857 Test RE 0.03212364119497067\n",
      "63 Train Loss 0.01180541 Test MSE 0.004669395266587454 Test RE 0.03266166947962365\n",
      "64 Train Loss 0.011131188 Test MSE 0.004124348187303351 Test RE 0.03069627814580034\n",
      "65 Train Loss 0.010275381 Test MSE 0.004138374435033746 Test RE 0.03074843040626816\n",
      "66 Train Loss 0.009432423 Test MSE 0.004498170106248727 Test RE 0.032057230343554226\n",
      "67 Train Loss 0.009045387 Test MSE 0.004358134712796712 Test RE 0.03155428803093623\n",
      "68 Train Loss 0.00851802 Test MSE 0.0038960120747859846 Test RE 0.029834461772793794\n",
      "69 Train Loss 0.0076987413 Test MSE 0.0034836706016623895 Test RE 0.028211527539310166\n",
      "70 Train Loss 0.007315653 Test MSE 0.003575476912360404 Test RE 0.02858084398869858\n",
      "71 Train Loss 0.0068709203 Test MSE 0.0034496241165317887 Test RE 0.028073331109372716\n",
      "72 Train Loss 0.006646865 Test MSE 0.0031999010581591843 Test RE 0.027038110294070862\n",
      "73 Train Loss 0.0064313076 Test MSE 0.003126573191068761 Test RE 0.02672651668877038\n",
      "74 Train Loss 0.0061632493 Test MSE 0.0031139760681756475 Test RE 0.026672621097342832\n",
      "75 Train Loss 0.0058007743 Test MSE 0.0026866875819854283 Test RE 0.024775170063125743\n",
      "76 Train Loss 0.0054789144 Test MSE 0.0022580503333607758 Test RE 0.022713019275849757\n",
      "77 Train Loss 0.005260027 Test MSE 0.0022131196195631087 Test RE 0.022485911881935904\n",
      "78 Train Loss 0.004909342 Test MSE 0.0021167485646614594 Test RE 0.021990884484558913\n",
      "79 Train Loss 0.0045274086 Test MSE 0.0017358121845105904 Test RE 0.01991404235833654\n",
      "80 Train Loss 0.0039685583 Test MSE 0.001287323036125925 Test RE 0.01714951453779222\n",
      "81 Train Loss 0.0036585063 Test MSE 0.0011763467519435012 Test RE 0.016393653032547625\n",
      "82 Train Loss 0.0035004101 Test MSE 0.0011486967413536528 Test RE 0.01619984110462196\n",
      "83 Train Loss 0.0033405204 Test MSE 0.0011153875277766837 Test RE 0.01596323665978463\n",
      "84 Train Loss 0.0031082267 Test MSE 0.0011818090615691686 Test RE 0.01643167052068254\n",
      "85 Train Loss 0.00298056 Test MSE 0.0012629407700195212 Test RE 0.016986329800015246\n",
      "86 Train Loss 0.0027730542 Test MSE 0.0012533601811774177 Test RE 0.016921778534487626\n",
      "87 Train Loss 0.0026036052 Test MSE 0.0010834409568966541 Test RE 0.015732968922357017\n",
      "88 Train Loss 0.0024472 Test MSE 0.0009903611993566498 Test RE 0.01504197521792361\n",
      "89 Train Loss 0.002360841 Test MSE 0.0009804296842093297 Test RE 0.014966363400313583\n",
      "90 Train Loss 0.0022857299 Test MSE 0.0009492048779257882 Test RE 0.014726110025527081\n",
      "91 Train Loss 0.002222826 Test MSE 0.0009218601792017972 Test RE 0.014512445040432326\n",
      "92 Train Loss 0.0021594889 Test MSE 0.0008607877164289592 Test RE 0.014023489405638181\n",
      "93 Train Loss 0.0020645624 Test MSE 0.0007827251488217802 Test RE 0.013372503006387263\n",
      "94 Train Loss 0.0019734423 Test MSE 0.0007845654924514728 Test RE 0.013388214493349454\n",
      "95 Train Loss 0.0019176749 Test MSE 0.0007827130683053039 Test RE 0.013372399810925568\n",
      "96 Train Loss 0.0018368692 Test MSE 0.000732583254862714 Test RE 0.012937088647272384\n",
      "97 Train Loss 0.0017583111 Test MSE 0.0006590943488901153 Test RE 0.01227105363288949\n",
      "98 Train Loss 0.0017049953 Test MSE 0.0005881500497481865 Test RE 0.011591833362059495\n",
      "99 Train Loss 0.001582365 Test MSE 0.0004717559997289625 Test RE 0.010381659396649432\n",
      "Training time: 88.79\n",
      "8\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.14297 Test MSE 8.93360524229727 Test RE 1.4286355053018274\n",
      "1 Train Loss 38.63299 Test MSE 9.112366134307193 Test RE 1.4428581634181812\n",
      "2 Train Loss 26.818087 Test MSE 7.442749070603627 Test RE 1.3039914651245739\n",
      "3 Train Loss 22.017134 Test MSE 6.847340777358286 Test RE 1.250745737311741\n",
      "4 Train Loss 18.576965 Test MSE 6.910328268136097 Test RE 1.2564852639944384\n",
      "5 Train Loss 17.067362 Test MSE 7.049473267972438 Test RE 1.2690723859118882\n",
      "6 Train Loss 15.846126 Test MSE 7.239108432438719 Test RE 1.286028523683932\n",
      "7 Train Loss 14.670801 Test MSE 7.268056327004923 Test RE 1.288597256826028\n",
      "8 Train Loss 13.388735 Test MSE 7.322538712022777 Test RE 1.2934179937115284\n",
      "9 Train Loss 12.226905 Test MSE 7.194210867247378 Test RE 1.282034291858085\n",
      "10 Train Loss 11.439882 Test MSE 7.138715209077855 Test RE 1.2770799559103954\n",
      "11 Train Loss 10.45673 Test MSE 6.889425963077191 Test RE 1.2545835215791181\n",
      "12 Train Loss 9.355655 Test MSE 6.754311450006011 Test RE 1.2422202414172585\n",
      "13 Train Loss 8.69267 Test MSE 6.629036265204304 Test RE 1.230646321036006\n",
      "14 Train Loss 8.080814 Test MSE 6.436434511014496 Test RE 1.2126367832389648\n",
      "15 Train Loss 7.378771 Test MSE 6.313754096175631 Test RE 1.2010245695328738\n",
      "16 Train Loss 6.5742674 Test MSE 5.939197298773419 Test RE 1.1648551835720091\n",
      "17 Train Loss 5.7711587 Test MSE 5.591210165965832 Test RE 1.1302147448505568\n",
      "18 Train Loss 4.861401 Test MSE 5.298044040870387 Test RE 1.1001853113081081\n",
      "19 Train Loss 3.640491 Test MSE 4.5006191384651055 Test RE 1.0140145614649216\n",
      "20 Train Loss 2.8730733 Test MSE 4.49598972880569 Test RE 1.0134929113943674\n",
      "21 Train Loss 2.5591025 Test MSE 4.464012908107862 Test RE 1.009882348065439\n",
      "22 Train Loss 2.3242593 Test MSE 4.398783534720384 Test RE 1.0024768576813134\n",
      "23 Train Loss 2.1474528 Test MSE 4.3706206951360365 Test RE 0.9992625679636513\n",
      "24 Train Loss 2.0149481 Test MSE 4.37224932941847 Test RE 0.9994487293590856\n",
      "25 Train Loss 1.9047244 Test MSE 4.25371969880637 Test RE 0.9858083547664174\n",
      "26 Train Loss 1.8234398 Test MSE 4.209264970787869 Test RE 0.9806435876835206\n",
      "27 Train Loss 1.7737921 Test MSE 4.156102795738563 Test RE 0.9744312439613085\n",
      "28 Train Loss 1.7124466 Test MSE 4.072437775909709 Test RE 0.9645734171067918\n",
      "29 Train Loss 1.600127 Test MSE 3.7369691297349243 Test RE 0.923991158182112\n",
      "30 Train Loss 1.4750367 Test MSE 3.4645478075861234 Test RE 0.8896749028331354\n",
      "31 Train Loss 1.3599355 Test MSE 3.3513537732030514 Test RE 0.8750204394473046\n",
      "32 Train Loss 1.2427421 Test MSE 3.1193610355856896 Test RE 0.8441913187817921\n",
      "33 Train Loss 1.1532439 Test MSE 3.014040166906318 Test RE 0.8298174784239243\n",
      "34 Train Loss 1.0906205 Test MSE 2.9145647134095722 Test RE 0.8160089301791574\n",
      "35 Train Loss 1.0326525 Test MSE 2.8102451403262823 Test RE 0.8012723619646304\n",
      "36 Train Loss 0.97857565 Test MSE 2.8164737927019665 Test RE 0.8021598440832424\n",
      "37 Train Loss 0.9388803 Test MSE 2.743488495948857 Test RE 0.7916981534597649\n",
      "38 Train Loss 0.8983233 Test MSE 2.680930606133434 Test RE 0.7826198278474753\n",
      "39 Train Loss 0.8723767 Test MSE 2.658031714623608 Test RE 0.7792703269949277\n",
      "40 Train Loss 0.8506082 Test MSE 2.651914320004002 Test RE 0.7783730747004215\n",
      "41 Train Loss 0.8258459 Test MSE 2.6308129056543965 Test RE 0.7752701131023357\n",
      "42 Train Loss 0.799562 Test MSE 2.647088557593177 Test RE 0.7776645386272574\n",
      "43 Train Loss 0.7785174 Test MSE 2.683709886318199 Test RE 0.7830253878307032\n",
      "44 Train Loss 0.75639844 Test MSE 2.7148789753132734 Test RE 0.7875593600406742\n",
      "45 Train Loss 0.73447436 Test MSE 2.7138939925016365 Test RE 0.787416480226638\n",
      "46 Train Loss 0.7144419 Test MSE 2.724730895216751 Test RE 0.7889870379388977\n",
      "47 Train Loss 0.69194627 Test MSE 2.772074554671816 Test RE 0.7958120548305085\n",
      "48 Train Loss 0.67952204 Test MSE 2.81118621532286 Test RE 0.8014065129425456\n",
      "49 Train Loss 0.66789544 Test MSE 2.85277601069941 Test RE 0.8073129094554393\n",
      "50 Train Loss 0.65440047 Test MSE 2.835478612525227 Test RE 0.8048616751111797\n",
      "51 Train Loss 0.6424698 Test MSE 2.820303510071387 Test RE 0.8027050296797071\n",
      "52 Train Loss 0.6299324 Test MSE 2.8021715589630363 Test RE 0.8001205424108306\n",
      "53 Train Loss 0.6186296 Test MSE 2.8091867323976625 Test RE 0.8011214582453993\n",
      "54 Train Loss 0.6070977 Test MSE 2.8180714572296166 Test RE 0.8023873272284087\n",
      "55 Train Loss 0.5959815 Test MSE 2.826842585637009 Test RE 0.8036350554434918\n",
      "56 Train Loss 0.58326405 Test MSE 2.8502882184229006 Test RE 0.8069608199693367\n",
      "57 Train Loss 0.57218343 Test MSE 2.866128832852455 Test RE 0.8092000749528049\n",
      "58 Train Loss 0.55988413 Test MSE 2.877085949223397 Test RE 0.810745372108083\n",
      "59 Train Loss 0.5504088 Test MSE 2.8733589657351977 Test RE 0.8102200812650755\n",
      "60 Train Loss 0.54305065 Test MSE 2.869759444716457 Test RE 0.809712431823979\n",
      "61 Train Loss 0.5366036 Test MSE 2.8772249659212843 Test RE 0.8107649589026764\n",
      "62 Train Loss 0.5309904 Test MSE 2.8858700359528004 Test RE 0.8119820800574249\n",
      "63 Train Loss 0.5249735 Test MSE 2.902470555569093 Test RE 0.8143141316403258\n",
      "64 Train Loss 0.518204 Test MSE 2.903086264639372 Test RE 0.8144004984096549\n",
      "65 Train Loss 0.5129651 Test MSE 2.909973686453323 Test RE 0.8153659876082223\n",
      "66 Train Loss 0.5077162 Test MSE 2.929037877691072 Test RE 0.8180324923440279\n",
      "67 Train Loss 0.5029158 Test MSE 2.930472457930767 Test RE 0.8182327952489812\n",
      "68 Train Loss 0.49759245 Test MSE 2.9193865098053102 Test RE 0.8166836454981572\n",
      "69 Train Loss 0.4926474 Test MSE 2.9429409528166577 Test RE 0.8199716449833225\n",
      "70 Train Loss 0.48721966 Test MSE 2.9585753801431407 Test RE 0.8221468170369374\n",
      "71 Train Loss 0.48291522 Test MSE 2.945327532753028 Test RE 0.8203040558820583\n",
      "72 Train Loss 0.476853 Test MSE 2.9607463392445914 Test RE 0.8224484013439632\n",
      "73 Train Loss 0.46836966 Test MSE 2.96773286026155 Test RE 0.8234182019640325\n",
      "74 Train Loss 0.46359375 Test MSE 2.971207500515168 Test RE 0.8239000925538309\n",
      "75 Train Loss 0.45891407 Test MSE 2.987958356873626 Test RE 0.8262192902416929\n",
      "76 Train Loss 0.45461667 Test MSE 2.9786265320727088 Test RE 0.8249280803040239\n",
      "77 Train Loss 0.45134795 Test MSE 2.969112687016312 Test RE 0.8236096010025422\n",
      "78 Train Loss 0.4481625 Test MSE 2.985793750591808 Test RE 0.8259199615236724\n",
      "79 Train Loss 0.44607854 Test MSE 2.9897142358827393 Test RE 0.8264620191999598\n",
      "80 Train Loss 0.4444487 Test MSE 2.991975737165371 Test RE 0.8267745393028069\n",
      "81 Train Loss 0.44209284 Test MSE 2.999674452011606 Test RE 0.8278375512879966\n",
      "82 Train Loss 0.43969378 Test MSE 3.006512092187196 Test RE 0.8287805258282055\n",
      "83 Train Loss 0.43751544 Test MSE 3.0070139267024394 Test RE 0.8288496912442421\n",
      "84 Train Loss 0.4348697 Test MSE 3.010795066674504 Test RE 0.8293706419598681\n",
      "85 Train Loss 0.4322056 Test MSE 3.0156773327344566 Test RE 0.8300428178869131\n",
      "86 Train Loss 0.43016094 Test MSE 3.020199061668062 Test RE 0.8306648709716579\n",
      "87 Train Loss 0.42829832 Test MSE 3.0271361781688 Test RE 0.8316183037959402\n",
      "88 Train Loss 0.42568105 Test MSE 3.042943033615179 Test RE 0.833786715451589\n",
      "89 Train Loss 0.4232012 Test MSE 3.057051460829743 Test RE 0.8357173818285821\n",
      "90 Train Loss 0.4210738 Test MSE 3.0578782537524285 Test RE 0.8358303858969127\n",
      "91 Train Loss 0.41838345 Test MSE 3.0683885278208107 Test RE 0.8372655756025162\n",
      "92 Train Loss 0.41588676 Test MSE 3.078059395581934 Test RE 0.838583973611454\n",
      "93 Train Loss 0.41242358 Test MSE 3.0968028462353483 Test RE 0.8411333236667821\n",
      "94 Train Loss 0.40900666 Test MSE 3.1222654266622305 Test RE 0.8445842343897743\n",
      "95 Train Loss 0.40621 Test MSE 3.1200618910787665 Test RE 0.8442861495639228\n",
      "96 Train Loss 0.40415606 Test MSE 3.1221475834917403 Test RE 0.8445682957347488\n",
      "97 Train Loss 0.40007403 Test MSE 3.1588214305923223 Test RE 0.8495141129032452\n",
      "98 Train Loss 0.39745665 Test MSE 3.1752442098492577 Test RE 0.8517195709609425\n",
      "99 Train Loss 0.39566538 Test MSE 3.1748916173371744 Test RE 0.8516722803809664\n",
      "Training time: 88.27\n",
      "9\n",
      "KG_rowdy_tune1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.785137 Test MSE 8.557670550745847 Test RE 1.3982532642812553\n",
      "1 Train Loss 56.412434 Test MSE 8.623530345768291 Test RE 1.4036234273907198\n",
      "2 Train Loss 55.44867 Test MSE 8.443269258035672 Test RE 1.3888757013417927\n",
      "3 Train Loss 48.750893 Test MSE 10.027936334470958 Test RE 1.5136094980217356\n",
      "4 Train Loss 44.45569 Test MSE 8.328195298694478 Test RE 1.3793786851183483\n",
      "5 Train Loss 43.548515 Test MSE 8.540358153872416 Test RE 1.3968381963251126\n",
      "6 Train Loss 43.04035 Test MSE 8.441527573386304 Test RE 1.3887324447325737\n",
      "7 Train Loss 42.558605 Test MSE 8.532927942244854 Test RE 1.3962304313096539\n",
      "8 Train Loss 42.082756 Test MSE 8.455249994282749 Test RE 1.3898607377246563\n",
      "9 Train Loss 41.409187 Test MSE 8.708438061961534 Test RE 1.4105165750315742\n",
      "10 Train Loss 40.791077 Test MSE 8.954183857084027 Test RE 1.4302799941738378\n",
      "11 Train Loss 40.330948 Test MSE 8.94728798675082 Test RE 1.4297291385504916\n",
      "12 Train Loss 39.975853 Test MSE 8.905516795755442 Test RE 1.4263878268630128\n",
      "13 Train Loss 39.05639 Test MSE 8.859197692035702 Test RE 1.4226735483779003\n",
      "14 Train Loss 36.79988 Test MSE 8.337207321687881 Test RE 1.3801248030271098\n",
      "15 Train Loss 32.62335 Test MSE 8.033372573515356 Test RE 1.3547433095094785\n",
      "16 Train Loss 29.94606 Test MSE 8.44071043324255 Test RE 1.3886652284329826\n",
      "17 Train Loss 29.387794 Test MSE 8.528770131115852 Test RE 1.3958902216058298\n",
      "18 Train Loss 28.478382 Test MSE 8.435493861415924 Test RE 1.388236047052735\n",
      "19 Train Loss 27.361023 Test MSE 8.587053040641834 Test RE 1.4006516364367596\n",
      "20 Train Loss 26.687775 Test MSE 8.889921029418247 Test RE 1.4251383003225548\n",
      "21 Train Loss 26.18127 Test MSE 8.758023955738075 Test RE 1.4145266193627548\n",
      "22 Train Loss 25.191664 Test MSE 8.44134093723559 Test RE 1.3887170927060455\n",
      "23 Train Loss 23.937141 Test MSE 8.681175286808374 Test RE 1.4083069514568813\n",
      "24 Train Loss 23.077902 Test MSE 8.637757655660275 Test RE 1.4047808162327\n",
      "25 Train Loss 21.591137 Test MSE 8.295658767850833 Test RE 1.376681575134607\n",
      "26 Train Loss 20.454388 Test MSE 8.295754818438398 Test RE 1.3766895450074725\n",
      "27 Train Loss 18.428223 Test MSE 8.039679230239932 Test RE 1.3552749806550668\n",
      "28 Train Loss 15.652212 Test MSE 7.0970429097670555 Test RE 1.2733470186459181\n",
      "29 Train Loss 10.783321 Test MSE 5.686860328723148 Test RE 1.1398411753185647\n",
      "30 Train Loss 9.32392 Test MSE 5.74389148159739 Test RE 1.1455424132647338\n",
      "31 Train Loss 8.210821 Test MSE 5.6249500580348215 Test RE 1.133619729359101\n",
      "32 Train Loss 6.7868557 Test MSE 5.133154710311972 Test RE 1.0829296315172687\n",
      "33 Train Loss 6.16537 Test MSE 5.201134373480964 Test RE 1.0900768015946698\n",
      "34 Train Loss 5.4303775 Test MSE 5.135438531402457 Test RE 1.0831705109217853\n",
      "35 Train Loss 4.836384 Test MSE 5.1253546429838055 Test RE 1.0821065377447057\n",
      "36 Train Loss 4.2320857 Test MSE 5.078694174377029 Test RE 1.077169607058603\n",
      "37 Train Loss 3.831766 Test MSE 5.097110882156552 Test RE 1.0791208926974707\n",
      "38 Train Loss 3.3539677 Test MSE 5.183758075951871 Test RE 1.0882543774645395\n",
      "39 Train Loss 3.1295168 Test MSE 5.138370233337229 Test RE 1.0834796451839366\n",
      "40 Train Loss 2.9584467 Test MSE 5.155008171202808 Test RE 1.085232369989478\n",
      "41 Train Loss 2.7739348 Test MSE 5.175088846822978 Test RE 1.0873440075973324\n",
      "42 Train Loss 2.6131842 Test MSE 5.104742121831374 Test RE 1.0799284040854435\n",
      "43 Train Loss 2.4722404 Test MSE 5.177875396918952 Test RE 1.087636710860709\n",
      "44 Train Loss 2.348959 Test MSE 5.222314719099094 Test RE 1.092294081924977\n",
      "45 Train Loss 2.2382016 Test MSE 5.152986609373413 Test RE 1.0850195595158387\n",
      "46 Train Loss 2.1598444 Test MSE 5.1814869286180985 Test RE 1.0880159542232888\n",
      "47 Train Loss 2.0445132 Test MSE 5.252619859159747 Test RE 1.095458793625629\n",
      "48 Train Loss 1.991609 Test MSE 5.296572997993615 Test RE 1.100032563226917\n",
      "49 Train Loss 1.9158819 Test MSE 5.416859478766907 Test RE 1.1124534443898462\n",
      "50 Train Loss 1.8122196 Test MSE 5.370246220487486 Test RE 1.1076566503636822\n",
      "51 Train Loss 1.7026576 Test MSE 5.502606550950906 Test RE 1.1212237557015843\n",
      "52 Train Loss 1.6272349 Test MSE 5.499389990762847 Test RE 1.1208960009493956\n",
      "53 Train Loss 1.5888631 Test MSE 5.4677165308236395 Test RE 1.1176634677665795\n",
      "54 Train Loss 1.535559 Test MSE 5.488043073597392 Test RE 1.1197390288563196\n",
      "55 Train Loss 1.4789693 Test MSE 5.496292955129937 Test RE 1.1205803346895722\n",
      "56 Train Loss 1.4419588 Test MSE 5.498997940405337 Test RE 1.1208560460170345\n",
      "57 Train Loss 1.4014385 Test MSE 5.572198997588025 Test RE 1.1282916371505416\n",
      "58 Train Loss 1.3578256 Test MSE 5.645288448502926 Test RE 1.1356673206170909\n",
      "59 Train Loss 1.3111308 Test MSE 5.661340622455968 Test RE 1.1372807889902787\n",
      "60 Train Loss 1.2692863 Test MSE 5.706472814011684 Test RE 1.1418049897895517\n",
      "61 Train Loss 1.2304661 Test MSE 5.770447517672103 Test RE 1.148187482811131\n",
      "62 Train Loss 1.1997579 Test MSE 5.813171974241791 Test RE 1.1524302402824176\n",
      "63 Train Loss 1.1733788 Test MSE 5.84603601162173 Test RE 1.1556832089846953\n",
      "64 Train Loss 1.1438184 Test MSE 5.860747855923252 Test RE 1.1571364627872631\n",
      "65 Train Loss 1.1238128 Test MSE 5.858938442511696 Test RE 1.1569578251873056\n",
      "66 Train Loss 1.107793 Test MSE 5.87201468009768 Test RE 1.1582481804072613\n",
      "67 Train Loss 1.0925529 Test MSE 5.884495909759702 Test RE 1.1594784811281444\n",
      "68 Train Loss 1.0749997 Test MSE 5.918564310020361 Test RE 1.1628300484263367\n",
      "69 Train Loss 1.0604875 Test MSE 5.935105430047641 Test RE 1.164453845183219\n",
      "70 Train Loss 1.0506777 Test MSE 5.91780761975972 Test RE 1.162755711961269\n",
      "71 Train Loss 1.040367 Test MSE 5.917493404222524 Test RE 1.162724842356843\n",
      "72 Train Loss 1.0261663 Test MSE 5.938756520106382 Test RE 1.1648119577945215\n",
      "73 Train Loss 1.0139254 Test MSE 5.949661597820999 Test RE 1.1658809138149149\n",
      "74 Train Loss 1.001639 Test MSE 5.968366601424436 Test RE 1.167712168665427\n",
      "75 Train Loss 0.9842317 Test MSE 5.979362371379757 Test RE 1.1687873360279015\n",
      "76 Train Loss 0.97584367 Test MSE 5.983252477239288 Test RE 1.169167474152464\n",
      "77 Train Loss 0.964131 Test MSE 5.99974661393294 Test RE 1.1707778972526892\n",
      "78 Train Loss 0.94898766 Test MSE 6.030375372896345 Test RE 1.1737625086898744\n",
      "79 Train Loss 0.9424704 Test MSE 6.032761823646314 Test RE 1.1739947371310986\n",
      "80 Train Loss 0.93431133 Test MSE 6.026204306050394 Test RE 1.173356506703315\n",
      "81 Train Loss 0.9265107 Test MSE 6.01094559673359 Test RE 1.1718700607779906\n",
      "82 Train Loss 0.91918343 Test MSE 6.030646802298518 Test RE 1.1737889241326456\n",
      "83 Train Loss 0.91245776 Test MSE 6.042674458747383 Test RE 1.1749588564896463\n",
      "84 Train Loss 0.9031377 Test MSE 6.066901560457893 Test RE 1.1773119017096196\n",
      "85 Train Loss 0.89357513 Test MSE 6.101326009069974 Test RE 1.1806472932893775\n",
      "86 Train Loss 0.88622737 Test MSE 6.108237293893413 Test RE 1.1813157938958514\n",
      "87 Train Loss 0.8785468 Test MSE 6.118899725796645 Test RE 1.182346386412743\n",
      "88 Train Loss 0.8730871 Test MSE 6.1334802406212905 Test RE 1.1837542344180687\n",
      "89 Train Loss 0.86499363 Test MSE 6.1440743109975875 Test RE 1.1847761147026241\n",
      "90 Train Loss 0.85385424 Test MSE 6.125453922152789 Test RE 1.182979446005277\n",
      "91 Train Loss 0.8452263 Test MSE 6.118638190872062 Test RE 1.1823211181299498\n",
      "92 Train Loss 0.84079105 Test MSE 6.139437536635356 Test RE 1.184328970341657\n",
      "93 Train Loss 0.83352304 Test MSE 6.158117426881485 Test RE 1.1861293252279668\n",
      "94 Train Loss 0.82794285 Test MSE 6.159717732265106 Test RE 1.1862834344881785\n",
      "95 Train Loss 0.8196915 Test MSE 6.188155719300838 Test RE 1.1890186787607837\n",
      "96 Train Loss 0.81473815 Test MSE 6.200425420710734 Test RE 1.1901968714537035\n",
      "97 Train Loss 0.8085948 Test MSE 6.192451589635734 Test RE 1.1894313205984524\n",
      "98 Train Loss 0.80056155 Test MSE 6.197874724033159 Test RE 1.1899520379721464\n",
      "99 Train Loss 0.79624796 Test MSE 6.220014879809839 Test RE 1.1920755269443326\n",
      "Training time: 88.81\n",
      "0\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.56292 Test MSE 8.061696312332773 Test RE 1.3571294575891524\n",
      "1 Train Loss 34.71691 Test MSE 6.327106962170058 Test RE 1.2022939133872317\n",
      "2 Train Loss 24.059425 Test MSE 5.367505051816612 Test RE 1.1073739201928126\n",
      "3 Train Loss 21.825943 Test MSE 6.008745634319698 Test RE 1.1716555931889823\n",
      "4 Train Loss 18.027588 Test MSE 5.581528802904127 Test RE 1.1292358190295924\n",
      "5 Train Loss 15.170912 Test MSE 5.961686821208454 Test RE 1.1670585355328424\n",
      "6 Train Loss 11.995569 Test MSE 5.515095497271379 Test RE 1.122495422754141\n",
      "7 Train Loss 10.712799 Test MSE 5.648645233979276 Test RE 1.136004914087501\n",
      "8 Train Loss 9.842428 Test MSE 5.487939585415969 Test RE 1.1197284713314872\n",
      "9 Train Loss 8.939163 Test MSE 5.383419073525375 Test RE 1.1090143219624975\n",
      "10 Train Loss 8.309149 Test MSE 5.259876724916597 Test RE 1.096215259330641\n",
      "11 Train Loss 7.636487 Test MSE 5.207379445953087 Test RE 1.0907310402536228\n",
      "12 Train Loss 6.8199835 Test MSE 4.921893340486228 Test RE 1.0604108417158304\n",
      "13 Train Loss 6.1084375 Test MSE 4.748951208226827 Test RE 1.041614253240886\n",
      "14 Train Loss 5.4304433 Test MSE 4.7259631714082735 Test RE 1.0390901470676976\n",
      "15 Train Loss 4.482825 Test MSE 4.471679517981316 Test RE 1.0107491749265811\n",
      "16 Train Loss 3.8618054 Test MSE 4.115175014143793 Test RE 0.9696214519911068\n",
      "17 Train Loss 3.2690458 Test MSE 3.710718097557396 Test RE 0.9207400650822469\n",
      "18 Train Loss 2.8094978 Test MSE 3.235033852302907 Test RE 0.859701085468277\n",
      "19 Train Loss 2.3112717 Test MSE 2.8359123794645678 Test RE 0.8049232359765729\n",
      "20 Train Loss 2.0358763 Test MSE 2.637525679936725 Test RE 0.7762585714094227\n",
      "21 Train Loss 1.7909904 Test MSE 2.503352556616422 Test RE 0.7562564102892559\n",
      "22 Train Loss 1.6602125 Test MSE 2.363005739837424 Test RE 0.7347514445004204\n",
      "23 Train Loss 1.4934727 Test MSE 2.2839548541007924 Test RE 0.7223568872025313\n",
      "24 Train Loss 1.3828839 Test MSE 2.2031386995879267 Test RE 0.7094617403033389\n",
      "25 Train Loss 1.2683789 Test MSE 2.128459760979705 Test RE 0.6973339063666332\n",
      "26 Train Loss 1.1790407 Test MSE 2.114055904786509 Test RE 0.6949703784427209\n",
      "27 Train Loss 1.0939219 Test MSE 1.9479123224811572 Test RE 0.6671027988504875\n",
      "28 Train Loss 0.9998708 Test MSE 1.6980783882178594 Test RE 0.62285496054788\n",
      "29 Train Loss 0.88111943 Test MSE 1.5194499345433221 Test RE 0.5891844247959428\n",
      "30 Train Loss 0.7718301 Test MSE 1.3643984662592004 Test RE 0.5583141972224099\n",
      "31 Train Loss 0.6542538 Test MSE 1.2232189149842931 Test RE 0.5286401619092098\n",
      "32 Train Loss 0.5320251 Test MSE 0.9832121105957721 Test RE 0.47394906400238496\n",
      "33 Train Loss 0.4321259 Test MSE 0.7803247219110636 Test RE 0.42222674904943025\n",
      "34 Train Loss 0.36312634 Test MSE 0.7668442057397057 Test RE 0.4185637665967417\n",
      "35 Train Loss 0.30998576 Test MSE 0.6933714352627891 Test RE 0.3980072959976358\n",
      "36 Train Loss 0.27967462 Test MSE 0.6507956618078157 Test RE 0.3855941042647574\n",
      "37 Train Loss 0.25984102 Test MSE 0.6318140243097343 Test RE 0.37992921570625027\n",
      "38 Train Loss 0.23936678 Test MSE 0.6098859691256225 Test RE 0.373277988698325\n",
      "39 Train Loss 0.21797049 Test MSE 0.6074182851757094 Test RE 0.37252205579006753\n",
      "40 Train Loss 0.20136487 Test MSE 0.5847956337866579 Test RE 0.3655191381134214\n",
      "41 Train Loss 0.1885394 Test MSE 0.5827194689298686 Test RE 0.3648697208698643\n",
      "42 Train Loss 0.17966537 Test MSE 0.5856842200368827 Test RE 0.3657967325199905\n",
      "43 Train Loss 0.17363618 Test MSE 0.5538648884344896 Test RE 0.35572138741065784\n",
      "44 Train Loss 0.16570212 Test MSE 0.5322501391580096 Test RE 0.3487112447410596\n",
      "45 Train Loss 0.16135444 Test MSE 0.5191875016804933 Test RE 0.3444055765773872\n",
      "46 Train Loss 0.15499727 Test MSE 0.48404961111358896 Test RE 0.3325469722487681\n",
      "47 Train Loss 0.15000363 Test MSE 0.4666844222682122 Test RE 0.32652746189613535\n",
      "48 Train Loss 0.1432017 Test MSE 0.4236884090119878 Test RE 0.31112245121301363\n",
      "49 Train Loss 0.1329963 Test MSE 0.3577341065357647 Test RE 0.28588293641507095\n",
      "50 Train Loss 0.11633645 Test MSE 0.2695059483331275 Test RE 0.24813740597379713\n",
      "51 Train Loss 0.09677758 Test MSE 0.20228949306256866 Test RE 0.21497834902898907\n",
      "52 Train Loss 0.0876364 Test MSE 0.1725667081698701 Test RE 0.19855762415910252\n",
      "53 Train Loss 0.07371591 Test MSE 0.12298637957844946 Test RE 0.16762414236705833\n",
      "54 Train Loss 0.061814547 Test MSE 0.10734496674921579 Test RE 0.15660257656617305\n",
      "55 Train Loss 0.050865173 Test MSE 0.08636946143100578 Test RE 0.14047148254919184\n",
      "56 Train Loss 0.044045947 Test MSE 0.08031824133723968 Test RE 0.13546127392213872\n",
      "57 Train Loss 0.03691224 Test MSE 0.08306064675290162 Test RE 0.1377544745367241\n",
      "58 Train Loss 0.032579113 Test MSE 0.08271432594936796 Test RE 0.13746699138510263\n",
      "59 Train Loss 0.028419752 Test MSE 0.08151812757570484 Test RE 0.1364693610196307\n",
      "60 Train Loss 0.02482649 Test MSE 0.0713861246873358 Test RE 0.12770707660139938\n",
      "61 Train Loss 0.022377942 Test MSE 0.06699560928538142 Test RE 0.12371752716317888\n",
      "62 Train Loss 0.020750616 Test MSE 0.05932210689815269 Test RE 0.11641698399077438\n",
      "63 Train Loss 0.01902116 Test MSE 0.0531568694379989 Test RE 0.11020156405542705\n",
      "64 Train Loss 0.017524587 Test MSE 0.05274604294020529 Test RE 0.10977488789835141\n",
      "65 Train Loss 0.016963089 Test MSE 0.05174253514996524 Test RE 0.10872562477792411\n",
      "66 Train Loss 0.015797654 Test MSE 0.049039105974136306 Test RE 0.10584718982939038\n",
      "67 Train Loss 0.014836311 Test MSE 0.04624217261380173 Test RE 0.10278439301586721\n",
      "68 Train Loss 0.013843644 Test MSE 0.04252039580719046 Test RE 0.0985613650114451\n",
      "69 Train Loss 0.012917485 Test MSE 0.0399678835676359 Test RE 0.09555724849445206\n",
      "70 Train Loss 0.01239581 Test MSE 0.040643352990970966 Test RE 0.09636133870924166\n",
      "71 Train Loss 0.011687022 Test MSE 0.03870652030283348 Test RE 0.0940372944184035\n",
      "72 Train Loss 0.010779027 Test MSE 0.0351523640659278 Test RE 0.08961595330438774\n",
      "73 Train Loss 0.010181366 Test MSE 0.03363486891269995 Test RE 0.08766029543463759\n",
      "74 Train Loss 0.009582696 Test MSE 0.03114018196885593 Test RE 0.08434680438874453\n",
      "75 Train Loss 0.008980981 Test MSE 0.02953840990848246 Test RE 0.08214887433018768\n",
      "76 Train Loss 0.0084936125 Test MSE 0.030094132035598437 Test RE 0.08291802922006061\n",
      "77 Train Loss 0.007969104 Test MSE 0.029061525803471624 Test RE 0.08148304804626749\n",
      "78 Train Loss 0.007565303 Test MSE 0.027427620485626438 Test RE 0.07915933297777876\n",
      "79 Train Loss 0.0073238695 Test MSE 0.027030653063786308 Test RE 0.07858439780374736\n",
      "80 Train Loss 0.006878577 Test MSE 0.0276880622565488 Test RE 0.07953427776372321\n",
      "81 Train Loss 0.0063259522 Test MSE 0.02691582579194789 Test RE 0.07841730536276767\n",
      "82 Train Loss 0.005891597 Test MSE 0.026207837767586197 Test RE 0.07737909679628725\n",
      "83 Train Loss 0.0056684995 Test MSE 0.02611044148510645 Test RE 0.07723518085406275\n",
      "84 Train Loss 0.005431574 Test MSE 0.0253685245479489 Test RE 0.07612997107992435\n",
      "85 Train Loss 0.0052065225 Test MSE 0.023831763618197655 Test RE 0.07378807007963066\n",
      "86 Train Loss 0.0048675844 Test MSE 0.021938614038508143 Test RE 0.07079664122974877\n",
      "87 Train Loss 0.0047098324 Test MSE 0.02166839566351079 Test RE 0.07035928846957921\n",
      "88 Train Loss 0.004550248 Test MSE 0.021626923162321978 Test RE 0.07029192369366433\n",
      "89 Train Loss 0.0043702936 Test MSE 0.02132400027024636 Test RE 0.06979790702294097\n",
      "90 Train Loss 0.0041727847 Test MSE 0.020637737567407468 Test RE 0.06866558162841581\n",
      "91 Train Loss 0.0040107667 Test MSE 0.020000980878081432 Test RE 0.06759797833298112\n",
      "92 Train Loss 0.0038172216 Test MSE 0.019390594544827507 Test RE 0.06655851488055547\n",
      "93 Train Loss 0.0036929608 Test MSE 0.0189162918825087 Test RE 0.06573944959286827\n",
      "94 Train Loss 0.003546005 Test MSE 0.018690745819133436 Test RE 0.06534635623658235\n",
      "95 Train Loss 0.003448448 Test MSE 0.018945605689290216 Test RE 0.06579036674767678\n",
      "96 Train Loss 0.003362643 Test MSE 0.019292973603030776 Test RE 0.06639076078254554\n",
      "97 Train Loss 0.0032698382 Test MSE 0.019286716269504227 Test RE 0.06637999357704433\n",
      "98 Train Loss 0.0030728641 Test MSE 0.018853459983240506 Test RE 0.06563017949438144\n",
      "99 Train Loss 0.0029701455 Test MSE 0.018444401575444785 Test RE 0.0649142950101997\n",
      "Training time: 88.30\n",
      "1\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.49341 Test MSE 8.554428865739869 Test RE 1.3979884068093882\n",
      "1 Train Loss 54.734886 Test MSE 9.547145133017246 Test RE 1.476878685003032\n",
      "2 Train Loss 46.783714 Test MSE 8.621273225015093 Test RE 1.4034397233405642\n",
      "3 Train Loss 44.376297 Test MSE 8.43004072667223 Test RE 1.3877872611139428\n",
      "4 Train Loss 42.803303 Test MSE 8.326441009256595 Test RE 1.3792333981254412\n",
      "5 Train Loss 40.914047 Test MSE 8.460293176451385 Test RE 1.3902751711251078\n",
      "6 Train Loss 38.13973 Test MSE 8.723855909082074 Test RE 1.4117646468284235\n",
      "7 Train Loss 31.60377 Test MSE 8.89799043732415 Test RE 1.4257849547620125\n",
      "8 Train Loss 28.497606 Test MSE 8.663411265497187 Test RE 1.406865326045529\n",
      "9 Train Loss 26.350681 Test MSE 9.06998464705735 Test RE 1.4394988963362303\n",
      "10 Train Loss 24.374445 Test MSE 9.046788467019494 Test RE 1.4376569829693944\n",
      "11 Train Loss 23.274166 Test MSE 8.982651376000613 Test RE 1.4325517931931082\n",
      "12 Train Loss 21.293095 Test MSE 9.18481763196853 Test RE 1.448582816272431\n",
      "13 Train Loss 20.225325 Test MSE 9.13482848354049 Test RE 1.4446354205588603\n",
      "14 Train Loss 19.110853 Test MSE 8.992262512781057 Test RE 1.4333179795715285\n",
      "15 Train Loss 17.955183 Test MSE 8.93672516605756 Test RE 1.4288849479764143\n",
      "16 Train Loss 16.681738 Test MSE 8.895423011473305 Test RE 1.4255792419512583\n",
      "17 Train Loss 15.361864 Test MSE 8.365872010709976 Test RE 1.3824953151735264\n",
      "18 Train Loss 13.680573 Test MSE 8.419437389760011 Test RE 1.386914204477411\n",
      "19 Train Loss 11.871038 Test MSE 7.830839937776408 Test RE 1.3375568006529006\n",
      "20 Train Loss 10.182039 Test MSE 7.41778875836854 Test RE 1.3018030688561926\n",
      "21 Train Loss 8.9679165 Test MSE 7.176230118121332 Test RE 1.2804311724152744\n",
      "22 Train Loss 8.098892 Test MSE 6.808907979974531 Test RE 1.247230701296489\n",
      "23 Train Loss 7.2395005 Test MSE 6.552148096187659 Test RE 1.2234885597348046\n",
      "24 Train Loss 6.8249683 Test MSE 6.441219488960641 Test RE 1.2130874490728074\n",
      "25 Train Loss 5.9769645 Test MSE 6.081648146268598 Test RE 1.1787418568302697\n",
      "26 Train Loss 4.2642164 Test MSE 5.239127743677742 Test RE 1.094050966642649\n",
      "27 Train Loss 3.6463625 Test MSE 5.32405849865234 Test RE 1.102883068889228\n",
      "28 Train Loss 3.1647372 Test MSE 5.41102725812361 Test RE 1.1118544052876616\n",
      "29 Train Loss 2.8857028 Test MSE 5.421038974378373 Test RE 1.112882530449606\n",
      "30 Train Loss 2.6285372 Test MSE 5.620349702862343 Test RE 1.1331560701222636\n",
      "31 Train Loss 2.474787 Test MSE 5.737221697682671 Test RE 1.144877120430574\n",
      "32 Train Loss 2.32878 Test MSE 5.707693417836304 Test RE 1.1419270982323584\n",
      "33 Train Loss 2.1924646 Test MSE 5.779923167636405 Test RE 1.1491298152621507\n",
      "34 Train Loss 2.0770621 Test MSE 5.848090293831043 Test RE 1.1558862432223056\n",
      "35 Train Loss 2.0165539 Test MSE 5.808097843599239 Test RE 1.1519271708549024\n",
      "36 Train Loss 1.9576371 Test MSE 5.757619637391902 Test RE 1.1469105449060806\n",
      "37 Train Loss 1.8815459 Test MSE 5.745078374537728 Test RE 1.1456607621208565\n",
      "38 Train Loss 1.8049213 Test MSE 5.76661079791011 Test RE 1.14780570946576\n",
      "39 Train Loss 1.748163 Test MSE 5.7440825694039015 Test RE 1.145561468061222\n",
      "40 Train Loss 1.6738462 Test MSE 5.746185702530192 Test RE 1.1457711662811834\n",
      "41 Train Loss 1.6395316 Test MSE 5.771773539592704 Test RE 1.1483193992967642\n",
      "42 Train Loss 1.5940411 Test MSE 5.728839978801688 Test RE 1.1440405181475692\n",
      "43 Train Loss 1.5420754 Test MSE 5.740749007270565 Test RE 1.1452290081336771\n",
      "44 Train Loss 1.4898136 Test MSE 5.754725393725865 Test RE 1.1466222438330325\n",
      "45 Train Loss 1.4478899 Test MSE 5.737046818963038 Test RE 1.1448596715518973\n",
      "46 Train Loss 1.4184066 Test MSE 5.752438454320561 Test RE 1.146394386204112\n",
      "47 Train Loss 1.3828025 Test MSE 5.764122555676315 Test RE 1.1475580486736718\n",
      "48 Train Loss 1.3533716 Test MSE 5.759639727613768 Test RE 1.1471117269689712\n",
      "49 Train Loss 1.3315436 Test MSE 5.743079918669462 Test RE 1.145461482714494\n",
      "50 Train Loss 1.2925081 Test MSE 5.807806722131378 Test RE 1.151898301254199\n",
      "51 Train Loss 1.2669482 Test MSE 5.822782139980459 Test RE 1.1533824288814039\n",
      "52 Train Loss 1.2432185 Test MSE 5.787905942355434 Test RE 1.1499230852604576\n",
      "53 Train Loss 1.2242604 Test MSE 5.7980294435016155 Test RE 1.1509282987064562\n",
      "54 Train Loss 1.199386 Test MSE 5.810894719357886 Test RE 1.1522044913734093\n",
      "55 Train Loss 1.1873025 Test MSE 5.813346586634221 Test RE 1.1524475481387122\n",
      "56 Train Loss 1.1747314 Test MSE 5.814729441198254 Test RE 1.1525846096888492\n",
      "57 Train Loss 1.1640484 Test MSE 5.816499262525466 Test RE 1.1527600016524697\n",
      "58 Train Loss 1.1513057 Test MSE 5.8246586246539085 Test RE 1.1535682618780756\n",
      "59 Train Loss 1.1368666 Test MSE 5.864136104587165 Test RE 1.1574708995924892\n",
      "60 Train Loss 1.1292048 Test MSE 5.878080176366356 Test RE 1.1588462321090232\n",
      "61 Train Loss 1.1183375 Test MSE 5.886627305301228 Test RE 1.1596884467363666\n",
      "62 Train Loss 1.1003389 Test MSE 5.892512292658745 Test RE 1.16026798461377\n",
      "63 Train Loss 1.08517 Test MSE 5.882853839291948 Test RE 1.1593166934199253\n",
      "64 Train Loss 1.0719805 Test MSE 5.878026181694027 Test RE 1.1588409096513166\n",
      "65 Train Loss 1.057632 Test MSE 5.887752050351603 Test RE 1.1597992310168843\n",
      "66 Train Loss 1.0435673 Test MSE 5.918381009141849 Test RE 1.1628120415746224\n",
      "67 Train Loss 1.0320516 Test MSE 5.925056534681385 Test RE 1.1634676426456818\n",
      "68 Train Loss 1.0229976 Test MSE 5.946861169001467 Test RE 1.1656064989812032\n",
      "69 Train Loss 1.0125183 Test MSE 5.982479925064675 Test RE 1.1690919907898247\n",
      "70 Train Loss 1.0031759 Test MSE 5.965743620039518 Test RE 1.167455547040134\n",
      "71 Train Loss 0.9934361 Test MSE 5.953947324221806 Test RE 1.1663007483756143\n",
      "72 Train Loss 0.983124 Test MSE 5.961499638425606 Test RE 1.1670402139582834\n",
      "73 Train Loss 0.9746455 Test MSE 5.956144398507266 Test RE 1.1665159176485524\n",
      "74 Train Loss 0.9692507 Test MSE 5.949498985604787 Test RE 1.1658649811629862\n",
      "75 Train Loss 0.9622997 Test MSE 5.957098150927561 Test RE 1.1666093105190303\n",
      "76 Train Loss 0.9561823 Test MSE 5.958655719570844 Test RE 1.1667618139087266\n",
      "77 Train Loss 0.9491074 Test MSE 5.960685187778096 Test RE 1.1669604916416152\n",
      "78 Train Loss 0.9437492 Test MSE 5.966571783494107 Test RE 1.1675365772124429\n",
      "79 Train Loss 0.9372753 Test MSE 5.983889313039726 Test RE 1.1692296934801512\n",
      "80 Train Loss 0.93034446 Test MSE 6.003206898151277 Test RE 1.1711154648689506\n",
      "81 Train Loss 0.9232706 Test MSE 6.014892613789243 Test RE 1.1722547450168872\n",
      "82 Train Loss 0.91554296 Test MSE 6.0298583167076725 Test RE 1.1737121872636445\n",
      "83 Train Loss 0.9066234 Test MSE 6.043069000934385 Test RE 1.174997213948198\n",
      "84 Train Loss 0.8985171 Test MSE 6.055617347752789 Test RE 1.1762165138120113\n",
      "85 Train Loss 0.890625 Test MSE 6.051635493884374 Test RE 1.175829741318885\n",
      "86 Train Loss 0.8850075 Test MSE 6.057601227313323 Test RE 1.1764091680601874\n",
      "87 Train Loss 0.8806912 Test MSE 6.068118873105557 Test RE 1.1774300085200782\n",
      "88 Train Loss 0.87445533 Test MSE 6.0742442885019985 Test RE 1.1780241324062755\n",
      "89 Train Loss 0.8671848 Test MSE 6.076452878836853 Test RE 1.1782382772555655\n",
      "90 Train Loss 0.86142814 Test MSE 6.0775217640867165 Test RE 1.1783419023606443\n",
      "91 Train Loss 0.85506165 Test MSE 6.077592573178879 Test RE 1.1783487667603592\n",
      "92 Train Loss 0.85167 Test MSE 6.086265969858114 Test RE 1.179189283987162\n",
      "93 Train Loss 0.8477038 Test MSE 6.101363624567913 Test RE 1.1806509327086872\n",
      "94 Train Loss 0.84157676 Test MSE 6.097872567832776 Test RE 1.1803131140339949\n",
      "95 Train Loss 0.83429927 Test MSE 6.087541892291533 Test RE 1.1793128799015429\n",
      "96 Train Loss 0.82927984 Test MSE 6.108755789608124 Test RE 1.1813659306333275\n",
      "97 Train Loss 0.8262756 Test MSE 6.122100228087253 Test RE 1.1826555602672284\n",
      "98 Train Loss 0.82357466 Test MSE 6.135392211794903 Test RE 1.183938724098343\n",
      "99 Train Loss 0.82012373 Test MSE 6.1527153574170494 Test RE 1.1856089584988676\n",
      "Training time: 88.88\n",
      "2\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.071545 Test MSE 7.805854139267738 Test RE 1.3354212298988963\n",
      "1 Train Loss 42.46385 Test MSE 7.208272388678704 Test RE 1.2832865871211017\n",
      "2 Train Loss 33.126373 Test MSE 6.527598066551621 Test RE 1.221194283975311\n",
      "3 Train Loss 25.783512 Test MSE 5.8322029052417035 Test RE 1.1543150890296952\n",
      "4 Train Loss 20.818993 Test MSE 6.201430229567619 Test RE 1.1902933061198344\n",
      "5 Train Loss 16.37024 Test MSE 6.095548538455417 Test RE 1.1800881713402436\n",
      "6 Train Loss 14.283428 Test MSE 5.955699064779163 Test RE 1.1664723073397274\n",
      "7 Train Loss 12.395397 Test MSE 5.755160703849227 Test RE 1.146665610527137\n",
      "8 Train Loss 11.177064 Test MSE 6.016520663320514 Test RE 1.172413381237483\n",
      "9 Train Loss 9.987904 Test MSE 5.72430427724192 Test RE 1.1435875421640236\n",
      "10 Train Loss 9.2837715 Test MSE 5.856016192114013 Test RE 1.1566692624914565\n",
      "11 Train Loss 8.3813505 Test MSE 5.869094593938241 Test RE 1.1579601527668228\n",
      "12 Train Loss 7.749154 Test MSE 5.766021883220831 Test RE 1.1477470981839006\n",
      "13 Train Loss 7.1339526 Test MSE 5.533759928705907 Test RE 1.1243932179227834\n",
      "14 Train Loss 6.6795397 Test MSE 5.340185077894564 Test RE 1.1045521229876172\n",
      "15 Train Loss 6.4487267 Test MSE 5.244233995394565 Test RE 1.0945839884889879\n",
      "16 Train Loss 6.166498 Test MSE 5.091294278936642 Test RE 1.0785049938152105\n",
      "17 Train Loss 5.980506 Test MSE 5.039604738785205 Test RE 1.0730162475956193\n",
      "18 Train Loss 5.78888 Test MSE 4.937390317609803 Test RE 1.0620789241446928\n",
      "19 Train Loss 5.6688046 Test MSE 4.836086698319245 Test RE 1.051126776021349\n",
      "20 Train Loss 5.503587 Test MSE 4.698932293127779 Test RE 1.03611426720284\n",
      "21 Train Loss 5.188999 Test MSE 4.441833053472326 Test RE 1.0073703777375578\n",
      "22 Train Loss 4.929433 Test MSE 4.366919516419069 Test RE 0.9988393749059961\n",
      "23 Train Loss 4.498422 Test MSE 4.232268021258029 Test RE 0.9833194775616058\n",
      "24 Train Loss 3.929194 Test MSE 4.21531724535589 Test RE 0.9813483416454394\n",
      "25 Train Loss 3.4421084 Test MSE 3.9640414658680028 Test RE 0.9516497868563001\n",
      "26 Train Loss 2.9874408 Test MSE 3.765612975402859 Test RE 0.927525591564427\n",
      "27 Train Loss 2.6238637 Test MSE 3.6037926203876838 Test RE 0.9073773957744473\n",
      "28 Train Loss 2.4011848 Test MSE 3.5047269230839824 Test RE 0.8948189085947531\n",
      "29 Train Loss 2.217752 Test MSE 3.356486803238791 Test RE 0.875690286319215\n",
      "30 Train Loss 2.0509386 Test MSE 3.148079862168588 Test RE 0.8480684970503325\n",
      "31 Train Loss 1.9265516 Test MSE 3.020687429383317 Test RE 0.8307320277217535\n",
      "32 Train Loss 1.8114401 Test MSE 2.8683984320654856 Test RE 0.809520401868561\n",
      "33 Train Loss 1.7190999 Test MSE 2.7264794276079116 Test RE 0.7892401543363453\n",
      "34 Train Loss 1.6346595 Test MSE 2.60793265611296 Test RE 0.7718914786852538\n",
      "35 Train Loss 1.5353919 Test MSE 2.5024637571749895 Test RE 0.7561221463507982\n",
      "36 Train Loss 1.4671766 Test MSE 2.467403580694996 Test RE 0.7508067278466691\n",
      "37 Train Loss 1.4063821 Test MSE 2.3881050600990226 Test RE 0.7386433201745493\n",
      "38 Train Loss 1.3268062 Test MSE 2.21093467945626 Test RE 0.7107158749519197\n",
      "39 Train Loss 1.2471138 Test MSE 2.0174707074781586 Test RE 0.6789091769298434\n",
      "40 Train Loss 1.1351066 Test MSE 1.71120574591158 Test RE 0.6252578820722392\n",
      "41 Train Loss 1.0172385 Test MSE 1.3191883996409253 Test RE 0.5489862562375067\n",
      "42 Train Loss 0.90221 Test MSE 1.0838008064639586 Test RE 0.497602776790857\n",
      "43 Train Loss 0.7924745 Test MSE 0.8957587241846744 Test RE 0.45238019515293043\n",
      "44 Train Loss 0.6940179 Test MSE 0.7693475484606173 Test RE 0.4192464051350463\n",
      "45 Train Loss 0.51387596 Test MSE 0.5723433864933096 Test RE 0.36160663841709917\n",
      "46 Train Loss 0.4037059 Test MSE 0.48837020927101665 Test RE 0.3340278223832115\n",
      "47 Train Loss 0.35434666 Test MSE 0.47642087256546567 Test RE 0.32991605488776665\n",
      "48 Train Loss 0.27598798 Test MSE 0.41213444050234516 Test RE 0.30685097987554233\n",
      "49 Train Loss 0.22275941 Test MSE 0.4027748765329299 Test RE 0.3033466805157827\n",
      "50 Train Loss 0.1880983 Test MSE 0.43042486920672235 Test RE 0.31358605266074047\n",
      "51 Train Loss 0.16312903 Test MSE 0.42214402122921013 Test RE 0.3105548968918917\n",
      "52 Train Loss 0.14457078 Test MSE 0.389504029609314 Test RE 0.29830740749626383\n",
      "53 Train Loss 0.12640159 Test MSE 0.36701887420949164 Test RE 0.2895691288935825\n",
      "54 Train Loss 0.11574396 Test MSE 0.33940106609532744 Test RE 0.27846118140593007\n",
      "55 Train Loss 0.09984715 Test MSE 0.300626894550516 Test RE 0.26207281620578093\n",
      "56 Train Loss 0.088810265 Test MSE 0.2856607578507998 Test RE 0.25546614369500625\n",
      "57 Train Loss 0.08017762 Test MSE 0.2772879888519825 Test RE 0.25169442101571726\n",
      "58 Train Loss 0.07439634 Test MSE 0.2650743879849344 Test RE 0.24608885407481057\n",
      "59 Train Loss 0.065638125 Test MSE 0.2420547549611973 Test RE 0.23516076779631703\n",
      "60 Train Loss 0.058768522 Test MSE 0.2323216722507785 Test RE 0.23038432277306345\n",
      "61 Train Loss 0.054019146 Test MSE 0.21565716244043753 Test RE 0.2219678132632957\n",
      "62 Train Loss 0.049520276 Test MSE 0.19272762688262213 Test RE 0.2098360233243325\n",
      "63 Train Loss 0.04648824 Test MSE 0.19320443422659098 Test RE 0.2100954297035244\n",
      "64 Train Loss 0.042840805 Test MSE 0.17710184896897696 Test RE 0.2011498013152864\n",
      "65 Train Loss 0.039565656 Test MSE 0.1626018776139605 Test RE 0.19273954898472356\n",
      "66 Train Loss 0.037358787 Test MSE 0.1615448341828187 Test RE 0.19211204619454475\n",
      "67 Train Loss 0.03351953 Test MSE 0.14916010357786122 Test RE 0.18460114839047315\n",
      "68 Train Loss 0.029654602 Test MSE 0.1364332330720263 Test RE 0.17655017227064365\n",
      "69 Train Loss 0.026876876 Test MSE 0.12358798015953798 Test RE 0.16803361763487235\n",
      "70 Train Loss 0.02458266 Test MSE 0.1084541979960148 Test RE 0.15740961034385773\n",
      "71 Train Loss 0.02237717 Test MSE 0.09305624932727706 Test RE 0.1458078252200013\n",
      "72 Train Loss 0.020894188 Test MSE 0.08916132656478938 Test RE 0.14272377396148933\n",
      "73 Train Loss 0.019585576 Test MSE 0.08720201897918968 Test RE 0.14114689550999043\n",
      "74 Train Loss 0.018046785 Test MSE 0.08442758315318716 Test RE 0.13888336769411214\n",
      "75 Train Loss 0.017110465 Test MSE 0.07971413003838528 Test RE 0.13495087837802758\n",
      "76 Train Loss 0.015911534 Test MSE 0.07188680930546941 Test RE 0.1281541469816035\n",
      "77 Train Loss 0.014959917 Test MSE 0.06740785354408156 Test RE 0.12409757910866584\n",
      "78 Train Loss 0.014195865 Test MSE 0.06338280150369806 Test RE 0.12033550247973922\n",
      "79 Train Loss 0.013659195 Test MSE 0.061579011953417966 Test RE 0.11861085006151857\n",
      "80 Train Loss 0.012825785 Test MSE 0.05954345826020738 Test RE 0.11663397783791045\n",
      "81 Train Loss 0.01208934 Test MSE 0.05546038947229432 Test RE 0.11256400008456639\n",
      "82 Train Loss 0.011207572 Test MSE 0.0533001843143372 Test RE 0.11035001987015929\n",
      "83 Train Loss 0.010673209 Test MSE 0.05304697833559039 Test RE 0.11008759537366423\n",
      "84 Train Loss 0.010169654 Test MSE 0.050376974354062354 Test RE 0.10728131799648291\n",
      "85 Train Loss 0.0094785355 Test MSE 0.04684107427420721 Test RE 0.10344785350574794\n",
      "86 Train Loss 0.009032426 Test MSE 0.04503721091239562 Test RE 0.10143639448934468\n",
      "87 Train Loss 0.008594566 Test MSE 0.04145910886003505 Test RE 0.09732357235630582\n",
      "88 Train Loss 0.0083018765 Test MSE 0.03992495719454696 Test RE 0.09550591943077376\n",
      "89 Train Loss 0.0080290325 Test MSE 0.03886183308304547 Test RE 0.09422577134349291\n",
      "90 Train Loss 0.0077011795 Test MSE 0.037594710978948696 Test RE 0.092676886571219\n",
      "91 Train Loss 0.0072237635 Test MSE 0.03526685203163865 Test RE 0.08976177006685344\n",
      "92 Train Loss 0.00691371 Test MSE 0.0331192851069675 Test RE 0.08698583508918352\n",
      "93 Train Loss 0.006625197 Test MSE 0.03148583400790275 Test RE 0.08481363190538999\n",
      "94 Train Loss 0.006394891 Test MSE 0.030844902756980846 Test RE 0.08394595283821665\n",
      "95 Train Loss 0.0061716037 Test MSE 0.029838524888318063 Test RE 0.08256514253044951\n",
      "96 Train Loss 0.006013979 Test MSE 0.029129652829891682 Test RE 0.08157849981788409\n",
      "97 Train Loss 0.00578366 Test MSE 0.02870299692442153 Test RE 0.08097886446080578\n",
      "98 Train Loss 0.0055584097 Test MSE 0.02863194069157059 Test RE 0.08087856798972556\n",
      "99 Train Loss 0.0053741965 Test MSE 0.028423151389718487 Test RE 0.08058313783207624\n",
      "Training time: 88.49\n",
      "3\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.422085 Test MSE 7.839040897882118 Test RE 1.3382570052047078\n",
      "1 Train Loss 45.15903 Test MSE 8.44587436158638 Test RE 1.3890899480905656\n",
      "2 Train Loss 39.9384 Test MSE 8.514797606305208 Test RE 1.3947463224674017\n",
      "3 Train Loss 35.49461 Test MSE 8.652222622435218 Test RE 1.4059565616425926\n",
      "4 Train Loss 32.733864 Test MSE 8.989665818005543 Test RE 1.433111015082051\n",
      "5 Train Loss 30.22411 Test MSE 9.05199260464378 Test RE 1.4380704274290996\n",
      "6 Train Loss 27.8679 Test MSE 8.842838359309427 Test RE 1.42135939188897\n",
      "7 Train Loss 26.197567 Test MSE 8.644521481694042 Test RE 1.4053307178437306\n",
      "8 Train Loss 24.872227 Test MSE 8.535111102851207 Test RE 1.3964090335637354\n",
      "9 Train Loss 23.63302 Test MSE 8.267581631719917 Test RE 1.3743498713722613\n",
      "10 Train Loss 21.916658 Test MSE 8.042730314556191 Test RE 1.3555321218840086\n",
      "11 Train Loss 20.764755 Test MSE 8.134354026869305 Test RE 1.3632314453041599\n",
      "12 Train Loss 19.459356 Test MSE 7.691659261633986 Test RE 1.3256170420613134\n",
      "13 Train Loss 18.775175 Test MSE 7.908030534900987 Test RE 1.3441329548531173\n",
      "14 Train Loss 18.257736 Test MSE 7.908385263737878 Test RE 1.344163101257507\n",
      "15 Train Loss 17.826454 Test MSE 7.908308858650333 Test RE 1.344156608076911\n",
      "16 Train Loss 17.206266 Test MSE 8.32439552623228 Test RE 1.379063975692418\n",
      "17 Train Loss 16.684807 Test MSE 8.604837107564684 Test RE 1.4021012838695777\n",
      "18 Train Loss 16.136162 Test MSE 8.5771628736989 Test RE 1.3998448014571985\n",
      "19 Train Loss 15.595951 Test MSE 8.517875405835408 Test RE 1.3949983755357858\n",
      "20 Train Loss 15.066416 Test MSE 8.44078223474008 Test RE 1.388671134809686\n",
      "21 Train Loss 14.59091 Test MSE 8.437767697167336 Test RE 1.3884231379400265\n",
      "22 Train Loss 14.092197 Test MSE 8.41477563623575 Test RE 1.3865301914435098\n",
      "23 Train Loss 13.675528 Test MSE 8.45233422841813 Test RE 1.3896210725502216\n",
      "24 Train Loss 13.373799 Test MSE 8.469335236952277 Test RE 1.3910179110571121\n",
      "25 Train Loss 13.031436 Test MSE 8.418638747821662 Test RE 1.3868484237093155\n",
      "26 Train Loss 12.7652855 Test MSE 8.494382046728228 Test RE 1.3930732577344465\n",
      "27 Train Loss 12.463253 Test MSE 8.442007440610492 Test RE 1.3887719161260632\n",
      "28 Train Loss 11.909001 Test MSE 8.470434557742541 Test RE 1.3911081852786376\n",
      "29 Train Loss 10.526126 Test MSE 7.597839038618657 Test RE 1.3175075257806859\n",
      "30 Train Loss 8.792702 Test MSE 7.168020071695069 Test RE 1.2796985169940924\n",
      "31 Train Loss 8.1587715 Test MSE 7.076291046588448 Test RE 1.2714840126009619\n",
      "32 Train Loss 7.838314 Test MSE 7.034068130250027 Test RE 1.2676849824452352\n",
      "33 Train Loss 7.5751014 Test MSE 6.935776948606718 Test RE 1.2587967682690904\n",
      "34 Train Loss 7.311102 Test MSE 6.961521335583154 Test RE 1.261130820735036\n",
      "35 Train Loss 7.0677853 Test MSE 6.769806071518328 Test RE 1.2436442730541175\n",
      "36 Train Loss 6.711919 Test MSE 6.626335422281086 Test RE 1.2303955967306814\n",
      "37 Train Loss 6.485964 Test MSE 6.706054230365066 Test RE 1.237774669635061\n",
      "38 Train Loss 6.141596 Test MSE 6.46914935976283 Test RE 1.2157146477583987\n",
      "39 Train Loss 5.924267 Test MSE 6.394022199190619 Test RE 1.2086348987995708\n",
      "40 Train Loss 5.585451 Test MSE 6.218480955157866 Test RE 1.191928528358118\n",
      "41 Train Loss 4.4954896 Test MSE 5.318950161801695 Test RE 1.1023538438367142\n",
      "42 Train Loss 3.6865687 Test MSE 5.155091479319872 Test RE 1.0852411389668544\n",
      "43 Train Loss 3.213917 Test MSE 5.277713839391173 Test RE 1.098072410078107\n",
      "44 Train Loss 3.0029962 Test MSE 5.31808635532471 Test RE 1.1022643281404814\n",
      "45 Train Loss 2.8578017 Test MSE 5.419658371418177 Test RE 1.1127408097610638\n",
      "46 Train Loss 2.7493072 Test MSE 5.422323606224491 Test RE 1.1130143833711714\n",
      "47 Train Loss 2.6476593 Test MSE 5.419755558472337 Test RE 1.1127507867290867\n",
      "48 Train Loss 2.575079 Test MSE 5.41828757531566 Test RE 1.1126000778990135\n",
      "49 Train Loss 2.484986 Test MSE 5.371456165544952 Test RE 1.107781423805551\n",
      "50 Train Loss 2.3769696 Test MSE 5.350006027829444 Test RE 1.105567328274692\n",
      "51 Train Loss 2.299221 Test MSE 5.354299267626692 Test RE 1.1060108337381316\n",
      "52 Train Loss 2.236973 Test MSE 5.272235233894561 Test RE 1.097502327296105\n",
      "53 Train Loss 2.173156 Test MSE 5.231162504980907 Test RE 1.0932189873285731\n",
      "54 Train Loss 2.131294 Test MSE 5.289663316141991 Test RE 1.0993148014209966\n",
      "55 Train Loss 2.0788777 Test MSE 5.288868936324949 Test RE 1.0992322530405758\n",
      "56 Train Loss 2.0257237 Test MSE 5.2755930854597155 Test RE 1.0978517676333626\n",
      "57 Train Loss 1.993612 Test MSE 5.28991256706071 Test RE 1.099340701178704\n",
      "58 Train Loss 1.9445972 Test MSE 5.275424797428589 Test RE 1.0978342571105768\n",
      "59 Train Loss 1.9096928 Test MSE 5.248990482223682 Test RE 1.0950802663369208\n",
      "60 Train Loss 1.8799725 Test MSE 5.297224360491891 Test RE 1.100100201106271\n",
      "61 Train Loss 1.8510232 Test MSE 5.322587328632667 Test RE 1.1027306813254631\n",
      "62 Train Loss 1.825216 Test MSE 5.337701909855013 Test RE 1.1042952866223217\n",
      "63 Train Loss 1.8041291 Test MSE 5.342984128816427 Test RE 1.1048415598303336\n",
      "64 Train Loss 1.7806222 Test MSE 5.32776579424481 Test RE 1.1032669867234082\n",
      "65 Train Loss 1.7571996 Test MSE 5.3191501947346 Test RE 1.1023745720812577\n",
      "66 Train Loss 1.7322211 Test MSE 5.3085875230619735 Test RE 1.1012794904792724\n",
      "67 Train Loss 1.6998008 Test MSE 5.311048097488417 Test RE 1.1015346870085012\n",
      "68 Train Loss 1.6696272 Test MSE 5.346765320254552 Test RE 1.1052324349003109\n",
      "69 Train Loss 1.6425984 Test MSE 5.320811448627735 Test RE 1.1025467030624343\n",
      "70 Train Loss 1.6244546 Test MSE 5.309693012741164 Test RE 1.1013941527815934\n",
      "71 Train Loss 1.6072154 Test MSE 5.318908927967637 Test RE 1.1023495709668636\n",
      "72 Train Loss 1.5877162 Test MSE 5.309805143937219 Test RE 1.1014057824550378\n",
      "73 Train Loss 1.571327 Test MSE 5.305924134695787 Test RE 1.1010031925977206\n",
      "74 Train Loss 1.5445365 Test MSE 5.354204951350156 Test RE 1.1060010924743533\n",
      "75 Train Loss 1.5222839 Test MSE 5.379206368387894 Test RE 1.1085803166756238\n",
      "76 Train Loss 1.5055741 Test MSE 5.404097484306405 Test RE 1.1111422144567984\n",
      "77 Train Loss 1.4883015 Test MSE 5.415422971800817 Test RE 1.1123059278177532\n",
      "78 Train Loss 1.4719303 Test MSE 5.420269127798986 Test RE 1.112803506923631\n",
      "79 Train Loss 1.4491229 Test MSE 5.4401762172460595 Test RE 1.1148451376608874\n",
      "80 Train Loss 1.4360244 Test MSE 5.460972587664312 Test RE 1.1169739857418166\n",
      "81 Train Loss 1.4172083 Test MSE 5.457912217276286 Test RE 1.116660961540779\n",
      "82 Train Loss 1.4007375 Test MSE 5.446708986034486 Test RE 1.1155143108739733\n",
      "83 Train Loss 1.3872564 Test MSE 5.429152211399501 Test RE 1.1137150003911127\n",
      "84 Train Loss 1.3774887 Test MSE 5.425176288470822 Test RE 1.1133071230811298\n",
      "85 Train Loss 1.367544 Test MSE 5.424008945285628 Test RE 1.1131873406693333\n",
      "86 Train Loss 1.3562323 Test MSE 5.423923395001198 Test RE 1.1131785617504473\n",
      "87 Train Loss 1.3470805 Test MSE 5.434645801841673 Test RE 1.1142783247277597\n",
      "88 Train Loss 1.3369657 Test MSE 5.459419284945441 Test RE 1.116815120073374\n",
      "89 Train Loss 1.3305925 Test MSE 5.463929599813754 Test RE 1.1172763548344458\n",
      "90 Train Loss 1.3228972 Test MSE 5.477666922055889 Test RE 1.1186799920870238\n",
      "91 Train Loss 1.3167473 Test MSE 5.4947001493838385 Test RE 1.1204179528677374\n",
      "92 Train Loss 1.3074607 Test MSE 5.490766680418853 Test RE 1.1200168465164804\n",
      "93 Train Loss 1.2914234 Test MSE 5.484248658909414 Test RE 1.119351870008583\n",
      "94 Train Loss 1.2791089 Test MSE 5.495490702578796 Test RE 1.1204985503626954\n",
      "95 Train Loss 1.2729427 Test MSE 5.499598006770299 Test RE 1.1209171998556784\n",
      "96 Train Loss 1.2641739 Test MSE 5.5193144628899224 Test RE 1.1229246867846492\n",
      "97 Train Loss 1.2567939 Test MSE 5.529315903666065 Test RE 1.1239416411205445\n",
      "98 Train Loss 1.2505647 Test MSE 5.521718207589318 Test RE 1.1231691854862167\n",
      "99 Train Loss 1.2465689 Test MSE 5.527276199741946 Test RE 1.1237343171337177\n",
      "Training time: 89.47\n",
      "4\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.93528 Test MSE 8.239209383870142 Test RE 1.3719896342247277\n",
      "1 Train Loss 55.606033 Test MSE 8.110105922122385 Test RE 1.3611980662574383\n",
      "2 Train Loss 50.021507 Test MSE 8.12486562425085 Test RE 1.3624361354993986\n",
      "3 Train Loss 41.773598 Test MSE 7.718415116323523 Test RE 1.3279206559449004\n",
      "4 Train Loss 33.559566 Test MSE 6.895855170703752 Test RE 1.2551687733166765\n",
      "5 Train Loss 30.69857 Test MSE 5.863216936425812 Test RE 1.1573801827270138\n",
      "6 Train Loss 29.195951 Test MSE 5.4122440724213465 Test RE 1.1119794133703493\n",
      "7 Train Loss 22.813698 Test MSE 3.806124783192475 Test RE 0.9325015696375366\n",
      "8 Train Loss 18.864666 Test MSE 3.6102187060919007 Test RE 0.9081860283057092\n",
      "9 Train Loss 15.692922 Test MSE 3.913467905323743 Test RE 0.945559687664637\n",
      "10 Train Loss 13.61737 Test MSE 3.603352486550226 Test RE 0.9073219847489247\n",
      "11 Train Loss 11.879039 Test MSE 3.9157200827897984 Test RE 0.9458317305141704\n",
      "12 Train Loss 10.366487 Test MSE 3.983633297405107 Test RE 0.9539985995585498\n",
      "13 Train Loss 9.645058 Test MSE 3.973718619465631 Test RE 0.9528106787890659\n",
      "14 Train Loss 9.064773 Test MSE 3.8816959296411313 Test RE 0.9417135434712184\n",
      "15 Train Loss 8.704838 Test MSE 3.786612210820896 Test RE 0.9301082055532004\n",
      "16 Train Loss 8.54844 Test MSE 3.7798055409145963 Test RE 0.9292718659964115\n",
      "17 Train Loss 8.290464 Test MSE 3.7209465239720965 Test RE 0.922008180956778\n",
      "18 Train Loss 8.076856 Test MSE 3.628151101992554 Test RE 0.9104387696533114\n",
      "19 Train Loss 7.745698 Test MSE 3.449784832947608 Test RE 0.8877773579855006\n",
      "20 Train Loss 7.2743177 Test MSE 2.995991016361652 Test RE 0.8273291256135045\n",
      "21 Train Loss 6.285734 Test MSE 2.557934534725868 Test RE 0.7644564916397232\n",
      "22 Train Loss 5.6731496 Test MSE 2.6092729205871774 Test RE 0.7720897978100668\n",
      "23 Train Loss 5.1661377 Test MSE 2.5163824413873885 Test RE 0.7582220033400681\n",
      "24 Train Loss 4.3850384 Test MSE 2.074005170441452 Test RE 0.6883558024925319\n",
      "25 Train Loss 3.50034 Test MSE 1.9420010832060137 Test RE 0.6660898167762507\n",
      "26 Train Loss 2.6927135 Test MSE 1.7844203234288796 Test RE 0.638493735726766\n",
      "27 Train Loss 2.2370856 Test MSE 1.5619695898909471 Test RE 0.5973712915158679\n",
      "28 Train Loss 1.7583804 Test MSE 1.2438202099367832 Test RE 0.5330732192578528\n",
      "29 Train Loss 1.5043261 Test MSE 0.9805312476135524 Test RE 0.47330247931250863\n",
      "30 Train Loss 1.2172725 Test MSE 0.8087719557189009 Test RE 0.4298541283508995\n",
      "31 Train Loss 0.9279027 Test MSE 0.5968788919296008 Test RE 0.36927607462597567\n",
      "32 Train Loss 0.800527 Test MSE 0.45686302970566506 Test RE 0.32307330019090413\n",
      "33 Train Loss 0.59324527 Test MSE 0.3200960312600442 Test RE 0.27042585099402194\n",
      "34 Train Loss 0.48075455 Test MSE 0.3224252790984553 Test RE 0.2714079736029282\n",
      "35 Train Loss 0.40421256 Test MSE 0.2546350939433275 Test RE 0.24119438285009145\n",
      "36 Train Loss 0.34005734 Test MSE 0.24493091045846901 Test RE 0.2365537617434645\n",
      "37 Train Loss 0.29140553 Test MSE 0.21555098968113937 Test RE 0.22191316672086916\n",
      "38 Train Loss 0.23662442 Test MSE 0.18555438606975627 Test RE 0.2058939912753873\n",
      "39 Train Loss 0.20192 Test MSE 0.18212967805502764 Test RE 0.2039850880194763\n",
      "40 Train Loss 0.17338303 Test MSE 0.1847514808497384 Test RE 0.20544805037878625\n",
      "41 Train Loss 0.15370296 Test MSE 0.17764748259716237 Test RE 0.20145942453796586\n",
      "42 Train Loss 0.12963447 Test MSE 0.17811493019580377 Test RE 0.20172430264150842\n",
      "43 Train Loss 0.11129905 Test MSE 0.15757727814690967 Test RE 0.18973823554192384\n",
      "44 Train Loss 0.09639887 Test MSE 0.12957301784732644 Test RE 0.17205422718685673\n",
      "45 Train Loss 0.08796424 Test MSE 0.1214816221440672 Test RE 0.1665955326904941\n",
      "46 Train Loss 0.073396936 Test MSE 0.09246772411297052 Test RE 0.14534602018433046\n",
      "47 Train Loss 0.06413494 Test MSE 0.07697046971947856 Test RE 0.13260812325645435\n",
      "48 Train Loss 0.059276693 Test MSE 0.07288653962119303 Test RE 0.12904219040562026\n",
      "49 Train Loss 0.052929755 Test MSE 0.05710292928645351 Test RE 0.11421871081616655\n",
      "50 Train Loss 0.047963157 Test MSE 0.05286996745299472 Test RE 0.10990376788376605\n",
      "51 Train Loss 0.04433476 Test MSE 0.05429048541453927 Test RE 0.11137043671172467\n",
      "52 Train Loss 0.04074261 Test MSE 0.050530526599231754 Test RE 0.1074446937613051\n",
      "53 Train Loss 0.03704187 Test MSE 0.04902546190311018 Test RE 0.10583246395893807\n",
      "54 Train Loss 0.03472334 Test MSE 0.04585844291903381 Test RE 0.10235703864844341\n",
      "55 Train Loss 0.032260854 Test MSE 0.03867446134590253 Test RE 0.09399834281475505\n",
      "56 Train Loss 0.029706499 Test MSE 0.03317630413591937 Test RE 0.0870606814350208\n",
      "57 Train Loss 0.027770894 Test MSE 0.030408566348457414 Test RE 0.08335008228384166\n",
      "58 Train Loss 0.025874523 Test MSE 0.025570255668785277 Test RE 0.07643206538956931\n",
      "59 Train Loss 0.023769358 Test MSE 0.021554697493600915 Test RE 0.07017445143558278\n",
      "60 Train Loss 0.021148061 Test MSE 0.01746080062321789 Test RE 0.06315971141025553\n",
      "61 Train Loss 0.019792037 Test MSE 0.014740845235639463 Test RE 0.05803222920764667\n",
      "62 Train Loss 0.018256454 Test MSE 0.014907171223365911 Test RE 0.058358709567645155\n",
      "63 Train Loss 0.017378123 Test MSE 0.01538263837199037 Test RE 0.05928208578413626\n",
      "64 Train Loss 0.016213352 Test MSE 0.013916460052615466 Test RE 0.056386150856255826\n",
      "65 Train Loss 0.015001862 Test MSE 0.011954470265194533 Test RE 0.052260460029180694\n",
      "66 Train Loss 0.014050425 Test MSE 0.012602841060196759 Test RE 0.053658964796644094\n",
      "67 Train Loss 0.013033372 Test MSE 0.013212218203667024 Test RE 0.054940920196087116\n",
      "68 Train Loss 0.012348845 Test MSE 0.011664691307578086 Test RE 0.05162317188126705\n",
      "69 Train Loss 0.01155524 Test MSE 0.011071845086147593 Test RE 0.05029421808033375\n",
      "70 Train Loss 0.011071803 Test MSE 0.010898006240981027 Test RE 0.04989782165387248\n",
      "71 Train Loss 0.010723805 Test MSE 0.010478160679371561 Test RE 0.048927225295276724\n",
      "72 Train Loss 0.010242992 Test MSE 0.010977032642779872 Test RE 0.05007841076582955\n",
      "73 Train Loss 0.009818323 Test MSE 0.011507422799254804 Test RE 0.051273987747944165\n",
      "74 Train Loss 0.0095499465 Test MSE 0.010930238785595197 Test RE 0.04997155744821471\n",
      "75 Train Loss 0.008910849 Test MSE 0.009365723398886725 Test RE 0.046257134294788824\n",
      "76 Train Loss 0.008340616 Test MSE 0.009420010965864029 Test RE 0.04639100322890403\n",
      "77 Train Loss 0.0078231925 Test MSE 0.009766470040068117 Test RE 0.047236408677536916\n",
      "78 Train Loss 0.007489098 Test MSE 0.00934681132014914 Test RE 0.04621040749097139\n",
      "79 Train Loss 0.007151234 Test MSE 0.009164055987366472 Test RE 0.0457564083523888\n",
      "80 Train Loss 0.0066882055 Test MSE 0.008534551972179474 Test RE 0.04415688449466986\n",
      "81 Train Loss 0.0063110148 Test MSE 0.007576128838200746 Test RE 0.041603678925905115\n",
      "82 Train Loss 0.0060498836 Test MSE 0.00714464785398958 Test RE 0.04040159160736053\n",
      "83 Train Loss 0.0058982866 Test MSE 0.007220090354454014 Test RE 0.04061433779005271\n",
      "84 Train Loss 0.0057660807 Test MSE 0.007144213576734946 Test RE 0.04040036371206939\n",
      "85 Train Loss 0.0055810935 Test MSE 0.006850142415361393 Test RE 0.03956014371040678\n",
      "86 Train Loss 0.0053609842 Test MSE 0.006502778591691823 Test RE 0.03854406756333689\n",
      "87 Train Loss 0.0052338913 Test MSE 0.00659105996695303 Test RE 0.03880482165340663\n",
      "88 Train Loss 0.0050801965 Test MSE 0.006974170631479455 Test RE 0.039916673768340065\n",
      "89 Train Loss 0.0049128495 Test MSE 0.007040690450526692 Test RE 0.040106585129239064\n",
      "90 Train Loss 0.0047517386 Test MSE 0.006590618516067851 Test RE 0.03880352211207332\n",
      "91 Train Loss 0.0046912506 Test MSE 0.006427750503378292 Test RE 0.03832106460560845\n",
      "92 Train Loss 0.0045117596 Test MSE 0.006396356687848851 Test RE 0.038227367986558396\n",
      "93 Train Loss 0.0043648286 Test MSE 0.006600666954273742 Test RE 0.03883309189256452\n",
      "94 Train Loss 0.0043220688 Test MSE 0.006647310551855191 Test RE 0.03897005732852047\n",
      "95 Train Loss 0.004240645 Test MSE 0.006698401939262719 Test RE 0.03911953305473923\n",
      "96 Train Loss 0.0040631327 Test MSE 0.0066449133200265475 Test RE 0.03896302977315334\n",
      "97 Train Loss 0.003878072 Test MSE 0.006332952698020964 Test RE 0.03803743142316337\n",
      "98 Train Loss 0.0037389603 Test MSE 0.006041908606987206 Test RE 0.037153106808905885\n",
      "99 Train Loss 0.0035005158 Test MSE 0.0057219960946968814 Test RE 0.0361561216391662\n",
      "Training time: 88.41\n",
      "5\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.343304 Test MSE 8.292814582365502 Test RE 1.3764455556975854\n",
      "1 Train Loss 52.96349 Test MSE 7.7848701648215215 Test RE 1.3336250585541651\n",
      "2 Train Loss 46.819527 Test MSE 8.147612129900194 Test RE 1.364341951700256\n",
      "3 Train Loss 45.03875 Test MSE 8.420500559261104 Test RE 1.3870017684242864\n",
      "4 Train Loss 42.767124 Test MSE 8.751467143978962 Test RE 1.4139970180856103\n",
      "5 Train Loss 41.883163 Test MSE 8.910134989234644 Test RE 1.426757624670577\n",
      "6 Train Loss 40.789635 Test MSE 8.980893150842341 Test RE 1.4324115855994835\n",
      "7 Train Loss 39.606735 Test MSE 8.855916564536583 Test RE 1.4224100704786342\n",
      "8 Train Loss 38.44763 Test MSE 9.259419456935062 Test RE 1.4544538294361875\n",
      "9 Train Loss 37.507362 Test MSE 8.590049904622687 Test RE 1.4008960273964879\n",
      "10 Train Loss 36.24951 Test MSE 8.76758616356194 Test RE 1.4152986147119357\n",
      "11 Train Loss 33.735558 Test MSE 9.238817605423202 Test RE 1.4528348765437042\n",
      "12 Train Loss 31.14426 Test MSE 9.636825707777236 Test RE 1.483798960417988\n",
      "13 Train Loss 27.406433 Test MSE 9.548883856058978 Test RE 1.477013163219232\n",
      "14 Train Loss 23.461132 Test MSE 9.608880921120816 Test RE 1.4816460446201103\n",
      "15 Train Loss 21.255577 Test MSE 9.6648918771659 Test RE 1.4859580881759096\n",
      "16 Train Loss 19.033737 Test MSE 9.522864985882054 Test RE 1.474999502314803\n",
      "17 Train Loss 17.905241 Test MSE 9.559199542904526 Test RE 1.477810758662123\n",
      "18 Train Loss 16.661694 Test MSE 9.465874358118045 Test RE 1.4705792310126036\n",
      "19 Train Loss 15.808087 Test MSE 9.278655841245694 Test RE 1.455963854809612\n",
      "20 Train Loss 14.754093 Test MSE 8.900661249106696 Test RE 1.425998919790108\n",
      "21 Train Loss 13.782389 Test MSE 8.585692900004757 Test RE 1.4005407043949603\n",
      "22 Train Loss 12.568581 Test MSE 8.642224823551519 Test RE 1.4051440227996788\n",
      "23 Train Loss 11.229633 Test MSE 8.41452194633672 Test RE 1.3865092906274534\n",
      "24 Train Loss 9.769208 Test MSE 7.911691112938427 Test RE 1.3444440142432845\n",
      "25 Train Loss 8.682179 Test MSE 7.817784081944835 Test RE 1.3364413243003292\n",
      "26 Train Loss 8.055644 Test MSE 7.668390691217269 Test RE 1.3236104154162422\n",
      "27 Train Loss 6.882483 Test MSE 7.361544893276897 Test RE 1.296858350274563\n",
      "28 Train Loss 5.7981668 Test MSE 7.143487343835969 Test RE 1.2775067399536493\n",
      "29 Train Loss 4.995272 Test MSE 7.045201006251169 Test RE 1.2686877734112898\n",
      "30 Train Loss 4.3359766 Test MSE 6.992194305525195 Test RE 1.2639060842075494\n",
      "31 Train Loss 4.0320272 Test MSE 7.192501207468399 Test RE 1.2818819490411009\n",
      "32 Train Loss 3.8076322 Test MSE 7.292556464416884 Test RE 1.2907673176657029\n",
      "33 Train Loss 3.652453 Test MSE 7.439469299337223 Test RE 1.303704120692946\n",
      "34 Train Loss 3.482712 Test MSE 7.414301235839428 Test RE 1.3014970072089682\n",
      "35 Train Loss 3.3300235 Test MSE 7.42605446308871 Test RE 1.3025281719975408\n",
      "36 Train Loss 3.2418437 Test MSE 7.4477029761277596 Test RE 1.3044253623241935\n",
      "37 Train Loss 3.1249738 Test MSE 7.366870247455045 Test RE 1.2973273402482108\n",
      "38 Train Loss 3.0432372 Test MSE 7.35860615835981 Test RE 1.296599470963323\n",
      "39 Train Loss 2.9618123 Test MSE 7.320319981518591 Test RE 1.2932220259272322\n",
      "40 Train Loss 2.816119 Test MSE 7.222436008500666 Test RE 1.2845467409119764\n",
      "41 Train Loss 2.7362242 Test MSE 7.168847341526996 Test RE 1.2797723606373201\n",
      "42 Train Loss 2.644001 Test MSE 7.139476582084252 Test RE 1.2771480569798805\n",
      "43 Train Loss 2.5432904 Test MSE 7.111348254474777 Test RE 1.2746297006220915\n",
      "44 Train Loss 2.4338002 Test MSE 7.165933812940776 Test RE 1.2795122747335979\n",
      "45 Train Loss 2.3772576 Test MSE 7.129808349149015 Test RE 1.2762830112083638\n",
      "46 Train Loss 2.2949152 Test MSE 7.034766025144994 Test RE 1.2677478684535823\n",
      "47 Train Loss 2.231553 Test MSE 7.145877804692037 Test RE 1.277720471305817\n",
      "48 Train Loss 2.1828737 Test MSE 7.1100665114588155 Test RE 1.2745148263900057\n",
      "49 Train Loss 2.1124947 Test MSE 7.016723977542558 Test RE 1.266121129797451\n",
      "50 Train Loss 2.066397 Test MSE 6.984943861146945 Test RE 1.2632506206163057\n",
      "51 Train Loss 2.0158644 Test MSE 6.91913884108901 Test RE 1.257286009506342\n",
      "52 Train Loss 1.9783319 Test MSE 6.897001331354476 Test RE 1.2552730798347846\n",
      "53 Train Loss 1.9417362 Test MSE 6.894993034334187 Test RE 1.2550903087573682\n",
      "54 Train Loss 1.9032289 Test MSE 6.840788472843347 Test RE 1.2501471671014464\n",
      "55 Train Loss 1.8597827 Test MSE 6.7409433203307705 Test RE 1.2409903317319257\n",
      "56 Train Loss 1.8191642 Test MSE 6.671903665951199 Test RE 1.2346189646958627\n",
      "57 Train Loss 1.782241 Test MSE 6.657132526166939 Test RE 1.2332515263207688\n",
      "58 Train Loss 1.7492195 Test MSE 6.635212307145748 Test RE 1.2312194627061035\n",
      "59 Train Loss 1.6984861 Test MSE 6.5663332406999535 Test RE 1.2248122461433453\n",
      "60 Train Loss 1.6523798 Test MSE 6.483656972507317 Test RE 1.2170770556445554\n",
      "61 Train Loss 1.6173825 Test MSE 6.45694524648713 Test RE 1.2145673776569785\n",
      "62 Train Loss 1.5711725 Test MSE 6.3878165991659435 Test RE 1.2080482472969438\n",
      "63 Train Loss 1.5335295 Test MSE 6.323363080092459 Test RE 1.2019381494710468\n",
      "64 Train Loss 1.5053917 Test MSE 6.239152670878898 Test RE 1.1939080121892198\n",
      "65 Train Loss 1.4704659 Test MSE 6.187137481385593 Test RE 1.1889208504445727\n",
      "66 Train Loss 1.4474238 Test MSE 6.125739288982212 Test RE 1.1830070014457723\n",
      "67 Train Loss 1.4308546 Test MSE 6.074181064645437 Test RE 1.1780180016500004\n",
      "68 Train Loss 1.414231 Test MSE 6.053046590005172 Test RE 1.1759668209627046\n",
      "69 Train Loss 1.3958839 Test MSE 6.05691004210993 Test RE 1.1763420507495979\n",
      "70 Train Loss 1.3777565 Test MSE 6.032323487732109 Test RE 1.173952085571213\n",
      "71 Train Loss 1.3582075 Test MSE 6.018708508065749 Test RE 1.1726265297872958\n",
      "72 Train Loss 1.3506733 Test MSE 6.009405167790294 Test RE 1.171719893204603\n",
      "73 Train Loss 1.3311281 Test MSE 5.955529722107222 Test RE 1.1664557236491067\n",
      "74 Train Loss 1.3174232 Test MSE 5.95771704920823 Test RE 1.166669909969152\n",
      "75 Train Loss 1.3046577 Test MSE 5.9504397777629 Test RE 1.1659571564265832\n",
      "76 Train Loss 1.297853 Test MSE 5.9343142033815734 Test RE 1.1643762241827582\n",
      "77 Train Loss 1.2912455 Test MSE 5.926485005282449 Test RE 1.1636078842749042\n",
      "78 Train Loss 1.2815726 Test MSE 5.92593718383892 Test RE 1.1635541033168986\n",
      "79 Train Loss 1.2714372 Test MSE 5.946166077631249 Test RE 1.165538376767504\n",
      "80 Train Loss 1.2652017 Test MSE 5.949564305085337 Test RE 1.165871381154492\n",
      "81 Train Loss 1.2564232 Test MSE 5.915678453555768 Test RE 1.162546519381232\n",
      "82 Train Loss 1.2500094 Test MSE 5.8980751646549505 Test RE 1.1608155354156153\n",
      "83 Train Loss 1.2428949 Test MSE 5.902460417311818 Test RE 1.1612469917316197\n",
      "84 Train Loss 1.237442 Test MSE 5.903814648431868 Test RE 1.1613801994544364\n",
      "85 Train Loss 1.2315148 Test MSE 5.8918817699642405 Test RE 1.160205906264918\n",
      "86 Train Loss 1.2245297 Test MSE 5.897247088557995 Test RE 1.1607340446485028\n",
      "87 Train Loss 1.2177795 Test MSE 5.909958898008887 Test RE 1.161984381206831\n",
      "88 Train Loss 1.2127713 Test MSE 5.900944339220809 Test RE 1.1610978459463435\n",
      "89 Train Loss 1.2078524 Test MSE 5.889344011606648 Test RE 1.15995601671656\n",
      "90 Train Loss 1.2039626 Test MSE 5.880415064251387 Test RE 1.1590763674000895\n",
      "91 Train Loss 1.1992556 Test MSE 5.864272297174391 Test RE 1.157484340450475\n",
      "92 Train Loss 1.1947778 Test MSE 5.85602877479603 Test RE 1.1566705051445876\n",
      "93 Train Loss 1.1909921 Test MSE 5.853514760834549 Test RE 1.1564221971128952\n",
      "94 Train Loss 1.1859709 Test MSE 5.847297799077906 Test RE 1.1558079215161787\n",
      "95 Train Loss 1.1810368 Test MSE 5.8422077268625365 Test RE 1.1553047466423443\n",
      "96 Train Loss 1.1767589 Test MSE 5.840033524554991 Test RE 1.1550897508644273\n",
      "97 Train Loss 1.1725068 Test MSE 5.840986973010533 Test RE 1.1551840374457867\n",
      "98 Train Loss 1.1674151 Test MSE 5.844907197576469 Test RE 1.1555716278709471\n",
      "99 Train Loss 1.1632444 Test MSE 5.845260572180281 Test RE 1.155606559434486\n",
      "Training time: 88.99\n",
      "6\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.515133 Test MSE 8.266402444371872 Test RE 1.374251857597335\n",
      "1 Train Loss 58.56303 Test MSE 8.422320505207962 Test RE 1.3871516485798332\n",
      "2 Train Loss 56.6498 Test MSE 7.924699902050807 Test RE 1.3455488605397659\n",
      "3 Train Loss 47.78312 Test MSE 8.368662498865293 Test RE 1.3827258658650246\n",
      "4 Train Loss 45.60049 Test MSE 8.294840095794944 Test RE 1.3766136433057683\n",
      "5 Train Loss 44.89508 Test MSE 8.535120669734848 Test RE 1.3964098161709462\n",
      "6 Train Loss 44.024178 Test MSE 8.808028149982587 Test RE 1.418559012366643\n",
      "7 Train Loss 42.57538 Test MSE 9.10181394317762 Test RE 1.4420225009129004\n",
      "8 Train Loss 41.32306 Test MSE 8.80189870461883 Test RE 1.4180653438046211\n",
      "9 Train Loss 37.206383 Test MSE 8.915654162062566 Test RE 1.4271994419314527\n",
      "10 Train Loss 32.039352 Test MSE 8.48539474641665 Test RE 1.3923361069311941\n",
      "11 Train Loss 30.98422 Test MSE 8.658098279647653 Test RE 1.4064338677156545\n",
      "12 Train Loss 29.553373 Test MSE 8.697776879534644 Test RE 1.409652908109863\n",
      "13 Train Loss 27.914465 Test MSE 8.72960750854582 Test RE 1.4122299552285709\n",
      "14 Train Loss 26.158733 Test MSE 8.70050864915977 Test RE 1.4098742603434138\n",
      "15 Train Loss 24.512371 Test MSE 8.44269736378581 Test RE 1.3888286636687297\n",
      "16 Train Loss 21.750824 Test MSE 7.921748161930235 Test RE 1.3452982466040337\n",
      "17 Train Loss 19.192844 Test MSE 7.1200298474618435 Test RE 1.275407502567941\n",
      "18 Train Loss 16.555786 Test MSE 6.7673720120407745 Test RE 1.2434206790366091\n",
      "19 Train Loss 15.787787 Test MSE 6.681870967195107 Test RE 1.2355408325169455\n",
      "20 Train Loss 15.171158 Test MSE 6.413138732866699 Test RE 1.2104403090180613\n",
      "21 Train Loss 14.45863 Test MSE 6.454444324480725 Test RE 1.2143321400677625\n",
      "22 Train Loss 14.025444 Test MSE 6.402794477554444 Test RE 1.2094637079134738\n",
      "23 Train Loss 13.429279 Test MSE 6.219063976266166 Test RE 1.1919844023898267\n",
      "24 Train Loss 12.937888 Test MSE 6.386627391116546 Test RE 1.2079357920043625\n",
      "25 Train Loss 12.482996 Test MSE 6.421986020067687 Test RE 1.2112749566522625\n",
      "26 Train Loss 11.530345 Test MSE 5.997828359083752 Test RE 1.1705907201880346\n",
      "27 Train Loss 10.132946 Test MSE 5.907140489535823 Test RE 1.1617072779964983\n",
      "28 Train Loss 9.372206 Test MSE 5.776380677589888 Test RE 1.1487776129277179\n",
      "29 Train Loss 8.707401 Test MSE 5.85651772623551 Test RE 1.1567187924673972\n",
      "30 Train Loss 8.073246 Test MSE 6.043915488349437 Test RE 1.1750795053738021\n",
      "31 Train Loss 7.0178685 Test MSE 6.053090335053693 Test RE 1.1759710702801298\n",
      "32 Train Loss 4.519679 Test MSE 5.099616666355382 Test RE 1.0793861127302309\n",
      "33 Train Loss 3.7308352 Test MSE 5.118170867184016 Test RE 1.081347923257125\n",
      "34 Train Loss 3.2322834 Test MSE 5.247110450281937 Test RE 1.0948841362173851\n",
      "35 Train Loss 2.9630272 Test MSE 5.274455041249693 Test RE 1.0977333476553053\n",
      "36 Train Loss 2.6624002 Test MSE 5.365535823017999 Test RE 1.1071707650358757\n",
      "37 Train Loss 2.4989645 Test MSE 5.4255079947714755 Test RE 1.113341157490615\n",
      "38 Train Loss 2.3945746 Test MSE 5.31829539733513 Test RE 1.1022859916930734\n",
      "39 Train Loss 2.2658758 Test MSE 5.341053918136773 Test RE 1.104641973834418\n",
      "40 Train Loss 2.1304078 Test MSE 5.293568878344167 Test RE 1.0997205597716828\n",
      "41 Train Loss 2.047832 Test MSE 5.292768595979187 Test RE 1.0996374286879051\n",
      "42 Train Loss 1.9891369 Test MSE 5.294282031671964 Test RE 1.0997946348411038\n",
      "43 Train Loss 1.9156797 Test MSE 5.2709953087503765 Test RE 1.0973732643190222\n",
      "44 Train Loss 1.8439978 Test MSE 5.249315467922773 Test RE 1.0951141661809694\n",
      "45 Train Loss 1.8003873 Test MSE 5.295190601609968 Test RE 1.0998890005615287\n",
      "46 Train Loss 1.7642255 Test MSE 5.319883758928426 Test RE 1.1024505837190108\n",
      "47 Train Loss 1.7243506 Test MSE 5.336090937975423 Test RE 1.1041286303596674\n",
      "48 Train Loss 1.6918619 Test MSE 5.353558775796943 Test RE 1.105934351245898\n",
      "49 Train Loss 1.6665242 Test MSE 5.340909093268818 Test RE 1.104626997322765\n",
      "50 Train Loss 1.6355128 Test MSE 5.348862288859095 Test RE 1.1054491463493483\n",
      "51 Train Loss 1.5931627 Test MSE 5.324888032906035 Test RE 1.1029689848920246\n",
      "52 Train Loss 1.5484569 Test MSE 5.291302973087724 Test RE 1.0994851676032797\n",
      "53 Train Loss 1.5093104 Test MSE 5.291005747784901 Test RE 1.0994542867972767\n",
      "54 Train Loss 1.4765322 Test MSE 5.284651484709256 Test RE 1.098793890560047\n",
      "55 Train Loss 1.4393921 Test MSE 5.2296014375162265 Test RE 1.0930558576294864\n",
      "56 Train Loss 1.4116884 Test MSE 5.1853040792771 Test RE 1.0884166457877589\n",
      "57 Train Loss 1.3929248 Test MSE 5.169661501030116 Test RE 1.0867736850217544\n",
      "58 Train Loss 1.370188 Test MSE 5.126343883410834 Test RE 1.0822109609466806\n",
      "59 Train Loss 1.3377779 Test MSE 5.063192386362649 Test RE 1.0755244187724178\n",
      "60 Train Loss 1.3078603 Test MSE 5.02365384881212 Test RE 1.0713167959900625\n",
      "61 Train Loss 1.2834712 Test MSE 4.993762673726217 Test RE 1.0681248269656762\n",
      "62 Train Loss 1.2619555 Test MSE 4.9809538135744065 Test RE 1.0667540924276326\n",
      "63 Train Loss 1.2294352 Test MSE 4.908744624058542 Test RE 1.0589934637810199\n",
      "64 Train Loss 1.2087319 Test MSE 4.856908652539025 Test RE 1.053387178620578\n",
      "65 Train Loss 1.1893315 Test MSE 4.829435381842969 Test RE 1.0504036932031506\n",
      "66 Train Loss 1.1686593 Test MSE 4.783095262917539 Test RE 1.0453520508069751\n",
      "67 Train Loss 1.1473386 Test MSE 4.741963673596346 Test RE 1.0408476634593617\n",
      "68 Train Loss 1.126315 Test MSE 4.684915680583135 Test RE 1.0345677819945809\n",
      "69 Train Loss 1.1013896 Test MSE 4.602984368927087 Test RE 1.025481453618849\n",
      "70 Train Loss 1.0780303 Test MSE 4.587388632314369 Test RE 1.023742722040282\n",
      "71 Train Loss 1.0631096 Test MSE 4.55745644421852 Test RE 1.0203973537695532\n",
      "72 Train Loss 1.0368809 Test MSE 4.427395212212058 Test RE 1.0057318546971736\n",
      "73 Train Loss 1.007369 Test MSE 4.357732760988059 Test RE 0.9977881849227164\n",
      "74 Train Loss 0.9924364 Test MSE 4.3178892616935745 Test RE 0.9932162359988799\n",
      "75 Train Loss 0.9651639 Test MSE 4.26762115527997 Test RE 0.9874178864954017\n",
      "76 Train Loss 0.9414508 Test MSE 4.207814927387952 Test RE 0.98047466291203\n",
      "77 Train Loss 0.92262805 Test MSE 4.165418236409371 Test RE 0.9755226721772068\n",
      "78 Train Loss 0.90015125 Test MSE 4.076745608090779 Test RE 0.9650834460337702\n",
      "79 Train Loss 0.8786972 Test MSE 3.9948592412359463 Test RE 0.9553418457355333\n",
      "80 Train Loss 0.8587464 Test MSE 3.9693878257065816 Test RE 0.9522913225065028\n",
      "81 Train Loss 0.83618206 Test MSE 3.8398677694217804 Test RE 0.9366259688865184\n",
      "82 Train Loss 0.81975555 Test MSE 3.7817560888945545 Test RE 0.9295116079034417\n",
      "83 Train Loss 0.8013343 Test MSE 3.7135742096691287 Test RE 0.9210943403134743\n",
      "84 Train Loss 0.7846443 Test MSE 3.646558981309602 Test RE 0.9127454601339164\n",
      "85 Train Loss 0.76575464 Test MSE 3.5747611541006523 Test RE 0.9037151756691316\n",
      "86 Train Loss 0.7479212 Test MSE 3.4674612064936463 Test RE 0.8900488958263022\n",
      "87 Train Loss 0.73247445 Test MSE 3.2828753150564367 Test RE 0.8660346220749453\n",
      "88 Train Loss 0.7190341 Test MSE 3.1706860281143188 Test RE 0.851108013765659\n",
      "89 Train Loss 0.71062064 Test MSE 3.0999936202221363 Test RE 0.8415665406797719\n",
      "90 Train Loss 0.7031446 Test MSE 3.0412529802510826 Test RE 0.8335551403379332\n",
      "91 Train Loss 0.6931222 Test MSE 2.9921890753427953 Test RE 0.8268040147138377\n",
      "92 Train Loss 0.6843821 Test MSE 2.9651321655056777 Test RE 0.8230573324283973\n",
      "93 Train Loss 0.67650306 Test MSE 2.924671218163153 Test RE 0.8174224965288794\n",
      "94 Train Loss 0.67092204 Test MSE 2.9251399157842037 Test RE 0.8174879925458057\n",
      "95 Train Loss 0.6637722 Test MSE 2.914590529392403 Test RE 0.8160125441023248\n",
      "96 Train Loss 0.6581905 Test MSE 2.8964327831243346 Test RE 0.813466715117557\n",
      "97 Train Loss 0.6529697 Test MSE 2.906795953625736 Test RE 0.814920670349807\n",
      "98 Train Loss 0.6476159 Test MSE 2.9209950805662985 Test RE 0.8169086092908137\n",
      "99 Train Loss 0.63851696 Test MSE 2.8945399009430357 Test RE 0.8132008625291534\n",
      "Training time: 88.44\n",
      "7\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.388397 Test MSE 8.276134597085552 Test RE 1.3750605827274347\n",
      "1 Train Loss 38.281837 Test MSE 6.387385884650319 Test RE 1.2080075187726553\n",
      "2 Train Loss 28.581106 Test MSE 5.687231152730769 Test RE 1.1398783376153354\n",
      "3 Train Loss 25.03957 Test MSE 5.052785866758122 Test RE 1.0744185726916569\n",
      "4 Train Loss 22.916313 Test MSE 5.62967169684569 Test RE 1.1340954153725316\n",
      "5 Train Loss 20.842571 Test MSE 5.712839577689781 Test RE 1.1424417733345946\n",
      "6 Train Loss 18.337986 Test MSE 5.7784660826013265 Test RE 1.1489849616588004\n",
      "7 Train Loss 15.49173 Test MSE 5.832430364125466 Test RE 1.1543375982484236\n",
      "8 Train Loss 13.301857 Test MSE 5.917113650699013 Test RE 1.1626875329836093\n",
      "9 Train Loss 11.764193 Test MSE 5.833836074814926 Test RE 1.1544766969465163\n",
      "10 Train Loss 10.531761 Test MSE 5.733656186288509 Test RE 1.1445213117263333\n",
      "11 Train Loss 9.861266 Test MSE 5.864643592572743 Test RE 1.1575209828320898\n",
      "12 Train Loss 8.941842 Test MSE 5.66173788555043 Test RE 1.1373206904721085\n",
      "13 Train Loss 8.243226 Test MSE 5.603177576220522 Test RE 1.1314236525150778\n",
      "14 Train Loss 7.603794 Test MSE 5.331342367609921 Test RE 1.1036372407344188\n",
      "15 Train Loss 7.1248283 Test MSE 5.254948855995668 Test RE 1.0957016283807879\n",
      "16 Train Loss 6.67844 Test MSE 4.918282654370286 Test RE 1.0600218132569488\n",
      "17 Train Loss 6.271645 Test MSE 4.6089898067191255 Test RE 1.0261501999343372\n",
      "18 Train Loss 5.6699686 Test MSE 4.197040413769812 Test RE 0.9792185586056269\n",
      "19 Train Loss 5.1247396 Test MSE 3.874607502167593 Test RE 0.9408533114342222\n",
      "20 Train Loss 4.424099 Test MSE 3.798043798885922 Test RE 0.931511122003544\n",
      "21 Train Loss 3.6675313 Test MSE 3.542983477447747 Test RE 0.8996894415818442\n",
      "22 Train Loss 3.1030698 Test MSE 3.3401726129647056 Test RE 0.8735595495422863\n",
      "23 Train Loss 2.718154 Test MSE 3.1278243603535874 Test RE 0.8453357559957204\n",
      "24 Train Loss 2.5001442 Test MSE 2.8596032550734134 Test RE 0.8082783600874252\n",
      "25 Train Loss 2.1258912 Test MSE 2.3649810381178753 Test RE 0.7350584793207523\n",
      "26 Train Loss 1.9393225 Test MSE 2.2981039164480532 Test RE 0.724590927037708\n",
      "27 Train Loss 1.7479318 Test MSE 2.028351169913946 Test RE 0.6807374347079275\n",
      "28 Train Loss 1.583883 Test MSE 1.9115194281215446 Test RE 0.6608416676594865\n",
      "29 Train Loss 1.4577792 Test MSE 1.8347195817291015 Test RE 0.6474301325243897\n",
      "30 Train Loss 1.2647141 Test MSE 1.4705639726838098 Test RE 0.5796288869707615\n",
      "31 Train Loss 1.0816051 Test MSE 1.1677342077086257 Test RE 0.5165115787152387\n",
      "32 Train Loss 0.9695684 Test MSE 1.0411641967443275 Test RE 0.48771675202209447\n",
      "33 Train Loss 0.84312785 Test MSE 0.811785961653995 Test RE 0.4306543403788037\n",
      "34 Train Loss 0.6568866 Test MSE 0.5556936789811228 Test RE 0.3563081765437805\n",
      "35 Train Loss 0.48321438 Test MSE 0.33261849264103277 Test RE 0.27566476306533566\n",
      "36 Train Loss 0.33623245 Test MSE 0.1815162206960882 Test RE 0.20364126238701005\n",
      "37 Train Loss 0.24510112 Test MSE 0.12129316848920363 Test RE 0.16646626325104344\n",
      "38 Train Loss 0.18286355 Test MSE 0.08194894685458973 Test RE 0.1368295027309492\n",
      "39 Train Loss 0.13486825 Test MSE 0.06868142389141248 Test RE 0.12526441237318398\n",
      "40 Train Loss 0.114319764 Test MSE 0.05379086735055677 Test RE 0.11085679892163647\n",
      "41 Train Loss 0.08514852 Test MSE 0.032267840286255914 Test RE 0.08586042020769646\n",
      "42 Train Loss 0.06603757 Test MSE 0.026374646830287674 Test RE 0.07762495952605354\n",
      "43 Train Loss 0.052448444 Test MSE 0.015287190145094606 Test RE 0.05909787893268656\n",
      "44 Train Loss 0.043532677 Test MSE 0.00799611276800355 Test RE 0.042741279144488734\n",
      "45 Train Loss 0.038299344 Test MSE 0.007797602573505538 Test RE 0.04220740080520719\n",
      "46 Train Loss 0.032972652 Test MSE 0.007677951063865296 Test RE 0.04188231995064315\n",
      "47 Train Loss 0.028166233 Test MSE 0.008140536760483322 Test RE 0.04312554347638267\n",
      "48 Train Loss 0.024943588 Test MSE 0.006443073952632507 Test RE 0.03836671520564516\n",
      "49 Train Loss 0.020224601 Test MSE 0.004480163080047387 Test RE 0.031993000418053044\n",
      "50 Train Loss 0.018034447 Test MSE 0.0037370454125694305 Test RE 0.029219464201346707\n",
      "51 Train Loss 0.015970157 Test MSE 0.0032484439408418386 Test RE 0.027242424032072828\n",
      "52 Train Loss 0.01468142 Test MSE 0.0030147074542751957 Test RE 0.026244037381052552\n",
      "53 Train Loss 0.01334753 Test MSE 0.002845296396951052 Test RE 0.02549598630790068\n",
      "54 Train Loss 0.012419818 Test MSE 0.0029311296688620788 Test RE 0.025877694172525285\n",
      "55 Train Loss 0.010946479 Test MSE 0.0023280740026045124 Test RE 0.02306250357626888\n",
      "56 Train Loss 0.010335903 Test MSE 0.00206821785075857 Test RE 0.021737330141068312\n",
      "57 Train Loss 0.009415339 Test MSE 0.0022066872321568906 Test RE 0.022453210679284765\n",
      "58 Train Loss 0.008439697 Test MSE 0.0022077825194530016 Test RE 0.022458782303837924\n",
      "59 Train Loss 0.008121956 Test MSE 0.002213902882885112 Test RE 0.022489890616709793\n",
      "60 Train Loss 0.007647831 Test MSE 0.0024749745692033945 Test RE 0.023778991448422736\n",
      "61 Train Loss 0.007084476 Test MSE 0.002600751995144409 Test RE 0.024375724370645096\n",
      "62 Train Loss 0.0068326234 Test MSE 0.002297750104746884 Test RE 0.022911813080091138\n",
      "63 Train Loss 0.0064420477 Test MSE 0.001963457871626006 Test RE 0.021179653657082985\n",
      "64 Train Loss 0.006120286 Test MSE 0.0020038917136447638 Test RE 0.021396620553245132\n",
      "65 Train Loss 0.0057992935 Test MSE 0.0020844333900726557 Test RE 0.021822377838175692\n",
      "66 Train Loss 0.0053810617 Test MSE 0.002096672697817491 Test RE 0.021886352027152035\n",
      "67 Train Loss 0.00515572 Test MSE 0.002179634493462172 Test RE 0.022315154413040047\n",
      "68 Train Loss 0.004814598 Test MSE 0.0025140953696875766 Test RE 0.023966186488305005\n",
      "69 Train Loss 0.004610164 Test MSE 0.002591076318250812 Test RE 0.02433033915043614\n",
      "70 Train Loss 0.0043045455 Test MSE 0.0023507720376575174 Test RE 0.0231746571779614\n",
      "71 Train Loss 0.0041936487 Test MSE 0.0023383559049898364 Test RE 0.023113375062862568\n",
      "72 Train Loss 0.0039943047 Test MSE 0.0022722791441109574 Test RE 0.022784468465409113\n",
      "73 Train Loss 0.0038031503 Test MSE 0.0020633064300034413 Test RE 0.021711504855909634\n",
      "74 Train Loss 0.0036262518 Test MSE 0.0019659687683488405 Test RE 0.021193191745367483\n",
      "75 Train Loss 0.0034714225 Test MSE 0.0020262562344724377 Test RE 0.02151568821829053\n",
      "76 Train Loss 0.0032702503 Test MSE 0.0019797030689508452 Test RE 0.021267090954012288\n",
      "77 Train Loss 0.0031329296 Test MSE 0.0018982703478661058 Test RE 0.020825099840896047\n",
      "78 Train Loss 0.0030020783 Test MSE 0.0018752814608940136 Test RE 0.020698615179116513\n",
      "79 Train Loss 0.0028530103 Test MSE 0.0017830170408922217 Test RE 0.02018300404407404\n",
      "80 Train Loss 0.0026918647 Test MSE 0.0016549237115725797 Test RE 0.019444512064365104\n",
      "81 Train Loss 0.0026151284 Test MSE 0.0015852077292657387 Test RE 0.019030541714867365\n",
      "82 Train Loss 0.0025333934 Test MSE 0.0015386184423144165 Test RE 0.018748802193366693\n",
      "83 Train Loss 0.002486826 Test MSE 0.001517551185577214 Test RE 0.018620002478306003\n",
      "84 Train Loss 0.0024101245 Test MSE 0.001468672908692991 Test RE 0.01831768566753071\n",
      "85 Train Loss 0.002306256 Test MSE 0.0013746772607243518 Test RE 0.01772182463422091\n",
      "86 Train Loss 0.0021946651 Test MSE 0.0012834519997062623 Test RE 0.017123710456235623\n",
      "87 Train Loss 0.0021123106 Test MSE 0.0012770294619609877 Test RE 0.01708081223828401\n",
      "88 Train Loss 0.0020466743 Test MSE 0.0012563297487988916 Test RE 0.016941812933711064\n",
      "89 Train Loss 0.001986961 Test MSE 0.001242841933148232 Test RE 0.0168506248226521\n",
      "90 Train Loss 0.0019483558 Test MSE 0.0012436252326309054 Test RE 0.016855934028244885\n",
      "91 Train Loss 0.0019042483 Test MSE 0.001222121833585747 Test RE 0.016709571452742385\n",
      "92 Train Loss 0.001806798 Test MSE 0.001113579587772658 Test RE 0.015950293947946753\n",
      "93 Train Loss 0.001728977 Test MSE 0.0011027871688520092 Test RE 0.015872813462952697\n",
      "94 Train Loss 0.0016816896 Test MSE 0.0011225217284459219 Test RE 0.016014207019524322\n",
      "95 Train Loss 0.001603754 Test MSE 0.001112638980052433 Test RE 0.015943556154226445\n",
      "96 Train Loss 0.0015518895 Test MSE 0.0010775787353776004 Test RE 0.015690347658374237\n",
      "97 Train Loss 0.0014911345 Test MSE 0.0010554538079349373 Test RE 0.015528434547240948\n",
      "98 Train Loss 0.001439838 Test MSE 0.0009677400202088066 Test RE 0.01486919342421039\n",
      "99 Train Loss 0.001388955 Test MSE 0.0008182847521177861 Test RE 0.013672889046988221\n",
      "Training time: 88.92\n",
      "8\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.198307 Test MSE 8.342922239665903 Test RE 1.3805977401017\n",
      "1 Train Loss 35.80831 Test MSE 8.7576584919869 Test RE 1.4144971056505173\n",
      "2 Train Loss 26.62593 Test MSE 7.706982287818152 Test RE 1.32693680660058\n",
      "3 Train Loss 22.791836 Test MSE 7.508056277767181 Test RE 1.3096999770990767\n",
      "4 Train Loss 18.756203 Test MSE 7.463384043701515 Test RE 1.3057978678335884\n",
      "5 Train Loss 16.54112 Test MSE 7.208038012940953 Test RE 1.2832657240301066\n",
      "6 Train Loss 14.869827 Test MSE 7.002243542072283 Test RE 1.2648140059797668\n",
      "7 Train Loss 13.052333 Test MSE 7.126238661347651 Test RE 1.275963472304123\n",
      "8 Train Loss 12.055338 Test MSE 6.988300370657839 Test RE 1.2635541021867245\n",
      "9 Train Loss 10.883553 Test MSE 7.020963553038428 Test RE 1.2665035736242682\n",
      "10 Train Loss 9.698906 Test MSE 6.6781412396543764 Test RE 1.2351959535200685\n",
      "11 Train Loss 8.959245 Test MSE 6.694683349677762 Test RE 1.236724830270965\n",
      "12 Train Loss 8.31427 Test MSE 6.6328532152449435 Test RE 1.2310005685738012\n",
      "13 Train Loss 7.624236 Test MSE 6.568423787978258 Test RE 1.2250072045809581\n",
      "14 Train Loss 7.1509085 Test MSE 6.348168331742913 Test RE 1.2042933199855699\n",
      "15 Train Loss 6.8268623 Test MSE 6.30065154957943 Test RE 1.199777716007527\n",
      "16 Train Loss 6.229938 Test MSE 6.2387925576533405 Test RE 1.193873556527367\n",
      "17 Train Loss 5.641306 Test MSE 6.0765909665782845 Test RE 1.1782516649458419\n",
      "18 Train Loss 4.618956 Test MSE 5.568274826469554 Test RE 1.1278942725501122\n",
      "19 Train Loss 3.7647643 Test MSE 5.298546112106896 Test RE 1.100237439820968\n",
      "20 Train Loss 3.3125463 Test MSE 5.187012807172035 Test RE 1.0885959655213604\n",
      "21 Train Loss 2.9992864 Test MSE 5.15672226736612 Test RE 1.085412780764017\n",
      "22 Train Loss 2.7602315 Test MSE 5.137766572811196 Test RE 1.083415999215108\n",
      "23 Train Loss 2.5513165 Test MSE 5.162719452067304 Test RE 1.0860437561295442\n",
      "24 Train Loss 2.4021382 Test MSE 4.933735533781104 Test RE 1.0616857622493503\n",
      "25 Train Loss 2.2224035 Test MSE 4.733654591361995 Test RE 1.0399353535688358\n",
      "26 Train Loss 2.1055758 Test MSE 4.5967912325621025 Test RE 1.024791348716356\n",
      "27 Train Loss 2.032069 Test MSE 4.491445854361628 Test RE 1.0129806383506574\n",
      "28 Train Loss 1.9425242 Test MSE 4.434246428734734 Test RE 1.006509718739428\n",
      "29 Train Loss 1.8632357 Test MSE 4.3978876560034195 Test RE 1.0023747677050272\n",
      "30 Train Loss 1.8015609 Test MSE 4.392243739017341 Test RE 1.0017313751686063\n",
      "31 Train Loss 1.7446907 Test MSE 4.375684018358658 Test RE 0.9998412185942062\n",
      "32 Train Loss 1.6993546 Test MSE 4.321478573108594 Test RE 0.9936289633302032\n",
      "33 Train Loss 1.6607852 Test MSE 4.235062075854645 Test RE 0.9836440074578819\n",
      "34 Train Loss 1.6293776 Test MSE 4.176298938711937 Test RE 0.9767959475886685\n",
      "35 Train Loss 1.5936729 Test MSE 4.135618193496549 Test RE 0.9720268889712961\n",
      "36 Train Loss 1.5742865 Test MSE 4.099084987793934 Test RE 0.9677240218138515\n",
      "37 Train Loss 1.5474725 Test MSE 4.076892694890399 Test RE 0.965100855723843\n",
      "38 Train Loss 1.5223182 Test MSE 4.051193308981064 Test RE 0.9620542082441988\n",
      "39 Train Loss 1.5033058 Test MSE 4.019707258886704 Test RE 0.9583083522935617\n",
      "40 Train Loss 1.4797351 Test MSE 3.9821135165053674 Test RE 0.9538166039967577\n",
      "41 Train Loss 1.4464006 Test MSE 3.8759005471995382 Test RE 0.9410102904595109\n",
      "42 Train Loss 1.4195777 Test MSE 3.8164314126575185 Test RE 0.9337632795273199\n",
      "43 Train Loss 1.3801148 Test MSE 3.6647442446201572 Test RE 0.9150185447043699\n",
      "44 Train Loss 1.3087051 Test MSE 3.54299123014708 Test RE 0.899690425924272\n",
      "45 Train Loss 1.2410839 Test MSE 3.376962024738802 Test RE 0.8783571658072391\n",
      "46 Train Loss 1.1744353 Test MSE 3.2483431181022864 Test RE 0.8614677201524764\n",
      "47 Train Loss 1.1294749 Test MSE 3.17804813251163 Test RE 0.8520955465808071\n",
      "48 Train Loss 1.0723488 Test MSE 3.060844750439751 Test RE 0.8362357138414799\n",
      "49 Train Loss 1.0374606 Test MSE 2.969052229080851 Test RE 0.8236012156708233\n",
      "50 Train Loss 1.0039352 Test MSE 2.9222553445323767 Test RE 0.8170848179855763\n",
      "51 Train Loss 0.96809953 Test MSE 2.873937253957933 Test RE 0.8103016090456827\n",
      "52 Train Loss 0.9364042 Test MSE 2.8472892350020906 Test RE 0.8065361788719787\n",
      "53 Train Loss 0.8942075 Test MSE 2.7907324605047044 Test RE 0.7984857357279092\n",
      "54 Train Loss 0.8537755 Test MSE 2.7083960949753916 Test RE 0.7866184885067709\n",
      "55 Train Loss 0.82468855 Test MSE 2.704868390122732 Test RE 0.7861060335424279\n",
      "56 Train Loss 0.80406857 Test MSE 2.6988081675465443 Test RE 0.7852249095383735\n",
      "57 Train Loss 0.7822913 Test MSE 2.681625866237512 Test RE 0.7827213017663863\n",
      "58 Train Loss 0.7603762 Test MSE 2.6999933597336976 Test RE 0.7853973079118008\n",
      "59 Train Loss 0.74300504 Test MSE 2.712414008010047 Test RE 0.787201747612815\n",
      "60 Train Loss 0.729357 Test MSE 2.6814201280649788 Test RE 0.7826912754414811\n",
      "61 Train Loss 0.7163433 Test MSE 2.683010622787784 Test RE 0.7829233692088009\n",
      "62 Train Loss 0.70468724 Test MSE 2.6937990143179467 Test RE 0.7844958583314783\n",
      "63 Train Loss 0.6923615 Test MSE 2.7099307558270596 Test RE 0.7868413181072917\n",
      "64 Train Loss 0.67945635 Test MSE 2.7009674710103706 Test RE 0.7855389740715465\n",
      "65 Train Loss 0.6684444 Test MSE 2.7038513041963173 Test RE 0.7859582236598752\n",
      "66 Train Loss 0.6580633 Test MSE 2.7371810371727157 Test RE 0.7907875469577736\n",
      "67 Train Loss 0.64818066 Test MSE 2.751846936080616 Test RE 0.7929032485604778\n",
      "68 Train Loss 0.63595563 Test MSE 2.7462715954287695 Test RE 0.7920996160882372\n",
      "69 Train Loss 0.6293363 Test MSE 2.7544198205216346 Test RE 0.7932738309107005\n",
      "70 Train Loss 0.61718553 Test MSE 2.774369976143386 Test RE 0.7961414734739994\n",
      "71 Train Loss 0.60757184 Test MSE 2.7804388610391677 Test RE 0.7970117704389641\n",
      "72 Train Loss 0.60161 Test MSE 2.7966312854492488 Test RE 0.7993291776016073\n",
      "73 Train Loss 0.5930065 Test MSE 2.834632944537571 Test RE 0.8047416430806904\n",
      "74 Train Loss 0.5862175 Test MSE 2.836837388799172 Test RE 0.8050544989886997\n",
      "75 Train Loss 0.57952136 Test MSE 2.843290143079147 Test RE 0.8059695793114601\n",
      "76 Train Loss 0.57204306 Test MSE 2.8659218498055115 Test RE 0.8091708554496191\n",
      "77 Train Loss 0.5670593 Test MSE 2.887533311601537 Test RE 0.8122160399139513\n",
      "78 Train Loss 0.5625076 Test MSE 2.895028811999209 Test RE 0.8132695377105063\n",
      "79 Train Loss 0.5575713 Test MSE 2.9000476392996224 Test RE 0.813974175239535\n",
      "80 Train Loss 0.5527407 Test MSE 2.9260395654937232 Test RE 0.817613695301285\n",
      "81 Train Loss 0.5481256 Test MSE 2.9286999093768853 Test RE 0.8179852964644391\n",
      "82 Train Loss 0.5446424 Test MSE 2.9122848282651037 Test RE 0.8156897108816813\n",
      "83 Train Loss 0.5412999 Test MSE 2.925503414971803 Test RE 0.817538784473473\n",
      "84 Train Loss 0.5354137 Test MSE 2.927122578269904 Test RE 0.8177649926671037\n",
      "85 Train Loss 0.53179884 Test MSE 2.9336194791405843 Test RE 0.8186720256205297\n",
      "86 Train Loss 0.5287021 Test MSE 2.937736102881466 Test RE 0.8192462281111987\n",
      "87 Train Loss 0.523947 Test MSE 2.9228222843866707 Test RE 0.8171640744890806\n",
      "88 Train Loss 0.5187297 Test MSE 2.9205337932496587 Test RE 0.8168441031125329\n",
      "89 Train Loss 0.51438797 Test MSE 2.9296111895350023 Test RE 0.818112546749129\n",
      "90 Train Loss 0.51084507 Test MSE 2.9403084061232834 Test RE 0.8196048186301851\n",
      "91 Train Loss 0.506831 Test MSE 2.944656159044861 Test RE 0.8202105583071038\n",
      "92 Train Loss 0.50320023 Test MSE 2.950395400339793 Test RE 0.8210094792283729\n",
      "93 Train Loss 0.49985373 Test MSE 2.960156607794322 Test RE 0.8223664882403926\n",
      "94 Train Loss 0.4974153 Test MSE 2.965291501197232 Test RE 0.823079446223027\n",
      "95 Train Loss 0.49331555 Test MSE 2.9691915567058533 Test RE 0.8236205398602098\n",
      "96 Train Loss 0.48705098 Test MSE 2.988048423286477 Test RE 0.8262317425649934\n",
      "97 Train Loss 0.48289186 Test MSE 2.9951490749951626 Test RE 0.8272128683291702\n",
      "98 Train Loss 0.47907412 Test MSE 3.0025015190534745 Test RE 0.8282275604595739\n",
      "99 Train Loss 0.47612 Test MSE 3.0046812688508107 Test RE 0.828528143374731\n",
      "Training time: 87.75\n",
      "9\n",
      "KG_rowdy_tune2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.22412 Test MSE 8.43448846151545 Test RE 1.3881533148501402\n",
      "1 Train Loss 55.33345 Test MSE 8.77735866498354 Test RE 1.416087153058939\n",
      "2 Train Loss 50.230423 Test MSE 8.370465615432114 Test RE 1.3828748192750528\n",
      "3 Train Loss 46.220665 Test MSE 8.853915869982293 Test RE 1.4222493887012095\n",
      "4 Train Loss 44.656326 Test MSE 8.563081155951245 Test RE 1.3986952187193098\n",
      "5 Train Loss 43.429268 Test MSE 8.269939878629275 Test RE 1.3745458673354065\n",
      "6 Train Loss 42.445602 Test MSE 8.68147899453585 Test RE 1.4083315857920313\n",
      "7 Train Loss 42.041794 Test MSE 8.849734224832373 Test RE 1.4219134896067331\n",
      "8 Train Loss 40.399185 Test MSE 9.168572686914995 Test RE 1.4473012141991095\n",
      "9 Train Loss 39.618343 Test MSE 9.32581405295543 Test RE 1.4596590900336492\n",
      "10 Train Loss 38.943733 Test MSE 9.579702519201165 Test RE 1.479394745338883\n",
      "11 Train Loss 37.65057 Test MSE 9.452807235989065 Test RE 1.4695638533513464\n",
      "12 Train Loss 36.537613 Test MSE 9.526469573002807 Test RE 1.4752786337100245\n",
      "13 Train Loss 35.38884 Test MSE 9.22364297299997 Test RE 1.4516412554404579\n",
      "14 Train Loss 32.93097 Test MSE 9.188192495954782 Test RE 1.4488489250387886\n",
      "15 Train Loss 29.620178 Test MSE 9.047074263659425 Test RE 1.4376796912648102\n",
      "16 Train Loss 27.624844 Test MSE 8.85071276939366 Test RE 1.4219921002867582\n",
      "17 Train Loss 26.596077 Test MSE 8.592524193314139 Test RE 1.401097770789672\n",
      "18 Train Loss 25.566479 Test MSE 8.6070172926306 Test RE 1.402278895987065\n",
      "19 Train Loss 24.053757 Test MSE 8.505309600645885 Test RE 1.3939690256872044\n",
      "20 Train Loss 22.629532 Test MSE 8.546841489703604 Test RE 1.3973682942958237\n",
      "21 Train Loss 20.998568 Test MSE 8.305555459261122 Test RE 1.377502518473763\n",
      "22 Train Loss 19.678638 Test MSE 8.170256180810858 Test RE 1.3662365431702557\n",
      "23 Train Loss 18.686981 Test MSE 7.776919903633284 Test RE 1.3329439055174364\n",
      "24 Train Loss 17.808075 Test MSE 7.52723559691958 Test RE 1.3113717235319626\n",
      "25 Train Loss 16.804836 Test MSE 7.453823883416019 Test RE 1.3049612743319507\n",
      "26 Train Loss 15.929022 Test MSE 7.451118557511118 Test RE 1.3047244384485326\n",
      "27 Train Loss 15.313601 Test MSE 7.239960758614944 Test RE 1.2861042293818306\n",
      "28 Train Loss 13.373655 Test MSE 5.836117603257921 Test RE 1.154702424401869\n",
      "29 Train Loss 10.58329 Test MSE 5.134165289262753 Test RE 1.0830362260087776\n",
      "30 Train Loss 9.670776 Test MSE 5.2933044868489185 Test RE 1.0996930962210567\n",
      "31 Train Loss 8.989763 Test MSE 5.090573323906993 Test RE 1.078428630017952\n",
      "32 Train Loss 8.594794 Test MSE 5.068369039816518 Test RE 1.0760740912323956\n",
      "33 Train Loss 8.256233 Test MSE 4.994704340311557 Test RE 1.068225529593367\n",
      "34 Train Loss 7.909783 Test MSE 4.871050038436333 Test RE 1.0549195862021332\n",
      "35 Train Loss 7.116584 Test MSE 4.9070549854657965 Test RE 1.0588111900670136\n",
      "36 Train Loss 5.8926344 Test MSE 4.098498136462073 Test RE 0.9676547465413656\n",
      "37 Train Loss 4.7371097 Test MSE 3.764921843188283 Test RE 0.9274404696683435\n",
      "38 Train Loss 3.9231746 Test MSE 3.420942244739184 Test RE 0.8840583518076326\n",
      "39 Train Loss 3.239175 Test MSE 3.174378294206118 Test RE 0.8516034275181145\n",
      "40 Train Loss 2.8305087 Test MSE 2.9299200884453196 Test RE 0.8181556766043644\n",
      "41 Train Loss 2.4257085 Test MSE 3.027313436242164 Test RE 0.831642651709567\n",
      "42 Train Loss 2.187436 Test MSE 3.082874498509802 Test RE 0.839239628639752\n",
      "43 Train Loss 2.1026738 Test MSE 3.019270202491704 Test RE 0.8305371260771662\n",
      "44 Train Loss 2.0357018 Test MSE 3.0486544996185976 Test RE 0.834568838537561\n",
      "45 Train Loss 1.9132909 Test MSE 3.0156995850584516 Test RE 0.8300458802748284\n",
      "46 Train Loss 1.8400166 Test MSE 2.939530978814994 Test RE 0.8194964583488985\n",
      "47 Train Loss 1.7844001 Test MSE 2.8764017883460995 Test RE 0.810648970183704\n",
      "48 Train Loss 1.7398576 Test MSE 2.8767518085491717 Test RE 0.8106982913332865\n",
      "49 Train Loss 1.679308 Test MSE 2.7552955992445773 Test RE 0.7933999331705948\n",
      "50 Train Loss 1.6465672 Test MSE 2.701770771635211 Test RE 0.7856557798168772\n",
      "51 Train Loss 1.6002287 Test MSE 2.6699206821864756 Test RE 0.7810111607812725\n",
      "52 Train Loss 1.5775228 Test MSE 2.63498938526711 Test RE 0.7758852491639996\n",
      "53 Train Loss 1.5459 Test MSE 2.6045572898190676 Test RE 0.7713917993612875\n",
      "54 Train Loss 1.523745 Test MSE 2.5708662709376546 Test RE 0.7663864250680663\n",
      "55 Train Loss 1.4832623 Test MSE 2.546728254145143 Test RE 0.7627801162091608\n",
      "56 Train Loss 1.4671987 Test MSE 2.5379101619637847 Test RE 0.7614584011962804\n",
      "57 Train Loss 1.446942 Test MSE 2.496919691141239 Test RE 0.755284109146102\n",
      "58 Train Loss 1.4104089 Test MSE 2.475894334299452 Test RE 0.7520974449604002\n",
      "59 Train Loss 1.3800712 Test MSE 2.481067170618127 Test RE 0.7528827060619677\n",
      "60 Train Loss 1.3399717 Test MSE 2.5029366297687283 Test RE 0.7561935824605546\n",
      "61 Train Loss 1.3081352 Test MSE 2.4820964951363256 Test RE 0.7530388647257108\n",
      "62 Train Loss 1.2918987 Test MSE 2.475399283912393 Test RE 0.7520222509710179\n",
      "63 Train Loss 1.2745612 Test MSE 2.470356971938425 Test RE 0.7512559374703749\n",
      "64 Train Loss 1.2500228 Test MSE 2.4731110611739893 Test RE 0.7516745914482047\n",
      "65 Train Loss 1.2160053 Test MSE 2.4612549539201867 Test RE 0.749870660892747\n",
      "66 Train Loss 1.1951716 Test MSE 2.4695655499977516 Test RE 0.7511355888596658\n",
      "67 Train Loss 1.1851163 Test MSE 2.45854090668584 Test RE 0.7494571024043215\n",
      "68 Train Loss 1.1712223 Test MSE 2.460691075783836 Test RE 0.7497847575833437\n",
      "69 Train Loss 1.1455578 Test MSE 2.5006679662888547 Test RE 0.7558507975766391\n",
      "70 Train Loss 1.1262993 Test MSE 2.509681221510901 Test RE 0.7572117436277976\n",
      "71 Train Loss 1.1152816 Test MSE 2.511678003436777 Test RE 0.7575129145662066\n",
      "72 Train Loss 1.0891093 Test MSE 2.5326345236436523 Test RE 0.7606665550122768\n",
      "73 Train Loss 1.0752589 Test MSE 2.519124148118425 Test RE 0.7586349486067923\n",
      "74 Train Loss 1.0609485 Test MSE 2.524033678719151 Test RE 0.7593738420374053\n",
      "75 Train Loss 1.0482327 Test MSE 2.5146685773651845 Test RE 0.7579637534947254\n",
      "76 Train Loss 1.0272455 Test MSE 2.5125821914160427 Test RE 0.7576492521936169\n",
      "77 Train Loss 1.0164298 Test MSE 2.512020325078012 Test RE 0.7575645342859406\n",
      "78 Train Loss 1.0033343 Test MSE 2.5270329424135185 Test RE 0.7598248832059901\n",
      "79 Train Loss 0.9875363 Test MSE 2.5305661057016278 Test RE 0.7603558710755814\n",
      "80 Train Loss 0.9793539 Test MSE 2.5267665647982134 Test RE 0.7597848351181437\n",
      "81 Train Loss 0.96731544 Test MSE 2.5329122691305734 Test RE 0.760708263736668\n",
      "82 Train Loss 0.96081984 Test MSE 2.536500985842928 Test RE 0.7612469717289497\n",
      "83 Train Loss 0.9528166 Test MSE 2.521965922827347 Test RE 0.7590627286262822\n",
      "84 Train Loss 0.944791 Test MSE 2.5263371507202463 Test RE 0.7597202711469602\n",
      "85 Train Loss 0.9355402 Test MSE 2.5362442465736366 Test RE 0.7612084448491714\n",
      "86 Train Loss 0.92845315 Test MSE 2.526753908321322 Test RE 0.7597829322491998\n",
      "87 Train Loss 0.92394996 Test MSE 2.520070355523992 Test RE 0.7587774105442258\n",
      "88 Train Loss 0.9190011 Test MSE 2.5280524873209766 Test RE 0.7599781454480922\n",
      "89 Train Loss 0.91137564 Test MSE 2.5358363640894894 Test RE 0.7611472330640744\n",
      "90 Train Loss 0.9026696 Test MSE 2.526302814117537 Test RE 0.7597151082767254\n",
      "91 Train Loss 0.8931634 Test MSE 2.532217279194094 Test RE 0.7606038935883355\n",
      "92 Train Loss 0.88406885 Test MSE 2.5439878417834128 Test RE 0.7623696101636777\n",
      "93 Train Loss 0.87265813 Test MSE 2.532862045166202 Test RE 0.7607007218303424\n",
      "94 Train Loss 0.86367 Test MSE 2.535035953850746 Test RE 0.7610270995000511\n",
      "95 Train Loss 0.8544366 Test MSE 2.5541348981426046 Test RE 0.7638885067516037\n",
      "96 Train Loss 0.8456981 Test MSE 2.547666005305633 Test RE 0.762920537964748\n",
      "97 Train Loss 0.84097934 Test MSE 2.5400312963093596 Test RE 0.7617765405563754\n",
      "98 Train Loss 0.83505887 Test MSE 2.5367318967465824 Test RE 0.7612816210799181\n",
      "99 Train Loss 0.8288505 Test MSE 2.530875121683964 Test RE 0.7604022944713839\n",
      "Training time: 84.97\n",
      "0\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 49.52638 Test MSE 6.760249395016325 Test RE 1.2427661604999176\n",
      "1 Train Loss 33.10938 Test MSE 6.814091767725787 Test RE 1.2477053845464943\n",
      "2 Train Loss 24.106462 Test MSE 5.79676110442347 Test RE 1.1508024070399299\n",
      "3 Train Loss 19.294558 Test MSE 6.1935693115942065 Test RE 1.189538660437977\n",
      "4 Train Loss 16.440084 Test MSE 5.630768050378779 Test RE 1.1342058400165582\n",
      "5 Train Loss 14.575205 Test MSE 5.880563008227398 Test RE 1.1590909477728935\n",
      "6 Train Loss 13.011322 Test MSE 5.941076153136871 Test RE 1.1650394189216988\n",
      "7 Train Loss 11.679895 Test MSE 5.969113043429636 Test RE 1.1677851871493528\n",
      "8 Train Loss 10.95804 Test MSE 5.881265555460038 Test RE 1.1591601836450864\n",
      "9 Train Loss 10.165307 Test MSE 5.979150915721965 Test RE 1.1687666692021859\n",
      "10 Train Loss 9.692341 Test MSE 5.766616357494717 Test RE 1.147806262764885\n",
      "11 Train Loss 9.168226 Test MSE 5.797831561799197 Test RE 1.1509086584479362\n",
      "12 Train Loss 8.773635 Test MSE 5.736190087197227 Test RE 1.1447741855606186\n",
      "13 Train Loss 8.33063 Test MSE 5.60984925619252 Test RE 1.132097042815997\n",
      "14 Train Loss 7.8572474 Test MSE 5.5955407639677786 Test RE 1.1306523565834126\n",
      "15 Train Loss 7.1208606 Test MSE 5.344489870328639 Test RE 1.104997230198197\n",
      "16 Train Loss 6.5722656 Test MSE 5.2434346424831215 Test RE 1.094500564270812\n",
      "17 Train Loss 6.242872 Test MSE 5.064343264218306 Test RE 1.075646646688289\n",
      "18 Train Loss 6.007019 Test MSE 5.05866858876904 Test RE 1.0750438383724155\n",
      "19 Train Loss 5.772644 Test MSE 4.87965380142779 Test RE 1.055850830357765\n",
      "20 Train Loss 5.5306435 Test MSE 4.682678183812956 Test RE 1.0343206997966918\n",
      "21 Train Loss 5.353256 Test MSE 4.618763479694382 Test RE 1.0272376340142249\n",
      "22 Train Loss 5.168355 Test MSE 4.420190757380312 Test RE 1.0049132356870092\n",
      "23 Train Loss 4.9548883 Test MSE 4.064896350187479 Test RE 0.9636798946078328\n",
      "24 Train Loss 4.6041718 Test MSE 3.7008117958919797 Test RE 0.9195102189602067\n",
      "25 Train Loss 4.1647606 Test MSE 3.178647021926988 Test RE 0.8521758296575944\n",
      "26 Train Loss 3.6537173 Test MSE 2.6651734909052833 Test RE 0.7803165223746025\n",
      "27 Train Loss 3.1475651 Test MSE 2.558051799916835 Test RE 0.7644740141970598\n",
      "28 Train Loss 2.663751 Test MSE 2.3079742261916585 Test RE 0.7261453114864147\n",
      "29 Train Loss 2.3503013 Test MSE 2.064407845175648 Test RE 0.6867612946757924\n",
      "30 Train Loss 2.1605585 Test MSE 1.9334361480333067 Test RE 0.6646193437778362\n",
      "31 Train Loss 1.9643183 Test MSE 1.805665217784738 Test RE 0.642283368617295\n",
      "32 Train Loss 1.6981379 Test MSE 1.6807782985810011 Test RE 0.6196740024145636\n",
      "33 Train Loss 1.5009986 Test MSE 1.5488134763782533 Test RE 0.5948502106149036\n",
      "34 Train Loss 1.2962843 Test MSE 1.3098462370501298 Test RE 0.5470389107188316\n",
      "35 Train Loss 1.1641777 Test MSE 1.1831093374503872 Test RE 0.5199008186151172\n",
      "36 Train Loss 1.0127233 Test MSE 1.033678305737145 Test RE 0.4859602659889398\n",
      "37 Train Loss 0.84615564 Test MSE 0.7529180403373298 Test RE 0.41474571894679374\n",
      "38 Train Loss 0.73100877 Test MSE 0.6702824591178075 Test RE 0.3913244535313307\n",
      "39 Train Loss 0.6285209 Test MSE 0.5157969586220799 Test RE 0.34327916788152035\n",
      "40 Train Loss 0.532493 Test MSE 0.38437769521240794 Test RE 0.29633786624470637\n",
      "41 Train Loss 0.43866995 Test MSE 0.3179529549545594 Test RE 0.2695190660554082\n",
      "42 Train Loss 0.36339056 Test MSE 0.20108007016781435 Test RE 0.21433474289623722\n",
      "43 Train Loss 0.2874931 Test MSE 0.13216338271839254 Test RE 0.17376553155500032\n",
      "44 Train Loss 0.23286335 Test MSE 0.09814334717001805 Test RE 0.14974022901721112\n",
      "45 Train Loss 0.18321414 Test MSE 0.08090701996544392 Test RE 0.13595687161855166\n",
      "46 Train Loss 0.15390874 Test MSE 0.07028598828119875 Test RE 0.12671920457606312\n",
      "47 Train Loss 0.13619584 Test MSE 0.061953939478471706 Test RE 0.11897138676102907\n",
      "48 Train Loss 0.115962446 Test MSE 0.04937362333570399 Test RE 0.10620759143258751\n",
      "49 Train Loss 0.08937955 Test MSE 0.020681862791110506 Test RE 0.06873894883575218\n",
      "50 Train Loss 0.076713555 Test MSE 0.014212787383312516 Test RE 0.056983312272691884\n",
      "51 Train Loss 0.064836286 Test MSE 0.008930063584938027 Test RE 0.0451684654254141\n",
      "52 Train Loss 0.057436194 Test MSE 0.008370236237037407 Test RE 0.04372974229605325\n",
      "53 Train Loss 0.050411247 Test MSE 0.00850603366618485 Test RE 0.044083047386200225\n",
      "54 Train Loss 0.044715334 Test MSE 0.009934040932442495 Test RE 0.04763992102380514\n",
      "55 Train Loss 0.03954224 Test MSE 0.009905975757190303 Test RE 0.047572578418664885\n",
      "56 Train Loss 0.03316124 Test MSE 0.006298702310477679 Test RE 0.03793443341561673\n",
      "57 Train Loss 0.030423174 Test MSE 0.005567851621329062 Test RE 0.03566579318171316\n",
      "58 Train Loss 0.028437108 Test MSE 0.006125277497552303 Test RE 0.037408556015364844\n",
      "59 Train Loss 0.026615093 Test MSE 0.005942679713259292 Test RE 0.03684675293705725\n",
      "60 Train Loss 0.024373287 Test MSE 0.005482159296811779 Test RE 0.03539027079140886\n",
      "61 Train Loss 0.02276927 Test MSE 0.005525788434800281 Test RE 0.03553081642842136\n",
      "62 Train Loss 0.020801932 Test MSE 0.005257289874921184 Test RE 0.03465684484982886\n",
      "63 Train Loss 0.019361481 Test MSE 0.004941212754512911 Test RE 0.03359888282380355\n",
      "64 Train Loss 0.018041855 Test MSE 0.004936241522889157 Test RE 0.0335819770691941\n",
      "65 Train Loss 0.017362922 Test MSE 0.005097024996479507 Test RE 0.03412451141548654\n",
      "66 Train Loss 0.016812552 Test MSE 0.005026542318378048 Test RE 0.0338877497949554\n",
      "67 Train Loss 0.015380108 Test MSE 0.00463852385710395 Test RE 0.032553520153565295\n",
      "68 Train Loss 0.0145924715 Test MSE 0.004219734697434901 Test RE 0.03104921565151821\n",
      "69 Train Loss 0.013736719 Test MSE 0.003674541702216142 Test RE 0.028974079708795564\n",
      "70 Train Loss 0.0131166335 Test MSE 0.003457673143955875 Test RE 0.028106063857596293\n",
      "71 Train Loss 0.012384969 Test MSE 0.0031337531196479213 Test RE 0.0267571867591568\n",
      "72 Train Loss 0.011391089 Test MSE 0.002698210548217329 Test RE 0.024828242478629785\n",
      "73 Train Loss 0.0107066315 Test MSE 0.0026668372697498696 Test RE 0.02468347599532146\n",
      "74 Train Loss 0.010053138 Test MSE 0.0027028663465005582 Test RE 0.02484965397790218\n",
      "75 Train Loss 0.009705943 Test MSE 0.0027447450240314555 Test RE 0.025041426407635865\n",
      "76 Train Loss 0.009079656 Test MSE 0.0025802044073710124 Test RE 0.024279241594360224\n",
      "77 Train Loss 0.008513025 Test MSE 0.0024588442292246097 Test RE 0.02370137646552597\n",
      "78 Train Loss 0.007988512 Test MSE 0.002287289223917835 Test RE 0.02285959870712113\n",
      "79 Train Loss 0.007232734 Test MSE 0.0020540519307507424 Test RE 0.02166275908677104\n",
      "80 Train Loss 0.00667087 Test MSE 0.001970677231300262 Test RE 0.021218555241453857\n",
      "81 Train Loss 0.0062715616 Test MSE 0.0019082818053482247 Test RE 0.020879943301781723\n",
      "82 Train Loss 0.0056888945 Test MSE 0.001650550352557211 Test RE 0.019418802695745637\n",
      "83 Train Loss 0.0054976344 Test MSE 0.0015453924995756153 Test RE 0.018790029430631256\n",
      "84 Train Loss 0.00535604 Test MSE 0.0016082026141772104 Test RE 0.019168072446634835\n",
      "85 Train Loss 0.005108876 Test MSE 0.001890195737909862 Test RE 0.020780761120015263\n",
      "86 Train Loss 0.0048115347 Test MSE 0.002069783588489179 Test RE 0.021745556672638732\n",
      "87 Train Loss 0.0046110745 Test MSE 0.0020499574016041187 Test RE 0.021641157138905836\n",
      "88 Train Loss 0.0044971663 Test MSE 0.002075810721881033 Test RE 0.021777194786211915\n",
      "89 Train Loss 0.0044224486 Test MSE 0.002100836564599242 Test RE 0.021908073742120004\n",
      "90 Train Loss 0.004313904 Test MSE 0.0021244150352197405 Test RE 0.022030671943121333\n",
      "91 Train Loss 0.004158793 Test MSE 0.0020190358080252376 Test RE 0.02147731915970336\n",
      "92 Train Loss 0.0040489384 Test MSE 0.0018459603315543133 Test RE 0.02053616014200447\n",
      "93 Train Loss 0.0039015147 Test MSE 0.001632504137727802 Test RE 0.019312353648107135\n",
      "94 Train Loss 0.0036734608 Test MSE 0.0014599657388074778 Test RE 0.018263305860045733\n",
      "95 Train Loss 0.0035113124 Test MSE 0.0014255723127758464 Test RE 0.01804690309191492\n",
      "96 Train Loss 0.0033323555 Test MSE 0.0014515964349161971 Test RE 0.018210883108266074\n",
      "97 Train Loss 0.0032020586 Test MSE 0.00146598988812514 Test RE 0.01830094634002096\n",
      "98 Train Loss 0.0030714348 Test MSE 0.0014408132568267862 Test RE 0.01814311728937272\n",
      "99 Train Loss 0.002969021 Test MSE 0.001419137955125774 Test RE 0.018006129448803074\n",
      "Training time: 84.66\n",
      "1\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.447197 Test MSE 9.229815145640337 Test RE 1.4521268706180486\n",
      "1 Train Loss 41.22784 Test MSE 9.962363583863278 Test RE 1.5086526295737819\n",
      "2 Train Loss 36.737953 Test MSE 9.954384229103038 Test RE 1.5080483309111383\n",
      "3 Train Loss 34.286755 Test MSE 9.77394781287596 Test RE 1.494318138859662\n",
      "4 Train Loss 31.0454 Test MSE 9.655954651197156 Test RE 1.4852708888300148\n",
      "5 Train Loss 29.067669 Test MSE 9.301544945748718 Test RE 1.4577585749866464\n",
      "6 Train Loss 26.094028 Test MSE 8.894340414507411 Test RE 1.4254924908928976\n",
      "7 Train Loss 23.187786 Test MSE 8.641697356766889 Test RE 1.4051011415900276\n",
      "8 Train Loss 21.291882 Test MSE 8.617794050486177 Test RE 1.4031565108536492\n",
      "9 Train Loss 18.514008 Test MSE 8.078802901833186 Test RE 1.3585685811250778\n",
      "10 Train Loss 16.510895 Test MSE 7.751725604829073 Test RE 1.3307830352533103\n",
      "11 Train Loss 15.665512 Test MSE 7.92435219592369 Test RE 1.3455193413957622\n",
      "12 Train Loss 14.892055 Test MSE 7.98762642391432 Test RE 1.3508805003339908\n",
      "13 Train Loss 14.403679 Test MSE 8.055907914558096 Test RE 1.3566421522231502\n",
      "14 Train Loss 14.058128 Test MSE 7.952504622053449 Test RE 1.3479073000147137\n",
      "15 Train Loss 13.683058 Test MSE 8.053508281898452 Test RE 1.356440084044541\n",
      "16 Train Loss 13.284651 Test MSE 8.183877947211293 Test RE 1.3673749899966423\n",
      "17 Train Loss 12.875751 Test MSE 8.278196963137937 Test RE 1.3752319007251859\n",
      "18 Train Loss 12.565833 Test MSE 8.363462834905489 Test RE 1.3822962376546202\n",
      "19 Train Loss 12.135895 Test MSE 8.384682156444613 Test RE 1.3840486701082617\n",
      "20 Train Loss 11.810858 Test MSE 8.319366724177957 Test RE 1.378647363614085\n",
      "21 Train Loss 10.757668 Test MSE 7.45317193046728 Test RE 1.3049042034936633\n",
      "22 Train Loss 9.011751 Test MSE 6.743480986716396 Test RE 1.2412238986802344\n",
      "23 Train Loss 8.265323 Test MSE 6.505598552397709 Test RE 1.2191346936961625\n",
      "24 Train Loss 7.8660097 Test MSE 6.450554992378236 Test RE 1.2139662175775952\n",
      "25 Train Loss 7.4673667 Test MSE 6.340448156261211 Test RE 1.203560810725739\n",
      "26 Train Loss 7.2146893 Test MSE 6.418023032373225 Test RE 1.2109011619632837\n",
      "27 Train Loss 6.985191 Test MSE 6.4777008824378575 Test RE 1.2165179046781338\n",
      "28 Train Loss 6.686165 Test MSE 6.346671124084916 Test RE 1.2041512960652163\n",
      "29 Train Loss 6.3940544 Test MSE 6.295248395034957 Test RE 1.1992631680471446\n",
      "30 Train Loss 5.774475 Test MSE 6.135106356029664 Test RE 1.1839111431678642\n",
      "31 Train Loss 4.6139393 Test MSE 5.593282159169988 Test RE 1.1304241431994988\n",
      "32 Train Loss 3.77416 Test MSE 5.318518738541219 Test RE 1.1023091366370694\n",
      "33 Train Loss 3.25091 Test MSE 5.2170400838723605 Test RE 1.0917423238750226\n",
      "34 Train Loss 2.9309492 Test MSE 5.249888313213183 Test RE 1.0951739181507776\n",
      "35 Train Loss 2.6993008 Test MSE 5.387948683252525 Test RE 1.1094807862822162\n",
      "36 Train Loss 2.5505862 Test MSE 5.538857872192338 Test RE 1.1249110189838065\n",
      "37 Train Loss 2.3499477 Test MSE 5.555825442912364 Test RE 1.1266327107489853\n",
      "38 Train Loss 2.2689512 Test MSE 5.605129622092306 Test RE 1.1316207191362315\n",
      "39 Train Loss 2.1677504 Test MSE 5.626664250295198 Test RE 1.1337924503716426\n",
      "40 Train Loss 2.0844533 Test MSE 5.62633680305577 Test RE 1.1337594590118434\n",
      "41 Train Loss 2.0153224 Test MSE 5.654847041276186 Test RE 1.1366283689630168\n",
      "42 Train Loss 1.9508212 Test MSE 5.617190686951161 Test RE 1.1328375702611855\n",
      "43 Train Loss 1.9012469 Test MSE 5.595308079708562 Test RE 1.130628847886738\n",
      "44 Train Loss 1.8430376 Test MSE 5.536052347072236 Test RE 1.1246260896776876\n",
      "45 Train Loss 1.8077124 Test MSE 5.5192043150919 Test RE 1.1229134817428332\n",
      "46 Train Loss 1.7608017 Test MSE 5.5177880676011375 Test RE 1.122769400699279\n",
      "47 Train Loss 1.7061284 Test MSE 5.4271575252780595 Test RE 1.1135103905502979\n",
      "48 Train Loss 1.67688 Test MSE 5.469569498711865 Test RE 1.1178528355833417\n",
      "49 Train Loss 1.6344056 Test MSE 5.442207726929303 Test RE 1.1150532749716375\n",
      "50 Train Loss 1.6127988 Test MSE 5.413676041297926 Test RE 1.1121265071248216\n",
      "51 Train Loss 1.5708624 Test MSE 5.455358034425697 Test RE 1.116399644582111\n",
      "52 Train Loss 1.5431451 Test MSE 5.412835708281424 Test RE 1.112040189354366\n",
      "53 Train Loss 1.5040865 Test MSE 5.429833378224549 Test RE 1.1137848641458576\n",
      "54 Train Loss 1.4620496 Test MSE 5.470708851939443 Test RE 1.1179692581753484\n",
      "55 Train Loss 1.4290758 Test MSE 5.535412109552638 Test RE 1.1245610569981022\n",
      "56 Train Loss 1.400003 Test MSE 5.5784085633499405 Test RE 1.128920136806683\n",
      "57 Train Loss 1.3664759 Test MSE 5.553739327453545 Test RE 1.1264211754332418\n",
      "58 Train Loss 1.3280151 Test MSE 5.548043619506809 Test RE 1.1258434194882332\n",
      "59 Train Loss 1.2957065 Test MSE 5.592566824237135 Test RE 1.1303518548979652\n",
      "60 Train Loss 1.2646649 Test MSE 5.598899716605539 Test RE 1.130991665874443\n",
      "61 Train Loss 1.2333679 Test MSE 5.641692747319554 Test RE 1.1353055879252334\n",
      "62 Train Loss 1.2118491 Test MSE 5.6681091802320385 Test RE 1.1379604381940387\n",
      "63 Train Loss 1.1884015 Test MSE 5.632247395370472 Test RE 1.1343548224931017\n",
      "64 Train Loss 1.1653434 Test MSE 5.660992463871656 Test RE 1.1372458184608933\n",
      "65 Train Loss 1.1446455 Test MSE 5.701069051992751 Test RE 1.141264243866879\n",
      "66 Train Loss 1.1258318 Test MSE 5.713981918990703 Test RE 1.1425559891435957\n",
      "67 Train Loss 1.1069688 Test MSE 5.7294515996213375 Test RE 1.1441015863853983\n",
      "68 Train Loss 1.0898641 Test MSE 5.739982659647801 Test RE 1.1451525657723682\n",
      "69 Train Loss 1.0794398 Test MSE 5.721395729837397 Test RE 1.1432969739974983\n",
      "70 Train Loss 1.0663564 Test MSE 5.69671772967762 Test RE 1.1408286276288768\n",
      "71 Train Loss 1.0554824 Test MSE 5.701406317161805 Test RE 1.1412980009554332\n",
      "72 Train Loss 1.0433298 Test MSE 5.707881046181111 Test RE 1.141945867296747\n",
      "73 Train Loss 1.0291545 Test MSE 5.716601607410863 Test RE 1.1428178728657534\n",
      "74 Train Loss 1.0212647 Test MSE 5.745256065983226 Test RE 1.1456784792458041\n",
      "75 Train Loss 1.0087669 Test MSE 5.760595079954929 Test RE 1.147206858824905\n",
      "76 Train Loss 0.9998287 Test MSE 5.745698735638166 Test RE 1.1457226154272535\n",
      "77 Train Loss 0.9882558 Test MSE 5.759673092766421 Test RE 1.1471150495294318\n",
      "78 Train Loss 0.97523147 Test MSE 5.78798544560125 Test RE 1.1499309829616877\n",
      "79 Train Loss 0.966562 Test MSE 5.808850230250631 Test RE 1.1520017793225767\n",
      "80 Train Loss 0.95890653 Test MSE 5.810916571527806 Test RE 1.152206657833642\n",
      "81 Train Loss 0.9491131 Test MSE 5.807179446986016 Test RE 1.1518360938909011\n",
      "82 Train Loss 0.942938 Test MSE 5.8253285710417675 Test RE 1.1536346011022924\n",
      "83 Train Loss 0.9363671 Test MSE 5.857405821250105 Test RE 1.1568064928124873\n",
      "84 Train Loss 0.93251127 Test MSE 5.860523073646231 Test RE 1.1571142722520817\n",
      "85 Train Loss 0.929664 Test MSE 5.857653796347443 Test RE 1.1568309794346718\n",
      "86 Train Loss 0.9247915 Test MSE 5.86060311086436 Test RE 1.1571221735852943\n",
      "87 Train Loss 0.92155755 Test MSE 5.876238176958494 Test RE 1.1586646454971012\n",
      "88 Train Loss 0.9157872 Test MSE 5.872164640290174 Test RE 1.1582629700510747\n",
      "89 Train Loss 0.9115701 Test MSE 5.8486742324090315 Test RE 1.1559439500707867\n",
      "90 Train Loss 0.90665054 Test MSE 5.84852411718558 Test RE 1.1559291154355409\n",
      "91 Train Loss 0.9029596 Test MSE 5.8757318630015964 Test RE 1.1586147274456977\n",
      "92 Train Loss 0.89937025 Test MSE 5.891646886657244 Test RE 1.1601827798914834\n",
      "93 Train Loss 0.89642733 Test MSE 5.893685731703769 Test RE 1.1603835071542639\n",
      "94 Train Loss 0.89230335 Test MSE 5.903627134920041 Test RE 1.161361755768281\n",
      "95 Train Loss 0.88884753 Test MSE 5.916018886634153 Test RE 1.162579969779165\n",
      "96 Train Loss 0.88621473 Test MSE 5.928639582238205 Test RE 1.1638193802045607\n",
      "97 Train Loss 0.8823594 Test MSE 5.941821336390349 Test RE 1.1651124814966096\n",
      "98 Train Loss 0.87875915 Test MSE 5.942910093122644 Test RE 1.1652192219960067\n",
      "99 Train Loss 0.8749192 Test MSE 5.9445865814525165 Test RE 1.165383563930165\n",
      "Training time: 84.64\n",
      "2\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.780098 Test MSE 8.312912865336036 Test RE 1.3781125078943453\n",
      "1 Train Loss 47.673843 Test MSE 8.445830770649698 Test RE 1.3890863633930255\n",
      "2 Train Loss 35.21492 Test MSE 6.347246340890513 Test RE 1.2042058626525647\n",
      "3 Train Loss 25.761509 Test MSE 6.0417467199687005 Test RE 1.1748686566332316\n",
      "4 Train Loss 21.495558 Test MSE 5.488105467659285 Test RE 1.119745394045765\n",
      "5 Train Loss 17.904385 Test MSE 5.942068624227861 Test RE 1.1651367261795122\n",
      "6 Train Loss 14.617432 Test MSE 5.461314147702899 Test RE 1.1170089161233765\n",
      "7 Train Loss 13.156969 Test MSE 5.749277028685315 Test RE 1.1460793251461858\n",
      "8 Train Loss 12.160065 Test MSE 5.5810857308208295 Test RE 1.1291909977257641\n",
      "9 Train Loss 11.272681 Test MSE 5.709814485979204 Test RE 1.1421392575085356\n",
      "10 Train Loss 10.672527 Test MSE 5.661719288691344 Test RE 1.1373188226171835\n",
      "11 Train Loss 10.187746 Test MSE 5.615335120196539 Test RE 1.132650445639967\n",
      "12 Train Loss 9.849395 Test MSE 5.554884123272414 Test RE 1.1265372644077354\n",
      "13 Train Loss 9.570938 Test MSE 5.621903064050317 Test RE 1.133312651042254\n",
      "14 Train Loss 8.945074 Test MSE 5.634452325117971 Test RE 1.1345768411450678\n",
      "15 Train Loss 8.302673 Test MSE 5.614134037558678 Test RE 1.132529305983191\n",
      "16 Train Loss 7.77048 Test MSE 5.526581032280343 Test RE 1.1236636486825216\n",
      "17 Train Loss 7.47321 Test MSE 5.493150200961235 Test RE 1.1202599176271093\n",
      "18 Train Loss 7.0923004 Test MSE 5.465563525346583 Test RE 1.1174433966926236\n",
      "19 Train Loss 6.693128 Test MSE 5.303002106781922 Test RE 1.1006999838603218\n",
      "20 Train Loss 6.464719 Test MSE 5.197071043511872 Test RE 1.0896509130432186\n",
      "21 Train Loss 6.241131 Test MSE 5.049231734707421 Test RE 1.0740406329443752\n",
      "22 Train Loss 6.0577784 Test MSE 5.012857306496881 Test RE 1.0701649711752712\n",
      "23 Train Loss 5.947475 Test MSE 4.9941414926493986 Test RE 1.068165339325788\n",
      "24 Train Loss 5.802017 Test MSE 4.893629746249189 Test RE 1.057361794303147\n",
      "25 Train Loss 5.7013016 Test MSE 4.885784524221565 Test RE 1.056513899615026\n",
      "26 Train Loss 5.5930796 Test MSE 4.80581232304786 Test RE 1.0478315326261498\n",
      "27 Train Loss 5.482094 Test MSE 4.659126153081658 Test RE 1.0317163076119673\n",
      "28 Train Loss 5.3986692 Test MSE 4.520165623893012 Test RE 1.0162141418445891\n",
      "29 Train Loss 5.3146915 Test MSE 4.453844162593479 Test RE 1.0087314674956\n",
      "30 Train Loss 5.208523 Test MSE 4.299460883773265 Test RE 0.9910944892236571\n",
      "31 Train Loss 5.114786 Test MSE 4.185534844754327 Test RE 0.9778754456572403\n",
      "32 Train Loss 5.033464 Test MSE 4.048618817473378 Test RE 0.961748471906721\n",
      "33 Train Loss 4.9213023 Test MSE 3.8328584186064267 Test RE 0.9357707130344455\n",
      "34 Train Loss 4.778624 Test MSE 3.577157540243014 Test RE 0.9040180333439665\n",
      "35 Train Loss 4.6380863 Test MSE 3.367855206566612 Test RE 0.8771720119508875\n",
      "36 Train Loss 4.4450426 Test MSE 3.167374176811199 Test RE 0.8506633971110978\n",
      "37 Train Loss 4.0049996 Test MSE 2.779356723955295 Test RE 0.7968566582479255\n",
      "38 Train Loss 3.5555348 Test MSE 2.5376653028062255 Test RE 0.7614216673191618\n",
      "39 Train Loss 3.2843049 Test MSE 2.3858561908856384 Test RE 0.738295449492447\n",
      "40 Train Loss 2.7213116 Test MSE 2.2258916093181047 Test RE 0.7131158124072946\n",
      "41 Train Loss 2.3684762 Test MSE 2.068191692584068 Test RE 0.6873903879771673\n",
      "42 Train Loss 2.1294906 Test MSE 2.062274135203165 Test RE 0.6864062949944837\n",
      "43 Train Loss 2.0013103 Test MSE 2.015129751235705 Test RE 0.6785151791459992\n",
      "44 Train Loss 1.8209261 Test MSE 1.9869602802144557 Test RE 0.6737560113567918\n",
      "45 Train Loss 1.7061652 Test MSE 1.9094001748948872 Test RE 0.6604752368496802\n",
      "46 Train Loss 1.5859619 Test MSE 1.7810348295321854 Test RE 0.6378877566103878\n",
      "47 Train Loss 1.5086375 Test MSE 1.6731365355933032 Test RE 0.618263704405451\n",
      "48 Train Loss 1.4142704 Test MSE 1.495552633991285 Test RE 0.5845328342899812\n",
      "49 Train Loss 1.3067201 Test MSE 1.2912730241511736 Test RE 0.5431466427271304\n",
      "50 Train Loss 1.0991793 Test MSE 1.0572602572578766 Test RE 0.4914722642760888\n",
      "51 Train Loss 0.93613553 Test MSE 1.0471467443339926 Test RE 0.48911595940510527\n",
      "52 Train Loss 0.8281193 Test MSE 0.984506726188932 Test RE 0.47426099059275073\n",
      "53 Train Loss 0.6919874 Test MSE 0.8315682812740893 Test RE 0.435870039721263\n",
      "54 Train Loss 0.62288696 Test MSE 0.7931003468326265 Test RE 0.42566910488959436\n",
      "55 Train Loss 0.54439473 Test MSE 0.759278177757994 Test RE 0.41649377940223914\n",
      "56 Train Loss 0.47000378 Test MSE 0.7337644585156363 Test RE 0.4094363493266449\n",
      "57 Train Loss 0.38800693 Test MSE 0.6273791780399539 Test RE 0.3785934628221771\n",
      "58 Train Loss 0.34535658 Test MSE 0.5964246071729089 Test RE 0.3691355197948215\n",
      "59 Train Loss 0.31249553 Test MSE 0.5724527399644277 Test RE 0.36164118153702396\n",
      "60 Train Loss 0.28438386 Test MSE 0.513060445725559 Test RE 0.34236733898330535\n",
      "61 Train Loss 0.2576053 Test MSE 0.5081516571581292 Test RE 0.34072557521668156\n",
      "62 Train Loss 0.23106672 Test MSE 0.4986523816444295 Test RE 0.3375258262704294\n",
      "63 Train Loss 0.21823078 Test MSE 0.474181975966409 Test RE 0.32913993672927955\n",
      "64 Train Loss 0.2049513 Test MSE 0.4551736081444279 Test RE 0.3224754048918186\n",
      "65 Train Loss 0.19149557 Test MSE 0.4501483353162811 Test RE 0.3206903447341177\n",
      "66 Train Loss 0.17938311 Test MSE 0.4264801809481828 Test RE 0.3121457938220917\n",
      "67 Train Loss 0.17207694 Test MSE 0.4167093604694715 Test RE 0.3085493872644174\n",
      "68 Train Loss 0.16542521 Test MSE 0.414837848642586 Test RE 0.3078557339620218\n",
      "69 Train Loss 0.15933456 Test MSE 0.3993859267313715 Test RE 0.30206780448140647\n",
      "70 Train Loss 0.15579432 Test MSE 0.39935201748046717 Test RE 0.3020549809068761\n",
      "71 Train Loss 0.1488951 Test MSE 0.396758316221571 Test RE 0.3010724935714398\n",
      "72 Train Loss 0.1456532 Test MSE 0.39008905713193337 Test RE 0.2985313494183107\n",
      "73 Train Loss 0.14294015 Test MSE 0.38678051781060974 Test RE 0.2972626571564451\n",
      "74 Train Loss 0.14047493 Test MSE 0.38560219697757575 Test RE 0.29680950873450107\n",
      "75 Train Loss 0.1380243 Test MSE 0.38721313952287983 Test RE 0.29742885779590017\n",
      "76 Train Loss 0.13459194 Test MSE 0.3962903681205483 Test RE 0.300894894436496\n",
      "77 Train Loss 0.13148405 Test MSE 0.3992980150893452 Test RE 0.3020345575185121\n",
      "78 Train Loss 0.12876338 Test MSE 0.39238495969277815 Test RE 0.2994085764778185\n",
      "79 Train Loss 0.12691948 Test MSE 0.3891589957003105 Test RE 0.2981752535685616\n",
      "80 Train Loss 0.12530008 Test MSE 0.39318384809653856 Test RE 0.2997132166136952\n",
      "81 Train Loss 0.12379992 Test MSE 0.4003512863472577 Test RE 0.3024326496638284\n",
      "82 Train Loss 0.12190404 Test MSE 0.40925224899614865 Test RE 0.3057761425629285\n",
      "83 Train Loss 0.12052665 Test MSE 0.41638603516527023 Test RE 0.30842966211206246\n",
      "84 Train Loss 0.1191833 Test MSE 0.42302136156570946 Test RE 0.3108774419317333\n",
      "85 Train Loss 0.11764453 Test MSE 0.42426461858730147 Test RE 0.3113339401532327\n",
      "86 Train Loss 0.116445616 Test MSE 0.4265080899367815 Test RE 0.31215600711132646\n",
      "87 Train Loss 0.11520647 Test MSE 0.42740966022387533 Test RE 0.31248575702662007\n",
      "88 Train Loss 0.1140983 Test MSE 0.4262942903339682 Test RE 0.31207775865871373\n",
      "89 Train Loss 0.11313796 Test MSE 0.42798577724789827 Test RE 0.31269629010029026\n",
      "90 Train Loss 0.11229936 Test MSE 0.4339438548166369 Test RE 0.3148653218230492\n",
      "91 Train Loss 0.1115624 Test MSE 0.44035529100833853 Test RE 0.3171828300216551\n",
      "92 Train Loss 0.11047229 Test MSE 0.45095167280430887 Test RE 0.32097637016119185\n",
      "93 Train Loss 0.10989271 Test MSE 0.4545800476250399 Test RE 0.32226507733017734\n",
      "94 Train Loss 0.10918849 Test MSE 0.4563284410839898 Test RE 0.3228842261662842\n",
      "95 Train Loss 0.108190216 Test MSE 0.4561537699649424 Test RE 0.3228224242468214\n",
      "96 Train Loss 0.106780216 Test MSE 0.4570872106847617 Test RE 0.32315255589920894\n",
      "97 Train Loss 0.10583623 Test MSE 0.4561374580135039 Test RE 0.3228166521682683\n",
      "98 Train Loss 0.10488799 Test MSE 0.4542378257166595 Test RE 0.32214374893612374\n",
      "99 Train Loss 0.104038596 Test MSE 0.4538976329652948 Test RE 0.32202309463480483\n",
      "Training time: 85.26\n",
      "3\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.80178 Test MSE 7.07917415196907 Test RE 1.2717430076774043\n",
      "1 Train Loss 47.239803 Test MSE 8.189601984437884 Test RE 1.3678530969090514\n",
      "2 Train Loss 37.019543 Test MSE 8.175052465427694 Test RE 1.366637503541082\n",
      "3 Train Loss 30.734592 Test MSE 8.746118847584526 Test RE 1.4135648830619147\n",
      "4 Train Loss 28.267706 Test MSE 8.710365983412386 Test RE 1.410672700312143\n",
      "5 Train Loss 25.489517 Test MSE 8.99073746285933 Test RE 1.433196432065749\n",
      "6 Train Loss 23.849052 Test MSE 8.792102843978997 Test RE 1.4172760233372257\n",
      "7 Train Loss 22.135857 Test MSE 8.962526576048191 Test RE 1.4309461434354998\n",
      "8 Train Loss 20.2767 Test MSE 8.83017397648179 Test RE 1.4203412182934003\n",
      "9 Train Loss 18.823793 Test MSE 8.844388027980134 Test RE 1.4214839299353417\n",
      "10 Train Loss 17.19738 Test MSE 8.268063608794936 Test RE 1.3743899311809669\n",
      "11 Train Loss 15.239473 Test MSE 7.943726852647965 Test RE 1.3471632019799373\n",
      "12 Train Loss 14.462374 Test MSE 8.316789174221459 Test RE 1.378433777180399\n",
      "13 Train Loss 13.919874 Test MSE 8.008848624032556 Test RE 1.3526738765963264\n",
      "14 Train Loss 13.536629 Test MSE 8.138260818264557 Test RE 1.3635587744034448\n",
      "15 Train Loss 13.220604 Test MSE 8.228624533191446 Test RE 1.371108058583979\n",
      "16 Train Loss 12.838411 Test MSE 8.429397951762525 Test RE 1.3877343520079828\n",
      "17 Train Loss 12.546698 Test MSE 8.403816431357882 Test RE 1.3856270052025181\n",
      "18 Train Loss 12.214703 Test MSE 8.256739023383496 Test RE 1.373448372787913\n",
      "19 Train Loss 11.600655 Test MSE 8.129090522410689 Test RE 1.3627903201769112\n",
      "20 Train Loss 10.189532 Test MSE 7.270039195911514 Test RE 1.2887730221937392\n",
      "21 Train Loss 8.295285 Test MSE 6.636666969206347 Test RE 1.2313544177012257\n",
      "22 Train Loss 7.727995 Test MSE 6.818643228567828 Test RE 1.2481220163156572\n",
      "23 Train Loss 7.2596846 Test MSE 6.55009677988928 Test RE 1.2232970226653161\n",
      "24 Train Loss 6.8408513 Test MSE 6.432156132982521 Test RE 1.212233688870205\n",
      "25 Train Loss 6.629345 Test MSE 6.473067226613256 Test RE 1.2160827245274173\n",
      "26 Train Loss 6.4564333 Test MSE 6.379223715977877 Test RE 1.2072354413356332\n",
      "27 Train Loss 6.293154 Test MSE 6.367586313080898 Test RE 1.2061337792042097\n",
      "28 Train Loss 6.1201773 Test MSE 6.337193534607949 Test RE 1.203251870585766\n",
      "29 Train Loss 5.9950185 Test MSE 6.29776727245137 Test RE 1.1995030707966632\n",
      "30 Train Loss 5.8474817 Test MSE 6.372289557263693 Test RE 1.206579135912741\n",
      "31 Train Loss 5.7063956 Test MSE 6.34486927737435 Test RE 1.2039803521146202\n",
      "32 Train Loss 5.589058 Test MSE 6.333000520056939 Test RE 1.202853737926532\n",
      "33 Train Loss 5.420587 Test MSE 6.226121915891815 Test RE 1.1926605948516464\n",
      "34 Train Loss 5.183119 Test MSE 6.052954150425733 Test RE 1.1759578414932943\n",
      "35 Train Loss 4.820763 Test MSE 6.0031698360332895 Test RE 1.1711118497939366\n",
      "36 Train Loss 4.194383 Test MSE 5.399735654352046 Test RE 1.110693703695294\n",
      "37 Train Loss 3.1727788 Test MSE 5.227974207716328 Test RE 1.0928857881253775\n",
      "38 Train Loss 2.6088097 Test MSE 5.151797155290623 Test RE 1.084894325789556\n",
      "39 Train Loss 2.3182073 Test MSE 5.280289792507947 Test RE 1.0983403516597159\n",
      "40 Train Loss 2.0685298 Test MSE 5.247797356467166 Test RE 1.094955800238943\n",
      "41 Train Loss 1.92243 Test MSE 5.291695815643688 Test RE 1.0995259814207021\n",
      "42 Train Loss 1.8250576 Test MSE 5.325658462773172 Test RE 1.1030487733785268\n",
      "43 Train Loss 1.757549 Test MSE 5.317097083170879 Test RE 1.102161801587806\n",
      "44 Train Loss 1.6963553 Test MSE 5.356441379165095 Test RE 1.1062320542503155\n",
      "45 Train Loss 1.6371286 Test MSE 5.322998506522764 Test RE 1.1027732743061336\n",
      "46 Train Loss 1.59899 Test MSE 5.353752952684634 Test RE 1.105954407525477\n",
      "47 Train Loss 1.565397 Test MSE 5.370745052717953 Test RE 1.1077080932570267\n",
      "48 Train Loss 1.5146626 Test MSE 5.374682477861477 Test RE 1.1081140628724355\n",
      "49 Train Loss 1.4833502 Test MSE 5.407923813909885 Test RE 1.1115355126948476\n",
      "50 Train Loss 1.4523789 Test MSE 5.374118680946798 Test RE 1.1080559415157707\n",
      "51 Train Loss 1.4301721 Test MSE 5.360136321677962 Test RE 1.1066135350604018\n",
      "52 Train Loss 1.4064258 Test MSE 5.385676432998338 Test RE 1.1092468119072667\n",
      "53 Train Loss 1.3869581 Test MSE 5.374960087257976 Test RE 1.1081426802749832\n",
      "54 Train Loss 1.3667607 Test MSE 5.379377540070641 Test RE 1.1085979545979983\n",
      "55 Train Loss 1.3420156 Test MSE 5.415769356205028 Test RE 1.1123415002252404\n",
      "56 Train Loss 1.324976 Test MSE 5.411700902932811 Test RE 1.1119236131850654\n",
      "57 Train Loss 1.3074461 Test MSE 5.4063481866049115 Test RE 1.1113735750131675\n",
      "58 Train Loss 1.2829115 Test MSE 5.410655202894304 Test RE 1.1118161797958\n",
      "59 Train Loss 1.2590023 Test MSE 5.435735574170119 Test RE 1.1143900384309662\n",
      "60 Train Loss 1.2376643 Test MSE 5.501816819802945 Test RE 1.1211432940977815\n",
      "61 Train Loss 1.2240329 Test MSE 5.516901479525447 Test RE 1.1226791948106556\n",
      "62 Train Loss 1.2094595 Test MSE 5.511339969626898 Test RE 1.122113173662644\n",
      "63 Train Loss 1.1968931 Test MSE 5.542882169989046 Test RE 1.1253196009569437\n",
      "64 Train Loss 1.1830956 Test MSE 5.573625175682645 Test RE 1.128436018378479\n",
      "65 Train Loss 1.1716512 Test MSE 5.589796178720027 Test RE 1.1300718231718943\n",
      "66 Train Loss 1.1627405 Test MSE 5.58645505473778 Test RE 1.1297340403332323\n",
      "67 Train Loss 1.1487565 Test MSE 5.634909752859126 Test RE 1.1346228949901203\n",
      "68 Train Loss 1.1307284 Test MSE 5.644083958926498 Test RE 1.1355461600745738\n",
      "69 Train Loss 1.1173859 Test MSE 5.625233436674588 Test RE 1.1336482842411648\n",
      "70 Train Loss 1.1090077 Test MSE 5.647070523054129 Test RE 1.1358465571747365\n",
      "71 Train Loss 1.0976304 Test MSE 5.64349824215407 Test RE 1.1354872376973533\n",
      "72 Train Loss 1.0845704 Test MSE 5.653491111606317 Test RE 1.1364920893681714\n",
      "73 Train Loss 1.0734649 Test MSE 5.704123181136223 Test RE 1.1415698972159183\n",
      "74 Train Loss 1.0617156 Test MSE 5.720526442280233 Test RE 1.143210116556233\n",
      "75 Train Loss 1.0507431 Test MSE 5.7383190077089425 Test RE 1.1449866006934322\n",
      "76 Train Loss 1.0408808 Test MSE 5.779655874179389 Test RE 1.149103244110324\n",
      "77 Train Loss 1.031208 Test MSE 5.783139263211677 Test RE 1.149449473262201\n",
      "78 Train Loss 1.0191088 Test MSE 5.769199531915497 Test RE 1.148063315742319\n",
      "79 Train Loss 1.0124345 Test MSE 5.780126461862765 Test RE 1.1491500239566153\n",
      "80 Train Loss 1.0059075 Test MSE 5.79519916387248 Test RE 1.1506473544154556\n",
      "81 Train Loss 0.9985647 Test MSE 5.805446217625627 Test RE 1.1516641907200553\n",
      "82 Train Loss 0.99036926 Test MSE 5.818144716510985 Test RE 1.1529230446894445\n",
      "83 Train Loss 0.9844488 Test MSE 5.829603140294782 Test RE 1.1540577863899038\n",
      "84 Train Loss 0.9789564 Test MSE 5.8421430914157035 Test RE 1.1552983557496748\n",
      "85 Train Loss 0.97289723 Test MSE 5.847002799165139 Test RE 1.1557787655241032\n",
      "86 Train Loss 0.9675999 Test MSE 5.857517252544123 Test RE 1.1568174963040745\n",
      "87 Train Loss 0.96202517 Test MSE 5.877747679178724 Test RE 1.158813456223825\n",
      "88 Train Loss 0.9556131 Test MSE 5.875833826457404 Test RE 1.1586247803082015\n",
      "89 Train Loss 0.94969666 Test MSE 5.86701694568537 Test RE 1.1577551767860628\n",
      "90 Train Loss 0.9428956 Test MSE 5.873942509326132 Test RE 1.158438295859759\n",
      "91 Train Loss 0.9371868 Test MSE 5.884056544301087 Test RE 1.1594351941319423\n",
      "92 Train Loss 0.9319209 Test MSE 5.894872638335838 Test RE 1.1605003438511492\n",
      "93 Train Loss 0.9269378 Test MSE 5.910692736295658 Test RE 1.1620565206390803\n",
      "94 Train Loss 0.91850805 Test MSE 5.911536155737312 Test RE 1.1621394268350569\n",
      "95 Train Loss 0.9125461 Test MSE 5.909792134231701 Test RE 1.1619679869920165\n",
      "96 Train Loss 0.90836287 Test MSE 5.929733580975976 Test RE 1.1639267537583684\n",
      "97 Train Loss 0.9036162 Test MSE 5.936334690432078 Test RE 1.1645744279503059\n",
      "98 Train Loss 0.89776963 Test MSE 5.933324115132431 Test RE 1.1642790871533768\n",
      "99 Train Loss 0.8913166 Test MSE 5.9480681962424375 Test RE 1.1657247838523002\n",
      "Training time: 85.33\n",
      "4\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.32453 Test MSE 8.411204482513654 Test RE 1.386235944863227\n",
      "1 Train Loss 57.006218 Test MSE 8.42112030664222 Test RE 1.3870528090299887\n",
      "2 Train Loss 52.910583 Test MSE 8.359794969200198 Test RE 1.381993095698489\n",
      "3 Train Loss 48.298195 Test MSE 8.192755267881816 Test RE 1.368116407227815\n",
      "4 Train Loss 46.818916 Test MSE 7.888313048632365 Test RE 1.342456212214388\n",
      "5 Train Loss 44.77459 Test MSE 8.126391562808916 Test RE 1.3625640696907402\n",
      "6 Train Loss 44.680973 Test MSE 8.090532327385915 Test RE 1.3595544604330831\n",
      "7 Train Loss 44.555077 Test MSE 8.087779679755414 Test RE 1.3593231596617348\n",
      "8 Train Loss 44.374367 Test MSE 8.122251350997786 Test RE 1.362216927756754\n",
      "9 Train Loss 44.36286 Test MSE 8.10246152251529 Test RE 1.360556397996547\n",
      "10 Train Loss 44.249535 Test MSE 8.092144993315575 Test RE 1.3596899520066448\n",
      "11 Train Loss 44.090557 Test MSE 8.09900714735138 Test RE 1.360266339644781\n",
      "12 Train Loss 43.837658 Test MSE 8.047706702012995 Test RE 1.355951420408902\n",
      "13 Train Loss 42.285896 Test MSE 8.210853571862955 Test RE 1.3696267005586875\n",
      "14 Train Loss 40.055035 Test MSE 7.602566186988136 Test RE 1.3179173189531037\n",
      "15 Train Loss 38.14081 Test MSE 7.559344063359334 Test RE 1.31416566611283\n",
      "16 Train Loss 35.066208 Test MSE 6.549183066891164 Test RE 1.2232116971036775\n",
      "17 Train Loss 32.421364 Test MSE 5.087298668100808 Test RE 1.078081709301517\n",
      "18 Train Loss 27.972322 Test MSE 4.768463117629587 Test RE 1.0437518883478552\n",
      "19 Train Loss 19.114756 Test MSE 3.9115967520993244 Test RE 0.9453336095876074\n",
      "20 Train Loss 15.972682 Test MSE 2.96619877966514 Test RE 0.8232053537681037\n",
      "21 Train Loss 12.878017 Test MSE 2.1277135502251623 Test RE 0.6972116574790352\n",
      "22 Train Loss 11.173842 Test MSE 2.0172144205396383 Test RE 0.6788660533593195\n",
      "23 Train Loss 9.004286 Test MSE 1.6379620748642403 Test RE 0.6117302843784147\n",
      "24 Train Loss 7.841976 Test MSE 1.3211436336959868 Test RE 0.5493929453750228\n",
      "25 Train Loss 6.265607 Test MSE 1.5964603770044565 Test RE 0.6039307353276191\n",
      "26 Train Loss 5.493541 Test MSE 1.2809340071563855 Test RE 0.540967828370801\n",
      "27 Train Loss 5.056382 Test MSE 1.179851265379514 Test RE 0.5191844680427299\n",
      "28 Train Loss 4.8041916 Test MSE 1.115691688721142 Test RE 0.5048706905905567\n",
      "29 Train Loss 4.509115 Test MSE 0.9520435674589549 Test RE 0.46637629911582\n",
      "30 Train Loss 4.1826744 Test MSE 0.9789693335415774 Test RE 0.472925361074279\n",
      "31 Train Loss 3.9872184 Test MSE 0.8378434505524258 Test RE 0.4375115270881684\n",
      "32 Train Loss 3.296587 Test MSE 0.46398316355413743 Test RE 0.3255810887540077\n",
      "33 Train Loss 3.031952 Test MSE 0.38618341689646013 Test RE 0.297033115656366\n",
      "34 Train Loss 2.9106627 Test MSE 0.3232299805669372 Test RE 0.2717464493800374\n",
      "35 Train Loss 2.6590512 Test MSE 0.1856425212600251 Test RE 0.20594288354943002\n",
      "36 Train Loss 2.4637904 Test MSE 0.13683175152737048 Test RE 0.17680783382551443\n",
      "37 Train Loss 2.1973803 Test MSE 0.12400830911178189 Test RE 0.16831912049172024\n",
      "38 Train Loss 1.9365978 Test MSE 0.125242858104936 Test RE 0.16915488538319035\n",
      "39 Train Loss 1.4666382 Test MSE 0.08457868625873435 Test RE 0.13900759443409783\n",
      "40 Train Loss 1.1237222 Test MSE 0.06725625108790133 Test RE 0.12395795081045344\n",
      "41 Train Loss 0.9162751 Test MSE 0.07944401851589858 Test RE 0.1347220436728593\n",
      "42 Train Loss 0.7416089 Test MSE 0.0951432003172446 Test RE 0.1474337588500277\n",
      "43 Train Loss 0.7069336 Test MSE 0.09022343309306485 Test RE 0.14357133361017332\n",
      "44 Train Loss 0.679026 Test MSE 0.09063384021144916 Test RE 0.14389750077412172\n",
      "45 Train Loss 0.61855936 Test MSE 0.0814097770376737 Test RE 0.13637863613542123\n",
      "46 Train Loss 0.5229709 Test MSE 0.05544899758928366 Test RE 0.1125524388443019\n",
      "47 Train Loss 0.47367054 Test MSE 0.04601586890086701 Test RE 0.1025325772292702\n",
      "48 Train Loss 0.4568603 Test MSE 0.04335142138792167 Test RE 0.09951985418689975\n",
      "49 Train Loss 0.43462282 Test MSE 0.04870346935853638 Test RE 0.1054843448259893\n",
      "50 Train Loss 0.35010022 Test MSE 0.044988311153578917 Test RE 0.10138131156722516\n",
      "51 Train Loss 0.31601545 Test MSE 0.04332605014501173 Test RE 0.09949072813001054\n",
      "52 Train Loss 0.30567408 Test MSE 0.044695128671516454 Test RE 0.10105042774707798\n",
      "53 Train Loss 0.29220086 Test MSE 0.04217525817352129 Test RE 0.09816053916514321\n",
      "54 Train Loss 0.2785209 Test MSE 0.03762886165482722 Test RE 0.09271897041492458\n",
      "55 Train Loss 0.23270105 Test MSE 0.03721750050792493 Test RE 0.0922107727981313\n",
      "56 Train Loss 0.22154643 Test MSE 0.0425293307020104 Test RE 0.09857171991472637\n",
      "57 Train Loss 0.21661471 Test MSE 0.041910087117878456 Test RE 0.09785146723527541\n",
      "58 Train Loss 0.20696703 Test MSE 0.038967676345702335 Test RE 0.09435399974695081\n",
      "59 Train Loss 0.19833833 Test MSE 0.042430236175984924 Test RE 0.09845681551555265\n",
      "60 Train Loss 0.17530139 Test MSE 0.03765174553831452 Test RE 0.09274715951676962\n",
      "61 Train Loss 0.1620476 Test MSE 0.0343561002133901 Test RE 0.08859515875816613\n",
      "62 Train Loss 0.15914921 Test MSE 0.03522109304614509 Test RE 0.08970351790497635\n",
      "63 Train Loss 0.15588813 Test MSE 0.03542673163879435 Test RE 0.08996500408964914\n",
      "64 Train Loss 0.14908755 Test MSE 0.03361532099898394 Test RE 0.08763481852639814\n",
      "65 Train Loss 0.13927884 Test MSE 0.03012659619797695 Test RE 0.08296274123880287\n",
      "66 Train Loss 0.13225128 Test MSE 0.027065630211376895 Test RE 0.07863522471996925\n",
      "67 Train Loss 0.12998289 Test MSE 0.026109680418904224 Test RE 0.07723405522173386\n",
      "68 Train Loss 0.12769003 Test MSE 0.024818817627533837 Test RE 0.07530062903822785\n",
      "69 Train Loss 0.12634015 Test MSE 0.025379556076316378 Test RE 0.07614652187801313\n",
      "70 Train Loss 0.12503581 Test MSE 0.025705733400606737 Test RE 0.07663427618395516\n",
      "71 Train Loss 0.123245254 Test MSE 0.024933577424836866 Test RE 0.07547451964689396\n",
      "72 Train Loss 0.120382525 Test MSE 0.024045403992554684 Test RE 0.07411806955449722\n",
      "73 Train Loss 0.11810324 Test MSE 0.025083400632028643 Test RE 0.07570093919260816\n",
      "74 Train Loss 0.11489458 Test MSE 0.025881247466918236 Test RE 0.0768954535653037\n",
      "75 Train Loss 0.11205971 Test MSE 0.02420478915728028 Test RE 0.07436330995818106\n",
      "76 Train Loss 0.110299274 Test MSE 0.023152506847412557 Test RE 0.0727289086871284\n",
      "77 Train Loss 0.10840057 Test MSE 0.02270714153101136 Test RE 0.07202599950769467\n",
      "78 Train Loss 0.105613895 Test MSE 0.023143956870954184 Test RE 0.07271547843785398\n",
      "79 Train Loss 0.09649749 Test MSE 0.02117805554634155 Test RE 0.0695586431473264\n",
      "80 Train Loss 0.08468252 Test MSE 0.019512308524986696 Test RE 0.06676708065998345\n",
      "81 Train Loss 0.08268592 Test MSE 0.02056914240823217 Test RE 0.06855137223767588\n",
      "82 Train Loss 0.08065152 Test MSE 0.018722525587476804 Test RE 0.06540188666019746\n",
      "83 Train Loss 0.07969661 Test MSE 0.01795576053930348 Test RE 0.06404864742202573\n",
      "84 Train Loss 0.0791488 Test MSE 0.018567505262617277 Test RE 0.06513056387162268\n",
      "85 Train Loss 0.07829301 Test MSE 0.01870917131602586 Test RE 0.06537855780048961\n",
      "86 Train Loss 0.07550642 Test MSE 0.016927712325900655 Test RE 0.062188086680506925\n",
      "87 Train Loss 0.07346458 Test MSE 0.01649316263899593 Test RE 0.06138468492874269\n",
      "88 Train Loss 0.071311206 Test MSE 0.01856966240773451 Test RE 0.06513434714771262\n",
      "89 Train Loss 0.070478484 Test MSE 0.018476728169611878 Test RE 0.0649711561504406\n",
      "90 Train Loss 0.07022005 Test MSE 0.018243175007143696 Test RE 0.06455921967648712\n",
      "91 Train Loss 0.06895134 Test MSE 0.018119343615160332 Test RE 0.0643397384044616\n",
      "92 Train Loss 0.06726226 Test MSE 0.01858772562050499 Test RE 0.06516601841810102\n",
      "93 Train Loss 0.06573886 Test MSE 0.017888509681803354 Test RE 0.06392859215763926\n",
      "94 Train Loss 0.06393559 Test MSE 0.016850831203109033 Test RE 0.06204670517527381\n",
      "95 Train Loss 0.06284036 Test MSE 0.01640654659338819 Test RE 0.061223287815984385\n",
      "96 Train Loss 0.06167893 Test MSE 0.016341602765254145 Test RE 0.06110199424579669\n",
      "97 Train Loss 0.0595989 Test MSE 0.016740315939728797 Test RE 0.061842905496362045\n",
      "98 Train Loss 0.057472747 Test MSE 0.017154686058834443 Test RE 0.06260362013663205\n",
      "99 Train Loss 0.056036115 Test MSE 0.016864744328048426 Test RE 0.06207231475597901\n",
      "Training time: 86.21\n",
      "5\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.691734 Test MSE 9.197682246586634 Test RE 1.449596932153537\n",
      "1 Train Loss 47.424095 Test MSE 8.417716032965606 Test RE 1.386772419693229\n",
      "2 Train Loss 43.687626 Test MSE 8.112362862506187 Test RE 1.3613874552253904\n",
      "3 Train Loss 40.387627 Test MSE 8.383088733462705 Test RE 1.3839171517212152\n",
      "4 Train Loss 37.161285 Test MSE 8.575492635548029 Test RE 1.3997084983426378\n",
      "5 Train Loss 33.83035 Test MSE 8.609371561904153 Test RE 1.4024706648823255\n",
      "6 Train Loss 32.05735 Test MSE 8.528403865758758 Test RE 1.3958602482502478\n",
      "7 Train Loss 29.949118 Test MSE 8.85403630094982 Test RE 1.4222590613867205\n",
      "8 Train Loss 28.500044 Test MSE 8.790063560640634 Test RE 1.417111648838636\n",
      "9 Train Loss 27.512486 Test MSE 8.785002557043896 Test RE 1.4167036290475528\n",
      "10 Train Loss 26.753143 Test MSE 8.66335069159412 Test RE 1.4068604076900322\n",
      "11 Train Loss 25.843998 Test MSE 8.878916273362062 Test RE 1.4242559440085396\n",
      "12 Train Loss 24.972507 Test MSE 8.85734990661944 Test RE 1.4225251753189558\n",
      "13 Train Loss 24.30155 Test MSE 9.211133810890749 Test RE 1.4506565590035305\n",
      "14 Train Loss 23.47229 Test MSE 9.083187044327913 Test RE 1.4405461927838727\n",
      "15 Train Loss 22.697346 Test MSE 9.139322443639525 Test RE 1.4449907274855271\n",
      "16 Train Loss 21.668644 Test MSE 9.59733530510483 Test RE 1.4807556361456264\n",
      "17 Train Loss 21.207668 Test MSE 9.477391165081945 Test RE 1.4714735609044476\n",
      "18 Train Loss 20.523228 Test MSE 9.348709858421829 Test RE 1.4614497960846804\n",
      "19 Train Loss 19.979668 Test MSE 9.345505970922375 Test RE 1.4611993485876\n",
      "20 Train Loss 19.470709 Test MSE 9.198268531800041 Test RE 1.449643132037432\n",
      "21 Train Loss 19.011883 Test MSE 9.0438440389357 Test RE 1.4374230092173592\n",
      "22 Train Loss 18.434807 Test MSE 9.132839098022156 Test RE 1.444478105439105\n",
      "23 Train Loss 17.76408 Test MSE 8.931530030434 Test RE 1.4284695648187133\n",
      "24 Train Loss 16.772202 Test MSE 9.007113202879985 Test RE 1.4345010511292737\n",
      "25 Train Loss 14.473311 Test MSE 8.28277366300077 Test RE 1.375612004870347\n",
      "26 Train Loss 13.119598 Test MSE 7.630400339439471 Test RE 1.320327662801531\n",
      "27 Train Loss 11.687855 Test MSE 7.282606620709363 Test RE 1.2898864662935718\n",
      "28 Train Loss 10.532675 Test MSE 7.03479122971558 Test RE 1.267750139532102\n",
      "29 Train Loss 9.58193 Test MSE 7.039055636129538 Test RE 1.2681343288139366\n",
      "30 Train Loss 9.148779 Test MSE 6.995395021107285 Test RE 1.2641953311074288\n",
      "31 Train Loss 8.792017 Test MSE 7.105380214457497 Test RE 1.2740947361211208\n",
      "32 Train Loss 8.313731 Test MSE 7.148842665388068 Test RE 1.2779855101469884\n",
      "33 Train Loss 8.035072 Test MSE 7.343439166333684 Test RE 1.295262556258918\n",
      "34 Train Loss 7.546381 Test MSE 7.234307024715131 Test RE 1.2856019675998023\n",
      "35 Train Loss 7.018063 Test MSE 7.274373520731324 Test RE 1.2891571417576952\n",
      "36 Train Loss 6.536631 Test MSE 7.01994527394602 Test RE 1.2664117271943525\n",
      "37 Train Loss 5.694445 Test MSE 6.901473698047923 Test RE 1.2556800053543802\n",
      "38 Train Loss 5.0414505 Test MSE 6.759996482598127 Test RE 1.2427429132854786\n",
      "39 Train Loss 4.5083475 Test MSE 6.839852560024131 Test RE 1.2500616456161715\n",
      "40 Train Loss 4.21072 Test MSE 6.825559469149044 Test RE 1.248754849270281\n",
      "41 Train Loss 3.9668534 Test MSE 6.677495823971828 Test RE 1.2351362636996794\n",
      "42 Train Loss 3.857965 Test MSE 6.728737352403644 Test RE 1.2398662790103085\n",
      "43 Train Loss 3.7473845 Test MSE 6.782993426984859 Test RE 1.2448549724339684\n",
      "44 Train Loss 3.6325693 Test MSE 6.80217675612645 Test RE 1.2466140484504906\n",
      "45 Train Loss 3.5122993 Test MSE 6.779012942359803 Test RE 1.244489657820085\n",
      "46 Train Loss 3.42198 Test MSE 6.677931081907758 Test RE 1.2351765178693985\n",
      "47 Train Loss 3.335825 Test MSE 6.6692517966506495 Test RE 1.2343735794436583\n",
      "48 Train Loss 3.2628074 Test MSE 6.678728922198848 Test RE 1.2352503015119352\n",
      "49 Train Loss 3.204657 Test MSE 6.648466153172462 Test RE 1.2324485305606097\n",
      "50 Train Loss 3.1051557 Test MSE 6.596572273324321 Test RE 1.2276292365019459\n",
      "51 Train Loss 2.9855392 Test MSE 6.613139144364139 Test RE 1.229169826146915\n",
      "52 Train Loss 2.877389 Test MSE 6.494061007360646 Test RE 1.2180531588290209\n",
      "53 Train Loss 2.7665324 Test MSE 6.408447039085841 Test RE 1.209997463904037\n",
      "54 Train Loss 2.6668124 Test MSE 6.2561875443568935 Test RE 1.1955367757065076\n",
      "55 Train Loss 2.581247 Test MSE 6.129767427074775 Test RE 1.183395895929353\n",
      "56 Train Loss 2.5045211 Test MSE 6.103680413199847 Test RE 1.1808750677722015\n",
      "57 Train Loss 2.4370615 Test MSE 5.956341992103404 Test RE 1.1665352669245324\n",
      "58 Train Loss 2.3903735 Test MSE 5.9122619078345044 Test RE 1.1622107618670232\n",
      "59 Train Loss 2.3379786 Test MSE 5.788472315738407 Test RE 1.1499793465320112\n",
      "60 Train Loss 2.2892432 Test MSE 5.750103251583601 Test RE 1.1461616731491855\n",
      "61 Train Loss 2.2626176 Test MSE 5.74610905753981 Test RE 1.1457635248719595\n",
      "62 Train Loss 2.2267318 Test MSE 5.7269028297408155 Test RE 1.1438470789522304\n",
      "63 Train Loss 2.1597776 Test MSE 5.724147270170941 Test RE 1.1435718588116968\n",
      "64 Train Loss 2.1240714 Test MSE 5.693038398422146 Test RE 1.1404601554137221\n",
      "65 Train Loss 2.0889292 Test MSE 5.6626793420511685 Test RE 1.1374152456662172\n",
      "66 Train Loss 2.0545673 Test MSE 5.628651774556878 Test RE 1.1339926792230823\n",
      "67 Train Loss 2.0214777 Test MSE 5.613145233054254 Test RE 1.1324295667014825\n",
      "68 Train Loss 1.9910594 Test MSE 5.584020106742137 Test RE 1.1294878069503829\n",
      "69 Train Loss 1.9703741 Test MSE 5.553020849929938 Test RE 1.1263483115099162\n",
      "70 Train Loss 1.9396211 Test MSE 5.52839985428227 Test RE 1.1238485347840217\n",
      "71 Train Loss 1.9151623 Test MSE 5.529445431967719 Test RE 1.1239548056242452\n",
      "72 Train Loss 1.8907166 Test MSE 5.52550892003706 Test RE 1.1235546525437763\n",
      "73 Train Loss 1.8595418 Test MSE 5.482923925850582 Test RE 1.119216670815792\n",
      "74 Train Loss 1.8339531 Test MSE 5.468614393352182 Test RE 1.1177552306577268\n",
      "75 Train Loss 1.812688 Test MSE 5.471870633577892 Test RE 1.118087960087885\n",
      "76 Train Loss 1.7859038 Test MSE 5.441271843648604 Test RE 1.1149573943439615\n",
      "77 Train Loss 1.767098 Test MSE 5.448032187619867 Test RE 1.1156498019267271\n",
      "78 Train Loss 1.7407843 Test MSE 5.45918337615519 Test RE 1.1167909902771072\n",
      "79 Train Loss 1.7123541 Test MSE 5.461894700280118 Test RE 1.117068285091591\n",
      "80 Train Loss 1.6893607 Test MSE 5.46192135034752 Test RE 1.117071010328016\n",
      "81 Train Loss 1.6747715 Test MSE 5.468237482971247 Test RE 1.1177167107714383\n",
      "82 Train Loss 1.6642036 Test MSE 5.491410361405734 Test RE 1.120082494217756\n",
      "83 Train Loss 1.6467633 Test MSE 5.4958202674558185 Test RE 1.1205321480385644\n",
      "84 Train Loss 1.6294384 Test MSE 5.478215296599446 Test RE 1.1187359867546567\n",
      "85 Train Loss 1.6194 Test MSE 5.494246952162847 Test RE 1.1203717464543477\n",
      "86 Train Loss 1.5993729 Test MSE 5.525156851255997 Test RE 1.1235188572148742\n",
      "87 Train Loss 1.576015 Test MSE 5.552172246937034 Test RE 1.126262244926194\n",
      "88 Train Loss 1.5534673 Test MSE 5.550826900670222 Test RE 1.1261257844168522\n",
      "89 Train Loss 1.5250841 Test MSE 5.559499099963624 Test RE 1.1270051286992675\n",
      "90 Train Loss 1.5027277 Test MSE 5.549913709030747 Test RE 1.1260331485836153\n",
      "91 Train Loss 1.483696 Test MSE 5.559967459276187 Test RE 1.1270525999031735\n",
      "92 Train Loss 1.4646006 Test MSE 5.5809699164586775 Test RE 1.1291792816171153\n",
      "93 Train Loss 1.4511622 Test MSE 5.574743211739509 Test RE 1.1285491914798278\n",
      "94 Train Loss 1.4328154 Test MSE 5.561680805464981 Test RE 1.1272262414350878\n",
      "95 Train Loss 1.4174194 Test MSE 5.573555446438719 Test RE 1.1284289596658812\n",
      "96 Train Loss 1.4033446 Test MSE 5.579094510230015 Test RE 1.1289895432900066\n",
      "97 Train Loss 1.3887533 Test MSE 5.569313597293144 Test RE 1.1279994729094647\n",
      "98 Train Loss 1.3758352 Test MSE 5.5545688115466785 Test RE 1.1265052911530367\n",
      "99 Train Loss 1.3579804 Test MSE 5.5671672912730745 Test RE 1.1277820973463222\n",
      "Training time: 85.17\n",
      "6\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.860085 Test MSE 8.388050938535368 Test RE 1.3843266824438005\n",
      "1 Train Loss 56.55018 Test MSE 7.564154775750494 Test RE 1.3145837624112953\n",
      "2 Train Loss 51.53219 Test MSE 8.318734922330037 Test RE 1.3785950129653648\n",
      "3 Train Loss 47.060555 Test MSE 8.824843755980869 Test RE 1.4199124682631743\n",
      "4 Train Loss 46.186157 Test MSE 8.642829198385565 Test RE 1.4051931547567926\n",
      "5 Train Loss 45.40828 Test MSE 8.740980999240609 Test RE 1.4131496275047473\n",
      "6 Train Loss 44.82016 Test MSE 8.690779588771516 Test RE 1.4090857668716426\n",
      "7 Train Loss 44.201794 Test MSE 8.729755212496533 Test RE 1.4122419025618946\n",
      "8 Train Loss 43.16658 Test MSE 9.075945318819814 Test RE 1.439971828292168\n",
      "9 Train Loss 42.397213 Test MSE 9.22401695216978 Test RE 1.4516706840561564\n",
      "10 Train Loss 41.292572 Test MSE 9.487570830165314 Test RE 1.472263603631514\n",
      "11 Train Loss 40.250465 Test MSE 9.706231594204612 Test RE 1.489132647188463\n",
      "12 Train Loss 39.38427 Test MSE 9.651717261812768 Test RE 1.484944957218383\n",
      "13 Train Loss 38.34368 Test MSE 9.419680539670308 Test RE 1.4669866019776938\n",
      "14 Train Loss 35.18362 Test MSE 8.983072574330004 Test RE 1.4325853791202319\n",
      "15 Train Loss 31.474304 Test MSE 9.26909036226007 Test RE 1.4552131758792304\n",
      "16 Train Loss 30.606533 Test MSE 9.386639555113302 Test RE 1.464411500796325\n",
      "17 Train Loss 28.690132 Test MSE 9.210031608204309 Test RE 1.4505697637498915\n",
      "18 Train Loss 26.568748 Test MSE 8.114618972140818 Test RE 1.3615767481532528\n",
      "19 Train Loss 23.17952 Test MSE 7.926370412898423 Test RE 1.3456906725674946\n",
      "20 Train Loss 21.649849 Test MSE 7.853044113109214 Test RE 1.3394517648450341\n",
      "21 Train Loss 19.944117 Test MSE 7.750651717160193 Test RE 1.3306908518438743\n",
      "22 Train Loss 17.866665 Test MSE 6.699658558228008 Test RE 1.237184285998501\n",
      "23 Train Loss 17.010384 Test MSE 6.518054146711984 Test RE 1.220301210941124\n",
      "24 Train Loss 16.36394 Test MSE 6.203611118443259 Test RE 1.1905025860073724\n",
      "25 Train Loss 16.032043 Test MSE 6.0652875737006 Test RE 1.1771552902834725\n",
      "26 Train Loss 15.801207 Test MSE 6.018577878596683 Test RE 1.1726138044316854\n",
      "27 Train Loss 15.639728 Test MSE 6.024943095645483 Test RE 1.1732337157393482\n",
      "28 Train Loss 15.498775 Test MSE 6.0161574681885455 Test RE 1.1723779935705105\n",
      "29 Train Loss 15.314335 Test MSE 5.9141519101938504 Test RE 1.1623965118892872\n",
      "30 Train Loss 15.144673 Test MSE 5.930234332570066 Test RE 1.1639758981141046\n",
      "31 Train Loss 15.055002 Test MSE 5.860776164703438 Test RE 1.157139257403498\n",
      "32 Train Loss 14.888983 Test MSE 5.805419322974825 Test RE 1.151661523083412\n",
      "33 Train Loss 14.77475 Test MSE 5.970920529984212 Test RE 1.1679619802713415\n",
      "34 Train Loss 14.512733 Test MSE 6.00481593966474 Test RE 1.1712724015847442\n",
      "35 Train Loss 14.384525 Test MSE 5.956594161309741 Test RE 1.1665599600297494\n",
      "36 Train Loss 14.280872 Test MSE 5.876826732615022 Test RE 1.1587226691455603\n",
      "37 Train Loss 14.173256 Test MSE 5.798850225705039 Test RE 1.1510097598342806\n",
      "38 Train Loss 14.065925 Test MSE 5.858661342491287 Test RE 1.1569304655528905\n",
      "39 Train Loss 13.949389 Test MSE 5.859672088744134 Test RE 1.157030259058072\n",
      "40 Train Loss 13.828138 Test MSE 5.815148702122115 Test RE 1.1526261614912852\n",
      "41 Train Loss 13.505579 Test MSE 5.96997180907775 Test RE 1.1678691877143197\n",
      "42 Train Loss 13.153885 Test MSE 6.034321206785962 Test RE 1.1741464577994218\n",
      "43 Train Loss 12.694633 Test MSE 5.844359342627179 Test RE 1.155517469571253\n",
      "44 Train Loss 12.059534 Test MSE 5.076724509113797 Test RE 1.076960707956257\n",
      "45 Train Loss 9.548323 Test MSE 4.5712024421957 Test RE 1.0219350337908764\n",
      "46 Train Loss 8.725697 Test MSE 4.311830897637177 Test RE 0.9925192081983938\n",
      "47 Train Loss 8.250178 Test MSE 4.464301621995099 Test RE 1.0099150050436085\n",
      "48 Train Loss 7.9726186 Test MSE 4.373618456091278 Test RE 0.9996052008574051\n",
      "49 Train Loss 7.648178 Test MSE 4.389402206179829 Test RE 1.0014072910229583\n",
      "50 Train Loss 7.3181553 Test MSE 4.515998449035363 Test RE 1.0157456060834416\n",
      "51 Train Loss 7.0096617 Test MSE 4.636909671594252 Test RE 1.0292535608470015\n",
      "52 Train Loss 6.9174585 Test MSE 4.670495896690433 Test RE 1.0329743978402322\n",
      "53 Train Loss 6.671378 Test MSE 4.646125496115363 Test RE 1.0302758701545647\n",
      "54 Train Loss 6.3624134 Test MSE 4.625352969740072 Test RE 1.0279701417111156\n",
      "55 Train Loss 5.6199927 Test MSE 3.975115803161662 Test RE 0.952978171089705\n",
      "56 Train Loss 4.9300895 Test MSE 3.681053330837951 Test RE 0.9170523224012569\n",
      "57 Train Loss 4.621163 Test MSE 3.6198877357264267 Test RE 0.9094013848540744\n",
      "58 Train Loss 4.3471823 Test MSE 3.6377539952131674 Test RE 0.9116428359399202\n",
      "59 Train Loss 4.230073 Test MSE 3.5616475893097252 Test RE 0.9020560695932702\n",
      "60 Train Loss 4.0628905 Test MSE 3.446109751454108 Test RE 0.8873043540602845\n",
      "61 Train Loss 3.8326807 Test MSE 3.24074968540602 Test RE 0.8604602335209792\n",
      "62 Train Loss 3.6416237 Test MSE 3.0318985318035376 Test RE 0.8322722063251232\n",
      "63 Train Loss 3.4612486 Test MSE 2.8309990466896706 Test RE 0.8042256526842264\n",
      "64 Train Loss 3.2631483 Test MSE 2.529173570114531 Test RE 0.7601466356181671\n",
      "65 Train Loss 2.9776707 Test MSE 2.3733585108817867 Test RE 0.7363592273219569\n",
      "66 Train Loss 2.8482647 Test MSE 2.413328139296394 Test RE 0.7425338362897804\n",
      "67 Train Loss 2.750544 Test MSE 2.384706948977733 Test RE 0.7381176134864841\n",
      "68 Train Loss 2.5979583 Test MSE 2.5224788587794187 Test RE 0.7591399165780769\n",
      "69 Train Loss 2.5206814 Test MSE 2.5290440376630263 Test RE 0.7601271697896602\n",
      "70 Train Loss 2.4579318 Test MSE 2.4966885897046702 Test RE 0.7552491558229663\n",
      "71 Train Loss 2.4190009 Test MSE 2.494387313220067 Test RE 0.7549010071161054\n",
      "72 Train Loss 2.3504074 Test MSE 2.51312761401768 Test RE 0.7577314816633598\n",
      "73 Train Loss 2.3262126 Test MSE 2.518476888552914 Test RE 0.7585374811451385\n",
      "74 Train Loss 2.249882 Test MSE 2.4572044186413557 Test RE 0.749253368430034\n",
      "75 Train Loss 2.199402 Test MSE 2.412958364220502 Test RE 0.7424769478336345\n",
      "76 Train Loss 2.1799407 Test MSE 2.41827131426835 Test RE 0.7432939063765844\n",
      "77 Train Loss 2.1673143 Test MSE 2.4159309829703615 Test RE 0.7429341504099142\n",
      "78 Train Loss 2.1310709 Test MSE 2.4192364612970567 Test RE 0.7434422181761655\n",
      "79 Train Loss 2.0700803 Test MSE 2.4509165181975288 Test RE 0.7482940977272522\n",
      "80 Train Loss 2.039769 Test MSE 2.488262164900503 Test RE 0.7539735804351256\n",
      "81 Train Loss 1.9880052 Test MSE 2.5044001197224013 Test RE 0.7564146268076926\n",
      "82 Train Loss 1.9542814 Test MSE 2.509268810572185 Test RE 0.7571495255194655\n",
      "83 Train Loss 1.9379333 Test MSE 2.540048248974057 Test RE 0.761779082674801\n",
      "84 Train Loss 1.9085996 Test MSE 2.5562072529872744 Test RE 0.7641983429839606\n",
      "85 Train Loss 1.8879027 Test MSE 2.549458267286998 Test RE 0.7631888449320334\n",
      "86 Train Loss 1.8392301 Test MSE 2.6130998295167553 Test RE 0.7726557858910289\n",
      "87 Train Loss 1.8084445 Test MSE 2.6157106036298745 Test RE 0.7730416735816441\n",
      "88 Train Loss 1.7911979 Test MSE 2.6193700694050603 Test RE 0.7735822400336103\n",
      "89 Train Loss 1.7851762 Test MSE 2.615582222711672 Test RE 0.773022702634037\n",
      "90 Train Loss 1.7794125 Test MSE 2.603213086520828 Test RE 0.7711927173089105\n",
      "91 Train Loss 1.7620326 Test MSE 2.5868761862543552 Test RE 0.7687690341559511\n",
      "92 Train Loss 1.748833 Test MSE 2.5936933667245032 Test RE 0.7697813340542365\n",
      "93 Train Loss 1.725852 Test MSE 2.600578880119058 Test RE 0.7708024313618183\n",
      "94 Train Loss 1.704729 Test MSE 2.60123234586934 Test RE 0.7708992677537719\n",
      "95 Train Loss 1.6902728 Test MSE 2.6026547261606368 Test RE 0.7711100067275071\n",
      "96 Train Loss 1.6766539 Test MSE 2.60231581818895 Test RE 0.771059799561381\n",
      "97 Train Loss 1.6620119 Test MSE 2.6009804565439154 Test RE 0.7708619419843286\n",
      "98 Train Loss 1.6427255 Test MSE 2.6120076957345013 Test RE 0.7724943049432085\n",
      "99 Train Loss 1.6281738 Test MSE 2.6075601703337012 Test RE 0.7718363528626166\n",
      "Training time: 84.69\n",
      "7\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 47.4044 Test MSE 7.570904039117915 Test RE 1.3151701130359073\n",
      "1 Train Loss 34.037632 Test MSE 7.091622456440222 Test RE 1.2728606585823679\n",
      "2 Train Loss 27.93715 Test MSE 5.995880540591486 Test RE 1.1704006277693344\n",
      "3 Train Loss 22.830585 Test MSE 6.033594666663902 Test RE 1.174075771291313\n",
      "4 Train Loss 17.72723 Test MSE 5.483058424267497 Test RE 1.1192303981581098\n",
      "5 Train Loss 15.535796 Test MSE 5.5451443976448465 Test RE 1.1255492170077133\n",
      "6 Train Loss 13.281177 Test MSE 5.205303501866786 Test RE 1.0905136062842777\n",
      "7 Train Loss 12.660369 Test MSE 5.2755667503063215 Test RE 1.097849027455119\n",
      "8 Train Loss 11.541777 Test MSE 5.0391976502285685 Test RE 1.0729729087347681\n",
      "9 Train Loss 10.898968 Test MSE 5.264413177544465 Test RE 1.0966878803703997\n",
      "10 Train Loss 10.451176 Test MSE 5.156699016256098 Test RE 1.0854103337560994\n",
      "11 Train Loss 9.897587 Test MSE 5.1535290512791025 Test RE 1.0850766666494243\n",
      "12 Train Loss 9.622288 Test MSE 5.061038852561213 Test RE 1.0752956673887601\n",
      "13 Train Loss 9.263609 Test MSE 5.039978162392156 Test RE 1.0730560009290633\n",
      "14 Train Loss 8.932785 Test MSE 4.9976809980076355 Test RE 1.0685437934901267\n",
      "15 Train Loss 8.58097 Test MSE 4.714154799994423 Test RE 1.0377911910646724\n",
      "16 Train Loss 8.266629 Test MSE 4.623026060455962 Test RE 1.027711535049402\n",
      "17 Train Loss 7.698534 Test MSE 4.3589020788954205 Test RE 0.9979220450512627\n",
      "18 Train Loss 6.64959 Test MSE 3.5159608472115718 Test RE 0.8962518712036098\n",
      "19 Train Loss 5.569892 Test MSE 2.8673610142587487 Test RE 0.8093739984229894\n",
      "20 Train Loss 5.273909 Test MSE 2.75244354108091 Test RE 0.7929891952750112\n",
      "21 Train Loss 4.8714533 Test MSE 2.675992991300999 Test RE 0.7818987990817865\n",
      "22 Train Loss 3.972538 Test MSE 2.3373819377552607 Test RE 0.7307568618867639\n",
      "23 Train Loss 3.2977533 Test MSE 2.4422985922496023 Test RE 0.7469773613475779\n",
      "24 Train Loss 2.994043 Test MSE 2.2773815697943127 Test RE 0.7213166568078058\n",
      "25 Train Loss 2.7426972 Test MSE 2.18430923074584 Test RE 0.7064234718530765\n",
      "26 Train Loss 2.5779784 Test MSE 2.1349108289686973 Test RE 0.6983898683019248\n",
      "27 Train Loss 2.3904653 Test MSE 1.9805503275743213 Test RE 0.6726683618265635\n",
      "28 Train Loss 2.1883738 Test MSE 1.8482253535749658 Test RE 0.649808700615936\n",
      "29 Train Loss 1.8938129 Test MSE 1.5354749596923594 Test RE 0.592283220942619\n",
      "30 Train Loss 1.7300624 Test MSE 1.4175492018245828 Test RE 0.5690849902928699\n",
      "31 Train Loss 1.4350818 Test MSE 0.9889738670602704 Test RE 0.4753357383778527\n",
      "32 Train Loss 1.1629761 Test MSE 0.6447421007393669 Test RE 0.38379655774951954\n",
      "33 Train Loss 0.8593082 Test MSE 0.44195106277489526 Test RE 0.31775701828838027\n",
      "34 Train Loss 0.73299587 Test MSE 0.4487815503657267 Test RE 0.32020311872184776\n",
      "35 Train Loss 0.6215911 Test MSE 0.4171278185450649 Test RE 0.30870427049614596\n",
      "36 Train Loss 0.47231084 Test MSE 0.26777899493355495 Test RE 0.24734111479105444\n",
      "37 Train Loss 0.32928795 Test MSE 0.11754236878042726 Test RE 0.16387219826133761\n",
      "38 Train Loss 0.28097978 Test MSE 0.10519646542391607 Test RE 0.15502746095998823\n",
      "39 Train Loss 0.22705805 Test MSE 0.07783627390075026 Test RE 0.13335186045182723\n",
      "40 Train Loss 0.1784864 Test MSE 0.05949577431652646 Test RE 0.11658726672890671\n",
      "41 Train Loss 0.14923997 Test MSE 0.035793199504443235 Test RE 0.09042912338466469\n",
      "42 Train Loss 0.12751348 Test MSE 0.03106087054926119 Test RE 0.08423932380727052\n",
      "43 Train Loss 0.10051801 Test MSE 0.026813142926032964 Test RE 0.07826758289045828\n",
      "44 Train Loss 0.08706098 Test MSE 0.01868870826156314 Test RE 0.06534279429761383\n",
      "45 Train Loss 0.074518934 Test MSE 0.01590630963445274 Test RE 0.0602827112040696\n",
      "46 Train Loss 0.06900568 Test MSE 0.017103493517143267 Test RE 0.06251014034502646\n",
      "47 Train Loss 0.061245166 Test MSE 0.015597514213071926 Test RE 0.05969469743553579\n",
      "48 Train Loss 0.054366674 Test MSE 0.014688766092926351 Test RE 0.05792962508862251\n",
      "49 Train Loss 0.048963897 Test MSE 0.014865355605887672 Test RE 0.058276802036403196\n",
      "50 Train Loss 0.04499205 Test MSE 0.012476310938580842 Test RE 0.05338892240482954\n",
      "51 Train Loss 0.041891698 Test MSE 0.0120535165136759 Test RE 0.05247650996690327\n",
      "52 Train Loss 0.038279634 Test MSE 0.013292739966572297 Test RE 0.055108084396934695\n",
      "53 Train Loss 0.034630656 Test MSE 0.012946534389559746 Test RE 0.054385712797518325\n",
      "54 Train Loss 0.03190002 Test MSE 0.012958217773489966 Test RE 0.054410247003154555\n",
      "55 Train Loss 0.027612569 Test MSE 0.012407156999387173 Test RE 0.05324075422284373\n",
      "56 Train Loss 0.024300262 Test MSE 0.010504459807734207 Test RE 0.04898858802058671\n",
      "57 Train Loss 0.02026257 Test MSE 0.008520847102458708 Test RE 0.04412141646475682\n",
      "58 Train Loss 0.017953955 Test MSE 0.009450120869286554 Test RE 0.04646508563786717\n",
      "59 Train Loss 0.016183406 Test MSE 0.008768131341362019 Test RE 0.044757063373635185\n",
      "60 Train Loss 0.01474309 Test MSE 0.007542804511826858 Test RE 0.04151207920948096\n",
      "61 Train Loss 0.014168937 Test MSE 0.00764059789129457 Test RE 0.04178031715729342\n",
      "62 Train Loss 0.013205084 Test MSE 0.0072951166465091795 Test RE 0.040824810784197876\n",
      "63 Train Loss 0.012177745 Test MSE 0.006217385433799906 Test RE 0.03768876928843143\n",
      "64 Train Loss 0.011368414 Test MSE 0.005881758219544664 Test RE 0.036657398801966806\n",
      "65 Train Loss 0.010736052 Test MSE 0.005365633368129336 Test RE 0.03501213201750904\n",
      "66 Train Loss 0.0101738 Test MSE 0.004609582410466774 Test RE 0.032451804586674876\n",
      "67 Train Loss 0.009854238 Test MSE 0.004377341753698086 Test RE 0.03162374414585766\n",
      "68 Train Loss 0.009454912 Test MSE 0.004541773555188479 Test RE 0.03221223056045892\n",
      "69 Train Loss 0.008731019 Test MSE 0.004962637642754727 Test RE 0.033671645698036934\n",
      "70 Train Loss 0.008155501 Test MSE 0.004795139807502227 Test RE 0.033098529339982564\n",
      "71 Train Loss 0.007899228 Test MSE 0.00465047909409702 Test RE 0.0325954445473611\n",
      "72 Train Loss 0.00764768 Test MSE 0.00461664545202531 Test RE 0.03247665724034008\n",
      "73 Train Loss 0.0074397796 Test MSE 0.004384402155663381 Test RE 0.03164923751574019\n",
      "74 Train Loss 0.0071084434 Test MSE 0.0039125885725132415 Test RE 0.029897863264974567\n",
      "75 Train Loss 0.0068052146 Test MSE 0.003528410433139845 Test RE 0.028392106085883155\n",
      "76 Train Loss 0.0066086003 Test MSE 0.0033188753985189143 Test RE 0.027536170001381942\n",
      "77 Train Loss 0.006465415 Test MSE 0.003295415216154465 Test RE 0.02743867474341362\n",
      "78 Train Loss 0.0062376587 Test MSE 0.0033053619689450684 Test RE 0.027480053455932164\n",
      "79 Train Loss 0.006117294 Test MSE 0.003162443749131905 Test RE 0.02687939348738391\n",
      "80 Train Loss 0.0059648636 Test MSE 0.0029851729296416583 Test RE 0.026115167013565848\n",
      "81 Train Loss 0.005796319 Test MSE 0.002956841732479793 Test RE 0.025990946773717105\n",
      "82 Train Loss 0.0054540033 Test MSE 0.0027727610236141283 Test RE 0.025168902627172408\n",
      "83 Train Loss 0.005141362 Test MSE 0.002494160333214562 Test RE 0.023870979744925212\n",
      "84 Train Loss 0.005005073 Test MSE 0.0023406720189773785 Test RE 0.023124818992703456\n",
      "85 Train Loss 0.0048937993 Test MSE 0.0022693063916131933 Test RE 0.022769559480012032\n",
      "86 Train Loss 0.0048377085 Test MSE 0.002195886579057365 Test RE 0.022398194543441705\n",
      "87 Train Loss 0.0047491435 Test MSE 0.002073462144084018 Test RE 0.02176487191150876\n",
      "88 Train Loss 0.004471323 Test MSE 0.0019409753747040457 Test RE 0.02105804614486363\n",
      "89 Train Loss 0.004304559 Test MSE 0.0018854811038427797 Test RE 0.020754828659278968\n",
      "90 Train Loss 0.0041292766 Test MSE 0.0018832331594963512 Test RE 0.02074245260996874\n",
      "91 Train Loss 0.0039970092 Test MSE 0.0019144150890980948 Test RE 0.020913470813861346\n",
      "92 Train Loss 0.0038804677 Test MSE 0.0019571680652745553 Test RE 0.021145702641294745\n",
      "93 Train Loss 0.0038049445 Test MSE 0.0019584564663130484 Test RE 0.021152661589661375\n",
      "94 Train Loss 0.0037104695 Test MSE 0.0018824108484890266 Test RE 0.020737923534699537\n",
      "95 Train Loss 0.0035724384 Test MSE 0.0018447799143484602 Test RE 0.020529593068779137\n",
      "96 Train Loss 0.003444754 Test MSE 0.0019388357375463665 Test RE 0.021046436259832994\n",
      "97 Train Loss 0.0033893683 Test MSE 0.0019130494448466278 Test RE 0.02090601019141203\n",
      "98 Train Loss 0.00329892 Test MSE 0.0017570058368634985 Test RE 0.02003524522388857\n",
      "99 Train Loss 0.0031551006 Test MSE 0.0016689813745394144 Test RE 0.019526922622093646\n",
      "Training time: 84.86\n",
      "8\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.422306 Test MSE 9.224665336688442 Test RE 1.4517217043579684\n",
      "1 Train Loss 38.736893 Test MSE 8.813673026017117 Test RE 1.4190135015595715\n",
      "2 Train Loss 31.03996 Test MSE 7.307774184186741 Test RE 1.2921133681798034\n",
      "3 Train Loss 28.484844 Test MSE 6.976543675957556 Test RE 1.2624907912118957\n",
      "4 Train Loss 26.49958 Test MSE 6.678339891895974 Test RE 1.2352143248461183\n",
      "5 Train Loss 24.223724 Test MSE 6.986022033637215 Test RE 1.2633481124172479\n",
      "6 Train Loss 20.036343 Test MSE 6.8910308101657 Test RE 1.254729636617103\n",
      "7 Train Loss 17.70417 Test MSE 6.770411046284646 Test RE 1.2436998401255788\n",
      "8 Train Loss 15.925692 Test MSE 6.663658138330846 Test RE 1.2338558217823452\n",
      "9 Train Loss 14.907944 Test MSE 6.827786618867567 Test RE 1.2489585642324221\n",
      "10 Train Loss 13.463752 Test MSE 6.652495802423165 Test RE 1.2328219688007027\n",
      "11 Train Loss 12.32735 Test MSE 6.461832440010531 Test RE 1.2150269373116762\n",
      "12 Train Loss 10.426922 Test MSE 5.757751508024268 Test RE 1.1469236790624115\n",
      "13 Train Loss 9.318521 Test MSE 5.5651172993942675 Test RE 1.1275744372482859\n",
      "14 Train Loss 8.641815 Test MSE 5.133884418711175 Test RE 1.0830066012182362\n",
      "15 Train Loss 7.952202 Test MSE 4.646068709804538 Test RE 1.0302695739681382\n",
      "16 Train Loss 7.3456373 Test MSE 4.249527556353303 Test RE 0.9853224661729683\n",
      "17 Train Loss 6.9588284 Test MSE 3.9974349681714596 Test RE 0.9556497793902023\n",
      "18 Train Loss 6.5421124 Test MSE 3.8515612398399304 Test RE 0.9380510286937187\n",
      "19 Train Loss 6.343724 Test MSE 3.8253850665299978 Test RE 0.9348579795741216\n",
      "20 Train Loss 6.0448866 Test MSE 3.6356061266566395 Test RE 0.9113736618695161\n",
      "21 Train Loss 5.6867867 Test MSE 3.514953768880786 Test RE 0.8961235050869724\n",
      "22 Train Loss 5.3842087 Test MSE 3.6089849149252577 Test RE 0.9080308288925113\n",
      "23 Train Loss 5.033889 Test MSE 3.6097313490065557 Test RE 0.9081247265023871\n",
      "24 Train Loss 4.6004305 Test MSE 3.4366710199080197 Test RE 0.8860883785443862\n",
      "25 Train Loss 3.9975328 Test MSE 3.1909763176419275 Test RE 0.8538269345307353\n",
      "26 Train Loss 3.2657387 Test MSE 3.05343004480989 Test RE 0.8352222352494405\n",
      "27 Train Loss 2.4603658 Test MSE 2.8634112503510845 Test RE 0.8088163536316605\n",
      "28 Train Loss 2.046205 Test MSE 2.70149840606252 Test RE 0.7856161778303029\n",
      "29 Train Loss 1.7155768 Test MSE 2.6153444871294615 Test RE 0.7729875710337403\n",
      "30 Train Loss 1.5577439 Test MSE 2.6441717917079264 Test RE 0.7772359752209147\n",
      "31 Train Loss 1.426627 Test MSE 2.617755612956385 Test RE 0.773343803442881\n",
      "32 Train Loss 1.3193444 Test MSE 2.652274160498513 Test RE 0.7784258819591684\n",
      "33 Train Loss 1.2447305 Test MSE 2.6663132200574595 Test RE 0.7804833509941932\n",
      "34 Train Loss 1.1863029 Test MSE 2.6946096531593353 Test RE 0.7846138877342439\n",
      "35 Train Loss 1.1379328 Test MSE 2.7027009127003625 Test RE 0.7857910073918082\n",
      "36 Train Loss 1.0885518 Test MSE 2.671981268235853 Test RE 0.7813124862699614\n",
      "37 Train Loss 1.0478028 Test MSE 2.6572378499523075 Test RE 0.7791539473864998\n",
      "38 Train Loss 1.0203891 Test MSE 2.6627700788604796 Test RE 0.779964604360181\n",
      "39 Train Loss 0.9959811 Test MSE 2.6136015874985925 Test RE 0.7727299636156351\n",
      "40 Train Loss 0.9563555 Test MSE 2.575134076239451 Test RE 0.7670222869525182\n",
      "41 Train Loss 0.9354078 Test MSE 2.580008627232646 Test RE 0.767747903842337\n",
      "42 Train Loss 0.9094718 Test MSE 2.5419314766089878 Test RE 0.7620614272346938\n",
      "43 Train Loss 0.8956058 Test MSE 2.5424208968079043 Test RE 0.7621347868645181\n",
      "44 Train Loss 0.8849256 Test MSE 2.542560116275522 Test RE 0.7621556533046352\n",
      "45 Train Loss 0.8661358 Test MSE 2.5338295088681977 Test RE 0.7608459883430858\n",
      "46 Train Loss 0.85170984 Test MSE 2.5363158641982517 Test RE 0.7612191921492164\n",
      "47 Train Loss 0.83686143 Test MSE 2.530330602952115 Test RE 0.7603204896516089\n",
      "48 Train Loss 0.82254064 Test MSE 2.5383841776282705 Test RE 0.761529508196698\n",
      "49 Train Loss 0.81511986 Test MSE 2.540844094657095 Test RE 0.7618984133044368\n",
      "50 Train Loss 0.8034502 Test MSE 2.522998827516573 Test RE 0.7592181548322248\n",
      "51 Train Loss 0.787698 Test MSE 2.5117996197317365 Test RE 0.7575312538594522\n",
      "52 Train Loss 0.77699447 Test MSE 2.506721312410841 Test RE 0.7567650854745218\n",
      "53 Train Loss 0.7646264 Test MSE 2.513011431800499 Test RE 0.7577139664483409\n",
      "54 Train Loss 0.75273085 Test MSE 2.5220338186358155 Test RE 0.7590729462169142\n",
      "55 Train Loss 0.7434621 Test MSE 2.5338789140659634 Test RE 0.7608534058830505\n",
      "56 Train Loss 0.7336755 Test MSE 2.525589795774417 Test RE 0.7596078905212903\n",
      "57 Train Loss 0.7261071 Test MSE 2.516688086732781 Test RE 0.7582680495978993\n",
      "58 Train Loss 0.7183669 Test MSE 2.524772754668904 Test RE 0.7594850120803622\n",
      "59 Train Loss 0.710945 Test MSE 2.5358393241609813 Test RE 0.7611476773059822\n",
      "60 Train Loss 0.70176256 Test MSE 2.5584963397099605 Test RE 0.764540436690352\n",
      "61 Train Loss 0.6955424 Test MSE 2.5710216953809404 Test RE 0.7664095910694544\n",
      "62 Train Loss 0.6874689 Test MSE 2.6032008261714656 Test RE 0.7711909012640924\n",
      "63 Train Loss 0.67638195 Test MSE 2.629658968707805 Test RE 0.7751000685229024\n",
      "64 Train Loss 0.67002344 Test MSE 2.633262196633599 Test RE 0.7756309179955868\n",
      "65 Train Loss 0.66610366 Test MSE 2.628082187106771 Test RE 0.7748676530646171\n",
      "66 Train Loss 0.65924764 Test MSE 2.611978775664433 Test RE 0.7724900284146011\n",
      "67 Train Loss 0.6546198 Test MSE 2.6249174823013766 Test RE 0.7744009693973981\n",
      "68 Train Loss 0.6517496 Test MSE 2.6324367458123707 Test RE 0.7755093396428014\n",
      "69 Train Loss 0.64700186 Test MSE 2.644731732533989 Test RE 0.7773182662274122\n",
      "70 Train Loss 0.64325297 Test MSE 2.655672153085367 Test RE 0.7789243671388512\n",
      "71 Train Loss 0.6391423 Test MSE 2.6728651905405445 Test RE 0.7814417091868603\n",
      "72 Train Loss 0.63507736 Test MSE 2.678675239928689 Test RE 0.7822905642533398\n",
      "73 Train Loss 0.63019854 Test MSE 2.6973594760908775 Test RE 0.7850141310681057\n",
      "74 Train Loss 0.6254836 Test MSE 2.7088876876898857 Test RE 0.7866898736290109\n",
      "75 Train Loss 0.6221772 Test MSE 2.702424345723716 Test RE 0.7857508014255962\n",
      "76 Train Loss 0.61858296 Test MSE 2.706863895739937 Test RE 0.7863959533397127\n",
      "77 Train Loss 0.61470544 Test MSE 2.7169397865605056 Test RE 0.7878582137501146\n",
      "78 Train Loss 0.6127249 Test MSE 2.7200726314057593 Test RE 0.788312314066941\n",
      "79 Train Loss 0.6090786 Test MSE 2.7210375127065882 Test RE 0.7884521192251863\n",
      "80 Train Loss 0.6051877 Test MSE 2.7164211113262193 Test RE 0.787783007437045\n",
      "81 Train Loss 0.60121346 Test MSE 2.7010781523119167 Test RE 0.7855550689683392\n",
      "82 Train Loss 0.59828264 Test MSE 2.700081096234199 Test RE 0.7854100685823531\n",
      "83 Train Loss 0.59392494 Test MSE 2.701887605875058 Test RE 0.7856727669174215\n",
      "84 Train Loss 0.5901321 Test MSE 2.7035324082306507 Test RE 0.7859118737927562\n",
      "85 Train Loss 0.5854018 Test MSE 2.7004974070298498 Test RE 0.7854706152985944\n",
      "86 Train Loss 0.5820041 Test MSE 2.706901328681931 Test RE 0.7864013908152322\n",
      "87 Train Loss 0.5791356 Test MSE 2.713104129230316 Test RE 0.7873018853642167\n",
      "88 Train Loss 0.57571405 Test MSE 2.7246256279943935 Test RE 0.7889717969335746\n",
      "89 Train Loss 0.5731476 Test MSE 2.7247515051793703 Test RE 0.7889900218964397\n",
      "90 Train Loss 0.56976163 Test MSE 2.721911657362024 Test RE 0.7885787558220657\n",
      "91 Train Loss 0.56564075 Test MSE 2.741380997959717 Test RE 0.791394010974696\n",
      "92 Train Loss 0.5630021 Test MSE 2.754154725022208 Test RE 0.7932356561958451\n",
      "93 Train Loss 0.5589974 Test MSE 2.7585437294206927 Test RE 0.7938674523738684\n",
      "94 Train Loss 0.5557965 Test MSE 2.772035776560598 Test RE 0.7958064885667432\n",
      "95 Train Loss 0.55336654 Test MSE 2.7831693606830825 Test RE 0.7974030227624334\n",
      "96 Train Loss 0.5505112 Test MSE 2.7900682904799274 Test RE 0.7983907137479016\n",
      "97 Train Loss 0.54682326 Test MSE 2.797769841572241 Test RE 0.7994918712905568\n",
      "98 Train Loss 0.54272187 Test MSE 2.8023714991206443 Test RE 0.8001490869468162\n",
      "99 Train Loss 0.5402602 Test MSE 2.799529538461825 Test RE 0.7997432576253344\n",
      "Training time: 84.94\n",
      "9\n",
      "KG_rowdy_tune3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.93423 Test MSE 8.662470614431767 Test RE 1.4067889470505086\n",
      "1 Train Loss 47.623596 Test MSE 8.495351394423182 Test RE 1.3931527416698979\n",
      "2 Train Loss 45.767555 Test MSE 8.741198656345455 Test RE 1.4131672216478948\n",
      "3 Train Loss 44.56201 Test MSE 8.685318635128485 Test RE 1.4086429894915078\n",
      "4 Train Loss 43.642616 Test MSE 8.443163525655741 Test RE 1.3888670050898684\n",
      "5 Train Loss 42.797188 Test MSE 8.545978006873918 Test RE 1.397297704826749\n",
      "6 Train Loss 42.042805 Test MSE 8.577647094987597 Test RE 1.3998843148194404\n",
      "7 Train Loss 41.372086 Test MSE 8.597458193496742 Test RE 1.4014999823161067\n",
      "8 Train Loss 40.782543 Test MSE 8.862081882814818 Test RE 1.4229051115602294\n",
      "9 Train Loss 39.058987 Test MSE 8.914550719858859 Test RE 1.4271111208279852\n",
      "10 Train Loss 37.90978 Test MSE 9.384028494695398 Test RE 1.4642078106032055\n",
      "11 Train Loss 35.706066 Test MSE 8.773715164184813 Test RE 1.4157932121131032\n",
      "12 Train Loss 32.038948 Test MSE 8.706398816510605 Test RE 1.4103514157975878\n",
      "13 Train Loss 30.075144 Test MSE 8.703841887901271 Test RE 1.41014430188244\n",
      "14 Train Loss 29.055622 Test MSE 8.797905196855373 Test RE 1.4177436122304856\n",
      "15 Train Loss 28.516598 Test MSE 8.560975533725363 Test RE 1.398523241789716\n",
      "16 Train Loss 27.890749 Test MSE 8.633395000045478 Test RE 1.404426016457562\n",
      "17 Train Loss 27.525562 Test MSE 8.464051365899875 Test RE 1.3905839274088307\n",
      "18 Train Loss 27.097721 Test MSE 8.359383508275414 Test RE 1.381959085106339\n",
      "19 Train Loss 26.876133 Test MSE 8.362370685995229 Test RE 1.3822059806254394\n",
      "20 Train Loss 26.426208 Test MSE 8.205411782536704 Test RE 1.3691727614389573\n",
      "21 Train Loss 25.767633 Test MSE 8.200990480246565 Test RE 1.3688038377031495\n",
      "22 Train Loss 25.174366 Test MSE 7.849201789032144 Test RE 1.3391240424117374\n",
      "23 Train Loss 24.563423 Test MSE 7.654858306850068 Test RE 1.3224420142005624\n",
      "24 Train Loss 21.820717 Test MSE 6.708299617828409 Test RE 1.2379818742759943\n",
      "25 Train Loss 20.124012 Test MSE 6.842879701194573 Test RE 1.2503382374319234\n",
      "26 Train Loss 19.351414 Test MSE 6.776736179028249 Test RE 1.2442806564221787\n",
      "27 Train Loss 18.473053 Test MSE 6.528593748688374 Test RE 1.2212874173880752\n",
      "28 Train Loss 17.52275 Test MSE 5.9750610966833415 Test RE 1.1683668748228517\n",
      "29 Train Loss 16.074306 Test MSE 5.78799377533846 Test RE 1.149931810418801\n",
      "30 Train Loss 15.021425 Test MSE 5.681372917542376 Test RE 1.1392911102185754\n",
      "31 Train Loss 14.580051 Test MSE 5.683833819635798 Test RE 1.1395378270226615\n",
      "32 Train Loss 14.462296 Test MSE 5.696950938826154 Test RE 1.140851978702485\n",
      "33 Train Loss 14.2284565 Test MSE 5.714070654897852 Test RE 1.1425648608332502\n",
      "34 Train Loss 14.050505 Test MSE 5.755124849097259 Test RE 1.1466620386481565\n",
      "35 Train Loss 13.875399 Test MSE 5.766372380766821 Test RE 1.147781981543373\n",
      "36 Train Loss 13.689539 Test MSE 5.6658316101599 Test RE 1.1377317865426562\n",
      "37 Train Loss 13.5232935 Test MSE 5.6810007003494 Test RE 1.139253789073574\n",
      "38 Train Loss 13.385269 Test MSE 5.605581970768141 Test RE 1.131666380596458\n",
      "39 Train Loss 13.287909 Test MSE 5.62803940353258 Test RE 1.1339309909916109\n",
      "40 Train Loss 13.211082 Test MSE 5.57485520962323 Test RE 1.1285605278303554\n",
      "41 Train Loss 13.077267 Test MSE 5.5209248240351405 Test RE 1.1230884917656658\n",
      "42 Train Loss 12.930323 Test MSE 5.624332610972073 Test RE 1.1335575093060988\n",
      "43 Train Loss 12.6952 Test MSE 5.549245684698158 Test RE 1.1259653781443948\n",
      "44 Train Loss 11.89118 Test MSE 5.030671019673598 Test RE 1.0720647565246397\n",
      "45 Train Loss 10.177332 Test MSE 4.336996612765871 Test RE 0.9954113806185266\n",
      "46 Train Loss 9.6742115 Test MSE 4.565741164394345 Test RE 1.021324391500693\n",
      "47 Train Loss 9.202503 Test MSE 4.458928920455869 Test RE 1.0093071154050854\n",
      "48 Train Loss 8.979263 Test MSE 4.521043312147635 Test RE 1.0163127970708044\n",
      "49 Train Loss 8.516232 Test MSE 4.515180752886985 Test RE 1.0156536431565533\n",
      "50 Train Loss 8.044072 Test MSE 4.53230357163932 Test RE 1.017577641070614\n",
      "51 Train Loss 6.389257 Test MSE 3.9903783563285864 Test RE 0.9548059097150057\n",
      "52 Train Loss 5.8024864 Test MSE 3.8520904526324724 Test RE 0.9381154715938974\n",
      "53 Train Loss 5.4168983 Test MSE 3.9967965461211805 Test RE 0.9555734639206477\n",
      "54 Train Loss 5.307234 Test MSE 3.9646252680507676 Test RE 0.9517198611445699\n",
      "55 Train Loss 4.973899 Test MSE 3.5408395994251736 Test RE 0.8994171969740151\n",
      "56 Train Loss 4.7321844 Test MSE 3.4858735695439176 Test RE 0.8924088653955548\n",
      "57 Train Loss 4.4826956 Test MSE 3.298980233840045 Test RE 0.8681562916723423\n",
      "58 Train Loss 4.0725756 Test MSE 3.22205129507719 Test RE 0.8579743123829379\n",
      "59 Train Loss 3.904327 Test MSE 3.164307336513988 Test RE 0.8502514658935404\n",
      "60 Train Loss 3.7357562 Test MSE 2.8681294920295235 Test RE 0.8094824508037862\n",
      "61 Train Loss 3.1996963 Test MSE 2.5650327582161436 Test RE 0.7655164335003694\n",
      "62 Train Loss 2.8817732 Test MSE 2.577487159568937 Test RE 0.7673726483672391\n",
      "63 Train Loss 2.699505 Test MSE 2.5214956895496785 Test RE 0.7589919597885046\n",
      "64 Train Loss 2.5413635 Test MSE 2.5375987906288633 Test RE 0.7614116888273615\n",
      "65 Train Loss 2.4146256 Test MSE 2.563348658034099 Test RE 0.7652650881635507\n",
      "66 Train Loss 2.3537426 Test MSE 2.4795981820381012 Test RE 0.7526597899182049\n",
      "67 Train Loss 2.3198433 Test MSE 2.4767610381588385 Test RE 0.752229071886752\n",
      "68 Train Loss 2.250407 Test MSE 2.5414783606498794 Test RE 0.7619935029835592\n",
      "69 Train Loss 2.1997173 Test MSE 2.5020492372755956 Test RE 0.7560595199380039\n",
      "70 Train Loss 2.1534393 Test MSE 2.527348544390758 Test RE 0.7598723291147261\n",
      "71 Train Loss 2.0932884 Test MSE 2.549489856906542 Test RE 0.7631935731464311\n",
      "72 Train Loss 2.0650153 Test MSE 2.5457331110192825 Test RE 0.7626310721257771\n",
      "73 Train Loss 2.0240567 Test MSE 2.5388125589570416 Test RE 0.7615937638879967\n",
      "74 Train Loss 1.9891086 Test MSE 2.5618752216617473 Test RE 0.7650451158447714\n",
      "75 Train Loss 1.9325901 Test MSE 2.5629366692469606 Test RE 0.7652035878866092\n",
      "76 Train Loss 1.8956791 Test MSE 2.53355870430953 Test RE 0.760805329319494\n",
      "77 Train Loss 1.8740156 Test MSE 2.5271554412471415 Test RE 0.7598432993754869\n",
      "78 Train Loss 1.850039 Test MSE 2.5211261506723504 Test RE 0.7589363405552468\n",
      "79 Train Loss 1.8198445 Test MSE 2.532948829626544 Test RE 0.7607137538145105\n",
      "80 Train Loss 1.8057336 Test MSE 2.5392171794930434 Test RE 0.7616544505658738\n",
      "81 Train Loss 1.7533361 Test MSE 2.545853406286326 Test RE 0.7626490904766267\n",
      "82 Train Loss 1.7320707 Test MSE 2.54986917689038 Test RE 0.7632503460349173\n",
      "83 Train Loss 1.716349 Test MSE 2.5542577580682577 Test RE 0.7639068789520356\n",
      "84 Train Loss 1.6929051 Test MSE 2.5561285326235907 Test RE 0.7641865758562018\n",
      "85 Train Loss 1.673475 Test MSE 2.5450468039150733 Test RE 0.762528265904433\n",
      "86 Train Loss 1.6605765 Test MSE 2.556544282354615 Test RE 0.7642487201188249\n",
      "87 Train Loss 1.648808 Test MSE 2.574291282974535 Test RE 0.7668967606499968\n",
      "88 Train Loss 1.62901 Test MSE 2.5656526928616277 Test RE 0.7656089355330277\n",
      "89 Train Loss 1.6160638 Test MSE 2.5560827516328923 Test RE 0.7641797324258491\n",
      "90 Train Loss 1.6006868 Test MSE 2.5464508328244047 Test RE 0.7627385693283579\n",
      "91 Train Loss 1.5861984 Test MSE 2.5348584023194083 Test RE 0.7610004482226341\n",
      "92 Train Loss 1.580978 Test MSE 2.5317883648465673 Test RE 0.7605394742075011\n",
      "93 Train Loss 1.5730363 Test MSE 2.5321252013872826 Test RE 0.7605900647246712\n",
      "94 Train Loss 1.566884 Test MSE 2.525017855581847 Test RE 0.7595218759826492\n",
      "95 Train Loss 1.5607388 Test MSE 2.514740507180597 Test RE 0.7579745938502896\n",
      "96 Train Loss 1.5570228 Test MSE 2.507360060904498 Test RE 0.7568614966245627\n",
      "97 Train Loss 1.5510206 Test MSE 2.5092321731769385 Test RE 0.7571439979953585\n",
      "98 Train Loss 1.5476449 Test MSE 2.5144534716356777 Test RE 0.7579313345440873\n",
      "99 Train Loss 1.539198 Test MSE 2.5121450118093667 Test RE 0.7575833353028993\n",
      "Training time: 86.00\n",
      "0\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.264587 Test MSE 6.021221849787849 Test RE 1.1728713417400485\n",
      "1 Train Loss 39.28007 Test MSE 6.5211699952344775 Test RE 1.2205928485483388\n",
      "2 Train Loss 28.72147 Test MSE 6.135027262280953 Test RE 1.183903511656133\n",
      "3 Train Loss 23.173754 Test MSE 5.607121958986112 Test RE 1.1318218179109312\n",
      "4 Train Loss 19.7342 Test MSE 5.607853413085975 Test RE 1.1318956390902777\n",
      "5 Train Loss 16.637669 Test MSE 5.778956402394848 Test RE 1.1490337079965578\n",
      "6 Train Loss 14.494524 Test MSE 6.2790854291028095 Test RE 1.197722632525373\n",
      "7 Train Loss 13.395145 Test MSE 6.175892757649981 Test RE 1.1878399655897838\n",
      "8 Train Loss 12.641857 Test MSE 6.062643975759909 Test RE 1.1768987266477042\n",
      "9 Train Loss 11.896844 Test MSE 6.016928314151098 Test RE 1.172453099142566\n",
      "10 Train Loss 11.0399685 Test MSE 5.873329713692685 Test RE 1.1583778675832002\n",
      "11 Train Loss 9.516745 Test MSE 5.4388665293527145 Test RE 1.1147109336379457\n",
      "12 Train Loss 8.179528 Test MSE 5.007716569994116 Test RE 1.0696160978518052\n",
      "13 Train Loss 7.082816 Test MSE 4.983525377165417 Test RE 1.0670294284486987\n",
      "14 Train Loss 6.1347485 Test MSE 4.815455084817068 Test RE 1.0488822318505406\n",
      "15 Train Loss 5.507153 Test MSE 4.4558382042453335 Test RE 1.0089572530642659\n",
      "16 Train Loss 4.912257 Test MSE 4.2738654774521505 Test RE 0.9881400102986715\n",
      "17 Train Loss 4.404381 Test MSE 4.009133922225069 Test RE 0.957047167331784\n",
      "18 Train Loss 3.988079 Test MSE 3.9834508377689324 Test RE 0.9539767516351095\n",
      "19 Train Loss 3.7359228 Test MSE 3.8344441387299155 Test RE 0.9359642653190042\n",
      "20 Train Loss 3.4550247 Test MSE 3.656993032792369 Test RE 0.9140503657048092\n",
      "21 Train Loss 3.232306 Test MSE 3.4897515805033255 Test RE 0.8929051268498286\n",
      "22 Train Loss 3.0034497 Test MSE 3.303140563755251 Test RE 0.8687035332956932\n",
      "23 Train Loss 2.8133001 Test MSE 3.170108918311927 Test RE 0.8510305533791885\n",
      "24 Train Loss 2.607252 Test MSE 2.944003120355537 Test RE 0.8201196038969698\n",
      "25 Train Loss 2.42886 Test MSE 2.9059547360303024 Test RE 0.8148027440794163\n",
      "26 Train Loss 2.2571335 Test MSE 2.704353580087933 Test RE 0.7860312213012992\n",
      "27 Train Loss 2.0689151 Test MSE 2.341237204804786 Test RE 0.7313592670964805\n",
      "28 Train Loss 1.9182743 Test MSE 2.354359959088071 Test RE 0.733406056064926\n",
      "29 Train Loss 1.8268583 Test MSE 2.355564866016068 Test RE 0.7335937021810147\n",
      "30 Train Loss 1.7254815 Test MSE 2.3314204230319295 Test RE 0.7298243657807341\n",
      "31 Train Loss 1.6569228 Test MSE 2.2307628701896927 Test RE 0.7138956964475063\n",
      "32 Train Loss 1.6014011 Test MSE 2.158025290255982 Test RE 0.702160387872948\n",
      "33 Train Loss 1.5302777 Test MSE 2.05821142756437 Test RE 0.6857298468847888\n",
      "34 Train Loss 1.4673599 Test MSE 1.9495953759104483 Test RE 0.667390934825237\n",
      "35 Train Loss 1.4180284 Test MSE 1.8688075843720504 Test RE 0.6534168870224507\n",
      "36 Train Loss 1.3655236 Test MSE 1.8314562734221527 Test RE 0.6468541032364363\n",
      "37 Train Loss 1.2747262 Test MSE 1.7016330493006266 Test RE 0.6235065443703426\n",
      "38 Train Loss 1.2309498 Test MSE 1.668442248037542 Test RE 0.6173957697957458\n",
      "39 Train Loss 1.197432 Test MSE 1.66068676923837 Test RE 0.6159591671598372\n",
      "40 Train Loss 1.1449317 Test MSE 1.617454500889566 Test RE 0.607888736782486\n",
      "41 Train Loss 1.0966508 Test MSE 1.5541607660011865 Test RE 0.5958761881360768\n",
      "42 Train Loss 1.0575659 Test MSE 1.4999959988378855 Test RE 0.5854005290391127\n",
      "43 Train Loss 0.997038 Test MSE 1.4523689070511012 Test RE 0.5760318958043428\n",
      "44 Train Loss 0.9674712 Test MSE 1.4006767452245616 Test RE 0.5656880694761766\n",
      "45 Train Loss 0.92621934 Test MSE 1.3855563586023179 Test RE 0.5626264667682296\n",
      "46 Train Loss 0.88753086 Test MSE 1.2473316154436944 Test RE 0.5338251434498642\n",
      "47 Train Loss 0.8249353 Test MSE 0.9584544754841569 Test RE 0.46794391596024787\n",
      "48 Train Loss 0.7532528 Test MSE 0.9103993513166525 Test RE 0.4560621497689389\n",
      "49 Train Loss 0.67093575 Test MSE 0.6579978226849881 Test RE 0.38772186094336186\n",
      "50 Train Loss 0.58392113 Test MSE 0.4690671186817162 Test RE 0.32735995731067313\n",
      "51 Train Loss 0.5105419 Test MSE 0.48182477824565567 Test RE 0.3317818507291911\n",
      "52 Train Loss 0.43389854 Test MSE 0.4239918042592758 Test RE 0.3112338257264411\n",
      "53 Train Loss 0.36164317 Test MSE 0.3637807983206004 Test RE 0.28828891664203\n",
      "54 Train Loss 0.3256999 Test MSE 0.3340512363319096 Test RE 0.2762578337397094\n",
      "55 Train Loss 0.27825275 Test MSE 0.2889345307365515 Test RE 0.2569258394392232\n",
      "56 Train Loss 0.23442528 Test MSE 0.22114223690608217 Test RE 0.22477287959220466\n",
      "57 Train Loss 0.20942032 Test MSE 0.1776086398047011 Test RE 0.2014373986857035\n",
      "58 Train Loss 0.17107803 Test MSE 0.12705813568833996 Test RE 0.17037634591025017\n",
      "59 Train Loss 0.15060344 Test MSE 0.09249523742900916 Test RE 0.14536764207242087\n",
      "60 Train Loss 0.12683803 Test MSE 0.0792970359472282 Test RE 0.1345973586436347\n",
      "61 Train Loss 0.10524546 Test MSE 0.05813638423165431 Test RE 0.11524764748566495\n",
      "62 Train Loss 0.09066095 Test MSE 0.041168250555101864 Test RE 0.0969815824667193\n",
      "63 Train Loss 0.08091465 Test MSE 0.025024810606385388 Test RE 0.07561247604764464\n",
      "64 Train Loss 0.07153088 Test MSE 0.0195102915041382 Test RE 0.06676362965689035\n",
      "65 Train Loss 0.059368372 Test MSE 0.015685412739940698 Test RE 0.059862663442283505\n",
      "66 Train Loss 0.053358063 Test MSE 0.012620525762722283 Test RE 0.05369659957131465\n",
      "67 Train Loss 0.04964403 Test MSE 0.012043341838569954 Test RE 0.05245435692290124\n",
      "68 Train Loss 0.04440899 Test MSE 0.00953443871509425 Test RE 0.04667191556192083\n",
      "69 Train Loss 0.039346837 Test MSE 0.0079951989047661 Test RE 0.0427388366576863\n",
      "70 Train Loss 0.033511605 Test MSE 0.006809857068153823 Test RE 0.039443646559511714\n",
      "71 Train Loss 0.030667117 Test MSE 0.006281712227024272 Test RE 0.03788323680648114\n",
      "72 Train Loss 0.028639756 Test MSE 0.0059225093082844295 Test RE 0.03678416790102164\n",
      "73 Train Loss 0.027457245 Test MSE 0.006280935733598173 Test RE 0.037880895327567755\n",
      "74 Train Loss 0.025795832 Test MSE 0.005974258022664301 Test RE 0.036944521669390974\n",
      "75 Train Loss 0.022872796 Test MSE 0.00521259083139969 Test RE 0.03450919894170779\n",
      "76 Train Loss 0.02088768 Test MSE 0.0056494515739853295 Test RE 0.03592619356113002\n",
      "77 Train Loss 0.01925022 Test MSE 0.005448897875113337 Test RE 0.03528274731667942\n",
      "78 Train Loss 0.018236337 Test MSE 0.005030342951985404 Test RE 0.03390055885692245\n",
      "79 Train Loss 0.016188202 Test MSE 0.00614632893796711 Test RE 0.03747278400522246\n",
      "80 Train Loss 0.015296655 Test MSE 0.005857174110787161 Test RE 0.03658070973225831\n",
      "81 Train Loss 0.013695009 Test MSE 0.005352616407827127 Test RE 0.03496963672860531\n",
      "82 Train Loss 0.012349329 Test MSE 0.005624129029652714 Test RE 0.03584558712141591\n",
      "83 Train Loss 0.011660651 Test MSE 0.005933539092936872 Test RE 0.036818404464134105\n",
      "84 Train Loss 0.011164879 Test MSE 0.005255991539166257 Test RE 0.034652565173389833\n",
      "85 Train Loss 0.010108473 Test MSE 0.004386287994834713 Test RE 0.031656043341605905\n",
      "86 Train Loss 0.009546194 Test MSE 0.005049695448809279 Test RE 0.033965706569865896\n",
      "87 Train Loss 0.009123299 Test MSE 0.005078363488922432 Test RE 0.034061984864906365\n",
      "88 Train Loss 0.008699271 Test MSE 0.005115093783999844 Test RE 0.0341849430463181\n",
      "89 Train Loss 0.008431608 Test MSE 0.005391997217233226 Test RE 0.03509804205180889\n",
      "90 Train Loss 0.008177167 Test MSE 0.005395079584921458 Test RE 0.0351080726220817\n",
      "91 Train Loss 0.0077638766 Test MSE 0.0051240205758888374 Test RE 0.03421475959124959\n",
      "92 Train Loss 0.007472286 Test MSE 0.0052715931439572435 Test RE 0.03470395747669394\n",
      "93 Train Loss 0.0071008466 Test MSE 0.005554620211663896 Test RE 0.03562338998505615\n",
      "94 Train Loss 0.0067522386 Test MSE 0.005313667797624919 Test RE 0.03484217518429603\n",
      "95 Train Loss 0.00641754 Test MSE 0.0051452949993759265 Test RE 0.03428571415684356\n",
      "96 Train Loss 0.00611523 Test MSE 0.005262031248163035 Test RE 0.03467246925028204\n",
      "97 Train Loss 0.005876023 Test MSE 0.005439409344877713 Test RE 0.03525201382765667\n",
      "98 Train Loss 0.005584156 Test MSE 0.005472083964422481 Test RE 0.03535773500559329\n",
      "99 Train Loss 0.0052331616 Test MSE 0.005243652466423484 Test RE 0.034611865738906886\n",
      "Training time: 84.59\n",
      "1\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.97531 Test MSE 7.7261802667857 Test RE 1.3285884686602425\n",
      "1 Train Loss 46.662483 Test MSE 9.369258982142284 Test RE 1.463055099297211\n",
      "2 Train Loss 40.728485 Test MSE 9.589784311889762 Test RE 1.4801730069285757\n",
      "3 Train Loss 38.484856 Test MSE 9.72343505591696 Test RE 1.4904517427998643\n",
      "4 Train Loss 35.806297 Test MSE 9.690447615251834 Test RE 1.4879213634136434\n",
      "5 Train Loss 31.89207 Test MSE 9.575504970113037 Test RE 1.4790705957923191\n",
      "6 Train Loss 28.812971 Test MSE 9.190604951949577 Test RE 1.4490391177712316\n",
      "7 Train Loss 26.187645 Test MSE 9.394615556709162 Test RE 1.4650335374816972\n",
      "8 Train Loss 23.772701 Test MSE 9.05147864932858 Test RE 1.4380296013666165\n",
      "9 Train Loss 22.697277 Test MSE 8.9503373978885 Test RE 1.4299727576532666\n",
      "10 Train Loss 21.481726 Test MSE 8.845237341108936 Test RE 1.421552179766659\n",
      "11 Train Loss 20.536121 Test MSE 9.054409866264574 Test RE 1.4382624271667668\n",
      "12 Train Loss 19.580505 Test MSE 9.027503753821264 Test RE 1.4361238647001535\n",
      "13 Train Loss 18.758894 Test MSE 8.981906197934626 Test RE 1.4324923715218054\n",
      "14 Train Loss 16.902931 Test MSE 8.612580420160105 Test RE 1.4027320027906907\n",
      "15 Train Loss 15.699496 Test MSE 8.398444651694904 Test RE 1.3851840830576763\n",
      "16 Train Loss 15.050774 Test MSE 8.179580623715134 Test RE 1.3670159411272462\n",
      "17 Train Loss 14.546895 Test MSE 8.373522691087485 Test RE 1.3831273241660949\n",
      "18 Train Loss 14.056612 Test MSE 8.416834581042592 Test RE 1.3866998106141823\n",
      "19 Train Loss 13.750118 Test MSE 8.557953315098686 Test RE 1.3982763647798702\n",
      "20 Train Loss 13.47641 Test MSE 8.655291957672302 Test RE 1.4062059177652866\n",
      "21 Train Loss 13.237955 Test MSE 8.60763404092738 Test RE 1.4023291362502588\n",
      "22 Train Loss 12.999063 Test MSE 8.64161803425064 Test RE 1.405094692832955\n",
      "23 Train Loss 12.835899 Test MSE 8.601524949718645 Test RE 1.4018314107921226\n",
      "24 Train Loss 12.626228 Test MSE 8.517931050417772 Test RE 1.3950029320696353\n",
      "25 Train Loss 12.462476 Test MSE 8.564657746542876 Test RE 1.3988239730888201\n",
      "26 Train Loss 12.293638 Test MSE 8.526055783189738 Test RE 1.3956680774289945\n",
      "27 Train Loss 12.155391 Test MSE 8.491146950819084 Test RE 1.3928079556352366\n",
      "28 Train Loss 11.93056 Test MSE 8.48554153931871 Test RE 1.3923481502232244\n",
      "29 Train Loss 11.592777 Test MSE 8.383037233932034 Test RE 1.383912900830194\n",
      "30 Train Loss 11.222704 Test MSE 8.312821956660812 Test RE 1.3781049724656125\n",
      "31 Train Loss 10.676661 Test MSE 8.012427093328542 Test RE 1.3529760399647017\n",
      "32 Train Loss 9.845029 Test MSE 6.946107584516533 Test RE 1.2597338898391761\n",
      "33 Train Loss 8.237915 Test MSE 6.374932765632112 Test RE 1.2068293528392549\n",
      "34 Train Loss 7.214036 Test MSE 6.024562113834328 Test RE 1.1731966209680647\n",
      "35 Train Loss 6.8509736 Test MSE 5.865860139926082 Test RE 1.1576410332704612\n",
      "36 Train Loss 6.48763 Test MSE 5.874115528911605 Test RE 1.158455356891383\n",
      "37 Train Loss 5.2315445 Test MSE 5.375216459062813 Test RE 1.1081691077411182\n",
      "38 Train Loss 4.1121144 Test MSE 5.015851760132992 Test RE 1.0704845574682307\n",
      "39 Train Loss 3.6229703 Test MSE 4.816562417486596 Test RE 1.0490028221974943\n",
      "40 Train Loss 3.2613451 Test MSE 4.814672790100274 Test RE 1.0487970303128074\n",
      "41 Train Loss 3.093544 Test MSE 4.805167602468002 Test RE 1.0477612446949225\n",
      "42 Train Loss 2.9451706 Test MSE 4.859193051187778 Test RE 1.0536348745867445\n",
      "43 Train Loss 2.7970107 Test MSE 4.908367188418229 Test RE 1.0589527497502125\n",
      "44 Train Loss 2.6711814 Test MSE 4.904840067094478 Test RE 1.058572203030813\n",
      "45 Train Loss 2.5506465 Test MSE 4.9588114819226305 Test RE 1.0643803771858666\n",
      "46 Train Loss 2.4665802 Test MSE 4.931510226539259 Test RE 1.0614463043920306\n",
      "47 Train Loss 2.412898 Test MSE 4.944626889400916 Test RE 1.0628569663633307\n",
      "48 Train Loss 2.3643818 Test MSE 4.965394685711605 Test RE 1.0650866662741003\n",
      "49 Train Loss 2.2953162 Test MSE 5.008058899939836 Test RE 1.0696526569659315\n",
      "50 Train Loss 2.2561269 Test MSE 5.068690639054572 Test RE 1.0761082303327298\n",
      "51 Train Loss 2.196693 Test MSE 5.11324562457352 Test RE 1.0808275046438087\n",
      "52 Train Loss 2.119933 Test MSE 5.113570877532949 Test RE 1.0808618797530947\n",
      "53 Train Loss 2.0789142 Test MSE 5.120524003062638 Test RE 1.081596475548213\n",
      "54 Train Loss 2.0476205 Test MSE 5.139641973577712 Test RE 1.0836137168209619\n",
      "55 Train Loss 1.9931316 Test MSE 5.181538210032869 Test RE 1.0880213382819712\n",
      "56 Train Loss 1.9457705 Test MSE 5.223577624245467 Test RE 1.0924261479247526\n",
      "57 Train Loss 1.9060174 Test MSE 5.223382701410499 Test RE 1.0924057652671562\n",
      "58 Train Loss 1.8680528 Test MSE 5.249414625676334 Test RE 1.0951245092960367\n",
      "59 Train Loss 1.8373681 Test MSE 5.291074264109408 Test RE 1.0994614055121685\n",
      "60 Train Loss 1.8036065 Test MSE 5.277634069571604 Test RE 1.0980641116584056\n",
      "61 Train Loss 1.7738283 Test MSE 5.326820068987813 Test RE 1.1031690625839494\n",
      "62 Train Loss 1.7542931 Test MSE 5.318300984806287 Test RE 1.1022865707310077\n",
      "63 Train Loss 1.7265352 Test MSE 5.2661205135084295 Test RE 1.0968657029317308\n",
      "64 Train Loss 1.7043968 Test MSE 5.307487283368531 Test RE 1.1011653608551533\n",
      "65 Train Loss 1.6851879 Test MSE 5.309514597575789 Test RE 1.101375648221141\n",
      "66 Train Loss 1.6610911 Test MSE 5.2709335204087795 Test RE 1.0973668324149084\n",
      "67 Train Loss 1.6301748 Test MSE 5.330939310775844 Test RE 1.103595521697328\n",
      "68 Train Loss 1.6124411 Test MSE 5.347069364022744 Test RE 1.1052638589704757\n",
      "69 Train Loss 1.5998471 Test MSE 5.333590229741329 Test RE 1.1038698803536624\n",
      "70 Train Loss 1.5852059 Test MSE 5.358298168170197 Test RE 1.1064237730982156\n",
      "71 Train Loss 1.5674715 Test MSE 5.378157889710803 Test RE 1.108472272905983\n",
      "72 Train Loss 1.5554848 Test MSE 5.375167910043752 Test RE 1.1081641032315301\n",
      "73 Train Loss 1.5403374 Test MSE 5.369706025845479 Test RE 1.1076009392090207\n",
      "74 Train Loss 1.5274575 Test MSE 5.365869124667323 Test RE 1.1072051526649593\n",
      "75 Train Loss 1.5135696 Test MSE 5.374136012310921 Test RE 1.1080577282371522\n",
      "76 Train Loss 1.5032184 Test MSE 5.38448712025421 Test RE 1.1091243282948664\n",
      "77 Train Loss 1.4919524 Test MSE 5.381232052124835 Test RE 1.108789029782292\n",
      "78 Train Loss 1.4792037 Test MSE 5.349571870985394 Test RE 1.1055224685719272\n",
      "79 Train Loss 1.4658365 Test MSE 5.369353804267918 Test RE 1.1075646125138658\n",
      "80 Train Loss 1.4555368 Test MSE 5.377164729915175 Test RE 1.108369919930543\n",
      "81 Train Loss 1.4432188 Test MSE 5.362246126464598 Test RE 1.1068313008684014\n",
      "82 Train Loss 1.4333322 Test MSE 5.358757102704655 Test RE 1.1064711542993995\n",
      "83 Train Loss 1.4252822 Test MSE 5.366819290554878 Test RE 1.107303177977733\n",
      "84 Train Loss 1.4133272 Test MSE 5.380158198782564 Test RE 1.1086783919022147\n",
      "85 Train Loss 1.4010308 Test MSE 5.404344946896287 Test RE 1.1111676546883262\n",
      "86 Train Loss 1.3862425 Test MSE 5.427603327156622 Test RE 1.1135561230380677\n",
      "87 Train Loss 1.377994 Test MSE 5.428143744813239 Test RE 1.1136115591463551\n",
      "88 Train Loss 1.3675965 Test MSE 5.430809078815229 Test RE 1.1138849290704722\n",
      "89 Train Loss 1.3596206 Test MSE 5.4416939545283185 Test RE 1.1150006403471906\n",
      "90 Train Loss 1.3467263 Test MSE 5.467681744045171 Test RE 1.1176599123542716\n",
      "91 Train Loss 1.3325026 Test MSE 5.484059742221399 Test RE 1.1193325906065834\n",
      "92 Train Loss 1.3139421 Test MSE 5.526775623324277 Test RE 1.1236834306197154\n",
      "93 Train Loss 1.3019235 Test MSE 5.546449503033075 Test RE 1.1256816638674365\n",
      "94 Train Loss 1.2883321 Test MSE 5.538933842041765 Test RE 1.1249187334828663\n",
      "95 Train Loss 1.2737126 Test MSE 5.538958062372215 Test RE 1.1249211929700573\n",
      "96 Train Loss 1.2648345 Test MSE 5.555814487416593 Test RE 1.1266315999486094\n",
      "97 Train Loss 1.2525234 Test MSE 5.570879758723483 Test RE 1.1281580656206571\n",
      "98 Train Loss 1.237119 Test MSE 5.566432817228325 Test RE 1.1277077009830283\n",
      "99 Train Loss 1.2267559 Test MSE 5.574445080666949 Test RE 1.1285190142979789\n",
      "Training time: 84.67\n",
      "2\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.121067 Test MSE 6.998579903923501 Test RE 1.2644830815347234\n",
      "1 Train Loss 40.30931 Test MSE 6.2948310160271514 Test RE 1.1992234114293998\n",
      "2 Train Loss 28.925877 Test MSE 5.393914819452964 Test RE 1.1100948866082871\n",
      "3 Train Loss 23.271833 Test MSE 4.180329055341312 Test RE 0.9772671366013866\n",
      "4 Train Loss 18.156986 Test MSE 3.668566527886023 Test RE 0.9154955969024599\n",
      "5 Train Loss 13.833395 Test MSE 3.899267186219477 Test RE 0.9438425621975686\n",
      "6 Train Loss 12.159714 Test MSE 3.8619706912236955 Test RE 0.9393177887529718\n",
      "7 Train Loss 10.984031 Test MSE 3.7543958798831696 Test RE 0.9261430938392243\n",
      "8 Train Loss 9.564684 Test MSE 3.7136625620057027 Test RE 0.9211052974599505\n",
      "9 Train Loss 8.861462 Test MSE 3.584474364439464 Test RE 0.9049421137075242\n",
      "10 Train Loss 7.9192586 Test MSE 3.672445488503202 Test RE 0.9159794688898352\n",
      "11 Train Loss 7.528083 Test MSE 3.698470054615497 Test RE 0.9192192563436028\n",
      "12 Train Loss 7.1132336 Test MSE 3.708074903300602 Test RE 0.9204120789174639\n",
      "13 Train Loss 6.6553087 Test MSE 3.7152724972779856 Test RE 0.9213049331565499\n",
      "14 Train Loss 6.2617817 Test MSE 3.6946226101406974 Test RE 0.9187410092237507\n",
      "15 Train Loss 5.887911 Test MSE 3.5608545417130757 Test RE 0.9019556366887856\n",
      "16 Train Loss 5.585231 Test MSE 3.436486228941083 Test RE 0.8860645555877401\n",
      "17 Train Loss 5.317954 Test MSE 3.2187517032128463 Test RE 0.8575348888687774\n",
      "18 Train Loss 5.140174 Test MSE 3.15320612193869 Test RE 0.8487587036587096\n",
      "19 Train Loss 5.038296 Test MSE 3.0895869287600726 Test RE 0.8401527819972019\n",
      "20 Train Loss 4.907694 Test MSE 2.9689995884969465 Test RE 0.823593914512453\n",
      "21 Train Loss 4.7726936 Test MSE 2.9448541817596308 Test RE 0.8202381366697618\n",
      "22 Train Loss 4.6219244 Test MSE 2.687524423094017 Test RE 0.7835816734680282\n",
      "23 Train Loss 4.5079474 Test MSE 2.600065603628301 Test RE 0.7707263609350367\n",
      "24 Train Loss 4.3792534 Test MSE 2.6011425742572674 Test RE 0.7708859653151763\n",
      "25 Train Loss 4.262663 Test MSE 2.4663301402855926 Test RE 0.7506433913817416\n",
      "26 Train Loss 4.133609 Test MSE 2.3401400517402324 Test RE 0.7311878818373347\n",
      "27 Train Loss 3.881969 Test MSE 2.3091645388494437 Test RE 0.7263325381311249\n",
      "28 Train Loss 3.6420746 Test MSE 2.2474689100664373 Test RE 0.7165638698329011\n",
      "29 Train Loss 3.2944012 Test MSE 2.075117405509337 Test RE 0.688540351416635\n",
      "30 Train Loss 2.9956021 Test MSE 2.0657128609739344 Test RE 0.6869783285209632\n",
      "31 Train Loss 2.7906547 Test MSE 2.0255042852476484 Test RE 0.6802595437286659\n",
      "32 Train Loss 2.514715 Test MSE 2.04224584016897 Test RE 0.6830650590213028\n",
      "33 Train Loss 2.2649496 Test MSE 1.9741981710177907 Test RE 0.6715887815021604\n",
      "34 Train Loss 2.0971708 Test MSE 1.855151801863645 Test RE 0.6510251803464586\n",
      "35 Train Loss 1.8807496 Test MSE 1.786578951237733 Test RE 0.638879814539404\n",
      "36 Train Loss 1.7890111 Test MSE 1.731297976110375 Test RE 0.6289179222072613\n",
      "37 Train Loss 1.6589437 Test MSE 1.6750574770306044 Test RE 0.6186185193449711\n",
      "38 Train Loss 1.5825522 Test MSE 1.631456339724158 Test RE 0.6105142260578966\n",
      "39 Train Loss 1.5263088 Test MSE 1.5892495547524372 Test RE 0.6025652877978589\n",
      "40 Train Loss 1.4566057 Test MSE 1.551082363043879 Test RE 0.5952857549241346\n",
      "41 Train Loss 1.375356 Test MSE 1.4368061539814085 Test RE 0.5729373698072151\n",
      "42 Train Loss 1.3278172 Test MSE 1.3763467037402102 Test RE 0.5607534882113426\n",
      "43 Train Loss 1.244178 Test MSE 1.281627727827042 Test RE 0.5411142956227443\n",
      "44 Train Loss 1.1431804 Test MSE 1.064717602557164 Test RE 0.4932025091114808\n",
      "45 Train Loss 1.0887165 Test MSE 0.9653367576467589 Test RE 0.46962097078582404\n",
      "46 Train Loss 0.9657073 Test MSE 0.7642235582918047 Test RE 0.4178479453002828\n",
      "47 Train Loss 0.83212626 Test MSE 0.5903152202088848 Test RE 0.3672400608757845\n",
      "48 Train Loss 0.72213894 Test MSE 0.44226959507264274 Test RE 0.317871507935135\n",
      "49 Train Loss 0.56750584 Test MSE 0.2680341148356682 Test RE 0.24745891084620794\n",
      "50 Train Loss 0.47123075 Test MSE 0.1797845302283916 Test RE 0.20266755123562746\n",
      "51 Train Loss 0.30751517 Test MSE 0.07786406027571059 Test RE 0.1333756606286579\n",
      "52 Train Loss 0.23894393 Test MSE 0.06068689016344561 Test RE 0.1177485321212948\n",
      "53 Train Loss 0.18820158 Test MSE 0.05535097679508515 Test RE 0.11245291171174505\n",
      "54 Train Loss 0.16356653 Test MSE 0.044473142757105975 Test RE 0.10079917336597914\n",
      "55 Train Loss 0.14024405 Test MSE 0.03787480821090975 Test RE 0.09302148781102076\n",
      "56 Train Loss 0.11912138 Test MSE 0.027283102909513437 Test RE 0.07895051019373409\n",
      "57 Train Loss 0.10606464 Test MSE 0.02386767212102405 Test RE 0.07384363923176\n",
      "58 Train Loss 0.09078698 Test MSE 0.020466055090059325 Test RE 0.06837937543146491\n",
      "59 Train Loss 0.08206845 Test MSE 0.01673594524973384 Test RE 0.06183483175945236\n",
      "60 Train Loss 0.07537085 Test MSE 0.016056752389152724 Test RE 0.06056711890612868\n",
      "61 Train Loss 0.0702993 Test MSE 0.01620579439221058 Test RE 0.060847567699636694\n",
      "62 Train Loss 0.06326782 Test MSE 0.014824445084841617 Test RE 0.058196555825430554\n",
      "63 Train Loss 0.056018673 Test MSE 0.012002998527037866 Test RE 0.052366426276840884\n",
      "64 Train Loss 0.051024403 Test MSE 0.010243323469904487 Test RE 0.04837583830190008\n",
      "65 Train Loss 0.04704194 Test MSE 0.009934870316340718 Test RE 0.04764190968879113\n",
      "66 Train Loss 0.04287425 Test MSE 0.008774966674552792 Test RE 0.04477450550748939\n",
      "67 Train Loss 0.040124997 Test MSE 0.007632826663854243 Test RE 0.04175906443907417\n",
      "68 Train Loss 0.036876544 Test MSE 0.007351079840778469 Test RE 0.0409811017670072\n",
      "69 Train Loss 0.034571346 Test MSE 0.007164604234947048 Test RE 0.040457976984090975\n",
      "70 Train Loss 0.03173641 Test MSE 0.00685185356963652 Test RE 0.03956508443119961\n",
      "71 Train Loss 0.030137632 Test MSE 0.007188954037355379 Test RE 0.04052666941279845\n",
      "72 Train Loss 0.027894715 Test MSE 0.007221923182510573 Test RE 0.04061949246060621\n",
      "73 Train Loss 0.025735363 Test MSE 0.006680618851226611 Test RE 0.03906757077787945\n",
      "74 Train Loss 0.02420525 Test MSE 0.006750417724959074 Test RE 0.03927112877902822\n",
      "75 Train Loss 0.023304299 Test MSE 0.007007170919671888 Test RE 0.04001100091008488\n",
      "76 Train Loss 0.021633271 Test MSE 0.006704574491209046 Test RE 0.03913755315489817\n",
      "77 Train Loss 0.020753 Test MSE 0.006423787737800873 Test RE 0.03830925014515242\n",
      "78 Train Loss 0.019388394 Test MSE 0.005847458556975054 Test RE 0.03655035811988364\n",
      "79 Train Loss 0.018870693 Test MSE 0.005575192844520636 Test RE 0.03568929814526836\n",
      "80 Train Loss 0.017882401 Test MSE 0.005053711587466967 Test RE 0.03397921073825157\n",
      "81 Train Loss 0.016534064 Test MSE 0.004425779372344294 Test RE 0.03179822956896256\n",
      "82 Train Loss 0.015875284 Test MSE 0.004065401303316855 Test RE 0.030476126762489116\n",
      "83 Train Loss 0.0153823495 Test MSE 0.004014594443617447 Test RE 0.030285092179175032\n",
      "84 Train Loss 0.014404764 Test MSE 0.0040544427854698065 Test RE 0.03043502398827115\n",
      "85 Train Loss 0.01392081 Test MSE 0.004156012665992281 Test RE 0.030813887419216212\n",
      "86 Train Loss 0.01339825 Test MSE 0.004304256171505246 Test RE 0.0313586325117863\n",
      "87 Train Loss 0.012929317 Test MSE 0.004341151211202167 Test RE 0.03149274502521848\n",
      "88 Train Loss 0.012285605 Test MSE 0.004443906291359791 Test RE 0.03186328194580818\n",
      "89 Train Loss 0.011612369 Test MSE 0.004639206531850287 Test RE 0.03255591559758729\n",
      "90 Train Loss 0.011238298 Test MSE 0.004699882344427251 Test RE 0.03276812210661266\n",
      "91 Train Loss 0.010998547 Test MSE 0.004814727285240263 Test RE 0.03316606188444991\n",
      "92 Train Loss 0.010515024 Test MSE 0.00451143313787149 Test RE 0.032104456559867336\n",
      "93 Train Loss 0.009948552 Test MSE 0.004101274620256141 Test RE 0.030610292920507584\n",
      "94 Train Loss 0.009649033 Test MSE 0.004219812530756795 Test RE 0.031049502002749484\n",
      "95 Train Loss 0.009341257 Test MSE 0.004290564952548382 Test RE 0.03130871914158089\n",
      "96 Train Loss 0.008942695 Test MSE 0.0040680887169423025 Test RE 0.030486198145539947\n",
      "97 Train Loss 0.008343798 Test MSE 0.0037964527379209753 Test RE 0.02945079747052363\n",
      "98 Train Loss 0.0076592905 Test MSE 0.003502303899177284 Test RE 0.028286875181880927\n",
      "99 Train Loss 0.0073560947 Test MSE 0.003166110682502232 Test RE 0.026894972640277563\n",
      "Training time: 84.77\n",
      "3\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.36913 Test MSE 8.305625487561333 Test RE 1.3775083256685399\n",
      "1 Train Loss 42.900528 Test MSE 8.597198064948843 Test RE 1.4014787799499686\n",
      "2 Train Loss 34.958958 Test MSE 8.70401144528415 Test RE 1.4101580371510682\n",
      "3 Train Loss 31.818768 Test MSE 8.588357545868588 Test RE 1.4007580226430578\n",
      "4 Train Loss 28.789297 Test MSE 8.625798864952007 Test RE 1.4038080349218003\n",
      "5 Train Loss 25.936916 Test MSE 8.29876242506647 Test RE 1.3769390801898127\n",
      "6 Train Loss 23.883934 Test MSE 8.399839243912025 Test RE 1.3852990857060266\n",
      "7 Train Loss 22.083168 Test MSE 8.28295525791129 Test RE 1.3756270845272298\n",
      "8 Train Loss 20.68001 Test MSE 8.39341301757312 Test RE 1.3847690786123261\n",
      "9 Train Loss 18.814404 Test MSE 8.408284218230325 Test RE 1.3859952821402868\n",
      "10 Train Loss 16.331116 Test MSE 7.9439049243541655 Test RE 1.3471783013350624\n",
      "11 Train Loss 14.928929 Test MSE 8.065242253925813 Test RE 1.3574278918483536\n",
      "12 Train Loss 14.177185 Test MSE 8.274958518308793 Test RE 1.374962877874675\n",
      "13 Train Loss 13.332129 Test MSE 8.262571108548864 Test RE 1.3739333495986286\n",
      "14 Train Loss 12.229368 Test MSE 7.976584730533306 Test RE 1.3499464827774472\n",
      "15 Train Loss 9.616393 Test MSE 6.758006691089565 Test RE 1.2425600003730815\n",
      "16 Train Loss 8.62122 Test MSE 6.5607955896020895 Test RE 1.224295670663551\n",
      "17 Train Loss 7.7061787 Test MSE 6.166138999639629 Test RE 1.186901600714091\n",
      "18 Train Loss 7.2570343 Test MSE 6.069204987646891 Test RE 1.1775353761523133\n",
      "19 Train Loss 6.8223834 Test MSE 5.94978105625299 Test RE 1.165892618145025\n",
      "20 Train Loss 6.537755 Test MSE 5.8227915073871275 Test RE 1.153383356633606\n",
      "21 Train Loss 6.2060843 Test MSE 5.894622748274099 Test RE 1.1604757461546635\n",
      "22 Train Loss 5.893733 Test MSE 5.7933260049407185 Test RE 1.1504613798266334\n",
      "23 Train Loss 5.4671364 Test MSE 5.899350564848248 Test RE 1.1609410360484052\n",
      "24 Train Loss 5.107434 Test MSE 5.8262375824015615 Test RE 1.1537246068451563\n",
      "25 Train Loss 4.6107697 Test MSE 5.844472097288161 Test RE 1.1555286161610234\n",
      "26 Train Loss 4.056896 Test MSE 5.5930209107515925 Test RE 1.1303977432289944\n",
      "27 Train Loss 3.0890832 Test MSE 5.301964620748969 Test RE 1.1005923074257422\n",
      "28 Train Loss 2.42243 Test MSE 5.100067574445597 Test RE 1.0794338313338454\n",
      "29 Train Loss 2.2425506 Test MSE 5.053585197972767 Test RE 1.0745035537657341\n",
      "30 Train Loss 2.063542 Test MSE 5.013042605623076 Test RE 1.0701847501944428\n",
      "31 Train Loss 1.9547256 Test MSE 5.032072229258612 Test RE 1.0722140490165328\n",
      "32 Train Loss 1.8693576 Test MSE 5.108843258467239 Test RE 1.0803621228360734\n",
      "33 Train Loss 1.8301754 Test MSE 5.110683702053136 Test RE 1.080556703722331\n",
      "34 Train Loss 1.7882177 Test MSE 5.173084265958408 Test RE 1.0871333947778217\n",
      "35 Train Loss 1.7443831 Test MSE 5.15295856207662 Test RE 1.0850166066741826\n",
      "36 Train Loss 1.6877735 Test MSE 5.185830742730545 Test RE 1.0884719187964325\n",
      "37 Train Loss 1.6329012 Test MSE 5.211253668127813 Test RE 1.0911367096259175\n",
      "38 Train Loss 1.5825459 Test MSE 5.221704326366939 Test RE 1.0922302454953416\n",
      "39 Train Loss 1.5570533 Test MSE 5.284325731058281 Test RE 1.098760024406465\n",
      "40 Train Loss 1.5260218 Test MSE 5.287541037065736 Test RE 1.099094249873453\n",
      "41 Train Loss 1.4835718 Test MSE 5.30717222415357 Test RE 1.1011326770799175\n",
      "42 Train Loss 1.4572873 Test MSE 5.326294837307322 Test RE 1.103114674260645\n",
      "43 Train Loss 1.4291282 Test MSE 5.3416115003604565 Test RE 1.1046996321789477\n",
      "44 Train Loss 1.4056985 Test MSE 5.371045755790409 Test RE 1.1077391026013095\n",
      "45 Train Loss 1.3588516 Test MSE 5.392248934511884 Test RE 1.109923449607068\n",
      "46 Train Loss 1.333065 Test MSE 5.428423754819512 Test RE 1.1136402815211761\n",
      "47 Train Loss 1.3088038 Test MSE 5.4796310926226335 Test RE 1.1188805410987426\n",
      "48 Train Loss 1.2818811 Test MSE 5.508895402701098 Test RE 1.1218642881820886\n",
      "49 Train Loss 1.2602063 Test MSE 5.542381020171197 Test RE 1.1252687279234261\n",
      "50 Train Loss 1.2292821 Test MSE 5.605280548050113 Test RE 1.1316359542692918\n",
      "51 Train Loss 1.2059894 Test MSE 5.618735997783541 Test RE 1.1329933835390775\n",
      "52 Train Loss 1.1818826 Test MSE 5.615029941394273 Test RE 1.1326196669245778\n",
      "53 Train Loss 1.1629577 Test MSE 5.624340374093843 Test RE 1.1335582916159792\n",
      "54 Train Loss 1.1203976 Test MSE 5.647381108019818 Test RE 1.135877792132053\n",
      "55 Train Loss 1.1017346 Test MSE 5.686664629709214 Test RE 1.1398215627643387\n",
      "56 Train Loss 1.0846336 Test MSE 5.6890731239917045 Test RE 1.140062913651051\n",
      "57 Train Loss 1.0687976 Test MSE 5.689711600845107 Test RE 1.1401268857027502\n",
      "58 Train Loss 1.0552164 Test MSE 5.693936649825375 Test RE 1.140550123147822\n",
      "59 Train Loss 1.0431412 Test MSE 5.706945039794318 Test RE 1.1418522325100646\n",
      "60 Train Loss 1.0337514 Test MSE 5.718418286454498 Test RE 1.142999446509107\n",
      "61 Train Loss 1.0210867 Test MSE 5.71485947563013 Test RE 1.1426437229791393\n",
      "62 Train Loss 1.0113419 Test MSE 5.716132895942827 Test RE 1.142771021356778\n",
      "63 Train Loss 1.0002602 Test MSE 5.7476604364254475 Test RE 1.1459181854746487\n",
      "64 Train Loss 0.9917196 Test MSE 5.771694319132223 Test RE 1.1483115186424797\n",
      "65 Train Loss 0.9844404 Test MSE 5.778604501595481 Test RE 1.148998723130097\n",
      "66 Train Loss 0.978373 Test MSE 5.794590882780379 Test RE 1.1505869651711105\n",
      "67 Train Loss 0.9704602 Test MSE 5.809067169315192 Test RE 1.152023290623882\n",
      "68 Train Loss 0.95682746 Test MSE 5.82774264996759 Test RE 1.1538736156466696\n",
      "69 Train Loss 0.94410336 Test MSE 5.863337636608334 Test RE 1.157392095579794\n",
      "70 Train Loss 0.9366519 Test MSE 5.871036761624243 Test RE 1.1581517297411301\n",
      "71 Train Loss 0.93067664 Test MSE 5.87481971123032 Test RE 1.1585247919687645\n",
      "72 Train Loss 0.92389596 Test MSE 5.892160471634922 Test RE 1.1602333463522516\n",
      "73 Train Loss 0.9178773 Test MSE 5.88234655767746 Test RE 1.1592667080948937\n",
      "74 Train Loss 0.9105588 Test MSE 5.868772302983087 Test RE 1.1579283586628737\n",
      "75 Train Loss 0.90439785 Test MSE 5.889534619985493 Test RE 1.1599747875292787\n",
      "76 Train Loss 0.896418 Test MSE 5.918558812476042 Test RE 1.1628295083704308\n",
      "77 Train Loss 0.8887181 Test MSE 5.906607501537722 Test RE 1.1616548676970542\n",
      "78 Train Loss 0.8822434 Test MSE 5.892365694496732 Test RE 1.1602535515329817\n",
      "79 Train Loss 0.87649095 Test MSE 5.878792076821539 Test RE 1.158916404525718\n",
      "80 Train Loss 0.87053823 Test MSE 5.867682503284326 Test RE 1.1578208431128374\n",
      "81 Train Loss 0.8641254 Test MSE 5.890346568028253 Test RE 1.160054743490168\n",
      "82 Train Loss 0.8593405 Test MSE 5.910828882090474 Test RE 1.1620699038586666\n",
      "83 Train Loss 0.85142595 Test MSE 5.941389644021313 Test RE 1.165070156149314\n",
      "84 Train Loss 0.8460854 Test MSE 5.959975424515247 Test RE 1.1668910121843226\n",
      "85 Train Loss 0.84167504 Test MSE 5.975132290523637 Test RE 1.1683738354443058\n",
      "86 Train Loss 0.8338806 Test MSE 5.990666846875876 Test RE 1.1698916585320525\n",
      "87 Train Loss 0.8274822 Test MSE 5.99512333318173 Test RE 1.17032672169301\n",
      "88 Train Loss 0.82243204 Test MSE 6.00541110550259 Test RE 1.1713304453328661\n",
      "89 Train Loss 0.81629175 Test MSE 6.0159025566638835 Test RE 1.1723531558041165\n",
      "90 Train Loss 0.8112745 Test MSE 6.0073578745942315 Test RE 1.1715202845541473\n",
      "91 Train Loss 0.8060069 Test MSE 6.0243177787659645 Test RE 1.1731728303607438\n",
      "92 Train Loss 0.8012564 Test MSE 6.069573477004368 Test RE 1.1775711224048364\n",
      "93 Train Loss 0.7970413 Test MSE 6.081065485712294 Test RE 1.1786853899959169\n",
      "94 Train Loss 0.79256684 Test MSE 6.08997087824311 Test RE 1.1795481348518562\n",
      "95 Train Loss 0.7883199 Test MSE 6.105283175064251 Test RE 1.1810301002415664\n",
      "96 Train Loss 0.7844862 Test MSE 6.107505971358431 Test RE 1.1812450739254439\n",
      "97 Train Loss 0.78049433 Test MSE 6.133248920939767 Test RE 1.1837319119988554\n",
      "98 Train Loss 0.77759075 Test MSE 6.14655655272933 Test RE 1.1850154187532087\n",
      "99 Train Loss 0.774003 Test MSE 6.1470038494137675 Test RE 1.1850585358888248\n",
      "Training time: 85.01\n",
      "4\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.672806 Test MSE 8.261823910403372 Test RE 1.373871224646982\n",
      "1 Train Loss 57.261856 Test MSE 8.595323238639148 Test RE 1.401325958499658\n",
      "2 Train Loss 56.350597 Test MSE 8.614695556021315 Test RE 1.4029042384319461\n",
      "3 Train Loss 52.502213 Test MSE 8.123306352768518 Test RE 1.3623053942757124\n",
      "4 Train Loss 47.525185 Test MSE 8.049290185659979 Test RE 1.3560848137700117\n",
      "5 Train Loss 46.64483 Test MSE 7.994238059613072 Test RE 1.3514394700326884\n",
      "6 Train Loss 45.2334 Test MSE 8.199677080515558 Test RE 1.3686942254202288\n",
      "7 Train Loss 43.714935 Test MSE 8.434202736149505 Test RE 1.388129802222505\n",
      "8 Train Loss 42.544594 Test MSE 7.765270388635238 Test RE 1.3319451830342557\n",
      "9 Train Loss 40.97639 Test MSE 7.962749688775036 Test RE 1.3487752627599237\n",
      "10 Train Loss 40.033905 Test MSE 7.943249141855132 Test RE 1.347122694288217\n",
      "11 Train Loss 38.931072 Test MSE 7.96851099611336 Test RE 1.3492631158283435\n",
      "12 Train Loss 36.721817 Test MSE 7.373254825432081 Test RE 1.2978893899009836\n",
      "13 Train Loss 34.841335 Test MSE 5.80171364474937 Test RE 1.1512939037918624\n",
      "14 Train Loss 31.255198 Test MSE 5.703970742143284 Test RE 1.141554643256402\n",
      "15 Train Loss 21.576504 Test MSE 3.7275442716116505 Test RE 0.9228252422974718\n",
      "16 Train Loss 18.597834 Test MSE 3.674776492969808 Test RE 0.9162701217446114\n",
      "17 Train Loss 15.982851 Test MSE 3.562405887713519 Test RE 0.9021520913438679\n",
      "18 Train Loss 14.187213 Test MSE 3.300357687657111 Test RE 0.8683375174316662\n",
      "19 Train Loss 13.526092 Test MSE 2.9013626538664945 Test RE 0.8141587009296929\n",
      "20 Train Loss 10.481805 Test MSE 1.6596698148821905 Test RE 0.615770540894874\n",
      "21 Train Loss 7.4909186 Test MSE 1.222670262967933 Test RE 0.5285215927727074\n",
      "22 Train Loss 5.3690534 Test MSE 0.8604500484327826 Test RE 0.44337468401237434\n",
      "23 Train Loss 3.5474958 Test MSE 0.46614951711160474 Test RE 0.32634027833923474\n",
      "24 Train Loss 2.581934 Test MSE 0.31844103394902695 Test RE 0.26972585160058415\n",
      "25 Train Loss 1.7886316 Test MSE 0.18282374356226314 Test RE 0.20437339482387504\n",
      "26 Train Loss 1.2158974 Test MSE 0.13776824611153293 Test RE 0.1774118501821984\n",
      "27 Train Loss 0.86799216 Test MSE 0.09521150938711333 Test RE 0.14748667516928507\n",
      "28 Train Loss 0.59865004 Test MSE 0.0526964401205584 Test RE 0.10972325914641477\n",
      "29 Train Loss 0.38642186 Test MSE 0.04774824165930684 Test RE 0.10444478299218084\n",
      "30 Train Loss 0.2862261 Test MSE 0.04533661592735233 Test RE 0.10177300788301734\n",
      "31 Train Loss 0.25996834 Test MSE 0.04376427811984777 Test RE 0.09999261931858315\n",
      "32 Train Loss 0.2126392 Test MSE 0.04026510322610232 Test RE 0.0959118943249868\n",
      "33 Train Loss 0.17721784 Test MSE 0.03972967380368595 Test RE 0.09527206091922939\n",
      "34 Train Loss 0.1513842 Test MSE 0.02648079636853412 Test RE 0.07778101051717162\n",
      "35 Train Loss 0.14356686 Test MSE 0.02524668737074079 Test RE 0.07594693669856095\n",
      "36 Train Loss 0.12605707 Test MSE 0.0263069556025566 Test RE 0.07752528227441277\n",
      "37 Train Loss 0.11655268 Test MSE 0.02306043834840115 Test RE 0.07258415737234343\n",
      "38 Train Loss 0.092139564 Test MSE 0.015613686255699644 Test RE 0.059725636182307855\n",
      "39 Train Loss 0.080984674 Test MSE 0.013853674688482687 Test RE 0.056258811466636374\n",
      "40 Train Loss 0.07419046 Test MSE 0.011809065631833602 Test RE 0.0519416603984815\n",
      "41 Train Loss 0.07183038 Test MSE 0.011115741381737912 Test RE 0.050393819634502304\n",
      "42 Train Loss 0.06296418 Test MSE 0.008286446434205346 Test RE 0.043510314647735616\n",
      "43 Train Loss 0.057612933 Test MSE 0.007111757280638184 Test RE 0.04030848944211507\n",
      "44 Train Loss 0.051929105 Test MSE 0.006623550059108215 Test RE 0.038900346677996876\n",
      "45 Train Loss 0.049130935 Test MSE 0.007112244854164223 Test RE 0.04030987116921219\n",
      "46 Train Loss 0.045610998 Test MSE 0.007232695180323057 Test RE 0.04064977456374377\n",
      "47 Train Loss 0.04202877 Test MSE 0.006019428661386416 Test RE 0.03708392518116175\n",
      "48 Train Loss 0.041003995 Test MSE 0.004972199480684955 Test RE 0.03370406876664552\n",
      "49 Train Loss 0.039538644 Test MSE 0.004741923068927737 Test RE 0.032914352216915486\n",
      "50 Train Loss 0.038299106 Test MSE 0.004658508159115335 Test RE 0.03262357047530534\n",
      "51 Train Loss 0.035556752 Test MSE 0.004086723775063965 Test RE 0.030555943792606205\n",
      "52 Train Loss 0.0336648 Test MSE 0.0041488093398469655 Test RE 0.030787172060026586\n",
      "53 Train Loss 0.03248193 Test MSE 0.004266149114821541 Test RE 0.031219509534934752\n",
      "54 Train Loss 0.031999197 Test MSE 0.004057326833130208 Test RE 0.030445846740062163\n",
      "55 Train Loss 0.030422792 Test MSE 0.0036116665012872135 Test RE 0.028725121928900286\n",
      "56 Train Loss 0.028839566 Test MSE 0.0034942090362558203 Test RE 0.028254166592616984\n",
      "57 Train Loss 0.027827237 Test MSE 0.003347837428922543 Test RE 0.027656055655742865\n",
      "58 Train Loss 0.026353206 Test MSE 0.0028500736066256844 Test RE 0.025517381019275257\n",
      "59 Train Loss 0.025703987 Test MSE 0.0027693727991674483 Test RE 0.025153520133317404\n",
      "60 Train Loss 0.024700344 Test MSE 0.0030853324770710945 Test RE 0.026549665002642598\n",
      "61 Train Loss 0.022714414 Test MSE 0.0031473964379708707 Test RE 0.026815369444752327\n",
      "62 Train Loss 0.021994332 Test MSE 0.002955029521104287 Test RE 0.025982980789603736\n",
      "63 Train Loss 0.021440659 Test MSE 0.0030762232024490175 Test RE 0.026510442817300514\n",
      "64 Train Loss 0.020392943 Test MSE 0.0032436577220532306 Test RE 0.02722234730185258\n",
      "65 Train Loss 0.018847287 Test MSE 0.002808931342818477 Test RE 0.0253325333071696\n",
      "66 Train Loss 0.01768103 Test MSE 0.0024945194957163 Test RE 0.023872698409932634\n",
      "67 Train Loss 0.016916087 Test MSE 0.0020684851921180017 Test RE 0.021738734997816377\n",
      "68 Train Loss 0.016645242 Test MSE 0.0019490581074172854 Test RE 0.021101846218893657\n",
      "69 Train Loss 0.016463494 Test MSE 0.001964744489606709 Test RE 0.021186591840211173\n",
      "70 Train Loss 0.016281707 Test MSE 0.0019452745526205547 Test RE 0.021081354583569547\n",
      "71 Train Loss 0.015952533 Test MSE 0.0019129067721751513 Test RE 0.02090523060572339\n",
      "72 Train Loss 0.015507378 Test MSE 0.0018104826876338903 Test RE 0.020337859765423596\n",
      "73 Train Loss 0.0148221925 Test MSE 0.0016079216593371999 Test RE 0.01916639803138769\n",
      "74 Train Loss 0.014495809 Test MSE 0.0016314036224432068 Test RE 0.01930584306017516\n",
      "75 Train Loss 0.013992609 Test MSE 0.0016561165306216387 Test RE 0.01945151831075232\n",
      "76 Train Loss 0.0137346 Test MSE 0.0015840168901747802 Test RE 0.019023392314107313\n",
      "77 Train Loss 0.013410462 Test MSE 0.0015030113047377822 Test RE 0.018530587298304663\n",
      "78 Train Loss 0.013164923 Test MSE 0.0014630492627427968 Test RE 0.01828258221543734\n",
      "79 Train Loss 0.013055047 Test MSE 0.001477334789476435 Test RE 0.018371622916916484\n",
      "80 Train Loss 0.01292292 Test MSE 0.0014890326685590728 Test RE 0.018444214883246962\n",
      "81 Train Loss 0.0125680845 Test MSE 0.0014077441293933492 Test RE 0.01793370091890715\n",
      "82 Train Loss 0.012328001 Test MSE 0.001390941975296396 Test RE 0.017826355655312383\n",
      "83 Train Loss 0.012033651 Test MSE 0.001515973900731313 Test RE 0.01861032350231679\n",
      "84 Train Loss 0.011811984 Test MSE 0.0015219000852206104 Test RE 0.01864666338818849\n",
      "85 Train Loss 0.011303051 Test MSE 0.0013578870019213527 Test RE 0.017613265265220772\n",
      "86 Train Loss 0.010770341 Test MSE 0.0012597235003045546 Test RE 0.016964680149325857\n",
      "87 Train Loss 0.010387458 Test MSE 0.001221929086206588 Test RE 0.016708253722784797\n",
      "88 Train Loss 0.009985121 Test MSE 0.0011584225779798496 Test RE 0.01626827731761649\n",
      "89 Train Loss 0.009309619 Test MSE 0.0012352952809476043 Test RE 0.01679938764177022\n",
      "90 Train Loss 0.008980641 Test MSE 0.0012362621918117324 Test RE 0.016805961103726143\n",
      "91 Train Loss 0.008718808 Test MSE 0.0010756489799550659 Test RE 0.015676292025813717\n",
      "92 Train Loss 0.008611007 Test MSE 0.0010243329620526819 Test RE 0.015297787868191944\n",
      "93 Train Loss 0.008499513 Test MSE 0.0010421550292018106 Test RE 0.015430294841205857\n",
      "94 Train Loss 0.008391788 Test MSE 0.0010602233526089343 Test RE 0.015563481120498967\n",
      "95 Train Loss 0.008315895 Test MSE 0.0010885765801185317 Test RE 0.015770212796996304\n",
      "96 Train Loss 0.008208888 Test MSE 0.001157507367432128 Test RE 0.016261849680077548\n",
      "97 Train Loss 0.007963946 Test MSE 0.0012270045402533287 Test RE 0.016742917803585625\n",
      "98 Train Loss 0.007813909 Test MSE 0.0012191173409107456 Test RE 0.01668901921434212\n",
      "99 Train Loss 0.007720895 Test MSE 0.0012548407392328294 Test RE 0.01693177018791209\n",
      "Training time: 85.92\n",
      "5\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.091095 Test MSE 8.861526903319639 Test RE 1.4228605568193338\n",
      "1 Train Loss 49.320137 Test MSE 8.857664743087323 Test RE 1.4225504570808047\n",
      "2 Train Loss 45.33029 Test MSE 8.626767155866164 Test RE 1.4038868250977523\n",
      "3 Train Loss 42.302017 Test MSE 7.466240722096271 Test RE 1.3060477469539122\n",
      "4 Train Loss 35.52236 Test MSE 7.4333855361220955 Test RE 1.303170947624092\n",
      "5 Train Loss 32.38139 Test MSE 7.964916187733178 Test RE 1.3489587371614\n",
      "6 Train Loss 31.14309 Test MSE 8.0724003515275 Test RE 1.358030133297386\n",
      "7 Train Loss 30.120808 Test MSE 8.22301747087698 Test RE 1.3706408360008104\n",
      "8 Train Loss 29.382553 Test MSE 8.380308490410673 Test RE 1.3836876453163416\n",
      "9 Train Loss 28.442719 Test MSE 8.706539717609658 Test RE 1.4103628280510774\n",
      "10 Train Loss 27.64281 Test MSE 8.679047882645866 Test RE 1.4081343814104308\n",
      "11 Train Loss 26.666351 Test MSE 8.61064369716175 Test RE 1.4025742767700218\n",
      "12 Train Loss 25.749529 Test MSE 8.706596318494134 Test RE 1.4103674124012524\n",
      "13 Train Loss 24.421307 Test MSE 8.756618650092792 Test RE 1.4144131278947059\n",
      "14 Train Loss 23.509995 Test MSE 9.027699944702686 Test RE 1.4361394699485\n",
      "15 Train Loss 22.419796 Test MSE 9.343870222058943 Test RE 1.4610714657432775\n",
      "16 Train Loss 21.368607 Test MSE 9.087870071757218 Test RE 1.4409174968206393\n",
      "17 Train Loss 20.425365 Test MSE 9.097757299147862 Test RE 1.44170111311283\n",
      "18 Train Loss 19.283554 Test MSE 9.191898776834178 Test RE 1.4491411098001314\n",
      "19 Train Loss 17.12664 Test MSE 8.619136376626969 Test RE 1.4032657859369568\n",
      "20 Train Loss 16.3258 Test MSE 8.475722949494058 Test RE 1.3915423765290853\n",
      "21 Train Loss 15.528072 Test MSE 8.316185148014535 Test RE 1.3783837202878533\n",
      "22 Train Loss 14.946316 Test MSE 8.47398240596692 Test RE 1.391399488161406\n",
      "23 Train Loss 14.298368 Test MSE 8.624681850463672 Test RE 1.403717137562212\n",
      "24 Train Loss 13.781553 Test MSE 8.860787619835243 Test RE 1.4228012036592297\n",
      "25 Train Loss 13.31036 Test MSE 8.64062176202879 Test RE 1.4050136954343835\n",
      "26 Train Loss 12.819494 Test MSE 8.630263958563685 Test RE 1.404171324364965\n",
      "27 Train Loss 12.273497 Test MSE 8.509908540589553 Test RE 1.3943458440376266\n",
      "28 Train Loss 11.698557 Test MSE 8.316520313327658 Test RE 1.3784114963503298\n",
      "29 Train Loss 11.2257805 Test MSE 8.289579943250626 Test RE 1.3761770859981022\n",
      "30 Train Loss 9.760904 Test MSE 7.237692017468452 Test RE 1.285902704380307\n",
      "31 Train Loss 9.043383 Test MSE 7.349604999826222 Test RE 1.2958062182514234\n",
      "32 Train Loss 8.314484 Test MSE 7.221297036153263 Test RE 1.2844454509247307\n",
      "33 Train Loss 6.5060987 Test MSE 6.474212419196415 Test RE 1.2161902923370564\n",
      "34 Train Loss 5.619178 Test MSE 6.529959083248274 Test RE 1.2214151155426796\n",
      "35 Train Loss 4.8245196 Test MSE 6.860832427775699 Test RE 1.251977333689944\n",
      "36 Train Loss 4.4556575 Test MSE 6.97564535180654 Test RE 1.2624095072314803\n",
      "37 Train Loss 4.145875 Test MSE 7.002657525132624 Test RE 1.264851394270453\n",
      "38 Train Loss 3.9002254 Test MSE 7.040786802352549 Test RE 1.2682902599833055\n",
      "39 Train Loss 3.688703 Test MSE 7.105101283025204 Test RE 1.2740697277087103\n",
      "40 Train Loss 3.4305968 Test MSE 7.1502585914983365 Test RE 1.2781120651395392\n",
      "41 Train Loss 3.24923 Test MSE 7.2211137086119646 Test RE 1.2844291466708142\n",
      "42 Train Loss 3.0782568 Test MSE 7.215498367215517 Test RE 1.2839296454057034\n",
      "43 Train Loss 2.9588747 Test MSE 7.1449655511112375 Test RE 1.2776389108376582\n",
      "44 Train Loss 2.8069732 Test MSE 7.132361508440036 Test RE 1.2765115069828314\n",
      "45 Train Loss 2.7190468 Test MSE 7.170388436552728 Test RE 1.2799099102838847\n",
      "46 Train Loss 2.6496282 Test MSE 7.096597241922902 Test RE 1.2733070372947262\n",
      "47 Train Loss 2.5679283 Test MSE 7.00296645039419 Test RE 1.2648792936955673\n",
      "48 Train Loss 2.49537 Test MSE 7.1068060471817684 Test RE 1.2742225656521642\n",
      "49 Train Loss 2.4293754 Test MSE 7.105455354509967 Test RE 1.2741014729381053\n",
      "50 Train Loss 2.3849676 Test MSE 7.039219377202683 Test RE 1.2681490782689122\n",
      "51 Train Loss 2.3287015 Test MSE 7.002933539412112 Test RE 1.2648763214930754\n",
      "52 Train Loss 2.275341 Test MSE 6.985600295550193 Test RE 1.2633099784080069\n",
      "53 Train Loss 2.2187397 Test MSE 6.9673760133807 Test RE 1.261661018267905\n",
      "54 Train Loss 2.1691108 Test MSE 6.900240418315768 Test RE 1.25556780657208\n",
      "55 Train Loss 2.1420422 Test MSE 6.860167138299914 Test RE 1.2519166305940845\n",
      "56 Train Loss 2.114546 Test MSE 6.8539897413089195 Test RE 1.2513528449291738\n",
      "57 Train Loss 2.0810177 Test MSE 6.759284125080077 Test RE 1.2426774324392194\n",
      "58 Train Loss 2.0569744 Test MSE 6.725927658036853 Test RE 1.2396073887567247\n",
      "59 Train Loss 2.0300367 Test MSE 6.698252529956016 Test RE 1.2370544579375327\n",
      "60 Train Loss 2.000167 Test MSE 6.621850713946852 Test RE 1.2299791599679675\n",
      "61 Train Loss 1.9787898 Test MSE 6.576622088855286 Test RE 1.2257714553480994\n",
      "62 Train Loss 1.9477906 Test MSE 6.519078527863816 Test RE 1.2203970987951507\n",
      "63 Train Loss 1.9226964 Test MSE 6.494261321659405 Test RE 1.218071944576689\n",
      "64 Train Loss 1.8899617 Test MSE 6.417107352659616 Test RE 1.2108147773261968\n",
      "65 Train Loss 1.8460023 Test MSE 6.323752881912352 Test RE 1.2019751954584388\n",
      "66 Train Loss 1.8210254 Test MSE 6.322017702583029 Test RE 1.201810278703914\n",
      "67 Train Loss 1.7947196 Test MSE 6.294024806812407 Test RE 1.1991466138219\n",
      "68 Train Loss 1.779382 Test MSE 6.239480089418017 Test RE 1.1939393387578605\n",
      "69 Train Loss 1.7592692 Test MSE 6.1998282620457115 Test RE 1.190139556556732\n",
      "70 Train Loss 1.7316356 Test MSE 6.129144979441569 Test RE 1.1833358103972462\n",
      "71 Train Loss 1.704038 Test MSE 6.068154043622377 Test RE 1.1774334206781771\n",
      "72 Train Loss 1.6739204 Test MSE 6.016400256730146 Test RE 1.1724016496228236\n",
      "73 Train Loss 1.6498523 Test MSE 5.99218562448102 Test RE 1.170039946919258\n",
      "74 Train Loss 1.6265564 Test MSE 5.978998197392951 Test RE 1.1687517428995209\n",
      "75 Train Loss 1.6024497 Test MSE 5.931586408616596 Test RE 1.164108582098246\n",
      "76 Train Loss 1.5783662 Test MSE 5.925931441422535 Test RE 1.163553539556808\n",
      "77 Train Loss 1.5545552 Test MSE 5.885073260380003 Test RE 1.1595353601889336\n",
      "78 Train Loss 1.5383906 Test MSE 5.811474684190398 Test RE 1.1522619886646481\n",
      "79 Train Loss 1.5193179 Test MSE 5.826032734057262 Test RE 1.1537043244030503\n",
      "80 Train Loss 1.4961033 Test MSE 5.813885860452692 Test RE 1.1525010001708855\n",
      "81 Train Loss 1.4770621 Test MSE 5.75192582930853 Test RE 1.1463433049510274\n",
      "82 Train Loss 1.4621329 Test MSE 5.753187869548831 Test RE 1.146469058661542\n",
      "83 Train Loss 1.4441679 Test MSE 5.728235686017167 Test RE 1.1439801783872692\n",
      "84 Train Loss 1.4244446 Test MSE 5.705529283758611 Test RE 1.1417105906640193\n",
      "85 Train Loss 1.4048437 Test MSE 5.737313996817522 Test RE 1.144886329656598\n",
      "86 Train Loss 1.3817215 Test MSE 5.759590571126727 Test RE 1.1471068318621833\n",
      "87 Train Loss 1.3623954 Test MSE 5.739962486547903 Test RE 1.1451505534581528\n",
      "88 Train Loss 1.3529333 Test MSE 5.754602865004685 Test RE 1.1466100369165024\n",
      "89 Train Loss 1.3407145 Test MSE 5.765288841172253 Test RE 1.1476741385556484\n",
      "90 Train Loss 1.3312657 Test MSE 5.759149243768716 Test RE 1.1470628826161906\n",
      "91 Train Loss 1.31723 Test MSE 5.780381503992528 Test RE 1.1491753762078631\n",
      "92 Train Loss 1.3025312 Test MSE 5.804594210202657 Test RE 1.151579678487375\n",
      "93 Train Loss 1.2854016 Test MSE 5.814996425836196 Test RE 1.152611069978672\n",
      "94 Train Loss 1.2686375 Test MSE 5.831828507054339 Test RE 1.1542780378142223\n",
      "95 Train Loss 1.2565571 Test MSE 5.843039263716206 Test RE 1.1553869625046875\n",
      "96 Train Loss 1.243468 Test MSE 5.845475741098129 Test RE 1.1556278286594905\n",
      "97 Train Loss 1.2340511 Test MSE 5.865902047087366 Test RE 1.1576451685005624\n",
      "98 Train Loss 1.2248977 Test MSE 5.8914310147774325 Test RE 1.1601615249574528\n",
      "99 Train Loss 1.2106974 Test MSE 5.875480879580475 Test RE 1.1585899819160999\n",
      "Training time: 84.96\n",
      "6\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.159115 Test MSE 8.04008618419117 Test RE 1.3553092809992324\n",
      "1 Train Loss 58.741028 Test MSE 8.379503296952265 Test RE 1.383621170257276\n",
      "2 Train Loss 53.94205 Test MSE 8.422588458657657 Test RE 1.3871737142987162\n",
      "3 Train Loss 48.467194 Test MSE 9.212788241858387 Test RE 1.4507868308802518\n",
      "4 Train Loss 46.68721 Test MSE 8.667532162347857 Test RE 1.4071998858079942\n",
      "5 Train Loss 46.24395 Test MSE 8.501306945414543 Test RE 1.3936409815432473\n",
      "6 Train Loss 44.968407 Test MSE 8.510335648897964 Test RE 1.3943808343797495\n",
      "7 Train Loss 43.922447 Test MSE 8.72435182800275 Test RE 1.4118047730557282\n",
      "8 Train Loss 43.025467 Test MSE 8.737030501946615 Test RE 1.4128302540446498\n",
      "9 Train Loss 42.01757 Test MSE 9.071124161597007 Test RE 1.439589319775091\n",
      "10 Train Loss 40.843742 Test MSE 8.887994387631707 Test RE 1.4249838625174753\n",
      "11 Train Loss 39.22593 Test MSE 8.809895067369615 Test RE 1.4187093406876807\n",
      "12 Train Loss 37.038097 Test MSE 8.652222096022106 Test RE 1.4059565188724277\n",
      "13 Train Loss 34.491936 Test MSE 8.4881703423258 Test RE 1.3925638067932788\n",
      "14 Train Loss 32.82524 Test MSE 8.488414770680814 Test RE 1.3925838570288671\n",
      "15 Train Loss 31.796894 Test MSE 8.654509773087353 Test RE 1.4061423764400143\n",
      "16 Train Loss 31.200264 Test MSE 8.703753217407346 Test RE 1.4101371189331273\n",
      "17 Train Loss 30.579403 Test MSE 8.616327213154308 Test RE 1.403037089924709\n",
      "18 Train Loss 29.782314 Test MSE 8.637922341575626 Test RE 1.4047942078165532\n",
      "19 Train Loss 28.837254 Test MSE 8.767985868457547 Test RE 1.4153308753209104\n",
      "20 Train Loss 27.53493 Test MSE 8.940798020520193 Test RE 1.4292105134052517\n",
      "21 Train Loss 26.443523 Test MSE 8.561125712372498 Test RE 1.3985355083478046\n",
      "22 Train Loss 25.112003 Test MSE 8.46950936628749 Test RE 1.39103221063154\n",
      "23 Train Loss 24.284317 Test MSE 8.505867394638129 Test RE 1.3940147344759828\n",
      "24 Train Loss 23.302284 Test MSE 8.502443038911915 Test RE 1.3937340997880785\n",
      "25 Train Loss 22.40179 Test MSE 8.298335381627096 Test RE 1.3769036519936984\n",
      "26 Train Loss 21.462183 Test MSE 8.404434715375432 Test RE 1.385677975811035\n",
      "27 Train Loss 20.74791 Test MSE 8.048592648950079 Test RE 1.3560260545868223\n",
      "28 Train Loss 19.13567 Test MSE 7.558526740131015 Test RE 1.3140946197925103\n",
      "29 Train Loss 18.426016 Test MSE 7.858876282070477 Test RE 1.3399490534778888\n",
      "30 Train Loss 17.989952 Test MSE 7.923950679421065 Test RE 1.3454852531163413\n",
      "31 Train Loss 17.67796 Test MSE 7.948013513104041 Test RE 1.3475266367050567\n",
      "32 Train Loss 17.268917 Test MSE 7.434912755072242 Test RE 1.3033048116045265\n",
      "33 Train Loss 16.923208 Test MSE 7.538326076164619 Test RE 1.3123374424551597\n",
      "34 Train Loss 16.60176 Test MSE 7.554038848699579 Test RE 1.3137044386194836\n",
      "35 Train Loss 16.361382 Test MSE 7.411809202388665 Test RE 1.3012782646360226\n",
      "36 Train Loss 16.131556 Test MSE 7.480330318129375 Test RE 1.307279492120802\n",
      "37 Train Loss 15.90308 Test MSE 7.512838265352828 Test RE 1.3101169939589492\n",
      "38 Train Loss 15.7691345 Test MSE 7.533432170100476 Test RE 1.3119113864042977\n",
      "39 Train Loss 15.584897 Test MSE 7.450270402421166 Test RE 1.3046501784459705\n",
      "40 Train Loss 15.469698 Test MSE 7.3941720994318345 Test RE 1.2997290849580623\n",
      "41 Train Loss 15.340548 Test MSE 7.373369013675972 Test RE 1.2978994399494297\n",
      "42 Train Loss 15.261829 Test MSE 7.3359175374874175 Test RE 1.2945990401606613\n",
      "43 Train Loss 15.134662 Test MSE 7.30376918069974 Test RE 1.291759250247744\n",
      "44 Train Loss 15.048544 Test MSE 7.308525410890073 Test RE 1.2921797799966523\n",
      "45 Train Loss 14.86191 Test MSE 7.259671291243198 Test RE 1.2878537256973588\n",
      "46 Train Loss 14.753432 Test MSE 7.248391477718861 Test RE 1.2868528265890125\n",
      "47 Train Loss 14.590828 Test MSE 7.2620330471426175 Test RE 1.2880631944649727\n",
      "48 Train Loss 14.427677 Test MSE 7.147058551824809 Test RE 1.2778260288390133\n",
      "49 Train Loss 14.302856 Test MSE 7.158462843542478 Test RE 1.2788451118679156\n",
      "50 Train Loss 14.094975 Test MSE 7.091505647632907 Test RE 1.2728501756534916\n",
      "51 Train Loss 12.291962 Test MSE 6.1314080014453 Test RE 1.1835542477032905\n",
      "52 Train Loss 11.048213 Test MSE 5.471482785097275 Test RE 1.1180483341144172\n",
      "53 Train Loss 10.565693 Test MSE 5.366421098388134 Test RE 1.1072620989319666\n",
      "54 Train Loss 10.144435 Test MSE 5.172024335929391 Test RE 1.0870220159270878\n",
      "55 Train Loss 9.783041 Test MSE 4.875075084408564 Test RE 1.055355346767197\n",
      "56 Train Loss 9.59025 Test MSE 4.906183263774745 Test RE 1.0587171387797403\n",
      "57 Train Loss 9.323531 Test MSE 4.9530333978048775 Test RE 1.06376008016897\n",
      "58 Train Loss 9.09437 Test MSE 4.770147922247586 Test RE 1.0439362625009796\n",
      "59 Train Loss 8.821036 Test MSE 4.664627821390366 Test RE 1.0323252722611522\n",
      "60 Train Loss 8.1278925 Test MSE 3.8989806642751335 Test RE 0.9438078843259022\n",
      "61 Train Loss 7.530571 Test MSE 3.5306321988284837 Test RE 0.8981198581109316\n",
      "62 Train Loss 6.98032 Test MSE 3.309346777360673 Test RE 0.8695192463309996\n",
      "63 Train Loss 6.633371 Test MSE 3.067334527357022 Test RE 0.8371217616601994\n",
      "64 Train Loss 6.346099 Test MSE 2.5987203274338753 Test RE 0.7705269478943622\n",
      "65 Train Loss 6.0623655 Test MSE 2.422411088603908 Test RE 0.743929846863712\n",
      "66 Train Loss 5.7312465 Test MSE 2.093479742857002 Test RE 0.6915800261541362\n",
      "67 Train Loss 4.8557186 Test MSE 1.7242236981940544 Test RE 0.6276316923206151\n",
      "68 Train Loss 4.14098 Test MSE 1.3445178756035523 Test RE 0.5542316851934012\n",
      "69 Train Loss 3.734732 Test MSE 1.2703697415032782 Test RE 0.5387324439324243\n",
      "70 Train Loss 2.8764422 Test MSE 0.5380756850611994 Test RE 0.3506143959595814\n",
      "71 Train Loss 2.19508 Test MSE 0.3227502123781387 Test RE 0.2715446987312479\n",
      "72 Train Loss 1.6154873 Test MSE 0.2821647716811505 Test RE 0.25389810285840747\n",
      "73 Train Loss 1.1054065 Test MSE 0.13933387174941075 Test RE 0.1784170740628852\n",
      "74 Train Loss 0.87078834 Test MSE 0.1090887265110518 Test RE 0.15786941375262506\n",
      "75 Train Loss 0.7287966 Test MSE 0.10005595824029795 Test RE 0.15119225276390671\n",
      "76 Train Loss 0.58475363 Test MSE 0.09191542597757196 Test RE 0.1449113032970976\n",
      "77 Train Loss 0.50393635 Test MSE 0.08216285524171642 Test RE 0.13700796691084652\n",
      "78 Train Loss 0.38837746 Test MSE 0.05559918106597182 Test RE 0.11270475977885905\n",
      "79 Train Loss 0.31381845 Test MSE 0.048197773865189725 Test RE 0.10493528590817867\n",
      "80 Train Loss 0.2663113 Test MSE 0.0353648672912138 Test RE 0.08988641854267017\n",
      "81 Train Loss 0.20938307 Test MSE 0.02044786870332695 Test RE 0.06834898730470655\n",
      "82 Train Loss 0.1813408 Test MSE 0.02060238450923061 Test RE 0.06860674332802441\n",
      "83 Train Loss 0.15509707 Test MSE 0.020530646344786137 Test RE 0.0684871937267026\n",
      "84 Train Loss 0.1372197 Test MSE 0.017727696378649245 Test RE 0.06364059227279793\n",
      "85 Train Loss 0.11631651 Test MSE 0.016603254327744142 Test RE 0.061589215253082995\n",
      "86 Train Loss 0.09398113 Test MSE 0.014844767927524332 Test RE 0.058236433013811525\n",
      "87 Train Loss 0.08116444 Test MSE 0.012937523287540437 Test RE 0.05436678261522356\n",
      "88 Train Loss 0.07061379 Test MSE 0.010286311450446617 Test RE 0.048477241051406016\n",
      "89 Train Loss 0.066503115 Test MSE 0.010744829311552266 Test RE 0.049545911286522866\n",
      "90 Train Loss 0.060761508 Test MSE 0.008754342871388057 Test RE 0.044721857797245676\n",
      "91 Train Loss 0.05728078 Test MSE 0.00742081289739273 Test RE 0.04117501832844077\n",
      "92 Train Loss 0.05031529 Test MSE 0.006828213467937009 Test RE 0.039496772202846316\n",
      "93 Train Loss 0.0470979 Test MSE 0.006772108817779342 Test RE 0.03933417306257266\n",
      "94 Train Loss 0.04619257 Test MSE 0.006852389388392549 Test RE 0.03956663140674904\n",
      "95 Train Loss 0.043961186 Test MSE 0.006080383282156376 Test RE 0.03727121396239756\n",
      "96 Train Loss 0.042624243 Test MSE 0.005490491309016538 Test RE 0.03541715437847187\n",
      "97 Train Loss 0.040940188 Test MSE 0.005107284190991891 Test RE 0.03415883673407378\n",
      "98 Train Loss 0.039612055 Test MSE 0.005024217842005291 Test RE 0.03387991335614757\n",
      "99 Train Loss 0.039081294 Test MSE 0.00480725393216409 Test RE 0.03314031193720377\n",
      "Training time: 86.64\n",
      "7\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 45.673927 Test MSE 8.31806016915786 Test RE 1.3785391012053119\n",
      "1 Train Loss 35.054874 Test MSE 7.014024456979978 Test RE 1.2658775511103029\n",
      "2 Train Loss 29.459837 Test MSE 6.490533033642066 Test RE 1.2177222531507501\n",
      "3 Train Loss 27.032848 Test MSE 5.987303721171124 Test RE 1.169563227226775\n",
      "4 Train Loss 24.99412 Test MSE 5.867592294492612 Test RE 1.1578119430044338\n",
      "5 Train Loss 22.430134 Test MSE 6.0461644447399285 Test RE 1.1752981100825106\n",
      "6 Train Loss 20.212744 Test MSE 5.5742184130004695 Test RE 1.1284960701871098\n",
      "7 Train Loss 17.896523 Test MSE 5.494578990447822 Test RE 1.1204056001103806\n",
      "8 Train Loss 16.16338 Test MSE 5.295443876223794 Test RE 1.0999153046789614\n",
      "9 Train Loss 14.199668 Test MSE 5.531200704664998 Test RE 1.1241331861387793\n",
      "10 Train Loss 12.719714 Test MSE 5.151986633555383 Test RE 1.084914276303719\n",
      "11 Train Loss 11.387926 Test MSE 5.078274366762609 Test RE 1.0771250864266473\n",
      "12 Train Loss 10.89938 Test MSE 4.959859346890333 Test RE 1.0644928303411112\n",
      "13 Train Loss 10.264588 Test MSE 4.764666058959057 Test RE 1.043336243271939\n",
      "14 Train Loss 9.772362 Test MSE 4.7248057805397545 Test RE 1.0389629024146432\n",
      "15 Train Loss 9.331933 Test MSE 4.692186937348159 Test RE 1.0353703248662145\n",
      "16 Train Loss 8.945932 Test MSE 4.5137355491102715 Test RE 1.0154910866572349\n",
      "17 Train Loss 8.546585 Test MSE 4.303448789518168 Test RE 0.9915540207140432\n",
      "18 Train Loss 8.25569 Test MSE 4.270424804584633 Test RE 0.9877421794495972\n",
      "19 Train Loss 8.08271 Test MSE 4.173195178116494 Test RE 0.9764329103263097\n",
      "20 Train Loss 7.858884 Test MSE 3.9168090432076155 Test RE 0.9459632391123102\n",
      "21 Train Loss 7.0094953 Test MSE 3.060985101086372 Test RE 0.8362548858164329\n",
      "22 Train Loss 6.372942 Test MSE 2.617943015564247 Test RE 0.77337148441721\n",
      "23 Train Loss 6.006875 Test MSE 2.3909628226483126 Test RE 0.7390851424649695\n",
      "24 Train Loss 5.0860057 Test MSE 2.216843319538247 Test RE 0.7116649220735884\n",
      "25 Train Loss 4.644372 Test MSE 2.155808866994039 Test RE 0.701799714522777\n",
      "26 Train Loss 4.4433055 Test MSE 2.1554255948882632 Test RE 0.701737326753895\n",
      "27 Train Loss 4.1185656 Test MSE 2.0408276542831807 Test RE 0.6828278492202764\n",
      "28 Train Loss 3.8310914 Test MSE 1.96599835160685 Test RE 0.6701926104036089\n",
      "29 Train Loss 3.3321173 Test MSE 1.7601740842758755 Test RE 0.6341410559951662\n",
      "30 Train Loss 2.8764908 Test MSE 1.69985574121095 Test RE 0.6231808417347734\n",
      "31 Train Loss 2.5233924 Test MSE 1.507047118172254 Test RE 0.5867748292023408\n",
      "32 Train Loss 2.1690602 Test MSE 1.3106658828334075 Test RE 0.547210040734611\n",
      "33 Train Loss 1.8773012 Test MSE 1.1593168176857793 Test RE 0.5146466240870313\n",
      "34 Train Loss 1.5906271 Test MSE 0.9352605835932218 Test RE 0.46224729244080326\n",
      "35 Train Loss 1.258739 Test MSE 0.8670339767166867 Test RE 0.4450677423494101\n",
      "36 Train Loss 0.9854949 Test MSE 0.5353602659800646 Test RE 0.3497285826383775\n",
      "37 Train Loss 0.7837361 Test MSE 0.36426800810955406 Test RE 0.2884819039931356\n",
      "38 Train Loss 0.59459937 Test MSE 0.2748887627349478 Test RE 0.25060316611035305\n",
      "39 Train Loss 0.47164595 Test MSE 0.16647000178750643 Test RE 0.19501860807350682\n",
      "40 Train Loss 0.3928485 Test MSE 0.16835986844174405 Test RE 0.19612246771894792\n",
      "41 Train Loss 0.28285548 Test MSE 0.09041024019240387 Test RE 0.14371988856466678\n",
      "42 Train Loss 0.23859288 Test MSE 0.05333766157413132 Test RE 0.1103888085694555\n",
      "43 Train Loss 0.20053007 Test MSE 0.046924077960986486 Test RE 0.10353946917455087\n",
      "44 Train Loss 0.16991886 Test MSE 0.031787487906438816 Test RE 0.08521894713337558\n",
      "45 Train Loss 0.14846413 Test MSE 0.03214866892727156 Test RE 0.08570172400062957\n",
      "46 Train Loss 0.12595098 Test MSE 0.03867400030947202 Test RE 0.09399778253817855\n",
      "47 Train Loss 0.10957793 Test MSE 0.02967303012346623 Test RE 0.08233585676520509\n",
      "48 Train Loss 0.098885566 Test MSE 0.02637731437650609 Test RE 0.07762888494225133\n",
      "49 Train Loss 0.09007405 Test MSE 0.024824638282062716 Test RE 0.07530945849293676\n",
      "50 Train Loss 0.08320742 Test MSE 0.020006686473884965 Test RE 0.06760761934113889\n",
      "51 Train Loss 0.07372497 Test MSE 0.016704316119851258 Test RE 0.061776373547974585\n",
      "52 Train Loss 0.069699034 Test MSE 0.013860697234366297 Test RE 0.05627306869582227\n",
      "53 Train Loss 0.064592466 Test MSE 0.01246530647518315 Test RE 0.0533653719316935\n",
      "54 Train Loss 0.05945428 Test MSE 0.011669977436434486 Test RE 0.051634867682814216\n",
      "55 Train Loss 0.05481039 Test MSE 0.008718687407287951 Test RE 0.04463069130029687\n",
      "56 Train Loss 0.051037144 Test MSE 0.00721965934737603 Test RE 0.040613125524869925\n",
      "57 Train Loss 0.04638096 Test MSE 0.005940285941355866 Test RE 0.03683933106593197\n",
      "58 Train Loss 0.043108724 Test MSE 0.005347221926075936 Test RE 0.03495201071112144\n",
      "59 Train Loss 0.039200075 Test MSE 0.00423088300096477 Test RE 0.031090203744621663\n",
      "60 Train Loss 0.03587266 Test MSE 0.0037660169418920275 Test RE 0.02933250781053457\n",
      "61 Train Loss 0.029310117 Test MSE 0.0033575377680554325 Test RE 0.02769609330328594\n",
      "62 Train Loss 0.02753751 Test MSE 0.003444523338953392 Test RE 0.028052568152854063\n",
      "63 Train Loss 0.02537591 Test MSE 0.0031436633545380145 Test RE 0.026799462056851537\n",
      "64 Train Loss 0.02276267 Test MSE 0.0025809644340847935 Test RE 0.024282817185789517\n",
      "65 Train Loss 0.021050088 Test MSE 0.0023264096235131445 Test RE 0.023054258217308575\n",
      "66 Train Loss 0.019239206 Test MSE 0.002360378329025768 Test RE 0.023221959837624057\n",
      "67 Train Loss 0.017397787 Test MSE 0.0021190819412825208 Test RE 0.022003001861955654\n",
      "68 Train Loss 0.016242702 Test MSE 0.0017982268885872817 Test RE 0.02026890578297979\n",
      "69 Train Loss 0.0154018495 Test MSE 0.0019493648322234333 Test RE 0.02110350656063571\n",
      "70 Train Loss 0.014685117 Test MSE 0.0020914560618230708 Test RE 0.021859107851745063\n",
      "71 Train Loss 0.013824531 Test MSE 0.0019652567732903682 Test RE 0.021189353735709193\n",
      "72 Train Loss 0.013043813 Test MSE 0.0017541988645339236 Test RE 0.020019234788070366\n",
      "73 Train Loss 0.012019604 Test MSE 0.0016447824562517259 Test RE 0.01938484321573257\n",
      "74 Train Loss 0.0113490615 Test MSE 0.0016643939091297113 Test RE 0.019500067702126055\n",
      "75 Train Loss 0.010250128 Test MSE 0.0016347170676391325 Test RE 0.019325438580311258\n",
      "76 Train Loss 0.009808492 Test MSE 0.0015579030816939739 Test RE 0.018865932596627832\n",
      "77 Train Loss 0.00921989 Test MSE 0.001505112370478384 Test RE 0.018543534767499075\n",
      "78 Train Loss 0.00885523 Test MSE 0.0015585401031817446 Test RE 0.018869789311564883\n",
      "79 Train Loss 0.0083196135 Test MSE 0.0015585848461881645 Test RE 0.018870060169222994\n",
      "80 Train Loss 0.008110296 Test MSE 0.0014944247829151776 Test RE 0.018477579981620217\n",
      "81 Train Loss 0.007935628 Test MSE 0.0014446824171455207 Test RE 0.018167461722788922\n",
      "82 Train Loss 0.0076421048 Test MSE 0.0015132129337793918 Test RE 0.018593368756412897\n",
      "83 Train Loss 0.0073028607 Test MSE 0.0016312203395506858 Test RE 0.019304758555366446\n",
      "84 Train Loss 0.0070288843 Test MSE 0.001515137106070901 Test RE 0.018605186484806503\n",
      "85 Train Loss 0.0067650597 Test MSE 0.00129983689988593 Test RE 0.017232666809074607\n",
      "86 Train Loss 0.006414468 Test MSE 0.001137934467646938 Test RE 0.01612377341346264\n",
      "87 Train Loss 0.0060167843 Test MSE 0.000922478080697076 Test RE 0.014517307903347688\n",
      "88 Train Loss 0.005695993 Test MSE 0.000744504217280687 Test RE 0.013041923287698903\n",
      "89 Train Loss 0.0053287162 Test MSE 0.0006932292734034796 Test RE 0.012584805478200513\n",
      "90 Train Loss 0.005118106 Test MSE 0.0006963152317209057 Test RE 0.012612785442452592\n",
      "91 Train Loss 0.004960513 Test MSE 0.0006166319987580797 Test RE 0.011869190194992345\n",
      "92 Train Loss 0.004806894 Test MSE 0.0005752353348195815 Test RE 0.011463859058400642\n",
      "93 Train Loss 0.0044509107 Test MSE 0.0006788664234583527 Test RE 0.012453752337514945\n",
      "94 Train Loss 0.004084971 Test MSE 0.0007823300339984236 Test RE 0.013369127401852877\n",
      "95 Train Loss 0.0038500498 Test MSE 0.0006490519070476713 Test RE 0.012177209432994458\n",
      "96 Train Loss 0.0037377332 Test MSE 0.0005838507782188109 Test RE 0.011549388540857223\n",
      "97 Train Loss 0.003606455 Test MSE 0.0006071549339323419 Test RE 0.011777627774767261\n",
      "98 Train Loss 0.003506484 Test MSE 0.0006122619284819723 Test RE 0.011827056943957893\n",
      "99 Train Loss 0.0033129994 Test MSE 0.0005886219978300098 Test RE 0.011596483235414942\n",
      "Training time: 85.36\n",
      "8\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.05797 Test MSE 6.93684905911395 Test RE 1.2588940549251293\n",
      "1 Train Loss 40.440353 Test MSE 8.725979326800937 Test RE 1.4119364506559182\n",
      "2 Train Loss 30.98536 Test MSE 7.488081943041982 Test RE 1.307956662509152\n",
      "3 Train Loss 27.103405 Test MSE 6.886455281891735 Test RE 1.2543130077851132\n",
      "4 Train Loss 24.812325 Test MSE 7.163568016109955 Test RE 1.2793010450427102\n",
      "5 Train Loss 22.66716 Test MSE 7.157717560522253 Test RE 1.278778538472421\n",
      "6 Train Loss 19.45505 Test MSE 7.223794555151828 Test RE 1.284667547424785\n",
      "7 Train Loss 16.170605 Test MSE 7.29187645090022 Test RE 1.2907071357740791\n",
      "8 Train Loss 14.301868 Test MSE 6.7091971843659115 Test RE 1.2380646921286296\n",
      "9 Train Loss 12.630833 Test MSE 6.451632555231388 Test RE 1.2140676096498049\n",
      "10 Train Loss 11.155586 Test MSE 5.978882578340278 Test RE 1.1687404424593688\n",
      "11 Train Loss 9.97389 Test MSE 5.763071814409495 Test RE 1.1474534497913744\n",
      "12 Train Loss 9.339941 Test MSE 5.633126073064041 Test RE 1.1344433034614916\n",
      "13 Train Loss 8.69442 Test MSE 5.431850819259263 Test RE 1.1139917569227313\n",
      "14 Train Loss 8.472181 Test MSE 5.240631852713266 Test RE 1.0942080017384006\n",
      "15 Train Loss 8.1432 Test MSE 5.149875687828997 Test RE 1.0846919902266259\n",
      "16 Train Loss 7.7490597 Test MSE 4.929003460512086 Test RE 1.06117649497962\n",
      "17 Train Loss 7.4388266 Test MSE 4.821595415633998 Test RE 1.0495507493605885\n",
      "18 Train Loss 7.009092 Test MSE 4.694666127255309 Test RE 1.0356438157480454\n",
      "19 Train Loss 6.549489 Test MSE 4.65152066070349 Test RE 1.0308738840450273\n",
      "20 Train Loss 4.985513 Test MSE 3.7983265210772914 Test RE 0.9315457916886223\n",
      "21 Train Loss 3.780324 Test MSE 3.523354272216172 Test RE 0.8971937035259637\n",
      "22 Train Loss 3.0549474 Test MSE 3.389787411826979 Test RE 0.8800235444520075\n",
      "23 Train Loss 2.58536 Test MSE 3.3201740810226332 Test RE 0.870940502797636\n",
      "24 Train Loss 2.2697504 Test MSE 3.2524229796692943 Test RE 0.8620085445076738\n",
      "25 Train Loss 1.929288 Test MSE 3.1407369515257413 Test RE 0.8470788578094091\n",
      "26 Train Loss 1.7511866 Test MSE 3.092211149276383 Test RE 0.8405095090051093\n",
      "27 Train Loss 1.6035613 Test MSE 3.05033364292413 Test RE 0.8347986395482292\n",
      "28 Train Loss 1.4677932 Test MSE 2.8996180668623595 Test RE 0.8139138876402879\n",
      "29 Train Loss 1.382304 Test MSE 2.8385785843517994 Test RE 0.8053015244777079\n",
      "30 Train Loss 1.3096215 Test MSE 2.7945671438237247 Test RE 0.7990341381385226\n",
      "31 Train Loss 1.2343925 Test MSE 2.773446923214407 Test RE 0.7960090214469642\n",
      "32 Train Loss 1.1767033 Test MSE 2.7668118191638156 Test RE 0.7950562782547144\n",
      "33 Train Loss 1.1360221 Test MSE 2.7799150731859124 Test RE 0.796936695105928\n",
      "34 Train Loss 1.0895438 Test MSE 2.768860694740537 Test RE 0.7953506007525559\n",
      "35 Train Loss 1.0573715 Test MSE 2.763126374354002 Test RE 0.7945265869303486\n",
      "36 Train Loss 1.0171309 Test MSE 2.726515991704705 Test RE 0.7892454464644199\n",
      "37 Train Loss 0.98246014 Test MSE 2.666841590336193 Test RE 0.7805606794518163\n",
      "38 Train Loss 0.9545129 Test MSE 2.713199684194493 Test RE 0.7873157495466213\n",
      "39 Train Loss 0.93053454 Test MSE 2.6603596888803014 Test RE 0.7796115050573099\n",
      "40 Train Loss 0.9048549 Test MSE 2.5902086621541813 Test RE 0.7692640481320466\n",
      "41 Train Loss 0.8841282 Test MSE 2.581478892446482 Test RE 0.7679666302942677\n",
      "42 Train Loss 0.86052144 Test MSE 2.5858686151461985 Test RE 0.768619304356196\n",
      "43 Train Loss 0.8452983 Test MSE 2.587315993392388 Test RE 0.7688343824205511\n",
      "44 Train Loss 0.8237025 Test MSE 2.5496097747220468 Test RE 0.7632115217234152\n",
      "45 Train Loss 0.8029795 Test MSE 2.5692018587961916 Test RE 0.7661383006499589\n",
      "46 Train Loss 0.7839614 Test MSE 2.572511189949183 Test RE 0.7666315646208126\n",
      "47 Train Loss 0.77215636 Test MSE 2.5604124297528856 Test RE 0.764826670077181\n",
      "48 Train Loss 0.75746405 Test MSE 2.5568131326637196 Test RE 0.764288903874782\n",
      "49 Train Loss 0.745486 Test MSE 2.5402074073110503 Test RE 0.7618029486767158\n",
      "50 Train Loss 0.7316353 Test MSE 2.548935912369191 Test RE 0.7631106565824607\n",
      "51 Train Loss 0.71885115 Test MSE 2.5799397318290125 Test RE 0.7677376529745129\n",
      "52 Train Loss 0.7032975 Test MSE 2.5756270605728453 Test RE 0.7670957029114633\n",
      "53 Train Loss 0.69248724 Test MSE 2.5853238187847185 Test RE 0.7685383329070742\n",
      "54 Train Loss 0.67519176 Test MSE 2.6004239896099253 Test RE 0.7707794765190106\n",
      "55 Train Loss 0.660781 Test MSE 2.5787708720999207 Test RE 0.767563718816705\n",
      "56 Train Loss 0.6499499 Test MSE 2.602887303138695 Test RE 0.7711444597087103\n",
      "57 Train Loss 0.64078903 Test MSE 2.612982451195772 Test RE 0.7726384321611198\n",
      "58 Train Loss 0.63504237 Test MSE 2.6096511792281984 Test RE 0.7721457595785224\n",
      "59 Train Loss 0.6297256 Test MSE 2.626876348695759 Test RE 0.774689867075468\n",
      "60 Train Loss 0.620093 Test MSE 2.6319998667680413 Test RE 0.7754449852308973\n",
      "61 Train Loss 0.6130095 Test MSE 2.625738260652008 Test RE 0.7745220326071042\n",
      "62 Train Loss 0.6028885 Test MSE 2.6545138465665197 Test RE 0.7787544795319058\n",
      "63 Train Loss 0.59604764 Test MSE 2.6611864537925682 Test RE 0.7797326363033273\n",
      "64 Train Loss 0.58969337 Test MSE 2.668220646917861 Test RE 0.7807624721309376\n",
      "65 Train Loss 0.58389795 Test MSE 2.6806754870947542 Test RE 0.7825825896646083\n",
      "66 Train Loss 0.57826066 Test MSE 2.6979344829369434 Test RE 0.7850977989014287\n",
      "67 Train Loss 0.5687913 Test MSE 2.734591748593467 Test RE 0.790413428183482\n",
      "68 Train Loss 0.5625518 Test MSE 2.739663092976685 Test RE 0.7911460059046302\n",
      "69 Train Loss 0.5564068 Test MSE 2.7444273797943772 Test RE 0.7918336103833481\n",
      "70 Train Loss 0.55040765 Test MSE 2.758080797519163 Test RE 0.7938008371549083\n",
      "71 Train Loss 0.54641986 Test MSE 2.7643764137482765 Test RE 0.7947062886693377\n",
      "72 Train Loss 0.5433525 Test MSE 2.771166800126085 Test RE 0.7956817442732137\n",
      "73 Train Loss 0.53930265 Test MSE 2.788267525861442 Test RE 0.7981330236743317\n",
      "74 Train Loss 0.5350482 Test MSE 2.7841939761579333 Test RE 0.7975497900244749\n",
      "75 Train Loss 0.5310302 Test MSE 2.7974731339298553 Test RE 0.7994494765169934\n",
      "76 Train Loss 0.5274907 Test MSE 2.835567981323552 Test RE 0.8048743588524082\n",
      "77 Train Loss 0.5233607 Test MSE 2.861253217263114 Test RE 0.8085115106850534\n",
      "78 Train Loss 0.5204993 Test MSE 2.8570686388497957 Test RE 0.8079200709428664\n",
      "79 Train Loss 0.516181 Test MSE 2.871892720490791 Test RE 0.8100133314389032\n",
      "80 Train Loss 0.5104803 Test MSE 2.8910951697787635 Test RE 0.8127168318410575\n",
      "81 Train Loss 0.50714815 Test MSE 2.879712446930202 Test RE 0.8111153532507644\n",
      "82 Train Loss 0.50417745 Test MSE 2.892407625013849 Test RE 0.812901283297954\n",
      "83 Train Loss 0.50084174 Test MSE 2.922731323356222 Test RE 0.8171513589256041\n",
      "84 Train Loss 0.4971484 Test MSE 2.919718498679628 Test RE 0.8167300802842901\n",
      "85 Train Loss 0.49427092 Test MSE 2.9159966962545614 Test RE 0.8162093661638475\n",
      "86 Train Loss 0.49116945 Test MSE 2.9360497529525467 Test RE 0.8190110582239152\n",
      "87 Train Loss 0.48826796 Test MSE 2.946308598952694 Test RE 0.8204406630282887\n",
      "88 Train Loss 0.48475945 Test MSE 2.9443766833759657 Test RE 0.8201716345208805\n",
      "89 Train Loss 0.481799 Test MSE 2.9412874384160377 Test RE 0.8197412588755212\n",
      "90 Train Loss 0.47782055 Test MSE 2.9383326353186883 Test RE 0.819329401365282\n",
      "91 Train Loss 0.47519743 Test MSE 2.9456453504950333 Test RE 0.8203483124456032\n",
      "92 Train Loss 0.47287235 Test MSE 2.958154248248723 Test RE 0.8220883016158558\n",
      "93 Train Loss 0.47081873 Test MSE 2.9588891411130334 Test RE 0.8221904107789818\n",
      "94 Train Loss 0.468339 Test MSE 2.959856910755861 Test RE 0.8223248574971292\n",
      "95 Train Loss 0.4654971 Test MSE 2.968500425917577 Test RE 0.8235246783048933\n",
      "96 Train Loss 0.46205926 Test MSE 2.9700416695502487 Test RE 0.8237384373210146\n",
      "97 Train Loss 0.45941287 Test MSE 2.9769751446917865 Test RE 0.8246993734360576\n",
      "98 Train Loss 0.45775193 Test MSE 2.9850450128265322 Test RE 0.8258163984025751\n",
      "99 Train Loss 0.4549656 Test MSE 2.988778238805754 Test RE 0.8263326378397025\n",
      "Training time: 85.10\n",
      "9\n",
      "KG_rowdy_tune4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.59107 Test MSE 7.939859511848673 Test RE 1.3468352341652174\n",
      "1 Train Loss 50.65759 Test MSE 8.891690418200408 Test RE 1.4252801181325274\n",
      "2 Train Loss 45.19896 Test MSE 8.822659199255595 Test RE 1.419736710402411\n",
      "3 Train Loss 41.622913 Test MSE 9.069012591087747 Test RE 1.439421756680381\n",
      "4 Train Loss 37.830864 Test MSE 9.454734325124097 Test RE 1.4697136414589516\n",
      "5 Train Loss 36.07327 Test MSE 9.234215165764237 Test RE 1.4524729569724135\n",
      "6 Train Loss 32.2576 Test MSE 8.957379794063495 Test RE 1.4305352199426502\n",
      "7 Train Loss 29.118061 Test MSE 8.6098658073137 Test RE 1.4025109207090827\n",
      "8 Train Loss 27.44292 Test MSE 8.38546581922508 Test RE 1.3841133476992997\n",
      "9 Train Loss 26.05901 Test MSE 8.48179983280136 Test RE 1.3920411378444382\n",
      "10 Train Loss 24.317486 Test MSE 8.404187618265931 Test RE 1.3856576056403545\n",
      "11 Train Loss 23.152205 Test MSE 8.204859973641339 Test RE 1.3691267226518984\n",
      "12 Train Loss 21.976074 Test MSE 7.908894712713862 Test RE 1.344206395271695\n",
      "13 Train Loss 19.058105 Test MSE 7.613605687724308 Test RE 1.3188738296279323\n",
      "14 Train Loss 15.825428 Test MSE 6.638341192105541 Test RE 1.2315097239545192\n",
      "15 Train Loss 13.8399105 Test MSE 5.85058557711784 Test RE 1.1561328156825443\n",
      "16 Train Loss 12.006224 Test MSE 5.811768334493705 Test RE 1.152291099847837\n",
      "17 Train Loss 10.872541 Test MSE 5.771767765559687 Test RE 1.1483188249121543\n",
      "18 Train Loss 10.129791 Test MSE 5.708919949630389 Test RE 1.1420497865543704\n",
      "19 Train Loss 9.775839 Test MSE 5.6481643777588815 Test RE 1.1359565603112796\n",
      "20 Train Loss 9.37615 Test MSE 5.636086440453249 Test RE 1.1347413553604997\n",
      "21 Train Loss 9.005809 Test MSE 5.635262373683 Test RE 1.1346583955942593\n",
      "22 Train Loss 8.519142 Test MSE 5.61263526106345 Test RE 1.1323781231298047\n",
      "23 Train Loss 8.132006 Test MSE 5.701818524668262 Test RE 1.1413392577150736\n",
      "24 Train Loss 7.8108025 Test MSE 5.6773146536515435 Test RE 1.138884133771395\n",
      "25 Train Loss 7.5034075 Test MSE 5.73821709421783 Test RE 1.1449764330729404\n",
      "26 Train Loss 7.3134613 Test MSE 5.7816199788536755 Test RE 1.1492984778222166\n",
      "27 Train Loss 7.0691123 Test MSE 5.9211189667256 Test RE 1.1630809801504045\n",
      "28 Train Loss 6.85925 Test MSE 5.841556383847247 Test RE 1.1552403428512172\n",
      "29 Train Loss 6.6611614 Test MSE 5.894724515447504 Test RE 1.1604857635749304\n",
      "30 Train Loss 6.331478 Test MSE 5.965328201470397 Test RE 1.167414899034883\n",
      "31 Train Loss 6.121642 Test MSE 5.931896041383949 Test RE 1.1641389653240122\n",
      "32 Train Loss 5.849558 Test MSE 5.848659217374463 Test RE 1.155942466268747\n",
      "33 Train Loss 5.501579 Test MSE 5.767472708880258 Test RE 1.14789148509751\n",
      "34 Train Loss 5.2212486 Test MSE 5.725292416434115 Test RE 1.1436862419232383\n",
      "35 Train Loss 4.9022126 Test MSE 5.701190901818236 Test RE 1.1412764400097986\n",
      "36 Train Loss 4.4741383 Test MSE 5.441084311907114 Test RE 1.1149381808485286\n",
      "37 Train Loss 4.117917 Test MSE 5.341055153861674 Test RE 1.1046421016213244\n",
      "38 Train Loss 3.4204252 Test MSE 5.0878840470145725 Test RE 1.0781437331955215\n",
      "39 Train Loss 2.9947836 Test MSE 4.992711396312333 Test RE 1.068012391245074\n",
      "40 Train Loss 2.7233367 Test MSE 5.075723865992744 Test RE 1.0768545660502082\n",
      "41 Train Loss 2.5274496 Test MSE 5.068233533932778 Test RE 1.0760597063933892\n",
      "42 Train Loss 2.3716955 Test MSE 5.102507843275917 Test RE 1.079692042982938\n",
      "43 Train Loss 2.265482 Test MSE 5.1508066806581585 Test RE 1.084790030926094\n",
      "44 Train Loss 2.1825585 Test MSE 5.119434603750704 Test RE 1.0814814137759226\n",
      "45 Train Loss 2.1002157 Test MSE 5.249025657630815 Test RE 1.0950839355976874\n",
      "46 Train Loss 1.9879466 Test MSE 5.226177842773129 Test RE 1.0926980107653976\n",
      "47 Train Loss 1.9215606 Test MSE 5.212073837361322 Test RE 1.0912225701123854\n",
      "48 Train Loss 1.8616742 Test MSE 5.223622981386307 Test RE 1.092430890767939\n",
      "49 Train Loss 1.7943002 Test MSE 5.211735080725119 Test RE 1.0911871077508197\n",
      "50 Train Loss 1.7399192 Test MSE 5.232302650950605 Test RE 1.0933381158504805\n",
      "51 Train Loss 1.7023816 Test MSE 5.2465861432040395 Test RE 1.0948294327907475\n",
      "52 Train Loss 1.6625155 Test MSE 5.263444485451563 Test RE 1.0965869762698837\n",
      "53 Train Loss 1.635103 Test MSE 5.269213587973707 Test RE 1.097187779615925\n",
      "54 Train Loss 1.6021255 Test MSE 5.234988368438591 Test RE 1.093618682627736\n",
      "55 Train Loss 1.5717652 Test MSE 5.296699673712257 Test RE 1.1000457176366047\n",
      "56 Train Loss 1.5554522 Test MSE 5.311540100427877 Test RE 1.101585707611509\n",
      "57 Train Loss 1.5263782 Test MSE 5.270202933465366 Test RE 1.0972907785565418\n",
      "58 Train Loss 1.4983671 Test MSE 5.316414530448816 Test RE 1.1020910573762408\n",
      "59 Train Loss 1.4640771 Test MSE 5.3870086389039455 Test RE 1.1093839955831877\n",
      "60 Train Loss 1.4256275 Test MSE 5.3821955741916385 Test RE 1.1088882909616318\n",
      "61 Train Loss 1.3874391 Test MSE 5.394459717886781 Test RE 1.1101509566158327\n",
      "62 Train Loss 1.3640261 Test MSE 5.37064973471547 Test RE 1.107698263616053\n",
      "63 Train Loss 1.3410262 Test MSE 5.362852348271837 Test RE 1.1068938647914692\n",
      "64 Train Loss 1.3201563 Test MSE 5.409917104800868 Test RE 1.1117403426411145\n",
      "65 Train Loss 1.3054562 Test MSE 5.424677100078405 Test RE 1.113255902369749\n",
      "66 Train Loss 1.2930775 Test MSE 5.440332681571674 Test RE 1.1148611695164252\n",
      "67 Train Loss 1.2765124 Test MSE 5.461364895330434 Test RE 1.1170141058468765\n",
      "68 Train Loss 1.2633708 Test MSE 5.463361046356038 Test RE 1.1172182237907626\n",
      "69 Train Loss 1.2537344 Test MSE 5.463733378181561 Test RE 1.1172562927386336\n",
      "70 Train Loss 1.2453201 Test MSE 5.45403187224952 Test RE 1.116263941575969\n",
      "71 Train Loss 1.2339473 Test MSE 5.446969631303837 Test RE 1.1155410013076317\n",
      "72 Train Loss 1.2242656 Test MSE 5.452602950468861 Test RE 1.1161177049583952\n",
      "73 Train Loss 1.2151705 Test MSE 5.45899779983493 Test RE 1.1167720083424928\n",
      "74 Train Loss 1.2052159 Test MSE 5.465309382890462 Test RE 1.1174174164703217\n",
      "75 Train Loss 1.1925187 Test MSE 5.475438913080488 Test RE 1.118452460676733\n",
      "76 Train Loss 1.1829066 Test MSE 5.485439015393055 Test RE 1.1194733411111684\n",
      "77 Train Loss 1.1725504 Test MSE 5.473667058357504 Test RE 1.1182714801512514\n",
      "78 Train Loss 1.1630503 Test MSE 5.4612281833685525 Test RE 1.1170001248962833\n",
      "79 Train Loss 1.1547751 Test MSE 5.477283593136769 Test RE 1.1186408486067014\n",
      "80 Train Loss 1.1437606 Test MSE 5.468004345615506 Test RE 1.1176928836885118\n",
      "81 Train Loss 1.132819 Test MSE 5.45260810990205 Test RE 1.1161182330120079\n",
      "82 Train Loss 1.1189746 Test MSE 5.483826731963984 Test RE 1.1193088108924825\n",
      "83 Train Loss 1.1109426 Test MSE 5.501965448493693 Test RE 1.1211584375440313\n",
      "84 Train Loss 1.1026781 Test MSE 5.474294052283356 Test RE 1.1183355258212284\n",
      "85 Train Loss 1.0903001 Test MSE 5.499743246601433 Test RE 1.1209320010056687\n",
      "86 Train Loss 1.0789539 Test MSE 5.528128229039503 Test RE 1.1238209255852605\n",
      "87 Train Loss 1.0716711 Test MSE 5.520511671787338 Test RE 1.123046468442507\n",
      "88 Train Loss 1.0627033 Test MSE 5.543977665062984 Test RE 1.1254307995298085\n",
      "89 Train Loss 1.0564283 Test MSE 5.571266179465973 Test RE 1.1281971919469078\n",
      "90 Train Loss 1.048433 Test MSE 5.554049805174595 Test RE 1.126452660867755\n",
      "91 Train Loss 1.0400709 Test MSE 5.572117678778503 Test RE 1.128283404165008\n",
      "92 Train Loss 1.0277884 Test MSE 5.6066572402068395 Test RE 1.1317749141913256\n",
      "93 Train Loss 1.0187345 Test MSE 5.6188501546885545 Test RE 1.1330048930993393\n",
      "94 Train Loss 1.0091617 Test MSE 5.6434293129778075 Test RE 1.1354803033070529\n",
      "95 Train Loss 1.0043885 Test MSE 5.64544897233467 Test RE 1.1356834668579463\n",
      "96 Train Loss 0.9980209 Test MSE 5.6511251374496085 Test RE 1.136254254705974\n",
      "97 Train Loss 0.9928845 Test MSE 5.671988844082108 Test RE 1.1383498227862416\n",
      "98 Train Loss 0.98687804 Test MSE 5.685021289208437 Test RE 1.1396568572292711\n",
      "99 Train Loss 0.9826152 Test MSE 5.685488746036404 Test RE 1.1397037110053185\n",
      "Training time: 85.31\n",
      "0\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.725815 Test MSE 8.176275468135055 Test RE 1.366739725445308\n",
      "1 Train Loss 58.04914 Test MSE 8.415210099322168 Test RE 1.3865659849356393\n",
      "2 Train Loss 48.19844 Test MSE 7.818958399415299 Test RE 1.3365416946513022\n",
      "3 Train Loss 37.230785 Test MSE 7.473111962551407 Test RE 1.306648591786622\n",
      "4 Train Loss 32.145157 Test MSE 6.721912811173474 Test RE 1.2392373597432238\n",
      "5 Train Loss 28.506748 Test MSE 6.27179173091312 Test RE 1.1970268014347158\n",
      "6 Train Loss 25.301523 Test MSE 6.055315119182433 Test RE 1.1761871616708035\n",
      "7 Train Loss 23.55524 Test MSE 6.128213787118554 Test RE 1.1832459157151907\n",
      "8 Train Loss 22.029308 Test MSE 6.0349201357153115 Test RE 1.1742047255654289\n",
      "9 Train Loss 19.777924 Test MSE 5.822199801240411 Test RE 1.1533247523233294\n",
      "10 Train Loss 16.04324 Test MSE 5.445099871625753 Test RE 1.1153495212048459\n",
      "11 Train Loss 13.031805 Test MSE 5.113862624283246 Test RE 1.0808927127512908\n",
      "12 Train Loss 10.6912 Test MSE 4.883013249042872 Test RE 1.056214223479817\n",
      "13 Train Loss 9.128072 Test MSE 4.761006848321233 Test RE 1.0429355309954556\n",
      "14 Train Loss 7.947777 Test MSE 4.715467879928681 Test RE 1.0379357140988328\n",
      "15 Train Loss 6.9504223 Test MSE 4.550842968116721 Test RE 1.019656718771591\n",
      "16 Train Loss 6.4119825 Test MSE 4.3060204536482 Test RE 0.9918502439522306\n",
      "17 Train Loss 5.9865737 Test MSE 4.0841542801169615 Test RE 0.9659599713245566\n",
      "18 Train Loss 5.6726756 Test MSE 3.973490852288608 Test RE 0.9527833716079072\n",
      "19 Train Loss 5.301957 Test MSE 3.831934316655676 Test RE 0.9356578991008416\n",
      "20 Train Loss 5.0937333 Test MSE 3.725104523128613 Test RE 0.9225231895453642\n",
      "21 Train Loss 4.9585857 Test MSE 3.560420452729879 Test RE 0.9019006581809899\n",
      "22 Train Loss 4.8243876 Test MSE 3.501151695772073 Test RE 0.8943623826839426\n",
      "23 Train Loss 4.7145762 Test MSE 3.459833748086145 Test RE 0.8890694258309846\n",
      "24 Train Loss 4.615937 Test MSE 3.351032756128671 Test RE 0.8749785305281922\n",
      "25 Train Loss 4.497693 Test MSE 3.2908872102883704 Test RE 0.8670907618505077\n",
      "26 Train Loss 4.399287 Test MSE 3.2661761774384535 Test RE 0.8638291667919616\n",
      "27 Train Loss 4.320844 Test MSE 3.2496611155138164 Test RE 0.8616424703305733\n",
      "28 Train Loss 4.253987 Test MSE 3.1199185784531767 Test RE 0.8442667592026856\n",
      "29 Train Loss 4.1760416 Test MSE 3.040606694464995 Test RE 0.833466567722345\n",
      "30 Train Loss 4.106308 Test MSE 2.92419452442794 Test RE 0.8173558777479848\n",
      "31 Train Loss 3.95958 Test MSE 2.7137793314808127 Test RE 0.7873998460229177\n",
      "32 Train Loss 3.6150672 Test MSE 2.4508707367750993 Test RE 0.7482871088869728\n",
      "33 Train Loss 2.9914122 Test MSE 2.03171380530078 Test RE 0.6813014701400042\n",
      "34 Train Loss 2.496241 Test MSE 1.8407688829369446 Test RE 0.6484965834781443\n",
      "35 Train Loss 2.126126 Test MSE 1.6956429417149108 Test RE 0.6224081395278324\n",
      "36 Train Loss 1.642093 Test MSE 1.4425300260838412 Test RE 0.5740774542273827\n",
      "37 Train Loss 1.2733462 Test MSE 1.3183916851796416 Test RE 0.5488204530253222\n",
      "38 Train Loss 0.9655809 Test MSE 1.0527846055740895 Test RE 0.49043089744083423\n",
      "39 Train Loss 0.7506745 Test MSE 0.8789514557830524 Test RE 0.448116056214718\n",
      "40 Train Loss 0.6324453 Test MSE 0.7612233486457509 Test RE 0.4170269393075705\n",
      "41 Train Loss 0.49843913 Test MSE 0.5647090071493064 Test RE 0.359186841009415\n",
      "42 Train Loss 0.39332333 Test MSE 0.49369650758390826 Test RE 0.3358443819757633\n",
      "43 Train Loss 0.33216795 Test MSE 0.431308269246392 Test RE 0.31390768827885773\n",
      "44 Train Loss 0.2759124 Test MSE 0.43501324102612327 Test RE 0.31525305106576423\n",
      "45 Train Loss 0.24870886 Test MSE 0.458592820502187 Test RE 0.3236843380736096\n",
      "46 Train Loss 0.22120647 Test MSE 0.4538797739967419 Test RE 0.3220167594432625\n",
      "47 Train Loss 0.19085848 Test MSE 0.4437143103737965 Test RE 0.3183902632543733\n",
      "48 Train Loss 0.1675308 Test MSE 0.46598713067356673 Test RE 0.3262834319311754\n",
      "49 Train Loss 0.15010409 Test MSE 0.4419839576528553 Test RE 0.3177688435612736\n",
      "50 Train Loss 0.14145304 Test MSE 0.4522430179517203 Test RE 0.32143561556689043\n",
      "51 Train Loss 0.131897 Test MSE 0.45228125418495585 Test RE 0.32144920364554086\n",
      "52 Train Loss 0.123581566 Test MSE 0.4422949543272124 Test RE 0.31788062100669967\n",
      "53 Train Loss 0.11877332 Test MSE 0.44584481102099593 Test RE 0.3191537256235767\n",
      "54 Train Loss 0.113923915 Test MSE 0.4478066573523406 Test RE 0.3198551392910672\n",
      "55 Train Loss 0.10986509 Test MSE 0.4492908060998807 Test RE 0.3203847427667079\n",
      "56 Train Loss 0.10631824 Test MSE 0.4450715414895785 Test RE 0.31887683672962575\n",
      "57 Train Loss 0.10266451 Test MSE 0.4459931029846024 Test RE 0.319206797899766\n",
      "58 Train Loss 0.100176364 Test MSE 0.4506243510514355 Test RE 0.32085985920647564\n",
      "59 Train Loss 0.09771805 Test MSE 0.4535735850668152 Test RE 0.32190812428601473\n",
      "60 Train Loss 0.095704846 Test MSE 0.44977994384712827 Test RE 0.32055909492314116\n",
      "61 Train Loss 0.09443159 Test MSE 0.4535325359233845 Test RE 0.3218935573533413\n",
      "62 Train Loss 0.09273525 Test MSE 0.45366276457531896 Test RE 0.3219397687625696\n",
      "63 Train Loss 0.09103271 Test MSE 0.4636705125906845 Test RE 0.32547137529565645\n",
      "64 Train Loss 0.09003889 Test MSE 0.4675367527810803 Test RE 0.3268255030872806\n",
      "65 Train Loss 0.08877127 Test MSE 0.4689147482225112 Test RE 0.32730678364275745\n",
      "66 Train Loss 0.087469794 Test MSE 0.4717396110523353 Test RE 0.3282911933325304\n",
      "67 Train Loss 0.08628286 Test MSE 0.47418168445813647 Test RE 0.3291398355581742\n",
      "68 Train Loss 0.0854296 Test MSE 0.4763568390836993 Test RE 0.3298938829125239\n",
      "69 Train Loss 0.084387094 Test MSE 0.4792417336794499 Test RE 0.33089132057114407\n",
      "70 Train Loss 0.08343432 Test MSE 0.4788743609099113 Test RE 0.3307644704270294\n",
      "71 Train Loss 0.08253786 Test MSE 0.479831154549583 Test RE 0.33109474016603\n",
      "72 Train Loss 0.08157323 Test MSE 0.47990492891783726 Test RE 0.331120192209148\n",
      "73 Train Loss 0.08092522 Test MSE 0.48290008461155537 Test RE 0.33215186937647456\n",
      "74 Train Loss 0.07986988 Test MSE 0.48664112312683844 Test RE 0.33343598140458813\n",
      "75 Train Loss 0.07885452 Test MSE 0.489200224142246 Test RE 0.33431155217951625\n",
      "76 Train Loss 0.078220986 Test MSE 0.4925398967590276 Test RE 0.3354507504486784\n",
      "77 Train Loss 0.07757007 Test MSE 0.4973524083587612 Test RE 0.3370855788001927\n",
      "78 Train Loss 0.07668791 Test MSE 0.49267187097564136 Test RE 0.3354956888233556\n",
      "79 Train Loss 0.07605658 Test MSE 0.49326515194956144 Test RE 0.33569763187538687\n",
      "80 Train Loss 0.07540463 Test MSE 0.49597344104948227 Test RE 0.33661794998006034\n",
      "81 Train Loss 0.07502573 Test MSE 0.49675287752792785 Test RE 0.33688234852172033\n",
      "82 Train Loss 0.074638546 Test MSE 0.4976270899199946 Test RE 0.33717865004181685\n",
      "83 Train Loss 0.073990636 Test MSE 0.5007979634415145 Test RE 0.33825119324319947\n",
      "84 Train Loss 0.073373355 Test MSE 0.5021918309416378 Test RE 0.33872159225675885\n",
      "85 Train Loss 0.072528705 Test MSE 0.5039897657657023 Test RE 0.3393273918748949\n",
      "86 Train Loss 0.071571596 Test MSE 0.50325584663448 Test RE 0.339080234480658\n",
      "87 Train Loss 0.071099095 Test MSE 0.5082782434123467 Test RE 0.3407680118474544\n",
      "88 Train Loss 0.07072567 Test MSE 0.5066148136106964 Test RE 0.34020994330132504\n",
      "89 Train Loss 0.07013695 Test MSE 0.5036503027628406 Test RE 0.33921309540877265\n",
      "90 Train Loss 0.06973311 Test MSE 0.5025766658012059 Test RE 0.3388513503545818\n",
      "91 Train Loss 0.06933639 Test MSE 0.5015566160927083 Test RE 0.33850730256373046\n",
      "92 Train Loss 0.06879488 Test MSE 0.5035555234091923 Test RE 0.33918117652532087\n",
      "93 Train Loss 0.06836852 Test MSE 0.5025023252564755 Test RE 0.3388262881826941\n",
      "94 Train Loss 0.06785381 Test MSE 0.504857959433479 Test RE 0.33961953583171095\n",
      "95 Train Loss 0.06743406 Test MSE 0.5024646222924952 Test RE 0.33881357680373153\n",
      "96 Train Loss 0.06686568 Test MSE 0.507010435105083 Test RE 0.3403427543603693\n",
      "97 Train Loss 0.066437826 Test MSE 0.5077760514740941 Test RE 0.34059962647790626\n",
      "98 Train Loss 0.06593354 Test MSE 0.5071204349492814 Test RE 0.34037967235749983\n",
      "99 Train Loss 0.0653127 Test MSE 0.5080817077023368 Test RE 0.34070212317388854\n",
      "Training time: 83.03\n",
      "1\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.962826 Test MSE 8.444715217366557 Test RE 1.3889946228012602\n",
      "1 Train Loss 57.33928 Test MSE 8.457871727593094 Test RE 1.3900761992293948\n",
      "2 Train Loss 56.490906 Test MSE 8.26486242251584 Test RE 1.3741238408155763\n",
      "3 Train Loss 52.13891 Test MSE 8.775727351019409 Test RE 1.4159555536689443\n",
      "4 Train Loss 45.66002 Test MSE 8.443097534005902 Test RE 1.38886157739657\n",
      "5 Train Loss 44.301888 Test MSE 8.455703764200047 Test RE 1.3898980322180767\n",
      "6 Train Loss 43.72184 Test MSE 8.434727992682761 Test RE 1.3881730258038487\n",
      "7 Train Loss 41.491783 Test MSE 8.318621395739765 Test RE 1.378585606022686\n",
      "8 Train Loss 40.198128 Test MSE 7.876688047161902 Test RE 1.3414666591094602\n",
      "9 Train Loss 39.219437 Test MSE 7.955909073874434 Test RE 1.3481957873946002\n",
      "10 Train Loss 38.696426 Test MSE 7.8937788898131815 Test RE 1.3429212281038119\n",
      "11 Train Loss 38.066135 Test MSE 7.820701231968657 Test RE 1.3366906427890697\n",
      "12 Train Loss 37.046684 Test MSE 7.585934075377118 Test RE 1.3164749277277612\n",
      "13 Train Loss 35.642174 Test MSE 7.699815243156041 Test RE 1.3263196761196279\n",
      "14 Train Loss 33.418125 Test MSE 7.94663358089196 Test RE 1.3474096530003954\n",
      "15 Train Loss 30.647158 Test MSE 7.994131710099836 Test RE 1.3514304807202149\n",
      "16 Train Loss 27.086967 Test MSE 7.776398915308888 Test RE 1.3328992567457252\n",
      "17 Train Loss 23.843224 Test MSE 7.354504582930292 Test RE 1.2962380681594965\n",
      "18 Train Loss 21.96445 Test MSE 6.172384899718959 Test RE 1.1875025758512225\n",
      "19 Train Loss 19.317238 Test MSE 5.799778914864466 Test RE 1.1511019235780167\n",
      "20 Train Loss 18.332087 Test MSE 5.568579083410328 Test RE 1.1279250868493262\n",
      "21 Train Loss 17.648014 Test MSE 5.522995708979485 Test RE 1.1232991058443362\n",
      "22 Train Loss 17.043236 Test MSE 5.619695060392518 Test RE 1.1330900747901256\n",
      "23 Train Loss 16.244026 Test MSE 5.907039450803606 Test RE 1.1616973427382533\n",
      "24 Train Loss 15.372712 Test MSE 5.703642421411413 Test RE 1.1415217888233804\n",
      "25 Train Loss 14.454418 Test MSE 5.844693259092912 Test RE 1.1555504792456888\n",
      "26 Train Loss 13.855896 Test MSE 5.887379468092022 Test RE 1.1597625338656696\n",
      "27 Train Loss 13.228891 Test MSE 6.041184319600303 Test RE 1.1748139736108236\n",
      "28 Train Loss 12.624095 Test MSE 5.744704936460712 Test RE 1.1456235267450539\n",
      "29 Train Loss 11.610713 Test MSE 5.343648454020957 Test RE 1.1049102434782803\n",
      "30 Train Loss 10.322855 Test MSE 4.874683928505342 Test RE 1.055313007239335\n",
      "31 Train Loss 8.73741 Test MSE 4.401464940545042 Test RE 1.002782355524593\n",
      "32 Train Loss 7.414604 Test MSE 4.066051671121813 Test RE 0.9638168329651827\n",
      "33 Train Loss 5.585958 Test MSE 3.521152056972348 Test RE 0.896913271538154\n",
      "34 Train Loss 3.7702305 Test MSE 2.741310613278129 Test RE 0.7913838514286397\n",
      "35 Train Loss 2.7117267 Test MSE 2.6253212008313644 Test RE 0.7744605194599858\n",
      "36 Train Loss 2.2145925 Test MSE 2.6712085629103353 Test RE 0.7811995049440807\n",
      "37 Train Loss 1.7930875 Test MSE 2.7966720208145133 Test RE 0.7993349990424992\n",
      "38 Train Loss 1.5420353 Test MSE 2.8631602206000015 Test RE 0.8087808991683766\n",
      "39 Train Loss 1.393345 Test MSE 2.8757104301891467 Test RE 0.8105515424771547\n",
      "40 Train Loss 1.2789078 Test MSE 2.8388676789877185 Test RE 0.8053425313437896\n",
      "41 Train Loss 1.1843318 Test MSE 2.7478985828236917 Test RE 0.7923342151126879\n",
      "42 Train Loss 1.1099366 Test MSE 2.6396044015698528 Test RE 0.7765644087487177\n",
      "43 Train Loss 1.0539904 Test MSE 2.5757100286849446 Test RE 0.7671080579551557\n",
      "44 Train Loss 1.0013942 Test MSE 2.546515930362147 Test RE 0.7627483186007255\n",
      "45 Train Loss 0.961777 Test MSE 2.526587772427054 Test RE 0.7597579537003522\n",
      "46 Train Loss 0.9350275 Test MSE 2.5128717939624132 Test RE 0.7576929146121535\n",
      "47 Train Loss 0.9127728 Test MSE 2.50308144194136 Test RE 0.756215457655162\n",
      "48 Train Loss 0.8904602 Test MSE 2.5023295217607213 Test RE 0.7561018663906142\n",
      "49 Train Loss 0.86406356 Test MSE 2.5084357910391453 Test RE 0.7570238369729885\n",
      "50 Train Loss 0.8401782 Test MSE 2.5154430991792274 Test RE 0.7580804715127127\n",
      "51 Train Loss 0.81718665 Test MSE 2.5193125893705064 Test RE 0.758663322644318\n",
      "52 Train Loss 0.7982147 Test MSE 2.5241086175958993 Test RE 0.7593851149060779\n",
      "53 Train Loss 0.78018135 Test MSE 2.5355815078439976 Test RE 0.7611089837505554\n",
      "54 Train Loss 0.7608804 Test MSE 2.5415044343361033 Test RE 0.7619974117181076\n",
      "55 Train Loss 0.7421463 Test MSE 2.5588838085776215 Test RE 0.7645983270218254\n",
      "56 Train Loss 0.7245153 Test MSE 2.5917957826823383 Test RE 0.7694996908839434\n",
      "57 Train Loss 0.71150434 Test MSE 2.590461597210848 Test RE 0.7693016067076593\n",
      "58 Train Loss 0.69751763 Test MSE 2.5825537748945093 Test RE 0.7681264975594375\n",
      "59 Train Loss 0.6887339 Test MSE 2.5698017713889674 Test RE 0.7662277426659038\n",
      "60 Train Loss 0.67614317 Test MSE 2.5791946532155503 Test RE 0.7676267848397569\n",
      "61 Train Loss 0.6667183 Test MSE 2.5708708609688085 Test RE 0.7663871092218933\n",
      "62 Train Loss 0.6574647 Test MSE 2.6018473180987844 Test RE 0.7709903887229049\n",
      "63 Train Loss 0.6488745 Test MSE 2.5974877200077313 Test RE 0.7703441906589426\n",
      "64 Train Loss 0.64229757 Test MSE 2.603778984500976 Test RE 0.7712765353967065\n",
      "65 Train Loss 0.6355849 Test MSE 2.6260142493285525 Test RE 0.7745627361488902\n",
      "66 Train Loss 0.6302694 Test MSE 2.6337588122678963 Test RE 0.775704053948672\n",
      "67 Train Loss 0.6252845 Test MSE 2.6380589996780563 Test RE 0.7763370489571301\n",
      "68 Train Loss 0.61987746 Test MSE 2.6374177957298497 Test RE 0.7762426953750508\n",
      "69 Train Loss 0.6134469 Test MSE 2.6328399888391276 Test RE 0.7755687345663561\n",
      "70 Train Loss 0.6058666 Test MSE 2.639195634963065 Test RE 0.7765042774107709\n",
      "71 Train Loss 0.59727824 Test MSE 2.6547717710868954 Test RE 0.7787923122591691\n",
      "72 Train Loss 0.59043473 Test MSE 2.648560722905317 Test RE 0.7778807557280092\n",
      "73 Train Loss 0.5842401 Test MSE 2.669931440259744 Test RE 0.7810127342674967\n",
      "74 Train Loss 0.57763857 Test MSE 2.670082412515052 Test RE 0.781034815281517\n",
      "75 Train Loss 0.57281256 Test MSE 2.6788349863265486 Test RE 0.7823138903801418\n",
      "76 Train Loss 0.5678525 Test MSE 2.693563104402074 Test RE 0.7844615063989423\n",
      "77 Train Loss 0.5626085 Test MSE 2.709796000362675 Test RE 0.7868217544182261\n",
      "78 Train Loss 0.5574323 Test MSE 2.723048356942224 Test RE 0.7887433981192589\n",
      "79 Train Loss 0.5528777 Test MSE 2.7348100435687006 Test RE 0.7904449758242844\n",
      "80 Train Loss 0.54868555 Test MSE 2.749988671012924 Test RE 0.7926354878037325\n",
      "81 Train Loss 0.54223984 Test MSE 2.7850864966114526 Test RE 0.7976776138162595\n",
      "82 Train Loss 0.53701735 Test MSE 2.8035150924517827 Test RE 0.8003123329379424\n",
      "83 Train Loss 0.53214324 Test MSE 2.81479545309258 Test RE 0.8019208045318114\n",
      "84 Train Loss 0.52690977 Test MSE 2.8321547404462386 Test RE 0.804389789745727\n",
      "85 Train Loss 0.52222764 Test MSE 2.8293932059862286 Test RE 0.8039975280083688\n",
      "86 Train Loss 0.5175142 Test MSE 2.8347367131815044 Test RE 0.8047563727099621\n",
      "87 Train Loss 0.5120274 Test MSE 2.8481137622533863 Test RE 0.8066529501001026\n",
      "88 Train Loss 0.50613743 Test MSE 2.8655099974065577 Test RE 0.809112711691834\n",
      "89 Train Loss 0.5009954 Test MSE 2.862401847917938 Test RE 0.8086737801262672\n",
      "90 Train Loss 0.497033 Test MSE 2.8676388765480265 Test RE 0.8094132137612159\n",
      "91 Train Loss 0.49308223 Test MSE 2.884229140483921 Test RE 0.8117512021679927\n",
      "92 Train Loss 0.48812482 Test MSE 2.914606724707528 Test RE 0.8160148112410203\n",
      "93 Train Loss 0.48358506 Test MSE 2.9399390506637433 Test RE 0.8195533384825019\n",
      "94 Train Loss 0.4798356 Test MSE 2.9494437447106288 Test RE 0.8208770594675329\n",
      "95 Train Loss 0.47223532 Test MSE 2.9355960048931027 Test RE 0.8189477692695755\n",
      "96 Train Loss 0.4664425 Test MSE 2.9431924148035122 Test RE 0.8200066758075812\n",
      "97 Train Loss 0.46291345 Test MSE 2.945271559879828 Test RE 0.8202962613341621\n",
      "98 Train Loss 0.45973894 Test MSE 2.9590544499271005 Test RE 0.8222133777468144\n",
      "99 Train Loss 0.45659542 Test MSE 2.972250918515217 Test RE 0.8240447469957984\n",
      "Training time: 77.61\n",
      "2\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.731346 Test MSE 8.480384550025326 Test RE 1.3919249942147705\n",
      "1 Train Loss 56.157597 Test MSE 8.46900109319967 Test RE 1.3909904706195624\n",
      "2 Train Loss 49.727222 Test MSE 8.660388243011573 Test RE 1.406619847881103\n",
      "3 Train Loss 43.835075 Test MSE 7.591151609160955 Test RE 1.3169275794172561\n",
      "4 Train Loss 34.93921 Test MSE 6.679562291022509 Test RE 1.2353273660995299\n",
      "5 Train Loss 31.71279 Test MSE 6.2289334192060375 Test RE 1.1929298467874276\n",
      "6 Train Loss 28.009579 Test MSE 5.920941525823644 Test RE 1.163063552727859\n",
      "7 Train Loss 25.491203 Test MSE 5.091465664708875 Test RE 1.0785231462579463\n",
      "8 Train Loss 22.727335 Test MSE 5.890250516895104 Test RE 1.1600452852158896\n",
      "9 Train Loss 21.2207 Test MSE 5.534780729840217 Test RE 1.1244969203746156\n",
      "10 Train Loss 19.283619 Test MSE 5.957539497202349 Test RE 1.1666525252793154\n",
      "11 Train Loss 16.755466 Test MSE 6.068270690213958 Test RE 1.17744473737633\n",
      "12 Train Loss 13.870647 Test MSE 5.338413907529882 Test RE 1.1043689353078188\n",
      "13 Train Loss 11.544917 Test MSE 4.412167273391226 Test RE 1.00400076743059\n",
      "14 Train Loss 8.824828 Test MSE 4.25297022986551 Test RE 0.9857215054506743\n",
      "15 Train Loss 7.3534975 Test MSE 4.135065098285388 Test RE 0.9719618876379021\n",
      "16 Train Loss 6.373981 Test MSE 4.089962654228407 Test RE 0.9666466083969407\n",
      "17 Train Loss 5.796053 Test MSE 3.9830541628467007 Test RE 0.9539292516043012\n",
      "18 Train Loss 5.2939816 Test MSE 4.030528750755987 Test RE 0.959597420780522\n",
      "19 Train Loss 4.559002 Test MSE 4.110391685437246 Test RE 0.9690577619099672\n",
      "20 Train Loss 3.898109 Test MSE 4.028131171406701 Test RE 0.9593119677604566\n",
      "21 Train Loss 3.3849149 Test MSE 3.9728535210394194 Test RE 0.9527069573174768\n",
      "22 Train Loss 3.0857427 Test MSE 3.7732262486587325 Test RE 0.9284627484379743\n",
      "23 Train Loss 2.850989 Test MSE 3.6088786976744323 Test RE 0.9080174665135813\n",
      "24 Train Loss 2.6211925 Test MSE 3.399812385460454 Test RE 0.8813238766959828\n",
      "25 Train Loss 2.3642166 Test MSE 2.823868681647878 Test RE 0.8032122228445778\n",
      "26 Train Loss 2.1777563 Test MSE 2.6713992023158064 Test RE 0.7812273808565369\n",
      "27 Train Loss 2.0421498 Test MSE 2.556014750981268 Test RE 0.7641695674448161\n",
      "28 Train Loss 1.9090512 Test MSE 2.383262046893956 Test RE 0.7378939656128163\n",
      "29 Train Loss 1.7978994 Test MSE 2.2668022818558367 Test RE 0.7196393139366776\n",
      "30 Train Loss 1.6933117 Test MSE 1.9584446517629017 Test RE 0.6689038743628573\n",
      "31 Train Loss 1.5744456 Test MSE 1.6149059074534013 Test RE 0.6074096284024499\n",
      "32 Train Loss 1.3404868 Test MSE 0.938895416925889 Test RE 0.4631446693695935\n",
      "33 Train Loss 1.0412666 Test MSE 0.6798610336612055 Test RE 0.39411061777532647\n",
      "34 Train Loss 0.746252 Test MSE 0.4025132135974057 Test RE 0.30324812983256483\n",
      "35 Train Loss 0.54006934 Test MSE 0.161128372468148 Test RE 0.1918642544785447\n",
      "36 Train Loss 0.39983034 Test MSE 0.0889521510798229 Test RE 0.1425562582561788\n",
      "37 Train Loss 0.30168825 Test MSE 0.06430139431908163 Test RE 0.1212043635598214\n",
      "38 Train Loss 0.23427264 Test MSE 0.04255240122141731 Test RE 0.0985984519655298\n",
      "39 Train Loss 0.19320717 Test MSE 0.04332327231926067 Test RE 0.09948753868237334\n",
      "40 Train Loss 0.16788153 Test MSE 0.03223263940027997 Test RE 0.08581357499654797\n",
      "41 Train Loss 0.14889915 Test MSE 0.0302455786488834 Test RE 0.08312640697689339\n",
      "42 Train Loss 0.13079825 Test MSE 0.026629513875236384 Test RE 0.0779991157898111\n",
      "43 Train Loss 0.10708786 Test MSE 0.01929134679648153 Test RE 0.06638796164946362\n",
      "44 Train Loss 0.095743544 Test MSE 0.017921364555674137 Test RE 0.063987272348066\n",
      "45 Train Loss 0.08265047 Test MSE 0.01568193725609602 Test RE 0.059856031061958345\n",
      "46 Train Loss 0.07389167 Test MSE 0.011194154283163327 Test RE 0.050571251854875744\n",
      "47 Train Loss 0.063656114 Test MSE 0.01267552790782533 Test RE 0.053813481282060704\n",
      "48 Train Loss 0.05567782 Test MSE 0.011882306335894327 Test RE 0.05210248444529206\n",
      "49 Train Loss 0.04871253 Test MSE 0.011326625697054948 Test RE 0.05086960141274484\n",
      "50 Train Loss 0.0416306 Test MSE 0.010694679474359014 Test RE 0.049430152098566375\n",
      "51 Train Loss 0.036524963 Test MSE 0.012431398463585364 Test RE 0.053292740509189356\n",
      "52 Train Loss 0.030439872 Test MSE 0.01062693377350998 Test RE 0.04927334514414824\n",
      "53 Train Loss 0.026870186 Test MSE 0.009399959219164467 Test RE 0.0463416022143285\n",
      "54 Train Loss 0.023375954 Test MSE 0.007634583814665548 Test RE 0.04176387083352362\n",
      "55 Train Loss 0.021933598 Test MSE 0.006876138668749551 Test RE 0.039635137892779844\n",
      "56 Train Loss 0.019821309 Test MSE 0.006446917650630411 Test RE 0.038378157576187275\n",
      "57 Train Loss 0.01735863 Test MSE 0.005624996977014382 Test RE 0.0358483529614553\n",
      "58 Train Loss 0.015774215 Test MSE 0.004941673129971879 Test RE 0.03360044800036984\n",
      "59 Train Loss 0.014272039 Test MSE 0.00394818448879219 Test RE 0.030033557601859905\n",
      "60 Train Loss 0.012887396 Test MSE 0.003867882559317756 Test RE 0.029726563073299347\n",
      "61 Train Loss 0.011838124 Test MSE 0.003459663147476866 Test RE 0.028114150671831258\n",
      "62 Train Loss 0.0109063815 Test MSE 0.003213734516335191 Test RE 0.027096491348775797\n",
      "63 Train Loss 0.009941465 Test MSE 0.0024197810777223834 Test RE 0.02351235327523254\n",
      "64 Train Loss 0.009661029 Test MSE 0.0022063674428867376 Test RE 0.022451583680245447\n",
      "65 Train Loss 0.008963389 Test MSE 0.0020665279059754573 Test RE 0.021728447519065636\n",
      "66 Train Loss 0.008204445 Test MSE 0.0018984540669515163 Test RE 0.02082610756767574\n",
      "67 Train Loss 0.007875275 Test MSE 0.0018137994530369366 Test RE 0.020356480502292457\n",
      "68 Train Loss 0.0074003455 Test MSE 0.0017034566647371777 Test RE 0.01972757054888903\n",
      "69 Train Loss 0.006727194 Test MSE 0.0017966276758954367 Test RE 0.020259890930204378\n",
      "70 Train Loss 0.0064350995 Test MSE 0.0018245430802480732 Test RE 0.020416679973242535\n",
      "71 Train Loss 0.006128643 Test MSE 0.0016634718757363015 Test RE 0.019494665674316868\n",
      "72 Train Loss 0.00584286 Test MSE 0.001476594939988107 Test RE 0.018367022085037894\n",
      "73 Train Loss 0.005591246 Test MSE 0.001411909095816327 Test RE 0.017960210742361375\n",
      "74 Train Loss 0.0050858604 Test MSE 0.0013394981322331298 Test RE 0.01749359695989009\n",
      "75 Train Loss 0.0047212048 Test MSE 0.0011046299375927304 Test RE 0.01588606974497601\n",
      "76 Train Loss 0.004475103 Test MSE 0.0010271943049509416 Test RE 0.015319139173331903\n",
      "77 Train Loss 0.0040868563 Test MSE 0.0010353016079674335 Test RE 0.015379474790346523\n",
      "78 Train Loss 0.0036178452 Test MSE 0.0008392048015736256 Test RE 0.013846564730972353\n",
      "79 Train Loss 0.0034871232 Test MSE 0.0008477269038571055 Test RE 0.013916692890282793\n",
      "80 Train Loss 0.0033385677 Test MSE 0.0007885150678625842 Test RE 0.013421870945461437\n",
      "81 Train Loss 0.0031538722 Test MSE 0.000761555244513838 Test RE 0.013190424332703225\n",
      "82 Train Loss 0.002896494 Test MSE 0.0007621090171252143 Test RE 0.01319521923653886\n",
      "83 Train Loss 0.0026318973 Test MSE 0.0006925312889173686 Test RE 0.012578468317106309\n",
      "84 Train Loss 0.0025508527 Test MSE 0.0006960027506678222 Test RE 0.012609955044257682\n",
      "85 Train Loss 0.0024579698 Test MSE 0.0007060110608317582 Test RE 0.012700295117609294\n",
      "86 Train Loss 0.0023532768 Test MSE 0.0007984564348264333 Test RE 0.013506215438820557\n",
      "87 Train Loss 0.0021973134 Test MSE 0.0008937327707227583 Test RE 0.014289331170473388\n",
      "88 Train Loss 0.0020808147 Test MSE 0.0008931541175080024 Test RE 0.014284704560312287\n",
      "89 Train Loss 0.001962024 Test MSE 0.0008550933830329839 Test RE 0.013977027934606376\n",
      "90 Train Loss 0.0019229153 Test MSE 0.0008332339570317016 Test RE 0.013797218452359088\n",
      "91 Train Loss 0.001864225 Test MSE 0.0007803346421265101 Test RE 0.01335206703159896\n",
      "92 Train Loss 0.0017762253 Test MSE 0.0007203334911796388 Test RE 0.012828470030627072\n",
      "93 Train Loss 0.0016274696 Test MSE 0.0007218359879111319 Test RE 0.012841842096494702\n",
      "94 Train Loss 0.0015777659 Test MSE 0.0007014573423607838 Test RE 0.01265927088357991\n",
      "95 Train Loss 0.0015592254 Test MSE 0.0006582476726104355 Test RE 0.012263169368035932\n",
      "96 Train Loss 0.0015323212 Test MSE 0.0006665136607392736 Test RE 0.012339926922855796\n",
      "97 Train Loss 0.0014845572 Test MSE 0.0007019187612857206 Test RE 0.012663433835861044\n",
      "98 Train Loss 0.0014059722 Test MSE 0.0006765476156918365 Test RE 0.012432464969033474\n",
      "99 Train Loss 0.0012687219 Test MSE 0.0005381821003760928 Test RE 0.011088497041074478\n",
      "Training time: 82.70\n",
      "3\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.579575 Test MSE 8.569108240035932 Test RE 1.3991873646360096\n",
      "1 Train Loss 56.02688 Test MSE 8.609073843333087 Test RE 1.4024464154252605\n",
      "2 Train Loss 53.648212 Test MSE 8.779072045790132 Test RE 1.416225359679325\n",
      "3 Train Loss 46.62818 Test MSE 8.999087626157426 Test RE 1.4338618194654718\n",
      "4 Train Loss 43.45305 Test MSE 8.627532904327136 Test RE 1.403949131191183\n",
      "5 Train Loss 41.582882 Test MSE 8.6163106677919 Test RE 1.4030357428444689\n",
      "6 Train Loss 40.19735 Test MSE 8.951725104895276 Test RE 1.4300836085751796\n",
      "7 Train Loss 38.978638 Test MSE 9.28604211940354 Test RE 1.4565432498665312\n",
      "8 Train Loss 37.628235 Test MSE 9.069160356881918 Test RE 1.439433483228917\n",
      "9 Train Loss 36.220352 Test MSE 8.761283720239675 Test RE 1.4147898405359365\n",
      "10 Train Loss 32.453545 Test MSE 9.04805098317848 Test RE 1.4377572949120343\n",
      "11 Train Loss 28.292559 Test MSE 8.845270756196268 Test RE 1.4215548648978509\n",
      "12 Train Loss 23.978752 Test MSE 8.580257001739765 Test RE 1.4000972688854596\n",
      "13 Train Loss 20.806623 Test MSE 9.264965920173402 Test RE 1.4548893787185233\n",
      "14 Train Loss 18.531334 Test MSE 8.525087075140338 Test RE 1.3955887891074086\n",
      "15 Train Loss 16.951302 Test MSE 8.180962627086485 Test RE 1.3671314202045588\n",
      "16 Train Loss 15.325439 Test MSE 7.771842713808857 Test RE 1.3325087258934563\n",
      "17 Train Loss 14.0635805 Test MSE 7.586559252157173 Test RE 1.3165291736908722\n",
      "18 Train Loss 12.733349 Test MSE 6.8513064493141655 Test RE 1.2511078727380638\n",
      "19 Train Loss 10.230523 Test MSE 6.070697657394783 Test RE 1.1776801696943673\n",
      "20 Train Loss 8.631506 Test MSE 6.153124011567082 Test RE 1.1856483310318326\n",
      "21 Train Loss 7.5595717 Test MSE 6.141387728657703 Test RE 1.1845170564251615\n",
      "22 Train Loss 6.9831753 Test MSE 6.060967175438728 Test RE 1.1767359626258065\n",
      "23 Train Loss 6.618001 Test MSE 6.055795771441064 Test RE 1.1762338418011085\n",
      "24 Train Loss 6.3065853 Test MSE 6.09977065456158 Test RE 1.1804967979600047\n",
      "25 Train Loss 5.9618273 Test MSE 6.263173527214807 Test RE 1.1962040885942715\n",
      "26 Train Loss 5.795721 Test MSE 6.256586642574247 Test RE 1.1955749082739366\n",
      "27 Train Loss 5.615983 Test MSE 6.367967181648432 Test RE 1.2061698502956002\n",
      "28 Train Loss 5.4418693 Test MSE 6.432352183726055 Test RE 1.2122521630412453\n",
      "29 Train Loss 5.2085238 Test MSE 6.283949643926989 Test RE 1.1981864622012826\n",
      "30 Train Loss 4.945565 Test MSE 6.272764076410828 Test RE 1.1971195881982357\n",
      "31 Train Loss 4.691661 Test MSE 6.221421782136111 Test RE 1.1922103368312493\n",
      "32 Train Loss 4.448517 Test MSE 6.216321668833589 Test RE 1.1917215695806942\n",
      "33 Train Loss 4.0566087 Test MSE 6.1395971358443235 Test RE 1.184344363994357\n",
      "34 Train Loss 3.6703315 Test MSE 6.032324633591963 Test RE 1.173952197069254\n",
      "35 Train Loss 3.370678 Test MSE 5.910601868574219 Test RE 1.162047588197592\n",
      "36 Train Loss 3.0859914 Test MSE 5.865942165259617 Test RE 1.1576491271865836\n",
      "37 Train Loss 2.650682 Test MSE 5.877659618247388 Test RE 1.158804775468884\n",
      "38 Train Loss 2.355808 Test MSE 5.840867564538 Test RE 1.1551722295555256\n",
      "39 Train Loss 2.0558476 Test MSE 5.727154199571534 Test RE 1.1438721820053215\n",
      "40 Train Loss 1.834782 Test MSE 5.681379908045918 Test RE 1.1392918111245192\n",
      "41 Train Loss 1.6363237 Test MSE 5.651372466592343 Test RE 1.1362791192868387\n",
      "42 Train Loss 1.4741343 Test MSE 5.559842284173659 Test RE 1.1270399128038477\n",
      "43 Train Loss 1.3424726 Test MSE 5.663156418676991 Test RE 1.137463157861675\n",
      "44 Train Loss 1.2554859 Test MSE 5.673097052095461 Test RE 1.1384610242374544\n",
      "45 Train Loss 1.181926 Test MSE 5.691403424903219 Test RE 1.1402963802978179\n",
      "46 Train Loss 1.1282103 Test MSE 5.714439284854875 Test RE 1.1426017151940269\n",
      "47 Train Loss 1.07995 Test MSE 5.710754017139689 Test RE 1.14223322126914\n",
      "48 Train Loss 1.0542233 Test MSE 5.697008240621916 Test RE 1.1408577162192193\n",
      "49 Train Loss 1.0282203 Test MSE 5.708725112105275 Test RE 1.1420302980999437\n",
      "50 Train Loss 0.99711066 Test MSE 5.742179403072353 Test RE 1.1453716749472407\n",
      "51 Train Loss 0.97751564 Test MSE 5.8026772193603815 Test RE 1.1513895058489003\n",
      "52 Train Loss 0.9567665 Test MSE 5.834018778413929 Test RE 1.1544947747081613\n",
      "53 Train Loss 0.9426323 Test MSE 5.8672687112095145 Test RE 1.1577800173238224\n",
      "54 Train Loss 0.9301372 Test MSE 5.901852180175904 Test RE 1.1611871580613027\n",
      "55 Train Loss 0.9159958 Test MSE 5.922641638242492 Test RE 1.1632305191520858\n",
      "56 Train Loss 0.9040279 Test MSE 5.906153749507536 Test RE 1.1616102470431506\n",
      "57 Train Loss 0.891513 Test MSE 5.93130895144316 Test RE 1.1640813554819862\n",
      "58 Train Loss 0.87892 Test MSE 5.969990897061328 Test RE 1.1678710547457538\n",
      "59 Train Loss 0.86609924 Test MSE 5.987318303039816 Test RE 1.169564651441064\n",
      "60 Train Loss 0.85596925 Test MSE 6.008897779427571 Test RE 1.1716704266125493\n",
      "61 Train Loss 0.84846795 Test MSE 6.026130896748256 Test RE 1.1733493599538636\n",
      "62 Train Loss 0.84160423 Test MSE 6.007008989054291 Test RE 1.1714862652373301\n",
      "63 Train Loss 0.8362778 Test MSE 6.028133266026034 Test RE 1.1735442846585635\n",
      "64 Train Loss 0.8319814 Test MSE 6.027147490725323 Test RE 1.1734483264060143\n",
      "65 Train Loss 0.8239255 Test MSE 6.0516828698926854 Test RE 1.1758343438772043\n",
      "66 Train Loss 0.817034 Test MSE 6.0691983292512806 Test RE 1.1775347302276373\n",
      "67 Train Loss 0.8092113 Test MSE 6.064839234587841 Test RE 1.1771117824938322\n",
      "68 Train Loss 0.80203706 Test MSE 6.087483948385042 Test RE 1.179307267278332\n",
      "69 Train Loss 0.7982219 Test MSE 6.083190638452517 Test RE 1.1788913298665342\n",
      "70 Train Loss 0.79348207 Test MSE 6.089775377790538 Test RE 1.1795292017527057\n",
      "71 Train Loss 0.7886086 Test MSE 6.096804693106813 Test RE 1.1802097598136274\n",
      "72 Train Loss 0.78352594 Test MSE 6.100042287252973 Test RE 1.1805230823869735\n",
      "73 Train Loss 0.77886647 Test MSE 6.115875288098197 Test RE 1.1820541463753609\n",
      "74 Train Loss 0.7748508 Test MSE 6.131626492266046 Test RE 1.1835753353095315\n",
      "75 Train Loss 0.7706567 Test MSE 6.123254232237567 Test RE 1.1827670191673698\n",
      "76 Train Loss 0.76632595 Test MSE 6.132058868663114 Test RE 1.1836170649402\n",
      "77 Train Loss 0.76097274 Test MSE 6.162375084803864 Test RE 1.1865392930775451\n",
      "78 Train Loss 0.7574812 Test MSE 6.156565446747807 Test RE 1.1859798505574404\n",
      "79 Train Loss 0.7530203 Test MSE 6.164391312576589 Test RE 1.1867333852735065\n",
      "80 Train Loss 0.7492441 Test MSE 6.162052179692747 Test RE 1.186508205662692\n",
      "81 Train Loss 0.7458906 Test MSE 6.163721364309589 Test RE 1.1866688962155205\n",
      "82 Train Loss 0.7420612 Test MSE 6.169700187522129 Test RE 1.1872442924286077\n",
      "83 Train Loss 0.73825216 Test MSE 6.1868752144056085 Test RE 1.1888956515552416\n",
      "84 Train Loss 0.73455244 Test MSE 6.196179300964797 Test RE 1.1897892716842209\n",
      "85 Train Loss 0.7310868 Test MSE 6.210403592770217 Test RE 1.1911541618231907\n",
      "86 Train Loss 0.7268405 Test MSE 6.229964771285663 Test RE 1.1930286020374787\n",
      "87 Train Loss 0.7233423 Test MSE 6.243491166076415 Test RE 1.1943230416255228\n",
      "88 Train Loss 0.7191521 Test MSE 6.250551820407122 Test RE 1.1949981702659223\n",
      "89 Train Loss 0.71343964 Test MSE 6.275378397764146 Test RE 1.1973690260251992\n",
      "90 Train Loss 0.7104323 Test MSE 6.282869218038204 Test RE 1.1980834531547497\n",
      "91 Train Loss 0.70685846 Test MSE 6.285945213630554 Test RE 1.1983766988309903\n",
      "92 Train Loss 0.7020244 Test MSE 6.291739640710059 Test RE 1.1989289075013898\n",
      "93 Train Loss 0.6986856 Test MSE 6.306283142931185 Test RE 1.200313783669379\n",
      "94 Train Loss 0.696217 Test MSE 6.328945533584063 Test RE 1.2024685858458584\n",
      "95 Train Loss 0.69238114 Test MSE 6.328057697661184 Test RE 1.2023842406540217\n",
      "96 Train Loss 0.6907027 Test MSE 6.335647123701514 Test RE 1.2031050520190347\n",
      "97 Train Loss 0.6876004 Test MSE 6.359548456264884 Test RE 1.2053722824997664\n",
      "98 Train Loss 0.6849719 Test MSE 6.33789556769649 Test RE 1.2033185167461786\n",
      "99 Train Loss 0.6828912 Test MSE 6.352457661566065 Test RE 1.2047001096848238\n",
      "Training time: 83.66\n",
      "4\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.59052 Test MSE 8.325553720978471 Test RE 1.3791599087300561\n",
      "1 Train Loss 56.346107 Test MSE 8.574171739392865 Test RE 1.3996006945782407\n",
      "2 Train Loss 52.882935 Test MSE 9.363569313617742 Test RE 1.4626107972066316\n",
      "3 Train Loss 46.968987 Test MSE 8.061750698964042 Test RE 1.357134035383456\n",
      "4 Train Loss 44.697433 Test MSE 8.207209066228835 Test RE 1.3693227025513035\n",
      "5 Train Loss 44.221672 Test MSE 8.108585797050308 Test RE 1.361070491580996\n",
      "6 Train Loss 43.83184 Test MSE 8.29105089524748 Test RE 1.3762991790748313\n",
      "7 Train Loss 43.573715 Test MSE 8.251952480276005 Test RE 1.3730502117906254\n",
      "8 Train Loss 43.187218 Test MSE 8.274999195608393 Test RE 1.3749662573301773\n",
      "9 Train Loss 41.886616 Test MSE 8.021078985737784 Test RE 1.35370632085776\n",
      "10 Train Loss 40.02037 Test MSE 7.866281551314453 Test RE 1.3405802090508956\n",
      "11 Train Loss 37.23157 Test MSE 6.297557490651787 Test RE 1.1994830926045947\n",
      "12 Train Loss 27.699587 Test MSE 5.947253363692683 Test RE 1.1656449341431352\n",
      "13 Train Loss 20.316936 Test MSE 5.281917446435085 Test RE 1.0985096208013516\n",
      "14 Train Loss 17.068531 Test MSE 5.651758571316181 Test RE 1.1363179342158636\n",
      "15 Train Loss 14.868084 Test MSE 5.893743465266675 Test RE 1.160389190602041\n",
      "16 Train Loss 12.586812 Test MSE 5.7998035693810115 Test RE 1.151104370208455\n",
      "17 Train Loss 10.7703285 Test MSE 5.669674068158142 Test RE 1.1381175150602498\n",
      "18 Train Loss 9.524391 Test MSE 5.6198477546583145 Test RE 1.1331054684351487\n",
      "19 Train Loss 8.6791115 Test MSE 5.461135799934947 Test RE 1.1169906771365647\n",
      "20 Train Loss 7.910655 Test MSE 5.248301829341017 Test RE 1.095008428245265\n",
      "21 Train Loss 7.4175615 Test MSE 5.1150494573633 Test RE 1.0810181330939497\n",
      "22 Train Loss 6.996896 Test MSE 4.9614465860068355 Test RE 1.064663144596767\n",
      "23 Train Loss 6.352733 Test MSE 4.556899670797576 Test RE 1.0203350221285203\n",
      "24 Train Loss 5.585765 Test MSE 4.17785484018503 Test RE 0.9769778858012199\n",
      "25 Train Loss 4.76064 Test MSE 4.000311316702244 Test RE 0.9559935357699927\n",
      "26 Train Loss 4.069791 Test MSE 3.92667751206409 Test RE 0.9471541748972849\n",
      "27 Train Loss 3.5513508 Test MSE 3.7410840525218885 Test RE 0.9244997396074653\n",
      "28 Train Loss 2.8644052 Test MSE 3.205583797420339 Test RE 0.8557790045726177\n",
      "29 Train Loss 2.4775586 Test MSE 3.0214611410970558 Test RE 0.8308384117755809\n",
      "30 Train Loss 2.2088814 Test MSE 2.8258149927583163 Test RE 0.8034889764354256\n",
      "31 Train Loss 1.8764375 Test MSE 2.4083379881805627 Test RE 0.7417657531168823\n",
      "32 Train Loss 1.6646848 Test MSE 2.1918321972900343 Test RE 0.7076389206799539\n",
      "33 Train Loss 1.4942751 Test MSE 2.0739715420283034 Test RE 0.688350221887555\n",
      "34 Train Loss 1.3560796 Test MSE 1.9814339257825326 Test RE 0.6728183964591556\n",
      "35 Train Loss 1.2451043 Test MSE 1.93065163013785 Test RE 0.6641405818443089\n",
      "36 Train Loss 1.1538469 Test MSE 1.7977449172103743 Test RE 0.6408731769628445\n",
      "37 Train Loss 1.0780209 Test MSE 1.7224783666080008 Test RE 0.6273139543242494\n",
      "38 Train Loss 1.0278828 Test MSE 1.6880885317244536 Test RE 0.6210201188417663\n",
      "39 Train Loss 0.9624627 Test MSE 1.5951713250188788 Test RE 0.6036868660350955\n",
      "40 Train Loss 0.8550418 Test MSE 1.365147717235132 Test RE 0.5584674735761076\n",
      "41 Train Loss 0.7028508 Test MSE 1.2496770226763176 Test RE 0.5343267940637448\n",
      "42 Train Loss 0.5619946 Test MSE 1.106024754764573 Test RE 0.5026787007997456\n",
      "43 Train Loss 0.44694814 Test MSE 1.0242991644801092 Test RE 0.48375054745293844\n",
      "44 Train Loss 0.36428952 Test MSE 0.9506723878995752 Test RE 0.46604032916089616\n",
      "45 Train Loss 0.30695385 Test MSE 0.8955606427876215 Test RE 0.4523301743978991\n",
      "46 Train Loss 0.2572065 Test MSE 0.822209031064813 Test RE 0.43341025361498114\n",
      "47 Train Loss 0.22459926 Test MSE 0.7734486425212639 Test RE 0.42036234013066076\n",
      "48 Train Loss 0.19687471 Test MSE 0.7368800819105117 Test RE 0.4103046785250507\n",
      "49 Train Loss 0.16591877 Test MSE 0.6708180429029489 Test RE 0.3914807646347339\n",
      "50 Train Loss 0.15025365 Test MSE 0.6451118526545542 Test RE 0.3839065933529693\n",
      "51 Train Loss 0.13509409 Test MSE 0.6320330727862591 Test RE 0.37999507029370594\n",
      "52 Train Loss 0.12537865 Test MSE 0.6186242029751037 Test RE 0.37594257685709626\n",
      "53 Train Loss 0.11586587 Test MSE 0.6005536833316912 Test RE 0.3704110873520871\n",
      "54 Train Loss 0.109313585 Test MSE 0.5988467288476839 Test RE 0.36988430281759577\n",
      "55 Train Loss 0.1012505 Test MSE 0.5658322140842377 Test RE 0.35954387510456165\n",
      "56 Train Loss 0.09469141 Test MSE 0.5393171249094533 Test RE 0.3510186289733265\n",
      "57 Train Loss 0.09002424 Test MSE 0.5391827856125837 Test RE 0.3509749083769405\n",
      "58 Train Loss 0.08499552 Test MSE 0.51838897743509 Test RE 0.34414062217341634\n",
      "59 Train Loss 0.08303199 Test MSE 0.5052341518659902 Test RE 0.3397460451849127\n",
      "60 Train Loss 0.0795011 Test MSE 0.4964410621180408 Test RE 0.33677660016885536\n",
      "61 Train Loss 0.07638295 Test MSE 0.48032599331415166 Test RE 0.331265421343853\n",
      "62 Train Loss 0.07181537 Test MSE 0.47139286495603727 Test RE 0.3281705180566408\n",
      "63 Train Loss 0.06897268 Test MSE 0.4651171859868104 Test RE 0.32597872272217815\n",
      "64 Train Loss 0.06680915 Test MSE 0.4542656965994933 Test RE 0.32215363174690564\n",
      "65 Train Loss 0.064947076 Test MSE 0.4479555897404929 Test RE 0.3199083238840723\n",
      "66 Train Loss 0.06312628 Test MSE 0.4428966793727034 Test RE 0.318096779610078\n",
      "67 Train Loss 0.06020485 Test MSE 0.4348304717101714 Test RE 0.3151868178659503\n",
      "68 Train Loss 0.058153953 Test MSE 0.4310558668259321 Test RE 0.3138158251488095\n",
      "69 Train Loss 0.056436375 Test MSE 0.4215686595262253 Test RE 0.31034318914478554\n",
      "70 Train Loss 0.054730296 Test MSE 0.4193008418295936 Test RE 0.3095073219191365\n",
      "71 Train Loss 0.05373606 Test MSE 0.4257910049857208 Test RE 0.3118934839075676\n",
      "72 Train Loss 0.052484937 Test MSE 0.4156756531717641 Test RE 0.3081664491432044\n",
      "73 Train Loss 0.051333517 Test MSE 0.4086287085915608 Test RE 0.3055431121278422\n",
      "74 Train Loss 0.049717806 Test MSE 0.3915057955769654 Test RE 0.29907296615317885\n",
      "75 Train Loss 0.048322227 Test MSE 0.3880328503996846 Test RE 0.2977435123752882\n",
      "76 Train Loss 0.046816457 Test MSE 0.38145802260708567 Test RE 0.2952102529238514\n",
      "77 Train Loss 0.045380935 Test MSE 0.36809191892689885 Test RE 0.2899921232756095\n",
      "78 Train Loss 0.043437216 Test MSE 0.3450428089777053 Test RE 0.280766023197204\n",
      "79 Train Loss 0.042023446 Test MSE 0.32691862796789883 Test RE 0.2732926136537561\n",
      "80 Train Loss 0.0406259 Test MSE 0.3153483019648949 Test RE 0.2684128532603673\n",
      "81 Train Loss 0.038088173 Test MSE 0.30066082331949523 Test RE 0.26208760456525515\n",
      "82 Train Loss 0.035941184 Test MSE 0.2804725774363825 Test RE 0.2531356210473814\n",
      "83 Train Loss 0.034400273 Test MSE 0.2788547867658544 Test RE 0.25240451090336924\n",
      "84 Train Loss 0.033203654 Test MSE 0.2704190276689283 Test RE 0.24855739217632977\n",
      "85 Train Loss 0.03255158 Test MSE 0.26606237449572456 Test RE 0.2465470393039221\n",
      "86 Train Loss 0.03176757 Test MSE 0.2678080545160219 Test RE 0.24735453525096268\n",
      "87 Train Loss 0.03123169 Test MSE 0.26353696183862474 Test RE 0.2453741610517362\n",
      "88 Train Loss 0.030443342 Test MSE 0.2563233874519237 Test RE 0.2419926509960586\n",
      "89 Train Loss 0.029834367 Test MSE 0.25363171400913526 Test RE 0.24071870512921006\n",
      "90 Train Loss 0.029190391 Test MSE 0.25136223629223164 Test RE 0.23963931859913523\n",
      "91 Train Loss 0.028546305 Test MSE 0.25492368293792134 Test RE 0.24133102217315477\n",
      "92 Train Loss 0.028074026 Test MSE 0.2473120380815647 Test RE 0.23770082469846845\n",
      "93 Train Loss 0.027606176 Test MSE 0.24731461662796322 Test RE 0.2377020638638009\n",
      "94 Train Loss 0.027162135 Test MSE 0.2392985247661233 Test RE 0.2338180697378\n",
      "95 Train Loss 0.026769746 Test MSE 0.23752979885900097 Test RE 0.2329523579636098\n",
      "96 Train Loss 0.02637387 Test MSE 0.23343344256798543 Test RE 0.23093491443481293\n",
      "97 Train Loss 0.026089601 Test MSE 0.23193550567829752 Test RE 0.23019276999101085\n",
      "98 Train Loss 0.025831208 Test MSE 0.2293670289188217 Test RE 0.22891463281946664\n",
      "99 Train Loss 0.025497971 Test MSE 0.2294635445228593 Test RE 0.22896279037382491\n",
      "Training time: 81.60\n",
      "5\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.865417 Test MSE 8.657874720555562 Test RE 1.4064157099691101\n",
      "1 Train Loss 57.712563 Test MSE 8.609255123341898 Test RE 1.4024611809020606\n",
      "2 Train Loss 57.593 Test MSE 8.71385715762235 Test RE 1.4109553756196136\n",
      "3 Train Loss 56.909645 Test MSE 8.982653976936279 Test RE 1.4325520005914936\n",
      "4 Train Loss 49.495842 Test MSE 8.206626925040723 Test RE 1.3692741383393772\n",
      "5 Train Loss 44.737194 Test MSE 8.327388451499921 Test RE 1.3793118654329481\n",
      "6 Train Loss 44.187775 Test MSE 8.452399228805426 Test RE 1.3896264157922087\n",
      "7 Train Loss 43.7182 Test MSE 8.132627133064581 Test RE 1.3630867330819312\n",
      "8 Train Loss 43.362946 Test MSE 8.296857031315238 Test RE 1.3767809986833643\n",
      "9 Train Loss 42.84308 Test MSE 8.182332725311456 Test RE 1.367245894869706\n",
      "10 Train Loss 42.473953 Test MSE 8.426402114352614 Test RE 1.3874877272806192\n",
      "11 Train Loss 42.039864 Test MSE 8.87400127640048 Test RE 1.4238616851572108\n",
      "12 Train Loss 41.507645 Test MSE 8.819741736040593 Test RE 1.4195019528304227\n",
      "13 Train Loss 40.94178 Test MSE 8.912459533416675 Test RE 1.4269437242557887\n",
      "14 Train Loss 40.43588 Test MSE 8.880601373513285 Test RE 1.4243910900089563\n",
      "15 Train Loss 39.63343 Test MSE 8.764941075381948 Test RE 1.4150851082826825\n",
      "16 Train Loss 38.931015 Test MSE 8.353069039200708 Test RE 1.3814370378504757\n",
      "17 Train Loss 37.9886 Test MSE 8.565540932658385 Test RE 1.398896094480016\n",
      "18 Train Loss 36.78189 Test MSE 8.60295210842951 Test RE 1.401947701388362\n",
      "19 Train Loss 35.238556 Test MSE 7.765525861647342 Test RE 1.3319670929763545\n",
      "20 Train Loss 32.65391 Test MSE 7.109967726304996 Test RE 1.2745059724938936\n",
      "21 Train Loss 29.064129 Test MSE 6.928079826729978 Test RE 1.2580980865005567\n",
      "22 Train Loss 24.506947 Test MSE 6.482952453755042 Test RE 1.2170109296213525\n",
      "23 Train Loss 22.112783 Test MSE 6.042880278313781 Test RE 1.1749788664591412\n",
      "24 Train Loss 18.553904 Test MSE 5.476055579391481 Test RE 1.1185154412473721\n",
      "25 Train Loss 13.765362 Test MSE 4.690660709723616 Test RE 1.0352019237206254\n",
      "26 Train Loss 9.952256 Test MSE 3.0522925639652065 Test RE 0.8350666499280792\n",
      "27 Train Loss 7.7723546 Test MSE 2.693158249170237 Test RE 0.7844025500523538\n",
      "28 Train Loss 6.409166 Test MSE 2.4479456231775756 Test RE 0.7478404353344495\n",
      "29 Train Loss 4.0555077 Test MSE 1.2651316043758634 Test RE 0.5376206143248993\n",
      "30 Train Loss 2.3581169 Test MSE 0.9611893949093206 Test RE 0.468611071928181\n",
      "31 Train Loss 1.7466944 Test MSE 0.6599519535222702 Test RE 0.38829716493810146\n",
      "32 Train Loss 0.980213 Test MSE 0.2628862692663224 Test RE 0.2450710502094253\n",
      "33 Train Loss 0.6285748 Test MSE 0.1525642099701326 Test RE 0.18669573317285\n",
      "34 Train Loss 0.41857308 Test MSE 0.07797108662367458 Test RE 0.13346729345601285\n",
      "35 Train Loss 0.32927388 Test MSE 0.06684195302756157 Test RE 0.12357557095930478\n",
      "36 Train Loss 0.25244474 Test MSE 0.06136084121317558 Test RE 0.11840054806605206\n",
      "37 Train Loss 0.21292451 Test MSE 0.05555107301721964 Test RE 0.11265598946111015\n",
      "38 Train Loss 0.19145979 Test MSE 0.04898849947052919 Test RE 0.10579256058256933\n",
      "39 Train Loss 0.14155173 Test MSE 0.02371222012525539 Test RE 0.07360277172515943\n",
      "40 Train Loss 0.10503166 Test MSE 0.016615959241259255 Test RE 0.06161277497229024\n",
      "41 Train Loss 0.09374644 Test MSE 0.015310091705828241 Test RE 0.05914212928671857\n",
      "42 Train Loss 0.08508535 Test MSE 0.014052912765934157 Test RE 0.05666191333013155\n",
      "43 Train Loss 0.075478345 Test MSE 0.014333502881138173 Test RE 0.057224792860442505\n",
      "44 Train Loss 0.06629051 Test MSE 0.010892520089265575 Test RE 0.04988526057278363\n",
      "45 Train Loss 0.061365347 Test MSE 0.009895230294065456 Test RE 0.047546769346316665\n",
      "46 Train Loss 0.05009386 Test MSE 0.00872382461191326 Test RE 0.04464383795985138\n",
      "47 Train Loss 0.046862017 Test MSE 0.009083539778969297 Test RE 0.045554954948984344\n",
      "48 Train Loss 0.042513892 Test MSE 0.008989035078716574 Test RE 0.0453173595973768\n",
      "49 Train Loss 0.039115485 Test MSE 0.008055797560420946 Test RE 0.04290049786817384\n",
      "50 Train Loss 0.03264974 Test MSE 0.0070867963178298755 Test RE 0.040237689563874995\n",
      "51 Train Loss 0.030171182 Test MSE 0.006866327546307544 Test RE 0.039606851377602025\n",
      "52 Train Loss 0.026017522 Test MSE 0.005184410075113003 Test RE 0.034415789222959826\n",
      "53 Train Loss 0.024523504 Test MSE 0.004600169104150584 Test RE 0.03241865246299407\n",
      "54 Train Loss 0.021502288 Test MSE 0.0031849148482015776 Test RE 0.026974721719702735\n",
      "55 Train Loss 0.020331092 Test MSE 0.003212261326115553 Test RE 0.027090280060698402\n",
      "56 Train Loss 0.018459303 Test MSE 0.0032572268064194557 Test RE 0.02727922704357309\n",
      "57 Train Loss 0.016703969 Test MSE 0.0023982727127821336 Test RE 0.023407624573740224\n",
      "58 Train Loss 0.016131695 Test MSE 0.002257928335629074 Test RE 0.022712405699124118\n",
      "59 Train Loss 0.014069516 Test MSE 0.0024230748656751946 Test RE 0.023528350253286742\n",
      "60 Train Loss 0.013304611 Test MSE 0.00241073175565007 Test RE 0.02346834719581387\n",
      "61 Train Loss 0.012816359 Test MSE 0.0026647689617021403 Test RE 0.02467390230756511\n",
      "62 Train Loss 0.012125997 Test MSE 0.0028765201427797386 Test RE 0.025635498678280882\n",
      "63 Train Loss 0.011652479 Test MSE 0.003025955141590477 Test RE 0.026292949243024756\n",
      "64 Train Loss 0.010936431 Test MSE 0.0027413100840389458 Test RE 0.025025752324163753\n",
      "65 Train Loss 0.010385102 Test MSE 0.002562743565573291 Test RE 0.024196950507140963\n",
      "66 Train Loss 0.009384175 Test MSE 0.0024260124817107845 Test RE 0.023542608236825913\n",
      "67 Train Loss 0.00897349 Test MSE 0.002702098003449791 Test RE 0.02484612172480722\n",
      "68 Train Loss 0.008629249 Test MSE 0.002794902313595908 Test RE 0.025269193256724193\n",
      "69 Train Loss 0.0085021 Test MSE 0.0028715743844833705 Test RE 0.025613450940246574\n",
      "70 Train Loss 0.008100086 Test MSE 0.002956689676001662 Test RE 0.02599027846898558\n",
      "71 Train Loss 0.0075688655 Test MSE 0.0023867790766420134 Test RE 0.023351467108275573\n",
      "72 Train Loss 0.007048776 Test MSE 0.0019472594121207943 Test RE 0.02109210701400554\n",
      "73 Train Loss 0.006826316 Test MSE 0.0018508485893038123 Test RE 0.020563332902010754\n",
      "74 Train Loss 0.0060351407 Test MSE 0.00167605799941777 Test RE 0.01956827674967274\n",
      "75 Train Loss 0.0054523344 Test MSE 0.001572937794903564 Test RE 0.018956747884702124\n",
      "76 Train Loss 0.005173138 Test MSE 0.0014705659055385789 Test RE 0.018329486850346143\n",
      "77 Train Loss 0.0050489614 Test MSE 0.0013836242640643322 Test RE 0.017779401810646148\n",
      "78 Train Loss 0.004907459 Test MSE 0.0012927316575290346 Test RE 0.01718550317713566\n",
      "79 Train Loss 0.0046385573 Test MSE 0.0011916641133564582 Test RE 0.01650003975959338\n",
      "80 Train Loss 0.0042524654 Test MSE 0.0012183350405681789 Test RE 0.016683663732903236\n",
      "81 Train Loss 0.0040277196 Test MSE 0.0011776545945919301 Test RE 0.016402763595664994\n",
      "82 Train Loss 0.0039403024 Test MSE 0.0010510830228558775 Test RE 0.015496248457370165\n",
      "83 Train Loss 0.0038904953 Test MSE 0.0010053132003446567 Test RE 0.015155098131893821\n",
      "84 Train Loss 0.0038175234 Test MSE 0.0009464485440542068 Test RE 0.014704713387993232\n",
      "85 Train Loss 0.0037044915 Test MSE 0.000897654849123419 Test RE 0.014320650669683478\n",
      "86 Train Loss 0.0035293018 Test MSE 0.000790444377766032 Test RE 0.013438280985825403\n",
      "87 Train Loss 0.0033688357 Test MSE 0.000670567706689595 Test RE 0.012377398615395252\n",
      "88 Train Loss 0.0032027182 Test MSE 0.0006747146114441411 Test RE 0.01241561159670858\n",
      "89 Train Loss 0.0030367658 Test MSE 0.000732315251258769 Test RE 0.012934722019643111\n",
      "90 Train Loss 0.0029199938 Test MSE 0.0007041509618577347 Test RE 0.012683553604668286\n",
      "91 Train Loss 0.0028029701 Test MSE 0.000574776669559203 Test RE 0.01145928777936568\n",
      "92 Train Loss 0.002676982 Test MSE 0.0005642975135441217 Test RE 0.01135434611229172\n",
      "93 Train Loss 0.0025949997 Test MSE 0.0005571548516119609 Test RE 0.011282257785710322\n",
      "94 Train Loss 0.002508988 Test MSE 0.0005724702706006301 Test RE 0.011436273400347469\n",
      "95 Train Loss 0.0024117955 Test MSE 0.0005496632717356173 Test RE 0.01120614969395965\n",
      "96 Train Loss 0.0023577937 Test MSE 0.0005736088711960888 Test RE 0.01144764069763844\n",
      "97 Train Loss 0.0022974245 Test MSE 0.0005771059285561816 Test RE 0.011482483451285597\n",
      "98 Train Loss 0.0022634242 Test MSE 0.0005951756616389927 Test RE 0.011660861630666477\n",
      "99 Train Loss 0.002240419 Test MSE 0.0006332698836184409 Test RE 0.012028250875344846\n",
      "Training time: 82.22\n",
      "6\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.946716 Test MSE 8.576652771245719 Test RE 1.3998031749371673\n",
      "1 Train Loss 58.81513 Test MSE 8.54406759225452 Test RE 1.3971415163155247\n",
      "2 Train Loss 58.603382 Test MSE 8.575513846990905 Test RE 1.3997102294279387\n",
      "3 Train Loss 57.89164 Test MSE 9.342112835046489 Test RE 1.4609340607547834\n",
      "4 Train Loss 53.485825 Test MSE 8.996973575743239 Test RE 1.433693389378747\n",
      "5 Train Loss 52.00036 Test MSE 8.930897853091567 Test RE 1.4284190100945942\n",
      "6 Train Loss 51.019756 Test MSE 8.677707187978246 Test RE 1.4080256165323564\n",
      "7 Train Loss 49.033638 Test MSE 9.106408701959097 Test RE 1.4423864343882906\n",
      "8 Train Loss 47.048386 Test MSE 8.538930591895594 Test RE 1.3967214473318266\n",
      "9 Train Loss 46.621033 Test MSE 8.52270946300558 Test RE 1.3953941635159577\n",
      "10 Train Loss 46.47464 Test MSE 8.453635604962395 Test RE 1.389728045997833\n",
      "11 Train Loss 46.067078 Test MSE 8.334296607836936 Test RE 1.3798838650903107\n",
      "12 Train Loss 45.936028 Test MSE 8.402414667841848 Test RE 1.3855114385191816\n",
      "13 Train Loss 45.735985 Test MSE 8.427788388687643 Test RE 1.3876018542530804\n",
      "14 Train Loss 45.631134 Test MSE 8.301618194891406 Test RE 1.377175975924612\n",
      "15 Train Loss 45.280838 Test MSE 8.370333230868873 Test RE 1.382863883682505\n",
      "16 Train Loss 45.090485 Test MSE 8.381260377954437 Test RE 1.3837662270079427\n",
      "17 Train Loss 42.91752 Test MSE 8.576139412760377 Test RE 1.3997612814613463\n",
      "18 Train Loss 39.98047 Test MSE 7.634148591576338 Test RE 1.3206519127197995\n",
      "19 Train Loss 39.06923 Test MSE 7.304980582745767 Test RE 1.2918663713025973\n",
      "20 Train Loss 37.961075 Test MSE 7.264942405942646 Test RE 1.2883211843908264\n",
      "21 Train Loss 37.37234 Test MSE 7.273069818274998 Test RE 1.2890416161638838\n",
      "22 Train Loss 36.868805 Test MSE 7.282835471883752 Test RE 1.2899067330558038\n",
      "23 Train Loss 36.19228 Test MSE 7.252139544010609 Test RE 1.287185492558429\n",
      "24 Train Loss 35.462738 Test MSE 7.167561386711406 Test RE 1.279657572083361\n",
      "25 Train Loss 34.948635 Test MSE 7.030964915101307 Test RE 1.267405319727791\n",
      "26 Train Loss 34.771637 Test MSE 7.035201860164725 Test RE 1.2677871391526823\n",
      "27 Train Loss 34.519848 Test MSE 6.950738169916509 Test RE 1.2601537173055415\n",
      "28 Train Loss 34.159588 Test MSE 6.917395178520265 Test RE 1.2571275778909572\n",
      "29 Train Loss 33.753242 Test MSE 6.874111881225669 Test RE 1.2531883775235573\n",
      "30 Train Loss 33.492035 Test MSE 6.708867410759459 Test RE 1.2380342647865452\n",
      "31 Train Loss 33.281097 Test MSE 6.847033834868812 Test RE 1.250717703705324\n",
      "32 Train Loss 32.912094 Test MSE 6.725003804763453 Test RE 1.2395222514544373\n",
      "33 Train Loss 31.208868 Test MSE 6.946291751812499 Test RE 1.2597505898573889\n",
      "34 Train Loss 29.862226 Test MSE 6.927348750614444 Test RE 1.2580317052123378\n",
      "35 Train Loss 28.992985 Test MSE 6.830270508802718 Test RE 1.2491857237561665\n",
      "36 Train Loss 27.756363 Test MSE 6.4405487857147214 Test RE 1.213024290002377\n",
      "37 Train Loss 27.078632 Test MSE 6.59738627922486 Test RE 1.2277049778547866\n",
      "38 Train Loss 26.624504 Test MSE 6.39779270379631 Test RE 1.2089912075265135\n",
      "39 Train Loss 26.053936 Test MSE 6.421174568788763 Test RE 1.2111984287946869\n",
      "40 Train Loss 25.553453 Test MSE 6.339567641523341 Test RE 1.2034772369939715\n",
      "41 Train Loss 24.873842 Test MSE 6.1504862462092245 Test RE 1.1853941676722204\n",
      "42 Train Loss 24.466389 Test MSE 6.032421188028988 Test RE 1.173961592273159\n",
      "43 Train Loss 23.92783 Test MSE 6.062782132567055 Test RE 1.1769121362792734\n",
      "44 Train Loss 23.47949 Test MSE 5.9408453816121 Test RE 1.1650167916630103\n",
      "45 Train Loss 22.888262 Test MSE 6.008339338177576 Test RE 1.1716159803293447\n",
      "46 Train Loss 22.385925 Test MSE 5.945486875946169 Test RE 1.165471807971186\n",
      "47 Train Loss 21.86772 Test MSE 5.799664755503112 Test RE 1.1510905947231556\n",
      "48 Train Loss 21.256165 Test MSE 5.642873736485968 Test RE 1.135424409837373\n",
      "49 Train Loss 20.67396 Test MSE 5.597106093887219 Test RE 1.13081049323879\n",
      "50 Train Loss 19.971958 Test MSE 5.508144248339767 Test RE 1.1217878007994846\n",
      "51 Train Loss 18.638481 Test MSE 5.280707350201255 Test RE 1.0983837783858352\n",
      "52 Train Loss 17.601128 Test MSE 5.167862717369654 Test RE 1.086584597126372\n",
      "53 Train Loss 16.513123 Test MSE 4.849271149597498 Test RE 1.0525586255702648\n",
      "54 Train Loss 15.8327265 Test MSE 4.471708179228733 Test RE 1.0107524141217923\n",
      "55 Train Loss 14.802453 Test MSE 4.1073393399561615 Test RE 0.9686978876401667\n",
      "56 Train Loss 13.744185 Test MSE 3.9937937255747946 Test RE 0.9552144320368167\n",
      "57 Train Loss 12.945943 Test MSE 3.890131899876189 Test RE 0.9427362866216975\n",
      "58 Train Loss 11.698486 Test MSE 3.5496576216918236 Test RE 0.900536444110579\n",
      "59 Train Loss 10.69518 Test MSE 3.4796055925872893 Test RE 0.8916061806697498\n",
      "60 Train Loss 9.825155 Test MSE 3.5502330863774585 Test RE 0.9006094378997157\n",
      "61 Train Loss 9.275846 Test MSE 3.4970569092777684 Test RE 0.8938392270565081\n",
      "62 Train Loss 8.681064 Test MSE 3.55194075419892 Test RE 0.9008260091537352\n",
      "63 Train Loss 8.164789 Test MSE 3.4905538897489903 Test RE 0.8930077623601084\n",
      "64 Train Loss 7.3790293 Test MSE 3.476895317429178 Test RE 0.8912588756727159\n",
      "65 Train Loss 6.791738 Test MSE 3.3178336453097956 Test RE 0.87063347979916\n",
      "66 Train Loss 6.457139 Test MSE 3.2468356220208126 Test RE 0.8612678013213775\n",
      "67 Train Loss 5.976762 Test MSE 3.1898393477588276 Test RE 0.8536748083626855\n",
      "68 Train Loss 5.561893 Test MSE 3.1407396981521125 Test RE 0.8470792282015585\n",
      "69 Train Loss 5.3161683 Test MSE 3.2558595570920406 Test RE 0.8624638323056389\n",
      "70 Train Loss 5.0845237 Test MSE 3.2053123657482927 Test RE 0.8557427724136458\n",
      "71 Train Loss 4.878261 Test MSE 3.2214845453021392 Test RE 0.8578988514283022\n",
      "72 Train Loss 4.615957 Test MSE 3.1391190140583776 Test RE 0.8468606451426078\n",
      "73 Train Loss 4.2812333 Test MSE 3.047129774268053 Test RE 0.8343601157374823\n",
      "74 Train Loss 3.9962254 Test MSE 3.0103900368862893 Test RE 0.8293148541851673\n",
      "75 Train Loss 3.8279347 Test MSE 2.9092972536076416 Test RE 0.815271214862785\n",
      "76 Train Loss 3.6622477 Test MSE 3.0450677004652413 Test RE 0.8340777511121023\n",
      "77 Train Loss 3.485107 Test MSE 3.135194203370734 Test RE 0.8463310686491883\n",
      "78 Train Loss 3.2559922 Test MSE 3.1937634077921944 Test RE 0.8541997316007068\n",
      "79 Train Loss 3.1485977 Test MSE 3.192353896869782 Test RE 0.8540112178367502\n",
      "80 Train Loss 3.051218 Test MSE 3.2738999208303263 Test RE 0.8648499407316187\n",
      "81 Train Loss 2.8985565 Test MSE 3.114022039084006 Test RE 0.8434685642393467\n",
      "82 Train Loss 2.7699335 Test MSE 3.165722846564423 Test RE 0.8504416188718564\n",
      "83 Train Loss 2.6810744 Test MSE 3.133431371792786 Test RE 0.8460931011080628\n",
      "84 Train Loss 2.491373 Test MSE 3.0496439049829203 Test RE 0.8347042523572809\n",
      "85 Train Loss 2.404321 Test MSE 3.1547135443485548 Test RE 0.8489615583033857\n",
      "86 Train Loss 2.3089988 Test MSE 3.1986459394034252 Test RE 0.8548524199627203\n",
      "87 Train Loss 2.2342982 Test MSE 3.256075743037644 Test RE 0.8624924652151522\n",
      "88 Train Loss 2.1619818 Test MSE 3.164705040058226 Test RE 0.8503048958169352\n",
      "89 Train Loss 2.123121 Test MSE 3.2071645094160917 Test RE 0.8559899760370542\n",
      "90 Train Loss 2.0585532 Test MSE 3.19143454532523 Test RE 0.8538882375700458\n",
      "91 Train Loss 2.0171716 Test MSE 3.298018458061435 Test RE 0.8680297324783779\n",
      "92 Train Loss 1.9494919 Test MSE 3.196617245327778 Test RE 0.8545812881872558\n",
      "93 Train Loss 1.9204731 Test MSE 3.2079939200901633 Test RE 0.8561006534478003\n",
      "94 Train Loss 1.8586577 Test MSE 3.1552421271401663 Test RE 0.8490326784967855\n",
      "95 Train Loss 1.821504 Test MSE 3.105639156187904 Test RE 0.8423324991969648\n",
      "96 Train Loss 1.7937531 Test MSE 3.1020409779312788 Test RE 0.8418443966316784\n",
      "97 Train Loss 1.7416164 Test MSE 3.0803626480723554 Test RE 0.8388976630488613\n",
      "98 Train Loss 1.673473 Test MSE 3.083055385460291 Test RE 0.8392642493744714\n",
      "99 Train Loss 1.6432791 Test MSE 3.076427284156257 Test RE 0.8383616185839917\n",
      "Training time: 82.90\n",
      "7\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.03484 Test MSE 8.390737581423037 Test RE 1.3845483605011821\n",
      "1 Train Loss 55.550293 Test MSE 8.538768134160716 Test RE 1.3967081605812532\n",
      "2 Train Loss 55.355713 Test MSE 8.539825296091864 Test RE 1.3967946192468421\n",
      "3 Train Loss 54.06169 Test MSE 8.654559493115018 Test RE 1.4061464155675483\n",
      "4 Train Loss 48.42055 Test MSE 7.826723098931532 Test RE 1.337205163424329\n",
      "5 Train Loss 46.455505 Test MSE 7.9115899265371645 Test RE 1.3444354168470685\n",
      "6 Train Loss 44.476227 Test MSE 8.063749158067159 Test RE 1.3573022376081472\n",
      "7 Train Loss 44.1716 Test MSE 8.0700144141529 Test RE 1.3578294238325703\n",
      "8 Train Loss 43.725243 Test MSE 8.215263007076743 Test RE 1.3699944132183137\n",
      "9 Train Loss 43.660393 Test MSE 8.085050176614683 Test RE 1.3590937648170498\n",
      "10 Train Loss 43.362206 Test MSE 8.089368335520295 Test RE 1.359456656778629\n",
      "11 Train Loss 43.310173 Test MSE 7.973500703321287 Test RE 1.349685489236802\n",
      "12 Train Loss 43.108765 Test MSE 8.069579813162546 Test RE 1.3577928611991454\n",
      "13 Train Loss 42.69455 Test MSE 7.963166421156509 Test RE 1.348810556533768\n",
      "14 Train Loss 41.339836 Test MSE 7.102145570968805 Test RE 1.2738046945426464\n",
      "15 Train Loss 39.534897 Test MSE 7.018948822740293 Test RE 1.2663218431406031\n",
      "16 Train Loss 32.89421 Test MSE 5.310704581615671 Test RE 1.1014990630825632\n",
      "17 Train Loss 30.865868 Test MSE 4.640347434010595 Test RE 1.0296350297433876\n",
      "18 Train Loss 29.863644 Test MSE 4.649877269855534 Test RE 1.0306917631332695\n",
      "19 Train Loss 29.501314 Test MSE 4.320717887643534 Test RE 0.9935415080343215\n",
      "20 Train Loss 28.846157 Test MSE 3.770003832117816 Test RE 0.9280662001555064\n",
      "21 Train Loss 28.03338 Test MSE 2.822156180554474 Test RE 0.8029686367279191\n",
      "22 Train Loss 25.254898 Test MSE 1.64893554987469 Test RE 0.6137759976267508\n",
      "23 Train Loss 20.256813 Test MSE 1.7011677507810556 Test RE 0.6234212919983885\n",
      "24 Train Loss 13.790446 Test MSE 1.5474667244058264 Test RE 0.5945915319771821\n",
      "25 Train Loss 11.722604 Test MSE 1.5756408264460466 Test RE 0.5999798608354874\n",
      "26 Train Loss 10.354547 Test MSE 1.6406917039899158 Test RE 0.6122397899816613\n",
      "27 Train Loss 9.146206 Test MSE 1.6801576085590348 Test RE 0.6195595729902976\n",
      "28 Train Loss 7.9588776 Test MSE 1.8667078137694504 Test RE 0.6530496980200159\n",
      "29 Train Loss 7.3430233 Test MSE 1.854644325605765 Test RE 0.6509361303779081\n",
      "30 Train Loss 6.647492 Test MSE 1.6559629071148938 Test RE 0.6150824881969019\n",
      "31 Train Loss 5.429731 Test MSE 1.2345538736154995 Test RE 0.5310838360367384\n",
      "32 Train Loss 4.974434 Test MSE 1.276209344185877 Test RE 0.5399692399076572\n",
      "33 Train Loss 4.312755 Test MSE 0.9802041050623554 Test RE 0.4732235168633194\n",
      "34 Train Loss 3.6116168 Test MSE 0.5996637368910436 Test RE 0.3701365338424085\n",
      "35 Train Loss 2.7492146 Test MSE 0.3894907820895636 Test RE 0.2983023345489073\n",
      "36 Train Loss 2.280495 Test MSE 0.2899158127852126 Test RE 0.2573617565584085\n",
      "37 Train Loss 1.7473809 Test MSE 0.19728990086265766 Test RE 0.21230512964470874\n",
      "38 Train Loss 1.1787039 Test MSE 0.1267712033990295 Test RE 0.17018385880305717\n",
      "39 Train Loss 0.8484957 Test MSE 0.09909985091515452 Test RE 0.15046814288962285\n",
      "40 Train Loss 0.6317886 Test MSE 0.07622831478329781 Test RE 0.13196726607256742\n",
      "41 Train Loss 0.49743977 Test MSE 0.055973069299739595 Test RE 0.11308307810011853\n",
      "42 Train Loss 0.4112299 Test MSE 0.04309920151253957 Test RE 0.09922992711603233\n",
      "43 Train Loss 0.36689916 Test MSE 0.03139990879764335 Test RE 0.08469782414316292\n",
      "44 Train Loss 0.31697297 Test MSE 0.031149521124389172 Test RE 0.08435945153501524\n",
      "45 Train Loss 0.27612802 Test MSE 0.026552671717236534 Test RE 0.07788649731587441\n",
      "46 Train Loss 0.23229215 Test MSE 0.018415401021176205 Test RE 0.06486324181923049\n",
      "47 Train Loss 0.21717113 Test MSE 0.016859553156760434 Test RE 0.062062760717918775\n",
      "48 Train Loss 0.20981294 Test MSE 0.015882155296691847 Test RE 0.0602369230167777\n",
      "49 Train Loss 0.19107516 Test MSE 0.013947711495715777 Test RE 0.05644942701977817\n",
      "50 Train Loss 0.16479169 Test MSE 0.015690624989603337 Test RE 0.059872608772887324\n",
      "51 Train Loss 0.14709646 Test MSE 0.015698155862658197 Test RE 0.05988697527921681\n",
      "52 Train Loss 0.13987035 Test MSE 0.012456550499748446 Test RE 0.05334662598386723\n",
      "53 Train Loss 0.13383661 Test MSE 0.012529813074894557 Test RE 0.05350327374114542\n",
      "54 Train Loss 0.12213458 Test MSE 0.011756537292628209 Test RE 0.0518260098426894\n",
      "55 Train Loss 0.109541215 Test MSE 0.00970465317666494 Test RE 0.04708667997122457\n",
      "56 Train Loss 0.09810154 Test MSE 0.007029998905313717 Test RE 0.04007612190389154\n",
      "57 Train Loss 0.08979859 Test MSE 0.00703956749121129 Test RE 0.040103386589288824\n",
      "58 Train Loss 0.07745031 Test MSE 0.006401486328092171 Test RE 0.03824269337848006\n",
      "59 Train Loss 0.06730046 Test MSE 0.006489425556239221 Test RE 0.03850447335136239\n",
      "60 Train Loss 0.06266575 Test MSE 0.005521675971535179 Test RE 0.03551759239932637\n",
      "61 Train Loss 0.05691059 Test MSE 0.0054157164048494015 Test RE 0.035175154806922286\n",
      "62 Train Loss 0.05190848 Test MSE 0.005411335414611136 Test RE 0.0351609246316553\n",
      "63 Train Loss 0.04869454 Test MSE 0.005468603082269928 Test RE 0.03534648739970444\n",
      "64 Train Loss 0.04656976 Test MSE 0.005695169431174697 Test RE 0.03607126596748394\n",
      "65 Train Loss 0.043160897 Test MSE 0.005334996581317896 Test RE 0.03491203248499981\n",
      "66 Train Loss 0.041111168 Test MSE 0.00560211216581145 Test RE 0.03577535568620976\n",
      "67 Train Loss 0.03662401 Test MSE 0.005161462185489649 Test RE 0.03433953699704811\n",
      "68 Train Loss 0.03383597 Test MSE 0.0053818687317577765 Test RE 0.035065061961825704\n",
      "69 Train Loss 0.031359605 Test MSE 0.004779457062621174 Test RE 0.033044359813781704\n",
      "70 Train Loss 0.026065538 Test MSE 0.003941113190729354 Test RE 0.030006650118642498\n",
      "71 Train Loss 0.023956843 Test MSE 0.003275552574354825 Test RE 0.02735585842884231\n",
      "72 Train Loss 0.022501316 Test MSE 0.0030957660401005546 Test RE 0.026594518160872826\n",
      "73 Train Loss 0.021190913 Test MSE 0.002988619868171141 Test RE 0.026130240077511604\n",
      "74 Train Loss 0.019637384 Test MSE 0.003057402807675837 Test RE 0.02642922269175253\n",
      "75 Train Loss 0.018138904 Test MSE 0.0027849574403822287 Test RE 0.025224196538119\n",
      "76 Train Loss 0.016661786 Test MSE 0.0027405249930812356 Test RE 0.025022168472249372\n",
      "77 Train Loss 0.016084896 Test MSE 0.0026987522471564225 Test RE 0.02483073464100979\n",
      "78 Train Loss 0.015014584 Test MSE 0.002207805998655762 Test RE 0.022458901725224956\n",
      "79 Train Loss 0.014175366 Test MSE 0.0018118204893438495 Test RE 0.020345372402654376\n",
      "80 Train Loss 0.012519718 Test MSE 0.0018129447914687926 Test RE 0.0203516839545063\n",
      "81 Train Loss 0.012087611 Test MSE 0.0018344502350595465 Test RE 0.020472035578262205\n",
      "82 Train Loss 0.011794324 Test MSE 0.001964535939726374 Test RE 0.021185467373779753\n",
      "83 Train Loss 0.01101345 Test MSE 0.0018618102041586591 Test RE 0.02062413597869437\n",
      "84 Train Loss 0.010438668 Test MSE 0.00180877908732217 Test RE 0.020328288909306547\n",
      "85 Train Loss 0.010313083 Test MSE 0.0018587582088982477 Test RE 0.020607224861216845\n",
      "86 Train Loss 0.0101785995 Test MSE 0.001848962054432199 Test RE 0.020552850322501745\n",
      "87 Train Loss 0.009865477 Test MSE 0.0016983979594709638 Test RE 0.019698256575837556\n",
      "88 Train Loss 0.009515929 Test MSE 0.0016576700351178958 Test RE 0.01946063932895528\n",
      "89 Train Loss 0.0090758195 Test MSE 0.0015240605333144664 Test RE 0.018659893843320716\n",
      "90 Train Loss 0.008868215 Test MSE 0.001542409255060224 Test RE 0.018771884418656428\n",
      "91 Train Loss 0.008666005 Test MSE 0.001390011923286551 Test RE 0.017820394870972273\n",
      "92 Train Loss 0.008325886 Test MSE 0.0012593442867805198 Test RE 0.016962126525311212\n",
      "93 Train Loss 0.007945801 Test MSE 0.0012845367636916349 Test RE 0.017130945343539282\n",
      "94 Train Loss 0.007650881 Test MSE 0.0012938971463171934 Test RE 0.017193248403565585\n",
      "95 Train Loss 0.0075586643 Test MSE 0.0012660758043467292 Test RE 0.017007399560980466\n",
      "96 Train Loss 0.0073984507 Test MSE 0.0013122170437193544 Test RE 0.017314537584075945\n",
      "97 Train Loss 0.0071316883 Test MSE 0.0012843032973068875 Test RE 0.017129388485948704\n",
      "98 Train Loss 0.0069333077 Test MSE 0.0013037112798816761 Test RE 0.017258330114161953\n",
      "99 Train Loss 0.006841835 Test MSE 0.0013199349373244338 Test RE 0.017365381247550337\n",
      "Training time: 84.07\n",
      "8\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.49318 Test MSE 8.479721971417696 Test RE 1.3918706170969606\n",
      "1 Train Loss 48.85388 Test MSE 8.694473147640625 Test RE 1.4093851639692643\n",
      "2 Train Loss 37.65651 Test MSE 7.356717463891866 Test RE 1.2964330646255806\n",
      "3 Train Loss 32.5297 Test MSE 6.854575763621081 Test RE 1.2514063396848538\n",
      "4 Train Loss 25.11327 Test MSE 6.469052326083461 Test RE 1.2157055301989537\n",
      "5 Train Loss 22.162077 Test MSE 5.858849395454723 Test RE 1.1569490331440166\n",
      "6 Train Loss 20.642414 Test MSE 5.880089124425692 Test RE 1.159044244294815\n",
      "7 Train Loss 18.122868 Test MSE 5.913162160605917 Test RE 1.1622992426929408\n",
      "8 Train Loss 15.679944 Test MSE 5.78766745187658 Test RE 1.149899393744466\n",
      "9 Train Loss 13.636744 Test MSE 5.939816936148087 Test RE 1.1649159467481114\n",
      "10 Train Loss 11.9837265 Test MSE 6.156189293033281 Test RE 1.1859436195172341\n",
      "11 Train Loss 10.694857 Test MSE 5.946964757251543 Test RE 1.1656166507745842\n",
      "12 Train Loss 9.332823 Test MSE 5.885023854872203 Test RE 1.1595304929977377\n",
      "13 Train Loss 8.359842 Test MSE 5.63989748628688 Test RE 1.1351249389478417\n",
      "14 Train Loss 7.140417 Test MSE 5.198788607348525 Test RE 1.0898309558387111\n",
      "15 Train Loss 5.505219 Test MSE 4.695205801736876 Test RE 1.035703340159661\n",
      "16 Train Loss 4.358937 Test MSE 4.519429134781791 Test RE 1.0161313505045015\n",
      "17 Train Loss 3.7520103 Test MSE 4.371754806359743 Test RE 0.999392206459569\n",
      "18 Train Loss 3.3158717 Test MSE 4.047405175763736 Test RE 0.9616043109472988\n",
      "19 Train Loss 3.044558 Test MSE 3.94120224346648 Test RE 0.948904313726942\n",
      "20 Train Loss 2.8141296 Test MSE 3.7044318362991566 Test RE 0.9199598298462923\n",
      "21 Train Loss 2.5831609 Test MSE 3.5940716849807717 Test RE 0.9061527812915628\n",
      "22 Train Loss 2.2643998 Test MSE 3.3311458092697523 Test RE 0.8723783552905241\n",
      "23 Train Loss 2.0147214 Test MSE 3.097915491477485 Test RE 0.8412844148064471\n",
      "24 Train Loss 1.796352 Test MSE 2.844234189319067 Test RE 0.8061033696328254\n",
      "25 Train Loss 1.5244745 Test MSE 2.2713972362148325 Test RE 0.7203683223280803\n",
      "26 Train Loss 1.3476971 Test MSE 2.0689320115601246 Test RE 0.6875134042861542\n",
      "27 Train Loss 1.0207196 Test MSE 1.5349222063555366 Test RE 0.5921766037705823\n",
      "28 Train Loss 0.8032923 Test MSE 1.1311164625174097 Test RE 0.5083487054209699\n",
      "29 Train Loss 0.65543556 Test MSE 0.9922102507736954 Test RE 0.47611286322580015\n",
      "30 Train Loss 0.5394629 Test MSE 0.8005627977392018 Test RE 0.4276670220413536\n",
      "31 Train Loss 0.4584385 Test MSE 0.6955530083427284 Test RE 0.3986329347650038\n",
      "32 Train Loss 0.37443304 Test MSE 0.5038748291623495 Test RE 0.339288697277965\n",
      "33 Train Loss 0.28847435 Test MSE 0.42124119113684855 Test RE 0.31022263069554873\n",
      "34 Train Loss 0.23113172 Test MSE 0.37730006801728444 Test RE 0.2935969245674934\n",
      "35 Train Loss 0.19372684 Test MSE 0.3591075142277997 Test RE 0.286431189558739\n",
      "36 Train Loss 0.17109933 Test MSE 0.3218558366854842 Test RE 0.2711681978768684\n",
      "37 Train Loss 0.15581235 Test MSE 0.31071829625713737 Test RE 0.26643512194160135\n",
      "38 Train Loss 0.14321226 Test MSE 0.30884610498442966 Test RE 0.26563122468521116\n",
      "39 Train Loss 0.13097613 Test MSE 0.3160357125839582 Test RE 0.2687052432988951\n",
      "40 Train Loss 0.11666351 Test MSE 0.30815604804454944 Test RE 0.2653343079213164\n",
      "41 Train Loss 0.10804851 Test MSE 0.2859442513375419 Test RE 0.2555928762376469\n",
      "42 Train Loss 0.09728033 Test MSE 0.2729881566560938 Test RE 0.2497353167910777\n",
      "43 Train Loss 0.08528966 Test MSE 0.2445616556762837 Test RE 0.23637538173854583\n",
      "44 Train Loss 0.072212264 Test MSE 0.17743429934824875 Test RE 0.20133850904153608\n",
      "45 Train Loss 0.06475981 Test MSE 0.16892419245664186 Test RE 0.1964508833637295\n",
      "46 Train Loss 0.057384692 Test MSE 0.15074531568911131 Test RE 0.18557948837671873\n",
      "47 Train Loss 0.05195918 Test MSE 0.13989995288847648 Test RE 0.17877914024143435\n",
      "48 Train Loss 0.048401438 Test MSE 0.1394313893016853 Test RE 0.17847949877307273\n",
      "49 Train Loss 0.04491282 Test MSE 0.13096356889036886 Test RE 0.17297498875620784\n",
      "50 Train Loss 0.04243365 Test MSE 0.13364473099362933 Test RE 0.1747366401723126\n",
      "51 Train Loss 0.040943027 Test MSE 0.12637975900405496 Test RE 0.16992090861865408\n",
      "52 Train Loss 0.03987071 Test MSE 0.12075126955676378 Test RE 0.16609398807618686\n",
      "53 Train Loss 0.038315743 Test MSE 0.11914038236582719 Test RE 0.1649823764737511\n",
      "54 Train Loss 0.03622273 Test MSE 0.11184143257766431 Test RE 0.1598488149465764\n",
      "55 Train Loss 0.035025623 Test MSE 0.11387844119828183 Test RE 0.16129793862016514\n",
      "56 Train Loss 0.033713236 Test MSE 0.11225862152761201 Test RE 0.16014667006440972\n",
      "57 Train Loss 0.03261617 Test MSE 0.11251371402054233 Test RE 0.1603285226085525\n",
      "58 Train Loss 0.03173879 Test MSE 0.10870337633022299 Test RE 0.15759033438164982\n",
      "59 Train Loss 0.030769888 Test MSE 0.10505969860035344 Test RE 0.15492665192033483\n",
      "60 Train Loss 0.029839488 Test MSE 0.10411251455604834 Test RE 0.15422668655175362\n",
      "61 Train Loss 0.029195683 Test MSE 0.09750164900809269 Test RE 0.14924989720657236\n",
      "62 Train Loss 0.027911838 Test MSE 0.09170677489744605 Test RE 0.14474673310519381\n",
      "63 Train Loss 0.02691994 Test MSE 0.0883044467297182 Test RE 0.14203629890103112\n",
      "64 Train Loss 0.02609896 Test MSE 0.08460328563943549 Test RE 0.1390278078725308\n",
      "65 Train Loss 0.025566116 Test MSE 0.08441561281637144 Test RE 0.13887352174354087\n",
      "66 Train Loss 0.024582507 Test MSE 0.07733816487323975 Test RE 0.1329244866040477\n",
      "67 Train Loss 0.023948843 Test MSE 0.0766057352399585 Test RE 0.13229355983247806\n",
      "68 Train Loss 0.023368668 Test MSE 0.07309292938294867 Test RE 0.12922476293438104\n",
      "69 Train Loss 0.022617972 Test MSE 0.06509661039911167 Test RE 0.12195152848498991\n",
      "70 Train Loss 0.021780161 Test MSE 0.05845559173660445 Test RE 0.11556360757766683\n",
      "71 Train Loss 0.021060454 Test MSE 0.05762072950529567 Test RE 0.11473540063427073\n",
      "72 Train Loss 0.019842915 Test MSE 0.05186858297621306 Test RE 0.10885797519768411\n",
      "73 Train Loss 0.018776396 Test MSE 0.04861191812785323 Test RE 0.10538515513458946\n",
      "74 Train Loss 0.016238399 Test MSE 0.03239363105897365 Test RE 0.08602761365851129\n",
      "75 Train Loss 0.0147220595 Test MSE 0.025683693536178623 Test RE 0.0766014163697283\n",
      "76 Train Loss 0.012476533 Test MSE 0.02050524974258294 Test RE 0.06844482096808562\n",
      "77 Train Loss 0.0113980295 Test MSE 0.018344996332958118 Test RE 0.06473913240021516\n",
      "78 Train Loss 0.010063993 Test MSE 0.01463038328664858 Test RE 0.05781438527136366\n",
      "79 Train Loss 0.008791567 Test MSE 0.012874463281800145 Test RE 0.05423412362806337\n",
      "80 Train Loss 0.008055857 Test MSE 0.012426868362836156 Test RE 0.05328302947456995\n",
      "81 Train Loss 0.0073799905 Test MSE 0.01070939297450215 Test RE 0.049464142858931845\n",
      "82 Train Loss 0.0068391445 Test MSE 0.010597586105395004 Test RE 0.04920526071069654\n",
      "83 Train Loss 0.006180289 Test MSE 0.009785791273617063 Test RE 0.047283110031217726\n",
      "84 Train Loss 0.0056759818 Test MSE 0.009488893861270416 Test RE 0.046560309088365184\n",
      "85 Train Loss 0.0051427893 Test MSE 0.00855708152464677 Test RE 0.04421512886250046\n",
      "86 Train Loss 0.004806497 Test MSE 0.00848281266981133 Test RE 0.04402283413597669\n",
      "87 Train Loss 0.004362931 Test MSE 0.0070962618822381866 Test RE 0.040264552572968695\n",
      "88 Train Loss 0.0040687295 Test MSE 0.006641189412158253 Test RE 0.038952110513551026\n",
      "89 Train Loss 0.0038512347 Test MSE 0.006325775505464825 Test RE 0.038015871230355394\n",
      "90 Train Loss 0.0036865599 Test MSE 0.006199515581159332 Test RE 0.03763456825881453\n",
      "91 Train Loss 0.003431467 Test MSE 0.006103141461523278 Test RE 0.03734089976285503\n",
      "92 Train Loss 0.0032637971 Test MSE 0.005697304976219114 Test RE 0.036078028241576035\n",
      "93 Train Loss 0.0031450624 Test MSE 0.005627304277602161 Test RE 0.03585570447168671\n",
      "94 Train Loss 0.0029766615 Test MSE 0.005553487146519176 Test RE 0.03561975646209646\n",
      "95 Train Loss 0.0028251202 Test MSE 0.005353532837823426 Test RE 0.034972630204133846\n",
      "96 Train Loss 0.0027030057 Test MSE 0.005283647611712821 Test RE 0.03474361331189069\n",
      "97 Train Loss 0.002539721 Test MSE 0.005151294509872523 Test RE 0.03430569722634088\n",
      "98 Train Loss 0.002423947 Test MSE 0.004955742273564819 Test RE 0.03364824492292745\n",
      "99 Train Loss 0.0023331712 Test MSE 0.004598847533795105 Test RE 0.03241399539423935\n",
      "Training time: 83.00\n",
      "9\n",
      "KG_rowdy_tune5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.92943 Test MSE 8.270965109638574 Test RE 1.374631066465904\n",
      "1 Train Loss 56.342365 Test MSE 8.650539605694854 Test RE 1.4058198127623545\n",
      "2 Train Loss 55.378563 Test MSE 8.939631352348574 Test RE 1.4291172628469282\n",
      "3 Train Loss 45.80918 Test MSE 8.27027794184633 Test RE 1.3745739617747812\n",
      "4 Train Loss 44.147957 Test MSE 8.591381237060878 Test RE 1.4010045824157196\n",
      "5 Train Loss 43.820732 Test MSE 8.53783837826588 Test RE 1.396632117235357\n",
      "6 Train Loss 43.421616 Test MSE 8.412095820416395 Test RE 1.3863093928402532\n",
      "7 Train Loss 43.19954 Test MSE 8.38159283102913 Test RE 1.3837936711365213\n",
      "8 Train Loss 43.039757 Test MSE 8.391525903166324 Test RE 1.3846133991185596\n",
      "9 Train Loss 42.54095 Test MSE 8.141634456636465 Test RE 1.3638413702594685\n",
      "10 Train Loss 42.16434 Test MSE 8.239300859417868 Test RE 1.3719972504381936\n",
      "11 Train Loss 41.98812 Test MSE 8.373816000961096 Test RE 1.3831515482210752\n",
      "12 Train Loss 41.511253 Test MSE 8.218076357589227 Test RE 1.3702289732415096\n",
      "13 Train Loss 41.130737 Test MSE 8.294537568401264 Test RE 1.3765885393176165\n",
      "14 Train Loss 40.049026 Test MSE 8.578796170691605 Test RE 1.3999780770813168\n",
      "15 Train Loss 38.889404 Test MSE 7.5079345610628145 Test RE 1.309689360968543\n",
      "16 Train Loss 37.56977 Test MSE 7.6096607693006995 Test RE 1.3185321043003446\n",
      "17 Train Loss 35.791775 Test MSE 6.650423355505715 Test RE 1.2326299238012068\n",
      "18 Train Loss 33.626366 Test MSE 7.6046477016434455 Test RE 1.3180977235955502\n",
      "19 Train Loss 32.392784 Test MSE 7.53372076283758 Test RE 1.3119365146900117\n",
      "20 Train Loss 31.74671 Test MSE 7.682054991937546 Test RE 1.3247891608466102\n",
      "21 Train Loss 31.340616 Test MSE 7.617706560741675 Test RE 1.3192289705576794\n",
      "22 Train Loss 30.55227 Test MSE 7.6462258109259515 Test RE 1.3216961352341305\n",
      "23 Train Loss 30.216446 Test MSE 7.511472981040154 Test RE 1.309997946843418\n",
      "24 Train Loss 29.83002 Test MSE 7.480052844514077 Test RE 1.3072552459367883\n",
      "25 Train Loss 29.653694 Test MSE 7.33338473034593 Test RE 1.2943755335064777\n",
      "26 Train Loss 29.242067 Test MSE 7.285527718808651 Test RE 1.2901451310372918\n",
      "27 Train Loss 28.93974 Test MSE 7.270765175424776 Test RE 1.2888373684393164\n",
      "28 Train Loss 28.823654 Test MSE 7.236629752535285 Test RE 1.2858083359358494\n",
      "29 Train Loss 28.703785 Test MSE 7.210200439254355 Test RE 1.2834582007811282\n",
      "30 Train Loss 28.536053 Test MSE 7.050966332331341 Test RE 1.269206772294941\n",
      "31 Train Loss 28.31953 Test MSE 7.075946242058871 Test RE 1.2714530345939323\n",
      "32 Train Loss 28.20484 Test MSE 7.019052805956635 Test RE 1.2663312231584534\n",
      "33 Train Loss 28.000706 Test MSE 7.075743847594019 Test RE 1.271434850672808\n",
      "34 Train Loss 27.724611 Test MSE 6.869468919256776 Test RE 1.2527650872932365\n",
      "35 Train Loss 27.376427 Test MSE 6.708303867541535 Test RE 1.2379822664071816\n",
      "36 Train Loss 27.040344 Test MSE 6.60903169491335 Test RE 1.228788045496966\n",
      "37 Train Loss 26.809591 Test MSE 6.569762327344774 Test RE 1.2251320166280995\n",
      "38 Train Loss 26.64768 Test MSE 6.57343465611792 Test RE 1.2254743774920414\n",
      "39 Train Loss 26.548344 Test MSE 6.4791953417978725 Test RE 1.2166582269742174\n",
      "40 Train Loss 26.257088 Test MSE 6.666796891311147 Test RE 1.2341463763562492\n",
      "41 Train Loss 25.859379 Test MSE 6.4468199536576085 Test RE 1.2136147077168105\n",
      "42 Train Loss 25.297108 Test MSE 6.522057166691205 Test RE 1.2206758733973244\n",
      "43 Train Loss 24.970875 Test MSE 6.628339697361534 Test RE 1.2305816622274723\n",
      "44 Train Loss 24.347761 Test MSE 6.472488766465942 Test RE 1.216028386214221\n",
      "45 Train Loss 23.740181 Test MSE 5.798323409335484 Test RE 1.150957474938829\n",
      "46 Train Loss 22.500359 Test MSE 4.82686281712707 Test RE 1.0501238891246314\n",
      "47 Train Loss 20.793438 Test MSE 4.109830695964053 Test RE 0.9689916307727151\n",
      "48 Train Loss 18.459232 Test MSE 3.5471970533878245 Test RE 0.9002242709666565\n",
      "49 Train Loss 16.034935 Test MSE 3.416361478990502 Test RE 0.8834662604336486\n",
      "50 Train Loss 15.375114 Test MSE 3.364734480127019 Test RE 0.8767655146176713\n",
      "51 Train Loss 14.792925 Test MSE 3.2065294590532467 Test RE 0.8559052245914504\n",
      "52 Train Loss 13.748594 Test MSE 3.0491464784068882 Test RE 0.8346361753909988\n",
      "53 Train Loss 12.715525 Test MSE 3.314919829525541 Test RE 0.87025108829335\n",
      "54 Train Loss 12.227949 Test MSE 3.416319874459275 Test RE 0.8834608809807204\n",
      "55 Train Loss 11.641344 Test MSE 3.306889548964625 Test RE 0.8691963723186912\n",
      "56 Train Loss 11.155933 Test MSE 3.4621050188649978 Test RE 0.8893612008494671\n",
      "57 Train Loss 10.776905 Test MSE 3.424036918958404 Test RE 0.8844581326191888\n",
      "58 Train Loss 10.232694 Test MSE 3.590312523499927 Test RE 0.9056787693481955\n",
      "59 Train Loss 9.770111 Test MSE 3.609262408224334 Test RE 0.9080657372715963\n",
      "60 Train Loss 9.549658 Test MSE 3.609138348642583 Test RE 0.9080501308663399\n",
      "61 Train Loss 9.268407 Test MSE 3.6184551711928643 Test RE 0.9092214200065126\n",
      "62 Train Loss 9.050352 Test MSE 3.5595107397419086 Test RE 0.9017854297733847\n",
      "63 Train Loss 8.815268 Test MSE 3.499812375377806 Test RE 0.8941913029280004\n",
      "64 Train Loss 8.642424 Test MSE 3.5306555937106574 Test RE 0.8981228336932452\n",
      "65 Train Loss 8.307412 Test MSE 3.6264210594165838 Test RE 0.910221677586074\n",
      "66 Train Loss 8.184536 Test MSE 3.6340802793263407 Test RE 0.9111823921114679\n",
      "67 Train Loss 8.096658 Test MSE 3.6076907751730967 Test RE 0.9078680096809576\n",
      "68 Train Loss 7.974267 Test MSE 3.650930039247854 Test RE 0.9132923412406017\n",
      "69 Train Loss 7.8873224 Test MSE 3.6936498963245694 Test RE 0.9186200589946915\n",
      "70 Train Loss 7.7691813 Test MSE 3.644329899399947 Test RE 0.912466444296541\n",
      "71 Train Loss 7.6832666 Test MSE 3.6322130941507518 Test RE 0.9109482799403695\n",
      "72 Train Loss 7.583107 Test MSE 3.6132159188873563 Test RE 0.9085629392745789\n",
      "73 Train Loss 7.5219097 Test MSE 3.6260935457003605 Test RE 0.9101805741385628\n",
      "74 Train Loss 7.3895516 Test MSE 3.661623749535412 Test RE 0.9146288969203729\n",
      "75 Train Loss 7.3197355 Test MSE 3.637531684869122 Test RE 0.9116149793656139\n",
      "76 Train Loss 7.2456903 Test MSE 3.6744381832885193 Test RE 0.9162279436436779\n",
      "77 Train Loss 7.1395254 Test MSE 3.6724576319018825 Test RE 0.9159809832887162\n",
      "78 Train Loss 7.0220275 Test MSE 3.743590300589564 Test RE 0.9248093607927482\n",
      "79 Train Loss 6.9475985 Test MSE 3.727289373135583 Test RE 0.9227936892491007\n",
      "80 Train Loss 6.7919884 Test MSE 3.7503684454446375 Test RE 0.9256462121093432\n",
      "81 Train Loss 6.68636 Test MSE 3.720489224559002 Test RE 0.9219515224220938\n",
      "82 Train Loss 6.6007214 Test MSE 3.718904317626726 Test RE 0.9217551284910089\n",
      "83 Train Loss 6.5019503 Test MSE 3.7312285791132305 Test RE 0.9232811902348274\n",
      "84 Train Loss 6.377716 Test MSE 3.791267595903117 Test RE 0.930679782675025\n",
      "85 Train Loss 6.2149143 Test MSE 3.853164899611432 Test RE 0.9382462947236251\n",
      "86 Train Loss 6.0634184 Test MSE 3.8235387664851435 Test RE 0.9346323504395015\n",
      "87 Train Loss 5.8891716 Test MSE 3.813482502067457 Test RE 0.9334024559926093\n",
      "88 Train Loss 5.698795 Test MSE 3.7861072792590047 Test RE 0.930046190139408\n",
      "89 Train Loss 5.4759917 Test MSE 3.7732583953021432 Test RE 0.9284667035277775\n",
      "90 Train Loss 5.2155614 Test MSE 3.6778302580850637 Test RE 0.9166507561418263\n",
      "91 Train Loss 4.9716177 Test MSE 3.576780534000587 Test RE 0.9039703936442229\n",
      "92 Train Loss 4.544593 Test MSE 3.508851633982284 Test RE 0.8953453096637066\n",
      "93 Train Loss 4.2332196 Test MSE 3.521962353470842 Test RE 0.897016465587309\n",
      "94 Train Loss 3.9657826 Test MSE 3.518311990141322 Test RE 0.8965514854744572\n",
      "95 Train Loss 3.5707426 Test MSE 3.4304859955270084 Test RE 0.8852906667125328\n",
      "96 Train Loss 3.4252992 Test MSE 3.4052319429225943 Test RE 0.8820260453581257\n",
      "97 Train Loss 3.161272 Test MSE 3.440131945644546 Test RE 0.886534437297538\n",
      "98 Train Loss 2.8932378 Test MSE 3.385316219525191 Test RE 0.8794429692744125\n",
      "99 Train Loss 2.5789244 Test MSE 3.3261689023825194 Test RE 0.8717264221412264\n",
      "Training time: 82.12\n",
      "0\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.838806 Test MSE 7.644196828908376 Test RE 1.32152076272467\n",
      "1 Train Loss 38.824318 Test MSE 7.287706164679582 Test RE 1.290337999788926\n",
      "2 Train Loss 30.349957 Test MSE 7.175397465321559 Test RE 1.2803568865081085\n",
      "3 Train Loss 25.212057 Test MSE 6.237661836520294 Test RE 1.1937653625764189\n",
      "4 Train Loss 23.169174 Test MSE 5.766701209808798 Test RE 1.1478147073754854\n",
      "5 Train Loss 21.455513 Test MSE 5.74688522072594 Test RE 1.1458409050113123\n",
      "6 Train Loss 18.701118 Test MSE 5.81180008111504 Test RE 1.1522942470224278\n",
      "7 Train Loss 15.921017 Test MSE 5.5384651966999146 Test RE 1.1248711431801868\n",
      "8 Train Loss 13.492319 Test MSE 5.778187201078649 Test RE 1.148957235049582\n",
      "9 Train Loss 11.384026 Test MSE 5.517352139745142 Test RE 1.1227250481327178\n",
      "10 Train Loss 9.92546 Test MSE 5.633597546846862 Test RE 1.134490777020374\n",
      "11 Train Loss 8.282373 Test MSE 5.51493658554934 Test RE 1.122479250870476\n",
      "12 Train Loss 7.390523 Test MSE 5.377532873522383 Test RE 1.1084078611446546\n",
      "13 Train Loss 6.7586803 Test MSE 5.354897558616397 Test RE 1.1060726250014894\n",
      "14 Train Loss 6.1313376 Test MSE 5.152474547156162 Test RE 1.0849656479334\n",
      "15 Train Loss 5.5982466 Test MSE 4.902988709395732 Test RE 1.0583724023502943\n",
      "16 Train Loss 5.112398 Test MSE 4.686174488884834 Test RE 1.034706763689413\n",
      "17 Train Loss 4.5176306 Test MSE 4.543143228108515 Test RE 1.0187937560866758\n",
      "18 Train Loss 3.731989 Test MSE 3.9801464190691136 Test RE 0.9535809901757433\n",
      "19 Train Loss 3.2987385 Test MSE 3.78227445496847 Test RE 0.9295753098928896\n",
      "20 Train Loss 2.8481703 Test MSE 3.508967798251279 Test RE 0.8953601302208924\n",
      "21 Train Loss 2.4648213 Test MSE 3.2294583392867264 Test RE 0.8589599275902295\n",
      "22 Train Loss 2.1422076 Test MSE 2.698309981081353 Test RE 0.7851524319015245\n",
      "23 Train Loss 1.8136294 Test MSE 2.3345463935689263 Test RE 0.730313476458795\n",
      "24 Train Loss 1.639586 Test MSE 2.201556690107096 Test RE 0.7092069726942384\n",
      "25 Train Loss 1.4857792 Test MSE 2.071603455146762 Test RE 0.6879571261597033\n",
      "26 Train Loss 1.3633897 Test MSE 1.9232808709959068 Test RE 0.6628716057848146\n",
      "27 Train Loss 1.2021508 Test MSE 1.4975266056706737 Test RE 0.5849184679162832\n",
      "28 Train Loss 0.9918186 Test MSE 1.3582875711298301 Test RE 0.5570624997231343\n",
      "29 Train Loss 0.88621736 Test MSE 1.0216308276954496 Test RE 0.48312004262909414\n",
      "30 Train Loss 0.74718326 Test MSE 0.8999170551751625 Test RE 0.453429009080976\n",
      "31 Train Loss 0.5279093 Test MSE 0.5012382992346449 Test RE 0.3383998673515737\n",
      "32 Train Loss 0.3960774 Test MSE 0.37785028774397084 Test RE 0.293810923956025\n",
      "33 Train Loss 0.32929146 Test MSE 0.3019216406427298 Test RE 0.2626365601692416\n",
      "34 Train Loss 0.25679684 Test MSE 0.08855697497238643 Test RE 0.14223924774121527\n",
      "35 Train Loss 0.1959761 Test MSE 0.04740074518223199 Test RE 0.10406403106650608\n",
      "36 Train Loss 0.16029398 Test MSE 0.03414336726905737 Test RE 0.08832044226156578\n",
      "37 Train Loss 0.11999543 Test MSE 0.023834581522335016 Test RE 0.07379243235774899\n",
      "38 Train Loss 0.098990425 Test MSE 0.019427638971541 Test RE 0.0666220623273141\n",
      "39 Train Loss 0.08327225 Test MSE 0.01754109438166479 Test RE 0.06330476529236674\n",
      "40 Train Loss 0.06988567 Test MSE 0.014181858184857008 Test RE 0.05692127630429729\n",
      "41 Train Loss 0.056679204 Test MSE 0.01325770656836 Test RE 0.05503541701599242\n",
      "42 Train Loss 0.048062425 Test MSE 0.013252029658552626 Test RE 0.055023632754903413\n",
      "43 Train Loss 0.03672181 Test MSE 0.008877455318602102 Test RE 0.04503522199065804\n",
      "44 Train Loss 0.033168446 Test MSE 0.007649304860244075 Test RE 0.04180411610277673\n",
      "45 Train Loss 0.03028585 Test MSE 0.006300311944222052 Test RE 0.03793928017932947\n",
      "46 Train Loss 0.027645722 Test MSE 0.00500126738159527 Test RE 0.03380244362501827\n",
      "47 Train Loss 0.024935298 Test MSE 0.004037180372132693 Test RE 0.03037016398048178\n",
      "48 Train Loss 0.023638986 Test MSE 0.0038223664969982774 Test RE 0.02955113889739366\n",
      "49 Train Loss 0.021375054 Test MSE 0.0037113275904479786 Test RE 0.029118748498185038\n",
      "50 Train Loss 0.020119809 Test MSE 0.0038990656631238754 Test RE 0.029846151202771214\n",
      "51 Train Loss 0.018923463 Test MSE 0.003864785094061377 Test RE 0.029714657924101488\n",
      "52 Train Loss 0.017173717 Test MSE 0.0032297081788052614 Test RE 0.02716374856907581\n",
      "53 Train Loss 0.01602161 Test MSE 0.002864208333036198 Test RE 0.025580578529547312\n",
      "54 Train Loss 0.015002982 Test MSE 0.002800816808479056 Test RE 0.02529591611017877\n",
      "55 Train Loss 0.014290864 Test MSE 0.0024624982920079465 Test RE 0.023718981111710384\n",
      "56 Train Loss 0.01366782 Test MSE 0.0024584215491726055 Test RE 0.02369933922187151\n",
      "57 Train Loss 0.013405526 Test MSE 0.0023631857522768197 Test RE 0.02323576578037874\n",
      "58 Train Loss 0.012911063 Test MSE 0.0020559614017473023 Test RE 0.02167282572647397\n",
      "59 Train Loss 0.01232648 Test MSE 0.002037703175293017 Test RE 0.021576376976317528\n",
      "60 Train Loss 0.011264453 Test MSE 0.0017805118931623562 Test RE 0.0201688204502422\n",
      "61 Train Loss 0.0104904575 Test MSE 0.0017265832304072608 Test RE 0.019861032382977265\n",
      "62 Train Loss 0.010033216 Test MSE 0.0015469906820906481 Test RE 0.018799742864786858\n",
      "63 Train Loss 0.009670014 Test MSE 0.0014210271528276234 Test RE 0.01801811060420429\n",
      "64 Train Loss 0.0090794265 Test MSE 0.001320202834816195 Test RE 0.017367143420032986\n",
      "65 Train Loss 0.00862145 Test MSE 0.001424771430421009 Test RE 0.018041833031047918\n",
      "66 Train Loss 0.00800395 Test MSE 0.0014500429854019498 Test RE 0.0182011361636065\n",
      "67 Train Loss 0.0074972385 Test MSE 0.0014280736372752044 Test RE 0.018062728798018433\n",
      "68 Train Loss 0.007198357 Test MSE 0.0013025811332154854 Test RE 0.017250848138157998\n",
      "69 Train Loss 0.0067142816 Test MSE 0.0012789910858979727 Test RE 0.017093925981532167\n",
      "70 Train Loss 0.0063788868 Test MSE 0.001163354773879556 Test RE 0.01630287311460836\n",
      "71 Train Loss 0.005867259 Test MSE 0.0010225314353242653 Test RE 0.01528432959690508\n",
      "72 Train Loss 0.0056480453 Test MSE 0.0010984164015864523 Test RE 0.01584132721914493\n",
      "73 Train Loss 0.005558471 Test MSE 0.001099257653341605 Test RE 0.015847392311427472\n",
      "74 Train Loss 0.0053942036 Test MSE 0.0010820375346005232 Test RE 0.015722775863782866\n",
      "75 Train Loss 0.0049781995 Test MSE 0.0009864219481975716 Test RE 0.01501203000299636\n",
      "76 Train Loss 0.004734364 Test MSE 0.0009528736597432716 Test RE 0.014754541601066847\n",
      "77 Train Loss 0.0044757593 Test MSE 0.000991044914318825 Test RE 0.015047166580995862\n",
      "78 Train Loss 0.0041816104 Test MSE 0.0010383521104590121 Test RE 0.015402115834234847\n",
      "79 Train Loss 0.0040166704 Test MSE 0.001087241497426411 Test RE 0.0157605391561715\n",
      "80 Train Loss 0.0039352938 Test MSE 0.0010206904044390628 Test RE 0.015270563956520678\n",
      "81 Train Loss 0.003661782 Test MSE 0.0008576948646727638 Test RE 0.013998273197800403\n",
      "82 Train Loss 0.0034067393 Test MSE 0.0008813837154409408 Test RE 0.014190267139467175\n",
      "83 Train Loss 0.0032395292 Test MSE 0.0008256926590668669 Test RE 0.01373463972924895\n",
      "84 Train Loss 0.0031299281 Test MSE 0.0007934206063646177 Test RE 0.013463556526872198\n",
      "85 Train Loss 0.00297495 Test MSE 0.0008396513985966279 Test RE 0.013850248582689403\n",
      "86 Train Loss 0.0027584727 Test MSE 0.0007449748978167833 Test RE 0.013046045231803555\n",
      "87 Train Loss 0.0026369276 Test MSE 0.0006852184018123266 Test RE 0.012511879960034836\n",
      "88 Train Loss 0.0025170215 Test MSE 0.0006421737947346537 Test RE 0.012112515614614683\n",
      "89 Train Loss 0.0023601223 Test MSE 0.0006384052796660937 Test RE 0.012076922942951747\n",
      "90 Train Loss 0.002255302 Test MSE 0.0005595514889503662 Test RE 0.011306497424430744\n",
      "91 Train Loss 0.0021383294 Test MSE 0.0004872351863120625 Test RE 0.01055060544373486\n",
      "92 Train Loss 0.0020365096 Test MSE 0.0004476740596478286 Test RE 0.010113209997050175\n",
      "93 Train Loss 0.0019531958 Test MSE 0.00047921003426449585 Test RE 0.010463356243662323\n",
      "94 Train Loss 0.0018868484 Test MSE 0.0005154149058462111 Test RE 0.010851419360102461\n",
      "95 Train Loss 0.0017730116 Test MSE 0.0005813358044262826 Test RE 0.011524486838278792\n",
      "96 Train Loss 0.0016533935 Test MSE 0.0006201161518901049 Test RE 0.011902675178773898\n",
      "97 Train Loss 0.0015935097 Test MSE 0.0006492602192787409 Test RE 0.012179163404730669\n",
      "98 Train Loss 0.0014966797 Test MSE 0.0005635896226051469 Test RE 0.011347222067924687\n",
      "99 Train Loss 0.0014338659 Test MSE 0.0006164971213801451 Test RE 0.011867892035955946\n",
      "Training time: 83.68\n",
      "1\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.681328 Test MSE 8.257769634754144 Test RE 1.3735340874591717\n",
      "1 Train Loss 55.37556 Test MSE 8.732724858201966 Test RE 1.4124820869312145\n",
      "2 Train Loss 51.093224 Test MSE 9.618253096308232 Test RE 1.4823684420572973\n",
      "3 Train Loss 44.819195 Test MSE 8.676059225601774 Test RE 1.4078919128151495\n",
      "4 Train Loss 42.84179 Test MSE 8.385493521947117 Test RE 1.3841156340168697\n",
      "5 Train Loss 41.791496 Test MSE 8.488535008355072 Test RE 1.3925937199099676\n",
      "6 Train Loss 40.094208 Test MSE 8.711586359367194 Test RE 1.410771518820521\n",
      "7 Train Loss 37.870674 Test MSE 8.978604975354504 Test RE 1.432229097186601\n",
      "8 Train Loss 34.719097 Test MSE 8.811785413476962 Test RE 1.4188615393127941\n",
      "9 Train Loss 31.373867 Test MSE 8.972516285427 Test RE 1.4317433937949668\n",
      "10 Train Loss 28.167286 Test MSE 8.760323596908624 Test RE 1.4147123170819051\n",
      "11 Train Loss 25.838654 Test MSE 8.620723827222783 Test RE 1.4033950049474795\n",
      "12 Train Loss 23.542038 Test MSE 8.635068117658161 Test RE 1.404562095952989\n",
      "13 Train Loss 21.280064 Test MSE 8.506309435540544 Test RE 1.3940509567386197\n",
      "14 Train Loss 19.508097 Test MSE 8.411631642353536 Test RE 1.386271144150542\n",
      "15 Train Loss 17.850986 Test MSE 8.355497557614331 Test RE 1.381637838386288\n",
      "16 Train Loss 16.353024 Test MSE 8.118875022578436 Test RE 1.361933769208986\n",
      "17 Train Loss 15.18668 Test MSE 8.072369377259315 Test RE 1.358027527874707\n",
      "18 Train Loss 14.159891 Test MSE 8.181848966144287 Test RE 1.3672054768413722\n",
      "19 Train Loss 13.405497 Test MSE 8.172460559765337 Test RE 1.3664208397149384\n",
      "20 Train Loss 12.300179 Test MSE 8.03913717182464 Test RE 1.355229291606379\n",
      "21 Train Loss 10.789369 Test MSE 7.799172549461564 Test RE 1.3348495661874382\n",
      "22 Train Loss 8.962112 Test MSE 6.874593780872438 Test RE 1.2532323032308479\n",
      "23 Train Loss 7.9778385 Test MSE 7.160612106157653 Test RE 1.2790370782000777\n",
      "24 Train Loss 6.230046 Test MSE 6.694912793034617 Test RE 1.2367460228987943\n",
      "25 Train Loss 5.0865602 Test MSE 6.653495101789636 Test RE 1.2329145590095543\n",
      "26 Train Loss 4.4170027 Test MSE 6.602361151873713 Test RE 1.228167776658064\n",
      "27 Train Loss 4.1412697 Test MSE 6.647772970832622 Test RE 1.2323842801150418\n",
      "28 Train Loss 3.8650856 Test MSE 6.8880087945990205 Test RE 1.2544544797931099\n",
      "29 Train Loss 3.695865 Test MSE 6.952242735082904 Test RE 1.2602900971223616\n",
      "30 Train Loss 3.5811198 Test MSE 6.992202386333554 Test RE 1.2639068145490884\n",
      "31 Train Loss 3.4466524 Test MSE 6.902565307317731 Test RE 1.2557793071699404\n",
      "32 Train Loss 3.3201904 Test MSE 6.977663727915405 Test RE 1.2625921306858299\n",
      "33 Train Loss 3.2456608 Test MSE 6.9843062280992 Test RE 1.263192960258342\n",
      "34 Train Loss 3.1716619 Test MSE 6.979801153729756 Test RE 1.2627854970102248\n",
      "35 Train Loss 3.1009302 Test MSE 7.036457174681426 Test RE 1.2679002418500132\n",
      "36 Train Loss 3.0472703 Test MSE 7.0169894125009 Test RE 1.2661450775565597\n",
      "37 Train Loss 3.0054963 Test MSE 7.105725250369086 Test RE 1.2741256706445925\n",
      "38 Train Loss 2.9502435 Test MSE 7.052841911745845 Test RE 1.2693755675847436\n",
      "39 Train Loss 2.9064484 Test MSE 7.118510765472481 Test RE 1.275271439099174\n",
      "40 Train Loss 2.8598564 Test MSE 7.124792163557173 Test RE 1.2758339669577201\n",
      "41 Train Loss 2.8120902 Test MSE 7.174464187518776 Test RE 1.2802736181229686\n",
      "42 Train Loss 2.77711 Test MSE 7.165031396694221 Test RE 1.2794317067958676\n",
      "43 Train Loss 2.7099917 Test MSE 7.150953468482824 Test RE 1.2781741684236196\n",
      "44 Train Loss 2.656434 Test MSE 7.243421777339787 Test RE 1.2864115997616303\n",
      "45 Train Loss 2.6182878 Test MSE 7.266057024511782 Test RE 1.288420010476452\n",
      "46 Train Loss 2.574592 Test MSE 7.316286214617033 Test RE 1.2928656702594055\n",
      "47 Train Loss 2.5332243 Test MSE 7.3269974627366246 Test RE 1.293811719917671\n",
      "48 Train Loss 2.4845679 Test MSE 7.319876827188948 Test RE 1.2931828810800694\n",
      "49 Train Loss 2.4539406 Test MSE 7.275384135430091 Test RE 1.2892466887066945\n",
      "50 Train Loss 2.430313 Test MSE 7.302190198500398 Test RE 1.2916196117226997\n",
      "51 Train Loss 2.4035897 Test MSE 7.335473419538387 Test RE 1.294559851922119\n",
      "52 Train Loss 2.3745914 Test MSE 7.370614279449074 Test RE 1.2976569658503634\n",
      "53 Train Loss 2.3442729 Test MSE 7.395420753613993 Test RE 1.2998388229805387\n",
      "54 Train Loss 2.3062282 Test MSE 7.401910219368845 Test RE 1.3004090008068223\n",
      "55 Train Loss 2.275359 Test MSE 7.400869044391076 Test RE 1.3003175378676273\n",
      "56 Train Loss 2.2497516 Test MSE 7.389969290818119 Test RE 1.2993596528595908\n",
      "57 Train Loss 2.213855 Test MSE 7.377880738220601 Test RE 1.2982964680410043\n",
      "58 Train Loss 2.1829038 Test MSE 7.384368709148908 Test RE 1.2988671914660725\n",
      "59 Train Loss 2.1544397 Test MSE 7.3703325368758685 Test RE 1.2976321640704351\n",
      "60 Train Loss 2.122145 Test MSE 7.384405738073975 Test RE 1.2988704480474749\n",
      "61 Train Loss 2.0983348 Test MSE 7.3677273556006275 Test RE 1.2974028076755253\n",
      "62 Train Loss 2.0736473 Test MSE 7.3649517630076975 Test RE 1.2971584038951043\n",
      "63 Train Loss 2.0469112 Test MSE 7.345487968472181 Test RE 1.2954432312508615\n",
      "64 Train Loss 2.020709 Test MSE 7.301290441188387 Test RE 1.2915400342288446\n",
      "65 Train Loss 1.9945138 Test MSE 7.343538716432747 Test RE 1.2952713357337575\n",
      "66 Train Loss 1.9767687 Test MSE 7.370635482244387 Test RE 1.2976588323118414\n",
      "67 Train Loss 1.9616367 Test MSE 7.3525435216406665 Test RE 1.296065237226681\n",
      "68 Train Loss 1.943321 Test MSE 7.3677559811402835 Test RE 1.2974053280469817\n",
      "69 Train Loss 1.9230806 Test MSE 7.351556896738778 Test RE 1.2959782759503364\n",
      "70 Train Loss 1.8958328 Test MSE 7.368601961128552 Test RE 1.297479811203202\n",
      "71 Train Loss 1.8713158 Test MSE 7.32190054753989 Test RE 1.2933616313321536\n",
      "72 Train Loss 1.8465372 Test MSE 7.34204686110245 Test RE 1.295139760503367\n",
      "73 Train Loss 1.82733 Test MSE 7.349214992736231 Test RE 1.2957718367903124\n",
      "74 Train Loss 1.810585 Test MSE 7.354098828527179 Test RE 1.2962023103764777\n",
      "75 Train Loss 1.7972437 Test MSE 7.3606309475115195 Test RE 1.2967778444157485\n",
      "76 Train Loss 1.7865446 Test MSE 7.366773889658693 Test RE 1.2973188557759565\n",
      "77 Train Loss 1.7739911 Test MSE 7.365450286400809 Test RE 1.2972023045808894\n",
      "78 Train Loss 1.7495947 Test MSE 7.363619109374502 Test RE 1.2970410412075506\n",
      "79 Train Loss 1.7302399 Test MSE 7.357955216766912 Test RE 1.2965421211627688\n",
      "80 Train Loss 1.7134829 Test MSE 7.335617433052676 Test RE 1.2945725595681046\n",
      "81 Train Loss 1.6946201 Test MSE 7.28140850160383 Test RE 1.2897803572265856\n",
      "82 Train Loss 1.6684318 Test MSE 7.292549655991314 Test RE 1.2907667151269837\n",
      "83 Train Loss 1.6467077 Test MSE 7.2887318997132216 Test RE 1.2904288032799827\n",
      "84 Train Loss 1.6305898 Test MSE 7.283864119540441 Test RE 1.2899978248218076\n",
      "85 Train Loss 1.6146111 Test MSE 7.247882551750694 Test RE 1.286807649371501\n",
      "86 Train Loss 1.5941663 Test MSE 7.246898653083341 Test RE 1.2867203044612432\n",
      "87 Train Loss 1.5758945 Test MSE 7.216566157448647 Test RE 1.2840246434743392\n",
      "88 Train Loss 1.5543768 Test MSE 7.195999433389853 Test RE 1.282193646419064\n",
      "89 Train Loss 1.5345685 Test MSE 7.0713444257467195 Test RE 1.2710395248867399\n",
      "90 Train Loss 1.5145037 Test MSE 7.05359994490674 Test RE 1.2694437814290644\n",
      "91 Train Loss 1.5002395 Test MSE 7.052876438536233 Test RE 1.269378674659243\n",
      "92 Train Loss 1.4771783 Test MSE 7.023872501398838 Test RE 1.266765917384737\n",
      "93 Train Loss 1.4643376 Test MSE 7.009194333811344 Test RE 1.265441610408161\n",
      "94 Train Loss 1.4492126 Test MSE 7.020359476083042 Test RE 1.266449088077231\n",
      "95 Train Loss 1.4340997 Test MSE 6.988963111685301 Test RE 1.2636140158457234\n",
      "96 Train Loss 1.421439 Test MSE 6.938088915090611 Test RE 1.2590065539550561\n",
      "97 Train Loss 1.4100071 Test MSE 6.902876781697855 Test RE 1.2558076400180505\n",
      "98 Train Loss 1.3995624 Test MSE 6.877789143754312 Test RE 1.2535235252932497\n",
      "99 Train Loss 1.3853321 Test MSE 6.831351007150839 Test RE 1.2492845258265717\n",
      "Training time: 80.62\n",
      "2\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.075012 Test MSE 8.087803825443379 Test RE 1.3593251887580782\n",
      "1 Train Loss 52.04374 Test MSE 8.559748550264114 Test RE 1.3984230180260957\n",
      "2 Train Loss 42.570198 Test MSE 7.347636667309423 Test RE 1.2956326886325977\n",
      "3 Train Loss 33.823463 Test MSE 7.143030141726008 Test RE 1.2774658573920359\n",
      "4 Train Loss 30.526367 Test MSE 5.77677504472154 Test RE 1.148816827136851\n",
      "5 Train Loss 27.258663 Test MSE 5.0288809176923746 Test RE 1.071873999070019\n",
      "6 Train Loss 24.29108 Test MSE 5.813537086211693 Test RE 1.1524664304614145\n",
      "7 Train Loss 21.780571 Test MSE 6.021595576982586 Test RE 1.172907740258972\n",
      "8 Train Loss 19.194445 Test MSE 5.6898706537934896 Test RE 1.1401428214204214\n",
      "9 Train Loss 17.788063 Test MSE 5.554485545960515 Test RE 1.1264968477006203\n",
      "10 Train Loss 15.983752 Test MSE 5.643005719264415 Test RE 1.1354376881419281\n",
      "11 Train Loss 14.044189 Test MSE 5.830701002356939 Test RE 1.1541664504433962\n",
      "12 Train Loss 12.0178795 Test MSE 5.910329438435649 Test RE 1.162020807470307\n",
      "13 Train Loss 11.269234 Test MSE 5.925580918419427 Test RE 1.1635191265437346\n",
      "14 Train Loss 10.062591 Test MSE 5.828350522902559 Test RE 1.1539337924847697\n",
      "15 Train Loss 9.546568 Test MSE 5.783617119817371 Test RE 1.149496961369671\n",
      "16 Train Loss 9.209829 Test MSE 5.7263573567356 Test RE 1.1437926033848915\n",
      "17 Train Loss 8.880089 Test MSE 5.570245053958343 Test RE 1.1280937968042817\n",
      "18 Train Loss 8.612499 Test MSE 5.614710810648359 Test RE 1.1325874801954885\n",
      "19 Train Loss 8.350833 Test MSE 5.585045148844709 Test RE 1.1295914705661099\n",
      "20 Train Loss 8.139254 Test MSE 5.543477205281398 Test RE 1.1253800015650977\n",
      "21 Train Loss 7.8539147 Test MSE 5.4445785268679225 Test RE 1.1152961249808104\n",
      "22 Train Loss 7.460064 Test MSE 5.321566971037844 Test RE 1.1026249776998955\n",
      "23 Train Loss 6.984357 Test MSE 5.1664673105702255 Test RE 1.0864378894850077\n",
      "24 Train Loss 6.5847893 Test MSE 4.986991152965339 Test RE 1.0674003949592954\n",
      "25 Train Loss 6.239051 Test MSE 4.786324591788761 Test RE 1.0457048783977607\n",
      "26 Train Loss 5.875025 Test MSE 4.54024531421347 Test RE 1.0184687776093722\n",
      "27 Train Loss 5.6181517 Test MSE 4.388966740663795 Test RE 1.001357615789469\n",
      "28 Train Loss 5.3989 Test MSE 4.252950845245256 Test RE 0.9857192590372506\n",
      "29 Train Loss 5.1316204 Test MSE 3.9057506708296024 Test RE 0.944626920745221\n",
      "30 Train Loss 4.9389834 Test MSE 3.67093068397594 Test RE 0.9157905385215361\n",
      "31 Train Loss 4.7143707 Test MSE 3.4561522196141596 Test RE 0.888596280902178\n",
      "32 Train Loss 4.4550614 Test MSE 3.3183651305549913 Test RE 0.8707032105886223\n",
      "33 Train Loss 3.8486109 Test MSE 3.005806814554767 Test RE 0.8286833110768854\n",
      "34 Train Loss 3.4110298 Test MSE 2.702306240245085 Test RE 0.7857336311968358\n",
      "35 Train Loss 3.036712 Test MSE 2.565997177600527 Test RE 0.7656603321508574\n",
      "36 Train Loss 2.609845 Test MSE 2.4678231516229894 Test RE 0.7508705607938521\n",
      "37 Train Loss 2.2611911 Test MSE 2.193830202901397 Test RE 0.7079613779542246\n",
      "38 Train Loss 1.9920084 Test MSE 1.895192683392603 Test RE 0.6580134121183433\n",
      "39 Train Loss 1.8235795 Test MSE 1.7620698137182125 Test RE 0.6344824530109717\n",
      "40 Train Loss 1.5606698 Test MSE 1.4237640729751009 Test RE 0.5703311275794847\n",
      "41 Train Loss 1.4225361 Test MSE 1.3669946420495407 Test RE 0.5588451245780258\n",
      "42 Train Loss 1.238012 Test MSE 1.0382541883108616 Test RE 0.48703470160843937\n",
      "43 Train Loss 0.95610446 Test MSE 0.5782888840487286 Test RE 0.3634799690799428\n",
      "44 Train Loss 0.7452701 Test MSE 0.44490621430326915 Test RE 0.3188176059071982\n",
      "45 Train Loss 0.5289439 Test MSE 0.24391094122665208 Test RE 0.23606070582116673\n",
      "46 Train Loss 0.37753797 Test MSE 0.10349016866015415 Test RE 0.15376504074083092\n",
      "47 Train Loss 0.2668492 Test MSE 0.04219322832889361 Test RE 0.09818144920053283\n",
      "48 Train Loss 0.16658588 Test MSE 0.028268885559741355 Test RE 0.080364158980526\n",
      "49 Train Loss 0.116638705 Test MSE 0.01670408135892589 Test RE 0.06177593944670786\n",
      "50 Train Loss 0.09701983 Test MSE 0.016396747245767937 Test RE 0.061205001277504015\n",
      "51 Train Loss 0.08420201 Test MSE 0.018477531384779172 Test RE 0.06497256833907158\n",
      "52 Train Loss 0.067118995 Test MSE 0.01393143880308665 Test RE 0.05641648784341123\n",
      "53 Train Loss 0.0544515 Test MSE 0.01157703652007223 Test RE 0.05142884393077887\n",
      "54 Train Loss 0.047532655 Test MSE 0.010923832983483183 Test RE 0.04995691207636721\n",
      "55 Train Loss 0.0411126 Test MSE 0.012019790644892437 Test RE 0.05240304362148822\n",
      "56 Train Loss 0.0356587 Test MSE 0.01165730049314137 Test RE 0.05160681492294098\n",
      "57 Train Loss 0.031614345 Test MSE 0.011679780135970852 Test RE 0.05165654959470842\n",
      "58 Train Loss 0.027341856 Test MSE 0.010128706089438276 Test RE 0.048104426886006725\n",
      "59 Train Loss 0.025100628 Test MSE 0.010457150928426183 Test RE 0.04887814871344895\n",
      "60 Train Loss 0.023730133 Test MSE 0.009059632997671124 Test RE 0.04549496787936021\n",
      "61 Train Loss 0.021711797 Test MSE 0.00702748242686293 Test RE 0.04006894838044317\n",
      "62 Train Loss 0.020043744 Test MSE 0.005899606125594927 Test RE 0.03671297421061095\n",
      "63 Train Loss 0.01877776 Test MSE 0.005708246622328363 Test RE 0.03611265546185455\n",
      "64 Train Loss 0.017117346 Test MSE 0.005070924561130436 Test RE 0.034037028251850364\n",
      "65 Train Loss 0.016490404 Test MSE 0.005048923158278314 Test RE 0.033963109146234245\n",
      "66 Train Loss 0.015471365 Test MSE 0.004381034841132245 Test RE 0.031637081535969586\n",
      "67 Train Loss 0.014780059 Test MSE 0.0042416840568506135 Test RE 0.031129863666685006\n",
      "68 Train Loss 0.013668878 Test MSE 0.004079711625627671 Test RE 0.03052971803760392\n",
      "69 Train Loss 0.013231742 Test MSE 0.0037337268257291592 Test RE 0.029206487523842316\n",
      "70 Train Loss 0.012016756 Test MSE 0.0033015502425205057 Test RE 0.027464203957060142\n",
      "71 Train Loss 0.011095435 Test MSE 0.0026385732143124957 Test RE 0.02455232560609755\n",
      "72 Train Loss 0.010377832 Test MSE 0.0022922743374543166 Test RE 0.02288449622971055\n",
      "73 Train Loss 0.009385306 Test MSE 0.0022970972585745013 Test RE 0.022908557949764746\n",
      "74 Train Loss 0.00889008 Test MSE 0.0019360952865419925 Test RE 0.02103155693779828\n",
      "75 Train Loss 0.008657534 Test MSE 0.001802350286765609 Test RE 0.020292131137199278\n",
      "76 Train Loss 0.007975476 Test MSE 0.001221845499312064 Test RE 0.016707682243252198\n",
      "77 Train Loss 0.0076254783 Test MSE 0.0012753991705176627 Test RE 0.017069905835568347\n",
      "78 Train Loss 0.0071470146 Test MSE 0.001231902395272316 Test RE 0.016776301018422004\n",
      "79 Train Loss 0.006811907 Test MSE 0.0011767103259718605 Test RE 0.016396186233746682\n",
      "80 Train Loss 0.006578737 Test MSE 0.0010036088358386563 Test RE 0.01514224603350885\n",
      "81 Train Loss 0.0061973277 Test MSE 0.0009395483808811237 Test RE 0.014651012352524133\n",
      "82 Train Loss 0.0060767257 Test MSE 0.0008568302254448906 Test RE 0.013991215613262168\n",
      "83 Train Loss 0.0059006494 Test MSE 0.0009245152919831217 Test RE 0.014533329158367974\n",
      "84 Train Loss 0.005259042 Test MSE 0.000912598724889236 Test RE 0.014439361489350001\n",
      "85 Train Loss 0.004599372 Test MSE 0.0010129413453800762 Test RE 0.015212486623516791\n",
      "86 Train Loss 0.004211798 Test MSE 0.00094094077077775 Test RE 0.014661864571274764\n",
      "87 Train Loss 0.0038464046 Test MSE 0.0009538471009093526 Test RE 0.01476207618434222\n",
      "88 Train Loss 0.0037319034 Test MSE 0.0009357301855899264 Test RE 0.014621212197024253\n",
      "89 Train Loss 0.003627388 Test MSE 0.0009646306553516419 Test RE 0.014845286722124137\n",
      "90 Train Loss 0.0034750658 Test MSE 0.0009294673721468804 Test RE 0.01457220038823228\n",
      "91 Train Loss 0.0031817248 Test MSE 0.0007325282324905245 Test RE 0.01293660280305722\n",
      "92 Train Loss 0.0030332226 Test MSE 0.0006463987670261773 Test RE 0.012152295458224879\n",
      "93 Train Loss 0.0029399358 Test MSE 0.0005976683914155201 Test RE 0.011685255273808752\n",
      "94 Train Loss 0.0028113616 Test MSE 0.0005569684176863726 Test RE 0.01128037000568808\n",
      "95 Train Loss 0.002628162 Test MSE 0.0005396333590920836 Test RE 0.011103437563978911\n",
      "96 Train Loss 0.002542393 Test MSE 0.000561162599876481 Test RE 0.011322763066143528\n",
      "97 Train Loss 0.0024773057 Test MSE 0.0005165561538128082 Test RE 0.010863426494906353\n",
      "98 Train Loss 0.0024290304 Test MSE 0.000493848595062836 Test RE 0.010621967580726352\n",
      "99 Train Loss 0.002394224 Test MSE 0.0004760221619202111 Test RE 0.010428495221800832\n",
      "Training time: 82.08\n",
      "3\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.25081 Test MSE 8.90538405075581 Test RE 1.426377196005675\n",
      "1 Train Loss 47.429047 Test MSE 8.88900774931306 Test RE 1.4250650947292778\n",
      "2 Train Loss 43.10328 Test MSE 8.543189629998144 Test RE 1.3970697314766356\n",
      "3 Train Loss 42.189404 Test MSE 8.562318018636848 Test RE 1.3986328918374349\n",
      "4 Train Loss 40.841118 Test MSE 8.416515842366575 Test RE 1.386673553768928\n",
      "5 Train Loss 39.864243 Test MSE 8.371285804666643 Test RE 1.3829425688668031\n",
      "6 Train Loss 38.188293 Test MSE 8.354867234026118 Test RE 1.3815857232765116\n",
      "7 Train Loss 35.936123 Test MSE 7.993385511012901 Test RE 1.351367405719631\n",
      "8 Train Loss 32.654564 Test MSE 7.887484910400197 Test RE 1.3423857428702177\n",
      "9 Train Loss 29.717499 Test MSE 7.864156822099283 Test RE 1.3403991474982897\n",
      "10 Train Loss 26.954979 Test MSE 7.6926347624297495 Test RE 1.3257011006133845\n",
      "11 Train Loss 24.997341 Test MSE 7.957008735677313 Test RE 1.3482889576514696\n",
      "12 Train Loss 22.322727 Test MSE 7.504631908331563 Test RE 1.3094012707559015\n",
      "13 Train Loss 20.341507 Test MSE 7.84211230180576 Test RE 1.3385191498556628\n",
      "14 Train Loss 18.45095 Test MSE 8.34274261839337 Test RE 1.3805828780395482\n",
      "15 Train Loss 17.474339 Test MSE 8.538747118821943 Test RE 1.3967064418138175\n",
      "16 Train Loss 16.509794 Test MSE 8.462743604483604 Test RE 1.3904764952715332\n",
      "17 Train Loss 15.823309 Test MSE 8.436471622629503 Test RE 1.3883165001983098\n",
      "18 Train Loss 15.308613 Test MSE 8.427265977091949 Test RE 1.3875588470903866\n",
      "19 Train Loss 15.032656 Test MSE 8.462610171401172 Test RE 1.3904655333243898\n",
      "20 Train Loss 14.854431 Test MSE 8.409774906025055 Test RE 1.386118136853096\n",
      "21 Train Loss 14.694326 Test MSE 8.465417847906823 Test RE 1.3906961745553241\n",
      "22 Train Loss 14.508945 Test MSE 8.620879239293432 Test RE 1.4034076549026957\n",
      "23 Train Loss 14.366415 Test MSE 8.610002628123317 Test RE 1.402522064431971\n",
      "24 Train Loss 14.217171 Test MSE 8.614279357479596 Test RE 1.4028703490305825\n",
      "25 Train Loss 14.065754 Test MSE 8.628921095869938 Test RE 1.4040620761049039\n",
      "26 Train Loss 13.931309 Test MSE 8.570538726677789 Test RE 1.3993041466426335\n",
      "27 Train Loss 13.7192955 Test MSE 8.526383552759572 Test RE 1.3956949042021558\n",
      "28 Train Loss 13.525118 Test MSE 8.538621650867107 Test RE 1.3966961802062259\n",
      "29 Train Loss 13.344148 Test MSE 8.447013892331187 Test RE 1.3891836540377995\n",
      "30 Train Loss 13.216387 Test MSE 8.559917178122706 Test RE 1.3984367924913261\n",
      "31 Train Loss 13.024771 Test MSE 8.568383629543 Test RE 1.3991282051965541\n",
      "32 Train Loss 12.849897 Test MSE 8.457881587977951 Test RE 1.390077009520846\n",
      "33 Train Loss 11.624529 Test MSE 7.552733187634024 Test RE 1.3135909015504286\n",
      "34 Train Loss 10.234631 Test MSE 7.383588844564401 Test RE 1.2987986028494882\n",
      "35 Train Loss 9.275701 Test MSE 7.007366105151769 Test RE 1.2652765652268614\n",
      "36 Train Loss 8.833078 Test MSE 7.014481469065568 Test RE 1.2659187907666454\n",
      "37 Train Loss 8.478007 Test MSE 6.935398575482826 Test RE 1.2587624317149317\n",
      "38 Train Loss 8.038204 Test MSE 7.058934204849701 Test RE 1.2699236968914518\n",
      "39 Train Loss 7.794044 Test MSE 7.078390468801179 Test RE 1.2716726130839184\n",
      "40 Train Loss 7.5529804 Test MSE 7.1247465028208135 Test RE 1.2758298787253617\n",
      "41 Train Loss 7.2605023 Test MSE 7.0730400531697795 Test RE 1.2711919061145014\n",
      "42 Train Loss 7.054426 Test MSE 6.963575728563151 Test RE 1.2613168912118218\n",
      "43 Train Loss 6.8459377 Test MSE 6.810814043237277 Test RE 1.2474052619071443\n",
      "44 Train Loss 6.6954336 Test MSE 6.783693094194988 Test RE 1.2449191743055723\n",
      "45 Train Loss 6.6063375 Test MSE 6.722622472810634 Test RE 1.2393027738617874\n",
      "46 Train Loss 6.443231 Test MSE 6.66940956376951 Test RE 1.234388179463081\n",
      "47 Train Loss 6.334231 Test MSE 6.617663407499507 Test RE 1.2295902117463424\n",
      "48 Train Loss 6.2572813 Test MSE 6.603528764228423 Test RE 1.2282763711776117\n",
      "49 Train Loss 6.1891084 Test MSE 6.722196223423532 Test RE 1.2392634841036851\n",
      "50 Train Loss 6.1312466 Test MSE 6.605167419087811 Test RE 1.2284287591105105\n",
      "51 Train Loss 6.071925 Test MSE 6.652699607478826 Test RE 1.2328408529483295\n",
      "52 Train Loss 5.9804006 Test MSE 6.660354033976377 Test RE 1.2335498866794095\n",
      "53 Train Loss 5.8969955 Test MSE 6.672361854851919 Test RE 1.2346613573189287\n",
      "54 Train Loss 5.833066 Test MSE 6.687073390404172 Test RE 1.236021727439066\n",
      "55 Train Loss 5.773984 Test MSE 6.687532283554079 Test RE 1.236064137035923\n",
      "56 Train Loss 5.70936 Test MSE 6.667452068192552 Test RE 1.2342070174948947\n",
      "57 Train Loss 5.6437297 Test MSE 6.638580492065047 Test RE 1.2315319205818651\n",
      "58 Train Loss 5.5875344 Test MSE 6.623480532888762 Test RE 1.2301305164455918\n",
      "59 Train Loss 5.5027575 Test MSE 6.614260164395398 Test RE 1.2292740025128912\n",
      "60 Train Loss 5.417076 Test MSE 6.51173962505083 Test RE 1.2197099696433797\n",
      "61 Train Loss 5.3216667 Test MSE 6.518084487046071 Test RE 1.2203040510758105\n",
      "62 Train Loss 5.1737003 Test MSE 6.576133399872297 Test RE 1.2257259128092342\n",
      "63 Train Loss 5.010667 Test MSE 6.522878837602229 Test RE 1.2207527634216815\n",
      "64 Train Loss 4.8279614 Test MSE 6.641288946298004 Test RE 1.2317831194414477\n",
      "65 Train Loss 4.5418215 Test MSE 6.566708536348223 Test RE 1.2248472474234549\n",
      "66 Train Loss 3.6700385 Test MSE 5.735102466016766 Test RE 1.1446656518773985\n",
      "67 Train Loss 2.6918402 Test MSE 5.778326165977166 Test RE 1.1489710511271893\n",
      "68 Train Loss 2.2771528 Test MSE 5.7418091836177165 Test RE 1.145334751186927\n",
      "69 Train Loss 1.9863011 Test MSE 5.969080557140688 Test RE 1.1677820093691396\n",
      "70 Train Loss 1.7973443 Test MSE 5.957675398834969 Test RE 1.1666658318699614\n",
      "71 Train Loss 1.6537137 Test MSE 5.966243384895132 Test RE 1.167504446311645\n",
      "72 Train Loss 1.5782728 Test MSE 6.039412672324582 Test RE 1.1746416970766604\n",
      "73 Train Loss 1.5033349 Test MSE 6.0315563397874925 Test RE 1.1738774357645514\n",
      "74 Train Loss 1.4542472 Test MSE 6.049319862493054 Test RE 1.1756047567855188\n",
      "75 Train Loss 1.419029 Test MSE 5.995323352814946 Test RE 1.1703462447583521\n",
      "76 Train Loss 1.3950334 Test MSE 5.987986704948311 Test RE 1.1696299325393094\n",
      "77 Train Loss 1.3522464 Test MSE 6.016260135115511 Test RE 1.1723879969599638\n",
      "78 Train Loss 1.3282243 Test MSE 5.977845658326785 Test RE 1.168639090501984\n",
      "79 Train Loss 1.2995577 Test MSE 5.959455253426202 Test RE 1.1668400894732434\n",
      "80 Train Loss 1.2750901 Test MSE 5.956071132873374 Test RE 1.1665087430583092\n",
      "81 Train Loss 1.2533672 Test MSE 5.938069852080257 Test RE 1.1647446152248422\n",
      "82 Train Loss 1.23419 Test MSE 5.922097555772318 Test RE 1.1631770879377112\n",
      "83 Train Loss 1.2167401 Test MSE 5.92416455522771 Test RE 1.163380063034647\n",
      "84 Train Loss 1.1930794 Test MSE 5.943824366179556 Test RE 1.1653088487574152\n",
      "85 Train Loss 1.1756397 Test MSE 5.9538130333676955 Test RE 1.1662875953866567\n",
      "86 Train Loss 1.1604717 Test MSE 6.000155901374564 Test RE 1.1708178303156331\n",
      "87 Train Loss 1.1402621 Test MSE 5.99759463478425 Test RE 1.1705679120860746\n",
      "88 Train Loss 1.1264882 Test MSE 5.9761209624190075 Test RE 1.1684704936050458\n",
      "89 Train Loss 1.1076198 Test MSE 6.007246822337658 Test RE 1.1715094561188182\n",
      "90 Train Loss 1.0907091 Test MSE 6.023795403840093 Test RE 1.173121965733554\n",
      "91 Train Loss 1.0775366 Test MSE 5.99176169880172 Test RE 1.1699985581186236\n",
      "92 Train Loss 1.0676401 Test MSE 6.008113744600474 Test RE 1.171593984940424\n",
      "93 Train Loss 1.0533917 Test MSE 5.978874032960291 Test RE 1.1687396072418657\n",
      "94 Train Loss 1.03947 Test MSE 5.972107689195163 Test RE 1.1680780836345326\n",
      "95 Train Loss 1.0287733 Test MSE 5.990020926205512 Test RE 1.1698285872919294\n",
      "96 Train Loss 1.0176513 Test MSE 5.974008857386711 Test RE 1.1682639925552532\n",
      "97 Train Loss 1.007438 Test MSE 5.98426468634393 Test RE 1.169266366178089\n",
      "98 Train Loss 0.9975289 Test MSE 5.9817464885598675 Test RE 1.1690203247720274\n",
      "99 Train Loss 0.9842979 Test MSE 5.9761371841415505 Test RE 1.168472079465791\n",
      "Training time: 81.78\n",
      "4\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.898254 Test MSE 8.544324234455525 Test RE 1.397162499458356\n",
      "1 Train Loss 55.625965 Test MSE 8.746624728706033 Test RE 1.4136057632203443\n",
      "2 Train Loss 49.96186 Test MSE 8.142157345200994 Test RE 1.3638851652499195\n",
      "3 Train Loss 44.260223 Test MSE 8.23371276640038 Test RE 1.3715319106728723\n",
      "4 Train Loss 39.944893 Test MSE 7.667135297190081 Test RE 1.3235020666968238\n",
      "5 Train Loss 34.942883 Test MSE 6.994612231186563 Test RE 1.264124596928315\n",
      "6 Train Loss 27.437622 Test MSE 5.309808888257379 Test RE 1.1014061707946323\n",
      "7 Train Loss 20.437088 Test MSE 5.343729400655285 Test RE 1.104918612145073\n",
      "8 Train Loss 15.762209 Test MSE 5.0651602446503405 Test RE 1.0757334049092293\n",
      "9 Train Loss 11.173765 Test MSE 4.085805584166976 Test RE 0.9661552299147141\n",
      "10 Train Loss 8.756137 Test MSE 3.56960104683736 Test RE 0.9030626913361456\n",
      "11 Train Loss 7.391063 Test MSE 3.2381455386749867 Test RE 0.860114447012955\n",
      "12 Train Loss 5.9244323 Test MSE 2.7858751046768013 Test RE 0.7977905385812589\n",
      "13 Train Loss 4.8292184 Test MSE 2.122558443921468 Test RE 0.6963665296437894\n",
      "14 Train Loss 3.5815873 Test MSE 1.873095423968182 Test RE 0.6541660656874081\n",
      "15 Train Loss 2.7706246 Test MSE 1.7455675872571979 Test RE 0.6315044203217264\n",
      "16 Train Loss 2.149319 Test MSE 1.4153694430667547 Test RE 0.568647282302775\n",
      "17 Train Loss 1.7182088 Test MSE 1.137653143082015 Test RE 0.5098154536676136\n",
      "18 Train Loss 1.4283493 Test MSE 0.9156810163706868 Test RE 0.4573831546706783\n",
      "19 Train Loss 1.0548977 Test MSE 0.5499484767360722 Test RE 0.35446149267620813\n",
      "20 Train Loss 0.6730304 Test MSE 0.32529277225224157 Test RE 0.27261218716994456\n",
      "21 Train Loss 0.54480577 Test MSE 0.28530057717763474 Test RE 0.2553050382793039\n",
      "22 Train Loss 0.41619664 Test MSE 0.20586858385914372 Test RE 0.21687180737392242\n",
      "23 Train Loss 0.3096199 Test MSE 0.16935236873418535 Test RE 0.19669970021971497\n",
      "24 Train Loss 0.23334369 Test MSE 0.11404512743935008 Test RE 0.16141594302705098\n",
      "25 Train Loss 0.18882532 Test MSE 0.09333605529510842 Test RE 0.1460268716446165\n",
      "26 Train Loss 0.16618183 Test MSE 0.05807956564209475 Test RE 0.11519131607123556\n",
      "27 Train Loss 0.14121081 Test MSE 0.049756880422457093 Test RE 0.10661900670690423\n",
      "28 Train Loss 0.11936937 Test MSE 0.05154035815113279 Test RE 0.10851300149559276\n",
      "29 Train Loss 0.10157001 Test MSE 0.04394124804693145 Test RE 0.10019458578922105\n",
      "30 Train Loss 0.09126842 Test MSE 0.039661333363437204 Test RE 0.09519008520313497\n",
      "31 Train Loss 0.077504225 Test MSE 0.03163618628715632 Test RE 0.08501589327387715\n",
      "32 Train Loss 0.06686123 Test MSE 0.03540157608189549 Test RE 0.08993305756844615\n",
      "33 Train Loss 0.0615975 Test MSE 0.033780050174623565 Test RE 0.08784927979819103\n",
      "34 Train Loss 0.058995746 Test MSE 0.03286041147750667 Test RE 0.08664521006240013\n",
      "35 Train Loss 0.05466392 Test MSE 0.027539425021138125 Test RE 0.07932050940020198\n",
      "36 Train Loss 0.04857304 Test MSE 0.028937451447311177 Test RE 0.0813089214248463\n",
      "37 Train Loss 0.04415115 Test MSE 0.02880847448730843 Test RE 0.08112751828707204\n",
      "38 Train Loss 0.040996864 Test MSE 0.029189240156091763 Test RE 0.08166189527270118\n",
      "39 Train Loss 0.038336396 Test MSE 0.02805882469196657 Test RE 0.0800650166147023\n",
      "40 Train Loss 0.0360115 Test MSE 0.02740192488018482 Test RE 0.07912224402192986\n",
      "41 Train Loss 0.031559784 Test MSE 0.022862051502759814 Test RE 0.07227126553439599\n",
      "42 Train Loss 0.029043483 Test MSE 0.021910568069519198 Test RE 0.07075137411798015\n",
      "43 Train Loss 0.026326437 Test MSE 0.022938935895344792 Test RE 0.07239268658397258\n",
      "44 Train Loss 0.02368784 Test MSE 0.02131382936406258 Test RE 0.06978125928737232\n",
      "45 Train Loss 0.022307396 Test MSE 0.019146591394688557 Test RE 0.0661384168236261\n",
      "46 Train Loss 0.020955434 Test MSE 0.018611409434334415 Test RE 0.0652075213045449\n",
      "47 Train Loss 0.019196657 Test MSE 0.015597869188680637 Test RE 0.05969537671175594\n",
      "48 Train Loss 0.017403997 Test MSE 0.01345034931836736 Test RE 0.055433824435738285\n",
      "49 Train Loss 0.01562945 Test MSE 0.011890992353618868 Test RE 0.052121524537947835\n",
      "50 Train Loss 0.014608665 Test MSE 0.011619602824422407 Test RE 0.051523303651248055\n",
      "51 Train Loss 0.01400576 Test MSE 0.01151835882857346 Test RE 0.05129834596800789\n",
      "52 Train Loss 0.012681128 Test MSE 0.010336655309142852 Test RE 0.048595726308394455\n",
      "53 Train Loss 0.011735447 Test MSE 0.010010019930765428 Test RE 0.04782175733753843\n",
      "54 Train Loss 0.010601129 Test MSE 0.008383881305612259 Test RE 0.04376537165775488\n",
      "55 Train Loss 0.009602053 Test MSE 0.007865358145533075 Test RE 0.042390380190849675\n",
      "56 Train Loss 0.008675058 Test MSE 0.006901401532336686 Test RE 0.03970788068686846\n",
      "57 Train Loss 0.008280747 Test MSE 0.006393323084113945 Test RE 0.038218301853670755\n",
      "58 Train Loss 0.0079734335 Test MSE 0.0062802863286404095 Test RE 0.03787893696672991\n",
      "59 Train Loss 0.0074146125 Test MSE 0.005739409120356574 Test RE 0.03621109451969042\n",
      "60 Train Loss 0.006975257 Test MSE 0.005419859389369148 Test RE 0.035188606606368696\n",
      "61 Train Loss 0.0066323467 Test MSE 0.005114014978525586 Test RE 0.034181337946396544\n",
      "62 Train Loss 0.006382904 Test MSE 0.005209570744429519 Test RE 0.034499200470145305\n",
      "63 Train Loss 0.006075401 Test MSE 0.005293480764733267 Test RE 0.0347759281525783\n",
      "64 Train Loss 0.0057334956 Test MSE 0.005511113420056712 Test RE 0.03548360489414189\n",
      "65 Train Loss 0.0050616344 Test MSE 0.005489264781995099 Test RE 0.035413198218564985\n",
      "66 Train Loss 0.004735003 Test MSE 0.00507334536007845 Test RE 0.03404515171826424\n",
      "67 Train Loss 0.004505025 Test MSE 0.0051718851438256955 Test RE 0.034374191813723344\n",
      "68 Train Loss 0.0042510917 Test MSE 0.0055064452574689095 Test RE 0.03546857360047097\n",
      "69 Train Loss 0.003987928 Test MSE 0.004963586174161786 Test RE 0.03367486345135422\n",
      "70 Train Loss 0.0037312384 Test MSE 0.00491880690544178 Test RE 0.0335226194773131\n",
      "71 Train Loss 0.0034302347 Test MSE 0.004400732643521062 Test RE 0.03170812434821693\n",
      "72 Train Loss 0.003280244 Test MSE 0.0041631885387203105 Test RE 0.030840477950592225\n",
      "73 Train Loss 0.0031389075 Test MSE 0.004082271966217485 Test RE 0.03053929643718207\n",
      "74 Train Loss 0.0029916172 Test MSE 0.003932424080022819 Test RE 0.029973553508422818\n",
      "75 Train Loss 0.0028628942 Test MSE 0.0037655026561922004 Test RE 0.02933050492464941\n",
      "76 Train Loss 0.002735876 Test MSE 0.003538892297019518 Test RE 0.02843424708712834\n",
      "77 Train Loss 0.0026092476 Test MSE 0.003484333080972952 Test RE 0.028214209863071688\n",
      "78 Train Loss 0.0025440059 Test MSE 0.003488794442380374 Test RE 0.028232266908348735\n",
      "79 Train Loss 0.0024151849 Test MSE 0.003308971875368904 Test RE 0.02749505534560565\n",
      "80 Train Loss 0.0023485362 Test MSE 0.003373838352985083 Test RE 0.027763243090497658\n",
      "81 Train Loss 0.0022967737 Test MSE 0.0033853570976896626 Test RE 0.02781059645817686\n",
      "82 Train Loss 0.0021898053 Test MSE 0.0034351568029961253 Test RE 0.028014401151153057\n",
      "83 Train Loss 0.0020883272 Test MSE 0.0034716146796149004 Test RE 0.028162669483327876\n",
      "84 Train Loss 0.0019986194 Test MSE 0.003594486516095931 Test RE 0.028656720619376807\n",
      "85 Train Loss 0.0019147678 Test MSE 0.003830658820044207 Test RE 0.029583175965452048\n",
      "86 Train Loss 0.0018441345 Test MSE 0.003863984117528698 Test RE 0.02971157858380208\n",
      "87 Train Loss 0.0017848476 Test MSE 0.0037515784440328836 Test RE 0.02927622499667512\n",
      "88 Train Loss 0.0017418849 Test MSE 0.003738604453566554 Test RE 0.029225558533554866\n",
      "89 Train Loss 0.0016938891 Test MSE 0.0036170960746738775 Test RE 0.02874670567482999\n",
      "90 Train Loss 0.0016577416 Test MSE 0.003619024101980668 Test RE 0.028754366108586567\n",
      "91 Train Loss 0.0016069444 Test MSE 0.0036922708990249128 Test RE 0.029043893725694436\n",
      "92 Train Loss 0.0015658054 Test MSE 0.003723243732611785 Test RE 0.029165457534985503\n",
      "93 Train Loss 0.001514915 Test MSE 0.0038057376596692095 Test RE 0.02948678914234356\n",
      "94 Train Loss 0.0014906274 Test MSE 0.0036450033508869553 Test RE 0.028857388495862397\n",
      "95 Train Loss 0.001429501 Test MSE 0.003770404471955652 Test RE 0.029349589491201387\n",
      "96 Train Loss 0.0013791597 Test MSE 0.003549053341210188 Test RE 0.028475038742057777\n",
      "97 Train Loss 0.0013389415 Test MSE 0.00353215586122131 Test RE 0.02840717128140398\n",
      "98 Train Loss 0.0012885716 Test MSE 0.0034434633516259574 Test RE 0.02804825149539599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0012722465 Test MSE 0.003508174368595919 Test RE 0.028310572113036836\n",
      "Training time: 84.12\n",
      "5\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.935394 Test MSE 8.5120391263544 Test RE 1.394520381018314\n",
      "1 Train Loss 57.77583 Test MSE 8.595190298355963 Test RE 1.4013151215953947\n",
      "2 Train Loss 57.590416 Test MSE 8.563358845070887 Test RE 1.3987178974308665\n",
      "3 Train Loss 57.288887 Test MSE 8.412076302698722 Test RE 1.386307784584023\n",
      "4 Train Loss 53.52716 Test MSE 8.646307772834872 Test RE 1.405475908074747\n",
      "5 Train Loss 47.538208 Test MSE 10.07752493755722 Test RE 1.5173473168414695\n",
      "6 Train Loss 44.000507 Test MSE 9.000982840058775 Test RE 1.4340127976482222\n",
      "7 Train Loss 43.609756 Test MSE 9.1364501261688 Test RE 1.4447636429126658\n",
      "8 Train Loss 42.811764 Test MSE 8.878405092776829 Test RE 1.4242149444966739\n",
      "9 Train Loss 42.142242 Test MSE 9.04954939349278 Test RE 1.4378763405041892\n",
      "10 Train Loss 41.403915 Test MSE 8.955491314502856 Test RE 1.4303844125083538\n",
      "11 Train Loss 40.494347 Test MSE 8.993628229354591 Test RE 1.4334268193544943\n",
      "12 Train Loss 39.66883 Test MSE 8.795443148935187 Test RE 1.4175452242693078\n",
      "13 Train Loss 38.804573 Test MSE 8.934019443238608 Test RE 1.4286686238075317\n",
      "14 Train Loss 38.19085 Test MSE 9.1460481396205 Test RE 1.445522319463711\n",
      "15 Train Loss 37.32213 Test MSE 8.849361460766435 Test RE 1.4218835427279934\n",
      "16 Train Loss 36.338524 Test MSE 8.855510106805399 Test RE 1.4223774281089938\n",
      "17 Train Loss 35.285072 Test MSE 8.997837216118821 Test RE 1.433762199505506\n",
      "18 Train Loss 34.377228 Test MSE 8.900674007843909 Test RE 1.425999941845574\n",
      "19 Train Loss 32.942356 Test MSE 8.78981294525682 Test RE 1.4170914469078524\n",
      "20 Train Loss 31.074348 Test MSE 8.952690343730035 Test RE 1.4301607074031364\n",
      "21 Train Loss 29.753153 Test MSE 8.872011174434837 Test RE 1.42370201711475\n",
      "22 Train Loss 27.826492 Test MSE 8.523242248074995 Test RE 1.3954377783758214\n",
      "23 Train Loss 25.526413 Test MSE 8.417503484562204 Test RE 1.3867549114924762\n",
      "24 Train Loss 22.357477 Test MSE 7.98604086035175 Test RE 1.3507464171227186\n",
      "25 Train Loss 20.600447 Test MSE 8.0217618267963 Test RE 1.3537639406983404\n",
      "26 Train Loss 18.13347 Test MSE 7.833869482764278 Test RE 1.3378155083195264\n",
      "27 Train Loss 16.198872 Test MSE 7.5267975060500625 Test RE 1.3113335615579844\n",
      "28 Train Loss 14.606059 Test MSE 7.56633961219048 Test RE 1.314773601410104\n",
      "29 Train Loss 13.468173 Test MSE 7.500827262008817 Test RE 1.3090693130821967\n",
      "30 Train Loss 12.781328 Test MSE 7.322303584636299 Test RE 1.2933972276599035\n",
      "31 Train Loss 11.984539 Test MSE 7.237778432099383 Test RE 1.2859103808934602\n",
      "32 Train Loss 10.996859 Test MSE 7.017373886688763 Test RE 1.266179764329177\n",
      "33 Train Loss 10.387938 Test MSE 6.903448934942521 Test RE 1.2558596835030003\n",
      "34 Train Loss 9.623895 Test MSE 6.674778616170713 Test RE 1.2348849371943873\n",
      "35 Train Loss 8.559149 Test MSE 6.4512891074546355 Test RE 1.2140352942345054\n",
      "36 Train Loss 7.669235 Test MSE 6.228922395717947 Test RE 1.1929287912091375\n",
      "37 Train Loss 6.616128 Test MSE 6.006795267310415 Test RE 1.1714654250558845\n",
      "38 Train Loss 6.1004014 Test MSE 5.909010024523017 Test RE 1.161891096257736\n",
      "39 Train Loss 5.70569 Test MSE 5.931989450104301 Test RE 1.164148131052999\n",
      "40 Train Loss 5.4910336 Test MSE 5.907582109001935 Test RE 1.1617507019645361\n",
      "41 Train Loss 5.208316 Test MSE 5.8981814341916765 Test RE 1.1608259929606684\n",
      "42 Train Loss 4.9204574 Test MSE 6.05393219010496 Test RE 1.1760528436150224\n",
      "43 Train Loss 4.7071576 Test MSE 6.05036169134904 Test RE 1.1757059852093428\n",
      "44 Train Loss 4.471845 Test MSE 6.1464256557738715 Test RE 1.1850028006527327\n",
      "45 Train Loss 4.342123 Test MSE 6.087936564983668 Test RE 1.179351108389631\n",
      "46 Train Loss 4.175749 Test MSE 6.039701079992673 Test RE 1.1746697438128813\n",
      "47 Train Loss 4.037168 Test MSE 6.079145647516523 Test RE 1.178499315378853\n",
      "48 Train Loss 3.934864 Test MSE 6.009622553270414 Test RE 1.1717410860332567\n",
      "49 Train Loss 3.8067093 Test MSE 5.947612942042322 Test RE 1.1656801717831686\n",
      "50 Train Loss 3.7287438 Test MSE 5.9183335393217025 Test RE 1.162807378256303\n",
      "51 Train Loss 3.6121922 Test MSE 5.853425220459259 Test RE 1.1564133522668723\n",
      "52 Train Loss 3.4986706 Test MSE 5.944921278601213 Test RE 1.165416370674634\n",
      "53 Train Loss 3.4327931 Test MSE 5.944852127554158 Test RE 1.1654095926204882\n",
      "54 Train Loss 3.357707 Test MSE 5.9572426341669535 Test RE 1.1666234578828976\n",
      "55 Train Loss 3.2769873 Test MSE 5.916105980608434 Test RE 1.1625885273361363\n",
      "56 Train Loss 3.206515 Test MSE 5.731816780690683 Test RE 1.1443377109216342\n",
      "57 Train Loss 3.1223598 Test MSE 5.735236308455144 Test RE 1.1446790085653606\n",
      "58 Train Loss 3.0487459 Test MSE 5.709020747729189 Test RE 1.1420598686662329\n",
      "59 Train Loss 2.9983037 Test MSE 5.679731506895947 Test RE 1.1391265215114599\n",
      "60 Train Loss 2.9444685 Test MSE 5.538277296950383 Test RE 1.124852061648456\n",
      "61 Train Loss 2.8376584 Test MSE 5.574990901928804 Test RE 1.128574262361784\n",
      "62 Train Loss 2.7846398 Test MSE 5.495794008012893 Test RE 1.1205294710418918\n",
      "63 Train Loss 2.7057073 Test MSE 5.36430074990477 Test RE 1.107043329902728\n",
      "64 Train Loss 2.6510105 Test MSE 5.447734254647263 Test RE 1.1156192961041806\n",
      "65 Train Loss 2.5990064 Test MSE 5.398531451327142 Test RE 1.1105698480677992\n",
      "66 Train Loss 2.5465748 Test MSE 5.405362408807841 Test RE 1.111272248082134\n",
      "67 Train Loss 2.477813 Test MSE 5.469105715483637 Test RE 1.1178054413243\n",
      "68 Train Loss 2.4505405 Test MSE 5.486606772953902 Test RE 1.119592493278193\n",
      "69 Train Loss 2.386553 Test MSE 5.385389687841859 Test RE 1.109217282154744\n",
      "70 Train Loss 2.3133004 Test MSE 5.378554141836134 Test RE 1.1085131071853807\n",
      "71 Train Loss 2.2727802 Test MSE 5.350692719216612 Test RE 1.1056382776529665\n",
      "72 Train Loss 2.2307181 Test MSE 5.38661325001797 Test RE 1.1093432822503828\n",
      "73 Train Loss 2.1554863 Test MSE 5.389228812133531 Test RE 1.1096125798579868\n",
      "74 Train Loss 2.1222572 Test MSE 5.408438569359989 Test RE 1.1115884124182858\n",
      "75 Train Loss 2.0876276 Test MSE 5.400701027344858 Test RE 1.1107929850169969\n",
      "76 Train Loss 2.0624473 Test MSE 5.442968119358161 Test RE 1.1151311706066453\n",
      "77 Train Loss 2.0329132 Test MSE 5.464026871867732 Test RE 1.1172862999920674\n",
      "78 Train Loss 1.9833587 Test MSE 5.497413235814988 Test RE 1.1206945298892428\n",
      "79 Train Loss 1.9341011 Test MSE 5.50027570907069 Test RE 1.120986261700107\n",
      "80 Train Loss 1.9097319 Test MSE 5.506565961643092 Test RE 1.1216270724734425\n",
      "81 Train Loss 1.8816495 Test MSE 5.48675795015611 Test RE 1.1196079177200973\n",
      "82 Train Loss 1.8586456 Test MSE 5.4697634714448675 Test RE 1.1178726571659414\n",
      "83 Train Loss 1.8319535 Test MSE 5.479711727776021 Test RE 1.1188887734752127\n",
      "84 Train Loss 1.8086492 Test MSE 5.473928940457039 Test RE 1.1182982311188565\n",
      "85 Train Loss 1.788044 Test MSE 5.4825373237111314 Test RE 1.1191772120167223\n",
      "86 Train Loss 1.7513163 Test MSE 5.523682897012777 Test RE 1.1233689858274487\n",
      "87 Train Loss 1.7271591 Test MSE 5.5435648049645 Test RE 1.1253888933254852\n",
      "88 Train Loss 1.701225 Test MSE 5.523923128363255 Test RE 1.1233934138693389\n",
      "89 Train Loss 1.6869117 Test MSE 5.5425303256930905 Test RE 1.12528388455941\n",
      "90 Train Loss 1.6617073 Test MSE 5.566316073203517 Test RE 1.1276958752922823\n",
      "91 Train Loss 1.6491344 Test MSE 5.567817237704506 Test RE 1.1278479276437423\n",
      "92 Train Loss 1.6281749 Test MSE 5.5377608938230605 Test RE 1.1247996183856408\n",
      "93 Train Loss 1.61017 Test MSE 5.556999498060065 Test RE 1.1267517442818904\n",
      "94 Train Loss 1.5887412 Test MSE 5.5665699858773054 Test RE 1.1277215954459576\n",
      "95 Train Loss 1.5737724 Test MSE 5.558144678090614 Test RE 1.12686783814933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 1.564528 Test MSE 5.564343973174179 Test RE 1.1274960909057736\n",
      "97 Train Loss 1.5437387 Test MSE 5.564616245587943 Test RE 1.1275236756784277\n",
      "98 Train Loss 1.5280367 Test MSE 5.590746023630917 Test RE 1.130167832698961\n",
      "99 Train Loss 1.515414 Test MSE 5.595845178469804 Test RE 1.1306831116352953\n",
      "Training time: 83.08\n",
      "6\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.114464 Test MSE 8.389804998658919 Test RE 1.3844714160249607\n",
      "1 Train Loss 58.783607 Test MSE 8.60844189344498 Test RE 1.402394941124057\n",
      "2 Train Loss 58.428467 Test MSE 8.200045673927255 Test RE 1.368724987973424\n",
      "3 Train Loss 55.47139 Test MSE 8.496883234753943 Test RE 1.3932783392622825\n",
      "4 Train Loss 50.320038 Test MSE 8.950815403209885 Test RE 1.4300109419937654\n",
      "5 Train Loss 46.959465 Test MSE 8.5209239182182 Test RE 1.395247985279063\n",
      "6 Train Loss 46.44976 Test MSE 8.480905569246907 Test RE 1.3919677522131846\n",
      "7 Train Loss 45.822083 Test MSE 8.48997368427762 Test RE 1.392711726501784\n",
      "8 Train Loss 45.2594 Test MSE 8.38791742831953 Test RE 1.3843156654333553\n",
      "9 Train Loss 44.547134 Test MSE 8.327952238019847 Test RE 1.3793585561979729\n",
      "10 Train Loss 43.85388 Test MSE 8.420143379692087 Test RE 1.3869723512926064\n",
      "11 Train Loss 43.612934 Test MSE 8.256538634898291 Test RE 1.3734317061046093\n",
      "12 Train Loss 43.556927 Test MSE 8.294511645348722 Test RE 1.3765863881787117\n",
      "13 Train Loss 43.291817 Test MSE 8.31844839307639 Test RE 1.3785712707013493\n",
      "14 Train Loss 43.0939 Test MSE 8.456975009865456 Test RE 1.3900025081726095\n",
      "15 Train Loss 42.714844 Test MSE 8.339963930210772 Test RE 1.3803529459305754\n",
      "16 Train Loss 42.405457 Test MSE 8.526926925511722 Test RE 1.3957393761927905\n",
      "17 Train Loss 41.945877 Test MSE 8.67823181465569 Test RE 1.4080681782724922\n",
      "18 Train Loss 41.71769 Test MSE 8.705652955107366 Test RE 1.4102910033791851\n",
      "19 Train Loss 41.578087 Test MSE 8.765679862081798 Test RE 1.4151447449658745\n",
      "20 Train Loss 41.29048 Test MSE 8.82535215256437 Test RE 1.4199533680383536\n",
      "21 Train Loss 40.864998 Test MSE 8.779065715721698 Test RE 1.4162248491011564\n",
      "22 Train Loss 40.227028 Test MSE 9.078002406187048 Test RE 1.4401350057864912\n",
      "23 Train Loss 39.16593 Test MSE 9.16679123680122 Test RE 1.447160602336536\n",
      "24 Train Loss 38.469227 Test MSE 9.308875805333969 Test RE 1.458332916060763\n",
      "25 Train Loss 37.060036 Test MSE 9.096331476631672 Test RE 1.4415881352443591\n",
      "26 Train Loss 34.446934 Test MSE 9.240941896287659 Test RE 1.4530018928547839\n",
      "27 Train Loss 31.010612 Test MSE 9.034612519762984 Test RE 1.4366891959194792\n",
      "28 Train Loss 27.59 Test MSE 7.95797632783123 Test RE 1.3483709328133626\n",
      "29 Train Loss 19.598822 Test MSE 4.890348471174643 Test RE 1.057007243911456\n",
      "30 Train Loss 12.181773 Test MSE 4.289464027349007 Test RE 0.9899416010404537\n",
      "31 Train Loss 7.9614315 Test MSE 3.65930088993624 Test RE 0.9143387399150795\n",
      "32 Train Loss 6.138464 Test MSE 3.6698666977318983 Test RE 0.9156578120777576\n",
      "33 Train Loss 5.1539755 Test MSE 3.5843997579472346 Test RE 0.904932696021523\n",
      "34 Train Loss 4.5712934 Test MSE 3.6492116705196995 Test RE 0.9130773881070043\n",
      "35 Train Loss 4.139781 Test MSE 3.7797063280259904 Test RE 0.9292596700844621\n",
      "36 Train Loss 3.8483837 Test MSE 3.81089910446868 Test RE 0.9330862413272085\n",
      "37 Train Loss 3.3910863 Test MSE 3.9508550355033654 Test RE 0.9500656312497804\n",
      "38 Train Loss 3.0654132 Test MSE 3.906656870134085 Test RE 0.9447364989907019\n",
      "39 Train Loss 2.84851 Test MSE 3.985386914725167 Test RE 0.9542085541744548\n",
      "40 Train Loss 2.7239723 Test MSE 3.91660182045116 Test RE 0.9459382152088538\n",
      "41 Train Loss 2.5451796 Test MSE 3.976477804488569 Test RE 0.9531414174498671\n",
      "42 Train Loss 2.445786 Test MSE 3.9462152721176893 Test RE 0.9495076033508518\n",
      "43 Train Loss 2.3175673 Test MSE 3.9912135198623915 Test RE 0.9549058222153999\n",
      "44 Train Loss 2.2219853 Test MSE 4.015038888289902 Test RE 0.9577517149667079\n",
      "45 Train Loss 2.147922 Test MSE 3.947686966615016 Test RE 0.9496846406838887\n",
      "46 Train Loss 2.0590801 Test MSE 4.0423685642012765 Test RE 0.961005812050715\n",
      "47 Train Loss 1.9475083 Test MSE 4.121564136073186 Test RE 0.9703738655533585\n",
      "48 Train Loss 1.8954066 Test MSE 4.16433168731001 Test RE 0.9753954313634514\n",
      "49 Train Loss 1.8317406 Test MSE 4.217408695792065 Test RE 0.9815917618649185\n",
      "50 Train Loss 1.7653432 Test MSE 4.252786112431658 Test RE 0.9857001685415809\n",
      "51 Train Loss 1.6870394 Test MSE 4.276765752631397 Test RE 0.9884752328184577\n",
      "52 Train Loss 1.595227 Test MSE 4.322471160402653 Test RE 0.9937430685884924\n",
      "53 Train Loss 1.5097194 Test MSE 4.351774111309861 Test RE 0.9971057768467717\n",
      "54 Train Loss 1.4685626 Test MSE 4.374475266804838 Test RE 0.9997031095469116\n",
      "55 Train Loss 1.3803504 Test MSE 4.373560016981125 Test RE 0.9995985226075574\n",
      "56 Train Loss 1.296922 Test MSE 4.448628428439459 Test RE 1.0081406501926735\n",
      "57 Train Loss 1.2385231 Test MSE 4.47442622078553 Test RE 1.011059550635807\n",
      "58 Train Loss 1.1855531 Test MSE 4.5456155777563865 Test RE 1.0190709289238704\n",
      "59 Train Loss 1.0940082 Test MSE 4.595906466357033 Test RE 1.0246927207452168\n",
      "60 Train Loss 1.0474001 Test MSE 4.62051808958774 Test RE 1.0274327327867132\n",
      "61 Train Loss 0.98820263 Test MSE 4.62538363113542 Test RE 1.0279735489047823\n",
      "62 Train Loss 0.9118688 Test MSE 4.662772458589467 Test RE 1.0321199473695468\n",
      "63 Train Loss 0.86986125 Test MSE 4.6529013999395 Test RE 1.0310268729826049\n",
      "64 Train Loss 0.83476746 Test MSE 4.682722561985835 Test RE 1.0343256009613966\n",
      "65 Train Loss 0.80574894 Test MSE 4.657772121047506 Test RE 1.0315663783766738\n",
      "66 Train Loss 0.77804697 Test MSE 4.677739293982434 Test RE 1.0337750992374477\n",
      "67 Train Loss 0.73674214 Test MSE 4.743879652478133 Test RE 1.04105791820593\n",
      "68 Train Loss 0.7117262 Test MSE 4.70362719249929 Test RE 1.0366317504794498\n",
      "69 Train Loss 0.6845126 Test MSE 4.723110550160293 Test RE 1.0387764990396016\n",
      "70 Train Loss 0.65608275 Test MSE 4.739295621944258 Test RE 1.0405548073503923\n",
      "71 Train Loss 0.63876384 Test MSE 4.800918790042688 Test RE 1.04729791793137\n",
      "72 Train Loss 0.6071294 Test MSE 4.778310407915635 Test RE 1.0448290516542635\n",
      "73 Train Loss 0.59100634 Test MSE 4.808777620076987 Test RE 1.0481547508852826\n",
      "74 Train Loss 0.5758045 Test MSE 4.78974267872346 Test RE 1.0460781995344377\n",
      "75 Train Loss 0.5694107 Test MSE 4.802903969163995 Test RE 1.0475144243097965\n",
      "76 Train Loss 0.5532751 Test MSE 4.755550367248126 Test RE 1.0423377173802257\n",
      "77 Train Loss 0.5448286 Test MSE 4.762513150021911 Test RE 1.0431005014918484\n",
      "78 Train Loss 0.5307744 Test MSE 4.751968319833187 Test RE 1.0419450807565314\n",
      "79 Train Loss 0.52477586 Test MSE 4.7408743922363925 Test RE 1.0407281094987986\n",
      "80 Train Loss 0.5179095 Test MSE 4.757461157927236 Test RE 1.0425471031521092\n",
      "81 Train Loss 0.5075553 Test MSE 4.770390281638069 Test RE 1.0439627820708977\n",
      "82 Train Loss 0.5022075 Test MSE 4.741562787487664 Test RE 1.0408036658438735\n",
      "83 Train Loss 0.49172017 Test MSE 4.702732864620592 Test RE 1.0365331953953805\n",
      "84 Train Loss 0.48447785 Test MSE 4.688236745721014 Test RE 1.0349344116774921\n",
      "85 Train Loss 0.47251874 Test MSE 4.678549885415078 Test RE 1.0338646652528785\n",
      "86 Train Loss 0.4658327 Test MSE 4.6429603696145 Test RE 1.0299248778035421\n",
      "87 Train Loss 0.4592143 Test MSE 4.637744292696809 Test RE 1.0293461869870897\n",
      "88 Train Loss 0.45594904 Test MSE 4.633128863830798 Test RE 1.028833862848809\n",
      "89 Train Loss 0.4492615 Test MSE 4.662944837666431 Test RE 1.0321390255297083\n",
      "90 Train Loss 0.44296646 Test MSE 4.660335747060737 Test RE 1.0318502250897486\n",
      "91 Train Loss 0.43559006 Test MSE 4.67801976386875 Test RE 1.0338060905369126\n",
      "92 Train Loss 0.43140918 Test MSE 4.661771801753045 Test RE 1.03200919209385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 0.4217577 Test MSE 4.652237915866716 Test RE 1.0309533603247878\n",
      "94 Train Loss 0.41725084 Test MSE 4.649128449069476 Test RE 1.0306087679866285\n",
      "95 Train Loss 0.41245288 Test MSE 4.653754998185168 Test RE 1.0311214421872978\n",
      "96 Train Loss 0.4079423 Test MSE 4.650777442155018 Test RE 1.0307915243980992\n",
      "97 Train Loss 0.40590823 Test MSE 4.657412209998541 Test RE 1.0315265224863364\n",
      "98 Train Loss 0.3992846 Test MSE 4.634231915451176 Test RE 1.0289563275324436\n",
      "99 Train Loss 0.3922034 Test MSE 4.613764565244857 Test RE 1.0266815909026243\n",
      "Training time: 85.49\n",
      "7\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.5328 Test MSE 8.611152175714526 Test RE 1.4026156887965253\n",
      "1 Train Loss 53.89947 Test MSE 8.444015620598094 Test RE 1.388937086445619\n",
      "2 Train Loss 42.75671 Test MSE 6.984579952770734 Test RE 1.26321771316\n",
      "3 Train Loss 34.410786 Test MSE 6.916972549081317 Test RE 1.257089174183737\n",
      "4 Train Loss 27.855192 Test MSE 5.916085431440437 Test RE 1.1625865082506275\n",
      "5 Train Loss 24.43679 Test MSE 5.914203685528432 Test RE 1.162401599967639\n",
      "6 Train Loss 23.06456 Test MSE 5.445028943976057 Test RE 1.1153422569324167\n",
      "7 Train Loss 21.448418 Test MSE 5.512556565107757 Test RE 1.1222370167293314\n",
      "8 Train Loss 18.509464 Test MSE 5.487406800270934 Test RE 1.1196741167630093\n",
      "9 Train Loss 15.40572 Test MSE 5.586367973072281 Test RE 1.1297252351513927\n",
      "10 Train Loss 13.2988615 Test MSE 5.632022004696402 Test RE 1.1343321250210228\n",
      "11 Train Loss 11.724318 Test MSE 5.53480097749107 Test RE 1.124498977222151\n",
      "12 Train Loss 10.509965 Test MSE 5.281097224756477 Test RE 1.098424324467531\n",
      "13 Train Loss 9.849697 Test MSE 5.114175122748826 Test RE 1.0809257379006676\n",
      "14 Train Loss 9.248898 Test MSE 4.961110219860287 Test RE 1.0646270540430305\n",
      "15 Train Loss 8.821602 Test MSE 4.81546150655967 Test RE 1.0488829312288288\n",
      "16 Train Loss 8.414656 Test MSE 4.604513609592678 Test RE 1.0256517863406176\n",
      "17 Train Loss 7.836877 Test MSE 4.478948092186536 Test RE 1.01157031185239\n",
      "18 Train Loss 7.094234 Test MSE 4.3827563102161085 Test RE 1.0006488996281278\n",
      "19 Train Loss 6.270529 Test MSE 4.318786426785728 Test RE 0.9933194151912947\n",
      "20 Train Loss 5.3643265 Test MSE 4.174598055444883 Test RE 0.9765970172555157\n",
      "21 Train Loss 4.502207 Test MSE 3.9514355626961057 Test RE 0.9501354286316097\n",
      "22 Train Loss 3.4747562 Test MSE 3.45327608202552 Test RE 0.8882264683290033\n",
      "23 Train Loss 3.0251803 Test MSE 3.0577391638120814 Test RE 0.8358113764873003\n",
      "24 Train Loss 2.4508588 Test MSE 2.596725139893023 Test RE 0.7702311021004367\n",
      "25 Train Loss 1.9246086 Test MSE 2.0499791473814346 Test RE 0.6843571073782627\n",
      "26 Train Loss 1.6014986 Test MSE 1.6451900082581667 Test RE 0.6130785081090018\n",
      "27 Train Loss 1.1689191 Test MSE 1.1983421540791106 Test RE 0.5232370382028837\n",
      "28 Train Loss 0.90937984 Test MSE 0.8511181148126463 Test RE 0.4409638394114518\n",
      "29 Train Loss 0.6492498 Test MSE 0.4749950901277404 Test RE 0.32942201589404346\n",
      "30 Train Loss 0.4136466 Test MSE 0.29238817831304 Test RE 0.2584568012325797\n",
      "31 Train Loss 0.31588808 Test MSE 0.16154696968589885 Test RE 0.19211331597984205\n",
      "32 Train Loss 0.21002628 Test MSE 0.08296430432004263 Test RE 0.13767456032695885\n",
      "33 Train Loss 0.16147986 Test MSE 0.0594447920827992 Test RE 0.11653730391027543\n",
      "34 Train Loss 0.11496001 Test MSE 0.036199889061536074 Test RE 0.09094140929669306\n",
      "35 Train Loss 0.09243881 Test MSE 0.02705867395875843 Test RE 0.07862511888398424\n",
      "36 Train Loss 0.07492283 Test MSE 0.02646598578480228 Test RE 0.07775925619995669\n",
      "37 Train Loss 0.06438584 Test MSE 0.025280376575173808 Test RE 0.07599759163916905\n",
      "38 Train Loss 0.055090975 Test MSE 0.02448708812688085 Test RE 0.07479570023636514\n",
      "39 Train Loss 0.04971618 Test MSE 0.020339422466437513 Test RE 0.06816750031334323\n",
      "40 Train Loss 0.04203188 Test MSE 0.018480988905002157 Test RE 0.06497864689622346\n",
      "41 Train Loss 0.037264366 Test MSE 0.015197516115993761 Test RE 0.05892429112906689\n",
      "42 Train Loss 0.034805685 Test MSE 0.014259250150033811 Test RE 0.057076377833870984\n",
      "43 Train Loss 0.027732646 Test MSE 0.010813367275403381 Test RE 0.049703679168543444\n",
      "44 Train Loss 0.025305124 Test MSE 0.01029984122819339 Test RE 0.048509112085411164\n",
      "45 Train Loss 0.02239427 Test MSE 0.009250999043454713 Test RE 0.04597295061174884\n",
      "46 Train Loss 0.019996116 Test MSE 0.008243488951004518 Test RE 0.04339738793658479\n",
      "47 Train Loss 0.018094495 Test MSE 0.006483056778593681 Test RE 0.038485574403884074\n",
      "48 Train Loss 0.017158866 Test MSE 0.005941672504222293 Test RE 0.03684363027548148\n",
      "49 Train Loss 0.016109422 Test MSE 0.005606767918462774 Test RE 0.03579021852815999\n",
      "50 Train Loss 0.014644951 Test MSE 0.0052944296994705455 Test RE 0.034779045062689626\n",
      "51 Train Loss 0.013618125 Test MSE 0.004762135266896501 Test RE 0.03298442547402204\n",
      "52 Train Loss 0.01267277 Test MSE 0.004129719466748699 Test RE 0.030716260047623303\n",
      "53 Train Loss 0.0116883265 Test MSE 0.0032728918811589782 Test RE 0.027344745749156286\n",
      "54 Train Loss 0.011168597 Test MSE 0.0030813130111412576 Test RE 0.02653236536740098\n",
      "55 Train Loss 0.010409045 Test MSE 0.0029788391636864082 Test RE 0.02608744748260885\n",
      "56 Train Loss 0.009528691 Test MSE 0.002549941351104873 Test RE 0.024136436768282477\n",
      "57 Train Loss 0.008768402 Test MSE 0.0025138186006369734 Test RE 0.023964867270003798\n",
      "58 Train Loss 0.008226972 Test MSE 0.002597107241118652 Test RE 0.024358638030162107\n",
      "59 Train Loss 0.0077592116 Test MSE 0.0027846047929558013 Test RE 0.025222599470696418\n",
      "60 Train Loss 0.007414176 Test MSE 0.002616527882787515 Test RE 0.024449542884224632\n",
      "61 Train Loss 0.0066732476 Test MSE 0.002196387710448898 Test RE 0.022400750185018737\n",
      "62 Train Loss 0.0063479873 Test MSE 0.0020157388115529667 Test RE 0.02145977623735546\n",
      "63 Train Loss 0.006037234 Test MSE 0.0019974146838781827 Test RE 0.0213620132153404\n",
      "64 Train Loss 0.005583895 Test MSE 0.0019490148500538262 Test RE 0.02110161205058106\n",
      "65 Train Loss 0.0053055314 Test MSE 0.001829720852993965 Test RE 0.020445629148858196\n",
      "66 Train Loss 0.005029235 Test MSE 0.0017754780517312489 Test RE 0.02014028974940056\n",
      "67 Train Loss 0.0048427796 Test MSE 0.0018482410222813782 Test RE 0.020548842476350474\n",
      "68 Train Loss 0.0047289785 Test MSE 0.0019874414891550645 Test RE 0.02130861565986146\n",
      "69 Train Loss 0.004464429 Test MSE 0.001884263520308998 Test RE 0.02074812617399622\n",
      "70 Train Loss 0.0042054965 Test MSE 0.0019140602334570649 Test RE 0.020911532465415664\n",
      "71 Train Loss 0.004068601 Test MSE 0.0017979123580664819 Test RE 0.020267133073337232\n",
      "72 Train Loss 0.0039238296 Test MSE 0.0017686746414538788 Test RE 0.020101665174554383\n",
      "73 Train Loss 0.0036681108 Test MSE 0.001820516602242282 Test RE 0.020394139338685117\n",
      "74 Train Loss 0.0034318527 Test MSE 0.0015017333054929297 Test RE 0.018522707413165515\n",
      "75 Train Loss 0.0032883065 Test MSE 0.0014197365033949225 Test RE 0.01800992626130066\n",
      "76 Train Loss 0.0032185372 Test MSE 0.0013904437669066156 Test RE 0.017823162842269567\n",
      "77 Train Loss 0.0031199192 Test MSE 0.0014110443606986968 Test RE 0.01795470996199306\n",
      "78 Train Loss 0.0029404154 Test MSE 0.0012624477217831845 Test RE 0.016983013770590277\n",
      "79 Train Loss 0.00272261 Test MSE 0.001210059315160324 Test RE 0.016626904024233502\n",
      "80 Train Loss 0.0026629176 Test MSE 0.0012191220918038271 Test RE 0.016689051732815114\n",
      "81 Train Loss 0.0025381034 Test MSE 0.001237577262426352 Test RE 0.016814897376060404\n",
      "82 Train Loss 0.0023623004 Test MSE 0.0012801199982555122 Test RE 0.01710146836712227\n",
      "83 Train Loss 0.002261043 Test MSE 0.0011517052620084818 Test RE 0.016221041515805862\n",
      "84 Train Loss 0.002215288 Test MSE 0.001173341594994555 Test RE 0.01637269959999972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 0.0021362344 Test MSE 0.0011850702568924959 Test RE 0.01645432645197465\n",
      "86 Train Loss 0.0020658383 Test MSE 0.0011278348601742082 Test RE 0.016052061586091574\n",
      "87 Train Loss 0.0019881397 Test MSE 0.0010097130133413582 Test RE 0.015188225519514237\n",
      "88 Train Loss 0.0019225163 Test MSE 0.0010647392532426236 Test RE 0.015596591338404861\n",
      "89 Train Loss 0.00186721 Test MSE 0.0010505335748369022 Test RE 0.015492197637485232\n",
      "90 Train Loss 0.0018302838 Test MSE 0.0009332282593560401 Test RE 0.01460165224262176\n",
      "91 Train Loss 0.0018067139 Test MSE 0.0009123892816675904 Test RE 0.014437704463187921\n",
      "92 Train Loss 0.0017490251 Test MSE 0.0009256104327902365 Test RE 0.014541934387177328\n",
      "93 Train Loss 0.001670976 Test MSE 0.0008078210148891884 Test RE 0.013585187401830371\n",
      "94 Train Loss 0.0016249794 Test MSE 0.0007804927021105997 Test RE 0.013353419221115189\n",
      "95 Train Loss 0.0016029064 Test MSE 0.0007865790279540306 Test RE 0.013405383468637606\n",
      "96 Train Loss 0.0015807468 Test MSE 0.0007721703678424036 Test RE 0.013282035174146197\n",
      "97 Train Loss 0.0015490128 Test MSE 0.0008001531963485348 Test RE 0.013520558528639282\n",
      "98 Train Loss 0.0015115074 Test MSE 0.000786109140907995 Test RE 0.01340137881251042\n",
      "99 Train Loss 0.0014463642 Test MSE 0.0008289504553498218 Test RE 0.013761708281487067\n",
      "Training time: 83.55\n",
      "8\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 51.20074 Test MSE 8.953247360278098 Test RE 1.4302051974256431\n",
      "1 Train Loss 37.6327 Test MSE 7.8840176455999025 Test RE 1.342090660311679\n",
      "2 Train Loss 28.410686 Test MSE 7.382135498551112 Test RE 1.2986707722845117\n",
      "3 Train Loss 23.053501 Test MSE 6.981733319415558 Test RE 1.2629602686061459\n",
      "4 Train Loss 18.674267 Test MSE 7.767473840418456 Test RE 1.3321341441826258\n",
      "5 Train Loss 16.898434 Test MSE 7.620890012202694 Test RE 1.3195045956875313\n",
      "6 Train Loss 15.211642 Test MSE 7.635940562829266 Test RE 1.320806902590234\n",
      "7 Train Loss 13.997597 Test MSE 7.320058862582251 Test RE 1.2931989608308903\n",
      "8 Train Loss 12.709042 Test MSE 6.984089990279015 Test RE 1.2631734055454236\n",
      "9 Train Loss 11.171306 Test MSE 7.0085251487925415 Test RE 1.2653812015551347\n",
      "10 Train Loss 9.022161 Test MSE 6.653650366137882 Test RE 1.2329289444232165\n",
      "11 Train Loss 7.338374 Test MSE 6.556695452152596 Test RE 1.2239130520483983\n",
      "12 Train Loss 5.5454607 Test MSE 6.233913481852295 Test RE 1.1934066281243427\n",
      "13 Train Loss 4.298587 Test MSE 5.932411569550364 Test RE 1.1641895506160733\n",
      "14 Train Loss 3.5420384 Test MSE 5.733029569454658 Test RE 1.1444587690927157\n",
      "15 Train Loss 3.0997906 Test MSE 5.559960440893201 Test RE 1.1270518885600456\n",
      "16 Train Loss 2.7121942 Test MSE 5.362932157735973 Test RE 1.1069021011060083\n",
      "17 Train Loss 2.4303248 Test MSE 5.259523484932603 Test RE 1.096178449193975\n",
      "18 Train Loss 2.2643924 Test MSE 5.214510591019157 Test RE 1.0914776250056526\n",
      "19 Train Loss 2.0472608 Test MSE 5.198927329403802 Test RE 1.0898454960126822\n",
      "20 Train Loss 1.9479766 Test MSE 5.131262761705299 Test RE 1.0827300431407259\n",
      "21 Train Loss 1.8371975 Test MSE 5.060675617147772 Test RE 1.0752570792168339\n",
      "22 Train Loss 1.769101 Test MSE 5.005699320134856 Test RE 1.0694006403443375\n",
      "23 Train Loss 1.7002336 Test MSE 4.875746111484827 Test RE 1.0554279761763021\n",
      "24 Train Loss 1.6469144 Test MSE 4.850813157168658 Test RE 1.0527259625073524\n",
      "25 Train Loss 1.5912716 Test MSE 4.817807704470604 Test RE 1.0491384194372027\n",
      "26 Train Loss 1.5452722 Test MSE 4.764703652627248 Test RE 1.043340359274896\n",
      "27 Train Loss 1.5018098 Test MSE 4.744014360983861 Test RE 1.0410726991838701\n",
      "28 Train Loss 1.4594562 Test MSE 4.70092531893418 Test RE 1.0363339749391645\n",
      "29 Train Loss 1.429549 Test MSE 4.6633306263371965 Test RE 1.0321817216499605\n",
      "30 Train Loss 1.400835 Test MSE 4.622794381131622 Test RE 1.027685783248086\n",
      "31 Train Loss 1.3767568 Test MSE 4.5889793763682345 Test RE 1.0239202055309042\n",
      "32 Train Loss 1.3549101 Test MSE 4.549086350677343 Test RE 1.0194599069209982\n",
      "33 Train Loss 1.3383235 Test MSE 4.525838983775221 Test RE 1.0168516782872674\n",
      "34 Train Loss 1.3233571 Test MSE 4.5546254200354515 Test RE 1.020080376704079\n",
      "35 Train Loss 1.3079281 Test MSE 4.562211166690831 Test RE 1.020929497249204\n",
      "36 Train Loss 1.2910577 Test MSE 4.607122386908379 Test RE 1.025942296745845\n",
      "37 Train Loss 1.2743062 Test MSE 4.5959857071094845 Test RE 1.0247015543749727\n",
      "38 Train Loss 1.2627286 Test MSE 4.589864271356938 Test RE 1.0240189222726384\n",
      "39 Train Loss 1.2493514 Test MSE 4.571960960070217 Test RE 1.0220198171543364\n",
      "40 Train Loss 1.2364119 Test MSE 4.544007086831045 Test RE 1.0188906110608587\n",
      "41 Train Loss 1.2248722 Test MSE 4.520282058543347 Test RE 1.0162272300570752\n",
      "42 Train Loss 1.2138867 Test MSE 4.504216033142096 Test RE 1.0144196807414216\n",
      "43 Train Loss 1.2031844 Test MSE 4.502140202391147 Test RE 1.0141858990771206\n",
      "44 Train Loss 1.1932292 Test MSE 4.487669037289172 Test RE 1.012554645551156\n",
      "45 Train Loss 1.1765906 Test MSE 4.406910755875538 Test RE 1.0034025217039646\n",
      "46 Train Loss 1.1609515 Test MSE 4.306763343208547 Test RE 0.9919357989817515\n",
      "47 Train Loss 1.1394496 Test MSE 4.20222483744577 Test RE 0.9798231652562682\n",
      "48 Train Loss 1.0829626 Test MSE 3.939914500366093 Test RE 0.9487492792047443\n",
      "49 Train Loss 1.0352166 Test MSE 3.814502480477322 Test RE 0.9335272745410694\n",
      "50 Train Loss 0.9925905 Test MSE 3.6664050227197786 Test RE 0.915225853936686\n",
      "51 Train Loss 0.9608515 Test MSE 3.533415428173509 Test RE 0.8984737863833987\n",
      "52 Train Loss 0.9251152 Test MSE 3.4509573611423283 Test RE 0.8879282160242098\n",
      "53 Train Loss 0.8858102 Test MSE 3.3662072203243047 Test RE 0.8769573732265908\n",
      "54 Train Loss 0.8326025 Test MSE 3.219631000367993 Test RE 0.8576520113697522\n",
      "55 Train Loss 0.7804116 Test MSE 3.1329210543816948 Test RE 0.8460242000262943\n",
      "56 Train Loss 0.7476822 Test MSE 3.0918707387659694 Test RE 0.8404632433828695\n",
      "57 Train Loss 0.72415763 Test MSE 2.9966564827088047 Test RE 0.8274210032458253\n",
      "58 Train Loss 0.690489 Test MSE 2.9394409154415357 Test RE 0.819483904104454\n",
      "59 Train Loss 0.6674639 Test MSE 2.941970514687042 Test RE 0.8198364405447294\n",
      "60 Train Loss 0.6487071 Test MSE 2.951326688166909 Test RE 0.821139044202525\n",
      "61 Train Loss 0.6351711 Test MSE 2.9365010208937563 Test RE 0.8190739964001594\n",
      "62 Train Loss 0.6162699 Test MSE 2.941257756980675 Test RE 0.8197371227346167\n",
      "63 Train Loss 0.6043074 Test MSE 2.9618053140654816 Test RE 0.8225954714039981\n",
      "64 Train Loss 0.58284175 Test MSE 2.9707584040172 Test RE 0.823837824161441\n",
      "65 Train Loss 0.5711951 Test MSE 2.977858754480707 Test RE 0.8248217557769851\n",
      "66 Train Loss 0.5582309 Test MSE 2.9668930063441623 Test RE 0.8233016820533048\n",
      "67 Train Loss 0.55080557 Test MSE 2.965015317846414 Test RE 0.823041115061876\n",
      "68 Train Loss 0.54306304 Test MSE 2.9630572718646735 Test RE 0.8227693089624574\n",
      "69 Train Loss 0.5380049 Test MSE 2.981982043561745 Test RE 0.8253926025403313\n",
      "70 Train Loss 0.53079605 Test MSE 2.996611923371923 Test RE 0.8274148514782638\n",
      "71 Train Loss 0.5256249 Test MSE 3.0094886537587224 Test RE 0.8291906864903894\n",
      "72 Train Loss 0.5209443 Test MSE 3.0230247123662863 Test RE 0.8310533586156611\n",
      "73 Train Loss 0.5175194 Test MSE 3.025805720633314 Test RE 0.8314355313052618\n",
      "74 Train Loss 0.5120432 Test MSE 3.0148652633861777 Test RE 0.8299310523298699\n",
      "75 Train Loss 0.50574875 Test MSE 2.997797396251947 Test RE 0.8275784997752937\n",
      "76 Train Loss 0.50076896 Test MSE 3.016613631571353 Test RE 0.8301716625419195\n",
      "77 Train Loss 0.4975643 Test MSE 3.0129058196456433 Test RE 0.8296613110018334\n",
      "78 Train Loss 0.49302605 Test MSE 3.00436396696019 Test RE 0.8284843948929914\n",
      "79 Train Loss 0.48858792 Test MSE 3.007042242811736 Test RE 0.8288535937441585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.48380032 Test MSE 3.0035939302963452 Test RE 0.8283782153071934\n",
      "81 Train Loss 0.47916168 Test MSE 3.0099552217073575 Test RE 0.8292549596691268\n",
      "82 Train Loss 0.47481653 Test MSE 3.0122798015957284 Test RE 0.8295751134953238\n",
      "83 Train Loss 0.47102565 Test MSE 3.026382228359989 Test RE 0.8315147343709541\n",
      "84 Train Loss 0.4641397 Test MSE 3.0441996023142344 Test RE 0.8339588517908744\n",
      "85 Train Loss 0.46095094 Test MSE 3.03862329653401 Test RE 0.833194686861047\n",
      "86 Train Loss 0.45816603 Test MSE 3.0442784874031004 Test RE 0.8339696570107261\n",
      "87 Train Loss 0.4538426 Test MSE 3.064506335453351 Test RE 0.836735744589245\n",
      "88 Train Loss 0.4469453 Test MSE 3.0672873141742154 Test RE 0.8371153190412903\n",
      "89 Train Loss 0.44247302 Test MSE 3.0707858982273004 Test RE 0.8375925947819016\n",
      "90 Train Loss 0.4383689 Test MSE 3.089932006498289 Test RE 0.8401996992605165\n",
      "91 Train Loss 0.43463263 Test MSE 3.110219481125894 Test RE 0.8429534237255503\n",
      "92 Train Loss 0.43065944 Test MSE 3.1201139495190335 Test RE 0.8442931930198356\n",
      "93 Train Loss 0.42634714 Test MSE 3.1271500811088484 Test RE 0.8452446346583781\n",
      "94 Train Loss 0.42336217 Test MSE 3.1342615999505923 Test RE 0.846205183312762\n",
      "95 Train Loss 0.42100188 Test MSE 3.140138927334369 Test RE 0.8469982083037173\n",
      "96 Train Loss 0.41893005 Test MSE 3.146927631199682 Test RE 0.8479132817668971\n",
      "97 Train Loss 0.41659904 Test MSE 3.154443935297308 Test RE 0.8489252804278216\n",
      "98 Train Loss 0.4145615 Test MSE 3.1597956595729277 Test RE 0.8496451043954\n",
      "99 Train Loss 0.41270018 Test MSE 3.160890686295116 Test RE 0.8497923138357821\n",
      "Training time: 80.60\n",
      "9\n",
      "KG_rowdy_tune6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.73648 Test MSE 8.507709134912547 Test RE 1.3941656464287397\n",
      "1 Train Loss 56.498207 Test MSE 8.642384344307224 Test RE 1.4051569910229447\n",
      "2 Train Loss 56.457954 Test MSE 8.66014524764528 Test RE 1.4066001140947413\n",
      "3 Train Loss 56.26077 Test MSE 8.064837182132125 Test RE 1.3573938034330366\n",
      "4 Train Loss 46.40932 Test MSE 9.190593876257465 Test RE 1.4490382446450303\n",
      "5 Train Loss 44.293427 Test MSE 8.571890435942422 Test RE 1.3994144884698672\n",
      "6 Train Loss 42.990196 Test MSE 8.348165714986093 Test RE 1.381031520549936\n",
      "7 Train Loss 41.931328 Test MSE 8.633986333075066 Test RE 1.404474112789938\n",
      "8 Train Loss 40.754787 Test MSE 8.64043184769269 Test RE 1.4049982547799533\n",
      "9 Train Loss 40.209114 Test MSE 8.828745120874155 Test RE 1.4202262973062263\n",
      "10 Train Loss 39.54494 Test MSE 8.900461955925135 Test RE 1.4259829550519545\n",
      "11 Train Loss 38.748833 Test MSE 9.086252396536562 Test RE 1.4407892467329224\n",
      "12 Train Loss 38.28795 Test MSE 9.007999397817956 Test RE 1.4345716184838715\n",
      "13 Train Loss 37.02701 Test MSE 8.928774716525352 Test RE 1.4282492114390906\n",
      "14 Train Loss 34.95713 Test MSE 8.556335812337416 Test RE 1.398144217368146\n",
      "15 Train Loss 33.261368 Test MSE 8.15495476910214 Test RE 1.3649565866709983\n",
      "16 Train Loss 29.897615 Test MSE 7.461941721879382 Test RE 1.305671687018685\n",
      "17 Train Loss 26.370262 Test MSE 7.09064240230696 Test RE 1.2727727015979144\n",
      "18 Train Loss 23.170242 Test MSE 6.67446433463512 Test RE 1.2348558646119692\n",
      "19 Train Loss 20.842075 Test MSE 6.713164894136069 Test RE 1.2384307236517742\n",
      "20 Train Loss 20.146652 Test MSE 6.315778837486646 Test RE 1.201217130812318\n",
      "21 Train Loss 18.561853 Test MSE 6.096388064326251 Test RE 1.1801694339561997\n",
      "22 Train Loss 17.45829 Test MSE 6.304722639714514 Test RE 1.20016526437778\n",
      "23 Train Loss 16.98184 Test MSE 6.593461331743133 Test RE 1.2273397275679383\n",
      "24 Train Loss 16.592876 Test MSE 6.553868687977474 Test RE 1.2236491930230655\n",
      "25 Train Loss 16.30011 Test MSE 6.350842189261417 Test RE 1.2045469183128876\n",
      "26 Train Loss 16.037613 Test MSE 6.362911732258731 Test RE 1.2056909736644705\n",
      "27 Train Loss 15.765464 Test MSE 6.29952257261417 Test RE 1.199670220609886\n",
      "28 Train Loss 15.32083 Test MSE 6.187666783053354 Test RE 1.1889717046831072\n",
      "29 Train Loss 14.952244 Test MSE 6.05600701556512 Test RE 1.176254356885347\n",
      "30 Train Loss 14.1949415 Test MSE 5.915864465743018 Test RE 1.1625647967540347\n",
      "31 Train Loss 12.92799 Test MSE 5.553235820837716 Test RE 1.1263701131366526\n",
      "32 Train Loss 11.159792 Test MSE 5.060211049205094 Test RE 1.075207724005038\n",
      "33 Train Loss 9.4092045 Test MSE 4.762962631906103 Test RE 1.0431497237933978\n",
      "34 Train Loss 8.74527 Test MSE 4.779725828595182 Test RE 1.0449837886867261\n",
      "35 Train Loss 8.325735 Test MSE 4.799641001043374 Test RE 1.047158536817794\n",
      "36 Train Loss 7.285982 Test MSE 4.994149183444884 Test RE 1.068166161793275\n",
      "37 Train Loss 5.27625 Test MSE 4.137519160762827 Test RE 0.9722502629534329\n",
      "38 Train Loss 3.5309963 Test MSE 3.935552019610757 Test RE 0.948223881152497\n",
      "39 Train Loss 2.7927325 Test MSE 4.1186363129206915 Test RE 0.9700291435366033\n",
      "40 Train Loss 2.3784714 Test MSE 3.8431089045588767 Test RE 0.9370211766377424\n",
      "41 Train Loss 2.1560984 Test MSE 3.765543112822487 Test RE 0.9275169874364717\n",
      "42 Train Loss 1.9924473 Test MSE 3.788245241434495 Test RE 0.9303087451599865\n",
      "43 Train Loss 1.8847328 Test MSE 3.7339131662395597 Test RE 0.9236132769814566\n",
      "44 Train Loss 1.790693 Test MSE 3.760538214195395 Test RE 0.9269003868714787\n",
      "45 Train Loss 1.6783321 Test MSE 3.63682179005056 Test RE 0.9115260203703736\n",
      "46 Train Loss 1.598041 Test MSE 3.56457346448691 Test RE 0.9024265107409777\n",
      "47 Train Loss 1.534487 Test MSE 3.4738731123717677 Test RE 0.8908714391209673\n",
      "48 Train Loss 1.4437013 Test MSE 3.3264068840043834 Test RE 0.8717576068409855\n",
      "49 Train Loss 1.3565803 Test MSE 3.1523507491560414 Test RE 0.8486435741193222\n",
      "50 Train Loss 1.2693901 Test MSE 2.9984617509531057 Test RE 0.8276701963005108\n",
      "51 Train Loss 1.2079725 Test MSE 2.8871903484126595 Test RE 0.8121678035050607\n",
      "52 Train Loss 1.1666589 Test MSE 2.8452099076506427 Test RE 0.8062416251946195\n",
      "53 Train Loss 1.1199102 Test MSE 2.802589639695092 Test RE 0.8001802287110237\n",
      "54 Train Loss 1.0857531 Test MSE 2.709490833474173 Test RE 0.78677744873856\n",
      "55 Train Loss 1.0589969 Test MSE 2.6199268087709817 Test RE 0.7736644469749149\n",
      "56 Train Loss 1.0362048 Test MSE 2.6114521670982493 Test RE 0.7724121525191049\n",
      "57 Train Loss 1.0155346 Test MSE 2.575399920521303 Test RE 0.7670618777506367\n",
      "58 Train Loss 0.9968301 Test MSE 2.541977129683207 Test RE 0.7620682705133207\n",
      "59 Train Loss 0.9794545 Test MSE 2.5253302330729457 Test RE 0.7595688558881625\n",
      "60 Train Loss 0.95714635 Test MSE 2.5250610905233626 Test RE 0.7595283784600969\n",
      "61 Train Loss 0.9331356 Test MSE 2.508679497561009 Test RE 0.7570606103211627\n",
      "62 Train Loss 0.92499703 Test MSE 2.5081792298037566 Test RE 0.7569851220220156\n",
      "63 Train Loss 0.9071643 Test MSE 2.4874547045745334 Test RE 0.7538512353783994\n",
      "64 Train Loss 0.8857697 Test MSE 2.495267215743829 Test RE 0.7550341421609448\n",
      "65 Train Loss 0.8582007 Test MSE 2.541526531646847 Test RE 0.7620007243342031\n",
      "66 Train Loss 0.8461295 Test MSE 2.520818788744964 Test RE 0.7588900764588502\n",
      "67 Train Loss 0.8230963 Test MSE 2.520676337950911 Test RE 0.7588686338185153\n",
      "68 Train Loss 0.8055184 Test MSE 2.540441537230152 Test RE 0.7618380554070872\n",
      "69 Train Loss 0.79483986 Test MSE 2.5365936030454064 Test RE 0.7612608695988352\n",
      "70 Train Loss 0.78117484 Test MSE 2.556432923033219 Test RE 0.7642320751605831\n",
      "71 Train Loss 0.77140784 Test MSE 2.57250225365897 Test RE 0.7666302330720666\n",
      "72 Train Loss 0.7560336 Test MSE 2.596931983870488 Test RE 0.7702617781411472\n",
      "73 Train Loss 0.7472283 Test MSE 2.5877946080391725 Test RE 0.7689054905460002\n",
      "74 Train Loss 0.73711824 Test MSE 2.597316454823566 Test RE 0.7703187939432065\n",
      "75 Train Loss 0.72905314 Test MSE 2.6071155139316318 Test RE 0.7717705410336116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 0.71709394 Test MSE 2.6373819075963203 Test RE 0.7762374140737118\n",
      "77 Train Loss 0.70575 Test MSE 2.6403079422077447 Test RE 0.7766678917212717\n",
      "78 Train Loss 0.6940586 Test MSE 2.6602438502707955 Test RE 0.7795945317705453\n",
      "79 Train Loss 0.68875766 Test MSE 2.6659333581431777 Test RE 0.7804277524137617\n",
      "80 Train Loss 0.6773713 Test MSE 2.712395629547513 Test RE 0.7871990806928149\n",
      "81 Train Loss 0.6660781 Test MSE 2.714589126057986 Test RE 0.787517317726964\n",
      "82 Train Loss 0.65988135 Test MSE 2.719604746298432 Test RE 0.7882445115660098\n",
      "83 Train Loss 0.65064406 Test MSE 2.741935008262399 Test RE 0.7914739740091729\n",
      "84 Train Loss 0.6448596 Test MSE 2.7486721233890146 Test RE 0.7924457293318011\n",
      "85 Train Loss 0.6401681 Test MSE 2.7579579903559055 Test RE 0.7937831644467215\n",
      "86 Train Loss 0.63400286 Test MSE 2.780785658146293 Test RE 0.7970614735203793\n",
      "87 Train Loss 0.6256152 Test MSE 2.8049699052439876 Test RE 0.8005199568625417\n",
      "88 Train Loss 0.6169548 Test MSE 2.813447604659687 Test RE 0.8017287839852923\n",
      "89 Train Loss 0.61142516 Test MSE 2.8481601805181467 Test RE 0.8066595234466698\n",
      "90 Train Loss 0.60536885 Test MSE 2.850677924734952 Test RE 0.8070159840356518\n",
      "91 Train Loss 0.60152274 Test MSE 2.86746989840623 Test RE 0.809389365717298\n",
      "92 Train Loss 0.5964361 Test MSE 2.862057055290962 Test RE 0.808625073975132\n",
      "93 Train Loss 0.5922369 Test MSE 2.8741841025444135 Test RE 0.8103364075632303\n",
      "94 Train Loss 0.58693117 Test MSE 2.8782375764626065 Test RE 0.8109076166599981\n",
      "95 Train Loss 0.5824032 Test MSE 2.8727995978215826 Test RE 0.8101412130865661\n",
      "96 Train Loss 0.57783806 Test MSE 2.884678593743207 Test RE 0.8118144478383853\n",
      "97 Train Loss 0.5709734 Test MSE 2.8982705208996093 Test RE 0.8137247396549956\n",
      "98 Train Loss 0.56759113 Test MSE 2.9238454142476455 Test RE 0.8173070855468091\n",
      "99 Train Loss 0.5640778 Test MSE 2.9327449061309045 Test RE 0.8185499849412259\n",
      "Training time: 82.51\n",
      "0\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 49.88746 Test MSE 7.893154348917138 Test RE 1.342868102355754\n",
      "1 Train Loss 31.907627 Test MSE 6.551609305250016 Test RE 1.2234382542402578\n",
      "2 Train Loss 23.60971 Test MSE 5.325656580948433 Test RE 1.1030485784970239\n",
      "3 Train Loss 20.074606 Test MSE 5.817754317249327 Test RE 1.1528843632988939\n",
      "4 Train Loss 16.414711 Test MSE 5.722529347437611 Test RE 1.1434102328455358\n",
      "5 Train Loss 14.197561 Test MSE 5.686938238982808 Test RE 1.1398489832312484\n",
      "6 Train Loss 12.525558 Test MSE 5.755835791394929 Test RE 1.1467328612098895\n",
      "7 Train Loss 11.266522 Test MSE 5.547725426337046 Test RE 1.125811134159618\n",
      "8 Train Loss 10.172702 Test MSE 5.366111817575632 Test RE 1.1072301912741798\n",
      "9 Train Loss 9.281354 Test MSE 5.358356273366766 Test RE 1.1064297720921616\n",
      "10 Train Loss 8.456429 Test MSE 5.284816388719177 Test RE 1.098811033990002\n",
      "11 Train Loss 7.822066 Test MSE 5.177973658250136 Test RE 1.0876470309356272\n",
      "12 Train Loss 7.2931337 Test MSE 5.023115028568226 Test RE 1.07125934152824\n",
      "13 Train Loss 6.937012 Test MSE 4.859712140650056 Test RE 1.0536911510249167\n",
      "14 Train Loss 6.4855385 Test MSE 4.818350903920244 Test RE 1.0491975620373573\n",
      "15 Train Loss 5.8383217 Test MSE 4.56571095711342 Test RE 1.0213210129162826\n",
      "16 Train Loss 5.2134523 Test MSE 4.421699392733129 Test RE 1.005084712256721\n",
      "17 Train Loss 4.3948936 Test MSE 4.008179030948298 Test RE 0.95693318630343\n",
      "18 Train Loss 3.7291548 Test MSE 3.6403135134264497 Test RE 0.9119634948068639\n",
      "19 Train Loss 3.3154435 Test MSE 3.215336119858563 Test RE 0.8570797808644578\n",
      "20 Train Loss 2.8577547 Test MSE 2.910804071684529 Test RE 0.8154823150483019\n",
      "21 Train Loss 2.4083447 Test MSE 2.5571693112876663 Test RE 0.7643421369184283\n",
      "22 Train Loss 2.1149175 Test MSE 2.343938470275015 Test RE 0.7317810581926265\n",
      "23 Train Loss 1.9285376 Test MSE 2.1088671002744044 Test RE 0.6941169760192833\n",
      "24 Train Loss 1.749695 Test MSE 1.9436300276557636 Test RE 0.6663691152499455\n",
      "25 Train Loss 1.5739974 Test MSE 1.7043448210251317 Test RE 0.6240031656377966\n",
      "26 Train Loss 1.3673702 Test MSE 1.3156400939474602 Test RE 0.5482474373093368\n",
      "27 Train Loss 1.0991701 Test MSE 0.9019389830698639 Test RE 0.4539381039851304\n",
      "28 Train Loss 0.9030182 Test MSE 0.7154465146701635 Test RE 0.4042933951747621\n",
      "29 Train Loss 0.68716013 Test MSE 0.4471364743763696 Test RE 0.31961570366802616\n",
      "30 Train Loss 0.53922945 Test MSE 0.3741544487027731 Test RE 0.2923704774497899\n",
      "31 Train Loss 0.4192314 Test MSE 0.32397344766648223 Test RE 0.27205879432677127\n",
      "32 Train Loss 0.31379917 Test MSE 0.2755867689651072 Test RE 0.2509211341277274\n",
      "33 Train Loss 0.25723284 Test MSE 0.23940384163145395 Test RE 0.2338695165182967\n",
      "34 Train Loss 0.19656636 Test MSE 0.18106357936285924 Test RE 0.2033871969698821\n",
      "35 Train Loss 0.15511084 Test MSE 0.14053621395040167 Test RE 0.17918522031278714\n",
      "36 Train Loss 0.13813627 Test MSE 0.11568309874871952 Test RE 0.16257097746486557\n",
      "37 Train Loss 0.11795749 Test MSE 0.09080687165498165 Test RE 0.14403479452564638\n",
      "38 Train Loss 0.09987314 Test MSE 0.06822916722566182 Test RE 0.12485130769930035\n",
      "39 Train Loss 0.08832801 Test MSE 0.05043064772399033 Test RE 0.10733845339439557\n",
      "40 Train Loss 0.08243358 Test MSE 0.049763359798156846 Test RE 0.1066259484816585\n",
      "41 Train Loss 0.07339059 Test MSE 0.035075035229815435 Test RE 0.08951732960043633\n",
      "42 Train Loss 0.06226714 Test MSE 0.026636730623116403 Test RE 0.07800968417314812\n",
      "43 Train Loss 0.051630568 Test MSE 0.021005552092245607 Test RE 0.06927477288024152\n",
      "44 Train Loss 0.045915045 Test MSE 0.016557044703653753 Test RE 0.06150344901044536\n",
      "45 Train Loss 0.040827285 Test MSE 0.014308169203744817 Test RE 0.05717419965958332\n",
      "46 Train Loss 0.035921253 Test MSE 0.014142881908115766 Test RE 0.0568430035621679\n",
      "47 Train Loss 0.03163381 Test MSE 0.01189928534813423 Test RE 0.052139696620096994\n",
      "48 Train Loss 0.029069144 Test MSE 0.010601498934649992 Test RE 0.04921434362889032\n",
      "49 Train Loss 0.026130352 Test MSE 0.010877629063024433 Test RE 0.04985115015689487\n",
      "50 Train Loss 0.023528518 Test MSE 0.00980060300158029 Test RE 0.047318880248171435\n",
      "51 Train Loss 0.021113893 Test MSE 0.00897399411648987 Test RE 0.045279429938817714\n",
      "52 Train Loss 0.019966751 Test MSE 0.009270752855948826 Test RE 0.046022007841494815\n",
      "53 Train Loss 0.018953525 Test MSE 0.008527571832138472 Test RE 0.044138823541649906\n",
      "54 Train Loss 0.017545141 Test MSE 0.007280112012350243 Test RE 0.04078280483115323\n",
      "55 Train Loss 0.016430419 Test MSE 0.006541939816950101 Test RE 0.0386599539625374\n",
      "56 Train Loss 0.015270637 Test MSE 0.0059195637895948375 Test RE 0.036775019588766555\n",
      "57 Train Loss 0.0141755035 Test MSE 0.006027172770955314 Test RE 0.037107772101616684\n",
      "58 Train Loss 0.012846438 Test MSE 0.005207020687725035 Test RE 0.034490755850595835\n",
      "59 Train Loss 0.012034947 Test MSE 0.005064111964878433 Test RE 0.0340141568344834\n",
      "60 Train Loss 0.011287759 Test MSE 0.00515861723147413 Test RE 0.03433007186236808\n",
      "61 Train Loss 0.01064009 Test MSE 0.005403470199888361 Test RE 0.035135362661954016\n",
      "62 Train Loss 0.009807861 Test MSE 0.0052389228673556274 Test RE 0.034596252845158\n",
      "63 Train Loss 0.008994166 Test MSE 0.004833506310663122 Test RE 0.033230678233088395\n",
      "64 Train Loss 0.008393582 Test MSE 0.004555262619458728 Test RE 0.032260030246588155\n",
      "65 Train Loss 0.007960814 Test MSE 0.004199582780617225 Test RE 0.030974987047660517\n",
      "66 Train Loss 0.0076256013 Test MSE 0.004035423994042129 Test RE 0.0303635569814713\n",
      "67 Train Loss 0.0072008073 Test MSE 0.0038306310580746004 Test RE 0.029583068766043472\n",
      "68 Train Loss 0.0068756803 Test MSE 0.003826378930786984 Test RE 0.02956664511423933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 0.00664429 Test MSE 0.0038005458799606692 Test RE 0.029466669368757623\n",
      "70 Train Loss 0.006440364 Test MSE 0.0036880664845713035 Test RE 0.029027352774025045\n",
      "71 Train Loss 0.0061588236 Test MSE 0.0035153418283918082 Test RE 0.02833947765325769\n",
      "72 Train Loss 0.005888566 Test MSE 0.003439626612303629 Test RE 0.028032621327271603\n",
      "73 Train Loss 0.0057522506 Test MSE 0.003089936963115255 Test RE 0.026569468700779163\n",
      "74 Train Loss 0.005501901 Test MSE 0.0029075974150680035 Test RE 0.025773606719903627\n",
      "75 Train Loss 0.0051511466 Test MSE 0.0026608248946911007 Test RE 0.02465563589106745\n",
      "76 Train Loss 0.0048525124 Test MSE 0.0026352151758646672 Test RE 0.0245366971024362\n",
      "77 Train Loss 0.0046327934 Test MSE 0.0026189139991188745 Test RE 0.02446068860132084\n",
      "78 Train Loss 0.0043558814 Test MSE 0.002468635284636471 Test RE 0.023748518722571055\n",
      "79 Train Loss 0.0042420914 Test MSE 0.0022514247551069103 Test RE 0.02267967249070705\n",
      "80 Train Loss 0.0040793484 Test MSE 0.002137078442128459 Test RE 0.022096235603191454\n",
      "81 Train Loss 0.003791182 Test MSE 0.001999441431068024 Test RE 0.02137284832719038\n",
      "82 Train Loss 0.0036754524 Test MSE 0.0019640596216590556 Test RE 0.021182898921758134\n",
      "83 Train Loss 0.0035098481 Test MSE 0.0020601744116533495 Test RE 0.021695019990675374\n",
      "84 Train Loss 0.0033808583 Test MSE 0.0019990645507978874 Test RE 0.0213708339184812\n",
      "85 Train Loss 0.003270407 Test MSE 0.0019447696901953775 Test RE 0.021078618755241352\n",
      "86 Train Loss 0.0031527225 Test MSE 0.001818122648988071 Test RE 0.020380725927074808\n",
      "87 Train Loss 0.0030671693 Test MSE 0.0017771829116958542 Test RE 0.02014995704292815\n",
      "88 Train Loss 0.0029919522 Test MSE 0.0017775347573876841 Test RE 0.020151951582899716\n",
      "89 Train Loss 0.0028822287 Test MSE 0.0017788321492209244 Test RE 0.02015930452166717\n",
      "90 Train Loss 0.0028187737 Test MSE 0.0018154867167148889 Test RE 0.020365946478854004\n",
      "91 Train Loss 0.0027381184 Test MSE 0.0017527567496331677 Test RE 0.020011004258089236\n",
      "92 Train Loss 0.0026403298 Test MSE 0.001643640578777035 Test RE 0.019378113158863463\n",
      "93 Train Loss 0.0025370766 Test MSE 0.001545515765402811 Test RE 0.018790778794413234\n",
      "94 Train Loss 0.002485014 Test MSE 0.0015101596505464356 Test RE 0.018574600912826946\n",
      "95 Train Loss 0.0024446663 Test MSE 0.0014662738699329487 Test RE 0.018302718822970562\n",
      "96 Train Loss 0.0023582082 Test MSE 0.001340950823313564 Test RE 0.017503080327325213\n",
      "97 Train Loss 0.0022433577 Test MSE 0.0013149077407881692 Test RE 0.0173322801968449\n",
      "98 Train Loss 0.002194271 Test MSE 0.0012949161815807501 Test RE 0.01720001751893282\n",
      "99 Train Loss 0.0021413066 Test MSE 0.001264678100927839 Test RE 0.016998009181381474\n",
      "Training time: 82.25\n",
      "1\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 59.205845 Test MSE 8.388224639348667 Test RE 1.384341015775079\n",
      "1 Train Loss 54.596184 Test MSE 8.805530050235737 Test RE 1.418357834921032\n",
      "2 Train Loss 46.138443 Test MSE 8.548261821380935 Test RE 1.3974843982393708\n",
      "3 Train Loss 43.730606 Test MSE 8.35182275781966 Test RE 1.3813339785153889\n",
      "4 Train Loss 42.792397 Test MSE 8.625702032303412 Test RE 1.403800155371525\n",
      "5 Train Loss 42.191162 Test MSE 8.609299823968316 Test RE 1.402464821798459\n",
      "6 Train Loss 40.899075 Test MSE 8.485786954031289 Test RE 1.3923682844862475\n",
      "7 Train Loss 38.634834 Test MSE 8.90045966398133 Test RE 1.4259827714506408\n",
      "8 Train Loss 35.666603 Test MSE 7.869034763624234 Test RE 1.3408147912363093\n",
      "9 Train Loss 32.53686 Test MSE 7.9112384370633775 Test RE 1.3444055517914804\n",
      "10 Train Loss 29.448994 Test MSE 8.084420389893372 Test RE 1.3590408303357266\n",
      "11 Train Loss 27.125145 Test MSE 8.245431916327217 Test RE 1.3725076231684912\n",
      "12 Train Loss 25.441826 Test MSE 8.447477001483584 Test RE 1.3892217346456415\n",
      "13 Train Loss 24.16882 Test MSE 8.411132593614179 Test RE 1.386230020908481\n",
      "14 Train Loss 22.387344 Test MSE 8.55266524727979 Test RE 1.3978442916797564\n",
      "15 Train Loss 20.934578 Test MSE 8.697524388669096 Test RE 1.4096324473029846\n",
      "16 Train Loss 19.372108 Test MSE 8.62671656880068 Test RE 1.403882708919723\n",
      "17 Train Loss 16.767948 Test MSE 7.963709911740515 Test RE 1.348856584287723\n",
      "18 Train Loss 15.820129 Test MSE 8.0833896204652 Test RE 1.3589541882310725\n",
      "19 Train Loss 14.300636 Test MSE 8.21294569870918 Test RE 1.3698011799998033\n",
      "20 Train Loss 13.095274 Test MSE 7.397625452667848 Test RE 1.3000325604275471\n",
      "21 Train Loss 12.080681 Test MSE 7.125436106702617 Test RE 1.2758916209886275\n",
      "22 Train Loss 10.191275 Test MSE 6.071578669166608 Test RE 1.1777656221835655\n",
      "23 Train Loss 9.024332 Test MSE 5.858556996166563 Test RE 1.1569201626891035\n",
      "24 Train Loss 8.599453 Test MSE 5.663171880210448 Test RE 1.1374647106099454\n",
      "25 Train Loss 8.161944 Test MSE 5.628905716413665 Test RE 1.134018259501465\n",
      "26 Train Loss 7.923425 Test MSE 5.656711683857166 Test RE 1.1368157507749737\n",
      "27 Train Loss 7.5366364 Test MSE 5.591958987523596 Test RE 1.1302904262152127\n",
      "28 Train Loss 7.171876 Test MSE 5.542814782176187 Test RE 1.125312760377004\n",
      "29 Train Loss 6.846199 Test MSE 5.533374569076656 Test RE 1.1243540670287355\n",
      "30 Train Loss 6.3622413 Test MSE 5.137883604106515 Test RE 1.0834283385121473\n",
      "31 Train Loss 5.251053 Test MSE 4.706762355858141 Test RE 1.036977172040452\n",
      "32 Train Loss 4.55779 Test MSE 4.7319635371822635 Test RE 1.03974958334837\n",
      "33 Train Loss 3.9901915 Test MSE 4.765661330387227 Test RE 1.0434452066828894\n",
      "34 Train Loss 3.5491793 Test MSE 4.749581730275725 Test RE 1.0416833989244385\n",
      "35 Train Loss 3.2557797 Test MSE 4.759270941837676 Test RE 1.042745381761947\n",
      "36 Train Loss 3.0762496 Test MSE 4.774817883218602 Test RE 1.044447142779525\n",
      "37 Train Loss 2.8855886 Test MSE 4.9185051075565545 Test RE 1.060045785299646\n",
      "38 Train Loss 2.7798247 Test MSE 4.9619543848126195 Test RE 1.0647176267756413\n",
      "39 Train Loss 2.667501 Test MSE 5.004898968356232 Test RE 1.0693151447058178\n",
      "40 Train Loss 2.5774515 Test MSE 5.0997199091031575 Test RE 1.0793970388675722\n",
      "41 Train Loss 2.520091 Test MSE 5.093311400797502 Test RE 1.0787186193147296\n",
      "42 Train Loss 2.446093 Test MSE 5.181464711475635 Test RE 1.0880136216272882\n",
      "43 Train Loss 2.3924217 Test MSE 5.210947685320285 Test RE 1.0911046756859042\n",
      "44 Train Loss 2.339202 Test MSE 5.232545867170537 Test RE 1.0933635266964554\n",
      "45 Train Loss 2.2835786 Test MSE 5.260489063081614 Test RE 1.096279066425396\n",
      "46 Train Loss 2.2396028 Test MSE 5.280394592943862 Test RE 1.098351251248661\n",
      "47 Train Loss 2.1906903 Test MSE 5.333700029848711 Test RE 1.1038812427195719\n",
      "48 Train Loss 2.1356573 Test MSE 5.348392244509707 Test RE 1.1054005732591543\n",
      "49 Train Loss 2.0862513 Test MSE 5.3523004130903775 Test RE 1.1058043677723066\n",
      "50 Train Loss 2.0388374 Test MSE 5.3311663783061745 Test RE 1.1036190248762814\n",
      "51 Train Loss 2.0121849 Test MSE 5.387443910485984 Test RE 1.1094288139235073\n",
      "52 Train Loss 1.9750751 Test MSE 5.407849144992948 Test RE 1.111527839006921\n",
      "53 Train Loss 1.9368641 Test MSE 5.40235994138895 Test RE 1.1109635710752375\n",
      "54 Train Loss 1.8912395 Test MSE 5.427249040435306 Test RE 1.1135197787658075\n",
      "55 Train Loss 1.8503714 Test MSE 5.423552016200834 Test RE 1.1131404511462215\n",
      "56 Train Loss 1.8104173 Test MSE 5.478263709498928 Test RE 1.118740930073811\n",
      "57 Train Loss 1.7794472 Test MSE 5.5407109119737274 Test RE 1.1250991742499081\n",
      "58 Train Loss 1.7493721 Test MSE 5.523166479936362 Test RE 1.12331647190711\n",
      "59 Train Loss 1.6964779 Test MSE 5.497646071488162 Test RE 1.1207182624059044\n",
      "60 Train Loss 1.6613307 Test MSE 5.535228539552976 Test RE 1.1245424100229273\n",
      "61 Train Loss 1.6246808 Test MSE 5.54644141366537 Test RE 1.125680842976864\n",
      "62 Train Loss 1.5824622 Test MSE 5.554387334535133 Test RE 1.126486888600967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Train Loss 1.5451763 Test MSE 5.587341549782732 Test RE 1.1298236735524145\n",
      "64 Train Loss 1.5253167 Test MSE 5.602261389824435 Test RE 1.1313311480993316\n",
      "65 Train Loss 1.4976135 Test MSE 5.618105924116058 Test RE 1.13292985596715\n",
      "66 Train Loss 1.466591 Test MSE 5.62930448203082 Test RE 1.1340584271206533\n",
      "67 Train Loss 1.442229 Test MSE 5.589996527179182 Test RE 1.1300920749049257\n",
      "68 Train Loss 1.4194934 Test MSE 5.650856649157678 Test RE 1.1362272623300984\n",
      "69 Train Loss 1.3999823 Test MSE 5.631697265019588 Test RE 1.1342994220275477\n",
      "70 Train Loss 1.3833599 Test MSE 5.618034620774069 Test RE 1.1329226665386858\n",
      "71 Train Loss 1.3678564 Test MSE 5.650773791359566 Test RE 1.1362189321210647\n",
      "72 Train Loss 1.3453835 Test MSE 5.651776504703024 Test RE 1.1363197370187141\n",
      "73 Train Loss 1.3291619 Test MSE 5.654707862403628 Test RE 1.1366143813496339\n",
      "74 Train Loss 1.3166513 Test MSE 5.6461962392471 Test RE 1.1357586274519356\n",
      "75 Train Loss 1.3053669 Test MSE 5.648476506575524 Test RE 1.1359879474890298\n",
      "76 Train Loss 1.2877688 Test MSE 5.64747256971763 Test RE 1.1358869901026483\n",
      "77 Train Loss 1.2772259 Test MSE 5.646713850294756 Test RE 1.1358106861933737\n",
      "78 Train Loss 1.2596534 Test MSE 5.659317539249224 Test RE 1.137077566873381\n",
      "79 Train Loss 1.2410598 Test MSE 5.682818507434126 Test RE 1.1394360437571789\n",
      "80 Train Loss 1.2251145 Test MSE 5.700162694924258 Test RE 1.1411735210550453\n",
      "81 Train Loss 1.2159687 Test MSE 5.691186852377934 Test RE 1.140274684487699\n",
      "82 Train Loss 1.1995006 Test MSE 5.685224228639871 Test RE 1.1396771983360923\n",
      "83 Train Loss 1.1856434 Test MSE 5.734053218114908 Test RE 1.1445609377089287\n",
      "84 Train Loss 1.1749481 Test MSE 5.749232934268593 Test RE 1.1460749301765225\n",
      "85 Train Loss 1.1632104 Test MSE 5.751786341438249 Test RE 1.146329405088581\n",
      "86 Train Loss 1.1515994 Test MSE 5.797223421189039 Test RE 1.1508482968592137\n",
      "87 Train Loss 1.1395127 Test MSE 5.829013596803544 Test RE 1.1539994304056083\n",
      "88 Train Loss 1.1298369 Test MSE 5.861904062975417 Test RE 1.1572505969722986\n",
      "89 Train Loss 1.1161807 Test MSE 5.837445987447192 Test RE 1.154833830353079\n",
      "90 Train Loss 1.0970212 Test MSE 5.870354976289227 Test RE 1.1580844815001279\n",
      "91 Train Loss 1.0866458 Test MSE 5.844869494205903 Test RE 1.155567900778789\n",
      "92 Train Loss 1.075746 Test MSE 5.90377701286577 Test RE 1.1613764976723246\n",
      "93 Train Loss 1.0632098 Test MSE 5.8912220216261275 Test RE 1.1601409469380497\n",
      "94 Train Loss 1.0537498 Test MSE 5.917633969298121 Test RE 1.1627386520498688\n",
      "95 Train Loss 1.04343 Test MSE 5.905431652493006 Test RE 1.1615392345901452\n",
      "96 Train Loss 1.0367217 Test MSE 5.900266383224543 Test RE 1.16103114510895\n",
      "97 Train Loss 1.0263394 Test MSE 5.934422877583385 Test RE 1.1643868856571191\n",
      "98 Train Loss 1.0197475 Test MSE 5.94037927709255 Test RE 1.1649710885510385\n",
      "99 Train Loss 1.0166054 Test MSE 5.947042392412149 Test RE 1.1656242590709376\n",
      "Training time: 83.05\n",
      "2\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.331512 Test MSE 7.866270268253616 Test RE 1.3405792476148353\n",
      "1 Train Loss 44.497826 Test MSE 7.16685735882598 Test RE 1.2795947238780978\n",
      "2 Train Loss 32.210575 Test MSE 6.369310346679281 Test RE 1.2062970494234981\n",
      "3 Train Loss 23.996914 Test MSE 5.684277087809956 Test RE 1.1395822610279558\n",
      "4 Train Loss 20.71912 Test MSE 5.851717644895644 Test RE 1.156244664093555\n",
      "5 Train Loss 16.641445 Test MSE 5.728001948788051 Test RE 1.1439568384358907\n",
      "6 Train Loss 13.4205265 Test MSE 5.670104303726719 Test RE 1.1381606964972597\n",
      "7 Train Loss 11.829512 Test MSE 5.637007027246386 Test RE 1.1348340247387154\n",
      "8 Train Loss 10.690359 Test MSE 5.758355950530005 Test RE 1.1469838788841917\n",
      "9 Train Loss 9.5397 Test MSE 5.701227847360349 Test RE 1.1412801379221464\n",
      "10 Train Loss 8.532487 Test MSE 5.668447453660679 Test RE 1.1379943944944262\n",
      "11 Train Loss 7.3174267 Test MSE 5.487065966716452 Test RE 1.1196393436498626\n",
      "12 Train Loss 6.7012835 Test MSE 5.243582379778195 Test RE 1.094515983306699\n",
      "13 Train Loss 6.333475 Test MSE 5.123332724630929 Test RE 1.0818930747704831\n",
      "14 Train Loss 5.8502293 Test MSE 4.886829711884753 Test RE 1.056626900530024\n",
      "15 Train Loss 5.5679574 Test MSE 4.641402839282661 Test RE 1.0297521136980001\n",
      "16 Train Loss 5.3320866 Test MSE 4.4703567931456885 Test RE 1.0105996738372698\n",
      "17 Train Loss 5.080204 Test MSE 4.333954848640755 Test RE 0.9950622521808083\n",
      "18 Train Loss 4.773037 Test MSE 4.0210351142104015 Test RE 0.9584666212538273\n",
      "19 Train Loss 4.2167273 Test MSE 3.7208821791971585 Test RE 0.9220002089710226\n",
      "20 Train Loss 3.7152429 Test MSE 3.3849843411474088 Test RE 0.8793998602646901\n",
      "21 Train Loss 3.3160076 Test MSE 3.218694493045969 Test RE 0.8575272679124845\n",
      "22 Train Loss 2.721048 Test MSE 2.835296316447433 Test RE 0.8048358019685972\n",
      "23 Train Loss 2.3407 Test MSE 2.557904257241252 Test RE 0.7644519673081105\n",
      "24 Train Loss 2.0946267 Test MSE 2.3890815579904703 Test RE 0.7387943206347996\n",
      "25 Train Loss 1.8350282 Test MSE 2.1595462027994796 Test RE 0.70240777525347\n",
      "26 Train Loss 1.5512261 Test MSE 1.9452465311958163 Test RE 0.6666461649299525\n",
      "27 Train Loss 1.3335067 Test MSE 1.6565315711447814 Test RE 0.6151880899774608\n",
      "28 Train Loss 1.1528304 Test MSE 1.4610793145442351 Test RE 0.5777566546001801\n",
      "29 Train Loss 0.95381296 Test MSE 1.0891911197812887 Test RE 0.49883866261227305\n",
      "30 Train Loss 0.7803037 Test MSE 0.8429783540125393 Test RE 0.4388501708404483\n",
      "31 Train Loss 0.6137473 Test MSE 0.7658973024686351 Test RE 0.4183052643984672\n",
      "32 Train Loss 0.4577397 Test MSE 0.637401077256509 Test RE 0.3816053518300543\n",
      "33 Train Loss 0.33753502 Test MSE 0.5348270244541051 Test RE 0.34955436699705084\n",
      "34 Train Loss 0.2780006 Test MSE 0.4344259922273364 Test RE 0.3150401903062437\n",
      "35 Train Loss 0.21905045 Test MSE 0.33269263310610797 Test RE 0.2756954841097422\n",
      "36 Train Loss 0.17251815 Test MSE 0.24180275210432295 Test RE 0.23503832315040038\n",
      "37 Train Loss 0.1258785 Test MSE 0.14187604663860817 Test RE 0.18003734486722925\n",
      "38 Train Loss 0.10242393 Test MSE 0.12126031678487459 Test RE 0.16644371840835973\n",
      "39 Train Loss 0.08063723 Test MSE 0.07428363847361509 Test RE 0.13027306889776982\n",
      "40 Train Loss 0.067396335 Test MSE 0.06569485175163593 Test RE 0.12251061746284314\n",
      "41 Train Loss 0.050060265 Test MSE 0.04377480345846389 Test RE 0.10000464274215098\n",
      "42 Train Loss 0.0419362 Test MSE 0.030790402215208734 Test RE 0.08387175706762089\n",
      "43 Train Loss 0.032931067 Test MSE 0.028896630534082226 Test RE 0.08125155155260996\n",
      "44 Train Loss 0.027989268 Test MSE 0.021249443209891604 Test RE 0.06967577976230022\n",
      "45 Train Loss 0.02338155 Test MSE 0.019337673099277166 Test RE 0.0664676259848573\n",
      "46 Train Loss 0.019904878 Test MSE 0.017198937025119244 Test RE 0.0626843119801991\n",
      "47 Train Loss 0.017934337 Test MSE 0.012677228591060095 Test RE 0.05381709125461884\n",
      "48 Train Loss 0.015558177 Test MSE 0.011835813327181583 Test RE 0.052000451412696685\n",
      "49 Train Loss 0.012847771 Test MSE 0.013166899398947655 Test RE 0.054846613715557366\n",
      "50 Train Loss 0.010929547 Test MSE 0.012159062528551494 Test RE 0.052705763167984525\n",
      "51 Train Loss 0.009660212 Test MSE 0.012477348014815374 Test RE 0.05339114129919376\n",
      "52 Train Loss 0.008968409 Test MSE 0.010828310130917323 Test RE 0.04973800975528254\n",
      "53 Train Loss 0.008264819 Test MSE 0.011138717396592907 Test RE 0.05044587425747257\n",
      "54 Train Loss 0.0077598896 Test MSE 0.010478261241708633 Test RE 0.048927460080009824\n",
      "55 Train Loss 0.0073126196 Test MSE 0.010041687584151752 Test RE 0.04789734195163133\n",
      "56 Train Loss 0.0067366282 Test MSE 0.009619652411276849 Test RE 0.04688001589039386\n",
      "57 Train Loss 0.005819885 Test MSE 0.009578336824550792 Test RE 0.046779234727207734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.0054564313 Test MSE 0.009890832234954842 Test RE 0.04753620179322124\n",
      "59 Train Loss 0.005056489 Test MSE 0.008765441228380445 Test RE 0.04475019698506849\n",
      "60 Train Loss 0.0046414034 Test MSE 0.00787904951654293 Test RE 0.04242725899921124\n",
      "61 Train Loss 0.0042062234 Test MSE 0.0078033699363637965 Test RE 0.04222300690969494\n",
      "62 Train Loss 0.0040438175 Test MSE 0.007632322756166297 Test RE 0.041757685981141573\n",
      "63 Train Loss 0.0037577595 Test MSE 0.007566900711720742 Test RE 0.04157833346250501\n",
      "64 Train Loss 0.003540801 Test MSE 0.00702079254217987 Test RE 0.04004987181411696\n",
      "65 Train Loss 0.0033343635 Test MSE 0.006918949860366636 Test RE 0.03975833163719554\n",
      "66 Train Loss 0.003242244 Test MSE 0.00686297928989977 Test RE 0.039597193371649506\n",
      "67 Train Loss 0.0031299626 Test MSE 0.006316618259449773 Test RE 0.03798834521699038\n",
      "68 Train Loss 0.002915139 Test MSE 0.006182127516232454 Test RE 0.037581753502287804\n",
      "69 Train Loss 0.0028325617 Test MSE 0.0062299948972937245 Test RE 0.037726968178765245\n",
      "70 Train Loss 0.0027535183 Test MSE 0.0063150466090475185 Test RE 0.03798361894496921\n",
      "71 Train Loss 0.0025973106 Test MSE 0.006436198562116954 Test RE 0.038346239221607174\n",
      "72 Train Loss 0.0024647457 Test MSE 0.005965379004713675 Test RE 0.03691705775324667\n",
      "73 Train Loss 0.0023750225 Test MSE 0.005661279350017579 Test RE 0.03596378170483959\n",
      "74 Train Loss 0.0022954193 Test MSE 0.005437608390811748 Test RE 0.03524617748500086\n",
      "75 Train Loss 0.0022610556 Test MSE 0.005441440499120316 Test RE 0.035258595019641195\n",
      "76 Train Loss 0.0022077984 Test MSE 0.0053659600588897675 Test RE 0.035013197871728734\n",
      "77 Train Loss 0.0021199698 Test MSE 0.005180496923574345 Test RE 0.0344027983890029\n",
      "78 Train Loss 0.00202344 Test MSE 0.004807648410441159 Test RE 0.033141671639141515\n",
      "79 Train Loss 0.0019209782 Test MSE 0.004809358438496278 Test RE 0.03314756518052039\n",
      "80 Train Loss 0.0018174794 Test MSE 0.004295355393825247 Test RE 0.03132619245120371\n",
      "81 Train Loss 0.0017379697 Test MSE 0.004073511916650333 Test RE 0.030506512067813886\n",
      "82 Train Loss 0.0016234403 Test MSE 0.0037428749371778485 Test RE 0.029242245461771066\n",
      "83 Train Loss 0.00158828 Test MSE 0.0036593091629432816 Test RE 0.02891396239512272\n",
      "84 Train Loss 0.0015463431 Test MSE 0.003690562398098242 Test RE 0.029037173300474787\n",
      "85 Train Loss 0.0014501057 Test MSE 0.0035412906116609466 Test RE 0.028443880429350726\n",
      "86 Train Loss 0.0013681258 Test MSE 0.0035104273552828903 Test RE 0.028319661328405493\n",
      "87 Train Loss 0.0013095 Test MSE 0.003505182133747336 Test RE 0.0282984960383271\n",
      "88 Train Loss 0.0012890178 Test MSE 0.0034561593526863167 Test RE 0.028099910677387693\n",
      "89 Train Loss 0.0012584346 Test MSE 0.0033757643351429636 Test RE 0.027771166392722427\n",
      "90 Train Loss 0.0012152817 Test MSE 0.0031425857181741523 Test RE 0.02679486828407636\n",
      "91 Train Loss 0.0011853995 Test MSE 0.0029909929389979966 Test RE 0.02614061219051428\n",
      "92 Train Loss 0.0011544137 Test MSE 0.0029400988783653366 Test RE 0.025917256593911003\n",
      "93 Train Loss 0.0011218144 Test MSE 0.0029965904601875395 Test RE 0.02616506130129518\n",
      "94 Train Loss 0.0010752485 Test MSE 0.0028543220570777803 Test RE 0.02553639262634027\n",
      "95 Train Loss 0.0010191327 Test MSE 0.0027537617808652405 Test RE 0.02508252445446482\n",
      "96 Train Loss 0.00094737153 Test MSE 0.002635380388209661 Test RE 0.024537466242992367\n",
      "97 Train Loss 0.0008805878 Test MSE 0.0023430642078757927 Test RE 0.023136632866651477\n",
      "98 Train Loss 0.00083895546 Test MSE 0.0022235368173671 Test RE 0.022538770569133046\n",
      "99 Train Loss 0.000798557 Test MSE 0.0020644415582586027 Test RE 0.021717476328090957\n",
      "Training time: 83.60\n",
      "3\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.679092 Test MSE 8.062074174237722 Test RE 1.3571612624037597\n",
      "1 Train Loss 44.61416 Test MSE 9.030254857768556 Test RE 1.4363426751918704\n",
      "2 Train Loss 36.696266 Test MSE 8.852477332949368 Test RE 1.4221338442598228\n",
      "3 Train Loss 32.528076 Test MSE 8.883421947288289 Test RE 1.4246172729568978\n",
      "4 Train Loss 29.489721 Test MSE 8.983392495874511 Test RE 1.4326108888132028\n",
      "5 Train Loss 26.443256 Test MSE 8.74719921305023 Test RE 1.413652185758794\n",
      "6 Train Loss 23.5786 Test MSE 8.86138839434969 Test RE 1.4228494368553386\n",
      "7 Train Loss 20.868176 Test MSE 9.04642588428893 Test RE 1.4376281730320644\n",
      "8 Train Loss 19.054056 Test MSE 8.750294394191668 Test RE 1.4139022728141593\n",
      "9 Train Loss 17.919975 Test MSE 8.616808045288336 Test RE 1.4030762374576327\n",
      "10 Train Loss 16.874409 Test MSE 8.585736945116887 Test RE 1.4005442968186572\n",
      "11 Train Loss 15.6538515 Test MSE 8.50069869241786 Test RE 1.3935911244170485\n",
      "12 Train Loss 14.7129135 Test MSE 8.455656002113985 Test RE 1.3898941067894537\n",
      "13 Train Loss 13.925751 Test MSE 8.399450240834812 Test RE 1.3852670081965202\n",
      "14 Train Loss 13.202303 Test MSE 8.178500188019449 Test RE 1.3669256540047376\n",
      "15 Train Loss 12.670651 Test MSE 7.990646823805006 Test RE 1.3511358836891663\n",
      "16 Train Loss 10.751505 Test MSE 6.8251673973540905 Test RE 1.2487189834494268\n",
      "17 Train Loss 7.6440763 Test MSE 6.273356484878793 Test RE 1.1971761156739462\n",
      "18 Train Loss 6.82835 Test MSE 5.9729619374905765 Test RE 1.168161621397418\n",
      "19 Train Loss 6.428686 Test MSE 5.965173017178202 Test RE 1.1673997141509238\n",
      "20 Train Loss 6.216997 Test MSE 5.988641454432432 Test RE 1.1696938767078207\n",
      "21 Train Loss 6.063582 Test MSE 5.973568950058989 Test RE 1.1682209781101236\n",
      "22 Train Loss 5.8562255 Test MSE 6.046048198561085 Test RE 1.1752868116327035\n",
      "23 Train Loss 5.7198124 Test MSE 6.033498240972192 Test RE 1.1740663895274601\n",
      "24 Train Loss 5.440468 Test MSE 6.114382982825748 Test RE 1.1819099239075708\n",
      "25 Train Loss 5.1121073 Test MSE 6.053897985839935 Test RE 1.1760495213049351\n",
      "26 Train Loss 4.7474103 Test MSE 5.808985961131879 Test RE 1.1520152382083393\n",
      "27 Train Loss 4.1047535 Test MSE 5.673772652130433 Test RE 1.1385288109686746\n",
      "28 Train Loss 3.3205957 Test MSE 5.2829244723306905 Test RE 1.0986143341865862\n",
      "29 Train Loss 2.8768415 Test MSE 5.2661417146702885 Test RE 1.0968679108952442\n",
      "30 Train Loss 2.435943 Test MSE 5.277967272195854 Test RE 1.0980987741666475\n",
      "31 Train Loss 2.1737144 Test MSE 5.287669562099352 Test RE 1.0991076077146515\n",
      "32 Train Loss 1.9984632 Test MSE 5.314296458976593 Test RE 1.1018714977313215\n",
      "33 Train Loss 1.8809035 Test MSE 5.340666936886935 Test RE 1.10460195519001\n",
      "34 Train Loss 1.7399786 Test MSE 5.354990750000724 Test RE 1.1060822494611078\n",
      "35 Train Loss 1.6383597 Test MSE 5.3998046703502265 Test RE 1.1107008017640325\n",
      "36 Train Loss 1.5576408 Test MSE 5.490810302905371 Test RE 1.1200212956057967\n",
      "37 Train Loss 1.4951174 Test MSE 5.500494193584421 Test RE 1.1210085256482343\n",
      "38 Train Loss 1.4266526 Test MSE 5.569176153679257 Test RE 1.1279855540236052\n",
      "39 Train Loss 1.3826536 Test MSE 5.669421788239125 Test RE 1.1380921937291517\n",
      "40 Train Loss 1.3395091 Test MSE 5.675806876067897 Test RE 1.138732891670214\n",
      "41 Train Loss 1.2962438 Test MSE 5.677582553360958 Test RE 1.13891100414479\n",
      "42 Train Loss 1.258915 Test MSE 5.659320474386338 Test RE 1.1370778617391586\n",
      "43 Train Loss 1.2256252 Test MSE 5.66058202197885 Test RE 1.1372045905498622\n",
      "44 Train Loss 1.1956918 Test MSE 5.657704571679923 Test RE 1.1369155155370212\n",
      "45 Train Loss 1.1699619 Test MSE 5.700624488757084 Test RE 1.1412197457199795\n",
      "46 Train Loss 1.149784 Test MSE 5.661753790820377 Test RE 1.137322287983355\n",
      "47 Train Loss 1.1219875 Test MSE 5.656449310541572 Test RE 1.1367893862019551\n",
      "48 Train Loss 1.1022286 Test MSE 5.67684026467372 Test RE 1.1388365509439793\n",
      "49 Train Loss 1.0842572 Test MSE 5.690976547533968 Test RE 1.1402536161665187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 1.0690582 Test MSE 5.682651165524732 Test RE 1.1394192671518135\n",
      "51 Train Loss 1.0543512 Test MSE 5.706559434351295 Test RE 1.1418136556645928\n",
      "52 Train Loss 1.0381969 Test MSE 5.729281894869645 Test RE 1.1440846422756512\n",
      "53 Train Loss 1.0203264 Test MSE 5.754849757697595 Test RE 1.1466346334534012\n",
      "54 Train Loss 1.0110667 Test MSE 5.798198359378036 Test RE 1.1509450637684686\n",
      "55 Train Loss 0.9957621 Test MSE 5.797855336196787 Test RE 1.1509110181346305\n",
      "56 Train Loss 0.9825022 Test MSE 5.797398978412142 Test RE 1.1508657222874716\n",
      "57 Train Loss 0.9664338 Test MSE 5.825866632349305 Test RE 1.1536878780807074\n",
      "58 Train Loss 0.9548399 Test MSE 5.838487299386228 Test RE 1.1549368281909766\n",
      "59 Train Loss 0.94177985 Test MSE 5.8655185932766045 Test RE 1.1576073302701817\n",
      "60 Train Loss 0.9297118 Test MSE 5.833298130987524 Test RE 1.1544234679971197\n",
      "61 Train Loss 0.9192529 Test MSE 5.867608884571464 Test RE 1.1578135798067957\n",
      "62 Train Loss 0.90679353 Test MSE 5.875479635431736 Test RE 1.1585898592488348\n",
      "63 Train Loss 0.8983446 Test MSE 5.894709618466893 Test RE 1.16048429720065\n",
      "64 Train Loss 0.8923677 Test MSE 5.896615801842946 Test RE 1.1606719160330574\n",
      "65 Train Loss 0.8865906 Test MSE 5.900780420511421 Test RE 1.1610817191222973\n",
      "66 Train Loss 0.88123244 Test MSE 5.903074945411498 Test RE 1.1613074411275661\n",
      "67 Train Loss 0.8752122 Test MSE 5.909577355225987 Test RE 1.1619468721549138\n",
      "68 Train Loss 0.8695208 Test MSE 5.905670829618456 Test RE 1.1615627562240143\n",
      "69 Train Loss 0.8623055 Test MSE 5.937158926643377 Test RE 1.1646552733833562\n",
      "70 Train Loss 0.8563688 Test MSE 5.935017436095561 Test RE 1.1644452130471223\n",
      "71 Train Loss 0.8489528 Test MSE 5.964374007095835 Test RE 1.16732152736773\n",
      "72 Train Loss 0.84302235 Test MSE 5.964520733394295 Test RE 1.167335885598221\n",
      "73 Train Loss 0.8383862 Test MSE 5.971627476791862 Test RE 1.1680311205781604\n",
      "74 Train Loss 0.83490777 Test MSE 5.974794650475606 Test RE 1.1683408240102648\n",
      "75 Train Loss 0.83002865 Test MSE 5.981999377317027 Test RE 1.1690450356965933\n",
      "76 Train Loss 0.82426935 Test MSE 5.982089555512008 Test RE 1.169053847296797\n",
      "77 Train Loss 0.8205411 Test MSE 5.9955633758977855 Test RE 1.170369671960324\n",
      "78 Train Loss 0.8161928 Test MSE 6.025738811101307 Test RE 1.173311187788814\n",
      "79 Train Loss 0.8128785 Test MSE 6.030524850926779 Test RE 1.1737770559286371\n",
      "80 Train Loss 0.8079855 Test MSE 6.03441055792468 Test RE 1.1741551506524435\n",
      "81 Train Loss 0.8034453 Test MSE 6.030743240442146 Test RE 1.1737983093259776\n",
      "82 Train Loss 0.7985035 Test MSE 6.034107376915814 Test RE 1.1741256543154655\n",
      "83 Train Loss 0.7926109 Test MSE 6.06313968336205 Test RE 1.1769468397913512\n",
      "84 Train Loss 0.78763604 Test MSE 6.041778943183719 Test RE 1.174871789667155\n",
      "85 Train Loss 0.78111565 Test MSE 6.038203962275941 Test RE 1.174524146551001\n",
      "86 Train Loss 0.7779654 Test MSE 6.051451932486054 Test RE 1.1758119082398388\n",
      "87 Train Loss 0.7743437 Test MSE 6.060123219332996 Test RE 1.1766540327913808\n",
      "88 Train Loss 0.76949024 Test MSE 6.074334225905192 Test RE 1.178032853494378\n",
      "89 Train Loss 0.7657732 Test MSE 6.099485642591546 Test RE 1.180469218263375\n",
      "90 Train Loss 0.7611909 Test MSE 6.105805982746998 Test RE 1.181080666150994\n",
      "91 Train Loss 0.75767016 Test MSE 6.1328153906964 Test RE 1.1836900750654895\n",
      "92 Train Loss 0.75287926 Test MSE 6.14236192667867 Test RE 1.184611001675349\n",
      "93 Train Loss 0.74855536 Test MSE 6.141886340742918 Test RE 1.1845651402262685\n",
      "94 Train Loss 0.74555075 Test MSE 6.144697588061778 Test RE 1.1848362071603702\n",
      "95 Train Loss 0.7425469 Test MSE 6.164823407796257 Test RE 1.1867749767957838\n",
      "96 Train Loss 0.7394183 Test MSE 6.171505963911648 Test RE 1.1874180237930319\n",
      "97 Train Loss 0.73562413 Test MSE 6.1717057974099525 Test RE 1.187437247948225\n",
      "98 Train Loss 0.73224974 Test MSE 6.184147171325106 Test RE 1.1886335066069411\n",
      "99 Train Loss 0.72894144 Test MSE 6.185264915688684 Test RE 1.1887409206397541\n",
      "Training time: 80.45\n",
      "4\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 58.110977 Test MSE 8.568905247836497 Test RE 1.399170791977882\n",
      "1 Train Loss 56.245903 Test MSE 8.289514545606373 Test RE 1.376171657561582\n",
      "2 Train Loss 53.849224 Test MSE 8.058128880365782 Test RE 1.3568291484142403\n",
      "3 Train Loss 45.793015 Test MSE 8.856152496659075 Test RE 1.422429017698237\n",
      "4 Train Loss 43.33757 Test MSE 7.878099864339882 Test RE 1.341586875931771\n",
      "5 Train Loss 40.68505 Test MSE 7.913204001627123 Test RE 1.3445725516751643\n",
      "6 Train Loss 37.842274 Test MSE 7.611104287948699 Test RE 1.318657158194579\n",
      "7 Train Loss 33.986687 Test MSE 6.696560398164675 Test RE 1.2368981939429669\n",
      "8 Train Loss 29.896397 Test MSE 5.819248286687246 Test RE 1.153032381189501\n",
      "9 Train Loss 24.880714 Test MSE 5.193921824592242 Test RE 1.0893207203976238\n",
      "10 Train Loss 19.476238 Test MSE 6.04995684117945 Test RE 1.1756666493188221\n",
      "11 Train Loss 16.105968 Test MSE 5.738884848528683 Test RE 1.1450430513878949\n",
      "12 Train Loss 13.931318 Test MSE 5.742625777047907 Test RE 1.1454161923801374\n",
      "13 Train Loss 11.456574 Test MSE 5.188251120993642 Test RE 1.0887258999398175\n",
      "14 Train Loss 8.601236 Test MSE 4.8487031387016195 Test RE 1.0524969789580298\n",
      "15 Train Loss 6.529819 Test MSE 4.781168473730558 Test RE 1.0451414783845034\n",
      "16 Train Loss 5.1664305 Test MSE 4.565947169021681 Test RE 1.0213474321385514\n",
      "17 Train Loss 4.3404436 Test MSE 4.411551956074474 Test RE 1.0039307564178381\n",
      "18 Train Loss 3.6745555 Test MSE 4.058204882470188 Test RE 0.9628863825078178\n",
      "19 Train Loss 3.1362457 Test MSE 3.6437737841330615 Test RE 0.9123968216369498\n",
      "20 Train Loss 2.7479835 Test MSE 3.482673660963791 Test RE 0.8919991714737266\n",
      "21 Train Loss 2.455797 Test MSE 3.2412563602463123 Test RE 0.8605274951972092\n",
      "22 Train Loss 2.2131267 Test MSE 2.9678227334322775 Test RE 0.8234306698389846\n",
      "23 Train Loss 1.9723741 Test MSE 2.600769069027857 Test RE 0.770830616508256\n",
      "24 Train Loss 1.8006493 Test MSE 2.369212470051022 Test RE 0.7357157699825275\n",
      "25 Train Loss 1.6281599 Test MSE 2.0489440669608023 Test RE 0.6841843119419407\n",
      "26 Train Loss 1.5238618 Test MSE 1.8960424535087517 Test RE 0.658160916241082\n",
      "27 Train Loss 1.381907 Test MSE 1.7281854396018874 Test RE 0.6283523319313834\n",
      "28 Train Loss 1.2328137 Test MSE 1.472333133177315 Test RE 0.5799774431415705\n",
      "29 Train Loss 1.1240566 Test MSE 1.3502746220163824 Test RE 0.5554169291358687\n",
      "30 Train Loss 0.95874995 Test MSE 1.056806201429694 Test RE 0.49136671797895815\n",
      "31 Train Loss 0.8831628 Test MSE 1.0061678274479307 Test RE 0.4794499454265103\n",
      "32 Train Loss 0.8055885 Test MSE 0.9555331574916247 Test RE 0.4672302377145556\n",
      "33 Train Loss 0.698959 Test MSE 0.8015776728872359 Test RE 0.4279380133776333\n",
      "34 Train Loss 0.5938859 Test MSE 0.6510504976547986 Test RE 0.3856695915401246\n",
      "35 Train Loss 0.47354656 Test MSE 0.40088481759427713 Test RE 0.3026341021775363\n",
      "36 Train Loss 0.35479996 Test MSE 0.24393600340916857 Test RE 0.23607283328969678\n",
      "37 Train Loss 0.26714557 Test MSE 0.18850352818846042 Test RE 0.20752374774865667\n",
      "38 Train Loss 0.22583607 Test MSE 0.1544582435385418 Test RE 0.18785104104167108\n",
      "39 Train Loss 0.18138333 Test MSE 0.12387391668921575 Test RE 0.16822788891777526\n",
      "40 Train Loss 0.14335378 Test MSE 0.07236161073812208 Test RE 0.12857666977156243\n",
      "41 Train Loss 0.11726503 Test MSE 0.041762792897440955 Test RE 0.09767936497341546\n",
      "42 Train Loss 0.096414775 Test MSE 0.04885737903999697 Test RE 0.10565088589680573\n",
      "43 Train Loss 0.07745424 Test MSE 0.042276261841421366 Test RE 0.09827800905188157\n",
      "44 Train Loss 0.06771213 Test MSE 0.034703807744631825 Test RE 0.08904235231592336\n",
      "45 Train Loss 0.055108543 Test MSE 0.028698720296664683 Test RE 0.08097283147823478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 0.049269967 Test MSE 0.02719806843317972 Test RE 0.07882737987091705\n",
      "47 Train Loss 0.042644195 Test MSE 0.028579665228307415 Test RE 0.08080470125036679\n",
      "48 Train Loss 0.03790515 Test MSE 0.02643055085105656 Test RE 0.0777071833804999\n",
      "49 Train Loss 0.03479824 Test MSE 0.02260706944880878 Test RE 0.07186711225627292\n",
      "50 Train Loss 0.031926338 Test MSE 0.02124400807461342 Test RE 0.06966686843451705\n",
      "51 Train Loss 0.02944995 Test MSE 0.020018645400590986 Test RE 0.06762782243123915\n",
      "52 Train Loss 0.026772823 Test MSE 0.018535522203886903 Test RE 0.06507444506534511\n",
      "53 Train Loss 0.024514567 Test MSE 0.01774082882105114 Test RE 0.06366415996237763\n",
      "54 Train Loss 0.021738797 Test MSE 0.01661861906699819 Test RE 0.06161770615575539\n",
      "55 Train Loss 0.01989222 Test MSE 0.012585852896879596 Test RE 0.05362278745179044\n",
      "56 Train Loss 0.016952788 Test MSE 0.011801256365212238 Test RE 0.05192448319881073\n",
      "57 Train Loss 0.015302494 Test MSE 0.009453676030741796 Test RE 0.046473824962494054\n",
      "58 Train Loss 0.014271904 Test MSE 0.009617520352935057 Test RE 0.0468748204600677\n",
      "59 Train Loss 0.013267053 Test MSE 0.009045840953426308 Test RE 0.04546032477623078\n",
      "60 Train Loss 0.0119916685 Test MSE 0.008664485612143034 Test RE 0.04449174636070769\n",
      "61 Train Loss 0.011212561 Test MSE 0.007660211026804939 Test RE 0.04183390706200476\n",
      "62 Train Loss 0.010626529 Test MSE 0.006945171105224163 Test RE 0.039833597907042634\n",
      "63 Train Loss 0.00993283 Test MSE 0.006397300818840066 Test RE 0.03823018914810912\n",
      "64 Train Loss 0.008774656 Test MSE 0.005853662274255931 Test RE 0.03656974158171257\n",
      "65 Train Loss 0.008021192 Test MSE 0.00583468957300502 Test RE 0.03651042914921232\n",
      "66 Train Loss 0.00761922 Test MSE 0.005849361176286221 Test RE 0.03655630393041522\n",
      "67 Train Loss 0.0070845527 Test MSE 0.005931702751864274 Test RE 0.036812706652149224\n",
      "68 Train Loss 0.0063854186 Test MSE 0.0056254546456725235 Test RE 0.0358498113030288\n",
      "69 Train Loss 0.0057662623 Test MSE 0.005037317849360445 Test RE 0.033924053379431225\n",
      "70 Train Loss 0.0052568945 Test MSE 0.004406601790160505 Test RE 0.03172926146773451\n",
      "71 Train Loss 0.0047726436 Test MSE 0.0043407540705507255 Test RE 0.03149130447008407\n",
      "72 Train Loss 0.0045533846 Test MSE 0.0043480884574838485 Test RE 0.03151789799805279\n",
      "73 Train Loss 0.004173066 Test MSE 0.004523312797036566 Test RE 0.032146698043638205\n",
      "74 Train Loss 0.003963154 Test MSE 0.004640052965792287 Test RE 0.032558885413111395\n",
      "75 Train Loss 0.0037183375 Test MSE 0.004176952106522788 Test RE 0.03089141544163171\n",
      "76 Train Loss 0.0034224226 Test MSE 0.004503398755734009 Test RE 0.032075856511114484\n",
      "77 Train Loss 0.003185239 Test MSE 0.0036925706612260813 Test RE 0.029045072686427743\n",
      "78 Train Loss 0.0029455486 Test MSE 0.0032199025011083286 Test RE 0.027122481459395407\n",
      "79 Train Loss 0.0028052123 Test MSE 0.0031596599236134257 Test RE 0.026867560230900076\n",
      "80 Train Loss 0.002608547 Test MSE 0.002938010059568219 Test RE 0.025908048388025982\n",
      "81 Train Loss 0.002504023 Test MSE 0.0027717375406291016 Test RE 0.025164257019249278\n",
      "82 Train Loss 0.0023691894 Test MSE 0.0029515285355421386 Test RE 0.02596758449676759\n",
      "83 Train Loss 0.0022804174 Test MSE 0.002793519946171095 Test RE 0.025262943372820965\n",
      "84 Train Loss 0.002178869 Test MSE 0.0026191845650164044 Test RE 0.024461952113074316\n",
      "85 Train Loss 0.0021020374 Test MSE 0.002356868232138034 Test RE 0.023204686832235415\n",
      "86 Train Loss 0.0019681114 Test MSE 0.0023957384434433377 Test RE 0.023395253815299125\n",
      "87 Train Loss 0.0018042272 Test MSE 0.002366760525477982 Test RE 0.023253333422794762\n",
      "88 Train Loss 0.00174345 Test MSE 0.0025183678122734604 Test RE 0.023986541859841032\n",
      "89 Train Loss 0.0016322667 Test MSE 0.002485378498749643 Test RE 0.023828918326317564\n",
      "90 Train Loss 0.0015553643 Test MSE 0.002367778465368507 Test RE 0.02325833349585045\n",
      "91 Train Loss 0.0015115292 Test MSE 0.0022858721409765607 Test RE 0.022852516313259283\n",
      "92 Train Loss 0.0014323764 Test MSE 0.002164101741919547 Test RE 0.022235499892249655\n",
      "93 Train Loss 0.0013746296 Test MSE 0.001993919963092517 Test RE 0.02134331730932807\n",
      "94 Train Loss 0.0013484597 Test MSE 0.0020613110662012976 Test RE 0.02170100403323389\n",
      "95 Train Loss 0.001322814 Test MSE 0.0019636740123293614 Test RE 0.021180819370727477\n",
      "96 Train Loss 0.0012848027 Test MSE 0.0019017490852556566 Test RE 0.02084417296541926\n",
      "97 Train Loss 0.001219651 Test MSE 0.0016231321582823052 Test RE 0.019256839088500666\n",
      "98 Train Loss 0.0011584788 Test MSE 0.0016658663330218959 Test RE 0.019508691267154217\n",
      "99 Train Loss 0.0011071106 Test MSE 0.0015621742327808297 Test RE 0.01889177634004512\n",
      "Training time: 83.99\n",
      "5\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.21963 Test MSE 8.29429074902735 Test RE 1.3765680576906263\n",
      "1 Train Loss 51.850708 Test MSE 7.954041599021712 Test RE 1.3480375484385974\n",
      "2 Train Loss 45.864346 Test MSE 8.47789729960704 Test RE 1.3917208572506892\n",
      "3 Train Loss 42.967033 Test MSE 8.48598298314038 Test RE 1.392384366856658\n",
      "4 Train Loss 41.07186 Test MSE 8.451852904301635 Test RE 1.3895815055123277\n",
      "5 Train Loss 38.025593 Test MSE 8.592303543454609 Test RE 1.4010797810811715\n",
      "6 Train Loss 32.62831 Test MSE 8.745597130378082 Test RE 1.4135227219540554\n",
      "7 Train Loss 29.204224 Test MSE 9.229315381031629 Test RE 1.452087556101453\n",
      "8 Train Loss 27.546007 Test MSE 9.075806170358803 Test RE 1.4399607897377928\n",
      "9 Train Loss 25.595306 Test MSE 9.039207769217127 Test RE 1.4370545190564772\n",
      "10 Train Loss 23.621819 Test MSE 9.055331917542967 Test RE 1.4383356576681992\n",
      "11 Train Loss 22.149696 Test MSE 9.086036045864681 Test RE 1.4407720934796593\n",
      "12 Train Loss 20.688656 Test MSE 8.973595761990905 Test RE 1.4318295171803839\n",
      "13 Train Loss 19.078506 Test MSE 8.800477043891506 Test RE 1.4179508179910751\n",
      "14 Train Loss 16.770092 Test MSE 7.952251239760542 Test RE 1.3478858263671598\n",
      "15 Train Loss 14.50539 Test MSE 7.1587469108444 Test RE 1.278870485644699\n",
      "16 Train Loss 12.366596 Test MSE 6.584455326481733 Test RE 1.2265012298096678\n",
      "17 Train Loss 10.050394 Test MSE 6.312026869942349 Test RE 1.2008602787634615\n",
      "18 Train Loss 9.21331 Test MSE 6.241832006676363 Test RE 1.1941643400343085\n",
      "19 Train Loss 8.573236 Test MSE 5.919405459999378 Test RE 1.1629126765494349\n",
      "20 Train Loss 8.101629 Test MSE 5.755468128774943 Test RE 1.1466962359866875\n",
      "21 Train Loss 7.597134 Test MSE 5.667488339291435 Test RE 1.1378981147848253\n",
      "22 Train Loss 7.24399 Test MSE 5.6893200902689625 Test RE 1.1400876588100521\n",
      "23 Train Loss 6.8343563 Test MSE 5.670228082618244 Test RE 1.1381731195051084\n",
      "24 Train Loss 6.4884567 Test MSE 5.605038424483359 Test RE 1.131611513147203\n",
      "25 Train Loss 5.9853764 Test MSE 5.48920797991249 Test RE 1.1198578619118795\n",
      "26 Train Loss 4.7529745 Test MSE 4.786783002912882 Test RE 1.0457549534879893\n",
      "27 Train Loss 3.9746618 Test MSE 4.67183296359499 Test RE 1.0331222469205192\n",
      "28 Train Loss 3.4879384 Test MSE 4.54454649910045 Test RE 1.018951084754742\n",
      "29 Train Loss 3.0318685 Test MSE 4.327998256436948 Test RE 0.9943782097481896\n",
      "30 Train Loss 2.8193247 Test MSE 4.3083760549773515 Test RE 0.9921215018728609\n",
      "31 Train Loss 2.5953915 Test MSE 4.3119313316405155 Test RE 0.9925307673364231\n",
      "32 Train Loss 2.4015677 Test MSE 4.216097940830044 Test RE 0.9814392124737445\n",
      "33 Train Loss 2.223868 Test MSE 4.172795620056526 Test RE 0.9763861654507942\n",
      "34 Train Loss 2.1026359 Test MSE 4.068875164746242 Test RE 0.9641514153364167\n",
      "35 Train Loss 2.0013 Test MSE 4.022152824434363 Test RE 0.9585998224665087\n",
      "36 Train Loss 1.9120122 Test MSE 3.9781368682166707 Test RE 0.953340231265257\n",
      "37 Train Loss 1.814923 Test MSE 3.906279374691142 Test RE 0.9446908535257059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 1.7044215 Test MSE 3.8787766082336512 Test RE 0.9413593578723135\n",
      "39 Train Loss 1.6255438 Test MSE 3.8750188079850143 Test RE 0.9409032478691798\n",
      "40 Train Loss 1.5346446 Test MSE 3.830141040574813 Test RE 0.9354389379778804\n",
      "41 Train Loss 1.4320697 Test MSE 3.6851955165654307 Test RE 0.9175681439183612\n",
      "42 Train Loss 1.3501492 Test MSE 3.6058215591973477 Test RE 0.9076327870187623\n",
      "43 Train Loss 1.2525908 Test MSE 3.5274212297938727 Test RE 0.8977113631342727\n",
      "44 Train Loss 1.1555642 Test MSE 3.438969196806981 Test RE 0.8863846023463957\n",
      "45 Train Loss 1.0708822 Test MSE 3.3652706906202 Test RE 0.876835373345459\n",
      "46 Train Loss 1.0037559 Test MSE 3.2887063093725635 Test RE 0.8668033997621398\n",
      "47 Train Loss 0.951837 Test MSE 3.3093656534344533 Test RE 0.8695217261385186\n",
      "48 Train Loss 0.883426 Test MSE 3.2590801005450754 Test RE 0.8628902812465367\n",
      "49 Train Loss 0.83870035 Test MSE 3.228096525097559 Test RE 0.8587788032287609\n",
      "50 Train Loss 0.80782646 Test MSE 3.2098570467494203 Test RE 0.8563492188237628\n",
      "51 Train Loss 0.7702175 Test MSE 3.2131110776175382 Test RE 0.8567831759868418\n",
      "52 Train Loss 0.74311006 Test MSE 3.206428168218708 Test RE 0.8558917059195881\n",
      "53 Train Loss 0.71745574 Test MSE 3.16940952710364 Test RE 0.8509366707816972\n",
      "54 Train Loss 0.6908609 Test MSE 3.1426937597958773 Test RE 0.8473426992002489\n",
      "55 Train Loss 0.674642 Test MSE 3.1421841857800175 Test RE 0.8472739999633165\n",
      "56 Train Loss 0.65633 Test MSE 3.1360746317923693 Test RE 0.8464498940829012\n",
      "57 Train Loss 0.63295466 Test MSE 3.1583637331810013 Test RE 0.8494525655026632\n",
      "58 Train Loss 0.60853887 Test MSE 3.1907423077262376 Test RE 0.8537956263020989\n",
      "59 Train Loss 0.5942075 Test MSE 3.215318033389054 Test RE 0.8570773702970171\n",
      "60 Train Loss 0.57375497 Test MSE 3.2241680673782365 Test RE 0.8582560953073838\n",
      "61 Train Loss 0.5562874 Test MSE 3.219847008266213 Test RE 0.8576807812041148\n",
      "62 Train Loss 0.541657 Test MSE 3.2488592302586428 Test RE 0.8615361544722706\n",
      "63 Train Loss 0.5243545 Test MSE 3.234304872594064 Test RE 0.8596042178642828\n",
      "64 Train Loss 0.512549 Test MSE 3.230226744656985 Test RE 0.8590621103861179\n",
      "65 Train Loss 0.49614277 Test MSE 3.2333570300074412 Test RE 0.8594782512006427\n",
      "66 Train Loss 0.48214322 Test MSE 3.2357853815751296 Test RE 0.8598009380574141\n",
      "67 Train Loss 0.4734265 Test MSE 3.2348973924025506 Test RE 0.8596829533610126\n",
      "68 Train Loss 0.46732014 Test MSE 3.230299084749658 Test RE 0.8590717295691764\n",
      "69 Train Loss 0.45842618 Test MSE 3.248912941461366 Test RE 0.861543276041491\n",
      "70 Train Loss 0.44741246 Test MSE 3.277756780577874 Test RE 0.8653592145632747\n",
      "71 Train Loss 0.43851292 Test MSE 3.2874450759581344 Test RE 0.8666371723546885\n",
      "72 Train Loss 0.43341917 Test MSE 3.2887826300478546 Test RE 0.8668134576132799\n",
      "73 Train Loss 0.42588228 Test MSE 3.28560784650378 Test RE 0.8663949730446706\n",
      "74 Train Loss 0.41507113 Test MSE 3.289096562776953 Test RE 0.8668548277266953\n",
      "75 Train Loss 0.40708062 Test MSE 3.2962409191248967 Test RE 0.8677957791779716\n",
      "76 Train Loss 0.4013327 Test MSE 3.3110021879119547 Test RE 0.8697366957961326\n",
      "77 Train Loss 0.39772573 Test MSE 3.3225965474986414 Test RE 0.8712581728078272\n",
      "78 Train Loss 0.3925572 Test MSE 3.333268864314025 Test RE 0.8726563095388007\n",
      "79 Train Loss 0.3864987 Test MSE 3.3378591452631907 Test RE 0.873256975080398\n",
      "80 Train Loss 0.38029674 Test MSE 3.3613978001551237 Test RE 0.8763306791821798\n",
      "81 Train Loss 0.37607104 Test MSE 3.362841129089298 Test RE 0.8765187999811498\n",
      "82 Train Loss 0.37211487 Test MSE 3.3603224922148356 Test RE 0.876190499297505\n",
      "83 Train Loss 0.3669385 Test MSE 3.360580923944616 Test RE 0.8762241911639013\n",
      "84 Train Loss 0.36322123 Test MSE 3.380690948768236 Test RE 0.8788419837357204\n",
      "85 Train Loss 0.35921264 Test MSE 3.394806518470502 Test RE 0.8806748092221649\n",
      "86 Train Loss 0.35304224 Test MSE 3.398614984482469 Test RE 0.8811686635714662\n",
      "87 Train Loss 0.34744588 Test MSE 3.404440873458064 Test RE 0.8819235876678673\n",
      "88 Train Loss 0.34352654 Test MSE 3.3929166020040893 Test RE 0.8804296356717041\n",
      "89 Train Loss 0.3396377 Test MSE 3.400119854071215 Test RE 0.8813637279099495\n",
      "90 Train Loss 0.33551195 Test MSE 3.4010323952297297 Test RE 0.8814819923763328\n",
      "91 Train Loss 0.3312567 Test MSE 3.395528855724682 Test RE 0.8807684979765042\n",
      "92 Train Loss 0.3277956 Test MSE 3.398247685950603 Test RE 0.8811210470125276\n",
      "93 Train Loss 0.32490677 Test MSE 3.4041819335261523 Test RE 0.8818900477145051\n",
      "94 Train Loss 0.3220459 Test MSE 3.4217641217077266 Test RE 0.8841645423702106\n",
      "95 Train Loss 0.31777385 Test MSE 3.4515264011114133 Test RE 0.8880014197419986\n",
      "96 Train Loss 0.31498984 Test MSE 3.459931929467262 Test RE 0.8890820405187462\n",
      "97 Train Loss 0.3122493 Test MSE 3.458381788168985 Test RE 0.8888828520348244\n",
      "98 Train Loss 0.30951676 Test MSE 3.461890533748621 Test RE 0.8893336514692288\n",
      "99 Train Loss 0.3064642 Test MSE 3.4660816566902106 Test RE 0.8898718226221688\n",
      "Training time: 81.69\n",
      "6\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.36839 Test MSE 8.45420658751615 Test RE 1.389774978294615\n",
      "1 Train Loss 58.813614 Test MSE 8.591541164195787 Test RE 1.4010176220888515\n",
      "2 Train Loss 58.760387 Test MSE 8.567688201354262 Test RE 1.3990714259381218\n",
      "3 Train Loss 58.655212 Test MSE 8.506527712477025 Test RE 1.394068842710345\n",
      "4 Train Loss 57.956142 Test MSE 8.129515865669562 Test RE 1.3628259727565049\n",
      "5 Train Loss 55.778053 Test MSE 8.458266387087743 Test RE 1.3901086305778705\n",
      "6 Train Loss 49.719337 Test MSE 8.932568819874009 Test RE 1.4285526321067812\n",
      "7 Train Loss 47.05594 Test MSE 8.647045142449251 Test RE 1.4055358373047175\n",
      "8 Train Loss 46.968536 Test MSE 8.618093666010134 Test RE 1.4031809024680637\n",
      "9 Train Loss 46.8693 Test MSE 8.603194406164528 Test RE 1.4019674438184386\n",
      "10 Train Loss 46.35665 Test MSE 8.318683164328696 Test RE 1.3785907242463362\n",
      "11 Train Loss 45.86383 Test MSE 8.393721468361196 Test RE 1.3847945229213687\n",
      "12 Train Loss 45.193043 Test MSE 8.293879784508439 Test RE 1.3765339542540316\n",
      "13 Train Loss 43.53814 Test MSE 8.0080698060175 Test RE 1.3526081048202703\n",
      "14 Train Loss 40.860107 Test MSE 7.9010302653154705 Test RE 1.3435379030115755\n",
      "15 Train Loss 37.96557 Test MSE 7.284322701455433 Test RE 1.2900384324136243\n",
      "16 Train Loss 36.951508 Test MSE 7.402240230976286 Test RE 1.3004379896265124\n",
      "17 Train Loss 35.834564 Test MSE 7.242742556841114 Test RE 1.2863512845101306\n",
      "18 Train Loss 35.6036 Test MSE 7.1907312877094105 Test RE 1.2817242175566366\n",
      "19 Train Loss 35.470562 Test MSE 7.13883985415064 Test RE 1.2770911050474993\n",
      "20 Train Loss 35.31579 Test MSE 7.141619664911389 Test RE 1.2773397257017818\n",
      "21 Train Loss 35.230392 Test MSE 7.154182348802256 Test RE 1.2784627037682377\n",
      "22 Train Loss 35.142952 Test MSE 7.200266409100969 Test RE 1.282573738051654\n",
      "23 Train Loss 34.972088 Test MSE 7.1137734749494115 Test RE 1.2748470289278395\n",
      "24 Train Loss 34.86087 Test MSE 7.128444055674159 Test RE 1.2761608965733637\n",
      "25 Train Loss 34.81346 Test MSE 7.098499039176475 Test RE 1.2734776408620485\n",
      "26 Train Loss 34.784897 Test MSE 7.07683684831335 Test RE 1.271533047100914\n",
      "27 Train Loss 34.70362 Test MSE 7.041928397652897 Test RE 1.2683930762988669\n",
      "28 Train Loss 34.522346 Test MSE 6.985615860296483 Test RE 1.263311385809484\n",
      "29 Train Loss 34.388817 Test MSE 7.002872513289241 Test RE 1.26487081018374\n",
      "30 Train Loss 34.308525 Test MSE 6.956670157877849 Test RE 1.2606913308855108\n",
      "31 Train Loss 34.201714 Test MSE 6.947037298397649 Test RE 1.2598181926578556\n",
      "32 Train Loss 34.15697 Test MSE 6.939634559645814 Test RE 1.2591467848083506\n",
      "33 Train Loss 34.12092 Test MSE 6.89282367234272 Test RE 1.2548928495724794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 34.108078 Test MSE 6.90054763726467 Test RE 1.2555957570422815\n",
      "35 Train Loss 34.092922 Test MSE 6.892223430804473 Test RE 1.2548382090326011\n",
      "36 Train Loss 34.053444 Test MSE 6.865356670806919 Test RE 1.2523900617589965\n",
      "37 Train Loss 34.01096 Test MSE 6.875351959684445 Test RE 1.2533014089854986\n",
      "38 Train Loss 33.931953 Test MSE 6.896661149175542 Test RE 1.2552421224102035\n",
      "39 Train Loss 33.885246 Test MSE 6.878628366620204 Test RE 1.2535999999782605\n",
      "40 Train Loss 33.79955 Test MSE 6.880202466736766 Test RE 1.2537434282114912\n",
      "41 Train Loss 33.695198 Test MSE 6.877812412384188 Test RE 1.2535256457239334\n",
      "42 Train Loss 33.65158 Test MSE 6.896477124755657 Test RE 1.2552253754119582\n",
      "43 Train Loss 33.61554 Test MSE 6.865821044010006 Test RE 1.252432416918258\n",
      "44 Train Loss 33.564 Test MSE 6.8922845128783115 Test RE 1.2548437694987615\n",
      "45 Train Loss 33.494537 Test MSE 6.977621432684152 Test RE 1.2625883040678418\n",
      "46 Train Loss 33.249317 Test MSE 6.959745368407657 Test RE 1.2609699457123837\n",
      "47 Train Loss 33.050423 Test MSE 6.92715948888603 Test RE 1.2580145197861539\n",
      "48 Train Loss 32.909218 Test MSE 6.956736384189828 Test RE 1.2606973316543264\n",
      "49 Train Loss 32.806385 Test MSE 7.034793175531367 Test RE 1.2677503148612612\n",
      "50 Train Loss 32.435017 Test MSE 7.061533346949384 Test RE 1.270157472151895\n",
      "51 Train Loss 32.243782 Test MSE 7.020719170711198 Test RE 1.26648153150841\n",
      "52 Train Loss 31.822035 Test MSE 6.86155224345518 Test RE 1.2520430086126544\n",
      "53 Train Loss 31.16386 Test MSE 6.830274396962752 Test RE 1.2491860793082132\n",
      "54 Train Loss 29.88497 Test MSE 6.669959240173636 Test RE 1.2344390460405126\n",
      "55 Train Loss 27.779015 Test MSE 6.316907624309742 Test RE 1.201324469711064\n",
      "56 Train Loss 26.228235 Test MSE 6.461792411065635 Test RE 1.2150231739580066\n",
      "57 Train Loss 25.482922 Test MSE 6.444330343847368 Test RE 1.2133803504010168\n",
      "58 Train Loss 24.10299 Test MSE 6.214185996344871 Test RE 1.1915168387331154\n",
      "59 Train Loss 22.27275 Test MSE 5.97341221110243 Test RE 1.1682056516830077\n",
      "60 Train Loss 21.157211 Test MSE 6.209431464798947 Test RE 1.1910609311998246\n",
      "61 Train Loss 19.977335 Test MSE 6.038231600533797 Test RE 1.1745268345824318\n",
      "62 Train Loss 19.578888 Test MSE 5.75962001450298 Test RE 1.1471097638982777\n",
      "63 Train Loss 19.011112 Test MSE 5.707450929608666 Test RE 1.1419028409011602\n",
      "64 Train Loss 18.084705 Test MSE 5.733320876231815 Test RE 1.1444878448507112\n",
      "65 Train Loss 17.343008 Test MSE 5.681464729267872 Test RE 1.1393003157276669\n",
      "66 Train Loss 16.145704 Test MSE 6.071875989629074 Test RE 1.177794458961586\n",
      "67 Train Loss 15.31328 Test MSE 6.004003127273469 Test RE 1.1711931271365477\n",
      "68 Train Loss 14.299349 Test MSE 5.783270263999191 Test RE 1.1494624919642098\n",
      "69 Train Loss 13.86812 Test MSE 5.561039082212926 Test RE 1.1271612082030462\n",
      "70 Train Loss 13.304522 Test MSE 5.621551272094166 Test RE 1.1332771918296767\n",
      "71 Train Loss 12.898497 Test MSE 5.529702019132185 Test RE 1.1239808831969933\n",
      "72 Train Loss 12.592314 Test MSE 5.3870767511404525 Test RE 1.1093910089732992\n",
      "73 Train Loss 12.216311 Test MSE 5.231796556404478 Test RE 1.0932852379996238\n",
      "74 Train Loss 11.010815 Test MSE 3.7443922103959197 Test RE 0.9249084066184262\n",
      "75 Train Loss 9.297658 Test MSE 3.436829305706847 Test RE 0.8861087839877773\n",
      "76 Train Loss 8.220848 Test MSE 3.364333401902492 Test RE 0.8767132575914636\n",
      "77 Train Loss 7.451962 Test MSE 3.3027614056005965 Test RE 0.8686536738551325\n",
      "78 Train Loss 6.5004473 Test MSE 3.2320359806777934 Test RE 0.8593026551940158\n",
      "79 Train Loss 5.718452 Test MSE 2.751878191377634 Test RE 0.7929077514192387\n",
      "80 Train Loss 5.3897448 Test MSE 2.426308797446395 Test RE 0.7445281054552586\n",
      "81 Train Loss 4.800237 Test MSE 1.8956377077301905 Test RE 0.658090664103569\n",
      "82 Train Loss 4.2393045 Test MSE 1.346533945086366 Test RE 0.5546470575191631\n",
      "83 Train Loss 3.8310423 Test MSE 1.4375583629842756 Test RE 0.5730873247107067\n",
      "84 Train Loss 3.3250363 Test MSE 1.4901820228459977 Test RE 0.5834823456936141\n",
      "85 Train Loss 2.7455342 Test MSE 1.519669002667741 Test RE 0.5892268963746456\n",
      "86 Train Loss 2.464533 Test MSE 1.4187062152317158 Test RE 0.5693171884634589\n",
      "87 Train Loss 2.2235522 Test MSE 1.3123636760505135 Test RE 0.5475643449235617\n",
      "88 Train Loss 1.9552815 Test MSE 1.1989054649033113 Test RE 0.5233600041088627\n",
      "89 Train Loss 1.7829034 Test MSE 1.0153983358196186 Test RE 0.4816441435276116\n",
      "90 Train Loss 1.4913142 Test MSE 0.7574074453204958 Test RE 0.41598037801625554\n",
      "91 Train Loss 1.3283365 Test MSE 0.6407179172779501 Test RE 0.38259694221866\n",
      "92 Train Loss 1.0349494 Test MSE 0.6234778496851957 Test RE 0.3774144941684907\n",
      "93 Train Loss 0.8808694 Test MSE 0.5230578466654761 Test RE 0.3456868992357473\n",
      "94 Train Loss 0.7367395 Test MSE 0.5185021518308269 Test RE 0.34417818641872144\n",
      "95 Train Loss 0.6738325 Test MSE 0.5860724071723024 Test RE 0.36591793611396173\n",
      "96 Train Loss 0.6198131 Test MSE 0.5590224674314928 Test RE 0.3573737848487811\n",
      "97 Train Loss 0.5682545 Test MSE 0.47571727366190514 Test RE 0.3296723477418623\n",
      "98 Train Loss 0.50849736 Test MSE 0.49522809201236084 Test RE 0.33636492010248625\n",
      "99 Train Loss 0.41060767 Test MSE 0.33756745091696955 Test RE 0.2777079690771146\n",
      "Training time: 82.39\n",
      "7\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 54.295685 Test MSE 7.753321208648262 Test RE 1.3309199914191727\n",
      "1 Train Loss 42.52391 Test MSE 7.2933441756064115 Test RE 1.2908370274039362\n",
      "2 Train Loss 31.884863 Test MSE 6.004918049055833 Test RE 1.171282360041798\n",
      "3 Train Loss 25.378267 Test MSE 5.0968328124707005 Test RE 1.0790914569144143\n",
      "4 Train Loss 22.344002 Test MSE 5.515700087636966 Test RE 1.1225569476470627\n",
      "5 Train Loss 20.188644 Test MSE 5.724148920130357 Test RE 1.143572023626378\n",
      "6 Train Loss 15.965603 Test MSE 5.007147455940369 Test RE 1.0695553165714429\n",
      "7 Train Loss 12.818916 Test MSE 5.225006914324345 Test RE 1.0925755940681627\n",
      "8 Train Loss 10.739851 Test MSE 5.124532886863653 Test RE 1.082019786351127\n",
      "9 Train Loss 9.333835 Test MSE 4.619326342405143 Test RE 1.0273002239419826\n",
      "10 Train Loss 7.505252 Test MSE 4.06821057130086 Test RE 0.9640726718443807\n",
      "11 Train Loss 6.37104 Test MSE 3.785510714374235 Test RE 0.9299729150424736\n",
      "12 Train Loss 5.096176 Test MSE 3.4763821577646175 Test RE 0.8911931021965696\n",
      "13 Train Loss 4.014709 Test MSE 3.141003261900746 Test RE 0.8471147699392653\n",
      "14 Train Loss 3.2762144 Test MSE 2.880730038018379 Test RE 0.8112586506923498\n",
      "15 Train Loss 2.136226 Test MSE 2.17382616094045 Test RE 0.7047262778239283\n",
      "16 Train Loss 1.6031847 Test MSE 1.6545359554982264 Test RE 0.6148174212359309\n",
      "17 Train Loss 1.2384028 Test MSE 1.3967221984616827 Test RE 0.5648889482193947\n",
      "18 Train Loss 0.96317446 Test MSE 1.245939779662074 Test RE 0.533527225754721\n",
      "19 Train Loss 0.841467 Test MSE 1.1053253025928045 Test RE 0.5025197281758835\n",
      "20 Train Loss 0.64485455 Test MSE 0.940007216387648 Test RE 0.463418806210254\n",
      "21 Train Loss 0.46203294 Test MSE 0.5809133579601214 Test RE 0.3643038339685188\n",
      "22 Train Loss 0.3102264 Test MSE 0.40579347723408576 Test RE 0.304481276175345\n",
      "23 Train Loss 0.23498422 Test MSE 0.32663778815237143 Test RE 0.27317520226897374\n",
      "24 Train Loss 0.17135303 Test MSE 0.23010813553830556 Test RE 0.22928415701066152\n",
      "25 Train Loss 0.12683664 Test MSE 0.15379668845844854 Test RE 0.18744832001601947\n",
      "26 Train Loss 0.098518305 Test MSE 0.12308466597220062 Test RE 0.1676911086532243\n",
      "27 Train Loss 0.08066749 Test MSE 0.096929579418061 Test RE 0.14881140751844743\n",
      "28 Train Loss 0.06704122 Test MSE 0.08677419399985019 Test RE 0.140800226841646\n",
      "29 Train Loss 0.052714746 Test MSE 0.08210638432904384 Test RE 0.13696087571141005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 0.04459824 Test MSE 0.0724375918832355 Test RE 0.12864415610397503\n",
      "31 Train Loss 0.036483552 Test MSE 0.054100345673450484 Test RE 0.11117524118778278\n",
      "32 Train Loss 0.031234184 Test MSE 0.04898541927141884 Test RE 0.10578923462569272\n",
      "33 Train Loss 0.027664788 Test MSE 0.04514371290784745 Test RE 0.10155625980767927\n",
      "34 Train Loss 0.025121104 Test MSE 0.03899266443577486 Test RE 0.09438424723169424\n",
      "35 Train Loss 0.021850511 Test MSE 0.041512973535214694 Test RE 0.09738677440200914\n",
      "36 Train Loss 0.019935604 Test MSE 0.03609536167917152 Test RE 0.09081001746517982\n",
      "37 Train Loss 0.01796605 Test MSE 0.033010790216596114 Test RE 0.08684324052006942\n",
      "38 Train Loss 0.015760634 Test MSE 0.03195907764602139 Test RE 0.08544864468985079\n",
      "39 Train Loss 0.014523061 Test MSE 0.03261936990518692 Test RE 0.08632684006103439\n",
      "40 Train Loss 0.013559926 Test MSE 0.031776427848144446 Test RE 0.08520412041090548\n",
      "41 Train Loss 0.011609517 Test MSE 0.028926648922759885 Test RE 0.08129374345367309\n",
      "42 Train Loss 0.01048795 Test MSE 0.026325628807218147 Test RE 0.07755279189360646\n",
      "43 Train Loss 0.00984451 Test MSE 0.02437209365067261 Test RE 0.0746198685069507\n",
      "44 Train Loss 0.00907714 Test MSE 0.022398506994193972 Test RE 0.0715348376183249\n",
      "45 Train Loss 0.008378052 Test MSE 0.020353341080218027 Test RE 0.06819082041613407\n",
      "46 Train Loss 0.007850289 Test MSE 0.019347028037206504 Test RE 0.0664837014797907\n",
      "47 Train Loss 0.0070868284 Test MSE 0.01784287247719105 Test RE 0.06384699269889467\n",
      "48 Train Loss 0.0068658004 Test MSE 0.017511170538454374 Test RE 0.06325074555979351\n",
      "49 Train Loss 0.0061855293 Test MSE 0.01641726301138552 Test RE 0.06124327944669788\n",
      "50 Train Loss 0.0056051095 Test MSE 0.015080650149411227 Test RE 0.058697295684406355\n",
      "51 Train Loss 0.005212338 Test MSE 0.014555927703950864 Test RE 0.05766708583681141\n",
      "52 Train Loss 0.004704546 Test MSE 0.012334926378704354 Test RE 0.053085552428185315\n",
      "53 Train Loss 0.0042576334 Test MSE 0.009607333433699721 Test RE 0.04684998887641371\n",
      "54 Train Loss 0.0039265906 Test MSE 0.008940515147810984 Test RE 0.04519488981780843\n",
      "55 Train Loss 0.003587161 Test MSE 0.008454673753724587 Test RE 0.043949757912274616\n",
      "56 Train Loss 0.0034422155 Test MSE 0.00822042506223763 Test RE 0.04333663613530218\n",
      "57 Train Loss 0.003280512 Test MSE 0.00841286373726137 Test RE 0.04384095315298623\n",
      "58 Train Loss 0.0029613543 Test MSE 0.008070847652525758 Test RE 0.04294055319242366\n",
      "59 Train Loss 0.0026718893 Test MSE 0.007930282514012248 Test RE 0.04256497570886927\n",
      "60 Train Loss 0.0024474894 Test MSE 0.006861594123817122 Test RE 0.03959319718757708\n",
      "61 Train Loss 0.0022627446 Test MSE 0.005676784079761407 Test RE 0.03601299562081873\n",
      "62 Train Loss 0.002195292 Test MSE 0.005189295191505808 Test RE 0.03443199989567675\n",
      "63 Train Loss 0.0020472866 Test MSE 0.005152071187915949 Test RE 0.03430828332169082\n",
      "64 Train Loss 0.001857117 Test MSE 0.005081194118100913 Test RE 0.034071476447848525\n",
      "65 Train Loss 0.0016937287 Test MSE 0.004747602249913641 Test RE 0.03293405631435994\n",
      "66 Train Loss 0.0016434839 Test MSE 0.004443811438716178 Test RE 0.031862941892209354\n",
      "67 Train Loss 0.0015694005 Test MSE 0.00404168612064921 Test RE 0.030387106765962027\n",
      "68 Train Loss 0.001478926 Test MSE 0.004274846547976715 Test RE 0.031251317066563485\n",
      "69 Train Loss 0.0014189617 Test MSE 0.004309761569378376 Test RE 0.031378680874660884\n",
      "70 Train Loss 0.0013450095 Test MSE 0.004175033142313864 Test RE 0.030884318600543057\n",
      "71 Train Loss 0.0012628085 Test MSE 0.0038076452902766483 Test RE 0.029494178360866468\n",
      "72 Train Loss 0.0012031263 Test MSE 0.0033412974836455438 Test RE 0.027629029625956817\n",
      "73 Train Loss 0.0011339359 Test MSE 0.0029913535542720896 Test RE 0.0261421879916114\n",
      "74 Train Loss 0.0010686379 Test MSE 0.0029585615384611495 Test RE 0.025998504311786644\n",
      "75 Train Loss 0.0010484771 Test MSE 0.00283335472812832 Test RE 0.025442426904440495\n",
      "76 Train Loss 0.0010134195 Test MSE 0.002755681701849027 Test RE 0.025091266691106614\n",
      "77 Train Loss 0.0009681816 Test MSE 0.0027293497947906845 Test RE 0.02497109918054963\n",
      "78 Train Loss 0.00094502704 Test MSE 0.0027825178429283022 Test RE 0.025213146033880862\n",
      "79 Train Loss 0.0009149222 Test MSE 0.002665183497532852 Test RE 0.02467582138929196\n",
      "80 Train Loss 0.0008524565 Test MSE 0.002313973115181221 Test RE 0.02299255397607779\n",
      "81 Train Loss 0.00080067385 Test MSE 0.002263893171843895 Test RE 0.022742385929960928\n",
      "82 Train Loss 0.00076595903 Test MSE 0.0020380430399991015 Test RE 0.02157817624310168\n",
      "83 Train Loss 0.0007457123 Test MSE 0.001964880148987218 Test RE 0.02118732326109774\n",
      "84 Train Loss 0.0007378333 Test MSE 0.0019551888236923184 Test RE 0.021135007841709266\n",
      "85 Train Loss 0.00072034914 Test MSE 0.0019176635777749427 Test RE 0.020931206878006377\n",
      "86 Train Loss 0.00069622055 Test MSE 0.0019067581998724456 Test RE 0.020871606181874065\n",
      "87 Train Loss 0.0006745754 Test MSE 0.0018088978418012269 Test RE 0.020328956220133514\n",
      "88 Train Loss 0.0006580733 Test MSE 0.0017419253507272828 Test RE 0.01994907807723593\n",
      "89 Train Loss 0.00064489135 Test MSE 0.0017707007286546566 Test RE 0.020113175507896125\n",
      "90 Train Loss 0.0006350006 Test MSE 0.0017583249946553818 Test RE 0.020042765031256137\n",
      "91 Train Loss 0.0006253299 Test MSE 0.0017374595303435297 Test RE 0.019923489675084022\n",
      "92 Train Loss 0.00061430316 Test MSE 0.001641916825518027 Test RE 0.019367949182464327\n",
      "93 Train Loss 0.00060893525 Test MSE 0.001615211353222669 Test RE 0.019209795412033735\n",
      "94 Train Loss 0.00060521404 Test MSE 0.0016024815015289451 Test RE 0.01913394726715822\n",
      "95 Train Loss 0.00059632387 Test MSE 0.0015127647536083884 Test RE 0.01859061508040342\n",
      "96 Train Loss 0.0005782398 Test MSE 0.0014656689416135303 Test RE 0.018298942933842904\n",
      "97 Train Loss 0.0005595889 Test MSE 0.0013405541693302643 Test RE 0.017500491425518298\n",
      "98 Train Loss 0.0005457421 Test MSE 0.0012463630354652613 Test RE 0.016874477739079727\n",
      "99 Train Loss 0.00052635715 Test MSE 0.0011424816076491353 Test RE 0.016155956267632082\n",
      "Training time: 83.94\n",
      "8\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 55.35606 Test MSE 9.01666270235442 Test RE 1.4352612912711793\n",
      "1 Train Loss 31.871202 Test MSE 8.571784868673053 Test RE 1.3994058711863042\n",
      "2 Train Loss 25.898537 Test MSE 7.717779243585975 Test RE 1.3278659552115424\n",
      "3 Train Loss 21.647015 Test MSE 7.438883562792682 Test RE 1.3036527969931355\n",
      "4 Train Loss 18.470318 Test MSE 7.143617962029587 Test RE 1.277518419463384\n",
      "5 Train Loss 15.540258 Test MSE 6.801206701730207 Test RE 1.2465251558357915\n",
      "6 Train Loss 13.453859 Test MSE 7.106389601184363 Test RE 1.2741852315348623\n",
      "7 Train Loss 12.26663 Test MSE 7.134152051250436 Test RE 1.276671727764296\n",
      "8 Train Loss 11.203783 Test MSE 7.020736772173565 Test RE 1.2664831190888632\n",
      "9 Train Loss 10.211754 Test MSE 7.051257474201085 Test RE 1.269232975470576\n",
      "10 Train Loss 9.330912 Test MSE 6.944259300857744 Test RE 1.2595662779470371\n",
      "11 Train Loss 8.552813 Test MSE 6.672370902700948 Test RE 1.2346621944307357\n",
      "12 Train Loss 8.039909 Test MSE 6.559426698678947 Test RE 1.2241679411346869\n",
      "13 Train Loss 7.536484 Test MSE 6.313582819622787 Test RE 1.2010082790074497\n",
      "14 Train Loss 7.2423534 Test MSE 6.200009529558422 Test RE 1.1901569547854594\n",
      "15 Train Loss 6.8459234 Test MSE 6.104951506650624 Test RE 1.1809980201816737\n",
      "16 Train Loss 6.502919 Test MSE 6.0445769625214565 Test RE 1.1751438066928828\n",
      "17 Train Loss 6.0857124 Test MSE 5.932613886213119 Test RE 1.1642094019812241\n",
      "18 Train Loss 5.595851 Test MSE 5.7460505742063885 Test RE 1.1457576941228313\n",
      "19 Train Loss 4.584125 Test MSE 5.329662078783926 Test RE 1.1034633093551642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 3.6627054 Test MSE 5.105568439801404 Test RE 1.080015805967452\n",
      "21 Train Loss 3.0143504 Test MSE 4.924139280107867 Test RE 1.0606527554397844\n",
      "22 Train Loss 2.6383038 Test MSE 4.816604295096108 Test RE 1.049007382465926\n",
      "23 Train Loss 2.3922691 Test MSE 4.71097065448623 Test RE 1.037440647172358\n",
      "24 Train Loss 2.2164812 Test MSE 4.623168149726011 Test RE 1.027727328347764\n",
      "25 Train Loss 2.0731356 Test MSE 4.554286502213093 Test RE 1.0200424229955154\n",
      "26 Train Loss 1.9234412 Test MSE 4.528852184752274 Test RE 1.0171901203605898\n",
      "27 Train Loss 1.8525562 Test MSE 4.425410346562419 Test RE 1.005506387317173\n",
      "28 Train Loss 1.7809825 Test MSE 4.401057312460424 Test RE 1.0027359196537076\n",
      "29 Train Loss 1.7095306 Test MSE 4.432851970878535 Test RE 1.0063514454264078\n",
      "30 Train Loss 1.6643193 Test MSE 4.462690041068203 Test RE 1.009732702546084\n",
      "31 Train Loss 1.6282399 Test MSE 4.505236010976327 Test RE 1.0145345316957224\n",
      "32 Train Loss 1.6030608 Test MSE 4.4698143540672985 Test RE 1.0105383582184544\n",
      "33 Train Loss 1.570295 Test MSE 4.3946795890155395 Test RE 1.002009106699923\n",
      "34 Train Loss 1.5444385 Test MSE 4.413159633091839 Test RE 1.0041136681688583\n",
      "35 Train Loss 1.5128975 Test MSE 4.412836474865006 Test RE 1.004076903859387\n",
      "36 Train Loss 1.491669 Test MSE 4.40442353357084 Test RE 1.003119325888798\n",
      "37 Train Loss 1.4734061 Test MSE 4.389186969402354 Test RE 1.0013827384403426\n",
      "38 Train Loss 1.4570792 Test MSE 4.3652014165753705 Test RE 0.9986428662922273\n",
      "39 Train Loss 1.4417024 Test MSE 4.336625261044949 Test RE 0.9953687640712638\n",
      "40 Train Loss 1.42327 Test MSE 4.305189057076954 Test RE 0.9917544872426756\n",
      "41 Train Loss 1.4093701 Test MSE 4.288118712477333 Test RE 0.9897863499894552\n",
      "42 Train Loss 1.3988801 Test MSE 4.283834450305875 Test RE 0.9892917783365287\n",
      "43 Train Loss 1.3865703 Test MSE 4.288044601854296 Test RE 0.9897777968213959\n",
      "44 Train Loss 1.3698831 Test MSE 4.288025830704543 Test RE 0.9897756304158071\n",
      "45 Train Loss 1.3507464 Test MSE 4.267450187398711 Test RE 0.9873981075097993\n",
      "46 Train Loss 1.3347975 Test MSE 4.237290965618639 Test RE 0.9839028166122433\n",
      "47 Train Loss 1.319248 Test MSE 4.210437083603957 Test RE 0.9807801132906013\n",
      "48 Train Loss 1.3019208 Test MSE 4.1926010809656145 Test RE 0.9787005474886132\n",
      "49 Train Loss 1.2871771 Test MSE 4.178772901163947 Test RE 0.9770852227050045\n",
      "50 Train Loss 1.2524244 Test MSE 4.083976318864752 Test RE 0.9659389259248305\n",
      "51 Train Loss 1.2173417 Test MSE 4.004754122922721 Test RE 0.9565242588898281\n",
      "52 Train Loss 1.1849484 Test MSE 3.95121569614029 Test RE 0.9501089944525661\n",
      "53 Train Loss 1.1535625 Test MSE 3.8819355320772924 Test RE 0.9417426072337403\n",
      "54 Train Loss 1.1202911 Test MSE 3.7799828206970663 Test RE 0.9292936580146594\n",
      "55 Train Loss 1.0948848 Test MSE 3.7360159453990414 Test RE 0.9238733099959215\n",
      "56 Train Loss 1.0687548 Test MSE 3.650544868661135 Test RE 0.9132441641156507\n",
      "57 Train Loss 1.049418 Test MSE 3.5736920162493675 Test RE 0.903580024212488\n",
      "58 Train Loss 1.0202866 Test MSE 3.4897542985950327 Test RE 0.8929054745819657\n",
      "59 Train Loss 0.9952172 Test MSE 3.4114644246942176 Test RE 0.8828328476994649\n",
      "60 Train Loss 0.97067714 Test MSE 3.3611674072833972 Test RE 0.8763006464675945\n",
      "61 Train Loss 0.9449189 Test MSE 3.325834967861581 Test RE 0.8716826620586218\n",
      "62 Train Loss 0.9270421 Test MSE 3.2808306188251217 Test RE 0.8657648808617784\n",
      "63 Train Loss 0.9121958 Test MSE 3.2599424776765984 Test RE 0.8630044373278638\n",
      "64 Train Loss 0.89796305 Test MSE 3.2257027037423343 Test RE 0.8584603269562977\n",
      "65 Train Loss 0.88410366 Test MSE 3.1898055351326318 Test RE 0.8536702838301722\n",
      "66 Train Loss 0.86852866 Test MSE 3.15348879463264 Test RE 0.8487967467683644\n",
      "67 Train Loss 0.85341334 Test MSE 3.1150420365304274 Test RE 0.8436066919294667\n",
      "68 Train Loss 0.8416581 Test MSE 3.1026818723902 Test RE 0.8419313564024123\n",
      "69 Train Loss 0.830221 Test MSE 3.076014064809197 Test RE 0.8383053131942876\n",
      "70 Train Loss 0.8106214 Test MSE 3.0447220177426226 Test RE 0.8340304066062384\n",
      "71 Train Loss 0.7963875 Test MSE 3.0604764934288258 Test RE 0.8361854076429299\n",
      "72 Train Loss 0.78627294 Test MSE 3.039031205152949 Test RE 0.8332506095364779\n",
      "73 Train Loss 0.7742093 Test MSE 3.003681146186894 Test RE 0.8283902421025884\n",
      "74 Train Loss 0.76424867 Test MSE 2.9844732091406736 Test RE 0.8257372995156201\n",
      "75 Train Loss 0.7552303 Test MSE 2.9759109924749625 Test RE 0.8245519613709172\n",
      "76 Train Loss 0.7421613 Test MSE 2.9374811648197188 Test RE 0.8192106800616894\n",
      "77 Train Loss 0.70040184 Test MSE 2.916585077182124 Test RE 0.8162917081297294\n",
      "78 Train Loss 0.6723902 Test MSE 2.9046417765965673 Test RE 0.814618652461905\n",
      "79 Train Loss 0.6523563 Test MSE 2.8921754804423 Test RE 0.8128686609239293\n",
      "80 Train Loss 0.63414896 Test MSE 2.87457591218935 Test RE 0.8103916383329365\n",
      "81 Train Loss 0.61555475 Test MSE 2.8810744998450133 Test RE 0.8113071521624284\n",
      "82 Train Loss 0.6072274 Test MSE 2.88391111612642 Test RE 0.8117064477884631\n",
      "83 Train Loss 0.5994097 Test MSE 2.898487701479057 Test RE 0.8137552271299595\n",
      "84 Train Loss 0.59023184 Test MSE 2.914422568903933 Test RE 0.8159890313929488\n",
      "85 Train Loss 0.58381915 Test MSE 2.906366126240139 Test RE 0.8148604170371331\n",
      "86 Train Loss 0.57592654 Test MSE 2.8974791835351463 Test RE 0.8136136432706876\n",
      "87 Train Loss 0.57083976 Test MSE 2.8893725112721076 Test RE 0.8124746671774552\n",
      "88 Train Loss 0.5640898 Test MSE 2.8957913517469773 Test RE 0.8133766367339494\n",
      "89 Train Loss 0.55967736 Test MSE 2.8816950860906894 Test RE 0.8113945256319012\n",
      "90 Train Loss 0.55652535 Test MSE 2.8885276700628753 Test RE 0.812355876287565\n",
      "91 Train Loss 0.55236596 Test MSE 2.8829269481612383 Test RE 0.8115679338715683\n",
      "92 Train Loss 0.5482985 Test MSE 2.881349146172994 Test RE 0.8113458212805261\n",
      "93 Train Loss 0.5440982 Test MSE 2.8667017539455326 Test RE 0.8092809479094554\n",
      "94 Train Loss 0.5407154 Test MSE 2.8680561049465902 Test RE 0.8094720945880148\n",
      "95 Train Loss 0.5372544 Test MSE 2.880963548955647 Test RE 0.8112915301927899\n",
      "96 Train Loss 0.5336042 Test MSE 2.892800074341026 Test RE 0.8129564296988656\n",
      "97 Train Loss 0.5311068 Test MSE 2.8905118145550666 Test RE 0.8126348341032611\n",
      "98 Train Loss 0.5273417 Test MSE 2.909071248954454 Test RE 0.8152395476506294\n",
      "99 Train Loss 0.5237552 Test MSE 2.89290105956692 Test RE 0.8129706193888055\n",
      "Training time: 81.25\n",
      "9\n",
      "KG_rowdy_tune7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.702557 Test MSE 8.504404008348192 Test RE 1.3938948131496127\n",
      "1 Train Loss 56.166977 Test MSE 8.628371447667437 Test RE 1.4040173571604497\n",
      "2 Train Loss 51.06067 Test MSE 9.414834527843874 Test RE 1.466609203352061\n",
      "3 Train Loss 45.70645 Test MSE 8.498076451944343 Test RE 1.393376164856559\n",
      "4 Train Loss 44.264545 Test MSE 8.474581774063784 Test RE 1.3914486944068987\n",
      "5 Train Loss 43.404247 Test MSE 8.437799865271822 Test RE 1.3884257845463095\n",
      "6 Train Loss 41.803833 Test MSE 9.071289456554194 Test RE 1.439602435887644\n",
      "7 Train Loss 40.67985 Test MSE 9.491533976386215 Test RE 1.4725710683577915\n",
      "8 Train Loss 39.98922 Test MSE 9.868639752814902 Test RE 1.5015393158407897\n",
      "9 Train Loss 38.966118 Test MSE 9.891532137528412 Test RE 1.5032798750923966\n",
      "10 Train Loss 37.683777 Test MSE 10.014151859249377 Test RE 1.512568830883641\n",
      "11 Train Loss 36.78526 Test MSE 10.254338295068338 Test RE 1.5306006052638395\n",
      "12 Train Loss 35.999336 Test MSE 10.150778018028905 Test RE 1.5228520965281893\n",
      "13 Train Loss 34.821754 Test MSE 10.345731589437325 Test RE 1.537406325873626\n",
      "14 Train Loss 33.26676 Test MSE 10.52757803581315 Test RE 1.5508589294242365\n",
      "15 Train Loss 31.968996 Test MSE 10.547703531687647 Test RE 1.5523406046146206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Train Loss 29.92939 Test MSE 10.15334098555626 Test RE 1.523044336676105\n",
      "17 Train Loss 27.735933 Test MSE 9.850896140807206 Test RE 1.500188840078602\n",
      "18 Train Loss 24.939701 Test MSE 9.649755093097866 Test RE 1.4847940068454104\n",
      "19 Train Loss 22.844149 Test MSE 9.596979109882405 Test RE 1.480728157529931\n",
      "20 Train Loss 21.715412 Test MSE 9.793179741230519 Test RE 1.4957875807258902\n",
      "21 Train Loss 21.121754 Test MSE 9.66810248827312 Test RE 1.4862048802486825\n",
      "22 Train Loss 20.671715 Test MSE 9.475220475922335 Test RE 1.471305039073577\n",
      "23 Train Loss 20.230297 Test MSE 9.258655147171426 Test RE 1.4543937999597827\n",
      "24 Train Loss 19.42809 Test MSE 9.405137497746118 Test RE 1.4658537244618624\n",
      "25 Train Loss 17.415915 Test MSE 8.361531338371426 Test RE 1.3821366115157612\n",
      "26 Train Loss 16.062511 Test MSE 8.39621351613864 Test RE 1.3850000764425625\n",
      "27 Train Loss 15.390635 Test MSE 8.304520115723749 Test RE 1.3774166583054703\n",
      "28 Train Loss 14.690395 Test MSE 8.131146111871976 Test RE 1.3629626125349794\n",
      "29 Train Loss 13.076518 Test MSE 7.875298540133557 Test RE 1.341348331485456\n",
      "30 Train Loss 10.785784 Test MSE 6.580494574491494 Test RE 1.226132285249719\n",
      "31 Train Loss 9.778355 Test MSE 6.802054102324635 Test RE 1.246602809206996\n",
      "32 Train Loss 9.001398 Test MSE 6.905150288939772 Test RE 1.2560144271886466\n",
      "33 Train Loss 8.41257 Test MSE 6.791868480044461 Test RE 1.2456691072615211\n",
      "34 Train Loss 8.072189 Test MSE 6.7357298104298025 Test RE 1.2405103420233976\n",
      "35 Train Loss 7.7345195 Test MSE 6.420243649321519 Test RE 1.211110627952861\n",
      "36 Train Loss 7.430208 Test MSE 6.451275362997848 Test RE 1.2140340009840982\n",
      "37 Train Loss 7.3127537 Test MSE 6.461224782844973 Test RE 1.2149698066765202\n",
      "38 Train Loss 7.104392 Test MSE 6.493362291800647 Test RE 1.2179876300645387\n",
      "39 Train Loss 6.9708824 Test MSE 6.576560608890225 Test RE 1.225765725920336\n",
      "40 Train Loss 6.7346992 Test MSE 6.391235925514731 Test RE 1.2083715313569634\n",
      "41 Train Loss 6.5189667 Test MSE 6.351202643616249 Test RE 1.2045811010251013\n",
      "42 Train Loss 6.2931623 Test MSE 6.238158202986278 Test RE 1.1938128590039412\n",
      "43 Train Loss 5.3716173 Test MSE 5.668719842891229 Test RE 1.138021736522048\n",
      "44 Train Loss 4.4576936 Test MSE 5.614409744189494 Test RE 1.1325571145466946\n",
      "45 Train Loss 3.71273 Test MSE 5.669531308125043 Test RE 1.1381031863074011\n",
      "46 Train Loss 3.322374 Test MSE 5.7438889737308685 Test RE 1.1455421631844718\n",
      "47 Train Loss 3.097454 Test MSE 5.734261350352073 Test RE 1.1445817099147158\n",
      "48 Train Loss 2.863769 Test MSE 5.7782595951256575 Test RE 1.1489644325840913\n",
      "49 Train Loss 2.718937 Test MSE 5.724838072689258 Test RE 1.1436408610970943\n",
      "50 Train Loss 2.6123242 Test MSE 5.6444760824999065 Test RE 1.1355856055087392\n",
      "51 Train Loss 2.5400288 Test MSE 5.648142406586302 Test RE 1.135954350892411\n",
      "52 Train Loss 2.458296 Test MSE 5.638473133305373 Test RE 1.1349815923099233\n",
      "53 Train Loss 2.410622 Test MSE 5.686882981447769 Test RE 1.1398434455064232\n",
      "54 Train Loss 2.3630338 Test MSE 5.69318483575344 Test RE 1.140474822877385\n",
      "55 Train Loss 2.3005672 Test MSE 5.674372157555628 Test RE 1.1385889593224778\n",
      "56 Train Loss 2.211219 Test MSE 5.635687566894943 Test RE 1.1347012010499389\n",
      "57 Train Loss 2.1500056 Test MSE 5.641544436020126 Test RE 1.13529066512093\n",
      "58 Train Loss 2.0788577 Test MSE 5.6342398107392855 Test RE 1.1345554445520971\n",
      "59 Train Loss 2.0370362 Test MSE 5.661465162451815 Test RE 1.1372932980561743\n",
      "60 Train Loss 1.9988621 Test MSE 5.6381065968689095 Test RE 1.134944701217288\n",
      "61 Train Loss 1.9535478 Test MSE 5.648436381699784 Test RE 1.1359839126438702\n",
      "62 Train Loss 1.9180154 Test MSE 5.662493238063202 Test RE 1.1373965549334704\n",
      "63 Train Loss 1.8717049 Test MSE 5.640968690256382 Test RE 1.1352327328050504\n",
      "64 Train Loss 1.8239002 Test MSE 5.69394414551611 Test RE 1.1405508738769488\n",
      "65 Train Loss 1.7743189 Test MSE 5.710005137669048 Test RE 1.1421583254627008\n",
      "66 Train Loss 1.746964 Test MSE 5.724661610501061 Test RE 1.1436232351903466\n",
      "67 Train Loss 1.7151887 Test MSE 5.711888820018967 Test RE 1.1423467041084712\n",
      "68 Train Loss 1.6764127 Test MSE 5.70679618127976 Test RE 1.1418373405201823\n",
      "69 Train Loss 1.6424131 Test MSE 5.729166868171789 Test RE 1.1440731573337837\n",
      "70 Train Loss 1.6154182 Test MSE 5.699907240363202 Test RE 1.1411479497457069\n",
      "71 Train Loss 1.5772008 Test MSE 5.682335827834966 Test RE 1.1393876527861257\n",
      "72 Train Loss 1.5479653 Test MSE 5.659200265840811 Test RE 1.137065785448165\n",
      "73 Train Loss 1.5335141 Test MSE 5.65034831047792 Test RE 1.1361761549235116\n",
      "74 Train Loss 1.5094461 Test MSE 5.671180004855501 Test RE 1.138268654183576\n",
      "75 Train Loss 1.4876289 Test MSE 5.685583645059012 Test RE 1.139713222616523\n",
      "76 Train Loss 1.4622945 Test MSE 5.6857038624381255 Test RE 1.139725271741192\n",
      "77 Train Loss 1.4375917 Test MSE 5.6800334182820915 Test RE 1.1391567967715248\n",
      "78 Train Loss 1.4118899 Test MSE 5.727738085157442 Test RE 1.1439304896249407\n",
      "79 Train Loss 1.3828077 Test MSE 5.728626896842401 Test RE 1.1440192418802246\n",
      "80 Train Loss 1.3582212 Test MSE 5.767892122805447 Test RE 1.147933222002511\n",
      "81 Train Loss 1.3356881 Test MSE 5.77028122420801 Test RE 1.1481709383881054\n",
      "82 Train Loss 1.3160293 Test MSE 5.7771725146479955 Test RE 1.148856348520505\n",
      "83 Train Loss 1.3016211 Test MSE 5.7740226351466335 Test RE 1.1485431111669155\n",
      "84 Train Loss 1.2857835 Test MSE 5.774666453241065 Test RE 1.148607142109671\n",
      "85 Train Loss 1.2685622 Test MSE 5.772574716502325 Test RE 1.148399095343141\n",
      "86 Train Loss 1.2533793 Test MSE 5.803957428511586 Test RE 1.1515165108531658\n",
      "87 Train Loss 1.241163 Test MSE 5.836173513465249 Test RE 1.1547079554330884\n",
      "88 Train Loss 1.229554 Test MSE 5.828980112829443 Test RE 1.1539961159046308\n",
      "89 Train Loss 1.2076868 Test MSE 5.802026781018713 Test RE 1.1513249728031647\n",
      "90 Train Loss 1.1901736 Test MSE 5.824621250155106 Test RE 1.1535645608796516\n",
      "91 Train Loss 1.1734931 Test MSE 5.8463510534425795 Test RE 1.1557143483444878\n",
      "92 Train Loss 1.1617389 Test MSE 5.856978733617206 Test RE 1.1567643182758331\n",
      "93 Train Loss 1.1538296 Test MSE 5.8678469611293425 Test RE 1.1578370685465138\n",
      "94 Train Loss 1.1459671 Test MSE 5.881878088742085 Test RE 1.1592205452882345\n",
      "95 Train Loss 1.1388962 Test MSE 5.89248542427817 Test RE 1.1602653393450144\n",
      "96 Train Loss 1.128527 Test MSE 5.905314353149125 Test RE 1.16152769873005\n",
      "97 Train Loss 1.1160887 Test MSE 5.919078997602593 Test RE 1.1628806080843797\n",
      "98 Train Loss 1.1037557 Test MSE 5.937621748550316 Test RE 1.1647006669357987\n",
      "99 Train Loss 1.0951881 Test MSE 5.940525993196219 Test RE 1.1649854747506136\n",
      "Training time: 82.43\n",
      "0\n",
      "KG_rowdy_tune8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.97\n",
      "0\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 61.89754 Test MSE 6.21843130179017 Test RE 1.1919237696892366\n",
      "1 Train Loss 36.314644 Test MSE 6.809733634537459 Test RE 1.247306319186053\n",
      "2 Train Loss 25.783447 Test MSE 5.811957523975259 Test RE 1.1523098548608657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 21.039526 Test MSE 5.693479885983584 Test RE 1.1405043751411028\n",
      "4 Train Loss 16.833519 Test MSE 5.865779037601913 Test RE 1.1576330303773954\n",
      "5 Train Loss 14.709978 Test MSE 5.96138587597078 Test RE 1.16702907867345\n",
      "6 Train Loss 12.929989 Test MSE 5.971147498894746 Test RE 1.1679841785687175\n",
      "7 Train Loss 11.8123865 Test MSE 5.9633461240470735 Test RE 1.167220936617636\n",
      "8 Train Loss 10.3551035 Test MSE 5.443782752384848 Test RE 1.1152146166854255\n",
      "9 Train Loss 9.151123 Test MSE 5.5901791695106935 Test RE 1.1301105365412125\n",
      "10 Train Loss 8.596228 Test MSE 5.476798074724345 Test RE 1.1185912681206778\n",
      "11 Train Loss 7.7143183 Test MSE 5.280072141641602 Test RE 1.098317714910413\n",
      "12 Train Loss 7.2270794 Test MSE 4.976119867528916 Test RE 1.0662363318102033\n",
      "13 Train Loss 6.624603 Test MSE 4.601642658694502 Test RE 1.0253319854555716\n",
      "14 Train Loss 6.227765 Test MSE 4.319629385176744 Test RE 0.9934163505336592\n",
      "15 Train Loss 5.735889 Test MSE 3.8997289301621563 Test RE 0.9438984445805689\n",
      "16 Train Loss 5.538321 Test MSE 3.836335722955642 Test RE 0.936195098900406\n",
      "17 Train Loss 5.320421 Test MSE 3.6272350059230227 Test RE 0.9103238210182767\n",
      "18 Train Loss 5.067038 Test MSE 3.5204128962113117 Test RE 0.8968191265137946\n",
      "19 Train Loss 4.7163815 Test MSE 3.351656073020841 Test RE 0.8750599029854044\n",
      "20 Train Loss 4.5508165 Test MSE 3.193619025473791 Test RE 0.854180423230645\n",
      "21 Train Loss 4.3145094 Test MSE 2.986383484265352 Test RE 0.8260015225431525\n",
      "22 Train Loss 4.01631 Test MSE 2.8203847916494946 Test RE 0.8027165966371721\n",
      "23 Train Loss 3.7364795 Test MSE 2.7047491888070825 Test RE 0.7860887118298121\n",
      "24 Train Loss 3.4318619 Test MSE 2.541110027426856 Test RE 0.7619382836086558\n",
      "25 Train Loss 3.1875238 Test MSE 2.409266394521239 Test RE 0.741908713464561\n",
      "26 Train Loss 2.8855047 Test MSE 2.2684286879536244 Test RE 0.7198974343539476\n",
      "27 Train Loss 2.616797 Test MSE 2.206047448350162 Test RE 0.7099299280900695\n",
      "28 Train Loss 2.4079914 Test MSE 2.2134179566877266 Test RE 0.7111148938077283\n",
      "29 Train Loss 2.2264132 Test MSE 2.1081224031621684 Test RE 0.6939944096069701\n",
      "30 Train Loss 2.1133246 Test MSE 2.128042242356585 Test RE 0.697265508509843\n",
      "31 Train Loss 1.9989312 Test MSE 2.083948718380382 Test RE 0.6900039455689669\n",
      "32 Train Loss 1.8005115 Test MSE 1.9468398775776172 Test RE 0.6669191331157017\n",
      "33 Train Loss 1.6508683 Test MSE 1.8222413414902536 Test RE 0.6452247350272805\n",
      "34 Train Loss 1.4737692 Test MSE 1.6412077410181294 Test RE 0.6123360644866023\n",
      "35 Train Loss 1.3360301 Test MSE 1.565072750493245 Test RE 0.5979643950172638\n",
      "36 Train Loss 1.2289208 Test MSE 1.560615774306202 Test RE 0.5971123537348232\n",
      "37 Train Loss 1.1277639 Test MSE 1.4535892739698786 Test RE 0.5762738531538204\n",
      "38 Train Loss 1.0669478 Test MSE 1.305822354364494 Test RE 0.546198005316122\n",
      "39 Train Loss 1.0041577 Test MSE 1.2122544730259242 Test RE 0.5262655699033725\n",
      "40 Train Loss 0.94933224 Test MSE 1.1196804864524403 Test RE 0.5057723869766638\n",
      "41 Train Loss 0.88431203 Test MSE 0.9750096340129026 Test RE 0.47196795633069266\n",
      "42 Train Loss 0.8196125 Test MSE 0.9127267442846286 Test RE 0.45664472835210673\n",
      "43 Train Loss 0.75962234 Test MSE 0.8072856265714828 Test RE 0.42945896224499897\n",
      "44 Train Loss 0.67695725 Test MSE 0.6821940376404646 Test RE 0.39478625157463043\n",
      "45 Train Loss 0.5913638 Test MSE 0.5381555849289583 Test RE 0.35064042668793616\n",
      "46 Train Loss 0.5069707 Test MSE 0.37808203444446864 Test RE 0.293901011587621\n",
      "47 Train Loss 0.42522088 Test MSE 0.21841097119769143 Test RE 0.22338051367626258\n",
      "48 Train Loss 0.356287 Test MSE 0.14869962744722062 Test RE 0.184315984573884\n",
      "49 Train Loss 0.2980054 Test MSE 0.14962973667531668 Test RE 0.18489152991420013\n",
      "50 Train Loss 0.26279178 Test MSE 0.12906234371054412 Test RE 0.1717148417629413\n",
      "51 Train Loss 0.22096995 Test MSE 0.06924966949605191 Test RE 0.12578154147601334\n",
      "52 Train Loss 0.17812487 Test MSE 0.05089578635277716 Test RE 0.1078323263388934\n",
      "53 Train Loss 0.1374336 Test MSE 0.04234742912496043 Test RE 0.09836069419987992\n",
      "54 Train Loss 0.11686669 Test MSE 0.04026479148448751 Test RE 0.09591152303838507\n",
      "55 Train Loss 0.10136033 Test MSE 0.031309107898925784 Test RE 0.08457527272878329\n",
      "56 Train Loss 0.091655076 Test MSE 0.03386382454195916 Test RE 0.08795814524620962\n",
      "57 Train Loss 0.085487306 Test MSE 0.03188299947817134 Test RE 0.08534687939846354\n",
      "58 Train Loss 0.0783154 Test MSE 0.028194712247947666 Test RE 0.08025865798619937\n",
      "59 Train Loss 0.06695058 Test MSE 0.021815159718111994 Test RE 0.07059716459664701\n",
      "60 Train Loss 0.063321285 Test MSE 0.02001852491045194 Test RE 0.06762761890852753\n",
      "61 Train Loss 0.055296525 Test MSE 0.019248213024021053 Test RE 0.0663137012641299\n",
      "62 Train Loss 0.05170757 Test MSE 0.014737489294858616 Test RE 0.05802562294432751\n",
      "63 Train Loss 0.04855711 Test MSE 0.015711337244117638 Test RE 0.05991211286331376\n",
      "64 Train Loss 0.046388775 Test MSE 0.014724907379166515 Test RE 0.05800084839249589\n",
      "65 Train Loss 0.04242001 Test MSE 0.012861356227774047 Test RE 0.05420650963794974\n",
      "66 Train Loss 0.03960149 Test MSE 0.012640199002443505 Test RE 0.05373843517843273\n",
      "67 Train Loss 0.038023178 Test MSE 0.013017163879934535 Test RE 0.05453386095689229\n",
      "68 Train Loss 0.036112748 Test MSE 0.012133096774318576 Test RE 0.05264945634724519\n",
      "69 Train Loss 0.033814993 Test MSE 0.010968464317746698 Test RE 0.05005886213732475\n",
      "70 Train Loss 0.03103516 Test MSE 0.010665082294548591 Test RE 0.04936170653632225\n",
      "71 Train Loss 0.028977707 Test MSE 0.008544827546389924 Test RE 0.044183458874471594\n",
      "72 Train Loss 0.027350111 Test MSE 0.00801628207181181 Test RE 0.04279515025286307\n",
      "73 Train Loss 0.025665786 Test MSE 0.007427878343768313 Test RE 0.04119461528324136\n",
      "74 Train Loss 0.024374995 Test MSE 0.007671496725591263 Test RE 0.04186471242144459\n",
      "75 Train Loss 0.023068395 Test MSE 0.0074938273927592225 Test RE 0.04137708610356774\n",
      "76 Train Loss 0.021465745 Test MSE 0.006462195238001196 Test RE 0.038423604000108275\n",
      "77 Train Loss 0.019886948 Test MSE 0.006186733952306653 Test RE 0.037595752381164346\n",
      "78 Train Loss 0.018265089 Test MSE 0.006354549145514874 Test RE 0.03810223328417702\n",
      "79 Train Loss 0.017557124 Test MSE 0.006446317036297465 Test RE 0.03837636982197283\n",
      "80 Train Loss 0.016527431 Test MSE 0.00579775684203985 Test RE 0.03639469287382995\n",
      "81 Train Loss 0.015115727 Test MSE 0.004750273259015343 Test RE 0.032943319389740086\n",
      "82 Train Loss 0.01374424 Test MSE 0.004180099006086591 Test RE 0.03090304998715358\n",
      "83 Train Loss 0.01259701 Test MSE 0.004648059322256384 Test RE 0.03258696329199588\n",
      "84 Train Loss 0.011967321 Test MSE 0.004256704839387488 Test RE 0.03118493397275312\n",
      "85 Train Loss 0.011233693 Test MSE 0.004133946677649166 Test RE 0.030731976720388996\n",
      "86 Train Loss 0.010268125 Test MSE 0.0032328634076469825 Test RE 0.027177013996719627\n",
      "87 Train Loss 0.00987844 Test MSE 0.0032169746716371136 Test RE 0.027110147536172538\n",
      "88 Train Loss 0.009381141 Test MSE 0.0029760791810017556 Test RE 0.02607535928568811\n",
      "89 Train Loss 0.008433738 Test MSE 0.0023075859035974235 Test RE 0.022960799114986337\n",
      "90 Train Loss 0.008113794 Test MSE 0.002412547927196563 Test RE 0.023477185698835338\n",
      "91 Train Loss 0.007817347 Test MSE 0.0024825463929123936 Test RE 0.023815337848559767\n",
      "92 Train Loss 0.007438056 Test MSE 0.0023049363803597346 Test RE 0.02294761376765538\n",
      "93 Train Loss 0.007045017 Test MSE 0.0021583800900175486 Test RE 0.022206086304470418\n",
      "94 Train Loss 0.0068057636 Test MSE 0.0021569847017052874 Test RE 0.022198907049257706\n",
      "95 Train Loss 0.0066061164 Test MSE 0.0021044916782226135 Test RE 0.02192712370069217\n",
      "96 Train Loss 0.006200225 Test MSE 0.0020169169510588633 Test RE 0.021466046622405692\n",
      "97 Train Loss 0.005873259 Test MSE 0.002089436263360583 Test RE 0.02184855021729153\n",
      "98 Train Loss 0.0057445965 Test MSE 0.0020198262095583058 Test RE 0.02148152266239945\n",
      "99 Train Loss 0.0055630016 Test MSE 0.0018460844629062108 Test RE 0.02053685060604755\n",
      "Training time: 83.80\n",
      "1\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.001766 Test MSE 7.627211787872475 Test RE 1.3200517681859838\n",
      "1 Train Loss 42.402893 Test MSE 8.955759957338485 Test RE 1.4304058663643977\n",
      "2 Train Loss 37.310085 Test MSE 9.32079209273135 Test RE 1.4592660231675707\n",
      "3 Train Loss 33.179047 Test MSE 9.661909189703232 Test RE 1.485728779321724\n",
      "4 Train Loss 29.791222 Test MSE 9.751910023949625 Test RE 1.4926325327790486\n",
      "5 Train Loss 26.28961 Test MSE 9.214043446797717 Test RE 1.4508856594175688\n",
      "6 Train Loss 23.668041 Test MSE 9.326853099231759 Test RE 1.4597404025652432\n",
      "7 Train Loss 22.283669 Test MSE 9.142161312901665 Test RE 1.4452151325922502\n",
      "8 Train Loss 21.108582 Test MSE 9.192015200660189 Test RE 1.4491502871215043\n",
      "9 Train Loss 20.392334 Test MSE 9.12854303101571 Test RE 1.4441383258477043\n",
      "10 Train Loss 19.439789 Test MSE 8.855558642423754 Test RE 1.4223813260139473\n",
      "11 Train Loss 17.92347 Test MSE 8.542456886702508 Test RE 1.39700981735352\n",
      "12 Train Loss 15.554556 Test MSE 7.874494358881792 Test RE 1.3412798442583656\n",
      "13 Train Loss 14.390459 Test MSE 7.889448537772282 Test RE 1.342552829170929\n",
      "14 Train Loss 13.875721 Test MSE 7.983235195773046 Test RE 1.3505091234276256\n",
      "15 Train Loss 13.48053 Test MSE 8.214119454139954 Test RE 1.3698990592621278\n",
      "16 Train Loss 13.197688 Test MSE 8.38900083339891 Test RE 1.3844050634401104\n",
      "17 Train Loss 12.995161 Test MSE 8.528088741475646 Test RE 1.3958344595135537\n",
      "18 Train Loss 12.781643 Test MSE 8.588794273289128 Test RE 1.4007936372328051\n",
      "19 Train Loss 12.560002 Test MSE 8.659029984022341 Test RE 1.4065095393755314\n",
      "20 Train Loss 12.312721 Test MSE 8.587715685424754 Test RE 1.40070567806142\n",
      "21 Train Loss 11.971724 Test MSE 8.308216381838818 Test RE 1.3777231619958044\n",
      "22 Train Loss 11.5883665 Test MSE 8.030550727102794 Test RE 1.3545053513366756\n",
      "23 Train Loss 10.6200485 Test MSE 7.163994402559088 Test RE 1.279339117446859\n",
      "24 Train Loss 9.331138 Test MSE 6.849814044175294 Test RE 1.2509716022673674\n",
      "25 Train Loss 8.350513 Test MSE 6.573619570899827 Test RE 1.2254916140468608\n",
      "26 Train Loss 7.6135874 Test MSE 6.3897632061471565 Test RE 1.208232302050852\n",
      "27 Train Loss 7.028182 Test MSE 6.260021860257667 Test RE 1.1959030821412835\n",
      "28 Train Loss 5.974366 Test MSE 5.623435641762155 Test RE 1.1334671157611593\n",
      "29 Train Loss 5.08402 Test MSE 5.592205323946529 Test RE 1.1303153216619422\n",
      "30 Train Loss 4.00865 Test MSE 5.430445121354048 Test RE 1.1138476037366707\n",
      "31 Train Loss 3.2502759 Test MSE 5.3222729924674885 Test RE 1.10269811884879\n",
      "32 Train Loss 2.8929172 Test MSE 5.451394032600981 Test RE 1.1159939686946263\n",
      "33 Train Loss 2.6761634 Test MSE 5.485525050518868 Test RE 1.1194821201397775\n",
      "34 Train Loss 2.546719 Test MSE 5.415799749776688 Test RE 1.112344621479253\n",
      "35 Train Loss 2.4546866 Test MSE 5.461169008373743 Test RE 1.116994073267105\n",
      "36 Train Loss 2.3482113 Test MSE 5.43710488742712 Test RE 1.1145303922933019\n",
      "37 Train Loss 2.2708318 Test MSE 5.436364748344963 Test RE 1.1144545306358837\n",
      "38 Train Loss 2.1823812 Test MSE 5.460207890698204 Test RE 1.1168957783796736\n",
      "39 Train Loss 2.082724 Test MSE 5.501891097174157 Test RE 1.1211508620792592\n",
      "40 Train Loss 2.0224507 Test MSE 5.537255274613111 Test RE 1.124748267913176\n",
      "41 Train Loss 1.9429988 Test MSE 5.548424095617525 Test RE 1.1258820231124251\n",
      "42 Train Loss 1.8783833 Test MSE 5.605803016423071 Test RE 1.1316886929514967\n",
      "43 Train Loss 1.8206984 Test MSE 5.70265564776012 Test RE 1.14142303856306\n",
      "44 Train Loss 1.770094 Test MSE 5.722958682420609 Test RE 1.1434531244390795\n",
      "45 Train Loss 1.7365437 Test MSE 5.753229830279678 Test RE 1.1464732395255228\n",
      "46 Train Loss 1.6782709 Test MSE 5.754296965468106 Test RE 1.1465795611262106\n",
      "47 Train Loss 1.6342006 Test MSE 5.753154581899057 Test RE 1.1464657419511746\n",
      "48 Train Loss 1.5942671 Test MSE 5.743223891247597 Test RE 1.1454758403424223\n",
      "49 Train Loss 1.5523982 Test MSE 5.780089296047297 Test RE 1.149146329472881\n",
      "50 Train Loss 1.4988458 Test MSE 5.7218733242608035 Test RE 1.143344691450573\n",
      "51 Train Loss 1.4766579 Test MSE 5.695393437011264 Test RE 1.140696018039558\n",
      "52 Train Loss 1.4394552 Test MSE 5.714214054605881 Test RE 1.1425791975862765\n",
      "53 Train Loss 1.4040014 Test MSE 5.702527026696394 Test RE 1.1414101663257838\n",
      "54 Train Loss 1.3594081 Test MSE 5.691000181255724 Test RE 1.1402559838101467\n",
      "55 Train Loss 1.3196874 Test MSE 5.644818156275639 Test RE 1.1356200150947526\n",
      "56 Train Loss 1.280593 Test MSE 5.693164440469519 Test RE 1.1404727800551933\n",
      "57 Train Loss 1.2648824 Test MSE 5.722622741660721 Test RE 1.1434195632891395\n",
      "58 Train Loss 1.2394888 Test MSE 5.758454026667383 Test RE 1.1469936465392705\n",
      "59 Train Loss 1.2024546 Test MSE 5.774581732125378 Test RE 1.1485987163732\n",
      "60 Train Loss 1.1812211 Test MSE 5.817698620785851 Test RE 1.1528788446973846\n",
      "61 Train Loss 1.1586411 Test MSE 5.850206030891126 Test RE 1.1560953140548091\n",
      "62 Train Loss 1.1404649 Test MSE 5.859593255540924 Test RE 1.1570224759682564\n",
      "63 Train Loss 1.116122 Test MSE 5.880425461850192 Test RE 1.1590773921241597\n",
      "64 Train Loss 1.0997108 Test MSE 5.908552429033679 Test RE 1.1618461067911223\n",
      "65 Train Loss 1.0842468 Test MSE 5.916943464852821 Test RE 1.1626708124678182\n",
      "66 Train Loss 1.0716114 Test MSE 5.939002659609993 Test RE 1.1648360961192241\n",
      "67 Train Loss 1.054718 Test MSE 5.952896649446269 Test RE 1.166197837081996\n",
      "68 Train Loss 1.0437695 Test MSE 5.953650413669107 Test RE 1.166271667557611\n",
      "69 Train Loss 1.026769 Test MSE 5.970028588400542 Test RE 1.1678747413974893\n",
      "70 Train Loss 1.012193 Test MSE 5.978232091449605 Test RE 1.1686768627681892\n",
      "71 Train Loss 1.0012982 Test MSE 6.003536835176433 Test RE 1.1711476467552515\n",
      "72 Train Loss 0.98971677 Test MSE 6.015486937753065 Test RE 1.172312658093833\n",
      "73 Train Loss 0.9821335 Test MSE 5.9944754943481495 Test RE 1.1702634866651584\n",
      "74 Train Loss 0.971091 Test MSE 5.989962766067339 Test RE 1.1698229080498814\n",
      "75 Train Loss 0.9636195 Test MSE 6.0041592478697305 Test RE 1.17120835415899\n",
      "76 Train Loss 0.95419985 Test MSE 6.0124907180253695 Test RE 1.1720206664529569\n",
      "77 Train Loss 0.9487117 Test MSE 6.0346212683004365 Test RE 1.1741756501288139\n",
      "78 Train Loss 0.94461757 Test MSE 6.03286952627576 Test RE 1.1740052167223292\n",
      "79 Train Loss 0.9378555 Test MSE 6.038547254106017 Test RE 1.1745575338641443\n",
      "80 Train Loss 0.9284514 Test MSE 6.047283980765317 Test RE 1.1754069168874761\n",
      "81 Train Loss 0.9206035 Test MSE 6.083545218998755 Test RE 1.178925687316875\n",
      "82 Train Loss 0.91463745 Test MSE 6.06726643673692 Test RE 1.1773473041900295\n",
      "83 Train Loss 0.9082881 Test MSE 6.088033909492171 Test RE 1.1793605371093503\n",
      "84 Train Loss 0.89956963 Test MSE 6.0904892505163595 Test RE 1.1795983347665562\n",
      "85 Train Loss 0.892992 Test MSE 6.103977234465987 Test RE 1.1809037803314972\n",
      "86 Train Loss 0.88423365 Test MSE 6.089034978978892 Test RE 1.1794574956131947\n",
      "87 Train Loss 0.8767817 Test MSE 6.090221865510459 Test RE 1.179572441085724\n",
      "88 Train Loss 0.8701983 Test MSE 6.082972582385272 Test RE 1.1788702006001606\n",
      "89 Train Loss 0.86542034 Test MSE 6.099560986694226 Test RE 1.1804765091338307\n",
      "90 Train Loss 0.85827714 Test MSE 6.086088357509191 Test RE 1.1791720780264299\n",
      "91 Train Loss 0.85471046 Test MSE 6.110341800897414 Test RE 1.1815192792176297\n",
      "92 Train Loss 0.8501513 Test MSE 6.121023005249952 Test RE 1.1825515077707778\n",
      "93 Train Loss 0.84670043 Test MSE 6.127123809211141 Test RE 1.1831406836439182\n",
      "94 Train Loss 0.84275144 Test MSE 6.143369818503023 Test RE 1.1847081882937134\n",
      "95 Train Loss 0.8399626 Test MSE 6.152101061378406 Test RE 1.1855497705611695\n",
      "96 Train Loss 0.8372222 Test MSE 6.155952451716035 Test RE 1.185920806447556\n",
      "97 Train Loss 0.8345694 Test MSE 6.157309095278423 Test RE 1.1860514753578104\n",
      "98 Train Loss 0.8315581 Test MSE 6.162304573150256 Test RE 1.1865325046975932\n",
      "99 Train Loss 0.8264891 Test MSE 6.179624187004901 Test RE 1.1881987535250353\n",
      "Training time: 83.53\n",
      "2\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.147472 Test MSE 8.107216100372188 Test RE 1.3609555311852235\n",
      "1 Train Loss 36.17275 Test MSE 6.563578081294097 Test RE 1.2245552604778271\n",
      "2 Train Loss 24.193535 Test MSE 5.134714137011624 Test RE 1.0830941133259815\n",
      "3 Train Loss 18.389685 Test MSE 3.8997549679114205 Test RE 0.9439015956906137\n",
      "4 Train Loss 13.517033 Test MSE 3.9875632507052257 Test RE 0.9544690552278207\n",
      "5 Train Loss 10.933707 Test MSE 3.889295615886422 Test RE 0.9426349484589582\n",
      "6 Train Loss 9.9220085 Test MSE 3.765076867277984 Test RE 0.9274595635752769\n",
      "7 Train Loss 8.798994 Test MSE 3.8427313855601075 Test RE 0.9369751524431476\n",
      "8 Train Loss 8.299404 Test MSE 3.807393246479376 Test RE 0.9326569436121895\n",
      "9 Train Loss 7.8679295 Test MSE 3.8626425739068395 Test RE 0.9393994936595885\n",
      "10 Train Loss 7.513576 Test MSE 3.7786181970496067 Test RE 0.9291258992396263\n",
      "11 Train Loss 7.073157 Test MSE 3.7238388818135393 Test RE 0.9223664580165001\n",
      "12 Train Loss 6.582856 Test MSE 3.727956592294924 Test RE 0.9228762798419109\n",
      "13 Train Loss 6.33729 Test MSE 3.603904695667295 Test RE 0.9073915050470125\n",
      "14 Train Loss 6.1378617 Test MSE 3.5816110358049564 Test RE 0.9045806012413783\n",
      "15 Train Loss 5.839823 Test MSE 3.6312209749218187 Test RE 0.910823861162477\n",
      "16 Train Loss 5.585579 Test MSE 3.477845591474496 Test RE 0.8913806628187562\n",
      "17 Train Loss 5.3448453 Test MSE 3.2190695780122387 Test RE 0.8575772316814908\n",
      "18 Train Loss 5.0367765 Test MSE 3.0503887706245942 Test RE 0.8348061830380256\n",
      "19 Train Loss 4.820293 Test MSE 2.9438538530264853 Test RE 0.820098812714095\n",
      "20 Train Loss 4.6518636 Test MSE 2.8221904987994213 Test RE 0.8029735188798668\n",
      "21 Train Loss 4.5304117 Test MSE 2.6839377826287483 Test RE 0.7830586337507692\n",
      "22 Train Loss 4.4425898 Test MSE 2.6353435054942804 Test RE 0.7759373836112211\n",
      "23 Train Loss 4.337389 Test MSE 2.581358972505835 Test RE 0.7679487925380578\n",
      "24 Train Loss 4.29141 Test MSE 2.4506617340420855 Test RE 0.7482552023929183\n",
      "25 Train Loss 4.2413387 Test MSE 2.43512736564563 Test RE 0.7458798948202019\n",
      "26 Train Loss 4.173545 Test MSE 2.2745011653625107 Test RE 0.7208603562265594\n",
      "27 Train Loss 4.1540194 Test MSE 2.272061340987621 Test RE 0.7204736242695883\n",
      "28 Train Loss 4.120731 Test MSE 2.271228010531526 Test RE 0.7203414870633622\n",
      "29 Train Loss 4.089547 Test MSE 2.271618219081892 Test RE 0.7204033635756009\n",
      "30 Train Loss 4.0607734 Test MSE 2.259172752908634 Test RE 0.7184272239462324\n",
      "31 Train Loss 4.0416446 Test MSE 2.246606390831777 Test RE 0.7164263574902303\n",
      "32 Train Loss 4.008211 Test MSE 2.2443028865726244 Test RE 0.7160589779592055\n",
      "33 Train Loss 3.978991 Test MSE 2.220320534376513 Test RE 0.7122228420180036\n",
      "34 Train Loss 3.9307585 Test MSE 2.184589146412039 Test RE 0.7064687339110723\n",
      "35 Train Loss 3.8364844 Test MSE 2.1554630688081002 Test RE 0.701743426879572\n",
      "36 Train Loss 3.6907825 Test MSE 2.10617126034914 Test RE 0.6936731769165607\n",
      "37 Train Loss 3.5404515 Test MSE 2.019376846763506 Test RE 0.6792298234508108\n",
      "38 Train Loss 3.3224156 Test MSE 1.9471856101996592 Test RE 0.6669783484285169\n",
      "39 Train Loss 2.9958043 Test MSE 1.9320011695188506 Test RE 0.6643726608178612\n",
      "40 Train Loss 2.7347028 Test MSE 1.9385167353240518 Test RE 0.6654919976929409\n",
      "41 Train Loss 2.407274 Test MSE 1.7298785191970139 Test RE 0.6286600506677479\n",
      "42 Train Loss 1.9809623 Test MSE 1.3487633658607863 Test RE 0.5551060248823401\n",
      "43 Train Loss 1.7117436 Test MSE 0.9808615416100077 Test RE 0.47338218906428203\n",
      "44 Train Loss 1.2256116 Test MSE 0.5728714283584515 Test RE 0.36177340842587385\n",
      "45 Train Loss 0.8636067 Test MSE 0.4579472794838419 Test RE 0.3234564397151406\n",
      "46 Train Loss 0.6448729 Test MSE 0.2820797568328574 Test RE 0.25385985085642243\n",
      "47 Train Loss 0.40645814 Test MSE 0.13807010500544928 Test RE 0.17760610409694516\n",
      "48 Train Loss 0.2999164 Test MSE 0.11377727116565886 Test RE 0.16122627385416846\n",
      "49 Train Loss 0.24640565 Test MSE 0.12641121491852778 Test RE 0.16994205395497425\n",
      "50 Train Loss 0.21244182 Test MSE 0.11989207003772064 Test RE 0.16550201649673849\n",
      "51 Train Loss 0.16788116 Test MSE 0.09514391190264174 Test RE 0.1474343101848227\n",
      "52 Train Loss 0.13847664 Test MSE 0.07477652849920662 Test RE 0.13070455109730614\n",
      "53 Train Loss 0.10377287 Test MSE 0.054761746002762984 Test RE 0.11185275965270444\n",
      "54 Train Loss 0.086269915 Test MSE 0.05141619061882202 Test RE 0.10838221159687211\n",
      "55 Train Loss 0.07265709 Test MSE 0.05166168010088998 Test RE 0.10864064196166107\n",
      "56 Train Loss 0.064133115 Test MSE 0.0509212876679114 Test RE 0.10785933762965115\n",
      "57 Train Loss 0.055270262 Test MSE 0.04534744195289798 Test RE 0.10178515845263311\n",
      "58 Train Loss 0.050814226 Test MSE 0.045800885273763255 Test RE 0.10229278352426374\n",
      "59 Train Loss 0.04281704 Test MSE 0.044686758166899265 Test RE 0.1010409649409148\n",
      "60 Train Loss 0.038709298 Test MSE 0.0438580290378971 Test RE 0.10009966306774636\n",
      "61 Train Loss 0.035771545 Test MSE 0.04455676349525884 Test RE 0.10089389281197045\n",
      "62 Train Loss 0.032629408 Test MSE 0.045876956517268974 Test RE 0.10237769793983939\n",
      "63 Train Loss 0.029173005 Test MSE 0.042180666526306664 Test RE 0.09816683278170772\n",
      "64 Train Loss 0.02655151 Test MSE 0.03973201806664418 Test RE 0.09527487165799815\n",
      "65 Train Loss 0.024963096 Test MSE 0.0424786505480228 Test RE 0.09851297082307726\n",
      "66 Train Loss 0.02264407 Test MSE 0.04467242534962269 Test RE 0.10102475971715362\n",
      "67 Train Loss 0.020605575 Test MSE 0.04634446899945757 Test RE 0.10289801941725482\n",
      "68 Train Loss 0.019148739 Test MSE 0.04392268550587919 Test RE 0.10017342045304418\n",
      "69 Train Loss 0.017430501 Test MSE 0.04537780008275973 Test RE 0.10181922310922817\n",
      "70 Train Loss 0.01643727 Test MSE 0.045489479942483056 Test RE 0.10194444038184104\n",
      "71 Train Loss 0.015576146 Test MSE 0.04497319785247498 Test RE 0.10136428119920195\n",
      "72 Train Loss 0.014925547 Test MSE 0.04584242560397787 Test RE 0.10233916159009165\n",
      "73 Train Loss 0.013502471 Test MSE 0.04304917244311042 Test RE 0.0991723179002577\n",
      "74 Train Loss 0.012860228 Test MSE 0.0405066245251048 Test RE 0.09619911738004913\n",
      "75 Train Loss 0.011561754 Test MSE 0.03561837263450099 Test RE 0.09020800885939456\n",
      "76 Train Loss 0.01065592 Test MSE 0.03197868007031516 Test RE 0.08547484606902042\n",
      "77 Train Loss 0.010364539 Test MSE 0.030993494964267294 Test RE 0.08414791048231375\n",
      "78 Train Loss 0.010094032 Test MSE 0.03099350950385688 Test RE 0.08414793021993838\n",
      "79 Train Loss 0.009449282 Test MSE 0.029806602481020426 Test RE 0.08252096502111841\n",
      "80 Train Loss 0.009068122 Test MSE 0.028939650535621624 Test RE 0.0813120108831912\n",
      "81 Train Loss 0.008387081 Test MSE 0.02704320574677577 Test RE 0.07860264247091749\n",
      "82 Train Loss 0.00797398 Test MSE 0.02650090943673138 Test RE 0.07781054357583383\n",
      "83 Train Loss 0.0077025634 Test MSE 0.02613358488552579 Test RE 0.07726940258107053\n",
      "84 Train Loss 0.0072727036 Test MSE 0.027742018113885464 Test RE 0.0796117344578845\n",
      "85 Train Loss 0.0069354633 Test MSE 0.025541220954148718 Test RE 0.07638865922347098\n",
      "86 Train Loss 0.0065411464 Test MSE 0.02349740895722743 Test RE 0.07326862612354376\n",
      "87 Train Loss 0.0062874644 Test MSE 0.02329486295006405 Test RE 0.07295215746957937\n",
      "88 Train Loss 0.0059982194 Test MSE 0.02301163645270205 Test RE 0.07250731320122135\n",
      "89 Train Loss 0.005741043 Test MSE 0.023002424423673 Test RE 0.07249279866775378\n",
      "90 Train Loss 0.005610146 Test MSE 0.02221422244789033 Test RE 0.07123995205643466\n",
      "91 Train Loss 0.005461924 Test MSE 0.021220671989309242 Test RE 0.06962859414353299\n",
      "92 Train Loss 0.005037279 Test MSE 0.019744411543914916 Test RE 0.06716301096447436\n",
      "93 Train Loss 0.0048072473 Test MSE 0.01812728808268863 Test RE 0.0643538418112267\n",
      "94 Train Loss 0.0045549804 Test MSE 0.01765453020890144 Test RE 0.0635091270035586\n",
      "95 Train Loss 0.0043332432 Test MSE 0.01659252311673329 Test RE 0.061569308502247844\n",
      "96 Train Loss 0.0042026727 Test MSE 0.01574237565250982 Test RE 0.05997126311532266\n",
      "97 Train Loss 0.0040796176 Test MSE 0.014850588127171395 Test RE 0.05824784829669673\n",
      "98 Train Loss 0.003973284 Test MSE 0.015247817512941146 Test RE 0.05902172565761933\n",
      "99 Train Loss 0.0037894947 Test MSE 0.01515621415958899 Test RE 0.058844168027668654\n",
      "Training time: 82.30\n",
      "3\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 48.92022 Test MSE 9.396527179958513 Test RE 1.4651825829483416\n",
      "1 Train Loss 37.964252 Test MSE 8.980247335464457 Test RE 1.4323600823667317\n",
      "2 Train Loss 34.064583 Test MSE 9.059189451524729 Test RE 1.4386419875714571\n",
      "3 Train Loss 30.602383 Test MSE 8.77703863658038 Test RE 1.4160613370783814\n",
      "4 Train Loss 27.391607 Test MSE 8.422795921895094 Test RE 1.387190798463454\n",
      "5 Train Loss 24.599794 Test MSE 8.466085740962269 Test RE 1.3907510341035538\n",
      "6 Train Loss 22.470903 Test MSE 8.641802191311474 Test RE 1.4051096643770133\n",
      "7 Train Loss 20.885094 Test MSE 8.594354161914653 Test RE 1.4012469602694073\n",
      "8 Train Loss 19.276855 Test MSE 8.667369356428743 Test RE 1.4071866697308957\n",
      "9 Train Loss 18.094574 Test MSE 8.526569603597283 Test RE 1.3957101315718832\n",
      "10 Train Loss 15.855373 Test MSE 7.473636693612028 Test RE 1.3066944647154364\n",
      "11 Train Loss 11.741379 Test MSE 6.467246081519025 Test RE 1.2155357978568002\n",
      "12 Train Loss 9.25037 Test MSE 6.102811810979827 Test RE 1.1807910408302353\n",
      "13 Train Loss 7.911874 Test MSE 5.970155782094984 Test RE 1.167887182335552\n",
      "14 Train Loss 7.330944 Test MSE 5.830492071608831 Test RE 1.1541457717102506\n",
      "15 Train Loss 6.79749 Test MSE 5.7461041803155455 Test RE 1.1457630386171045\n",
      "16 Train Loss 6.32139 Test MSE 5.969903393178611 Test RE 1.1678624958025294\n",
      "17 Train Loss 5.9080753 Test MSE 6.103679179745607 Test RE 1.1808749484544019\n",
      "18 Train Loss 5.4859447 Test MSE 6.10339510489953 Test RE 1.1808474682443024\n",
      "19 Train Loss 5.053232 Test MSE 6.001549712220143 Test RE 1.1709538104349113\n",
      "20 Train Loss 4.5320706 Test MSE 5.733441466838378 Test RE 1.1444998809603828\n",
      "21 Train Loss 3.4047623 Test MSE 5.4685662899971375 Test RE 1.1177503146140013\n",
      "22 Train Loss 2.5717509 Test MSE 5.290644779928418 Test RE 1.0994167821672287\n",
      "23 Train Loss 2.2352085 Test MSE 5.214643849269482 Test RE 1.091491571421793\n",
      "24 Train Loss 2.0116532 Test MSE 5.273667859342305 Test RE 1.0976514294223187\n",
      "25 Train Loss 1.8962243 Test MSE 5.318658830368218 Test RE 1.1023236541645591\n",
      "26 Train Loss 1.8017786 Test MSE 5.3979306423033355 Test RE 1.1105080480247849\n",
      "27 Train Loss 1.7241907 Test MSE 5.450074215175075 Test RE 1.1158588658714572\n",
      "28 Train Loss 1.6658963 Test MSE 5.463917778472011 Test RE 1.1172751462067987\n",
      "29 Train Loss 1.6267653 Test MSE 5.465415928572979 Test RE 1.1174283083899472\n",
      "30 Train Loss 1.5486767 Test MSE 5.558221562896545 Test RE 1.1268756320014557\n",
      "31 Train Loss 1.5072091 Test MSE 5.515818795586578 Test RE 1.1225690273209472\n",
      "32 Train Loss 1.473135 Test MSE 5.5416506322590955 Test RE 1.1251945802102918\n",
      "33 Train Loss 1.4326363 Test MSE 5.537335762106712 Test RE 1.1247564423457745\n",
      "34 Train Loss 1.407404 Test MSE 5.572220743030649 Test RE 1.1282938387209749\n",
      "35 Train Loss 1.3879043 Test MSE 5.541146086496083 Test RE 1.1251433567465385\n",
      "36 Train Loss 1.3631228 Test MSE 5.558702270168445 Test RE 1.1269243603215595\n",
      "37 Train Loss 1.3369102 Test MSE 5.609794539761234 Test RE 1.1320915217709326\n",
      "38 Train Loss 1.3147894 Test MSE 5.622777653536826 Test RE 1.1334008013333632\n",
      "39 Train Loss 1.2914135 Test MSE 5.643827215345567 Test RE 1.1355203323667329\n",
      "40 Train Loss 1.2750033 Test MSE 5.641050218969211 Test RE 1.1352409365138578\n",
      "41 Train Loss 1.2514856 Test MSE 5.639098967067413 Test RE 1.1350445783412588\n",
      "42 Train Loss 1.2192603 Test MSE 5.665551825578702 Test RE 1.1377036950140729\n",
      "43 Train Loss 1.1986464 Test MSE 5.679521064650395 Test RE 1.139105418175554\n",
      "44 Train Loss 1.171171 Test MSE 5.698814236533219 Test RE 1.1410385322739152\n",
      "45 Train Loss 1.1525321 Test MSE 5.714114074899217 Test RE 1.1425692018780647\n",
      "46 Train Loss 1.1428099 Test MSE 5.71103721217459 Test RE 1.1422615424650653\n",
      "47 Train Loss 1.1272709 Test MSE 5.705816768213257 Test RE 1.1417393539825251\n",
      "48 Train Loss 1.1108516 Test MSE 5.704308222413177 Test RE 1.1415884132815517\n",
      "49 Train Loss 1.0948809 Test MSE 5.721080182074523 Test RE 1.1432654458709828\n",
      "50 Train Loss 1.0757481 Test MSE 5.743158464526593 Test RE 1.1454693157019868\n",
      "51 Train Loss 1.0642011 Test MSE 5.762049689789598 Test RE 1.147351690480833\n",
      "52 Train Loss 1.047722 Test MSE 5.794433721971263 Test RE 1.1505713619638978\n",
      "53 Train Loss 1.0242621 Test MSE 5.815582678429946 Test RE 1.1526691701174874\n",
      "54 Train Loss 1.0125263 Test MSE 5.828221559643359 Test RE 1.1539210259322594\n",
      "55 Train Loss 1.001159 Test MSE 5.876366392204011 Test RE 1.1586772860383092\n",
      "56 Train Loss 0.9892863 Test MSE 5.8748627244629565 Test RE 1.1585290331036104\n",
      "57 Train Loss 0.9803202 Test MSE 5.870776805241926 Test RE 1.1581260892726064\n",
      "58 Train Loss 0.9719448 Test MSE 5.878070871065749 Test RE 1.158845314852327\n",
      "59 Train Loss 0.9632081 Test MSE 5.899079028757189 Test RE 1.160914317766881\n",
      "60 Train Loss 0.9511255 Test MSE 5.928192153932543 Test RE 1.1637754632526878\n",
      "61 Train Loss 0.9416796 Test MSE 5.963252519866783 Test RE 1.1672117758892915\n",
      "62 Train Loss 0.93387455 Test MSE 5.978146441555146 Test RE 1.1686684909446348\n",
      "63 Train Loss 0.9258425 Test MSE 6.019604308673681 Test RE 1.172713791072167\n",
      "64 Train Loss 0.9185109 Test MSE 6.015432369152175 Test RE 1.1723073408512483\n",
      "65 Train Loss 0.9147278 Test MSE 6.015553502643985 Test RE 1.172319144239439\n",
      "66 Train Loss 0.9076036 Test MSE 6.025983708899007 Test RE 1.1733350303760426\n",
      "67 Train Loss 0.9004282 Test MSE 6.007514620005511 Test RE 1.1715355682474815\n",
      "68 Train Loss 0.89480186 Test MSE 6.010207760842884 Test RE 1.1717981357945249\n",
      "69 Train Loss 0.88780123 Test MSE 6.039464384591683 Test RE 1.1746467259808318\n",
      "70 Train Loss 0.8807456 Test MSE 6.044066036105763 Test RE 1.1750941402972848\n",
      "71 Train Loss 0.8769655 Test MSE 6.045675340731999 Test RE 1.1752505712959502\n",
      "72 Train Loss 0.8706196 Test MSE 6.066155839453073 Test RE 1.1772395440831023\n",
      "73 Train Loss 0.86555654 Test MSE 6.049749249410785 Test RE 1.1756464788598313\n",
      "74 Train Loss 0.859319 Test MSE 6.0766237239710685 Test RE 1.178254840772616\n",
      "75 Train Loss 0.8538482 Test MSE 6.07760568320118 Test RE 1.1783500376723277\n",
      "76 Train Loss 0.84886646 Test MSE 6.08110508372979 Test RE 1.1786892276070084\n",
      "77 Train Loss 0.8435814 Test MSE 6.098028990052748 Test RE 1.1803282525935093\n",
      "78 Train Loss 0.8403002 Test MSE 6.114164108377643 Test RE 1.181888769508334\n",
      "79 Train Loss 0.8361831 Test MSE 6.1319837147656635 Test RE 1.1836098117720573\n",
      "80 Train Loss 0.8322717 Test MSE 6.146361571570157 Test RE 1.1849966230657032\n",
      "81 Train Loss 0.82757497 Test MSE 6.140331386264277 Test RE 1.1844151812914334\n",
      "82 Train Loss 0.8239489 Test MSE 6.137956869197767 Test RE 1.1841861475607254\n",
      "83 Train Loss 0.8216592 Test MSE 6.145463152261072 Test RE 1.1849100138789448\n",
      "84 Train Loss 0.81785375 Test MSE 6.147992657091872 Test RE 1.1851538463756914\n",
      "85 Train Loss 0.81452537 Test MSE 6.149040433143796 Test RE 1.1852548324197718\n",
      "86 Train Loss 0.8095172 Test MSE 6.150986717499286 Test RE 1.1854423950526751\n",
      "87 Train Loss 0.80627704 Test MSE 6.155314901428118 Test RE 1.1858593940394202\n",
      "88 Train Loss 0.80305964 Test MSE 6.169659086102084 Test RE 1.1872403378192962\n",
      "89 Train Loss 0.7999611 Test MSE 6.175784015423848 Test RE 1.1878295080789578\n",
      "90 Train Loss 0.7969126 Test MSE 6.187607533265058 Test RE 1.1889660121908556\n",
      "91 Train Loss 0.79336023 Test MSE 6.189104494856731 Test RE 1.1891098261616837\n",
      "92 Train Loss 0.79054236 Test MSE 6.183948386242913 Test RE 1.1886144025573784\n",
      "93 Train Loss 0.7874866 Test MSE 6.178740692971912 Test RE 1.1881138127583606\n",
      "94 Train Loss 0.784555 Test MSE 6.194043603078718 Test RE 1.1895842058438701\n",
      "95 Train Loss 0.782426 Test MSE 6.198514044667466 Test RE 1.190013409112107\n",
      "96 Train Loss 0.780208 Test MSE 6.1875960639883765 Test RE 1.1889649102636242\n",
      "97 Train Loss 0.7765959 Test MSE 6.210475852087988 Test RE 1.191161091464352\n",
      "98 Train Loss 0.7748213 Test MSE 6.205254323114695 Test RE 1.190660244978005\n",
      "99 Train Loss 0.77058506 Test MSE 6.199942446318355 Test RE 1.1901505161017523\n",
      "Training time: 84.03\n",
      "4\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.080105 Test MSE 7.735629312259046 Test RE 1.3294006459875\n",
      "1 Train Loss 57.080837 Test MSE 8.430010549193145 Test RE 1.3877847771426377\n",
      "2 Train Loss 53.867218 Test MSE 8.57061775246309 Test RE 1.3993105978621942\n",
      "3 Train Loss 49.047028 Test MSE 8.270700701269613 Test RE 1.3746090940081404\n",
      "4 Train Loss 47.125816 Test MSE 8.081470537186389 Test RE 1.3587928635152824\n",
      "5 Train Loss 46.023247 Test MSE 8.115877077348129 Test RE 1.361682294723653\n",
      "6 Train Loss 45.00598 Test MSE 8.213358220261854 Test RE 1.369835580897782\n",
      "7 Train Loss 44.373707 Test MSE 8.11642243290954 Test RE 1.3617280438479105\n",
      "8 Train Loss 43.390594 Test MSE 8.652848283638345 Test RE 1.4060073946256582\n",
      "9 Train Loss 41.39361 Test MSE 7.807883587706843 Test RE 1.335594817077861\n",
      "10 Train Loss 40.078705 Test MSE 8.042358123839692 Test RE 1.3555007567698676\n",
      "11 Train Loss 39.573326 Test MSE 7.962193741014154 Test RE 1.3487281771610182\n",
      "12 Train Loss 38.343735 Test MSE 7.526956056413193 Test RE 1.311347372964317\n",
      "13 Train Loss 36.166676 Test MSE 6.415303754966048 Test RE 1.2106446090488063\n",
      "14 Train Loss 28.160612 Test MSE 4.260504038503818 Test RE 0.9865941839494221\n",
      "15 Train Loss 24.79921 Test MSE 3.5285935143186604 Test RE 0.8978605210671748\n",
      "16 Train Loss 19.11467 Test MSE 2.7457692202381923 Test RE 0.7920271634225408\n",
      "17 Train Loss 16.813591 Test MSE 2.34951935313473 Test RE 0.732651720185176\n",
      "18 Train Loss 8.948458 Test MSE 0.8092471250468599 Test RE 0.4299803836592868\n",
      "19 Train Loss 3.5085196 Test MSE 0.24380610206614253 Test RE 0.2360099679041851\n",
      "20 Train Loss 1.8508971 Test MSE 0.15131431748257984 Test RE 0.18592940175322906\n",
      "21 Train Loss 1.1370609 Test MSE 0.10086854309351449 Test RE 0.1518049504264544\n",
      "22 Train Loss 0.7689692 Test MSE 0.09586360663465264 Test RE 0.14799087650961065\n",
      "23 Train Loss 0.5795988 Test MSE 0.0705717332676815 Test RE 0.1269765293355482\n",
      "24 Train Loss 0.3969701 Test MSE 0.0572944714940896 Test RE 0.11441011420587517\n",
      "25 Train Loss 0.3071155 Test MSE 0.04733834339586765 Test RE 0.1039955097801921\n",
      "26 Train Loss 0.24233428 Test MSE 0.04116564882496583 Test RE 0.09697851792196736\n",
      "27 Train Loss 0.19073181 Test MSE 0.02522393186003409 Test RE 0.07591270248592731\n",
      "28 Train Loss 0.16555846 Test MSE 0.022230166119645112 Test RE 0.07126551276838006\n",
      "29 Train Loss 0.15198395 Test MSE 0.01940795346940989 Test RE 0.06658830060402117\n",
      "30 Train Loss 0.117777094 Test MSE 0.015617360219487746 Test RE 0.05973266261137458\n",
      "31 Train Loss 0.10360581 Test MSE 0.017586707737718487 Test RE 0.06338701979719812\n",
      "32 Train Loss 0.08971762 Test MSE 0.013509010076201776 Test RE 0.055554574175825475\n",
      "33 Train Loss 0.07429558 Test MSE 0.009732126952521961 Test RE 0.047153283825313544\n",
      "34 Train Loss 0.070112444 Test MSE 0.009215780730890773 Test RE 0.04588535825362418\n",
      "35 Train Loss 0.060640972 Test MSE 0.00836681459115442 Test RE 0.0437208033017971\n",
      "36 Train Loss 0.057372086 Test MSE 0.007507692770756448 Test RE 0.041415347180293355\n",
      "37 Train Loss 0.054180544 Test MSE 0.006477259334089291 Test RE 0.03846836277884924\n",
      "38 Train Loss 0.050693303 Test MSE 0.006513229714372216 Test RE 0.038575028716986405\n",
      "39 Train Loss 0.03751372 Test MSE 0.005829702482153864 Test RE 0.03649482251332553\n",
      "40 Train Loss 0.03508615 Test MSE 0.0062617899207640096 Test RE 0.03782311619248978\n",
      "41 Train Loss 0.030811643 Test MSE 0.0055103520955875375 Test RE 0.03548115389489396\n",
      "42 Train Loss 0.027082127 Test MSE 0.0045818604275748845 Test RE 0.032354075013479325\n",
      "43 Train Loss 0.021407843 Test MSE 0.0028818856177352803 Test RE 0.025659396050591633\n",
      "44 Train Loss 0.019909255 Test MSE 0.0028192867021335733 Test RE 0.025379185596666073\n",
      "45 Train Loss 0.018428873 Test MSE 0.002478640188719553 Test RE 0.023796594151445048\n",
      "46 Train Loss 0.016087677 Test MSE 0.0024396070367187907 Test RE 0.023608478501744076\n",
      "47 Train Loss 0.01377508 Test MSE 0.0019843547251704257 Test RE 0.02129206165643061\n",
      "48 Train Loss 0.013217755 Test MSE 0.0018164014838969516 Test RE 0.020371076715585676\n",
      "49 Train Loss 0.012502246 Test MSE 0.0014609963070668721 Test RE 0.018269750621910035\n",
      "50 Train Loss 0.012238912 Test MSE 0.0014861898214209082 Test RE 0.018426599710931534\n",
      "51 Train Loss 0.011204891 Test MSE 0.001304492122589744 Test RE 0.01726349767856272\n",
      "52 Train Loss 0.010539338 Test MSE 0.001278244255365116 Test RE 0.017088934496384576\n",
      "53 Train Loss 0.010300545 Test MSE 0.0012886003189885242 Test RE 0.017158020308921683\n",
      "54 Train Loss 0.0098964665 Test MSE 0.0012034909538103915 Test RE 0.016581716106742035\n",
      "55 Train Loss 0.009625122 Test MSE 0.0012548793803919538 Test RE 0.01693203088162761\n",
      "56 Train Loss 0.009141175 Test MSE 0.0013220171056052307 Test RE 0.017379072603373638\n",
      "57 Train Loss 0.0077253236 Test MSE 0.0010020886100105162 Test RE 0.0151307732581588\n",
      "58 Train Loss 0.0074572675 Test MSE 0.0009589306035665023 Test RE 0.014801360957550977\n",
      "59 Train Loss 0.007336003 Test MSE 0.0009373917372306556 Test RE 0.014634187691746537\n",
      "60 Train Loss 0.0070774034 Test MSE 0.0009852144260924897 Test RE 0.01500283874912962\n",
      "61 Train Loss 0.006472477 Test MSE 0.0009513711088693661 Test RE 0.014742904068854978\n",
      "62 Train Loss 0.0062644845 Test MSE 0.000885062466708933 Test RE 0.014219850228289416\n",
      "63 Train Loss 0.0061600734 Test MSE 0.0008555257409574217 Test RE 0.013980561066317652\n",
      "64 Train Loss 0.00588719 Test MSE 0.0008831319843929963 Test RE 0.014204333721951982\n",
      "65 Train Loss 0.0053356895 Test MSE 0.0009003081296946317 Test RE 0.01434179948209256\n",
      "66 Train Loss 0.005225995 Test MSE 0.0009149936156612612 Test RE 0.0144582953510966\n",
      "67 Train Loss 0.005021394 Test MSE 0.0009166819114707748 Test RE 0.014471628028763043\n",
      "68 Train Loss 0.0045569497 Test MSE 0.0008584232666337126 Test RE 0.01400421599060203\n",
      "69 Train Loss 0.004320101 Test MSE 0.0008795601722387467 Test RE 0.014175580027059952\n",
      "70 Train Loss 0.004236006 Test MSE 0.0008915504238511515 Test RE 0.01427187442155327\n",
      "71 Train Loss 0.0041394252 Test MSE 0.0008506312310273448 Test RE 0.013940511923004608\n",
      "72 Train Loss 0.004034968 Test MSE 0.0008094683168468471 Test RE 0.013599031748713734\n",
      "73 Train Loss 0.0038192547 Test MSE 0.0007013492760430017 Test RE 0.01265829570419149\n",
      "74 Train Loss 0.0037344196 Test MSE 0.0006860447154749768 Test RE 0.012519421805308559\n",
      "75 Train Loss 0.003635821 Test MSE 0.0006599795365994865 Test RE 0.012279291103931679\n",
      "76 Train Loss 0.0034904224 Test MSE 0.0006516262605265081 Test RE 0.012201334944421697\n",
      "77 Train Loss 0.0032035168 Test MSE 0.0006169775319997209 Test RE 0.011872515213317912\n",
      "78 Train Loss 0.0030369274 Test MSE 0.0006264710567187344 Test RE 0.011963508592930395\n",
      "79 Train Loss 0.0029598027 Test MSE 0.0006043596569399432 Test RE 0.011750485022875946\n",
      "80 Train Loss 0.002921948 Test MSE 0.0005941441201572302 Test RE 0.011650752111984918\n",
      "81 Train Loss 0.0029005143 Test MSE 0.0006042470484840111 Test RE 0.011749390256206341\n",
      "82 Train Loss 0.0028437092 Test MSE 0.0005787218359045633 Test RE 0.011498547797789582\n",
      "83 Train Loss 0.0027368786 Test MSE 0.0005537874054154902 Test RE 0.01124811110579894\n",
      "84 Train Loss 0.0026025332 Test MSE 0.0005136730973110533 Test RE 0.010833068037297902\n",
      "85 Train Loss 0.0025391069 Test MSE 0.0005191136159116787 Test RE 0.01089028562544021\n",
      "86 Train Loss 0.0025204588 Test MSE 0.0005367314974314033 Test RE 0.011073543125044502\n",
      "87 Train Loss 0.0024288609 Test MSE 0.0004937478733985 Test RE 0.010620884336975346\n",
      "88 Train Loss 0.0022199675 Test MSE 0.0005047893870857344 Test RE 0.010738983325502344\n",
      "89 Train Loss 0.0020974772 Test MSE 0.0004621983807962365 Test RE 0.010275956807070039\n",
      "90 Train Loss 0.0020559658 Test MSE 0.0004574696024047401 Test RE 0.01022325470645458\n",
      "91 Train Loss 0.002025187 Test MSE 0.0004671626254532149 Test RE 0.010330993909991485\n",
      "92 Train Loss 0.0020118942 Test MSE 0.00044964846382079045 Test RE 0.01013548691478233\n",
      "93 Train Loss 0.002001081 Test MSE 0.0004429349601639372 Test RE 0.010059538108066831\n",
      "94 Train Loss 0.0019716418 Test MSE 0.0004549798147586597 Test RE 0.010195396614004183\n",
      "95 Train Loss 0.0019160097 Test MSE 0.0004594395098218373 Test RE 0.010245242213116231\n",
      "96 Train Loss 0.001862075 Test MSE 0.00044571768423239935 Test RE 0.010091087988691077\n",
      "97 Train Loss 0.0017064002 Test MSE 0.000433931382951194 Test RE 0.009956772646059998\n",
      "98 Train Loss 0.0016387772 Test MSE 0.00041782608521676414 Test RE 0.009770253569445294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0016040977 Test MSE 0.0004037523709354548 Test RE 0.009604297476116429\n",
      "Training time: 84.35\n",
      "5\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 55.536507 Test MSE 8.867786687456544 Test RE 1.42336302257122\n",
      "1 Train Loss 46.811134 Test MSE 8.650524737766286 Test RE 1.405818604650578\n",
      "2 Train Loss 41.17318 Test MSE 8.435194963476143 Test RE 1.3882114518970174\n",
      "3 Train Loss 35.9035 Test MSE 7.8571240457646825 Test RE 1.339799665818402\n",
      "4 Train Loss 33.040066 Test MSE 8.1447985391663 Test RE 1.3641063592793785\n",
      "5 Train Loss 31.51274 Test MSE 8.083737877716585 Test RE 1.3589834618758707\n",
      "6 Train Loss 29.395473 Test MSE 8.475321013151188 Test RE 1.3915093812266084\n",
      "7 Train Loss 28.35823 Test MSE 8.427235119858379 Test RE 1.3875563067489076\n",
      "8 Train Loss 27.503479 Test MSE 8.429834401351433 Test RE 1.387770277957326\n",
      "9 Train Loss 26.60146 Test MSE 8.327014722625131 Test RE 1.3792809136850925\n",
      "10 Train Loss 25.474207 Test MSE 8.339668713619083 Test RE 1.3803285149677038\n",
      "11 Train Loss 23.397982 Test MSE 8.136390770627878 Test RE 1.36340210294621\n",
      "12 Train Loss 22.009552 Test MSE 8.144725697526223 Test RE 1.3641002594374894\n",
      "13 Train Loss 20.74912 Test MSE 7.924645920020229 Test RE 1.3455442776795739\n",
      "14 Train Loss 19.719242 Test MSE 8.010776428147155 Test RE 1.3528366673720362\n",
      "15 Train Loss 18.534569 Test MSE 8.073139203781745 Test RE 1.3580922809005282\n",
      "16 Train Loss 16.915043 Test MSE 7.774162562535075 Test RE 1.3327075840112217\n",
      "17 Train Loss 15.7730055 Test MSE 7.519470377526247 Test RE 1.3106951327288616\n",
      "18 Train Loss 14.967924 Test MSE 7.342139724044621 Test RE 1.2951479510060064\n",
      "19 Train Loss 13.965927 Test MSE 6.770493957209664 Test RE 1.2437074553196783\n",
      "20 Train Loss 12.134889 Test MSE 5.673094607111119 Test RE 1.138460778911167\n",
      "21 Train Loss 10.496399 Test MSE 5.726819596849167 Test RE 1.143838766776458\n",
      "22 Train Loss 9.589647 Test MSE 5.951809129972516 Test RE 1.1660913073652897\n",
      "23 Train Loss 8.89706 Test MSE 5.999294600417658 Test RE 1.1707337939400964\n",
      "24 Train Loss 8.326488 Test MSE 5.957524967760391 Test RE 1.1666511026433013\n",
      "25 Train Loss 7.7210865 Test MSE 5.8538126609817205 Test RE 1.1564516233613804\n",
      "26 Train Loss 7.1477137 Test MSE 5.903559292693898 Test RE 1.1613550827864494\n",
      "27 Train Loss 5.792341 Test MSE 5.208624904779095 Test RE 1.0908614685619777\n",
      "28 Train Loss 4.8124256 Test MSE 4.908697568499852 Test RE 1.0589883879772934\n",
      "29 Train Loss 4.3410187 Test MSE 5.038786979555064 Test RE 1.0729291867461181\n",
      "30 Train Loss 3.942278 Test MSE 4.97915402694637 Test RE 1.0665613478963638\n",
      "31 Train Loss 3.5233302 Test MSE 4.992758776830978 Test RE 1.0680174589184228\n",
      "32 Train Loss 3.306098 Test MSE 4.96589077945392 Test RE 1.0651398714739437\n",
      "33 Train Loss 3.1692781 Test MSE 5.062669191894085 Test RE 1.0754688487958992\n",
      "34 Train Loss 3.0058777 Test MSE 5.10270795767281 Test RE 1.079713214905673\n",
      "35 Train Loss 2.7844229 Test MSE 5.167798795767258 Test RE 1.086577877090724\n",
      "36 Train Loss 2.6476731 Test MSE 5.271509459819627 Test RE 1.097426783801203\n",
      "37 Train Loss 2.44345 Test MSE 5.341876010093105 Test RE 1.1047269834929705\n",
      "38 Train Loss 2.3164117 Test MSE 5.276722924595149 Test RE 1.0979693211924728\n",
      "39 Train Loss 2.1895552 Test MSE 5.2549925450312 Test RE 1.0957061831394725\n",
      "40 Train Loss 2.0945327 Test MSE 5.271081664857182 Test RE 1.0973822535600601\n",
      "41 Train Loss 2.0010252 Test MSE 5.389939026554831 Test RE 1.1096856920714335\n",
      "42 Train Loss 1.970363 Test MSE 5.427297818927922 Test RE 1.1135247827460797\n",
      "43 Train Loss 1.907619 Test MSE 5.433579228733401 Test RE 1.1141689783549298\n",
      "44 Train Loss 1.8424146 Test MSE 5.491862022311173 Test RE 1.1201285558884653\n",
      "45 Train Loss 1.7891515 Test MSE 5.469841237465364 Test RE 1.1178806037800348\n",
      "46 Train Loss 1.73482 Test MSE 5.457041885681173 Test RE 1.1165719252917297\n",
      "47 Train Loss 1.6755852 Test MSE 5.58981991389078 Test RE 1.1300742224024167\n",
      "48 Train Loss 1.6372099 Test MSE 5.563038442573802 Test RE 1.1273638141264863\n",
      "49 Train Loss 1.6010089 Test MSE 5.5728380336266135 Test RE 1.128356333184148\n",
      "50 Train Loss 1.5667644 Test MSE 5.58655045671028 Test RE 1.1297436867364214\n",
      "51 Train Loss 1.5359612 Test MSE 5.57417152915925 Test RE 1.1284913243790073\n",
      "52 Train Loss 1.5051954 Test MSE 5.573022058218902 Test RE 1.1283749631531825\n",
      "53 Train Loss 1.4765462 Test MSE 5.5666637885030035 Test RE 1.1277310970601782\n",
      "54 Train Loss 1.4523444 Test MSE 5.586390613630334 Test RE 1.1297275244370237\n",
      "55 Train Loss 1.4209124 Test MSE 5.614991234111098 Test RE 1.132615763053522\n",
      "56 Train Loss 1.393016 Test MSE 5.614853855737747 Test RE 1.1326019074786504\n",
      "57 Train Loss 1.3669465 Test MSE 5.603809577092623 Test RE 1.1314874592178819\n",
      "58 Train Loss 1.3489754 Test MSE 5.6257268632234565 Test RE 1.1336980030573527\n",
      "59 Train Loss 1.3332545 Test MSE 5.646678336338482 Test RE 1.1358071144527526\n",
      "60 Train Loss 1.3123976 Test MSE 5.664335362222459 Test RE 1.1375815489994463\n",
      "61 Train Loss 1.2988669 Test MSE 5.689709742209161 Test RE 1.140126699482329\n",
      "62 Train Loss 1.2746077 Test MSE 5.668345467216999 Test RE 1.1379841570771965\n",
      "63 Train Loss 1.2515558 Test MSE 5.645953686819143 Test RE 1.1357342319155759\n",
      "64 Train Loss 1.2280719 Test MSE 5.640903562958749 Test RE 1.1352261794223308\n",
      "65 Train Loss 1.2014422 Test MSE 5.669673971262983 Test RE 1.1381175053349921\n",
      "66 Train Loss 1.1848409 Test MSE 5.698498629370342 Test RE 1.1410069357956778\n",
      "67 Train Loss 1.1722071 Test MSE 5.727903127116219 Test RE 1.1439469704037322\n",
      "68 Train Loss 1.1612605 Test MSE 5.695103499809309 Test RE 1.140666982782849\n",
      "69 Train Loss 1.1456566 Test MSE 5.714964644285041 Test RE 1.1426542367766395\n",
      "70 Train Loss 1.1285311 Test MSE 5.718478091202792 Test RE 1.1430054233904796\n",
      "71 Train Loss 1.1163925 Test MSE 5.725486742570584 Test RE 1.1437056510840917\n",
      "72 Train Loss 1.1068093 Test MSE 5.729122275958076 Test RE 1.1440687049539544\n",
      "73 Train Loss 1.0888196 Test MSE 5.755431022906901 Test RE 1.1466925395690513\n",
      "74 Train Loss 1.0808389 Test MSE 5.756711437683038 Test RE 1.1468200852223982\n",
      "75 Train Loss 1.071402 Test MSE 5.788072791803997 Test RE 1.1499396597048128\n",
      "76 Train Loss 1.0634699 Test MSE 5.788060051768251 Test RE 1.149938394147091\n",
      "77 Train Loss 1.0484321 Test MSE 5.845632536047945 Test RE 1.1556433274315636\n",
      "78 Train Loss 1.0334568 Test MSE 5.863430864329726 Test RE 1.1574012968748248\n",
      "79 Train Loss 1.0230944 Test MSE 5.880051779742232 Test RE 1.1590405637205727\n",
      "80 Train Loss 1.0151341 Test MSE 5.897653711713822 Test RE 1.1607740610491695\n",
      "81 Train Loss 1.0038823 Test MSE 5.899050617573324 Test RE 1.1609115221618644\n",
      "82 Train Loss 0.9848492 Test MSE 5.964348935628226 Test RE 1.1673190739254584\n",
      "83 Train Loss 0.9716697 Test MSE 5.972422690367527 Test RE 1.1681088885976354\n",
      "84 Train Loss 0.9593564 Test MSE 5.979978919551187 Test RE 1.168847592880966\n",
      "85 Train Loss 0.95260465 Test MSE 5.9780735947509545 Test RE 1.168661370508149\n",
      "86 Train Loss 0.9405695 Test MSE 5.976316619397643 Test RE 1.1684896211910363\n",
      "87 Train Loss 0.93425083 Test MSE 5.9878359598822595 Test RE 1.1696152099739625\n",
      "88 Train Loss 0.9272038 Test MSE 6.001285160282795 Test RE 1.1709280019747783\n",
      "89 Train Loss 0.9160338 Test MSE 5.990876154787062 Test RE 1.1699120957760853\n",
      "90 Train Loss 0.911836 Test MSE 5.989693959656211 Test RE 1.1697966591867561\n",
      "91 Train Loss 0.9043276 Test MSE 5.987903496302518 Test RE 1.1696218059630774\n",
      "92 Train Loss 0.8972578 Test MSE 6.019102634319357 Test RE 1.1726649230185584\n",
      "93 Train Loss 0.8925777 Test MSE 6.041400039362918 Test RE 1.1748349486643686\n",
      "94 Train Loss 0.8882846 Test MSE 6.044007877912877 Test RE 1.1750884866929348\n",
      "95 Train Loss 0.88006043 Test MSE 6.05406691550472 Test RE 1.1760659295980675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 0.8757123 Test MSE 6.052019935901004 Test RE 1.1758670891712548\n",
      "97 Train Loss 0.8722985 Test MSE 6.054692524860753 Test RE 1.1761266936144195\n",
      "98 Train Loss 0.86810505 Test MSE 6.087410800317261 Test RE 1.1793001818956188\n",
      "99 Train Loss 0.8619739 Test MSE 6.074072039623751 Test RE 1.1780074295240521\n",
      "Training time: 83.46\n",
      "6\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.93338 Test MSE 8.135145414639762 Test RE 1.3632977577889465\n",
      "1 Train Loss 55.276306 Test MSE 8.232835318290066 Test RE 1.3714588282019815\n",
      "2 Train Loss 48.49157 Test MSE 8.754814314167739 Test RE 1.414267397676147\n",
      "3 Train Loss 46.883194 Test MSE 8.703005034535574 Test RE 1.410076509269289\n",
      "4 Train Loss 46.345383 Test MSE 8.892711200867133 Test RE 1.425361928194363\n",
      "5 Train Loss 45.74738 Test MSE 8.825905848007146 Test RE 1.4199979107015757\n",
      "6 Train Loss 44.63878 Test MSE 8.688230957108951 Test RE 1.4088791396127338\n",
      "7 Train Loss 43.662052 Test MSE 8.979476496769918 Test RE 1.432298606205254\n",
      "8 Train Loss 43.041817 Test MSE 8.965273711776064 Test RE 1.4311654288156692\n",
      "9 Train Loss 42.67817 Test MSE 9.19429767246705 Test RE 1.4493301954058693\n",
      "10 Train Loss 42.324978 Test MSE 9.255264849197777 Test RE 1.4541274934743909\n",
      "11 Train Loss 41.690742 Test MSE 8.944307919629152 Test RE 1.4294910192656156\n",
      "12 Train Loss 41.44551 Test MSE 9.007670553932869 Test RE 1.434545433179615\n",
      "13 Train Loss 40.74626 Test MSE 9.127945221152434 Test RE 1.4440910382210304\n",
      "14 Train Loss 39.869843 Test MSE 9.137992767861514 Test RE 1.4448856081470043\n",
      "15 Train Loss 38.443924 Test MSE 9.682124022346743 Test RE 1.48728220241587\n",
      "16 Train Loss 37.21554 Test MSE 9.672897364941466 Test RE 1.4865733747790162\n",
      "17 Train Loss 35.870293 Test MSE 9.860549629040017 Test RE 1.5009237229199648\n",
      "18 Train Loss 32.38972 Test MSE 9.834138011739503 Test RE 1.4989122526996685\n",
      "19 Train Loss 29.95005 Test MSE 9.60599383048818 Test RE 1.4814234397290822\n",
      "20 Train Loss 28.784863 Test MSE 9.432549989146448 Test RE 1.4679883804301843\n",
      "21 Train Loss 28.265558 Test MSE 9.345975138168736 Test RE 1.4612360260170019\n",
      "22 Train Loss 27.350853 Test MSE 9.820157677933054 Test RE 1.4978464375519769\n",
      "23 Train Loss 27.014172 Test MSE 9.966151817994737 Test RE 1.5089394383284527\n",
      "24 Train Loss 26.673523 Test MSE 10.157274847563558 Test RE 1.5233393561201138\n",
      "25 Train Loss 26.139832 Test MSE 10.078688979299985 Test RE 1.517434947714352\n",
      "26 Train Loss 25.872522 Test MSE 10.18085522173194 Test RE 1.5251065667586035\n",
      "27 Train Loss 25.371258 Test MSE 9.690673135097915 Test RE 1.4879386770537304\n",
      "28 Train Loss 24.991741 Test MSE 9.448669122946733 Test RE 1.4692421559508162\n",
      "29 Train Loss 24.519836 Test MSE 9.448170951420355 Test RE 1.4692034232866813\n",
      "30 Train Loss 24.177397 Test MSE 9.363461651940908 Test RE 1.4626023886832176\n",
      "31 Train Loss 21.899384 Test MSE 7.692644094771255 Test RE 1.3257019047521506\n",
      "32 Train Loss 20.24726 Test MSE 7.418585685096291 Test RE 1.3018729962854345\n",
      "33 Train Loss 18.896671 Test MSE 7.104606991188787 Test RE 1.2740254093243804\n",
      "34 Train Loss 18.62238 Test MSE 7.0763494803227225 Test RE 1.2714892623430276\n",
      "35 Train Loss 18.311802 Test MSE 7.049705152247 Test RE 1.269093258074846\n",
      "36 Train Loss 17.930166 Test MSE 7.270654378333877 Test RE 1.2888275482916671\n",
      "37 Train Loss 17.634119 Test MSE 7.08265522741634 Test RE 1.272055649319392\n",
      "38 Train Loss 17.400593 Test MSE 7.093437671170101 Test RE 1.2730235527293885\n",
      "39 Train Loss 16.894255 Test MSE 6.730796710677103 Test RE 1.2400559976314698\n",
      "40 Train Loss 16.312204 Test MSE 6.153347722383592 Test RE 1.1856698843066322\n",
      "41 Train Loss 14.799896 Test MSE 5.819271822277938 Test RE 1.1530347128713094\n",
      "42 Train Loss 14.086958 Test MSE 5.365852138346694 Test RE 1.1072034001663265\n",
      "43 Train Loss 13.682963 Test MSE 5.068728204003851 Test RE 1.076112217938117\n",
      "44 Train Loss 12.159195 Test MSE 4.605839600071515 Test RE 1.0257994573782612\n",
      "45 Train Loss 11.287064 Test MSE 4.199480154166536 Test RE 0.9795031272245601\n",
      "46 Train Loss 9.215066 Test MSE 2.8066373734337966 Test RE 0.8007578637362087\n",
      "47 Train Loss 5.911713 Test MSE 2.1131095421345645 Test RE 0.6948148083771505\n",
      "48 Train Loss 4.949233 Test MSE 1.8988736991936688 Test RE 0.6586521289083314\n",
      "49 Train Loss 4.579165 Test MSE 1.670532506994438 Test RE 0.6177823918366552\n",
      "50 Train Loss 4.2200885 Test MSE 1.6091104937383645 Test RE 0.6063187431745357\n",
      "51 Train Loss 3.9529967 Test MSE 1.7258439164390966 Test RE 0.6279265095018547\n",
      "52 Train Loss 3.7487457 Test MSE 1.7775450095935788 Test RE 0.6372625007409208\n",
      "53 Train Loss 3.637145 Test MSE 1.857648355574073 Test RE 0.6514630886839013\n",
      "54 Train Loss 3.4403496 Test MSE 1.9418594922470676 Test RE 0.6660655340876741\n",
      "55 Train Loss 3.3304386 Test MSE 1.9695934848800989 Test RE 0.6708051061496352\n",
      "56 Train Loss 3.2062528 Test MSE 2.0616247263376417 Test RE 0.6862982120234826\n",
      "57 Train Loss 3.0650184 Test MSE 2.1282656135763274 Test RE 0.6973021019940234\n",
      "58 Train Loss 2.9471185 Test MSE 2.176428476257141 Test RE 0.7051479701137164\n",
      "59 Train Loss 2.7457597 Test MSE 2.287363727465613 Test RE 0.7228957562223355\n",
      "60 Train Loss 2.5441194 Test MSE 2.3387910809660757 Test RE 0.7309771052924702\n",
      "61 Train Loss 2.4127688 Test MSE 2.334044579924135 Test RE 0.7302349813463207\n",
      "62 Train Loss 2.3408928 Test MSE 2.3703492249830247 Test RE 0.7358922480836907\n",
      "63 Train Loss 2.2697344 Test MSE 2.394047982901073 Test RE 0.739561825121681\n",
      "64 Train Loss 2.2085702 Test MSE 2.372931977827006 Test RE 0.7362930561847418\n",
      "65 Train Loss 2.142601 Test MSE 2.4092205866370833 Test RE 0.741901660398528\n",
      "66 Train Loss 2.0867412 Test MSE 2.4597077538591083 Test RE 0.7496349310835004\n",
      "67 Train Loss 2.0263207 Test MSE 2.5029562915312376 Test RE 0.7561965525855774\n",
      "68 Train Loss 1.9854374 Test MSE 2.4966274097009813 Test RE 0.7552399022802145\n",
      "69 Train Loss 1.9407489 Test MSE 2.4614776879139724 Test RE 0.7499045903132497\n",
      "70 Train Loss 1.9038603 Test MSE 2.486357152790919 Test RE 0.7536849042980778\n",
      "71 Train Loss 1.8624227 Test MSE 2.518423007392463 Test RE 0.7585293668959033\n",
      "72 Train Loss 1.838894 Test MSE 2.5256538862233744 Test RE 0.7596175285278197\n",
      "73 Train Loss 1.825633 Test MSE 2.5245518591516323 Test RE 0.7594517872081462\n",
      "74 Train Loss 1.8055038 Test MSE 2.5396324116958757 Test RE 0.7617167237990303\n",
      "75 Train Loss 1.7863319 Test MSE 2.5344937732136197 Test RE 0.7609457128393675\n",
      "76 Train Loss 1.7761648 Test MSE 2.528754453686376 Test RE 0.7600836499958553\n",
      "77 Train Loss 1.7604157 Test MSE 2.542634602062691 Test RE 0.7621668171209103\n",
      "78 Train Loss 1.7486218 Test MSE 2.533673276066694 Test RE 0.7608225315690125\n",
      "79 Train Loss 1.7402221 Test MSE 2.5471650327013706 Test RE 0.7628455239953247\n",
      "80 Train Loss 1.7197329 Test MSE 2.5657090378698406 Test RE 0.7656173423616368\n",
      "81 Train Loss 1.708387 Test MSE 2.567258068293094 Test RE 0.7658484257751835\n",
      "82 Train Loss 1.6957972 Test MSE 2.5719790337319233 Test RE 0.7665522668405833\n",
      "83 Train Loss 1.6821786 Test MSE 2.57113014550968 Test RE 0.7664257551380971\n",
      "84 Train Loss 1.6694722 Test MSE 2.5848324625007875 Test RE 0.7684652967789101\n",
      "85 Train Loss 1.6543695 Test MSE 2.6100712252438347 Test RE 0.7722078988602449\n",
      "86 Train Loss 1.6416209 Test MSE 2.6095723580716648 Test RE 0.7721340986558223\n",
      "87 Train Loss 1.6275537 Test MSE 2.5964285435717587 Test RE 0.7701871131869472\n",
      "88 Train Loss 1.6195781 Test MSE 2.58245160663673 Test RE 0.7681113035055988\n",
      "89 Train Loss 1.6080337 Test MSE 2.5788555242612783 Test RE 0.7675763169492603\n",
      "90 Train Loss 1.5996951 Test MSE 2.5644369381924985 Test RE 0.7654275191369826\n",
      "91 Train Loss 1.5929713 Test MSE 2.554274004443481 Test RE 0.7639093083658285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 1.5841025 Test MSE 2.5658534700518185 Test RE 0.7656388916147879\n",
      "93 Train Loss 1.5799114 Test MSE 2.566864280695079 Test RE 0.7657896873917265\n",
      "94 Train Loss 1.5697409 Test MSE 2.587340368171131 Test RE 0.7688380039580578\n",
      "95 Train Loss 1.5595514 Test MSE 2.576511798615005 Test RE 0.7672274417972151\n",
      "96 Train Loss 1.5518506 Test MSE 2.5890471004884086 Test RE 0.769091543144118\n",
      "97 Train Loss 1.5437251 Test MSE 2.5919121348627967 Test RE 0.7695169630707953\n",
      "98 Train Loss 1.5350974 Test MSE 2.6054836286296355 Test RE 0.7715289640609948\n",
      "99 Train Loss 1.5318311 Test MSE 2.6020843790539208 Test RE 0.7710255113747356\n",
      "Training time: 83.76\n",
      "7\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 53.529686 Test MSE 6.987732708756764 Test RE 1.2635027816901545\n",
      "1 Train Loss 39.18604 Test MSE 7.64972204701298 Test RE 1.3219982734213545\n",
      "2 Train Loss 29.91159 Test MSE 6.5873435756391805 Test RE 1.2267702006343741\n",
      "3 Train Loss 27.344612 Test MSE 6.542758483944696 Test RE 1.2226115800239725\n",
      "4 Train Loss 24.039047 Test MSE 6.314727933731628 Test RE 1.2011171893686388\n",
      "5 Train Loss 18.440983 Test MSE 5.327324644472903 Test RE 1.1032213094100818\n",
      "6 Train Loss 15.395739 Test MSE 5.468521920407688 Test RE 1.117745780132701\n",
      "7 Train Loss 13.347946 Test MSE 5.540137502504039 Test RE 1.1250409543550735\n",
      "8 Train Loss 12.174562 Test MSE 5.392266006468033 Test RE 1.1099252066243803\n",
      "9 Train Loss 11.150821 Test MSE 5.282002938844234 Test RE 1.0985185109302575\n",
      "10 Train Loss 10.253356 Test MSE 5.199718623377146 Test RE 1.089928431905622\n",
      "11 Train Loss 9.634443 Test MSE 4.913364171873563 Test RE 1.0594916482348316\n",
      "12 Train Loss 8.98761 Test MSE 4.688114971014798 Test RE 1.0349209706271398\n",
      "13 Train Loss 8.139275 Test MSE 4.477323992814992 Test RE 1.0113868938229784\n",
      "14 Train Loss 6.9477415 Test MSE 4.186139406779072 Test RE 0.9779460656657917\n",
      "15 Train Loss 6.1351233 Test MSE 4.085038070081494 Test RE 0.9660644800540099\n",
      "16 Train Loss 5.664496 Test MSE 3.975893316283566 Test RE 0.9530713654570454\n",
      "17 Train Loss 5.3189864 Test MSE 3.8713331278246383 Test RE 0.9404556766955026\n",
      "18 Train Loss 5.0753393 Test MSE 3.8065966660655657 Test RE 0.9325593735597658\n",
      "19 Train Loss 4.792081 Test MSE 3.5907035080990615 Test RE 0.9057280821598586\n",
      "20 Train Loss 4.4460373 Test MSE 3.353019046533941 Test RE 0.8752378094017582\n",
      "21 Train Loss 4.1596303 Test MSE 3.1412375748165227 Test RE 0.8471463659316263\n",
      "22 Train Loss 3.7916424 Test MSE 2.9186008015362725 Test RE 0.8165737391408845\n",
      "23 Train Loss 2.9452739 Test MSE 2.5988711071297894 Test RE 0.7705493008448717\n",
      "24 Train Loss 2.6416206 Test MSE 2.552238357369721 Test RE 0.763604846178915\n",
      "25 Train Loss 2.3524735 Test MSE 2.407455418308015 Test RE 0.7416298253322894\n",
      "26 Train Loss 2.1044555 Test MSE 2.0477878838510084 Test RE 0.6839912481139602\n",
      "27 Train Loss 1.8179284 Test MSE 1.8620371269589118 Test RE 0.6522321889945829\n",
      "28 Train Loss 1.649183 Test MSE 1.60474489561881 Test RE 0.6054956978528817\n",
      "29 Train Loss 1.4490898 Test MSE 1.3701970858810768 Test RE 0.5594993419145956\n",
      "30 Train Loss 1.1474409 Test MSE 0.9512550269674966 Test RE 0.46618311847270694\n",
      "31 Train Loss 0.9006199 Test MSE 0.6438441227994358 Test RE 0.38352919431308014\n",
      "32 Train Loss 0.69595855 Test MSE 0.3977356862357271 Test RE 0.3014430947906434\n",
      "33 Train Loss 0.49119487 Test MSE 0.22087077022288762 Test RE 0.22463487545861333\n",
      "34 Train Loss 0.43130773 Test MSE 0.15354581673249293 Test RE 0.18729537564322207\n",
      "35 Train Loss 0.34134582 Test MSE 0.09910555400159335 Test RE 0.15047247246464976\n",
      "36 Train Loss 0.2801915 Test MSE 0.08086932788865812 Test RE 0.13592519887975854\n",
      "37 Train Loss 0.23920313 Test MSE 0.059145943778316175 Test RE 0.11624399934591863\n",
      "38 Train Loss 0.18623681 Test MSE 0.044260527660877326 Test RE 0.10055793673850533\n",
      "39 Train Loss 0.15264857 Test MSE 0.047301057717958 Test RE 0.10395454608529385\n",
      "40 Train Loss 0.13568553 Test MSE 0.03702081854041994 Test RE 0.09196679858683926\n",
      "41 Train Loss 0.116495505 Test MSE 0.03869132549904378 Test RE 0.09401883475727081\n",
      "42 Train Loss 0.097224966 Test MSE 0.024484131421022105 Test RE 0.07479118447769187\n",
      "43 Train Loss 0.078072354 Test MSE 0.024207437128904743 Test RE 0.07436737747036247\n",
      "44 Train Loss 0.06920933 Test MSE 0.01900600136591173 Test RE 0.0658951480919008\n",
      "45 Train Loss 0.055639975 Test MSE 0.01148719559033339 Test RE 0.05122890442060001\n",
      "46 Train Loss 0.047281366 Test MSE 0.009387261114295055 Test RE 0.04631029094078414\n",
      "47 Train Loss 0.040476073 Test MSE 0.007854847099936208 Test RE 0.04236204605963382\n",
      "48 Train Loss 0.035696313 Test MSE 0.007876828436069306 Test RE 0.04242127851905645\n",
      "49 Train Loss 0.030091278 Test MSE 0.005063827645542215 Test RE 0.034013201976227474\n",
      "50 Train Loss 0.027017254 Test MSE 0.003732646619089549 Test RE 0.02920226234543298\n",
      "51 Train Loss 0.023375187 Test MSE 0.004395202483028893 Test RE 0.03168819515074992\n",
      "52 Train Loss 0.018364236 Test MSE 0.004645027054067732 Test RE 0.03257633213109642\n",
      "53 Train Loss 0.016745709 Test MSE 0.004426073415489046 Test RE 0.031799285868354975\n",
      "54 Train Loss 0.015205792 Test MSE 0.003216343633349298 Test RE 0.027107488457090254\n",
      "55 Train Loss 0.013142307 Test MSE 0.0030748330321602167 Test RE 0.02650445199801954\n",
      "56 Train Loss 0.012089425 Test MSE 0.0027994642496908294 Test RE 0.025289807473372974\n",
      "57 Train Loss 0.011137182 Test MSE 0.0023677677495703587 Test RE 0.02325828086595018\n",
      "58 Train Loss 0.009678736 Test MSE 0.002237960270086418 Test RE 0.02261175371145333\n",
      "59 Train Loss 0.008761893 Test MSE 0.0021677924274404125 Test RE 0.022254452161770424\n",
      "60 Train Loss 0.008052222 Test MSE 0.0018015570631067196 Test RE 0.02028766530999012\n",
      "61 Train Loss 0.0074334587 Test MSE 0.0014989791499718833 Test RE 0.018505714439751148\n",
      "62 Train Loss 0.006977002 Test MSE 0.0013745547109737866 Test RE 0.01772103468386102\n",
      "63 Train Loss 0.006327514 Test MSE 0.0009613286617003309 Test RE 0.014819856748987845\n",
      "64 Train Loss 0.0060315137 Test MSE 0.0010423330442473498 Test RE 0.015431612642911274\n",
      "65 Train Loss 0.0058573205 Test MSE 0.001156098067411219 Test RE 0.01625194701950955\n",
      "66 Train Loss 0.0056062094 Test MSE 0.0012133799970337404 Test RE 0.01664970242383703\n",
      "67 Train Loss 0.0051822364 Test MSE 0.0012218658514666625 Test RE 0.016707821391743642\n",
      "68 Train Loss 0.0048937304 Test MSE 0.0012965185175465264 Test RE 0.017210655924167\n",
      "69 Train Loss 0.0046792515 Test MSE 0.001127891626381988 Test RE 0.016052465547358393\n",
      "70 Train Loss 0.0045433445 Test MSE 0.0011568812773365867 Test RE 0.016257451107574268\n",
      "71 Train Loss 0.0043756403 Test MSE 0.0011494187088047603 Test RE 0.01620493118646062\n",
      "72 Train Loss 0.0040097013 Test MSE 0.0010774170940453594 Test RE 0.015689170805243617\n",
      "73 Train Loss 0.0037758206 Test MSE 0.0008506575607376646 Test RE 0.013940727672666131\n",
      "74 Train Loss 0.003650614 Test MSE 0.0007766329863162316 Test RE 0.013320360436090764\n",
      "75 Train Loss 0.0035056693 Test MSE 0.0007121900697781391 Test RE 0.012755750538186717\n",
      "76 Train Loss 0.0033147067 Test MSE 0.0006850238959072048 Test RE 0.012510104024612504\n",
      "77 Train Loss 0.0032280032 Test MSE 0.0007308102393374098 Test RE 0.012921423837669244\n",
      "78 Train Loss 0.0030921162 Test MSE 0.0007082897134651824 Test RE 0.012720773725875835\n",
      "79 Train Loss 0.002945431 Test MSE 0.0007548770942526317 Test RE 0.013132462943868719\n",
      "80 Train Loss 0.0028395213 Test MSE 0.0006653816017073089 Test RE 0.012329442919805944\n",
      "81 Train Loss 0.0026859394 Test MSE 0.0006763506587301813 Test RE 0.012430655163848132\n",
      "82 Train Loss 0.0025697765 Test MSE 0.0005984659774201851 Test RE 0.011693049636786667\n",
      "83 Train Loss 0.002445858 Test MSE 0.0005178834817524224 Test RE 0.010877374715644487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 Train Loss 0.0023409708 Test MSE 0.000495368331562146 Test RE 0.010638298691139813\n",
      "85 Train Loss 0.0022501647 Test MSE 0.0005339010410003808 Test RE 0.011044306334462935\n",
      "86 Train Loss 0.002114267 Test MSE 0.0004548080780598368 Test RE 0.01019347225499088\n",
      "87 Train Loss 0.002007878 Test MSE 0.00045093098643352584 Test RE 0.010149931237641827\n",
      "88 Train Loss 0.0019103949 Test MSE 0.00044171031730257863 Test RE 0.010045621992073022\n",
      "89 Train Loss 0.0018284504 Test MSE 0.00045183023447033043 Test RE 0.01016004670998629\n",
      "90 Train Loss 0.0017630694 Test MSE 0.00045385035726542303 Test RE 0.01018273404954964\n",
      "91 Train Loss 0.0017400752 Test MSE 0.000445462300197397 Test RE 0.010088196615836207\n",
      "92 Train Loss 0.0016238734 Test MSE 0.00040349735048538166 Test RE 0.009601263835545335\n",
      "93 Train Loss 0.0015590304 Test MSE 0.0003960613095781629 Test RE 0.009512381724186107\n",
      "94 Train Loss 0.0015009227 Test MSE 0.0003912786243977146 Test RE 0.009454773336533646\n",
      "95 Train Loss 0.0014218951 Test MSE 0.0003385221257327992 Test RE 0.008794306344706704\n",
      "96 Train Loss 0.0012794823 Test MSE 0.0003300872148930845 Test RE 0.008684051932201588\n",
      "97 Train Loss 0.0011900134 Test MSE 0.00030885538167618666 Test RE 0.008400123029443717\n",
      "98 Train Loss 0.0011071704 Test MSE 0.00028367408823463784 Test RE 0.00805040805286149\n",
      "99 Train Loss 0.0010757145 Test MSE 0.00026931083830754045 Test RE 0.007843952880815762\n",
      "Training time: 83.69\n",
      "8\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 55.27556 Test MSE 9.175230652152452 Test RE 1.447826613995341\n",
      "1 Train Loss 34.995922 Test MSE 8.038205813603826 Test RE 1.3551507856377352\n",
      "2 Train Loss 30.151932 Test MSE 7.653719530727934 Test RE 1.322343643901514\n",
      "3 Train Loss 25.495478 Test MSE 7.0670195707386565 Test RE 1.2706507796860025\n",
      "4 Train Loss 23.204115 Test MSE 7.040639681240845 Test RE 1.2682770091028996\n",
      "5 Train Loss 20.416044 Test MSE 7.327581267602943 Test RE 1.2938632634412388\n",
      "6 Train Loss 18.18329 Test MSE 7.345403706732123 Test RE 1.2954358010696185\n",
      "7 Train Loss 14.906673 Test MSE 6.799948988264562 Test RE 1.2464098936456192\n",
      "8 Train Loss 13.1518135 Test MSE 6.541581792274405 Test RE 1.2225016339244044\n",
      "9 Train Loss 11.541665 Test MSE 6.120232454619982 Test RE 1.1824751400601938\n",
      "10 Train Loss 10.468933 Test MSE 5.85193798662828 Test RE 1.1562664326211787\n",
      "11 Train Loss 9.754648 Test MSE 5.747170859827826 Test RE 1.1458693806887976\n",
      "12 Train Loss 8.950275 Test MSE 5.568420418702599 Test RE 1.1279090178327629\n",
      "13 Train Loss 8.32124 Test MSE 5.362499671636416 Test RE 1.1068574679268044\n",
      "14 Train Loss 7.884639 Test MSE 5.248379010257648 Test RE 1.095016479748994\n",
      "15 Train Loss 7.611416 Test MSE 5.0871267562991065 Test RE 1.078063493687802\n",
      "16 Train Loss 7.2844057 Test MSE 4.947062060635591 Test RE 1.0631186564946624\n",
      "17 Train Loss 7.032565 Test MSE 4.954325338926621 Test RE 1.0638988058421088\n",
      "18 Train Loss 6.83434 Test MSE 4.802749157386792 Test RE 1.047497541932227\n",
      "19 Train Loss 6.4959345 Test MSE 4.66585938825208 Test RE 1.0324615418347916\n",
      "20 Train Loss 6.2640324 Test MSE 4.579367194113044 Test RE 1.0228472799298043\n",
      "21 Train Loss 6.061364 Test MSE 4.429308267654265 Test RE 1.0059491170953507\n",
      "22 Train Loss 5.671137 Test MSE 4.171323406634884 Test RE 0.9762139097548366\n",
      "23 Train Loss 5.191595 Test MSE 3.6647660962374546 Test RE 0.9150212726717148\n",
      "24 Train Loss 3.7598183 Test MSE 2.8789672945099722 Test RE 0.8110104046346115\n",
      "25 Train Loss 3.1065228 Test MSE 2.8399147748948077 Test RE 0.8054910400485729\n",
      "26 Train Loss 2.6812954 Test MSE 2.79577712924735 Test RE 0.7992071014240998\n",
      "27 Train Loss 2.19729 Test MSE 2.9991619174355963 Test RE 0.8277668246973569\n",
      "28 Train Loss 2.0104878 Test MSE 3.0693203046222775 Test RE 0.8373926920702234\n",
      "29 Train Loss 1.8791945 Test MSE 2.996400126837445 Test RE 0.8273856106724461\n",
      "30 Train Loss 1.6895977 Test MSE 2.9975580693867725 Test RE 0.8275454645672659\n",
      "31 Train Loss 1.5580236 Test MSE 2.951171514775919 Test RE 0.8211174571980501\n",
      "32 Train Loss 1.4579672 Test MSE 2.8483298617159796 Test RE 0.8066835517503752\n",
      "33 Train Loss 1.3659097 Test MSE 2.876406331986761 Test RE 0.8106496104447728\n",
      "34 Train Loss 1.2719139 Test MSE 2.7517054541842487 Test RE 0.7928828653597052\n",
      "35 Train Loss 1.1963902 Test MSE 2.7203830264218 Test RE 0.7883572910338115\n",
      "36 Train Loss 1.1212432 Test MSE 2.6584087128263145 Test RE 0.7793255883928126\n",
      "37 Train Loss 1.0752718 Test MSE 2.6552148911801026 Test RE 0.778857305439838\n",
      "38 Train Loss 1.0365913 Test MSE 2.66156173503648 Test RE 0.7797876134203342\n",
      "39 Train Loss 0.9914384 Test MSE 2.637414458944548 Test RE 0.7762422043349052\n",
      "40 Train Loss 0.96471494 Test MSE 2.646937626493934 Test RE 0.7776423679604567\n",
      "41 Train Loss 0.93985164 Test MSE 2.61646228600344 Test RE 0.7731527409257478\n",
      "42 Train Loss 0.9184605 Test MSE 2.635249134585723 Test RE 0.7759234904372795\n",
      "43 Train Loss 0.8986884 Test MSE 2.6219032107398785 Test RE 0.7739562077346492\n",
      "44 Train Loss 0.88744843 Test MSE 2.615821693902813 Test RE 0.7730580891015028\n",
      "45 Train Loss 0.87014663 Test MSE 2.5985991728410807 Test RE 0.7705089863681258\n",
      "46 Train Loss 0.84346694 Test MSE 2.594780103073036 Test RE 0.7699425832131355\n",
      "47 Train Loss 0.8234736 Test MSE 2.5914200682828965 Test RE 0.7694439143843905\n",
      "48 Train Loss 0.8093035 Test MSE 2.5925847579259695 Test RE 0.7696168046653848\n",
      "49 Train Loss 0.79277235 Test MSE 2.6074018133246133 Test RE 0.7718129157136907\n",
      "50 Train Loss 0.7767736 Test MSE 2.61221319252012 Test RE 0.7725246919085078\n",
      "51 Train Loss 0.7594332 Test MSE 2.6106560120794664 Test RE 0.7722944006610614\n",
      "52 Train Loss 0.74428356 Test MSE 2.6157547758970074 Test RE 0.7730482008440829\n",
      "53 Train Loss 0.73242265 Test MSE 2.6015925476754362 Test RE 0.7709526404747559\n",
      "54 Train Loss 0.7183446 Test MSE 2.6110787774668918 Test RE 0.7723569301790959\n",
      "55 Train Loss 0.7073631 Test MSE 2.629378204520689 Test RE 0.7750586893645572\n",
      "56 Train Loss 0.69582236 Test MSE 2.6400297132244948 Test RE 0.7766269689926242\n",
      "57 Train Loss 0.6869932 Test MSE 2.661091250884631 Test RE 0.7797186888630407\n",
      "58 Train Loss 0.67526776 Test MSE 2.659563788760746 Test RE 0.7794948781012158\n",
      "59 Train Loss 0.66719997 Test MSE 2.649522215396594 Test RE 0.7780219378109183\n",
      "60 Train Loss 0.6613079 Test MSE 2.64810262606478 Test RE 0.7778134814300915\n",
      "61 Train Loss 0.6543813 Test MSE 2.647637217538487 Test RE 0.7777451274075676\n",
      "62 Train Loss 0.65020394 Test MSE 2.6609153601744704 Test RE 0.7796929198218306\n",
      "63 Train Loss 0.6449448 Test MSE 2.6472000038728716 Test RE 0.7776809088592317\n",
      "64 Train Loss 0.6392527 Test MSE 2.655364488479039 Test RE 0.7788792459065859\n",
      "65 Train Loss 0.63291967 Test MSE 2.667957032234889 Test RE 0.7807239023193078\n",
      "66 Train Loss 0.6278844 Test MSE 2.666232313935884 Test RE 0.7804715094822063\n",
      "67 Train Loss 0.6226629 Test MSE 2.6695407140394396 Test RE 0.780955584238383\n",
      "68 Train Loss 0.61794233 Test MSE 2.678905703156525 Test RE 0.7823242162108766\n",
      "69 Train Loss 0.61395097 Test MSE 2.69281757579454 Test RE 0.7843529366447564\n",
      "70 Train Loss 0.6089267 Test MSE 2.6908920665431797 Test RE 0.7840724592502577\n",
      "71 Train Loss 0.6046063 Test MSE 2.693711345884545 Test RE 0.784483092701578\n",
      "72 Train Loss 0.60122466 Test MSE 2.7017504588631196 Test RE 0.7856528264062917\n",
      "73 Train Loss 0.5973497 Test MSE 2.700885871705378 Test RE 0.7855271079681682\n",
      "74 Train Loss 0.5936918 Test MSE 2.7139635969222717 Test RE 0.7874265777685172\n",
      "75 Train Loss 0.5896542 Test MSE 2.7242005367751365 Test RE 0.7889102475481774\n",
      "76 Train Loss 0.58659726 Test MSE 2.726174103545595 Test RE 0.7891959616763247\n",
      "77 Train Loss 0.582409 Test MSE 2.742715218451062 Test RE 0.7915865718889256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Train Loss 0.5783821 Test MSE 2.747556533714556 Test RE 0.7922849000381682\n",
      "79 Train Loss 0.5744821 Test MSE 2.760509518151848 Test RE 0.794150264234088\n",
      "80 Train Loss 0.5696345 Test MSE 2.7893467093197963 Test RE 0.7982874652086206\n",
      "81 Train Loss 0.5648936 Test MSE 2.802272158788663 Test RE 0.8001349047121629\n",
      "82 Train Loss 0.56114304 Test MSE 2.801222638315662 Test RE 0.7999850554901128\n",
      "83 Train Loss 0.5544625 Test MSE 2.808988609019134 Test RE 0.8010932074198646\n",
      "84 Train Loss 0.5472499 Test MSE 2.824892198507465 Test RE 0.803357772596534\n",
      "85 Train Loss 0.5424261 Test MSE 2.8189889624931785 Test RE 0.8025179368837481\n",
      "86 Train Loss 0.5365697 Test MSE 2.829170327049239 Test RE 0.8039658608574322\n",
      "87 Train Loss 0.53280693 Test MSE 2.814849483525086 Test RE 0.8019285009915905\n",
      "88 Train Loss 0.527972 Test MSE 2.8214765038968466 Test RE 0.802871939049295\n",
      "89 Train Loss 0.5241538 Test MSE 2.81652159528746 Test RE 0.8021666513810634\n",
      "90 Train Loss 0.5196086 Test MSE 2.8326867076245876 Test RE 0.8044653309703728\n",
      "91 Train Loss 0.51582134 Test MSE 2.8489005380631314 Test RE 0.8067643591337705\n",
      "92 Train Loss 0.51134413 Test MSE 2.8567295419121583 Test RE 0.8078721247109072\n",
      "93 Train Loss 0.50806266 Test MSE 2.8700993560509276 Test RE 0.8097603839762484\n",
      "94 Train Loss 0.5050769 Test MSE 2.8815598357957293 Test RE 0.8113754842980109\n",
      "95 Train Loss 0.5025557 Test MSE 2.8916975982451913 Test RE 0.8128015018749727\n",
      "96 Train Loss 0.4995179 Test MSE 2.896252422420582 Test RE 0.8134413874603493\n",
      "97 Train Loss 0.49661773 Test MSE 2.904384937802282 Test RE 0.8145826359211545\n",
      "98 Train Loss 0.49375677 Test MSE 2.904006244243999 Test RE 0.8145295287643012\n",
      "99 Train Loss 0.49173844 Test MSE 2.918825963428402 Test RE 0.8166052367239235\n",
      "Training time: 82.28\n",
      "9\n",
      "KG_rowdy_tune9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 55.638763 Test MSE 8.863745562723139 Test RE 1.423038666383229\n",
      "1 Train Loss 47.649685 Test MSE 9.306597460956143 Test RE 1.458154441882191\n",
      "2 Train Loss 39.86869 Test MSE 8.95363620551979 Test RE 1.430236254450271\n",
      "3 Train Loss 37.86986 Test MSE 9.61328961230518 Test RE 1.481985905776854\n",
      "4 Train Loss 34.297043 Test MSE 8.997002116115144 Test RE 1.4336956633717588\n",
      "5 Train Loss 30.791016 Test MSE 9.158491405202435 Test RE 1.4465053070962852\n",
      "6 Train Loss 27.986347 Test MSE 8.454974976991481 Test RE 1.3898381340852721\n",
      "7 Train Loss 26.736454 Test MSE 8.232695095255831 Test RE 1.3714471486936681\n",
      "8 Train Loss 25.414509 Test MSE 8.279136530099347 Test RE 1.3753099422239794\n",
      "9 Train Loss 24.078484 Test MSE 8.246273666043443 Test RE 1.3725776788326531\n",
      "10 Train Loss 22.709305 Test MSE 8.29318438711732 Test RE 1.3764762455452542\n",
      "11 Train Loss 21.710068 Test MSE 8.316130491104223 Test RE 1.3783791906677318\n",
      "12 Train Loss 20.515938 Test MSE 8.297604459681477 Test RE 1.3768430114427803\n",
      "13 Train Loss 19.541683 Test MSE 8.17074645424832 Test RE 1.366277534506589\n",
      "14 Train Loss 18.421444 Test MSE 7.784078821995354 Test RE 1.3335572744150934\n",
      "15 Train Loss 15.462973 Test MSE 6.771808501038897 Test RE 1.243828187176267\n",
      "16 Train Loss 13.4421215 Test MSE 6.643928544093727 Test RE 1.2320278828470752\n",
      "17 Train Loss 11.795617 Test MSE 6.577227784922873 Test RE 1.2258278998150716\n",
      "18 Train Loss 10.746609 Test MSE 6.595734964054824 Test RE 1.2275513219489806\n",
      "19 Train Loss 9.555931 Test MSE 6.446993680537032 Test RE 1.2136310596606474\n",
      "20 Train Loss 8.805458 Test MSE 6.457013795811535 Test RE 1.214573824788635\n",
      "21 Train Loss 8.066273 Test MSE 6.251134173389498 Test RE 1.1950538369142392\n",
      "22 Train Loss 7.4513025 Test MSE 5.866074086014666 Test RE 1.1576621444550816\n",
      "23 Train Loss 6.989606 Test MSE 6.0581385706616295 Test RE 1.1764613439628053\n",
      "24 Train Loss 6.580198 Test MSE 5.8884609300590975 Test RE 1.1598690482737366\n",
      "25 Train Loss 6.0930767 Test MSE 5.773980611311227 Test RE 1.1485389315613328\n",
      "26 Train Loss 5.675287 Test MSE 5.733819081292024 Test RE 1.144537569718867\n",
      "27 Train Loss 5.1288595 Test MSE 5.5204027283374595 Test RE 1.1230353871182077\n",
      "28 Train Loss 4.039421 Test MSE 5.0071169066152725 Test RE 1.0695520538112384\n",
      "29 Train Loss 3.3759475 Test MSE 4.915036076982548 Test RE 1.0596718932537417\n",
      "30 Train Loss 3.1159668 Test MSE 4.963559648280831 Test RE 1.0648898385662198\n",
      "31 Train Loss 2.9023445 Test MSE 5.120621916552622 Test RE 1.0816068165191126\n",
      "32 Train Loss 2.7375035 Test MSE 5.170704402741815 Test RE 1.0868832996435582\n",
      "33 Train Loss 2.575363 Test MSE 5.06589600388343 Test RE 1.0758115319581751\n",
      "34 Train Loss 2.415089 Test MSE 5.110387317202488 Test RE 1.0805253708029718\n",
      "35 Train Loss 2.3032277 Test MSE 5.078930738306946 Test RE 1.077194693872201\n",
      "36 Train Loss 2.237709 Test MSE 5.095215929207378 Test RE 1.0789202816594416\n",
      "37 Train Loss 2.166881 Test MSE 5.044876009308215 Test RE 1.073577271816862\n",
      "38 Train Loss 2.0906856 Test MSE 5.047326391102124 Test RE 1.0738379675042438\n",
      "39 Train Loss 2.0334458 Test MSE 5.0803501226891425 Test RE 1.0773452025714194\n",
      "40 Train Loss 1.9554645 Test MSE 5.063679357917688 Test RE 1.075576138830232\n",
      "41 Train Loss 1.9063452 Test MSE 5.1540975445306545 Test RE 1.085136513188132\n",
      "42 Train Loss 1.8567843 Test MSE 5.137433054906394 Test RE 1.0833808336919932\n",
      "43 Train Loss 1.8177638 Test MSE 5.15690304560353 Test RE 1.0854318061525798\n",
      "44 Train Loss 1.7885253 Test MSE 5.1668263273373105 Test RE 1.0864756370037085\n",
      "45 Train Loss 1.7576996 Test MSE 5.167263662293077 Test RE 1.0865216172331937\n",
      "46 Train Loss 1.734121 Test MSE 5.159200021253768 Test RE 1.0856735144839667\n",
      "47 Train Loss 1.7041116 Test MSE 5.155322561481021 Test RE 1.0852654622071365\n",
      "48 Train Loss 1.6872323 Test MSE 5.198538458718901 Test RE 1.089804735980569\n",
      "49 Train Loss 1.6525816 Test MSE 5.241352892143151 Test RE 1.0942832731942114\n",
      "50 Train Loss 1.630737 Test MSE 5.257394918513892 Test RE 1.0959566111543746\n",
      "51 Train Loss 1.6124368 Test MSE 5.271904502925513 Test RE 1.0974679032155417\n",
      "52 Train Loss 1.5973189 Test MSE 5.257288946218846 Test RE 1.0959455656057315\n",
      "53 Train Loss 1.5806357 Test MSE 5.2646287967726835 Test RE 1.0967103391483428\n",
      "54 Train Loss 1.5571395 Test MSE 5.2916768946228245 Test RE 1.0995240156829345\n",
      "55 Train Loss 1.5354133 Test MSE 5.309215242600778 Test RE 1.1013445995328903\n",
      "56 Train Loss 1.5233784 Test MSE 5.335130699031867 Test RE 1.1040292809460583\n",
      "57 Train Loss 1.5098703 Test MSE 5.3492608224870635 Test RE 1.1054903280464123\n",
      "58 Train Loss 1.487286 Test MSE 5.342521682152702 Test RE 1.104793745599842\n",
      "59 Train Loss 1.4729096 Test MSE 5.361465306641828 Test RE 1.1067507126910436\n",
      "60 Train Loss 1.4581137 Test MSE 5.376617602130967 Test RE 1.108313530045217\n",
      "61 Train Loss 1.436903 Test MSE 5.378060139411918 Test RE 1.1084621993835475\n",
      "62 Train Loss 1.4225191 Test MSE 5.372640590665436 Test RE 1.1079035519384166\n",
      "63 Train Loss 1.4091802 Test MSE 5.35567344351276 Test RE 1.1061527529545185\n",
      "64 Train Loss 1.3964636 Test MSE 5.370544453915681 Test RE 1.1076874064631566\n",
      "65 Train Loss 1.3715434 Test MSE 5.3822799736919595 Test RE 1.1088969852992387\n",
      "66 Train Loss 1.349634 Test MSE 5.404850809094241 Test RE 1.111219657712259\n",
      "67 Train Loss 1.330479 Test MSE 5.44337984351517 Test RE 1.1151733459188073\n",
      "68 Train Loss 1.3152645 Test MSE 5.476754080265874 Test RE 1.1185867753572736\n",
      "69 Train Loss 1.3003561 Test MSE 5.496536359808487 Test RE 1.1206051470020433\n",
      "70 Train Loss 1.2835617 Test MSE 5.5008528587826 Test RE 1.121045073290754\n",
      "71 Train Loss 1.2639338 Test MSE 5.4978604025049505 Test RE 1.120740108332369\n",
      "72 Train Loss 1.2373483 Test MSE 5.530306451445033 Test RE 1.1240423107204471\n",
      "73 Train Loss 1.2210553 Test MSE 5.5456218392354595 Test RE 1.1255976713312748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 1.1931353 Test MSE 5.5745883572748935 Test RE 1.1285335170274056\n",
      "75 Train Loss 1.1739978 Test MSE 5.624778596153118 Test RE 1.1336024515120815\n",
      "76 Train Loss 1.158158 Test MSE 5.680852033354016 Test RE 1.1392388823208017\n",
      "77 Train Loss 1.1457833 Test MSE 5.712206033858781 Test RE 1.1423784241895925\n",
      "78 Train Loss 1.1264557 Test MSE 5.759018808230308 Test RE 1.1470498929708883\n",
      "79 Train Loss 1.1087319 Test MSE 5.764872203136879 Test RE 1.1476326685312777\n",
      "80 Train Loss 1.09403 Test MSE 5.821327488384982 Test RE 1.153238350471073\n",
      "81 Train Loss 1.0763516 Test MSE 5.79929366979547 Test RE 1.151053768447942\n",
      "82 Train Loss 1.0668492 Test MSE 5.808822423056477 Test RE 1.1519990219804002\n",
      "83 Train Loss 1.055091 Test MSE 5.8083113911884094 Test RE 1.1519483472379284\n",
      "84 Train Loss 1.0433418 Test MSE 5.838611037806916 Test RE 1.1549490667464961\n",
      "85 Train Loss 1.0335736 Test MSE 5.841609586588211 Test RE 1.1552456035907126\n",
      "86 Train Loss 1.0225462 Test MSE 5.850740213679544 Test RE 1.1561480944285616\n",
      "87 Train Loss 1.0091608 Test MSE 5.86588169107963 Test RE 1.157643159853448\n",
      "88 Train Loss 0.9996568 Test MSE 5.8784728054935576 Test RE 1.1588849343020309\n",
      "89 Train Loss 0.98753417 Test MSE 5.868557017691988 Test RE 1.157907120214943\n",
      "90 Train Loss 0.9820095 Test MSE 5.869635977535056 Test RE 1.1580135584639273\n",
      "91 Train Loss 0.97615635 Test MSE 5.899062704874614 Test RE 1.1609127115295328\n",
      "92 Train Loss 0.96805704 Test MSE 5.907946593734352 Test RE 1.1617865401344334\n",
      "93 Train Loss 0.9599602 Test MSE 5.897192494396802 Test RE 1.1607286718493606\n",
      "94 Train Loss 0.95396036 Test MSE 5.915679112894821 Test RE 1.1625465841677403\n",
      "95 Train Loss 0.9458814 Test MSE 5.921433463190082 Test RE 1.1631118678931804\n",
      "96 Train Loss 0.9410432 Test MSE 5.93257228174085 Test RE 1.164205319766906\n",
      "97 Train Loss 0.93690515 Test MSE 5.930860585044248 Test RE 1.164037356355173\n",
      "98 Train Loss 0.93108296 Test MSE 5.947977455071306 Test RE 1.1657158919203274\n",
      "99 Train Loss 0.9253218 Test MSE 5.966273338552413 Test RE 1.1675073770489541\n",
      "Training time: 81.11\n",
      "0\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.95688 Test MSE 8.562169607110484 Test RE 1.3986207704620472\n",
      "1 Train Loss 56.919968 Test MSE 8.452627115057524 Test RE 1.3896451486166215\n",
      "2 Train Loss 43.031746 Test MSE 8.044201377850198 Test RE 1.3556560836666822\n",
      "3 Train Loss 35.983994 Test MSE 7.2121680928475245 Test RE 1.2836333158067523\n",
      "4 Train Loss 30.750076 Test MSE 6.291177197979509 Test RE 1.198875317877703\n",
      "5 Train Loss 27.315475 Test MSE 6.111564656408574 Test RE 1.1816375013342102\n",
      "6 Train Loss 24.280811 Test MSE 6.156646345098325 Test RE 1.1859876425235385\n",
      "7 Train Loss 23.07935 Test MSE 6.0056147155010295 Test RE 1.1713503018060107\n",
      "8 Train Loss 22.190548 Test MSE 5.6817615123495155 Test RE 1.1393300721953368\n",
      "9 Train Loss 20.135046 Test MSE 6.072797192720727 Test RE 1.177883800933432\n",
      "10 Train Loss 16.724388 Test MSE 5.7943290049859835 Test RE 1.1505609653561786\n",
      "11 Train Loss 13.628717 Test MSE 5.94597290250313 Test RE 1.1655194439920813\n",
      "12 Train Loss 12.61795 Test MSE 5.983969755660199 Test RE 1.169237552548013\n",
      "13 Train Loss 11.66716 Test MSE 5.914583614426289 Test RE 1.1624389357519525\n",
      "14 Train Loss 10.565718 Test MSE 5.660825991880077 Test RE 1.1372290969258123\n",
      "15 Train Loss 9.502758 Test MSE 5.658787082622866 Test RE 1.1370242756010207\n",
      "16 Train Loss 8.526382 Test MSE 5.502313570079318 Test RE 1.1211939060764209\n",
      "17 Train Loss 7.762639 Test MSE 5.265401477188176 Test RE 1.0967908173304162\n",
      "18 Train Loss 6.9018993 Test MSE 4.741028816615973 Test RE 1.0407450591657392\n",
      "19 Train Loss 5.879529 Test MSE 4.402258204240856 Test RE 1.0028727157807853\n",
      "20 Train Loss 4.3568907 Test MSE 3.303962074273011 Test RE 0.8688115524230928\n",
      "21 Train Loss 3.302957 Test MSE 2.6643821162012755 Test RE 0.7802006633871157\n",
      "22 Train Loss 2.506031 Test MSE 2.2776838039827427 Test RE 0.7213645186428101\n",
      "23 Train Loss 1.8783922 Test MSE 1.9206455407515926 Test RE 0.6624173080182487\n",
      "24 Train Loss 1.5863732 Test MSE 1.9101677639454018 Test RE 0.6606079807933877\n",
      "25 Train Loss 1.3533418 Test MSE 1.8680217746704197 Test RE 0.6532794958537029\n",
      "26 Train Loss 1.1424656 Test MSE 1.709419453797729 Test RE 0.6249314500069614\n",
      "27 Train Loss 0.9676733 Test MSE 1.5286570207897634 Test RE 0.5909668063056223\n",
      "28 Train Loss 0.8361981 Test MSE 1.2930062853575928 Test RE 0.543511050287265\n",
      "29 Train Loss 0.66846603 Test MSE 0.8988628125421726 Test RE 0.45316333777732476\n",
      "30 Train Loss 0.46187258 Test MSE 0.6417100113352928 Test RE 0.38289303611802994\n",
      "31 Train Loss 0.33427054 Test MSE 0.45376748689330976 Test RE 0.32197692448270615\n",
      "32 Train Loss 0.25931165 Test MSE 0.37682206321758477 Test RE 0.2934108853523818\n",
      "33 Train Loss 0.2055643 Test MSE 0.34455561313878363 Test RE 0.28056773423929454\n",
      "34 Train Loss 0.16915976 Test MSE 0.2936906558547779 Test RE 0.2590318246818909\n",
      "35 Train Loss 0.14692634 Test MSE 0.2546050253847439 Test RE 0.24118014172285754\n",
      "36 Train Loss 0.11729676 Test MSE 0.18846539758702419 Test RE 0.20750275767597132\n",
      "37 Train Loss 0.09484876 Test MSE 0.14396834557909424 Test RE 0.18136002511472207\n",
      "38 Train Loss 0.07648489 Test MSE 0.12220301275553322 Test RE 0.16708944511477852\n",
      "39 Train Loss 0.06462023 Test MSE 0.10486408530633132 Test RE 0.15478235380693778\n",
      "40 Train Loss 0.056482397 Test MSE 0.0994264022666627 Test RE 0.15071584843074887\n",
      "41 Train Loss 0.05238437 Test MSE 0.10952517635058712 Test RE 0.15818490602644214\n",
      "42 Train Loss 0.046481945 Test MSE 0.10582127707447085 Test RE 0.1554871701344818\n",
      "43 Train Loss 0.04341731 Test MSE 0.10192381901817599 Test RE 0.15259696790466376\n",
      "44 Train Loss 0.039255742 Test MSE 0.09643809783698382 Test RE 0.1484336538247207\n",
      "45 Train Loss 0.037561167 Test MSE 0.09450008181904068 Test RE 0.14693462622616657\n",
      "46 Train Loss 0.036000572 Test MSE 0.09377916223218791 Test RE 0.1463730878257516\n",
      "47 Train Loss 0.03368136 Test MSE 0.0942437531080339 Test RE 0.14673521296829592\n",
      "48 Train Loss 0.032006245 Test MSE 0.09748357095374732 Test RE 0.14923606014402224\n",
      "49 Train Loss 0.03075044 Test MSE 0.09505230886482822 Test RE 0.14736331939471464\n",
      "50 Train Loss 0.029551577 Test MSE 0.09078064287159307 Test RE 0.14401399141792462\n",
      "51 Train Loss 0.028113926 Test MSE 0.08687178550049778 Test RE 0.1408793808130269\n",
      "52 Train Loss 0.027178314 Test MSE 0.08201610239105192 Test RE 0.13688555578142433\n",
      "53 Train Loss 0.025466973 Test MSE 0.08025881257739394 Test RE 0.13541114965977155\n",
      "54 Train Loss 0.024686934 Test MSE 0.07893233724268323 Test RE 0.13428748544319546\n",
      "55 Train Loss 0.023872938 Test MSE 0.07146267980753045 Test RE 0.1277755353593841\n",
      "56 Train Loss 0.023265032 Test MSE 0.06781533405509751 Test RE 0.12447209893461861\n",
      "57 Train Loss 0.022636112 Test MSE 0.06430271690473557 Test RE 0.12120561005167314\n",
      "58 Train Loss 0.021625897 Test MSE 0.05570573556053917 Test RE 0.11281270606651284\n",
      "59 Train Loss 0.020549117 Test MSE 0.04647950952709437 Test RE 0.10304782472949646\n",
      "60 Train Loss 0.019428583 Test MSE 0.03936501604128363 Test RE 0.09483382697318811\n",
      "61 Train Loss 0.018204534 Test MSE 0.028524141359581843 Test RE 0.08072617039954982\n",
      "62 Train Loss 0.016909033 Test MSE 0.022006462482040894 Test RE 0.07090603131696074\n",
      "63 Train Loss 0.01544581 Test MSE 0.018371275502698105 Test RE 0.06478548514350423\n",
      "64 Train Loss 0.014097846 Test MSE 0.015637791137884566 Test RE 0.05977172152606803\n",
      "65 Train Loss 0.013186624 Test MSE 0.012860900611702206 Test RE 0.05420554949131812\n",
      "66 Train Loss 0.012387754 Test MSE 0.011312122994881919 Test RE 0.05083702405898638\n",
      "67 Train Loss 0.011452602 Test MSE 0.010491412145554057 Test RE 0.04895815403508193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Train Loss 0.010391797 Test MSE 0.00987168603013066 Test RE 0.04749017034148246\n",
      "69 Train Loss 0.009624213 Test MSE 0.009092923727967746 Test RE 0.045578479645054674\n",
      "70 Train Loss 0.008352858 Test MSE 0.006705376748587148 Test RE 0.03913989464962002\n",
      "71 Train Loss 0.007547443 Test MSE 0.005684068276749891 Test RE 0.03603609335126984\n",
      "72 Train Loss 0.006965234 Test MSE 0.0054086751342180715 Test RE 0.035152280793289886\n",
      "73 Train Loss 0.006505676 Test MSE 0.005085425018099402 Test RE 0.034085658450270354\n",
      "74 Train Loss 0.006158477 Test MSE 0.004947711163336647 Test RE 0.03362096925760987\n",
      "75 Train Loss 0.005813996 Test MSE 0.00459000411099008 Test RE 0.03238281490810461\n",
      "76 Train Loss 0.0054115653 Test MSE 0.004534983461229088 Test RE 0.03218814240629489\n",
      "77 Train Loss 0.005003284 Test MSE 0.004738552823688445 Test RE 0.03290265346573532\n",
      "78 Train Loss 0.004570201 Test MSE 0.004456245899411009 Test RE 0.03190748943154603\n",
      "79 Train Loss 0.004317411 Test MSE 0.00416729789654061 Test RE 0.030855695049161004\n",
      "80 Train Loss 0.0041281395 Test MSE 0.0038592649415354198 Test RE 0.029693429310668495\n",
      "81 Train Loss 0.0039345073 Test MSE 0.0035620199595660924 Test RE 0.0285270087034021\n",
      "82 Train Loss 0.0036957539 Test MSE 0.003498579053181957 Test RE 0.028271829045608852\n",
      "83 Train Loss 0.0034427925 Test MSE 0.0032527987911062394 Test RE 0.027260678455626176\n",
      "84 Train Loss 0.0032798497 Test MSE 0.0031171987045178237 Test RE 0.026686419201249492\n",
      "85 Train Loss 0.0029949145 Test MSE 0.003360700548104904 Test RE 0.02770913500798603\n",
      "86 Train Loss 0.0028740633 Test MSE 0.0032614350667122633 Test RE 0.027296843414743022\n",
      "87 Train Loss 0.0027021868 Test MSE 0.0028273904918026736 Test RE 0.02541563453259974\n",
      "88 Train Loss 0.0024840941 Test MSE 0.002669479959150211 Test RE 0.024695702952153804\n",
      "89 Train Loss 0.0022763493 Test MSE 0.0023884444468137305 Test RE 0.02335961240665753\n",
      "90 Train Loss 0.0021145856 Test MSE 0.0020690005771574964 Test RE 0.0217414430474165\n",
      "91 Train Loss 0.0019347771 Test MSE 0.0019246590117803482 Test RE 0.020969349539543908\n",
      "92 Train Loss 0.001843428 Test MSE 0.0017971731773696357 Test RE 0.02026296640369947\n",
      "93 Train Loss 0.0017785799 Test MSE 0.0017443509571395469 Test RE 0.019962962649926277\n",
      "94 Train Loss 0.0016905793 Test MSE 0.0015695337933133283 Test RE 0.018936224584369846\n",
      "95 Train Loss 0.001607464 Test MSE 0.001318291270597988 Test RE 0.017354565642199088\n",
      "96 Train Loss 0.0015281789 Test MSE 0.0012255882380148302 Test RE 0.01673325203708446\n",
      "97 Train Loss 0.001421197 Test MSE 0.0010315035256404641 Test RE 0.015351238486006315\n",
      "98 Train Loss 0.0013501296 Test MSE 0.0009429039974936526 Test RE 0.014677152231440404\n",
      "99 Train Loss 0.0012687416 Test MSE 0.0008920141152806509 Test RE 0.014275585308472144\n",
      "Training time: 66.26\n",
      "1\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.500175 Test MSE 8.619777512916535 Test RE 1.40331797607816\n",
      "1 Train Loss 55.785645 Test MSE 8.624576140244471 Test RE 1.4037085350593272\n",
      "2 Train Loss 48.0277 Test MSE 8.899785828808396 Test RE 1.4259287913433845\n",
      "3 Train Loss 44.72844 Test MSE 8.530418895672238 Test RE 1.3960251404198734\n",
      "4 Train Loss 43.77732 Test MSE 8.284335993948277 Test RE 1.375741735559489\n",
      "5 Train Loss 43.54209 Test MSE 8.451905253730045 Test RE 1.3895858089287338\n",
      "6 Train Loss 43.059177 Test MSE 8.388698743833807 Test RE 1.384380136866797\n",
      "7 Train Loss 42.79323 Test MSE 8.373595700114565 Test RE 1.3831333539198722\n",
      "8 Train Loss 42.198364 Test MSE 8.176490239200625 Test RE 1.36675767580796\n",
      "9 Train Loss 41.21186 Test MSE 7.987208761821194 Test RE 1.3508451820227025\n",
      "10 Train Loss 39.15766 Test MSE 7.271405879555173 Test RE 1.2888941537442022\n",
      "11 Train Loss 36.263546 Test MSE 7.30967088329929 Test RE 1.2922810383360892\n",
      "12 Train Loss 34.641556 Test MSE 7.140616277915021 Test RE 1.2772499903789798\n",
      "13 Train Loss 34.31473 Test MSE 7.141472200701462 Test RE 1.2773265380164485\n",
      "14 Train Loss 34.119057 Test MSE 7.154476055197067 Test RE 1.2784889463770752\n",
      "15 Train Loss 33.94674 Test MSE 7.1609612016967015 Test RE 1.2790682557509458\n",
      "16 Train Loss 33.82025 Test MSE 7.143776970465536 Test RE 1.2775326374042417\n",
      "17 Train Loss 33.720108 Test MSE 7.087768211524172 Test RE 1.2725147163444672\n",
      "18 Train Loss 33.60624 Test MSE 7.152802444598339 Test RE 1.278339402386639\n",
      "19 Train Loss 33.475346 Test MSE 7.13158928643653 Test RE 1.276442401052381\n",
      "20 Train Loss 33.37766 Test MSE 7.13400672478341 Test RE 1.276658724457436\n",
      "21 Train Loss 33.210728 Test MSE 7.20530165742985 Test RE 1.2830221206699282\n",
      "22 Train Loss 33.065144 Test MSE 7.126206144647666 Test RE 1.2759605612194171\n",
      "23 Train Loss 32.863556 Test MSE 7.171910122026147 Test RE 1.2800457130382217\n",
      "24 Train Loss 32.627712 Test MSE 7.105742769498539 Test RE 1.2741272413188032\n",
      "25 Train Loss 32.54348 Test MSE 7.083378400243394 Test RE 1.272120589131496\n",
      "26 Train Loss 32.338924 Test MSE 7.147446720527961 Test RE 1.2778607288022388\n",
      "27 Train Loss 32.237743 Test MSE 7.247644230950481 Test RE 1.2867864931546658\n",
      "28 Train Loss 32.170002 Test MSE 7.242368910335121 Test RE 1.2863181032353386\n",
      "29 Train Loss 32.003643 Test MSE 7.271697192146209 Test RE 1.2889199718144073\n",
      "30 Train Loss 31.920843 Test MSE 7.248591146027415 Test RE 1.286870550656385\n",
      "31 Train Loss 31.824915 Test MSE 7.207874482500089 Test RE 1.2832511670730349\n",
      "32 Train Loss 31.723778 Test MSE 7.190327893870418 Test RE 1.2816882652394426\n",
      "33 Train Loss 31.623287 Test MSE 7.229459606600706 Test RE 1.2851711803438617\n",
      "34 Train Loss 31.562586 Test MSE 7.247546249319475 Test RE 1.2867777950272838\n",
      "35 Train Loss 31.507616 Test MSE 7.247538325138858 Test RE 1.2867770915711\n",
      "36 Train Loss 31.404285 Test MSE 7.22715215521652 Test RE 1.2849660677322035\n",
      "37 Train Loss 31.294815 Test MSE 7.252475706193087 Test RE 1.2872153250008136\n",
      "38 Train Loss 31.214478 Test MSE 7.220594763252847 Test RE 1.2843829930892834\n",
      "39 Train Loss 31.0806 Test MSE 7.280525684146215 Test RE 1.2897021666450075\n",
      "40 Train Loss 30.893692 Test MSE 7.259731900905834 Test RE 1.2878591017132819\n",
      "41 Train Loss 30.774204 Test MSE 7.3013755908567655 Test RE 1.291547565355422\n",
      "42 Train Loss 30.549944 Test MSE 7.1317822640164374 Test RE 1.276459670912521\n",
      "43 Train Loss 30.01027 Test MSE 7.218704699200867 Test RE 1.2842148819374573\n",
      "44 Train Loss 29.462269 Test MSE 7.263153046748216 Test RE 1.2881625175224194\n",
      "45 Train Loss 28.97969 Test MSE 7.22216084255177 Test RE 1.284522270851657\n",
      "46 Train Loss 27.88338 Test MSE 7.072382062653229 Test RE 1.271132776541754\n",
      "47 Train Loss 27.23037 Test MSE 6.9404696432915065 Test RE 1.259222542490361\n",
      "48 Train Loss 26.477983 Test MSE 6.860104924638327 Test RE 1.251910953874217\n",
      "49 Train Loss 25.643639 Test MSE 6.526319572148054 Test RE 1.2210746866519298\n",
      "50 Train Loss 25.020998 Test MSE 6.541526748769635 Test RE 1.222496490602941\n",
      "51 Train Loss 24.356411 Test MSE 6.668592754209922 Test RE 1.2343125887433821\n",
      "52 Train Loss 24.03143 Test MSE 6.479004889062151 Test RE 1.2166403453100327\n",
      "53 Train Loss 23.740322 Test MSE 6.206336749659459 Test RE 1.1907640881074744\n",
      "54 Train Loss 23.383148 Test MSE 6.127406412417371 Test RE 1.18316796850919\n",
      "55 Train Loss 23.069386 Test MSE 5.949013968401017 Test RE 1.165817458161514\n",
      "56 Train Loss 22.699417 Test MSE 5.850141954194479 Test RE 1.1560889827417589\n",
      "57 Train Loss 22.440125 Test MSE 5.531652368660302 Test RE 1.1241790821520175\n",
      "58 Train Loss 22.140644 Test MSE 5.373924933566708 Test RE 1.1080359675550737\n",
      "59 Train Loss 21.70315 Test MSE 5.379806334923682 Test RE 1.108642137370168\n",
      "60 Train Loss 21.357132 Test MSE 5.1857496366779445 Test RE 1.0884634069484505\n",
      "61 Train Loss 20.943972 Test MSE 4.972666747966347 Test RE 1.0658663165575515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 20.58784 Test MSE 4.972931878820871 Test RE 1.0658947309169815\n",
      "63 Train Loss 20.1128 Test MSE 4.978531462995052 Test RE 1.0664946675526232\n",
      "64 Train Loss 19.884502 Test MSE 4.994081701111181 Test RE 1.068158945089665\n",
      "65 Train Loss 19.69548 Test MSE 4.967260945259317 Test RE 1.0652868055930735\n",
      "66 Train Loss 19.428251 Test MSE 4.964157688770182 Test RE 1.0649539889042445\n",
      "67 Train Loss 19.263832 Test MSE 4.969587665302044 Test RE 1.0655362724525101\n",
      "68 Train Loss 19.044434 Test MSE 4.874377681958172 Test RE 1.055279857291\n",
      "69 Train Loss 18.830431 Test MSE 4.86689511765606 Test RE 1.0544695762091114\n",
      "70 Train Loss 18.669785 Test MSE 4.907815742167491 Test RE 1.058893262358209\n",
      "71 Train Loss 18.489613 Test MSE 4.88050999656066 Test RE 1.0559434572865547\n",
      "72 Train Loss 18.33885 Test MSE 4.870781602737491 Test RE 1.0548905183445265\n",
      "73 Train Loss 18.176985 Test MSE 4.8105531883799975 Test RE 1.0483482406594038\n",
      "74 Train Loss 18.043055 Test MSE 4.840909617798049 Test RE 1.0516507778460173\n",
      "75 Train Loss 17.902077 Test MSE 4.883566490166635 Test RE 1.0562740558582824\n",
      "76 Train Loss 17.758053 Test MSE 4.799468612478199 Test RE 1.0471397312676936\n",
      "77 Train Loss 17.535366 Test MSE 4.746463246569808 Test RE 1.0413413681639394\n",
      "78 Train Loss 17.363508 Test MSE 4.847176867787413 Test RE 1.0523313138394208\n",
      "79 Train Loss 17.201593 Test MSE 4.885144596565429 Test RE 1.0564447075948118\n",
      "80 Train Loss 17.072239 Test MSE 4.857155472180999 Test RE 1.0534139439317893\n",
      "81 Train Loss 16.848125 Test MSE 4.741140538006113 Test RE 1.0407573215674568\n",
      "82 Train Loss 16.710196 Test MSE 4.700368089990177 Test RE 1.0362725516702094\n",
      "83 Train Loss 16.529114 Test MSE 4.679155995661329 Test RE 1.0339316321216943\n",
      "84 Train Loss 16.304642 Test MSE 4.513423868162656 Test RE 1.0154560253776364\n",
      "85 Train Loss 15.792829 Test MSE 4.4096455803909755 Test RE 1.0037138173443514\n",
      "86 Train Loss 15.0195 Test MSE 4.574678188623808 Test RE 1.022323477767079\n",
      "87 Train Loss 13.812323 Test MSE 4.589932703331178 Test RE 1.0240265559815203\n",
      "88 Train Loss 12.908456 Test MSE 4.707725671318716 Test RE 1.0370832837324886\n",
      "89 Train Loss 11.552127 Test MSE 4.74647800133354 Test RE 1.0413429867094874\n",
      "90 Train Loss 10.388517 Test MSE 4.623057636304297 Test RE 1.027715044742807\n",
      "91 Train Loss 9.010722 Test MSE 4.409579389305446 Test RE 1.0037062841815114\n",
      "92 Train Loss 7.888366 Test MSE 4.406191866796183 Test RE 1.0033206770087986\n",
      "93 Train Loss 6.5732875 Test MSE 4.7126149352711835 Test RE 1.0376216815094534\n",
      "94 Train Loss 5.8034062 Test MSE 4.834147075854826 Test RE 1.0509159657421299\n",
      "95 Train Loss 5.365655 Test MSE 4.621767419494924 Test RE 1.027571625835074\n",
      "96 Train Loss 4.850973 Test MSE 4.647344993897317 Test RE 1.030411072777187\n",
      "97 Train Loss 4.5961637 Test MSE 4.878555726779459 Test RE 1.055732023951692\n",
      "98 Train Loss 4.4182477 Test MSE 4.826295959059137 Test RE 1.0500622249858982\n",
      "99 Train Loss 4.2078767 Test MSE 4.929368344492363 Test RE 1.061215772608517\n",
      "Training time: 66.87\n",
      "2\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.51838 Test MSE 8.651387575298047 Test RE 1.4058887138547036\n",
      "1 Train Loss 55.673595 Test MSE 8.849404553588933 Test RE 1.4218870047235734\n",
      "2 Train Loss 45.579536 Test MSE 7.475793402092166 Test RE 1.3068829911226554\n",
      "3 Train Loss 38.22157 Test MSE 7.7590668442071635 Test RE 1.3314130423866055\n",
      "4 Train Loss 30.806639 Test MSE 6.901065062252253 Test RE 1.2556428304395613\n",
      "5 Train Loss 27.257053 Test MSE 5.900217512987889 Test RE 1.1610263368527942\n",
      "6 Train Loss 24.190699 Test MSE 5.90796969071805 Test RE 1.1617888111213264\n",
      "7 Train Loss 22.948784 Test MSE 5.631159555164154 Test RE 1.1342452697436993\n",
      "8 Train Loss 22.08884 Test MSE 5.891400752638793 Test RE 1.1601585452897023\n",
      "9 Train Loss 21.284992 Test MSE 5.751678900176748 Test RE 1.1463186985319367\n",
      "10 Train Loss 20.050228 Test MSE 5.222230892580463 Test RE 1.0922853153547327\n",
      "11 Train Loss 18.688892 Test MSE 5.310412749256057 Test RE 1.1014687980318552\n",
      "12 Train Loss 16.645903 Test MSE 4.410834262140734 Test RE 1.0038490907900044\n",
      "13 Train Loss 10.993886 Test MSE 3.6551458208246284 Test RE 0.9138194850291812\n",
      "14 Train Loss 8.26686 Test MSE 3.295141105035172 Test RE 0.8676509940009485\n",
      "15 Train Loss 6.809701 Test MSE 3.0469218356453447 Test RE 0.8343316465441536\n",
      "16 Train Loss 6.189272 Test MSE 2.9326550507951774 Test RE 0.8185374452131817\n",
      "17 Train Loss 5.8280582 Test MSE 2.8040175731850856 Test RE 0.8003840506739065\n",
      "18 Train Loss 5.2528653 Test MSE 2.4441955984048116 Test RE 0.7472674048342822\n",
      "19 Train Loss 4.8818307 Test MSE 2.3575003487917097 Test RE 0.7338950240536573\n",
      "20 Train Loss 4.681212 Test MSE 2.307564405103987 Test RE 0.7260808387402039\n",
      "21 Train Loss 4.4816585 Test MSE 2.218624138194248 Test RE 0.7119507094682599\n",
      "22 Train Loss 4.248618 Test MSE 2.1439648588611906 Test RE 0.6998692164584629\n",
      "23 Train Loss 4.057148 Test MSE 2.142720139083104 Test RE 0.6996660257372358\n",
      "24 Train Loss 3.699238 Test MSE 2.1197513209284002 Test RE 0.6959058984558315\n",
      "25 Train Loss 3.145431 Test MSE 2.16508376549379 Test RE 0.703307764521883\n",
      "26 Train Loss 2.6890616 Test MSE 2.113137490107798 Test RE 0.694819403170054\n",
      "27 Train Loss 2.1845493 Test MSE 2.1361589204807765 Test RE 0.6985939815364302\n",
      "28 Train Loss 1.8787344 Test MSE 1.9753310493955225 Test RE 0.6717814468847162\n",
      "29 Train Loss 1.6567109 Test MSE 1.8053377998652111 Test RE 0.642225133952254\n",
      "30 Train Loss 1.477904 Test MSE 1.7126254051236172 Test RE 0.6255171931123672\n",
      "31 Train Loss 1.2405764 Test MSE 1.4824874709661366 Test RE 0.5819739911175649\n",
      "32 Train Loss 1.1441799 Test MSE 1.30040887113306 Test RE 0.5450646564338999\n",
      "33 Train Loss 1.0222644 Test MSE 1.1070723281518238 Test RE 0.5029167009869931\n",
      "34 Train Loss 0.88821745 Test MSE 0.8816413530573685 Test RE 0.44880122792327776\n",
      "35 Train Loss 0.7893668 Test MSE 0.7283784704231961 Test RE 0.40793090647499697\n",
      "36 Train Loss 0.66180253 Test MSE 0.5578854824021431 Test RE 0.3570101720395349\n",
      "37 Train Loss 0.52498853 Test MSE 0.4563139443205422 Test RE 0.3228790973895065\n",
      "38 Train Loss 0.43231377 Test MSE 0.38949723180369317 Test RE 0.2983048043850442\n",
      "39 Train Loss 0.3602627 Test MSE 0.31484002489136276 Test RE 0.26819645266995523\n",
      "40 Train Loss 0.31026638 Test MSE 0.2946980142041524 Test RE 0.2594756837134529\n",
      "41 Train Loss 0.26902974 Test MSE 0.25792977439151166 Test RE 0.24274975452659422\n",
      "42 Train Loss 0.24464 Test MSE 0.22653646505964414 Test RE 0.22749775744551096\n",
      "43 Train Loss 0.21658581 Test MSE 0.2012713682400833 Test RE 0.21443667262984795\n",
      "44 Train Loss 0.1954672 Test MSE 0.15531645657002574 Test RE 0.18837219448467146\n",
      "45 Train Loss 0.17969108 Test MSE 0.1061779219796295 Test RE 0.15574896560622115\n",
      "46 Train Loss 0.15660144 Test MSE 0.06456020730057767 Test RE 0.1214480422630301\n",
      "47 Train Loss 0.12458946 Test MSE 0.03495610808539664 Test RE 0.08936543980339842\n",
      "48 Train Loss 0.096291505 Test MSE 0.03132226548541811 Test RE 0.08459304215198997\n",
      "49 Train Loss 0.08445766 Test MSE 0.029747456462049175 Test RE 0.08243905011251586\n",
      "50 Train Loss 0.073302805 Test MSE 0.025648178762551252 Test RE 0.07654843678050803\n",
      "51 Train Loss 0.060959786 Test MSE 0.023692556400005206 Test RE 0.0735722472772665\n",
      "52 Train Loss 0.054932076 Test MSE 0.029854302309786335 Test RE 0.08258696822229167\n",
      "53 Train Loss 0.04982411 Test MSE 0.032996652494590106 Test RE 0.08682464210015518\n",
      "54 Train Loss 0.04253443 Test MSE 0.02833835911722939 Test RE 0.08046284978158887\n",
      "55 Train Loss 0.037603848 Test MSE 0.026402458433348704 Test RE 0.07766587582252324\n",
      "56 Train Loss 0.03511344 Test MSE 0.026104432797890126 Test RE 0.07722629343738495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 0.032528892 Test MSE 0.025222893234407528 Test RE 0.0759111395715833\n",
      "58 Train Loss 0.028818456 Test MSE 0.022677451447119783 Test RE 0.07197889632118534\n",
      "59 Train Loss 0.026692178 Test MSE 0.019803991308572917 Test RE 0.06726426853295615\n",
      "60 Train Loss 0.02503839 Test MSE 0.017383387856009465 Test RE 0.06301954603458268\n",
      "61 Train Loss 0.022532972 Test MSE 0.01736142992660351 Test RE 0.06297973170112897\n",
      "62 Train Loss 0.019841932 Test MSE 0.016983990042374986 Test RE 0.062291375873242606\n",
      "63 Train Loss 0.018560633 Test MSE 0.016082046358214475 Test RE 0.06061480538536849\n",
      "64 Train Loss 0.016921189 Test MSE 0.014597335688323955 Test RE 0.0577490518241305\n",
      "65 Train Loss 0.015650226 Test MSE 0.013542680509191145 Test RE 0.05562376438477728\n",
      "66 Train Loss 0.014336266 Test MSE 0.013084618162587379 Test RE 0.05467497423269407\n",
      "67 Train Loss 0.013299536 Test MSE 0.012303904618979058 Test RE 0.053018756570777155\n",
      "68 Train Loss 0.0118309995 Test MSE 0.009935240752390159 Test RE 0.047642797879363534\n",
      "69 Train Loss 0.010780635 Test MSE 0.009378557505448588 Test RE 0.04628881715176267\n",
      "70 Train Loss 0.00965729 Test MSE 0.009636910938092899 Test RE 0.046922050540466644\n",
      "71 Train Loss 0.009197748 Test MSE 0.009032162708974455 Test RE 0.045425941423745154\n",
      "72 Train Loss 0.008585527 Test MSE 0.008016986858029172 Test RE 0.042797031472166715\n",
      "73 Train Loss 0.007839934 Test MSE 0.0077095837485753075 Test RE 0.04196850755716632\n",
      "74 Train Loss 0.0074758716 Test MSE 0.00791390900612102 Test RE 0.042521011444354266\n",
      "75 Train Loss 0.007027104 Test MSE 0.00796404304614481 Test RE 0.04265548257732795\n",
      "76 Train Loss 0.0066357623 Test MSE 0.007443337241861364 Test RE 0.04123746011290791\n",
      "77 Train Loss 0.0060064243 Test MSE 0.0064258252704081035 Test RE 0.03831532523362906\n",
      "78 Train Loss 0.005612485 Test MSE 0.005688421599519132 Test RE 0.036049890398763926\n",
      "79 Train Loss 0.005128023 Test MSE 0.005418136521313562 Test RE 0.03518301327446132\n",
      "80 Train Loss 0.004942621 Test MSE 0.0055471834373968295 Test RE 0.03559953490298142\n",
      "81 Train Loss 0.0045444565 Test MSE 0.004829176537588895 Test RE 0.033215791159125006\n",
      "82 Train Loss 0.004329253 Test MSE 0.004212752522629932 Test RE 0.03102351725822259\n",
      "83 Train Loss 0.004174569 Test MSE 0.004109209155713611 Test RE 0.030639888731474576\n",
      "84 Train Loss 0.0038847611 Test MSE 0.003464708351166379 Test RE 0.028134642542954707\n",
      "85 Train Loss 0.003702002 Test MSE 0.0031012435712541443 Test RE 0.026618035429302474\n",
      "86 Train Loss 0.0035397438 Test MSE 0.0031280570540287394 Test RE 0.026732858101781456\n",
      "87 Train Loss 0.0034386169 Test MSE 0.002903017829798668 Test RE 0.02575330147713209\n",
      "88 Train Loss 0.003226938 Test MSE 0.0024277003257226824 Test RE 0.023550796434874666\n",
      "89 Train Loss 0.003049594 Test MSE 0.0022402364364136882 Test RE 0.022623249677902208\n",
      "90 Train Loss 0.0028718777 Test MSE 0.0020185526416115662 Test RE 0.021474749185428455\n",
      "91 Train Loss 0.0027547355 Test MSE 0.0019273660584716993 Test RE 0.020984091128020212\n",
      "92 Train Loss 0.0025674575 Test MSE 0.001774242242731858 Test RE 0.02013327927583949\n",
      "93 Train Loss 0.002441521 Test MSE 0.0018469320430916298 Test RE 0.020541564537210025\n",
      "94 Train Loss 0.0023620068 Test MSE 0.0018156457326796585 Test RE 0.020366838371834242\n",
      "95 Train Loss 0.002270973 Test MSE 0.0017729786202118987 Test RE 0.020126108497276585\n",
      "96 Train Loss 0.0021878318 Test MSE 0.0017557437245717756 Test RE 0.02002804795925002\n",
      "97 Train Loss 0.0021183514 Test MSE 0.001606064096531495 Test RE 0.01915532377399701\n",
      "98 Train Loss 0.002042929 Test MSE 0.0015072741936384968 Test RE 0.018556847214895526\n",
      "99 Train Loss 0.0019644639 Test MSE 0.0015907886998478198 Test RE 0.01906401227348038\n",
      "Training time: 66.51\n",
      "3\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.48794 Test MSE 8.600769993058957 Test RE 1.4017698900043087\n",
      "1 Train Loss 55.43828 Test MSE 8.897908117473984 Test RE 1.4257783594146622\n",
      "2 Train Loss 49.20825 Test MSE 7.8506941136960116 Test RE 1.339251336429186\n",
      "3 Train Loss 44.21575 Test MSE 9.051785543517086 Test RE 1.4380539796590437\n",
      "4 Train Loss 41.76561 Test MSE 8.681233488735094 Test RE 1.4083116723637799\n",
      "5 Train Loss 40.765083 Test MSE 8.637470070130938 Test RE 1.4047574306496906\n",
      "6 Train Loss 40.276024 Test MSE 8.765621219511988 Test RE 1.4151400112849395\n",
      "7 Train Loss 39.65869 Test MSE 8.932463887197509 Test RE 1.4285442413350742\n",
      "8 Train Loss 38.935677 Test MSE 8.873000676292516 Test RE 1.4237814081617925\n",
      "9 Train Loss 37.972435 Test MSE 8.685065431628837 Test RE 1.408622456224437\n",
      "10 Train Loss 35.596184 Test MSE 8.776944554031516 Test RE 1.4160537475585855\n",
      "11 Train Loss 31.175102 Test MSE 8.64488307304179 Test RE 1.4053601092979358\n",
      "12 Train Loss 29.929996 Test MSE 8.473803801601013 Test RE 1.3913848249652336\n",
      "13 Train Loss 28.418518 Test MSE 8.523390136456866 Test RE 1.3954498845751915\n",
      "14 Train Loss 26.678553 Test MSE 8.270251969476906 Test RE 1.3745718033847598\n",
      "15 Train Loss 24.16453 Test MSE 8.522719619231829 Test RE 1.395394994937859\n",
      "16 Train Loss 20.727135 Test MSE 8.221755099389966 Test RE 1.370535623751934\n",
      "17 Train Loss 17.38666 Test MSE 8.188906083794768 Test RE 1.3677949799166815\n",
      "18 Train Loss 15.4560375 Test MSE 7.3975610791401945 Test RE 1.3000269040270864\n",
      "19 Train Loss 12.794186 Test MSE 6.466971138205695 Test RE 1.2155099594251393\n",
      "20 Train Loss 9.866013 Test MSE 6.12740426464667 Test RE 1.183167761147906\n",
      "21 Train Loss 8.857813 Test MSE 6.146446345005427 Test RE 1.185004795045741\n",
      "22 Train Loss 8.219721 Test MSE 6.063782830378553 Test RE 1.1770092604031004\n",
      "23 Train Loss 7.6772003 Test MSE 6.015243402535441 Test RE 1.172288927487241\n",
      "24 Train Loss 7.404228 Test MSE 6.0495922439362975 Test RE 1.1756312233406983\n",
      "25 Train Loss 7.1970406 Test MSE 6.155877545867386 Test RE 1.1859135912623053\n",
      "26 Train Loss 6.921108 Test MSE 6.146827368973712 Test RE 1.1850415242553407\n",
      "27 Train Loss 6.509122 Test MSE 6.021021226455386 Test RE 1.1728518019088403\n",
      "28 Train Loss 5.033972 Test MSE 5.098555419346395 Test RE 1.0792737949855686\n",
      "29 Train Loss 3.5799043 Test MSE 4.878668399845111 Test RE 1.0557442152520986\n",
      "30 Train Loss 3.0472212 Test MSE 4.9510927733702434 Test RE 1.063551666366294\n",
      "31 Train Loss 2.7275724 Test MSE 5.044023946110098 Test RE 1.0734866061285433\n",
      "32 Train Loss 2.4797373 Test MSE 5.09135990928977 Test RE 1.0785119451356024\n",
      "33 Train Loss 2.252578 Test MSE 5.110291697674365 Test RE 1.0805152619987883\n",
      "34 Train Loss 2.0469313 Test MSE 5.150489410760909 Test RE 1.0847566209630477\n",
      "35 Train Loss 1.9203172 Test MSE 5.215343722727639 Test RE 1.0915648151919235\n",
      "36 Train Loss 1.7839222 Test MSE 5.146875779353288 Test RE 1.0843760165111962\n",
      "37 Train Loss 1.6625075 Test MSE 5.282761864093601 Test RE 1.098597426400402\n",
      "38 Train Loss 1.5649087 Test MSE 5.389199834825352 Test RE 1.1096095967197652\n",
      "39 Train Loss 1.4844154 Test MSE 5.443259418567899 Test RE 1.115161010252548\n",
      "40 Train Loss 1.4240456 Test MSE 5.486774191582228 Test RE 1.1196095748021104\n",
      "41 Train Loss 1.3619395 Test MSE 5.51964123346771 Test RE 1.1229579276264416\n",
      "42 Train Loss 1.3082615 Test MSE 5.603129858664207 Test RE 1.1314188348124385\n",
      "43 Train Loss 1.2562678 Test MSE 5.677717128789554 Test RE 1.138924501837413\n",
      "44 Train Loss 1.2109032 Test MSE 5.727876629534044 Test RE 1.1439443244211416\n",
      "45 Train Loss 1.1693349 Test MSE 5.763263335129965 Test RE 1.14747251595025\n",
      "46 Train Loss 1.1230524 Test MSE 5.811983022858977 Test RE 1.152312382630782\n",
      "47 Train Loss 1.089816 Test MSE 5.814632991376003 Test RE 1.152575050599054\n",
      "48 Train Loss 1.0641409 Test MSE 5.837298314240541 Test RE 1.154819223015057\n",
      "49 Train Loss 1.0386403 Test MSE 5.923825284393442 Test RE 1.1633467497655718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 1.016515 Test MSE 5.941761000523409 Test RE 1.1651065659493278\n",
      "51 Train Loss 0.99589086 Test MSE 5.951089220164474 Test RE 1.1660207820898987\n",
      "52 Train Loss 0.97658235 Test MSE 5.970099076899355 Test RE 1.1678816359619886\n",
      "53 Train Loss 0.9543133 Test MSE 5.958805437188959 Test RE 1.1667764718878608\n",
      "54 Train Loss 0.936151 Test MSE 6.008555436889623 Test RE 1.171637049581064\n",
      "55 Train Loss 0.9241506 Test MSE 6.034272165304394 Test RE 1.174141686591784\n",
      "56 Train Loss 0.9020602 Test MSE 6.042433264916592 Test RE 1.174935406967624\n",
      "57 Train Loss 0.88808334 Test MSE 6.039633340076418 Test RE 1.1746631563798162\n",
      "58 Train Loss 0.87745965 Test MSE 6.047435841282412 Test RE 1.1754216753130902\n",
      "59 Train Loss 0.8639388 Test MSE 6.094937620772781 Test RE 1.180029033529182\n",
      "60 Train Loss 0.84951425 Test MSE 6.121269831994069 Test RE 1.1825753503862764\n",
      "61 Train Loss 0.835727 Test MSE 6.1552473011294335 Test RE 1.1858528822142236\n",
      "62 Train Loss 0.8249415 Test MSE 6.1530169254785445 Test RE 1.1856380137528097\n",
      "63 Train Loss 0.8162622 Test MSE 6.157084000811275 Test RE 1.186029795752261\n",
      "64 Train Loss 0.8075049 Test MSE 6.167716680365187 Test RE 1.1870534325180198\n",
      "65 Train Loss 0.7951262 Test MSE 6.177325325452102 Test RE 1.187977724023027\n",
      "66 Train Loss 0.7874635 Test MSE 6.214307985987713 Test RE 1.1915285339093091\n",
      "67 Train Loss 0.78113115 Test MSE 6.252148062262454 Test RE 1.1951507475410084\n",
      "68 Train Loss 0.77541757 Test MSE 6.25244574044255 Test RE 1.1951791990476965\n",
      "69 Train Loss 0.7675128 Test MSE 6.275963100002669 Test RE 1.1974248065692843\n",
      "70 Train Loss 0.75821465 Test MSE 6.2817186681138475 Test RE 1.19797374866372\n",
      "71 Train Loss 0.75216997 Test MSE 6.276152196873294 Test RE 1.19744284583868\n",
      "72 Train Loss 0.745548 Test MSE 6.2832816753366965 Test RE 1.198122778352956\n",
      "73 Train Loss 0.73897463 Test MSE 6.270150202719557 Test RE 1.1968701411120444\n",
      "74 Train Loss 0.73395807 Test MSE 6.282851382365549 Test RE 1.1980817526069019\n",
      "75 Train Loss 0.7280458 Test MSE 6.30851628846628 Test RE 1.200526289042929\n",
      "76 Train Loss 0.7220958 Test MSE 6.329125448263565 Test RE 1.2024856771773926\n",
      "77 Train Loss 0.71524996 Test MSE 6.3399378248303995 Test RE 1.203512373513161\n",
      "78 Train Loss 0.70999247 Test MSE 6.3446836064595145 Test RE 1.2039627358518517\n",
      "79 Train Loss 0.7041176 Test MSE 6.380469147674471 Test RE 1.207353281371784\n",
      "80 Train Loss 0.6983026 Test MSE 6.4166714007719925 Test RE 1.2107736477389741\n",
      "81 Train Loss 0.6939287 Test MSE 6.422472935304654 Test RE 1.2113208752397286\n",
      "82 Train Loss 0.6891985 Test MSE 6.4503214237898865 Test RE 1.2139442390856015\n",
      "83 Train Loss 0.68425065 Test MSE 6.460963360644278 Test RE 1.2149452274903656\n",
      "84 Train Loss 0.68066704 Test MSE 6.466687699926602 Test RE 1.2154833220845036\n",
      "85 Train Loss 0.6754158 Test MSE 6.477449753803279 Test RE 1.216494323360712\n",
      "86 Train Loss 0.6703527 Test MSE 6.502224810761932 Test RE 1.2188185368638969\n",
      "87 Train Loss 0.666203 Test MSE 6.512326743447343 Test RE 1.2197649547980225\n",
      "88 Train Loss 0.6600095 Test MSE 6.520119041227463 Test RE 1.2204944890029035\n",
      "89 Train Loss 0.65591896 Test MSE 6.5347861420870155 Test RE 1.2218664777472041\n",
      "90 Train Loss 0.64883566 Test MSE 6.562721971939791 Test RE 1.2244753964625252\n",
      "91 Train Loss 0.6451752 Test MSE 6.585912877905969 Test RE 1.226636972980883\n",
      "92 Train Loss 0.6409126 Test MSE 6.601531524360175 Test RE 1.2280906107952925\n",
      "93 Train Loss 0.6363531 Test MSE 6.6049072062490035 Test RE 1.2284045616857768\n",
      "94 Train Loss 0.63349974 Test MSE 6.632396136382677 Test RE 1.2309581528882054\n",
      "95 Train Loss 0.629262 Test MSE 6.654536034229124 Test RE 1.2330109993426412\n",
      "96 Train Loss 0.62491024 Test MSE 6.672725447804935 Test RE 1.234694996685559\n",
      "97 Train Loss 0.62049204 Test MSE 6.69549670301427 Test RE 1.2367999543406354\n",
      "98 Train Loss 0.61755675 Test MSE 6.694595333110312 Test RE 1.2367167004889768\n",
      "99 Train Loss 0.6138376 Test MSE 6.708183130252628 Test RE 1.2379711256405983\n",
      "Training time: 66.70\n",
      "4\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.31948 Test MSE 8.47031313193051 Test RE 1.3910982142998616\n",
      "1 Train Loss 54.67343 Test MSE 7.94327338195805 Test RE 1.347124749767483\n",
      "2 Train Loss 47.09539 Test MSE 8.47293300452045 Test RE 1.3913133313951147\n",
      "3 Train Loss 44.510704 Test MSE 8.161506984287584 Test RE 1.3655048235285607\n",
      "4 Train Loss 43.643303 Test MSE 8.209747814832337 Test RE 1.369534473524539\n",
      "5 Train Loss 41.319794 Test MSE 8.022996620511957 Test RE 1.3538681294613084\n",
      "6 Train Loss 37.603615 Test MSE 7.259736176599184 Test RE 1.2878594809621209\n",
      "7 Train Loss 31.562286 Test MSE 6.281292038278245 Test RE 1.197933067120294\n",
      "8 Train Loss 24.337677 Test MSE 5.513516143833018 Test RE 1.1223346871925752\n",
      "9 Train Loss 21.993166 Test MSE 5.242314154141756 Test RE 1.0943836141484564\n",
      "10 Train Loss 16.985718 Test MSE 3.7922646736291425 Test RE 0.9308021558726579\n",
      "11 Train Loss 11.553109 Test MSE 3.7289401522195575 Test RE 0.9229980146635186\n",
      "12 Train Loss 8.768111 Test MSE 3.730056510912669 Test RE 0.9231361664851638\n",
      "13 Train Loss 5.8606186 Test MSE 3.1190372637199855 Test RE 0.8441475065253804\n",
      "14 Train Loss 4.2171283 Test MSE 2.909355038810692 Test RE 0.815279311384841\n",
      "15 Train Loss 3.0904255 Test MSE 2.5057806254681516 Test RE 0.7566230780982781\n",
      "16 Train Loss 2.315405 Test MSE 2.161606747779978 Test RE 0.702742798817777\n",
      "17 Train Loss 1.7271188 Test MSE 1.7257147291707198 Test RE 0.6279030074841345\n",
      "18 Train Loss 1.4289373 Test MSE 1.4343227981635098 Test RE 0.5724420271791749\n",
      "19 Train Loss 1.245134 Test MSE 1.249302148017229 Test RE 0.534246645115191\n",
      "20 Train Loss 1.0910252 Test MSE 1.1029013667174505 Test RE 0.5019684225440457\n",
      "21 Train Loss 0.956836 Test MSE 0.9458624515858959 Test RE 0.4648598663079305\n",
      "22 Train Loss 0.8272459 Test MSE 0.6682635545362821 Test RE 0.39073467042703475\n",
      "23 Train Loss 0.5879206 Test MSE 0.2771901316845117 Test RE 0.25165000460115344\n",
      "24 Train Loss 0.4192633 Test MSE 0.13012456120656257 Test RE 0.17242002324122083\n",
      "25 Train Loss 0.3057341 Test MSE 0.0854598741659618 Test RE 0.13972984740880143\n",
      "26 Train Loss 0.20074785 Test MSE 0.03894861436326316 Test RE 0.09433091915217603\n",
      "27 Train Loss 0.16600493 Test MSE 0.024376406738357614 Test RE 0.07462647089004565\n",
      "28 Train Loss 0.12956133 Test MSE 0.019438292505597306 Test RE 0.06664032659336283\n",
      "29 Train Loss 0.105278745 Test MSE 0.01909069721937368 Test RE 0.0660418081350727\n",
      "30 Train Loss 0.08979437 Test MSE 0.017476978393846935 Test RE 0.06318896398521745\n",
      "31 Train Loss 0.07788151 Test MSE 0.017003670599855365 Test RE 0.06232745614834808\n",
      "32 Train Loss 0.067836136 Test MSE 0.016755690331204724 Test RE 0.06187129739883597\n",
      "33 Train Loss 0.056128502 Test MSE 0.01318601350466366 Test RE 0.05488640910520291\n",
      "34 Train Loss 0.0478877 Test MSE 0.01011181205145953 Test RE 0.04806429258038552\n",
      "35 Train Loss 0.04356253 Test MSE 0.008938768796570908 Test RE 0.045190475642276476\n",
      "36 Train Loss 0.03938285 Test MSE 0.008398526857754789 Test RE 0.04380358118932744\n",
      "37 Train Loss 0.034748033 Test MSE 0.007093211333396962 Test RE 0.04025589715765741\n",
      "38 Train Loss 0.031145215 Test MSE 0.006693508409682844 Test RE 0.03910524102139133\n",
      "39 Train Loss 0.027013503 Test MSE 0.005962864548918577 Test RE 0.036909276513064325\n",
      "40 Train Loss 0.023771621 Test MSE 0.004766070022517719 Test RE 0.032998049494363045\n",
      "41 Train Loss 0.02152779 Test MSE 0.004365811214160439 Test RE 0.031582065965682235\n",
      "42 Train Loss 0.018732686 Test MSE 0.0034286272590313906 Test RE 0.02798776360862947\n",
      "43 Train Loss 0.016784176 Test MSE 0.0027629358564020936 Test RE 0.025124270556809467\n",
      "44 Train Loss 0.015290333 Test MSE 0.0028189015046791673 Test RE 0.02537745176597332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 0.014091855 Test MSE 0.0026157163381979815 Test RE 0.02444575094431101\n",
      "46 Train Loss 0.012778177 Test MSE 0.0028082589718050168 Test RE 0.02532950121445871\n",
      "47 Train Loss 0.011724675 Test MSE 0.0030264981899555004 Test RE 0.026295308448941124\n",
      "48 Train Loss 0.010695232 Test MSE 0.0026065240667286008 Test RE 0.02440275894501817\n",
      "49 Train Loss 0.0097841695 Test MSE 0.00258643768146946 Test RE 0.0243085508762211\n",
      "50 Train Loss 0.009026343 Test MSE 0.0022237813425127176 Test RE 0.022540009843562792\n",
      "51 Train Loss 0.008304669 Test MSE 0.0018724337145270109 Test RE 0.02068289305893921\n",
      "52 Train Loss 0.007858236 Test MSE 0.002083746535796677 Test RE 0.0218187821299686\n",
      "53 Train Loss 0.0070235347 Test MSE 0.0017206800882517575 Test RE 0.019827051142059064\n",
      "54 Train Loss 0.006206349 Test MSE 0.0014563510386454855 Test RE 0.01824068297044093\n",
      "55 Train Loss 0.0058352654 Test MSE 0.0015556167268756212 Test RE 0.01885208383613528\n",
      "56 Train Loss 0.005429794 Test MSE 0.0014928264201262678 Test RE 0.018467695985507297\n",
      "57 Train Loss 0.005052073 Test MSE 0.001554041599646477 Test RE 0.018842537155842668\n",
      "58 Train Loss 0.0047538923 Test MSE 0.0015512431862658986 Test RE 0.018825564325993437\n",
      "59 Train Loss 0.0045040776 Test MSE 0.0013842321075214984 Test RE 0.01778330673869685\n",
      "60 Train Loss 0.004110966 Test MSE 0.0014333707577606975 Test RE 0.01809619762136872\n",
      "61 Train Loss 0.0038702595 Test MSE 0.001337563731926939 Test RE 0.017480960941789293\n",
      "62 Train Loss 0.003610721 Test MSE 0.0011659142139600121 Test RE 0.01632079683962516\n",
      "63 Train Loss 0.0033367365 Test MSE 0.0012718531582307123 Test RE 0.017046159455213962\n",
      "64 Train Loss 0.0030921178 Test MSE 0.0013474718181402943 Test RE 0.017545587132586415\n",
      "65 Train Loss 0.0029943485 Test MSE 0.001328486645566663 Test RE 0.01742154458985156\n",
      "66 Train Loss 0.0029059146 Test MSE 0.0013323337161524093 Test RE 0.017446751264339557\n",
      "67 Train Loss 0.0028054474 Test MSE 0.0012522176113163894 Test RE 0.016914063783865823\n",
      "68 Train Loss 0.002710651 Test MSE 0.0012518732622688762 Test RE 0.01691173801310245\n",
      "69 Train Loss 0.0025933832 Test MSE 0.0012127668475128968 Test RE 0.016645495148665323\n",
      "70 Train Loss 0.0024722102 Test MSE 0.0010134785487397617 Test RE 0.0152165199842522\n",
      "71 Train Loss 0.0023660206 Test MSE 0.0009079403085496882 Test RE 0.014402461034384103\n",
      "72 Train Loss 0.0022344443 Test MSE 0.0007970895073899162 Test RE 0.013494649419698027\n",
      "73 Train Loss 0.0021488299 Test MSE 0.0007012875094265292 Test RE 0.012657738294825228\n",
      "74 Train Loss 0.0020609905 Test MSE 0.0006458770879399638 Test RE 0.012147390685559463\n",
      "75 Train Loss 0.0019531648 Test MSE 0.0006446305258259216 Test RE 0.012135662610114683\n",
      "76 Train Loss 0.0018760234 Test MSE 0.0006308794224820402 Test RE 0.012005527347402595\n",
      "77 Train Loss 0.0017828658 Test MSE 0.0005946717638396684 Test RE 0.011655924326350701\n",
      "78 Train Loss 0.0016983248 Test MSE 0.0006011176109657526 Test RE 0.011718925305042658\n",
      "79 Train Loss 0.0015958783 Test MSE 0.0006208181007747973 Test RE 0.011909409970691377\n",
      "80 Train Loss 0.0015359037 Test MSE 0.000597265808565385 Test RE 0.01168131908118458\n",
      "81 Train Loss 0.0014728587 Test MSE 0.000559348651791532 Test RE 0.011304447938606818\n",
      "82 Train Loss 0.0014208194 Test MSE 0.0005165156729095736 Test RE 0.01086300082005038\n",
      "83 Train Loss 0.0013826 Test MSE 0.0005146375180980831 Test RE 0.010843232806290475\n",
      "84 Train Loss 0.0013402419 Test MSE 0.0005036198192921854 Test RE 0.010726535309582123\n",
      "85 Train Loss 0.0012812281 Test MSE 0.0004924081888796692 Test RE 0.010606465744174535\n",
      "86 Train Loss 0.0012303451 Test MSE 0.00048323189730545323 Test RE 0.010507172373982467\n",
      "87 Train Loss 0.0011809955 Test MSE 0.00045104304190356627 Test RE 0.010151192278356551\n",
      "88 Train Loss 0.0011242792 Test MSE 0.0004410522029326397 Test RE 0.010038135600768576\n",
      "89 Train Loss 0.0010840071 Test MSE 0.0004434922462215917 Test RE 0.010065864407199964\n",
      "90 Train Loss 0.0010522865 Test MSE 0.00045330144832102535 Test RE 0.010176574436856347\n",
      "91 Train Loss 0.001029815 Test MSE 0.00045388474779838544 Test RE 0.010183119840826121\n",
      "92 Train Loss 0.0010067524 Test MSE 0.00044205055353212935 Test RE 0.01004949016822383\n",
      "93 Train Loss 0.0009731383 Test MSE 0.000425208877009797 Test RE 0.009856193510942014\n",
      "94 Train Loss 0.0009218051 Test MSE 0.000400744658659503 Test RE 0.009568457485509671\n",
      "95 Train Loss 0.00089538225 Test MSE 0.0003859641803083563 Test RE 0.00939034527158698\n",
      "96 Train Loss 0.0008730382 Test MSE 0.0003953997235684145 Test RE 0.009504433599995978\n",
      "97 Train Loss 0.00085786555 Test MSE 0.0003889759152029257 Test RE 0.009426911196005958\n",
      "98 Train Loss 0.0008424475 Test MSE 0.0003777272451720013 Test RE 0.00928960431584141\n",
      "99 Train Loss 0.0008282041 Test MSE 0.0003646658865507467 Test RE 0.009127579607165624\n",
      "Training time: 66.93\n",
      "5\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.228413 Test MSE 8.741635977677328 Test RE 1.413202571516162\n",
      "1 Train Loss 57.824112 Test MSE 8.6743391515796 Test RE 1.4077523449375118\n",
      "2 Train Loss 57.6978 Test MSE 8.640401456190569 Test RE 1.404995783836039\n",
      "3 Train Loss 57.612713 Test MSE 8.666175504675262 Test RE 1.4070897527738424\n",
      "4 Train Loss 56.130604 Test MSE 8.420190678541756 Test RE 1.3869762468381837\n",
      "5 Train Loss 53.381325 Test MSE 8.7587229716943 Test RE 1.414583067995094\n",
      "6 Train Loss 50.242928 Test MSE 9.008189194031853 Test RE 1.4345867314304617\n",
      "7 Train Loss 48.071007 Test MSE 8.759673008596426 Test RE 1.4146597840688584\n",
      "8 Train Loss 47.3956 Test MSE 8.640109427451307 Test RE 1.4049720405750115\n",
      "9 Train Loss 46.625202 Test MSE 8.68787278871597 Test RE 1.4088500991106696\n",
      "10 Train Loss 46.295105 Test MSE 8.708411986652656 Test RE 1.410514463304842\n",
      "11 Train Loss 45.980118 Test MSE 8.762722133212781 Test RE 1.4149059746896073\n",
      "12 Train Loss 45.67178 Test MSE 8.70512844513555 Test RE 1.410248518177881\n",
      "13 Train Loss 45.460793 Test MSE 8.569367989891091 Test RE 1.3992085708077016\n",
      "14 Train Loss 45.23861 Test MSE 8.587388518516175 Test RE 1.4006789964077633\n",
      "15 Train Loss 45.023285 Test MSE 8.631492890641239 Test RE 1.4042712963799555\n",
      "16 Train Loss 44.837677 Test MSE 8.614653858543804 Test RE 1.4029008432081491\n",
      "17 Train Loss 44.656044 Test MSE 8.512155956249938 Test RE 1.3945299510584062\n",
      "18 Train Loss 44.557606 Test MSE 8.532779766227542 Test RE 1.3962183083452901\n",
      "19 Train Loss 44.14665 Test MSE 8.531707335998403 Test RE 1.396130564736976\n",
      "20 Train Loss 43.885185 Test MSE 8.47332277739021 Test RE 1.3913453327075926\n",
      "21 Train Loss 43.81713 Test MSE 8.421022063456391 Test RE 1.3870447181300054\n",
      "22 Train Loss 43.45962 Test MSE 8.46763400826319 Test RE 1.3908781977053988\n",
      "23 Train Loss 43.43244 Test MSE 8.359790082042029 Test RE 1.3819926917400271\n",
      "24 Train Loss 43.26538 Test MSE 8.272724184999607 Test RE 1.3747772375022573\n",
      "25 Train Loss 43.047256 Test MSE 8.462905722224109 Test RE 1.3904898136372192\n",
      "26 Train Loss 42.84307 Test MSE 8.301057223445966 Test RE 1.377129444668219\n",
      "27 Train Loss 42.554688 Test MSE 8.090833795642343 Test RE 1.3595797899588875\n",
      "28 Train Loss 42.052036 Test MSE 8.143309096488462 Test RE 1.3639816262295394\n",
      "29 Train Loss 41.506027 Test MSE 7.884998376447487 Test RE 1.3421741322697278\n",
      "30 Train Loss 41.143364 Test MSE 7.971145469361434 Test RE 1.3494861376599478\n",
      "31 Train Loss 40.70627 Test MSE 8.039490309709668 Test RE 1.3552590570861776\n",
      "32 Train Loss 40.554085 Test MSE 7.958796765920748 Test RE 1.3484404370638952\n",
      "33 Train Loss 40.30873 Test MSE 7.990285094713451 Test RE 1.3511053010155771\n",
      "34 Train Loss 40.20159 Test MSE 8.013657380501297 Test RE 1.3530799089394672\n",
      "35 Train Loss 39.989334 Test MSE 7.965552342128291 Test RE 1.3490126064598948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Train Loss 39.843285 Test MSE 7.962631547798666 Test RE 1.3487652570317694\n",
      "37 Train Loss 39.78159 Test MSE 7.998160453579851 Test RE 1.3517709730428082\n",
      "38 Train Loss 39.65763 Test MSE 7.921212071439205 Test RE 1.3452527254775861\n",
      "39 Train Loss 39.59329 Test MSE 7.8397367684776444 Test RE 1.338316402332839\n",
      "40 Train Loss 39.318947 Test MSE 7.741386822509564 Test RE 1.3298952802228943\n",
      "41 Train Loss 39.12634 Test MSE 7.781715852941164 Test RE 1.333354848808649\n",
      "42 Train Loss 39.080215 Test MSE 7.795025378885105 Test RE 1.3344946192414373\n",
      "43 Train Loss 39.025837 Test MSE 7.809897693834927 Test RE 1.335767069662009\n",
      "44 Train Loss 38.889866 Test MSE 7.836339014171068 Test RE 1.3380263566808468\n",
      "45 Train Loss 38.79641 Test MSE 7.845797493991798 Test RE 1.3388336136608454\n",
      "46 Train Loss 38.547215 Test MSE 7.682884508950008 Test RE 1.3248606850340539\n",
      "47 Train Loss 38.480732 Test MSE 7.788784635278983 Test RE 1.3339603101189836\n",
      "48 Train Loss 38.440163 Test MSE 7.752256211282866 Test RE 1.3308285805950824\n",
      "49 Train Loss 38.393757 Test MSE 7.6833536473167765 Test RE 1.3249011342617651\n",
      "50 Train Loss 38.319313 Test MSE 7.687274118446347 Test RE 1.325239109998484\n",
      "51 Train Loss 38.21855 Test MSE 7.648320746923989 Test RE 1.3218771839796724\n",
      "52 Train Loss 38.076687 Test MSE 7.489913956808114 Test RE 1.3081166532842106\n",
      "53 Train Loss 38.010212 Test MSE 7.585081451944742 Test RE 1.3164009428432455\n",
      "54 Train Loss 37.958744 Test MSE 7.673533830840783 Test RE 1.3240542094528036\n",
      "55 Train Loss 37.879597 Test MSE 7.617002123523728 Test RE 1.3191679721808252\n",
      "56 Train Loss 37.766953 Test MSE 7.530998757924248 Test RE 1.3116994857120634\n",
      "57 Train Loss 37.643085 Test MSE 7.601637140188714 Test RE 1.317836790599558\n",
      "58 Train Loss 37.49369 Test MSE 7.57182378800141 Test RE 1.3152499971224898\n",
      "59 Train Loss 37.285507 Test MSE 7.555648706476474 Test RE 1.31384441437847\n",
      "60 Train Loss 36.941994 Test MSE 7.380679075103547 Test RE 1.2985426584167552\n",
      "61 Train Loss 35.42648 Test MSE 7.208870555409299 Test RE 1.2833398317389935\n",
      "62 Train Loss 34.319458 Test MSE 6.989366258844993 Test RE 1.2636504600969811\n",
      "63 Train Loss 33.6252 Test MSE 7.263763082463977 Test RE 1.2882166130810953\n",
      "64 Train Loss 32.99561 Test MSE 7.126919661550938 Test RE 1.276024437889688\n",
      "65 Train Loss 32.64999 Test MSE 7.102764931881025 Test RE 1.273860236042745\n",
      "66 Train Loss 32.38275 Test MSE 7.161063814869167 Test RE 1.2790774199383816\n",
      "67 Train Loss 31.99966 Test MSE 7.085057208652464 Test RE 1.2722713307759517\n",
      "68 Train Loss 31.751106 Test MSE 7.103574047473778 Test RE 1.2739327902408863\n",
      "69 Train Loss 31.568848 Test MSE 6.995776784463523 Test RE 1.264229826433758\n",
      "70 Train Loss 31.28664 Test MSE 6.777082359617131 Test RE 1.2443124372306766\n",
      "71 Train Loss 30.62121 Test MSE 6.792461074876267 Test RE 1.245723448785976\n",
      "72 Train Loss 29.759949 Test MSE 7.056952883949522 Test RE 1.2697454615607104\n",
      "73 Train Loss 27.00771 Test MSE 6.939810093674054 Test RE 1.2591627094011906\n",
      "74 Train Loss 26.20801 Test MSE 6.837275296420639 Test RE 1.2498261111584559\n",
      "75 Train Loss 24.785423 Test MSE 6.393771323444461 Test RE 1.2086111875778283\n",
      "76 Train Loss 22.149824 Test MSE 5.740294373650505 Test RE 1.14518365952866\n",
      "77 Train Loss 20.948343 Test MSE 5.692989942215052 Test RE 1.1404553018990258\n",
      "78 Train Loss 19.826574 Test MSE 5.41548293008736 Test RE 1.1123120853952215\n",
      "79 Train Loss 18.106064 Test MSE 5.591891902418328 Test RE 1.130283646312158\n",
      "80 Train Loss 16.583643 Test MSE 5.299035391568344 Test RE 1.1002882378270347\n",
      "81 Train Loss 15.444214 Test MSE 5.20153902830966 Test RE 1.0901192054464495\n",
      "82 Train Loss 14.665242 Test MSE 4.660620161606256 Test RE 1.0318817108829723\n",
      "83 Train Loss 13.77104 Test MSE 4.678443157866759 Test RE 1.033852872873508\n",
      "84 Train Loss 12.367423 Test MSE 3.937798689862277 Test RE 0.9484944966120912\n",
      "85 Train Loss 10.409706 Test MSE 2.2993145972728195 Test RE 0.724781765412752\n",
      "86 Train Loss 8.741863 Test MSE 2.3635324769152755 Test RE 0.734833331576914\n",
      "87 Train Loss 7.084501 Test MSE 2.0134392794141447 Test RE 0.6782305196978885\n",
      "88 Train Loss 6.157303 Test MSE 1.728469717345173 Test RE 0.6284040101927633\n",
      "89 Train Loss 5.4570637 Test MSE 1.8246156534305622 Test RE 0.6456449499734019\n",
      "90 Train Loss 4.983712 Test MSE 1.7768360996455392 Test RE 0.6371354134449407\n",
      "91 Train Loss 4.5448704 Test MSE 1.7469126729270401 Test RE 0.6317476833094051\n",
      "92 Train Loss 3.9597323 Test MSE 1.7201888217159857 Test RE 0.6268968979823432\n",
      "93 Train Loss 3.6117795 Test MSE 1.6981062796926174 Test RE 0.6228600758217668\n",
      "94 Train Loss 3.1281493 Test MSE 1.6900999968164767 Test RE 0.6213900012190916\n",
      "95 Train Loss 2.8922598 Test MSE 1.5497548651367503 Test RE 0.595030961959105\n",
      "96 Train Loss 2.662999 Test MSE 1.3913792530418856 Test RE 0.5638074651790886\n",
      "97 Train Loss 2.4655423 Test MSE 1.348502522848787 Test RE 0.5550523451441052\n",
      "98 Train Loss 2.3489137 Test MSE 1.3275483151420717 Test RE 0.5507230174882265\n",
      "99 Train Loss 2.2264092 Test MSE 1.4055735474641167 Test RE 0.5666760368230538\n",
      "Training time: 67.43\n",
      "6\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.01162 Test MSE 8.458975207045203 Test RE 1.3901668763254538\n",
      "1 Train Loss 58.923927 Test MSE 8.635859815285176 Test RE 1.404626482416216\n",
      "2 Train Loss 58.682262 Test MSE 8.596358584419038 Test RE 1.4014103540010925\n",
      "3 Train Loss 57.87939 Test MSE 8.20841394351875 Test RE 1.3694232120707364\n",
      "4 Train Loss 54.690365 Test MSE 8.659096945137954 Test RE 1.4065149777021093\n",
      "5 Train Loss 51.380386 Test MSE 8.952006944401825 Test RE 1.4301061210452013\n",
      "6 Train Loss 46.690506 Test MSE 8.724129289056567 Test RE 1.411786766930107\n",
      "7 Train Loss 46.032463 Test MSE 8.390363909683147 Test RE 1.3845175305324218\n",
      "8 Train Loss 45.697952 Test MSE 8.465353374525291 Test RE 1.390690878711847\n",
      "9 Train Loss 45.162903 Test MSE 8.422187240863986 Test RE 1.3871406742536019\n",
      "10 Train Loss 43.22613 Test MSE 8.343722267617718 Test RE 1.3806639333534754\n",
      "11 Train Loss 37.621204 Test MSE 7.622986621299717 Test RE 1.3196860899149974\n",
      "12 Train Loss 35.065666 Test MSE 7.12886746331998 Test RE 1.2761987960261303\n",
      "13 Train Loss 34.249535 Test MSE 7.021742318308166 Test RE 1.2665738119641237\n",
      "14 Train Loss 33.512634 Test MSE 6.921009911047356 Test RE 1.257455995332506\n",
      "15 Train Loss 32.902805 Test MSE 6.984213264360921 Test RE 1.2631845534440733\n",
      "16 Train Loss 32.366375 Test MSE 7.002334680699073 Test RE 1.26482223712996\n",
      "17 Train Loss 31.342133 Test MSE 7.019314349935804 Test RE 1.266354815958719\n",
      "18 Train Loss 30.40279 Test MSE 7.0111920313802845 Test RE 1.2656219299576865\n",
      "19 Train Loss 28.159124 Test MSE 6.743341015400567 Test RE 1.2412110168582033\n",
      "20 Train Loss 23.533812 Test MSE 6.726207380655423 Test RE 1.2396331653214827\n",
      "21 Train Loss 18.842464 Test MSE 6.726866613354739 Test RE 1.239693911790403\n",
      "22 Train Loss 15.6816225 Test MSE 6.523777666649792 Test RE 1.2208368681762216\n",
      "23 Train Loss 13.184148 Test MSE 5.900046939708661 Test RE 1.161009554293469\n",
      "24 Train Loss 11.672648 Test MSE 5.938447532986411 Test RE 1.1647816554431365\n",
      "25 Train Loss 10.159323 Test MSE 5.617441123260105 Test RE 1.132862823142337\n",
      "26 Train Loss 9.217564 Test MSE 5.475805392031616 Test RE 1.118489889861205\n",
      "27 Train Loss 7.259034 Test MSE 5.47801660797212 Test RE 1.1187156989308848\n",
      "28 Train Loss 6.1084146 Test MSE 5.467754449028364 Test RE 1.1176673432160902\n",
      "29 Train Loss 5.3179383 Test MSE 5.625155830358537 Test RE 1.1336404642483175\n",
      "30 Train Loss 4.727435 Test MSE 5.720509978565321 Test RE 1.1432084714717134\n",
      "31 Train Loss 4.1841865 Test MSE 5.7045533025249995 Test RE 1.1416129366417924\n",
      "32 Train Loss 3.6103911 Test MSE 5.880603242033487 Test RE 1.1590949129170982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 3.1821778 Test MSE 6.013563656033726 Test RE 1.172125236213033\n",
      "34 Train Loss 2.7334585 Test MSE 6.01882631793862 Test RE 1.1726380061950832\n",
      "35 Train Loss 2.3879476 Test MSE 5.8507306573138145 Test RE 1.1561471502250815\n",
      "36 Train Loss 2.077683 Test MSE 5.860718516096121 Test RE 1.157133566379918\n",
      "37 Train Loss 1.8847537 Test MSE 5.859775857041791 Test RE 1.1570405038744171\n",
      "38 Train Loss 1.6503654 Test MSE 5.800964904375169 Test RE 1.1512196112556456\n",
      "39 Train Loss 1.5274467 Test MSE 5.854798024690174 Test RE 1.1565489511694782\n",
      "40 Train Loss 1.4392622 Test MSE 5.795396094789758 Test RE 1.1506669047456115\n",
      "41 Train Loss 1.3533669 Test MSE 5.798169029083941 Test RE 1.150942152726296\n",
      "42 Train Loss 1.277118 Test MSE 5.91326293623224 Test RE 1.1623091469482216\n",
      "43 Train Loss 1.2247531 Test MSE 5.950829735059008 Test RE 1.1659953608340012\n",
      "44 Train Loss 1.1739624 Test MSE 6.025446812205381 Test RE 1.1732827589328014\n",
      "45 Train Loss 1.1303725 Test MSE 6.06075823434339 Test RE 1.176715679508208\n",
      "46 Train Loss 1.0861316 Test MSE 6.075979806126747 Test RE 1.1781924114161335\n",
      "47 Train Loss 1.041556 Test MSE 6.157596981665456 Test RE 1.1860792020869517\n",
      "48 Train Loss 1.0150924 Test MSE 6.201820859107192 Test RE 1.1903307939562768\n",
      "49 Train Loss 0.98258275 Test MSE 6.20553793639434 Test RE 1.1906874544347816\n",
      "50 Train Loss 0.9583247 Test MSE 6.2338563705597805 Test RE 1.1934011614819733\n",
      "51 Train Loss 0.9397461 Test MSE 6.2610825461755075 Test RE 1.1960043935950693\n",
      "52 Train Loss 0.9153023 Test MSE 6.2531957179709154 Test RE 1.1952508774517223\n",
      "53 Train Loss 0.8894812 Test MSE 6.270201467482407 Test RE 1.196875033908592\n",
      "54 Train Loss 0.86643714 Test MSE 6.314861210698271 Test RE 1.2011298645315758\n",
      "55 Train Loss 0.84944713 Test MSE 6.354158499702828 Test RE 1.2048613750458153\n",
      "56 Train Loss 0.83341575 Test MSE 6.3844560562334385 Test RE 1.2077304366636126\n",
      "57 Train Loss 0.8132 Test MSE 6.431934374589608 Test RE 1.2122127918874375\n",
      "58 Train Loss 0.80086184 Test MSE 6.447959690891502 Test RE 1.2137219808182045\n",
      "59 Train Loss 0.78776455 Test MSE 6.463929165453104 Test RE 1.2152240463586452\n",
      "60 Train Loss 0.768705 Test MSE 6.537305893648529 Test RE 1.2221020251061019\n",
      "61 Train Loss 0.7569811 Test MSE 6.585197502959044 Test RE 1.2265703512986574\n",
      "62 Train Loss 0.7444408 Test MSE 6.606760704998636 Test RE 1.228576909800272\n",
      "63 Train Loss 0.7345958 Test MSE 6.634586637361854 Test RE 1.2311614121916545\n",
      "64 Train Loss 0.72346747 Test MSE 6.643525730351584 Test RE 1.2319905340645714\n",
      "65 Train Loss 0.7123474 Test MSE 6.659199838399666 Test RE 1.233442999004752\n",
      "66 Train Loss 0.7010413 Test MSE 6.698536849049839 Test RE 1.237080712133584\n",
      "67 Train Loss 0.69044024 Test MSE 6.7177657363844165 Test RE 1.2388550278788888\n",
      "68 Train Loss 0.6843296 Test MSE 6.7469161844781285 Test RE 1.2415400044639642\n",
      "69 Train Loss 0.6775238 Test MSE 6.757087030126237 Test RE 1.2424754508262288\n",
      "70 Train Loss 0.6705939 Test MSE 6.7325042655827225 Test RE 1.2402132843178528\n",
      "71 Train Loss 0.66329086 Test MSE 6.7634096452647325 Test RE 1.243056607859802\n",
      "72 Train Loss 0.6561184 Test MSE 6.76641279057344 Test RE 1.2433325533894868\n",
      "73 Train Loss 0.6507458 Test MSE 6.768249341084527 Test RE 1.2435012755901667\n",
      "74 Train Loss 0.6450555 Test MSE 6.79353897836879 Test RE 1.2458222875113047\n",
      "75 Train Loss 0.6367647 Test MSE 6.819585609050181 Test RE 1.2482082625930573\n",
      "76 Train Loss 0.6297413 Test MSE 6.8559330914625 Test RE 1.2515302339013585\n",
      "77 Train Loss 0.62327987 Test MSE 6.873271842535586 Test RE 1.253111803348966\n",
      "78 Train Loss 0.6170857 Test MSE 6.882686617900943 Test RE 1.2539697447432323\n",
      "79 Train Loss 0.6102209 Test MSE 6.919301499825641 Test RE 1.2573007878882092\n",
      "80 Train Loss 0.6031403 Test MSE 6.944731648895047 Test RE 1.259609115024156\n",
      "81 Train Loss 0.59795314 Test MSE 6.952918790635106 Test RE 1.2603513727018882\n",
      "82 Train Loss 0.5936113 Test MSE 6.958436687021722 Test RE 1.2608513863836535\n",
      "83 Train Loss 0.58837235 Test MSE 6.970084912727819 Test RE 1.2619062598457256\n",
      "84 Train Loss 0.58183235 Test MSE 6.989799258543396 Test RE 1.2636896018284196\n",
      "85 Train Loss 0.5778369 Test MSE 7.006790907555861 Test RE 1.2652246342328795\n",
      "86 Train Loss 0.5742244 Test MSE 7.023899491035706 Test RE 1.2667683511930996\n",
      "87 Train Loss 0.5714162 Test MSE 7.039003134351007 Test RE 1.268129599526709\n",
      "88 Train Loss 0.5669079 Test MSE 7.04820923852129 Test RE 1.2689586031705369\n",
      "89 Train Loss 0.5633733 Test MSE 7.049141186347816 Test RE 1.2690424942755243\n",
      "90 Train Loss 0.5599469 Test MSE 7.048102443115906 Test RE 1.2689489894192132\n",
      "91 Train Loss 0.5566161 Test MSE 7.057599300039484 Test RE 1.2698036144997296\n",
      "92 Train Loss 0.5540451 Test MSE 7.077735797009402 Test RE 1.2716138039914697\n",
      "93 Train Loss 0.55198085 Test MSE 7.071993698827151 Test RE 1.2710978753753968\n",
      "94 Train Loss 0.54970074 Test MSE 7.074187746222479 Test RE 1.2712950356691337\n",
      "95 Train Loss 0.5478977 Test MSE 7.085738878552321 Test RE 1.272332533401817\n",
      "96 Train Loss 0.5463254 Test MSE 7.096371824570067 Test RE 1.2732868143786422\n",
      "97 Train Loss 0.54414815 Test MSE 7.118757012565277 Test RE 1.2752934963228688\n",
      "98 Train Loss 0.5419447 Test MSE 7.124127648454367 Test RE 1.2757744683302812\n",
      "99 Train Loss 0.53972805 Test MSE 7.133556136879989 Test RE 1.276618406576913\n",
      "Training time: 67.26\n",
      "7\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.96494 Test MSE 8.200850955795335 Test RE 1.3687921938403096\n",
      "1 Train Loss 55.678062 Test MSE 8.564551709881144 Test RE 1.398815313835412\n",
      "2 Train Loss 55.480904 Test MSE 8.559613360780089 Test RE 1.3984119748960546\n",
      "3 Train Loss 54.073395 Test MSE 7.818187959586086 Test RE 1.3364758450668968\n",
      "4 Train Loss 49.631245 Test MSE 8.162780827225468 Test RE 1.3656113829429017\n",
      "5 Train Loss 47.465847 Test MSE 7.7444693241442994 Test RE 1.3301600258344055\n",
      "6 Train Loss 46.477085 Test MSE 7.972875531531293 Test RE 1.3496325763529398\n",
      "7 Train Loss 44.02504 Test MSE 7.834945404896554 Test RE 1.3379073745357508\n",
      "8 Train Loss 43.831062 Test MSE 8.04810007780553 Test RE 1.3559845597842772\n",
      "9 Train Loss 43.757973 Test MSE 8.110439525164237 Test RE 1.361226061893387\n",
      "10 Train Loss 43.706703 Test MSE 8.066660959638874 Test RE 1.357547274872672\n",
      "11 Train Loss 43.508743 Test MSE 8.087869246104244 Test RE 1.3593306864045516\n",
      "12 Train Loss 43.245914 Test MSE 8.087196110178184 Test RE 1.35927411814584\n",
      "13 Train Loss 43.08884 Test MSE 8.055703267648223 Test RE 1.3566249204976626\n",
      "14 Train Loss 42.874573 Test MSE 7.981741667377647 Test RE 1.350382788801299\n",
      "15 Train Loss 42.45816 Test MSE 7.966181539740007 Test RE 1.3490658845448797\n",
      "16 Train Loss 41.845444 Test MSE 8.111719574935824 Test RE 1.3613334770561858\n",
      "17 Train Loss 41.331482 Test MSE 8.208895625125407 Test RE 1.369463391349027\n",
      "18 Train Loss 39.43962 Test MSE 8.050281124126103 Test RE 1.3561682841890517\n",
      "19 Train Loss 37.584644 Test MSE 7.601863207134864 Test RE 1.3178563861891879\n",
      "20 Train Loss 34.110306 Test MSE 7.399084168759188 Test RE 1.3001607289156103\n",
      "21 Train Loss 27.14578 Test MSE 6.191188234873329 Test RE 1.1893099833258391\n",
      "22 Train Loss 23.001764 Test MSE 6.248150687330752 Test RE 1.1947686205132362\n",
      "23 Train Loss 21.647392 Test MSE 5.8286406749287965 Test RE 1.1539625151962638\n",
      "24 Train Loss 19.451317 Test MSE 5.650008496581526 Test RE 1.136141989396891\n",
      "25 Train Loss 17.85683 Test MSE 5.595834702506802 Test RE 1.1306820532607682\n",
      "26 Train Loss 16.550978 Test MSE 5.610928378110098 Test RE 1.1322059238153632\n",
      "27 Train Loss 15.892251 Test MSE 5.522931242953048 Test RE 1.1232925500868287\n",
      "28 Train Loss 14.86949 Test MSE 5.084900765412791 Test RE 1.0778276019750606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Train Loss 13.725772 Test MSE 4.70589986541986 Test RE 1.0368821572718574\n",
      "30 Train Loss 13.02293 Test MSE 4.463940280812006 Test RE 1.0098741328873124\n",
      "31 Train Loss 12.511979 Test MSE 4.503594584409482 Test RE 1.0143496983553326\n",
      "32 Train Loss 11.882673 Test MSE 4.427438881331666 Test RE 1.0057368146470145\n",
      "33 Train Loss 11.386661 Test MSE 4.266941573365322 Test RE 0.9873392644680985\n",
      "34 Train Loss 10.714229 Test MSE 4.194648960156687 Test RE 0.9789395418218334\n",
      "35 Train Loss 9.94702 Test MSE 3.9057214761857297 Test RE 0.9446233902973757\n",
      "36 Train Loss 9.030373 Test MSE 3.712724474561887 Test RE 0.9209889524940479\n",
      "37 Train Loss 8.09735 Test MSE 3.5679834800769825 Test RE 0.9028580564628204\n",
      "38 Train Loss 7.3875794 Test MSE 3.490765984965913 Test RE 0.8930348926958648\n",
      "39 Train Loss 6.6268234 Test MSE 3.132030036088823 Test RE 0.8459038847309638\n",
      "40 Train Loss 5.726063 Test MSE 2.8591861219739316 Test RE 0.8082194057633701\n",
      "41 Train Loss 4.8860164 Test MSE 2.5917601848359726 Test RE 0.7694944063962504\n",
      "42 Train Loss 3.9951017 Test MSE 2.2710692907272074 Test RE 0.7203163168785811\n",
      "43 Train Loss 3.4985466 Test MSE 1.964455765008862 Test RE 0.6699296312887315\n",
      "44 Train Loss 3.190631 Test MSE 1.7830376422578138 Test RE 0.6382463152228568\n",
      "45 Train Loss 2.8305838 Test MSE 1.5712610109567196 Test RE 0.5991453972592848\n",
      "46 Train Loss 2.56931 Test MSE 1.4250879785512032 Test RE 0.5705962308818018\n",
      "47 Train Loss 2.38722 Test MSE 1.2222594430513123 Test RE 0.5284327930999251\n",
      "48 Train Loss 2.151569 Test MSE 1.1035658866307054 Test RE 0.5021196227295148\n",
      "49 Train Loss 1.9897512 Test MSE 1.0706562263318107 Test RE 0.4945760523553867\n",
      "50 Train Loss 1.7355572 Test MSE 0.9223932977730297 Test RE 0.4590564877969668\n",
      "51 Train Loss 1.525656 Test MSE 0.782953412171918 Test RE 0.4229373315457593\n",
      "52 Train Loss 1.3212321 Test MSE 0.530456858479738 Test RE 0.3481233024287591\n",
      "53 Train Loss 1.1694037 Test MSE 0.4302320595049734 Test RE 0.31351580903613036\n",
      "54 Train Loss 0.99114764 Test MSE 0.2990555346185142 Test RE 0.2613869988870153\n",
      "55 Train Loss 0.7772977 Test MSE 0.1982236297738679 Test RE 0.21280693292785416\n",
      "56 Train Loss 0.6864399 Test MSE 0.19241469659133256 Test RE 0.2096655995891059\n",
      "57 Train Loss 0.6294684 Test MSE 0.1635728264831718 Test RE 0.19331414785163778\n",
      "58 Train Loss 0.5793148 Test MSE 0.16256817840525864 Test RE 0.19271957533205963\n",
      "59 Train Loss 0.51400214 Test MSE 0.17666843773623928 Test RE 0.20090351933900805\n",
      "60 Train Loss 0.48297474 Test MSE 0.16679549528162305 Test RE 0.19520917180569886\n",
      "61 Train Loss 0.4527113 Test MSE 0.16524657264590814 Test RE 0.19430066661006248\n",
      "62 Train Loss 0.41810355 Test MSE 0.17115607089285367 Test RE 0.19774440954297534\n",
      "63 Train Loss 0.4084316 Test MSE 0.16571354863693574 Test RE 0.19457501340408045\n",
      "64 Train Loss 0.39502853 Test MSE 0.16222087338092922 Test RE 0.19251360555448985\n",
      "65 Train Loss 0.3851993 Test MSE 0.1538643585702272 Test RE 0.18748955384848923\n",
      "66 Train Loss 0.37377658 Test MSE 0.15431547416581545 Test RE 0.18776420341167144\n",
      "67 Train Loss 0.35179117 Test MSE 0.1548731944175271 Test RE 0.18810320198401376\n",
      "68 Train Loss 0.3348385 Test MSE 0.14829924664871283 Test RE 0.18406767755208137\n",
      "69 Train Loss 0.326464 Test MSE 0.1476827216826525 Test RE 0.18368466647098539\n",
      "70 Train Loss 0.31658792 Test MSE 0.14199361276920605 Test RE 0.18011192373883478\n",
      "71 Train Loss 0.3005307 Test MSE 0.13145856138902806 Test RE 0.17330157030532398\n",
      "72 Train Loss 0.29170835 Test MSE 0.1335583087388015 Test RE 0.1746801337300669\n",
      "73 Train Loss 0.28305304 Test MSE 0.130431344803743 Test RE 0.1726231535890953\n",
      "74 Train Loss 0.27359366 Test MSE 0.11304763897223581 Test RE 0.16070848554747302\n",
      "75 Train Loss 0.26010472 Test MSE 0.1118142399318857 Test RE 0.15982938128793517\n",
      "76 Train Loss 0.23694849 Test MSE 0.10481479099011533 Test RE 0.15474596962858475\n",
      "77 Train Loss 0.22455609 Test MSE 0.10226873442057459 Test RE 0.15285494779618106\n",
      "78 Train Loss 0.21641034 Test MSE 0.10603519274910665 Test RE 0.15564424795282733\n",
      "79 Train Loss 0.19620132 Test MSE 0.08771877896573888 Test RE 0.1415644966634754\n",
      "80 Train Loss 0.18235195 Test MSE 0.07233463567580996 Test RE 0.1285527020424087\n",
      "81 Train Loss 0.17314349 Test MSE 0.06519722415836862 Test RE 0.12204573664854813\n",
      "82 Train Loss 0.16656101 Test MSE 0.060092952213182574 Test RE 0.11717091744184566\n",
      "83 Train Loss 0.16227502 Test MSE 0.062413486523308415 Test RE 0.11941181023514283\n",
      "84 Train Loss 0.1546251 Test MSE 0.05813139685002125 Test RE 0.11524270396934735\n",
      "85 Train Loss 0.14562304 Test MSE 0.0505284200132352 Test RE 0.10744245408697782\n",
      "86 Train Loss 0.13728887 Test MSE 0.040261311405715754 Test RE 0.09590737814087746\n",
      "87 Train Loss 0.13357699 Test MSE 0.038298741236127275 Test RE 0.0935406342720018\n",
      "88 Train Loss 0.12648717 Test MSE 0.036677989401654044 Test RE 0.09153998156299509\n",
      "89 Train Loss 0.11950419 Test MSE 0.035803450877947084 Test RE 0.090442072162165\n",
      "90 Train Loss 0.11693215 Test MSE 0.039253104277859815 Test RE 0.09469892832939329\n",
      "91 Train Loss 0.11247742 Test MSE 0.03560870322746478 Test RE 0.09019576353349104\n",
      "92 Train Loss 0.10915747 Test MSE 0.028591323340818237 Test RE 0.08082118034911154\n",
      "93 Train Loss 0.10615064 Test MSE 0.028176073249006194 Test RE 0.08023212484862852\n",
      "94 Train Loss 0.10305542 Test MSE 0.02826560296479855 Test RE 0.08035949288500611\n",
      "95 Train Loss 0.09931244 Test MSE 0.02530866128804627 Test RE 0.07604009435133503\n",
      "96 Train Loss 0.09470138 Test MSE 0.02791714643478937 Test RE 0.07986262347033783\n",
      "97 Train Loss 0.09018762 Test MSE 0.028406357984236446 Test RE 0.08055932862741723\n",
      "98 Train Loss 0.08788097 Test MSE 0.028227753179708083 Test RE 0.08030567113474095\n",
      "99 Train Loss 0.085835055 Test MSE 0.031038283470162346 Test RE 0.08420868934225269\n",
      "Training time: 67.84\n",
      "8\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.668503 Test MSE 8.463736592085395 Test RE 1.3905580696098891\n",
      "1 Train Loss 48.941277 Test MSE 8.619347333016362 Test RE 1.403282958543312\n",
      "2 Train Loss 40.872044 Test MSE 8.461224032434728 Test RE 1.390351652538868\n",
      "3 Train Loss 37.38623 Test MSE 7.6196090125952605 Test RE 1.3193936928991055\n",
      "4 Train Loss 27.540535 Test MSE 5.799082801451416 Test RE 1.1510328415021518\n",
      "5 Train Loss 22.055063 Test MSE 5.846493118975346 Test RE 1.1557283901096593\n",
      "6 Train Loss 18.375675 Test MSE 5.825544731683777 Test RE 1.1536560048806086\n",
      "7 Train Loss 15.822677 Test MSE 5.564719684255137 Test RE 1.127534155197509\n",
      "8 Train Loss 14.395832 Test MSE 5.998079688682647 Test RE 1.170615245816027\n",
      "9 Train Loss 13.053984 Test MSE 5.8955218324729435 Test RE 1.1605642442374893\n",
      "10 Train Loss 11.950004 Test MSE 5.864050438033276 Test RE 1.1574624450730542\n",
      "11 Train Loss 10.918714 Test MSE 5.825854033482635 Test RE 1.1536866306124305\n",
      "12 Train Loss 10.142617 Test MSE 5.80171225367578 Test RE 1.1512937657693114\n",
      "13 Train Loss 9.359048 Test MSE 5.689710590186654 Test RE 1.1401267844428797\n",
      "14 Train Loss 8.266829 Test MSE 5.649725135469377 Test RE 1.1361134989535167\n",
      "15 Train Loss 6.9929686 Test MSE 5.3237978576540375 Test RE 1.1028560725609213\n",
      "16 Train Loss 6.154805 Test MSE 5.042410605609516 Test RE 1.0733149140482745\n",
      "17 Train Loss 5.4918737 Test MSE 4.644594886506873 Test RE 1.0301061502400102\n",
      "18 Train Loss 4.448346 Test MSE 4.293832925902421 Test RE 0.9904456096648538\n",
      "19 Train Loss 3.6524594 Test MSE 4.013075653171401 Test RE 0.9575175302225608\n",
      "20 Train Loss 3.1205733 Test MSE 3.934257047297061 Test RE 0.9480678643225572\n",
      "21 Train Loss 2.7821577 Test MSE 3.8047080731608576 Test RE 0.9323280063205996\n",
      "22 Train Loss 2.54879 Test MSE 3.741989456383971 Test RE 0.9246116049096625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Train Loss 2.2656765 Test MSE 3.685745975980696 Test RE 0.9176366701555637\n",
      "24 Train Loss 2.107203 Test MSE 3.6012311324213346 Test RE 0.9070548675833784\n",
      "25 Train Loss 1.9949791 Test MSE 3.555425523247025 Test RE 0.9012677959454993\n",
      "26 Train Loss 1.878193 Test MSE 3.5380912438528997 Test RE 0.8990680710040349\n",
      "27 Train Loss 1.7607731 Test MSE 3.349169303360867 Test RE 0.8747352162998678\n",
      "28 Train Loss 1.6689988 Test MSE 3.117629664696434 Test RE 0.8439570061891201\n",
      "29 Train Loss 1.5848849 Test MSE 2.9700514528593107 Test RE 0.8237397940159666\n",
      "30 Train Loss 1.4812869 Test MSE 2.606746686640625 Test RE 0.7717159481119626\n",
      "31 Train Loss 1.354184 Test MSE 2.2901636389563165 Test RE 0.7233380612855811\n",
      "32 Train Loss 1.1298969 Test MSE 1.9022545729434075 Test RE 0.6592382209119368\n",
      "33 Train Loss 0.96568996 Test MSE 1.739267935475446 Test RE 0.6303638589958482\n",
      "34 Train Loss 0.791883 Test MSE 1.5684486589975346 Test RE 0.5986089611161105\n",
      "35 Train Loss 0.69525456 Test MSE 1.50091407742468 Test RE 0.585579650010048\n",
      "36 Train Loss 0.63037246 Test MSE 1.4261904795815352 Test RE 0.5708169054361008\n",
      "37 Train Loss 0.5508092 Test MSE 1.2049126917450061 Test RE 0.5246695376537166\n",
      "38 Train Loss 0.49273625 Test MSE 1.0787935040379162 Test RE 0.4964519508369473\n",
      "39 Train Loss 0.42916784 Test MSE 0.8931827427865889 Test RE 0.4517292598405834\n",
      "40 Train Loss 0.3682038 Test MSE 0.7116089437267581 Test RE 0.4032076461531976\n",
      "41 Train Loss 0.3076703 Test MSE 0.5771052744336578 Test RE 0.3631078032295215\n",
      "42 Train Loss 0.2597325 Test MSE 0.50484709572587 Test RE 0.3396158817869297\n",
      "43 Train Loss 0.21855167 Test MSE 0.40167900856697125 Test RE 0.3029337273323291\n",
      "44 Train Loss 0.1735632 Test MSE 0.31349484616847506 Test RE 0.26762289417132623\n",
      "45 Train Loss 0.15109025 Test MSE 0.2577404784688828 Test RE 0.24266066056105776\n",
      "46 Train Loss 0.12509179 Test MSE 0.2111041148600087 Test RE 0.2196121732239045\n",
      "47 Train Loss 0.108200535 Test MSE 0.16618620692975788 Test RE 0.19485230517940874\n",
      "48 Train Loss 0.09663226 Test MSE 0.1319738719036366 Test RE 0.1736409045210004\n",
      "49 Train Loss 0.08618009 Test MSE 0.12787962021601573 Test RE 0.17092623605332383\n",
      "50 Train Loss 0.07657314 Test MSE 0.11533332388925834 Test RE 0.16232501980606617\n",
      "51 Train Loss 0.06911338 Test MSE 0.10258974597127343 Test RE 0.15309465819908527\n",
      "52 Train Loss 0.06405725 Test MSE 0.09057041142214496 Test RE 0.14384713966347928\n",
      "53 Train Loss 0.056916915 Test MSE 0.06517465543428233 Test RE 0.12202461109450097\n",
      "54 Train Loss 0.051795863 Test MSE 0.05719564239188588 Test RE 0.11431139674885676\n",
      "55 Train Loss 0.048672978 Test MSE 0.05391592972886163 Test RE 0.11098559370216164\n",
      "56 Train Loss 0.044668388 Test MSE 0.0396304251047334 Test RE 0.09515298693937217\n",
      "57 Train Loss 0.038440704 Test MSE 0.023067762921769958 Test RE 0.07259568373122212\n",
      "58 Train Loss 0.033830877 Test MSE 0.014074336944924505 Test RE 0.05670508845950226\n",
      "59 Train Loss 0.02973478 Test MSE 0.01164634401662658 Test RE 0.05158255708651108\n",
      "60 Train Loss 0.026167588 Test MSE 0.007259496034974707 Test RE 0.040725019081604974\n",
      "61 Train Loss 0.023439964 Test MSE 0.005094104497919546 Test RE 0.03411473366606266\n",
      "62 Train Loss 0.020664457 Test MSE 0.004848773401588223 Test RE 0.033283117990878\n",
      "63 Train Loss 0.018148756 Test MSE 0.004902275967070047 Test RE 0.03346624129947712\n",
      "64 Train Loss 0.015803918 Test MSE 0.004328227975443148 Test RE 0.031445834483202456\n",
      "65 Train Loss 0.014315684 Test MSE 0.004140167984873029 Test RE 0.030755092788958337\n",
      "66 Train Loss 0.012576271 Test MSE 0.004579855163259841 Test RE 0.03234699431195945\n",
      "67 Train Loss 0.011259342 Test MSE 0.005330855298630309 Test RE 0.034898479649302115\n",
      "68 Train Loss 0.010375537 Test MSE 0.005391571969913775 Test RE 0.03509665799670018\n",
      "69 Train Loss 0.009172639 Test MSE 0.005020262834328779 Test RE 0.03386657578780332\n",
      "70 Train Loss 0.0083314665 Test MSE 0.005034431447970119 Test RE 0.03391433268394473\n",
      "71 Train Loss 0.007651604 Test MSE 0.005174208680038048 Test RE 0.03438191247153204\n",
      "72 Train Loss 0.006981611 Test MSE 0.005005685079674088 Test RE 0.033817369444542146\n",
      "73 Train Loss 0.0062803538 Test MSE 0.004536398610393351 Test RE 0.032193164196363235\n",
      "74 Train Loss 0.0058400785 Test MSE 0.004673364900590189 Test RE 0.032675550006105086\n",
      "75 Train Loss 0.005514135 Test MSE 0.004304044078077988 Test RE 0.03135785989957264\n",
      "76 Train Loss 0.005069759 Test MSE 0.0036979403935694173 Test RE 0.02906618367128687\n",
      "77 Train Loss 0.004717783 Test MSE 0.0037816959307703734 Test RE 0.02939350413465457\n",
      "78 Train Loss 0.004337995 Test MSE 0.0036104962844343215 Test RE 0.028720467935365434\n",
      "79 Train Loss 0.003917782 Test MSE 0.0034621333771794093 Test RE 0.028124185755424982\n",
      "80 Train Loss 0.0037639304 Test MSE 0.0034195637915718806 Test RE 0.027950746746322017\n",
      "81 Train Loss 0.0036088813 Test MSE 0.003193696578220392 Test RE 0.027011884669042176\n",
      "82 Train Loss 0.0034695102 Test MSE 0.0031396487290866193 Test RE 0.026782344420236828\n",
      "83 Train Loss 0.003264937 Test MSE 0.002973814498513864 Test RE 0.026065436221753894\n",
      "84 Train Loss 0.0031651391 Test MSE 0.0029249091438342673 Test RE 0.025850220406696742\n",
      "85 Train Loss 0.0029517985 Test MSE 0.0029350958046721336 Test RE 0.02589519591514995\n",
      "86 Train Loss 0.002795034 Test MSE 0.002745486604109106 Test RE 0.025044809047664866\n",
      "87 Train Loss 0.0026812092 Test MSE 0.00275342989934802 Test RE 0.02508101294443548\n",
      "88 Train Loss 0.0025564772 Test MSE 0.002729761804913799 Test RE 0.024972983870710324\n",
      "89 Train Loss 0.0024652956 Test MSE 0.0024958672337509072 Test RE 0.023879146505268452\n",
      "90 Train Loss 0.0023841716 Test MSE 0.0023446320853365474 Test RE 0.023144372590260632\n",
      "91 Train Loss 0.0022644948 Test MSE 0.002339150808155098 Test RE 0.023117303321558806\n",
      "92 Train Loss 0.0021645327 Test MSE 0.0023006677873604496 Test RE 0.02292635517295309\n",
      "93 Train Loss 0.0021033278 Test MSE 0.002248975520794527 Test RE 0.022667332982753932\n",
      "94 Train Loss 0.0020126754 Test MSE 0.002195780303371904 Test RE 0.0223976525272231\n",
      "95 Train Loss 0.0019367564 Test MSE 0.002039021272441459 Test RE 0.02158335423475784\n",
      "96 Train Loss 0.0018698357 Test MSE 0.0019012814521262036 Test RE 0.020841610054991695\n",
      "97 Train Loss 0.0017849493 Test MSE 0.001711842875910513 Test RE 0.01977607088899627\n",
      "98 Train Loss 0.0017093343 Test MSE 0.0015765637017170534 Test RE 0.018978584678006748\n",
      "99 Train Loss 0.0016474358 Test MSE 0.0015406246759138412 Test RE 0.018761021669718433\n",
      "Training time: 67.01\n",
      "9\n",
      "KG_rowdy_tune10\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.07496 Test MSE 8.357322496126958 Test RE 1.3817887130902409\n",
      "1 Train Loss 56.27595 Test MSE 8.686625204110218 Test RE 1.4087489395493464\n",
      "2 Train Loss 52.907993 Test MSE 9.487293184832314 Test RE 1.4722420612305973\n",
      "3 Train Loss 46.75055 Test MSE 8.630472092192747 Test RE 1.404188256263741\n",
      "4 Train Loss 44.396767 Test MSE 8.597541300931173 Test RE 1.4015067561080692\n",
      "5 Train Loss 43.697235 Test MSE 8.549532437853953 Test RE 1.397588255652449\n",
      "6 Train Loss 43.42121 Test MSE 8.38747403119855 Test RE 1.3842790765125867\n",
      "7 Train Loss 43.25539 Test MSE 8.481209115608792 Test RE 1.391992662463802\n",
      "8 Train Loss 42.820953 Test MSE 8.270881503411946 Test RE 1.3746241187877684\n",
      "9 Train Loss 42.472237 Test MSE 8.313388678254336 Test RE 1.3781519474002066\n",
      "10 Train Loss 41.910503 Test MSE 8.255216224835046 Test RE 1.3733217137264424\n",
      "11 Train Loss 41.83382 Test MSE 8.230608666463766 Test RE 1.3712733533507082\n",
      "12 Train Loss 41.71512 Test MSE 8.115496617950617 Test RE 1.3616503776004527\n",
      "13 Train Loss 41.18274 Test MSE 8.204802900068504 Test RE 1.3691219607735807\n",
      "14 Train Loss 40.729195 Test MSE 8.05622644809303 Test RE 1.3566689730205916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 38.631207 Test MSE 7.58902307034733 Test RE 1.3167429349695448\n",
      "16 Train Loss 38.14614 Test MSE 7.52036047817591 Test RE 1.3107727057498129\n",
      "17 Train Loss 37.66656 Test MSE 7.599208049137457 Test RE 1.3176262174514892\n",
      "18 Train Loss 37.202793 Test MSE 7.691387613470142 Test RE 1.3255936332880767\n",
      "19 Train Loss 36.89062 Test MSE 7.602968356392029 Test RE 1.3179521768550417\n",
      "20 Train Loss 36.740807 Test MSE 7.510391245253938 Test RE 1.3099036162983473\n",
      "21 Train Loss 36.55062 Test MSE 7.551112464772987 Test RE 1.313449953831502\n",
      "22 Train Loss 36.117065 Test MSE 7.423611177368357 Test RE 1.302313878504915\n",
      "23 Train Loss 34.97229 Test MSE 7.04351596820216 Test RE 1.2685360449502863\n",
      "24 Train Loss 34.04888 Test MSE 7.236243655080287 Test RE 1.2857740344747381\n",
      "25 Train Loss 33.551277 Test MSE 7.188181047829484 Test RE 1.281496911462714\n",
      "26 Train Loss 33.37271 Test MSE 7.149260109633688 Test RE 1.2780228224739176\n",
      "27 Train Loss 33.329674 Test MSE 7.13217150810218 Test RE 1.276494504252909\n",
      "28 Train Loss 33.29029 Test MSE 7.1269212005397495 Test RE 1.2760245756621982\n",
      "29 Train Loss 33.258854 Test MSE 7.111322642513602 Test RE 1.2746274052911197\n",
      "30 Train Loss 33.216682 Test MSE 7.098667680077944 Test RE 1.2734927679431867\n",
      "31 Train Loss 33.05371 Test MSE 7.171689558616822 Test RE 1.2800260297591177\n",
      "32 Train Loss 32.998753 Test MSE 7.176493616244072 Test RE 1.2804546797518308\n",
      "33 Train Loss 32.953773 Test MSE 7.211152755587439 Test RE 1.2835429569444083\n",
      "34 Train Loss 32.870842 Test MSE 7.240170037838808 Test RE 1.2861228173934842\n",
      "35 Train Loss 32.79052 Test MSE 7.207028886490123 Test RE 1.2831758921846954\n",
      "36 Train Loss 32.73281 Test MSE 7.209697957031363 Test RE 1.2834134776023634\n",
      "37 Train Loss 32.704872 Test MSE 7.211722704714316 Test RE 1.283593679745464\n",
      "38 Train Loss 32.65512 Test MSE 7.20314540722965 Test RE 1.282830128450642\n",
      "39 Train Loss 32.527077 Test MSE 7.305576454838299 Test RE 1.2919190594248893\n",
      "40 Train Loss 32.438988 Test MSE 7.321354777724682 Test RE 1.2933134272566986\n",
      "41 Train Loss 32.257652 Test MSE 7.272391806984247 Test RE 1.2889815311405388\n",
      "42 Train Loss 32.021667 Test MSE 7.337978686613538 Test RE 1.2947808970492334\n",
      "43 Train Loss 31.885603 Test MSE 7.369110294483027 Test RE 1.297524564664824\n",
      "44 Train Loss 31.74636 Test MSE 7.361177674818121 Test RE 1.296826004057113\n",
      "45 Train Loss 31.657265 Test MSE 7.348754272565764 Test RE 1.295731220372187\n",
      "46 Train Loss 31.553894 Test MSE 7.327537907924151 Test RE 1.2938594353309498\n",
      "47 Train Loss 31.216248 Test MSE 7.422572169543901 Test RE 1.3022227394604469\n",
      "48 Train Loss 30.924456 Test MSE 7.388944560972703 Test RE 1.2992695619048886\n",
      "49 Train Loss 30.777573 Test MSE 7.216615802741914 Test RE 1.2840290600949982\n",
      "50 Train Loss 30.428543 Test MSE 7.312982380241248 Test RE 1.2925737259421892\n",
      "51 Train Loss 29.47982 Test MSE 7.502776327713493 Test RE 1.309239380748621\n",
      "52 Train Loss 28.829222 Test MSE 7.712502918625316 Test RE 1.3274119742188815\n",
      "53 Train Loss 28.345062 Test MSE 7.581994515877757 Test RE 1.3161330446598718\n",
      "54 Train Loss 28.012331 Test MSE 7.4483451956736495 Test RE 1.3044816017719723\n",
      "55 Train Loss 27.542992 Test MSE 7.199609810997403 Test RE 1.2825152572513703\n",
      "56 Train Loss 27.12772 Test MSE 7.089660191676816 Test RE 1.2726845449752822\n",
      "57 Train Loss 26.618973 Test MSE 6.919626494847669 Test RE 1.2573303148353487\n",
      "58 Train Loss 26.395588 Test MSE 6.830632903222004 Test RE 1.2492188624092995\n",
      "59 Train Loss 26.206924 Test MSE 6.6500170919596835 Test RE 1.232592273547599\n",
      "60 Train Loss 25.961845 Test MSE 6.591419643351049 Test RE 1.2271496878327512\n",
      "61 Train Loss 25.591581 Test MSE 6.717666582228327 Test RE 1.2388458851011486\n",
      "62 Train Loss 25.390686 Test MSE 6.73956040130835 Test RE 1.2408630292844907\n",
      "63 Train Loss 25.230072 Test MSE 6.811010636630819 Test RE 1.2474232648846437\n",
      "64 Train Loss 25.045385 Test MSE 6.773299404246407 Test RE 1.2439651022540947\n",
      "65 Train Loss 24.739195 Test MSE 6.775437657310143 Test RE 1.244161439529292\n",
      "66 Train Loss 24.436655 Test MSE 6.691011157780362 Test RE 1.2363855973593094\n",
      "67 Train Loss 23.943249 Test MSE 6.657373308466948 Test RE 1.233273828900206\n",
      "68 Train Loss 23.319122 Test MSE 6.567290417419795 Test RE 1.2249015135475743\n",
      "69 Train Loss 22.846067 Test MSE 6.52457259733011 Test RE 1.22091124618004\n",
      "70 Train Loss 22.438248 Test MSE 6.4809069904171475 Test RE 1.2168189223805548\n",
      "71 Train Loss 21.772968 Test MSE 6.2281577624378475 Test RE 1.1928555697920753\n",
      "72 Train Loss 21.489697 Test MSE 6.228318328532448 Test RE 1.1928709460022746\n",
      "73 Train Loss 21.06807 Test MSE 6.343501354774604 Test RE 1.2038505589983588\n",
      "74 Train Loss 20.712948 Test MSE 6.443006736114395 Test RE 1.2132557352739097\n",
      "75 Train Loss 20.41193 Test MSE 6.466876216574216 Test RE 1.2155010388184642\n",
      "76 Train Loss 20.183075 Test MSE 6.4068693794317015 Test RE 1.209848513489644\n",
      "77 Train Loss 19.73138 Test MSE 6.190094829490398 Test RE 1.1892049586271687\n",
      "78 Train Loss 19.143053 Test MSE 6.008159740616487 Test RE 1.171598469588588\n",
      "79 Train Loss 18.704647 Test MSE 5.69193877814942 Test RE 1.1403500091630023\n",
      "80 Train Loss 18.38577 Test MSE 5.551707485177717 Test RE 1.126215105306447\n",
      "81 Train Loss 18.08521 Test MSE 5.363054267562329 Test RE 1.1069147026875685\n",
      "82 Train Loss 17.713829 Test MSE 5.080570937759587 Test RE 1.0773686154727076\n",
      "83 Train Loss 17.36897 Test MSE 5.0969951085578105 Test RE 1.079108637282438\n",
      "84 Train Loss 17.183914 Test MSE 5.004292110293676 Test RE 1.0692503140076166\n",
      "85 Train Loss 16.727116 Test MSE 4.790933683249415 Test RE 1.0462082489456281\n",
      "86 Train Loss 16.374788 Test MSE 4.647717119168985 Test RE 1.0304523258287024\n",
      "87 Train Loss 15.973708 Test MSE 4.625190693908569 Test RE 1.0279521089065111\n",
      "88 Train Loss 15.724193 Test MSE 4.54520855503148 Test RE 1.0190253031659464\n",
      "89 Train Loss 15.394402 Test MSE 4.2907107254490064 Test RE 0.9900854498574329\n",
      "90 Train Loss 14.773543 Test MSE 4.046131044568341 Test RE 0.9614529415591583\n",
      "91 Train Loss 14.370438 Test MSE 3.8727226168550626 Test RE 0.94062443453294\n",
      "92 Train Loss 13.821018 Test MSE 3.407947104943695 Test RE 0.8823776170672103\n",
      "93 Train Loss 13.233078 Test MSE 3.1098179783444513 Test RE 0.8428990129243669\n",
      "94 Train Loss 12.408354 Test MSE 3.056205174625196 Test RE 0.8356016976383485\n",
      "95 Train Loss 11.615561 Test MSE 2.8798165420746784 Test RE 0.8111300131184485\n",
      "96 Train Loss 11.122335 Test MSE 2.8022156643561003 Test RE 0.8001268392223243\n",
      "97 Train Loss 10.506761 Test MSE 2.591525102986553 Test RE 0.7694595076677039\n",
      "98 Train Loss 10.157603 Test MSE 2.428168011741242 Test RE 0.744813306626634\n",
      "99 Train Loss 9.92217 Test MSE 2.1529508393073966 Test RE 0.7013343605985373\n",
      "Training time: 67.90\n",
      "0\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 59.49222 Test MSE 8.089040748543399 Test RE 1.3594291302285542\n",
      "1 Train Loss 45.07823 Test MSE 7.416229115265147 Test RE 1.3016662049618783\n",
      "2 Train Loss 30.477297 Test MSE 7.062336756595008 Test RE 1.2702297247131358\n",
      "3 Train Loss 24.26523 Test MSE 5.796831602766747 Test RE 1.1508094048629385\n",
      "4 Train Loss 21.341858 Test MSE 5.917667152374296 Test RE 1.1627419120682632\n",
      "5 Train Loss 17.769615 Test MSE 5.997130919563944 Test RE 1.1705226588901858\n",
      "6 Train Loss 14.378217 Test MSE 6.005945192645757 Test RE 1.1713825299122327\n",
      "7 Train Loss 11.664383 Test MSE 5.8276356283337565 Test RE 1.1538630206346772\n",
      "8 Train Loss 9.663092 Test MSE 5.399957295087453 Test RE 1.1107164985559081\n",
      "9 Train Loss 7.8131437 Test MSE 5.1083862242042395 Test RE 1.0803137974593664\n",
      "10 Train Loss 6.2425294 Test MSE 4.847192884072137 Test RE 1.052333052420917\n",
      "11 Train Loss 4.9252234 Test MSE 4.436728157303138 Test RE 1.0067913375625641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 3.8490644 Test MSE 4.059580576535531 Test RE 0.9630495734850429\n",
      "13 Train Loss 3.1639602 Test MSE 3.7041217779627664 Test RE 0.9199213290456479\n",
      "14 Train Loss 2.3250296 Test MSE 2.8313426642091515 Test RE 0.8042744583592429\n",
      "15 Train Loss 1.9305334 Test MSE 2.3652627402697823 Test RE 0.7351022558640474\n",
      "16 Train Loss 1.7089444 Test MSE 2.095089334303363 Test RE 0.6918458389508616\n",
      "17 Train Loss 1.4148202 Test MSE 1.5120032916690274 Test RE 0.5877388902313962\n",
      "18 Train Loss 1.0622952 Test MSE 1.0305222638298863 Test RE 0.48521782831076726\n",
      "19 Train Loss 0.7689585 Test MSE 0.8182268080197498 Test RE 0.4323594069767712\n",
      "20 Train Loss 0.5371962 Test MSE 0.5472970014445019 Test RE 0.3536059748486113\n",
      "21 Train Loss 0.33132374 Test MSE 0.322998240274266 Test RE 0.2716490173703479\n",
      "22 Train Loss 0.22331604 Test MSE 0.23830030702335503 Test RE 0.2333298818989181\n",
      "23 Train Loss 0.16654582 Test MSE 0.1526525666715713 Test RE 0.18674978723797195\n",
      "24 Train Loss 0.10413721 Test MSE 0.060009205212736824 Test RE 0.11708924285516857\n",
      "25 Train Loss 0.0775048 Test MSE 0.04209199612552509 Test RE 0.09806359743135316\n",
      "26 Train Loss 0.06136892 Test MSE 0.027930101670111215 Test RE 0.07988115185175823\n",
      "27 Train Loss 0.049408413 Test MSE 0.0208764584273537 Test RE 0.06906157408423494\n",
      "28 Train Loss 0.040449575 Test MSE 0.017788559239992344 Test RE 0.06374974434909955\n",
      "29 Train Loss 0.032618143 Test MSE 0.013443584498899028 Test RE 0.05541988253099534\n",
      "30 Train Loss 0.026979873 Test MSE 0.01150511656193805 Test RE 0.051268849503209056\n",
      "31 Train Loss 0.022330146 Test MSE 0.010779196153322013 Test RE 0.04962508318801041\n",
      "32 Train Loss 0.019319884 Test MSE 0.008197320091922143 Test RE 0.043275690609273755\n",
      "33 Train Loss 0.01658432 Test MSE 0.006765374996797423 Test RE 0.03931461230515548\n",
      "34 Train Loss 0.014552604 Test MSE 0.006942919105670895 Test RE 0.0398271392815939\n",
      "35 Train Loss 0.012804845 Test MSE 0.006564818628431291 Test RE 0.03872749675933843\n",
      "36 Train Loss 0.01167612 Test MSE 0.0065813307291855885 Test RE 0.03877617066510629\n",
      "37 Train Loss 0.010433443 Test MSE 0.006569644722380317 Test RE 0.03874172930793185\n",
      "38 Train Loss 0.009022856 Test MSE 0.005725985769898702 Test RE 0.0361687244130413\n",
      "39 Train Loss 0.0077795098 Test MSE 0.004929056319385135 Test RE 0.03355752717052858\n",
      "40 Train Loss 0.00696677 Test MSE 0.004730731001041755 Test RE 0.03287548641480198\n",
      "41 Train Loss 0.0063497555 Test MSE 0.004787886819554916 Test RE 0.03307348793442507\n",
      "42 Train Loss 0.0057520056 Test MSE 0.004455993152864064 Test RE 0.03190658456427544\n",
      "43 Train Loss 0.0051417854 Test MSE 0.003963037656085268 Test RE 0.03008999806081324\n",
      "44 Train Loss 0.0048238817 Test MSE 0.004003075972347536 Test RE 0.03024161474381577\n",
      "45 Train Loss 0.004359659 Test MSE 0.0033420263850391044 Test RE 0.027632043087059518\n",
      "46 Train Loss 0.0039254203 Test MSE 0.002678044163803493 Test RE 0.02473528551065466\n",
      "47 Train Loss 0.0034460628 Test MSE 0.0022674461955324845 Test RE 0.022760225233873062\n",
      "48 Train Loss 0.0032129923 Test MSE 0.002194014598463962 Test RE 0.022388645342272143\n",
      "49 Train Loss 0.0030847387 Test MSE 0.002208314570005048 Test RE 0.022461488296751316\n",
      "50 Train Loss 0.0028362712 Test MSE 0.002028422709705272 Test RE 0.021527187443261254\n",
      "51 Train Loss 0.0025602428 Test MSE 0.0016973398424070315 Test RE 0.019692119525135967\n",
      "52 Train Loss 0.0023581877 Test MSE 0.0016644408007895695 Test RE 0.019500342391938538\n",
      "53 Train Loss 0.0021756897 Test MSE 0.0017323197560620812 Test RE 0.019893998892088705\n",
      "54 Train Loss 0.0020693587 Test MSE 0.0017372452923375891 Test RE 0.019922261301066935\n",
      "55 Train Loss 0.0019675405 Test MSE 0.0016895333374806522 Test RE 0.019646782760801233\n",
      "56 Train Loss 0.0019020971 Test MSE 0.0016121742150125228 Test RE 0.019191726490169193\n",
      "57 Train Loss 0.001823287 Test MSE 0.001558785522390316 Test RE 0.018871274941115075\n",
      "58 Train Loss 0.0017281944 Test MSE 0.0014453680982973588 Test RE 0.01817177256930247\n",
      "59 Train Loss 0.0016262355 Test MSE 0.0013706086423798545 Test RE 0.01769557964827209\n",
      "60 Train Loss 0.0015468587 Test MSE 0.0013893124402799258 Test RE 0.017815910509457297\n",
      "61 Train Loss 0.0014429606 Test MSE 0.0013173800289479178 Test RE 0.017348566612568783\n",
      "62 Train Loss 0.0013691899 Test MSE 0.0012959083740285812 Test RE 0.017206605767634966\n",
      "63 Train Loss 0.001277233 Test MSE 0.0012910148158526511 Test RE 0.017174087586533843\n",
      "64 Train Loss 0.0012324608 Test MSE 0.0012192526955588402 Test RE 0.01668994565249121\n",
      "65 Train Loss 0.0012029378 Test MSE 0.001180052802492301 Test RE 0.01641945661878649\n",
      "66 Train Loss 0.0011486883 Test MSE 0.0010997942672906977 Test RE 0.015851259873403488\n",
      "67 Train Loss 0.0010842837 Test MSE 0.0009928602122357421 Test RE 0.015060941230827027\n",
      "68 Train Loss 0.0010329257 Test MSE 0.0009826884867352858 Test RE 0.01498359391211418\n",
      "69 Train Loss 0.0009827254 Test MSE 0.0009907923071113879 Test RE 0.015045248774387772\n",
      "70 Train Loss 0.0009403653 Test MSE 0.0009386951763517912 Test RE 0.014644358544414182\n",
      "71 Train Loss 0.00089003134 Test MSE 0.0008892679726383375 Test RE 0.014253594057594417\n",
      "72 Train Loss 0.000844259 Test MSE 0.0008798032440280775 Test RE 0.01417753864551763\n",
      "73 Train Loss 0.00080549275 Test MSE 0.0008395877847865533 Test RE 0.013849723910323693\n",
      "74 Train Loss 0.0007695723 Test MSE 0.0008004592829180843 Test RE 0.013523144324519648\n",
      "75 Train Loss 0.0007416556 Test MSE 0.0007673376885992131 Test RE 0.013240406691104632\n",
      "76 Train Loss 0.0007255834 Test MSE 0.0007368093231344228 Test RE 0.012974350212945346\n",
      "77 Train Loss 0.00069583574 Test MSE 0.0007278338139358211 Test RE 0.012895083967627766\n",
      "78 Train Loss 0.00065999595 Test MSE 0.0007910606074508847 Test RE 0.013443518200827778\n",
      "79 Train Loss 0.00062809855 Test MSE 0.0008407177806421114 Test RE 0.01385904090408578\n",
      "80 Train Loss 0.0006140506 Test MSE 0.000804373798797148 Test RE 0.013556170365117292\n",
      "81 Train Loss 0.00059527013 Test MSE 0.0007541026126753424 Test RE 0.01312572445572341\n",
      "82 Train Loss 0.0005843712 Test MSE 0.0007446042425695336 Test RE 0.013042799359519915\n",
      "83 Train Loss 0.00057256967 Test MSE 0.0007600814761682373 Test RE 0.013177655039842836\n",
      "84 Train Loss 0.0005596531 Test MSE 0.0007259503215096245 Test RE 0.012878388173952988\n",
      "85 Train Loss 0.00053479883 Test MSE 0.0006648180814388982 Test RE 0.012324220831718746\n",
      "86 Train Loss 0.0005185466 Test MSE 0.0006202735870868934 Test RE 0.011904186009512586\n",
      "87 Train Loss 0.0004996175 Test MSE 0.0005421378325167996 Test RE 0.011129173624861585\n",
      "88 Train Loss 0.00048283415 Test MSE 0.0005441706889194741 Test RE 0.011150019655000657\n",
      "89 Train Loss 0.00046874429 Test MSE 0.0005505291363454736 Test RE 0.011214972541272671\n",
      "90 Train Loss 0.00045928833 Test MSE 0.0005550936791468301 Test RE 0.011261369314271026\n",
      "91 Train Loss 0.00044470347 Test MSE 0.0005243266608256345 Test RE 0.010944830266221109\n",
      "92 Train Loss 0.0004324255 Test MSE 0.00047179606801580964 Test RE 0.010382100267008922\n",
      "93 Train Loss 0.00041885325 Test MSE 0.0004658164697275019 Test RE 0.010316098497932632\n",
      "94 Train Loss 0.00040807112 Test MSE 0.0004676077571193332 Test RE 0.01033591463497762\n",
      "95 Train Loss 0.0003973509 Test MSE 0.0004366603855979459 Test RE 0.009988032739688344\n",
      "96 Train Loss 0.00038992055 Test MSE 0.00042090876536437843 Test RE 0.009806229324440877\n",
      "97 Train Loss 0.0003800666 Test MSE 0.00041907627520189474 Test RE 0.009784859586479528\n",
      "98 Train Loss 0.0003707513 Test MSE 0.00038289894975089333 Test RE 0.009352983061853379\n",
      "99 Train Loss 0.0003573996 Test MSE 0.00034426255962784723 Test RE 0.008868556904823643\n",
      "Training time: 67.54\n",
      "1\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.58867 Test MSE 8.312806507125497 Test RE 1.3781036918480651\n",
      "1 Train Loss 54.52013 Test MSE 9.1978880020465 Test RE 1.449613146065225\n",
      "2 Train Loss 47.42503 Test MSE 8.89609663388046 Test RE 1.4256332182455749\n",
      "3 Train Loss 45.24894 Test MSE 8.432435920791734 Test RE 1.3879844003638044\n",
      "4 Train Loss 43.148067 Test MSE 8.670216588100871 Test RE 1.40741778123099\n",
      "5 Train Loss 42.337315 Test MSE 8.695348502897584 Test RE 1.4094561102842724\n",
      "6 Train Loss 40.809013 Test MSE 9.24664772416007 Test RE 1.4534504022941126\n",
      "7 Train Loss 39.734253 Test MSE 9.483988096818756 Test RE 1.4719855964333624\n",
      "8 Train Loss 37.36782 Test MSE 9.241345972168007 Test RE 1.453033659995379\n",
      "9 Train Loss 35.0352 Test MSE 9.641147705948583 Test RE 1.484131655940035\n",
      "10 Train Loss 32.232494 Test MSE 9.786136317597494 Test RE 1.495249585872425\n",
      "11 Train Loss 29.18406 Test MSE 9.769748615456434 Test RE 1.4939971011829989\n",
      "12 Train Loss 25.526142 Test MSE 9.165564380987504 Test RE 1.447063757281274\n",
      "13 Train Loss 22.823471 Test MSE 9.038871152367156 Test RE 1.4370277611103481\n",
      "14 Train Loss 20.13783 Test MSE 9.110114942664419 Test RE 1.4426799248120747\n",
      "15 Train Loss 16.412945 Test MSE 8.15892671030619 Test RE 1.3652889531569021\n",
      "16 Train Loss 12.546446 Test MSE 7.04217320469515 Test RE 1.2684151234457037\n",
      "17 Train Loss 9.676104 Test MSE 6.8262238270320355 Test RE 1.2488156208411128\n",
      "18 Train Loss 7.122319 Test MSE 6.007371254988087 Test RE 1.171521589237039\n",
      "19 Train Loss 5.1060576 Test MSE 5.5197218004707596 Test RE 1.1229661231794503\n",
      "20 Train Loss 4.2377667 Test MSE 5.443137758431346 Test RE 1.11514854792176\n",
      "21 Train Loss 3.7436943 Test MSE 5.489430677674144 Test RE 1.1198805780587935\n",
      "22 Train Loss 3.3703766 Test MSE 5.608922412236728 Test RE 1.1320035179638268\n",
      "23 Train Loss 3.075759 Test MSE 5.65183847353271 Test RE 1.1363259665830971\n",
      "24 Train Loss 2.8143804 Test MSE 5.6942672852373235 Test RE 1.1405832373892262\n",
      "25 Train Loss 2.6096795 Test MSE 5.669865380544167 Test RE 1.1381367167055316\n",
      "26 Train Loss 2.4645834 Test MSE 5.605683975900894 Test RE 1.1316766770522804\n",
      "27 Train Loss 2.3531537 Test MSE 5.655391601613148 Test RE 1.1366830961574321\n",
      "28 Train Loss 2.220795 Test MSE 5.566701082018119 Test RE 1.1277348746357485\n",
      "29 Train Loss 2.146844 Test MSE 5.5590316745193835 Test RE 1.1269577501552057\n",
      "30 Train Loss 2.082136 Test MSE 5.630408098945365 Test RE 1.134169586921152\n",
      "31 Train Loss 1.9934257 Test MSE 5.615371114375874 Test RE 1.1326540757668482\n",
      "32 Train Loss 1.9257332 Test MSE 5.611597611548537 Test RE 1.1322734427195513\n",
      "33 Train Loss 1.8685329 Test MSE 5.59328077318843 Test RE 1.1304240031433503\n",
      "34 Train Loss 1.8097188 Test MSE 5.572047467191499 Test RE 1.128276295663132\n",
      "35 Train Loss 1.7541138 Test MSE 5.563872593938473 Test RE 1.1274483324004962\n",
      "36 Train Loss 1.721349 Test MSE 5.586090299922836 Test RE 1.1296971580301092\n",
      "37 Train Loss 1.6862527 Test MSE 5.534612017176092 Test RE 1.1244797816363103\n",
      "38 Train Loss 1.6563107 Test MSE 5.5152790050679625 Test RE 1.1225140974034147\n",
      "39 Train Loss 1.6183777 Test MSE 5.502936234073224 Test RE 1.1212573436937985\n",
      "40 Train Loss 1.5866016 Test MSE 5.4890358147592275 Test RE 1.1198402999964885\n",
      "41 Train Loss 1.5638216 Test MSE 5.512303256617372 Test RE 1.1222112323743827\n",
      "42 Train Loss 1.5428712 Test MSE 5.508635500527002 Test RE 1.1218378238561817\n",
      "43 Train Loss 1.5203959 Test MSE 5.513230628495344 Test RE 1.1223056269787788\n",
      "44 Train Loss 1.4976252 Test MSE 5.525520598214158 Test RE 1.1235558398609509\n",
      "45 Train Loss 1.4706964 Test MSE 5.5171782229971305 Test RE 1.1227073528485396\n",
      "46 Train Loss 1.4530379 Test MSE 5.522045565846029 Test RE 1.1232024788600707\n",
      "47 Train Loss 1.4343085 Test MSE 5.527004870100539 Test RE 1.1237067351783172\n",
      "48 Train Loss 1.4166267 Test MSE 5.567961730309918 Test RE 1.127862562160406\n",
      "49 Train Loss 1.4017997 Test MSE 5.581655395583568 Test RE 1.1292486248559659\n",
      "50 Train Loss 1.3877633 Test MSE 5.56540447769992 Test RE 1.127603530142613\n",
      "51 Train Loss 1.3743525 Test MSE 5.567514650564591 Test RE 1.1278172803630475\n",
      "52 Train Loss 1.3554906 Test MSE 5.568978910073392 Test RE 1.1279655789050325\n",
      "53 Train Loss 1.3329448 Test MSE 5.570101764772585 Test RE 1.1280792871481018\n",
      "54 Train Loss 1.3143667 Test MSE 5.594160762256198 Test RE 1.1305129242686947\n",
      "55 Train Loss 1.2991414 Test MSE 5.572257664141859 Test RE 1.1282975767094012\n",
      "56 Train Loss 1.2800144 Test MSE 5.58460076163145 Test RE 1.1295465303751209\n",
      "57 Train Loss 1.2610778 Test MSE 5.6262960229638885 Test RE 1.1337553502195414\n",
      "58 Train Loss 1.2451023 Test MSE 5.651047427037882 Test RE 1.1362464421830363\n",
      "59 Train Loss 1.2290018 Test MSE 5.680833314059812 Test RE 1.1392370053342817\n",
      "60 Train Loss 1.2139326 Test MSE 5.693303374590036 Test RE 1.1404866958324067\n",
      "61 Train Loss 1.1984615 Test MSE 5.677823863068257 Test RE 1.1389352069950618\n",
      "62 Train Loss 1.1772337 Test MSE 5.698081373549725 Test RE 1.1409651615906005\n",
      "63 Train Loss 1.1652938 Test MSE 5.695211251376508 Test RE 1.140677773462395\n",
      "64 Train Loss 1.1501721 Test MSE 5.704025622205154 Test RE 1.141560134907884\n",
      "65 Train Loss 1.1362557 Test MSE 5.699851839448873 Test RE 1.1411424039718234\n",
      "66 Train Loss 1.1215776 Test MSE 5.679449087076362 Test RE 1.1390982001105616\n",
      "67 Train Loss 1.1089165 Test MSE 5.7261358446502815 Test RE 1.1437704805658617\n",
      "68 Train Loss 1.098559 Test MSE 5.749082552260478 Test RE 1.1460599412050838\n",
      "69 Train Loss 1.08911 Test MSE 5.76099716947067 Test RE 1.1472468956435726\n",
      "70 Train Loss 1.0766096 Test MSE 5.8010558313501495 Test RE 1.1512286335914403\n",
      "71 Train Loss 1.0645502 Test MSE 5.8075850005269425 Test RE 1.151876313334375\n",
      "72 Train Loss 1.0535582 Test MSE 5.828568344172092 Test RE 1.1539553551013517\n",
      "73 Train Loss 1.0407866 Test MSE 5.809436638521581 Test RE 1.152059925624897\n",
      "74 Train Loss 1.0340334 Test MSE 5.8044653539619 Test RE 1.151566896452452\n",
      "75 Train Loss 1.0261492 Test MSE 5.834566101751665 Test RE 1.1545489283831882\n",
      "76 Train Loss 1.0185128 Test MSE 5.856675091625226 Test RE 1.1567343329548776\n",
      "77 Train Loss 1.0103495 Test MSE 5.882609857268196 Test RE 1.1592926527609584\n",
      "78 Train Loss 1.0021935 Test MSE 5.873012912454744 Test RE 1.1583466263189561\n",
      "79 Train Loss 0.9940793 Test MSE 5.887620483807042 Test RE 1.1597862726222068\n",
      "80 Train Loss 0.9866698 Test MSE 5.8997305451468565 Test RE 1.160978423860292\n",
      "81 Train Loss 0.9807847 Test MSE 5.898439654673986 Test RE 1.1608514029764894\n",
      "82 Train Loss 0.9748491 Test MSE 5.933454187397806 Test RE 1.164291848936273\n",
      "83 Train Loss 0.96822476 Test MSE 5.927040427965075 Test RE 1.1636624089273984\n",
      "84 Train Loss 0.9623834 Test MSE 5.931692686151754 Test RE 1.1641190108459765\n",
      "85 Train Loss 0.9564045 Test MSE 5.96327004793906 Test RE 1.1672134913086256\n",
      "86 Train Loss 0.95106435 Test MSE 5.961074127515668 Test RE 1.1669985635988946\n",
      "87 Train Loss 0.9457326 Test MSE 5.954938786700139 Test RE 1.1663978516276574\n",
      "88 Train Loss 0.93951404 Test MSE 5.951654704330171 Test RE 1.1660761795643715\n",
      "89 Train Loss 0.9351961 Test MSE 5.94726249581404 Test RE 1.165645829077844\n",
      "90 Train Loss 0.92993146 Test MSE 5.978633974544518 Test RE 1.168716143911368\n",
      "91 Train Loss 0.92648256 Test MSE 5.990629693010784 Test RE 1.1698880307168726\n",
      "92 Train Loss 0.92141163 Test MSE 5.98921082429429 Test RE 1.1697494796869863\n",
      "93 Train Loss 0.9165764 Test MSE 6.004030082793312 Test RE 1.1711957562227981\n",
      "94 Train Loss 0.91248053 Test MSE 5.9961139894723345 Test RE 1.1704234122507269\n",
      "95 Train Loss 0.9090388 Test MSE 5.994109248197685 Test RE 1.1702277361608595\n",
      "96 Train Loss 0.9053244 Test MSE 6.007577642801326 Test RE 1.1715417133222703\n",
      "97 Train Loss 0.900941 Test MSE 6.00157388027557 Test RE 1.1709561681299616\n",
      "98 Train Loss 0.89449704 Test MSE 6.007357439150432 Test RE 1.1715202420952766\n",
      "99 Train Loss 0.89049256 Test MSE 6.012038085973152 Test RE 1.1719765496194423\n",
      "Training time: 67.00\n",
      "2\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.609886 Test MSE 8.686432196773893 Test RE 1.4087332890300521\n",
      "1 Train Loss 46.262856 Test MSE 8.650948802275025 Test RE 1.4058530621250103\n",
      "2 Train Loss 31.930992 Test MSE 6.242238778936286 Test RE 1.194203250486646\n",
      "3 Train Loss 25.02596 Test MSE 6.166400874359851 Test RE 1.186926804186199\n",
      "4 Train Loss 21.400383 Test MSE 5.9114019624817615 Test RE 1.1621262363415856\n",
      "5 Train Loss 17.984556 Test MSE 5.500093662819433 Test RE 1.1209677105359428\n",
      "6 Train Loss 14.814781 Test MSE 5.717932733518314 Test RE 1.1429509192336402\n",
      "7 Train Loss 12.505021 Test MSE 5.810765246725999 Test RE 1.1521916551591815\n",
      "8 Train Loss 11.178742 Test MSE 5.846230242917621 Test RE 1.1557024072912432\n",
      "9 Train Loss 10.254398 Test MSE 5.83024968303406 Test RE 1.154121781054504\n",
      "10 Train Loss 9.6121235 Test MSE 5.812646867747852 Test RE 1.1523781893305345\n",
      "11 Train Loss 9.080314 Test MSE 5.719073258255117 Test RE 1.1430649026311275\n",
      "12 Train Loss 8.58586 Test MSE 5.62513174450015 Test RE 1.133638037228184\n",
      "13 Train Loss 8.034503 Test MSE 5.583099069308184 Test RE 1.1293946533234018\n",
      "14 Train Loss 7.604092 Test MSE 5.489375098829392 Test RE 1.1198749088163904\n",
      "15 Train Loss 7.1866713 Test MSE 5.399904206390797 Test RE 1.1107110386390078\n",
      "16 Train Loss 6.7649426 Test MSE 5.309458469795134 Test RE 1.101369826791231\n",
      "17 Train Loss 6.454209 Test MSE 5.2987067267306305 Test RE 1.1002541154221153\n",
      "18 Train Loss 6.1203127 Test MSE 5.064857810971807 Test RE 1.0757012891565614\n",
      "19 Train Loss 5.894346 Test MSE 4.830300550788968 Test RE 1.0504977762467402\n",
      "20 Train Loss 5.6972675 Test MSE 4.661211125613282 Test RE 1.0319471298186496\n",
      "21 Train Loss 5.4746704 Test MSE 4.212494384060636 Test RE 0.9810196980315811\n",
      "22 Train Loss 5.2993555 Test MSE 3.843205103635953 Test RE 0.9370329041232952\n",
      "23 Train Loss 5.0073414 Test MSE 3.344866869740709 Test RE 0.8741731814623184\n",
      "24 Train Loss 4.772579 Test MSE 3.155909339320569 Test RE 0.8491224426064095\n",
      "25 Train Loss 4.5289426 Test MSE 2.8669159818884062 Test RE 0.8093111860312924\n",
      "26 Train Loss 4.2399187 Test MSE 2.5301513167149596 Test RE 0.7602935529710432\n",
      "27 Train Loss 3.9343302 Test MSE 2.2531684090668938 Test RE 0.7174718844145356\n",
      "28 Train Loss 3.1621995 Test MSE 1.7798361553825892 Test RE 0.6376730644982199\n",
      "29 Train Loss 2.2096963 Test MSE 1.5051137841023816 Test RE 0.5863983327350178\n",
      "30 Train Loss 1.7879888 Test MSE 1.4166071464686443 Test RE 0.5688958615267962\n",
      "31 Train Loss 1.5106097 Test MSE 1.3235916414325448 Test RE 0.5499017075216089\n",
      "32 Train Loss 1.2686918 Test MSE 1.0729909502076898 Test RE 0.4951150067262145\n",
      "33 Train Loss 0.9495193 Test MSE 0.7747100271586262 Test RE 0.42070497605954726\n",
      "34 Train Loss 0.67220527 Test MSE 0.570411773377435 Test RE 0.3609959259753804\n",
      "35 Train Loss 0.44231963 Test MSE 0.4203157870118221 Test RE 0.3098816868962461\n",
      "36 Train Loss 0.33137566 Test MSE 0.34069463775892755 Test RE 0.2789913313704442\n",
      "37 Train Loss 0.26001355 Test MSE 0.3116388640354336 Test RE 0.2668295148575823\n",
      "38 Train Loss 0.19711094 Test MSE 0.25287853832350776 Test RE 0.24036102455525044\n",
      "39 Train Loss 0.15064676 Test MSE 0.21966790849542753 Test RE 0.22402235986232039\n",
      "40 Train Loss 0.11869164 Test MSE 0.18247337681677 Test RE 0.20417746846520202\n",
      "41 Train Loss 0.1018662 Test MSE 0.1381082881299524 Test RE 0.17763066077846568\n",
      "42 Train Loss 0.089709364 Test MSE 0.0985426939044765 Test RE 0.15004456734797747\n",
      "43 Train Loss 0.07672982 Test MSE 0.06398919328173158 Test RE 0.12090976519730627\n",
      "44 Train Loss 0.065579824 Test MSE 0.05611225859788575 Test RE 0.11322359372134809\n",
      "45 Train Loss 0.052152745 Test MSE 0.05296011549744138 Test RE 0.10999742587605076\n",
      "46 Train Loss 0.04417579 Test MSE 0.046299741259210506 Test RE 0.10284835322212645\n",
      "47 Train Loss 0.039887387 Test MSE 0.04043269204501742 Test RE 0.09611128622052734\n",
      "48 Train Loss 0.034563273 Test MSE 0.038833680644174785 Test RE 0.09419163546197988\n",
      "49 Train Loss 0.030149 Test MSE 0.035114129750080186 Test RE 0.08956720356927554\n",
      "50 Train Loss 0.026208691 Test MSE 0.0293598314156847 Test RE 0.08190017675486563\n",
      "51 Train Loss 0.023119632 Test MSE 0.027093684867195503 Test RE 0.07867596851143126\n",
      "52 Train Loss 0.021272948 Test MSE 0.023852658851915398 Test RE 0.07382041097523821\n",
      "53 Train Loss 0.01946963 Test MSE 0.023908351939643163 Test RE 0.07390654161601438\n",
      "54 Train Loss 0.017449908 Test MSE 0.023778148275067707 Test RE 0.07370502124700865\n",
      "55 Train Loss 0.015786259 Test MSE 0.020590715951756242 Test RE 0.06858731220076916\n",
      "56 Train Loss 0.013884314 Test MSE 0.020916775698691215 Test RE 0.06912822885735788\n",
      "57 Train Loss 0.013081759 Test MSE 0.02057009594817106 Test RE 0.06855296116424495\n",
      "58 Train Loss 0.012305045 Test MSE 0.019876961149434998 Test RE 0.06738807564725723\n",
      "59 Train Loss 0.011242794 Test MSE 0.019809927678460387 Test RE 0.06727434921954356\n",
      "60 Train Loss 0.010490774 Test MSE 0.017919355648266192 Test RE 0.06398368589940141\n",
      "61 Train Loss 0.009609015 Test MSE 0.015829194944528793 Test RE 0.0601364066665151\n",
      "62 Train Loss 0.008594599 Test MSE 0.0161400680563926 Test RE 0.06072405166507283\n",
      "63 Train Loss 0.0076666037 Test MSE 0.01515989073930533 Test RE 0.05885130477546403\n",
      "64 Train Loss 0.0072683217 Test MSE 0.014307120049075915 Test RE 0.057172103455753874\n",
      "65 Train Loss 0.006831443 Test MSE 0.014379839582641402 Test RE 0.05731721509052976\n",
      "66 Train Loss 0.0063887117 Test MSE 0.01411221221875904 Test RE 0.056781336377126464\n",
      "67 Train Loss 0.0061026076 Test MSE 0.01378378152420557 Test RE 0.05611671637427896\n",
      "68 Train Loss 0.0056509012 Test MSE 0.012934493004147537 Test RE 0.05436041522933063\n",
      "69 Train Loss 0.0053449417 Test MSE 0.011605033631983787 Test RE 0.051490992375822504\n",
      "70 Train Loss 0.005057589 Test MSE 0.010853065023727152 Test RE 0.04979483100369214\n",
      "71 Train Loss 0.0047287242 Test MSE 0.010199403552959585 Test RE 0.04827201725389591\n",
      "72 Train Loss 0.004511045 Test MSE 0.00963330301954952 Test RE 0.046913266253400726\n",
      "73 Train Loss 0.0043317885 Test MSE 0.009100009409805496 Test RE 0.045596234754620865\n",
      "74 Train Loss 0.004081098 Test MSE 0.007944263229288314 Test RE 0.042602479212534336\n",
      "75 Train Loss 0.0038740416 Test MSE 0.007636879573694104 Test RE 0.04177014966803884\n",
      "76 Train Loss 0.003661654 Test MSE 0.0071282727804163155 Test RE 0.040355266123042764\n",
      "77 Train Loss 0.0034886303 Test MSE 0.006568717544024203 Test RE 0.03873899538837678\n",
      "78 Train Loss 0.0033499114 Test MSE 0.006306256407453963 Test RE 0.03795717417295338\n",
      "79 Train Loss 0.0032331634 Test MSE 0.005785283224571567 Test RE 0.036355521007180085\n",
      "80 Train Loss 0.0030857746 Test MSE 0.005279169864190265 Test RE 0.03472888805816077\n",
      "81 Train Loss 0.0029067486 Test MSE 0.004992281151912085 Test RE 0.03377206201686687\n",
      "82 Train Loss 0.0027738237 Test MSE 0.004699599041804972 Test RE 0.032767134482440397\n",
      "83 Train Loss 0.0026569876 Test MSE 0.004901720084354131 Test RE 0.03346434383056371\n",
      "84 Train Loss 0.002526421 Test MSE 0.004737112045560253 Test RE 0.03289765098615534\n",
      "85 Train Loss 0.0023958194 Test MSE 0.004483424388038258 Test RE 0.032004642856588904\n",
      "86 Train Loss 0.0022949842 Test MSE 0.00462439186656983 Test RE 0.03250389262245363\n",
      "87 Train Loss 0.002208267 Test MSE 0.0046019046745854235 Test RE 0.032424767406545194\n",
      "88 Train Loss 0.0021306667 Test MSE 0.004409839859156686 Test RE 0.03174091701042496\n",
      "89 Train Loss 0.0020465474 Test MSE 0.00429488421079002 Test RE 0.03132447422606304\n",
      "90 Train Loss 0.001963877 Test MSE 0.004178545876253589 Test RE 0.030897308387739932\n",
      "91 Train Loss 0.0018656799 Test MSE 0.004169908016666764 Test RE 0.03086535652115388\n",
      "92 Train Loss 0.0017949265 Test MSE 0.004154590599000256 Test RE 0.030808615158904328\n",
      "93 Train Loss 0.0017259911 Test MSE 0.003988511590002327 Test RE 0.030186550613653575\n",
      "94 Train Loss 0.0016506201 Test MSE 0.0041421389631684956 Test RE 0.030762412589490327\n",
      "95 Train Loss 0.0015899858 Test MSE 0.004288475122199225 Test RE 0.031301093353199694\n",
      "96 Train Loss 0.0015543515 Test MSE 0.0042189577798511105 Test RE 0.03104635720261406\n",
      "97 Train Loss 0.0015256195 Test MSE 0.004213511710085048 Test RE 0.031026312533279497\n",
      "98 Train Loss 0.001484789 Test MSE 0.004340242251330256 Test RE 0.03148944784220487\n",
      "99 Train Loss 0.0014479315 Test MSE 0.004235958091950286 Test RE 0.031108845045238444\n",
      "Training time: 67.80\n",
      "3\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.759224 Test MSE 8.677429802371266 Test RE 1.408003112364319\n",
      "1 Train Loss 44.607956 Test MSE 9.283006438190462 Test RE 1.4563051526047477\n",
      "2 Train Loss 38.68142 Test MSE 8.739215005288676 Test RE 1.4130068666544873\n",
      "3 Train Loss 33.874905 Test MSE 8.520207150310647 Test RE 1.3951893009145209\n",
      "4 Train Loss 29.885502 Test MSE 8.884614081090245 Test RE 1.4247128598513261\n",
      "5 Train Loss 26.846088 Test MSE 8.405660801039827 Test RE 1.3857790473286464\n",
      "6 Train Loss 23.224012 Test MSE 8.49144710614677 Test RE 1.392832572747407\n",
      "7 Train Loss 20.261105 Test MSE 8.493525888047948 Test RE 1.3930030512256015\n",
      "8 Train Loss 18.063423 Test MSE 8.773144672540095 Test RE 1.4157471819358538\n",
      "9 Train Loss 15.43893 Test MSE 8.360426436606556 Test RE 1.3820452899879285\n",
      "10 Train Loss 14.0801735 Test MSE 8.44075712177501 Test RE 1.3886690690251013\n",
      "11 Train Loss 13.28738 Test MSE 8.409871483655968 Test RE 1.3861260959021184\n",
      "12 Train Loss 12.644814 Test MSE 8.347128482717453 Test RE 1.3809457235615241\n",
      "13 Train Loss 11.783201 Test MSE 8.289493160461475 Test RE 1.3761698824486293\n",
      "14 Train Loss 8.665461 Test MSE 6.674220916453952 Test RE 1.2348333467667794\n",
      "15 Train Loss 7.42862 Test MSE 6.5907085721156955 Test RE 1.227083494628071\n",
      "16 Train Loss 6.674318 Test MSE 6.401317087698871 Test RE 1.2093241631798457\n",
      "17 Train Loss 6.346166 Test MSE 6.5943218653628355 Test RE 1.227419816961547\n",
      "18 Train Loss 5.9279823 Test MSE 6.337930231941826 Test RE 1.2033218074339789\n",
      "19 Train Loss 5.4400415 Test MSE 6.170782359404416 Test RE 1.187348409810137\n",
      "20 Train Loss 4.91825 Test MSE 6.2399778124566705 Test RE 1.1939869580511966\n",
      "21 Train Loss 4.06102 Test MSE 5.607973891147192 Test RE 1.1319077977408016\n",
      "22 Train Loss 3.1025085 Test MSE 5.448165830492499 Test RE 1.1156634855582557\n",
      "23 Train Loss 2.411243 Test MSE 5.165915479598473 Test RE 1.086379866657214\n",
      "24 Train Loss 2.0204394 Test MSE 5.200428032097836 Test RE 1.0900027800021084\n",
      "25 Train Loss 1.8055834 Test MSE 5.337879603854552 Test RE 1.104313667661239\n",
      "26 Train Loss 1.677328 Test MSE 5.285499532895872 Test RE 1.0988820508472925\n",
      "27 Train Loss 1.5999926 Test MSE 5.387884112593378 Test RE 1.1094741381008268\n",
      "28 Train Loss 1.512216 Test MSE 5.454841096734123 Test RE 1.1163467495453832\n",
      "29 Train Loss 1.4502687 Test MSE 5.447775624681262 Test RE 1.1156235320964698\n",
      "30 Train Loss 1.4001219 Test MSE 5.53369218755081 Test RE 1.1243863358092248\n",
      "31 Train Loss 1.3520992 Test MSE 5.531188741099617 Test RE 1.1241319704309378\n",
      "32 Train Loss 1.3143284 Test MSE 5.543439044580033 Test RE 1.1253761280609338\n",
      "33 Train Loss 1.2748364 Test MSE 5.620564831746532 Test RE 1.1331777566970482\n",
      "34 Train Loss 1.2440975 Test MSE 5.615813783034065 Test RE 1.1326987193503923\n",
      "35 Train Loss 1.2104335 Test MSE 5.67561498767424 Test RE 1.1387136422950117\n",
      "36 Train Loss 1.1891781 Test MSE 5.695136746511586 Test RE 1.1406703122535278\n",
      "37 Train Loss 1.1649483 Test MSE 5.677310001517932 Test RE 1.1388836671562281\n",
      "38 Train Loss 1.1408318 Test MSE 5.690335023672646 Test RE 1.1401893459562447\n",
      "39 Train Loss 1.1214168 Test MSE 5.717154026626766 Test RE 1.1428730891765704\n",
      "40 Train Loss 1.1049047 Test MSE 5.737100639535924 Test RE 1.144865041636963\n",
      "41 Train Loss 1.0794144 Test MSE 5.757619125910538 Test RE 1.1469104939628594\n",
      "42 Train Loss 1.0548549 Test MSE 5.764213975031353 Test RE 1.1475671488098769\n",
      "43 Train Loss 1.0382081 Test MSE 5.789535287564725 Test RE 1.1500849304810852\n",
      "44 Train Loss 1.0246289 Test MSE 5.7743459438171945 Test RE 1.1485752662840563\n",
      "45 Train Loss 1.0132135 Test MSE 5.796163947492143 Test RE 1.1507431302023288\n",
      "46 Train Loss 1.0025926 Test MSE 5.82597522936807 Test RE 1.1536986306852728\n",
      "47 Train Loss 0.99194086 Test MSE 5.8145395112971485 Test RE 1.1525657857632667\n",
      "48 Train Loss 0.97992706 Test MSE 5.8306768825377535 Test RE 1.154164063224872\n",
      "49 Train Loss 0.96623296 Test MSE 5.864364048212442 Test RE 1.1574933952802127\n",
      "50 Train Loss 0.95415694 Test MSE 5.861189249137196 Test RE 1.1571800359436735\n",
      "51 Train Loss 0.93892217 Test MSE 5.890049634334081 Test RE 1.160025503811515\n",
      "52 Train Loss 0.9253692 Test MSE 5.910012246087478 Test RE 1.1619896257013584\n",
      "53 Train Loss 0.9133278 Test MSE 5.940942173267356 Test RE 1.1650262821847395\n",
      "54 Train Loss 0.90104246 Test MSE 5.971237736322278 Test RE 1.167993003965302\n",
      "55 Train Loss 0.89045596 Test MSE 5.967121234941276 Test RE 1.1675903342036564\n",
      "56 Train Loss 0.8806689 Test MSE 5.991972646081076 Test RE 1.1700191535505546\n",
      "57 Train Loss 0.86971784 Test MSE 6.020374472440027 Test RE 1.1727888086926668\n",
      "58 Train Loss 0.8616195 Test MSE 6.010228390550615 Test RE 1.1718001468591401\n",
      "59 Train Loss 0.8548837 Test MSE 6.023849977085441 Test RE 1.1731272797360695\n",
      "60 Train Loss 0.8489888 Test MSE 6.055423951613262 Test RE 1.1761977314537326\n",
      "61 Train Loss 0.84154785 Test MSE 6.070871348084478 Test RE 1.1776970170675487\n",
      "62 Train Loss 0.83360577 Test MSE 6.083550653495896 Test RE 1.1789262138903296\n",
      "63 Train Loss 0.82674164 Test MSE 6.084476473461468 Test RE 1.1790159174175825\n",
      "64 Train Loss 0.81785417 Test MSE 6.080476152484135 Test RE 1.1786282737472789\n",
      "65 Train Loss 0.8116715 Test MSE 6.089793749966773 Test RE 1.1795309810056898\n",
      "66 Train Loss 0.80512804 Test MSE 6.081138760166377 Test RE 1.1786924913228567\n",
      "67 Train Loss 0.8003779 Test MSE 6.087290528788133 Test RE 1.1792885318738433\n",
      "68 Train Loss 0.7948656 Test MSE 6.110661544405571 Test RE 1.1815501922327727\n",
      "69 Train Loss 0.7896795 Test MSE 6.12369783113412 Test RE 1.1828098611450604\n",
      "70 Train Loss 0.7845495 Test MSE 6.139408401343453 Test RE 1.184326160164748\n",
      "71 Train Loss 0.77993184 Test MSE 6.15690890025729 Test RE 1.1860129309546736\n",
      "72 Train Loss 0.7755181 Test MSE 6.149589443804993 Test RE 1.1853077433594787\n",
      "73 Train Loss 0.77114666 Test MSE 6.15868568603785 Test RE 1.18618405082462\n",
      "74 Train Loss 0.7643601 Test MSE 6.184719185595635 Test RE 1.1886884777765774\n",
      "75 Train Loss 0.75851643 Test MSE 6.1909066847147765 Test RE 1.1892829405184924\n",
      "76 Train Loss 0.7535599 Test MSE 6.201579204497744 Test RE 1.1903076030473663\n",
      "77 Train Loss 0.749718 Test MSE 6.22052010845674 Test RE 1.192123939889282\n",
      "78 Train Loss 0.7466529 Test MSE 6.226750298674183 Test RE 1.192720779062962\n",
      "79 Train Loss 0.7426758 Test MSE 6.2348074041947825 Test RE 1.1934921903165394\n",
      "80 Train Loss 0.7392617 Test MSE 6.235920750992585 Test RE 1.1935987462458528\n",
      "81 Train Loss 0.73526335 Test MSE 6.252673626811843 Test RE 1.1952009795299208\n",
      "82 Train Loss 0.7313663 Test MSE 6.287481096274396 Test RE 1.1985230931674489\n",
      "83 Train Loss 0.727931 Test MSE 6.264369833008041 Test RE 1.1963183244163857\n",
      "84 Train Loss 0.72395223 Test MSE 6.26087236124987 Test RE 1.1959843184561108\n",
      "85 Train Loss 0.71905446 Test MSE 6.276340361596288 Test RE 1.1974607959142634\n",
      "86 Train Loss 0.7159882 Test MSE 6.273523998423408 Test RE 1.1971920992926377\n",
      "87 Train Loss 0.7127774 Test MSE 6.293287301616949 Test RE 1.1990763564910751\n",
      "88 Train Loss 0.7093097 Test MSE 6.3046262700122435 Test RE 1.2001560918877447\n",
      "89 Train Loss 0.706168 Test MSE 6.305190447402603 Test RE 1.2002097894231587\n",
      "90 Train Loss 0.7029926 Test MSE 6.316947466078864 Test RE 1.201328258180007\n",
      "91 Train Loss 0.6998322 Test MSE 6.311698462064735 Test RE 1.2008290386314557\n",
      "92 Train Loss 0.69628733 Test MSE 6.3171072913142226 Test RE 1.2013434555010376\n",
      "93 Train Loss 0.69315183 Test MSE 6.339581890020747 Test RE 1.2034785894310482\n",
      "94 Train Loss 0.6908796 Test MSE 6.350915917144365 Test RE 1.2045539101758411\n",
      "95 Train Loss 0.6869322 Test MSE 6.343940459374011 Test RE 1.2038922242507448\n",
      "96 Train Loss 0.6841458 Test MSE 6.361646151493055 Test RE 1.2055710619595332\n",
      "97 Train Loss 0.68166333 Test MSE 6.377499074757818 Test RE 1.2070722405420826\n",
      "98 Train Loss 0.6783663 Test MSE 6.386576907667363 Test RE 1.2079310178973146\n",
      "99 Train Loss 0.67557955 Test MSE 6.397863732515707 Test RE 1.2089979186582167\n",
      "Training time: 68.12\n",
      "4\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.281013 Test MSE 8.460995247036987 Test RE 1.3903328553586443\n",
      "1 Train Loss 50.74011 Test MSE 8.824051970996031 Test RE 1.4198487679517413\n",
      "2 Train Loss 41.661537 Test MSE 7.968906380756904 Test RE 1.3492965895412465\n",
      "3 Train Loss 29.539665 Test MSE 6.134745125111366 Test RE 1.1838762887105854\n",
      "4 Train Loss 23.126251 Test MSE 5.557737758838239 Test RE 1.1268265876387953\n",
      "5 Train Loss 17.754368 Test MSE 5.668526677690591 Test RE 1.1380023469529854\n",
      "6 Train Loss 14.63603 Test MSE 5.60749094582555 Test RE 1.1318590580929706\n",
      "7 Train Loss 12.34754 Test MSE 5.121311841662532 Test RE 1.0816796790131555\n",
      "8 Train Loss 10.283878 Test MSE 4.740279828633033 Test RE 1.040662847438941\n",
      "9 Train Loss 8.648484 Test MSE 4.380627869757853 Test RE 1.0004058927055433\n",
      "10 Train Loss 6.7892036 Test MSE 3.9141699616908205 Test RE 0.9456444981761436\n",
      "11 Train Loss 5.5307207 Test MSE 3.5089029444959006 Test RE 0.8953518560305168\n",
      "12 Train Loss 4.6911316 Test MSE 3.2127924611487066 Test RE 0.8567406950406148\n",
      "13 Train Loss 3.7791953 Test MSE 2.9511246798644573 Test RE 0.8211109416302845\n",
      "14 Train Loss 3.2466855 Test MSE 2.691197438767635 Test RE 0.7841169476861594\n",
      "15 Train Loss 2.8310602 Test MSE 2.2444723979331758 Test RE 0.7160860192824717\n",
      "16 Train Loss 2.3653924 Test MSE 1.8778413207577278 Test RE 0.6549942777822165\n",
      "17 Train Loss 2.014497 Test MSE 1.7949281950977205 Test RE 0.6403709173619901\n",
      "18 Train Loss 1.6383446 Test MSE 1.6272998683936988 Test RE 0.6097360246641732\n",
      "19 Train Loss 1.3957814 Test MSE 1.3446213207448974 Test RE 0.5542530056508402\n",
      "20 Train Loss 1.1164683 Test MSE 0.9567329061272162 Test RE 0.46752346824743934\n",
      "21 Train Loss 0.85135525 Test MSE 0.7456173015475371 Test RE 0.41273001072938836\n",
      "22 Train Loss 0.62677985 Test MSE 0.5862110129416901 Test RE 0.3659612032411015\n",
      "23 Train Loss 0.45998523 Test MSE 0.44206640029247457 Test RE 0.31779847866483024\n",
      "24 Train Loss 0.3238108 Test MSE 0.27701322701946607 Test RE 0.2515696893952995\n",
      "25 Train Loss 0.23846923 Test MSE 0.21618006485578772 Test RE 0.22223675224154069\n",
      "26 Train Loss 0.18869685 Test MSE 0.19931998932277006 Test RE 0.21339463075537782\n",
      "27 Train Loss 0.15487438 Test MSE 0.16773425564115052 Test RE 0.19575774029702242\n",
      "28 Train Loss 0.13043398 Test MSE 0.15722860149980036 Test RE 0.18952819913867894\n",
      "29 Train Loss 0.11174047 Test MSE 0.139422197124022 Test RE 0.17847361544109505\n",
      "30 Train Loss 0.0954712 Test MSE 0.11789436294978364 Test RE 0.1641173819323478\n",
      "31 Train Loss 0.079753526 Test MSE 0.1055450530720613 Test RE 0.15528410439105073\n",
      "32 Train Loss 0.07141891 Test MSE 0.08862763024661345 Test RE 0.14229597929322485\n",
      "33 Train Loss 0.06403345 Test MSE 0.0671782529652529 Test RE 0.12388605197506908\n",
      "34 Train Loss 0.057060894 Test MSE 0.055587776716342734 Test RE 0.11269320034238856\n",
      "35 Train Loss 0.049937136 Test MSE 0.05411972680313206 Test RE 0.11119515334173748\n",
      "36 Train Loss 0.04490134 Test MSE 0.05614915034593311 Test RE 0.11326080778173224\n",
      "37 Train Loss 0.041751422 Test MSE 0.05183942972721238 Test RE 0.10882737854810284\n",
      "38 Train Loss 0.038407125 Test MSE 0.04517272483966834 Test RE 0.10158888749684838\n",
      "39 Train Loss 0.03368536 Test MSE 0.03947911274326123 Test RE 0.0949711620857841\n",
      "40 Train Loss 0.028765677 Test MSE 0.03115687053607483 Test RE 0.08436940282400182\n",
      "41 Train Loss 0.026030421 Test MSE 0.027167546437879584 Test RE 0.07878313694417044\n",
      "42 Train Loss 0.022467718 Test MSE 0.024350308012956644 Test RE 0.07458651058358014\n",
      "43 Train Loss 0.020389015 Test MSE 0.02124050280876553 Test RE 0.06966112067336189\n",
      "44 Train Loss 0.018651938 Test MSE 0.018998354646462264 Test RE 0.06588189090031824\n",
      "45 Train Loss 0.016820839 Test MSE 0.016678818189646782 Test RE 0.06172920695927547\n",
      "46 Train Loss 0.015041827 Test MSE 0.014659219957856592 Test RE 0.057871333667370475\n",
      "47 Train Loss 0.013640089 Test MSE 0.01269830267176353 Test RE 0.0538618042914134\n",
      "48 Train Loss 0.012464758 Test MSE 0.010853352740761858 Test RE 0.04979549103503527\n",
      "49 Train Loss 0.011085591 Test MSE 0.009945646069818645 Test RE 0.047667739836832576\n",
      "50 Train Loss 0.010067457 Test MSE 0.00949917185211323 Test RE 0.04658551839737328\n",
      "51 Train Loss 0.0089043295 Test MSE 0.00778076797248352 Test RE 0.04216181444276627\n",
      "52 Train Loss 0.008295157 Test MSE 0.007189032295768355 Test RE 0.040526889997335766\n",
      "53 Train Loss 0.0075819604 Test MSE 0.006215929568963436 Test RE 0.03768435642333108\n",
      "54 Train Loss 0.0070738737 Test MSE 0.0056511513360266875 Test RE 0.03593159774830954\n",
      "55 Train Loss 0.006559927 Test MSE 0.005285011513717781 Test RE 0.0347480973189311\n",
      "56 Train Loss 0.0058667324 Test MSE 0.004637191080067813 Test RE 0.03254884305127652\n",
      "57 Train Loss 0.00549489 Test MSE 0.004778629051199011 Test RE 0.03304149732415749\n",
      "58 Train Loss 0.0052443454 Test MSE 0.0053376876446164555 Test RE 0.03492083648733574\n",
      "59 Train Loss 0.0050025433 Test MSE 0.0054787218735037335 Test RE 0.035379173848530635\n",
      "60 Train Loss 0.004784784 Test MSE 0.0052327746118349 Test RE 0.03457594628107633\n",
      "61 Train Loss 0.004603869 Test MSE 0.005389681391516002 Test RE 0.035090504058519066\n",
      "62 Train Loss 0.0044075027 Test MSE 0.00556362037186776 Test RE 0.03565223862240882\n",
      "63 Train Loss 0.004131058 Test MSE 0.005441113454044302 Test RE 0.035257535435955736\n",
      "64 Train Loss 0.0039013934 Test MSE 0.005266464757349499 Test RE 0.03468707276915991\n",
      "65 Train Loss 0.0037694992 Test MSE 0.005181961811643165 Test RE 0.03440766208137708\n",
      "66 Train Loss 0.003661551 Test MSE 0.004974748724577414 Test RE 0.033712707688096706\n",
      "67 Train Loss 0.0034161792 Test MSE 0.004736724616465897 Test RE 0.032896305676226326\n",
      "68 Train Loss 0.0032658037 Test MSE 0.004722071113450847 Test RE 0.03284538235420502\n",
      "69 Train Loss 0.003044087 Test MSE 0.004518799592686179 Test RE 0.032130656612044124\n",
      "70 Train Loss 0.002892614 Test MSE 0.004300412132931725 Test RE 0.03134462652399472\n",
      "71 Train Loss 0.0028078689 Test MSE 0.004176032185162837 Test RE 0.030888013530739434\n",
      "72 Train Loss 0.0027156824 Test MSE 0.004104804170489317 Test RE 0.030623461671887314\n",
      "73 Train Loss 0.0025990668 Test MSE 0.004021970291999163 Test RE 0.0303129001862496\n",
      "74 Train Loss 0.0025149728 Test MSE 0.0039154493598051385 Test RE 0.029908791554110963\n",
      "75 Train Loss 0.002440238 Test MSE 0.00381900745828134 Test RE 0.029538151493235156\n",
      "76 Train Loss 0.0023524235 Test MSE 0.0036243951661571695 Test RE 0.028775695655092633\n",
      "77 Train Loss 0.0022367525 Test MSE 0.0035313553512853705 Test RE 0.028403952070200602\n",
      "78 Train Loss 0.0021216702 Test MSE 0.00358288806014904 Test RE 0.028610449439316517\n",
      "79 Train Loss 0.0020329938 Test MSE 0.0035010101064284985 Test RE 0.028281649945072696\n",
      "80 Train Loss 0.0019588359 Test MSE 0.003436194137520802 Test RE 0.02801863066870087\n",
      "81 Train Loss 0.0019134453 Test MSE 0.0034159967004536527 Test RE 0.02793616464153035\n",
      "82 Train Loss 0.0018655255 Test MSE 0.0034353173121870755 Test RE 0.028015055636027655\n",
      "83 Train Loss 0.0017931439 Test MSE 0.0035095034588062475 Test RE 0.02831593440936833\n",
      "84 Train Loss 0.0017323836 Test MSE 0.0035245108493556906 Test RE 0.02837641233276104\n",
      "85 Train Loss 0.0016518624 Test MSE 0.003478843071157382 Test RE 0.028191973562996322\n",
      "86 Train Loss 0.0015959472 Test MSE 0.003423779705177047 Test RE 0.02796797140464265\n",
      "87 Train Loss 0.0015613537 Test MSE 0.0034143521898503566 Test RE 0.027929439393596295\n",
      "88 Train Loss 0.0015171653 Test MSE 0.003395077045049564 Test RE 0.02785049236453872\n",
      "89 Train Loss 0.0014688547 Test MSE 0.0033480795563547556 Test RE 0.02765705572949388\n",
      "90 Train Loss 0.00143003 Test MSE 0.0033021277143255798 Test RE 0.027466605724233584\n",
      "91 Train Loss 0.0014059163 Test MSE 0.003263646898309453 Test RE 0.027306097897292825\n",
      "92 Train Loss 0.0013813997 Test MSE 0.0032536012243924435 Test RE 0.027264040718140634\n",
      "93 Train Loss 0.0013451476 Test MSE 0.0032959102450463447 Test RE 0.027440735549989076\n",
      "94 Train Loss 0.0013082189 Test MSE 0.003276581967885414 Test RE 0.02736015659395695\n",
      "95 Train Loss 0.0012668875 Test MSE 0.0031868103020113382 Test RE 0.026982747324238082\n",
      "96 Train Loss 0.0012432791 Test MSE 0.003176379535550608 Test RE 0.026938552441066136\n",
      "97 Train Loss 0.001215323 Test MSE 0.003108987947628663 Test RE 0.02665124977509249\n",
      "98 Train Loss 0.0011918761 Test MSE 0.0029818237298036747 Test RE 0.026100513011658735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0011601165 Test MSE 0.0028925397025462074 Test RE 0.02570678259202765\n",
      "Training time: 67.32\n",
      "5\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.02444 Test MSE 8.59121155408944 Test RE 1.4009907471668934\n",
      "1 Train Loss 57.45748 Test MSE 8.6474844759841 Test RE 1.4055715426337876\n",
      "2 Train Loss 54.70891 Test MSE 8.478345636477945 Test RE 1.391757655969951\n",
      "3 Train Loss 45.484047 Test MSE 8.100124951879096 Test RE 1.3603602066697764\n",
      "4 Train Loss 43.073605 Test MSE 8.040154163618572 Test RE 1.355315010599141\n",
      "5 Train Loss 36.390568 Test MSE 8.51176804195463 Test RE 1.3944981750741972\n",
      "6 Train Loss 31.048512 Test MSE 8.160364932362384 Test RE 1.365409281616117\n",
      "7 Train Loss 29.599152 Test MSE 8.229265909292197 Test RE 1.3711614927151277\n",
      "8 Train Loss 27.332718 Test MSE 7.955564616089125 Test RE 1.3481666014425302\n",
      "9 Train Loss 24.862116 Test MSE 8.31900063033045 Test RE 1.3786170295822375\n",
      "10 Train Loss 22.660065 Test MSE 8.493233667073913 Test RE 1.3929790877847896\n",
      "11 Train Loss 20.250753 Test MSE 8.087232601078954 Test RE 1.3592771847884897\n",
      "12 Train Loss 17.197863 Test MSE 7.926839970169403 Test RE 1.345730531257478\n",
      "13 Train Loss 15.742924 Test MSE 7.9532004134045495 Test RE 1.3479662651944098\n",
      "14 Train Loss 14.607265 Test MSE 8.22274342314745 Test RE 1.3706179962014269\n",
      "15 Train Loss 13.71026 Test MSE 8.353639368586453 Test RE 1.3814841978036274\n",
      "16 Train Loss 12.61611 Test MSE 8.492355293288645 Test RE 1.3929070546817979\n",
      "17 Train Loss 11.2031975 Test MSE 8.463576382518875 Test RE 1.3905449086521138\n",
      "18 Train Loss 9.567603 Test MSE 8.020362888073237 Test RE 1.3536458921066221\n",
      "19 Train Loss 7.642911 Test MSE 7.862768010740331 Test RE 1.3402807849198872\n",
      "20 Train Loss 5.253867 Test MSE 7.042638746684222 Test RE 1.268457048766449\n",
      "21 Train Loss 3.9210992 Test MSE 6.912184609174015 Test RE 1.2566540192579694\n",
      "22 Train Loss 3.2640467 Test MSE 7.094603235980545 Test RE 1.273128137458054\n",
      "23 Train Loss 2.7934506 Test MSE 7.137849233311269 Test RE 1.2770024942241949\n",
      "24 Train Loss 2.5805671 Test MSE 7.11703843676621 Test RE 1.2751395494450437\n",
      "25 Train Loss 2.4196315 Test MSE 7.139157656954296 Test RE 1.2771195311380898\n",
      "26 Train Loss 2.271427 Test MSE 7.097966781428067 Test RE 1.2734298961878223\n",
      "27 Train Loss 2.1283488 Test MSE 7.104742306188391 Test RE 1.274037541869299\n",
      "28 Train Loss 2.0397446 Test MSE 7.1482651427656405 Test RE 1.2779338877736446\n",
      "29 Train Loss 1.9526932 Test MSE 7.224870865485695 Test RE 1.2847632484754046\n",
      "30 Train Loss 1.8612399 Test MSE 7.264961612694339 Test RE 1.288322887394605\n",
      "31 Train Loss 1.7745978 Test MSE 7.209007636631944 Test RE 1.283352033439353\n",
      "32 Train Loss 1.7006412 Test MSE 7.151204650085072 Test RE 1.2781966165501342\n",
      "33 Train Loss 1.6334257 Test MSE 7.135441398513936 Test RE 1.2767870882738726\n",
      "34 Train Loss 1.5690947 Test MSE 7.078172831007947 Test RE 1.2716530630075358\n",
      "35 Train Loss 1.4996524 Test MSE 6.999676416197732 Test RE 1.2645821349808481\n",
      "36 Train Loss 1.4244801 Test MSE 6.989381080392698 Test RE 1.2636517999355987\n",
      "37 Train Loss 1.3815193 Test MSE 6.9548348824533095 Test RE 1.2605250251398394\n",
      "38 Train Loss 1.3329183 Test MSE 6.892826620615496 Test RE 1.2548931179505929\n",
      "39 Train Loss 1.283926 Test MSE 6.769131582902297 Test RE 1.2435823181923278\n",
      "40 Train Loss 1.2474253 Test MSE 6.58798823595978 Test RE 1.226830227162053\n",
      "41 Train Loss 1.2077633 Test MSE 6.424348232670904 Test RE 1.2114977090756973\n",
      "42 Train Loss 1.183937 Test MSE 6.3692324136972465 Test RE 1.2062896694554373\n",
      "43 Train Loss 1.1589121 Test MSE 6.276465357577513 Test RE 1.197472719824801\n",
      "44 Train Loss 1.1328672 Test MSE 6.161502990213248 Test RE 1.1864553310420052\n",
      "45 Train Loss 1.1118205 Test MSE 6.068292754253395 Test RE 1.1774468779502125\n",
      "46 Train Loss 1.0838552 Test MSE 5.963374510325146 Test RE 1.1672237146736097\n",
      "47 Train Loss 1.0610756 Test MSE 5.89294605236073 Test RE 1.160310688659918\n",
      "48 Train Loss 1.0387536 Test MSE 5.855402621360361 Test RE 1.1566086652356882\n",
      "49 Train Loss 1.0111339 Test MSE 5.880837423350441 Test RE 1.1591179918139147\n",
      "50 Train Loss 0.98118675 Test MSE 5.930934374076388 Test RE 1.1640445975406222\n",
      "51 Train Loss 0.94735384 Test MSE 5.91793677802635 Test RE 1.1627684006715562\n",
      "52 Train Loss 0.91675884 Test MSE 5.9132247368529836 Test RE 1.1623053927130302\n",
      "53 Train Loss 0.8868291 Test MSE 5.965679666524055 Test RE 1.1674492893888468\n",
      "54 Train Loss 0.86954015 Test MSE 6.011859606056165 Test RE 1.1719591532035543\n",
      "55 Train Loss 0.85584027 Test MSE 6.053799314466345 Test RE 1.1760399371580934\n",
      "56 Train Loss 0.84182924 Test MSE 6.070361939221894 Test RE 1.1776476055540175\n",
      "57 Train Loss 0.8279967 Test MSE 6.110675174881772 Test RE 1.1815515100183085\n",
      "58 Train Loss 0.8153543 Test MSE 6.120210826080772 Test RE 1.1824730506597736\n",
      "59 Train Loss 0.8036904 Test MSE 6.125900784646981 Test RE 1.1830225954201432\n",
      "60 Train Loss 0.7929994 Test MSE 6.170386845229988 Test RE 1.1873103578562778\n",
      "61 Train Loss 0.783458 Test MSE 6.191888616188054 Test RE 1.189377252071508\n",
      "62 Train Loss 0.77525365 Test MSE 6.207463290188517 Test RE 1.1908721537178757\n",
      "63 Train Loss 0.76502556 Test MSE 6.230731986917409 Test RE 1.1931020600784137\n",
      "64 Train Loss 0.7558508 Test MSE 6.244096045192486 Test RE 1.1943808941594685\n",
      "65 Train Loss 0.74537534 Test MSE 6.2873725152412945 Test RE 1.1985127442347432\n",
      "66 Train Loss 0.73806244 Test MSE 6.302848687652838 Test RE 1.1999868886231044\n",
      "67 Train Loss 0.7304431 Test MSE 6.314286858277843 Test RE 1.2010752404069094\n",
      "68 Train Loss 0.7214579 Test MSE 6.349582756500208 Test RE 1.20442747580237\n",
      "69 Train Loss 0.71433085 Test MSE 6.333510339175766 Test RE 1.202902153009524\n",
      "70 Train Loss 0.7067425 Test MSE 6.343594857434656 Test RE 1.203859431292104\n",
      "71 Train Loss 0.70091647 Test MSE 6.3694879087619745 Test RE 1.2063138637339965\n",
      "72 Train Loss 0.6955925 Test MSE 6.372797676807802 Test RE 1.2066272406177871\n",
      "73 Train Loss 0.6902126 Test MSE 6.39571807422309 Test RE 1.2087951702056805\n",
      "74 Train Loss 0.6844563 Test MSE 6.439962195948236 Test RE 1.2129690490702034\n",
      "75 Train Loss 0.67905796 Test MSE 6.460096228180743 Test RE 1.2148636952373422\n",
      "76 Train Loss 0.6733629 Test MSE 6.478005697207263 Test RE 1.2165465265818916\n",
      "77 Train Loss 0.66845983 Test MSE 6.494593855707804 Test RE 1.2181031294328233\n",
      "78 Train Loss 0.6641405 Test MSE 6.513686135415744 Test RE 1.2198922558554413\n",
      "79 Train Loss 0.65866107 Test MSE 6.5212922531552096 Test RE 1.220604290240889\n",
      "80 Train Loss 0.6525929 Test MSE 6.545265096734795 Test RE 1.2228457565081383\n",
      "81 Train Loss 0.6466979 Test MSE 6.557591175537362 Test RE 1.2239966498081754\n",
      "82 Train Loss 0.64143807 Test MSE 6.55142103469026 Test RE 1.2234206754249606\n",
      "83 Train Loss 0.63583016 Test MSE 6.572369808516552 Test RE 1.2253751145973941\n",
      "84 Train Loss 0.62973344 Test MSE 6.592810059793004 Test RE 1.2272791105689762\n",
      "85 Train Loss 0.62445945 Test MSE 6.609997931334257 Test RE 1.228877866247228\n",
      "86 Train Loss 0.6188604 Test MSE 6.632567540966165 Test RE 1.2309740589425164\n",
      "87 Train Loss 0.6142815 Test MSE 6.632968892143414 Test RE 1.2310113028462417\n",
      "88 Train Loss 0.6098658 Test MSE 6.663595832795094 Test RE 1.2338500534621433\n",
      "89 Train Loss 0.6057464 Test MSE 6.696508537684893 Test RE 1.2368934044499913\n",
      "90 Train Loss 0.6017246 Test MSE 6.707175790940269 Test RE 1.2378781717231189\n",
      "91 Train Loss 0.59736484 Test MSE 6.731279454856509 Test RE 1.2401004662959845\n",
      "92 Train Loss 0.59353495 Test MSE 6.733601208016395 Test RE 1.2403143156068215\n",
      "93 Train Loss 0.5892174 Test MSE 6.742640902802518 Test RE 1.2411465821793028\n",
      "94 Train Loss 0.5854762 Test MSE 6.770682721685328 Test RE 1.24372479276587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.58122873 Test MSE 6.777788211442015 Test RE 1.2443772348301292\n",
      "96 Train Loss 0.5776131 Test MSE 6.796080244938043 Test RE 1.24605527877858\n",
      "97 Train Loss 0.57377595 Test MSE 6.802136667264447 Test RE 1.2466103749637534\n",
      "98 Train Loss 0.5684726 Test MSE 6.819131580666504 Test RE 1.2481667108445027\n",
      "99 Train Loss 0.56370306 Test MSE 6.845039722039964 Test RE 1.2505355625112935\n",
      "Training time: 67.62\n",
      "6\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.33217 Test MSE 8.399341592121207 Test RE 1.3852580488027004\n",
      "1 Train Loss 58.81402 Test MSE 8.566444800872619 Test RE 1.398969900931352\n",
      "2 Train Loss 58.52974 Test MSE 8.401849035570814 Test RE 1.3854648029267942\n",
      "3 Train Loss 54.90532 Test MSE 8.465760058019253 Test RE 1.3907242833559346\n",
      "4 Train Loss 48.598984 Test MSE 8.586096890979244 Test RE 1.400573654510627\n",
      "5 Train Loss 47.285828 Test MSE 8.692640884790883 Test RE 1.4092366500743752\n",
      "6 Train Loss 46.14496 Test MSE 8.34336211427372 Test RE 1.380634135136169\n",
      "7 Train Loss 45.351433 Test MSE 8.355443129563422 Test RE 1.3816333383564245\n",
      "8 Train Loss 44.937023 Test MSE 8.46711519714725 Test RE 1.390835587566448\n",
      "9 Train Loss 44.30014 Test MSE 8.41782722790633 Test RE 1.386781579040442\n",
      "10 Train Loss 43.850174 Test MSE 8.483552250939516 Test RE 1.3921849346916586\n",
      "11 Train Loss 42.54944 Test MSE 8.52354599742359 Test RE 1.3954626432997275\n",
      "12 Train Loss 38.339462 Test MSE 7.652344278887825 Test RE 1.3222248364889244\n",
      "13 Train Loss 33.582634 Test MSE 7.101412437749013 Test RE 1.2737389473237872\n",
      "14 Train Loss 30.766872 Test MSE 6.718294539039835 Test RE 1.2389037864217258\n",
      "15 Train Loss 27.897602 Test MSE 6.496714265343018 Test RE 1.2183019614833115\n",
      "16 Train Loss 23.882805 Test MSE 6.666916917695833 Test RE 1.2341574858488158\n",
      "17 Train Loss 20.927025 Test MSE 6.198498349796765 Test RE 1.1900119025317981\n",
      "18 Train Loss 18.179672 Test MSE 5.754839120194954 Test RE 1.1466335737094382\n",
      "19 Train Loss 15.9404955 Test MSE 5.6494517073170725 Test RE 1.136086006538751\n",
      "20 Train Loss 13.113569 Test MSE 5.023623811574904 Test RE 1.0713135931972544\n",
      "21 Train Loss 10.602958 Test MSE 4.197461144977215 Test RE 0.9792676381285137\n",
      "22 Train Loss 8.801658 Test MSE 3.238876699928647 Test RE 0.8602115468582273\n",
      "23 Train Loss 7.0820775 Test MSE 1.9482709199963668 Test RE 0.6671642005867332\n",
      "24 Train Loss 5.968598 Test MSE 1.5886666297095038 Test RE 0.6024547694056617\n",
      "25 Train Loss 5.4507937 Test MSE 1.219762886801896 Test RE 0.5278928354987339\n",
      "26 Train Loss 4.4730754 Test MSE 0.8617384147308912 Test RE 0.4437064960295845\n",
      "27 Train Loss 4.0237217 Test MSE 0.74527600733196 Test RE 0.4126355396863881\n",
      "28 Train Loss 3.5922787 Test MSE 0.5441284679542148 Test RE 0.3525809018836214\n",
      "29 Train Loss 3.241955 Test MSE 0.4663008024793732 Test RE 0.32639322970157214\n",
      "30 Train Loss 2.9031806 Test MSE 0.45191386406447936 Test RE 0.32131861979639537\n",
      "31 Train Loss 2.642943 Test MSE 0.403644855164783 Test RE 0.3036741125291232\n",
      "32 Train Loss 2.383555 Test MSE 0.3524404755382853 Test RE 0.2837598523959774\n",
      "33 Train Loss 2.1634965 Test MSE 0.33284795032976106 Test RE 0.27575983068135623\n",
      "34 Train Loss 1.9222946 Test MSE 0.2621794839431442 Test RE 0.2447413844536267\n",
      "35 Train Loss 1.7546046 Test MSE 0.2488042370288552 Test RE 0.23841685029153808\n",
      "36 Train Loss 1.6230808 Test MSE 0.2616225653719428 Test RE 0.24448130788446099\n",
      "37 Train Loss 1.4461715 Test MSE 0.2485284463567452 Test RE 0.23828467534240477\n",
      "38 Train Loss 1.2205039 Test MSE 0.20635125284000658 Test RE 0.21712589182148795\n",
      "39 Train Loss 1.0793827 Test MSE 0.1786249641305596 Test RE 0.20201291598518958\n",
      "40 Train Loss 0.95243907 Test MSE 0.18054830718199305 Test RE 0.20309759032674995\n",
      "41 Train Loss 0.8032284 Test MSE 0.17018997437129266 Test RE 0.19718553210430265\n",
      "42 Train Loss 0.7203214 Test MSE 0.14520663533194986 Test RE 0.18213830530992897\n",
      "43 Train Loss 0.6167024 Test MSE 0.11519120279182196 Test RE 0.16222497534110128\n",
      "44 Train Loss 0.5445174 Test MSE 0.10145006979714984 Test RE 0.15224191401941378\n",
      "45 Train Loss 0.48915404 Test MSE 0.09919097062999548 Test RE 0.15053730275190655\n",
      "46 Train Loss 0.33640537 Test MSE 0.06036785916346779 Test RE 0.11743862225099962\n",
      "47 Train Loss 0.28948224 Test MSE 0.04817439921685907 Test RE 0.10490983740018872\n",
      "48 Train Loss 0.25646105 Test MSE 0.05112714076031706 Test RE 0.10807713243565806\n",
      "49 Train Loss 0.23168814 Test MSE 0.050468088746904435 Test RE 0.10737829142964224\n",
      "50 Train Loss 0.19915746 Test MSE 0.04210522996644227 Test RE 0.09807901195405302\n",
      "51 Train Loss 0.17461804 Test MSE 0.04185656558805133 Test RE 0.09778896637107061\n",
      "52 Train Loss 0.14960001 Test MSE 0.036653737712378134 Test RE 0.0915097131879326\n",
      "53 Train Loss 0.1323334 Test MSE 0.03116756156963462 Test RE 0.08438387665815146\n",
      "54 Train Loss 0.12001592 Test MSE 0.030524804682880234 Test RE 0.08350923535942899\n",
      "55 Train Loss 0.11154722 Test MSE 0.028342851714780917 Test RE 0.08046922758339703\n",
      "56 Train Loss 0.10273149 Test MSE 0.02483539589511697 Test RE 0.07532577418412928\n",
      "57 Train Loss 0.091107525 Test MSE 0.02386937896005942 Test RE 0.07384627955948131\n",
      "58 Train Loss 0.086240515 Test MSE 0.024084540141944423 Test RE 0.07417836208512782\n",
      "59 Train Loss 0.08210001 Test MSE 0.021688081489222213 Test RE 0.07039124206380128\n",
      "60 Train Loss 0.07628527 Test MSE 0.018126909955765543 Test RE 0.06435317061190056\n",
      "61 Train Loss 0.07225415 Test MSE 0.01718560595259163 Test RE 0.062660013644175\n",
      "62 Train Loss 0.06528703 Test MSE 0.015204619816243308 Test RE 0.05893806086604482\n",
      "63 Train Loss 0.05885252 Test MSE 0.014221731516522554 Test RE 0.057001239304304424\n",
      "64 Train Loss 0.056284294 Test MSE 0.0132511117005867 Test RE 0.05502172699940712\n",
      "65 Train Loss 0.05377993 Test MSE 0.011964124734063743 Test RE 0.05228155862852977\n",
      "66 Train Loss 0.04627575 Test MSE 0.008409153269356696 Test RE 0.04383128412737569\n",
      "67 Train Loss 0.04411981 Test MSE 0.0075559999657933774 Test RE 0.041548374155869684\n",
      "68 Train Loss 0.042118464 Test MSE 0.006921575778027306 Test RE 0.039765875571128914\n",
      "69 Train Loss 0.03919504 Test MSE 0.006109256268693535 Test RE 0.03735960121680912\n",
      "70 Train Loss 0.036933944 Test MSE 0.005843017407519588 Test RE 0.03653647547028505\n",
      "71 Train Loss 0.035699245 Test MSE 0.0052548601573113645 Test RE 0.03464883539251147\n",
      "72 Train Loss 0.033512328 Test MSE 0.004860836523079492 Test RE 0.033324494319888\n",
      "73 Train Loss 0.0323303 Test MSE 0.004941986769850996 Test RE 0.03360151426608217\n",
      "74 Train Loss 0.031417288 Test MSE 0.004817555607351581 Test RE 0.033175801847771\n",
      "75 Train Loss 0.029905658 Test MSE 0.004679044838835907 Test RE 0.03269540066531811\n",
      "76 Train Loss 0.027353613 Test MSE 0.0037864841426792687 Test RE 0.02941210660916746\n",
      "77 Train Loss 0.025452768 Test MSE 0.0031114315375443454 Test RE 0.026661721339263252\n",
      "78 Train Loss 0.022019945 Test MSE 0.0029325655622700394 Test RE 0.02588403184180662\n",
      "79 Train Loss 0.019190954 Test MSE 0.0028497818502554576 Test RE 0.02551607490406035\n",
      "80 Train Loss 0.017776735 Test MSE 0.0030995101353683886 Test RE 0.02661059533210787\n",
      "81 Train Loss 0.016633566 Test MSE 0.0033515242481713765 Test RE 0.027671279636027595\n",
      "82 Train Loss 0.015731437 Test MSE 0.0031940863831756467 Test RE 0.027013533079429223\n",
      "83 Train Loss 0.01519085 Test MSE 0.0030304013693582816 Test RE 0.02631225910111875\n",
      "84 Train Loss 0.014335127 Test MSE 0.0027947016721708924 Test RE 0.02526828622360263\n",
      "85 Train Loss 0.013014186 Test MSE 0.0022790219856676022 Test RE 0.022818249142554346\n",
      "86 Train Loss 0.011927322 Test MSE 0.002137036367161817 Test RE 0.022096018085917955\n",
      "87 Train Loss 0.011306741 Test MSE 0.0020989199985832685 Test RE 0.021898078235799628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Train Loss 0.011061341 Test MSE 0.002101864069436572 Test RE 0.021913430631929336\n",
      "89 Train Loss 0.010581246 Test MSE 0.0020466252819789765 Test RE 0.021623561589965097\n",
      "90 Train Loss 0.009892335 Test MSE 0.001861928614393371 Test RE 0.02062479181083787\n",
      "91 Train Loss 0.009201978 Test MSE 0.00177017669225902 Test RE 0.0201101990546282\n",
      "92 Train Loss 0.008847086 Test MSE 0.0017616209375976959 Test RE 0.020061541105702425\n",
      "93 Train Loss 0.008644323 Test MSE 0.0018025874970207276 Test RE 0.02029346643347091\n",
      "94 Train Loss 0.008329059 Test MSE 0.00176045936202261 Test RE 0.02005492593716867\n",
      "95 Train Loss 0.007920616 Test MSE 0.001589750555086439 Test RE 0.019057790694696444\n",
      "96 Train Loss 0.0072589484 Test MSE 0.0016099953957690065 Test RE 0.019178753499942004\n",
      "97 Train Loss 0.006866184 Test MSE 0.00158350342416289 Test RE 0.019020308806239703\n",
      "98 Train Loss 0.0066351052 Test MSE 0.0014242821419118742 Test RE 0.018038734843010065\n",
      "99 Train Loss 0.006531889 Test MSE 0.0014401923175932532 Test RE 0.018139207349157135\n",
      "Training time: 67.02\n",
      "7\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.7943 Test MSE 8.482021246880878 Test RE 1.3920593070715963\n",
      "1 Train Loss 54.254196 Test MSE 8.357784915668157 Test RE 1.3818269404809276\n",
      "2 Train Loss 48.63434 Test MSE 8.044152697938426 Test RE 1.3556519817480892\n",
      "3 Train Loss 43.83779 Test MSE 8.038073756939058 Test RE 1.355139653960333\n",
      "4 Train Loss 40.905533 Test MSE 7.4165589683790785 Test RE 1.3016951518748086\n",
      "5 Train Loss 30.20332 Test MSE 6.326709457817311 Test RE 1.2022561453699288\n",
      "6 Train Loss 25.294361 Test MSE 5.4489409679165774 Test RE 1.115742848208903\n",
      "7 Train Loss 20.286377 Test MSE 5.503430198239378 Test RE 1.1213076666937993\n",
      "8 Train Loss 15.696972 Test MSE 5.524663331083703 Test RE 1.1234686784039076\n",
      "9 Train Loss 12.742575 Test MSE 5.5097255184261344 Test RE 1.1219488098546602\n",
      "10 Train Loss 10.7806 Test MSE 5.492497996864091 Test RE 1.120193411180904\n",
      "11 Train Loss 9.299862 Test MSE 5.332703756193328 Test RE 1.1037781417619423\n",
      "12 Train Loss 7.665863 Test MSE 5.236751028615282 Test RE 1.093802781972955\n",
      "13 Train Loss 6.4588346 Test MSE 5.19808011314967 Test RE 1.089756691882533\n",
      "14 Train Loss 5.4646225 Test MSE 4.9987891661327595 Test RE 1.0686622544862372\n",
      "15 Train Loss 4.69096 Test MSE 4.709366547922195 Test RE 1.0372640055456055\n",
      "16 Train Loss 3.9935684 Test MSE 4.503516518567157 Test RE 1.0143409068882847\n",
      "17 Train Loss 3.3351383 Test MSE 3.989341614651572 Test RE 0.9546818674192952\n",
      "18 Train Loss 2.8153045 Test MSE 3.4482451658557975 Test RE 0.8875792247401265\n",
      "19 Train Loss 2.4514303 Test MSE 3.1731680102201474 Test RE 0.8514410681275442\n",
      "20 Train Loss 2.0727599 Test MSE 2.9443092042897963 Test RE 0.8201622361395844\n",
      "21 Train Loss 1.8692279 Test MSE 2.8311205036844225 Test RE 0.8042429041529873\n",
      "22 Train Loss 1.7094572 Test MSE 2.6497588224007136 Test RE 0.7780566764006103\n",
      "23 Train Loss 1.5950185 Test MSE 2.507952906712229 Test RE 0.7569509683467142\n",
      "24 Train Loss 1.4545082 Test MSE 2.155242310403824 Test RE 0.70170749034971\n",
      "25 Train Loss 1.2966331 Test MSE 1.7289660720727464 Test RE 0.6284942313024898\n",
      "26 Train Loss 1.0617682 Test MSE 1.1604929116071536 Test RE 0.5149076050918907\n",
      "27 Train Loss 0.791964 Test MSE 0.8370584652828893 Test RE 0.43730652424142363\n",
      "28 Train Loss 0.5752472 Test MSE 0.6534560574175092 Test RE 0.3863814378941354\n",
      "29 Train Loss 0.42698863 Test MSE 0.44314092827323254 Test RE 0.31818447961265334\n",
      "30 Train Loss 0.2798008 Test MSE 0.2641091843642322 Test RE 0.24564040925819705\n",
      "31 Train Loss 0.20659715 Test MSE 0.2476851254743964 Test RE 0.2378800512348462\n",
      "32 Train Loss 0.15326783 Test MSE 0.2072055080576297 Test RE 0.2175748577369846\n",
      "33 Train Loss 0.1226192 Test MSE 0.18884805161466367 Test RE 0.20771330429131457\n",
      "34 Train Loss 0.10099696 Test MSE 0.1692510109299697 Test RE 0.19664082878544029\n",
      "35 Train Loss 0.084959105 Test MSE 0.14710143339183965 Test RE 0.18332281296876365\n",
      "36 Train Loss 0.07145879 Test MSE 0.13394121415635993 Test RE 0.1749303543978715\n",
      "37 Train Loss 0.05962261 Test MSE 0.12472286762420487 Test RE 0.16880336666286078\n",
      "38 Train Loss 0.05422846 Test MSE 0.11739513439129502 Test RE 0.16376953237328334\n",
      "39 Train Loss 0.049955547 Test MSE 0.10903632406156501 Test RE 0.15783149169611213\n",
      "40 Train Loss 0.043873817 Test MSE 0.09597575981706284 Test RE 0.14807742028096277\n",
      "41 Train Loss 0.038449824 Test MSE 0.08422032838611788 Test RE 0.1387127959110865\n",
      "42 Train Loss 0.03494309 Test MSE 0.07473378090901862 Test RE 0.13066718574047673\n",
      "43 Train Loss 0.03150156 Test MSE 0.06330374846414898 Test RE 0.12026043593916527\n",
      "44 Train Loss 0.028848711 Test MSE 0.05453588001734884 Test RE 0.11162185176819402\n",
      "45 Train Loss 0.026264146 Test MSE 0.045829182206988776 Test RE 0.10232437816594836\n",
      "46 Train Loss 0.023696413 Test MSE 0.03915757407234873 Test RE 0.09458362383134514\n",
      "47 Train Loss 0.021017928 Test MSE 0.036822867607225813 Test RE 0.09172059503036371\n",
      "48 Train Loss 0.018526532 Test MSE 0.03427068661385479 Test RE 0.08848496085310029\n",
      "49 Train Loss 0.016471105 Test MSE 0.030236625846102143 Test RE 0.08311410320487901\n",
      "50 Train Loss 0.014898994 Test MSE 0.028372130544307872 Test RE 0.08051078015319484\n",
      "51 Train Loss 0.013411468 Test MSE 0.02603344621819268 Test RE 0.07712122004974757\n",
      "52 Train Loss 0.011535243 Test MSE 0.022171788439306353 Test RE 0.0711718776106512\n",
      "53 Train Loss 0.010650314 Test MSE 0.019909497023884556 Test RE 0.0674432056409119\n",
      "54 Train Loss 0.00976376 Test MSE 0.017155273814870503 Test RE 0.06260469259404455\n",
      "55 Train Loss 0.0087619135 Test MSE 0.014897037030133002 Test RE 0.05833886948600187\n",
      "56 Train Loss 0.007803742 Test MSE 0.014451431161021022 Test RE 0.05745971790516845\n",
      "57 Train Loss 0.0071178363 Test MSE 0.013191506899375795 Test RE 0.05489784096490983\n",
      "58 Train Loss 0.006267128 Test MSE 0.010955972874112393 Test RE 0.05003034923109292\n",
      "59 Train Loss 0.0058352994 Test MSE 0.01048453869116218 Test RE 0.04894211392681483\n",
      "60 Train Loss 0.0052049165 Test MSE 0.009193928535164254 Test RE 0.045830924942139056\n",
      "61 Train Loss 0.0048846286 Test MSE 0.008287148722446666 Test RE 0.043512158389512647\n",
      "62 Train Loss 0.0046266597 Test MSE 0.008147490486262546 Test RE 0.043143958674224395\n",
      "63 Train Loss 0.004343699 Test MSE 0.007654721566183524 Test RE 0.04181891486782384\n",
      "64 Train Loss 0.004076782 Test MSE 0.006914500395174541 Test RE 0.03974554560995497\n",
      "65 Train Loss 0.0038291237 Test MSE 0.006522309392758225 Test RE 0.03860190684734125\n",
      "66 Train Loss 0.0036205165 Test MSE 0.006257321195040272 Test RE 0.03780961755227157\n",
      "67 Train Loss 0.003429605 Test MSE 0.006026909788403337 Test RE 0.037106962534392676\n",
      "68 Train Loss 0.0031479632 Test MSE 0.005513671956186162 Test RE 0.03549184057573506\n",
      "69 Train Loss 0.002918758 Test MSE 0.004645555737208073 Test RE 0.032578185948883086\n",
      "70 Train Loss 0.0027512936 Test MSE 0.004116362664892302 Test RE 0.030666546831482674\n",
      "71 Train Loss 0.0026095314 Test MSE 0.003971907699774977 Test RE 0.03012365285345662\n",
      "72 Train Loss 0.0024492396 Test MSE 0.003738854258492895 Test RE 0.029226534909450968\n",
      "73 Train Loss 0.0023217248 Test MSE 0.0036964167474590097 Test RE 0.02906019504846954\n",
      "74 Train Loss 0.0021961904 Test MSE 0.003480205928731524 Test RE 0.028197495209370437\n",
      "75 Train Loss 0.0020867682 Test MSE 0.0031004864828106595 Test RE 0.02661478617837958\n",
      "76 Train Loss 0.0019419314 Test MSE 0.003073291125176375 Test RE 0.026497805698229963\n",
      "77 Train Loss 0.0018358727 Test MSE 0.0031627377244597215 Test RE 0.026880642789428633\n",
      "78 Train Loss 0.0017252625 Test MSE 0.002947133255270178 Test RE 0.025948242428206\n",
      "79 Train Loss 0.0016482485 Test MSE 0.002847704825967635 Test RE 0.025506774689125038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.0015212165 Test MSE 0.0025931135775118094 Test RE 0.024339902255362908\n",
      "81 Train Loss 0.0014423527 Test MSE 0.002399774545851453 Test RE 0.023414952523279582\n",
      "82 Train Loss 0.001332226 Test MSE 0.0021876257871117667 Test RE 0.022356024522035594\n",
      "83 Train Loss 0.0012668341 Test MSE 0.002124731851005044 Test RE 0.02203231460811742\n",
      "84 Train Loss 0.0011745906 Test MSE 0.0018598044463863492 Test RE 0.020613023630000882\n",
      "85 Train Loss 0.0011101033 Test MSE 0.0016322756876777013 Test RE 0.019311002330699673\n",
      "86 Train Loss 0.0010669716 Test MSE 0.0014911711321290563 Test RE 0.018457454394847205\n",
      "87 Train Loss 0.0010303189 Test MSE 0.0014324444007124757 Test RE 0.018090349082364683\n",
      "88 Train Loss 0.0009808835 Test MSE 0.0013205926805810462 Test RE 0.01736970742284581\n",
      "89 Train Loss 0.0009231931 Test MSE 0.0011515787990972548 Test RE 0.01622015091622438\n",
      "90 Train Loss 0.0008903693 Test MSE 0.0011444887906021648 Test RE 0.016170141935666113\n",
      "91 Train Loss 0.00085890316 Test MSE 0.0011700436789200636 Test RE 0.016349674001833646\n",
      "92 Train Loss 0.00083146803 Test MSE 0.0010642688461461882 Test RE 0.01559314563197705\n",
      "93 Train Loss 0.0007884687 Test MSE 0.0009581166125499091 Test RE 0.014795077534811242\n",
      "94 Train Loss 0.00074696745 Test MSE 0.0009324935823561456 Test RE 0.014595903589988952\n",
      "95 Train Loss 0.00072914624 Test MSE 0.0008703776749325473 Test RE 0.01410139025191725\n",
      "96 Train Loss 0.00070969807 Test MSE 0.000820530831657276 Test RE 0.013691641291344554\n",
      "97 Train Loss 0.0006959715 Test MSE 0.0008267249800183248 Test RE 0.013743222903197707\n",
      "98 Train Loss 0.00067558326 Test MSE 0.0007768947296059417 Test RE 0.013322604881866644\n",
      "99 Train Loss 0.0006534835 Test MSE 0.0007694641410801334 Test RE 0.013258739960242592\n",
      "Training time: 67.07\n",
      "8\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 55.185127 Test MSE 9.607800496946863 Test RE 1.4815627440142303\n",
      "1 Train Loss 39.208786 Test MSE 8.840394722600319 Test RE 1.4211629885492556\n",
      "2 Train Loss 28.065475 Test MSE 7.778275579608851 Test RE 1.3330600801281918\n",
      "3 Train Loss 21.550198 Test MSE 7.74217474329196 Test RE 1.3299629570805687\n",
      "4 Train Loss 18.134764 Test MSE 7.855343739321865 Test RE 1.3396478679662713\n",
      "5 Train Loss 15.622383 Test MSE 7.759275612000761 Test RE 1.3314309539666405\n",
      "6 Train Loss 14.195261 Test MSE 7.649731522321185 Test RE 1.3219990921659528\n",
      "7 Train Loss 12.811729 Test MSE 7.723021832818642 Test RE 1.3283168798709435\n",
      "8 Train Loss 11.311931 Test MSE 7.682031450264591 Test RE 1.3247871309355326\n",
      "9 Train Loss 10.069977 Test MSE 7.8248663256604445 Test RE 1.3370465380297385\n",
      "10 Train Loss 9.001382 Test MSE 7.601345064310954 Test RE 1.3178114728931454\n",
      "11 Train Loss 8.244467 Test MSE 7.501852405732152 Test RE 1.3091587657714447\n",
      "12 Train Loss 7.5438666 Test MSE 7.262442949882028 Test RE 1.2880995460746607\n",
      "13 Train Loss 6.7452264 Test MSE 7.048217440257796 Test RE 1.2689593414900675\n",
      "14 Train Loss 5.888258 Test MSE 6.579705431499788 Test RE 1.2260587632142983\n",
      "15 Train Loss 5.064693 Test MSE 6.32957974486984 Test RE 1.202528832852228\n",
      "16 Train Loss 4.1661444 Test MSE 6.007435525963131 Test RE 1.1715278560907292\n",
      "17 Train Loss 3.592198 Test MSE 5.7556188439409715 Test RE 1.1467112498290306\n",
      "18 Train Loss 3.158052 Test MSE 5.621846209742595 Test RE 1.1333069204321407\n",
      "19 Train Loss 2.77482 Test MSE 5.400509625485706 Test RE 1.1107733014865502\n",
      "20 Train Loss 2.559738 Test MSE 5.2318228403173945 Test RE 1.0932879842625558\n",
      "21 Train Loss 2.409338 Test MSE 5.126840143698732 Test RE 1.0822633418772505\n",
      "22 Train Loss 2.2846637 Test MSE 5.0648232836543166 Test RE 1.0756976226031632\n",
      "23 Train Loss 2.1533134 Test MSE 5.038531627081563 Test RE 1.072901999786835\n",
      "24 Train Loss 2.070567 Test MSE 4.949946251170045 Test RE 1.0634285161594939\n",
      "25 Train Loss 2.014114 Test MSE 4.84610649556837 Test RE 1.0522151175024201\n",
      "26 Train Loss 1.9589776 Test MSE 4.800405260357092 Test RE 1.04724190438722\n",
      "27 Train Loss 1.912226 Test MSE 4.737988356344374 Test RE 1.0404112865163533\n",
      "28 Train Loss 1.8647114 Test MSE 4.710430626722027 Test RE 1.0373811835447173\n",
      "29 Train Loss 1.820593 Test MSE 4.681280755093056 Test RE 1.0341663546499662\n",
      "30 Train Loss 1.785491 Test MSE 4.604155968607587 Test RE 1.0256119534430084\n",
      "31 Train Loss 1.753767 Test MSE 4.558626218982743 Test RE 1.0205282994521905\n",
      "32 Train Loss 1.7242223 Test MSE 4.525878261869244 Test RE 1.0168560907187876\n",
      "33 Train Loss 1.6771909 Test MSE 4.501963802981736 Test RE 1.0141660303549107\n",
      "34 Train Loss 1.6172733 Test MSE 4.4557801504310115 Test RE 1.0089506803382007\n",
      "35 Train Loss 1.5641549 Test MSE 4.403199955871485 Test RE 1.002979979651545\n",
      "36 Train Loss 1.5138056 Test MSE 4.384434566184933 Test RE 1.0008404667762505\n",
      "37 Train Loss 1.4717011 Test MSE 4.375423110041939 Test RE 0.9998114094515645\n",
      "38 Train Loss 1.437252 Test MSE 4.385749587684855 Test RE 1.0009905463407198\n",
      "39 Train Loss 1.4120166 Test MSE 4.360920407719699 Test RE 0.9981530552564888\n",
      "40 Train Loss 1.3942282 Test MSE 4.354133770162146 Test RE 0.9973760701290144\n",
      "41 Train Loss 1.3719199 Test MSE 4.358565464862755 Test RE 0.9978835122919519\n",
      "42 Train Loss 1.3534087 Test MSE 4.3188634272913795 Test RE 0.9933282701969337\n",
      "43 Train Loss 1.3362697 Test MSE 4.343540750379373 Test RE 0.9961620906362296\n",
      "44 Train Loss 1.3169351 Test MSE 4.3691453474901785 Test RE 0.9990938980865401\n",
      "45 Train Loss 1.2979404 Test MSE 4.36898137130502 Test RE 0.999075149666637\n",
      "46 Train Loss 1.2862039 Test MSE 4.370247430012754 Test RE 0.9992198969272453\n",
      "47 Train Loss 1.270798 Test MSE 4.360331788646471 Test RE 0.9980856896893158\n",
      "48 Train Loss 1.2539709 Test MSE 4.336899300966317 Test RE 0.9954002132341871\n",
      "49 Train Loss 1.23374 Test MSE 4.285409790776614 Test RE 0.9894736630640831\n",
      "50 Train Loss 1.2140439 Test MSE 4.2587023226769904 Test RE 0.986385552493263\n",
      "51 Train Loss 1.186489 Test MSE 4.153036206531777 Test RE 0.9740716845501711\n",
      "52 Train Loss 1.1546502 Test MSE 4.031445331569968 Test RE 0.959706525396897\n",
      "53 Train Loss 1.1169627 Test MSE 3.9527646309397664 Test RE 0.9502952045709742\n",
      "54 Train Loss 1.0804874 Test MSE 3.8826409853909816 Test RE 0.9418281734747689\n",
      "55 Train Loss 1.0524964 Test MSE 3.8076149483835002 Test RE 0.9326840972048117\n",
      "56 Train Loss 1.0225486 Test MSE 3.697313586249832 Test RE 0.9190755305476606\n",
      "57 Train Loss 0.9891248 Test MSE 3.5388958003655504 Test RE 0.8991702885423108\n",
      "58 Train Loss 0.95684624 Test MSE 3.5069887524310763 Test RE 0.8951076045865282\n",
      "59 Train Loss 0.92339313 Test MSE 3.4403800326372607 Test RE 0.8865664031786257\n",
      "60 Train Loss 0.88952017 Test MSE 3.326286009342001 Test RE 0.8717417677738838\n",
      "61 Train Loss 0.8527094 Test MSE 3.2205665876435368 Test RE 0.8577766141618784\n",
      "62 Train Loss 0.8158164 Test MSE 3.181438520384473 Test RE 0.8525499393729594\n",
      "63 Train Loss 0.7869851 Test MSE 3.1465174279617854 Test RE 0.8478580170532383\n",
      "64 Train Loss 0.7618431 Test MSE 3.0891856937990054 Test RE 0.8400982262229596\n",
      "65 Train Loss 0.7330637 Test MSE 3.0161161314224056 Test RE 0.8301032037324648\n",
      "66 Train Loss 0.6922922 Test MSE 2.9449208342455506 Test RE 0.8202474190651089\n",
      "67 Train Loss 0.6729829 Test MSE 2.924135686832737 Test RE 0.8173476547149783\n",
      "68 Train Loss 0.6551087 Test MSE 2.9194566769694594 Test RE 0.8166934598942462\n",
      "69 Train Loss 0.63906866 Test MSE 2.9095090068148712 Test RE 0.8153008840815416\n",
      "70 Train Loss 0.6238209 Test MSE 2.9219195707719003 Test RE 0.8170378741885617\n",
      "71 Train Loss 0.6099201 Test MSE 2.9409640145434492 Test RE 0.8196961882752021\n",
      "72 Train Loss 0.5988993 Test MSE 2.9298270530263206 Test RE 0.8181426868199778\n",
      "73 Train Loss 0.5872383 Test MSE 2.9264170172794026 Test RE 0.8176664286616088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 0.5755743 Test MSE 2.940464808584209 Test RE 0.8196266167697501\n",
      "75 Train Loss 0.56830084 Test MSE 2.9446418209425334 Test RE 0.820208561422477\n",
      "76 Train Loss 0.5600789 Test MSE 2.946928016187997 Test RE 0.8205269011738978\n",
      "77 Train Loss 0.55077493 Test MSE 2.957676990683577 Test RE 0.8220219826117575\n",
      "78 Train Loss 0.5423946 Test MSE 2.9593788377229258 Test RE 0.8222584442842004\n",
      "79 Train Loss 0.5358963 Test MSE 2.966884281781008 Test RE 0.8233004715356378\n",
      "80 Train Loss 0.53060937 Test MSE 2.9773330248172805 Test RE 0.8247489429875662\n",
      "81 Train Loss 0.5245152 Test MSE 2.9887682172820806 Test RE 0.8263312524711052\n",
      "82 Train Loss 0.5195565 Test MSE 2.9979299031500752 Test RE 0.8275967896451072\n",
      "83 Train Loss 0.51513654 Test MSE 3.003422083415747 Test RE 0.8283545176550187\n",
      "84 Train Loss 0.5100685 Test MSE 3.0129130924513645 Test RE 0.8296623123543894\n",
      "85 Train Loss 0.50364316 Test MSE 3.012543589996369 Test RE 0.8296114360676247\n",
      "86 Train Loss 0.49987406 Test MSE 3.0114387789757497 Test RE 0.829459297537528\n",
      "87 Train Loss 0.49499616 Test MSE 3.0177168572801896 Test RE 0.8303234524479367\n",
      "88 Train Loss 0.49063152 Test MSE 3.027328205179345 Test RE 0.8316446803173339\n",
      "89 Train Loss 0.48731434 Test MSE 3.038152237135756 Test RE 0.8331301017904725\n",
      "90 Train Loss 0.48439878 Test MSE 3.039971126212113 Test RE 0.8333794547498232\n",
      "91 Train Loss 0.48070055 Test MSE 3.0490981698057613 Test RE 0.8346295636611144\n",
      "92 Train Loss 0.47722584 Test MSE 3.0609915366739093 Test RE 0.8362557649106649\n",
      "93 Train Loss 0.47235388 Test MSE 3.0598838578965433 Test RE 0.8361044435875844\n",
      "94 Train Loss 0.4682905 Test MSE 3.0726701265539424 Test RE 0.8378495279778798\n",
      "95 Train Loss 0.4638585 Test MSE 3.083083115841825 Test RE 0.8392680237253347\n",
      "96 Train Loss 0.45947635 Test MSE 3.0812313272787124 Test RE 0.8390159415877821\n",
      "97 Train Loss 0.45396757 Test MSE 3.088029717791683 Test RE 0.8399410287676561\n",
      "98 Train Loss 0.44952995 Test MSE 3.082548875079675 Test RE 0.8391953058327141\n",
      "99 Train Loss 0.44451532 Test MSE 3.089308748293367 Test RE 0.8401149582752254\n",
      "Training time: 67.11\n",
      "9\n",
      "KG_rowdy_tune11\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.57924 Test MSE 8.679707285561422 Test RE 1.4081878728932102\n",
      "1 Train Loss 56.50629 Test MSE 8.620157229169354 Test RE 1.4033488850415488\n",
      "2 Train Loss 56.383728 Test MSE 8.533062340929957 Test RE 1.3962414269958032\n",
      "3 Train Loss 55.024178 Test MSE 8.598858068170475 Test RE 1.4016140767630132\n",
      "4 Train Loss 51.95766 Test MSE 9.293219662681755 Test RE 1.457106050611181\n",
      "5 Train Loss 44.56773 Test MSE 8.365204179993341 Test RE 1.382440133163667\n",
      "6 Train Loss 42.768448 Test MSE 8.341059915793346 Test RE 1.3804436416003245\n",
      "7 Train Loss 40.799957 Test MSE 8.098161380290396 Test RE 1.3601953125126718\n",
      "8 Train Loss 38.49676 Test MSE 7.961531859531909 Test RE 1.348672117437598\n",
      "9 Train Loss 37.391846 Test MSE 7.454539277511719 Test RE 1.3050238958270646\n",
      "10 Train Loss 37.023956 Test MSE 7.576663414381174 Test RE 1.3156702592658533\n",
      "11 Train Loss 36.53697 Test MSE 7.5628435896354 Test RE 1.3144698211495258\n",
      "12 Train Loss 35.34973 Test MSE 7.221025457873211 Test RE 1.2844212980084078\n",
      "13 Train Loss 33.815403 Test MSE 6.920057228987267 Test RE 1.2573694474868007\n",
      "14 Train Loss 31.960756 Test MSE 6.791208518263597 Test RE 1.2456085853317773\n",
      "15 Train Loss 30.035326 Test MSE 6.717581521278588 Test RE 1.2388380417719318\n",
      "16 Train Loss 28.22708 Test MSE 6.338354183304053 Test RE 1.2033620525431823\n",
      "17 Train Loss 26.41753 Test MSE 5.882110282966269 Test RE 1.1592434258762685\n",
      "18 Train Loss 24.056892 Test MSE 6.466500837079629 Test RE 1.215465760519343\n",
      "19 Train Loss 22.859568 Test MSE 6.34857171535112 Test RE 1.2043315817677407\n",
      "20 Train Loss 21.989555 Test MSE 6.430197796703542 Test RE 1.2120491362968389\n",
      "21 Train Loss 21.20912 Test MSE 6.26709091213019 Test RE 1.196578120970362\n",
      "22 Train Loss 20.730453 Test MSE 5.815479246546114 Test RE 1.1526589197882946\n",
      "23 Train Loss 19.853556 Test MSE 4.822150433625041 Test RE 1.0496111549665736\n",
      "24 Train Loss 18.36318 Test MSE 3.807391140983855 Test RE 0.932656685731645\n",
      "25 Train Loss 17.353348 Test MSE 3.3186492241922676 Test RE 0.870740481343689\n",
      "26 Train Loss 16.580471 Test MSE 3.237906811069896 Test RE 0.8600827410806247\n",
      "27 Train Loss 15.628169 Test MSE 3.1445103700617256 Test RE 0.8475875638265904\n",
      "28 Train Loss 14.725498 Test MSE 2.8293280158136156 Test RE 0.8039882657680717\n",
      "29 Train Loss 13.44535 Test MSE 2.7256003713640022 Test RE 0.7891129128817992\n",
      "30 Train Loss 12.723085 Test MSE 2.633049293876543 Test RE 0.7755995619652094\n",
      "31 Train Loss 11.9729595 Test MSE 2.56170107283739 Test RE 0.7650191126322359\n",
      "32 Train Loss 11.706659 Test MSE 2.5991062147925077 Test RE 0.7705841540447091\n",
      "33 Train Loss 11.201811 Test MSE 2.6450869297839494 Test RE 0.7773704628334757\n",
      "34 Train Loss 10.891909 Test MSE 2.7390477736434646 Test RE 0.7910571565181876\n",
      "35 Train Loss 10.427708 Test MSE 2.330403791108931 Test RE 0.7296652259612415\n",
      "36 Train Loss 9.8828335 Test MSE 2.0051375203190296 Test RE 0.6768308444437929\n",
      "37 Train Loss 6.512995 Test MSE 1.5865117652841696 Test RE 0.6020460465034393\n",
      "38 Train Loss 3.352352 Test MSE 0.6081561987286572 Test RE 0.3727482636972367\n",
      "39 Train Loss 2.0075808 Test MSE 0.22120720334656144 Test RE 0.22480589368707482\n",
      "40 Train Loss 1.2786494 Test MSE 0.13853512216682345 Test RE 0.17790493947113023\n",
      "41 Train Loss 0.91179734 Test MSE 0.1398429148031702 Test RE 0.17874269183948346\n",
      "42 Train Loss 0.6295557 Test MSE 0.1209646831402758 Test RE 0.16624069901836683\n",
      "43 Train Loss 0.45965686 Test MSE 0.09817168213256916 Test RE 0.14976184320557653\n",
      "44 Train Loss 0.3876396 Test MSE 0.08322708983171957 Test RE 0.1378924267734745\n",
      "45 Train Loss 0.33300543 Test MSE 0.07443491711290844 Test RE 0.13040565199150173\n",
      "46 Train Loss 0.28458995 Test MSE 0.05969117080482517 Test RE 0.11677855820497106\n",
      "47 Train Loss 0.25625074 Test MSE 0.05781692186793648 Test RE 0.1149305654722176\n",
      "48 Train Loss 0.21889189 Test MSE 0.04974306128049977 Test RE 0.10660419985514205\n",
      "49 Train Loss 0.1995643 Test MSE 0.04528973807492766 Test RE 0.10172037786358458\n",
      "50 Train Loss 0.18253995 Test MSE 0.04307005998052223 Test RE 0.09919637427781432\n",
      "51 Train Loss 0.15955639 Test MSE 0.038452720604895865 Test RE 0.09372848482932225\n",
      "52 Train Loss 0.14438295 Test MSE 0.033948258526172635 Test RE 0.08806773170339759\n",
      "53 Train Loss 0.13753328 Test MSE 0.036400896456496225 Test RE 0.09119354529392804\n",
      "54 Train Loss 0.12623225 Test MSE 0.03828500670164312 Test RE 0.09352386019238426\n",
      "55 Train Loss 0.12082922 Test MSE 0.03490881012078981 Test RE 0.089304960613982\n",
      "56 Train Loss 0.11517013 Test MSE 0.03413612325009067 Test RE 0.08831107252229937\n",
      "57 Train Loss 0.10987176 Test MSE 0.029930062106661513 Test RE 0.08269169027415753\n",
      "58 Train Loss 0.105011925 Test MSE 0.028244171019480156 Test RE 0.08032902145206988\n",
      "59 Train Loss 0.101767346 Test MSE 0.028797654812909888 Test RE 0.08111228221885529\n",
      "60 Train Loss 0.09716942 Test MSE 0.03044679171709604 Test RE 0.08340245382511224\n",
      "61 Train Loss 0.09270865 Test MSE 0.029632559381551484 Test RE 0.08227968909110625\n",
      "62 Train Loss 0.08920687 Test MSE 0.028181325352163743 Test RE 0.08023960225254843\n",
      "63 Train Loss 0.08290678 Test MSE 0.030370441879611684 Test RE 0.08329781618553263\n",
      "64 Train Loss 0.07608779 Test MSE 0.029525294608224634 Test RE 0.08213063491281523\n",
      "65 Train Loss 0.07262896 Test MSE 0.02607397924661719 Test RE 0.07718123401749781\n",
      "66 Train Loss 0.06983446 Test MSE 0.025736049142648283 Test RE 0.07667945171637465\n",
      "67 Train Loss 0.06656924 Test MSE 0.02779311543406907 Test RE 0.07968501814673798\n",
      "68 Train Loss 0.059188105 Test MSE 0.02448834315585251 Test RE 0.07479761695197283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 0.054125495 Test MSE 0.022063823243468936 Test RE 0.0709983809404141\n",
      "70 Train Loss 0.051196706 Test MSE 0.02076684557766905 Test RE 0.06888002990978914\n",
      "71 Train Loss 0.04663061 Test MSE 0.016919745306305682 Test RE 0.06217345056176856\n",
      "72 Train Loss 0.044177465 Test MSE 0.016667790289675008 Test RE 0.06170879615814171\n",
      "73 Train Loss 0.04291452 Test MSE 0.016836567609329816 Test RE 0.06202043951667548\n",
      "74 Train Loss 0.04073837 Test MSE 0.015586907139228359 Test RE 0.059674396324053476\n",
      "75 Train Loss 0.03777295 Test MSE 0.015227717040071902 Test RE 0.05898281006087248\n",
      "76 Train Loss 0.03642029 Test MSE 0.015996198987779667 Test RE 0.0604528053363874\n",
      "77 Train Loss 0.033843655 Test MSE 0.015421334413781258 Test RE 0.05935660294950847\n",
      "78 Train Loss 0.030868188 Test MSE 0.015368954904538115 Test RE 0.059255713033663004\n",
      "79 Train Loss 0.029629715 Test MSE 0.015242255857072114 Test RE 0.05901096056073783\n",
      "80 Train Loss 0.027863055 Test MSE 0.01523654846785561 Test RE 0.05899991134147634\n",
      "81 Train Loss 0.026984708 Test MSE 0.01536831950034997 Test RE 0.05925448810595539\n",
      "82 Train Loss 0.026267841 Test MSE 0.015358189037071262 Test RE 0.059234955249074184\n",
      "83 Train Loss 0.025032388 Test MSE 0.014577700116969268 Test RE 0.05771019825398706\n",
      "84 Train Loss 0.023558185 Test MSE 0.013403769117490737 Test RE 0.05533775413883361\n",
      "85 Train Loss 0.023097195 Test MSE 0.013484463214232328 Test RE 0.05550407785887753\n",
      "86 Train Loss 0.022839282 Test MSE 0.013979097031189554 Test RE 0.056512903380567005\n",
      "87 Train Loss 0.022245336 Test MSE 0.013361410566528738 Test RE 0.055250245845940134\n",
      "88 Train Loss 0.021468217 Test MSE 0.012916889739226292 Test RE 0.0543234115913251\n",
      "89 Train Loss 0.021011224 Test MSE 0.012900186538240085 Test RE 0.054288276647529506\n",
      "90 Train Loss 0.02072744 Test MSE 0.01281577678962325 Test RE 0.054110372998812516\n",
      "91 Train Loss 0.020398827 Test MSE 0.013048863878090212 Test RE 0.05460022226725791\n",
      "92 Train Loss 0.02008557 Test MSE 0.012583334203668426 Test RE 0.05361742166094756\n",
      "93 Train Loss 0.019718496 Test MSE 0.012344493257468564 Test RE 0.0531061348213458\n",
      "94 Train Loss 0.019452523 Test MSE 0.012329069702189097 Test RE 0.05307294830667811\n",
      "95 Train Loss 0.019107966 Test MSE 0.011825275704999359 Test RE 0.05197729782307017\n",
      "96 Train Loss 0.018287674 Test MSE 0.010998405713450335 Test RE 0.05012714018805691\n",
      "97 Train Loss 0.017567975 Test MSE 0.010989802749727004 Test RE 0.050107531603762974\n",
      "98 Train Loss 0.016935345 Test MSE 0.010761722845094935 Test RE 0.04958484521247607\n",
      "99 Train Loss 0.016517956 Test MSE 0.0101110588379916 Test RE 0.04806250242909961\n",
      "Training time: 67.39\n",
      "0\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 52.75827 Test MSE 8.086693502943486 Test RE 1.3592318790550966\n",
      "1 Train Loss 31.397924 Test MSE 6.022566592917195 Test RE 1.173002305410415\n",
      "2 Train Loss 22.956182 Test MSE 5.834171189329068 Test RE 1.1545098549181019\n",
      "3 Train Loss 18.461178 Test MSE 5.97933014157405 Test RE 1.1687841860398946\n",
      "4 Train Loss 15.060214 Test MSE 5.677327176334357 Test RE 1.1388853898121265\n",
      "5 Train Loss 12.120898 Test MSE 5.933228590199962 Test RE 1.1642697148245889\n",
      "6 Train Loss 10.647893 Test MSE 5.622595399097516 Test RE 1.1333824323870694\n",
      "7 Train Loss 9.628362 Test MSE 5.5471739782433644 Test RE 1.1257551795309646\n",
      "8 Train Loss 8.915357 Test MSE 5.369514812185756 Test RE 1.1075812183608456\n",
      "9 Train Loss 8.093994 Test MSE 5.146514704778426 Test RE 1.0843379791179086\n",
      "10 Train Loss 7.5267253 Test MSE 4.99437281350943 Test RE 1.0681900769172423\n",
      "11 Train Loss 6.888606 Test MSE 4.607046222059425 Test RE 1.0259338162827207\n",
      "12 Train Loss 6.0248365 Test MSE 3.825455607853561 Test RE 0.9348665990743891\n",
      "13 Train Loss 4.904977 Test MSE 3.358201790927672 Test RE 0.8759139735199155\n",
      "14 Train Loss 3.9839337 Test MSE 2.969569506750859 Test RE 0.8236729577505355\n",
      "15 Train Loss 3.1800802 Test MSE 2.514194693817094 Test RE 0.7578923318609506\n",
      "16 Train Loss 2.504908 Test MSE 2.0420342319709706 Test RE 0.6830296700618039\n",
      "17 Train Loss 2.1033983 Test MSE 1.8449474422272722 Test RE 0.6492322123193321\n",
      "18 Train Loss 1.8177444 Test MSE 1.641258057083931 Test RE 0.61234545089906\n",
      "19 Train Loss 1.4544871 Test MSE 1.4839297656913595 Test RE 0.5822570201407526\n",
      "20 Train Loss 1.260093 Test MSE 1.3103288110401095 Test RE 0.5471396715685826\n",
      "21 Train Loss 1.0460219 Test MSE 0.9968960700545724 Test RE 0.4772357860261122\n",
      "22 Train Loss 0.8821437 Test MSE 0.7836936428794675 Test RE 0.42313721396100906\n",
      "23 Train Loss 0.6804759 Test MSE 0.5781140095318636 Test RE 0.3634250067662499\n",
      "24 Train Loss 0.49752498 Test MSE 0.44292947983774783 Test RE 0.3181085583494722\n",
      "25 Train Loss 0.3555403 Test MSE 0.31117963587585573 Test RE 0.26663284361995876\n",
      "26 Train Loss 0.26366422 Test MSE 0.21751301356888728 Test RE 0.22292084622276703\n",
      "27 Train Loss 0.21264559 Test MSE 0.15975798798754198 Test RE 0.1910466168771896\n",
      "28 Train Loss 0.17832357 Test MSE 0.13466113885763867 Test RE 0.17539984361358976\n",
      "29 Train Loss 0.1385773 Test MSE 0.10388643375572303 Test RE 0.15405914357051684\n",
      "30 Train Loss 0.11730583 Test MSE 0.08094286016218473 Test RE 0.13598698137614174\n",
      "31 Train Loss 0.10465647 Test MSE 0.07896946036432334 Test RE 0.13431906049100037\n",
      "32 Train Loss 0.090550505 Test MSE 0.07980350732609767 Test RE 0.1350265121737747\n",
      "33 Train Loss 0.07875072 Test MSE 0.07116018320787415 Test RE 0.12750481605298053\n",
      "34 Train Loss 0.07028572 Test MSE 0.07153781506658786 Test RE 0.12784268877319724\n",
      "35 Train Loss 0.061633237 Test MSE 0.07285014905817137 Test RE 0.12900997249354762\n",
      "36 Train Loss 0.05445934 Test MSE 0.05879775246420662 Test RE 0.11590133091046806\n",
      "37 Train Loss 0.049796086 Test MSE 0.05390872918881294 Test RE 0.11097818232207265\n",
      "38 Train Loss 0.042702124 Test MSE 0.04759397579393147 Test RE 0.1042759254669093\n",
      "39 Train Loss 0.037889697 Test MSE 0.03888348695233104 Test RE 0.09425201905534121\n",
      "40 Train Loss 0.03279346 Test MSE 0.030142477197597148 Test RE 0.08298460493803428\n",
      "41 Train Loss 0.026705425 Test MSE 0.020776646305389508 Test RE 0.06889628165071793\n",
      "42 Train Loss 0.023966867 Test MSE 0.01641515884387858 Test RE 0.061239354607096626\n",
      "43 Train Loss 0.020101301 Test MSE 0.012219945614526771 Test RE 0.052837553041804104\n",
      "44 Train Loss 0.018122872 Test MSE 0.012142976693071647 Test RE 0.052670888076936616\n",
      "45 Train Loss 0.015688308 Test MSE 0.01137409306302052 Test RE 0.05097608155641195\n",
      "46 Train Loss 0.01398308 Test MSE 0.010795687465841764 Test RE 0.049663029894245495\n",
      "47 Train Loss 0.012560018 Test MSE 0.010719379522521666 Test RE 0.04948720023175063\n",
      "48 Train Loss 0.010713631 Test MSE 0.009102662664032864 Test RE 0.04560288142827537\n",
      "49 Train Loss 0.009920137 Test MSE 0.008438945904613412 Test RE 0.043908860004866726\n",
      "50 Train Loss 0.0088554965 Test MSE 0.0068876635703625545 Test RE 0.03966833965347842\n",
      "51 Train Loss 0.007862043 Test MSE 0.00528861653068461 Test RE 0.034759946500854816\n",
      "52 Train Loss 0.0073924745 Test MSE 0.00500490742652057 Test RE 0.033814742510862236\n",
      "53 Train Loss 0.006873723 Test MSE 0.004800867899602455 Test RE 0.03311829256338815\n",
      "54 Train Loss 0.006475354 Test MSE 0.004117844714722459 Test RE 0.03067206690637376\n",
      "55 Train Loss 0.005999936 Test MSE 0.003535344683106075 Test RE 0.028419991351805094\n",
      "56 Train Loss 0.0052892133 Test MSE 0.0028454621705776427 Test RE 0.02549672902499647\n",
      "57 Train Loss 0.004989015 Test MSE 0.002835810410804313 Test RE 0.0254534500556568\n",
      "58 Train Loss 0.004584339 Test MSE 0.0030352837872302165 Test RE 0.026333447010761245\n",
      "59 Train Loss 0.0043208785 Test MSE 0.00284849432599705 Test RE 0.025510310203697338\n",
      "60 Train Loss 0.0039580185 Test MSE 0.0024924269144519303 Test RE 0.023862683246194918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 0.0036208099 Test MSE 0.002405333291947909 Test RE 0.023442055588066803\n",
      "62 Train Loss 0.0033177831 Test MSE 0.002569543064998088 Test RE 0.024229029051105837\n",
      "63 Train Loss 0.0030928038 Test MSE 0.0027043789934366705 Test RE 0.024856606503575327\n",
      "64 Train Loss 0.0030029933 Test MSE 0.0026296198988808145 Test RE 0.02451063422698981\n",
      "65 Train Loss 0.002863046 Test MSE 0.0024321055957567386 Test RE 0.023572154218336226\n",
      "66 Train Loss 0.0027076893 Test MSE 0.002334732631499076 Test RE 0.023095461077830715\n",
      "67 Train Loss 0.0026439507 Test MSE 0.0022915130611793895 Test RE 0.022880695883819274\n",
      "68 Train Loss 0.0025329106 Test MSE 0.0020811830373509616 Test RE 0.02180535688217261\n",
      "69 Train Loss 0.0024344334 Test MSE 0.0021001369783314777 Test RE 0.021904425704008336\n",
      "70 Train Loss 0.0023408232 Test MSE 0.002083070649437548 Test RE 0.021815243260678397\n",
      "71 Train Loss 0.002254327 Test MSE 0.0019539151497921584 Test RE 0.02112812270279926\n",
      "72 Train Loss 0.0022044233 Test MSE 0.001862897619048684 Test RE 0.020630157999297644\n",
      "73 Train Loss 0.0020585738 Test MSE 0.001720717273469689 Test RE 0.0198272653798013\n",
      "74 Train Loss 0.0019584242 Test MSE 0.0017137167265241424 Test RE 0.019786891761494414\n",
      "75 Train Loss 0.0018433783 Test MSE 0.0016879279819894523 Test RE 0.01963744658328626\n",
      "76 Train Loss 0.0017076194 Test MSE 0.001542083109998044 Test RE 0.01876989964027455\n",
      "77 Train Loss 0.0016128775 Test MSE 0.0014436286493113716 Test RE 0.018160834737212913\n",
      "78 Train Loss 0.0015245635 Test MSE 0.0013735960432353963 Test RE 0.01771485393773853\n",
      "79 Train Loss 0.0014462449 Test MSE 0.0013416574781964037 Test RE 0.017507691610559737\n",
      "80 Train Loss 0.0013747797 Test MSE 0.0012550377130984812 Test RE 0.01693309903596944\n",
      "81 Train Loss 0.0013099413 Test MSE 0.0010500955496257293 Test RE 0.015488967526228869\n",
      "82 Train Loss 0.0012715602 Test MSE 0.0009534334871506005 Test RE 0.014758875220652725\n",
      "83 Train Loss 0.0012211083 Test MSE 0.0009412272915024874 Test RE 0.014664096703435301\n",
      "84 Train Loss 0.0011468052 Test MSE 0.0009215923307531367 Test RE 0.014510336576278543\n",
      "85 Train Loss 0.0010870548 Test MSE 0.0008614210173243176 Test RE 0.0140286471555245\n",
      "86 Train Loss 0.0010521504 Test MSE 0.0009040347768458085 Test RE 0.014371451348191325\n",
      "87 Train Loss 0.001018151 Test MSE 0.0009585560801288297 Test RE 0.014798470238482617\n",
      "88 Train Loss 0.0009981279 Test MSE 0.0009164886328653283 Test RE 0.014470102306753352\n",
      "89 Train Loss 0.0009717214 Test MSE 0.0008634836876070212 Test RE 0.014045432891908712\n",
      "90 Train Loss 0.00095332786 Test MSE 0.0008059408969669277 Test RE 0.013569369149648052\n",
      "91 Train Loss 0.0009199239 Test MSE 0.0007541245166736866 Test RE 0.013125915082140952\n",
      "92 Train Loss 0.00088119344 Test MSE 0.0007208488888159646 Test RE 0.012833058586454631\n",
      "93 Train Loss 0.00083922845 Test MSE 0.0007431083263082139 Test RE 0.01302969122515544\n",
      "94 Train Loss 0.0007914712 Test MSE 0.0007585028805713002 Test RE 0.01316396374423658\n",
      "95 Train Loss 0.00076991256 Test MSE 0.0007355036805048667 Test RE 0.012962849696252587\n",
      "96 Train Loss 0.0007512622 Test MSE 0.0007043162992994563 Test RE 0.012685042591642028\n",
      "97 Train Loss 0.0007294213 Test MSE 0.0006983602279619434 Test RE 0.012631293000219269\n",
      "98 Train Loss 0.0007037528 Test MSE 0.0006936280327470689 Test RE 0.012588424473757813\n",
      "99 Train Loss 0.00068573205 Test MSE 0.0006773894719868505 Test RE 0.012440197680486488\n",
      "Training time: 67.11\n",
      "1\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.165047 Test MSE 8.49581345780591 Test RE 1.3931906280436188\n",
      "1 Train Loss 45.95775 Test MSE 8.85139580853976 Test RE 1.4220469691745419\n",
      "2 Train Loss 44.31615 Test MSE 8.659711866425324 Test RE 1.406564918282044\n",
      "3 Train Loss 42.833138 Test MSE 8.53999388396446 Test RE 1.3968084065002682\n",
      "4 Train Loss 41.10786 Test MSE 8.559798861565486 Test RE 1.3984271277483675\n",
      "5 Train Loss 39.07113 Test MSE 8.937220093128614 Test RE 1.4289245141507114\n",
      "6 Train Loss 35.590157 Test MSE 8.455261299000657 Test RE 1.389861666850249\n",
      "7 Train Loss 32.6572 Test MSE 8.799078806426754 Test RE 1.417838170079809\n",
      "8 Train Loss 29.239561 Test MSE 8.866002562780881 Test RE 1.423219830987866\n",
      "9 Train Loss 26.645727 Test MSE 9.03100171205984 Test RE 1.436402070886018\n",
      "10 Train Loss 24.9165 Test MSE 8.550951109027341 Test RE 1.397704205614681\n",
      "11 Train Loss 22.826778 Test MSE 8.852533450218061 Test RE 1.4221383518195476\n",
      "12 Train Loss 21.209919 Test MSE 8.853872986904696 Test RE 1.4222459444339692\n",
      "13 Train Loss 18.933014 Test MSE 8.827032616753282 Test RE 1.4200885505876928\n",
      "14 Train Loss 16.866879 Test MSE 8.816680699292462 Test RE 1.4192556006780055\n",
      "15 Train Loss 14.820877 Test MSE 8.290037265882761 Test RE 1.3762150461994422\n",
      "16 Train Loss 13.5715275 Test MSE 8.259450025413658 Test RE 1.3736738319995518\n",
      "17 Train Loss 12.422754 Test MSE 8.575033832806467 Test RE 1.3996710545062598\n",
      "18 Train Loss 11.699085 Test MSE 8.325170823528548 Test RE 1.3791281941497666\n",
      "19 Train Loss 10.765921 Test MSE 8.044872492691313 Test RE 1.3557126325954973\n",
      "20 Train Loss 8.80217 Test MSE 7.532016492998925 Test RE 1.3117881138952876\n",
      "21 Train Loss 7.7000265 Test MSE 7.3959098038680695 Test RE 1.2998818006567836\n",
      "22 Train Loss 6.3378024 Test MSE 7.539515740441598 Test RE 1.3124409919279956\n",
      "23 Train Loss 4.6665807 Test MSE 6.875554995851635 Test RE 1.2533199144843647\n",
      "24 Train Loss 4.132616 Test MSE 6.654893331859814 Test RE 1.2330441005230242\n",
      "25 Train Loss 3.8058517 Test MSE 6.867007343849318 Test RE 1.2525406120046347\n",
      "26 Train Loss 3.4825633 Test MSE 7.098156697221796 Test RE 1.273446932251757\n",
      "27 Train Loss 3.2256484 Test MSE 6.919205771033638 Test RE 1.2572920904566902\n",
      "28 Train Loss 3.0434551 Test MSE 6.886559126133305 Test RE 1.2543224649504194\n",
      "29 Train Loss 2.8610914 Test MSE 6.898553453859486 Test RE 1.2554143171566943\n",
      "30 Train Loss 2.7291138 Test MSE 6.808183594346767 Test RE 1.24716435438534\n",
      "31 Train Loss 2.586163 Test MSE 6.726164126735918 Test RE 1.2396291794884338\n",
      "32 Train Loss 2.4584816 Test MSE 6.574830701033779 Test RE 1.225604501737499\n",
      "33 Train Loss 2.370629 Test MSE 6.428992078142937 Test RE 1.2119354960404658\n",
      "34 Train Loss 2.2663386 Test MSE 6.365436164933616 Test RE 1.2059301239142606\n",
      "35 Train Loss 2.1993208 Test MSE 6.285836591564265 Test RE 1.1983663447226474\n",
      "36 Train Loss 2.122441 Test MSE 6.146758952805206 Test RE 1.1850349292900564\n",
      "37 Train Loss 2.042078 Test MSE 6.1305053935511005 Test RE 1.183467128665905\n",
      "38 Train Loss 1.9824634 Test MSE 6.0645869727927195 Test RE 1.1770873017609036\n",
      "39 Train Loss 1.9168987 Test MSE 5.923260625969829 Test RE 1.1632913033973211\n",
      "40 Train Loss 1.8705031 Test MSE 5.839989344831476 Test RE 1.1550853817420477\n",
      "41 Train Loss 1.8120084 Test MSE 5.74956619523621 Test RE 1.146108146477705\n",
      "42 Train Loss 1.771883 Test MSE 5.6992147583435875 Test RE 1.1410786285790502\n",
      "43 Train Loss 1.7281529 Test MSE 5.709098339750842 Test RE 1.1420676295797838\n",
      "44 Train Loss 1.6790396 Test MSE 5.704015631301996 Test RE 1.1415591351559102\n",
      "45 Train Loss 1.6420579 Test MSE 5.708722687957341 Test RE 1.1420300556245555\n",
      "46 Train Loss 1.6122409 Test MSE 5.733728696753919 Test RE 1.144528548776124\n",
      "47 Train Loss 1.585889 Test MSE 5.7499637459503115 Test RE 1.146147769313645\n",
      "48 Train Loss 1.5642548 Test MSE 5.757455131667975 Test RE 1.14689416012304\n",
      "49 Train Loss 1.5438768 Test MSE 5.7589710484425005 Test RE 1.1470451366942642\n",
      "50 Train Loss 1.5153978 Test MSE 5.749372770393793 Test RE 1.1460888678360999\n",
      "51 Train Loss 1.4916422 Test MSE 5.771705041207375 Test RE 1.148312585251\n",
      "52 Train Loss 1.4636302 Test MSE 5.781453038983571 Test RE 1.1492818851436681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 1.4362605 Test MSE 5.791919636628626 Test RE 1.1503217302856963\n",
      "54 Train Loss 1.4208828 Test MSE 5.789917366458864 Test RE 1.1501228796347667\n",
      "55 Train Loss 1.3989786 Test MSE 5.758258550165914 Test RE 1.1469741784487906\n",
      "56 Train Loss 1.3795812 Test MSE 5.754014808458132 Test RE 1.1465514500095504\n",
      "57 Train Loss 1.3625883 Test MSE 5.769514174403067 Test RE 1.1480946220414399\n",
      "58 Train Loss 1.3435555 Test MSE 5.764358297969599 Test RE 1.1475815149686277\n",
      "59 Train Loss 1.3218538 Test MSE 5.750787293527025 Test RE 1.146229845780902\n",
      "60 Train Loss 1.3049046 Test MSE 5.73942597645265 Test RE 1.1450970340151994\n",
      "61 Train Loss 1.2833939 Test MSE 5.7749353041846625 Test RE 1.1486338796296918\n",
      "62 Train Loss 1.2681158 Test MSE 5.7918276894192955 Test RE 1.1503125995225516\n",
      "63 Train Loss 1.250438 Test MSE 5.7777492685869385 Test RE 1.1489136941239007\n",
      "64 Train Loss 1.2380482 Test MSE 5.819984878294128 Test RE 1.1531053534238938\n",
      "65 Train Loss 1.2254062 Test MSE 5.847492302046406 Test RE 1.1558271446009276\n",
      "66 Train Loss 1.2120799 Test MSE 5.849484127371486 Test RE 1.156023981949573\n",
      "67 Train Loss 1.1973615 Test MSE 5.874871828764442 Test RE 1.1585299307921186\n",
      "68 Train Loss 1.1835327 Test MSE 5.866577449247864 Test RE 1.1577118124315846\n",
      "69 Train Loss 1.1673783 Test MSE 5.8777522837907075 Test RE 1.1588139101294346\n",
      "70 Train Loss 1.1532214 Test MSE 5.883203587337887 Test RE 1.1593511548168005\n",
      "71 Train Loss 1.1409088 Test MSE 5.866283335507275 Test RE 1.1576827918295085\n",
      "72 Train Loss 1.1291876 Test MSE 5.899555511469219 Test RE 1.1609612017321906\n",
      "73 Train Loss 1.1173822 Test MSE 5.911539366092449 Test RE 1.1621397423943018\n",
      "74 Train Loss 1.1087046 Test MSE 5.8878438661372305 Test RE 1.159808274150962\n",
      "75 Train Loss 1.1012263 Test MSE 5.8749643132348774 Test RE 1.158539049765994\n",
      "76 Train Loss 1.0901122 Test MSE 5.867224940112184 Test RE 1.1577756986707286\n",
      "77 Train Loss 1.0812154 Test MSE 5.877419565590905 Test RE 1.1587811115428417\n",
      "78 Train Loss 1.0714072 Test MSE 5.8655607332758075 Test RE 1.1576114885968145\n",
      "79 Train Loss 1.0632248 Test MSE 5.877771496962191 Test RE 1.1588158040908592\n",
      "80 Train Loss 1.0551611 Test MSE 5.87882233415966 Test RE 1.15891938691393\n",
      "81 Train Loss 1.0493532 Test MSE 5.878331824292984 Test RE 1.15887103766813\n",
      "82 Train Loss 1.0434877 Test MSE 5.894407678791193 Test RE 1.1604545755720914\n",
      "83 Train Loss 1.0352263 Test MSE 5.903221971039054 Test RE 1.1613219031574196\n",
      "84 Train Loss 1.0297068 Test MSE 5.9104796790328775 Test RE 1.1620355766631643\n",
      "85 Train Loss 1.0213139 Test MSE 5.934950158388756 Test RE 1.1644386131148985\n",
      "86 Train Loss 1.0156854 Test MSE 5.93915435999447 Test RE 1.1648509727715324\n",
      "87 Train Loss 1.0096277 Test MSE 5.94947606898204 Test RE 1.1658627357878932\n",
      "88 Train Loss 1.0029173 Test MSE 5.971363133551931 Test RE 1.1680052679484567\n",
      "89 Train Loss 0.9950272 Test MSE 5.966483461960817 Test RE 1.1675279358178505\n",
      "90 Train Loss 0.9867524 Test MSE 5.962358259110346 Test RE 1.1671242539524511\n",
      "91 Train Loss 0.9828092 Test MSE 5.971437976368895 Test RE 1.168012587594626\n",
      "92 Train Loss 0.97810227 Test MSE 5.975317188498351 Test RE 1.168391912724788\n",
      "93 Train Loss 0.96961504 Test MSE 6.006198497387804 Test RE 1.171407231571303\n",
      "94 Train Loss 0.96456265 Test MSE 6.012903285850966 Test RE 1.1720608768870324\n",
      "95 Train Loss 0.9603725 Test MSE 6.004412836530328 Test RE 1.1712330871823473\n",
      "96 Train Loss 0.9575523 Test MSE 6.0148314394673195 Test RE 1.1722487838072624\n",
      "97 Train Loss 0.9537806 Test MSE 6.026301790502634 Test RE 1.1733659972174046\n",
      "98 Train Loss 0.9484755 Test MSE 6.025009291627763 Test RE 1.1732401608744893\n",
      "99 Train Loss 0.9440711 Test MSE 6.026883160256011 Test RE 1.1734225943704015\n",
      "Training time: 67.65\n",
      "2\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 54.136837 Test MSE 8.098037955252048 Test RE 1.3601849470241114\n",
      "1 Train Loss 38.919712 Test MSE 6.883286689053002 Test RE 1.2540244076031521\n",
      "2 Train Loss 30.628166 Test MSE 6.032742913938545 Test RE 1.1739928971848643\n",
      "3 Train Loss 23.650734 Test MSE 6.215269682717851 Test RE 1.1916207279852913\n",
      "4 Train Loss 19.725601 Test MSE 6.051634682052502 Test RE 1.17582966244962\n",
      "5 Train Loss 15.49954 Test MSE 5.406066153963913 Test RE 1.1113445861558433\n",
      "6 Train Loss 13.187696 Test MSE 5.796237305406823 Test RE 1.1507504122469736\n",
      "7 Train Loss 11.620939 Test MSE 5.669231988294324 Test RE 1.1380731431406144\n",
      "8 Train Loss 10.297233 Test MSE 5.7121651214169304 Test RE 1.1423743331629157\n",
      "9 Train Loss 9.308224 Test MSE 5.760881654456412 Test RE 1.1472353937367035\n",
      "10 Train Loss 8.307337 Test MSE 5.795799445945523 Test RE 1.1507069464220612\n",
      "11 Train Loss 7.6809196 Test MSE 5.663606761762212 Test RE 1.1375083833902202\n",
      "12 Train Loss 7.0183673 Test MSE 5.469680000790349 Test RE 1.1178641275541183\n",
      "13 Train Loss 6.512912 Test MSE 5.248909287862255 Test RE 1.0950717966428833\n",
      "14 Train Loss 6.2666874 Test MSE 5.127324952835782 Test RE 1.0823145116756674\n",
      "15 Train Loss 5.9898033 Test MSE 4.923231313761754 Test RE 1.0605549635872427\n",
      "16 Train Loss 5.8016934 Test MSE 4.781598011360549 Test RE 1.045188424807088\n",
      "17 Train Loss 5.6093063 Test MSE 4.517034773810872 Test RE 1.015862145312396\n",
      "18 Train Loss 5.300503 Test MSE 4.077109719059333 Test RE 0.9651265428634734\n",
      "19 Train Loss 4.799739 Test MSE 3.5250063726545244 Test RE 0.8974040258892438\n",
      "20 Train Loss 4.121493 Test MSE 3.295079885450845 Test RE 0.8676429340304924\n",
      "21 Train Loss 3.5347536 Test MSE 3.3630264385422057 Test RE 0.8765429499447482\n",
      "22 Train Loss 3.1377833 Test MSE 3.2306088148518595 Test RE 0.8591129136808933\n",
      "23 Train Loss 2.7177987 Test MSE 2.8457396415617304 Test RE 0.8063166765380285\n",
      "24 Train Loss 2.3438067 Test MSE 2.608320559855472 Test RE 0.7719488820962674\n",
      "25 Train Loss 2.0298076 Test MSE 2.3593018444314575 Test RE 0.7341753752758777\n",
      "26 Train Loss 1.7433281 Test MSE 2.1061047650557994 Test RE 0.6936622266281574\n",
      "27 Train Loss 1.5827469 Test MSE 1.960066689363712 Test RE 0.6691808193031961\n",
      "28 Train Loss 1.4270798 Test MSE 1.613148406124348 Test RE 0.6070790166223214\n",
      "29 Train Loss 1.2000325 Test MSE 0.9974775215779137 Test RE 0.4773749424701219\n",
      "30 Train Loss 0.8340324 Test MSE 0.7642141753276329 Test RE 0.41784538017107975\n",
      "31 Train Loss 0.60924214 Test MSE 0.6360143860707913 Test RE 0.3811900270705909\n",
      "32 Train Loss 0.41392943 Test MSE 0.5169753261993232 Test RE 0.3436710646028434\n",
      "33 Train Loss 0.32827833 Test MSE 0.479353306838705 Test RE 0.33092983604140724\n",
      "34 Train Loss 0.25451985 Test MSE 0.41809322345102734 Test RE 0.3090612982049627\n",
      "35 Train Loss 0.216459 Test MSE 0.37428272009217 Test RE 0.2924205898482567\n",
      "36 Train Loss 0.20140392 Test MSE 0.3722144241123837 Test RE 0.29161150868225083\n",
      "37 Train Loss 0.1853425 Test MSE 0.3712232892688475 Test RE 0.29122299742347235\n",
      "38 Train Loss 0.171371 Test MSE 0.35705665629473926 Test RE 0.2856121162196892\n",
      "39 Train Loss 0.16125338 Test MSE 0.3513382970444979 Test RE 0.2833158073323249\n",
      "40 Train Loss 0.15505159 Test MSE 0.35296761420053063 Test RE 0.28397198027267845\n",
      "41 Train Loss 0.150237 Test MSE 0.35153259729032854 Test RE 0.2833941374243603\n",
      "42 Train Loss 0.14454728 Test MSE 0.3564104042965663 Test RE 0.2853535284131889\n",
      "43 Train Loss 0.13833775 Test MSE 0.3439460014800176 Test RE 0.2803194244235099\n",
      "44 Train Loss 0.13549803 Test MSE 0.33489659213064554 Test RE 0.27660716428441273\n",
      "45 Train Loss 0.13189872 Test MSE 0.3291204071732384 Test RE 0.2742113747537575\n",
      "46 Train Loss 0.12951249 Test MSE 0.3165576546677836 Test RE 0.26892703898632436\n",
      "47 Train Loss 0.12760478 Test MSE 0.31872412757079 Test RE 0.26984571791357276\n",
      "48 Train Loss 0.1247686 Test MSE 0.3275725849223935 Test RE 0.2735658197395352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 0.12194703 Test MSE 0.3287357952517895 Test RE 0.27405110545538075\n",
      "50 Train Loss 0.12039088 Test MSE 0.3369589298278762 Test RE 0.27745754892749247\n",
      "51 Train Loss 0.1179156 Test MSE 0.3445205348572562 Test RE 0.2805534519520537\n",
      "52 Train Loss 0.11677468 Test MSE 0.3450507481179651 Test RE 0.2807692532717895\n",
      "53 Train Loss 0.11504153 Test MSE 0.35180914060490537 Test RE 0.28350558561949474\n",
      "54 Train Loss 0.11376315 Test MSE 0.35687816618558826 Test RE 0.2855407195526671\n",
      "55 Train Loss 0.11251887 Test MSE 0.3707613881140777 Test RE 0.29104176134224974\n",
      "56 Train Loss 0.11123491 Test MSE 0.3843541040222272 Test RE 0.29632877223337534\n",
      "57 Train Loss 0.11045392 Test MSE 0.38733076987529114 Test RE 0.29747403188875565\n",
      "58 Train Loss 0.10909019 Test MSE 0.39395633595027646 Test RE 0.30000749524822895\n",
      "59 Train Loss 0.106833816 Test MSE 0.40789248999081873 Test RE 0.30526774242229565\n",
      "60 Train Loss 0.10457559 Test MSE 0.4243247335259504 Test RE 0.31135599614961756\n",
      "61 Train Loss 0.10350371 Test MSE 0.4296637986582558 Test RE 0.31330869101326175\n",
      "62 Train Loss 0.102401204 Test MSE 0.43074564219060263 Test RE 0.3137028804823831\n",
      "63 Train Loss 0.10150046 Test MSE 0.43957287925180993 Test RE 0.3169009236693296\n",
      "64 Train Loss 0.10068092 Test MSE 0.44367505855181855 Test RE 0.3183761802351434\n",
      "65 Train Loss 0.099775776 Test MSE 0.44408185937008554 Test RE 0.3185221046159062\n",
      "66 Train Loss 0.09856248 Test MSE 0.45365892706024996 Test RE 0.32193840712191585\n",
      "67 Train Loss 0.097704664 Test MSE 0.46315184851378943 Test RE 0.3252892874334055\n",
      "68 Train Loss 0.09682699 Test MSE 0.4669116926717915 Test RE 0.3266069599378824\n",
      "69 Train Loss 0.095816545 Test MSE 0.46971423214159125 Test RE 0.32758568835697666\n",
      "70 Train Loss 0.094764814 Test MSE 0.47494525869855897 Test RE 0.3294047357149887\n",
      "71 Train Loss 0.09418204 Test MSE 0.48062115543082856 Test RE 0.33136718763157913\n",
      "72 Train Loss 0.09359113 Test MSE 0.48020154009093674 Test RE 0.3312225028667727\n",
      "73 Train Loss 0.092953786 Test MSE 0.4844301070335331 Test RE 0.33267764884384626\n",
      "74 Train Loss 0.09226416 Test MSE 0.4840101752366854 Test RE 0.3325334255499591\n",
      "75 Train Loss 0.09164655 Test MSE 0.4781000687884167 Test RE 0.3304969556531914\n",
      "76 Train Loss 0.090767026 Test MSE 0.48483188469860033 Test RE 0.33281557869606665\n",
      "77 Train Loss 0.08964519 Test MSE 0.4943133958757388 Test RE 0.33605414018292434\n",
      "78 Train Loss 0.08905867 Test MSE 0.49826024673484176 Test RE 0.33739308681580454\n",
      "79 Train Loss 0.08847136 Test MSE 0.5040524076006159 Test RE 0.339348479039217\n",
      "80 Train Loss 0.08763465 Test MSE 0.5053784603115052 Test RE 0.33979456201916164\n",
      "81 Train Loss 0.0870716 Test MSE 0.5063968203764678 Test RE 0.34013674030409535\n",
      "82 Train Loss 0.086631075 Test MSE 0.5085348107908771 Test RE 0.3408540069950304\n",
      "83 Train Loss 0.08594673 Test MSE 0.508838303560195 Test RE 0.3409557023900303\n",
      "84 Train Loss 0.08553853 Test MSE 0.5113629961933746 Test RE 0.34180051224515084\n",
      "85 Train Loss 0.08485251 Test MSE 0.5146148496571841 Test RE 0.3428855768160516\n",
      "86 Train Loss 0.0844352 Test MSE 0.5146230608977788 Test RE 0.3428883123616138\n",
      "87 Train Loss 0.0839551 Test MSE 0.5158293559474918 Test RE 0.34328994843392113\n",
      "88 Train Loss 0.08369135 Test MSE 0.513608280991284 Test RE 0.3425500765749438\n",
      "89 Train Loss 0.083394706 Test MSE 0.5104798722534248 Test RE 0.34150523994870363\n",
      "90 Train Loss 0.08297152 Test MSE 0.5094401186710956 Test RE 0.3411572709991709\n",
      "91 Train Loss 0.082204066 Test MSE 0.5081905511785092 Test RE 0.34073861456596655\n",
      "92 Train Loss 0.08183762 Test MSE 0.5094219347264719 Test RE 0.34115118231469654\n",
      "93 Train Loss 0.081375726 Test MSE 0.5102471050927502 Test RE 0.34142737177701893\n",
      "94 Train Loss 0.08071644 Test MSE 0.5071629082264845 Test RE 0.34039392610915975\n",
      "95 Train Loss 0.08023262 Test MSE 0.5071938782776997 Test RE 0.34040431907779073\n",
      "96 Train Loss 0.07985643 Test MSE 0.5076096486565496 Test RE 0.34054381311149484\n",
      "97 Train Loss 0.0795656 Test MSE 0.5095340016239621 Test RE 0.3411887048962413\n",
      "98 Train Loss 0.07896872 Test MSE 0.5136382508005689 Test RE 0.34256007058310955\n",
      "99 Train Loss 0.07859867 Test MSE 0.5149956768866952 Test RE 0.34301242509411123\n",
      "Training time: 66.99\n",
      "3\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.730827 Test MSE 8.132354247246868 Test RE 1.3630638640783468\n",
      "1 Train Loss 44.95244 Test MSE 8.836630510100049 Test RE 1.4208603929507557\n",
      "2 Train Loss 37.00168 Test MSE 8.737470953009352 Test RE 1.4128658653856134\n",
      "3 Train Loss 32.153374 Test MSE 9.628328521316442 Test RE 1.4831446528005543\n",
      "4 Train Loss 27.895945 Test MSE 9.110340650908155 Test RE 1.4426977963064136\n",
      "5 Train Loss 24.388771 Test MSE 8.517467115562157 Test RE 1.3949649416648826\n",
      "6 Train Loss 20.232475 Test MSE 8.695474096808706 Test RE 1.4094662892015515\n",
      "7 Train Loss 17.827484 Test MSE 8.428350821088616 Test RE 1.387648154610084\n",
      "8 Train Loss 16.209337 Test MSE 8.584362968277704 Test RE 1.40043222767237\n",
      "9 Train Loss 14.883164 Test MSE 8.510442332344974 Test RE 1.3943895741576973\n",
      "10 Train Loss 13.995751 Test MSE 8.419641077166933 Test RE 1.3869309808507178\n",
      "11 Train Loss 13.270595 Test MSE 8.225359179109457 Test RE 1.3708359840998579\n",
      "12 Train Loss 12.506432 Test MSE 8.149674179336543 Test RE 1.3645145889420416\n",
      "13 Train Loss 10.967352 Test MSE 6.981106935935641 Test RE 1.262903612532613\n",
      "14 Train Loss 7.8862724 Test MSE 6.7250669640964205 Test RE 1.2395280720619088\n",
      "15 Train Loss 6.736353 Test MSE 6.385587213795345 Test RE 1.2078374209469083\n",
      "16 Train Loss 6.2211585 Test MSE 6.2479472690393205 Test RE 1.1947491715769227\n",
      "17 Train Loss 5.7675667 Test MSE 6.187174624886553 Test RE 1.1889244191883255\n",
      "18 Train Loss 5.3353367 Test MSE 6.155671213822518 Test RE 1.1858937164333367\n",
      "19 Train Loss 4.472316 Test MSE 5.963292046017634 Test RE 1.1672156441903672\n",
      "20 Train Loss 3.0672262 Test MSE 5.430613652572922 Test RE 1.1138648874614565\n",
      "21 Train Loss 2.3483741 Test MSE 5.2881015858890414 Test RE 1.0991525075452557\n",
      "22 Train Loss 1.9870453 Test MSE 5.414376252572675 Test RE 1.1121984266795448\n",
      "23 Train Loss 1.8357251 Test MSE 5.598717564425488 Test RE 1.1309732681281364\n",
      "24 Train Loss 1.707814 Test MSE 5.687199142721282 Test RE 1.1398751297654375\n",
      "25 Train Loss 1.5961615 Test MSE 5.689401761005383 Test RE 1.1400958418146154\n",
      "26 Train Loss 1.5085381 Test MSE 5.724069743859289 Test RE 1.1435641146705762\n",
      "27 Train Loss 1.4336581 Test MSE 5.75617817130799 Test RE 1.1467669668092415\n",
      "28 Train Loss 1.3659666 Test MSE 5.748024651921427 Test RE 1.1459544919469349\n",
      "29 Train Loss 1.3183726 Test MSE 5.790969424486402 Test RE 1.150227366535956\n",
      "30 Train Loss 1.2745837 Test MSE 5.792354694933222 Test RE 1.1503649325101355\n",
      "31 Train Loss 1.2306691 Test MSE 5.767040562496802 Test RE 1.1478484795670598\n",
      "32 Train Loss 1.1913438 Test MSE 5.802929440529363 Test RE 1.151414528923638\n",
      "33 Train Loss 1.1492987 Test MSE 5.770213343717131 Test RE 1.1481641849359683\n",
      "34 Train Loss 1.1151891 Test MSE 5.7358999496536285 Test RE 1.1447452337506905\n",
      "35 Train Loss 1.0835035 Test MSE 5.772204827057377 Test RE 1.148362301751918\n",
      "36 Train Loss 1.0599087 Test MSE 5.817939415212294 Test RE 1.152902703266364\n",
      "37 Train Loss 1.0349958 Test MSE 5.833922528524539 Test RE 1.1544852512169876\n",
      "38 Train Loss 1.0177735 Test MSE 5.833521314654928 Test RE 1.154445552073157\n",
      "39 Train Loss 1.0010363 Test MSE 5.863491913812617 Test RE 1.1574073222350945\n",
      "40 Train Loss 0.9830406 Test MSE 5.874421781633201 Test RE 1.1584855550956972\n",
      "41 Train Loss 0.9643683 Test MSE 5.876861448913232 Test RE 1.1587260916135131\n",
      "42 Train Loss 0.9474853 Test MSE 5.89351068152869 Test RE 1.1603662745723424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 0.93641335 Test MSE 5.896360339843208 Test RE 1.1606467735793027\n",
      "44 Train Loss 0.92495 Test MSE 5.925749213526271 Test RE 1.1635356492432034\n",
      "45 Train Loss 0.9172517 Test MSE 5.9300607223396415 Test RE 1.1639588600350381\n",
      "46 Train Loss 0.9079264 Test MSE 5.923525113113813 Test RE 1.163317274917009\n",
      "47 Train Loss 0.8992387 Test MSE 5.93407368976963 Test RE 1.1643526282659138\n",
      "48 Train Loss 0.8901575 Test MSE 5.9282407201044895 Test RE 1.1637802303049383\n",
      "49 Train Loss 0.88049525 Test MSE 5.926185343574026 Test RE 1.1635784660671444\n",
      "50 Train Loss 0.86970776 Test MSE 5.94680516930148 Test RE 1.165601010895467\n",
      "51 Train Loss 0.8597002 Test MSE 5.95532214880564 Test RE 1.166435395719704\n",
      "52 Train Loss 0.850577 Test MSE 5.94914597468977 Test RE 1.1658303926060385\n",
      "53 Train Loss 0.8418999 Test MSE 5.955694743398028 Test RE 1.1664718841507546\n",
      "54 Train Loss 0.8345367 Test MSE 5.967938190071983 Test RE 1.1676702585281638\n",
      "55 Train Loss 0.8278575 Test MSE 5.973030742700991 Test RE 1.1681683496651964\n",
      "56 Train Loss 0.82152283 Test MSE 5.995825875190554 Test RE 1.1703952923924064\n",
      "57 Train Loss 0.8153081 Test MSE 6.0153907495782954 Test RE 1.1723032853641786\n",
      "58 Train Loss 0.80815136 Test MSE 6.024866483962399 Test RE 1.1732262564410676\n",
      "59 Train Loss 0.8027467 Test MSE 6.029315914281522 Test RE 1.1736593967483697\n",
      "60 Train Loss 0.7971985 Test MSE 6.026564700973269 Test RE 1.173391592255018\n",
      "61 Train Loss 0.79250085 Test MSE 6.026025925767551 Test RE 1.1733391404472253\n",
      "62 Train Loss 0.78559875 Test MSE 6.021678854685201 Test RE 1.1729158507940474\n",
      "63 Train Loss 0.77910614 Test MSE 6.035589168636754 Test RE 1.1742698100925648\n",
      "64 Train Loss 0.7750092 Test MSE 6.050606257847362 Test RE 1.1757297470441623\n",
      "65 Train Loss 0.7719307 Test MSE 6.047138718238523 Test RE 1.1753927995081141\n",
      "66 Train Loss 0.7682718 Test MSE 6.045594797623305 Test RE 1.1752427426709873\n",
      "67 Train Loss 0.76297 Test MSE 6.053889885793103 Test RE 1.1760487345342128\n",
      "68 Train Loss 0.75805116 Test MSE 6.067495142547978 Test RE 1.1773694940539048\n",
      "69 Train Loss 0.75331134 Test MSE 6.072548009158745 Test RE 1.177859634780444\n",
      "70 Train Loss 0.7481033 Test MSE 6.08817626990642 Test RE 1.1793743259018923\n",
      "71 Train Loss 0.7430467 Test MSE 6.114790766992968 Test RE 1.18194933558\n",
      "72 Train Loss 0.7383542 Test MSE 6.129381522975249 Test RE 1.1833586445555546\n",
      "73 Train Loss 0.73441386 Test MSE 6.1512642347875035 Test RE 1.1854691368636485\n",
      "74 Train Loss 0.73083425 Test MSE 6.15843012443053 Test RE 1.1861594395469106\n",
      "75 Train Loss 0.72717386 Test MSE 6.1613169312131095 Test RE 1.186437417201869\n",
      "76 Train Loss 0.72412384 Test MSE 6.161979166984871 Test RE 1.18650117631345\n",
      "77 Train Loss 0.7215074 Test MSE 6.164503712637705 Test RE 1.1867442045328807\n",
      "78 Train Loss 0.71837556 Test MSE 6.181794244806041 Test RE 1.188407361166125\n",
      "79 Train Loss 0.7157484 Test MSE 6.190911755143576 Test RE 1.189283427537078\n",
      "80 Train Loss 0.71211106 Test MSE 6.185661006413606 Test RE 1.188778982203941\n",
      "81 Train Loss 0.70895827 Test MSE 6.190389474963959 Test RE 1.1892332610763479\n",
      "82 Train Loss 0.7060094 Test MSE 6.207683428491108 Test RE 1.1908932697710894\n",
      "83 Train Loss 0.7039583 Test MSE 6.219524564084585 Test RE 1.192028541132641\n",
      "84 Train Loss 0.70102894 Test MSE 6.223060888993968 Test RE 1.1923673774172168\n",
      "85 Train Loss 0.6980327 Test MSE 6.228728777575426 Test RE 1.192910250726776\n",
      "86 Train Loss 0.69472826 Test MSE 6.232527721446124 Test RE 1.1932739772963536\n",
      "87 Train Loss 0.69170976 Test MSE 6.227367207780954 Test RE 1.192779861413416\n",
      "88 Train Loss 0.6884198 Test MSE 6.241404503406509 Test RE 1.1941234451575273\n",
      "89 Train Loss 0.68457574 Test MSE 6.2505839190029375 Test RE 1.195001238612136\n",
      "90 Train Loss 0.68105495 Test MSE 6.248349679246876 Test RE 1.1947876459350033\n",
      "91 Train Loss 0.67796767 Test MSE 6.252119979586366 Test RE 1.1951480634179936\n",
      "92 Train Loss 0.6749952 Test MSE 6.244285604173661 Test RE 1.1943990235977016\n",
      "93 Train Loss 0.67125344 Test MSE 6.25127842743042 Test RE 1.1950676256400747\n",
      "94 Train Loss 0.6681814 Test MSE 6.273562453838885 Test RE 1.1971957685580334\n",
      "95 Train Loss 0.6658999 Test MSE 6.276210644526544 Test RE 1.1974484215130026\n",
      "96 Train Loss 0.6633223 Test MSE 6.297224742571689 Test RE 1.1994514032576438\n",
      "97 Train Loss 0.66168547 Test MSE 6.308917641058031 Test RE 1.2005644776321405\n",
      "98 Train Loss 0.6592286 Test MSE 6.3201733341779 Test RE 1.2016349594704263\n",
      "99 Train Loss 0.6572209 Test MSE 6.333323666248337 Test RE 1.202884425800686\n",
      "Training time: 67.66\n",
      "4\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.79261 Test MSE 8.481118701156065 Test RE 1.3919852427322228\n",
      "1 Train Loss 54.736626 Test MSE 8.902073282393074 Test RE 1.4261120281329334\n",
      "2 Train Loss 45.8404 Test MSE 8.424097100274842 Test RE 1.3872979429905152\n",
      "3 Train Loss 43.502472 Test MSE 7.900784164570579 Test RE 1.3435169786357415\n",
      "4 Train Loss 41.53943 Test MSE 8.261237275416914 Test RE 1.373822447570429\n",
      "5 Train Loss 32.323185 Test MSE 6.387683930273341 Test RE 1.2080357022236101\n",
      "6 Train Loss 24.905663 Test MSE 5.6915488078647485 Test RE 1.140310944245736\n",
      "7 Train Loss 21.515812 Test MSE 5.87243129091074 Test RE 1.1582892676817236\n",
      "8 Train Loss 17.108412 Test MSE 5.407128031069411 Test RE 1.1114537277566037\n",
      "9 Train Loss 11.619122 Test MSE 4.511031433299668 Test RE 1.015186857835045\n",
      "10 Train Loss 8.074063 Test MSE 4.455085660889963 Test RE 1.0088720484289884\n",
      "11 Train Loss 6.096987 Test MSE 4.187490014489874 Test RE 0.9781038142318418\n",
      "12 Train Loss 4.8841996 Test MSE 3.9395938211701935 Test RE 0.9487106679167348\n",
      "13 Train Loss 3.6416378 Test MSE 3.5862220379817016 Test RE 0.9051626970481012\n",
      "14 Train Loss 2.971315 Test MSE 3.4694350114114116 Test RE 0.890302183873089\n",
      "15 Train Loss 2.5540483 Test MSE 3.219021516924906 Test RE 0.8575708297931393\n",
      "16 Train Loss 2.2626858 Test MSE 2.9513099167823102 Test RE 0.8211367110724215\n",
      "17 Train Loss 1.9704251 Test MSE 2.688432812502532 Test RE 0.7837140884797125\n",
      "18 Train Loss 1.6815381 Test MSE 2.3378270673932815 Test RE 0.7308264410272178\n",
      "19 Train Loss 1.4458983 Test MSE 2.022798041627561 Test RE 0.6798049499294779\n",
      "20 Train Loss 1.1445125 Test MSE 1.6720394053505996 Test RE 0.6180609633175108\n",
      "21 Train Loss 0.96968216 Test MSE 1.4436925053212033 Test RE 0.5743087210692273\n",
      "22 Train Loss 0.7957079 Test MSE 1.019814591332365 Test RE 0.4826904106644371\n",
      "23 Train Loss 0.64890385 Test MSE 0.8798425223210425 Test RE 0.4483431450204842\n",
      "24 Train Loss 0.4958956 Test MSE 0.7121809022262868 Test RE 0.40336965347540626\n",
      "25 Train Loss 0.39400268 Test MSE 0.46598908281688545 Test RE 0.32628411537424995\n",
      "26 Train Loss 0.3076562 Test MSE 0.43564429037931884 Test RE 0.31548162817518405\n",
      "27 Train Loss 0.25033632 Test MSE 0.3966509987490887 Test RE 0.30103177290738564\n",
      "28 Train Loss 0.19151327 Test MSE 0.3866662277283486 Test RE 0.2972187347222612\n",
      "29 Train Loss 0.1474812 Test MSE 0.3714153514549477 Test RE 0.2912983236414399\n",
      "30 Train Loss 0.11787988 Test MSE 0.3393748745686387 Test RE 0.27845043679593223\n",
      "31 Train Loss 0.093656875 Test MSE 0.3254406445409081 Test RE 0.2726741424472509\n",
      "32 Train Loss 0.077661745 Test MSE 0.2900731243405989 Test RE 0.2574315707697925\n",
      "33 Train Loss 0.06521413 Test MSE 0.26452164522302707 Test RE 0.24583214346161006\n",
      "34 Train Loss 0.058402415 Test MSE 0.26194223463251287 Test RE 0.24463062470675093\n",
      "35 Train Loss 0.051346157 Test MSE 0.24124218102370354 Test RE 0.2347657205092778\n",
      "36 Train Loss 0.045266278 Test MSE 0.2279576572073015 Test RE 0.22821025316080118\n",
      "37 Train Loss 0.039618544 Test MSE 0.22885152922696556 Test RE 0.22865724665154452\n",
      "38 Train Loss 0.03668635 Test MSE 0.2309840098797079 Test RE 0.22972011154608854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 0.033905484 Test MSE 0.22372547323665085 Test RE 0.22608189148012214\n",
      "40 Train Loss 0.03186521 Test MSE 0.21616994230670664 Test RE 0.22223154910505236\n",
      "41 Train Loss 0.030179935 Test MSE 0.21873555505651665 Test RE 0.22354643663964935\n",
      "42 Train Loss 0.028138958 Test MSE 0.22126888936288588 Test RE 0.224837236277157\n",
      "43 Train Loss 0.026310157 Test MSE 0.2094262358900264 Test RE 0.21873768113551317\n",
      "44 Train Loss 0.024218246 Test MSE 0.2022716426703699 Test RE 0.21496886377979033\n",
      "45 Train Loss 0.022704631 Test MSE 0.1991108745678648 Test RE 0.21328266086111147\n",
      "46 Train Loss 0.021334972 Test MSE 0.19556486943198537 Test RE 0.21137493227713158\n",
      "47 Train Loss 0.020272594 Test MSE 0.1906224087091964 Test RE 0.208686827455441\n",
      "48 Train Loss 0.019505942 Test MSE 0.18599182173473175 Test RE 0.20613654106943494\n",
      "49 Train Loss 0.018534519 Test MSE 0.18016611317578426 Test RE 0.20288251269634955\n",
      "50 Train Loss 0.017873146 Test MSE 0.1777152109517982 Test RE 0.20149782422396345\n",
      "51 Train Loss 0.017039621 Test MSE 0.17329376672635616 Test RE 0.19897546628792412\n",
      "52 Train Loss 0.015626375 Test MSE 0.16527031013560256 Test RE 0.1943146216482052\n",
      "53 Train Loss 0.014675909 Test MSE 0.1566659847874869 Test RE 0.18918879748606\n",
      "54 Train Loss 0.013769705 Test MSE 0.1465594707087323 Test RE 0.18298479517268662\n",
      "55 Train Loss 0.013167396 Test MSE 0.14189628333510237 Test RE 0.1800501843538172\n",
      "56 Train Loss 0.012414353 Test MSE 0.135696047134202 Test RE 0.17607255187216247\n",
      "57 Train Loss 0.011515201 Test MSE 0.12646158640184882 Test RE 0.16997590926107103\n",
      "58 Train Loss 0.010769283 Test MSE 0.12152399454174392 Test RE 0.1666245841494779\n",
      "59 Train Loss 0.009958778 Test MSE 0.11366090991625916 Test RE 0.16114380883473542\n",
      "60 Train Loss 0.009300925 Test MSE 0.10613261483219479 Test RE 0.1557157322647212\n",
      "61 Train Loss 0.008833398 Test MSE 0.10182652671620943 Test RE 0.15252411910894936\n",
      "62 Train Loss 0.008382346 Test MSE 0.09601325174461713 Test RE 0.14810633990530792\n",
      "63 Train Loss 0.007943839 Test MSE 0.09179187604002938 Test RE 0.14481387784996036\n",
      "64 Train Loss 0.0075031132 Test MSE 0.09027053669085125 Test RE 0.1436088063801856\n",
      "65 Train Loss 0.007214143 Test MSE 0.089091507914815 Test RE 0.14266788239324849\n",
      "66 Train Loss 0.00689326 Test MSE 0.08437070709894828 Test RE 0.13883657926044093\n",
      "67 Train Loss 0.0066467063 Test MSE 0.07929198692969996 Test RE 0.13459307351977776\n",
      "68 Train Loss 0.0062985807 Test MSE 0.0720416875290253 Test RE 0.1282921250589909\n",
      "69 Train Loss 0.006014768 Test MSE 0.06487609294282928 Test RE 0.1217447953374655\n",
      "70 Train Loss 0.0057248673 Test MSE 0.06048014121154309 Test RE 0.11754778732178707\n",
      "71 Train Loss 0.0055527473 Test MSE 0.061097268482398985 Test RE 0.11814598229117304\n",
      "72 Train Loss 0.005347152 Test MSE 0.05894220961855562 Test RE 0.1160436195588042\n",
      "73 Train Loss 0.00521461 Test MSE 0.055472192068956414 Test RE 0.11257597689206231\n",
      "74 Train Loss 0.005055827 Test MSE 0.05393931899526836 Test RE 0.11100966441895886\n",
      "75 Train Loss 0.004984357 Test MSE 0.05398768350546883 Test RE 0.11105942149022463\n",
      "76 Train Loss 0.004828009 Test MSE 0.05186871530798442 Test RE 0.10885811406170036\n",
      "77 Train Loss 0.0046612583 Test MSE 0.047979736141844004 Test RE 0.10469766304991286\n",
      "78 Train Loss 0.0045234724 Test MSE 0.0446109847425119 Test RE 0.10095526317413928\n",
      "79 Train Loss 0.004376024 Test MSE 0.041550990964009396 Test RE 0.09743135742237836\n",
      "80 Train Loss 0.0042721364 Test MSE 0.03794226446957978 Test RE 0.09310428809943745\n",
      "81 Train Loss 0.0041599004 Test MSE 0.035808254793768556 Test RE 0.09044813947575893\n",
      "82 Train Loss 0.0040336717 Test MSE 0.03524853932581198 Test RE 0.0897384621411624\n",
      "83 Train Loss 0.0039163735 Test MSE 0.03427602101494535 Test RE 0.08849184714502938\n",
      "84 Train Loss 0.0037509762 Test MSE 0.032916930196044095 Test RE 0.08671969136270163\n",
      "85 Train Loss 0.0035981766 Test MSE 0.02992740950974989 Test RE 0.08268802585505818\n",
      "86 Train Loss 0.003440529 Test MSE 0.028322097883163477 Test RE 0.08043976070674408\n",
      "87 Train Loss 0.0033016847 Test MSE 0.027618718827359032 Test RE 0.07943462042829934\n",
      "88 Train Loss 0.0031929873 Test MSE 0.026315274322698194 Test RE 0.07753753873163823\n",
      "89 Train Loss 0.0030909623 Test MSE 0.026201586890345834 Test RE 0.07736986833409885\n",
      "90 Train Loss 0.0030095244 Test MSE 0.02579198611587627 Test RE 0.07676273738901535\n",
      "91 Train Loss 0.0029135658 Test MSE 0.024353760496762734 Test RE 0.07459179798267175\n",
      "92 Train Loss 0.0028208192 Test MSE 0.02352289780884193 Test RE 0.0733083544817806\n",
      "93 Train Loss 0.002742211 Test MSE 0.0226149042808447 Test RE 0.07187956451104818\n",
      "94 Train Loss 0.002679258 Test MSE 0.021382057536191667 Test RE 0.06989285921625207\n",
      "95 Train Loss 0.002613305 Test MSE 0.021411555285369834 Test RE 0.0699410531626374\n",
      "96 Train Loss 0.0025174257 Test MSE 0.02143066976463157 Test RE 0.06997226501436435\n",
      "97 Train Loss 0.002454629 Test MSE 0.020805036193170076 Test RE 0.06894333664604353\n",
      "98 Train Loss 0.0023872633 Test MSE 0.0202768473875024 Test RE 0.06806255946287938\n",
      "99 Train Loss 0.0023372942 Test MSE 0.0201302563322967 Test RE 0.06781608474013073\n",
      "Training time: 66.96\n",
      "5\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.056465 Test MSE 8.739121942783493 Test RE 1.4129993431922054\n",
      "1 Train Loss 53.599094 Test MSE 8.289873226084003 Test RE 1.3762014301475005\n",
      "2 Train Loss 43.71331 Test MSE 7.158869447222331 Test RE 1.2788814308204763\n",
      "3 Train Loss 34.8849 Test MSE 8.202085551024817 Test RE 1.368895222216572\n",
      "4 Train Loss 32.064976 Test MSE 7.976689686419771 Test RE 1.3499553640448376\n",
      "5 Train Loss 29.908073 Test MSE 8.50805499310196 Test RE 1.3941939841809006\n",
      "6 Train Loss 27.592125 Test MSE 9.159376653311364 Test RE 1.4465752140869257\n",
      "7 Train Loss 24.832825 Test MSE 8.998394277818402 Test RE 1.4338065813734449\n",
      "8 Train Loss 22.561735 Test MSE 9.268376834052006 Test RE 1.455157164146012\n",
      "9 Train Loss 20.821564 Test MSE 9.203701566625453 Test RE 1.4500711908039332\n",
      "10 Train Loss 18.867367 Test MSE 9.290003635394738 Test RE 1.4568539045047497\n",
      "11 Train Loss 17.26968 Test MSE 8.926059613994877 Test RE 1.4280320406617926\n",
      "12 Train Loss 14.84231 Test MSE 8.431395149705393 Test RE 1.3878987419240278\n",
      "13 Train Loss 12.205814 Test MSE 7.569396269268497 Test RE 1.3150391463394746\n",
      "14 Train Loss 10.401428 Test MSE 6.71511388237848 Test RE 1.2386104832581246\n",
      "15 Train Loss 9.139872 Test MSE 6.29425178911236 Test RE 1.1991682361232747\n",
      "16 Train Loss 8.356036 Test MSE 6.161190179371045 Test RE 1.1864252133253892\n",
      "17 Train Loss 7.7987714 Test MSE 6.056783410357339 Test RE 1.1763297538000732\n",
      "18 Train Loss 7.297059 Test MSE 5.862049271218389 Test RE 1.1572649303086522\n",
      "19 Train Loss 6.7528973 Test MSE 5.654795208489886 Test RE 1.136623159737204\n",
      "20 Train Loss 5.3285127 Test MSE 4.89317419892967 Test RE 1.057312578325795\n",
      "21 Train Loss 4.1439953 Test MSE 4.645833211285397 Test RE 1.0302434626416845\n",
      "22 Train Loss 3.751771 Test MSE 4.726006897058714 Test RE 1.0390949540018408\n",
      "23 Train Loss 3.390556 Test MSE 4.842659908940696 Test RE 1.051840879380177\n",
      "24 Train Loss 3.0245159 Test MSE 5.010653863313153 Test RE 1.0699297453600467\n",
      "25 Train Loss 2.750329 Test MSE 5.116806390279565 Test RE 1.0812037728705173\n",
      "26 Train Loss 2.5027094 Test MSE 5.234383195352304 Test RE 1.0935554687602904\n",
      "27 Train Loss 2.3105378 Test MSE 5.281009140735293 Test RE 1.0984151640572233\n",
      "28 Train Loss 2.1927195 Test MSE 5.265920359472952 Test RE 1.0968448579679313\n",
      "29 Train Loss 2.0898921 Test MSE 5.257477265958864 Test RE 1.0959651941954753\n",
      "30 Train Loss 1.9799759 Test MSE 5.294516752424231 Test RE 1.0998190141395012\n",
      "31 Train Loss 1.905806 Test MSE 5.308718387740794 Test RE 1.1012930644947725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 1.8302385 Test MSE 5.289719240588389 Test RE 1.099320612604575\n",
      "33 Train Loss 1.7625191 Test MSE 5.2687575660188735 Test RE 1.0971403007527456\n",
      "34 Train Loss 1.7039685 Test MSE 5.278204409683766 Test RE 1.0981234425139954\n",
      "35 Train Loss 1.6444017 Test MSE 5.253144429078111 Test RE 1.0955134930326753\n",
      "36 Train Loss 1.5684744 Test MSE 5.2739070725011 Test RE 1.0976763238312188\n",
      "37 Train Loss 1.5246493 Test MSE 5.334785881320308 Test RE 1.1039936028134174\n",
      "38 Train Loss 1.4654896 Test MSE 5.344875416946499 Test RE 1.1050370862248844\n",
      "39 Train Loss 1.4179015 Test MSE 5.409652289286882 Test RE 1.1117131324558718\n",
      "40 Train Loss 1.3850899 Test MSE 5.442070283883319 Test RE 1.115039194538303\n",
      "41 Train Loss 1.3590139 Test MSE 5.430491531522729 Test RE 1.1138523633598292\n",
      "42 Train Loss 1.3240422 Test MSE 5.467983594115993 Test RE 1.1176907628210186\n",
      "43 Train Loss 1.3001142 Test MSE 5.474541077328084 Test RE 1.1183607577291441\n",
      "44 Train Loss 1.272741 Test MSE 5.457793476801456 Test RE 1.1166488146273907\n",
      "45 Train Loss 1.2534283 Test MSE 5.479543269990091 Test RE 1.118871574853873\n",
      "46 Train Loss 1.2340679 Test MSE 5.504842240758127 Test RE 1.1214515072166173\n",
      "47 Train Loss 1.2144434 Test MSE 5.519831586193352 Test RE 1.1229772908649527\n",
      "48 Train Loss 1.1976811 Test MSE 5.521236869307423 Test RE 1.1231202300625593\n",
      "49 Train Loss 1.1794715 Test MSE 5.519459357623413 Test RE 1.1229394263692913\n",
      "50 Train Loss 1.1623161 Test MSE 5.536869785077486 Test RE 1.1247091161843488\n",
      "51 Train Loss 1.1521282 Test MSE 5.54883484088586 Test RE 1.125923696400852\n",
      "52 Train Loss 1.1405782 Test MSE 5.591093983682973 Test RE 1.1302030021680753\n",
      "53 Train Loss 1.1260823 Test MSE 5.593418987276873 Test RE 1.1304379698620164\n",
      "54 Train Loss 1.1164364 Test MSE 5.581865074136365 Test RE 1.1292698351401\n",
      "55 Train Loss 1.1063739 Test MSE 5.611175371882359 Test RE 1.1322308434646435\n",
      "56 Train Loss 1.0868382 Test MSE 5.641204968242383 Test RE 1.1352565077725925\n",
      "57 Train Loss 1.077748 Test MSE 5.644552738954275 Test RE 1.1355933165583854\n",
      "58 Train Loss 1.0664964 Test MSE 5.670419686804956 Test RE 1.1381923494981059\n",
      "59 Train Loss 1.0557535 Test MSE 5.6697669430355875 Test RE 1.1381268367682158\n",
      "60 Train Loss 1.0472863 Test MSE 5.6788496042116705 Test RE 1.139038080910408\n",
      "61 Train Loss 1.038339 Test MSE 5.69044319617947 Test RE 1.1402001833281346\n",
      "62 Train Loss 1.0295653 Test MSE 5.688751042975729 Test RE 1.1400306414504033\n",
      "63 Train Loss 1.0174075 Test MSE 5.732217136219215 Test RE 1.1443776750330863\n",
      "64 Train Loss 1.008324 Test MSE 5.743531058324471 Test RE 1.145506471897776\n",
      "65 Train Loss 0.99854374 Test MSE 5.757066712413662 Test RE 1.14685547260591\n",
      "66 Train Loss 0.98900795 Test MSE 5.778344877625714 Test RE 1.14897291145183\n",
      "67 Train Loss 0.9797855 Test MSE 5.802703715066897 Test RE 1.1513921345358364\n",
      "68 Train Loss 0.97175646 Test MSE 5.824352779858407 Test RE 1.1535379753408346\n",
      "69 Train Loss 0.9646126 Test MSE 5.839014439019547 Test RE 1.1549889649177985\n",
      "70 Train Loss 0.9591235 Test MSE 5.860185869249924 Test RE 1.157080982592821\n",
      "71 Train Loss 0.95106965 Test MSE 5.8713689980496575 Test RE 1.1581844986338292\n",
      "72 Train Loss 0.94228023 Test MSE 5.853050069586738 Test RE 1.1563762939281128\n",
      "73 Train Loss 0.9345015 Test MSE 5.842328316926811 Test RE 1.1553166700077269\n",
      "74 Train Loss 0.9279438 Test MSE 5.871969154095302 Test RE 1.1582436904226059\n",
      "75 Train Loss 0.922294 Test MSE 5.882516794256591 Test RE 1.1592834827076215\n",
      "76 Train Loss 0.9136418 Test MSE 5.923404858364917 Test RE 1.1633054664808056\n",
      "77 Train Loss 0.9058965 Test MSE 5.948790683740924 Test RE 1.1657955796116517\n",
      "78 Train Loss 0.89900714 Test MSE 5.958643398006658 Test RE 1.1667606075680108\n",
      "79 Train Loss 0.8930636 Test MSE 5.976960322441712 Test RE 1.168552547916769\n",
      "80 Train Loss 0.8873211 Test MSE 5.977371638218276 Test RE 1.1685927552967714\n",
      "81 Train Loss 0.88137025 Test MSE 5.9949268575321275 Test RE 1.1703075442237505\n",
      "82 Train Loss 0.8759173 Test MSE 5.9964593192691185 Test RE 1.1704571154342005\n",
      "83 Train Loss 0.870611 Test MSE 5.999629198132791 Test RE 1.1707664410608682\n",
      "84 Train Loss 0.86543787 Test MSE 6.028935504282585 Test RE 1.1736223710875158\n",
      "85 Train Loss 0.8604893 Test MSE 6.022408001432441 Test RE 1.1729868610480285\n",
      "86 Train Loss 0.8553081 Test MSE 6.040516917905105 Test RE 1.1747490778509513\n",
      "87 Train Loss 0.8500293 Test MSE 6.056384363716651 Test RE 1.1762910023591895\n",
      "88 Train Loss 0.8447311 Test MSE 6.059780164746174 Test RE 1.176620728000273\n",
      "89 Train Loss 0.840626 Test MSE 6.071036617784383 Test RE 1.1777130474111992\n",
      "90 Train Loss 0.8368323 Test MSE 6.070649471178882 Test RE 1.1776754957617543\n",
      "91 Train Loss 0.83222544 Test MSE 6.0882246691661726 Test RE 1.1793790137368338\n",
      "92 Train Loss 0.82766056 Test MSE 6.11894574353126 Test RE 1.1823508323754466\n",
      "93 Train Loss 0.8241622 Test MSE 6.123744424300767 Test RE 1.1828143609386221\n",
      "94 Train Loss 0.8209449 Test MSE 6.134328955985187 Test RE 1.1838361321020676\n",
      "95 Train Loss 0.81597114 Test MSE 6.1546769452845265 Test RE 1.1857979393534146\n",
      "96 Train Loss 0.81176805 Test MSE 6.16508055253602 Test RE 1.1867997276880744\n",
      "97 Train Loss 0.8084749 Test MSE 6.169377104278807 Test RE 1.1872132063347363\n",
      "98 Train Loss 0.8046975 Test MSE 6.1726517981003814 Test RE 1.1875282498082462\n",
      "99 Train Loss 0.80123246 Test MSE 6.183052326181083 Test RE 1.1885282837531996\n",
      "Training time: 67.52\n",
      "6\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.02147 Test MSE 8.527611557953158 Test RE 1.3957954074737582\n",
      "1 Train Loss 58.185993 Test MSE 8.673253962559832 Test RE 1.407664284905331\n",
      "2 Train Loss 51.094406 Test MSE 9.174718069616558 Test RE 1.4477861713606701\n",
      "3 Train Loss 44.982002 Test MSE 8.725502682621986 Test RE 1.4118978876215817\n",
      "4 Train Loss 43.03714 Test MSE 9.067929031009655 Test RE 1.4393357634961077\n",
      "5 Train Loss 40.825455 Test MSE 8.958082253282857 Test RE 1.4305913118454288\n",
      "6 Train Loss 35.310173 Test MSE 8.385118999733486 Test RE 1.384084724217817\n",
      "7 Train Loss 32.426994 Test MSE 8.374144002631935 Test RE 1.3831786369209138\n",
      "8 Train Loss 31.054405 Test MSE 8.374224417339681 Test RE 1.3831852780557448\n",
      "9 Train Loss 30.074821 Test MSE 8.288359018637474 Test RE 1.3760757376572044\n",
      "10 Train Loss 28.591427 Test MSE 8.287007697652198 Test RE 1.3759635564753248\n",
      "11 Train Loss 26.426699 Test MSE 8.159285149332932 Test RE 1.3653189428532364\n",
      "12 Train Loss 25.179077 Test MSE 7.731206553953742 Test RE 1.3290205567825841\n",
      "13 Train Loss 24.195614 Test MSE 7.996823199134691 Test RE 1.3516579634753292\n",
      "14 Train Loss 22.710276 Test MSE 7.784133325238623 Test RE 1.3335619431158465\n",
      "15 Train Loss 21.220219 Test MSE 7.629304604819033 Test RE 1.3202328590816856\n",
      "16 Train Loss 19.889126 Test MSE 7.254024723139371 Test RE 1.2873527823310091\n",
      "17 Train Loss 18.770859 Test MSE 6.99040630827833 Test RE 1.2637444750625733\n",
      "18 Train Loss 17.566582 Test MSE 6.793823868582666 Test RE 1.2458484093057178\n",
      "19 Train Loss 16.41542 Test MSE 6.365344068994761 Test RE 1.2059214001076122\n",
      "20 Train Loss 15.692022 Test MSE 6.259012318272955 Test RE 1.195806647729609\n",
      "21 Train Loss 14.686153 Test MSE 5.820677216683663 Test RE 1.1531739373961114\n",
      "22 Train Loss 14.210943 Test MSE 5.793396691755716 Test RE 1.150468398437582\n",
      "23 Train Loss 13.864729 Test MSE 5.834982473191095 Test RE 1.1545901236164509\n",
      "24 Train Loss 13.249459 Test MSE 5.8610504455405845 Test RE 1.1571663338010665\n",
      "25 Train Loss 12.5359 Test MSE 5.371388151524134 Test RE 1.1077744103528664\n",
      "26 Train Loss 10.003444 Test MSE 4.092323979602018 Test RE 0.9669256131206672\n",
      "27 Train Loss 7.898826 Test MSE 3.9389227273049814 Test RE 0.9486298599636798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 6.153765 Test MSE 3.4905777534038034 Test RE 0.8930108149404778\n",
      "29 Train Loss 5.2316113 Test MSE 3.3223517411832426 Test RE 0.8712260754061576\n",
      "30 Train Loss 4.525552 Test MSE 3.044117309125147 Test RE 0.8339475796001079\n",
      "31 Train Loss 3.9914682 Test MSE 3.105657439503227 Test RE 0.8423349786556602\n",
      "32 Train Loss 3.577406 Test MSE 2.7729119921105565 Test RE 0.7959322522621896\n",
      "33 Train Loss 3.07073 Test MSE 2.3685151265079503 Test RE 0.7356074883476492\n",
      "34 Train Loss 2.53307 Test MSE 2.32377722296035 Test RE 0.7286270757275196\n",
      "35 Train Loss 2.2683854 Test MSE 2.4738843981139 Test RE 0.7517921058417\n",
      "36 Train Loss 2.078539 Test MSE 2.5606183214382288 Test RE 0.7648574206478093\n",
      "37 Train Loss 1.9159236 Test MSE 2.571771824606003 Test RE 0.7665213879293709\n",
      "38 Train Loss 1.8307261 Test MSE 2.554325156062966 Test RE 0.7639169573108061\n",
      "39 Train Loss 1.7619004 Test MSE 2.543604605645869 Test RE 0.7623121848521014\n",
      "40 Train Loss 1.6954854 Test MSE 2.5374748042179536 Test RE 0.7613930874125031\n",
      "41 Train Loss 1.6547614 Test MSE 2.5408452628717155 Test RE 0.7618985884550421\n",
      "42 Train Loss 1.6082373 Test MSE 2.5674725274375367 Test RE 0.7658804131648171\n",
      "43 Train Loss 1.5593135 Test MSE 2.6405577438399557 Test RE 0.7767046314354591\n",
      "44 Train Loss 1.5204172 Test MSE 2.6938570354681186 Test RE 0.784504306828688\n",
      "45 Train Loss 1.4832939 Test MSE 2.643245413680472 Test RE 0.7770998120928911\n",
      "46 Train Loss 1.4437095 Test MSE 2.6259581080810595 Test RE 0.7745544564621564\n",
      "47 Train Loss 1.406352 Test MSE 2.604639018078382 Test RE 0.7714039019966753\n",
      "48 Train Loss 1.3677537 Test MSE 2.6040307337158906 Test RE 0.7713138203525933\n",
      "49 Train Loss 1.3359476 Test MSE 2.624696529039045 Test RE 0.7743683759877803\n",
      "50 Train Loss 1.3101466 Test MSE 2.5957113589406413 Test RE 0.7700807354260587\n",
      "51 Train Loss 1.29666 Test MSE 2.584423765573858 Test RE 0.7684045420055472\n",
      "52 Train Loss 1.2745852 Test MSE 2.599266418806295 Test RE 0.7706079023570096\n",
      "53 Train Loss 1.2573314 Test MSE 2.6169688780886573 Test RE 0.7732275851351385\n",
      "54 Train Loss 1.2401509 Test MSE 2.6288045867676377 Test RE 0.7749741424414021\n",
      "55 Train Loss 1.2260158 Test MSE 2.618453560821961 Test RE 0.7734468913097767\n",
      "56 Train Loss 1.2114533 Test MSE 2.618465293314831 Test RE 0.7734486240978065\n",
      "57 Train Loss 1.1912675 Test MSE 2.6422570363119986 Test RE 0.7769545097163416\n",
      "58 Train Loss 1.1789837 Test MSE 2.627916490085288 Test RE 0.7748432255016959\n",
      "59 Train Loss 1.1617631 Test MSE 2.602595702818478 Test RE 0.7711012630114552\n",
      "60 Train Loss 1.1402233 Test MSE 2.6114722241215547 Test RE 0.7724151187344146\n",
      "61 Train Loss 1.125414 Test MSE 2.6130199824438307 Test RE 0.7726439809891492\n",
      "62 Train Loss 1.1144376 Test MSE 2.614247530203708 Test RE 0.7728254465019854\n",
      "63 Train Loss 1.1025375 Test MSE 2.6210628567063896 Test RE 0.7738321662860953\n",
      "64 Train Loss 1.0850561 Test MSE 2.6271392809897596 Test RE 0.7747286366748111\n",
      "65 Train Loss 1.0668058 Test MSE 2.66407731483215 Test RE 0.7801560352103785\n",
      "66 Train Loss 1.0502628 Test MSE 2.6780803822933716 Test RE 0.7822036971806817\n",
      "67 Train Loss 1.0354673 Test MSE 2.6430480921092565 Test RE 0.7770708058158056\n",
      "68 Train Loss 1.0217122 Test MSE 2.62964625616537 Test RE 0.7750981949901482\n",
      "69 Train Loss 1.0096372 Test MSE 2.630176829923301 Test RE 0.7751763853587738\n",
      "70 Train Loss 0.99622166 Test MSE 2.642070810434675 Test RE 0.7769271294155744\n",
      "71 Train Loss 0.9878242 Test MSE 2.6621181897727912 Test RE 0.7798691245548781\n",
      "72 Train Loss 0.97389644 Test MSE 2.6715796509492113 Test RE 0.7812537657249262\n",
      "73 Train Loss 0.9574783 Test MSE 2.6565060302716224 Test RE 0.7790466480987149\n",
      "74 Train Loss 0.9482337 Test MSE 2.654751199641198 Test RE 0.7787892948783585\n",
      "75 Train Loss 0.9420686 Test MSE 2.6691269828578488 Test RE 0.7808950648024343\n",
      "76 Train Loss 0.93402666 Test MSE 2.6772185741944607 Test RE 0.782077830211446\n",
      "77 Train Loss 0.92405707 Test MSE 2.686749315186871 Test RE 0.7834686690718192\n",
      "78 Train Loss 0.91051865 Test MSE 2.6815084176422266 Test RE 0.782704160947985\n",
      "79 Train Loss 0.9019385 Test MSE 2.6814629191847255 Test RE 0.7826975206587301\n",
      "80 Train Loss 0.8904982 Test MSE 2.6929328055536117 Test RE 0.7843697182926977\n",
      "81 Train Loss 0.8797592 Test MSE 2.6784161426016913 Test RE 0.7822527294511439\n",
      "82 Train Loss 0.86813706 Test MSE 2.6836195469341066 Test RE 0.7830122085696111\n",
      "83 Train Loss 0.8605343 Test MSE 2.7043992099821663 Test RE 0.7860378525292688\n",
      "84 Train Loss 0.8533117 Test MSE 2.6951455028509104 Test RE 0.7846918979591048\n",
      "85 Train Loss 0.8449414 Test MSE 2.7041941482280696 Test RE 0.7860080512048485\n",
      "86 Train Loss 0.8380049 Test MSE 2.7134605895821156 Test RE 0.787353603373599\n",
      "87 Train Loss 0.82494956 Test MSE 2.7223505845263656 Test RE 0.7886423351604014\n",
      "88 Train Loss 0.8157891 Test MSE 2.729845018374664 Test RE 0.7897271266800977\n",
      "89 Train Loss 0.8046531 Test MSE 2.717649419475766 Test RE 0.7879610967108662\n",
      "90 Train Loss 0.7997749 Test MSE 2.7244349385593907 Test RE 0.7889441874122679\n",
      "91 Train Loss 0.79579544 Test MSE 2.7291829405017918 Test RE 0.7896313533744193\n",
      "92 Train Loss 0.7903308 Test MSE 2.7317513722016216 Test RE 0.7900028266877991\n",
      "93 Train Loss 0.78308976 Test MSE 2.739649823766302 Test RE 0.7911440899946898\n",
      "94 Train Loss 0.77416503 Test MSE 2.739234474381834 Test RE 0.7910841163324649\n",
      "95 Train Loss 0.76473874 Test MSE 2.741582879584444 Test RE 0.7914231504791176\n",
      "96 Train Loss 0.7573074 Test MSE 2.7285588637792797 Test RE 0.7895410665134202\n",
      "97 Train Loss 0.74997616 Test MSE 2.7165878321051524 Test RE 0.7878071822199778\n",
      "98 Train Loss 0.7436907 Test MSE 2.7458573318099035 Test RE 0.7920398713729827\n",
      "99 Train Loss 0.7372849 Test MSE 2.7400406017150094 Test RE 0.7912005115559744\n",
      "Training time: 68.55\n",
      "7\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 51.07379 Test MSE 8.494204153477796 Test RE 1.3930586704680603\n",
      "1 Train Loss 41.327503 Test MSE 5.697966680704866 Test RE 1.1409536786729133\n",
      "2 Train Loss 29.780151 Test MSE 5.2521124989202415 Test RE 1.0954058861553848\n",
      "3 Train Loss 23.427849 Test MSE 3.7747008493706016 Test RE 0.9286441552767526\n",
      "4 Train Loss 17.567022 Test MSE 3.7134450874304044 Test RE 0.9210783267924778\n",
      "5 Train Loss 13.516006 Test MSE 3.5151910797514203 Test RE 0.8961537553084372\n",
      "6 Train Loss 11.215903 Test MSE 3.983205191061029 Test RE 0.9539473368298466\n",
      "7 Train Loss 9.89967 Test MSE 4.056086117932356 Test RE 0.9626349910755582\n",
      "8 Train Loss 8.909057 Test MSE 3.9543361820737974 Test RE 0.950484096300444\n",
      "9 Train Loss 8.499593 Test MSE 3.9425997436285525 Test RE 0.949072533513335\n",
      "10 Train Loss 8.097004 Test MSE 3.870508990733979 Test RE 0.9403555683305804\n",
      "11 Train Loss 7.6809278 Test MSE 3.8979063074224993 Test RE 0.9436778431157042\n",
      "12 Train Loss 7.3440647 Test MSE 3.857564058724367 Test RE 0.9387817399260446\n",
      "13 Train Loss 6.758301 Test MSE 3.68533538878115 Test RE 0.917585556979757\n",
      "14 Train Loss 5.323638 Test MSE 3.528608743442044 Test RE 0.8978624586116734\n",
      "15 Train Loss 4.4444184 Test MSE 3.347536425106747 Test RE 0.8745219529319694\n",
      "16 Train Loss 3.6440666 Test MSE 3.1724891919763447 Test RE 0.8513499912222728\n",
      "17 Train Loss 2.5011406 Test MSE 3.002185006373131 Test RE 0.8281839049555929\n",
      "18 Train Loss 2.0514846 Test MSE 2.720312565482747 Test RE 0.7883470813033816\n",
      "19 Train Loss 1.677206 Test MSE 1.8318340401918358 Test RE 0.6469208117320486\n",
      "20 Train Loss 1.3404262 Test MSE 1.3187708001772185 Test RE 0.5488993564010816\n",
      "21 Train Loss 1.058246 Test MSE 0.4996269269004948 Test RE 0.3378554884238232\n",
      "22 Train Loss 0.66257125 Test MSE 0.1549106048212139 Test RE 0.18812591925229907\n",
      "23 Train Loss 0.380938 Test MSE 0.09889682793258267 Test RE 0.15031393401409043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 0.23984897 Test MSE 0.0784226737963981 Test RE 0.13385323844037295\n",
      "25 Train Loss 0.16121219 Test MSE 0.051629827148040965 Test RE 0.10860714461105071\n",
      "26 Train Loss 0.1287305 Test MSE 0.04645176536294437 Test RE 0.1030170649112442\n",
      "27 Train Loss 0.09089863 Test MSE 0.03589239158533413 Test RE 0.09055433777181751\n",
      "28 Train Loss 0.06968799 Test MSE 0.024344540522109156 Test RE 0.07457767696857386\n",
      "29 Train Loss 0.058347043 Test MSE 0.022270455121974144 Test RE 0.07133006281840065\n",
      "30 Train Loss 0.04719338 Test MSE 0.013880522288406071 Test RE 0.056313298201432674\n",
      "31 Train Loss 0.039221916 Test MSE 0.007891431905600455 Test RE 0.04246058437580516\n",
      "32 Train Loss 0.034090605 Test MSE 0.006792877129057516 Test RE 0.03939444077398882\n",
      "33 Train Loss 0.03085236 Test MSE 0.005391401307566833 Test RE 0.03509610252554479\n",
      "34 Train Loss 0.027579034 Test MSE 0.005153792192811909 Test RE 0.034314013036148706\n",
      "35 Train Loss 0.024168007 Test MSE 0.006285018738677036 Test RE 0.03789320581495094\n",
      "36 Train Loss 0.021785973 Test MSE 0.005844738537820107 Test RE 0.03654185620086416\n",
      "37 Train Loss 0.017407887 Test MSE 0.005408110188750239 Test RE 0.035150444887099154\n",
      "38 Train Loss 0.015212939 Test MSE 0.0054032154485169435 Test RE 0.035134534408350966\n",
      "39 Train Loss 0.01322037 Test MSE 0.00469175697743561 Test RE 0.03273978435522446\n",
      "40 Train Loss 0.011540218 Test MSE 0.003871328420799899 Test RE 0.029739801688094605\n",
      "41 Train Loss 0.009747204 Test MSE 0.0025236359466286854 Test RE 0.024011617289402945\n",
      "42 Train Loss 0.008855716 Test MSE 0.0021455659055893556 Test RE 0.022140070015503402\n",
      "43 Train Loss 0.007994471 Test MSE 0.0020228374524138898 Test RE 0.021497529482714557\n",
      "44 Train Loss 0.0073889326 Test MSE 0.0018140407245327845 Test RE 0.02035783436618679\n",
      "45 Train Loss 0.006793976 Test MSE 0.0016563108350107895 Test RE 0.01945265935501516\n",
      "46 Train Loss 0.0063474374 Test MSE 0.0017092221599836611 Test RE 0.019760927175760418\n",
      "47 Train Loss 0.0057087136 Test MSE 0.001637796436346902 Test RE 0.019343631989151882\n",
      "48 Train Loss 0.005276662 Test MSE 0.001390267893027625 Test RE 0.017822035602179483\n",
      "49 Train Loss 0.004881895 Test MSE 0.001334015656166637 Test RE 0.017457760193054377\n",
      "50 Train Loss 0.0045515285 Test MSE 0.0012310066201263361 Test RE 0.016770200483833396\n",
      "51 Train Loss 0.0042785164 Test MSE 0.0010309021712920803 Test RE 0.015346763038444455\n",
      "52 Train Loss 0.0037269576 Test MSE 0.0009541865905211221 Test RE 0.014764702981479015\n",
      "53 Train Loss 0.0034791287 Test MSE 0.0009208261842113399 Test RE 0.014504303889558671\n",
      "54 Train Loss 0.0033090445 Test MSE 0.000865696962275405 Test RE 0.014063421944079333\n",
      "55 Train Loss 0.003001185 Test MSE 0.0008609130479804157 Test RE 0.014024510285512859\n",
      "56 Train Loss 0.0026462548 Test MSE 0.0008026597974181213 Test RE 0.013541719567687915\n",
      "57 Train Loss 0.0025189794 Test MSE 0.0007582330663945661 Test RE 0.013161622197453733\n",
      "58 Train Loss 0.0023243008 Test MSE 0.0007869967688723466 Test RE 0.013408942700248113\n",
      "59 Train Loss 0.002197471 Test MSE 0.0008010209288064361 Test RE 0.013527887780390449\n",
      "60 Train Loss 0.0020818799 Test MSE 0.0007597188528781407 Test RE 0.013174511235624164\n",
      "61 Train Loss 0.001988384 Test MSE 0.0006947006728505498 Test RE 0.012598154207892887\n",
      "62 Train Loss 0.001878557 Test MSE 0.0006661823320873656 Test RE 0.012336859409139556\n",
      "63 Train Loss 0.0017874964 Test MSE 0.000674302703823994 Test RE 0.012411821204664612\n",
      "64 Train Loss 0.0017129921 Test MSE 0.0006465346883070686 Test RE 0.01215357305096426\n",
      "65 Train Loss 0.0016092679 Test MSE 0.0005845371980448483 Test RE 0.011556175720754519\n",
      "66 Train Loss 0.001526093 Test MSE 0.0005666367889386858 Test RE 0.011377856292552472\n",
      "67 Train Loss 0.0014687942 Test MSE 0.0005489310192115415 Test RE 0.011198682880613908\n",
      "68 Train Loss 0.0013800173 Test MSE 0.0005217168834296342 Test RE 0.01091755795251282\n",
      "69 Train Loss 0.0013177027 Test MSE 0.0004931465061723348 Test RE 0.010614414437981659\n",
      "70 Train Loss 0.0012609297 Test MSE 0.0004676995349830595 Test RE 0.010336928905601773\n",
      "71 Train Loss 0.0012280985 Test MSE 0.0004707068984793255 Test RE 0.010370109491895322\n",
      "72 Train Loss 0.001177378 Test MSE 0.00043156762161662574 Test RE 0.009929616770782078\n",
      "73 Train Loss 0.001113023 Test MSE 0.0004020028833539708 Test RE 0.009583466836312615\n",
      "74 Train Loss 0.0010638821 Test MSE 0.0003720197085104392 Test RE 0.009219153250719442\n",
      "75 Train Loss 0.0010025428 Test MSE 0.00033704801239326263 Test RE 0.008775137807378323\n",
      "76 Train Loss 0.0009626894 Test MSE 0.0003446218922618268 Test RE 0.008873184086448901\n",
      "77 Train Loss 0.0009245229 Test MSE 0.0003445772294820834 Test RE 0.008872609088289617\n",
      "78 Train Loss 0.0008816167 Test MSE 0.0003024235510359996 Test RE 0.008312197709177849\n",
      "79 Train Loss 0.0008523094 Test MSE 0.0002886019339251818 Test RE 0.008120030841279161\n",
      "80 Train Loss 0.0008278839 Test MSE 0.0002975395336820442 Test RE 0.008244805205074902\n",
      "81 Train Loss 0.0008016895 Test MSE 0.0002893741153609761 Test RE 0.008130886535323862\n",
      "82 Train Loss 0.00076515425 Test MSE 0.00027560682276197787 Test RE 0.00793511166305343\n",
      "83 Train Loss 0.00072122284 Test MSE 0.0002464454660718366 Test RE 0.007503579299872541\n",
      "84 Train Loss 0.00069959654 Test MSE 0.0002244045258886338 Test RE 0.007160178779113362\n",
      "85 Train Loss 0.0006846163 Test MSE 0.00022130072505138564 Test RE 0.00711048916023075\n",
      "86 Train Loss 0.0006524186 Test MSE 0.00021604269028817179 Test RE 0.0070255098763935845\n",
      "87 Train Loss 0.0006246951 Test MSE 0.0002057009481628596 Test RE 0.006855295927815564\n",
      "88 Train Loss 0.0005889634 Test MSE 0.00019916025937229037 Test RE 0.006745426304611193\n",
      "89 Train Loss 0.0005749676 Test MSE 0.0001902505520059888 Test RE 0.006592817031243795\n",
      "90 Train Loss 0.0005558332 Test MSE 0.00017715809311571822 Test RE 0.006361925202557186\n",
      "91 Train Loss 0.00053681387 Test MSE 0.00017032551119258165 Test RE 0.006238036488955876\n",
      "92 Train Loss 0.00052221376 Test MSE 0.00015722144560387173 Test RE 0.0059932715114848585\n",
      "93 Train Loss 0.00050502364 Test MSE 0.00014560362496505343 Test RE 0.005767586995870706\n",
      "94 Train Loss 0.00049547583 Test MSE 0.00014261959118084107 Test RE 0.005708179925293142\n",
      "95 Train Loss 0.00047939544 Test MSE 0.00013270210511347167 Test RE 0.005506136409556177\n",
      "96 Train Loss 0.0004635614 Test MSE 0.00012668744833063821 Test RE 0.005379908070971442\n",
      "97 Train Loss 0.00045244122 Test MSE 0.00012038803621445373 Test RE 0.005244447296818514\n",
      "98 Train Loss 0.00044235948 Test MSE 0.00011118165923205912 Test RE 0.005039931523031783\n",
      "99 Train Loss 0.00043046387 Test MSE 0.00010861181721824713 Test RE 0.004981344759129676\n",
      "Training time: 67.87\n",
      "8\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.163525 Test MSE 8.68097460126237 Test RE 1.4082906732184186\n",
      "1 Train Loss 33.785595 Test MSE 8.492756960047236 Test RE 1.3929399947689087\n",
      "2 Train Loss 24.430483 Test MSE 7.6840503280075 Test RE 1.324961199967243\n",
      "3 Train Loss 18.859756 Test MSE 7.589730487614807 Test RE 1.3168043041981043\n",
      "4 Train Loss 15.93035 Test MSE 7.161952458490908 Test RE 1.2791567802652752\n",
      "5 Train Loss 13.630297 Test MSE 6.825545198564686 Test RE 1.2487535438482993\n",
      "6 Train Loss 11.974992 Test MSE 7.092205128038833 Test RE 1.2729129487688242\n",
      "7 Train Loss 10.292871 Test MSE 6.788944749550856 Test RE 1.2454009636132295\n",
      "8 Train Loss 8.934759 Test MSE 6.707596306700454 Test RE 1.2379169763659206\n",
      "9 Train Loss 7.8925233 Test MSE 6.381803706356023 Test RE 1.207479541645096\n",
      "10 Train Loss 6.3819532 Test MSE 5.856573840886345 Test RE 1.1567243340467712\n",
      "11 Train Loss 4.874493 Test MSE 5.259832942423426 Test RE 1.096210696948337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 3.54291 Test MSE 5.060389154173018 Test RE 1.0752266459581243\n",
      "13 Train Loss 2.9448528 Test MSE 4.841605859015953 Test RE 1.0517264016802672\n",
      "14 Train Loss 2.6042597 Test MSE 4.7582958786027065 Test RE 1.0426385592276084\n",
      "15 Train Loss 2.391852 Test MSE 4.757366850634955 Test RE 1.042536769879975\n",
      "16 Train Loss 2.2410178 Test MSE 4.633282408944855 Test RE 1.0288509108425783\n",
      "17 Train Loss 2.0999103 Test MSE 4.552220684227496 Test RE 1.0198110518471566\n",
      "18 Train Loss 1.9824891 Test MSE 4.427236589949714 Test RE 1.0057138381340045\n",
      "19 Train Loss 1.8596885 Test MSE 4.3438222274051075 Test RE 0.9961943675522302\n",
      "20 Train Loss 1.7700701 Test MSE 4.37706844529797 Test RE 0.9999993764550009\n",
      "21 Train Loss 1.7037271 Test MSE 4.305502438814475 Test RE 0.9917905822996668\n",
      "22 Train Loss 1.6575791 Test MSE 4.321426579800318 Test RE 0.9936229859533035\n",
      "23 Train Loss 1.6187838 Test MSE 4.357598379554495 Test RE 0.997772800174757\n",
      "24 Train Loss 1.5776299 Test MSE 4.3231146393762945 Test RE 0.9938170342610576\n",
      "25 Train Loss 1.532965 Test MSE 4.277103907462439 Test RE 0.9885143103700087\n",
      "26 Train Loss 1.5052662 Test MSE 4.250820399819628 Test RE 0.9854723382261013\n",
      "27 Train Loss 1.4835365 Test MSE 4.223487119876151 Test RE 0.9822988764865733\n",
      "28 Train Loss 1.4616466 Test MSE 4.201518038723515 Test RE 0.9797407604693931\n",
      "29 Train Loss 1.4370345 Test MSE 4.169414981651673 Test RE 0.9759905700649347\n",
      "30 Train Loss 1.4192928 Test MSE 4.159504846606253 Test RE 0.9748299812758494\n",
      "31 Train Loss 1.4053379 Test MSE 4.15987815999987 Test RE 0.974873725535918\n",
      "32 Train Loss 1.3863283 Test MSE 4.12269800769844 Test RE 0.970507334752484\n",
      "33 Train Loss 1.3713144 Test MSE 4.100913289579224 Test RE 0.9679398131816982\n",
      "34 Train Loss 1.3593751 Test MSE 4.071780306069432 Test RE 0.964495551763787\n",
      "35 Train Loss 1.3419834 Test MSE 4.024799218546684 Test RE 0.9589151282112098\n",
      "36 Train Loss 1.3291897 Test MSE 4.001337297504989 Test RE 0.9561161222458882\n",
      "37 Train Loss 1.3133763 Test MSE 3.9235129010757395 Test RE 0.9467724299412472\n",
      "38 Train Loss 1.2970732 Test MSE 3.8479340879235404 Test RE 0.9376092266808841\n",
      "39 Train Loss 1.2639389 Test MSE 3.7173674651819493 Test RE 0.921564649268359\n",
      "40 Train Loss 1.2333579 Test MSE 3.65793609247923 Test RE 0.9141682150523502\n",
      "41 Train Loss 1.1899159 Test MSE 3.5674996912997314 Test RE 0.9027968443797254\n",
      "42 Train Loss 1.1349428 Test MSE 3.4195973017291403 Test RE 0.8838845510090169\n",
      "43 Train Loss 1.0941457 Test MSE 3.344389354091167 Test RE 0.8741107804326093\n",
      "44 Train Loss 1.067712 Test MSE 3.31581248993448 Test RE 0.8703682534800605\n",
      "45 Train Loss 1.0416903 Test MSE 3.2577085972079356 Test RE 0.862708699113365\n",
      "46 Train Loss 0.9989549 Test MSE 3.141187632665192 Test RE 0.8471396315667202\n",
      "47 Train Loss 0.96458626 Test MSE 3.0397027495207976 Test RE 0.8333426674666677\n",
      "48 Train Loss 0.92379546 Test MSE 2.977021638792542 Test RE 0.8247058134471742\n",
      "49 Train Loss 0.8818504 Test MSE 2.8964956745123556 Test RE 0.8134755466315161\n",
      "50 Train Loss 0.8547957 Test MSE 2.815660317113969 Test RE 0.8020439927344656\n",
      "51 Train Loss 0.8198775 Test MSE 2.8126578720696656 Test RE 0.8016162537598256\n",
      "52 Train Loss 0.791087 Test MSE 2.761869464774111 Test RE 0.7943458565660697\n",
      "53 Train Loss 0.76603067 Test MSE 2.714689440647257 Test RE 0.7875318685010925\n",
      "54 Train Loss 0.7469639 Test MSE 2.7264008324299662 Test RE 0.789228778692579\n",
      "55 Train Loss 0.7279148 Test MSE 2.6893728867238713 Test RE 0.7838510986020852\n",
      "56 Train Loss 0.71365255 Test MSE 2.662410028475176 Test RE 0.7799118705450668\n",
      "57 Train Loss 0.7003675 Test MSE 2.6435032763248016 Test RE 0.7771377162777426\n",
      "58 Train Loss 0.68578243 Test MSE 2.633824554398333 Test RE 0.7757137351918115\n",
      "59 Train Loss 0.6753532 Test MSE 2.6429834190241146 Test RE 0.7770612986346898\n",
      "60 Train Loss 0.6658333 Test MSE 2.63123141881885 Test RE 0.7753317761428278\n",
      "61 Train Loss 0.65805197 Test MSE 2.6316908686334846 Test RE 0.7753994650753037\n",
      "62 Train Loss 0.64878273 Test MSE 2.647376173625426 Test RE 0.777706785554187\n",
      "63 Train Loss 0.6397066 Test MSE 2.6529597694689633 Test RE 0.7785264864309861\n",
      "64 Train Loss 0.6308743 Test MSE 2.669304535741867 Test RE 0.7809210373144304\n",
      "65 Train Loss 0.623798 Test MSE 2.6736592603644294 Test RE 0.7815577781159243\n",
      "66 Train Loss 0.6145783 Test MSE 2.6851107775772878 Test RE 0.7832297300204323\n",
      "67 Train Loss 0.60691535 Test MSE 2.676300005423016 Test RE 0.7819436510468686\n",
      "68 Train Loss 0.60093975 Test MSE 2.6976886673321268 Test RE 0.7850620319679407\n",
      "69 Train Loss 0.5963504 Test MSE 2.7088821345878857 Test RE 0.7866890672885765\n",
      "70 Train Loss 0.59253293 Test MSE 2.6986352882933775 Test RE 0.7851997593125122\n",
      "71 Train Loss 0.5873326 Test MSE 2.7067876686564207 Test RE 0.786384880545818\n",
      "72 Train Loss 0.58248186 Test MSE 2.7075263025113867 Test RE 0.7864921683988717\n",
      "73 Train Loss 0.5770273 Test MSE 2.715272885743114 Test RE 0.7876164927152225\n",
      "74 Train Loss 0.571685 Test MSE 2.731231927795266 Test RE 0.7899277133259024\n",
      "75 Train Loss 0.56694686 Test MSE 2.7208173131964637 Test RE 0.7884202159011385\n",
      "76 Train Loss 0.5617764 Test MSE 2.7287058546385903 Test RE 0.7895623330065863\n",
      "77 Train Loss 0.55737543 Test MSE 2.7337468137505807 Test RE 0.790291307680116\n",
      "78 Train Loss 0.5522918 Test MSE 2.7414433551471977 Test RE 0.7914030116980761\n",
      "79 Train Loss 0.5463038 Test MSE 2.779418859306293 Test RE 0.7968655654693345\n",
      "80 Train Loss 0.5424496 Test MSE 2.785876087424078 Test RE 0.7977906792958243\n",
      "81 Train Loss 0.5396338 Test MSE 2.7878091024728495 Test RE 0.7980674098331304\n",
      "82 Train Loss 0.5363412 Test MSE 2.8008963682779418 Test RE 0.7999384653420528\n",
      "83 Train Loss 0.5329946 Test MSE 2.815807766278102 Test RE 0.8020649929892535\n",
      "84 Train Loss 0.52943045 Test MSE 2.8425737245137674 Test RE 0.8058680335814068\n",
      "85 Train Loss 0.5246067 Test MSE 2.8441925689030274 Test RE 0.8060974716514848\n",
      "86 Train Loss 0.51977503 Test MSE 2.854422965657845 Test RE 0.8075459134046507\n",
      "87 Train Loss 0.5133606 Test MSE 2.872208635535599 Test RE 0.8100578819123908\n",
      "88 Train Loss 0.50635576 Test MSE 2.8945605927125473 Test RE 0.8132037691283572\n",
      "89 Train Loss 0.50052035 Test MSE 2.917166032735666 Test RE 0.8163730027903485\n",
      "90 Train Loss 0.49347055 Test MSE 2.9289551680803725 Test RE 0.8180209425400565\n",
      "91 Train Loss 0.4879643 Test MSE 2.935109606721628 Test RE 0.8188799208329715\n",
      "92 Train Loss 0.48241216 Test MSE 2.9492509963582316 Test RE 0.8208502365647237\n",
      "93 Train Loss 0.47748694 Test MSE 2.957423337031879 Test RE 0.8219867330985415\n",
      "94 Train Loss 0.47346735 Test MSE 2.9702014328359216 Test RE 0.8237605921262642\n",
      "95 Train Loss 0.4677172 Test MSE 2.9827357671700234 Test RE 0.8254969087660224\n",
      "96 Train Loss 0.46312216 Test MSE 2.995412988109609 Test RE 0.8272493118433442\n",
      "97 Train Loss 0.45715392 Test MSE 3.0110957223233847 Test RE 0.8294120510790897\n",
      "98 Train Loss 0.45264834 Test MSE 3.024565507031405 Test RE 0.8312651199447311\n",
      "99 Train Loss 0.4468561 Test MSE 3.0511649513626256 Test RE 0.8349123857738644\n",
      "Training time: 67.40\n",
      "9\n",
      "KG_rowdy_tune12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.199528 Test MSE 8.286575132086346 Test RE 1.3759276447057627\n",
      "1 Train Loss 52.59603 Test MSE 8.97718357877608 Test RE 1.432115725113747\n",
      "2 Train Loss 45.27269 Test MSE 8.569747303795337 Test RE 1.3992395377000941\n",
      "3 Train Loss 43.820435 Test MSE 8.45693761082146 Test RE 1.3899994346846085\n",
      "4 Train Loss 42.61617 Test MSE 8.63833752165436 Test RE 1.404827967992817\n",
      "5 Train Loss 41.55865 Test MSE 8.994878483764872 Test RE 1.433526450219658\n",
      "6 Train Loss 40.327904 Test MSE 9.164188737601064 Test RE 1.446955159583229\n",
      "7 Train Loss 39.49029 Test MSE 9.324955062547089 Test RE 1.4595918646941617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 38.085632 Test MSE 9.454104412007268 Test RE 1.469664681472905\n",
      "9 Train Loss 35.968124 Test MSE 9.360861834347096 Test RE 1.4623993247124785\n",
      "10 Train Loss 31.976221 Test MSE 8.970459868622813 Test RE 1.4315793132962953\n",
      "11 Train Loss 28.500183 Test MSE 8.889626277027041 Test RE 1.4251146743306946\n",
      "12 Train Loss 26.716421 Test MSE 9.046692895589777 Test RE 1.4376493891532747\n",
      "13 Train Loss 25.655663 Test MSE 9.254718519886818 Test RE 1.4540845749729492\n",
      "14 Train Loss 24.554012 Test MSE 9.071848833772725 Test RE 1.4396468214403422\n",
      "15 Train Loss 23.894478 Test MSE 8.780599850133267 Test RE 1.4163485857512563\n",
      "16 Train Loss 22.396114 Test MSE 8.738476396239557 Test RE 1.4129471540996337\n",
      "17 Train Loss 20.70099 Test MSE 8.92429309167605 Test RE 1.4278907254899644\n",
      "18 Train Loss 18.007908 Test MSE 8.403699565345239 Test RE 1.3856173706949462\n",
      "19 Train Loss 16.436897 Test MSE 8.361390868492443 Test RE 1.3821250018374551\n",
      "20 Train Loss 15.61877 Test MSE 8.249490196776431 Test RE 1.372845345661868\n",
      "21 Train Loss 14.899672 Test MSE 8.233341162812602 Test RE 1.371500960362611\n",
      "22 Train Loss 12.81901 Test MSE 7.5547965677278475 Test RE 1.313770323499752\n",
      "23 Train Loss 10.555677 Test MSE 7.062255959601009 Test RE 1.2702224586310638\n",
      "24 Train Loss 9.2672615 Test MSE 6.972890140277581 Test RE 1.262160171967661\n",
      "25 Train Loss 8.419266 Test MSE 7.356266811747797 Test RE 1.2963933560673415\n",
      "26 Train Loss 7.397187 Test MSE 7.472501644318569 Test RE 1.3065952346479741\n",
      "27 Train Loss 6.121234 Test MSE 6.757319895359594 Test RE 1.242496859966129\n",
      "28 Train Loss 4.908905 Test MSE 6.56887226437192 Test RE 1.2250490241600285\n",
      "29 Train Loss 4.271181 Test MSE 6.584119906375282 Test RE 1.2264699896848568\n",
      "30 Train Loss 3.7339613 Test MSE 6.842304252933294 Test RE 1.25028566306825\n",
      "31 Train Loss 3.4548566 Test MSE 6.87571906559027 Test RE 1.2533348682331311\n",
      "32 Train Loss 3.2434633 Test MSE 6.822099865121417 Test RE 1.2484383371295316\n",
      "33 Train Loss 3.0665777 Test MSE 6.861607665016952 Test RE 1.2520480650515156\n",
      "34 Train Loss 2.916742 Test MSE 6.832980714937644 Test RE 1.249433533490305\n",
      "35 Train Loss 2.8304286 Test MSE 6.807248166908524 Test RE 1.247078672806931\n",
      "36 Train Loss 2.7019734 Test MSE 6.8835123137695495 Test RE 1.2540449600365857\n",
      "37 Train Loss 2.612193 Test MSE 6.8504279397079255 Test RE 1.2510276584367168\n",
      "38 Train Loss 2.5263534 Test MSE 6.881513269139989 Test RE 1.2538628528679119\n",
      "39 Train Loss 2.4036372 Test MSE 6.847949072191556 Test RE 1.250801292110166\n",
      "40 Train Loss 2.307663 Test MSE 6.829933910927664 Test RE 1.2491549432446178\n",
      "41 Train Loss 2.194049 Test MSE 6.720709702515644 Test RE 1.2391264535207243\n",
      "42 Train Loss 2.1005466 Test MSE 6.703176520045287 Test RE 1.2375090634359571\n",
      "43 Train Loss 2.0229297 Test MSE 6.6623229555979515 Test RE 1.2337322030818632\n",
      "44 Train Loss 1.9476296 Test MSE 6.485916473228238 Test RE 1.217289107805178\n",
      "45 Train Loss 1.8758049 Test MSE 6.3772661393348855 Test RE 1.2070501964424274\n",
      "46 Train Loss 1.8368464 Test MSE 6.378089228569434 Test RE 1.2071280885944475\n",
      "47 Train Loss 1.7829056 Test MSE 6.306419928287643 Test RE 1.2003268011992567\n",
      "48 Train Loss 1.7137067 Test MSE 6.123764485238985 Test RE 1.1828162983436423\n",
      "49 Train Loss 1.6617761 Test MSE 6.041651723037995 Test RE 1.1748594201193343\n",
      "50 Train Loss 1.6272415 Test MSE 6.023874503314932 Test RE 1.1731296679396028\n",
      "51 Train Loss 1.5747597 Test MSE 6.001685327494506 Test RE 1.1709670402116201\n",
      "52 Train Loss 1.5346278 Test MSE 5.943674535976729 Test RE 1.1652941612809078\n",
      "53 Train Loss 1.5086309 Test MSE 5.917310984100607 Test RE 1.1627069204068141\n",
      "54 Train Loss 1.4767686 Test MSE 5.879271660600658 Test RE 1.158963674965535\n",
      "55 Train Loss 1.4491824 Test MSE 5.8440958873788125 Test RE 1.1554914247513721\n",
      "56 Train Loss 1.4226217 Test MSE 5.800202729264378 Test RE 1.1511439807552026\n",
      "57 Train Loss 1.3954641 Test MSE 5.787824786423674 Test RE 1.1499150233286024\n",
      "58 Train Loss 1.3721381 Test MSE 5.819069034597278 Test RE 1.1530146224476838\n",
      "59 Train Loss 1.3575162 Test MSE 5.839718871501481 Test RE 1.1550586331138724\n",
      "60 Train Loss 1.3404181 Test MSE 5.832428277216922 Test RE 1.1543373917309803\n",
      "61 Train Loss 1.3211656 Test MSE 5.834421416948271 Test RE 1.1545346131181444\n",
      "62 Train Loss 1.2923787 Test MSE 5.758659755912765 Test RE 1.1470141353743564\n",
      "63 Train Loss 1.2705393 Test MSE 5.730844498978223 Test RE 1.1442406504381222\n",
      "64 Train Loss 1.2546306 Test MSE 5.729969569000631 Test RE 1.1441533012995724\n",
      "65 Train Loss 1.2406703 Test MSE 5.726565314734614 Test RE 1.1438133721430017\n",
      "66 Train Loss 1.2242174 Test MSE 5.725448506545798 Test RE 1.1437018321222636\n",
      "67 Train Loss 1.2125754 Test MSE 5.726941625798444 Test RE 1.1438509533572412\n",
      "68 Train Loss 1.199273 Test MSE 5.717429099149156 Test RE 1.142900582681262\n",
      "69 Train Loss 1.1863477 Test MSE 5.703155729499282 Test RE 1.1414730847468193\n",
      "70 Train Loss 1.1779201 Test MSE 5.692482389318164 Test RE 1.1404044626827088\n",
      "71 Train Loss 1.1631012 Test MSE 5.711045236803177 Test RE 1.1422623449656504\n",
      "72 Train Loss 1.154796 Test MSE 5.702978080767482 Test RE 1.1414553066223347\n",
      "73 Train Loss 1.1463696 Test MSE 5.691727271561157 Test RE 1.1403288218496883\n",
      "74 Train Loss 1.1348522 Test MSE 5.7240038254972125 Test RE 1.1435575300119531\n",
      "75 Train Loss 1.1241206 Test MSE 5.7272555229414355 Test RE 1.1438823005098668\n",
      "76 Train Loss 1.1100438 Test MSE 5.728680414020516 Test RE 1.1440245856161362\n",
      "77 Train Loss 1.0998565 Test MSE 5.749054451593511 Test RE 1.1460571403157422\n",
      "78 Train Loss 1.0908856 Test MSE 5.768746008795387 Test RE 1.148018189595508\n",
      "79 Train Loss 1.0842868 Test MSE 5.787086731576653 Test RE 1.1498417032605346\n",
      "80 Train Loss 1.0763693 Test MSE 5.777754132213268 Test RE 1.14891417769332\n",
      "81 Train Loss 1.0657357 Test MSE 5.763719952937381 Test RE 1.1475179716214647\n",
      "82 Train Loss 1.0579932 Test MSE 5.764233230336614 Test RE 1.1475690655271777\n",
      "83 Train Loss 1.0484637 Test MSE 5.7783242437476074 Test RE 1.1489708600176678\n",
      "84 Train Loss 1.0373818 Test MSE 5.8224752075950486 Test RE 1.1533520297459923\n",
      "85 Train Loss 1.0240716 Test MSE 5.860161512845353 Test RE 1.1570785780307093\n",
      "86 Train Loss 1.0145204 Test MSE 5.881309225263442 Test RE 1.1591644871579017\n",
      "87 Train Loss 1.0036558 Test MSE 5.890886161272242 Test RE 1.1601078764731125\n",
      "88 Train Loss 0.9942757 Test MSE 5.902635052493432 Test RE 1.1612641704219426\n",
      "89 Train Loss 0.98293924 Test MSE 5.933118026480686 Test RE 1.164258866886771\n",
      "90 Train Loss 0.97152084 Test MSE 5.929091877610331 Test RE 1.1638637731949908\n",
      "91 Train Loss 0.96407104 Test MSE 5.954410602233547 Test RE 1.1663461225578284\n",
      "92 Train Loss 0.9557067 Test MSE 5.947421093428071 Test RE 1.1656613713054618\n",
      "93 Train Loss 0.94528544 Test MSE 5.935400549059857 Test RE 1.1644827956543389\n",
      "94 Train Loss 0.9367645 Test MSE 5.9735600180118285 Test RE 1.168220104711921\n",
      "95 Train Loss 0.9274899 Test MSE 5.977213073949652 Test RE 1.1685772553165408\n",
      "96 Train Loss 0.9191171 Test MSE 5.992582987704871 Test RE 1.1700787410393776\n",
      "97 Train Loss 0.90964395 Test MSE 6.011792586012132 Test RE 1.171952620701292\n",
      "98 Train Loss 0.9028082 Test MSE 6.001795647343943 Test RE 1.170977802214865\n",
      "99 Train Loss 0.8959893 Test MSE 6.030014798982676 Test RE 1.173727416805704\n",
      "Training time: 67.70\n",
      "0\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 59.922783 Test MSE 6.329871428500397 Test RE 1.2025565403738236\n",
      "1 Train Loss 34.60736 Test MSE 7.089252356885018 Test RE 1.2726479386720777\n",
      "2 Train Loss 23.036287 Test MSE 6.05689839720983 Test RE 1.1763409199426222\n",
      "3 Train Loss 18.308414 Test MSE 6.014082644741484 Test RE 1.1721758140959717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 14.416576 Test MSE 5.8954587874899484 Test RE 1.160558038853918\n",
      "5 Train Loss 12.669873 Test MSE 5.8663157147223455 Test RE 1.1576859867662537\n",
      "6 Train Loss 11.5058155 Test MSE 5.959335617974089 Test RE 1.1668283773169892\n",
      "7 Train Loss 10.266614 Test MSE 5.85467387766679 Test RE 1.15653668918621\n",
      "8 Train Loss 9.45541 Test MSE 5.826197554438161 Test RE 1.1537206436248955\n",
      "9 Train Loss 8.804638 Test MSE 5.900059388141114 Test RE 1.1610107790923172\n",
      "10 Train Loss 7.9767356 Test MSE 5.56897530247752 Test RE 1.1279652135557752\n",
      "11 Train Loss 6.839636 Test MSE 5.279872520454206 Test RE 1.0982969529252737\n",
      "12 Train Loss 6.185693 Test MSE 5.198619218567662 Test RE 1.0898132010640278\n",
      "13 Train Loss 5.7523265 Test MSE 4.920162016389901 Test RE 1.0602243203719188\n",
      "14 Train Loss 5.258683 Test MSE 4.549023523873436 Test RE 1.0194528670866374\n",
      "15 Train Loss 4.6374574 Test MSE 3.9845106414447677 Test RE 0.9541036467408532\n",
      "16 Train Loss 3.9786656 Test MSE 3.6766846074704174 Test RE 0.9165079758579334\n",
      "17 Train Loss 3.4207826 Test MSE 3.4363370412069365 Test RE 0.8860453220757653\n",
      "18 Train Loss 3.0599613 Test MSE 3.142522161720184 Test RE 0.8473195654855721\n",
      "19 Train Loss 2.678981 Test MSE 2.8286629658852287 Test RE 0.8038937691667745\n",
      "20 Train Loss 2.2680497 Test MSE 2.4143171228040794 Test RE 0.7426859661404174\n",
      "21 Train Loss 1.9551873 Test MSE 2.070337627237416 Test RE 0.6877469101558792\n",
      "22 Train Loss 1.7747116 Test MSE 1.8801760798568141 Test RE 0.6554013352875572\n",
      "23 Train Loss 1.5662638 Test MSE 1.5460560071345317 Test RE 0.5943204464066684\n",
      "24 Train Loss 1.3173441 Test MSE 1.243107500495152 Test RE 0.5329204717974526\n",
      "25 Train Loss 0.930685 Test MSE 0.8149127023501184 Test RE 0.43148291489947377\n",
      "26 Train Loss 0.70437914 Test MSE 0.6159752453969746 Test RE 0.3751368176506213\n",
      "27 Train Loss 0.53075105 Test MSE 0.4918966375612469 Test RE 0.33523162882921886\n",
      "28 Train Loss 0.41686085 Test MSE 0.3487025403893621 Test RE 0.2822510823214355\n",
      "29 Train Loss 0.30955574 Test MSE 0.26614952827082655 Test RE 0.2465874165761397\n",
      "30 Train Loss 0.20356897 Test MSE 0.14039156820622295 Test RE 0.1790929841150367\n",
      "31 Train Loss 0.15659581 Test MSE 0.04975519788353632 Test RE 0.10661720402008476\n",
      "32 Train Loss 0.1213101 Test MSE 0.025126941006303728 Test RE 0.07576661246741981\n",
      "33 Train Loss 0.096329354 Test MSE 0.019247549074208573 Test RE 0.0663125575384979\n",
      "34 Train Loss 0.077286355 Test MSE 0.018637522112552825 Test RE 0.06525324987198208\n",
      "35 Train Loss 0.06488187 Test MSE 0.01926941484829956 Test RE 0.06635021334150841\n",
      "36 Train Loss 0.053115398 Test MSE 0.01328255662468914 Test RE 0.055086971669799166\n",
      "37 Train Loss 0.04593072 Test MSE 0.010798208223635903 Test RE 0.04966882763353543\n",
      "38 Train Loss 0.04009453 Test MSE 0.01167812310389102 Test RE 0.05165288515946361\n",
      "39 Train Loss 0.03294898 Test MSE 0.008563817013514436 Test RE 0.04423252684608524\n",
      "40 Train Loss 0.029152378 Test MSE 0.007848353267058626 Test RE 0.04234453146487805\n",
      "41 Train Loss 0.023783617 Test MSE 0.007568991284222614 Test RE 0.041584076667090596\n",
      "42 Train Loss 0.021058684 Test MSE 0.00647794043203599 Test RE 0.03847038524180932\n",
      "43 Train Loss 0.019987972 Test MSE 0.005759924683240395 Test RE 0.03627575520928302\n",
      "44 Train Loss 0.018073283 Test MSE 0.004821341271290362 Test RE 0.03318883415956948\n",
      "45 Train Loss 0.016520225 Test MSE 0.004367005792585975 Test RE 0.031586386431272116\n",
      "46 Train Loss 0.0149550345 Test MSE 0.0034850724976363714 Test RE 0.028217203398671887\n",
      "47 Train Loss 0.013758587 Test MSE 0.003040576295049177 Test RE 0.026356395321917768\n",
      "48 Train Loss 0.01191719 Test MSE 0.002413292283950768 Test RE 0.023480807192487328\n",
      "49 Train Loss 0.0109568015 Test MSE 0.0021306722224777104 Test RE 0.022063092322818223\n",
      "50 Train Loss 0.010084534 Test MSE 0.0018351804834214995 Test RE 0.020476109873297732\n",
      "51 Train Loss 0.009352428 Test MSE 0.00170649076037811 Test RE 0.019745131520079617\n",
      "52 Train Loss 0.008557916 Test MSE 0.001800428519836705 Test RE 0.020281309947917176\n",
      "53 Train Loss 0.007998006 Test MSE 0.001562879403542791 Test RE 0.018896039765015676\n",
      "54 Train Loss 0.007032275 Test MSE 0.0012850191702141057 Test RE 0.0171341617964495\n",
      "55 Train Loss 0.0064261127 Test MSE 0.0011787423055279115 Test RE 0.016410336846608822\n",
      "56 Train Loss 0.006074764 Test MSE 0.0010795025827360803 Test RE 0.015704347736468043\n",
      "57 Train Loss 0.0055765184 Test MSE 0.0009338729916281347 Test RE 0.014606695237688727\n",
      "58 Train Loss 0.005172976 Test MSE 0.0009236056386972375 Test RE 0.01452617754915105\n",
      "59 Train Loss 0.004733746 Test MSE 0.0008426658758603495 Test RE 0.01387508856585405\n",
      "60 Train Loss 0.0043238816 Test MSE 0.0007545754757962206 Test RE 0.013129839080345415\n",
      "61 Train Loss 0.003906689 Test MSE 0.0008402933049530663 Test RE 0.0138555417698845\n",
      "62 Train Loss 0.0036433241 Test MSE 0.0008999795505773166 Test RE 0.014339182130487111\n",
      "63 Train Loss 0.0034227432 Test MSE 0.000946724739599113 Test RE 0.01470685881898088\n",
      "64 Train Loss 0.0032603254 Test MSE 0.0009657263385001421 Test RE 0.014853715395906398\n",
      "65 Train Loss 0.0031180007 Test MSE 0.0009869367955814235 Test RE 0.01501594713813088\n",
      "66 Train Loss 0.0029503203 Test MSE 0.0010556571251442537 Test RE 0.015529930134220453\n",
      "67 Train Loss 0.002742773 Test MSE 0.0009080121412356441 Test RE 0.014403030756307892\n",
      "68 Train Loss 0.002563645 Test MSE 0.000812369469068646 Test RE 0.013623379566644065\n",
      "69 Train Loss 0.0024118877 Test MSE 0.0006707225440865771 Test RE 0.012378827534164564\n",
      "70 Train Loss 0.0022831606 Test MSE 0.0006091715008060377 Test RE 0.011797170303881983\n",
      "71 Train Loss 0.0021729437 Test MSE 0.0006225807464865456 Test RE 0.011926304767389095\n",
      "72 Train Loss 0.0020576913 Test MSE 0.0006124716834915049 Test RE 0.011829082688079678\n",
      "73 Train Loss 0.0019933446 Test MSE 0.0006135465227192706 Test RE 0.011839457689209668\n",
      "74 Train Loss 0.0019232559 Test MSE 0.0006338088936844756 Test RE 0.01203336873225819\n",
      "75 Train Loss 0.0018383955 Test MSE 0.0005964117735016566 Test RE 0.011672964488659345\n",
      "76 Train Loss 0.0017784638 Test MSE 0.000539342801020974 Test RE 0.011100447915786666\n",
      "77 Train Loss 0.0016960228 Test MSE 0.0005208114339631298 Test RE 0.010908080024834638\n",
      "78 Train Loss 0.0016138967 Test MSE 0.0005386601649728823 Test RE 0.011093420877419624\n",
      "79 Train Loss 0.0015609817 Test MSE 0.000554819970923175 Test RE 0.011258592567243587\n",
      "80 Train Loss 0.0014993838 Test MSE 0.000522311730157583 Test RE 0.010923780123712914\n",
      "81 Train Loss 0.0014375213 Test MSE 0.0004459796561639988 Test RE 0.010094053086977089\n",
      "82 Train Loss 0.0013926302 Test MSE 0.0004390691210802842 Test RE 0.010015543183189935\n",
      "83 Train Loss 0.0013233982 Test MSE 0.00046053658040451546 Test RE 0.010257466947715886\n",
      "84 Train Loss 0.0012737612 Test MSE 0.0004224939666826325 Test RE 0.00982467778692033\n",
      "85 Train Loss 0.0012315843 Test MSE 0.0004003344986585619 Test RE 0.009563559599584024\n",
      "86 Train Loss 0.0012057228 Test MSE 0.00038868323708836274 Test RE 0.009423363971509127\n",
      "87 Train Loss 0.0011596371 Test MSE 0.0003595009476116013 Test RE 0.009062709935441785\n",
      "88 Train Loss 0.0011249565 Test MSE 0.00038781160212100296 Test RE 0.009412791939033677\n",
      "89 Train Loss 0.0010826454 Test MSE 0.0004231961692321767 Test RE 0.009832838908904917\n",
      "90 Train Loss 0.0010524428 Test MSE 0.0004062566247826588 Test RE 0.00963403652056124\n",
      "91 Train Loss 0.0010192414 Test MSE 0.0003921301730662516 Test RE 0.009465056065261695\n",
      "92 Train Loss 0.0009813851 Test MSE 0.00038406960363266513 Test RE 0.009367269794563158\n",
      "93 Train Loss 0.0009128365 Test MSE 0.0002986217796501432 Test RE 0.008259786084994102\n",
      "94 Train Loss 0.0008781435 Test MSE 0.00026947643392339786 Test RE 0.007846364080834337\n",
      "95 Train Loss 0.0008473501 Test MSE 0.00028923002618878873 Test RE 0.008128861961380348\n",
      "96 Train Loss 0.00081958965 Test MSE 0.000278332897819624 Test RE 0.007974258883602706\n",
      "97 Train Loss 0.0007907646 Test MSE 0.0002638785533382463 Test RE 0.007764439450127139\n",
      "98 Train Loss 0.0007427417 Test MSE 0.0002529724892418349 Test RE 0.007602294814463869\n",
      "99 Train Loss 0.0007189427 Test MSE 0.0002411632241196387 Test RE 0.007422728931119649\n",
      "Training time: 67.69\n",
      "1\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.864555 Test MSE 9.083941054390877 Test RE 1.4406059825789985\n",
      "1 Train Loss 42.88158 Test MSE 9.630062868886801 Test RE 1.4832782259588366\n",
      "2 Train Loss 36.843174 Test MSE 9.97540405753712 Test RE 1.5096397001070172\n",
      "3 Train Loss 33.307064 Test MSE 9.795262563858794 Test RE 1.4959466350203285\n",
      "4 Train Loss 29.337297 Test MSE 9.40187851058588 Test RE 1.465599734959951\n",
      "5 Train Loss 25.870361 Test MSE 8.898427644478238 Test RE 1.4258199826556515\n",
      "6 Train Loss 23.180561 Test MSE 8.919271879634344 Test RE 1.427488970929646\n",
      "7 Train Loss 20.761011 Test MSE 8.744501730900822 Test RE 1.413434196235647\n",
      "8 Train Loss 18.616499 Test MSE 8.53480894938536 Test RE 1.3963843160434584\n",
      "9 Train Loss 16.47991 Test MSE 8.569251439260894 Test RE 1.399199055567173\n",
      "10 Train Loss 14.920584 Test MSE 8.23684006897855 Test RE 1.3717923513879038\n",
      "11 Train Loss 13.996494 Test MSE 8.067122841684471 Test RE 1.3575861396359308\n",
      "12 Train Loss 13.465142 Test MSE 8.042389413188857 Test RE 1.3555033936019112\n",
      "13 Train Loss 12.986576 Test MSE 8.140192195073695 Test RE 1.3637205650871955\n",
      "14 Train Loss 12.539167 Test MSE 8.224344903095188 Test RE 1.370751462020422\n",
      "15 Train Loss 11.6869335 Test MSE 7.972761301153107 Test RE 1.3496229079722402\n",
      "16 Train Loss 10.054135 Test MSE 7.204871102038348 Test RE 1.2829837863731575\n",
      "17 Train Loss 9.276163 Test MSE 6.9741158078586505 Test RE 1.26227109590299\n",
      "18 Train Loss 8.731582 Test MSE 6.638260830597144 Test RE 1.231502269812312\n",
      "19 Train Loss 8.2292385 Test MSE 6.406986340280256 Test RE 1.2098595566571082\n",
      "20 Train Loss 7.896269 Test MSE 6.265978642441706 Test RE 1.1964719332151619\n",
      "21 Train Loss 7.675729 Test MSE 6.257847267822718 Test RE 1.195695349026251\n",
      "22 Train Loss 7.511205 Test MSE 6.1135890446717545 Test RE 1.1818331873138004\n",
      "23 Train Loss 7.373353 Test MSE 6.073474883490585 Test RE 1.177949521777217\n",
      "24 Train Loss 7.236827 Test MSE 6.1243632534901895 Test RE 1.182874123521002\n",
      "25 Train Loss 7.1014795 Test MSE 6.1037105045674425 Test RE 1.1808779786472432\n",
      "26 Train Loss 6.9375706 Test MSE 6.221788803404252 Test RE 1.1922455024342151\n",
      "27 Train Loss 6.7993097 Test MSE 6.247951679333203 Test RE 1.1947495932509384\n",
      "28 Train Loss 6.6316333 Test MSE 6.267317042699011 Test RE 1.196599708374643\n",
      "29 Train Loss 6.4252205 Test MSE 6.365055308982321 Test RE 1.2058940468472044\n",
      "30 Train Loss 6.221072 Test MSE 6.259953590146434 Test RE 1.1958965610251546\n",
      "31 Train Loss 5.8008575 Test MSE 6.263513907426341 Test RE 1.1962365927766263\n",
      "32 Train Loss 4.8074427 Test MSE 5.430510579802879 Test RE 1.1138543168619326\n",
      "33 Train Loss 3.651982 Test MSE 5.176492336210973 Test RE 1.0874914420053814\n",
      "34 Train Loss 2.9128463 Test MSE 5.069653735684413 Test RE 1.0762104605788934\n",
      "35 Train Loss 2.5168796 Test MSE 5.144062674184027 Test RE 1.0840796347019352\n",
      "36 Train Loss 2.1857393 Test MSE 5.344947315175026 Test RE 1.10504451857228\n",
      "37 Train Loss 2.0421917 Test MSE 5.3426612533119435 Test RE 1.104808176644384\n",
      "38 Train Loss 1.8814259 Test MSE 5.4210451608463766 Test RE 1.1128831654579716\n",
      "39 Train Loss 1.7845087 Test MSE 5.45271424695727 Test RE 1.1161290957884693\n",
      "40 Train Loss 1.6941345 Test MSE 5.469823231681957 Test RE 1.117878763842483\n",
      "41 Train Loss 1.6297207 Test MSE 5.540626097193255 Test RE 1.1250905629537968\n",
      "42 Train Loss 1.5811251 Test MSE 5.5558877466609715 Test RE 1.1266390278340985\n",
      "43 Train Loss 1.5516927 Test MSE 5.592383135922395 Test RE 1.1303332914959738\n",
      "44 Train Loss 1.5043478 Test MSE 5.634683643617243 Test RE 1.134600130535363\n",
      "45 Train Loss 1.4696356 Test MSE 5.617929622666943 Test RE 1.1329120796253487\n",
      "46 Train Loss 1.4362283 Test MSE 5.623157740608618 Test RE 1.1334391083533462\n",
      "47 Train Loss 1.4080243 Test MSE 5.655444599865148 Test RE 1.1366884222321132\n",
      "48 Train Loss 1.376354 Test MSE 5.6463121321518726 Test RE 1.1357702835904622\n",
      "49 Train Loss 1.3429353 Test MSE 5.670288082829638 Test RE 1.1381791413481566\n",
      "50 Train Loss 1.3258547 Test MSE 5.693109360305666 Test RE 1.1404672631251813\n",
      "51 Train Loss 1.2982742 Test MSE 5.661368120177906 Test RE 1.1372835509326362\n",
      "52 Train Loss 1.2723373 Test MSE 5.66413764348229 Test RE 1.1375616946706393\n",
      "53 Train Loss 1.2526015 Test MSE 5.69186827833849 Test RE 1.140342947007899\n",
      "54 Train Loss 1.2296002 Test MSE 5.6899936890911915 Test RE 1.1401551483309675\n",
      "55 Train Loss 1.2084651 Test MSE 5.704596030996429 Test RE 1.1416172121110373\n",
      "56 Train Loss 1.187608 Test MSE 5.689016138261627 Test RE 1.1400572038035286\n",
      "57 Train Loss 1.1690472 Test MSE 5.707866819742474 Test RE 1.1419444441913247\n",
      "58 Train Loss 1.1508954 Test MSE 5.724422383791557 Test RE 1.1435993396223343\n",
      "59 Train Loss 1.1357377 Test MSE 5.707339253896384 Test RE 1.1418916692381453\n",
      "60 Train Loss 1.1133049 Test MSE 5.7586047801075955 Test RE 1.1470086603003977\n",
      "61 Train Loss 1.0939898 Test MSE 5.772821380752838 Test RE 1.1484236308398708\n",
      "62 Train Loss 1.0802292 Test MSE 5.77718341324678 Test RE 1.1488574321750493\n",
      "63 Train Loss 1.0630271 Test MSE 5.833251932496444 Test RE 1.1544188965928572\n",
      "64 Train Loss 1.0500919 Test MSE 5.835634780700218 Test RE 1.1546546590939055\n",
      "65 Train Loss 1.0408535 Test MSE 5.846234698759011 Test RE 1.1557028477139966\n",
      "66 Train Loss 1.0331395 Test MSE 5.853488740673527 Test RE 1.1564196268344862\n",
      "67 Train Loss 1.0245266 Test MSE 5.8605513599266175 Test RE 1.157117064700711\n",
      "68 Train Loss 1.0112377 Test MSE 5.903668897337261 Test RE 1.1613658635131723\n",
      "69 Train Loss 1.0002626 Test MSE 5.921012931034153 Test RE 1.1630705658479068\n",
      "70 Train Loss 0.9887316 Test MSE 5.902091483361731 Test RE 1.161210699227793\n",
      "71 Train Loss 0.98257387 Test MSE 5.877161533905172 Test RE 1.1587556747400016\n",
      "72 Train Loss 0.97557944 Test MSE 5.880635393969599 Test RE 1.1590980815626533\n",
      "73 Train Loss 0.96700627 Test MSE 5.893354108786978 Test RE 1.1603508607599715\n",
      "74 Train Loss 0.9604729 Test MSE 5.887932745616263 Test RE 1.1598170280147286\n",
      "75 Train Loss 0.9545551 Test MSE 5.897465870787496 Test RE 1.160755575510536\n",
      "76 Train Loss 0.94746816 Test MSE 5.912801546414453 Test RE 1.1622638007432036\n",
      "77 Train Loss 0.9396318 Test MSE 5.936036769215346 Test RE 1.1645452048857565\n",
      "78 Train Loss 0.93159854 Test MSE 5.956858047318664 Test RE 1.166585799916968\n",
      "79 Train Loss 0.92274374 Test MSE 5.967375969156511 Test RE 1.1676152559390804\n",
      "80 Train Loss 0.9152031 Test MSE 5.969212631582887 Test RE 1.167794928721029\n",
      "81 Train Loss 0.9074934 Test MSE 5.986318510771699 Test RE 1.1694669974952356\n",
      "82 Train Loss 0.90205675 Test MSE 6.003592121356564 Test RE 1.1711530392540788\n",
      "83 Train Loss 0.8961609 Test MSE 6.014968747158712 Test RE 1.1722621638875914\n",
      "84 Train Loss 0.8899592 Test MSE 6.031368596131353 Test RE 1.1738591660391058\n",
      "85 Train Loss 0.8849225 Test MSE 6.012763565260971 Test RE 1.172047259339836\n",
      "86 Train Loss 0.8789253 Test MSE 6.0250557259868875 Test RE 1.1732446819090108\n",
      "87 Train Loss 0.8731562 Test MSE 6.037642044826495 Test RE 1.1744694944580765\n",
      "88 Train Loss 0.8677105 Test MSE 6.019874060456224 Test RE 1.1727400667271284\n",
      "89 Train Loss 0.86248887 Test MSE 6.028209186064955 Test RE 1.173551674611913\n",
      "90 Train Loss 0.8585109 Test MSE 6.038031263334317 Test RE 1.174507350122074\n",
      "91 Train Loss 0.8538614 Test MSE 6.044904883813797 Test RE 1.1751756823271813\n",
      "92 Train Loss 0.84994346 Test MSE 6.049142028932565 Test RE 1.175587476866382\n",
      "93 Train Loss 0.8470876 Test MSE 6.049811573871256 Test RE 1.1756525345937774\n",
      "94 Train Loss 0.8426074 Test MSE 6.062793071815678 Test RE 1.176913198046658\n",
      "95 Train Loss 0.8394037 Test MSE 6.0794983440183366 Test RE 1.1785335016429614\n",
      "96 Train Loss 0.8360928 Test MSE 6.082221080463982 Test RE 1.1787973784254306\n",
      "97 Train Loss 0.83184844 Test MSE 6.085155963690912 Test RE 1.1790817494932126\n",
      "98 Train Loss 0.82757306 Test MSE 6.100823007668976 Test RE 1.1805986252226301\n",
      "99 Train Loss 0.8237753 Test MSE 6.1193955746439945 Test RE 1.1823942915298828\n",
      "Training time: 67.83\n",
      "2\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.97677 Test MSE 8.353614171525145 Test RE 1.3814821143184095\n",
      "1 Train Loss 36.38866 Test MSE 6.448955440915668 Test RE 1.213815693953369\n",
      "2 Train Loss 26.762737 Test MSE 5.383994961438148 Test RE 1.1090736384354514\n",
      "3 Train Loss 19.38538 Test MSE 5.433617876515745 Test RE 1.1141729407599845\n",
      "4 Train Loss 14.894925 Test MSE 5.742550080538736 Test RE 1.1454086431947643\n",
      "5 Train Loss 12.768795 Test MSE 5.665640442944822 Test RE 1.13771259263903\n",
      "6 Train Loss 11.435043 Test MSE 5.780329915552339 Test RE 1.1491702481469044\n",
      "7 Train Loss 10.357909 Test MSE 5.814925607437617 Test RE 1.1526040513742988\n",
      "8 Train Loss 9.140757 Test MSE 5.872683032089735 Test RE 1.1583140943647874\n",
      "9 Train Loss 8.531326 Test MSE 5.754775682832358 Test RE 1.1466272538446496\n",
      "10 Train Loss 7.983855 Test MSE 5.72883822222221 Test RE 1.1440403427544479\n",
      "11 Train Loss 7.4845324 Test MSE 5.735285758325514 Test RE 1.1446839433320843\n",
      "12 Train Loss 7.0677805 Test MSE 5.663819637148947 Test RE 1.1375297606919894\n",
      "13 Train Loss 6.7029195 Test MSE 5.593149650400707 Test RE 1.1304107528506042\n",
      "14 Train Loss 6.2919884 Test MSE 5.42530626150425 Test RE 1.1133204589645727\n",
      "15 Train Loss 5.953055 Test MSE 5.114526692957085 Test RE 1.0809628909846762\n",
      "16 Train Loss 5.712507 Test MSE 4.778252646784578 Test RE 1.0448227365883709\n",
      "17 Train Loss 5.4483633 Test MSE 4.454298460332327 Test RE 1.008782912126661\n",
      "18 Train Loss 5.2168474 Test MSE 4.2776367538557025 Test RE 0.9885758835620972\n",
      "19 Train Loss 4.9154425 Test MSE 4.164085111327781 Test RE 0.975366553662906\n",
      "20 Train Loss 4.6518364 Test MSE 3.9285759223973913 Test RE 0.9473831050795928\n",
      "21 Train Loss 4.0955296 Test MSE 3.5565552993186587 Test RE 0.9014109785136112\n",
      "22 Train Loss 3.5169995 Test MSE 3.3831211279174034 Test RE 0.8791578008008653\n",
      "23 Train Loss 3.1377978 Test MSE 3.1241481919656082 Test RE 0.8448388434678917\n",
      "24 Train Loss 2.8589272 Test MSE 3.1646850514544185 Test RE 0.8503022105059349\n",
      "25 Train Loss 2.5652251 Test MSE 3.1148457876908227 Test RE 0.8435801177388058\n",
      "26 Train Loss 2.3127253 Test MSE 2.9546847267892296 Test RE 0.8216060600584892\n",
      "27 Train Loss 2.0997243 Test MSE 2.791496965926431 Test RE 0.7985950985710681\n",
      "28 Train Loss 1.891875 Test MSE 2.6139726399820216 Test RE 0.7727848138264705\n",
      "29 Train Loss 1.729768 Test MSE 2.422234955997634 Test RE 0.743902800941303\n",
      "30 Train Loss 1.6017755 Test MSE 2.17242889998947 Test RE 0.7044997544688444\n",
      "31 Train Loss 1.5011367 Test MSE 2.0497124029907905 Test RE 0.6843125814721007\n",
      "32 Train Loss 1.42568 Test MSE 1.8425044925277299 Test RE 0.6488022361094937\n",
      "33 Train Loss 1.3567497 Test MSE 1.7176387121959782 Test RE 0.6264320511433155\n",
      "34 Train Loss 1.2110112 Test MSE 1.2328167879545378 Test RE 0.5307100723314311\n",
      "35 Train Loss 0.9385517 Test MSE 0.6935978803103926 Test RE 0.3980722823953892\n",
      "36 Train Loss 0.66859937 Test MSE 0.5134118483690648 Test RE 0.342484565126646\n",
      "37 Train Loss 0.4505012 Test MSE 0.46912039173903264 Test RE 0.3273785463035296\n",
      "38 Train Loss 0.35486463 Test MSE 0.4147577018391119 Test RE 0.30782599361293894\n",
      "39 Train Loss 0.2799276 Test MSE 0.3206059004654351 Test RE 0.27064114099650716\n",
      "40 Train Loss 0.2394532 Test MSE 0.25619975223663755 Test RE 0.24193428249828502\n",
      "41 Train Loss 0.20390812 Test MSE 0.210455045747404 Test RE 0.219274299149982\n",
      "42 Train Loss 0.16401948 Test MSE 0.16733875513719348 Test RE 0.19552681556128518\n",
      "43 Train Loss 0.1340781 Test MSE 0.10593952123391032 Test RE 0.15557401616941743\n",
      "44 Train Loss 0.10543952 Test MSE 0.07821631857846782 Test RE 0.13367701703059923\n",
      "45 Train Loss 0.080149576 Test MSE 0.060062621149895905 Test RE 0.11714134353224351\n",
      "46 Train Loss 0.06835977 Test MSE 0.05872216688986973 Test RE 0.11582681032471144\n",
      "47 Train Loss 0.05694394 Test MSE 0.0564658515299934 Test RE 0.11357977426832018\n",
      "48 Train Loss 0.043858837 Test MSE 0.041035452447152586 Test RE 0.09682503739467477\n",
      "49 Train Loss 0.035808533 Test MSE 0.03423495114135859 Test RE 0.08843881534321625\n",
      "50 Train Loss 0.03103239 Test MSE 0.032638484373644985 Test RE 0.08635212948269852\n",
      "51 Train Loss 0.027340278 Test MSE 0.03077229173874362 Test RE 0.08384708735244714\n",
      "52 Train Loss 0.023793641 Test MSE 0.026403422152007285 Test RE 0.07766729325436693\n",
      "53 Train Loss 0.020957995 Test MSE 0.022859553302431276 Test RE 0.0722673167848317\n",
      "54 Train Loss 0.018343253 Test MSE 0.02025560990700799 Test RE 0.06802690658402684\n",
      "55 Train Loss 0.016252223 Test MSE 0.019203753156798918 Test RE 0.06623707070038085\n",
      "56 Train Loss 0.013874196 Test MSE 0.017224374932426567 Test RE 0.06273065113905539\n",
      "57 Train Loss 0.012840153 Test MSE 0.014784360485235952 Test RE 0.058117822196735586\n",
      "58 Train Loss 0.011183531 Test MSE 0.011676621746411623 Test RE 0.05164956476553536\n",
      "59 Train Loss 0.010434034 Test MSE 0.010218740981049704 Test RE 0.04831775594011925\n",
      "60 Train Loss 0.009398971 Test MSE 0.008280708706085613 Test RE 0.043495248262601115\n",
      "61 Train Loss 0.00838359 Test MSE 0.00703270470835273 Test RE 0.04008383368746504\n",
      "62 Train Loss 0.0075227898 Test MSE 0.006075072571538664 Test RE 0.03725493374931463\n",
      "63 Train Loss 0.0071991673 Test MSE 0.005885146947310629 Test RE 0.03666795721437475\n",
      "64 Train Loss 0.0068045924 Test MSE 0.005855690074651831 Test RE 0.03657607519918853\n",
      "65 Train Loss 0.0063059106 Test MSE 0.00583763383033211 Test RE 0.036519639796980675\n",
      "66 Train Loss 0.005960394 Test MSE 0.0054921668992843455 Test RE 0.035422558276669305\n",
      "67 Train Loss 0.005660161 Test MSE 0.005926447262709503 Test RE 0.03679639500766899\n",
      "68 Train Loss 0.005397918 Test MSE 0.006935149312899984 Test RE 0.039804847847809514\n",
      "69 Train Loss 0.005166065 Test MSE 0.006502008945223495 Test RE 0.038541786524325675\n",
      "70 Train Loss 0.004929018 Test MSE 0.006197432193763349 Test RE 0.03762824405714332\n",
      "71 Train Loss 0.0044378024 Test MSE 0.006167204330312446 Test RE 0.037536366347272004\n",
      "72 Train Loss 0.0041890163 Test MSE 0.005697099967907123 Test RE 0.03607737913096691\n",
      "73 Train Loss 0.003914578 Test MSE 0.005604395099753525 Test RE 0.035782644406283814\n",
      "74 Train Loss 0.0036951895 Test MSE 0.0056643362958613075 Test RE 0.03597349015491869\n",
      "75 Train Loss 0.003367947 Test MSE 0.005576114676351315 Test RE 0.03569224855183984\n",
      "76 Train Loss 0.0031224918 Test MSE 0.00566395867981159 Test RE 0.03597229103882249\n",
      "77 Train Loss 0.0029700114 Test MSE 0.005470757321198451 Test RE 0.03535344870961973\n",
      "78 Train Loss 0.0028836268 Test MSE 0.005354718652089522 Test RE 0.03497650323049395\n",
      "79 Train Loss 0.0027760547 Test MSE 0.005272141775701026 Test RE 0.03470576330624411\n",
      "80 Train Loss 0.0026742932 Test MSE 0.0054522528565288594 Test RE 0.03529360774651147\n",
      "81 Train Loss 0.0025785575 Test MSE 0.005680682164574907 Test RE 0.03602535804456012\n",
      "82 Train Loss 0.002461832 Test MSE 0.00561810807844089 Test RE 0.03582639460963856\n",
      "83 Train Loss 0.0023719408 Test MSE 0.005194489189787948 Test RE 0.03444922718894434\n",
      "84 Train Loss 0.002302392 Test MSE 0.004886600619121889 Test RE 0.03341269321192544\n",
      "85 Train Loss 0.0022131552 Test MSE 0.004666023444442236 Test RE 0.03264987467293577\n",
      "86 Train Loss 0.002149221 Test MSE 0.004642761867440653 Test RE 0.03256838810090066\n",
      "87 Train Loss 0.0020851835 Test MSE 0.004638178867141576 Test RE 0.03255230954789998\n",
      "88 Train Loss 0.002015161 Test MSE 0.00449807566739459 Test RE 0.03205689382182212\n",
      "89 Train Loss 0.0019505376 Test MSE 0.004294433274857895 Test RE 0.03132282974613326\n",
      "90 Train Loss 0.0018639138 Test MSE 0.004461715632202953 Test RE 0.031927065541523324\n",
      "91 Train Loss 0.0017776744 Test MSE 0.004353579428611992 Test RE 0.03153779286286388\n",
      "92 Train Loss 0.0016865452 Test MSE 0.0040313649794963885 Test RE 0.030348282610441594\n",
      "93 Train Loss 0.0016419773 Test MSE 0.004081372416415311 Test RE 0.030535931505614428\n",
      "94 Train Loss 0.0015964222 Test MSE 0.004133477538430401 Test RE 0.03073023286811655\n",
      "95 Train Loss 0.0015311943 Test MSE 0.00407575139404371 Test RE 0.030514896633551225\n",
      "96 Train Loss 0.0014791345 Test MSE 0.004044307561152885 Test RE 0.030396959718135663\n",
      "97 Train Loss 0.0014237484 Test MSE 0.0037820510557530465 Test RE 0.029394884219514916\n",
      "98 Train Loss 0.0013459519 Test MSE 0.0033963794681833967 Test RE 0.02785583387033463\n",
      "99 Train Loss 0.0012878475 Test MSE 0.0032198889173493867 Test RE 0.02712242424871303\n",
      "Training time: 67.71\n",
      "3\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.321125 Test MSE 7.128317449984709 Test RE 1.276149563809419\n",
      "1 Train Loss 44.442345 Test MSE 8.477159826631805 Test RE 1.3916603246205983\n",
      "2 Train Loss 35.313652 Test MSE 8.484851393358703 Test RE 1.3922915278505927\n",
      "3 Train Loss 30.410795 Test MSE 8.829696264314205 Test RE 1.4203027975634657\n",
      "4 Train Loss 26.70192 Test MSE 9.100425809769781 Test RE 1.4419125340454102\n",
      "5 Train Loss 24.913864 Test MSE 9.044935098210864 Test RE 1.4375097127475105\n",
      "6 Train Loss 22.984917 Test MSE 9.039645963699654 Test RE 1.4370893507444955\n",
      "7 Train Loss 21.193638 Test MSE 9.053214744431083 Test RE 1.4381675035008996\n",
      "8 Train Loss 19.451218 Test MSE 8.851493956743935 Test RE 1.4220548532965716\n",
      "9 Train Loss 17.242743 Test MSE 9.015567287647043 Test RE 1.4351741052394311\n",
      "10 Train Loss 14.407814 Test MSE 8.430016486928697 Test RE 1.3877852658903984\n",
      "11 Train Loss 12.800969 Test MSE 8.003988026733516 Test RE 1.3522633431245297\n",
      "12 Train Loss 10.667563 Test MSE 7.973915745975586 Test RE 1.3497206162016864\n",
      "13 Train Loss 8.165416 Test MSE 7.696409647617764 Test RE 1.326026330903445\n",
      "14 Train Loss 7.46871 Test MSE 7.550265458453864 Test RE 1.3133762870959773\n",
      "15 Train Loss 6.831721 Test MSE 7.7145650369017496 Test RE 1.3275894196977818\n",
      "16 Train Loss 6.3722286 Test MSE 7.721786005421787 Test RE 1.3282105978932988\n",
      "17 Train Loss 5.783059 Test MSE 7.53207027672867 Test RE 1.3117927974173906\n",
      "18 Train Loss 4.6741405 Test MSE 6.975460677131758 Test RE 1.2623927964759545\n",
      "19 Train Loss 3.750361 Test MSE 6.799307978862488 Test RE 1.2463511447276643\n",
      "20 Train Loss 3.2257028 Test MSE 6.7703287643029615 Test RE 1.243692282652503\n",
      "21 Train Loss 2.8971176 Test MSE 6.626636546026734 Test RE 1.2304235531423313\n",
      "22 Train Loss 2.6906178 Test MSE 6.614155540137245 Test RE 1.229264280156499\n",
      "23 Train Loss 2.501234 Test MSE 6.375274845248504 Test RE 1.2068617317049815\n",
      "24 Train Loss 2.312054 Test MSE 5.9546316679481395 Test RE 1.1663677734619367\n",
      "25 Train Loss 2.1331918 Test MSE 5.890125829657204 Test RE 1.1600330069938078\n",
      "26 Train Loss 1.9926361 Test MSE 5.724075093534169 Test RE 1.1435646490538962\n",
      "27 Train Loss 1.9407387 Test MSE 5.641974771498769 Test RE 1.1353339641271636\n",
      "28 Train Loss 1.8968217 Test MSE 5.6460516374607 Test RE 1.1357440836979618\n",
      "29 Train Loss 1.8558252 Test MSE 5.630484916190974 Test RE 1.134177323792532\n",
      "30 Train Loss 1.7945071 Test MSE 5.61072958861434 Test RE 1.1321858671845295\n",
      "31 Train Loss 1.7491765 Test MSE 5.567912801952293 Test RE 1.1278576066141304\n",
      "32 Train Loss 1.7171221 Test MSE 5.530987120347901 Test RE 1.1241114820324238\n",
      "33 Train Loss 1.6734017 Test MSE 5.489645832295685 Test RE 1.1199025243347547\n",
      "34 Train Loss 1.6220188 Test MSE 5.4593321415341896 Test RE 1.116806206719902\n",
      "35 Train Loss 1.5773022 Test MSE 5.523309679240868 Test RE 1.1233310339428078\n",
      "36 Train Loss 1.5254236 Test MSE 5.521427167298635 Test RE 1.1231395849360368\n",
      "37 Train Loss 1.4631573 Test MSE 5.428617880043957 Test RE 1.1136601937228252\n",
      "38 Train Loss 1.4167246 Test MSE 5.511134313872123 Test RE 1.1220922376302294\n",
      "39 Train Loss 1.3570678 Test MSE 5.516725179636257 Test RE 1.1226612563174934\n",
      "40 Train Loss 1.3077902 Test MSE 5.542322291270369 Test RE 1.125262766047984\n",
      "41 Train Loss 1.2705729 Test MSE 5.598015235941269 Test RE 1.1309023286992292\n",
      "42 Train Loss 1.2466819 Test MSE 5.570345366696054 Test RE 1.128103954496321\n",
      "43 Train Loss 1.2141495 Test MSE 5.586440235662927 Test RE 1.1297325419210689\n",
      "44 Train Loss 1.1863409 Test MSE 5.600288382496644 Test RE 1.1311319141603609\n",
      "45 Train Loss 1.1631662 Test MSE 5.607611856161241 Test RE 1.1318712607627819\n",
      "46 Train Loss 1.1433517 Test MSE 5.598294763816237 Test RE 1.1309305632399806\n",
      "47 Train Loss 1.1175253 Test MSE 5.621362746358517 Test RE 1.1332581887380708\n",
      "48 Train Loss 1.1025892 Test MSE 5.66229826311536 Test RE 1.1373769729460261\n",
      "49 Train Loss 1.0870996 Test MSE 5.712715137179685 Test RE 1.1424293305896782\n",
      "50 Train Loss 1.0737756 Test MSE 5.722023409395046 Test RE 1.1433596863575315\n",
      "51 Train Loss 1.0579762 Test MSE 5.722363357324906 Test RE 1.1433936496042603\n",
      "52 Train Loss 1.040299 Test MSE 5.733839833128515 Test RE 1.1445396408720268\n",
      "53 Train Loss 1.026048 Test MSE 5.771151297444048 Test RE 1.1482574987401544\n",
      "54 Train Loss 1.0154618 Test MSE 5.783978392539341 Test RE 1.1495328623813221\n",
      "55 Train Loss 1.0020125 Test MSE 5.810181882316592 Test RE 1.152133817297334\n",
      "56 Train Loss 0.9907269 Test MSE 5.846357448732479 Test RE 1.1557149804589648\n",
      "57 Train Loss 0.9744155 Test MSE 5.872271936218946 Test RE 1.1582735518672411\n",
      "58 Train Loss 0.96526146 Test MSE 5.890084267936073 Test RE 1.1600289142923288\n",
      "59 Train Loss 0.9521862 Test MSE 5.899765275954729 Test RE 1.1609818411061248\n",
      "60 Train Loss 0.9417443 Test MSE 5.913804356928158 Test RE 1.1623623564731453\n",
      "61 Train Loss 0.9324706 Test MSE 5.946293242801403 Test RE 1.1655508398480536\n",
      "62 Train Loss 0.9225485 Test MSE 5.960253149431888 Test RE 1.1669181994553057\n",
      "63 Train Loss 0.9135032 Test MSE 5.959697616539158 Test RE 1.166863816148684\n",
      "64 Train Loss 0.90438354 Test MSE 5.972104546196932 Test RE 1.1680777762666796\n",
      "65 Train Loss 0.8953806 Test MSE 5.980088003286779 Test RE 1.168858253594159\n",
      "66 Train Loss 0.8826792 Test MSE 5.999968267385388 Test RE 1.1707995235465083\n",
      "67 Train Loss 0.87350345 Test MSE 6.004228627521933 Test RE 1.17121512095099\n",
      "68 Train Loss 0.8668109 Test MSE 6.010296269872233 Test RE 1.1718067639766017\n",
      "69 Train Loss 0.8580588 Test MSE 6.0209082804488245 Test RE 1.1728408013207703\n",
      "70 Train Loss 0.84987795 Test MSE 6.02415915698909 Test RE 1.1731573852937063\n",
      "71 Train Loss 0.842062 Test MSE 6.039746194548369 Test RE 1.1746741310005842\n",
      "72 Train Loss 0.8359145 Test MSE 6.049362670313588 Test RE 1.1756089163430854\n",
      "73 Train Loss 0.8307457 Test MSE 6.051761174040643 Test RE 1.1758419510511577\n",
      "74 Train Loss 0.8263066 Test MSE 6.062015797171757 Test RE 1.176837753107522\n",
      "75 Train Loss 0.82162833 Test MSE 6.059905937720102 Test RE 1.1766329385356593\n",
      "76 Train Loss 0.8171513 Test MSE 6.0755578833511965 Test RE 1.1781515032121543\n",
      "77 Train Loss 0.8101214 Test MSE 6.103682928768412 Test RE 1.180875311114881\n",
      "78 Train Loss 0.8043411 Test MSE 6.100356165333445 Test RE 1.1805534539430367\n",
      "79 Train Loss 0.79908884 Test MSE 6.10850892381587 Test RE 1.1813420598327158\n",
      "80 Train Loss 0.79540825 Test MSE 6.117517523335028 Test RE 1.1822128383518606\n",
      "81 Train Loss 0.790877 Test MSE 6.125062417822836 Test RE 1.1829416407273472\n",
      "82 Train Loss 0.7865324 Test MSE 6.128140712753528 Test RE 1.1832388610329676\n",
      "83 Train Loss 0.7837881 Test MSE 6.114364599601892 Test RE 1.1819081471681103\n",
      "84 Train Loss 0.7800002 Test MSE 6.114108179752655 Test RE 1.1818833638990178\n",
      "85 Train Loss 0.7772277 Test MSE 6.1275083382672175 Test RE 1.1831778091245397\n",
      "86 Train Loss 0.7744958 Test MSE 6.132251491439919 Test RE 1.1836356549293205\n",
      "87 Train Loss 0.77114874 Test MSE 6.139927713134052 Test RE 1.1843762481775755\n",
      "88 Train Loss 0.7670575 Test MSE 6.15796534032107 Test RE 1.1861146782644079\n",
      "89 Train Loss 0.762617 Test MSE 6.17114794153918 Test RE 1.1873835809531308\n",
      "90 Train Loss 0.75851524 Test MSE 6.167052794044347 Test RE 1.1869895442280214\n",
      "91 Train Loss 0.7545221 Test MSE 6.177663591305895 Test RE 1.1880102499769634\n",
      "92 Train Loss 0.75193256 Test MSE 6.19288009785549 Test RE 1.1894724733045616\n",
      "93 Train Loss 0.7483092 Test MSE 6.19093684700038 Test RE 1.1892858376262871\n",
      "94 Train Loss 0.7445139 Test MSE 6.206311768007298 Test RE 1.1907616915823271\n",
      "95 Train Loss 0.74201465 Test MSE 6.217246562705913 Test RE 1.1918102212818737\n",
      "96 Train Loss 0.7385163 Test MSE 6.216499815155513 Test RE 1.1917386455385268\n",
      "97 Train Loss 0.7344959 Test MSE 6.225714437933167 Test RE 1.1926215664754876\n",
      "98 Train Loss 0.73178345 Test MSE 6.245897152082665 Test RE 1.1945531410736758\n",
      "99 Train Loss 0.7295642 Test MSE 6.2551735343604244 Test RE 1.195439884799763\n",
      "Training time: 69.05\n",
      "4\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.606377 Test MSE 8.313432768828465 Test RE 1.3781556019526628\n",
      "1 Train Loss 53.63345 Test MSE 7.764531840274212 Test RE 1.3318818414328908\n",
      "2 Train Loss 47.758507 Test MSE 8.073453472835304 Test RE 1.3581187143740145\n",
      "3 Train Loss 45.100906 Test MSE 8.224967075147784 Test RE 1.3708033097439776\n",
      "4 Train Loss 44.499657 Test MSE 8.10304043136893 Test RE 1.3606050019963374\n",
      "5 Train Loss 44.419037 Test MSE 8.06699881643469 Test RE 1.3575757037215082\n",
      "6 Train Loss 43.256763 Test MSE 7.966841079423008 Test RE 1.3491217296235898\n",
      "7 Train Loss 41.98011 Test MSE 8.107405923457728 Test RE 1.3609714638594501\n",
      "8 Train Loss 37.66384 Test MSE 7.526889418843381 Test RE 1.3113415681479434\n",
      "9 Train Loss 35.064262 Test MSE 6.8804874529407085 Test RE 1.2537693937177528\n",
      "10 Train Loss 33.370064 Test MSE 6.319637474052929 Test RE 1.2015840176785932\n",
      "11 Train Loss 28.126143 Test MSE 4.555579024302942 Test RE 1.0201871584917768\n",
      "12 Train Loss 24.475292 Test MSE 4.163522778778183 Test RE 0.975300692991873\n",
      "13 Train Loss 19.969559 Test MSE 4.165118511220291 Test RE 0.975487574383814\n",
      "14 Train Loss 14.087605 Test MSE 3.997141796090073 Test RE 0.9556147350462371\n",
      "15 Train Loss 10.969783 Test MSE 4.142465388066981 Test RE 0.9728312311905537\n",
      "16 Train Loss 8.813936 Test MSE 3.7772853708079186 Test RE 0.9289620202054766\n",
      "17 Train Loss 7.6137867 Test MSE 3.8142441278641646 Test RE 0.9334956605500032\n",
      "18 Train Loss 6.6838326 Test MSE 3.725721319655113 Test RE 0.9225995613013045\n",
      "19 Train Loss 5.84439 Test MSE 3.5745726307267596 Test RE 0.9036913455902951\n",
      "20 Train Loss 5.4883604 Test MSE 3.435264043333735 Test RE 0.8859069772390398\n",
      "21 Train Loss 4.999254 Test MSE 3.040407406423178 Test RE 0.8334392536599521\n",
      "22 Train Loss 4.6981564 Test MSE 2.8334505224822157 Test RE 0.8045737829842774\n",
      "23 Train Loss 4.508562 Test MSE 2.747667040951874 Test RE 0.7923008328013461\n",
      "24 Train Loss 4.3274813 Test MSE 2.767251257416202 Test RE 0.7951194130634628\n",
      "25 Train Loss 4.1403613 Test MSE 2.675818655941198 Test RE 0.7818733291293049\n",
      "26 Train Loss 3.8239918 Test MSE 2.3137227702525314 Test RE 0.7270490655774959\n",
      "27 Train Loss 2.7965844 Test MSE 1.7163044023825371 Test RE 0.6261886888986192\n",
      "28 Train Loss 1.970665 Test MSE 1.5539910929662923 Test RE 0.5958436603297216\n",
      "29 Train Loss 1.403028 Test MSE 1.2589542237652247 Test RE 0.5363064620566124\n",
      "30 Train Loss 1.0770448 Test MSE 1.075711576207311 Test RE 0.4957423046445029\n",
      "31 Train Loss 0.75366396 Test MSE 0.7832023275395681 Test RE 0.4230045560024146\n",
      "32 Train Loss 0.63809186 Test MSE 0.6660955492513378 Test RE 0.3901003376089435\n",
      "33 Train Loss 0.50997233 Test MSE 0.48783323352636504 Test RE 0.3338441357388862\n",
      "34 Train Loss 0.41764694 Test MSE 0.41492943484102074 Test RE 0.3078897156495549\n",
      "35 Train Loss 0.3036429 Test MSE 0.29073156459475247 Test RE 0.25772357856768524\n",
      "36 Train Loss 0.23137069 Test MSE 0.21185503495930263 Test RE 0.22000241858590683\n",
      "37 Train Loss 0.19102544 Test MSE 0.18666901327520485 Test RE 0.2065114690818586\n",
      "38 Train Loss 0.16126886 Test MSE 0.15017851776598962 Test RE 0.18523027311735804\n",
      "39 Train Loss 0.14707147 Test MSE 0.12985953827670974 Test RE 0.1722443509862926\n",
      "40 Train Loss 0.13154054 Test MSE 0.115859114046662 Test RE 0.1626946087601051\n",
      "41 Train Loss 0.11483168 Test MSE 0.11221934198559691 Test RE 0.16011864977460938\n",
      "42 Train Loss 0.10493079 Test MSE 0.09949451404512903 Test RE 0.15076746332757415\n",
      "43 Train Loss 0.093552716 Test MSE 0.08115948544529629 Test RE 0.1361688290094242\n",
      "44 Train Loss 0.079221636 Test MSE 0.0714632932594987 Test RE 0.1277760837853993\n",
      "45 Train Loss 0.07066192 Test MSE 0.06150530957222959 Test RE 0.1185398476281041\n",
      "46 Train Loss 0.06254177 Test MSE 0.049215261298224226 Test RE 0.10603712836224946\n",
      "47 Train Loss 0.05402966 Test MSE 0.041672365119452964 Test RE 0.0975735565022666\n",
      "48 Train Loss 0.04876424 Test MSE 0.037717192446089315 Test RE 0.0928277318680332\n",
      "49 Train Loss 0.045589954 Test MSE 0.03192109991989995 Test RE 0.08539785927755991\n",
      "50 Train Loss 0.03970857 Test MSE 0.026273476675313587 Test RE 0.0774759362076606\n",
      "51 Train Loss 0.033974845 Test MSE 0.02149878131942341 Test RE 0.07008337071067584\n",
      "52 Train Loss 0.030804025 Test MSE 0.01662575888541796 Test RE 0.06163094106983741\n",
      "53 Train Loss 0.02872943 Test MSE 0.014865564775459156 Test RE 0.05827721203974094\n",
      "54 Train Loss 0.025784265 Test MSE 0.014763924112947706 Test RE 0.05807764027001056\n",
      "55 Train Loss 0.024035713 Test MSE 0.013280269214548243 Test RE 0.055082228158192144\n",
      "56 Train Loss 0.022278981 Test MSE 0.011202437061508284 Test RE 0.0505899577349781\n",
      "57 Train Loss 0.020627247 Test MSE 0.010105052775107776 Test RE 0.04804822552215357\n",
      "58 Train Loss 0.019448834 Test MSE 0.010032287033932994 Test RE 0.0478749170956368\n",
      "59 Train Loss 0.018428396 Test MSE 0.00882855412713487 Test RE 0.04491101313189067\n",
      "60 Train Loss 0.017096743 Test MSE 0.007265339217811814 Test RE 0.04074140560942199\n",
      "61 Train Loss 0.01591845 Test MSE 0.006631876262118057 Test RE 0.038924789043240246\n",
      "62 Train Loss 0.014894731 Test MSE 0.005764218901862911 Test RE 0.03628927509095468\n",
      "63 Train Loss 0.013421933 Test MSE 0.005211998472549842 Test RE 0.03450723807322214\n",
      "64 Train Loss 0.012608533 Test MSE 0.00493359604716436 Test RE 0.03357297708297652\n",
      "65 Train Loss 0.011837156 Test MSE 0.004598240497931996 Test RE 0.03241185604227351\n",
      "66 Train Loss 0.011156519 Test MSE 0.004727181541185497 Test RE 0.032863150888263394\n",
      "67 Train Loss 0.010234648 Test MSE 0.00439425289843195 Test RE 0.031684771844590134\n",
      "68 Train Loss 0.009705067 Test MSE 0.0041090720163818465 Test RE 0.03063937744465932\n",
      "69 Train Loss 0.0091451965 Test MSE 0.004147810193606725 Test RE 0.030783464642195446\n",
      "70 Train Loss 0.008603896 Test MSE 0.0038125384487414705 Test RE 0.029513123580472235\n",
      "71 Train Loss 0.00800524 Test MSE 0.003180998644690717 Test RE 0.026958132423212572\n",
      "72 Train Loss 0.0076188864 Test MSE 0.0030583449368042676 Test RE 0.0264332944193277\n",
      "73 Train Loss 0.0072990954 Test MSE 0.0028986639952016365 Test RE 0.025733982324871868\n",
      "74 Train Loss 0.0069263466 Test MSE 0.002760795641552039 Test RE 0.025114537838279296\n",
      "75 Train Loss 0.006539449 Test MSE 0.0026733617456203788 Test RE 0.024713651882798452\n",
      "76 Train Loss 0.0061623333 Test MSE 0.0022820048531390293 Test RE 0.02283317693987481\n",
      "77 Train Loss 0.005922741 Test MSE 0.0020386413618340786 Test RE 0.02158134343494243\n",
      "78 Train Loss 0.005468181 Test MSE 0.002020101690419564 Test RE 0.021482987527686345\n",
      "79 Train Loss 0.005305958 Test MSE 0.001976867138068777 Test RE 0.021251852907529113\n",
      "80 Train Loss 0.005058424 Test MSE 0.001958740834513743 Test RE 0.021154197218889156\n",
      "81 Train Loss 0.0048409966 Test MSE 0.0019629205597237118 Test RE 0.02117675548981797\n",
      "82 Train Loss 0.0047042575 Test MSE 0.001844696505731356 Test RE 0.020529128958044335\n",
      "83 Train Loss 0.004375957 Test MSE 0.001590849713867458 Test RE 0.01906437786599003\n",
      "84 Train Loss 0.0041194293 Test MSE 0.001498270810692171 Test RE 0.018501341505884634\n",
      "85 Train Loss 0.0039086416 Test MSE 0.0014488880504141344 Test RE 0.018193886269431914\n",
      "86 Train Loss 0.0036543277 Test MSE 0.0014804686127132614 Test RE 0.01839109816361777\n",
      "87 Train Loss 0.0034828119 Test MSE 0.001474398824080931 Test RE 0.0183533585144639\n",
      "88 Train Loss 0.0033779815 Test MSE 0.0014675785619218307 Test RE 0.01831085990135082\n",
      "89 Train Loss 0.0032832874 Test MSE 0.0014571517050156317 Test RE 0.01824569642333095\n",
      "90 Train Loss 0.0031511378 Test MSE 0.001356454714851185 Test RE 0.0176039736570281\n",
      "91 Train Loss 0.0030700413 Test MSE 0.0013758291517620032 Test RE 0.01772924795350387\n",
      "92 Train Loss 0.0029651078 Test MSE 0.001375734839657293 Test RE 0.017728640279453905\n",
      "93 Train Loss 0.0029104084 Test MSE 0.0013234471598829553 Test RE 0.017388469720716584\n",
      "94 Train Loss 0.002806393 Test MSE 0.0013226234720390066 Test RE 0.01738305775535824\n",
      "95 Train Loss 0.0027214703 Test MSE 0.0013091957706268117 Test RE 0.017294593439744623\n",
      "96 Train Loss 0.0026434176 Test MSE 0.0012022991673480501 Test RE 0.016573503847415256\n",
      "97 Train Loss 0.0025682994 Test MSE 0.0012118705983120734 Test RE 0.016639343401932852\n",
      "98 Train Loss 0.0024882942 Test MSE 0.0012240541789885363 Test RE 0.016722776318881853\n",
      "99 Train Loss 0.002377119 Test MSE 0.0011539667350026924 Test RE 0.01623695941529478\n",
      "Training time: 68.14\n",
      "5\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.183968 Test MSE 8.648205190849003 Test RE 1.4056301143028653\n",
      "1 Train Loss 45.125557 Test MSE 8.426035616394287 Test RE 1.3874575532548745\n",
      "2 Train Loss 40.03105 Test MSE 8.59097293186217 Test RE 1.4009712906646434\n",
      "3 Train Loss 34.697235 Test MSE 8.992124101009512 Test RE 1.433306948485421\n",
      "4 Train Loss 31.83459 Test MSE 8.712083252886998 Test RE 1.4108117522063242\n",
      "5 Train Loss 29.356922 Test MSE 8.561953137299888 Test RE 1.398603090300313\n",
      "6 Train Loss 27.122168 Test MSE 8.326103918846032 Test RE 1.3792054791707782\n",
      "7 Train Loss 25.275778 Test MSE 8.695895593210608 Test RE 1.4095004493729104\n",
      "8 Train Loss 22.447432 Test MSE 8.767402266293056 Test RE 1.4152837719199844\n",
      "9 Train Loss 20.792156 Test MSE 8.863930758335982 Test RE 1.4230535325106177\n",
      "10 Train Loss 18.799866 Test MSE 8.311842872074461 Test RE 1.3780238134394782\n",
      "11 Train Loss 16.761538 Test MSE 8.197410050579455 Test RE 1.3685050054515384\n",
      "12 Train Loss 14.1326065 Test MSE 7.329119688555953 Test RE 1.2939990791911233\n",
      "13 Train Loss 11.835869 Test MSE 6.399571497922716 Test RE 1.209159265253508\n",
      "14 Train Loss 10.533415 Test MSE 6.554918947027825 Test RE 1.223747234135757\n",
      "15 Train Loss 9.763634 Test MSE 6.6335500434424635 Test RE 1.2310652295387967\n",
      "16 Train Loss 9.003278 Test MSE 6.472385237140178 Test RE 1.2160186608128403\n",
      "17 Train Loss 8.453312 Test MSE 6.393559290122369 Test RE 1.208591147138712\n",
      "18 Train Loss 7.899728 Test MSE 6.322392666460991 Test RE 1.201845918335293\n",
      "19 Train Loss 7.4535837 Test MSE 6.047250230969246 Test RE 1.175403636919211\n",
      "20 Train Loss 6.6307216 Test MSE 5.738576480201645 Test RE 1.1450122875929403\n",
      "21 Train Loss 4.824312 Test MSE 4.929164138550059 Test RE 1.061193791210894\n",
      "22 Train Loss 4.327865 Test MSE 4.982576105368416 Test RE 1.066927798667994\n",
      "23 Train Loss 3.9855332 Test MSE 5.140788424681603 Test RE 1.0837345657904398\n",
      "24 Train Loss 3.6668458 Test MSE 5.108128097347399 Test RE 1.0802865029757989\n",
      "25 Train Loss 3.3723068 Test MSE 5.195738824937956 Test RE 1.0895112433894358\n",
      "26 Train Loss 3.145614 Test MSE 5.440398938572556 Test RE 1.1148679583597656\n",
      "27 Train Loss 2.938126 Test MSE 5.614833873816066 Test RE 1.1325998921472347\n",
      "28 Train Loss 2.701886 Test MSE 5.717505000682123 Test RE 1.142908168924733\n",
      "29 Train Loss 2.5354967 Test MSE 5.7022861502504805 Test RE 1.1413860593179306\n",
      "30 Train Loss 2.3877902 Test MSE 5.805815301417585 Test RE 1.1517007989164798\n",
      "31 Train Loss 2.2898967 Test MSE 5.864754769451734 Test RE 1.157531954424678\n",
      "32 Train Loss 2.2230263 Test MSE 5.824582345401845 Test RE 1.1535607083356294\n",
      "33 Train Loss 2.1483493 Test MSE 5.868935970118095 Test RE 1.157944504586242\n",
      "34 Train Loss 2.0698647 Test MSE 5.932341966862969 Test RE 1.164182721103481\n",
      "35 Train Loss 1.9875605 Test MSE 5.89451696465171 Test RE 1.160465333284822\n",
      "36 Train Loss 1.9372061 Test MSE 5.869731920073858 Test RE 1.1580230226204085\n",
      "37 Train Loss 1.8872685 Test MSE 5.875148340647629 Test RE 1.158557194665517\n",
      "38 Train Loss 1.8528216 Test MSE 5.844096512287089 Test RE 1.1554914865296304\n",
      "39 Train Loss 1.8033856 Test MSE 5.825465081718414 Test RE 1.1536481181524871\n",
      "40 Train Loss 1.750108 Test MSE 5.807353171539871 Test RE 1.1518533226261969\n",
      "41 Train Loss 1.7094144 Test MSE 5.776706617271275 Test RE 1.1488100230949347\n",
      "42 Train Loss 1.6686467 Test MSE 5.776570953609446 Test RE 1.1487965333420487\n",
      "43 Train Loss 1.6263078 Test MSE 5.7698509235219255 Test RE 1.1481281269605164\n",
      "44 Train Loss 1.5975043 Test MSE 5.752341120831399 Test RE 1.14638468744432\n",
      "45 Train Loss 1.5671268 Test MSE 5.744713427826382 Test RE 1.1456243734295048\n",
      "46 Train Loss 1.5313796 Test MSE 5.745029426801478 Test RE 1.145655881628668\n",
      "47 Train Loss 1.48852 Test MSE 5.676234617805083 Test RE 1.138775799614346\n",
      "48 Train Loss 1.4513032 Test MSE 5.648176871706407 Test RE 1.1359578166994493\n",
      "49 Train Loss 1.4147848 Test MSE 5.695059127284686 Test RE 1.1406625391083511\n",
      "50 Train Loss 1.3838619 Test MSE 5.678883527497681 Test RE 1.1390414829953004\n",
      "51 Train Loss 1.3621976 Test MSE 5.683168492842837 Test RE 1.1394711302067262\n",
      "52 Train Loss 1.3409268 Test MSE 5.706215891252117 Test RE 1.1417792857337854\n",
      "53 Train Loss 1.3168821 Test MSE 5.669139136064659 Test RE 1.1380638232660907\n",
      "54 Train Loss 1.2886214 Test MSE 5.664847586773231 Test RE 1.1376329834562662\n",
      "55 Train Loss 1.2614148 Test MSE 5.702430982808843 Test RE 1.1414005542774106\n",
      "56 Train Loss 1.2397122 Test MSE 5.697388967502076 Test RE 1.140895836924332\n",
      "57 Train Loss 1.2215687 Test MSE 5.6790979144515825 Test RE 1.139062983113068\n",
      "58 Train Loss 1.1995547 Test MSE 5.676453695154687 Test RE 1.1387977752367096\n",
      "59 Train Loss 1.1834606 Test MSE 5.697313467544654 Test RE 1.1408882775078195\n",
      "60 Train Loss 1.1664323 Test MSE 5.74033160773624 Test RE 1.1451873736062521\n",
      "61 Train Loss 1.1479661 Test MSE 5.766381689446398 Test RE 1.1477829079776776\n",
      "62 Train Loss 1.1300479 Test MSE 5.7922707920511245 Test RE 1.1503566008999433\n",
      "63 Train Loss 1.1182165 Test MSE 5.825417795228663 Test RE 1.1536434359442982\n",
      "64 Train Loss 1.1001539 Test MSE 5.859322027730724 Test RE 1.1569956976331075\n",
      "65 Train Loss 1.086319 Test MSE 5.85412852486623 Test RE 1.1564828232302324\n",
      "66 Train Loss 1.0755451 Test MSE 5.863331036983343 Test RE 1.1573914442139317\n",
      "67 Train Loss 1.0628844 Test MSE 5.863654994146595 Test RE 1.1574234175127065\n",
      "68 Train Loss 1.0523005 Test MSE 5.8475524498438975 Test RE 1.1558330890532387\n",
      "69 Train Loss 1.0394702 Test MSE 5.876539370981267 Test RE 1.1586943395278178\n",
      "70 Train Loss 1.0268364 Test MSE 5.845917387228839 Test RE 1.1556714836964637\n",
      "71 Train Loss 1.0102224 Test MSE 5.855689848566931 Test RE 1.156637032661773\n",
      "72 Train Loss 0.9962201 Test MSE 5.885980138272342 Test RE 1.1596246977748426\n",
      "73 Train Loss 0.987645 Test MSE 5.886315117046059 Test RE 1.1596576951791377\n",
      "74 Train Loss 0.97907245 Test MSE 5.9040903853204805 Test RE 1.1614073201926975\n",
      "75 Train Loss 0.9695214 Test MSE 5.882045696507932 Test RE 1.1592370615249425\n",
      "76 Train Loss 0.9607308 Test MSE 5.884478622335927 Test RE 1.1594767779737123\n",
      "77 Train Loss 0.950986 Test MSE 5.897554330073785 Test RE 1.1607642808788234\n",
      "78 Train Loss 0.9411788 Test MSE 5.912615089201139 Test RE 1.1622454748974744\n",
      "79 Train Loss 0.9330699 Test MSE 5.958213810029662 Test RE 1.1667185480479274\n",
      "80 Train Loss 0.92873883 Test MSE 5.946296216499773 Test RE 1.1655511312898021\n",
      "81 Train Loss 0.9229858 Test MSE 5.951953953469693 Test RE 1.166105494345263\n",
      "82 Train Loss 0.91226214 Test MSE 5.979139644461776 Test RE 1.1687655675842787\n",
      "83 Train Loss 0.9024432 Test MSE 5.982466022352005 Test RE 1.169090632359903\n",
      "84 Train Loss 0.894873 Test MSE 5.970748277411094 Test RE 1.1679451331280581\n",
      "85 Train Loss 0.88641393 Test MSE 5.979228109894893 Test RE 1.168774213892598\n",
      "86 Train Loss 0.8794943 Test MSE 6.008838038276872 Test RE 1.1716646021572108\n",
      "87 Train Loss 0.8744208 Test MSE 6.026921299580868 Test RE 1.173426307191235\n",
      "88 Train Loss 0.8692804 Test MSE 6.045501575262086 Test RE 1.1752336815835762\n",
      "89 Train Loss 0.8640672 Test MSE 6.0426177971021415 Test RE 1.174953347732024\n",
      "90 Train Loss 0.8579378 Test MSE 6.036727610139064 Test RE 1.1743805511002994\n",
      "91 Train Loss 0.852194 Test MSE 6.044617119731409 Test RE 1.1751477102264534\n",
      "92 Train Loss 0.8467611 Test MSE 6.054369757752495 Test RE 1.1760953443700435\n",
      "93 Train Loss 0.8434112 Test MSE 6.051735753546193 Test RE 1.1758394814795465\n",
      "94 Train Loss 0.8393327 Test MSE 6.057604351660363 Test RE 1.17640947144018\n",
      "95 Train Loss 0.8351209 Test MSE 6.080993800067356 Test RE 1.1786784426055645\n",
      "96 Train Loss 0.8312961 Test MSE 6.067927182733792 Test RE 1.1774114110120797\n",
      "97 Train Loss 0.8278482 Test MSE 6.065543185851894 Test RE 1.1771800947154452\n",
      "98 Train Loss 0.82391566 Test MSE 6.095737993186494 Test RE 1.1801065102599118\n",
      "99 Train Loss 0.81947595 Test MSE 6.118581610483441 Test RE 1.1823156515260338\n",
      "Training time: 67.49\n",
      "6\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.839928 Test MSE 8.422418735816441 Test RE 1.3871597378203882\n",
      "1 Train Loss 51.093372 Test MSE 8.333564317033463 Test RE 1.3798232421901973\n",
      "2 Train Loss 47.280006 Test MSE 8.66309178744174 Test RE 1.406839385528069\n",
      "3 Train Loss 46.206047 Test MSE 8.601179589847717 Test RE 1.4018032680396648\n",
      "4 Train Loss 45.503063 Test MSE 8.627860877691841 Test RE 1.4039758163136615\n",
      "5 Train Loss 44.507664 Test MSE 9.035072791404346 Test RE 1.436725791781835\n",
      "6 Train Loss 43.756874 Test MSE 9.195498323105653 Test RE 1.4494248237549126\n",
      "7 Train Loss 42.70981 Test MSE 9.080693462466945 Test RE 1.440348444658343\n",
      "8 Train Loss 41.72473 Test MSE 9.009563533515724 Test RE 1.434696161525201\n",
      "9 Train Loss 40.187366 Test MSE 9.044152946076876 Test RE 1.4374475577632515\n",
      "10 Train Loss 36.962837 Test MSE 8.798181574187085 Test RE 1.4177658805495132\n",
      "11 Train Loss 33.115337 Test MSE 8.784855480323696 Test RE 1.4166917699163797\n",
      "12 Train Loss 31.579376 Test MSE 8.28056936290011 Test RE 1.3754289464182219\n",
      "13 Train Loss 31.012291 Test MSE 8.27857961230452 Test RE 1.3752636845340307\n",
      "14 Train Loss 30.25288 Test MSE 8.21800885320693 Test RE 1.370223345607598\n",
      "15 Train Loss 29.333893 Test MSE 8.676278399821841 Test RE 1.4079096957541046\n",
      "16 Train Loss 28.29106 Test MSE 8.840764989998087 Test RE 1.4211927499359533\n",
      "17 Train Loss 27.176601 Test MSE 9.009291327725588 Test RE 1.434674488136105\n",
      "18 Train Loss 24.870174 Test MSE 8.842333155861743 Test RE 1.4213187892061852\n",
      "19 Train Loss 23.430805 Test MSE 8.223760541609096 Test RE 1.3707027633945796\n",
      "20 Train Loss 21.861294 Test MSE 7.692663618705997 Test RE 1.3257035870671472\n",
      "21 Train Loss 18.94777 Test MSE 6.892728691760631 Test RE 1.2548842035610923\n",
      "22 Train Loss 17.220417 Test MSE 6.426738193906691 Test RE 1.2117230364723646\n",
      "23 Train Loss 16.485699 Test MSE 6.2326844206286225 Test RE 1.1932889779421436\n",
      "24 Train Loss 15.655743 Test MSE 5.9960397958013845 Test RE 1.1704161710376428\n",
      "25 Train Loss 15.276833 Test MSE 5.870052186587829 Test RE 1.158054614432673\n",
      "26 Train Loss 15.012352 Test MSE 5.823465901832582 Test RE 1.1534501470044558\n",
      "27 Train Loss 14.747381 Test MSE 5.881938450756284 Test RE 1.1592264934485363\n",
      "28 Train Loss 14.511055 Test MSE 5.796703149196871 Test RE 1.1507966542428274\n",
      "29 Train Loss 14.334171 Test MSE 5.721318455027715 Test RE 1.1432892531232082\n",
      "30 Train Loss 14.110783 Test MSE 5.753507044490116 Test RE 1.1465008600843132\n",
      "31 Train Loss 13.901737 Test MSE 5.65849108888671 Test RE 1.1369945380919364\n",
      "32 Train Loss 13.582954 Test MSE 5.663344046238509 Test RE 1.13748200050482\n",
      "33 Train Loss 13.03808 Test MSE 5.4806778321426375 Test RE 1.1189874023577813\n",
      "34 Train Loss 12.443898 Test MSE 5.062072590133664 Test RE 1.0754054785174836\n",
      "35 Train Loss 9.491588 Test MSE 4.1480052007338015 Test RE 0.9734815084611153\n",
      "36 Train Loss 8.390383 Test MSE 3.7806176265788616 Test RE 0.9293716869823054\n",
      "37 Train Loss 6.474688 Test MSE 2.5510734853804693 Test RE 0.7634305671168541\n",
      "38 Train Loss 4.964701 Test MSE 1.9337905021285289 Test RE 0.6646802456588088\n",
      "39 Train Loss 4.3581448 Test MSE 1.8726319041577353 Test RE 0.6540851200804744\n",
      "40 Train Loss 4.027611 Test MSE 1.7755725255037127 Test RE 0.6369088278266176\n",
      "41 Train Loss 3.7271454 Test MSE 1.8557745777436325 Test RE 0.6511344460027852\n",
      "42 Train Loss 3.486642 Test MSE 1.9323690582677397 Test RE 0.6644359122269836\n",
      "43 Train Loss 3.2971387 Test MSE 2.0506756536784483 Test RE 0.6844733569885207\n",
      "44 Train Loss 3.1529045 Test MSE 2.022103690100792 Test RE 0.6796882640050367\n",
      "45 Train Loss 3.0598812 Test MSE 2.062991124322905 Test RE 0.6865256057757914\n",
      "46 Train Loss 2.9496489 Test MSE 2.150659116714488 Test RE 0.7009609912411366\n",
      "47 Train Loss 2.8322756 Test MSE 2.150549980746834 Test RE 0.700943205757142\n",
      "48 Train Loss 2.7586408 Test MSE 2.147208892538025 Test RE 0.7003985024474361\n",
      "49 Train Loss 2.6581185 Test MSE 2.129280914991973 Test RE 0.6974684081616828\n",
      "50 Train Loss 2.5315697 Test MSE 2.0982358916593546 Test RE 0.6923651761987932\n",
      "51 Train Loss 2.4517066 Test MSE 2.1382936667038566 Test RE 0.6989429603627844\n",
      "52 Train Loss 2.3896208 Test MSE 2.197078022477778 Test RE 0.7084852289905058\n",
      "53 Train Loss 2.3341548 Test MSE 2.2419002639536267 Test RE 0.7156755893801409\n",
      "54 Train Loss 2.2578802 Test MSE 2.2704278939001203 Test RE 0.7202145936007341\n",
      "55 Train Loss 2.2190626 Test MSE 2.251938042141241 Test RE 0.717275966032376\n",
      "56 Train Loss 2.1610818 Test MSE 2.251250212685706 Test RE 0.7171664156791226\n",
      "57 Train Loss 2.1239119 Test MSE 2.26010332522693 Test RE 0.718575171830129\n",
      "58 Train Loss 2.0835443 Test MSE 2.237900363258983 Test RE 0.7150368657671983\n",
      "59 Train Loss 2.0472212 Test MSE 2.242492663739202 Test RE 0.7157701382030758\n",
      "60 Train Loss 2.009182 Test MSE 2.256292614019738 Test RE 0.7179691292559485\n",
      "61 Train Loss 1.9814188 Test MSE 2.2591197745060736 Test RE 0.7184188002102055\n",
      "62 Train Loss 1.958751 Test MSE 2.294372547443665 Test RE 0.7240024387439078\n",
      "63 Train Loss 1.9389089 Test MSE 2.309384193898613 Test RE 0.7263670828361087\n",
      "64 Train Loss 1.9095539 Test MSE 2.273869981268955 Test RE 0.7207603283242535\n",
      "65 Train Loss 1.8865339 Test MSE 2.2701651618428462 Test RE 0.7201729210735255\n",
      "66 Train Loss 1.8698415 Test MSE 2.276122855816083 Test RE 0.7211172925775621\n",
      "67 Train Loss 1.8516994 Test MSE 2.274632437239237 Test RE 0.7208811580023369\n",
      "68 Train Loss 1.8174287 Test MSE 2.261221014587665 Test RE 0.7187528284322199\n",
      "69 Train Loss 1.7942138 Test MSE 2.2520592836748796 Test RE 0.7172952743938992\n",
      "70 Train Loss 1.7708048 Test MSE 2.2292476490072852 Test RE 0.7136532023565736\n",
      "71 Train Loss 1.7576271 Test MSE 2.2489305255340866 Test RE 0.7167968364837091\n",
      "72 Train Loss 1.7448151 Test MSE 2.251262168413832 Test RE 0.7171683200066057\n",
      "73 Train Loss 1.7372023 Test MSE 2.238774124467059 Test RE 0.7151764409051684\n",
      "74 Train Loss 1.7226603 Test MSE 2.2549721800698843 Test RE 0.7177590125471839\n",
      "75 Train Loss 1.7095914 Test MSE 2.2708005169871583 Test RE 0.7202736920587046\n",
      "76 Train Loss 1.7021638 Test MSE 2.2687236472461887 Test RE 0.7199442362518825\n",
      "77 Train Loss 1.6876354 Test MSE 2.2826729554697445 Test RE 0.7221541427677376\n",
      "78 Train Loss 1.6721448 Test MSE 2.2974355288435557 Test RE 0.7244855482491345\n",
      "79 Train Loss 1.6629431 Test MSE 2.2931872270053737 Test RE 0.7238153972463646\n",
      "80 Train Loss 1.6480297 Test MSE 2.311828421049605 Test RE 0.7267513706975508\n",
      "81 Train Loss 1.6352396 Test MSE 2.3168057966480737 Test RE 0.7275332993164372\n",
      "82 Train Loss 1.6247288 Test MSE 2.312659150690677 Test RE 0.7268819339507143\n",
      "83 Train Loss 1.6131017 Test MSE 2.3217180393041583 Test RE 0.7283041726791997\n",
      "84 Train Loss 1.5977308 Test MSE 2.326651301901974 Test RE 0.7290775243767059\n",
      "85 Train Loss 1.5882746 Test MSE 2.3307208121828586 Test RE 0.7297148549971977\n",
      "86 Train Loss 1.5755908 Test MSE 2.3409796861439527 Test RE 0.7313190439533676\n",
      "87 Train Loss 1.5621719 Test MSE 2.3402692567051737 Test RE 0.7312080669114248\n",
      "88 Train Loss 1.5461937 Test MSE 2.329490351060194 Test RE 0.7295222098095235\n",
      "89 Train Loss 1.5313579 Test MSE 2.346435172215259 Test RE 0.732170691483207\n",
      "90 Train Loss 1.5135391 Test MSE 2.3436919947022554 Test RE 0.7317425821618847\n",
      "91 Train Loss 1.4934629 Test MSE 2.355657580180532 Test RE 0.7336081390277541\n",
      "92 Train Loss 1.4704877 Test MSE 2.348385814425981 Test RE 0.732474962910024\n",
      "93 Train Loss 1.4592896 Test MSE 2.328161563389976 Test RE 0.7293141131340053\n",
      "94 Train Loss 1.4424558 Test MSE 2.3121043119582887 Test RE 0.726794734234524\n",
      "95 Train Loss 1.4307455 Test MSE 2.321453702591813 Test RE 0.7282627113545759\n",
      "96 Train Loss 1.4141549 Test MSE 2.3239539437824233 Test RE 0.7286547808634818\n",
      "97 Train Loss 1.3976831 Test MSE 2.3449977103890878 Test RE 0.7319463876817454\n",
      "98 Train Loss 1.3815509 Test MSE 2.377222450211789 Test RE 0.7369583972870061\n",
      "99 Train Loss 1.3724356 Test MSE 2.38738041289225 Test RE 0.7385312446133833\n",
      "Training time: 67.65\n",
      "7\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 42.846565 Test MSE 7.969897253436443 Test RE 1.3493804742993947\n",
      "1 Train Loss 30.849148 Test MSE 6.450610668521509 Test RE 1.2139714565695339\n",
      "2 Train Loss 27.216007 Test MSE 6.44558101039181 Test RE 1.213498086496797\n",
      "3 Train Loss 24.054398 Test MSE 6.103503325977245 Test RE 1.180857937173231\n",
      "4 Train Loss 19.537537 Test MSE 5.420651239765582 Test RE 1.1128427308101771\n",
      "5 Train Loss 15.077695 Test MSE 5.102708568651364 Test RE 1.0797132795460178\n",
      "6 Train Loss 12.66256 Test MSE 4.7510599357627 Test RE 1.0418454871264005\n",
      "7 Train Loss 11.19821 Test MSE 4.556311537250433 Test RE 1.0202691755372946\n",
      "8 Train Loss 10.364114 Test MSE 4.499312553506566 Test RE 1.0138673603459918\n",
      "9 Train Loss 9.674251 Test MSE 4.350188748986519 Test RE 0.996924136223111\n",
      "10 Train Loss 9.1821165 Test MSE 4.2118738158884925 Test RE 0.9809474353805111\n",
      "11 Train Loss 8.783753 Test MSE 4.1889397451229256 Test RE 0.9782731118718986\n",
      "12 Train Loss 8.408731 Test MSE 4.032114685820608 Test RE 0.9597861937201967\n",
      "13 Train Loss 8.020139 Test MSE 3.969352118691023 Test RE 0.9522870392821073\n",
      "14 Train Loss 7.5908914 Test MSE 3.92605317479536 Test RE 0.9470788736844383\n",
      "15 Train Loss 7.332428 Test MSE 3.8564230335550143 Test RE 0.9386428889828655\n",
      "16 Train Loss 6.9030614 Test MSE 3.6336400016488324 Test RE 0.9111271944564818\n",
      "17 Train Loss 6.1014175 Test MSE 3.4906059777170535 Test RE 0.893014425312142\n",
      "18 Train Loss 5.782751 Test MSE 3.428154997441433 Test RE 0.8849898403100287\n",
      "19 Train Loss 5.553314 Test MSE 3.3918287555964026 Test RE 0.880288481450726\n",
      "20 Train Loss 5.3244643 Test MSE 3.3323990545746502 Test RE 0.872542443164329\n",
      "21 Train Loss 5.1301737 Test MSE 3.2288317605972705 Test RE 0.8588765959541844\n",
      "22 Train Loss 4.9084024 Test MSE 3.112786756001803 Test RE 0.8433012523539912\n",
      "23 Train Loss 4.503482 Test MSE 2.8258488493818334 Test RE 0.8034937897976527\n",
      "24 Train Loss 2.887683 Test MSE 1.955745586734539 Test RE 0.6684427846090165\n",
      "25 Train Loss 2.0633953 Test MSE 1.808426951050651 Test RE 0.6427743615187259\n",
      "26 Train Loss 1.6159234 Test MSE 1.5809148089365939 Test RE 0.6009831478089158\n",
      "27 Train Loss 1.4268069 Test MSE 1.4630324702604842 Test RE 0.5781426951896675\n",
      "28 Train Loss 1.2508065 Test MSE 1.3407789548042943 Test RE 0.553460527343543\n",
      "29 Train Loss 1.0641526 Test MSE 1.061156766446079 Test RE 0.49237708642261613\n",
      "30 Train Loss 0.771675 Test MSE 0.6621110842595962 Test RE 0.3889318321546356\n",
      "31 Train Loss 0.58228385 Test MSE 0.46214055674130416 Test RE 0.32493395888433557\n",
      "32 Train Loss 0.45324138 Test MSE 0.30101113929006246 Test RE 0.26224024624289083\n",
      "33 Train Loss 0.3373079 Test MSE 0.19294409259873324 Test RE 0.20995383092336334\n",
      "34 Train Loss 0.2795831 Test MSE 0.1417059388783014 Test RE 0.1799293811350798\n",
      "35 Train Loss 0.22784519 Test MSE 0.13557674768168954 Test RE 0.17599513628667404\n",
      "36 Train Loss 0.1816916 Test MSE 0.09326483778222391 Test RE 0.14597115011699843\n",
      "37 Train Loss 0.14827654 Test MSE 0.07043095605804027 Test RE 0.1268498190786774\n",
      "38 Train Loss 0.12162195 Test MSE 0.05848517487921435 Test RE 0.11559284603162781\n",
      "39 Train Loss 0.10285927 Test MSE 0.04236576786759032 Test RE 0.09838198966277138\n",
      "40 Train Loss 0.083741195 Test MSE 0.029847531564686215 Test RE 0.08257760262043519\n",
      "41 Train Loss 0.07385092 Test MSE 0.022799617159542148 Test RE 0.07217251468899973\n",
      "42 Train Loss 0.06296024 Test MSE 0.01955129860288457 Test RE 0.06683375535650896\n",
      "43 Train Loss 0.0533493 Test MSE 0.017420466932631853 Test RE 0.06308672114059263\n",
      "44 Train Loss 0.04513611 Test MSE 0.01310469936211566 Test RE 0.054716913482252404\n",
      "45 Train Loss 0.03915801 Test MSE 0.01053843862499908 Test RE 0.04906775583989159\n",
      "46 Train Loss 0.03474278 Test MSE 0.008789750291413647 Test RE 0.044812206538021926\n",
      "47 Train Loss 0.028849684 Test MSE 0.008014297857901292 Test RE 0.04278985353382856\n",
      "48 Train Loss 0.024181535 Test MSE 0.007882662438367867 Test RE 0.042436985350177134\n",
      "49 Train Loss 0.021415275 Test MSE 0.006460386124653221 Test RE 0.038418225214875854\n",
      "50 Train Loss 0.019509843 Test MSE 0.006064596520849386 Test RE 0.03722279808592666\n",
      "51 Train Loss 0.01762782 Test MSE 0.005101293515016537 Test RE 0.034138797261281544\n",
      "52 Train Loss 0.01591991 Test MSE 0.004224342794382376 Test RE 0.031066164436922228\n",
      "53 Train Loss 0.0140529405 Test MSE 0.0037813646582040513 Test RE 0.029392216686512394\n",
      "54 Train Loss 0.012748702 Test MSE 0.0032773546131600042 Test RE 0.027363382280026976\n",
      "55 Train Loss 0.012196653 Test MSE 0.003081016899945882 Test RE 0.026531090469466726\n",
      "56 Train Loss 0.011403171 Test MSE 0.0027218115598944895 Test RE 0.024936591297794464\n",
      "57 Train Loss 0.010570803 Test MSE 0.00243308934406457 Test RE 0.02357692101843652\n",
      "58 Train Loss 0.00976015 Test MSE 0.0020019953963749245 Test RE 0.02138649416156107\n",
      "59 Train Loss 0.009085597 Test MSE 0.0019436525331919872 Test RE 0.02107256366568198\n",
      "60 Train Loss 0.008376607 Test MSE 0.0020869672454944463 Test RE 0.02183563754622767\n",
      "61 Train Loss 0.007879604 Test MSE 0.002029256424675911 Test RE 0.021531611002156836\n",
      "62 Train Loss 0.007465194 Test MSE 0.0018622078240886535 Test RE 0.020626338171402112\n",
      "63 Train Loss 0.0069154184 Test MSE 0.0017340344357925053 Test RE 0.019903842167151856\n",
      "64 Train Loss 0.0061888685 Test MSE 0.001566893658142448 Test RE 0.018920291434529765\n",
      "65 Train Loss 0.00548588 Test MSE 0.001382454694402822 Test RE 0.017771885808769476\n",
      "66 Train Loss 0.0050766347 Test MSE 0.0013036519934814476 Test RE 0.017257937697560663\n",
      "67 Train Loss 0.0047154706 Test MSE 0.0013188708009932721 Test RE 0.017358379819466467\n",
      "68 Train Loss 0.0043571955 Test MSE 0.0013229262925707605 Test RE 0.017385047605696508\n",
      "69 Train Loss 0.004034582 Test MSE 0.0014378657624302211 Test RE 0.018124549958091436\n",
      "70 Train Loss 0.0038373522 Test MSE 0.0014663672610110239 Test RE 0.018303301689330257\n",
      "71 Train Loss 0.0036492078 Test MSE 0.0015163285681693897 Test RE 0.018612500350397472\n",
      "72 Train Loss 0.003489825 Test MSE 0.0016428310339452327 Test RE 0.019373340405112602\n",
      "73 Train Loss 0.0033346 Test MSE 0.0015500003173637648 Test RE 0.018818021215680044\n",
      "74 Train Loss 0.0032010626 Test MSE 0.0015032236861293945 Test RE 0.018531896474386043\n",
      "75 Train Loss 0.0030610953 Test MSE 0.0015605099632950454 Test RE 0.01888171043809453\n",
      "76 Train Loss 0.0029524618 Test MSE 0.0016175889955226132 Test RE 0.019223928926515203\n",
      "77 Train Loss 0.0027186302 Test MSE 0.0015866393497715322 Test RE 0.019039133133144943\n",
      "78 Train Loss 0.0024846497 Test MSE 0.001450316773803657 Test RE 0.01820285439707425\n",
      "79 Train Loss 0.002361585 Test MSE 0.0014662196598899144 Test RE 0.01830238048223961\n",
      "80 Train Loss 0.0022022256 Test MSE 0.0014588017486936158 Test RE 0.018256023995219483\n",
      "81 Train Loss 0.0020472782 Test MSE 0.0012625125196339686 Test RE 0.016983449609893817\n",
      "82 Train Loss 0.0018942046 Test MSE 0.0011565728130054618 Test RE 0.016255283565317784\n",
      "83 Train Loss 0.0017688357 Test MSE 0.001159250661015271 Test RE 0.016274090860144197\n",
      "84 Train Loss 0.0016767702 Test MSE 0.0012097094994497706 Test RE 0.016624500516985812\n",
      "85 Train Loss 0.0016077828 Test MSE 0.0013124472778860753 Test RE 0.01731605647278019\n",
      "86 Train Loss 0.0015395368 Test MSE 0.0012950064612055803 Test RE 0.017200617088266645\n",
      "87 Train Loss 0.0014863663 Test MSE 0.0012465406980971627 Test RE 0.01687568038117249\n",
      "88 Train Loss 0.0014155816 Test MSE 0.001249897222683341 Test RE 0.016898385438764627\n",
      "89 Train Loss 0.0013355557 Test MSE 0.0011932510623967375 Test RE 0.01651102272457665\n",
      "90 Train Loss 0.0012958942 Test MSE 0.0012088849877474384 Test RE 0.01661883410218178\n",
      "91 Train Loss 0.0012360646 Test MSE 0.0011951424435230904 Test RE 0.016524103069811877\n",
      "92 Train Loss 0.0011604105 Test MSE 0.00113558992052671 Test RE 0.016107154513367115\n",
      "93 Train Loss 0.0010949757 Test MSE 0.0012205126780989173 Test RE 0.016698567167176836\n",
      "94 Train Loss 0.0010664774 Test MSE 0.0012296279217095779 Test RE 0.01676080673815285\n",
      "95 Train Loss 0.0010473345 Test MSE 0.0012005112541280426 Test RE 0.01656117621220317\n",
      "96 Train Loss 0.0010202691 Test MSE 0.001250065994085537 Test RE 0.016899526279741853\n",
      "97 Train Loss 0.0009958737 Test MSE 0.0012845148131052128 Test RE 0.017130798973301643\n",
      "98 Train Loss 0.0009578925 Test MSE 0.0012523688150120906 Test RE 0.016915084928965606\n",
      "99 Train Loss 0.00091812643 Test MSE 0.0012555718759290617 Test RE 0.01693670214279111\n",
      "Training time: 67.44\n",
      "8\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.15606 Test MSE 9.797803607606866 Test RE 1.4961406583721615\n",
      "1 Train Loss 36.122467 Test MSE 8.187761643296174 Test RE 1.3676993984893024\n",
      "2 Train Loss 29.382828 Test MSE 7.140233444549262 Test RE 1.277215751004689\n",
      "3 Train Loss 25.48671 Test MSE 6.989608598787646 Test RE 1.2636723669705268\n",
      "4 Train Loss 20.764538 Test MSE 7.162087560089912 Test RE 1.2791688450836618\n",
      "5 Train Loss 17.456532 Test MSE 7.279052074781323 Test RE 1.2895716394378343\n",
      "6 Train Loss 15.117213 Test MSE 7.171663921277835 Test RE 1.2800237418400509\n",
      "7 Train Loss 13.207596 Test MSE 7.110872558362433 Test RE 1.2745870683031733\n",
      "8 Train Loss 11.985301 Test MSE 6.7741982820287685 Test RE 1.2440476421973545\n",
      "9 Train Loss 10.193719 Test MSE 6.627822966361784 Test RE 1.23053369455268\n",
      "10 Train Loss 9.129824 Test MSE 6.376721295818801 Test RE 1.2069986330055213\n",
      "11 Train Loss 8.507193 Test MSE 5.9422352676500205 Test RE 1.1651530640091743\n",
      "12 Train Loss 7.9680967 Test MSE 5.972003358931462 Test RE 1.1680678806682538\n",
      "13 Train Loss 7.514267 Test MSE 5.965484847611617 Test RE 1.1674302267614103\n",
      "14 Train Loss 7.0311537 Test MSE 5.812639090105837 Test RE 1.152377418357497\n",
      "15 Train Loss 6.6050954 Test MSE 5.559223147783564 Test RE 1.1269771582494204\n",
      "16 Train Loss 6.088084 Test MSE 5.209685867472158 Test RE 1.090972563564188\n",
      "17 Train Loss 5.504793 Test MSE 4.953708438023899 Test RE 1.063832566695408\n",
      "18 Train Loss 4.4837756 Test MSE 4.456291765869582 Test RE 1.0090086028468064\n",
      "19 Train Loss 3.4549696 Test MSE 3.8949900156108206 Test RE 0.943324761911348\n",
      "20 Train Loss 2.6064453 Test MSE 3.6442627548230635 Test RE 0.9124580384363117\n",
      "21 Train Loss 2.2488382 Test MSE 3.653191627175502 Test RE 0.9135751693337685\n",
      "22 Train Loss 1.9272947 Test MSE 3.663907735993585 Test RE 0.9149141084138068\n",
      "23 Train Loss 1.7218813 Test MSE 3.4542617332834706 Test RE 0.8883532202962512\n",
      "24 Train Loss 1.593007 Test MSE 3.309375227545165 Test RE 0.8695229839160088\n",
      "25 Train Loss 1.4813421 Test MSE 3.2181114143115574 Test RE 0.8574495922334594\n",
      "26 Train Loss 1.3839478 Test MSE 3.1536280993433077 Test RE 0.848815494271072\n",
      "27 Train Loss 1.3128767 Test MSE 3.1000758553832752 Test RE 0.8415777029448595\n",
      "28 Train Loss 1.2453547 Test MSE 2.9689916442898032 Test RE 0.8235928126589768\n",
      "29 Train Loss 1.1775763 Test MSE 2.8376999120096187 Test RE 0.8051768756574234\n",
      "30 Train Loss 1.1101992 Test MSE 2.770193200817206 Test RE 0.7955419578030779\n",
      "31 Train Loss 1.0523212 Test MSE 2.727794646788544 Test RE 0.7894304911176167\n",
      "32 Train Loss 0.9972145 Test MSE 2.687521267913982 Test RE 0.7835812135016078\n",
      "33 Train Loss 0.9593079 Test MSE 2.6915122237077305 Test RE 0.7841628047803842\n",
      "34 Train Loss 0.92857707 Test MSE 2.7243166230320623 Test RE 0.7889270562707428\n",
      "35 Train Loss 0.89404374 Test MSE 2.7218718030485562 Test RE 0.7885729826038411\n",
      "36 Train Loss 0.86091095 Test MSE 2.6961638140409487 Test RE 0.784840124664537\n",
      "37 Train Loss 0.83300924 Test MSE 2.714130875351764 Test RE 0.787450844389449\n",
      "38 Train Loss 0.8105172 Test MSE 2.7581425118118856 Test RE 0.793809718073704\n",
      "39 Train Loss 0.79146653 Test MSE 2.7601789503099825 Test RE 0.7941027135198369\n",
      "40 Train Loss 0.7771616 Test MSE 2.7450909207246625 Test RE 0.7919293283935682\n",
      "41 Train Loss 0.76031744 Test MSE 2.7481399024646205 Test RE 0.7923690056271115\n",
      "42 Train Loss 0.74822295 Test MSE 2.7323750407235092 Test RE 0.7900930017641524\n",
      "43 Train Loss 0.7347015 Test MSE 2.7353516651739866 Test RE 0.7905232446756625\n",
      "44 Train Loss 0.7201016 Test MSE 2.741739089123288 Test RE 0.7914456969586213\n",
      "45 Train Loss 0.71231866 Test MSE 2.7342506231025157 Test RE 0.7903641267515346\n",
      "46 Train Loss 0.70231944 Test MSE 2.7628720435816128 Test RE 0.7944900201608104\n",
      "47 Train Loss 0.69559175 Test MSE 2.7801072602186245 Test RE 0.7969642423956095\n",
      "48 Train Loss 0.68372583 Test MSE 2.780858565553557 Test RE 0.7970719222409416\n",
      "49 Train Loss 0.6750609 Test MSE 2.78788780501338 Test RE 0.798078674860087\n",
      "50 Train Loss 0.66705656 Test MSE 2.798292282611089 Test RE 0.7995665142901717\n",
      "51 Train Loss 0.6593056 Test MSE 2.7975077186118162 Test RE 0.7994544182303026\n",
      "52 Train Loss 0.64983237 Test MSE 2.8058780601083737 Test RE 0.8006495370867021\n",
      "53 Train Loss 0.6421858 Test MSE 2.831192375690623 Test RE 0.8042531125111397\n",
      "54 Train Loss 0.6348462 Test MSE 2.8343966881817932 Test RE 0.8047081062359938\n",
      "55 Train Loss 0.6298738 Test MSE 2.837684847128131 Test RE 0.8051747383788731\n",
      "56 Train Loss 0.6232323 Test MSE 2.8511523904540335 Test RE 0.8070831409537812\n",
      "57 Train Loss 0.61689425 Test MSE 2.834880296425514 Test RE 0.804776753450605\n",
      "58 Train Loss 0.61143404 Test MSE 2.8352291580336626 Test RE 0.8048262700167566\n",
      "59 Train Loss 0.6057621 Test MSE 2.853550593935785 Test RE 0.8074225024627862\n",
      "60 Train Loss 0.60047096 Test MSE 2.8510466103692487 Test RE 0.807068169092713\n",
      "61 Train Loss 0.59420544 Test MSE 2.8561120122346817 Test RE 0.8077848024830263\n",
      "62 Train Loss 0.5880758 Test MSE 2.8601987070409023 Test RE 0.8083625091537124\n",
      "63 Train Loss 0.5814828 Test MSE 2.86095434610717 Test RE 0.8084692831955762\n",
      "64 Train Loss 0.57829726 Test MSE 2.8693128379248156 Test RE 0.8096494235564214\n",
      "65 Train Loss 0.5714473 Test MSE 2.8937477208095697 Test RE 0.8130895761637378\n",
      "66 Train Loss 0.56546235 Test MSE 2.907197572263095 Test RE 0.8149769653272044\n",
      "67 Train Loss 0.55889815 Test MSE 2.909623957039107 Test RE 0.8153169895642142\n",
      "68 Train Loss 0.5539361 Test MSE 2.914919998802205 Test RE 0.8160586644014176\n",
      "69 Train Loss 0.5482612 Test MSE 2.921141476488507 Test RE 0.8169290801556238\n",
      "70 Train Loss 0.5440088 Test MSE 2.930393041399058 Test RE 0.81822170801784\n",
      "71 Train Loss 0.53928876 Test MSE 2.939359475971663 Test RE 0.8194725518101055\n",
      "72 Train Loss 0.534595 Test MSE 2.9526417736865733 Test RE 0.8213219700376811\n",
      "73 Train Loss 0.5286555 Test MSE 2.957403655543855 Test RE 0.821983997955967\n",
      "74 Train Loss 0.5251577 Test MSE 2.9512706974678014 Test RE 0.8211312551008657\n",
      "75 Train Loss 0.520292 Test MSE 2.9644246554175853 Test RE 0.8229591317286763\n",
      "76 Train Loss 0.51546043 Test MSE 2.987814025932288 Test RE 0.8261993350693376\n",
      "77 Train Loss 0.5116103 Test MSE 2.99079191545265 Test RE 0.8266109600209085\n",
      "78 Train Loss 0.5083793 Test MSE 2.9938674276534436 Test RE 0.8270358640152158\n",
      "79 Train Loss 0.50502455 Test MSE 2.9914968557435624 Test RE 0.8267083718526845\n",
      "80 Train Loss 0.50114405 Test MSE 2.9957518645092445 Test RE 0.8272961046130312\n",
      "81 Train Loss 0.49828792 Test MSE 3.0113339699280197 Test RE 0.829444863308259\n",
      "82 Train Loss 0.49560237 Test MSE 3.0167908203002716 Test RE 0.8301960433409983\n",
      "83 Train Loss 0.4934761 Test MSE 3.014585876188728 Test RE 0.8298925966340646\n",
      "84 Train Loss 0.4908684 Test MSE 3.013540215695951 Test RE 0.8297486529545959\n",
      "85 Train Loss 0.48904082 Test MSE 3.012194960184554 Test RE 0.8295634308457146\n",
      "86 Train Loss 0.48664302 Test MSE 3.0089350716428984 Test RE 0.8291144200048972\n",
      "87 Train Loss 0.4842285 Test MSE 3.0135598245397293 Test RE 0.8297513525013213\n",
      "88 Train Loss 0.4818175 Test MSE 3.0130105067780226 Test RE 0.8296757246798965\n",
      "89 Train Loss 0.4800372 Test MSE 3.013211775638147 Test RE 0.829703435353059\n",
      "90 Train Loss 0.47705656 Test MSE 3.0094958002895345 Test RE 0.8291916710153293\n",
      "91 Train Loss 0.4756972 Test MSE 3.012289341636875 Test RE 0.8295764271472704\n",
      "92 Train Loss 0.47366166 Test MSE 3.017286859950661 Test RE 0.8302642935533783\n",
      "93 Train Loss 0.47185957 Test MSE 3.0190150788130325 Test RE 0.8305020357823362\n",
      "94 Train Loss 0.47040597 Test MSE 3.0159061553872997 Test RE 0.8300743081585555\n",
      "95 Train Loss 0.4684359 Test MSE 3.024316370049894 Test RE 0.8312308831019088\n",
      "96 Train Loss 0.4664548 Test MSE 3.035329225283475 Test RE 0.8327429449646475\n",
      "97 Train Loss 0.46479705 Test MSE 3.0327292714497673 Test RE 0.8323862197323187\n",
      "98 Train Loss 0.46245044 Test MSE 3.0320004539193968 Test RE 0.8322861952878907\n",
      "99 Train Loss 0.4599804 Test MSE 3.0378114255259536 Test RE 0.833083371351646\n",
      "Training time: 67.33\n",
      "9\n",
      "KG_rowdy_tune13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.70405 Test MSE 8.487128544688805 Test RE 1.3924783458433545\n",
      "1 Train Loss 47.63681 Test MSE 8.66757177566102 Test RE 1.407203101474519\n",
      "2 Train Loss 44.805748 Test MSE 8.6000655826942 Test RE 1.4017124857568515\n",
      "3 Train Loss 44.03097 Test MSE 8.741822070407196 Test RE 1.4132176136275845\n",
      "4 Train Loss 43.179066 Test MSE 8.646565628837186 Test RE 1.4054968654421314\n",
      "5 Train Loss 42.80497 Test MSE 8.488377031972325 Test RE 1.3925807613757875\n",
      "6 Train Loss 42.272606 Test MSE 8.49502905698626 Test RE 1.393126311359783\n",
      "7 Train Loss 41.70588 Test MSE 8.567056116239591 Test RE 1.399019816419135\n",
      "8 Train Loss 40.679794 Test MSE 8.925287347333175 Test RE 1.4279702639406466\n",
      "9 Train Loss 39.518173 Test MSE 9.131145405537218 Test RE 1.4443441594053181\n",
      "10 Train Loss 37.66317 Test MSE 9.190532563287828 Test RE 1.449033411171412\n",
      "11 Train Loss 34.37539 Test MSE 9.776423871100475 Test RE 1.4945074065171413\n",
      "12 Train Loss 30.368328 Test MSE 9.26435531102552 Test RE 1.454841435563148\n",
      "13 Train Loss 28.63724 Test MSE 9.533071567307228 Test RE 1.4757897409041114\n",
      "14 Train Loss 27.54955 Test MSE 9.679480919142147 Test RE 1.4870791834985044\n",
      "15 Train Loss 26.812138 Test MSE 9.644675781923782 Test RE 1.4844031822385708\n",
      "16 Train Loss 25.95453 Test MSE 9.53629193663278 Test RE 1.476038988309764\n",
      "17 Train Loss 25.373497 Test MSE 9.435909943530776 Test RE 1.4682498121130523\n",
      "18 Train Loss 23.882587 Test MSE 9.37861525053506 Test RE 1.4637854302910853\n",
      "19 Train Loss 21.10603 Test MSE 9.00533417231555 Test RE 1.4343593771442473\n",
      "20 Train Loss 19.608465 Test MSE 8.409195072358788 Test RE 1.3860703512806969\n",
      "21 Train Loss 15.757153 Test MSE 6.995288638494778 Test RE 1.2641857184327374\n",
      "22 Train Loss 13.427259 Test MSE 6.827955164004801 Test RE 1.248973979520368\n",
      "23 Train Loss 11.184781 Test MSE 6.935408327171226 Test RE 1.258763316671618\n",
      "24 Train Loss 9.531985 Test MSE 6.889131404165813 Test RE 1.254556701296235\n",
      "25 Train Loss 7.9392414 Test MSE 7.299394167941398 Test RE 1.2913723055325204\n",
      "26 Train Loss 7.383872 Test MSE 7.2240320182700986 Test RE 1.2846886622732518\n",
      "27 Train Loss 6.9820666 Test MSE 7.085619703472649 Test RE 1.272321833673023\n",
      "28 Train Loss 6.3986087 Test MSE 7.064847764406821 Test RE 1.2704555191924143\n",
      "29 Train Loss 5.9852934 Test MSE 6.602565916914093 Test RE 1.2281868216533876\n",
      "30 Train Loss 4.75866 Test MSE 5.785705090163524 Test RE 1.1497044352513708\n",
      "31 Train Loss 4.2678523 Test MSE 5.882563292145742 Test RE 1.1592880644309078\n",
      "32 Train Loss 3.8330784 Test MSE 5.733572044158089 Test RE 1.144512913697949\n",
      "33 Train Loss 3.5728855 Test MSE 5.567354506755822 Test RE 1.1278010599967785\n",
      "34 Train Loss 3.3471646 Test MSE 5.542551651828041 Test RE 1.1252860494490442\n",
      "35 Train Loss 3.219682 Test MSE 5.5985224251524395 Test RE 1.1309535583265669\n",
      "36 Train Loss 3.0598276 Test MSE 5.737170977896683 Test RE 1.1448720597885136\n",
      "37 Train Loss 2.956876 Test MSE 5.735442396618496 Test RE 1.144699574646915\n",
      "38 Train Loss 2.8833637 Test MSE 5.684775618676975 Test RE 1.1396322325958388\n",
      "39 Train Loss 2.8267446 Test MSE 5.673272019490505 Test RE 1.1384785800823574\n",
      "40 Train Loss 2.783094 Test MSE 5.651296007665592 Test RE 1.136271432749071\n",
      "41 Train Loss 2.7547078 Test MSE 5.626287674399527 Test RE 1.1337545090593018\n",
      "42 Train Loss 2.7122602 Test MSE 5.644136617146602 Test RE 1.1355514572760863\n",
      "43 Train Loss 2.637757 Test MSE 5.6555926845243745 Test RE 1.136703303910539\n",
      "44 Train Loss 2.58402 Test MSE 5.707285859691007 Test RE 1.1418863278226277\n",
      "45 Train Loss 2.5207477 Test MSE 5.6918126347997715 Test RE 1.1403373730145367\n",
      "46 Train Loss 2.4929924 Test MSE 5.6610100102375505 Test RE 1.1372475809182636\n",
      "47 Train Loss 2.4508076 Test MSE 5.676629571845302 Test RE 1.1388154170993374\n",
      "48 Train Loss 2.4159102 Test MSE 5.6657807719799225 Test RE 1.1377266822307863\n",
      "49 Train Loss 2.3655555 Test MSE 5.698756401086964 Test RE 1.1410327422413395\n",
      "50 Train Loss 2.309718 Test MSE 5.6490539234848836 Test RE 1.1360460093298137\n",
      "51 Train Loss 2.2620196 Test MSE 5.626503190270116 Test RE 1.1337762231774156\n",
      "52 Train Loss 2.246704 Test MSE 5.667407889890081 Test RE 1.1378900385840887\n",
      "53 Train Loss 2.2170029 Test MSE 5.651242928944079 Test RE 1.1362660966300222\n",
      "54 Train Loss 2.1964726 Test MSE 5.641944713584633 Test RE 1.1353309398477538\n",
      "55 Train Loss 2.1726174 Test MSE 5.645174987201797 Test RE 1.1356559080081097\n",
      "56 Train Loss 2.1660633 Test MSE 5.641022033861886 Test RE 1.1352381004349044\n",
      "57 Train Loss 2.1563394 Test MSE 5.636345311803178 Test RE 1.1347674149904023\n",
      "58 Train Loss 2.143643 Test MSE 5.603196868099612 Test RE 1.1314256002732221\n",
      "59 Train Loss 2.13263 Test MSE 5.579225724361961 Test RE 1.1290028195045982\n",
      "60 Train Loss 2.1178868 Test MSE 5.567034080315617 Test RE 1.1277686045030293\n",
      "61 Train Loss 2.1030056 Test MSE 5.581170742570726 Test RE 1.1291995976776166\n",
      "62 Train Loss 2.092208 Test MSE 5.570851935261763 Test RE 1.1281552483545068\n",
      "63 Train Loss 2.0800726 Test MSE 5.534085263626605 Test RE 1.1244262695013447\n",
      "64 Train Loss 2.0699878 Test MSE 5.507956563175189 Test RE 1.1217686886709646\n",
      "65 Train Loss 2.0611293 Test MSE 5.525282714704726 Test RE 1.1235316540599742\n",
      "66 Train Loss 2.0511153 Test MSE 5.523220211783462 Test RE 1.1233219359576996\n",
      "67 Train Loss 2.039077 Test MSE 5.499421904580276 Test RE 1.1208992533117939\n",
      "68 Train Loss 2.0203507 Test MSE 5.491644896974677 Test RE 1.1201064130621763\n",
      "69 Train Loss 2.0014062 Test MSE 5.4711632173647375 Test RE 1.118015683240587\n",
      "70 Train Loss 1.9810319 Test MSE 5.45648137498384 Test RE 1.1165145804340946\n",
      "71 Train Loss 1.9562355 Test MSE 5.424856289271777 Test RE 1.1132742888816247\n",
      "72 Train Loss 1.9436542 Test MSE 5.42363796327916 Test RE 1.1131492710847266\n",
      "73 Train Loss 1.9275856 Test MSE 5.4091284522403695 Test RE 1.1116593054637325\n",
      "74 Train Loss 1.9054602 Test MSE 5.39983891036975 Test RE 1.1107043232207494\n",
      "75 Train Loss 1.8848238 Test MSE 5.3803318148501065 Test RE 1.1086962801150357\n",
      "76 Train Loss 1.8704954 Test MSE 5.354520734565556 Test RE 1.1060337071608362\n",
      "77 Train Loss 1.8495973 Test MSE 5.336126076350326 Test RE 1.1041322657195531\n",
      "78 Train Loss 1.8304274 Test MSE 5.303967811215433 Test RE 1.1008002009114521\n",
      "79 Train Loss 1.8141563 Test MSE 5.28744996890502 Test RE 1.099084784895113\n",
      "80 Train Loss 1.7930224 Test MSE 5.25996975839602 Test RE 1.096224953879976\n",
      "81 Train Loss 1.7654332 Test MSE 5.190697922290153 Test RE 1.0889825935615485\n",
      "82 Train Loss 1.7431903 Test MSE 5.170447060377724 Test RE 1.086856252593848\n",
      "83 Train Loss 1.7160772 Test MSE 5.184129397322947 Test RE 1.0882933535187274\n",
      "84 Train Loss 1.6956307 Test MSE 5.164770117737418 Test RE 1.0862594265291872\n",
      "85 Train Loss 1.6854995 Test MSE 5.173742385237985 Test RE 1.0872025450811944\n",
      "86 Train Loss 1.6703575 Test MSE 5.17482008716283 Test RE 1.0873157725265088\n",
      "87 Train Loss 1.6581367 Test MSE 5.146728076835271 Test RE 1.0843604569538952\n",
      "88 Train Loss 1.6433318 Test MSE 5.133302897352549 Test RE 1.0829452627409641\n",
      "89 Train Loss 1.6353157 Test MSE 5.145497596717829 Test RE 1.084230824717432\n",
      "90 Train Loss 1.6270835 Test MSE 5.145679501410251 Test RE 1.0842499895239364\n",
      "91 Train Loss 1.6233855 Test MSE 5.141024382701132 Test RE 1.0837594367738863\n",
      "92 Train Loss 1.6101457 Test MSE 5.147972950968107 Test RE 1.0844915898451557\n",
      "93 Train Loss 1.597739 Test MSE 5.142670243231117 Test RE 1.0839329016332366\n",
      "94 Train Loss 1.5862625 Test MSE 5.122255304609445 Test RE 1.0817793095114001\n",
      "95 Train Loss 1.5663793 Test MSE 5.089997743973952 Test RE 1.0783676605174592\n",
      "96 Train Loss 1.5556374 Test MSE 5.08079814074149 Test RE 1.0773927051496799\n",
      "97 Train Loss 1.5446835 Test MSE 5.0861206923741955 Test RE 1.0779568859235875\n",
      "98 Train Loss 1.525465 Test MSE 5.05355264201889 Test RE 1.074500092703626\n",
      "99 Train Loss 1.5074817 Test MSE 4.9829308653108555 Test RE 1.0669657806776325\n",
      "Training time: 68.19\n",
      "0\n",
      "KG_rowdy_tune14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.65\n",
      "0\n",
      "KG_rowdy_tune15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.938286 Test MSE 8.566050291890427 Test RE 1.3989376873025416\n",
      "1 Train Loss 54.664326 Test MSE 7.167719121721393 Test RE 1.279671652582887\n",
      "2 Train Loss 39.020687 Test MSE 8.038465902368666 Test RE 1.3551727094756616\n",
      "3 Train Loss 30.895666 Test MSE 7.3360832222864305 Test RE 1.294613659611437\n",
      "4 Train Loss 26.811886 Test MSE 6.160203184080625 Test RE 1.1863301794955001\n",
      "5 Train Loss 23.316486 Test MSE 5.918913076331364 Test RE 1.1628643092665205\n",
      "6 Train Loss 21.703396 Test MSE 5.521311849436183 Test RE 1.1231278561991984\n",
      "7 Train Loss 16.526527 Test MSE 5.606716786676176 Test RE 1.1317809242806174\n",
      "8 Train Loss 12.6662035 Test MSE 6.109786710511104 Test RE 1.1814656107887387\n",
      "9 Train Loss 9.566886 Test MSE 5.7481053481267 Test RE 1.145962535915077\n",
      "10 Train Loss 7.7059274 Test MSE 5.6613884464093935 Test RE 1.137285592547621\n",
      "11 Train Loss 6.4915924 Test MSE 5.245076787044356 Test RE 1.0946719392922593\n",
      "12 Train Loss 5.7287445 Test MSE 4.968209322415429 Test RE 1.065388495987855\n",
      "13 Train Loss 4.9186544 Test MSE 4.354737602035162 Test RE 0.9974452258570908\n",
      "14 Train Loss 3.9625044 Test MSE 4.107690241581156 Test RE 0.9687392660575614\n",
      "15 Train Loss 2.988363 Test MSE 3.7149178766808038 Test RE 0.9212609630975098\n",
      "16 Train Loss 2.1283615 Test MSE 2.6539270744011216 Test RE 0.7786684041272546\n",
      "17 Train Loss 1.6926597 Test MSE 2.1597801875461395 Test RE 0.7024458268250242\n",
      "18 Train Loss 1.4398632 Test MSE 1.855180021225697 Test RE 0.6510301318133382\n",
      "19 Train Loss 1.1508937 Test MSE 1.5169596267081087 Test RE 0.5887014038558863\n",
      "20 Train Loss 0.85993564 Test MSE 1.327912525423106 Test RE 0.5507985571983286\n",
      "21 Train Loss 0.6565021 Test MSE 1.110517346833263 Test RE 0.5036985883235184\n",
      "22 Train Loss 0.51588315 Test MSE 0.9526512259142303 Test RE 0.46652511178824163\n",
      "23 Train Loss 0.4068556 Test MSE 0.7914030327647747 Test RE 0.4252133737015475\n",
      "24 Train Loss 0.29608768 Test MSE 0.5906703614353984 Test RE 0.36735051243723654\n",
      "25 Train Loss 0.24566665 Test MSE 0.5284096299443077 Test RE 0.3474508849562758\n",
      "26 Train Loss 0.20372774 Test MSE 0.4932329749683951 Test RE 0.335686682477788\n",
      "27 Train Loss 0.16731595 Test MSE 0.4332369176261855 Test RE 0.31460874400465605\n",
      "28 Train Loss 0.1440581 Test MSE 0.3886480973571937 Test RE 0.2979794630618035\n",
      "29 Train Loss 0.13173142 Test MSE 0.36854876564855704 Test RE 0.2901720251736976\n",
      "30 Train Loss 0.11649114 Test MSE 0.35819300539797705 Test RE 0.286066241984727\n",
      "31 Train Loss 0.10199358 Test MSE 0.3347916750596032 Test RE 0.2765638328688823\n",
      "32 Train Loss 0.09207525 Test MSE 0.33219036725321666 Test RE 0.27548729685805456\n",
      "33 Train Loss 0.08114913 Test MSE 0.332669927824795 Test RE 0.27568607625139735\n",
      "34 Train Loss 0.06721228 Test MSE 0.31965514806328826 Test RE 0.27023955175211023\n",
      "35 Train Loss 0.054544777 Test MSE 0.3031001302601134 Test RE 0.2631486351152646\n",
      "36 Train Loss 0.046101943 Test MSE 0.2663246852848755 Test RE 0.2466685446772504\n",
      "37 Train Loss 0.03904358 Test MSE 0.2342348342751958 Test RE 0.23133098184637424\n",
      "38 Train Loss 0.031666495 Test MSE 0.23777779427312393 Test RE 0.23307393438369908\n",
      "39 Train Loss 0.027362995 Test MSE 0.22706553415134542 Test RE 0.22776325959840385\n",
      "40 Train Loss 0.023885146 Test MSE 0.20636631517066917 Test RE 0.2171338160823179\n",
      "41 Train Loss 0.020639753 Test MSE 0.18450378190308114 Test RE 0.20531028061945192\n",
      "42 Train Loss 0.018480755 Test MSE 0.1747684293823223 Test RE 0.19982027481993736\n",
      "43 Train Loss 0.017302912 Test MSE 0.16213418602096047 Test RE 0.1924621611072822\n",
      "44 Train Loss 0.015846178 Test MSE 0.15819001627316337 Test RE 0.19010677551352864\n",
      "45 Train Loss 0.013881941 Test MSE 0.1352315836958916 Test RE 0.17577096106111353\n",
      "46 Train Loss 0.012071275 Test MSE 0.12611510588520977 Test RE 0.16974289883867003\n",
      "47 Train Loss 0.011047514 Test MSE 0.12096244392991373 Test RE 0.16623916034770322\n",
      "48 Train Loss 0.01012265 Test MSE 0.11728471386878826 Test RE 0.16369249437797967\n",
      "49 Train Loss 0.008906383 Test MSE 0.09879810735655227 Test RE 0.1502388922586113\n",
      "50 Train Loss 0.008027822 Test MSE 0.09793202463426823 Test RE 0.1495789315992689\n",
      "51 Train Loss 0.007317777 Test MSE 0.0939373297004878 Test RE 0.1464964718836628\n",
      "52 Train Loss 0.006395442 Test MSE 0.08411136024031837 Test RE 0.13862303035902376\n",
      "53 Train Loss 0.0059406124 Test MSE 0.08277777594997625 Test RE 0.1375197066101678\n",
      "54 Train Loss 0.005358189 Test MSE 0.07843061585722075 Test RE 0.13386001609532874\n",
      "55 Train Loss 0.004812429 Test MSE 0.07423973556600673 Test RE 0.13023456639616912\n",
      "56 Train Loss 0.0043555205 Test MSE 0.06691405025267907 Test RE 0.12364219868459782\n",
      "57 Train Loss 0.0038610213 Test MSE 0.05830343275198636 Test RE 0.11541310444932973\n",
      "58 Train Loss 0.0034940774 Test MSE 0.05544363851317935 Test RE 0.11254699968681936\n",
      "59 Train Loss 0.0031330546 Test MSE 0.052868325003127735 Test RE 0.1099020607441592\n",
      "60 Train Loss 0.002841906 Test MSE 0.047984006783290144 Test RE 0.10470232247768319\n",
      "61 Train Loss 0.0025540981 Test MSE 0.0457335369962152 Test RE 0.10221754723588176\n",
      "62 Train Loss 0.0022731023 Test MSE 0.04369016806995673 Test RE 0.09990792012799483\n",
      "63 Train Loss 0.0021014076 Test MSE 0.043023284962013124 Test RE 0.0991424949392341\n",
      "64 Train Loss 0.0019645419 Test MSE 0.040020544239522886 Test RE 0.09562017967827507\n",
      "65 Train Loss 0.0018191932 Test MSE 0.0369104454213375 Test RE 0.09182960227599772\n",
      "66 Train Loss 0.0016894151 Test MSE 0.03512623971037995 Test RE 0.08958264695041296\n",
      "67 Train Loss 0.0015998741 Test MSE 0.034345276585879304 Test RE 0.08858120204409227\n",
      "68 Train Loss 0.0015143843 Test MSE 0.030525592696689256 Test RE 0.08351031326978135\n",
      "69 Train Loss 0.0014130875 Test MSE 0.028436391830177578 Test RE 0.08060190478717094\n",
      "70 Train Loss 0.0013507667 Test MSE 0.027462398762908184 Test RE 0.07920950417428624\n",
      "71 Train Loss 0.0012817928 Test MSE 0.025214701805689528 Test RE 0.07589881205671409\n",
      "72 Train Loss 0.0012287556 Test MSE 0.02430140178961302 Test RE 0.07451157153235526\n",
      "73 Train Loss 0.0011611494 Test MSE 0.021901667670528556 Test RE 0.07073700252752822\n",
      "74 Train Loss 0.0011177262 Test MSE 0.021937217187457038 Test RE 0.07079438735134208\n",
      "75 Train Loss 0.0010649182 Test MSE 0.021437445505046584 Test RE 0.06998332571475165\n",
      "76 Train Loss 0.0010204398 Test MSE 0.02080120558276811 Test RE 0.06893698945160882\n",
      "77 Train Loss 0.00097090105 Test MSE 0.02054433657106925 Test RE 0.06851002420443601\n",
      "78 Train Loss 0.0009374337 Test MSE 0.019405598661562714 Test RE 0.06658426083214036\n",
      "79 Train Loss 0.00090668286 Test MSE 0.018828889757095 Test RE 0.06558740023601331\n",
      "80 Train Loss 0.00087045634 Test MSE 0.017824670240995273 Test RE 0.06381441793871051\n",
      "81 Train Loss 0.000843958 Test MSE 0.01758271370344132 Test RE 0.06337982162488345\n",
      "82 Train Loss 0.00082318136 Test MSE 0.016991125265885625 Test RE 0.062304459259919974\n",
      "83 Train Loss 0.00080303126 Test MSE 0.016899903844256936 Test RE 0.06213698505924519\n",
      "84 Train Loss 0.0007815585 Test MSE 0.016927711190127433 Test RE 0.06218808459423669\n",
      "85 Train Loss 0.0007505543 Test MSE 0.015827115353504444 Test RE 0.06013245626854099\n",
      "86 Train Loss 0.00072191434 Test MSE 0.015618707105317061 Test RE 0.05973523831370636\n",
      "87 Train Loss 0.0006930101 Test MSE 0.014858871242365982 Test RE 0.058264090292480454\n",
      "88 Train Loss 0.00065613096 Test MSE 0.015409928326310308 Test RE 0.05933464791563361\n",
      "89 Train Loss 0.00063170237 Test MSE 0.013941057230417594 Test RE 0.05643595978265955\n",
      "90 Train Loss 0.0006023207 Test MSE 0.013254419171026658 Test RE 0.0550285932678922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Train Loss 0.0005854896 Test MSE 0.013102687973536198 Test RE 0.05471271417957415\n",
      "92 Train Loss 0.0005650704 Test MSE 0.01245005184013155 Test RE 0.05333270853568347\n",
      "93 Train Loss 0.0005447374 Test MSE 0.01163909606458606 Test RE 0.05156650371880057\n",
      "94 Train Loss 0.00053557986 Test MSE 0.011243656308257289 Test RE 0.05068294488005453\n",
      "95 Train Loss 0.0005215529 Test MSE 0.011258272968580478 Test RE 0.050715877885212424\n",
      "96 Train Loss 0.0005058557 Test MSE 0.011183046366492722 Test RE 0.05054615479707535\n",
      "97 Train Loss 0.0004934638 Test MSE 0.01060758436719963 Test RE 0.04922846651871433\n",
      "98 Train Loss 0.0004818614 Test MSE 0.01050565811953849 Test RE 0.04899138216375517\n",
      "99 Train Loss 0.00047342852 Test MSE 0.010392139642836107 Test RE 0.04872597602847029\n",
      "Training time: 66.78\n",
      "1\n",
      "KG_rowdy_tune15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.64875 Test MSE 8.734671473190458 Test RE 1.4126395066161819\n",
      "1 Train Loss 56.874672 Test MSE 8.731544320812532 Test RE 1.4123866101870453\n",
      "2 Train Loss 51.8833 Test MSE 9.535329376400002 Test RE 1.4759644933018778\n",
      "3 Train Loss 49.378666 Test MSE 9.021678379957565 Test RE 1.4356604304711968\n",
      "4 Train Loss 45.11325 Test MSE 8.65820141861528 Test RE 1.4064422447114147\n",
      "5 Train Loss 44.302914 Test MSE 8.492610401568117 Test RE 1.3929279758185942\n",
      "6 Train Loss 44.04107 Test MSE 8.579537998603547 Test RE 1.4000386054085272\n",
      "7 Train Loss 43.82611 Test MSE 8.369882625391172 Test RE 1.3828266608856208\n",
      "8 Train Loss 43.606728 Test MSE 8.53043189052076 Test RE 1.3960262037397726\n",
      "9 Train Loss 43.372154 Test MSE 8.448121637602673 Test RE 1.389274740142023\n",
      "10 Train Loss 42.994225 Test MSE 8.482490565032665 Test RE 1.3920978185092139\n",
      "11 Train Loss 42.36876 Test MSE 8.286128376887914 Test RE 1.3758905539231716\n",
      "12 Train Loss 41.128803 Test MSE 8.200862683888719 Test RE 1.3687931725995275\n",
      "13 Train Loss 40.088734 Test MSE 7.99143520401464 Test RE 1.3512025355223583\n",
      "14 Train Loss 39.427326 Test MSE 7.996707914059492 Test RE 1.351648220446898\n",
      "15 Train Loss 39.076324 Test MSE 7.769373448417935 Test RE 1.3322970271244448\n",
      "16 Train Loss 38.683746 Test MSE 7.824063929545362 Test RE 1.3369779829638744\n",
      "17 Train Loss 38.378174 Test MSE 7.812490180143534 Test RE 1.3359887544165239\n",
      "18 Train Loss 37.78257 Test MSE 7.8468457055133864 Test RE 1.338923045866432\n",
      "19 Train Loss 37.201935 Test MSE 7.943346570704601 Test RE 1.347130955908203\n",
      "20 Train Loss 36.817112 Test MSE 7.9380156034958524 Test RE 1.3466788343614005\n",
      "21 Train Loss 36.53836 Test MSE 7.872852756859922 Test RE 1.3411400281399544\n",
      "22 Train Loss 36.30961 Test MSE 7.859026715068589 Test RE 1.3399618779315123\n",
      "23 Train Loss 36.08542 Test MSE 7.83510429088867 Test RE 1.3379209402756427\n",
      "24 Train Loss 35.91653 Test MSE 7.876429312862338 Test RE 1.341444626607686\n",
      "25 Train Loss 35.49289 Test MSE 7.791069360405534 Test RE 1.3341559445672302\n",
      "26 Train Loss 35.096992 Test MSE 7.692491157124312 Test RE 1.3256887265305215\n",
      "27 Train Loss 33.920635 Test MSE 7.446527933352292 Test RE 1.3043224570348386\n",
      "28 Train Loss 32.918964 Test MSE 7.250104381422866 Test RE 1.2870048689263158\n",
      "29 Train Loss 32.069298 Test MSE 7.331999003595288 Test RE 1.2942532342129847\n",
      "30 Train Loss 31.600721 Test MSE 7.268145859697138 Test RE 1.2886051936953293\n",
      "31 Train Loss 31.225193 Test MSE 7.217043330832196 Test RE 1.2840670938754297\n",
      "32 Train Loss 30.845211 Test MSE 7.253419187251168 Test RE 1.2872990497750096\n",
      "33 Train Loss 30.377502 Test MSE 7.136461175863209 Test RE 1.2768783224360039\n",
      "34 Train Loss 29.928165 Test MSE 7.020253115349248 Test RE 1.2664394944827029\n",
      "35 Train Loss 29.413952 Test MSE 6.930375548085427 Test RE 1.258306513906913\n",
      "36 Train Loss 29.024422 Test MSE 6.970815778592803 Test RE 1.2619724182961487\n",
      "37 Train Loss 27.855614 Test MSE 7.4832394118246945 Test RE 1.3075336673171527\n",
      "38 Train Loss 26.163038 Test MSE 7.329531037907088 Test RE 1.2940353917522323\n",
      "39 Train Loss 24.150238 Test MSE 6.898534188659474 Test RE 1.2554125641931952\n",
      "40 Train Loss 23.28264 Test MSE 7.15526377759215 Test RE 1.278559326559208\n",
      "41 Train Loss 21.622929 Test MSE 7.016886057230064 Test RE 1.2661357528133115\n",
      "42 Train Loss 20.538902 Test MSE 6.920470948738755 Test RE 1.2574070332164606\n",
      "43 Train Loss 19.202528 Test MSE 6.301272840246013 Test RE 1.1998368680107938\n",
      "44 Train Loss 17.296198 Test MSE 6.314146927126519 Test RE 1.2010619317961242\n",
      "45 Train Loss 16.251318 Test MSE 5.759217033305823 Test RE 1.1470696334946395\n",
      "46 Train Loss 14.524986 Test MSE 6.019020520832695 Test RE 1.1726569241572846\n",
      "47 Train Loss 12.944984 Test MSE 5.878034791394269 Test RE 1.158841758343454\n",
      "48 Train Loss 12.019575 Test MSE 5.300326832873399 Test RE 1.1004223066723113\n",
      "49 Train Loss 10.972079 Test MSE 5.013520004538217 Test RE 1.070235706561261\n",
      "50 Train Loss 10.06226 Test MSE 4.9367319566847 Test RE 1.0620081119819103\n",
      "51 Train Loss 9.601455 Test MSE 4.80633425658862 Test RE 1.0478884307670946\n",
      "52 Train Loss 8.852952 Test MSE 3.86510069679864 Test RE 0.9396983553966916\n",
      "53 Train Loss 8.0932 Test MSE 3.8859976179865585 Test RE 0.9422352016012493\n",
      "54 Train Loss 7.397132 Test MSE 3.833729714350634 Test RE 0.9358770679555142\n",
      "55 Train Loss 6.6589556 Test MSE 3.8235578344841525 Test RE 0.9346346809437283\n",
      "56 Train Loss 6.0978165 Test MSE 3.8814538658827935 Test RE 0.9416841802395681\n",
      "57 Train Loss 5.640007 Test MSE 3.9848278176148733 Test RE 0.9541416204025822\n",
      "58 Train Loss 5.279283 Test MSE 3.9712918124269385 Test RE 0.9525196867702593\n",
      "59 Train Loss 4.880951 Test MSE 4.001372497991869 Test RE 0.9561203277997434\n",
      "60 Train Loss 4.558052 Test MSE 4.006336010752039 Test RE 0.9567131549675515\n",
      "61 Train Loss 4.350316 Test MSE 3.914432851581601 Test RE 0.945676254104883\n",
      "62 Train Loss 4.0653663 Test MSE 3.961603437263949 Test RE 0.9513570923581424\n",
      "63 Train Loss 3.9289422 Test MSE 3.9160397266427904 Test RE 0.9458703342859706\n",
      "64 Train Loss 3.808879 Test MSE 3.9139583633286597 Test RE 0.9456189372611451\n",
      "65 Train Loss 3.6770155 Test MSE 3.960202100184512 Test RE 0.9511888158121767\n",
      "66 Train Loss 3.5041144 Test MSE 4.0290076058936775 Test RE 0.9594163248838886\n",
      "67 Train Loss 3.389839 Test MSE 4.010732103171671 Test RE 0.9572379045553825\n",
      "68 Train Loss 3.2102332 Test MSE 3.8050733451188905 Test RE 0.9323727594391721\n",
      "69 Train Loss 2.9951892 Test MSE 3.672464868380181 Test RE 0.9159818857461314\n",
      "70 Train Loss 2.8011732 Test MSE 3.4973346012645083 Test RE 0.893874715049692\n",
      "71 Train Loss 2.5669436 Test MSE 3.4121265443466258 Test RE 0.8829185165714424\n",
      "72 Train Loss 2.3787966 Test MSE 3.184188608513752 Test RE 0.8529183389187439\n",
      "73 Train Loss 2.250598 Test MSE 2.9836544172266213 Test RE 0.8256240209978485\n",
      "74 Train Loss 2.091606 Test MSE 2.8976800693769142 Test RE 0.8136418472056278\n",
      "75 Train Loss 2.0240376 Test MSE 2.787168048048172 Test RE 0.7979756470833138\n",
      "76 Train Loss 1.9370108 Test MSE 2.7991629793038366 Test RE 0.7996908983257095\n",
      "77 Train Loss 1.867977 Test MSE 2.718382696092868 Test RE 0.7880673934380013\n",
      "78 Train Loss 1.8016961 Test MSE 2.730344911541733 Test RE 0.7897994313567989\n",
      "79 Train Loss 1.7373005 Test MSE 2.8254039576619614 Test RE 0.8034305376876093\n",
      "80 Train Loss 1.6806425 Test MSE 2.7882408355981974 Test RE 0.7981292036622119\n",
      "81 Train Loss 1.6231046 Test MSE 2.768968210263313 Test RE 0.7953660424296485\n",
      "82 Train Loss 1.5799863 Test MSE 2.7293082310288934 Test RE 0.789649478248276\n",
      "83 Train Loss 1.5463499 Test MSE 2.7076268366713436 Test RE 0.7865067700290416\n",
      "84 Train Loss 1.5203638 Test MSE 2.719064408944746 Test RE 0.788166202555903\n",
      "85 Train Loss 1.497876 Test MSE 2.7042902140117624 Test RE 0.7860220124451837\n",
      "86 Train Loss 1.4653438 Test MSE 2.738612044891007 Test RE 0.7909942331802766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 1.4285893 Test MSE 2.728618875232339 Test RE 0.7895497489807027\n",
      "88 Train Loss 1.3951321 Test MSE 2.7298436805774258 Test RE 0.789726933171878\n",
      "89 Train Loss 1.3676274 Test MSE 2.722370525284144 Test RE 0.788645223490999\n",
      "90 Train Loss 1.3357346 Test MSE 2.7171008576950193 Test RE 0.7878815671082209\n",
      "91 Train Loss 1.3018196 Test MSE 2.6952921689883107 Test RE 0.7847132485993421\n",
      "92 Train Loss 1.2833762 Test MSE 2.6962984953991738 Test RE 0.7848597269627009\n",
      "93 Train Loss 1.2637805 Test MSE 2.66597397785534 Test RE 0.7804336979168294\n",
      "94 Train Loss 1.2402427 Test MSE 2.6821839692418243 Test RE 0.7828027479496625\n",
      "95 Train Loss 1.222419 Test MSE 2.69345211974111 Test RE 0.7844453448894844\n",
      "96 Train Loss 1.202471 Test MSE 2.671690111846766 Test RE 0.7812699166751952\n",
      "97 Train Loss 1.1755384 Test MSE 2.6984653034624 Test RE 0.7851750293775633\n",
      "98 Train Loss 1.1607851 Test MSE 2.6804786056233287 Test RE 0.7825538508557464\n",
      "99 Train Loss 1.1393969 Test MSE 2.6943098982927762 Test RE 0.7845702453513607\n",
      "Training time: 67.93\n",
      "2\n",
      "KG_rowdy_tune15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.612495 Test MSE 8.488392123833176 Test RE 1.3925819993406927\n",
      "1 Train Loss 56.3095 Test MSE 8.563121226987791 Test RE 1.3986984913206453\n",
      "2 Train Loss 49.601463 Test MSE 8.060738171408154 Test RE 1.3570488070745854\n",
      "3 Train Loss 40.971542 Test MSE 8.117973729382133 Test RE 1.3618581715611984\n",
      "4 Train Loss 34.463337 Test MSE 6.944101508053031 Test RE 1.2595519674485258\n",
      "5 Train Loss 29.694067 Test MSE 6.180157284649861 Test RE 1.1882500035911987\n",
      "6 Train Loss 26.87909 Test MSE 6.009746448956087 Test RE 1.1717531644055479\n",
      "7 Train Loss 24.739471 Test MSE 6.333083570917446 Test RE 1.2028616250023478\n",
      "8 Train Loss 23.233673 Test MSE 6.188868343568231 Test RE 1.189087140125558\n",
      "9 Train Loss 22.350925 Test MSE 5.845444498068988 Test RE 1.1556247403426647\n",
      "10 Train Loss 21.794176 Test MSE 5.7441175017378825 Test RE 1.1455649513916297\n",
      "11 Train Loss 21.318241 Test MSE 5.9460213086756335 Test RE 1.1655241882300194\n",
      "12 Train Loss 20.259384 Test MSE 5.749812978206962 Test RE 1.1461327428497297\n",
      "13 Train Loss 16.178421 Test MSE 5.818022650633456 Test RE 1.1529109503442374\n",
      "14 Train Loss 13.231567 Test MSE 5.806397137869009 Test RE 1.151758506980141\n",
      "15 Train Loss 11.980365 Test MSE 6.000710782505467 Test RE 1.1708719663842\n",
      "16 Train Loss 10.725014 Test MSE 5.949781007094153 Test RE 1.1658926133285514\n",
      "17 Train Loss 9.477882 Test MSE 5.912927543521457 Test RE 1.162276184136692\n",
      "18 Train Loss 8.320395 Test MSE 5.799624526764862 Test RE 1.1510866025094257\n",
      "19 Train Loss 7.5498633 Test MSE 5.748001798366647 Test RE 1.1459522138460765\n",
      "20 Train Loss 7.0174417 Test MSE 5.646537156120977 Test RE 1.135792915441562\n",
      "21 Train Loss 6.6501036 Test MSE 5.488979421342588 Test RE 1.1198345474577056\n",
      "22 Train Loss 6.119397 Test MSE 5.293410810324543 Test RE 1.0997041406079104\n",
      "23 Train Loss 5.6440268 Test MSE 5.0343510328277254 Test RE 1.0724568007627302\n",
      "24 Train Loss 5.3805933 Test MSE 4.855772786110598 Test RE 1.0532639956268528\n",
      "25 Train Loss 5.1995516 Test MSE 4.761051161849047 Test RE 1.0429403845953973\n",
      "26 Train Loss 4.8524446 Test MSE 4.439010857683945 Test RE 1.0070503017538954\n",
      "27 Train Loss 4.1593533 Test MSE 3.9374485977759295 Test RE 0.9484523324711341\n",
      "28 Train Loss 3.2799969 Test MSE 3.743815638658826 Test RE 0.9248371939159242\n",
      "29 Train Loss 2.6665583 Test MSE 3.3307958197978014 Test RE 0.8723325255253968\n",
      "30 Train Loss 2.29362 Test MSE 3.225110563499857 Test RE 0.8583815298253472\n",
      "31 Train Loss 1.900018 Test MSE 2.827978128651862 Test RE 0.8037964493875079\n",
      "32 Train Loss 1.6960404 Test MSE 2.686995279119616 Test RE 0.7835045303677998\n",
      "33 Train Loss 1.5505143 Test MSE 2.52095622606558 Test RE 0.7589107638635983\n",
      "34 Train Loss 1.4236453 Test MSE 2.2659281908343925 Test RE 0.7195005521842579\n",
      "35 Train Loss 1.2582474 Test MSE 1.9283440909993084 Test RE 0.6637435685869877\n",
      "36 Train Loss 1.0650454 Test MSE 1.4196583327600125 Test RE 0.5695081955772356\n",
      "37 Train Loss 0.84856844 Test MSE 1.186178403925726 Test RE 0.5205747109942714\n",
      "38 Train Loss 0.64241934 Test MSE 0.8613201126271921 Test RE 0.44359879171540645\n",
      "39 Train Loss 0.5106851 Test MSE 0.6242092224183811 Test RE 0.3776357929428234\n",
      "40 Train Loss 0.34309363 Test MSE 0.31512180659611105 Test RE 0.26831644369049124\n",
      "41 Train Loss 0.22831406 Test MSE 0.19692769052569642 Test RE 0.212110151493308\n",
      "42 Train Loss 0.16489127 Test MSE 0.15543415377609668 Test RE 0.18844355421968073\n",
      "43 Train Loss 0.10334188 Test MSE 0.12755126436823605 Test RE 0.17070665179466088\n",
      "44 Train Loss 0.07922279 Test MSE 0.09162517120268182 Test RE 0.1446823185782612\n",
      "45 Train Loss 0.060927574 Test MSE 0.06791398961888172 Test RE 0.12456260503050677\n",
      "46 Train Loss 0.051648524 Test MSE 0.0558941328158392 Test RE 0.11300331179435605\n",
      "47 Train Loss 0.042386256 Test MSE 0.04002564650615621 Test RE 0.09562627484904823\n",
      "48 Train Loss 0.034611717 Test MSE 0.03455809100048635 Test RE 0.08885521708170083\n",
      "49 Train Loss 0.02652022 Test MSE 0.028766034597055925 Test RE 0.08106773879477096\n",
      "50 Train Loss 0.019483265 Test MSE 0.01683608961560174 Test RE 0.062019559123705784\n",
      "51 Train Loss 0.016199272 Test MSE 0.014734687335906455 Test RE 0.058020106633542984\n",
      "52 Train Loss 0.014799169 Test MSE 0.011873940069286113 Test RE 0.05208413867891493\n",
      "53 Train Loss 0.012822323 Test MSE 0.00977523326327661 Test RE 0.0472575959835636\n",
      "54 Train Loss 0.011222146 Test MSE 0.00900824990816646 Test RE 0.04536576860296211\n",
      "55 Train Loss 0.009505246 Test MSE 0.0067815780205970145 Test RE 0.03936166325527144\n",
      "56 Train Loss 0.008091364 Test MSE 0.006409273175711317 Test RE 0.038265945753537166\n",
      "57 Train Loss 0.0072398256 Test MSE 0.004908774903399986 Test RE 0.03348841701311086\n",
      "58 Train Loss 0.0062195184 Test MSE 0.0039801282947218575 Test RE 0.030154809965898734\n",
      "59 Train Loss 0.0054353573 Test MSE 0.0037577710580522423 Test RE 0.029300377711414714\n",
      "60 Train Loss 0.0049027083 Test MSE 0.0033205035410353314 Test RE 0.02754292339020651\n",
      "61 Train Loss 0.0043943333 Test MSE 0.0028887465806447022 Test RE 0.025689921812559805\n",
      "62 Train Loss 0.004132805 Test MSE 0.0025944240326634897 Test RE 0.024346051681638288\n",
      "63 Train Loss 0.0037272181 Test MSE 0.00240839298718975 Test RE 0.023456960539310866\n",
      "64 Train Loss 0.0033541846 Test MSE 0.0020623630646336706 Test RE 0.021706540924431247\n",
      "65 Train Loss 0.0030415093 Test MSE 0.0019639769205130136 Test RE 0.021182452940271684\n",
      "66 Train Loss 0.0027620266 Test MSE 0.0019309912087452656 Test RE 0.021003816168584516\n",
      "67 Train Loss 0.002499471 Test MSE 0.0014984691650708768 Test RE 0.01850256615119594\n",
      "68 Train Loss 0.0023328413 Test MSE 0.001281051578764347 Test RE 0.017107689853094084\n",
      "69 Train Loss 0.0021812841 Test MSE 0.0011798679428943724 Test RE 0.016418170484376177\n",
      "70 Train Loss 0.0020658302 Test MSE 0.0012267682921587825 Test RE 0.016741305880925823\n",
      "71 Train Loss 0.0018688354 Test MSE 0.0011502182549263569 Test RE 0.016210566355518024\n",
      "72 Train Loss 0.0017085061 Test MSE 0.000991746234207365 Test RE 0.015052489755931157\n",
      "73 Train Loss 0.0016274254 Test MSE 0.0009073937800911201 Test RE 0.014398125650417632\n",
      "74 Train Loss 0.0015614361 Test MSE 0.000865236522819843 Test RE 0.014059681480690596\n",
      "75 Train Loss 0.0014415333 Test MSE 0.0007574898146075067 Test RE 0.013155169829370957\n",
      "76 Train Loss 0.0013780191 Test MSE 0.0006768285860131217 Test RE 0.012435046303291545\n",
      "77 Train Loss 0.0013133676 Test MSE 0.0006529618597929129 Test RE 0.012213832715960797\n",
      "78 Train Loss 0.0012257777 Test MSE 0.000645016606877374 Test RE 0.012139296201658576\n",
      "79 Train Loss 0.0011838106 Test MSE 0.0006539570717658729 Test RE 0.012223137030028192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.0011345258 Test MSE 0.0006353240372424466 Test RE 0.012047743252769152\n",
      "81 Train Loss 0.0010595149 Test MSE 0.0005837500988057115 Test RE 0.01154839270781612\n",
      "82 Train Loss 0.0010173583 Test MSE 0.0005396837426871839 Test RE 0.011103955895579078\n",
      "83 Train Loss 0.00097352127 Test MSE 0.0005257010519771489 Test RE 0.010959165445386356\n",
      "84 Train Loss 0.00093380525 Test MSE 0.0005089076429106181 Test RE 0.010782700611499897\n",
      "85 Train Loss 0.00089117175 Test MSE 0.00048078885712335445 Test RE 0.010480578547593503\n",
      "86 Train Loss 0.0008679053 Test MSE 0.00047657174159629686 Test RE 0.010434513466547566\n",
      "87 Train Loss 0.0008428548 Test MSE 0.00045620512904419157 Test RE 0.010209116085760955\n",
      "88 Train Loss 0.00082324597 Test MSE 0.0004412444122233237 Test RE 0.010040322657932477\n",
      "89 Train Loss 0.000802782 Test MSE 0.00045465063701554575 Test RE 0.010191707763650568\n",
      "90 Train Loss 0.00077531085 Test MSE 0.0004266754078421081 Test RE 0.00987317571746179\n",
      "91 Train Loss 0.00073491846 Test MSE 0.0004350183399059046 Test RE 0.009969235232067837\n",
      "92 Train Loss 0.0007132299 Test MSE 0.00043945303207377476 Test RE 0.010019920895954076\n",
      "93 Train Loss 0.0007004447 Test MSE 0.0004575969147127223 Test RE 0.010224677156824511\n",
      "94 Train Loss 0.0006566704 Test MSE 0.00043682753030662184 Test RE 0.009989944164620146\n",
      "95 Train Loss 0.00063410273 Test MSE 0.000410737555706867 Test RE 0.009687021584539641\n",
      "96 Train Loss 0.00061536866 Test MSE 0.0004031061300248482 Test RE 0.009596608139817104\n",
      "97 Train Loss 0.00057953293 Test MSE 0.0003755567892089005 Test RE 0.00926287639905594\n",
      "98 Train Loss 0.00054947013 Test MSE 0.0003401702503303443 Test RE 0.008815688276425418\n",
      "99 Train Loss 0.000536934 Test MSE 0.00032800427060063984 Test RE 0.008656609150849164\n",
      "Training time: 67.78\n",
      "3\n",
      "KG_rowdy_tune15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.689175 Test MSE 8.620934617762291 Test RE 1.4034121624732194\n",
      "1 Train Loss 56.29001 Test MSE 8.616889002211776 Test RE 1.403082828556572\n",
      "2 Train Loss 56.041016 Test MSE 8.44314551340714 Test RE 1.3888655236172525\n",
      "3 Train Loss 53.4922 Test MSE 7.6806321563824955 Test RE 1.3246664694305847\n",
      "4 Train Loss 44.4431 Test MSE 8.551184717226588 Test RE 1.397723297814388\n",
      "5 Train Loss 43.083908 Test MSE 8.5418461190288 Test RE 1.396959874831157\n",
      "6 Train Loss 42.573982 Test MSE 8.329965146557713 Test RE 1.379525245125848\n",
      "7 Train Loss 42.037308 Test MSE 8.299734547757318 Test RE 1.3770197256196812\n",
      "8 Train Loss 41.481537 Test MSE 8.40886949442214 Test RE 1.386043518849698\n",
      "9 Train Loss 40.591972 Test MSE 8.337084162894591 Test RE 1.380114609257991\n",
      "10 Train Loss 39.917873 Test MSE 8.460630391339407 Test RE 1.3903028780145044\n",
      "11 Train Loss 38.861217 Test MSE 8.278659459207885 Test RE 1.3752703167274067\n",
      "12 Train Loss 37.082787 Test MSE 8.334487053155549 Test RE 1.3798996307231806\n",
      "13 Train Loss 33.77597 Test MSE 8.330545023490041 Test RE 1.3795732609897644\n",
      "14 Train Loss 30.883276 Test MSE 9.174119878870144 Test RE 1.4477389728309167\n",
      "15 Train Loss 28.365334 Test MSE 10.02807137063885 Test RE 1.513619689118457\n",
      "16 Train Loss 26.263012 Test MSE 10.433635885809963 Test RE 1.5439239299392606\n",
      "17 Train Loss 23.978493 Test MSE 10.23671228208425 Test RE 1.5292845774268728\n",
      "18 Train Loss 21.866245 Test MSE 9.880108945682414 Test RE 1.5024115963028823\n",
      "19 Train Loss 20.166248 Test MSE 9.885795576654333 Test RE 1.5028439008129728\n",
      "20 Train Loss 18.779741 Test MSE 9.737218815974435 Test RE 1.491507786961713\n",
      "21 Train Loss 17.31868 Test MSE 9.745446280434432 Test RE 1.4921377787730559\n",
      "22 Train Loss 15.789179 Test MSE 9.823160791837951 Test RE 1.4980754491301966\n",
      "23 Train Loss 14.542145 Test MSE 9.5327508681162 Test RE 1.4757649173961174\n",
      "24 Train Loss 13.586683 Test MSE 9.594027347947286 Test RE 1.4805004247666367\n",
      "25 Train Loss 12.497899 Test MSE 9.783091748791774 Test RE 1.4950169739289965\n",
      "26 Train Loss 11.556572 Test MSE 9.635135859893314 Test RE 1.48366886029275\n",
      "27 Train Loss 10.030606 Test MSE 9.80111694905301 Test RE 1.4963936133212254\n",
      "28 Train Loss 8.871814 Test MSE 9.365642036092536 Test RE 1.4627726702285573\n",
      "29 Train Loss 7.4943037 Test MSE 9.200753504267569 Test RE 1.4498389341056936\n",
      "30 Train Loss 6.158598 Test MSE 8.862418714314241 Test RE 1.4229321523117462\n",
      "31 Train Loss 5.445954 Test MSE 8.669965166291147 Test RE 1.407397374699773\n",
      "32 Train Loss 4.886434 Test MSE 8.4829174139866 Test RE 1.3921328440726275\n",
      "33 Train Loss 4.4435368 Test MSE 8.46137463324011 Test RE 1.3903640258755225\n",
      "34 Train Loss 3.937529 Test MSE 8.300558518405579 Test RE 1.3770880769428717\n",
      "35 Train Loss 3.6037397 Test MSE 8.042089667631455 Test RE 1.355478133080112\n",
      "36 Train Loss 3.2949283 Test MSE 7.860825427265849 Test RE 1.340115209124396\n",
      "37 Train Loss 3.0554836 Test MSE 7.716293303221965 Test RE 1.32773811891682\n",
      "38 Train Loss 2.8295994 Test MSE 7.415202066140866 Test RE 1.3015760701101091\n",
      "39 Train Loss 2.5082836 Test MSE 7.174327451190393 Test RE 1.2802614178566203\n",
      "40 Train Loss 2.173331 Test MSE 6.808500004209957 Test RE 1.247193334987321\n",
      "41 Train Loss 1.9886423 Test MSE 6.782854837265596 Test RE 1.2448422549675378\n",
      "42 Train Loss 1.8563696 Test MSE 6.6812677568694205 Test RE 1.23548506162487\n",
      "43 Train Loss 1.7723815 Test MSE 6.548837761606092 Test RE 1.223179449796867\n",
      "44 Train Loss 1.6926756 Test MSE 6.4115996310634875 Test RE 1.2102950523248086\n",
      "45 Train Loss 1.5896814 Test MSE 6.371753109270651 Test RE 1.2065283472148067\n",
      "46 Train Loss 1.512082 Test MSE 6.30392797545083 Test RE 1.2000896259591582\n",
      "47 Train Loss 1.4340982 Test MSE 6.164964759003436 Test RE 1.186788582304243\n",
      "48 Train Loss 1.3597548 Test MSE 6.059266542547654 Test RE 1.1765708622200743\n",
      "49 Train Loss 1.3033667 Test MSE 6.032494470466411 Test RE 1.173968722951121\n",
      "50 Train Loss 1.2559383 Test MSE 6.038175216702454 Test RE 1.1745213508181505\n",
      "51 Train Loss 1.2120906 Test MSE 6.043511574160825 Test RE 1.1750402395025275\n",
      "52 Train Loss 1.1728185 Test MSE 6.017169482441315 Test RE 1.172476595822368\n",
      "53 Train Loss 1.1320863 Test MSE 6.041162846874021 Test RE 1.174811885735337\n",
      "54 Train Loss 1.1011966 Test MSE 6.041140753879523 Test RE 1.1748097375449211\n",
      "55 Train Loss 1.0596054 Test MSE 6.08501886852029 Test RE 1.1790684673912382\n",
      "56 Train Loss 1.0357031 Test MSE 6.084665532646709 Test RE 1.179034234692552\n",
      "57 Train Loss 1.0130379 Test MSE 6.0702129222346946 Test RE 1.177633150849592\n",
      "58 Train Loss 0.99668634 Test MSE 6.086730948576638 Test RE 1.1792343269949\n",
      "59 Train Loss 0.9765483 Test MSE 6.08662674836481 Test RE 1.1792242331535914\n",
      "60 Train Loss 0.95976627 Test MSE 6.086150092435393 Test RE 1.1791780585439922\n",
      "61 Train Loss 0.9456254 Test MSE 6.103483340190878 Test RE 1.1808560038250766\n",
      "62 Train Loss 0.93062234 Test MSE 6.124887958434119 Test RE 1.182924793817797\n",
      "63 Train Loss 0.9144579 Test MSE 6.140010467583028 Test RE 1.1843842297107567\n",
      "64 Train Loss 0.9057701 Test MSE 6.176278026865603 Test RE 1.187877015377792\n",
      "65 Train Loss 0.8928348 Test MSE 6.160360555087961 Test RE 1.1863453326306712\n",
      "66 Train Loss 0.88142204 Test MSE 6.203387610335124 Test RE 1.190481139677776\n",
      "67 Train Loss 0.8693444 Test MSE 6.228865190886559 Test RE 1.1929233134199868\n",
      "68 Train Loss 0.8576493 Test MSE 6.278931240469312 Test RE 1.1977079268527209\n",
      "69 Train Loss 0.8423405 Test MSE 6.296708892826978 Test RE 1.1994022745225865\n",
      "70 Train Loss 0.8244744 Test MSE 6.305823458021721 Test RE 1.2002700355394715\n",
      "71 Train Loss 0.8075463 Test MSE 6.381450083663796 Test RE 1.2074460873035684\n",
      "72 Train Loss 0.7962878 Test MSE 6.378108994479305 Test RE 1.2071299590579718\n",
      "73 Train Loss 0.7857951 Test MSE 6.4024896116272725 Test RE 1.209434913559286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 0.7760434 Test MSE 6.411812136913651 Test RE 1.2103151091485937\n",
      "75 Train Loss 0.7690642 Test MSE 6.412374506581597 Test RE 1.2103681853747532\n",
      "76 Train Loss 0.76317674 Test MSE 6.408989695907138 Test RE 1.2100486931233694\n",
      "77 Train Loss 0.75859284 Test MSE 6.420847019145954 Test RE 1.211167536263425\n",
      "78 Train Loss 0.75273585 Test MSE 6.4229041065225445 Test RE 1.2113615354290896\n",
      "79 Train Loss 0.7463383 Test MSE 6.421439482865436 Test RE 1.2112234133361168\n",
      "80 Train Loss 0.7396691 Test MSE 6.417325658623914 Test RE 1.2108353727304024\n",
      "81 Train Loss 0.73379964 Test MSE 6.426068075911441 Test RE 1.2116598614560956\n",
      "82 Train Loss 0.72998214 Test MSE 6.440073465714555 Test RE 1.2129795278739253\n",
      "83 Train Loss 0.7256749 Test MSE 6.42322604993825 Test RE 1.2113918943584019\n",
      "84 Train Loss 0.7217426 Test MSE 6.416050466077135 Test RE 1.210715063661076\n",
      "85 Train Loss 0.71772075 Test MSE 6.437678870551134 Test RE 1.2127539974526984\n",
      "86 Train Loss 0.7115586 Test MSE 6.433873185460865 Test RE 1.2123954798718712\n",
      "87 Train Loss 0.7086917 Test MSE 6.431836839134168 Test RE 1.212203600704187\n",
      "88 Train Loss 0.706208 Test MSE 6.446163165998821 Test RE 1.2135528859604496\n",
      "89 Train Loss 0.7027155 Test MSE 6.43506812393716 Test RE 1.21250806141527\n",
      "90 Train Loss 0.69970924 Test MSE 6.4463847573450925 Test RE 1.2135737441438272\n",
      "91 Train Loss 0.6966437 Test MSE 6.45173436459436 Test RE 1.2140771888502058\n",
      "92 Train Loss 0.69203293 Test MSE 6.470082898912313 Test RE 1.2158023622486809\n",
      "93 Train Loss 0.68762577 Test MSE 6.494997705218816 Test RE 1.2181410011394302\n",
      "94 Train Loss 0.6852685 Test MSE 6.495722253631003 Test RE 1.2182089440052315\n",
      "95 Train Loss 0.68227446 Test MSE 6.51389257056154 Test RE 1.2199115864337966\n",
      "96 Train Loss 0.6795908 Test MSE 6.532942969250585 Test RE 1.2216941484712283\n",
      "97 Train Loss 0.6765476 Test MSE 6.5294269135494 Test RE 1.221365343917031\n",
      "98 Train Loss 0.6735365 Test MSE 6.5191760354192665 Test RE 1.2204062256596537\n",
      "99 Train Loss 0.67061174 Test MSE 6.523172387082 Test RE 1.2207802319149583\n",
      "Training time: 68.05\n",
      "4\n",
      "KG_rowdy_tune15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.27333 Test MSE 8.41040586374065 Test RE 1.3861701338173018\n",
      "1 Train Loss 55.782555 Test MSE 8.144730655017625 Test RE 1.3641006745843303\n",
      "2 Train Loss 47.888603 Test MSE 8.72376133533965 Test RE 1.4117569944652184\n",
      "3 Train Loss 44.17816 Test MSE 8.155532654815435 Test RE 1.365004948370083\n",
      "4 Train Loss 43.35226 Test MSE 8.256222898276032 Test RE 1.3734054452916495\n",
      "5 Train Loss 42.125973 Test MSE 8.322266706140647 Test RE 1.378887628544596\n",
      "6 Train Loss 37.808243 Test MSE 7.685483167895357 Test RE 1.325084726537435\n",
      "7 Train Loss 32.398716 Test MSE 5.936120621688436 Test RE 1.1645534300412268\n",
      "8 Train Loss 23.89997 Test MSE 4.560896891589785 Test RE 1.020782432720874\n",
      "9 Train Loss 17.989414 Test MSE 4.653118765332986 Test RE 1.0310509554770917\n",
      "10 Train Loss 13.519306 Test MSE 4.451916434729191 Test RE 1.0085131425896583\n",
      "11 Train Loss 10.897229 Test MSE 3.9660218026177945 Test RE 0.9518874674844685\n",
      "12 Train Loss 8.769041 Test MSE 3.5404106634647925 Test RE 0.89936271779574\n",
      "13 Train Loss 6.9747114 Test MSE 3.0748223743924092 Test RE 0.8381429119239392\n",
      "14 Train Loss 4.551496 Test MSE 2.597002169127711 Test RE 0.7702721867032702\n",
      "15 Train Loss 3.1239831 Test MSE 1.9839136765028014 Test RE 0.6732392785797563\n",
      "16 Train Loss 2.342464 Test MSE 1.6713849672540582 Test RE 0.6179399966029787\n",
      "17 Train Loss 1.7565205 Test MSE 1.2402517559384814 Test RE 0.5323079906630607\n",
      "18 Train Loss 1.2608179 Test MSE 0.7719947300886851 Test RE 0.4199670601564719\n",
      "19 Train Loss 0.8699196 Test MSE 0.5784004128159522 Test RE 0.3635150177551001\n",
      "20 Train Loss 0.6479856 Test MSE 0.49525683060313347 Test RE 0.3363746797604173\n",
      "21 Train Loss 0.47120258 Test MSE 0.2909908804469458 Test RE 0.2578384902622729\n",
      "22 Train Loss 0.32717136 Test MSE 0.14474991969983447 Test RE 0.1818516416719721\n",
      "23 Train Loss 0.21231642 Test MSE 0.055870185691783154 Test RE 0.11297910179143658\n",
      "24 Train Loss 0.16710313 Test MSE 0.03590686688847048 Test RE 0.09057259608921633\n",
      "25 Train Loss 0.13268606 Test MSE 0.033508226900687596 Test RE 0.08749511052258455\n",
      "26 Train Loss 0.10773144 Test MSE 0.03449654282868772 Test RE 0.08877605597638429\n",
      "27 Train Loss 0.08927784 Test MSE 0.02632139053556277 Test RE 0.07754654887026916\n",
      "28 Train Loss 0.07682116 Test MSE 0.02116854364704971 Test RE 0.0695430206291188\n",
      "29 Train Loss 0.0654082 Test MSE 0.015673516862463495 Test RE 0.05983995909936209\n",
      "30 Train Loss 0.056503113 Test MSE 0.016447548422788484 Test RE 0.06129974206502705\n",
      "31 Train Loss 0.046408832 Test MSE 0.013682672866466879 Test RE 0.055910520086242546\n",
      "32 Train Loss 0.040026374 Test MSE 0.010650261376981158 Test RE 0.04932739643418979\n",
      "33 Train Loss 0.03630294 Test MSE 0.01002338394614812 Test RE 0.04785366923884622\n",
      "34 Train Loss 0.032534555 Test MSE 0.009996820123594919 Test RE 0.04779021663062311\n",
      "35 Train Loss 0.028977094 Test MSE 0.00859161950668812 Test RE 0.04430426927254791\n",
      "36 Train Loss 0.025409404 Test MSE 0.009147493723832008 Test RE 0.045715041712328756\n",
      "37 Train Loss 0.02297844 Test MSE 0.008997715125754082 Test RE 0.045339234130983244\n",
      "38 Train Loss 0.020112406 Test MSE 0.007390888419014744 Test RE 0.04109191519487939\n",
      "39 Train Loss 0.01714612 Test MSE 0.005806716669362292 Test RE 0.036422804114536515\n",
      "40 Train Loss 0.014560778 Test MSE 0.005983020228509504 Test RE 0.03697160427063638\n",
      "41 Train Loss 0.013026947 Test MSE 0.006531868716566283 Test RE 0.03863018463946599\n",
      "42 Train Loss 0.011758599 Test MSE 0.006044646771239325 Test RE 0.037161524660954834\n",
      "43 Train Loss 0.010461813 Test MSE 0.006222596194025679 Test RE 0.03770455936703571\n",
      "44 Train Loss 0.009486157 Test MSE 0.0052413278376853495 Test RE 0.03460419278025153\n",
      "45 Train Loss 0.008870008 Test MSE 0.004637987442429278 Test RE 0.03255163779924995\n",
      "46 Train Loss 0.008063682 Test MSE 0.004123044540927825 Test RE 0.03069142643922343\n",
      "47 Train Loss 0.007018629 Test MSE 0.0035221453738474577 Test RE 0.02836688831970581\n",
      "48 Train Loss 0.006290218 Test MSE 0.0032511659230705136 Test RE 0.027253835321296282\n",
      "49 Train Loss 0.0057132547 Test MSE 0.0030826791926712865 Test RE 0.026538246628147983\n",
      "50 Train Loss 0.0051737707 Test MSE 0.0023505124222362697 Test RE 0.023173377456999225\n",
      "51 Train Loss 0.0048576677 Test MSE 0.0018465310727955977 Test RE 0.02053933462183944\n",
      "52 Train Loss 0.0046603326 Test MSE 0.001691638441983424 Test RE 0.019659018582109236\n",
      "53 Train Loss 0.004445289 Test MSE 0.0014204943335407645 Test RE 0.018014732309525598\n",
      "54 Train Loss 0.0041367495 Test MSE 0.0014004989871089168 Test RE 0.017887492299715358\n",
      "55 Train Loss 0.003835012 Test MSE 0.001189453481883439 Test RE 0.016484728213857366\n",
      "56 Train Loss 0.0034937905 Test MSE 0.0012578760060715753 Test RE 0.016952235494342147\n",
      "57 Train Loss 0.003167178 Test MSE 0.001228541858778004 Test RE 0.016753403152137757\n",
      "58 Train Loss 0.0029966105 Test MSE 0.0011942601633893597 Test RE 0.016518002717694096\n",
      "59 Train Loss 0.0028847293 Test MSE 0.0011494245354274218 Test RE 0.016204972259352027\n",
      "60 Train Loss 0.0027244762 Test MSE 0.0012332266425743278 Test RE 0.016785315533016047\n",
      "61 Train Loss 0.0025584085 Test MSE 0.001131071207529348 Test RE 0.016075075962713212\n",
      "62 Train Loss 0.002439883 Test MSE 0.0013291926525219504 Test RE 0.017426173201661205\n",
      "63 Train Loss 0.0023737985 Test MSE 0.0013289723830000825 Test RE 0.01742472923721064\n",
      "64 Train Loss 0.0022610612 Test MSE 0.0013596847679081892 Test RE 0.017624920894733567\n",
      "65 Train Loss 0.0021216164 Test MSE 0.001250868716065121 Test RE 0.016904951370970218\n",
      "66 Train Loss 0.0019755075 Test MSE 0.001107514743908003 Test RE 0.015906799923920006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Train Loss 0.0018945558 Test MSE 0.0009936316953408385 Test RE 0.015066791503256275\n",
      "68 Train Loss 0.00184634 Test MSE 0.0009372841391014684 Test RE 0.014633347778003366\n",
      "69 Train Loss 0.0018089473 Test MSE 0.0008991601937358091 Test RE 0.014332653325309067\n",
      "70 Train Loss 0.0017353144 Test MSE 0.0009495442366848941 Test RE 0.014728742222195761\n",
      "71 Train Loss 0.0016867375 Test MSE 0.0008716916162643856 Test RE 0.014112030122731316\n",
      "72 Train Loss 0.0016316122 Test MSE 0.0008409208534781568 Test RE 0.013860714607720008\n",
      "73 Train Loss 0.0015710032 Test MSE 0.0008055298576455514 Test RE 0.0135659084395374\n",
      "74 Train Loss 0.0015215899 Test MSE 0.0007078674402239912 Test RE 0.012716981179468359\n",
      "75 Train Loss 0.0014557971 Test MSE 0.0006544535569280721 Test RE 0.01222777606143122\n",
      "76 Train Loss 0.0014046733 Test MSE 0.000678904190257988 Test RE 0.012454098747214768\n",
      "77 Train Loss 0.0013455106 Test MSE 0.0006140295569608477 Test RE 0.011844117269296028\n",
      "78 Train Loss 0.0013164945 Test MSE 0.0006027550559531682 Test RE 0.011734875632514316\n",
      "79 Train Loss 0.0012564644 Test MSE 0.0005154480927486812 Test RE 0.010851768708942661\n",
      "80 Train Loss 0.001214887 Test MSE 0.0005347374278353969 Test RE 0.011052953721193717\n",
      "81 Train Loss 0.0011795962 Test MSE 0.0005345715986560441 Test RE 0.011051239754419124\n",
      "82 Train Loss 0.0011506481 Test MSE 0.0005379466734208988 Test RE 0.011086071452551624\n",
      "83 Train Loss 0.001094876 Test MSE 0.0004997203710974191 Test RE 0.010684927683972287\n",
      "84 Train Loss 0.0010529275 Test MSE 0.0004376941546057669 Test RE 0.009999848804421403\n",
      "85 Train Loss 0.0010234792 Test MSE 0.0004645172336461918 Test RE 0.010301701834094559\n",
      "86 Train Loss 0.0009885294 Test MSE 0.0004478126067611998 Test RE 0.010114774804782943\n",
      "87 Train Loss 0.00094503356 Test MSE 0.00044534137154410747 Test RE 0.010086827212818283\n",
      "88 Train Loss 0.0009162247 Test MSE 0.00044767744185043087 Test RE 0.010113248199912083\n",
      "89 Train Loss 0.00089802686 Test MSE 0.0004490027964255768 Test RE 0.010128207334287372\n",
      "90 Train Loss 0.0008747925 Test MSE 0.00045014334694381576 Test RE 0.01014106293967773\n",
      "91 Train Loss 0.0008363824 Test MSE 0.0004665751091294666 Test RE 0.010324495597878486\n",
      "92 Train Loss 0.000807605 Test MSE 0.0004820213124780271 Test RE 0.010494002920667244\n",
      "93 Train Loss 0.0007929141 Test MSE 0.0004530491931473215 Test RE 0.010173742490479318\n",
      "94 Train Loss 0.00076445285 Test MSE 0.000408392150124844 Test RE 0.009659324431929324\n",
      "95 Train Loss 0.00074904383 Test MSE 0.00041142130824145285 Test RE 0.009695081197331866\n",
      "96 Train Loss 0.0007297802 Test MSE 0.0004198030824425733 Test RE 0.009793340889783932\n",
      "97 Train Loss 0.0007137498 Test MSE 0.00040650072102938796 Test RE 0.009636930355243597\n",
      "98 Train Loss 0.00069655373 Test MSE 0.00041322984712125377 Test RE 0.009716366804226578\n",
      "99 Train Loss 0.0006778499 Test MSE 0.0004070791350904532 Test RE 0.009643784161731884\n",
      "Training time: 68.04\n",
      "5\n",
      "KG_rowdy_tune15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.912975 Test MSE 8.581870409245406 Test RE 1.400228897883354\n",
      "1 Train Loss 57.658287 Test MSE 8.606281178378037 Test RE 1.4022189298270258\n",
      "2 Train Loss 53.187706 Test MSE 9.800838848586556 Test RE 1.4963723835615943\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.70\n",
      "0\n",
      "KG_rowdy_tune16\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.416687 Test MSE 7.568882156004075 Test RE 1.3149944868630434\n",
      "1 Train Loss 37.72887 Test MSE 7.519968458139024 Test RE 1.3107385414393\n",
      "2 Train Loss 25.451767 Test MSE 6.302007318522008 Test RE 1.1999067926481102\n",
      "3 Train Loss 23.221985 Test MSE 6.039950385533762 Test RE 1.1746939874509519\n",
      "4 Train Loss 20.776573 Test MSE 6.1011775640728665 Test RE 1.1806329306533034\n",
      "5 Train Loss 16.373096 Test MSE 6.041924118882306 Test RE 1.174885904864834\n",
      "6 Train Loss 12.367922 Test MSE 6.002661545332202 Test RE 1.1710622694988333\n",
      "7 Train Loss 10.160297 Test MSE 5.859414736395532 Test RE 1.1570048508338977\n",
      "8 Train Loss 8.600634 Test MSE 5.709037024820203 Test RE 1.1420614967387166\n",
      "9 Train Loss 7.406776 Test MSE 5.5763278720008955 Test RE 1.1287095791351776\n",
      "10 Train Loss 6.010994 Test MSE 5.267550698505811 Test RE 1.0970146374627312\n",
      "11 Train Loss 4.7930717 Test MSE 4.841076367341345 Test RE 1.05166889022475\n",
      "12 Train Loss 3.8595905 Test MSE 4.533758729579958 Test RE 1.0177409815582543\n",
      "13 Train Loss 3.2867656 Test MSE 4.186170029022035 Test RE 0.9779496425709482\n",
      "14 Train Loss 2.788935 Test MSE 3.8137701642253505 Test RE 0.9334376599697088\n",
      "15 Train Loss 2.322905 Test MSE 3.278282856803978 Test RE 0.8654286563606972\n",
      "16 Train Loss 1.9856328 Test MSE 2.665859236829338 Test RE 0.7804169031679862\n",
      "17 Train Loss 1.628341 Test MSE 2.198063617308941 Test RE 0.7086441220928842\n",
      "18 Train Loss 1.433057 Test MSE 1.869517881707737 Test RE 0.6535410507366388\n",
      "19 Train Loss 1.2006885 Test MSE 1.516718941263277 Test RE 0.588654699422384\n",
      "20 Train Loss 1.0541558 Test MSE 1.372217126030869 Test RE 0.5599116165040837\n",
      "21 Train Loss 0.8563786 Test MSE 1.0560442546987916 Test RE 0.49118955078781035\n",
      "22 Train Loss 0.67695373 Test MSE 0.7848031619197883 Test RE 0.423436637562616\n",
      "23 Train Loss 0.4866189 Test MSE 0.5342384215557962 Test RE 0.3493619633371897\n",
      "24 Train Loss 0.37988496 Test MSE 0.42648555754814155 Test RE 0.3121477614138435\n",
      "25 Train Loss 0.25334364 Test MSE 0.30656162239378654 Test RE 0.2646469865442161\n",
      "26 Train Loss 0.20257667 Test MSE 0.18991848324895214 Test RE 0.20830115443794048\n",
      "27 Train Loss 0.14513043 Test MSE 0.08042817154734949 Test RE 0.13555394399420204\n",
      "28 Train Loss 0.105298705 Test MSE 0.04311106598124012 Test RE 0.09924358432209347\n",
      "29 Train Loss 0.077988654 Test MSE 0.026946194438827 Test RE 0.07846153131597296\n",
      "30 Train Loss 0.05659862 Test MSE 0.024389577677881552 Test RE 0.07464662907029687\n",
      "31 Train Loss 0.045034565 Test MSE 0.017413390047296078 Test RE 0.0630739056734513\n",
      "32 Train Loss 0.038507078 Test MSE 0.016253469681999217 Test RE 0.06093700469208769\n",
      "33 Train Loss 0.033742838 Test MSE 0.01210180344658576 Test RE 0.052581516544214044\n",
      "34 Train Loss 0.029960696 Test MSE 0.010972667248032059 Test RE 0.050068452074012615\n",
      "35 Train Loss 0.025833221 Test MSE 0.010956138718713256 Test RE 0.05003072789358121\n",
      "36 Train Loss 0.022975173 Test MSE 0.011667104501403205 Test RE 0.05162851151151888\n",
      "37 Train Loss 0.020469083 Test MSE 0.010137144585253893 Test RE 0.04812446125609464\n",
      "38 Train Loss 0.017868355 Test MSE 0.007910016167707964 Test RE 0.04251055215127561\n",
      "39 Train Loss 0.015333462 Test MSE 0.006306430857279111 Test RE 0.037957699173538265\n",
      "40 Train Loss 0.013589149 Test MSE 0.004974413562316933 Test RE 0.03371157201087334\n",
      "41 Train Loss 0.012601555 Test MSE 0.004434588722247454 Test RE 0.03182986043582156\n",
      "42 Train Loss 0.011617851 Test MSE 0.004573497209567851 Test RE 0.03232453376343355\n",
      "43 Train Loss 0.0103916535 Test MSE 0.003728194594279207 Test RE 0.02918484200013571\n",
      "44 Train Loss 0.009604219 Test MSE 0.003986765896638392 Test RE 0.030179943859829327\n",
      "45 Train Loss 0.008843087 Test MSE 0.003725174326596018 Test RE 0.029173018060658924\n",
      "46 Train Loss 0.00789777 Test MSE 0.0033968316041683177 Test RE 0.02785768793373806\n",
      "47 Train Loss 0.007293848 Test MSE 0.0031958094075340993 Test RE 0.027020818214290105\n",
      "48 Train Loss 0.006772814 Test MSE 0.0030107964856257515 Test RE 0.026227008710925575\n",
      "49 Train Loss 0.006247881 Test MSE 0.0026722120201859803 Test RE 0.02470833704468798\n",
      "50 Train Loss 0.0056042597 Test MSE 0.002524660952475027 Test RE 0.024016493101526388\n",
      "51 Train Loss 0.0051132725 Test MSE 0.0025398145035603063 Test RE 0.0240884613164113\n",
      "52 Train Loss 0.004801766 Test MSE 0.0024446922156610585 Test RE 0.023633070749694084\n",
      "53 Train Loss 0.0044990755 Test MSE 0.002438944533046528 Test RE 0.023605272705591974\n",
      "54 Train Loss 0.004228473 Test MSE 0.002383714132330742 Test RE 0.023336469084702518\n",
      "55 Train Loss 0.0039813607 Test MSE 0.002257414114462693 Test RE 0.02270981928736841\n",
      "56 Train Loss 0.003779267 Test MSE 0.0021961158314317926 Test RE 0.022399363707941725\n",
      "57 Train Loss 0.0035763937 Test MSE 0.0020104716935627786 Test RE 0.021431720740539117\n",
      "58 Train Loss 0.0034349563 Test MSE 0.0019277819028536774 Test RE 0.020986354747257685\n",
      "59 Train Loss 0.0032526362 Test MSE 0.0018288402272425965 Test RE 0.020440708421627516\n",
      "60 Train Loss 0.0030350247 Test MSE 0.0016395102086967609 Test RE 0.019353749825943352\n",
      "61 Train Loss 0.002818193 Test MSE 0.001610912438586252 Test RE 0.019184214768475753\n",
      "62 Train Loss 0.002669558 Test MSE 0.0015650340221696499 Test RE 0.01890906051908377\n",
      "63 Train Loss 0.0025726238 Test MSE 0.0015205793519516867 Test RE 0.018638570670982287\n",
      "64 Train Loss 0.0024284858 Test MSE 0.0015911606449496218 Test RE 0.019066240838329633\n",
      "65 Train Loss 0.0023091985 Test MSE 0.0016463673938315645 Test RE 0.019394180732820628\n",
      "66 Train Loss 0.0021704822 Test MSE 0.0016425151100445538 Test RE 0.01937147752468794\n",
      "67 Train Loss 0.0020648912 Test MSE 0.0015322033386000625 Test RE 0.018709675812757346\n",
      "68 Train Loss 0.0019697424 Test MSE 0.0014238892422833097 Test RE 0.01803624660670551\n",
      "69 Train Loss 0.0018280738 Test MSE 0.0013828206614302115 Test RE 0.017774237963190834\n",
      "70 Train Loss 0.0017308348 Test MSE 0.0012912781085208198 Test RE 0.017175838759628356\n",
      "71 Train Loss 0.0016524212 Test MSE 0.0013981074295565232 Test RE 0.017872213014921937\n",
      "72 Train Loss 0.0015341849 Test MSE 0.0013395131502195476 Test RE 0.017493695025672662\n",
      "73 Train Loss 0.0014446181 Test MSE 0.0013377231827506717 Test RE 0.01748200286244331\n",
      "74 Train Loss 0.0013641901 Test MSE 0.0014028452690712401 Test RE 0.01790246965340346\n",
      "75 Train Loss 0.0012772601 Test MSE 0.0013041216049896594 Test RE 0.017261045810942958\n",
      "76 Train Loss 0.0012244015 Test MSE 0.0012466796049157834 Test RE 0.016876620615926433\n",
      "77 Train Loss 0.0011906978 Test MSE 0.0012235996104217079 Test RE 0.01671967091943582\n",
      "78 Train Loss 0.0011205146 Test MSE 0.001109848907702975 Test RE 0.01592355344085754\n",
      "79 Train Loss 0.0010974694 Test MSE 0.0009918240739777387 Test RE 0.015053080461151917\n",
      "80 Train Loss 0.0010729331 Test MSE 0.0009579597498808732 Test RE 0.014793866361600115\n",
      "81 Train Loss 0.0010377959 Test MSE 0.0009544450109646207 Test RE 0.014766702193598193\n",
      "82 Train Loss 0.0009981825 Test MSE 0.0008652478984648951 Test RE 0.014059773904794385\n",
      "83 Train Loss 0.00097217073 Test MSE 0.0008568981111696044 Test RE 0.013991769856664824\n",
      "84 Train Loss 0.0009491473 Test MSE 0.000829322474683264 Test RE 0.013764795949294733\n",
      "85 Train Loss 0.00091883505 Test MSE 0.0007590908930791559 Test RE 0.013169065290939131\n",
      "86 Train Loss 0.00088481425 Test MSE 0.0007264805739414286 Test RE 0.01288309066523822\n",
      "87 Train Loss 0.0008156174 Test MSE 0.0006542180436569811 Test RE 0.012225575704631382\n",
      "88 Train Loss 0.0007890915 Test MSE 0.0006173705832443909 Test RE 0.01187629635903738\n",
      "89 Train Loss 0.0007643777 Test MSE 0.0005866591048586299 Test RE 0.01157713154279175\n",
      "90 Train Loss 0.0007380384 Test MSE 0.0005925351328557753 Test RE 0.011634965857341\n",
      "91 Train Loss 0.0007156172 Test MSE 0.0006163418928375106 Test RE 0.011866397826575023\n",
      "92 Train Loss 0.0006874887 Test MSE 0.0005651890331027387 Test RE 0.011363311796551685\n",
      "93 Train Loss 0.00066305685 Test MSE 0.0005429395265821833 Test RE 0.011137399297277724\n",
      "94 Train Loss 0.00064452225 Test MSE 0.000547796871599814 Test RE 0.011187108086919459\n",
      "95 Train Loss 0.0006259956 Test MSE 0.0004980785727437453 Test RE 0.010667360930550308\n",
      "96 Train Loss 0.00060339813 Test MSE 0.00047746573513996105 Test RE 0.010444295852084241\n",
      "97 Train Loss 0.00057776074 Test MSE 0.00045085273949789083 Test RE 0.01014905057574878\n",
      "98 Train Loss 0.00055780483 Test MSE 0.00043771579206548355 Test RE 0.010000095973191403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0005369854 Test MSE 0.00043413253794792275 Test RE 0.009959080179680125\n",
      "Training time: 66.60\n",
      "1\n",
      "KG_rowdy_tune16\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.593033 Test MSE 8.051006695306741 Test RE 1.3562293984804066\n",
      "1 Train Loss 49.791702 Test MSE 9.35007819687225 Test RE 1.4615567458569245\n",
      "2 Train Loss 43.54096 Test MSE 8.40047740690253 Test RE 1.3853517075355206\n",
      "3 Train Loss 41.751244 Test MSE 8.518260892685609 Test RE 1.3950299413559089\n",
      "4 Train Loss 39.463234 Test MSE 8.587552755453913 Test RE 1.4006923905920792\n",
      "5 Train Loss 36.78161 Test MSE 9.100463492028236 Test RE 1.441915519315862\n",
      "6 Train Loss 33.724617 Test MSE 9.38380963643394 Test RE 1.4641907360682935\n",
      "7 Train Loss 31.12048 Test MSE 10.118510055360895 Test RE 1.5204296985333918\n",
      "8 Train Loss 28.057787 Test MSE 10.177823738461585 Test RE 1.5248794896045794\n",
      "9 Train Loss 25.055183 Test MSE 10.493612483234646 Test RE 1.548355108673136\n",
      "10 Train Loss 22.136051 Test MSE 10.124719889272306 Test RE 1.5208961786619049\n",
      "11 Train Loss 19.503664 Test MSE 10.050055300603274 Test RE 1.5152778889413974\n",
      "12 Train Loss 17.242702 Test MSE 9.79002140030677 Test RE 1.4955463624387868\n",
      "13 Train Loss 15.414457 Test MSE 9.567313024401702 Test RE 1.478437780154289\n",
      "14 Train Loss 13.813232 Test MSE 9.394502696848342 Test RE 1.4650247375485486\n",
      "15 Train Loss 12.721961 Test MSE 9.354853548202554 Test RE 1.4619299275502002\n",
      "16 Train Loss 10.369911 Test MSE 9.017868151195469 Test RE 1.4353572289975423\n",
      "17 Train Loss 8.480799 Test MSE 8.479252384776048 Test RE 1.3918320773370545\n",
      "18 Train Loss 7.025091 Test MSE 8.684923347480746 Test RE 1.4086109339312647\n",
      "19 Train Loss 5.7023516 Test MSE 7.93590886626888 Test RE 1.346500119249197\n",
      "20 Train Loss 5.0233564 Test MSE 7.847398231928409 Test RE 1.338970184382715\n",
      "21 Train Loss 4.53168 Test MSE 7.834537682268184 Test RE 1.3378725624100751\n",
      "22 Train Loss 4.033383 Test MSE 7.8587160721206555 Test RE 1.3399353954015303\n",
      "23 Train Loss 3.7461119 Test MSE 7.85060532434428 Test RE 1.339243763111944\n",
      "24 Train Loss 3.5335968 Test MSE 7.989824304961558 Test RE 1.351066342177119\n",
      "25 Train Loss 3.3339696 Test MSE 8.072778333238727 Test RE 1.3580619270961736\n",
      "26 Train Loss 3.1980085 Test MSE 8.01127216067611 Test RE 1.3528785256596376\n",
      "27 Train Loss 3.0919652 Test MSE 8.035758128201039 Test RE 1.3549444438605642\n",
      "28 Train Loss 2.981663 Test MSE 8.160712872682662 Test RE 1.3654383903559038\n",
      "29 Train Loss 2.8610787 Test MSE 8.19241886321867 Test RE 1.3680883186636703\n",
      "30 Train Loss 2.7727833 Test MSE 8.16370844578235 Test RE 1.365688974789377\n",
      "31 Train Loss 2.6591783 Test MSE 8.18212959214491 Test RE 1.367228923260194\n",
      "32 Train Loss 2.5571275 Test MSE 8.23270716634626 Test RE 1.371448154127265\n",
      "33 Train Loss 2.4838097 Test MSE 8.265134504513087 Test RE 1.3741464589344872\n",
      "34 Train Loss 2.418142 Test MSE 8.31237170656134 Test RE 1.3780676505846448\n",
      "35 Train Loss 2.3488166 Test MSE 8.279844161726814 Test RE 1.3753687159870713\n",
      "36 Train Loss 2.2940464 Test MSE 8.289191521833875 Test RE 1.3761448441403183\n",
      "37 Train Loss 2.250223 Test MSE 8.296955109308612 Test RE 1.3767891361936346\n",
      "38 Train Loss 2.1915278 Test MSE 8.308939413270789 Test RE 1.3777831096087074\n",
      "39 Train Loss 2.1495001 Test MSE 8.312627678072818 Test RE 1.3780888685568624\n",
      "40 Train Loss 2.108853 Test MSE 8.294903643815388 Test RE 1.3766189165179932\n",
      "41 Train Loss 2.0776217 Test MSE 8.32275183564723 Test RE 1.3789278176751636\n",
      "42 Train Loss 2.043855 Test MSE 8.328879675545569 Test RE 1.3794353597887963\n",
      "43 Train Loss 1.9991562 Test MSE 8.398587265322682 Test RE 1.385195843883448\n",
      "44 Train Loss 1.9553893 Test MSE 8.379241925884275 Test RE 1.3835995913312809\n",
      "45 Train Loss 1.9174476 Test MSE 8.40648261735819 Test RE 1.3858467890581037\n",
      "46 Train Loss 1.8861643 Test MSE 8.39741025301172 Test RE 1.3850987769818184\n",
      "47 Train Loss 1.8635619 Test MSE 8.404120386344319 Test RE 1.3856520631290448\n",
      "48 Train Loss 1.8374438 Test MSE 8.364081710761942 Test RE 1.3823473799840444\n",
      "49 Train Loss 1.8143399 Test MSE 8.386766418997535 Test RE 1.384220682685015\n",
      "50 Train Loss 1.781784 Test MSE 8.366264739841103 Test RE 1.3825277648578707\n",
      "51 Train Loss 1.7639797 Test MSE 8.39150162629621 Test RE 1.3846113962585107\n",
      "52 Train Loss 1.7385807 Test MSE 8.369188610467079 Test RE 1.3827693290042757\n",
      "53 Train Loss 1.7190474 Test MSE 8.351235745125905 Test RE 1.3812854337335092\n",
      "54 Train Loss 1.6992495 Test MSE 8.340818670893109 Test RE 1.3804236784661434\n",
      "55 Train Loss 1.6805036 Test MSE 8.322458061839532 Test RE 1.3789034809859106\n",
      "56 Train Loss 1.6592133 Test MSE 8.319012777571473 Test RE 1.3786180360965994\n",
      "57 Train Loss 1.6386874 Test MSE 8.300999221607915 Test RE 1.3771246334630673\n",
      "58 Train Loss 1.6198659 Test MSE 8.274193011605314 Test RE 1.37489927830247\n",
      "59 Train Loss 1.6035315 Test MSE 8.257505081167036 Test RE 1.3735120853752973\n",
      "60 Train Loss 1.5821596 Test MSE 8.232152116168958 Test RE 1.371401921742425\n",
      "61 Train Loss 1.5591526 Test MSE 8.225368040769306 Test RE 1.3708367225404934\n",
      "62 Train Loss 1.5425775 Test MSE 8.216802886008722 Test RE 1.370122803915215\n",
      "63 Train Loss 1.524061 Test MSE 8.195837876792579 Test RE 1.368373766996143\n",
      "64 Train Loss 1.5084549 Test MSE 8.169788181785288 Test RE 1.3661974130308012\n",
      "65 Train Loss 1.494969 Test MSE 8.129953800788815 Test RE 1.3628626798204444\n",
      "66 Train Loss 1.4791023 Test MSE 8.099474322149831 Test RE 1.3603055711812917\n",
      "67 Train Loss 1.4628168 Test MSE 8.131174980782372 Test RE 1.3629650320715412\n",
      "68 Train Loss 1.4475651 Test MSE 8.128714172880903 Test RE 1.362758773509351\n",
      "69 Train Loss 1.4378365 Test MSE 8.105212014412432 Test RE 1.3607873081839346\n",
      "70 Train Loss 1.4255432 Test MSE 8.112100359810741 Test RE 1.3613654289197625\n",
      "71 Train Loss 1.415844 Test MSE 8.096605806073322 Test RE 1.3600646664142115\n",
      "72 Train Loss 1.4063914 Test MSE 8.068348242752055 Test RE 1.3576892448177467\n",
      "73 Train Loss 1.3983458 Test MSE 8.042115010985198 Test RE 1.3554802688642287\n",
      "74 Train Loss 1.3897673 Test MSE 8.038920922484692 Test RE 1.3552110639406236\n",
      "75 Train Loss 1.3825463 Test MSE 8.029663669329466 Test RE 1.3544305396753213\n",
      "76 Train Loss 1.3728368 Test MSE 8.024860027737182 Test RE 1.3540253438604317\n",
      "77 Train Loss 1.363897 Test MSE 8.00942976151215 Test RE 1.352722952016823\n",
      "78 Train Loss 1.3560063 Test MSE 7.987147853498197 Test RE 1.3508400314204094\n",
      "79 Train Loss 1.3470896 Test MSE 7.958124821810815 Test RE 1.3483835128980155\n",
      "80 Train Loss 1.3355501 Test MSE 7.934220989147065 Test RE 1.346356919040959\n",
      "81 Train Loss 1.3208783 Test MSE 7.888589844128557 Test RE 1.3424797649417877\n",
      "82 Train Loss 1.3109577 Test MSE 7.873365248530795 Test RE 1.3411836788933715\n",
      "83 Train Loss 1.2998011 Test MSE 7.865551605804106 Test RE 1.3405180085562598\n",
      "84 Train Loss 1.2868507 Test MSE 7.820264514761706 Test RE 1.3366533210747888\n",
      "85 Train Loss 1.2767786 Test MSE 7.8047447795801785 Test RE 1.3353263322047018\n",
      "86 Train Loss 1.2659378 Test MSE 7.803639024699948 Test RE 1.335231736163953\n",
      "87 Train Loss 1.2527988 Test MSE 7.790322085472655 Test RE 1.3340919607188555\n",
      "88 Train Loss 1.238723 Test MSE 7.770982710202524 Test RE 1.3324349985899269\n",
      "89 Train Loss 1.2254534 Test MSE 7.750143884605046 Test RE 1.3306472568514969\n",
      "90 Train Loss 1.2099918 Test MSE 7.728470379507277 Test RE 1.3287853571495776\n",
      "91 Train Loss 1.1945277 Test MSE 7.691150503479429 Test RE 1.3255732004395249\n",
      "92 Train Loss 1.1816366 Test MSE 7.685557663104669 Test RE 1.3250911485295667\n",
      "93 Train Loss 1.1694821 Test MSE 7.680272239352699 Test RE 1.3246354319067863\n",
      "94 Train Loss 1.1558915 Test MSE 7.647870525630958 Test RE 1.3218382770069392\n",
      "95 Train Loss 1.1407851 Test MSE 7.593392760095525 Test RE 1.31712196465813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 1.1281835 Test MSE 7.543633933521821 Test RE 1.3127993801681666\n",
      "97 Train Loss 1.1138222 Test MSE 7.517833593832107 Test RE 1.31055247366706\n",
      "98 Train Loss 1.0954192 Test MSE 7.500929395047998 Test RE 1.3090782253506474\n",
      "99 Train Loss 1.0796633 Test MSE 7.446816071301253 Test RE 1.3043476916922134\n",
      "Training time: 66.98\n",
      "2\n",
      "KG_rowdy_tune16\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 53.50185 Test MSE 8.327904813324366 Test RE 1.379354628716718\n",
      "1 Train Loss 41.0112 Test MSE 7.258591371148566 Test RE 1.287757934112101\n",
      "2 Train Loss 31.53955 Test MSE 6.366466894179761 Test RE 1.2060277556476893\n",
      "3 Train Loss 24.985043 Test MSE 6.153247862893519 Test RE 1.18566026345667\n",
      "4 Train Loss 21.460474 Test MSE 5.347991482138261 Test RE 1.105359157892265\n",
      "5 Train Loss 17.512077 Test MSE 4.748649540654899 Test RE 1.041581169490484\n",
      "6 Train Loss 12.275202 Test MSE 3.981380746618061 Test RE 0.9537288415260432\n",
      "7 Train Loss 9.469415 Test MSE 3.3313131661445508 Test RE 0.8724002691738914\n",
      "8 Train Loss 7.187215 Test MSE 2.7795653920635854 Test RE 0.7968865708261098\n",
      "9 Train Loss 5.6564827 Test MSE 2.4587866088024253 Test RE 0.7494945511600746\n",
      "10 Train Loss 4.5097446 Test MSE 2.199557471328037 Test RE 0.7088848865226877\n",
      "11 Train Loss 3.7910488 Test MSE 2.177484015552514 Test RE 0.7053189431496294\n",
      "12 Train Loss 3.168563 Test MSE 2.1498000283988667 Test RE 0.7008209765960726\n",
      "13 Train Loss 2.801484 Test MSE 2.100792406022886 Test RE 0.6927868405820373\n",
      "14 Train Loss 2.454708 Test MSE 2.0381120002914233 Test RE 0.6823733910862286\n",
      "15 Train Loss 2.2148583 Test MSE 1.9305635205730203 Test RE 0.6641254269079149\n",
      "16 Train Loss 2.0104163 Test MSE 1.7900740637791273 Test RE 0.6395044345220429\n",
      "17 Train Loss 1.8012061 Test MSE 1.6883157132534548 Test RE 0.6210619056174761\n",
      "18 Train Loss 1.5930483 Test MSE 1.5290492500342938 Test RE 0.591042617816653\n",
      "19 Train Loss 1.3318323 Test MSE 1.2341959916464218 Test RE 0.5310068531243498\n",
      "20 Train Loss 1.0444797 Test MSE 0.925992914477939 Test RE 0.45995134382250974\n",
      "21 Train Loss 0.8780629 Test MSE 0.6915053308843264 Test RE 0.3974713469194779\n",
      "22 Train Loss 0.678498 Test MSE 0.47563797014193354 Test RE 0.329644867903805\n",
      "23 Train Loss 0.5271153 Test MSE 0.3948944490324069 Test RE 0.30036448101469376\n",
      "24 Train Loss 0.4056415 Test MSE 0.2612703894700236 Test RE 0.24431670163208585\n",
      "25 Train Loss 0.29615813 Test MSE 0.16749360756648682 Test RE 0.19561726323120923\n",
      "26 Train Loss 0.23593289 Test MSE 0.1007872867289061 Test RE 0.15174379358203674\n",
      "27 Train Loss 0.1773087 Test MSE 0.04232246262541702 Test RE 0.09833169498628683\n",
      "28 Train Loss 0.14647135 Test MSE 0.03058948401931285 Test RE 0.0835976628495097\n",
      "29 Train Loss 0.10822448 Test MSE 0.02072194306189461 Test RE 0.06880552267891821\n",
      "30 Train Loss 0.084690556 Test MSE 0.016805404266215844 Test RE 0.061963015121629814\n",
      "31 Train Loss 0.069244005 Test MSE 0.013719832939787156 Test RE 0.05598639087259671\n",
      "32 Train Loss 0.063185036 Test MSE 0.011432720443063028 Test RE 0.05110728994513622\n",
      "33 Train Loss 0.050637238 Test MSE 0.008875780392306203 Test RE 0.04503097334996687\n",
      "34 Train Loss 0.04472828 Test MSE 0.007024509149178225 Test RE 0.040060471040557565\n",
      "35 Train Loss 0.038932066 Test MSE 0.006827365088635095 Test RE 0.03949431846549108\n",
      "36 Train Loss 0.034487575 Test MSE 0.0062298525060884465 Test RE 0.03772653703722705\n",
      "37 Train Loss 0.030839464 Test MSE 0.005646194709169393 Test RE 0.035915836482882636\n",
      "38 Train Loss 0.027923279 Test MSE 0.005210751958978227 Test RE 0.034503111411162704\n",
      "39 Train Loss 0.025290268 Test MSE 0.005429602214093546 Test RE 0.03522022020260126\n",
      "40 Train Loss 0.022755822 Test MSE 0.005083555746965907 Test RE 0.03407939336984093\n",
      "41 Train Loss 0.020624151 Test MSE 0.004656206442670834 Test RE 0.032615510010058205\n",
      "42 Train Loss 0.019373426 Test MSE 0.004304536201330392 Test RE 0.03135965257300104\n",
      "43 Train Loss 0.018008268 Test MSE 0.004004006766860809 Test RE 0.03024513042690253\n",
      "44 Train Loss 0.016496163 Test MSE 0.004044806654669905 Test RE 0.030398835250261318\n",
      "45 Train Loss 0.015764093 Test MSE 0.0039409541835451365 Test RE 0.03000604479207125\n",
      "46 Train Loss 0.01441144 Test MSE 0.003853279095072855 Test RE 0.029670392633314557\n",
      "47 Train Loss 0.012609586 Test MSE 0.0035454503946139326 Test RE 0.028460581352260695\n",
      "48 Train Loss 0.011146765 Test MSE 0.0028980439281170267 Test RE 0.025731229738014276\n",
      "49 Train Loss 0.009350814 Test MSE 0.0025903490330002636 Test RE 0.024326924287941157\n",
      "50 Train Loss 0.008453619 Test MSE 0.002107336782748589 Test RE 0.02194194055383036\n",
      "51 Train Loss 0.00782644 Test MSE 0.0021434178641746185 Test RE 0.022128984432832326\n",
      "52 Train Loss 0.006949441 Test MSE 0.002404823262216884 Test RE 0.023439570115635126\n",
      "53 Train Loss 0.0064798803 Test MSE 0.0021004115334358766 Test RE 0.021905857461890374\n",
      "54 Train Loss 0.005891613 Test MSE 0.0020149988083603887 Test RE 0.021455836798235376\n",
      "55 Train Loss 0.0051913867 Test MSE 0.0018663024370402183 Test RE 0.020649002262773983\n",
      "56 Train Loss 0.0049358034 Test MSE 0.0017011769513368765 Test RE 0.019714365556738354\n",
      "57 Train Loss 0.0046747066 Test MSE 0.0015616536397414916 Test RE 0.01888862824472915\n",
      "58 Train Loss 0.004428397 Test MSE 0.0013220103984435167 Test RE 0.017379028517560475\n",
      "59 Train Loss 0.004184636 Test MSE 0.0012671103244294092 Test RE 0.01701434657934159\n",
      "60 Train Loss 0.0040627345 Test MSE 0.001302372838568034 Test RE 0.017249468798744973\n",
      "61 Train Loss 0.003439061 Test MSE 0.0012027821973872924 Test RE 0.016576832759440503\n",
      "62 Train Loss 0.0032633482 Test MSE 0.0011585383882738737 Test RE 0.01626909048671805\n",
      "63 Train Loss 0.0031797148 Test MSE 0.0010932443985622905 Test RE 0.015803987979932946\n",
      "64 Train Loss 0.0030543816 Test MSE 0.0010012043697526138 Test RE 0.015124096108319834\n",
      "65 Train Loss 0.0028898534 Test MSE 0.0009777780588418597 Test RE 0.014946111026010324\n",
      "66 Train Loss 0.0027830563 Test MSE 0.0009472803541006522 Test RE 0.014711173771966039\n",
      "67 Train Loss 0.0027094628 Test MSE 0.0010000129677232128 Test RE 0.015115094827957498\n",
      "68 Train Loss 0.0026247583 Test MSE 0.0010139702438470405 Test RE 0.015220210728957568\n",
      "69 Train Loss 0.0025429446 Test MSE 0.0009497172574937384 Test RE 0.014730084056897463\n",
      "70 Train Loss 0.0024992235 Test MSE 0.000918294027912909 Test RE 0.014484347654263928\n",
      "71 Train Loss 0.002395595 Test MSE 0.0008631247148342353 Test RE 0.0140425130613509\n",
      "72 Train Loss 0.0021692966 Test MSE 0.0009005059188244806 Test RE 0.014343374774021632\n",
      "73 Train Loss 0.0020367834 Test MSE 0.0008368216531105813 Test RE 0.013826890225001475\n",
      "74 Train Loss 0.0020103876 Test MSE 0.0008395397007658096 Test RE 0.013849327310969191\n",
      "75 Train Loss 0.001980191 Test MSE 0.0008043077673074176 Test RE 0.01355561393693871\n",
      "76 Train Loss 0.0019010117 Test MSE 0.000819828111472714 Test RE 0.013685777128050369\n",
      "77 Train Loss 0.0018071041 Test MSE 0.0007936162138410696 Test RE 0.013465216056506898\n",
      "78 Train Loss 0.0017547526 Test MSE 0.000803697776316787 Test RE 0.013550472639614414\n",
      "79 Train Loss 0.0016938869 Test MSE 0.000790139033379987 Test RE 0.013435685167498325\n",
      "80 Train Loss 0.0016371013 Test MSE 0.0008315521076563033 Test RE 0.013783286852245677\n",
      "81 Train Loss 0.0016012646 Test MSE 0.0008206530922658407 Test RE 0.013692661293263578\n",
      "82 Train Loss 0.0014685254 Test MSE 0.0007745372275421164 Test RE 0.01330237567279561\n",
      "83 Train Loss 0.0013881412 Test MSE 0.0006992916424982863 Test RE 0.01263971347526391\n",
      "84 Train Loss 0.0013701469 Test MSE 0.0006600058533878226 Test RE 0.012279535920827974\n",
      "85 Train Loss 0.0013501317 Test MSE 0.0006363629028409084 Test RE 0.012057589310052476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.00132507 Test MSE 0.0006181935235298469 Test RE 0.011884209133143413\n",
      "87 Train Loss 0.0013060507 Test MSE 0.0006089443810389811 Test RE 0.011794970906541169\n",
      "88 Train Loss 0.0012741968 Test MSE 0.0006022975228060975 Test RE 0.011730420992282078\n",
      "89 Train Loss 0.0011898181 Test MSE 0.0006173191046871039 Test RE 0.011875801204778129\n",
      "90 Train Loss 0.0011765906 Test MSE 0.0006009602869554208 Test RE 0.011717391670909532\n",
      "91 Train Loss 0.0011627094 Test MSE 0.0006094594488933661 Test RE 0.011799958165172398\n",
      "92 Train Loss 0.0011147573 Test MSE 0.0005922029607360574 Test RE 0.011631704149420658\n",
      "93 Train Loss 0.0010464661 Test MSE 0.0005270408231733374 Test RE 0.010973121505706167\n",
      "94 Train Loss 0.0010240518 Test MSE 0.0005142946398815238 Test RE 0.010839620042288795\n",
      "95 Train Loss 0.001010939 Test MSE 0.0005226366554109027 Test RE 0.010927177386282957\n",
      "96 Train Loss 0.001006261 Test MSE 0.0005395495249885283 Test RE 0.011102575049760385\n",
      "97 Train Loss 0.00097567594 Test MSE 0.0005559125014617239 Test RE 0.011269672113267987\n",
      "98 Train Loss 0.00088070025 Test MSE 0.0005244897178665754 Test RE 0.010946531965794936\n",
      "99 Train Loss 0.00085588376 Test MSE 0.0005158988586658834 Test RE 0.010856512676927282\n",
      "Training time: 68.11\n",
      "3\n",
      "KG_rowdy_tune16\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.70\n",
      "0\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 43.849415 Test MSE 6.993276908438621 Test RE 1.2640039258427715\n",
      "1 Train Loss 27.844315 Test MSE 6.040333362758513 Test RE 1.174731228974749\n",
      "2 Train Loss 22.756323 Test MSE 5.850156294462605 Test RE 1.1560903996830876\n",
      "3 Train Loss 19.321114 Test MSE 5.7661286396968015 Test RE 1.1477577232622338\n",
      "4 Train Loss 15.748825 Test MSE 5.721133892163298 Test RE 1.1432708124051443\n",
      "5 Train Loss 12.880787 Test MSE 5.935131455472972 Test RE 1.1644563982443004\n",
      "6 Train Loss 10.627797 Test MSE 5.604527191841082 Test RE 1.131559905121331\n",
      "7 Train Loss 9.417318 Test MSE 5.547592925525759 Test RE 1.1257976897506148\n",
      "8 Train Loss 7.9326487 Test MSE 5.085083255492485 Test RE 1.0778469426750403\n",
      "9 Train Loss 6.561203 Test MSE 5.144547776027 Test RE 1.0841307496148318\n",
      "10 Train Loss 5.3727784 Test MSE 4.78872882752915 Test RE 1.0459674812942352\n",
      "11 Train Loss 4.5625772 Test MSE 4.34900118557457 Test RE 0.9967880511579198\n",
      "12 Train Loss 3.9328952 Test MSE 4.0602187487723675 Test RE 0.9631252669387295\n",
      "13 Train Loss 3.2146034 Test MSE 3.50803304746751 Test RE 0.8952408651867201\n",
      "14 Train Loss 2.6178527 Test MSE 2.9515753866798513 Test RE 0.821173640805819\n",
      "15 Train Loss 2.2711186 Test MSE 2.6249445633037 Test RE 0.77440496409447\n",
      "16 Train Loss 1.9591404 Test MSE 2.1542606858393616 Test RE 0.7015476726448294\n",
      "17 Train Loss 1.6306021 Test MSE 1.5599078601137568 Test RE 0.5969769096801508\n",
      "18 Train Loss 1.3007126 Test MSE 1.108868064702969 Test RE 0.5033244159813787\n",
      "19 Train Loss 0.8628122 Test MSE 0.5744936995355937 Test RE 0.3622852856428333\n",
      "20 Train Loss 0.59372026 Test MSE 0.4433437138478069 Test RE 0.318257273433398\n",
      "21 Train Loss 0.41337666 Test MSE 0.2594787337662254 Test RE 0.2434775624737947\n",
      "22 Train Loss 0.29328838 Test MSE 0.22202070789185752 Test RE 0.22521888382266667\n",
      "23 Train Loss 0.23224817 Test MSE 0.17665705549002814 Test RE 0.20089704741288425\n",
      "24 Train Loss 0.18572244 Test MSE 0.09503583417906573 Test RE 0.14735054816582766\n",
      "25 Train Loss 0.15094176 Test MSE 0.06276552089986766 Test RE 0.11974809935369377\n",
      "26 Train Loss 0.107040346 Test MSE 0.048234593754609464 Test RE 0.10497536004119205\n",
      "27 Train Loss 0.084485725 Test MSE 0.04201903177464825 Test RE 0.0979785664177165\n",
      "28 Train Loss 0.067621306 Test MSE 0.03416951427762814 Test RE 0.0883542537101126\n",
      "29 Train Loss 0.058295667 Test MSE 0.02988281879256374 Test RE 0.08262640186425615\n",
      "30 Train Loss 0.048700746 Test MSE 0.028087958525106215 Test RE 0.08010657209113205\n",
      "31 Train Loss 0.042052258 Test MSE 0.021313179582918697 Test RE 0.06978019559085642\n",
      "32 Train Loss 0.035921432 Test MSE 0.017067270080919853 Test RE 0.062443910242486855\n",
      "33 Train Loss 0.031309675 Test MSE 0.012658278867274244 Test RE 0.05377685373762536\n",
      "34 Train Loss 0.027528323 Test MSE 0.009022802353646012 Test RE 0.04540239705309105\n",
      "35 Train Loss 0.024939327 Test MSE 0.008829209298099319 Test RE 0.04491267953419649\n",
      "36 Train Loss 0.022503268 Test MSE 0.0072726648486512455 Test RE 0.04076194018413503\n",
      "37 Train Loss 0.020604897 Test MSE 0.007391957062321368 Test RE 0.04109488581291823\n",
      "38 Train Loss 0.018741246 Test MSE 0.007211027043374193 Test RE 0.04058883838835503\n",
      "39 Train Loss 0.016276678 Test MSE 0.006291383413721772 Test RE 0.037912387692020835\n",
      "40 Train Loss 0.01485589 Test MSE 0.005678531740193374 Test RE 0.036018538692676655\n",
      "41 Train Loss 0.012815196 Test MSE 0.004554488458160391 Test RE 0.03225728885381107\n",
      "42 Train Loss 0.011838815 Test MSE 0.004557339904365923 Test RE 0.03226738499662668\n",
      "43 Train Loss 0.01103953 Test MSE 0.004532208296135851 Test RE 0.03217829219624922\n",
      "44 Train Loss 0.010178776 Test MSE 0.005687640913796071 Test RE 0.03604741654903756\n",
      "45 Train Loss 0.009434564 Test MSE 0.006217001833576881 Test RE 0.03768760660972476\n",
      "46 Train Loss 0.008532776 Test MSE 0.005548594079844303 Test RE 0.03560406107589498\n",
      "47 Train Loss 0.008022261 Test MSE 0.004984451013493342 Test RE 0.03374556674509056\n",
      "48 Train Loss 0.0071901972 Test MSE 0.004889078942905484 Test RE 0.03342116504971889\n",
      "49 Train Loss 0.0064648804 Test MSE 0.004814693271742262 Test RE 0.03316594473391312\n",
      "50 Train Loss 0.006175735 Test MSE 0.004882189868520619 Test RE 0.03339761030059775\n",
      "51 Train Loss 0.0057765944 Test MSE 0.004584646874752514 Test RE 0.03236391154386122\n",
      "52 Train Loss 0.005482598 Test MSE 0.004489881933403551 Test RE 0.032027682953933705\n",
      "53 Train Loss 0.0052159894 Test MSE 0.004455937259389993 Test RE 0.031906384454514464\n",
      "54 Train Loss 0.004920161 Test MSE 0.004275539851506081 Test RE 0.03125385116571324\n",
      "55 Train Loss 0.0045523467 Test MSE 0.0037083336226645582 Test RE 0.02910700092507975\n",
      "56 Train Loss 0.004111937 Test MSE 0.0031039448590169934 Test RE 0.026629625509388268\n",
      "57 Train Loss 0.003778209 Test MSE 0.0032972594394009933 Test RE 0.02744635146405332\n",
      "58 Train Loss 0.0035174966 Test MSE 0.003223564904991134 Test RE 0.027137901996396437\n",
      "59 Train Loss 0.003406246 Test MSE 0.0032185333740039714 Test RE 0.027116714503290628\n",
      "60 Train Loss 0.0033021693 Test MSE 0.003401342113464124 Test RE 0.027876177321876326\n",
      "61 Train Loss 0.0032042265 Test MSE 0.0034619377213880543 Test RE 0.028123391052135734\n",
      "62 Train Loss 0.0030693058 Test MSE 0.0036406199673961067 Test RE 0.028840031714496343\n",
      "63 Train Loss 0.002950268 Test MSE 0.0033438060045998938 Test RE 0.02763939910016898\n",
      "64 Train Loss 0.0027193357 Test MSE 0.0031712017109926105 Test RE 0.02691658718374373\n",
      "65 Train Loss 0.0026069647 Test MSE 0.0029856839523215786 Test RE 0.026117402205940932\n",
      "66 Train Loss 0.0025388517 Test MSE 0.0028395057140883236 Test RE 0.025470028666782583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Train Loss 0.002438289 Test MSE 0.002544573713252389 Test RE 0.024111019732274253\n",
      "68 Train Loss 0.0023759115 Test MSE 0.00237698158597634 Test RE 0.023303490097728596\n",
      "69 Train Loss 0.0022969227 Test MSE 0.00207397838855282 Test RE 0.021767581219581104\n",
      "70 Train Loss 0.002220783 Test MSE 0.002206174327664906 Test RE 0.02245060110650101\n",
      "71 Train Loss 0.002123349 Test MSE 0.0020648145661224687 Test RE 0.021719438220288198\n",
      "72 Train Loss 0.0019788628 Test MSE 0.0020169386921349646 Test RE 0.021466162317227765\n",
      "73 Train Loss 0.0018434416 Test MSE 0.002020813511873827 Test RE 0.0214867721650197\n",
      "74 Train Loss 0.0018035608 Test MSE 0.002032187226404179 Test RE 0.021547154162012982\n",
      "75 Train Loss 0.001749703 Test MSE 0.0019452699109725575 Test RE 0.02108132943229064\n",
      "76 Train Loss 0.001649199 Test MSE 0.0018647959921009832 Test RE 0.020640666833306138\n",
      "77 Train Loss 0.0015715689 Test MSE 0.0016826569650525967 Test RE 0.019606760958632466\n",
      "78 Train Loss 0.0015031751 Test MSE 0.0017477584273031049 Test RE 0.019982451277506762\n",
      "79 Train Loss 0.001442655 Test MSE 0.0016436362456056226 Test RE 0.019378087615340628\n",
      "80 Train Loss 0.0013924069 Test MSE 0.0015792709840035403 Test RE 0.018994872744047556\n",
      "81 Train Loss 0.0013312183 Test MSE 0.0015281805482002344 Test RE 0.018685098601194886\n",
      "82 Train Loss 0.0012663961 Test MSE 0.0014732074980439987 Test RE 0.018345942185845183\n",
      "83 Train Loss 0.0011883297 Test MSE 0.001332837949061304 Test RE 0.017450052386965797\n",
      "84 Train Loss 0.0011451119 Test MSE 0.0012419313024317272 Test RE 0.0168444504621229\n",
      "85 Train Loss 0.0011196213 Test MSE 0.0012303510739601845 Test RE 0.016765734583955322\n",
      "86 Train Loss 0.0010714161 Test MSE 0.001206528287550712 Test RE 0.016602627135931053\n",
      "87 Train Loss 0.0010399868 Test MSE 0.001273779026584036 Test RE 0.017059060410311137\n",
      "88 Train Loss 0.0010081051 Test MSE 0.001189513635179051 Test RE 0.016485145043186027\n",
      "89 Train Loss 0.00097032596 Test MSE 0.0010929201506080534 Test RE 0.01580164413495204\n",
      "90 Train Loss 0.00092832686 Test MSE 0.0010669612665875484 Test RE 0.01561285718562405\n",
      "91 Train Loss 0.00088540453 Test MSE 0.0010304129313559094 Test RE 0.01534312101469287\n",
      "92 Train Loss 0.0008297381 Test MSE 0.0009328648607684289 Test RE 0.014598809028001461\n",
      "93 Train Loss 0.0007838611 Test MSE 0.0008734736977841132 Test RE 0.014126448035689179\n",
      "94 Train Loss 0.000751878 Test MSE 0.0007592396860676128 Test RE 0.013170355893017306\n",
      "95 Train Loss 0.0007306199 Test MSE 0.0007336181831015265 Test RE 0.012946223604245582\n",
      "96 Train Loss 0.0007200196 Test MSE 0.0007102561285433133 Test RE 0.012738419742127288\n",
      "97 Train Loss 0.00068359135 Test MSE 0.0005966598924413333 Test RE 0.0116753923267198\n",
      "98 Train Loss 0.0006453737 Test MSE 0.0005439757071182537 Test RE 0.01114802189424177\n",
      "99 Train Loss 0.0006104398 Test MSE 0.0005544578806260086 Test RE 0.011254918138881203\n",
      "Training time: 67.22\n",
      "1\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.665634 Test MSE 8.308100467315542 Test RE 1.3777135511074252\n",
      "1 Train Loss 47.683197 Test MSE 9.178606649855896 Test RE 1.4480929511575145\n",
      "2 Train Loss 43.908432 Test MSE 8.09653775817104 Test RE 1.3600589510722405\n",
      "3 Train Loss 42.679276 Test MSE 8.45846135297086 Test RE 1.3901246517211283\n",
      "4 Train Loss 40.117443 Test MSE 8.662921187508605 Test RE 1.4068255332053303\n",
      "5 Train Loss 36.308655 Test MSE 8.964471266443544 Test RE 1.431101378472403\n",
      "6 Train Loss 31.029781 Test MSE 8.844711266455583 Test RE 1.421509905395647\n",
      "7 Train Loss 27.130278 Test MSE 9.202008301515008 Test RE 1.4499377951326597\n",
      "8 Train Loss 25.030138 Test MSE 9.13696392283827 Test RE 1.4448042661471694\n",
      "9 Train Loss 22.63855 Test MSE 8.953997214891965 Test RE 1.4302650876235175\n",
      "10 Train Loss 20.964977 Test MSE 8.775782243736243 Test RE 1.4159599821067588\n",
      "11 Train Loss 18.42715 Test MSE 7.5809472374899824 Test RE 1.3160421447462263\n",
      "12 Train Loss 14.802196 Test MSE 6.99761854073164 Test RE 1.2643962303979794\n",
      "13 Train Loss 13.603567 Test MSE 6.821268053109459 Test RE 1.2483622243722967\n",
      "14 Train Loss 11.545067 Test MSE 6.0969546529010215 Test RE 1.1802242742136557\n",
      "15 Train Loss 9.384976 Test MSE 5.891067418189574 Test RE 1.160125724039185\n",
      "16 Train Loss 8.175668 Test MSE 5.8464485521992176 Test RE 1.1557239851453893\n",
      "17 Train Loss 7.3008776 Test MSE 5.963296033682478 Test RE 1.167216034449974\n",
      "18 Train Loss 6.7365026 Test MSE 5.917627154158337 Test RE 1.162737982506199\n",
      "19 Train Loss 5.656831 Test MSE 5.517462382161159 Test RE 1.1227362646819277\n",
      "20 Train Loss 4.1904917 Test MSE 5.0752726143803155 Test RE 1.0768066967045828\n",
      "21 Train Loss 3.5086477 Test MSE 5.1127531204543795 Test RE 1.080775451128703\n",
      "22 Train Loss 2.9768314 Test MSE 5.278147618937979 Test RE 1.0981175348783512\n",
      "23 Train Loss 2.688371 Test MSE 5.216159491887218 Test RE 1.0916501815782043\n",
      "24 Train Loss 2.4768043 Test MSE 5.309376332997028 Test RE 1.101361307717065\n",
      "25 Train Loss 2.3589928 Test MSE 5.281842141246567 Test RE 1.0985017899549048\n",
      "26 Train Loss 2.2030048 Test MSE 5.387908549743938 Test RE 1.109476654149358\n",
      "27 Train Loss 2.0739276 Test MSE 5.423191203143179 Test RE 1.1131034235406314\n",
      "28 Train Loss 1.9816821 Test MSE 5.450394181911759 Test RE 1.1158916206987926\n",
      "29 Train Loss 1.9192218 Test MSE 5.473884643457807 Test RE 1.1182937062742118\n",
      "30 Train Loss 1.8571543 Test MSE 5.520723596212578 Test RE 1.1230680242970552\n",
      "31 Train Loss 1.799024 Test MSE 5.518493456063078 Test RE 1.1228411652597186\n",
      "32 Train Loss 1.7648842 Test MSE 5.519803668383698 Test RE 1.122974451004225\n",
      "33 Train Loss 1.7208742 Test MSE 5.524532255135506 Test RE 1.1234553508410388\n",
      "34 Train Loss 1.6775861 Test MSE 5.579926328099474 Test RE 1.1290737037817338\n",
      "35 Train Loss 1.6356689 Test MSE 5.5694691600483015 Test RE 1.1280152265097447\n",
      "36 Train Loss 1.5874846 Test MSE 5.589645282884497 Test RE 1.1300565699965244\n",
      "37 Train Loss 1.5349594 Test MSE 5.602297176339392 Test RE 1.1313347614914584\n",
      "38 Train Loss 1.5054456 Test MSE 5.608754512252435 Test RE 1.1319865748880185\n",
      "39 Train Loss 1.4699734 Test MSE 5.6369263869806785 Test RE 1.1348259075194056\n",
      "40 Train Loss 1.442183 Test MSE 5.644169485570477 Test RE 1.1355547636925338\n",
      "41 Train Loss 1.4142154 Test MSE 5.664837713910758 Test RE 1.1376319921057738\n",
      "42 Train Loss 1.3832818 Test MSE 5.686009718762859 Test RE 1.1397559264765904\n",
      "43 Train Loss 1.3616246 Test MSE 5.6965141250869085 Test RE 1.1408082404487228\n",
      "44 Train Loss 1.3410633 Test MSE 5.674811274680592 Test RE 1.1386330139089662\n",
      "45 Train Loss 1.3182261 Test MSE 5.661361408303764 Test RE 1.1372828767752456\n",
      "46 Train Loss 1.2911711 Test MSE 5.7041778230478295 Test RE 1.1415753649635503\n",
      "47 Train Loss 1.2654145 Test MSE 5.725323595767434 Test RE 1.1436893561157897\n",
      "48 Train Loss 1.2421416 Test MSE 5.734345144540759 Test RE 1.1445900727132985\n",
      "49 Train Loss 1.2145622 Test MSE 5.738677122671787 Test RE 1.1450223280934126\n",
      "50 Train Loss 1.1900344 Test MSE 5.744212076222419 Test RE 1.145574381975945\n",
      "51 Train Loss 1.1646076 Test MSE 5.7644646117767975 Test RE 1.1475920975166827\n",
      "52 Train Loss 1.1457767 Test MSE 5.769090408242252 Test RE 1.1480524579553877\n",
      "53 Train Loss 1.1288457 Test MSE 5.76735676411835 Test RE 1.1478799468830654\n",
      "54 Train Loss 1.1127162 Test MSE 5.782394307299831 Test RE 1.1493754376286955\n",
      "55 Train Loss 1.0930512 Test MSE 5.810492607959509 Test RE 1.1521646246577668\n",
      "56 Train Loss 1.0731664 Test MSE 5.804904570457186 Test RE 1.15161046442795\n",
      "57 Train Loss 1.0567414 Test MSE 5.798965417553484 Test RE 1.151021191952564\n",
      "58 Train Loss 1.0460683 Test MSE 5.808953252342957 Test RE 1.1520119948646164\n",
      "59 Train Loss 1.0371612 Test MSE 5.818995163978032 Test RE 1.1530073039080717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Train Loss 1.0251182 Test MSE 5.8054730120278215 Test RE 1.1516668484070578\n",
      "61 Train Loss 1.0174105 Test MSE 5.820320837380505 Test RE 1.1531386344923737\n",
      "62 Train Loss 1.0073781 Test MSE 5.852152767523432 Test RE 1.156287651374806\n",
      "63 Train Loss 0.99614245 Test MSE 5.861649895185155 Test RE 1.1572255079387443\n",
      "64 Train Loss 0.98654604 Test MSE 5.871257861740851 Test RE 1.158173537224382\n",
      "65 Train Loss 0.9767725 Test MSE 5.847889006121815 Test RE 1.155866350600576\n",
      "66 Train Loss 0.969376 Test MSE 5.843688954646097 Test RE 1.1554511947929873\n",
      "67 Train Loss 0.9587511 Test MSE 5.868432204658499 Test RE 1.15789480690963\n",
      "68 Train Loss 0.9527225 Test MSE 5.880807211176917 Test RE 1.1591150143877118\n",
      "69 Train Loss 0.9448873 Test MSE 5.890299638761813 Test RE 1.1600501223166981\n",
      "70 Train Loss 0.93740743 Test MSE 5.888392218031321 Test RE 1.1598622810396744\n",
      "71 Train Loss 0.9319345 Test MSE 5.902074801209619 Test RE 1.1612090581563816\n",
      "72 Train Loss 0.92626053 Test MSE 5.893154015512269 Test RE 1.1603311622682433\n",
      "73 Train Loss 0.92125005 Test MSE 5.9105289729785815 Test RE 1.162040422395008\n",
      "74 Train Loss 0.91509694 Test MSE 5.921798772482375 Test RE 1.1631477451028902\n",
      "75 Train Loss 0.90877897 Test MSE 5.930710195493584 Test RE 1.1640225979434524\n",
      "76 Train Loss 0.9020562 Test MSE 5.953572399516725 Test RE 1.1662640263637778\n",
      "77 Train Loss 0.8976245 Test MSE 5.9532231828376165 Test RE 1.1662298212852555\n",
      "78 Train Loss 0.8918165 Test MSE 5.9827135784653995 Test RE 1.169114820757974\n",
      "79 Train Loss 0.88662434 Test MSE 5.984312772418022 Test RE 1.1692710639412325\n",
      "80 Train Loss 0.8810272 Test MSE 5.9816401625226385 Test RE 1.169009935009509\n",
      "81 Train Loss 0.87631536 Test MSE 5.972723086329619 Test RE 1.1681382645141984\n",
      "82 Train Loss 0.8717191 Test MSE 5.977374654816692 Test RE 1.168593050173418\n",
      "83 Train Loss 0.8678319 Test MSE 5.969883395845354 Test RE 1.1678605398114899\n",
      "84 Train Loss 0.8657462 Test MSE 5.975489925993289 Test RE 1.1684088008352556\n",
      "85 Train Loss 0.8627261 Test MSE 5.993763574882161 Test RE 1.1701939928374654\n",
      "86 Train Loss 0.86000395 Test MSE 5.98908007875512 Test RE 1.1697367116975481\n",
      "87 Train Loss 0.8563078 Test MSE 6.011108236812054 Test RE 1.171885914502363\n",
      "88 Train Loss 0.8531053 Test MSE 6.013591766409725 Test RE 1.1721279757568779\n",
      "89 Train Loss 0.8500427 Test MSE 6.015022178438223 Test RE 1.1722673705088453\n",
      "90 Train Loss 0.8455128 Test MSE 6.037362202425048 Test RE 1.1744422760365645\n",
      "91 Train Loss 0.8427705 Test MSE 6.0249597366463625 Test RE 1.173235335984511\n",
      "92 Train Loss 0.8396546 Test MSE 6.025210684105817 Test RE 1.173259769123826\n",
      "93 Train Loss 0.8364779 Test MSE 6.034208046744327 Test RE 1.174135448517648\n",
      "94 Train Loss 0.8340684 Test MSE 6.035413146927053 Test RE 1.1742526867860492\n",
      "95 Train Loss 0.8304399 Test MSE 6.018289004314807 Test RE 1.172585663063225\n",
      "96 Train Loss 0.82696795 Test MSE 6.018328547703119 Test RE 1.1725895153154187\n",
      "97 Train Loss 0.823513 Test MSE 6.0122245040517726 Test RE 1.1719947194912779\n",
      "98 Train Loss 0.82090276 Test MSE 6.028234700730999 Test RE 1.1735541581643623\n",
      "99 Train Loss 0.81804174 Test MSE 6.036490402270323 Test RE 1.17435747775144\n",
      "Training time: 67.86\n",
      "2\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.308342 Test MSE 7.980126795482757 Test RE 1.3502461766673195\n",
      "1 Train Loss 39.225895 Test MSE 7.345045846774221 Test RE 1.295404244584351\n",
      "2 Train Loss 27.971561 Test MSE 5.908485732552671 Test RE 1.161839549240317\n",
      "3 Train Loss 21.01772 Test MSE 5.72664487391426 Test RE 1.143821317615767\n",
      "4 Train Loss 16.299213 Test MSE 5.8184055255101805 Test RE 1.1529488853440162\n",
      "5 Train Loss 13.832944 Test MSE 5.806493907268717 Test RE 1.1517681045423047\n",
      "6 Train Loss 11.943712 Test MSE 5.870077704761436 Test RE 1.1580571315658807\n",
      "7 Train Loss 10.70783 Test MSE 5.896918151181114 Test RE 1.1607016724135881\n",
      "8 Train Loss 9.60052 Test MSE 5.671977184772162 Test RE 1.138348652792735\n",
      "9 Train Loss 8.373108 Test MSE 5.685693824821484 Test RE 1.139724265697729\n",
      "10 Train Loss 7.3724866 Test MSE 5.5601206498897175 Test RE 1.1270681263150886\n",
      "11 Train Loss 6.577126 Test MSE 5.316446019740899 Test RE 1.1020943212315721\n",
      "12 Train Loss 5.798599 Test MSE 5.204168235109033 Test RE 1.0903946803315765\n",
      "13 Train Loss 5.172374 Test MSE 4.848165593426336 Test RE 1.0524386354748685\n",
      "14 Train Loss 4.1926966 Test MSE 4.67699285033578 Test RE 1.03369261434541\n",
      "15 Train Loss 3.277114 Test MSE 4.056225681825964 Test RE 0.9626515523525999\n",
      "16 Train Loss 2.6503716 Test MSE 3.743445413958579 Test RE 0.924791464362007\n",
      "17 Train Loss 2.3259993 Test MSE 3.5793025310216406 Test RE 0.9042890333936817\n",
      "18 Train Loss 2.1100419 Test MSE 3.3878344455873353 Test RE 0.8797700029052545\n",
      "19 Train Loss 1.9009128 Test MSE 3.0662808623806725 Test RE 0.8369779687946686\n",
      "20 Train Loss 1.7116419 Test MSE 2.671151381987332 Test RE 0.7811911435700537\n",
      "21 Train Loss 1.5234393 Test MSE 2.38861284301198 Test RE 0.7387218448859046\n",
      "22 Train Loss 1.4046901 Test MSE 2.1355817679739766 Test RE 0.6984996012678187\n",
      "23 Train Loss 1.1385309 Test MSE 1.4455970918451557 Test RE 0.5746874236425458\n",
      "24 Train Loss 0.8760122 Test MSE 1.1651583288694949 Test RE 0.5159415835221711\n",
      "25 Train Loss 0.6858145 Test MSE 0.7642694063694391 Test RE 0.41786047909193774\n",
      "26 Train Loss 0.5112773 Test MSE 0.5067100186869754 Test RE 0.34024190860432724\n",
      "27 Train Loss 0.3570524 Test MSE 0.22059496293521658 Test RE 0.22449457783287605\n",
      "28 Train Loss 0.26668394 Test MSE 0.09627873696690728 Test RE 0.14831096218667497\n",
      "29 Train Loss 0.18474033 Test MSE 0.09053501521041417 Test RE 0.14381902815718559\n",
      "30 Train Loss 0.139196 Test MSE 0.09902867056965492 Test RE 0.15041409488540294\n",
      "31 Train Loss 0.11853351 Test MSE 0.08367249874468052 Test RE 0.13826091593585915\n",
      "32 Train Loss 0.096908085 Test MSE 0.07539286329839666 Test RE 0.13124210244540416\n",
      "33 Train Loss 0.07673482 Test MSE 0.05483669203872568 Test RE 0.11192927341767529\n",
      "34 Train Loss 0.062717855 Test MSE 0.03996044224286894 Test RE 0.09554835253153353\n",
      "35 Train Loss 0.04931281 Test MSE 0.03265281902354415 Test RE 0.08637109010060011\n",
      "36 Train Loss 0.041618988 Test MSE 0.02785930707552241 Test RE 0.07977985000341126\n",
      "37 Train Loss 0.037295215 Test MSE 0.0228925255299055 Test RE 0.07231941657354861\n",
      "38 Train Loss 0.033005714 Test MSE 0.0188411427293632 Test RE 0.0656087373914716\n",
      "39 Train Loss 0.029385654 Test MSE 0.017155876706718802 Test RE 0.06260579265014489\n",
      "40 Train Loss 0.024432287 Test MSE 0.010151391784997828 Test RE 0.04815826752513534\n",
      "41 Train Loss 0.021275705 Test MSE 0.00797925563760455 Test RE 0.04269620252610289\n",
      "42 Train Loss 0.018886259 Test MSE 0.00684660119888153 Test RE 0.0395499169783015\n",
      "43 Train Loss 0.015750878 Test MSE 0.005500943903919682 Test RE 0.03545085128464999\n",
      "44 Train Loss 0.0140597075 Test MSE 0.005740807536288794 Test RE 0.03621550569567527\n",
      "45 Train Loss 0.011978239 Test MSE 0.005055749130481676 Test RE 0.03398605987529515\n",
      "46 Train Loss 0.0111358175 Test MSE 0.004663084534058874 Test RE 0.03263959073726791\n",
      "47 Train Loss 0.009791463 Test MSE 0.00434666266764029 Test RE 0.03151273002782666\n",
      "48 Train Loss 0.00893827 Test MSE 0.0038991886908034154 Test RE 0.02984662206862452\n",
      "49 Train Loss 0.008024705 Test MSE 0.002819051942338307 Test RE 0.025378128922216275\n",
      "50 Train Loss 0.0073119425 Test MSE 0.002459163460586877 Test RE 0.023702914988593504\n",
      "51 Train Loss 0.0068176296 Test MSE 0.0023320236753769244 Test RE 0.023082058526170755\n",
      "52 Train Loss 0.0065413765 Test MSE 0.0021543125937933502 Test RE 0.022185152603643853\n",
      "53 Train Loss 0.006222477 Test MSE 0.0021025397599687906 Test RE 0.021916952626531205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 0.0058122776 Test MSE 0.0019799889131662234 Test RE 0.021268626248775128\n",
      "55 Train Loss 0.005509694 Test MSE 0.0018829502821782393 Test RE 0.020740894706824404\n",
      "56 Train Loss 0.0051292307 Test MSE 0.001740173246209388 Test RE 0.01993904272654888\n",
      "57 Train Loss 0.0048272037 Test MSE 0.001618801533001941 Test RE 0.019231132662385714\n",
      "58 Train Loss 0.004606689 Test MSE 0.0016033225303600125 Test RE 0.019138967634141767\n",
      "59 Train Loss 0.0042856275 Test MSE 0.0013871408482565152 Test RE 0.01780198131030325\n",
      "60 Train Loss 0.003708276 Test MSE 0.0012620144740563602 Test RE 0.016980099399024486\n",
      "61 Train Loss 0.0035029207 Test MSE 0.0013114405038604645 Test RE 0.01730941365339722\n",
      "62 Train Loss 0.0033287716 Test MSE 0.0013580183729878547 Test RE 0.01761411725713063\n",
      "63 Train Loss 0.0030494945 Test MSE 0.0011904690885543826 Test RE 0.01649176439810592\n",
      "64 Train Loss 0.0027924664 Test MSE 0.0012346542941435521 Test RE 0.016795028528929418\n",
      "65 Train Loss 0.0025090673 Test MSE 0.00124422800810074 Test RE 0.01686001850338468\n",
      "66 Train Loss 0.002388121 Test MSE 0.0012464079472151307 Test RE 0.01687478176586595\n",
      "67 Train Loss 0.0023023654 Test MSE 0.001248456125600633 Test RE 0.016888640942607776\n",
      "68 Train Loss 0.0021363697 Test MSE 0.00123883447553303 Test RE 0.01682343605235355\n",
      "69 Train Loss 0.002032624 Test MSE 0.0012420499940042978 Test RE 0.016845255356300454\n",
      "70 Train Loss 0.0019101739 Test MSE 0.001214335084687476 Test RE 0.016656253874031142\n",
      "71 Train Loss 0.0018210218 Test MSE 0.001153918364355789 Test RE 0.016236619110658036\n",
      "72 Train Loss 0.0017193032 Test MSE 0.0010703981486129175 Test RE 0.015637982936435625\n",
      "73 Train Loss 0.0016308925 Test MSE 0.001035947441259037 Test RE 0.015384270990902487\n",
      "74 Train Loss 0.0015889298 Test MSE 0.0009564462634138172 Test RE 0.014782175282105918\n",
      "75 Train Loss 0.001531822 Test MSE 0.0009243027553863519 Test RE 0.0145316585305856\n",
      "76 Train Loss 0.001380224 Test MSE 0.0008833564647896515 Test RE 0.014206138883539181\n",
      "77 Train Loss 0.0012818006 Test MSE 0.0008556339265178267 Test RE 0.013981444994730731\n",
      "78 Train Loss 0.001235147 Test MSE 0.0008681832477754125 Test RE 0.014083602569731934\n",
      "79 Train Loss 0.0011982236 Test MSE 0.0008260487675245349 Test RE 0.013737601178690913\n",
      "80 Train Loss 0.0011538052 Test MSE 0.0008059621079856418 Test RE 0.013569547710042706\n",
      "81 Train Loss 0.0011269472 Test MSE 0.0007792927245370249 Test RE 0.013343150087728389\n",
      "82 Train Loss 0.0010977592 Test MSE 0.0007577151703869316 Test RE 0.013157126537587917\n",
      "83 Train Loss 0.0010724965 Test MSE 0.0007156548588611012 Test RE 0.012786741115222018\n",
      "84 Train Loss 0.0010316181 Test MSE 0.0006615356787482079 Test RE 0.0122937590312963\n",
      "85 Train Loss 0.0010063095 Test MSE 0.0005966741143936747 Test RE 0.011675531472894941\n",
      "86 Train Loss 0.0009866474 Test MSE 0.0005774238336043339 Test RE 0.011485645641019795\n",
      "87 Train Loss 0.0009497629 Test MSE 0.000542740099315229 Test RE 0.011135353668814643\n",
      "88 Train Loss 0.00091512385 Test MSE 0.0004992083870206946 Test RE 0.0106794527073041\n",
      "89 Train Loss 0.0008972783 Test MSE 0.0005033991543106803 Test RE 0.010724185094242552\n",
      "90 Train Loss 0.0008837417 Test MSE 0.00049572417516974 Test RE 0.010642118970671991\n",
      "91 Train Loss 0.00087028363 Test MSE 0.000468333323929019 Test RE 0.010343930423450864\n",
      "92 Train Loss 0.0008544375 Test MSE 0.0004590858431204396 Test RE 0.010241298169870376\n",
      "93 Train Loss 0.00083850545 Test MSE 0.00043517177577028193 Test RE 0.009970993207799353\n",
      "94 Train Loss 0.0008085078 Test MSE 0.00040660295480503337 Test RE 0.009638142109353343\n",
      "95 Train Loss 0.0007907251 Test MSE 0.00038615493276306 Test RE 0.009392665448225238\n",
      "96 Train Loss 0.00077443925 Test MSE 0.0003728263372771953 Test RE 0.009229142516629303\n",
      "97 Train Loss 0.00073576084 Test MSE 0.000379613707563245 Test RE 0.009312772704493835\n",
      "98 Train Loss 0.0007173687 Test MSE 0.00037139670851712536 Test RE 0.00921143062354617\n",
      "99 Train Loss 0.0007007313 Test MSE 0.0003576352017093955 Test RE 0.009039162418454313\n",
      "Training time: 68.34\n",
      "3\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 51.80862 Test MSE 7.975854448775562 Test RE 1.3498846854112265\n",
      "1 Train Loss 40.53412 Test MSE 8.466198492453527 Test RE 1.3907602950971096\n",
      "2 Train Loss 32.537773 Test MSE 8.841802415467589 Test RE 1.421276132895855\n",
      "3 Train Loss 29.46613 Test MSE 8.788755274153589 Test RE 1.4170061856074174\n",
      "4 Train Loss 26.62684 Test MSE 8.571102748604021 Test RE 1.3993501895613432\n",
      "5 Train Loss 24.457212 Test MSE 8.413060383832311 Test RE 1.3863888703582559\n",
      "6 Train Loss 23.0061 Test MSE 8.336975545989656 Test RE 1.3801056190485474\n",
      "7 Train Loss 21.207874 Test MSE 8.18518053989228 Test RE 1.3674838052671934\n",
      "8 Train Loss 19.369162 Test MSE 7.863526435450996 Test RE 1.3403454235785595\n",
      "9 Train Loss 17.944744 Test MSE 8.197952006208286 Test RE 1.3685502427111191\n",
      "10 Train Loss 16.786936 Test MSE 8.030518206084048 Test RE 1.3545026086892527\n",
      "11 Train Loss 15.760065 Test MSE 8.02056857137862 Test RE 1.3536632492125455\n",
      "12 Train Loss 14.669043 Test MSE 8.095154056317572 Test RE 1.3599427287708337\n",
      "13 Train Loss 13.880984 Test MSE 8.191441543013966 Test RE 1.3680067127145152\n",
      "14 Train Loss 13.442051 Test MSE 8.11791939106105 Test RE 1.3618536136990462\n",
      "15 Train Loss 12.969815 Test MSE 8.258155603255245 Test RE 1.3735661866046938\n",
      "16 Train Loss 11.988089 Test MSE 7.756586361257475 Test RE 1.331200206783717\n",
      "17 Train Loss 8.639902 Test MSE 6.791334917193601 Test RE 1.2456201769991058\n",
      "18 Train Loss 7.1933055 Test MSE 6.186397942831744 Test RE 1.188849793426322\n",
      "19 Train Loss 6.736866 Test MSE 5.999142145325209 Test RE 1.1707189184026703\n",
      "20 Train Loss 6.3941507 Test MSE 5.97150226549534 Test RE 1.1680188750506058\n",
      "21 Train Loss 6.133499 Test MSE 6.022957989091689 Test RE 1.173040420485525\n",
      "22 Train Loss 5.937023 Test MSE 6.038938505190819 Test RE 1.174595584362585\n",
      "23 Train Loss 5.785507 Test MSE 6.08034782766325 Test RE 1.1786158365584531\n",
      "24 Train Loss 5.595025 Test MSE 6.202116246093656 Test RE 1.190359140795658\n",
      "25 Train Loss 5.415937 Test MSE 6.106765055658336 Test RE 1.1811734219639174\n",
      "26 Train Loss 5.1831074 Test MSE 6.20738133756197 Test RE 1.1908642925821398\n",
      "27 Train Loss 4.924155 Test MSE 6.183339985678776 Test RE 1.188555930896926\n",
      "28 Train Loss 4.641001 Test MSE 6.159527839158255 Test RE 1.1862651488464542\n",
      "29 Train Loss 3.9415803 Test MSE 5.616131607322853 Test RE 1.1327307711674082\n",
      "30 Train Loss 3.1023328 Test MSE 5.566223583592753 Test RE 1.127686506386128\n",
      "31 Train Loss 2.4638605 Test MSE 5.4015667693006115 Test RE 1.1108820124923704\n",
      "32 Train Loss 2.1724453 Test MSE 5.499185434015722 Test RE 1.1208751541852642\n",
      "33 Train Loss 1.9922705 Test MSE 5.405740487143075 Test RE 1.1113111113981533\n",
      "34 Train Loss 1.8741595 Test MSE 5.423955959207476 Test RE 1.1131819034017993\n",
      "35 Train Loss 1.7710148 Test MSE 5.452049118069806 Test RE 1.1160610203025458\n",
      "36 Train Loss 1.6848252 Test MSE 5.462570355764731 Test RE 1.1171373755826164\n",
      "37 Train Loss 1.6149652 Test MSE 5.4582278403563205 Test RE 1.116693248509021\n",
      "38 Train Loss 1.5777955 Test MSE 5.469914834138823 Test RE 1.1178881242923724\n",
      "39 Train Loss 1.5246084 Test MSE 5.515086661675039 Test RE 1.1224945235928825\n",
      "40 Train Loss 1.4814312 Test MSE 5.575119828698439 Test RE 1.1285873119429655\n",
      "41 Train Loss 1.4394062 Test MSE 5.630532243793743 Test RE 1.134182090502847\n",
      "42 Train Loss 1.4076201 Test MSE 5.673685446922736 Test RE 1.1385200614091644\n",
      "43 Train Loss 1.3776888 Test MSE 5.642448308295708 Test RE 1.1353816080063257\n",
      "44 Train Loss 1.3453889 Test MSE 5.690582684659818 Test RE 1.14021415797042\n",
      "45 Train Loss 1.3196931 Test MSE 5.702207158789985 Test RE 1.1413781537111545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 1.2911562 Test MSE 5.726449252184685 Test RE 1.1438017810266898\n",
      "47 Train Loss 1.2652041 Test MSE 5.733841070153672 Test RE 1.1445397643341648\n",
      "48 Train Loss 1.2409989 Test MSE 5.751845750379196 Test RE 1.1463353251659312\n",
      "49 Train Loss 1.2196091 Test MSE 5.7797726808844825 Test RE 1.149114855726009\n",
      "50 Train Loss 1.2012606 Test MSE 5.821440718191296 Test RE 1.1532495661534365\n",
      "51 Train Loss 1.1852719 Test MSE 5.815325619494693 Test RE 1.15264369483837\n",
      "52 Train Loss 1.1679991 Test MSE 5.839027003336712 Test RE 1.1549902075624279\n",
      "53 Train Loss 1.1479194 Test MSE 5.874401347919869 Test RE 1.1584835402435805\n",
      "54 Train Loss 1.133055 Test MSE 5.862909471237097 Test RE 1.1573498360090346\n",
      "55 Train Loss 1.1185997 Test MSE 5.849230466420491 Test RE 1.1559989163783735\n",
      "56 Train Loss 1.1002809 Test MSE 5.89463391332018 Test RE 1.160476845186747\n",
      "57 Train Loss 1.0872147 Test MSE 5.902351912070388 Test RE 1.1612363180501917\n",
      "58 Train Loss 1.0716407 Test MSE 5.912450142500198 Test RE 1.1622292629598685\n",
      "59 Train Loss 1.0574275 Test MSE 5.94343445057244 Test RE 1.1652706259288785\n",
      "60 Train Loss 1.0435929 Test MSE 5.956772236583265 Test RE 1.1665773973375275\n",
      "61 Train Loss 1.0262771 Test MSE 5.947225938146956 Test RE 1.1656422464751193\n",
      "62 Train Loss 1.0143688 Test MSE 5.938217584487346 Test RE 1.164759103893696\n",
      "63 Train Loss 1.0050557 Test MSE 5.982141187534971 Test RE 1.1690588923971996\n",
      "64 Train Loss 0.99215513 Test MSE 6.013722901906068 Test RE 1.172140755702034\n",
      "65 Train Loss 0.9790593 Test MSE 6.013490273126539 Test RE 1.1721180845285453\n",
      "66 Train Loss 0.9692352 Test MSE 6.0115953661874855 Test RE 1.1719333973013928\n",
      "67 Train Loss 0.96168405 Test MSE 6.0057614995714665 Test RE 1.171364616286941\n",
      "68 Train Loss 0.9556036 Test MSE 6.018011748842946 Test RE 1.1725586529333134\n",
      "69 Train Loss 0.9487994 Test MSE 6.0272512549849235 Test RE 1.1734584274922155\n",
      "70 Train Loss 0.9419281 Test MSE 6.024768931191622 Test RE 1.1732167581446602\n",
      "71 Train Loss 0.9320774 Test MSE 6.024546168934443 Test RE 1.1731950684473427\n",
      "72 Train Loss 0.9205622 Test MSE 6.016069125670866 Test RE 1.172369385816775\n",
      "73 Train Loss 0.9107402 Test MSE 6.036705560812589 Test RE 1.1743784063684604\n",
      "74 Train Loss 0.89828825 Test MSE 6.056610493171342 Test RE 1.1763129619595145\n",
      "75 Train Loss 0.88937616 Test MSE 6.082726944317496 Test RE 1.1788463982307\n",
      "76 Train Loss 0.88308775 Test MSE 6.080021081690191 Test RE 1.1785841678806759\n",
      "77 Train Loss 0.8735379 Test MSE 6.101490875979558 Test RE 1.1806632446051533\n",
      "78 Train Loss 0.8659214 Test MSE 6.113600183289228 Test RE 1.1818342639303097\n",
      "79 Train Loss 0.8584933 Test MSE 6.10770538459254 Test RE 1.1812643578998558\n",
      "80 Train Loss 0.8517217 Test MSE 6.1037742858596395 Test RE 1.180884148478413\n",
      "81 Train Loss 0.84558153 Test MSE 6.100971124146562 Test RE 1.1806129564897598\n",
      "82 Train Loss 0.8402098 Test MSE 6.091596191639207 Test RE 1.179705525381902\n",
      "83 Train Loss 0.83376175 Test MSE 6.091497095160147 Test RE 1.1796959297738163\n",
      "84 Train Loss 0.8281569 Test MSE 6.100335441672394 Test RE 1.1805514486986093\n",
      "85 Train Loss 0.8210773 Test MSE 6.098039202611026 Test RE 1.1803292409592616\n",
      "86 Train Loss 0.8147024 Test MSE 6.09766770848552 Test RE 1.1802932874303511\n",
      "87 Train Loss 0.8095747 Test MSE 6.125490392452884 Test RE 1.1829829676668326\n",
      "88 Train Loss 0.8047674 Test MSE 6.125181419135453 Test RE 1.1829531321142632\n",
      "89 Train Loss 0.798513 Test MSE 6.149410111142574 Test RE 1.185290460421727\n",
      "90 Train Loss 0.79380774 Test MSE 6.167524131066558 Test RE 1.187034903125245\n",
      "91 Train Loss 0.79000473 Test MSE 6.168996546911459 Test RE 1.1871765892101698\n",
      "92 Train Loss 0.7843978 Test MSE 6.149001352298556 Test RE 1.185251065910609\n",
      "93 Train Loss 0.7805113 Test MSE 6.157255664582858 Test RE 1.1860463293036003\n",
      "94 Train Loss 0.7761862 Test MSE 6.175386052352262 Test RE 1.1877912360236265\n",
      "95 Train Loss 0.7714036 Test MSE 6.177938035380471 Test RE 1.1880366384932508\n",
      "96 Train Loss 0.7681199 Test MSE 6.173743008044446 Test RE 1.1876332116149604\n",
      "97 Train Loss 0.7642092 Test MSE 6.173001700300671 Test RE 1.1875619073733221\n",
      "98 Train Loss 0.7599636 Test MSE 6.176232883530023 Test RE 1.187872674184885\n",
      "99 Train Loss 0.7545994 Test MSE 6.185020232969621 Test RE 1.1887174077230627\n",
      "Training time: 67.06\n",
      "4\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.15869 Test MSE 8.448229320981588 Test RE 1.3892835942594208\n",
      "1 Train Loss 54.607307 Test MSE 8.574956725888946 Test RE 1.399664761553644\n",
      "2 Train Loss 47.500015 Test MSE 8.700328840557415 Test RE 1.4098596917221833\n",
      "3 Train Loss 43.31829 Test MSE 8.073686739613285 Test RE 1.3581383343352464\n",
      "4 Train Loss 41.87533 Test MSE 7.799412778297711 Test RE 1.3348701239380465\n",
      "5 Train Loss 38.44291 Test MSE 7.511599684178022 Test RE 1.3100089952856442\n",
      "6 Train Loss 34.213295 Test MSE 6.220269381931201 Test RE 1.1920999145585887\n",
      "7 Train Loss 28.359842 Test MSE 5.735571730721736 Test RE 1.1447124810496048\n",
      "8 Train Loss 24.366985 Test MSE 5.297878501744028 Test RE 1.1001681233481257\n",
      "9 Train Loss 22.326002 Test MSE 5.121852498912558 Test RE 1.081736774006074\n",
      "10 Train Loss 19.050121 Test MSE 5.590591142555297 Test RE 1.130152178006266\n",
      "11 Train Loss 16.180805 Test MSE 5.600709398147673 Test RE 1.1311744311931202\n",
      "12 Train Loss 14.010452 Test MSE 5.442050400325225 Test RE 1.1150371575408284\n",
      "13 Train Loss 10.6796255 Test MSE 4.74796240669166 Test RE 1.0415058078867696\n",
      "14 Train Loss 8.458843 Test MSE 4.524074571032862 Test RE 1.0166534475324642\n",
      "15 Train Loss 7.5550156 Test MSE 4.485645058380846 Test RE 1.0123262841953569\n",
      "16 Train Loss 6.574088 Test MSE 4.178185465411742 Test RE 0.977016542858127\n",
      "17 Train Loss 5.4488964 Test MSE 3.3831007375208637 Test RE 0.8791551514125471\n",
      "18 Train Loss 3.94457 Test MSE 2.660656135755253 Test RE 0.7796549403411492\n",
      "19 Train Loss 3.2648377 Test MSE 2.263892171326183 Test RE 0.7191772307337585\n",
      "20 Train Loss 2.6191428 Test MSE 1.7743132883979158 Test RE 0.6366829397071342\n",
      "21 Train Loss 2.0550716 Test MSE 1.557688488432494 Test RE 0.5965520816261747\n",
      "22 Train Loss 1.647505 Test MSE 1.3541926965689204 Test RE 0.5562221685106518\n",
      "23 Train Loss 1.2092564 Test MSE 1.072515039068963 Test RE 0.4950051936471116\n",
      "24 Train Loss 0.89302385 Test MSE 0.7605068411443276 Test RE 0.41683062814829824\n",
      "25 Train Loss 0.68605274 Test MSE 0.6325649690561258 Test RE 0.38015493174972986\n",
      "26 Train Loss 0.5219643 Test MSE 0.3514330443250058 Test RE 0.28335400640283387\n",
      "27 Train Loss 0.38055697 Test MSE 0.23184859998246105 Test RE 0.2301496396020092\n",
      "28 Train Loss 0.28477916 Test MSE 0.14153398501349046 Test RE 0.17982017983989582\n",
      "29 Train Loss 0.20444307 Test MSE 0.05215308302607423 Test RE 0.10915611084925494\n",
      "30 Train Loss 0.13222738 Test MSE 0.016111544222449092 Test RE 0.060670370085143664\n",
      "31 Train Loss 0.100041315 Test MSE 0.01807614865271911 Test RE 0.06426300243279714\n",
      "32 Train Loss 0.0783064 Test MSE 0.014397828459516778 Test RE 0.057353055200507014\n",
      "33 Train Loss 0.06168601 Test MSE 0.01056126168592487 Test RE 0.04912086004006792\n",
      "34 Train Loss 0.050579466 Test MSE 0.00701805229030299 Test RE 0.04004205521460067\n",
      "35 Train Loss 0.04258121 Test MSE 0.005672114918297917 Test RE 0.035998182208929655\n",
      "36 Train Loss 0.03423833 Test MSE 0.004459575212309588 Test RE 0.03191940643349261\n",
      "37 Train Loss 0.028799096 Test MSE 0.0035114113993708696 Test RE 0.028323630338411964\n",
      "38 Train Loss 0.024551753 Test MSE 0.0032006048151633918 Test RE 0.027041083388089058\n",
      "39 Train Loss 0.021365486 Test MSE 0.0033953428782572707 Test RE 0.02785158268453801\n",
      "40 Train Loss 0.01910311 Test MSE 0.003815124239821402 Test RE 0.0295231302777554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 0.017476384 Test MSE 0.0033540320976560615 Test RE 0.02768163051259077\n",
      "42 Train Loss 0.01611734 Test MSE 0.0038405629222563044 Test RE 0.0296213946731805\n",
      "43 Train Loss 0.014244288 Test MSE 0.0035494225115635285 Test RE 0.028476519681585974\n",
      "44 Train Loss 0.013195694 Test MSE 0.003050017540278648 Test RE 0.02639728301913094\n",
      "45 Train Loss 0.012260918 Test MSE 0.003101710972638138 Test RE 0.02662004121143116\n",
      "46 Train Loss 0.01062426 Test MSE 0.0025925091919492575 Test RE 0.024337065599284367\n",
      "47 Train Loss 0.010013777 Test MSE 0.002597501085497821 Test RE 0.02436048492135713\n",
      "48 Train Loss 0.009192558 Test MSE 0.0028432114726910087 Test RE 0.0254866433547546\n",
      "49 Train Loss 0.008614857 Test MSE 0.002522595689357179 Test RE 0.02400666791584224\n",
      "50 Train Loss 0.007996727 Test MSE 0.0022638216943172617 Test RE 0.022742026906322498\n",
      "51 Train Loss 0.0067930585 Test MSE 0.0019030224063945665 Test RE 0.02085114993337171\n",
      "52 Train Loss 0.0064311847 Test MSE 0.0017909206959364923 Test RE 0.020227687608947078\n",
      "53 Train Loss 0.006120071 Test MSE 0.001504614578813207 Test RE 0.01854046802623992\n",
      "54 Train Loss 0.005898649 Test MSE 0.001481228765481611 Test RE 0.018395819050637814\n",
      "55 Train Loss 0.0054365415 Test MSE 0.001368066184747044 Test RE 0.017679159517979652\n",
      "56 Train Loss 0.0050140563 Test MSE 0.0013681472030353473 Test RE 0.017679682999245862\n",
      "57 Train Loss 0.0048583024 Test MSE 0.0015226029608276543 Test RE 0.01865096878644378\n",
      "58 Train Loss 0.0046840208 Test MSE 0.0015258762159342432 Test RE 0.018671005724829194\n",
      "59 Train Loss 0.0044046175 Test MSE 0.001401590344108618 Test RE 0.01789446047265457\n",
      "60 Train Loss 0.0041166176 Test MSE 0.0015010566814795776 Test RE 0.01851853412866369\n",
      "61 Train Loss 0.0040110275 Test MSE 0.0013475409146045461 Test RE 0.017546036983364887\n",
      "62 Train Loss 0.0038942103 Test MSE 0.0013883717022753557 Test RE 0.017809877690003566\n",
      "63 Train Loss 0.003736433 Test MSE 0.0014075054974337954 Test RE 0.017932180850210314\n",
      "64 Train Loss 0.0035071506 Test MSE 0.0014342418567951168 Test RE 0.018101695565960488\n",
      "65 Train Loss 0.0034045526 Test MSE 0.00137769106055646 Test RE 0.017741240388031973\n",
      "66 Train Loss 0.003322044 Test MSE 0.0013083369890665702 Test RE 0.017288920218558115\n",
      "67 Train Loss 0.0032016279 Test MSE 0.001262134386952958 Test RE 0.016980906079368\n",
      "68 Train Loss 0.003133888 Test MSE 0.0013062909704847252 Test RE 0.01727539645034069\n",
      "69 Train Loss 0.0029853783 Test MSE 0.0012875450758852932 Test RE 0.01715099346335765\n",
      "70 Train Loss 0.0029254798 Test MSE 0.001190159675945737 Test RE 0.01648962108691122\n",
      "71 Train Loss 0.0028345287 Test MSE 0.0010856022039841212 Test RE 0.01574865316095384\n",
      "72 Train Loss 0.0026630529 Test MSE 0.0009390639134358875 Test RE 0.014647234551456187\n",
      "73 Train Loss 0.0026013535 Test MSE 0.0008726971213915322 Test RE 0.014120166961918729\n",
      "74 Train Loss 0.0025587524 Test MSE 0.0008245714230654563 Test RE 0.013725311195270621\n",
      "75 Train Loss 0.0024217218 Test MSE 0.0007948074857927098 Test RE 0.013475318369744985\n",
      "76 Train Loss 0.0022700815 Test MSE 0.000863066033123334 Test RE 0.014042035695401234\n",
      "77 Train Loss 0.0021492075 Test MSE 0.0007923805076674714 Test RE 0.013454728914008346\n",
      "78 Train Loss 0.0020769532 Test MSE 0.0007608386471860853 Test RE 0.013184217004017708\n",
      "79 Train Loss 0.0020238024 Test MSE 0.0007683931239956405 Test RE 0.01324950932748023\n",
      "80 Train Loss 0.0019677363 Test MSE 0.0008200066774548761 Test RE 0.013687267489958918\n",
      "81 Train Loss 0.0018173703 Test MSE 0.0007590208709992618 Test RE 0.013168457888968824\n",
      "82 Train Loss 0.0017263767 Test MSE 0.0006152745931747725 Test RE 0.011856119042840382\n",
      "83 Train Loss 0.0016860137 Test MSE 0.0005620129339449914 Test RE 0.011331338554381868\n",
      "84 Train Loss 0.0016697228 Test MSE 0.000579152534271667 Test RE 0.011502825746513774\n",
      "85 Train Loss 0.0016373129 Test MSE 0.0005239703380006019 Test RE 0.01094111068076932\n",
      "86 Train Loss 0.0016057454 Test MSE 0.0005347111270773306 Test RE 0.011052681901211435\n",
      "87 Train Loss 0.0015537199 Test MSE 0.000465038613088818 Test RE 0.010307481586568652\n",
      "88 Train Loss 0.0014833643 Test MSE 0.0004428723920159777 Test RE 0.010058827587387582\n",
      "89 Train Loss 0.0014488916 Test MSE 0.00041334966995322953 Test RE 0.009717775412788487\n",
      "90 Train Loss 0.0014280484 Test MSE 0.00038985710386401165 Test RE 0.0094375830494965\n",
      "91 Train Loss 0.0014107022 Test MSE 0.0004009020349093008 Test RE 0.009570336113348734\n",
      "92 Train Loss 0.0013710109 Test MSE 0.0003528372207734175 Test RE 0.0089783236458498\n",
      "93 Train Loss 0.0013290045 Test MSE 0.0003647688176187233 Test RE 0.009128867697530085\n",
      "94 Train Loss 0.0012948735 Test MSE 0.0003610930397231897 Test RE 0.009082755403479897\n",
      "95 Train Loss 0.0012669588 Test MSE 0.0003842488594856336 Test RE 0.009369455520850617\n",
      "96 Train Loss 0.0012453177 Test MSE 0.0003801701584260549 Test RE 0.009319595696746945\n",
      "97 Train Loss 0.0012069102 Test MSE 0.0003653867283529727 Test RE 0.009136596481119471\n",
      "98 Train Loss 0.001168673 Test MSE 0.00035800171021983367 Test RE 0.009043792949216652\n",
      "99 Train Loss 0.0010809227 Test MSE 0.00032594394078407107 Test RE 0.008629378459302645\n",
      "Training time: 68.05\n",
      "5\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 55.820564 Test MSE 7.952661145850822 Test RE 1.3479205649256443\n",
      "1 Train Loss 49.271244 Test MSE 7.790446594910581 Test RE 1.3341026217913152\n",
      "2 Train Loss 33.228703 Test MSE 7.765018182891076 Test RE 1.331923552946899\n",
      "3 Train Loss 30.787804 Test MSE 8.65041437963953 Test RE 1.4058096373331441\n",
      "4 Train Loss 29.338379 Test MSE 8.646633350185324 Test RE 1.4055023694746138\n",
      "5 Train Loss 28.164787 Test MSE 8.650408252295446 Test RE 1.4058091394448058\n",
      "6 Train Loss 26.509136 Test MSE 8.69081994367772 Test RE 1.409089038353641\n",
      "7 Train Loss 24.992397 Test MSE 8.594766683539936 Test RE 1.4012805891917406\n",
      "8 Train Loss 23.34374 Test MSE 8.620138164689829 Test RE 1.4033473332061144\n",
      "9 Train Loss 20.846872 Test MSE 8.47578833466977 Test RE 1.3915477439807975\n",
      "10 Train Loss 18.245579 Test MSE 8.437854356709323 Test RE 1.3884302677762936\n",
      "11 Train Loss 16.297316 Test MSE 8.815801332150736 Test RE 1.4191848213277711\n",
      "12 Train Loss 13.922585 Test MSE 8.534331823421814 Test RE 1.3963452840904327\n",
      "13 Train Loss 11.982267 Test MSE 8.43767478767107 Test RE 1.3884154938536941\n",
      "14 Train Loss 9.59615 Test MSE 7.89725124335169 Test RE 1.3432165609633815\n",
      "15 Train Loss 8.593593 Test MSE 7.705912769153379 Test RE 1.3268447321109784\n",
      "16 Train Loss 7.449639 Test MSE 7.689572008164669 Test RE 1.3254371662756201\n",
      "17 Train Loss 5.985316 Test MSE 7.338510113499563 Test RE 1.2948277811403492\n",
      "18 Train Loss 4.290594 Test MSE 6.6894223533894515 Test RE 1.2362387965660198\n",
      "19 Train Loss 3.7693746 Test MSE 6.927531608395943 Test RE 1.2580483089215564\n",
      "20 Train Loss 3.442673 Test MSE 6.863953587396292 Test RE 1.2522620787864047\n",
      "21 Train Loss 3.1411486 Test MSE 7.05392343403862 Test RE 1.2694728904345276\n",
      "22 Train Loss 2.9218493 Test MSE 7.141344965725852 Test RE 1.2773151593167749\n",
      "23 Train Loss 2.7956765 Test MSE 7.143053572159224 Test RE 1.2774679525500654\n",
      "24 Train Loss 2.6683505 Test MSE 7.259039427297858 Test RE 1.2877976786663756\n",
      "25 Train Loss 2.5671253 Test MSE 7.271226293320566 Test RE 1.2888782373532799\n",
      "26 Train Loss 2.471599 Test MSE 7.394471962635482 Test RE 1.2997554392929864\n",
      "27 Train Loss 2.3842578 Test MSE 7.345565064393959 Test RE 1.29545002951453\n",
      "28 Train Loss 2.3140602 Test MSE 7.380277697593595 Test RE 1.2985073491383154\n",
      "29 Train Loss 2.250456 Test MSE 7.427731199696761 Test RE 1.3026752132973356\n",
      "30 Train Loss 2.1797414 Test MSE 7.4081518435257525 Test RE 1.3009571669983604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 2.1112447 Test MSE 7.412682102820125 Test RE 1.3013548891743654\n",
      "32 Train Loss 2.0487735 Test MSE 7.468312079953945 Test RE 1.3062289026892866\n",
      "33 Train Loss 2.0026712 Test MSE 7.405156283836818 Test RE 1.3006941129353686\n",
      "34 Train Loss 1.9362376 Test MSE 7.336427890311676 Test RE 1.2946440713910659\n",
      "35 Train Loss 1.8816482 Test MSE 7.349399718490956 Test RE 1.2957881215858067\n",
      "36 Train Loss 1.842646 Test MSE 7.339513522905906 Test RE 1.2949163003319917\n",
      "37 Train Loss 1.8005596 Test MSE 7.32370067739184 Test RE 1.293520611625796\n",
      "38 Train Loss 1.7720205 Test MSE 7.31525815761562 Test RE 1.2927748327593462\n",
      "39 Train Loss 1.742097 Test MSE 7.275479867108052 Test RE 1.289255170825337\n",
      "40 Train Loss 1.711911 Test MSE 7.2656437102838565 Test RE 1.2883833654368426\n",
      "41 Train Loss 1.6700621 Test MSE 7.244808740685752 Test RE 1.2865347542865375\n",
      "42 Train Loss 1.6359653 Test MSE 7.199222758556564 Test RE 1.2824807826516638\n",
      "43 Train Loss 1.5920411 Test MSE 7.060063934292092 Test RE 1.2700253137043362\n",
      "44 Train Loss 1.5622891 Test MSE 7.013315606700815 Test RE 1.2658135835312554\n",
      "45 Train Loss 1.5363238 Test MSE 6.9883694206278015 Test RE 1.2635603446314283\n",
      "46 Train Loss 1.4904383 Test MSE 6.894443911973269 Test RE 1.255040329600559\n",
      "47 Train Loss 1.459792 Test MSE 6.832986441750437 Test RE 1.2494340570736973\n",
      "48 Train Loss 1.4344969 Test MSE 6.837029485743481 Test RE 1.249803644360594\n",
      "49 Train Loss 1.4146104 Test MSE 6.867057795787045 Test RE 1.2525452132072927\n",
      "50 Train Loss 1.3853495 Test MSE 6.788936347164254 Test RE 1.245400192923233\n",
      "51 Train Loss 1.3622003 Test MSE 6.734814235421147 Test RE 1.240426029046345\n",
      "52 Train Loss 1.3363962 Test MSE 6.6689935245189025 Test RE 1.234349678158177\n",
      "53 Train Loss 1.305036 Test MSE 6.587074746903153 Test RE 1.2267451682033648\n",
      "54 Train Loss 1.2805037 Test MSE 6.538467872080216 Test RE 1.2222106320093853\n",
      "55 Train Loss 1.2620251 Test MSE 6.539366481870728 Test RE 1.2222946159585595\n",
      "56 Train Loss 1.2419235 Test MSE 6.523289651838275 Test RE 1.2207912046322584\n",
      "57 Train Loss 1.2232635 Test MSE 6.532907062172315 Test RE 1.2216907910618724\n",
      "58 Train Loss 1.2068149 Test MSE 6.40700653035762 Test RE 1.209861462946392\n",
      "59 Train Loss 1.1890961 Test MSE 6.402022789131681 Test RE 1.2093908212021958\n",
      "60 Train Loss 1.1709435 Test MSE 6.342837285294679 Test RE 1.2037875447974185\n",
      "61 Train Loss 1.1603576 Test MSE 6.335395845638986 Test RE 1.2030811936113484\n",
      "62 Train Loss 1.1489061 Test MSE 6.312636896852983 Test RE 1.2009183060344464\n",
      "63 Train Loss 1.1356242 Test MSE 6.322960281866125 Test RE 1.2018998671315078\n",
      "64 Train Loss 1.1266421 Test MSE 6.3202947402058856 Test RE 1.2016465006908346\n",
      "65 Train Loss 1.1150627 Test MSE 6.307698947829008 Test RE 1.2004485155489704\n",
      "66 Train Loss 1.1046724 Test MSE 6.283077636055954 Test RE 1.1981033246576382\n",
      "67 Train Loss 1.0951695 Test MSE 6.2864596302223985 Test RE 1.1984257330036148\n",
      "68 Train Loss 1.0876459 Test MSE 6.246753064169691 Test RE 1.1946349865973902\n",
      "69 Train Loss 1.0811775 Test MSE 6.253328053355672 Test RE 1.1952635248367582\n",
      "70 Train Loss 1.0745165 Test MSE 6.244657189616411 Test RE 1.1944345612649059\n",
      "71 Train Loss 1.0649097 Test MSE 6.236987706859955 Test RE 1.1937008532775908\n",
      "72 Train Loss 1.0518931 Test MSE 6.231010410192839 Test RE 1.1931287169522191\n",
      "73 Train Loss 1.0409716 Test MSE 6.249323624362025 Test RE 1.1948807595017168\n",
      "74 Train Loss 1.0324465 Test MSE 6.277233483528612 Test RE 1.1975459920950298\n",
      "75 Train Loss 1.0169246 Test MSE 6.258520621894412 Test RE 1.195759676632876\n",
      "76 Train Loss 1.0043525 Test MSE 6.2567650906297505 Test RE 1.1955919580255456\n",
      "77 Train Loss 0.9940111 Test MSE 6.256606509527632 Test RE 1.195576806466471\n",
      "78 Train Loss 0.9865538 Test MSE 6.23413495622184 Test RE 1.1934278272181253\n",
      "79 Train Loss 0.9795445 Test MSE 6.204945850382245 Test RE 1.1906306498345376\n",
      "80 Train Loss 0.9724248 Test MSE 6.2021415453773745 Test RE 1.1903615686123683\n",
      "81 Train Loss 0.9622946 Test MSE 6.195958271159093 Test RE 1.189768050442544\n",
      "82 Train Loss 0.9531297 Test MSE 6.18641402983546 Test RE 1.1888513391576818\n",
      "83 Train Loss 0.94380933 Test MSE 6.192419824873821 Test RE 1.1894282699447156\n",
      "84 Train Loss 0.9337031 Test MSE 6.207249516095531 Test RE 1.1908516477724953\n",
      "85 Train Loss 0.925116 Test MSE 6.165305821093511 Test RE 1.1868214099855126\n",
      "86 Train Loss 0.9165484 Test MSE 6.167328029107533 Test RE 1.1870160315557647\n",
      "87 Train Loss 0.9078156 Test MSE 6.178001287807067 Test RE 1.1880427202965558\n",
      "88 Train Loss 0.90256786 Test MSE 6.189619399440957 Test RE 1.1891592893244896\n",
      "89 Train Loss 0.8965548 Test MSE 6.201666838119912 Test RE 1.1903160130502708\n",
      "90 Train Loss 0.8898535 Test MSE 6.205534062080703 Test RE 1.1906870827428018\n",
      "91 Train Loss 0.880523 Test MSE 6.201419743945361 Test RE 1.1902922998220287\n",
      "92 Train Loss 0.8733164 Test MSE 6.206687723486195 Test RE 1.190797757012114\n",
      "93 Train Loss 0.86714506 Test MSE 6.206427025387755 Test RE 1.1907727483452857\n",
      "94 Train Loss 0.8628194 Test MSE 6.22252341422246 Test RE 1.1923158849737545\n",
      "95 Train Loss 0.8592906 Test MSE 6.222685989287715 Test RE 1.192331460613556\n",
      "96 Train Loss 0.85527295 Test MSE 6.212975985312152 Test RE 1.1914008284695305\n",
      "97 Train Loss 0.85019517 Test MSE 6.237752834526722 Test RE 1.1937740701558617\n",
      "98 Train Loss 0.84570175 Test MSE 6.239738448559421 Test RE 1.1939640573197383\n",
      "99 Train Loss 0.84229225 Test MSE 6.247737602666788 Test RE 1.194729124926745\n",
      "Training time: 67.34\n",
      "6\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.97736 Test MSE 8.571025890827203 Test RE 1.3993439155036855\n",
      "1 Train Loss 56.488525 Test MSE 7.963448107898938 Test RE 1.348834412539771\n",
      "2 Train Loss 47.554577 Test MSE 8.277610899879036 Test RE 1.37518321940252\n",
      "3 Train Loss 45.377583 Test MSE 8.25017319721826 Test RE 1.3729021755112452\n",
      "4 Train Loss 44.71689 Test MSE 8.275492019356179 Test RE 1.3750072002909757\n",
      "5 Train Loss 43.881218 Test MSE 8.367357445168254 Test RE 1.3826180468520688\n",
      "6 Train Loss 42.21917 Test MSE 9.188000684352314 Test RE 1.448833801961831\n",
      "7 Train Loss 40.501213 Test MSE 9.210456369035215 Test RE 1.4506032130441202\n",
      "8 Train Loss 36.64865 Test MSE 8.326514707706576 Test RE 1.3792395020021497\n",
      "9 Train Loss 32.226646 Test MSE 8.40073730707583 Test RE 1.385373137886832\n",
      "10 Train Loss 30.38562 Test MSE 8.292128136859708 Test RE 1.3763885862326397\n",
      "11 Train Loss 28.412613 Test MSE 8.09257004037361 Test RE 1.3597256609951465\n",
      "12 Train Loss 26.307568 Test MSE 7.776091374579445 Test RE 1.3328728997604986\n",
      "13 Train Loss 23.257612 Test MSE 7.700640559638288 Test RE 1.3263907560172579\n",
      "14 Train Loss 20.558369 Test MSE 7.762747367122099 Test RE 1.331728783656305\n",
      "15 Train Loss 18.929775 Test MSE 7.729131481218436 Test RE 1.3288421888022133\n",
      "16 Train Loss 17.751404 Test MSE 7.601017371293281 Test RE 1.3177830672446162\n",
      "17 Train Loss 16.88761 Test MSE 7.6496681973959415 Test RE 1.321993620361701\n",
      "18 Train Loss 16.384768 Test MSE 7.801396863496719 Test RE 1.3350399013120042\n",
      "19 Train Loss 15.649906 Test MSE 7.993067248860668 Test RE 1.3513405026396046\n",
      "20 Train Loss 14.805392 Test MSE 7.753277001370863 Test RE 1.33091619714627\n",
      "21 Train Loss 12.40582 Test MSE 7.250235698346921 Test RE 1.2870165242588787\n",
      "22 Train Loss 8.069883 Test MSE 6.179248770562985 Test RE 1.1881626610289713\n",
      "23 Train Loss 6.2683077 Test MSE 5.918543148485147 Test RE 1.162827969603693\n",
      "24 Train Loss 5.417922 Test MSE 5.77204958352668 Test RE 1.1483468590378874\n",
      "25 Train Loss 4.899208 Test MSE 5.571664386105417 Test RE 1.1282375102130433\n",
      "26 Train Loss 4.4016657 Test MSE 5.712245333895747 Test RE 1.1423823539705575\n",
      "27 Train Loss 4.09262 Test MSE 5.612114296423564 Test RE 1.132325568258196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 3.8504338 Test MSE 5.766254309458928 Test RE 1.147770230584146\n",
      "29 Train Loss 3.6033478 Test MSE 6.013128754479849 Test RE 1.1720828513367336\n",
      "30 Train Loss 3.37539 Test MSE 6.0473161969980405 Test RE 1.1754100478081064\n",
      "31 Train Loss 3.1882968 Test MSE 6.005035364942538 Test RE 1.1712938014433634\n",
      "32 Train Loss 3.0509665 Test MSE 5.922797738354467 Test RE 1.163245848394419\n",
      "33 Train Loss 2.9453247 Test MSE 5.844293990388018 Test RE 1.155511008994421\n",
      "34 Train Loss 2.7720032 Test MSE 5.821938420433716 Test RE 1.1532988634541828\n",
      "35 Train Loss 2.6967556 Test MSE 5.800395322664272 Test RE 1.151163092233112\n",
      "36 Train Loss 2.5957012 Test MSE 5.770218116813495 Test RE 1.1481646598141777\n",
      "37 Train Loss 2.494535 Test MSE 5.706100494191627 Test RE 1.1417677405485036\n",
      "38 Train Loss 2.4131281 Test MSE 5.7067520508280705 Test RE 1.1418329256178965\n",
      "39 Train Loss 2.35038 Test MSE 5.572435134431764 Test RE 1.1283155440859818\n",
      "40 Train Loss 2.2935054 Test MSE 5.54911017139076 Test RE 1.1259516299493593\n",
      "41 Train Loss 2.241476 Test MSE 5.555774916745806 Test RE 1.1266275877873302\n",
      "42 Train Loss 2.192788 Test MSE 5.460916918013287 Test RE 1.1169682924601287\n",
      "43 Train Loss 2.139423 Test MSE 5.482902747093111 Test RE 1.1192145092281391\n",
      "44 Train Loss 2.073735 Test MSE 5.544558024198729 Test RE 1.1254897046150207\n",
      "45 Train Loss 2.0321636 Test MSE 5.544297125242827 Test RE 1.1254632243670097\n",
      "46 Train Loss 1.9869283 Test MSE 5.520546984636618 Test RE 1.1230500603113056\n",
      "47 Train Loss 1.9413679 Test MSE 5.553137567295904 Test RE 1.1263601486451287\n",
      "48 Train Loss 1.8839339 Test MSE 5.5906263791472295 Test RE 1.1301557395838657\n",
      "49 Train Loss 1.8254766 Test MSE 5.537061462473987 Test RE 1.1247285838129768\n",
      "50 Train Loss 1.7883544 Test MSE 5.527294606258705 Test RE 1.1237361882196353\n",
      "51 Train Loss 1.7628572 Test MSE 5.562813590694781 Test RE 1.1273410304951974\n",
      "52 Train Loss 1.7320877 Test MSE 5.581996961379893 Test RE 1.1292831761474535\n",
      "53 Train Loss 1.7084829 Test MSE 5.629358228277097 Test RE 1.1340638408656571\n",
      "54 Train Loss 1.6872509 Test MSE 5.594511232325069 Test RE 1.130548336616845\n",
      "55 Train Loss 1.673657 Test MSE 5.601537236557234 Test RE 1.1312580273034276\n",
      "56 Train Loss 1.6474828 Test MSE 5.626180978744727 Test RE 1.1337437588755015\n",
      "57 Train Loss 1.6286211 Test MSE 5.60657257624512 Test RE 1.131766368911523\n",
      "58 Train Loss 1.603159 Test MSE 5.653515948599325 Test RE 1.1364945857915771\n",
      "59 Train Loss 1.5655614 Test MSE 5.6112609737079895 Test RE 1.1322394798599766\n",
      "60 Train Loss 1.5277579 Test MSE 5.69258438437683 Test RE 1.1404146792359713\n",
      "61 Train Loss 1.5074705 Test MSE 5.7362262054826845 Test RE 1.144777789626654\n",
      "62 Train Loss 1.4898106 Test MSE 5.741703704431028 Test RE 1.145324231024291\n",
      "63 Train Loss 1.4701847 Test MSE 5.750704883490565 Test RE 1.1462216328896078\n",
      "64 Train Loss 1.4553543 Test MSE 5.744839615249508 Test RE 1.1456369556579757\n",
      "65 Train Loss 1.4419224 Test MSE 5.734090211041907 Test RE 1.1445646297387475\n",
      "66 Train Loss 1.4279301 Test MSE 5.748301822319236 Test RE 1.1459821206413783\n",
      "67 Train Loss 1.407336 Test MSE 5.765403506903485 Test RE 1.1476855515345636\n",
      "68 Train Loss 1.3899071 Test MSE 5.7809445282007825 Test RE 1.1492313411819275\n",
      "69 Train Loss 1.3733623 Test MSE 5.764169399033437 Test RE 1.1475627116004024\n",
      "70 Train Loss 1.3626696 Test MSE 5.770714894016632 Test RE 1.1482140834010257\n",
      "71 Train Loss 1.3516577 Test MSE 5.800915136029482 Test RE 1.1512146729031982\n",
      "72 Train Loss 1.3399329 Test MSE 5.805201397987172 Test RE 1.1516399072306565\n",
      "73 Train Loss 1.3312681 Test MSE 5.8170027091327485 Test RE 1.1528098890957659\n",
      "74 Train Loss 1.3191222 Test MSE 5.820917018261846 Test RE 1.1531976915119735\n",
      "75 Train Loss 1.3119974 Test MSE 5.797104627879553 Test RE 1.150836505543929\n",
      "76 Train Loss 1.3004148 Test MSE 5.8051989907549855 Test RE 1.1516396684564303\n",
      "77 Train Loss 1.2923188 Test MSE 5.836415112538533 Test RE 1.1547318558092665\n",
      "78 Train Loss 1.2856047 Test MSE 5.851044924093905 Test RE 1.1561782005147394\n",
      "79 Train Loss 1.2762145 Test MSE 5.876489133343907 Test RE 1.1586893867667818\n",
      "80 Train Loss 1.2691541 Test MSE 5.876831867852185 Test RE 1.158723175397887\n",
      "81 Train Loss 1.2622828 Test MSE 5.879241388993283 Test RE 1.1589606912848585\n",
      "82 Train Loss 1.2550237 Test MSE 5.897514124195398 Test RE 1.1607603241855533\n",
      "83 Train Loss 1.2475854 Test MSE 5.905327175904259 Test RE 1.161528959795616\n",
      "84 Train Loss 1.2405032 Test MSE 5.904265821668716 Test RE 1.1614245753100993\n",
      "85 Train Loss 1.2346134 Test MSE 5.907353876648009 Test RE 1.1617282603248376\n",
      "86 Train Loss 1.2269748 Test MSE 5.899948927331401 Test RE 1.160999910829596\n",
      "87 Train Loss 1.219592 Test MSE 5.902958241835725 Test RE 1.161295961568009\n",
      "88 Train Loss 1.2109989 Test MSE 5.955342268143312 Test RE 1.1664373660486962\n",
      "89 Train Loss 1.2044152 Test MSE 5.947622364770384 Test RE 1.1656810951689895\n",
      "90 Train Loss 1.1982342 Test MSE 5.941132140654533 Test RE 1.165044908458417\n",
      "91 Train Loss 1.1917633 Test MSE 5.935636249727105 Test RE 1.1645059168105993\n",
      "92 Train Loss 1.186044 Test MSE 5.936474233701348 Test RE 1.1645881154844882\n",
      "93 Train Loss 1.1789442 Test MSE 5.935247329290498 Test RE 1.1644677652502933\n",
      "94 Train Loss 1.1710656 Test MSE 5.9482085904976705 Test RE 1.1657385412682975\n",
      "95 Train Loss 1.162171 Test MSE 5.949455571367804 Test RE 1.1658607274240547\n",
      "96 Train Loss 1.1543343 Test MSE 5.925747032967008 Test RE 1.163535435164056\n",
      "97 Train Loss 1.1477661 Test MSE 5.913395616846175 Test RE 1.1623221867054425\n",
      "98 Train Loss 1.1429737 Test MSE 5.928348748222994 Test RE 1.1637908338230671\n",
      "99 Train Loss 1.1371332 Test MSE 5.924817373098378 Test RE 1.1634441610493844\n",
      "Training time: 67.64\n",
      "7\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 53.39673 Test MSE 8.122782943760182 Test RE 1.362261504856137\n",
      "1 Train Loss 33.583637 Test MSE 6.510152475194231 Test RE 1.219561316549933\n",
      "2 Train Loss 24.71423 Test MSE 5.242866174072843 Test RE 1.0944412323726533\n",
      "3 Train Loss 21.701147 Test MSE 4.905006988367684 Test RE 1.0585902155158458\n",
      "4 Train Loss 18.316158 Test MSE 4.9945083942733355 Test RE 1.068204575739132\n",
      "5 Train Loss 13.501732 Test MSE 5.2786593648883695 Test RE 1.0981707679083401\n",
      "6 Train Loss 11.060768 Test MSE 5.328389215663264 Test RE 1.103331533493764\n",
      "7 Train Loss 9.624912 Test MSE 4.8757454803148175 Test RE 1.0554279078632185\n",
      "8 Train Loss 8.606976 Test MSE 4.343398215411844 Test RE 0.9961457457802392\n",
      "9 Train Loss 8.173153 Test MSE 4.162202330090947 Test RE 0.9751460238916235\n",
      "10 Train Loss 7.707846 Test MSE 3.90166360560706 Test RE 0.9441325519689392\n",
      "11 Train Loss 7.2445536 Test MSE 3.6465380124530293 Test RE 0.9127428358439691\n",
      "12 Train Loss 6.269742 Test MSE 3.6339633620921137 Test RE 0.9111677345125924\n",
      "13 Train Loss 4.914451 Test MSE 2.9106418517884607 Test RE 0.8154595912070044\n",
      "14 Train Loss 4.01561 Test MSE 2.5200678465371684 Test RE 0.7587770328240173\n",
      "15 Train Loss 3.0615501 Test MSE 2.0607376019816614 Test RE 0.6861505378708376\n",
      "16 Train Loss 2.244821 Test MSE 1.8146201318466553 Test RE 0.6438740507964233\n",
      "17 Train Loss 1.8238004 Test MSE 1.6741774243373984 Test RE 0.6184559910653138\n",
      "18 Train Loss 1.522328 Test MSE 1.2875566136953314 Test RE 0.542364464861333\n",
      "19 Train Loss 1.0109252 Test MSE 0.8683445296580565 Test RE 0.4454039832620737\n",
      "20 Train Loss 0.70282155 Test MSE 0.6090936056206387 Test RE 0.37303542861369576\n",
      "21 Train Loss 0.44237563 Test MSE 0.31750434961217777 Test RE 0.26932886437804565\n",
      "22 Train Loss 0.3398793 Test MSE 0.21354318932818103 Test RE 0.2208772175056019\n",
      "23 Train Loss 0.19428335 Test MSE 0.10780446549502619 Test RE 0.15693739359505365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 0.14627199 Test MSE 0.07256537933197217 Test RE 0.12875757694244908\n",
      "25 Train Loss 0.0987427 Test MSE 0.045800793967809665 Test RE 0.10229268156177171\n",
      "26 Train Loss 0.06867748 Test MSE 0.02451858329809906 Test RE 0.07484378570872441\n",
      "27 Train Loss 0.051051892 Test MSE 0.024107708715854104 Test RE 0.07421403214030665\n",
      "28 Train Loss 0.039667815 Test MSE 0.019927162409908872 Test RE 0.06747311965878446\n",
      "29 Train Loss 0.02935118 Test MSE 0.014709142184534466 Test RE 0.0579697908272419\n",
      "30 Train Loss 0.024167407 Test MSE 0.014203382200814185 Test RE 0.05696445505878755\n",
      "31 Train Loss 0.019028258 Test MSE 0.012506444980838709 Test RE 0.05345335867027356\n",
      "32 Train Loss 0.015638223 Test MSE 0.010795848812868047 Test RE 0.04966340101244785\n",
      "33 Train Loss 0.013462186 Test MSE 0.010088969293026438 Test RE 0.048009972851336034\n",
      "34 Train Loss 0.011157122 Test MSE 0.00793035955172223 Test RE 0.0425651824543594\n",
      "35 Train Loss 0.010138599 Test MSE 0.00614584807065163 Test RE 0.03747131810666024\n",
      "36 Train Loss 0.009224799 Test MSE 0.005144712522010576 Test RE 0.03428377343063796\n",
      "37 Train Loss 0.008475973 Test MSE 0.0047954133927197015 Test RE 0.033099473539688236\n",
      "38 Train Loss 0.007546531 Test MSE 0.004479852993077884 Test RE 0.03199189322797612\n",
      "39 Train Loss 0.0066322978 Test MSE 0.004228708879862888 Test RE 0.031082214566730954\n",
      "40 Train Loss 0.006308677 Test MSE 0.004097158478786433 Test RE 0.030594928437890707\n",
      "41 Train Loss 0.005655634 Test MSE 0.00371182645779215 Test RE 0.02912070546698627\n",
      "42 Train Loss 0.0050725453 Test MSE 0.003294334877790658 Test RE 0.027434176754403572\n",
      "43 Train Loss 0.0046125534 Test MSE 0.0027831248427608577 Test RE 0.02521589597866507\n",
      "44 Train Loss 0.004233171 Test MSE 0.0025183808231049394 Test RE 0.023986603821491224\n",
      "45 Train Loss 0.0040103993 Test MSE 0.002490224317971179 Test RE 0.02385213700330201\n",
      "46 Train Loss 0.003623992 Test MSE 0.0023947206712150834 Test RE 0.023390283830137252\n",
      "47 Train Loss 0.003299328 Test MSE 0.0026118416368646376 Test RE 0.024427638298465976\n",
      "48 Train Loss 0.0031658807 Test MSE 0.0026847869585051613 Test RE 0.024766405255293465\n",
      "49 Train Loss 0.0030633663 Test MSE 0.002717731586744991 Test RE 0.02491789441588555\n",
      "50 Train Loss 0.002935721 Test MSE 0.0024729089048183173 Test RE 0.023769066160774156\n",
      "51 Train Loss 0.0027372956 Test MSE 0.0022862315678701746 Test RE 0.022854312889267696\n",
      "52 Train Loss 0.0026554547 Test MSE 0.0022275201844687217 Test RE 0.022558950136920296\n",
      "53 Train Loss 0.002585695 Test MSE 0.002231190687189241 Test RE 0.02257752878010859\n",
      "54 Train Loss 0.002449775 Test MSE 0.0020420854104206583 Test RE 0.021599565332975808\n",
      "55 Train Loss 0.0023383473 Test MSE 0.002056822644486011 Test RE 0.021677364627210472\n",
      "56 Train Loss 0.0022110273 Test MSE 0.0021456761291379404 Test RE 0.02214063870596766\n",
      "57 Train Loss 0.002087677 Test MSE 0.002063790719342976 Test RE 0.02171405271629515\n",
      "58 Train Loss 0.0019287842 Test MSE 0.0019074857393341573 Test RE 0.020875587669647675\n",
      "59 Train Loss 0.0018201487 Test MSE 0.0019416042801580025 Test RE 0.021061457431694252\n",
      "60 Train Loss 0.0016861538 Test MSE 0.0018798027659571947 Test RE 0.020723552345944512\n",
      "61 Train Loss 0.0016265736 Test MSE 0.001974040756953248 Test RE 0.021236655295262963\n",
      "62 Train Loss 0.001549614 Test MSE 0.0018724638990325418 Test RE 0.020683059767212804\n",
      "63 Train Loss 0.0013839342 Test MSE 0.0017764423723655265 Test RE 0.02014575843445183\n",
      "64 Train Loss 0.0013049986 Test MSE 0.0015768234846060174 Test RE 0.018980148239461904\n",
      "65 Train Loss 0.0012829703 Test MSE 0.0015790512339634254 Test RE 0.018993551162981494\n",
      "66 Train Loss 0.0012492492 Test MSE 0.0015645404958836583 Test RE 0.018906078841336334\n",
      "67 Train Loss 0.0011876065 Test MSE 0.0014728635107537336 Test RE 0.018343800213524452\n",
      "68 Train Loss 0.0011597315 Test MSE 0.001382924630499506 Test RE 0.017774906139584136\n",
      "69 Train Loss 0.0011183138 Test MSE 0.0012819879884354173 Test RE 0.017113941310906367\n",
      "70 Train Loss 0.0010607145 Test MSE 0.0011899127931767918 Test RE 0.01648791072210227\n",
      "71 Train Loss 0.0010332976 Test MSE 0.0011416746830749912 Test RE 0.016150249855917242\n",
      "72 Train Loss 0.0010119387 Test MSE 0.0011201113849285825 Test RE 0.015997004464655813\n",
      "73 Train Loss 0.0009685286 Test MSE 0.001086780600552862 Test RE 0.015757198245606112\n",
      "74 Train Loss 0.0009451986 Test MSE 0.0010227516198064834 Test RE 0.015285975116511079\n",
      "75 Train Loss 0.00093162066 Test MSE 0.0010171450515948164 Test RE 0.015244019848646942\n",
      "76 Train Loss 0.0009130774 Test MSE 0.0010016341625812318 Test RE 0.015127341964408287\n",
      "77 Train Loss 0.0008934632 Test MSE 0.0009453884678224104 Test RE 0.014696476022847125\n",
      "78 Train Loss 0.0008575553 Test MSE 0.0009337084396414156 Test RE 0.014605408303260391\n",
      "79 Train Loss 0.0008327221 Test MSE 0.0009309272549128643 Test RE 0.014583639927655365\n",
      "80 Train Loss 0.00079650414 Test MSE 0.0008396273210178704 Test RE 0.013850049998585122\n",
      "81 Train Loss 0.0007652388 Test MSE 0.0008140884458505113 Test RE 0.01363778551052693\n",
      "82 Train Loss 0.0007453205 Test MSE 0.000821498378451244 Test RE 0.013699711311515513\n",
      "83 Train Loss 0.000717758 Test MSE 0.0007723637936225099 Test RE 0.013283698619970693\n",
      "84 Train Loss 0.0007001267 Test MSE 0.0007891739638349474 Test RE 0.013427477540929312\n",
      "85 Train Loss 0.0006780594 Test MSE 0.0007527383910265083 Test RE 0.013113846428146772\n",
      "86 Train Loss 0.0006431629 Test MSE 0.0006962904657820228 Test RE 0.012612561140127487\n",
      "87 Train Loss 0.0006147109 Test MSE 0.0007240608571478775 Test RE 0.012861617667259892\n",
      "88 Train Loss 0.0006062164 Test MSE 0.0007049490040701167 Test RE 0.012690738956554813\n",
      "89 Train Loss 0.00059197843 Test MSE 0.0006715325308948497 Test RE 0.01238629982041718\n",
      "90 Train Loss 0.0005780944 Test MSE 0.0007089835469392037 Test RE 0.012727002771722049\n",
      "91 Train Loss 0.0005478546 Test MSE 0.0006433961231387019 Test RE 0.012124037755061353\n",
      "92 Train Loss 0.0005308605 Test MSE 0.0006200611257180027 Test RE 0.01190214707353023\n",
      "93 Train Loss 0.0005224865 Test MSE 0.0005693042894348247 Test RE 0.011404606057377153\n",
      "94 Train Loss 0.0005090577 Test MSE 0.0005590320372794426 Test RE 0.011301248092779381\n",
      "95 Train Loss 0.0004900992 Test MSE 0.0005256598885513967 Test RE 0.010958736374888405\n",
      "96 Train Loss 0.0004762433 Test MSE 0.00047108224084892625 Test RE 0.010374243238237045\n",
      "97 Train Loss 0.00046989153 Test MSE 0.00046070011959628516 Test RE 0.010259288028852277\n",
      "98 Train Loss 0.00046214982 Test MSE 0.0004546612998260935 Test RE 0.010191827274768592\n",
      "99 Train Loss 0.00045538563 Test MSE 0.00045822553319781217 Test RE 0.010231697762705227\n",
      "Training time: 66.95\n",
      "8\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 58.436172 Test MSE 8.47702683263234 Test RE 1.3916494080399173\n",
      "1 Train Loss 30.552809 Test MSE 7.893715717652246 Test RE 1.3429158545427549\n",
      "2 Train Loss 22.98772 Test MSE 7.598155445272702 Test RE 1.3175349588314411\n",
      "3 Train Loss 18.226751 Test MSE 7.377268222167865 Test RE 1.2982425742494235\n",
      "4 Train Loss 15.759254 Test MSE 6.970611049523043 Test RE 1.2619538864381505\n",
      "5 Train Loss 13.521008 Test MSE 7.03677487702766 Test RE 1.2679288649429177\n",
      "6 Train Loss 11.410468 Test MSE 7.107144437055767 Test RE 1.274252901282403\n",
      "7 Train Loss 10.075365 Test MSE 6.794588475390638 Test RE 1.245918513962049\n",
      "8 Train Loss 8.88733 Test MSE 6.564961518494093 Test RE 1.224684306405296\n",
      "9 Train Loss 8.272985 Test MSE 6.282349069102698 Test RE 1.198033858398773\n",
      "10 Train Loss 7.583438 Test MSE 6.020300628257511 Test RE 1.1727816161254263\n",
      "11 Train Loss 7.063649 Test MSE 5.796419236474488 Test RE 1.1507684718602447\n",
      "12 Train Loss 6.5155573 Test MSE 5.57775198134026 Test RE 1.1288536975654706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train Loss 5.997298 Test MSE 5.447181217383196 Test RE 1.1155626675432357\n",
      "14 Train Loss 5.217558 Test MSE 5.040623791516364 Test RE 1.073124728808246\n",
      "15 Train Loss 4.417044 Test MSE 4.599740753942737 Test RE 1.025120073595086\n",
      "16 Train Loss 3.04135 Test MSE 4.023025016908955 Test RE 0.9587037516640203\n",
      "17 Train Loss 2.3860323 Test MSE 4.106343566998011 Test RE 0.9685804561897361\n",
      "18 Train Loss 2.1139205 Test MSE 4.096068300532101 Test RE 0.9673678620796166\n",
      "19 Train Loss 1.9415454 Test MSE 3.9618437210257986 Test RE 0.9513859433270087\n",
      "20 Train Loss 1.8067852 Test MSE 3.723482317597229 Test RE 0.9223222978424367\n",
      "21 Train Loss 1.6115255 Test MSE 3.351436112822201 Test RE 0.8750311885970617\n",
      "22 Train Loss 1.4616523 Test MSE 3.194119817197149 Test RE 0.8542473926647858\n",
      "23 Train Loss 1.3363764 Test MSE 3.092508052202535 Test RE 0.8405498593774978\n",
      "24 Train Loss 1.2442836 Test MSE 2.9211286165481227 Test RE 0.8169272819423371\n",
      "25 Train Loss 1.1587315 Test MSE 2.8993768447659742 Test RE 0.8138800317852751\n",
      "26 Train Loss 1.1083579 Test MSE 2.811611851990519 Test RE 0.8014671804083098\n",
      "27 Train Loss 1.0663394 Test MSE 2.82469573223977 Test RE 0.8033298360530389\n",
      "28 Train Loss 1.0133792 Test MSE 2.7163173136058254 Test RE 0.7877679562247821\n",
      "29 Train Loss 0.9625971 Test MSE 2.6476655021491244 Test RE 0.7777492817077124\n",
      "30 Train Loss 0.92729974 Test MSE 2.6162776954602687 Test RE 0.7731254676104764\n",
      "31 Train Loss 0.8959678 Test MSE 2.5608015235188226 Test RE 0.7648847814152101\n",
      "32 Train Loss 0.8463448 Test MSE 2.5350765926441374 Test RE 0.7610331994330849\n",
      "33 Train Loss 0.8157943 Test MSE 2.537625246994568 Test RE 0.7614156579602405\n",
      "34 Train Loss 0.78529465 Test MSE 2.5335008579216995 Test RE 0.7607966438899276\n",
      "35 Train Loss 0.76199335 Test MSE 2.542927423620119 Test RE 0.7622107031848027\n",
      "36 Train Loss 0.74142164 Test MSE 2.561104596612714 Test RE 0.7649300424665925\n",
      "37 Train Loss 0.7253847 Test MSE 2.541504111976445 Test RE 0.7619973633929441\n",
      "38 Train Loss 0.7074882 Test MSE 2.5610317110524474 Test RE 0.7649191579538226\n",
      "39 Train Loss 0.6956335 Test MSE 2.564396910510523 Test RE 0.7654215454262604\n",
      "40 Train Loss 0.68354183 Test MSE 2.576566728860401 Test RE 0.7672356202513279\n",
      "41 Train Loss 0.66602695 Test MSE 2.5877238244410066 Test RE 0.7688949745898108\n",
      "42 Train Loss 0.6544633 Test MSE 2.6112032916008596 Test RE 0.7723753455958633\n",
      "43 Train Loss 0.64292306 Test MSE 2.6221816918567367 Test RE 0.7739973088831301\n",
      "44 Train Loss 0.63248134 Test MSE 2.640424354752311 Test RE 0.7766850133773362\n",
      "45 Train Loss 0.62588865 Test MSE 2.6475531797885856 Test RE 0.7777327842382086\n",
      "46 Train Loss 0.6172213 Test MSE 2.6620178432551893 Test RE 0.7798544261300278\n",
      "47 Train Loss 0.6092981 Test MSE 2.66957158618997 Test RE 0.7809600999418751\n",
      "48 Train Loss 0.6005907 Test MSE 2.6735854056761545 Test RE 0.7815469835271099\n",
      "49 Train Loss 0.5935392 Test MSE 2.6975350299785252 Test RE 0.7850396764285833\n",
      "50 Train Loss 0.5852031 Test MSE 2.7066744896545685 Test RE 0.7863684398055141\n",
      "51 Train Loss 0.577972 Test MSE 2.705561389572435 Test RE 0.7862067290442706\n",
      "52 Train Loss 0.56955326 Test MSE 2.7343765160487417 Test RE 0.7903823218874084\n",
      "53 Train Loss 0.56173 Test MSE 2.7608154474342346 Test RE 0.7941942682644981\n",
      "54 Train Loss 0.5554352 Test MSE 2.760311694028738 Test RE 0.7941218084556753\n",
      "55 Train Loss 0.5503495 Test MSE 2.7698414260015065 Test RE 0.7954914449886006\n",
      "56 Train Loss 0.5446919 Test MSE 2.787918588057822 Test RE 0.7980830809239639\n",
      "57 Train Loss 0.54103583 Test MSE 2.804933616479395 Test RE 0.800514778558459\n",
      "58 Train Loss 0.5363564 Test MSE 2.8198617495749434 Test RE 0.8026421610455109\n",
      "59 Train Loss 0.529893 Test MSE 2.8584703548272987 Test RE 0.8081182348211999\n",
      "60 Train Loss 0.5235253 Test MSE 2.858636562745548 Test RE 0.8081417288023197\n",
      "61 Train Loss 0.51853216 Test MSE 2.878833072792302 Test RE 0.8109914991613636\n",
      "62 Train Loss 0.51258886 Test MSE 2.9086832164430527 Test RE 0.8151851746271455\n",
      "63 Train Loss 0.5068984 Test MSE 2.932694966257854 Test RE 0.8185430156244821\n",
      "64 Train Loss 0.50317526 Test MSE 2.948965829033961 Test RE 0.8208105510098954\n",
      "65 Train Loss 0.49949494 Test MSE 2.9449183399231695 Test RE 0.8202470716938138\n",
      "66 Train Loss 0.49341953 Test MSE 2.9733989182017613 Test RE 0.8242038708061624\n",
      "67 Train Loss 0.48942545 Test MSE 2.9631213146655666 Test RE 0.8227782004825129\n",
      "68 Train Loss 0.48508132 Test MSE 2.972483322285886 Test RE 0.824076962876654\n",
      "69 Train Loss 0.48084688 Test MSE 2.996405867950924 Test RE 0.8273864033089774\n",
      "70 Train Loss 0.47680745 Test MSE 3.0007338908899066 Test RE 0.8279837281273343\n",
      "71 Train Loss 0.47314978 Test MSE 2.9939400303063937 Test RE 0.8270458919531988\n",
      "72 Train Loss 0.46945637 Test MSE 2.9999452758762355 Test RE 0.8278749208606521\n",
      "73 Train Loss 0.46656853 Test MSE 3.013047554556209 Test RE 0.8296808254831726\n",
      "74 Train Loss 0.46309522 Test MSE 3.018849371228297 Test RE 0.8304792431875074\n",
      "75 Train Loss 0.4597583 Test MSE 3.0144582167179137 Test RE 0.8298750246066452\n",
      "76 Train Loss 0.45581523 Test MSE 3.011097957869014 Test RE 0.8294123589716829\n",
      "77 Train Loss 0.45260155 Test MSE 3.007996260902743 Test RE 0.8289850648961125\n",
      "78 Train Loss 0.44973642 Test MSE 3.0059875455932112 Test RE 0.8287082239461018\n",
      "79 Train Loss 0.4469218 Test MSE 3.0267962397030805 Test RE 0.8315716083434349\n",
      "80 Train Loss 0.4438673 Test MSE 3.0300098472061587 Test RE 0.8320129389789894\n",
      "81 Train Loss 0.44078684 Test MSE 3.0391277928617133 Test RE 0.83326385078382\n",
      "82 Train Loss 0.43861938 Test MSE 3.0348571921226957 Test RE 0.8326781912692836\n",
      "83 Train Loss 0.43620974 Test MSE 3.0477543674586043 Test RE 0.8344456239013645\n",
      "84 Train Loss 0.43412817 Test MSE 3.053707341949529 Test RE 0.8352601597270517\n",
      "85 Train Loss 0.4310441 Test MSE 3.0720917302601336 Test RE 0.8377706662957731\n",
      "86 Train Loss 0.4282306 Test MSE 3.0778889693930767 Test RE 0.8385607579046397\n",
      "87 Train Loss 0.4255855 Test MSE 3.071006655058375 Test RE 0.837622701238366\n",
      "88 Train Loss 0.42308402 Test MSE 3.0782780652367254 Test RE 0.8386137601730186\n",
      "89 Train Loss 0.42038184 Test MSE 3.0836197177382316 Test RE 0.8393410566605901\n",
      "90 Train Loss 0.4183696 Test MSE 3.0829017405504575 Test RE 0.8392433366320153\n",
      "91 Train Loss 0.41596207 Test MSE 3.0846796932492224 Test RE 0.8394853034556543\n",
      "92 Train Loss 0.41372108 Test MSE 3.077843090157026 Test RE 0.8385545080576331\n",
      "93 Train Loss 0.4112516 Test MSE 3.0778378414003105 Test RE 0.8385537930487205\n",
      "94 Train Loss 0.40768582 Test MSE 3.1217798501476697 Test RE 0.8445185567232194\n",
      "95 Train Loss 0.40490803 Test MSE 3.1182564754393964 Test RE 0.8440418422325626\n",
      "96 Train Loss 0.4004706 Test MSE 3.15245347472878 Test RE 0.8486574013698313\n",
      "97 Train Loss 0.39766383 Test MSE 3.169458098590846 Test RE 0.8509431910973769\n",
      "98 Train Loss 0.39425117 Test MSE 3.188335378624513 Test RE 0.8534735361677626\n",
      "99 Train Loss 0.39046037 Test MSE 3.198545372136968 Test RE 0.854838981331425\n",
      "Training time: 67.03\n",
      "9\n",
      "KG_rowdy_tune17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.799194 Test MSE 8.572944570980061 Test RE 1.3995005328789556\n",
      "1 Train Loss 49.73327 Test MSE 8.789176184635949 Test RE 1.4170401167841071\n",
      "2 Train Loss 44.078274 Test MSE 8.690359081867351 Test RE 1.409051676865383\n",
      "3 Train Loss 42.349854 Test MSE 8.402369348372089 Test RE 1.3855077020499114\n",
      "4 Train Loss 40.5851 Test MSE 8.636971909869953 Test RE 1.4047169208468824\n",
      "5 Train Loss 37.608826 Test MSE 8.495637124865523 Test RE 1.393176169941642\n",
      "6 Train Loss 33.90451 Test MSE 8.997889766536943 Test RE 1.4337663863279198\n",
      "7 Train Loss 30.284996 Test MSE 8.452847383557666 Test RE 1.38966325500262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 28.672943 Test MSE 8.761430276624031 Test RE 1.4148016735973448\n",
      "9 Train Loss 27.725666 Test MSE 8.742572306469798 Test RE 1.413278254536454\n",
      "10 Train Loss 26.60151 Test MSE 8.47309586904497 Test RE 1.3913267030631773\n",
      "11 Train Loss 25.278633 Test MSE 8.08897683909069 Test RE 1.35942375996612\n",
      "12 Train Loss 23.06371 Test MSE 7.401940489805667 Test RE 1.3004116598439557\n",
      "13 Train Loss 19.137466 Test MSE 6.3187775542509295 Test RE 1.2015022644889046\n",
      "14 Train Loss 17.019121 Test MSE 6.094222395474072 Test RE 1.1799597948074863\n",
      "15 Train Loss 16.200315 Test MSE 6.122137917576804 Test RE 1.1826592006532166\n",
      "16 Train Loss 15.432764 Test MSE 6.08228911306616 Test RE 1.178803971118114\n",
      "17 Train Loss 14.524885 Test MSE 5.849113576266421 Test RE 1.155987365665224\n",
      "18 Train Loss 13.762827 Test MSE 5.760740934189093 Test RE 1.1472213819702033\n",
      "19 Train Loss 13.153677 Test MSE 5.83868933757901 Test RE 1.154956811049459\n",
      "20 Train Loss 11.876123 Test MSE 4.879176484281211 Test RE 1.0557991885762854\n",
      "21 Train Loss 8.944563 Test MSE 4.23630167850356 Test RE 0.9837879532235103\n",
      "22 Train Loss 8.078831 Test MSE 3.749605826885265 Test RE 0.9255520945738596\n",
      "23 Train Loss 7.319489 Test MSE 3.5545941448003835 Test RE 0.9011624163751758\n",
      "24 Train Loss 6.9923363 Test MSE 3.4433524373272504 Test RE 0.8869493063987641\n",
      "25 Train Loss 6.785917 Test MSE 3.4742843709449116 Test RE 0.89092417099432\n",
      "26 Train Loss 6.5844746 Test MSE 3.4089692325448047 Test RE 0.8825099305793717\n",
      "27 Train Loss 6.2882414 Test MSE 3.3121202648407717 Test RE 0.8698835320708213\n",
      "28 Train Loss 6.0257034 Test MSE 3.332659212666085 Test RE 0.872576501892403\n",
      "29 Train Loss 5.570209 Test MSE 3.1139537216168223 Test RE 0.8434593119040575\n",
      "30 Train Loss 3.910184 Test MSE 2.4411466982689065 Test RE 0.7468011871058257\n",
      "31 Train Loss 2.9668844 Test MSE 2.3542861158951363 Test RE 0.7333945545378664\n",
      "32 Train Loss 2.5325181 Test MSE 2.4809721000133793 Test RE 0.7528682812812305\n",
      "33 Train Loss 2.102528 Test MSE 2.4316835746670127 Test RE 0.7453522913591659\n",
      "34 Train Loss 1.7805607 Test MSE 2.5355953790498353 Test RE 0.7611110656171621\n",
      "35 Train Loss 1.6512567 Test MSE 2.534889424285219 Test RE 0.7610051048254717\n",
      "36 Train Loss 1.5772005 Test MSE 2.567526696576705 Test RE 0.7658884924847358\n",
      "37 Train Loss 1.4888597 Test MSE 2.5567352523047426 Test RE 0.7642772636914014\n",
      "38 Train Loss 1.4340305 Test MSE 2.542117127103889 Test RE 0.7620892553841353\n",
      "39 Train Loss 1.3848581 Test MSE 2.5478082642230984 Test RE 0.7629418379967338\n",
      "40 Train Loss 1.3501949 Test MSE 2.5441081859141508 Test RE 0.7623876420153889\n",
      "41 Train Loss 1.318485 Test MSE 2.53731755688868 Test RE 0.761369495279834\n",
      "42 Train Loss 1.2703788 Test MSE 2.5289469860050744 Test RE 0.760112584770827\n",
      "43 Train Loss 1.2279873 Test MSE 2.531956494932303 Test RE 0.7605647266033908\n",
      "44 Train Loss 1.2003471 Test MSE 2.5548377030913216 Test RE 0.7639935966779199\n",
      "45 Train Loss 1.1541933 Test MSE 2.5287000596279054 Test RE 0.7600754751695544\n",
      "46 Train Loss 1.1223228 Test MSE 2.539351501893723 Test RE 0.7616745957315093\n",
      "47 Train Loss 1.0914237 Test MSE 2.523834031215344 Test RE 0.7593438087435962\n",
      "48 Train Loss 1.0655382 Test MSE 2.5391894572390874 Test RE 0.7616502928207409\n",
      "49 Train Loss 1.0432401 Test MSE 2.5297535914949885 Test RE 0.7602337937378811\n",
      "50 Train Loss 1.0126543 Test MSE 2.5148952875129846 Test RE 0.7579979198662475\n",
      "51 Train Loss 0.9880677 Test MSE 2.527406862162659 Test RE 0.7598810959715238\n",
      "52 Train Loss 0.95758474 Test MSE 2.538110877640682 Test RE 0.7614885113276371\n",
      "53 Train Loss 0.93430185 Test MSE 2.525600651694246 Test RE 0.759609523057483\n",
      "54 Train Loss 0.9013396 Test MSE 2.5731040851425857 Test RE 0.766719903591928\n",
      "55 Train Loss 0.8777803 Test MSE 2.5896172023347677 Test RE 0.7691762145227029\n",
      "56 Train Loss 0.8561038 Test MSE 2.586649646360132 Test RE 0.7687353718048839\n",
      "57 Train Loss 0.8429934 Test MSE 2.598370046305784 Test RE 0.7704750165377483\n",
      "58 Train Loss 0.83660775 Test MSE 2.600026434833551 Test RE 0.7707205555937613\n",
      "59 Train Loss 0.828485 Test MSE 2.594842974659243 Test RE 0.7699519110205698\n",
      "60 Train Loss 0.8152248 Test MSE 2.597224021919113 Test RE 0.7703050868269931\n",
      "61 Train Loss 0.8056101 Test MSE 2.604780513011952 Test RE 0.771424854662435\n",
      "62 Train Loss 0.7953185 Test MSE 2.6108399642149442 Test RE 0.7723216088993543\n",
      "63 Train Loss 0.7893067 Test MSE 2.59974653671405 Test RE 0.7706790696616656\n",
      "64 Train Loss 0.7785646 Test MSE 2.622667341298945 Test RE 0.7740689808728268\n",
      "65 Train Loss 0.7624944 Test MSE 2.6409929963657754 Test RE 0.776768642291417\n",
      "66 Train Loss 0.75283766 Test MSE 2.6467956167644777 Test RE 0.7776215072000033\n",
      "67 Train Loss 0.7459451 Test MSE 2.65572529658788 Test RE 0.7789321607518401\n",
      "68 Train Loss 0.73874795 Test MSE 2.646810297615981 Test RE 0.7776236637945607\n",
      "69 Train Loss 0.7334827 Test MSE 2.6521150035935674 Test RE 0.7784025258305639\n",
      "70 Train Loss 0.725911 Test MSE 2.6625347125884535 Test RE 0.7799301324732637\n",
      "71 Train Loss 0.72013783 Test MSE 2.6786691225581087 Test RE 0.7822896709826769\n",
      "72 Train Loss 0.71190464 Test MSE 2.679160246458365 Test RE 0.7823613826290057\n",
      "73 Train Loss 0.702942 Test MSE 2.710368822726025 Test RE 0.7869049129439174\n",
      "74 Train Loss 0.6981045 Test MSE 2.7095070443689755 Test RE 0.7867798023813958\n",
      "75 Train Loss 0.6918125 Test MSE 2.71004363231674 Test RE 0.7868577050501855\n",
      "76 Train Loss 0.6828169 Test MSE 2.7101043832542944 Test RE 0.7868665244792972\n",
      "77 Train Loss 0.67700934 Test MSE 2.7238090096310543 Test RE 0.7888535536904787\n",
      "78 Train Loss 0.67299056 Test MSE 2.7269774401312907 Test RE 0.7893122314497836\n",
      "79 Train Loss 0.66763556 Test MSE 2.727654528624814 Test RE 0.789410215586348\n",
      "80 Train Loss 0.66109 Test MSE 2.73301909142727 Test RE 0.7901861130617978\n",
      "81 Train Loss 0.6563132 Test MSE 2.7515010702228953 Test RE 0.7928534189758443\n",
      "82 Train Loss 0.6521259 Test MSE 2.7631624949447797 Test RE 0.7945317800833267\n",
      "83 Train Loss 0.64837515 Test MSE 2.7723824137336024 Test RE 0.795856243965018\n",
      "84 Train Loss 0.64314663 Test MSE 2.7793328071042676 Test RE 0.7968532296950485\n",
      "85 Train Loss 0.6405997 Test MSE 2.7809108091634274 Test RE 0.7970794094464189\n",
      "86 Train Loss 0.6363139 Test MSE 2.7866259201657115 Test RE 0.7978980367852033\n",
      "87 Train Loss 0.63320786 Test MSE 2.7891754022343678 Test RE 0.7982629515118724\n",
      "88 Train Loss 0.6301528 Test MSE 2.7906481230726965 Test RE 0.7984736703031169\n",
      "89 Train Loss 0.62694895 Test MSE 2.7899429194449636 Test RE 0.7983727758008465\n",
      "90 Train Loss 0.6238471 Test MSE 2.7920543408719496 Test RE 0.7986748218679615\n",
      "91 Train Loss 0.6196667 Test MSE 2.8049293981239445 Test RE 0.8005141766088928\n",
      "92 Train Loss 0.61684084 Test MSE 2.811236492355105 Test RE 0.8014136793409723\n",
      "93 Train Loss 0.61351013 Test MSE 2.8104552438239097 Test RE 0.8013023143301549\n",
      "94 Train Loss 0.61036015 Test MSE 2.8192990244740175 Test RE 0.8025620703412774\n",
      "95 Train Loss 0.60770726 Test MSE 2.820349777741892 Test RE 0.8027116139248734\n",
      "96 Train Loss 0.60479 Test MSE 2.82822723396132 Test RE 0.8038318502189478\n",
      "97 Train Loss 0.6013999 Test MSE 2.828802692177518 Test RE 0.8039136237252762\n",
      "98 Train Loss 0.5985778 Test MSE 2.8265986719233904 Test RE 0.8036003839268882\n",
      "99 Train Loss 0.59578305 Test MSE 2.832773273053823 Test RE 0.8044776228970568\n",
      "Training time: 67.04\n",
      "0\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 52.938583 Test MSE 7.053877927689391 Test RE 1.269468795609115\n",
      "1 Train Loss 28.98248 Test MSE 6.235525875151606 Test RE 1.193560954651865\n",
      "2 Train Loss 20.77415 Test MSE 6.092141441903628 Test RE 1.1797583210972042\n",
      "3 Train Loss 15.796776 Test MSE 5.907101491496291 Test RE 1.161703443283137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 13.588971 Test MSE 5.850131353081554 Test RE 1.156087935259877\n",
      "5 Train Loss 11.819648 Test MSE 5.935162424750856 Test RE 1.164459436283728\n",
      "6 Train Loss 10.641466 Test MSE 5.919724479153527 Test RE 1.1629440130090278\n",
      "7 Train Loss 9.548693 Test MSE 5.805026522049812 Test RE 1.1516225610947355\n",
      "8 Train Loss 8.986104 Test MSE 5.628399885674165 Test RE 1.1339673051764922\n",
      "9 Train Loss 8.198004 Test MSE 5.691170298092944 Test RE 1.1402730260949674\n",
      "10 Train Loss 6.9697037 Test MSE 5.2142273152810485 Test RE 1.0914479776088635\n",
      "11 Train Loss 6.2721205 Test MSE 5.113326095379466 Test RE 1.0808360094883414\n",
      "12 Train Loss 5.842968 Test MSE 4.916625877567682 Test RE 1.0598432583019783\n",
      "13 Train Loss 5.4818935 Test MSE 4.5373461390087995 Test RE 1.0181435538892918\n",
      "14 Train Loss 5.193577 Test MSE 4.121071349470997 Test RE 0.9703158534105769\n",
      "15 Train Loss 4.839397 Test MSE 3.6910510236183454 Test RE 0.9182968290248225\n",
      "16 Train Loss 4.5352473 Test MSE 3.3466119117850734 Test RE 0.8744011830696842\n",
      "17 Train Loss 4.155005 Test MSE 2.8142748336323318 Test RE 0.8018466401937686\n",
      "18 Train Loss 3.5262434 Test MSE 2.2483415846497463 Test RE 0.7167029744014002\n",
      "19 Train Loss 2.619974 Test MSE 1.885432047705368 Test RE 0.6563167719610536\n",
      "20 Train Loss 2.1798153 Test MSE 1.7254963549606106 Test RE 0.6278632783913104\n",
      "21 Train Loss 1.6835227 Test MSE 1.3112241783974619 Test RE 0.5473265740234542\n",
      "22 Train Loss 1.3813651 Test MSE 1.2495574987239422 Test RE 0.5343012409103014\n",
      "23 Train Loss 1.1064698 Test MSE 1.014159586437497 Test RE 0.48135025961823885\n",
      "24 Train Loss 0.9105789 Test MSE 0.8015705267803211 Test RE 0.42793610582848635\n",
      "25 Train Loss 0.6539069 Test MSE 0.5937310077505494 Test RE 0.3683010233787809\n",
      "26 Train Loss 0.46164215 Test MSE 0.4214203406249789 Test RE 0.3102885909089889\n",
      "27 Train Loss 0.34833774 Test MSE 0.27234498529497564 Test RE 0.2494409499482557\n",
      "28 Train Loss 0.23950416 Test MSE 0.11736608986574812 Test RE 0.16374927215281534\n",
      "29 Train Loss 0.16659366 Test MSE 0.044948876184940374 Test RE 0.10133686840811268\n",
      "30 Train Loss 0.12659584 Test MSE 0.0292849302656211 Test RE 0.08179564047898973\n",
      "31 Train Loss 0.08636874 Test MSE 0.025182582624084123 Test RE 0.07585045565380308\n",
      "32 Train Loss 0.07174078 Test MSE 0.021279213357437612 Test RE 0.0697245700348454\n",
      "33 Train Loss 0.05663792 Test MSE 0.015844254993908787 Test RE 0.06016500704533243\n",
      "34 Train Loss 0.045929097 Test MSE 0.011598813264681157 Test RE 0.051477190786497394\n",
      "35 Train Loss 0.036191102 Test MSE 0.008225514892275713 Test RE 0.04335005040389475\n",
      "36 Train Loss 0.02954888 Test MSE 0.009170759940223717 Test RE 0.045773141812170445\n",
      "37 Train Loss 0.024196653 Test MSE 0.009804400964188997 Test RE 0.0473280479458243\n",
      "38 Train Loss 0.019848032 Test MSE 0.010444107906768503 Test RE 0.04884765677199219\n",
      "39 Train Loss 0.016712496 Test MSE 0.008488345227165538 Test RE 0.04403718781584824\n",
      "40 Train Loss 0.014825226 Test MSE 0.007580261484061523 Test RE 0.04161502441876311\n",
      "41 Train Loss 0.013035137 Test MSE 0.006727336858569815 Test RE 0.039203933841177596\n",
      "42 Train Loss 0.011955084 Test MSE 0.006133021398509211 Test RE 0.03743219548728154\n",
      "43 Train Loss 0.01044074 Test MSE 0.005643554780524925 Test RE 0.03590743911652128\n",
      "44 Train Loss 0.009277775 Test MSE 0.004497702052800843 Test RE 0.032055562455593344\n",
      "45 Train Loss 0.008677878 Test MSE 0.004183215451352346 Test RE 0.030914567623457408\n",
      "46 Train Loss 0.0078070206 Test MSE 0.0043117819859789415 Test RE 0.03138603517700637\n",
      "47 Train Loss 0.0072611673 Test MSE 0.004456688631667275 Test RE 0.031909074411847226\n",
      "48 Train Loss 0.006649232 Test MSE 0.004322885192492087 Test RE 0.031426420054379976\n",
      "49 Train Loss 0.0060905227 Test MSE 0.004168742668015929 Test RE 0.030861043306712382\n",
      "50 Train Loss 0.005536965 Test MSE 0.0038806237502222924 Test RE 0.029775483950596482\n",
      "51 Train Loss 0.005176804 Test MSE 0.003409723210139888 Test RE 0.02791050041922904\n",
      "52 Train Loss 0.004811256 Test MSE 0.0030162495810553756 Test RE 0.026250748887748247\n",
      "53 Train Loss 0.004518808 Test MSE 0.0029614596499503414 Test RE 0.026011234843217917\n",
      "54 Train Loss 0.0042247693 Test MSE 0.002597642959749141 Test RE 0.024361150191217377\n",
      "55 Train Loss 0.0039305054 Test MSE 0.002398583513284063 Test RE 0.023409141262343152\n",
      "56 Train Loss 0.0037444704 Test MSE 0.0022042622278432558 Test RE 0.02244086998614332\n",
      "57 Train Loss 0.0034061242 Test MSE 0.002173307145362722 Test RE 0.022282741095580576\n",
      "58 Train Loss 0.0031713825 Test MSE 0.0018867035904422198 Test RE 0.020761555957820466\n",
      "59 Train Loss 0.0030029002 Test MSE 0.0017855170961620101 Test RE 0.020197148875342453\n",
      "60 Train Loss 0.0028211046 Test MSE 0.0017454485355707242 Test RE 0.019969242198067345\n",
      "61 Train Loss 0.0025549892 Test MSE 0.0017118840021877906 Test RE 0.019776308443301468\n",
      "62 Train Loss 0.0024979643 Test MSE 0.0016667844868851814 Test RE 0.019514066702296058\n",
      "63 Train Loss 0.0023816023 Test MSE 0.0016168959988477698 Test RE 0.019219810591756058\n",
      "64 Train Loss 0.0022176832 Test MSE 0.001541910842776777 Test RE 0.018768851211450905\n",
      "65 Train Loss 0.0021087355 Test MSE 0.0013995504954995195 Test RE 0.017881434098288993\n",
      "66 Train Loss 0.0020324523 Test MSE 0.0013610402406433254 Test RE 0.01763370386753659\n",
      "67 Train Loss 0.0019722027 Test MSE 0.0014004561952860963 Test RE 0.01788721902417026\n",
      "68 Train Loss 0.0019005791 Test MSE 0.0013522221273836851 Test RE 0.017576487087603686\n",
      "69 Train Loss 0.0017964804 Test MSE 0.001301177360316832 Test RE 0.017241550137297442\n",
      "70 Train Loss 0.0017431687 Test MSE 0.001241902951244564 Test RE 0.01684425819589518\n",
      "71 Train Loss 0.0016820462 Test MSE 0.0011257177217015922 Test RE 0.016036988279713622\n",
      "72 Train Loss 0.0015938092 Test MSE 0.001125656922792412 Test RE 0.016036555202868237\n",
      "73 Train Loss 0.0015513685 Test MSE 0.0010536309331043347 Test RE 0.015515019168546012\n",
      "74 Train Loss 0.0015060359 Test MSE 0.001032009843506037 Test RE 0.015355005633932037\n",
      "75 Train Loss 0.0014782946 Test MSE 0.0010378027548338486 Test RE 0.015398040935980233\n",
      "76 Train Loss 0.001431279 Test MSE 0.0009597735612338915 Test RE 0.014807865171658961\n",
      "77 Train Loss 0.0013819729 Test MSE 0.0009187127725960108 Test RE 0.014487649729688365\n",
      "78 Train Loss 0.0012981284 Test MSE 0.0007806395590450142 Test RE 0.013354675446808954\n",
      "79 Train Loss 0.001248809 Test MSE 0.0007155118482049759 Test RE 0.012785463452129095\n",
      "80 Train Loss 0.0011930647 Test MSE 0.0006329299869420246 Test RE 0.012025022464095416\n",
      "81 Train Loss 0.0011562549 Test MSE 0.0006061597318026209 Test RE 0.011767971320852812\n",
      "82 Train Loss 0.0011238729 Test MSE 0.0005482019215164503 Test RE 0.011191243287489524\n",
      "83 Train Loss 0.0010874167 Test MSE 0.0005669584226087712 Test RE 0.011381084976777877\n",
      "84 Train Loss 0.0010333705 Test MSE 0.0005156736329268475 Test RE 0.010854142606728949\n",
      "85 Train Loss 0.0010046101 Test MSE 0.0004990537180052053 Test RE 0.010677798179414378\n",
      "86 Train Loss 0.0009606238 Test MSE 0.00048586311714341634 Test RE 0.010535739557044803\n",
      "87 Train Loss 0.00092594256 Test MSE 0.0004546823664027703 Test RE 0.010192063389458593\n",
      "88 Train Loss 0.0009026317 Test MSE 0.0004510711504691705 Test RE 0.010151508579665172\n",
      "89 Train Loss 0.0008697681 Test MSE 0.00048075488148856976 Test RE 0.010480208228486878\n",
      "90 Train Loss 0.00081158464 Test MSE 0.0004192950034563797 Test RE 0.009787412756624866\n",
      "91 Train Loss 0.0007686136 Test MSE 0.00044991830025960147 Test RE 0.010138527638511223\n",
      "92 Train Loss 0.0007415152 Test MSE 0.0004347411317937369 Test RE 0.009966058362241789\n",
      "93 Train Loss 0.00072250376 Test MSE 0.000407636969361869 Test RE 0.009650389501009183\n",
      "94 Train Loss 0.0007022771 Test MSE 0.0003866570226270336 Test RE 0.009398769772882652\n",
      "95 Train Loss 0.0006891412 Test MSE 0.0003744023763638275 Test RE 0.009248629001826764\n",
      "96 Train Loss 0.0006721025 Test MSE 0.0003599488193404431 Test RE 0.009068353409000014\n",
      "97 Train Loss 0.0006510039 Test MSE 0.00034639651896696696 Test RE 0.008896000933109986\n",
      "98 Train Loss 0.0006397166 Test MSE 0.00033232495088938616 Test RE 0.008713437790492965\n",
      "99 Train Loss 0.00062986574 Test MSE 0.00032563085101519 Test RE 0.008625232931673003\n",
      "Training time: 67.37\n",
      "1\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.355614 Test MSE 9.219548110456133 Test RE 1.4513189895357643\n",
      "1 Train Loss 40.223415 Test MSE 10.238539945923833 Test RE 1.5294210906598815\n",
      "2 Train Loss 35.222054 Test MSE 9.982959354568317 Test RE 1.5102112868534538\n",
      "3 Train Loss 31.361979 Test MSE 10.149494963306198 Test RE 1.5227558495056452\n",
      "4 Train Loss 28.422865 Test MSE 9.607476914529837 Test RE 1.4815377949277875\n",
      "5 Train Loss 24.953157 Test MSE 9.0540667015504 Test RE 1.43823517163059\n",
      "6 Train Loss 21.868488 Test MSE 8.986735857830263 Test RE 1.4328774524291958\n",
      "7 Train Loss 18.894093 Test MSE 8.696275700600255 Test RE 1.40953125446229\n",
      "8 Train Loss 16.348787 Test MSE 7.952392865703624 Test RE 1.3478978289275443\n",
      "9 Train Loss 15.179179 Test MSE 8.179391510711596 Test RE 1.367000138239746\n",
      "10 Train Loss 14.430784 Test MSE 8.15358477536612 Test RE 1.3648419287378613\n",
      "11 Train Loss 13.679464 Test MSE 8.28681982082156 Test RE 1.3759479589794186\n",
      "12 Train Loss 13.194185 Test MSE 8.272085535312014 Test RE 1.374724170460521\n",
      "13 Train Loss 12.654654 Test MSE 8.2635058894584 Test RE 1.3740110669535532\n",
      "14 Train Loss 12.115534 Test MSE 8.13057167181462 Test RE 1.3629144671604465\n",
      "15 Train Loss 10.883209 Test MSE 7.446107657923887 Test RE 1.3042856491144792\n",
      "16 Train Loss 9.761568 Test MSE 7.070449073903172 Test RE 1.2709590547852305\n",
      "17 Train Loss 8.923432 Test MSE 6.563243129039943 Test RE 1.2245240143516438\n",
      "18 Train Loss 8.195994 Test MSE 6.41861098991572 Test RE 1.2109566262521194\n",
      "19 Train Loss 7.729875 Test MSE 6.166454262038466 Test RE 1.1869319422830318\n",
      "20 Train Loss 7.452299 Test MSE 6.286396894501324 Test RE 1.1984197531441616\n",
      "21 Train Loss 7.1415205 Test MSE 6.178258673185618 Test RE 1.1880674679152639\n",
      "22 Train Loss 6.92884 Test MSE 6.189431302456679 Test RE 1.18914122044488\n",
      "23 Train Loss 6.68019 Test MSE 6.180449018758595 Test RE 1.1882780489101887\n",
      "24 Train Loss 6.432118 Test MSE 6.142643820186023 Test RE 1.1846381842415064\n",
      "25 Train Loss 6.142226 Test MSE 6.130226178895391 Test RE 1.183440177777826\n",
      "26 Train Loss 5.890401 Test MSE 6.13015692968752 Test RE 1.1834334934790804\n",
      "27 Train Loss 5.52362 Test MSE 6.0784558379159925 Test RE 1.1784324504563963\n",
      "28 Train Loss 5.116126 Test MSE 6.107023836871973 Test RE 1.1811984484919318\n",
      "29 Train Loss 3.8569777 Test MSE 5.382285426199857 Test RE 1.1088975469820264\n",
      "30 Train Loss 2.7885184 Test MSE 5.356879181792115 Test RE 1.10627726163423\n",
      "31 Train Loss 2.2998855 Test MSE 5.304087439113205 Test RE 1.1008126147944237\n",
      "32 Train Loss 1.9605354 Test MSE 5.264348386132452 Test RE 1.096681131643377\n",
      "33 Train Loss 1.7560071 Test MSE 5.328701120071353 Test RE 1.1033638255166451\n",
      "34 Train Loss 1.6062748 Test MSE 5.32472369630532 Test RE 1.10295196485601\n",
      "35 Train Loss 1.5121769 Test MSE 5.388863887166636 Test RE 1.1095750111999214\n",
      "36 Train Loss 1.4304621 Test MSE 5.417667340568749 Test RE 1.1125363960652657\n",
      "37 Train Loss 1.3647662 Test MSE 5.4603901572255005 Test RE 1.1169144197043375\n",
      "38 Train Loss 1.3054492 Test MSE 5.47225060812563 Test RE 1.1181267802300456\n",
      "39 Train Loss 1.2656034 Test MSE 5.467852706679293 Test RE 1.1176773856270394\n",
      "40 Train Loss 1.2317454 Test MSE 5.555220885909979 Test RE 1.1265714118266876\n",
      "41 Train Loss 1.1951467 Test MSE 5.585229790168705 Test RE 1.1296101425316312\n",
      "42 Train Loss 1.1565814 Test MSE 5.600042008655381 Test RE 1.1311070329077617\n",
      "43 Train Loss 1.1256175 Test MSE 5.686475130364021 Test RE 1.1398025712066062\n",
      "44 Train Loss 1.1003573 Test MSE 5.706231855466561 Test RE 1.1417808829040437\n",
      "45 Train Loss 1.0801276 Test MSE 5.7219087598852925 Test RE 1.143348231818222\n",
      "46 Train Loss 1.0558832 Test MSE 5.713182676592244 Test RE 1.1424760789218784\n",
      "47 Train Loss 1.0378778 Test MSE 5.749121799771641 Test RE 1.1460638531269562\n",
      "48 Train Loss 1.0240506 Test MSE 5.761459483089787 Test RE 1.1472929273641599\n",
      "49 Train Loss 1.0001788 Test MSE 5.82482289311437 Test RE 1.1535845283718396\n",
      "50 Train Loss 0.98205495 Test MSE 5.857504829002739 Test RE 1.1568162695234239\n",
      "51 Train Loss 0.96761715 Test MSE 5.844369632997874 Test RE 1.1555184868510928\n",
      "52 Train Loss 0.95710105 Test MSE 5.859074248005515 Test RE 1.1569712337868192\n",
      "53 Train Loss 0.9439379 Test MSE 5.886208589230959 Test RE 1.159647201656705\n",
      "54 Train Loss 0.9327266 Test MSE 5.917490669904179 Test RE 1.1627245737245002\n",
      "55 Train Loss 0.9197732 Test MSE 5.914279893909861 Test RE 1.1624090890958327\n",
      "56 Train Loss 0.90679115 Test MSE 5.961778424643932 Test RE 1.167067501632857\n",
      "57 Train Loss 0.89562577 Test MSE 5.995591776573549 Test RE 1.1703724439475531\n",
      "58 Train Loss 0.8864304 Test MSE 6.005378387946314 Test RE 1.1713272546169193\n",
      "59 Train Loss 0.8766401 Test MSE 6.028625630233106 Test RE 1.1735922098932572\n",
      "60 Train Loss 0.86671233 Test MSE 6.040990642559219 Test RE 1.1747951415155025\n",
      "61 Train Loss 0.8583858 Test MSE 6.057520359570212 Test RE 1.1764013156225372\n",
      "62 Train Loss 0.85058004 Test MSE 6.0558553758362725 Test RE 1.176239630349542\n",
      "63 Train Loss 0.8434115 Test MSE 6.05514801575704 Test RE 1.1761709324361773\n",
      "64 Train Loss 0.83749557 Test MSE 6.040997690387859 Test RE 1.1747958268130736\n",
      "65 Train Loss 0.83180666 Test MSE 6.069563082388265 Test RE 1.1775701140633903\n",
      "66 Train Loss 0.82346636 Test MSE 6.077481713225944 Test RE 1.1783380197184212\n",
      "67 Train Loss 0.8164876 Test MSE 6.107432636151857 Test RE 1.181237982068968\n",
      "68 Train Loss 0.8109498 Test MSE 6.121026573946094 Test RE 1.1825518524979892\n",
      "69 Train Loss 0.8046464 Test MSE 6.134468063121026 Test RE 1.1838495548514207\n",
      "70 Train Loss 0.799352 Test MSE 6.130065270293548 Test RE 1.1834246459729283\n",
      "71 Train Loss 0.7954419 Test MSE 6.143956521059287 Test RE 1.1847647577945486\n",
      "72 Train Loss 0.79101825 Test MSE 6.155815607770758 Test RE 1.1859076251417293\n",
      "73 Train Loss 0.7861049 Test MSE 6.167870955330127 Test RE 1.1870682784886604\n",
      "74 Train Loss 0.78004426 Test MSE 6.165995238206959 Test RE 1.1868877645299627\n",
      "75 Train Loss 0.7741137 Test MSE 6.168035241204542 Test RE 1.187084087610879\n",
      "76 Train Loss 0.76896495 Test MSE 6.185359194095781 Test RE 1.188749980249562\n",
      "77 Train Loss 0.76352775 Test MSE 6.212823787022786 Test RE 1.1913862356013962\n",
      "78 Train Loss 0.75995356 Test MSE 6.232443251132012 Test RE 1.1932658909649554\n",
      "79 Train Loss 0.75540423 Test MSE 6.221440175803199 Test RE 1.1922120992180958\n",
      "80 Train Loss 0.75037646 Test MSE 6.246756100700411 Test RE 1.1946352769518638\n",
      "81 Train Loss 0.74737793 Test MSE 6.247549473353212 Test RE 1.1947111371945052\n",
      "82 Train Loss 0.7442223 Test MSE 6.258463488925908 Test RE 1.1957542186772352\n",
      "83 Train Loss 0.7418916 Test MSE 6.264112267962945 Test RE 1.1962937303264203\n",
      "84 Train Loss 0.7387657 Test MSE 6.2666133772468 Test RE 1.196532532140807\n",
      "85 Train Loss 0.7352062 Test MSE 6.27410742930965 Test RE 1.1972477667778487\n",
      "86 Train Loss 0.7319009 Test MSE 6.271156468079616 Test RE 1.1969661771404987\n",
      "87 Train Loss 0.7285188 Test MSE 6.287470129079768 Test RE 1.1985220478806669\n",
      "88 Train Loss 0.7256737 Test MSE 6.308497685895166 Test RE 1.2005245189839235\n",
      "89 Train Loss 0.7225129 Test MSE 6.310635355496819 Test RE 1.2007279039680756\n",
      "90 Train Loss 0.7192146 Test MSE 6.317050840765811 Test RE 1.2013380878030337\n",
      "91 Train Loss 0.7151415 Test MSE 6.3171907952362245 Test RE 1.2013513955718698\n",
      "92 Train Loss 0.7102983 Test MSE 6.3181590014751166 Test RE 1.2014434547948332\n",
      "93 Train Loss 0.7071673 Test MSE 6.324879055429234 Test RE 1.2020822183290243\n",
      "94 Train Loss 0.70368254 Test MSE 6.350330648693438 Test RE 1.2044984060837514\n",
      "95 Train Loss 0.69929516 Test MSE 6.362495038722422 Test RE 1.205651493951231\n",
      "96 Train Loss 0.69727474 Test MSE 6.3712942902145695 Test RE 1.2064849064102259\n",
      "97 Train Loss 0.69541097 Test MSE 6.3730152700031475 Test RE 1.206647840019264\n",
      "98 Train Loss 0.6933128 Test MSE 6.37306634576213 Test RE 1.2066526752760582\n",
      "99 Train Loss 0.6915138 Test MSE 6.3848257518670675 Test RE 1.2077654033233938\n",
      "Training time: 67.34\n",
      "2\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.300907 Test MSE 7.59363201765136 Test RE 1.317142714862265\n",
      "1 Train Loss 36.03306 Test MSE 6.6566635840770045 Test RE 1.2332080891704018\n",
      "2 Train Loss 25.78738 Test MSE 5.069849957925967 Test RE 1.0762312878776201\n",
      "3 Train Loss 18.432367 Test MSE 4.126506100031069 Test RE 0.9709554549505591\n",
      "4 Train Loss 12.686779 Test MSE 3.9798575544173276 Test RE 0.9535463858157834\n",
      "5 Train Loss 10.69153 Test MSE 3.993801908013032 Test RE 0.955215410552437\n",
      "6 Train Loss 9.421701 Test MSE 3.882354254283024 Test RE 0.9417933960613176\n",
      "7 Train Loss 8.544731 Test MSE 3.903084313214528 Test RE 0.9443044291926173\n",
      "8 Train Loss 8.06034 Test MSE 3.9387194401330468 Test RE 0.9486053803301575\n",
      "9 Train Loss 7.601125 Test MSE 3.9083699295152408 Test RE 0.9449436085987405\n",
      "10 Train Loss 7.2733593 Test MSE 3.9255883287705142 Test RE 0.9470228047951325\n",
      "11 Train Loss 7.0205264 Test MSE 3.8549184021632685 Test RE 0.9384597595221292\n",
      "12 Train Loss 6.773166 Test MSE 3.8541738908319383 Test RE 0.9383691314477437\n",
      "13 Train Loss 6.1629906 Test MSE 3.5504491412473276 Test RE 0.9006368414658877\n",
      "14 Train Loss 5.403833 Test MSE 3.195792660971786 Test RE 0.8544710591925778\n",
      "15 Train Loss 4.8858204 Test MSE 3.121701363435152 Test RE 0.8445079403593205\n",
      "16 Train Loss 4.1987624 Test MSE 2.78018311420992 Test RE 0.7969751147290658\n",
      "17 Train Loss 3.3501859 Test MSE 2.3822006177470945 Test RE 0.7377296300567653\n",
      "18 Train Loss 2.2352972 Test MSE 1.8859208900521973 Test RE 0.6564018491819834\n",
      "19 Train Loss 1.7589343 Test MSE 1.6275016063065082 Test RE 0.6097738182704057\n",
      "20 Train Loss 1.3691953 Test MSE 1.3007366402975897 Test RE 0.5451333441116287\n",
      "21 Train Loss 1.0915507 Test MSE 0.9734551521083026 Test RE 0.47159157117473377\n",
      "22 Train Loss 0.86810553 Test MSE 0.6165276299878212 Test RE 0.37530498460462536\n",
      "23 Train Loss 0.6367049 Test MSE 0.3317142790846297 Test RE 0.275289814808825\n",
      "24 Train Loss 0.41723996 Test MSE 0.23598211176873884 Test RE 0.2321921868742223\n",
      "25 Train Loss 0.31452245 Test MSE 0.20924268241917962 Test RE 0.21864180283799997\n",
      "26 Train Loss 0.21316902 Test MSE 0.1450874223007569 Test RE 0.18206352319739288\n",
      "27 Train Loss 0.16322091 Test MSE 0.10599056581929485 Test RE 0.15561149158329607\n",
      "28 Train Loss 0.14121555 Test MSE 0.08901481184257468 Test RE 0.14260646002873384\n",
      "29 Train Loss 0.11418348 Test MSE 0.04839033111169871 Test RE 0.10514469296965251\n",
      "30 Train Loss 0.092111364 Test MSE 0.043621451829789354 Test RE 0.09982932122908202\n",
      "31 Train Loss 0.07511718 Test MSE 0.024081021960553603 Test RE 0.07417294403556698\n",
      "32 Train Loss 0.05973595 Test MSE 0.016459580538448915 Test RE 0.06132215971434192\n",
      "33 Train Loss 0.04765257 Test MSE 0.010533511027675899 Test RE 0.04905628286835695\n",
      "34 Train Loss 0.040524654 Test MSE 0.009365076478954576 Test RE 0.046255536704422846\n",
      "35 Train Loss 0.035022207 Test MSE 0.009023584140700557 Test RE 0.045404363971794974\n",
      "36 Train Loss 0.028323706 Test MSE 0.006142115106404767 Test RE 0.03745993641156104\n",
      "37 Train Loss 0.025456324 Test MSE 0.0051809200621539785 Test RE 0.03440420335596057\n",
      "38 Train Loss 0.022196192 Test MSE 0.005884849033916092 Test RE 0.03666702911402732\n",
      "39 Train Loss 0.019346137 Test MSE 0.005860426013292872 Test RE 0.03659086312643409\n",
      "40 Train Loss 0.017641013 Test MSE 0.005409311365736529 Test RE 0.035154348243336554\n",
      "41 Train Loss 0.015731089 Test MSE 0.00573017625678129 Test RE 0.03618195679357057\n",
      "42 Train Loss 0.014462932 Test MSE 0.006146869451221252 Test RE 0.03747443166282005\n",
      "43 Train Loss 0.013020614 Test MSE 0.004838665166341159 Test RE 0.03324840724217295\n",
      "44 Train Loss 0.012346317 Test MSE 0.005200709383295107 Test RE 0.03446984680539216\n",
      "45 Train Loss 0.011227651 Test MSE 0.005144134572015069 Test RE 0.034281847680353084\n",
      "46 Train Loss 0.010377888 Test MSE 0.005710171410097279 Test RE 0.036118743438040356\n",
      "47 Train Loss 0.00977997 Test MSE 0.006264214733268242 Test RE 0.03783043878628115\n",
      "48 Train Loss 0.008881405 Test MSE 0.006779560438750365 Test RE 0.039355807591252186\n",
      "49 Train Loss 0.008205738 Test MSE 0.0061640160508718385 Test RE 0.03752666244497971\n",
      "50 Train Loss 0.007717637 Test MSE 0.005974834465561222 Test RE 0.03694630397384868\n",
      "51 Train Loss 0.0072889407 Test MSE 0.005850868178749858 Test RE 0.03656101272600586\n",
      "52 Train Loss 0.006536868 Test MSE 0.005579413446001684 Test RE 0.035702804566623704\n",
      "53 Train Loss 0.0060893404 Test MSE 0.004896888451329752 Test RE 0.0334478468366979\n",
      "54 Train Loss 0.0058162604 Test MSE 0.004942315494774372 Test RE 0.033602631779345825\n",
      "55 Train Loss 0.005482931 Test MSE 0.004268596150288235 Test RE 0.03122846190547023\n",
      "56 Train Loss 0.0051244046 Test MSE 0.004049073310149065 Test RE 0.03041486409691341\n",
      "57 Train Loss 0.0050054123 Test MSE 0.003751879253159794 Test RE 0.029277398686534884\n",
      "58 Train Loss 0.0046763085 Test MSE 0.003577577447656428 Test RE 0.028589238149567008\n",
      "59 Train Loss 0.00448862 Test MSE 0.0035112523989279327 Test RE 0.028322989069099025\n",
      "60 Train Loss 0.0042366167 Test MSE 0.003202509333410708 Test RE 0.027049127582967018\n",
      "61 Train Loss 0.003910704 Test MSE 0.002802694032868698 Test RE 0.02530439187989144\n",
      "62 Train Loss 0.0037745286 Test MSE 0.0026592945915973557 Test RE 0.02464854485278513\n",
      "63 Train Loss 0.0034291213 Test MSE 0.002288614551998506 Test RE 0.02286622053709119\n",
      "64 Train Loss 0.0032226217 Test MSE 0.002381384883502609 Test RE 0.023325064670130173\n",
      "65 Train Loss 0.0030101978 Test MSE 0.00220492822305533 Test RE 0.022444259869397454\n",
      "66 Train Loss 0.002907921 Test MSE 0.0020560359389641333 Test RE 0.021673218588292256\n",
      "67 Train Loss 0.0028166971 Test MSE 0.0021700144831532323 Test RE 0.022265854998663702\n",
      "68 Train Loss 0.0027119555 Test MSE 0.0021673342621542735 Test RE 0.02225210028616743\n",
      "69 Train Loss 0.0025882698 Test MSE 0.0023140250258914226 Test RE 0.022992811877326626\n",
      "70 Train Loss 0.0025075318 Test MSE 0.002235082213597081 Test RE 0.022597209476313607\n",
      "71 Train Loss 0.0023933675 Test MSE 0.001960722872836115 Test RE 0.02116489741653872\n",
      "72 Train Loss 0.0023017586 Test MSE 0.0019180384594695756 Test RE 0.02093325268597469\n",
      "73 Train Loss 0.0022102473 Test MSE 0.0017673084960497817 Test RE 0.020093900291784757\n",
      "74 Train Loss 0.0020640732 Test MSE 0.0016067467326572216 Test RE 0.019159394198980172\n",
      "75 Train Loss 0.0019241609 Test MSE 0.0014264775528680532 Test RE 0.018052632084904967\n",
      "76 Train Loss 0.0018432224 Test MSE 0.001403574334865581 Test RE 0.017907121051237197\n",
      "77 Train Loss 0.0017841184 Test MSE 0.0012087502328962058 Test RE 0.01661790782261348\n",
      "78 Train Loss 0.0017156141 Test MSE 0.00103784192495171 Test RE 0.015398331519804772\n",
      "79 Train Loss 0.0016432588 Test MSE 0.0009760481229544888 Test RE 0.014932883453506542\n",
      "80 Train Loss 0.0015802688 Test MSE 0.0009123850718877473 Test RE 0.014437671155241107\n",
      "81 Train Loss 0.0015384821 Test MSE 0.0009375761948870784 Test RE 0.014635627460776063\n",
      "82 Train Loss 0.0014647031 Test MSE 0.000851115435873854 Test RE 0.013944479037588662\n",
      "83 Train Loss 0.0014084517 Test MSE 0.0008331305597593818 Test RE 0.013796362366861516\n",
      "84 Train Loss 0.0013366375 Test MSE 0.0007754117001347249 Test RE 0.013309882917776792\n",
      "85 Train Loss 0.0012897329 Test MSE 0.000803568679609109 Test RE 0.013549384300371645\n",
      "86 Train Loss 0.0012551765 Test MSE 0.0007790185205042609 Test RE 0.013340802402866678\n",
      "87 Train Loss 0.0012217915 Test MSE 0.000753312945956156 Test RE 0.013118850283391232\n",
      "88 Train Loss 0.0011836623 Test MSE 0.0007087534246945435 Test RE 0.012724937135536287\n",
      "89 Train Loss 0.0011348535 Test MSE 0.0006649122241191833 Test RE 0.012325093396817801\n",
      "90 Train Loss 0.0011050153 Test MSE 0.0006685081365003424 Test RE 0.01235837613258848\n",
      "91 Train Loss 0.0010768811 Test MSE 0.0006447107331681225 Test RE 0.012136417568908233\n",
      "92 Train Loss 0.0010305077 Test MSE 0.00064127144866136 Test RE 0.012104002714264754\n",
      "93 Train Loss 0.001007625 Test MSE 0.0006227759238955483 Test RE 0.011928174053316842\n",
      "94 Train Loss 0.0009867613 Test MSE 0.0006272538753426274 Test RE 0.011970980872317126\n",
      "95 Train Loss 0.0009676268 Test MSE 0.0006305606412880038 Test RE 0.01200249378838298\n",
      "96 Train Loss 0.0009437291 Test MSE 0.0006420028131048701 Test RE 0.012110903001681609\n",
      "97 Train Loss 0.00093302754 Test MSE 0.0006085361948408083 Test RE 0.011791017054949025\n",
      "98 Train Loss 0.0009123144 Test MSE 0.000600063088575316 Test RE 0.011708641715426998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.00087100273 Test MSE 0.0005725455459318453 Test RE 0.011437025265566302\n",
      "Training time: 66.88\n",
      "3\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 49.593594 Test MSE 8.502862573834651 Test RE 1.3937684847826284\n",
      "1 Train Loss 39.958748 Test MSE 8.471492006704741 Test RE 1.39119501553445\n",
      "2 Train Loss 32.097572 Test MSE 8.729928846922554 Test RE 1.412255947205007\n",
      "3 Train Loss 26.99266 Test MSE 8.704162840444239 Test RE 1.4101703010465594\n",
      "4 Train Loss 24.199326 Test MSE 8.865406880034424 Test RE 1.423172019038098\n",
      "5 Train Loss 21.789547 Test MSE 8.998370016919718 Test RE 1.4338046485030582\n",
      "6 Train Loss 19.649971 Test MSE 8.758075842119549 Test RE 1.4145308094951092\n",
      "7 Train Loss 17.626673 Test MSE 8.881882642597953 Test RE 1.424493839944944\n",
      "8 Train Loss 16.05806 Test MSE 8.858315551729772 Test RE 1.4226027164038622\n",
      "9 Train Loss 14.552652 Test MSE 8.614822449021004 Test RE 1.402914570664257\n",
      "10 Train Loss 13.464504 Test MSE 8.558102052507236 Test RE 1.3982885157633844\n",
      "11 Train Loss 11.499033 Test MSE 8.116746564941854 Test RE 1.3617552341078674\n",
      "12 Train Loss 8.176514 Test MSE 7.086303233895767 Test RE 1.2723832009030625\n",
      "13 Train Loss 6.8318243 Test MSE 6.373439155666041 Test RE 1.2066879679801414\n",
      "14 Train Loss 6.2647524 Test MSE 6.2361574786303855 Test RE 1.1936214016917288\n",
      "15 Train Loss 5.817944 Test MSE 6.16725414286856 Test RE 1.1870089211497317\n",
      "16 Train Loss 5.4607673 Test MSE 6.044050061980179 Test RE 1.1750925874424962\n",
      "17 Train Loss 4.9777956 Test MSE 5.957739413962119 Test RE 1.1666720997560038\n",
      "18 Train Loss 4.3997693 Test MSE 6.018971701985393 Test RE 1.1726521685766045\n",
      "19 Train Loss 3.3322556 Test MSE 5.431865799022815 Test RE 1.1139932929849468\n",
      "20 Train Loss 2.4083676 Test MSE 5.09691880126894 Test RE 1.0791005595659655\n",
      "21 Train Loss 2.0314944 Test MSE 5.341102769061547 Test RE 1.1046470255207894\n",
      "22 Train Loss 1.8391958 Test MSE 5.369642224750057 Test RE 1.107594359112943\n",
      "23 Train Loss 1.6953716 Test MSE 5.319125732894778 Test RE 1.1023720372645835\n",
      "24 Train Loss 1.6048977 Test MSE 5.3539238675214875 Test RE 1.1059720607969492\n",
      "25 Train Loss 1.5373294 Test MSE 5.469187530195979 Test RE 1.1178138021599993\n",
      "26 Train Loss 1.4742085 Test MSE 5.440156347009399 Test RE 1.1148431016738103\n",
      "27 Train Loss 1.4140011 Test MSE 5.432273894218443 Test RE 1.1140351392666092\n",
      "28 Train Loss 1.3679562 Test MSE 5.430339960681956 Test RE 1.113836818844541\n",
      "29 Train Loss 1.3366492 Test MSE 5.462910651090392 Test RE 1.1171721715378096\n",
      "30 Train Loss 1.3133292 Test MSE 5.454709930990833 Test RE 1.116333327767478\n",
      "31 Train Loss 1.2803721 Test MSE 5.439116451953278 Test RE 1.114736544512342\n",
      "32 Train Loss 1.2520242 Test MSE 5.486931005537176 Test RE 1.1196255741074261\n",
      "33 Train Loss 1.2272882 Test MSE 5.477558860122728 Test RE 1.1186689575242743\n",
      "34 Train Loss 1.1977751 Test MSE 5.486129631266012 Test RE 1.1195438096483243\n",
      "35 Train Loss 1.1701846 Test MSE 5.503224555571405 Test RE 1.1212867169546372\n",
      "36 Train Loss 1.1423408 Test MSE 5.5213982654995615 Test RE 1.1231366454064453\n",
      "37 Train Loss 1.1266842 Test MSE 5.557290299114109 Test RE 1.1267812256871381\n",
      "38 Train Loss 1.1080676 Test MSE 5.564990560618935 Test RE 1.127561597607248\n",
      "39 Train Loss 1.0887204 Test MSE 5.576135946771124 Test RE 1.1286901550881803\n",
      "40 Train Loss 1.0726023 Test MSE 5.632764524335822 Test RE 1.134406897111827\n",
      "41 Train Loss 1.0559387 Test MSE 5.641045653901701 Test RE 1.1352404771621087\n",
      "42 Train Loss 1.0356573 Test MSE 5.657293317338297 Test RE 1.1368741940140539\n",
      "43 Train Loss 1.021117 Test MSE 5.721862779183946 Test RE 1.143343637891492\n",
      "44 Train Loss 1.0074531 Test MSE 5.699200147734132 Test RE 1.1410771659332648\n",
      "45 Train Loss 0.9931482 Test MSE 5.7484856408839935 Test RE 1.1460004435401343\n",
      "46 Train Loss 0.97863305 Test MSE 5.778323489477222 Test RE 1.1489707850275248\n",
      "47 Train Loss 0.9681587 Test MSE 5.792830143702952 Test RE 1.150412143739219\n",
      "48 Train Loss 0.9579123 Test MSE 5.840473546262035 Test RE 1.1551332655966884\n",
      "49 Train Loss 0.9475403 Test MSE 5.850753572312807 Test RE 1.1561494143085262\n",
      "50 Train Loss 0.9379542 Test MSE 5.828433362910446 Test RE 1.1539419930506438\n",
      "51 Train Loss 0.92981565 Test MSE 5.822876963781204 Test RE 1.153391820239154\n",
      "52 Train Loss 0.9210875 Test MSE 5.858677258613775 Test RE 1.1569320370581728\n",
      "53 Train Loss 0.91079915 Test MSE 5.850303700931295 Test RE 1.1561049646041988\n",
      "54 Train Loss 0.90229166 Test MSE 5.860250980516293 Test RE 1.1570874106140887\n",
      "55 Train Loss 0.893741 Test MSE 5.862149952312586 Test RE 1.1572748683178522\n",
      "56 Train Loss 0.8878775 Test MSE 5.86988515522654 Test RE 1.1580381381894822\n",
      "57 Train Loss 0.8808687 Test MSE 5.884763162479099 Test RE 1.1595048105082355\n",
      "58 Train Loss 0.8743141 Test MSE 5.8678985096919725 Test RE 1.1578421542880097\n",
      "59 Train Loss 0.8681623 Test MSE 5.884192802467937 Test RE 1.1594486186799853\n",
      "60 Train Loss 0.8615601 Test MSE 5.898663851002772 Test RE 1.1608734644168897\n",
      "61 Train Loss 0.8533663 Test MSE 5.881734218495849 Test RE 1.1592063679827356\n",
      "62 Train Loss 0.8485086 Test MSE 5.899056891399309 Test RE 1.1609121394946704\n",
      "63 Train Loss 0.84222656 Test MSE 5.921690968459005 Test RE 1.163137157730523\n",
      "64 Train Loss 0.8374998 Test MSE 5.9262447157064395 Test RE 1.1635842947712534\n",
      "65 Train Loss 0.8332591 Test MSE 5.950630313921367 Test RE 1.1659758235526654\n",
      "66 Train Loss 0.8297298 Test MSE 5.954867760934677 Test RE 1.1663908956747724\n",
      "67 Train Loss 0.82500875 Test MSE 5.9574880652003515 Test RE 1.1666474893576444\n",
      "68 Train Loss 0.8202163 Test MSE 5.95887662460213 Test RE 1.166783441367868\n",
      "69 Train Loss 0.8157196 Test MSE 5.965791527790581 Test RE 1.1674602346416298\n",
      "70 Train Loss 0.81015396 Test MSE 5.979011143262829 Test RE 1.1687530082034474\n",
      "71 Train Loss 0.80658513 Test MSE 5.97218649980292 Test RE 1.168085790849871\n",
      "72 Train Loss 0.8026474 Test MSE 5.97751622130512 Test RE 1.1686068884088103\n",
      "73 Train Loss 0.798169 Test MSE 5.966399843951421 Test RE 1.167519754557936\n",
      "74 Train Loss 0.7944054 Test MSE 5.973676658093265 Test RE 1.1682315100232077\n",
      "75 Train Loss 0.79185784 Test MSE 5.983931438714219 Test RE 1.1692338090728875\n",
      "76 Train Loss 0.788291 Test MSE 5.992121928449591 Test RE 1.1700337282284532\n",
      "77 Train Loss 0.78457487 Test MSE 5.992102745610191 Test RE 1.170031855387135\n",
      "78 Train Loss 0.7825759 Test MSE 6.00718621744709 Test RE 1.1715035466411856\n",
      "79 Train Loss 0.7798661 Test MSE 6.004554959290456 Test RE 1.171246948478917\n",
      "80 Train Loss 0.77639 Test MSE 6.007378846480127 Test RE 1.171522329460477\n",
      "81 Train Loss 0.7732599 Test MSE 6.009702276722312 Test RE 1.1717488581465194\n",
      "82 Train Loss 0.76855886 Test MSE 6.011081680117652 Test RE 1.1718833258407344\n",
      "83 Train Loss 0.76533926 Test MSE 6.030751642810623 Test RE 1.1737991270263908\n",
      "84 Train Loss 0.7623244 Test MSE 6.030312320805858 Test RE 1.173756372390823\n",
      "85 Train Loss 0.75917155 Test MSE 6.0479000948633175 Test RE 1.1754667922240845\n",
      "86 Train Loss 0.7564119 Test MSE 6.049361901219004 Test RE 1.1756088416117023\n",
      "87 Train Loss 0.75349885 Test MSE 6.057259244879503 Test RE 1.1763759604476647\n",
      "88 Train Loss 0.75061226 Test MSE 6.064824248114359 Test RE 1.1771103281465094\n",
      "89 Train Loss 0.7482142 Test MSE 6.068351288816721 Test RE 1.1774525567445153\n",
      "90 Train Loss 0.745029 Test MSE 6.074549541885212 Test RE 1.178053732082976\n",
      "91 Train Loss 0.7413112 Test MSE 6.081103658386163 Test RE 1.1786890894711555\n",
      "92 Train Loss 0.7385563 Test MSE 6.069639659032804 Test RE 1.177577542446818\n",
      "93 Train Loss 0.73524123 Test MSE 6.065788174340056 Test RE 1.1772038677437493\n",
      "94 Train Loss 0.73237455 Test MSE 6.08779661924237 Test RE 1.1793375532127783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.72895145 Test MSE 6.107428393805856 Test RE 1.1812375718130224\n",
      "96 Train Loss 0.72644734 Test MSE 6.11630095868343 Test RE 1.182095281691376\n",
      "97 Train Loss 0.72418606 Test MSE 6.13628423484581 Test RE 1.184024787239259\n",
      "98 Train Loss 0.7220237 Test MSE 6.144965370593718 Test RE 1.184862024133322\n",
      "99 Train Loss 0.71951723 Test MSE 6.1592793255363 Test RE 1.1862412179519075\n",
      "Training time: 67.34\n",
      "4\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.11209 Test MSE 8.616443319897003 Test RE 1.4030465429963934\n",
      "1 Train Loss 54.07956 Test MSE 7.041974000307193 Test RE 1.2683971832702863\n",
      "2 Train Loss 49.111576 Test MSE 7.61307060701835 Test RE 1.3188274838905547\n",
      "3 Train Loss 46.890453 Test MSE 8.222918325464631 Test RE 1.370632573026728\n",
      "4 Train Loss 45.11271 Test MSE 7.9849283527643165 Test RE 1.3506523299522302\n",
      "5 Train Loss 44.619633 Test MSE 8.090097933426152 Test RE 1.3595179615879371\n",
      "6 Train Loss 44.33032 Test MSE 8.148765724452296 Test RE 1.3644385347058499\n",
      "7 Train Loss 44.291283 Test MSE 8.097480060564177 Test RE 1.3601380928953257\n",
      "8 Train Loss 43.932343 Test MSE 7.981233361568057 Test RE 1.350339789517816\n",
      "9 Train Loss 41.540924 Test MSE 7.685094270757984 Test RE 1.325051200462051\n",
      "10 Train Loss 39.973602 Test MSE 7.757527592169186 Test RE 1.331280972259509\n",
      "11 Train Loss 38.68705 Test MSE 7.387397206067785 Test RE 1.299133511595037\n",
      "12 Train Loss 37.98108 Test MSE 7.39806169559974 Test RE 1.300070891758228\n",
      "13 Train Loss 37.310684 Test MSE 7.222011071629586 Test RE 1.2845089517712132\n",
      "14 Train Loss 36.802155 Test MSE 7.0884383641591455 Test RE 1.2725748734283349\n",
      "15 Train Loss 35.83065 Test MSE 6.727308744210846 Test RE 1.2397346512576832\n",
      "16 Train Loss 33.734512 Test MSE 6.031814065957443 Test RE 1.1739025151708182\n",
      "17 Train Loss 31.955511 Test MSE 4.75625771157925 Test RE 1.0424152335670256\n",
      "18 Train Loss 24.05666 Test MSE 4.492808775635128 Test RE 1.0131343202813956\n",
      "19 Train Loss 21.660774 Test MSE 3.9283355374234468 Test RE 0.9473541200031464\n",
      "20 Train Loss 19.605644 Test MSE 2.4767809001369163 Test RE 0.75223208806941\n",
      "21 Train Loss 18.254112 Test MSE 2.2867889856060257 Test RE 0.7228049301441203\n",
      "22 Train Loss 15.858951 Test MSE 1.9266676890700183 Test RE 0.6634549938091826\n",
      "23 Train Loss 13.566439 Test MSE 2.327288089435651 Test RE 0.7291772891579424\n",
      "24 Train Loss 11.810753 Test MSE 2.258538397484075 Test RE 0.7183263529078477\n",
      "25 Train Loss 8.531952 Test MSE 2.244413401035738 Test RE 0.716076607910094\n",
      "26 Train Loss 8.060571 Test MSE 2.0602897577639068 Test RE 0.6860759759160361\n",
      "27 Train Loss 7.5058594 Test MSE 2.056392945346235 Test RE 0.6854268500511411\n",
      "28 Train Loss 6.748845 Test MSE 2.1103317452033576 Test RE 0.6943579723467673\n",
      "29 Train Loss 5.783947 Test MSE 2.019545721284416 Test RE 0.6792582238489846\n",
      "30 Train Loss 5.6194186 Test MSE 1.9791412371701476 Test RE 0.6724290295634439\n",
      "31 Train Loss 5.088672 Test MSE 1.946751350041751 Test RE 0.66690396972724\n",
      "32 Train Loss 4.837262 Test MSE 1.939127860650926 Test RE 0.6655968889633854\n",
      "33 Train Loss 4.6597743 Test MSE 1.9054845132702092 Test RE 0.6597976615483847\n",
      "34 Train Loss 4.369791 Test MSE 1.7930369795231973 Test RE 0.6400334669181335\n",
      "35 Train Loss 4.297483 Test MSE 1.80369351499945 Test RE 0.6419326009906118\n",
      "36 Train Loss 4.2251196 Test MSE 1.808996891987407 Test RE 0.642875641407861\n",
      "37 Train Loss 4.168082 Test MSE 1.8033271123932142 Test RE 0.6418673965303692\n",
      "38 Train Loss 4.077689 Test MSE 1.7799057553720339 Test RE 0.6376855323887463\n",
      "39 Train Loss 4.032551 Test MSE 1.7602581718082095 Test RE 0.6341562029968738\n",
      "40 Train Loss 3.9968188 Test MSE 1.7373017677159344 Test RE 0.6300074585984187\n",
      "41 Train Loss 3.946632 Test MSE 1.701887991319733 Test RE 0.6235532501110448\n",
      "42 Train Loss 3.9014351 Test MSE 1.6561038301623296 Test RE 0.6151086595121703\n",
      "43 Train Loss 3.8898318 Test MSE 1.6414866915258466 Test RE 0.6123881006165719\n",
      "44 Train Loss 3.859003 Test MSE 1.6220713536342786 Test RE 0.6087556956047713\n",
      "45 Train Loss 3.833273 Test MSE 1.6156863195855802 Test RE 0.6075563776915179\n",
      "46 Train Loss 3.811739 Test MSE 1.6100040475608053 Test RE 0.606487066990685\n",
      "47 Train Loss 3.7766526 Test MSE 1.5527468182746111 Test RE 0.5956050676964639\n",
      "48 Train Loss 3.7577095 Test MSE 1.5379217055253818 Test RE 0.5927549282958949\n",
      "49 Train Loss 3.7225895 Test MSE 1.49489506485943 Test RE 0.5844043155741356\n",
      "50 Train Loss 3.7071414 Test MSE 1.4833100432402895 Test RE 0.5821354256295512\n",
      "51 Train Loss 3.675437 Test MSE 1.4815804411014355 Test RE 0.5817959293913212\n",
      "52 Train Loss 3.6561215 Test MSE 1.4558037867847848 Test RE 0.576712656663334\n",
      "53 Train Loss 3.63516 Test MSE 1.4461766741824142 Test RE 0.5748026166321766\n",
      "54 Train Loss 3.5890374 Test MSE 1.414957578805753 Test RE 0.5685645397600306\n",
      "55 Train Loss 3.5569367 Test MSE 1.4150333172693736 Test RE 0.5685797563393553\n",
      "56 Train Loss 3.0647664 Test MSE 0.7343115316191834 Test RE 0.40958895271108675\n",
      "57 Train Loss 1.4790289 Test MSE 0.15135620556492235 Test RE 0.1859551352307162\n",
      "58 Train Loss 1.1136879 Test MSE 0.12081547406286272 Test RE 0.16613813902115462\n",
      "59 Train Loss 0.9165903 Test MSE 0.09933059324693715 Test RE 0.15064321471532147\n",
      "60 Train Loss 0.71909153 Test MSE 0.09903670311718993 Test RE 0.1504201950575081\n",
      "61 Train Loss 0.5242622 Test MSE 0.0978818903804586 Test RE 0.14954063979361187\n",
      "62 Train Loss 0.44766685 Test MSE 0.06159965609259407 Test RE 0.1186307303229141\n",
      "63 Train Loss 0.35315675 Test MSE 0.057850098145210194 Test RE 0.1149635352443487\n",
      "64 Train Loss 0.30549416 Test MSE 0.0450478329108326 Test RE 0.10144835563969098\n",
      "65 Train Loss 0.25466377 Test MSE 0.042855122250536865 Test RE 0.09894854887025446\n",
      "66 Train Loss 0.20536068 Test MSE 0.038894974151970046 Test RE 0.09426594028376058\n",
      "67 Train Loss 0.18339056 Test MSE 0.04515165242500394 Test RE 0.10156518986866153\n",
      "68 Train Loss 0.16731232 Test MSE 0.04493360180713868 Test RE 0.1013196489661155\n",
      "69 Train Loss 0.15845504 Test MSE 0.047730597153627236 Test RE 0.10442548336161209\n",
      "70 Train Loss 0.15129691 Test MSE 0.050613678842172403 Test RE 0.10753306207426248\n",
      "71 Train Loss 0.14855592 Test MSE 0.046174327904921104 Test RE 0.10270896471663271\n",
      "72 Train Loss 0.14661081 Test MSE 0.0436144371375031 Test RE 0.09982129421376217\n",
      "73 Train Loss 0.14267047 Test MSE 0.03973045960818541 Test RE 0.09527300309716331\n",
      "74 Train Loss 0.14047267 Test MSE 0.04104837446599078 Test RE 0.09684028124358733\n",
      "75 Train Loss 0.13126501 Test MSE 0.039718448230444466 Test RE 0.09525860046321095\n",
      "76 Train Loss 0.12731864 Test MSE 0.03716265028216425 Test RE 0.09214279877355756\n",
      "77 Train Loss 0.12031955 Test MSE 0.029831347061687507 Test RE 0.0825552111761694\n",
      "78 Train Loss 0.106716484 Test MSE 0.026912488239387227 Test RE 0.07841244335343917\n",
      "79 Train Loss 0.094238 Test MSE 0.017697931613740885 Test RE 0.06358714361808722\n",
      "80 Train Loss 0.0889101 Test MSE 0.014398407256901245 Test RE 0.057354207994653045\n",
      "81 Train Loss 0.085716695 Test MSE 0.014871077972287103 Test RE 0.0582880176822226\n",
      "82 Train Loss 0.08185324 Test MSE 0.014375755633288759 Test RE 0.05730907531871565\n",
      "83 Train Loss 0.07865268 Test MSE 0.014340150566378574 Test RE 0.05723806136559184\n",
      "84 Train Loss 0.078236066 Test MSE 0.014146390351575965 Test RE 0.056850053684578954\n",
      "85 Train Loss 0.07708233 Test MSE 0.013651994553780043 Test RE 0.05584780562389988\n",
      "86 Train Loss 0.072871715 Test MSE 0.013572868427372011 Test RE 0.055685725195773125\n",
      "87 Train Loss 0.067451164 Test MSE 0.015606910999401098 Test RE 0.05971267638556809\n",
      "88 Train Loss 0.06651247 Test MSE 0.01454584618078555 Test RE 0.05764711209230368\n",
      "89 Train Loss 0.06549514 Test MSE 0.013937632587903509 Test RE 0.05642902756600941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 0.065121844 Test MSE 0.013947369893711826 Test RE 0.056448735746680447\n",
      "91 Train Loss 0.062305 Test MSE 0.012529376798883848 Test RE 0.05350234226683374\n",
      "92 Train Loss 0.057772785 Test MSE 0.009942366501288725 Test RE 0.04765987999002727\n",
      "93 Train Loss 0.056118485 Test MSE 0.009011877001615336 Test RE 0.04537490074982038\n",
      "94 Train Loss 0.054532878 Test MSE 0.008975822808681885 Test RE 0.04528404315346067\n",
      "95 Train Loss 0.053144936 Test MSE 0.008954166217487644 Test RE 0.045229380182979846\n",
      "96 Train Loss 0.052385848 Test MSE 0.009093703042320832 Test RE 0.04558043276835195\n",
      "97 Train Loss 0.051957656 Test MSE 0.009098004507684821 Test RE 0.04559121162665722\n",
      "98 Train Loss 0.051455285 Test MSE 0.009188294863528654 Test RE 0.045816881111685144\n",
      "99 Train Loss 0.049990736 Test MSE 0.009021845957754305 Test RE 0.04539999071551157\n",
      "Training time: 70.69\n",
      "5\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 56.1249 Test MSE 8.960462716193257 Test RE 1.4307813772665028\n",
      "1 Train Loss 45.3678 Test MSE 8.036365504968 Test RE 1.3549956491241153\n",
      "2 Train Loss 39.731712 Test MSE 8.434652317952908 Test RE 1.3881667985814399\n",
      "3 Train Loss 33.408817 Test MSE 9.059576032657437 Test RE 1.438672682697057\n",
      "4 Train Loss 30.707722 Test MSE 8.375316161660802 Test RE 1.3832754377758008\n",
      "5 Train Loss 28.68386 Test MSE 8.466942017818816 Test RE 1.3908213639968479\n",
      "6 Train Loss 26.137665 Test MSE 8.752850644289882 Test RE 1.4141087815175395\n",
      "7 Train Loss 24.324184 Test MSE 8.884915441817483 Test RE 1.4247370223449831\n",
      "8 Train Loss 23.033459 Test MSE 8.7060042617857 Test RE 1.410319458433175\n",
      "9 Train Loss 21.319277 Test MSE 8.489330417335688 Test RE 1.3926589641248275\n",
      "10 Train Loss 19.891037 Test MSE 8.879270126724371 Test RE 1.4242843243152052\n",
      "11 Train Loss 18.343529 Test MSE 8.616427689675147 Test RE 1.4030452704331176\n",
      "12 Train Loss 16.73825 Test MSE 8.714482076333207 Test RE 1.4110059684047929\n",
      "13 Train Loss 15.650392 Test MSE 8.506694874971226 Test RE 1.3940825401253112\n",
      "14 Train Loss 14.66431 Test MSE 8.484814926407955 Test RE 1.3922885358900514\n",
      "15 Train Loss 14.057265 Test MSE 8.325352207935747 Test RE 1.379143217924817\n",
      "16 Train Loss 13.53059 Test MSE 8.315501456634284 Test RE 1.378327059185363\n",
      "17 Train Loss 13.022631 Test MSE 8.265885220335011 Test RE 1.3742088638514398\n",
      "18 Train Loss 12.594757 Test MSE 8.201571267633954 Test RE 1.3688523056249287\n",
      "19 Train Loss 11.807756 Test MSE 8.07658575282106 Test RE 1.3583821453550589\n",
      "20 Train Loss 9.708085 Test MSE 7.280943771003269 Test RE 1.2897391969233112\n",
      "21 Train Loss 8.980113 Test MSE 7.09334757296509 Test RE 1.2730154679680525\n",
      "22 Train Loss 8.468047 Test MSE 6.77096185669983 Test RE 1.2437504300298095\n",
      "23 Train Loss 8.09478 Test MSE 6.914277241786898 Test RE 1.256844228021842\n",
      "24 Train Loss 7.708275 Test MSE 6.753358892913449 Test RE 1.24213264348572\n",
      "25 Train Loss 7.2152457 Test MSE 6.43902544821953 Test RE 1.2128808274868057\n",
      "26 Train Loss 6.4580526 Test MSE 6.337790344880549 Test RE 1.2033085278557822\n",
      "27 Train Loss 4.5455956 Test MSE 5.708921918129465 Test RE 1.142049983450086\n",
      "28 Train Loss 3.8492622 Test MSE 5.609247314052923 Test RE 1.132036303644026\n",
      "29 Train Loss 3.3000042 Test MSE 5.534752531773639 Test RE 1.1244940558817873\n",
      "30 Train Loss 2.9624739 Test MSE 5.450945540007997 Test RE 1.1159480606827767\n",
      "31 Train Loss 2.7269607 Test MSE 5.697087973941449 Test RE 1.1408656997125473\n",
      "32 Train Loss 2.5496323 Test MSE 5.713282940984328 Test RE 1.1424861039091263\n",
      "33 Train Loss 2.354269 Test MSE 5.672540476269993 Test RE 1.13840517683871\n",
      "34 Train Loss 2.2414691 Test MSE 5.683842720624883 Test RE 1.1395387192909883\n",
      "35 Train Loss 2.1298187 Test MSE 5.596486313444962 Test RE 1.130747882880979\n",
      "36 Train Loss 2.004701 Test MSE 5.659644421304215 Test RE 1.1371104051866685\n",
      "37 Train Loss 1.9335647 Test MSE 5.683374505026479 Test RE 1.1394917826657123\n",
      "38 Train Loss 1.8876209 Test MSE 5.694041199136472 Test RE 1.140560594214644\n",
      "39 Train Loss 1.8296852 Test MSE 5.629526550401238 Test RE 1.134080795427791\n",
      "40 Train Loss 1.7813305 Test MSE 5.671010113143982 Test RE 1.1382516044815765\n",
      "41 Train Loss 1.7147074 Test MSE 5.596217510824822 Test RE 1.1307207273027824\n",
      "42 Train Loss 1.6530857 Test MSE 5.568018377322036 Test RE 1.1278682994377816\n",
      "43 Train Loss 1.602441 Test MSE 5.59628803070534 Test RE 1.1307278515826407\n",
      "44 Train Loss 1.5628773 Test MSE 5.611582490380908 Test RE 1.132271917190705\n",
      "45 Train Loss 1.5246968 Test MSE 5.58749438006846 Test RE 1.1298391254531588\n",
      "46 Train Loss 1.4928603 Test MSE 5.5476039289467804 Test RE 1.1257988062366284\n",
      "47 Train Loss 1.472654 Test MSE 5.552344630796858 Test RE 1.1262797288871875\n",
      "48 Train Loss 1.4562011 Test MSE 5.532145563580445 Test RE 1.1242291962063704\n",
      "49 Train Loss 1.4373734 Test MSE 5.511289393179095 Test RE 1.1221080249484592\n",
      "50 Train Loss 1.4159318 Test MSE 5.51512438756193 Test RE 1.1224983627917575\n",
      "51 Train Loss 1.3958216 Test MSE 5.552776324800192 Test RE 1.1263235120803323\n",
      "52 Train Loss 1.371941 Test MSE 5.542249120172904 Test RE 1.1252553380260324\n",
      "53 Train Loss 1.3542248 Test MSE 5.580894218101274 Test RE 1.1291716236913467\n",
      "54 Train Loss 1.3305576 Test MSE 5.546365237268597 Test RE 1.1256731127406125\n",
      "55 Train Loss 1.314395 Test MSE 5.560990424899863 Test RE 1.1271562770422558\n",
      "56 Train Loss 1.2968761 Test MSE 5.576096402150244 Test RE 1.128686152880932\n",
      "57 Train Loss 1.2859018 Test MSE 5.581578333487164 Test RE 1.1292408294475615\n",
      "58 Train Loss 1.2724981 Test MSE 5.610251526263696 Test RE 1.1321376321949088\n",
      "59 Train Loss 1.2611306 Test MSE 5.626777752140515 Test RE 1.1338038858226154\n",
      "60 Train Loss 1.25064 Test MSE 5.613815060862327 Test RE 1.1324971322244655\n",
      "61 Train Loss 1.2392367 Test MSE 5.635358004896014 Test RE 1.1346680232115003\n",
      "62 Train Loss 1.2329085 Test MSE 5.6136996328944555 Test RE 1.1324854892941996\n",
      "63 Train Loss 1.2228413 Test MSE 5.633877931365153 Test RE 1.134519008509186\n",
      "64 Train Loss 1.2108265 Test MSE 5.641083161460331 Test RE 1.135244251287563\n",
      "65 Train Loss 1.1969349 Test MSE 5.631702001612576 Test RE 1.1342998990341504\n",
      "66 Train Loss 1.187953 Test MSE 5.643458210688253 Test RE 1.135483210470162\n",
      "67 Train Loss 1.1797489 Test MSE 5.671776718042005 Test RE 1.1383285360820055\n",
      "68 Train Loss 1.1734926 Test MSE 5.666474202016056 Test RE 1.1377963027957505\n",
      "69 Train Loss 1.1655176 Test MSE 5.671521897086462 Test RE 1.1383029644456524\n",
      "70 Train Loss 1.1598006 Test MSE 5.677916176581077 Test RE 1.1389444657079968\n",
      "71 Train Loss 1.1519492 Test MSE 5.6995363759135405 Test RE 1.1411108247476325\n",
      "72 Train Loss 1.144649 Test MSE 5.690910969936365 Test RE 1.140247046528813\n",
      "73 Train Loss 1.1378344 Test MSE 5.710054628170731 Test RE 1.1421632751838207\n",
      "74 Train Loss 1.1312301 Test MSE 5.709445696460936 Test RE 1.1421023722656642\n",
      "75 Train Loss 1.1248167 Test MSE 5.716997571756315 Test RE 1.1428574512137306\n",
      "76 Train Loss 1.1194904 Test MSE 5.704149106322663 Test RE 1.1415724914252163\n",
      "77 Train Loss 1.1144104 Test MSE 5.706195738806217 Test RE 1.1417772695407389\n",
      "78 Train Loss 1.1076804 Test MSE 5.715935721557862 Test RE 1.142751311605401\n",
      "79 Train Loss 1.102535 Test MSE 5.726923415661542 Test RE 1.14384913478632\n",
      "80 Train Loss 1.0982438 Test MSE 5.735074418123144 Test RE 1.144662852842867\n",
      "81 Train Loss 1.0944754 Test MSE 5.728882634921986 Test RE 1.1440447773203954\n",
      "82 Train Loss 1.0870619 Test MSE 5.75718853394922 Test RE 1.14686760647222\n",
      "83 Train Loss 1.0796003 Test MSE 5.764850166158508 Test RE 1.147630475041156\n",
      "84 Train Loss 1.0750358 Test MSE 5.768431716899845 Test RE 1.1479869160980312\n",
      "85 Train Loss 1.0692286 Test MSE 5.806520935621239 Test RE 1.151770785192506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 1.0634232 Test MSE 5.812003488316824 Test RE 1.1523144114202366\n",
      "87 Train Loss 1.0565474 Test MSE 5.797908789269567 Test RE 1.1509163235092086\n",
      "88 Train Loss 1.0502853 Test MSE 5.806832673617305 Test RE 1.1518017026645584\n",
      "89 Train Loss 1.0442874 Test MSE 5.838532633195088 Test RE 1.154941312022241\n",
      "90 Train Loss 1.0374713 Test MSE 5.85102502756781 Test RE 1.1561762347163573\n",
      "91 Train Loss 1.031718 Test MSE 5.852098812277099 Test RE 1.1562823210347297\n",
      "92 Train Loss 1.027008 Test MSE 5.856711907563904 Test RE 1.1567379686519816\n",
      "93 Train Loss 1.020134 Test MSE 5.872321878709312 Test RE 1.1582784772984318\n",
      "94 Train Loss 1.0137227 Test MSE 5.848913789384718 Test RE 1.155967623093958\n",
      "95 Train Loss 1.007527 Test MSE 5.860803513958111 Test RE 1.1571419572898642\n",
      "96 Train Loss 1.0025252 Test MSE 5.880738324477426 Test RE 1.15910822553725\n",
      "97 Train Loss 0.997879 Test MSE 5.902435493501263 Test RE 1.1612445399802707\n",
      "98 Train Loss 0.9943014 Test MSE 5.9084673528948155 Test RE 1.1618377421588604\n",
      "99 Train Loss 0.9885394 Test MSE 5.907062178776086 Test RE 1.1616995776141212\n",
      "Training time: 67.56\n",
      "6\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.521675 Test MSE 8.398301741272556 Test RE 1.3851722976561713\n",
      "1 Train Loss 53.33698 Test MSE 8.241390183183015 Test RE 1.3721711950973414\n",
      "2 Train Loss 46.953293 Test MSE 8.631742895767994 Test RE 1.404291633098398\n",
      "3 Train Loss 45.34099 Test MSE 8.778897794876018 Test RE 1.4162113046751752\n",
      "4 Train Loss 43.98266 Test MSE 8.773012201934096 Test RE 1.415736493317228\n",
      "5 Train Loss 41.626347 Test MSE 9.014622382900578 Test RE 1.4350988943117498\n",
      "6 Train Loss 40.1303 Test MSE 9.109275646140132 Test RE 1.442613467684836\n",
      "7 Train Loss 38.119522 Test MSE 9.142649817834462 Test RE 1.4452537441014022\n",
      "8 Train Loss 32.867157 Test MSE 8.139958932394276 Test RE 1.3637010257824547\n",
      "9 Train Loss 30.397148 Test MSE 8.258969670643134 Test RE 1.3736338862180213\n",
      "10 Train Loss 29.055614 Test MSE 7.838163247248252 Test RE 1.3381820881963262\n",
      "11 Train Loss 23.375832 Test MSE 6.004731914800225 Test RE 1.171264206799915\n",
      "12 Train Loss 18.65137 Test MSE 6.309374065173931 Test RE 1.2006079047856588\n",
      "13 Train Loss 17.354267 Test MSE 6.148643295405471 Test RE 1.1852165567709871\n",
      "14 Train Loss 16.756355 Test MSE 6.119560169078245 Test RE 1.182410192954171\n",
      "15 Train Loss 16.207067 Test MSE 6.173128915275851 Test RE 1.1875741441170946\n",
      "16 Train Loss 15.897707 Test MSE 6.0939673816486035 Test RE 1.17993510673495\n",
      "17 Train Loss 15.643875 Test MSE 6.179512677553199 Test RE 1.188188033132887\n",
      "18 Train Loss 15.295963 Test MSE 6.165854103984703 Test RE 1.1868741810423316\n",
      "19 Train Loss 15.0738325 Test MSE 6.27041631417802 Test RE 1.1968955390267066\n",
      "20 Train Loss 14.851511 Test MSE 6.272504606229982 Test RE 1.197094828774443\n",
      "21 Train Loss 14.720238 Test MSE 6.095582634955932 Test RE 1.1800914718488373\n",
      "22 Train Loss 14.575666 Test MSE 6.140896997173815 Test RE 1.18446973068619\n",
      "23 Train Loss 14.378785 Test MSE 6.035490251531412 Test RE 1.1742601875152838\n",
      "24 Train Loss 14.235743 Test MSE 5.953029420272713 Test RE 1.1662108421950024\n",
      "25 Train Loss 14.132814 Test MSE 5.929962786633215 Test RE 1.163949248531109\n",
      "26 Train Loss 13.995673 Test MSE 5.955533120778722 Test RE 1.1664560564825774\n",
      "27 Train Loss 13.821196 Test MSE 5.9432501616641 Test RE 1.165252559933699\n",
      "28 Train Loss 13.725191 Test MSE 5.8247244155031686 Test RE 1.15357477676815\n",
      "29 Train Loss 13.600838 Test MSE 5.757628332470629 Test RE 1.1469114109300926\n",
      "30 Train Loss 13.357695 Test MSE 5.69048944393808 Test RE 1.140204816675124\n",
      "31 Train Loss 13.084056 Test MSE 5.566006378205258 Test RE 1.1276645038586988\n",
      "32 Train Loss 10.322306 Test MSE 4.423161234803997 Test RE 1.0052508422407844\n",
      "33 Train Loss 9.237849 Test MSE 4.093669015032781 Test RE 0.967084501122793\n",
      "34 Train Loss 7.8628845 Test MSE 3.492907992374072 Test RE 0.8933088431707975\n",
      "35 Train Loss 6.620167 Test MSE 3.1331127132052488 Test RE 0.8460500777168354\n",
      "36 Train Loss 6.1374726 Test MSE 3.1174541954681727 Test RE 0.8439332556824435\n",
      "37 Train Loss 5.681343 Test MSE 2.7962352854271892 Test RE 0.7992725835164959\n",
      "38 Train Loss 5.496517 Test MSE 2.685419361750269 Test RE 0.783274734747395\n",
      "39 Train Loss 5.324047 Test MSE 2.7167771445175455 Test RE 0.7878346319269529\n",
      "40 Train Loss 5.19182 Test MSE 2.7087791076327106 Test RE 0.7866741070677354\n",
      "41 Train Loss 5.0484385 Test MSE 2.683672070918833 Test RE 0.783019871116282\n",
      "42 Train Loss 4.932813 Test MSE 2.767688619303813 Test RE 0.7951822445802846\n",
      "43 Train Loss 4.7371387 Test MSE 2.670203487907844 Test RE 0.781052523166603\n",
      "44 Train Loss 4.562452 Test MSE 2.6044490744065487 Test RE 0.7713757741140781\n",
      "45 Train Loss 4.4558587 Test MSE 2.5602929397069594 Test RE 0.7648088232961034\n",
      "46 Train Loss 4.2898583 Test MSE 2.4539802368192043 Test RE 0.7487616466113644\n",
      "47 Train Loss 4.163256 Test MSE 2.445744026968796 Test RE 0.74750406899397\n",
      "48 Train Loss 3.9914527 Test MSE 2.2953352528050526 Test RE 0.7241543164176436\n",
      "49 Train Loss 3.071672 Test MSE 1.5114820328069078 Test RE 0.587637570837475\n",
      "50 Train Loss 2.1045551 Test MSE 1.02486322974101 Test RE 0.4838837259874418\n",
      "51 Train Loss 1.5931985 Test MSE 0.7521136568593613 Test RE 0.41452411198673467\n",
      "52 Train Loss 1.2653407 Test MSE 0.4603544179790227 Test RE 0.3243054282397499\n",
      "53 Train Loss 0.80027807 Test MSE 0.16627455900066185 Test RE 0.19490409442672782\n",
      "54 Train Loss 0.56161684 Test MSE 0.09006533716461856 Test RE 0.1434454904976342\n",
      "55 Train Loss 0.42096955 Test MSE 0.06786036874672868 Test RE 0.12451342168518868\n",
      "56 Train Loss 0.2963235 Test MSE 0.04176698434519026 Test RE 0.09768426655750452\n",
      "57 Train Loss 0.21803114 Test MSE 0.025584077991040215 Test RE 0.07645272075412339\n",
      "58 Train Loss 0.16225146 Test MSE 0.021781006621285556 Test RE 0.07054188065057287\n",
      "59 Train Loss 0.13765067 Test MSE 0.019479992823085664 Test RE 0.06671176892786027\n",
      "60 Train Loss 0.12660842 Test MSE 0.015743577086575502 Test RE 0.05997355152926335\n",
      "61 Train Loss 0.10429957 Test MSE 0.012353421873195674 Test RE 0.05312533684739995\n",
      "62 Train Loss 0.08330996 Test MSE 0.00817733308757896 Test RE 0.04322290022844109\n",
      "63 Train Loss 0.07669766 Test MSE 0.0069635291059866565 Test RE 0.039886208750852054\n",
      "64 Train Loss 0.07032924 Test MSE 0.006084632229538766 Test RE 0.03728423417538311\n",
      "65 Train Loss 0.06522303 Test MSE 0.006540419854668274 Test RE 0.03865546255119224\n",
      "66 Train Loss 0.058219224 Test MSE 0.008365848036041179 Test RE 0.043718277861197814\n",
      "67 Train Loss 0.050870694 Test MSE 0.008830379338867933 Test RE 0.04491565533437645\n",
      "68 Train Loss 0.04635197 Test MSE 0.007595107151323067 Test RE 0.041655755244252704\n",
      "69 Train Loss 0.039791137 Test MSE 0.006978024864120747 Test RE 0.03992770209738165\n",
      "70 Train Loss 0.03485244 Test MSE 0.006401251124677768 Test RE 0.0382419908154954\n",
      "71 Train Loss 0.029360685 Test MSE 0.007043255825469372 Test RE 0.04011389116397699\n",
      "72 Train Loss 0.027375454 Test MSE 0.007272889593601715 Test RE 0.0407625700061909\n",
      "73 Train Loss 0.024886439 Test MSE 0.006250846007652907 Test RE 0.03779004945587647\n",
      "74 Train Loss 0.023970012 Test MSE 0.005965547623476011 Test RE 0.03691757950254327\n",
      "75 Train Loss 0.022016672 Test MSE 0.0053365011870700136 Test RE 0.03491695518185598\n",
      "76 Train Loss 0.01999178 Test MSE 0.004512981556977252 Test RE 0.032109965550874274\n",
      "77 Train Loss 0.019334577 Test MSE 0.004432113698385809 Test RE 0.03182097678683151\n",
      "78 Train Loss 0.018040154 Test MSE 0.004195799039268417 Test RE 0.030961029976646737\n",
      "79 Train Loss 0.016645353 Test MSE 0.0037674370911844344 Test RE 0.02933803787246307\n",
      "80 Train Loss 0.015421604 Test MSE 0.003831258573658291 Test RE 0.029585491744945017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 0.014537037 Test MSE 0.003523067364413495 Test RE 0.028370600871188784\n",
      "82 Train Loss 0.013203066 Test MSE 0.003910076480196382 Test RE 0.029888263705676175\n",
      "83 Train Loss 0.012261665 Test MSE 0.003869575744909445 Test RE 0.02973306883974674\n",
      "84 Train Loss 0.0118974475 Test MSE 0.0036587968854636284 Test RE 0.02891193844885962\n",
      "85 Train Loss 0.010956626 Test MSE 0.003071812573356439 Test RE 0.02649143092107259\n",
      "86 Train Loss 0.009610856 Test MSE 0.0026232054489926035 Test RE 0.024480721495024116\n",
      "87 Train Loss 0.009317379 Test MSE 0.0023952976749200853 Test RE 0.023393101584148177\n",
      "88 Train Loss 0.008992898 Test MSE 0.002331294271010738 Test RE 0.023078448470418417\n",
      "89 Train Loss 0.008606883 Test MSE 0.002462616284989968 Test RE 0.023719549363838018\n",
      "90 Train Loss 0.007569922 Test MSE 0.0023837395418565555 Test RE 0.023336593463508134\n",
      "91 Train Loss 0.007207401 Test MSE 0.0021920640083236942 Test RE 0.02237869080923143\n",
      "92 Train Loss 0.0068047205 Test MSE 0.0023203722707269333 Test RE 0.023024324299354696\n",
      "93 Train Loss 0.0066254847 Test MSE 0.0022254142434095098 Test RE 0.022548283779395602\n",
      "94 Train Loss 0.0065404726 Test MSE 0.0021636386578479457 Test RE 0.022233120739613692\n",
      "95 Train Loss 0.006149793 Test MSE 0.002074582325064154 Test RE 0.021770750317252813\n",
      "96 Train Loss 0.0055102343 Test MSE 0.0020853216809716586 Test RE 0.021827027196353627\n",
      "97 Train Loss 0.00492734 Test MSE 0.002143239676059988 Test RE 0.02212806459260083\n",
      "98 Train Loss 0.0046260552 Test MSE 0.0021407470120266402 Test RE 0.0221151929855853\n",
      "99 Train Loss 0.0045038755 Test MSE 0.0019924225744052393 Test RE 0.02133530163043919\n",
      "Training time: 66.98\n",
      "7\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 47.494415 Test MSE 7.710324869729255 Test RE 1.327224527136887\n",
      "1 Train Loss 31.791271 Test MSE 6.734358244794662 Test RE 1.2403840358898364\n",
      "2 Train Loss 26.650116 Test MSE 6.251885852374374 Test RE 1.1951256854642283\n",
      "3 Train Loss 22.370422 Test MSE 5.936561494430087 Test RE 1.1645966746418437\n",
      "4 Train Loss 18.988836 Test MSE 5.607056349416517 Test RE 1.1318151961038703\n",
      "5 Train Loss 15.546596 Test MSE 5.462709847756516 Test RE 1.1171516390806273\n",
      "6 Train Loss 13.382267 Test MSE 5.788938638047368 Test RE 1.1500256670631421\n",
      "7 Train Loss 11.546297 Test MSE 5.433445822755883 Test RE 1.114155300656697\n",
      "8 Train Loss 10.671357 Test MSE 5.292226933954574 Test RE 1.099581158791991\n",
      "9 Train Loss 9.993058 Test MSE 5.2008587849111345 Test RE 1.0900479216749517\n",
      "10 Train Loss 9.609144 Test MSE 5.070773711860651 Test RE 1.0763293309768511\n",
      "11 Train Loss 8.984043 Test MSE 4.846438478685022 Test RE 1.0522511579476836\n",
      "12 Train Loss 8.535484 Test MSE 4.715021813964027 Test RE 1.037886620482133\n",
      "13 Train Loss 7.724366 Test MSE 4.36881271028266 Test RE 0.9990558652330221\n",
      "14 Train Loss 6.8127813 Test MSE 3.8656733896246083 Test RE 0.9397679704747499\n",
      "15 Train Loss 6.237667 Test MSE 3.682196899979612 Test RE 0.9171947587104299\n",
      "16 Train Loss 5.8449087 Test MSE 3.4245641292112303 Test RE 0.8845262214656104\n",
      "17 Train Loss 5.2468452 Test MSE 3.238111939149491 Test RE 0.8601099846575865\n",
      "18 Train Loss 3.6638582 Test MSE 2.521391160325618 Test RE 0.7589762275262601\n",
      "19 Train Loss 2.5818946 Test MSE 1.9559661830124186 Test RE 0.6684804816984177\n",
      "20 Train Loss 1.7929763 Test MSE 1.3130786923712097 Test RE 0.5477134896070115\n",
      "21 Train Loss 1.3194966 Test MSE 0.8389864575733401 Test RE 0.4378098574672586\n",
      "22 Train Loss 0.9693667 Test MSE 0.4946231328575277 Test RE 0.33615940952785267\n",
      "23 Train Loss 0.6031113 Test MSE 0.20388832135283502 Test RE 0.2158262353495891\n",
      "24 Train Loss 0.42726216 Test MSE 0.1081396783760504 Test RE 0.1571811989141594\n",
      "25 Train Loss 0.31428653 Test MSE 0.06402332956731442 Test RE 0.12094201173572736\n",
      "26 Train Loss 0.23423901 Test MSE 0.058138556812286316 Test RE 0.11524980089158209\n",
      "27 Train Loss 0.17893769 Test MSE 0.06166542689961732 Test RE 0.118694045264782\n",
      "28 Train Loss 0.149201 Test MSE 0.04963551480794131 Test RE 0.10648889624331834\n",
      "29 Train Loss 0.12935874 Test MSE 0.031395484405831946 Test RE 0.08469185677613252\n",
      "30 Train Loss 0.10662594 Test MSE 0.023859101005014368 Test RE 0.07383037905230903\n",
      "31 Train Loss 0.084395796 Test MSE 0.018104862780710836 Test RE 0.06431402336353649\n",
      "32 Train Loss 0.07025556 Test MSE 0.01769558926896443 Test RE 0.06358293555735216\n",
      "33 Train Loss 0.061817363 Test MSE 0.011568018988345582 Test RE 0.05140881067037226\n",
      "34 Train Loss 0.052964937 Test MSE 0.01004163148919998 Test RE 0.04789720816919605\n",
      "35 Train Loss 0.04322265 Test MSE 0.008474494920817487 Test RE 0.044001245736936236\n",
      "36 Train Loss 0.03623034 Test MSE 0.006482345079089358 Test RE 0.03848346190379999\n",
      "37 Train Loss 0.03120731 Test MSE 0.0072100687618939785 Test RE 0.040586141350595996\n",
      "38 Train Loss 0.026661139 Test MSE 0.006021976412744258 Test RE 0.037091772323375974\n",
      "39 Train Loss 0.023198538 Test MSE 0.005757775920140094 Test RE 0.036268988169818384\n",
      "40 Train Loss 0.020964907 Test MSE 0.005855664371619016 Test RE 0.036575994925379586\n",
      "41 Train Loss 0.018900089 Test MSE 0.005037811235512844 Test RE 0.03392571470484722\n",
      "42 Train Loss 0.017339455 Test MSE 0.004734940184987146 Test RE 0.03289010870071089\n",
      "43 Train Loss 0.014958274 Test MSE 0.004134563022447284 Test RE 0.03073426760480326\n",
      "44 Train Loss 0.014054114 Test MSE 0.004287161131708272 Test RE 0.03129629765206529\n",
      "45 Train Loss 0.013136235 Test MSE 0.004194797238639732 Test RE 0.030957333585251535\n",
      "46 Train Loss 0.012500906 Test MSE 0.004071714833048392 Test RE 0.030499782150056085\n",
      "47 Train Loss 0.01109158 Test MSE 0.0033083925334811224 Test RE 0.027492648293634205\n",
      "48 Train Loss 0.010502624 Test MSE 0.0027199316131168902 Test RE 0.024927977997223377\n",
      "49 Train Loss 0.009800647 Test MSE 0.0028114336935477127 Test RE 0.025343814603100742\n",
      "50 Train Loss 0.009231117 Test MSE 0.0024511296014667725 Test RE 0.023664165701834362\n",
      "51 Train Loss 0.00836048 Test MSE 0.0023124910057852714 Test RE 0.022985189383442427\n",
      "52 Train Loss 0.007691934 Test MSE 0.0019382072008508231 Test RE 0.021043024539715075\n",
      "53 Train Loss 0.007385364 Test MSE 0.0018547732656567434 Test RE 0.020585123363217092\n",
      "54 Train Loss 0.0069507146 Test MSE 0.0016027013499555634 Test RE 0.019135259739074484\n",
      "55 Train Loss 0.00662287 Test MSE 0.0014701348045571604 Test RE 0.01832679998029873\n",
      "56 Train Loss 0.006391382 Test MSE 0.0015069637388364801 Test RE 0.01855493603011044\n",
      "57 Train Loss 0.00602793 Test MSE 0.0019041372030918278 Test RE 0.02085725637483547\n",
      "58 Train Loss 0.005666837 Test MSE 0.0020916444675881485 Test RE 0.021860092402477077\n",
      "59 Train Loss 0.005566513 Test MSE 0.002010008039916961 Test RE 0.021429249313444306\n",
      "60 Train Loss 0.005418158 Test MSE 0.002177944105542589 Test RE 0.022306499617027978\n",
      "61 Train Loss 0.0049993163 Test MSE 0.002073621305170529 Test RE 0.021765707242454215\n",
      "62 Train Loss 0.0046348004 Test MSE 0.0022681329753080786 Test RE 0.022763671860073588\n",
      "63 Train Loss 0.004452351 Test MSE 0.002183864020488777 Test RE 0.02233679492354617\n",
      "64 Train Loss 0.0043227132 Test MSE 0.001985619188974726 Test RE 0.02129884440382846\n",
      "65 Train Loss 0.00414706 Test MSE 0.001913917505392734 Test RE 0.020910752783005172\n",
      "66 Train Loss 0.0039009473 Test MSE 0.0017777815037978856 Test RE 0.020153350219169055\n",
      "67 Train Loss 0.0037416143 Test MSE 0.0018142408680030706 Test RE 0.02035895737714898\n",
      "68 Train Loss 0.003638845 Test MSE 0.0016636857687785294 Test RE 0.01949591896851978\n",
      "69 Train Loss 0.0033853068 Test MSE 0.0015396474626342953 Test RE 0.018755070698029584\n",
      "70 Train Loss 0.0031462195 Test MSE 0.0013416726816379634 Test RE 0.017507790807417548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Train Loss 0.0030085517 Test MSE 0.0013592457205230577 Test RE 0.017622075087974864\n",
      "72 Train Loss 0.002865712 Test MSE 0.0014679871626009054 Test RE 0.018313408762886136\n",
      "73 Train Loss 0.002719506 Test MSE 0.0016360417865550847 Test RE 0.019333267332501822\n",
      "74 Train Loss 0.0026089472 Test MSE 0.0014412992412815605 Test RE 0.018146176856437945\n",
      "75 Train Loss 0.0025008647 Test MSE 0.0015960385334650572 Test RE 0.019095443366897624\n",
      "76 Train Loss 0.0023822498 Test MSE 0.0016157860432752505 Test RE 0.019213212517947564\n",
      "77 Train Loss 0.002239947 Test MSE 0.0015749570763429381 Test RE 0.018968911980399735\n",
      "78 Train Loss 0.0020898362 Test MSE 0.001394652633864921 Test RE 0.017850117775996502\n",
      "79 Train Loss 0.0019393334 Test MSE 0.0015473189228922865 Test RE 0.0188017372256586\n",
      "80 Train Loss 0.0018130278 Test MSE 0.0013036250923995818 Test RE 0.01725775963639396\n",
      "81 Train Loss 0.001719081 Test MSE 0.0013551794939207964 Test RE 0.01759569684762163\n",
      "82 Train Loss 0.0016677696 Test MSE 0.001385623900891092 Test RE 0.01779224471590743\n",
      "83 Train Loss 0.0016286089 Test MSE 0.0013603964573529162 Test RE 0.017629532930371204\n",
      "84 Train Loss 0.0015723922 Test MSE 0.0012815007550576333 Test RE 0.017110688832747217\n",
      "85 Train Loss 0.0015136101 Test MSE 0.0011827426245097454 Test RE 0.016438159289008037\n",
      "86 Train Loss 0.0014704525 Test MSE 0.0012074014301207644 Test RE 0.016608633559037342\n",
      "87 Train Loss 0.0014183575 Test MSE 0.0011938146186639116 Test RE 0.016514921230198442\n",
      "88 Train Loss 0.001372356 Test MSE 0.0011654134953663468 Test RE 0.016317291863040734\n",
      "89 Train Loss 0.0013522033 Test MSE 0.001177209915571605 Test RE 0.016399666484867414\n",
      "90 Train Loss 0.0013188936 Test MSE 0.001212708193041955 Test RE 0.016645092620958254\n",
      "91 Train Loss 0.0012800981 Test MSE 0.0011793271545836087 Test RE 0.01641440744786211\n",
      "92 Train Loss 0.0012387991 Test MSE 0.0011598572189476187 Test RE 0.016278347872169942\n",
      "93 Train Loss 0.0012066737 Test MSE 0.0010302403519718087 Test RE 0.015341836084557008\n",
      "94 Train Loss 0.0011962758 Test MSE 0.001013726230882415 Test RE 0.015218379239211294\n",
      "95 Train Loss 0.0011807852 Test MSE 0.0009947851264197718 Test RE 0.015075533910146852\n",
      "96 Train Loss 0.0011578473 Test MSE 0.0009983011349594681 Test RE 0.0151021521972399\n",
      "97 Train Loss 0.001126242 Test MSE 0.0009523592595476902 Test RE 0.014750558510760377\n",
      "98 Train Loss 0.0010942944 Test MSE 0.000974391134729709 Test RE 0.014920202663551216\n",
      "99 Train Loss 0.0010740604 Test MSE 0.0009565680015075344 Test RE 0.014783116002274815\n",
      "Training time: 66.60\n",
      "8\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 52.040977 Test MSE 9.315493229722556 Test RE 1.4588511684020764\n",
      "1 Train Loss 36.879883 Test MSE 8.536082438005959 Test RE 1.3964884902093462\n",
      "2 Train Loss 29.135227 Test MSE 6.908978502577336 Test RE 1.2563625459922734\n",
      "3 Train Loss 25.81011 Test MSE 6.620983490427874 Test RE 1.2298986158853942\n",
      "4 Train Loss 21.31179 Test MSE 7.2008963183596375 Test RE 1.282629839267753\n",
      "5 Train Loss 17.391403 Test MSE 7.218502660670084 Test RE 1.2841969103820157\n",
      "6 Train Loss 15.507196 Test MSE 7.100523490825964 Test RE 1.2736592222152456\n",
      "7 Train Loss 13.983675 Test MSE 7.042686141265904 Test RE 1.268461316903168\n",
      "8 Train Loss 12.647607 Test MSE 6.9127277882882945 Test RE 1.2567033940104042\n",
      "9 Train Loss 10.933117 Test MSE 6.737318866894907 Test RE 1.240656660595187\n",
      "10 Train Loss 9.290894 Test MSE 6.283774201583025 Test RE 1.1981697359287464\n",
      "11 Train Loss 8.532065 Test MSE 6.101178837096323 Test RE 1.1806330538240621\n",
      "12 Train Loss 7.9380903 Test MSE 6.021674440484299 Test RE 1.1729154208900885\n",
      "13 Train Loss 7.313755 Test MSE 5.883120004250333 Test RE 1.1593429192958113\n",
      "14 Train Loss 6.744997 Test MSE 5.716482780012411 Test RE 1.1428059952862266\n",
      "15 Train Loss 5.8814964 Test MSE 5.501602082646534 Test RE 1.1211214146459592\n",
      "16 Train Loss 4.0302944 Test MSE 4.354147096493181 Test RE 0.9973775964203746\n",
      "17 Train Loss 3.034702 Test MSE 4.607949191714343 Test RE 1.0260343516009545\n",
      "18 Train Loss 2.5806227 Test MSE 4.7330984995910015 Test RE 1.0398742679460435\n",
      "19 Train Loss 2.315976 Test MSE 4.610762303047746 Test RE 1.0263474961642762\n",
      "20 Train Loss 2.1577146 Test MSE 4.547999641529672 Test RE 1.0193381327347502\n",
      "21 Train Loss 2.03753 Test MSE 4.459936338879463 Test RE 1.0094211267714839\n",
      "22 Train Loss 1.9752297 Test MSE 4.410755093697877 Test RE 1.0038400818904099\n",
      "23 Train Loss 1.8833886 Test MSE 4.352488468385996 Test RE 0.9971876124752301\n",
      "24 Train Loss 1.8348764 Test MSE 4.276226685486168 Test RE 0.9884129344200011\n",
      "25 Train Loss 1.7868338 Test MSE 4.259417563400868 Test RE 0.986468379777686\n",
      "26 Train Loss 1.7483346 Test MSE 4.235978036783694 Test RE 0.9837503731677585\n",
      "27 Train Loss 1.7110424 Test MSE 4.143643986956959 Test RE 0.9729696145152643\n",
      "28 Train Loss 1.6493895 Test MSE 4.105527540130481 Test RE 0.9684842115704331\n",
      "29 Train Loss 1.6063665 Test MSE 4.112488791322611 Test RE 0.9693049351418742\n",
      "30 Train Loss 1.5662757 Test MSE 4.118234471785101 Test RE 0.969981821183858\n",
      "31 Train Loss 1.5258822 Test MSE 4.095682968503321 Test RE 0.9673223591044945\n",
      "32 Train Loss 1.495772 Test MSE 4.082933558391943 Test RE 0.9658156016012518\n",
      "33 Train Loss 1.470086 Test MSE 4.04548603434196 Test RE 0.9613763039404469\n",
      "34 Train Loss 1.4436162 Test MSE 4.053374468293249 Test RE 0.9623131580113136\n",
      "35 Train Loss 1.4200187 Test MSE 4.032733851198217 Test RE 0.9598598825429924\n",
      "36 Train Loss 1.3907492 Test MSE 3.9461815713227946 Test RE 0.9495035489307171\n",
      "37 Train Loss 1.3591748 Test MSE 3.892316667606937 Test RE 0.9430009782525134\n",
      "38 Train Loss 1.3220469 Test MSE 3.7586161648772034 Test RE 0.9266634824903529\n",
      "39 Train Loss 1.265676 Test MSE 3.5958468097545944 Test RE 0.9063765297064176\n",
      "40 Train Loss 1.2233031 Test MSE 3.5288538179944666 Test RE 0.897893637956794\n",
      "41 Train Loss 1.1614265 Test MSE 3.3469656669538717 Test RE 0.874447396340358\n",
      "42 Train Loss 1.086785 Test MSE 3.1853051285155605 Test RE 0.8530678616130878\n",
      "43 Train Loss 1.0254662 Test MSE 3.083795128187718 Test RE 0.8393649291078741\n",
      "44 Train Loss 0.9882363 Test MSE 3.0070245195100203 Test RE 0.8288511511373077\n",
      "45 Train Loss 0.9542569 Test MSE 2.9414028847523235 Test RE 0.8197573462519536\n",
      "46 Train Loss 0.9107728 Test MSE 2.893025489705378 Test RE 0.8129881030422238\n",
      "47 Train Loss 0.8787518 Test MSE 2.8568818549648696 Test RE 0.8078936611965262\n",
      "48 Train Loss 0.843461 Test MSE 2.7952536496502693 Test RE 0.7991322763973363\n",
      "49 Train Loss 0.81361157 Test MSE 2.783363582372335 Test RE 0.797430845406368\n",
      "50 Train Loss 0.7906756 Test MSE 2.762652129538772 Test RE 0.7944584003488063\n",
      "51 Train Loss 0.7666986 Test MSE 2.7625303730980213 Test RE 0.7944408933503819\n",
      "52 Train Loss 0.7502367 Test MSE 2.719977527373406 Test RE 0.788298532755683\n",
      "53 Train Loss 0.7275769 Test MSE 2.736275726948779 Test RE 0.7906567614439317\n",
      "54 Train Loss 0.7139867 Test MSE 2.7139432462529833 Test RE 0.7874236255019628\n",
      "55 Train Loss 0.6974708 Test MSE 2.704227747619418 Test RE 0.7860129342325889\n",
      "56 Train Loss 0.68346 Test MSE 2.7191817452168254 Test RE 0.7881832083108966\n",
      "57 Train Loss 0.6697005 Test MSE 2.716851544189827 Test RE 0.7878454193846687\n",
      "58 Train Loss 0.65670526 Test MSE 2.712456732460132 Test RE 0.7872079473723712\n",
      "59 Train Loss 0.6480316 Test MSE 2.6929671144804135 Test RE 0.7843747148521146\n",
      "60 Train Loss 0.6405783 Test MSE 2.685298877888865 Test RE 0.7832571633720501\n",
      "61 Train Loss 0.6343682 Test MSE 2.688258525154492 Test RE 0.7836886845225632\n",
      "62 Train Loss 0.629102 Test MSE 2.713105758089925 Test RE 0.7873021216994228\n",
      "63 Train Loss 0.62229306 Test MSE 2.7212109614538798 Test RE 0.7884772482159627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Train Loss 0.61692286 Test MSE 2.732830196937022 Test RE 0.7901588054621788\n",
      "65 Train Loss 0.6121849 Test MSE 2.737679100064406 Test RE 0.7908594903206086\n",
      "66 Train Loss 0.6060517 Test MSE 2.75052104577051 Test RE 0.7927122078842901\n",
      "67 Train Loss 0.5999608 Test MSE 2.743877799334644 Test RE 0.7917543227929061\n",
      "68 Train Loss 0.59466904 Test MSE 2.7517565672954554 Test RE 0.7928902292513988\n",
      "69 Train Loss 0.5891331 Test MSE 2.7509104727181497 Test RE 0.7927683231737789\n",
      "70 Train Loss 0.5851697 Test MSE 2.753832086296659 Test RE 0.7931891925686294\n",
      "71 Train Loss 0.58068806 Test MSE 2.7701960997384565 Test RE 0.7955423740579588\n",
      "72 Train Loss 0.575721 Test MSE 2.7832105084582066 Test RE 0.797408917344246\n",
      "73 Train Loss 0.57085896 Test MSE 2.8108103808351252 Test RE 0.801352940135414\n",
      "74 Train Loss 0.56599593 Test MSE 2.828564050764026 Test RE 0.8038797134192819\n",
      "75 Train Loss 0.5602837 Test MSE 2.8344867733195223 Test RE 0.8047208940833852\n",
      "76 Train Loss 0.55463356 Test MSE 2.8570494581583787 Test RE 0.8079173589863932\n",
      "77 Train Loss 0.548236 Test MSE 2.880878177173346 Test RE 0.8112795095761044\n",
      "78 Train Loss 0.5408706 Test MSE 2.8883396140334145 Test RE 0.812329431862479\n",
      "79 Train Loss 0.5360126 Test MSE 2.900114885446564 Test RE 0.8139836123792826\n",
      "80 Train Loss 0.5311019 Test MSE 2.9137201408926217 Test RE 0.8158906914852213\n",
      "81 Train Loss 0.5243593 Test MSE 2.9120782326785175 Test RE 0.8156607781204693\n",
      "82 Train Loss 0.5175308 Test MSE 2.927702612431712 Test RE 0.8178460121877276\n",
      "83 Train Loss 0.51293147 Test MSE 2.923272326897497 Test RE 0.8172269836194881\n",
      "84 Train Loss 0.5089346 Test MSE 2.934216786969494 Test RE 0.81875536538651\n",
      "85 Train Loss 0.50327086 Test MSE 2.927018312560204 Test RE 0.8177504279188984\n",
      "86 Train Loss 0.49881604 Test MSE 2.9270882292991165 Test RE 0.8177601945304527\n",
      "87 Train Loss 0.49519205 Test MSE 2.9282989860406463 Test RE 0.8179293056445193\n",
      "88 Train Loss 0.4920139 Test MSE 2.9274032718673695 Test RE 0.8178042011199249\n",
      "89 Train Loss 0.48939395 Test MSE 2.934854308647715 Test RE 0.8188443066582415\n",
      "90 Train Loss 0.48616308 Test MSE 2.9452220402674834 Test RE 0.8202893653785964\n",
      "91 Train Loss 0.48191795 Test MSE 2.945656959724063 Test RE 0.8203499290017269\n",
      "92 Train Loss 0.47952104 Test MSE 2.950622449696345 Test RE 0.821041069246406\n",
      "93 Train Loss 0.47628057 Test MSE 2.960170415156327 Test RE 0.822368406162325\n",
      "94 Train Loss 0.4738964 Test MSE 2.9717662572609846 Test RE 0.8239775590540779\n",
      "95 Train Loss 0.47207242 Test MSE 2.982068495189626 Test RE 0.8254045670686075\n",
      "96 Train Loss 0.4703772 Test MSE 2.98146869081445 Test RE 0.8253215531860097\n",
      "97 Train Loss 0.46858674 Test MSE 2.980683825505178 Test RE 0.8252129139615783\n",
      "98 Train Loss 0.46538526 Test MSE 2.980398001184375 Test RE 0.8251733472733354\n",
      "99 Train Loss 0.46245456 Test MSE 2.990133213276317 Test RE 0.82651992720466\n",
      "Training time: 67.42\n",
      "9\n",
      "KG_rowdy_tune18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 54.795 Test MSE 8.407924000239692 Test RE 1.3859655932186297\n",
      "1 Train Loss 45.95914 Test MSE 8.720938555066654 Test RE 1.4115285722250848\n",
      "2 Train Loss 44.323616 Test MSE 8.638802146330448 Test RE 1.4048657477717017\n",
      "3 Train Loss 43.1936 Test MSE 8.718314376725681 Test RE 1.4113161878944498\n",
      "4 Train Loss 42.14991 Test MSE 8.799759547745893 Test RE 1.4178930145913968\n",
      "5 Train Loss 41.126865 Test MSE 8.591445235512776 Test RE 1.401009800549738\n",
      "6 Train Loss 39.688286 Test MSE 9.13136914098561 Test RE 1.4443618542833596\n",
      "7 Train Loss 38.86643 Test MSE 9.140428281918107 Test RE 1.4450781452199941\n",
      "8 Train Loss 37.91861 Test MSE 9.597702240448143 Test RE 1.4807839427727862\n",
      "9 Train Loss 36.512093 Test MSE 9.816503823200998 Test RE 1.4975677545280248\n",
      "10 Train Loss 35.291264 Test MSE 9.873290331458902 Test RE 1.5018930730129723\n",
      "11 Train Loss 33.324333 Test MSE 10.673183644664759 Test RE 1.5615469675852713\n",
      "12 Train Loss 29.380835 Test MSE 10.090234592910674 Test RE 1.518303845597684\n",
      "13 Train Loss 25.074116 Test MSE 9.628043916166604 Test RE 1.4831227323953369\n",
      "14 Train Loss 21.308622 Test MSE 9.97324387967366 Test RE 1.5094762347070245\n",
      "15 Train Loss 19.883652 Test MSE 9.752931824489487 Test RE 1.4927107293976825\n",
      "16 Train Loss 18.19049 Test MSE 9.456028698354213 Test RE 1.4698142414770625\n",
      "17 Train Loss 16.734364 Test MSE 8.65940760167845 Test RE 1.4065402077671485\n",
      "18 Train Loss 15.725996 Test MSE 8.297020015958473 Test RE 1.3767945214581352\n",
      "19 Train Loss 14.431065 Test MSE 7.712646716339777 Test RE 1.3274243487956134\n",
      "20 Train Loss 11.662038 Test MSE 5.706719151342158 Test RE 1.1418296342737082\n",
      "21 Train Loss 9.575553 Test MSE 5.1856220788713685 Test RE 1.0884500199872327\n",
      "22 Train Loss 8.475647 Test MSE 5.3598068555274185 Test RE 1.1065795249828292\n",
      "23 Train Loss 7.32294 Test MSE 5.51832727505144 Test RE 1.122824258808074\n",
      "24 Train Loss 6.6068873 Test MSE 4.783535034729733 Test RE 1.0454001060697358\n",
      "25 Train Loss 5.885925 Test MSE 4.734952571423716 Test RE 1.0400779202485908\n",
      "26 Train Loss 5.234072 Test MSE 4.398307446412275 Test RE 1.0024226062704513\n",
      "27 Train Loss 4.7326374 Test MSE 4.302488377732388 Test RE 0.9914433707037766\n",
      "28 Train Loss 4.3944244 Test MSE 4.477800892224543 Test RE 1.0114407560150143\n",
      "29 Train Loss 4.104148 Test MSE 4.388510827752894 Test RE 1.0013056054019616\n",
      "30 Train Loss 3.8050718 Test MSE 4.466829030884962 Test RE 1.0102008400093032\n",
      "31 Train Loss 3.5640047 Test MSE 4.478562512264387 Test RE 1.0115267693074879\n",
      "32 Train Loss 3.253161 Test MSE 4.458882062568902 Test RE 1.0093018120997597\n",
      "33 Train Loss 2.9979177 Test MSE 4.347452756312428 Test RE 0.9966105859045054\n",
      "34 Train Loss 2.8848603 Test MSE 4.425182569242771 Test RE 1.0054805101126865\n",
      "35 Train Loss 2.7907465 Test MSE 4.4319809886916435 Test RE 1.0062525748519058\n",
      "36 Train Loss 2.7241883 Test MSE 4.495952315730296 Test RE 1.0134886945291302\n",
      "37 Train Loss 2.6600158 Test MSE 4.4944151411354865 Test RE 1.01331542286723\n",
      "38 Train Loss 2.6194875 Test MSE 4.504727167556175 Test RE 1.0144772368284627\n",
      "39 Train Loss 2.588442 Test MSE 4.565476986016867 Test RE 1.0212948436448337\n",
      "40 Train Loss 2.5529876 Test MSE 4.619187027409572 Test RE 1.0272847325700118\n",
      "41 Train Loss 2.5110552 Test MSE 4.63845999264615 Test RE 1.0294256086355733\n",
      "42 Train Loss 2.4588985 Test MSE 4.595698654119777 Test RE 1.0246695538144304\n",
      "43 Train Loss 2.4107773 Test MSE 4.4942143003017 Test RE 1.013292781724647\n",
      "44 Train Loss 2.372902 Test MSE 4.53029337859454 Test RE 1.0173519551334762\n",
      "45 Train Loss 2.3378537 Test MSE 4.5341729361992895 Test RE 1.0177874711763102\n",
      "46 Train Loss 2.2833319 Test MSE 4.520365122803058 Test RE 1.01623656706013\n",
      "47 Train Loss 2.25214 Test MSE 4.497382418970927 Test RE 1.013649870418541\n",
      "48 Train Loss 2.209769 Test MSE 4.5184172474213256 Test RE 1.0160175896732908\n",
      "49 Train Loss 2.1859167 Test MSE 4.516068912944055 Test RE 1.0157535304801457\n",
      "50 Train Loss 2.1618035 Test MSE 4.497288864464638 Test RE 1.0136393273962316\n",
      "51 Train Loss 2.1442027 Test MSE 4.548550953538303 Test RE 1.0193999133380982\n",
      "52 Train Loss 2.1162982 Test MSE 4.502338572593225 Test RE 1.0142082420114404\n",
      "53 Train Loss 2.0925357 Test MSE 4.506585446548739 Test RE 1.0146864600832768\n",
      "54 Train Loss 2.0655918 Test MSE 4.4970778753440275 Test RE 1.013615549806534\n",
      "55 Train Loss 2.0415828 Test MSE 4.433645425822455 Test RE 1.006441506949628\n",
      "56 Train Loss 2.0040436 Test MSE 4.426362820014568 Test RE 1.005614588200077\n",
      "57 Train Loss 1.986817 Test MSE 4.445655534302872 Test RE 1.0078037377754867\n",
      "58 Train Loss 1.9478197 Test MSE 4.442196316083363 Test RE 1.0074115693478412\n",
      "59 Train Loss 1.933923 Test MSE 4.429931547601533 Test RE 1.0060198917873937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Train Loss 1.9038256 Test MSE 4.443044873990739 Test RE 1.0075077837171016\n",
      "61 Train Loss 1.8808426 Test MSE 4.396663913447137 Test RE 1.0022352991579349\n",
      "62 Train Loss 1.8445876 Test MSE 4.442213444985688 Test RE 1.0074135116120397\n",
      "63 Train Loss 1.827374 Test MSE 4.425296067749585 Test RE 1.0054934044738797\n",
      "64 Train Loss 1.7977606 Test MSE 4.392810434708001 Test RE 1.0017959957335987\n",
      "65 Train Loss 1.7801462 Test MSE 4.384743724326702 Test RE 1.0008757521157814\n",
      "66 Train Loss 1.7324326 Test MSE 4.3926802038048365 Test RE 1.0017811458139156\n",
      "67 Train Loss 1.7165947 Test MSE 4.388201837916195 Test RE 1.0012703544120656\n",
      "68 Train Loss 1.6952797 Test MSE 4.377836429587213 Test RE 1.0000871007088044\n",
      "69 Train Loss 1.673385 Test MSE 4.353041771648431 Test RE 0.9972509934157389\n",
      "70 Train Loss 1.6546547 Test MSE 4.325367012483014 Test RE 0.9940758933779181\n",
      "71 Train Loss 1.6191334 Test MSE 4.317125097771312 Test RE 0.993128344259202\n",
      "72 Train Loss 1.5988079 Test MSE 4.25170013280569 Test RE 0.9855743076803035\n",
      "73 Train Loss 1.5681221 Test MSE 4.232118969468889 Test RE 0.9833021621627289\n",
      "74 Train Loss 1.5394382 Test MSE 4.229073740593562 Test RE 0.9829483300746203\n",
      "75 Train Loss 1.5228277 Test MSE 4.201459433306797 Test RE 0.9797339274253314\n",
      "76 Train Loss 1.4901432 Test MSE 4.144309891903464 Test RE 0.9730477919905502\n",
      "77 Train Loss 1.4623655 Test MSE 4.132921943901112 Test RE 0.9717099769293548\n",
      "78 Train Loss 1.4381237 Test MSE 4.080231754320788 Test RE 0.9654959936138088\n",
      "79 Train Loss 1.4175303 Test MSE 4.038495569994023 Test RE 0.9605453317881574\n",
      "80 Train Loss 1.3931149 Test MSE 3.95787714528037 Test RE 0.9509095629206596\n",
      "81 Train Loss 1.3719395 Test MSE 3.9239690185475937 Test RE 0.946827460587023\n",
      "82 Train Loss 1.360076 Test MSE 3.923652278098483 Test RE 0.9467892461406511\n",
      "83 Train Loss 1.3285213 Test MSE 3.9199793573087436 Test RE 0.9463459988985778\n",
      "84 Train Loss 1.2988304 Test MSE 3.8298681495502946 Test RE 0.9354056131688775\n",
      "85 Train Loss 1.2714448 Test MSE 3.7026622164761074 Test RE 0.9197400696114552\n",
      "86 Train Loss 1.2524246 Test MSE 3.620972805247132 Test RE 0.9095376722007742\n",
      "87 Train Loss 1.2375636 Test MSE 3.5067922100023665 Test RE 0.8950825219444213\n",
      "88 Train Loss 1.209655 Test MSE 3.4274495366750943 Test RE 0.8848987770801231\n",
      "89 Train Loss 1.1984242 Test MSE 3.332418606754864 Test RE 0.8725450028940893\n",
      "90 Train Loss 1.1828758 Test MSE 3.3800716142853227 Test RE 0.8787614791754729\n",
      "91 Train Loss 1.1727738 Test MSE 3.4115129626121377 Test RE 0.8828391280985176\n",
      "92 Train Loss 1.1588645 Test MSE 3.3265903972536455 Test RE 0.8717816533377288\n",
      "93 Train Loss 1.1449821 Test MSE 3.3594970440630143 Test RE 0.8760828765542729\n",
      "94 Train Loss 1.1234053 Test MSE 3.245283505889086 Test RE 0.8610619166383542\n",
      "95 Train Loss 1.1130203 Test MSE 3.2007162142635353 Test RE 0.8551290203171531\n",
      "96 Train Loss 1.1016368 Test MSE 3.2083399147306855 Test RE 0.8561468190981879\n",
      "97 Train Loss 1.0904955 Test MSE 3.1954132779738487 Test RE 0.8544203391603475\n",
      "98 Train Loss 1.0850246 Test MSE 3.17516665149409 Test RE 0.851709168867748\n",
      "99 Train Loss 1.0779517 Test MSE 3.1242080202078024 Test RE 0.8448469328698421\n",
      "Training time: 68.53\n",
      "0\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 62.070915 Test MSE 6.180287123640745 Test RE 1.188262485504196\n",
      "1 Train Loss 35.206272 Test MSE 7.132424053082194 Test RE 1.2765171039215377\n",
      "2 Train Loss 25.14088 Test MSE 5.665145132236473 Test RE 1.1376628600842875\n",
      "3 Train Loss 19.651855 Test MSE 6.153922621869764 Test RE 1.1857252708309722\n",
      "4 Train Loss 15.697932 Test MSE 5.859413226873114 Test RE 1.1570047017981195\n",
      "5 Train Loss 13.708992 Test MSE 5.744081012671511 Test RE 1.1455613128290558\n",
      "6 Train Loss 12.036964 Test MSE 5.949968374542347 Test RE 1.165910971029765\n",
      "7 Train Loss 10.709178 Test MSE 5.977338780525318 Test RE 1.1685895434072453\n",
      "8 Train Loss 9.9105 Test MSE 5.774406549171882 Test RE 1.1485812937743924\n",
      "9 Train Loss 9.170803 Test MSE 5.532788516537436 Test RE 1.1242945239781181\n",
      "10 Train Loss 8.563536 Test MSE 5.44089892943922 Test RE 1.1149191872306923\n",
      "11 Train Loss 8.045075 Test MSE 5.33476602279982 Test RE 1.1039915480261713\n",
      "12 Train Loss 7.3266716 Test MSE 5.231106692107544 Test RE 1.0932131553690816\n",
      "13 Train Loss 6.725895 Test MSE 5.1019955551714 Test RE 1.0796378414715542\n",
      "14 Train Loss 5.6907816 Test MSE 4.910318323838432 Test RE 1.059163202111346\n",
      "15 Train Loss 5.0609818 Test MSE 4.777324553851075 Test RE 1.0447212622878936\n",
      "16 Train Loss 4.5577126 Test MSE 4.793892465466998 Test RE 1.046531257443068\n",
      "17 Train Loss 4.1696844 Test MSE 4.636632689362243 Test RE 1.0292228195530964\n",
      "18 Train Loss 3.8163984 Test MSE 4.202246931985821 Test RE 0.9798257411195964\n",
      "19 Train Loss 3.372366 Test MSE 3.822716464306749 Test RE 0.934531842560433\n",
      "20 Train Loss 2.8691313 Test MSE 3.359158759197924 Test RE 0.8760387668207574\n",
      "21 Train Loss 2.5144546 Test MSE 3.005079006972336 Test RE 0.8285829788619542\n",
      "22 Train Loss 2.20815 Test MSE 2.7983735335126148 Test RE 0.7995781222678201\n",
      "23 Train Loss 1.9716835 Test MSE 2.478928979864539 Test RE 0.7525582179055669\n",
      "24 Train Loss 1.8373442 Test MSE 2.3334120135377026 Test RE 0.7301360214959326\n",
      "25 Train Loss 1.7377659 Test MSE 2.2029443989706143 Test RE 0.7094304549617547\n",
      "26 Train Loss 1.6367422 Test MSE 2.0528748070112317 Test RE 0.6848402747201123\n",
      "27 Train Loss 1.5485435 Test MSE 1.9312421049102393 Test RE 0.664242135193635\n",
      "28 Train Loss 1.4396405 Test MSE 1.6774976776601407 Test RE 0.6190689528217388\n",
      "29 Train Loss 1.3653729 Test MSE 1.6039650833949204 Test RE 0.6053485622165441\n",
      "30 Train Loss 1.2525104 Test MSE 1.3289211145145192 Test RE 0.5510076914449304\n",
      "31 Train Loss 1.0581408 Test MSE 1.0174904556761708 Test RE 0.48214007637111195\n",
      "32 Train Loss 0.8141841 Test MSE 0.9130824475892045 Test RE 0.45673370033503374\n",
      "33 Train Loss 0.6310776 Test MSE 0.7927143442628002 Test RE 0.4255655055365735\n",
      "34 Train Loss 0.5147028 Test MSE 0.7270739328445855 Test RE 0.40756543734766115\n",
      "35 Train Loss 0.4398176 Test MSE 0.6328502767108105 Test RE 0.380240653288364\n",
      "36 Train Loss 0.36846733 Test MSE 0.5555804706345066 Test RE 0.3562718803650601\n",
      "37 Train Loss 0.30164063 Test MSE 0.45028766398397063 Test RE 0.3207399704886633\n",
      "38 Train Loss 0.25740978 Test MSE 0.40072275184277956 Test RE 0.30257292303197053\n",
      "39 Train Loss 0.2268679 Test MSE 0.30781389098517287 Test RE 0.26518696176035017\n",
      "40 Train Loss 0.20913918 Test MSE 0.3112315385614012 Test RE 0.26665507898183605\n",
      "41 Train Loss 0.1913816 Test MSE 0.30983425254547 Test RE 0.2660558264941504\n",
      "42 Train Loss 0.17743455 Test MSE 0.2872409233107419 Test RE 0.2561717395024907\n",
      "43 Train Loss 0.16767763 Test MSE 0.25302838932828237 Test RE 0.24043223069024264\n",
      "44 Train Loss 0.15525606 Test MSE 0.1973955009973882 Test RE 0.2123619405888474\n",
      "45 Train Loss 0.13700907 Test MSE 0.07844947527475693 Test RE 0.13387610911056283\n",
      "46 Train Loss 0.11966506 Test MSE 0.03953196884446362 Test RE 0.09503471627880167\n",
      "47 Train Loss 0.09611195 Test MSE 0.02393852987640042 Test RE 0.07395317058448775\n",
      "48 Train Loss 0.07823146 Test MSE 0.021519487159893266 Test RE 0.07011711182922879\n",
      "49 Train Loss 0.068403974 Test MSE 0.01631025934215328 Test RE 0.061043368880639395\n",
      "50 Train Loss 0.060399286 Test MSE 0.015419855839226502 Test RE 0.059353757369995895\n",
      "51 Train Loss 0.051048603 Test MSE 0.013534140456081487 Test RE 0.055606223366435\n",
      "52 Train Loss 0.045234125 Test MSE 0.01210614127840717 Test RE 0.05259093949265881\n",
      "53 Train Loss 0.041321617 Test MSE 0.01020444989573463 Test RE 0.04828395751200264\n",
      "54 Train Loss 0.037711248 Test MSE 0.010286225303568439 Test RE 0.04847703805484388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 0.034612235 Test MSE 0.01004870401495686 Test RE 0.0479140726902622\n",
      "56 Train Loss 0.031638023 Test MSE 0.010548628621397597 Test RE 0.04909147279951008\n",
      "57 Train Loss 0.028792812 Test MSE 0.009879562184322522 Test RE 0.047509111651285074\n",
      "58 Train Loss 0.02714825 Test MSE 0.011356388621537516 Test RE 0.05093639247873129\n",
      "59 Train Loss 0.024301127 Test MSE 0.009474627224834874 Test RE 0.04652529400233349\n",
      "60 Train Loss 0.023150824 Test MSE 0.008826982549247934 Test RE 0.04490701563153936\n",
      "61 Train Loss 0.022107147 Test MSE 0.00918370471030016 Test RE 0.04580543542018857\n",
      "62 Train Loss 0.02030633 Test MSE 0.008526735991299704 Test RE 0.04413666032707423\n",
      "63 Train Loss 0.019277953 Test MSE 0.008942332353591485 Test RE 0.04519948263158014\n",
      "64 Train Loss 0.018202879 Test MSE 0.009111543263631254 Test RE 0.04562512119581811\n",
      "65 Train Loss 0.01687235 Test MSE 0.008237664388499724 Test RE 0.04338205368517571\n",
      "66 Train Loss 0.015621297 Test MSE 0.007690982391296937 Test RE 0.041917847061702096\n",
      "67 Train Loss 0.0147150755 Test MSE 0.007673213951390921 Test RE 0.04186939776148764\n",
      "68 Train Loss 0.013765844 Test MSE 0.008245121572307777 Test RE 0.04340168514573909\n",
      "69 Train Loss 0.012816309 Test MSE 0.008172180699517235 Test RE 0.043209281103245754\n",
      "70 Train Loss 0.012360173 Test MSE 0.00843665226125597 Test RE 0.04390289254694623\n",
      "71 Train Loss 0.011757342 Test MSE 0.008342757118133783 Test RE 0.043657901871162176\n",
      "72 Train Loss 0.01113899 Test MSE 0.007731200473376031 Test RE 0.04202730363897832\n",
      "73 Train Loss 0.01035033 Test MSE 0.007406550633314134 Test RE 0.04113543159940403\n",
      "74 Train Loss 0.009401914 Test MSE 0.006332369867660531 Test RE 0.038035681064285266\n",
      "75 Train Loss 0.008447638 Test MSE 0.005065215807922958 Test RE 0.03401786372770523\n",
      "76 Train Loss 0.007996466 Test MSE 0.0049413343750521225 Test RE 0.03359929631430727\n",
      "77 Train Loss 0.007615985 Test MSE 0.00440062335397661 Test RE 0.0317077306196879\n",
      "78 Train Loss 0.0070106867 Test MSE 0.003736994147168048 Test RE 0.02921926378196022\n",
      "79 Train Loss 0.0065237815 Test MSE 0.003808918467719088 Test RE 0.029499108991372775\n",
      "80 Train Loss 0.0061565046 Test MSE 0.0032500650452400616 Test RE 0.027249220717784427\n",
      "81 Train Loss 0.0059047965 Test MSE 0.0033151503984576976 Test RE 0.027520712802822773\n",
      "82 Train Loss 0.0056434767 Test MSE 0.003167961279744647 Test RE 0.026902831571375917\n",
      "83 Train Loss 0.0052693374 Test MSE 0.003368634666761998 Test RE 0.027741824317538053\n",
      "84 Train Loss 0.0049384898 Test MSE 0.002734503997795285 Test RE 0.024994666223633357\n",
      "85 Train Loss 0.0046746945 Test MSE 0.002179417268203223 Test RE 0.022314042406418894\n",
      "86 Train Loss 0.004493356 Test MSE 0.0020880317516312943 Test RE 0.021841205723427987\n",
      "87 Train Loss 0.004291291 Test MSE 0.002113502629642533 Test RE 0.021974017018793396\n",
      "88 Train Loss 0.0041169194 Test MSE 0.002251594582618176 Test RE 0.02268052785122846\n",
      "89 Train Loss 0.0037279546 Test MSE 0.0021842815325970122 Test RE 0.02233893000076784\n",
      "90 Train Loss 0.0035068819 Test MSE 0.0020522637656477617 Test RE 0.021653327722474098\n",
      "91 Train Loss 0.0034112877 Test MSE 0.0019139377915054518 Test RE 0.020910863601983194\n",
      "92 Train Loss 0.0033665448 Test MSE 0.0017699654801876395 Test RE 0.020108999275102093\n",
      "93 Train Loss 0.0031996253 Test MSE 0.0016654418824901707 Test RE 0.01950620577304953\n",
      "94 Train Loss 0.0030106085 Test MSE 0.0016504800643846959 Test RE 0.019418389219512337\n",
      "95 Train Loss 0.0028659643 Test MSE 0.001783164948164392 Test RE 0.020183841150814494\n",
      "96 Train Loss 0.002749901 Test MSE 0.001612625472291226 Test RE 0.019194412242195476\n",
      "97 Train Loss 0.0026993258 Test MSE 0.0015340989723736144 Test RE 0.018721245990634353\n",
      "98 Train Loss 0.0026219976 Test MSE 0.0014699812498451615 Test RE 0.01832584284358839\n",
      "99 Train Loss 0.0025777759 Test MSE 0.0014343021339868495 Test RE 0.018102075943895075\n",
      "Training time: 67.23\n",
      "1\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 60.775513 Test MSE 7.507330258419216 Test RE 1.3096366524198093\n",
      "1 Train Loss 44.80709 Test MSE 9.22745718894573 Test RE 1.45194137009951\n",
      "2 Train Loss 38.259644 Test MSE 9.815407572096941 Test RE 1.497484132284778\n",
      "3 Train Loss 33.31929 Test MSE 9.200221283582852 Test RE 1.4497970002885847\n",
      "4 Train Loss 28.412083 Test MSE 9.170583047489805 Test RE 1.447459877816853\n",
      "5 Train Loss 26.0153 Test MSE 8.817762888625731 Test RE 1.419342700131701\n",
      "6 Train Loss 23.87779 Test MSE 8.867661371858647 Test RE 1.423352965370666\n",
      "7 Train Loss 21.934612 Test MSE 8.887291931916993 Test RE 1.4249275501598835\n",
      "8 Train Loss 20.02881 Test MSE 9.25442611222121 Test RE 1.4540616035106735\n",
      "9 Train Loss 17.24475 Test MSE 8.815814727118191 Test RE 1.4191858995013005\n",
      "10 Train Loss 15.25486 Test MSE 8.25822654953014 Test RE 1.3735720867838406\n",
      "11 Train Loss 14.398067 Test MSE 8.196471461448743 Test RE 1.3684266574925588\n",
      "12 Train Loss 13.928169 Test MSE 8.299649756389975 Test RE 1.3770126916788406\n",
      "13 Train Loss 13.525415 Test MSE 8.536315904918995 Test RE 1.3965075874726391\n",
      "14 Train Loss 13.136854 Test MSE 8.49874269429701 Test RE 1.3934307835708755\n",
      "15 Train Loss 12.716614 Test MSE 8.539570188481688 Test RE 1.3967737560800872\n",
      "16 Train Loss 12.165745 Test MSE 8.651291536431435 Test RE 1.4058809104629237\n",
      "17 Train Loss 10.611345 Test MSE 7.11704150718365 Test RE 1.2751398245039975\n",
      "18 Train Loss 8.475439 Test MSE 6.772468412442693 Test RE 1.2438887911056924\n",
      "19 Train Loss 7.907215 Test MSE 6.5027859695839965 Test RE 1.2188711293255785\n",
      "20 Train Loss 7.6203194 Test MSE 6.543608225583702 Test RE 1.2226909708681148\n",
      "21 Train Loss 7.3897257 Test MSE 6.402900897011238 Test RE 1.2094737589885511\n",
      "22 Train Loss 7.0747585 Test MSE 6.306658409060836 Test RE 1.200349496497121\n",
      "23 Train Loss 6.8561764 Test MSE 6.330709276598669 Test RE 1.2026361254319724\n",
      "24 Train Loss 6.423321 Test MSE 6.144714465690588 Test RE 1.1848378343528958\n",
      "25 Train Loss 5.5625453 Test MSE 5.463812585311744 Test RE 1.1172643910788878\n",
      "26 Train Loss 3.7221477 Test MSE 5.047726271129691 Test RE 1.073880504663332\n",
      "27 Train Loss 3.002688 Test MSE 5.193977931893922 Test RE 1.0893266040712035\n",
      "28 Train Loss 2.604332 Test MSE 5.29042581052404 Test RE 1.0993940305803291\n",
      "29 Train Loss 2.355251 Test MSE 5.33817761841935 Test RE 1.104344494224235\n",
      "30 Train Loss 2.1504605 Test MSE 5.364913486417736 Test RE 1.107106554033139\n",
      "31 Train Loss 2.0096724 Test MSE 5.470874481564822 Test RE 1.1179861817069163\n",
      "32 Train Loss 1.91225 Test MSE 5.511331845828465 Test RE 1.1221123466564482\n",
      "33 Train Loss 1.8479438 Test MSE 5.437435354106247 Test RE 1.1145642623002985\n",
      "34 Train Loss 1.7817993 Test MSE 5.46088909302807 Test RE 1.1169654468147654\n",
      "35 Train Loss 1.7370987 Test MSE 5.449192960098667 Test RE 1.1157686472794088\n",
      "36 Train Loss 1.6892959 Test MSE 5.493347397525954 Test RE 1.1202800253446026\n",
      "37 Train Loss 1.6340531 Test MSE 5.436162234075727 Test RE 1.11443377273449\n",
      "38 Train Loss 1.5897725 Test MSE 5.451764356826979 Test RE 1.1160318739149893\n",
      "39 Train Loss 1.5467063 Test MSE 5.464754339261341 Test RE 1.1173606739217923\n",
      "40 Train Loss 1.5187366 Test MSE 5.477061824326069 Test RE 1.1186182021472346\n",
      "41 Train Loss 1.4910522 Test MSE 5.472160611280778 Test RE 1.1181175858141357\n",
      "42 Train Loss 1.4533637 Test MSE 5.4596011664645125 Test RE 1.1168337233650585\n",
      "43 Train Loss 1.4071712 Test MSE 5.5118027548555775 Test RE 1.1221602843928562\n",
      "44 Train Loss 1.3718705 Test MSE 5.5316323061402155 Test RE 1.1241770435309726\n",
      "45 Train Loss 1.3300096 Test MSE 5.530200276283674 Test RE 1.1240315205456537\n",
      "46 Train Loss 1.3022846 Test MSE 5.544689611010314 Test RE 1.1255030599376967\n",
      "47 Train Loss 1.278996 Test MSE 5.53478920697954 Test RE 1.1244977815210526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 1.2562494 Test MSE 5.574659050617637 Test RE 1.1285406726726908\n",
      "49 Train Loss 1.2342597 Test MSE 5.586543987735336 Test RE 1.1297430326399647\n",
      "50 Train Loss 1.2193658 Test MSE 5.582386451334721 Test RE 1.1293225739457615\n",
      "51 Train Loss 1.1981297 Test MSE 5.585088028098258 Test RE 1.129595806784065\n",
      "52 Train Loss 1.18485 Test MSE 5.562218634967514 Test RE 1.1272807430231822\n",
      "53 Train Loss 1.1664416 Test MSE 5.616607721404207 Test RE 1.1327787844333521\n",
      "54 Train Loss 1.1478541 Test MSE 5.607226969542159 Test RE 1.1318324162787616\n",
      "55 Train Loss 1.1331563 Test MSE 5.6423681237908445 Test RE 1.1353735405566534\n",
      "56 Train Loss 1.1153529 Test MSE 5.612353793194673 Test RE 1.1323497289764162\n",
      "57 Train Loss 1.1046019 Test MSE 5.61342163450924 Test RE 1.1324574478014509\n",
      "58 Train Loss 1.0955997 Test MSE 5.612763470912895 Test RE 1.1323910565552673\n",
      "59 Train Loss 1.084323 Test MSE 5.641480925929285 Test RE 1.1352842747949283\n",
      "60 Train Loss 1.0734471 Test MSE 5.6758475951294605 Test RE 1.1387369763803326\n",
      "61 Train Loss 1.0654235 Test MSE 5.674647545250225 Test RE 1.1386165878931513\n",
      "62 Train Loss 1.0563719 Test MSE 5.680410685936857 Test RE 1.1391946275240434\n",
      "63 Train Loss 1.0474545 Test MSE 5.698949236394173 Test RE 1.1410520472898946\n",
      "64 Train Loss 1.036818 Test MSE 5.700707327652463 Test RE 1.1412280375343118\n",
      "65 Train Loss 1.0242707 Test MSE 5.717387415867263 Test RE 1.142896416478833\n",
      "66 Train Loss 1.0122788 Test MSE 5.7592551360502044 Test RE 1.1470734279712582\n",
      "67 Train Loss 1.0019248 Test MSE 5.768326048363474 Test RE 1.1479764013984832\n",
      "68 Train Loss 0.99027354 Test MSE 5.75765673534913 Test RE 1.146914239833193\n",
      "69 Train Loss 0.9793723 Test MSE 5.7759932339099365 Test RE 1.1487390858539064\n",
      "70 Train Loss 0.9725648 Test MSE 5.78098349412284 Test RE 1.1492352143191968\n",
      "71 Train Loss 0.96423674 Test MSE 5.795011412835244 Test RE 1.1506287151091983\n",
      "72 Train Loss 0.9563858 Test MSE 5.79450940384144 Test RE 1.1505788758222222\n",
      "73 Train Loss 0.9479172 Test MSE 5.810972846022347 Test RE 1.1522122369612637\n",
      "74 Train Loss 0.93998754 Test MSE 5.818777375569403 Test RE 1.152985726817146\n",
      "75 Train Loss 0.9305671 Test MSE 5.846430516169519 Test RE 1.1557222024658695\n",
      "76 Train Loss 0.9231812 Test MSE 5.856089793815605 Test RE 1.1566765313031888\n",
      "77 Train Loss 0.9163734 Test MSE 5.904213878092015 Test RE 1.1614194664040114\n",
      "78 Train Loss 0.90989 Test MSE 5.9040206838102405 Test RE 1.1614004645995535\n",
      "79 Train Loss 0.9025244 Test MSE 5.904922246631785 Test RE 1.161489135995369\n",
      "80 Train Loss 0.8948293 Test MSE 5.946082896083002 Test RE 1.1655302243189747\n",
      "81 Train Loss 0.8903578 Test MSE 5.936565837653519 Test RE 1.1645971006546663\n",
      "82 Train Loss 0.88658786 Test MSE 5.967128157288599 Test RE 1.1675910114534696\n",
      "83 Train Loss 0.88043886 Test MSE 5.989850056057871 Test RE 1.1698119020239308\n",
      "84 Train Loss 0.87547123 Test MSE 6.004592485201442 Test RE 1.1712506083704792\n",
      "85 Train Loss 0.8682816 Test MSE 6.030658383380832 Test RE 1.17379005118751\n",
      "86 Train Loss 0.86119616 Test MSE 6.068983554865515 Test RE 1.1775138949770703\n",
      "87 Train Loss 0.85652363 Test MSE 6.061449973411511 Test RE 1.1767828292732798\n",
      "88 Train Loss 0.85215044 Test MSE 6.066364273732999 Test RE 1.1772597689978095\n",
      "89 Train Loss 0.847246 Test MSE 6.0810779947160505 Test RE 1.1786866022976448\n",
      "90 Train Loss 0.84343636 Test MSE 6.088611933321193 Test RE 1.1794165225328483\n",
      "91 Train Loss 0.8407091 Test MSE 6.103674232264604 Test RE 1.1808744698612959\n",
      "92 Train Loss 0.83799636 Test MSE 6.108559636050946 Test RE 1.1813469635148297\n",
      "93 Train Loss 0.83300287 Test MSE 6.122225224453648 Test RE 1.1826676334845618\n",
      "94 Train Loss 0.82862884 Test MSE 6.142960776578215 Test RE 1.1846687471239097\n",
      "95 Train Loss 0.8244325 Test MSE 6.157524776557107 Test RE 1.1860722479757442\n",
      "96 Train Loss 0.8210094 Test MSE 6.146278708671562 Test RE 1.1849886352028982\n",
      "97 Train Loss 0.81787884 Test MSE 6.148018025409765 Test RE 1.185156291509428\n",
      "98 Train Loss 0.8134575 Test MSE 6.173050441767686 Test RE 1.1875665958051487\n",
      "99 Train Loss 0.8085648 Test MSE 6.172646140719869 Test RE 1.1875277056093396\n",
      "Training time: 67.77\n",
      "2\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 52.72382 Test MSE 7.266261262357309 Test RE 1.2884381181156486\n",
      "1 Train Loss 36.64107 Test MSE 6.213929737124277 Test RE 1.1914922707265803\n",
      "2 Train Loss 26.41655 Test MSE 5.04694352084045 Test RE 1.0737972381765835\n",
      "3 Train Loss 18.993818 Test MSE 4.298807412129535 Test RE 0.9910191685295774\n",
      "4 Train Loss 12.418676 Test MSE 3.0604469498136173 Test RE 0.836181371670166\n",
      "5 Train Loss 8.930222 Test MSE 2.766472382950544 Test RE 0.795007507469492\n",
      "6 Train Loss 6.9848537 Test MSE 2.223508331747271 Test RE 0.712733941140858\n",
      "7 Train Loss 5.6344995 Test MSE 2.2452555286005285 Test RE 0.716210935056499\n",
      "8 Train Loss 5.0885897 Test MSE 2.1998852163618854 Test RE 0.7089376982473387\n",
      "9 Train Loss 4.8068743 Test MSE 2.2049109291546642 Test RE 0.70974703244634\n",
      "10 Train Loss 4.533643 Test MSE 2.1848140520946373 Test RE 0.7065050988137965\n",
      "11 Train Loss 4.3507576 Test MSE 2.1856112369411576 Test RE 0.7066339802148838\n",
      "12 Train Loss 4.229082 Test MSE 2.186684896073426 Test RE 0.7068075222570704\n",
      "13 Train Loss 4.122072 Test MSE 2.146350567869151 Test RE 0.7002584999063219\n",
      "14 Train Loss 4.0518513 Test MSE 2.1312049854899935 Test RE 0.6977834617916994\n",
      "15 Train Loss 3.9983864 Test MSE 2.159380844070346 Test RE 0.7023808826867812\n",
      "16 Train Loss 3.9574277 Test MSE 2.1508469048492307 Test RE 0.7009915933209268\n",
      "17 Train Loss 3.8688335 Test MSE 2.143850358860956 Test RE 0.6998505276970627\n",
      "18 Train Loss 3.7057178 Test MSE 2.0691552233788877 Test RE 0.6875504903232083\n",
      "19 Train Loss 3.5119772 Test MSE 2.059881941495601 Test RE 0.6860080711977246\n",
      "20 Train Loss 2.3154325 Test MSE 1.6299887031689508 Test RE 0.610239559008934\n",
      "21 Train Loss 1.7012258 Test MSE 1.3557741314131833 Test RE 0.5565468536390625\n",
      "22 Train Loss 1.3463347 Test MSE 1.2652692920465167 Test RE 0.5376498688767123\n",
      "23 Train Loss 1.129829 Test MSE 1.1316037410219295 Test RE 0.5084581904886761\n",
      "24 Train Loss 0.9943517 Test MSE 1.0195334549462076 Test RE 0.4826238734759631\n",
      "25 Train Loss 0.85130244 Test MSE 0.8159207242844182 Test RE 0.4317496979678954\n",
      "26 Train Loss 0.7175418 Test MSE 0.5383688564022162 Test RE 0.3507098993413321\n",
      "27 Train Loss 0.6349693 Test MSE 0.3879929251469011 Test RE 0.29772819435417247\n",
      "28 Train Loss 0.5256863 Test MSE 0.3706807285999039 Test RE 0.291010101405787\n",
      "29 Train Loss 0.41581985 Test MSE 0.28649889460176003 Test RE 0.2558406416483932\n",
      "30 Train Loss 0.3627373 Test MSE 0.245227011322482 Test RE 0.23669670535281898\n",
      "31 Train Loss 0.30989945 Test MSE 0.18814704426191836 Test RE 0.20732742810913368\n",
      "32 Train Loss 0.25284234 Test MSE 0.17380150199762395 Test RE 0.19926674326961882\n",
      "33 Train Loss 0.22372623 Test MSE 0.17774677750765688 Test RE 0.2015157188933778\n",
      "34 Train Loss 0.17563467 Test MSE 0.09938938351125214 Test RE 0.15068778831579965\n",
      "35 Train Loss 0.14415455 Test MSE 0.0763691890835071 Test RE 0.13208915132625734\n",
      "36 Train Loss 0.118242644 Test MSE 0.05807317805074912 Test RE 0.11518498152588136\n",
      "37 Train Loss 0.09930538 Test MSE 0.04192225043869321 Test RE 0.09786566563626221\n",
      "38 Train Loss 0.07945377 Test MSE 0.0375331256558516 Test RE 0.0926009466955854\n",
      "39 Train Loss 0.06914533 Test MSE 0.03245992252456846 Test RE 0.0861155936368938\n",
      "40 Train Loss 0.06006568 Test MSE 0.03163743622575915 Test RE 0.08501757273669687\n",
      "41 Train Loss 0.05159677 Test MSE 0.022025518035086147 Test RE 0.07093672369369466\n",
      "42 Train Loss 0.041580305 Test MSE 0.01239121483876059 Test RE 0.053206538266619995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 0.036615264 Test MSE 0.011367808926876676 Test RE 0.050961997580936766\n",
      "44 Train Loss 0.031879522 Test MSE 0.008650972343414281 Test RE 0.044457037806950206\n",
      "45 Train Loss 0.02992803 Test MSE 0.0086047687830873 Test RE 0.04433815964386466\n",
      "46 Train Loss 0.028011762 Test MSE 0.008833435706171606 Test RE 0.04492342775606182\n",
      "47 Train Loss 0.025164563 Test MSE 0.008294212783106417 Test RE 0.043530699570715495\n",
      "48 Train Loss 0.022851335 Test MSE 0.009074646007558687 Test RE 0.0455326478645687\n",
      "49 Train Loss 0.02137303 Test MSE 0.007368454530476968 Test RE 0.0410295037504955\n",
      "50 Train Loss 0.020458695 Test MSE 0.006441088134047257 Test RE 0.03836080225104069\n",
      "51 Train Loss 0.019129872 Test MSE 0.006251437635891453 Test RE 0.03779183778431765\n",
      "52 Train Loss 0.017372355 Test MSE 0.005336677236267432 Test RE 0.03491753112581474\n",
      "53 Train Loss 0.01631851 Test MSE 0.004853357815277862 Test RE 0.03329884851899423\n",
      "54 Train Loss 0.015278636 Test MSE 0.0047009238672827336 Test RE 0.032771752714256495\n",
      "55 Train Loss 0.013198255 Test MSE 0.003086272271343178 Test RE 0.02655370821735775\n",
      "56 Train Loss 0.011919905 Test MSE 0.002019024760701799 Test RE 0.02147726040214815\n",
      "57 Train Loss 0.01113248 Test MSE 0.002014630668514429 Test RE 0.021453876720336336\n",
      "58 Train Loss 0.010424636 Test MSE 0.001783038300727053 Test RE 0.020183124369916008\n",
      "59 Train Loss 0.009330783 Test MSE 0.001762107279341923 Test RE 0.020064310172354372\n",
      "60 Train Loss 0.008785088 Test MSE 0.0016883365888540175 Test RE 0.01963982331677746\n",
      "61 Train Loss 0.00848577 Test MSE 0.0017206881536459074 Test RE 0.019827097609963228\n",
      "62 Train Loss 0.00793482 Test MSE 0.001432444948096658 Test RE 0.01809035253882344\n",
      "63 Train Loss 0.0070977425 Test MSE 0.001152808932363784 Test RE 0.01622881190476577\n",
      "64 Train Loss 0.006595044 Test MSE 0.0012095265915797837 Test RE 0.016623243658653492\n",
      "65 Train Loss 0.006289943 Test MSE 0.0012887163397302542 Test RE 0.01715879271344737\n",
      "66 Train Loss 0.006083964 Test MSE 0.001173457850036975 Test RE 0.016373510685939823\n",
      "67 Train Loss 0.0057303444 Test MSE 0.001024025075212867 Test RE 0.015295488644348534\n",
      "68 Train Loss 0.005400268 Test MSE 0.0009195437697195051 Test RE 0.014494200457188817\n",
      "69 Train Loss 0.0052144574 Test MSE 0.0008352090491620289 Test RE 0.013813561190015367\n",
      "70 Train Loss 0.0049408632 Test MSE 0.0008326954777299148 Test RE 0.013792759490251539\n",
      "71 Train Loss 0.0045366017 Test MSE 0.0007094919391351647 Test RE 0.012731565042180596\n",
      "72 Train Loss 0.004370706 Test MSE 0.0006180313748018195 Test RE 0.011882650449900436\n",
      "73 Train Loss 0.0041618026 Test MSE 0.0007127564876805729 Test RE 0.01276082197190953\n",
      "74 Train Loss 0.003909669 Test MSE 0.0007632271119511366 Test RE 0.013204895082611866\n",
      "75 Train Loss 0.003538543 Test MSE 0.0006492002222186448 Test RE 0.012178600663584045\n",
      "76 Train Loss 0.0034119054 Test MSE 0.0006088843590700537 Test RE 0.011794389593333015\n",
      "77 Train Loss 0.003270129 Test MSE 0.0006130904476166618 Test RE 0.01183505648611698\n",
      "78 Train Loss 0.0031717261 Test MSE 0.0005375170387848391 Test RE 0.011081643586480944\n",
      "79 Train Loss 0.003058889 Test MSE 0.0005423171555355309 Test RE 0.011131014071964776\n",
      "80 Train Loss 0.0029680235 Test MSE 0.0005097259524891103 Test RE 0.010791366273278032\n",
      "81 Train Loss 0.002871139 Test MSE 0.000533875717701718 Test RE 0.011044044411781794\n",
      "82 Train Loss 0.0027138004 Test MSE 0.0005666107581469182 Test RE 0.011377594945235043\n",
      "83 Train Loss 0.0025708212 Test MSE 0.0005158576101431354 Test RE 0.010856078653809985\n",
      "84 Train Loss 0.002434293 Test MSE 0.0004659409162354011 Test RE 0.01031747641904924\n",
      "85 Train Loss 0.0023981447 Test MSE 0.00046490483253309317 Test RE 0.010305998871195843\n",
      "86 Train Loss 0.0023123794 Test MSE 0.00044958604606722325 Test RE 0.010134783413790248\n",
      "87 Train Loss 0.002195975 Test MSE 0.0003570861619102138 Test RE 0.0090322213146448\n",
      "88 Train Loss 0.0020800547 Test MSE 0.00030831329493962253 Test RE 0.00839274806471395\n",
      "89 Train Loss 0.0020224904 Test MSE 0.000303026452003866 Test RE 0.008320479036573814\n",
      "90 Train Loss 0.0019395881 Test MSE 0.00027499812910563865 Test RE 0.00792634424232192\n",
      "91 Train Loss 0.0018662367 Test MSE 0.0002751746648503365 Test RE 0.007928888002513713\n",
      "92 Train Loss 0.0017907806 Test MSE 0.000271908530104513 Test RE 0.00788169230512089\n",
      "93 Train Loss 0.0017343764 Test MSE 0.0002696101452002714 Test RE 0.00784831047969599\n",
      "94 Train Loss 0.0016722516 Test MSE 0.00026594653993460335 Test RE 0.007794804594295377\n",
      "95 Train Loss 0.001624621 Test MSE 0.00026129031919179324 Test RE 0.007726267138986168\n",
      "96 Train Loss 0.0015848253 Test MSE 0.00025492219885520605 Test RE 0.007631534786984783\n",
      "97 Train Loss 0.0015251325 Test MSE 0.00024127548470145985 Test RE 0.007424456356439045\n",
      "98 Train Loss 0.0014725521 Test MSE 0.0002455150277462979 Test RE 0.007489401275019981\n",
      "99 Train Loss 0.001405392 Test MSE 0.00021937889141085932 Test RE 0.007079547158597416\n",
      "Training time: 67.54\n",
      "3\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 45.42608 Test MSE 8.403611698052767 Test RE 1.3856101268159815\n",
      "1 Train Loss 35.12043 Test MSE 8.93779643431188 Test RE 1.4289705874688095\n",
      "2 Train Loss 30.875175 Test MSE 8.937610529069238 Test RE 1.42895572617122\n",
      "3 Train Loss 26.6867 Test MSE 8.347588090987841 Test RE 1.380983741745874\n",
      "4 Train Loss 23.89869 Test MSE 8.221531187477112 Test RE 1.3705169609883963\n",
      "5 Train Loss 21.290695 Test MSE 7.678662595422058 Test RE 1.3244966150103556\n",
      "6 Train Loss 18.353237 Test MSE 7.688112904667085 Test RE 1.3253114088372344\n",
      "7 Train Loss 16.141096 Test MSE 7.330040057073537 Test RE 1.2940803248712371\n",
      "8 Train Loss 15.082146 Test MSE 7.718994107263504 Test RE 1.3279704614813361\n",
      "9 Train Loss 13.865341 Test MSE 7.821441943272675 Test RE 1.3367539413602145\n",
      "10 Train Loss 9.864234 Test MSE 6.577291497154753 Test RE 1.2258338369701174\n",
      "11 Train Loss 7.8514013 Test MSE 6.503246004020739 Test RE 1.2189142425988309\n",
      "12 Train Loss 6.999174 Test MSE 6.090484625281618 Test RE 1.1795978868616335\n",
      "13 Train Loss 6.5336485 Test MSE 6.224973013533894 Test RE 1.1925505493203477\n",
      "14 Train Loss 6.169821 Test MSE 6.163132756240987 Test RE 1.186612234052998\n",
      "15 Train Loss 5.838675 Test MSE 6.211906508736298 Test RE 1.191298282594649\n",
      "16 Train Loss 5.5684233 Test MSE 6.198738081435834 Test RE 1.1900349146171028\n",
      "17 Train Loss 5.230336 Test MSE 6.2878486966994345 Test RE 1.1985581287526275\n",
      "18 Train Loss 4.571247 Test MSE 6.080625543251406 Test RE 1.1786427524736354\n",
      "19 Train Loss 2.82658 Test MSE 5.471818184715564 Test RE 1.1180826015381362\n",
      "20 Train Loss 2.18236 Test MSE 5.271737616651892 Test RE 1.0974505324742692\n",
      "21 Train Loss 1.8246878 Test MSE 5.432823576772529 Test RE 1.1140915015011306\n",
      "22 Train Loss 1.6527883 Test MSE 5.539518985652014 Test RE 1.124978151201531\n",
      "23 Train Loss 1.5407926 Test MSE 5.54605169971674 Test RE 1.1256412949856538\n",
      "24 Train Loss 1.4598132 Test MSE 5.567413511230332 Test RE 1.127807036366031\n",
      "25 Train Loss 1.3945272 Test MSE 5.602557181476554 Test RE 1.1313610140649757\n",
      "26 Train Loss 1.3254873 Test MSE 5.5642482612463535 Test RE 1.1274863938696937\n",
      "27 Train Loss 1.2689037 Test MSE 5.611963119005201 Test RE 1.1323103170355782\n",
      "28 Train Loss 1.2197706 Test MSE 5.61041898854847 Test RE 1.132154528847306\n",
      "29 Train Loss 1.1845121 Test MSE 5.625980338868412 Test RE 1.1337235430100245\n",
      "30 Train Loss 1.1546516 Test MSE 5.639981982057736 Test RE 1.1351334420188404\n",
      "31 Train Loss 1.1273743 Test MSE 5.702464683100907 Test RE 1.1414039270034755\n",
      "32 Train Loss 1.0996128 Test MSE 5.703613702205672 Test RE 1.141518914901949\n",
      "33 Train Loss 1.0759022 Test MSE 5.731775087645672 Test RE 1.1443335489768032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 1.0449024 Test MSE 5.793841946102215 Test RE 1.1505126074949121\n",
      "35 Train Loss 1.0195765 Test MSE 5.808228990253977 Test RE 1.1519401760199535\n",
      "36 Train Loss 0.99950194 Test MSE 5.881439838932962 Test RE 1.1591773586020693\n",
      "37 Train Loss 0.97652674 Test MSE 5.897145874312888 Test RE 1.1607240837868982\n",
      "38 Train Loss 0.96054 Test MSE 5.926797851238739 Test RE 1.1636385960051308\n",
      "39 Train Loss 0.9473953 Test MSE 5.9182282192218825 Test RE 1.1627970318020873\n",
      "40 Train Loss 0.93532604 Test MSE 5.9604300054194 Test RE 1.1669355120538167\n",
      "41 Train Loss 0.925784 Test MSE 5.948543542456216 Test RE 1.165771362991412\n",
      "42 Train Loss 0.9095038 Test MSE 5.960647497415167 Test RE 1.166956802197147\n",
      "43 Train Loss 0.897529 Test MSE 5.976522078723437 Test RE 1.1685097067254628\n",
      "44 Train Loss 0.8832217 Test MSE 6.002478128652326 Test RE 1.1710443779358497\n",
      "45 Train Loss 0.8724436 Test MSE 6.031843865997124 Test RE 1.1739054149865242\n",
      "46 Train Loss 0.8662008 Test MSE 6.0319570938820295 Test RE 1.173916433027309\n",
      "47 Train Loss 0.86054575 Test MSE 6.0410736743209865 Test RE 1.1748032151064838\n",
      "48 Train Loss 0.8530617 Test MSE 6.060682008512811 Test RE 1.1767082797400115\n",
      "49 Train Loss 0.845731 Test MSE 6.071574093813428 Test RE 1.1777651784196783\n",
      "50 Train Loss 0.83987653 Test MSE 6.092234991240785 Test RE 1.179767379093174\n",
      "51 Train Loss 0.83439004 Test MSE 6.082800886707712 Test RE 1.1788535633111223\n",
      "52 Train Loss 0.82829404 Test MSE 6.103158455183884 Test RE 1.180824575254285\n",
      "53 Train Loss 0.8210641 Test MSE 6.121434232471669 Test RE 1.182591230640895\n",
      "54 Train Loss 0.81340116 Test MSE 6.117603030841072 Test RE 1.182221100503771\n",
      "55 Train Loss 0.8077839 Test MSE 6.127517143865946 Test RE 1.183178659273139\n",
      "56 Train Loss 0.80290127 Test MSE 6.145839542332403 Test RE 1.1849462993081277\n",
      "57 Train Loss 0.797792 Test MSE 6.169428413380627 Test RE 1.1872181431959141\n",
      "58 Train Loss 0.79236794 Test MSE 6.205684065401557 Test RE 1.1907014736022665\n",
      "59 Train Loss 0.7880007 Test MSE 6.219818169042764 Test RE 1.1920566768330485\n",
      "60 Train Loss 0.7854786 Test MSE 6.209747133622085 Test RE 1.1910912057930985\n",
      "61 Train Loss 0.7824205 Test MSE 6.213965933040345 Test RE 1.1914957409212277\n",
      "62 Train Loss 0.77823496 Test MSE 6.214661356980128 Test RE 1.1915624110228962\n",
      "63 Train Loss 0.77421194 Test MSE 6.235634279188447 Test RE 1.1935713295798143\n",
      "64 Train Loss 0.7674595 Test MSE 6.23099060665619 Test RE 1.1931268209365256\n",
      "65 Train Loss 0.76098204 Test MSE 6.211650830034438 Test RE 1.1912737657468626\n",
      "66 Train Loss 0.7547895 Test MSE 6.204394946065502 Test RE 1.1905777937629376\n",
      "67 Train Loss 0.7477647 Test MSE 6.212252225593214 Test RE 1.1913314323343625\n",
      "68 Train Loss 0.74246806 Test MSE 6.245590170748163 Test RE 1.1945237850008499\n",
      "69 Train Loss 0.7378041 Test MSE 6.241511642793748 Test RE 1.1941336942212668\n",
      "70 Train Loss 0.7333809 Test MSE 6.2229848883590115 Test RE 1.1923600963576158\n",
      "71 Train Loss 0.7297423 Test MSE 6.244101504177864 Test RE 1.1943814162611757\n",
      "72 Train Loss 0.7267174 Test MSE 6.24672971317519 Test RE 1.1946327537621246\n",
      "73 Train Loss 0.72277683 Test MSE 6.259035191617923 Test RE 1.1958088327447192\n",
      "74 Train Loss 0.72002834 Test MSE 6.266681118720448 Test RE 1.1965389993227655\n",
      "75 Train Loss 0.7176647 Test MSE 6.272215478050543 Test RE 1.1970672386921097\n",
      "76 Train Loss 0.71353334 Test MSE 6.293206013667233 Test RE 1.1990686124640948\n",
      "77 Train Loss 0.711564 Test MSE 6.302696849801526 Test RE 1.1999724344820364\n",
      "78 Train Loss 0.7081588 Test MSE 6.31458290906823 Test RE 1.201103396801638\n",
      "79 Train Loss 0.70516 Test MSE 6.326118898334471 Test RE 1.2022000324456998\n",
      "80 Train Loss 0.7020797 Test MSE 6.312906647297314 Test RE 1.2009439644709516\n",
      "81 Train Loss 0.6999067 Test MSE 6.320858833871901 Test RE 1.2017001236691796\n",
      "82 Train Loss 0.69678617 Test MSE 6.327332776029214 Test RE 1.2023153680747913\n",
      "83 Train Loss 0.6948894 Test MSE 6.338144845803847 Test RE 1.2033421805956208\n",
      "84 Train Loss 0.69267243 Test MSE 6.343747446136196 Test RE 1.2038739100101612\n",
      "85 Train Loss 0.690465 Test MSE 6.344882395713508 Test RE 1.2039815967592098\n",
      "86 Train Loss 0.6887959 Test MSE 6.341517693556887 Test RE 1.2036623176588868\n",
      "87 Train Loss 0.6867317 Test MSE 6.337150622868976 Test RE 1.2032477967226818\n",
      "88 Train Loss 0.68362737 Test MSE 6.351892159158861 Test RE 1.2046464866612165\n",
      "89 Train Loss 0.6818284 Test MSE 6.36372536863954 Test RE 1.2057680580814112\n",
      "90 Train Loss 0.6792956 Test MSE 6.368799368381322 Test RE 1.2062486608270406\n",
      "91 Train Loss 0.67750907 Test MSE 6.372952733541135 Test RE 1.2066419197704705\n",
      "92 Train Loss 0.67431337 Test MSE 6.38847218823131 Test RE 1.2081102374065198\n",
      "93 Train Loss 0.6725377 Test MSE 6.398985344076649 Test RE 1.2091038889221422\n",
      "94 Train Loss 0.669785 Test MSE 6.401696042018196 Test RE 1.2093599583003314\n",
      "95 Train Loss 0.66747004 Test MSE 6.40657416163611 Test RE 1.2098206392733513\n",
      "96 Train Loss 0.66535723 Test MSE 6.430817279656522 Test RE 1.2121075190805968\n",
      "97 Train Loss 0.6634981 Test MSE 6.431444313474067 Test RE 1.2121666106272984\n",
      "98 Train Loss 0.66137266 Test MSE 6.428835581775471 Test RE 1.2119207453101295\n",
      "99 Train Loss 0.6598693 Test MSE 6.418538607719842 Test RE 1.210949798299236\n",
      "Training time: 67.16\n",
      "4\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.41288 Test MSE 8.679172023789173 Test RE 1.408144452030464\n",
      "1 Train Loss 57.089622 Test MSE 8.50685717287916 Test RE 1.3940958388038174\n",
      "2 Train Loss 52.01957 Test MSE 8.161566228553943 Test RE 1.3655097796098843\n",
      "3 Train Loss 47.746147 Test MSE 6.861704572903838 Test RE 1.252056906485607\n",
      "4 Train Loss 41.206264 Test MSE 8.20005035608895 Test RE 1.3687253787389793\n",
      "5 Train Loss 37.078705 Test MSE 8.158510210245938 Test RE 1.365254104811728\n",
      "6 Train Loss 33.046787 Test MSE 7.52654142906674 Test RE 1.3113112542487657\n",
      "7 Train Loss 29.631233 Test MSE 7.040162915834918 Test RE 1.2682340669224095\n",
      "8 Train Loss 28.036179 Test MSE 7.1179199194951845 Test RE 1.2752185133777427\n",
      "9 Train Loss 25.691685 Test MSE 7.067374082032615 Test RE 1.2706826498682249\n",
      "10 Train Loss 23.551096 Test MSE 7.185790866682653 Test RE 1.2812838349970566\n",
      "11 Train Loss 22.180073 Test MSE 6.856223123761974 Test RE 1.2515567058890464\n",
      "12 Train Loss 20.207172 Test MSE 7.0835855280930495 Test RE 1.272139188284404\n",
      "13 Train Loss 17.579638 Test MSE 6.87715889377601 Test RE 1.2534660903197632\n",
      "14 Train Loss 15.121304 Test MSE 6.263712340011581 Test RE 1.196255541440521\n",
      "15 Train Loss 12.971277 Test MSE 5.96999835270459 Test RE 1.1678717839953783\n",
      "16 Train Loss 11.649115 Test MSE 5.994693501762863 Test RE 1.1702847665751301\n",
      "17 Train Loss 10.674081 Test MSE 5.888904934887043 Test RE 1.1599127759774488\n",
      "18 Train Loss 10.081289 Test MSE 5.6570879807812755 Test RE 1.1368535618903548\n",
      "19 Train Loss 9.530508 Test MSE 5.351982562817187 Test RE 1.1057715327843909\n",
      "20 Train Loss 9.170721 Test MSE 5.380873741014506 Test RE 1.1087521146262274\n",
      "21 Train Loss 8.84906 Test MSE 5.534622719856353 Test RE 1.124480868879798\n",
      "22 Train Loss 8.6004095 Test MSE 5.3141451852468755 Test RE 1.101855814997152\n",
      "23 Train Loss 8.422832 Test MSE 5.232336914044137 Test RE 1.0933416956400392\n",
      "24 Train Loss 8.043006 Test MSE 4.815804901139551 Test RE 1.0489203289208315\n",
      "25 Train Loss 7.7995663 Test MSE 4.587396040438801 Test RE 1.023743548655489\n",
      "26 Train Loss 7.442646 Test MSE 4.514526189654539 Test RE 1.015580021117469\n",
      "27 Train Loss 7.0560904 Test MSE 4.247145901184536 Test RE 0.9850463146233769\n",
      "28 Train Loss 6.842405 Test MSE 4.080082245263234 Test RE 0.9654783044570248\n",
      "29 Train Loss 6.285318 Test MSE 3.7356005164689217 Test RE 0.9238219431955291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 4.642059 Test MSE 2.797551901979412 Test RE 0.7994607314298572\n",
      "31 Train Loss 4.0629425 Test MSE 2.66694343698696 Test RE 0.7805755841113626\n",
      "32 Train Loss 3.4752207 Test MSE 2.685879307158677 Test RE 0.7833418095957738\n",
      "33 Train Loss 3.165127 Test MSE 2.8024035400546037 Test RE 0.800153661188807\n",
      "34 Train Loss 2.9656253 Test MSE 2.734095622403141 Test RE 0.7903417241364253\n",
      "35 Train Loss 2.728055 Test MSE 2.6320657601675124 Test RE 0.7754546919917183\n",
      "36 Train Loss 2.4781566 Test MSE 2.6171731189206 Test RE 0.7732577577454075\n",
      "37 Train Loss 2.337644 Test MSE 2.4841125121606935 Test RE 0.7533446205720958\n",
      "38 Train Loss 2.2061753 Test MSE 2.478963987679702 Test RE 0.7525635317580802\n",
      "39 Train Loss 2.1587763 Test MSE 2.492280767101583 Test RE 0.7545821773851238\n",
      "40 Train Loss 2.1204426 Test MSE 2.4796504809451765 Test RE 0.7526677273084523\n",
      "41 Train Loss 2.0406933 Test MSE 2.4945576879739035 Test RE 0.7549267877710238\n",
      "42 Train Loss 1.9901738 Test MSE 2.5029432126917244 Test RE 0.7561945768846228\n",
      "43 Train Loss 1.9562967 Test MSE 2.4861779033469955 Test RE 0.7536577360300696\n",
      "44 Train Loss 1.9282589 Test MSE 2.527259244506922 Test RE 0.7598589045496258\n",
      "45 Train Loss 1.8921586 Test MSE 2.557134383997659 Test RE 0.7643369169882263\n",
      "46 Train Loss 1.8582587 Test MSE 2.5451711333607188 Test RE 0.7625468910154984\n",
      "47 Train Loss 1.833798 Test MSE 2.5472194813477342 Test RE 0.7628536773115931\n",
      "48 Train Loss 1.7954859 Test MSE 2.541975068226995 Test RE 0.7620679615076512\n",
      "49 Train Loss 1.7670909 Test MSE 2.481453750281942 Test RE 0.7529413578007247\n",
      "50 Train Loss 1.7419612 Test MSE 2.4810295779202094 Test RE 0.7528770022665039\n",
      "51 Train Loss 1.7017365 Test MSE 2.4997404119848223 Test RE 0.7557106034975386\n",
      "52 Train Loss 1.660048 Test MSE 2.5207443117892585 Test RE 0.7588788657680356\n",
      "53 Train Loss 1.6123724 Test MSE 2.5637507408430134 Test RE 0.7653251049446981\n",
      "54 Train Loss 1.5695883 Test MSE 2.5955822260968646 Test RE 0.7700615799926603\n",
      "55 Train Loss 1.5456208 Test MSE 2.560786266835888 Test RE 0.7648825029055586\n",
      "56 Train Loss 1.516648 Test MSE 2.571450691790818 Test RE 0.7664735293181258\n",
      "57 Train Loss 1.4887897 Test MSE 2.522504827537258 Test RE 0.7591438242163616\n",
      "58 Train Loss 1.461852 Test MSE 2.5477677074515213 Test RE 0.7629357656047445\n",
      "59 Train Loss 1.4291421 Test MSE 2.5703642907721727 Test RE 0.766311600179263\n",
      "60 Train Loss 1.401258 Test MSE 2.579701093694243 Test RE 0.7677021452229004\n",
      "61 Train Loss 1.3840657 Test MSE 2.6052368108235258 Test RE 0.7714924196754963\n",
      "62 Train Loss 1.3667039 Test MSE 2.6097781101030235 Test RE 0.7721645375565522\n",
      "63 Train Loss 1.3456383 Test MSE 2.591509402663615 Test RE 0.7694571768430787\n",
      "64 Train Loss 1.3270293 Test MSE 2.5661032033735904 Test RE 0.7656761503463662\n",
      "65 Train Loss 1.3099835 Test MSE 2.5755100028476408 Test RE 0.767078271137344\n",
      "66 Train Loss 1.2977493 Test MSE 2.599385992045678 Test RE 0.7706256271702139\n",
      "67 Train Loss 1.2927101 Test MSE 2.6052527839503887 Test RE 0.7714947847440677\n",
      "68 Train Loss 1.2882377 Test MSE 2.616416429062211 Test RE 0.7731459656369659\n",
      "69 Train Loss 1.2762392 Test MSE 2.5880604603215986 Test RE 0.7689449855718439\n",
      "70 Train Loss 1.2699106 Test MSE 2.5985049395912894 Test RE 0.7704950157210186\n",
      "71 Train Loss 1.2584654 Test MSE 2.613586235921307 Test RE 0.7727276942106053\n",
      "72 Train Loss 1.2445238 Test MSE 2.5863586470415636 Test RE 0.7686921290407058\n",
      "73 Train Loss 1.2388211 Test MSE 2.585237289868456 Test RE 0.7685254715886946\n",
      "74 Train Loss 1.2291455 Test MSE 2.5990583791942132 Test RE 0.7705770628524676\n",
      "75 Train Loss 1.2255514 Test MSE 2.5966348204560488 Test RE 0.7702177068736288\n",
      "76 Train Loss 1.2211896 Test MSE 2.5953093573947106 Test RE 0.7700211013623516\n",
      "77 Train Loss 1.2105777 Test MSE 2.589298912562926 Test RE 0.7691289433575283\n",
      "78 Train Loss 1.204979 Test MSE 2.5967650137452467 Test RE 0.7702370156957519\n",
      "79 Train Loss 1.2018433 Test MSE 2.604185250667867 Test RE 0.7713367039712594\n",
      "80 Train Loss 1.1939949 Test MSE 2.5681037924211223 Test RE 0.7659745609632844\n",
      "81 Train Loss 1.1821965 Test MSE 2.6020856784066804 Test RE 0.7710257038807915\n",
      "82 Train Loss 1.1737196 Test MSE 2.606012531967377 Test RE 0.7716072688204256\n",
      "83 Train Loss 1.1645592 Test MSE 2.5861271031321036 Test RE 0.7686577196666108\n",
      "84 Train Loss 1.1569352 Test MSE 2.589761204830451 Test RE 0.7691976002616134\n",
      "85 Train Loss 1.1499926 Test MSE 2.5979298538341045 Test RE 0.7704097503013551\n",
      "86 Train Loss 1.145735 Test MSE 2.6122618369255384 Test RE 0.7725318848186172\n",
      "87 Train Loss 1.1427395 Test MSE 2.609764951485457 Test RE 0.7721625909100889\n",
      "88 Train Loss 1.1402715 Test MSE 2.59627879615904 Test RE 0.7701649028336546\n",
      "89 Train Loss 1.1371914 Test MSE 2.606303986514418 Test RE 0.7716504156120819\n",
      "90 Train Loss 1.1351697 Test MSE 2.589677065096179 Test RE 0.769185104783796\n",
      "91 Train Loss 1.1325061 Test MSE 2.5983012864672035 Test RE 0.770464822052877\n",
      "92 Train Loss 1.1303164 Test MSE 2.5942576940087987 Test RE 0.7698650727468265\n",
      "93 Train Loss 1.1269988 Test MSE 2.596514844560371 Test RE 0.7701999129532142\n",
      "94 Train Loss 1.1236731 Test MSE 2.5796808997764082 Test RE 0.7676991404281936\n",
      "95 Train Loss 1.1161318 Test MSE 2.591268117975971 Test RE 0.7694213555267353\n",
      "96 Train Loss 1.111679 Test MSE 2.5968882018458435 Test RE 0.7702552851404637\n",
      "97 Train Loss 1.1077862 Test MSE 2.5824821194876946 Test RE 0.7681158412859851\n",
      "98 Train Loss 1.102268 Test MSE 2.570685404306832 Test RE 0.7663594660289642\n",
      "99 Train Loss 1.099332 Test MSE 2.575607142411826 Test RE 0.7670927368055583\n",
      "Training time: 70.16\n",
      "5\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.319206 Test MSE 9.138777851417498 Test RE 1.4449476749266992\n",
      "1 Train Loss 46.10666 Test MSE 8.830506199290602 Test RE 1.4203679372069797\n",
      "2 Train Loss 38.10319 Test MSE 8.284733507586907 Test RE 1.3757747417982136\n",
      "3 Train Loss 31.827953 Test MSE 8.181159031500835 Test RE 1.3671478308060132\n",
      "4 Train Loss 30.16504 Test MSE 8.103564345164147 Test RE 1.3606489872272127\n",
      "5 Train Loss 28.837116 Test MSE 8.35333549564963 Test RE 1.3814590710618835\n",
      "6 Train Loss 28.103443 Test MSE 8.429595639649229 Test RE 1.3877506246210736\n",
      "7 Train Loss 26.381489 Test MSE 8.55052698526456 Test RE 1.3976695423994303\n",
      "8 Train Loss 24.708643 Test MSE 8.700843036781084 Test RE 1.4099013530106121\n",
      "9 Train Loss 22.15595 Test MSE 8.28456720312278 Test RE 1.3757609333498675\n",
      "10 Train Loss 18.979399 Test MSE 7.586057603574197 Test RE 1.3164856463229064\n",
      "11 Train Loss 16.610691 Test MSE 7.543559778883417 Test RE 1.3127929276809813\n",
      "12 Train Loss 15.250564 Test MSE 7.0680664781481255 Test RE 1.2707448932257013\n",
      "13 Train Loss 14.470715 Test MSE 6.849667874071662 Test RE 1.2509582547791676\n",
      "14 Train Loss 13.272012 Test MSE 6.321880879415642 Test RE 1.201797273648695\n",
      "15 Train Loss 12.512166 Test MSE 6.178335770856386 Test RE 1.1880748807603374\n",
      "16 Train Loss 11.86467 Test MSE 5.870602260070357 Test RE 1.1581088729121332\n",
      "17 Train Loss 9.214008 Test MSE 4.400348664385405 Test RE 1.0026551872938072\n",
      "18 Train Loss 8.166815 Test MSE 4.15103593046012 Test RE 0.9738370794502492\n",
      "19 Train Loss 7.449132 Test MSE 3.680566909537294 Test RE 0.9169917298913729\n",
      "20 Train Loss 6.8400593 Test MSE 3.7112630528514945 Test RE 0.9208076724481185\n",
      "21 Train Loss 6.468049 Test MSE 3.6269208004322935 Test RE 0.9102843922334112\n",
      "22 Train Loss 6.047221 Test MSE 3.468712347460863 Test RE 0.890209456556054\n",
      "23 Train Loss 5.634026 Test MSE 3.426217361715863 Test RE 0.8847397013422773\n",
      "24 Train Loss 4.9526362 Test MSE 3.057126176531009 Test RE 0.8357275944189697\n",
      "25 Train Loss 3.567567 Test MSE 2.5367131581785647 Test RE 0.7612788093216475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 2.9481018 Test MSE 2.2486150975712538 Test RE 0.7167465668795957\n",
      "27 Train Loss 2.404585 Test MSE 2.3102037567715312 Test RE 0.7264959593323331\n",
      "28 Train Loss 2.0431209 Test MSE 2.416262774310939 Test RE 0.7429851640060845\n",
      "29 Train Loss 1.8452084 Test MSE 2.4127931153779474 Test RE 0.7424515235331625\n",
      "30 Train Loss 1.6256553 Test MSE 2.4808557237470996 Test RE 0.7528506234794634\n",
      "31 Train Loss 1.5059965 Test MSE 2.4679372562555946 Test RE 0.7508879195780646\n",
      "32 Train Loss 1.3858132 Test MSE 2.4073383892194804 Test RE 0.741611799387422\n",
      "33 Train Loss 1.2859429 Test MSE 2.413748990605402 Test RE 0.7425985773229862\n",
      "34 Train Loss 1.2106748 Test MSE 2.4405482412015638 Test RE 0.7467096408166203\n",
      "35 Train Loss 1.1661235 Test MSE 2.4453874319999955 Test RE 0.747449573121946\n",
      "36 Train Loss 1.1250229 Test MSE 2.4181385692761324 Test RE 0.7432735054609981\n",
      "37 Train Loss 1.1032902 Test MSE 2.4202203712118333 Test RE 0.7435933827734704\n",
      "38 Train Loss 1.0627193 Test MSE 2.4543925720066255 Test RE 0.7488245500938662\n",
      "39 Train Loss 1.0232534 Test MSE 2.4749663558928936 Test RE 0.7519564866836009\n",
      "40 Train Loss 0.98617244 Test MSE 2.48777906419429 Test RE 0.7539003841988633\n",
      "41 Train Loss 0.9632209 Test MSE 2.4766660663050772 Test RE 0.7522146495680111\n",
      "42 Train Loss 0.93823075 Test MSE 2.4747368688226583 Test RE 0.7519216239285923\n",
      "43 Train Loss 0.92059845 Test MSE 2.499949177611056 Test RE 0.755742159394865\n",
      "44 Train Loss 0.9005803 Test MSE 2.5093371796771735 Test RE 0.7571598403336017\n",
      "45 Train Loss 0.88210845 Test MSE 2.5219381473254034 Test RE 0.7590585486716375\n",
      "46 Train Loss 0.8669389 Test MSE 2.55040039817624 Test RE 0.7633298469204426\n",
      "47 Train Loss 0.85533595 Test MSE 2.5311132688945057 Test RE 0.76043806933519\n",
      "48 Train Loss 0.8338949 Test MSE 2.565442866730196 Test RE 0.7655776280910256\n",
      "49 Train Loss 0.8114609 Test MSE 2.5919205489474493 Test RE 0.769518212105345\n",
      "50 Train Loss 0.80207944 Test MSE 2.5807239653714436 Test RE 0.7678543300937969\n",
      "51 Train Loss 0.78670466 Test MSE 2.5899672706203822 Test RE 0.769228201955294\n",
      "52 Train Loss 0.7749482 Test MSE 2.5933654126002055 Test RE 0.7697326658216542\n",
      "53 Train Loss 0.76577705 Test MSE 2.624214052006711 Test RE 0.7742971997350044\n",
      "54 Train Loss 0.7541126 Test MSE 2.618224946328304 Test RE 0.7734131261455287\n",
      "55 Train Loss 0.74695647 Test MSE 2.6265591446184935 Test RE 0.7746430924712222\n",
      "56 Train Loss 0.7376017 Test MSE 2.65190010048415 Test RE 0.7783709878859756\n",
      "57 Train Loss 0.7257121 Test MSE 2.654613539493368 Test RE 0.7787691028469332\n",
      "58 Train Loss 0.72080976 Test MSE 2.650602265149431 Test RE 0.7781804978673507\n",
      "59 Train Loss 0.7127226 Test MSE 2.661760111792135 Test RE 0.7798166732111469\n",
      "60 Train Loss 0.701552 Test MSE 2.6619616187181765 Test RE 0.7798461904253567\n",
      "61 Train Loss 0.6944734 Test MSE 2.6643355830521407 Test RE 0.7801938502967328\n",
      "62 Train Loss 0.69042474 Test MSE 2.684397967458195 Test RE 0.7831257620316676\n",
      "63 Train Loss 0.6839104 Test MSE 2.7076255098233872 Test RE 0.7865065773187658\n",
      "64 Train Loss 0.678419 Test MSE 2.7259741377425257 Test RE 0.789167017248665\n",
      "65 Train Loss 0.6716459 Test MSE 2.7293141358192976 Test RE 0.789650332441307\n",
      "66 Train Loss 0.6666813 Test MSE 2.734801097374839 Test RE 0.790443682959394\n",
      "67 Train Loss 0.66195923 Test MSE 2.746197556844367 Test RE 0.7920889386429232\n",
      "68 Train Loss 0.6585187 Test MSE 2.7384658858143323 Test RE 0.7909731253111342\n",
      "69 Train Loss 0.65216845 Test MSE 2.770216138579702 Test RE 0.7955452514207764\n",
      "70 Train Loss 0.6468037 Test MSE 2.7616159929318598 Test RE 0.7943094050012787\n",
      "71 Train Loss 0.6441318 Test MSE 2.762156365139743 Test RE 0.7943871134396183\n",
      "72 Train Loss 0.6408652 Test MSE 2.7702842983052847 Test RE 0.7955550383489033\n",
      "73 Train Loss 0.6374071 Test MSE 2.7750831377183975 Test RE 0.7962437923841345\n",
      "74 Train Loss 0.63364536 Test MSE 2.781111997372337 Test RE 0.7971082417408436\n",
      "75 Train Loss 0.6295693 Test MSE 2.7804363574285427 Test RE 0.797011411609354\n",
      "76 Train Loss 0.6274208 Test MSE 2.785062968628352 Test RE 0.7976742444801407\n",
      "77 Train Loss 0.6241323 Test MSE 2.787657326534032 Test RE 0.7980456850530994\n",
      "78 Train Loss 0.6192753 Test MSE 2.7783785232454226 Test RE 0.7967164181809439\n",
      "79 Train Loss 0.6154738 Test MSE 2.797389739283169 Test RE 0.7994375603518825\n",
      "80 Train Loss 0.6108367 Test MSE 2.797678453402003 Test RE 0.7994788136231931\n",
      "81 Train Loss 0.6056337 Test MSE 2.808676185469046 Test RE 0.8010486562702767\n",
      "82 Train Loss 0.60317093 Test MSE 2.80302572248901 Test RE 0.8002424802893389\n",
      "83 Train Loss 0.6001988 Test MSE 2.8189166241541046 Test RE 0.8025076400738218\n",
      "84 Train Loss 0.59722805 Test MSE 2.816389870338955 Test RE 0.8021478930309573\n",
      "85 Train Loss 0.59464395 Test MSE 2.8223708928557003 Test RE 0.8029991814521779\n",
      "86 Train Loss 0.59243476 Test MSE 2.8252454881262246 Test RE 0.8034080062104272\n",
      "87 Train Loss 0.5884791 Test MSE 2.8341228450192375 Test RE 0.8046692321545194\n",
      "88 Train Loss 0.58527714 Test MSE 2.8477695951769975 Test RE 0.8066042105134485\n",
      "89 Train Loss 0.5816844 Test MSE 2.842469823955982 Test RE 0.8058533055723139\n",
      "90 Train Loss 0.5791142 Test MSE 2.852666056938835 Test RE 0.8072973512858931\n",
      "91 Train Loss 0.57598865 Test MSE 2.8498967284468724 Test RE 0.8069053996229574\n",
      "92 Train Loss 0.57379556 Test MSE 2.847655756327501 Test RE 0.8065880884554798\n",
      "93 Train Loss 0.57076025 Test MSE 2.8479786151735316 Test RE 0.8066338114537838\n",
      "94 Train Loss 0.5693684 Test MSE 2.852251439193109 Test RE 0.8072386812620457\n",
      "95 Train Loss 0.5670761 Test MSE 2.852716765920416 Test RE 0.807304526511415\n",
      "96 Train Loss 0.56534946 Test MSE 2.863935158365464 Test RE 0.8088903433508737\n",
      "97 Train Loss 0.5629469 Test MSE 2.8821698380799425 Test RE 0.8114613604789739\n",
      "98 Train Loss 0.5608206 Test MSE 2.898375648978988 Test RE 0.8137394975153612\n",
      "99 Train Loss 0.5574124 Test MSE 2.9045383230621287 Test RE 0.8146041453495465\n",
      "Training time: 67.70\n",
      "6\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.93781 Test MSE 8.42499552149282 Test RE 1.3873719179615622\n",
      "1 Train Loss 53.315567 Test MSE 8.904900381202875 Test RE 1.4263384607538072\n",
      "2 Train Loss 46.8901 Test MSE 8.671244909044637 Test RE 1.4075012413300403\n",
      "3 Train Loss 45.94467 Test MSE 8.61547892993099 Test RE 1.4029680232510322\n",
      "4 Train Loss 44.77086 Test MSE 8.576660565324934 Test RE 1.3998038109763449\n",
      "5 Train Loss 43.394047 Test MSE 8.548185405474443 Test RE 1.3974781519241557\n",
      "6 Train Loss 41.21232 Test MSE 8.980725830716787 Test RE 1.4323982421380568\n",
      "7 Train Loss 36.386307 Test MSE 8.802211188967968 Test RE 1.4180905156060695\n",
      "8 Train Loss 32.01641 Test MSE 8.769051207497554 Test RE 1.4154168563809013\n",
      "9 Train Loss 30.839123 Test MSE 8.270135060938788 Test RE 1.374562087855621\n",
      "10 Train Loss 29.636635 Test MSE 8.665663743841796 Test RE 1.4070482059545202\n",
      "11 Train Loss 28.593994 Test MSE 8.85654403305191 Test RE 1.4224604606172366\n",
      "12 Train Loss 27.93389 Test MSE 9.12067787036172 Test RE 1.4435160563599636\n",
      "13 Train Loss 27.052467 Test MSE 9.225487315065996 Test RE 1.451786381895119\n",
      "14 Train Loss 26.510506 Test MSE 9.36321972866783 Test RE 1.4625834939701405\n",
      "15 Train Loss 25.738255 Test MSE 8.980221218872241 Test RE 1.4323579995515276\n",
      "16 Train Loss 23.07116 Test MSE 8.734284578147033 Test RE 1.4126082204208599\n",
      "17 Train Loss 21.481041 Test MSE 7.9220888823286755 Test RE 1.3453271774420652\n",
      "18 Train Loss 20.48509 Test MSE 8.153768768664799 Test RE 1.3648573281210086\n",
      "19 Train Loss 19.86073 Test MSE 7.906642038911102 Test RE 1.344014947901884\n",
      "20 Train Loss 19.41069 Test MSE 7.953289373213255 Test RE 1.347973803951108\n",
      "21 Train Loss 19.036991 Test MSE 7.779134137187508 Test RE 1.3331336489573118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 18.439909 Test MSE 8.103602255926539 Test RE 1.36065216997359\n",
      "23 Train Loss 18.023388 Test MSE 7.587659416916845 Test RE 1.3166246284581629\n",
      "24 Train Loss 17.652756 Test MSE 7.691630223081629 Test RE 1.3256145397380237\n",
      "25 Train Loss 17.226038 Test MSE 7.271041369767299 Test RE 1.2888618477204181\n",
      "26 Train Loss 13.738039 Test MSE 5.884585347752833 Test RE 1.1594872925060422\n",
      "27 Train Loss 12.3347645 Test MSE 5.839559772107873 Test RE 1.1550428985910433\n",
      "28 Train Loss 11.683409 Test MSE 5.320446249390835 Test RE 1.102508865213096\n",
      "29 Train Loss 10.78713 Test MSE 4.388104864223334 Test RE 1.0012592909487337\n",
      "30 Train Loss 8.892026 Test MSE 3.4334663496561886 Test RE 0.8856751467655822\n",
      "31 Train Loss 7.745357 Test MSE 3.2032661694870037 Test RE 0.8554695857467796\n",
      "32 Train Loss 6.9769287 Test MSE 3.144372150065299 Test RE 0.8475689353560678\n",
      "33 Train Loss 6.533494 Test MSE 2.9569948972914424 Test RE 0.821927190635715\n",
      "34 Train Loss 6.0374727 Test MSE 2.746650593538642 Test RE 0.792154270897534\n",
      "35 Train Loss 5.6751013 Test MSE 2.5959389441372602 Test RE 0.7701144940205163\n",
      "36 Train Loss 5.377026 Test MSE 2.49859619256342 Test RE 0.7555376259917997\n",
      "37 Train Loss 5.240737 Test MSE 2.4433229017507876 Test RE 0.7471339875280113\n",
      "38 Train Loss 5.1252966 Test MSE 2.5085811702101255 Test RE 0.7570457737320785\n",
      "39 Train Loss 5.0057487 Test MSE 2.410029933024519 Test RE 0.7420262660514251\n",
      "40 Train Loss 4.8418956 Test MSE 2.3931007144516636 Test RE 0.7394154970402945\n",
      "41 Train Loss 4.706047 Test MSE 2.325918301902871 Test RE 0.7289626691936326\n",
      "42 Train Loss 4.5513983 Test MSE 2.3284107538513856 Test RE 0.729353142482415\n",
      "43 Train Loss 3.8837998 Test MSE 1.2366539924947944 Test RE 0.5315353615987907\n",
      "44 Train Loss 3.0865288 Test MSE 1.1614722648291076 Test RE 0.5151248274767601\n",
      "45 Train Loss 2.7090023 Test MSE 0.9805752241906952 Test RE 0.47331309294143226\n",
      "46 Train Loss 2.5272062 Test MSE 0.9124134161868046 Test RE 0.4565663413066422\n",
      "47 Train Loss 2.3146033 Test MSE 0.9267006420599625 Test RE 0.46012707847073\n",
      "48 Train Loss 2.0902386 Test MSE 0.4624648854504974 Test RE 0.3250479576739064\n",
      "49 Train Loss 1.4903443 Test MSE 0.21315778789193773 Test RE 0.22067780856934233\n",
      "50 Train Loss 1.2294375 Test MSE 0.19281579994066966 Test RE 0.20988401791776773\n",
      "51 Train Loss 0.98037165 Test MSE 0.20190376239056285 Test RE 0.21477328817836652\n",
      "52 Train Loss 0.7430424 Test MSE 0.15256281184963696 Test RE 0.1866948777175335\n",
      "53 Train Loss 0.5676546 Test MSE 0.07810640736249565 Test RE 0.13358306113383037\n",
      "54 Train Loss 0.49151844 Test MSE 0.05348058649439485 Test RE 0.11053660991671953\n",
      "55 Train Loss 0.4025669 Test MSE 0.0333416167454445 Test RE 0.08727731714464732\n",
      "56 Train Loss 0.29473242 Test MSE 0.03202462842806083 Test RE 0.08553623101415124\n",
      "57 Train Loss 0.24231848 Test MSE 0.03340269367840695 Test RE 0.08735722016629408\n",
      "58 Train Loss 0.19232994 Test MSE 0.0346303514019765 Test RE 0.08894806597146587\n",
      "59 Train Loss 0.17733634 Test MSE 0.032518850391126515 Test RE 0.08619372548053865\n",
      "60 Train Loss 0.1669279 Test MSE 0.030088921836515806 Test RE 0.08291085110740112\n",
      "61 Train Loss 0.14080028 Test MSE 0.0259572194255748 Test RE 0.07700823053677827\n",
      "62 Train Loss 0.124863036 Test MSE 0.021074496561686695 Test RE 0.06938836665339221\n",
      "63 Train Loss 0.11034259 Test MSE 0.021542519109167078 Test RE 0.07015462438407681\n",
      "64 Train Loss 0.0982825 Test MSE 0.019385550709559763 Test RE 0.06654985779637423\n",
      "65 Train Loss 0.08144514 Test MSE 0.018281652116432602 Test RE 0.06462726550009973\n",
      "66 Train Loss 0.07249053 Test MSE 0.015718754357314662 Test RE 0.0599262530501922\n",
      "67 Train Loss 0.06600947 Test MSE 0.016780925100030774 Test RE 0.06191787024810436\n",
      "68 Train Loss 0.060498692 Test MSE 0.015441999438315562 Test RE 0.05939635939913999\n",
      "69 Train Loss 0.054809533 Test MSE 0.014337994396597767 Test RE 0.057233758076824334\n",
      "70 Train Loss 0.052986056 Test MSE 0.013500110946789849 Test RE 0.05553627273148933\n",
      "71 Train Loss 0.049457964 Test MSE 0.013755880971463956 Test RE 0.056059893052437824\n",
      "72 Train Loss 0.047812875 Test MSE 0.01431332813185295 Test RE 0.057184506044660625\n",
      "73 Train Loss 0.044365626 Test MSE 0.013595724529511861 Test RE 0.05573259160662673\n",
      "74 Train Loss 0.03966164 Test MSE 0.014497793053817805 Test RE 0.05755181287185299\n",
      "75 Train Loss 0.038031977 Test MSE 0.013142152384181994 Test RE 0.054795047729119715\n",
      "76 Train Loss 0.03576238 Test MSE 0.01210203168011259 Test RE 0.05258201237148632\n",
      "77 Train Loss 0.03300965 Test MSE 0.010677897757328572 Test RE 0.04939135483973328\n",
      "78 Train Loss 0.03194877 Test MSE 0.010910573128175744 Test RE 0.04992658286095801\n",
      "79 Train Loss 0.029889196 Test MSE 0.008979527630725608 Test RE 0.04529338781280364\n",
      "80 Train Loss 0.025720509 Test MSE 0.0063887016625510315 Test RE 0.03820448628299493\n",
      "81 Train Loss 0.024140496 Test MSE 0.007149989430800722 Test RE 0.04041669157365646\n",
      "82 Train Loss 0.023319867 Test MSE 0.007031264938957468 Test RE 0.04007973039908404\n",
      "83 Train Loss 0.022864878 Test MSE 0.007070573452277692 Test RE 0.04019160776596514\n",
      "84 Train Loss 0.021362636 Test MSE 0.006970390900710176 Test RE 0.0399058556556518\n",
      "85 Train Loss 0.01906125 Test MSE 0.007066599605173993 Test RE 0.040180311811503736\n",
      "86 Train Loss 0.017675627 Test MSE 0.007154002869215343 Test RE 0.040428033348882716\n",
      "87 Train Loss 0.01683973 Test MSE 0.006851627643703084 Test RE 0.039564432136734586\n",
      "88 Train Loss 0.016346877 Test MSE 0.006710579479194655 Test RE 0.03915507611149989\n",
      "89 Train Loss 0.016127963 Test MSE 0.006719813582058407 Test RE 0.03918200655059943\n",
      "90 Train Loss 0.015651789 Test MSE 0.0066770689780147365 Test RE 0.03905718975224715\n",
      "91 Train Loss 0.014841385 Test MSE 0.006365828068178257 Test RE 0.03813603281944\n",
      "92 Train Loss 0.014222576 Test MSE 0.006725717727233592 Test RE 0.03919921576781961\n",
      "93 Train Loss 0.013637714 Test MSE 0.006100526355976838 Test RE 0.03733289889499276\n",
      "94 Train Loss 0.013525432 Test MSE 0.006067431030218441 Test RE 0.03723149578280912\n",
      "95 Train Loss 0.013282836 Test MSE 0.006015581076765922 Test RE 0.037072071369434814\n",
      "96 Train Loss 0.013142001 Test MSE 0.0059975732945542265 Test RE 0.037016541725961194\n",
      "97 Train Loss 0.01304945 Test MSE 0.005878897784802353 Test RE 0.036648484048523416\n",
      "98 Train Loss 0.012784266 Test MSE 0.0063734982808397005 Test RE 0.038159001035014274\n",
      "99 Train Loss 0.012477284 Test MSE 0.006016620923029008 Test RE 0.03707527534828871\n",
      "Training time: 68.24\n",
      "7\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 42.492245 Test MSE 7.940564267914263 Test RE 1.346895006585447\n",
      "1 Train Loss 30.218863 Test MSE 6.634547634627464 Test RE 1.2311577933729736\n",
      "2 Train Loss 26.801334 Test MSE 6.119848933106998 Test RE 1.1824380898531117\n",
      "3 Train Loss 23.508461 Test MSE 6.171517832645875 Test RE 1.1874191655842128\n",
      "4 Train Loss 17.55755 Test MSE 5.7320383738610285 Test RE 1.1443598308689584\n",
      "5 Train Loss 14.374088 Test MSE 5.68947468505339 Test RE 1.1401031483945496\n",
      "6 Train Loss 12.299232 Test MSE 5.450426073592763 Test RE 1.1158948853807917\n",
      "7 Train Loss 11.110951 Test MSE 5.20398965866569 Test RE 1.0903759722051782\n",
      "8 Train Loss 10.29646 Test MSE 4.999641017441085 Test RE 1.0687533067920585\n",
      "9 Train Loss 9.553631 Test MSE 4.9908844946177195 Test RE 1.067816973163226\n",
      "10 Train Loss 8.935089 Test MSE 4.724989495642564 Test RE 1.0389831012682993\n",
      "11 Train Loss 8.295815 Test MSE 4.612389303167793 Test RE 1.0265285638602593\n",
      "12 Train Loss 7.6788244 Test MSE 4.428053291824416 Test RE 1.0058065969558934\n",
      "13 Train Loss 6.6655293 Test MSE 3.690894295073349 Test RE 0.9182773325653032\n",
      "14 Train Loss 6.1342983 Test MSE 3.313165886141842 Test RE 0.8700208303725899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 5.5635853 Test MSE 2.8779877154453484 Test RE 0.8108724182800756\n",
      "16 Train Loss 5.2468677 Test MSE 2.5974603669946874 Test RE 0.7703401345685121\n",
      "17 Train Loss 4.9888015 Test MSE 2.4657660921906857 Test RE 0.750557550646456\n",
      "18 Train Loss 4.6833096 Test MSE 2.328447936100568 Test RE 0.7293589659570696\n",
      "19 Train Loss 4.456012 Test MSE 2.0735361625894497 Test RE 0.6882779669753627\n",
      "20 Train Loss 3.5047932 Test MSE 1.7828756577249223 Test RE 0.638217323019611\n",
      "21 Train Loss 2.8575191 Test MSE 1.557501740343185 Test RE 0.5965163208493977\n",
      "22 Train Loss 2.5018134 Test MSE 1.409832670699689 Test RE 0.5675339490556733\n",
      "23 Train Loss 2.1795194 Test MSE 0.8892268106939929 Test RE 0.4507277887728796\n",
      "24 Train Loss 1.1693313 Test MSE 0.17870715267104537 Test RE 0.20205938551813807\n",
      "25 Train Loss 0.56917274 Test MSE 0.09311320060945297 Test RE 0.1458524362618382\n",
      "26 Train Loss 0.32737613 Test MSE 0.04464388717248308 Test RE 0.10099248563464026\n",
      "27 Train Loss 0.23214096 Test MSE 0.03461993687214611 Test RE 0.08893469010454812\n",
      "28 Train Loss 0.17176758 Test MSE 0.034927430116581046 Test RE 0.08932877460687302\n",
      "29 Train Loss 0.12864609 Test MSE 0.019794621729431673 Test RE 0.06724835475984159\n",
      "30 Train Loss 0.09784391 Test MSE 0.016519705537833385 Test RE 0.061434059100164064\n",
      "31 Train Loss 0.067332745 Test MSE 0.011663291396114994 Test RE 0.05162007406939324\n",
      "32 Train Loss 0.052384168 Test MSE 0.010756592050993668 Test RE 0.049573023686986496\n",
      "33 Train Loss 0.04412689 Test MSE 0.00862995635257693 Test RE 0.044403004758041126\n",
      "34 Train Loss 0.036468815 Test MSE 0.008472470421852901 Test RE 0.04399598962444327\n",
      "35 Train Loss 0.02938604 Test MSE 0.006208738119807807 Test RE 0.037662550870386245\n",
      "36 Train Loss 0.023708927 Test MSE 0.00458751443957199 Test RE 0.03237403130983497\n",
      "37 Train Loss 0.021120325 Test MSE 0.0035606945594692514 Test RE 0.028521700869875606\n",
      "38 Train Loss 0.017613225 Test MSE 0.0033550829079890634 Test RE 0.027685966467730028\n",
      "39 Train Loss 0.016212476 Test MSE 0.002883857577142846 Test RE 0.025668173400101007\n",
      "40 Train Loss 0.014532314 Test MSE 0.0021898870395224493 Test RE 0.022367575756685985\n",
      "41 Train Loss 0.012428198 Test MSE 0.002069235700001285 Test RE 0.021742678369617876\n",
      "42 Train Loss 0.01145693 Test MSE 0.00171791687652953 Test RE 0.019811124778609725\n",
      "43 Train Loss 0.0101991175 Test MSE 0.0014741377721293946 Test RE 0.01835173365147723\n",
      "44 Train Loss 0.009331646 Test MSE 0.0011721018881739687 Test RE 0.01636404793724777\n",
      "45 Train Loss 0.008959734 Test MSE 0.0010739007557922856 Test RE 0.015663547711682317\n",
      "46 Train Loss 0.008222166 Test MSE 0.0010577260337525103 Test RE 0.015545140697595813\n",
      "47 Train Loss 0.0075241886 Test MSE 0.000964619863560003 Test RE 0.014845203681175605\n",
      "48 Train Loss 0.0065095676 Test MSE 0.0008468350936041613 Test RE 0.013909370770871536\n",
      "49 Train Loss 0.006108479 Test MSE 0.0008921851773964738 Test RE 0.01427695406190347\n",
      "50 Train Loss 0.0054894737 Test MSE 0.0006658941044187655 Test RE 0.012334190313346037\n",
      "51 Train Loss 0.004817596 Test MSE 0.0006601341740986973 Test RE 0.0122807295785726\n",
      "52 Train Loss 0.0046760673 Test MSE 0.0006199788131767063 Test RE 0.011901357047799327\n",
      "53 Train Loss 0.0043785376 Test MSE 0.0006156485567511907 Test RE 0.011859721567001782\n",
      "54 Train Loss 0.0040980405 Test MSE 0.0005690578408319891 Test RE 0.011402137295481897\n",
      "55 Train Loss 0.0036240066 Test MSE 0.000664575449588058 Test RE 0.01232197170411982\n",
      "56 Train Loss 0.0035355221 Test MSE 0.0007199266041622252 Test RE 0.012824846379023196\n",
      "57 Train Loss 0.0034008555 Test MSE 0.0006560279596892107 Test RE 0.01224247525583141\n",
      "58 Train Loss 0.0032069525 Test MSE 0.000694870705308878 Test RE 0.012599695853206633\n",
      "59 Train Loss 0.0030529224 Test MSE 0.0007358325835848104 Test RE 0.012965747740659665\n",
      "60 Train Loss 0.002895348 Test MSE 0.0006478699071455977 Test RE 0.012166116314538924\n",
      "61 Train Loss 0.0028492792 Test MSE 0.000647698386659803 Test RE 0.012164505747132348\n",
      "62 Train Loss 0.0025749267 Test MSE 0.0005529206219712548 Test RE 0.011239304933604753\n",
      "63 Train Loss 0.0022312796 Test MSE 0.0005154334240533365 Test RE 0.010851614297253204\n",
      "64 Train Loss 0.0020232915 Test MSE 0.0005113188986698111 Test RE 0.010808215186275323\n",
      "65 Train Loss 0.0019719428 Test MSE 0.0005244919388724969 Test RE 0.01094655514288092\n",
      "66 Train Loss 0.0019048604 Test MSE 0.0005202878923684383 Test RE 0.010902596015505\n",
      "67 Train Loss 0.0017666296 Test MSE 0.000523580473341298 Test RE 0.01093703950934113\n",
      "68 Train Loss 0.0016613752 Test MSE 0.0005326507039143658 Test RE 0.011031366483190919\n",
      "69 Train Loss 0.0016132016 Test MSE 0.000595646332229959 Test RE 0.011665471479777211\n",
      "70 Train Loss 0.0015810706 Test MSE 0.0005978602681050031 Test RE 0.01168713085247782\n",
      "71 Train Loss 0.0015134341 Test MSE 0.0005322986073739757 Test RE 0.011027719864465928\n",
      "72 Train Loss 0.0013936609 Test MSE 0.00046406107363596813 Test RE 0.010296642410772628\n",
      "73 Train Loss 0.0013404123 Test MSE 0.0004826065755387702 Test RE 0.010500371818613134\n",
      "74 Train Loss 0.0012962302 Test MSE 0.00043786836403073075 Test RE 0.010001838658047766\n",
      "75 Train Loss 0.0012843105 Test MSE 0.000447955524103879 Test RE 0.010116388718054006\n",
      "76 Train Loss 0.0012436763 Test MSE 0.00043697262641749095 Test RE 0.009991603150832435\n",
      "77 Train Loss 0.0011578235 Test MSE 0.00038160787710160565 Test RE 0.009337201382538494\n",
      "78 Train Loss 0.0010723012 Test MSE 0.0003544785988371846 Test RE 0.008999182732779947\n",
      "79 Train Loss 0.0010167961 Test MSE 0.00034413360884194896 Test RE 0.008866895796955114\n",
      "80 Train Loss 0.0009900292 Test MSE 0.00034425545407012787 Test RE 0.008868465381121196\n",
      "81 Train Loss 0.0009701401 Test MSE 0.0003465935582069907 Test RE 0.008898530710359303\n",
      "82 Train Loss 0.00095722574 Test MSE 0.0003338425545941303 Test RE 0.00873331063341825\n",
      "83 Train Loss 0.00093984656 Test MSE 0.0003252458874036133 Test RE 0.008620133011407655\n",
      "84 Train Loss 0.00091901945 Test MSE 0.00028094805460028116 Test RE 0.00801163351905723\n",
      "85 Train Loss 0.0008953052 Test MSE 0.0002848331014290892 Test RE 0.008066837149623583\n",
      "86 Train Loss 0.0008763581 Test MSE 0.00026580296024538124 Test RE 0.007792700173764298\n",
      "87 Train Loss 0.00085389 Test MSE 0.00023980518609304212 Test RE 0.007401799995136841\n",
      "88 Train Loss 0.00081743416 Test MSE 0.00024269004610670322 Test RE 0.007446188777723069\n",
      "89 Train Loss 0.0007949544 Test MSE 0.00022696581335677804 Test RE 0.007200924933516221\n",
      "90 Train Loss 0.00078643346 Test MSE 0.00021574576405502011 Test RE 0.007020680332203735\n",
      "91 Train Loss 0.0007751442 Test MSE 0.0002092744248890637 Test RE 0.006914585304430275\n",
      "92 Train Loss 0.00067843153 Test MSE 0.0001813707091939379 Test RE 0.006437120453548048\n",
      "93 Train Loss 0.00062318164 Test MSE 0.0001416330007378477 Test RE 0.005688402106027707\n",
      "94 Train Loss 0.00060543284 Test MSE 0.00013392365072463275 Test RE 0.005531420820476088\n",
      "95 Train Loss 0.00058560586 Test MSE 0.0001404895484891775 Test RE 0.0056653933527385375\n",
      "96 Train Loss 0.0005725699 Test MSE 0.00013996253345620986 Test RE 0.005654757142246352\n",
      "97 Train Loss 0.0005677969 Test MSE 0.00014439912578406903 Test RE 0.005743681406829365\n",
      "98 Train Loss 0.000561312 Test MSE 0.00014418514898637913 Test RE 0.005739424212795328\n",
      "99 Train Loss 0.0005343926 Test MSE 0.00013815788491486407 Test RE 0.005618183219267966\n",
      "Training time: 67.12\n",
      "8\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54.63822 Test MSE 9.175201418707408 Test RE 1.447824307514171\n",
      "1 Train Loss 31.65059 Test MSE 7.750201938617121 Test RE 1.3306522405826637\n",
      "2 Train Loss 27.583729 Test MSE 7.048086738834116 Test RE 1.2689475757093693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 23.654465 Test MSE 6.788605615241839 Test RE 1.2453698569033085\n",
      "4 Train Loss 18.478355 Test MSE 7.327084818875024 Test RE 1.2938194326307821\n",
      "5 Train Loss 15.096312 Test MSE 6.574007486148148 Test RE 1.2255277721988198\n",
      "6 Train Loss 12.734995 Test MSE 6.370188599204162 Test RE 1.2063802136008916\n",
      "7 Train Loss 11.2834015 Test MSE 6.374081429883454 Test RE 1.206748767575686\n",
      "8 Train Loss 9.996418 Test MSE 6.213998721431222 Test RE 1.191498884419033\n",
      "9 Train Loss 9.224947 Test MSE 5.994709337553233 Test RE 1.1702863123065332\n",
      "10 Train Loss 8.615169 Test MSE 5.606494677383801 Test RE 1.1317585063879885\n",
      "11 Train Loss 7.9494534 Test MSE 5.401944099326761 Test RE 1.1109208125143495\n",
      "12 Train Loss 7.112364 Test MSE 5.115025108955584 Test RE 1.0810155601861222\n",
      "13 Train Loss 5.9946294 Test MSE 4.8108270182491735 Test RE 1.0483780776620604\n",
      "14 Train Loss 4.1252327 Test MSE 4.450192736446167 Test RE 1.0083178850307364\n",
      "15 Train Loss 3.2370687 Test MSE 4.310769918262521 Test RE 0.9923970898662575\n",
      "16 Train Loss 2.8049645 Test MSE 4.321702236111117 Test RE 0.9936546761919125\n",
      "17 Train Loss 2.6228983 Test MSE 4.353771553019688 Test RE 0.9973345837803128\n",
      "18 Train Loss 2.4596515 Test MSE 4.367452202906367 Test RE 0.9989002933647939\n",
      "19 Train Loss 2.333795 Test MSE 4.303818426533905 Test RE 0.9915966036768172\n",
      "20 Train Loss 2.232224 Test MSE 4.247382876818519 Test RE 0.9850737952803014\n",
      "21 Train Loss 2.1627939 Test MSE 4.223716412517745 Test RE 0.9823255405725445\n",
      "22 Train Loss 2.0959945 Test MSE 4.221231794400781 Test RE 0.9820365696000032\n",
      "23 Train Loss 2.0453506 Test MSE 4.21494231089809 Test RE 0.9813046973039774\n",
      "24 Train Loss 1.9694403 Test MSE 4.165793928519051 Test RE 0.9755666639070241\n",
      "25 Train Loss 1.9229119 Test MSE 4.175799698148568 Test RE 0.9767375620730513\n",
      "26 Train Loss 1.8832015 Test MSE 4.1319061416131095 Test RE 0.9715905546550321\n",
      "27 Train Loss 1.8414702 Test MSE 4.169756884815465 Test RE 0.9760305861612609\n",
      "28 Train Loss 1.8085462 Test MSE 4.134092570378774 Test RE 0.9718475828297551\n",
      "29 Train Loss 1.7768438 Test MSE 4.16573476061801 Test RE 0.9755597357634596\n",
      "30 Train Loss 1.7548115 Test MSE 4.2050403008511505 Test RE 0.9801513478805317\n",
      "31 Train Loss 1.7183042 Test MSE 4.2405071907745375 Test RE 0.9842761509862096\n",
      "32 Train Loss 1.6512268 Test MSE 4.28393430761738 Test RE 0.9893033085955449\n",
      "33 Train Loss 1.5962375 Test MSE 4.319331724846132 Test RE 0.9933821223965629\n",
      "34 Train Loss 1.5387809 Test MSE 4.349038230604485 Test RE 0.9967922964964426\n",
      "35 Train Loss 1.511838 Test MSE 4.369791446766663 Test RE 0.9991677672223597\n",
      "36 Train Loss 1.4927837 Test MSE 4.3630305993252705 Test RE 0.9983945225685513\n",
      "37 Train Loss 1.4729981 Test MSE 4.342154007001078 Test RE 0.9960030577711105\n",
      "38 Train Loss 1.455156 Test MSE 4.294996983133577 Test RE 0.9905798553684413\n",
      "39 Train Loss 1.4312687 Test MSE 4.281251451859503 Test RE 0.9889934796432996\n",
      "40 Train Loss 1.4089302 Test MSE 4.284364167283055 Test RE 0.9893529418172001\n",
      "41 Train Loss 1.3813257 Test MSE 4.294389163247647 Test RE 0.99050976039045\n",
      "42 Train Loss 1.3643365 Test MSE 4.308695791932003 Test RE 0.9921583152821839\n",
      "43 Train Loss 1.3531904 Test MSE 4.3297376286531435 Test RE 0.9945780042013008\n",
      "44 Train Loss 1.3374761 Test MSE 4.346661433846183 Test RE 0.9965198803487194\n",
      "45 Train Loss 1.3266195 Test MSE 4.344869255855558 Test RE 0.9963144209228038\n",
      "46 Train Loss 1.3142273 Test MSE 4.304605125367487 Test RE 0.991687226952384\n",
      "47 Train Loss 1.304462 Test MSE 4.29322227594584 Test RE 0.9903751787603384\n",
      "48 Train Loss 1.293057 Test MSE 4.271084204098816 Test RE 0.9878184355133891\n",
      "49 Train Loss 1.2798612 Test MSE 4.247440444704901 Test RE 0.9850804709704636\n",
      "50 Train Loss 1.2687155 Test MSE 4.210136009906624 Test RE 0.9807450465780435\n",
      "51 Train Loss 1.2492398 Test MSE 4.1799818502219805 Test RE 0.9772265513754231\n",
      "52 Train Loss 1.235178 Test MSE 4.110200351075929 Test RE 0.9690352073434074\n",
      "53 Train Loss 1.2099634 Test MSE 3.993225443586413 Test RE 0.9551464702809674\n",
      "54 Train Loss 1.1725008 Test MSE 3.92535541556693 Test RE 0.9469947099761227\n",
      "55 Train Loss 1.1486703 Test MSE 3.8983009387548018 Test RE 0.9437256117624933\n",
      "56 Train Loss 1.1173419 Test MSE 3.7819864510333345 Test RE 0.9295399176378993\n",
      "57 Train Loss 1.0860918 Test MSE 3.731267022311904 Test RE 0.9232859465490081\n",
      "58 Train Loss 1.0610981 Test MSE 3.6737375254421654 Test RE 0.9161405843152995\n",
      "59 Train Loss 1.029507 Test MSE 3.6036445258300365 Test RE 0.9073587516613192\n",
      "60 Train Loss 0.9973326 Test MSE 3.442772234495983 Test RE 0.8868745780362383\n",
      "61 Train Loss 0.96968025 Test MSE 3.4151602544128523 Test RE 0.8833109292876208\n",
      "62 Train Loss 0.9431333 Test MSE 3.3678883090402323 Test RE 0.8771763227793313\n",
      "63 Train Loss 0.9101844 Test MSE 3.2973467423651694 Test RE 0.8679413310798774\n",
      "64 Train Loss 0.88607264 Test MSE 3.245078130044214 Test RE 0.861034670310536\n",
      "65 Train Loss 0.85796475 Test MSE 3.216665054959551 Test RE 0.8572568829925438\n",
      "66 Train Loss 0.83569205 Test MSE 3.1624240593767055 Test RE 0.8499984093317672\n",
      "67 Train Loss 0.81394696 Test MSE 3.0287061427854973 Test RE 0.8318339270775175\n",
      "68 Train Loss 0.7876123 Test MSE 2.9936161478568106 Test RE 0.8270011561048741\n",
      "69 Train Loss 0.76376057 Test MSE 2.923132546235635 Test RE 0.8172074449173984\n",
      "70 Train Loss 0.74472874 Test MSE 2.9267673532255665 Test RE 0.8177153706557654\n",
      "71 Train Loss 0.7294317 Test MSE 2.9364502440100635 Test RE 0.8190669148080627\n",
      "72 Train Loss 0.7141288 Test MSE 2.9363155980924556 Test RE 0.8190481361345945\n",
      "73 Train Loss 0.70105743 Test MSE 2.939445717302948 Test RE 0.8194845734573417\n",
      "74 Train Loss 0.67982817 Test MSE 2.9498058173143233 Test RE 0.8209274432006964\n",
      "75 Train Loss 0.6674968 Test MSE 2.897070013802172 Test RE 0.8135561937068083\n",
      "76 Train Loss 0.6575127 Test MSE 2.8870088552778186 Test RE 0.8121422760580531\n",
      "77 Train Loss 0.64939594 Test MSE 2.8962399311399394 Test RE 0.813439633308064\n",
      "78 Train Loss 0.6356125 Test MSE 2.8662752319567626 Test RE 0.8092207412696985\n",
      "79 Train Loss 0.6277586 Test MSE 2.860488447105011 Test RE 0.8084034519513956\n",
      "80 Train Loss 0.6200039 Test MSE 2.8571715771319712 Test RE 0.8079346252230855\n",
      "81 Train Loss 0.6109914 Test MSE 2.8208472545746957 Test RE 0.8027824052903179\n",
      "82 Train Loss 0.60334665 Test MSE 2.834205857683713 Test RE 0.8046810166203856\n",
      "83 Train Loss 0.59606504 Test MSE 2.825745913393433 Test RE 0.8034791554019286\n",
      "84 Train Loss 0.588808 Test MSE 2.8217808069153207 Test RE 0.8029152337155792\n",
      "85 Train Loss 0.5819682 Test MSE 2.84739363477125 Test RE 0.8065509651146309\n",
      "86 Train Loss 0.57760674 Test MSE 2.854415301945924 Test RE 0.80754482933206\n",
      "87 Train Loss 0.5705521 Test MSE 2.8584918182126495 Test RE 0.8081212687726441\n",
      "88 Train Loss 0.56188595 Test MSE 2.8737915072399627 Test RE 0.8102810622683907\n",
      "89 Train Loss 0.5577385 Test MSE 2.8766195234401732 Test RE 0.8106796514658469\n",
      "90 Train Loss 0.5527424 Test MSE 2.8849144819729213 Test RE 0.811847639327848\n",
      "91 Train Loss 0.5481373 Test MSE 2.8830080552879487 Test RE 0.811579349956934\n",
      "92 Train Loss 0.54306966 Test MSE 2.887734213387734 Test RE 0.8122442946208978\n",
      "93 Train Loss 0.53830034 Test MSE 2.905762565528288 Test RE 0.8147758022211709\n",
      "94 Train Loss 0.53459436 Test MSE 2.9033955593210186 Test RE 0.8144438803506661\n",
      "95 Train Loss 0.52979666 Test MSE 2.9172607908448005 Test RE 0.8163862617775012\n",
      "96 Train Loss 0.5254203 Test MSE 2.9332522361667603 Test RE 0.8186207815922547\n",
      "97 Train Loss 0.52210224 Test MSE 2.9271753442161077 Test RE 0.8177723633780999\n",
      "98 Train Loss 0.5175556 Test MSE 2.9452408402934607 Test RE 0.8202919834217449\n",
      "99 Train Loss 0.5134749 Test MSE 2.953416813938218 Test RE 0.821429757549346\n",
      "Training time: 67.50\n",
      "9\n",
      "KG_rowdy_tune19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.214848 Test MSE 8.586180415435633 Test RE 1.4005804667950754\n",
      "1 Train Loss 44.53111 Test MSE 8.983388099203882 Test RE 1.43261053823746\n",
      "2 Train Loss 39.374916 Test MSE 9.487838990573847 Test RE 1.472284409801333\n",
      "3 Train Loss 36.03533 Test MSE 9.515108354012876 Test RE 1.4743986663862303\n",
      "4 Train Loss 30.918953 Test MSE 8.816742138743917 Test RE 1.419260545743878\n",
      "5 Train Loss 27.483725 Test MSE 8.60236206414765 Test RE 1.4018996233914975\n",
      "6 Train Loss 25.123787 Test MSE 8.319791743091931 Test RE 1.3786825792585624\n",
      "7 Train Loss 23.56672 Test MSE 8.368830158795864 Test RE 1.3827397167379443\n",
      "8 Train Loss 20.982292 Test MSE 7.624749436634386 Test RE 1.319838669770803\n",
      "9 Train Loss 16.963531 Test MSE 6.186074682559561 Test RE 1.1888187323038533\n",
      "10 Train Loss 14.434128 Test MSE 5.794799112292182 Test RE 1.150607638244891\n",
      "11 Train Loss 12.7182865 Test MSE 5.352915483220989 Test RE 1.1058679037891066\n",
      "12 Train Loss 10.527668 Test MSE 5.197358212868332 Test RE 1.0896810175026694\n",
      "13 Train Loss 9.519932 Test MSE 5.083888111625247 Test RE 1.0777202723927963\n",
      "14 Train Loss 8.976698 Test MSE 5.205743418155938 Test RE 1.090559686648587\n",
      "15 Train Loss 8.6750765 Test MSE 5.129504979689396 Test RE 1.0825445754979537\n",
      "16 Train Loss 8.179226 Test MSE 4.94393291919547 Test RE 1.0627823786375485\n",
      "17 Train Loss 7.6856127 Test MSE 4.729270724735355 Test RE 1.039453696763664\n",
      "18 Train Loss 7.0986567 Test MSE 4.387578283525146 Test RE 1.0011992126630822\n",
      "19 Train Loss 6.7247076 Test MSE 4.307473738914611 Test RE 0.9920176049483244\n",
      "20 Train Loss 6.2708845 Test MSE 4.308517113508266 Test RE 0.9921377430336007\n",
      "21 Train Loss 5.8876934 Test MSE 4.252433540412079 Test RE 0.9856593085626014\n",
      "22 Train Loss 5.5876493 Test MSE 4.2336509695884565 Test RE 0.9834801206200666\n",
      "23 Train Loss 5.249875 Test MSE 4.023901113593425 Test RE 0.9588081347404799\n",
      "24 Train Loss 4.7958746 Test MSE 3.9377391381798112 Test RE 0.94848732450134\n",
      "25 Train Loss 4.2546597 Test MSE 3.7249265401962672 Test RE 0.9225011505203217\n",
      "26 Train Loss 3.5741549 Test MSE 3.351111396948001 Test RE 0.8749887973071009\n",
      "27 Train Loss 2.9306788 Test MSE 3.212472782162549 Test RE 0.8566980703125334\n",
      "28 Train Loss 2.5843396 Test MSE 3.166687283520408 Test RE 0.8505711524582069\n",
      "29 Train Loss 2.386949 Test MSE 3.1950744318935826 Test RE 0.8543750359971505\n",
      "30 Train Loss 2.1463597 Test MSE 2.962192087256313 Test RE 0.8226491797769941\n",
      "31 Train Loss 1.9835364 Test MSE 2.95813174750024 Test RE 0.8220851750653569\n",
      "32 Train Loss 1.8674234 Test MSE 2.879122973706431 Test RE 0.8110323318967875\n",
      "33 Train Loss 1.710723 Test MSE 2.717922487024396 Test RE 0.7880006826116223\n",
      "34 Train Loss 1.539174 Test MSE 2.599186215641894 Test RE 0.7705960132969641\n",
      "35 Train Loss 1.3833884 Test MSE 2.6127695887585336 Test RE 0.7726069606429473\n",
      "36 Train Loss 1.3403971 Test MSE 2.6126023878933147 Test RE 0.7725822392477654\n",
      "37 Train Loss 1.2732637 Test MSE 2.57153326429667 Test RE 0.7664858354323589\n",
      "38 Train Loss 1.2111355 Test MSE 2.5623449585877167 Test RE 0.7651152506948605\n",
      "39 Train Loss 1.1623617 Test MSE 2.5712986119036065 Test RE 0.7664508637208859\n",
      "40 Train Loss 1.1180868 Test MSE 2.570595530041943 Test RE 0.7663460694858589\n",
      "41 Train Loss 1.0804901 Test MSE 2.5830733996075215 Test RE 0.7682037694132817\n",
      "42 Train Loss 1.0540789 Test MSE 2.5715751065144756 Test RE 0.7664920712717423\n",
      "43 Train Loss 1.0314946 Test MSE 2.5957596643991634 Test RE 0.7700879008856987\n",
      "44 Train Loss 1.0083406 Test MSE 2.5869964004020654 Test RE 0.7687868965958062\n",
      "45 Train Loss 0.99098986 Test MSE 2.582011771535471 Test RE 0.7680458895597239\n",
      "46 Train Loss 0.96894217 Test MSE 2.58946132151874 Test RE 0.7691530640701452\n",
      "47 Train Loss 0.95643985 Test MSE 2.6017779294378043 Test RE 0.7709801078837836\n",
      "48 Train Loss 0.9389622 Test MSE 2.600778817154143 Test RE 0.7708320611092478\n",
      "49 Train Loss 0.93004686 Test MSE 2.599492828519567 Test RE 0.7706414636175521\n",
      "50 Train Loss 0.917604 Test MSE 2.6258557385616292 Test RE 0.7745393588221726\n",
      "51 Train Loss 0.90331143 Test MSE 2.6519814232489267 Test RE 0.7783829224975907\n",
      "52 Train Loss 0.89154255 Test MSE 2.6609410677571703 Test RE 0.7796966861896201\n",
      "53 Train Loss 0.8707211 Test MSE 2.644028996264123 Test RE 0.777214988071966\n",
      "54 Train Loss 0.8543767 Test MSE 2.6663910983255046 Test RE 0.7804947491763956\n",
      "55 Train Loss 0.83996785 Test MSE 2.66470575918359 Test RE 0.7802480475067637\n",
      "56 Train Loss 0.8308044 Test MSE 2.659088470349019 Test RE 0.7794252191547371\n",
      "57 Train Loss 0.8176225 Test MSE 2.652635874164081 Test RE 0.7784789604990947\n",
      "58 Train Loss 0.8075379 Test MSE 2.6727180904845778 Test RE 0.7814202057266102\n",
      "59 Train Loss 0.8001179 Test MSE 2.669192916465942 Test RE 0.7809047096997244\n",
      "60 Train Loss 0.78436315 Test MSE 2.653403605570626 Test RE 0.778591606851198\n",
      "61 Train Loss 0.7682507 Test MSE 2.6663397619438864 Test RE 0.7804872356557462\n",
      "62 Train Loss 0.7543468 Test MSE 2.660265055831041 Test RE 0.7795976389492096\n",
      "63 Train Loss 0.74153584 Test MSE 2.675386042237607 Test RE 0.7818101217836507\n",
      "64 Train Loss 0.729944 Test MSE 2.686716934789064 Test RE 0.7834639479198554\n",
      "65 Train Loss 0.71556 Test MSE 2.7104495486875555 Test RE 0.7869166314934751\n",
      "66 Train Loss 0.7070694 Test MSE 2.71398248303686 Test RE 0.7874293175625812\n",
      "67 Train Loss 0.6962435 Test MSE 2.7321039286817457 Test RE 0.7900538034408259\n",
      "68 Train Loss 0.6861168 Test MSE 2.729295677832677 Test RE 0.7896476622869772\n",
      "69 Train Loss 0.6746299 Test MSE 2.729836913967549 Test RE 0.7897259544020283\n",
      "70 Train Loss 0.6686852 Test MSE 2.7467867230939085 Test RE 0.79217390103774\n",
      "71 Train Loss 0.6616878 Test MSE 2.743380903811845 Test RE 0.791682629186294\n",
      "72 Train Loss 0.655673 Test MSE 2.770937373255713 Test RE 0.7956488060626868\n",
      "73 Train Loss 0.6499402 Test MSE 2.77228261138704 Test RE 0.7958419189146348\n",
      "74 Train Loss 0.6420082 Test MSE 2.7658445393112894 Test RE 0.7949172899179513\n",
      "75 Train Loss 0.63513374 Test MSE 2.766163455207084 Test RE 0.7949631175934798\n",
      "76 Train Loss 0.6301561 Test MSE 2.7730617909793347 Test RE 0.7959537509864788\n",
      "77 Train Loss 0.62220067 Test MSE 2.7793652790776346 Test RE 0.7968578846469865\n",
      "78 Train Loss 0.6172929 Test MSE 2.798444767571788 Test RE 0.7995882990423155\n",
      "79 Train Loss 0.6140808 Test MSE 2.7990951169501446 Test RE 0.7996812044929618\n",
      "80 Train Loss 0.61035967 Test MSE 2.799017472732299 Test RE 0.7996701132206676\n",
      "81 Train Loss 0.60487753 Test MSE 2.8155579241809043 Test RE 0.8020294092310871\n",
      "82 Train Loss 0.5990867 Test MSE 2.8189322576451135 Test RE 0.8025098653930233\n",
      "83 Train Loss 0.59420663 Test MSE 2.8224890955252366 Test RE 0.8030159963317096\n",
      "84 Train Loss 0.58979434 Test MSE 2.818937647202987 Test RE 0.8025106325578397\n",
      "85 Train Loss 0.5859428 Test MSE 2.822815871455607 Test RE 0.8030624798956468\n",
      "86 Train Loss 0.58192396 Test MSE 2.823573066210784 Test RE 0.8031701797870641\n",
      "87 Train Loss 0.57772696 Test MSE 2.851086469319248 Test RE 0.8070738106661001\n",
      "88 Train Loss 0.5729317 Test MSE 2.8527062815539663 Test RE 0.8073030429985105\n",
      "89 Train Loss 0.5696868 Test MSE 2.8615150311260256 Test RE 0.8085485005394337\n",
      "90 Train Loss 0.5661688 Test MSE 2.877762786200026 Test RE 0.8108407307777437\n",
      "91 Train Loss 0.5631141 Test MSE 2.883032364031347 Test RE 0.8115827714584009\n",
      "92 Train Loss 0.55956286 Test MSE 2.8765867361589774 Test RE 0.8106750314496762\n",
      "93 Train Loss 0.55302674 Test MSE 2.8930163015037142 Test RE 0.8129868120227359\n",
      "94 Train Loss 0.54813933 Test MSE 2.9004198769110263 Test RE 0.8140264126711849\n",
      "95 Train Loss 0.5427227 Test MSE 2.9055409875409253 Test RE 0.814744736395909\n",
      "96 Train Loss 0.53940123 Test MSE 2.92984143860556 Test RE 0.818144695375737\n",
      "97 Train Loss 0.534566 Test MSE 2.933694754159744 Test RE 0.8186825288840817\n",
      "98 Train Loss 0.53086233 Test MSE 2.946021181155416 Test RE 0.8204006443080105\n",
      "99 Train Loss 0.52812165 Test MSE 2.9634181297431486 Test RE 0.8228194081878506\n",
      "Training time: 67.15\n",
      "0\n",
      "KG_rowdy_tune20\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.454727 Test MSE 8.779532445107593 Test RE 1.4162624946200815\n",
      "1 Train Loss 51.817184 Test MSE 7.85176664048785 Test RE 1.3393428145751831\n",
      "2 Train Loss 37.276196 Test MSE 7.389499099106358 Test RE 1.2993183158909494\n",
      "3 Train Loss 30.265488 Test MSE 6.463567420150404 Test RE 1.215190041674354\n",
      "4 Train Loss 26.866234 Test MSE 6.333556063360714 Test RE 1.2029064951214254\n",
      "5 Train Loss 24.27737 Test MSE 6.090488699331894 Test RE 1.1795982813901966\n",
      "6 Train Loss 22.63396 Test MSE 5.725369381470377 Test RE 1.1436939291775172\n",
      "7 Train Loss 19.478281 Test MSE 5.585057776621264 Test RE 1.1295927475674812\n",
      "8 Train Loss 15.469188 Test MSE 5.553267644168364 Test RE 1.1263733405159992\n",
      "9 Train Loss 12.640139 Test MSE 5.6856291912701975 Test RE 1.1397177876285265\n",
      "10 Train Loss 10.418579 Test MSE 5.7100226405872405 Test RE 1.1421600759942618\n",
      "11 Train Loss 8.354216 Test MSE 5.596599730057175 Test RE 1.1307593405114658\n",
      "12 Train Loss 7.2673993 Test MSE 5.559936119916567 Test RE 1.1270494235215875\n",
      "13 Train Loss 6.5267735 Test MSE 5.207742660283131 Test RE 1.0907690787949087\n",
      "14 Train Loss 5.8769636 Test MSE 4.936357987352939 Test RE 1.061967886384373\n",
      "15 Train Loss 5.2217684 Test MSE 4.472789455964403 Test RE 1.0108746087024787\n",
      "16 Train Loss 4.3815074 Test MSE 4.178854316226115 Test RE 0.9770947409378169\n",
      "17 Train Loss 3.60879 Test MSE 3.5147226726949343 Test RE 0.8960940460753207\n",
      "18 Train Loss 2.7609415 Test MSE 2.61538455261473 Test RE 0.7729934918605534\n",
      "19 Train Loss 2.1771843 Test MSE 2.4555454292287116 Test RE 0.7490003953213525\n",
      "20 Train Loss 1.723423 Test MSE 1.6977897195812803 Test RE 0.6228020164860907\n",
      "21 Train Loss 1.3093596 Test MSE 1.082171211759039 Test RE 0.49722854017510404\n",
      "22 Train Loss 0.9964456 Test MSE 0.9956623337563667 Test RE 0.4769403864309439\n",
      "23 Train Loss 0.6884389 Test MSE 0.4826900852497549 Test RE 0.33207963987423167\n",
      "24 Train Loss 0.45913965 Test MSE 0.3320648982988852 Test RE 0.2754352658979194\n",
      "25 Train Loss 0.29963756 Test MSE 0.22136173049317578 Test RE 0.22488440050807687\n",
      "26 Train Loss 0.18882419 Test MSE 0.08690804909387452 Test RE 0.14090878195582382\n",
      "27 Train Loss 0.14619955 Test MSE 0.07916588724881228 Test RE 0.1344860078663849\n",
      "28 Train Loss 0.11349367 Test MSE 0.051170329818806155 Test RE 0.10812277125081587\n",
      "29 Train Loss 0.08744314 Test MSE 0.026382244309658444 Test RE 0.07763613904188628\n",
      "30 Train Loss 0.071983896 Test MSE 0.019874800336857526 Test RE 0.06738441268897284\n",
      "31 Train Loss 0.057201296 Test MSE 0.0142189299489119 Test RE 0.056995624633160345\n",
      "32 Train Loss 0.047674358 Test MSE 0.01146930367470512 Test RE 0.05118899300735\n",
      "33 Train Loss 0.039616473 Test MSE 0.01100742405963632 Test RE 0.05014768731478322\n",
      "34 Train Loss 0.033404432 Test MSE 0.01037960782840571 Test RE 0.04869658799536267\n",
      "35 Train Loss 0.028544642 Test MSE 0.008285988411746723 Test RE 0.04350911214333042\n",
      "36 Train Loss 0.023433613 Test MSE 0.007764940079532369 Test RE 0.042118909140159054\n",
      "37 Train Loss 0.01973376 Test MSE 0.006259368511423349 Test RE 0.037815802460823146\n",
      "38 Train Loss 0.016600646 Test MSE 0.004625712878607295 Test RE 0.03250853485095163\n",
      "39 Train Loss 0.013579705 Test MSE 0.004133240120804629 Test RE 0.030729350317815127\n",
      "40 Train Loss 0.012042195 Test MSE 0.0038877865150605444 Test RE 0.02980295072907294\n",
      "41 Train Loss 0.010242851 Test MSE 0.0038419189206159226 Test RE 0.029626623466276057\n",
      "42 Train Loss 0.008512048 Test MSE 0.002808540715919789 Test RE 0.025330771798650488\n",
      "43 Train Loss 0.007246016 Test MSE 0.0021197280019726004 Test RE 0.022006355717928645\n",
      "44 Train Loss 0.005851569 Test MSE 0.001839649387223609 Test RE 0.020501025713101348\n",
      "45 Train Loss 0.0052121575 Test MSE 0.0016855385864165324 Test RE 0.01962354248147835\n",
      "46 Train Loss 0.0046502915 Test MSE 0.0015210826521096475 Test RE 0.018641655028084837\n",
      "47 Train Loss 0.004271321 Test MSE 0.001338008397146813 Test RE 0.017483866421814646\n",
      "48 Train Loss 0.0038180328 Test MSE 0.001322645812743536 Test RE 0.017383204565136468\n",
      "49 Train Loss 0.0035365582 Test MSE 0.001170235320209864 Test RE 0.016351012902415276\n",
      "50 Train Loss 0.003265463 Test MSE 0.0012460912512034887 Test RE 0.01687263779863234\n",
      "51 Train Loss 0.0029210781 Test MSE 0.0013139339307555971 Test RE 0.01732586093488106\n",
      "52 Train Loss 0.0027938592 Test MSE 0.0012691699475609966 Test RE 0.017028168940528512\n",
      "53 Train Loss 0.0025548842 Test MSE 0.001237194653492473 Test RE 0.01681229793137218\n",
      "54 Train Loss 0.0023972953 Test MSE 0.0011428396870653268 Test RE 0.016158487889202315\n",
      "55 Train Loss 0.0022147063 Test MSE 0.0010964859895289487 Test RE 0.015827400926402387\n",
      "56 Train Loss 0.0020626688 Test MSE 0.0010357938356976792 Test RE 0.0153831303938549\n",
      "57 Train Loss 0.0018568824 Test MSE 0.0009581701236852807 Test RE 0.014795490684073319\n",
      "58 Train Loss 0.0016109583 Test MSE 0.0009268327511275187 Test RE 0.014551532922443398\n",
      "59 Train Loss 0.001524444 Test MSE 0.0009276643809786997 Test RE 0.014558059869053095\n",
      "60 Train Loss 0.0014127287 Test MSE 0.0009563900459517547 Test RE 0.014781740846517882\n",
      "61 Train Loss 0.0012819187 Test MSE 0.0009930641269213 Test RE 0.015062487767481824\n",
      "62 Train Loss 0.0011995976 Test MSE 0.0009580903661227967 Test RE 0.014794874886940165\n",
      "63 Train Loss 0.0011095804 Test MSE 0.0008833421678188494 Test RE 0.014206023921130042\n",
      "64 Train Loss 0.0010600784 Test MSE 0.0007989484811317768 Test RE 0.013510376379596978\n",
      "65 Train Loss 0.0009893673 Test MSE 0.0007671067741459374 Test RE 0.013238414327528768\n",
      "66 Train Loss 0.0009419863 Test MSE 0.0007557980852072688 Test RE 0.013140471660004167\n",
      "67 Train Loss 0.00090521923 Test MSE 0.0007279422341712442 Test RE 0.012896044376412622\n",
      "68 Train Loss 0.0008549724 Test MSE 0.0006631149666974124 Test RE 0.012308424764610004\n",
      "69 Train Loss 0.0008280581 Test MSE 0.000716151602481993 Test RE 0.012791178051675097\n",
      "70 Train Loss 0.0007919622 Test MSE 0.000680369250592521 Test RE 0.012467529341196455\n",
      "71 Train Loss 0.0007539212 Test MSE 0.0007003488247543689 Test RE 0.012649264164485148\n",
      "72 Train Loss 0.00073926355 Test MSE 0.000699947353024204 Test RE 0.012645638078612123\n",
      "73 Train Loss 0.0006946405 Test MSE 0.0006543029078135009 Test RE 0.0122263686203391\n",
      "74 Train Loss 0.000645674 Test MSE 0.0005960541841262297 Test RE 0.011669464596368202\n",
      "75 Train Loss 0.000635279 Test MSE 0.0005845401518767472 Test RE 0.011556204919030918\n",
      "76 Train Loss 0.0006207399 Test MSE 0.0005700393065494267 Test RE 0.011411965809353036\n",
      "77 Train Loss 0.0005824665 Test MSE 0.0005196624776730087 Test RE 0.010896041284753742\n",
      "78 Train Loss 0.0005674194 Test MSE 0.0005240179972753614 Test RE 0.010941608260026608\n",
      "79 Train Loss 0.0005607141 Test MSE 0.0005070275346295655 Test RE 0.010762764378005794\n",
      "80 Train Loss 0.0005247313 Test MSE 0.0005055006575972374 Test RE 0.010746546512812802\n",
      "81 Train Loss 0.0005017556 Test MSE 0.000488099186582901 Test RE 0.010559955844354195\n",
      "82 Train Loss 0.0004963943 Test MSE 0.00046816855703013353 Test RE 0.01034211068611797\n",
      "83 Train Loss 0.00048638016 Test MSE 0.0004442555230725946 Test RE 0.01007452266272786\n",
      "84 Train Loss 0.00046405007 Test MSE 0.000409427031379552 Test RE 0.009671555236407055\n",
      "85 Train Loss 0.00043963818 Test MSE 0.00038742965506260253 Test RE 0.009408155572026775\n",
      "86 Train Loss 0.00042886252 Test MSE 0.00036302546669969777 Test RE 0.009107026629646065\n",
      "87 Train Loss 0.00042414124 Test MSE 0.00035257069387493485 Test RE 0.008974931973025341\n",
      "88 Train Loss 0.00041552656 Test MSE 0.00033310281149928666 Test RE 0.008723629439497279\n",
      "89 Train Loss 0.00040838512 Test MSE 0.00032749192857404346 Test RE 0.008649845705447306\n",
      "90 Train Loss 0.00039454526 Test MSE 0.00032945063335858624 Test RE 0.0086756741842886\n",
      "91 Train Loss 0.00037674844 Test MSE 0.00031515010068239275 Test RE 0.008485291869476084\n",
      "92 Train Loss 0.00036971833 Test MSE 0.0003106959344545851 Test RE 0.008425115153910631\n",
      "93 Train Loss 0.00036522842 Test MSE 0.0003030297988554529 Test RE 0.008320524985254847\n",
      "94 Train Loss 0.00036077228 Test MSE 0.00030647518651537607 Test RE 0.008367692637501329\n",
      "95 Train Loss 0.0003483868 Test MSE 0.00028991952607522134 Test RE 0.008138545452885533\n",
      "96 Train Loss 0.00033138058 Test MSE 0.00026656216652348096 Test RE 0.007803821284476341\n",
      "97 Train Loss 0.0003223591 Test MSE 0.00028421076944767074 Test RE 0.00805801971248447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 Train Loss 0.0003134119 Test MSE 0.00029500322014016115 Test RE 0.008209589438071633\n",
      "99 Train Loss 0.00030774222 Test MSE 0.00028752814857597986 Test RE 0.00810491088800854\n",
      "Training time: 68.26\n",
      "1\n",
      "KG_rowdy_tune20\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.86197 Test MSE 8.392457545114418 Test RE 1.3846902580914011\n",
      "1 Train Loss 57.34522 Test MSE 8.579294374440554 Test RE 1.4000187275517686\n",
      "2 Train Loss 54.103973 Test MSE 9.32336508904205 Test RE 1.459467423808895\n",
      "3 Train Loss 48.527695 Test MSE 8.306616870767229 Test RE 1.3775905348816146\n",
      "4 Train Loss 45.537785 Test MSE 8.611538837692148 Test RE 1.402647178895473\n",
      "5 Train Loss 44.630203 Test MSE 8.633244818641389 Test RE 1.404413801124639\n",
      "6 Train Loss 44.097076 Test MSE 8.415689160655244 Test RE 1.3866054516089577\n",
      "7 Train Loss 42.586906 Test MSE 8.175775099935445 Test RE 1.3666979042296712\n",
      "8 Train Loss 41.329323 Test MSE 8.180715795835217 Test RE 1.367110795901536\n",
      "9 Train Loss 39.82878 Test MSE 7.801648311318489 Test RE 1.3350614160596925\n",
      "10 Train Loss 39.657722 Test MSE 7.899446815863025 Test RE 1.3434032667118998\n",
      "11 Train Loss 39.425716 Test MSE 7.913681530911928 Test RE 1.34461312077224\n",
      "12 Train Loss 39.087494 Test MSE 7.8696239103913035 Test RE 1.3408649830284627\n",
      "13 Train Loss 38.847847 Test MSE 7.848321378709096 Test RE 1.3390489384887827\n",
      "14 Train Loss 38.65085 Test MSE 7.869652046311557 Test RE 1.3408673799941209\n",
      "15 Train Loss 38.522297 Test MSE 7.901720872547448 Test RE 1.3435966191970996\n",
      "16 Train Loss 38.36606 Test MSE 7.920906555612066 Test RE 1.3452267824805764\n",
      "17 Train Loss 38.199818 Test MSE 7.812696250176646 Test RE 1.3360063739862826\n",
      "18 Train Loss 38.000492 Test MSE 7.921396884287591 Test RE 1.3452684186906703\n",
      "19 Train Loss 37.662148 Test MSE 7.695170514127685 Test RE 1.3259195804930426\n",
      "20 Train Loss 37.159836 Test MSE 7.925521522991217 Test RE 1.34561861097072\n",
      "21 Train Loss 36.61898 Test MSE 7.693990002999393 Test RE 1.3258178723597909\n",
      "22 Train Loss 35.39959 Test MSE 7.333704460846443 Test RE 1.2944037501377867\n",
      "23 Train Loss 33.8189 Test MSE 7.292927400847949 Test RE 1.2908001447364417\n",
      "24 Train Loss 32.82159 Test MSE 7.260097187284306 Test RE 1.287891501771307\n",
      "25 Train Loss 32.43783 Test MSE 7.240458944538591 Test RE 1.286148477411834\n",
      "26 Train Loss 31.496246 Test MSE 7.194640775104155 Test RE 1.282072596850197\n",
      "27 Train Loss 30.60975 Test MSE 7.132346756084068 Test RE 1.2765101868336872\n",
      "28 Train Loss 29.477531 Test MSE 6.928615993201269 Test RE 1.2581467678796723\n",
      "29 Train Loss 28.37252 Test MSE 7.337905969513765 Test RE 1.2947744815941775\n",
      "30 Train Loss 27.0733 Test MSE 6.826890375749188 Test RE 1.2488765898447827\n",
      "31 Train Loss 25.730911 Test MSE 6.824613617520192 Test RE 1.2486683231960896\n",
      "32 Train Loss 24.463284 Test MSE 6.76730349349394 Test RE 1.2434143843040655\n",
      "33 Train Loss 22.930458 Test MSE 6.771966557498434 Test RE 1.2438427027914363\n",
      "34 Train Loss 20.778202 Test MSE 6.13035925980339 Test RE 1.1834530233429068\n",
      "35 Train Loss 18.500872 Test MSE 5.858882610647774 Test RE 1.1569523126472454\n",
      "36 Train Loss 17.303627 Test MSE 5.747502296967885 Test RE 1.1459024211363795\n",
      "37 Train Loss 16.200562 Test MSE 5.872544248623362 Test RE 1.1583004076227958\n",
      "38 Train Loss 15.175159 Test MSE 5.998282128936226 Test RE 1.1706350002757855\n",
      "39 Train Loss 13.594072 Test MSE 6.058841325043238 Test RE 1.1765295777428286\n",
      "40 Train Loss 12.1714115 Test MSE 5.831569967596649 Test RE 1.1542524515229653\n",
      "41 Train Loss 10.451391 Test MSE 5.900959684159174 Test RE 1.1610993556168534\n",
      "42 Train Loss 8.916936 Test MSE 6.113937417215871 Test RE 1.1818668592179857\n",
      "43 Train Loss 7.8610973 Test MSE 6.073501977638228 Test RE 1.1779521492271754\n",
      "44 Train Loss 6.8470325 Test MSE 5.832005523508971 Test RE 1.1542955558752548\n",
      "45 Train Loss 6.490689 Test MSE 5.858506599948918 Test RE 1.1569151866748948\n",
      "46 Train Loss 6.147012 Test MSE 5.569908577063738 Test RE 1.1280597244047492\n",
      "47 Train Loss 5.7951612 Test MSE 5.473692050712875 Test RE 1.1182740331204069\n",
      "48 Train Loss 5.536267 Test MSE 5.432806388136097 Test RE 1.1140897390907885\n",
      "49 Train Loss 4.8765993 Test MSE 4.8120513809004075 Test RE 1.048511476067259\n",
      "50 Train Loss 4.0654044 Test MSE 4.010007442311567 Test RE 0.9571514235636952\n",
      "51 Train Loss 3.4209833 Test MSE 3.8532197103219223 Test RE 0.9382529679084596\n",
      "52 Train Loss 2.8678713 Test MSE 3.514737190401998 Test RE 0.8960958967501305\n",
      "53 Train Loss 2.529653 Test MSE 3.3797337203045177 Test RE 0.8787175547162673\n",
      "54 Train Loss 2.0800989 Test MSE 2.988229742970649 Test RE 0.8262568107340375\n",
      "55 Train Loss 1.7184918 Test MSE 2.7802264754628996 Test RE 0.7969813297342296\n",
      "56 Train Loss 1.5209578 Test MSE 2.7420808613769188 Test RE 0.7914950243638881\n",
      "57 Train Loss 1.4270461 Test MSE 2.6733117592584916 Test RE 0.7815069861130498\n",
      "58 Train Loss 1.3340621 Test MSE 2.633468783017035 Test RE 0.7756613425472791\n",
      "59 Train Loss 1.2614868 Test MSE 2.60876772480036 Test RE 0.7720150499000455\n",
      "60 Train Loss 1.199832 Test MSE 2.6025889282516204 Test RE 0.7711002594209911\n",
      "61 Train Loss 1.1429212 Test MSE 2.593397694749411 Test RE 0.7697374566134412\n",
      "62 Train Loss 1.0995439 Test MSE 2.613079040209627 Test RE 0.7726527123363556\n",
      "63 Train Loss 1.0702506 Test MSE 2.5952939568123035 Test RE 0.7700188167038805\n",
      "64 Train Loss 1.0476522 Test MSE 2.612648099546947 Test RE 0.7725889979986211\n",
      "65 Train Loss 1.0181752 Test MSE 2.6297451903336304 Test RE 0.775112775463437\n",
      "66 Train Loss 0.9865918 Test MSE 2.65431107299842 Test RE 0.7787247351324863\n",
      "67 Train Loss 0.9586142 Test MSE 2.6720084516488556 Test RE 0.7813164606028342\n",
      "68 Train Loss 0.9372312 Test MSE 2.6546983206801458 Test RE 0.7787815386385519\n",
      "69 Train Loss 0.89915466 Test MSE 2.6902873274519243 Test RE 0.7839843498244867\n",
      "70 Train Loss 0.8639158 Test MSE 2.7050585808720453 Test RE 0.7861336702784751\n",
      "71 Train Loss 0.8410909 Test MSE 2.7397873280767024 Test RE 0.7911639436921604\n",
      "72 Train Loss 0.81443834 Test MSE 2.7521102516723968 Test RE 0.792941182864009\n",
      "73 Train Loss 0.7932836 Test MSE 2.780687189434056 Test RE 0.797047361265547\n",
      "74 Train Loss 0.77476335 Test MSE 2.8146024211702514 Test RE 0.8018933071574874\n",
      "75 Train Loss 0.7510898 Test MSE 2.8197850897408445 Test RE 0.8026312507884554\n",
      "76 Train Loss 0.7367446 Test MSE 2.813152071444914 Test RE 0.8016866748472006\n",
      "77 Train Loss 0.72504413 Test MSE 2.8119699488883425 Test RE 0.8015182176403804\n",
      "78 Train Loss 0.7069761 Test MSE 2.818599354539663 Test RE 0.8024624776075203\n",
      "79 Train Loss 0.68366414 Test MSE 2.830896066014826 Test RE 0.8042110252590218\n",
      "80 Train Loss 0.6581281 Test MSE 2.8638846667601046 Test RE 0.8088832128905542\n",
      "81 Train Loss 0.63536334 Test MSE 2.9323361404763655 Test RE 0.8184929382510352\n",
      "82 Train Loss 0.61355245 Test MSE 2.9606963568411353 Test RE 0.8224414591549675\n",
      "83 Train Loss 0.60053366 Test MSE 2.9880224140095266 Test RE 0.8262281466164114\n",
      "84 Train Loss 0.5822881 Test MSE 3.0074018051106335 Test RE 0.8289031466887358\n",
      "85 Train Loss 0.5717762 Test MSE 3.003073086644614 Test RE 0.8283063889800263\n",
      "86 Train Loss 0.5549872 Test MSE 3.0172607641290465 Test RE 0.8302607031629465\n",
      "87 Train Loss 0.53821474 Test MSE 3.0346559134539075 Test RE 0.8326505782505713\n",
      "88 Train Loss 0.52280104 Test MSE 3.0650305179894515 Test RE 0.836807303180182\n",
      "89 Train Loss 0.51559204 Test MSE 3.052240781155444 Test RE 0.8350595663540165\n",
      "90 Train Loss 0.50568914 Test MSE 3.084602960363274 Test RE 0.8394748620910638\n",
      "91 Train Loss 0.49443015 Test MSE 3.0970893095488568 Test RE 0.8411722264124505\n",
      "92 Train Loss 0.4862111 Test MSE 3.108507479948083 Test RE 0.8427213925282027\n",
      "93 Train Loss 0.47754318 Test MSE 3.135795474115911 Test RE 0.8464122198767591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 0.4684974 Test MSE 3.166189805950158 Test RE 0.8505043386789807\n",
      "95 Train Loss 0.46217912 Test MSE 3.1817463884156796 Test RE 0.8525911890340933\n",
      "96 Train Loss 0.45671427 Test MSE 3.178840227182941 Test RE 0.8522017278379133\n",
      "97 Train Loss 0.44833234 Test MSE 3.182511282002062 Test RE 0.8526936645716764\n",
      "98 Train Loss 0.4432927 Test MSE 3.1968524570529726 Test RE 0.8546127282731678\n",
      "99 Train Loss 0.43837392 Test MSE 3.2127385727067574 Test RE 0.8567335099181135\n",
      "Training time: 70.28\n",
      "2\n",
      "KG_rowdy_tune20\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.54642 Test MSE 8.62053033166088 Test RE 1.4033792549806392\n",
      "1 Train Loss 55.651344 Test MSE 8.078842960079415 Test RE 1.358571949310188\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.04\n",
      "0\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 54.69676 Test MSE 7.548569559103913 Test RE 1.3132287771116034\n",
      "1 Train Loss 38.19539 Test MSE 7.3735646235501315 Test RE 1.2979166559779405\n",
      "2 Train Loss 25.702808 Test MSE 6.423077416955046 Test RE 1.2113778785171951\n",
      "3 Train Loss 22.555779 Test MSE 6.018585975697487 Test RE 1.1726145932200986\n",
      "4 Train Loss 19.047636 Test MSE 5.742356947767555 Test RE 1.1453893819082017\n",
      "5 Train Loss 14.883959 Test MSE 5.799215113586914 Test RE 1.1510459724359403\n",
      "6 Train Loss 12.6072 Test MSE 5.811126634701447 Test RE 1.1522274836359843\n",
      "7 Train Loss 10.673977 Test MSE 5.857164867342865 Test RE 1.1567826990102898\n",
      "8 Train Loss 9.446386 Test MSE 5.87171040170994 Test RE 1.1582181707364887\n",
      "9 Train Loss 8.391176 Test MSE 5.6934065914949725 Test RE 1.1404970340284928\n",
      "10 Train Loss 7.508401 Test MSE 5.534218008890965 Test RE 1.124439755141719\n",
      "11 Train Loss 6.6310067 Test MSE 5.3108933135015235 Test RE 1.1015186354524151\n",
      "12 Train Loss 6.1159773 Test MSE 5.255148916352165 Test RE 1.095722485327077\n",
      "13 Train Loss 5.47707 Test MSE 4.554031319656454 Test RE 1.0200138454477976\n",
      "14 Train Loss 5.0107465 Test MSE 3.9856935310702597 Test RE 0.954245259558207\n",
      "15 Train Loss 4.3221965 Test MSE 3.1793066634622664 Test RE 0.8522642480016303\n",
      "16 Train Loss 3.6865444 Test MSE 2.7434531531207167 Test RE 0.7916930539410437\n",
      "17 Train Loss 2.883141 Test MSE 2.5204946688017578 Test RE 0.7588412868916136\n",
      "18 Train Loss 2.4407914 Test MSE 2.342642554960584 Test RE 0.7315787368847262\n",
      "19 Train Loss 2.02705 Test MSE 2.09252376025236 Test RE 0.6914221039265515\n",
      "20 Train Loss 1.6339489 Test MSE 1.8229782327531732 Test RE 0.6453551821862844\n",
      "21 Train Loss 1.3329581 Test MSE 1.5660731457483932 Test RE 0.5981554740521916\n",
      "22 Train Loss 1.0980158 Test MSE 1.4172314505648091 Test RE 0.5690212049911502\n",
      "23 Train Loss 0.98672765 Test MSE 1.2546159304298237 Test RE 0.5353816219984626\n",
      "24 Train Loss 0.8323938 Test MSE 0.9366710549504148 Test RE 0.46259571989859455\n",
      "25 Train Loss 0.64354044 Test MSE 0.651999764103119 Test RE 0.38595065257332506\n",
      "26 Train Loss 0.47267327 Test MSE 0.5217026950599037 Test RE 0.34523880159555015\n",
      "27 Train Loss 0.33183733 Test MSE 0.44742093594161886 Test RE 0.3197173548784737\n",
      "28 Train Loss 0.26600483 Test MSE 0.39391704237835407 Test RE 0.29999253336162335\n",
      "29 Train Loss 0.22879164 Test MSE 0.35190519125832315 Test RE 0.2835442842137292\n",
      "30 Train Loss 0.20836873 Test MSE 0.32119619168375296 Test RE 0.27089017512389807\n",
      "31 Train Loss 0.18408664 Test MSE 0.26541622857704134 Test RE 0.24624748134985938\n",
      "32 Train Loss 0.16541402 Test MSE 0.17722144239639367 Test RE 0.20121770612402884\n",
      "33 Train Loss 0.1437853 Test MSE 0.06809065141409247 Test RE 0.12472450953399919\n",
      "34 Train Loss 0.09200972 Test MSE 0.02026005973945851 Test RE 0.06803437838355796\n",
      "35 Train Loss 0.06610373 Test MSE 0.020128044315062356 Test RE 0.06781235864576463\n",
      "36 Train Loss 0.056742962 Test MSE 0.01826968377232928 Test RE 0.06460610745647387\n",
      "37 Train Loss 0.045077056 Test MSE 0.016331306297214732 Test RE 0.061082741732074536\n",
      "38 Train Loss 0.037741933 Test MSE 0.014423620023657224 Test RE 0.057404401941645866\n",
      "39 Train Loss 0.030571427 Test MSE 0.010720429388645907 Test RE 0.04948962358391068\n",
      "40 Train Loss 0.026228014 Test MSE 0.008138463121584394 Test RE 0.04312005044178501\n",
      "41 Train Loss 0.02268473 Test MSE 0.0062563296632332675 Test RE 0.037806621787590346\n",
      "42 Train Loss 0.018987723 Test MSE 0.004420394223158282 Test RE 0.03177887813764381\n",
      "43 Train Loss 0.017531851 Test MSE 0.0040866081711369495 Test RE 0.030555511611197385\n",
      "44 Train Loss 0.015415063 Test MSE 0.0029198727364127416 Test RE 0.02582795504247872\n",
      "45 Train Loss 0.014264402 Test MSE 0.0026440815927727904 Test RE 0.024577940394724936\n",
      "46 Train Loss 0.01253885 Test MSE 0.0023695452084130457 Test RE 0.023267009104057903\n",
      "47 Train Loss 0.01080167 Test MSE 0.002343067052919527 Test RE 0.023136646913366907\n",
      "48 Train Loss 0.010042234 Test MSE 0.0025294847632849255 Test RE 0.02403942602906846\n",
      "49 Train Loss 0.009030083 Test MSE 0.002349028209642334 Test RE 0.02316605997814974\n",
      "50 Train Loss 0.0075781844 Test MSE 0.002289853937277316 Test RE 0.022872411230339024\n",
      "51 Train Loss 0.00717662 Test MSE 0.001966098713467672 Test RE 0.021193892139584943\n",
      "52 Train Loss 0.0063996906 Test MSE 0.0017998982410103242 Test RE 0.020278323008660275\n",
      "53 Train Loss 0.0058770813 Test MSE 0.0013439965681895842 Test RE 0.01752294670851183\n",
      "54 Train Loss 0.0051765526 Test MSE 0.0010623446391076112 Test RE 0.015579042985342375\n",
      "55 Train Loss 0.004881407 Test MSE 0.0010563692554046878 Test RE 0.015535167378606869\n",
      "56 Train Loss 0.0044920743 Test MSE 0.001097930895996874 Test RE 0.015837825858932605\n",
      "57 Train Loss 0.0041135284 Test MSE 0.001276253897596749 Test RE 0.017075624698912457\n",
      "58 Train Loss 0.0038719163 Test MSE 0.001116098967836983 Test RE 0.015968326852822495\n",
      "59 Train Loss 0.003447753 Test MSE 0.0010581933293678637 Test RE 0.015548574183072438\n",
      "60 Train Loss 0.003264641 Test MSE 0.0009597302214860245 Test RE 0.014807530834262075\n",
      "61 Train Loss 0.0029788082 Test MSE 0.0009143212644214496 Test RE 0.014452982287109445\n",
      "62 Train Loss 0.0028264083 Test MSE 0.0008368047223727577 Test RE 0.013826750350132951\n",
      "63 Train Loss 0.0026065318 Test MSE 0.0008516938835464614 Test RE 0.0139492168093769\n",
      "64 Train Loss 0.0024020618 Test MSE 0.0006805705570296514 Test RE 0.012469373639927207\n",
      "65 Train Loss 0.002126645 Test MSE 0.0006677926629268944 Test RE 0.012351761060804966\n",
      "66 Train Loss 0.0020213774 Test MSE 0.0006323680402497637 Test RE 0.012019683072458598\n",
      "67 Train Loss 0.0019055391 Test MSE 0.0005334216756852854 Test RE 0.01103934713240017\n",
      "68 Train Loss 0.0017946197 Test MSE 0.000608926100554935 Test RE 0.011794793862953594\n",
      "69 Train Loss 0.0017126702 Test MSE 0.0005622143530211828 Test RE 0.011333368884246653\n",
      "70 Train Loss 0.0015376887 Test MSE 0.0005384345210520038 Test RE 0.011091097125504006\n",
      "71 Train Loss 0.0014889193 Test MSE 0.0005236924357799522 Test RE 0.010938208834994679\n",
      "72 Train Loss 0.0013710078 Test MSE 0.0004983799156256457 Test RE 0.010670587376538155\n",
      "73 Train Loss 0.0013243188 Test MSE 0.0004898071535536701 Test RE 0.010578415519968035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 0.0012813642 Test MSE 0.0004772844731937138 Test RE 0.010442313162056276\n",
      "75 Train Loss 0.0011335708 Test MSE 0.0004524192508885585 Test RE 0.010166666989876809\n",
      "76 Train Loss 0.0010956238 Test MSE 0.00041657814930764407 Test RE 0.00975565207808556\n",
      "77 Train Loss 0.0010788254 Test MSE 0.0004098411477968254 Test RE 0.009676445164591081\n",
      "78 Train Loss 0.0010358016 Test MSE 0.00043747671569411244 Test RE 0.009997364619596646\n",
      "79 Train Loss 0.0009455363 Test MSE 0.0004278376148051888 Test RE 0.00988661318082292\n",
      "80 Train Loss 0.00091449637 Test MSE 0.00038627085496298005 Test RE 0.009394075163144045\n",
      "81 Train Loss 0.0009053695 Test MSE 0.00038781515642108264 Test RE 0.009412835073135778\n",
      "82 Train Loss 0.00078013056 Test MSE 0.0003841005498740829 Test RE 0.009367647168808226\n",
      "83 Train Loss 0.00071850454 Test MSE 0.0003513205954396931 Test RE 0.008959006782023597\n",
      "84 Train Loss 0.000706943 Test MSE 0.00036397492194981785 Test RE 0.009118928092181747\n",
      "85 Train Loss 0.0006928856 Test MSE 0.00037337891138450075 Test RE 0.009235979341781811\n",
      "86 Train Loss 0.00067327236 Test MSE 0.0003938719604721647 Test RE 0.00948605400150004\n",
      "87 Train Loss 0.00065056136 Test MSE 0.0003840874797938232 Test RE 0.009367487787440568\n",
      "88 Train Loss 0.00063088024 Test MSE 0.00037103437105967876 Test RE 0.009206936156133477\n",
      "89 Train Loss 0.0006202651 Test MSE 0.00038112036113757604 Test RE 0.009331235193450728\n",
      "90 Train Loss 0.00060159364 Test MSE 0.0003666304258862757 Test RE 0.009152132772682385\n",
      "91 Train Loss 0.0005646328 Test MSE 0.0003367714135189764 Test RE 0.008771536404426536\n",
      "92 Train Loss 0.0005524445 Test MSE 0.00032385557122269334 Test RE 0.008601689203252565\n",
      "93 Train Loss 0.00054186257 Test MSE 0.00031870502682372805 Test RE 0.008533015156429251\n",
      "94 Train Loss 0.00050058914 Test MSE 0.0002650680022316503 Test RE 0.007781919120029265\n",
      "95 Train Loss 0.0004675056 Test MSE 0.0002279142216883095 Test RE 0.007215954284302098\n",
      "96 Train Loss 0.0004449835 Test MSE 0.00022258109334970296 Test RE 0.007131028891084352\n",
      "97 Train Loss 0.00042392703 Test MSE 0.0002140749292197641 Test RE 0.006993441797317562\n",
      "98 Train Loss 0.00041541236 Test MSE 0.00020386459630220125 Test RE 0.006824627723610461\n",
      "99 Train Loss 0.00040773774 Test MSE 0.00020598952635015745 Test RE 0.006860102895260331\n",
      "Training time: 68.33\n",
      "1\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.35786 Test MSE 8.578432991423462 Test RE 1.3999484430636404\n",
      "1 Train Loss 55.13977 Test MSE 8.869006935288885 Test RE 1.4234609498194977\n",
      "2 Train Loss 45.301468 Test MSE 8.822161188702013 Test RE 1.4196966400660767\n",
      "3 Train Loss 42.07576 Test MSE 8.466697663362199 Test RE 1.3908012944221426\n",
      "4 Train Loss 39.119373 Test MSE 8.354501861761953 Test RE 1.381555513423459\n",
      "5 Train Loss 36.398705 Test MSE 9.000525858862504 Test RE 1.4339763946679458\n",
      "6 Train Loss 33.297916 Test MSE 9.023817566178812 Test RE 1.4358306295654737\n",
      "7 Train Loss 29.559448 Test MSE 9.170550880450628 Test RE 1.4474573392356533\n",
      "8 Train Loss 25.722157 Test MSE 9.207909034474422 Test RE 1.4504026026140215\n",
      "9 Train Loss 22.912544 Test MSE 9.184571271262735 Test RE 1.4485633887621396\n",
      "10 Train Loss 19.777903 Test MSE 9.196546176959288 Test RE 1.4495074044954401\n",
      "11 Train Loss 16.668455 Test MSE 8.150550592960286 Test RE 1.364587956723368\n",
      "12 Train Loss 14.706278 Test MSE 8.282040494358421 Test RE 1.3755511208026008\n",
      "13 Train Loss 13.026779 Test MSE 8.51221685257228 Test RE 1.3945349393124966\n",
      "14 Train Loss 11.74617 Test MSE 8.44777027433418 Test RE 1.3892458493891375\n",
      "15 Train Loss 10.6277275 Test MSE 8.552964716870923 Test RE 1.3978687640624612\n",
      "16 Train Loss 9.287458 Test MSE 8.398862134426215 Test RE 1.3852185110542812\n",
      "17 Train Loss 8.100558 Test MSE 7.942105649368992 Test RE 1.347025726404273\n",
      "18 Train Loss 6.735471 Test MSE 7.757558758110934 Test RE 1.331283646473881\n",
      "19 Train Loss 5.3106885 Test MSE 7.799340006370154 Test RE 1.3348638964628945\n",
      "20 Train Loss 4.3682513 Test MSE 7.481942843993714 Test RE 1.3074203888666418\n",
      "21 Train Loss 3.8840194 Test MSE 7.511698577913867 Test RE 1.3100176186989372\n",
      "22 Train Loss 3.411572 Test MSE 7.4017551207789785 Test RE 1.3003953764414315\n",
      "23 Train Loss 3.200402 Test MSE 7.276912933789051 Test RE 1.2893821382343913\n",
      "24 Train Loss 3.0229576 Test MSE 7.279335056090141 Test RE 1.2895967059657243\n",
      "25 Train Loss 2.847864 Test MSE 7.344281805146344 Test RE 1.2953368679791961\n",
      "26 Train Loss 2.7419581 Test MSE 7.394897564857527 Test RE 1.2997928436435808\n",
      "27 Train Loss 2.662604 Test MSE 7.368329206726787 Test RE 1.297455797380326\n",
      "28 Train Loss 2.590917 Test MSE 7.426425693323746 Test RE 1.3025607284377705\n",
      "29 Train Loss 2.5309072 Test MSE 7.442541401554443 Test RE 1.3039732728844398\n",
      "30 Train Loss 2.4761105 Test MSE 7.439966317448728 Test RE 1.3037476690773786\n",
      "31 Train Loss 2.398043 Test MSE 7.43340964696289 Test RE 1.303173061097261\n",
      "32 Train Loss 2.3506968 Test MSE 7.473192935240159 Test RE 1.3066556706691317\n",
      "33 Train Loss 2.289768 Test MSE 7.510191379554722 Test RE 1.309886186677477\n",
      "34 Train Loss 2.233714 Test MSE 7.490117265607421 Test RE 1.308134407147801\n",
      "35 Train Loss 2.1772766 Test MSE 7.522048385411301 Test RE 1.3109197956805614\n",
      "36 Train Loss 2.1283786 Test MSE 7.565898177115058 Test RE 1.3147352476169136\n",
      "37 Train Loss 2.0937073 Test MSE 7.650415834159789 Test RE 1.3220582209991625\n",
      "38 Train Loss 2.0635955 Test MSE 7.672297843562638 Test RE 1.3239475714878988\n",
      "39 Train Loss 2.033327 Test MSE 7.715593895516806 Test RE 1.327677944213882\n",
      "40 Train Loss 1.9966757 Test MSE 7.7506178145728635 Test RE 1.3306879415136341\n",
      "41 Train Loss 1.9663097 Test MSE 7.795440778932045 Test RE 1.3345301766460227\n",
      "42 Train Loss 1.9315867 Test MSE 7.791995252333357 Test RE 1.3342352178649144\n",
      "43 Train Loss 1.9044375 Test MSE 7.783658940712401 Test RE 1.3335213071989878\n",
      "44 Train Loss 1.8761703 Test MSE 7.828864478549816 Test RE 1.33738807957028\n",
      "45 Train Loss 1.8505998 Test MSE 7.8363590254871465 Test RE 1.3380280651094383\n",
      "46 Train Loss 1.8200867 Test MSE 7.839785690434577 Test RE 1.3383205780441663\n",
      "47 Train Loss 1.7912236 Test MSE 7.868008045821361 Test RE 1.3407273165100393\n",
      "48 Train Loss 1.7605666 Test MSE 7.860659310633256 Test RE 1.3401010492499659\n",
      "49 Train Loss 1.7269677 Test MSE 7.861279596576842 Test RE 1.3401539220061303\n",
      "50 Train Loss 1.6940169 Test MSE 7.868750257309629 Test RE 1.34079055232173\n",
      "51 Train Loss 1.6695261 Test MSE 7.871503767289543 Test RE 1.341025123068537\n",
      "52 Train Loss 1.646013 Test MSE 7.892459584793377 Test RE 1.342809000691798\n",
      "53 Train Loss 1.6265197 Test MSE 7.936801962354402 Test RE 1.346575883737826\n",
      "54 Train Loss 1.6069809 Test MSE 7.933632058562393 Test RE 1.3463069503368539\n",
      "55 Train Loss 1.591728 Test MSE 7.9532739992273855 Test RE 1.3479725011102794\n",
      "56 Train Loss 1.5763029 Test MSE 7.955741378459416 Test RE 1.3481815786196274\n",
      "57 Train Loss 1.5566719 Test MSE 7.972922187174127 Test RE 1.3496365252345617\n",
      "58 Train Loss 1.534443 Test MSE 7.99369058218892 Test RE 1.3513931932479346\n",
      "59 Train Loss 1.5188383 Test MSE 8.039775838142354 Test RE 1.3552831233853933\n",
      "60 Train Loss 1.5046991 Test MSE 8.063521746664774 Test RE 1.3572830983606632\n",
      "61 Train Loss 1.4893988 Test MSE 8.038960276046772 Test RE 1.3552143810722375\n",
      "62 Train Loss 1.4757447 Test MSE 8.026556679673245 Test RE 1.3541684733542263\n",
      "63 Train Loss 1.4582548 Test MSE 8.012780760880649 Test RE 1.353005899733682\n",
      "64 Train Loss 1.4457452 Test MSE 7.994805111844101 Test RE 1.3514873997523056\n",
      "65 Train Loss 1.4331764 Test MSE 7.968151290207528 Test RE 1.3492326619964554\n",
      "66 Train Loss 1.4219687 Test MSE 7.980813874066661 Test RE 1.350304302639916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Train Loss 1.4104137 Test MSE 8.005764360776864 Test RE 1.352413389460502\n",
      "68 Train Loss 1.3962861 Test MSE 7.975936114090386 Test RE 1.3498915961739755\n",
      "69 Train Loss 1.3828623 Test MSE 7.940827245951702 Test RE 1.346917309841293\n",
      "70 Train Loss 1.373647 Test MSE 7.951973057043604 Test RE 1.3478622505388052\n",
      "71 Train Loss 1.3612179 Test MSE 7.912265329135016 Test RE 1.344492802012565\n",
      "72 Train Loss 1.3509829 Test MSE 7.905766687552033 Test RE 1.3439405472985873\n",
      "73 Train Loss 1.3405703 Test MSE 7.885536994870479 Test RE 1.3422199729493884\n",
      "74 Train Loss 1.3296974 Test MSE 7.8724655578071925 Test RE 1.341107048065926\n",
      "75 Train Loss 1.3172789 Test MSE 7.827498688220237 Test RE 1.3372714169697981\n",
      "76 Train Loss 1.3088334 Test MSE 7.818038217719427 Test RE 1.336463046235052\n",
      "77 Train Loss 1.2994548 Test MSE 7.788325344919947 Test RE 1.3339209789414759\n",
      "78 Train Loss 1.2889948 Test MSE 7.755295394107354 Test RE 1.331089423046567\n",
      "79 Train Loss 1.2767421 Test MSE 7.745664441734056 Test RE 1.3302626562569813\n",
      "80 Train Loss 1.2662144 Test MSE 7.7256209258569815 Test RE 1.3285403758554761\n",
      "81 Train Loss 1.2520415 Test MSE 7.728527441557815 Test RE 1.3287902625883983\n",
      "82 Train Loss 1.2423129 Test MSE 7.714973623711989 Test RE 1.3276245758175143\n",
      "83 Train Loss 1.2323122 Test MSE 7.693582344508763 Test RE 1.3257827483167464\n",
      "84 Train Loss 1.2195148 Test MSE 7.667447341249033 Test RE 1.3235289989693693\n",
      "85 Train Loss 1.2071664 Test MSE 7.665273995159398 Test RE 1.323341407825206\n",
      "86 Train Loss 1.1997747 Test MSE 7.663042907189159 Test RE 1.3231488050578504\n",
      "87 Train Loss 1.1877744 Test MSE 7.651456798266982 Test RE 1.3221481617536621\n",
      "88 Train Loss 1.1785228 Test MSE 7.623292357367373 Test RE 1.3197125540563002\n",
      "89 Train Loss 1.1693552 Test MSE 7.5725477678523125 Test RE 1.3153128744267608\n",
      "90 Train Loss 1.1595603 Test MSE 7.558603538709602 Test RE 1.3141012957193179\n",
      "91 Train Loss 1.1488267 Test MSE 7.548272295631844 Test RE 1.3132029193125743\n",
      "92 Train Loss 1.1372302 Test MSE 7.515643707021523 Test RE 1.3103615828625026\n",
      "93 Train Loss 1.1263705 Test MSE 7.50579226908655 Test RE 1.3095024961816744\n",
      "94 Train Loss 1.1156259 Test MSE 7.478453003862887 Test RE 1.3071154399777252\n",
      "95 Train Loss 1.1085514 Test MSE 7.476286697254818 Test RE 1.3069261081798331\n",
      "96 Train Loss 1.0989393 Test MSE 7.443860965583162 Test RE 1.304088865117669\n",
      "97 Train Loss 1.0917716 Test MSE 7.414720614423869 Test RE 1.3015338152800884\n",
      "98 Train Loss 1.084325 Test MSE 7.395195057106723 Test RE 1.299818988319979\n",
      "99 Train Loss 1.0771246 Test MSE 7.409816513747131 Test RE 1.3011033264625635\n",
      "Training time: 68.38\n",
      "2\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 54.80088 Test MSE 8.397337724761389 Test RE 1.3850927954348464\n",
      "1 Train Loss 38.410442 Test MSE 7.354618478455555 Test RE 1.2962481052151809\n",
      "2 Train Loss 28.980347 Test MSE 6.425793198465366 Test RE 1.211633946578908\n",
      "3 Train Loss 23.685112 Test MSE 6.005871524552375 Test RE 1.1713753458821217\n",
      "4 Train Loss 21.345413 Test MSE 6.163298778861489 Test RE 1.1866282164400164\n",
      "5 Train Loss 18.319519 Test MSE 6.144648775951075 Test RE 1.1848315011133976\n",
      "6 Train Loss 13.397613 Test MSE 5.8893847050123975 Test RE 1.1599600241645207\n",
      "7 Train Loss 11.363165 Test MSE 5.984998284022645 Test RE 1.169338032861511\n",
      "8 Train Loss 10.084763 Test MSE 5.776693310605001 Test RE 1.1488086999499834\n",
      "9 Train Loss 9.378707 Test MSE 5.842500952435788 Test RE 1.1553337391621097\n",
      "10 Train Loss 8.813084 Test MSE 5.90669662942691 Test RE 1.1616636320728593\n",
      "11 Train Loss 8.300394 Test MSE 5.720875497353578 Test RE 1.1432449942207354\n",
      "12 Train Loss 7.5578833 Test MSE 5.478982379726965 Test RE 1.1188143091109626\n",
      "13 Train Loss 6.6608667 Test MSE 5.408351399250424 Test RE 1.1115794544100832\n",
      "14 Train Loss 5.4560404 Test MSE 5.065036862677414 Test RE 1.0757203029626268\n",
      "15 Train Loss 4.5344424 Test MSE 4.87920362560856 Test RE 1.055802125111952\n",
      "16 Train Loss 3.942932 Test MSE 4.579231837676529 Test RE 1.0228321632138777\n",
      "17 Train Loss 3.3898485 Test MSE 4.225450295415435 Test RE 0.9825271477029467\n",
      "18 Train Loss 2.9265177 Test MSE 3.898027101845359 Test RE 0.9436924650855925\n",
      "19 Train Loss 2.5151522 Test MSE 3.224399903566673 Test RE 0.8582869515222201\n",
      "20 Train Loss 2.1705027 Test MSE 2.4857312862292633 Test RE 0.7535900394337647\n",
      "21 Train Loss 1.9032062 Test MSE 2.182710940588801 Test RE 0.7061649745028488\n",
      "22 Train Loss 1.6949998 Test MSE 1.8006672446480705 Test RE 0.6413938517173837\n",
      "23 Train Loss 1.3881435 Test MSE 1.2065781128852966 Test RE 0.5250320095637955\n",
      "24 Train Loss 1.0411459 Test MSE 0.8994496894208801 Test RE 0.4533112511658405\n",
      "25 Train Loss 0.73047805 Test MSE 0.6581868217508802 Test RE 0.38777754031320294\n",
      "26 Train Loss 0.5398211 Test MSE 0.3933672443070987 Test RE 0.29978310740440534\n",
      "27 Train Loss 0.42184937 Test MSE 0.2918249856468351 Test RE 0.25820776391235734\n",
      "28 Train Loss 0.31228873 Test MSE 0.17199680623824573 Test RE 0.1982294845202873\n",
      "29 Train Loss 0.20954722 Test MSE 0.07560467194498925 Test RE 0.13142632887074868\n",
      "30 Train Loss 0.16375664 Test MSE 0.06903355874838277 Test RE 0.12558512188335266\n",
      "31 Train Loss 0.1204779 Test MSE 0.06365171164307505 Test RE 0.12059050215052725\n",
      "32 Train Loss 0.09310663 Test MSE 0.0472923209182718 Test RE 0.1039449451161798\n",
      "33 Train Loss 0.07541608 Test MSE 0.04338573369239148 Test RE 0.09955923098248877\n",
      "34 Train Loss 0.06221822 Test MSE 0.03734084342865876 Test RE 0.09236344476924224\n",
      "35 Train Loss 0.051491566 Test MSE 0.03799067976402662 Test RE 0.0931636708817573\n",
      "36 Train Loss 0.039851017 Test MSE 0.03937609537764022 Test RE 0.09484717158793919\n",
      "37 Train Loss 0.03394806 Test MSE 0.046767396723756974 Test RE 0.10336646357128078\n",
      "38 Train Loss 0.030303562 Test MSE 0.0487376825012328 Test RE 0.10552138856649845\n",
      "39 Train Loss 0.026364863 Test MSE 0.047178351818572876 Test RE 0.10381962183555564\n",
      "40 Train Loss 0.022375638 Test MSE 0.04765019791537279 Test RE 0.10433749716072631\n",
      "41 Train Loss 0.02001872 Test MSE 0.043414648316092715 Test RE 0.0995924013126982\n",
      "42 Train Loss 0.017903289 Test MSE 0.04239241267509272 Test RE 0.09841292214998781\n",
      "43 Train Loss 0.015732236 Test MSE 0.04153380387822817 Test RE 0.09741120466235428\n",
      "44 Train Loss 0.014031865 Test MSE 0.04024308622249363 Test RE 0.09588566837370187\n",
      "45 Train Loss 0.011898814 Test MSE 0.03668524404237237 Test RE 0.0915490340881423\n",
      "46 Train Loss 0.0109304795 Test MSE 0.03585471278509497 Test RE 0.09050679462168777\n",
      "47 Train Loss 0.009797502 Test MSE 0.034606684722954265 Test RE 0.08891766684141861\n",
      "48 Train Loss 0.009051753 Test MSE 0.03610457997380781 Test RE 0.09082161258457716\n",
      "49 Train Loss 0.007896282 Test MSE 0.03430577067003768 Test RE 0.0885302417845374\n",
      "50 Train Loss 0.007227663 Test MSE 0.03079512134258484 Test RE 0.08387818417333893\n",
      "51 Train Loss 0.0061550695 Test MSE 0.027986615419830385 Test RE 0.07996192674802602\n",
      "52 Train Loss 0.0059340373 Test MSE 0.027953326663710833 Test RE 0.0799143571323245\n",
      "53 Train Loss 0.0052534216 Test MSE 0.027205096929183704 Test RE 0.07883756445694635\n",
      "54 Train Loss 0.0047368803 Test MSE 0.02512421969229627 Test RE 0.07576250949430735\n",
      "55 Train Loss 0.004350089 Test MSE 0.023855705742839926 Test RE 0.07382512566049206\n",
      "56 Train Loss 0.0039353417 Test MSE 0.023325611274651145 Test RE 0.0730002886152742\n",
      "57 Train Loss 0.0036076375 Test MSE 0.021288779430252622 Test RE 0.06974024061810892\n",
      "58 Train Loss 0.003492247 Test MSE 0.01972493198925252 Test RE 0.06712987175471277\n",
      "59 Train Loss 0.0032113024 Test MSE 0.018042476306293097 Test RE 0.0642031197999914\n",
      "60 Train Loss 0.0030836046 Test MSE 0.01817568940666099 Test RE 0.06443969951658234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 0.0027827069 Test MSE 0.017345999323939116 Test RE 0.06295173771532403\n",
      "62 Train Loss 0.0026661619 Test MSE 0.016496895531190655 Test RE 0.06139163112372955\n",
      "63 Train Loss 0.0025481721 Test MSE 0.015568763047325837 Test RE 0.059639653927827954\n",
      "64 Train Loss 0.0023874822 Test MSE 0.01461848619222512 Test RE 0.05779087382007249\n",
      "65 Train Loss 0.0022299832 Test MSE 0.015016628575840584 Test RE 0.05857256995932856\n",
      "66 Train Loss 0.0020893938 Test MSE 0.014996742562431518 Test RE 0.05853377427428917\n",
      "67 Train Loss 0.0018921819 Test MSE 0.013917973251997652 Test RE 0.056389216333002104\n",
      "68 Train Loss 0.0018577934 Test MSE 0.014063703710157843 Test RE 0.05668366391751392\n",
      "69 Train Loss 0.0017241415 Test MSE 0.012462850583880601 Test RE 0.05336011469999374\n",
      "70 Train Loss 0.0015828966 Test MSE 0.0112142294189237 Test RE 0.050616577743861926\n",
      "71 Train Loss 0.0014759627 Test MSE 0.010815207472860243 Test RE 0.04970790822553783\n",
      "72 Train Loss 0.0014280131 Test MSE 0.010972251747270317 Test RE 0.050067504096804764\n",
      "73 Train Loss 0.0013421596 Test MSE 0.01107678884154632 Test RE 0.05030544541239675\n",
      "74 Train Loss 0.0012651862 Test MSE 0.010746020164152301 Test RE 0.04954865680443001\n",
      "75 Train Loss 0.0011798393 Test MSE 0.009462641530621504 Test RE 0.0464958567272419\n",
      "76 Train Loss 0.0011648487 Test MSE 0.009035498276996727 Test RE 0.045434328525256376\n",
      "77 Train Loss 0.0011059389 Test MSE 0.008353838385454273 Test RE 0.0436868865541764\n",
      "78 Train Loss 0.0009990053 Test MSE 0.00798383373461223 Test RE 0.04270844924037032\n",
      "79 Train Loss 0.0009870819 Test MSE 0.007998063035161134 Test RE 0.0427464911664611\n",
      "80 Train Loss 0.00095807767 Test MSE 0.00804949794416243 Test RE 0.04288372053932815\n",
      "81 Train Loss 0.0008908612 Test MSE 0.008459212442550596 Test RE 0.04396155301622482\n",
      "82 Train Loss 0.00086102425 Test MSE 0.007912212839820517 Test RE 0.04251645449459032\n",
      "83 Train Loss 0.00084879063 Test MSE 0.007972186447989981 Test RE 0.042677285070293246\n",
      "84 Train Loss 0.00079896225 Test MSE 0.007375558870503964 Test RE 0.041049278407349066\n",
      "85 Train Loss 0.0007668299 Test MSE 0.007493485136059305 Test RE 0.041376141209463584\n",
      "86 Train Loss 0.00075414777 Test MSE 0.00766900309772537 Test RE 0.04185790778461609\n",
      "87 Train Loss 0.00074126135 Test MSE 0.007662849056499896 Test RE 0.041841109839379116\n",
      "88 Train Loss 0.0007248713 Test MSE 0.007453271412426492 Test RE 0.041264969505079165\n",
      "89 Train Loss 0.0006947575 Test MSE 0.006933049831185182 Test RE 0.039798822319578764\n",
      "90 Train Loss 0.00064334087 Test MSE 0.006405302668420475 Test RE 0.03825409115236201\n",
      "91 Train Loss 0.00061472534 Test MSE 0.006171323100568858 Test RE 0.0375488985949931\n",
      "92 Train Loss 0.000609269 Test MSE 0.0062208926428943805 Test RE 0.0376993978524914\n",
      "93 Train Loss 0.0005997814 Test MSE 0.006315779772508982 Test RE 0.03798582378960745\n",
      "94 Train Loss 0.00058152125 Test MSE 0.006533665352737397 Test RE 0.03863549702541152\n",
      "95 Train Loss 0.0005735645 Test MSE 0.006532645217576311 Test RE 0.03863248072709888\n",
      "96 Train Loss 0.0005587634 Test MSE 0.006400155272693564 Test RE 0.03823871728705332\n",
      "97 Train Loss 0.00052677724 Test MSE 0.0060118262585617584 Test RE 0.0370604997012274\n",
      "98 Train Loss 0.0005122727 Test MSE 0.005683107371334142 Test RE 0.036033047228391145\n",
      "99 Train Loss 0.0005055329 Test MSE 0.0055547567068584824 Test RE 0.035623827673997216\n",
      "Training time: 68.22\n",
      "3\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.258865 Test MSE 8.093009784132793 Test RE 1.3597626036937014\n",
      "1 Train Loss 43.81036 Test MSE 8.543253525864625 Test RE 1.3970749559196123\n",
      "2 Train Loss 40.00352 Test MSE 8.50418601727116 Test RE 1.3938769483716407\n",
      "3 Train Loss 35.951756 Test MSE 8.776725317692554 Test RE 1.4160360618835672\n",
      "4 Train Loss 31.78484 Test MSE 8.267571645446369 Test RE 1.3743490413449015\n",
      "5 Train Loss 27.711285 Test MSE 8.413222747778306 Test RE 1.3864022482773108\n",
      "6 Train Loss 24.70507 Test MSE 8.766818717512757 Test RE 1.4152366712602453\n",
      "7 Train Loss 21.823698 Test MSE 8.73181872522805 Test RE 1.412408803401847\n",
      "8 Train Loss 19.436352 Test MSE 8.689109836246077 Test RE 1.4089503971089998\n",
      "9 Train Loss 17.20057 Test MSE 8.800597653051021 Test RE 1.4179605343547224\n",
      "10 Train Loss 15.612869 Test MSE 8.486401667232883 Test RE 1.392418715381497\n",
      "11 Train Loss 14.264883 Test MSE 8.396563470417622 Test RE 1.3850289395516215\n",
      "12 Train Loss 12.676557 Test MSE 7.906246686666088 Test RE 1.343981345396113\n",
      "13 Train Loss 9.343926 Test MSE 7.257060512317911 Test RE 1.28762213093366\n",
      "14 Train Loss 8.524515 Test MSE 6.930555823158066 Test RE 1.2583228795296322\n",
      "15 Train Loss 7.5386086 Test MSE 6.891959042230247 Test RE 1.2548141407424462\n",
      "16 Train Loss 7.1194544 Test MSE 6.6972222571189475 Test RE 1.2369593172562425\n",
      "17 Train Loss 6.5480995 Test MSE 6.5951578407957046 Test RE 1.2274976157341764\n",
      "18 Train Loss 5.935874 Test MSE 6.381007638580935 Test RE 1.207404228647825\n",
      "19 Train Loss 4.8751063 Test MSE 5.871753061734028 Test RE 1.1582223781583418\n",
      "20 Train Loss 3.362402 Test MSE 5.362846086228443 Test RE 1.1068932185477365\n",
      "21 Train Loss 2.591383 Test MSE 5.417000343300333 Test RE 1.1124679088795804\n",
      "22 Train Loss 2.2204413 Test MSE 5.618444181076673 Test RE 1.1329639613797868\n",
      "23 Train Loss 1.9749799 Test MSE 5.631319051876513 Test RE 1.1342613327862008\n",
      "24 Train Loss 1.7899095 Test MSE 5.515236683677997 Test RE 1.1225097905997201\n",
      "25 Train Loss 1.6720026 Test MSE 5.525381434834857 Test RE 1.1235416910753993\n",
      "26 Train Loss 1.5839612 Test MSE 5.58433687750161 Test RE 1.129519843335421\n",
      "27 Train Loss 1.4934328 Test MSE 5.605121376068569 Test RE 1.1316198867402503\n",
      "28 Train Loss 1.4296488 Test MSE 5.609810508302166 Test RE 1.1320931330453576\n",
      "29 Train Loss 1.3758366 Test MSE 5.605345771539104 Test RE 1.1316425381529944\n",
      "30 Train Loss 1.3363163 Test MSE 5.6495815627460395 Test RE 1.136099063211826\n",
      "31 Train Loss 1.2967663 Test MSE 5.629165350172505 Test RE 1.1340444125446205\n",
      "32 Train Loss 1.2599671 Test MSE 5.646947712827056 Test RE 1.1358342061396773\n",
      "33 Train Loss 1.2304518 Test MSE 5.669474711276436 Test RE 1.1380975056601843\n",
      "34 Train Loss 1.2029368 Test MSE 5.68284586598766 Test RE 1.139438786523329\n",
      "35 Train Loss 1.1711248 Test MSE 5.721324799724289 Test RE 1.1432898870523847\n",
      "36 Train Loss 1.1451536 Test MSE 5.76342279815287 Test RE 1.1474883904782525\n",
      "37 Train Loss 1.1211426 Test MSE 5.8181567940902825 Test RE 1.1529242413348482\n",
      "38 Train Loss 1.0983146 Test MSE 5.846968175202482 Test RE 1.1557753434545888\n",
      "39 Train Loss 1.08313 Test MSE 5.923068023914831 Test RE 1.163272390324682\n",
      "40 Train Loss 1.0651151 Test MSE 5.924714758136308 Test RE 1.1634340858615877\n",
      "41 Train Loss 1.047822 Test MSE 5.943970527048867 Test RE 1.165323176360049\n",
      "42 Train Loss 1.0279193 Test MSE 5.926549378736764 Test RE 1.163614203809629\n",
      "43 Train Loss 1.0086243 Test MSE 5.937609155870938 Test RE 1.1646994318697683\n",
      "44 Train Loss 0.99146444 Test MSE 5.9424553708214924 Test RE 1.165174642716373\n",
      "45 Train Loss 0.9718734 Test MSE 5.965307636443914 Test RE 1.167412886745014\n",
      "46 Train Loss 0.9438079 Test MSE 5.987141651601934 Test RE 1.169547397739918\n",
      "47 Train Loss 0.91717035 Test MSE 6.026059052741816 Test RE 1.173342365551346\n",
      "48 Train Loss 0.89197123 Test MSE 6.0675482399788425 Test RE 1.1773746456986174\n",
      "49 Train Loss 0.8694866 Test MSE 6.084862263415012 Test RE 1.1790532949379138\n",
      "50 Train Loss 0.85534436 Test MSE 6.10788532662682 Test RE 1.1812817586692648\n",
      "51 Train Loss 0.8392745 Test MSE 6.145742682915491 Test RE 1.1849369617994725\n",
      "52 Train Loss 0.82511985 Test MSE 6.1898852072798665 Test RE 1.189184822757723\n",
      "53 Train Loss 0.8154688 Test MSE 6.187070404017467 Test RE 1.1889144056307994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 0.8076585 Test MSE 6.197963214316879 Test RE 1.1899605327241618\n",
      "55 Train Loss 0.7994088 Test MSE 6.213649597040951 Test RE 1.1914654126415853\n",
      "56 Train Loss 0.79028815 Test MSE 6.23236799839895 Test RE 1.1932586869851507\n",
      "57 Train Loss 0.78235435 Test MSE 6.248143465298101 Test RE 1.1947679300160865\n",
      "58 Train Loss 0.77481 Test MSE 6.266387133116323 Test RE 1.1965109326827408\n",
      "59 Train Loss 0.76773286 Test MSE 6.27950002401049 Test RE 1.1977621734356907\n",
      "60 Train Loss 0.75852823 Test MSE 6.270714488634656 Test RE 1.1969239964222396\n",
      "61 Train Loss 0.7506672 Test MSE 6.274422357919336 Test RE 1.1972778143063245\n",
      "62 Train Loss 0.7434883 Test MSE 6.295163427393838 Test RE 1.1992550747281912\n",
      "63 Train Loss 0.7361056 Test MSE 6.309462580908994 Test RE 1.2006163265654886\n",
      "64 Train Loss 0.7293089 Test MSE 6.301946037418759 Test RE 1.1999009586505371\n",
      "65 Train Loss 0.7245991 Test MSE 6.295369241426481 Test RE 1.1992746787868123\n",
      "66 Train Loss 0.7196673 Test MSE 6.3119949693635355 Test RE 1.2008572442242271\n",
      "67 Train Loss 0.71552813 Test MSE 6.31119098436535 Test RE 1.2007807627029348\n",
      "68 Train Loss 0.7116972 Test MSE 6.312692510645147 Test RE 1.200923596016673\n",
      "69 Train Loss 0.7072624 Test MSE 6.325193946858761 Test RE 1.2021121414843614\n",
      "70 Train Loss 0.7037056 Test MSE 6.3472789581998725 Test RE 1.2042089567427083\n",
      "71 Train Loss 0.69864446 Test MSE 6.338184465043495 Test RE 1.2033459415879055\n",
      "72 Train Loss 0.69421667 Test MSE 6.352559391323857 Test RE 1.2047097558222912\n",
      "73 Train Loss 0.69001293 Test MSE 6.3568422169878565 Test RE 1.205115788430976\n",
      "74 Train Loss 0.6866536 Test MSE 6.3656531460361006 Test RE 1.2059506772440873\n",
      "75 Train Loss 0.6834779 Test MSE 6.371981078136933 Test RE 1.2065499306342033\n",
      "76 Train Loss 0.6792742 Test MSE 6.384741505137761 Test RE 1.2077574351638387\n",
      "77 Train Loss 0.6741471 Test MSE 6.416743892920866 Test RE 1.210780487058782\n",
      "78 Train Loss 0.67015195 Test MSE 6.425534231240715 Test RE 1.2116095311774027\n",
      "79 Train Loss 0.6660679 Test MSE 6.406991041006838 Test RE 1.209860000486518\n",
      "80 Train Loss 0.6626527 Test MSE 6.4172900963447566 Test RE 1.2108320177405292\n",
      "81 Train Loss 0.6592072 Test MSE 6.4373255982676385 Test RE 1.2127207216198699\n",
      "82 Train Loss 0.6558851 Test MSE 6.446709571971971 Test RE 1.2136043179888876\n",
      "83 Train Loss 0.65275186 Test MSE 6.454534027791687 Test RE 1.2143405783801584\n",
      "84 Train Loss 0.6497969 Test MSE 6.4674216208204784 Test RE 1.2155522942800292\n",
      "85 Train Loss 0.64656746 Test MSE 6.46960469698933 Test RE 1.215757431621065\n",
      "86 Train Loss 0.64348817 Test MSE 6.4694436296191995 Test RE 1.2157422977697567\n",
      "87 Train Loss 0.6394901 Test MSE 6.488607733411286 Test RE 1.2175416320206587\n",
      "88 Train Loss 0.6357246 Test MSE 6.517343204716276 Test RE 1.2202346583307195\n",
      "89 Train Loss 0.6315915 Test MSE 6.54037060329385 Test RE 1.2223884541844772\n",
      "90 Train Loss 0.62725884 Test MSE 6.555817305846927 Test RE 1.2238310892119477\n",
      "91 Train Loss 0.6230223 Test MSE 6.582720497270029 Test RE 1.2263396439056433\n",
      "92 Train Loss 0.6195749 Test MSE 6.594179910316268 Test RE 1.2274066056428894\n",
      "93 Train Loss 0.6172277 Test MSE 6.598674298087842 Test RE 1.2278248154639506\n",
      "94 Train Loss 0.61416626 Test MSE 6.600574952829004 Test RE 1.2280016315129314\n",
      "95 Train Loss 0.6115048 Test MSE 6.616149767934723 Test RE 1.229449583346649\n",
      "96 Train Loss 0.60924447 Test MSE 6.619697532812466 Test RE 1.229779171825664\n",
      "97 Train Loss 0.60642815 Test MSE 6.642965067081453 Test RE 1.2319385476312088\n",
      "98 Train Loss 0.60382473 Test MSE 6.655376663370862 Test RE 1.2330888764659251\n",
      "99 Train Loss 0.6012813 Test MSE 6.65831849252401 Test RE 1.233361373141442\n",
      "Training time: 67.74\n",
      "4\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.749035 Test MSE 8.595653403721704 Test RE 1.4013528722319852\n",
      "1 Train Loss 52.984497 Test MSE 8.435514488749305 Test RE 1.3882377443801657\n",
      "2 Train Loss 43.899834 Test MSE 7.8601063667533 Test RE 1.3400539149272606\n",
      "3 Train Loss 37.650642 Test MSE 7.342990445607068 Test RE 1.2952229821560193\n",
      "4 Train Loss 29.719028 Test MSE 5.651548279598828 Test RE 1.136296793851349\n",
      "5 Train Loss 21.149635 Test MSE 5.1590477450434 Test RE 1.0856574922840414\n",
      "6 Train Loss 16.033482 Test MSE 5.5299140158155735 Test RE 1.1240024284750993\n",
      "7 Train Loss 12.772049 Test MSE 5.476809451566674 Test RE 1.11859242993363\n",
      "8 Train Loss 10.604998 Test MSE 5.329020831350905 Test RE 1.1033969248180966\n",
      "9 Train Loss 7.9250345 Test MSE 4.885830796776688 Test RE 1.0565189026479742\n",
      "10 Train Loss 6.68919 Test MSE 4.981254375983551 Test RE 1.06678627716125\n",
      "11 Train Loss 5.5240765 Test MSE 4.664511546701259 Test RE 1.032312405849006\n",
      "12 Train Loss 4.1773806 Test MSE 4.0481726417875254 Test RE 0.9616954759806425\n",
      "13 Train Loss 3.2829351 Test MSE 3.5191775097354396 Test RE 0.8966617564171838\n",
      "14 Train Loss 2.6547904 Test MSE 3.207464603005613 Test RE 0.856030022485412\n",
      "15 Train Loss 2.2131505 Test MSE 2.8975283122632995 Test RE 0.8136205409275015\n",
      "16 Train Loss 1.865399 Test MSE 2.573402554973566 Test RE 0.7667643705308154\n",
      "17 Train Loss 1.6819034 Test MSE 2.4712767057305465 Test RE 0.7513957737733805\n",
      "18 Train Loss 1.558322 Test MSE 2.3233112087007055 Test RE 0.7285540120041301\n",
      "19 Train Loss 1.4468033 Test MSE 2.075037203801996 Test RE 0.6885270455079684\n",
      "20 Train Loss 1.2964433 Test MSE 1.7447999920074881 Test RE 0.6313655562931166\n",
      "21 Train Loss 1.1996037 Test MSE 1.594147228885227 Test RE 0.6034930521689316\n",
      "22 Train Loss 1.0347191 Test MSE 1.3933552628385117 Test RE 0.5642076773429833\n",
      "23 Train Loss 0.9285521 Test MSE 1.264151420683058 Test RE 0.5374123083011939\n",
      "24 Train Loss 0.84373724 Test MSE 0.9513944656632383 Test RE 0.46621728469638746\n",
      "25 Train Loss 0.69843286 Test MSE 0.7518837483017722 Test RE 0.4144607506024396\n",
      "26 Train Loss 0.52124894 Test MSE 0.49432814485422105 Test RE 0.3360591536201005\n",
      "27 Train Loss 0.37267727 Test MSE 0.35333096344450915 Test RE 0.2841181048176792\n",
      "28 Train Loss 0.30029187 Test MSE 0.26418558519119223 Test RE 0.24567593580267663\n",
      "29 Train Loss 0.22613612 Test MSE 0.1656129786328396 Test RE 0.1945159615645399\n",
      "30 Train Loss 0.16100506 Test MSE 0.1166763334191648 Test RE 0.1632673887049538\n",
      "31 Train Loss 0.11583071 Test MSE 0.09136135511731598 Test RE 0.1444738767419052\n",
      "32 Train Loss 0.08729028 Test MSE 0.06128800877674189 Test RE 0.11833025925780914\n",
      "33 Train Loss 0.07187636 Test MSE 0.051293285294414424 Test RE 0.10825259560695447\n",
      "34 Train Loss 0.053939555 Test MSE 0.037331196146493086 Test RE 0.09235151261008584\n",
      "35 Train Loss 0.04388941 Test MSE 0.029195136847984866 Test RE 0.08167014335857584\n",
      "36 Train Loss 0.038897276 Test MSE 0.025026857252194615 Test RE 0.0756155679550262\n",
      "37 Train Loss 0.032662135 Test MSE 0.021769740895715598 Test RE 0.07052363520696711\n",
      "38 Train Loss 0.02796205 Test MSE 0.02165619965836791 Test RE 0.07033948490321121\n",
      "39 Train Loss 0.024841756 Test MSE 0.019836817290376323 Test RE 0.06731999218500635\n",
      "40 Train Loss 0.022196557 Test MSE 0.017679163104442074 Test RE 0.06355341785573743\n",
      "41 Train Loss 0.019693311 Test MSE 0.015888444514911927 Test RE 0.06024884852843911\n",
      "42 Train Loss 0.018304652 Test MSE 0.013103539432596404 Test RE 0.05471449186364515\n",
      "43 Train Loss 0.016870897 Test MSE 0.01195370115280332 Test RE 0.05225877886669505\n",
      "44 Train Loss 0.014364445 Test MSE 0.011637129954303261 Test RE 0.051562148152243255\n",
      "45 Train Loss 0.012227254 Test MSE 0.01107864460310452 Test RE 0.05030965922396925\n",
      "46 Train Loss 0.011175273 Test MSE 0.009923998449355596 Test RE 0.047615834950626615\n",
      "47 Train Loss 0.009081963 Test MSE 0.009849148375576763 Test RE 0.04743592790262522\n",
      "48 Train Loss 0.008474846 Test MSE 0.009559325191749837 Test RE 0.046732786612247675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 0.0077886903 Test MSE 0.008975903822106822 Test RE 0.045284247513953914\n",
      "50 Train Loss 0.007393403 Test MSE 0.008398143823466219 Test RE 0.043802582296000724\n",
      "51 Train Loss 0.006554984 Test MSE 0.007393372123575684 Test RE 0.04109881907425921\n",
      "52 Train Loss 0.0063171024 Test MSE 0.007522255821218005 Test RE 0.041455495439575114\n",
      "53 Train Loss 0.0059277792 Test MSE 0.00736392275155185 Test RE 0.041016884738101486\n",
      "54 Train Loss 0.005600055 Test MSE 0.007510739829703577 Test RE 0.04142375070760223\n",
      "55 Train Loss 0.0053456854 Test MSE 0.007308058756691823 Test RE 0.04086100794833502\n",
      "56 Train Loss 0.0051282705 Test MSE 0.006936057943917116 Test RE 0.039807455342844474\n",
      "57 Train Loss 0.0046949405 Test MSE 0.005848814971365109 Test RE 0.03655459710306671\n",
      "58 Train Loss 0.004410332 Test MSE 0.005751657944688123 Test RE 0.03624971408228557\n",
      "59 Train Loss 0.004060205 Test MSE 0.005104896104964754 Test RE 0.034150849732019865\n",
      "60 Train Loss 0.0039514536 Test MSE 0.005017100376604131 Test RE 0.033855907174433916\n",
      "61 Train Loss 0.0037313863 Test MSE 0.004897218482610311 Test RE 0.03344897394525325\n",
      "62 Train Loss 0.0035025408 Test MSE 0.004684739245281764 Test RE 0.032715289798199376\n",
      "63 Train Loss 0.0032998929 Test MSE 0.004747961677836418 Test RE 0.03293530296422553\n",
      "64 Train Loss 0.0031082972 Test MSE 0.00502073245407174 Test RE 0.03386815977266774\n",
      "65 Train Loss 0.0029366133 Test MSE 0.004872691840950677 Test RE 0.0333651078927152\n",
      "66 Train Loss 0.002619492 Test MSE 0.004115113171869982 Test RE 0.030661892170607514\n",
      "67 Train Loss 0.002435011 Test MSE 0.0038214885383815044 Test RE 0.0295477449048201\n",
      "68 Train Loss 0.002369264 Test MSE 0.003676871693360079 Test RE 0.028983264344082292\n",
      "69 Train Loss 0.0022994305 Test MSE 0.003336204094306395 Test RE 0.027607963097742355\n",
      "70 Train Loss 0.0022445822 Test MSE 0.003149616371800642 Test RE 0.02682482453786986\n",
      "71 Train Loss 0.0021250308 Test MSE 0.0031726910943522344 Test RE 0.026922907250197085\n",
      "72 Train Loss 0.0020634136 Test MSE 0.0031341078757506353 Test RE 0.02675870123817032\n",
      "73 Train Loss 0.002002308 Test MSE 0.0029506447184408746 Test RE 0.025963696288786302\n",
      "74 Train Loss 0.0019723387 Test MSE 0.002913631497302225 Test RE 0.025800336599746232\n",
      "75 Train Loss 0.0019201997 Test MSE 0.0027773671066005285 Test RE 0.025189799117651686\n",
      "76 Train Loss 0.0018246918 Test MSE 0.0027198746404992077 Test RE 0.024927716920880433\n",
      "77 Train Loss 0.0017582402 Test MSE 0.0026539507136212324 Test RE 0.02462376665492669\n",
      "78 Train Loss 0.0017238894 Test MSE 0.002670837678725807 Test RE 0.024701982373153353\n",
      "79 Train Loss 0.0016548547 Test MSE 0.0027408487962116146 Test RE 0.025023646659309673\n",
      "80 Train Loss 0.0015438106 Test MSE 0.0023925075186385703 Test RE 0.02337947291732151\n",
      "81 Train Loss 0.0015042023 Test MSE 0.002266799660245156 Test RE 0.022756980098903125\n",
      "82 Train Loss 0.0014680187 Test MSE 0.00219211931104873 Test RE 0.02237897309906743\n",
      "83 Train Loss 0.0013979352 Test MSE 0.0018737902101519323 Test RE 0.020690383624342876\n",
      "84 Train Loss 0.0013320859 Test MSE 0.0018769684288298873 Test RE 0.020707923128752536\n",
      "85 Train Loss 0.0013103709 Test MSE 0.001921973779312373 Test RE 0.020954716497719864\n",
      "86 Train Loss 0.0012922533 Test MSE 0.001980309591562973 Test RE 0.021270348509133886\n",
      "87 Train Loss 0.0012708 Test MSE 0.0019676090070486645 Test RE 0.0212020308089013\n",
      "88 Train Loss 0.0012302572 Test MSE 0.0018615155117376817 Test RE 0.0206225036917219\n",
      "89 Train Loss 0.0011758006 Test MSE 0.0018124108705396649 Test RE 0.02034868689960106\n",
      "90 Train Loss 0.001161753 Test MSE 0.001757047510525897 Test RE 0.020035482826142696\n",
      "91 Train Loss 0.0011470526 Test MSE 0.0017202188432453058 Test RE 0.01982439354715323\n",
      "92 Train Loss 0.0010786196 Test MSE 0.0015199380986977468 Test RE 0.018634640161063407\n",
      "93 Train Loss 0.0009980306 Test MSE 0.0015138365448832962 Test RE 0.018597199624030374\n",
      "94 Train Loss 0.0009547924 Test MSE 0.0014632910680358777 Test RE 0.018284092978818903\n",
      "95 Train Loss 0.0009308358 Test MSE 0.0015012017145189548 Test RE 0.018519428743254157\n",
      "96 Train Loss 0.0009129183 Test MSE 0.0015956328751569433 Test RE 0.019093016508975557\n",
      "97 Train Loss 0.00089882687 Test MSE 0.001625550889610758 Test RE 0.019271181660913888\n",
      "98 Train Loss 0.00087832846 Test MSE 0.0016110934723246237 Test RE 0.019185292695638706\n",
      "99 Train Loss 0.00083676813 Test MSE 0.0015554517852716177 Test RE 0.018851084369067957\n",
      "Training time: 68.92\n",
      "5\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.895084 Test MSE 8.58145768148136 Test RE 1.4001952268848905\n",
      "1 Train Loss 57.732822 Test MSE 8.59367763113084 Test RE 1.4011918074712368\n",
      "2 Train Loss 57.311108 Test MSE 8.739002876180843 Test RE 1.4129897174194164\n",
      "3 Train Loss 54.833107 Test MSE 7.985684065470206 Test RE 1.3507162429225497\n",
      "4 Train Loss 46.73204 Test MSE 8.937479742350888 Test RE 1.428945270965481\n",
      "5 Train Loss 46.036835 Test MSE 8.695040268747654 Test RE 1.4094311287463859\n",
      "6 Train Loss 45.873856 Test MSE 8.889017406229634 Test RE 1.4250658688162954\n",
      "7 Train Loss 45.767975 Test MSE 8.6995250079686 Test RE 1.4097945610033147\n",
      "8 Train Loss 45.549263 Test MSE 8.786694459577447 Test RE 1.4168400438663866\n",
      "9 Train Loss 45.044304 Test MSE 8.624523822065061 Test RE 1.4037042774827715\n",
      "10 Train Loss 44.47766 Test MSE 8.538985933121221 Test RE 1.3967259734344026\n",
      "11 Train Loss 43.91926 Test MSE 8.534242566396918 Test RE 1.396337982174229\n",
      "12 Train Loss 43.539536 Test MSE 8.403060195054366 Test RE 1.3855646594202402\n",
      "13 Train Loss 43.394875 Test MSE 8.48584318841346 Test RE 1.3923728980147831\n",
      "14 Train Loss 43.216377 Test MSE 8.390244925793727 Test RE 1.3845077135646142\n",
      "15 Train Loss 43.048866 Test MSE 8.506079212461612 Test RE 1.3940320916316378\n",
      "16 Train Loss 42.961433 Test MSE 8.391296626011995 Test RE 1.3845944834653081\n",
      "17 Train Loss 42.764366 Test MSE 8.521422757198906 Test RE 1.3952888255625389\n",
      "18 Train Loss 42.44419 Test MSE 8.262440331268689 Test RE 1.373922476471171\n",
      "19 Train Loss 42.073586 Test MSE 8.513992763936042 Test RE 1.3946804032574347\n",
      "20 Train Loss 41.717216 Test MSE 8.676811202801014 Test RE 1.4079529243672122\n",
      "21 Train Loss 41.46644 Test MSE 8.618361770343109 Test RE 1.4032027284059505\n",
      "22 Train Loss 41.254467 Test MSE 8.722996731540702 Test RE 1.4116951256008163\n",
      "23 Train Loss 40.567 Test MSE 8.274589851492214 Test RE 1.37493224878862\n",
      "24 Train Loss 38.53528 Test MSE 7.830633041797236 Test RE 1.337539130967779\n",
      "25 Train Loss 37.562344 Test MSE 8.317841132299709 Test RE 1.3785209507678753\n",
      "26 Train Loss 37.14995 Test MSE 8.223319663035928 Test RE 1.3706660209836665\n",
      "27 Train Loss 36.53866 Test MSE 8.13691780969107 Test RE 1.3634462597813073\n",
      "28 Train Loss 32.98015 Test MSE 7.793168273245098 Test RE 1.3343356431643907\n",
      "29 Train Loss 32.1842 Test MSE 7.094625335082963 Test RE 1.273130120300946\n",
      "30 Train Loss 30.649517 Test MSE 6.65524956112178 Test RE 1.233077101841758\n",
      "31 Train Loss 29.698761 Test MSE 7.0924236641800364 Test RE 1.2729325601122647\n",
      "32 Train Loss 28.43037 Test MSE 7.296330368722886 Test RE 1.291101261071436\n",
      "33 Train Loss 26.018024 Test MSE 6.825624818137186 Test RE 1.2487608271443937\n",
      "34 Train Loss 25.009716 Test MSE 6.596895656951918 Test RE 1.2276593271546394\n",
      "35 Train Loss 23.975374 Test MSE 6.148572754970319 Test RE 1.1852097580409717\n",
      "36 Train Loss 22.471928 Test MSE 6.102299114633409 Test RE 1.180741440745354\n",
      "37 Train Loss 19.970856 Test MSE 5.067212774765175 Test RE 1.0759513399266853\n",
      "38 Train Loss 17.98664 Test MSE 4.080479645655451 Test RE 0.9655253221507387\n",
      "39 Train Loss 15.909966 Test MSE 3.9721512201807228 Test RE 0.9526227462481881\n",
      "40 Train Loss 14.784255 Test MSE 3.800591088580204 Test RE 0.931823444752468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 13.711961 Test MSE 3.6534828412003977 Test RE 0.9136115814122343\n",
      "42 Train Loss 12.457459 Test MSE 3.365405895733398 Test RE 0.8768529872978081\n",
      "43 Train Loss 10.314842 Test MSE 2.286236377531473 Test RE 0.7227175910899205\n",
      "44 Train Loss 8.617155 Test MSE 2.2827398231660108 Test RE 0.7221647199356424\n",
      "45 Train Loss 7.388181 Test MSE 1.3580562643939564 Test RE 0.5570150658080512\n",
      "46 Train Loss 6.615237 Test MSE 0.8698253304909198 Test RE 0.44578359850654037\n",
      "47 Train Loss 4.8453603 Test MSE 0.3742219692669417 Test RE 0.292396857102775\n",
      "48 Train Loss 3.3927097 Test MSE 0.27336529344197463 Test RE 0.2499077635907047\n",
      "49 Train Loss 2.7397673 Test MSE 0.1880643609629831 Test RE 0.2072818669376466\n",
      "50 Train Loss 2.1438913 Test MSE 0.1792268100082831 Test RE 0.2023529535668967\n",
      "51 Train Loss 1.5585136 Test MSE 0.1348649013863729 Test RE 0.17553249660550507\n",
      "52 Train Loss 1.3621702 Test MSE 0.12751911880331576 Test RE 0.17068513963025037\n",
      "53 Train Loss 1.2031337 Test MSE 0.09754504119979684 Test RE 0.14928310464370645\n",
      "54 Train Loss 1.0452253 Test MSE 0.08385870040798363 Test RE 0.13841467079052025\n",
      "55 Train Loss 0.9377783 Test MSE 0.09622378201058217 Test RE 0.14826862892554382\n",
      "56 Train Loss 0.85834396 Test MSE 0.0910559056960475 Test RE 0.14423216399367186\n",
      "57 Train Loss 0.79803145 Test MSE 0.08359552103650082 Test RE 0.13819730209865838\n",
      "58 Train Loss 0.75278056 Test MSE 0.08074933798840153 Test RE 0.13582432191047197\n",
      "59 Train Loss 0.65898865 Test MSE 0.06911252660853201 Test RE 0.12565693010287005\n",
      "60 Train Loss 0.55292183 Test MSE 0.057895756606702375 Test RE 0.1150088940510992\n",
      "61 Train Loss 0.5160892 Test MSE 0.06079389890100292 Test RE 0.11785229894971715\n",
      "62 Train Loss 0.46535444 Test MSE 0.04986881885615858 Test RE 0.10673887012699255\n",
      "63 Train Loss 0.43095854 Test MSE 0.038274472553954816 Test RE 0.09351099272781943\n",
      "64 Train Loss 0.39260978 Test MSE 0.030174224028281682 Test RE 0.08302829419538867\n",
      "65 Train Loss 0.37900728 Test MSE 0.03170567099509049 Test RE 0.08510920515989065\n",
      "66 Train Loss 0.3415013 Test MSE 0.030695245554500088 Test RE 0.08374205541517495\n",
      "67 Train Loss 0.3111041 Test MSE 0.033317788860461765 Test RE 0.08724612481254664\n",
      "68 Train Loss 0.22252437 Test MSE 0.025713990920496182 Test RE 0.07664658390998605\n",
      "69 Train Loss 0.2030958 Test MSE 0.027468503153195843 Test RE 0.07921830709906705\n",
      "70 Train Loss 0.19735417 Test MSE 0.02467576694014444 Test RE 0.07508330657279667\n",
      "71 Train Loss 0.18623385 Test MSE 0.021949935953698308 Test RE 0.07081490697292847\n",
      "72 Train Loss 0.17713854 Test MSE 0.020750744303987823 Test RE 0.06885332216390987\n",
      "73 Train Loss 0.16419818 Test MSE 0.016394204104713945 Test RE 0.06120025463522642\n",
      "74 Train Loss 0.15119682 Test MSE 0.016115983861837314 Test RE 0.06067872856425564\n",
      "75 Train Loss 0.14163332 Test MSE 0.01783232966480318 Test RE 0.06382812728559403\n",
      "76 Train Loss 0.1397521 Test MSE 0.017942716602625804 Test RE 0.06402537917109863\n",
      "77 Train Loss 0.12468753 Test MSE 0.016253588180056518 Test RE 0.06093722682630437\n",
      "78 Train Loss 0.12104361 Test MSE 0.015472229722182153 Test RE 0.05945447010204423\n",
      "79 Train Loss 0.11823969 Test MSE 0.015057251164762066 Test RE 0.058651740941032496\n",
      "80 Train Loss 0.111539364 Test MSE 0.013800257618666174 Test RE 0.05615024520628229\n",
      "81 Train Loss 0.10523754 Test MSE 0.011707840979259511 Test RE 0.05171856517819302\n",
      "82 Train Loss 0.09581294 Test MSE 0.0095063812232933 Test RE 0.04660319302204525\n",
      "83 Train Loss 0.088426724 Test MSE 0.008635992649330439 Test RE 0.044418531074165116\n",
      "84 Train Loss 0.084992535 Test MSE 0.008744424489419702 Test RE 0.044696516421952194\n",
      "85 Train Loss 0.07128675 Test MSE 0.010113644265672718 Test RE 0.0480686468984209\n",
      "86 Train Loss 0.060943328 Test MSE 0.00956658333467847 Test RE 0.0467505247306398\n",
      "87 Train Loss 0.057144366 Test MSE 0.008479616137184827 Test RE 0.044014538910658554\n",
      "88 Train Loss 0.05490312 Test MSE 0.008265290138420145 Test RE 0.04345473561318233\n",
      "89 Train Loss 0.052311465 Test MSE 0.008184272311811028 Test RE 0.04324123565578052\n",
      "90 Train Loss 0.04370302 Test MSE 0.00725955031056091 Test RE 0.040725171321522306\n",
      "91 Train Loss 0.033744533 Test MSE 0.006453949354566534 Test RE 0.03839908155185733\n",
      "92 Train Loss 0.029705944 Test MSE 0.00573570502022849 Test RE 0.03619940767482971\n",
      "93 Train Loss 0.029292362 Test MSE 0.005616434530834998 Test RE 0.03582105814744935\n",
      "94 Train Loss 0.028311428 Test MSE 0.005379493320041216 Test RE 0.03505732272141187\n",
      "95 Train Loss 0.026475905 Test MSE 0.005506745400581701 Test RE 0.035469540240701244\n",
      "96 Train Loss 0.025065046 Test MSE 0.005404574500944118 Test RE 0.03513895276557913\n",
      "97 Train Loss 0.024349771 Test MSE 0.005064322512605567 Test RE 0.034014863920841756\n",
      "98 Train Loss 0.023164846 Test MSE 0.004375352244612261 Test RE 0.031616556807023154\n",
      "99 Train Loss 0.02236853 Test MSE 0.0038288309336240154 Test RE 0.029576116978938694\n",
      "Training time: 73.74\n",
      "6\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.970913 Test MSE 8.31762930373267 Test RE 1.378503397416462\n",
      "1 Train Loss 58.726593 Test MSE 8.459343039008623 Test RE 1.3901971011600418\n",
      "2 Train Loss 57.935753 Test MSE 8.250099955248901 Test RE 1.3728960814402582\n",
      "3 Train Loss 54.684097 Test MSE 8.413906695159122 Test RE 1.3864586004591275\n",
      "4 Train Loss 47.551075 Test MSE 8.777513430566566 Test RE 1.4160996374859827\n",
      "5 Train Loss 46.917652 Test MSE 8.52811432259317 Test RE 1.395836553005991\n",
      "6 Train Loss 46.14028 Test MSE 8.477792774302726 Test RE 1.3917122778536188\n",
      "7 Train Loss 45.147873 Test MSE 8.358236165558447 Test RE 1.3818642434771888\n",
      "8 Train Loss 43.554905 Test MSE 8.548695060684695 Test RE 1.3975198111402232\n",
      "9 Train Loss 41.386917 Test MSE 8.715533776095933 Test RE 1.4110911088560227\n",
      "10 Train Loss 38.201622 Test MSE 8.869976577045012 Test RE 1.4235387606421717\n",
      "11 Train Loss 34.347412 Test MSE 8.358039385168714 Test RE 1.381847976565157\n",
      "12 Train Loss 30.497417 Test MSE 8.357427072074113 Test RE 1.3817973582879979\n",
      "13 Train Loss 27.183308 Test MSE 8.320998521858726 Test RE 1.3787825640049731\n",
      "14 Train Loss 23.519352 Test MSE 8.61278036914882 Test RE 1.4027482855540356\n",
      "15 Train Loss 21.372118 Test MSE 8.47089183617772 Test RE 1.391145734425892\n",
      "16 Train Loss 19.37315 Test MSE 8.648834740493125 Test RE 1.4056812750821757\n",
      "17 Train Loss 17.552567 Test MSE 8.89935917834396 Test RE 1.4258946118426514\n",
      "18 Train Loss 15.327566 Test MSE 8.152063378911874 Test RE 1.3647145882734901\n",
      "19 Train Loss 11.658916 Test MSE 6.815815305746597 Test RE 1.2478631701895524\n",
      "20 Train Loss 8.518067 Test MSE 6.4406737038991 Test RE 1.2130360536006521\n",
      "21 Train Loss 4.734654 Test MSE 5.7485744869942685 Test RE 1.1460092995497635\n",
      "22 Train Loss 3.7847612 Test MSE 5.985043501459955 Test RE 1.1693424501033225\n",
      "23 Train Loss 2.985882 Test MSE 5.870466016877433 Test RE 1.1580954343108556\n",
      "24 Train Loss 2.547618 Test MSE 5.690344927274806 Test RE 1.140190338162917\n",
      "25 Train Loss 2.2152941 Test MSE 5.647103989337388 Test RE 1.1358499228584256\n",
      "26 Train Loss 1.9905707 Test MSE 5.6163244404165145 Test RE 1.1327502174802113\n",
      "27 Train Loss 1.8117739 Test MSE 5.5671722813318505 Test RE 1.1277826027826952\n",
      "28 Train Loss 1.6518562 Test MSE 5.582272261020245 Test RE 1.1293110234771162\n",
      "29 Train Loss 1.5443525 Test MSE 5.59919612440541 Test RE 1.131021603034562\n",
      "30 Train Loss 1.4367114 Test MSE 5.625960249393195 Test RE 1.1337215188355716\n",
      "31 Train Loss 1.3611434 Test MSE 5.6102539712050605 Test RE 1.1321378788870413\n",
      "32 Train Loss 1.3001329 Test MSE 5.6603646170029505 Test RE 1.1371827521320497\n",
      "33 Train Loss 1.2406825 Test MSE 5.78314738728614 Test RE 1.14945028062732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 1.2003231 Test MSE 5.801729658331068 Test RE 1.1512954926608927\n",
      "35 Train Loss 1.1472013 Test MSE 5.781452471156331 Test RE 1.1492818287051243\n",
      "36 Train Loss 1.104577 Test MSE 5.8030420379082415 Test RE 1.1514256996289165\n",
      "37 Train Loss 1.0736767 Test MSE 5.828893624345208 Test RE 1.1539875545660108\n",
      "38 Train Loss 1.0442772 Test MSE 5.895639398019279 Test RE 1.160575815875514\n",
      "39 Train Loss 1.0205255 Test MSE 5.900348624229624 Test RE 1.1610392366110431\n",
      "40 Train Loss 0.99563134 Test MSE 5.921176849643016 Test RE 1.163086665085648\n",
      "41 Train Loss 0.9701451 Test MSE 5.973444292953434 Test RE 1.1682087887634578\n",
      "42 Train Loss 0.948418 Test MSE 5.978343691284809 Test RE 1.1686877709710346\n",
      "43 Train Loss 0.93080866 Test MSE 6.011122981357504 Test RE 1.1718873517510242\n",
      "44 Train Loss 0.9024551 Test MSE 6.00316330161362 Test RE 1.1711112124191332\n",
      "45 Train Loss 0.8695562 Test MSE 6.0734313844062155 Test RE 1.1779453034492942\n",
      "46 Train Loss 0.84541094 Test MSE 6.071584418981998 Test RE 1.1777661798584032\n",
      "47 Train Loss 0.8204725 Test MSE 6.137260723441659 Test RE 1.1841189925159652\n",
      "48 Train Loss 0.8048084 Test MSE 6.178868544147636 Test RE 1.1881261049850147\n",
      "49 Train Loss 0.7887887 Test MSE 6.191126294529111 Test RE 1.1893040340273198\n",
      "50 Train Loss 0.7741532 Test MSE 6.229503523187226 Test RE 1.1929844370718672\n",
      "51 Train Loss 0.7598554 Test MSE 6.25040272610845 Test RE 1.1949839180461423\n",
      "52 Train Loss 0.74540925 Test MSE 6.309496666238939 Test RE 1.200619569579282\n",
      "53 Train Loss 0.73533094 Test MSE 6.297981609835215 Test RE 1.1995234824879428\n",
      "54 Train Loss 0.72399694 Test MSE 6.334015015851566 Test RE 1.2029500778201234\n",
      "55 Train Loss 0.7162094 Test MSE 6.37673154854925 Test RE 1.2069996033338524\n",
      "56 Train Loss 0.7090879 Test MSE 6.445961160790574 Test RE 1.2135338710893009\n",
      "57 Train Loss 0.70014584 Test MSE 6.515590510340442 Test RE 1.2200705698238048\n",
      "58 Train Loss 0.69066983 Test MSE 6.535508996265288 Test RE 1.2219340550822482\n",
      "59 Train Loss 0.6831508 Test MSE 6.562193001345824 Test RE 1.2244260476913276\n",
      "60 Train Loss 0.6749272 Test MSE 6.621829292202788 Test RE 1.2299771704697726\n",
      "61 Train Loss 0.6679293 Test MSE 6.64362039778156 Test RE 1.2319993117051553\n",
      "62 Train Loss 0.6588462 Test MSE 6.672905785965479 Test RE 1.2347116811064802\n",
      "63 Train Loss 0.6499185 Test MSE 6.7277353396924156 Test RE 1.239773957972804\n",
      "64 Train Loss 0.6418245 Test MSE 6.7514457561743955 Test RE 1.2419566911962718\n",
      "65 Train Loss 0.63356864 Test MSE 6.771428526554322 Test RE 1.2437932903238014\n",
      "66 Train Loss 0.6269081 Test MSE 6.784289242001442 Test RE 1.2449738745639947\n",
      "67 Train Loss 0.6189307 Test MSE 6.797636150153569 Test RE 1.2461979075355358\n",
      "68 Train Loss 0.61061513 Test MSE 6.8205672628724745 Test RE 1.2482980968139883\n",
      "69 Train Loss 0.60534006 Test MSE 6.840291183966056 Test RE 1.2501017267562033\n",
      "70 Train Loss 0.5980901 Test MSE 6.881417163703093 Test RE 1.2538540972749699\n",
      "71 Train Loss 0.5929598 Test MSE 6.893769783026476 Test RE 1.2549789700689562\n",
      "72 Train Loss 0.58862257 Test MSE 6.893635912457084 Test RE 1.2549667847501669\n",
      "73 Train Loss 0.5844005 Test MSE 6.905730880161441 Test RE 1.2560672294878186\n",
      "74 Train Loss 0.57813925 Test MSE 6.960366852417955 Test RE 1.26102624483851\n",
      "75 Train Loss 0.5722937 Test MSE 6.958978338025718 Test RE 1.260900458334751\n",
      "76 Train Loss 0.5678941 Test MSE 6.966730716696514 Test RE 1.2616025913564057\n",
      "77 Train Loss 0.5627984 Test MSE 6.996774683132471 Test RE 1.2643199899934643\n",
      "78 Train Loss 0.5570537 Test MSE 7.010859806702738 Test RE 1.2655919439141716\n",
      "79 Train Loss 0.5539149 Test MSE 7.01807857775106 Test RE 1.2662433381944282\n",
      "80 Train Loss 0.54845184 Test MSE 7.032021358284068 Test RE 1.2675005336446454\n",
      "81 Train Loss 0.54403985 Test MSE 7.052543177064623 Test RE 1.269348684058511\n",
      "82 Train Loss 0.5390253 Test MSE 7.072885424452399 Test RE 1.271178010827127\n",
      "83 Train Loss 0.53472894 Test MSE 7.09469659881633 Test RE 1.2731365144213762\n",
      "84 Train Loss 0.5302689 Test MSE 7.111412871813144 Test RE 1.274635491576817\n",
      "85 Train Loss 0.52766454 Test MSE 7.116950938549389 Test RE 1.275131711017537\n",
      "86 Train Loss 0.52537495 Test MSE 7.114956697521586 Test RE 1.274953046153973\n",
      "87 Train Loss 0.522438 Test MSE 7.120750955046758 Test RE 1.2754720867591718\n",
      "88 Train Loss 0.5198281 Test MSE 7.142414022443167 Test RE 1.2774107625439695\n",
      "89 Train Loss 0.5171925 Test MSE 7.149487101475545 Test RE 1.2780431111784338\n",
      "90 Train Loss 0.5146025 Test MSE 7.156576380616171 Test RE 1.2786765943449316\n",
      "91 Train Loss 0.5119629 Test MSE 7.161364632798474 Test RE 1.2791042850376269\n",
      "92 Train Loss 0.5101792 Test MSE 7.162452807137681 Test RE 1.2792014617393397\n",
      "93 Train Loss 0.5073696 Test MSE 7.172359797094756 Test RE 1.2800858415124914\n",
      "94 Train Loss 0.50567883 Test MSE 7.1766238447660005 Test RE 1.2804662976095738\n",
      "95 Train Loss 0.5036901 Test MSE 7.169606427251403 Test RE 1.2798401142920175\n",
      "96 Train Loss 0.50206184 Test MSE 7.169477635045476 Test RE 1.2798286189488992\n",
      "97 Train Loss 0.4998238 Test MSE 7.174087385916389 Test RE 1.280239997808449\n",
      "98 Train Loss 0.49809468 Test MSE 7.181104549978992 Test RE 1.2808659630293515\n",
      "99 Train Loss 0.49633121 Test MSE 7.176746433464593 Test RE 1.2804772338123123\n",
      "Training time: 69.42\n",
      "7\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.439148 Test MSE 8.150017723978168 Test RE 1.364543348787223\n",
      "1 Train Loss 53.83869 Test MSE 8.44922657319868 Test RE 1.3893655892673846\n",
      "2 Train Loss 44.865257 Test MSE 7.241355329906472 Test RE 1.2862280890086035\n",
      "3 Train Loss 33.950188 Test MSE 7.078675246393236 Test RE 1.2716981937737568\n",
      "4 Train Loss 27.732138 Test MSE 6.338303017585097 Test RE 1.203357195524542\n",
      "5 Train Loss 23.96095 Test MSE 6.193092661367428 Test RE 1.189492886769115\n",
      "6 Train Loss 21.594603 Test MSE 5.440398629515082 Test RE 1.1148679266931283\n",
      "7 Train Loss 19.772617 Test MSE 4.948065657309237 Test RE 1.0632264869835317\n",
      "8 Train Loss 18.343872 Test MSE 4.817359710941351 Test RE 1.0490896401812964\n",
      "9 Train Loss 15.253273 Test MSE 3.550707440252752 Test RE 0.9006696020209911\n",
      "10 Train Loss 10.737149 Test MSE 3.7464695762856173 Test RE 0.9251649378055237\n",
      "11 Train Loss 8.429895 Test MSE 3.2075609264376665 Test RE 0.8560428761160616\n",
      "12 Train Loss 6.5074663 Test MSE 2.522831745369342 Test RE 0.7591930153239619\n",
      "13 Train Loss 4.928954 Test MSE 2.0467628155963458 Test RE 0.6838200327539274\n",
      "14 Train Loss 4.1795917 Test MSE 2.050054493023907 Test RE 0.6843696838115929\n",
      "15 Train Loss 3.6817422 Test MSE 2.061844686765918 Test RE 0.6863348225715578\n",
      "16 Train Loss 3.1442842 Test MSE 1.964748345597456 Test RE 0.6699795181611254\n",
      "17 Train Loss 2.738832 Test MSE 1.7936478774709852 Test RE 0.6401424891630798\n",
      "18 Train Loss 2.2075467 Test MSE 1.6427323649489383 Test RE 0.6126204177341288\n",
      "19 Train Loss 1.7948595 Test MSE 1.3279171809638752 Test RE 0.5507995227223533\n",
      "20 Train Loss 1.4396377 Test MSE 1.1593261356924278 Test RE 0.5146486923184914\n",
      "21 Train Loss 0.9414979 Test MSE 0.7870244968529169 Test RE 0.4240354692236718\n",
      "22 Train Loss 0.7138773 Test MSE 0.626246221814694 Test RE 0.37825146578358587\n",
      "23 Train Loss 0.42247254 Test MSE 0.3853728212173598 Test RE 0.2967212169214017\n",
      "24 Train Loss 0.27369112 Test MSE 0.2527282137834297 Test RE 0.24028957220498828\n",
      "25 Train Loss 0.19765815 Test MSE 0.218803104691662 Test RE 0.22358095163786568\n",
      "26 Train Loss 0.14860168 Test MSE 0.18922786328883986 Test RE 0.2079220761322223\n",
      "27 Train Loss 0.11676251 Test MSE 0.18238935121092964 Test RE 0.20413045308339264\n",
      "28 Train Loss 0.09614302 Test MSE 0.14968739767497222 Test RE 0.1849271511877496\n",
      "29 Train Loss 0.07811947 Test MSE 0.11345439339928262 Test RE 0.160997346922565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 0.0696759 Test MSE 0.0798179787837687 Test RE 0.13503875437930926\n",
      "31 Train Loss 0.05965551 Test MSE 0.03839433073308238 Test RE 0.0936572951541064\n",
      "32 Train Loss 0.050292116 Test MSE 0.022590445750557814 Test RE 0.07184068430866715\n",
      "33 Train Loss 0.0390551 Test MSE 0.015398659493758368 Test RE 0.05931294909652598\n",
      "34 Train Loss 0.03178508 Test MSE 0.010993162767693724 Test RE 0.050115190946860774\n",
      "35 Train Loss 0.02628035 Test MSE 0.007390348226588425 Test RE 0.041090413484548616\n",
      "36 Train Loss 0.021866094 Test MSE 0.006063561110476804 Test RE 0.037219620420581065\n",
      "37 Train Loss 0.019512665 Test MSE 0.0046497698633727585 Test RE 0.032592958935476174\n",
      "38 Train Loss 0.016966665 Test MSE 0.0036776060472162343 Test RE 0.028986158503995173\n",
      "39 Train Loss 0.015280616 Test MSE 0.0029040011030781665 Test RE 0.025757662523260165\n",
      "40 Train Loss 0.013480533 Test MSE 0.002365701671215877 Test RE 0.02324813123917223\n",
      "41 Train Loss 0.01013482 Test MSE 0.0022844711709066406 Test RE 0.022845512291081508\n",
      "42 Train Loss 0.009100258 Test MSE 0.0018090547870891337 Test RE 0.020329838100970297\n",
      "43 Train Loss 0.0081155645 Test MSE 0.0012358883558692068 Test RE 0.016803419916516685\n",
      "44 Train Loss 0.007538508 Test MSE 0.0010053993829686049 Test RE 0.015155747719570463\n",
      "45 Train Loss 0.006834005 Test MSE 0.001042849571962817 Test RE 0.015435435734016578\n",
      "46 Train Loss 0.0060775187 Test MSE 0.0010713822196735871 Test RE 0.01564516967865616\n",
      "47 Train Loss 0.0055925986 Test MSE 0.0010281052505000782 Test RE 0.015325930395327612\n",
      "48 Train Loss 0.005113525 Test MSE 0.00098690507010217 Test RE 0.015015705789368726\n",
      "49 Train Loss 0.004513396 Test MSE 0.0009175685839411833 Test RE 0.014478625272099487\n",
      "50 Train Loss 0.004244919 Test MSE 0.0008069492969202595 Test RE 0.013577855549682858\n",
      "51 Train Loss 0.0039383373 Test MSE 0.0006729803330934803 Test RE 0.012399644860307719\n",
      "52 Train Loss 0.0034469601 Test MSE 0.0005661073876412743 Test RE 0.01137253995979203\n",
      "53 Train Loss 0.003352861 Test MSE 0.0004996647029210598 Test RE 0.010684332524119605\n",
      "54 Train Loss 0.0029308312 Test MSE 0.00037252496885346864 Test RE 0.00922541164497199\n",
      "55 Train Loss 0.0026319022 Test MSE 0.0003644925654612449 Test RE 0.00912541023772162\n",
      "56 Train Loss 0.0024650658 Test MSE 0.0003716074585001283 Test RE 0.009214043777460587\n",
      "57 Train Loss 0.0023138085 Test MSE 0.0003841064144075206 Test RE 0.0093677186822054\n",
      "58 Train Loss 0.0022149787 Test MSE 0.0003674959374185 Test RE 0.009162929212956658\n",
      "59 Train Loss 0.002054099 Test MSE 0.00038362633808961607 Test RE 0.009361862719095348\n",
      "60 Train Loss 0.0018975422 Test MSE 0.0003867688479684583 Test RE 0.009400128786939955\n",
      "61 Train Loss 0.0018286129 Test MSE 0.00039875333670312443 Test RE 0.009544654787208517\n",
      "62 Train Loss 0.0017228654 Test MSE 0.00043763973816560343 Test RE 0.009999227168191488\n",
      "63 Train Loss 0.0015365309 Test MSE 0.0004003321980685584 Test RE 0.009563532120237004\n",
      "64 Train Loss 0.0013896475 Test MSE 0.000389016478619997 Test RE 0.009427402714564069\n",
      "65 Train Loss 0.0013312628 Test MSE 0.00037796962834019853 Test RE 0.009292584353231634\n",
      "66 Train Loss 0.0012812301 Test MSE 0.00035376193673989433 Test RE 0.008990081144949355\n",
      "67 Train Loss 0.0010793856 Test MSE 0.00031325901325495386 Test RE 0.00845979517241936\n",
      "68 Train Loss 0.0010177672 Test MSE 0.00030629207728611864 Test RE 0.008365192548186016\n",
      "69 Train Loss 0.0009779168 Test MSE 0.0003286103641218929 Test RE 0.008664603396169075\n",
      "70 Train Loss 0.00093211484 Test MSE 0.00033540143147820894 Test RE 0.008753676970876673\n",
      "71 Train Loss 0.0009067434 Test MSE 0.00032497502549704097 Test RE 0.008616542878420237\n",
      "72 Train Loss 0.00088747643 Test MSE 0.0002985300725625278 Test RE 0.00825851769276261\n",
      "73 Train Loss 0.0008659173 Test MSE 0.0002779595785993787 Test RE 0.007968909277030284\n",
      "74 Train Loss 0.00083272276 Test MSE 0.000251115160055275 Test RE 0.007574335298127377\n",
      "75 Train Loss 0.0007798119 Test MSE 0.00022342126756282459 Test RE 0.007144474919483188\n",
      "76 Train Loss 0.0007609272 Test MSE 0.0002136385999912284 Test RE 0.006986311117581139\n",
      "77 Train Loss 0.0007406134 Test MSE 0.00022463659022726773 Test RE 0.007163880114421346\n",
      "78 Train Loss 0.00070257555 Test MSE 0.00019404606679236853 Test RE 0.006658255897137338\n",
      "79 Train Loss 0.0006004463 Test MSE 0.0001888628740871683 Test RE 0.006568729189734066\n",
      "80 Train Loss 0.0005700561 Test MSE 0.00018977862767439652 Test RE 0.006584635077056743\n",
      "81 Train Loss 0.0005585553 Test MSE 0.00017766115366793945 Test RE 0.006370951504349648\n",
      "82 Train Loss 0.00055480184 Test MSE 0.00018076101893802797 Test RE 0.006426291931580265\n",
      "83 Train Loss 0.00054307457 Test MSE 0.00017872168098731869 Test RE 0.006389938533394714\n",
      "84 Train Loss 0.0005161682 Test MSE 0.00017391974473786095 Test RE 0.006303510853460765\n",
      "85 Train Loss 0.00047590767 Test MSE 0.00015478562763077963 Test RE 0.005946663670878055\n",
      "86 Train Loss 0.00046527287 Test MSE 0.00015558581246188086 Test RE 0.005962014889686356\n",
      "87 Train Loss 0.00046102417 Test MSE 0.00016624163901705726 Test RE 0.006162798473245859\n",
      "88 Train Loss 0.00043694017 Test MSE 0.0001405893317803682 Test RE 0.005667404930317097\n",
      "89 Train Loss 0.00038818014 Test MSE 0.00013801421908490573 Test RE 0.0056152613777294335\n",
      "90 Train Loss 0.00038217395 Test MSE 0.00013841140516848363 Test RE 0.005623335550691769\n",
      "91 Train Loss 0.0003807781 Test MSE 0.0001383476017589643 Test RE 0.005622039308746738\n",
      "92 Train Loss 0.00036779288 Test MSE 0.0001293572880584645 Test RE 0.005436301204889417\n",
      "93 Train Loss 0.00034218642 Test MSE 0.00012850230908346725 Test RE 0.005418305973126212\n",
      "94 Train Loss 0.00032349915 Test MSE 0.00013011787134234668 Test RE 0.005452259717510872\n",
      "95 Train Loss 0.00031699767 Test MSE 0.0001248784210966519 Test RE 0.005341358893555092\n",
      "96 Train Loss 0.0003083344 Test MSE 0.0001259010516208952 Test RE 0.005363184520334109\n",
      "97 Train Loss 0.00028946833 Test MSE 0.00011921438446636804 Test RE 0.0052188208724164445\n",
      "98 Train Loss 0.00026703905 Test MSE 0.00010605601339411499 Test RE 0.004922386481221059\n",
      "99 Train Loss 0.00025454347 Test MSE 0.00010906731530201362 Test RE 0.0049917792546130026\n",
      "Training time: 69.41\n",
      "8\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 47.57283 Test MSE 10.28853556690136 Test RE 1.5331506868408797\n",
      "1 Train Loss 31.924644 Test MSE 7.352427129479114 Test RE 1.2960549787065485\n",
      "2 Train Loss 24.682379 Test MSE 7.29876979474335 Test RE 1.2913170738598168\n",
      "3 Train Loss 20.848648 Test MSE 7.954301457392998 Test RE 1.3480595684378889\n",
      "4 Train Loss 17.658016 Test MSE 7.713142358639836 Test RE 1.3274670006317297\n",
      "5 Train Loss 15.84749 Test MSE 7.753759307056818 Test RE 1.3309575924470487\n",
      "6 Train Loss 14.429299 Test MSE 7.7596780948396145 Test RE 1.3314654849710736\n",
      "7 Train Loss 12.5571 Test MSE 7.445470848108588 Test RE 1.3042298750308507\n",
      "8 Train Loss 10.517273 Test MSE 7.1855416735559015 Test RE 1.281261618243245\n",
      "9 Train Loss 8.738384 Test MSE 6.716225717211223 Test RE 1.2387130186212452\n",
      "10 Train Loss 7.9840264 Test MSE 6.707905167869687 Test RE 1.23794547689472\n",
      "11 Train Loss 7.218123 Test MSE 6.371602131846761 Test RE 1.206514052905403\n",
      "12 Train Loss 6.6381626 Test MSE 6.126975669191121 Test RE 1.1831263807222345\n",
      "13 Train Loss 5.8885865 Test MSE 5.848083327492417 Test RE 1.155885554767017\n",
      "14 Train Loss 4.830595 Test MSE 5.6208263384094135 Test RE 1.1332041179343704\n",
      "15 Train Loss 3.694137 Test MSE 5.187068730762434 Test RE 1.0886018338344976\n",
      "16 Train Loss 2.8239262 Test MSE 5.0111776543963025 Test RE 1.069985666705877\n",
      "17 Train Loss 2.399467 Test MSE 4.942361888713053 Test RE 1.0626135053737553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 2.1631484 Test MSE 4.986181407519974 Test RE 1.0673137337170873\n",
      "19 Train Loss 2.0548196 Test MSE 4.884543842082474 Test RE 1.0563797470399285\n",
      "20 Train Loss 1.9099071 Test MSE 4.740269470078308 Test RE 1.0406617103996374\n",
      "21 Train Loss 1.8018258 Test MSE 4.6791803348112895 Test RE 1.0339343211733456\n",
      "22 Train Loss 1.7131835 Test MSE 4.651897955929722 Test RE 1.0309156914384547\n",
      "23 Train Loss 1.6381972 Test MSE 4.735717116719009 Test RE 1.0401618867268054\n",
      "24 Train Loss 1.5724492 Test MSE 4.772376355084665 Test RE 1.0441800778138148\n",
      "25 Train Loss 1.5344667 Test MSE 4.756483646851865 Test RE 1.04243999206282\n",
      "26 Train Loss 1.5050151 Test MSE 4.756218888121082 Test RE 1.042410979145876\n",
      "27 Train Loss 1.4717829 Test MSE 4.737575417469294 Test RE 1.0403659470605149\n",
      "28 Train Loss 1.440561 Test MSE 4.684037426650797 Test RE 1.0344708052428244\n",
      "29 Train Loss 1.4123875 Test MSE 4.605499483766103 Test RE 1.025761581812349\n",
      "30 Train Loss 1.3921486 Test MSE 4.589793120172923 Test RE 1.0240109851707069\n",
      "31 Train Loss 1.3722587 Test MSE 4.5572778840258525 Test RE 1.0203773640960354\n",
      "32 Train Loss 1.351225 Test MSE 4.521999463150312 Test RE 1.0164202608860973\n",
      "33 Train Loss 1.3277658 Test MSE 4.47075207390094 Test RE 1.010644352795868\n",
      "34 Train Loss 1.3078934 Test MSE 4.459407099282441 Test RE 1.009361233373999\n",
      "35 Train Loss 1.2909386 Test MSE 4.444548560678311 Test RE 1.0076782577868006\n",
      "36 Train Loss 1.2759379 Test MSE 4.4067861134046025 Test RE 1.003388331780352\n",
      "37 Train Loss 1.261641 Test MSE 4.387143571460685 Test RE 1.0011496130742448\n",
      "38 Train Loss 1.2487043 Test MSE 4.366058461741511 Test RE 0.9987408961370893\n",
      "39 Train Loss 1.2330412 Test MSE 4.356674663179852 Test RE 0.9976670414699014\n",
      "40 Train Loss 1.2196503 Test MSE 4.322889584984979 Test RE 0.9937911656666135\n",
      "41 Train Loss 1.2047195 Test MSE 4.294789604459598 Test RE 0.9905559406116419\n",
      "42 Train Loss 1.1837391 Test MSE 4.245071525105373 Test RE 0.9848057288132035\n",
      "43 Train Loss 1.1537244 Test MSE 4.124172992605283 Test RE 0.9706809292838882\n",
      "44 Train Loss 1.1061941 Test MSE 3.955021952317192 Test RE 0.9505665103166957\n",
      "45 Train Loss 1.0478051 Test MSE 3.904557500090054 Test RE 0.9444826223261051\n",
      "46 Train Loss 1.0012264 Test MSE 3.7975327492077375 Test RE 0.9314484496781037\n",
      "47 Train Loss 0.92350537 Test MSE 3.510298432434321 Test RE 0.895529878696518\n",
      "48 Train Loss 0.8606769 Test MSE 3.3937060430109978 Test RE 0.8805320559364195\n",
      "49 Train Loss 0.8112446 Test MSE 3.2330013150461197 Test RE 0.859430972524155\n",
      "50 Train Loss 0.75280464 Test MSE 3.180663150574981 Test RE 0.8524460426983163\n",
      "51 Train Loss 0.7056352 Test MSE 3.135483745043301 Test RE 0.8463701479597274\n",
      "52 Train Loss 0.657278 Test MSE 3.063676358070958 Test RE 0.8366224280065219\n",
      "53 Train Loss 0.6088202 Test MSE 3.0166618534595186 Test RE 0.8301782978439461\n",
      "54 Train Loss 0.56769335 Test MSE 3.0023586396584157 Test RE 0.828207853881591\n",
      "55 Train Loss 0.544518 Test MSE 2.9695854738801652 Test RE 0.8236751721581986\n",
      "56 Train Loss 0.52766985 Test MSE 2.962944589909198 Test RE 0.8227536642874519\n",
      "57 Train Loss 0.51439977 Test MSE 2.9762834025931477 Test RE 0.82460355261271\n",
      "58 Train Loss 0.5023267 Test MSE 2.9929268210451188 Test RE 0.8269059356652894\n",
      "59 Train Loss 0.49382308 Test MSE 3.007743978576568 Test RE 0.8289503004470049\n",
      "60 Train Loss 0.48469615 Test MSE 3.036841415718319 Test RE 0.8329503539508222\n",
      "61 Train Loss 0.47766176 Test MSE 3.0178299376415167 Test RE 0.8303390093077885\n",
      "62 Train Loss 0.47149512 Test MSE 3.0132723573082565 Test RE 0.829711776049118\n",
      "63 Train Loss 0.46530554 Test MSE 3.019801965004798 Test RE 0.8306102611454734\n",
      "64 Train Loss 0.4587987 Test MSE 3.020354962677965 Test RE 0.8306863099262555\n",
      "65 Train Loss 0.45392674 Test MSE 3.036783196231769 Test RE 0.8329423696395408\n",
      "66 Train Loss 0.44956082 Test MSE 3.047922168077995 Test RE 0.8344685946772913\n",
      "67 Train Loss 0.44537032 Test MSE 3.0525078621044432 Test RE 0.8350961007624603\n",
      "68 Train Loss 0.44034737 Test MSE 3.0494768962395438 Test RE 0.8346813964401285\n",
      "69 Train Loss 0.4353867 Test MSE 3.0519894712488878 Test RE 0.835025187830735\n",
      "70 Train Loss 0.4317846 Test MSE 3.048499596507056 Test RE 0.8345476359132392\n",
      "71 Train Loss 0.42845577 Test MSE 3.0555718532050555 Test RE 0.8355151144669825\n",
      "72 Train Loss 0.42503327 Test MSE 3.061029673843413 Test RE 0.8362609743874201\n",
      "73 Train Loss 0.4205374 Test MSE 3.0857961833245664 Test RE 0.8396372142384803\n",
      "74 Train Loss 0.41600478 Test MSE 3.106251297530312 Test RE 0.8424155096684106\n",
      "75 Train Loss 0.41182017 Test MSE 3.108497037506712 Test RE 0.842719977045663\n",
      "76 Train Loss 0.40767702 Test MSE 3.122788190861774 Test RE 0.8446549362458753\n",
      "77 Train Loss 0.40309474 Test MSE 3.1352939015255363 Test RE 0.8463445250684144\n",
      "78 Train Loss 0.3985888 Test MSE 3.1339126270590185 Test RE 0.846158073191195\n",
      "79 Train Loss 0.39390072 Test MSE 3.146406003935389 Test RE 0.8478430048067457\n",
      "80 Train Loss 0.3893311 Test MSE 3.1661149909435697 Test RE 0.8504942901873401\n",
      "81 Train Loss 0.3851403 Test MSE 3.2040095418746715 Test RE 0.8555688431210396\n",
      "82 Train Loss 0.3807106 Test MSE 3.2186671999693157 Test RE 0.8575236321826691\n",
      "83 Train Loss 0.37451714 Test MSE 3.229664088783917 Test RE 0.8589872894168651\n",
      "84 Train Loss 0.36931407 Test MSE 3.24937236800615 Test RE 0.861604189009244\n",
      "85 Train Loss 0.3646226 Test MSE 3.262665769047007 Test RE 0.8633648304831952\n",
      "86 Train Loss 0.35885906 Test MSE 3.277605123035051 Test RE 0.8653391948090622\n",
      "87 Train Loss 0.35473946 Test MSE 3.282813359458405 Test RE 0.8660264499786986\n",
      "88 Train Loss 0.34944353 Test MSE 3.2778756544677936 Test RE 0.865374906344306\n",
      "89 Train Loss 0.34512028 Test MSE 3.2750232483055117 Test RE 0.8649982999366935\n",
      "90 Train Loss 0.340329 Test MSE 3.2798243805561853 Test RE 0.8656321046438589\n",
      "91 Train Loss 0.33638716 Test MSE 3.2871577869399826 Test RE 0.8665993039224716\n",
      "92 Train Loss 0.33245224 Test MSE 3.2937372612503664 Test RE 0.8674661496837289\n",
      "93 Train Loss 0.3282348 Test MSE 3.3041369984173885 Test RE 0.8688345511898042\n",
      "94 Train Loss 0.32418877 Test MSE 3.3132328271729645 Test RE 0.8700296195185774\n",
      "95 Train Loss 0.32080266 Test MSE 3.3295546433682635 Test RE 0.8721699788680929\n",
      "96 Train Loss 0.318586 Test MSE 3.3457139416257404 Test RE 0.8742838645893584\n",
      "97 Train Loss 0.31572047 Test MSE 3.3437039796433394 Test RE 0.8740212089403834\n",
      "98 Train Loss 0.31311634 Test MSE 3.35373429279014 Test RE 0.8753311547089438\n",
      "99 Train Loss 0.31040782 Test MSE 3.362899522358861 Test RE 0.8765264100011317\n",
      "Training time: 68.19\n",
      "9\n",
      "KG_rowdy_tune21\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.64715 Test MSE 8.62466324016063 Test RE 1.4037156230938603\n",
      "1 Train Loss 56.486492 Test MSE 8.630441723355425 Test RE 1.4041857857382718\n",
      "2 Train Loss 56.412518 Test MSE 8.720729539858041 Test RE 1.411511657032706\n",
      "3 Train Loss 55.833496 Test MSE 8.646693742824855 Test RE 1.4055072778502966\n",
      "4 Train Loss 54.169968 Test MSE 8.883654451764508 Test RE 1.4246359159824988\n",
      "5 Train Loss 50.94709 Test MSE 8.929721785449797 Test RE 1.4283249561308704\n",
      "6 Train Loss 43.206696 Test MSE 8.380834916980104 Test RE 1.3837311042476166\n",
      "7 Train Loss 41.466526 Test MSE 8.442378777614735 Test RE 1.3888024596156094\n",
      "8 Train Loss 38.587257 Test MSE 8.572020717213531 Test RE 1.3994251230438275\n",
      "9 Train Loss 34.448547 Test MSE 9.50907465722647 Test RE 1.4739311212516562\n",
      "10 Train Loss 31.008945 Test MSE 9.229120968509454 Test RE 1.452072262145227\n",
      "11 Train Loss 27.105625 Test MSE 9.01359788857278 Test RE 1.4350173438934535\n",
      "12 Train Loss 23.299368 Test MSE 9.00174204413615 Test RE 1.4340732735665764\n",
      "13 Train Loss 16.959894 Test MSE 8.497533856313787 Test RE 1.3933316811494767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 11.307137 Test MSE 8.576399069955363 Test RE 1.39978247137673\n",
      "15 Train Loss 8.444221 Test MSE 8.019837078032737 Test RE 1.3536015192847612\n",
      "16 Train Loss 5.2343044 Test MSE 7.0693557960080495 Test RE 1.2708607890920893\n",
      "17 Train Loss 3.8369377 Test MSE 6.8134538082186635 Test RE 1.247646975871434\n",
      "18 Train Loss 2.9165099 Test MSE 6.496212136467582 Test RE 1.2182548794977324\n",
      "19 Train Loss 2.424276 Test MSE 6.351267816454293 Test RE 1.204587281411086\n",
      "20 Train Loss 2.1588821 Test MSE 6.212795878379952 Test RE 1.1913835596836972\n",
      "21 Train Loss 1.996441 Test MSE 6.1427851805485165 Test RE 1.184651815173449\n",
      "22 Train Loss 1.8834658 Test MSE 6.018931732764474 Test RE 1.1726482750484644\n",
      "23 Train Loss 1.780879 Test MSE 6.086622898710809 Test RE 1.1792238602371805\n",
      "24 Train Loss 1.6998194 Test MSE 5.894888203413311 Test RE 1.1605018759678671\n",
      "25 Train Loss 1.6383017 Test MSE 5.878959215515836 Test RE 1.1589328788622295\n",
      "26 Train Loss 1.5800846 Test MSE 5.917318807724692 Test RE 1.162707689048084\n",
      "27 Train Loss 1.5261203 Test MSE 5.886115640027545 Test RE 1.1596380456178448\n",
      "28 Train Loss 1.4600759 Test MSE 5.850705292805961 Test RE 1.1561446441162746\n",
      "29 Train Loss 1.4152954 Test MSE 5.799910457407422 Test RE 1.1511149773528147\n",
      "30 Train Loss 1.3709667 Test MSE 5.834020183930188 Test RE 1.1544949137770555\n",
      "31 Train Loss 1.3283825 Test MSE 5.812915718029325 Test RE 1.152404839290977\n",
      "32 Train Loss 1.3031647 Test MSE 5.821458498472808 Test RE 1.1532513273228169\n",
      "33 Train Loss 1.2733095 Test MSE 5.8690155936496 Test RE 1.1579523594443029\n",
      "34 Train Loss 1.2379999 Test MSE 5.947270208309227 Test RE 1.1656465848907023\n",
      "35 Train Loss 1.205814 Test MSE 5.974091768974889 Test RE 1.1682720995307585\n",
      "36 Train Loss 1.1815782 Test MSE 6.008895775479221 Test RE 1.1716702312383478\n",
      "37 Train Loss 1.1526875 Test MSE 6.052396854879184 Test RE 1.1759037050223196\n",
      "38 Train Loss 1.1272478 Test MSE 6.044192479362781 Test RE 1.1751064318533686\n",
      "39 Train Loss 1.1043794 Test MSE 6.035981958588473 Test RE 1.1743080196082474\n",
      "40 Train Loss 1.078991 Test MSE 6.053435667506977 Test RE 1.1760046147310057\n",
      "41 Train Loss 1.0603193 Test MSE 6.029816452378497 Test RE 1.1737081128098124\n",
      "42 Train Loss 1.0395706 Test MSE 5.992186423436825 Test RE 1.170040024921696\n",
      "43 Train Loss 1.0172217 Test MSE 6.002984677259923 Test RE 1.1710937890600601\n",
      "44 Train Loss 0.9865204 Test MSE 6.038308363738352 Test RE 1.174534300357436\n",
      "45 Train Loss 0.960057 Test MSE 6.060546332041482 Test RE 1.1766951085721078\n",
      "46 Train Loss 0.9390644 Test MSE 6.05408127233185 Test RE 1.1760673240792876\n",
      "47 Train Loss 0.92248666 Test MSE 6.053194250509601 Test RE 1.1759811643840237\n",
      "48 Train Loss 0.900542 Test MSE 6.086566224286268 Test RE 1.1792183701657264\n",
      "49 Train Loss 0.88448775 Test MSE 6.068088383618625 Test RE 1.1774270504961253\n",
      "50 Train Loss 0.8660313 Test MSE 6.069281858689643 Test RE 1.177542833313985\n",
      "51 Train Loss 0.85200137 Test MSE 6.0822335726521315 Test RE 1.178798588982469\n",
      "52 Train Loss 0.837847 Test MSE 6.132391376229623 Test RE 1.1836491550019028\n",
      "53 Train Loss 0.8261626 Test MSE 6.131502644717829 Test RE 1.1835633822295635\n",
      "54 Train Loss 0.81218964 Test MSE 6.134119189524217 Test RE 1.1838158909933372\n",
      "55 Train Loss 0.8018882 Test MSE 6.140097936010018 Test RE 1.1843926658410473\n",
      "56 Train Loss 0.79096305 Test MSE 6.175939237188639 Test RE 1.1878444354010227\n",
      "57 Train Loss 0.7791445 Test MSE 6.161138786806833 Test RE 1.1864202651287472\n",
      "58 Train Loss 0.76957136 Test MSE 6.170485799069294 Test RE 1.1873198782032406\n",
      "59 Train Loss 0.7609217 Test MSE 6.209733233615146 Test RE 1.1910898727126256\n",
      "60 Train Loss 0.7534832 Test MSE 6.201761429952 Test RE 1.1903250907503504\n",
      "61 Train Loss 0.74577487 Test MSE 6.215654303590904 Test RE 1.191657598076031\n",
      "62 Train Loss 0.740067 Test MSE 6.235757510039254 Test RE 1.1935831234148258\n",
      "63 Train Loss 0.7339418 Test MSE 6.254972590768782 Test RE 1.1954206832610719\n",
      "64 Train Loss 0.7277006 Test MSE 6.2722320055292995 Test RE 1.1970688158453815\n",
      "65 Train Loss 0.7230326 Test MSE 6.277108231837468 Test RE 1.1975340445221572\n",
      "66 Train Loss 0.71923846 Test MSE 6.274344575934413 Test RE 1.1972703931503828\n",
      "67 Train Loss 0.7132254 Test MSE 6.263100311755591 Test RE 1.1961970968601903\n",
      "68 Train Loss 0.7073827 Test MSE 6.2785729575713045 Test RE 1.1976737550826992\n",
      "69 Train Loss 0.7026127 Test MSE 6.304536543540391 Test RE 1.2001475516388593\n",
      "70 Train Loss 0.6975305 Test MSE 6.333435133389119 Test RE 1.2028950111982386\n",
      "71 Train Loss 0.6933079 Test MSE 6.344993212010449 Test RE 1.2039921107601996\n",
      "72 Train Loss 0.68957543 Test MSE 6.35848035776183 Test RE 1.2052710559424369\n",
      "73 Train Loss 0.6855651 Test MSE 6.366124970043 Test RE 1.205995369118154\n",
      "74 Train Loss 0.6820875 Test MSE 6.395916942660382 Test RE 1.2088139631961676\n",
      "75 Train Loss 0.67857945 Test MSE 6.403082860311955 Test RE 1.2094909448139501\n",
      "76 Train Loss 0.6745409 Test MSE 6.4132031276497905 Test RE 1.210446386061513\n",
      "77 Train Loss 0.670407 Test MSE 6.428808979569738 Test RE 1.2119182378732898\n",
      "78 Train Loss 0.6664051 Test MSE 6.439738588890856 Test RE 1.2129479906551128\n",
      "79 Train Loss 0.66320723 Test MSE 6.450649892301385 Test RE 1.2139751474198468\n",
      "80 Train Loss 0.65989256 Test MSE 6.468173629677988 Test RE 1.2156229622815096\n",
      "81 Train Loss 0.6543815 Test MSE 6.495193618271957 Test RE 1.2181593728105147\n",
      "82 Train Loss 0.6499359 Test MSE 6.512117953670295 Test RE 1.2197454013799978\n",
      "83 Train Loss 0.64576226 Test MSE 6.527306968792688 Test RE 1.2211670541367867\n",
      "84 Train Loss 0.64066947 Test MSE 6.536815046720205 Test RE 1.2220561441044042\n",
      "85 Train Loss 0.6370469 Test MSE 6.547883774243134 Test RE 1.2230903545803098\n",
      "86 Train Loss 0.6333766 Test MSE 6.566255825846307 Test RE 1.2248050260604788\n",
      "87 Train Loss 0.62941897 Test MSE 6.592531226020155 Test RE 1.2272531572592338\n",
      "88 Train Loss 0.6247526 Test MSE 6.623018207055668 Test RE 1.2300875835013723\n",
      "89 Train Loss 0.6201464 Test MSE 6.636510671481032 Test RE 1.2313399180262696\n",
      "90 Train Loss 0.6176265 Test MSE 6.665808461237952 Test RE 1.2340548846975683\n",
      "91 Train Loss 0.61471784 Test MSE 6.681641509259127 Test RE 1.2355196178687886\n",
      "92 Train Loss 0.61207056 Test MSE 6.681862504087156 Test RE 1.2355400500625402\n",
      "93 Train Loss 0.60781866 Test MSE 6.700209477774808 Test RE 1.237235152396308\n",
      "94 Train Loss 0.6049044 Test MSE 6.725210190901443 Test RE 1.2395412713877447\n",
      "95 Train Loss 0.6009854 Test MSE 6.735953630581144 Test RE 1.2405309521810077\n",
      "96 Train Loss 0.59790856 Test MSE 6.766727338257705 Test RE 1.2433614522198249\n",
      "97 Train Loss 0.5947263 Test MSE 6.765810173382357 Test RE 1.2432771865151186\n",
      "98 Train Loss 0.59207064 Test MSE 6.778701577512254 Test RE 1.2444610773478688\n",
      "99 Train Loss 0.5889679 Test MSE 6.813077690656192 Test RE 1.247612538974315\n",
      "Training time: 68.99\n",
      "0\n",
      "KG_rowdy_tune22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 52.677826 Test MSE 7.987510494689486 Test RE 1.350870697227963\n",
      "1 Train Loss 29.120327 Test MSE 6.246264067034839 Test RE 1.1945882275441362\n",
      "2 Train Loss 21.327188 Test MSE 5.751060617463185 Test RE 1.1462570845149003\n",
      "3 Train Loss 17.364117 Test MSE 5.435789811316072 Test RE 1.1143955980450764\n",
      "4 Train Loss 13.4724 Test MSE 5.868164068129376 Test RE 1.1578683537250007\n",
      "5 Train Loss 11.263642 Test MSE 5.576131689952291 Test RE 1.1286897242674045\n",
      "6 Train Loss 9.896631 Test MSE 5.390608090775543 Test RE 1.1097545637182256\n",
      "7 Train Loss 8.79917 Test MSE 5.392198394704787 Test RE 1.109918248117934\n",
      "8 Train Loss 7.764763 Test MSE 5.397696674964673 Test RE 1.110483980891908\n",
      "9 Train Loss 6.985961 Test MSE 5.359581281698256 Test RE 1.1065562388818695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 6.1439075 Test MSE 4.991849325722904 Test RE 1.0679201826488405\n",
      "11 Train Loss 5.282592 Test MSE 4.734330579020015 Test RE 1.040009604695006\n",
      "12 Train Loss 4.572866 Test MSE 4.297634943218752 Test RE 0.9908840126256097\n",
      "13 Train Loss 3.7910593 Test MSE 3.683509170857972 Test RE 0.917358180274676\n",
      "14 Train Loss 3.0694962 Test MSE 3.2542549353402452 Test RE 0.8622512772556699\n",
      "15 Train Loss 2.5898643 Test MSE 2.8572735955989845 Test RE 0.8079490491934239\n",
      "16 Train Loss 2.1898186 Test MSE 2.6065351544208717 Test RE 0.7716846358827769\n",
      "17 Train Loss 1.941961 Test MSE 2.3969148684616295 Test RE 0.7400045072991073\n",
      "18 Train Loss 1.7590107 Test MSE 2.4097239375876165 Test RE 0.7419791579520563\n",
      "19 Train Loss 1.598136 Test MSE 2.2171743770724737 Test RE 0.7117180591710165\n",
      "20 Train Loss 1.4668865 Test MSE 2.0644694661760283 Test RE 0.6867715442498551\n",
      "21 Train Loss 1.3975831 Test MSE 1.8715878696392902 Test RE 0.6539027610568782\n",
      "22 Train Loss 1.2748121 Test MSE 1.5566311314350563 Test RE 0.5963495778521228\n",
      "23 Train Loss 1.1041616 Test MSE 1.4638726072748753 Test RE 0.5783086687334706\n",
      "24 Train Loss 0.9541248 Test MSE 1.1813451074028578 Test RE 0.5195130409140027\n",
      "25 Train Loss 0.79576665 Test MSE 0.8687852387467855 Test RE 0.4455169964020637\n",
      "26 Train Loss 0.6354076 Test MSE 0.6094710828028441 Test RE 0.37315100243625327\n",
      "27 Train Loss 0.4863178 Test MSE 0.40837309467255656 Test RE 0.3054475323406829\n",
      "28 Train Loss 0.37989685 Test MSE 0.2266372286771541 Test RE 0.22754834742112148\n",
      "29 Train Loss 0.26062664 Test MSE 0.08692749177182582 Test RE 0.14092454281392938\n",
      "30 Train Loss 0.18247639 Test MSE 0.06499419540587344 Test RE 0.12185555896229111\n",
      "31 Train Loss 0.11895137 Test MSE 0.0450463922445517 Test RE 0.10144673342631998\n",
      "32 Train Loss 0.08769521 Test MSE 0.034422505819163896 Test RE 0.08868073853923217\n",
      "33 Train Loss 0.07010904 Test MSE 0.03805417177393947 Test RE 0.09324148838052891\n",
      "34 Train Loss 0.060183674 Test MSE 0.04028055780401142 Test RE 0.09593029904172141\n",
      "35 Train Loss 0.047153324 Test MSE 0.03439093043577521 Test RE 0.08864005627804472\n",
      "36 Train Loss 0.043729313 Test MSE 0.03253339875140655 Test RE 0.08621300410104046\n",
      "37 Train Loss 0.036991496 Test MSE 0.028136432249674853 Test RE 0.08017566557866251\n",
      "38 Train Loss 0.03371915 Test MSE 0.027786885591703565 Test RE 0.079676086925538\n",
      "39 Train Loss 0.030494237 Test MSE 0.02611293157086889 Test RE 0.07723886362670397\n",
      "40 Train Loss 0.028285462 Test MSE 0.023758245870943016 Test RE 0.0736741690927072\n",
      "41 Train Loss 0.02660514 Test MSE 0.021730380231124502 Test RE 0.0704598514205992\n",
      "42 Train Loss 0.023288462 Test MSE 0.019712981649529396 Test RE 0.06710953337491092\n",
      "43 Train Loss 0.020563928 Test MSE 0.015271498031151116 Test RE 0.05906753951952075\n",
      "44 Train Loss 0.019327383 Test MSE 0.013648668653181217 Test RE 0.0558410023848723\n",
      "45 Train Loss 0.015903689 Test MSE 0.01043567201191793 Test RE 0.04882792521888247\n",
      "46 Train Loss 0.014964959 Test MSE 0.008794231067304146 Test RE 0.04482362710543044\n",
      "47 Train Loss 0.013570556 Test MSE 0.008887192936098456 Test RE 0.04505991462830556\n",
      "48 Train Loss 0.012723745 Test MSE 0.009192876053267286 Test RE 0.045828301602225834\n",
      "49 Train Loss 0.011484621 Test MSE 0.009348654727502615 Test RE 0.046214964146839316\n",
      "50 Train Loss 0.010276366 Test MSE 0.00810949839667042 Test RE 0.043043250091242866\n",
      "51 Train Loss 0.009772355 Test MSE 0.006771241910645353 Test RE 0.03933165537070645\n",
      "52 Train Loss 0.009327811 Test MSE 0.007165617183761116 Test RE 0.04046083690559087\n",
      "53 Train Loss 0.008574477 Test MSE 0.006488318563285324 Test RE 0.03850118908542611\n",
      "54 Train Loss 0.008057943 Test MSE 0.005689515821228466 Test RE 0.036053357500771537\n",
      "55 Train Loss 0.007821978 Test MSE 0.005440798661350395 Test RE 0.03525651551832418\n",
      "56 Train Loss 0.0070695756 Test MSE 0.004946046056096875 Test RE 0.03361531136567101\n",
      "57 Train Loss 0.0068195113 Test MSE 0.004660702830666385 Test RE 0.03263125422178742\n",
      "58 Train Loss 0.0064908452 Test MSE 0.004546127732378349 Test RE 0.03222766771929411\n",
      "59 Train Loss 0.0058154985 Test MSE 0.0040317802628822225 Test RE 0.030349845705456006\n",
      "60 Train Loss 0.005541526 Test MSE 0.003727441950930932 Test RE 0.029181895951402956\n",
      "61 Train Loss 0.005396598 Test MSE 0.0035163906627842852 Test RE 0.028343705009165835\n",
      "62 Train Loss 0.0050735148 Test MSE 0.0032451245409302917 Test RE 0.027228501733533316\n",
      "63 Train Loss 0.004814662 Test MSE 0.0035215707875127455 Test RE 0.028364574404541064\n",
      "64 Train Loss 0.004441495 Test MSE 0.0035504002385346625 Test RE 0.028480441494803024\n",
      "65 Train Loss 0.0043018814 Test MSE 0.003789380131680057 Test RE 0.029423351982697944\n",
      "66 Train Loss 0.0040637874 Test MSE 0.0037346071528504923 Test RE 0.0292099304307465\n",
      "67 Train Loss 0.0038541015 Test MSE 0.0037229872481860655 Test RE 0.029164452952020203\n",
      "68 Train Loss 0.0037540863 Test MSE 0.003608551564725577 Test RE 0.02871273204828555\n",
      "69 Train Loss 0.0035648835 Test MSE 0.003487387625668976 Test RE 0.02822657416401096\n",
      "70 Train Loss 0.0031055226 Test MSE 0.0031992244610250208 Test RE 0.027035251631453136\n",
      "71 Train Loss 0.0030051558 Test MSE 0.0030552687892672972 Test RE 0.026419997493702836\n",
      "72 Train Loss 0.00294295 Test MSE 0.0029907417160513865 Test RE 0.02613951435115812\n",
      "73 Train Loss 0.0026194965 Test MSE 0.0025607038113994035 Test RE 0.024187319099562253\n",
      "74 Train Loss 0.0023317279 Test MSE 0.002043645052331956 Test RE 0.021607812088332377\n",
      "75 Train Loss 0.0022889075 Test MSE 0.0020181955428996 Test RE 0.021472849570747667\n",
      "76 Train Loss 0.0022386196 Test MSE 0.00199603302519788 Test RE 0.021354623633935817\n",
      "77 Train Loss 0.0021223342 Test MSE 0.001896587138805617 Test RE 0.020815864915360808\n",
      "78 Train Loss 0.0020873866 Test MSE 0.001979769355772962 Test RE 0.02126744699631397\n",
      "79 Train Loss 0.0020336572 Test MSE 0.0019182341545536713 Test RE 0.02093432055563569\n",
      "80 Train Loss 0.0019344384 Test MSE 0.0019525408362425262 Test RE 0.021120691015465133\n",
      "81 Train Loss 0.0018877938 Test MSE 0.0018299692493054655 Test RE 0.020447016914239596\n",
      "82 Train Loss 0.0018544404 Test MSE 0.0017112291608983635 Test RE 0.01977252559878501\n",
      "83 Train Loss 0.0017802604 Test MSE 0.0016895006551111902 Test RE 0.01964659273598671\n",
      "84 Train Loss 0.0016474184 Test MSE 0.0017733267097246681 Test RE 0.020128084083275592\n",
      "85 Train Loss 0.0015949125 Test MSE 0.0016868822948760329 Test RE 0.019631362850335236\n",
      "86 Train Loss 0.0015669469 Test MSE 0.0016296720938547787 Test RE 0.01929559498499148\n",
      "87 Train Loss 0.0015510416 Test MSE 0.0016202200135700525 Test RE 0.01923955649144002\n",
      "88 Train Loss 0.0015335171 Test MSE 0.0015709783130905396 Test RE 0.018944936553546808\n",
      "89 Train Loss 0.0014737796 Test MSE 0.0013995499740270334 Test RE 0.017881430766977686\n",
      "90 Train Loss 0.0014361443 Test MSE 0.0014573727242815496 Test RE 0.01824708011505992\n",
      "91 Train Loss 0.0014182171 Test MSE 0.0014403088106230636 Test RE 0.018139940948575736\n",
      "92 Train Loss 0.0014036421 Test MSE 0.0014617397122373154 Test RE 0.0182743981695197\n",
      "93 Train Loss 0.0013792793 Test MSE 0.001492903695642854 Test RE 0.01846817396548553\n",
      "94 Train Loss 0.0012798493 Test MSE 0.0014676698859647074 Test RE 0.018311429613863762\n",
      "95 Train Loss 0.0011402825 Test MSE 0.001593267927243646 Test RE 0.01907886202088039\n",
      "96 Train Loss 0.0010865019 Test MSE 0.0015406462105643666 Test RE 0.01876115278881567\n",
      "97 Train Loss 0.0010693985 Test MSE 0.0015401635216309678 Test RE 0.018758213596748022\n",
      "98 Train Loss 0.0009938701 Test MSE 0.0016344003448740053 Test RE 0.01932356635943357\n",
      "99 Train Loss 0.00087690953 Test MSE 0.0016159618904976582 Test RE 0.019214257983759777\n",
      "Training time: 68.60\n",
      "1\n",
      "KG_rowdy_tune22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.965866 Test MSE 8.606932820427371 Test RE 1.4022720147485075\n",
      "1 Train Loss 50.139244 Test MSE 8.86161388017443 Test RE 1.422867539568115\n",
      "2 Train Loss 44.491974 Test MSE 8.696276808749223 Test RE 1.4095313442691573\n",
      "3 Train Loss 42.844128 Test MSE 8.250313908697326 Test RE 1.3729138832819436\n",
      "4 Train Loss 39.498116 Test MSE 8.267246136208273 Test RE 1.374321985775747\n",
      "5 Train Loss 33.678925 Test MSE 7.9397669616456295 Test RE 1.3468273845151424\n",
      "6 Train Loss 31.31968 Test MSE 8.329478016827911 Test RE 1.379484907767108\n",
      "7 Train Loss 29.699894 Test MSE 8.64921810389433 Test RE 1.405712428457129\n",
      "8 Train Loss 27.121822 Test MSE 9.03344028310903 Test RE 1.4365959880278993\n",
      "9 Train Loss 25.341694 Test MSE 9.488586553228984 Test RE 1.4723424105307112\n",
      "10 Train Loss 23.99984 Test MSE 9.695394955259506 Test RE 1.4883011350130562\n",
      "11 Train Loss 23.046535 Test MSE 9.680803175382199 Test RE 1.4871807505453176\n",
      "12 Train Loss 22.047487 Test MSE 9.65462082239752 Test RE 1.4851683010705459\n",
      "13 Train Loss 20.884174 Test MSE 9.251745826781155 Test RE 1.453851024144411\n",
      "14 Train Loss 20.074467 Test MSE 9.234524904245399 Test RE 1.452497316540987\n",
      "15 Train Loss 19.28992 Test MSE 9.301840541122719 Test RE 1.457781737981089\n",
      "16 Train Loss 18.136261 Test MSE 8.992320987421266 Test RE 1.4333226398345482\n",
      "17 Train Loss 16.517067 Test MSE 8.09337013780256 Test RE 1.3597928761141604\n",
      "18 Train Loss 12.385496 Test MSE 6.847178043394103 Test RE 1.2507308746060584\n",
      "19 Train Loss 11.015188 Test MSE 6.716101528871896 Test RE 1.2387015661753111\n",
      "20 Train Loss 9.688376 Test MSE 6.49105598678887 Test RE 1.2177713091261373\n",
      "21 Train Loss 9.110025 Test MSE 6.369987804939321 Test RE 1.2063612003383148\n",
      "22 Train Loss 8.573757 Test MSE 6.257833008364198 Test RE 1.1956939867384535\n",
      "23 Train Loss 8.209089 Test MSE 6.296805721930818 Test RE 1.199411496530693\n",
      "24 Train Loss 7.919895 Test MSE 6.416603264551068 Test RE 1.2107672193468533\n",
      "25 Train Loss 7.694315 Test MSE 6.434307229799571 Test RE 1.2124363747188942\n",
      "26 Train Loss 7.4742885 Test MSE 6.454938198225505 Test RE 1.2143785976138666\n",
      "27 Train Loss 7.2816925 Test MSE 6.416941034587301 Test RE 1.2107990863245128\n",
      "28 Train Loss 7.074699 Test MSE 6.334228639023248 Test RE 1.2029703632033801\n",
      "29 Train Loss 6.908473 Test MSE 6.252479573602939 Test RE 1.1951824327130902\n",
      "30 Train Loss 6.7488832 Test MSE 6.226752319729533 Test RE 1.1927209726273735\n",
      "31 Train Loss 6.6106434 Test MSE 6.286009498801858 Test RE 1.1983828266011025\n",
      "32 Train Loss 6.479027 Test MSE 6.315583349681062 Test RE 1.2011985404591659\n",
      "33 Train Loss 6.2812014 Test MSE 6.363381181880682 Test RE 1.2057354502151472\n",
      "34 Train Loss 6.1185646 Test MSE 6.327895446600308 Test RE 1.2023688260214065\n",
      "35 Train Loss 5.9172363 Test MSE 6.327282257431616 Test RE 1.2023105683108422\n",
      "36 Train Loss 5.729388 Test MSE 6.317344252579005 Test RE 1.201365987110997\n",
      "37 Train Loss 5.518011 Test MSE 6.391565404834303 Test RE 1.2084026777818173\n",
      "38 Train Loss 5.270795 Test MSE 6.3124282615227445 Test RE 1.2008984604404631\n",
      "39 Train Loss 5.0210567 Test MSE 6.211841822420805 Test RE 1.191292079917817\n",
      "40 Train Loss 4.068959 Test MSE 5.54398789686756 Test RE 1.1254318380605701\n",
      "41 Train Loss 3.2167497 Test MSE 5.508494706557814 Test RE 1.1218234873649362\n",
      "42 Train Loss 2.6569 Test MSE 5.62414186953626 Test RE 1.1335382876281634\n",
      "43 Train Loss 2.3007035 Test MSE 5.67628043245919 Test RE 1.138780395311811\n",
      "44 Train Loss 2.0862315 Test MSE 5.6672183695104605 Test RE 1.1378710126767269\n",
      "45 Train Loss 1.8985137 Test MSE 5.5903461130127505 Test RE 1.1301274110631583\n",
      "46 Train Loss 1.830732 Test MSE 5.552964188952377 Test RE 1.126342565073793\n",
      "47 Train Loss 1.749625 Test MSE 5.520455495019254 Test RE 1.123040754363337\n",
      "48 Train Loss 1.680238 Test MSE 5.585866055799519 Test RE 1.129674482914096\n",
      "49 Train Loss 1.6252384 Test MSE 5.617639824298733 Test RE 1.1328828588689335\n",
      "50 Train Loss 1.5785882 Test MSE 5.604738252078896 Test RE 1.1315812115621824\n",
      "51 Train Loss 1.5493264 Test MSE 5.614153531956263 Test RE 1.1325312722666154\n",
      "52 Train Loss 1.5221429 Test MSE 5.620240259282004 Test RE 1.1331450372446228\n",
      "53 Train Loss 1.4912947 Test MSE 5.598041036108114 Test RE 1.1309049347510096\n",
      "54 Train Loss 1.4675457 Test MSE 5.589655899825199 Test RE 1.1300576432075504\n",
      "55 Train Loss 1.4302256 Test MSE 5.646786295345856 Test RE 1.1358179721654869\n",
      "56 Train Loss 1.3987792 Test MSE 5.645430607120408 Test RE 1.1356816196100772\n",
      "57 Train Loss 1.3773481 Test MSE 5.676219442070487 Test RE 1.1387742773225444\n",
      "58 Train Loss 1.3571837 Test MSE 5.716339503710726 Test RE 1.1427916737139565\n",
      "59 Train Loss 1.3400477 Test MSE 5.752545214930322 Test RE 1.1464050242315162\n",
      "60 Train Loss 1.3264073 Test MSE 5.756310209424774 Test RE 1.1467801192932219\n",
      "61 Train Loss 1.3088279 Test MSE 5.7759246070318175 Test RE 1.1487322615201327\n",
      "62 Train Loss 1.2951854 Test MSE 5.770539775196763 Test RE 1.1481966613463572\n",
      "63 Train Loss 1.2807709 Test MSE 5.787189957893882 Test RE 1.1498519582818123\n",
      "64 Train Loss 1.2652395 Test MSE 5.747584994989568 Test RE 1.1459106650236803\n",
      "65 Train Loss 1.2480786 Test MSE 5.757012979886795 Test RE 1.1468501206107569\n",
      "66 Train Loss 1.2343549 Test MSE 5.747944209882007 Test RE 1.145946473258384\n",
      "67 Train Loss 1.2150607 Test MSE 5.758312728963459 Test RE 1.1469795743106728\n",
      "68 Train Loss 1.1999402 Test MSE 5.753913564041286 Test RE 1.1465413629271013\n",
      "69 Train Loss 1.1839435 Test MSE 5.741496336505238 Test RE 1.1453035485172485\n",
      "70 Train Loss 1.1717981 Test MSE 5.73585355631031 Test RE 1.1447406042534458\n",
      "71 Train Loss 1.161855 Test MSE 5.76611524745072 Test RE 1.1477563903867678\n",
      "72 Train Loss 1.1518967 Test MSE 5.774126028139427 Test RE 1.1485533943598913\n",
      "73 Train Loss 1.1382155 Test MSE 5.789467728249597 Test RE 1.150078220169026\n",
      "74 Train Loss 1.122724 Test MSE 5.783580352454812 Test RE 1.1494933075974876\n",
      "75 Train Loss 1.111869 Test MSE 5.801357236451492 Test RE 1.151258540360664\n",
      "76 Train Loss 1.1005027 Test MSE 5.7940820277562315 Test RE 1.150536444364383\n",
      "77 Train Loss 1.0869124 Test MSE 5.818527994747986 Test RE 1.152961019254895\n",
      "78 Train Loss 1.0722007 Test MSE 5.84143398312672 Test RE 1.1552282396562996\n",
      "79 Train Loss 1.0621614 Test MSE 5.845252718337488 Test RE 1.1556057830828437\n",
      "80 Train Loss 1.051597 Test MSE 5.837857898720417 Test RE 1.1548745742574469\n",
      "81 Train Loss 1.0462996 Test MSE 5.834382528117593 Test RE 1.154530765386494\n",
      "82 Train Loss 1.0372838 Test MSE 5.851021724163253 Test RE 1.1561759083360763\n",
      "83 Train Loss 1.0290312 Test MSE 5.848868774331335 Test RE 1.1559631747428407\n",
      "84 Train Loss 1.0177435 Test MSE 5.877145087135921 Test RE 1.158754053396057\n",
      "85 Train Loss 1.0111339 Test MSE 5.856347519160698 Test RE 1.1567019835750008\n",
      "86 Train Loss 1.0045716 Test MSE 5.8524590631232645 Test RE 1.1563179104264563\n",
      "87 Train Loss 0.99874276 Test MSE 5.868815242204673 Test RE 1.157932594680976\n",
      "88 Train Loss 0.99033344 Test MSE 5.87564377728922 Test RE 1.1586060427585372\n",
      "89 Train Loss 0.9818266 Test MSE 5.867239242054441 Test RE 1.1577771097663714\n",
      "90 Train Loss 0.9731913 Test MSE 5.874339866170954 Test RE 1.1584774778572806\n",
      "91 Train Loss 0.96752167 Test MSE 5.8770413789054325 Test RE 1.158743829651295\n",
      "92 Train Loss 0.96225893 Test MSE 5.871389167900446 Test RE 1.158186487981498\n",
      "93 Train Loss 0.9566566 Test MSE 5.853291248314694 Test RE 1.1564001183006498\n",
      "94 Train Loss 0.94899005 Test MSE 5.871528507096389 Test RE 1.1582002308804884\n",
      "95 Train Loss 0.94314843 Test MSE 5.882969321479865 Test RE 1.1593280722315422\n",
      "96 Train Loss 0.9385391 Test MSE 5.8792821827410116 Test RE 1.1589647120644904\n",
      "97 Train Loss 0.9313441 Test MSE 5.88488065412227 Test RE 1.1595163854384165\n",
      "98 Train Loss 0.92542285 Test MSE 5.903812967511358 Test RE 1.1613800341216776\n",
      "99 Train Loss 0.9189999 Test MSE 5.9204002817410855 Test RE 1.163010392630818\n",
      "Training time: 69.08\n",
      "2\n",
      "KG_rowdy_tune22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.075447 Test MSE 8.537270714683212 Test RE 1.3965856868430935\n",
      "1 Train Loss 37.993958 Test MSE 6.578521293074431 Test RE 1.2259484323921361\n",
      "2 Train Loss 25.608986 Test MSE 5.947463977189247 Test RE 1.165665573786921\n",
      "3 Train Loss 19.387264 Test MSE 5.714033081659642 Test RE 1.1425611043227992\n",
      "4 Train Loss 15.9547825 Test MSE 5.834002880175528 Test RE 1.1544932016548026\n",
      "5 Train Loss 12.848158 Test MSE 5.88629697707676 Test RE 1.1596559083081686\n",
      "6 Train Loss 10.926539 Test MSE 5.907738004137569 Test RE 1.1617660305782649\n",
      "7 Train Loss 9.765901 Test MSE 5.917629785800691 Test RE 1.162738241048188\n",
      "8 Train Loss 8.85498 Test MSE 5.88168178982295 Test RE 1.1592012014974216\n",
      "9 Train Loss 8.166334 Test MSE 5.782085756497174 Test RE 1.1493447716600627\n",
      "10 Train Loss 7.5756335 Test MSE 5.756600736993208 Test RE 1.1468090585810378\n",
      "11 Train Loss 6.574907 Test MSE 5.478002322709463 Test RE 1.118714240268091\n",
      "12 Train Loss 6.0889025 Test MSE 5.274500747857207 Test RE 1.097738103934218\n",
      "13 Train Loss 5.730175 Test MSE 5.018715570611374 Test RE 1.0707901114974592\n",
      "14 Train Loss 5.4357805 Test MSE 4.818001110962642 Test RE 1.0491594775779016\n",
      "15 Train Loss 5.1617117 Test MSE 4.763686847660454 Test RE 1.0432290270346012\n",
      "16 Train Loss 4.917773 Test MSE 4.646067327540629 Test RE 1.0302694207090448\n",
      "17 Train Loss 4.5813227 Test MSE 4.29008908079994 Test RE 0.9900137247219031\n",
      "18 Train Loss 3.635741 Test MSE 3.750624690937917 Test RE 0.9256778341515826\n",
      "19 Train Loss 2.9272091 Test MSE 3.689130291318327 Test RE 0.9180578683752937\n",
      "20 Train Loss 2.4270098 Test MSE 3.5538417739868065 Test RE 0.9010670406228932\n",
      "21 Train Loss 2.1295154 Test MSE 3.0988027021991793 Test RE 0.8414048737283361\n",
      "22 Train Loss 1.8645067 Test MSE 2.6169861133140535 Test RE 0.7732301313499369\n",
      "23 Train Loss 1.7009218 Test MSE 2.3979316221293008 Test RE 0.7401614428942813\n",
      "24 Train Loss 1.5249256 Test MSE 2.242880928352508 Test RE 0.7158320996516506\n",
      "25 Train Loss 1.3799323 Test MSE 2.008583164724002 Test RE 0.6774121306064125\n",
      "26 Train Loss 1.2514727 Test MSE 1.759642445879283 Test RE 0.6340452816061927\n",
      "27 Train Loss 0.96262234 Test MSE 1.147867751072326 Test RE 0.5120990705922117\n",
      "28 Train Loss 0.7468602 Test MSE 1.0268297714810963 Test RE 0.4843477496125707\n",
      "29 Train Loss 0.51500106 Test MSE 0.787323588032192 Test RE 0.4241160342010384\n",
      "30 Train Loss 0.3719396 Test MSE 0.5802737793294076 Test RE 0.36410323166506015\n",
      "31 Train Loss 0.30239078 Test MSE 0.4565319014008604 Test RE 0.32295619933300873\n",
      "32 Train Loss 0.25362557 Test MSE 0.3763724683201007 Test RE 0.29323579554038365\n",
      "33 Train Loss 0.2122998 Test MSE 0.30864857243943866 Test RE 0.26554626456505637\n",
      "34 Train Loss 0.16990235 Test MSE 0.20079180303592636 Test RE 0.21418105332044152\n",
      "35 Train Loss 0.11604164 Test MSE 0.09618852558170739 Test RE 0.14824146359707227\n",
      "36 Train Loss 0.094575405 Test MSE 0.06812770778761594 Test RE 0.12475844377653023\n",
      "37 Train Loss 0.07226239 Test MSE 0.03669618991110567 Test RE 0.09156269092754103\n",
      "38 Train Loss 0.056866147 Test MSE 0.02007852790808898 Test RE 0.06772889569325091\n",
      "39 Train Loss 0.042987708 Test MSE 0.015433639167219874 Test RE 0.05938027868053414\n",
      "40 Train Loss 0.0355797 Test MSE 0.01256197058126038 Test RE 0.05357188726884172\n",
      "41 Train Loss 0.02894164 Test MSE 0.00790941120783995 Test RE 0.0425089265117569\n",
      "42 Train Loss 0.024449252 Test MSE 0.00725674431928789 Test RE 0.04071729993038744\n",
      "43 Train Loss 0.022164539 Test MSE 0.007992760141608575 Test RE 0.0427323178799197\n",
      "44 Train Loss 0.01946399 Test MSE 0.008066973599493658 Test RE 0.0429302460998501\n",
      "45 Train Loss 0.016368115 Test MSE 0.007918651259527804 Test RE 0.04253374947383296\n",
      "46 Train Loss 0.01408392 Test MSE 0.007659701416206779 Test RE 0.041832515497404875\n",
      "47 Train Loss 0.012180202 Test MSE 0.007428234091475615 Test RE 0.04119560175029139\n",
      "48 Train Loss 0.011051303 Test MSE 0.007263454345098868 Test RE 0.04073612042295699\n",
      "49 Train Loss 0.009568323 Test MSE 0.006974597360079583 Test RE 0.039917894940481424\n",
      "50 Train Loss 0.008526187 Test MSE 0.007378120654980837 Test RE 0.04105640669933857\n",
      "51 Train Loss 0.0074603353 Test MSE 0.006327539816279246 Test RE 0.03802117233032371\n",
      "52 Train Loss 0.0067898203 Test MSE 0.005848994424724752 Test RE 0.03655515788289785\n",
      "53 Train Loss 0.0061792834 Test MSE 0.0046909917276334355 Test RE 0.0327371142323559\n",
      "54 Train Loss 0.005677119 Test MSE 0.0041982493788807725 Test RE 0.030970069251937397\n",
      "55 Train Loss 0.0052731815 Test MSE 0.0040054610317209385 Test RE 0.03025062248021851\n",
      "56 Train Loss 0.004909105 Test MSE 0.0042685705157153205 Test RE 0.031228368135825895\n",
      "57 Train Loss 0.0044223987 Test MSE 0.003843001428378441 Test RE 0.029630797004520544\n",
      "58 Train Loss 0.0038871584 Test MSE 0.002638496496278535 Test RE 0.02455196866700799\n",
      "59 Train Loss 0.0036843317 Test MSE 0.0029502208082257527 Test RE 0.025961831158879546\n",
      "60 Train Loss 0.0031699152 Test MSE 0.002309276663053864 Test RE 0.022969209220053303\n",
      "61 Train Loss 0.002959002 Test MSE 0.0024099073409001594 Test RE 0.02346433403550796\n",
      "62 Train Loss 0.002748896 Test MSE 0.002176923019264488 Test RE 0.022301270022094793\n",
      "63 Train Loss 0.0026188616 Test MSE 0.002074361163194736 Test RE 0.021769589845549647\n",
      "64 Train Loss 0.002396895 Test MSE 0.0019549701991788304 Test RE 0.02113382617579415\n",
      "65 Train Loss 0.0023259548 Test MSE 0.0018736792430213444 Test RE 0.020689770965977475\n",
      "66 Train Loss 0.0022122562 Test MSE 0.0017872916628531709 Test RE 0.02020718302365892\n",
      "67 Train Loss 0.0020813039 Test MSE 0.0016836859443217819 Test RE 0.019612755010769922\n",
      "68 Train Loss 0.001856455 Test MSE 0.0015669467971458095 Test RE 0.01892061225939903\n",
      "69 Train Loss 0.0017670919 Test MSE 0.0014108801937698433 Test RE 0.017953665467782532\n",
      "70 Train Loss 0.0016643028 Test MSE 0.0011709469060968735 Test RE 0.016355983433387844\n",
      "71 Train Loss 0.0016340159 Test MSE 0.0011706118271186854 Test RE 0.016353643046166644\n",
      "72 Train Loss 0.0014971836 Test MSE 0.0010958556997636747 Test RE 0.015822851263698482\n",
      "73 Train Loss 0.0014170051 Test MSE 0.0010692834328501607 Test RE 0.015629838094783126\n",
      "74 Train Loss 0.0013927277 Test MSE 0.0010094773869975212 Test RE 0.015186453256104045\n",
      "75 Train Loss 0.0013217088 Test MSE 0.0008972618405089679 Test RE 0.014317515413832096\n",
      "76 Train Loss 0.0012913847 Test MSE 0.0008545933091387698 Test RE 0.013972940329012997\n",
      "77 Train Loss 0.0012561188 Test MSE 0.000848824802267097 Test RE 0.013925701788726158\n",
      "78 Train Loss 0.0012152304 Test MSE 0.0008155317169856782 Test RE 0.013649869152145399\n",
      "79 Train Loss 0.0011834229 Test MSE 0.0008390117313690617 Test RE 0.013844971846340242\n",
      "80 Train Loss 0.0011622271 Test MSE 0.0008377297616970883 Test RE 0.013834390576508855\n",
      "81 Train Loss 0.0010248419 Test MSE 0.0007012758761190227 Test RE 0.012657633307947079\n",
      "82 Train Loss 0.0009836367 Test MSE 0.000711642878132147 Test RE 0.01275084933158723\n",
      "83 Train Loss 0.0009695464 Test MSE 0.000680591082762449 Test RE 0.012469561674142829\n",
      "84 Train Loss 0.00093954906 Test MSE 0.0006357876443439484 Test RE 0.012052138176011999\n",
      "85 Train Loss 0.00090125785 Test MSE 0.0006194950068708556 Test RE 0.011896712473483279\n",
      "86 Train Loss 0.000854222 Test MSE 0.00063266822431043 Test RE 0.012022535595793714\n",
      "87 Train Loss 0.0008172445 Test MSE 0.0005659108221001916 Test RE 0.01137056538429356\n",
      "88 Train Loss 0.0007863072 Test MSE 0.0005312967880784495 Test RE 0.011017337547619037\n",
      "89 Train Loss 0.0007614774 Test MSE 0.0005035508059353043 Test RE 0.010725800330989542\n",
      "90 Train Loss 0.00074438436 Test MSE 0.0004937439904195261 Test RE 0.010620842574008992\n",
      "91 Train Loss 0.00072216097 Test MSE 0.00048173071170942516 Test RE 0.010490839134124815\n",
      "92 Train Loss 0.00068791956 Test MSE 0.00043922812392574136 Test RE 0.010017356514666795\n",
      "93 Train Loss 0.0006616991 Test MSE 0.0004335628140465509 Test RE 0.009952543248844363\n",
      "94 Train Loss 0.0006470679 Test MSE 0.0004215949987323646 Test RE 0.009814219917344751\n",
      "95 Train Loss 0.00062007253 Test MSE 0.00041900051098190245 Test RE 0.009783975050885697\n",
      "96 Train Loss 0.0005974578 Test MSE 0.00042148393358873936 Test RE 0.009812927101317412\n",
      "97 Train Loss 0.0005819412 Test MSE 0.00040632917828385223 Test RE 0.009634896754994895\n",
      "98 Train Loss 0.0005673023 Test MSE 0.0003720863977167844 Test RE 0.009219979538209602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0005404145 Test MSE 0.00034308311463458464 Test RE 0.008853352013810212\n",
      "Training time: 67.99\n",
      "3\n",
      "KG_rowdy_tune22\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.91\n",
      "0\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 53.92625 Test MSE 6.846461811364024 Test RE 1.2506654580990657\n",
      "1 Train Loss 28.74284 Test MSE 6.391391836336656 Test RE 1.2083862700594528\n",
      "2 Train Loss 21.639503 Test MSE 5.952482890083627 Test RE 1.166157307766014\n",
      "3 Train Loss 17.610943 Test MSE 5.882320492113374 Test RE 1.159264139649304\n",
      "4 Train Loss 14.319102 Test MSE 5.90601504661989 Test RE 1.161596607062854\n",
      "5 Train Loss 12.667355 Test MSE 5.965001963879867 Test RE 1.1673829762455392\n",
      "6 Train Loss 11.261493 Test MSE 6.009150946272601 Test RE 1.171695108758252\n",
      "7 Train Loss 10.156935 Test MSE 5.905996866157307 Test RE 1.161594819192375\n",
      "8 Train Loss 9.468238 Test MSE 5.776208376895869 Test RE 1.148760479651097\n",
      "9 Train Loss 8.862753 Test MSE 5.586663410224256 Test RE 1.1297551077264654\n",
      "10 Train Loss 8.408501 Test MSE 5.315862362966173 Test RE 1.1020338238175165\n",
      "11 Train Loss 8.022134 Test MSE 5.121123104472128 Test RE 1.0816597471020741\n",
      "12 Train Loss 7.561297 Test MSE 5.01547661073201 Test RE 1.070444524471941\n",
      "13 Train Loss 6.4345474 Test MSE 4.049357758366599 Test RE 0.9618362355222084\n",
      "14 Train Loss 4.813985 Test MSE 3.5151508287674043 Test RE 0.8961486245526804\n",
      "15 Train Loss 4.3376355 Test MSE 3.2213139173712957 Test RE 0.857876131554564\n",
      "16 Train Loss 3.5584722 Test MSE 2.5270640582224404 Test RE 0.7598295611214823\n",
      "17 Train Loss 2.7686875 Test MSE 2.2603163204786214 Test RE 0.7186090307895978\n",
      "18 Train Loss 2.1859972 Test MSE 2.0043834744485483 Test RE 0.6767035690104714\n",
      "19 Train Loss 1.6011555 Test MSE 1.1946076013615998 Test RE 0.5224210854741843\n",
      "20 Train Loss 1.2380196 Test MSE 0.8465681502471472 Test RE 0.43978359283511587\n",
      "21 Train Loss 0.83701956 Test MSE 0.5287327430472841 Test RE 0.34755709874411966\n",
      "22 Train Loss 0.5884765 Test MSE 0.4148179080967646 Test RE 0.30784833482382606\n",
      "23 Train Loss 0.4321406 Test MSE 0.33179656700998666 Test RE 0.27532395808280846\n",
      "24 Train Loss 0.343123 Test MSE 0.3085401674957675 Test RE 0.265499627291308\n",
      "25 Train Loss 0.25102085 Test MSE 0.21330180894816095 Test RE 0.22075234697759302\n",
      "26 Train Loss 0.20176747 Test MSE 0.1905923534288415 Test RE 0.20867037506561348\n",
      "27 Train Loss 0.15689352 Test MSE 0.17237791024254825 Test RE 0.19844897769069159\n",
      "28 Train Loss 0.130699 Test MSE 0.1336944089243303 Test RE 0.174769113387346\n",
      "29 Train Loss 0.11271641 Test MSE 0.09670885127681177 Test RE 0.1486418742004108\n",
      "30 Train Loss 0.094812036 Test MSE 0.0703829794183542 Test RE 0.12680660750556746\n",
      "31 Train Loss 0.07990371 Test MSE 0.058675173827341304 Test RE 0.1157804552067818\n",
      "32 Train Loss 0.06338265 Test MSE 0.05043845437010455 Test RE 0.10734676104987599\n",
      "33 Train Loss 0.049801376 Test MSE 0.04061609719496794 Test RE 0.0963290229027506\n",
      "34 Train Loss 0.039273284 Test MSE 0.03353380151649285 Test RE 0.08752849377265336\n",
      "35 Train Loss 0.035486057 Test MSE 0.03395869311412738 Test RE 0.08808126523839056\n",
      "36 Train Loss 0.031299975 Test MSE 0.02715082255648179 Test RE 0.07875888442893636\n",
      "37 Train Loss 0.028374529 Test MSE 0.02540076023291382 Test RE 0.076178324752406\n",
      "38 Train Loss 0.025112174 Test MSE 0.024061700908254876 Test RE 0.0741431822815786\n",
      "39 Train Loss 0.021237206 Test MSE 0.020938994402526334 Test RE 0.06916493460964163\n",
      "40 Train Loss 0.018526739 Test MSE 0.015440554935996687 Test RE 0.05939358125548728\n",
      "41 Train Loss 0.016327335 Test MSE 0.014652497401818938 Test RE 0.05785806256912526\n",
      "42 Train Loss 0.01476088 Test MSE 0.015473087723050881 Test RE 0.05945611858066448\n",
      "43 Train Loss 0.013627893 Test MSE 0.015041818717694133 Test RE 0.058621676624509345\n",
      "44 Train Loss 0.012435995 Test MSE 0.01340330078448991 Test RE 0.055336787368867095\n",
      "45 Train Loss 0.011845719 Test MSE 0.011950367511150164 Test RE 0.05225149140871531\n",
      "46 Train Loss 0.0094609745 Test MSE 0.008974781169390036 Test RE 0.04528141548309386\n",
      "47 Train Loss 0.00891919 Test MSE 0.009111693916812255 Test RE 0.0456254983844584\n",
      "48 Train Loss 0.008119114 Test MSE 0.007782466094362909 Test RE 0.042166415016506455\n",
      "49 Train Loss 0.0077940226 Test MSE 0.006882782169488408 Test RE 0.0396542803584438\n",
      "50 Train Loss 0.006989442 Test MSE 0.006746508639429731 Test RE 0.039259756413755426\n",
      "51 Train Loss 0.0065425294 Test MSE 0.006854498811558563 Test RE 0.03957272098674106\n",
      "52 Train Loss 0.0060065105 Test MSE 0.005563039324376462 Test RE 0.03565037686843173\n",
      "53 Train Loss 0.0056904824 Test MSE 0.006368245776845497 Test RE 0.038143274066243446\n",
      "54 Train Loss 0.0054328186 Test MSE 0.00633336315892329 Test RE 0.038038664072939515\n",
      "55 Train Loss 0.0051230025 Test MSE 0.006161285953116573 Test RE 0.03751835107762302\n",
      "56 Train Loss 0.0046702377 Test MSE 0.006086281058072325 Test RE 0.03728928551971446\n",
      "57 Train Loss 0.00448348 Test MSE 0.005766180309950079 Test RE 0.03629544869616364\n",
      "58 Train Loss 0.004111643 Test MSE 0.005303992959116042 Test RE 0.03481044136024068\n",
      "59 Train Loss 0.003951845 Test MSE 0.005216787846018023 Test RE 0.03452308900852555\n",
      "60 Train Loss 0.0036157086 Test MSE 0.0047356568067258445 Test RE 0.03289259752572483\n",
      "61 Train Loss 0.0034087608 Test MSE 0.00489985350921714 Test RE 0.03345797161236548\n",
      "62 Train Loss 0.0032973827 Test MSE 0.004958753900163106 Test RE 0.03365846746406277\n",
      "63 Train Loss 0.0030714392 Test MSE 0.004648891862480948 Test RE 0.03258988157908248\n",
      "64 Train Loss 0.0029566218 Test MSE 0.004493962997862881 Test RE 0.032042235380100634\n",
      "65 Train Loss 0.0028473523 Test MSE 0.0044058989623643185 Test RE 0.03172673104891818\n",
      "66 Train Loss 0.002691537 Test MSE 0.00432402716648674 Test RE 0.031430570729568445\n",
      "67 Train Loss 0.0025016665 Test MSE 0.0035738430504139614 Test RE 0.02857431304325043\n",
      "68 Train Loss 0.0024387334 Test MSE 0.003319790551858601 Test RE 0.02753996617900097\n",
      "69 Train Loss 0.0022796504 Test MSE 0.002813111973408278 Test RE 0.025351377944889796\n",
      "70 Train Loss 0.0022185568 Test MSE 0.002650699714559005 Test RE 0.024608680396520855\n",
      "71 Train Loss 0.0021742475 Test MSE 0.002510914795514961 Test RE 0.023951021916917947\n",
      "72 Train Loss 0.0019691433 Test MSE 0.002558979203262003 Test RE 0.02417917277023057\n",
      "73 Train Loss 0.0018540678 Test MSE 0.002266351605109832 Test RE 0.02275473091784842\n",
      "74 Train Loss 0.0018072237 Test MSE 0.002450758384059592 Test RE 0.02366237369482373\n",
      "75 Train Loss 0.001748694 Test MSE 0.0025003501564241897 Test RE 0.023900582008836716\n",
      "76 Train Loss 0.0016431278 Test MSE 0.002373434263983592 Test RE 0.023286094959285467\n",
      "77 Train Loss 0.001556317 Test MSE 0.002522034407047933 Test RE 0.0240039970027681\n",
      "78 Train Loss 0.0015038827 Test MSE 0.0025720902443213157 Test RE 0.024241035153591706\n",
      "79 Train Loss 0.0014481139 Test MSE 0.0024677139352004183 Test RE 0.023744086572054818\n",
      "80 Train Loss 0.0013881231 Test MSE 0.002248508534211071 Test RE 0.02266497949116614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 0.0013697847 Test MSE 0.0022158285384136756 Test RE 0.022499669358437804\n",
      "82 Train Loss 0.0013343713 Test MSE 0.0022341894941817495 Test RE 0.022592696223457737\n",
      "83 Train Loss 0.0013016519 Test MSE 0.0022902532991686333 Test RE 0.022874405674400303\n",
      "84 Train Loss 0.0012127913 Test MSE 0.0022398379527814667 Test RE 0.022621237525193558\n",
      "85 Train Loss 0.0011728436 Test MSE 0.0021364192760826585 Test RE 0.022092827630124302\n",
      "86 Train Loss 0.00114553 Test MSE 0.002209884056225801 Test RE 0.022469468757361173\n",
      "87 Train Loss 0.001096002 Test MSE 0.002315318541249094 Test RE 0.022999237348055052\n",
      "88 Train Loss 0.001055935 Test MSE 0.0021259402454009172 Test RE 0.022038578914163807\n",
      "89 Train Loss 0.0009807891 Test MSE 0.0018037290218221927 Test RE 0.020299891039471066\n",
      "90 Train Loss 0.00095176685 Test MSE 0.0017981208684626077 Test RE 0.020268308265612357\n",
      "91 Train Loss 0.00093756843 Test MSE 0.0018076313672378923 Test RE 0.02032183845665918\n",
      "92 Train Loss 0.00092493114 Test MSE 0.0017110875157610827 Test RE 0.019771707257172713\n",
      "93 Train Loss 0.0009132455 Test MSE 0.001681063064712646 Test RE 0.019597472485755833\n",
      "94 Train Loss 0.0008853839 Test MSE 0.0015749603462756514 Test RE 0.018968931672058178\n",
      "95 Train Loss 0.0008576252 Test MSE 0.001596268528193961 Test RE 0.019096819177387\n",
      "96 Train Loss 0.0008210866 Test MSE 0.0014980068872439674 Test RE 0.01849971190966425\n",
      "97 Train Loss 0.0008059258 Test MSE 0.0014811947996028996 Test RE 0.01839560813327135\n",
      "98 Train Loss 0.00079365034 Test MSE 0.0014593866876826938 Test RE 0.018259683707713973\n",
      "99 Train Loss 0.00077781535 Test MSE 0.0013078260762628706 Test RE 0.017285544179628312\n",
      "Training time: 68.89\n",
      "1\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 48.47812 Test MSE 10.33767331803413 Test RE 1.5368074677515864\n",
      "1 Train Loss 38.96943 Test MSE 9.87481773170806 Test RE 1.5020092401195553\n",
      "2 Train Loss 33.315536 Test MSE 10.060543550360084 Test RE 1.516068355672657\n",
      "3 Train Loss 29.41959 Test MSE 9.881928322836774 Test RE 1.5025499210684858\n",
      "4 Train Loss 25.819946 Test MSE 10.00950699938886 Test RE 1.51221800311435\n",
      "5 Train Loss 21.725868 Test MSE 9.521236655618278 Test RE 1.4748733906345284\n",
      "6 Train Loss 19.135365 Test MSE 9.146236104184808 Test RE 1.44553717317828\n",
      "7 Train Loss 16.881006 Test MSE 8.868704662011224 Test RE 1.423436692432155\n",
      "8 Train Loss 14.944469 Test MSE 8.758310973648266 Test RE 1.4145497976019332\n",
      "9 Train Loss 14.006451 Test MSE 8.709266242806248 Test RE 1.4105836441792359\n",
      "10 Train Loss 13.417853 Test MSE 8.886198273139245 Test RE 1.4248398725815519\n",
      "11 Train Loss 12.759737 Test MSE 8.925460860096102 Test RE 1.4279841441582826\n",
      "12 Train Loss 12.271322 Test MSE 8.73717539720601 Test RE 1.4128419692124838\n",
      "13 Train Loss 11.931962 Test MSE 8.70122776954775 Test RE 1.409932524085058\n",
      "14 Train Loss 11.594636 Test MSE 8.67116956937151 Test RE 1.4074951268150604\n",
      "15 Train Loss 11.145433 Test MSE 8.611768936809062 Test RE 1.402665918038811\n",
      "16 Train Loss 10.578157 Test MSE 8.367059858553604 Test RE 1.3825934601002183\n",
      "17 Train Loss 9.126867 Test MSE 7.205698775309612 Test RE 1.2830574768582097\n",
      "18 Train Loss 7.902564 Test MSE 6.678882636570273 Test RE 1.2352645163897473\n",
      "19 Train Loss 7.3086634 Test MSE 6.5423607540091275 Test RE 1.2225744185869152\n",
      "20 Train Loss 7.0049686 Test MSE 6.460067624763218 Test RE 1.2148610057037235\n",
      "21 Train Loss 6.7812395 Test MSE 6.292405386836147 Test RE 1.198992336791845\n",
      "22 Train Loss 6.5446076 Test MSE 6.28168706003358 Test RE 1.1979707347036843\n",
      "23 Train Loss 6.357763 Test MSE 6.245027234005038 Test RE 1.1944699504981227\n",
      "24 Train Loss 6.1700516 Test MSE 6.288962618034418 Test RE 1.198664289095434\n",
      "25 Train Loss 5.959983 Test MSE 6.246957114576419 Test RE 1.1946544978348108\n",
      "26 Train Loss 5.7070293 Test MSE 6.058529214374602 Test RE 1.176499273915528\n",
      "27 Train Loss 5.047966 Test MSE 5.471447476149692 Test RE 1.118044726575541\n",
      "28 Train Loss 3.5142517 Test MSE 5.047530723367134 Test RE 1.0738597035191644\n",
      "29 Train Loss 2.7078931 Test MSE 5.14465245237696 Test RE 1.0841417789878143\n",
      "30 Train Loss 2.2699819 Test MSE 5.207561055710179 Test RE 1.0907500599615452\n",
      "31 Train Loss 1.9691751 Test MSE 5.266148342338009 Test RE 1.0968686011229438\n",
      "32 Train Loss 1.7785084 Test MSE 5.401659365974294 Test RE 1.1108915341314398\n",
      "33 Train Loss 1.651684 Test MSE 5.379375043698629 Test RE 1.1085976973681229\n",
      "34 Train Loss 1.5472903 Test MSE 5.468521244249276 Test RE 1.1177457110305515\n",
      "35 Train Loss 1.4927979 Test MSE 5.560013148314265 Test RE 1.1270572306715856\n",
      "36 Train Loss 1.3982558 Test MSE 5.54395004347222 Test RE 1.1254279959265499\n",
      "37 Train Loss 1.3421459 Test MSE 5.56528947472121 Test RE 1.1275918797373987\n",
      "38 Train Loss 1.2964339 Test MSE 5.617059905373271 Test RE 1.132824382606044\n",
      "39 Train Loss 1.2570505 Test MSE 5.630267114733062 Test RE 1.1341553871505494\n",
      "40 Train Loss 1.2337372 Test MSE 5.623902067436389 Test RE 1.133514121473971\n",
      "41 Train Loss 1.2035787 Test MSE 5.607279014441416 Test RE 1.1318376689613896\n",
      "42 Train Loss 1.1760181 Test MSE 5.672112858590126 Test RE 1.1383622673736211\n",
      "43 Train Loss 1.1518114 Test MSE 5.679773597207253 Test RE 1.1391307423184667\n",
      "44 Train Loss 1.1214645 Test MSE 5.660557358292791 Test RE 1.1372021130937058\n",
      "45 Train Loss 1.0992726 Test MSE 5.705794622423273 Test RE 1.141737138283572\n",
      "46 Train Loss 1.0726978 Test MSE 5.750313228044499 Test RE 1.146182600145115\n",
      "47 Train Loss 1.0456394 Test MSE 5.79393617993363 Test RE 1.1505219637020085\n",
      "48 Train Loss 1.0262387 Test MSE 5.820203642667744 Test RE 1.1531270249578558\n",
      "49 Train Loss 1.0090584 Test MSE 5.835277147900457 Test RE 1.1546192774498407\n",
      "50 Train Loss 0.9832772 Test MSE 5.920420713390488 Test RE 1.1630123994377028\n",
      "51 Train Loss 0.961495 Test MSE 5.9325168911711605 Test RE 1.1641998848439625\n",
      "52 Train Loss 0.94587755 Test MSE 5.915530430602223 Test RE 1.1625319745874885\n",
      "53 Train Loss 0.9319359 Test MSE 5.948373756724455 Test RE 1.1657547259142103\n",
      "54 Train Loss 0.91700834 Test MSE 5.93780741919122 Test RE 1.1647188770069286\n",
      "55 Train Loss 0.9037669 Test MSE 5.919398838373089 Test RE 1.1629120261145767\n",
      "56 Train Loss 0.8892787 Test MSE 5.958321417912842 Test RE 1.1667290837177076\n",
      "57 Train Loss 0.8778236 Test MSE 6.013516706755314 Test RE 1.172120660678075\n",
      "58 Train Loss 0.87141275 Test MSE 6.017203886393999 Test RE 1.1724799477116394\n",
      "59 Train Loss 0.8638004 Test MSE 6.044506622496795 Test RE 1.175136969168492\n",
      "60 Train Loss 0.85596526 Test MSE 6.053842571139106 Test RE 1.1760441387744014\n",
      "61 Train Loss 0.8490685 Test MSE 6.055725244378338 Test RE 1.1762269924486364\n",
      "62 Train Loss 0.8415811 Test MSE 6.068534040821685 Test RE 1.1774702864527335\n",
      "63 Train Loss 0.8341049 Test MSE 6.043466167765042 Test RE 1.1750358253104027\n",
      "64 Train Loss 0.8276344 Test MSE 6.048491174921713 Test RE 1.1755242318307255\n",
      "65 Train Loss 0.8215816 Test MSE 6.063091025130942 Test RE 1.1769421171336836\n",
      "66 Train Loss 0.81678903 Test MSE 6.06839806628313 Test RE 1.1774570948915881\n",
      "67 Train Loss 0.8109726 Test MSE 6.074872519316047 Test RE 1.1780850496076576\n",
      "68 Train Loss 0.8056995 Test MSE 6.086238138890722 Test RE 1.1791865879156962\n",
      "69 Train Loss 0.8022684 Test MSE 6.099945334852166 Test RE 1.1805137008944826\n",
      "70 Train Loss 0.7967403 Test MSE 6.1088737242032485 Test RE 1.181377334202654\n",
      "71 Train Loss 0.79135907 Test MSE 6.125665438291468 Test RE 1.1829998703760833\n",
      "72 Train Loss 0.7876497 Test MSE 6.132547880868975 Test RE 1.183664258848906\n",
      "73 Train Loss 0.7822864 Test MSE 6.129850065723645 Test RE 1.1834038728966259\n",
      "74 Train Loss 0.77903557 Test MSE 6.127788354460218 Test RE 1.1832048433725977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Train Loss 0.77671707 Test MSE 6.1369026074611845 Test RE 1.184084444682716\n",
      "76 Train Loss 0.77262044 Test MSE 6.149416845269516 Test RE 1.1852911094184677\n",
      "77 Train Loss 0.76869714 Test MSE 6.160186979437851 Test RE 1.1863286191517228\n",
      "78 Train Loss 0.7646541 Test MSE 6.187542363373004 Test RE 1.1889597508862821\n",
      "79 Train Loss 0.76030016 Test MSE 6.185090553827532 Test RE 1.1887241652911207\n",
      "80 Train Loss 0.75636214 Test MSE 6.195784921783402 Test RE 1.1897514067707884\n",
      "81 Train Loss 0.75300056 Test MSE 6.184941217293235 Test RE 1.1887098145700532\n",
      "82 Train Loss 0.74844956 Test MSE 6.182806385189418 Test RE 1.1885046456925685\n",
      "83 Train Loss 0.74441504 Test MSE 6.216871743916631 Test RE 1.1917742954429484\n",
      "84 Train Loss 0.74209887 Test MSE 6.233014567813019 Test RE 1.193320581963199\n",
      "85 Train Loss 0.7376069 Test MSE 6.25876865431948 Test RE 1.1957833710689771\n",
      "86 Train Loss 0.73508 Test MSE 6.2721218942783175 Test RE 1.1970583083160673\n",
      "87 Train Loss 0.73264 Test MSE 6.272388800695839 Test RE 1.19708377809735\n",
      "88 Train Loss 0.7297269 Test MSE 6.270208673033204 Test RE 1.196875721617067\n",
      "89 Train Loss 0.72695357 Test MSE 6.286193372197496 Test RE 1.1984003535479106\n",
      "90 Train Loss 0.72473717 Test MSE 6.3077486490430825 Test RE 1.2004532449781664\n",
      "91 Train Loss 0.7217777 Test MSE 6.3356703793701294 Test RE 1.2031072600797252\n",
      "92 Train Loss 0.71911967 Test MSE 6.337216650146539 Test RE 1.2032540650737156\n",
      "93 Train Loss 0.7160707 Test MSE 6.332842084482455 Test RE 1.2028386916609966\n",
      "94 Train Loss 0.7135929 Test MSE 6.353687418936427 Test RE 1.2048167115754096\n",
      "95 Train Loss 0.71043 Test MSE 6.3766486073641575 Test RE 1.2069917536774666\n",
      "96 Train Loss 0.707765 Test MSE 6.3895946773365555 Test RE 1.208216368495189\n",
      "97 Train Loss 0.70614207 Test MSE 6.3992917278570545 Test RE 1.2091328345569803\n",
      "98 Train Loss 0.7035562 Test MSE 6.387495802533225 Test RE 1.2080179127789168\n",
      "99 Train Loss 0.70109415 Test MSE 6.398990987900734 Test RE 1.2091044221291882\n",
      "Training time: 68.01\n",
      "2\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 50.221962 Test MSE 8.444644758941038 Test RE 1.3889888282554521\n",
      "1 Train Loss 33.3426 Test MSE 5.956972857500763 Test RE 1.1665970420249472\n",
      "2 Train Loss 23.542746 Test MSE 5.942674169028632 Test RE 1.1651960930900227\n",
      "3 Train Loss 19.599129 Test MSE 5.664249227734771 Test RE 1.1375728996725472\n",
      "4 Train Loss 14.893078 Test MSE 5.902247919115894 Test RE 1.1612260881512206\n",
      "5 Train Loss 12.439947 Test MSE 6.049807337195376 Test RE 1.1756521229396668\n",
      "6 Train Loss 11.275887 Test MSE 5.760145387254843 Test RE 1.1471620804112863\n",
      "7 Train Loss 10.307838 Test MSE 5.8830785363306335 Test RE 1.159338833400592\n",
      "8 Train Loss 9.748263 Test MSE 5.87742268952237 Test RE 1.1587814194970596\n",
      "9 Train Loss 9.250576 Test MSE 5.8250751619939845 Test RE 1.1536095085584497\n",
      "10 Train Loss 8.741608 Test MSE 5.712564918679602 Test RE 1.1424143101357827\n",
      "11 Train Loss 8.268262 Test MSE 5.65715406380154 Test RE 1.1368602019229854\n",
      "12 Train Loss 7.647011 Test MSE 5.398728583269829 Test RE 1.1105901245814267\n",
      "13 Train Loss 6.9055862 Test MSE 4.996039470234988 Test RE 1.0683682932561096\n",
      "14 Train Loss 6.2541237 Test MSE 4.720004885800715 Test RE 1.0384349210035855\n",
      "15 Train Loss 5.7747183 Test MSE 4.354204597362563 Test RE 0.9973841820832249\n",
      "16 Train Loss 5.588669 Test MSE 4.308375639083217 Test RE 0.9921214539873559\n",
      "17 Train Loss 5.4347243 Test MSE 4.100711851776281 Test RE 0.9679160401767598\n",
      "18 Train Loss 5.2643623 Test MSE 3.875234397969002 Test RE 0.9409294214834056\n",
      "19 Train Loss 5.14618 Test MSE 3.720241040527694 Test RE 0.9219207714310667\n",
      "20 Train Loss 5.0215178 Test MSE 3.535747767044249 Test RE 0.8987702700103325\n",
      "21 Train Loss 4.8955503 Test MSE 3.305699906967835 Test RE 0.8690400130713101\n",
      "22 Train Loss 4.7890553 Test MSE 3.2122169522649107 Test RE 0.8566639574409032\n",
      "23 Train Loss 4.6894264 Test MSE 3.0838655621856876 Test RE 0.8393745146165873\n",
      "24 Train Loss 4.614725 Test MSE 2.9919670003057797 Test RE 0.8267733321709696\n",
      "25 Train Loss 4.4405994 Test MSE 2.8144085035053195 Test RE 0.8018656826598033\n",
      "26 Train Loss 4.311491 Test MSE 2.6252487625953407 Test RE 0.7744498348738729\n",
      "27 Train Loss 4.1319942 Test MSE 2.5069386112832204 Test RE 0.7567978854182763\n",
      "28 Train Loss 3.9186735 Test MSE 2.456634437553368 Test RE 0.7491664637721801\n",
      "29 Train Loss 3.6995153 Test MSE 2.367207691341902 Test RE 0.735404430353885\n",
      "30 Train Loss 2.7567017 Test MSE 1.745424665220616 Test RE 0.6314785669127634\n",
      "31 Train Loss 1.9822745 Test MSE 1.245449792515057 Test RE 0.5334223060809756\n",
      "32 Train Loss 1.5158476 Test MSE 1.0244736366596083 Test RE 0.48379174509397277\n",
      "33 Train Loss 1.1721141 Test MSE 0.8795261835685296 Test RE 0.4482625390835513\n",
      "34 Train Loss 0.79297614 Test MSE 0.6231267499961853 Test RE 0.37730821230780476\n",
      "35 Train Loss 0.61585724 Test MSE 0.5103976039042978 Test RE 0.3414777205440516\n",
      "36 Train Loss 0.51458645 Test MSE 0.3826535743247952 Test RE 0.2956725095738312\n",
      "37 Train Loss 0.38718182 Test MSE 0.297304020234583 Test RE 0.26062042654116513\n",
      "38 Train Loss 0.30596906 Test MSE 0.20550085703148244 Test RE 0.21667803029371194\n",
      "39 Train Loss 0.245544 Test MSE 0.14310099988654956 Test RE 0.1808128927890906\n",
      "40 Train Loss 0.20499179 Test MSE 0.12159485117252977 Test RE 0.1666731537187888\n",
      "41 Train Loss 0.16147223 Test MSE 0.10873908492697668 Test RE 0.1576162161335793\n",
      "42 Train Loss 0.13111044 Test MSE 0.06937416067202379 Test RE 0.1258945503970641\n",
      "43 Train Loss 0.11414421 Test MSE 0.04138119108752216 Test RE 0.09723207494484108\n",
      "44 Train Loss 0.09103837 Test MSE 0.02928147049756837 Test RE 0.08179080860300357\n",
      "45 Train Loss 0.071756884 Test MSE 0.02643825718687943 Test RE 0.07771851106735092\n",
      "46 Train Loss 0.06282747 Test MSE 0.018191710140356275 Test RE 0.0644680930440517\n",
      "47 Train Loss 0.051518183 Test MSE 0.01694206356329234 Test RE 0.06221444248389544\n",
      "48 Train Loss 0.041848693 Test MSE 0.010765620170512467 Test RE 0.049593822900688735\n",
      "49 Train Loss 0.036018074 Test MSE 0.009101915419026257 Test RE 0.04560100960098355\n",
      "50 Train Loss 0.031076424 Test MSE 0.00732214427754059 Test RE 0.04090036665753454\n",
      "51 Train Loss 0.026826203 Test MSE 0.00634727418199115 Test RE 0.03808041649341265\n",
      "52 Train Loss 0.023737261 Test MSE 0.005873408126071157 Test RE 0.036631369049544685\n",
      "53 Train Loss 0.02015806 Test MSE 0.0050768718707856755 Test RE 0.034056982150365234\n",
      "54 Train Loss 0.018160995 Test MSE 0.005469780627727951 Test RE 0.03535029274585087\n",
      "55 Train Loss 0.017028188 Test MSE 0.00517818324880389 Test RE 0.03439511517086121\n",
      "56 Train Loss 0.015439635 Test MSE 0.004882267381404631 Test RE 0.03339787542084993\n",
      "57 Train Loss 0.013370509 Test MSE 0.004926143689851547 Test RE 0.033547610963284256\n",
      "58 Train Loss 0.011738052 Test MSE 0.0038597399337143906 Test RE 0.02969525656442676\n",
      "59 Train Loss 0.011049783 Test MSE 0.0034573563877135344 Test RE 0.028104776434709832\n",
      "60 Train Loss 0.010285882 Test MSE 0.003362322177328641 Test RE 0.02771581940656543\n",
      "61 Train Loss 0.009751832 Test MSE 0.0031718635738093802 Test RE 0.02691939592320327\n",
      "62 Train Loss 0.008872332 Test MSE 0.0034505868512342023 Test RE 0.028077248244067567\n",
      "63 Train Loss 0.008240685 Test MSE 0.003252436114644286 Test RE 0.027259158674869707\n",
      "64 Train Loss 0.0074331206 Test MSE 0.0031225711448534927 Test RE 0.026709406101864792\n",
      "65 Train Loss 0.0069696642 Test MSE 0.002977036772134911 Test RE 0.026079553986683043\n",
      "66 Train Loss 0.00650069 Test MSE 0.0026849276819160164 Test RE 0.024767054313749075\n",
      "67 Train Loss 0.0059113186 Test MSE 0.0024479815258098667 Test RE 0.0236489644413647\n",
      "68 Train Loss 0.005639995 Test MSE 0.0023479780740935405 Test RE 0.02316088119346644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 0.005311354 Test MSE 0.002286713025030584 Test RE 0.022856719205736845\n",
      "70 Train Loss 0.005146964 Test MSE 0.0022510592553730458 Test RE 0.02267783148964826\n",
      "71 Train Loss 0.0047796452 Test MSE 0.0019393789871018428 Test RE 0.021049384592726015\n",
      "72 Train Loss 0.0044670706 Test MSE 0.00188172463812097 Test RE 0.02073414330912176\n",
      "73 Train Loss 0.0041570505 Test MSE 0.001612400628128654 Test RE 0.019193074082137617\n",
      "74 Train Loss 0.0040481733 Test MSE 0.0015991084108554934 Test RE 0.019113798972802215\n",
      "75 Train Loss 0.0038614504 Test MSE 0.0014759753230221364 Test RE 0.018363168044796506\n",
      "76 Train Loss 0.0035461807 Test MSE 0.0012178302192622128 Test RE 0.01668020690811232\n",
      "77 Train Loss 0.0034200926 Test MSE 0.0012010031659390593 Test RE 0.016564568851714395\n",
      "78 Train Loss 0.0032375874 Test MSE 0.0010741953799622498 Test RE 0.01566569620782622\n",
      "79 Train Loss 0.003092718 Test MSE 0.0010247279049376624 Test RE 0.015300736699501893\n",
      "80 Train Loss 0.0029255585 Test MSE 0.0009786721395977354 Test RE 0.014952942830389735\n",
      "81 Train Loss 0.0028476275 Test MSE 0.0009068464249771792 Test RE 0.014393782400161623\n",
      "82 Train Loss 0.0026566726 Test MSE 0.0008645336036250905 Test RE 0.014053969269206427\n",
      "83 Train Loss 0.002535059 Test MSE 0.0008534947229049248 Test RE 0.01396395627999761\n",
      "84 Train Loss 0.002508293 Test MSE 0.0008384076622201534 Test RE 0.013839986918276152\n",
      "85 Train Loss 0.002341388 Test MSE 0.0008776046825018592 Test RE 0.014159813268526594\n",
      "86 Train Loss 0.0022211508 Test MSE 0.0008313513650191684 Test RE 0.013781623059722779\n",
      "87 Train Loss 0.0021774368 Test MSE 0.0007749588729368848 Test RE 0.013305995977994523\n",
      "88 Train Loss 0.002105493 Test MSE 0.0006798050078281476 Test RE 0.012462358492922742\n",
      "89 Train Loss 0.00200972 Test MSE 0.0006286056940558361 Test RE 0.011983873488086329\n",
      "90 Train Loss 0.0019247811 Test MSE 0.0006253015578699207 Test RE 0.011952336612007876\n",
      "91 Train Loss 0.0018976482 Test MSE 0.000626581342296535 Test RE 0.011964561590016933\n",
      "92 Train Loss 0.0018448988 Test MSE 0.0006355953205020301 Test RE 0.012050315170441708\n",
      "93 Train Loss 0.0017769602 Test MSE 0.0006204697376242061 Test RE 0.011906068104734945\n",
      "94 Train Loss 0.001652848 Test MSE 0.0005054678405393852 Test RE 0.010746197674727889\n",
      "95 Train Loss 0.0015836556 Test MSE 0.0005200899580468622 Test RE 0.010900521968367369\n",
      "96 Train Loss 0.001523318 Test MSE 0.0004885658776958501 Test RE 0.010565003035809147\n",
      "97 Train Loss 0.0014997591 Test MSE 0.0004724334130103178 Test RE 0.01038911044247446\n",
      "98 Train Loss 0.001444012 Test MSE 0.0004023227703470041 Test RE 0.009587279018890721\n",
      "99 Train Loss 0.0013988018 Test MSE 0.0003788815784284301 Test RE 0.00930378798837254\n",
      "Training time: 68.25\n",
      "3\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 47.791557 Test MSE 8.420060721074194 Test RE 1.38696554348104\n",
      "1 Train Loss 38.91272 Test MSE 8.037872758090579 Test RE 1.3551227106464863\n",
      "2 Train Loss 33.710327 Test MSE 8.299114987744021 Test RE 1.3769683286577263\n",
      "3 Train Loss 27.640049 Test MSE 8.530823223251563 Test RE 1.3960582246554922\n",
      "4 Train Loss 24.816763 Test MSE 8.679915571932433 Test RE 1.4082047688882302\n",
      "5 Train Loss 22.680178 Test MSE 8.705460796893245 Test RE 1.4102754387513827\n",
      "6 Train Loss 19.522038 Test MSE 8.258921025098175 Test RE 1.3736298408425065\n",
      "7 Train Loss 16.688114 Test MSE 7.920334743820277 Test RE 1.3451782255121012\n",
      "8 Train Loss 15.512459 Test MSE 8.351399712177418 Test RE 1.3812989936541662\n",
      "9 Train Loss 14.804535 Test MSE 8.410204185253964 Test RE 1.38615351378877\n",
      "10 Train Loss 14.210916 Test MSE 8.470582242563827 Test RE 1.3911203124408769\n",
      "11 Train Loss 13.861097 Test MSE 8.350566912114479 Test RE 1.381230120494696\n",
      "12 Train Loss 13.323233 Test MSE 8.435698367201756 Test RE 1.3882528747920295\n",
      "13 Train Loss 12.866516 Test MSE 8.410775589053317 Test RE 1.3862006018209934\n",
      "14 Train Loss 12.010393 Test MSE 8.226721966141287 Test RE 1.370949540243\n",
      "15 Train Loss 9.565407 Test MSE 7.248881260621976 Test RE 1.2868963029843208\n",
      "16 Train Loss 8.59644 Test MSE 7.033052068201412 Test RE 1.2675934214101459\n",
      "17 Train Loss 7.497678 Test MSE 6.2140835507557135 Test RE 1.1915070171613364\n",
      "18 Train Loss 7.052804 Test MSE 6.190464737215836 Test RE 1.1892404903550187\n",
      "19 Train Loss 6.65753 Test MSE 6.0486668020611525 Test RE 1.1755412982737068\n",
      "20 Train Loss 6.355402 Test MSE 6.130692567241589 Test RE 1.1834851950572594\n",
      "21 Train Loss 6.1310167 Test MSE 6.07871323570707 Test RE 1.1784574010940811\n",
      "22 Train Loss 5.8539433 Test MSE 5.974312906635361 Test RE 1.1682937217771312\n",
      "23 Train Loss 4.9458895 Test MSE 5.0125127797129085 Test RE 1.070128195060514\n",
      "24 Train Loss 4.0248003 Test MSE 4.847542577351796 Test RE 1.0523710112115354\n",
      "25 Train Loss 3.391173 Test MSE 4.9890066794643175 Test RE 1.0676160717457481\n",
      "26 Train Loss 2.9693255 Test MSE 4.998747674757176 Test RE 1.068657819376303\n",
      "27 Train Loss 2.735801 Test MSE 5.020528558185325 Test RE 1.0709835029984103\n",
      "28 Train Loss 2.5600705 Test MSE 5.121490073415266 Test RE 1.0816985011424962\n",
      "29 Train Loss 2.422899 Test MSE 5.1799021191411105 Test RE 1.0878495512305062\n",
      "30 Train Loss 2.3206177 Test MSE 5.165789546801201 Test RE 1.0863666248910802\n",
      "31 Train Loss 2.2276917 Test MSE 5.105256926020523 Test RE 1.079982857144693\n",
      "32 Train Loss 2.142826 Test MSE 5.18745609215063 Test RE 1.0886424805337316\n",
      "33 Train Loss 2.0836883 Test MSE 5.2754743765961285 Test RE 1.097839415897098\n",
      "34 Train Loss 2.0400674 Test MSE 5.30141255778272 Test RE 1.1005350067726325\n",
      "35 Train Loss 1.9815707 Test MSE 5.376838777735028 Test RE 1.108336325919102\n",
      "36 Train Loss 1.9297093 Test MSE 5.426141347161508 Test RE 1.1134061391205528\n",
      "37 Train Loss 1.8804901 Test MSE 5.41492560786329 Test RE 1.1122548483765256\n",
      "38 Train Loss 1.8252677 Test MSE 5.4538080674975555 Test RE 1.1162410385435555\n",
      "39 Train Loss 1.789071 Test MSE 5.51229997706087 Test RE 1.1222108985433579\n",
      "40 Train Loss 1.7549248 Test MSE 5.523342207027156 Test RE 1.1233343416894421\n",
      "41 Train Loss 1.7209833 Test MSE 5.550133713100288 Test RE 1.1260554668963922\n",
      "42 Train Loss 1.6802853 Test MSE 5.554085222473111 Test RE 1.1264562524673938\n",
      "43 Train Loss 1.6389445 Test MSE 5.557198765858331 Test RE 1.1267719461306205\n",
      "44 Train Loss 1.6005392 Test MSE 5.567644712838983 Test RE 1.1278304537117598\n",
      "45 Train Loss 1.5719945 Test MSE 5.559555192922412 Test RE 1.1270108141838446\n",
      "46 Train Loss 1.5248352 Test MSE 5.612050073158993 Test RE 1.1323190892514652\n",
      "47 Train Loss 1.481037 Test MSE 5.629844847094582 Test RE 1.1341128557672935\n",
      "48 Train Loss 1.4547211 Test MSE 5.6488192913309145 Test RE 1.1360224163801222\n",
      "49 Train Loss 1.410811 Test MSE 5.668494436368592 Test RE 1.1379991105959597\n",
      "50 Train Loss 1.3707014 Test MSE 5.711584603131308 Test RE 1.1423162828417683\n",
      "51 Train Loss 1.3450919 Test MSE 5.730783666919661 Test RE 1.1442345774501892\n",
      "52 Train Loss 1.3186468 Test MSE 5.711162784299694 Test RE 1.1422741002033125\n",
      "53 Train Loss 1.287343 Test MSE 5.748892826102504 Test RE 1.1460410304187603\n",
      "54 Train Loss 1.2648333 Test MSE 5.7760246240163635 Test RE 1.1487422073078026\n",
      "55 Train Loss 1.237311 Test MSE 5.804475613762296 Test RE 1.1515679141897073\n",
      "56 Train Loss 1.2152482 Test MSE 5.8086300716495005 Test RE 1.1519799483669366\n",
      "57 Train Loss 1.191202 Test MSE 5.812676964228403 Test RE 1.152381172694538\n",
      "58 Train Loss 1.1747522 Test MSE 5.874381949340369 Test RE 1.1584816274568748\n",
      "59 Train Loss 1.1600528 Test MSE 5.859182636783374 Test RE 1.1569819353168544\n",
      "60 Train Loss 1.1373641 Test MSE 5.900897001296668 Test RE 1.1610931887195655\n",
      "61 Train Loss 1.1215951 Test MSE 5.958034926763572 Test RE 1.1667010337393056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 1.1067909 Test MSE 5.952226512387024 Test RE 1.1661321938808233\n",
      "63 Train Loss 1.0831405 Test MSE 5.986245863141009 Test RE 1.1694599013756302\n",
      "64 Train Loss 1.0625416 Test MSE 6.04000300506963 Test RE 1.1746991043570385\n",
      "65 Train Loss 1.0489897 Test MSE 6.028957572506726 Test RE 1.1736245190403196\n",
      "66 Train Loss 1.0272093 Test MSE 5.968779927611941 Test RE 1.1677526016427515\n",
      "67 Train Loss 1.0109632 Test MSE 5.983605964139186 Test RE 1.1692020104923135\n",
      "68 Train Loss 1.0010535 Test MSE 5.981253712460279 Test RE 1.1689721718503319\n",
      "69 Train Loss 0.98891133 Test MSE 5.9640836179027765 Test RE 1.1672931101623325\n",
      "70 Train Loss 0.97529685 Test MSE 6.008926290827992 Test RE 1.1716732063174387\n",
      "71 Train Loss 0.9583596 Test MSE 6.000576782164192 Test RE 1.170858893089661\n",
      "72 Train Loss 0.9489937 Test MSE 6.019360651324075 Test RE 1.1726900566860607\n",
      "73 Train Loss 0.9361214 Test MSE 6.063823300684723 Test RE 1.1770131881365784\n",
      "74 Train Loss 0.9255479 Test MSE 6.085742496191961 Test RE 1.1791385724495789\n",
      "75 Train Loss 0.9132533 Test MSE 6.086548084194059 Test RE 1.1792166129232087\n",
      "76 Train Loss 0.9046819 Test MSE 6.091579232244757 Test RE 1.1797038831928408\n",
      "77 Train Loss 0.89239043 Test MSE 6.126362504013126 Test RE 1.1830671777738264\n",
      "78 Train Loss 0.88286436 Test MSE 6.152151657275821 Test RE 1.1855546456299177\n",
      "79 Train Loss 0.87503487 Test MSE 6.163747659686977 Test RE 1.18667142746826\n",
      "80 Train Loss 0.86760604 Test MSE 6.167444336512453 Test RE 1.1870272242556403\n",
      "81 Train Loss 0.856858 Test MSE 6.158335355518372 Test RE 1.1861503129131805\n",
      "82 Train Loss 0.85142106 Test MSE 6.161505173843038 Test RE 1.1864555412812097\n",
      "83 Train Loss 0.8472693 Test MSE 6.160135676067317 Test RE 1.1863236791406773\n",
      "84 Train Loss 0.84096 Test MSE 6.1827872755478985 Test RE 1.1885028089930296\n",
      "85 Train Loss 0.8320312 Test MSE 6.204001318228446 Test RE 1.1905400260193288\n",
      "86 Train Loss 0.8271948 Test MSE 6.205365827150306 Test RE 1.1906709425915947\n",
      "87 Train Loss 0.82277465 Test MSE 6.203535994443052 Test RE 1.1904953776584306\n",
      "88 Train Loss 0.8182817 Test MSE 6.207133874863719 Test RE 1.1908405549211047\n",
      "89 Train Loss 0.8131021 Test MSE 6.191791383473729 Test RE 1.1893679134964987\n",
      "90 Train Loss 0.8062573 Test MSE 6.2077400029047585 Test RE 1.1908986964278874\n",
      "91 Train Loss 0.80221474 Test MSE 6.213938948465652 Test RE 1.1914931538422937\n",
      "92 Train Loss 0.7983314 Test MSE 6.224671372799668 Test RE 1.1925216555259213\n",
      "93 Train Loss 0.79505825 Test MSE 6.228614490657423 Test RE 1.1928993067070364\n",
      "94 Train Loss 0.789838 Test MSE 6.231155124410056 Test RE 1.193142571983301\n",
      "95 Train Loss 0.7858491 Test MSE 6.218623242150092 Test RE 1.191942164723361\n",
      "96 Train Loss 0.7808153 Test MSE 6.221600780666447 Test RE 1.1922274874417256\n",
      "97 Train Loss 0.7770233 Test MSE 6.221707000834521 Test RE 1.1922376647311443\n",
      "98 Train Loss 0.77422917 Test MSE 6.230977571253836 Test RE 1.1931255729089416\n",
      "99 Train Loss 0.77084637 Test MSE 6.2384062322967155 Test RE 1.1938365917810998\n",
      "Training time: 67.19\n",
      "4\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.965576 Test MSE 8.394966576490877 Test RE 1.3848972279603584\n",
      "1 Train Loss 56.87903 Test MSE 8.127842950059641 Test RE 1.3626857423796948\n",
      "2 Train Loss 49.38477 Test MSE 8.94817354627091 Test RE 1.429799890655758\n",
      "3 Train Loss 45.592323 Test MSE 8.049550360456443 Test RE 1.356106729754608\n",
      "4 Train Loss 44.33599 Test MSE 8.118633508328413 Test RE 1.3619135121624033\n",
      "5 Train Loss 43.96929 Test MSE 8.120795987386826 Test RE 1.3620948797138326\n",
      "6 Train Loss 41.528145 Test MSE 7.759830351880372 Test RE 1.3314785476263602\n",
      "7 Train Loss 38.866135 Test MSE 7.813660908525145 Test RE 1.3360888519094452\n",
      "8 Train Loss 37.426857 Test MSE 7.328458842457279 Test RE 1.293940739748145\n",
      "9 Train Loss 34.55433 Test MSE 5.7294751421495675 Test RE 1.1441039369608204\n",
      "10 Train Loss 31.703 Test MSE 4.586238319032213 Test RE 1.023614359394524\n",
      "11 Train Loss 26.678026 Test MSE 3.8749847863888234 Test RE 0.9408991174246318\n",
      "12 Train Loss 18.588467 Test MSE 4.483900763572766 Test RE 1.0121294376822587\n",
      "13 Train Loss 15.104168 Test MSE 3.586674313180478 Test RE 0.9052197723947917\n",
      "14 Train Loss 12.675297 Test MSE 3.7288697904174404 Test RE 0.9229893065444055\n",
      "15 Train Loss 11.782126 Test MSE 3.8048544918533858 Test RE 0.9323459457960789\n",
      "16 Train Loss 11.140853 Test MSE 4.020554432362176 Test RE 0.9584093311203848\n",
      "17 Train Loss 10.043261 Test MSE 4.05906442920443 Test RE 0.9629883490237195\n",
      "18 Train Loss 9.330221 Test MSE 3.9957794834860425 Test RE 0.9554518740560829\n",
      "19 Train Loss 8.829858 Test MSE 3.8861831148393846 Test RE 0.9422576899808062\n",
      "20 Train Loss 8.44969 Test MSE 3.9255385961801594 Test RE 0.9470168059431855\n",
      "21 Train Loss 8.112654 Test MSE 3.7934012494732445 Test RE 0.9309416303135715\n",
      "22 Train Loss 7.9561768 Test MSE 3.651553599649655 Test RE 0.9133703307691038\n",
      "23 Train Loss 7.6681986 Test MSE 3.4715940601225097 Test RE 0.890579160789998\n",
      "24 Train Loss 5.9902086 Test MSE 2.3880824582330185 Test RE 0.738639824776225\n",
      "25 Train Loss 5.20014 Test MSE 2.261946532421321 Test RE 0.718868125913054\n",
      "26 Train Loss 4.8573475 Test MSE 2.1580986882623967 Test RE 0.7021723285889995\n",
      "27 Train Loss 4.6973085 Test MSE 2.1442845143930582 Test RE 0.6999213881924162\n",
      "28 Train Loss 4.572117 Test MSE 2.1614697194743515 Test RE 0.7027205243727954\n",
      "29 Train Loss 4.4914575 Test MSE 2.1464693360417684 Test RE 0.7002778740181613\n",
      "30 Train Loss 4.426941 Test MSE 2.146755337143746 Test RE 0.7003245258778635\n",
      "31 Train Loss 4.397224 Test MSE 2.148823561236238 Test RE 0.7006617975126956\n",
      "32 Train Loss 4.338148 Test MSE 2.1360568898258476 Test RE 0.6985772976530529\n",
      "33 Train Loss 4.3349614 Test MSE 2.137233733988744 Test RE 0.698769709057323\n",
      "34 Train Loss 4.306581 Test MSE 2.133113797622661 Test RE 0.6980958764686501\n",
      "35 Train Loss 4.23181 Test MSE 2.096603107044268 Test RE 0.6920957348016394\n",
      "36 Train Loss 4.1437626 Test MSE 2.0827058740675675 Test RE 0.689798159464174\n",
      "37 Train Loss 4.0513544 Test MSE 2.071116268364066 Test RE 0.6878762266695442\n",
      "38 Train Loss 3.9446268 Test MSE 1.9927221313272017 Test RE 0.6747321938173174\n",
      "39 Train Loss 3.5111146 Test MSE 1.9382881516784014 Test RE 0.6654527602004633\n",
      "40 Train Loss 3.1029928 Test MSE 2.0161162105386174 Test RE 0.6786812343880689\n",
      "41 Train Loss 2.7571466 Test MSE 1.9836787235453233 Test RE 0.6731994118645341\n",
      "42 Train Loss 2.533749 Test MSE 1.8890367730108022 Test RE 0.6569438727774877\n",
      "43 Train Loss 2.1482525 Test MSE 1.7018571140249343 Test RE 0.6235475935328932\n",
      "44 Train Loss 1.9807954 Test MSE 1.6077964554822768 Test RE 0.6060711253913372\n",
      "45 Train Loss 1.9266573 Test MSE 1.5722261924001117 Test RE 0.5993293880910622\n",
      "46 Train Loss 1.8007429 Test MSE 1.3278523000605107 Test RE 0.5507860667600226\n",
      "47 Train Loss 1.6436468 Test MSE 0.8068535783895333 Test RE 0.42934402659524634\n",
      "48 Train Loss 1.5340332 Test MSE 0.5343902233320648 Test RE 0.34941159473550937\n",
      "49 Train Loss 1.3552411 Test MSE 0.13350717471393786 Test RE 0.17464669158227628\n",
      "50 Train Loss 1.1648607 Test MSE 0.10159597043752415 Test RE 0.15235134820906338\n",
      "51 Train Loss 1.0194921 Test MSE 0.09817681647695052 Test RE 0.14976575940018622\n",
      "52 Train Loss 0.9229989 Test MSE 0.09468679399159236 Test RE 0.14707971046813006\n",
      "53 Train Loss 0.7484784 Test MSE 0.0776507565988282 Test RE 0.13319284824149044\n",
      "54 Train Loss 0.66164905 Test MSE 0.08333842559240323 Test RE 0.13798462768632852\n",
      "55 Train Loss 0.57302046 Test MSE 0.10287096966022966 Test RE 0.15330434962200468\n",
      "56 Train Loss 0.5184326 Test MSE 0.11317022818819447 Test RE 0.1607955983316189\n",
      "57 Train Loss 0.48738006 Test MSE 0.0860906631228221 Test RE 0.14024458020086603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.44845444 Test MSE 0.08570212735331056 Test RE 0.13992775342326352\n",
      "59 Train Loss 0.42563018 Test MSE 0.08162747530963946 Test RE 0.13656085977523477\n",
      "60 Train Loss 0.41360345 Test MSE 0.07767530797879967 Test RE 0.13321390283213888\n",
      "61 Train Loss 0.39228994 Test MSE 0.06488900443440676 Test RE 0.12175690942007095\n",
      "62 Train Loss 0.3655321 Test MSE 0.05847567145044651 Test RE 0.11558345413863949\n",
      "63 Train Loss 0.34806094 Test MSE 0.05301233893217854 Test RE 0.11005164618789239\n",
      "64 Train Loss 0.33488446 Test MSE 0.05117141000778118 Test RE 0.10812391246301355\n",
      "65 Train Loss 0.32371035 Test MSE 0.056213957656624805 Test RE 0.11332615170539384\n",
      "66 Train Loss 0.31509203 Test MSE 0.05900099418110472 Test RE 0.11610147176244594\n",
      "67 Train Loss 0.30909765 Test MSE 0.06281210560196761 Test RE 0.11979252975719286\n",
      "68 Train Loss 0.2623377 Test MSE 0.04058538428526835 Test RE 0.09629259517713516\n",
      "69 Train Loss 0.24651934 Test MSE 0.04078433871204044 Test RE 0.09652832556725863\n",
      "70 Train Loss 0.23823753 Test MSE 0.04036792285201056 Test RE 0.09603427495673732\n",
      "71 Train Loss 0.23558947 Test MSE 0.042203489415041616 Test RE 0.09819338698183921\n",
      "72 Train Loss 0.22787209 Test MSE 0.041150026293166206 Test RE 0.09696011430399264\n",
      "73 Train Loss 0.21098635 Test MSE 0.05257547671482425 Test RE 0.1095972532481603\n",
      "74 Train Loss 0.2055375 Test MSE 0.047069356962513395 Test RE 0.10369962667346626\n",
      "75 Train Loss 0.20232072 Test MSE 0.042408092469083954 Test RE 0.09843112059149314\n",
      "76 Train Loss 0.18854256 Test MSE 0.044238384824766566 Test RE 0.10053277982569761\n",
      "77 Train Loss 0.18381421 Test MSE 0.04104885048931322 Test RE 0.0968408427530183\n",
      "78 Train Loss 0.17344917 Test MSE 0.0328375532721249 Test RE 0.0866150689524192\n",
      "79 Train Loss 0.16475001 Test MSE 0.027410402724394323 Test RE 0.07913448283701101\n",
      "80 Train Loss 0.1615288 Test MSE 0.023375249888862654 Test RE 0.07307792232292795\n",
      "81 Train Loss 0.15618286 Test MSE 0.02327793128243911 Test RE 0.0729256403311025\n",
      "82 Train Loss 0.14383179 Test MSE 0.021843132477264042 Test RE 0.07064241214149636\n",
      "83 Train Loss 0.13496467 Test MSE 0.0221290559159107 Test RE 0.07110325841070847\n",
      "84 Train Loss 0.1300093 Test MSE 0.02117912147705184 Test RE 0.06956039363288913\n",
      "85 Train Loss 0.12808254 Test MSE 0.021357563492629 Test RE 0.06985281514433302\n",
      "86 Train Loss 0.1271403 Test MSE 0.021717256726178167 Test RE 0.07043857199865197\n",
      "87 Train Loss 0.12612912 Test MSE 0.021157673775456166 Test RE 0.06952516345429062\n",
      "88 Train Loss 0.11946132 Test MSE 0.023306766287020515 Test RE 0.07297079383611678\n",
      "89 Train Loss 0.11610611 Test MSE 0.022769036451771713 Test RE 0.07212409661374804\n",
      "90 Train Loss 0.1103729 Test MSE 0.020908461786325976 Test RE 0.06911448909253369\n",
      "91 Train Loss 0.10578225 Test MSE 0.02005532664316839 Test RE 0.06768975312590879\n",
      "92 Train Loss 0.10035372 Test MSE 0.021477107558936667 Test RE 0.07004803491199288\n",
      "93 Train Loss 0.098800965 Test MSE 0.019940325473829394 Test RE 0.06749540096376423\n",
      "94 Train Loss 0.096081905 Test MSE 0.01803264851601927 Test RE 0.06418563160345794\n",
      "95 Train Loss 0.08109369 Test MSE 0.01619695516857639 Test RE 0.06083097120934676\n",
      "96 Train Loss 0.0732634 Test MSE 0.014504217046375018 Test RE 0.05756456210445062\n",
      "97 Train Loss 0.07219086 Test MSE 0.01416889342192727 Test RE 0.05689525222550942\n",
      "98 Train Loss 0.0712281 Test MSE 0.014533411480276454 Test RE 0.05762246664276005\n",
      "99 Train Loss 0.07039011 Test MSE 0.015049563413127012 Test RE 0.05863676617635372\n",
      "Training time: 75.12\n",
      "5\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 53.810463 Test MSE 8.49050559514426 Test RE 1.392755353662849\n",
      "1 Train Loss 43.901623 Test MSE 8.016504002847421 Test RE 1.3533202090502994\n",
      "2 Train Loss 36.18959 Test MSE 8.509998668073614 Test RE 1.3943532276980668\n",
      "3 Train Loss 31.34026 Test MSE 8.382782567940817 Test RE 1.383891879915131\n",
      "4 Train Loss 29.595428 Test MSE 8.584432887452637 Test RE 1.400437930883365\n",
      "5 Train Loss 28.2419 Test MSE 8.460509869672801 Test RE 1.3902929755480848\n",
      "6 Train Loss 26.929813 Test MSE 8.240286432106615 Test RE 1.372079306100891\n",
      "7 Train Loss 25.467367 Test MSE 8.494387850334155 Test RE 1.3930737336282069\n",
      "8 Train Loss 23.479794 Test MSE 8.292417248526169 Test RE 1.3764125804668597\n",
      "9 Train Loss 19.022655 Test MSE 6.355425843724624 Test RE 1.2049815245297526\n",
      "10 Train Loss 16.708443 Test MSE 6.230155189654825 Test RE 1.1930468343095084\n",
      "11 Train Loss 14.762587 Test MSE 5.738785672982762 Test RE 1.1450331574134256\n",
      "12 Train Loss 12.287539 Test MSE 4.996870960604993 Test RE 1.0684571937736427\n",
      "13 Train Loss 10.434639 Test MSE 4.563691318760137 Test RE 1.0210950976900628\n",
      "14 Train Loss 8.322124 Test MSE 3.975283349404016 Test RE 0.9529982543070378\n",
      "15 Train Loss 6.8385653 Test MSE 3.7227811463763687 Test RE 0.9222354522171989\n",
      "16 Train Loss 5.5224 Test MSE 3.3712460489724285 Test RE 0.8776134804206155\n",
      "17 Train Loss 3.7410135 Test MSE 2.6655939272096565 Test RE 0.7803780681723701\n",
      "18 Train Loss 2.727709 Test MSE 2.4989342826869416 Test RE 0.7555887409277829\n",
      "19 Train Loss 2.2382095 Test MSE 2.550742418184062 Test RE 0.7633810281640209\n",
      "20 Train Loss 1.8917637 Test MSE 2.5315984682554227 Test RE 0.7605109515703378\n",
      "21 Train Loss 1.7019594 Test MSE 2.570559076683329 Test RE 0.7663406357280378\n",
      "22 Train Loss 1.5811995 Test MSE 2.5406307506345085 Test RE 0.7618664259257406\n",
      "23 Train Loss 1.4528985 Test MSE 2.557390112843628 Test RE 0.7643751351812768\n",
      "24 Train Loss 1.350879 Test MSE 2.5460650351889473 Test RE 0.7626807881454131\n",
      "25 Train Loss 1.2986711 Test MSE 2.5861126459126185 Test RE 0.7686555711510025\n",
      "26 Train Loss 1.2290882 Test MSE 2.584053251324833 Test RE 0.7683494591200537\n",
      "27 Train Loss 1.1894591 Test MSE 2.571696347609089 Test RE 0.7665101398170059\n",
      "28 Train Loss 1.1583081 Test MSE 2.564278962599105 Test RE 0.7654039426693736\n",
      "29 Train Loss 1.1202193 Test MSE 2.567697495596889 Test RE 0.7659139665779211\n",
      "30 Train Loss 1.0945163 Test MSE 2.564859903987722 Test RE 0.7654906394863606\n",
      "31 Train Loss 1.0786152 Test MSE 2.5615138750541298 Test RE 0.7649911600151376\n",
      "32 Train Loss 1.0661098 Test MSE 2.56621819531856 Test RE 0.7656933058534533\n",
      "33 Train Loss 1.0531753 Test MSE 2.561335515827795 Test RE 0.7649645262326674\n",
      "34 Train Loss 1.0427178 Test MSE 2.564804551423342 Test RE 0.7654823793668802\n",
      "35 Train Loss 1.0317436 Test MSE 2.551908778335532 Test RE 0.7635555411694139\n",
      "36 Train Loss 1.0180663 Test MSE 2.5709811022032945 Test RE 0.7664035407269901\n",
      "37 Train Loss 1.002847 Test MSE 2.560283996231898 Test RE 0.7648074875007917\n",
      "38 Train Loss 0.992026 Test MSE 2.558112979392853 Test RE 0.7644831558884007\n",
      "39 Train Loss 0.9753658 Test MSE 2.540774161502616 Test RE 0.76188792814201\n",
      "40 Train Loss 0.96455765 Test MSE 2.548059125355552 Test RE 0.7629793972874379\n",
      "41 Train Loss 0.9552454 Test MSE 2.5663680650115954 Test RE 0.7657156641520434\n",
      "42 Train Loss 0.9441054 Test MSE 2.5775693958876458 Test RE 0.7673848900185882\n",
      "43 Train Loss 0.932479 Test MSE 2.5821052192758183 Test RE 0.7680597879284831\n",
      "44 Train Loss 0.91652036 Test MSE 2.578582296302748 Test RE 0.7675356537823191\n",
      "45 Train Loss 0.9071801 Test MSE 2.5860589568711414 Test RE 0.7686475922651839\n",
      "46 Train Loss 0.89764154 Test MSE 2.584360611261629 Test RE 0.7683951533833173\n",
      "47 Train Loss 0.8834111 Test MSE 2.5832053263802717 Test RE 0.768223386616209\n",
      "48 Train Loss 0.8750922 Test MSE 2.590028550215504 Test RE 0.7692373020150678\n",
      "49 Train Loss 0.8669487 Test MSE 2.5939111466240803 Test RE 0.7698136507854438\n",
      "50 Train Loss 0.85615 Test MSE 2.588714580914178 Test RE 0.7690421531186796\n",
      "51 Train Loss 0.8469124 Test MSE 2.587908064043976 Test RE 0.7689223458228066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 0.8324674 Test MSE 2.6077427637772197 Test RE 0.7718633761681588\n",
      "53 Train Loss 0.819613 Test MSE 2.6280143673879794 Test RE 0.7748576549668359\n",
      "54 Train Loss 0.8134737 Test MSE 2.629921984833476 Test RE 0.7751388299596785\n",
      "55 Train Loss 0.79848313 Test MSE 2.6248617108993555 Test RE 0.7743927425374122\n",
      "56 Train Loss 0.79134476 Test MSE 2.630018621320332 Test RE 0.7751530710675296\n",
      "57 Train Loss 0.7853792 Test MSE 2.629152458581507 Test RE 0.7750254172192534\n",
      "58 Train Loss 0.7751673 Test MSE 2.6453267457354914 Test RE 0.7774057020556306\n",
      "59 Train Loss 0.769215 Test MSE 2.644009534067034 Test RE 0.7772121276004783\n",
      "60 Train Loss 0.76436496 Test MSE 2.6484656200775962 Test RE 0.7778667897798309\n",
      "61 Train Loss 0.7560119 Test MSE 2.664181519564905 Test RE 0.7801712928674577\n",
      "62 Train Loss 0.74711525 Test MSE 2.673927494422225 Test RE 0.7815969819066931\n",
      "63 Train Loss 0.7427876 Test MSE 2.666275532550236 Test RE 0.7804778350301181\n",
      "64 Train Loss 0.738927 Test MSE 2.661210717157266 Test RE 0.7797361909009717\n",
      "65 Train Loss 0.729753 Test MSE 2.6697389559846054 Test RE 0.7809845808517656\n",
      "66 Train Loss 0.7259337 Test MSE 2.665943118250331 Test RE 0.7804291810037703\n",
      "67 Train Loss 0.722628 Test MSE 2.6720922553023017 Test RE 0.7813287129331864\n",
      "68 Train Loss 0.71797025 Test MSE 2.655120324318162 Test RE 0.7788434356119496\n",
      "69 Train Loss 0.71276045 Test MSE 2.660648835645742 Test RE 0.7796538707609295\n",
      "70 Train Loss 0.7103474 Test MSE 2.6558656005071364 Test RE 0.7789527362593551\n",
      "71 Train Loss 0.70568866 Test MSE 2.655910404716292 Test RE 0.7789593066622625\n",
      "72 Train Loss 0.70203847 Test MSE 2.659793073645548 Test RE 0.7795284780739229\n",
      "73 Train Loss 0.6987627 Test MSE 2.6739572813169885 Test RE 0.7816013352936606\n",
      "74 Train Loss 0.69292015 Test MSE 2.685760850454673 Test RE 0.7833245353437693\n",
      "75 Train Loss 0.6902145 Test MSE 2.697061572385785 Test RE 0.7849707803249767\n",
      "76 Train Loss 0.6870369 Test MSE 2.6977613473123414 Test RE 0.7850726073003239\n",
      "77 Train Loss 0.68104976 Test MSE 2.7032958174914103 Test RE 0.7858774847950915\n",
      "78 Train Loss 0.6787044 Test MSE 2.7188064927733806 Test RE 0.7881288210158666\n",
      "79 Train Loss 0.6751582 Test MSE 2.7324395764930833 Test RE 0.7901023322839513\n",
      "80 Train Loss 0.6711139 Test MSE 2.7374979295970494 Test RE 0.7908333216666559\n",
      "81 Train Loss 0.6677922 Test MSE 2.74208540954825 Test RE 0.7914956807729562\n",
      "82 Train Loss 0.6642998 Test MSE 2.735112395954348 Test RE 0.7904886692280558\n",
      "83 Train Loss 0.6584704 Test MSE 2.7520767181583476 Test RE 0.7929363519919037\n",
      "84 Train Loss 0.65226233 Test MSE 2.761327217873323 Test RE 0.7942678744731095\n",
      "85 Train Loss 0.6504016 Test MSE 2.7616764849844495 Test RE 0.7943181044626265\n",
      "86 Train Loss 0.6464333 Test MSE 2.762588832750314 Test RE 0.7944492991389925\n",
      "87 Train Loss 0.64355564 Test MSE 2.7710515882744224 Test RE 0.7956652037820516\n",
      "88 Train Loss 0.6397605 Test MSE 2.7901218681302953 Test RE 0.7983983794551013\n",
      "89 Train Loss 0.634752 Test MSE 2.7953334113957933 Test RE 0.799143677818918\n",
      "90 Train Loss 0.6290383 Test MSE 2.8097075250904133 Test RE 0.8011957144102722\n",
      "91 Train Loss 0.62654614 Test MSE 2.81434686571577 Test RE 0.8018569018629237\n",
      "92 Train Loss 0.6232816 Test MSE 2.8148456860924758 Test RE 0.8019279600620514\n",
      "93 Train Loss 0.61906016 Test MSE 2.8285578424065307 Test RE 0.8038788312092109\n",
      "94 Train Loss 0.6142881 Test MSE 2.8457671472486896 Test RE 0.8063205732825127\n",
      "95 Train Loss 0.61036974 Test MSE 2.8592383510975488 Test RE 0.8082267876539991\n",
      "96 Train Loss 0.6074197 Test MSE 2.858906415354591 Test RE 0.8081798718126032\n",
      "97 Train Loss 0.6016267 Test MSE 2.8754196603271858 Test RE 0.8105105630524556\n",
      "98 Train Loss 0.5964498 Test MSE 2.9003076845740297 Test RE 0.8140106686733025\n",
      "99 Train Loss 0.5941309 Test MSE 2.906393159707173 Test RE 0.8148642067267384\n",
      "Training time: 68.07\n",
      "6\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 57.861412 Test MSE 7.313130772123446 Test RE 1.2925868400497509\n",
      "1 Train Loss 48.010643 Test MSE 8.638261774597147 Test RE 1.4048218087163669\n",
      "2 Train Loss 45.45161 Test MSE 8.547906585269862 Test RE 1.3974553606355309\n",
      "3 Train Loss 43.497612 Test MSE 8.70931998581633 Test RE 1.410587996376766\n",
      "4 Train Loss 42.016136 Test MSE 9.410789986698894 Test RE 1.4662941474450368\n",
      "5 Train Loss 40.08352 Test MSE 9.188408433530423 Test RE 1.448865950100373\n",
      "6 Train Loss 38.083286 Test MSE 9.702128304837803 Test RE 1.4888178500389286\n",
      "7 Train Loss 31.14101 Test MSE 8.31329524429124 Test RE 1.3781442028711712\n",
      "8 Train Loss 29.339283 Test MSE 9.016313814709957 Test RE 1.4352335232492606\n",
      "9 Train Loss 27.973717 Test MSE 9.065546164340846 Test RE 1.4391466370400723\n",
      "10 Train Loss 26.166693 Test MSE 8.964680280325679 Test RE 1.431118062016943\n",
      "11 Train Loss 25.108425 Test MSE 9.075032997126891 Test RE 1.4398994528808107\n",
      "12 Train Loss 24.058348 Test MSE 9.135639465320242 Test RE 1.444699545846211\n",
      "13 Train Loss 23.354343 Test MSE 9.236910697754801 Test RE 1.4526849350114088\n",
      "14 Train Loss 21.333902 Test MSE 8.617505533872368 Test RE 1.4031330223976\n",
      "15 Train Loss 19.27025 Test MSE 8.463090172010142 Test RE 1.3905049664794917\n",
      "16 Train Loss 18.545488 Test MSE 8.267598571975268 Test RE 1.37435127939137\n",
      "17 Train Loss 17.452919 Test MSE 8.036764022463561 Test RE 1.3550292453298876\n",
      "18 Train Loss 16.83877 Test MSE 7.936978486526009 Test RE 1.3465908584009096\n",
      "19 Train Loss 16.543953 Test MSE 7.896278950418633 Test RE 1.343133871421792\n",
      "20 Train Loss 16.090652 Test MSE 7.985647608200156 Test RE 1.3507131596874364\n",
      "21 Train Loss 15.680721 Test MSE 8.131420103814634 Test RE 1.3629855759415508\n",
      "22 Train Loss 14.426342 Test MSE 7.563781729800448 Test RE 1.314551345954362\n",
      "23 Train Loss 10.955422 Test MSE 6.20322796927919 Test RE 1.19046582136294\n",
      "24 Train Loss 9.350318 Test MSE 5.837995986557732 Test RE 1.1548882327938543\n",
      "25 Train Loss 8.647599 Test MSE 5.879504587979762 Test RE 1.1589866328855913\n",
      "26 Train Loss 8.258193 Test MSE 5.792090011231456 Test RE 1.1503386490431176\n",
      "27 Train Loss 7.9943647 Test MSE 5.724018591794418 Test RE 1.143559005037126\n",
      "28 Train Loss 7.6869345 Test MSE 5.816628254739884 Test RE 1.1527727839321706\n",
      "29 Train Loss 7.4705153 Test MSE 5.762981040362286 Test RE 1.1474444129957966\n",
      "30 Train Loss 7.2364926 Test MSE 5.934062298546924 Test RE 1.1643515107025708\n",
      "31 Train Loss 7.0562086 Test MSE 5.843497748118508 Test RE 1.155432291355474\n",
      "32 Train Loss 6.8303127 Test MSE 6.069260635160668 Test RE 1.1775407744512667\n",
      "33 Train Loss 6.621171 Test MSE 6.281418102118894 Test RE 1.197945088157101\n",
      "34 Train Loss 6.5239286 Test MSE 6.280562155847239 Test RE 1.197863465540308\n",
      "35 Train Loss 6.1607146 Test MSE 6.309795321132186 Test RE 1.200647984418475\n",
      "36 Train Loss 5.8713403 Test MSE 6.403707505181927 Test RE 1.2095499385756907\n",
      "37 Train Loss 5.757635 Test MSE 6.461473282624037 Test RE 1.214993170422231\n",
      "38 Train Loss 5.6504045 Test MSE 6.433707082083604 Test RE 1.2123798295569073\n",
      "39 Train Loss 5.560369 Test MSE 6.4045895807457836 Test RE 1.2096332401400847\n",
      "40 Train Loss 5.4330344 Test MSE 6.445930232579851 Test RE 1.2135309597720148\n",
      "41 Train Loss 5.357533 Test MSE 6.5133685174605 Test RE 1.2198625135252708\n",
      "42 Train Loss 5.25961 Test MSE 6.6744670873793375 Test RE 1.2348561192572722\n",
      "43 Train Loss 5.2190127 Test MSE 6.7659080972878085 Test RE 1.2432861836724454\n",
      "44 Train Loss 5.152308 Test MSE 6.856662513098569 Test RE 1.2515968090078105\n",
      "45 Train Loss 5.0968614 Test MSE 6.926842904603953 Test RE 1.257985772636999\n",
      "46 Train Loss 5.0414896 Test MSE 6.992141820413695 Test RE 1.2639013406053738\n",
      "47 Train Loss 4.99135 Test MSE 7.018636228796198 Test RE 1.2662936445487034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 4.9486685 Test MSE 7.020976263459455 Test RE 1.2665047200328945\n",
      "49 Train Loss 4.882171 Test MSE 7.044530632317989 Test RE 1.2686274120784686\n",
      "50 Train Loss 4.8340745 Test MSE 7.055890531941109 Test RE 1.2696498843736677\n",
      "51 Train Loss 4.7917237 Test MSE 7.07192961957323 Test RE 1.2710921166607052\n",
      "52 Train Loss 4.734305 Test MSE 7.034292610729575 Test RE 1.2677052103032218\n",
      "53 Train Loss 4.694423 Test MSE 7.0623517335604875 Test RE 1.2702310715886325\n",
      "54 Train Loss 4.608027 Test MSE 7.225190748084032 Test RE 1.2847916897351133\n",
      "55 Train Loss 4.549611 Test MSE 7.146133811157951 Test RE 1.2777433587509692\n",
      "56 Train Loss 4.493679 Test MSE 7.121929246788939 Test RE 1.2755776104651975\n",
      "57 Train Loss 4.4366393 Test MSE 7.132975054905362 Test RE 1.2765664104169598\n",
      "58 Train Loss 4.408045 Test MSE 7.155229001342189 Test RE 1.2785562195072435\n",
      "59 Train Loss 4.3704824 Test MSE 7.081221215732902 Test RE 1.271926867460996\n",
      "60 Train Loss 4.3528976 Test MSE 7.111994589751082 Test RE 1.2746876234935274\n",
      "61 Train Loss 4.3259735 Test MSE 7.1537472090272844 Test RE 1.278423823124337\n",
      "62 Train Loss 4.2848396 Test MSE 7.183081206692658 Test RE 1.281042235222904\n",
      "63 Train Loss 4.275899 Test MSE 7.2143409638031875 Test RE 1.2838266667843077\n",
      "64 Train Loss 4.2295947 Test MSE 7.120599802182907 Test RE 1.2754585494031394\n",
      "65 Train Loss 4.205601 Test MSE 7.111848355885863 Test RE 1.2746745186286426\n",
      "66 Train Loss 4.1704297 Test MSE 7.139622500447758 Test RE 1.2771611082449195\n",
      "67 Train Loss 4.1459556 Test MSE 7.192566600100469 Test RE 1.281887776321604\n",
      "68 Train Loss 4.1210117 Test MSE 7.191014748333199 Test RE 1.2817494802699296\n",
      "69 Train Loss 4.0750456 Test MSE 7.220698515463892 Test RE 1.284392220659936\n",
      "70 Train Loss 4.0536447 Test MSE 7.242282424445357 Test RE 1.2863104228272304\n",
      "71 Train Loss 4.0309806 Test MSE 7.247648628921029 Test RE 1.2867868835745089\n",
      "72 Train Loss 4.007522 Test MSE 7.210372213617772 Test RE 1.2834734891149409\n",
      "73 Train Loss 3.9874647 Test MSE 7.229225203070935 Test RE 1.2851503453769801\n",
      "74 Train Loss 3.9537392 Test MSE 7.177032303046391 Test RE 1.2805027360262762\n",
      "75 Train Loss 3.938728 Test MSE 7.181823899278716 Test RE 1.2809301152049535\n",
      "76 Train Loss 3.919623 Test MSE 7.194431594996835 Test RE 1.2820539589472673\n",
      "77 Train Loss 3.8832624 Test MSE 7.2092417710340975 Test RE 1.2833728736462546\n",
      "78 Train Loss 3.8671432 Test MSE 7.208132432602755 Test RE 1.283274128891364\n",
      "79 Train Loss 3.8506114 Test MSE 7.237123749979305 Test RE 1.2858522220550472\n",
      "80 Train Loss 3.827132 Test MSE 7.205272393850727 Test RE 1.2830195152372026\n",
      "81 Train Loss 3.811606 Test MSE 7.195437156069874 Test RE 1.2821435517450925\n",
      "82 Train Loss 3.7821856 Test MSE 7.226316017856 Test RE 1.2848917342194608\n",
      "83 Train Loss 3.7478626 Test MSE 7.227092820674731 Test RE 1.2849607929692195\n",
      "84 Train Loss 3.734525 Test MSE 7.234872181943249 Test RE 1.2856521834015617\n",
      "85 Train Loss 3.7192674 Test MSE 7.230154566954832 Test RE 1.2852329499368886\n",
      "86 Train Loss 3.6929703 Test MSE 7.248316359776733 Test RE 1.2868461584898279\n",
      "87 Train Loss 3.6670866 Test MSE 7.26234693430573 Test RE 1.2880910311692848\n",
      "88 Train Loss 3.6485574 Test MSE 7.291681153951144 Test RE 1.2906898512756866\n",
      "89 Train Loss 3.5962102 Test MSE 7.256797605025445 Test RE 1.287598806867831\n",
      "90 Train Loss 3.5775738 Test MSE 7.247580519108039 Test RE 1.2867808372673273\n",
      "91 Train Loss 3.5672028 Test MSE 7.274040245424797 Test RE 1.2891276100625253\n",
      "92 Train Loss 3.540698 Test MSE 7.227590674254022 Test RE 1.2850050508284394\n",
      "93 Train Loss 3.5163827 Test MSE 7.25977379411234 Test RE 1.287862817585314\n",
      "94 Train Loss 3.4958668 Test MSE 7.267465413660616 Test RE 1.2885448724774586\n",
      "95 Train Loss 3.4856076 Test MSE 7.2203576017892 Test RE 1.2843619000448896\n",
      "96 Train Loss 3.46901 Test MSE 7.246351713315447 Test RE 1.2866717477049385\n",
      "97 Train Loss 3.4342766 Test MSE 7.208380963889659 Test RE 1.283296251890947\n",
      "98 Train Loss 3.3952868 Test MSE 7.273372187075022 Test RE 1.2890684110335524\n",
      "99 Train Loss 3.377093 Test MSE 7.279644209677826 Test RE 1.2896240902812088\n",
      "Training time: 69.55\n",
      "7\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 38.01916 Test MSE 7.576451652744073 Test RE 1.315651873175598\n",
      "1 Train Loss 29.121542 Test MSE 6.025511747439367 Test RE 1.17328908105194\n",
      "2 Train Loss 25.322783 Test MSE 6.106257385548747 Test RE 1.1811243240456135\n",
      "3 Train Loss 21.227512 Test MSE 5.355734406633381 Test RE 1.1061590485523098\n",
      "4 Train Loss 17.611671 Test MSE 5.476898113704236 Test RE 1.1186014841462508\n",
      "5 Train Loss 14.58862 Test MSE 5.574639369973522 Test RE 1.1285386805843187\n",
      "6 Train Loss 12.295901 Test MSE 5.169867865394921 Test RE 1.0867953759122568\n",
      "7 Train Loss 10.71608 Test MSE 5.0545089697568155 Test RE 1.0746017563951158\n",
      "8 Train Loss 9.797874 Test MSE 4.895788881064453 Test RE 1.057595029653517\n",
      "9 Train Loss 8.968521 Test MSE 4.359797184994128 Test RE 0.9980245020736728\n",
      "10 Train Loss 8.544873 Test MSE 4.04718000226541 Test RE 0.9615775616092708\n",
      "11 Train Loss 8.134208 Test MSE 3.946745583552881 Test RE 0.9495714009124921\n",
      "12 Train Loss 7.8212028 Test MSE 3.9617412498609137 Test RE 0.9513736396796261\n",
      "13 Train Loss 7.3669186 Test MSE 3.7358976094443723 Test RE 0.9238586783271249\n",
      "14 Train Loss 6.249523 Test MSE 2.93949914921502 Test RE 0.8194920215330852\n",
      "15 Train Loss 5.225283 Test MSE 2.7541869402141903 Test RE 0.7932402953985727\n",
      "16 Train Loss 4.0258656 Test MSE 2.5177252805603403 Test RE 0.7584242846772762\n",
      "17 Train Loss 3.1581624 Test MSE 1.8100883347999428 Test RE 0.6430695489258202\n",
      "18 Train Loss 2.5342207 Test MSE 1.576532823179244 Test RE 0.6001496661441252\n",
      "19 Train Loss 1.8627357 Test MSE 1.178669032238761 Test RE 0.518924286552725\n",
      "20 Train Loss 1.3923094 Test MSE 0.8879755466237754 Test RE 0.4504105592316726\n",
      "21 Train Loss 0.8347206 Test MSE 0.4667975534133038 Test RE 0.3265670370195504\n",
      "22 Train Loss 0.546334 Test MSE 0.2969293663151836 Test RE 0.2604561616160704\n",
      "23 Train Loss 0.365887 Test MSE 0.20587200679831613 Test RE 0.2168736103103038\n",
      "24 Train Loss 0.2627259 Test MSE 0.18573260672418748 Test RE 0.20599284572934834\n",
      "25 Train Loss 0.1742769 Test MSE 0.1056392935444339 Test RE 0.1553534149921671\n",
      "26 Train Loss 0.13328335 Test MSE 0.07179276385314554 Test RE 0.12807029113059445\n",
      "27 Train Loss 0.10124246 Test MSE 0.03556768267421303 Test RE 0.09014379665534261\n",
      "28 Train Loss 0.08705119 Test MSE 0.03070210047731038 Test RE 0.08375140561371253\n",
      "29 Train Loss 0.06853359 Test MSE 0.027534206577893863 Test RE 0.07931299382595124\n",
      "30 Train Loss 0.055814296 Test MSE 0.02430732809364467 Test RE 0.07452065642614696\n",
      "31 Train Loss 0.044248898 Test MSE 0.02095232684040478 Test RE 0.069186950720718\n",
      "32 Train Loss 0.03972289 Test MSE 0.0175288448739616 Test RE 0.06328265756005289\n",
      "33 Train Loss 0.034600727 Test MSE 0.012862772370839956 Test RE 0.05420949385121673\n",
      "34 Train Loss 0.031406265 Test MSE 0.012060798873057882 Test RE 0.052492359909966806\n",
      "35 Train Loss 0.028140195 Test MSE 0.010835546419277257 Test RE 0.04975462631251208\n",
      "36 Train Loss 0.024830228 Test MSE 0.00965374455512029 Test RE 0.046963014040207904\n",
      "37 Train Loss 0.022344463 Test MSE 0.008994065239673056 Test RE 0.04533003736143959\n",
      "38 Train Loss 0.019704672 Test MSE 0.006115022627434029 Test RE 0.03737722840767975\n",
      "39 Train Loss 0.01711126 Test MSE 0.006132353976011535 Test RE 0.037430158663380904\n",
      "40 Train Loss 0.014907539 Test MSE 0.005360618803922542 Test RE 0.03499576753526302\n",
      "41 Train Loss 0.012404468 Test MSE 0.004989249501481273 Test RE 0.03376180612063887\n",
      "42 Train Loss 0.01125016 Test MSE 0.004356497293303807 Test RE 0.03154835975385143\n",
      "43 Train Loss 0.009902835 Test MSE 0.004312094439221153 Test RE 0.031387172350781575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 0.009054966 Test MSE 0.0043054095257767985 Test RE 0.03136283360818979\n",
      "45 Train Loss 0.007845781 Test MSE 0.0037996381781610165 Test RE 0.029463150328746603\n",
      "46 Train Loss 0.0076562297 Test MSE 0.0037535559592986856 Test RE 0.0292839399565912\n",
      "47 Train Loss 0.0067559807 Test MSE 0.0032427801659913914 Test RE 0.027218664614909186\n",
      "48 Train Loss 0.0064962488 Test MSE 0.0033977412097556925 Test RE 0.02786141755819675\n",
      "49 Train Loss 0.005324119 Test MSE 0.0028907516209617746 Test RE 0.025698835781413687\n",
      "50 Train Loss 0.005148257 Test MSE 0.0027930957561083823 Test RE 0.025261025237890405\n",
      "51 Train Loss 0.004724762 Test MSE 0.00226530648970492 Test RE 0.0227494837042097\n",
      "52 Train Loss 0.0044004563 Test MSE 0.0021384976909444887 Test RE 0.022103571518130305\n",
      "53 Train Loss 0.0042887894 Test MSE 0.0021035707772719503 Test RE 0.02192232564927266\n",
      "54 Train Loss 0.0038343184 Test MSE 0.001912981946965808 Test RE 0.02090564137610635\n",
      "55 Train Loss 0.0036519037 Test MSE 0.001678762934232526 Test RE 0.019584060682691258\n",
      "56 Train Loss 0.0035782005 Test MSE 0.0014809370737955416 Test RE 0.01839400765870513\n",
      "57 Train Loss 0.0033237417 Test MSE 0.0010780900056389933 Test RE 0.015694069454553154\n",
      "58 Train Loss 0.0030384855 Test MSE 0.0010005804969465415 Test RE 0.015119383292988993\n",
      "59 Train Loss 0.0028686938 Test MSE 0.001110864399584758 Test RE 0.01593083665840072\n",
      "60 Train Loss 0.0027730938 Test MSE 0.001009014066546556 Test RE 0.01518296778827744\n",
      "61 Train Loss 0.0024447974 Test MSE 0.0008453819717851582 Test RE 0.013897431794542867\n",
      "62 Train Loss 0.0023822968 Test MSE 0.0008009154201882697 Test RE 0.01352699682005557\n",
      "63 Train Loss 0.0022427943 Test MSE 0.0006672840966785507 Test RE 0.012347056842292882\n",
      "64 Train Loss 0.0019762404 Test MSE 0.0006457574908276938 Test RE 0.01214626596683634\n",
      "65 Train Loss 0.0018474888 Test MSE 0.0006421879345091637 Test RE 0.012112648964260982\n",
      "66 Train Loss 0.0018140371 Test MSE 0.0006510316106262792 Test RE 0.012195766431393036\n",
      "67 Train Loss 0.0017664724 Test MSE 0.0006834930702397133 Test RE 0.012496118016594584\n",
      "68 Train Loss 0.0016828481 Test MSE 0.0006384972217249005 Test RE 0.012077792560747059\n",
      "69 Train Loss 0.0016166233 Test MSE 0.0005417350454985427 Test RE 0.01112503858823863\n",
      "70 Train Loss 0.0015788146 Test MSE 0.00044760946966244225 Test RE 0.010112480408597656\n",
      "71 Train Loss 0.0015593282 Test MSE 0.0004276721662419776 Test RE 0.009884701375903058\n",
      "72 Train Loss 0.0014019844 Test MSE 0.00046590300562881495 Test RE 0.010317056677261873\n",
      "73 Train Loss 0.0013552753 Test MSE 0.00046672478895212776 Test RE 0.01032615154214034\n",
      "74 Train Loss 0.0013109591 Test MSE 0.000472456882525428 Test RE 0.010389368494032273\n",
      "75 Train Loss 0.0011451968 Test MSE 0.000403253654901112 Test RE 0.009598364016020764\n",
      "76 Train Loss 0.0010850758 Test MSE 0.0003355515756182246 Test RE 0.008755636065443063\n",
      "77 Train Loss 0.0010725344 Test MSE 0.0003215500278982195 Test RE 0.008571016597077078\n",
      "78 Train Loss 0.001007569 Test MSE 0.0002858937186854121 Test RE 0.008081842211749143\n",
      "79 Train Loss 0.000983246 Test MSE 0.0002313822984177629 Test RE 0.00727064810690222\n",
      "80 Train Loss 0.0009663741 Test MSE 0.00020187700761822234 Test RE 0.006791277702755409\n",
      "81 Train Loss 0.00092680147 Test MSE 0.00016277040461654731 Test RE 0.006098117410247901\n",
      "82 Train Loss 0.0009097251 Test MSE 0.00014904913867286388 Test RE 0.005835429084281236\n",
      "83 Train Loss 0.0008881638 Test MSE 0.00017726208669313642 Test RE 0.0063637921855625\n",
      "84 Train Loss 0.0008770528 Test MSE 0.00018366652776065313 Test RE 0.006477733371085998\n",
      "85 Train Loss 0.00083996245 Test MSE 0.00017834145033978003 Test RE 0.006383137612262473\n",
      "86 Train Loss 0.00080131035 Test MSE 0.00016494299508030554 Test RE 0.006138680050676966\n",
      "87 Train Loss 0.0007982733 Test MSE 0.00015762062553003727 Test RE 0.006000875044970224\n",
      "88 Train Loss 0.00078697776 Test MSE 0.00014404688445634084 Test RE 0.0057366716785308015\n",
      "89 Train Loss 0.0007567819 Test MSE 0.0001509932859799295 Test RE 0.005873363480554128\n",
      "90 Train Loss 0.00070633134 Test MSE 0.0001327387410497449 Test RE 0.005506896414612811\n",
      "91 Train Loss 0.0006807655 Test MSE 0.0001275725447747498 Test RE 0.0053986686095001575\n",
      "92 Train Loss 0.0006719806 Test MSE 0.0001355617261471016 Test RE 0.0055651465506103654\n",
      "93 Train Loss 0.0006685419 Test MSE 0.00013354757533255227 Test RE 0.00552364887844778\n",
      "94 Train Loss 0.000658855 Test MSE 0.0001327773597669106 Test RE 0.005507697438516165\n",
      "95 Train Loss 0.0006009866 Test MSE 0.00013626389337088266 Test RE 0.005579540792108686\n",
      "96 Train Loss 0.00053961517 Test MSE 0.00019150526935937477 Test RE 0.006614521378001429\n",
      "97 Train Loss 0.0005184553 Test MSE 0.00021889737602477074 Test RE 0.007071773430974141\n",
      "98 Train Loss 0.0005119308 Test MSE 0.00021268672795672917 Test RE 0.00697072990211338\n",
      "99 Train Loss 0.00050466513 Test MSE 0.00020198799402837102 Test RE 0.0067931442748173036\n",
      "Training time: 68.21\n",
      "8\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 46.03317 Test MSE 9.226018778151044 Test RE 1.4518281986431747\n",
      "1 Train Loss 30.845133 Test MSE 7.456541435202135 Test RE 1.3051991372546858\n",
      "2 Train Loss 27.518291 Test MSE 6.867459068721459 Test RE 1.252581808585246\n",
      "3 Train Loss 22.731812 Test MSE 7.158485899195585 Test RE 1.2788471712894829\n",
      "4 Train Loss 17.639004 Test MSE 7.247645285678336 Test RE 1.2867865867857455\n",
      "5 Train Loss 15.272831 Test MSE 7.086988588321127 Test RE 1.2724447289202088\n",
      "6 Train Loss 13.297138 Test MSE 6.8751953679405835 Test RE 1.2532871364237552\n",
      "7 Train Loss 11.643774 Test MSE 6.799603051408439 Test RE 1.246378188657477\n",
      "8 Train Loss 10.778737 Test MSE 6.789185288356349 Test RE 1.2454230262914334\n",
      "9 Train Loss 9.746191 Test MSE 6.730882742886275 Test RE 1.2400639227271644\n",
      "10 Train Loss 8.819103 Test MSE 6.3714462573439565 Test RE 1.2064992947704438\n",
      "11 Train Loss 8.115928 Test MSE 6.249486120149342 Test RE 1.1948962941290853\n",
      "12 Train Loss 6.4607053 Test MSE 5.6088619904529535 Test RE 1.1319974207270518\n",
      "13 Train Loss 4.772361 Test MSE 4.517710132829507 Test RE 1.015938085177097\n",
      "14 Train Loss 3.9892702 Test MSE 4.430940700894206 Test RE 1.0061344726182555\n",
      "15 Train Loss 3.35778 Test MSE 4.351681669493345 Test RE 0.997095186366152\n",
      "16 Train Loss 2.9497645 Test MSE 4.284283533756416 Test RE 0.98934363175519\n",
      "17 Train Loss 2.6378987 Test MSE 4.2313400236467285 Test RE 0.9832116667910511\n",
      "18 Train Loss 2.4112308 Test MSE 4.152248959280223 Test RE 0.973979357929116\n",
      "19 Train Loss 2.181394 Test MSE 3.855745239462206 Test RE 0.9385603987377862\n",
      "20 Train Loss 1.9976276 Test MSE 3.5678451422637805 Test RE 0.9028405534922305\n",
      "21 Train Loss 1.8095042 Test MSE 3.2572879928680263 Test RE 0.8626530049459651\n",
      "22 Train Loss 1.6717623 Test MSE 3.129511226786706 Test RE 0.845563674212883\n",
      "23 Train Loss 1.53802 Test MSE 3.0250593949600275 Test RE 0.8313329867257058\n",
      "24 Train Loss 1.4297867 Test MSE 2.9394100646285732 Test RE 0.8194796036589418\n",
      "25 Train Loss 1.2793621 Test MSE 2.786080799790871 Test RE 0.7978199904735139\n",
      "26 Train Loss 1.2186625 Test MSE 2.6713905518994716 Test RE 0.7812261159861346\n",
      "27 Train Loss 1.1214578 Test MSE 2.6119400282395366 Test RE 0.7724842986378806\n",
      "28 Train Loss 1.0395535 Test MSE 2.551892541819797 Test RE 0.7635531121050635\n",
      "29 Train Loss 0.9803139 Test MSE 2.5798121013343236 Test RE 0.7677186626184361\n",
      "30 Train Loss 0.9524036 Test MSE 2.577942830857668 Test RE 0.7674404768778972\n",
      "31 Train Loss 0.920246 Test MSE 2.584060966130202 Test RE 0.7683506060898586\n",
      "32 Train Loss 0.8905788 Test MSE 2.5919792453768213 Test RE 0.7695269252805408\n",
      "33 Train Loss 0.8632336 Test MSE 2.6126583006509714 Test RE 0.7725905062869057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 0.83888525 Test MSE 2.62527841562369 Test RE 0.7744542086913918\n",
      "35 Train Loss 0.81970227 Test MSE 2.598314449350932 Test RE 0.7704667736214031\n",
      "36 Train Loss 0.8012221 Test MSE 2.601966736589549 Test RE 0.7710080818157212\n",
      "37 Train Loss 0.7885063 Test MSE 2.580676466452672 Test RE 0.7678472637785373\n",
      "38 Train Loss 0.77563745 Test MSE 2.5973447992806555 Test RE 0.7703229971677288\n",
      "39 Train Loss 0.7587386 Test MSE 2.61614920054439 Test RE 0.7731064818751515\n",
      "40 Train Loss 0.7480186 Test MSE 2.6096614986367297 Test RE 0.7721472862345988\n",
      "41 Train Loss 0.73576593 Test MSE 2.6163335253558127 Test RE 0.7731337165979415\n",
      "42 Train Loss 0.7220628 Test MSE 2.6081555972797412 Test RE 0.7719244708541474\n",
      "43 Train Loss 0.7128431 Test MSE 2.596199403164218 Test RE 0.770153127101847\n",
      "44 Train Loss 0.7062586 Test MSE 2.609415493177222 Test RE 0.7721108912989266\n",
      "45 Train Loss 0.6988016 Test MSE 2.5998853270552553 Test RE 0.7706996411639224\n",
      "46 Train Loss 0.69305724 Test MSE 2.611996258688377 Test RE 0.7724926137034231\n",
      "47 Train Loss 0.6876801 Test MSE 2.6290142919021133 Test RE 0.775005052463517\n",
      "48 Train Loss 0.67979735 Test MSE 2.6346422541126224 Test RE 0.775834140264883\n",
      "49 Train Loss 0.6742688 Test MSE 2.646089788084961 Test RE 0.7775178149929018\n",
      "50 Train Loss 0.6658255 Test MSE 2.6474989971527845 Test RE 0.7777248259792167\n",
      "51 Train Loss 0.65832424 Test MSE 2.674873178995672 Test RE 0.7817351828991448\n",
      "52 Train Loss 0.65171325 Test MSE 2.695731998873614 Test RE 0.7847772725042192\n",
      "53 Train Loss 0.6422131 Test MSE 2.7199586969576606 Test RE 0.7882958040539483\n",
      "54 Train Loss 0.6361276 Test MSE 2.721623864495019 Test RE 0.7885370657584678\n",
      "55 Train Loss 0.62939155 Test MSE 2.753181284210824 Test RE 0.7930954614211184\n",
      "56 Train Loss 0.6253421 Test MSE 2.7569717215424876 Test RE 0.7936412200105856\n",
      "57 Train Loss 0.6199078 Test MSE 2.753608426641077 Test RE 0.7931569814500317\n",
      "58 Train Loss 0.61475635 Test MSE 2.7477263221933743 Test RE 0.7923093797473504\n",
      "59 Train Loss 0.6067874 Test MSE 2.7429598215294244 Test RE 0.7916218690634497\n",
      "60 Train Loss 0.6017331 Test MSE 2.734038809606429 Test RE 0.7903335126904548\n",
      "61 Train Loss 0.5954987 Test MSE 2.750690756028666 Test RE 0.7927366631267849\n",
      "62 Train Loss 0.59015733 Test MSE 2.7474114701385166 Test RE 0.7922639845089532\n",
      "63 Train Loss 0.5876847 Test MSE 2.759432073473866 Test RE 0.7939952681223001\n",
      "64 Train Loss 0.5830934 Test MSE 2.761862130344243 Test RE 0.7943448018316008\n",
      "65 Train Loss 0.5800225 Test MSE 2.7738169694882004 Test RE 0.7960621233010295\n",
      "66 Train Loss 0.57752395 Test MSE 2.767980917273163 Test RE 0.795224233411194\n",
      "67 Train Loss 0.5740732 Test MSE 2.7623186077887882 Test RE 0.7944104433239717\n",
      "68 Train Loss 0.5700488 Test MSE 2.7705396305731584 Test RE 0.7955916999637325\n",
      "69 Train Loss 0.5672102 Test MSE 2.7677283468309355 Test RE 0.7951879516006856\n",
      "70 Train Loss 0.5628656 Test MSE 2.796419838370208 Test RE 0.7992989592786696\n",
      "71 Train Loss 0.5578853 Test MSE 2.811630240041736 Test RE 0.8014698012173406\n",
      "72 Train Loss 0.5538313 Test MSE 2.8151850486560184 Test RE 0.8019762995016869\n",
      "73 Train Loss 0.5509421 Test MSE 2.825838898777259 Test RE 0.8034923751331672\n",
      "74 Train Loss 0.5486786 Test MSE 2.834027583854629 Test RE 0.8046557086806779\n",
      "75 Train Loss 0.54532915 Test MSE 2.83995631481485 Test RE 0.8054969310547644\n",
      "76 Train Loss 0.5401506 Test MSE 2.85539510038595 Test RE 0.8076834152057075\n",
      "77 Train Loss 0.5380883 Test MSE 2.858325882925217 Test RE 0.8080978127353944\n",
      "78 Train Loss 0.5348584 Test MSE 2.876425332687206 Test RE 0.8106522878976777\n",
      "79 Train Loss 0.53061205 Test MSE 2.8763546698596945 Test RE 0.8106423305151669\n",
      "80 Train Loss 0.52740395 Test MSE 2.8883591259537162 Test RE 0.8123321756673084\n",
      "81 Train Loss 0.5222712 Test MSE 2.885369750874315 Test RE 0.8119116957157062\n",
      "82 Train Loss 0.51802886 Test MSE 2.8966199688812333 Test RE 0.8134930003680894\n",
      "83 Train Loss 0.5131687 Test MSE 2.8989418794699886 Test RE 0.8138189802445432\n",
      "84 Train Loss 0.5105094 Test MSE 2.9093631296163407 Test RE 0.8152804450144228\n",
      "85 Train Loss 0.50520664 Test MSE 2.930226560599336 Test RE 0.818198465378179\n",
      "86 Train Loss 0.50148445 Test MSE 2.950901567318663 Test RE 0.8210799020038417\n",
      "87 Train Loss 0.4971691 Test MSE 2.947109521401568 Test RE 0.8205521694560705\n",
      "88 Train Loss 0.49309236 Test MSE 2.9408148004547465 Test RE 0.8196753937720094\n",
      "89 Train Loss 0.48746586 Test MSE 2.9386629414332184 Test RE 0.8193754516154655\n",
      "90 Train Loss 0.48486957 Test MSE 2.950006858708664 Test RE 0.820955417514279\n",
      "91 Train Loss 0.48097938 Test MSE 2.965882457001582 Test RE 0.8231614582856602\n",
      "92 Train Loss 0.4783978 Test MSE 2.970492369130539 Test RE 0.8238009355156282\n",
      "93 Train Loss 0.47622165 Test MSE 2.980703260226647 Test RE 0.8252156042430592\n",
      "94 Train Loss 0.47314754 Test MSE 2.985505995727777 Test RE 0.8258801616860887\n",
      "95 Train Loss 0.47056827 Test MSE 2.9833363576184393 Test RE 0.8255800137814372\n",
      "96 Train Loss 0.4685736 Test MSE 2.9939542105227286 Test RE 0.8270478505221183\n",
      "97 Train Loss 0.46594375 Test MSE 2.9945671725312426 Test RE 0.8271325082909546\n",
      "98 Train Loss 0.46499345 Test MSE 2.9922060916978386 Test RE 0.8268063656967319\n",
      "99 Train Loss 0.46292147 Test MSE 2.984693639130491 Test RE 0.8257677929881685\n",
      "Training time: 67.25\n",
      "9\n",
      "KG_rowdy_tune23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 52.332558 Test MSE 8.546983938392 Test RE 1.397379939091832\n",
      "1 Train Loss 45.31038 Test MSE 8.475720699871232 Test RE 1.3915421918577764\n",
      "2 Train Loss 43.873226 Test MSE 8.460621582530937 Test RE 1.3903021542554936\n",
      "3 Train Loss 41.955055 Test MSE 8.732287111879016 Test RE 1.4124466846599566\n",
      "4 Train Loss 40.508995 Test MSE 8.974158961239862 Test RE 1.431874448592364\n",
      "5 Train Loss 39.230484 Test MSE 8.97861288066596 Test RE 1.4322297276973894\n",
      "6 Train Loss 36.25956 Test MSE 9.173038833146821 Test RE 1.4476536721070277\n",
      "7 Train Loss 32.45437 Test MSE 8.633047560787311 Test RE 1.404397756564284\n",
      "8 Train Loss 29.749226 Test MSE 8.75511400244359 Test RE 1.4142916035425255\n",
      "9 Train Loss 28.63469 Test MSE 8.539887933892809 Test RE 1.3967997418330693\n",
      "10 Train Loss 27.442898 Test MSE 9.030441683342088 Test RE 1.4363575332529317\n",
      "11 Train Loss 26.187828 Test MSE 8.527715527746725 Test RE 1.395803916311025\n",
      "12 Train Loss 24.693583 Test MSE 9.093771060384597 Test RE 1.4413852333675161\n",
      "13 Train Loss 23.113232 Test MSE 9.054095740974384 Test RE 1.4382374780796596\n",
      "14 Train Loss 21.359537 Test MSE 9.055905326686577 Test RE 1.4383811966815205\n",
      "15 Train Loss 19.512978 Test MSE 9.065535028935058 Test RE 1.439145753172381\n",
      "16 Train Loss 17.128712 Test MSE 8.439716265239143 Test RE 1.3885834457914321\n",
      "17 Train Loss 15.077323 Test MSE 8.382038210597836 Test RE 1.383830436537423\n",
      "18 Train Loss 13.708717 Test MSE 8.509419877424381 Test RE 1.3943058098097605\n",
      "19 Train Loss 12.528978 Test MSE 8.349728040610142 Test RE 1.381160741750602\n",
      "20 Train Loss 9.789644 Test MSE 7.431673230225901 Test RE 1.3030208440269115\n",
      "21 Train Loss 8.64885 Test MSE 6.923068694487388 Test RE 1.2576430082914347\n",
      "22 Train Loss 7.854476 Test MSE 6.91203787945909 Test RE 1.2566406812559499\n",
      "23 Train Loss 7.0254855 Test MSE 6.1683457481544925 Test RE 1.1871139669165378\n",
      "24 Train Loss 6.4831657 Test MSE 6.109765455964736 Test RE 1.1814635557630364\n",
      "25 Train Loss 5.789518 Test MSE 5.875934107228626 Test RE 1.1586346671850452\n",
      "26 Train Loss 5.061898 Test MSE 5.3598560703583695 Test RE 1.1065846053897077\n",
      "27 Train Loss 3.9563894 Test MSE 4.924905802384863 Test RE 1.0607353061437463\n",
      "28 Train Loss 3.381634 Test MSE 4.779795427194374 Test RE 1.044991396774065\n",
      "29 Train Loss 3.0055509 Test MSE 4.687868520613509 Test RE 1.0348937677916492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 2.703785 Test MSE 4.783697675064803 Test RE 1.0454178777362035\n",
      "31 Train Loss 2.4675977 Test MSE 4.790965518325541 Test RE 1.0462117248927103\n",
      "32 Train Loss 2.2394698 Test MSE 4.913729808652286 Test RE 1.0595310694839999\n",
      "33 Train Loss 2.024692 Test MSE 4.886898346148205 Test RE 1.0566343205301783\n",
      "34 Train Loss 1.8661168 Test MSE 4.6976316544766785 Test RE 1.0359708619094141\n",
      "35 Train Loss 1.7064754 Test MSE 4.57387668753883 Test RE 1.0222339163557408\n",
      "36 Train Loss 1.5134066 Test MSE 4.543730582021972 Test RE 1.0188596106206698\n",
      "37 Train Loss 1.3740432 Test MSE 4.488169997411033 Test RE 1.0126111598951386\n",
      "38 Train Loss 1.2868124 Test MSE 4.489795816560614 Test RE 1.012794550179995\n",
      "39 Train Loss 1.2058308 Test MSE 4.394803244647222 Test RE 1.0020232036545424\n",
      "40 Train Loss 1.1187751 Test MSE 4.473178740316582 Test RE 1.0109185979299042\n",
      "41 Train Loss 1.0306503 Test MSE 4.331575062197723 Test RE 0.9947890189673325\n",
      "42 Train Loss 0.9687952 Test MSE 4.2357004094647985 Test RE 0.9837181349867098\n",
      "43 Train Loss 0.90408814 Test MSE 4.148206614274391 Test RE 0.9735051427103176\n",
      "44 Train Loss 0.8302254 Test MSE 4.204155520487371 Test RE 0.9800482258856585\n",
      "45 Train Loss 0.7740596 Test MSE 4.0632355459267835 Test RE 0.9634830080148221\n",
      "46 Train Loss 0.720071 Test MSE 4.056719643274226 Test RE 0.9627101657430193\n",
      "47 Train Loss 0.687654 Test MSE 3.959207840528978 Test RE 0.9510694042256947\n",
      "48 Train Loss 0.6609358 Test MSE 3.9110679573012983 Test RE 0.9452697092903022\n",
      "49 Train Loss 0.6289401 Test MSE 3.948052441976509 Test RE 0.9497286003883163\n",
      "50 Train Loss 0.60737944 Test MSE 3.985160211933818 Test RE 0.9541814144231886\n",
      "51 Train Loss 0.57678497 Test MSE 3.988087754569114 Test RE 0.9545318261752258\n",
      "52 Train Loss 0.5473731 Test MSE 3.936425925596451 Test RE 0.948329153872145\n",
      "53 Train Loss 0.5295093 Test MSE 3.909923497149776 Test RE 0.9451313963436657\n",
      "54 Train Loss 0.5102068 Test MSE 3.8790407154171844 Test RE 0.9413914060619628\n",
      "55 Train Loss 0.49515718 Test MSE 3.835571627828552 Test RE 0.9361018617872435\n",
      "56 Train Loss 0.47668937 Test MSE 3.8077490304350006 Test RE 0.9327005189147185\n",
      "57 Train Loss 0.46023762 Test MSE 3.807102668940351 Test RE 0.9326213530765016\n",
      "58 Train Loss 0.45044973 Test MSE 3.8017243907414278 Test RE 0.9319623650921879\n",
      "59 Train Loss 0.4362943 Test MSE 3.794094037323816 Test RE 0.9310266352425012\n",
      "60 Train Loss 0.4256591 Test MSE 3.805268659320745 Test RE 0.9323966884528883\n",
      "61 Train Loss 0.41147366 Test MSE 3.8547729791160945 Test RE 0.9384420581143759\n",
      "62 Train Loss 0.40074542 Test MSE 3.897654658241919 Test RE 0.9436473806609645\n",
      "63 Train Loss 0.39140254 Test MSE 3.8733471049392936 Test RE 0.9407002707250421\n",
      "64 Train Loss 0.3817856 Test MSE 3.908903179092795 Test RE 0.9450080694357282\n",
      "65 Train Loss 0.3754462 Test MSE 3.917999455312916 Test RE 0.9461069786373231\n",
      "66 Train Loss 0.366211 Test MSE 3.93502946474991 Test RE 0.948160927411226\n",
      "67 Train Loss 0.35999423 Test MSE 3.939673319243441 Test RE 0.9487202400062844\n",
      "68 Train Loss 0.35447162 Test MSE 3.95374176074594 Test RE 0.9504126545682975\n",
      "69 Train Loss 0.3490458 Test MSE 3.9524110236546783 Test RE 0.9502526977619148\n",
      "70 Train Loss 0.34196883 Test MSE 3.978063227708135 Test RE 0.9533314074380912\n",
      "71 Train Loss 0.33415344 Test MSE 4.001548087944238 Test RE 0.9561413060117369\n",
      "72 Train Loss 0.3294063 Test MSE 3.998799443203874 Test RE 0.9558128650964612\n",
      "73 Train Loss 0.3229735 Test MSE 4.004782181645351 Test RE 0.9565276097574511\n",
      "74 Train Loss 0.3185726 Test MSE 4.0100450822190945 Test RE 0.9571559157008106\n",
      "75 Train Loss 0.31488872 Test MSE 4.027218457229537 Test RE 0.9592032787431616\n",
      "76 Train Loss 0.31151432 Test MSE 4.037122538725543 Test RE 0.9603820320061147\n",
      "77 Train Loss 0.3076906 Test MSE 4.051105295969774 Test RE 0.9620437577742601\n",
      "78 Train Loss 0.3049697 Test MSE 4.044500268590517 Test RE 0.9612591672645561\n",
      "79 Train Loss 0.3019833 Test MSE 4.037577274371813 Test RE 0.9604361185049287\n",
      "80 Train Loss 0.2987207 Test MSE 4.059062791349661 Test RE 0.9629881547381584\n",
      "81 Train Loss 0.29579842 Test MSE 4.041933878144361 Test RE 0.9609541409758082\n",
      "82 Train Loss 0.29307714 Test MSE 4.025532036265284 Test RE 0.959002421759876\n",
      "83 Train Loss 0.28985286 Test MSE 4.024986914170246 Test RE 0.9589374873482531\n",
      "84 Train Loss 0.2870742 Test MSE 4.040596850222157 Test RE 0.9607951912222872\n",
      "85 Train Loss 0.284541 Test MSE 4.059502769688235 Test RE 0.9630403444269253\n",
      "86 Train Loss 0.28227454 Test MSE 4.063111362934031 Test RE 0.9634682846353558\n",
      "87 Train Loss 0.27932718 Test MSE 4.075727517620676 Test RE 0.9649629327979389\n",
      "88 Train Loss 0.27705902 Test MSE 4.091312301319757 Test RE 0.9668060871358121\n",
      "89 Train Loss 0.27500707 Test MSE 4.083448485397703 Test RE 0.9658765025257299\n",
      "90 Train Loss 0.27266175 Test MSE 4.120920687463611 Test RE 0.9702981163880849\n",
      "91 Train Loss 0.27064544 Test MSE 4.128058701659953 Test RE 0.9711380992034506\n",
      "92 Train Loss 0.26964462 Test MSE 4.133390772063146 Test RE 0.9717650895215956\n",
      "93 Train Loss 0.26796502 Test MSE 4.145726857378038 Test RE 0.9732141233375663\n",
      "94 Train Loss 0.26626176 Test MSE 4.167162164719905 Test RE 0.9757268609863902\n",
      "95 Train Loss 0.26437244 Test MSE 4.189251275426205 Test RE 0.9783094881474871\n",
      "96 Train Loss 0.26267827 Test MSE 4.208488849821017 Test RE 0.9805531760390298\n",
      "97 Train Loss 0.2613916 Test MSE 4.2153488804776895 Test RE 0.9813520240510875\n",
      "98 Train Loss 0.2599522 Test MSE 4.217979340139852 Test RE 0.981658167670561\n",
      "99 Train Loss 0.25859854 Test MSE 4.223353695749287 Test RE 0.9822833604684932\n",
      "Training time: 68.85\n",
      "0\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 46.574787 Test MSE 6.274546766286794 Test RE 1.1972896839758682\n",
      "1 Train Loss 27.560698 Test MSE 6.033030243871699 Test RE 1.1740208545575752\n",
      "2 Train Loss 21.363186 Test MSE 5.766831203894925 Test RE 1.1478276444323599\n",
      "3 Train Loss 18.065329 Test MSE 5.8213328179785355 Test RE 1.1532388783824716\n",
      "4 Train Loss 14.377611 Test MSE 5.264610939123045 Test RE 1.096708479123035\n",
      "5 Train Loss 12.396193 Test MSE 5.773662571609162 Test RE 1.1485072994833614\n",
      "6 Train Loss 11.130684 Test MSE 5.945665126942306 Test RE 1.165489278782071\n",
      "7 Train Loss 10.077491 Test MSE 5.534747090851051 Test RE 1.1244935031663248\n",
      "8 Train Loss 9.000049 Test MSE 5.534629631305239 Test RE 1.1244815709863387\n",
      "9 Train Loss 8.006218 Test MSE 5.528516526863872 Test RE 1.1238603936963234\n",
      "10 Train Loss 7.2035284 Test MSE 5.425783307026007 Test RE 1.1133694048525262\n",
      "11 Train Loss 6.5251837 Test MSE 4.980893893619275 Test RE 1.0667476759809056\n",
      "12 Train Loss 6.121277 Test MSE 4.862675388694009 Test RE 1.0540123503395835\n",
      "13 Train Loss 5.7717915 Test MSE 4.406453259463323 Test RE 1.0033504370358488\n",
      "14 Train Loss 5.5104327 Test MSE 4.31797160693663 Test RE 0.9932257066264799\n",
      "15 Train Loss 5.2787356 Test MSE 3.879601419751833 Test RE 0.941459441332479\n",
      "16 Train Loss 4.879348 Test MSE 3.4059791744083285 Test RE 0.8821228143140962\n",
      "17 Train Loss 4.6143866 Test MSE 3.1883837274876607 Test RE 0.8534800073061254\n",
      "18 Train Loss 4.377924 Test MSE 2.882763737020345 Test RE 0.8115449608990425\n",
      "19 Train Loss 4.0153027 Test MSE 2.685980127204795 Test RE 0.7833565116369333\n",
      "20 Train Loss 3.6482394 Test MSE 2.346875140420815 Test RE 0.7322393310796029\n",
      "21 Train Loss 3.2458606 Test MSE 2.0757645528366506 Test RE 0.6886477073455428\n",
      "22 Train Loss 2.8381643 Test MSE 1.952475212591353 Test RE 0.6678836698004116\n",
      "23 Train Loss 2.5141792 Test MSE 1.8932742625532306 Test RE 0.6576802886660819\n",
      "24 Train Loss 2.192394 Test MSE 1.6952853062419093 Test RE 0.62234249865431\n",
      "25 Train Loss 1.8723515 Test MSE 1.4332922492717255 Test RE 0.5722363428309903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 1.6726538 Test MSE 1.38576327843493 Test RE 0.5626684766898843\n",
      "27 Train Loss 1.4969854 Test MSE 1.2074301690498843 Test RE 0.5252173592752364\n",
      "28 Train Loss 1.2584865 Test MSE 0.949150744348585 Test RE 0.4656672083768588\n",
      "29 Train Loss 1.1090711 Test MSE 0.8827389566098621 Test RE 0.44908050962768237\n",
      "30 Train Loss 0.8783659 Test MSE 0.7072439151437544 Test RE 0.4019691005887198\n",
      "31 Train Loss 0.70186496 Test MSE 0.565443680660203 Test RE 0.3594204120016338\n",
      "32 Train Loss 0.5133885 Test MSE 0.34889198409017885 Test RE 0.28232774283141543\n",
      "33 Train Loss 0.4111143 Test MSE 0.24405858969593203 Test RE 0.2361321432250867\n",
      "34 Train Loss 0.34796938 Test MSE 0.2507696771299907 Test RE 0.2393566901056409\n",
      "35 Train Loss 0.2683092 Test MSE 0.17667903578156927 Test RE 0.2009095451823947\n",
      "36 Train Loss 0.20492901 Test MSE 0.11730040926426522 Test RE 0.16370344692414587\n",
      "37 Train Loss 0.17621629 Test MSE 0.06663153079568712 Test RE 0.1233809062067975\n",
      "38 Train Loss 0.11121374 Test MSE 0.015945011306032583 Test RE 0.0603560036375866\n",
      "39 Train Loss 0.07472269 Test MSE 0.009795977883644348 Test RE 0.047307713525651364\n",
      "40 Train Loss 0.062887095 Test MSE 0.00882371221222959 Test RE 0.0448986959888947\n",
      "41 Train Loss 0.051983796 Test MSE 0.007965598623812933 Test RE 0.0426596482175628\n",
      "42 Train Loss 0.038273122 Test MSE 0.007208264217893176 Test RE 0.04058106206054367\n",
      "43 Train Loss 0.033269014 Test MSE 0.007713692001661237 Test RE 0.041979688075671893\n",
      "44 Train Loss 0.028551482 Test MSE 0.006977752180297344 Test RE 0.03992692195220827\n",
      "45 Train Loss 0.024165973 Test MSE 0.0056464449902167806 Test RE 0.03591663250161938\n",
      "46 Train Loss 0.021246392 Test MSE 0.005084333303796881 Test RE 0.03408199958222735\n",
      "47 Train Loss 0.019498276 Test MSE 0.005185407810869719 Test RE 0.034419100709810885\n",
      "48 Train Loss 0.016715914 Test MSE 0.004046249286708231 Test RE 0.030404255833715418\n",
      "49 Train Loss 0.015087166 Test MSE 0.0033512297866507973 Test RE 0.02767006402404719\n",
      "50 Train Loss 0.012727033 Test MSE 0.0036610054229619915 Test RE 0.028920663101977145\n",
      "51 Train Loss 0.011639735 Test MSE 0.003612839358995921 Test RE 0.02872978566874811\n",
      "52 Train Loss 0.010457262 Test MSE 0.0028539746969002537 Test RE 0.025534838737958653\n",
      "53 Train Loss 0.010194683 Test MSE 0.002528243229886865 Test RE 0.02403352573390264\n",
      "54 Train Loss 0.009090591 Test MSE 0.0019441417500947115 Test RE 0.021075215478580104\n",
      "55 Train Loss 0.008762255 Test MSE 0.0017088464632297607 Test RE 0.019758755274301848\n",
      "56 Train Loss 0.0071052792 Test MSE 0.0014381427492747793 Test RE 0.01812629560788842\n",
      "57 Train Loss 0.0065950314 Test MSE 0.0015234490203427503 Test RE 0.018656149926419677\n",
      "58 Train Loss 0.0062512886 Test MSE 0.0016947796464293534 Test RE 0.019677262538480754\n",
      "59 Train Loss 0.005591661 Test MSE 0.001244772904342586 Test RE 0.016863709930939646\n",
      "60 Train Loss 0.005352985 Test MSE 0.0010979384133612718 Test RE 0.015837880078421688\n",
      "61 Train Loss 0.0046096165 Test MSE 0.0007737742093446655 Test RE 0.013295821787888925\n",
      "62 Train Loss 0.0041951933 Test MSE 0.0008289945028971991 Test RE 0.013762073901314762\n",
      "63 Train Loss 0.004113705 Test MSE 0.0007847820386732526 Test RE 0.013390061991915342\n",
      "64 Train Loss 0.003381604 Test MSE 0.0005316704827371802 Test RE 0.011021211461958473\n",
      "65 Train Loss 0.0032119192 Test MSE 0.0004984296659710595 Test RE 0.010671119954340223\n",
      "66 Train Loss 0.0031021792 Test MSE 0.00046554941966896565 Test RE 0.01031314099230065\n",
      "67 Train Loss 0.0027874792 Test MSE 0.00045318346957070444 Test RE 0.010175250044810836\n",
      "68 Train Loss 0.0025872753 Test MSE 0.00048081558273266605 Test RE 0.010480869835495775\n",
      "69 Train Loss 0.00249299 Test MSE 0.0004976314635025779 Test RE 0.010662571980830144\n",
      "70 Train Loss 0.0020886215 Test MSE 0.0005135052338025273 Test RE 0.01083129782059014\n",
      "71 Train Loss 0.002017554 Test MSE 0.0005060911701610304 Test RE 0.01075282159714806\n",
      "72 Train Loss 0.0019160542 Test MSE 0.0005416359756469677 Test RE 0.011124021295445142\n",
      "73 Train Loss 0.0017305752 Test MSE 0.0004967837143637832 Test RE 0.01065348590018864\n",
      "74 Train Loss 0.0016927965 Test MSE 0.0004839507649810806 Test RE 0.010514984833802631\n",
      "75 Train Loss 0.0015666394 Test MSE 0.0004927231170940585 Test RE 0.010609856976775004\n",
      "76 Train Loss 0.0015519857 Test MSE 0.0004840956385045435 Test RE 0.010516558577480597\n",
      "77 Train Loss 0.001405236 Test MSE 0.0005654252229593895 Test RE 0.011365685886005386\n",
      "78 Train Loss 0.0013060179 Test MSE 0.0005523093350116886 Test RE 0.011233090352126865\n",
      "79 Train Loss 0.0012936207 Test MSE 0.0005079749561644163 Test RE 0.010772815228379971\n",
      "80 Train Loss 0.0012385583 Test MSE 0.00046602671118959254 Test RE 0.010318426267669172\n",
      "81 Train Loss 0.0011203653 Test MSE 0.00035541991521161384 Test RE 0.00901112345616553\n",
      "82 Train Loss 0.0011061906 Test MSE 0.00034808113843657446 Test RE 0.0089176065195272\n",
      "83 Train Loss 0.0010855305 Test MSE 0.0003483236783479719 Test RE 0.008920712833859304\n",
      "84 Train Loss 0.0010519212 Test MSE 0.00031587510167489503 Test RE 0.008495046445163234\n",
      "85 Train Loss 0.0010289234 Test MSE 0.0003104063728577192 Test RE 0.008421188230184208\n",
      "86 Train Loss 0.0009900681 Test MSE 0.0003054231665096875 Test RE 0.00835331863952355\n",
      "87 Train Loss 0.0009732684 Test MSE 0.0003168592198977762 Test RE 0.008508269438258123\n",
      "88 Train Loss 0.0009598479 Test MSE 0.0002989134441695454 Test RE 0.008263818775758974\n",
      "89 Train Loss 0.00083027733 Test MSE 0.00026116890024730866 Test RE 0.007724471771648808\n",
      "90 Train Loss 0.00077213946 Test MSE 0.0002711071116342652 Test RE 0.007870068552512193\n",
      "91 Train Loss 0.0007594821 Test MSE 0.0002886337064847776 Test RE 0.008120477801318512\n",
      "92 Train Loss 0.0007501099 Test MSE 0.00028041248994192607 Test RE 0.008003993682284213\n",
      "93 Train Loss 0.0007231225 Test MSE 0.0002990525166894999 Test RE 0.008265740965071117\n",
      "94 Train Loss 0.0006617973 Test MSE 0.0002956784060379846 Test RE 0.008218978879677114\n",
      "95 Train Loss 0.00062002765 Test MSE 0.0003274080454965996 Test RE 0.008648737858075089\n",
      "96 Train Loss 0.0006085999 Test MSE 0.00033185120077015563 Test RE 0.008707224798647495\n",
      "97 Train Loss 0.00060397264 Test MSE 0.0003128273097328967 Test RE 0.008453963923618048\n",
      "98 Train Loss 0.0005817726 Test MSE 0.00029994137716217255 Test RE 0.008278015797671342\n",
      "99 Train Loss 0.0005303152 Test MSE 0.0003155122059899469 Test RE 0.008490165241135916\n",
      "Training time: 67.33\n",
      "1\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.902264 Test MSE 7.733637542507496 Test RE 1.3292294879373812\n",
      "1 Train Loss 42.79459 Test MSE 8.838015507073518 Test RE 1.4209717368752997\n",
      "2 Train Loss 37.065323 Test MSE 9.887571182967864 Test RE 1.502978859061243\n",
      "3 Train Loss 34.113583 Test MSE 9.530279113358949 Test RE 1.4755735788469442\n",
      "4 Train Loss 31.107853 Test MSE 8.614745635593621 Test RE 1.4029083161582965\n",
      "5 Train Loss 28.107895 Test MSE 8.996330531922098 Test RE 1.433642153030124\n",
      "6 Train Loss 26.041225 Test MSE 8.921539546279913 Test RE 1.4276704242727662\n",
      "7 Train Loss 24.40345 Test MSE 8.892616998986249 Test RE 1.4253543786334284\n",
      "8 Train Loss 23.043858 Test MSE 9.135092067384965 Test RE 1.4446562627570414\n",
      "9 Train Loss 21.74179 Test MSE 9.026171502338183 Test RE 1.4360178913992854\n",
      "10 Train Loss 20.805882 Test MSE 9.220680900424913 Test RE 1.4514081473272407\n",
      "11 Train Loss 19.899242 Test MSE 9.159723611088213 Test RE 1.4466026120085531\n",
      "12 Train Loss 18.79763 Test MSE 9.12710768799822 Test RE 1.4440247855300925\n",
      "13 Train Loss 17.688576 Test MSE 9.106401299963581 Test RE 1.4423858481780485\n",
      "14 Train Loss 16.479538 Test MSE 8.854810587259086 Test RE 1.42232124837169\n",
      "15 Train Loss 14.610189 Test MSE 8.292701592865955 Test RE 1.376436178638524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Train Loss 13.867027 Test MSE 8.489904413911917 Test RE 1.3927060448677187\n",
      "17 Train Loss 13.443937 Test MSE 8.540802669579424 Test RE 1.3968745477537026\n",
      "18 Train Loss 13.071049 Test MSE 8.672486310774824 Test RE 1.4076019887984115\n",
      "19 Train Loss 12.735629 Test MSE 8.70590938411743 Test RE 1.4103117736111672\n",
      "20 Train Loss 12.497471 Test MSE 8.767943178982902 Test RE 1.4153274298428975\n",
      "21 Train Loss 12.118138 Test MSE 8.507900008898156 Test RE 1.394181285683488\n",
      "22 Train Loss 11.720244 Test MSE 8.45997000929077 Test RE 1.390248617933584\n",
      "23 Train Loss 10.5427885 Test MSE 7.358545202393399 Test RE 1.2965941006774442\n",
      "24 Train Loss 9.33769 Test MSE 6.720607479883116 Test RE 1.2391170298694003\n",
      "25 Train Loss 8.680144 Test MSE 6.403265542503741 Test RE 1.2095081982905664\n",
      "26 Train Loss 8.282498 Test MSE 6.4086093335827705 Test RE 1.210012785454266\n",
      "27 Train Loss 8.023176 Test MSE 6.40923981329284 Test RE 1.210072304587677\n",
      "28 Train Loss 7.7953396 Test MSE 6.410518805784625 Test RE 1.2101930362371067\n",
      "29 Train Loss 7.635907 Test MSE 6.3805059006077 Test RE 1.2073567586796132\n",
      "30 Train Loss 7.473672 Test MSE 6.229551011162873 Test RE 1.192988984168415\n",
      "31 Train Loss 7.38879 Test MSE 6.250483101739001 Test RE 1.1949916013332316\n",
      "32 Train Loss 7.3107595 Test MSE 6.268054966951567 Test RE 1.1966701511134943\n",
      "33 Train Loss 7.231122 Test MSE 6.211012609963477 Test RE 1.1912125650790886\n",
      "34 Train Loss 7.1378126 Test MSE 6.20287613273776 Test RE 1.190432060285753\n",
      "35 Train Loss 7.050199 Test MSE 6.1153295593314505 Test RE 1.1820014069625895\n",
      "36 Train Loss 6.9574056 Test MSE 6.177091695725915 Test RE 1.1879552588362312\n",
      "37 Train Loss 6.8740635 Test MSE 6.1395289608895185 Test RE 1.184337788412454\n",
      "38 Train Loss 6.7710776 Test MSE 6.1006214316510095 Test RE 1.1805791211053016\n",
      "39 Train Loss 6.6564837 Test MSE 6.108840910202953 Test RE 1.1813741612963211\n",
      "40 Train Loss 6.508027 Test MSE 6.059884808604446 Test RE 1.1766308872467972\n",
      "41 Train Loss 6.3071632 Test MSE 6.115556244310799 Test RE 1.182023314161452\n",
      "42 Train Loss 5.479694 Test MSE 5.774828829937605 Test RE 1.1486232907239504\n",
      "43 Train Loss 4.0617933 Test MSE 5.410561949939884 Test RE 1.1118065986465318\n",
      "44 Train Loss 3.6301498 Test MSE 5.279347702207618 Test RE 1.0982423663227363\n",
      "45 Train Loss 3.1791198 Test MSE 5.170959925660397 Test RE 1.0869101548010227\n",
      "46 Train Loss 2.7603204 Test MSE 5.203338924523426 Test RE 1.0903077969106207\n",
      "47 Train Loss 2.501474 Test MSE 5.279671478384787 Test RE 1.0982760427618818\n",
      "48 Train Loss 2.3387287 Test MSE 5.253044396898831 Test RE 1.0955030624110424\n",
      "49 Train Loss 2.2310534 Test MSE 5.290314303079472 Test RE 1.0993824444368612\n",
      "50 Train Loss 2.1722465 Test MSE 5.283018391852656 Test RE 1.0986240996938395\n",
      "51 Train Loss 2.0731785 Test MSE 5.327580231433064 Test RE 1.1032477735002\n",
      "52 Train Loss 2.020229 Test MSE 5.334713200992126 Test RE 1.1039860824656063\n",
      "53 Train Loss 1.9721572 Test MSE 5.339463314051259 Test RE 1.1044774764432292\n",
      "54 Train Loss 1.9213169 Test MSE 5.34163153278912 Test RE 1.1047017036320879\n",
      "55 Train Loss 1.87689 Test MSE 5.41400236842948 Test RE 1.1121600251614934\n",
      "56 Train Loss 1.8220434 Test MSE 5.42646626914994 Test RE 1.1134394744778442\n",
      "57 Train Loss 1.7800906 Test MSE 5.400847734247981 Test RE 1.1108080719373195\n",
      "58 Train Loss 1.7274553 Test MSE 5.369019309056818 Test RE 1.1075301129406923\n",
      "59 Train Loss 1.6751037 Test MSE 5.382804460511227 Test RE 1.1089510133029297\n",
      "60 Train Loss 1.6322695 Test MSE 5.403604910635982 Test RE 1.1110915740054665\n",
      "61 Train Loss 1.5952435 Test MSE 5.439289623937701 Test RE 1.1147542900050817\n",
      "62 Train Loss 1.5521418 Test MSE 5.49977725953784 Test RE 1.1209354671792893\n",
      "63 Train Loss 1.5107628 Test MSE 5.464070155525796 Test RE 1.117290725312763\n",
      "64 Train Loss 1.4692799 Test MSE 5.4847304694284365 Test RE 1.1194010384265676\n",
      "65 Train Loss 1.433171 Test MSE 5.504066857286385 Test RE 1.1213725235194076\n",
      "66 Train Loss 1.4009221 Test MSE 5.489567792639422 Test RE 1.1198945641565095\n",
      "67 Train Loss 1.3696965 Test MSE 5.469567728021799 Test RE 1.1178526546393868\n",
      "68 Train Loss 1.3305731 Test MSE 5.488315167411078 Test RE 1.1197667864998286\n",
      "69 Train Loss 1.2936565 Test MSE 5.521334892208196 Test RE 1.1231301998407848\n",
      "70 Train Loss 1.268875 Test MSE 5.544636383349656 Test RE 1.1254976576480353\n",
      "71 Train Loss 1.245092 Test MSE 5.576365894529336 Test RE 1.1287134272158412\n",
      "72 Train Loss 1.2288857 Test MSE 5.592987133701338 Test RE 1.1303943299073183\n",
      "73 Train Loss 1.2102867 Test MSE 5.590100390662301 Test RE 1.1301025735477572\n",
      "74 Train Loss 1.1960508 Test MSE 5.613086877662381 Test RE 1.1324236802029022\n",
      "75 Train Loss 1.1789733 Test MSE 5.6196365562512804 Test RE 1.1330841767268331\n",
      "76 Train Loss 1.1657643 Test MSE 5.62809245565624 Test RE 1.133936335419846\n",
      "77 Train Loss 1.1499226 Test MSE 5.631892677691403 Test RE 1.1343191012243776\n",
      "78 Train Loss 1.1385274 Test MSE 5.634222771277799 Test RE 1.134553728949898\n",
      "79 Train Loss 1.129266 Test MSE 5.644406603693414 Test RE 1.13557861643002\n",
      "80 Train Loss 1.1135842 Test MSE 5.640155859702849 Test RE 1.135150939664152\n",
      "81 Train Loss 1.0968575 Test MSE 5.616437898106339 Test RE 1.1327616589999387\n",
      "82 Train Loss 1.0845264 Test MSE 5.63593866860046 Test RE 1.1347264794414182\n",
      "83 Train Loss 1.0732534 Test MSE 5.674590665735425 Test RE 1.138610881448757\n",
      "84 Train Loss 1.063726 Test MSE 5.683241179741443 Test RE 1.1394784170184562\n",
      "85 Train Loss 1.0509286 Test MSE 5.686786147155371 Test RE 1.1398337410335408\n",
      "86 Train Loss 1.041574 Test MSE 5.695230671099272 Test RE 1.1406797182214443\n",
      "87 Train Loss 1.0330132 Test MSE 5.706236900726441 Test RE 1.1417813876662186\n",
      "88 Train Loss 1.0273832 Test MSE 5.718973012895588 Test RE 1.1430548846221698\n",
      "89 Train Loss 1.0195041 Test MSE 5.746945084773805 Test RE 1.1458468729829625\n",
      "90 Train Loss 1.0133309 Test MSE 5.775207052891603 Test RE 1.148660904702972\n",
      "91 Train Loss 1.001308 Test MSE 5.7897141012835105 Test RE 1.1501026909199834\n",
      "92 Train Loss 0.99653876 Test MSE 5.788155206562883 Test RE 1.1499478465111854\n",
      "93 Train Loss 0.9896486 Test MSE 5.798442728553776 Test RE 1.1509693172102926\n",
      "94 Train Loss 0.98443687 Test MSE 5.792562728132486 Test RE 1.1503855900804263\n",
      "95 Train Loss 0.97529006 Test MSE 5.795725249004162 Test RE 1.150699580810994\n",
      "96 Train Loss 0.96926564 Test MSE 5.784089153779669 Test RE 1.1495438689124193\n",
      "97 Train Loss 0.96399426 Test MSE 5.813104602930937 Test RE 1.152423562262117\n",
      "98 Train Loss 0.9589715 Test MSE 5.81185618340573 Test RE 1.1522998086547875\n",
      "99 Train Loss 0.95059323 Test MSE 5.8311151523871505 Test RE 1.1542074394756303\n",
      "Training time: 68.04\n",
      "2\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 52.91809 Test MSE 7.259303934549492 Test RE 1.2878211410490434\n",
      "1 Train Loss 36.94986 Test MSE 6.328009412222456 Test RE 1.2023796533253264\n",
      "2 Train Loss 25.49176 Test MSE 4.598434166351352 Test RE 1.0249744670957124\n",
      "3 Train Loss 18.685915 Test MSE 4.241353524019938 Test RE 0.9843743684907986\n",
      "4 Train Loss 12.875694 Test MSE 3.7283391286310494 Test RE 0.9229236281205269\n",
      "5 Train Loss 9.88218 Test MSE 3.9584307195647654 Test RE 0.9509760607749879\n",
      "6 Train Loss 8.662007 Test MSE 3.8434140329675373 Test RE 0.9370583738799694\n",
      "7 Train Loss 7.9816604 Test MSE 3.805912590936025 Test RE 0.932475575696012\n",
      "8 Train Loss 7.4026833 Test MSE 3.7682429658995695 Test RE 0.927849437605633\n",
      "9 Train Loss 6.957662 Test MSE 3.7533537532354515 Test RE 0.9260145478076072\n",
      "10 Train Loss 6.5933247 Test MSE 3.730447229982124 Test RE 0.9231845139375423\n",
      "11 Train Loss 6.126338 Test MSE 3.6024451517700737 Test RE 0.9072077443815134\n",
      "12 Train Loss 5.7044945 Test MSE 3.622641065383656 Test RE 0.9097471698681997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train Loss 5.4096518 Test MSE 3.5683731676962998 Test RE 0.9029073592416158\n",
      "14 Train Loss 5.155835 Test MSE 3.4756177850898635 Test RE 0.891095120865186\n",
      "15 Train Loss 4.9680376 Test MSE 3.3664990310218275 Test RE 0.8769953833638563\n",
      "16 Train Loss 4.841728 Test MSE 3.3025459390539766 Test RE 0.8686253386475556\n",
      "17 Train Loss 4.6700487 Test MSE 3.153468416245955 Test RE 0.8487940042286896\n",
      "18 Train Loss 4.5707393 Test MSE 3.088698032955974 Test RE 0.840031914382345\n",
      "19 Train Loss 4.4669266 Test MSE 3.052830714947963 Test RE 0.8351402621593011\n",
      "20 Train Loss 4.3960314 Test MSE 3.0102412989938343 Test RE 0.8292943664633522\n",
      "21 Train Loss 4.339911 Test MSE 2.9725302001375895 Test RE 0.8240834609459724\n",
      "22 Train Loss 4.2849536 Test MSE 2.9415960867687683 Test RE 0.8197842681286666\n",
      "23 Train Loss 4.220813 Test MSE 2.900499080246531 Test RE 0.81403752712524\n",
      "24 Train Loss 4.190434 Test MSE 2.8712847460758506 Test RE 0.8099275877333444\n",
      "25 Train Loss 4.1564336 Test MSE 2.877168425773654 Test RE 0.8107569927206398\n",
      "26 Train Loss 4.131394 Test MSE 2.8236524436874215 Test RE 0.8031814692371022\n",
      "27 Train Loss 4.0708213 Test MSE 2.7443741726848097 Test RE 0.7918259345777896\n",
      "28 Train Loss 4.030448 Test MSE 2.7259344415183615 Test RE 0.7891612712174693\n",
      "29 Train Loss 3.9883077 Test MSE 2.642659099762505 Test RE 0.7770136207574001\n",
      "30 Train Loss 3.9501367 Test MSE 2.6260788449747987 Test RE 0.7745722625771704\n",
      "31 Train Loss 3.8805966 Test MSE 2.609829213033508 Test RE 0.7721720975244599\n",
      "32 Train Loss 3.7871728 Test MSE 2.577493812065161 Test RE 0.7673736386612803\n",
      "33 Train Loss 3.6839352 Test MSE 2.5229843465498263 Test RE 0.7592159760304535\n",
      "34 Train Loss 3.5901341 Test MSE 2.430388654115715 Test RE 0.7451538073669006\n",
      "35 Train Loss 3.3325343 Test MSE 2.2831088590554693 Test RE 0.7222230914431829\n",
      "36 Train Loss 2.971789 Test MSE 2.321047713273485 Test RE 0.7281990271618798\n",
      "37 Train Loss 2.6115947 Test MSE 2.479667250192315 Test RE 0.7526702723545969\n",
      "38 Train Loss 2.279525 Test MSE 2.2861740047940184 Test RE 0.7227077324894575\n",
      "39 Train Loss 2.0038922 Test MSE 2.0947941191845296 Test RE 0.6917970938821885\n",
      "40 Train Loss 1.8222178 Test MSE 1.9347978309879938 Test RE 0.6648533420779587\n",
      "41 Train Loss 1.6055888 Test MSE 1.7640679371650803 Test RE 0.6348420911641277\n",
      "42 Train Loss 1.3834697 Test MSE 1.3988814716197224 Test RE 0.5653254267432964\n",
      "43 Train Loss 1.1254297 Test MSE 1.0105549929280906 Test RE 0.4804940745967345\n",
      "44 Train Loss 0.92897135 Test MSE 0.870037959002368 Test RE 0.44583808100305083\n",
      "45 Train Loss 0.7444764 Test MSE 0.597073997108029 Test RE 0.36933642337402783\n",
      "46 Train Loss 0.5515125 Test MSE 0.49932736068980477 Test RE 0.3377541875747209\n",
      "47 Train Loss 0.4413679 Test MSE 0.3016856690917216 Test RE 0.2625339062647539\n",
      "48 Train Loss 0.30026546 Test MSE 0.18097855297603316 Test RE 0.20333943664936913\n",
      "49 Train Loss 0.22744045 Test MSE 0.1682926442995904 Test RE 0.19608330909669033\n",
      "50 Train Loss 0.17827153 Test MSE 0.16124381705662538 Test RE 0.19193297522447444\n",
      "51 Train Loss 0.14590918 Test MSE 0.14053194832063032 Test RE 0.17918250092968702\n",
      "52 Train Loss 0.12080272 Test MSE 0.14086903608804038 Test RE 0.1793972707861279\n",
      "53 Train Loss 0.10556819 Test MSE 0.10883403380962817 Test RE 0.1576850148463508\n",
      "54 Train Loss 0.088826336 Test MSE 0.10445482675016862 Test RE 0.15448001993688504\n",
      "55 Train Loss 0.07364549 Test MSE 0.08243330766973074 Test RE 0.13723327368024318\n",
      "56 Train Loss 0.06694691 Test MSE 0.07464449365705657 Test RE 0.13058910591765363\n",
      "57 Train Loss 0.05969641 Test MSE 0.06847270936435654 Test RE 0.12507393586706117\n",
      "58 Train Loss 0.053674135 Test MSE 0.05826277908654924 Test RE 0.11537285995857237\n",
      "59 Train Loss 0.04605018 Test MSE 0.056219236265637344 Test RE 0.11333147236264857\n",
      "60 Train Loss 0.041881185 Test MSE 0.050873424687083536 Test RE 0.10780863503237263\n",
      "61 Train Loss 0.037390865 Test MSE 0.04141514116488554 Test RE 0.0972719524785218\n",
      "62 Train Loss 0.033818174 Test MSE 0.03547393359332472 Test RE 0.09002491803427569\n",
      "63 Train Loss 0.030368669 Test MSE 0.027831347430552083 Test RE 0.07973980636163362\n",
      "64 Train Loss 0.027044237 Test MSE 0.019663208217096106 Test RE 0.06702475718481143\n",
      "65 Train Loss 0.024806444 Test MSE 0.019963937265594575 Test RE 0.06753535055870778\n",
      "66 Train Loss 0.023038492 Test MSE 0.022333293779148077 Test RE 0.0714306249301924\n",
      "67 Train Loss 0.021104936 Test MSE 0.020865529352519806 Test RE 0.06904349443907457\n",
      "68 Train Loss 0.018785821 Test MSE 0.01745027392500282 Test RE 0.06314066980175609\n",
      "69 Train Loss 0.017753288 Test MSE 0.01557149666268439 Test RE 0.059644889562722916\n",
      "70 Train Loss 0.016471809 Test MSE 0.016033511583336126 Test RE 0.06052327011465527\n",
      "71 Train Loss 0.015565886 Test MSE 0.013778860496214202 Test RE 0.05610669820242862\n",
      "72 Train Loss 0.014667048 Test MSE 0.012716930864365608 Test RE 0.05390129698528802\n",
      "73 Train Loss 0.014164509 Test MSE 0.012574214148146075 Test RE 0.05359798792069022\n",
      "74 Train Loss 0.013384547 Test MSE 0.01209172700242149 Test RE 0.052559621251740164\n",
      "75 Train Loss 0.012928224 Test MSE 0.011021982119302767 Test RE 0.05018083820428873\n",
      "76 Train Loss 0.0123682115 Test MSE 0.010486840548192601 Test RE 0.048947486197812334\n",
      "77 Train Loss 0.012052957 Test MSE 0.010343338024299565 Test RE 0.048611432497462734\n",
      "78 Train Loss 0.011429565 Test MSE 0.009368853675416403 Test RE 0.046264863837871276\n",
      "79 Train Loss 0.010157243 Test MSE 0.009348226935942922 Test RE 0.046213906743483094\n",
      "80 Train Loss 0.009878269 Test MSE 0.009846139101677162 Test RE 0.04742868064633361\n",
      "81 Train Loss 0.009069578 Test MSE 0.009617218093155983 Test RE 0.046874083862499964\n",
      "82 Train Loss 0.008307986 Test MSE 0.008699917607726598 Test RE 0.044582624404623045\n",
      "83 Train Loss 0.008067785 Test MSE 0.008202242293512742 Test RE 0.04328868142236026\n",
      "84 Train Loss 0.007699324 Test MSE 0.007055165356886172 Test RE 0.0401477913854291\n",
      "85 Train Loss 0.0072562187 Test MSE 0.00628969713726947 Test RE 0.03790730653205819\n",
      "86 Train Loss 0.0069967457 Test MSE 0.005987460774429706 Test RE 0.03698532172849097\n",
      "87 Train Loss 0.006731383 Test MSE 0.006157752984071833 Test RE 0.037507592756948746\n",
      "88 Train Loss 0.006483058 Test MSE 0.0067608351900924814 Test RE 0.039301419341542417\n",
      "89 Train Loss 0.0062698834 Test MSE 0.006981821009794783 Test RE 0.03993856124218961\n",
      "90 Train Loss 0.006169743 Test MSE 0.0067727523744331225 Test RE 0.039336041990561725\n",
      "91 Train Loss 0.0057609207 Test MSE 0.006001398751811987 Test RE 0.03702834505193062\n",
      "92 Train Loss 0.005565739 Test MSE 0.005627492799439004 Test RE 0.03585630507246484\n",
      "93 Train Loss 0.0054572504 Test MSE 0.005732161441747231 Test RE 0.0361882237610634\n",
      "94 Train Loss 0.00532895 Test MSE 0.0051406556744725785 Test RE 0.034270253581799824\n",
      "95 Train Loss 0.0050551877 Test MSE 0.005418767052501461 Test RE 0.035185060412042043\n",
      "96 Train Loss 0.0049977046 Test MSE 0.005334593710774712 Test RE 0.03491071427468649\n",
      "97 Train Loss 0.004664674 Test MSE 0.004309596837223744 Test RE 0.03137808117476774\n",
      "98 Train Loss 0.004412839 Test MSE 0.004186161607056259 Test RE 0.03092545196591299\n",
      "99 Train Loss 0.004379189 Test MSE 0.00405130445054929 Test RE 0.030423242617295287\n",
      "Training time: 67.47\n",
      "3\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 47.61357 Test MSE 9.242404009466844 Test RE 1.4531168361805844\n",
      "1 Train Loss 35.652657 Test MSE 9.043787311013192 Test RE 1.4374185010597331\n",
      "2 Train Loss 28.013376 Test MSE 8.870274685120993 Test RE 1.4235626820602147\n",
      "3 Train Loss 25.172943 Test MSE 8.785960540917705 Test RE 1.4167808710417644\n",
      "4 Train Loss 22.689785 Test MSE 8.80759708198395 Test RE 1.4185242995531804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 20.972288 Test MSE 8.99396330577174 Test RE 1.433453521761854\n",
      "6 Train Loss 19.177765 Test MSE 8.812569464991157 Test RE 1.4189246613556725\n",
      "7 Train Loss 17.626503 Test MSE 8.634260872684068 Test RE 1.4044964420300938\n",
      "8 Train Loss 15.223655 Test MSE 8.415384637810124 Test RE 1.386580364129548\n",
      "9 Train Loss 11.232536 Test MSE 7.259346500758396 Test RE 1.2878249167267017\n",
      "10 Train Loss 8.783905 Test MSE 6.560022823742052 Test RE 1.2242235664694325\n",
      "11 Train Loss 7.603056 Test MSE 6.373270315708162 Test RE 1.2066719845769867\n",
      "12 Train Loss 6.9644165 Test MSE 6.472708589319184 Test RE 1.2160490358104985\n",
      "13 Train Loss 6.317665 Test MSE 6.3927290952692015 Test RE 1.2085126776448087\n",
      "14 Train Loss 5.846833 Test MSE 6.139548410820282 Test RE 1.1843396643926711\n",
      "15 Train Loss 5.3368883 Test MSE 6.1434910096660635 Test RE 1.1847198736927178\n",
      "16 Train Loss 4.880551 Test MSE 6.057566431356187 Test RE 1.176405789301812\n",
      "17 Train Loss 3.9769716 Test MSE 5.454461602823325 Test RE 1.116307916685285\n",
      "18 Train Loss 2.8732674 Test MSE 5.238384087964181 Test RE 1.0939733176364432\n",
      "19 Train Loss 2.5336797 Test MSE 5.240905474370465 Test RE 1.0942365665286065\n",
      "20 Train Loss 2.3221571 Test MSE 5.299714254354594 Test RE 1.1003587148820324\n",
      "21 Train Loss 2.1896994 Test MSE 5.354475038559321 Test RE 1.1060289876505836\n",
      "22 Train Loss 2.0739706 Test MSE 5.3572099853732436 Test RE 1.1063114190995966\n",
      "23 Train Loss 1.9761989 Test MSE 5.362249692086273 Test RE 1.1068316688616757\n",
      "24 Train Loss 1.9111171 Test MSE 5.304254341721467 Test RE 1.1008299341781451\n",
      "25 Train Loss 1.8453946 Test MSE 5.327912223410043 Test RE 1.103282147802191\n",
      "26 Train Loss 1.7788479 Test MSE 5.358329226710613 Test RE 1.1064269797000696\n",
      "27 Train Loss 1.697214 Test MSE 5.377878724672607 Test RE 1.108443503694807\n",
      "28 Train Loss 1.6310822 Test MSE 5.4314475808441545 Test RE 1.1139504070566786\n",
      "29 Train Loss 1.5714881 Test MSE 5.422953142224073 Test RE 1.1130789924149138\n",
      "30 Train Loss 1.5031978 Test MSE 5.484492570372289 Test RE 1.119376761268395\n",
      "31 Train Loss 1.4459515 Test MSE 5.568188299431863 Test RE 1.127885509177936\n",
      "32 Train Loss 1.3843242 Test MSE 5.596763713096095 Test RE 1.1307759062838671\n",
      "33 Train Loss 1.313202 Test MSE 5.614329829157424 Test RE 1.1325490541570604\n",
      "34 Train Loss 1.2600069 Test MSE 5.649572505712894 Test RE 1.1360981525522587\n",
      "35 Train Loss 1.2068206 Test MSE 5.657137098343028 Test RE 1.1368584972346534\n",
      "36 Train Loss 1.161227 Test MSE 5.7060759916225905 Test RE 1.1417652891131542\n",
      "37 Train Loss 1.1173279 Test MSE 5.766093367588439 Test RE 1.1477542127702527\n",
      "38 Train Loss 1.0874418 Test MSE 5.805224149766675 Test RE 1.1516421639853982\n",
      "39 Train Loss 1.066295 Test MSE 5.793116577820599 Test RE 1.1504405852096138\n",
      "40 Train Loss 1.0372655 Test MSE 5.811561009838652 Test RE 1.152270546681257\n",
      "41 Train Loss 1.0120935 Test MSE 5.850054134123254 Test RE 1.1560803053285758\n",
      "42 Train Loss 0.9926214 Test MSE 5.853198525656347 Test RE 1.156390958930889\n",
      "43 Train Loss 0.97562027 Test MSE 5.837288175237545 Test RE 1.1548182200921282\n",
      "44 Train Loss 0.95942885 Test MSE 5.841731698286912 Test RE 1.1552576780253163\n",
      "45 Train Loss 0.9459331 Test MSE 5.847286109586848 Test RE 1.1558067662121752\n",
      "46 Train Loss 0.93743813 Test MSE 5.852198571394424 Test RE 1.1562921764059264\n",
      "47 Train Loss 0.92314845 Test MSE 5.874766474462316 Test RE 1.1585195427646755\n",
      "48 Train Loss 0.9114603 Test MSE 5.899317238431502 Test RE 1.1609377568688586\n",
      "49 Train Loss 0.8988458 Test MSE 5.88795625699878 Test RE 1.1598193436725108\n",
      "50 Train Loss 0.8872591 Test MSE 5.936018563046876 Test RE 1.1645434190206017\n",
      "51 Train Loss 0.8718622 Test MSE 5.948881803539371 Test RE 1.1658045080356894\n",
      "52 Train Loss 0.86003363 Test MSE 5.97501276618837 Test RE 1.168362149526939\n",
      "53 Train Loss 0.84981775 Test MSE 5.997171338957573 Test RE 1.1705266034210802\n",
      "54 Train Loss 0.84030014 Test MSE 6.002168587623875 Test RE 1.1710141828275362\n",
      "55 Train Loss 0.8332696 Test MSE 6.025562209481067 Test RE 1.1732939940320368\n",
      "56 Train Loss 0.8255825 Test MSE 6.055732106751277 Test RE 1.1762276589010978\n",
      "57 Train Loss 0.8183453 Test MSE 6.0611870680063324 Test RE 1.176757308488426\n",
      "58 Train Loss 0.813081 Test MSE 6.044356388892607 Test RE 1.175122365316572\n",
      "59 Train Loss 0.808143 Test MSE 6.034229960469989 Test RE 1.1741375805007144\n",
      "60 Train Loss 0.80250025 Test MSE 6.047999179526643 Test RE 1.1754764212070778\n",
      "61 Train Loss 0.79729116 Test MSE 6.046769316850655 Test RE 1.1753568983668699\n",
      "62 Train Loss 0.78811413 Test MSE 6.076227827092575 Test RE 1.1782164580264853\n",
      "63 Train Loss 0.7816953 Test MSE 6.097705062665159 Test RE 1.1802969026503063\n",
      "64 Train Loss 0.777411 Test MSE 6.092127965941362 Test RE 1.1797570162697013\n",
      "65 Train Loss 0.77393067 Test MSE 6.0859520374526435 Test RE 1.1791588720314596\n",
      "66 Train Loss 0.7706874 Test MSE 6.09317691984668 Test RE 1.1798585782749496\n",
      "67 Train Loss 0.7650927 Test MSE 6.125484965279561 Test RE 1.1829824436063405\n",
      "68 Train Loss 0.76114535 Test MSE 6.140918401298536 Test RE 1.1844717949217372\n",
      "69 Train Loss 0.75829947 Test MSE 6.144938897421368 Test RE 1.1848594718739953\n",
      "70 Train Loss 0.7537318 Test MSE 6.149319233405571 Test RE 1.185281702109079\n",
      "71 Train Loss 0.75002754 Test MSE 6.135646362280704 Test RE 1.1839632453901754\n",
      "72 Train Loss 0.7461121 Test MSE 6.144806885252631 Test RE 1.1848467445945852\n",
      "73 Train Loss 0.7422842 Test MSE 6.164094442671958 Test RE 1.1867048090807568\n",
      "74 Train Loss 0.73827755 Test MSE 6.170131122433406 Test RE 1.1872857544174173\n",
      "75 Train Loss 0.7349441 Test MSE 6.1905162682690325 Test RE 1.1892454401197001\n",
      "76 Train Loss 0.73117894 Test MSE 6.204641950744266 Test RE 1.1906014927183717\n",
      "77 Train Loss 0.72792447 Test MSE 6.205528205850647 Test RE 1.1906865209104875\n",
      "78 Train Loss 0.72532773 Test MSE 6.201761090929062 Test RE 1.1903250582154397\n",
      "79 Train Loss 0.7224488 Test MSE 6.208503333072319 Test RE 1.1909719131668017\n",
      "80 Train Loss 0.71906036 Test MSE 6.210003439530785 Test RE 1.1911157865495454\n",
      "81 Train Loss 0.7165487 Test MSE 6.214997173476826 Test RE 1.1915946043224208\n",
      "82 Train Loss 0.7138246 Test MSE 6.225256246665798 Test RE 1.1925776792359553\n",
      "83 Train Loss 0.7114197 Test MSE 6.229468163752557 Test RE 1.1929810513032448\n",
      "84 Train Loss 0.70867187 Test MSE 6.236557362614931 Test RE 1.193659670644392\n",
      "85 Train Loss 0.70406264 Test MSE 6.250071069500808 Test RE 1.1949522137234485\n",
      "86 Train Loss 0.7010345 Test MSE 6.254507347452048 Test RE 1.1953762248867408\n",
      "87 Train Loss 0.6985979 Test MSE 6.25776523914509 Test RE 1.1956875123353294\n",
      "88 Train Loss 0.6961764 Test MSE 6.275933536771848 Test RE 1.1974219863019344\n",
      "89 Train Loss 0.69420326 Test MSE 6.277877089792174 Test RE 1.1976073828612173\n",
      "90 Train Loss 0.692364 Test MSE 6.278433832901873 Test RE 1.1976604855953923\n",
      "91 Train Loss 0.6899483 Test MSE 6.2839569165264875 Test RE 1.198187155549275\n",
      "92 Train Loss 0.68802077 Test MSE 6.294005172020183 Test RE 1.1991447433960842\n",
      "93 Train Loss 0.68572354 Test MSE 6.2988264582567135 Test RE 1.1996039353694694\n",
      "94 Train Loss 0.68395394 Test MSE 6.303157884543299 Test RE 1.200016321954178\n",
      "95 Train Loss 0.6810576 Test MSE 6.3038682880824455 Test RE 1.2000839445521498\n",
      "96 Train Loss 0.67876196 Test MSE 6.304250986901294 Test RE 1.2001203716883866\n",
      "97 Train Loss 0.67640984 Test MSE 6.299983464565603 Test RE 1.1997141055416214\n",
      "98 Train Loss 0.673864 Test MSE 6.30203506969372 Test RE 1.1999094345668755\n",
      "99 Train Loss 0.6718103 Test MSE 6.295801813944142 Test RE 1.1993158808462936\n",
      "Training time: 67.95\n",
      "4\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.242355 Test MSE 8.574429669777684 Test RE 1.3996217459894926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 56.329613 Test MSE 8.305882031136418 Test RE 1.3775295996943357\n",
      "2 Train Loss 51.46217 Test MSE 8.062765285142621 Test RE 1.3572194316061026\n",
      "3 Train Loss 46.476913 Test MSE 7.979315157144656 Test RE 1.3501775098743003\n",
      "4 Train Loss 44.49755 Test MSE 8.086707705189847 Test RE 1.3592330726293014\n",
      "5 Train Loss 44.343307 Test MSE 8.143973681952561 Test RE 1.3640372832024792\n",
      "6 Train Loss 44.297626 Test MSE 8.100133461638983 Test RE 1.3603609212473748\n",
      "7 Train Loss 44.222046 Test MSE 8.144413324274415 Test RE 1.3640741006363615\n",
      "8 Train Loss 43.98688 Test MSE 8.109206473007358 Test RE 1.3611225825118707\n",
      "9 Train Loss 43.91725 Test MSE 8.068332930740622 Test RE 1.3576879565142133\n",
      "10 Train Loss 42.815826 Test MSE 7.719696190106061 Test RE 1.328030853033915\n",
      "11 Train Loss 38.207382 Test MSE 7.592158007227985 Test RE 1.317014872460147\n",
      "12 Train Loss 32.587463 Test MSE 4.979925364850911 Test RE 1.0666439570436357\n",
      "13 Train Loss 24.370186 Test MSE 4.498670645689141 Test RE 1.0137950345639126\n",
      "14 Train Loss 17.394571 Test MSE 4.15939939890141 Test RE 0.9748176247286859\n",
      "15 Train Loss 13.417679 Test MSE 3.890897224214458 Test RE 0.9428290165805765\n",
      "16 Train Loss 10.808765 Test MSE 4.010150956499146 Test RE 0.9571685511603268\n",
      "17 Train Loss 10.057454 Test MSE 3.911256471316714 Test RE 0.9452924900810314\n",
      "18 Train Loss 9.36527 Test MSE 3.9885543516396527 Test RE 0.9545876635532926\n",
      "19 Train Loss 8.835278 Test MSE 3.782311370048387 Test RE 0.9295798462193157\n",
      "20 Train Loss 8.307526 Test MSE 3.8587720928731963 Test RE 0.9389287227900561\n",
      "21 Train Loss 7.8702774 Test MSE 3.8165127729154 Test RE 0.9337732326495063\n",
      "22 Train Loss 7.1743426 Test MSE 3.644565312006851 Test RE 0.9124959150965852\n",
      "23 Train Loss 6.3203444 Test MSE 3.5575147537167933 Test RE 0.9015325574480423\n",
      "24 Train Loss 5.5708294 Test MSE 3.5108035267308106 Test RE 0.8955943049515344\n",
      "25 Train Loss 5.2426314 Test MSE 3.3514411395003347 Test RE 0.8750318448080625\n",
      "26 Train Loss 4.9023533 Test MSE 3.278390194659175 Test RE 0.8654428242192209\n",
      "27 Train Loss 4.129384 Test MSE 2.6587899222655316 Test RE 0.7793814631007694\n",
      "28 Train Loss 3.0927598 Test MSE 1.7162979204229625 Test RE 0.626187506435417\n",
      "29 Train Loss 2.527083 Test MSE 1.3453204930155191 Test RE 0.5543970863538648\n",
      "30 Train Loss 2.1548684 Test MSE 1.1877237473129034 Test RE 0.5209137008299948\n",
      "31 Train Loss 1.8103423 Test MSE 0.8889394954648767 Test RE 0.450654966283334\n",
      "32 Train Loss 1.3792006 Test MSE 0.8143877810112921 Test RE 0.4313439238920531\n",
      "33 Train Loss 1.1200587 Test MSE 0.7250755468522649 Test RE 0.4070049486230012\n",
      "34 Train Loss 0.9869115 Test MSE 0.5943958158666734 Test RE 0.3685071613473193\n",
      "35 Train Loss 0.91260594 Test MSE 0.46028420170109136 Test RE 0.32428069470013743\n",
      "36 Train Loss 0.8019336 Test MSE 0.45908036089602183 Test RE 0.32385635043649497\n",
      "37 Train Loss 0.699461 Test MSE 0.39140865463781266 Test RE 0.2990358606601328\n",
      "38 Train Loss 0.60844046 Test MSE 0.31804163792017637 Test RE 0.26955665036350773\n",
      "39 Train Loss 0.5520821 Test MSE 0.222112111963371 Test RE 0.22526523941902396\n",
      "40 Train Loss 0.4869685 Test MSE 0.0839022976126696 Test RE 0.13845064623845857\n",
      "41 Train Loss 0.38863102 Test MSE 0.06305003899749315 Test RE 0.12001920343705852\n",
      "42 Train Loss 0.35752532 Test MSE 0.051773318089693314 Test RE 0.10875796177788725\n",
      "43 Train Loss 0.33072728 Test MSE 0.0452227971409439 Test RE 0.10164517567240239\n",
      "44 Train Loss 0.2739253 Test MSE 0.034765253118870694 Test RE 0.08912114512513243\n",
      "45 Train Loss 0.2295056 Test MSE 0.03575344653367139 Test RE 0.09037889282365032\n",
      "46 Train Loss 0.19205496 Test MSE 0.03128136007221743 Test RE 0.08453778682834683\n",
      "47 Train Loss 0.16380088 Test MSE 0.029034397743723992 Test RE 0.08144500818034447\n",
      "48 Train Loss 0.14145482 Test MSE 0.024674028517166366 Test RE 0.07508066169361759\n",
      "49 Train Loss 0.12146463 Test MSE 0.018684780370088614 Test RE 0.06533592723948736\n",
      "50 Train Loss 0.101772994 Test MSE 0.01549974701531752 Test RE 0.05950731637375782\n",
      "51 Train Loss 0.09229134 Test MSE 0.014527768352483032 Test RE 0.05761127854303267\n",
      "52 Train Loss 0.08383819 Test MSE 0.014670843994263352 Test RE 0.05789427367338987\n",
      "53 Train Loss 0.07940927 Test MSE 0.014715161194385528 Test RE 0.057981650290228066\n",
      "54 Train Loss 0.071678706 Test MSE 0.009602532813943887 Test RE 0.04683828234584906\n",
      "55 Train Loss 0.06468431 Test MSE 0.00819736881277835 Test RE 0.04327581921383859\n",
      "56 Train Loss 0.061240207 Test MSE 0.007832270847144142 Test RE 0.04230112415769004\n",
      "57 Train Loss 0.052500978 Test MSE 0.007231872603641479 Test RE 0.040647462942238664\n",
      "58 Train Loss 0.04973688 Test MSE 0.0066359160301083285 Test RE 0.038936642640272585\n",
      "59 Train Loss 0.047641717 Test MSE 0.006576425710768213 Test RE 0.03876171817133441\n",
      "60 Train Loss 0.04224716 Test MSE 0.005631955831602947 Test RE 0.035870520650566555\n",
      "61 Train Loss 0.03913723 Test MSE 0.005974656076370074 Test RE 0.03694575242128973\n",
      "62 Train Loss 0.038509294 Test MSE 0.005796787288963165 Test RE 0.03639164962255445\n",
      "63 Train Loss 0.036343716 Test MSE 0.005436366989798462 Test RE 0.03524215392033138\n",
      "64 Train Loss 0.034528412 Test MSE 0.005116614294308739 Test RE 0.03419002356862124\n",
      "65 Train Loss 0.032739814 Test MSE 0.005183449716833458 Test RE 0.03441260149104804\n",
      "66 Train Loss 0.03023475 Test MSE 0.004423206847955418 Test RE 0.03178898672101872\n",
      "67 Train Loss 0.02920004 Test MSE 0.00443999685284392 Test RE 0.03184926331647328\n",
      "68 Train Loss 0.02823274 Test MSE 0.004027010829765341 Test RE 0.030331889072912892\n",
      "69 Train Loss 0.026683198 Test MSE 0.003651828948722825 Test RE 0.028884394891361128\n",
      "70 Train Loss 0.026152272 Test MSE 0.003379544204579002 Test RE 0.027786709837814342\n",
      "71 Train Loss 0.025321553 Test MSE 0.0034139260560856867 Test RE 0.027927696449713053\n",
      "72 Train Loss 0.024183996 Test MSE 0.0031703206726345205 Test RE 0.02691284787680429\n",
      "73 Train Loss 0.023863913 Test MSE 0.0031434977442480476 Test RE 0.026798756140753683\n",
      "74 Train Loss 0.022019396 Test MSE 0.0028584910520582344 Test RE 0.02555503492473985\n",
      "75 Train Loss 0.019781625 Test MSE 0.0026151307978386986 Test RE 0.024443014643219397\n",
      "76 Train Loss 0.017937101 Test MSE 0.0023851338787643055 Test RE 0.023343417681519797\n",
      "77 Train Loss 0.01627305 Test MSE 0.002426901670314304 Test RE 0.02354692229152899\n",
      "78 Train Loss 0.01581699 Test MSE 0.002399698231667059 Test RE 0.023414580215969757\n",
      "79 Train Loss 0.01568861 Test MSE 0.0022737298726383816 Test RE 0.0227917406362468\n",
      "80 Train Loss 0.015430819 Test MSE 0.0023576161209908166 Test RE 0.023208368232376417\n",
      "81 Train Loss 0.015050779 Test MSE 0.0022982669729409017 Test RE 0.022914389888057832\n",
      "82 Train Loss 0.014138345 Test MSE 0.0020018367335261334 Test RE 0.02138564667976148\n",
      "83 Train Loss 0.013920018 Test MSE 0.002034220483029189 Test RE 0.021557930713595557\n",
      "84 Train Loss 0.013466968 Test MSE 0.0019771035703404684 Test RE 0.021253123724757343\n",
      "85 Train Loss 0.01280055 Test MSE 0.0021157383486461994 Test RE 0.021985636295122096\n",
      "86 Train Loss 0.012146216 Test MSE 0.0020487111144254617 Test RE 0.02163457768578651\n",
      "87 Train Loss 0.011949726 Test MSE 0.0020927648421635216 Test RE 0.021865946220687334\n",
      "88 Train Loss 0.0118147535 Test MSE 0.002127588764069128 Test RE 0.022047121950245538\n",
      "89 Train Loss 0.0117254 Test MSE 0.0020692079956028415 Test RE 0.021742532815913918\n",
      "90 Train Loss 0.011285871 Test MSE 0.0019125902582494195 Test RE 0.02090350102056173\n",
      "91 Train Loss 0.010558283 Test MSE 0.001621809680198983 Test RE 0.01924899255024642\n",
      "92 Train Loss 0.009907071 Test MSE 0.001487355209970987 Test RE 0.018433822859666615\n",
      "93 Train Loss 0.009248697 Test MSE 0.0014058773733849885 Test RE 0.017921806374638694\n",
      "94 Train Loss 0.0087468475 Test MSE 0.0013392063895331864 Test RE 0.017491691803395715\n",
      "95 Train Loss 0.008431095 Test MSE 0.0013944336468365193 Test RE 0.01784871631673339\n",
      "96 Train Loss 0.008351475 Test MSE 0.0014066945039485866 Test RE 0.017927013915747674\n",
      "97 Train Loss 0.008304478 Test MSE 0.0013917545898950944 Test RE 0.0178315621419882\n",
      "98 Train Loss 0.00815252 Test MSE 0.0013530375327823027 Test RE 0.017581785700249007\n",
      "99 Train Loss 0.007937694 Test MSE 0.0013537285375715394 Test RE 0.017586274691525527\n",
      "Training time: 71.76\n",
      "5\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.203796 Test MSE 8.586288930651147 Test RE 1.4005893172852604\n",
      "1 Train Loss 42.760353 Test MSE 8.912457897060554 Test RE 1.426943593260064\n",
      "2 Train Loss 34.27285 Test MSE 8.477673873437377 Test RE 1.391702518451687\n",
      "3 Train Loss 30.650684 Test MSE 8.192427570856953 Test RE 1.368089045727023\n",
      "4 Train Loss 29.157795 Test MSE 8.530452516965484 Test RE 1.3960278915230109\n",
      "5 Train Loss 27.79583 Test MSE 8.415044442354768 Test RE 1.3865523372997592\n",
      "6 Train Loss 26.571053 Test MSE 8.319971368572565 Test RE 1.3786974621541876\n",
      "7 Train Loss 24.995716 Test MSE 8.06199481230709 Test RE 1.3571545825344915\n",
      "8 Train Loss 23.335142 Test MSE 7.943789376139976 Test RE 1.3471685035961383\n",
      "9 Train Loss 21.144104 Test MSE 8.547023701250295 Test RE 1.3973831895809101\n",
      "10 Train Loss 18.737555 Test MSE 8.544608987254621 Test RE 1.3971857805632715\n",
      "11 Train Loss 16.398151 Test MSE 7.829926421841518 Test RE 1.3374787812387665\n",
      "12 Train Loss 14.802037 Test MSE 7.474931371101808 Test RE 1.3068076408516813\n",
      "13 Train Loss 12.454325 Test MSE 6.441999398478316 Test RE 1.2131608877913622\n",
      "14 Train Loss 11.116686 Test MSE 6.2525602138391765 Test RE 1.195190140013996\n",
      "15 Train Loss 10.385433 Test MSE 6.031388259705947 Test RE 1.1738610795557556\n",
      "16 Train Loss 9.674086 Test MSE 6.030573686335743 Test RE 1.1737818085636011\n",
      "17 Train Loss 8.958514 Test MSE 6.076186532324092 Test RE 1.1782124543699484\n",
      "18 Train Loss 8.587595 Test MSE 6.037864489502684 Test RE 1.1744911297320912\n",
      "19 Train Loss 8.205447 Test MSE 6.112494783431401 Test RE 1.1817274153921322\n",
      "20 Train Loss 7.932086 Test MSE 6.140913518378683 Test RE 1.1844713240082998\n",
      "21 Train Loss 7.6677127 Test MSE 6.068801529529209 Test RE 1.1774962364212374\n",
      "22 Train Loss 7.4045687 Test MSE 5.953740817738322 Test RE 1.1662805222347408\n",
      "23 Train Loss 7.0778055 Test MSE 5.897645019525535 Test RE 1.1607732056521838\n",
      "24 Train Loss 6.3171587 Test MSE 5.681565759939026 Test RE 1.1393104454890333\n",
      "25 Train Loss 5.400858 Test MSE 5.2859491581183375 Test RE 1.0989287895307678\n",
      "26 Train Loss 4.7440705 Test MSE 4.998901896992653 Test RE 1.068674304457909\n",
      "27 Train Loss 4.0803933 Test MSE 5.050400698075927 Test RE 1.0741649529957782\n",
      "28 Train Loss 3.6936374 Test MSE 5.183291372884447 Test RE 1.0882053876119295\n",
      "29 Train Loss 3.4672582 Test MSE 5.179427545378635 Test RE 1.0877997166324744\n",
      "30 Train Loss 3.2008524 Test MSE 5.190231793333059 Test RE 1.0889336966959813\n",
      "31 Train Loss 2.9625292 Test MSE 5.168130637850127 Test RE 1.0866127629765698\n",
      "32 Train Loss 2.8544278 Test MSE 5.228170311270731 Test RE 1.0929062852404483\n",
      "33 Train Loss 2.7479734 Test MSE 5.2342051624911425 Test RE 1.0935368714913138\n",
      "34 Train Loss 2.643868 Test MSE 5.208287402198972 Test RE 1.0908261257861813\n",
      "35 Train Loss 2.5752528 Test MSE 5.175882924886394 Test RE 1.0874274267356308\n",
      "36 Train Loss 2.5080788 Test MSE 5.128744437492921 Test RE 1.0824643190840484\n",
      "37 Train Loss 2.4373584 Test MSE 5.113617401602368 Test RE 1.0808667966673169\n",
      "38 Train Loss 2.3633099 Test MSE 5.2087098393233795 Test RE 1.0908703626026988\n",
      "39 Train Loss 2.3124363 Test MSE 5.19949965894432 Test RE 1.089905482772145\n",
      "40 Train Loss 2.265407 Test MSE 5.218336257566819 Test RE 1.0918779371514074\n",
      "41 Train Loss 2.2130399 Test MSE 5.199460825730541 Test RE 1.0899014127063296\n",
      "42 Train Loss 2.1611207 Test MSE 5.211003305524677 Test RE 1.091110498744089\n",
      "43 Train Loss 2.1232636 Test MSE 5.195153281078693 Test RE 1.0894498493688158\n",
      "44 Train Loss 2.0760083 Test MSE 5.2727573503870575 Test RE 1.097556669510942\n",
      "45 Train Loss 2.0444255 Test MSE 5.232621314527562 Test RE 1.0933714091969715\n",
      "46 Train Loss 2.0104816 Test MSE 5.230125596025789 Test RE 1.0931106342869992\n",
      "47 Train Loss 1.9664258 Test MSE 5.259785555702241 Test RE 1.0962057589637826\n",
      "48 Train Loss 1.9408106 Test MSE 5.260291443097203 Test RE 1.096258474358371\n",
      "49 Train Loss 1.9120384 Test MSE 5.24864530961916 Test RE 1.0950442596111192\n",
      "50 Train Loss 1.8785183 Test MSE 5.286100499655018 Test RE 1.0989445210840159\n",
      "51 Train Loss 1.8473041 Test MSE 5.269713115862702 Test RE 1.097239785754724\n",
      "52 Train Loss 1.8158333 Test MSE 5.305371406999615 Test RE 1.1009458443590292\n",
      "53 Train Loss 1.793995 Test MSE 5.327883319651559 Test RE 1.1032791551624241\n",
      "54 Train Loss 1.7614942 Test MSE 5.357531162566169 Test RE 1.1063445815733117\n",
      "55 Train Loss 1.7411662 Test MSE 5.326560041526045 Test RE 1.103142136786917\n",
      "56 Train Loss 1.7160633 Test MSE 5.335342283381273 Test RE 1.104051172912192\n",
      "57 Train Loss 1.6857841 Test MSE 5.3026535132155015 Test RE 1.1006638059340257\n",
      "58 Train Loss 1.6638287 Test MSE 5.3148907878062746 Test RE 1.1019331103732009\n",
      "59 Train Loss 1.6252624 Test MSE 5.358269297322378 Test RE 1.1064207923537328\n",
      "60 Train Loss 1.6021332 Test MSE 5.387623199361059 Test RE 1.1094472741239745\n",
      "61 Train Loss 1.5786331 Test MSE 5.338062507787393 Test RE 1.1043325873070222\n",
      "62 Train Loss 1.5513389 Test MSE 5.381662857202884 Test RE 1.1088334120334224\n",
      "63 Train Loss 1.530252 Test MSE 5.385253099022811 Test RE 1.1092032156109943\n",
      "64 Train Loss 1.4994711 Test MSE 5.411554373433729 Test RE 1.1119085596265001\n",
      "65 Train Loss 1.4737704 Test MSE 5.416223234659146 Test RE 1.1123881101554245\n",
      "66 Train Loss 1.4482604 Test MSE 5.406844790578948 Test RE 1.111424616847826\n",
      "67 Train Loss 1.4308915 Test MSE 5.398090246156614 Test RE 1.1105244654322297\n",
      "68 Train Loss 1.4086078 Test MSE 5.411428945580638 Test RE 1.11189567376211\n",
      "69 Train Loss 1.3916202 Test MSE 5.381777446537702 Test RE 1.1088452169169802\n",
      "70 Train Loss 1.3762349 Test MSE 5.411774348767085 Test RE 1.1119311584912277\n",
      "71 Train Loss 1.3620175 Test MSE 5.427184708781369 Test RE 1.1135131792177855\n",
      "72 Train Loss 1.3366888 Test MSE 5.451206667116794 Test RE 1.115974790063824\n",
      "73 Train Loss 1.3260887 Test MSE 5.470383331994796 Test RE 1.117935996790527\n",
      "74 Train Loss 1.309183 Test MSE 5.492209738645949 Test RE 1.1201640157042316\n",
      "75 Train Loss 1.2901983 Test MSE 5.479975843622007 Test RE 1.1189157377307113\n",
      "76 Train Loss 1.2723439 Test MSE 5.463875950393649 Test RE 1.1172708696452083\n",
      "77 Train Loss 1.2606621 Test MSE 5.498142139965875 Test RE 1.1207688240876137\n",
      "78 Train Loss 1.2487334 Test MSE 5.491052915063282 Test RE 1.1200460394748153\n",
      "79 Train Loss 1.2345148 Test MSE 5.502209657101728 Test RE 1.121183318971031\n",
      "80 Train Loss 1.2250676 Test MSE 5.48070923125041 Test RE 1.1189906077236862\n",
      "81 Train Loss 1.2147045 Test MSE 5.467332101529987 Test RE 1.1176241762151997\n",
      "82 Train Loss 1.206643 Test MSE 5.474641124889968 Test RE 1.1183709767369427\n",
      "83 Train Loss 1.1949613 Test MSE 5.469796968035782 Test RE 1.1178760800621925\n",
      "84 Train Loss 1.1872715 Test MSE 5.509835049538237 Test RE 1.1219599617432359\n",
      "85 Train Loss 1.1823839 Test MSE 5.514921607402635 Test RE 1.1224777265854684\n",
      "86 Train Loss 1.1743643 Test MSE 5.525356741809099 Test RE 1.123539180508912\n",
      "87 Train Loss 1.1691563 Test MSE 5.535581481130762 Test RE 1.124578261428431\n",
      "88 Train Loss 1.161545 Test MSE 5.530560134796385 Test RE 1.1240680911679635\n",
      "89 Train Loss 1.1555566 Test MSE 5.538365470928526 Test RE 1.1248610159027315\n",
      "90 Train Loss 1.1495697 Test MSE 5.547209473494497 Test RE 1.125758781265744\n",
      "91 Train Loss 1.1442285 Test MSE 5.53733529485724 Test RE 1.1247563948913768\n",
      "92 Train Loss 1.1390741 Test MSE 5.559698174686227 Test RE 1.1270253064365878\n",
      "93 Train Loss 1.1358097 Test MSE 5.572537502060408 Test RE 1.1283259078186565\n",
      "94 Train Loss 1.1287161 Test MSE 5.588410934594739 Test RE 1.1299317892332001\n",
      "95 Train Loss 1.1226091 Test MSE 5.606060574933459 Test RE 1.1317146903603634\n",
      "96 Train Loss 1.1178442 Test MSE 5.592952138549084 Test RE 1.130390793480127\n",
      "97 Train Loss 1.112463 Test MSE 5.588336144056141 Test RE 1.1299242281849131\n",
      "98 Train Loss 1.1073548 Test MSE 5.604166895500524 Test RE 1.1315235324326491\n",
      "99 Train Loss 1.1015085 Test MSE 5.6216439605564155 Test RE 1.1332865345610823\n",
      "Training time: 68.39\n",
      "6\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.277946 Test MSE 8.601207002956574 Test RE 1.4018055019050644\n",
      "1 Train Loss 58.75509 Test MSE 8.547693801653699 Test RE 1.3974379670519304\n",
      "2 Train Loss 58.412952 Test MSE 8.693257388867687 Test RE 1.4092866225020662\n",
      "3 Train Loss 55.330097 Test MSE 8.119474649335936 Test RE 1.3619840616971446\n",
      "4 Train Loss 53.414993 Test MSE 9.010137118443776 Test RE 1.4347418300525576\n",
      "5 Train Loss 49.822258 Test MSE 8.96186842171739 Test RE 1.430893602409048\n",
      "6 Train Loss 47.352524 Test MSE 8.73142751277266 Test RE 1.4123771629084667\n",
      "7 Train Loss 46.888313 Test MSE 8.723279847059317 Test RE 1.4117180345601452\n",
      "8 Train Loss 46.518272 Test MSE 8.652964659245884 Test RE 1.406016849570968\n",
      "9 Train Loss 45.63498 Test MSE 8.422656772039693 Test RE 1.3871793397864278\n",
      "10 Train Loss 45.10119 Test MSE 8.531756973180526 Test RE 1.3961346260510594\n",
      "11 Train Loss 44.417534 Test MSE 8.798012142187195 Test RE 1.4177522290885267\n",
      "12 Train Loss 44.057297 Test MSE 8.775907053520884 Test RE 1.4159700510115694\n",
      "13 Train Loss 43.68235 Test MSE 8.59010980661476 Test RE 1.4009009119034095\n",
      "14 Train Loss 43.042942 Test MSE 8.52791143976828 Test RE 1.3958199495144963\n",
      "15 Train Loss 42.52584 Test MSE 8.431021237986482 Test RE 1.3878679666283182\n",
      "16 Train Loss 41.863075 Test MSE 8.181134372168897 Test RE 1.3671457704025032\n",
      "17 Train Loss 40.672897 Test MSE 7.898450982647481 Test RE 1.3433185868734967\n",
      "18 Train Loss 38.83265 Test MSE 7.657346657830178 Test RE 1.3226569386556113\n",
      "19 Train Loss 38.352898 Test MSE 8.014572677425035 Test RE 1.3531571791831165\n",
      "20 Train Loss 36.85253 Test MSE 7.495400570651963 Test RE 1.3085956852924154\n",
      "21 Train Loss 35.22823 Test MSE 7.66685174817126 Test RE 1.3234775933330707\n",
      "22 Train Loss 34.866634 Test MSE 7.798226799344303 Test RE 1.3347686298829993\n",
      "23 Train Loss 34.00504 Test MSE 7.769938616583422 Test RE 1.3323454839388085\n",
      "24 Train Loss 32.919792 Test MSE 7.243679277347802 Test RE 1.286434465201718\n",
      "25 Train Loss 31.988472 Test MSE 6.846205126862805 Test RE 1.2506420131827611\n",
      "26 Train Loss 30.727655 Test MSE 6.912527365722028 Test RE 1.2566851759094866\n",
      "27 Train Loss 30.259338 Test MSE 6.887520053452063 Test RE 1.2544099738687078\n",
      "28 Train Loss 29.750614 Test MSE 7.008120053277831 Test RE 1.2653446312606997\n",
      "29 Train Loss 28.450981 Test MSE 6.693293529068111 Test RE 1.2365964511688938\n",
      "30 Train Loss 26.648796 Test MSE 6.728014938912026 Test RE 1.2397997197048134\n",
      "31 Train Loss 25.705566 Test MSE 6.60875147376706 Test RE 1.2287619950813735\n",
      "32 Train Loss 24.932068 Test MSE 6.608368316313532 Test RE 1.228726374424192\n",
      "33 Train Loss 24.452673 Test MSE 6.544905726919858 Test RE 1.2228121856841174\n",
      "34 Train Loss 23.938107 Test MSE 6.3720784747238355 Test RE 1.2065591517378664\n",
      "35 Train Loss 23.393612 Test MSE 6.28481528148345 Test RE 1.1982689866917047\n",
      "36 Train Loss 22.924213 Test MSE 6.192161782073599 Test RE 1.1894034875004036\n",
      "37 Train Loss 21.760418 Test MSE 5.193574329902235 Test RE 1.0892842797742952\n",
      "38 Train Loss 21.076303 Test MSE 4.517372714796527 Test RE 1.0159001453556875\n",
      "39 Train Loss 18.12152 Test MSE 3.2870581849774663 Test RE 0.866586174700993\n",
      "40 Train Loss 15.7450485 Test MSE 2.980642617442676 Test RE 0.8252072096425596\n",
      "41 Train Loss 13.3565645 Test MSE 2.8026628791404393 Test RE 0.8001906841077805\n",
      "42 Train Loss 11.775614 Test MSE 2.5962165788397775 Test RE 0.7701556746485317\n",
      "43 Train Loss 10.826246 Test MSE 2.212975039099557 Test RE 0.7110437411700417\n",
      "44 Train Loss 9.279158 Test MSE 1.6216745193589066 Test RE 0.6086812260378979\n",
      "45 Train Loss 8.395601 Test MSE 1.346345513761329 Test RE 0.5546082480495077\n",
      "46 Train Loss 7.4089956 Test MSE 0.9698310648039774 Test RE 0.4707129057904583\n",
      "47 Train Loss 6.8097 Test MSE 0.8118065603155955 Test RE 0.43065980416308314\n",
      "48 Train Loss 4.9276786 Test MSE 0.690287631747781 Test RE 0.39712123119653797\n",
      "49 Train Loss 4.728406 Test MSE 0.68376141288463 Test RE 0.3952395120492948\n",
      "50 Train Loss 4.243743 Test MSE 0.6657881230215895 Test RE 0.39001030479235194\n",
      "51 Train Loss 3.6972806 Test MSE 0.5446125745680042 Test RE 0.35273771117478964\n",
      "52 Train Loss 3.37257 Test MSE 0.533613667312739 Test RE 0.34915762646344106\n",
      "53 Train Loss 3.2287383 Test MSE 0.5289666830749175 Test RE 0.3476339792916451\n",
      "54 Train Loss 3.049477 Test MSE 0.4862567749625689 Test RE 0.33330428186718813\n",
      "55 Train Loss 2.902854 Test MSE 0.4289990126138545 Test RE 0.3130662178591238\n",
      "56 Train Loss 2.8656187 Test MSE 0.4327853113157667 Test RE 0.31444472711977145\n",
      "57 Train Loss 2.7838151 Test MSE 0.4124506454211524 Test RE 0.30696867106553394\n",
      "58 Train Loss 2.4095342 Test MSE 0.3391153335574789 Test RE 0.27834394227345605\n",
      "59 Train Loss 2.1915584 Test MSE 0.31117718905624303 Test RE 0.2666317953448173\n",
      "60 Train Loss 2.096075 Test MSE 0.31819683498595563 Test RE 0.2696224110908729\n",
      "61 Train Loss 1.9561392 Test MSE 0.30705940328482173 Test RE 0.2648617602955596\n",
      "62 Train Loss 1.7983813 Test MSE 0.2896310749040167 Test RE 0.25723534288962574\n",
      "63 Train Loss 1.688767 Test MSE 0.2808401369158628 Test RE 0.25330143393163695\n",
      "64 Train Loss 1.4550822 Test MSE 0.26021496309020753 Test RE 0.24382273208871977\n",
      "65 Train Loss 1.2517325 Test MSE 0.2185492549292258 Test RE 0.2234512175493091\n",
      "66 Train Loss 1.2178485 Test MSE 0.22316090265123212 Test RE 0.22579645279042163\n",
      "67 Train Loss 1.1368011 Test MSE 0.22031793352187562 Test RE 0.22435357021844143\n",
      "68 Train Loss 1.0145625 Test MSE 0.20656692511994293 Test RE 0.21723932899728768\n",
      "69 Train Loss 0.9186037 Test MSE 0.17690133164472724 Test RE 0.20103589667982208\n",
      "70 Train Loss 0.9005742 Test MSE 0.17687243696037155 Test RE 0.20101947762309108\n",
      "71 Train Loss 0.8404087 Test MSE 0.15945232706936294 Test RE 0.19086376704454922\n",
      "72 Train Loss 0.8045474 Test MSE 0.15253300774177378 Test RE 0.18667664081567623\n",
      "73 Train Loss 0.77845514 Test MSE 0.14262897737469557 Test RE 0.18051443836640085\n",
      "74 Train Loss 0.73671687 Test MSE 0.12897622359258462 Test RE 0.17165754166377925\n",
      "75 Train Loss 0.69475186 Test MSE 0.11804669019160878 Test RE 0.16422337291210767\n",
      "76 Train Loss 0.6495855 Test MSE 0.11871978811398665 Test RE 0.1646909052379845\n",
      "77 Train Loss 0.6065196 Test MSE 0.11188861226390921 Test RE 0.15988252705836908\n",
      "78 Train Loss 0.5572612 Test MSE 0.10372093780867034 Test RE 0.15393638295016135\n",
      "79 Train Loss 0.5470838 Test MSE 0.09944759055156084 Test RE 0.15073190674195916\n",
      "80 Train Loss 0.53935933 Test MSE 0.10179985424494721 Test RE 0.15250414169365348\n",
      "81 Train Loss 0.48839805 Test MSE 0.08782007170342127 Test RE 0.1416462084610111\n",
      "82 Train Loss 0.4716109 Test MSE 0.07909590237222551 Test RE 0.13442655001133083\n",
      "83 Train Loss 0.46581963 Test MSE 0.07534915355349962 Test RE 0.13120405248772798\n",
      "84 Train Loss 0.44338202 Test MSE 0.07012367444073575 Test RE 0.12657280150378308\n",
      "85 Train Loss 0.3662991 Test MSE 0.05628044769410838 Test RE 0.11339315315470122\n",
      "86 Train Loss 0.35151392 Test MSE 0.05696313812049713 Test RE 0.114078818250035\n",
      "87 Train Loss 0.33450112 Test MSE 0.04889034314653526 Test RE 0.10568652124894959\n",
      "88 Train Loss 0.3190034 Test MSE 0.04729269132955212 Test RE 0.10394535218337447\n",
      "89 Train Loss 0.3077991 Test MSE 0.04557490497835788 Test RE 0.10204011660008347\n",
      "90 Train Loss 0.2939892 Test MSE 0.03975770845887369 Test RE 0.09530566865009818\n",
      "91 Train Loss 0.28524446 Test MSE 0.03841547621277456 Test RE 0.09368308224027606\n",
      "92 Train Loss 0.27377883 Test MSE 0.03521861573344678 Test RE 0.08970036315376777\n",
      "93 Train Loss 0.27120882 Test MSE 0.03453410253187928 Test RE 0.08882437234249398\n",
      "94 Train Loss 0.26853895 Test MSE 0.03434648215060707 Test RE 0.0885827566892464\n",
      "95 Train Loss 0.26096052 Test MSE 0.03474228204832939 Test RE 0.08909169695186138\n",
      "96 Train Loss 0.24428016 Test MSE 0.037561419023430825 Test RE 0.09263584252440343\n",
      "97 Train Loss 0.23610279 Test MSE 0.036926324288673894 Test RE 0.09184935269170247\n",
      "98 Train Loss 0.22698191 Test MSE 0.03838499477932948 Test RE 0.09364590762215248\n",
      "99 Train Loss 0.22279164 Test MSE 0.03639287401679021 Test RE 0.09118349560966699\n",
      "Training time: 73.87\n",
      "7\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 46.328457 Test MSE 8.729481196061334 Test RE 1.4122197381071584\n",
      "1 Train Loss 32.671883 Test MSE 7.052738511355353 Test RE 1.2693662625122573\n",
      "2 Train Loss 26.921143 Test MSE 6.005892419401222 Test RE 1.1713773835288988\n",
      "3 Train Loss 21.933598 Test MSE 6.01893316498158 Test RE 1.1726484145654827\n",
      "4 Train Loss 18.451126 Test MSE 5.698496710815636 Test RE 1.141006743720137\n",
      "5 Train Loss 15.872883 Test MSE 5.7497541444597555 Test RE 1.146126879054089\n",
      "6 Train Loss 13.664582 Test MSE 5.579043709807256 Test RE 1.128984403273419\n",
      "7 Train Loss 12.345184 Test MSE 5.409094867134871 Test RE 1.111655854329845\n",
      "8 Train Loss 11.122272 Test MSE 5.3318258642057135 Test RE 1.103687283736214\n",
      "9 Train Loss 10.282912 Test MSE 5.116912086898157 Test RE 1.081214939893845\n",
      "10 Train Loss 9.764897 Test MSE 5.013386436915496 Test RE 1.070221450131542\n",
      "11 Train Loss 9.250007 Test MSE 4.74788095409226 Test RE 1.0414968741893316\n",
      "12 Train Loss 8.894181 Test MSE 4.689672907465721 Test RE 1.0350929168341365\n",
      "13 Train Loss 8.3372345 Test MSE 4.352904724169669 Test RE 0.9972352949895312\n",
      "14 Train Loss 8.021696 Test MSE 4.1481476522752185 Test RE 0.9734982240562191\n",
      "15 Train Loss 7.642606 Test MSE 3.9813099847476883 Test RE 0.9537203660823693\n",
      "16 Train Loss 7.2551937 Test MSE 3.9272690025169816 Test RE 0.9472255089391356\n",
      "17 Train Loss 6.6542463 Test MSE 3.5615933398839763 Test RE 0.9020491997094753\n",
      "18 Train Loss 5.9730997 Test MSE 3.1793514484840752 Test RE 0.8522702506529252\n",
      "19 Train Loss 5.312811 Test MSE 2.9929722089137627 Test RE 0.8269122056742042\n",
      "20 Train Loss 4.527467 Test MSE 2.844813748595354 Test RE 0.8061854938282529\n",
      "21 Train Loss 3.695498 Test MSE 2.1869615681979875 Test RE 0.7068522355474776\n",
      "22 Train Loss 2.8578053 Test MSE 0.8845421337503797 Test RE 0.4495389456088801\n",
      "23 Train Loss 1.7931015 Test MSE 0.30875312622243545 Test RE 0.26559123725919176\n",
      "24 Train Loss 1.1270638 Test MSE 0.1679026253610642 Test RE 0.1958559653399374\n",
      "25 Train Loss 0.7635635 Test MSE 0.07882254228877705 Test RE 0.13419405593370132\n",
      "26 Train Loss 0.5116967 Test MSE 0.050819347439518076 Test RE 0.10775132078242097\n",
      "27 Train Loss 0.379278 Test MSE 0.04152656281359717 Test RE 0.09740271288566914\n",
      "28 Train Loss 0.2686318 Test MSE 0.0520653571742487 Test RE 0.10906426735247236\n",
      "29 Train Loss 0.23460604 Test MSE 0.05024236718274149 Test RE 0.10713789439556451\n",
      "30 Train Loss 0.18296127 Test MSE 0.04599513860274133 Test RE 0.10250947899829128\n",
      "31 Train Loss 0.15535408 Test MSE 0.032490080473057265 Test RE 0.08615558859825027\n",
      "32 Train Loss 0.122777164 Test MSE 0.02149457848213176 Test RE 0.07007652001071143\n",
      "33 Train Loss 0.09819762 Test MSE 0.01721203221442589 Test RE 0.06270817120882195\n",
      "34 Train Loss 0.08267052 Test MSE 0.013104153069858066 Test RE 0.05471577298536292\n",
      "35 Train Loss 0.06942144 Test MSE 0.010229164705042542 Test RE 0.048342393152266315\n",
      "36 Train Loss 0.0613259 Test MSE 0.009530807490059178 Test RE 0.04666302713268194\n",
      "37 Train Loss 0.050820503 Test MSE 0.0071977009275377285 Test RE 0.040551316570420166\n",
      "38 Train Loss 0.04554093 Test MSE 0.006865064154439144 Test RE 0.03960320741541062\n",
      "39 Train Loss 0.037953913 Test MSE 0.006176082020960087 Test RE 0.03756337343131434\n",
      "40 Train Loss 0.034106754 Test MSE 0.00579821066015949 Test RE 0.03639611723917846\n",
      "41 Train Loss 0.03015454 Test MSE 0.00651765694506648 Test RE 0.03858813677146893\n",
      "42 Train Loss 0.028211743 Test MSE 0.007635439294159684 Test RE 0.041766210655520095\n",
      "43 Train Loss 0.025073543 Test MSE 0.006597975897520998 Test RE 0.03882517506322773\n",
      "44 Train Loss 0.023449467 Test MSE 0.006408101340842421 Test RE 0.03826244743023917\n",
      "45 Train Loss 0.021511791 Test MSE 0.006327281832254684 Test RE 0.03802039723010121\n",
      "46 Train Loss 0.020126881 Test MSE 0.005379868873426564 Test RE 0.03505854641160622\n",
      "47 Train Loss 0.018857164 Test MSE 0.004631436312406046 Test RE 0.032528640176771755\n",
      "48 Train Loss 0.01684481 Test MSE 0.003618908038940912 Test RE 0.028753905024907603\n",
      "49 Train Loss 0.016276991 Test MSE 0.003443802802201328 Test RE 0.028049633935036965\n",
      "50 Train Loss 0.014917666 Test MSE 0.003414889078041518 Test RE 0.027931635183008008\n",
      "51 Train Loss 0.0137181645 Test MSE 0.0036769424885361147 Test RE 0.028983543367338452\n",
      "52 Train Loss 0.012143666 Test MSE 0.003384305850489708 Test RE 0.027806278142442815\n",
      "53 Train Loss 0.010791208 Test MSE 0.002605685379098891 Test RE 0.02439883265503736\n",
      "54 Train Loss 0.008941212 Test MSE 0.0024384442204057107 Test RE 0.023602851448796612\n",
      "55 Train Loss 0.008190405 Test MSE 0.002718534986750262 Test RE 0.024921577185247974\n",
      "56 Train Loss 0.0078027598 Test MSE 0.0025478135833737967 Test RE 0.024126364487747555\n",
      "57 Train Loss 0.006298326 Test MSE 0.002386376160832734 Test RE 0.02334949602673169\n",
      "58 Train Loss 0.0059244474 Test MSE 0.002736951542245544 Test RE 0.025005849581534706\n",
      "59 Train Loss 0.005555078 Test MSE 0.002352657045376872 Test RE 0.02318394681838734\n",
      "60 Train Loss 0.0047416193 Test MSE 0.002373443998113463 Test RE 0.023286142710690162\n",
      "61 Train Loss 0.0044670557 Test MSE 0.002138930063811085 Test RE 0.022105805914173403\n",
      "62 Train Loss 0.004416494 Test MSE 0.002019685523696808 Test RE 0.02148077452893763\n",
      "63 Train Loss 0.0042335307 Test MSE 0.0019528931715536019 Test RE 0.02112259654015999\n",
      "64 Train Loss 0.0039530145 Test MSE 0.0019964472645855142 Test RE 0.021356839395699653\n",
      "65 Train Loss 0.0031334013 Test MSE 0.001348418720949488 Test RE 0.01755175091567334\n",
      "66 Train Loss 0.0030373442 Test MSE 0.0012560758931334042 Test RE 0.016940101204573867\n",
      "67 Train Loss 0.0027384262 Test MSE 0.001387133946639884 Test RE 0.017801937024027895\n",
      "68 Train Loss 0.0023702309 Test MSE 0.0011884692471087841 Test RE 0.016477906509276156\n",
      "69 Train Loss 0.0021496536 Test MSE 0.0010262012029306395 Test RE 0.01531173203190697\n",
      "70 Train Loss 0.002103681 Test MSE 0.0009084314238401112 Test RE 0.014406355735678184\n",
      "71 Train Loss 0.0020435392 Test MSE 0.0008800497085149651 Test RE 0.014179524325343588\n",
      "72 Train Loss 0.001708878 Test MSE 0.000670670640609369 Test RE 0.012378348560683738\n",
      "73 Train Loss 0.0016729326 Test MSE 0.0006799653331918821 Test RE 0.012463827968982178\n",
      "74 Train Loss 0.0016349696 Test MSE 0.0006311790355996978 Test RE 0.012008377802167307\n",
      "75 Train Loss 0.001476484 Test MSE 0.0005305173920953775 Test RE 0.011009253534783577\n",
      "76 Train Loss 0.0013299184 Test MSE 0.00039148249119810505 Test RE 0.009457236112752303\n",
      "77 Train Loss 0.0012796016 Test MSE 0.00032781977888567815 Test RE 0.008654174278120859\n",
      "78 Train Loss 0.0012486911 Test MSE 0.0002966606989595997 Test RE 0.008232619968093787\n",
      "79 Train Loss 0.0012330966 Test MSE 0.0002738621304472913 Test RE 0.007909955704032162\n",
      "80 Train Loss 0.0011909441 Test MSE 0.0002499956413519138 Test RE 0.007557432531124675\n",
      "81 Train Loss 0.0011526806 Test MSE 0.00026215633977826313 Test RE 0.007739060516364428\n",
      "82 Train Loss 0.0011313271 Test MSE 0.0002794016883582763 Test RE 0.007989554679294405\n",
      "83 Train Loss 0.001112092 Test MSE 0.00027448518939234267 Test RE 0.007918948493070023\n",
      "84 Train Loss 0.001103499 Test MSE 0.0002673470045252295 Test RE 0.007815301221686381\n",
      "85 Train Loss 0.0010974386 Test MSE 0.0002690581623546112 Test RE 0.00784027229486487\n",
      "86 Train Loss 0.001029975 Test MSE 0.00022469005744962513 Test RE 0.00716473262464978\n",
      "87 Train Loss 0.0008319802 Test MSE 0.00022751024204570143 Test RE 0.007209556281764547\n",
      "88 Train Loss 0.0007604672 Test MSE 0.00022783469108236614 Test RE 0.0072146951718039904\n",
      "89 Train Loss 0.00074096245 Test MSE 0.00023820206408264503 Test RE 0.007377017615359552\n",
      "90 Train Loss 0.00071088487 Test MSE 0.00018680664512075827 Test RE 0.006532873078855442\n",
      "91 Train Loss 0.00070258323 Test MSE 0.00016654346044019133 Test RE 0.006168390396900429\n",
      "92 Train Loss 0.0006934536 Test MSE 0.00016674810111703286 Test RE 0.006172178945715015\n",
      "93 Train Loss 0.0006699111 Test MSE 0.00016288328274501553 Test RE 0.006100231507049169\n",
      "94 Train Loss 0.0006497721 Test MSE 0.00015013902771284234 Test RE 0.005856725369865331\n",
      "95 Train Loss 0.0006355328 Test MSE 0.00014756375940062403 Test RE 0.005806279204565568\n",
      "96 Train Loss 0.0006184904 Test MSE 0.00013846827132691313 Test RE 0.005624490602371344\n",
      "97 Train Loss 0.0005967099 Test MSE 0.0001292765222904598 Test RE 0.0054346038301063635\n",
      "98 Train Loss 0.000576877 Test MSE 0.00010446847894120963 Test RE 0.004885406388621469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.00056273246 Test MSE 9.893298290198324e-05 Test RE 0.004754212746210556\n",
      "Training time: 69.28\n",
      "8\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54.562943 Test MSE 8.477578683272965 Test RE 1.3916947051785302\n",
      "1 Train Loss 31.934807 Test MSE 8.141043708469365 Test RE 1.3637918899364778\n",
      "2 Train Loss 28.176765 Test MSE 6.756096130854035 Test RE 1.2423843455056809\n",
      "3 Train Loss 23.116875 Test MSE 6.774976235153865 Test RE 1.2441190737473573\n",
      "4 Train Loss 17.411894 Test MSE 6.3541399787054536 Test RE 1.204859619089411\n",
      "5 Train Loss 13.17277 Test MSE 5.55494008519478 Test RE 1.1265429389664439\n",
      "6 Train Loss 10.936762 Test MSE 5.199505134724551 Test RE 1.08990605668134\n",
      "7 Train Loss 9.174749 Test MSE 4.491049429687175 Test RE 1.0129359334389134\n",
      "8 Train Loss 8.0855255 Test MSE 3.9550447414842647 Test RE 0.950569248934594\n",
      "9 Train Loss 7.5652676 Test MSE 3.871331243730738 Test RE 0.9404554478457807\n",
      "10 Train Loss 7.1556673 Test MSE 3.7773233798885015 Test RE 0.9289666940519025\n",
      "11 Train Loss 6.8311844 Test MSE 3.806249787835739 Test RE 0.9325168825969912\n",
      "12 Train Loss 6.6260633 Test MSE 3.7939817110024445 Test RE 0.9310128533528003\n",
      "13 Train Loss 6.395481 Test MSE 3.6681134606054155 Test RE 0.915439063389372\n",
      "14 Train Loss 6.2769604 Test MSE 3.5976841422888493 Test RE 0.9066080610398628\n",
      "15 Train Loss 6.1916833 Test MSE 3.6100354545222504 Test RE 0.9081629786457388\n",
      "16 Train Loss 6.058997 Test MSE 3.585779711118497 Test RE 0.9051068736608833\n",
      "17 Train Loss 5.944068 Test MSE 3.469988003221463 Test RE 0.8903731334942858\n",
      "18 Train Loss 5.7744684 Test MSE 3.522378696042767 Test RE 0.8970694836307109\n",
      "19 Train Loss 5.603344 Test MSE 3.6199569210943823 Test RE 0.9094100753126463\n",
      "20 Train Loss 5.3593206 Test MSE 3.6859431190828342 Test RE 0.9176612110927261\n",
      "21 Train Loss 5.093606 Test MSE 3.697312407607027 Test RE 0.919075384054562\n",
      "22 Train Loss 4.90045 Test MSE 3.6068900889520634 Test RE 0.9077672585650194\n",
      "23 Train Loss 4.6379995 Test MSE 3.4901978731625123 Test RE 0.8929622203498204\n",
      "24 Train Loss 4.2960033 Test MSE 3.387557870097163 Test RE 0.8797340909104403\n",
      "25 Train Loss 3.8108716 Test MSE 3.0902147165208658 Test RE 0.8402381349675956\n",
      "26 Train Loss 2.8555777 Test MSE 2.9867736320005243 Test RE 0.8260554761128096\n",
      "27 Train Loss 2.0770745 Test MSE 2.8076114597038 Test RE 0.8008968092910277\n",
      "28 Train Loss 1.7981274 Test MSE 2.810946610733637 Test RE 0.8013723592516473\n",
      "29 Train Loss 1.5638704 Test MSE 2.796904711660381 Test RE 0.7993682517920082\n",
      "30 Train Loss 1.3547044 Test MSE 2.680947318104162 Test RE 0.782622267130917\n",
      "31 Train Loss 1.1869253 Test MSE 2.7007134152331225 Test RE 0.7855020289009852\n",
      "32 Train Loss 1.0695523 Test MSE 2.7507905980833933 Test RE 0.792751050011048\n",
      "33 Train Loss 1.0000335 Test MSE 2.817336364549939 Test RE 0.802282669215182\n",
      "34 Train Loss 0.9641987 Test MSE 2.8390614251216757 Test RE 0.8053700122547527\n",
      "35 Train Loss 0.9332081 Test MSE 2.8754589995738966 Test RE 0.8105161074198373\n",
      "36 Train Loss 0.89431953 Test MSE 2.9005350214194223 Test RE 0.8140425706319022\n",
      "37 Train Loss 0.8604629 Test MSE 2.906736802424155 Test RE 0.8149123787836217\n",
      "38 Train Loss 0.83877754 Test MSE 2.904843436197649 Test RE 0.8146469301005855\n",
      "39 Train Loss 0.821421 Test MSE 2.90377358224112 Test RE 0.8144968990363404\n",
      "40 Train Loss 0.7929789 Test MSE 2.911634333093104 Test RE 0.8155986085543787\n",
      "41 Train Loss 0.77805185 Test MSE 2.8973767658779948 Test RE 0.813599263678245\n",
      "42 Train Loss 0.750187 Test MSE 2.9151358033545534 Test RE 0.8160888720770003\n",
      "43 Train Loss 0.7345853 Test MSE 2.917614381807385 Test RE 0.8164357359380742\n",
      "44 Train Loss 0.7207413 Test MSE 2.9212297873487043 Test RE 0.8169414286100077\n",
      "45 Train Loss 0.706632 Test MSE 2.918429138250423 Test RE 0.8165497245869985\n",
      "46 Train Loss 0.69211423 Test MSE 2.92635466531471 Test RE 0.8176577177739325\n",
      "47 Train Loss 0.6845052 Test MSE 2.9369444202009314 Test RE 0.8191358324307679\n",
      "48 Train Loss 0.67194307 Test MSE 2.9226486399859324 Test RE 0.8171398003355778\n",
      "49 Train Loss 0.6641752 Test MSE 2.909390072692694 Test RE 0.8152842200867402\n",
      "50 Train Loss 0.65391487 Test MSE 2.9270288129142754 Test RE 0.8177518947121363\n",
      "51 Train Loss 0.6420445 Test MSE 2.9212557331780293 Test RE 0.8169450565642176\n",
      "52 Train Loss 0.63600075 Test MSE 2.9242484501767887 Test RE 0.8173634142378133\n",
      "53 Train Loss 0.62825096 Test MSE 2.9376395807102678 Test RE 0.8192327694356322\n",
      "54 Train Loss 0.62272114 Test MSE 2.930367266855395 Test RE 0.8182181096374839\n",
      "55 Train Loss 0.61494863 Test MSE 2.952733792214399 Test RE 0.8213347681106473\n",
      "56 Train Loss 0.6126355 Test MSE 2.946564477061618 Test RE 0.8204762886663504\n",
      "57 Train Loss 0.6098881 Test MSE 2.954283448999646 Test RE 0.821550266718612\n",
      "58 Train Loss 0.6042452 Test MSE 2.94578551275246 Test RE 0.8203678294766621\n",
      "59 Train Loss 0.59774137 Test MSE 2.9451630896792103 Test RE 0.8202811560174759\n",
      "60 Train Loss 0.5947956 Test MSE 2.9480783389834646 Test RE 0.8206870304173602\n",
      "61 Train Loss 0.5884849 Test MSE 2.984837349961875 Test RE 0.8257876728086717\n",
      "62 Train Loss 0.5829706 Test MSE 3.0072070625977387 Test RE 0.8288763086894448\n",
      "63 Train Loss 0.57785213 Test MSE 3.007052341927199 Test RE 0.8288549855904381\n",
      "64 Train Loss 0.57496893 Test MSE 2.9980468978661325 Test RE 0.8276129380391513\n",
      "65 Train Loss 0.5675992 Test MSE 3.009934606938467 Test RE 0.8292521199377427\n",
      "66 Train Loss 0.5642587 Test MSE 3.000355124517357 Test RE 0.8279314705294165\n",
      "67 Train Loss 0.5570996 Test MSE 3.013922810713132 Test RE 0.8298013231700319\n",
      "68 Train Loss 0.5534723 Test MSE 3.031103440111144 Test RE 0.832163070729165\n",
      "69 Train Loss 0.54796195 Test MSE 3.043987388990907 Test RE 0.8339297833513853\n",
      "70 Train Loss 0.54181874 Test MSE 3.0370713856963567 Test RE 0.832981891644447\n",
      "71 Train Loss 0.5358869 Test MSE 3.0621413290806148 Test RE 0.8364128104693702\n",
      "72 Train Loss 0.5323598 Test MSE 3.06793149298384 Test RE 0.8372032181496266\n",
      "73 Train Loss 0.5262693 Test MSE 3.0594015782067583 Test RE 0.8360385502235632\n",
      "74 Train Loss 0.5234294 Test MSE 3.0738633824668096 Test RE 0.8380121995008908\n",
      "75 Train Loss 0.51839745 Test MSE 3.0689499886735683 Test RE 0.8373421744975297\n",
      "76 Train Loss 0.51446515 Test MSE 3.054710972845336 Test RE 0.8353974066766597\n",
      "77 Train Loss 0.5103642 Test MSE 3.055593598024005 Test RE 0.8355180874117281\n",
      "78 Train Loss 0.5032209 Test MSE 3.063985645335678 Test RE 0.8366646567052952\n",
      "79 Train Loss 0.4997282 Test MSE 3.0783480611914587 Test RE 0.8386232946003623\n",
      "80 Train Loss 0.49583846 Test MSE 3.070535215261044 Test RE 0.8375584057357541\n",
      "81 Train Loss 0.48964483 Test MSE 3.0562032285518805 Test RE 0.8356014315988761\n",
      "82 Train Loss 0.48695138 Test MSE 3.0656624778111876 Test RE 0.8368935668135896\n",
      "83 Train Loss 0.48113254 Test MSE 3.0679246468339874 Test RE 0.837202284031329\n",
      "84 Train Loss 0.4794268 Test MSE 3.07335515508547 Test RE 0.8379429188760599\n",
      "85 Train Loss 0.476699 Test MSE 3.091665873795503 Test RE 0.8404353986984809\n",
      "86 Train Loss 0.47355095 Test MSE 3.0876059614345785 Test RE 0.8398833961354312\n",
      "87 Train Loss 0.47091648 Test MSE 3.0835595724496043 Test RE 0.8393328710441886\n",
      "88 Train Loss 0.46854958 Test MSE 3.092712762005285 Test RE 0.8405776791835525\n",
      "89 Train Loss 0.46511847 Test MSE 3.082506811661158 Test RE 0.8391895801256418\n",
      "90 Train Loss 0.46272856 Test MSE 3.0941370515750606 Test RE 0.8407712128714542\n",
      "91 Train Loss 0.46130896 Test MSE 3.0991352766439535 Test RE 0.8414500237875565\n",
      "92 Train Loss 0.45753133 Test MSE 3.109980540784892 Test RE 0.8429210434629537\n",
      "93 Train Loss 0.45505744 Test MSE 3.1234143521359554 Test RE 0.8447396143714871\n",
      "94 Train Loss 0.45213607 Test MSE 3.1411276924028577 Test RE 0.8471315489527654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.4489764 Test MSE 3.1369547587649884 Test RE 0.8465686621621701\n",
      "96 Train Loss 0.44595945 Test MSE 3.1484132943957692 Test RE 0.8481134078996422\n",
      "97 Train Loss 0.4436071 Test MSE 3.145924591125735 Test RE 0.8477781406257724\n",
      "98 Train Loss 0.43867505 Test MSE 3.152957008792142 Test RE 0.8487251757002819\n",
      "99 Train Loss 0.4361154 Test MSE 3.159546097303915 Test RE 0.8496115510315335\n",
      "Training time: 69.04\n",
      "9\n",
      "KG_rowdy_tune24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 54.56162 Test MSE 8.353316320118587 Test RE 1.3814574854541632\n",
      "1 Train Loss 43.935093 Test MSE 9.1050427674872 Test RE 1.4422782534739584\n",
      "2 Train Loss 36.63607 Test MSE 9.382857592696533 Test RE 1.4641164587207554\n",
      "3 Train Loss 31.614565 Test MSE 8.974079846806868 Test RE 1.4318681370156867\n",
      "4 Train Loss 28.377504 Test MSE 8.755056109934966 Test RE 1.4142869275883247\n",
      "5 Train Loss 26.839539 Test MSE 8.762167651989373 Test RE 1.41486120828054\n",
      "6 Train Loss 25.739574 Test MSE 8.428393803231318 Test RE 1.3876516929069718\n",
      "7 Train Loss 24.747843 Test MSE 8.181923838475795 Test RE 1.3672117324950723\n",
      "8 Train Loss 23.24585 Test MSE 8.134695735549236 Test RE 1.3632600783784055\n",
      "9 Train Loss 22.061117 Test MSE 7.797500353116296 Test RE 1.334706458042902\n",
      "10 Train Loss 20.708992 Test MSE 7.666428764737981 Test RE 1.3234410844219733\n",
      "11 Train Loss 18.545534 Test MSE 7.559223319060525 Test RE 1.3141551705827825\n",
      "12 Train Loss 15.801693 Test MSE 6.9413580281919565 Test RE 1.259303130588506\n",
      "13 Train Loss 12.232392 Test MSE 5.995085951042266 Test RE 1.170323072945312\n",
      "14 Train Loss 10.655102 Test MSE 6.179449778311525 Test RE 1.1881819860285012\n",
      "15 Train Loss 8.268344 Test MSE 5.729076829473763 Test RE 1.1440641672603027\n",
      "16 Train Loss 7.0280266 Test MSE 5.538870698619103 Test RE 1.1249123214707795\n",
      "17 Train Loss 6.0368886 Test MSE 5.483286393022847 Test RE 1.1192536650001752\n",
      "18 Train Loss 5.4354224 Test MSE 5.650153136730341 Test RE 1.1361565319143765\n",
      "19 Train Loss 4.829566 Test MSE 5.723324400286376 Test RE 1.1434896592612644\n",
      "20 Train Loss 4.331882 Test MSE 5.928543573790987 Test RE 1.1638099567152123\n",
      "21 Train Loss 3.9133284 Test MSE 5.887358463953955 Test RE 1.1597604650475948\n",
      "22 Train Loss 3.6220345 Test MSE 5.778476195012587 Test RE 1.148985967029708\n",
      "23 Train Loss 3.2825706 Test MSE 5.6827583435941 Test RE 1.1394300121525085\n",
      "24 Train Loss 3.0743816 Test MSE 5.491428395683711 Test RE 1.120084333441302\n",
      "25 Train Loss 2.9280818 Test MSE 5.465857524216408 Test RE 1.1174734505632227\n",
      "26 Train Loss 2.8063593 Test MSE 5.411354571232638 Test RE 1.1118880328228353\n",
      "27 Train Loss 2.6846812 Test MSE 5.307081827329332 Test RE 1.1011232992684639\n",
      "28 Train Loss 2.5187783 Test MSE 5.422234418842891 Test RE 1.1130052298003101\n",
      "29 Train Loss 2.3751428 Test MSE 5.24276689456282 Test RE 1.094430870091786\n",
      "30 Train Loss 2.2951703 Test MSE 5.236576941548566 Test RE 1.0937846009959151\n",
      "31 Train Loss 2.186022 Test MSE 5.185123798014376 Test RE 1.0883977247341583\n",
      "32 Train Loss 2.1328425 Test MSE 5.2319262837682095 Test RE 1.0932987924384308\n",
      "33 Train Loss 2.071293 Test MSE 5.224334443350774 Test RE 1.0925052832506612\n",
      "34 Train Loss 2.0194747 Test MSE 5.230043411943247 Test RE 1.0931020459036165\n",
      "35 Train Loss 1.9745228 Test MSE 5.290287602204809 Test RE 1.0993796700733531\n",
      "36 Train Loss 1.943504 Test MSE 5.271198718646106 Test RE 1.0973944381595144\n",
      "37 Train Loss 1.912952 Test MSE 5.2679106141801375 Test RE 1.0970521146548253\n",
      "38 Train Loss 1.8784904 Test MSE 5.245010683616066 Test RE 1.09466504122394\n",
      "39 Train Loss 1.8499186 Test MSE 5.283570955295365 Test RE 1.0986815520437199\n",
      "40 Train Loss 1.8235312 Test MSE 5.293274248617187 Test RE 1.0996899551942894\n",
      "41 Train Loss 1.7920928 Test MSE 5.284892560380497 Test RE 1.0988189527098011\n",
      "42 Train Loss 1.7601475 Test MSE 5.281730188228522 Test RE 1.0984901480656644\n",
      "43 Train Loss 1.7346697 Test MSE 5.290064229273065 Test RE 1.099356460158247\n",
      "44 Train Loss 1.7173518 Test MSE 5.281216096236729 Test RE 1.0984366865378634\n",
      "45 Train Loss 1.699859 Test MSE 5.287697776339402 Test RE 1.0991105400503574\n",
      "46 Train Loss 1.6777581 Test MSE 5.310762208869185 Test RE 1.101505039332285\n",
      "47 Train Loss 1.6577448 Test MSE 5.306733135009226 Test RE 1.101087125005716\n",
      "48 Train Loss 1.6262127 Test MSE 5.350347538414451 Test RE 1.105602613928387\n",
      "49 Train Loss 1.607841 Test MSE 5.354708867837537 Test RE 1.1060531374630835\n",
      "50 Train Loss 1.5771859 Test MSE 5.37404310834827 Test RE 1.1080481505675077\n",
      "51 Train Loss 1.5464904 Test MSE 5.416108130936399 Test RE 1.1123762900468972\n",
      "52 Train Loss 1.5248953 Test MSE 5.441772281788334 Test RE 1.115008664928464\n",
      "53 Train Loss 1.503259 Test MSE 5.418928357604265 Test RE 1.1126658655982764\n",
      "54 Train Loss 1.4711306 Test MSE 5.394590494150006 Test RE 1.1101644130620227\n",
      "55 Train Loss 1.4462764 Test MSE 5.4304368599000705 Test RE 1.1138467564760859\n",
      "56 Train Loss 1.4201659 Test MSE 5.394855303482798 Test RE 1.1101916605695195\n",
      "57 Train Loss 1.3915311 Test MSE 5.447372693233488 Test RE 1.115582274145689\n",
      "58 Train Loss 1.3604047 Test MSE 5.450889685189416 Test RE 1.115942343212689\n",
      "59 Train Loss 1.3255694 Test MSE 5.4680576817122155 Test RE 1.1176983347842497\n",
      "60 Train Loss 1.3087786 Test MSE 5.461838624056945 Test RE 1.117062550714175\n",
      "61 Train Loss 1.2922801 Test MSE 5.469642221644918 Test RE 1.1178602669969775\n",
      "62 Train Loss 1.2737744 Test MSE 5.485438238367788 Test RE 1.119473261823157\n",
      "63 Train Loss 1.2485142 Test MSE 5.509550611801036 Test RE 1.121931001541286\n",
      "64 Train Loss 1.2260752 Test MSE 5.555015396560533 Test RE 1.126550575520435\n",
      "65 Train Loss 1.2153618 Test MSE 5.555417399285097 Test RE 1.1265913376223644\n",
      "66 Train Loss 1.1995472 Test MSE 5.558600542394974 Test RE 1.1269140485594817\n",
      "67 Train Loss 1.1795875 Test MSE 5.602083402678821 Test RE 1.131313176427969\n",
      "68 Train Loss 1.1625272 Test MSE 5.641277209965566 Test RE 1.1352637768422564\n",
      "69 Train Loss 1.1419318 Test MSE 5.647144226351461 Test RE 1.1358539694571783\n",
      "70 Train Loss 1.1295059 Test MSE 5.636206187094939 Test RE 1.1347534098903744\n",
      "71 Train Loss 1.1168813 Test MSE 5.63835412734491 Test RE 1.1349696147511052\n",
      "72 Train Loss 1.1024959 Test MSE 5.642826872600915 Test RE 1.135419694995965\n",
      "73 Train Loss 1.0845466 Test MSE 5.634528668968216 Test RE 1.1345845275772222\n",
      "74 Train Loss 1.0694543 Test MSE 5.659168163414944 Test RE 1.1370625603792386\n",
      "75 Train Loss 1.0603714 Test MSE 5.68935841915468 Test RE 1.140091499182477\n",
      "76 Train Loss 1.0498965 Test MSE 5.709209629345339 Test RE 1.1420787609017913\n",
      "77 Train Loss 1.0379524 Test MSE 5.738064902390783 Test RE 1.1449612491571128\n",
      "78 Train Loss 1.0301756 Test MSE 5.74424355105664 Test RE 1.145577520501638\n",
      "79 Train Loss 1.0198503 Test MSE 5.757582250832984 Test RE 1.1469068212224258\n",
      "80 Train Loss 1.0117682 Test MSE 5.7826672204685705 Test RE 1.149402560994465\n",
      "81 Train Loss 1.0029745 Test MSE 5.790713359656494 Test RE 1.1502019359034177\n",
      "82 Train Loss 0.99534094 Test MSE 5.774777263215553 Test RE 1.1486181623580758\n",
      "83 Train Loss 0.9869728 Test MSE 5.815944270914979 Test RE 1.1527050040187623\n",
      "84 Train Loss 0.98020107 Test MSE 5.820756792973198 Test RE 1.1531818200690442\n",
      "85 Train Loss 0.9744221 Test MSE 5.8241766400516335 Test RE 1.1535205325879698\n",
      "86 Train Loss 0.96726954 Test MSE 5.837818487459537 Test RE 1.154870675983393\n",
      "87 Train Loss 0.96286887 Test MSE 5.862837485053018 Test RE 1.1573427308802176\n",
      "88 Train Loss 0.95908654 Test MSE 5.862551305194454 Test RE 1.157314484129241\n",
      "89 Train Loss 0.9521546 Test MSE 5.889152460048529 Test RE 1.1599371527150144\n",
      "90 Train Loss 0.946924 Test MSE 5.9074351403275855 Test RE 1.1617362508727551\n",
      "91 Train Loss 0.9421038 Test MSE 5.940343466419467 Test RE 1.164967577120225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 0.93535787 Test MSE 5.958605835503489 Test RE 1.1667569300096172\n",
      "93 Train Loss 0.9280852 Test MSE 5.969434530556576 Test RE 1.1678166342711538\n",
      "94 Train Loss 0.91875803 Test MSE 5.970983764860824 Test RE 1.1679681648902618\n",
      "95 Train Loss 0.913042 Test MSE 5.980362642593022 Test RE 1.1688850935615702\n",
      "96 Train Loss 0.90824854 Test MSE 5.982049735453565 Test RE 1.1690499563595618\n",
      "97 Train Loss 0.9023309 Test MSE 5.978032817677736 Test RE 1.168657384719853\n",
      "98 Train Loss 0.8976148 Test MSE 5.981065554415784 Test RE 1.1689537849653804\n",
      "99 Train Loss 0.8949466 Test MSE 5.995652119973558 Test RE 1.1703783336142843\n",
      "Training time: 67.91\n",
      "0\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 53.49248 Test MSE 8.445626552320812 Test RE 1.3890695693902593\n",
      "1 Train Loss 38.766785 Test MSE 7.698528485793263 Test RE 1.3262088472969462\n",
      "2 Train Loss 25.339865 Test MSE 6.166280324967622 Test RE 1.1869152022803964\n",
      "3 Train Loss 19.793322 Test MSE 5.955702754104985 Test RE 1.1664726686319695\n",
      "4 Train Loss 17.455563 Test MSE 5.84181489813257 Test RE 1.1552659047740987\n",
      "5 Train Loss 16.133204 Test MSE 5.660184977391987 Test RE 1.1371647069439887\n",
      "6 Train Loss 14.316905 Test MSE 5.813465454502809 Test RE 1.1524593303610007\n",
      "7 Train Loss 13.199072 Test MSE 5.851999534469139 Test RE 1.1562725131295017\n",
      "8 Train Loss 12.260308 Test MSE 5.823784407558732 Test RE 1.153481689685365\n",
      "9 Train Loss 11.41316 Test MSE 5.95358403640631 Test RE 1.1662651661566756\n",
      "10 Train Loss 10.398967 Test MSE 5.869154859714462 Test RE 1.1579660979076938\n",
      "11 Train Loss 9.639012 Test MSE 5.830266879340011 Test RE 1.1541234830928127\n",
      "12 Train Loss 8.788942 Test MSE 5.805145904908848 Test RE 1.1516344028396874\n",
      "13 Train Loss 8.014769 Test MSE 5.688770097631396 Test RE 1.140032550733563\n",
      "14 Train Loss 7.001131 Test MSE 5.5552202270918905 Test RE 1.1265713450241555\n",
      "15 Train Loss 6.2432566 Test MSE 5.471505347069572 Test RE 1.1180506392801763\n",
      "16 Train Loss 5.3047295 Test MSE 5.23569724064314 Test RE 1.093692723828016\n",
      "17 Train Loss 4.605354 Test MSE 5.093769087217347 Test RE 1.078767085207859\n",
      "18 Train Loss 4.0233073 Test MSE 4.907704990027777 Test RE 1.0588813145424878\n",
      "19 Train Loss 3.655654 Test MSE 4.775185713382136 Test RE 1.0444873717237657\n",
      "20 Train Loss 3.3443556 Test MSE 4.593906830332892 Test RE 1.024469779371395\n",
      "21 Train Loss 2.9237523 Test MSE 4.321839861939169 Test RE 0.9936704976728277\n",
      "22 Train Loss 2.6904883 Test MSE 4.166049394699074 Test RE 0.9755965766286419\n",
      "23 Train Loss 2.4932847 Test MSE 4.013279129773704 Test RE 0.9575418046146891\n",
      "24 Train Loss 2.3043087 Test MSE 3.818479265956514 Test RE 0.9340137692593512\n",
      "25 Train Loss 2.176669 Test MSE 3.6612426239372273 Test RE 0.9145812954216098\n",
      "26 Train Loss 2.0726428 Test MSE 3.5156382588518067 Test RE 0.8962107548394616\n",
      "27 Train Loss 1.9809012 Test MSE 3.3639951302438726 Test RE 0.8766691812964863\n",
      "28 Train Loss 1.8911649 Test MSE 3.2627689099554193 Test RE 0.8633784769207197\n",
      "29 Train Loss 1.7816637 Test MSE 3.1585276999011476 Test RE 0.8494746149173588\n",
      "30 Train Loss 1.6840792 Test MSE 2.9296395502178085 Test RE 0.8181165066900195\n",
      "31 Train Loss 1.6105134 Test MSE 2.799227882872382 Test RE 0.7997001693993407\n",
      "32 Train Loss 1.5556252 Test MSE 2.7179976481928616 Test RE 0.788011578184046\n",
      "33 Train Loss 1.5058607 Test MSE 2.61611915396196 Test RE 0.773102042282347\n",
      "34 Train Loss 1.4210879 Test MSE 2.3859990495026286 Test RE 0.7383175527291072\n",
      "35 Train Loss 1.3627285 Test MSE 2.193719305081994 Test RE 0.7079434840522396\n",
      "36 Train Loss 1.3100188 Test MSE 2.0447272678854453 Test RE 0.6834799116260096\n",
      "37 Train Loss 1.2463986 Test MSE 1.8505542335979457 Test RE 0.6502179716166829\n",
      "38 Train Loss 1.1641005 Test MSE 1.6063649610867916 Test RE 0.6058012589491433\n",
      "39 Train Loss 1.0862827 Test MSE 1.4220088661141224 Test RE 0.569979468958808\n",
      "40 Train Loss 0.96689 Test MSE 1.0206759843781357 Test RE 0.48289422143772687\n",
      "41 Train Loss 0.774127 Test MSE 0.7107965782935652 Test RE 0.40297743158598115\n",
      "42 Train Loss 0.6482055 Test MSE 0.6148587195557452 Test RE 0.3747966741711111\n",
      "43 Train Loss 0.49122885 Test MSE 0.4585434757551646 Test RE 0.32366692333144853\n",
      "44 Train Loss 0.40422615 Test MSE 0.40780495245730913 Test RE 0.3052349840119797\n",
      "45 Train Loss 0.3211675 Test MSE 0.3135217682904689 Test RE 0.26763438530365874\n",
      "46 Train Loss 0.23923297 Test MSE 0.243230156303558 Test RE 0.23573103864165504\n",
      "47 Train Loss 0.20786187 Test MSE 0.21406264522029325 Test RE 0.22114570249388166\n",
      "48 Train Loss 0.1538835 Test MSE 0.15696598373616408 Test RE 0.1893698492177051\n",
      "49 Train Loss 0.12458796 Test MSE 0.15406095334351988 Test RE 0.18760929470407184\n",
      "50 Train Loss 0.105388656 Test MSE 0.14523211182223073 Test RE 0.18215428268327563\n",
      "51 Train Loss 0.088284 Test MSE 0.13986268245140127 Test RE 0.17875532457745863\n",
      "52 Train Loss 0.073528856 Test MSE 0.1268101794272031 Test RE 0.1702100184550013\n",
      "53 Train Loss 0.059237942 Test MSE 0.10427532541556604 Test RE 0.15434722907501558\n",
      "54 Train Loss 0.053120993 Test MSE 0.1012047954420035 Test RE 0.15205776612081204\n",
      "55 Train Loss 0.042007625 Test MSE 0.08745307214908844 Test RE 0.14134992927076936\n",
      "56 Train Loss 0.036330663 Test MSE 0.07479036999140265 Test RE 0.13071664755556428\n",
      "57 Train Loss 0.032006867 Test MSE 0.0646215937977488 Test RE 0.12150576743819826\n",
      "58 Train Loss 0.028569747 Test MSE 0.0606590030896891 Test RE 0.11772147488283609\n",
      "59 Train Loss 0.026390254 Test MSE 0.0593953027119163 Test RE 0.11648878360662535\n",
      "60 Train Loss 0.023772435 Test MSE 0.05707648888858468 Test RE 0.11419226438107648\n",
      "61 Train Loss 0.02113155 Test MSE 0.051276301555533234 Test RE 0.10823467234447427\n",
      "62 Train Loss 0.019340135 Test MSE 0.047050317990302126 Test RE 0.10367865194461068\n",
      "63 Train Loss 0.017934076 Test MSE 0.04588146872013937 Test RE 0.1023827324671866\n",
      "64 Train Loss 0.016471205 Test MSE 0.04355449257038346 Test RE 0.0997526724210388\n",
      "65 Train Loss 0.015286259 Test MSE 0.04000586742748387 Test RE 0.09560264458320837\n",
      "66 Train Loss 0.014215585 Test MSE 0.03835946509959805 Test RE 0.09361476071572579\n",
      "67 Train Loss 0.012840283 Test MSE 0.03711682495921377 Test RE 0.09208597053381741\n",
      "68 Train Loss 0.012031866 Test MSE 0.03526500324943887 Test RE 0.08975941726063308\n",
      "69 Train Loss 0.011377863 Test MSE 0.035346448775472154 Test RE 0.08986300844446504\n",
      "70 Train Loss 0.010248743 Test MSE 0.03409279723369081 Test RE 0.08825501194133115\n",
      "71 Train Loss 0.009653032 Test MSE 0.03104492562324281 Test RE 0.08421769913632261\n",
      "72 Train Loss 0.0087396735 Test MSE 0.02643763609810616 Test RE 0.0777175981785426\n",
      "73 Train Loss 0.008169576 Test MSE 0.02542508141562086 Test RE 0.07621478633169253\n",
      "74 Train Loss 0.0076528927 Test MSE 0.024190117699870138 Test RE 0.07434076930506862\n",
      "75 Train Loss 0.0071422504 Test MSE 0.021278834250884393 Test RE 0.0697239489320182\n",
      "76 Train Loss 0.006860979 Test MSE 0.020554493136813286 Test RE 0.06852695686576417\n",
      "77 Train Loss 0.006507218 Test MSE 0.019539169139231236 Test RE 0.06681302058606704\n",
      "78 Train Loss 0.006247526 Test MSE 0.018439300384718225 Test RE 0.06490531767641357\n",
      "79 Train Loss 0.005933854 Test MSE 0.017045998472880276 Test RE 0.06240498496306144\n",
      "80 Train Loss 0.0056645013 Test MSE 0.015590296100043184 Test RE 0.059680883281265716\n",
      "81 Train Loss 0.0053915177 Test MSE 0.014995735859127887 Test RE 0.05853180960987541\n",
      "82 Train Loss 0.0051271254 Test MSE 0.014432892535963096 Test RE 0.05742285076041793\n",
      "83 Train Loss 0.0048647313 Test MSE 0.013703578865410817 Test RE 0.05595321712152016\n",
      "84 Train Loss 0.0046763606 Test MSE 0.013664168868451116 Test RE 0.05587270151897281\n",
      "85 Train Loss 0.004411908 Test MSE 0.01317492161965734 Test RE 0.05486331941933991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.004210287 Test MSE 0.011936390105388349 Test RE 0.05222092523672139\n",
      "87 Train Loss 0.003941464 Test MSE 0.010820229612740814 Test RE 0.04971944804550771\n",
      "88 Train Loss 0.0037432453 Test MSE 0.010154411733639674 Test RE 0.04816543032028963\n",
      "89 Train Loss 0.0035827637 Test MSE 0.00941685902236089 Test RE 0.04638324134543628\n",
      "90 Train Loss 0.0033596149 Test MSE 0.008986458199738845 Test RE 0.04531086358748444\n",
      "91 Train Loss 0.003241787 Test MSE 0.008572774005473687 Test RE 0.04425565244801158\n",
      "92 Train Loss 0.0030589248 Test MSE 0.007534031858038745 Test RE 0.04148793188820159\n",
      "93 Train Loss 0.0028017152 Test MSE 0.007128875822658158 Test RE 0.04035697308742444\n",
      "94 Train Loss 0.0026949772 Test MSE 0.007228224574254064 Test RE 0.04063720959209786\n",
      "95 Train Loss 0.0026100883 Test MSE 0.00680314383589845 Test RE 0.03942419977456532\n",
      "96 Train Loss 0.0025078761 Test MSE 0.006143530803721522 Test RE 0.03746425323687789\n",
      "97 Train Loss 0.0024163756 Test MSE 0.0059633116598404945 Test RE 0.036910660263372114\n",
      "98 Train Loss 0.00230616 Test MSE 0.00602691275798389 Test RE 0.03710697167606765\n",
      "99 Train Loss 0.0022493512 Test MSE 0.005728002982897818 Test RE 0.036175094809277164\n",
      "Training time: 156.28\n",
      "1\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.296864 Test MSE 8.655352819490272 Test RE 1.4062108617982876\n",
      "1 Train Loss 50.883175 Test MSE 9.099903769895443 Test RE 1.4418711762755008\n",
      "2 Train Loss 43.32389 Test MSE 8.828908831938008 Test RE 1.4202394648445933\n",
      "3 Train Loss 40.20378 Test MSE 9.089039499830447 Test RE 1.4410102025456382\n",
      "4 Train Loss 38.529762 Test MSE 9.302795688056257 Test RE 1.4578565812343358\n",
      "5 Train Loss 36.637863 Test MSE 9.107494705398338 Test RE 1.4424724391998665\n",
      "6 Train Loss 33.89132 Test MSE 9.09452334211321 Test RE 1.4414448513930553\n",
      "7 Train Loss 31.232868 Test MSE 8.8699137514646 Test RE 1.4235337192079318\n",
      "8 Train Loss 28.888615 Test MSE 8.89831249221813 Test RE 1.4258107570412368\n",
      "9 Train Loss 26.760206 Test MSE 9.090364314357418 Test RE 1.441115219235718\n",
      "10 Train Loss 24.926683 Test MSE 8.9536743489852 Test RE 1.4302393009281338\n",
      "11 Train Loss 22.838112 Test MSE 9.230211022440056 Test RE 1.4521580119337338\n",
      "12 Train Loss 21.1912 Test MSE 8.937865080719417 Test RE 1.4289760750355536\n",
      "13 Train Loss 18.771523 Test MSE 8.875202031806872 Test RE 1.423958014407747\n",
      "14 Train Loss 16.90153 Test MSE 8.854174968709081 Test RE 1.4222701987199224\n",
      "15 Train Loss 15.498131 Test MSE 8.725101245728052 Test RE 1.4118654084371483\n",
      "16 Train Loss 13.860197 Test MSE 8.412005806383904 Test RE 1.3863019756855262\n",
      "17 Train Loss 12.530605 Test MSE 8.276350921485331 Test RE 1.3750785535088415\n",
      "18 Train Loss 11.293129 Test MSE 8.0753296291909 Test RE 1.3582765089938207\n",
      "19 Train Loss 10.032787 Test MSE 7.795322064840683 Test RE 1.3345200150563845\n",
      "20 Train Loss 9.019607 Test MSE 7.660707352674301 Test RE 1.3229471539837014\n",
      "21 Train Loss 7.5394754 Test MSE 7.241546060998502 Test RE 1.2862450279697137\n",
      "22 Train Loss 6.0434585 Test MSE 6.116186049508733 Test RE 1.1820841774118336\n",
      "23 Train Loss 5.0782967 Test MSE 5.773207508071015 Test RE 1.1484620375644723\n",
      "24 Train Loss 4.403243 Test MSE 5.49573690117429 Test RE 1.1205236493115114\n",
      "25 Train Loss 3.968278 Test MSE 5.434835410382315 Test RE 1.1142977625027277\n",
      "26 Train Loss 3.487267 Test MSE 5.475766873717467 Test RE 1.1184859559722484\n",
      "27 Train Loss 3.0794854 Test MSE 5.466289590615695 Test RE 1.11751761684333\n",
      "28 Train Loss 2.7144723 Test MSE 5.340152242460896 Test RE 1.1045487271779977\n",
      "29 Train Loss 2.4311385 Test MSE 5.268913542950971 Test RE 1.097156540569205\n",
      "30 Train Loss 2.187276 Test MSE 5.193963545350631 Test RE 1.0893250954341431\n",
      "31 Train Loss 2.0124674 Test MSE 5.141910640321188 Test RE 1.0838528470163462\n",
      "32 Train Loss 1.8529571 Test MSE 5.123747945305429 Test RE 1.081936914912721\n",
      "33 Train Loss 1.7415731 Test MSE 5.0837001791156915 Test RE 1.0777003525457467\n",
      "34 Train Loss 1.6712186 Test MSE 5.084926141812954 Test RE 1.0778302914425328\n",
      "35 Train Loss 1.6110325 Test MSE 5.083868033102294 Test RE 1.077718144193659\n",
      "36 Train Loss 1.549222 Test MSE 5.095193230356452 Test RE 1.0789178783974158\n",
      "37 Train Loss 1.5081933 Test MSE 5.138328473855751 Test RE 1.0834752424610838\n",
      "38 Train Loss 1.4613209 Test MSE 5.178110017753747 Test RE 1.0876613521781264\n",
      "39 Train Loss 1.4276581 Test MSE 5.197095867782245 Test RE 1.0896535154471834\n",
      "40 Train Loss 1.3978382 Test MSE 5.2217735818752535 Test RE 1.0922374886007824\n",
      "41 Train Loss 1.3686616 Test MSE 5.23743404908499 Test RE 1.093874111059158\n",
      "42 Train Loss 1.3502775 Test MSE 5.275343293610696 Test RE 1.0978257764637656\n",
      "43 Train Loss 1.3257926 Test MSE 5.3213176165758025 Test RE 1.1025991443616596\n",
      "44 Train Loss 1.3027318 Test MSE 5.333878274233949 Test RE 1.103899687606662\n",
      "45 Train Loss 1.2775806 Test MSE 5.371608900725328 Test RE 1.1077971733516352\n",
      "46 Train Loss 1.2524686 Test MSE 5.356195683283385 Test RE 1.1062066829489645\n",
      "47 Train Loss 1.2324492 Test MSE 5.403488887354397 Test RE 1.1110796455628174\n",
      "48 Train Loss 1.2083918 Test MSE 5.466318409977579 Test RE 1.1175205627266054\n",
      "49 Train Loss 1.1946272 Test MSE 5.455623218720168 Test RE 1.1164267782782458\n",
      "50 Train Loss 1.1757127 Test MSE 5.461607627338162 Test RE 1.1170389285852544\n",
      "51 Train Loss 1.1639646 Test MSE 5.486486219165868 Test RE 1.1195801931569047\n",
      "52 Train Loss 1.1531538 Test MSE 5.5024744535438845 Test RE 1.1212102973852067\n",
      "53 Train Loss 1.1431023 Test MSE 5.513031328413064 Test RE 1.1222853414474496\n",
      "54 Train Loss 1.1333311 Test MSE 5.556469672923802 Test RE 1.1266980286366985\n",
      "55 Train Loss 1.1210632 Test MSE 5.606807888351545 Test RE 1.1317901192090791\n",
      "56 Train Loss 1.1124498 Test MSE 5.622937134560484 Test RE 1.1334168747626767\n",
      "57 Train Loss 1.1019614 Test MSE 5.639187312850977 Test RE 1.1350534694788763\n",
      "58 Train Loss 1.0926173 Test MSE 5.6365331826293525 Test RE 1.1347863268830825\n",
      "59 Train Loss 1.0847623 Test MSE 5.629198748044749 Test RE 1.134047776685828\n",
      "60 Train Loss 1.075382 Test MSE 5.6766221573309785 Test RE 1.1388146733687599\n",
      "61 Train Loss 1.0675914 Test MSE 5.73126898464541 Test RE 1.1442830268070932\n",
      "62 Train Loss 1.0544267 Test MSE 5.7769806922457985 Test RE 1.1488372753308658\n",
      "63 Train Loss 1.0471388 Test MSE 5.797945643119091 Test RE 1.1509199813478488\n",
      "64 Train Loss 1.0381184 Test MSE 5.798634106483242 Test RE 1.1509883109572034\n",
      "65 Train Loss 1.0283473 Test MSE 5.807422770891102 Test RE 1.15186022491037\n",
      "66 Train Loss 1.0193598 Test MSE 5.83672161758203 Test RE 1.1547621763471505\n",
      "67 Train Loss 1.0128553 Test MSE 5.8486582001347065 Test RE 1.1559423657439398\n",
      "68 Train Loss 1.0047054 Test MSE 5.868280885620389 Test RE 1.157879878505263\n",
      "69 Train Loss 0.9962969 Test MSE 5.893533363392029 Test RE 1.1603685074726766\n",
      "70 Train Loss 0.99037516 Test MSE 5.895537492793234 Test RE 1.1605657856443594\n",
      "71 Train Loss 0.9840127 Test MSE 5.9028895781513295 Test RE 1.1612892074044174\n",
      "72 Train Loss 0.97727513 Test MSE 5.927486815058298 Test RE 1.1637062279384711\n",
      "73 Train Loss 0.9690002 Test MSE 5.940761112402057 Test RE 1.1650085289170071\n",
      "74 Train Loss 0.9605868 Test MSE 5.952171112980435 Test RE 1.1661267670727435\n",
      "75 Train Loss 0.9534199 Test MSE 5.98252005031198 Test RE 1.169095911406959\n",
      "76 Train Loss 0.9457016 Test MSE 6.036954285875476 Test RE 1.1744025995588798\n",
      "77 Train Loss 0.9359026 Test MSE 6.075340967358037 Test RE 1.1781304712189264\n",
      "78 Train Loss 0.9279234 Test MSE 6.075975769669858 Test RE 1.178192020061667\n",
      "79 Train Loss 0.9193951 Test MSE 6.097815057213521 Test RE 1.1803075481011718\n",
      "80 Train Loss 0.91230875 Test MSE 6.12688800937474 Test RE 1.1831179170839032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 0.90517604 Test MSE 6.131890734087852 Test RE 1.183600838064292\n",
      "82 Train Loss 0.89820874 Test MSE 6.129914984897069 Test RE 1.183410139395563\n",
      "83 Train Loss 0.89096963 Test MSE 6.147485932678005 Test RE 1.1851050045181468\n",
      "84 Train Loss 0.8811855 Test MSE 6.1870231647979255 Test RE 1.1889098668513645\n",
      "85 Train Loss 0.8765094 Test MSE 6.180390776803603 Test RE 1.1882724499804445\n",
      "86 Train Loss 0.86977124 Test MSE 6.181032165542455 Test RE 1.1883341066639124\n",
      "87 Train Loss 0.865232 Test MSE 6.2119269448044365 Test RE 1.1913002421728252\n",
      "88 Train Loss 0.861118 Test MSE 6.22160092856553 Test RE 1.1922275016124637\n",
      "89 Train Loss 0.85573727 Test MSE 6.216363775328172 Test RE 1.1917256056598673\n",
      "90 Train Loss 0.85006607 Test MSE 6.227395057583775 Test RE 1.1927825285635698\n",
      "91 Train Loss 0.84603906 Test MSE 6.2402120734757744 Test RE 1.1940093701482322\n",
      "92 Train Loss 0.84281 Test MSE 6.243735363850352 Test RE 1.1943463978030708\n",
      "93 Train Loss 0.84031016 Test MSE 6.246186926309165 Test RE 1.1945808509998304\n",
      "94 Train Loss 0.8373631 Test MSE 6.252505533385209 Test RE 1.195184913860222\n",
      "95 Train Loss 0.8338181 Test MSE 6.265418833523731 Test RE 1.196418485010399\n",
      "96 Train Loss 0.82910234 Test MSE 6.286816382560518 Test RE 1.198459737446653\n",
      "97 Train Loss 0.8247663 Test MSE 6.311875298466664 Test RE 1.2008458604742966\n",
      "98 Train Loss 0.8197967 Test MSE 6.3269124298978685 Test RE 1.2022754304718968\n",
      "99 Train Loss 0.815279 Test MSE 6.317495865291695 Test RE 1.201380403078858\n",
      "Training time: 156.64\n",
      "2\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 54.307137 Test MSE 8.279504331052996 Test RE 1.3753404909828149\n",
      "1 Train Loss 44.30133 Test MSE 7.846355325874152 Test RE 1.3388812079812986\n",
      "2 Train Loss 37.10021 Test MSE 7.448559311623663 Test RE 1.3045003514608504\n",
      "3 Train Loss 31.043743 Test MSE 6.7860421475266115 Test RE 1.245134700595894\n",
      "4 Train Loss 23.616467 Test MSE 5.9389638885161515 Test RE 1.1648322939620366\n",
      "5 Train Loss 18.188164 Test MSE 5.877688044139479 Test RE 1.1588075776062836\n",
      "6 Train Loss 14.578702 Test MSE 6.084434517068793 Test RE 1.1790118523726851\n",
      "7 Train Loss 12.42485 Test MSE 5.896649417851979 Test RE 1.1606752244648189\n",
      "8 Train Loss 10.994299 Test MSE 6.01613025741209 Test RE 1.1723753422642786\n",
      "9 Train Loss 9.999916 Test MSE 5.774569162160066 Test RE 1.148597466252018\n",
      "10 Train Loss 9.18615 Test MSE 5.875212973597407 Test RE 1.1585635673355072\n",
      "11 Train Loss 8.268057 Test MSE 5.682661911250764 Test RE 1.1394203444554472\n",
      "12 Train Loss 7.3310137 Test MSE 5.512391368519914 Test RE 1.1222202013812563\n",
      "13 Train Loss 6.191886 Test MSE 5.372489697567337 Test RE 1.1078879938371127\n",
      "14 Train Loss 5.1460457 Test MSE 5.3688986167836585 Test RE 1.1075176645706601\n",
      "15 Train Loss 4.6700506 Test MSE 5.261219470310606 Test RE 1.0963551717411315\n",
      "16 Train Loss 4.2668695 Test MSE 5.111577367401245 Test RE 1.0806511738488922\n",
      "17 Train Loss 3.7279825 Test MSE 4.872552026257161 Test RE 1.055082215843942\n",
      "18 Train Loss 3.3649824 Test MSE 4.70497368875857 Test RE 1.03678011692484\n",
      "19 Train Loss 3.0825386 Test MSE 4.636428876151314 Test RE 1.029200198447767\n",
      "20 Train Loss 2.8143933 Test MSE 4.565978597024831 Test RE 1.0213509471655426\n",
      "21 Train Loss 2.5973191 Test MSE 4.365101515807597 Test RE 0.9986314388974342\n",
      "22 Train Loss 2.4332879 Test MSE 4.23411297138115 Test RE 0.9835337808281057\n",
      "23 Train Loss 2.2701159 Test MSE 4.132426462742758 Test RE 0.9716517277750518\n",
      "24 Train Loss 2.0976782 Test MSE 3.9398297158488216 Test RE 0.9487390709016964\n",
      "25 Train Loss 1.954303 Test MSE 3.5892894562494373 Test RE 0.9055497226010427\n",
      "26 Train Loss 1.8439022 Test MSE 3.3740603296229743 Test RE 0.8779797152436531\n",
      "27 Train Loss 1.7194787 Test MSE 3.049289710999546 Test RE 0.8346557785324489\n",
      "28 Train Loss 1.5989515 Test MSE 2.6696631783049223 Test RE 0.7809734970678575\n",
      "29 Train Loss 1.4908369 Test MSE 2.4484631334596103 Test RE 0.747919480117712\n",
      "30 Train Loss 1.4167849 Test MSE 2.160704946223156 Test RE 0.7025961947554398\n",
      "31 Train Loss 1.3064717 Test MSE 1.790458604960343 Test RE 0.6395731195530749\n",
      "32 Train Loss 1.139683 Test MSE 1.3606431752471555 Test RE 0.5575453320449769\n",
      "33 Train Loss 0.8371584 Test MSE 0.8413592990452038 Test RE 0.43842853246887514\n",
      "34 Train Loss 0.6234495 Test MSE 0.7450666746403074 Test RE 0.4125775852013016\n",
      "35 Train Loss 0.46620333 Test MSE 0.5898633711433292 Test RE 0.3670994844189953\n",
      "36 Train Loss 0.3531477 Test MSE 0.44865123295950055 Test RE 0.3201566249772237\n",
      "37 Train Loss 0.2653189 Test MSE 0.3297120401395993 Test RE 0.2744577278253735\n",
      "38 Train Loss 0.20043236 Test MSE 0.2730209380650085 Test RE 0.24975031090269723\n",
      "39 Train Loss 0.15327816 Test MSE 0.24066561068713738 Test RE 0.23448500690460614\n",
      "40 Train Loss 0.12698306 Test MSE 0.2015782434658214 Test RE 0.21460008444278106\n",
      "41 Train Loss 0.10139749 Test MSE 0.20143141479159835 Test RE 0.21452191334338586\n",
      "42 Train Loss 0.088674955 Test MSE 0.19845261083284998 Test RE 0.21292981104434291\n",
      "43 Train Loss 0.07451207 Test MSE 0.18653025289831762 Test RE 0.20643469968118477\n",
      "44 Train Loss 0.068324 Test MSE 0.18452607458342032 Test RE 0.2053226835582042\n",
      "45 Train Loss 0.05979202 Test MSE 0.18157670608321164 Test RE 0.20367518854140468\n",
      "46 Train Loss 0.05367487 Test MSE 0.1732229384362154 Test RE 0.19893479970007433\n",
      "47 Train Loss 0.045716505 Test MSE 0.14919185530133136 Test RE 0.1846207953757566\n",
      "48 Train Loss 0.03950216 Test MSE 0.129348378647336 Test RE 0.17190501830469657\n",
      "49 Train Loss 0.035316877 Test MSE 0.12445811350196981 Test RE 0.16862410871975483\n",
      "50 Train Loss 0.03097468 Test MSE 0.10624591563252966 Test RE 0.15579882647216042\n",
      "51 Train Loss 0.027375136 Test MSE 0.09387046912471524 Test RE 0.14644432764027532\n",
      "52 Train Loss 0.022812828 Test MSE 0.08489501005925044 Test RE 0.1392672956425928\n",
      "53 Train Loss 0.020688318 Test MSE 0.07511791010216717 Test RE 0.1310025678631821\n",
      "54 Train Loss 0.019084543 Test MSE 0.06729713849956076 Test RE 0.12399562425800235\n",
      "55 Train Loss 0.017171582 Test MSE 0.06335647298647341 Test RE 0.12031050686296665\n",
      "56 Train Loss 0.015881222 Test MSE 0.05987533642925875 Test RE 0.11695856835326887\n",
      "57 Train Loss 0.014147113 Test MSE 0.059650464881372586 Test RE 0.1167387333055766\n",
      "58 Train Loss 0.012765004 Test MSE 0.06113825288083287 Test RE 0.11818560214955555\n",
      "59 Train Loss 0.011406222 Test MSE 0.058398072327230516 Test RE 0.11550673717199574\n",
      "60 Train Loss 0.01044079 Test MSE 0.05481621816999346 Test RE 0.11190837646796231\n",
      "61 Train Loss 0.009491074 Test MSE 0.05217314634346799 Test RE 0.10917710503583142\n",
      "62 Train Loss 0.008761181 Test MSE 0.05267407358349327 Test RE 0.10969997114251327\n",
      "63 Train Loss 0.008113936 Test MSE 0.05273018547376315 Test RE 0.1097583854049159\n",
      "64 Train Loss 0.007523124 Test MSE 0.05024148383300239 Test RE 0.10713695255452121\n",
      "65 Train Loss 0.007004588 Test MSE 0.04808062227959511 Test RE 0.1048076782054521\n",
      "66 Train Loss 0.0065592914 Test MSE 0.04605818936323524 Test RE 0.10257971562901756\n",
      "67 Train Loss 0.005982265 Test MSE 0.044343256617993695 Test RE 0.10065187110783337\n",
      "68 Train Loss 0.0055798506 Test MSE 0.0417261041684326 Test RE 0.09763644974998321\n",
      "69 Train Loss 0.005092867 Test MSE 0.03686445787357984 Test RE 0.09177237817073089\n",
      "70 Train Loss 0.0048496677 Test MSE 0.034646437696616954 Test RE 0.08896872239878463\n",
      "71 Train Loss 0.0046067014 Test MSE 0.03288972519118224 Test RE 0.0866838481466225\n",
      "72 Train Loss 0.004422941 Test MSE 0.03197319746251597 Test RE 0.0854675186067186\n",
      "73 Train Loss 0.0041930927 Test MSE 0.030891759370459758 Test RE 0.08400968995566147\n",
      "74 Train Loss 0.00398824 Test MSE 0.029592001455003746 Test RE 0.08222336192423532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Train Loss 0.003859539 Test MSE 0.029031785019461864 Test RE 0.08144134359363313\n",
      "76 Train Loss 0.0036726925 Test MSE 0.0290091821937886 Test RE 0.08140963415995915\n",
      "77 Train Loss 0.0034746323 Test MSE 0.028589699780218237 Test RE 0.08081888559791456\n",
      "78 Train Loss 0.0032418454 Test MSE 0.02715370714069518 Test RE 0.07876306810698681\n",
      "79 Train Loss 0.003075602 Test MSE 0.025773334849859872 Test RE 0.07673497719332953\n",
      "80 Train Loss 0.0029811375 Test MSE 0.02528272334879687 Test RE 0.07600111897991306\n",
      "81 Train Loss 0.0028632106 Test MSE 0.025030850949505946 Test RE 0.07562160094672198\n",
      "82 Train Loss 0.0027574375 Test MSE 0.024785637391945666 Test RE 0.07525027756167406\n",
      "83 Train Loss 0.0025817158 Test MSE 0.023762280678593636 Test RE 0.07368042478353144\n",
      "84 Train Loss 0.0024437623 Test MSE 0.02307948369030472 Test RE 0.07261412438263995\n",
      "85 Train Loss 0.0023614937 Test MSE 0.022887244782806064 Test RE 0.07231107493000365\n",
      "86 Train Loss 0.0022787955 Test MSE 0.022844064100078935 Test RE 0.07224282915033095\n",
      "87 Train Loss 0.0021984095 Test MSE 0.023004500733038745 Test RE 0.07249607036811015\n",
      "88 Train Loss 0.002132732 Test MSE 0.023200701277635693 Test RE 0.07280456585373175\n",
      "89 Train Loss 0.0020537404 Test MSE 0.023249815603973763 Test RE 0.07288158630151277\n",
      "90 Train Loss 0.0019766323 Test MSE 0.023361666962798285 Test RE 0.07305668712202937\n",
      "91 Train Loss 0.0019071572 Test MSE 0.023450584752508555 Test RE 0.07319558709176459\n",
      "92 Train Loss 0.0018499189 Test MSE 0.023369936011024824 Test RE 0.07306961547646106\n",
      "93 Train Loss 0.0018122022 Test MSE 0.023079511296361193 Test RE 0.07261416781058322\n",
      "94 Train Loss 0.0017605778 Test MSE 0.02226828853875492 Test RE 0.07132659305823777\n",
      "95 Train Loss 0.0017103915 Test MSE 0.021126891677780438 Test RE 0.06947456929692543\n",
      "96 Train Loss 0.0016643892 Test MSE 0.020224420017030818 Test RE 0.06797451198452406\n",
      "97 Train Loss 0.0016329195 Test MSE 0.020127208850405833 Test RE 0.06781095127066275\n",
      "98 Train Loss 0.0015953911 Test MSE 0.020582671254648213 Test RE 0.06857391251964938\n",
      "99 Train Loss 0.0015647315 Test MSE 0.02040363339341733 Test RE 0.06827501686754964\n",
      "Training time: 157.33\n",
      "3\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.550232 Test MSE 8.866783500653437 Test RE 1.4232825098437267\n",
      "1 Train Loss 47.888313 Test MSE 8.551850354516985 Test RE 1.3977776972148612\n",
      "2 Train Loss 43.932293 Test MSE 8.870337499867519 Test RE 1.42356772252254\n",
      "3 Train Loss 40.343895 Test MSE 9.15767084361359 Test RE 1.4464405053058982\n",
      "4 Train Loss 37.725372 Test MSE 9.202875639762643 Test RE 1.4500061256988277\n",
      "5 Train Loss 34.4615 Test MSE 9.331569955107922 Test RE 1.4601094721060826\n",
      "6 Train Loss 31.720726 Test MSE 9.332782788478825 Test RE 1.4602043549588493\n",
      "7 Train Loss 28.68188 Test MSE 9.22939424376092 Test RE 1.4520937599929928\n",
      "8 Train Loss 26.549925 Test MSE 9.26151065072755 Test RE 1.4546180607426789\n",
      "9 Train Loss 23.947433 Test MSE 9.223611999315247 Test RE 1.4516388180783197\n",
      "10 Train Loss 21.209637 Test MSE 9.057678113909107 Test RE 1.4385219787972976\n",
      "11 Train Loss 19.122723 Test MSE 9.157007706990967 Test RE 1.4463881336355802\n",
      "12 Train Loss 17.765467 Test MSE 8.953388230640941 Test RE 1.4302164488031879\n",
      "13 Train Loss 16.1811 Test MSE 8.804005544310117 Test RE 1.4182350490972626\n",
      "14 Train Loss 14.95047 Test MSE 8.816839580714355 Test RE 1.4192683885025676\n",
      "15 Train Loss 14.159273 Test MSE 9.052485019172117 Test RE 1.438109541311102\n",
      "16 Train Loss 13.039655 Test MSE 9.125475725714837 Test RE 1.4438956811402757\n",
      "17 Train Loss 12.048895 Test MSE 9.119948222748052 Test RE 1.4434583150864204\n",
      "18 Train Loss 11.132709 Test MSE 8.942470432260476 Test RE 1.4293441769032686\n",
      "19 Train Loss 10.330149 Test MSE 8.587560884948589 Test RE 1.4006930535818134\n",
      "20 Train Loss 9.322208 Test MSE 8.362004112155198 Test RE 1.3821756850235158\n",
      "21 Train Loss 8.372465 Test MSE 8.315468230359787 Test RE 1.3783243054897985\n",
      "22 Train Loss 7.486521 Test MSE 8.115455193202283 Test RE 1.361646902391304\n",
      "23 Train Loss 7.1838512 Test MSE 8.108854754801 Test RE 1.361093064408833\n",
      "24 Train Loss 6.9086504 Test MSE 7.9848866661845905 Test RE 1.350648804300713\n",
      "25 Train Loss 6.6899157 Test MSE 7.876663110771112 Test RE 1.341464535668547\n",
      "26 Train Loss 6.5162306 Test MSE 7.947369803537761 Test RE 1.3474720675130727\n",
      "27 Train Loss 6.3437576 Test MSE 8.113569530253793 Test RE 1.3614887007736642\n",
      "28 Train Loss 6.2148457 Test MSE 8.126738579184613 Test RE 1.3625931617541611\n",
      "29 Train Loss 6.0974216 Test MSE 8.112326899605835 Test RE 1.3613844376399795\n",
      "30 Train Loss 5.9859858 Test MSE 8.099519252024555 Test RE 1.3603093441591239\n",
      "31 Train Loss 5.863165 Test MSE 8.093338041032544 Test RE 1.3597901797712433\n",
      "32 Train Loss 5.76357 Test MSE 8.065965481093084 Test RE 1.3574887521852572\n",
      "33 Train Loss 5.629525 Test MSE 7.940687364265469 Test RE 1.3469054464743904\n",
      "34 Train Loss 5.4930506 Test MSE 7.821085939210197 Test RE 1.3367235188848936\n",
      "35 Train Loss 5.3213687 Test MSE 7.585143265881579 Test RE 1.316406306777665\n",
      "36 Train Loss 5.1327314 Test MSE 7.332339401616452 Test RE 1.2942832775972175\n",
      "37 Train Loss 4.9186034 Test MSE 7.178767012361326 Test RE 1.2806574772704813\n",
      "38 Train Loss 4.533086 Test MSE 6.73087539422153 Test RE 1.2400632457864964\n",
      "39 Train Loss 4.28307 Test MSE 6.661688909264497 Test RE 1.233673495180936\n",
      "40 Train Loss 4.097984 Test MSE 6.693661360298519 Test RE 1.2366304293997248\n",
      "41 Train Loss 3.8110552 Test MSE 6.599965893405824 Test RE 1.2279449740834674\n",
      "42 Train Loss 3.5225356 Test MSE 6.555126604363788 Test RE 1.2237666179054125\n",
      "43 Train Loss 3.226438 Test MSE 6.441792115612689 Test RE 1.2131413698224345\n",
      "44 Train Loss 2.967908 Test MSE 6.398906118894999 Test RE 1.209096404003317\n",
      "45 Train Loss 2.7874618 Test MSE 6.378659398187889 Test RE 1.2071820430278042\n",
      "46 Train Loss 2.4855425 Test MSE 6.306309290602821 Test RE 1.2003162720906428\n",
      "47 Train Loss 2.2318616 Test MSE 6.222790203170826 Test RE 1.192341444804582\n",
      "48 Train Loss 2.013149 Test MSE 6.129378961393004 Test RE 1.1833583972817638\n",
      "49 Train Loss 1.7310253 Test MSE 6.14388602745981 Test RE 1.1847579609876706\n",
      "50 Train Loss 1.6027352 Test MSE 6.098697883233221 Test RE 1.1803929859582496\n",
      "51 Train Loss 1.4582435 Test MSE 5.88071663588979 Test RE 1.1591060880978572\n",
      "52 Train Loss 1.3215189 Test MSE 5.921061369504672 Test RE 1.1630753232470843\n",
      "53 Train Loss 1.2507743 Test MSE 5.970290989094369 Test RE 1.1679004069173964\n",
      "54 Train Loss 1.2015061 Test MSE 5.912501968557354 Test RE 1.1622343567557367\n",
      "55 Train Loss 1.1548101 Test MSE 5.844052451081072 Test RE 1.1554871306429428\n",
      "56 Train Loss 1.1141198 Test MSE 5.88025730041155 Test RE 1.159060819044839\n",
      "57 Train Loss 1.0763485 Test MSE 5.911543605290979 Test RE 1.1621401590827396\n",
      "58 Train Loss 1.0557154 Test MSE 5.923893246440384 Test RE 1.1633534230886236\n",
      "59 Train Loss 1.033448 Test MSE 5.924819572007036 Test RE 1.1634443769469422\n",
      "60 Train Loss 1.0183923 Test MSE 5.948880307522653 Test RE 1.1658043614482128\n",
      "61 Train Loss 1.0001056 Test MSE 5.973233749271821 Test RE 1.1681882008802735\n",
      "62 Train Loss 0.9840963 Test MSE 5.970339657849473 Test RE 1.167905167166365\n",
      "63 Train Loss 0.9701967 Test MSE 5.966791120244621 Test RE 1.1675580368826535\n",
      "64 Train Loss 0.961009 Test MSE 5.966814293463863 Test RE 1.167560304102299\n",
      "65 Train Loss 0.9473458 Test MSE 5.959388341998595 Test RE 1.1668335389453843\n",
      "66 Train Loss 0.9364848 Test MSE 5.9480166726255925 Test RE 1.1657197349452264\n",
      "67 Train Loss 0.92819864 Test MSE 5.959927466613532 Test RE 1.1668863173866875\n",
      "68 Train Loss 0.9188957 Test MSE 5.9846383015111115 Test RE 1.1693028659699138\n",
      "69 Train Loss 0.9104424 Test MSE 5.981968029653036 Test RE 1.169041972600405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 0.89878947 Test MSE 5.973628953521553 Test RE 1.168226845383799\n",
      "71 Train Loss 0.8907081 Test MSE 5.980843573508059 Test RE 1.1689320925238254\n",
      "72 Train Loss 0.8822148 Test MSE 5.988142975869264 Test RE 1.1696451945934219\n",
      "73 Train Loss 0.87526584 Test MSE 6.002531609465642 Test RE 1.1710495948033595\n",
      "74 Train Loss 0.8652055 Test MSE 6.0191857167174385 Test RE 1.1726730162081636\n",
      "75 Train Loss 0.8565574 Test MSE 6.027676292602494 Test RE 1.1734998025038441\n",
      "76 Train Loss 0.850672 Test MSE 6.028399808827158 Test RE 1.1735702293672667\n",
      "77 Train Loss 0.8455007 Test MSE 6.0265249297788115 Test RE 1.173387720458688\n",
      "78 Train Loss 0.84060544 Test MSE 6.026294055794768 Test RE 1.1733652442144487\n",
      "79 Train Loss 0.8336765 Test MSE 6.043310229444514 Test RE 1.1750206656081663\n",
      "80 Train Loss 0.82591766 Test MSE 6.058176426224218 Test RE 1.1764650196410642\n",
      "81 Train Loss 0.81593126 Test MSE 6.067626069784952 Test RE 1.1773821968991118\n",
      "82 Train Loss 0.8083472 Test MSE 6.093788084566121 Test RE 1.17991774854569\n",
      "83 Train Loss 0.80241853 Test MSE 6.1204445718002916 Test RE 1.1824956312033907\n",
      "84 Train Loss 0.7965583 Test MSE 6.1239944664964945 Test RE 1.1828385087851427\n",
      "85 Train Loss 0.7909422 Test MSE 6.120016033165099 Test RE 1.18245423274544\n",
      "86 Train Loss 0.78543586 Test MSE 6.136035544896168 Test RE 1.1840007940507997\n",
      "87 Train Loss 0.7792204 Test MSE 6.173891556525539 Test RE 1.1876474995476\n",
      "88 Train Loss 0.77425116 Test MSE 6.203540785713936 Test RE 1.1904958373950023\n",
      "89 Train Loss 0.77098954 Test MSE 6.192734746837949 Test RE 1.1894585143673566\n",
      "90 Train Loss 0.766348 Test MSE 6.203849131648451 Test RE 1.1905254237234268\n",
      "91 Train Loss 0.764343 Test MSE 6.221122261823748 Test RE 1.192181637964415\n",
      "92 Train Loss 0.75933576 Test MSE 6.226887298764769 Test RE 1.192733900028807\n",
      "93 Train Loss 0.75584835 Test MSE 6.229321190105954 Test RE 1.1929669780465049\n",
      "94 Train Loss 0.7516573 Test MSE 6.243384388274601 Test RE 1.1943128287709752\n",
      "95 Train Loss 0.74784 Test MSE 6.2447863979038045 Test RE 1.1944469182319162\n",
      "96 Train Loss 0.7454879 Test MSE 6.246825617300444 Test RE 1.1946419241420492\n",
      "97 Train Loss 0.74324155 Test MSE 6.258502858329578 Test RE 1.1957579796687767\n",
      "98 Train Loss 0.7404165 Test MSE 6.272501964462728 Test RE 1.1970945766864454\n",
      "99 Train Loss 0.73790056 Test MSE 6.269542323038053 Test RE 1.1968121225119115\n",
      "Training time: 157.39\n",
      "4\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 54.327995 Test MSE 8.304671110912528 Test RE 1.3774291805427614\n",
      "1 Train Loss 44.385727 Test MSE 7.581566741340559 Test RE 1.3160959161612744\n",
      "2 Train Loss 37.521347 Test MSE 7.287242169059516 Test RE 1.290296922343101\n",
      "3 Train Loss 31.712389 Test MSE 7.10814627946318 Test RE 1.2743427091947426\n",
      "4 Train Loss 27.737564 Test MSE 6.457307048334157 Test RE 1.2146014050916472\n",
      "5 Train Loss 24.109362 Test MSE 6.375686355864923 Test RE 1.2069006812729022\n",
      "6 Train Loss 21.892635 Test MSE 6.293786335563094 Test RE 1.1991238966648656\n",
      "7 Train Loss 20.7373 Test MSE 6.25197019648543 Test RE 1.1951337471496097\n",
      "8 Train Loss 19.075523 Test MSE 6.110719879448354 Test RE 1.18155583201629\n",
      "9 Train Loss 17.517418 Test MSE 5.987497178972086 Test RE 1.169582122151176\n",
      "10 Train Loss 15.8386345 Test MSE 6.0692349457116626 Test RE 1.1775382823515281\n",
      "11 Train Loss 14.0047035 Test MSE 5.952401785577084 Test RE 1.1661493631035165\n",
      "12 Train Loss 12.26517 Test MSE 5.608490184878403 Test RE 1.1319599006447858\n",
      "13 Train Loss 10.284317 Test MSE 5.503330599073593 Test RE 1.1212975201297957\n",
      "14 Train Loss 8.49345 Test MSE 5.142440768717927 Test RE 1.0839087179175817\n",
      "15 Train Loss 6.918701 Test MSE 5.253153334366961 Test RE 1.0955144216060357\n",
      "16 Train Loss 5.713717 Test MSE 5.006178754731578 Test RE 1.069451851509455\n",
      "17 Train Loss 4.7292895 Test MSE 4.826929356141975 Test RE 1.0501311271559315\n",
      "18 Train Loss 3.8642669 Test MSE 4.466316755332041 Test RE 1.0101429112159153\n",
      "19 Train Loss 3.3982105 Test MSE 4.242222708972153 Test RE 0.9844752277510754\n",
      "20 Train Loss 3.0920396 Test MSE 4.026842270076916 Test RE 0.9591584775508419\n",
      "21 Train Loss 2.785794 Test MSE 3.800798026850045 Test RE 0.9318488128205109\n",
      "22 Train Loss 2.5263865 Test MSE 3.541645763093225 Test RE 0.899519578934607\n",
      "23 Train Loss 2.3738208 Test MSE 3.270910388287716 Test RE 0.8644549855397434\n",
      "24 Train Loss 2.169759 Test MSE 3.0511163418965754 Test RE 0.8349057350670752\n",
      "25 Train Loss 2.0226524 Test MSE 2.885060390436156 Test RE 0.8118681692160741\n",
      "26 Train Loss 1.8874395 Test MSE 2.713956915589071 Test RE 0.7874256085103843\n",
      "27 Train Loss 1.7863832 Test MSE 2.600385252420559 Test RE 0.7707737355433357\n",
      "28 Train Loss 1.7090248 Test MSE 2.4441042916179927 Test RE 0.7472534470268746\n",
      "29 Train Loss 1.617172 Test MSE 2.22004171211772 Test RE 0.7121781210389158\n",
      "30 Train Loss 1.5312022 Test MSE 1.9685647235956216 Test RE 0.6706298952584546\n",
      "31 Train Loss 1.4538988 Test MSE 1.8358561226473675 Test RE 0.6476306309888268\n",
      "32 Train Loss 1.3881985 Test MSE 1.7190890747880372 Test RE 0.6266964728443942\n",
      "33 Train Loss 1.3330393 Test MSE 1.530745988863447 Test RE 0.5913704577822484\n",
      "34 Train Loss 1.2752216 Test MSE 1.415954996883677 Test RE 0.5687648979389908\n",
      "35 Train Loss 1.2033721 Test MSE 1.2801657059955667 Test RE 0.5408055684300936\n",
      "36 Train Loss 1.003171 Test MSE 0.7257316675757648 Test RE 0.40718905633269675\n",
      "37 Train Loss 0.78631675 Test MSE 0.629186491960602 Test RE 0.3791383846105596\n",
      "38 Train Loss 0.6580762 Test MSE 0.5774043198088561 Test RE 0.3632018689493534\n",
      "39 Train Loss 0.53362226 Test MSE 0.602157897533422 Test RE 0.3709054831483183\n",
      "40 Train Loss 0.43905306 Test MSE 0.5784368042147979 Test RE 0.36352645326900235\n",
      "41 Train Loss 0.39248148 Test MSE 0.5688898009917811 Test RE 0.3605139997244584\n",
      "42 Train Loss 0.34430248 Test MSE 0.5548066982081523 Test RE 0.35602369902744957\n",
      "43 Train Loss 0.30592626 Test MSE 0.5163499390579548 Test RE 0.34346313156158575\n",
      "44 Train Loss 0.27686116 Test MSE 0.5064773174592535 Test RE 0.34016377337997816\n",
      "45 Train Loss 0.2539544 Test MSE 0.51537606607018 Test RE 0.34313908065395926\n",
      "46 Train Loss 0.23745032 Test MSE 0.4947154155518643 Test RE 0.33619076698686484\n",
      "47 Train Loss 0.21991208 Test MSE 0.47911397775969033 Test RE 0.3308472132452344\n",
      "48 Train Loss 0.20502956 Test MSE 0.477997499341447 Test RE 0.3304615020834226\n",
      "49 Train Loss 0.1896888 Test MSE 0.45947631149319634 Test RE 0.3239959811948449\n",
      "50 Train Loss 0.1798706 Test MSE 0.4537909161438533 Test RE 0.32198523664794304\n",
      "51 Train Loss 0.17142673 Test MSE 0.4493091762228371 Test RE 0.32039129247446874\n",
      "52 Train Loss 0.16351916 Test MSE 0.44294827665157344 Test RE 0.3181153081416887\n",
      "53 Train Loss 0.15816317 Test MSE 0.43437892491833374 Test RE 0.31502312353778933\n",
      "54 Train Loss 0.15236866 Test MSE 0.4089222571990213 Test RE 0.3056528396762321\n",
      "55 Train Loss 0.1444415 Test MSE 0.3974478728407863 Test RE 0.3013340084493969\n",
      "56 Train Loss 0.13890237 Test MSE 0.4012533657655818 Test RE 0.3027731815554529\n",
      "57 Train Loss 0.13588572 Test MSE 0.3937379606682453 Test RE 0.2999243346327279\n",
      "58 Train Loss 0.13009652 Test MSE 0.394016689029046 Test RE 0.30003047454939874\n",
      "59 Train Loss 0.12697478 Test MSE 0.3935048263940723 Test RE 0.299835528113543\n",
      "60 Train Loss 0.12431458 Test MSE 0.3888692917559846 Test RE 0.2980642467171605\n",
      "61 Train Loss 0.12225474 Test MSE 0.39831530409403376 Test RE 0.3016626604445776\n",
      "62 Train Loss 0.12003538 Test MSE 0.40036324910116 Test RE 0.30243716807110876\n",
      "63 Train Loss 0.11835911 Test MSE 0.3942622053496333 Test RE 0.3001239362082973\n",
      "64 Train Loss 0.11603299 Test MSE 0.3940678673410787 Test RE 0.30004995919953364\n",
      "65 Train Loss 0.11330636 Test MSE 0.38289278908157265 Test RE 0.2957649145343755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.111629605 Test MSE 0.37930083529804315 Test RE 0.2943743461459854\n",
      "67 Train Loss 0.109901 Test MSE 0.3843519594498583 Test RE 0.29632794552256775\n",
      "68 Train Loss 0.1084176 Test MSE 0.38699496557226476 Test RE 0.2973450533409752\n",
      "69 Train Loss 0.106448956 Test MSE 0.39115041858573 Test RE 0.29893719832811727\n",
      "70 Train Loss 0.10464793 Test MSE 0.4033129794478035 Test RE 0.30354924683748846\n",
      "71 Train Loss 0.1034553 Test MSE 0.4093530224143735 Test RE 0.3058137870847441\n",
      "72 Train Loss 0.10218873 Test MSE 0.41390477262934366 Test RE 0.30750931606652854\n",
      "73 Train Loss 0.10092654 Test MSE 0.4219687374736591 Test RE 0.3104904154853663\n",
      "74 Train Loss 0.09970238 Test MSE 0.42459266178314486 Test RE 0.31145427925509384\n",
      "75 Train Loss 0.098871015 Test MSE 0.42554476573939126 Test RE 0.31180328528624934\n",
      "76 Train Loss 0.09829069 Test MSE 0.4267802672095693 Test RE 0.3122555928195257\n",
      "77 Train Loss 0.097273976 Test MSE 0.42817209648739196 Test RE 0.31276434726313457\n",
      "78 Train Loss 0.096440025 Test MSE 0.42694496873733556 Test RE 0.31231583929327034\n",
      "79 Train Loss 0.09591846 Test MSE 0.42790170307980446 Test RE 0.31266557532765443\n",
      "80 Train Loss 0.09508885 Test MSE 0.43271670039958443 Test RE 0.3144198011398649\n",
      "81 Train Loss 0.09441003 Test MSE 0.43652144026103024 Test RE 0.31579907239042515\n",
      "82 Train Loss 0.09355133 Test MSE 0.4380946928271829 Test RE 0.31636764108650806\n",
      "83 Train Loss 0.092265 Test MSE 0.44387658192216195 Test RE 0.31844847746672944\n",
      "84 Train Loss 0.091152035 Test MSE 0.44739483650245004 Test RE 0.31970802969420375\n",
      "85 Train Loss 0.09049537 Test MSE 0.44303666292501714 Test RE 0.3181470450572726\n",
      "86 Train Loss 0.089702025 Test MSE 0.44304752692852106 Test RE 0.3181509457834572\n",
      "87 Train Loss 0.08877594 Test MSE 0.4497873332146017 Test RE 0.32056172812105616\n",
      "88 Train Loss 0.0882234 Test MSE 0.4556761598994458 Test RE 0.3226533764066074\n",
      "89 Train Loss 0.087747574 Test MSE 0.45997019741015893 Test RE 0.32417006424464034\n",
      "90 Train Loss 0.087335855 Test MSE 0.4627710448743716 Test RE 0.32515553344197046\n",
      "91 Train Loss 0.08673177 Test MSE 0.46667086385615053 Test RE 0.3265227186201415\n",
      "92 Train Loss 0.08589092 Test MSE 0.4708207555043623 Test RE 0.32797131430370136\n",
      "93 Train Loss 0.085238904 Test MSE 0.47598246074701817 Test RE 0.32976422234206926\n",
      "94 Train Loss 0.084626056 Test MSE 0.4821860295903312 Test RE 0.33190620525361\n",
      "95 Train Loss 0.08382688 Test MSE 0.4852127652251836 Test RE 0.3329462818228798\n",
      "96 Train Loss 0.082986385 Test MSE 0.4866472734446188 Test RE 0.3334380884303492\n",
      "97 Train Loss 0.08225249 Test MSE 0.48963283747868774 Test RE 0.3344593400058863\n",
      "98 Train Loss 0.081666075 Test MSE 0.4921659554981237 Test RE 0.3353233874725247\n",
      "99 Train Loss 0.08113195 Test MSE 0.49355358048606557 Test RE 0.3357957643161817\n",
      "Training time: 157.13\n",
      "5\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.294365 Test MSE 8.381591921452207 Test RE 1.383793596051341\n",
      "1 Train Loss 51.180923 Test MSE 8.529958421558895 Test RE 1.3959874610208944\n",
      "2 Train Loss 44.056244 Test MSE 8.267827005960179 Test RE 1.3743702659427919\n",
      "3 Train Loss 42.468063 Test MSE 8.899804539398783 Test RE 1.4259302902533597\n",
      "4 Train Loss 40.906563 Test MSE 9.27350474910204 Test RE 1.4555596558997848\n",
      "5 Train Loss 39.903408 Test MSE 9.589068314206065 Test RE 1.4801177491567346\n",
      "6 Train Loss 38.461155 Test MSE 9.71165731406652 Test RE 1.4895487967365524\n",
      "7 Train Loss 37.177837 Test MSE 9.95715003796279 Test RE 1.5082578207024873\n",
      "8 Train Loss 35.3069 Test MSE 9.919589559025688 Test RE 1.505410398916214\n",
      "9 Train Loss 32.84692 Test MSE 10.098370632508729 Test RE 1.5189158477746718\n",
      "10 Train Loss 31.006243 Test MSE 10.179267261401902 Test RE 1.524987622764352\n",
      "11 Train Loss 28.944279 Test MSE 9.662834727852914 Test RE 1.485799938432666\n",
      "12 Train Loss 27.40754 Test MSE 10.061860971084258 Test RE 1.5161676164372009\n",
      "13 Train Loss 25.934078 Test MSE 10.03333936170375 Test RE 1.514017207633172\n",
      "14 Train Loss 24.12783 Test MSE 10.025450326569946 Test RE 1.5134218682699798\n",
      "15 Train Loss 21.85686 Test MSE 10.091294798142213 Test RE 1.5183836094219756\n",
      "16 Train Loss 20.48714 Test MSE 10.192396200121307 Test RE 1.5259707493936125\n",
      "17 Train Loss 19.181051 Test MSE 10.11043342565551 Test RE 1.5198227712756451\n",
      "18 Train Loss 18.194262 Test MSE 10.015498394794475 Test RE 1.5126705199364017\n",
      "19 Train Loss 17.072601 Test MSE 9.8378206074473 Test RE 1.4991928757272974\n",
      "20 Train Loss 16.14484 Test MSE 9.852223541927678 Test RE 1.5002899113537422\n",
      "21 Train Loss 15.25571 Test MSE 9.561813235481635 Test RE 1.4780127776179603\n",
      "22 Train Loss 13.83264 Test MSE 9.587828956720061 Test RE 1.4800220957403245\n",
      "23 Train Loss 12.894728 Test MSE 9.242912210852193 Test RE 1.4531567860592796\n",
      "24 Train Loss 12.12595 Test MSE 9.3855380492128 Test RE 1.4643255751983202\n",
      "25 Train Loss 11.09095 Test MSE 9.070806752069753 Test RE 1.4395641330752635\n",
      "26 Train Loss 10.404595 Test MSE 9.050504327557828 Test RE 1.4379522028934828\n",
      "27 Train Loss 9.328395 Test MSE 8.768161695643245 Test RE 1.4153450662879585\n",
      "28 Train Loss 8.27461 Test MSE 8.623272049114092 Test RE 1.4036024061885335\n",
      "29 Train Loss 7.381758 Test MSE 8.580058116631664 Test RE 1.4000810420923542\n",
      "30 Train Loss 6.523594 Test MSE 8.223547842634257 Test RE 1.370685037382479\n",
      "31 Train Loss 5.825007 Test MSE 8.069959868054234 Test RE 1.3578248349669828\n",
      "32 Train Loss 5.0573707 Test MSE 8.066873514977134 Test RE 1.3575651603410739\n",
      "33 Train Loss 4.6112294 Test MSE 7.908544581381825 Test RE 1.344176640546042\n",
      "34 Train Loss 4.1668715 Test MSE 7.811668336620588 Test RE 1.3359184821629664\n",
      "35 Train Loss 3.7672465 Test MSE 7.7039974249089465 Test RE 1.326679824822643\n",
      "36 Train Loss 3.5416567 Test MSE 7.623606762272669 Test RE 1.3197397680081646\n",
      "37 Train Loss 3.3613882 Test MSE 7.717782562558401 Test RE 1.3278662407308532\n",
      "38 Train Loss 3.137466 Test MSE 7.6039557139808505 Test RE 1.3180377518421613\n",
      "39 Train Loss 2.9777317 Test MSE 7.559183832865836 Test RE 1.3141517382821022\n",
      "40 Train Loss 2.8510454 Test MSE 7.612056907381742 Test RE 1.318739678357421\n",
      "41 Train Loss 2.7659745 Test MSE 7.552958273653703 Test RE 1.3136104751761155\n",
      "42 Train Loss 2.6670878 Test MSE 7.516425846720246 Test RE 1.3104297645905396\n",
      "43 Train Loss 2.5832744 Test MSE 7.507984512537221 Test RE 1.309693717746379\n",
      "44 Train Loss 2.4668584 Test MSE 7.394350991718141 Test RE 1.2997448074823796\n",
      "45 Train Loss 2.4076757 Test MSE 7.412752107603036 Test RE 1.3013610341061295\n",
      "46 Train Loss 2.336594 Test MSE 7.380988156523084 Test RE 1.2985698477310643\n",
      "47 Train Loss 2.235064 Test MSE 7.353209930581414 Test RE 1.296123971315729\n",
      "48 Train Loss 2.17949 Test MSE 7.286934293359357 Test RE 1.2902696654429542\n",
      "49 Train Loss 2.100815 Test MSE 7.244029006892524 Test RE 1.2864655197730426\n",
      "50 Train Loss 2.035978 Test MSE 7.224808549759106 Test RE 1.2847577078138865\n",
      "51 Train Loss 1.9995596 Test MSE 7.164891480439468 Test RE 1.279419214584972\n",
      "52 Train Loss 1.9675021 Test MSE 7.133950602344721 Test RE 1.276653702781352\n",
      "53 Train Loss 1.9319121 Test MSE 7.072734001467519 Test RE 1.2711644034669478\n",
      "54 Train Loss 1.8904874 Test MSE 6.963418846581581 Test RE 1.261302683065354\n",
      "55 Train Loss 1.852204 Test MSE 6.91154326940424 Test RE 1.2565957192457111\n",
      "56 Train Loss 1.8270504 Test MSE 6.9077890099070975 Test RE 1.2562543897454874\n",
      "57 Train Loss 1.8042507 Test MSE 6.87432195964831 Test RE 1.2532075266027964\n",
      "58 Train Loss 1.7706411 Test MSE 6.817372397816671 Test RE 1.2480057009653471\n",
      "59 Train Loss 1.7512168 Test MSE 6.780965935663266 Test RE 1.2446689099444077\n",
      "60 Train Loss 1.730316 Test MSE 6.7007264229405346 Test RE 1.2372828800380313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 1.706503 Test MSE 6.593765415401882 Test RE 1.2273680290649174\n",
      "62 Train Loss 1.6757741 Test MSE 6.482732209311045 Test RE 1.2169902567740654\n",
      "63 Train Loss 1.6393511 Test MSE 6.284640858891274 Test RE 1.1982523587859055\n",
      "64 Train Loss 1.6135131 Test MSE 6.2443530687425275 Test RE 1.194405475848819\n",
      "65 Train Loss 1.5926893 Test MSE 6.190896477820796 Test RE 1.1892819601378706\n",
      "66 Train Loss 1.5630107 Test MSE 6.128331571202293 Test RE 1.1832572866359197\n",
      "67 Train Loss 1.5364716 Test MSE 6.05610559833381 Test RE 1.1762639306803397\n",
      "68 Train Loss 1.5127025 Test MSE 5.96948936426428 Test RE 1.1678219978921631\n",
      "69 Train Loss 1.4872144 Test MSE 5.872310243133402 Test RE 1.1582773297758586\n",
      "70 Train Loss 1.473413 Test MSE 5.807613463327362 Test RE 1.1518791359865999\n",
      "71 Train Loss 1.4609327 Test MSE 5.781868703075839 Test RE 1.149323198860321\n",
      "72 Train Loss 1.4464878 Test MSE 5.7510961169468935 Test RE 1.1462606222512075\n",
      "73 Train Loss 1.4346293 Test MSE 5.712654915609363 Test RE 1.1424233090160543\n",
      "74 Train Loss 1.4152471 Test MSE 5.70208893212896 Test RE 1.1413663212729612\n",
      "75 Train Loss 1.4065714 Test MSE 5.704051144210883 Test RE 1.1415626887947041\n",
      "76 Train Loss 1.3958602 Test MSE 5.677362981147165 Test RE 1.1388889810719425\n",
      "77 Train Loss 1.3793073 Test MSE 5.674236091226687 Test RE 1.1385753080722327\n",
      "78 Train Loss 1.3660166 Test MSE 5.708651627814453 Test RE 1.1420229478111343\n",
      "79 Train Loss 1.3496437 Test MSE 5.709250080038708 Test RE 1.1420828068029694\n",
      "80 Train Loss 1.3345977 Test MSE 5.676055333142319 Test RE 1.1387578152760376\n",
      "81 Train Loss 1.3247019 Test MSE 5.674860417439537 Test RE 1.1386379440682155\n",
      "82 Train Loss 1.3145912 Test MSE 5.651943648583128 Test RE 1.1363365394776863\n",
      "83 Train Loss 1.3002455 Test MSE 5.611366523033383 Test RE 1.1322501286741968\n",
      "84 Train Loss 1.28996 Test MSE 5.600278523009595 Test RE 1.1311309184629428\n",
      "85 Train Loss 1.2796714 Test MSE 5.59134222844467 Test RE 1.1302280924153087\n",
      "86 Train Loss 1.2734497 Test MSE 5.600677131475507 Test RE 1.1311711727409752\n",
      "87 Train Loss 1.2673205 Test MSE 5.614298645849922 Test RE 1.1325459089308685\n",
      "88 Train Loss 1.2567396 Test MSE 5.605991864326151 Test RE 1.1317077549160435\n",
      "89 Train Loss 1.2485266 Test MSE 5.585902857370547 Test RE 1.1296782042463684\n",
      "90 Train Loss 1.2362669 Test MSE 5.556336120963352 Test RE 1.1266844882375249\n",
      "91 Train Loss 1.2248348 Test MSE 5.553048092235976 Test RE 1.1263510743563556\n",
      "92 Train Loss 1.215286 Test MSE 5.571679571561701 Test RE 1.1282390477060193\n",
      "93 Train Loss 1.2087018 Test MSE 5.578885943803807 Test RE 1.128968440267415\n",
      "94 Train Loss 1.2015715 Test MSE 5.584223195394621 Test RE 1.1295083462810702\n",
      "95 Train Loss 1.1915891 Test MSE 5.585759809868425 Test RE 1.1296637393797182\n",
      "96 Train Loss 1.1840578 Test MSE 5.5971849137443295 Test RE 1.1308184553897849\n",
      "97 Train Loss 1.1767774 Test MSE 5.621617330129386 Test RE 1.13328385029823\n",
      "98 Train Loss 1.1687758 Test MSE 5.623669876026761 Test RE 1.133490721799228\n",
      "99 Train Loss 1.1623691 Test MSE 5.62686569809446 Test RE 1.133812746406692\n",
      "Training time: 157.70\n",
      "6\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 56.74671 Test MSE 8.72544610524563 Test RE 1.4118933101427498\n",
      "1 Train Loss 47.83976 Test MSE 8.717955174441485 Test RE 1.4112871138556915\n",
      "2 Train Loss 43.049973 Test MSE 8.817888969117403 Test RE 1.419352847307808\n",
      "3 Train Loss 40.08394 Test MSE 9.450135106146499 Test RE 1.4693561297152913\n",
      "4 Train Loss 37.455013 Test MSE 9.154344729448002 Test RE 1.4461778040544886\n",
      "5 Train Loss 35.174274 Test MSE 8.944149304657072 Test RE 1.429478344183017\n",
      "6 Train Loss 32.3947 Test MSE 8.77837096947096 Test RE 1.416168810315098\n",
      "7 Train Loss 29.511578 Test MSE 8.628636744608151 Test RE 1.4040389416882306\n",
      "8 Train Loss 26.791418 Test MSE 8.5352019186255 Test RE 1.3964164626193585\n",
      "9 Train Loss 24.699266 Test MSE 8.695021480237894 Test RE 1.409429605974552\n",
      "10 Train Loss 21.966452 Test MSE 8.462739911575614 Test RE 1.3904761918886968\n",
      "11 Train Loss 19.132172 Test MSE 8.417510977247632 Test RE 1.386755528689489\n",
      "12 Train Loss 16.557495 Test MSE 8.196725524557456 Test RE 1.3684478656452495\n",
      "13 Train Loss 14.549753 Test MSE 8.107037802852215 Test RE 1.3609405657317826\n",
      "14 Train Loss 12.927557 Test MSE 7.699771625078938 Test RE 1.3263159194323568\n",
      "15 Train Loss 10.423565 Test MSE 7.627752107634462 Test RE 1.3200985242906809\n",
      "16 Train Loss 9.100825 Test MSE 7.252449244720479 Test RE 1.28721297672379\n",
      "17 Train Loss 7.3834753 Test MSE 6.7778649636076596 Test RE 1.2443842805192455\n",
      "18 Train Loss 6.1063423 Test MSE 6.421188971255906 Test RE 1.211199787131515\n",
      "19 Train Loss 5.111514 Test MSE 5.7127629923867165 Test RE 1.1424341156241438\n",
      "20 Train Loss 4.269405 Test MSE 5.4382043537811535 Test RE 1.1146430742031044\n",
      "21 Train Loss 3.5799181 Test MSE 5.333458236375599 Test RE 1.103856221223881\n",
      "22 Train Loss 3.0569627 Test MSE 5.242467889410867 Test RE 1.0943996608905076\n",
      "23 Train Loss 2.6446214 Test MSE 5.2506382214065095 Test RE 1.095252134154527\n",
      "24 Train Loss 2.3383904 Test MSE 5.206670918099813 Test RE 1.0906568340602825\n",
      "25 Train Loss 2.1067097 Test MSE 5.30514095521186 Test RE 1.1009219329611424\n",
      "26 Train Loss 1.9675881 Test MSE 5.342988960747852 Test RE 1.1048420594123385\n",
      "27 Train Loss 1.8131024 Test MSE 5.316403449501709 Test RE 1.10208990883722\n",
      "28 Train Loss 1.6852152 Test MSE 5.392964912266528 Test RE 1.1099971344583652\n",
      "29 Train Loss 1.5914471 Test MSE 5.49860874127348 Test RE 1.1208163802521216\n",
      "30 Train Loss 1.5314546 Test MSE 5.55699724479399 Test RE 1.1267515158428076\n",
      "31 Train Loss 1.4327718 Test MSE 5.576058404752018 Test RE 1.1286823072506567\n",
      "32 Train Loss 1.3274832 Test MSE 5.600748357516838 Test RE 1.131178365495231\n",
      "33 Train Loss 1.2427635 Test MSE 5.611515905860317 Test RE 1.13226519965545\n",
      "34 Train Loss 1.1762285 Test MSE 5.713610088359368 Test RE 1.1425188132973583\n",
      "35 Train Loss 1.1205926 Test MSE 5.846673790884178 Test RE 1.15574624748475\n",
      "36 Train Loss 1.0862328 Test MSE 5.880234459208587 Test RE 1.1590585679214807\n",
      "37 Train Loss 1.0434537 Test MSE 5.9325313827542825 Test RE 1.1642013067606132\n",
      "38 Train Loss 1.0119412 Test MSE 5.949971387149109 Test RE 1.1659112661935882\n",
      "39 Train Loss 0.9770113 Test MSE 6.040336201518197 Test RE 1.1747315050173994\n",
      "40 Train Loss 0.95525014 Test MSE 6.040694403263589 Test RE 1.1747663362439411\n",
      "41 Train Loss 0.9206686 Test MSE 6.093715600562414 Test RE 1.1799107311194525\n",
      "42 Train Loss 0.8988685 Test MSE 6.13227038503948 Test RE 1.183637478331451\n",
      "43 Train Loss 0.8835015 Test MSE 6.11776208234923 Test RE 1.1822364686819529\n",
      "44 Train Loss 0.8672788 Test MSE 6.115651824759266 Test RE 1.182032551087131\n",
      "45 Train Loss 0.8551264 Test MSE 6.129658005447319 Test RE 1.1833853335642812\n",
      "46 Train Loss 0.84270144 Test MSE 6.137272753353371 Test RE 1.1841201530369694\n",
      "47 Train Loss 0.82927746 Test MSE 6.154418904953367 Test RE 1.1857730812737048\n",
      "48 Train Loss 0.82406753 Test MSE 6.160261288155321 Test RE 1.1863357743154084\n",
      "49 Train Loss 0.8132251 Test MSE 6.171334770146119 Test RE 1.1874015545573493\n",
      "50 Train Loss 0.8056936 Test MSE 6.177332958832653 Test RE 1.1879784580205726\n",
      "51 Train Loss 0.7971668 Test MSE 6.184553594027354 Test RE 1.188672564515127\n",
      "52 Train Loss 0.7885399 Test MSE 6.209398660547169 Test RE 1.1910577850249693\n",
      "53 Train Loss 0.78274876 Test MSE 6.226644117731773 Test RE 1.1927106096527418\n",
      "54 Train Loss 0.7765001 Test MSE 6.254312187218059 Test RE 1.1953575749986947\n",
      "55 Train Loss 0.7693946 Test MSE 6.27284888709012 Test RE 1.1971276809768785\n",
      "56 Train Loss 0.76238984 Test MSE 6.266173497131853 Test RE 1.1964905365625924\n",
      "57 Train Loss 0.75707483 Test MSE 6.267676457301199 Test RE 1.1966340188490836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.75098777 Test MSE 6.289623352089774 Test RE 1.198727254767486\n",
      "59 Train Loss 0.7435169 Test MSE 6.3137835720514355 Test RE 1.2010273730321226\n",
      "60 Train Loss 0.73882985 Test MSE 6.325875986565145 Test RE 1.202176951047369\n",
      "61 Train Loss 0.73394805 Test MSE 6.346193177647523 Test RE 1.204105954921307\n",
      "62 Train Loss 0.730009 Test MSE 6.373094060054592 Test RE 1.2066552989337276\n",
      "63 Train Loss 0.72599727 Test MSE 6.394433481112245 Test RE 1.2086737696131942\n",
      "64 Train Loss 0.72146666 Test MSE 6.409360037642355 Test RE 1.210083653786467\n",
      "65 Train Loss 0.7160942 Test MSE 6.412473073344392 Test RE 1.2103774878270075\n",
      "66 Train Loss 0.71235764 Test MSE 6.412697750577688 Test RE 1.2103986919615182\n",
      "67 Train Loss 0.7083794 Test MSE 6.429343138401539 Test RE 1.2119685849426962\n",
      "68 Train Loss 0.7046155 Test MSE 6.447506605512007 Test RE 1.2136793371470724\n",
      "69 Train Loss 0.6985056 Test MSE 6.4610594426288905 Test RE 1.2149542612758981\n",
      "70 Train Loss 0.6952392 Test MSE 6.465071406030173 Test RE 1.2153314127037942\n",
      "71 Train Loss 0.6912637 Test MSE 6.48369115295482 Test RE 1.2170802637247915\n",
      "72 Train Loss 0.6884603 Test MSE 6.489033553534904 Test RE 1.2175815824417546\n",
      "73 Train Loss 0.68404615 Test MSE 6.502446484969771 Test RE 1.2188393127013066\n",
      "74 Train Loss 0.68100715 Test MSE 6.515962782974396 Test RE 1.2201054241011233\n",
      "75 Train Loss 0.67713577 Test MSE 6.522940246451118 Test RE 1.2207585097223113\n",
      "76 Train Loss 0.6736129 Test MSE 6.52427099381855 Test RE 1.22088302706153\n",
      "77 Train Loss 0.67022884 Test MSE 6.538694076582692 Test RE 1.2222317735950141\n",
      "78 Train Loss 0.6671392 Test MSE 6.561203634636537 Test RE 1.2243337422659157\n",
      "79 Train Loss 0.6638013 Test MSE 6.57034736629859 Test RE 1.2251865645677051\n",
      "80 Train Loss 0.6604556 Test MSE 6.581535943457331 Test RE 1.226229299659769\n",
      "81 Train Loss 0.657487 Test MSE 6.599800636007429 Test RE 1.2279296006508345\n",
      "82 Train Loss 0.6533883 Test MSE 6.606443831946826 Test RE 1.228547446981788\n",
      "83 Train Loss 0.64904356 Test MSE 6.612303864507615 Test RE 1.2290921978681728\n",
      "84 Train Loss 0.64446354 Test MSE 6.62840302308729 Test RE 1.2305875405691307\n",
      "85 Train Loss 0.640313 Test MSE 6.6378525925911696 Test RE 1.231464401929934\n",
      "86 Train Loss 0.63691217 Test MSE 6.637384669637042 Test RE 1.2314209962796696\n",
      "87 Train Loss 0.6337086 Test MSE 6.6359214272925815 Test RE 1.2312852525527525\n",
      "88 Train Loss 0.62930906 Test MSE 6.638599960297548 Test RE 1.2315337263694286\n",
      "89 Train Loss 0.62590986 Test MSE 6.6480408027525 Test RE 1.232409105611093\n",
      "90 Train Loss 0.6215596 Test MSE 6.663377031772305 Test RE 1.233829796390992\n",
      "91 Train Loss 0.61871207 Test MSE 6.6737971107621386 Test RE 1.2347941408642986\n",
      "92 Train Loss 0.61478883 Test MSE 6.681316214948273 Test RE 1.2354895419964222\n",
      "93 Train Loss 0.6111025 Test MSE 6.704617791498701 Test RE 1.2376420966790604\n",
      "94 Train Loss 0.6084322 Test MSE 6.7192744872044 Test RE 1.2389941380143956\n",
      "95 Train Loss 0.6053353 Test MSE 6.732795724149007 Test RE 1.2402401292227674\n",
      "96 Train Loss 0.60215414 Test MSE 6.758536727509424 Test RE 1.2426087269555621\n",
      "97 Train Loss 0.59826136 Test MSE 6.778979171964932 Test RE 1.2444865580355111\n",
      "98 Train Loss 0.5950242 Test MSE 6.787321176119207 Test RE 1.2452520361366146\n",
      "99 Train Loss 0.59192395 Test MSE 6.792825685760279 Test RE 1.2457568827819734\n",
      "Training time: 157.50\n",
      "7\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 53.77124 Test MSE 8.061186730192997 Test RE 1.357086564639885\n",
      "1 Train Loss 42.100132 Test MSE 7.068618631632474 Test RE 1.2707945272041141\n",
      "2 Train Loss 34.640423 Test MSE 7.570524598608063 Test RE 1.3151371556064892\n",
      "3 Train Loss 29.966621 Test MSE 7.108583359245193 Test RE 1.27438188824717\n",
      "4 Train Loss 26.548233 Test MSE 6.629841510521448 Test RE 1.2307210635819286\n",
      "5 Train Loss 24.379803 Test MSE 6.6958602106133815 Test RE 1.2368335276586377\n",
      "6 Train Loss 20.857403 Test MSE 6.364756412840697 Test RE 1.2058657327720042\n",
      "7 Train Loss 18.345448 Test MSE 6.469221248845237 Test RE 1.2157214026161731\n",
      "8 Train Loss 16.595097 Test MSE 6.488930310203758 Test RE 1.217571896278361\n",
      "9 Train Loss 15.295158 Test MSE 6.135818353343219 Test RE 1.183979839376981\n",
      "10 Train Loss 13.774553 Test MSE 6.094077929482991 Test RE 1.179945809014027\n",
      "11 Train Loss 12.250061 Test MSE 5.959912531932957 Test RE 1.1668848553650915\n",
      "12 Train Loss 11.089009 Test MSE 5.705942531759643 Test RE 1.1417519366157243\n",
      "13 Train Loss 9.93722 Test MSE 5.766686037633198 Test RE 1.1478131974257657\n",
      "14 Train Loss 8.972445 Test MSE 5.607674019266464 Test RE 1.131877534417155\n",
      "15 Train Loss 7.7830505 Test MSE 5.584186170504123 Test RE 1.1295046018039339\n",
      "16 Train Loss 6.8953733 Test MSE 5.450770063236533 Test RE 1.1159300982451241\n",
      "17 Train Loss 6.2818313 Test MSE 5.315554931635448 Test RE 1.1020019564928565\n",
      "18 Train Loss 5.835675 Test MSE 5.1780517165968885 Test RE 1.087655229085591\n",
      "19 Train Loss 5.4246187 Test MSE 5.046695454153799 Test RE 1.0737708482838515\n",
      "20 Train Loss 5.026215 Test MSE 4.686917382190134 Test RE 1.0347887758154652\n",
      "21 Train Loss 4.575694 Test MSE 4.33616941138538 Test RE 0.9953164479948932\n",
      "22 Train Loss 4.09197 Test MSE 3.785870797591543 Test RE 0.9300171441705396\n",
      "23 Train Loss 3.6743054 Test MSE 3.5871993047812536 Test RE 0.9052860197519326\n",
      "24 Train Loss 3.1772647 Test MSE 2.8711879724723115 Test RE 0.8099139387436691\n",
      "25 Train Loss 2.7077599 Test MSE 2.4927571850174064 Test RE 0.7546542959230014\n",
      "26 Train Loss 2.0420036 Test MSE 1.7447109017556015 Test RE 0.6313494371864176\n",
      "27 Train Loss 1.8306928 Test MSE 1.6644911343734805 Test RE 0.616664295034916\n",
      "28 Train Loss 1.478452 Test MSE 1.4261046384195284 Test RE 0.570799726691575\n",
      "29 Train Loss 1.1450155 Test MSE 0.989401107030919 Test RE 0.47543840059439\n",
      "30 Train Loss 0.8663002 Test MSE 0.7243634626364038 Test RE 0.40680504325233796\n",
      "31 Train Loss 0.6531689 Test MSE 0.5770106832895958 Test RE 0.363078044196313\n",
      "32 Train Loss 0.53449357 Test MSE 0.48807947025862736 Test RE 0.3339283800181921\n",
      "33 Train Loss 0.43086463 Test MSE 0.4430110184548907 Test RE 0.31813783720706224\n",
      "34 Train Loss 0.34623536 Test MSE 0.38381610539758065 Test RE 0.29612130690672867\n",
      "35 Train Loss 0.25471148 Test MSE 0.3679972746796866 Test RE 0.2899548393130132\n",
      "36 Train Loss 0.21779339 Test MSE 0.3497807968945226 Test RE 0.282687133288142\n",
      "37 Train Loss 0.1895158 Test MSE 0.31345172571306457 Test RE 0.26760448809851706\n",
      "38 Train Loss 0.1570176 Test MSE 0.2802645160613604 Test RE 0.25304171255008434\n",
      "39 Train Loss 0.13376556 Test MSE 0.2446675764621772 Test RE 0.23642656383371102\n",
      "40 Train Loss 0.117372185 Test MSE 0.22010037886325165 Test RE 0.2242427730200482\n",
      "41 Train Loss 0.10538685 Test MSE 0.21663015628479876 Test RE 0.22246798273702453\n",
      "42 Train Loss 0.09303294 Test MSE 0.2089149702780654 Test RE 0.21847051930884587\n",
      "43 Train Loss 0.0838353 Test MSE 0.19822753427198997 Test RE 0.21280902879346636\n",
      "44 Train Loss 0.074786946 Test MSE 0.20010071212713565 Test RE 0.21381214841537893\n",
      "45 Train Loss 0.06467677 Test MSE 0.1942794102869181 Test RE 0.21067909715171887\n",
      "46 Train Loss 0.060093716 Test MSE 0.19606224202652725 Test RE 0.21164355245174743\n",
      "47 Train Loss 0.05358826 Test MSE 0.19211597309036693 Test RE 0.20950278362188746\n",
      "48 Train Loss 0.049002364 Test MSE 0.18824893611544233 Test RE 0.2073835600476202\n",
      "49 Train Loss 0.04501007 Test MSE 0.18514372288882128 Test RE 0.2056660259936557\n",
      "50 Train Loss 0.04139506 Test MSE 0.18887789829940954 Test RE 0.2077297177743327\n",
      "51 Train Loss 0.038986415 Test MSE 0.18299809301292244 Test RE 0.20447082171516442\n",
      "52 Train Loss 0.03629704 Test MSE 0.1773864061482184 Test RE 0.20131133448648986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 0.033314988 Test MSE 0.18200464589868187 Test RE 0.20391505804292062\n",
      "54 Train Loss 0.031043453 Test MSE 0.17452044852923185 Test RE 0.19967846090022662\n",
      "55 Train Loss 0.029204577 Test MSE 0.16408848542833132 Test RE 0.1936186169140736\n",
      "56 Train Loss 0.027485397 Test MSE 0.1631512881792736 Test RE 0.19306489530646964\n",
      "57 Train Loss 0.025567677 Test MSE 0.15945088346652694 Test RE 0.1908629030493222\n",
      "58 Train Loss 0.02325836 Test MSE 0.15182641873082744 Test RE 0.18624376147903324\n",
      "59 Train Loss 0.021786487 Test MSE 0.14874658070292546 Test RE 0.1843450819988313\n",
      "60 Train Loss 0.020938866 Test MSE 0.14660402297177194 Test RE 0.1830126056145005\n",
      "61 Train Loss 0.020039732 Test MSE 0.14160500810057028 Test RE 0.17986529191136016\n",
      "62 Train Loss 0.019143278 Test MSE 0.13814123294084357 Test RE 0.17765184581978094\n",
      "63 Train Loss 0.018157275 Test MSE 0.13244157979224944 Test RE 0.17394831913694087\n",
      "64 Train Loss 0.01729062 Test MSE 0.12548699057940538 Test RE 0.16931966961345885\n",
      "65 Train Loss 0.016689025 Test MSE 0.12436322755483424 Test RE 0.16855981757569\n",
      "66 Train Loss 0.016004628 Test MSE 0.12134773101649295 Test RE 0.16650370063898576\n",
      "67 Train Loss 0.015716393 Test MSE 0.11692368310179971 Test RE 0.16344035761399098\n",
      "68 Train Loss 0.014972598 Test MSE 0.11755140083268036 Test RE 0.16387849417761408\n",
      "69 Train Loss 0.014358198 Test MSE 0.11810448029594417 Test RE 0.164263566011126\n",
      "70 Train Loss 0.013913413 Test MSE 0.11340088136189022 Test RE 0.16095937434210628\n",
      "71 Train Loss 0.013524713 Test MSE 0.11172356886434488 Test RE 0.15976456467903935\n",
      "72 Train Loss 0.012880289 Test MSE 0.11085899967608814 Test RE 0.15914519768150995\n",
      "73 Train Loss 0.012378827 Test MSE 0.1069567748964203 Test RE 0.1563191589723334\n",
      "74 Train Loss 0.011764145 Test MSE 0.10181848574342015 Test RE 0.1525180967759473\n",
      "75 Train Loss 0.011366564 Test MSE 0.09943810727712514 Test RE 0.1507247197095281\n",
      "76 Train Loss 0.010976878 Test MSE 0.0945202993865726 Test RE 0.14695034315360622\n",
      "77 Train Loss 0.010185781 Test MSE 0.09022354506847696 Test RE 0.14357142270262802\n",
      "78 Train Loss 0.00965986 Test MSE 0.08787778576047313 Test RE 0.14169274471701865\n",
      "79 Train Loss 0.009147296 Test MSE 0.08212490934599269 Test RE 0.13697632554194694\n",
      "80 Train Loss 0.008759303 Test MSE 0.0813822263177428 Test RE 0.1363555575342483\n",
      "81 Train Loss 0.008403739 Test MSE 0.08127765358377464 Test RE 0.13626792379890448\n",
      "82 Train Loss 0.007742732 Test MSE 0.07796981280666021 Test RE 0.13346620322108724\n",
      "83 Train Loss 0.0074480437 Test MSE 0.0770256705302566 Test RE 0.1326556659308351\n",
      "84 Train Loss 0.007197708 Test MSE 0.07506816866810087 Test RE 0.13095918716561786\n",
      "85 Train Loss 0.00698542 Test MSE 0.07180835556280353 Test RE 0.1280841973119648\n",
      "86 Train Loss 0.0067114057 Test MSE 0.06876486631253466 Test RE 0.1253404823822733\n",
      "87 Train Loss 0.0064647896 Test MSE 0.06647285286488688 Test RE 0.12323390750858652\n",
      "88 Train Loss 0.0062326174 Test MSE 0.06269767662432585 Test RE 0.11968336301820025\n",
      "89 Train Loss 0.006012043 Test MSE 0.06145004502931774 Test RE 0.11848657968435544\n",
      "90 Train Loss 0.005871919 Test MSE 0.06019932836659511 Test RE 0.11727457918502478\n",
      "91 Train Loss 0.0055555417 Test MSE 0.054506915266749965 Test RE 0.11159220588646783\n",
      "92 Train Loss 0.005100449 Test MSE 0.048487266515586366 Test RE 0.10524995308961739\n",
      "93 Train Loss 0.004939805 Test MSE 0.0473331125873296 Test RE 0.103989763955671\n",
      "94 Train Loss 0.004787365 Test MSE 0.04708848634016747 Test RE 0.10372069672775613\n",
      "95 Train Loss 0.004688111 Test MSE 0.0455193981833322 Test RE 0.10197795908766588\n",
      "96 Train Loss 0.004614063 Test MSE 0.04419664945489838 Test RE 0.10048534632617662\n",
      "97 Train Loss 0.0044452883 Test MSE 0.04315750132700902 Test RE 0.09929701804932299\n",
      "98 Train Loss 0.0041815788 Test MSE 0.041882007528047945 Test RE 0.0978186816980383\n",
      "99 Train Loss 0.004058969 Test MSE 0.041088237474259465 Test RE 0.09688729173084547\n",
      "Training time: 156.51\n",
      "8\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 63.112186 Test MSE 6.830744237138475 Test RE 1.249229043007769\n",
      "1 Train Loss 46.771103 Test MSE 8.266010588051769 Test RE 1.37421928504468\n",
      "2 Train Loss 33.23319 Test MSE 8.015174863961903 Test RE 1.3532080139414153\n",
      "3 Train Loss 26.874218 Test MSE 7.870485590693923 Test RE 1.3409383896697356\n",
      "4 Train Loss 21.845512 Test MSE 7.890527467852591 Test RE 1.342644627165728\n",
      "5 Train Loss 18.913515 Test MSE 7.473218602832898 Test RE 1.3066579146013502\n",
      "6 Train Loss 16.848711 Test MSE 7.2851454065023775 Test RE 1.2901112800349743\n",
      "7 Train Loss 15.584188 Test MSE 7.342154974691649 Test RE 1.2951492961066673\n",
      "8 Train Loss 14.289398 Test MSE 7.594544072144673 Test RE 1.3172218120491739\n",
      "9 Train Loss 13.184895 Test MSE 7.485493031557574 Test RE 1.307730538063411\n",
      "10 Train Loss 12.118486 Test MSE 7.3967855932988416 Test RE 1.2999587613737718\n",
      "11 Train Loss 10.897711 Test MSE 7.283591213547841 Test RE 1.289973658292292\n",
      "12 Train Loss 9.854422 Test MSE 7.003995757236715 Test RE 1.264972247237762\n",
      "13 Train Loss 8.753564 Test MSE 6.877274451099147 Test RE 1.2534766213093633\n",
      "14 Train Loss 7.8655815 Test MSE 6.808835633598585 Test RE 1.2472240752074626\n",
      "15 Train Loss 7.024642 Test MSE 6.6301776313133045 Test RE 1.2307522608356511\n",
      "16 Train Loss 6.1810904 Test MSE 6.428907557477682 Test RE 1.2119275294782277\n",
      "17 Train Loss 5.6501055 Test MSE 6.2584811551779636 Test RE 1.1957559063503007\n",
      "18 Train Loss 4.8126326 Test MSE 6.022884721685319 Test RE 1.1730332856283077\n",
      "19 Train Loss 4.243205 Test MSE 5.928494891452308 Test RE 1.1638051783825516\n",
      "20 Train Loss 3.8665226 Test MSE 5.737778867505563 Test RE 1.1449327114055796\n",
      "21 Train Loss 3.35317 Test MSE 5.3369773257342334 Test RE 1.1042203309579164\n",
      "22 Train Loss 3.014074 Test MSE 5.22848548072957 Test RE 1.0929392265440978\n",
      "23 Train Loss 2.7374287 Test MSE 5.034199402109602 Test RE 1.0724406498608274\n",
      "24 Train Loss 2.5134745 Test MSE 4.94666364814089 Test RE 1.0630758464107062\n",
      "25 Train Loss 2.3409762 Test MSE 4.848592485382599 Test RE 1.0524849692571774\n",
      "26 Train Loss 2.2326932 Test MSE 4.803307911435995 Test RE 1.0475584733333438\n",
      "27 Train Loss 2.1310706 Test MSE 4.788412828853208 Test RE 1.0459329700696587\n",
      "28 Train Loss 2.0469828 Test MSE 4.73295117842063 Test RE 1.0398580843945808\n",
      "29 Train Loss 1.9830433 Test MSE 4.64872542794108 Test RE 1.0305640965912142\n",
      "30 Train Loss 1.9369155 Test MSE 4.612254416398243 Test RE 1.0265135536209804\n",
      "31 Train Loss 1.8767776 Test MSE 4.458506815392228 Test RE 1.0092593411822965\n",
      "32 Train Loss 1.7974436 Test MSE 4.184752423238245 Test RE 0.9777840419804241\n",
      "33 Train Loss 1.6669313 Test MSE 3.8811197515573097 Test RE 0.9416436494286041\n",
      "34 Train Loss 1.4977968 Test MSE 3.682353025293656 Test RE 0.917214203053817\n",
      "35 Train Loss 1.3384609 Test MSE 3.4721286189503577 Test RE 0.8906477241961983\n",
      "36 Train Loss 1.2124618 Test MSE 3.3821806557436678 Test RE 0.8790355939855072\n",
      "37 Train Loss 1.1266959 Test MSE 3.3030663695482056 Test RE 0.8686937769546441\n",
      "38 Train Loss 1.0613086 Test MSE 3.214788769116917 Test RE 0.8570068268710371\n",
      "39 Train Loss 1.0047715 Test MSE 3.1272425211046153 Test RE 0.8452571274762812\n",
      "40 Train Loss 0.96229875 Test MSE 3.1053389002821996 Test RE 0.8422917794919305\n",
      "41 Train Loss 0.91870654 Test MSE 3.012201359434705 Test RE 0.8295643120272382\n",
      "42 Train Loss 0.89122695 Test MSE 2.961459022812171 Test RE 0.8225473814869786\n",
      "43 Train Loss 0.8657402 Test MSE 2.943176286664869 Test RE 0.8200044290636366\n",
      "44 Train Loss 0.83909214 Test MSE 2.871294812065538 Test RE 0.8099290074315494\n",
      "45 Train Loss 0.8107358 Test MSE 2.83773896929134 Test RE 0.8051824167492995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 0.78892714 Test MSE 2.8215080573073856 Test RE 0.8028764284145339\n",
      "47 Train Loss 0.7722902 Test MSE 2.7745792686390933 Test RE 0.7961715025067144\n",
      "48 Train Loss 0.75741684 Test MSE 2.7689198654512324 Test RE 0.7953590990509649\n",
      "49 Train Loss 0.74399215 Test MSE 2.781667934950964 Test RE 0.7971879077670005\n",
      "50 Train Loss 0.7332563 Test MSE 2.793843684873649 Test RE 0.7989307042637215\n",
      "51 Train Loss 0.7241212 Test MSE 2.8005594009016583 Test RE 0.7998903448052351\n",
      "52 Train Loss 0.71255463 Test MSE 2.798249662308606 Test RE 0.7995604252378118\n",
      "53 Train Loss 0.70185137 Test MSE 2.8049581546478324 Test RE 0.8005182800893681\n",
      "54 Train Loss 0.69300556 Test MSE 2.812311429163213 Test RE 0.8015668835858334\n",
      "55 Train Loss 0.6805928 Test MSE 2.827198241507073 Test RE 0.8036856080524214\n",
      "56 Train Loss 0.6708878 Test MSE 2.818559745179364 Test RE 0.8024568391443914\n",
      "57 Train Loss 0.66302913 Test MSE 2.799332684331452 Test RE 0.7997151394131526\n",
      "58 Train Loss 0.6538017 Test MSE 2.805321411681746 Test RE 0.8005701141035954\n",
      "59 Train Loss 0.644815 Test MSE 2.8228370633403888 Test RE 0.8030654943281108\n",
      "60 Train Loss 0.6368425 Test MSE 2.8091258358789366 Test RE 0.8011127749899014\n",
      "61 Train Loss 0.6296997 Test MSE 2.81406574664163 Test RE 0.8018168529794713\n",
      "62 Train Loss 0.6216221 Test MSE 2.8114115938964077 Test RE 0.8014386375018708\n",
      "63 Train Loss 0.6147703 Test MSE 2.797965784856592 Test RE 0.7995198672175244\n",
      "64 Train Loss 0.6070418 Test MSE 2.804655617617106 Test RE 0.8004751077957128\n",
      "65 Train Loss 0.59898317 Test MSE 2.819795000801305 Test RE 0.8026326613427373\n",
      "66 Train Loss 0.5936395 Test MSE 2.8100168735535527 Test RE 0.8012398189725909\n",
      "67 Train Loss 0.58843255 Test MSE 2.8112277926190226 Test RE 0.801412439300706\n",
      "68 Train Loss 0.58173865 Test MSE 2.8286476977788375 Test RE 0.8038915995989776\n",
      "69 Train Loss 0.5740983 Test MSE 2.836107432349226 Test RE 0.8049509166448282\n",
      "70 Train Loss 0.5683101 Test MSE 2.8202489637858785 Test RE 0.8026972672546209\n",
      "71 Train Loss 0.56215 Test MSE 2.826076892208387 Test RE 0.8035262096665532\n",
      "72 Train Loss 0.5567479 Test MSE 2.8247335321421394 Test RE 0.8033352110899743\n",
      "73 Train Loss 0.5506344 Test MSE 2.818148835133424 Test RE 0.8023983430284298\n",
      "74 Train Loss 0.54389894 Test MSE 2.822823215275085 Test RE 0.8030635245160389\n",
      "75 Train Loss 0.53817326 Test MSE 2.838115096866501 Test RE 0.8052357763568205\n",
      "76 Train Loss 0.53281367 Test MSE 2.8420494267136367 Test RE 0.8057937110901349\n",
      "77 Train Loss 0.5291984 Test MSE 2.83473242236195 Test RE 0.8047557636471044\n",
      "78 Train Loss 0.5253488 Test MSE 2.8317973870421214 Test RE 0.8043390403121725\n",
      "79 Train Loss 0.52112734 Test MSE 2.8431848680444927 Test RE 0.8059546583472721\n",
      "80 Train Loss 0.5172397 Test MSE 2.8557220187400443 Test RE 0.807729650309101\n",
      "81 Train Loss 0.51346296 Test MSE 2.8585069271625048 Test RE 0.8081234044876242\n",
      "82 Train Loss 0.50958306 Test MSE 2.8746226805831774 Test RE 0.810398230707307\n",
      "83 Train Loss 0.5055408 Test MSE 2.8902765740816987 Test RE 0.8126017658259296\n",
      "84 Train Loss 0.5019641 Test MSE 2.894181088222624 Test RE 0.8131504579973651\n",
      "85 Train Loss 0.4980584 Test MSE 2.9118612543800317 Test RE 0.81563039020324\n",
      "86 Train Loss 0.49397796 Test MSE 2.9285341309562316 Test RE 0.8179621451970202\n",
      "87 Train Loss 0.4900052 Test MSE 2.928263107438386 Test RE 0.8179242948429813\n",
      "88 Train Loss 0.48626873 Test MSE 2.93540198444095 Test RE 0.8189207057292069\n",
      "89 Train Loss 0.4824648 Test MSE 2.952050028650827 Test RE 0.8212396644976017\n",
      "90 Train Loss 0.47839403 Test MSE 2.9620136891114903 Test RE 0.8226244073630352\n",
      "91 Train Loss 0.47528362 Test MSE 2.962682283593044 Test RE 0.8227172447303389\n",
      "92 Train Loss 0.47134742 Test MSE 2.963151609624535 Test RE 0.8227824065148461\n",
      "93 Train Loss 0.46747118 Test MSE 2.963798234250074 Test RE 0.8228721761948258\n",
      "94 Train Loss 0.46373415 Test MSE 2.9643469362132846 Test RE 0.8229483437756091\n",
      "95 Train Loss 0.460401 Test MSE 2.966230665700767 Test RE 0.8232097784015563\n",
      "96 Train Loss 0.45653963 Test MSE 2.971477192103352 Test RE 0.8239374837293879\n",
      "97 Train Loss 0.45344657 Test MSE 2.975074162535219 Test RE 0.8244360206918074\n",
      "98 Train Loss 0.45058385 Test MSE 2.9811246636042643 Test RE 0.8252739355029113\n",
      "99 Train Loss 0.44773665 Test MSE 2.9920466414584364 Test RE 0.8267843357587408\n",
      "Training time: 156.53\n",
      "9\n",
      "KG_rowdy_tune25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.00065 Test MSE 8.466481461042397 Test RE 1.3907835368265704\n",
      "1 Train Loss 52.92886 Test MSE 7.901935860295269 Test RE 1.3436148971678763\n",
      "2 Train Loss 47.678818 Test MSE 8.184812503917438 Test RE 1.3674530613581013\n",
      "3 Train Loss 43.37439 Test MSE 8.857263378193977 Test RE 1.4225182268995349\n",
      "4 Train Loss 40.941284 Test MSE 8.890222712767427 Test RE 1.4251624814624417\n",
      "5 Train Loss 38.780415 Test MSE 9.152243911831725 Test RE 1.44601185388425\n",
      "6 Train Loss 36.338047 Test MSE 9.33966891339158 Test RE 1.4607429561305856\n",
      "7 Train Loss 34.09122 Test MSE 9.542128043232198 Test RE 1.4764905791048784\n",
      "8 Train Loss 32.322647 Test MSE 9.430372210685398 Test RE 1.4678189067444694\n",
      "9 Train Loss 29.777538 Test MSE 9.24240722906088 Test RE 1.4531170892773912\n",
      "10 Train Loss 28.240582 Test MSE 9.141863126282372 Test RE 1.4451915633664498\n",
      "11 Train Loss 26.662018 Test MSE 8.852736155690197 Test RE 1.4221546338012796\n",
      "12 Train Loss 25.339256 Test MSE 8.818538788006393 Test RE 1.419405144705856\n",
      "13 Train Loss 23.441021 Test MSE 8.680018781328313 Test RE 1.4082131410624887\n",
      "14 Train Loss 21.470821 Test MSE 8.530624461118288 Test RE 1.396041960977301\n",
      "15 Train Loss 19.922104 Test MSE 8.51121458029531 Test RE 1.3944528370306364\n",
      "16 Train Loss 18.817768 Test MSE 8.426530525678714 Test RE 1.3874982993170482\n",
      "17 Train Loss 17.305882 Test MSE 8.282059560193616 Test RE 1.3755527041090276\n",
      "18 Train Loss 16.032852 Test MSE 8.251524057342293 Test RE 1.373014568478537\n",
      "19 Train Loss 14.911611 Test MSE 8.23991646594739 Test RE 1.372048504464743\n",
      "20 Train Loss 13.968022 Test MSE 8.16105978429308 Test RE 1.3654674124158832\n",
      "21 Train Loss 12.876292 Test MSE 8.124343759040844 Test RE 1.3623923797334365\n",
      "22 Train Loss 11.8696995 Test MSE 8.104933591112262 Test RE 1.3607639356832373\n",
      "23 Train Loss 11.083017 Test MSE 7.979007717576222 Test RE 1.350151498745448\n",
      "24 Train Loss 10.5314045 Test MSE 7.956881245276812 Test RE 1.348278156193695\n",
      "25 Train Loss 10.011474 Test MSE 7.840866815708059 Test RE 1.3384128536738222\n",
      "26 Train Loss 9.553366 Test MSE 7.846013287291327 Test RE 1.3388520253861464\n",
      "27 Train Loss 8.860367 Test MSE 7.743605939910727 Test RE 1.3300858780034637\n",
      "28 Train Loss 8.09181 Test MSE 7.643217613858479 Test RE 1.3214361171763538\n",
      "29 Train Loss 7.3668013 Test MSE 7.6780223494263735 Test RE 1.3244413956722958\n",
      "30 Train Loss 6.864017 Test MSE 7.628694638995524 Test RE 1.3201800814655449\n",
      "31 Train Loss 6.2969313 Test MSE 7.406121024801301 Test RE 1.3007788371449451\n",
      "32 Train Loss 5.7609844 Test MSE 7.283360231826241 Test RE 1.2899532039113426\n",
      "33 Train Loss 5.297937 Test MSE 7.242086895372531 Test RE 1.2862930586340646\n",
      "34 Train Loss 4.9590592 Test MSE 7.174990293655379 Test RE 1.2803205587335684\n",
      "35 Train Loss 4.571559 Test MSE 7.013608068353487 Test RE 1.2658399760461523\n",
      "36 Train Loss 4.1077724 Test MSE 6.926149872027404 Test RE 1.2579228401480604\n",
      "37 Train Loss 3.7597077 Test MSE 6.910213865112314 Test RE 1.2564748631637608\n",
      "38 Train Loss 3.467898 Test MSE 6.641662761990006 Test RE 1.2318177854064178\n",
      "39 Train Loss 3.1719794 Test MSE 6.490646069178197 Test RE 1.21773285669346\n",
      "40 Train Loss 2.9196324 Test MSE 6.383668147981082 Test RE 1.2076559111183003\n",
      "41 Train Loss 2.7247653 Test MSE 6.205603100666817 Test RE 1.1906937061150402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 2.5098016 Test MSE 6.179016116605772 Test RE 1.1881402931524556\n",
      "43 Train Loss 2.354122 Test MSE 6.051476556466595 Test RE 1.1758143004872212\n",
      "44 Train Loss 2.2076993 Test MSE 6.006093890116001 Test RE 1.1713970305890784\n",
      "45 Train Loss 2.104316 Test MSE 5.94383276131608 Test RE 1.1653096717059768\n",
      "46 Train Loss 1.9634575 Test MSE 5.803835981711912 Test RE 1.1515044631487914\n",
      "47 Train Loss 1.8524868 Test MSE 5.796616368770445 Test RE 1.1507880401223878\n",
      "48 Train Loss 1.7725551 Test MSE 5.764476066938717 Test RE 1.1475932377654006\n",
      "49 Train Loss 1.6996057 Test MSE 5.685924318061564 Test RE 1.139747367194622\n",
      "50 Train Loss 1.6419414 Test MSE 5.663536518379663 Test RE 1.1375013293443057\n",
      "51 Train Loss 1.5879307 Test MSE 5.664687713546562 Test RE 1.1376169302142063\n",
      "52 Train Loss 1.5287386 Test MSE 5.605726412117781 Test RE 1.1316809605604328\n",
      "53 Train Loss 1.4907134 Test MSE 5.550511326307541 Test RE 1.1260937728369411\n",
      "54 Train Loss 1.4633563 Test MSE 5.530372818545655 Test RE 1.1240490553019618\n",
      "55 Train Loss 1.4306428 Test MSE 5.547748714017609 Test RE 1.1258134970651814\n",
      "56 Train Loss 1.4056095 Test MSE 5.585105576287421 Test RE 1.129597581361764\n",
      "57 Train Loss 1.3764474 Test MSE 5.593554580057284 Test RE 1.130451671526315\n",
      "58 Train Loss 1.3519028 Test MSE 5.570672832066772 Test RE 1.128137113082215\n",
      "59 Train Loss 1.3279538 Test MSE 5.564481177619331 Test RE 1.1275099916030253\n",
      "60 Train Loss 1.3009548 Test MSE 5.558523608536431 Test RE 1.1269062500007148\n",
      "61 Train Loss 1.2812467 Test MSE 5.6057162678969545 Test RE 1.1316799366051131\n",
      "62 Train Loss 1.2614685 Test MSE 5.615844196788757 Test RE 1.1327017865438282\n",
      "63 Train Loss 1.2436442 Test MSE 5.575517571478129 Test RE 1.128627569324194\n",
      "64 Train Loss 1.2259272 Test MSE 5.557835542008316 Test RE 1.1268365003223368\n",
      "65 Train Loss 1.2067984 Test MSE 5.581428460542614 Test RE 1.1292256685222626\n",
      "66 Train Loss 1.1920432 Test MSE 5.601156609962437 Test RE 1.131219591942966\n",
      "67 Train Loss 1.1789693 Test MSE 5.587864672969136 Test RE 1.1298765630277923\n",
      "68 Train Loss 1.1637398 Test MSE 5.572537524451265 Test RE 1.1283259100855036\n",
      "69 Train Loss 1.1540918 Test MSE 5.597500686452809 Test RE 1.1308503532612855\n",
      "70 Train Loss 1.144465 Test MSE 5.619406148524222 Test RE 1.1330609479981442\n",
      "71 Train Loss 1.134119 Test MSE 5.628177260006549 Test RE 1.1339448784895207\n",
      "72 Train Loss 1.1226659 Test MSE 5.62441220064139 Test RE 1.133565529737534\n",
      "73 Train Loss 1.1133691 Test MSE 5.606777784379664 Test RE 1.1317870808114439\n",
      "74 Train Loss 1.1035365 Test MSE 5.615819534518117 Test RE 1.1326992993818183\n",
      "75 Train Loss 1.0907388 Test MSE 5.6372214380596715 Test RE 1.1348556069694364\n",
      "76 Train Loss 1.0772748 Test MSE 5.659716023806158 Test RE 1.1371175981908943\n",
      "77 Train Loss 1.0696161 Test MSE 5.6665314653218966 Test RE 1.1378020518568726\n",
      "78 Train Loss 1.0585715 Test MSE 5.672725682980123 Test RE 1.1384237609772934\n",
      "79 Train Loss 1.0487199 Test MSE 5.675550736179459 Test RE 1.1387071968031246\n",
      "80 Train Loss 1.0347457 Test MSE 5.719165337495688 Test RE 1.1430741044825248\n",
      "81 Train Loss 1.0247334 Test MSE 5.7400128860167845 Test RE 1.145155580917229\n",
      "82 Train Loss 1.0158488 Test MSE 5.738789716088567 Test RE 1.1450335607643831\n",
      "83 Train Loss 1.0051672 Test MSE 5.753806857107771 Test RE 1.1465307315125997\n",
      "84 Train Loss 0.99375033 Test MSE 5.766962904534643 Test RE 1.1478407511773498\n",
      "85 Train Loss 0.9851203 Test MSE 5.779085982069589 Test RE 1.1490465901303861\n",
      "86 Train Loss 0.9775289 Test MSE 5.807797672047989 Test RE 1.1518974037742862\n",
      "87 Train Loss 0.97181565 Test MSE 5.826713964201909 Test RE 1.1537717729762338\n",
      "88 Train Loss 0.9659697 Test MSE 5.832414541951622 Test RE 1.1543360325081233\n",
      "89 Train Loss 0.9594691 Test MSE 5.836090420490916 Test RE 1.1546997352816655\n",
      "90 Train Loss 0.95370495 Test MSE 5.8475342934649355 Test RE 1.155831294647797\n",
      "91 Train Loss 0.9483251 Test MSE 5.865519906818896 Test RE 1.1576074598892496\n",
      "92 Train Loss 0.9432731 Test MSE 5.875751185419987 Test RE 1.1586166325037088\n",
      "93 Train Loss 0.93697095 Test MSE 5.886891983810698 Test RE 1.1597145177905908\n",
      "94 Train Loss 0.92990196 Test MSE 5.911169533390338 Test RE 1.1621033894262423\n",
      "95 Train Loss 0.92254055 Test MSE 5.918396468159048 Test RE 1.162813560226394\n",
      "96 Train Loss 0.9170406 Test MSE 5.9041726423243635 Test RE 1.161415410647575\n",
      "97 Train Loss 0.91171443 Test MSE 5.914836858698405 Test RE 1.1624638215148653\n",
      "98 Train Loss 0.9042692 Test MSE 5.956911214650243 Test RE 1.1665910060268956\n",
      "99 Train Loss 0.8995632 Test MSE 5.971829362104925 Test RE 1.1680508644701215\n",
      "Training time: 156.83\n",
      "0\n",
      "KG_rowdy_tune26\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.66\n",
      "0\n",
      "KG_rowdy_tune27\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 75.08797 Test MSE 4.442806366718069 Test RE 1.0074807413210138\n",
      "1 Train Loss 66.78706 Test MSE 4.767176428646634 Test RE 1.0436110594654515\n",
      "2 Train Loss 43.217686 Test MSE 6.544749184882959 Test RE 1.222797561894035\n",
      "3 Train Loss 31.329323 Test MSE 6.435510498657678 Test RE 1.2125497372519858\n",
      "4 Train Loss 24.571192 Test MSE 5.802436984725369 Test RE 1.151365671462617\n",
      "5 Train Loss 21.188276 Test MSE 5.691437751844234 Test RE 1.140299819065433\n",
      "6 Train Loss 19.260387 Test MSE 5.474851035953601 Test RE 1.1183924170638657\n",
      "7 Train Loss 17.040447 Test MSE 5.30960003112144 Test RE 1.1013845091110102\n",
      "8 Train Loss 15.404613 Test MSE 5.266159731252925 Test RE 1.096869787201991\n",
      "9 Train Loss 14.146149 Test MSE 5.586276613908347 Test RE 1.1297159973804982\n",
      "10 Train Loss 13.242096 Test MSE 5.466111632885473 Test RE 1.1174994260290778\n",
      "11 Train Loss 12.541031 Test MSE 5.465462643383313 Test RE 1.1174330839038906\n",
      "12 Train Loss 11.767939 Test MSE 5.586099275377544 Test RE 1.1296980656006157\n",
      "13 Train Loss 11.035748 Test MSE 5.490127487586869 Test RE 1.1199516527450128\n",
      "14 Train Loss 10.655972 Test MSE 5.308820150103671 Test RE 1.1013036197398631\n",
      "15 Train Loss 9.800813 Test MSE 5.180740876717042 Test RE 1.0879376228868514\n",
      "16 Train Loss 9.158995 Test MSE 5.21604808106192 Test RE 1.0916385233555896\n",
      "17 Train Loss 8.310268 Test MSE 5.050134658779186 Test RE 1.0741366607998486\n",
      "18 Train Loss 7.4770784 Test MSE 5.043952428844539 Test RE 1.0734789958257733\n",
      "19 Train Loss 6.889884 Test MSE 5.026606631829496 Test RE 1.0716315968735974\n",
      "20 Train Loss 6.1928825 Test MSE 4.887222547957365 Test RE 1.0566693690469235\n",
      "21 Train Loss 5.39412 Test MSE 4.861093442065135 Test RE 1.0538408884606874\n",
      "22 Train Loss 4.8518686 Test MSE 4.759735522578567 Test RE 1.0427962748090402\n",
      "23 Train Loss 4.2248583 Test MSE 4.738634543065504 Test RE 1.0404822319246243\n",
      "24 Train Loss 3.83256 Test MSE 4.6285424534832496 Test RE 1.028324506994494\n",
      "25 Train Loss 3.330861 Test MSE 4.5322425842894605 Test RE 1.0175707947096628\n",
      "26 Train Loss 3.0469365 Test MSE 4.51233692624149 Test RE 1.0153337447969426\n",
      "27 Train Loss 2.7799258 Test MSE 4.445523079661091 Test RE 1.0077887243228758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 2.646853 Test MSE 4.367541089908081 Test RE 0.9989104581927307\n",
      "29 Train Loss 2.4764931 Test MSE 4.343947689507756 Test RE 0.9962087539302852\n",
      "30 Train Loss 2.296543 Test MSE 4.273730023468897 Test RE 0.9881243513405623\n",
      "31 Train Loss 2.171723 Test MSE 4.26725668115438 Test RE 0.9873757206210156\n",
      "32 Train Loss 2.0348294 Test MSE 4.181803942890674 Test RE 0.9774395192059409\n",
      "33 Train Loss 1.9313841 Test MSE 4.155712539259416 Test RE 0.9743854935248376\n",
      "34 Train Loss 1.8404206 Test MSE 4.173971644005174 Test RE 0.9765237437946946\n",
      "35 Train Loss 1.7621454 Test MSE 4.141999738922473 Test RE 0.9727765523074413\n",
      "36 Train Loss 1.6827959 Test MSE 4.068358990863114 Test RE 0.9640902577014052\n",
      "37 Train Loss 1.622761 Test MSE 3.985377727581495 Test RE 0.9542074543494795\n",
      "38 Train Loss 1.5795821 Test MSE 3.913944981130319 Test RE 0.9456173206789261\n",
      "39 Train Loss 1.5274177 Test MSE 3.8626175890429066 Test RE 0.9393964554796339\n",
      "40 Train Loss 1.4561702 Test MSE 3.8156803331931486 Test RE 0.9336713919945546\n",
      "41 Train Loss 1.4031527 Test MSE 3.72734870960031 Test RE 0.9228010344122732\n",
      "42 Train Loss 1.3394458 Test MSE 3.6365209969952166 Test RE 0.9114883244944183\n",
      "43 Train Loss 1.2866622 Test MSE 3.613734827519417 Test RE 0.90862817814165\n",
      "44 Train Loss 1.2482378 Test MSE 3.552018829506676 Test RE 0.9008359096400156\n",
      "45 Train Loss 1.1929015 Test MSE 3.4659556166570664 Test RE 0.8898556428975133\n",
      "46 Train Loss 1.1529936 Test MSE 3.4054886025252404 Test RE 0.8820592848250087\n",
      "47 Train Loss 1.1179705 Test MSE 3.3981211256434807 Test RE 0.8811046391460432\n",
      "48 Train Loss 1.0580673 Test MSE 3.3040271030063653 Test RE 0.8688201023754698\n",
      "49 Train Loss 0.99160224 Test MSE 3.142322162877097 Test RE 0.8472926021706831\n",
      "50 Train Loss 0.94551843 Test MSE 3.0964786845633485 Test RE 0.8410892991786526\n",
      "51 Train Loss 0.89093965 Test MSE 3.0817275434870206 Test RE 0.8390834984350776\n",
      "52 Train Loss 0.85101765 Test MSE 3.0667208331677025 Test RE 0.8370380142803122\n",
      "53 Train Loss 0.81415623 Test MSE 3.0435935197174087 Test RE 0.8338758294577456\n",
      "54 Train Loss 0.7885697 Test MSE 3.03305388952467 Test RE 0.8324307671280453\n",
      "55 Train Loss 0.7439001 Test MSE 3.0224047512946837 Test RE 0.8309681381497649\n",
      "56 Train Loss 0.7190024 Test MSE 2.986101876336517 Test RE 0.8259625767642441\n",
      "57 Train Loss 0.6913737 Test MSE 2.9723389487268657 Test RE 0.8240569499184933\n",
      "58 Train Loss 0.6622826 Test MSE 2.991291654513603 Test RE 0.8266800174047045\n",
      "59 Train Loss 0.6460618 Test MSE 3.0062293018868402 Test RE 0.8287415476704443\n",
      "60 Train Loss 0.6300624 Test MSE 3.028113413840905 Test RE 0.8317525266134558\n",
      "61 Train Loss 0.61505514 Test MSE 2.9927425930737432 Test RE 0.8268804854026339\n",
      "62 Train Loss 0.5951172 Test MSE 3.001260687199111 Test RE 0.8280564036204252\n",
      "63 Train Loss 0.57598877 Test MSE 3.0650016492999677 Test RE 0.8368033623406153\n",
      "64 Train Loss 0.5621908 Test MSE 3.065774004071096 Test RE 0.8369087894222867\n",
      "65 Train Loss 0.5521499 Test MSE 3.0656013550571415 Test RE 0.83688522383797\n",
      "66 Train Loss 0.53960705 Test MSE 3.0864591006263895 Test RE 0.8397273984426172\n",
      "67 Train Loss 0.53075564 Test MSE 3.0839959610992054 Test RE 0.839392260585975\n",
      "68 Train Loss 0.51968384 Test MSE 3.0790124324263384 Test RE 0.8387137858515928\n",
      "69 Train Loss 0.5122117 Test MSE 3.0857242941503973 Test RE 0.8396274337517103\n",
      "70 Train Loss 0.5044597 Test MSE 3.0855500823446698 Test RE 0.8396037318486833\n",
      "71 Train Loss 0.49610317 Test MSE 3.0836087053295276 Test RE 0.8393395579065516\n",
      "72 Train Loss 0.4923877 Test MSE 3.0987236150436863 Test RE 0.84139413655836\n",
      "73 Train Loss 0.48595306 Test MSE 3.1101106778596255 Test RE 0.8429386792857285\n",
      "74 Train Loss 0.48004788 Test MSE 3.1204183773380354 Test RE 0.8443343806287394\n",
      "75 Train Loss 0.47361162 Test MSE 3.1430246840782106 Test RE 0.8473873104342379\n",
      "76 Train Loss 0.4666812 Test MSE 3.1505591866647884 Test RE 0.8484023867961752\n",
      "77 Train Loss 0.45764357 Test MSE 3.159626302449954 Test RE 0.8496223346669006\n",
      "78 Train Loss 0.45210072 Test MSE 3.1806847707320833 Test RE 0.8524489398906895\n",
      "79 Train Loss 0.447084 Test MSE 3.1923753932839682 Test RE 0.8540140931677049\n",
      "80 Train Loss 0.44279686 Test MSE 3.1922693676390987 Test RE 0.8539999112286104\n",
      "81 Train Loss 0.43750912 Test MSE 3.213117493312959 Test RE 0.856784031366102\n",
      "82 Train Loss 0.43208125 Test MSE 3.2090079320255787 Test RE 0.8562359448033996\n",
      "83 Train Loss 0.42717603 Test MSE 3.2012292928587245 Test RE 0.8551975566673816\n",
      "84 Train Loss 0.42179573 Test MSE 3.2127611660028057 Test RE 0.8567365223636262\n",
      "85 Train Loss 0.41565117 Test MSE 3.2249716248435405 Test RE 0.8583630399691853\n",
      "86 Train Loss 0.40962088 Test MSE 3.2228809606504054 Test RE 0.8580847677833843\n",
      "87 Train Loss 0.4042303 Test MSE 3.232747461139232 Test RE 0.8593972307820967\n",
      "88 Train Loss 0.3985328 Test MSE 3.2332780270310297 Test RE 0.8594677510062391\n",
      "89 Train Loss 0.39551768 Test MSE 3.23740899489624 Test RE 0.8600166212719697\n",
      "90 Train Loss 0.39217132 Test MSE 3.246108100317317 Test RE 0.8611713033468745\n",
      "91 Train Loss 0.38761002 Test MSE 3.2423088410210568 Test RE 0.8606671964478524\n",
      "92 Train Loss 0.38551232 Test MSE 3.2386198803590003 Test RE 0.8601774418954217\n",
      "93 Train Loss 0.38136172 Test MSE 3.2515746234461975 Test RE 0.8618961147881995\n",
      "94 Train Loss 0.37866065 Test MSE 3.2497646744089828 Test RE 0.8616561994592737\n",
      "95 Train Loss 0.3737257 Test MSE 3.245200637337337 Test RE 0.8610509229286539\n",
      "96 Train Loss 0.370015 Test MSE 3.2550089204918833 Test RE 0.8623511598739838\n",
      "97 Train Loss 0.36698171 Test MSE 3.263422920686211 Test RE 0.8634650031981064\n",
      "98 Train Loss 0.36455926 Test MSE 3.2706017265314355 Test RE 0.8644141971265115\n",
      "99 Train Loss 0.3620784 Test MSE 3.2779539230449335 Test RE 0.8653852379226569\n",
      "Training time: 156.03\n",
      "1\n",
      "KG_rowdy_tune27\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 59.189133 Test MSE 6.259776888050225 Test RE 1.1958796823919988\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.19\n",
      "0\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 74.01472 Test MSE 4.461545028176275 Test RE 1.0096031583562768\n",
      "1 Train Loss 67.908424 Test MSE 4.70392082320205 Test RE 1.0366641065896\n",
      "2 Train Loss 46.432415 Test MSE 5.758772898350144 Test RE 1.1470254032164453\n",
      "3 Train Loss 36.55641 Test MSE 6.204520423122168 Test RE 1.1905898327645876\n",
      "4 Train Loss 29.164148 Test MSE 5.440582939577121 Test RE 1.1148868113053079\n",
      "5 Train Loss 23.59817 Test MSE 5.452280225126058 Test RE 1.1160846744221373\n",
      "6 Train Loss 19.616219 Test MSE 4.69194687129706 Test RE 1.0353438382355722\n",
      "7 Train Loss 16.788204 Test MSE 4.865977746385812 Test RE 1.054370191934387\n",
      "8 Train Loss 15.673694 Test MSE 4.955458290151855 Test RE 1.0640204446598762\n",
      "9 Train Loss 14.915263 Test MSE 5.068862655663104 Test RE 1.0761264901685428\n",
      "10 Train Loss 14.087098 Test MSE 5.093667108306971 Test RE 1.0787562865202236\n",
      "11 Train Loss 13.590591 Test MSE 5.1574764303114735 Test RE 1.0854921478629662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 13.015439 Test MSE 5.147448239443834 Test RE 1.0844363195726205\n",
      "13 Train Loss 12.448219 Test MSE 5.323051427758045 Test RE 1.102778756176811\n",
      "14 Train Loss 12.112034 Test MSE 5.306158214755286 Test RE 1.1010274786640006\n",
      "15 Train Loss 11.752778 Test MSE 5.296588766770197 Test RE 1.100034200715423\n",
      "16 Train Loss 11.166772 Test MSE 5.382185166843978 Test RE 1.1088872188534766\n",
      "17 Train Loss 10.742174 Test MSE 5.44072978422428 Test RE 1.1149018569408182\n",
      "18 Train Loss 10.51897 Test MSE 5.379421713556432 Test RE 1.1086025062896294\n",
      "19 Train Loss 10.289316 Test MSE 5.261769770014686 Test RE 1.0964125071321529\n",
      "20 Train Loss 9.860146 Test MSE 5.062736661919303 Test RE 1.0754760151409481\n",
      "21 Train Loss 9.25202 Test MSE 4.895717772410241 Test RE 1.0575873491311167\n",
      "22 Train Loss 8.848852 Test MSE 4.74720200320829 Test RE 1.0414224040718307\n",
      "23 Train Loss 8.257033 Test MSE 4.585865602558877 Test RE 1.0235727647739212\n",
      "24 Train Loss 7.5866632 Test MSE 4.362640783445179 Test RE 0.9983499206887241\n",
      "25 Train Loss 6.8750253 Test MSE 4.350477618785998 Test RE 0.9969572355334319\n",
      "26 Train Loss 6.5900564 Test MSE 4.382606190370415 Test RE 1.000631762176931\n",
      "27 Train Loss 6.308329 Test MSE 4.495633462641159 Test RE 1.0134527555658042\n",
      "28 Train Loss 6.14437 Test MSE 4.450894972289665 Test RE 1.0083974376558908\n",
      "29 Train Loss 5.948803 Test MSE 4.477860887027666 Test RE 1.0114475317724934\n",
      "30 Train Loss 5.730027 Test MSE 4.559893790183524 Test RE 1.0206701735945631\n",
      "31 Train Loss 5.5468025 Test MSE 4.572625398108166 Test RE 1.022094078962092\n",
      "32 Train Loss 5.4171104 Test MSE 4.629164881502478 Test RE 1.0283936471693744\n",
      "33 Train Loss 5.3427844 Test MSE 4.592207409198629 Test RE 1.0242802711052443\n",
      "34 Train Loss 5.261488 Test MSE 4.600951335000281 Test RE 1.025254962642914\n",
      "35 Train Loss 5.156752 Test MSE 4.570895209375581 Test RE 1.0219006908294663\n",
      "36 Train Loss 5.1161757 Test MSE 4.562323774795029 Test RE 1.0209420968661003\n",
      "37 Train Loss 5.0681496 Test MSE 4.526792872724192 Test RE 1.0169588310692053\n",
      "38 Train Loss 5.0080843 Test MSE 4.546075788271172 Test RE 1.0191225143779192\n",
      "39 Train Loss 4.9256105 Test MSE 4.547278170277326 Test RE 1.019257278250867\n",
      "40 Train Loss 4.8645887 Test MSE 4.554327837863908 Test RE 1.0200470520435256\n",
      "41 Train Loss 4.798932 Test MSE 4.578656860878761 Test RE 1.0227679468513151\n",
      "42 Train Loss 4.6915455 Test MSE 4.557891445414467 Test RE 1.0204460501732844\n",
      "43 Train Loss 4.573965 Test MSE 4.550687895411004 Test RE 1.0196393459162287\n",
      "44 Train Loss 4.4090314 Test MSE 4.555057118656275 Test RE 1.0201287184245131\n",
      "45 Train Loss 4.063384 Test MSE 4.574898670070582 Test RE 1.0223481134501078\n",
      "46 Train Loss 3.8832436 Test MSE 4.533448632508368 Test RE 1.0177061755712633\n",
      "47 Train Loss 3.57983 Test MSE 4.445314262808504 Test RE 1.007765054921432\n",
      "48 Train Loss 3.3531525 Test MSE 4.321834043120541 Test RE 0.9936698287458734\n",
      "49 Train Loss 3.0687962 Test MSE 4.276791733466353 Test RE 0.9884782352476719\n",
      "50 Train Loss 2.9013453 Test MSE 4.20184092875529 Test RE 0.9797784066778216\n",
      "51 Train Loss 2.7859142 Test MSE 4.006143394063929 Test RE 0.956690156255776\n",
      "52 Train Loss 2.6091757 Test MSE 3.8403208371700326 Test RE 0.9366812237191633\n",
      "53 Train Loss 2.4897208 Test MSE 3.825441597489508 Test RE 0.9348648871432194\n",
      "54 Train Loss 2.3820677 Test MSE 3.783629967681636 Test RE 0.9297418681754233\n",
      "55 Train Loss 2.306906 Test MSE 3.788068193188414 Test RE 0.9302870053509636\n",
      "56 Train Loss 2.1784608 Test MSE 3.530563475465569 Test RE 0.8981111171668419\n",
      "57 Train Loss 2.0405684 Test MSE 3.225615939684142 Test RE 0.858448781564569\n",
      "58 Train Loss 1.9486196 Test MSE 3.0439245917908897 Test RE 0.8339211813568951\n",
      "59 Train Loss 1.8459387 Test MSE 2.9973965271253746 Test RE 0.8275231655218755\n",
      "60 Train Loss 1.7859749 Test MSE 2.97990538187666 Test RE 0.8251051494820698\n",
      "61 Train Loss 1.7205871 Test MSE 2.8899738929641487 Test RE 0.8125592152872373\n",
      "62 Train Loss 1.6422051 Test MSE 2.8772942038473523 Test RE 0.8107747140221473\n",
      "63 Train Loss 1.5656497 Test MSE 2.913736595962763 Test RE 0.815892995330298\n",
      "64 Train Loss 1.5220972 Test MSE 2.8871393291683716 Test RE 0.8121606276064143\n",
      "65 Train Loss 1.4262863 Test MSE 2.839297902359505 Test RE 0.8054035528658383\n",
      "66 Train Loss 1.3597282 Test MSE 2.808609676889551 Test RE 0.8010391719224712\n",
      "67 Train Loss 1.3249173 Test MSE 2.8069822227729784 Test RE 0.8008070564714344\n",
      "68 Train Loss 1.2764717 Test MSE 2.8342821130701674 Test RE 0.8046918416719602\n",
      "69 Train Loss 1.2238022 Test MSE 2.8142474069266488 Test RE 0.8018427329589237\n",
      "70 Train Loss 1.1989219 Test MSE 2.804257038032888 Test RE 0.8004182265925652\n",
      "71 Train Loss 1.1831696 Test MSE 2.7856427986449233 Test RE 0.7977572751701133\n",
      "72 Train Loss 1.155681 Test MSE 2.7543511504524267 Test RE 0.7932639423476012\n",
      "73 Train Loss 1.1094693 Test MSE 2.7161889994789785 Test RE 0.7877493496078906\n",
      "74 Train Loss 1.0844488 Test MSE 2.7071301235123837 Test RE 0.7864346245295908\n",
      "75 Train Loss 1.0673227 Test MSE 2.7086129949966815 Test RE 0.786649985773993\n",
      "76 Train Loss 1.051687 Test MSE 2.7021150617658627 Test RE 0.7857058367863906\n",
      "77 Train Loss 1.0260637 Test MSE 2.704790090110595 Test RE 0.7860946554366306\n",
      "78 Train Loss 1.0117925 Test MSE 2.7032140323815588 Test RE 0.7858655967948693\n",
      "79 Train Loss 0.9977305 Test MSE 2.6790273473296082 Test RE 0.7823419779600038\n",
      "80 Train Loss 0.97633666 Test MSE 2.6587007133952096 Test RE 0.7793683879189908\n",
      "81 Train Loss 0.9530206 Test MSE 2.651632552098083 Test RE 0.7783317222374705\n",
      "82 Train Loss 0.9383 Test MSE 2.656391065667416 Test RE 0.7790297906631302\n",
      "83 Train Loss 0.9255905 Test MSE 2.6778589292845134 Test RE 0.7821713559289902\n",
      "84 Train Loss 0.9116998 Test MSE 2.6810151096737 Test RE 0.7826321619274492\n",
      "85 Train Loss 0.8951314 Test MSE 2.661551846290954 Test RE 0.7797861648106076\n",
      "86 Train Loss 0.8772589 Test MSE 2.6916827795064515 Test RE 0.7841876498086957\n",
      "87 Train Loss 0.8644614 Test MSE 2.7328006584222866 Test RE 0.7901545351308908\n",
      "88 Train Loss 0.85107356 Test MSE 2.740201092399281 Test RE 0.7912236824630199\n",
      "89 Train Loss 0.84083027 Test MSE 2.7422033044076883 Test RE 0.7915126956093168\n",
      "90 Train Loss 0.8343214 Test MSE 2.746814553686582 Test RE 0.7921779142021288\n",
      "91 Train Loss 0.8258661 Test MSE 2.7367531828580858 Test RE 0.7907257397404058\n",
      "92 Train Loss 0.81264853 Test MSE 2.716872123652854 Test RE 0.7878484032438735\n",
      "93 Train Loss 0.7994971 Test MSE 2.7200500857663634 Test RE 0.7883090470508715\n",
      "94 Train Loss 0.7899672 Test MSE 2.7145938289815903 Test RE 0.7875179998987413\n",
      "95 Train Loss 0.783316 Test MSE 2.7142295190014627 Test RE 0.7874651540014478\n",
      "96 Train Loss 0.7721985 Test MSE 2.7352544825438088 Test RE 0.7905092015433857\n",
      "97 Train Loss 0.7575624 Test MSE 2.7257509280230274 Test RE 0.7891347070825185\n",
      "98 Train Loss 0.74906534 Test MSE 2.7128360100614364 Test RE 0.7872629823342262\n",
      "99 Train Loss 0.7422455 Test MSE 2.725662833951307 Test RE 0.7891219548808284\n",
      "Training time: 157.31\n",
      "1\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 60.642704 Test MSE 7.320261330085548 Test RE 1.2932168451784956\n",
      "1 Train Loss 45.459038 Test MSE 8.394854242736622 Test RE 1.3848879622161845\n",
      "2 Train Loss 43.85719 Test MSE 8.821870519001887 Test RE 1.4196732520216429\n",
      "3 Train Loss 41.544434 Test MSE 9.523653846443537 Test RE 1.4750605944777815\n",
      "4 Train Loss 39.800503 Test MSE 9.888079704812663 Test RE 1.503017507974165\n",
      "5 Train Loss 37.33174 Test MSE 9.661481949758251 Test RE 1.4856959302394788\n",
      "6 Train Loss 35.967243 Test MSE 9.459982247540191 Test RE 1.4701214727588068\n",
      "7 Train Loss 33.994427 Test MSE 9.763404337011893 Test RE 1.4935119365570677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 32.02444 Test MSE 10.054367374876385 Test RE 1.5156029264605104\n",
      "9 Train Loss 30.526443 Test MSE 9.800108229036237 Test RE 1.4963166077596095\n",
      "10 Train Loss 28.48653 Test MSE 9.886895906668736 Test RE 1.502927534862805\n",
      "11 Train Loss 27.387005 Test MSE 9.820994098274255 Test RE 1.4979102248450902\n",
      "12 Train Loss 25.537952 Test MSE 9.40842908951746 Test RE 1.4661102103437598\n",
      "13 Train Loss 24.573387 Test MSE 9.581585550750916 Test RE 1.4795401366019718\n",
      "14 Train Loss 23.532497 Test MSE 9.702367530929706 Test RE 1.488836204871455\n",
      "15 Train Loss 22.608639 Test MSE 9.773175885271105 Test RE 1.4942591285078466\n",
      "16 Train Loss 21.68599 Test MSE 9.969653707529595 Test RE 1.5092045193357901\n",
      "17 Train Loss 21.281933 Test MSE 9.99700142261241 Test RE 1.511273048043506\n",
      "18 Train Loss 20.69983 Test MSE 9.841162457739868 Test RE 1.4994474876453692\n",
      "19 Train Loss 20.286018 Test MSE 9.820231905590122 Test RE 1.4978520984295953\n",
      "20 Train Loss 19.846996 Test MSE 9.758350971567843 Test RE 1.4931253788470193\n",
      "21 Train Loss 19.349176 Test MSE 9.750047077770368 Test RE 1.4924899542030778\n",
      "22 Train Loss 19.030132 Test MSE 9.797596731986769 Test RE 1.4961248631657718\n",
      "23 Train Loss 18.797272 Test MSE 9.787013833435228 Test RE 1.4953166233496182\n",
      "24 Train Loss 18.357872 Test MSE 9.558601909374097 Test RE 1.4777645621651492\n",
      "25 Train Loss 17.64267 Test MSE 9.103902307656208 Test RE 1.4421879237541797\n",
      "26 Train Loss 16.41042 Test MSE 8.749043511475943 Test RE 1.413801208264367\n",
      "27 Train Loss 15.766397 Test MSE 8.731214906283514 Test RE 1.4123599674168095\n",
      "28 Train Loss 14.732151 Test MSE 8.810820539821776 Test RE 1.4187838558732997\n",
      "29 Train Loss 14.164949 Test MSE 8.612566432538351 Test RE 1.4027308637074143\n",
      "30 Train Loss 13.808203 Test MSE 8.714777564173449 Test RE 1.4110298901690612\n",
      "31 Train Loss 13.527869 Test MSE 8.768386679707698 Test RE 1.4153632244865653\n",
      "32 Train Loss 13.246203 Test MSE 8.7374995689776 Test RE 1.4128681790122826\n",
      "33 Train Loss 12.6930895 Test MSE 8.655795089963517 Test RE 1.4062467885601262\n",
      "34 Train Loss 11.439532 Test MSE 7.790730283156128 Test RE 1.3341269121694166\n",
      "35 Train Loss 10.8776045 Test MSE 7.473810447932532 Test RE 1.3067096542743162\n",
      "36 Train Loss 10.468182 Test MSE 7.439000512894075 Test RE 1.3036630446147224\n",
      "37 Train Loss 10.138174 Test MSE 7.405484837088391 Test RE 1.30072296732572\n",
      "38 Train Loss 9.796476 Test MSE 7.47071178067957 Test RE 1.306438743055841\n",
      "39 Train Loss 9.532904 Test MSE 7.393671838503457 Test RE 1.2996851169067465\n",
      "40 Train Loss 9.159951 Test MSE 7.187001532772639 Test RE 1.28139176616204\n",
      "41 Train Loss 8.9558735 Test MSE 7.110994859241069 Test RE 1.2745980291555028\n",
      "42 Train Loss 8.772691 Test MSE 7.071230699388296 Test RE 1.2710293039676988\n",
      "43 Train Loss 8.616544 Test MSE 6.987882970248619 Test RE 1.2635163665538158\n",
      "44 Train Loss 8.519296 Test MSE 6.877656811635137 Test RE 1.253511466023985\n",
      "45 Train Loss 8.364838 Test MSE 6.940567790329676 Test RE 1.2592314459603258\n",
      "46 Train Loss 8.295914 Test MSE 6.927860728731604 Test RE 1.2580781928966474\n",
      "47 Train Loss 8.200202 Test MSE 6.932622966717445 Test RE 1.2585105224961124\n",
      "48 Train Loss 8.118698 Test MSE 7.0562178479330875 Test RE 1.2696793329521316\n",
      "49 Train Loss 8.01058 Test MSE 7.0330287575116746 Test RE 1.267591320721771\n",
      "50 Train Loss 7.947263 Test MSE 7.009865336392175 Test RE 1.2655021804412634\n",
      "51 Train Loss 7.858322 Test MSE 7.156954498742049 Test RE 1.2787103733745682\n",
      "52 Train Loss 7.7762694 Test MSE 7.12515734705455 Test RE 1.275866663177445\n",
      "53 Train Loss 7.6809034 Test MSE 7.104329230512277 Test RE 1.274000504525364\n",
      "54 Train Loss 7.56654 Test MSE 7.080065381939098 Test RE 1.2718230579620708\n",
      "55 Train Loss 7.4921722 Test MSE 7.0637283505378345 Test RE 1.2703548643789662\n",
      "56 Train Loss 7.409375 Test MSE 7.129317194815614 Test RE 1.2762390505086625\n",
      "57 Train Loss 7.3037796 Test MSE 7.206689999555409 Test RE 1.2831457232576915\n",
      "58 Train Loss 7.2345467 Test MSE 7.200846408289373 Test RE 1.2826253942477517\n",
      "59 Train Loss 7.162465 Test MSE 7.155201282514864 Test RE 1.278553742988785\n",
      "60 Train Loss 7.101903 Test MSE 7.1479273114114426 Test RE 1.2779036894508145\n",
      "61 Train Loss 7.0645056 Test MSE 7.16949231490211 Test RE 1.2798299292041209\n",
      "62 Train Loss 7.0039086 Test MSE 7.186162547069251 Test RE 1.281316971357548\n",
      "63 Train Loss 6.94979 Test MSE 7.108264566289147 Test RE 1.2743533123338195\n",
      "64 Train Loss 6.882225 Test MSE 7.020039603907598 Test RE 1.266420235819676\n",
      "65 Train Loss 6.8317723 Test MSE 7.032498002879419 Test RE 1.2675434897884728\n",
      "66 Train Loss 6.657485 Test MSE 6.801498090373275 Test RE 1.2465518584048554\n",
      "67 Train Loss 6.5784597 Test MSE 6.76425956534163 Test RE 1.2431347094116934\n",
      "68 Train Loss 6.454635 Test MSE 6.901140197359019 Test RE 1.2556496658048624\n",
      "69 Train Loss 6.3427744 Test MSE 6.944000451673717 Test RE 1.2595428023877666\n",
      "70 Train Loss 6.264024 Test MSE 6.841129502950376 Test RE 1.2501783281664698\n",
      "71 Train Loss 6.1736684 Test MSE 6.893966659163947 Test RE 1.2549968901370763\n",
      "72 Train Loss 6.0723085 Test MSE 6.8835256506090685 Test RE 1.2540461748951868\n",
      "73 Train Loss 5.9851494 Test MSE 6.800071580249243 Test RE 1.246421128963279\n",
      "74 Train Loss 5.8965783 Test MSE 6.773105895778588 Test RE 1.243947332516933\n",
      "75 Train Loss 5.8157816 Test MSE 6.778923984959085 Test RE 1.2444814924035776\n",
      "76 Train Loss 5.6806784 Test MSE 6.716810010380397 Test RE 1.2387668997626016\n",
      "77 Train Loss 5.4551697 Test MSE 6.577682156406999 Test RE 1.225870240725349\n",
      "78 Train Loss 5.3204374 Test MSE 6.616390178196549 Test RE 1.2294719203267364\n",
      "79 Train Loss 5.172463 Test MSE 6.654725077178406 Test RE 1.2330285129889127\n",
      "80 Train Loss 4.980836 Test MSE 6.663310447498943 Test RE 1.2338236318091824\n",
      "81 Train Loss 4.73724 Test MSE 6.652562435745739 Test RE 1.2328281429359942\n",
      "82 Train Loss 4.228117 Test MSE 6.330809387928321 Test RE 1.2026456344001126\n",
      "83 Train Loss 3.8712668 Test MSE 6.278705024582311 Test RE 1.1976863512858726\n",
      "84 Train Loss 3.6033938 Test MSE 6.218219341392433 Test RE 1.191903455660108\n",
      "85 Train Loss 3.2445168 Test MSE 5.997720715004181 Test RE 1.1705802157422203\n",
      "86 Train Loss 3.00166 Test MSE 6.004478626421752 Test RE 1.1712395037203722\n",
      "87 Train Loss 2.8327217 Test MSE 6.012557871427436 Test RE 1.1720272115736878\n",
      "88 Train Loss 2.671762 Test MSE 6.095911536402273 Test RE 1.180123308719866\n",
      "89 Train Loss 2.5358515 Test MSE 6.130408910389203 Test RE 1.1834578158040352\n",
      "90 Train Loss 2.423435 Test MSE 6.154436489145157 Test RE 1.1857747752473127\n",
      "91 Train Loss 2.3354633 Test MSE 6.168646888898064 Test RE 1.1871429442172783\n",
      "92 Train Loss 2.2709413 Test MSE 6.112632337398942 Test RE 1.1817407119580852\n",
      "93 Train Loss 2.1861374 Test MSE 6.178002101182505 Test RE 1.1880427985034623\n",
      "94 Train Loss 2.1169302 Test MSE 6.241129456289198 Test RE 1.1940971334652117\n",
      "95 Train Loss 2.0854952 Test MSE 6.228189732856571 Test RE 1.1928586313750147\n",
      "96 Train Loss 2.0432873 Test MSE 6.220838498760611 Test RE 1.1921544482583684\n",
      "97 Train Loss 2.0134306 Test MSE 6.200784585490076 Test RE 1.190231342524428\n",
      "98 Train Loss 1.9803859 Test MSE 6.1699376052869495 Test RE 1.187267135530054\n",
      "99 Train Loss 1.9326893 Test MSE 6.162944912455821 Test RE 1.1865941507631508\n",
      "Training time: 157.10\n",
      "2\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 59.454533 Test MSE 7.469287751449347 Test RE 1.3063142237546004\n",
      "1 Train Loss 44.53048 Test MSE 7.496560396447287 Test RE 1.3086969263340673\n",
      "2 Train Loss 37.509655 Test MSE 7.477219723268441 Test RE 1.3070076565516386\n",
      "3 Train Loss 29.676243 Test MSE 5.815201726473744 Test RE 1.1526314164829192\n",
      "4 Train Loss 24.547688 Test MSE 5.929907301361252 Test RE 1.1639438031182123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 21.426613 Test MSE 5.800039909395467 Test RE 1.1511278235244848\n",
      "6 Train Loss 18.59807 Test MSE 5.995195059285128 Test RE 1.1703337226102317\n",
      "7 Train Loss 16.464481 Test MSE 5.793980109912206 Test RE 1.150526325357699\n",
      "8 Train Loss 14.262251 Test MSE 5.7041900307292055 Test RE 1.1415765865226686\n",
      "9 Train Loss 12.345842 Test MSE 5.543048696741654 Test RE 1.12533650501566\n",
      "10 Train Loss 10.159092 Test MSE 5.603720349585988 Test RE 1.1314784510418123\n",
      "11 Train Loss 9.150045 Test MSE 5.226930891233322 Test RE 1.0927767322459654\n",
      "12 Train Loss 8.4368 Test MSE 5.056720038227832 Test RE 1.0748367701510844\n",
      "13 Train Loss 7.7655196 Test MSE 4.900889478057734 Test RE 1.0581458052162451\n",
      "14 Train Loss 7.3158216 Test MSE 4.878722136633528 Test RE 1.0557500295586524\n",
      "15 Train Loss 6.959016 Test MSE 4.681612730496642 Test RE 1.034203023216166\n",
      "16 Train Loss 6.5417147 Test MSE 4.492372159086035 Test RE 1.0130850902807034\n",
      "17 Train Loss 6.191541 Test MSE 4.410950786854268 Test RE 1.0038623504647335\n",
      "18 Train Loss 5.805106 Test MSE 4.363500874788469 Test RE 0.998448327806054\n",
      "19 Train Loss 5.6215725 Test MSE 4.304258558745582 Test RE 0.9916473054497035\n",
      "20 Train Loss 5.294774 Test MSE 4.143223268950493 Test RE 0.9729202188349227\n",
      "21 Train Loss 5.063537 Test MSE 4.023619663927 Test RE 0.9587746024864592\n",
      "22 Train Loss 4.7667327 Test MSE 3.8722756541050303 Test RE 0.9405701527966903\n",
      "23 Train Loss 4.245249 Test MSE 3.661294461884673 Test RE 0.9145877699787728\n",
      "24 Train Loss 3.929862 Test MSE 3.66878710643198 Test RE 0.9155231193217316\n",
      "25 Train Loss 3.556149 Test MSE 3.505116322551027 Test RE 0.894868617507275\n",
      "26 Train Loss 3.2151823 Test MSE 3.464370368811311 Test RE 0.8896521199398376\n",
      "27 Train Loss 2.9590995 Test MSE 3.3405195455585783 Test RE 0.8736049152233943\n",
      "28 Train Loss 2.7513902 Test MSE 3.063447926872203 Test RE 0.8365912376645457\n",
      "29 Train Loss 2.546356 Test MSE 2.9390936013021647 Test RE 0.8194354889869289\n",
      "30 Train Loss 2.3444083 Test MSE 2.7244272913501018 Test RE 0.7889430801688045\n",
      "31 Train Loss 2.2405527 Test MSE 2.6910668438136267 Test RE 0.784097922148014\n",
      "32 Train Loss 2.180606 Test MSE 2.6244955100954726 Test RE 0.7743387219512616\n",
      "33 Train Loss 2.0963178 Test MSE 2.5246580240736507 Test RE 0.7594677556446507\n",
      "34 Train Loss 2.0183444 Test MSE 2.531979104385403 Test RE 0.7605681223793771\n",
      "35 Train Loss 1.9362572 Test MSE 2.539379925728193 Test RE 0.7616788585623995\n",
      "36 Train Loss 1.8788549 Test MSE 2.510572677034974 Test RE 0.7573462150207485\n",
      "37 Train Loss 1.8340119 Test MSE 2.4719645699612873 Test RE 0.7515003396266614\n",
      "38 Train Loss 1.7765405 Test MSE 2.4044519656503036 Test RE 0.7411670659374869\n",
      "39 Train Loss 1.7303263 Test MSE 2.3650079108362903 Test RE 0.7350626554564391\n",
      "40 Train Loss 1.6900698 Test MSE 2.3109768596033673 Test RE 0.7266175090226051\n",
      "41 Train Loss 1.6546696 Test MSE 2.215796525311988 Test RE 0.7114968780153883\n",
      "42 Train Loss 1.6238176 Test MSE 2.1191645193760844 Test RE 0.6958095694849757\n",
      "43 Train Loss 1.5838828 Test MSE 2.058389026782799 Test RE 0.6857594314202237\n",
      "44 Train Loss 1.5466344 Test MSE 2.012984320484633 Test RE 0.6781538885157705\n",
      "45 Train Loss 1.491388 Test MSE 1.8738688997887305 Test RE 0.6543011173787795\n",
      "46 Train Loss 1.4431936 Test MSE 1.7659516094834848 Test RE 0.6351809430276837\n",
      "47 Train Loss 1.3924673 Test MSE 1.6253080176540875 Test RE 0.6093627452681807\n",
      "48 Train Loss 1.3670574 Test MSE 1.5979080140494464 Test RE 0.6042044891941225\n",
      "49 Train Loss 1.327484 Test MSE 1.6216989964924031 Test RE 0.6086858196586369\n",
      "50 Train Loss 1.3016176 Test MSE 1.5612783313338878 Test RE 0.5972390918505204\n",
      "51 Train Loss 1.2663659 Test MSE 1.421713613840336 Test RE 0.569920293353595\n",
      "52 Train Loss 1.2368486 Test MSE 1.3515631159760653 Test RE 0.5556818680976192\n",
      "53 Train Loss 1.2176332 Test MSE 1.2669094108648342 Test RE 0.5379982232129853\n",
      "54 Train Loss 1.1347936 Test MSE 0.9003124630906334 Test RE 0.45352861255466587\n",
      "55 Train Loss 1.0354843 Test MSE 0.7039074269754717 Test RE 0.4010198165942285\n",
      "56 Train Loss 0.9219029 Test MSE 0.6486229782266458 Test RE 0.38494991252685656\n",
      "57 Train Loss 0.82477576 Test MSE 0.6947047131031491 Test RE 0.3983897745858948\n",
      "58 Train Loss 0.75141025 Test MSE 0.6965498000304813 Test RE 0.3989184714040159\n",
      "59 Train Loss 0.6753922 Test MSE 0.6353161147306691 Test RE 0.3809807179934628\n",
      "60 Train Loss 0.5921296 Test MSE 0.6182392378459401 Test RE 0.37582558555263984\n",
      "61 Train Loss 0.5158874 Test MSE 0.5226658056535707 Test RE 0.3455573257607845\n",
      "62 Train Loss 0.43902564 Test MSE 0.4966543044357867 Test RE 0.3368489222610679\n",
      "63 Train Loss 0.41290116 Test MSE 0.4666533306327601 Test RE 0.3265165846936578\n",
      "64 Train Loss 0.3950403 Test MSE 0.4441663852055952 Test RE 0.3185524166692338\n",
      "65 Train Loss 0.3687276 Test MSE 0.44424496292648386 Test RE 0.31858059306523046\n",
      "66 Train Loss 0.3407178 Test MSE 0.39405663002041263 Test RE 0.30004568102574103\n",
      "67 Train Loss 0.32958028 Test MSE 0.3712674825243928 Test RE 0.291240331612493\n",
      "68 Train Loss 0.30150226 Test MSE 0.3387950186171401 Test RE 0.27821245487359136\n",
      "69 Train Loss 0.2876848 Test MSE 0.3119593489682692 Test RE 0.26696668142240015\n",
      "70 Train Loss 0.27259225 Test MSE 0.28136998891327214 Test RE 0.2535402691429206\n",
      "71 Train Loss 0.2624631 Test MSE 0.2561846185058962 Test RE 0.24192713685835485\n",
      "72 Train Loss 0.2433528 Test MSE 0.17993532727702116 Test RE 0.20275252868810612\n",
      "73 Train Loss 0.23102719 Test MSE 0.14008782094864908 Test RE 0.17889913893122794\n",
      "74 Train Loss 0.21135417 Test MSE 0.09555895596628924 Test RE 0.14775553487139864\n",
      "75 Train Loss 0.19272053 Test MSE 0.052653504305297874 Test RE 0.10967855007707848\n",
      "76 Train Loss 0.1826196 Test MSE 0.03976484980806625 Test RE 0.09531422775128698\n",
      "77 Train Loss 0.17464955 Test MSE 0.03371821115550063 Test RE 0.08776883288079555\n",
      "78 Train Loss 0.1590644 Test MSE 0.026106203016316304 Test RE 0.07722891186413132\n",
      "79 Train Loss 0.13527294 Test MSE 0.020304731638515643 Test RE 0.068109342412584\n",
      "80 Train Loss 0.12125307 Test MSE 0.017646833569712642 Test RE 0.0634952818285122\n",
      "81 Train Loss 0.11263484 Test MSE 0.017585772636426633 Test RE 0.06338533460196694\n",
      "82 Train Loss 0.1037397 Test MSE 0.013574463445712517 Test RE 0.055688997059204305\n",
      "83 Train Loss 0.09536557 Test MSE 0.010530312011479815 Test RE 0.04904883313199549\n",
      "84 Train Loss 0.08757542 Test MSE 0.009842032173176392 Test RE 0.04741878811310967\n",
      "85 Train Loss 0.07552583 Test MSE 0.009414394562758374 Test RE 0.046377171534677235\n",
      "86 Train Loss 0.07207158 Test MSE 0.008995388907664768 Test RE 0.045333372878274415\n",
      "87 Train Loss 0.0679989 Test MSE 0.008855358365835444 Test RE 0.04497913828406632\n",
      "88 Train Loss 0.063172966 Test MSE 0.007403945098313094 Test RE 0.04112819548910651\n",
      "89 Train Loss 0.057796955 Test MSE 0.00620844346967444 Test RE 0.03766165717773182\n",
      "90 Train Loss 0.053296812 Test MSE 0.006037601676484085 Test RE 0.03713986228750439\n",
      "91 Train Loss 0.050162483 Test MSE 0.005686019560988201 Test RE 0.03604227823714962\n",
      "92 Train Loss 0.047938112 Test MSE 0.005463247001792977 Test RE 0.03532917356226243\n",
      "93 Train Loss 0.04449557 Test MSE 0.005254639339414144 Test RE 0.034648107384236945\n",
      "94 Train Loss 0.04227842 Test MSE 0.004869338672350325 Test RE 0.033353625729476324\n",
      "95 Train Loss 0.040666137 Test MSE 0.005036724243243558 Test RE 0.033922054486419814\n",
      "96 Train Loss 0.03959444 Test MSE 0.004796651732738514 Test RE 0.0331037469728126\n",
      "97 Train Loss 0.03753654 Test MSE 0.0040101327645169615 Test RE 0.030268258607544424\n",
      "98 Train Loss 0.03579718 Test MSE 0.0039943509716917755 Test RE 0.030208639846291217\n",
      "99 Train Loss 0.035248503 Test MSE 0.00396777231271744 Test RE 0.030107967014873765\n",
      "Training time: 157.32\n",
      "3\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.16772 Test MSE 5.46731119589984 Test RE 1.117622039463712\n",
      "1 Train Loss 54.937828 Test MSE 7.031022703574874 Test RE 1.2674105282069406\n",
      "2 Train Loss 43.275074 Test MSE 8.351724903025408 Test RE 1.3813258862370859\n",
      "3 Train Loss 37.058525 Test MSE 8.437671936479788 Test RE 1.3884152592725691\n",
      "4 Train Loss 31.503532 Test MSE 8.791712851307366 Test RE 1.417244589822282\n",
      "5 Train Loss 28.364832 Test MSE 8.792414786150953 Test RE 1.4173011654589351\n",
      "6 Train Loss 27.062815 Test MSE 8.720212484603337 Test RE 1.411469811890376\n",
      "7 Train Loss 25.223213 Test MSE 8.94709844020157 Test RE 1.4297139942039443\n",
      "8 Train Loss 23.919283 Test MSE 9.067519118550651 Test RE 1.4393032308015974\n",
      "9 Train Loss 22.725876 Test MSE 9.138096478641506 Test RE 1.444893807419648\n",
      "10 Train Loss 21.523273 Test MSE 9.214524631961542 Test RE 1.4509235437374757\n",
      "11 Train Loss 20.459541 Test MSE 8.959019883009399 Test RE 1.430666178865218\n",
      "12 Train Loss 19.377087 Test MSE 9.147087346464147 Test RE 1.4456044398503127\n",
      "13 Train Loss 18.567242 Test MSE 9.031308790268998 Test RE 1.4364264914342662\n",
      "14 Train Loss 17.800144 Test MSE 8.881517306734535 Test RE 1.4244645430008414\n",
      "15 Train Loss 16.72461 Test MSE 8.746127084318143 Test RE 1.4135655486802794\n",
      "16 Train Loss 16.116068 Test MSE 8.671425422890167 Test RE 1.4075158915989487\n",
      "17 Train Loss 15.197726 Test MSE 8.458944574455915 Test RE 1.3901643592091086\n",
      "18 Train Loss 14.222393 Test MSE 8.349104940438632 Test RE 1.3811092060869776\n",
      "19 Train Loss 13.693832 Test MSE 8.359217486450941 Test RE 1.381945361815165\n",
      "20 Train Loss 13.27083 Test MSE 8.415701815692291 Test RE 1.3866064941579648\n",
      "21 Train Loss 12.670682 Test MSE 8.221308173176562 Test RE 1.3704983727870497\n",
      "22 Train Loss 12.086775 Test MSE 8.155819733457397 Test RE 1.3650289725715083\n",
      "23 Train Loss 11.77578 Test MSE 8.08644135951127 Test RE 1.359210688437287\n",
      "24 Train Loss 10.941263 Test MSE 7.948209209826953 Test RE 1.3475432260656042\n",
      "25 Train Loss 10.263454 Test MSE 7.793815332546513 Test RE 1.3343910363201579\n",
      "26 Train Loss 9.71369 Test MSE 7.863829891456091 Test RE 1.3403712855087682\n",
      "27 Train Loss 8.759251 Test MSE 7.57626397630392 Test RE 1.3156355780548432\n",
      "28 Train Loss 8.24938 Test MSE 7.486913995998579 Test RE 1.3078546548321124\n",
      "29 Train Loss 7.865403 Test MSE 7.512430199285335 Test RE 1.3100814134279635\n",
      "30 Train Loss 7.624691 Test MSE 7.496494010819743 Test RE 1.3086911317526546\n",
      "31 Train Loss 7.448311 Test MSE 7.5641111727785555 Test RE 1.3145799734987729\n",
      "32 Train Loss 7.236536 Test MSE 7.62199339404818 Test RE 1.3196001137122675\n",
      "33 Train Loss 7.05597 Test MSE 7.628878857565288 Test RE 1.3201960212973087\n",
      "34 Train Loss 6.8765564 Test MSE 7.7345971344339315 Test RE 1.3293119509642422\n",
      "35 Train Loss 6.578923 Test MSE 7.736452450436516 Test RE 1.3294713739963024\n",
      "36 Train Loss 6.3037376 Test MSE 7.758714433435685 Test RE 1.3313828061716912\n",
      "37 Train Loss 6.1325927 Test MSE 7.742980482281864 Test RE 1.3300321608357033\n",
      "38 Train Loss 5.981203 Test MSE 7.592161428973953 Test RE 1.317015169245977\n",
      "39 Train Loss 5.802948 Test MSE 7.605785300979293 Test RE 1.3181963087687665\n",
      "40 Train Loss 5.637252 Test MSE 7.639649522643172 Test RE 1.3211276374728034\n",
      "41 Train Loss 5.4089775 Test MSE 7.534800958830525 Test RE 1.3120305650149575\n",
      "42 Train Loss 5.1934896 Test MSE 7.36644652795779 Test RE 1.2972900305919761\n",
      "43 Train Loss 5.0005155 Test MSE 7.38747864051048 Test RE 1.2991406720277987\n",
      "44 Train Loss 4.6691217 Test MSE 7.285826213368027 Test RE 1.290171559964123\n",
      "45 Train Loss 4.1347837 Test MSE 6.867400937739615 Test RE 1.2525765072093127\n",
      "46 Train Loss 3.4936657 Test MSE 6.649114455357742 Test RE 1.2325086180740477\n",
      "47 Train Loss 3.0704343 Test MSE 6.650177965492022 Test RE 1.232607182552419\n",
      "48 Train Loss 2.80412 Test MSE 6.617297330302106 Test RE 1.229556201920204\n",
      "49 Train Loss 2.679802 Test MSE 6.611713194162618 Test RE 1.2290372998673327\n",
      "50 Train Loss 2.5468528 Test MSE 6.57972423676203 Test RE 1.2260605152942612\n",
      "51 Train Loss 2.4230576 Test MSE 6.427862387177793 Test RE 1.2118290117958623\n",
      "52 Train Loss 2.3722146 Test MSE 6.448451405739672 Test RE 1.213768258537873\n",
      "53 Train Loss 2.305859 Test MSE 6.498906042244864 Test RE 1.2185074515829502\n",
      "54 Train Loss 2.2456179 Test MSE 6.521985264785449 Test RE 1.2206691447562483\n",
      "55 Train Loss 2.2007551 Test MSE 6.557821112782155 Test RE 1.224018108903647\n",
      "56 Train Loss 2.1714072 Test MSE 6.538095829181795 Test RE 1.2221758592412477\n",
      "57 Train Loss 2.1235375 Test MSE 6.365716768865813 Test RE 1.2059567037900765\n",
      "58 Train Loss 2.0865364 Test MSE 6.325076613436506 Test RE 1.2021009917404326\n",
      "59 Train Loss 2.0383103 Test MSE 6.289762244362176 Test RE 1.1987404903003578\n",
      "60 Train Loss 1.9927166 Test MSE 6.245779487894498 Test RE 1.1945418891442796\n",
      "61 Train Loss 1.9639242 Test MSE 6.26507192538629 Test RE 1.1963853624798397\n",
      "62 Train Loss 1.9339558 Test MSE 6.1769278585881775 Test RE 1.187939504457833\n",
      "63 Train Loss 1.9009327 Test MSE 6.0245313135162375 Test RE 1.1731936220052679\n",
      "64 Train Loss 1.8726251 Test MSE 5.996300327045311 Test RE 1.1704415983762746\n",
      "65 Train Loss 1.831681 Test MSE 5.958437438069437 Test RE 1.1667404429095465\n",
      "66 Train Loss 1.8084131 Test MSE 5.917238110100164 Test RE 1.1626997607894023\n",
      "67 Train Loss 1.7771263 Test MSE 5.873742002026591 Test RE 1.158418524018595\n",
      "68 Train Loss 1.7537688 Test MSE 5.826542314798986 Test RE 1.1537547783463509\n",
      "69 Train Loss 1.7257599 Test MSE 5.830474223514225 Test RE 1.1541440051939398\n",
      "70 Train Loss 1.7001306 Test MSE 5.825292261360606 Test RE 1.1536310057540378\n",
      "71 Train Loss 1.6785526 Test MSE 5.805770478888981 Test RE 1.1516963531806998\n",
      "72 Train Loss 1.6576862 Test MSE 5.852783047068566 Test RE 1.1563499160543487\n",
      "73 Train Loss 1.6346862 Test MSE 5.8794880897465545 Test RE 1.158985006792365\n",
      "74 Train Loss 1.6140238 Test MSE 5.888430801587553 Test RE 1.1598660810190726\n",
      "75 Train Loss 1.5938338 Test MSE 5.905357263994604 Test RE 1.1615319188309687\n",
      "76 Train Loss 1.5782789 Test MSE 5.872920349522744 Test RE 1.1583374980926033\n",
      "77 Train Loss 1.5618912 Test MSE 5.814449221618428 Test RE 1.15255683705819\n",
      "78 Train Loss 1.5423517 Test MSE 5.812668253039508 Test RE 1.1523803091841542\n",
      "79 Train Loss 1.5299913 Test MSE 5.846977683731689 Test RE 1.1557762832338738\n",
      "80 Train Loss 1.5116965 Test MSE 5.822811443723825 Test RE 1.1533853311349456\n",
      "81 Train Loss 1.4980267 Test MSE 5.793663332095812 Test RE 1.1504948732132425\n",
      "82 Train Loss 1.4762427 Test MSE 5.753955162114574 Test RE 1.1465455073954625\n",
      "83 Train Loss 1.4663903 Test MSE 5.741138671669897 Test RE 1.1452678747868474\n",
      "84 Train Loss 1.4532498 Test MSE 5.757780408224539 Test RE 1.1469265574674954\n",
      "85 Train Loss 1.437357 Test MSE 5.78363309540449 Test RE 1.1494985489467695\n",
      "86 Train Loss 1.4211882 Test MSE 5.763023458552647 Test RE 1.1474486358472715\n",
      "87 Train Loss 1.4025078 Test MSE 5.7327665643671395 Test RE 1.1444325175334604\n",
      "88 Train Loss 1.3910553 Test MSE 5.748685317278266 Test RE 1.1460203468036734\n",
      "89 Train Loss 1.379937 Test MSE 5.765378201844421 Test RE 1.1476830328658796\n",
      "90 Train Loss 1.3695394 Test MSE 5.789944303526733 Test RE 1.1501255550530904\n",
      "91 Train Loss 1.3520625 Test MSE 5.7914576638154 Test RE 1.1502758536164488\n",
      "92 Train Loss 1.3361166 Test MSE 5.798312640640957 Test RE 1.150956406154429\n",
      "93 Train Loss 1.3294263 Test MSE 5.798787455611229 Test RE 1.1510035302212274\n",
      "94 Train Loss 1.3228905 Test MSE 5.798774452013775 Test RE 1.1510022396759987\n",
      "95 Train Loss 1.3144958 Test MSE 5.810303234471355 Test RE 1.1521458490369687\n",
      "96 Train Loss 1.3011502 Test MSE 5.806511604629762 Test RE 1.1517698597530033\n",
      "97 Train Loss 1.2923188 Test MSE 5.798659274374415 Test RE 1.1509908087796723\n",
      "98 Train Loss 1.2823361 Test MSE 5.792551323442268 Test RE 1.1503844576112274\n",
      "99 Train Loss 1.2714716 Test MSE 5.803659567341513 Test RE 1.1514869623545558\n",
      "Training time: 158.10\n",
      "4\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 61.993095 Test MSE 8.638193874661347 Test RE 1.4048162874957464\n",
      "1 Train Loss 50.404274 Test MSE 7.497378880744788 Test RE 1.3087683670076564\n",
      "2 Train Loss 42.504646 Test MSE 7.393284216589575 Test RE 1.2996510477022607\n",
      "3 Train Loss 37.31663 Test MSE 7.6222821019688825 Test RE 1.3196251055600465\n",
      "4 Train Loss 31.910278 Test MSE 6.953459441325952 Test RE 1.260400373460777\n",
      "5 Train Loss 28.208864 Test MSE 6.52292168360827 Test RE 1.2207567727169395\n",
      "6 Train Loss 24.981735 Test MSE 6.290569317619604 Test RE 1.1988173962565254\n",
      "7 Train Loss 22.114864 Test MSE 6.490460100044261 Test RE 1.2177154114080082\n",
      "8 Train Loss 20.501633 Test MSE 5.998369748523123 Test RE 1.1706435502387884\n",
      "9 Train Loss 16.71519 Test MSE 5.70230116190455 Test RE 1.1413875617049518\n",
      "10 Train Loss 14.582825 Test MSE 5.80067286820595 Test RE 1.151190633145786\n",
      "11 Train Loss 13.013224 Test MSE 5.864070232836941 Test RE 1.1574643986478703\n",
      "12 Train Loss 11.287899 Test MSE 5.6547201944744705 Test RE 1.1366156207418157\n",
      "13 Train Loss 10.31221 Test MSE 5.598112460590056 Test RE 1.1309121492427332\n",
      "14 Train Loss 9.271504 Test MSE 5.661955489561732 Test RE 1.1373425462318996\n",
      "15 Train Loss 7.902599 Test MSE 5.513583722340718 Test RE 1.122341565332487\n",
      "16 Train Loss 7.110182 Test MSE 5.524206374449677 Test RE 1.1234222152032562\n",
      "17 Train Loss 5.92955 Test MSE 5.273030142249964 Test RE 1.0975850607905155\n",
      "18 Train Loss 5.2723093 Test MSE 5.3172210803104605 Test RE 1.102174652971921\n",
      "19 Train Loss 4.8320055 Test MSE 4.920786890772471 Test RE 1.060291643966309\n",
      "20 Train Loss 4.4404926 Test MSE 4.8323739040286995 Test RE 1.0507232093506074\n",
      "21 Train Loss 4.0970035 Test MSE 4.671330199122051 Test RE 1.033066655128051\n",
      "22 Train Loss 3.8596764 Test MSE 4.496073754136358 Test RE 1.0135023819096785\n",
      "23 Train Loss 3.6706865 Test MSE 4.332106022264456 Test RE 0.9948499872122503\n",
      "24 Train Loss 3.3830767 Test MSE 4.086038695646389 Test RE 0.9661827910232873\n",
      "25 Train Loss 3.2032087 Test MSE 4.063299586331295 Test RE 0.9634906006829997\n",
      "26 Train Loss 3.086306 Test MSE 3.9480260341004647 Test RE 0.9497254240934899\n",
      "27 Train Loss 2.8666482 Test MSE 3.707937501315856 Test RE 0.9203950259153949\n",
      "28 Train Loss 2.7201703 Test MSE 3.6186006125390375 Test RE 0.9092396925913948\n",
      "29 Train Loss 2.6292405 Test MSE 3.518623700681778 Test RE 0.8965912003091903\n",
      "30 Train Loss 2.4531007 Test MSE 3.3478122844298936 Test RE 0.8745579854098177\n",
      "31 Train Loss 2.3436837 Test MSE 3.273590716254817 Test RE 0.8648090992459889\n",
      "32 Train Loss 2.21388 Test MSE 3.0759052922536703 Test RE 0.838290491185118\n",
      "33 Train Loss 2.1494455 Test MSE 3.008796644832631 Test RE 0.8290953479774475\n",
      "34 Train Loss 2.0615547 Test MSE 2.9612232336107485 Test RE 0.8225146355247066\n",
      "35 Train Loss 2.0039606 Test MSE 2.8789481806144788 Test RE 0.8110077124203101\n",
      "36 Train Loss 1.951303 Test MSE 2.776257634463756 Test RE 0.7964122714472244\n",
      "37 Train Loss 1.8941771 Test MSE 2.6681223376298124 Test RE 0.7807480885922518\n",
      "38 Train Loss 1.8036422 Test MSE 2.564520805658045 Test RE 0.7654400353233407\n",
      "39 Train Loss 1.7692552 Test MSE 2.5678069860238377 Test RE 0.7659302962572131\n",
      "40 Train Loss 1.7320312 Test MSE 2.5079652470304965 Test RE 0.7569528306233833\n",
      "41 Train Loss 1.6770507 Test MSE 2.37207903871844 Test RE 0.736160715773579\n",
      "42 Train Loss 1.6295794 Test MSE 2.3096323950542916 Test RE 0.7264061149525716\n",
      "43 Train Loss 1.5897173 Test MSE 2.256406028207938 Test RE 0.7179871736492622\n",
      "44 Train Loss 1.5530103 Test MSE 2.148555631448334 Test RE 0.7006181145360302\n",
      "45 Train Loss 1.5173999 Test MSE 2.0733332922221095 Test RE 0.6882442963256811\n",
      "46 Train Loss 1.4793633 Test MSE 2.018891412078501 Test RE 0.679148179072839\n",
      "47 Train Loss 1.4563627 Test MSE 1.973094464684548 Test RE 0.6714010241555742\n",
      "48 Train Loss 1.4063694 Test MSE 1.8422746696627366 Test RE 0.6487617710144646\n",
      "49 Train Loss 1.3672498 Test MSE 1.7570611949145964 Test RE 0.6335800647549761\n",
      "50 Train Loss 1.3240104 Test MSE 1.6101960026281243 Test RE 0.6065232205631315\n",
      "51 Train Loss 1.2818159 Test MSE 1.5065637849675888 Test RE 0.5866807277976187\n",
      "52 Train Loss 1.2396555 Test MSE 1.4457102143529525 Test RE 0.5747099087496229\n",
      "53 Train Loss 1.1834447 Test MSE 1.3909797095389753 Test RE 0.5637265088966616\n",
      "54 Train Loss 1.1271762 Test MSE 1.3653431153577726 Test RE 0.5585074397973423\n",
      "55 Train Loss 1.0708592 Test MSE 1.349237021900747 Test RE 0.5552034868421107\n",
      "56 Train Loss 0.98763883 Test MSE 1.2371614822746169 Test RE 0.5316444143720469\n",
      "57 Train Loss 0.91214275 Test MSE 1.124610268587464 Test RE 0.5068845833915102\n",
      "58 Train Loss 0.8606283 Test MSE 1.0603030825371889 Test RE 0.49217899176723556\n",
      "59 Train Loss 0.7714113 Test MSE 0.9686013379170132 Test RE 0.47041438373552263\n",
      "60 Train Loss 0.68549883 Test MSE 0.8281643510146468 Test RE 0.43497703269092985\n",
      "61 Train Loss 0.637463 Test MSE 0.6814830017801569 Test RE 0.3945804594184335\n",
      "62 Train Loss 0.5952189 Test MSE 0.6756851501633349 Test RE 0.3928983884326054\n",
      "63 Train Loss 0.56522274 Test MSE 0.6490697307627649 Test RE 0.38508246082719755\n",
      "64 Train Loss 0.50789493 Test MSE 0.5362134074378407 Test RE 0.35000713261472466\n",
      "65 Train Loss 0.45659977 Test MSE 0.4447994693608909 Test RE 0.3187793571623727\n",
      "66 Train Loss 0.40986145 Test MSE 0.4036240884591296 Test RE 0.3036663007213638\n",
      "67 Train Loss 0.34583843 Test MSE 0.3757020507558763 Test RE 0.29297451440651756\n",
      "68 Train Loss 0.32393137 Test MSE 0.3713592882154008 Test RE 0.2912763378188892\n",
      "69 Train Loss 0.31051216 Test MSE 0.35956429954279984 Test RE 0.2866133021239343\n",
      "70 Train Loss 0.2795898 Test MSE 0.30884353621042204 Test RE 0.2656301200120529\n",
      "71 Train Loss 0.25985935 Test MSE 0.29041621447722066 Test RE 0.2575837671033412\n",
      "72 Train Loss 0.24452776 Test MSE 0.2708276956253354 Test RE 0.24874513616459984\n",
      "73 Train Loss 0.22688939 Test MSE 0.24303929908442667 Test RE 0.23563853407623353\n",
      "74 Train Loss 0.2155824 Test MSE 0.21168024646090272 Test RE 0.21991164465846022\n",
      "75 Train Loss 0.2000899 Test MSE 0.16390130138392311 Test RE 0.1935081501209504\n",
      "76 Train Loss 0.189515 Test MSE 0.1698597244812336 Test RE 0.19699412211540315\n",
      "77 Train Loss 0.17627957 Test MSE 0.1634652335986991 Test RE 0.19325055951421938\n",
      "78 Train Loss 0.1574543 Test MSE 0.15704096771617426 Test RE 0.18941507560760631\n",
      "79 Train Loss 0.14233321 Test MSE 0.13868307970192958 Test RE 0.17799991665632237\n",
      "80 Train Loss 0.1306584 Test MSE 0.11397578836919012 Test RE 0.16136686537942257\n",
      "81 Train Loss 0.12410926 Test MSE 0.12153179713113438 Test RE 0.16662993322621533\n",
      "82 Train Loss 0.118709795 Test MSE 0.12088614031803363 Test RE 0.16618671990019052\n",
      "83 Train Loss 0.11201461 Test MSE 0.115175089686514 Test RE 0.1622136288169528\n",
      "84 Train Loss 0.10403724 Test MSE 0.11558234368003147 Test RE 0.16250016583260948\n",
      "85 Train Loss 0.09757203 Test MSE 0.10125316567802954 Test RE 0.15209409933697332\n",
      "86 Train Loss 0.091818504 Test MSE 0.08877310128791759 Test RE 0.1424127118353372\n",
      "87 Train Loss 0.085275024 Test MSE 0.08014694891885789 Test RE 0.1353167496311127\n",
      "88 Train Loss 0.07978864 Test MSE 0.07202658836638823 Test RE 0.12827868002988746\n",
      "89 Train Loss 0.07651664 Test MSE 0.07141004362282637 Test RE 0.12772846984490377\n",
      "90 Train Loss 0.075129785 Test MSE 0.06779994988614808 Test RE 0.12445797964700397\n",
      "91 Train Loss 0.0730534 Test MSE 0.059478851405909174 Test RE 0.11657068457466321\n",
      "92 Train Loss 0.07044739 Test MSE 0.06039675565078705 Test RE 0.1174667262594961\n",
      "93 Train Loss 0.06616557 Test MSE 0.055853429693857225 Test RE 0.11296215876958052\n",
      "94 Train Loss 0.062314093 Test MSE 0.04780350656423461 Test RE 0.10450520890074362\n",
      "95 Train Loss 0.059111584 Test MSE 0.04584435267510324 Test RE 0.10234131257543073\n",
      "96 Train Loss 0.05628576 Test MSE 0.043509296197404734 Test RE 0.09970090245503495\n",
      "97 Train Loss 0.051684156 Test MSE 0.041863737063024035 Test RE 0.09779734332554374\n",
      "98 Train Loss 0.04906314 Test MSE 0.04025422662121798 Test RE 0.0958989393571302\n",
      "99 Train Loss 0.047530703 Test MSE 0.03884555265657916 Test RE 0.09420603222779352\n",
      "Training time: 157.11\n",
      "5\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.75731 Test MSE 5.047781093835532 Test RE 1.073886336286522\n",
      "1 Train Loss 51.19394 Test MSE 7.107847511266478 Test RE 1.2743159274531293\n",
      "2 Train Loss 41.61734 Test MSE 7.168870097842168 Test RE 1.2797743918481053\n",
      "3 Train Loss 35.884598 Test MSE 6.968383760044221 Test RE 1.2617522569715525\n",
      "4 Train Loss 32.39445 Test MSE 6.735736412335215 Test RE 1.2405109499552898\n",
      "5 Train Loss 28.607395 Test MSE 7.083095580897698 Test RE 1.2720951927822077\n",
      "6 Train Loss 26.189732 Test MSE 6.817659191072336 Test RE 1.2480319512442688\n",
      "7 Train Loss 24.244728 Test MSE 6.812612203137758 Test RE 1.247569918149263\n",
      "8 Train Loss 22.762226 Test MSE 6.997810655630619 Test RE 1.264413586851854\n",
      "9 Train Loss 21.621485 Test MSE 6.886451036112453 Test RE 1.2543126211176054\n",
      "10 Train Loss 20.942865 Test MSE 6.883305931096205 Test RE 1.2540261603977152\n",
      "11 Train Loss 20.183582 Test MSE 6.889127520759779 Test RE 1.2545563476991366\n",
      "12 Train Loss 19.17527 Test MSE 6.904852646050119 Test RE 1.2559873569746338\n",
      "13 Train Loss 18.577385 Test MSE 6.823925119494844 Test RE 1.2486053359409228\n",
      "14 Train Loss 17.824945 Test MSE 7.177998211838446 Test RE 1.2805889002782083\n",
      "15 Train Loss 16.917221 Test MSE 7.246343997940474 Test RE 1.2866710627286888\n",
      "16 Train Loss 16.078617 Test MSE 7.363919006365365 Test RE 1.2970674531348323\n",
      "17 Train Loss 15.60616 Test MSE 7.285946366416851 Test RE 1.2901821982502133\n",
      "18 Train Loss 15.183121 Test MSE 7.120206932693327 Test RE 1.2754233630652525\n",
      "19 Train Loss 14.563283 Test MSE 6.975589591061309 Test RE 1.2624044616025796\n",
      "20 Train Loss 14.06172 Test MSE 6.982482091770611 Test RE 1.2630279913576183\n",
      "21 Train Loss 13.471773 Test MSE 6.851700034884618 Test RE 1.2511438082882889\n",
      "22 Train Loss 12.9858465 Test MSE 6.885790414589795 Test RE 1.2542524561804766\n",
      "23 Train Loss 11.843636 Test MSE 6.570570900635197 Test RE 1.225207405850617\n",
      "24 Train Loss 11.493113 Test MSE 6.609549531199021 Test RE 1.228836184059696\n",
      "25 Train Loss 10.839947 Test MSE 6.615854956286603 Test RE 1.229422191275093\n",
      "26 Train Loss 10.413017 Test MSE 6.537086902870336 Test RE 1.2220815555641218\n",
      "27 Train Loss 9.726276 Test MSE 6.247281451805474 Test RE 1.1946855102055722\n",
      "28 Train Loss 9.199324 Test MSE 6.3455982745648 Test RE 1.2040495161151865\n",
      "29 Train Loss 8.531719 Test MSE 6.131263452769085 Test RE 1.1835402964046635\n",
      "30 Train Loss 7.928692 Test MSE 6.012494010978689 Test RE 1.1720209874022105\n",
      "31 Train Loss 5.9570208 Test MSE 5.130618825289055 Test RE 1.08266210360896\n",
      "32 Train Loss 5.091752 Test MSE 5.05274881741238 Test RE 1.0744146336193126\n",
      "33 Train Loss 4.680529 Test MSE 5.138725482460385 Test RE 1.0835170985518245\n",
      "34 Train Loss 4.336902 Test MSE 5.36860093426898 Test RE 1.107486960581159\n",
      "35 Train Loss 4.142915 Test MSE 5.40483638926073 Test RE 1.1112181753759547\n",
      "36 Train Loss 3.9476361 Test MSE 5.529753864459495 Test RE 1.1239861522892505\n",
      "37 Train Loss 3.7241638 Test MSE 5.388652125121504 Test RE 1.1095532099272518\n",
      "38 Train Loss 3.552509 Test MSE 5.347916457467504 Test RE 1.1053514045611297\n",
      "39 Train Loss 3.41337 Test MSE 5.388889063984425 Test RE 1.1095776031688263\n",
      "40 Train Loss 3.3477304 Test MSE 5.369865854545958 Test RE 1.107617422895524\n",
      "41 Train Loss 3.2521167 Test MSE 5.36436019609506 Test RE 1.1070494639106065\n",
      "42 Train Loss 3.0919008 Test MSE 5.354807897229185 Test RE 1.1060633650277956\n",
      "43 Train Loss 2.9899616 Test MSE 5.381549519619892 Test RE 1.108821735980512\n",
      "44 Train Loss 2.907105 Test MSE 5.320157046835318 Test RE 1.1024789003662236\n",
      "45 Train Loss 2.840862 Test MSE 5.289854583458998 Test RE 1.099334676135073\n",
      "46 Train Loss 2.7423978 Test MSE 5.280621593805172 Test RE 1.098374859711639\n",
      "47 Train Loss 2.67634 Test MSE 5.217265551387732 Test RE 1.091765914816032\n",
      "48 Train Loss 2.583237 Test MSE 5.144428883042426 Test RE 1.0841182221497536\n",
      "49 Train Loss 2.4797378 Test MSE 5.1450529947723 Test RE 1.0841839816727616\n",
      "50 Train Loss 2.3688684 Test MSE 5.1671233163281585 Test RE 1.0865068618452187\n",
      "51 Train Loss 2.306229 Test MSE 5.180523245508343 Test RE 1.0879147717472093\n",
      "52 Train Loss 2.1995564 Test MSE 5.196061847061176 Test RE 1.089545110638842\n",
      "53 Train Loss 2.1208823 Test MSE 5.128057785940528 Test RE 1.082391854888003\n",
      "54 Train Loss 2.0509303 Test MSE 5.130240987642111 Test RE 1.0826222372646421\n",
      "55 Train Loss 2.0246332 Test MSE 5.138166432569197 Test RE 1.0834581581984373\n",
      "56 Train Loss 1.9908249 Test MSE 5.123644456130256 Test RE 1.0819259884068215\n",
      "57 Train Loss 1.9347621 Test MSE 5.119225349415168 Test RE 1.0814593110434219\n",
      "58 Train Loss 1.8958143 Test MSE 5.123675332502017 Test RE 1.0819292483811418\n",
      "59 Train Loss 1.8601508 Test MSE 5.131058079078662 Test RE 1.0827084482381126\n",
      "60 Train Loss 1.8166232 Test MSE 5.068663153765025 Test RE 1.0761053126969442\n",
      "61 Train Loss 1.7876606 Test MSE 5.027663943448492 Test RE 1.071744296060712\n",
      "62 Train Loss 1.7341661 Test MSE 4.9772174586072095 Test RE 1.0663539160917443\n",
      "63 Train Loss 1.702596 Test MSE 4.9689203984068975 Test RE 1.0654647352349298\n",
      "64 Train Loss 1.6769053 Test MSE 4.9774307910784765 Test RE 1.0663767687680112\n",
      "65 Train Loss 1.6436757 Test MSE 4.981937023913302 Test RE 1.0668593726548985\n",
      "66 Train Loss 1.6110337 Test MSE 4.998703119309116 Test RE 1.0686530567200174\n",
      "67 Train Loss 1.578894 Test MSE 4.990156145873305 Test RE 1.0677390539557468\n",
      "68 Train Loss 1.5428439 Test MSE 4.930988214181626 Test RE 1.0613901245681965\n",
      "69 Train Loss 1.5120276 Test MSE 4.919720885804 Test RE 1.0601767906505684\n",
      "70 Train Loss 1.489075 Test MSE 4.905548604325065 Test RE 1.0586486592171311\n",
      "71 Train Loss 1.4708605 Test MSE 4.888034184840853 Test RE 1.0567571076572169\n",
      "72 Train Loss 1.4499818 Test MSE 4.9095146979499305 Test RE 1.0590765268958229\n",
      "73 Train Loss 1.4339628 Test MSE 4.901026534560075 Test RE 1.0581606009742148\n",
      "74 Train Loss 1.4141293 Test MSE 4.908629864432357 Test RE 1.0589810848110746\n",
      "75 Train Loss 1.3988839 Test MSE 4.934272543296061 Test RE 1.0617435399554256\n",
      "76 Train Loss 1.3733394 Test MSE 4.922200796380886 Test RE 1.0604439615388468\n",
      "77 Train Loss 1.345711 Test MSE 4.971135865429974 Test RE 1.0657022354098509\n",
      "78 Train Loss 1.3305583 Test MSE 4.967182339014434 Test RE 1.065278376548604\n",
      "79 Train Loss 1.3033367 Test MSE 4.906349653351476 Test RE 1.0587350914318912\n",
      "80 Train Loss 1.2896723 Test MSE 4.914814361260593 Test RE 1.0596479922523236\n",
      "81 Train Loss 1.2827922 Test MSE 4.92256652790747 Test RE 1.0604833575936705\n",
      "82 Train Loss 1.265292 Test MSE 4.9022365204383656 Test RE 1.058291214465057\n",
      "83 Train Loss 1.2490866 Test MSE 4.90927340683562 Test RE 1.0590505010143478\n",
      "84 Train Loss 1.2322822 Test MSE 4.913941974651953 Test RE 1.0595539435583554\n",
      "85 Train Loss 1.2204505 Test MSE 4.9056436711138005 Test RE 1.058658917176939\n",
      "86 Train Loss 1.2140335 Test MSE 4.914965736785258 Test RE 1.0596643106240773\n",
      "87 Train Loss 1.2044346 Test MSE 4.925444774221747 Test RE 1.0607933469305744\n",
      "88 Train Loss 1.1933777 Test MSE 4.920850118450143 Test RE 1.060298455840552\n",
      "89 Train Loss 1.1744533 Test MSE 4.903328059167549 Test RE 1.0584090281962977\n",
      "90 Train Loss 1.1669054 Test MSE 4.881224770958077 Test RE 1.0560207784800697\n",
      "91 Train Loss 1.1550663 Test MSE 4.855574061097623 Test RE 1.0532424427194176\n",
      "92 Train Loss 1.1366603 Test MSE 4.839390423640466 Test RE 1.0514857482121744\n",
      "93 Train Loss 1.115395 Test MSE 4.779894492960919 Test RE 1.0450022259339038\n",
      "94 Train Loss 1.0894636 Test MSE 4.756087060184072 Test RE 1.0423965328131535\n",
      "95 Train Loss 1.0732911 Test MSE 4.7743443561314205 Test RE 1.0443953516654048\n",
      "96 Train Loss 1.0539906 Test MSE 4.78581849422604 Test RE 1.0456495914368789\n",
      "97 Train Loss 1.036176 Test MSE 4.785088528468893 Test RE 1.0455698435834702\n",
      "98 Train Loss 1.0287007 Test MSE 4.779359640003176 Test RE 1.0449437583078465\n",
      "99 Train Loss 1.0208532 Test MSE 4.76593724200009 Test RE 1.0434754117754304\n",
      "Training time: 158.42\n",
      "6\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.84732 Test MSE 6.166325280702173 Test RE 1.1869195289201777\n",
      "1 Train Loss 54.531715 Test MSE 8.332045703686171 Test RE 1.3796975148673665\n",
      "2 Train Loss 40.80864 Test MSE 8.840827635948132 Test RE 1.4211977852362012\n",
      "3 Train Loss 34.36571 Test MSE 8.680074678113023 Test RE 1.408217675295768\n",
      "4 Train Loss 30.816494 Test MSE 8.195135083949983 Test RE 1.368315096734429\n",
      "5 Train Loss 28.609001 Test MSE 8.153675217604162 Test RE 1.3648494983541533\n",
      "6 Train Loss 25.574821 Test MSE 8.022719232521505 Test RE 1.3538447248642707\n",
      "7 Train Loss 23.231787 Test MSE 8.15762412271191 Test RE 1.365179963365515\n",
      "8 Train Loss 20.365746 Test MSE 7.980903329692169 Test RE 1.3503118702877424\n",
      "9 Train Loss 18.128643 Test MSE 8.204355431256744 Test RE 1.3690846260723348\n",
      "10 Train Loss 15.522673 Test MSE 8.079363745255366 Test RE 1.3586157373088696\n",
      "11 Train Loss 13.222066 Test MSE 7.499751828528565 Test RE 1.3089754656048946\n",
      "12 Train Loss 11.475355 Test MSE 7.191871736321146 Test RE 1.2818258541352199\n",
      "13 Train Loss 9.886678 Test MSE 6.888030871448718 Test RE 1.2544564901259683\n",
      "14 Train Loss 8.737507 Test MSE 6.7954447348356295 Test RE 1.2459970173100128\n",
      "15 Train Loss 7.6975536 Test MSE 6.629729470804173 Test RE 1.230710664372358\n",
      "16 Train Loss 6.6119785 Test MSE 6.533511093474603 Test RE 1.2217472684015815\n",
      "17 Train Loss 5.401472 Test MSE 5.902695994942392 Test RE 1.1612701652106383\n",
      "18 Train Loss 4.3149486 Test MSE 5.18543167355962 Test RE 1.0884300369876354\n",
      "19 Train Loss 3.6443634 Test MSE 5.065956990988718 Test RE 1.0758180076570099\n",
      "20 Train Loss 3.1738513 Test MSE 5.182099277118715 Test RE 1.0880802432260728\n",
      "21 Train Loss 2.9457726 Test MSE 5.179063760598789 Test RE 1.0877615143479755\n",
      "22 Train Loss 2.7249951 Test MSE 5.15375750200169 Test RE 1.0851007165576534\n",
      "23 Train Loss 2.582102 Test MSE 5.1090033394184315 Test RE 1.0803790487851341\n",
      "24 Train Loss 2.496245 Test MSE 5.175767131653421 Test RE 1.0874152628745615\n",
      "25 Train Loss 2.39662 Test MSE 5.18756369454067 Test RE 1.0886537712245132\n",
      "26 Train Loss 2.3236349 Test MSE 5.192855482143431 Test RE 1.0892088927084398\n",
      "27 Train Loss 2.2367554 Test MSE 5.2226873966620735 Test RE 1.092333055661358\n",
      "28 Train Loss 2.154623 Test MSE 5.262687054965599 Test RE 1.0965080718288827\n",
      "29 Train Loss 2.0914001 Test MSE 5.280873927308371 Test RE 1.0984011022155147\n",
      "30 Train Loss 2.029806 Test MSE 5.300585297186479 Test RE 1.1004491367563125\n",
      "31 Train Loss 1.9812065 Test MSE 5.313491436889563 Test RE 1.1017880375316025\n",
      "32 Train Loss 1.9131889 Test MSE 5.361025142358645 Test RE 1.1067052808822766\n",
      "33 Train Loss 1.8542795 Test MSE 5.421213628429763 Test RE 1.1129004576290698\n",
      "34 Train Loss 1.8068315 Test MSE 5.420014108823147 Test RE 1.1127773283942994\n",
      "35 Train Loss 1.7657692 Test MSE 5.44073158609288 Test RE 1.1149020415581916\n",
      "36 Train Loss 1.7316308 Test MSE 5.446758403708142 Test RE 1.1155193713607072\n",
      "37 Train Loss 1.6911271 Test MSE 5.500866909899855 Test RE 1.121046505061983\n",
      "38 Train Loss 1.6417065 Test MSE 5.528896764889701 Test RE 1.123899041234757\n",
      "39 Train Loss 1.6021099 Test MSE 5.490346107070277 Test RE 1.1199739510263296\n",
      "40 Train Loss 1.5657269 Test MSE 5.562573632671124 Test RE 1.1273167156913166\n",
      "41 Train Loss 1.5243781 Test MSE 5.580489897355411 Test RE 1.1291307202299596\n",
      "42 Train Loss 1.490885 Test MSE 5.5768925176744695 Test RE 1.128766722909954\n",
      "43 Train Loss 1.4563723 Test MSE 5.644375047301172 Test RE 1.1355754420649502\n",
      "44 Train Loss 1.4327036 Test MSE 5.641783674999503 Test RE 1.1353147368005638\n",
      "45 Train Loss 1.4144653 Test MSE 5.644257963080173 Test RE 1.1355636640864832\n",
      "46 Train Loss 1.3892394 Test MSE 5.641757596028378 Test RE 1.1353121128188446\n",
      "47 Train Loss 1.3675147 Test MSE 5.637406308591356 Test RE 1.134874215395741\n",
      "48 Train Loss 1.3296355 Test MSE 5.69158657703676 Test RE 1.1403147277965935\n",
      "49 Train Loss 1.3096793 Test MSE 5.731882959550888 Test RE 1.1443443170946597\n",
      "50 Train Loss 1.2934805 Test MSE 5.726898932092481 Test RE 1.1438466897091653\n",
      "51 Train Loss 1.27283 Test MSE 5.725401466246621 Test RE 1.143697133784064\n",
      "52 Train Loss 1.247544 Test MSE 5.750255550140753 Test RE 1.1461768517995163\n",
      "53 Train Loss 1.2251275 Test MSE 5.76527358114591 Test RE 1.147672619676919\n",
      "54 Train Loss 1.2050233 Test MSE 5.7927768456251405 Test RE 1.1504068514299792\n",
      "55 Train Loss 1.1859114 Test MSE 5.810422248724721 Test RE 1.1521576488579321\n",
      "56 Train Loss 1.1647694 Test MSE 5.836715472156363 Test RE 1.1547615684282317\n",
      "57 Train Loss 1.1441438 Test MSE 5.813155142122388 Test RE 1.1524285718424043\n",
      "58 Train Loss 1.1275792 Test MSE 5.8007530685224 Test RE 1.1511985913202984\n",
      "59 Train Loss 1.1104939 Test MSE 5.8626199047920045 Test RE 1.1573212551638534\n",
      "60 Train Loss 1.0922637 Test MSE 5.901152003414338 Test RE 1.161118276263308\n",
      "61 Train Loss 1.0740145 Test MSE 5.897935372853899 Test RE 1.160801778939869\n",
      "62 Train Loss 1.0572858 Test MSE 5.943877817754418 Test RE 1.1653140884355493\n",
      "63 Train Loss 1.0374653 Test MSE 5.919425712920403 Test RE 1.1629146659686942\n",
      "64 Train Loss 1.0226119 Test MSE 5.919759065251556 Test RE 1.1629474102648485\n",
      "65 Train Loss 1.0147357 Test MSE 5.944786648811283 Test RE 1.1654031744822777\n",
      "66 Train Loss 1.0045317 Test MSE 5.941560210659233 Test RE 1.1650868795663227\n",
      "67 Train Loss 0.9969186 Test MSE 5.9517915039284475 Test RE 1.1660895806976879\n",
      "68 Train Loss 0.98816466 Test MSE 5.994891817735908 Test RE 1.170304124048763\n",
      "69 Train Loss 0.9813742 Test MSE 5.970065678193019 Test RE 1.1678783691995906\n",
      "70 Train Loss 0.9711616 Test MSE 5.976379436922917 Test RE 1.1684957622171988\n",
      "71 Train Loss 0.9631227 Test MSE 5.989226341661827 Test RE 1.1697509950302747\n",
      "72 Train Loss 0.9578898 Test MSE 5.972937482462417 Test RE 1.1681592299997428\n",
      "73 Train Loss 0.94958776 Test MSE 5.984048741463456 Test RE 1.1692452692366244\n",
      "74 Train Loss 0.94342285 Test MSE 6.005138584993102 Test RE 1.1713038680356918\n",
      "75 Train Loss 0.9339523 Test MSE 6.005674576315075 Test RE 1.1713561394938405\n",
      "76 Train Loss 0.9301248 Test MSE 6.009018640669541 Test RE 1.1716822098743118\n",
      "77 Train Loss 0.92300117 Test MSE 6.037753745905655 Test RE 1.1744803587079138\n",
      "78 Train Loss 0.9178801 Test MSE 6.040576894591792 Test RE 1.1747549099166044\n",
      "79 Train Loss 0.9094503 Test MSE 6.049974589860324 Test RE 1.1756683738366502\n",
      "80 Train Loss 0.9018248 Test MSE 6.047790583861766 Test RE 1.1754561499245744\n",
      "81 Train Loss 0.8942209 Test MSE 6.074321705042779 Test RE 1.1780316393699715\n",
      "82 Train Loss 0.8881626 Test MSE 6.09922588747073 Test RE 1.180444082030007\n",
      "83 Train Loss 0.8841924 Test MSE 6.096427960871397 Test RE 1.1801732956367201\n",
      "84 Train Loss 0.87952256 Test MSE 6.091441925743366 Test RE 1.1796905876319117\n",
      "85 Train Loss 0.8755443 Test MSE 6.088742072214261 Test RE 1.1794291269771973\n",
      "86 Train Loss 0.87143445 Test MSE 6.091569632146378 Test RE 1.1797029536081327\n",
      "87 Train Loss 0.86679107 Test MSE 6.096838899882418 Test RE 1.180213070655603\n",
      "88 Train Loss 0.8613838 Test MSE 6.1026680764973875 Test RE 1.1807771356506465\n",
      "89 Train Loss 0.85532224 Test MSE 6.1354797913223775 Test RE 1.1839471741224334\n",
      "90 Train Loss 0.8506465 Test MSE 6.144176392325192 Test RE 1.18478595695145\n",
      "91 Train Loss 0.8458347 Test MSE 6.152338394956074 Test RE 1.1855726382003826\n",
      "92 Train Loss 0.83950734 Test MSE 6.182074059166638 Test RE 1.1884342570534545\n",
      "93 Train Loss 0.8341794 Test MSE 6.1862410638153715 Test RE 1.18883471948747\n",
      "94 Train Loss 0.82851654 Test MSE 6.178476086648978 Test RE 1.1880883718304438\n",
      "95 Train Loss 0.823177 Test MSE 6.194939878354649 Test RE 1.189670268875871\n",
      "96 Train Loss 0.8193606 Test MSE 6.225510209373258 Test RE 1.1926020049147228\n",
      "97 Train Loss 0.81555474 Test MSE 6.226502180498774 Test RE 1.1926970155717842\n",
      "98 Train Loss 0.8120503 Test MSE 6.207877370390687 Test RE 1.1909118727090187\n",
      "99 Train Loss 0.8081603 Test MSE 6.194687888032942 Test RE 1.1896460726408544\n",
      "Training time: 157.65\n",
      "7\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.51374 Test MSE 6.057882263336592 Test RE 1.1764364568752974\n",
      "1 Train Loss 45.932804 Test MSE 7.3088330115548565 Test RE 1.2922069722929674\n",
      "2 Train Loss 37.147133 Test MSE 6.686771993361553 Test RE 1.235993872391777\n",
      "3 Train Loss 28.399635 Test MSE 6.0356542828703015 Test RE 1.1742761443103438\n",
      "4 Train Loss 25.614153 Test MSE 5.86947918210114 Test RE 1.1579980913675292\n",
      "5 Train Loss 21.890142 Test MSE 5.914613024705889 Test RE 1.1624418258633997\n",
      "6 Train Loss 18.68185 Test MSE 5.493278238244929 Test RE 1.1202729733597792\n",
      "7 Train Loss 17.018713 Test MSE 5.609593138704624 Test RE 1.132071199593933\n",
      "8 Train Loss 15.476423 Test MSE 5.489912962208517 Test RE 1.1199297716138696\n",
      "9 Train Loss 14.546777 Test MSE 5.810352719002545 Test RE 1.1521507552590289\n",
      "10 Train Loss 13.581094 Test MSE 5.918812020829848 Test RE 1.1628543822464708\n",
      "11 Train Loss 12.970176 Test MSE 5.882404473946483 Test RE 1.1592724150212552\n",
      "12 Train Loss 12.453746 Test MSE 6.014323889158129 Test RE 1.172199323752508\n",
      "13 Train Loss 12.073261 Test MSE 5.920574820576871 Test RE 1.1630275358115334\n",
      "14 Train Loss 11.6856 Test MSE 5.775289466783726 Test RE 1.1486691005371037\n",
      "15 Train Loss 11.176677 Test MSE 5.7565680635592225 Test RE 1.1468058040350866\n",
      "16 Train Loss 10.795548 Test MSE 5.680236904892695 Test RE 1.1391772016760748\n",
      "17 Train Loss 10.493011 Test MSE 5.669309922031147 Test RE 1.1380809655395028\n",
      "18 Train Loss 10.086018 Test MSE 5.767818153753329 Test RE 1.147925861271524\n",
      "19 Train Loss 9.888359 Test MSE 5.717561006661751 Test RE 1.1429137666054405\n",
      "20 Train Loss 9.6431465 Test MSE 5.798518366021596 Test RE 1.1509768240638454\n",
      "21 Train Loss 9.515474 Test MSE 5.798613971721245 Test RE 1.1509863126507587\n",
      "22 Train Loss 9.145701 Test MSE 5.447857719557546 Test RE 1.1156319379704553\n",
      "23 Train Loss 8.556316 Test MSE 5.327309294739753 Test RE 1.1032197200414933\n",
      "24 Train Loss 8.217052 Test MSE 5.148711252111623 Test RE 1.0845693537226073\n",
      "25 Train Loss 7.6082163 Test MSE 5.104394929792625 Test RE 1.079891678535858\n",
      "26 Train Loss 7.2191596 Test MSE 4.922808044473149 Test RE 1.060509372595758\n",
      "27 Train Loss 6.7714605 Test MSE 4.863661646689166 Test RE 1.054119233415252\n",
      "28 Train Loss 6.2990856 Test MSE 4.7063516146354845 Test RE 1.036931924529316\n",
      "29 Train Loss 5.9905996 Test MSE 4.551986498814338 Test RE 1.0197848198209982\n",
      "30 Train Loss 5.578171 Test MSE 4.383455208742788 Test RE 1.000728680947663\n",
      "31 Train Loss 5.2804613 Test MSE 4.3946745695984974 Test RE 1.0020085344735614\n",
      "32 Train Loss 5.0050173 Test MSE 4.327223400231392 Test RE 0.9942891923121557\n",
      "33 Train Loss 4.670362 Test MSE 4.035151489225943 Test RE 0.9601475591095769\n",
      "34 Train Loss 4.4225235 Test MSE 3.811810257657487 Test RE 0.9331977811068034\n",
      "35 Train Loss 4.1569858 Test MSE 3.521999626908416 Test RE 0.8970212122023228\n",
      "36 Train Loss 3.8806584 Test MSE 3.231899894405418 Test RE 0.8592845643486694\n",
      "37 Train Loss 3.4451602 Test MSE 2.947609733504961 Test RE 0.8206218025505867\n",
      "38 Train Loss 3.2833662 Test MSE 2.7687187912125784 Test RE 0.7953302197159592\n",
      "39 Train Loss 2.8717797 Test MSE 2.3742879976959905 Test RE 0.73650340469555\n",
      "40 Train Loss 2.6604323 Test MSE 2.1260065266486663 Test RE 0.6969319216229666\n",
      "41 Train Loss 2.2747004 Test MSE 1.872723970228446 Test RE 0.6541011986025396\n",
      "42 Train Loss 1.996452 Test MSE 1.836622272558222 Test RE 0.6477657533405973\n",
      "43 Train Loss 1.7996509 Test MSE 1.648581983255125 Test RE 0.6137101908282877\n",
      "44 Train Loss 1.6025851 Test MSE 1.5311763661722841 Test RE 0.5914535854014399\n",
      "45 Train Loss 1.4440166 Test MSE 1.391493878001775 Test RE 0.5638306885658747\n",
      "46 Train Loss 1.3023353 Test MSE 1.269068841732139 Test RE 0.5384565335411557\n",
      "47 Train Loss 1.2377107 Test MSE 1.2198789948055984 Test RE 0.5279179596951807\n",
      "48 Train Loss 1.158699 Test MSE 1.1636618522769093 Test RE 0.5156101510662211\n",
      "49 Train Loss 1.0882736 Test MSE 1.106460588071538 Test RE 0.5027777322821257\n",
      "50 Train Loss 1.0258478 Test MSE 1.0218920880791877 Test RE 0.48318181252474024\n",
      "51 Train Loss 0.9764605 Test MSE 0.992790535770077 Test RE 0.47625206797982644\n",
      "52 Train Loss 0.90465975 Test MSE 0.9638576309202691 Test RE 0.4692610470534301\n",
      "53 Train Loss 0.8232697 Test MSE 0.7821670240036863 Test RE 0.4227248818244742\n",
      "54 Train Loss 0.7724999 Test MSE 0.7159993565683687 Test RE 0.40444956839122614\n",
      "55 Train Loss 0.7030988 Test MSE 0.690189060984568 Test RE 0.3970928763929939\n",
      "56 Train Loss 0.6639855 Test MSE 0.6569213061642957 Test RE 0.38740456517784333\n",
      "57 Train Loss 0.6154989 Test MSE 0.5961485585999836 Test RE 0.36905008474929724\n",
      "58 Train Loss 0.5257286 Test MSE 0.5191021909983321 Test RE 0.3443772797851476\n",
      "59 Train Loss 0.45992878 Test MSE 0.47115339643974546 Test RE 0.328087151828645\n",
      "60 Train Loss 0.4016457 Test MSE 0.3894245649221487 Test RE 0.29827697634257044\n",
      "61 Train Loss 0.35571778 Test MSE 0.3627598776212855 Test RE 0.2878841029324079\n",
      "62 Train Loss 0.3300374 Test MSE 0.34105680572953734 Test RE 0.27913957979413506\n",
      "63 Train Loss 0.31163996 Test MSE 0.30149032447821034 Test RE 0.2624488957816212\n",
      "64 Train Loss 0.2805902 Test MSE 0.2439217900990613 Test RE 0.23606595561436688\n",
      "65 Train Loss 0.25531885 Test MSE 0.22978622388156333 Test RE 0.22912372140772558\n",
      "66 Train Loss 0.21058406 Test MSE 0.16582602055759407 Test RE 0.1946410324883158\n",
      "67 Train Loss 0.19402069 Test MSE 0.13757184188670998 Test RE 0.17728534474489624\n",
      "68 Train Loss 0.17950158 Test MSE 0.11416858348755192 Test RE 0.16150328732994812\n",
      "69 Train Loss 0.16696128 Test MSE 0.11192222405189044 Test RE 0.1599065399313736\n",
      "70 Train Loss 0.1545431 Test MSE 0.10556592594813743 Test RE 0.15529945833489098\n",
      "71 Train Loss 0.13492996 Test MSE 0.09323396566013335 Test RE 0.14594698874888526\n",
      "72 Train Loss 0.11545244 Test MSE 0.06796741695099195 Test RE 0.12461159154530792\n",
      "73 Train Loss 0.10701018 Test MSE 0.056686884257838355 Test RE 0.11380185829528434\n",
      "74 Train Loss 0.09282801 Test MSE 0.04239931807292745 Test RE 0.0984209371774927\n",
      "75 Train Loss 0.08601373 Test MSE 0.0413468772708357 Test RE 0.0971917535398486\n",
      "76 Train Loss 0.07898405 Test MSE 0.040444386962513346 Test RE 0.09612518502665558\n",
      "77 Train Loss 0.07388551 Test MSE 0.040248651975248996 Test RE 0.09589229879798129\n",
      "78 Train Loss 0.071297504 Test MSE 0.04249559980758346 Test RE 0.09853262252301072\n",
      "79 Train Loss 0.06736658 Test MSE 0.047053759443337895 Test RE 0.10368244361597881\n",
      "80 Train Loss 0.063123375 Test MSE 0.04941826291255431 Test RE 0.10625559267782764\n",
      "81 Train Loss 0.057879955 Test MSE 0.04406048951399152 Test RE 0.10033044054595813\n",
      "82 Train Loss 0.055176713 Test MSE 0.04294713049216619 Test RE 0.09905471121711786\n",
      "83 Train Loss 0.050938644 Test MSE 0.04069702748024166 Test RE 0.09642494614778938\n",
      "84 Train Loss 0.04723092 Test MSE 0.039324670665106504 Test RE 0.09478521671388429\n",
      "85 Train Loss 0.04467608 Test MSE 0.04033387994339027 Test RE 0.0959937728034594\n",
      "86 Train Loss 0.043106917 Test MSE 0.041284085724273965 Test RE 0.09711792524013117\n",
      "87 Train Loss 0.040893067 Test MSE 0.03836790230502837 Test RE 0.0936250554831095\n",
      "88 Train Loss 0.039400112 Test MSE 0.034867545866513965 Test RE 0.08925216316491544\n",
      "89 Train Loss 0.037144832 Test MSE 0.03308234164092174 Test RE 0.08693730664285206\n",
      "90 Train Loss 0.034706984 Test MSE 0.03331991304961151 Test RE 0.08724890597426554\n",
      "91 Train Loss 0.03287546 Test MSE 0.03355230692485303 Test RE 0.08755264145419614\n",
      "92 Train Loss 0.03195504 Test MSE 0.03297103696864218 Test RE 0.08679093427663227\n",
      "93 Train Loss 0.02928526 Test MSE 0.029546662092091246 Test RE 0.08216034854724885\n",
      "94 Train Loss 0.027729455 Test MSE 0.02889090669632517 Test RE 0.08124350400999765\n",
      "95 Train Loss 0.026614416 Test MSE 0.02748906556194526 Test RE 0.0792479522251837\n",
      "96 Train Loss 0.02572767 Test MSE 0.02677334715813706 Test RE 0.07820947938619618\n",
      "97 Train Loss 0.024939103 Test MSE 0.0271087500027032 Test RE 0.07869783891066383\n",
      "98 Train Loss 0.02367132 Test MSE 0.026224058032098957 Test RE 0.07740303839897482\n",
      "99 Train Loss 0.02269176 Test MSE 0.025519841389057024 Test RE 0.07635668153882681\n",
      "Training time: 158.66\n",
      "8\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.815716 Test MSE 5.366933271709577 Test RE 1.1073149364344532\n",
      "1 Train Loss 49.365692 Test MSE 6.6100226705358915 Test RE 1.2288801659021737\n",
      "2 Train Loss 35.541576 Test MSE 7.446096506041138 Test RE 1.304284672413178\n",
      "3 Train Loss 32.10117 Test MSE 6.618446576038743 Test RE 1.2296629676287052\n",
      "4 Train Loss 27.399467 Test MSE 7.101742760176248 Test RE 1.2737685709832922\n",
      "5 Train Loss 25.984062 Test MSE 7.505086443891454 Test RE 1.3094409236286413\n",
      "6 Train Loss 24.84336 Test MSE 7.547761574198757 Test RE 1.3131584924427098\n",
      "7 Train Loss 22.195164 Test MSE 7.8481452419072495 Test RE 1.3390339125291228\n",
      "8 Train Loss 20.499237 Test MSE 8.344298133892014 Test RE 1.3807115778011025\n",
      "9 Train Loss 19.707045 Test MSE 8.251128176454072 Test RE 1.3729816317299606\n",
      "10 Train Loss 18.331326 Test MSE 8.778704900012826 Test RE 1.4161957456953986\n",
      "11 Train Loss 17.16453 Test MSE 8.63488252092924 Test RE 1.4045470014842614\n",
      "12 Train Loss 16.32184 Test MSE 8.438859301492874 Test RE 1.3885129460351038\n",
      "13 Train Loss 15.672766 Test MSE 8.658727747648472 Test RE 1.406484992627612\n",
      "14 Train Loss 15.227045 Test MSE 8.654488538404562 Test RE 1.4061406513853074\n",
      "15 Train Loss 14.839592 Test MSE 8.672496665962555 Test RE 1.4076028291559495\n",
      "16 Train Loss 14.497968 Test MSE 8.581366799923984 Test RE 1.4001878125116867\n",
      "17 Train Loss 14.094109 Test MSE 8.39320859976156 Test RE 1.3847522157945715\n",
      "18 Train Loss 13.607516 Test MSE 8.2746117295869 Test RE 1.3749340664544247\n",
      "19 Train Loss 13.17095 Test MSE 8.316489783402398 Test RE 1.3784089662754306\n",
      "20 Train Loss 12.373743 Test MSE 8.276568196027064 Test RE 1.375096602985269\n",
      "21 Train Loss 11.715628 Test MSE 8.061583703515751 Test RE 1.3571199791077928\n",
      "22 Train Loss 10.754757 Test MSE 7.652947922247751 Test RE 1.322276986292577\n",
      "23 Train Loss 9.887109 Test MSE 7.595241007071039 Test RE 1.317282249964716\n",
      "24 Train Loss 9.435758 Test MSE 7.443712783039675 Test RE 1.3040758850144958\n",
      "25 Train Loss 9.089518 Test MSE 7.388744836090894 Test RE 1.299252002007725\n",
      "26 Train Loss 8.604128 Test MSE 7.343143423654341 Test RE 1.2952364739106454\n",
      "27 Train Loss 8.215728 Test MSE 7.306216991210167 Test RE 1.2919756944498038\n",
      "28 Train Loss 7.8807797 Test MSE 7.2749246759671795 Test RE 1.2892059784202932\n",
      "29 Train Loss 7.496338 Test MSE 7.121697696002266 Test RE 1.2755568742721173\n",
      "30 Train Loss 6.530548 Test MSE 6.4948980936054745 Test RE 1.2181316599925078\n",
      "31 Train Loss 5.746436 Test MSE 6.381847928113449 Test RE 1.2074837251625892\n",
      "32 Train Loss 5.204376 Test MSE 6.244380896521899 Test RE 1.1944081372626327\n",
      "33 Train Loss 4.812924 Test MSE 6.293136998824927 Test RE 1.19906203761513\n",
      "34 Train Loss 4.3637676 Test MSE 6.454586949423899 Test RE 1.2143455566445431\n",
      "35 Train Loss 4.231531 Test MSE 6.5538389425548305 Test RE 1.2236464161896068\n",
      "36 Train Loss 4.0543013 Test MSE 6.6272207363158 Test RE 1.2304777877185669\n",
      "37 Train Loss 3.9166749 Test MSE 6.628490669543645 Test RE 1.2305956764866546\n",
      "38 Train Loss 3.816455 Test MSE 6.55374723292955 Test RE 1.2236378547534874\n",
      "39 Train Loss 3.7143285 Test MSE 6.566621342775535 Test RE 1.224839115559414\n",
      "40 Train Loss 3.6045692 Test MSE 6.659299294288651 Test RE 1.2334522097744336\n",
      "41 Train Loss 3.4834275 Test MSE 6.677495755390827 Test RE 1.2351362573569657\n",
      "42 Train Loss 3.3884559 Test MSE 6.655870670249966 Test RE 1.2331346396972844\n",
      "43 Train Loss 3.2326875 Test MSE 6.656892202101379 Test RE 1.2332292657833377\n",
      "44 Train Loss 3.171566 Test MSE 6.669149130594974 Test RE 1.2343640784712695\n",
      "45 Train Loss 3.0925775 Test MSE 6.652850831993124 Test RE 1.2328548649066868\n",
      "46 Train Loss 3.023786 Test MSE 6.64585329676393 Test RE 1.232206329772029\n",
      "47 Train Loss 2.9591663 Test MSE 6.705453469228886 Test RE 1.2377192254389624\n",
      "48 Train Loss 2.8973653 Test MSE 6.708865582685826 Test RE 1.2380340961129221\n",
      "49 Train Loss 2.8479564 Test MSE 6.736293278741132 Test RE 1.2405622275406065\n",
      "50 Train Loss 2.777798 Test MSE 6.764518666875084 Test RE 1.2431585180061144\n",
      "51 Train Loss 2.7357144 Test MSE 6.770207724291405 Test RE 1.2436811652307107\n",
      "52 Train Loss 2.6903164 Test MSE 6.819536345193325 Test RE 1.2482037541325914\n",
      "53 Train Loss 2.6470344 Test MSE 6.874699424845013 Test RE 1.2532419325947526\n",
      "54 Train Loss 2.62611 Test MSE 6.857618281180708 Test RE 1.2516840376409646\n",
      "55 Train Loss 2.5922115 Test MSE 6.837914148364548 Test RE 1.2498844995628793\n",
      "56 Train Loss 2.5519836 Test MSE 6.865657599087279 Test RE 1.25241750938305\n",
      "57 Train Loss 2.5265362 Test MSE 6.869128823873769 Test RE 1.252734075805981\n",
      "58 Train Loss 2.5042725 Test MSE 6.882590252562943 Test RE 1.2539609662205438\n",
      "59 Train Loss 2.4669495 Test MSE 6.907381190725011 Test RE 1.2562173060853756\n",
      "60 Train Loss 2.4347897 Test MSE 6.925164530460979 Test RE 1.2578333584178594\n",
      "61 Train Loss 2.3995 Test MSE 6.901527560792066 Test RE 1.2556849053396482\n",
      "62 Train Loss 2.3733265 Test MSE 6.90771595045937 Test RE 1.25624774641182\n",
      "63 Train Loss 2.3529408 Test MSE 6.909803205815746 Test RE 1.2564375277961655\n",
      "64 Train Loss 2.3249803 Test MSE 6.876649810229391 Test RE 1.2534196953780181\n",
      "65 Train Loss 2.3080468 Test MSE 6.887478329118825 Test RE 1.254406174279115\n",
      "66 Train Loss 2.2881737 Test MSE 6.9206952180780785 Test RE 1.2574274072316158\n",
      "67 Train Loss 2.2671926 Test MSE 6.909542984122159 Test RE 1.256413868990703\n",
      "68 Train Loss 2.250158 Test MSE 6.895578188190048 Test RE 1.2551435651818992\n",
      "69 Train Loss 2.2236013 Test MSE 6.9023531451062246 Test RE 1.255760007753678\n",
      "70 Train Loss 2.1993256 Test MSE 6.918129459936998 Test RE 1.2571942981592088\n",
      "71 Train Loss 2.184747 Test MSE 6.916403410262499 Test RE 1.257037455533669\n",
      "72 Train Loss 2.171785 Test MSE 6.931546614712831 Test RE 1.258412821170599\n",
      "73 Train Loss 2.158715 Test MSE 6.9573945243533775 Test RE 1.2607569642089749\n",
      "74 Train Loss 2.1436362 Test MSE 6.975884655064975 Test RE 1.2624311608636865\n",
      "75 Train Loss 2.1235569 Test MSE 6.999842768460519 Test RE 1.2645971617361766\n",
      "76 Train Loss 2.1108468 Test MSE 7.015472353525064 Test RE 1.2660082011504474\n",
      "77 Train Loss 2.1006355 Test MSE 7.004129419587888 Test RE 1.264984317373434\n",
      "78 Train Loss 2.08854 Test MSE 7.007875088708498 Test RE 1.2653225163918764\n",
      "79 Train Loss 2.0762746 Test MSE 7.010674630756066 Test RE 1.265575229934695\n",
      "80 Train Loss 2.063219 Test MSE 6.996540636965813 Test RE 1.2642988436985558\n",
      "81 Train Loss 2.0563788 Test MSE 7.009231088219202 Test RE 1.2654449282285747\n",
      "82 Train Loss 2.0404522 Test MSE 7.019126984525234 Test RE 1.266337914544879\n",
      "83 Train Loss 2.0222857 Test MSE 7.028762972177419 Test RE 1.267206842509938\n",
      "84 Train Loss 2.006231 Test MSE 7.043512021382308 Test RE 1.26853568953944\n",
      "85 Train Loss 1.9951919 Test MSE 7.048015014351103 Test RE 1.2689411190038997\n",
      "86 Train Loss 1.9848899 Test MSE 6.999776059532022 Test RE 1.2645911358777806\n",
      "87 Train Loss 1.9728473 Test MSE 6.987450940979334 Test RE 1.263477307192603\n",
      "88 Train Loss 1.9616926 Test MSE 7.002925457306081 Test RE 1.2648755915941374\n",
      "89 Train Loss 1.9545689 Test MSE 6.9983431240574445 Test RE 1.2644616910046989\n",
      "90 Train Loss 1.9435449 Test MSE 7.012346413592797 Test RE 1.2657261170419782\n",
      "91 Train Loss 1.9274042 Test MSE 6.997765680677752 Test RE 1.2644095236501154\n",
      "92 Train Loss 1.907778 Test MSE 6.946727952683332 Test RE 1.25979014302457\n",
      "93 Train Loss 1.896586 Test MSE 6.956193025858884 Test RE 1.260648097089698\n",
      "94 Train Loss 1.8857749 Test MSE 6.970737391893183 Test RE 1.2619653228474867\n",
      "95 Train Loss 1.8701948 Test MSE 6.965659212616036 Test RE 1.2615055684943381\n",
      "96 Train Loss 1.853468 Test MSE 6.945285160823943 Test RE 1.2596593109722798\n",
      "97 Train Loss 1.8444561 Test MSE 6.934757655333302 Test RE 1.2587042674409592\n",
      "98 Train Loss 1.831628 Test MSE 6.927340072715073 Test RE 1.2580309172430615\n",
      "99 Train Loss 1.8138334 Test MSE 6.944738852637084 Test RE 1.2596097683177054\n",
      "Training time: 157.76\n",
      "9\n",
      "KG_rowdy_tune28\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.797157 Test MSE 7.625968486186773 Test RE 1.3199441738564255\n",
      "1 Train Loss 48.60911 Test MSE 8.18275403994676 Test RE 1.3672810946904599\n",
      "2 Train Loss 41.07202 Test MSE 8.579268705188928 Test RE 1.4000166331219523\n",
      "3 Train Loss 35.217545 Test MSE 8.978005147903138 Test RE 1.4321812554183009\n",
      "4 Train Loss 31.88485 Test MSE 8.331455706564324 Test RE 1.3796486654009497\n",
      "5 Train Loss 29.349493 Test MSE 8.469760324173727 Test RE 1.3910528191403833\n",
      "6 Train Loss 27.54047 Test MSE 8.689561360847975 Test RE 1.4089870042825035\n",
      "7 Train Loss 25.944004 Test MSE 8.985722057655215 Test RE 1.4327966281785425\n",
      "8 Train Loss 25.21974 Test MSE 8.956772372504714 Test RE 1.430486715096095\n",
      "9 Train Loss 23.768799 Test MSE 8.813233519761813 Test RE 1.4189781205621357\n",
      "10 Train Loss 22.48967 Test MSE 8.786525643093373 Test RE 1.4168264331106772\n",
      "11 Train Loss 21.602211 Test MSE 8.86679831872561 Test RE 1.4232836991303566\n",
      "12 Train Loss 20.794975 Test MSE 8.94439498423201 Test RE 1.4294979766381781\n",
      "13 Train Loss 19.573467 Test MSE 9.065645898384364 Test RE 1.4391545533595063\n",
      "14 Train Loss 18.737532 Test MSE 9.235892529874674 Test RE 1.4526048693947535\n",
      "15 Train Loss 17.543966 Test MSE 9.303706636999095 Test RE 1.4579279576488398\n",
      "16 Train Loss 16.43794 Test MSE 9.095939135991598 Test RE 1.441557045803959\n",
      "17 Train Loss 15.482559 Test MSE 9.100759749235838 Test RE 1.4419389892407284\n",
      "18 Train Loss 13.608715 Test MSE 8.500059207675461 Test RE 1.3935387053716055\n",
      "19 Train Loss 12.70845 Test MSE 8.452297687956131 Test RE 1.3896180687970872\n",
      "20 Train Loss 10.83752 Test MSE 8.125435147378909 Test RE 1.3624838855378865\n",
      "21 Train Loss 9.947926 Test MSE 7.975697027785348 Test RE 1.3498713638772288\n",
      "22 Train Loss 8.963638 Test MSE 7.985599115164092 Test RE 1.3507090585622288\n",
      "23 Train Loss 7.4233036 Test MSE 7.788389552690979 Test RE 1.3339264774223738\n",
      "24 Train Loss 6.582428 Test MSE 7.6878240190100815 Test RE 1.325286508900249\n",
      "25 Train Loss 5.697008 Test MSE 7.591028865779878 Test RE 1.3169169324953218\n",
      "26 Train Loss 5.1630125 Test MSE 7.357088938414728 Test RE 1.29646579564843\n",
      "27 Train Loss 4.6047163 Test MSE 7.2765401897096 Test RE 1.2893491149099916\n",
      "28 Train Loss 4.0952454 Test MSE 7.214614043503465 Test RE 1.2838509644773028\n",
      "29 Train Loss 3.7969725 Test MSE 7.140454561394865 Test RE 1.2772355270900102\n",
      "30 Train Loss 3.3737073 Test MSE 6.949143646766552 Test RE 1.260009167224927\n",
      "31 Train Loss 3.0698595 Test MSE 6.809933100169625 Test RE 1.2473245866348963\n",
      "32 Train Loss 2.8455598 Test MSE 6.689221831921578 Test RE 1.236220267740752\n",
      "33 Train Loss 2.6390443 Test MSE 6.622262061442682 Test RE 1.2300173623536845\n",
      "34 Train Loss 2.5205464 Test MSE 6.746024952198087 Test RE 1.2414580012908234\n",
      "35 Train Loss 2.4091058 Test MSE 6.679435867455149 Test RE 1.23531567557067\n",
      "36 Train Loss 2.293818 Test MSE 6.670119424308077 Test RE 1.2344538689469053\n",
      "37 Train Loss 2.2234735 Test MSE 6.712297466955434 Test RE 1.2383507104842228\n",
      "38 Train Loss 2.1483836 Test MSE 6.656821244254107 Test RE 1.2332226930821109\n",
      "39 Train Loss 2.0801406 Test MSE 6.60359463903877 Test RE 1.228282497619557\n",
      "40 Train Loss 2.0118701 Test MSE 6.483777703295749 Test RE 1.2170883870574534\n",
      "41 Train Loss 1.9518467 Test MSE 6.45137978862891 Test RE 1.2140438266190716\n",
      "42 Train Loss 1.9016283 Test MSE 6.415087997663199 Test RE 1.2106242508848157\n",
      "43 Train Loss 1.8491349 Test MSE 6.316332363040259 Test RE 1.2012697680108932\n",
      "44 Train Loss 1.8055055 Test MSE 6.271424321867889 Test RE 1.1969917392918492\n",
      "45 Train Loss 1.7475718 Test MSE 6.166387636724371 Test RE 1.1869255301761943\n",
      "46 Train Loss 1.7003196 Test MSE 6.089353380280631 Test RE 1.179488332674735\n",
      "47 Train Loss 1.6594598 Test MSE 6.095685641953474 Test RE 1.1801014427714784\n",
      "48 Train Loss 1.6245509 Test MSE 6.050793936193619 Test RE 1.175747981357724\n",
      "49 Train Loss 1.581167 Test MSE 6.051573078078689 Test RE 1.1758236776233797\n",
      "50 Train Loss 1.5516714 Test MSE 5.985646260690683 Test RE 1.1694013313971956\n",
      "51 Train Loss 1.5370533 Test MSE 5.997481388583063 Test RE 1.1705568607394001\n",
      "52 Train Loss 1.5187924 Test MSE 5.992116821393273 Test RE 1.1700332296213247\n",
      "53 Train Loss 1.4982363 Test MSE 5.969894492091675 Test RE 1.1678616251645315\n",
      "54 Train Loss 1.4806184 Test MSE 5.99130737703978 Test RE 1.16995420005586\n",
      "55 Train Loss 1.4526255 Test MSE 5.903710083836553 Test RE 1.161369914596636\n",
      "56 Train Loss 1.431003 Test MSE 5.861802486452767 Test RE 1.157240570366656\n",
      "57 Train Loss 1.4047543 Test MSE 5.85781772592785 Test RE 1.1568471665888536\n",
      "58 Train Loss 1.383124 Test MSE 5.82827965712044 Test RE 1.1539267772350033\n",
      "59 Train Loss 1.3616519 Test MSE 5.814968929611999 Test RE 1.1526083449133806\n",
      "60 Train Loss 1.3281204 Test MSE 5.840338384590916 Test RE 1.1551198993306984\n",
      "61 Train Loss 1.302972 Test MSE 5.863271886666765 Test RE 1.1573856062148016\n",
      "62 Train Loss 1.2738398 Test MSE 5.89771063932799 Test RE 1.1607796632718206\n",
      "63 Train Loss 1.2477669 Test MSE 5.852373684153411 Test RE 1.1563094758871442\n",
      "64 Train Loss 1.2300452 Test MSE 5.869574875818548 Test RE 1.1580075311054525\n",
      "65 Train Loss 1.2110286 Test MSE 5.919641969761469 Test RE 1.1629359083972168\n",
      "66 Train Loss 1.1825901 Test MSE 5.8910410106156785 Test RE 1.1601231238193992\n",
      "67 Train Loss 1.1612935 Test MSE 5.890360817885502 Test RE 1.160056146684726\n",
      "68 Train Loss 1.1475697 Test MSE 5.905247087135247 Test RE 1.1615210833700431\n",
      "69 Train Loss 1.1339831 Test MSE 5.878021767183266 Test RE 1.1588404744953247\n",
      "70 Train Loss 1.1208807 Test MSE 5.902605003045985 Test RE 1.1612612145055803\n",
      "71 Train Loss 1.1085829 Test MSE 5.894096759561263 Test RE 1.1604239692397185\n",
      "72 Train Loss 1.0937219 Test MSE 5.911036825916359 Test RE 1.16209034457361\n",
      "73 Train Loss 1.0814548 Test MSE 5.947485114491739 Test RE 1.1656676451743253\n",
      "74 Train Loss 1.0743488 Test MSE 5.950269143358025 Test RE 1.1659404388528207\n",
      "75 Train Loss 1.06386 Test MSE 5.949230048172937 Test RE 1.1658386303494075\n",
      "76 Train Loss 1.0568868 Test MSE 5.957979770310121 Test RE 1.166695633364771\n",
      "77 Train Loss 1.0393398 Test MSE 5.952230575874903 Test RE 1.1661325919304624\n",
      "78 Train Loss 1.0260832 Test MSE 5.94475811761373 Test RE 1.1654003778816542\n",
      "79 Train Loss 1.0160264 Test MSE 5.981820491619837 Test RE 1.1690275560057317\n",
      "80 Train Loss 1.007781 Test MSE 5.988912710795501 Test RE 1.1697203671327783\n",
      "81 Train Loss 0.994576 Test MSE 5.997137323922 Test RE 1.1705232838927344\n",
      "82 Train Loss 0.9842552 Test MSE 6.010140735130799 Test RE 1.1717916018420753\n",
      "83 Train Loss 0.97123474 Test MSE 6.020290101631396 Test RE 1.1727805908079427\n",
      "84 Train Loss 0.96255565 Test MSE 6.04829454941298 Test RE 1.175505124592083\n",
      "85 Train Loss 0.9561019 Test MSE 6.062117451648631 Test RE 1.1768476203141276\n",
      "86 Train Loss 0.9413732 Test MSE 6.0883171023736455 Test RE 1.1793879665414055\n",
      "87 Train Loss 0.9323913 Test MSE 6.124336652953999 Test RE 1.1828715546727158\n",
      "88 Train Loss 0.9266403 Test MSE 6.125928357516965 Test RE 1.183025257827898\n",
      "89 Train Loss 0.92061186 Test MSE 6.1209425149647725 Test RE 1.1825437325818153\n",
      "90 Train Loss 0.9112265 Test MSE 6.130770991653779 Test RE 1.1834927646615838\n",
      "91 Train Loss 0.907275 Test MSE 6.143120599505415 Test RE 1.1846841579333158\n",
      "92 Train Loss 0.89835817 Test MSE 6.144928101580033 Test RE 1.1848584310531922\n",
      "93 Train Loss 0.89140797 Test MSE 6.133806471175087 Test RE 1.183785715049733\n",
      "94 Train Loss 0.88350105 Test MSE 6.129425694259535 Test RE 1.1833629084749022\n",
      "95 Train Loss 0.8761313 Test MSE 6.132299589725732 Test RE 1.183640296840573\n",
      "96 Train Loss 0.86977756 Test MSE 6.14152774449122 Test RE 1.1845305590897874\n",
      "97 Train Loss 0.86287606 Test MSE 6.131561709002188 Test RE 1.183569082802479\n",
      "98 Train Loss 0.85486335 Test MSE 6.121742562883854 Test RE 1.182621013224222\n",
      "99 Train Loss 0.8507472 Test MSE 6.137625925062221 Test RE 1.1841542228704751\n",
      "Training time: 156.94\n",
      "0\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 75.0773 Test MSE 4.4169182683448796 Test RE 1.0045411729611897\n",
      "1 Train Loss 72.3514 Test MSE 4.411303649679797 Test RE 1.0039025026494415\n",
      "2 Train Loss 55.137447 Test MSE 5.80680176595395 Test RE 1.1517986373492095\n",
      "3 Train Loss 40.518364 Test MSE 6.493876548824282 Test RE 1.2180358598000989\n",
      "4 Train Loss 32.817898 Test MSE 6.608991177149477 Test RE 1.2287842788468362\n",
      "5 Train Loss 29.019148 Test MSE 6.32697603233651 Test RE 1.2022814735029936\n",
      "6 Train Loss 24.92058 Test MSE 5.905043665191538 Test RE 1.161501077356087\n",
      "7 Train Loss 20.688427 Test MSE 5.522234708486955 Test RE 1.123221714817241\n",
      "8 Train Loss 18.922888 Test MSE 5.548707714558021 Test RE 1.1259107986152013\n",
      "9 Train Loss 16.75704 Test MSE 5.016698523073058 Test RE 1.070574911852867\n",
      "10 Train Loss 14.634853 Test MSE 5.426290668521813 Test RE 1.1134214588629678\n",
      "11 Train Loss 13.91165 Test MSE 5.659923964414981 Test RE 1.1371384871147265\n",
      "12 Train Loss 13.369415 Test MSE 5.491539937046789 Test RE 1.120095708905926\n",
      "13 Train Loss 12.735189 Test MSE 5.607927660766756 Test RE 1.131903132184491\n",
      "14 Train Loss 12.228015 Test MSE 5.552068747259054 Test RE 1.126251747384175\n",
      "15 Train Loss 11.518771 Test MSE 5.4592092647299095 Test RE 1.1167936383006971\n",
      "16 Train Loss 11.257891 Test MSE 5.419971824069642 Test RE 1.112772987666963\n",
      "17 Train Loss 10.898306 Test MSE 5.5214751701133125 Test RE 1.123144467165082\n",
      "18 Train Loss 10.566409 Test MSE 5.556118663246948 Test RE 1.1266624405582781\n",
      "19 Train Loss 10.190226 Test MSE 5.544844887403327 Test RE 1.1255188194160628\n",
      "20 Train Loss 9.911659 Test MSE 5.407858276991096 Test RE 1.1115287775007296\n",
      "21 Train Loss 9.57814 Test MSE 5.31325112931679 Test RE 1.1017631225575388\n",
      "22 Train Loss 9.244829 Test MSE 5.279182319090174 Test RE 1.098225164181584\n",
      "23 Train Loss 8.753891 Test MSE 5.1715169219499115 Test RE 1.086968692154808\n",
      "24 Train Loss 8.355108 Test MSE 5.201589101027119 Test RE 1.0901244524607758\n",
      "25 Train Loss 8.065084 Test MSE 5.178866600554596 Test RE 1.0877408093364838\n",
      "26 Train Loss 7.856695 Test MSE 5.18478473430384 Test RE 1.0883621381002968\n",
      "27 Train Loss 7.64832 Test MSE 5.131895349565869 Test RE 1.082796781174343\n",
      "28 Train Loss 7.5050516 Test MSE 5.140594933833598 Test RE 1.0837141706023883\n",
      "29 Train Loss 7.3410454 Test MSE 5.167144045805655 Test RE 1.0865090412684273\n",
      "30 Train Loss 7.126899 Test MSE 5.128919883702084 Test RE 1.0824828336190884\n",
      "31 Train Loss 6.830303 Test MSE 5.174017069748704 Test RE 1.087231405595808\n",
      "32 Train Loss 6.628641 Test MSE 5.115760473310892 Test RE 1.0810932637872148\n",
      "33 Train Loss 6.485281 Test MSE 5.096935061711092 Test RE 1.079102280864549\n",
      "34 Train Loss 6.275712 Test MSE 5.150220067577877 Test RE 1.0847282570933585\n",
      "35 Train Loss 6.1176357 Test MSE 5.06389453722327 Test RE 1.0755989917057394\n",
      "36 Train Loss 5.9840155 Test MSE 5.022190444935531 Test RE 1.071160745892866\n",
      "37 Train Loss 5.7371044 Test MSE 5.021334266065082 Test RE 1.0710694367024132\n",
      "38 Train Loss 5.5185585 Test MSE 4.9631839334681445 Test RE 1.0648495345821711\n",
      "39 Train Loss 5.185158 Test MSE 4.995914482156176 Test RE 1.068354929256845\n",
      "40 Train Loss 4.7616215 Test MSE 5.043378658700465 Test RE 1.0734179377840967\n",
      "41 Train Loss 4.4009676 Test MSE 4.878973369558379 Test RE 1.055777212471086\n",
      "42 Train Loss 3.961916 Test MSE 4.65239355344707 Test RE 1.030970605116155\n",
      "43 Train Loss 3.7161388 Test MSE 4.458952454174007 Test RE 1.0093097789054744\n",
      "44 Train Loss 3.439317 Test MSE 4.338795891696968 Test RE 0.9956178411215039\n",
      "45 Train Loss 3.1819239 Test MSE 4.335375934058724 Test RE 0.9952253771565133\n",
      "46 Train Loss 2.9252882 Test MSE 4.301834585129338 Test RE 0.991368039533578\n",
      "47 Train Loss 2.714797 Test MSE 4.229589666879782 Test RE 0.9830082856874475\n",
      "48 Train Loss 2.5459902 Test MSE 4.150163029218216 Test RE 0.9737346823252975\n",
      "49 Train Loss 2.3657818 Test MSE 4.187894733015986 Test RE 0.9781510796782479\n",
      "50 Train Loss 2.252912 Test MSE 4.229060741760974 Test RE 0.9829468194376123\n",
      "51 Train Loss 2.1583958 Test MSE 4.183951415280868 Test RE 0.9776904581549679\n",
      "52 Train Loss 2.0793178 Test MSE 4.126978411292831 Test RE 0.9710110201264337\n",
      "53 Train Loss 2.0004663 Test MSE 4.14656127227551 Test RE 0.973312058335906\n",
      "54 Train Loss 1.9390271 Test MSE 4.07398358442313 Test RE 0.9647564652485631\n",
      "55 Train Loss 1.8851509 Test MSE 4.006102404001125 Test RE 0.9566852619115098\n",
      "56 Train Loss 1.834083 Test MSE 3.9785452261457195 Test RE 0.953389160458163\n",
      "57 Train Loss 1.8077778 Test MSE 3.9190418252562025 Test RE 0.9462328244808859\n",
      "58 Train Loss 1.7655262 Test MSE 3.862413078496667 Test RE 0.9393715864600068\n",
      "59 Train Loss 1.7324812 Test MSE 3.857308030637774 Test RE 0.938750585747244\n",
      "60 Train Loss 1.7060452 Test MSE 3.7952431925898047 Test RE 0.9311676192494889\n",
      "61 Train Loss 1.6577773 Test MSE 3.6975751802544963 Test RE 0.9191080433965855\n",
      "62 Train Loss 1.6177055 Test MSE 3.6069507284244255 Test RE 0.9077748892794117\n",
      "63 Train Loss 1.5801806 Test MSE 3.5555994332403587 Test RE 0.9012898379709499\n",
      "64 Train Loss 1.5284398 Test MSE 3.4903255316153547 Test RE 0.8929785508183622\n",
      "65 Train Loss 1.4669647 Test MSE 3.4193068399015574 Test RE 0.8838470114756418\n",
      "66 Train Loss 1.411164 Test MSE 3.382132301716587 Test RE 0.8790293103083235\n",
      "67 Train Loss 1.3826299 Test MSE 3.327268976005958 Test RE 0.8718705645457344\n",
      "68 Train Loss 1.3511864 Test MSE 3.2629025322468093 Test RE 0.8633961559890906\n",
      "69 Train Loss 1.3135277 Test MSE 3.1674164617930956 Test RE 0.8506690753423847\n",
      "70 Train Loss 1.2786599 Test MSE 3.1871072533819635 Test RE 0.8533091442161949\n",
      "71 Train Loss 1.2552983 Test MSE 3.24140482794768 Test RE 0.8605472034618404\n",
      "72 Train Loss 1.2148533 Test MSE 3.2764700534649323 Test RE 0.8651893437434147\n",
      "73 Train Loss 1.1913282 Test MSE 3.2442134451427718 Test RE 0.860919946835117\n",
      "74 Train Loss 1.1483314 Test MSE 3.217592977208179 Test RE 0.8573805219728831\n",
      "75 Train Loss 1.108204 Test MSE 3.199013671077812 Test RE 0.8549015575170548\n",
      "76 Train Loss 1.083833 Test MSE 3.163015905686307 Test RE 0.8500779440300283\n",
      "77 Train Loss 1.059867 Test MSE 3.1544360358349057 Test RE 0.8489242174738316\n",
      "78 Train Loss 1.0389988 Test MSE 3.1444031012866054 Test RE 0.8475731068134976\n",
      "79 Train Loss 1.0205041 Test MSE 3.130565967121013 Test RE 0.8457061525290337\n",
      "80 Train Loss 0.9856045 Test MSE 3.105998255935581 Test RE 0.8423811965229201\n",
      "81 Train Loss 0.94570315 Test MSE 3.0722159312451294 Test RE 0.8377876011563562\n",
      "82 Train Loss 0.9140371 Test MSE 3.073685496739698 Test RE 0.8379879510962549\n",
      "83 Train Loss 0.8820995 Test MSE 3.0532562431236347 Test RE 0.8351984644250746\n",
      "84 Train Loss 0.8630721 Test MSE 3.0747846973651463 Test RE 0.8381377768581963\n",
      "85 Train Loss 0.8329691 Test MSE 3.0800789275866145 Test RE 0.8388590283229381\n",
      "86 Train Loss 0.81488925 Test MSE 3.0691240316068553 Test RE 0.8373659173774463\n",
      "87 Train Loss 0.796653 Test MSE 3.0755294981139554 Test RE 0.8382392811759442\n",
      "88 Train Loss 0.77778476 Test MSE 3.084979188319227 Test RE 0.8395260557593488\n",
      "89 Train Loss 0.7633964 Test MSE 3.050678390056105 Test RE 0.83484581247082\n",
      "90 Train Loss 0.7504021 Test MSE 3.0260615210087902 Test RE 0.8314706751720391\n",
      "91 Train Loss 0.7364373 Test MSE 3.060124239966269 Test RE 0.8361372847964097\n",
      "92 Train Loss 0.7263005 Test MSE 3.079610313562153 Test RE 0.8387952124163424\n",
      "93 Train Loss 0.7126742 Test MSE 3.0639706369016206 Test RE 0.8366626075700905\n",
      "94 Train Loss 0.70122236 Test MSE 3.050423745948053 Test RE 0.8348109689087424\n",
      "95 Train Loss 0.6852084 Test MSE 3.0582430378934746 Test RE 0.835880238858928\n",
      "96 Train Loss 0.667177 Test MSE 3.0687448755187523 Test RE 0.8373141921639097\n",
      "97 Train Loss 0.6532981 Test MSE 3.0452669506718975 Test RE 0.8341050390843413\n",
      "98 Train Loss 0.64667225 Test MSE 3.0577284027258638 Test RE 0.835809905752598\n",
      "99 Train Loss 0.6377279 Test MSE 3.0545954539059212 Test RE 0.8353816105611431\n",
      "Training time: 158.20\n",
      "1\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 64.62415 Test MSE 6.129120817250746 Test RE 1.1833334779337512\n",
      "1 Train Loss 50.907482 Test MSE 6.179500657670696 Test RE 1.1881868775492477\n",
      "2 Train Loss 43.34494 Test MSE 6.539293447116989 Test RE 1.2222877903558214\n",
      "3 Train Loss 38.186222 Test MSE 5.810913897901592 Test RE 1.152206392766141\n",
      "4 Train Loss 32.826813 Test MSE 6.2964875385334285 Test RE 1.1993811924636095\n",
      "5 Train Loss 29.080286 Test MSE 6.415059573262338 Test RE 1.2106215688244035\n",
      "6 Train Loss 26.312683 Test MSE 6.578666264030744 Test RE 1.225961940438214\n",
      "7 Train Loss 22.08812 Test MSE 6.012416773915157 Test RE 1.1720134594321183\n",
      "8 Train Loss 20.253643 Test MSE 6.045287345052882 Test RE 1.1752128584322765\n",
      "9 Train Loss 18.967625 Test MSE 6.026902814102856 Test RE 1.1734245076519885\n",
      "10 Train Loss 17.937933 Test MSE 6.0120266957659165 Test RE 1.171975439425037\n",
      "11 Train Loss 17.361412 Test MSE 6.045940646695262 Test RE 1.1752763581226207\n",
      "12 Train Loss 16.814922 Test MSE 6.108229304018933 Test RE 1.1813150212860508\n",
      "13 Train Loss 16.31665 Test MSE 5.9445431925763135 Test RE 1.1653793109199047\n",
      "14 Train Loss 15.775349 Test MSE 5.935181197812696 Test RE 1.1644612778889067\n",
      "15 Train Loss 15.277318 Test MSE 6.133476831798797 Test RE 1.1837539054687234\n",
      "16 Train Loss 14.986494 Test MSE 6.0443283741556595 Test RE 1.175119642050439\n",
      "17 Train Loss 14.626097 Test MSE 6.005488616166077 Test RE 1.1713380043746562\n",
      "18 Train Loss 14.192029 Test MSE 5.9817222409921005 Test RE 1.1690179554031213\n",
      "19 Train Loss 13.847129 Test MSE 5.973966757901023 Test RE 1.168259876106729\n",
      "20 Train Loss 13.559984 Test MSE 5.986890005418208 Test RE 1.1695228187964852\n",
      "21 Train Loss 13.322804 Test MSE 6.01701494604949 Test RE 1.1724615396180744\n",
      "22 Train Loss 13.055414 Test MSE 6.01844328696563 Test RE 1.1726006929550155\n",
      "23 Train Loss 12.859383 Test MSE 6.012955497751613 Test RE 1.1720659655597\n",
      "24 Train Loss 12.699287 Test MSE 5.973764300459428 Test RE 1.1682400798039383\n",
      "25 Train Loss 12.476623 Test MSE 5.9122301018900805 Test RE 1.1622076357148674\n",
      "26 Train Loss 12.168968 Test MSE 5.852679374489131 Test RE 1.1563396745753425\n",
      "27 Train Loss 11.871685 Test MSE 5.6534813660965035 Test RE 1.136491109823022\n",
      "28 Train Loss 11.635314 Test MSE 5.4302967146983265 Test RE 1.1138323836650605\n",
      "29 Train Loss 11.053602 Test MSE 5.179887221206295 Test RE 1.0878479868454092\n",
      "30 Train Loss 9.976185 Test MSE 4.880061394534763 Test RE 1.0558949265735504\n",
      "31 Train Loss 9.004169 Test MSE 4.699187473324652 Test RE 1.0361424004293607\n",
      "32 Train Loss 8.573305 Test MSE 4.547571517516397 Test RE 1.0192901541246686\n",
      "33 Train Loss 7.9951878 Test MSE 4.518945094638114 Test RE 1.0160769341700018\n",
      "34 Train Loss 7.5858383 Test MSE 4.47785609416412 Test RE 1.011446990472593\n",
      "35 Train Loss 7.0406017 Test MSE 4.567226693554219 Test RE 1.021490529233807\n",
      "36 Train Loss 6.658789 Test MSE 4.208095142637378 Test RE 0.9805073092359586\n",
      "37 Train Loss 6.1183195 Test MSE 3.4506540352096917 Test RE 0.8878891924222613\n",
      "38 Train Loss 4.582205 Test MSE 3.123822510987153 Test RE 0.8447948066464231\n",
      "39 Train Loss 3.8950317 Test MSE 2.825778453266109 Test RE 0.8034837816200935\n",
      "40 Train Loss 3.451517 Test MSE 2.777853553906697 Test RE 0.7966411455990159\n",
      "41 Train Loss 3.0324826 Test MSE 2.707864792737667 Test RE 0.7865413298034597\n",
      "42 Train Loss 2.9363298 Test MSE 2.715364536002292 Test RE 0.7876297850526062\n",
      "43 Train Loss 2.7704694 Test MSE 2.667873503830022 Test RE 0.780711680770789\n",
      "44 Train Loss 2.6145203 Test MSE 2.6053316370850736 Test RE 0.7715064600644493\n",
      "45 Train Loss 2.5184104 Test MSE 2.627141927740704 Test RE 0.7747290269307162\n",
      "46 Train Loss 2.4743423 Test MSE 2.6361314259880952 Test RE 0.7760533706304333\n",
      "47 Train Loss 2.347125 Test MSE 2.7450696554837055 Test RE 0.7919262609905036\n",
      "48 Train Loss 2.271302 Test MSE 2.7582295583284284 Test RE 0.7938222442258674\n",
      "49 Train Loss 2.2397501 Test MSE 2.7800225347345777 Test RE 0.7969520983145822\n",
      "50 Train Loss 2.1157165 Test MSE 2.8015302571479066 Test RE 0.8000289798304036\n",
      "51 Train Loss 2.0840366 Test MSE 2.7941964216682202 Test RE 0.7989811371785517\n",
      "52 Train Loss 2.0444694 Test MSE 2.8041396602121234 Test RE 0.8004014748595727\n",
      "53 Train Loss 1.9761912 Test MSE 2.7807584471618165 Test RE 0.7970575737447209\n",
      "54 Train Loss 1.9350967 Test MSE 2.795157531706207 Test RE 0.799118536747668\n",
      "55 Train Loss 1.8939967 Test MSE 2.8365984384058325 Test RE 0.805020592896483\n",
      "56 Train Loss 1.8443086 Test MSE 2.8584177681063054 Test RE 0.808110801390323\n",
      "57 Train Loss 1.8143202 Test MSE 2.8336101982038624 Test RE 0.8045964530624189\n",
      "58 Train Loss 1.7358674 Test MSE 2.8104747515607658 Test RE 0.8013050952973306\n",
      "59 Train Loss 1.7044477 Test MSE 2.8268078040977023 Test RE 0.8036301114557379\n",
      "60 Train Loss 1.6808487 Test MSE 2.831132419841999 Test RE 0.8042445966763329\n",
      "61 Train Loss 1.6582515 Test MSE 2.809365503953383 Test RE 0.8011469487991784\n",
      "62 Train Loss 1.6257671 Test MSE 2.82039226814862 Test RE 0.8027176605887957\n",
      "63 Train Loss 1.5927949 Test MSE 2.84376090323766 Test RE 0.8060362982610151\n",
      "64 Train Loss 1.5530318 Test MSE 2.8386804070203517 Test RE 0.8053159678359683\n",
      "65 Train Loss 1.5300081 Test MSE 2.8462877631472616 Test RE 0.8063943256470997\n",
      "66 Train Loss 1.5035359 Test MSE 2.8425485718498344 Test RE 0.8058644681905629\n",
      "67 Train Loss 1.4832451 Test MSE 2.8349509694806447 Test RE 0.8047867848578331\n",
      "68 Train Loss 1.4723703 Test MSE 2.8369252061910384 Test RE 0.8050669595617954\n",
      "69 Train Loss 1.4449581 Test MSE 2.8416128547215194 Test RE 0.8057318190496473\n",
      "70 Train Loss 1.4268874 Test MSE 2.858543565844237 Test RE 0.8081285834992723\n",
      "71 Train Loss 1.4136655 Test MSE 2.864481981867318 Test RE 0.8089675621275214\n",
      "72 Train Loss 1.396851 Test MSE 2.8722006979719774 Test RE 0.8100567625838125\n",
      "73 Train Loss 1.383505 Test MSE 2.883425689198324 Test RE 0.8116381307124905\n",
      "74 Train Loss 1.3562421 Test MSE 2.901769792628762 Test RE 0.8142158230439239\n",
      "75 Train Loss 1.3352107 Test MSE 2.9103607332886505 Test RE 0.81542021049236\n",
      "76 Train Loss 1.3210002 Test MSE 2.9151525994102423 Test RE 0.8160912230917254\n",
      "77 Train Loss 1.3025172 Test MSE 2.905270807638906 Test RE 0.8147068548496622\n",
      "78 Train Loss 1.2851863 Test MSE 2.9015627080929365 Test RE 0.8141867693066929\n",
      "79 Train Loss 1.2675068 Test MSE 2.9228042309200135 Test RE 0.8171615507866933\n",
      "80 Train Loss 1.2411104 Test MSE 2.944934129187584 Test RE 0.8202492705800047\n",
      "81 Train Loss 1.2280135 Test MSE 2.9474996129371815 Test RE 0.8206064734889011\n",
      "82 Train Loss 1.2067711 Test MSE 2.9536548859774845 Test RE 0.8214628642066534\n",
      "83 Train Loss 1.1932844 Test MSE 2.952483049292675 Test RE 0.8212998939455043\n",
      "84 Train Loss 1.1787323 Test MSE 2.952672855389965 Test RE 0.8213262929492693\n",
      "85 Train Loss 1.1656511 Test MSE 2.961678566409607 Test RE 0.8225778701182703\n",
      "86 Train Loss 1.1508423 Test MSE 2.9763163538495108 Test RE 0.8246081173070247\n",
      "87 Train Loss 1.1319339 Test MSE 2.979561390610327 Test RE 0.8250575242858952\n",
      "88 Train Loss 1.1146657 Test MSE 2.958498469187579 Test RE 0.8221361307267823\n",
      "89 Train Loss 1.0986767 Test MSE 2.9516515999915103 Test RE 0.8211842425947651\n",
      "90 Train Loss 1.0857493 Test MSE 2.954744385200312 Test RE 0.8216143545922875\n",
      "91 Train Loss 1.0683877 Test MSE 2.935122925917024 Test RE 0.8188817788230904\n",
      "92 Train Loss 1.0523401 Test MSE 2.914255579580895 Test RE 0.8159656539648893\n",
      "93 Train Loss 1.0374981 Test MSE 2.9091719439993606 Test RE 0.815253656942818\n",
      "94 Train Loss 1.0308914 Test MSE 2.904470017222971 Test RE 0.8145945667968343\n",
      "95 Train Loss 1.0237993 Test MSE 2.9036539411416786 Test RE 0.8144801194380852\n",
      "96 Train Loss 1.0115777 Test MSE 2.9217759922926283 Test RE 0.8170177999712925\n",
      "97 Train Loss 0.996495 Test MSE 2.908579567552648 Test RE 0.8151706502212095\n",
      "98 Train Loss 0.9859274 Test MSE 2.8833915160336514 Test RE 0.8116333210990884\n",
      "99 Train Loss 0.9755105 Test MSE 2.8939818283085446 Test RE 0.8131224654367062\n",
      "Training time: 159.28\n",
      "2\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.25669 Test MSE 5.047136812001542 Test RE 1.0738178004760077\n",
      "1 Train Loss 51.852345 Test MSE 7.334858401345566 Test RE 1.2945055817677604\n",
      "2 Train Loss 39.58001 Test MSE 7.753258932669223 Test RE 1.3309146463219104\n",
      "3 Train Loss 33.996964 Test MSE 7.1276881341126685 Test RE 1.276093230817289\n",
      "4 Train Loss 29.089567 Test MSE 7.040973059941089 Test RE 1.268307035602973\n",
      "5 Train Loss 26.436443 Test MSE 6.9099708742177475 Test RE 1.256452771616306\n",
      "6 Train Loss 22.937614 Test MSE 6.6570849827851575 Test RE 1.2332471225438715\n",
      "7 Train Loss 18.994972 Test MSE 6.06028373054512 Test RE 1.1766696153882712\n",
      "8 Train Loss 16.549221 Test MSE 5.623654103588583 Test RE 1.1334891322744816\n",
      "9 Train Loss 14.912227 Test MSE 5.773030656844978 Test RE 1.1484444469552149\n",
      "10 Train Loss 13.724623 Test MSE 5.719124317089513 Test RE 1.1430700051563676\n",
      "11 Train Loss 12.666527 Test MSE 5.804138865093143 Test RE 1.15153450939891\n",
      "12 Train Loss 12.14386 Test MSE 5.940925880133228 Test RE 1.1650246846315286\n",
      "13 Train Loss 11.486913 Test MSE 5.8729744973658615 Test RE 1.1583428379685778\n",
      "14 Train Loss 10.725861 Test MSE 5.7996647733005995 Test RE 1.1510905964893372\n",
      "15 Train Loss 10.205656 Test MSE 5.944746199241054 Test RE 1.1653992096522072\n",
      "16 Train Loss 9.788418 Test MSE 5.872724332783157 Test RE 1.1583181673831104\n",
      "17 Train Loss 9.004911 Test MSE 5.887556241628893 Test RE 1.1597799451593727\n",
      "18 Train Loss 8.331912 Test MSE 5.685686231533389 Test RE 1.1397235046421876\n",
      "19 Train Loss 7.998644 Test MSE 5.590624221276865 Test RE 1.1301555214750487\n",
      "20 Train Loss 7.6794286 Test MSE 5.668618917707983 Test RE 1.1380116058782073\n",
      "21 Train Loss 7.4732523 Test MSE 5.592317529204003 Test RE 1.1303266612568035\n",
      "22 Train Loss 7.215293 Test MSE 5.5628659498918305 Test RE 1.127346335951807\n",
      "23 Train Loss 6.9285746 Test MSE 5.422244574475368 Test RE 1.1130062721074008\n",
      "24 Train Loss 6.774949 Test MSE 5.3893919706220474 Test RE 1.1096293764486898\n",
      "25 Train Loss 6.6187987 Test MSE 5.458814689251256 Test RE 1.116753278302967\n",
      "26 Train Loss 6.505043 Test MSE 5.380554937762729 Test RE 1.1087192687509722\n",
      "27 Train Loss 6.3815613 Test MSE 5.400844339001443 Test RE 1.1108077227821462\n",
      "28 Train Loss 6.2133255 Test MSE 5.311067041621769 Test RE 1.1015366515549534\n",
      "29 Train Loss 6.124681 Test MSE 5.160857850300185 Test RE 1.085847932660591\n",
      "30 Train Loss 6.0293627 Test MSE 5.118619952683742 Test RE 1.0813953627656068\n",
      "31 Train Loss 5.983451 Test MSE 5.112204458284927 Test RE 1.0807174592308801\n",
      "32 Train Loss 5.928604 Test MSE 5.1098368281943864 Test RE 1.080467172341493\n",
      "33 Train Loss 5.8145075 Test MSE 5.050477258219636 Test RE 1.0741730947172399\n",
      "34 Train Loss 5.686001 Test MSE 4.977715156980781 Test RE 1.0664072299510772\n",
      "35 Train Loss 5.6126137 Test MSE 4.935445912293957 Test RE 1.0618697736492098\n",
      "36 Train Loss 5.492772 Test MSE 4.839438329648518 Test RE 1.0514909526238514\n",
      "37 Train Loss 5.3456326 Test MSE 4.706433261956079 Test RE 1.0369409190066756\n",
      "38 Train Loss 5.2248387 Test MSE 4.71443707452607 Test RE 1.0378222610708305\n",
      "39 Train Loss 5.1251493 Test MSE 4.663560308572346 Test RE 1.0322071402729187\n",
      "40 Train Loss 4.927848 Test MSE 4.61752671860295 Test RE 1.027100093674592\n",
      "41 Train Loss 4.810709 Test MSE 4.601256889967822 Test RE 1.025289006313777\n",
      "42 Train Loss 4.6225376 Test MSE 4.429209952227166 Test RE 1.0059379527261165\n",
      "43 Train Loss 4.419428 Test MSE 4.3616107921430745 Test RE 0.9982320617488943\n",
      "44 Train Loss 4.254654 Test MSE 4.326697446648856 Test RE 0.994228764896479\n",
      "45 Train Loss 4.091453 Test MSE 4.214561059766583 Test RE 0.9812603156779589\n",
      "46 Train Loss 3.8860369 Test MSE 4.154633421732031 Test RE 0.9742589755423161\n",
      "47 Train Loss 3.7367568 Test MSE 4.093020347852598 Test RE 0.9670078778263649\n",
      "48 Train Loss 3.6120856 Test MSE 4.172541053283837 Test RE 0.9763563821485856\n",
      "49 Train Loss 3.4754987 Test MSE 4.158847647552945 Test RE 0.9747529669830052\n",
      "50 Train Loss 3.343883 Test MSE 3.9854484663245504 Test RE 0.9542159226981568\n",
      "51 Train Loss 3.2094274 Test MSE 3.9297608017370482 Test RE 0.9475259621940131\n",
      "52 Train Loss 3.108355 Test MSE 3.890931077148876 Test RE 0.9428331181357706\n",
      "53 Train Loss 2.9748988 Test MSE 3.833457250760843 Test RE 0.9358438109218571\n",
      "54 Train Loss 2.9068253 Test MSE 3.8312784500354837 Test RE 0.9355778229573083\n",
      "55 Train Loss 2.843182 Test MSE 3.8030561495627864 Test RE 0.9321255858175123\n",
      "56 Train Loss 2.7020884 Test MSE 3.6390126412035606 Test RE 0.9118005343943727\n",
      "57 Train Loss 2.6405172 Test MSE 3.640169810613805 Test RE 0.9119454945697821\n",
      "58 Train Loss 2.592517 Test MSE 3.6974252187495007 Test RE 0.9190894052058469\n",
      "59 Train Loss 2.5436273 Test MSE 3.674139148952813 Test RE 0.9161906605033177\n",
      "60 Train Loss 2.5072021 Test MSE 3.5667348819236095 Test RE 0.9027000672863741\n",
      "61 Train Loss 2.46005 Test MSE 3.5258467484667837 Test RE 0.897510991893602\n",
      "62 Train Loss 2.4156537 Test MSE 3.4975917674032906 Test RE 0.8939075786600704\n",
      "63 Train Loss 2.322779 Test MSE 3.3644103748158773 Test RE 0.8767232867383395\n",
      "64 Train Loss 2.1934626 Test MSE 3.229769186218434 Test RE 0.8590012655802517\n",
      "65 Train Loss 2.1180573 Test MSE 3.1346386136032143 Test RE 0.8462560758920095\n",
      "66 Train Loss 2.0737026 Test MSE 3.103201379095027 Test RE 0.8420018390840563\n",
      "67 Train Loss 2.0355988 Test MSE 3.037915113190965 Test RE 0.8330975887799774\n",
      "68 Train Loss 1.9654614 Test MSE 2.9467956321147835 Test RE 0.8205084708096813\n",
      "69 Train Loss 1.8872101 Test MSE 2.8346839713445937 Test RE 0.8047488862074962\n",
      "70 Train Loss 1.8477732 Test MSE 2.836054240151013 Test RE 0.8049433680398308\n",
      "71 Train Loss 1.7888488 Test MSE 2.738628390607595 Test RE 0.7909965937461495\n",
      "72 Train Loss 1.7328305 Test MSE 2.6705928145606284 Test RE 0.7811094614266426\n",
      "73 Train Loss 1.7000898 Test MSE 2.649029276067079 Test RE 0.7779495595817397\n",
      "74 Train Loss 1.6437249 Test MSE 2.5468508986349345 Test RE 0.7627984828432438\n",
      "75 Train Loss 1.572092 Test MSE 2.4031693742881717 Test RE 0.7409693615761365\n",
      "76 Train Loss 1.4893827 Test MSE 2.2846207765869746 Test RE 0.7224621867086216\n",
      "77 Train Loss 1.44505 Test MSE 2.2237975418632923 Test RE 0.712780292027093\n",
      "78 Train Loss 1.4079616 Test MSE 2.214958085449519 Test RE 0.7113622528860921\n",
      "79 Train Loss 1.375494 Test MSE 2.1393469039774415 Test RE 0.6991150747364896\n",
      "80 Train Loss 1.3266064 Test MSE 1.9683140293164387 Test RE 0.6705871919556162\n",
      "81 Train Loss 1.2810961 Test MSE 1.8911786581360468 Test RE 0.6573162053057726\n",
      "82 Train Loss 1.2399071 Test MSE 1.8309768771697725 Test RE 0.6467694384446123\n",
      "83 Train Loss 1.2015077 Test MSE 1.8148645660735272 Test RE 0.6439174151219267\n",
      "84 Train Loss 1.1496058 Test MSE 1.7696863962177223 Test RE 0.6358522559911478\n",
      "85 Train Loss 1.1187756 Test MSE 1.713197176213336 Test RE 0.6256216008830016\n",
      "86 Train Loss 1.0790311 Test MSE 1.6908330024939922 Test RE 0.6215247367448308\n",
      "87 Train Loss 1.0405723 Test MSE 1.6551467110606397 Test RE 0.6149308876467746\n",
      "88 Train Loss 1.007075 Test MSE 1.6289434412001893 Test RE 0.6100438636355572\n",
      "89 Train Loss 0.9593992 Test MSE 1.5944341562077853 Test RE 0.6035473604698169\n",
      "90 Train Loss 0.92501867 Test MSE 1.5645639874393262 Test RE 0.5978671960470308\n",
      "91 Train Loss 0.9001351 Test MSE 1.5163395661081014 Test RE 0.5885810750585148\n",
      "92 Train Loss 0.8766363 Test MSE 1.4617435901039986 Test RE 0.5778879773863627\n",
      "93 Train Loss 0.8630253 Test MSE 1.4249711024655858 Test RE 0.5705728321785851\n",
      "94 Train Loss 0.84871227 Test MSE 1.4037689370983089 Test RE 0.5663121434144458\n",
      "95 Train Loss 0.8233699 Test MSE 1.3505113336840844 Test RE 0.555465611049861\n",
      "96 Train Loss 0.7876854 Test MSE 1.3023269534739852 Test RE 0.5454664891509972\n",
      "97 Train Loss 0.7569292 Test MSE 1.2632821842591615 Test RE 0.5372275129220054\n",
      "98 Train Loss 0.72120917 Test MSE 1.1846159616276277 Test RE 0.5202317457349618\n",
      "99 Train Loss 0.7027587 Test MSE 1.1484387826512006 Test RE 0.5122264321202892\n",
      "Training time: 158.67\n",
      "3\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.90201 Test MSE 5.436037727130116 Test RE 1.1144210104645602\n",
      "1 Train Loss 54.762875 Test MSE 7.710639356841709 Test RE 1.3272515941386087\n",
      "2 Train Loss 42.12494 Test MSE 7.9002775488962955 Test RE 1.3434739033119913\n",
      "3 Train Loss 36.369663 Test MSE 8.316763633530318 Test RE 1.3784316606076654\n",
      "4 Train Loss 32.436413 Test MSE 8.36307898286322 Test RE 1.3822645161456844\n",
      "5 Train Loss 30.511189 Test MSE 8.715057350553682 Test RE 1.4110525404188166\n",
      "6 Train Loss 27.949108 Test MSE 9.120290378824285 Test RE 1.4434853921809925\n",
      "7 Train Loss 26.432255 Test MSE 9.165470329347734 Test RE 1.447056332802938\n",
      "8 Train Loss 24.745277 Test MSE 9.426282853839366 Test RE 1.4675006220563724\n",
      "9 Train Loss 23.368 Test MSE 9.45551758305645 Test RE 1.4697745178933332\n",
      "10 Train Loss 22.63496 Test MSE 9.759935043999583 Test RE 1.493246563398487\n",
      "11 Train Loss 21.689407 Test MSE 9.648597196434622 Test RE 1.4847049222216828\n",
      "12 Train Loss 21.348595 Test MSE 9.690671794335893 Test RE 1.4879385741211628\n",
      "13 Train Loss 20.606663 Test MSE 9.65423254745702 Test RE 1.4851384366438531\n",
      "14 Train Loss 20.040907 Test MSE 9.46245134642916 Test RE 1.470313314475705\n",
      "15 Train Loss 19.336967 Test MSE 9.408738917565096 Test RE 1.4661343503101762\n",
      "16 Train Loss 18.662888 Test MSE 9.405485789180304 Test RE 1.4658808659879479\n",
      "17 Train Loss 18.231613 Test MSE 9.433929279520873 Test RE 1.468095706033088\n",
      "18 Train Loss 17.74052 Test MSE 9.476103822165046 Test RE 1.4713736201420458\n",
      "19 Train Loss 17.067694 Test MSE 9.255249303494555 Test RE 1.4541262722535875\n",
      "20 Train Loss 16.413975 Test MSE 9.335682102059575 Test RE 1.4604311502064833\n",
      "21 Train Loss 15.982981 Test MSE 9.378948567677314 Test RE 1.463811441617304\n",
      "22 Train Loss 15.34577 Test MSE 9.331202900296507 Test RE 1.4600807553156667\n",
      "23 Train Loss 14.557544 Test MSE 9.078471149991566 Test RE 1.4401721860832966\n",
      "24 Train Loss 13.706241 Test MSE 8.616839963800297 Test RE 1.4030788361034394\n",
      "25 Train Loss 11.494169 Test MSE 8.080650607331961 Test RE 1.3587239315622397\n",
      "26 Train Loss 10.139226 Test MSE 7.628087927874508 Test RE 1.3201275833711146\n",
      "27 Train Loss 9.142984 Test MSE 7.158758287166299 Test RE 1.2788715018027441\n",
      "28 Train Loss 8.10353 Test MSE 7.139350816218696 Test RE 1.2771368080923504\n",
      "29 Train Loss 7.533327 Test MSE 6.6996365639463615 Test RE 1.237182255223221\n",
      "30 Train Loss 6.982834 Test MSE 6.782328048977927 Test RE 1.2447939138878117\n",
      "31 Train Loss 6.5288715 Test MSE 6.532142043539701 Test RE 1.2216192575491043\n",
      "32 Train Loss 6.198027 Test MSE 6.299526431090933 Test RE 1.199670588010662\n",
      "33 Train Loss 5.812148 Test MSE 6.173595908859774 Test RE 1.18761906291153\n",
      "34 Train Loss 5.449001 Test MSE 5.86776940548255 Test RE 1.1578294169240329\n",
      "35 Train Loss 5.078858 Test MSE 5.713125911036488 Test RE 1.1424704031493431\n",
      "36 Train Loss 4.721201 Test MSE 5.631864078065629 Test RE 1.1343162210964313\n",
      "37 Train Loss 4.4732113 Test MSE 5.419693513149895 Test RE 1.1127444173293775\n",
      "38 Train Loss 4.2110786 Test MSE 5.445673572547046 Test RE 1.115408276802479\n",
      "39 Train Loss 3.9896085 Test MSE 5.379330882759786 Test RE 1.1085931469496084\n",
      "40 Train Loss 3.720355 Test MSE 5.251870531677733 Test RE 1.0953806529378374\n",
      "41 Train Loss 3.4817607 Test MSE 5.218465030617144 Test RE 1.0918914092216414\n",
      "42 Train Loss 3.3515828 Test MSE 5.22616396726609 Test RE 1.0926965602073169\n",
      "43 Train Loss 3.2127128 Test MSE 5.241056180137903 Test RE 1.0942522991703068\n",
      "44 Train Loss 3.1269414 Test MSE 5.277150920808277 Test RE 1.0980138485619915\n",
      "45 Train Loss 3.0371258 Test MSE 5.229654283620668 Test RE 1.0930613803828717\n",
      "46 Train Loss 2.9584954 Test MSE 5.2014699475750135 Test RE 1.090111966580684\n",
      "47 Train Loss 2.8453875 Test MSE 5.332727226368704 Test RE 1.1037805707209885\n",
      "48 Train Loss 2.7470214 Test MSE 5.353958854460714 Test RE 1.105975674456297\n",
      "49 Train Loss 2.6777298 Test MSE 5.354271918755859 Test RE 1.1060080090747588\n",
      "50 Train Loss 2.6081789 Test MSE 5.293662722363325 Test RE 1.0997303076130978\n",
      "51 Train Loss 2.490557 Test MSE 5.25182610439369 Test RE 1.0953760198371139\n",
      "52 Train Loss 2.4186935 Test MSE 5.266176585842273 Test RE 1.096871542491992\n",
      "53 Train Loss 2.3409536 Test MSE 5.275279938744075 Test RE 1.0978191842089493\n",
      "54 Train Loss 2.3073373 Test MSE 5.320753976907934 Test RE 1.102540748573452\n",
      "55 Train Loss 2.2419791 Test MSE 5.416272106596195 Test RE 1.112393128822188\n",
      "56 Train Loss 2.1568186 Test MSE 5.45733195740918 Test RE 1.11660160086053\n",
      "57 Train Loss 2.0970595 Test MSE 5.443626629013009 Test RE 1.1151986248354047\n",
      "58 Train Loss 2.0453298 Test MSE 5.439515207951374 Test RE 1.1147774059041353\n",
      "59 Train Loss 2.0132957 Test MSE 5.463987153213802 Test RE 1.117282239141931\n",
      "60 Train Loss 1.9751422 Test MSE 5.491860710917423 Test RE 1.1201284221515226\n",
      "61 Train Loss 1.9408507 Test MSE 5.47559198164109 Test RE 1.1184680940090095\n",
      "62 Train Loss 1.8910941 Test MSE 5.500901293076084 Test RE 1.1210500086078732\n",
      "63 Train Loss 1.8502711 Test MSE 5.55461331945944 Test RE 1.1265098044015438\n",
      "64 Train Loss 1.8184996 Test MSE 5.549737951387435 Test RE 1.1260153185316752\n",
      "65 Train Loss 1.7939256 Test MSE 5.553343652475392 Test RE 1.1263810488998938\n",
      "66 Train Loss 1.7569557 Test MSE 5.581393218378941 Test RE 1.1292221034475747\n",
      "67 Train Loss 1.720549 Test MSE 5.570159803111074 Test RE 1.1280851642110103\n",
      "68 Train Loss 1.6965339 Test MSE 5.578240647505305 Test RE 1.1289031458492544\n",
      "69 Train Loss 1.6614144 Test MSE 5.573935621397591 Test RE 1.1284674443568585\n",
      "70 Train Loss 1.6439393 Test MSE 5.580351942932714 Test RE 1.1291167636112565\n",
      "71 Train Loss 1.6262852 Test MSE 5.5675476134367266 Test RE 1.127820619019891\n",
      "72 Train Loss 1.6104676 Test MSE 5.54547295551345 Test RE 1.125582561727659\n",
      "73 Train Loss 1.5932845 Test MSE 5.5636214833962825 Test RE 1.1274228899274943\n",
      "74 Train Loss 1.577001 Test MSE 5.581882225578542 Test RE 1.129271570097067\n",
      "75 Train Loss 1.5635589 Test MSE 5.583149234484793 Test RE 1.1293997272218117\n",
      "76 Train Loss 1.5513595 Test MSE 5.59888259187479 Test RE 1.1309899362540226\n",
      "77 Train Loss 1.5293986 Test MSE 5.587016840232845 Test RE 1.1297908431031323\n",
      "78 Train Loss 1.5095685 Test MSE 5.572978500862072 Test RE 1.1283705535952775\n",
      "79 Train Loss 1.4954369 Test MSE 5.578667035342903 Test RE 1.1289462903999883\n",
      "80 Train Loss 1.4795929 Test MSE 5.555202637122556 Test RE 1.1265695614431013\n",
      "81 Train Loss 1.4698085 Test MSE 5.546760050121756 Test RE 1.1257131770246567\n",
      "82 Train Loss 1.4526887 Test MSE 5.57559739618594 Test RE 1.1286356485780333\n",
      "83 Train Loss 1.4368799 Test MSE 5.561926944193651 Test RE 1.1272511845209998\n",
      "84 Train Loss 1.4229271 Test MSE 5.542465037614805 Test RE 1.125277256915141\n",
      "85 Train Loss 1.412379 Test MSE 5.5681481162578335 Test RE 1.1278814394429497\n",
      "86 Train Loss 1.4006634 Test MSE 5.589607800199985 Test RE 1.1300527810597707\n",
      "87 Train Loss 1.3865229 Test MSE 5.5835663640899265 Test RE 1.1294419164275316\n",
      "88 Train Loss 1.3758976 Test MSE 5.592376923603173 Test RE 1.1303326636783675\n",
      "89 Train Loss 1.3619859 Test MSE 5.615885282958803 Test RE 1.1327059300253304\n",
      "90 Train Loss 1.3510494 Test MSE 5.614971938937461 Test RE 1.132613817009826\n",
      "91 Train Loss 1.3411846 Test MSE 5.608366358131575 Test RE 1.1319474046181286\n",
      "92 Train Loss 1.3277278 Test MSE 5.606143716195508 Test RE 1.13172308233522\n",
      "93 Train Loss 1.3201303 Test MSE 5.599279947257801 Test RE 1.1310300689910993\n",
      "94 Train Loss 1.3115093 Test MSE 5.623086210656403 Test RE 1.1334318993164643\n",
      "95 Train Loss 1.2968163 Test MSE 5.635507494417184 Test RE 1.1346830728192148\n",
      "96 Train Loss 1.2870036 Test MSE 5.634380503998666 Test RE 1.1345696100218245\n",
      "97 Train Loss 1.2797432 Test MSE 5.641512791096703 Test RE 1.135287481042798\n",
      "98 Train Loss 1.2711327 Test MSE 5.644477094394392 Test RE 1.1355857072978819\n",
      "99 Train Loss 1.2631656 Test MSE 5.647449280267625 Test RE 1.135884647974359\n",
      "Training time: 157.51\n",
      "4\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.241936 Test MSE 8.321858632355603 Test RE 1.3788538219621187\n",
      "1 Train Loss 50.923203 Test MSE 7.687570282993134 Test RE 1.3252646382321664\n",
      "2 Train Loss 43.27693 Test MSE 7.513032538118672 Test RE 1.310133932857248\n",
      "3 Train Loss 38.20889 Test MSE 7.151670074882599 Test RE 1.2782382105717913\n",
      "4 Train Loss 34.835693 Test MSE 6.7855948615190975 Test RE 1.2450936648570607\n",
      "5 Train Loss 31.616177 Test MSE 6.4077969679400475 Test RE 1.2099360914387804\n",
      "6 Train Loss 26.820198 Test MSE 6.182430008904519 Test RE 1.1884684702292627\n",
      "7 Train Loss 22.387783 Test MSE 5.696340044801143 Test RE 1.1407908092849126\n",
      "8 Train Loss 19.398924 Test MSE 5.378401687563037 Test RE 1.10849739675902\n",
      "9 Train Loss 16.709696 Test MSE 5.825895349879985 Test RE 1.1536907215225758\n",
      "10 Train Loss 15.629768 Test MSE 5.923107892511592 Test RE 1.1632763053531456\n",
      "11 Train Loss 13.718713 Test MSE 5.864422220320046 Test RE 1.157499136197967\n",
      "12 Train Loss 12.535746 Test MSE 5.532189113845417 Test RE 1.1242336212872417\n",
      "13 Train Loss 11.182543 Test MSE 5.297105440854471 Test RE 1.1000878527288596\n",
      "14 Train Loss 9.62133 Test MSE 5.132769312347439 Test RE 1.082888977501034\n",
      "15 Train Loss 8.960702 Test MSE 4.995554595429408 Test RE 1.0683164484457364\n",
      "16 Train Loss 8.294631 Test MSE 4.904452995512763 Test RE 1.0585304329327512\n",
      "17 Train Loss 7.503459 Test MSE 4.714853485262852 Test RE 1.0378680937739875\n",
      "18 Train Loss 7.1142535 Test MSE 4.4691831356714085 Test RE 1.0104670025790226\n",
      "19 Train Loss 6.7349615 Test MSE 4.508679344083482 Test RE 1.0149221599014122\n",
      "20 Train Loss 6.237482 Test MSE 4.36561542089857 Test RE 0.998690221800263\n",
      "21 Train Loss 5.7569637 Test MSE 4.015245051022482 Test RE 0.9577763037915695\n",
      "22 Train Loss 5.4606543 Test MSE 3.9746159883882886 Test RE 0.9529182574210803\n",
      "23 Train Loss 4.996353 Test MSE 3.7242713095366544 Test RE 0.9224200109844746\n",
      "24 Train Loss 4.649191 Test MSE 3.6279117985589875 Test RE 0.9104087440686297\n",
      "25 Train Loss 4.2263193 Test MSE 3.5357985169750017 Test RE 0.898776720182729\n",
      "26 Train Loss 3.9151368 Test MSE 3.3998935876383998 Test RE 0.8813344015401263\n",
      "27 Train Loss 3.6693828 Test MSE 3.220598419454382 Test RE 0.8577808532475673\n",
      "28 Train Loss 3.419516 Test MSE 3.0767499857458267 Test RE 0.8384055873678684\n",
      "29 Train Loss 3.0372376 Test MSE 2.7081530481707166 Test RE 0.7865831928201773\n",
      "30 Train Loss 2.9303648 Test MSE 2.6389710638644868 Test RE 0.7764712400477923\n",
      "31 Train Loss 2.7911072 Test MSE 2.599268118743682 Test RE 0.7706081543482945\n",
      "32 Train Loss 2.5973415 Test MSE 2.403471503080405 Test RE 0.7410159378068634\n",
      "33 Train Loss 2.4289656 Test MSE 2.198367135443787 Test RE 0.7086930467272786\n",
      "34 Train Loss 2.316077 Test MSE 2.1881711742000927 Test RE 0.7070476881162814\n",
      "35 Train Loss 2.2014432 Test MSE 2.0911500803032483 Test RE 0.6911951175889368\n",
      "36 Train Loss 2.0349853 Test MSE 1.912546690263873 Test RE 0.6610192139706097\n",
      "37 Train Loss 1.9456384 Test MSE 1.8944475441697084 Test RE 0.6578840427379379\n",
      "38 Train Loss 1.8051275 Test MSE 1.7961820078203796 Test RE 0.640594537738849\n",
      "39 Train Loss 1.7193706 Test MSE 1.7627793287342575 Test RE 0.6346101805041157\n",
      "40 Train Loss 1.6433553 Test MSE 1.711130447554135 Test RE 0.6252441252783675\n",
      "41 Train Loss 1.5750352 Test MSE 1.6795268818564004 Test RE 0.6194432715655932\n",
      "42 Train Loss 1.499778 Test MSE 1.5938923470872082 Test RE 0.6034448052001682\n",
      "43 Train Loss 1.3844213 Test MSE 1.4142595365851143 Test RE 0.5684242772459901\n",
      "44 Train Loss 1.3313335 Test MSE 1.3867176215281993 Test RE 0.562862191721698\n",
      "45 Train Loss 1.2519995 Test MSE 1.3593154586288452 Test RE 0.5572732390776393\n",
      "46 Train Loss 1.2031224 Test MSE 1.3056439307266048 Test RE 0.5461606886152723\n",
      "47 Train Loss 1.1133513 Test MSE 1.1401960957158468 Test RE 0.5103849211271511\n",
      "48 Train Loss 1.052059 Test MSE 1.0721734171237822 Test RE 0.4949263518131557\n",
      "49 Train Loss 0.99056166 Test MSE 1.0170327086326005 Test RE 0.4820316119522367\n",
      "50 Train Loss 0.93481123 Test MSE 0.9063254830999087 Test RE 0.45504060892615744\n",
      "51 Train Loss 0.8608669 Test MSE 0.8322657235274419 Test RE 0.43605278506864414\n",
      "52 Train Loss 0.81731164 Test MSE 0.7527604461071237 Test RE 0.4147023111989441\n",
      "53 Train Loss 0.728555 Test MSE 0.5975180375432024 Test RE 0.36947373451701077\n",
      "54 Train Loss 0.6836412 Test MSE 0.5773795312710316 Test RE 0.36319407255816866\n",
      "55 Train Loss 0.63313544 Test MSE 0.584576292976733 Test RE 0.3654505835806301\n",
      "56 Train Loss 0.58997303 Test MSE 0.5648859737473384 Test RE 0.3592431169793512\n",
      "57 Train Loss 0.5150425 Test MSE 0.4825819672790658 Test RE 0.3320424464569453\n",
      "58 Train Loss 0.4733437 Test MSE 0.47433049374065217 Test RE 0.3291914773890289\n",
      "59 Train Loss 0.41925544 Test MSE 0.44994861759016386 Test RE 0.32061919635146524\n",
      "60 Train Loss 0.39997527 Test MSE 0.46299645705639814 Test RE 0.32523471416863764\n",
      "61 Train Loss 0.36003637 Test MSE 0.4250201270066188 Test RE 0.3116110205188648\n",
      "62 Train Loss 0.34652588 Test MSE 0.42269664193120493 Test RE 0.3107581011627336\n",
      "63 Train Loss 0.3289569 Test MSE 0.44146444318387995 Test RE 0.317582033555301\n",
      "64 Train Loss 0.3168491 Test MSE 0.4043304639744104 Test RE 0.30393190512724394\n",
      "65 Train Loss 0.30862018 Test MSE 0.39331778906977244 Test RE 0.2997642620239706\n",
      "66 Train Loss 0.30137613 Test MSE 0.39654301653957597 Test RE 0.3009907944544167\n",
      "67 Train Loss 0.29044974 Test MSE 0.3820983689863656 Test RE 0.295457930962812\n",
      "68 Train Loss 0.28183496 Test MSE 0.3972542849123522 Test RE 0.30126061299863344\n",
      "69 Train Loss 0.27506328 Test MSE 0.3956635346671265 Test RE 0.30065682956788486\n",
      "70 Train Loss 0.26830012 Test MSE 0.3835094860249152 Test RE 0.29600300198284185\n",
      "71 Train Loss 0.25363505 Test MSE 0.3734873398777139 Test RE 0.2921097162277453\n",
      "72 Train Loss 0.24626492 Test MSE 0.35710500868163614 Test RE 0.2856314542712248\n",
      "73 Train Loss 0.2372527 Test MSE 0.35717653948133554 Test RE 0.28566005989534976\n",
      "74 Train Loss 0.22824804 Test MSE 0.35552973333048443 Test RE 0.28500076374163613\n",
      "75 Train Loss 0.21683575 Test MSE 0.3418639473134888 Test RE 0.2794696890531623\n",
      "76 Train Loss 0.21422115 Test MSE 0.34904457779577386 Test RE 0.28238947644650203\n",
      "77 Train Loss 0.20735893 Test MSE 0.34334721200542656 Test RE 0.28007530842997147\n",
      "78 Train Loss 0.20254128 Test MSE 0.329614755221378 Test RE 0.27441723405472246\n",
      "79 Train Loss 0.19598776 Test MSE 0.3204034724789447 Test RE 0.27055568718601747\n",
      "80 Train Loss 0.19221726 Test MSE 0.31698606114482836 Test RE 0.26910895076564517\n",
      "81 Train Loss 0.18552539 Test MSE 0.30736623588232287 Test RE 0.26499406031488765\n",
      "82 Train Loss 0.18307689 Test MSE 0.298994227395593 Test RE 0.2613602049799873\n",
      "83 Train Loss 0.18088944 Test MSE 0.2935489019786938 Test RE 0.2589693044821147\n",
      "84 Train Loss 0.17804897 Test MSE 0.2878449332661345 Test RE 0.25644093691159187\n",
      "85 Train Loss 0.17559591 Test MSE 0.27690584830275783 Test RE 0.2515209266539049\n",
      "86 Train Loss 0.17107098 Test MSE 0.2671387966061774 Test RE 0.2470452698454697\n",
      "87 Train Loss 0.16879772 Test MSE 0.27062345858849285 Test RE 0.24865132642527413\n",
      "88 Train Loss 0.16598518 Test MSE 0.26933562069538036 Test RE 0.2480589822165852\n",
      "89 Train Loss 0.1631126 Test MSE 0.2605525277479429 Test RE 0.24398083072478777\n",
      "90 Train Loss 0.16177115 Test MSE 0.25831440181533494 Test RE 0.2429306825155524\n",
      "91 Train Loss 0.15811913 Test MSE 0.26322232869651996 Test RE 0.24522764289473442\n",
      "92 Train Loss 0.15570201 Test MSE 0.2576779349943925 Test RE 0.2426312166767656\n",
      "93 Train Loss 0.15261172 Test MSE 0.250262728731076 Test RE 0.23911462958352095\n",
      "94 Train Loss 0.1515382 Test MSE 0.25178907842721526 Test RE 0.23984269992728602\n",
      "95 Train Loss 0.15010439 Test MSE 0.2539955947856582 Test RE 0.24089132059888577\n",
      "96 Train Loss 0.14794226 Test MSE 0.24644304723732663 Test RE 0.23728284745209674\n",
      "97 Train Loss 0.145577 Test MSE 0.242137067700212 Test RE 0.2352007485882352\n",
      "98 Train Loss 0.14311783 Test MSE 0.24037845796718926 Test RE 0.23434507601857066\n",
      "99 Train Loss 0.14064048 Test MSE 0.23632385939294795 Test RE 0.23236025558815532\n",
      "Training time: 157.96\n",
      "5\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.78508 Test MSE 4.895931749992841 Test RE 1.0576104609118808\n",
      "1 Train Loss 63.248875 Test MSE 5.02928435989764 Test RE 1.0719169937784108\n",
      "2 Train Loss 42.685722 Test MSE 7.139450634933358 Test RE 1.2771457361946608\n",
      "3 Train Loss 34.65949 Test MSE 6.589490652643865 Test RE 1.2269701109217053\n",
      "4 Train Loss 30.82737 Test MSE 6.325627757407535 Test RE 1.202153363934689\n",
      "5 Train Loss 28.232706 Test MSE 6.425079661184985 Test RE 1.211566673172648\n",
      "6 Train Loss 26.1567 Test MSE 6.419065501757591 Test RE 1.2109995003555871\n",
      "7 Train Loss 25.183746 Test MSE 6.280068311119771 Test RE 1.1978163702189721\n",
      "8 Train Loss 24.028715 Test MSE 6.749512575064603 Test RE 1.241778870089962\n",
      "9 Train Loss 22.860723 Test MSE 7.0932269004643 Test RE 1.2730046396100854\n",
      "10 Train Loss 22.275364 Test MSE 7.059777575766805 Test RE 1.2699995571200375\n",
      "11 Train Loss 21.363644 Test MSE 7.095312767553284 Test RE 1.2731917986661139\n",
      "12 Train Loss 20.90243 Test MSE 7.170849806560372 Test RE 1.2799510867523334\n",
      "13 Train Loss 20.544697 Test MSE 7.218264881216302 Test RE 1.2841757593089385\n",
      "14 Train Loss 20.172737 Test MSE 7.135728666067894 Test RE 1.276812789263608\n",
      "15 Train Loss 19.919788 Test MSE 6.980566637955459 Test RE 1.2628547408078148\n",
      "16 Train Loss 19.402824 Test MSE 7.25478973171989 Test RE 1.2874206625766946\n",
      "17 Train Loss 18.97007 Test MSE 7.367614704579352 Test RE 1.297392889127858\n",
      "18 Train Loss 18.062866 Test MSE 7.256698185823006 Test RE 1.2875899866904021\n",
      "19 Train Loss 17.602125 Test MSE 7.381495818734719 Test RE 1.2986145045908084\n",
      "20 Train Loss 17.334143 Test MSE 7.323514144047877 Test RE 1.2935041386518045\n",
      "21 Train Loss 16.920927 Test MSE 7.319178735722067 Test RE 1.293121214642189\n",
      "22 Train Loss 16.466633 Test MSE 7.141103807820278 Test RE 1.2772935921434603\n",
      "23 Train Loss 16.146938 Test MSE 7.114856158662396 Test RE 1.2749440381738086\n",
      "24 Train Loss 15.832624 Test MSE 7.162459869012442 Test RE 1.279202092358384\n",
      "25 Train Loss 15.350601 Test MSE 7.110151052978055 Test RE 1.2745224036116285\n",
      "26 Train Loss 14.973105 Test MSE 7.158751352720197 Test RE 1.278870882402892\n",
      "27 Train Loss 14.601952 Test MSE 7.297551348013932 Test RE 1.2912092840006781\n",
      "28 Train Loss 14.1922245 Test MSE 7.269414732640785 Test RE 1.2887176711373212\n",
      "29 Train Loss 13.454384 Test MSE 7.096454480045791 Test RE 1.273294229704637\n",
      "30 Train Loss 13.17691 Test MSE 7.0378991600265035 Test RE 1.268030150969308\n",
      "31 Train Loss 12.84004 Test MSE 6.980010242483803 Test RE 1.2628044110353556\n",
      "32 Train Loss 12.405475 Test MSE 6.7705739197403165 Test RE 1.243714799665786\n",
      "33 Train Loss 11.72428 Test MSE 6.435029424073945 Test RE 1.2125044154580107\n",
      "34 Train Loss 11.263909 Test MSE 6.5274470292774485 Test RE 1.221180155736948\n",
      "35 Train Loss 10.9202585 Test MSE 6.4664414175261795 Test RE 1.2154601761545951\n",
      "36 Train Loss 10.609838 Test MSE 6.473386447787555 Test RE 1.2161127098926123\n",
      "37 Train Loss 10.43631 Test MSE 6.496903153880498 Test RE 1.2183196720977594\n",
      "38 Train Loss 10.150648 Test MSE 6.457057145721674 Test RE 1.2145779018728309\n",
      "39 Train Loss 9.910786 Test MSE 6.370339697762981 Test RE 1.206394520966202\n",
      "40 Train Loss 9.550727 Test MSE 6.395082867898312 Test RE 1.2087351414962886\n",
      "41 Train Loss 9.353285 Test MSE 6.329772569357411 Test RE 1.2025471496480797\n",
      "42 Train Loss 9.147284 Test MSE 6.364589806012047 Test RE 1.2058499500171547\n",
      "43 Train Loss 8.98723 Test MSE 6.457316835625285 Test RE 1.2146023255723495\n",
      "44 Train Loss 8.804617 Test MSE 6.427062797858035 Test RE 1.2117536371524624\n",
      "45 Train Loss 8.5491295 Test MSE 6.5489943027493895 Test RE 1.2231940689378702\n",
      "46 Train Loss 8.318416 Test MSE 6.688572362330365 Test RE 1.2361602527658015\n",
      "47 Train Loss 8.028957 Test MSE 6.613228182014677 Test RE 1.229178100736537\n",
      "48 Train Loss 7.734259 Test MSE 6.400355887275535 Test RE 1.2092333657298375\n",
      "49 Train Loss 7.500421 Test MSE 6.307565293745772 Test RE 1.200435797305989\n",
      "50 Train Loss 6.4735227 Test MSE 5.276242396652689 Test RE 1.0979193264363953\n",
      "51 Train Loss 5.8449864 Test MSE 5.014665477962122 Test RE 1.070357961637744\n",
      "52 Train Loss 4.9667044 Test MSE 5.092315196938491 Test RE 1.0786131205420753\n",
      "53 Train Loss 4.4407134 Test MSE 5.0850209813795395 Test RE 1.0778403427666043\n",
      "54 Train Loss 4.087917 Test MSE 5.0498396867223345 Test RE 1.0741052908514928\n",
      "55 Train Loss 3.883883 Test MSE 5.183772449595781 Test RE 1.0882558862319083\n",
      "56 Train Loss 3.650178 Test MSE 5.35584190221349 Test RE 1.1061701494212985\n",
      "57 Train Loss 3.4156406 Test MSE 5.300993743068952 Test RE 1.1004915344572421\n",
      "58 Train Loss 3.273901 Test MSE 5.31210509194107 Test RE 1.101644294199774\n",
      "59 Train Loss 3.1334174 Test MSE 5.424621538752953 Test RE 1.1132502011887624\n",
      "60 Train Loss 3.0089614 Test MSE 5.415135903764417 Test RE 1.1122764461215018\n",
      "61 Train Loss 2.8144534 Test MSE 5.390720267541951 Test RE 1.109766110470349\n",
      "62 Train Loss 2.7061768 Test MSE 5.366525164509072 Test RE 1.1072728349430585\n",
      "63 Train Loss 2.6220994 Test MSE 5.364118669022042 Test RE 1.1070245415138362\n",
      "64 Train Loss 2.5583184 Test MSE 5.335020419444745 Test RE 1.104017870492471\n",
      "65 Train Loss 2.4578352 Test MSE 5.344271899843 Test RE 1.10497469678111\n",
      "66 Train Loss 2.3722348 Test MSE 5.290777929689926 Test RE 1.099430616602105\n",
      "67 Train Loss 2.302446 Test MSE 5.238298851943268 Test RE 1.0939644173429244\n",
      "68 Train Loss 2.2405438 Test MSE 5.261134068310486 Test RE 1.0963462734899747\n",
      "69 Train Loss 2.1727607 Test MSE 5.206359136563499 Test RE 1.090624178668823\n",
      "70 Train Loss 2.1353042 Test MSE 5.166538606687738 Test RE 1.0864453857616274\n",
      "71 Train Loss 2.0795984 Test MSE 5.150808732160773 Test RE 1.0847902469553008\n",
      "72 Train Loss 2.0359724 Test MSE 5.112015529612509 Test RE 1.080697489333064\n",
      "73 Train Loss 2.0061166 Test MSE 5.1123143007102 Test RE 1.0807290694853287\n",
      "74 Train Loss 1.9720477 Test MSE 5.12375985676311 Test RE 1.0819381725310135\n",
      "75 Train Loss 1.9166492 Test MSE 5.123210259644158 Test RE 1.081880144240691\n",
      "76 Train Loss 1.8696206 Test MSE 5.106452272240571 Test RE 1.0801092834820458\n",
      "77 Train Loss 1.8278562 Test MSE 5.14563914495058 Test RE 1.0842457377456476\n",
      "78 Train Loss 1.8094165 Test MSE 5.143812414916671 Test RE 1.084053264078937\n",
      "79 Train Loss 1.7934475 Test MSE 5.12523984927857 Test RE 1.0820944195867315\n",
      "80 Train Loss 1.777945 Test MSE 5.157444000803369 Test RE 1.0854887351443414\n",
      "81 Train Loss 1.7287748 Test MSE 5.204729668082301 Test RE 1.090453495399599\n",
      "82 Train Loss 1.6891547 Test MSE 5.194835676837443 Test RE 1.0894165472540758\n",
      "83 Train Loss 1.6516316 Test MSE 5.196528906381949 Test RE 1.0895940776045288\n",
      "84 Train Loss 1.6172954 Test MSE 5.151560315910141 Test RE 1.0848693880207132\n",
      "85 Train Loss 1.5874748 Test MSE 5.123728876766296 Test RE 1.0819349016427655\n",
      "86 Train Loss 1.5488138 Test MSE 5.153340771796259 Test RE 1.0850568453252791\n",
      "87 Train Loss 1.5180221 Test MSE 5.13739209484951 Test RE 1.0833765148591687\n",
      "88 Train Loss 1.4977026 Test MSE 5.137169205800325 Test RE 1.0833530131119773\n",
      "89 Train Loss 1.4684477 Test MSE 5.19860560236754 Test RE 1.0898117738461714\n",
      "90 Train Loss 1.4401232 Test MSE 5.211532258824584 Test RE 1.0911658750142308\n",
      "91 Train Loss 1.4035796 Test MSE 5.1919707385802525 Test RE 1.089116100639564\n",
      "92 Train Loss 1.3597819 Test MSE 5.182626667477378 Test RE 1.0881356096325772\n",
      "93 Train Loss 1.347296 Test MSE 5.17520687220624 Test RE 1.087356406752722\n",
      "94 Train Loss 1.316352 Test MSE 5.18156844991627 Test RE 1.0880245131683726\n",
      "95 Train Loss 1.2832125 Test MSE 5.1462620661121745 Test RE 1.0843113641096407\n",
      "96 Train Loss 1.2546322 Test MSE 5.1391990631320805 Test RE 1.0835670254194059\n",
      "97 Train Loss 1.2301097 Test MSE 5.138177456369742 Test RE 1.0834593204632632\n",
      "98 Train Loss 1.215954 Test MSE 5.116742317746708 Test RE 1.0811970034448404\n",
      "99 Train Loss 1.2008444 Test MSE 5.1070366162552405 Test RE 1.0801710815079753\n",
      "Training time: 158.95\n",
      "6\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.06788 Test MSE 5.625190895862597 Test RE 1.1336439976270853\n",
      "1 Train Loss 59.00222 Test MSE 7.937817209673785 Test RE 1.3466620055691831\n",
      "2 Train Loss 43.54442 Test MSE 7.408084582887188 Test RE 1.3009512611118272\n",
      "3 Train Loss 36.571407 Test MSE 8.58192609578292 Test RE 1.4002334408191501\n",
      "4 Train Loss 34.648544 Test MSE 8.677380246832909 Test RE 1.4079990919081786\n",
      "5 Train Loss 32.734535 Test MSE 8.381764203492498 Test RE 1.3838078177863782\n",
      "6 Train Loss 32.055237 Test MSE 8.149727693807003 Test RE 1.3645190689466515\n",
      "7 Train Loss 31.615856 Test MSE 8.139699069877251 Test RE 1.3636792580062094\n",
      "8 Train Loss 30.921562 Test MSE 8.487394366205406 Test RE 1.3925001522650133\n",
      "9 Train Loss 30.650715 Test MSE 8.486893696585714 Test RE 1.3924590800128276\n",
      "10 Train Loss 29.964128 Test MSE 8.775845040534797 Test RE 1.4159650481847579\n",
      "11 Train Loss 29.403028 Test MSE 9.030815558689973 Test RE 1.4363872667439952\n",
      "12 Train Loss 28.849735 Test MSE 9.13613526531249 Test RE 1.4447387479353633\n",
      "13 Train Loss 28.309174 Test MSE 8.835736070988593 Test RE 1.4207884817586547\n",
      "14 Train Loss 27.900517 Test MSE 8.978157448313928 Test RE 1.4321934029313013\n",
      "15 Train Loss 27.10289 Test MSE 8.993831989278744 Test RE 1.4334430571440853\n",
      "16 Train Loss 26.69022 Test MSE 9.037113377693723 Test RE 1.4368880260826973\n",
      "17 Train Loss 26.180435 Test MSE 9.202923622896616 Test RE 1.4500099058079057\n",
      "18 Train Loss 25.537315 Test MSE 9.334015994386078 Test RE 1.4603008252826108\n",
      "19 Train Loss 25.143122 Test MSE 9.184933916839398 Test RE 1.448591986173202\n",
      "20 Train Loss 24.387484 Test MSE 9.128515471592157 Test RE 1.4441361458914015\n",
      "21 Train Loss 24.05323 Test MSE 9.160470506443154 Test RE 1.4466615897022368\n",
      "22 Train Loss 23.281837 Test MSE 9.156720721517981 Test RE 1.4463654681727849\n",
      "23 Train Loss 22.828543 Test MSE 9.149443084646183 Test RE 1.4457905781374898\n",
      "24 Train Loss 22.196735 Test MSE 9.07902057778025 Test RE 1.440215764932363\n",
      "25 Train Loss 21.778927 Test MSE 8.873034731099805 Test RE 1.4237841404142015\n",
      "26 Train Loss 21.52127 Test MSE 8.775692253809368 Test RE 1.4159527222147994\n",
      "27 Train Loss 21.004875 Test MSE 8.955109732932502 Test RE 1.430353938795336\n",
      "28 Train Loss 20.548168 Test MSE 8.767173769845815 Test RE 1.4152653292039459\n",
      "29 Train Loss 19.983793 Test MSE 8.703443418547295 Test RE 1.410112022704611\n",
      "30 Train Loss 19.577202 Test MSE 8.67047063329713 Test RE 1.4074384003876017\n",
      "31 Train Loss 19.117382 Test MSE 8.7640833562067 Test RE 1.4150158679240386\n",
      "32 Train Loss 18.48357 Test MSE 8.666475823449142 Test RE 1.4071141332983383\n",
      "33 Train Loss 18.067352 Test MSE 8.517423917132284 Test RE 1.3949614042064573\n",
      "34 Train Loss 17.617664 Test MSE 8.434135056626939 Test RE 1.3881242327482057\n",
      "35 Train Loss 17.037296 Test MSE 8.512509008343583 Test RE 1.3945588706773833\n",
      "36 Train Loss 16.715366 Test MSE 8.44475448575601 Test RE 1.3889978522481377\n",
      "37 Train Loss 16.402485 Test MSE 8.396067720580673 Test RE 1.384988051513995\n",
      "38 Train Loss 16.147373 Test MSE 8.420000384184377 Test RE 1.3869605740788076\n",
      "39 Train Loss 15.884132 Test MSE 8.430945831445918 Test RE 1.3878617601111494\n",
      "40 Train Loss 15.66245 Test MSE 8.364784362515195 Test RE 1.3824054430473378\n",
      "41 Train Loss 15.429772 Test MSE 8.442960277951482 Test RE 1.388850288267537\n",
      "42 Train Loss 15.206816 Test MSE 8.419945183066403 Test RE 1.386956027647913\n",
      "43 Train Loss 14.94807 Test MSE 8.455349452989052 Test RE 1.3898689121337218\n",
      "44 Train Loss 14.666691 Test MSE 8.428828140975245 Test RE 1.3876874471535763\n",
      "45 Train Loss 14.432106 Test MSE 8.267191346450495 Test RE 1.374317431726416\n",
      "46 Train Loss 14.146469 Test MSE 7.831463848987175 Test RE 1.33761008357453\n",
      "47 Train Loss 12.98513 Test MSE 7.167915352974048 Test RE 1.2796891693025338\n",
      "48 Train Loss 12.592845 Test MSE 7.178767528382744 Test RE 1.2806575232983493\n",
      "49 Train Loss 12.046984 Test MSE 7.236798639230998 Test RE 1.285823339788584\n",
      "50 Train Loss 11.677195 Test MSE 7.123593928909453 Test RE 1.2757266787232149\n",
      "51 Train Loss 11.494289 Test MSE 7.099159067819588 Test RE 1.2735368443765624\n",
      "52 Train Loss 11.337762 Test MSE 6.966171571994006 Test RE 1.2615519626907536\n",
      "53 Train Loss 11.099258 Test MSE 6.697011551123275 Test RE 1.2369398586818834\n",
      "54 Train Loss 10.883589 Test MSE 6.681080238495148 Test RE 1.2354677237644351\n",
      "55 Train Loss 10.688881 Test MSE 6.575138831429675 Test RE 1.2256332204675315\n",
      "56 Train Loss 10.527519 Test MSE 6.452213773025951 Test RE 1.2141222951732555\n",
      "57 Train Loss 10.338874 Test MSE 6.497521413675696 Test RE 1.218377639727414\n",
      "58 Train Loss 10.2365465 Test MSE 6.517856161722125 Test RE 1.2202826775604463\n",
      "59 Train Loss 10.14011 Test MSE 6.494290253412411 Test RE 1.2180746578119324\n",
      "60 Train Loss 10.016649 Test MSE 6.477550917640171 Test RE 1.216503822836392\n",
      "61 Train Loss 9.940786 Test MSE 6.3984232646476995 Test RE 1.2090507846164107\n",
      "62 Train Loss 9.883736 Test MSE 6.32198433670872 Test RE 1.201807107287327\n",
      "63 Train Loss 9.786374 Test MSE 6.253916460865331 Test RE 1.1953197577326258\n",
      "64 Train Loss 9.682612 Test MSE 6.23478061242426 Test RE 1.193489626018947\n",
      "65 Train Loss 9.519386 Test MSE 6.188439513920979 Test RE 1.189045943203607\n",
      "66 Train Loss 9.41052 Test MSE 6.085025888462581 Test RE 1.1790691475033612\n",
      "67 Train Loss 9.286998 Test MSE 6.102303104886928 Test RE 1.1807418267848475\n",
      "68 Train Loss 9.227439 Test MSE 6.165162443650009 Test RE 1.1868076098258844\n",
      "69 Train Loss 9.154448 Test MSE 6.068393294799834 Test RE 1.1774566319837578\n",
      "70 Train Loss 9.024126 Test MSE 6.008850540187233 Test RE 1.171665821031652\n",
      "71 Train Loss 8.863066 Test MSE 6.095738311997869 Test RE 1.1801065411201108\n",
      "72 Train Loss 8.740785 Test MSE 6.075990191160091 Test RE 1.1781934182958993\n",
      "73 Train Loss 8.622032 Test MSE 6.115134737389245 Test RE 1.1819825787341471\n",
      "74 Train Loss 8.239938 Test MSE 6.190420224229348 Test RE 1.1892362146872546\n",
      "75 Train Loss 6.2648554 Test MSE 5.875359986354175 Test RE 1.158578062346941\n",
      "76 Train Loss 5.0085716 Test MSE 5.42543146063477 Test RE 1.1133333048706457\n",
      "77 Train Loss 4.651623 Test MSE 5.389996302249187 Test RE 1.1096915880425537\n",
      "78 Train Loss 4.3932104 Test MSE 5.291079485324042 Test RE 1.0994619479844798\n",
      "79 Train Loss 4.1547046 Test MSE 5.241972536370754 Test RE 1.0943479555661209\n",
      "80 Train Loss 3.8780258 Test MSE 5.157048945631832 Test RE 1.0854471606599005\n",
      "81 Train Loss 3.6821287 Test MSE 5.22037985312622 Test RE 1.092091715870946\n",
      "82 Train Loss 3.5670738 Test MSE 5.200146690918989 Test RE 1.0899732952353858\n",
      "83 Train Loss 3.4469898 Test MSE 5.230748572856528 Test RE 1.093175734284007\n",
      "84 Train Loss 3.3147566 Test MSE 5.216245934916844 Test RE 1.0916592270414591\n",
      "85 Train Loss 3.1826777 Test MSE 5.2189973121353885 Test RE 1.091947094063259\n",
      "86 Train Loss 3.031702 Test MSE 5.206182180121699 Test RE 1.0906056441604604\n",
      "87 Train Loss 2.9274573 Test MSE 5.224151389237032 Test RE 1.0924861430768826\n",
      "88 Train Loss 2.834362 Test MSE 5.284559530415306 Test RE 1.0987843308704222\n",
      "89 Train Loss 2.711145 Test MSE 5.293413010978783 Test RE 1.0997043692004396\n",
      "90 Train Loss 2.6436725 Test MSE 5.329777160927536 Test RE 1.1034752227031077\n",
      "91 Train Loss 2.6139116 Test MSE 5.3106823177875535 Test RE 1.1014967541976366\n",
      "92 Train Loss 2.5892358 Test MSE 5.333954299749966 Test RE 1.103907554700737\n",
      "93 Train Loss 2.5636053 Test MSE 5.370416572696668 Test RE 1.107674218483773\n",
      "94 Train Loss 2.5217974 Test MSE 5.362447447137393 Test RE 1.106852078162606\n",
      "95 Train Loss 2.4806433 Test MSE 5.348819477345292 Test RE 1.1054447224136095\n",
      "96 Train Loss 2.433466 Test MSE 5.392440591393549 Test RE 1.1099431744546815\n",
      "97 Train Loss 2.4138682 Test MSE 5.416975686803267 Test RE 1.1124653770731183\n",
      "98 Train Loss 2.38242 Test MSE 5.411764545075547 Test RE 1.1119301513321767\n",
      "99 Train Loss 2.347187 Test MSE 5.37693295898444 Test RE 1.1083460327419363\n",
      "Training time: 157.47\n",
      "7\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.065536 Test MSE 6.581179602032903 Test RE 1.2261961035932498\n",
      "1 Train Loss 47.648216 Test MSE 6.380595400941647 Test RE 1.207365226539046\n",
      "2 Train Loss 35.48867 Test MSE 7.254643743227984 Test RE 1.2874077090967555\n",
      "3 Train Loss 29.726616 Test MSE 7.1134988004257185 Test RE 1.2748224167173234\n",
      "4 Train Loss 24.199085 Test MSE 6.36590129726656 Test RE 1.2059741827054393\n",
      "5 Train Loss 19.001076 Test MSE 5.890682532216051 Test RE 1.1600878256940803\n",
      "6 Train Loss 16.605732 Test MSE 6.096640573192226 Test RE 1.180193874670649\n",
      "7 Train Loss 15.271063 Test MSE 5.746193242154014 Test RE 1.1457719179694503\n",
      "8 Train Loss 14.510937 Test MSE 5.661827777631918 Test RE 1.1373297191237743\n",
      "9 Train Loss 13.573808 Test MSE 5.9074806742544625 Test RE 1.1617407281382943\n",
      "10 Train Loss 13.0220585 Test MSE 5.935431616653434 Test RE 1.1644858432692884\n",
      "11 Train Loss 12.635866 Test MSE 6.020467630139176 Test RE 1.172797882371129\n",
      "12 Train Loss 12.275217 Test MSE 5.944638720732198 Test RE 1.1653886746410203\n",
      "13 Train Loss 12.136715 Test MSE 5.864770255111521 Test RE 1.1575334826330101\n",
      "14 Train Loss 11.959542 Test MSE 5.846256791871689 Test RE 1.1557050314314172\n",
      "15 Train Loss 11.88895 Test MSE 5.8425006451624055 Test RE 1.1553337087810016\n",
      "16 Train Loss 11.717277 Test MSE 5.896603151314558 Test RE 1.160670670986628\n",
      "17 Train Loss 11.623574 Test MSE 5.877625934819059 Test RE 1.1588014550508894\n",
      "18 Train Loss 11.223373 Test MSE 5.576574137309841 Test RE 1.1287345022522164\n",
      "19 Train Loss 10.613302 Test MSE 5.31683128707757 Test RE 1.1021342532886462\n",
      "20 Train Loss 10.01387 Test MSE 5.340099044496401 Test RE 1.1045432254724614\n",
      "21 Train Loss 9.613539 Test MSE 5.17873365611872 Test RE 1.087726847785869\n",
      "22 Train Loss 9.372393 Test MSE 5.161826600634298 Test RE 1.0859498407365975\n",
      "23 Train Loss 9.231876 Test MSE 5.19185983126385 Test RE 1.0891044681020243\n",
      "24 Train Loss 9.112616 Test MSE 5.1367504981468 Test RE 1.0833088625863507\n",
      "25 Train Loss 8.95698 Test MSE 5.079344575875509 Test RE 1.0772385785573417\n",
      "26 Train Loss 8.797062 Test MSE 5.181092702535825 Test RE 1.0879745633607982\n",
      "27 Train Loss 8.706899 Test MSE 5.129656739015029 Test RE 1.0825605892283512\n",
      "28 Train Loss 8.5760145 Test MSE 5.017105752933857 Test RE 1.0706183628618546\n",
      "29 Train Loss 8.409972 Test MSE 4.937625065187182 Test RE 1.0621041720464168\n",
      "30 Train Loss 8.319034 Test MSE 4.8671732534978425 Test RE 1.0544997064652637\n",
      "31 Train Loss 8.253661 Test MSE 4.880320767697285 Test RE 1.0559229863811355\n",
      "32 Train Loss 8.045885 Test MSE 4.862250518998095 Test RE 1.0539663028808\n",
      "33 Train Loss 7.926612 Test MSE 4.855203203929437 Test RE 1.0532022198782656\n",
      "34 Train Loss 7.7164326 Test MSE 4.723380175475904 Test RE 1.0388061486149553\n",
      "35 Train Loss 7.5893164 Test MSE 4.697614544136325 Test RE 1.035968975232096\n",
      "36 Train Loss 7.389452 Test MSE 4.657483063022875 Test RE 1.0315343687422118\n",
      "37 Train Loss 7.045994 Test MSE 4.519471865777529 Test RE 1.016136154230866\n",
      "38 Train Loss 6.579209 Test MSE 4.364091352719928 Test RE 0.9985158815635027\n",
      "39 Train Loss 6.387725 Test MSE 4.3292467346540615 Test RE 0.9945216213144886\n",
      "40 Train Loss 6.081258 Test MSE 4.135323441927306 Test RE 0.9719922494636604\n",
      "41 Train Loss 5.7021866 Test MSE 3.8474915641789473 Test RE 0.9375553112205027\n",
      "42 Train Loss 5.3898687 Test MSE 3.768258065366265 Test RE 0.9278512965645397\n",
      "43 Train Loss 5.011551 Test MSE 3.549707113535887 Test RE 0.9005427220475892\n",
      "44 Train Loss 4.6302524 Test MSE 3.3860668887907566 Test RE 0.8795404689128635\n",
      "45 Train Loss 4.2905893 Test MSE 3.280697833448309 Test RE 0.865747360591377\n",
      "46 Train Loss 3.9054956 Test MSE 3.22689972765515 Test RE 0.8586195949234663\n",
      "47 Train Loss 3.6795828 Test MSE 3.246671043298504 Test RE 0.8612459726600132\n",
      "48 Train Loss 3.4426696 Test MSE 3.2007604651062183 Test RE 0.8551349315017802\n",
      "49 Train Loss 3.2738638 Test MSE 3.1817729300081696 Test RE 0.8525947451127284\n",
      "50 Train Loss 3.1413796 Test MSE 3.1791175805669627 Test RE 0.8522389042703233\n",
      "51 Train Loss 2.9536479 Test MSE 3.1239992996493275 Test RE 0.8448187113385343\n",
      "52 Train Loss 2.829199 Test MSE 3.061479256181694 Test RE 0.836322384174398\n",
      "53 Train Loss 2.7428298 Test MSE 3.0046532466962006 Test RE 0.8285242798704544\n",
      "54 Train Loss 2.6413589 Test MSE 2.8994951905363457 Test RE 0.8138966419538815\n",
      "55 Train Loss 2.5530605 Test MSE 2.888505523672207 Test RE 0.8123527621084508\n",
      "56 Train Loss 2.4470139 Test MSE 2.825123382174179 Test RE 0.8033906445404617\n",
      "57 Train Loss 2.3556018 Test MSE 2.7731343827666386 Test RE 0.7959641689525436\n",
      "58 Train Loss 2.2212715 Test MSE 2.6892911276368023 Test RE 0.7838391836613168\n",
      "59 Train Loss 2.1663773 Test MSE 2.603451156347624 Test RE 0.7712279801769736\n",
      "60 Train Loss 2.1131675 Test MSE 2.5038791038348474 Test RE 0.7563359403920229\n",
      "61 Train Loss 2.069574 Test MSE 2.464184761729973 Test RE 0.750316840492969\n",
      "62 Train Loss 2.0188801 Test MSE 2.4461985846524987 Test RE 0.747573530051243\n",
      "63 Train Loss 1.9279732 Test MSE 2.3413362795312813 Test RE 0.7313747414902443\n",
      "64 Train Loss 1.9006869 Test MSE 2.3165450852068874 Test RE 0.7274923633019376\n",
      "65 Train Loss 1.8701249 Test MSE 2.278184608674749 Test RE 0.7214438191319769\n",
      "66 Train Loss 1.8203424 Test MSE 2.1658947423404182 Test RE 0.7034394714150644\n",
      "67 Train Loss 1.7646337 Test MSE 2.0776594425164014 Test RE 0.688961956320986\n",
      "68 Train Loss 1.7383481 Test MSE 2.088925854514577 Test RE 0.6908274292437124\n",
      "69 Train Loss 1.6850294 Test MSE 2.0306332556735995 Test RE 0.681120273862152\n",
      "70 Train Loss 1.65999 Test MSE 1.9958555300711316 Test RE 0.6752624670859538\n",
      "71 Train Loss 1.6410468 Test MSE 1.9631853370012264 Test RE 0.6697129720416409\n",
      "72 Train Loss 1.6076447 Test MSE 1.8878280144416086 Test RE 0.6567336562221755\n",
      "73 Train Loss 1.55015 Test MSE 1.7670959803971344 Test RE 0.6353867144859261\n",
      "74 Train Loss 1.5007051 Test MSE 1.7121938994755384 Test RE 0.6254383868524767\n",
      "75 Train Loss 1.4368079 Test MSE 1.6411560833056789 Test RE 0.6123264276415941\n",
      "76 Train Loss 1.3978956 Test MSE 1.5685462053387056 Test RE 0.5986275754347076\n",
      "77 Train Loss 1.3556494 Test MSE 1.5053272634286716 Test RE 0.5864399174589604\n",
      "78 Train Loss 1.3072287 Test MSE 1.4211433138712277 Test RE 0.5698059742235333\n",
      "79 Train Loss 1.2443185 Test MSE 1.2623623632316914 Test RE 0.5370318942579638\n",
      "80 Train Loss 1.1944206 Test MSE 1.2774447835171703 Test RE 0.540230536328505\n",
      "81 Train Loss 1.175443 Test MSE 1.275424281826195 Test RE 0.539803132857981\n",
      "82 Train Loss 1.1542851 Test MSE 1.2012247207312077 Test RE 0.5238659736461687\n",
      "83 Train Loss 1.0933709 Test MSE 1.1150910054590963 Test RE 0.5047347622660777\n",
      "84 Train Loss 1.0602443 Test MSE 1.1269683576447063 Test RE 0.5074157243173396\n",
      "85 Train Loss 1.0338831 Test MSE 1.0695282582907923 Test RE 0.4943154584426449\n",
      "86 Train Loss 1.0121857 Test MSE 1.0138759293951356 Test RE 0.4812829388821943\n",
      "87 Train Loss 0.99894935 Test MSE 0.9871724556572683 Test RE 0.47490263011848205\n",
      "88 Train Loss 0.96488106 Test MSE 0.8979716510560961 Test RE 0.4529386417208427\n",
      "89 Train Loss 0.9318731 Test MSE 0.8185496449261953 Test RE 0.43244469372523503\n",
      "90 Train Loss 0.89153916 Test MSE 0.6997190357049995 Test RE 0.39982496210978613\n",
      "91 Train Loss 0.840309 Test MSE 0.6695609686154119 Test RE 0.39111378645333555\n",
      "92 Train Loss 0.8127122 Test MSE 0.6546366697134687 Test RE 0.38673032196664386\n",
      "93 Train Loss 0.78590214 Test MSE 0.5930755852754269 Test RE 0.36809768262292314\n",
      "94 Train Loss 0.7209753 Test MSE 0.5475072957322996 Test RE 0.3536739033907367\n",
      "95 Train Loss 0.70276475 Test MSE 0.5259635581903682 Test RE 0.3466457561404833\n",
      "96 Train Loss 0.6833056 Test MSE 0.5018194564409167 Test RE 0.3385959881885122\n",
      "97 Train Loss 0.6537011 Test MSE 0.5066140962001623 Test RE 0.34020970241784015\n",
      "98 Train Loss 0.6122832 Test MSE 0.4843056468430526 Test RE 0.33263491018790403\n",
      "99 Train Loss 0.5749315 Test MSE 0.45127081817162223 Test RE 0.3210899300057233\n",
      "Training time: 158.63\n",
      "8\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 64.74861 Test MSE 5.399935528910657 Test RE 1.1107142600126456\n",
      "1 Train Loss 51.675056 Test MSE 6.694859893827185 Test RE 1.2367411368744607\n",
      "2 Train Loss 38.956905 Test MSE 8.280740736371015 Test RE 1.3754431791842698\n",
      "3 Train Loss 33.22713 Test MSE 7.3789938497235905 Test RE 1.2983944022771583\n",
      "4 Train Loss 29.587946 Test MSE 6.688754325186891 Test RE 1.236177067543957\n",
      "5 Train Loss 26.48742 Test MSE 6.2973657567177375 Test RE 1.1994648328774677\n",
      "6 Train Loss 24.158869 Test MSE 6.464684552236964 Test RE 1.215295050955336\n",
      "7 Train Loss 22.62006 Test MSE 6.7064134117650465 Test RE 1.237807817270802\n",
      "8 Train Loss 21.108967 Test MSE 7.023397565203707 Test RE 1.2667230889339525\n",
      "9 Train Loss 20.204266 Test MSE 7.3274014864035975 Test RE 1.2938473909652073\n",
      "10 Train Loss 18.835798 Test MSE 7.576989084156706 Test RE 1.3156985348675503\n",
      "11 Train Loss 18.234282 Test MSE 7.608531143392725 Test RE 1.3184342350686844\n",
      "12 Train Loss 17.647053 Test MSE 7.67317466439684 Test RE 1.324023222334136\n",
      "13 Train Loss 16.95811 Test MSE 7.598275085797675 Test RE 1.317545331740681\n",
      "14 Train Loss 16.58402 Test MSE 7.83104038549951 Test RE 1.33757391941038\n",
      "15 Train Loss 16.199486 Test MSE 7.622567737053709 Test RE 1.319649830943648\n",
      "16 Train Loss 15.710274 Test MSE 7.731079286143772 Test RE 1.3290096178540627\n",
      "17 Train Loss 15.251896 Test MSE 7.865260718337564 Test RE 1.3404932204986508\n",
      "18 Train Loss 14.82892 Test MSE 8.038181173187628 Test RE 1.3551487085880969\n",
      "19 Train Loss 14.58997 Test MSE 8.103790864783182 Test RE 1.3606680042623873\n",
      "20 Train Loss 14.431199 Test MSE 8.137800372750362 Test RE 1.3635202002279658\n",
      "21 Train Loss 14.271628 Test MSE 8.152727821783683 Test RE 1.3647702034203504\n",
      "22 Train Loss 13.956283 Test MSE 8.159360462694075 Test RE 1.365325244049938\n",
      "23 Train Loss 13.755207 Test MSE 8.14409660984417 Test RE 1.364047577783547\n",
      "24 Train Loss 13.468498 Test MSE 8.183646282139026 Test RE 1.3673556363803183\n",
      "25 Train Loss 13.280585 Test MSE 8.288433477811285 Test RE 1.376081918689673\n",
      "26 Train Loss 12.897865 Test MSE 8.254679937608776 Test RE 1.3732771051520412\n",
      "27 Train Loss 12.638183 Test MSE 8.147170463544649 Test RE 1.364304972024839\n",
      "28 Train Loss 12.302874 Test MSE 8.140147464024626 Test RE 1.36371681820175\n",
      "29 Train Loss 11.627997 Test MSE 7.85321968543928 Test RE 1.3394667379783531\n",
      "30 Train Loss 11.258078 Test MSE 7.633175532006169 Test RE 1.3205677439405943\n",
      "31 Train Loss 10.220104 Test MSE 6.936889937075187 Test RE 1.2588977641702148\n",
      "32 Train Loss 9.008185 Test MSE 6.621248161612841 Test RE 1.2299231979940395\n",
      "33 Train Loss 7.9620514 Test MSE 6.441240605673849 Test RE 1.2130894375471026\n",
      "34 Train Loss 7.332849 Test MSE 6.232185856636964 Test RE 1.1932412502879124\n",
      "35 Train Loss 6.4920444 Test MSE 5.778598596289316 Test RE 1.1489981360341148\n",
      "36 Train Loss 6.074167 Test MSE 5.767762834464473 Test RE 1.1479203563654332\n",
      "37 Train Loss 5.596284 Test MSE 5.937833279961817 Test RE 1.164721413338336\n",
      "38 Train Loss 5.27666 Test MSE 5.938096471686387 Test RE 1.1647472259223353\n",
      "39 Train Loss 4.841239 Test MSE 5.919728895746231 Test RE 1.1629444468340397\n",
      "40 Train Loss 4.697088 Test MSE 5.890900268331206 Test RE 1.1601092655425986\n",
      "41 Train Loss 4.455825 Test MSE 6.0236388857440435 Test RE 1.1731067248433056\n",
      "42 Train Loss 4.239213 Test MSE 6.038344679247872 Test RE 1.1745378322859885\n",
      "43 Train Loss 4.1243596 Test MSE 6.04154678553829 Test RE 1.174849217003444\n",
      "44 Train Loss 3.9626698 Test MSE 6.192968553913326 Test RE 1.189480968194542\n",
      "45 Train Loss 3.8284516 Test MSE 6.1524980039259916 Test RE 1.185588016645791\n",
      "46 Train Loss 3.690309 Test MSE 6.176628704316969 Test RE 1.1879107376106437\n",
      "47 Train Loss 3.573801 Test MSE 6.251400021208451 Test RE 1.1950792482291726\n",
      "48 Train Loss 3.4941766 Test MSE 6.23594152321285 Test RE 1.1936007342181516\n",
      "49 Train Loss 3.433789 Test MSE 6.333996834552533 Test RE 1.2029483513314168\n",
      "50 Train Loss 3.3502307 Test MSE 6.375761490134829 Test RE 1.206907792611927\n",
      "51 Train Loss 3.2870197 Test MSE 6.296676978584197 Test RE 1.1993992349931648\n",
      "52 Train Loss 3.1900687 Test MSE 6.346956489583441 Test RE 1.204178366900122\n",
      "53 Train Loss 3.1228437 Test MSE 6.3932516094745395 Test RE 1.2085620659521499\n",
      "54 Train Loss 3.0419617 Test MSE 6.432157114572932 Test RE 1.2122337813677202\n",
      "55 Train Loss 2.947468 Test MSE 6.41088563909399 Test RE 1.210227661575487\n",
      "56 Train Loss 2.8821943 Test MSE 6.417153245523655 Test RE 1.2108191069762668\n",
      "57 Train Loss 2.816073 Test MSE 6.475030168649966 Test RE 1.2162670976285601\n",
      "58 Train Loss 2.761351 Test MSE 6.462389928518639 Test RE 1.215079348833623\n",
      "59 Train Loss 2.7171693 Test MSE 6.450056407329827 Test RE 1.2139193009090086\n",
      "60 Train Loss 2.6512172 Test MSE 6.4896229841058135 Test RE 1.2176368806232554\n",
      "61 Train Loss 2.6031065 Test MSE 6.443793088388793 Test RE 1.2133297703741344\n",
      "62 Train Loss 2.5594826 Test MSE 6.4156053461244555 Test RE 1.2106730656451676\n",
      "63 Train Loss 2.5055008 Test MSE 6.4653240184687855 Test RE 1.2153551560481213\n",
      "64 Train Loss 2.4754374 Test MSE 6.435772166814779 Test RE 1.2125743881658533\n",
      "65 Train Loss 2.4380398 Test MSE 6.379264478100927 Test RE 1.2072392983410616\n",
      "66 Train Loss 2.3920014 Test MSE 6.378345774110116 Test RE 1.207152365474484\n",
      "67 Train Loss 2.3525221 Test MSE 6.324728970270191 Test RE 1.2020679559400025\n",
      "68 Train Loss 2.3067923 Test MSE 6.340556919713651 Test RE 1.2035711335660495\n",
      "69 Train Loss 2.280529 Test MSE 6.385323713948533 Test RE 1.2078125001175393\n",
      "70 Train Loss 2.255589 Test MSE 6.4016208857107815 Test RE 1.2093528592991472\n",
      "71 Train Loss 2.203659 Test MSE 6.354285120766022 Test RE 1.2048733797879296\n",
      "72 Train Loss 2.1780012 Test MSE 6.328183338552544 Test RE 1.2023961770083604\n",
      "73 Train Loss 2.157751 Test MSE 6.298347222846602 Test RE 1.1995582995972272\n",
      "74 Train Loss 2.1301134 Test MSE 6.239940457039107 Test RE 1.1939833841644392\n",
      "75 Train Loss 2.0912175 Test MSE 6.229825585282251 Test RE 1.193015275011031\n",
      "76 Train Loss 2.068316 Test MSE 6.230457666865331 Test RE 1.193075795473995\n",
      "77 Train Loss 2.0489817 Test MSE 6.229400732446294 Test RE 1.1929745945330827\n",
      "78 Train Loss 2.0239131 Test MSE 6.234516710316492 Test RE 1.1934643670900078\n",
      "79 Train Loss 1.9965019 Test MSE 6.184288622925924 Test RE 1.1886471004903174\n",
      "80 Train Loss 1.9821889 Test MSE 6.2000138037644295 Test RE 1.1901573650247588\n",
      "81 Train Loss 1.9627063 Test MSE 6.213182919649293 Test RE 1.1914206691777878\n",
      "82 Train Loss 1.9452047 Test MSE 6.195871654241237 Test RE 1.1897597341823998\n",
      "83 Train Loss 1.9233754 Test MSE 6.1853247080109846 Test RE 1.188746666344219\n",
      "84 Train Loss 1.9014637 Test MSE 6.18533670847522 Test RE 1.1887478195177066\n",
      "85 Train Loss 1.8744111 Test MSE 6.147471703426775 Test RE 1.185103632968315\n",
      "86 Train Loss 1.8456873 Test MSE 6.123333011214349 Test RE 1.1827746276115332\n",
      "87 Train Loss 1.8239598 Test MSE 6.139627953831938 Test RE 1.1843473364258807\n",
      "88 Train Loss 1.8079152 Test MSE 6.12809496439144 Test RE 1.1832344444127063\n",
      "89 Train Loss 1.7934686 Test MSE 6.1202232920163055 Test RE 1.1824742549177416\n",
      "90 Train Loss 1.7788635 Test MSE 6.10926599479781 Test RE 1.1814152636288484\n",
      "91 Train Loss 1.7683852 Test MSE 6.106713902371149 Test RE 1.1811684749069034\n",
      "92 Train Loss 1.7526139 Test MSE 6.109632257928286 Test RE 1.1814506772421995\n",
      "93 Train Loss 1.7388943 Test MSE 6.098667072507555 Test RE 1.1803900042717408\n",
      "94 Train Loss 1.723956 Test MSE 6.08197474091994 Test RE 1.1787735066074547\n",
      "95 Train Loss 1.7026738 Test MSE 6.082797550800323 Test RE 1.1788532400598004\n",
      "96 Train Loss 1.6842741 Test MSE 6.105510830930193 Test RE 1.1810521193614087\n",
      "97 Train Loss 1.6678177 Test MSE 6.093183476090875 Test RE 1.1798592130373222\n",
      "98 Train Loss 1.6488727 Test MSE 6.0874231980652596 Test RE 1.1793013827887002\n",
      "99 Train Loss 1.633136 Test MSE 6.072631517519909 Test RE 1.177867733587524\n",
      "Training time: 157.45\n",
      "9\n",
      "KG_rowdy_tune29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 61.755806 Test MSE 6.945417948541688 Test RE 1.2596713527014292\n",
      "1 Train Loss 52.173584 Test MSE 7.971135972380508 Test RE 1.349485333757424\n",
      "2 Train Loss 44.691135 Test MSE 8.896827990146374 Test RE 1.4256918183486107\n",
      "3 Train Loss 39.658752 Test MSE 8.92255532391881 Test RE 1.4277516969280555\n",
      "4 Train Loss 33.604992 Test MSE 8.891304943985954 Test RE 1.4252492232934857\n",
      "5 Train Loss 29.945812 Test MSE 8.99892060115629 Test RE 1.4338485130119052\n",
      "6 Train Loss 28.306713 Test MSE 9.018820338442278 Test RE 1.4354330059300273\n",
      "7 Train Loss 27.38053 Test MSE 9.110887159665925 Test RE 1.442741067748546\n",
      "8 Train Loss 26.80017 Test MSE 8.939538897660894 Test RE 1.4291098727809062\n",
      "9 Train Loss 25.751 Test MSE 9.211558242191211 Test RE 1.4506899803482887\n",
      "10 Train Loss 24.883436 Test MSE 9.205341498017365 Test RE 1.450200373140449\n",
      "11 Train Loss 24.44926 Test MSE 9.301772482580688 Test RE 1.4577764049139004\n",
      "12 Train Loss 23.659374 Test MSE 9.385327537010115 Test RE 1.4643091531173908\n",
      "13 Train Loss 23.152409 Test MSE 9.366490824537669 Test RE 1.4628389527325374\n",
      "14 Train Loss 22.36017 Test MSE 9.401031919782955 Test RE 1.4655337486154483\n",
      "15 Train Loss 21.812191 Test MSE 9.457872541898594 Test RE 1.4699575350037661\n",
      "16 Train Loss 20.658484 Test MSE 9.128786850246062 Test RE 1.4441576118576842\n",
      "17 Train Loss 19.109324 Test MSE 8.913078138646608 Test RE 1.4269932447911005\n",
      "18 Train Loss 18.148575 Test MSE 8.614412713248788 Test RE 1.4028812077526336\n",
      "19 Train Loss 17.055342 Test MSE 8.455753268965587 Test RE 1.3899021008608192\n",
      "20 Train Loss 15.987143 Test MSE 8.28905770620217 Test RE 1.3761337362756763\n",
      "21 Train Loss 15.447782 Test MSE 8.040721240703844 Test RE 1.3553628053626972\n",
      "22 Train Loss 14.980894 Test MSE 7.983629123011263 Test RE 1.3505424429875208\n",
      "23 Train Loss 14.3884945 Test MSE 7.9681915004641075 Test RE 1.34923606635721\n",
      "24 Train Loss 13.765352 Test MSE 7.901949227797678 Test RE 1.3436160336468415\n",
      "25 Train Loss 11.205864 Test MSE 6.814398507252926 Test RE 1.2477334672511098\n",
      "26 Train Loss 10.273285 Test MSE 6.799463287991638 Test RE 1.2463653791619733\n",
      "27 Train Loss 9.330324 Test MSE 6.529500910843479 Test RE 1.221372264698569\n",
      "28 Train Loss 8.831822 Test MSE 6.340898891348794 Test RE 1.2036035898348187\n",
      "29 Train Loss 8.5329895 Test MSE 6.306938932212185 Test RE 1.2003761922571647\n",
      "30 Train Loss 8.245 Test MSE 6.41724228415825 Test RE 1.2108275070644319\n",
      "31 Train Loss 8.084263 Test MSE 6.458862185644425 Test RE 1.2147476547771354\n",
      "32 Train Loss 7.896407 Test MSE 6.333652480092577 Test RE 1.2029156511050818\n",
      "33 Train Loss 7.7965255 Test MSE 6.2515404306743845 Test RE 1.1950926691825758\n",
      "34 Train Loss 7.6351876 Test MSE 6.276960625921271 Test RE 1.197519964459934\n",
      "35 Train Loss 7.4671674 Test MSE 6.293765918144513 Test RE 1.199121951648537\n",
      "36 Train Loss 7.2935896 Test MSE 6.446814829444073 Test RE 1.2136142253997773\n",
      "37 Train Loss 7.154102 Test MSE 6.343722171227713 Test RE 1.2038715117563321\n",
      "38 Train Loss 7.071134 Test MSE 6.310336336016781 Test RE 1.2006994563343163\n",
      "39 Train Loss 6.9076524 Test MSE 6.239615697054636 Test RE 1.193952313109086\n",
      "40 Train Loss 6.788003 Test MSE 6.157000044793732 Test RE 1.1860217095642398\n",
      "41 Train Loss 6.5846767 Test MSE 6.093967826182839 Test RE 1.1799351497710795\n",
      "42 Train Loss 6.3751516 Test MSE 5.990897772407651 Test RE 1.1699142065435542\n",
      "43 Train Loss 6.232748 Test MSE 6.008984676336609 Test RE 1.1716788985631577\n",
      "44 Train Loss 6.0549355 Test MSE 6.021047624120043 Test RE 1.1728543729440075\n",
      "45 Train Loss 5.7068834 Test MSE 5.640157003214644 Test RE 1.1351510547370733\n",
      "46 Train Loss 4.8292837 Test MSE 4.825270243618412 Test RE 1.0499506360697495\n",
      "47 Train Loss 4.2196293 Test MSE 4.915437978551413 Test RE 1.059715216953096\n",
      "48 Train Loss 3.93216 Test MSE 4.878913738417991 Test RE 1.0557707605613524\n",
      "49 Train Loss 3.6829412 Test MSE 4.896908845218566 Test RE 1.057715990832536\n",
      "50 Train Loss 3.467003 Test MSE 4.832348913278693 Test RE 1.0507204924256015\n",
      "51 Train Loss 3.2146091 Test MSE 4.9235334384169835 Test RE 1.0605875047037008\n",
      "52 Train Loss 3.073317 Test MSE 4.983039643661882 Test RE 1.0669774266494465\n",
      "53 Train Loss 3.0041885 Test MSE 5.031925605419748 Test RE 1.072198427888893\n",
      "54 Train Loss 2.8834565 Test MSE 5.08163377652072 Test RE 1.0774813005684052\n",
      "55 Train Loss 2.7485275 Test MSE 5.07389632393307 Test RE 1.0766606849169476\n",
      "56 Train Loss 2.7004027 Test MSE 5.0799552108902555 Test RE 1.0773033290203808\n",
      "57 Train Loss 2.605418 Test MSE 5.1772489084695685 Test RE 1.0875709104699638\n",
      "58 Train Loss 2.5506768 Test MSE 5.199017177447668 Test RE 1.0898549133459772\n",
      "59 Train Loss 2.4949539 Test MSE 5.23802656011545 Test RE 1.0939359843105338\n",
      "60 Train Loss 2.4762943 Test MSE 5.250715725472522 Test RE 1.0952602175699975\n",
      "61 Train Loss 2.4435825 Test MSE 5.202745354185318 Test RE 1.0902456067636128\n",
      "62 Train Loss 2.4034839 Test MSE 5.167930575320263 Test RE 1.086591730942217\n",
      "63 Train Loss 2.3422298 Test MSE 5.250531184450664 Test RE 1.095240970459101\n",
      "64 Train Loss 2.293513 Test MSE 5.251179676115564 Test RE 1.095308604826555\n",
      "65 Train Loss 2.2230406 Test MSE 5.2931896890227295 Test RE 1.0996811714336479\n",
      "66 Train Loss 2.2038157 Test MSE 5.303667191432876 Test RE 1.1007690047373826\n",
      "67 Train Loss 2.1860313 Test MSE 5.3327740798250245 Test RE 1.1037854196302772\n",
      "68 Train Loss 2.1464818 Test MSE 5.367041949742764 Test RE 1.1073261476973952\n",
      "69 Train Loss 2.1250987 Test MSE 5.368444751178348 Test RE 1.1074708509842186\n",
      "70 Train Loss 2.1065276 Test MSE 5.3739309013867045 Test RE 1.108036582799746\n",
      "71 Train Loss 2.088336 Test MSE 5.386145267192327 Test RE 1.1092950919630815\n",
      "72 Train Loss 2.0514007 Test MSE 5.414449978196259 Test RE 1.1122059988577238\n",
      "73 Train Loss 2.0270076 Test MSE 5.461039952930185 Test RE 1.116980875083986\n",
      "74 Train Loss 2.0133708 Test MSE 5.463705719538205 Test RE 1.117253464834131\n",
      "75 Train Loss 2.002395 Test MSE 5.449176126882218 Test RE 1.1157669239058934\n",
      "76 Train Loss 1.9878349 Test MSE 5.441365951927812 Test RE 1.1149670360482458\n",
      "77 Train Loss 1.9303364 Test MSE 5.442919837497493 Test RE 1.1151262247089269\n",
      "78 Train Loss 1.9077097 Test MSE 5.4288815421665415 Test RE 1.1136872380324236\n",
      "79 Train Loss 1.8974826 Test MSE 5.41153187670122 Test RE 1.1119062484295956\n",
      "80 Train Loss 1.8749608 Test MSE 5.3963510902734955 Test RE 1.110345556720359\n",
      "81 Train Loss 1.8500905 Test MSE 5.373324778113386 Test RE 1.107974093561284\n",
      "82 Train Loss 1.8295811 Test MSE 5.351875761340675 Test RE 1.1057604996186263\n",
      "83 Train Loss 1.8123131 Test MSE 5.3781563989742205 Test RE 1.1084721192808653\n",
      "84 Train Loss 1.802017 Test MSE 5.401013366615682 Test RE 1.1108251048522877\n",
      "85 Train Loss 1.7805759 Test MSE 5.443133128898118 Test RE 1.1151480736899306\n",
      "86 Train Loss 1.7661127 Test MSE 5.441604388128223 Test RE 1.114991464251913\n",
      "87 Train Loss 1.7419989 Test MSE 5.451543854750383 Test RE 1.1160093041726085\n",
      "88 Train Loss 1.7289294 Test MSE 5.461699024610153 Test RE 1.117048275090041\n",
      "89 Train Loss 1.7142236 Test MSE 5.442393136113009 Test RE 1.1150722690423391\n",
      "90 Train Loss 1.6993313 Test MSE 5.429808799792458 Test RE 1.1137823433395346\n",
      "91 Train Loss 1.6731895 Test MSE 5.465200880739806 Test RE 1.117406324436355\n",
      "92 Train Loss 1.6444787 Test MSE 5.451014584134738 Test RE 1.1159551282103084\n",
      "93 Train Loss 1.6337605 Test MSE 5.439894294405169 Test RE 1.114816250326373\n",
      "94 Train Loss 1.625044 Test MSE 5.437101740868123 Test RE 1.114530069792981\n",
      "95 Train Loss 1.6069179 Test MSE 5.417905642513787 Test RE 1.1125608638532556\n",
      "96 Train Loss 1.5913944 Test MSE 5.392462356323643 Test RE 1.1099454144247665\n",
      "97 Train Loss 1.5843253 Test MSE 5.390552245283251 Test RE 1.1097488152989936\n",
      "98 Train Loss 1.5705613 Test MSE 5.403002682083603 Test RE 1.1110296570328302\n",
      "99 Train Loss 1.5606593 Test MSE 5.411489691090417 Test RE 1.111901914487125\n",
      "Training time: 157.96\n",
      "0\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.97435 Test MSE 7.905224715271922 Test RE 1.3438944802291115\n",
      "1 Train Loss 43.206806 Test MSE 8.055238918077874 Test RE 1.3565858204181154\n",
      "2 Train Loss 29.77797 Test MSE 6.4113141851381386 Test RE 1.2102681107145816\n",
      "3 Train Loss 22.007679 Test MSE 5.713891300827221 Test RE 1.142546929197539\n",
      "4 Train Loss 18.374956 Test MSE 5.596210804932956 Test RE 1.1307200498368704\n",
      "5 Train Loss 15.648131 Test MSE 5.828181813458923 Test RE 1.1539170912812136\n",
      "6 Train Loss 13.446831 Test MSE 5.9733007337316355 Test RE 1.1681947509534423\n",
      "7 Train Loss 12.203429 Test MSE 5.756353142981458 Test RE 1.146784395926661\n",
      "8 Train Loss 10.629465 Test MSE 5.815560660099237 Test RE 1.1526669880596947\n",
      "9 Train Loss 9.63777 Test MSE 5.655584070728439 Test RE 1.136702438277654\n",
      "10 Train Loss 8.768908 Test MSE 5.57029761137589 Test RE 1.1280991187924785\n",
      "11 Train Loss 8.000255 Test MSE 5.571782184399411 Test RE 1.1282494369679805\n",
      "12 Train Loss 7.307957 Test MSE 5.480621830224479 Test RE 1.1189816854005978\n",
      "13 Train Loss 6.6176963 Test MSE 5.457879420041434 Test RE 1.1166576064623746\n",
      "14 Train Loss 6.095675 Test MSE 5.455076766003182 Test RE 1.116370864434917\n",
      "15 Train Loss 5.554305 Test MSE 5.213972876542724 Test RE 1.091421347581299\n",
      "16 Train Loss 4.972564 Test MSE 5.00875669412162 Test RE 1.069727174001134\n",
      "17 Train Loss 4.4544897 Test MSE 4.755422588037162 Test RE 1.042323713744948\n",
      "18 Train Loss 3.9045935 Test MSE 4.670425294829018 Test RE 1.0329665902976808\n",
      "19 Train Loss 3.531665 Test MSE 4.500366124023653 Test RE 1.0139860582828137\n",
      "20 Train Loss 3.1265728 Test MSE 4.286806097470591 Test RE 0.9896348490700094\n",
      "21 Train Loss 2.8637125 Test MSE 4.1318055542958865 Test RE 0.9715787283600037\n",
      "22 Train Loss 2.651663 Test MSE 4.0168875814494855 Test RE 0.957972184223264\n",
      "23 Train Loss 2.467272 Test MSE 3.9103241772683694 Test RE 0.9451798225671946\n",
      "24 Train Loss 2.2539263 Test MSE 3.702774306390022 Test RE 0.9197539910548623\n",
      "25 Train Loss 2.0992796 Test MSE 3.4675644280821034 Test RE 0.8900621434982505\n",
      "26 Train Loss 1.9760863 Test MSE 3.3465298557310876 Test RE 0.874390463220417\n",
      "27 Train Loss 1.8701757 Test MSE 3.2492253068817196 Test RE 0.8615846914109104\n",
      "28 Train Loss 1.7844157 Test MSE 3.1263990186262887 Test RE 0.8451431253544732\n",
      "29 Train Loss 1.667829 Test MSE 2.9125763745075517 Test RE 0.8157305388454217\n",
      "30 Train Loss 1.5423644 Test MSE 2.8188243703934095 Test RE 0.8024945082640899\n",
      "31 Train Loss 1.4713101 Test MSE 2.6885742943460764 Test RE 0.7837347101323641\n",
      "32 Train Loss 1.4135451 Test MSE 2.655955781845646 Test RE 0.7789659610257116\n",
      "33 Train Loss 1.3391109 Test MSE 2.409211639663736 Test RE 0.7419002828201151\n",
      "34 Train Loss 1.2704211 Test MSE 2.202827537545623 Test RE 0.7094116378383064\n",
      "35 Train Loss 1.1812376 Test MSE 1.9380800645935394 Test RE 0.6654170390303369\n",
      "36 Train Loss 1.0685861 Test MSE 1.6485119554842345 Test RE 0.6136971562284106\n",
      "37 Train Loss 0.8729839 Test MSE 1.3817809950705386 Test RE 0.5618594216905822\n",
      "38 Train Loss 0.7118335 Test MSE 1.3158848957917857 Test RE 0.5482984412813858\n",
      "39 Train Loss 0.5605375 Test MSE 1.3635503661908945 Test RE 0.5581406482462858\n",
      "40 Train Loss 0.4406245 Test MSE 1.1646355634099366 Test RE 0.5158258281384676\n",
      "41 Train Loss 0.38472867 Test MSE 1.1324639192143435 Test RE 0.5086514036905483\n",
      "42 Train Loss 0.33458185 Test MSE 1.0476235557275129 Test RE 0.48922730460154074\n",
      "43 Train Loss 0.30221957 Test MSE 0.9830035586457918 Test RE 0.4738987959867412\n",
      "44 Train Loss 0.26331866 Test MSE 0.8701598053516978 Test RE 0.4458692990896653\n",
      "45 Train Loss 0.22800697 Test MSE 0.7938059775000057 Test RE 0.4258584241830899\n",
      "46 Train Loss 0.20249908 Test MSE 0.6847269170480835 Test RE 0.395518462258364\n",
      "47 Train Loss 0.15856498 Test MSE 0.5560249286365737 Test RE 0.35641435858382897\n",
      "48 Train Loss 0.12635534 Test MSE 0.5349293900356986 Test RE 0.3495878176478448\n",
      "49 Train Loss 0.1114773 Test MSE 0.507943148252057 Test RE 0.34065566340460346\n",
      "50 Train Loss 0.09293897 Test MSE 0.5184545952101861 Test RE 0.34416240217682603\n",
      "51 Train Loss 0.08072635 Test MSE 0.5013229338815051 Test RE 0.33842843574352194\n",
      "52 Train Loss 0.06641232 Test MSE 0.49844581127305787 Test RE 0.3374559077659353\n",
      "53 Train Loss 0.057864938 Test MSE 0.49936990234230827 Test RE 0.33776857524539494\n",
      "54 Train Loss 0.050535552 Test MSE 0.49268855611647555 Test RE 0.33550136983109463\n",
      "55 Train Loss 0.04319352 Test MSE 0.47294057208270446 Test RE 0.32870881176889044\n",
      "56 Train Loss 0.03841489 Test MSE 0.45999645297945224 Test RE 0.3241793160920189\n",
      "57 Train Loss 0.033909712 Test MSE 0.4493421555018211 Test RE 0.3204030506139569\n",
      "58 Train Loss 0.031495966 Test MSE 0.44822165714589257 Test RE 0.32000331604888416\n",
      "59 Train Loss 0.027711583 Test MSE 0.44925522542364 Test RE 0.3203720564048359\n",
      "60 Train Loss 0.02498303 Test MSE 0.4502601310791571 Test RE 0.3207301644926528\n",
      "61 Train Loss 0.023309397 Test MSE 0.44154606636858784 Test RE 0.3176113913657674\n",
      "62 Train Loss 0.0217206 Test MSE 0.43993894177509535 Test RE 0.3170328487900866\n",
      "63 Train Loss 0.020242404 Test MSE 0.4321412232437537 Test RE 0.31421065551177046\n",
      "64 Train Loss 0.018393923 Test MSE 0.4088001284673356 Test RE 0.3056071931253604\n",
      "65 Train Loss 0.017171424 Test MSE 0.3956851367261471 Test RE 0.30066503694278984\n",
      "66 Train Loss 0.015420377 Test MSE 0.370693925516958 Test RE 0.2910152816076328\n",
      "67 Train Loss 0.014418272 Test MSE 0.3607230325433304 Test RE 0.28707475110391684\n",
      "68 Train Loss 0.013639666 Test MSE 0.35185154048487516 Test RE 0.2835226690878532\n",
      "69 Train Loss 0.012703582 Test MSE 0.34240627096373594 Test RE 0.2796912727589897\n",
      "70 Train Loss 0.011604663 Test MSE 0.3181256426366875 Test RE 0.2695922471726148\n",
      "71 Train Loss 0.010462007 Test MSE 0.3014175844607811 Test RE 0.26241723358995694\n",
      "72 Train Loss 0.0097422255 Test MSE 0.29216981864537894 Test RE 0.25836027359184577\n",
      "73 Train Loss 0.009247191 Test MSE 0.2828861231650156 Test RE 0.2542224397102258\n",
      "74 Train Loss 0.008751853 Test MSE 0.26572117799445655 Test RE 0.24638890350265835\n",
      "75 Train Loss 0.008271776 Test MSE 0.25404577482512386 Test RE 0.24091511498597465\n",
      "76 Train Loss 0.0078683 Test MSE 0.2511793700574277 Test RE 0.23955213383826066\n",
      "77 Train Loss 0.0072876774 Test MSE 0.24489409116368055 Test RE 0.23653598107621682\n",
      "78 Train Loss 0.006535151 Test MSE 0.24282313265139874 Test RE 0.23553371877911536\n",
      "79 Train Loss 0.0062172934 Test MSE 0.23491485513535532 Test RE 0.2316665337408765\n",
      "80 Train Loss 0.0058776857 Test MSE 0.2270871776431187 Test RE 0.22777411433862096\n",
      "81 Train Loss 0.0053889174 Test MSE 0.21573883096171823 Test RE 0.22200983845497224\n",
      "82 Train Loss 0.0049205422 Test MSE 0.19974170991773824 Test RE 0.21362026130945316\n",
      "83 Train Loss 0.0046169236 Test MSE 0.1936464906247624 Test RE 0.21033564407925348\n",
      "84 Train Loss 0.00441402 Test MSE 0.18638873131426636 Test RE 0.20635637322008235\n",
      "85 Train Loss 0.0042478787 Test MSE 0.18721248573970717 Test RE 0.20681187171465576\n",
      "86 Train Loss 0.004070708 Test MSE 0.18311590651833973 Test RE 0.20453662991005306\n",
      "87 Train Loss 0.0038227504 Test MSE 0.17479843930224662 Test RE 0.19983742990071354\n",
      "88 Train Loss 0.003622683 Test MSE 0.17300780183290246 Test RE 0.19881122641880894\n",
      "89 Train Loss 0.0034916427 Test MSE 0.16991726922705855 Test RE 0.19702748793178\n",
      "90 Train Loss 0.003409151 Test MSE 0.16522946544827882 Test RE 0.19429060883433252\n",
      "91 Train Loss 0.0032493963 Test MSE 0.15602027064716179 Test RE 0.18879851488101212\n",
      "92 Train Loss 0.0031138419 Test MSE 0.1550417465229428 Test RE 0.18820553269774887\n",
      "93 Train Loss 0.0029808534 Test MSE 0.1540139798077214 Test RE 0.18758069127282276\n",
      "94 Train Loss 0.002810269 Test MSE 0.1502495579552936 Test RE 0.1852740784434375\n",
      "95 Train Loss 0.0026017404 Test MSE 0.1411511826757031 Test RE 0.17957683831098217\n",
      "96 Train Loss 0.0025006586 Test MSE 0.1364713207785412 Test RE 0.17657481407437822\n",
      "97 Train Loss 0.002379751 Test MSE 0.1372794321627237 Test RE 0.17709683402258036\n",
      "98 Train Loss 0.0022685798 Test MSE 0.13928667661914587 Test RE 0.1783868548128663\n",
      "99 Train Loss 0.0021082717 Test MSE 0.12871958684021162 Test RE 0.17148667462688064\n",
      "Training time: 156.32\n",
      "1\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.51821 Test MSE 8.488338277039928 Test RE 1.3925775823561313\n",
      "1 Train Loss 47.033928 Test MSE 9.25919573835275 Test RE 1.4544362586632174\n",
      "2 Train Loss 41.93288 Test MSE 8.393516923721236 Test RE 1.3847776499512667\n",
      "3 Train Loss 39.71871 Test MSE 8.887829578318897 Test RE 1.4249706507798434\n",
      "4 Train Loss 37.47245 Test MSE 9.043610227249467 Test RE 1.4374044281544605\n",
      "5 Train Loss 35.948303 Test MSE 8.972823563069522 Test RE 1.4317679097141458\n",
      "6 Train Loss 34.1511 Test MSE 8.822484745945193 Test RE 1.419722673875112\n",
      "7 Train Loss 33.05847 Test MSE 8.89351547791289 Test RE 1.4254263832258816\n",
      "8 Train Loss 31.59145 Test MSE 8.854622778916823 Test RE 1.42230616475078\n",
      "9 Train Loss 30.195385 Test MSE 8.761731667593995 Test RE 1.4148260077966832\n",
      "10 Train Loss 29.034609 Test MSE 8.753458387678311 Test RE 1.414157874114901\n",
      "11 Train Loss 27.743818 Test MSE 8.770923210674395 Test RE 1.415567928794127\n",
      "12 Train Loss 26.44519 Test MSE 8.863179968635233 Test RE 1.422993263732013\n",
      "13 Train Loss 25.048977 Test MSE 8.988949391987436 Test RE 1.4330539084834548\n",
      "14 Train Loss 23.597923 Test MSE 8.9574648609023 Test RE 1.4305420127114528\n",
      "15 Train Loss 22.162573 Test MSE 8.852817888631005 Test RE 1.4221611988118128\n",
      "16 Train Loss 20.668947 Test MSE 8.855390616179692 Test RE 1.4223678317480748\n",
      "17 Train Loss 19.03147 Test MSE 8.820775546040004 Test RE 1.4195851441729916\n",
      "18 Train Loss 17.323643 Test MSE 8.571813915317314 Test RE 1.3994082422216663\n",
      "19 Train Loss 15.4089775 Test MSE 8.193708132439749 Test RE 1.3681959648180422\n",
      "20 Train Loss 13.732887 Test MSE 7.882905841516273 Test RE 1.3419960261699904\n",
      "21 Train Loss 12.22147 Test MSE 7.6434722236288355 Test RE 1.3214581267383887\n",
      "22 Train Loss 10.428269 Test MSE 7.404170231205787 Test RE 1.3006075114173643\n",
      "23 Train Loss 9.061027 Test MSE 7.1428347229507105 Test RE 1.2774483828388126\n",
      "24 Train Loss 7.5196967 Test MSE 6.981342434879009 Test RE 1.2629249135928096\n",
      "25 Train Loss 6.51967 Test MSE 6.708452204182134 Test RE 1.2379959537057137\n",
      "26 Train Loss 5.5988445 Test MSE 6.658660294223046 Test RE 1.2333930297528874\n",
      "27 Train Loss 4.71588 Test MSE 6.496804957160743 Test RE 1.2183104649844134\n",
      "28 Train Loss 3.9837518 Test MSE 6.367636642150712 Test RE 1.2061385458040046\n",
      "29 Train Loss 3.3512816 Test MSE 6.14051001828537 Test RE 1.1844324094282879\n",
      "30 Train Loss 2.9617753 Test MSE 5.8664278709685895 Test RE 1.1576970534306068\n",
      "31 Train Loss 2.6878262 Test MSE 5.662636302518863 Test RE 1.137410923161774\n",
      "32 Train Loss 2.4400067 Test MSE 5.648380093712307 Test RE 1.1359782524572954\n",
      "33 Train Loss 2.2091556 Test MSE 5.536568836747755 Test RE 1.1246785498226135\n",
      "34 Train Loss 2.057005 Test MSE 5.547942372038787 Test RE 1.1258331465592983\n",
      "35 Train Loss 1.8956357 Test MSE 5.644270803846019 Test RE 1.1355649557973615\n",
      "36 Train Loss 1.7818094 Test MSE 5.70682711479137 Test RE 1.1418404351629245\n",
      "37 Train Loss 1.676244 Test MSE 5.695887409647723 Test RE 1.1407454843677773\n",
      "38 Train Loss 1.5979859 Test MSE 5.716721942095261 Test RE 1.1428299009826146\n",
      "39 Train Loss 1.5300083 Test MSE 5.662652660862389 Test RE 1.1374125660489536\n",
      "40 Train Loss 1.4779327 Test MSE 5.628515536775445 Test RE 1.1339789553698554\n",
      "41 Train Loss 1.4202976 Test MSE 5.6715336845028155 Test RE 1.138304147341906\n",
      "42 Train Loss 1.3688114 Test MSE 5.681120179049834 Test RE 1.139265768991699\n",
      "43 Train Loss 1.323014 Test MSE 5.683924733113945 Test RE 1.139546940495746\n",
      "44 Train Loss 1.2748739 Test MSE 5.688691932726362 Test RE 1.140024718562405\n",
      "45 Train Loss 1.2395918 Test MSE 5.714662884775917 Test RE 1.1426240693692484\n",
      "46 Train Loss 1.2078032 Test MSE 5.720561404926469 Test RE 1.143213610079968\n",
      "47 Train Loss 1.1811831 Test MSE 5.730120836038319 Test RE 1.1441684036082522\n",
      "48 Train Loss 1.15588 Test MSE 5.737094182336463 Test RE 1.1448643973547312\n",
      "49 Train Loss 1.1304474 Test MSE 5.755110200832849 Test RE 1.1466605793731752\n",
      "50 Train Loss 1.1123434 Test MSE 5.781937106628873 Test RE 1.149329997489095\n",
      "51 Train Loss 1.0954782 Test MSE 5.798122970541627 Test RE 1.1509375813846485\n",
      "52 Train Loss 1.0800354 Test MSE 5.798543506108622 Test RE 1.1509793191517566\n",
      "53 Train Loss 1.0499989 Test MSE 5.802753800107856 Test RE 1.1513971035468882\n",
      "54 Train Loss 1.0250273 Test MSE 5.8182538188599775 Test RE 1.152933854494702\n",
      "55 Train Loss 1.0016412 Test MSE 5.889086333642082 Test RE 1.1599306405138567\n",
      "56 Train Loss 0.977306 Test MSE 5.885711039585635 Test RE 1.15959818927136\n",
      "57 Train Loss 0.9392119 Test MSE 5.916367018065385 Test RE 1.1626141756093509\n",
      "58 Train Loss 0.91180557 Test MSE 5.99644919188377 Test RE 1.170456127044668\n",
      "59 Train Loss 0.8820177 Test MSE 6.056619809932844 Test RE 1.1763138667083937\n",
      "60 Train Loss 0.85761327 Test MSE 6.10891562779417 Test RE 1.1813813860025337\n",
      "61 Train Loss 0.839294 Test MSE 6.135363277948473 Test RE 1.1839359324315324\n",
      "62 Train Loss 0.81775296 Test MSE 6.186670528068102 Test RE 1.188875984703968\n",
      "63 Train Loss 0.8010298 Test MSE 6.211446185428936 Test RE 1.191254142158508\n",
      "64 Train Loss 0.7897283 Test MSE 6.218140111709246 Test RE 1.1918958622938394\n",
      "65 Train Loss 0.78012025 Test MSE 6.231974050077863 Test RE 1.1932209734158303\n",
      "66 Train Loss 0.7679299 Test MSE 6.22486214651927 Test RE 1.192539929586929\n",
      "67 Train Loss 0.75779974 Test MSE 6.2425122068690895 Test RE 1.1942294049611903\n",
      "68 Train Loss 0.7441169 Test MSE 6.301870531099981 Test RE 1.1998937703649561\n",
      "69 Train Loss 0.7329594 Test MSE 6.324312496775055 Test RE 1.2020283781425158\n",
      "70 Train Loss 0.7253858 Test MSE 6.336867989052024 Test RE 1.203220964292014\n",
      "71 Train Loss 0.71636593 Test MSE 6.360347208471233 Test RE 1.2054479768314614\n",
      "72 Train Loss 0.70879924 Test MSE 6.353592223740489 Test RE 1.2048076858565655\n",
      "73 Train Loss 0.69962204 Test MSE 6.402883491275165 Test RE 1.2094721150621741\n",
      "74 Train Loss 0.6924824 Test MSE 6.425171427938787 Test RE 1.2115753252944494\n",
      "75 Train Loss 0.685388 Test MSE 6.423662681806059 Test RE 1.2114330670738618\n",
      "76 Train Loss 0.6790585 Test MSE 6.457962510049898 Test RE 1.2146630487856\n",
      "77 Train Loss 0.67302257 Test MSE 6.485960886924312 Test RE 1.2172932756214099\n",
      "78 Train Loss 0.66520196 Test MSE 6.508672040362958 Test RE 1.2194226420938543\n",
      "79 Train Loss 0.6594196 Test MSE 6.524814976055077 Test RE 1.2209339235400125\n",
      "80 Train Loss 0.6549956 Test MSE 6.538530069888007 Test RE 1.2222164451939628\n",
      "81 Train Loss 0.6508033 Test MSE 6.555921450793958 Test RE 1.2238408099921214\n",
      "82 Train Loss 0.6459768 Test MSE 6.574763640307862 Test RE 1.225598251376015\n",
      "83 Train Loss 0.6403668 Test MSE 6.589403869501909 Test RE 1.226962031338812\n",
      "84 Train Loss 0.63649833 Test MSE 6.5914854618152 Test RE 1.2271558146544737\n",
      "85 Train Loss 0.632976 Test MSE 6.606146923588455 Test RE 1.2285198398369015\n",
      "86 Train Loss 0.63005835 Test MSE 6.621836576067984 Test RE 1.2299778469433758\n",
      "87 Train Loss 0.6267888 Test MSE 6.6361468930201015 Test RE 1.2313061697886072\n",
      "88 Train Loss 0.62249655 Test MSE 6.648195307371566 Test RE 1.2324234265064313\n",
      "89 Train Loss 0.61893725 Test MSE 6.661526725060286 Test RE 1.2336584777000388\n",
      "90 Train Loss 0.6144046 Test MSE 6.695187484335372 Test RE 1.2367713943935101\n",
      "91 Train Loss 0.6108748 Test MSE 6.704001794096417 Test RE 1.2375852402069734\n",
      "92 Train Loss 0.60724807 Test MSE 6.726207985218789 Test RE 1.2396332210316878\n",
      "93 Train Loss 0.60187596 Test MSE 6.742423642392661 Test RE 1.241126585994482\n",
      "94 Train Loss 0.59765196 Test MSE 6.753916773452866 Test RE 1.242183947387211\n",
      "95 Train Loss 0.59443235 Test MSE 6.756574367361023 Test RE 1.2424283163894694\n",
      "96 Train Loss 0.5900397 Test MSE 6.770799712541655 Test RE 1.2437355379008868\n",
      "97 Train Loss 0.58746964 Test MSE 6.778164695725518 Test RE 1.2444117949219669\n",
      "98 Train Loss 0.5849874 Test MSE 6.784147392459964 Test RE 1.244960859206742\n",
      "99 Train Loss 0.5810241 Test MSE 6.804874886958437 Test RE 1.2468612630146467\n",
      "Training time: 150.75\n",
      "2\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.276543 Test MSE 8.47791421411214 Test RE 1.3917222455818379\n",
      "1 Train Loss 43.9255 Test MSE 7.160186722944413 Test RE 1.2789990864072835\n",
      "2 Train Loss 35.48126 Test MSE 7.03578718300722 Test RE 1.2678398774644304\n",
      "3 Train Loss 28.48239 Test MSE 6.33427015072514 Test RE 1.2029743050618233\n",
      "4 Train Loss 23.25725 Test MSE 6.040364028002079 Test RE 1.1747342108775165\n",
      "5 Train Loss 19.706018 Test MSE 6.156248862675122 Test RE 1.1859493573253486\n",
      "6 Train Loss 15.961046 Test MSE 5.9122446564619215 Test RE 1.1622090662600109\n",
      "7 Train Loss 13.632026 Test MSE 5.910017602228175 Test RE 1.1619901522466727\n",
      "8 Train Loss 11.979794 Test MSE 5.898580640565946 Test RE 1.1608652763652243\n",
      "9 Train Loss 10.864939 Test MSE 5.766091175688247 Test RE 1.1477539946188327\n",
      "10 Train Loss 9.98147 Test MSE 5.681384022054477 Test RE 1.1392922236172136\n",
      "11 Train Loss 9.301251 Test MSE 5.609325626908841 Test RE 1.1320442060132343\n",
      "12 Train Loss 8.679048 Test MSE 5.717478391204052 Test RE 1.1429055093533604\n",
      "13 Train Loss 8.02335 Test MSE 5.638735213166799 Test RE 1.135007969340992\n",
      "14 Train Loss 7.6530647 Test MSE 5.658153613917898 Test RE 1.136960632152036\n",
      "15 Train Loss 7.1539583 Test MSE 5.541203885669362 Test RE 1.125149224863462\n",
      "16 Train Loss 6.68573 Test MSE 5.379149322876065 Test RE 1.1085744385130383\n",
      "17 Train Loss 6.3696175 Test MSE 5.302163143668554 Test RE 1.1006129121231079\n",
      "18 Train Loss 6.1391163 Test MSE 5.147873897807949 Test RE 1.0844811563369674\n",
      "19 Train Loss 5.9218655 Test MSE 5.072276570993072 Test RE 1.0764888186232737\n",
      "20 Train Loss 5.7664 Test MSE 5.017702898554844 Test RE 1.0706820744992627\n",
      "21 Train Loss 5.5395627 Test MSE 4.852155219360276 Test RE 1.052871579949168\n",
      "22 Train Loss 5.399416 Test MSE 4.797030983026598 Test RE 1.0468737786130158\n",
      "23 Train Loss 5.2268095 Test MSE 4.522208104383825 Test RE 1.016443709001542\n",
      "24 Train Loss 5.08502 Test MSE 4.322718709463552 Test RE 0.993771524144614\n",
      "25 Train Loss 4.866723 Test MSE 3.9480290383571677 Test RE 0.9497257854409585\n",
      "26 Train Loss 4.6033278 Test MSE 3.6100215902934334 Test RE 0.9081612347582361\n",
      "27 Train Loss 4.198499 Test MSE 3.0259583247701785 Test RE 0.8314564974401673\n",
      "28 Train Loss 3.7328625 Test MSE 2.807070643821456 Test RE 0.8008196692413649\n",
      "29 Train Loss 3.4666517 Test MSE 2.7786286549669175 Test RE 0.7967522807465506\n",
      "30 Train Loss 3.101346 Test MSE 2.5975204294880574 Test RE 0.7703490410146592\n",
      "31 Train Loss 2.604305 Test MSE 2.3544069144021376 Test RE 0.7334133695472729\n",
      "32 Train Loss 2.3003838 Test MSE 2.2082369217319884 Test RE 0.7102821388277132\n",
      "33 Train Loss 1.9893397 Test MSE 2.106297489457684 Test RE 0.6936939635535431\n",
      "34 Train Loss 1.7503468 Test MSE 2.0128388273511333 Test RE 0.6781293804964736\n",
      "35 Train Loss 1.516644 Test MSE 1.8630258881113515 Test RE 0.6524053370623183\n",
      "36 Train Loss 1.389795 Test MSE 1.7381779359792595 Test RE 0.6301663034728356\n",
      "37 Train Loss 1.2513392 Test MSE 1.3972071737121037 Test RE 0.5649870111636358\n",
      "38 Train Loss 1.0758514 Test MSE 1.1433403900411767 Test RE 0.5110881754003569\n",
      "39 Train Loss 0.8868015 Test MSE 0.8680850360409906 Test RE 0.4453374266575943\n",
      "40 Train Loss 0.67916375 Test MSE 0.6208476599470614 Test RE 0.3766175766357561\n",
      "41 Train Loss 0.4967972 Test MSE 0.3650744824891274 Test RE 0.28880107096707536\n",
      "42 Train Loss 0.32115558 Test MSE 0.251889530677365 Test RE 0.23989053825400375\n",
      "43 Train Loss 0.24166873 Test MSE 0.21166284234524924 Test RE 0.21990260402657577\n",
      "44 Train Loss 0.18490413 Test MSE 0.18980042440279377 Test RE 0.2082364013489906\n",
      "45 Train Loss 0.15437514 Test MSE 0.13614722083084813 Test RE 0.17636501942629892\n",
      "46 Train Loss 0.12781462 Test MSE 0.12438288918549578 Test RE 0.16857314157009792\n",
      "47 Train Loss 0.10173178 Test MSE 0.10625611368783826 Test RE 0.15580630349805483\n",
      "48 Train Loss 0.08034073 Test MSE 0.09301306651872855 Test RE 0.14577399018969725\n",
      "49 Train Loss 0.069695234 Test MSE 0.10140885672745739 Test RE 0.15221098750562154\n",
      "50 Train Loss 0.06315427 Test MSE 0.09075663600886266 Test RE 0.14399494797090945\n",
      "51 Train Loss 0.055756014 Test MSE 0.0791383929038033 Test RE 0.13446265231560195\n",
      "52 Train Loss 0.049905516 Test MSE 0.07766373277427067 Test RE 0.1332039766685848\n",
      "53 Train Loss 0.043543667 Test MSE 0.07187453639507796 Test RE 0.12814320692519102\n",
      "54 Train Loss 0.040178146 Test MSE 0.06197090007964511 Test RE 0.11898767053714586\n",
      "55 Train Loss 0.036572892 Test MSE 0.06364857613442156 Test RE 0.1205875319458786\n",
      "56 Train Loss 0.034828927 Test MSE 0.06542732015556299 Test RE 0.12226091070157635\n",
      "57 Train Loss 0.032512646 Test MSE 0.06239363681483997 Test RE 0.11939282012385458\n",
      "58 Train Loss 0.02965105 Test MSE 0.057501134524321665 Test RE 0.11461626898106227\n",
      "59 Train Loss 0.026041372 Test MSE 0.051365829734503064 Test RE 0.1083291197481908\n",
      "60 Train Loss 0.024764905 Test MSE 0.04868229985849338 Test RE 0.10546141736743717\n",
      "61 Train Loss 0.022998083 Test MSE 0.048292602402008604 Test RE 0.10503846463497282\n",
      "62 Train Loss 0.02145324 Test MSE 0.041442425316813074 Test RE 0.09730398841622888\n",
      "63 Train Loss 0.01989434 Test MSE 0.0375361994675149 Test RE 0.09260473844004548\n",
      "64 Train Loss 0.01875 Test MSE 0.03603406074134053 Test RE 0.09073287313844997\n",
      "65 Train Loss 0.017524976 Test MSE 0.03345659734085217 Test RE 0.0874276781950075\n",
      "66 Train Loss 0.016605021 Test MSE 0.032879694471400205 Test RE 0.08667062870361025\n",
      "67 Train Loss 0.015211258 Test MSE 0.027343224155381703 Test RE 0.07903745028657018\n",
      "68 Train Loss 0.013604419 Test MSE 0.02259697330836815 Test RE 0.07185106281899889\n",
      "69 Train Loss 0.012843663 Test MSE 0.019744778312609047 Test RE 0.06716363476567946\n",
      "70 Train Loss 0.012409255 Test MSE 0.02074856210883635 Test RE 0.06884970168326617\n",
      "71 Train Loss 0.010942448 Test MSE 0.01593391966321702 Test RE 0.06033500761313321\n",
      "72 Train Loss 0.009977622 Test MSE 0.01350500860859868 Test RE 0.05554634573082241\n",
      "73 Train Loss 0.009208167 Test MSE 0.012349170172722596 Test RE 0.05311619393702841\n",
      "74 Train Loss 0.008877397 Test MSE 0.011604388239039948 Test RE 0.05148956056673644\n",
      "75 Train Loss 0.008252265 Test MSE 0.00954612045775494 Test RE 0.04670049838812897\n",
      "76 Train Loss 0.0078070825 Test MSE 0.009773495284042762 Test RE 0.04725339473489501\n",
      "77 Train Loss 0.007067768 Test MSE 0.009194795580822495 Test RE 0.04583308596435614\n",
      "78 Train Loss 0.006467291 Test MSE 0.007872921491000665 Test RE 0.042410756634326884\n",
      "79 Train Loss 0.006009607 Test MSE 0.007963119618937826 Test RE 0.0426530095636358\n",
      "80 Train Loss 0.0056401505 Test MSE 0.007413438296673589 Test RE 0.04115455393989744\n",
      "81 Train Loss 0.0052172304 Test MSE 0.0073230390227829135 Test RE 0.04090286553554033\n",
      "82 Train Loss 0.0049012685 Test MSE 0.007013254234459986 Test RE 0.04002836502978937\n",
      "83 Train Loss 0.0044403044 Test MSE 0.006691612078164872 Test RE 0.03909970119462383\n",
      "84 Train Loss 0.0041177156 Test MSE 0.005981029966042634 Test RE 0.03696545442374275\n",
      "85 Train Loss 0.0038788307 Test MSE 0.006178936665481393 Test RE 0.03757205350469847\n",
      "86 Train Loss 0.0036606425 Test MSE 0.006346316784460457 Test RE 0.03807754443600852\n",
      "87 Train Loss 0.0034507378 Test MSE 0.006508464425464512 Test RE 0.03856091476744072\n",
      "88 Train Loss 0.0031725676 Test MSE 0.006674522461642738 Test RE 0.0390497411802513\n",
      "89 Train Loss 0.0029821075 Test MSE 0.007041457733029878 Test RE 0.0401087704435129\n",
      "90 Train Loss 0.002854963 Test MSE 0.006868091109643498 Test RE 0.039611937408379795\n",
      "91 Train Loss 0.0027413296 Test MSE 0.007031738783269219 Test RE 0.04008108088384578\n",
      "92 Train Loss 0.0026425833 Test MSE 0.0066854901576076315 Test RE 0.03908181163127934\n",
      "93 Train Loss 0.0025398983 Test MSE 0.006363912663730841 Test RE 0.038130295040977924\n",
      "94 Train Loss 0.002397785 Test MSE 0.005969035355455294 Test RE 0.03692836977836611\n",
      "95 Train Loss 0.0022749132 Test MSE 0.0054658607257479985 Test RE 0.035337623634670155\n",
      "96 Train Loss 0.0021364086 Test MSE 0.005065163869385015 Test RE 0.03401768931829188\n",
      "97 Train Loss 0.0020751804 Test MSE 0.004940251911186542 Test RE 0.03359561593027949\n",
      "98 Train Loss 0.0019768192 Test MSE 0.004783193923263872 Test RE 0.03305727530178163\n",
      "99 Train Loss 0.0018990615 Test MSE 0.004726432199315274 Test RE 0.03286054608974715\n",
      "Training time: 154.90\n",
      "3\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.685802 Test MSE 8.859448313444632 Test RE 1.4226936715278695\n",
      "1 Train Loss 47.245995 Test MSE 8.997758387858036 Test RE 1.433755919039134\n",
      "2 Train Loss 43.397354 Test MSE 8.721257651025656 Test RE 1.411554395646528\n",
      "3 Train Loss 40.806507 Test MSE 8.930375447815456 Test RE 1.4283772324059312\n",
      "4 Train Loss 37.91172 Test MSE 9.136063268771684 Test RE 1.4447330553534274\n",
      "5 Train Loss 35.919434 Test MSE 9.216368583644964 Test RE 1.4510687112411518\n",
      "6 Train Loss 32.933777 Test MSE 9.489284721130787 Test RE 1.4723965768334313\n",
      "7 Train Loss 29.785938 Test MSE 9.721713497787212 Test RE 1.4903197928827407\n",
      "8 Train Loss 27.05785 Test MSE 9.475342118582065 Test RE 1.4713144833331726\n",
      "9 Train Loss 25.168892 Test MSE 9.517174802089409 Test RE 1.4745587593022527\n",
      "10 Train Loss 22.802475 Test MSE 9.31974235078036 Test RE 1.4591838468954204\n",
      "11 Train Loss 21.272465 Test MSE 9.028406290172697 Test RE 1.4361956520753707\n",
      "12 Train Loss 19.67107 Test MSE 9.013453870946401 Test RE 1.4350058796247034\n",
      "13 Train Loss 18.291643 Test MSE 8.981211746940827 Test RE 1.4324369926880474\n",
      "14 Train Loss 16.985586 Test MSE 8.859971617862401 Test RE 1.4227356883027003\n",
      "15 Train Loss 16.180187 Test MSE 8.835472995994289 Test RE 1.4207673303400874\n",
      "16 Train Loss 15.301384 Test MSE 8.825394217199198 Test RE 1.41995675202506\n",
      "17 Train Loss 14.397083 Test MSE 8.694556237917018 Test RE 1.4093918984729568\n",
      "18 Train Loss 13.69275 Test MSE 8.801101366042682 Test RE 1.4180011131285224\n",
      "19 Train Loss 13.119749 Test MSE 8.711708773584856 Test RE 1.4107814307859177\n",
      "20 Train Loss 12.514608 Test MSE 8.719855234604157 Test RE 1.4114408990195806\n",
      "21 Train Loss 11.9455185 Test MSE 8.685808959666305 Test RE 1.4086827509846613\n",
      "22 Train Loss 10.916251 Test MSE 8.019754020711009 Test RE 1.3535945099897548\n",
      "23 Train Loss 8.286024 Test MSE 6.9000842127255915 Test RE 1.2555535949063752\n",
      "24 Train Loss 7.0442705 Test MSE 6.53799896660606 Test RE 1.2221668058759185\n",
      "25 Train Loss 6.3686485 Test MSE 6.381271779813455 Test RE 1.207429218583488\n",
      "26 Train Loss 5.9081607 Test MSE 6.36773393361333 Test RE 1.206147760096654\n",
      "27 Train Loss 5.605025 Test MSE 6.398434758447469 Test RE 1.2090518705543687\n",
      "28 Train Loss 5.314438 Test MSE 6.383478919965362 Test RE 1.2076380120029362\n",
      "29 Train Loss 4.9822245 Test MSE 6.32719911791552 Test RE 1.2023026691968823\n",
      "30 Train Loss 4.5797505 Test MSE 6.251413623544743 Test RE 1.1950805484068072\n",
      "31 Train Loss 4.2287693 Test MSE 6.102543558268569 Test RE 1.1807650893599329\n",
      "32 Train Loss 3.8715034 Test MSE 5.921918924576542 Test RE 1.1631595450587717\n",
      "33 Train Loss 3.5107026 Test MSE 5.804555106309717 Test RE 1.151575799549187\n",
      "34 Train Loss 3.1488066 Test MSE 5.784355938383806 Test RE 1.1495703793154932\n",
      "35 Train Loss 2.7044878 Test MSE 5.746527951816413 Test RE 1.145805287483076\n",
      "36 Train Loss 2.2352617 Test MSE 5.644114258111973 Test RE 1.1355492080516942\n",
      "37 Train Loss 1.9135109 Test MSE 5.53256005808616 Test RE 1.124271311701297\n",
      "38 Train Loss 1.7116812 Test MSE 5.461718453208652 Test RE 1.1170502618951583\n",
      "39 Train Loss 1.5612465 Test MSE 5.425085509184298 Test RE 1.1132978085774416\n",
      "40 Train Loss 1.4342103 Test MSE 5.430378060253237 Test RE 1.113840726208643\n",
      "41 Train Loss 1.2975433 Test MSE 5.5227609862681435 Test RE 1.123275235953149\n",
      "42 Train Loss 1.2304075 Test MSE 5.582913850477543 Test RE 1.1293759193828634\n",
      "43 Train Loss 1.1683629 Test MSE 5.617139646259272 Test RE 1.1328324234762572\n",
      "44 Train Loss 1.1310773 Test MSE 5.632583283246837 Test RE 1.1343886465002138\n",
      "45 Train Loss 1.0976629 Test MSE 5.652230777387678 Test RE 1.1363654030712307\n",
      "46 Train Loss 1.0645201 Test MSE 5.673702898258092 Test RE 1.1385218123592578\n",
      "47 Train Loss 1.0469759 Test MSE 5.687086602226336 Test RE 1.1398638515648074\n",
      "48 Train Loss 1.0259297 Test MSE 5.732651240051057 Test RE 1.1444210063756561\n",
      "49 Train Loss 1.0065264 Test MSE 5.771609728922635 Test RE 1.1483031037592086\n",
      "50 Train Loss 0.9931046 Test MSE 5.801967958171896 Test RE 1.1513191365336402\n",
      "51 Train Loss 0.9752178 Test MSE 5.809782680475971 Test RE 1.152094236622383\n",
      "52 Train Loss 0.9572801 Test MSE 5.8360715338153915 Test RE 1.1546978668684553\n",
      "53 Train Loss 0.93747544 Test MSE 5.87088423344274 Test RE 1.1581366853859534\n",
      "54 Train Loss 0.9142504 Test MSE 5.932036801280238 Test RE 1.1641527773587141\n",
      "55 Train Loss 0.90057033 Test MSE 5.9474438907819005 Test RE 1.1656636053804363\n",
      "56 Train Loss 0.8905345 Test MSE 5.942465891931735 Test RE 1.1651756741860835\n",
      "57 Train Loss 0.8809896 Test MSE 5.959570979515325 Test RE 1.1668514187960508\n",
      "58 Train Loss 0.8703608 Test MSE 5.974148103777024 Test RE 1.1682776078343602\n",
      "59 Train Loss 0.86150575 Test MSE 5.965065255079091 Test RE 1.1673891694432095\n",
      "60 Train Loss 0.8543902 Test MSE 5.986434513587522 Test RE 1.1694783283998036\n",
      "61 Train Loss 0.8436211 Test MSE 6.014974824198402 Test RE 1.1722627560670522\n",
      "62 Train Loss 0.83530635 Test MSE 6.031854907150408 Test RE 1.173906489389641\n",
      "63 Train Loss 0.8258666 Test MSE 6.023622876110101 Test RE 1.1731051659001088\n",
      "64 Train Loss 0.8189501 Test MSE 6.050512761612746 Test RE 1.1757206631008144\n",
      "65 Train Loss 0.81283045 Test MSE 6.077049281680803 Test RE 1.1782960977827444\n",
      "66 Train Loss 0.80832684 Test MSE 6.078827363776834 Test RE 1.1784684638331833\n",
      "67 Train Loss 0.8045231 Test MSE 6.081475579383188 Test RE 1.1787251332999846\n",
      "68 Train Loss 0.8000641 Test MSE 6.086385133480009 Test RE 1.1792008276642612\n",
      "69 Train Loss 0.7938025 Test MSE 6.096118841845869 Test RE 1.1801433749482426\n",
      "70 Train Loss 0.7891498 Test MSE 6.087675029168942 Test RE 1.179325775843668\n",
      "71 Train Loss 0.7848828 Test MSE 6.083079057794811 Test RE 1.178880517935677\n",
      "72 Train Loss 0.77942556 Test MSE 6.114635991319126 Test RE 1.1819343769191515\n",
      "73 Train Loss 0.77368397 Test MSE 6.103276203189548 Test RE 1.18083596600132\n",
      "74 Train Loss 0.7683466 Test MSE 6.094310319236847 Test RE 1.1799683066506843\n",
      "75 Train Loss 0.76393604 Test MSE 6.108819215949147 Test RE 1.18137206359448\n",
      "76 Train Loss 0.7562884 Test MSE 6.108950775911953 Test RE 1.1813847845821595\n",
      "77 Train Loss 0.7528622 Test MSE 6.130183548890657 Test RE 1.183436062909417\n",
      "78 Train Loss 0.7500982 Test MSE 6.130601051922299 Test RE 1.1834763618440045\n",
      "79 Train Loss 0.74538255 Test MSE 6.138496108888557 Test RE 1.1842381637414654\n",
      "80 Train Loss 0.7412738 Test MSE 6.137647348030021 Test RE 1.1841562894737476\n",
      "81 Train Loss 0.7377499 Test MSE 6.133183913585588 Test RE 1.183725638693748\n",
      "82 Train Loss 0.7331013 Test MSE 6.157352326163423 Test RE 1.1860556390244492\n",
      "83 Train Loss 0.72901744 Test MSE 6.1824946249378065 Test RE 1.1884746808873266\n",
      "84 Train Loss 0.7252265 Test MSE 6.200422747846598 Test RE 1.1901966149201062\n",
      "85 Train Loss 0.7230117 Test MSE 6.194540200301875 Test RE 1.1896318913633126\n",
      "86 Train Loss 0.72017235 Test MSE 6.198294684306454 Test RE 1.1899923521233917\n",
      "87 Train Loss 0.71711254 Test MSE 6.214933322104874 Test RE 1.191588483229877\n",
      "88 Train Loss 0.7143703 Test MSE 6.218985920901261 Test RE 1.191976922078498\n",
      "89 Train Loss 0.71236604 Test MSE 6.2084901578853655 Test RE 1.1909706494736783\n",
      "90 Train Loss 0.70982504 Test MSE 6.219101162187609 Test RE 1.191987966026755\n",
      "91 Train Loss 0.70650107 Test MSE 6.229097907858611 Test RE 1.192945597648329\n",
      "92 Train Loss 0.7044572 Test MSE 6.2258922787429 Test RE 1.1926386002852263\n",
      "93 Train Loss 0.7013232 Test MSE 6.225913248097589 Test RE 1.1926406087395687\n",
      "94 Train Loss 0.6985717 Test MSE 6.240885250876451 Test RE 1.194073771681263\n",
      "95 Train Loss 0.69575113 Test MSE 6.250617960671516 Test RE 1.1950044926905752\n",
      "96 Train Loss 0.6929911 Test MSE 6.249568321692951 Test RE 1.1949041525349569\n",
      "97 Train Loss 0.6911801 Test MSE 6.2635562206665005 Test RE 1.1962406333648252\n",
      "98 Train Loss 0.68832076 Test MSE 6.275421165082444 Test RE 1.1973731061118307\n",
      "99 Train Loss 0.68634546 Test MSE 6.273277801662808 Test RE 1.1971686078938228\n",
      "Training time: 152.30\n",
      "4\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.299847 Test MSE 8.24236928860864 Test RE 1.3722527019991755\n",
      "1 Train Loss 47.808887 Test MSE 8.587407788928461 Test RE 1.4006805679941974\n",
      "2 Train Loss 41.53344 Test MSE 7.429435586404974 Test RE 1.3028246623623854\n",
      "3 Train Loss 32.37974 Test MSE 7.188860524944594 Test RE 1.2815574780540608\n",
      "4 Train Loss 24.991856 Test MSE 6.547067584524333 Test RE 1.2230141234713374\n",
      "5 Train Loss 21.370861 Test MSE 6.521322722664937 Test RE 1.2206071417593771\n",
      "6 Train Loss 18.674099 Test MSE 6.4889673415567595 Test RE 1.2175753705235917\n",
      "7 Train Loss 16.613657 Test MSE 6.290754059446669 Test RE 1.198834999598838\n",
      "8 Train Loss 14.446211 Test MSE 6.060240536141363 Test RE 1.1766654220505273\n",
      "9 Train Loss 11.048193 Test MSE 5.7779824047162345 Test RE 1.1489368736162198\n",
      "10 Train Loss 8.736355 Test MSE 5.709729496461789 Test RE 1.1421307572126171\n",
      "11 Train Loss 7.1587915 Test MSE 5.663351965341586 Test RE 1.137482795780013\n",
      "12 Train Loss 6.075798 Test MSE 5.425280226649822 Test RE 1.1133177876710585\n",
      "13 Train Loss 4.985137 Test MSE 5.197044566810098 Test RE 1.0896481374029814\n",
      "14 Train Loss 4.3605213 Test MSE 4.9481401439024 Test RE 1.063234489688651\n",
      "15 Train Loss 3.6986766 Test MSE 4.442809093171219 Test RE 1.0074810504554204\n",
      "16 Train Loss 3.104116 Test MSE 3.98053218381206 Test RE 0.9536272006632291\n",
      "17 Train Loss 2.5765202 Test MSE 3.568163568373801 Test RE 0.9028808413382194\n",
      "18 Train Loss 2.3309145 Test MSE 3.5098272332853866 Test RE 0.8954697716876027\n",
      "19 Train Loss 2.1349528 Test MSE 3.357326625815923 Test RE 0.8757998321806274\n",
      "20 Train Loss 1.9138012 Test MSE 3.000724163244594 Test RE 0.8279823860658833\n",
      "21 Train Loss 1.75966 Test MSE 2.7883915359202374 Test RE 0.7981507722263961\n",
      "22 Train Loss 1.6481518 Test MSE 2.647584970823243 Test RE 0.777737453616687\n",
      "23 Train Loss 1.4950299 Test MSE 2.319455133347873 Test RE 0.7279491585038762\n",
      "24 Train Loss 1.4081668 Test MSE 2.1427427541667337 Test RE 0.699669717998219\n",
      "25 Train Loss 1.3233541 Test MSE 1.9083880614062925 Test RE 0.6603001649834128\n",
      "26 Train Loss 1.2061372 Test MSE 1.6930465967047628 Test RE 0.6219314456155803\n",
      "27 Train Loss 1.0691892 Test MSE 1.3282794393664548 Test RE 0.5508746471923862\n",
      "28 Train Loss 0.9576924 Test MSE 1.1574551194578864 Test RE 0.5142332333501585\n",
      "29 Train Loss 0.7606073 Test MSE 1.0091932737906346 Test RE 0.48017023346683435\n",
      "30 Train Loss 0.6150498 Test MSE 0.8476059395477564 Test RE 0.4400530707969608\n",
      "31 Train Loss 0.50672394 Test MSE 0.7835933107012514 Test RE 0.42311012707722917\n",
      "32 Train Loss 0.44169638 Test MSE 0.7342680335797543 Test RE 0.40957682122499445\n",
      "33 Train Loss 0.3663039 Test MSE 0.632541431426922 Test RE 0.3801478589354729\n",
      "34 Train Loss 0.3212139 Test MSE 0.5545708657424662 Test RE 0.3559480232367568\n",
      "35 Train Loss 0.2896878 Test MSE 0.504482998128345 Test RE 0.33949339358155056\n",
      "36 Train Loss 0.24421334 Test MSE 0.4657201338027831 Test RE 0.32618994315007704\n",
      "37 Train Loss 0.21903715 Test MSE 0.4553251042622322 Test RE 0.32252906541465215\n",
      "38 Train Loss 0.19485454 Test MSE 0.42644970029621654 Test RE 0.3121346390513254\n",
      "39 Train Loss 0.18095508 Test MSE 0.44087605850246736 Test RE 0.31737032601007664\n",
      "40 Train Loss 0.16700405 Test MSE 0.43959800642773805 Test RE 0.3169099809973015\n",
      "41 Train Loss 0.15758154 Test MSE 0.4326158437368445 Test RE 0.31438315686448753\n",
      "42 Train Loss 0.1470185 Test MSE 0.4292245149617491 Test RE 0.3131484883192251\n",
      "43 Train Loss 0.13926491 Test MSE 0.42946036706261514 Test RE 0.31323451158128096\n",
      "44 Train Loss 0.1342437 Test MSE 0.42890864712660526 Test RE 0.31303324357429635\n",
      "45 Train Loss 0.12994523 Test MSE 0.43791112088372497 Test RE 0.31630135141355387\n",
      "46 Train Loss 0.12609804 Test MSE 0.4316617846119111 Test RE 0.31403630679769606\n",
      "47 Train Loss 0.12163631 Test MSE 0.4328026258239878 Test RE 0.31445101707603523\n",
      "48 Train Loss 0.11837287 Test MSE 0.4399290406949759 Test RE 0.3170292812662788\n",
      "49 Train Loss 0.11527323 Test MSE 0.43328920407778715 Test RE 0.3146277281654066\n",
      "50 Train Loss 0.11308129 Test MSE 0.43364248981641057 Test RE 0.3147559691186269\n",
      "51 Train Loss 0.1099548 Test MSE 0.43726401762721795 Test RE 0.3160675650415039\n",
      "52 Train Loss 0.10788746 Test MSE 0.4336860368299094 Test RE 0.3147717728494235\n",
      "53 Train Loss 0.10575319 Test MSE 0.4375228392215655 Test RE 0.31616109321446517\n",
      "54 Train Loss 0.104048684 Test MSE 0.4405915490063579 Test RE 0.31726790556567125\n",
      "55 Train Loss 0.10256192 Test MSE 0.4459096118433664 Test RE 0.3191769183040193\n",
      "56 Train Loss 0.100458756 Test MSE 0.44842181926246355 Test RE 0.32007475993233747\n",
      "57 Train Loss 0.09895328 Test MSE 0.45023782146253283 Test RE 0.32072221857966604\n",
      "58 Train Loss 0.09758645 Test MSE 0.45234556832070855 Test RE 0.32147205777959326\n",
      "59 Train Loss 0.09578242 Test MSE 0.45207556271042776 Test RE 0.3213760999303942\n",
      "60 Train Loss 0.094365165 Test MSE 0.4530752547063586 Test RE 0.3217312393410203\n",
      "61 Train Loss 0.09319918 Test MSE 0.45474960783554136 Test RE 0.3223251748201997\n",
      "62 Train Loss 0.09209729 Test MSE 0.4568135539241801 Test RE 0.32305580617657015\n",
      "63 Train Loss 0.0909413 Test MSE 0.4623891394673554 Test RE 0.3250213371821287\n",
      "64 Train Loss 0.08965996 Test MSE 0.4627994191158303 Test RE 0.32516550154639606\n",
      "65 Train Loss 0.0885838 Test MSE 0.4660046709087935 Test RE 0.3262895726954962\n",
      "66 Train Loss 0.08736555 Test MSE 0.4686900438552576 Test RE 0.3272283513935208\n",
      "67 Train Loss 0.08598896 Test MSE 0.469897635761741 Test RE 0.3276496363209423\n",
      "68 Train Loss 0.084700674 Test MSE 0.47431963069546934 Test RE 0.3291877078207485\n",
      "69 Train Loss 0.083948694 Test MSE 0.48052561184243114 Test RE 0.3313342494395952\n",
      "70 Train Loss 0.08296832 Test MSE 0.48395695872760375 Test RE 0.3325151441631048\n",
      "71 Train Loss 0.082480334 Test MSE 0.48970205542881445 Test RE 0.33448297993566545\n",
      "72 Train Loss 0.081749596 Test MSE 0.4907846464634586 Test RE 0.3348524988735449\n",
      "73 Train Loss 0.08117575 Test MSE 0.4906332002724194 Test RE 0.33480083054134696\n",
      "74 Train Loss 0.08058314 Test MSE 0.49085208653190854 Test RE 0.3348755045847877\n",
      "75 Train Loss 0.0800239 Test MSE 0.49181973991656747 Test RE 0.3352054246144802\n",
      "76 Train Loss 0.07924198 Test MSE 0.49308423713062316 Test RE 0.33563606433326487\n",
      "77 Train Loss 0.07870778 Test MSE 0.49442496371402195 Test RE 0.3360920621965294\n",
      "78 Train Loss 0.07798725 Test MSE 0.49512832678670554 Test RE 0.3363310375209701\n",
      "79 Train Loss 0.0775845 Test MSE 0.4979329826387008 Test RE 0.33728226643522125\n",
      "80 Train Loss 0.07713858 Test MSE 0.5007947317406464 Test RE 0.3382501018565345\n",
      "81 Train Loss 0.0767314 Test MSE 0.506514034567065 Test RE 0.3401761032545408\n",
      "82 Train Loss 0.07625423 Test MSE 0.5082302398927119 Test RE 0.34075191982462494\n",
      "83 Train Loss 0.07600629 Test MSE 0.5107817737801503 Test RE 0.34160620936960534\n",
      "84 Train Loss 0.0758107 Test MSE 0.5127942217182975 Test RE 0.3422785012716875\n",
      "85 Train Loss 0.07534032 Test MSE 0.512460819332556 Test RE 0.342167213918175\n",
      "86 Train Loss 0.07512687 Test MSE 0.5122895617867435 Test RE 0.34211003528944156\n",
      "87 Train Loss 0.074586965 Test MSE 0.5109806759783335 Test RE 0.3416727148872658\n",
      "88 Train Loss 0.07424373 Test MSE 0.5079566308515532 Test RE 0.3406601844749377\n",
      "89 Train Loss 0.07375804 Test MSE 0.5090376149751684 Test RE 0.3410224718428267\n",
      "90 Train Loss 0.07318903 Test MSE 0.5102177846880426 Test RE 0.3414175618903622\n",
      "91 Train Loss 0.07277538 Test MSE 0.5105508137042492 Test RE 0.3415289686370009\n",
      "92 Train Loss 0.072407536 Test MSE 0.5125772625492856 Test RE 0.3422060859513932\n",
      "93 Train Loss 0.072083496 Test MSE 0.515671804357093 Test RE 0.343237518296647\n",
      "94 Train Loss 0.07175269 Test MSE 0.5176705996435864 Test RE 0.34390208634413194\n",
      "95 Train Loss 0.0715442 Test MSE 0.5221883641187792 Test RE 0.345399460914441\n",
      "96 Train Loss 0.07134739 Test MSE 0.5217618729044986 Test RE 0.345258381625524\n",
      "97 Train Loss 0.071183115 Test MSE 0.5220124591144144 Test RE 0.3453412801740917\n",
      "98 Train Loss 0.070924535 Test MSE 0.5243577140249707 Test RE 0.34611617134637873\n",
      "99 Train Loss 0.07062345 Test MSE 0.5237154631713774 Test RE 0.3459041390730293\n",
      "Training time: 158.28\n",
      "5\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.432377 Test MSE 8.707970575425177 Test RE 1.410478714834767\n",
      "1 Train Loss 52.741264 Test MSE 7.8088012677099465 Test RE 1.3356733026643108\n",
      "2 Train Loss 45.462833 Test MSE 8.564745899145198 Test RE 1.3988311718385997\n",
      "3 Train Loss 43.34932 Test MSE 8.630283767194424 Test RE 1.4041729358275707\n",
      "4 Train Loss 41.625656 Test MSE 8.849210780499202 Test RE 1.4218714372950103\n",
      "5 Train Loss 39.525272 Test MSE 9.00885034447285 Test RE 1.4346393757648062\n",
      "6 Train Loss 38.275204 Test MSE 9.231270095498884 Test RE 1.4522413197427642\n",
      "7 Train Loss 36.212124 Test MSE 9.55652642561614 Test RE 1.477604118049757\n",
      "8 Train Loss 34.24987 Test MSE 9.7529818458509 Test RE 1.49271455734032\n",
      "9 Train Loss 32.2073 Test MSE 9.941554128252799 Test RE 1.5070761637615033\n",
      "10 Train Loss 29.815979 Test MSE 9.897870091619659 Test RE 1.5037614078307202\n",
      "11 Train Loss 28.272429 Test MSE 9.765432887641179 Test RE 1.4936670826066185\n",
      "12 Train Loss 26.317131 Test MSE 9.683619902251305 Test RE 1.4873970898944984\n",
      "13 Train Loss 24.017265 Test MSE 9.508450358472974 Test RE 1.4738827364982274\n",
      "14 Train Loss 22.284042 Test MSE 9.271193898337065 Test RE 1.4553782902347607\n",
      "15 Train Loss 20.433952 Test MSE 9.069695192433798 Test RE 1.4394759264552577\n",
      "16 Train Loss 18.859371 Test MSE 8.950962348714102 Test RE 1.4300226801878297\n",
      "17 Train Loss 17.447077 Test MSE 8.87933542421022 Test RE 1.4242895613455693\n",
      "18 Train Loss 15.991998 Test MSE 8.869438604580736 Test RE 1.423495590501825\n",
      "19 Train Loss 14.548016 Test MSE 8.822138165641487 Test RE 1.4196947875844508\n",
      "20 Train Loss 13.225232 Test MSE 8.815737040188917 Test RE 1.4191796463958926\n",
      "21 Train Loss 12.182489 Test MSE 8.802714647098636 Test RE 1.4181310701313004\n",
      "22 Train Loss 10.954983 Test MSE 8.577795600215204 Test RE 1.3998964329001151\n",
      "23 Train Loss 9.800785 Test MSE 8.41392480169214 Test RE 1.3864600922717796\n",
      "24 Train Loss 8.625526 Test MSE 8.395996685697739 Test RE 1.384982192659858\n",
      "25 Train Loss 7.785411 Test MSE 8.36153938771783 Test RE 1.3821372767822797\n",
      "26 Train Loss 6.395705 Test MSE 7.8281243615102944 Test RE 1.3373248617751776\n",
      "27 Train Loss 5.5342216 Test MSE 7.623713474911264 Test RE 1.3197490046086648\n",
      "28 Train Loss 4.644045 Test MSE 7.452135546393768 Test RE 1.304813475078771\n",
      "29 Train Loss 3.9175415 Test MSE 7.498267605854829 Test RE 1.3088459341722996\n",
      "30 Train Loss 3.5089316 Test MSE 7.375560074382119 Test RE 1.2980922666766885\n",
      "31 Train Loss 3.2426677 Test MSE 7.25855691596844 Test RE 1.2877548777350458\n",
      "32 Train Loss 2.9766998 Test MSE 7.238552846073691 Test RE 1.2859791727431997\n",
      "33 Train Loss 2.8256335 Test MSE 7.275911161413785 Test RE 1.289293384124219\n",
      "34 Train Loss 2.69546 Test MSE 7.325188014800804 Test RE 1.2936519525974217\n",
      "35 Train Loss 2.4900367 Test MSE 7.2829928858867605 Test RE 1.2899206732502482\n",
      "36 Train Loss 2.4001288 Test MSE 7.372274692059347 Test RE 1.2978031222340172\n",
      "37 Train Loss 2.325293 Test MSE 7.370996251017757 Test RE 1.297690590025121\n",
      "38 Train Loss 2.2612548 Test MSE 7.310903918762982 Test RE 1.2923900282744447\n",
      "39 Train Loss 2.1783237 Test MSE 7.4225386091954055 Test RE 1.3022197955282524\n",
      "40 Train Loss 2.1297054 Test MSE 7.438365705095071 Test RE 1.303607419324563\n",
      "41 Train Loss 2.0853043 Test MSE 7.500295145419948 Test RE 1.3090228788805032\n",
      "42 Train Loss 2.0432606 Test MSE 7.518303230268508 Test RE 1.3105934079052162\n",
      "43 Train Loss 2.0067713 Test MSE 7.536616317834526 Test RE 1.3121886092066957\n",
      "44 Train Loss 1.9591951 Test MSE 7.486684543169799 Test RE 1.3078346136476129\n",
      "45 Train Loss 1.8943946 Test MSE 7.458506060520081 Test RE 1.3053710707449622\n",
      "46 Train Loss 1.8312523 Test MSE 7.398199499727903 Test RE 1.3000829999501355\n",
      "47 Train Loss 1.7912343 Test MSE 7.437732204607178 Test RE 1.3035519062217478\n",
      "48 Train Loss 1.7367556 Test MSE 7.445947275962203 Test RE 1.304271602512749\n",
      "49 Train Loss 1.6980906 Test MSE 7.47124626143569 Test RE 1.3064854758102995\n",
      "50 Train Loss 1.6525311 Test MSE 7.413975234137583 Test RE 1.3014683939324205\n",
      "51 Train Loss 1.6077663 Test MSE 7.322449362118673 Test RE 1.2934101025189517\n",
      "52 Train Loss 1.568667 Test MSE 7.177638652437622 Test RE 1.280556826325944\n",
      "53 Train Loss 1.5260141 Test MSE 7.0837998002214935 Test RE 1.2721584286753855\n",
      "54 Train Loss 1.5045613 Test MSE 7.036223027497249 Test RE 1.2678791461669268\n",
      "55 Train Loss 1.4860606 Test MSE 6.946874979520798 Test RE 1.2598034746234046\n",
      "56 Train Loss 1.4602865 Test MSE 6.817985992149927 Test RE 1.248061862778976\n",
      "57 Train Loss 1.440314 Test MSE 6.743596912431018 Test RE 1.241234567439393\n",
      "58 Train Loss 1.4199337 Test MSE 6.658597694837994 Test RE 1.2333872320531065\n",
      "59 Train Loss 1.4011184 Test MSE 6.5701387906309 Test RE 1.2251671176405035\n",
      "60 Train Loss 1.3815665 Test MSE 6.511751084655334 Test RE 1.219711042888666\n",
      "61 Train Loss 1.3605464 Test MSE 6.460836819903376 Test RE 1.2149333298202019\n",
      "62 Train Loss 1.3353366 Test MSE 6.296646390794567 Test RE 1.1993963217886157\n",
      "63 Train Loss 1.3173583 Test MSE 6.171522285908635 Test RE 1.1874195939949173\n",
      "64 Train Loss 1.3022459 Test MSE 6.160399898826189 Test RE 1.1863491209791996\n",
      "65 Train Loss 1.2777531 Test MSE 6.055544818587471 Test RE 1.1762094699176797\n",
      "66 Train Loss 1.2626936 Test MSE 6.007041609641957 Test RE 1.1714894460648106\n",
      "67 Train Loss 1.2467964 Test MSE 6.00801387530893 Test RE 1.1715842475459215\n",
      "68 Train Loss 1.2302126 Test MSE 5.991830937655191 Test RE 1.1700053181608927\n",
      "69 Train Loss 1.2105012 Test MSE 5.977163412325572 Test RE 1.168572400749355\n",
      "70 Train Loss 1.1965841 Test MSE 5.960096989474056 Test RE 1.166902912597025\n",
      "71 Train Loss 1.180959 Test MSE 5.962801556366891 Test RE 1.1671676405908356\n",
      "72 Train Loss 1.1715574 Test MSE 5.961594542428463 Test RE 1.1670495032607846\n",
      "73 Train Loss 1.1609511 Test MSE 5.97036086077299 Test RE 1.1679072409999633\n",
      "74 Train Loss 1.1524746 Test MSE 5.959774875343616 Test RE 1.1668713794695973\n",
      "75 Train Loss 1.14325 Test MSE 5.940564877636888 Test RE 1.164989287521949\n",
      "76 Train Loss 1.1350565 Test MSE 5.9290060997783485 Test RE 1.1638553541930312\n",
      "77 Train Loss 1.1202359 Test MSE 5.937375548150718 Test RE 1.1646765198315963\n",
      "78 Train Loss 1.1080271 Test MSE 5.967674056343432 Test RE 1.1676444184053323\n",
      "79 Train Loss 1.0981959 Test MSE 5.960766115136902 Test RE 1.1669684134414502\n",
      "80 Train Loss 1.0913188 Test MSE 5.955873920592858 Test RE 1.1664894306837033\n",
      "81 Train Loss 1.0841707 Test MSE 5.943815636489008 Test RE 1.1653079930129695\n",
      "82 Train Loss 1.078782 Test MSE 5.940333167546858 Test RE 1.1649665672579215\n",
      "83 Train Loss 1.0732974 Test MSE 5.935426272167256 Test RE 1.1644853189957143\n",
      "84 Train Loss 1.0672866 Test MSE 5.933890159288312 Test RE 1.164334622435368\n",
      "85 Train Loss 1.0625935 Test MSE 5.938029692192204 Test RE 1.1647406765634918\n",
      "86 Train Loss 1.0534866 Test MSE 5.949974116623631 Test RE 1.1659115336171204\n",
      "87 Train Loss 1.045829 Test MSE 5.949111891545455 Test RE 1.1658270530323753\n",
      "88 Train Loss 1.0418038 Test MSE 5.949164357291117 Test RE 1.1658321937871563\n",
      "89 Train Loss 1.0333233 Test MSE 5.96094057670218 Test RE 1.1669854909145836\n",
      "90 Train Loss 1.0275927 Test MSE 5.97031589750554 Test RE 1.167902843190038\n",
      "91 Train Loss 1.0224932 Test MSE 5.956553357437105 Test RE 1.16655596443728\n",
      "92 Train Loss 1.013605 Test MSE 5.949841895485629 Test RE 1.1658985790224279\n",
      "93 Train Loss 1.0090065 Test MSE 5.957093281081599 Test RE 1.1666088336753844\n",
      "94 Train Loss 1.0043362 Test MSE 5.949941220979911 Test RE 1.1659083106229797\n",
      "95 Train Loss 0.9977031 Test MSE 5.934211982622058 Test RE 1.1643661957337683\n",
      "96 Train Loss 0.99081147 Test MSE 5.946816973995963 Test RE 1.1656021677819466\n",
      "97 Train Loss 0.98439986 Test MSE 5.969107205715088 Test RE 1.1677846161098875\n",
      "98 Train Loss 0.97811633 Test MSE 5.983415930170433 Test RE 1.1691834439403201\n",
      "99 Train Loss 0.97375107 Test MSE 6.0060081387149316 Test RE 1.1713886683076222\n",
      "Training time: 149.87\n",
      "6\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.855362 Test MSE 8.526052317268123 Test RE 1.3956677937528863\n",
      "1 Train Loss 44.814507 Test MSE 9.089008269068474 Test RE 1.4410077268228014\n",
      "2 Train Loss 39.574635 Test MSE 9.083547683583694 Test RE 1.4405747902545472\n",
      "3 Train Loss 35.96412 Test MSE 9.144582574396496 Test RE 1.44540649938033\n",
      "4 Train Loss 32.916725 Test MSE 8.934370227655144 Test RE 1.4286966710808549\n",
      "5 Train Loss 31.337696 Test MSE 8.913666140295827 Test RE 1.4270403138580487\n",
      "6 Train Loss 28.60213 Test MSE 8.824446061141234 Test RE 1.4198804734630885\n",
      "7 Train Loss 26.609035 Test MSE 8.841416862774583 Test RE 1.4212451447110566\n",
      "8 Train Loss 24.25322 Test MSE 8.690692739012892 Test RE 1.4090787261301747\n",
      "9 Train Loss 22.084122 Test MSE 8.560906984795295 Test RE 1.3985176426927777\n",
      "10 Train Loss 19.389389 Test MSE 8.52717748684811 Test RE 1.3957598827455824\n",
      "11 Train Loss 16.91761 Test MSE 8.416993127779755 Test RE 1.3867128710879821\n",
      "12 Train Loss 14.624945 Test MSE 8.44671861779254 Test RE 1.389159373614416\n",
      "13 Train Loss 13.082314 Test MSE 8.387320401998611 Test RE 1.3842663988780537\n",
      "14 Train Loss 11.390971 Test MSE 8.000698728786151 Test RE 1.3519854532712337\n",
      "15 Train Loss 9.847157 Test MSE 7.647146650228552 Test RE 1.3217757191449786\n",
      "16 Train Loss 8.230029 Test MSE 7.123562033283868 Test RE 1.2757238227107552\n",
      "17 Train Loss 6.799241 Test MSE 7.056460105625714 Test RE 1.2697011284063093\n",
      "18 Train Loss 5.307616 Test MSE 6.609127553330643 Test RE 1.2287969567305297\n",
      "19 Train Loss 4.6363573 Test MSE 6.3001877923662 Test RE 1.1997335605892674\n",
      "20 Train Loss 3.8879561 Test MSE 6.09427251332383 Test RE 1.1799646466919675\n",
      "21 Train Loss 3.407958 Test MSE 5.866582843158902 Test RE 1.1577123446493165\n",
      "22 Train Loss 2.9566996 Test MSE 5.4265526184388095 Test RE 1.1134483333115284\n",
      "23 Train Loss 2.6338432 Test MSE 5.267543582303849 Test RE 1.0970138964560663\n",
      "24 Train Loss 2.3990393 Test MSE 5.253574700321664 Test RE 1.0955583574284293\n",
      "25 Train Loss 2.2295918 Test MSE 5.260142121982837 Test RE 1.0962429147928516\n",
      "26 Train Loss 2.1047106 Test MSE 5.162366788971617 Test RE 1.0860066619103408\n",
      "27 Train Loss 1.9854 Test MSE 5.251315339058553 Test RE 1.0953227532501737\n",
      "28 Train Loss 1.8557023 Test MSE 5.278532153141142 Test RE 1.0981575352810606\n",
      "29 Train Loss 1.7409228 Test MSE 5.378886497926371 Test RE 1.108547355738179\n",
      "30 Train Loss 1.6409329 Test MSE 5.410292271271106 Test RE 1.1117788904100823\n",
      "31 Train Loss 1.5712491 Test MSE 5.418283724822069 Test RE 1.1125996825656013\n",
      "32 Train Loss 1.5033665 Test MSE 5.442095659854258 Test RE 1.1150417942078896\n",
      "33 Train Loss 1.43456 Test MSE 5.551911216240243 Test RE 1.1262357694801006\n",
      "34 Train Loss 1.3605208 Test MSE 5.5808679341047105 Test RE 1.129168964692908\n",
      "35 Train Loss 1.3112521 Test MSE 5.599273229312493 Test RE 1.1310293904931046\n",
      "36 Train Loss 1.2700434 Test MSE 5.6261034732095965 Test RE 1.1337359496955537\n",
      "37 Train Loss 1.2305919 Test MSE 5.681483613459296 Test RE 1.1393022091432208\n",
      "38 Train Loss 1.1982486 Test MSE 5.7085000007437365 Test RE 1.142007781117192\n",
      "39 Train Loss 1.1746413 Test MSE 5.757489114172963 Test RE 1.1468975448023921\n",
      "40 Train Loss 1.1573888 Test MSE 5.745524446267463 Test RE 1.1457052381858435\n",
      "41 Train Loss 1.135581 Test MSE 5.79156670671281 Test RE 1.150286682394693\n",
      "42 Train Loss 1.1126236 Test MSE 5.805388815085348 Test RE 1.151658497048025\n",
      "43 Train Loss 1.0957693 Test MSE 5.81596004529157 Test RE 1.152706567237877\n",
      "44 Train Loss 1.0784199 Test MSE 5.801254261005853 Test RE 1.1512483227613606\n",
      "45 Train Loss 1.0672998 Test MSE 5.80260537161999 Test RE 1.1513823776745031\n",
      "46 Train Loss 1.0550973 Test MSE 5.820026811805636 Test RE 1.153109507530006\n",
      "47 Train Loss 1.0402036 Test MSE 5.803928075545867 Test RE 1.1515135990065661\n",
      "48 Train Loss 1.0218158 Test MSE 5.79280832887508 Test RE 1.1504099776074748\n",
      "49 Train Loss 1.0014791 Test MSE 5.849548248274511 Test RE 1.1560303179868108\n",
      "50 Train Loss 0.9822426 Test MSE 5.924039588297744 Test RE 1.1633677925448407\n",
      "51 Train Loss 0.95557255 Test MSE 5.976997685247613 Test RE 1.168556200302886\n",
      "52 Train Loss 0.93298084 Test MSE 5.992495273200382 Test RE 1.1700701776825781\n",
      "53 Train Loss 0.91387534 Test MSE 6.01419317547151 Test RE 1.172186585551971\n",
      "54 Train Loss 0.88958997 Test MSE 6.084809299626884 Test RE 1.179048163575683\n",
      "55 Train Loss 0.86845165 Test MSE 6.11682807422355 Test RE 1.1821462183091647\n",
      "56 Train Loss 0.8496441 Test MSE 6.1537267634416 Test RE 1.1857064018794197\n",
      "57 Train Loss 0.8334707 Test MSE 6.1796311709309775 Test RE 1.1881994249485446\n",
      "58 Train Loss 0.8183524 Test MSE 6.21199216874557 Test RE 1.1913064963588125\n",
      "59 Train Loss 0.80824155 Test MSE 6.269260469280175 Test RE 1.196785220246314\n",
      "60 Train Loss 0.79844946 Test MSE 6.303108858726129 Test RE 1.2000116550954165\n",
      "61 Train Loss 0.7879861 Test MSE 6.298779950172717 Test RE 1.199599506656919\n",
      "62 Train Loss 0.77927977 Test MSE 6.3258849394609085 Test RE 1.2021778017565157\n",
      "63 Train Loss 0.769936 Test MSE 6.339496234425133 Test RE 1.203470459161152\n",
      "64 Train Loss 0.75937915 Test MSE 6.340322560403798 Test RE 1.2035488901960827\n",
      "65 Train Loss 0.7503274 Test MSE 6.351275901947426 Test RE 1.2045880481618652\n",
      "66 Train Loss 0.7432606 Test MSE 6.336087152145368 Test RE 1.203146830801985\n",
      "67 Train Loss 0.73481345 Test MSE 6.342055800769204 Test RE 1.2037133847429935\n",
      "68 Train Loss 0.7282392 Test MSE 6.351022234335739 Test RE 1.204563992520994\n",
      "69 Train Loss 0.71898836 Test MSE 6.366758488066497 Test RE 1.206055374286092\n",
      "70 Train Loss 0.7121417 Test MSE 6.382137012478857 Test RE 1.2075110730967207\n",
      "71 Train Loss 0.70625615 Test MSE 6.4086302202144925 Test RE 1.210014757260435\n",
      "72 Train Loss 0.70046866 Test MSE 6.413719054499163 Test RE 1.2104950738403384\n",
      "73 Train Loss 0.6944181 Test MSE 6.430156557480999 Test RE 1.2120452496322454\n",
      "74 Train Loss 0.68925 Test MSE 6.479438015429407 Test RE 1.2166810112931141\n",
      "75 Train Loss 0.6840838 Test MSE 6.490828615817839 Test RE 1.2177499806804748\n",
      "76 Train Loss 0.6787896 Test MSE 6.524459926918672 Test RE 1.220900704403988\n",
      "77 Train Loss 0.67441785 Test MSE 6.5249182467399764 Test RE 1.2209435855905122\n",
      "78 Train Loss 0.671003 Test MSE 6.523849961653881 Test RE 1.2208436326742134\n",
      "79 Train Loss 0.66415656 Test MSE 6.530412720279315 Test RE 1.2214575407322537\n",
      "80 Train Loss 0.6590269 Test MSE 6.560130065240337 Test RE 1.2242335730682257\n",
      "81 Train Loss 0.6550457 Test MSE 6.571476404510467 Test RE 1.2252918271170645\n",
      "82 Train Loss 0.6494749 Test MSE 6.614027651178172 Test RE 1.2292523957905959\n",
      "83 Train Loss 0.64538324 Test MSE 6.629601351411023 Test RE 1.2306987725850729\n",
      "84 Train Loss 0.64213324 Test MSE 6.620230727687523 Test RE 1.2298286981631807\n",
      "85 Train Loss 0.63823026 Test MSE 6.6401821065328175 Test RE 1.2316804704406232\n",
      "86 Train Loss 0.6334459 Test MSE 6.6459896633748805 Test RE 1.2322189715602032\n",
      "87 Train Loss 0.63003397 Test MSE 6.663948594369614 Test RE 1.233882712190119\n",
      "88 Train Loss 0.62648475 Test MSE 6.677180680071173 Test RE 1.2351071172754082\n",
      "89 Train Loss 0.6229193 Test MSE 6.685124036399334 Test RE 1.2358415574765063\n",
      "90 Train Loss 0.6190665 Test MSE 6.699609280620345 Test RE 1.2371797360954404\n",
      "91 Train Loss 0.6147592 Test MSE 6.710697390932226 Test RE 1.2382031027993192\n",
      "92 Train Loss 0.60918486 Test MSE 6.727704764881757 Test RE 1.2397711408363397\n",
      "93 Train Loss 0.6050411 Test MSE 6.737295581166437 Test RE 1.2406545165954996\n",
      "94 Train Loss 0.6011316 Test MSE 6.762142811481807 Test RE 1.242940185823088\n",
      "95 Train Loss 0.59866685 Test MSE 6.782714639797313 Test RE 1.2448293898363665\n",
      "96 Train Loss 0.5946344 Test MSE 6.79302295526368 Test RE 1.2457749715765944\n",
      "97 Train Loss 0.5908375 Test MSE 6.814722438145713 Test RE 1.2477631231783644\n",
      "98 Train Loss 0.58741695 Test MSE 6.813288964590434 Test RE 1.2476318830929387\n",
      "99 Train Loss 0.58309114 Test MSE 6.812898510417463 Test RE 1.2475961331007481\n",
      "Training time: 159.29\n",
      "7\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.104084 Test MSE 8.10721552207096 Test RE 1.36095548264561\n",
      "1 Train Loss 48.301643 Test MSE 8.380685011801434 Test RE 1.3837187290255761\n",
      "2 Train Loss 40.18875 Test MSE 7.400953065722348 Test RE 1.300324919034614\n",
      "3 Train Loss 32.42722 Test MSE 6.833552501920538 Test RE 1.2494858089843635\n",
      "4 Train Loss 28.597672 Test MSE 6.514245729395966 Test RE 1.2199446555019513\n",
      "5 Train Loss 25.380383 Test MSE 6.7694137404064065 Test RE 1.2436082360240572\n",
      "6 Train Loss 21.864029 Test MSE 6.038967405432447 Test RE 1.174598394960471\n",
      "7 Train Loss 19.109785 Test MSE 5.999225970156345 Test RE 1.170727097486484\n",
      "8 Train Loss 17.48915 Test MSE 5.81133595194317 Test RE 1.1522482351117374\n",
      "9 Train Loss 15.622223 Test MSE 5.763421368174473 Test RE 1.147488248125022\n",
      "10 Train Loss 14.115522 Test MSE 5.778052197379025 Test RE 1.148943812640608\n",
      "11 Train Loss 13.267283 Test MSE 5.746538153567387 Test RE 1.1458063045506963\n",
      "12 Train Loss 12.237583 Test MSE 5.7569355176168635 Test RE 1.1468424049852444\n",
      "13 Train Loss 11.563394 Test MSE 5.79123419528255 Test RE 1.1502536611951295\n",
      "14 Train Loss 10.963405 Test MSE 5.627507232045332 Test RE 1.133877379070625\n",
      "15 Train Loss 10.371157 Test MSE 5.619332708595892 Test RE 1.133053543996325\n",
      "16 Train Loss 9.76297 Test MSE 5.389947597487784 Test RE 1.1096865743669322\n",
      "17 Train Loss 9.228183 Test MSE 5.351385346457935 Test RE 1.105709835715596\n",
      "18 Train Loss 8.775896 Test MSE 5.258919413614512 Test RE 1.0961154977710295\n",
      "19 Train Loss 8.15563 Test MSE 5.222047732240067 Test RE 1.0922661602169637\n",
      "20 Train Loss 7.7211814 Test MSE 5.090115421672166 Test RE 1.078380126052519\n",
      "21 Train Loss 7.0638885 Test MSE 4.9546877334072486 Test RE 1.0639377156813488\n",
      "22 Train Loss 6.548787 Test MSE 4.8731975382379895 Test RE 1.0551521017735395\n",
      "23 Train Loss 6.0006943 Test MSE 4.620331691297031 Test RE 1.0274120085266847\n",
      "24 Train Loss 5.320376 Test MSE 4.418708839677754 Test RE 1.004744767442792\n",
      "25 Train Loss 4.5557857 Test MSE 4.420094052935063 Test RE 1.0049022429364871\n",
      "26 Train Loss 3.7769551 Test MSE 4.0221479551609285 Test RE 0.9585992422192802\n",
      "27 Train Loss 3.2403321 Test MSE 3.8513696536233426 Test RE 0.9380276979102624\n",
      "28 Train Loss 2.771401 Test MSE 3.6197900978359794 Test RE 0.9093891202980968\n",
      "29 Train Loss 2.4806273 Test MSE 3.31727793430321 Test RE 0.870560564620178\n",
      "30 Train Loss 2.2150726 Test MSE 3.1682685394988983 Test RE 0.8507834883698066\n",
      "31 Train Loss 1.9067509 Test MSE 2.81570752149194 Test RE 0.8020507158162368\n",
      "32 Train Loss 1.73644 Test MSE 2.3828478789479144 Test RE 0.7378298464977675\n",
      "33 Train Loss 1.5668211 Test MSE 2.110827771814386 Test RE 0.6944395708433833\n",
      "34 Train Loss 1.4005469 Test MSE 1.9107959320063326 Test RE 0.6607165939558822\n",
      "35 Train Loss 1.2472125 Test MSE 1.4371041210938342 Test RE 0.5729967750524052\n",
      "36 Train Loss 1.036445 Test MSE 1.014157599431731 Test RE 0.4813497880720332\n",
      "37 Train Loss 0.7972558 Test MSE 0.6796572283864812 Test RE 0.39405154111166346\n",
      "38 Train Loss 0.60078424 Test MSE 0.5544856655287627 Test RE 0.3559206795604038\n",
      "39 Train Loss 0.45586416 Test MSE 0.4211908785236496 Test RE 0.31020410380687524\n",
      "40 Train Loss 0.3509789 Test MSE 0.25207511623781587 Test RE 0.239978894492069\n",
      "41 Train Loss 0.2681536 Test MSE 0.16935389138191417 Test RE 0.19670058448156738\n",
      "42 Train Loss 0.21075797 Test MSE 0.11644456308236803 Test RE 0.16310514779790933\n",
      "43 Train Loss 0.1631774 Test MSE 0.10376327230376094 Test RE 0.15396779490202572\n",
      "44 Train Loss 0.13429616 Test MSE 0.08616914623378044 Test RE 0.14030849144945304\n",
      "45 Train Loss 0.11701454 Test MSE 0.08141646066027851 Test RE 0.13638423426294938\n",
      "46 Train Loss 0.10318735 Test MSE 0.07665817127834033 Test RE 0.1323388290508539\n",
      "47 Train Loss 0.09110055 Test MSE 0.07285620146035199 Test RE 0.12901533146694671\n",
      "48 Train Loss 0.080270976 Test MSE 0.06513179693804048 Test RE 0.12198448313866837\n",
      "49 Train Loss 0.06629345 Test MSE 0.047858824173027066 Test RE 0.10456565746640832\n",
      "50 Train Loss 0.057577837 Test MSE 0.041465193712430445 Test RE 0.09733071406606919\n",
      "51 Train Loss 0.0503032 Test MSE 0.03404025507364347 Test RE 0.0881869785539513\n",
      "52 Train Loss 0.044750758 Test MSE 0.027461186037495446 Test RE 0.07920775522948395\n",
      "53 Train Loss 0.040291943 Test MSE 0.025294306723819222 Test RE 0.07601852708584286\n",
      "54 Train Loss 0.035570905 Test MSE 0.026495376873627224 Test RE 0.07780242094490701\n",
      "55 Train Loss 0.033594806 Test MSE 0.025649243667893167 Test RE 0.0765500258990547\n",
      "56 Train Loss 0.029874163 Test MSE 0.021997781295236232 Test RE 0.07089204430696644\n",
      "57 Train Loss 0.028601713 Test MSE 0.017650577933544652 Test RE 0.06350201779124351\n",
      "58 Train Loss 0.025956787 Test MSE 0.016934460501311005 Test RE 0.06220048098087032\n",
      "59 Train Loss 0.022360947 Test MSE 0.01449268537147317 Test RE 0.05754167400889838\n",
      "60 Train Loss 0.020718813 Test MSE 0.013282938954162203 Test RE 0.055087764484838056\n",
      "61 Train Loss 0.018066317 Test MSE 0.009287274885059354 Test RE 0.046062999036437284\n",
      "62 Train Loss 0.01639264 Test MSE 0.008061811154099329 Test RE 0.04291650733418968\n",
      "63 Train Loss 0.015221232 Test MSE 0.007715854953519217 Test RE 0.041985573304173\n",
      "64 Train Loss 0.013542001 Test MSE 0.006980054280643184 Test RE 0.03993350775509258\n",
      "65 Train Loss 0.012656584 Test MSE 0.007006535455451422 Test RE 0.040009186616108944\n",
      "66 Train Loss 0.011862044 Test MSE 0.007181588066062759 Test RE 0.040505901802632825\n",
      "67 Train Loss 0.011134694 Test MSE 0.007661370063011294 Test RE 0.041837071803733986\n",
      "68 Train Loss 0.010469864 Test MSE 0.007197000335860661 Test RE 0.04054934298145571\n",
      "69 Train Loss 0.010045611 Test MSE 0.00696389787274961 Test RE 0.03988726486142021\n",
      "70 Train Loss 0.009215916 Test MSE 0.006368431892537894 Test RE 0.038143831441872784\n",
      "71 Train Loss 0.008716763 Test MSE 0.005878533636667027 Test RE 0.03664734899869915\n",
      "72 Train Loss 0.0083487285 Test MSE 0.005356055327951895 Test RE 0.03498086847667945\n",
      "73 Train Loss 0.0076668146 Test MSE 0.005845867379011231 Test RE 0.036545384841253414\n",
      "74 Train Loss 0.007463694 Test MSE 0.005752208509987602 Test RE 0.03625144900439838\n",
      "75 Train Loss 0.0070745884 Test MSE 0.006126184261475725 Test RE 0.03741132482655367\n",
      "76 Train Loss 0.0067235464 Test MSE 0.00580298752405137 Test RE 0.036411106648378946\n",
      "77 Train Loss 0.0062874975 Test MSE 0.005426094777473765 Test RE 0.03520884251398726\n",
      "78 Train Loss 0.0060564084 Test MSE 0.0051634496350892135 Test RE 0.034346147675189204\n",
      "79 Train Loss 0.0057828636 Test MSE 0.005117824569813685 Test RE 0.03419406695541936\n",
      "80 Train Loss 0.0055545038 Test MSE 0.004979176019754536 Test RE 0.03372770572351873\n",
      "81 Train Loss 0.0053200684 Test MSE 0.004885319057298629 Test RE 0.033408311511509886\n",
      "82 Train Loss 0.0051035397 Test MSE 0.00469417252794385 Test RE 0.03274821130770348\n",
      "83 Train Loss 0.004842181 Test MSE 0.0044593215796681785 Test RE 0.03191849873286045\n",
      "84 Train Loss 0.0045238123 Test MSE 0.0046385693601644126 Test RE 0.03255367982517729\n",
      "85 Train Loss 0.0043759276 Test MSE 0.004823675216030537 Test RE 0.033196866315808884\n",
      "86 Train Loss 0.004198414 Test MSE 0.004923749118492773 Test RE 0.03353945631757622\n",
      "87 Train Loss 0.0039773555 Test MSE 0.0049918093224580766 Test RE 0.03377046605005147\n",
      "88 Train Loss 0.003772053 Test MSE 0.004923555589158403 Test RE 0.03353879717224988\n",
      "89 Train Loss 0.0035346064 Test MSE 0.0054812978563775275 Test RE 0.03538749015276701\n",
      "90 Train Loss 0.003396323 Test MSE 0.005655060806392661 Test RE 0.035944024351467825\n",
      "91 Train Loss 0.0030948448 Test MSE 0.005819691094629157 Test RE 0.036463472645367874\n",
      "92 Train Loss 0.0029344568 Test MSE 0.00608441295060423 Test RE 0.03728356234177864\n",
      "93 Train Loss 0.0028449285 Test MSE 0.006030524955550595 Test RE 0.03711808994179501\n",
      "94 Train Loss 0.0027923963 Test MSE 0.006169418405377958 Test RE 0.037543103668635974\n",
      "95 Train Loss 0.0027187748 Test MSE 0.0061571930609652 Test RE 0.03750588743965627\n",
      "96 Train Loss 0.0025727972 Test MSE 0.006570005850365303 Test RE 0.038742794093850404\n",
      "97 Train Loss 0.0024590997 Test MSE 0.007003189150646181 Test RE 0.039999631328503496\n",
      "98 Train Loss 0.0023814978 Test MSE 0.006733327963632494 Test RE 0.03922138670715618\n",
      "99 Train Loss 0.0022942754 Test MSE 0.006922384387459977 Test RE 0.03976819831699247\n",
      "Training time: 157.58\n",
      "8\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.596878 Test MSE 8.00570117684629 Test RE 1.3524080526207913\n",
      "1 Train Loss 43.16551 Test MSE 8.294052139723952 Test RE 1.3765482570640517\n",
      "2 Train Loss 31.812813 Test MSE 7.766129690905583 Test RE 1.3320188773037742\n",
      "3 Train Loss 24.226295 Test MSE 7.818018477824378 Test RE 1.3364613590050731\n",
      "4 Train Loss 19.722843 Test MSE 7.398578072859811 Test RE 1.300116262786378\n",
      "5 Train Loss 17.212141 Test MSE 7.1567603606141486 Test RE 1.2786930302349997\n",
      "6 Train Loss 15.467426 Test MSE 7.188338136755248 Test RE 1.2815109141618686\n",
      "7 Train Loss 14.03825 Test MSE 7.367862573425379 Test RE 1.2974147130550342\n",
      "8 Train Loss 12.795635 Test MSE 7.304891367199924 Test RE 1.2918584825126085\n",
      "9 Train Loss 12.01153 Test MSE 7.3549741887986055 Test RE 1.2962794517278833\n",
      "10 Train Loss 10.815887 Test MSE 7.17169297402397 Test RE 1.2800263345554626\n",
      "11 Train Loss 9.602545 Test MSE 7.176188490405003 Test RE 1.2804274586615314\n",
      "12 Train Loss 8.867983 Test MSE 7.135926149446394 Test RE 1.2768304572251146\n",
      "13 Train Loss 7.8205614 Test MSE 7.065131947833921 Test RE 1.2704810709654182\n",
      "14 Train Loss 7.0339613 Test MSE 6.919946802882381 Test RE 1.2573594152746523\n",
      "15 Train Loss 6.2470427 Test MSE 6.740147246553746 Test RE 1.2409170520006931\n",
      "16 Train Loss 5.3850822 Test MSE 6.272336604593406 Test RE 1.1970787972806722\n",
      "17 Train Loss 4.800762 Test MSE 6.144784272933071 Test RE 1.1848445645295023\n",
      "18 Train Loss 4.225121 Test MSE 5.917061873896979 Test RE 1.1626824460123704\n",
      "19 Train Loss 3.6348171 Test MSE 5.669477213356889 Test RE 1.13809775679555\n",
      "20 Train Loss 3.1116993 Test MSE 5.4706248399290525 Test RE 1.117960673985615\n",
      "21 Train Loss 2.6893797 Test MSE 5.214140768294193 Test RE 1.0914389195145344\n",
      "22 Train Loss 2.3564115 Test MSE 5.214897032809717 Test RE 1.0915180683747894\n",
      "23 Train Loss 2.178001 Test MSE 5.136221027776991 Test RE 1.0832530301368777\n",
      "24 Train Loss 2.040847 Test MSE 5.034110165058449 Test RE 1.0724311446885455\n",
      "25 Train Loss 1.9057207 Test MSE 4.974269227587515 Test RE 1.066038044480773\n",
      "26 Train Loss 1.8356445 Test MSE 4.913029290784739 Test RE 1.0594555416335134\n",
      "27 Train Loss 1.7409294 Test MSE 4.902689046825756 Test RE 1.0583400588697136\n",
      "28 Train Loss 1.6731147 Test MSE 4.857834048969212 Test RE 1.0534875258142538\n",
      "29 Train Loss 1.6101956 Test MSE 4.9040438454219375 Test RE 1.058486278482066\n",
      "30 Train Loss 1.5632122 Test MSE 4.847993775465718 Test RE 1.0524199862085952\n",
      "31 Train Loss 1.5292842 Test MSE 4.798948306692537 Test RE 1.047082970022692\n",
      "32 Train Loss 1.493907 Test MSE 4.794589044029708 Test RE 1.046607288013708\n",
      "33 Train Loss 1.4720134 Test MSE 4.779566286620308 Test RE 1.044966348338202\n",
      "34 Train Loss 1.4511327 Test MSE 4.7289639848229905 Test RE 1.0394199867981542\n",
      "35 Train Loss 1.4277332 Test MSE 4.687575453430294 Test RE 1.0348614185330849\n",
      "36 Train Loss 1.4092133 Test MSE 4.653865188272905 Test RE 1.0311336493930567\n",
      "37 Train Loss 1.3930256 Test MSE 4.6170946731198095 Test RE 1.0270520415068563\n",
      "38 Train Loss 1.3684518 Test MSE 4.543422684309484 Test RE 1.0188250894433704\n",
      "39 Train Loss 1.3458581 Test MSE 4.421556282959429 Test RE 1.0050684471743623\n",
      "40 Train Loss 1.304951 Test MSE 4.250795111300136 Test RE 0.9854694068891878\n",
      "41 Train Loss 1.2484045 Test MSE 4.015391845657103 Test RE 0.9577938114574498\n",
      "42 Train Loss 1.1705624 Test MSE 3.880943613636932 Test RE 0.9416222817503805\n",
      "43 Train Loss 1.0886813 Test MSE 3.7257162173258687 Test RE 0.9225989295567467\n",
      "44 Train Loss 1.0360148 Test MSE 3.621969556502583 Test RE 0.9096628485670226\n",
      "45 Train Loss 0.987461 Test MSE 3.5090095765215654 Test RE 0.8953654603476322\n",
      "46 Train Loss 0.9395305 Test MSE 3.434525659123635 Test RE 0.8858117625961852\n",
      "47 Train Loss 0.8881291 Test MSE 3.3237562295421945 Test RE 0.8714102066608826\n",
      "48 Train Loss 0.81550235 Test MSE 3.2600352148851863 Test RE 0.8630167123992635\n",
      "49 Train Loss 0.78 Test MSE 3.2684003751092514 Test RE 0.8641232415343924\n",
      "50 Train Loss 0.74833477 Test MSE 3.2516188440538993 Test RE 0.8619019755548746\n",
      "51 Train Loss 0.72471386 Test MSE 3.257396506357897 Test RE 0.862667374063572\n",
      "52 Train Loss 0.7016388 Test MSE 3.2363496392277673 Test RE 0.8598759010190363\n",
      "53 Train Loss 0.6866219 Test MSE 3.21012971705343 Test RE 0.8563855905437175\n",
      "54 Train Loss 0.6703126 Test MSE 3.1847716048945482 Test RE 0.8529964161948563\n",
      "55 Train Loss 0.65821385 Test MSE 3.160865659109042 Test RE 0.849788949601683\n",
      "56 Train Loss 0.64780056 Test MSE 3.181920584602342 Test RE 0.8526145278051716\n",
      "57 Train Loss 0.64090234 Test MSE 3.2071683089657035 Test RE 0.8559904830854776\n",
      "58 Train Loss 0.6311539 Test MSE 3.2094683834547655 Test RE 0.856297372031259\n",
      "59 Train Loss 0.62199956 Test MSE 3.2147739697590527 Test RE 0.8570048542429375\n",
      "60 Train Loss 0.614791 Test MSE 3.2124154114939985 Test RE 0.8566904205106814\n",
      "61 Train Loss 0.60295653 Test MSE 3.213108428094151 Test RE 0.8567828227361329\n",
      "62 Train Loss 0.5933031 Test MSE 3.215807768018205 Test RE 0.8571426398103241\n",
      "63 Train Loss 0.58645076 Test MSE 3.2215250489690863 Test RE 0.8579042445847251\n",
      "64 Train Loss 0.5813021 Test MSE 3.2207168688656673 Test RE 0.857796627133294\n",
      "65 Train Loss 0.5757105 Test MSE 3.2346961739826465 Test RE 0.8596562157686568\n",
      "66 Train Loss 0.56895375 Test MSE 3.2601871935474067 Test RE 0.8630368285311738\n",
      "67 Train Loss 0.5624486 Test MSE 3.287540799439619 Test RE 0.8666497895880606\n",
      "68 Train Loss 0.55593055 Test MSE 3.320893705698271 Test RE 0.8710348828367952\n",
      "69 Train Loss 0.5481722 Test MSE 3.3359486860664447 Test RE 0.8730070303500591\n",
      "70 Train Loss 0.5425848 Test MSE 3.3635972261608 Test RE 0.8766173321485186\n",
      "71 Train Loss 0.5374587 Test MSE 3.3893395778612456 Test RE 0.8799654113888712\n",
      "72 Train Loss 0.53311706 Test MSE 3.3958424161598417 Test RE 0.8808091643630525\n",
      "73 Train Loss 0.52912724 Test MSE 3.4142395487840225 Test RE 0.8831918537385287\n",
      "74 Train Loss 0.523196 Test MSE 3.43963943664918 Test RE 0.8864709743518481\n",
      "75 Train Loss 0.51975465 Test MSE 3.446252308357019 Test RE 0.8873227066464824\n",
      "76 Train Loss 0.5162595 Test MSE 3.4795422216697127 Test RE 0.8915980616232743\n",
      "77 Train Loss 0.5113414 Test MSE 3.4971410119943207 Test RE 0.8938499752166229\n",
      "78 Train Loss 0.50426924 Test MSE 3.507618138212198 Test RE 0.8951879217424364\n",
      "79 Train Loss 0.50118643 Test MSE 3.5201991659233998 Test RE 0.8967919023890796\n",
      "80 Train Loss 0.49710488 Test MSE 3.543308394566259 Test RE 0.8997306946389096\n",
      "81 Train Loss 0.49203712 Test MSE 3.562840225393128 Test RE 0.9022070860181965\n",
      "82 Train Loss 0.48826542 Test MSE 3.577272305438257 Test RE 0.9040325349381514\n",
      "83 Train Loss 0.48468003 Test MSE 3.575380579863603 Test RE 0.9037934690418401\n",
      "84 Train Loss 0.48139825 Test MSE 3.5824069631474553 Test RE 0.9046811063536957\n",
      "85 Train Loss 0.47693378 Test MSE 3.5962106533808202 Test RE 0.9064223841322363\n",
      "86 Train Loss 0.4707205 Test MSE 3.598288911461481 Test RE 0.9066842580523653\n",
      "87 Train Loss 0.46657583 Test MSE 3.643121007362679 Test RE 0.9123150906949313\n",
      "88 Train Loss 0.46124256 Test MSE 3.6471168487165384 Test RE 0.9128152754683925\n",
      "89 Train Loss 0.45563656 Test MSE 3.6650896481278523 Test RE 0.9150616641074211\n",
      "90 Train Loss 0.45082563 Test MSE 3.6828730688533793 Test RE 0.9172789679604154\n",
      "91 Train Loss 0.4474852 Test MSE 3.696022338314716 Test RE 0.9189150277952133\n",
      "92 Train Loss 0.44409287 Test MSE 3.706490570452104 Test RE 0.9202154277000597\n",
      "93 Train Loss 0.4384359 Test MSE 3.717013156823546 Test RE 0.9215207303066588\n",
      "94 Train Loss 0.4326505 Test MSE 3.7368781715219015 Test RE 0.9239799130937665\n",
      "95 Train Loss 0.42992094 Test MSE 3.742856762411065 Test RE 0.9247187504221934\n",
      "96 Train Loss 0.4267828 Test MSE 3.7474490683216466 Test RE 0.9252858693182835\n",
      "97 Train Loss 0.4231125 Test MSE 3.76984405712749 Test RE 0.9280465339501317\n",
      "98 Train Loss 0.41870692 Test MSE 3.7748657276443915 Test RE 0.9286644365625341\n",
      "99 Train Loss 0.4152892 Test MSE 3.770285922203529 Test RE 0.9281009207272266\n",
      "Training time: 158.57\n",
      "9\n",
      "KG_rowdy_tune30\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.669292 Test MSE 8.976222339607133 Test RE 1.4320390505882887\n",
      "1 Train Loss 49.11561 Test MSE 8.187589710210204 Test RE 1.3676850383978023\n",
      "2 Train Loss 43.270805 Test MSE 8.822934707623382 Test RE 1.4197588775450687\n",
      "3 Train Loss 40.16039 Test MSE 8.990781059802508 Test RE 1.43319990691461\n",
      "4 Train Loss 37.10791 Test MSE 9.018039028589639 Test RE 1.435370828050944\n",
      "5 Train Loss 34.03715 Test MSE 9.1296537205502 Test RE 1.4442261788891029\n",
      "6 Train Loss 31.534462 Test MSE 9.211678606384298 Test RE 1.4506994581453085\n",
      "7 Train Loss 28.88456 Test MSE 9.358299487777055 Test RE 1.4621991598973472\n",
      "8 Train Loss 26.745752 Test MSE 9.356445901358088 Test RE 1.4620543447667524\n",
      "9 Train Loss 25.043991 Test MSE 9.332648869169633 Test RE 1.4601938784340853\n",
      "10 Train Loss 23.653893 Test MSE 9.33170044699987 Test RE 1.4601196810946173\n",
      "11 Train Loss 22.383745 Test MSE 9.279825215670758 Test RE 1.456055598338265\n",
      "12 Train Loss 20.97618 Test MSE 9.128300436942867 Test RE 1.4441191364916015\n",
      "13 Train Loss 19.717098 Test MSE 9.010111505095297 Test RE 1.434739790762361\n",
      "14 Train Loss 18.8038 Test MSE 8.911941614823412 Test RE 1.4269022625571066\n",
      "15 Train Loss 17.8912 Test MSE 8.776486986663901 Test RE 1.416016835599837\n",
      "16 Train Loss 16.855371 Test MSE 8.644886429241431 Test RE 1.4053603820991172\n",
      "17 Train Loss 15.78444 Test MSE 8.600706533923889 Test RE 1.401764718649364\n",
      "18 Train Loss 14.778924 Test MSE 8.534487818652309 Test RE 1.3963580456172622\n",
      "19 Train Loss 13.753649 Test MSE 8.312563111761692 Test RE 1.3780835165616288\n",
      "20 Train Loss 12.84873 Test MSE 8.065501273608751 Test RE 1.3574496889443473\n",
      "21 Train Loss 11.505102 Test MSE 7.705361424677821 Test RE 1.3267972645610204\n",
      "22 Train Loss 10.37949 Test MSE 7.426706730581946 Test RE 1.3025853745224198\n",
      "23 Train Loss 9.50404 Test MSE 7.363364384212615 Test RE 1.297018607140716\n",
      "24 Train Loss 8.681103 Test MSE 7.161183757918846 Test RE 1.2790881317409912\n",
      "25 Train Loss 7.4511 Test MSE 7.010861341149719 Test RE 1.2655920824124214\n",
      "26 Train Loss 6.421158 Test MSE 6.967831970437036 Test RE 1.2617023002248164\n",
      "27 Train Loss 5.361471 Test MSE 6.669659329266979 Test RE 1.2344112928052997\n",
      "28 Train Loss 4.2790666 Test MSE 6.092215337042945 Test RE 1.1797654760641376\n",
      "29 Train Loss 3.5182137 Test MSE 5.883900301274628 Test RE 1.1594198004265164\n",
      "30 Train Loss 3.0643692 Test MSE 5.752626204260457 Test RE 1.1464130942461548\n",
      "31 Train Loss 2.6472998 Test MSE 5.747658597613081 Test RE 1.1459180021714837\n",
      "32 Train Loss 2.4285767 Test MSE 5.662521789691613 Test RE 1.1373994224408999\n",
      "33 Train Loss 2.249343 Test MSE 5.680692835354339 Test RE 1.1392229194141115\n",
      "34 Train Loss 2.031271 Test MSE 5.657095008049074 Test RE 1.1368542679932097\n",
      "35 Train Loss 1.8743119 Test MSE 5.599709399615119 Test RE 1.1310734419087578\n",
      "36 Train Loss 1.7899613 Test MSE 5.524953055513184 Test RE 1.1234981364934857\n",
      "37 Train Loss 1.7075655 Test MSE 5.450011421441344 Test RE 1.1158524375969452\n",
      "38 Train Loss 1.619014 Test MSE 5.56081630545625 Test RE 1.1271386307827664\n",
      "39 Train Loss 1.562251 Test MSE 5.597707168546427 Test RE 1.1308712106231935\n",
      "40 Train Loss 1.5128565 Test MSE 5.575012969123771 Test RE 1.1285764959478182\n",
      "41 Train Loss 1.475574 Test MSE 5.565072574482183 Test RE 1.1275699062774023\n",
      "42 Train Loss 1.4396905 Test MSE 5.559759968786617 Test RE 1.127031569665205\n",
      "43 Train Loss 1.4144229 Test MSE 5.5565028878480085 Test RE 1.1267013961646348\n",
      "44 Train Loss 1.3805171 Test MSE 5.553886537596647 Test RE 1.126436104070853\n",
      "45 Train Loss 1.3590853 Test MSE 5.545725792840286 Test RE 1.1256082210397265\n",
      "46 Train Loss 1.3334159 Test MSE 5.5365061392662644 Test RE 1.1246721817348801\n",
      "47 Train Loss 1.3087461 Test MSE 5.570232179953011 Test RE 1.1280924931727714\n",
      "48 Train Loss 1.2862349 Test MSE 5.523659087434811 Test RE 1.1233665647099829\n",
      "49 Train Loss 1.2685829 Test MSE 5.5347268094947095 Test RE 1.1244914428848014\n",
      "50 Train Loss 1.243963 Test MSE 5.558304271747699 Test RE 1.1268840161798426\n",
      "51 Train Loss 1.2185111 Test MSE 5.5361749021560165 Test RE 1.1246385378874597\n",
      "52 Train Loss 1.1933349 Test MSE 5.5452216171805 Test RE 1.1255570539619093\n",
      "53 Train Loss 1.1735778 Test MSE 5.568549099753263 Test RE 1.12792205022508\n",
      "54 Train Loss 1.1583301 Test MSE 5.594692069584401 Test RE 1.1305666084195232\n",
      "55 Train Loss 1.1466012 Test MSE 5.6112563823416055 Test RE 1.132239016637238\n",
      "56 Train Loss 1.1301323 Test MSE 5.628575357532048 Test RE 1.1339849814080172\n",
      "57 Train Loss 1.1162477 Test MSE 5.626810538939357 Test RE 1.1338071891115868\n",
      "58 Train Loss 1.097396 Test MSE 5.662969027636862 Test RE 1.1374443386598208\n",
      "59 Train Loss 1.0826848 Test MSE 5.688416142156097 Test RE 1.1399970837491895\n",
      "60 Train Loss 1.0664139 Test MSE 5.737713750242726 Test RE 1.144926214545248\n",
      "61 Train Loss 1.053571 Test MSE 5.770671107742517 Test RE 1.1482097272585985\n",
      "62 Train Loss 1.0394375 Test MSE 5.767311401875799 Test RE 1.147875432639098\n",
      "63 Train Loss 1.0338476 Test MSE 5.774785112488873 Test RE 1.1486189429782123\n",
      "64 Train Loss 1.0263872 Test MSE 5.773417545979154 Test RE 1.1484829287562113\n",
      "65 Train Loss 1.0160122 Test MSE 5.810654175618362 Test RE 1.1521806432003885\n",
      "66 Train Loss 1.005552 Test MSE 5.833695071373908 Test RE 1.154462745048623\n",
      "67 Train Loss 0.9952387 Test MSE 5.841337996136916 Test RE 1.1552187482080432\n",
      "68 Train Loss 0.98462355 Test MSE 5.888798554484016 Test RE 1.1599022992804051\n",
      "69 Train Loss 0.9752463 Test MSE 5.891800841587065 Test RE 1.1601979381906018\n",
      "70 Train Loss 0.9646776 Test MSE 5.918031229717077 Test RE 1.1627776796658482\n",
      "71 Train Loss 0.9559039 Test MSE 5.942218509016642 Test RE 1.1651514209922018\n",
      "72 Train Loss 0.9480367 Test MSE 5.9196000856666116 Test RE 1.1629317942460304\n",
      "73 Train Loss 0.94292367 Test MSE 5.934472370926551 Test RE 1.1643917411654594\n",
      "74 Train Loss 0.9339175 Test MSE 5.93280563159017 Test RE 1.1642282157765695\n",
      "75 Train Loss 0.92549574 Test MSE 5.943946524096929 Test RE 1.1653208234526533\n",
      "76 Train Loss 0.92070645 Test MSE 5.950745784851127 Test RE 1.1659871362751986\n",
      "77 Train Loss 0.9148253 Test MSE 5.970493083724358 Test RE 1.167920173491897\n",
      "78 Train Loss 0.90856034 Test MSE 5.9942238258798435 Test RE 1.170238920586711\n",
      "79 Train Loss 0.9030317 Test MSE 6.002425608087712 Test RE 1.171039254714645\n",
      "80 Train Loss 0.89949423 Test MSE 5.998468597227751 Test RE 1.1706531958697384\n",
      "81 Train Loss 0.89584756 Test MSE 5.999687230918222 Test RE 1.1707721033002434\n",
      "82 Train Loss 0.89064986 Test MSE 6.0065996597985345 Test RE 1.1714463508830193\n",
      "83 Train Loss 0.88276446 Test MSE 6.021301970471717 Test RE 1.1728791450517126\n",
      "84 Train Loss 0.8743322 Test MSE 6.0359525380662 Test RE 1.1743051577046177\n",
      "85 Train Loss 0.8695049 Test MSE 6.0472522236923 Test RE 1.1754038305819206\n",
      "86 Train Loss 0.8619293 Test MSE 6.069920646472313 Test RE 1.1776047994742254\n",
      "87 Train Loss 0.85107493 Test MSE 6.0736692213715955 Test RE 1.177968367527564\n",
      "88 Train Loss 0.8366157 Test MSE 6.111701644206215 Test RE 1.1816507441796162\n",
      "89 Train Loss 0.8210042 Test MSE 6.133078332108493 Test RE 1.183715449855369\n",
      "90 Train Loss 0.80621654 Test MSE 6.157296218482175 Test RE 1.1860502351609208\n",
      "91 Train Loss 0.7965612 Test MSE 6.17717378877095 Test RE 1.1879631527242733\n",
      "92 Train Loss 0.78442496 Test MSE 6.209089619372436 Test RE 1.1910281452404108\n",
      "93 Train Loss 0.77321285 Test MSE 6.262863959085847 Test RE 1.196174526006246\n",
      "94 Train Loss 0.76626694 Test MSE 6.280861187120853 Test RE 1.1978919816480444\n",
      "95 Train Loss 0.7611518 Test MSE 6.262788474872716 Test RE 1.196167317437968\n",
      "96 Train Loss 0.75665915 Test MSE 6.269989898287625 Test RE 1.196854841254131\n",
      "97 Train Loss 0.7529615 Test MSE 6.266043558887829 Test RE 1.1964781310103552\n",
      "98 Train Loss 0.74871135 Test MSE 6.270249474468446 Test RE 1.1968796157592205\n",
      "99 Train Loss 0.7458394 Test MSE 6.275157632805203 Test RE 1.1973479643909857\n",
      "Training time: 152.93\n",
      "0\n",
      "KG_rowdy_tune31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.89423 Test MSE 4.470936837832523 Test RE 1.0106652361608746\n",
      "1 Train Loss 58.728413 Test MSE 5.8062570058515774 Test RE 1.1517446085838414\n",
      "2 Train Loss 42.41483 Test MSE 7.7130007446258215 Test RE 1.3274548143667437\n",
      "3 Train Loss 31.253365 Test MSE 7.252745784224186 Test RE 1.287239292357491\n",
      "4 Train Loss 25.811277 Test MSE 6.7465925445225015 Test RE 1.241510226654394\n",
      "5 Train Loss 19.53245 Test MSE 6.139173425333014 Test RE 1.184303495855682\n",
      "6 Train Loss 15.682455 Test MSE 6.120820730533462 Test RE 1.1825319683696889\n",
      "7 Train Loss 12.615099 Test MSE 6.040268837844672 Test RE 1.1747249545169323\n",
      "8 Train Loss 11.209216 Test MSE 5.988344654334758 Test RE 1.1696648910387812\n",
      "9 Train Loss 9.934746 Test MSE 5.782720563556785 Test RE 1.1494078624011055\n",
      "10 Train Loss 8.696803 Test MSE 5.7007639621456025 Test RE 1.1412337063668994\n",
      "11 Train Loss 7.7702055 Test MSE 5.405352810123543 Test RE 1.1112712613993354\n",
      "12 Train Loss 6.942586 Test MSE 5.32540277461267 Test RE 1.103022294033386\n",
      "13 Train Loss 6.4281893 Test MSE 5.125982558272564 Test RE 1.082172821004786\n",
      "14 Train Loss 5.986258 Test MSE 4.917925788019403 Test RE 1.0599833554246918\n",
      "15 Train Loss 5.6318474 Test MSE 4.758384066372854 Test RE 1.0426482210420405\n",
      "16 Train Loss 5.2912264 Test MSE 4.480334238355923 Test RE 1.0117268302819034\n",
      "17 Train Loss 5.0926657 Test MSE 4.409754217299614 Test RE 1.0037261811151703\n",
      "18 Train Loss 4.8963547 Test MSE 4.251875682975077 Test RE 0.985594654358731\n",
      "19 Train Loss 4.722562 Test MSE 4.036050928745336 Test RE 0.9602545620985281\n",
      "20 Train Loss 4.5912614 Test MSE 3.8551537576687704 Test RE 0.938488407119422\n",
      "21 Train Loss 4.39359 Test MSE 3.5758009831327464 Test RE 0.9038466027645394\n",
      "22 Train Loss 4.1616764 Test MSE 3.307303606334363 Test RE 0.8692507868815841\n",
      "23 Train Loss 3.8433542 Test MSE 3.097858923956627 Test RE 0.8412767339011644\n",
      "24 Train Loss 3.3097172 Test MSE 2.797339726749219 Test RE 0.7994304140332504\n",
      "25 Train Loss 2.8663614 Test MSE 2.59819447978157 Test RE 0.7704489863912939\n",
      "26 Train Loss 2.365071 Test MSE 2.32978482208582 Test RE 0.7295683178272535\n",
      "27 Train Loss 2.0875912 Test MSE 2.16281085566815 Test RE 0.7029385005432849\n",
      "28 Train Loss 1.8182209 Test MSE 1.8685139943711706 Test RE 0.6533655590524059\n",
      "29 Train Loss 1.6538091 Test MSE 1.7836482533372404 Test RE 0.6383555913543558\n",
      "30 Train Loss 1.5174105 Test MSE 1.6490348032389277 Test RE 0.6137944696695073\n",
      "31 Train Loss 1.3615162 Test MSE 1.4644722858517225 Test RE 0.5784271093027599\n",
      "32 Train Loss 1.1907362 Test MSE 1.274655450680757 Test RE 0.5396404105273463\n",
      "33 Train Loss 1.0632553 Test MSE 1.0921591497626797 Test RE 0.4995178642784959\n",
      "34 Train Loss 0.9741284 Test MSE 0.9789483643495163 Test RE 0.4729202960965051\n",
      "35 Train Loss 0.88144386 Test MSE 0.8327317027988806 Test RE 0.4361748393116325\n",
      "36 Train Loss 0.70466954 Test MSE 0.5874849892175565 Test RE 0.3663586478902139\n",
      "37 Train Loss 0.5621452 Test MSE 0.2910659751201837 Test RE 0.257871757710588\n",
      "38 Train Loss 0.4464789 Test MSE 0.254371295436743 Test RE 0.24106941341902685\n",
      "39 Train Loss 0.33936244 Test MSE 0.21590327561598124 Test RE 0.22209443466927534\n",
      "40 Train Loss 0.25992697 Test MSE 0.19153944524298003 Test RE 0.20918819514815626\n",
      "41 Train Loss 0.20497654 Test MSE 0.15711670830835264 Test RE 0.1894607473861472\n",
      "42 Train Loss 0.15835804 Test MSE 0.12209294480692397 Test RE 0.1670141796399977\n",
      "43 Train Loss 0.13096233 Test MSE 0.11560994186232143 Test RE 0.1625195651689562\n",
      "44 Train Loss 0.114584915 Test MSE 0.11716144310380615 Test RE 0.16360644819505565\n",
      "45 Train Loss 0.097516954 Test MSE 0.11029312719259451 Test RE 0.15873850492834551\n",
      "46 Train Loss 0.0855239 Test MSE 0.09689272708429027 Test RE 0.14878311600493116\n",
      "47 Train Loss 0.06731155 Test MSE 0.08165437787506963 Test RE 0.1365833616031907\n",
      "48 Train Loss 0.061638657 Test MSE 0.07265250229540063 Test RE 0.12883484778942503\n",
      "49 Train Loss 0.05671913 Test MSE 0.07706332672886602 Test RE 0.13268808822390316\n",
      "50 Train Loss 0.048739243 Test MSE 0.06770328512366032 Test RE 0.12436922595124143\n",
      "51 Train Loss 0.042158604 Test MSE 0.057342076780413156 Test RE 0.11445763532972528\n",
      "52 Train Loss 0.037615944 Test MSE 0.058853088629601646 Test RE 0.11595585703323255\n",
      "53 Train Loss 0.032698587 Test MSE 0.05555445389268487 Test RE 0.11265941756839216\n",
      "54 Train Loss 0.030275136 Test MSE 0.049731426947827444 Test RE 0.10659173237502423\n",
      "55 Train Loss 0.027077291 Test MSE 0.04440075665293434 Test RE 0.10071710775935101\n",
      "56 Train Loss 0.024871923 Test MSE 0.040624553620371984 Test RE 0.0963390504147031\n",
      "57 Train Loss 0.021309465 Test MSE 0.04416110243678177 Test RE 0.100444928410078\n",
      "58 Train Loss 0.02043917 Test MSE 0.04234222268331593 Test RE 0.09835464749330952\n",
      "59 Train Loss 0.019443259 Test MSE 0.04105999058770454 Test RE 0.0968539825038227\n",
      "60 Train Loss 0.018070854 Test MSE 0.03954256592119261 Test RE 0.09504745309317975\n",
      "61 Train Loss 0.016745776 Test MSE 0.03698352362776706 Test RE 0.09192046306384327\n",
      "62 Train Loss 0.014793997 Test MSE 0.03325896888012744 Test RE 0.08716907764827436\n",
      "63 Train Loss 0.013860855 Test MSE 0.029730021550252658 Test RE 0.08241488790837993\n",
      "64 Train Loss 0.013215928 Test MSE 0.029559930605396734 Test RE 0.08217879434180399\n",
      "65 Train Loss 0.012783475 Test MSE 0.03011011967248215 Test RE 0.0829400515751394\n",
      "66 Train Loss 0.012323201 Test MSE 0.02992841309980162 Test RE 0.08268941227950664\n",
      "67 Train Loss 0.011604773 Test MSE 0.029180830245594713 Test RE 0.08165013034320732\n",
      "68 Train Loss 0.010736513 Test MSE 0.027523040384286906 Test RE 0.07929690994045599\n",
      "69 Train Loss 0.010235878 Test MSE 0.026952964884564595 Test RE 0.07847138773887855\n",
      "70 Train Loss 0.009396843 Test MSE 0.023862522377561382 Test RE 0.07383567246585648\n",
      "71 Train Loss 0.009018324 Test MSE 0.022191742925036624 Test RE 0.07120389755394899\n",
      "72 Train Loss 0.00854111 Test MSE 0.020030755558339473 Test RE 0.06764827485844156\n",
      "73 Train Loss 0.007995978 Test MSE 0.019234776855559396 Test RE 0.06629055216438905\n",
      "74 Train Loss 0.00750828 Test MSE 0.018309909668787875 Test RE 0.06467719269456333\n",
      "75 Train Loss 0.007237022 Test MSE 0.01800425470391308 Test RE 0.06413507905332676\n",
      "76 Train Loss 0.006996138 Test MSE 0.018164145896734353 Test RE 0.06441923321019742\n",
      "77 Train Loss 0.006725273 Test MSE 0.017963738579905214 Test RE 0.06406287477712981\n",
      "78 Train Loss 0.006390466 Test MSE 0.016918419618844154 Test RE 0.06217101482243254\n",
      "79 Train Loss 0.006121207 Test MSE 0.015531519987135717 Test RE 0.0595682772502788\n",
      "80 Train Loss 0.0059146173 Test MSE 0.014540092652684352 Test RE 0.057635709968298025\n",
      "81 Train Loss 0.005686879 Test MSE 0.014532946890874143 Test RE 0.05762154562702598\n",
      "82 Train Loss 0.005297115 Test MSE 0.014423613143492805 Test RE 0.05740438825049998\n",
      "83 Train Loss 0.0051538832 Test MSE 0.014063498940258667 Test RE 0.056683251254155985\n",
      "84 Train Loss 0.0050210967 Test MSE 0.014133921436003335 Test RE 0.05682499376570494\n",
      "85 Train Loss 0.0046574846 Test MSE 0.012885928073881898 Test RE 0.05425826617186111\n",
      "86 Train Loss 0.0045232996 Test MSE 0.012746724003580743 Test RE 0.053964399843826526\n",
      "87 Train Loss 0.004428257 Test MSE 0.0126107210488668 Test RE 0.05367573744174946\n",
      "88 Train Loss 0.004287813 Test MSE 0.01256067458386845 Test RE 0.053569123736777094\n",
      "89 Train Loss 0.0041507254 Test MSE 0.012599691791473142 Test RE 0.05365226007598184\n",
      "90 Train Loss 0.004081122 Test MSE 0.01271364595490916 Test RE 0.05389433491567809\n",
      "91 Train Loss 0.003951964 Test MSE 0.011850586058164749 Test RE 0.0520328931683477\n",
      "92 Train Loss 0.003878929 Test MSE 0.011382614715777268 Test RE 0.05099517402950126\n",
      "93 Train Loss 0.003775003 Test MSE 0.011056465327029573 Test RE 0.05025927441199905\n",
      "94 Train Loss 0.0036858504 Test MSE 0.011254518433225105 Test RE 0.050707420529667126\n",
      "95 Train Loss 0.0035690707 Test MSE 0.010445950615657493 Test RE 0.04885196580643392\n",
      "96 Train Loss 0.003406336 Test MSE 0.01002151423059474 Test RE 0.04784920582993214\n",
      "97 Train Loss 0.003218627 Test MSE 0.009267004065320815 Test RE 0.04601270199983617\n",
      "98 Train Loss 0.003144729 Test MSE 0.009541783272008919 Test RE 0.046689888227248906\n",
      "99 Train Loss 0.0031032828 Test MSE 0.009653805616579124 Test RE 0.046963162564213165\n",
      "Training time: 160.00\n",
      "1\n",
      "KG_rowdy_tune31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.02074 Test MSE 5.6870742747681735 Test RE 1.1398626161667438\n",
      "1 Train Loss 56.48806 Test MSE 7.431385828204417 Test RE 1.3029956481905427\n",
      "2 Train Loss 49.127995 Test MSE 8.251247614944424 Test RE 1.3729915689322696\n",
      "3 Train Loss 42.737 Test MSE 8.9943063013762 Test RE 1.433480854738037\n",
      "4 Train Loss 37.860146 Test MSE 9.31508658253208 Test RE 1.4588193265989329\n",
      "5 Train Loss 33.816742 Test MSE 9.076468163613205 Test RE 1.440013304463738\n",
      "6 Train Loss 30.735695 Test MSE 9.092698830904398 Test RE 1.4413002553485736\n",
      "7 Train Loss 28.038109 Test MSE 9.251228722081287 Test RE 1.453810393774922\n",
      "8 Train Loss 26.246433 Test MSE 9.212873610379194 Test RE 1.4507935525824989\n",
      "9 Train Loss 23.218922 Test MSE 8.480258725386218 Test RE 1.391914668084589\n",
      "10 Train Loss 20.589653 Test MSE 8.503354331257803 Test RE 1.3938087880383274\n",
      "11 Train Loss 18.227997 Test MSE 8.465705532425673 Test RE 1.3907198047155862\n",
      "12 Train Loss 16.795658 Test MSE 8.127621746349242 Test RE 1.3626671991330357\n",
      "13 Train Loss 15.618237 Test MSE 7.850090056704688 Test RE 1.339199812342065\n",
      "14 Train Loss 14.763025 Test MSE 8.001311031059867 Test RE 1.3520371867483445\n",
      "15 Train Loss 14.1369095 Test MSE 8.022573219973337 Test RE 1.353832404900689\n",
      "16 Train Loss 13.826279 Test MSE 8.0228146111713 Test RE 1.3538527724784502\n",
      "17 Train Loss 13.528082 Test MSE 8.19660371004961 Test RE 1.3684376971076975\n",
      "18 Train Loss 13.088711 Test MSE 8.243810989972895 Test RE 1.372372709488503\n",
      "19 Train Loss 12.617334 Test MSE 8.27055615937754 Test RE 1.374597082361571\n",
      "20 Train Loss 12.084564 Test MSE 8.295083679290343 Test RE 1.3766338557449165\n",
      "21 Train Loss 11.444113 Test MSE 8.283073476745669 Test RE 1.3756369013405014\n",
      "22 Train Loss 9.9363365 Test MSE 7.028841274373539 Test RE 1.2672139009925443\n",
      "23 Train Loss 8.528389 Test MSE 6.591930882615095 Test RE 1.2271972765900174\n",
      "24 Train Loss 7.759998 Test MSE 6.349394918326764 Test RE 1.2044096605270214\n",
      "25 Train Loss 7.3234453 Test MSE 6.202621587483154 Test RE 1.1904076343634737\n",
      "26 Train Loss 7.17959 Test MSE 6.128033671087479 Test RE 1.18322852703298\n",
      "27 Train Loss 6.9973183 Test MSE 6.1343198263801755 Test RE 1.1838352511613501\n",
      "28 Train Loss 6.8414736 Test MSE 6.248369680163252 Test RE 1.1947895581862296\n",
      "29 Train Loss 6.727519 Test MSE 6.27414106824714 Test RE 1.1972509763251233\n",
      "30 Train Loss 6.6109056 Test MSE 6.325487540779778 Test RE 1.2021400401325846\n",
      "31 Train Loss 6.465634 Test MSE 6.409294521276923 Test RE 1.2100774690437621\n",
      "32 Train Loss 6.327114 Test MSE 6.503924035797297 Test RE 1.2189777832559228\n",
      "33 Train Loss 6.164853 Test MSE 6.461549124945677 Test RE 1.215000300965715\n",
      "34 Train Loss 5.9959497 Test MSE 6.475846657066782 Test RE 1.2163437796413923\n",
      "35 Train Loss 5.81149 Test MSE 6.402702426804809 Test RE 1.2094550138626567\n",
      "36 Train Loss 5.6300554 Test MSE 6.407651349777658 Test RE 1.2099223433696613\n",
      "37 Train Loss 5.4734025 Test MSE 6.34113805210209 Test RE 1.2036262878806268\n",
      "38 Train Loss 5.305602 Test MSE 6.312472583308329 Test RE 1.2009026763989215\n",
      "39 Train Loss 5.1305027 Test MSE 6.320329595012524 Test RE 1.2016498140725997\n",
      "40 Train Loss 4.9216805 Test MSE 6.354415021359968 Test RE 1.204885695332857\n",
      "41 Train Loss 4.6070995 Test MSE 6.340306439939065 Test RE 1.2035473601651117\n",
      "42 Train Loss 4.2573867 Test MSE 6.241667612712058 Test RE 1.1941486143064857\n",
      "43 Train Loss 3.8315973 Test MSE 6.098430521784411 Test RE 1.1803671119894272\n",
      "44 Train Loss 3.2431316 Test MSE 6.007175135713895 Test RE 1.1715024660774027\n",
      "45 Train Loss 2.594432 Test MSE 5.833305761595387 Test RE 1.1544242230545256\n",
      "46 Train Loss 2.2669277 Test MSE 5.866452778402343 Test RE 1.1576995110788293\n",
      "47 Train Loss 1.9560555 Test MSE 5.798242701867124 Test RE 1.1509494647623801\n",
      "48 Train Loss 1.8171297 Test MSE 5.668926550930237 Test RE 1.1380424851305158\n",
      "49 Train Loss 1.7031257 Test MSE 5.763469402376734 Test RE 1.1474930298826131\n",
      "50 Train Loss 1.5861894 Test MSE 5.7807182602278 Test RE 1.1492088503251745\n",
      "51 Train Loss 1.5217462 Test MSE 5.7997482233095905 Test RE 1.1510988778451436\n",
      "52 Train Loss 1.4521924 Test MSE 5.775278365133071 Test RE 1.1486679965119913\n",
      "53 Train Loss 1.4160715 Test MSE 5.767316424549821 Test RE 1.147875932473636\n",
      "54 Train Loss 1.3870382 Test MSE 5.790718506129827 Test RE 1.1502024470219887\n",
      "55 Train Loss 1.3317392 Test MSE 5.851445741381083 Test RE 1.1562178009860817\n",
      "56 Train Loss 1.2959458 Test MSE 5.872146347290245 Test RE 1.158261165936048\n",
      "57 Train Loss 1.2500585 Test MSE 5.824955408728829 Test RE 1.153597650409709\n",
      "58 Train Loss 1.2199168 Test MSE 5.785445004071895 Test RE 1.1496785935009692\n",
      "59 Train Loss 1.1943579 Test MSE 5.788728395823167 Test RE 1.150004783602065\n",
      "60 Train Loss 1.1714014 Test MSE 5.78844546002625 Test RE 1.1499766788549062\n",
      "61 Train Loss 1.1506549 Test MSE 5.768283091804252 Test RE 1.1479721269167993\n",
      "62 Train Loss 1.1270633 Test MSE 5.7396067381925615 Test RE 1.145115066141002\n",
      "63 Train Loss 1.1083889 Test MSE 5.708822850158976 Test RE 1.1420400743055465\n",
      "64 Train Loss 1.0874244 Test MSE 5.726041493426292 Test RE 1.1437610574057866\n",
      "65 Train Loss 1.0719035 Test MSE 5.707229192823111 Test RE 1.1418806589912514\n",
      "66 Train Loss 1.0553899 Test MSE 5.722744948477454 Test RE 1.1434317721071356\n",
      "67 Train Loss 1.0437574 Test MSE 5.757273249431216 Test RE 1.1468760443654809\n",
      "68 Train Loss 1.0359976 Test MSE 5.751012203262725 Test RE 1.1462522597320688\n",
      "69 Train Loss 1.0285438 Test MSE 5.734646584586917 Test RE 1.1446201564230765\n",
      "70 Train Loss 1.0218569 Test MSE 5.750259514512517 Test RE 1.1461772469011189\n",
      "71 Train Loss 1.0124887 Test MSE 5.764624085728301 Test RE 1.1476079714783691\n",
      "72 Train Loss 1.005362 Test MSE 5.7424052417653835 Test RE 1.1453941983378078\n",
      "73 Train Loss 0.99986917 Test MSE 5.751165103796645 Test RE 1.1462674971730116\n",
      "74 Train Loss 0.9922945 Test MSE 5.7528086369480755 Test RE 1.1464312721666703\n",
      "75 Train Loss 0.9854272 Test MSE 5.771742857042541 Test RE 1.1483163470794382\n",
      "76 Train Loss 0.9750643 Test MSE 5.8086141688645165 Test RE 1.1519783714286798\n",
      "77 Train Loss 0.9659804 Test MSE 5.847683239625023 Test RE 1.1558460150006964\n",
      "78 Train Loss 0.95543766 Test MSE 5.83917558622639 Test RE 1.155004902706908\n",
      "79 Train Loss 0.94912434 Test MSE 5.83549141512548 Test RE 1.1546404756544202\n",
      "80 Train Loss 0.94144243 Test MSE 5.854247756108225 Test RE 1.1564946002334777\n",
      "81 Train Loss 0.9364518 Test MSE 5.852004332369199 Test RE 1.1562729871280717\n",
      "82 Train Loss 0.93248665 Test MSE 5.857186922819812 Test RE 1.1567848769727267\n",
      "83 Train Loss 0.92690843 Test MSE 5.863797338479146 Test RE 1.157437466059573\n",
      "84 Train Loss 0.91939384 Test MSE 5.915175925895272 Test RE 1.1624971400754864\n",
      "85 Train Loss 0.90977216 Test MSE 5.9215244989339 Test RE 1.1631208086629903\n",
      "86 Train Loss 0.9046833 Test MSE 5.9279295919273896 Test RE 1.1637496909265974\n",
      "87 Train Loss 0.898962 Test MSE 5.949024451386089 Test RE 1.16581848532683\n",
      "88 Train Loss 0.8941346 Test MSE 5.964817069972881 Test RE 1.1673648837391706\n",
      "89 Train Loss 0.8878329 Test MSE 5.9755443200106155 Test RE 1.1684141187510007\n",
      "90 Train Loss 0.88279563 Test MSE 5.979766095379503 Test RE 1.1688267933733545\n",
      "91 Train Loss 0.87604576 Test MSE 5.979918149385211 Test RE 1.1688416537929165\n",
      "92 Train Loss 0.86812735 Test MSE 5.989183866786064 Test RE 1.1697468471559542\n",
      "93 Train Loss 0.8635037 Test MSE 6.008745903521386 Test RE 1.1716556194350307\n",
      "94 Train Loss 0.8601923 Test MSE 6.007453474946409 Test RE 1.1715296062317087\n",
      "95 Train Loss 0.8566389 Test MSE 5.999340523495393 Test RE 1.1707382747665698\n",
      "96 Train Loss 0.8523301 Test MSE 6.00129083882943 Test RE 1.1709285559534273\n",
      "97 Train Loss 0.8477796 Test MSE 6.014012976793026 Test RE 1.1721690247545604\n",
      "98 Train Loss 0.8427263 Test MSE 6.025725378570402 Test RE 1.1733098800199193\n",
      "99 Train Loss 0.8378439 Test MSE 6.034870276739244 Test RE 1.174199875064932\n",
      "Training time: 159.30\n",
      "2\n",
      "KG_rowdy_tune31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.658966 Test MSE 6.390331046816941 Test RE 1.2082859869978215\n",
      "1 Train Loss 43.027508 Test MSE 7.878110231507898 Test RE 1.3415877586606153\n",
      "2 Train Loss 34.159676 Test MSE 7.006917028717151 Test RE 1.265236021106286\n",
      "3 Train Loss 27.33442 Test MSE 6.561394331978252 Test RE 1.2243515343896312\n",
      "4 Train Loss 22.37372 Test MSE 6.194952321930861 Test RE 1.1896714637014476\n",
      "5 Train Loss 18.215084 Test MSE 5.589555332122381 Test RE 1.1300474773033828\n",
      "6 Train Loss 15.183977 Test MSE 5.455091486475209 Test RE 1.1163723706919049\n",
      "7 Train Loss 12.744066 Test MSE 5.483804348150278 Test RE 1.1193065264999686\n",
      "8 Train Loss 11.03763 Test MSE 5.553237703602538 Test RE 1.1263703040784667\n",
      "9 Train Loss 9.733851 Test MSE 5.738960912559056 Test RE 1.1450506396479094\n",
      "10 Train Loss 8.799317 Test MSE 5.64439101909826 Test RE 1.1355770487235755\n",
      "11 Train Loss 7.8887305 Test MSE 5.556510652801193 Test RE 1.1267021834206403\n",
      "12 Train Loss 7.0576735 Test MSE 5.384929585625038 Test RE 1.1091698980041953\n",
      "13 Train Loss 6.4969425 Test MSE 5.299476272278267 Test RE 1.1003340089659284\n",
      "14 Train Loss 6.007703 Test MSE 5.278235407473395 Test RE 1.0981266670338168\n",
      "15 Train Loss 5.4819393 Test MSE 5.060260855001376 Test RE 1.0752130154291077\n",
      "16 Train Loss 4.8541784 Test MSE 4.758092327294053 Test RE 1.0426162578913363\n",
      "17 Train Loss 4.3717284 Test MSE 4.6254420831147005 Test RE 1.027980044246957\n",
      "18 Train Loss 3.9026752 Test MSE 4.517309350824445 Test RE 1.0158930204516512\n",
      "19 Train Loss 3.6717865 Test MSE 4.421668590778141 Test RE 1.0050812114954486\n",
      "20 Train Loss 3.2759075 Test MSE 4.352335704512518 Test RE 0.9971701126495492\n",
      "21 Train Loss 2.8988957 Test MSE 4.1124733246805 Test RE 0.969303112412697\n",
      "22 Train Loss 2.6042993 Test MSE 3.785377066847857 Test RE 0.92995649854202\n",
      "23 Train Loss 2.3978739 Test MSE 3.588439157845548 Test RE 0.9054424544215272\n",
      "24 Train Loss 2.263835 Test MSE 3.4583283247159486 Test RE 0.8888759813459891\n",
      "25 Train Loss 2.1406658 Test MSE 3.405069292011819 Test RE 0.88200498011864\n",
      "26 Train Loss 2.0389931 Test MSE 3.294505682379097 Test RE 0.8675673326852399\n",
      "27 Train Loss 1.9007976 Test MSE 3.172414398253565 Test RE 0.8513399555678258\n",
      "28 Train Loss 1.7942941 Test MSE 2.9768386674624434 Test RE 0.8246804693522038\n",
      "29 Train Loss 1.684124 Test MSE 2.6246892310641035 Test RE 0.7743672994204766\n",
      "30 Train Loss 1.6098441 Test MSE 2.485147828349778 Test RE 0.7535015918503352\n",
      "31 Train Loss 1.4874537 Test MSE 2.067726057359992 Test RE 0.6873130036621817\n",
      "32 Train Loss 1.3795806 Test MSE 1.8508803474762319 Test RE 0.6502752614165486\n",
      "33 Train Loss 1.0323464 Test MSE 1.3361956500620886 Test RE 0.5525137456975845\n",
      "34 Train Loss 0.8413806 Test MSE 1.1647865598667397 Test RE 0.5158592657864418\n",
      "35 Train Loss 0.6977832 Test MSE 0.938479667279637 Test RE 0.4630421161194754\n",
      "36 Train Loss 0.5721954 Test MSE 0.7652096951507764 Test RE 0.41811744917439453\n",
      "37 Train Loss 0.4629113 Test MSE 0.6782576937193591 Test RE 0.39364562106451306\n",
      "38 Train Loss 0.3446097 Test MSE 0.4849377074307602 Test RE 0.3328518980196861\n",
      "39 Train Loss 0.28254676 Test MSE 0.3272076893462546 Test RE 0.27341340959191596\n",
      "40 Train Loss 0.20631428 Test MSE 0.14189005074714164 Test RE 0.18004623008909743\n",
      "41 Train Loss 0.1823008 Test MSE 0.12521128880291268 Test RE 0.1691335650528283\n",
      "42 Train Loss 0.14280707 Test MSE 0.07328578234590763 Test RE 0.1293951279871222\n",
      "43 Train Loss 0.115080416 Test MSE 0.06097713167179115 Test RE 0.1180297687021594\n",
      "44 Train Loss 0.10245855 Test MSE 0.054534765658918766 Test RE 0.11162071135029962\n",
      "45 Train Loss 0.087975994 Test MSE 0.04645790146454093 Test RE 0.10302386876786455\n",
      "46 Train Loss 0.06931953 Test MSE 0.035966007559756014 Test RE 0.09064715453423819\n",
      "47 Train Loss 0.059315667 Test MSE 0.03670514910281176 Test RE 0.09157386753251709\n",
      "48 Train Loss 0.053069677 Test MSE 0.03354349189735974 Test RE 0.08754113956788309\n",
      "49 Train Loss 0.04777889 Test MSE 0.028212283947685463 Test RE 0.08028366376324558\n",
      "50 Train Loss 0.04337402 Test MSE 0.02962663836720395 Test RE 0.08227146834391826\n",
      "51 Train Loss 0.03827801 Test MSE 0.026206250563488475 Test RE 0.07737675363695899\n",
      "52 Train Loss 0.034837157 Test MSE 0.024544595478360038 Test RE 0.07488347670419884\n",
      "53 Train Loss 0.03175492 Test MSE 0.027314882578101177 Test RE 0.0789964780377924\n",
      "54 Train Loss 0.028772013 Test MSE 0.022264230612587206 Test RE 0.07132009387813425\n",
      "55 Train Loss 0.026740916 Test MSE 0.019071416313425203 Test RE 0.06600844980490443\n",
      "56 Train Loss 0.024222407 Test MSE 0.01643999181592962 Test RE 0.06128565877259674\n",
      "57 Train Loss 0.021267533 Test MSE 0.014900313494644582 Test RE 0.058345284678705374\n",
      "58 Train Loss 0.019936573 Test MSE 0.014265136384771 Test RE 0.05708815721531877\n",
      "59 Train Loss 0.018176477 Test MSE 0.01243828229308408 Test RE 0.05330749377157635\n",
      "60 Train Loss 0.016920906 Test MSE 0.012580121390521296 Test RE 0.05361057634668113\n",
      "61 Train Loss 0.015282104 Test MSE 0.01125571077198086 Test RE 0.05071010650960506\n",
      "62 Train Loss 0.013730046 Test MSE 0.010334543160159436 Test RE 0.0485907611308435\n",
      "63 Train Loss 0.013238852 Test MSE 0.01170395796410946 Test RE 0.051709987993615106\n",
      "64 Train Loss 0.012206172 Test MSE 0.010182153612184072 Test RE 0.048231179482940166\n",
      "65 Train Loss 0.010447252 Test MSE 0.009264780654688168 Test RE 0.046007181808664574\n",
      "66 Train Loss 0.01015883 Test MSE 0.00937403010890319 Test RE 0.04627764309175956\n",
      "67 Train Loss 0.009683902 Test MSE 0.009042755595145719 Test RE 0.045452571304091\n",
      "68 Train Loss 0.0089845285 Test MSE 0.008755350955937494 Test RE 0.044724432640197216\n",
      "69 Train Loss 0.008664409 Test MSE 0.00894879779749196 Test RE 0.045215819639883414\n",
      "70 Train Loss 0.0081562 Test MSE 0.008814717725083 Test RE 0.04487580631950611\n",
      "71 Train Loss 0.0075529236 Test MSE 0.008180368514104126 Test RE 0.04323092165568065\n",
      "72 Train Loss 0.007152785 Test MSE 0.007913122791317857 Test RE 0.04251889924676907\n",
      "73 Train Loss 0.0068454137 Test MSE 0.007555082763089443 Test RE 0.04154585235611927\n",
      "74 Train Loss 0.005940473 Test MSE 0.008430697214895129 Test RE 0.043887395291401156\n",
      "75 Train Loss 0.00562251 Test MSE 0.008246379838400352 Test RE 0.043404996727318255\n",
      "76 Train Loss 0.005468685 Test MSE 0.008323938833510031 Test RE 0.043608635745735674\n",
      "77 Train Loss 0.0051610256 Test MSE 0.008158201908666824 Test RE 0.0431723098196266\n",
      "78 Train Loss 0.0047105276 Test MSE 0.008496174647363892 Test RE 0.04405749249066674\n",
      "79 Train Loss 0.0045712604 Test MSE 0.008898410847402538 Test RE 0.04508834423027408\n",
      "80 Train Loss 0.004460948 Test MSE 0.00883822018043963 Test RE 0.044935592099315365\n",
      "81 Train Loss 0.0043375813 Test MSE 0.008729421685528127 Test RE 0.044658157068298586\n",
      "82 Train Loss 0.0040678703 Test MSE 0.008442949685306598 Test RE 0.04391927484820334\n",
      "83 Train Loss 0.003968738 Test MSE 0.00840696212118772 Test RE 0.04382557326137245\n",
      "84 Train Loss 0.0038904706 Test MSE 0.008301519430343693 Test RE 0.04354986916864738\n",
      "85 Train Loss 0.0037349223 Test MSE 0.00804530333842235 Test RE 0.04287254569701743\n",
      "86 Train Loss 0.0036425756 Test MSE 0.007916342842658776 Test RE 0.042527549378747705\n",
      "87 Train Loss 0.0035218124 Test MSE 0.007593191473013198 Test RE 0.04165050159491761\n",
      "88 Train Loss 0.003484167 Test MSE 0.007486806733367041 Test RE 0.04135769931475393\n",
      "89 Train Loss 0.0034412316 Test MSE 0.0074346786629894464 Test RE 0.041213468072243076\n",
      "90 Train Loss 0.0033984985 Test MSE 0.007614194500434065 Test RE 0.0417080651729557\n",
      "91 Train Loss 0.003273482 Test MSE 0.007522904695773099 Test RE 0.04145728338967503\n",
      "92 Train Loss 0.0031839313 Test MSE 0.0075344149327482976 Test RE 0.04148898662063034\n",
      "93 Train Loss 0.0031137988 Test MSE 0.007241913815729124 Test RE 0.04067567197199423\n",
      "94 Train Loss 0.0029949567 Test MSE 0.007010628162119923 Test RE 0.04002087013364705\n",
      "95 Train Loss 0.0028815365 Test MSE 0.006793076871499547 Test RE 0.03939501996037844\n",
      "96 Train Loss 0.002831636 Test MSE 0.0067976404150224875 Test RE 0.03940825039393714\n",
      "97 Train Loss 0.0027439762 Test MSE 0.006378495561180091 Test RE 0.03817395780232034\n",
      "98 Train Loss 0.0026044105 Test MSE 0.006078938028283571 Test RE 0.037266784178525816\n",
      "99 Train Loss 0.002447314 Test MSE 0.006171409922552646 Test RE 0.037549162724608884\n",
      "Training time: 158.11\n",
      "3\n",
      "KG_rowdy_tune31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.41433 Test MSE 5.913223290966787 Test RE 1.1623052506110891\n",
      "1 Train Loss 52.649914 Test MSE 7.099159339196671 Test RE 1.2735368687180872\n",
      "2 Train Loss 43.047016 Test MSE 8.6606325459718 Test RE 1.406639687578798\n",
      "3 Train Loss 38.125256 Test MSE 8.938886811201545 Test RE 1.4290577492764136\n",
      "4 Train Loss 34.80641 Test MSE 9.369359475066139 Test RE 1.463062945504191\n",
      "5 Train Loss 32.2967 Test MSE 9.34440084140842 Test RE 1.4611129507899465\n",
      "6 Train Loss 29.824322 Test MSE 9.128249480805865 Test RE 1.4441151057941142\n",
      "7 Train Loss 27.1534 Test MSE 8.749763812397147 Test RE 1.413859405560564\n",
      "8 Train Loss 24.71031 Test MSE 8.590436106157341 Test RE 1.400927518605548\n",
      "9 Train Loss 22.49104 Test MSE 8.7601954104591 Test RE 1.4147019665731357\n",
      "10 Train Loss 21.069979 Test MSE 8.780273699904201 Test RE 1.4163222807884246\n",
      "11 Train Loss 19.361958 Test MSE 8.860642093696267 Test RE 1.422789519843708\n",
      "12 Train Loss 17.61489 Test MSE 8.72788959992363 Test RE 1.412090991284099\n",
      "13 Train Loss 16.176903 Test MSE 8.61430029213264 Test RE 1.4028720536761456\n",
      "14 Train Loss 15.187922 Test MSE 8.78009450629442 Test RE 1.4163078280956207\n",
      "15 Train Loss 14.1715355 Test MSE 8.567082106346122 Test RE 1.3990219385393827\n",
      "16 Train Loss 13.097229 Test MSE 8.442616878906883 Test RE 1.388822043748079\n",
      "17 Train Loss 12.211399 Test MSE 8.511105747794641 Test RE 1.3944439216007032\n",
      "18 Train Loss 11.49356 Test MSE 8.495015969230788 Test RE 1.3931252382084498\n",
      "19 Train Loss 10.650317 Test MSE 8.49342910467349 Test RE 1.3929951145970583\n",
      "20 Train Loss 9.87677 Test MSE 8.328554139262877 Test RE 1.3794084017425348\n",
      "21 Train Loss 8.973138 Test MSE 7.889419627337703 Test RE 1.3425503693145073\n",
      "22 Train Loss 8.186336 Test MSE 7.7279745231099835 Test RE 1.3287427292260394\n",
      "23 Train Loss 7.6699533 Test MSE 7.565285453262744 Test RE 1.3146820096577683\n",
      "24 Train Loss 7.132733 Test MSE 7.244202762808139 Test RE 1.2864809483179644\n",
      "25 Train Loss 6.702936 Test MSE 6.918815022947398 Test RE 1.2572565884474487\n",
      "26 Train Loss 6.387395 Test MSE 7.057296667388809 Test RE 1.269776389367145\n",
      "27 Train Loss 6.151329 Test MSE 6.968450696384891 Test RE 1.261758316976211\n",
      "28 Train Loss 5.9484024 Test MSE 6.981548037510302 Test RE 1.2629435102148805\n",
      "29 Train Loss 5.752405 Test MSE 6.80266444567612 Test RE 1.2466587363326924\n",
      "30 Train Loss 5.619213 Test MSE 6.830998398609147 Test RE 1.2492522837357434\n",
      "31 Train Loss 5.452627 Test MSE 6.829126203876384 Test RE 1.2490810786142763\n",
      "32 Train Loss 5.2992935 Test MSE 6.841236499913782 Test RE 1.2501881046779177\n",
      "33 Train Loss 5.128825 Test MSE 6.851493509872572 Test RE 1.2511249520602057\n",
      "34 Train Loss 4.9848957 Test MSE 6.828434671273055 Test RE 1.249017834640416\n",
      "35 Train Loss 4.797431 Test MSE 6.61922396203778 Test RE 1.2297351820596267\n",
      "36 Train Loss 4.592288 Test MSE 6.477682022598512 Test RE 1.2165161337296633\n",
      "37 Train Loss 4.404931 Test MSE 6.460540101013359 Test RE 1.2149054311270295\n",
      "38 Train Loss 4.0402074 Test MSE 6.282732473804752 Test RE 1.1980704151708945\n",
      "39 Train Loss 3.6057038 Test MSE 6.067995918160502 Test RE 1.1774180796523028\n",
      "40 Train Loss 3.1215138 Test MSE 5.916924884256813 Test RE 1.1626689869362967\n",
      "41 Train Loss 2.603622 Test MSE 5.550398463509724 Test RE 1.1260823239151743\n",
      "42 Train Loss 2.2487402 Test MSE 5.418440083327451 Test RE 1.1126157359117583\n",
      "43 Train Loss 2.0256035 Test MSE 5.3535412337297625 Test RE 1.1059325393305541\n",
      "44 Train Loss 1.8369293 Test MSE 5.49425269076268 Test RE 1.1203723315539522\n",
      "45 Train Loss 1.7381232 Test MSE 5.395114833403051 Test RE 1.1102183642039793\n",
      "46 Train Loss 1.6379225 Test MSE 5.500198703523737 Test RE 1.1209784145968968\n",
      "47 Train Loss 1.5320414 Test MSE 5.563416550532034 Test RE 1.1274021257426565\n",
      "48 Train Loss 1.4759591 Test MSE 5.647824997950225 Test RE 1.1359224318329246\n",
      "49 Train Loss 1.4027886 Test MSE 5.7037619523169 Test RE 1.1415337501638794\n",
      "50 Train Loss 1.3602042 Test MSE 5.678461057188746 Test RE 1.1389991137377764\n",
      "51 Train Loss 1.3354211 Test MSE 5.715266980481788 Test RE 1.142684461037747\n",
      "52 Train Loss 1.3054188 Test MSE 5.7883565062564 Test RE 1.1499678427041182\n",
      "53 Train Loss 1.262302 Test MSE 5.820295485552811 Test RE 1.153136123101282\n",
      "54 Train Loss 1.227116 Test MSE 5.840788682182089 Test RE 1.1551644290863659\n",
      "55 Train Loss 1.1931688 Test MSE 5.904887585718178 Test RE 1.1614857271161325\n",
      "56 Train Loss 1.1676258 Test MSE 5.913139732298312 Test RE 1.16229703842144\n",
      "57 Train Loss 1.1520038 Test MSE 5.948297594149684 Test RE 1.1657472627680368\n",
      "58 Train Loss 1.1318444 Test MSE 5.96321954479475 Test RE 1.1672085487120532\n",
      "59 Train Loss 1.1159039 Test MSE 5.943031097619642 Test RE 1.165231084538594\n",
      "60 Train Loss 1.0943942 Test MSE 5.956008127145672 Test RE 1.1665025731415168\n",
      "61 Train Loss 1.0801253 Test MSE 5.99247143558533 Test RE 1.1700678504625346\n",
      "62 Train Loss 1.0633693 Test MSE 5.9968262365679275 Test RE 1.1704929244317213\n",
      "63 Train Loss 1.0488665 Test MSE 5.991775011938273 Test RE 1.1699998579318256\n",
      "64 Train Loss 1.0328541 Test MSE 5.991797878148597 Test RE 1.170002090445334\n",
      "65 Train Loss 1.0117552 Test MSE 6.010266145860174 Test RE 1.1718038273854805\n",
      "66 Train Loss 0.9965637 Test MSE 6.000947874397313 Test RE 1.1708950971030143\n",
      "67 Train Loss 0.9847177 Test MSE 6.0002917065765216 Test RE 1.1708310801590391\n",
      "68 Train Loss 0.971479 Test MSE 6.0487840526613965 Test RE 1.1755526918798846\n",
      "69 Train Loss 0.9604764 Test MSE 6.059356972816491 Test RE 1.1765796419314185\n",
      "70 Train Loss 0.95167935 Test MSE 6.053800753155734 Test RE 1.1760400769014179\n",
      "71 Train Loss 0.9419275 Test MSE 6.096687358165815 Test RE 1.1801984030033161\n",
      "72 Train Loss 0.93294734 Test MSE 6.116219836388803 Test RE 1.1820874424270613\n",
      "73 Train Loss 0.9255606 Test MSE 6.143020760158169 Test RE 1.1846745310204398\n",
      "74 Train Loss 0.90897894 Test MSE 6.133037996468768 Test RE 1.1837115573567052\n",
      "75 Train Loss 0.8993528 Test MSE 6.127745495601419 Test RE 1.1832007055911455\n",
      "76 Train Loss 0.8887256 Test MSE 6.143722419594198 Test RE 1.1847421861986493\n",
      "77 Train Loss 0.8795838 Test MSE 6.147253380091381 Test RE 1.1850825887010397\n",
      "78 Train Loss 0.86848223 Test MSE 6.167588518244227 Test RE 1.1870410992605263\n",
      "79 Train Loss 0.85663086 Test MSE 6.199220777874592 Test RE 1.1900812477921396\n",
      "80 Train Loss 0.8444609 Test MSE 6.201999176838756 Test RE 1.1903479063145745\n",
      "81 Train Loss 0.83857906 Test MSE 6.22134342262272 Test RE 1.192202828795362\n",
      "82 Train Loss 0.83242244 Test MSE 6.230156671993125 Test RE 1.193046976240075\n",
      "83 Train Loss 0.8237139 Test MSE 6.2322404247239644 Test RE 1.1932464741974143\n",
      "84 Train Loss 0.817086 Test MSE 6.221079043110733 Test RE 1.1921774968590493\n",
      "85 Train Loss 0.8098875 Test MSE 6.237229922725283 Test RE 1.1937240319731097\n",
      "86 Train Loss 0.7967913 Test MSE 6.249714771683917 Test RE 1.1949181529161166\n",
      "87 Train Loss 0.7873494 Test MSE 6.291652546573015 Test RE 1.1989206093163167\n",
      "88 Train Loss 0.781645 Test MSE 6.303637574293002 Test RE 1.2000619835565185\n",
      "89 Train Loss 0.7737678 Test MSE 6.305674971790956 Test RE 1.2002559037909495\n",
      "90 Train Loss 0.7692222 Test MSE 6.338338507011873 Test RE 1.20336056443868\n",
      "91 Train Loss 0.76371604 Test MSE 6.313504151213663 Test RE 1.2010007965915477\n",
      "92 Train Loss 0.7586834 Test MSE 6.310527451688549 Test RE 1.200717638467054\n",
      "93 Train Loss 0.75408757 Test MSE 6.297608894614569 Test RE 1.1994879879992393\n",
      "94 Train Loss 0.74862784 Test MSE 6.308219614364696 Test RE 1.200498059802531\n",
      "95 Train Loss 0.7435094 Test MSE 6.291497467801972 Test RE 1.1989058335257743\n",
      "96 Train Loss 0.7393484 Test MSE 6.305450692803353 Test RE 1.20023455837005\n",
      "97 Train Loss 0.7338353 Test MSE 6.322820350297175 Test RE 1.2018865676122048\n",
      "98 Train Loss 0.7299592 Test MSE 6.3318764755504136 Test RE 1.202746985911302\n",
      "99 Train Loss 0.7246396 Test MSE 6.3242142435750175 Test RE 1.202019040875148\n",
      "Training time: 156.66\n",
      "4\n",
      "KG_rowdy_tune31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.263435 Test MSE 8.431219589601962 Test RE 1.387884292303843\n",
      "1 Train Loss 44.627182 Test MSE 7.310775859690248 Test RE 1.2923787093599013\n",
      "2 Train Loss 38.02778 Test MSE 7.80670988333668 Test RE 1.3354944280049632\n",
      "3 Train Loss 31.090355 Test MSE 7.294761608555895 Test RE 1.2909624558769452\n",
      "4 Train Loss 26.32761 Test MSE 6.663833542570072 Test RE 1.2338720607694793\n",
      "5 Train Loss 21.890778 Test MSE 6.73721524502047 Test RE 1.2406471197328963\n",
      "6 Train Loss 18.405174 Test MSE 6.313588800344378 Test RE 1.2010088478520065\n",
      "7 Train Loss 16.615868 Test MSE 6.2724010370299865 Test RE 1.197084945747382\n",
      "8 Train Loss 15.115833 Test MSE 5.706066329279564 Test RE 1.1417643224126959\n",
      "9 Train Loss 12.77534 Test MSE 5.664613219101551 Test RE 1.1376094499765699\n",
      "10 Train Loss 10.167301 Test MSE 5.699349098945638 Test RE 1.1410920771235522\n",
      "11 Train Loss 8.654931 Test MSE 5.396517108089157 Test RE 1.1103626363842949\n",
      "12 Train Loss 6.986167 Test MSE 5.005070039739268 Test RE 1.0693334195659823\n",
      "13 Train Loss 5.726218 Test MSE 4.823713141721373 Test RE 1.0497812142592782\n",
      "14 Train Loss 4.712268 Test MSE 4.489427087136498 Test RE 1.0127529608923915\n",
      "15 Train Loss 4.0029006 Test MSE 4.202211689174119 Test RE 0.9798216323788376\n",
      "16 Train Loss 3.650936 Test MSE 3.9713127058778404 Test RE 0.9525221924281247\n",
      "17 Train Loss 3.2258723 Test MSE 3.8177153800586052 Test RE 0.9339203399667534\n",
      "18 Train Loss 2.9567075 Test MSE 3.7020765254052526 Test RE 0.9196673240004792\n",
      "19 Train Loss 2.6872804 Test MSE 3.5320713665242542 Test RE 0.8983028867192561\n",
      "20 Train Loss 2.3949625 Test MSE 3.197090907647283 Test RE 0.8546446001089566\n",
      "21 Train Loss 2.1967163 Test MSE 3.076908687126177 Test RE 0.8384272099255806\n",
      "22 Train Loss 2.0026658 Test MSE 2.849128277026378 Test RE 0.8067966045569757\n",
      "23 Train Loss 1.8511602 Test MSE 2.4981064419187953 Test RE 0.7554635757762372\n",
      "24 Train Loss 1.7124643 Test MSE 2.2970965898066655 Test RE 0.7244321048579617\n",
      "25 Train Loss 1.5571321 Test MSE 2.1090594357192693 Test RE 0.6941486281450882\n",
      "26 Train Loss 1.4562716 Test MSE 1.9092993624187728 Test RE 0.6604578007396875\n",
      "27 Train Loss 1.3700916 Test MSE 1.7703980513158724 Test RE 0.6359800927698389\n",
      "28 Train Loss 1.2876725 Test MSE 1.6825677994794688 Test RE 0.6200037937328431\n",
      "29 Train Loss 1.1999779 Test MSE 1.5008678635334447 Test RE 0.5855706347962601\n",
      "30 Train Loss 1.1460576 Test MSE 1.4378111432634602 Test RE 0.5731377083368446\n",
      "31 Train Loss 1.0469867 Test MSE 1.3171915504569096 Test RE 0.5485705999458312\n",
      "32 Train Loss 0.9695895 Test MSE 1.2088111290365808 Test RE 0.5255176237992909\n",
      "33 Train Loss 0.87091976 Test MSE 1.0814692126296623 Test RE 0.49706723916086454\n",
      "34 Train Loss 0.776915 Test MSE 0.9747493971425548 Test RE 0.47190496635793827\n",
      "35 Train Loss 0.6439608 Test MSE 0.780119542847491 Test RE 0.4221712351190913\n",
      "36 Train Loss 0.5314734 Test MSE 0.7154356265992043 Test RE 0.4042903187799284\n",
      "37 Train Loss 0.41321167 Test MSE 0.6543932946643398 Test RE 0.3866584276893196\n",
      "38 Train Loss 0.36116335 Test MSE 0.6545517037025104 Test RE 0.38670522407604085\n",
      "39 Train Loss 0.31621528 Test MSE 0.5930257719645801 Test RE 0.3680822237591808\n",
      "40 Train Loss 0.2749109 Test MSE 0.5829815770876664 Test RE 0.3649517711390404\n",
      "41 Train Loss 0.25012508 Test MSE 0.5381458572457138 Test RE 0.3506372575910122\n",
      "42 Train Loss 0.2307998 Test MSE 0.5488394757088735 Test RE 0.35410391687398024\n",
      "43 Train Loss 0.21689762 Test MSE 0.5145637213377703 Test RE 0.34286854310747444\n",
      "44 Train Loss 0.19521803 Test MSE 0.5030532484442986 Test RE 0.33901197500825414\n",
      "45 Train Loss 0.18109915 Test MSE 0.4920450173222689 Test RE 0.33528218603435544\n",
      "46 Train Loss 0.16930065 Test MSE 0.4735287057274538 Test RE 0.32891313410575795\n",
      "47 Train Loss 0.16284674 Test MSE 0.4537022739636201 Test RE 0.3219537872884451\n",
      "48 Train Loss 0.15674292 Test MSE 0.45292761810811866 Test RE 0.32167881628841893\n",
      "49 Train Loss 0.15142235 Test MSE 0.45593296298660485 Test RE 0.32274428165874003\n",
      "50 Train Loss 0.14511508 Test MSE 0.44190460103823687 Test RE 0.3177403151597004\n",
      "51 Train Loss 0.14021602 Test MSE 0.43223713438365574 Test RE 0.3142455221578591\n",
      "52 Train Loss 0.13776024 Test MSE 0.4331482259883133 Test RE 0.31457653923184054\n",
      "53 Train Loss 0.1352801 Test MSE 0.4268352061368091 Test RE 0.31227569032234187\n",
      "54 Train Loss 0.13185272 Test MSE 0.42872018342977336 Test RE 0.3129644621626575\n",
      "55 Train Loss 0.12855588 Test MSE 0.4200737070439584 Test RE 0.3097924362000047\n",
      "56 Train Loss 0.12511 Test MSE 0.42414003513774634 Test RE 0.3112882258721461\n",
      "57 Train Loss 0.123561986 Test MSE 0.42117555651657745 Test RE 0.3101984614806273\n",
      "58 Train Loss 0.121817105 Test MSE 0.4257112066600689 Test RE 0.3118642562539538\n",
      "59 Train Loss 0.11921889 Test MSE 0.4327794610389787 Test RE 0.31444260182247397\n",
      "60 Train Loss 0.11782932 Test MSE 0.4281117436740258 Test RE 0.3127423037044212\n",
      "61 Train Loss 0.115987256 Test MSE 0.4281852792520584 Test RE 0.3127691619942724\n",
      "62 Train Loss 0.113736644 Test MSE 0.4373351406332805 Test RE 0.31609326891880357\n",
      "63 Train Loss 0.11157324 Test MSE 0.44089701159263206 Test RE 0.3173778675967873\n",
      "64 Train Loss 0.10993499 Test MSE 0.4459813009165676 Test RE 0.3192025743756307\n",
      "65 Train Loss 0.10836072 Test MSE 0.4474519487890996 Test RE 0.3197284352425709\n",
      "66 Train Loss 0.10773958 Test MSE 0.4496300096049985 Test RE 0.32050566124772356\n",
      "67 Train Loss 0.107088454 Test MSE 0.4541737121219675 Test RE 0.32212101357434725\n",
      "68 Train Loss 0.10569372 Test MSE 0.4566436028088324 Test RE 0.3229957063813734\n",
      "69 Train Loss 0.1043638 Test MSE 0.45443218057807233 Test RE 0.3222126594322409\n",
      "70 Train Loss 0.10322075 Test MSE 0.4559485985818313 Test RE 0.3227498156473919\n",
      "71 Train Loss 0.101399004 Test MSE 0.4583202814540478 Test RE 0.32358814191875923\n",
      "72 Train Loss 0.10039079 Test MSE 0.454903377099545 Test RE 0.32237966581357497\n",
      "73 Train Loss 0.099431664 Test MSE 0.45805346926646956 Test RE 0.3234939394226769\n",
      "74 Train Loss 0.09777207 Test MSE 0.45960858389094345 Test RE 0.32404261324134737\n",
      "75 Train Loss 0.09689729 Test MSE 0.45379292733686105 Test RE 0.32198595016348064\n",
      "76 Train Loss 0.09600126 Test MSE 0.45824846758287174 Test RE 0.32356278953043993\n",
      "77 Train Loss 0.09532755 Test MSE 0.46107429805947103 Test RE 0.3245588957977579\n",
      "78 Train Loss 0.09461275 Test MSE 0.4626713887931051 Test RE 0.325120521019177\n",
      "79 Train Loss 0.09367946 Test MSE 0.463957235135083 Test RE 0.325571991526448\n",
      "80 Train Loss 0.09302684 Test MSE 0.46773988987995474 Test RE 0.32689649555399214\n",
      "81 Train Loss 0.09210523 Test MSE 0.4704638216255483 Test RE 0.3278469715817019\n",
      "82 Train Loss 0.09101618 Test MSE 0.47203436041579694 Test RE 0.32839373773192976\n",
      "83 Train Loss 0.09005994 Test MSE 0.47627532843065695 Test RE 0.32986565720647576\n",
      "84 Train Loss 0.08951568 Test MSE 0.4784625674659803 Test RE 0.3306222244165784\n",
      "85 Train Loss 0.08880398 Test MSE 0.4780232237395134 Test RE 0.3304703941894131\n",
      "86 Train Loss 0.0881442 Test MSE 0.48044719166181954 Test RE 0.3313072120130495\n",
      "87 Train Loss 0.08733171 Test MSE 0.4825312284584171 Test RE 0.33202499047418943\n",
      "88 Train Loss 0.0866527 Test MSE 0.48304512192106736 Test RE 0.3322017459433969\n",
      "89 Train Loss 0.08625377 Test MSE 0.48308632316589384 Test RE 0.332215913184714\n",
      "90 Train Loss 0.08557823 Test MSE 0.48256606339667735 Test RE 0.3320369750470261\n",
      "91 Train Loss 0.08503458 Test MSE 0.4855441396007143 Test RE 0.33305995467241095\n",
      "92 Train Loss 0.08419501 Test MSE 0.4887198796080899 Test RE 0.3341473820118909\n",
      "93 Train Loss 0.083856754 Test MSE 0.4899390386429357 Test RE 0.334563903900681\n",
      "94 Train Loss 0.083471715 Test MSE 0.4888874358683577 Test RE 0.33420465785639014\n",
      "95 Train Loss 0.08316779 Test MSE 0.4872054322315445 Test RE 0.33362925159378903\n",
      "96 Train Loss 0.0828413 Test MSE 0.4907776003990506 Test RE 0.3348500951708622\n",
      "97 Train Loss 0.08221411 Test MSE 0.4921093449174533 Test RE 0.3353041019069909\n",
      "98 Train Loss 0.08165128 Test MSE 0.4914895693220129 Test RE 0.33509288993327574\n",
      "99 Train Loss 0.081216365 Test MSE 0.49394726929304084 Test RE 0.33592966333651914\n",
      "Training time: 160.12\n",
      "5\n",
      "KG_rowdy_tune31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.69\n",
      "0\n",
      "KG_rowdy_tune32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 74.27569 Test MSE 4.488663468426729 Test RE 1.012666826294068\n",
      "1 Train Loss 63.77172 Test MSE 5.000329490116226 Test RE 1.0688268902869924\n",
      "2 Train Loss 48.247025 Test MSE 6.623788675783 Test RE 1.2301591306739539\n",
      "3 Train Loss 39.899685 Test MSE 6.345117727572063 Test RE 1.2040039244070668\n",
      "4 Train Loss 29.486893 Test MSE 5.812927810538422 Test RE 1.1524060379543872\n",
      "5 Train Loss 24.139734 Test MSE 5.154191363499904 Test RE 1.0851463894006983\n",
      "6 Train Loss 19.135405 Test MSE 4.8272017132639515 Test RE 1.0501607533049797\n",
      "7 Train Loss 14.614282 Test MSE 4.796311621966917 Test RE 1.046795281260338\n",
      "8 Train Loss 12.556662 Test MSE 4.778136564466094 Test RE 1.044810045109784\n",
      "9 Train Loss 10.646806 Test MSE 4.550656975245309 Test RE 1.01963588188268\n",
      "10 Train Loss 8.938452 Test MSE 4.650451248975949 Test RE 1.0307553752741747\n",
      "11 Train Loss 7.4432793 Test MSE 4.54468168748615 Test RE 1.0189662402084128\n",
      "12 Train Loss 6.7526274 Test MSE 4.361903258798399 Test RE 0.9982655292809901\n",
      "13 Train Loss 6.2739153 Test MSE 4.395103741326508 Test RE 1.0020574599661038\n",
      "14 Train Loss 5.9464436 Test MSE 4.387582073855687 Test RE 1.0011996451197689\n",
      "15 Train Loss 5.613997 Test MSE 4.492752439336104 Test RE 1.0131279683065182\n",
      "16 Train Loss 5.293505 Test MSE 4.539044544457043 Test RE 1.0183340902421725\n",
      "17 Train Loss 5.0435815 Test MSE 4.6165593477386295 Test RE 1.0269924994135924\n",
      "18 Train Loss 4.782916 Test MSE 4.640003407064977 Test RE 1.0295968613987743\n",
      "19 Train Loss 4.272974 Test MSE 4.818794243184223 Test RE 1.0492458295655012\n",
      "20 Train Loss 3.8626018 Test MSE 4.6353722334470415 Test RE 1.0290829143399751\n",
      "21 Train Loss 3.3821344 Test MSE 4.45461856911036 Test RE 1.0088191596375442\n",
      "22 Train Loss 3.0998366 Test MSE 4.359857388652203 Test RE 0.9980313928206386\n",
      "23 Train Loss 2.89321 Test MSE 4.174540384462773 Test RE 0.9765902715158208\n",
      "24 Train Loss 2.6509824 Test MSE 4.076561040330117 Test RE 0.9650615995263209\n",
      "25 Train Loss 2.5354452 Test MSE 3.9768953590814067 Test RE 0.9531914589877287\n",
      "26 Train Loss 2.43603 Test MSE 3.7961861589446415 Test RE 0.9312832910466823\n",
      "27 Train Loss 2.1743226 Test MSE 3.4569249967729507 Test RE 0.8886956180385431\n",
      "28 Train Loss 2.027622 Test MSE 3.354955134702029 Test RE 0.8754904612657477\n",
      "29 Train Loss 1.9196455 Test MSE 3.3440646511073777 Test RE 0.8740683461885741\n",
      "30 Train Loss 1.7965207 Test MSE 3.261482357463462 Test RE 0.8632082394196615\n",
      "31 Train Loss 1.7002165 Test MSE 3.0914344598674375 Test RE 0.8404039444430109\n",
      "32 Train Loss 1.5743572 Test MSE 3.0121898250910952 Test RE 0.8295627237388342\n",
      "33 Train Loss 1.4632217 Test MSE 2.9645214807093185 Test RE 0.8229725715385255\n",
      "34 Train Loss 1.3880665 Test MSE 3.0714201229700118 Test RE 0.8376790864064209\n",
      "35 Train Loss 1.2947419 Test MSE 3.0747830480710387 Test RE 0.8381375520723955\n",
      "36 Train Loss 1.2560503 Test MSE 3.0558410595566348 Test RE 0.8355519195287665\n",
      "37 Train Loss 1.2224599 Test MSE 3.043485317187859 Test RE 0.8338610068023178\n",
      "38 Train Loss 1.1779943 Test MSE 3.075473710458701 Test RE 0.8382316786450412\n",
      "39 Train Loss 1.1463925 Test MSE 2.9887283399091595 Test RE 0.8263257398272613\n",
      "40 Train Loss 1.1027688 Test MSE 2.9694260329790327 Test RE 0.823653059766473\n",
      "41 Train Loss 1.0779836 Test MSE 2.960971534767447 Test RE 0.822479678622537\n",
      "42 Train Loss 1.0532296 Test MSE 2.9559766224497084 Test RE 0.8217856584595422\n",
      "43 Train Loss 1.0101529 Test MSE 3.013349414018048 Test RE 0.8297223848562915\n",
      "44 Train Loss 0.97563255 Test MSE 3.033729801961937 Test RE 0.8325235150623322\n",
      "45 Train Loss 0.95076823 Test MSE 3.009229491951779 Test RE 0.8291549828862325\n",
      "46 Train Loss 0.92137235 Test MSE 3.042939999113496 Test RE 0.833786299714621\n",
      "47 Train Loss 0.88658756 Test MSE 3.0837723913119888 Test RE 0.8393618347759763\n",
      "48 Train Loss 0.8515769 Test MSE 3.0996155754263355 Test RE 0.8415152245175145\n",
      "49 Train Loss 0.8319346 Test MSE 3.109596609127012 Test RE 0.842869011937673\n",
      "50 Train Loss 0.81080365 Test MSE 3.1066465037263464 Test RE 0.8424690979341849\n",
      "51 Train Loss 0.7926177 Test MSE 3.131209218182555 Test RE 0.8457930335346354\n",
      "52 Train Loss 0.76056904 Test MSE 3.1476602861145166 Test RE 0.8480119798865099\n",
      "53 Train Loss 0.7320579 Test MSE 3.1891985406464265 Test RE 0.8535890566514285\n",
      "54 Train Loss 0.7050237 Test MSE 3.204935618989669 Test RE 0.8556924796881603\n",
      "55 Train Loss 0.6873498 Test MSE 3.193751914235358 Test RE 0.8541981945735788\n",
      "56 Train Loss 0.64993834 Test MSE 3.225510419885341 Test RE 0.8584347402023562\n",
      "57 Train Loss 0.6381818 Test MSE 3.204613878163086 Test RE 0.8556495274812582\n",
      "58 Train Loss 0.61265206 Test MSE 3.1846749641414327 Test RE 0.8529834741613824\n",
      "59 Train Loss 0.60153395 Test MSE 3.1968094757497414 Test RE 0.8546069831703242\n",
      "60 Train Loss 0.5844364 Test MSE 3.17910772658789 Test RE 0.8522375834712929\n",
      "61 Train Loss 0.56523645 Test MSE 3.1737909079178244 Test RE 0.8515246336138717\n",
      "62 Train Loss 0.55117035 Test MSE 3.193724869280016 Test RE 0.8541945778554438\n",
      "63 Train Loss 0.5379861 Test MSE 3.207068553770865 Test RE 0.8559771706937992\n",
      "64 Train Loss 0.53000224 Test MSE 3.24298712585214 Test RE 0.8607572167087977\n",
      "65 Train Loss 0.5158649 Test MSE 3.2061408604272974 Test RE 0.8558533595335869\n",
      "66 Train Loss 0.51300716 Test MSE 3.2012930299155133 Test RE 0.8552060701943639\n",
      "67 Train Loss 0.50613004 Test MSE 3.202960653361259 Test RE 0.8554287889519006\n",
      "68 Train Loss 0.49773496 Test MSE 3.195959763988067 Test RE 0.8544933983803805\n",
      "69 Train Loss 0.4895447 Test MSE 3.198983965158879 Test RE 0.8548975882162126\n",
      "70 Train Loss 0.48214033 Test MSE 3.205422670372671 Test RE 0.8557574966530076\n",
      "71 Train Loss 0.4759974 Test MSE 3.198852382929429 Test RE 0.8548800059950137\n",
      "72 Train Loss 0.47076207 Test MSE 3.1998701581253073 Test RE 0.8550159932749297\n",
      "73 Train Loss 0.462603 Test MSE 3.2060245663913634 Test RE 0.8558378375168934\n",
      "74 Train Loss 0.45547178 Test MSE 3.205622130499087 Test RE 0.8557841213544547\n",
      "75 Train Loss 0.44794855 Test MSE 3.215467564235056 Test RE 0.8570972995875153\n",
      "76 Train Loss 0.4448249 Test MSE 3.20633589436819 Test RE 0.8558793905038999\n",
      "77 Train Loss 0.43945816 Test MSE 3.1999900287044727 Test RE 0.8550320080344989\n",
      "78 Train Loss 0.4333772 Test MSE 3.1952587406897126 Test RE 0.8543996780777718\n",
      "79 Train Loss 0.43076682 Test MSE 3.1924459429812884 Test RE 0.8540235297306843\n",
      "80 Train Loss 0.4279704 Test MSE 3.199679689408807 Test RE 0.8549905459576522\n",
      "81 Train Loss 0.42453644 Test MSE 3.2046128113920704 Test RE 0.8556493850643826\n",
      "82 Train Loss 0.41909283 Test MSE 3.2060348511506946 Test RE 0.8558392102573301\n",
      "83 Train Loss 0.41608852 Test MSE 3.205558020737897 Test RE 0.8557755638283759\n",
      "84 Train Loss 0.41404545 Test MSE 3.195760299840482 Test RE 0.8544667329231546\n",
      "85 Train Loss 0.41165066 Test MSE 3.2004002861460403 Test RE 0.8550868163305456\n",
      "86 Train Loss 0.4079566 Test MSE 3.2111784936514542 Test RE 0.8565254733363921\n",
      "87 Train Loss 0.4022025 Test MSE 3.2211009388700074 Test RE 0.8578477716682643\n",
      "88 Train Loss 0.39932692 Test MSE 3.2308777744167307 Test RE 0.8591486750249004\n",
      "89 Train Loss 0.39608544 Test MSE 3.2256223970861138 Test RE 0.8584496408339589\n",
      "90 Train Loss 0.39277336 Test MSE 3.228627432227352 Test RE 0.8588494196185441\n",
      "91 Train Loss 0.3887254 Test MSE 3.23297174624235 Test RE 0.8594270423674045\n",
      "92 Train Loss 0.3855751 Test MSE 3.2363768129749086 Test RE 0.8598795109505742\n",
      "93 Train Loss 0.38146526 Test MSE 3.240349590383266 Test RE 0.8604071167245063\n",
      "94 Train Loss 0.37818533 Test MSE 3.241072109775055 Test RE 0.8605030363404872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.37439558 Test MSE 3.242920928599201 Test RE 0.8607484315900537\n",
      "96 Train Loss 0.3706001 Test MSE 3.2666027372048827 Test RE 0.8638855726191077\n",
      "97 Train Loss 0.3664623 Test MSE 3.2739800525479676 Test RE 0.8648605246665088\n",
      "98 Train Loss 0.35902253 Test MSE 3.2967068303194735 Test RE 0.8678571068375586\n",
      "99 Train Loss 0.3564865 Test MSE 3.2999020389111213 Test RE 0.8682775738444187\n",
      "Training time: 159.27\n",
      "1\n",
      "KG_rowdy_tune32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 59.5419 Test MSE 7.305590484082721 Test RE 1.291920299890968\n",
      "1 Train Loss 45.658974 Test MSE 8.969803773024326 Test RE 1.4315269597896263\n",
      "2 Train Loss 41.87739 Test MSE 9.484106481374772 Test RE 1.4719947834871485\n",
      "3 Train Loss 39.37805 Test MSE 9.968555567434171 Test RE 1.509121398914375\n",
      "4 Train Loss 36.51384 Test MSE 9.497611598608643 Test RE 1.4730424515112566\n",
      "5 Train Loss 34.857155 Test MSE 9.6585040363767 Test RE 1.4854669480406075\n",
      "6 Train Loss 32.361866 Test MSE 9.490295984165034 Test RE 1.4724750306160934\n",
      "7 Train Loss 30.594164 Test MSE 9.443250707199883 Test RE 1.4688208211375524\n",
      "8 Train Loss 28.972374 Test MSE 9.530605200396778 Test RE 1.4755988226669778\n",
      "9 Train Loss 27.119488 Test MSE 9.389396469080898 Test RE 1.464626538355767\n",
      "10 Train Loss 24.91809 Test MSE 9.175305814768 Test RE 1.4478325442120534\n",
      "11 Train Loss 22.636345 Test MSE 9.022219437048419 Test RE 1.43570348025513\n",
      "12 Train Loss 20.696789 Test MSE 8.901959215583178 Test RE 1.4261028913529077\n",
      "13 Train Loss 19.579262 Test MSE 9.132071612016935 Test RE 1.444417410182639\n",
      "14 Train Loss 18.015629 Test MSE 8.684760424396314 Test RE 1.4085977215916017\n",
      "15 Train Loss 16.905888 Test MSE 8.655852328819297 Test RE 1.4062514381517135\n",
      "16 Train Loss 15.935204 Test MSE 8.473855066384592 Test RE 1.391389033755979\n",
      "17 Train Loss 15.290113 Test MSE 8.408820566557594 Test RE 1.3860394864260623\n",
      "18 Train Loss 14.490065 Test MSE 8.520120977989638 Test RE 1.3951822455106924\n",
      "19 Train Loss 13.981146 Test MSE 8.459635267927624 Test RE 1.390221113207178\n",
      "20 Train Loss 13.295576 Test MSE 8.208662818979164 Test RE 1.3694439720647775\n",
      "21 Train Loss 12.5774975 Test MSE 8.27184587920433 Test RE 1.374704256290829\n",
      "22 Train Loss 12.158859 Test MSE 8.33235356639841 Test RE 1.3797230040155632\n",
      "23 Train Loss 11.714376 Test MSE 8.097410388789383 Test RE 1.3601322414799457\n",
      "24 Train Loss 10.922155 Test MSE 8.03037433222159 Test RE 1.3544904750765836\n",
      "25 Train Loss 9.735449 Test MSE 7.272120527000195 Test RE 1.2889574896587603\n",
      "26 Train Loss 8.94599 Test MSE 6.997099782295855 Test RE 1.264349362426849\n",
      "27 Train Loss 8.511455 Test MSE 6.803474001706333 Test RE 1.2467329138907013\n",
      "28 Train Loss 8.152866 Test MSE 6.640169057985588 Test RE 1.2316792602593036\n",
      "29 Train Loss 7.8404465 Test MSE 6.586247355818377 Test RE 1.226668121112698\n",
      "30 Train Loss 7.632516 Test MSE 6.66130514715184 Test RE 1.233637960350967\n",
      "31 Train Loss 7.431916 Test MSE 6.670206949944693 Test RE 1.2344619682026632\n",
      "32 Train Loss 7.27171 Test MSE 6.676074867837073 Test RE 1.2350048395942699\n",
      "33 Train Loss 7.1059666 Test MSE 6.760543412774739 Test RE 1.2427931854901597\n",
      "34 Train Loss 6.90279 Test MSE 6.745830201884652 Test RE 1.2414400813986246\n",
      "35 Train Loss 6.750574 Test MSE 6.74035956552045 Test RE 1.2409365966887964\n",
      "36 Train Loss 6.581974 Test MSE 6.625651767048613 Test RE 1.2303321236319378\n",
      "37 Train Loss 6.4268894 Test MSE 6.495221481336175 Test RE 1.2181619856361237\n",
      "38 Train Loss 6.267053 Test MSE 6.398791885209866 Test RE 1.209085611521619\n",
      "39 Train Loss 6.0502367 Test MSE 6.422020567029195 Test RE 1.2112782146641066\n",
      "40 Train Loss 5.819982 Test MSE 6.36640698346356 Test RE 1.206022081059429\n",
      "41 Train Loss 5.5409184 Test MSE 6.2616425971822665 Test RE 1.1960578834254298\n",
      "42 Train Loss 5.1423364 Test MSE 6.101774543729492 Test RE 1.1806906897165392\n",
      "43 Train Loss 4.7971673 Test MSE 6.014329110785665 Test RE 1.1721998326032992\n",
      "44 Train Loss 4.290178 Test MSE 5.682778388469279 Test RE 1.1394320217146654\n",
      "45 Train Loss 3.4037175 Test MSE 5.578019990423592 Test RE 1.1288808177575775\n",
      "46 Train Loss 3.0809798 Test MSE 5.590188572663606 Test RE 1.1301114870114386\n",
      "47 Train Loss 2.8145237 Test MSE 5.560805590606408 Test RE 1.1271375448696261\n",
      "48 Train Loss 2.6085858 Test MSE 5.5700765374133 Test RE 1.1280767325723589\n",
      "49 Train Loss 2.5106823 Test MSE 5.585916997389568 Test RE 1.1296796340654682\n",
      "50 Train Loss 2.3138587 Test MSE 5.615043842111264 Test RE 1.1326210688953486\n",
      "51 Train Loss 2.2117896 Test MSE 5.627417494634627 Test RE 1.133868338511324\n",
      "52 Train Loss 2.1325238 Test MSE 5.582572524612626 Test RE 1.129341395197562\n",
      "53 Train Loss 2.0572255 Test MSE 5.566445148506471 Test RE 1.127708950083672\n",
      "54 Train Loss 1.9971449 Test MSE 5.542753672733083 Test RE 1.1253065570824374\n",
      "55 Train Loss 1.9372834 Test MSE 5.602955911770849 Test RE 1.1314012724567692\n",
      "56 Train Loss 1.8879849 Test MSE 5.599595215212937 Test RE 1.1310619099171881\n",
      "57 Train Loss 1.823751 Test MSE 5.574804502506818 Test RE 1.1285553953042144\n",
      "58 Train Loss 1.7814021 Test MSE 5.598007305138032 Test RE 1.1309015276146799\n",
      "59 Train Loss 1.7606893 Test MSE 5.573896870092134 Test RE 1.1284635216651007\n",
      "60 Train Loss 1.7264087 Test MSE 5.57454309001353 Test RE 1.1285289350096754\n",
      "61 Train Loss 1.6866616 Test MSE 5.603983163789392 Test RE 1.131504983872027\n",
      "62 Train Loss 1.6538411 Test MSE 5.640118396815731 Test RE 1.1351471697238182\n",
      "63 Train Loss 1.6151245 Test MSE 5.585623777347594 Test RE 1.1296499836914138\n",
      "64 Train Loss 1.5633119 Test MSE 5.589119791941081 Test RE 1.1300034495908011\n",
      "65 Train Loss 1.5263096 Test MSE 5.6050537748651985 Test RE 1.1316130627045486\n",
      "66 Train Loss 1.4899004 Test MSE 5.566817863503374 Test RE 1.127746703711982\n",
      "67 Train Loss 1.4618455 Test MSE 5.578741016941297 Test RE 1.1289537761464603\n",
      "68 Train Loss 1.445505 Test MSE 5.596004578239908 Test RE 1.1306992154890332\n",
      "69 Train Loss 1.4094651 Test MSE 5.612781893521631 Test RE 1.1323929149606997\n",
      "70 Train Loss 1.3883616 Test MSE 5.602304392753679 Test RE 1.1313354901369987\n",
      "71 Train Loss 1.3686838 Test MSE 5.637133736273208 Test RE 1.1348467791051848\n",
      "72 Train Loss 1.3526326 Test MSE 5.656500663462903 Test RE 1.1367945464465021\n",
      "73 Train Loss 1.331971 Test MSE 5.6508164810342825 Test RE 1.1362232239868157\n",
      "74 Train Loss 1.3197652 Test MSE 5.664404763231135 Test RE 1.1375885179605054\n",
      "75 Train Loss 1.302374 Test MSE 5.682220733260243 Test RE 1.1393761136932805\n",
      "76 Train Loss 1.2844151 Test MSE 5.690253341459088 Test RE 1.1401811624728924\n",
      "77 Train Loss 1.2686003 Test MSE 5.70237592123495 Test RE 1.1413950436922884\n",
      "78 Train Loss 1.2590159 Test MSE 5.715767061940253 Test RE 1.142734451949309\n",
      "79 Train Loss 1.237857 Test MSE 5.741344215032918 Test RE 1.1452883759554382\n",
      "80 Train Loss 1.2235186 Test MSE 5.7281923023428085 Test RE 1.1439758463241156\n",
      "81 Train Loss 1.210955 Test MSE 5.720023539925387 Test RE 1.1431598645644185\n",
      "82 Train Loss 1.1989483 Test MSE 5.7084142594771 Test RE 1.1419992046469\n",
      "83 Train Loss 1.1857767 Test MSE 5.721021171210359 Test RE 1.14325954967186\n",
      "84 Train Loss 1.1750312 Test MSE 5.696306481457229 Test RE 1.1407874484593332\n",
      "85 Train Loss 1.1652592 Test MSE 5.688567483243496 Test RE 1.140012248537283\n",
      "86 Train Loss 1.1506027 Test MSE 5.724495886196172 Test RE 1.143606681588555\n",
      "87 Train Loss 1.138393 Test MSE 5.738595528327843 Test RE 1.1450141879179188\n",
      "88 Train Loss 1.127806 Test MSE 5.747474357454655 Test RE 1.1458996359269866\n",
      "89 Train Loss 1.1205307 Test MSE 5.756292424150657 Test RE 1.146778347688341\n",
      "90 Train Loss 1.1167967 Test MSE 5.7593227962348585 Test RE 1.1470801659061272\n",
      "91 Train Loss 1.1102487 Test MSE 5.765468351093758 Test RE 1.1476920055954927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 1.1000347 Test MSE 5.748689929887264 Test RE 1.1460208065733775\n",
      "93 Train Loss 1.0923555 Test MSE 5.768323051602012 Test RE 1.1479761032000235\n",
      "94 Train Loss 1.0855209 Test MSE 5.758018421985859 Test RE 1.1469502629115613\n",
      "95 Train Loss 1.0792718 Test MSE 5.769661056349307 Test RE 1.1481092362094774\n",
      "96 Train Loss 1.0691783 Test MSE 5.808357273978841 Test RE 1.151952897140358\n",
      "97 Train Loss 1.0588475 Test MSE 5.8106758772643925 Test RE 1.1521827947819816\n",
      "98 Train Loss 1.0527694 Test MSE 5.816888052734379 Test RE 1.1527985277738084\n",
      "99 Train Loss 1.0437093 Test MSE 5.805939322260102 Test RE 1.1517130998710585\n",
      "Training time: 157.90\n",
      "2\n",
      "KG_rowdy_tune32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 67.0262 Test MSE 5.170877820842244 Test RE 1.086901525753792\n",
      "1 Train Loss 50.600502 Test MSE 7.864918638317486 Test RE 1.3404640694666474\n",
      "2 Train Loss 39.449352 Test MSE 6.438023446777778 Test RE 1.2127864532968786\n",
      "3 Train Loss 30.18592 Test MSE 5.876345725478428 Test RE 1.1586752485473697\n",
      "4 Train Loss 22.508091 Test MSE 6.1538855120836615 Test RE 1.1857216957065986\n",
      "5 Train Loss 16.961447 Test MSE 5.7327002778816185 Test RE 1.1444259011268842\n",
      "6 Train Loss 13.560925 Test MSE 5.494703482759112 Test RE 1.1204182927200343\n",
      "7 Train Loss 11.928658 Test MSE 5.629114972579562 Test RE 1.1340393380307223\n",
      "8 Train Loss 10.208559 Test MSE 5.4747572893439465 Test RE 1.1183828418310875\n",
      "9 Train Loss 8.753632 Test MSE 5.374470056990471 Test RE 1.108092164938819\n",
      "10 Train Loss 7.7419267 Test MSE 5.485016485775634 Test RE 1.1194302251681911\n",
      "11 Train Loss 7.118388 Test MSE 5.329473527800403 Test RE 1.1034437902065406\n",
      "12 Train Loss 6.350067 Test MSE 5.270470144032681 Test RE 1.0973185956993237\n",
      "13 Train Loss 5.8566647 Test MSE 5.187067383256151 Test RE 1.0886016924349928\n",
      "14 Train Loss 5.5210724 Test MSE 5.129244586426682 Test RE 1.082517098100751\n",
      "15 Train Loss 5.0393424 Test MSE 4.815161243660236 Test RE 1.0488502297380924\n",
      "16 Train Loss 4.689855 Test MSE 4.80668941326339 Test RE 1.0479271461035498\n",
      "17 Train Loss 4.3885903 Test MSE 4.711802599797164 Test RE 1.0375322478045221\n",
      "18 Train Loss 4.071739 Test MSE 4.500321535543242 Test RE 1.013981035112672\n",
      "19 Train Loss 3.8141708 Test MSE 4.135247081353134 Test RE 0.9719832752890957\n",
      "20 Train Loss 3.4417677 Test MSE 3.686430855645185 Test RE 0.9177219231146964\n",
      "21 Train Loss 3.171691 Test MSE 3.417327571220889 Test RE 0.8835911666480621\n",
      "22 Train Loss 2.9954405 Test MSE 3.1202367608204074 Test RE 0.8443098090356519\n",
      "23 Train Loss 2.8046372 Test MSE 2.8389563162822435 Test RE 0.8053551037554038\n",
      "24 Train Loss 2.5325015 Test MSE 2.6087490451037367 Test RE 0.7720122859451334\n",
      "25 Train Loss 2.3506088 Test MSE 2.3320642190254546 Test RE 0.7299251252932567\n",
      "26 Train Loss 2.2431672 Test MSE 2.3074450022669817 Test RE 0.7260620532984234\n",
      "27 Train Loss 2.0708318 Test MSE 2.1457469673686806 Test RE 0.7001600290162541\n",
      "28 Train Loss 1.946744 Test MSE 2.0853094197249686 Test RE 0.6902291757000543\n",
      "29 Train Loss 1.8684318 Test MSE 1.9918712722293679 Test RE 0.6745881287435251\n",
      "30 Train Loss 1.7720299 Test MSE 1.8040357916156347 Test RE 0.6419935060429298\n",
      "31 Train Loss 1.7079787 Test MSE 1.8073354647678004 Test RE 0.6425803571961664\n",
      "32 Train Loss 1.5932524 Test MSE 1.6207133834278145 Test RE 0.6085008223566964\n",
      "33 Train Loss 1.4521089 Test MSE 1.4600018713269935 Test RE 0.5775435878667936\n",
      "34 Train Loss 1.3130294 Test MSE 1.2206605344420696 Test RE 0.5280870431657239\n",
      "35 Train Loss 1.1473725 Test MSE 0.9058018920787557 Test RE 0.45490914975286356\n",
      "36 Train Loss 1.0051105 Test MSE 0.72297725970159 Test RE 0.40641560865154275\n",
      "37 Train Loss 0.8483395 Test MSE 0.6701824717803823 Test RE 0.39129526512804236\n",
      "38 Train Loss 0.74621636 Test MSE 0.6294888256341014 Test RE 0.37922946454904827\n",
      "39 Train Loss 0.6690897 Test MSE 0.5688461983451484 Test RE 0.36050018363413344\n",
      "40 Train Loss 0.58376503 Test MSE 0.4535535869347812 Test RE 0.32190102771740475\n",
      "41 Train Loss 0.514096 Test MSE 0.3643585990439763 Test RE 0.2885177734903742\n",
      "42 Train Loss 0.44555014 Test MSE 0.21405292597468784 Test RE 0.2211406820154306\n",
      "43 Train Loss 0.3970795 Test MSE 0.17486301454323486 Test RE 0.199874339150716\n",
      "44 Train Loss 0.33518934 Test MSE 0.12021052585836896 Test RE 0.16572167292700116\n",
      "45 Train Loss 0.28428948 Test MSE 0.0924176574758888 Test RE 0.1453066660647646\n",
      "46 Train Loss 0.24522427 Test MSE 0.10238720008281797 Test RE 0.15294345393526912\n",
      "47 Train Loss 0.22933164 Test MSE 0.09284586805590243 Test RE 0.14564291102502305\n",
      "48 Train Loss 0.2072431 Test MSE 0.08074879066024611 Test RE 0.1358238615933759\n",
      "49 Train Loss 0.15651329 Test MSE 0.05017689741177257 Test RE 0.10706806707316571\n",
      "50 Train Loss 0.13588223 Test MSE 0.039188178090236156 Test RE 0.09462057803013196\n",
      "51 Train Loss 0.12745722 Test MSE 0.03562505446544418 Test RE 0.0902164697512678\n",
      "52 Train Loss 0.112334445 Test MSE 0.02433240304828311 Test RE 0.0745590835296435\n",
      "53 Train Loss 0.1032501 Test MSE 0.023790786282866835 Test RE 0.07372460563358918\n",
      "54 Train Loss 0.09509588 Test MSE 0.023577531330055183 Test RE 0.07339343691388012\n",
      "55 Train Loss 0.08731042 Test MSE 0.020122445718560332 Test RE 0.0678029270181375\n",
      "56 Train Loss 0.08085834 Test MSE 0.019914502244979437 Test RE 0.06745168267430447\n",
      "57 Train Loss 0.07400514 Test MSE 0.0184677769435146 Test RE 0.06495541629765961\n",
      "58 Train Loss 0.06504961 Test MSE 0.015609274830718185 Test RE 0.0597171982717436\n",
      "59 Train Loss 0.0620503 Test MSE 0.01596419873752991 Test RE 0.060392307421872356\n",
      "60 Train Loss 0.059539076 Test MSE 0.014419972609338857 Test RE 0.05739714333126741\n",
      "61 Train Loss 0.053783987 Test MSE 0.015177890403397867 Test RE 0.05888623212054149\n",
      "62 Train Loss 0.05158238 Test MSE 0.015432766877627964 Test RE 0.05937860060803324\n",
      "63 Train Loss 0.047765717 Test MSE 0.01491697698466121 Test RE 0.05837790024751335\n",
      "64 Train Loss 0.045204088 Test MSE 0.013341149371221118 Test RE 0.055208339315354626\n",
      "65 Train Loss 0.043637596 Test MSE 0.012613936623973315 Test RE 0.0536825803242172\n",
      "66 Train Loss 0.04013845 Test MSE 0.011327462405622166 Test RE 0.05087148027086364\n",
      "67 Train Loss 0.03871922 Test MSE 0.010768096887036463 Test RE 0.04959952729927599\n",
      "68 Train Loss 0.035535958 Test MSE 0.010127305159869713 Test RE 0.04810110004229019\n",
      "69 Train Loss 0.03423719 Test MSE 0.009727001828732639 Test RE 0.047140866280681516\n",
      "70 Train Loss 0.032738753 Test MSE 0.010532200814052917 Test RE 0.04905323183396048\n",
      "71 Train Loss 0.031223858 Test MSE 0.010138317951312825 Test RE 0.04812724635869638\n",
      "72 Train Loss 0.030803896 Test MSE 0.01015002406959941 Test RE 0.048155023190556\n",
      "73 Train Loss 0.029482218 Test MSE 0.009056288063778103 Test RE 0.04548656843817174\n",
      "74 Train Loss 0.028154839 Test MSE 0.008661064241341991 Test RE 0.04448296120029367\n",
      "75 Train Loss 0.027722355 Test MSE 0.007832315731665254 Test RE 0.04230124536538428\n",
      "76 Train Loss 0.026380546 Test MSE 0.00782128736744871 Test RE 0.04227145354569269\n",
      "77 Train Loss 0.024939738 Test MSE 0.007244179128293033 Test RE 0.04068203326739971\n",
      "78 Train Loss 0.023868619 Test MSE 0.006775066460185345 Test RE 0.03934276150392837\n",
      "79 Train Loss 0.022766512 Test MSE 0.0060276209968263975 Test RE 0.03710915188239329\n",
      "80 Train Loss 0.020644147 Test MSE 0.005678272892882429 Test RE 0.036017717757920883\n",
      "81 Train Loss 0.019335518 Test MSE 0.005101659746208576 Test RE 0.034140022682636856\n",
      "82 Train Loss 0.018868241 Test MSE 0.004811027351038967 Test RE 0.03315331600878555\n",
      "83 Train Loss 0.018542096 Test MSE 0.004940596012318567 Test RE 0.03359678592002765\n",
      "84 Train Loss 0.018088942 Test MSE 0.00498098111802642 Test RE 0.033733818813938714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 0.016861228 Test MSE 0.004330398132416506 Test RE 0.03145371690591662\n",
      "86 Train Loss 0.01600077 Test MSE 0.00407782746247828 Test RE 0.030522667341615472\n",
      "87 Train Loss 0.015304556 Test MSE 0.0038649178882546194 Test RE 0.029715168418221524\n",
      "88 Train Loss 0.014880432 Test MSE 0.0039954868745862345 Test RE 0.03021293486724609\n",
      "89 Train Loss 0.013673856 Test MSE 0.0039046902196744645 Test RE 0.029867670572167684\n",
      "90 Train Loss 0.013087766 Test MSE 0.00388767708676828 Test RE 0.029802531299027196\n",
      "91 Train Loss 0.012800655 Test MSE 0.003836457273104116 Test RE 0.029605557467009356\n",
      "92 Train Loss 0.012621918 Test MSE 0.0037947545066831533 Test RE 0.029444209760620576\n",
      "93 Train Loss 0.012388587 Test MSE 0.0037165088990066264 Test RE 0.029139067453613474\n",
      "94 Train Loss 0.012080409 Test MSE 0.003779946036217028 Test RE 0.029386702757009976\n",
      "95 Train Loss 0.01187418 Test MSE 0.003790759553255252 Test RE 0.029428706884044874\n",
      "96 Train Loss 0.0115224365 Test MSE 0.003712240417789995 Test RE 0.029122329259373424\n",
      "97 Train Loss 0.011304088 Test MSE 0.003676865154684845 Test RE 0.028983238573229684\n",
      "98 Train Loss 0.011087969 Test MSE 0.003740390342331579 Test RE 0.029232538058361717\n",
      "99 Train Loss 0.010872431 Test MSE 0.0038037053167132304 Test RE 0.02947891481201578\n",
      "Training time: 157.54\n",
      "3\n",
      "KG_rowdy_tune32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 62.722065 Test MSE 5.851286200806229 Test RE 1.1562020386498877\n",
      "1 Train Loss 43.14196 Test MSE 8.328656644676917 Test RE 1.379416890394462\n",
      "2 Train Loss 35.10397 Test MSE 8.800177476866146 Test RE 1.417926684360513\n",
      "3 Train Loss 30.922787 Test MSE 8.73545701140298 Test RE 1.4127030268852685\n",
      "4 Train Loss 27.9553 Test MSE 8.726316463613385 Test RE 1.411963726170722\n",
      "5 Train Loss 25.190819 Test MSE 8.84944304631924 Test RE 1.4218900971493493\n",
      "6 Train Loss 23.138935 Test MSE 8.92910228272129 Test RE 1.428275409987327\n",
      "7 Train Loss 21.696606 Test MSE 8.974477379180806 Test RE 1.4318998509989473\n",
      "8 Train Loss 20.721394 Test MSE 8.875315879053806 Test RE 1.4239671473367346\n",
      "9 Train Loss 19.31357 Test MSE 9.117987456506372 Test RE 1.443303136766941\n",
      "10 Train Loss 18.318535 Test MSE 9.227045285786202 Test RE 1.4519089632348743\n",
      "11 Train Loss 17.605518 Test MSE 9.364894894051211 Test RE 1.4627143228802422\n",
      "12 Train Loss 16.985867 Test MSE 9.325472610065347 Test RE 1.4596323687856518\n",
      "13 Train Loss 16.340088 Test MSE 8.91912431508789 Test RE 1.427477162362945\n",
      "14 Train Loss 15.2415695 Test MSE 8.478179618139578 Test RE 1.3917440295837138\n",
      "15 Train Loss 14.211424 Test MSE 8.550561069064901 Test RE 1.3976723280664562\n",
      "16 Train Loss 12.45179 Test MSE 8.284118433151674 Test RE 1.3757236707783627\n",
      "17 Train Loss 9.5799265 Test MSE 7.084990414003478 Test RE 1.2722653335683964\n",
      "18 Train Loss 6.4786224 Test MSE 5.99285793992255 Test RE 1.1701055835591392\n",
      "19 Train Loss 5.1328135 Test MSE 5.785002794055343 Test RE 1.1496346548666256\n",
      "20 Train Loss 4.239601 Test MSE 5.704424251715114 Test RE 1.1416000235441788\n",
      "21 Train Loss 3.374618 Test MSE 5.487117724057692 Test RE 1.1196446241968139\n",
      "22 Train Loss 2.836754 Test MSE 5.440337078256148 Test RE 1.114861620012019\n",
      "23 Train Loss 2.478478 Test MSE 5.449130544334508 Test RE 1.1157622571815835\n",
      "24 Train Loss 2.235128 Test MSE 5.449762828539814 Test RE 1.115826988461433\n",
      "25 Train Loss 2.077916 Test MSE 5.531987823027235 Test RE 1.1242131682659045\n",
      "26 Train Loss 1.8831887 Test MSE 5.539255280097903 Test RE 1.1249513739201285\n",
      "27 Train Loss 1.7460836 Test MSE 5.492219117192451 Test RE 1.1201649721048725\n",
      "28 Train Loss 1.6746231 Test MSE 5.488728326581691 Test RE 1.1198089336065555\n",
      "29 Train Loss 1.5593921 Test MSE 5.543193090380654 Test RE 1.125351162146037\n",
      "30 Train Loss 1.4781339 Test MSE 5.580746149325314 Test RE 1.129156644356259\n",
      "31 Train Loss 1.4205201 Test MSE 5.5956987710990616 Test RE 1.1306683201767191\n",
      "32 Train Loss 1.3745059 Test MSE 5.601168594385675 Test RE 1.131220802140079\n",
      "33 Train Loss 1.3222021 Test MSE 5.632292656075772 Test RE 1.1343593803181207\n",
      "34 Train Loss 1.2788885 Test MSE 5.633113764959916 Test RE 1.1344420641093318\n",
      "35 Train Loss 1.2241354 Test MSE 5.605867107134386 Test RE 1.1316951621875537\n",
      "36 Train Loss 1.1827697 Test MSE 5.594742382644744 Test RE 1.1305716920002993\n",
      "37 Train Loss 1.1576055 Test MSE 5.630947980225997 Test RE 1.134223961510056\n",
      "38 Train Loss 1.1401367 Test MSE 5.660644905921751 Test RE 1.1372109071891812\n",
      "39 Train Loss 1.1078817 Test MSE 5.736402441800985 Test RE 1.1447953752191753\n",
      "40 Train Loss 1.0842041 Test MSE 5.692212893351258 Test RE 1.1403774676021887\n",
      "41 Train Loss 1.0677168 Test MSE 5.725386137110694 Test RE 1.1436956027210754\n",
      "42 Train Loss 1.0471373 Test MSE 5.7904445465567935 Test RE 1.1501752385937074\n",
      "43 Train Loss 1.0328358 Test MSE 5.778090976264175 Test RE 1.1489476681514166\n",
      "44 Train Loss 1.0228696 Test MSE 5.814410874459639 Test RE 1.152553036409905\n",
      "45 Train Loss 1.0127103 Test MSE 5.827089786586752 Test RE 1.1538089814500125\n",
      "46 Train Loss 0.9985378 Test MSE 5.853140249348585 Test RE 1.15638520221831\n",
      "47 Train Loss 0.9883918 Test MSE 5.885185781691303 Test RE 1.1595464451669626\n",
      "48 Train Loss 0.97430855 Test MSE 5.900361432420812 Test RE 1.1610404967742465\n",
      "49 Train Loss 0.9610491 Test MSE 5.914536525115458 Test RE 1.162434308329222\n",
      "50 Train Loss 0.95097065 Test MSE 5.945417214695769 Test RE 1.1654649802325199\n",
      "51 Train Loss 0.94218135 Test MSE 5.947992870437533 Test RE 1.165717402511607\n",
      "52 Train Loss 0.93274784 Test MSE 5.954660671607957 Test RE 1.1663706140148722\n",
      "53 Train Loss 0.924785 Test MSE 5.962622595109432 Test RE 1.1671501253881298\n",
      "54 Train Loss 0.91766155 Test MSE 5.947972037216142 Test RE 1.1657153610103372\n",
      "55 Train Loss 0.9096531 Test MSE 5.958730586950148 Test RE 1.1667691437603749\n",
      "56 Train Loss 0.90068907 Test MSE 5.967968282395716 Test RE 1.1676732024148146\n",
      "57 Train Loss 0.89106965 Test MSE 5.9535396355732795 Test RE 1.166260817243387\n",
      "58 Train Loss 0.8839989 Test MSE 5.982548213907633 Test RE 1.1690986632494516\n",
      "59 Train Loss 0.8762718 Test MSE 5.998730389984354 Test RE 1.170678741155044\n",
      "60 Train Loss 0.87019736 Test MSE 5.993823048524358 Test RE 1.170199798499077\n",
      "61 Train Loss 0.8629748 Test MSE 5.991029457881557 Test RE 1.1699270643710433\n",
      "62 Train Loss 0.85777104 Test MSE 5.995328441199097 Test RE 1.1703467414096307\n",
      "63 Train Loss 0.84990525 Test MSE 6.018950455036183 Test RE 1.1726500988457367\n",
      "64 Train Loss 0.8444011 Test MSE 6.019447027360486 Test RE 1.1726984705327734\n",
      "65 Train Loss 0.8382459 Test MSE 6.030705330377071 Test RE 1.1737946199929674\n",
      "66 Train Loss 0.83188194 Test MSE 6.04480222077389 Test RE 1.1751657030452451\n",
      "67 Train Loss 0.8234577 Test MSE 6.060706750454615 Test RE 1.1767106816164028\n",
      "68 Train Loss 0.8191178 Test MSE 6.070035765000258 Test RE 1.1776159662996384\n",
      "69 Train Loss 0.8144141 Test MSE 6.074311892840852 Test RE 1.178030687898387\n",
      "70 Train Loss 0.80945927 Test MSE 6.096699102516544 Test RE 1.1801995397400784\n",
      "71 Train Loss 0.80496466 Test MSE 6.107021443794518 Test RE 1.181198217061719\n",
      "72 Train Loss 0.8011696 Test MSE 6.1207249956460625 Test RE 1.1825227204262754\n",
      "73 Train Loss 0.7963011 Test MSE 6.114152819032086 Test RE 1.181887678373336\n",
      "74 Train Loss 0.79154503 Test MSE 6.132259224311381 Test RE 1.183636401221242\n",
      "75 Train Loss 0.7863209 Test MSE 6.133906989291709 Test RE 1.183795414689233\n",
      "76 Train Loss 0.78032464 Test MSE 6.147227658769992 Test RE 1.1850801093887244\n",
      "77 Train Loss 0.7759184 Test MSE 6.138576437843052 Test RE 1.1842459122437587\n",
      "78 Train Loss 0.7718979 Test MSE 6.1509269949827505 Test RE 1.1854366400593594\n",
      "79 Train Loss 0.7688577 Test MSE 6.150506579803016 Test RE 1.1853961271354723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.7637264 Test MSE 6.1609658093900235 Test RE 1.1864036103056472\n",
      "81 Train Loss 0.75788075 Test MSE 6.185861480459067 Test RE 1.1887982459011077\n",
      "82 Train Loss 0.75346905 Test MSE 6.194246495111378 Test RE 1.1896036886887267\n",
      "83 Train Loss 0.75015885 Test MSE 6.196116368223553 Test RE 1.1897832295018644\n",
      "84 Train Loss 0.7477051 Test MSE 6.202410292726101 Test RE 1.190387358337403\n",
      "85 Train Loss 0.7433373 Test MSE 6.181703158687363 Test RE 1.188398605794432\n",
      "86 Train Loss 0.7404444 Test MSE 6.1790727230105835 Test RE 1.1881457354587313\n",
      "87 Train Loss 0.7372597 Test MSE 6.177149838755984 Test RE 1.1879608497485246\n",
      "88 Train Loss 0.73426473 Test MSE 6.158287012035949 Test RE 1.1861456572111093\n",
      "89 Train Loss 0.7310104 Test MSE 6.167405410245871 Test RE 1.187023478246065\n",
      "90 Train Loss 0.727306 Test MSE 6.163080765798992 Test RE 1.1866072290801157\n",
      "91 Train Loss 0.7226407 Test MSE 6.178178418869208 Test RE 1.1880597515135098\n",
      "92 Train Loss 0.71964103 Test MSE 6.18711994189836 Test RE 1.188919165248719\n",
      "93 Train Loss 0.7169562 Test MSE 6.198520178840817 Test RE 1.1900139979424855\n",
      "94 Train Loss 0.71380264 Test MSE 6.204872503520299 Test RE 1.1906236127642644\n",
      "95 Train Loss 0.7100002 Test MSE 6.209177931995278 Test RE 1.1910366152780352\n",
      "96 Train Loss 0.7070286 Test MSE 6.214934006632669 Test RE 1.1915885488520945\n",
      "97 Train Loss 0.7038007 Test MSE 6.2174507615283 Test RE 1.191829792988014\n",
      "98 Train Loss 0.70091265 Test MSE 6.225095082924838 Test RE 1.1925622419979909\n",
      "99 Train Loss 0.696802 Test MSE 6.213173525282301 Test RE 1.1914197684601213\n",
      "Training time: 156.87\n",
      "4\n",
      "KG_rowdy_tune32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 54.114883 Test MSE 7.284044939000016 Test RE 1.2900138366019627\n",
      "1 Train Loss 42.65042 Test MSE 7.550125847778722 Test RE 1.313364144331011\n",
      "2 Train Loss 34.82319 Test MSE 7.224814343738779 Test RE 1.2847582229734584\n",
      "3 Train Loss 30.65156 Test MSE 6.767589667522048 Test RE 1.243440674623507\n",
      "4 Train Loss 27.60946 Test MSE 6.3355665895541415 Test RE 1.2030974054956742\n",
      "5 Train Loss 24.309929 Test MSE 6.718693063685821 Test RE 1.2389405313402655\n",
      "6 Train Loss 20.410374 Test MSE 6.220601342387644 Test RE 1.1921317238523528\n",
      "7 Train Loss 18.236511 Test MSE 5.916097717975902 Test RE 1.1625877154807391\n",
      "8 Train Loss 14.963313 Test MSE 5.544231589498009 Test RE 1.1254565726411938\n",
      "9 Train Loss 12.705772 Test MSE 5.66469171919346 Test RE 1.137617332433283\n",
      "10 Train Loss 10.950423 Test MSE 5.279815245981054 Test RE 1.0982909959111893\n",
      "11 Train Loss 9.548305 Test MSE 5.1569266708951504 Test RE 1.0854342924911202\n",
      "12 Train Loss 8.387644 Test MSE 4.741674748827061 Test RE 1.0408159538900108\n",
      "13 Train Loss 7.431793 Test MSE 4.123915894188123 Test RE 0.9706506729851807\n",
      "14 Train Loss 6.7659407 Test MSE 3.3809425491235854 Test RE 0.8788746860508501\n",
      "15 Train Loss 5.578838 Test MSE 2.854365489888988 Test RE 0.8075377831176422\n",
      "16 Train Loss 3.9903362 Test MSE 2.4009866401080915 Test RE 0.7406327838503816\n",
      "17 Train Loss 3.3704605 Test MSE 2.112441800464989 Test RE 0.6947050191188874\n",
      "18 Train Loss 2.9075024 Test MSE 1.9333825356911991 Test RE 0.6646101290833974\n",
      "19 Train Loss 2.6606069 Test MSE 1.7939765140055033 Test RE 0.64020113071041\n",
      "20 Train Loss 2.336447 Test MSE 1.4877090696529862 Test RE 0.5829980009500443\n",
      "21 Train Loss 1.9919571 Test MSE 1.26593441915094 Test RE 0.537791166274245\n",
      "22 Train Loss 1.7144673 Test MSE 0.9815947954460821 Test RE 0.473559097039684\n",
      "23 Train Loss 1.3572966 Test MSE 0.7208123472979523 Test RE 0.40580665875984984\n",
      "24 Train Loss 1.1101688 Test MSE 0.558668167323332 Test RE 0.35726051780993556\n",
      "25 Train Loss 0.92934245 Test MSE 0.45085671049074627 Test RE 0.32094257245582075\n",
      "26 Train Loss 0.739677 Test MSE 0.3632078566372347 Test RE 0.2880618048421422\n",
      "27 Train Loss 0.562429 Test MSE 0.19429185228513307 Test RE 0.21068584317534658\n",
      "28 Train Loss 0.4550209 Test MSE 0.1362510431456755 Test RE 0.17643225229006596\n",
      "29 Train Loss 0.3543741 Test MSE 0.10557294877671276 Test RE 0.15530462393792846\n",
      "30 Train Loss 0.2750812 Test MSE 0.07098913079992734 Test RE 0.12735147799833307\n",
      "31 Train Loss 0.20670323 Test MSE 0.048003755790142356 Test RE 0.10472386667861865\n",
      "32 Train Loss 0.17250738 Test MSE 0.04131447134277177 Test RE 0.09715365868780583\n",
      "33 Train Loss 0.13263053 Test MSE 0.03131915471592391 Test RE 0.08458884137045544\n",
      "34 Train Loss 0.11627008 Test MSE 0.023191740611952873 Test RE 0.07279050506371308\n",
      "35 Train Loss 0.08748401 Test MSE 0.018220015239132487 Test RE 0.06451822759631495\n",
      "36 Train Loss 0.074737445 Test MSE 0.01586252466849952 Test RE 0.060199684548907076\n",
      "37 Train Loss 0.06644891 Test MSE 0.014048508882688661 Test RE 0.05665303431666544\n",
      "38 Train Loss 0.059167504 Test MSE 0.012489780221459459 Test RE 0.05341773366646044\n",
      "39 Train Loss 0.05173383 Test MSE 0.009283756815793071 Test RE 0.04605427375519202\n",
      "40 Train Loss 0.04711446 Test MSE 0.007645718286489499 Test RE 0.04179431448501141\n",
      "41 Train Loss 0.044069212 Test MSE 0.006783680264527987 Test RE 0.03936776370900184\n",
      "42 Train Loss 0.04087642 Test MSE 0.00662833487508962 Test RE 0.038914394839174846\n",
      "43 Train Loss 0.034572233 Test MSE 0.007057540209494229 Test RE 0.04015454792904178\n",
      "44 Train Loss 0.030490192 Test MSE 0.006115706294376359 Test RE 0.03737931775900557\n",
      "45 Train Loss 0.028324429 Test MSE 0.005126786945606313 Test RE 0.034223994322239236\n",
      "46 Train Loss 0.02674216 Test MSE 0.004268304680627773 Test RE 0.031227395711310352\n",
      "47 Train Loss 0.025551729 Test MSE 0.0039839211467959205 Test RE 0.030169174515259512\n",
      "48 Train Loss 0.02303495 Test MSE 0.003848672052881203 Test RE 0.02965265013013936\n",
      "49 Train Loss 0.021243386 Test MSE 0.0036114660031776815 Test RE 0.028724324594404715\n",
      "50 Train Loss 0.01939276 Test MSE 0.003062850370611671 Test RE 0.026452757500193724\n",
      "51 Train Loss 0.017604545 Test MSE 0.0029609899777757113 Test RE 0.02600917213781339\n",
      "52 Train Loss 0.016116783 Test MSE 0.0028388576978873904 Test RE 0.02546712218680806\n",
      "53 Train Loss 0.015106551 Test MSE 0.0026820955030979173 Test RE 0.024753988182624104\n",
      "54 Train Loss 0.013733357 Test MSE 0.0020958987610388033 Test RE 0.021882312241586953\n",
      "55 Train Loss 0.013261681 Test MSE 0.0020445110764273013 Test RE 0.021612389914567636\n",
      "56 Train Loss 0.012756046 Test MSE 0.0018200297487782101 Test RE 0.020391412194841533\n",
      "57 Train Loss 0.012174782 Test MSE 0.0019025765628275842 Test RE 0.02084870726754022\n",
      "58 Train Loss 0.011634484 Test MSE 0.0015035983607147728 Test RE 0.01853420584393889\n",
      "59 Train Loss 0.01097323 Test MSE 0.0014774494555121135 Test RE 0.018372335876601895\n",
      "60 Train Loss 0.010146209 Test MSE 0.001426353631659337 Test RE 0.018051847932160463\n",
      "61 Train Loss 0.00949274 Test MSE 0.001302475005471388 Test RE 0.01725014536777293\n",
      "62 Train Loss 0.009299301 Test MSE 0.0012788125718956953 Test RE 0.01709273300541981\n",
      "63 Train Loss 0.008838419 Test MSE 0.0013324222875047244 Test RE 0.017447331170354533\n",
      "64 Train Loss 0.008313431 Test MSE 0.0011666094128807303 Test RE 0.016325661910043067\n",
      "65 Train Loss 0.0076998193 Test MSE 0.0011723616889128582 Test RE 0.0163658614127784\n",
      "66 Train Loss 0.0072623063 Test MSE 0.0010985905883761152 Test RE 0.015842583227586995\n",
      "67 Train Loss 0.0069490494 Test MSE 0.0009902638478310423 Test RE 0.015041235894117006\n",
      "68 Train Loss 0.0065780804 Test MSE 0.0009280916211120832 Test RE 0.014561411874150332\n",
      "69 Train Loss 0.0060858047 Test MSE 0.0008233046685922826 Test RE 0.01371476433324286\n",
      "70 Train Loss 0.005909472 Test MSE 0.000794080554389903 Test RE 0.013469154692968843\n",
      "71 Train Loss 0.005701899 Test MSE 0.0007823641039515403 Test RE 0.013369418506990794\n",
      "72 Train Loss 0.005443813 Test MSE 0.0007188670777709423 Test RE 0.012815405648317247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 0.005291922 Test MSE 0.0007255057038363326 Test RE 0.012874443802128233\n",
      "74 Train Loss 0.0050063934 Test MSE 0.0007073896065443204 Test RE 0.012712688265718934\n",
      "75 Train Loss 0.0047316 Test MSE 0.0007092815042777778 Test RE 0.012729676815116057\n",
      "76 Train Loss 0.0045578396 Test MSE 0.0006824447220831408 Test RE 0.012486531006829544\n",
      "77 Train Loss 0.004403867 Test MSE 0.0007117660546498377 Test RE 0.012751952790435306\n",
      "78 Train Loss 0.004229993 Test MSE 0.0007077017753074486 Test RE 0.012715492990590329\n",
      "79 Train Loss 0.004026182 Test MSE 0.0007003708171778646 Test RE 0.0126494627696521\n",
      "80 Train Loss 0.003881826 Test MSE 0.0007851627821047299 Test RE 0.013393309747147704\n",
      "81 Train Loss 0.0038249483 Test MSE 0.0007430422652405937 Test RE 0.013029112053577497\n",
      "82 Train Loss 0.003710579 Test MSE 0.0007246647551532637 Test RE 0.01286698012148484\n",
      "83 Train Loss 0.0036258493 Test MSE 0.0007428287169880467 Test RE 0.013027239653998332\n",
      "84 Train Loss 0.0033689402 Test MSE 0.0005831967266390737 Test RE 0.011542917698625527\n",
      "85 Train Loss 0.0032661986 Test MSE 0.0006294188913269786 Test RE 0.011991622466185604\n",
      "86 Train Loss 0.0031771844 Test MSE 0.0006047513039448274 Test RE 0.011754291776752685\n",
      "87 Train Loss 0.003102366 Test MSE 0.0005809841791542042 Test RE 0.011521000975425816\n",
      "88 Train Loss 0.002861034 Test MSE 0.0006046887543563135 Test RE 0.011753683886268403\n",
      "89 Train Loss 0.002713121 Test MSE 0.0005409283149781691 Test RE 0.011116752017151631\n",
      "90 Train Loss 0.0025433917 Test MSE 0.0005552481655138622 Test RE 0.011262936263302159\n",
      "91 Train Loss 0.0024724952 Test MSE 0.0005636444349489353 Test RE 0.011347773845929755\n",
      "92 Train Loss 0.0024247626 Test MSE 0.0005720678991880837 Test RE 0.01143225359478873\n",
      "93 Train Loss 0.0023686886 Test MSE 0.0005772835624706309 Test RE 0.0114842504765858\n",
      "94 Train Loss 0.0023027179 Test MSE 0.000538764894622349 Test RE 0.011094499250844402\n",
      "95 Train Loss 0.0022386503 Test MSE 0.0005022090334743641 Test RE 0.010711500698100502\n",
      "96 Train Loss 0.0021668558 Test MSE 0.0005234262348122656 Test RE 0.01093542845122824\n",
      "97 Train Loss 0.0020777774 Test MSE 0.00046327073448754517 Test RE 0.010287870604770091\n",
      "98 Train Loss 0.002028292 Test MSE 0.0004430794367490805 Test RE 0.010061178585054514\n",
      "99 Train Loss 0.001995418 Test MSE 0.00043786864782280934 Test RE 0.010001841899252607\n",
      "Training time: 159.08\n",
      "5\n",
      "KG_rowdy_tune32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.48\n",
      "0\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 75.29877 Test MSE 4.4041095541573645 Test RE 1.0030835704228982\n",
      "1 Train Loss 72.17046 Test MSE 4.43070719770193 Test RE 1.0061079614638155\n",
      "2 Train Loss 51.64415 Test MSE 5.764336107761874 Test RE 1.147579306128077\n",
      "3 Train Loss 33.86998 Test MSE 5.867678619053258 Test RE 1.1578204598913158\n",
      "4 Train Loss 27.048103 Test MSE 5.64870299042329 Test RE 1.1360107218018984\n",
      "5 Train Loss 22.19938 Test MSE 5.490642482675974 Test RE 1.120004179401027\n",
      "6 Train Loss 19.663315 Test MSE 5.181492182214298 Test RE 1.0880165058019293\n",
      "7 Train Loss 17.516954 Test MSE 4.856633394317934 Test RE 1.0533573286058935\n",
      "8 Train Loss 16.004288 Test MSE 4.96612641109529 Test RE 1.065165141630917\n",
      "9 Train Loss 14.886213 Test MSE 5.194193500525649 Test RE 1.0893492093086687\n",
      "10 Train Loss 14.257559 Test MSE 5.205258512648508 Test RE 1.0905088936425786\n",
      "11 Train Loss 13.252256 Test MSE 5.169637920772473 Test RE 1.0867712064810695\n",
      "12 Train Loss 12.573929 Test MSE 5.154968999028583 Test RE 1.0852282467183967\n",
      "13 Train Loss 11.890281 Test MSE 5.1495220778646145 Test RE 1.084654750057771\n",
      "14 Train Loss 11.127692 Test MSE 5.2540739707367345 Test RE 1.0956104140672123\n",
      "15 Train Loss 10.472349 Test MSE 5.2730814611917785 Test RE 1.0975904018150597\n",
      "16 Train Loss 9.882347 Test MSE 5.372994841500254 Test RE 1.1079400767423917\n",
      "17 Train Loss 9.150987 Test MSE 5.362615457245052 Test RE 1.1068694173423443\n",
      "18 Train Loss 8.815786 Test MSE 5.317238201490271 Test RE 1.1021764274434864\n",
      "19 Train Loss 8.163684 Test MSE 5.363696932128782 Test RE 1.1069810225038481\n",
      "20 Train Loss 7.334547 Test MSE 5.152835986250283 Test RE 1.0850037016996454\n",
      "21 Train Loss 6.6218987 Test MSE 5.168249106823307 Test RE 1.0866252171084\n",
      "22 Train Loss 6.210886 Test MSE 5.117444356563645 Test RE 1.0812711733154206\n",
      "23 Train Loss 5.5498276 Test MSE 5.172381372241645 Test RE 1.0870595350500623\n",
      "24 Train Loss 4.8821607 Test MSE 5.013514309051444 Test RE 1.07023509865354\n",
      "25 Train Loss 4.4572797 Test MSE 4.860004924191611 Test RE 1.0537228914625707\n",
      "26 Train Loss 3.9547548 Test MSE 4.763048714711671 Test RE 1.0431591503684166\n",
      "27 Train Loss 3.4397955 Test MSE 4.756107073327775 Test RE 1.0423987259615757\n",
      "28 Train Loss 3.1608238 Test MSE 4.738398828593037 Test RE 1.0404563531859066\n",
      "29 Train Loss 2.9892192 Test MSE 4.673629279616455 Test RE 1.0333208451691376\n",
      "30 Train Loss 2.7410388 Test MSE 4.547254622732863 Test RE 1.0192546391955624\n",
      "31 Train Loss 2.594431 Test MSE 4.471513349865509 Test RE 1.010730394975379\n",
      "32 Train Loss 2.4366179 Test MSE 4.457698705477085 Test RE 1.009167872280883\n",
      "33 Train Loss 2.3295023 Test MSE 4.380224023054845 Test RE 1.0003597783190634\n",
      "34 Train Loss 2.1936815 Test MSE 4.295937988596441 Test RE 0.9906883641762554\n",
      "35 Train Loss 2.0193915 Test MSE 4.187397959193354 Test RE 0.9780930631457275\n",
      "36 Train Loss 1.9101698 Test MSE 4.122001110118727 Test RE 0.9704253043932379\n",
      "37 Train Loss 1.806887 Test MSE 4.03946089238242 Test RE 0.9606601245983822\n",
      "38 Train Loss 1.7538532 Test MSE 4.085018022227419 Test RE 0.9660621095077441\n",
      "39 Train Loss 1.6976261 Test MSE 4.104821270749544 Test RE 0.9684009043513485\n",
      "40 Train Loss 1.6425676 Test MSE 4.050981191407148 Test RE 0.9620290216805919\n",
      "41 Train Loss 1.5772434 Test MSE 4.049320160288108 Test RE 0.9618317702118576\n",
      "42 Train Loss 1.5281277 Test MSE 4.035570312293141 Test RE 0.9601973864224541\n",
      "43 Train Loss 1.4861596 Test MSE 4.089250106278011 Test RE 0.9665624007745132\n",
      "44 Train Loss 1.4569043 Test MSE 4.050733420996147 Test RE 0.9619996009106986\n",
      "45 Train Loss 1.4078305 Test MSE 3.941959910967144 Test RE 0.9489955193242755\n",
      "46 Train Loss 1.3719909 Test MSE 3.8718224856048975 Test RE 0.9405151141999154\n",
      "47 Train Loss 1.3181485 Test MSE 3.727989936171608 Test RE 0.9228804070632582\n",
      "48 Train Loss 1.2721542 Test MSE 3.681579630277104 Test RE 0.9171178779405649\n",
      "49 Train Loss 1.2109836 Test MSE 3.5749047054306424 Test RE 0.9037333206874212\n",
      "50 Train Loss 1.1739548 Test MSE 3.5378611909534414 Test RE 0.8990388410372867\n",
      "51 Train Loss 1.1280131 Test MSE 3.475536004193193 Test RE 0.8910846371193892\n",
      "52 Train Loss 1.0737714 Test MSE 3.4044037103585634 Test RE 0.8819187740869149\n",
      "53 Train Loss 1.0176904 Test MSE 3.398325669376097 Test RE 0.8811311569941517\n",
      "54 Train Loss 0.9748895 Test MSE 3.352142463391673 Test RE 0.8751233947729128\n",
      "55 Train Loss 0.9256108 Test MSE 3.33284619736818 Test RE 0.8726009802681297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 Train Loss 0.887946 Test MSE 3.240601454663806 Test RE 0.8604405547228678\n",
      "57 Train Loss 0.8642982 Test MSE 3.187261201509144 Test RE 0.853329752835219\n",
      "58 Train Loss 0.8336636 Test MSE 3.158381561193855 Test RE 0.8494549629513369\n",
      "59 Train Loss 0.80728906 Test MSE 3.1860167255273386 Test RE 0.8531631439513973\n",
      "60 Train Loss 0.7902614 Test MSE 3.1873503928551634 Test RE 0.8533416924115493\n",
      "61 Train Loss 0.76533705 Test MSE 3.1715255709649615 Test RE 0.8512206856525059\n",
      "62 Train Loss 0.74644387 Test MSE 3.1482831036776 Test RE 0.8480958724580044\n",
      "63 Train Loss 0.7244296 Test MSE 3.0998110121246456 Test RE 0.8415417536726165\n",
      "64 Train Loss 0.7037969 Test MSE 3.097442648342056 Test RE 0.8412202086100726\n",
      "65 Train Loss 0.6940014 Test MSE 3.090859950031859 Test RE 0.8403258507987766\n",
      "66 Train Loss 0.6692413 Test MSE 3.0309444399377745 Test RE 0.8321412443859945\n",
      "67 Train Loss 0.6546677 Test MSE 3.047440911644434 Test RE 0.834402712215166\n",
      "68 Train Loss 0.64441264 Test MSE 3.0521822155925293 Test RE 0.8350515548680824\n",
      "69 Train Loss 0.62846076 Test MSE 3.05232238741131 Test RE 0.8350707295672145\n",
      "70 Train Loss 0.6103141 Test MSE 3.042060611791824 Test RE 0.8336658119490555\n",
      "71 Train Loss 0.60000235 Test MSE 3.0516608247416417 Test RE 0.8349802277313936\n",
      "72 Train Loss 0.5897118 Test MSE 3.0330339904264894 Test RE 0.8324280364398783\n",
      "73 Train Loss 0.5764698 Test MSE 3.057892312101894 Test RE 0.8358323072262096\n",
      "74 Train Loss 0.5665932 Test MSE 3.020562411037777 Test RE 0.8307148366318556\n",
      "75 Train Loss 0.55569 Test MSE 3.0403739133088967 Test RE 0.8334346630657794\n",
      "76 Train Loss 0.54526174 Test MSE 3.030446235106954 Test RE 0.8320728508813\n",
      "77 Train Loss 0.5351204 Test MSE 3.055966112872807 Test RE 0.8355690158808619\n",
      "78 Train Loss 0.5258483 Test MSE 3.0745793688272918 Test RE 0.8381097917317074\n",
      "79 Train Loss 0.51910794 Test MSE 3.0725744801898616 Test RE 0.8378364875470268\n",
      "80 Train Loss 0.51547456 Test MSE 3.0682148881531535 Test RE 0.8372418848977987\n",
      "81 Train Loss 0.50712943 Test MSE 3.061593424184526 Test RE 0.8363379780030976\n",
      "82 Train Loss 0.50162965 Test MSE 3.0703825915340786 Test RE 0.8375375896784537\n",
      "83 Train Loss 0.49488002 Test MSE 3.037379840996403 Test RE 0.8330241908075482\n",
      "84 Train Loss 0.48872504 Test MSE 3.0400947222450005 Test RE 0.833396395921844\n",
      "85 Train Loss 0.4826547 Test MSE 3.0574333623878185 Test RE 0.8357695811139291\n",
      "86 Train Loss 0.4773037 Test MSE 3.0605552284149904 Test RE 0.8361961635861975\n",
      "87 Train Loss 0.4729591 Test MSE 3.069394708795976 Test RE 0.8374028417332668\n",
      "88 Train Loss 0.46533033 Test MSE 3.093642557459859 Test RE 0.8407040256359546\n",
      "89 Train Loss 0.4543195 Test MSE 3.1286934093961984 Test RE 0.8454531838182381\n",
      "90 Train Loss 0.4487112 Test MSE 3.1390166843712253 Test RE 0.8468468419559918\n",
      "91 Train Loss 0.44058627 Test MSE 3.1730471117741312 Test RE 0.8514248479207686\n",
      "92 Train Loss 0.43453318 Test MSE 3.17966967091632 Test RE 0.8523129016039777\n",
      "93 Train Loss 0.42885625 Test MSE 3.1822581649354267 Test RE 0.8526597549337159\n",
      "94 Train Loss 0.4245456 Test MSE 3.179846140979491 Test RE 0.8523365527439273\n",
      "95 Train Loss 0.42101768 Test MSE 3.2019284735972335 Test RE 0.8552909434508962\n",
      "96 Train Loss 0.41750115 Test MSE 3.2012764202967308 Test RE 0.8552038516118886\n",
      "97 Train Loss 0.41538474 Test MSE 3.2072678093073206 Test RE 0.8560037612605994\n",
      "98 Train Loss 0.4110934 Test MSE 3.2269441819938947 Test RE 0.8586255091504469\n",
      "99 Train Loss 0.40695584 Test MSE 3.246451415239183 Test RE 0.8612168417474434\n",
      "Training time: 157.65\n",
      "1\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 62.491844 Test MSE 6.943027753765657 Test RE 1.2594545825233916\n",
      "1 Train Loss 48.754307 Test MSE 8.780418737555925 Test RE 1.416333978556421\n",
      "2 Train Loss 43.197876 Test MSE 8.953887194108185 Test RE 1.4302563005217597\n",
      "3 Train Loss 41.18142 Test MSE 9.582187273124838 Test RE 1.4795865933403574\n",
      "4 Train Loss 38.802593 Test MSE 9.708129339893485 Test RE 1.4892782163990268\n",
      "5 Train Loss 36.48702 Test MSE 9.783090745997537 Test RE 1.495016897307286\n",
      "6 Train Loss 33.65145 Test MSE 9.97369113827691 Test RE 1.5095100812002797\n",
      "7 Train Loss 31.271923 Test MSE 9.861311378635087 Test RE 1.5009816966638663\n",
      "8 Train Loss 28.00382 Test MSE 9.481749602760159 Test RE 1.4718118707057573\n",
      "9 Train Loss 25.91594 Test MSE 9.527569189338058 Test RE 1.4753637750975122\n",
      "10 Train Loss 24.085922 Test MSE 9.60740799629849 Test RE 1.4815324810900061\n",
      "11 Train Loss 23.06044 Test MSE 9.771920436010847 Test RE 1.494163150148844\n",
      "12 Train Loss 22.31319 Test MSE 9.588201653225898 Test RE 1.4800508610481864\n",
      "13 Train Loss 21.811335 Test MSE 9.737510180913649 Test RE 1.4915301018461296\n",
      "14 Train Loss 21.278015 Test MSE 9.703247303727712 Test RE 1.4889037042677704\n",
      "15 Train Loss 20.796997 Test MSE 9.548875580569808 Test RE 1.4770125231963107\n",
      "16 Train Loss 20.451485 Test MSE 9.432983243596288 Test RE 1.4680220937524424\n",
      "17 Train Loss 19.671543 Test MSE 9.429345741385836 Test RE 1.4677390206056786\n",
      "18 Train Loss 19.323307 Test MSE 9.323769908642221 Test RE 1.459499108431353\n",
      "19 Train Loss 18.906166 Test MSE 9.287131402879478 Test RE 1.4566286760334806\n",
      "20 Train Loss 18.310535 Test MSE 9.15171457532042 Test RE 1.445970036929567\n",
      "21 Train Loss 17.774004 Test MSE 9.20613619725085 Test RE 1.4502629698541578\n",
      "22 Train Loss 17.407417 Test MSE 9.078730407236943 Test RE 1.4401927497003444\n",
      "23 Train Loss 16.286678 Test MSE 8.518532116352976 Test RE 1.3950521502392588\n",
      "24 Train Loss 15.264236 Test MSE 8.188734483691272 Test RE 1.3677806486380382\n",
      "25 Train Loss 14.436884 Test MSE 8.078336782790513 Test RE 1.358529388200795\n",
      "26 Train Loss 13.553108 Test MSE 7.958350067793566 Test RE 1.3484025950201999\n",
      "27 Train Loss 12.728346 Test MSE 7.82849521943243 Test RE 1.3373565393279785\n",
      "28 Train Loss 11.834762 Test MSE 6.981343560375304 Test RE 1.2629250153939504\n",
      "29 Train Loss 10.763608 Test MSE 6.502529985625534 Test RE 1.21884713849083\n",
      "30 Train Loss 10.088831 Test MSE 6.118131583101141 Test RE 1.1822721705172328\n",
      "31 Train Loss 9.608698 Test MSE 6.085901879385762 Test RE 1.1791540129353755\n",
      "32 Train Loss 9.292475 Test MSE 6.148251534613419 Test RE 1.185178798134568\n",
      "33 Train Loss 9.122743 Test MSE 6.148228253777376 Test RE 1.1851765542462651\n",
      "34 Train Loss 8.692329 Test MSE 6.019093549278587 Test RE 1.1726640380267825\n",
      "35 Train Loss 8.526827 Test MSE 6.036720667800121 Test RE 1.1743798758213484\n",
      "36 Train Loss 8.324892 Test MSE 6.03042996563911 Test RE 1.1737678216899547\n",
      "37 Train Loss 8.1888275 Test MSE 5.960344140501851 Test RE 1.1669271066885747\n",
      "38 Train Loss 8.054222 Test MSE 6.17876969831668 Test RE 1.1881166014827973\n",
      "39 Train Loss 7.91672 Test MSE 6.030652525898523 Test RE 1.1737894811455931\n",
      "40 Train Loss 7.8211756 Test MSE 6.047693887926724 Test RE 1.1754467529155126\n",
      "41 Train Loss 7.647333 Test MSE 6.213778362466302 Test RE 1.191477757943122\n",
      "42 Train Loss 7.5353355 Test MSE 6.307411126756326 Test RE 1.2004211269304061\n",
      "43 Train Loss 7.4275813 Test MSE 6.350780782389538 Test RE 1.2045410948618491\n",
      "44 Train Loss 7.3462048 Test MSE 6.383700324968365 Test RE 1.2076589547194891\n",
      "45 Train Loss 7.2436686 Test MSE 6.395579016669708 Test RE 1.2087820291470341\n",
      "46 Train Loss 7.107003 Test MSE 6.393331006358314 Test RE 1.2085695704091801\n",
      "47 Train Loss 6.980137 Test MSE 6.411794965134619 Test RE 1.2103134884462805\n",
      "48 Train Loss 6.81852 Test MSE 6.3638745441545765 Test RE 1.205782190527939\n",
      "49 Train Loss 6.7375946 Test MSE 6.310529587481849 Test RE 1.2007178416580302\n",
      "50 Train Loss 6.6388702 Test MSE 6.274592165130207 Test RE 1.1972940154017533\n",
      "51 Train Loss 6.542815 Test MSE 6.278315532575579 Test RE 1.1976492021847984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 6.451558 Test MSE 6.210059759561372 Test RE 1.1911211877965886\n",
      "53 Train Loss 6.350669 Test MSE 6.160225405161868 Test RE 1.1863323191583277\n",
      "54 Train Loss 6.180663 Test MSE 6.107332571712288 Test RE 1.1812283053023238\n",
      "55 Train Loss 5.9227843 Test MSE 6.095440833978937 Test RE 1.1800777455894398\n",
      "56 Train Loss 5.8254056 Test MSE 6.037877487718165 Test RE 1.174492393944016\n",
      "57 Train Loss 5.457268 Test MSE 5.841023970268671 Test RE 1.155187695952008\n",
      "58 Train Loss 4.8504705 Test MSE 5.340066499211807 Test RE 1.1045398596427185\n",
      "59 Train Loss 4.1187835 Test MSE 5.368950544867806 Test RE 1.1075230205231121\n",
      "60 Train Loss 3.4706633 Test MSE 5.202048147686135 Test RE 1.0901725538138392\n",
      "61 Train Loss 3.0718648 Test MSE 5.242975768531969 Test RE 1.0944526711605327\n",
      "62 Train Loss 2.9133964 Test MSE 5.375299411823748 Test RE 1.1081776585904761\n",
      "63 Train Loss 2.7173042 Test MSE 5.391659764933213 Test RE 1.1098628115502345\n",
      "64 Train Loss 2.6117175 Test MSE 5.387670479829515 Test RE 1.1094521422327697\n",
      "65 Train Loss 2.509452 Test MSE 5.342079518730199 Test RE 1.104748026600405\n",
      "66 Train Loss 2.3762662 Test MSE 5.342990154170586 Test RE 1.1048421828024075\n",
      "67 Train Loss 2.2792146 Test MSE 5.273032148329934 Test RE 1.0975852695739985\n",
      "68 Train Loss 2.1756878 Test MSE 5.34725980750639 Test RE 1.1052835415677196\n",
      "69 Train Loss 2.1081305 Test MSE 5.426674436593556 Test RE 1.1134608308831635\n",
      "70 Train Loss 2.0825498 Test MSE 5.408931844246061 Test RE 1.1116391022928889\n",
      "71 Train Loss 2.051128 Test MSE 5.466391978343403 Test RE 1.1175280827683214\n",
      "72 Train Loss 2.0046995 Test MSE 5.4749692932822125 Test RE 1.1184044956925372\n",
      "73 Train Loss 1.9598098 Test MSE 5.553915112274185 Test RE 1.126439001817037\n",
      "74 Train Loss 1.917991 Test MSE 5.614893770236518 Test RE 1.1326059331539633\n",
      "75 Train Loss 1.88863 Test MSE 5.628219639940997 Test RE 1.1339491477597416\n",
      "76 Train Loss 1.8478061 Test MSE 5.6653019863423255 Test RE 1.1376786095356557\n",
      "77 Train Loss 1.8255671 Test MSE 5.676993804359285 Test RE 1.1388519517140805\n",
      "78 Train Loss 1.7989116 Test MSE 5.697074764835306 Test RE 1.1408643771223987\n",
      "79 Train Loss 1.7777001 Test MSE 5.681496726699626 Test RE 1.1393035239349258\n",
      "80 Train Loss 1.7558988 Test MSE 5.666084567031649 Test RE 1.1377571838612883\n",
      "81 Train Loss 1.7208458 Test MSE 5.73830569151506 Test RE 1.1449852721795946\n",
      "82 Train Loss 1.7034835 Test MSE 5.745340639352046 Test RE 1.1456869117273927\n",
      "83 Train Loss 1.6901457 Test MSE 5.742805120955479 Test RE 1.1454340780843324\n",
      "84 Train Loss 1.656466 Test MSE 5.7957028996974085 Test RE 1.150697362161765\n",
      "85 Train Loss 1.6378958 Test MSE 5.770301715638286 Test RE 1.148172977079369\n",
      "86 Train Loss 1.6221243 Test MSE 5.80102707994051 Test RE 1.1512257807067239\n",
      "87 Train Loss 1.6048088 Test MSE 5.797227801290659 Test RE 1.1508487316217864\n",
      "88 Train Loss 1.5905416 Test MSE 5.798768320345006 Test RE 1.151001631136521\n",
      "89 Train Loss 1.5726465 Test MSE 5.775031266842168 Test RE 1.1486434230700842\n",
      "90 Train Loss 1.5479516 Test MSE 5.833389945818766 Test RE 1.1544325531472737\n",
      "91 Train Loss 1.5335163 Test MSE 5.820759532891004 Test RE 1.1531820914790294\n",
      "92 Train Loss 1.518507 Test MSE 5.797765717696539 Test RE 1.1509021231802066\n",
      "93 Train Loss 1.509147 Test MSE 5.806926005344677 Test RE 1.1518109589335606\n",
      "94 Train Loss 1.4979726 Test MSE 5.809156480955995 Test RE 1.1520321464945296\n",
      "95 Train Loss 1.4744667 Test MSE 5.78221411634505 Test RE 1.1493575290721365\n",
      "96 Train Loss 1.4574878 Test MSE 5.777439267064305 Test RE 1.1488828715876869\n",
      "97 Train Loss 1.4405595 Test MSE 5.784127148897693 Test RE 1.149547644527048\n",
      "98 Train Loss 1.4222971 Test MSE 5.801908146240201 Test RE 1.1513132020990204\n",
      "99 Train Loss 1.4071597 Test MSE 5.820784513053915 Test RE 1.1531845659538327\n",
      "Training time: 159.85\n",
      "2\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 62.925312 Test MSE 5.913542747183055 Test RE 1.162336646400197\n",
      "1 Train Loss 45.044327 Test MSE 7.637331422889734 Test RE 1.320927187308763\n",
      "2 Train Loss 38.213104 Test MSE 7.519792501255828 Test RE 1.3107232066131729\n",
      "3 Train Loss 31.006527 Test MSE 6.356289140476747 Test RE 1.2050633617927737\n",
      "4 Train Loss 26.139708 Test MSE 6.470373841681369 Test RE 1.2158296976735083\n",
      "5 Train Loss 21.055098 Test MSE 6.490118516571303 Test RE 1.217683367691094\n",
      "6 Train Loss 18.062874 Test MSE 6.228924297436431 Test RE 1.1929289733124309\n",
      "7 Train Loss 15.430438 Test MSE 5.728223470556081 Test RE 1.143978958617905\n",
      "8 Train Loss 14.191582 Test MSE 5.622498507876367 Test RE 1.1333726668541426\n",
      "9 Train Loss 13.1043 Test MSE 5.320700278566736 Test RE 1.10253518500493\n",
      "10 Train Loss 12.355967 Test MSE 5.736712581416524 Test RE 1.1448263215834131\n",
      "11 Train Loss 11.202611 Test MSE 5.700386967649795 Test RE 1.1411959705527346\n",
      "12 Train Loss 10.514339 Test MSE 5.832941569450468 Test RE 1.154388185273072\n",
      "13 Train Loss 10.082659 Test MSE 5.752367105539508 Test RE 1.1463872766890482\n",
      "14 Train Loss 9.5273075 Test MSE 5.776586350664633 Test RE 1.1487980643603624\n",
      "15 Train Loss 9.1567745 Test MSE 5.680990307020779 Test RE 1.1392527469469267\n",
      "16 Train Loss 8.768914 Test MSE 5.636576614093951 Test RE 1.134790698837939\n",
      "17 Train Loss 8.353115 Test MSE 5.526646685158173 Test RE 1.123670322929468\n",
      "18 Train Loss 8.107111 Test MSE 5.426617969264944 Test RE 1.1134550378028039\n",
      "19 Train Loss 7.802886 Test MSE 5.428522874937173 Test RE 1.113650448713057\n",
      "20 Train Loss 7.520393 Test MSE 5.376617895863186 Test RE 1.1083135603195837\n",
      "21 Train Loss 7.3307266 Test MSE 5.379028764434134 Test RE 1.1085620156606601\n",
      "22 Train Loss 7.095243 Test MSE 5.368634275293678 Test RE 1.1074903995304524\n",
      "23 Train Loss 6.843853 Test MSE 5.390473241265495 Test RE 1.1097406830212266\n",
      "24 Train Loss 6.649646 Test MSE 5.350683479016896 Test RE 1.1056373229800442\n",
      "25 Train Loss 6.4350514 Test MSE 5.24249897352863 Test RE 1.0944029053927375\n",
      "26 Train Loss 6.3044024 Test MSE 5.183545289533365 Test RE 1.088232041533307\n",
      "27 Train Loss 6.2020035 Test MSE 5.172970578391823 Test RE 1.0871214488841439\n",
      "28 Train Loss 6.0373683 Test MSE 5.0373411175033835 Test RE 1.0727752390893635\n",
      "29 Train Loss 5.8901815 Test MSE 4.98170680964746 Test RE 1.0668347226961103\n",
      "30 Train Loss 5.681899 Test MSE 4.800819372479891 Test RE 1.0472870741377016\n",
      "31 Train Loss 5.5979986 Test MSE 4.800591817367444 Test RE 1.04726225354631\n",
      "32 Train Loss 5.497022 Test MSE 4.819286222180946 Test RE 1.0492993900320329\n",
      "33 Train Loss 5.445121 Test MSE 4.801913991641368 Test RE 1.0474064615871979\n",
      "34 Train Loss 5.347884 Test MSE 4.723917764435909 Test RE 1.0388652625129793\n",
      "35 Train Loss 5.3070397 Test MSE 4.6760638697503705 Test RE 1.0335899492259562\n",
      "36 Train Loss 5.168153 Test MSE 4.586418524745979 Test RE 1.0236344694860047\n",
      "37 Train Loss 5.1209154 Test MSE 4.558929957805012 Test RE 1.0205622975127573\n",
      "38 Train Loss 5.029772 Test MSE 4.412322690712422 Test RE 1.00401845009378\n",
      "39 Train Loss 4.7997046 Test MSE 4.302087837788937 Test RE 0.9913972204437994\n",
      "40 Train Loss 4.5455313 Test MSE 4.1806752242559595 Test RE 0.9773075990262636\n",
      "41 Train Loss 4.172573 Test MSE 4.084201021075444 Test RE 0.9659654987560199\n",
      "42 Train Loss 3.9544582 Test MSE 3.889182640713655 Test RE 0.9426212576611839\n",
      "43 Train Loss 3.8284304 Test MSE 3.7597957739720838 Test RE 0.9268088837327656\n",
      "44 Train Loss 3.5986958 Test MSE 3.719836259955637 Test RE 0.9218706153034695\n",
      "45 Train Loss 3.2716403 Test MSE 3.2829757347117843 Test RE 0.8660478675114721\n",
      "46 Train Loss 3.0384371 Test MSE 3.0388236054585844 Test RE 0.8332221488997732\n",
      "47 Train Loss 2.8731894 Test MSE 2.9040366242877496 Test RE 0.8145337893229778\n",
      "48 Train Loss 2.6532156 Test MSE 2.862020338159978 Test RE 0.8086198870610684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 2.5845172 Test MSE 2.747950980055186 Test RE 0.7923417692345255\n",
      "50 Train Loss 2.4582894 Test MSE 2.614590984566859 Test RE 0.7728762109286786\n",
      "51 Train Loss 2.3266616 Test MSE 2.474585109883795 Test RE 0.751898568431529\n",
      "52 Train Loss 2.1912432 Test MSE 2.382710447693965 Test RE 0.7378085689449653\n",
      "53 Train Loss 2.0590496 Test MSE 2.3760166274919428 Test RE 0.7367714661278782\n",
      "54 Train Loss 1.9511641 Test MSE 2.2630486637618614 Test RE 0.7190432384970937\n",
      "55 Train Loss 1.8168042 Test MSE 2.0626993330026018 Test RE 0.6864770526592731\n",
      "56 Train Loss 1.7238705 Test MSE 1.9861330231782064 Test RE 0.6736157399500214\n",
      "57 Train Loss 1.6434813 Test MSE 1.8500986263040324 Test RE 0.6501379247093231\n",
      "58 Train Loss 1.5681545 Test MSE 1.6744909689910024 Test RE 0.6185139014421801\n",
      "59 Train Loss 1.4971517 Test MSE 1.647415985530264 Test RE 0.6134931220786843\n",
      "60 Train Loss 1.3961703 Test MSE 1.6091823777628627 Test RE 0.6063322861054913\n",
      "61 Train Loss 1.345995 Test MSE 1.5373816154616784 Test RE 0.5926508367944567\n",
      "62 Train Loss 1.2930555 Test MSE 1.3272840709689333 Test RE 0.5506682049480606\n",
      "63 Train Loss 1.2367364 Test MSE 1.2501674513719658 Test RE 0.5344316305466997\n",
      "64 Train Loss 1.2043517 Test MSE 1.19365078553845 Test RE 0.5222118281034819\n",
      "65 Train Loss 1.1597558 Test MSE 1.0625639414815564 Test RE 0.4927034431031477\n",
      "66 Train Loss 1.1109743 Test MSE 0.9732462718422692 Test RE 0.4715409723066355\n",
      "67 Train Loss 1.0559208 Test MSE 0.9216647855956298 Test RE 0.4588751691003937\n",
      "68 Train Loss 0.9968735 Test MSE 0.9464124934933438 Test RE 0.464995010294831\n",
      "69 Train Loss 0.91261244 Test MSE 0.8422650077102829 Test RE 0.43866444934415233\n",
      "70 Train Loss 0.86529315 Test MSE 0.786468416755574 Test RE 0.42388563948395264\n",
      "71 Train Loss 0.8263386 Test MSE 0.7387380705309755 Test RE 0.41082162931550265\n",
      "72 Train Loss 0.7348795 Test MSE 0.666115593314999 Test RE 0.3901062069899861\n",
      "73 Train Loss 0.6730208 Test MSE 0.6479107780782608 Test RE 0.3847385133828586\n",
      "74 Train Loss 0.6295271 Test MSE 0.6134102698538516 Test RE 0.3743549513745152\n",
      "75 Train Loss 0.5918081 Test MSE 0.5854024373069832 Test RE 0.3657087263904529\n",
      "76 Train Loss 0.5448371 Test MSE 0.5469305038364731 Test RE 0.35348755884518934\n",
      "77 Train Loss 0.5098584 Test MSE 0.5237198504877004 Test RE 0.345905587939641\n",
      "78 Train Loss 0.4845344 Test MSE 0.5199841266743307 Test RE 0.3446696978504833\n",
      "79 Train Loss 0.45173413 Test MSE 0.5273139413644679 Test RE 0.3470904680562789\n",
      "80 Train Loss 0.4315619 Test MSE 0.5366426415102445 Test RE 0.3501471933922094\n",
      "81 Train Loss 0.4096698 Test MSE 0.5140673446722908 Test RE 0.3427031282122739\n",
      "82 Train Loss 0.394921 Test MSE 0.5126037070645426 Test RE 0.34221491326193426\n",
      "83 Train Loss 0.3749656 Test MSE 0.509855828685408 Test RE 0.3412964370840002\n",
      "84 Train Loss 0.357966 Test MSE 0.5051770429859477 Test RE 0.339726843133362\n",
      "85 Train Loss 0.33060127 Test MSE 0.5196906386985162 Test RE 0.34457241537166244\n",
      "86 Train Loss 0.31614733 Test MSE 0.5091218341740094 Test RE 0.3410506814001133\n",
      "87 Train Loss 0.28954902 Test MSE 0.47165313268453585 Test RE 0.3282611011088545\n",
      "88 Train Loss 0.27443776 Test MSE 0.44218398101528866 Test RE 0.3178407398391938\n",
      "89 Train Loss 0.26519963 Test MSE 0.425832492143386 Test RE 0.31190867828557456\n",
      "90 Train Loss 0.25562635 Test MSE 0.4130157440628509 Test RE 0.30717888797836124\n",
      "91 Train Loss 0.2474404 Test MSE 0.41519259169832956 Test RE 0.3079873351970911\n",
      "92 Train Loss 0.2433998 Test MSE 0.4228726222119623 Test RE 0.31082278301928556\n",
      "93 Train Loss 0.23961405 Test MSE 0.41821867673311836 Test RE 0.3091076632785221\n",
      "94 Train Loss 0.23238118 Test MSE 0.43471058714254157 Test RE 0.31514336571316676\n",
      "95 Train Loss 0.22501314 Test MSE 0.43358977024776924 Test RE 0.3147368354962509\n",
      "96 Train Loss 0.22007456 Test MSE 0.4406549212714248 Test RE 0.31729072178051065\n",
      "97 Train Loss 0.21474777 Test MSE 0.44810616222360494 Test RE 0.3199620851772149\n",
      "98 Train Loss 0.21077609 Test MSE 0.45702429203596995 Test RE 0.32313031394905567\n",
      "99 Train Loss 0.20721196 Test MSE 0.46734471250673953 Test RE 0.3267583745618187\n",
      "Training time: 159.45\n",
      "3\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 57.992847 Test MSE 6.321089886925851 Test RE 1.2017220869777645\n",
      "1 Train Loss 46.282513 Test MSE 8.180703047569367 Test RE 1.3671097306953182\n",
      "2 Train Loss 37.292862 Test MSE 8.190172183938403 Test RE 1.367900714337752\n",
      "3 Train Loss 33.399887 Test MSE 8.16460024218776 Test RE 1.3657635660898562\n",
      "4 Train Loss 30.785606 Test MSE 8.454932534342863 Test RE 1.3898346456961428\n",
      "5 Train Loss 27.382626 Test MSE 8.318193752892537 Test RE 1.3785501704725724\n",
      "6 Train Loss 25.122002 Test MSE 8.247400835837299 Test RE 1.3726714833373883\n",
      "7 Train Loss 23.190481 Test MSE 8.66923492297788 Test RE 1.4073381031719145\n",
      "8 Train Loss 21.94125 Test MSE 8.782960141077293 Test RE 1.4165389355093752\n",
      "9 Train Loss 20.945042 Test MSE 8.97648066918573 Test RE 1.4320596569953536\n",
      "10 Train Loss 20.089813 Test MSE 9.291499260797208 Test RE 1.456971171413495\n",
      "11 Train Loss 19.138266 Test MSE 9.13600753892456 Test RE 1.4447286489218647\n",
      "12 Train Loss 18.34311 Test MSE 9.187780197098116 Test RE 1.4488164178042617\n",
      "13 Train Loss 17.494879 Test MSE 9.181446675588992 Test RE 1.4483169668126987\n",
      "14 Train Loss 16.64 Test MSE 9.14515873495617 Test RE 1.445452033066188\n",
      "15 Train Loss 15.9001255 Test MSE 8.858945554877282 Test RE 1.422653303236602\n",
      "16 Train Loss 14.4601 Test MSE 8.426429114286263 Test RE 1.3874899501775366\n",
      "17 Train Loss 13.495926 Test MSE 8.393524293997643 Test RE 1.3847782579319199\n",
      "18 Train Loss 12.81299 Test MSE 8.456686191331553 Test RE 1.3899787726221482\n",
      "19 Train Loss 12.2778015 Test MSE 8.415988739617093 Test RE 1.3866301313539566\n",
      "20 Train Loss 11.278645 Test MSE 7.893791227963025 Test RE 1.3429222776110947\n",
      "21 Train Loss 10.048358 Test MSE 7.4646617185593716 Test RE 1.3059096344060832\n",
      "22 Train Loss 9.093874 Test MSE 7.563038206745814 Test RE 1.314486733880137\n",
      "23 Train Loss 8.504112 Test MSE 7.577311624853906 Test RE 1.315726538194596\n",
      "24 Train Loss 8.235332 Test MSE 7.531822580226673 Test RE 1.3117712277063605\n",
      "25 Train Loss 7.851499 Test MSE 7.768920253357851 Test RE 1.3322581694713505\n",
      "26 Train Loss 7.59772 Test MSE 7.913510632796386 Test RE 1.3445986020499368\n",
      "27 Train Loss 7.265545 Test MSE 7.884120708087576 Test RE 1.3420994324096325\n",
      "28 Train Loss 7.022368 Test MSE 7.766074328887267 Test RE 1.3320141295473082\n",
      "29 Train Loss 6.688343 Test MSE 7.764610242725876 Test RE 1.331888565762203\n",
      "30 Train Loss 6.419628 Test MSE 7.818706913347142 Test RE 1.336520200463629\n",
      "31 Train Loss 6.1522884 Test MSE 7.7688127872464685 Test RE 1.3322489549926786\n",
      "32 Train Loss 5.782816 Test MSE 7.718904980614722 Test RE 1.3279627948153865\n",
      "33 Train Loss 5.3697643 Test MSE 7.641843618815288 Test RE 1.3213173368162943\n",
      "34 Train Loss 4.740405 Test MSE 7.23695922749947 Test RE 1.2858376062486918\n",
      "35 Train Loss 4.2853165 Test MSE 7.1045833524570705 Test RE 1.274023289828542\n",
      "36 Train Loss 3.9268568 Test MSE 7.0812279562801015 Test RE 1.2719274728284025\n",
      "37 Train Loss 3.7468169 Test MSE 6.910196733743039 Test RE 1.2564733056759154\n",
      "38 Train Loss 3.5920236 Test MSE 6.992593402393204 Test RE 1.2639421539833637\n",
      "39 Train Loss 3.3484085 Test MSE 6.952891214846828 Test RE 1.2603488733761998\n",
      "40 Train Loss 3.182808 Test MSE 6.960991167421456 Test RE 1.2610827978886645\n",
      "41 Train Loss 3.101892 Test MSE 6.9941264697885766 Test RE 1.2640807007427326\n",
      "42 Train Loss 3.0258472 Test MSE 7.040517369151945 Test RE 1.2682659926121376\n",
      "43 Train Loss 2.9465277 Test MSE 6.991381460187619 Test RE 1.263832617282699\n",
      "44 Train Loss 2.880547 Test MSE 7.012124518641516 Test RE 1.26570609090234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 2.814002 Test MSE 7.043948242025689 Test RE 1.2685749705746316\n",
      "46 Train Loss 2.7310424 Test MSE 7.132513580427154 Test RE 1.2765251154213895\n",
      "47 Train Loss 2.7012177 Test MSE 7.235934944964492 Test RE 1.285746607559372\n",
      "48 Train Loss 2.615984 Test MSE 7.221837482597407 Test RE 1.2844935143810294\n",
      "49 Train Loss 2.5840614 Test MSE 7.2374974829896965 Test RE 1.2858854230361545\n",
      "50 Train Loss 2.5172174 Test MSE 7.336199140378946 Test RE 1.2946238877228562\n",
      "51 Train Loss 2.467566 Test MSE 7.336234721462956 Test RE 1.294627027227699\n",
      "52 Train Loss 2.4371276 Test MSE 7.2777816655396865 Test RE 1.2894591003874116\n",
      "53 Train Loss 2.4014847 Test MSE 7.284195475154264 Test RE 1.290027166607488\n",
      "54 Train Loss 2.347756 Test MSE 7.277978656961348 Test RE 1.2894765514923077\n",
      "55 Train Loss 2.3183193 Test MSE 7.242605851123535 Test RE 1.2863391446056789\n",
      "56 Train Loss 2.2963817 Test MSE 7.225632300166473 Test RE 1.284830947783709\n",
      "57 Train Loss 2.2293484 Test MSE 7.274519027572608 Test RE 1.2891700349810813\n",
      "58 Train Loss 2.2025304 Test MSE 7.257534045375894 Test RE 1.2876641397951005\n",
      "59 Train Loss 2.179149 Test MSE 7.260204879119235 Test RE 1.2879010536327433\n",
      "60 Train Loss 2.156523 Test MSE 7.24958329675688 Test RE 1.2869586178299484\n",
      "61 Train Loss 2.138813 Test MSE 7.225969949758395 Test RE 1.2848609671342124\n",
      "62 Train Loss 2.1168594 Test MSE 7.257156664847576 Test RE 1.2876306610895565\n",
      "63 Train Loss 2.0968058 Test MSE 7.2772984056611 Test RE 1.2894162882901414\n",
      "64 Train Loss 2.072443 Test MSE 7.228135138872778 Test RE 1.2850534505401077\n",
      "65 Train Loss 2.0494113 Test MSE 7.232196414756548 Test RE 1.2854144166537198\n",
      "66 Train Loss 2.0238724 Test MSE 7.178670482193173 Test RE 1.2806488669828797\n",
      "67 Train Loss 2.0048685 Test MSE 7.190175414767613 Test RE 1.2816746753367474\n",
      "68 Train Loss 1.9787216 Test MSE 7.144820895465111 Test RE 1.277625977352094\n",
      "69 Train Loss 1.9511825 Test MSE 7.2030706740811254 Test RE 1.2828234737062372\n",
      "70 Train Loss 1.9318876 Test MSE 7.231304037900037 Test RE 1.2853351109077844\n",
      "71 Train Loss 1.9175196 Test MSE 7.226224842555203 Test RE 1.284883628376899\n",
      "72 Train Loss 1.9043448 Test MSE 7.236829116197426 Test RE 1.285826047336179\n",
      "73 Train Loss 1.8907909 Test MSE 7.212856915760176 Test RE 1.2836946132499722\n",
      "74 Train Loss 1.8762991 Test MSE 7.2273276926492125 Test RE 1.2849816726530743\n",
      "75 Train Loss 1.8585179 Test MSE 7.246135730815136 Test RE 1.2866525724935416\n",
      "76 Train Loss 1.8376474 Test MSE 7.270024820174456 Test RE 1.28877174798663\n",
      "77 Train Loss 1.8213067 Test MSE 7.285855712863402 Test RE 1.2901741718416455\n",
      "78 Train Loss 1.8092036 Test MSE 7.282812633369685 Test RE 1.2899047105210177\n",
      "79 Train Loss 1.8007795 Test MSE 7.256394056738901 Test RE 1.2875630048829496\n",
      "80 Train Loss 1.7865678 Test MSE 7.250304199472559 Test RE 1.28702260419035\n",
      "81 Train Loss 1.768388 Test MSE 7.251345023836545 Test RE 1.28711498075652\n",
      "82 Train Loss 1.7495705 Test MSE 7.269037045490698 Test RE 1.288684192621879\n",
      "83 Train Loss 1.7356093 Test MSE 7.289715208718662 Test RE 1.2905158449964014\n",
      "84 Train Loss 1.7264652 Test MSE 7.26612744647033 Test RE 1.2884262540856353\n",
      "85 Train Loss 1.7150431 Test MSE 7.278243682837355 Test RE 1.2895000292708008\n",
      "86 Train Loss 1.7011187 Test MSE 7.236284966300824 Test RE 1.2857777046675496\n",
      "87 Train Loss 1.6898594 Test MSE 7.245541397673399 Test RE 1.2865998053377015\n",
      "88 Train Loss 1.680574 Test MSE 7.260761702952833 Test RE 1.2879504406861546\n",
      "89 Train Loss 1.6751919 Test MSE 7.247011180636581 Test RE 1.2867302943156922\n",
      "90 Train Loss 1.6652124 Test MSE 7.201710298767756 Test RE 1.2827023306640613\n",
      "91 Train Loss 1.6550484 Test MSE 7.206538502238452 Test RE 1.2831322361952542\n",
      "92 Train Loss 1.646584 Test MSE 7.192821770211186 Test RE 1.2819105148350536\n",
      "93 Train Loss 1.6391913 Test MSE 7.19597932285366 Test RE 1.2821918547555158\n",
      "94 Train Loss 1.6345911 Test MSE 7.166969761487413 Test RE 1.279604758212631\n",
      "95 Train Loss 1.6262627 Test MSE 7.179237142379289 Test RE 1.28069941104997\n",
      "96 Train Loss 1.6192017 Test MSE 7.145225256658615 Test RE 1.277662130466585\n",
      "97 Train Loss 1.6108098 Test MSE 7.136322845733001 Test RE 1.2768659471426904\n",
      "98 Train Loss 1.5986212 Test MSE 7.145283362824968 Test RE 1.2776673255370476\n",
      "99 Train Loss 1.583399 Test MSE 7.112085426732084 Test RE 1.274695763854453\n",
      "Training time: 158.50\n",
      "4\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.540833 Test MSE 7.881975236376108 Test RE 1.3419168101241779\n",
      "1 Train Loss 47.594963 Test MSE 7.751076449962224 Test RE 1.3307273120237377\n",
      "2 Train Loss 39.820614 Test MSE 7.793003139514794 Test RE 1.3343215061034566\n",
      "3 Train Loss 34.14759 Test MSE 7.609190355682868 Test RE 1.3184913491956007\n",
      "4 Train Loss 28.459114 Test MSE 7.24710970552129 Test RE 1.286739040992071\n",
      "5 Train Loss 24.37709 Test MSE 6.344994287857005 Test RE 1.2039922128336509\n",
      "6 Train Loss 18.970669 Test MSE 6.056232015668035 Test RE 1.176276207495205\n",
      "7 Train Loss 16.131224 Test MSE 5.8342250754876535 Test RE 1.154515186605796\n",
      "8 Train Loss 13.303497 Test MSE 5.612409458032391 Test RE 1.1323553444374095\n",
      "9 Train Loss 12.216507 Test MSE 5.23757303382292 Test RE 1.0938886249219233\n",
      "10 Train Loss 10.364244 Test MSE 5.055353354792346 Test RE 1.0746915118743499\n",
      "11 Train Loss 9.397374 Test MSE 5.033724410744066 Test RE 1.0723900547190324\n",
      "12 Train Loss 8.444701 Test MSE 5.2019483001073095 Test RE 1.0901620914335195\n",
      "13 Train Loss 7.702543 Test MSE 4.904180751276207 Test RE 1.0585010532232166\n",
      "14 Train Loss 6.529224 Test MSE 4.619059123114272 Test RE 1.0272705098249064\n",
      "15 Train Loss 6.1225867 Test MSE 4.649742131762793 Test RE 1.0306767856701007\n",
      "16 Train Loss 5.62823 Test MSE 4.519860910710408 Test RE 1.016179888778452\n",
      "17 Train Loss 5.0432067 Test MSE 4.279494895719665 Test RE 0.9887905715898433\n",
      "18 Train Loss 4.549083 Test MSE 4.218457795411818 Test RE 0.9817138419839302\n",
      "19 Train Loss 4.1682014 Test MSE 4.003027312806854 Test RE 0.9563180147850692\n",
      "20 Train Loss 3.851778 Test MSE 3.7956871792821727 Test RE 0.9312220839991603\n",
      "21 Train Loss 3.6290781 Test MSE 3.5371808218640157 Test RE 0.8989523894192701\n",
      "22 Train Loss 3.2822297 Test MSE 3.2981315283817403 Test RE 0.8680446122554183\n",
      "23 Train Loss 3.0311162 Test MSE 3.198468879525952 Test RE 0.8548287596135785\n",
      "24 Train Loss 2.8232102 Test MSE 3.108879265306234 Test RE 0.8427717868266101\n",
      "25 Train Loss 2.7293916 Test MSE 3.0811394525065303 Test RE 0.83900343279423\n",
      "26 Train Loss 2.577827 Test MSE 2.836927072668898 Test RE 0.8050672243977179\n",
      "27 Train Loss 2.4091432 Test MSE 2.748594853426663 Test RE 0.7924345907384613\n",
      "28 Train Loss 2.3397884 Test MSE 2.650278548244719 Test RE 0.7781329769930803\n",
      "29 Train Loss 2.2408633 Test MSE 2.6174369403010496 Test RE 0.773296730480307\n",
      "30 Train Loss 2.152701 Test MSE 2.522622879615809 Test RE 0.7591615878013682\n",
      "31 Train Loss 2.0454836 Test MSE 2.437673994020733 Test RE 0.7462698092405998\n",
      "32 Train Loss 1.9593394 Test MSE 2.365669416545955 Test RE 0.7351654488011254\n",
      "33 Train Loss 1.8972403 Test MSE 2.2309470130044735 Test RE 0.713925160818639\n",
      "34 Train Loss 1.7830651 Test MSE 2.1236240744234967 Test RE 0.6965413131229174\n",
      "35 Train Loss 1.7319639 Test MSE 2.0533198066280978 Test RE 0.6849144967684633\n",
      "36 Train Loss 1.6837049 Test MSE 1.9824290512108347 Test RE 0.6729873283227392\n",
      "37 Train Loss 1.6310875 Test MSE 1.9493667653922302 Test RE 0.6673518043825059\n",
      "38 Train Loss 1.5662587 Test MSE 1.9268759189961426 Test RE 0.66349084520498\n",
      "39 Train Loss 1.5133613 Test MSE 1.8535881411472863 Test RE 0.650750756146443\n",
      "40 Train Loss 1.4531368 Test MSE 1.7815850158575268 Test RE 0.6379862751837693\n",
      "41 Train Loss 1.3747454 Test MSE 1.74191232936187 Test RE 0.6308428815717658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 1.3151897 Test MSE 1.63048181207496 Test RE 0.61033185774874\n",
      "43 Train Loss 1.2432451 Test MSE 1.5534945803504083 Test RE 0.5957484643113249\n",
      "44 Train Loss 1.1870842 Test MSE 1.434110683271406 Test RE 0.5723996978065617\n",
      "45 Train Loss 1.1298822 Test MSE 1.3857694284186335 Test RE 0.5626697252430017\n",
      "46 Train Loss 1.0699942 Test MSE 1.2902810942221987 Test RE 0.5429379854922838\n",
      "47 Train Loss 0.98751366 Test MSE 1.2525140118111648 Test RE 0.5349329586678675\n",
      "48 Train Loss 0.9496503 Test MSE 1.23818743797299 Test RE 0.5318648102498175\n",
      "49 Train Loss 0.8986427 Test MSE 1.1489104781968515 Test RE 0.5123316140967502\n",
      "50 Train Loss 0.8708938 Test MSE 1.112921291619885 Test RE 0.5042434735591808\n",
      "51 Train Loss 0.81632185 Test MSE 1.0710867973342155 Test RE 0.4946754907632976\n",
      "52 Train Loss 0.7721828 Test MSE 0.992150552485117 Test RE 0.47609853987516526\n",
      "53 Train Loss 0.75034505 Test MSE 0.9473409685135167 Test RE 0.46522304533138487\n",
      "54 Train Loss 0.72513586 Test MSE 0.9294520723583326 Test RE 0.4608096447745338\n",
      "55 Train Loss 0.6870463 Test MSE 0.848461028801423 Test RE 0.44027498394107273\n",
      "56 Train Loss 0.6531725 Test MSE 0.7552281994471909 Test RE 0.41538150845150335\n",
      "57 Train Loss 0.62006086 Test MSE 0.694494208247617 Test RE 0.39832941128748334\n",
      "58 Train Loss 0.5848183 Test MSE 0.6228549093829777 Test RE 0.3772259025011745\n",
      "59 Train Loss 0.551384 Test MSE 0.5488233035231552 Test RE 0.35409869979617636\n",
      "60 Train Loss 0.50522697 Test MSE 0.5108887151720236 Test RE 0.34164196821362397\n",
      "61 Train Loss 0.47436267 Test MSE 0.4799318718166987 Test RE 0.33112948697994515\n",
      "62 Train Loss 0.4182626 Test MSE 0.4094992126592001 Test RE 0.30586838910204045\n",
      "63 Train Loss 0.37796852 Test MSE 0.38344699651383113 Test RE 0.2959788854523607\n",
      "64 Train Loss 0.34890056 Test MSE 0.33271391666860006 Test RE 0.27570430259208606\n",
      "65 Train Loss 0.3264703 Test MSE 0.30830797919223124 Test RE 0.2653997091661512\n",
      "66 Train Loss 0.3108928 Test MSE 0.27864170389827464 Test RE 0.252308056838665\n",
      "67 Train Loss 0.29074937 Test MSE 0.25389247605650117 Test RE 0.24084241634801842\n",
      "68 Train Loss 0.27216473 Test MSE 0.2142968486527489 Test RE 0.22126664588345993\n",
      "69 Train Loss 0.25983095 Test MSE 0.19278881844778956 Test RE 0.20986933244525519\n",
      "70 Train Loss 0.23986997 Test MSE 0.17381974399402647 Test RE 0.19927720039396807\n",
      "71 Train Loss 0.22494142 Test MSE 0.13544733533957234 Test RE 0.17591111973935072\n",
      "72 Train Loss 0.20427956 Test MSE 0.11739020057794265 Test RE 0.16376609093254754\n",
      "73 Train Loss 0.18943946 Test MSE 0.08716735949737602 Test RE 0.14111884246422624\n",
      "74 Train Loss 0.18005802 Test MSE 0.07594871118564518 Test RE 0.1317250173728028\n",
      "75 Train Loss 0.16817944 Test MSE 0.07095916457058404 Test RE 0.12732459609140515\n",
      "76 Train Loss 0.14612785 Test MSE 0.046839244802705085 Test RE 0.10344583330498561\n",
      "77 Train Loss 0.12867159 Test MSE 0.044609977575062874 Test RE 0.10095412355091239\n",
      "78 Train Loss 0.12120394 Test MSE 0.038062403230930984 Test RE 0.09325157231830958\n",
      "79 Train Loss 0.107276425 Test MSE 0.03001555333467529 Test RE 0.08280970494967521\n",
      "80 Train Loss 0.096543446 Test MSE 0.028149188091238276 Test RE 0.08019383760899765\n",
      "81 Train Loss 0.09136644 Test MSE 0.029148040941640925 Test RE 0.08160424399553835\n",
      "82 Train Loss 0.0833638 Test MSE 0.024713513726298555 Test RE 0.0751407124984816\n",
      "83 Train Loss 0.072660714 Test MSE 0.019884010070118262 Test RE 0.06740002342667185\n",
      "84 Train Loss 0.06894259 Test MSE 0.01983210425089727 Test RE 0.06731199441438933\n",
      "85 Train Loss 0.06615698 Test MSE 0.019959934366944758 Test RE 0.06752857958181036\n",
      "86 Train Loss 0.0626747 Test MSE 0.015825095496570685 Test RE 0.060128619093180166\n",
      "87 Train Loss 0.05856719 Test MSE 0.014343054673072302 Test RE 0.057243856877340925\n",
      "88 Train Loss 0.05359281 Test MSE 0.012082524381634346 Test RE 0.052539616734291444\n",
      "89 Train Loss 0.049613196 Test MSE 0.010671444215076126 Test RE 0.049376426930755536\n",
      "90 Train Loss 0.04242115 Test MSE 0.009363209861688464 Test RE 0.046250926721449884\n",
      "91 Train Loss 0.038951047 Test MSE 0.006747769709023589 Test RE 0.03926342549463462\n",
      "92 Train Loss 0.036848586 Test MSE 0.006643224638205504 Test RE 0.03895807859187737\n",
      "93 Train Loss 0.033580497 Test MSE 0.005400269807272526 Test RE 0.03512495605229923\n",
      "94 Train Loss 0.030276738 Test MSE 0.0050614869880441305 Test RE 0.03400534009151632\n",
      "95 Train Loss 0.026976058 Test MSE 0.004359354917216105 Test RE 0.03155870505675057\n",
      "96 Train Loss 0.026050327 Test MSE 0.004141648720916311 Test RE 0.03076059209519747\n",
      "97 Train Loss 0.025392197 Test MSE 0.0040771565925832864 Test RE 0.030520156497166752\n",
      "98 Train Loss 0.023465874 Test MSE 0.0036116224907180097 Test RE 0.0287249469109664\n",
      "99 Train Loss 0.020464506 Test MSE 0.0037612833969485945 Test RE 0.029314067850879685\n",
      "Training time: 156.59\n",
      "5\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 68.66318 Test MSE 4.981101444948697 Test RE 1.0667699011674512\n",
      "1 Train Loss 53.226784 Test MSE 6.693485443898189 Test RE 1.2366141793243701\n",
      "2 Train Loss 38.687805 Test MSE 6.885228547264524 Test RE 1.2542012828360278\n",
      "3 Train Loss 33.02015 Test MSE 6.124871400819694 Test RE 1.1829231948966412\n",
      "4 Train Loss 28.296032 Test MSE 6.297780139444594 Test RE 1.1995042961507714\n",
      "5 Train Loss 24.487074 Test MSE 5.801354659168066 Test RE 1.151258284634309\n",
      "6 Train Loss 22.082874 Test MSE 5.346687100669679 Test RE 1.1052243504667094\n",
      "7 Train Loss 19.741955 Test MSE 5.332583472280929 Test RE 1.1037656933391482\n",
      "8 Train Loss 19.129967 Test MSE 5.097756579728561 Test RE 1.079189241580865\n",
      "9 Train Loss 18.27985 Test MSE 5.106069453717616 Test RE 1.0800687961174051\n",
      "10 Train Loss 17.518757 Test MSE 5.009693926650839 Test RE 1.0698272523509065\n",
      "11 Train Loss 16.452997 Test MSE 5.077366498326499 Test RE 1.077028800611185\n",
      "12 Train Loss 15.829411 Test MSE 5.0069364795930325 Test RE 1.0695327834572341\n",
      "13 Train Loss 15.166302 Test MSE 5.051452505154967 Test RE 1.0742768010996127\n",
      "14 Train Loss 14.47442 Test MSE 4.970660074874407 Test RE 1.0656512346722422\n",
      "15 Train Loss 13.604343 Test MSE 4.931292908474562 Test RE 1.0614229166276976\n",
      "16 Train Loss 12.699063 Test MSE 4.995221253280365 Test RE 1.0682808046713697\n",
      "17 Train Loss 11.776262 Test MSE 5.264778747320448 Test RE 1.0967259576422053\n",
      "18 Train Loss 11.09445 Test MSE 4.747300296729003 Test RE 1.041433185637972\n",
      "19 Train Loss 8.970212 Test MSE 3.291968990461164 Test RE 0.8672332651424716\n",
      "20 Train Loss 6.5265765 Test MSE 2.2263046884048734 Test RE 0.713181979053038\n",
      "21 Train Loss 5.489215 Test MSE 1.9481158146879467 Test RE 0.6671376429946424\n",
      "22 Train Loss 4.6868806 Test MSE 2.0107541322079103 Test RE 0.6777781205653333\n",
      "23 Train Loss 4.0884724 Test MSE 1.9292302372351862 Test RE 0.6638960585682068\n",
      "24 Train Loss 3.9075058 Test MSE 1.9480879545333427 Test RE 0.6671328725841288\n",
      "25 Train Loss 3.54154 Test MSE 1.7919073566219368 Test RE 0.639831822897721\n",
      "26 Train Loss 3.3068562 Test MSE 1.4163988771607101 Test RE 0.5688540405099959\n",
      "27 Train Loss 2.2535348 Test MSE 0.681664022140502 Test RE 0.3946328615723751\n",
      "28 Train Loss 1.8304003 Test MSE 0.5506249941577125 Test RE 0.3546794455240172\n",
      "29 Train Loss 1.4727536 Test MSE 0.4824154376083831 Test RE 0.3319851508117131\n",
      "30 Train Loss 1.2959431 Test MSE 0.4594580480038923 Test RE 0.3239895419554423\n",
      "31 Train Loss 1.0741534 Test MSE 0.3189214666781001 Test RE 0.26992924292529696\n",
      "32 Train Loss 0.93343914 Test MSE 0.25144712901286215 Test RE 0.239679781949257\n",
      "33 Train Loss 0.78098655 Test MSE 0.19473558413105754 Test RE 0.2109262925300417\n",
      "34 Train Loss 0.6471483 Test MSE 0.1481871802788848 Test RE 0.18399811652815679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.54922575 Test MSE 0.09665527137537411 Test RE 0.14860069223888614\n",
      "36 Train Loss 0.4705353 Test MSE 0.0766281365243255 Test RE 0.13231290126314144\n",
      "37 Train Loss 0.41112128 Test MSE 0.07115963936063893 Test RE 0.12750432881931237\n",
      "38 Train Loss 0.33637422 Test MSE 0.06773458076952071 Test RE 0.12439796728599967\n",
      "39 Train Loss 0.29331478 Test MSE 0.06955386284855551 Test RE 0.12605749934541594\n",
      "40 Train Loss 0.27514654 Test MSE 0.07421521711948909 Test RE 0.13021305895872445\n",
      "41 Train Loss 0.25280488 Test MSE 0.06127445521317488 Test RE 0.11831717443582972\n",
      "42 Train Loss 0.23398706 Test MSE 0.06173290417272124 Test RE 0.11875896787303518\n",
      "43 Train Loss 0.21549045 Test MSE 0.05922238965956091 Test RE 0.11631909752557032\n",
      "44 Train Loss 0.19487084 Test MSE 0.057005702601119236 Test RE 0.11412143176350442\n",
      "45 Train Loss 0.18096003 Test MSE 0.04821047322011338 Test RE 0.1049491093959043\n",
      "46 Train Loss 0.16773526 Test MSE 0.04399195832379345 Test RE 0.10025238376217549\n",
      "47 Train Loss 0.14249766 Test MSE 0.03990437717987983 Test RE 0.09548130116295798\n",
      "48 Train Loss 0.13349728 Test MSE 0.03138930434726882 Test RE 0.08468352076214203\n",
      "49 Train Loss 0.12660642 Test MSE 0.029436561693098138 Test RE 0.08200712768867122\n",
      "50 Train Loss 0.12004662 Test MSE 0.029200554720655903 Test RE 0.08167772095469696\n",
      "51 Train Loss 0.111577 Test MSE 0.02575819269652748 Test RE 0.07671243250693142\n",
      "52 Train Loss 0.10059194 Test MSE 0.027101609381742723 Test RE 0.07868747346688085\n",
      "53 Train Loss 0.096616454 Test MSE 0.029552322349775943 Test RE 0.08216821790441285\n",
      "54 Train Loss 0.08305325 Test MSE 0.024674562551861744 Test RE 0.07508147419696128\n",
      "55 Train Loss 0.077905275 Test MSE 0.024287062354001354 Test RE 0.0744895849088528\n",
      "56 Train Loss 0.07010981 Test MSE 0.017792300976621853 Test RE 0.06375644872037543\n",
      "57 Train Loss 0.06538013 Test MSE 0.017068058542751664 Test RE 0.06244535259592148\n",
      "58 Train Loss 0.062682256 Test MSE 0.01500984379615061 Test RE 0.058559336400294135\n",
      "59 Train Loss 0.06029866 Test MSE 0.01416395688782068 Test RE 0.05688534002514065\n",
      "60 Train Loss 0.05583446 Test MSE 0.013525012305958975 Test RE 0.05558746829402097\n",
      "61 Train Loss 0.053115077 Test MSE 0.013724997984696223 Test RE 0.055996928355585625\n",
      "62 Train Loss 0.04807143 Test MSE 0.01076905023561112 Test RE 0.04960172288650899\n",
      "63 Train Loss 0.04543232 Test MSE 0.011042156525356778 Test RE 0.05022674218798241\n",
      "64 Train Loss 0.043394133 Test MSE 0.009493024540619772 Test RE 0.04657044223896954\n",
      "65 Train Loss 0.041538008 Test MSE 0.008813936780034653 Test RE 0.04487381837638171\n",
      "66 Train Loss 0.0399461 Test MSE 0.008367679278974091 Test RE 0.04372306245723569\n",
      "67 Train Loss 0.0379437 Test MSE 0.007902443913079999 Test RE 0.042490199613797366\n",
      "68 Train Loss 0.03634771 Test MSE 0.0077851522271671835 Test RE 0.0421736912974151\n",
      "69 Train Loss 0.034093205 Test MSE 0.007962177519147256 Test RE 0.04265048639546346\n",
      "70 Train Loss 0.032293048 Test MSE 0.007359716789665137 Test RE 0.04100516950831396\n",
      "71 Train Loss 0.031603545 Test MSE 0.006992451289616899 Test RE 0.03996895421557284\n",
      "72 Train Loss 0.02976621 Test MSE 0.007090536279275359 Test RE 0.04024830561319312\n",
      "73 Train Loss 0.027446246 Test MSE 0.0067025678979298325 Test RE 0.03913169603241415\n",
      "74 Train Loss 0.026281698 Test MSE 0.006805164018864245 Test RE 0.039430052817443426\n",
      "75 Train Loss 0.025734518 Test MSE 0.007001843424433891 Test RE 0.03999578799817484\n",
      "76 Train Loss 0.024858616 Test MSE 0.006941119615374429 Test RE 0.03982197767780655\n",
      "77 Train Loss 0.023896998 Test MSE 0.0066997083341086205 Test RE 0.03912334762613055\n",
      "78 Train Loss 0.023352776 Test MSE 0.007157043127691159 Test RE 0.04043662284888245\n",
      "79 Train Loss 0.022348102 Test MSE 0.006421461566892843 Test RE 0.03830231327739353\n",
      "80 Train Loss 0.021176338 Test MSE 0.0066984948650781395 Test RE 0.03911980440318424\n",
      "81 Train Loss 0.020677654 Test MSE 0.006632144769531731 Test RE 0.03892557701697749\n",
      "82 Train Loss 0.019795379 Test MSE 0.006155840479735243 Test RE 0.037501767660953374\n",
      "83 Train Loss 0.019244129 Test MSE 0.006094339848919574 Test RE 0.03731396455944875\n",
      "84 Train Loss 0.018246267 Test MSE 0.005339159730928659 Test RE 0.03492565158190036\n",
      "85 Train Loss 0.017729826 Test MSE 0.005703731474670782 Test RE 0.036098370319791635\n",
      "86 Train Loss 0.017434824 Test MSE 0.005608727075854581 Test RE 0.035796471020498724\n",
      "87 Train Loss 0.016728587 Test MSE 0.005268930250119826 Test RE 0.034695191186760434\n",
      "88 Train Loss 0.01484968 Test MSE 0.004287305481972671 Test RE 0.03129682452645549\n",
      "89 Train Loss 0.013664371 Test MSE 0.003970601193539067 Test RE 0.03011869805839615\n",
      "90 Train Loss 0.01293643 Test MSE 0.0034100602075140814 Test RE 0.02791187964158561\n",
      "91 Train Loss 0.012609176 Test MSE 0.00317741786414398 Test RE 0.026942955061007214\n",
      "92 Train Loss 0.012466677 Test MSE 0.0032359053739317843 Test RE 0.027189797110564615\n",
      "93 Train Loss 0.012321536 Test MSE 0.003079885038632427 Test RE 0.026526216709545098\n",
      "94 Train Loss 0.011884863 Test MSE 0.00270199722784943 Test RE 0.024845658398499938\n",
      "95 Train Loss 0.011386177 Test MSE 0.002708279566032023 Test RE 0.024874525601378896\n",
      "96 Train Loss 0.011176921 Test MSE 0.0025102694784406537 Test RE 0.023947943955727878\n",
      "97 Train Loss 0.010931243 Test MSE 0.0024076577787292205 Test RE 0.023453379920971268\n",
      "98 Train Loss 0.010497669 Test MSE 0.002061849234870081 Test RE 0.02170383670571726\n",
      "99 Train Loss 0.010198282 Test MSE 0.0020518926860325815 Test RE 0.02165137001316242\n",
      "Training time: 158.07\n",
      "6\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 65.45041 Test MSE 6.224998499368406 Test RE 1.192552990544974\n",
      "1 Train Loss 47.634354 Test MSE 8.311046186337723 Test RE 1.3779577704305845\n",
      "2 Train Loss 39.579678 Test MSE 8.810364602943975 Test RE 1.4187471462247856\n",
      "3 Train Loss 33.57238 Test MSE 8.383481777080412 Test RE 1.383949594025339\n",
      "4 Train Loss 30.597654 Test MSE 8.55561149320724 Test RE 1.3980850375943161\n",
      "5 Train Loss 27.957314 Test MSE 8.533651864140458 Test RE 1.3962896571902879\n",
      "6 Train Loss 26.415348 Test MSE 8.339878352545156 Test RE 1.3803458639043902\n",
      "7 Train Loss 24.3902 Test MSE 8.104564359932867 Test RE 1.3607329396121632\n",
      "8 Train Loss 23.005232 Test MSE 7.96337516115561 Test RE 1.3488282347320126\n",
      "9 Train Loss 21.32843 Test MSE 7.462863555845095 Test RE 1.3057523346157396\n",
      "10 Train Loss 20.040205 Test MSE 7.741662680803004 Test RE 1.3299189749033637\n",
      "11 Train Loss 19.085072 Test MSE 7.6611321704666135 Test RE 1.322983834910944\n",
      "12 Train Loss 18.315483 Test MSE 7.362733052336502 Test RE 1.2969630030241346\n",
      "13 Train Loss 17.581669 Test MSE 7.594276640566637 Test RE 1.3171986197544376\n",
      "14 Train Loss 16.858757 Test MSE 7.724167012929651 Test RE 1.3284153585311795\n",
      "15 Train Loss 16.357376 Test MSE 7.874419219077175 Test RE 1.3412734448794805\n",
      "16 Train Loss 15.78097 Test MSE 7.982406901318916 Test RE 1.3504390610903256\n",
      "17 Train Loss 15.189507 Test MSE 8.111300727658346 Test RE 1.3612983304897917\n",
      "18 Train Loss 14.206066 Test MSE 8.015729905831803 Test RE 1.3532548671989322\n",
      "19 Train Loss 13.518917 Test MSE 8.19530756887315 Test RE 1.368329496282457\n",
      "20 Train Loss 12.59124 Test MSE 7.9532083432198455 Test RE 1.3479669371956353\n",
      "21 Train Loss 11.937862 Test MSE 7.794865604897533 Test RE 1.3344809426586852\n",
      "22 Train Loss 11.323077 Test MSE 7.753430322697156 Test RE 1.3309293565385956\n",
      "23 Train Loss 10.211964 Test MSE 7.627086912999059 Test RE 1.3200409620108866\n",
      "24 Train Loss 9.327489 Test MSE 7.212258581507156 Test RE 1.2836413684403274\n",
      "25 Train Loss 8.714011 Test MSE 7.154597886721424 Test RE 1.2784998318418463\n",
      "26 Train Loss 8.234412 Test MSE 6.982770116336966 Test RE 1.2630540407862687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 7.5719156 Test MSE 6.846201165218981 Test RE 1.250641651332741\n",
      "28 Train Loss 6.9568954 Test MSE 6.827522237607309 Test RE 1.2489343833042401\n",
      "29 Train Loss 6.071395 Test MSE 6.634197079929274 Test RE 1.2311252671275061\n",
      "30 Train Loss 5.4540915 Test MSE 6.2064099855427175 Test RE 1.190771113701315\n",
      "31 Train Loss 5.0400634 Test MSE 6.010649934250407 Test RE 1.17184123983233\n",
      "32 Train Loss 4.4938807 Test MSE 5.972678862080067 Test RE 1.1681339398424369\n",
      "33 Train Loss 4.0515995 Test MSE 5.681212839357579 Test RE 1.1392750597902552\n",
      "34 Train Loss 3.7828763 Test MSE 5.748779389828858 Test RE 1.1460297236098516\n",
      "35 Train Loss 3.4515429 Test MSE 5.756808178266031 Test RE 1.1468297212427836\n",
      "36 Train Loss 3.1841903 Test MSE 5.694455375968112 Test RE 1.1406020748754502\n",
      "37 Train Loss 3.010628 Test MSE 5.656484125118084 Test RE 1.136792884578586\n",
      "38 Train Loss 2.8817263 Test MSE 5.700920768889708 Test RE 1.1412494017993347\n",
      "39 Train Loss 2.758018 Test MSE 5.686049563712319 Test RE 1.1397599199131105\n",
      "40 Train Loss 2.6608224 Test MSE 5.707379873078202 Test RE 1.1418957326572567\n",
      "41 Train Loss 2.5678346 Test MSE 5.732391460921827 Test RE 1.1443950759598516\n",
      "42 Train Loss 2.4553652 Test MSE 5.656497110785922 Test RE 1.1367941894533102\n",
      "43 Train Loss 2.323883 Test MSE 5.684353341937647 Test RE 1.1395899047052853\n",
      "44 Train Loss 2.257887 Test MSE 5.671829997628705 Test RE 1.1383338826898244\n",
      "45 Train Loss 2.1905432 Test MSE 5.647840591071775 Test RE 1.1359239999201378\n",
      "46 Train Loss 2.1250706 Test MSE 5.6868556380134665 Test RE 1.1398407052291983\n",
      "47 Train Loss 2.074689 Test MSE 5.654688797884728 Test RE 1.1366124653333565\n",
      "48 Train Loss 2.0279891 Test MSE 5.656983825869264 Test RE 1.1368430963091112\n",
      "49 Train Loss 1.9677038 Test MSE 5.6976981011320795 Test RE 1.1409267883381764\n",
      "50 Train Loss 1.9310261 Test MSE 5.652821525317754 Test RE 1.1364247856403882\n",
      "51 Train Loss 1.8801568 Test MSE 5.683575456264478 Test RE 1.1395119274107208\n",
      "52 Train Loss 1.8291606 Test MSE 5.680044583925441 Test RE 1.1391579164315095\n",
      "53 Train Loss 1.7914943 Test MSE 5.703167177356854 Test RE 1.1414742303770071\n",
      "54 Train Loss 1.7393283 Test MSE 5.6981918284429325 Test RE 1.1409762201001308\n",
      "55 Train Loss 1.7044258 Test MSE 5.743974251070446 Test RE 1.1455506668677693\n",
      "56 Train Loss 1.6606508 Test MSE 5.777534580227348 Test RE 1.1488923483821427\n",
      "57 Train Loss 1.6230347 Test MSE 5.7267856859091 Test RE 1.1438353801929768\n",
      "58 Train Loss 1.5889232 Test MSE 5.757291251552898 Test RE 1.1468778374179442\n",
      "59 Train Loss 1.5648372 Test MSE 5.7542668808850275 Test RE 1.1465765638518821\n",
      "60 Train Loss 1.5412519 Test MSE 5.757099236606132 Test RE 1.1468587121458798\n",
      "61 Train Loss 1.524876 Test MSE 5.811909917614249 Test RE 1.1523051355050329\n",
      "62 Train Loss 1.5045885 Test MSE 5.825367569785678 Test RE 1.1536384627063654\n",
      "63 Train Loss 1.4848236 Test MSE 5.801945977806028 Test RE 1.15131695568397\n",
      "64 Train Loss 1.4689064 Test MSE 5.799486658658234 Test RE 1.1510729206690864\n",
      "65 Train Loss 1.4606589 Test MSE 5.774051074718962 Test RE 1.1485459397005677\n",
      "66 Train Loss 1.4466827 Test MSE 5.790798319097632 Test RE 1.1502103735646498\n",
      "67 Train Loss 1.4324136 Test MSE 5.7909034713100604 Test RE 1.150220816564891\n",
      "68 Train Loss 1.4186506 Test MSE 5.834858886494951 Test RE 1.1545778962674393\n",
      "69 Train Loss 1.4028969 Test MSE 5.830887212505048 Test RE 1.1541848801133203\n",
      "70 Train Loss 1.395843 Test MSE 5.825324619478878 Test RE 1.153634209823037\n",
      "71 Train Loss 1.3798124 Test MSE 5.868039356419736 Test RE 1.157856050003814\n",
      "72 Train Loss 1.3613287 Test MSE 5.879064894390956 Test RE 1.1589432951764187\n",
      "73 Train Loss 1.3529588 Test MSE 5.868343165135696 Test RE 1.1578860227243026\n",
      "74 Train Loss 1.3432243 Test MSE 5.8724787629258275 Test RE 1.1582939494065276\n",
      "75 Train Loss 1.3306034 Test MSE 5.864969968026109 Test RE 1.157553191198519\n",
      "76 Train Loss 1.3163011 Test MSE 5.896681065866675 Test RE 1.1606783392012283\n",
      "77 Train Loss 1.3026099 Test MSE 5.866156787796736 Test RE 1.1576703049712582\n",
      "78 Train Loss 1.2927485 Test MSE 5.858315037571749 Test RE 1.1568962720222238\n",
      "79 Train Loss 1.2749461 Test MSE 5.876356350502333 Test RE 1.1586762960475698\n",
      "80 Train Loss 1.2606404 Test MSE 5.897329322169282 Test RE 1.1607421374940334\n",
      "81 Train Loss 1.2531773 Test MSE 5.913807821251393 Test RE 1.1623626969306653\n",
      "82 Train Loss 1.2439177 Test MSE 5.892750324092946 Test RE 1.1602914192244806\n",
      "83 Train Loss 1.2349248 Test MSE 5.8919373727447475 Test RE 1.1602113807911107\n",
      "84 Train Loss 1.2264631 Test MSE 5.897745419611706 Test RE 1.1607830859716584\n",
      "85 Train Loss 1.2138959 Test MSE 5.90179271238519 Test RE 1.161181307914032\n",
      "86 Train Loss 1.2007751 Test MSE 5.883101067454065 Test RE 1.1593410534271638\n",
      "87 Train Loss 1.1900722 Test MSE 5.885371762567315 Test RE 1.1595647667431992\n",
      "88 Train Loss 1.182044 Test MSE 5.880922445503311 Test RE 1.1591263707524748\n",
      "89 Train Loss 1.1761329 Test MSE 5.885405407324893 Test RE 1.1595680811659141\n",
      "90 Train Loss 1.1666037 Test MSE 5.882196920749353 Test RE 1.159251963110851\n",
      "91 Train Loss 1.157957 Test MSE 5.86827587589581 Test RE 1.157879384266777\n",
      "92 Train Loss 1.1474652 Test MSE 5.887874581843542 Test RE 1.1598112993911582\n",
      "93 Train Loss 1.1401014 Test MSE 5.887672664656842 Test RE 1.1597914120923354\n",
      "94 Train Loss 1.1316359 Test MSE 5.9224898795299366 Test RE 1.1632156160473885\n",
      "95 Train Loss 1.1225561 Test MSE 5.908078388472049 Test RE 1.1617994986552969\n",
      "96 Train Loss 1.1121087 Test MSE 5.925667918628304 Test RE 1.1635276679877622\n",
      "97 Train Loss 1.1038554 Test MSE 5.922104288288971 Test RE 1.1631777491145006\n",
      "98 Train Loss 1.0993878 Test MSE 5.922756946586596 Test RE 1.163241842607085\n",
      "99 Train Loss 1.0906726 Test MSE 5.909465945950996 Test RE 1.161935919403055\n",
      "Training time: 159.98\n",
      "7\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 67.77754 Test MSE 4.850313505049762 Test RE 1.052671743731412\n",
      "1 Train Loss 51.667465 Test MSE 7.035946748310192 Test RE 1.267854254114967\n",
      "2 Train Loss 41.411057 Test MSE 5.618483684441031 Test RE 1.1329679443159926\n",
      "3 Train Loss 30.086044 Test MSE 6.755278962338998 Test RE 1.2423092083220277\n",
      "4 Train Loss 23.958254 Test MSE 5.7162195907534805 Test RE 1.1427796873503335\n",
      "5 Train Loss 20.809021 Test MSE 5.649271046634245 Test RE 1.136067841261374\n",
      "6 Train Loss 17.877449 Test MSE 5.6724835182207105 Test RE 1.1383994614541129\n",
      "7 Train Loss 14.752823 Test MSE 5.745836340283421 Test RE 1.145736334890923\n",
      "8 Train Loss 13.338262 Test MSE 5.725903045354715 Test RE 1.1437472300112312\n",
      "9 Train Loss 12.6301985 Test MSE 5.868741316020394 Test RE 1.1579253017432694\n",
      "10 Train Loss 12.16544 Test MSE 5.7764628426438 Test RE 1.1487857831855413\n",
      "11 Train Loss 11.4948015 Test MSE 5.587097688900589 Test RE 1.1297990175687425\n",
      "12 Train Loss 10.771927 Test MSE 5.463480678027198 Test RE 1.117230455633979\n",
      "13 Train Loss 10.268976 Test MSE 5.33952710061563 Test RE 1.104484073605631\n",
      "14 Train Loss 9.413618 Test MSE 5.3091484530739965 Test RE 1.1013376720951609\n",
      "15 Train Loss 8.687178 Test MSE 4.882925711411806 Test RE 1.0562047560771417\n",
      "16 Train Loss 7.649431 Test MSE 4.450223047788438 Test RE 1.0083213189737474\n",
      "17 Train Loss 6.7555704 Test MSE 4.062483455649692 Test RE 0.9633938352695051\n",
      "18 Train Loss 6.081961 Test MSE 4.153977861114656 Test RE 0.9741821082296993\n",
      "19 Train Loss 5.553108 Test MSE 3.9811580201578494 Test RE 0.9537021643965137\n",
      "20 Train Loss 5.0064745 Test MSE 3.6146102019603754 Test RE 0.9087382224253868\n",
      "21 Train Loss 4.2733307 Test MSE 3.0032999648711933 Test RE 0.8283376771188663\n",
      "22 Train Loss 3.78426 Test MSE 2.8273871750567903 Test RE 0.8037124616058495\n",
      "23 Train Loss 3.3466687 Test MSE 2.3483814057736208 Test RE 0.732474275367762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 2.6624565 Test MSE 2.0475260132463546 Test RE 0.6839475124004457\n",
      "25 Train Loss 2.2355528 Test MSE 1.8214445518838738 Test RE 0.6450836547645482\n",
      "26 Train Loss 1.9800594 Test MSE 1.6938861225017245 Test RE 0.6220856241193371\n",
      "27 Train Loss 1.6997044 Test MSE 1.6879303203357985 Test RE 0.6209910164707252\n",
      "28 Train Loss 1.4981471 Test MSE 1.5566079018312309 Test RE 0.596345128173635\n",
      "29 Train Loss 1.350004 Test MSE 1.4997713347864006 Test RE 0.5853566877956503\n",
      "30 Train Loss 1.2770513 Test MSE 1.4484210578858168 Test RE 0.5752484741490225\n",
      "31 Train Loss 1.1727422 Test MSE 1.4708094587277696 Test RE 0.5796772646229068\n",
      "32 Train Loss 0.94000036 Test MSE 1.3969134461631032 Test RE 0.5649276209114727\n",
      "33 Train Loss 0.82044643 Test MSE 1.3633653097013219 Test RE 0.5581027724712829\n",
      "34 Train Loss 0.7257987 Test MSE 1.2970362237714588 Test RE 0.5443573772110758\n",
      "35 Train Loss 0.6409046 Test MSE 1.1719366747058662 Test RE 0.5174401605081164\n",
      "36 Train Loss 0.58804977 Test MSE 1.1166752150889683 Test RE 0.5050931733144338\n",
      "37 Train Loss 0.50376755 Test MSE 1.0148792559503654 Test RE 0.481521017592493\n",
      "38 Train Loss 0.441226 Test MSE 0.9928146660614942 Test RE 0.4762578557220264\n",
      "39 Train Loss 0.39389932 Test MSE 0.9404323316490276 Test RE 0.4635235842027266\n",
      "40 Train Loss 0.34885633 Test MSE 0.9001246349775179 Test RE 0.45348130127638303\n",
      "41 Train Loss 0.33335802 Test MSE 0.8977967060574112 Test RE 0.4528945182734248\n",
      "42 Train Loss 0.28730807 Test MSE 0.8102273088673076 Test RE 0.4302407072725841\n",
      "43 Train Loss 0.25205296 Test MSE 0.7458562986943599 Test RE 0.4127961528317202\n",
      "44 Train Loss 0.22578399 Test MSE 0.7141894896618669 Test RE 0.40393807138631427\n",
      "45 Train Loss 0.20717515 Test MSE 0.6949964025862619 Test RE 0.39847340285972893\n",
      "46 Train Loss 0.19417438 Test MSE 0.6457691470136934 Test RE 0.38410212176692354\n",
      "47 Train Loss 0.17036171 Test MSE 0.5834833574566851 Test RE 0.36510879689580905\n",
      "48 Train Loss 0.15551652 Test MSE 0.5773465509760379 Test RE 0.363183699469013\n",
      "49 Train Loss 0.13849458 Test MSE 0.525594830138789 Test RE 0.34652422640529673\n",
      "50 Train Loss 0.12771906 Test MSE 0.4948825510793108 Test RE 0.33624755183166133\n",
      "51 Train Loss 0.122940175 Test MSE 0.4898924413972545 Test RE 0.3345479936282872\n",
      "52 Train Loss 0.11605746 Test MSE 0.4863720987325974 Test RE 0.3333438038127485\n",
      "53 Train Loss 0.106745385 Test MSE 0.4588991410350855 Test RE 0.3237924237247951\n",
      "54 Train Loss 0.10275546 Test MSE 0.4392582258307791 Test RE 0.31678748194546985\n",
      "55 Train Loss 0.09786243 Test MSE 0.430893341903618 Test RE 0.31375665915089973\n",
      "56 Train Loss 0.09033239 Test MSE 0.39888777528951336 Test RE 0.3018793621085893\n",
      "57 Train Loss 0.085033104 Test MSE 0.3892420696677554 Test RE 0.2982070776812949\n",
      "58 Train Loss 0.08166009 Test MSE 0.3727850590630227 Test RE 0.29183495514123176\n",
      "59 Train Loss 0.07722756 Test MSE 0.36224815520992126 Test RE 0.2876809813281225\n",
      "60 Train Loss 0.07379737 Test MSE 0.36455838709593424 Test RE 0.2885968638487472\n",
      "61 Train Loss 0.0708669 Test MSE 0.3525167157147116 Test RE 0.28379054230373796\n",
      "62 Train Loss 0.068384975 Test MSE 0.33771466172968173 Test RE 0.27776851573177297\n",
      "63 Train Loss 0.061536506 Test MSE 0.3205253597170037 Test RE 0.27060714441509415\n",
      "64 Train Loss 0.057727203 Test MSE 0.3158035764674258 Test RE 0.2686065398175906\n",
      "65 Train Loss 0.054134358 Test MSE 0.3013570971723625 Test RE 0.26239090184270586\n",
      "66 Train Loss 0.051681604 Test MSE 0.2864868966685245 Test RE 0.2558352845752378\n",
      "67 Train Loss 0.04850157 Test MSE 0.26849037446264595 Test RE 0.2476694390901156\n",
      "68 Train Loss 0.045624964 Test MSE 0.2621431853884609 Test RE 0.24472444173579466\n",
      "69 Train Loss 0.044659216 Test MSE 0.2603338941356841 Test RE 0.24387844521809177\n",
      "70 Train Loss 0.04285988 Test MSE 0.2696632296779406 Test RE 0.24820980083706634\n",
      "71 Train Loss 0.041175324 Test MSE 0.2725115878099068 Test RE 0.24951723395980202\n",
      "72 Train Loss 0.040146545 Test MSE 0.2726316234025123 Test RE 0.2495721814426239\n",
      "73 Train Loss 0.038499624 Test MSE 0.26701675214456916 Test RE 0.24698883111072734\n",
      "74 Train Loss 0.036481347 Test MSE 0.254825337468841 Test RE 0.24128446686338836\n",
      "75 Train Loss 0.03572433 Test MSE 0.258190812481576 Test RE 0.24287256103061336\n",
      "76 Train Loss 0.034412876 Test MSE 0.25817318816330653 Test RE 0.24286427154826737\n",
      "77 Train Loss 0.032643456 Test MSE 0.24581354499775993 Test RE 0.23697960174581234\n",
      "78 Train Loss 0.031745143 Test MSE 0.23789176721525282 Test RE 0.2331297868228731\n",
      "79 Train Loss 0.03068848 Test MSE 0.22683736757925263 Test RE 0.22764879699636845\n",
      "80 Train Loss 0.02858095 Test MSE 0.21301046466281007 Test RE 0.2206015350560025\n",
      "81 Train Loss 0.027190663 Test MSE 0.21042419029818815 Test RE 0.21925822432748313\n",
      "82 Train Loss 0.025649954 Test MSE 0.2073619627923586 Test RE 0.2176569843986494\n",
      "83 Train Loss 0.024438782 Test MSE 0.20143141719130075 Test RE 0.21452191462121226\n",
      "84 Train Loss 0.023665724 Test MSE 0.196957893342568 Test RE 0.21212641654579825\n",
      "85 Train Loss 0.023144644 Test MSE 0.19376761040042756 Test RE 0.21040141295430506\n",
      "86 Train Loss 0.022210915 Test MSE 0.1912437244214851 Test RE 0.20902664826559922\n",
      "87 Train Loss 0.021244977 Test MSE 0.19297110407735446 Test RE 0.20996852679942607\n",
      "88 Train Loss 0.020730712 Test MSE 0.18692824014622786 Test RE 0.2066548103587845\n",
      "89 Train Loss 0.02016724 Test MSE 0.18197132190160226 Test RE 0.20389638935499507\n",
      "90 Train Loss 0.018992664 Test MSE 0.18172943547693363 Test RE 0.20376082906819587\n",
      "91 Train Loss 0.01827 Test MSE 0.17860889884445405 Test RE 0.20200383139759293\n",
      "92 Train Loss 0.017620526 Test MSE 0.17770159070650235 Test RE 0.2014901025934849\n",
      "93 Train Loss 0.017185416 Test MSE 0.17821973450122114 Test RE 0.20178364204204577\n",
      "94 Train Loss 0.016760062 Test MSE 0.17788214582314565 Test RE 0.20159243941686025\n",
      "95 Train Loss 0.016347677 Test MSE 0.17856247458245292 Test RE 0.201977577139514\n",
      "96 Train Loss 0.015924383 Test MSE 0.17473963777879745 Test RE 0.19980381480163176\n",
      "97 Train Loss 0.015129179 Test MSE 0.1665807239260189 Test RE 0.1950834524534141\n",
      "98 Train Loss 0.014433826 Test MSE 0.16211785391489092 Test RE 0.19245246731083887\n",
      "99 Train Loss 0.014059722 Test MSE 0.16255003907636428 Test RE 0.19270882322387847\n",
      "Training time: 161.90\n",
      "8\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 63.75401 Test MSE 5.352266367527504 Test RE 1.105800850799315\n",
      "1 Train Loss 47.32068 Test MSE 6.922899949369257 Test RE 1.257627681099075\n",
      "2 Train Loss 35.798107 Test MSE 7.627124014274987 Test RE 1.3200441726170438\n",
      "3 Train Loss 31.237886 Test MSE 6.633522238079876 Test RE 1.2310626494534185\n",
      "4 Train Loss 27.664692 Test MSE 6.9911932483911645 Test RE 1.2638156056370333\n",
      "5 Train Loss 24.90338 Test MSE 7.643949590488437 Test RE 1.3214993913919761\n",
      "6 Train Loss 22.800522 Test MSE 7.955860779109384 Test RE 1.3481916954110824\n",
      "7 Train Loss 20.157553 Test MSE 7.918149871884647 Test RE 1.344992674966292\n",
      "8 Train Loss 18.99843 Test MSE 8.31745612519554 Test RE 1.3784890466660433\n",
      "9 Train Loss 17.858166 Test MSE 8.17388216012598 Test RE 1.366539679070415\n",
      "10 Train Loss 16.535263 Test MSE 8.290420244124475 Test RE 1.3762468346169514\n",
      "11 Train Loss 15.545546 Test MSE 8.419630724193487 Test RE 1.3869301281502344\n",
      "12 Train Loss 15.018362 Test MSE 8.260716537685854 Test RE 1.3737791482174169\n",
      "13 Train Loss 14.4572935 Test MSE 8.390609413040456 Test RE 1.384537785983751\n",
      "14 Train Loss 13.997877 Test MSE 8.462380455903395 Test RE 1.390446661271721\n",
      "15 Train Loss 13.440119 Test MSE 8.357677467461755 Test RE 1.3818180580255277\n",
      "16 Train Loss 12.5115795 Test MSE 7.7909212632977765 Test RE 1.3341432643068893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 11.659571 Test MSE 7.163148319059718 Test RE 1.2792635688340528\n",
      "18 Train Loss 10.65901 Test MSE 7.284811034004814 Test RE 1.2900816730294369\n",
      "19 Train Loss 10.140736 Test MSE 7.085453674597305 Test RE 1.2723069271856993\n",
      "20 Train Loss 9.740153 Test MSE 7.219568211211549 Test RE 1.2842916894714913\n",
      "21 Train Loss 9.133205 Test MSE 7.122821187185183 Test RE 1.2756574837368846\n",
      "22 Train Loss 8.674736 Test MSE 7.216679247831729 Test RE 1.2840347043721925\n",
      "23 Train Loss 8.135756 Test MSE 7.33623368411115 Test RE 1.2946269356968405\n",
      "24 Train Loss 7.637712 Test MSE 7.241810959769234 Test RE 1.2862685534439697\n",
      "25 Train Loss 7.339568 Test MSE 7.215539846777634 Test RE 1.2839333358481533\n",
      "26 Train Loss 7.101761 Test MSE 7.0908017776584495 Test RE 1.2727870054821986\n",
      "27 Train Loss 6.6580467 Test MSE 7.069137270541033 Test RE 1.2708411467369964\n",
      "28 Train Loss 6.2923045 Test MSE 6.9183874913161985 Test RE 1.2572177432649847\n",
      "29 Train Loss 5.759978 Test MSE 6.536699366276409 Test RE 1.2220453308397237\n",
      "30 Train Loss 5.20953 Test MSE 6.304005437228798 Test RE 1.2000969992025499\n",
      "31 Train Loss 4.632203 Test MSE 6.358347131554952 Test RE 1.205258429141446\n",
      "32 Train Loss 4.374949 Test MSE 6.523594597492975 Test RE 1.2208197385961341\n",
      "33 Train Loss 4.1117463 Test MSE 6.496904473727892 Test RE 1.2183197958487164\n",
      "34 Train Loss 3.9979992 Test MSE 6.486135274200259 Test RE 1.217309640122768\n",
      "35 Train Loss 3.8022316 Test MSE 6.4390112884133135 Test RE 1.212879493886942\n",
      "36 Train Loss 3.6776595 Test MSE 6.542180358159719 Test RE 1.2225575631367696\n",
      "37 Train Loss 3.5210557 Test MSE 6.7008592511353315 Test RE 1.2372951432783568\n",
      "38 Train Loss 3.387899 Test MSE 6.765105512753914 Test RE 1.2432124410320566\n",
      "39 Train Loss 3.2943301 Test MSE 6.832068264762757 Test RE 1.2493501084115883\n",
      "40 Train Loss 3.1949599 Test MSE 6.892597055261764 Test RE 1.2548722206905105\n",
      "41 Train Loss 3.132997 Test MSE 6.936033566407246 Test RE 1.2588200552542743\n",
      "42 Train Loss 3.0424566 Test MSE 6.896085839062246 Test RE 1.255189766021153\n",
      "43 Train Loss 2.9924068 Test MSE 6.831972274760307 Test RE 1.2493413317471467\n",
      "44 Train Loss 2.915464 Test MSE 6.7921452816961825 Test RE 1.245694490538183\n",
      "45 Train Loss 2.8805013 Test MSE 6.751105565037637 Test RE 1.2419254010107155\n",
      "46 Train Loss 2.8366332 Test MSE 6.802030618384773 Test RE 1.246600657270961\n",
      "47 Train Loss 2.7994998 Test MSE 6.828293136085627 Test RE 1.2490048901737927\n",
      "48 Train Loss 2.7523074 Test MSE 6.847303100415871 Test RE 1.2507422962430483\n",
      "49 Train Loss 2.7307467 Test MSE 6.824717939113104 Test RE 1.248677866781851\n",
      "50 Train Loss 2.6836674 Test MSE 6.85144001891988 Test RE 1.2511200681618155\n",
      "51 Train Loss 2.6391473 Test MSE 6.7610419905053405 Test RE 1.2428390115092007\n",
      "52 Train Loss 2.5776691 Test MSE 6.8092690495669 Test RE 1.2472637705575331\n",
      "53 Train Loss 2.5326016 Test MSE 6.7700000935107045 Test RE 1.2436620942891923\n",
      "54 Train Loss 2.4870892 Test MSE 6.800168175334482 Test RE 1.246429981644182\n",
      "55 Train Loss 2.4511743 Test MSE 6.816985168537365 Test RE 1.247970256868814\n",
      "56 Train Loss 2.4137516 Test MSE 6.841144253060769 Test RE 1.2501796759160195\n",
      "57 Train Loss 2.3880768 Test MSE 6.8831479588312785 Test RE 1.2540117703290883\n",
      "58 Train Loss 2.3599741 Test MSE 6.853150260716881 Test RE 1.2512762093756657\n",
      "59 Train Loss 2.3403087 Test MSE 6.8447985550445996 Test RE 1.2505135326493122\n",
      "60 Train Loss 2.3187857 Test MSE 6.835011356371279 Test RE 1.2496191745111378\n",
      "61 Train Loss 2.2962923 Test MSE 6.826582762880435 Test RE 1.2488484529612929\n",
      "62 Train Loss 2.2766936 Test MSE 6.827122011459728 Test RE 1.2488977767942233\n",
      "63 Train Loss 2.2464814 Test MSE 6.835339676881123 Test RE 1.2496491869468394\n",
      "64 Train Loss 2.2334468 Test MSE 6.831480002453172 Test RE 1.249296320790276\n",
      "65 Train Loss 2.2084222 Test MSE 6.809493469166789 Test RE 1.2472843240213505\n",
      "66 Train Loss 2.1842167 Test MSE 6.807244575056231 Test RE 1.2470783437956432\n",
      "67 Train Loss 2.1710715 Test MSE 6.795735299616641 Test RE 1.2460236556681012\n",
      "68 Train Loss 2.1567793 Test MSE 6.784147931843621 Test RE 1.2449609086979672\n",
      "69 Train Loss 2.1286843 Test MSE 6.773555549486983 Test RE 1.243988623488649\n",
      "70 Train Loss 2.1126924 Test MSE 6.806335220092525 Test RE 1.2469950446909133\n",
      "71 Train Loss 2.0946906 Test MSE 6.8366755462601 Test RE 1.2497712940114953\n",
      "72 Train Loss 2.0842037 Test MSE 6.809722363842826 Test RE 1.2473052869860282\n",
      "73 Train Loss 2.0716298 Test MSE 6.793912805594533 Test RE 1.2458565638939352\n",
      "74 Train Loss 2.0544229 Test MSE 6.818409818952027 Test RE 1.2481006538419464\n",
      "75 Train Loss 2.0386918 Test MSE 6.830304839202037 Test RE 1.2491888630894312\n",
      "76 Train Loss 2.0156386 Test MSE 6.838502186463668 Test RE 1.2499382413830105\n",
      "77 Train Loss 1.996167 Test MSE 6.864797553610706 Test RE 1.2523390631648328\n",
      "78 Train Loss 1.9777654 Test MSE 6.838311361625288 Test RE 1.249920801823853\n",
      "79 Train Loss 1.9588739 Test MSE 6.845894584916115 Test RE 1.250613648475419\n",
      "80 Train Loss 1.9459678 Test MSE 6.8622882713207165 Test RE 1.252110159149357\n",
      "81 Train Loss 1.9258258 Test MSE 6.882888215872595 Test RE 1.2539881093673952\n",
      "82 Train Loss 1.914552 Test MSE 6.869132337056417 Test RE 1.2527343961583264\n",
      "83 Train Loss 1.898272 Test MSE 6.835453134975629 Test RE 1.2496595582110266\n",
      "84 Train Loss 1.8785807 Test MSE 6.818594623750436 Test RE 1.2481175678609744\n",
      "85 Train Loss 1.8640102 Test MSE 6.79105295297639 Test RE 1.2455943187570948\n",
      "86 Train Loss 1.845252 Test MSE 6.813130771548039 Test RE 1.247617399058132\n",
      "87 Train Loss 1.8275228 Test MSE 6.771096772260394 Test RE 1.2437628212124907\n",
      "88 Train Loss 1.8111413 Test MSE 6.729868368563453 Test RE 1.2399704775992457\n",
      "89 Train Loss 1.7868184 Test MSE 6.736850078889204 Test RE 1.2406134969056941\n",
      "90 Train Loss 1.7639681 Test MSE 6.6893807656913085 Test RE 1.2362349537524633\n",
      "91 Train Loss 1.7305664 Test MSE 6.688643947543415 Test RE 1.236166867821564\n",
      "92 Train Loss 1.7099526 Test MSE 6.6519717216316545 Test RE 1.232773407248938\n",
      "93 Train Loss 1.68815 Test MSE 6.5961267150877605 Test RE 1.227587776366916\n",
      "94 Train Loss 1.672064 Test MSE 6.553674530616951 Test RE 1.2236310676784463\n",
      "95 Train Loss 1.657679 Test MSE 6.530125334026867 Test RE 1.2214306638729913\n",
      "96 Train Loss 1.6401085 Test MSE 6.471415488143442 Test RE 1.2159275601592818\n",
      "97 Train Loss 1.6124207 Test MSE 6.446471310105666 Test RE 1.2135818911757763\n",
      "98 Train Loss 1.5949605 Test MSE 6.398338399351392 Test RE 1.2090427664852963\n",
      "99 Train Loss 1.5764902 Test MSE 6.371097570835415 Test RE 1.2064662806190614\n",
      "Training time: 159.93\n",
      "9\n",
      "KG_rowdy_tune33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 61.254097 Test MSE 7.2555397034964 Test RE 1.2874872051124036\n",
      "1 Train Loss 50.761864 Test MSE 8.13529565513078 Test RE 1.3633103464747314\n",
      "2 Train Loss 40.261032 Test MSE 8.260056726108592 Test RE 1.3737242829110476\n",
      "3 Train Loss 34.03074 Test MSE 8.259197080438359 Test RE 1.3736527975146444\n",
      "4 Train Loss 30.638596 Test MSE 8.28750892906079 Test RE 1.3760051677389116\n",
      "5 Train Loss 28.1081 Test MSE 8.313797012509252 Test RE 1.3781857927886727\n",
      "6 Train Loss 26.89262 Test MSE 8.545193805288482 Test RE 1.3972335934861133\n",
      "7 Train Loss 26.143635 Test MSE 8.601743727936292 Test RE 1.4018492383418393\n",
      "8 Train Loss 25.180145 Test MSE 8.735025149578295 Test RE 1.4126681059849235\n",
      "9 Train Loss 23.908243 Test MSE 8.675910224974528 Test RE 1.407879823358789\n",
      "10 Train Loss 22.829025 Test MSE 9.009520869301971 Test RE 1.4346927645650733\n",
      "11 Train Loss 21.421534 Test MSE 8.871093018223762 Test RE 1.4236283464077637\n",
      "12 Train Loss 20.4057 Test MSE 8.831621227055848 Test RE 1.4204576092857517\n",
      "13 Train Loss 18.961931 Test MSE 8.522661761281425 Test RE 1.3953902584901616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 17.208778 Test MSE 8.483178945914508 Test RE 1.3921543039291042\n",
      "15 Train Loss 16.017519 Test MSE 8.860663428180771 Test RE 1.4227912327253691\n",
      "16 Train Loss 14.347685 Test MSE 8.574754941010962 Test RE 1.3996482930830907\n",
      "17 Train Loss 13.153736 Test MSE 8.321668749066005 Test RE 1.3788380909334688\n",
      "18 Train Loss 11.603481 Test MSE 8.21119383547861 Test RE 1.3696550794172955\n",
      "19 Train Loss 10.086503 Test MSE 8.201154343282154 Test RE 1.368817512589866\n",
      "20 Train Loss 8.644814 Test MSE 7.636534033946793 Test RE 1.3208582286523016\n",
      "21 Train Loss 7.590966 Test MSE 7.43442781497295 Test RE 1.3032623070660194\n",
      "22 Train Loss 6.5833216 Test MSE 7.454387117627579 Test RE 1.3050105768753018\n",
      "23 Train Loss 5.964214 Test MSE 6.994188918331846 Test RE 1.264086344036607\n",
      "24 Train Loss 5.4108305 Test MSE 6.805725911093602 Test RE 1.2469392274057562\n",
      "25 Train Loss 4.6212325 Test MSE 6.358680125329152 Test RE 1.2052899890964424\n",
      "26 Train Loss 4.083186 Test MSE 6.541010753716106 Test RE 1.222448274444372\n",
      "27 Train Loss 3.830851 Test MSE 6.447655496782674 Test RE 1.2136933507205745\n",
      "28 Train Loss 3.5091162 Test MSE 6.525759490055604 Test RE 1.2210222898353515\n",
      "29 Train Loss 3.338401 Test MSE 6.657825504660339 Test RE 1.2333157127059742\n",
      "30 Train Loss 3.2257314 Test MSE 6.668272280045614 Test RE 1.2342829295587152\n",
      "31 Train Loss 3.1063137 Test MSE 6.81393559599408 Test RE 1.2476910864247712\n",
      "32 Train Loss 3.0378103 Test MSE 6.875298914522094 Test RE 1.2532965741999247\n",
      "33 Train Loss 2.9567323 Test MSE 6.861294552177378 Test RE 1.2520194976357921\n",
      "34 Train Loss 2.8761816 Test MSE 6.854397554133085 Test RE 1.2513900721622322\n",
      "35 Train Loss 2.7623663 Test MSE 6.840899836363689 Test RE 1.2501573428453259\n",
      "36 Train Loss 2.6874554 Test MSE 6.836903566586155 Test RE 1.2497921353458488\n",
      "37 Train Loss 2.6360252 Test MSE 6.820458209985025 Test RE 1.2482881173613452\n",
      "38 Train Loss 2.579163 Test MSE 6.8406506897789905 Test RE 1.250134577180298\n",
      "39 Train Loss 2.5242138 Test MSE 6.797760636081835 Test RE 1.2462093183693657\n",
      "40 Train Loss 2.4757104 Test MSE 6.870087301769578 Test RE 1.2528214723353965\n",
      "41 Train Loss 2.4105043 Test MSE 6.8807732862655655 Test RE 1.2537954358662948\n",
      "42 Train Loss 2.3714085 Test MSE 6.920606860616998 Test RE 1.257419380332272\n",
      "43 Train Loss 2.343636 Test MSE 6.8552655909510625 Test RE 1.251469307299915\n",
      "44 Train Loss 2.30692 Test MSE 6.865005796753455 Test RE 1.2523580578287345\n",
      "45 Train Loss 2.2631054 Test MSE 6.8467980645661966 Test RE 1.2506961699552992\n",
      "46 Train Loss 2.2136624 Test MSE 6.9161007069472715 Test RE 1.257009947481722\n",
      "47 Train Loss 2.1846452 Test MSE 6.945428731282876 Test RE 1.2596723305191075\n",
      "48 Train Loss 2.1335764 Test MSE 6.940240379237359 Test RE 1.2592017444129864\n",
      "49 Train Loss 2.0908675 Test MSE 6.9308279672966595 Test RE 1.258347584751205\n",
      "50 Train Loss 2.0271275 Test MSE 6.852216050890775 Test RE 1.2511909205431075\n",
      "51 Train Loss 1.9663926 Test MSE 6.76877335484631 Test RE 1.24354941205327\n",
      "52 Train Loss 1.9189684 Test MSE 6.714536259661104 Test RE 1.2385572105250227\n",
      "53 Train Loss 1.8870012 Test MSE 6.638027150921079 Test RE 1.2314805939855067\n",
      "54 Train Loss 1.8396317 Test MSE 6.633222636569931 Test RE 1.2310348488084535\n",
      "55 Train Loss 1.8032941 Test MSE 6.569121565767665 Test RE 1.2250722704283112\n",
      "56 Train Loss 1.7736437 Test MSE 6.587899435419242 Test RE 1.2268219588143778\n",
      "57 Train Loss 1.7550066 Test MSE 6.530975500229844 Test RE 1.221510171173424\n",
      "58 Train Loss 1.7149308 Test MSE 6.501476179573601 Test RE 1.2187483707391318\n",
      "59 Train Loss 1.6824547 Test MSE 6.504050524227459 Test RE 1.218989636549082\n",
      "60 Train Loss 1.6443801 Test MSE 6.475755245648288 Test RE 1.2163351948100538\n",
      "61 Train Loss 1.6202424 Test MSE 6.459388149857374 Test RE 1.214797114013854\n",
      "62 Train Loss 1.5924681 Test MSE 6.370111112964957 Test RE 1.206372876443709\n",
      "63 Train Loss 1.5716627 Test MSE 6.340113972165782 Test RE 1.2035290924488242\n",
      "64 Train Loss 1.5471436 Test MSE 6.249925931105911 Test RE 1.1949383391249662\n",
      "65 Train Loss 1.532479 Test MSE 6.236308925364667 Test RE 1.1936358953095036\n",
      "66 Train Loss 1.5098612 Test MSE 6.144312997900262 Test RE 1.1847991277539347\n",
      "67 Train Loss 1.4877908 Test MSE 6.087358052842519 Test RE 1.1792950725606854\n",
      "68 Train Loss 1.4678766 Test MSE 6.03918121250077 Test RE 1.1746191878543226\n",
      "69 Train Loss 1.4363222 Test MSE 5.918172130751851 Test RE 1.1627915217356801\n",
      "70 Train Loss 1.4058826 Test MSE 5.956256627564655 Test RE 1.1665269076746845\n",
      "71 Train Loss 1.374125 Test MSE 5.933992107615834 Test RE 1.16434462442853\n",
      "72 Train Loss 1.3569477 Test MSE 5.8819062782023845 Test RE 1.1592233231222777\n",
      "73 Train Loss 1.341781 Test MSE 5.883336832499935 Test RE 1.1593642834681843\n",
      "74 Train Loss 1.3136561 Test MSE 5.85183507960804 Test RE 1.1562562660356337\n",
      "75 Train Loss 1.2911103 Test MSE 5.882566865003204 Test RE 1.1592884164858006\n",
      "76 Train Loss 1.2808226 Test MSE 5.892713778438452 Test RE 1.1602878212716803\n",
      "77 Train Loss 1.2675894 Test MSE 5.864782437920567 Test RE 1.1575346848968198\n",
      "78 Train Loss 1.2328637 Test MSE 5.889833615703518 Test RE 1.160004231544392\n",
      "79 Train Loss 1.215911 Test MSE 5.8929761168743475 Test RE 1.1603136484810073\n",
      "80 Train Loss 1.1976571 Test MSE 5.891534128281093 Test RE 1.160171677651757\n",
      "81 Train Loss 1.1791157 Test MSE 5.907896871215269 Test RE 1.16178165120441\n",
      "82 Train Loss 1.1636347 Test MSE 5.867696227093994 Test RE 1.1578221971144882\n",
      "83 Train Loss 1.1479516 Test MSE 5.836682545560981 Test RE 1.1547583112521083\n",
      "84 Train Loss 1.1422119 Test MSE 5.825492485271797 Test RE 1.1536508315856782\n",
      "85 Train Loss 1.128396 Test MSE 5.7910163603206755 Test RE 1.150232027825604\n",
      "86 Train Loss 1.1176937 Test MSE 5.777561950159889 Test RE 1.1488950697045672\n",
      "87 Train Loss 1.1061392 Test MSE 5.782474825652081 Test RE 1.149383439979389\n",
      "88 Train Loss 1.0952854 Test MSE 5.7860316574612645 Test RE 1.1497368816487308\n",
      "89 Train Loss 1.0865022 Test MSE 5.779118142402939 Test RE 1.1490497873202248\n",
      "90 Train Loss 1.077069 Test MSE 5.764889896047414 Test RE 1.147634429623791\n",
      "91 Train Loss 1.0683414 Test MSE 5.753904287357271 Test RE 1.146540438677362\n",
      "92 Train Loss 1.053699 Test MSE 5.785353258140966 Test RE 1.149669477629076\n",
      "93 Train Loss 1.0420512 Test MSE 5.781645719760279 Test RE 1.1493010362705374\n",
      "94 Train Loss 1.0364735 Test MSE 5.764390332530863 Test RE 1.1475847037207285\n",
      "95 Train Loss 1.0320888 Test MSE 5.751042838440197 Test RE 1.1462553127246027\n",
      "96 Train Loss 1.0273304 Test MSE 5.754895288399947 Test RE 1.146639169364775\n",
      "97 Train Loss 1.0174229 Test MSE 5.762825817058552 Test RE 1.1474289599420093\n",
      "98 Train Loss 1.0128487 Test MSE 5.766242111090499 Test RE 1.147769016543731\n",
      "99 Train Loss 1.0039943 Test MSE 5.803463438757482 Test RE 1.1514675055434809\n",
      "Training time: 160.07\n",
      "0\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.79124 Test MSE 4.466952729358899 Test RE 1.010214827497553\n",
      "1 Train Loss 60.670235 Test MSE 5.42814384063254 Test RE 1.1136115689752653\n",
      "2 Train Loss 43.454224 Test MSE 6.141834576443549 Test RE 1.1845601484118373\n",
      "3 Train Loss 34.597378 Test MSE 6.201271372397155 Test RE 1.1902780606175414\n",
      "4 Train Loss 29.296278 Test MSE 6.087694838580175 Test RE 1.1793276946164473\n",
      "5 Train Loss 23.170101 Test MSE 5.612599692186457 Test RE 1.1323745350218923\n",
      "6 Train Loss 20.305836 Test MSE 5.1403993039437035 Test RE 1.0836935495552467\n",
      "7 Train Loss 17.415598 Test MSE 4.93917134958718 Test RE 1.0622704652068462\n",
      "8 Train Loss 14.200804 Test MSE 5.07795777092875 Test RE 1.077091510195293\n",
      "9 Train Loss 13.128324 Test MSE 5.074191046919631 Test RE 1.0766919539875512\n",
      "10 Train Loss 11.9219675 Test MSE 5.080253146199099 Test RE 1.0773349200463596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 11.230011 Test MSE 5.106894237469413 Test RE 1.0801560243886963\n",
      "12 Train Loss 10.6731205 Test MSE 5.355813993460985 Test RE 1.106167267346948\n",
      "13 Train Loss 9.895824 Test MSE 5.464960540470611 Test RE 1.1173817543706528\n",
      "14 Train Loss 9.392269 Test MSE 5.410898156835622 Test RE 1.1118411413836806\n",
      "15 Train Loss 8.999713 Test MSE 5.490081454656151 Test RE 1.119946957520264\n",
      "16 Train Loss 8.344322 Test MSE 5.2976281055181955 Test RE 1.1001421241485532\n",
      "17 Train Loss 7.670165 Test MSE 5.395491129901351 Test RE 1.1102570810813128\n",
      "18 Train Loss 7.2022257 Test MSE 5.230133765988778 Test RE 1.093111488059033\n",
      "19 Train Loss 6.497433 Test MSE 5.154156241402178 Test RE 1.085142692149299\n",
      "20 Train Loss 6.167639 Test MSE 4.964908585787733 Test RE 1.0650345303159223\n",
      "21 Train Loss 5.8341765 Test MSE 4.843275193018805 Test RE 1.0519076980709763\n",
      "22 Train Loss 5.5004115 Test MSE 4.8711178478324975 Test RE 1.0549269288911454\n",
      "23 Train Loss 5.290585 Test MSE 4.816989696170435 Test RE 1.0490493498417404\n",
      "24 Train Loss 5.091402 Test MSE 4.821774419762172 Test RE 1.0495702317265871\n",
      "25 Train Loss 4.9690213 Test MSE 4.738152022769392 Test RE 1.0404292560545325\n",
      "26 Train Loss 4.8170915 Test MSE 4.872145012021033 Test RE 1.0550381483359854\n",
      "27 Train Loss 4.672765 Test MSE 4.886317213402132 Test RE 1.0565714930456587\n",
      "28 Train Loss 4.5966816 Test MSE 4.921976049704229 Test RE 1.060419751435826\n",
      "29 Train Loss 4.430876 Test MSE 4.797536889937593 Test RE 1.0469289801239472\n",
      "30 Train Loss 4.2405415 Test MSE 4.752335485668252 Test RE 1.0419853334708125\n",
      "31 Train Loss 3.94397 Test MSE 4.911444769045336 Test RE 1.0592846831250744\n",
      "32 Train Loss 3.5738792 Test MSE 4.760096826836993 Test RE 1.0428358525947485\n",
      "33 Train Loss 3.31996 Test MSE 4.763101349964968 Test RE 1.043164914197185\n",
      "34 Train Loss 3.0694628 Test MSE 4.7359715465247385 Test RE 1.040189828073991\n",
      "35 Train Loss 2.959496 Test MSE 4.648655797202832 Test RE 1.0305563784318301\n",
      "36 Train Loss 2.789183 Test MSE 4.536144392423977 Test RE 1.0180087138827791\n",
      "37 Train Loss 2.6241205 Test MSE 4.542467995167304 Test RE 1.0187180432340621\n",
      "38 Train Loss 2.4464006 Test MSE 4.3926803035863715 Test RE 1.0017811571918502\n",
      "39 Train Loss 2.2966857 Test MSE 4.395010533239295 Test RE 1.002046834465568\n",
      "40 Train Loss 2.1394658 Test MSE 4.240146091519504 Test RE 0.9842342422078896\n",
      "41 Train Loss 2.0687156 Test MSE 4.2582544510857705 Test RE 0.9863336839134687\n",
      "42 Train Loss 1.9975321 Test MSE 4.185000073789674 Test RE 0.977812973820381\n",
      "43 Train Loss 1.9262167 Test MSE 4.162970826240458 Test RE 0.9752360437076727\n",
      "44 Train Loss 1.8130498 Test MSE 4.128980347793754 Test RE 0.9712465031515227\n",
      "45 Train Loss 1.7707323 Test MSE 4.0655063214746265 Test RE 0.9637521959613022\n",
      "46 Train Loss 1.7384043 Test MSE 4.02533462068535 Test RE 0.9589789063166096\n",
      "47 Train Loss 1.6899463 Test MSE 3.9986844405233293 Test RE 0.9557991207422529\n",
      "48 Train Loss 1.6059436 Test MSE 3.8955973565863555 Test RE 0.9433983047762748\n",
      "49 Train Loss 1.5529804 Test MSE 3.821357251685039 Test RE 0.9343656857948338\n",
      "50 Train Loss 1.5195132 Test MSE 3.9163969718561136 Test RE 0.9459134773548338\n",
      "51 Train Loss 1.4736042 Test MSE 3.912483648583373 Test RE 0.9454407736933021\n",
      "52 Train Loss 1.4086362 Test MSE 3.7956557367094916 Test RE 0.9312182269796914\n",
      "53 Train Loss 1.3173392 Test MSE 3.70317806855462 Test RE 0.9198041361229294\n",
      "54 Train Loss 1.2753462 Test MSE 3.666580427251864 Test RE 0.9152477463410547\n",
      "55 Train Loss 1.2222657 Test MSE 3.6387272092662952 Test RE 0.9117647744064014\n",
      "56 Train Loss 1.1549286 Test MSE 3.6184318965380977 Test RE 0.9092184958513574\n",
      "57 Train Loss 1.0960075 Test MSE 3.4777580222713746 Test RE 0.8913694406434715\n",
      "58 Train Loss 1.0439131 Test MSE 3.4191218207900893 Test RE 0.8838230986171901\n",
      "59 Train Loss 1.0085624 Test MSE 3.3853732383100565 Test RE 0.8794503754596951\n",
      "60 Train Loss 0.9631586 Test MSE 3.325401449298033 Test RE 0.8716258488170784\n",
      "61 Train Loss 0.922737 Test MSE 3.307500958276895 Test RE 0.8692767212669166\n",
      "62 Train Loss 0.8552498 Test MSE 3.2736142425180375 Test RE 0.8648122067954218\n",
      "63 Train Loss 0.82848 Test MSE 3.2185743159788367 Test RE 0.8575112589258859\n",
      "64 Train Loss 0.7930935 Test MSE 3.179095918752641 Test RE 0.8522360007803009\n",
      "65 Train Loss 0.7776303 Test MSE 3.164761942090656 Test RE 0.8503125401090035\n",
      "66 Train Loss 0.7640945 Test MSE 3.164249364670903 Test RE 0.8502436773216538\n",
      "67 Train Loss 0.7462694 Test MSE 3.1658114099273575 Test RE 0.8504535146452127\n",
      "68 Train Loss 0.7280061 Test MSE 3.123243472017588 Test RE 0.8447165064576172\n",
      "69 Train Loss 0.7037723 Test MSE 3.1201353221346437 Test RE 0.8442960846967533\n",
      "70 Train Loss 0.6875547 Test MSE 3.112829102212464 Test RE 0.8433069884505873\n",
      "71 Train Loss 0.6691232 Test MSE 3.0809172457050136 Test RE 0.8389731784624226\n",
      "72 Train Loss 0.6387916 Test MSE 3.104658209738852 Test RE 0.8421994592186942\n",
      "73 Train Loss 0.6303725 Test MSE 3.1015381322584177 Test RE 0.8417761617225347\n",
      "74 Train Loss 0.62149096 Test MSE 3.1129546464483515 Test RE 0.8433239940844562\n",
      "75 Train Loss 0.61451226 Test MSE 3.0953627215424917 Test RE 0.8409377223012597\n",
      "76 Train Loss 0.6039968 Test MSE 3.091774205796963 Test RE 0.8404501230016571\n",
      "77 Train Loss 0.59655774 Test MSE 3.086363363596703 Test RE 0.8397143748405417\n",
      "78 Train Loss 0.5843418 Test MSE 3.107655833535603 Test RE 0.842605943262013\n",
      "79 Train Loss 0.5720032 Test MSE 3.0989464791447907 Test RE 0.8414243930768057\n",
      "80 Train Loss 0.56014115 Test MSE 3.103616747029629 Test RE 0.8420581887725832\n",
      "81 Train Loss 0.5549074 Test MSE 3.1025951310062214 Test RE 0.8419195874224612\n",
      "82 Train Loss 0.5476295 Test MSE 3.1100384665682603 Test RE 0.8429288934532934\n",
      "83 Train Loss 0.5402337 Test MSE 3.098058542581839 Test RE 0.8413038383955794\n",
      "84 Train Loss 0.53153545 Test MSE 3.076338886405695 Test RE 0.8383495737984716\n",
      "85 Train Loss 0.52157897 Test MSE 3.1104167527729865 Test RE 0.8429801562720127\n",
      "86 Train Loss 0.5162916 Test MSE 3.095829794727529 Test RE 0.8410011663431641\n",
      "87 Train Loss 0.51212716 Test MSE 3.0814115737687247 Test RE 0.8390404816905639\n",
      "88 Train Loss 0.5088833 Test MSE 3.061993758442133 Test RE 0.8363926560339071\n",
      "89 Train Loss 0.5017121 Test MSE 3.0696770058897496 Test RE 0.837441349480849\n",
      "90 Train Loss 0.4950136 Test MSE 3.077619300306285 Test RE 0.8385240218707137\n",
      "91 Train Loss 0.48901588 Test MSE 3.104024359053638 Test RE 0.8421134826122849\n",
      "92 Train Loss 0.48271558 Test MSE 3.0944993279170907 Test RE 0.8408204321851382\n",
      "93 Train Loss 0.47817734 Test MSE 3.0838855729112358 Test RE 0.839377237897719\n",
      "94 Train Loss 0.47452754 Test MSE 3.091440070300446 Test RE 0.8404047070384915\n",
      "95 Train Loss 0.46841934 Test MSE 3.103367928345138 Test RE 0.8420244339588656\n",
      "96 Train Loss 0.46249267 Test MSE 3.102006521835209 Test RE 0.8418397212015081\n",
      "97 Train Loss 0.45278344 Test MSE 3.1047796494432314 Test RE 0.8422159305089818\n",
      "98 Train Loss 0.44717103 Test MSE 3.0945360938825 Test RE 0.8408254270938184\n",
      "99 Train Loss 0.4422747 Test MSE 3.105930584965422 Test RE 0.8423720199138861\n",
      "Training time: 158.88\n",
      "1\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 66.59589 Test MSE 5.5929635232205195 Test RE 1.1303919439567363\n",
      "1 Train Loss 52.188835 Test MSE 8.782442141850211 Test RE 1.416497162753879\n",
      "2 Train Loss 44.560715 Test MSE 9.118410002564879 Test RE 1.4433365791789423\n",
      "3 Train Loss 41.082848 Test MSE 9.58567744685039 Test RE 1.4798560278630677\n",
      "4 Train Loss 37.997505 Test MSE 9.938531974197902 Test RE 1.5068470767156017\n",
      "5 Train Loss 35.71868 Test MSE 9.952121271137397 Test RE 1.507876906748763\n",
      "6 Train Loss 33.41584 Test MSE 10.121838140555344 Test RE 1.5206797206971234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 32.16921 Test MSE 10.45760660575008 Test RE 1.545696453745453\n",
      "8 Train Loss 31.060581 Test MSE 9.92275173713838 Test RE 1.5056503280214804\n",
      "9 Train Loss 29.383574 Test MSE 10.21390545376557 Test RE 1.5275800468044787\n",
      "10 Train Loss 26.289062 Test MSE 9.933370413830833 Test RE 1.5064557366130316\n",
      "11 Train Loss 24.14902 Test MSE 9.716715802744552 Test RE 1.4899366751680303\n",
      "12 Train Loss 22.619627 Test MSE 9.716777762204403 Test RE 1.4899414255140475\n",
      "13 Train Loss 21.697834 Test MSE 9.669449716628709 Test RE 1.4863084262967123\n",
      "14 Train Loss 20.93428 Test MSE 9.56577676985328 Test RE 1.478319076609123\n",
      "15 Train Loss 20.376701 Test MSE 9.51623969288673 Test RE 1.474486316199844\n",
      "16 Train Loss 19.714653 Test MSE 9.539168038152917 Test RE 1.476261554794122\n",
      "17 Train Loss 19.118921 Test MSE 9.145608671648027 Test RE 1.445487590344398\n",
      "18 Train Loss 17.903599 Test MSE 8.210591787054815 Test RE 1.3696048666337608\n",
      "19 Train Loss 16.584045 Test MSE 8.13983034828594 Test RE 1.3636902547838297\n",
      "20 Train Loss 15.744766 Test MSE 7.906714072565938 Test RE 1.3440210702283957\n",
      "21 Train Loss 15.1168785 Test MSE 7.862691060573377 Test RE 1.3402742264736534\n",
      "22 Train Loss 14.751849 Test MSE 7.746113069702367 Test RE 1.3303011800270197\n",
      "23 Train Loss 14.454737 Test MSE 7.780876548830845 Test RE 1.333282941763788\n",
      "24 Train Loss 14.105009 Test MSE 7.649961137305187 Test RE 1.3220189326349745\n",
      "25 Train Loss 13.808386 Test MSE 7.545236047093791 Test RE 1.3129387786373006\n",
      "26 Train Loss 13.433641 Test MSE 7.573954222449141 Test RE 1.3154350157460424\n",
      "27 Train Loss 13.0956135 Test MSE 7.4511399584452045 Test RE 1.3047263121471893\n",
      "28 Train Loss 12.724955 Test MSE 7.287994999150976 Test RE 1.290363569590519\n",
      "29 Train Loss 12.4555 Test MSE 7.229849149610141 Test RE 1.2852058041423773\n",
      "30 Train Loss 11.881136 Test MSE 7.060110039424937 Test RE 1.2700294605924345\n",
      "31 Train Loss 11.499989 Test MSE 6.700776507706007 Test RE 1.2372875040819904\n",
      "32 Train Loss 10.694993 Test MSE 6.275307638590801 Test RE 1.1973622754297826\n",
      "33 Train Loss 9.641998 Test MSE 6.343568193341832 Test RE 1.2038569011925249\n",
      "34 Train Loss 9.207329 Test MSE 6.355555486226781 Test RE 1.2049938145026895\n",
      "35 Train Loss 9.011631 Test MSE 6.311973956512148 Test RE 1.20085524537474\n",
      "36 Train Loss 8.768791 Test MSE 6.464111921494035 Test RE 1.215241225380885\n",
      "37 Train Loss 8.520589 Test MSE 6.457385837464741 Test RE 1.214608815076652\n",
      "38 Train Loss 8.30359 Test MSE 6.411723875600732 Test RE 1.2103067788695778\n",
      "39 Train Loss 8.130007 Test MSE 6.443843404364001 Test RE 1.2133345074715731\n",
      "40 Train Loss 7.9492545 Test MSE 6.501877988884132 Test RE 1.2187860311767762\n",
      "41 Train Loss 7.8067245 Test MSE 6.5748810996017495 Test RE 1.2256091990898892\n",
      "42 Train Loss 7.715102 Test MSE 6.571058943118884 Test RE 1.2252529073885576\n",
      "43 Train Loss 7.530999 Test MSE 6.498770684332052 Test RE 1.2184947621023563\n",
      "44 Train Loss 7.3413887 Test MSE 6.607581098843597 Test RE 1.2286531866394301\n",
      "45 Train Loss 7.27967 Test MSE 6.610918821473648 Test RE 1.228963465524936\n",
      "46 Train Loss 7.1048317 Test MSE 6.483768352552437 Test RE 1.217087509429802\n",
      "47 Train Loss 7.042407 Test MSE 6.515977071604392 Test RE 1.2201067618639367\n",
      "48 Train Loss 6.8172216 Test MSE 6.080980715032039 Test RE 1.178677174469315\n",
      "49 Train Loss 5.311155 Test MSE 5.605363891802973 Test RE 1.1316443672680623\n",
      "50 Train Loss 4.56785 Test MSE 5.5277804602639735 Test RE 1.1237855758287174\n",
      "51 Train Loss 4.3095016 Test MSE 5.509743613756582 Test RE 1.1219506522348046\n",
      "52 Train Loss 3.9124472 Test MSE 5.483988297918959 Test RE 1.1193252994572929\n",
      "53 Train Loss 3.6405911 Test MSE 5.60318557784051 Test RE 1.1314244603797905\n",
      "54 Train Loss 3.4970236 Test MSE 5.65529814766677 Test RE 1.1366737044152284\n",
      "55 Train Loss 3.404132 Test MSE 5.730764034898279 Test RE 1.1442326175387503\n",
      "56 Train Loss 3.218191 Test MSE 5.639582607545161 Test RE 1.1350932511643037\n",
      "57 Train Loss 3.1844199 Test MSE 5.6810910835835955 Test RE 1.139262851652326\n",
      "58 Train Loss 3.100673 Test MSE 5.702245390821031 Test RE 1.141381980048102\n",
      "59 Train Loss 3.0519476 Test MSE 5.829623059038172 Test RE 1.1540597579959222\n",
      "60 Train Loss 3.0319242 Test MSE 5.849922413426165 Test RE 1.1560672900164595\n",
      "61 Train Loss 2.958204 Test MSE 5.8775797491751955 Test RE 1.1587969021840485\n",
      "62 Train Loss 2.9024317 Test MSE 5.8586853190873835 Test RE 1.156932832921858\n",
      "63 Train Loss 2.8284461 Test MSE 5.83423503116371 Test RE 1.154516171653009\n",
      "64 Train Loss 2.7790396 Test MSE 5.8892962916091465 Test RE 1.1599513172788773\n",
      "65 Train Loss 2.7443163 Test MSE 5.8759729947913595 Test RE 1.1586385011630085\n",
      "66 Train Loss 2.7124422 Test MSE 5.880757149396959 Test RE 1.1591100807551165\n",
      "67 Train Loss 2.6858826 Test MSE 5.901542396410508 Test RE 1.1611566827427406\n",
      "68 Train Loss 2.6413448 Test MSE 5.8912659819763356 Test RE 1.1601452754209167\n",
      "69 Train Loss 2.5985181 Test MSE 5.882066055454606 Test RE 1.1592390676998616\n",
      "70 Train Loss 2.5486622 Test MSE 5.805772492130018 Test RE 1.151696552864977\n",
      "71 Train Loss 2.52612 Test MSE 5.857074701088049 Test RE 1.156773795115028\n",
      "72 Train Loss 2.5055053 Test MSE 5.825590864321716 Test RE 1.153660572787291\n",
      "73 Train Loss 2.470482 Test MSE 5.825438319903018 Test RE 1.1536454682564703\n",
      "74 Train Loss 2.4346664 Test MSE 5.802572645448472 Test RE 1.1513791308234864\n",
      "75 Train Loss 2.4040875 Test MSE 5.843562356386476 Test RE 1.1554386788203093\n",
      "76 Train Loss 2.3706775 Test MSE 5.872107078504867 Test RE 1.1582572931114887\n",
      "77 Train Loss 2.3501854 Test MSE 5.903771325359103 Test RE 1.161375938256026\n",
      "78 Train Loss 2.3258243 Test MSE 5.886903979973749 Test RE 1.1597156994087858\n",
      "79 Train Loss 2.2900417 Test MSE 5.948643397134907 Test RE 1.1657811475071962\n",
      "80 Train Loss 2.272097 Test MSE 5.989844023794291 Test RE 1.1698113129761714\n",
      "81 Train Loss 2.250159 Test MSE 5.991678794121969 Test RE 1.1699904637804164\n",
      "82 Train Loss 2.223355 Test MSE 5.992653238888002 Test RE 1.1700855994487795\n",
      "83 Train Loss 2.2050133 Test MSE 5.974149441708389 Test RE 1.1682777386542809\n",
      "84 Train Loss 2.1795926 Test MSE 5.953242661885818 Test RE 1.1662317292456683\n",
      "85 Train Loss 2.1592178 Test MSE 5.971016372436773 Test RE 1.1679713540262697\n",
      "86 Train Loss 2.1474557 Test MSE 5.950935071734015 Test RE 1.1660056805319536\n",
      "87 Train Loss 2.1349256 Test MSE 5.947363043600391 Test RE 1.1656556825703117\n",
      "88 Train Loss 2.1231813 Test MSE 5.935226938221508 Test RE 1.1644657649323946\n",
      "89 Train Loss 2.109585 Test MSE 5.902919423450182 Test RE 1.1612921431682655\n",
      "90 Train Loss 2.0921571 Test MSE 5.851663217385206 Test RE 1.1562392868976032\n",
      "91 Train Loss 2.0782125 Test MSE 5.837089704947332 Test RE 1.1547985877689813\n",
      "92 Train Loss 2.0636253 Test MSE 5.881164950587592 Test RE 1.1591502693111706\n",
      "93 Train Loss 2.0431874 Test MSE 5.854281930770276 Test RE 1.1564979757956413\n",
      "94 Train Loss 2.010183 Test MSE 5.862854505030697 Test RE 1.1573444107778095\n",
      "95 Train Loss 1.9854829 Test MSE 5.81185618397082 Test RE 1.152299808710807\n",
      "96 Train Loss 1.9673035 Test MSE 5.7693873417103125 Test RE 1.1480820025445173\n",
      "97 Train Loss 1.9533503 Test MSE 5.793434750746975 Test RE 1.150472177360133\n",
      "98 Train Loss 1.9416457 Test MSE 5.798010720772369 Test RE 1.1509264404426678\n",
      "99 Train Loss 1.9243264 Test MSE 5.788700308563363 Test RE 1.1500019936523471\n",
      "Training time: 158.81\n",
      "2\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 52.824497 Test MSE 7.696880805110013 Test RE 1.3260669185090879\n",
      "1 Train Loss 41.056297 Test MSE 8.469044942275367 Test RE 1.3909940716090314\n",
      "2 Train Loss 33.586586 Test MSE 6.593915483504982 Test RE 1.2273819958754075\n",
      "3 Train Loss 27.605576 Test MSE 6.79805889828451 Test RE 1.246236657744719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 21.406174 Test MSE 6.0107481885829905 Test RE 1.1718508176658127\n",
      "5 Train Loss 17.04336 Test MSE 5.923284318627447 Test RE 1.163293629939807\n",
      "6 Train Loss 14.564579 Test MSE 5.976362772182029 Test RE 1.168494133079283\n",
      "7 Train Loss 13.460968 Test MSE 5.755967884577421 Test RE 1.1467460195703374\n",
      "8 Train Loss 12.3206835 Test MSE 6.038223250270838 Test RE 1.1745260224563026\n",
      "9 Train Loss 11.275765 Test MSE 5.9346939493848625 Test RE 1.1644134787103066\n",
      "10 Train Loss 10.686258 Test MSE 5.944061789076915 Test RE 1.165332122345541\n",
      "11 Train Loss 10.11459 Test MSE 5.841685170268504 Test RE 1.1552530773383693\n",
      "12 Train Loss 9.529783 Test MSE 5.7918856394458125 Test RE 1.1503183542240445\n",
      "13 Train Loss 9.036809 Test MSE 5.648313327597164 Test RE 1.1359715385784774\n",
      "14 Train Loss 8.397211 Test MSE 5.37001291872358 Test RE 1.1076325899159463\n",
      "15 Train Loss 7.915143 Test MSE 5.372167115089919 Test RE 1.1078547326641102\n",
      "16 Train Loss 7.6526213 Test MSE 5.274544643367661 Test RE 1.097742671729017\n",
      "17 Train Loss 7.1468034 Test MSE 5.259030916653987 Test RE 1.0961271179872911\n",
      "18 Train Loss 6.854994 Test MSE 5.094973812083307 Test RE 1.0788946470069891\n",
      "19 Train Loss 6.643624 Test MSE 4.88341503747552 Test RE 1.0562576767643381\n",
      "20 Train Loss 6.493882 Test MSE 4.8476249584160875 Test RE 1.0523799533790583\n",
      "21 Train Loss 6.3827715 Test MSE 4.735686912499469 Test RE 1.0401585696654922\n",
      "22 Train Loss 6.2764573 Test MSE 4.736257038469922 Test RE 1.0402211797553937\n",
      "23 Train Loss 6.1897535 Test MSE 4.728583164747629 Test RE 1.039378134082812\n",
      "24 Train Loss 6.141217 Test MSE 4.689532338239437 Test RE 1.0350774036732329\n",
      "25 Train Loss 6.0869293 Test MSE 4.716669492165253 Test RE 1.0380679509036388\n",
      "26 Train Loss 6.0041027 Test MSE 4.63970125063464 Test RE 1.0295633372448152\n",
      "27 Train Loss 5.900031 Test MSE 4.637325629922302 Test RE 1.0292997248894007\n",
      "28 Train Loss 5.855568 Test MSE 4.653975692003937 Test RE 1.0311458912000775\n",
      "29 Train Loss 5.8060746 Test MSE 4.574839331233677 Test RE 1.0223414832328008\n",
      "30 Train Loss 5.71835 Test MSE 4.571315349202815 Test RE 1.0219476544213466\n",
      "31 Train Loss 5.647224 Test MSE 4.553186596081227 Test RE 1.0199192402901598\n",
      "32 Train Loss 5.596128 Test MSE 4.488039705412309 Test RE 1.0125964616896825\n",
      "33 Train Loss 5.552805 Test MSE 4.486793390743099 Test RE 1.012455854483248\n",
      "34 Train Loss 5.50576 Test MSE 4.495900148881315 Test RE 1.0134828147219919\n",
      "35 Train Loss 5.4596148 Test MSE 4.478024225113535 Test RE 1.0114659787945677\n",
      "36 Train Loss 5.4190435 Test MSE 4.493253392236952 Test RE 1.0131844498570381\n",
      "37 Train Loss 5.3494415 Test MSE 4.4208405111692635 Test RE 1.004987092475642\n",
      "38 Train Loss 5.2869663 Test MSE 4.330674033536871 Test RE 0.9946855485181239\n",
      "39 Train Loss 5.1695466 Test MSE 4.3727897092108154 Test RE 0.9995104899277971\n",
      "40 Train Loss 5.1358576 Test MSE 4.319851616172401 Test RE 0.9934419042381115\n",
      "41 Train Loss 5.049536 Test MSE 4.336948600396122 Test RE 0.9954058707927418\n",
      "42 Train Loss 4.9762764 Test MSE 4.324060782290299 Test RE 0.9939257801053706\n",
      "43 Train Loss 4.902266 Test MSE 4.265647559867381 Test RE 0.98718954045699\n",
      "44 Train Loss 4.7878523 Test MSE 4.262308776758694 Test RE 0.9868031211703693\n",
      "45 Train Loss 4.6243496 Test MSE 4.2040328962162805 Test RE 0.9800339330538305\n",
      "46 Train Loss 4.51138 Test MSE 4.208100805554743 Test RE 0.9805079689798349\n",
      "47 Train Loss 4.2933393 Test MSE 4.158767340096318 Test RE 0.9747435556849539\n",
      "48 Train Loss 4.219818 Test MSE 4.130305437531131 Test RE 0.9714023389058125\n",
      "49 Train Loss 4.0409594 Test MSE 4.160929540928681 Test RE 0.9749969141064291\n",
      "50 Train Loss 3.9145684 Test MSE 4.078304340211241 Test RE 0.9652679268606971\n",
      "51 Train Loss 3.7382932 Test MSE 4.0939929656423315 Test RE 0.9671227652587984\n",
      "52 Train Loss 3.4777963 Test MSE 4.021024735492265 Test RE 0.9584653843010229\n",
      "53 Train Loss 3.3875265 Test MSE 4.026797893675295 Test RE 0.9591531925016366\n",
      "54 Train Loss 3.3102584 Test MSE 4.043415784771324 Test RE 0.9611302836158334\n",
      "55 Train Loss 3.1922917 Test MSE 4.02569001949023 Test RE 0.9590212397456115\n",
      "56 Train Loss 3.0602264 Test MSE 3.972057510409928 Test RE 0.9526115091903862\n",
      "57 Train Loss 2.9616828 Test MSE 3.8110333679946136 Test RE 0.933102678176086\n",
      "58 Train Loss 2.8330095 Test MSE 3.7497890798631763 Test RE 0.9255747113652106\n",
      "59 Train Loss 2.779141 Test MSE 3.7295745032208285 Test RE 0.9230765195190694\n",
      "60 Train Loss 2.7206643 Test MSE 3.6589642221716523 Test RE 0.9142966778560232\n",
      "61 Train Loss 2.65624 Test MSE 3.604594574430799 Test RE 0.907478349765123\n",
      "62 Train Loss 2.5696197 Test MSE 3.564761470871569 Test RE 0.9024503087788541\n",
      "63 Train Loss 2.553972 Test MSE 3.522810614547634 Test RE 0.8971244818388192\n",
      "64 Train Loss 2.4911025 Test MSE 3.429033976043992 Test RE 0.8851032886922546\n",
      "65 Train Loss 2.4641182 Test MSE 3.4359101344178304 Test RE 0.8859902822895471\n",
      "66 Train Loss 2.4048772 Test MSE 3.3400808493650227 Test RE 0.8735475499349815\n",
      "67 Train Loss 2.3510973 Test MSE 3.295796425766895 Test RE 0.8677372666975348\n",
      "68 Train Loss 2.3145616 Test MSE 3.3225935004773857 Test RE 0.8712577733096122\n",
      "69 Train Loss 2.269246 Test MSE 3.299111180231525 Test RE 0.8681735213611409\n",
      "70 Train Loss 2.230066 Test MSE 3.2710009978010532 Test RE 0.8644669588581466\n",
      "71 Train Loss 2.2025533 Test MSE 3.249634725032945 Test RE 0.8616389716264796\n",
      "72 Train Loss 2.1726706 Test MSE 3.226238246148316 Test RE 0.8585315862865515\n",
      "73 Train Loss 2.1501484 Test MSE 3.1428954300369756 Test RE 0.8473698862375706\n",
      "74 Train Loss 2.110347 Test MSE 3.092310364934438 Test RE 0.8405229930511695\n",
      "75 Train Loss 2.0355814 Test MSE 3.028697795185101 Test RE 0.8318327807427996\n",
      "76 Train Loss 1.9893143 Test MSE 2.9591293944043513 Test RE 0.8222237898501847\n",
      "77 Train Loss 1.9470798 Test MSE 2.9211840826224633 Test RE 0.8169350377689727\n",
      "78 Train Loss 1.9136236 Test MSE 2.83865744576624 Test RE 0.8053127108469241\n",
      "79 Train Loss 1.869481 Test MSE 2.7596641274121785 Test RE 0.7940286528642714\n",
      "80 Train Loss 1.8182491 Test MSE 2.73763675827645 Test RE 0.7908533744587605\n",
      "81 Train Loss 1.7973024 Test MSE 2.7049198691437257 Test RE 0.7861135140868801\n",
      "82 Train Loss 1.7619787 Test MSE 2.6841746475913326 Test RE 0.7830931865379281\n",
      "83 Train Loss 1.7179327 Test MSE 2.6214722238382944 Test RE 0.7738925938881316\n",
      "84 Train Loss 1.6869409 Test MSE 2.5732824351346872 Test RE 0.7667464750237009\n",
      "85 Train Loss 1.6550621 Test MSE 2.4998861918902326 Test RE 0.7557326389484254\n",
      "86 Train Loss 1.6252315 Test MSE 2.4287432171971215 Test RE 0.7449015203141791\n",
      "87 Train Loss 1.5952232 Test MSE 2.3782473103097397 Test RE 0.7371172376743126\n",
      "88 Train Loss 1.5819921 Test MSE 2.390996599954873 Test RE 0.739090363001447\n",
      "89 Train Loss 1.5584817 Test MSE 2.395218642832405 Test RE 0.7397426213273319\n",
      "90 Train Loss 1.533334 Test MSE 2.357532801223117 Test RE 0.7339000752927756\n",
      "91 Train Loss 1.5153883 Test MSE 2.3561229063957985 Test RE 0.7336805923090207\n",
      "92 Train Loss 1.4934504 Test MSE 2.319895823570984 Test RE 0.7280183094083543\n",
      "93 Train Loss 1.4815261 Test MSE 2.307132030665983 Test RE 0.7260128117111063\n",
      "94 Train Loss 1.4513954 Test MSE 2.270051285749402 Test RE 0.7201548581790909\n",
      "95 Train Loss 1.4201214 Test MSE 2.218092907345198 Test RE 0.7118654690672651\n",
      "96 Train Loss 1.4051783 Test MSE 2.20574112264742 Test RE 0.7098806369168174\n",
      "97 Train Loss 1.3905685 Test MSE 2.196730733672294 Test RE 0.7084292321824089\n",
      "98 Train Loss 1.3658917 Test MSE 2.19990866001207 Test RE 0.7089414757269539\n",
      "99 Train Loss 1.354374 Test MSE 2.1990859181138314 Test RE 0.7088088951314527\n",
      "Training time: 159.93\n",
      "3\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.48028 Test MSE 5.421303468292476 Test RE 1.1129096790338104\n",
      "1 Train Loss 50.49684 Test MSE 8.764680930788659 Test RE 1.4150641081716522\n",
      "2 Train Loss 37.54875 Test MSE 9.565010605994205 Test RE 1.4782598729837284\n",
      "3 Train Loss 32.882557 Test MSE 9.070915210180296 Test RE 1.4395727393626327\n",
      "4 Train Loss 28.315645 Test MSE 8.615203379838944 Test RE 1.4029455874083938\n",
      "5 Train Loss 26.037083 Test MSE 9.727729301811184 Test RE 1.4907808271066856\n",
      "6 Train Loss 23.558655 Test MSE 9.543347268061094 Test RE 1.476584903791461\n",
      "7 Train Loss 22.115345 Test MSE 10.046412666096249 Test RE 1.515003258424673\n",
      "8 Train Loss 21.070255 Test MSE 9.711958403899283 Test RE 1.4895718867461945\n",
      "9 Train Loss 20.351627 Test MSE 9.746330707391968 Test RE 1.4922054851098396\n",
      "10 Train Loss 19.719994 Test MSE 9.976840513610862 Test RE 1.5097483900930313\n",
      "11 Train Loss 19.215149 Test MSE 10.07210124327722 Test RE 1.5169389459566254\n",
      "12 Train Loss 18.484686 Test MSE 9.905930789135162 Test RE 1.5043736051451566\n",
      "13 Train Loss 17.767105 Test MSE 9.640396232613018 Test RE 1.4840738149477941\n",
      "14 Train Loss 17.014687 Test MSE 9.49846381924377 Test RE 1.4731085380742326\n",
      "15 Train Loss 15.075595 Test MSE 8.595995662463237 Test RE 1.4013807712452233\n",
      "16 Train Loss 13.510962 Test MSE 8.387923072524185 Test RE 1.3843161311842214\n",
      "17 Train Loss 12.933653 Test MSE 8.433203508502825 Test RE 1.3880475716428227\n",
      "18 Train Loss 12.428474 Test MSE 8.21531390681537 Test RE 1.3699986572850882\n",
      "19 Train Loss 11.964485 Test MSE 7.975169168128332 Test RE 1.3498266935228571\n",
      "20 Train Loss 11.444201 Test MSE 7.558391334842653 Test RE 1.3140828492343086\n",
      "21 Train Loss 10.833767 Test MSE 7.171346750942286 Test RE 1.2799954366898796\n",
      "22 Train Loss 10.064629 Test MSE 6.707140534964468 Test RE 1.2378749182926456\n",
      "23 Train Loss 8.696115 Test MSE 6.355949187591829 Test RE 1.2050311362099726\n",
      "24 Train Loss 7.9138327 Test MSE 6.127702403348871 Test RE 1.1831965452622537\n",
      "25 Train Loss 7.2494836 Test MSE 5.885868569392655 Test RE 1.1596137073672603\n",
      "26 Train Loss 6.843379 Test MSE 5.861987906974171 Test RE 1.157258873137314\n",
      "27 Train Loss 6.3293 Test MSE 6.000995554041586 Test RE 1.1708997486807304\n",
      "28 Train Loss 5.9839535 Test MSE 6.009624568972963 Test RE 1.171741282541546\n",
      "29 Train Loss 5.7047577 Test MSE 5.885241691632868 Test RE 1.159551953066154\n",
      "30 Train Loss 5.4390593 Test MSE 5.931795605500956 Test RE 1.1641291099743056\n",
      "31 Train Loss 5.273664 Test MSE 5.946829622378367 Test RE 1.1656034073504566\n",
      "32 Train Loss 5.1751385 Test MSE 5.985035912873453 Test RE 1.1693417087838034\n",
      "33 Train Loss 5.054464 Test MSE 5.947563680796884 Test RE 1.16567534438632\n",
      "34 Train Loss 4.8576765 Test MSE 5.897554506926007 Test RE 1.1607642982829651\n",
      "35 Train Loss 4.6176224 Test MSE 5.941311814032832 Test RE 1.1650625251320585\n",
      "36 Train Loss 4.319537 Test MSE 5.823558176912244 Test RE 1.153459285401106\n",
      "37 Train Loss 4.0197916 Test MSE 5.779442147845735 Test RE 1.1490819975258215\n",
      "38 Train Loss 3.6534233 Test MSE 5.556286692473345 Test RE 1.1266794768023265\n",
      "39 Train Loss 3.2318788 Test MSE 5.309212324621254 Test RE 1.1013442968797407\n",
      "40 Train Loss 2.9422913 Test MSE 5.307595461986886 Test RE 1.1011765829206963\n",
      "41 Train Loss 2.7416053 Test MSE 5.285198590038995 Test RE 1.098850766631946\n",
      "42 Train Loss 2.489199 Test MSE 5.124589674954681 Test RE 1.0820257815968646\n",
      "43 Train Loss 2.3206744 Test MSE 5.199101657961677 Test RE 1.0898637680127452\n",
      "44 Train Loss 2.1970167 Test MSE 5.209813560682096 Test RE 1.0909859337498868\n",
      "45 Train Loss 2.0439334 Test MSE 5.233843056362921 Test RE 1.0934990449981754\n",
      "46 Train Loss 1.9394115 Test MSE 5.21736203101127 Test RE 1.0917760094409317\n",
      "47 Train Loss 1.8782218 Test MSE 5.226353961328084 Test RE 1.0927164221914114\n",
      "48 Train Loss 1.8302736 Test MSE 5.249021330085764 Test RE 1.0950834841780952\n",
      "49 Train Loss 1.7818005 Test MSE 5.307183740791058 Test RE 1.1011338718158759\n",
      "50 Train Loss 1.7341816 Test MSE 5.308693694026618 Test RE 1.1012905031376046\n",
      "51 Train Loss 1.7032621 Test MSE 5.316939286732863 Test RE 1.102145446940331\n",
      "52 Train Loss 1.6640577 Test MSE 5.376593606748938 Test RE 1.1083110568884662\n",
      "53 Train Loss 1.6366178 Test MSE 5.401755251845717 Test RE 1.1109013939099712\n",
      "54 Train Loss 1.5927432 Test MSE 5.442955403081718 Test RE 1.1151298679787218\n",
      "55 Train Loss 1.5608795 Test MSE 5.452433396324293 Test RE 1.1161003514250818\n",
      "56 Train Loss 1.515705 Test MSE 5.457280469851478 Test RE 1.1165963335224418\n",
      "57 Train Loss 1.4828087 Test MSE 5.513566097271104 Test RE 1.122339771457122\n",
      "58 Train Loss 1.4511024 Test MSE 5.508356867453909 Test RE 1.121809451578408\n",
      "59 Train Loss 1.4145364 Test MSE 5.528356466281658 Test RE 1.123844124680025\n",
      "60 Train Loss 1.3970503 Test MSE 5.493043200677527 Test RE 1.1202490068829682\n",
      "61 Train Loss 1.3711406 Test MSE 5.527392114609219 Test RE 1.123746100227831\n",
      "62 Train Loss 1.3511419 Test MSE 5.536208237321731 Test RE 1.1246419237952627\n",
      "63 Train Loss 1.3276374 Test MSE 5.556244867727442 Test RE 1.126675236274964\n",
      "64 Train Loss 1.301785 Test MSE 5.556229990623478 Test RE 1.1266737279112897\n",
      "65 Train Loss 1.2746233 Test MSE 5.50956954016563 Test RE 1.1219329287675066\n",
      "66 Train Loss 1.2494864 Test MSE 5.523255671765077 Test RE 1.1233255419076469\n",
      "67 Train Loss 1.2358924 Test MSE 5.542822909592435 Test RE 1.1253135853984255\n",
      "68 Train Loss 1.2143608 Test MSE 5.558922675362581 Test RE 1.126946701644075\n",
      "69 Train Loss 1.2019944 Test MSE 5.582712658663859 Test RE 1.1293555695043973\n",
      "70 Train Loss 1.1914247 Test MSE 5.590330370093315 Test RE 1.1301258197916202\n",
      "71 Train Loss 1.1824355 Test MSE 5.602275360348337 Test RE 1.1313325587153213\n",
      "72 Train Loss 1.1753033 Test MSE 5.600998719147341 Test RE 1.1312036478751084\n",
      "73 Train Loss 1.1672146 Test MSE 5.601466177207107 Test RE 1.131250851887842\n",
      "74 Train Loss 1.1597074 Test MSE 5.603691937707018 Test RE 1.131475582637649\n",
      "75 Train Loss 1.1517627 Test MSE 5.6164793376821995 Test RE 1.1327658379009582\n",
      "76 Train Loss 1.1416984 Test MSE 5.604935805431476 Test RE 1.1316011541252569\n",
      "77 Train Loss 1.1341097 Test MSE 5.631267013508348 Test RE 1.1342560919851872\n",
      "78 Train Loss 1.126072 Test MSE 5.618408235771687 Test RE 1.1329603371736046\n",
      "79 Train Loss 1.1168933 Test MSE 5.606651561893872 Test RE 1.1317743410714147\n",
      "80 Train Loss 1.1053993 Test MSE 5.61780869904007 Test RE 1.1328998868262212\n",
      "81 Train Loss 1.0939593 Test MSE 5.659743550454904 Test RE 1.137120363435521\n",
      "82 Train Loss 1.0879102 Test MSE 5.659802279996915 Test RE 1.1371262632068022\n",
      "83 Train Loss 1.0841768 Test MSE 5.669659040988782 Test RE 1.1381160067993006\n",
      "84 Train Loss 1.0767596 Test MSE 5.678187722979606 Test RE 1.1389717003976672\n",
      "85 Train Loss 1.0650785 Test MSE 5.696291855908227 Test RE 1.1407859839442576\n",
      "86 Train Loss 1.0547401 Test MSE 5.709604783403523 Test RE 1.1421182838198265\n",
      "87 Train Loss 1.0482578 Test MSE 5.738107988846399 Test RE 1.144965547838835\n",
      "88 Train Loss 1.0399382 Test MSE 5.705860722229188 Test RE 1.1417437515942215\n",
      "89 Train Loss 1.034088 Test MSE 5.721354024137903 Test RE 1.1432928069996906\n",
      "90 Train Loss 1.0261757 Test MSE 5.731643116625427 Test RE 1.1443203750705573\n",
      "91 Train Loss 1.0176884 Test MSE 5.749130711240355 Test RE 1.146064741358983\n",
      "92 Train Loss 1.0111765 Test MSE 5.737707756364338 Test RE 1.1449256165239294\n",
      "93 Train Loss 1.0048009 Test MSE 5.753998905152189 Test RE 1.1465498655531579\n",
      "94 Train Loss 0.9978683 Test MSE 5.754225799362526 Test RE 1.146572470959081\n",
      "95 Train Loss 0.9902151 Test MSE 5.7577152433914 Test RE 1.1469200671636013\n",
      "96 Train Loss 0.9840665 Test MSE 5.765826509797125 Test RE 1.147727653132858\n",
      "97 Train Loss 0.9787339 Test MSE 5.771334483197441 Test RE 1.1482757223783\n",
      "98 Train Loss 0.97355 Test MSE 5.7894528426466865 Test RE 1.1500767416549809\n",
      "99 Train Loss 0.9665748 Test MSE 5.827775724827882 Test RE 1.153876889998059\n",
      "Training time: 159.89\n",
      "4\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.799793 Test MSE 8.268086794097831 Test RE 1.374391858211649\n",
      "1 Train Loss 50.239075 Test MSE 7.3522026130222295 Test RE 1.2960351901463858\n",
      "2 Train Loss 43.363613 Test MSE 7.721545125584559 Test RE 1.3281898810767785\n",
      "3 Train Loss 35.96199 Test MSE 7.60601845275276 Test RE 1.318216512958058\n",
      "4 Train Loss 33.022823 Test MSE 7.189343685692668 Test RE 1.2816005438406326\n",
      "5 Train Loss 27.681797 Test MSE 6.413246654627921 Test RE 1.210450493758005\n",
      "6 Train Loss 22.41806 Test MSE 6.048308501766351 Test RE 1.1755064804332458\n",
      "7 Train Loss 19.399197 Test MSE 6.201271991005928 Test RE 1.1902781199857246\n",
      "8 Train Loss 16.040186 Test MSE 6.212178831531181 Test RE 1.1913243948777261\n",
      "9 Train Loss 14.032672 Test MSE 6.013434457198701 Test RE 1.1721126448415036\n",
      "10 Train Loss 12.175838 Test MSE 6.251590940769266 Test RE 1.1950974971224133\n",
      "11 Train Loss 11.173595 Test MSE 6.1173341147228815 Test RE 1.182195116323251\n",
      "12 Train Loss 10.113602 Test MSE 5.793997809285462 Test RE 1.150528082662603\n",
      "13 Train Loss 9.509346 Test MSE 5.5446333341012215 Test RE 1.1254973481667454\n",
      "14 Train Loss 8.987872 Test MSE 5.401111158204046 Test RE 1.1108351611928589\n",
      "15 Train Loss 8.336002 Test MSE 5.373528600842638 Test RE 1.107995107381543\n",
      "16 Train Loss 7.753744 Test MSE 5.199491474770346 Test RE 1.0899046249992648\n",
      "17 Train Loss 7.021038 Test MSE 4.413277909246215 Test RE 1.0041271235973246\n",
      "18 Train Loss 5.8657455 Test MSE 4.1171702964416115 Test RE 0.9698564886612674\n",
      "19 Train Loss 4.9454308 Test MSE 4.12453025863476 Test RE 0.9707229721142984\n",
      "20 Train Loss 4.6364074 Test MSE 4.078180153128734 Test RE 0.96525323022329\n",
      "21 Train Loss 4.0980835 Test MSE 4.2201277699758055 Test RE 0.9819081398772025\n",
      "22 Train Loss 3.8548489 Test MSE 4.108617281409549 Test RE 0.96884857435084\n",
      "23 Train Loss 3.6092381 Test MSE 4.012651769633355 Test RE 0.95746695970361\n",
      "24 Train Loss 3.47445 Test MSE 4.0009821540105 Test RE 0.9560736906873417\n",
      "25 Train Loss 3.3133051 Test MSE 3.8762889155543694 Test RE 0.9410574342728748\n",
      "26 Train Loss 3.2171867 Test MSE 3.837045549426046 Test RE 0.9362817056749667\n",
      "27 Train Loss 3.0104852 Test MSE 3.7944768158484714 Test RE 0.9310735987613624\n",
      "28 Train Loss 2.940413 Test MSE 3.779398915663327 Test RE 0.9292218798840312\n",
      "29 Train Loss 2.822744 Test MSE 3.676267946249758 Test RE 0.9164560426365232\n",
      "30 Train Loss 2.7535357 Test MSE 3.707980151221674 Test RE 0.9204003192419782\n",
      "31 Train Loss 2.6091735 Test MSE 3.6066816514044877 Test RE 0.9077410288338451\n",
      "32 Train Loss 2.532115 Test MSE 3.508298531289528 Test RE 0.8952747399345897\n",
      "33 Train Loss 2.4408996 Test MSE 3.461443920675701 Test RE 0.8892762838485552\n",
      "34 Train Loss 2.3697486 Test MSE 3.3993866062623463 Test RE 0.8812686881913869\n",
      "35 Train Loss 2.2541552 Test MSE 3.293053683535583 Test RE 0.8673761286451637\n",
      "36 Train Loss 2.1805263 Test MSE 3.235382509258818 Test RE 0.8597474115194722\n",
      "37 Train Loss 2.1172447 Test MSE 3.187056442557543 Test RE 0.8533023421994338\n",
      "38 Train Loss 2.0402133 Test MSE 3.120326957131073 Test RE 0.8443220121287723\n",
      "39 Train Loss 1.9759594 Test MSE 3.094363697777461 Test RE 0.8408020056433709\n",
      "40 Train Loss 1.9472015 Test MSE 3.0409722174124147 Test RE 0.8335166633170326\n",
      "41 Train Loss 1.9076413 Test MSE 2.992899096236586 Test RE 0.8269021056582082\n",
      "42 Train Loss 1.8394947 Test MSE 2.8947710043544674 Test RE 0.8132333253296131\n",
      "43 Train Loss 1.7595221 Test MSE 2.8135867871788096 Test RE 0.8017486146819077\n",
      "44 Train Loss 1.7477685 Test MSE 2.802545539959155 Test RE 0.8001739331272701\n",
      "45 Train Loss 1.7039642 Test MSE 2.7268340161521976 Test RE 0.7892914744409681\n",
      "46 Train Loss 1.6770977 Test MSE 2.709011470158428 Test RE 0.7867078472981625\n",
      "47 Train Loss 1.6399455 Test MSE 2.6290148153077064 Test RE 0.7750051296106742\n",
      "48 Train Loss 1.6117882 Test MSE 2.589989528405428 Test RE 0.7692315072633147\n",
      "49 Train Loss 1.5855457 Test MSE 2.494088521534488 Test RE 0.7548557926263141\n",
      "50 Train Loss 1.5647672 Test MSE 2.4978141910598888 Test RE 0.7554193840370635\n",
      "51 Train Loss 1.533091 Test MSE 2.4124059934822886 Test RE 0.7423919596258591\n",
      "52 Train Loss 1.4698439 Test MSE 2.2296351669403816 Test RE 0.7137152280800347\n",
      "53 Train Loss 1.4484755 Test MSE 2.216628649120407 Test RE 0.7116304638185752\n",
      "54 Train Loss 1.3965198 Test MSE 2.15550883053129 Test RE 0.7017508760487258\n",
      "55 Train Loss 1.3740067 Test MSE 2.0937068259225624 Test RE 0.691617533527787\n",
      "56 Train Loss 1.3330532 Test MSE 1.9898578563802278 Test RE 0.6742471002212727\n",
      "57 Train Loss 1.3033264 Test MSE 1.9597494356047702 Test RE 0.6691266607577661\n",
      "58 Train Loss 1.2685151 Test MSE 1.8971547287406538 Test RE 0.658353936380047\n",
      "59 Train Loss 1.2270476 Test MSE 1.849112127882001 Test RE 0.649964570287553\n",
      "60 Train Loss 1.1786814 Test MSE 1.7758267822615903 Test RE 0.636954427928681\n",
      "61 Train Loss 1.1472398 Test MSE 1.7276848925287736 Test RE 0.6282613281852273\n",
      "62 Train Loss 1.111545 Test MSE 1.6758067807994397 Test RE 0.6187568672428392\n",
      "63 Train Loss 1.087327 Test MSE 1.6564728915849256 Test RE 0.6151771939321732\n",
      "64 Train Loss 1.0462582 Test MSE 1.6360545797594221 Test RE 0.6113739841745602\n",
      "65 Train Loss 1.0251013 Test MSE 1.6329254885167281 Test RE 0.6107890524143395\n",
      "66 Train Loss 1.0045662 Test MSE 1.5927963204711055 Test RE 0.6032372926576025\n",
      "67 Train Loss 0.9902619 Test MSE 1.5697739047573491 Test RE 0.5988618021893742\n",
      "68 Train Loss 0.971803 Test MSE 1.5326966759942242 Test RE 0.5917471406126149\n",
      "69 Train Loss 0.9556033 Test MSE 1.4946019549284684 Test RE 0.5843470195437829\n",
      "70 Train Loss 0.9467234 Test MSE 1.4849207678467622 Test RE 0.5824514099531992\n",
      "71 Train Loss 0.93223876 Test MSE 1.4656571853198734 Test RE 0.5786610636775249\n",
      "72 Train Loss 0.921429 Test MSE 1.4476553546629454 Test RE 0.5750964024027512\n",
      "73 Train Loss 0.90675837 Test MSE 1.4326548018860077 Test RE 0.5721090794877016\n",
      "74 Train Loss 0.8835196 Test MSE 1.3652819484217824 Test RE 0.5584949291796601\n",
      "75 Train Loss 0.8552803 Test MSE 1.2656830108909354 Test RE 0.5377377623013587\n",
      "76 Train Loss 0.83377564 Test MSE 1.2034681056436627 Test RE 0.5243549266297828\n",
      "77 Train Loss 0.81958085 Test MSE 1.1692055058280753 Test RE 0.5168368681885864\n",
      "78 Train Loss 0.8068949 Test MSE 1.1713080858566887 Test RE 0.5173013728295341\n",
      "79 Train Loss 0.78766865 Test MSE 1.139835481891314 Test RE 0.510304204128528\n",
      "80 Train Loss 0.7675847 Test MSE 1.0925914040662132 Test RE 0.4996167039882312\n",
      "81 Train Loss 0.74579453 Test MSE 1.042352375392804 Test RE 0.48799496433348244\n",
      "82 Train Loss 0.72676957 Test MSE 1.0036186627567238 Test RE 0.4788422078595044\n",
      "83 Train Loss 0.7061623 Test MSE 0.9790464351644947 Test RE 0.472943984024811\n",
      "84 Train Loss 0.68773896 Test MSE 0.9619174457967519 Test RE 0.4687885125699019\n",
      "85 Train Loss 0.6641643 Test MSE 0.9291431226047574 Test RE 0.460733051874752\n",
      "86 Train Loss 0.6480131 Test MSE 0.8912563157485244 Test RE 0.4512418493969646\n",
      "87 Train Loss 0.6244951 Test MSE 0.8497190643921799 Test RE 0.44060126671604555\n",
      "88 Train Loss 0.60061437 Test MSE 0.8290602405505095 Test RE 0.43521224327357566\n",
      "89 Train Loss 0.5674634 Test MSE 0.7477464135757849 Test RE 0.41331886643688376\n",
      "90 Train Loss 0.54808235 Test MSE 0.7280319473177096 Test RE 0.40783385919337123\n",
      "91 Train Loss 0.51999867 Test MSE 0.6605061558380952 Test RE 0.38846016925052435\n",
      "92 Train Loss 0.4964105 Test MSE 0.597977876525784 Test RE 0.36961587729797085\n",
      "93 Train Loss 0.4713562 Test MSE 0.5467616649123811 Test RE 0.35343299335154627\n",
      "94 Train Loss 0.45102096 Test MSE 0.5397535859061694 Test RE 0.3511606372179477\n",
      "95 Train Loss 0.43413132 Test MSE 0.5176123205708586 Test RE 0.34388272764495675\n",
      "96 Train Loss 0.41875708 Test MSE 0.5340655736975642 Test RE 0.3493054423628143\n",
      "97 Train Loss 0.40745124 Test MSE 0.5250406702264874 Test RE 0.34634149964774963\n",
      "98 Train Loss 0.38912702 Test MSE 0.49986639088825424 Test RE 0.33793644335885\n",
      "99 Train Loss 0.3712965 Test MSE 0.4761010919421012 Test RE 0.32980531407316166\n",
      "Training time: 159.17\n",
      "5\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.11569 Test MSE 4.877259087175311 Test RE 1.0555917165533135\n",
      "1 Train Loss 45.92292 Test MSE 6.948348077815986 Test RE 1.2599370394265992\n",
      "2 Train Loss 35.78919 Test MSE 6.642327537611596 Test RE 1.2318794312602883\n",
      "3 Train Loss 32.060516 Test MSE 6.217247573836742 Test RE 1.1918103181958368\n",
      "4 Train Loss 28.770403 Test MSE 6.105209831958421 Test RE 1.1810230063301708\n",
      "5 Train Loss 26.551937 Test MSE 6.148446579789662 Test RE 1.1851975971031004\n",
      "6 Train Loss 23.37058 Test MSE 5.6072944534085085 Test RE 1.1318392271496351\n",
      "7 Train Loss 21.699106 Test MSE 5.458782684491609 Test RE 1.1167500045636407\n",
      "8 Train Loss 20.168037 Test MSE 5.106276743526312 Test RE 1.080090719534617\n",
      "9 Train Loss 19.736378 Test MSE 5.096160863200797 Test RE 1.0790203226783706\n",
      "10 Train Loss 19.213345 Test MSE 5.1282936655575835 Test RE 1.0824167484491705\n",
      "11 Train Loss 18.774532 Test MSE 5.113152760788866 Test RE 1.080817689919881\n",
      "12 Train Loss 18.091698 Test MSE 5.256790314980413 Test RE 1.0958935915123837\n",
      "13 Train Loss 17.59616 Test MSE 5.327498996606861 Test RE 1.1032393623192427\n",
      "14 Train Loss 17.318342 Test MSE 5.238229558193921 Test RE 1.0939571816783542\n",
      "15 Train Loss 16.716475 Test MSE 5.32478639943825 Test RE 1.1029584589338262\n",
      "16 Train Loss 16.265131 Test MSE 5.376784746840754 Test RE 1.108330757168042\n",
      "17 Train Loss 15.341553 Test MSE 5.6789395323159875 Test RE 1.139047099561806\n",
      "18 Train Loss 14.954252 Test MSE 5.79649444520927 Test RE 1.1507759374658648\n",
      "19 Train Loss 13.940428 Test MSE 5.657406151160621 Test RE 1.1368855313457071\n",
      "20 Train Loss 12.243387 Test MSE 5.373731800934797 Test RE 1.1080160566121358\n",
      "21 Train Loss 11.052461 Test MSE 4.776285860884998 Test RE 1.0446076836934033\n",
      "22 Train Loss 10.05062 Test MSE 4.857773452364333 Test RE 1.0534809551939128\n",
      "23 Train Loss 9.341928 Test MSE 4.5454375300258825 Test RE 1.019050970676215\n",
      "24 Train Loss 9.09033 Test MSE 4.5121552810318795 Test RE 1.0153133083390689\n",
      "25 Train Loss 8.867758 Test MSE 4.249721011663693 Test RE 0.985344893806588\n",
      "26 Train Loss 8.312276 Test MSE 3.565741524076865 Test RE 0.9025743547414412\n",
      "27 Train Loss 8.146831 Test MSE 3.5497146229510728 Test RE 0.9005436745973912\n",
      "28 Train Loss 7.901036 Test MSE 3.543871400426536 Test RE 0.8998021721222424\n",
      "29 Train Loss 7.6156235 Test MSE 3.3040903752681703 Test RE 0.8688284213068964\n",
      "30 Train Loss 7.358 Test MSE 3.0350332623445353 Test RE 0.8327023452406583\n",
      "31 Train Loss 6.995533 Test MSE 2.7052977504301436 Test RE 0.7861684227766425\n",
      "32 Train Loss 6.716522 Test MSE 2.7851699663549816 Test RE 0.7976895670261621\n",
      "33 Train Loss 6.4844713 Test MSE 2.802828658245962 Test RE 0.8002143496251801\n",
      "34 Train Loss 6.324109 Test MSE 2.7841262879093085 Test RE 0.7975400951043189\n",
      "35 Train Loss 6.1769953 Test MSE 2.7908343398677142 Test RE 0.7985003104814642\n",
      "36 Train Loss 6.101903 Test MSE 2.8454839814473987 Test RE 0.8062804561401995\n",
      "37 Train Loss 5.9944253 Test MSE 2.7198326545584095 Test RE 0.7882775390991041\n",
      "38 Train Loss 5.90685 Test MSE 2.7459787314007835 Test RE 0.7920573799763021\n",
      "39 Train Loss 5.8686857 Test MSE 2.739752246430439 Test RE 0.7911588784408958\n",
      "40 Train Loss 5.8448467 Test MSE 2.7554553664773436 Test RE 0.7934229356887886\n",
      "41 Train Loss 5.796693 Test MSE 2.7493346773801903 Test RE 0.7925412311635108\n",
      "42 Train Loss 5.765746 Test MSE 2.751522304493348 Test RE 0.7928564783298143\n",
      "43 Train Loss 5.750782 Test MSE 2.7768264542804184 Test RE 0.7964938546322161\n",
      "44 Train Loss 5.720254 Test MSE 2.7408152347105372 Test RE 0.7913123432402845\n",
      "45 Train Loss 5.6744776 Test MSE 2.718551002836825 Test RE 0.7880917893783208\n",
      "46 Train Loss 5.651763 Test MSE 2.7397080249948473 Test RE 0.7911524934981318\n",
      "47 Train Loss 5.6265383 Test MSE 2.715246940720598 Test RE 0.7876127297828558\n",
      "48 Train Loss 5.584675 Test MSE 2.6720022417247953 Test RE 0.7813155526867867\n",
      "49 Train Loss 5.497104 Test MSE 2.639618319532073 Test RE 0.7765664560592632\n",
      "50 Train Loss 5.4522886 Test MSE 2.634163949384974 Test RE 0.7757637128700018\n",
      "51 Train Loss 5.3993196 Test MSE 2.5727158098238454 Test RE 0.7666620532997432\n",
      "52 Train Loss 5.362898 Test MSE 2.557172012928306 Test RE 0.7643425406807497\n",
      "53 Train Loss 5.2898307 Test MSE 2.565874074127962 Test RE 0.7656419656894643\n",
      "54 Train Loss 5.179159 Test MSE 2.5811261483111676 Test RE 0.7679141594062697\n",
      "55 Train Loss 5.0933466 Test MSE 2.586532791318794 Test RE 0.7687180073314327\n",
      "56 Train Loss 5.0140705 Test MSE 2.577300340748463 Test RE 0.7673448378987549\n",
      "57 Train Loss 4.9368634 Test MSE 2.564079272509251 Test RE 0.7653741396409088\n",
      "58 Train Loss 4.823199 Test MSE 2.5579298017198364 Test RE 0.7644557843935428\n",
      "59 Train Loss 4.6504755 Test MSE 2.4272653618259787 Test RE 0.7446748548890698\n",
      "60 Train Loss 4.1383195 Test MSE 2.1002580154876322 Test RE 0.6926987209096339\n",
      "61 Train Loss 3.006151 Test MSE 1.7945255060275482 Test RE 0.6402990802726847\n",
      "62 Train Loss 2.4364805 Test MSE 1.2471328759410056 Test RE 0.5337826141142343\n",
      "63 Train Loss 1.7643071 Test MSE 0.8025950201950988 Test RE 0.428209492705196\n",
      "64 Train Loss 1.4852564 Test MSE 0.6752106905593465 Test RE 0.3927604194763286\n",
      "65 Train Loss 1.2888324 Test MSE 0.6433663813828018 Test RE 0.38338687587284176\n",
      "66 Train Loss 1.1640502 Test MSE 0.543640590069249 Test RE 0.3524228004327943\n",
      "67 Train Loss 1.1055393 Test MSE 0.5235703092795642 Test RE 0.34585620005363754\n",
      "68 Train Loss 1.0478044 Test MSE 0.5354553585046499 Test RE 0.3497596412537627\n",
      "69 Train Loss 0.9652896 Test MSE 0.5198035456322633 Test RE 0.3446098438907868\n",
      "70 Train Loss 0.85152256 Test MSE 0.46561689933830824 Test RE 0.3261537884855467\n",
      "71 Train Loss 0.80993307 Test MSE 0.4063942970660325 Test RE 0.30470660104458763\n",
      "72 Train Loss 0.76809233 Test MSE 0.38646341792255323 Test RE 0.29714077759048096\n",
      "73 Train Loss 0.74349374 Test MSE 0.42447603530919625 Test RE 0.31141150142078255\n",
      "74 Train Loss 0.71760166 Test MSE 0.4062758201299952 Test RE 0.3046621819468618\n",
      "75 Train Loss 0.67916155 Test MSE 0.32083226899764167 Test RE 0.27073666922504036\n",
      "76 Train Loss 0.6384139 Test MSE 0.2936480040527562 Test RE 0.2590130147963264\n",
      "77 Train Loss 0.62251943 Test MSE 0.3223905171743048 Test RE 0.27139334243360846\n",
      "78 Train Loss 0.59635377 Test MSE 0.30771506989848146 Test RE 0.2651443903102753\n",
      "79 Train Loss 0.57240516 Test MSE 0.30596791009709284 Test RE 0.264390593852919\n",
      "80 Train Loss 0.54493594 Test MSE 0.2508696557331428 Test RE 0.23940439954779053\n",
      "81 Train Loss 0.5052129 Test MSE 0.11422482562072243 Test RE 0.16154306259355794\n",
      "82 Train Loss 0.47640842 Test MSE 0.09984757187503678 Test RE 0.1510347267841875\n",
      "83 Train Loss 0.43638837 Test MSE 0.07435700454346632 Test RE 0.13033738497424516\n",
      "84 Train Loss 0.417679 Test MSE 0.06781051409490686 Test RE 0.12446767544227147\n",
      "85 Train Loss 0.3674889 Test MSE 0.05359993426333658 Test RE 0.1106598784411676\n",
      "86 Train Loss 0.30603498 Test MSE 0.04453088707862626 Test RE 0.10086459140670673\n",
      "87 Train Loss 0.27201268 Test MSE 0.036147549510930646 Test RE 0.09087564177141352\n",
      "88 Train Loss 0.25855842 Test MSE 0.03323746458747769 Test RE 0.08714089258244347\n",
      "89 Train Loss 0.23946394 Test MSE 0.0284827747971624 Test RE 0.08066761340891622\n",
      "90 Train Loss 0.22665234 Test MSE 0.031361949698231376 Test RE 0.08464661339923783\n",
      "91 Train Loss 0.20740095 Test MSE 0.03206068992691103 Test RE 0.085584376722451\n",
      "92 Train Loss 0.1907359 Test MSE 0.031339108376759496 Test RE 0.08461578316239711\n",
      "93 Train Loss 0.17794126 Test MSE 0.029427671972619987 Test RE 0.0819947438461122\n",
      "94 Train Loss 0.16590397 Test MSE 0.028662958368636905 Test RE 0.08092236499031585\n",
      "95 Train Loss 0.15612692 Test MSE 0.02740460880633061 Test RE 0.07912611880555696\n",
      "96 Train Loss 0.14895129 Test MSE 0.031117922464104983 Test RE 0.08431665277089387\n",
      "97 Train Loss 0.13915282 Test MSE 0.0290355278368185 Test RE 0.08144659318903906\n",
      "98 Train Loss 0.13025826 Test MSE 0.03518498877764288 Test RE 0.0896575296914639\n",
      "99 Train Loss 0.12521204 Test MSE 0.03186108176644526 Test RE 0.08531753884198821\n",
      "Training time: 156.69\n",
      "6\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.38998 Test MSE 5.96223245106025 Test RE 1.1671119405024033\n",
      "1 Train Loss 45.95539 Test MSE 8.382155259997672 Test RE 1.3838400986239308\n",
      "2 Train Loss 38.878277 Test MSE 8.566652709628816 Test RE 1.3989868774212528\n",
      "3 Train Loss 34.321503 Test MSE 8.352094231288214 Test RE 1.381356428254208\n",
      "4 Train Loss 32.36183 Test MSE 8.177332230951896 Test RE 1.366828046408938\n",
      "5 Train Loss 31.029305 Test MSE 8.143614110123977 Test RE 1.3640071704581833\n",
      "6 Train Loss 29.386936 Test MSE 8.029857807749226 Test RE 1.3544469130519738\n",
      "7 Train Loss 28.047764 Test MSE 8.630780211929284 Test RE 1.4042133217670765\n",
      "8 Train Loss 26.302618 Test MSE 8.321515638277836 Test RE 1.3788254062205634\n",
      "9 Train Loss 25.03178 Test MSE 8.260139031511983 Test RE 1.3737311269711643\n",
      "10 Train Loss 23.929981 Test MSE 8.43444705120173 Test RE 1.3881499071784678\n",
      "11 Train Loss 22.91246 Test MSE 8.5244721137531 Test RE 1.3955384524546546\n",
      "12 Train Loss 21.66458 Test MSE 8.16618445339473 Test RE 1.365896062044195\n",
      "13 Train Loss 20.464893 Test MSE 8.104379378267975 Test RE 1.3607174105800182\n",
      "14 Train Loss 19.072666 Test MSE 8.403797533430515 Test RE 1.3856254472500429\n",
      "15 Train Loss 17.343908 Test MSE 8.217610556550028 Test RE 1.370190140362851\n",
      "16 Train Loss 16.402435 Test MSE 8.082668007489554 Test RE 1.3588935292186886\n",
      "17 Train Loss 15.074419 Test MSE 8.057728150203204 Test RE 1.356795410487403\n",
      "18 Train Loss 14.337418 Test MSE 7.7948786107065136 Test RE 1.334482055955429\n",
      "19 Train Loss 13.175482 Test MSE 7.490954405761649 Test RE 1.3082075075548925\n",
      "20 Train Loss 10.821395 Test MSE 5.162394935279118 Test RE 1.086009622474461\n",
      "21 Train Loss 8.951775 Test MSE 5.248008468897591 Test RE 1.0949778243797141\n",
      "22 Train Loss 6.869164 Test MSE 4.66161294958136 Test RE 1.0319916088331378\n",
      "23 Train Loss 5.910416 Test MSE 4.620301487217304 Test RE 1.0274086503170359\n",
      "24 Train Loss 5.0606055 Test MSE 4.730661193061222 Test RE 1.039606492121017\n",
      "25 Train Loss 4.74186 Test MSE 4.828926473326652 Test RE 1.0503483478650315\n",
      "26 Train Loss 4.364857 Test MSE 4.778787238658859 Test RE 1.0448811824434172\n",
      "27 Train Loss 4.064334 Test MSE 4.875052103999625 Test RE 1.055352859366941\n",
      "28 Train Loss 3.8882442 Test MSE 5.058276931940338 Test RE 1.0750022210571994\n",
      "29 Train Loss 3.5777824 Test MSE 5.0256313267151125 Test RE 1.0715276282764166\n",
      "30 Train Loss 3.3815587 Test MSE 5.025998172397063 Test RE 1.0715667356128804\n",
      "31 Train Loss 3.2028463 Test MSE 5.0549904646324375 Test RE 1.074652938707821\n",
      "32 Train Loss 3.0772007 Test MSE 5.045604772899286 Test RE 1.073654811460398\n",
      "33 Train Loss 2.9670093 Test MSE 5.103148186904841 Test RE 1.079759789300276\n",
      "34 Train Loss 2.7891064 Test MSE 5.1354192185098055 Test RE 1.0831684741750367\n",
      "35 Train Loss 2.676943 Test MSE 5.114611156487971 Test RE 1.0809718166948212\n",
      "36 Train Loss 2.573649 Test MSE 5.1182562150838855 Test RE 1.0813569392114502\n",
      "37 Train Loss 2.4968476 Test MSE 5.141003070945595 Test RE 1.0837571904472403\n",
      "38 Train Loss 2.4072654 Test MSE 5.116845549974802 Test RE 1.0812079101708176\n",
      "39 Train Loss 2.3763695 Test MSE 5.12747974741128 Test RE 1.0823308491569525\n",
      "40 Train Loss 2.292909 Test MSE 5.098433475223751 Test RE 1.079260888203926\n",
      "41 Train Loss 2.2545512 Test MSE 5.058357679646718 Test RE 1.075010801411582\n",
      "42 Train Loss 2.2131324 Test MSE 4.986686492420649 Test RE 1.0673677901538599\n",
      "43 Train Loss 2.1578777 Test MSE 4.984762808786803 Test RE 1.0671618943139403\n",
      "44 Train Loss 2.0958474 Test MSE 4.999061467021741 Test RE 1.068691360906757\n",
      "45 Train Loss 2.044884 Test MSE 4.996734247352757 Test RE 1.068442577300841\n",
      "46 Train Loss 1.9774983 Test MSE 5.003699367408076 Test RE 1.0691869874400097\n",
      "47 Train Loss 1.9471889 Test MSE 5.038748250609055 Test RE 1.0729250633830387\n",
      "48 Train Loss 1.8879567 Test MSE 5.0329140606836535 Test RE 1.0723037323211617\n",
      "49 Train Loss 1.8623288 Test MSE 5.034643013560969 Test RE 1.072487900320633\n",
      "50 Train Loss 1.8134121 Test MSE 5.0612166878889475 Test RE 1.0753145591502338\n",
      "51 Train Loss 1.7643101 Test MSE 5.1169568294754475 Test RE 1.0812196669867133\n",
      "52 Train Loss 1.7230494 Test MSE 5.150499018303591 Test RE 1.0847576326960928\n",
      "53 Train Loss 1.6970296 Test MSE 5.1407717672338205 Test RE 1.0837328100027017\n",
      "54 Train Loss 1.6590292 Test MSE 5.142165005059442 Test RE 1.0838796551967613\n",
      "55 Train Loss 1.6416204 Test MSE 5.129522070894209 Test RE 1.0825463789834477\n",
      "56 Train Loss 1.6015651 Test MSE 5.133574413072534 Test RE 1.082973902466749\n",
      "57 Train Loss 1.5807227 Test MSE 5.162451792040266 Test RE 1.0860156029176924\n",
      "58 Train Loss 1.5566431 Test MSE 5.198428131340854 Test RE 1.0897931715824212\n",
      "59 Train Loss 1.5373805 Test MSE 5.229331201312219 Test RE 1.0930276157944923\n",
      "60 Train Loss 1.526045 Test MSE 5.202685316885639 Test RE 1.0902393162778603\n",
      "61 Train Loss 1.497794 Test MSE 5.2167765496918985 Test RE 1.0917147493262904\n",
      "62 Train Loss 1.4843476 Test MSE 5.229308719528339 Test RE 1.0930252662361934\n",
      "63 Train Loss 1.4634099 Test MSE 5.283453993239247 Test RE 1.0986693912564784\n",
      "64 Train Loss 1.4352611 Test MSE 5.308489571323997 Test RE 1.101269330268366\n",
      "65 Train Loss 1.4192495 Test MSE 5.281137530269564 Test RE 1.098428516065378\n",
      "66 Train Loss 1.394153 Test MSE 5.339655547135012 Test RE 1.1044973581418007\n",
      "67 Train Loss 1.3833649 Test MSE 5.325333860657097 Test RE 1.1030151571201325\n",
      "68 Train Loss 1.3658444 Test MSE 5.3500848224705715 Test RE 1.1055754696169333\n",
      "69 Train Loss 1.3516473 Test MSE 5.372390712591636 Test RE 1.1078777876964354\n",
      "70 Train Loss 1.3337523 Test MSE 5.385991575058813 Test RE 1.1092792651391508\n",
      "71 Train Loss 1.3198935 Test MSE 5.396045141194515 Test RE 1.1103140804496456\n",
      "72 Train Loss 1.3026175 Test MSE 5.425545258037398 Test RE 1.113344980787569\n",
      "73 Train Loss 1.2884055 Test MSE 5.413871611839835 Test RE 1.112146594881989\n",
      "74 Train Loss 1.2828162 Test MSE 5.409740139012668 Test RE 1.1117221592187876\n",
      "75 Train Loss 1.2728198 Test MSE 5.431099190105246 Test RE 1.1139146802800517\n",
      "76 Train Loss 1.2562377 Test MSE 5.413596196534317 Test RE 1.11211830587628\n",
      "77 Train Loss 1.2466962 Test MSE 5.433850766544479 Test RE 1.1141968177599646\n",
      "78 Train Loss 1.2385949 Test MSE 5.429117178191812 Test RE 1.1137114070978746\n",
      "79 Train Loss 1.2276136 Test MSE 5.452399385863041 Test RE 1.1160968704887553\n",
      "80 Train Loss 1.220686 Test MSE 5.466136460217007 Test RE 1.1175019638932029\n",
      "81 Train Loss 1.2103078 Test MSE 5.473118942978484 Test RE 1.1182154886984537\n",
      "82 Train Loss 1.1993642 Test MSE 5.494975366776488 Test RE 1.120446012146509\n",
      "83 Train Loss 1.191436 Test MSE 5.528485791082987 Test RE 1.1238572696417377\n",
      "84 Train Loss 1.180477 Test MSE 5.558903457136503 Test RE 1.1269447536105734\n",
      "85 Train Loss 1.1744168 Test MSE 5.564054716330156 Test RE 1.1274667846478348\n",
      "86 Train Loss 1.1699975 Test MSE 5.558309313602836 Test RE 1.1268845272695922\n",
      "87 Train Loss 1.1625375 Test MSE 5.588948021021062 Test RE 1.1299860852086847\n",
      "88 Train Loss 1.1451638 Test MSE 5.6315456357529365 Test RE 1.1342841518399698\n",
      "89 Train Loss 1.1349792 Test MSE 5.64985547907653 Test RE 1.1361266043943958\n",
      "90 Train Loss 1.1222907 Test MSE 5.673458470673729 Test RE 1.1384972878874453\n",
      "91 Train Loss 1.1144202 Test MSE 5.713611632090085 Test RE 1.1425189676429681\n",
      "92 Train Loss 1.0988415 Test MSE 5.7275590825721565 Test RE 1.1439126144958895\n",
      "93 Train Loss 1.0882132 Test MSE 5.7643071897053675 Test RE 1.1475764275828102\n",
      "94 Train Loss 1.0787255 Test MSE 5.751000939578458 Test RE 1.1462511372314188\n",
      "95 Train Loss 1.0702717 Test MSE 5.752165729948091 Test RE 1.1463672104769964\n",
      "96 Train Loss 1.0645497 Test MSE 5.758841010061505 Test RE 1.1470321864004291\n",
      "97 Train Loss 1.0554435 Test MSE 5.774665027175518 Test RE 1.1486070002842355\n",
      "98 Train Loss 1.0482529 Test MSE 5.796985004304644 Test RE 1.150824631695175\n",
      "99 Train Loss 1.0425543 Test MSE 5.797988275981432 Test RE 1.1509242127537598\n",
      "Training time: 161.72\n",
      "7\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.14754 Test MSE 4.841092331822781 Test RE 1.0516706242745104\n",
      "1 Train Loss 50.056664 Test MSE 7.002813976734995 Test RE 1.2648655236864217\n",
      "2 Train Loss 37.848835 Test MSE 6.929585402261797 Test RE 1.2582347808550378\n",
      "3 Train Loss 31.847553 Test MSE 6.708454892252568 Test RE 1.2379962017375912\n",
      "4 Train Loss 26.78884 Test MSE 6.45435069007754 Test RE 1.2143233318983944\n",
      "5 Train Loss 24.595102 Test MSE 6.214150931371353 Test RE 1.19151347702449\n",
      "6 Train Loss 23.117939 Test MSE 5.867476668398834 Test RE 1.1578005350942462\n",
      "7 Train Loss 20.728481 Test MSE 5.707874339972721 Test RE 1.141945196458555\n",
      "8 Train Loss 18.520058 Test MSE 6.062793500100138 Test RE 1.1769132396160817\n",
      "9 Train Loss 16.298191 Test MSE 5.713916660422021 Test RE 1.1425494646408552\n",
      "10 Train Loss 15.1483555 Test MSE 5.658188927549347 Test RE 1.1369641801421428\n",
      "11 Train Loss 14.246629 Test MSE 5.840020135373644 Test RE 1.1550884267525925\n",
      "12 Train Loss 13.518723 Test MSE 5.865399447045164 Test RE 1.1575955729763368\n",
      "13 Train Loss 12.847785 Test MSE 5.892627496655531 Test RE 1.1602793267077023\n",
      "14 Train Loss 12.427109 Test MSE 5.925187114777145 Test RE 1.163480463188258\n",
      "15 Train Loss 12.244308 Test MSE 5.725990692125095 Test RE 1.1437559836843583\n",
      "16 Train Loss 11.924852 Test MSE 5.8100643905049365 Test RE 1.1521221681806157\n",
      "17 Train Loss 11.540186 Test MSE 5.670550938196872 Test RE 1.1382055221091236\n",
      "18 Train Loss 11.086175 Test MSE 5.5006361605936025 Test RE 1.1210229920939005\n",
      "19 Train Loss 10.527543 Test MSE 5.467417991107773 Test RE 1.1176329548927924\n",
      "20 Train Loss 9.904545 Test MSE 5.008427709248651 Test RE 1.069692042544478\n",
      "21 Train Loss 8.645272 Test MSE 4.404062290513612 Test RE 1.003078188005506\n",
      "22 Train Loss 7.362466 Test MSE 4.156504141625108 Test RE 0.9744782921876916\n",
      "23 Train Loss 6.249919 Test MSE 4.015940208914117 Test RE 0.9578592099320865\n",
      "24 Train Loss 5.5601225 Test MSE 3.6122303354362457 Test RE 0.9084390156439337\n",
      "25 Train Loss 5.1456203 Test MSE 3.4280883542130165 Test RE 0.8849812381804932\n",
      "26 Train Loss 4.601121 Test MSE 3.077115512707094 Test RE 0.8384553884154896\n",
      "27 Train Loss 4.118139 Test MSE 2.9475943193739504 Test RE 0.8206196568817813\n",
      "28 Train Loss 3.783981 Test MSE 2.8026027629809502 Test RE 0.8001821021536139\n",
      "29 Train Loss 3.578461 Test MSE 2.9053078800707666 Test RE 0.8147120528277526\n",
      "30 Train Loss 3.2728174 Test MSE 2.7161605327960774 Test RE 0.7877452216422555\n",
      "31 Train Loss 3.1489632 Test MSE 2.731610582425798 Test RE 0.7899824687307911\n",
      "32 Train Loss 2.92893 Test MSE 2.6493600707759555 Test RE 0.7779981308767222\n",
      "33 Train Loss 2.7373915 Test MSE 2.50010110570354 Test RE 0.755765123205753\n",
      "34 Train Loss 2.5661795 Test MSE 2.3251232909975825 Test RE 0.7288380769408834\n",
      "35 Train Loss 2.372166 Test MSE 2.154080468513275 Test RE 0.70151832761458\n",
      "36 Train Loss 2.1308818 Test MSE 2.0407917907769577 Test RE 0.682821849520019\n",
      "37 Train Loss 1.9217474 Test MSE 1.8639505545650419 Test RE 0.6525672195404076\n",
      "38 Train Loss 1.7614783 Test MSE 1.6165988692579911 Test RE 0.6077279292801802\n",
      "39 Train Loss 1.6125541 Test MSE 1.4821327237388435 Test RE 0.5819043561237123\n",
      "40 Train Loss 1.4829599 Test MSE 1.3559745597708897 Test RE 0.5565879901554507\n",
      "41 Train Loss 1.357324 Test MSE 1.081374429575587 Test RE 0.4970454564865197\n",
      "42 Train Loss 1.1843369 Test MSE 0.9910279074390511 Test RE 0.47582910448108445\n",
      "43 Train Loss 1.068307 Test MSE 0.9117260106253552 Test RE 0.45639432203815217\n",
      "44 Train Loss 0.88350374 Test MSE 0.7372246854624229 Test RE 0.4104006072428296\n",
      "45 Train Loss 0.74525523 Test MSE 0.69103071328962 Test RE 0.39733492044019153\n",
      "46 Train Loss 0.6736561 Test MSE 0.7212389715828548 Test RE 0.4059267325674353\n",
      "47 Train Loss 0.6051641 Test MSE 0.6023601440743397 Test RE 0.3709677658598619\n",
      "48 Train Loss 0.5336154 Test MSE 0.5658040258694554 Test RE 0.35953491924631487\n",
      "49 Train Loss 0.47721562 Test MSE 0.5053121146476609 Test RE 0.3397722573133888\n",
      "50 Train Loss 0.4055517 Test MSE 0.38258446800067414 Test RE 0.295645809492785\n",
      "51 Train Loss 0.32711792 Test MSE 0.28449612232676275 Test RE 0.2549448456008046\n",
      "52 Train Loss 0.28345415 Test MSE 0.21521496073528212 Test RE 0.22174012568697465\n",
      "53 Train Loss 0.25599307 Test MSE 0.18900854099161057 Test RE 0.2078015463966682\n",
      "54 Train Loss 0.22534075 Test MSE 0.14795538000790753 Test RE 0.1838541516275766\n",
      "55 Train Loss 0.20663778 Test MSE 0.1302607534144236 Test RE 0.1725102295878655\n",
      "56 Train Loss 0.17649326 Test MSE 0.12637842431367777 Test RE 0.16992001135313387\n",
      "57 Train Loss 0.15820156 Test MSE 0.13943685190218766 Test RE 0.1784829949465511\n",
      "58 Train Loss 0.14650907 Test MSE 0.1282342974236651 Test RE 0.17116310594285564\n",
      "59 Train Loss 0.1275592 Test MSE 0.1098704340696367 Test RE 0.15843403407539616\n",
      "60 Train Loss 0.120475456 Test MSE 0.10344801841398418 Test RE 0.15373372426667092\n",
      "61 Train Loss 0.115561344 Test MSE 0.09856587548858378 Test RE 0.15006221485731291\n",
      "62 Train Loss 0.10609053 Test MSE 0.08755250225031354 Test RE 0.1414302606124139\n",
      "63 Train Loss 0.09730301 Test MSE 0.07813120099666399 Test RE 0.13360426135841\n",
      "64 Train Loss 0.09017372 Test MSE 0.06908095623706248 Test RE 0.125628226991499\n",
      "65 Train Loss 0.083741315 Test MSE 0.061781932533610605 Test RE 0.11880611778442925\n",
      "66 Train Loss 0.078981735 Test MSE 0.050840706054078956 Test RE 0.10777396154113533\n",
      "67 Train Loss 0.07493307 Test MSE 0.04508700149896351 Test RE 0.10149245016354946\n",
      "68 Train Loss 0.073600106 Test MSE 0.0433397954875205 Test RE 0.09950650877102744\n",
      "69 Train Loss 0.07056259 Test MSE 0.04115727174918775 Test RE 0.09696865001327555\n",
      "70 Train Loss 0.06669574 Test MSE 0.03376511868288979 Test RE 0.08782986203870838\n",
      "71 Train Loss 0.06363137 Test MSE 0.028009267827019766 Test RE 0.07999428085233848\n",
      "72 Train Loss 0.061556336 Test MSE 0.0297738557191649 Test RE 0.08247562209730906\n",
      "73 Train Loss 0.05871816 Test MSE 0.025011819293370072 Test RE 0.07559284687081305\n",
      "74 Train Loss 0.056086794 Test MSE 0.025671745245702846 Test RE 0.0765835964552465\n",
      "75 Train Loss 0.053886943 Test MSE 0.02580051703162965 Test RE 0.07677543129908998\n",
      "76 Train Loss 0.049271915 Test MSE 0.024027498271025103 Test RE 0.07409046792481087\n",
      "77 Train Loss 0.044990268 Test MSE 0.020497479266627552 Test RE 0.06843185113748285\n",
      "78 Train Loss 0.043850813 Test MSE 0.019250204165695596 Test RE 0.06631713110355071\n",
      "79 Train Loss 0.042132523 Test MSE 0.01724429648224473 Test RE 0.06276691749589175\n",
      "80 Train Loss 0.040919527 Test MSE 0.01586758436374941 Test RE 0.06020928477898203\n",
      "81 Train Loss 0.040434003 Test MSE 0.015590856159070743 Test RE 0.05968195524670691\n",
      "82 Train Loss 0.038680557 Test MSE 0.016417153267868603 Test RE 0.061243074751673475\n",
      "83 Train Loss 0.036911454 Test MSE 0.015837276571562194 Test RE 0.060151756088746344\n",
      "84 Train Loss 0.03436621 Test MSE 0.014855743784793814 Test RE 0.058257958330751064\n",
      "85 Train Loss 0.032738615 Test MSE 0.01628867201219402 Test RE 0.061002958742575074\n",
      "86 Train Loss 0.03191804 Test MSE 0.015734468619201133 Test RE 0.0599562001303982\n",
      "87 Train Loss 0.029543577 Test MSE 0.0161775087676405 Test RE 0.06079444277782755\n",
      "88 Train Loss 0.027203646 Test MSE 0.012427401030205648 Test RE 0.05328417142868834\n",
      "89 Train Loss 0.02646003 Test MSE 0.011138254065674317 Test RE 0.05044482506233228\n",
      "90 Train Loss 0.025943112 Test MSE 0.01071093665505373 Test RE 0.04946770767741139\n",
      "91 Train Loss 0.025248595 Test MSE 0.00973259030818068 Test RE 0.04715440631790642\n",
      "92 Train Loss 0.024710028 Test MSE 0.009909073736189218 Test RE 0.04758001672315514\n",
      "93 Train Loss 0.023910757 Test MSE 0.008923654118319035 Test RE 0.04515225290157467\n",
      "94 Train Loss 0.023489527 Test MSE 0.0087048440093949 Test RE 0.04459524526161502\n",
      "95 Train Loss 0.022880388 Test MSE 0.00820877727370589 Test RE 0.043305922704747354\n",
      "96 Train Loss 0.022059083 Test MSE 0.007440550125903837 Test RE 0.041229738822009226\n",
      "97 Train Loss 0.021416675 Test MSE 0.006804859351335864 Test RE 0.039429170164860645\n",
      "98 Train Loss 0.020383492 Test MSE 0.007159324218336436 Test RE 0.0404430663096796\n",
      "99 Train Loss 0.019660968 Test MSE 0.006808289453115101 Test RE 0.03943910637520643\n",
      "Training time: 159.64\n",
      "8\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.07907 Test MSE 5.195188846740124 Test RE 1.0894535785117374\n",
      "1 Train Loss 48.76509 Test MSE 6.739437563604966 Test RE 1.2408517210202865\n",
      "2 Train Loss 38.402687 Test MSE 8.209950532550238 Test RE 1.3695513819117093\n",
      "3 Train Loss 32.651283 Test MSE 8.112822361917463 Test RE 1.3614260104457916\n",
      "4 Train Loss 27.77192 Test MSE 7.17784609916336 Test RE 1.280575331395244\n",
      "5 Train Loss 25.305443 Test MSE 7.181220303274792 Test RE 1.2808762862225453\n",
      "6 Train Loss 22.89104 Test MSE 7.410349764780923 Test RE 1.3011501428857764\n",
      "7 Train Loss 21.612476 Test MSE 7.833695566184071 Test RE 1.3378006580855504\n",
      "8 Train Loss 20.356781 Test MSE 7.97711568468548 Test RE 1.3499914110134803\n",
      "9 Train Loss 19.47343 Test MSE 8.093933851960287 Test RE 1.359840230994495\n",
      "10 Train Loss 18.126888 Test MSE 7.971396736295341 Test RE 1.3495074067845279\n",
      "11 Train Loss 17.765423 Test MSE 7.873455195904588 Test RE 1.3411913398871993\n",
      "12 Train Loss 17.319206 Test MSE 7.957003605594572 Test RE 1.3482885230135768\n",
      "13 Train Loss 16.787888 Test MSE 7.649803923479068 Test RE 1.3220053482050207\n",
      "14 Train Loss 16.493671 Test MSE 7.695388134184494 Test RE 1.3259383289180382\n",
      "15 Train Loss 16.240555 Test MSE 7.829141884699332 Test RE 1.3374117737083095\n",
      "16 Train Loss 16.035042 Test MSE 7.89615383522921 Test RE 1.3431232305164067\n",
      "17 Train Loss 15.806739 Test MSE 8.040813184576916 Test RE 1.3553705544778434\n",
      "18 Train Loss 15.56074 Test MSE 8.145596971295642 Test RE 1.3641732191070948\n",
      "19 Train Loss 15.148106 Test MSE 8.033808163089443 Test RE 1.3547800377986663\n",
      "20 Train Loss 14.748268 Test MSE 8.05374439392988 Test RE 1.3564599678929927\n",
      "21 Train Loss 14.4286 Test MSE 8.100284689458073 Test RE 1.3603736200168504\n",
      "22 Train Loss 14.0858 Test MSE 8.250547919320496 Test RE 1.372933353702028\n",
      "23 Train Loss 13.812197 Test MSE 8.235602539234598 Test RE 1.3716892962361436\n",
      "24 Train Loss 13.396677 Test MSE 8.157513917861495 Test RE 1.3651707419329315\n",
      "25 Train Loss 13.114964 Test MSE 8.188211660407527 Test RE 1.3677369838332831\n",
      "26 Train Loss 12.85139 Test MSE 8.29969721778054 Test RE 1.3770166288837624\n",
      "27 Train Loss 12.483376 Test MSE 8.0600664513903 Test RE 1.3569922628834168\n",
      "28 Train Loss 11.615822 Test MSE 8.113425150482062 Test RE 1.3614765869745777\n",
      "29 Train Loss 10.115919 Test MSE 7.692453231772058 Test RE 1.3256854585856597\n",
      "30 Train Loss 9.55072 Test MSE 7.524721234632279 Test RE 1.3111526830249656\n",
      "31 Train Loss 8.4730425 Test MSE 7.068840463421744 Test RE 1.2708144674800557\n",
      "32 Train Loss 7.719308 Test MSE 6.887206311594526 Test RE 1.254381402961164\n",
      "33 Train Loss 6.587562 Test MSE 6.815369161901366 Test RE 1.2478223287378092\n",
      "34 Train Loss 5.95088 Test MSE 6.723906245483517 Test RE 1.2394210987486485\n",
      "35 Train Loss 5.263624 Test MSE 6.602903528899225 Test RE 1.228218221967727\n",
      "36 Train Loss 4.992947 Test MSE 6.634453824983865 Test RE 1.2311490893219643\n",
      "37 Train Loss 4.6728 Test MSE 6.699378865709983 Test RE 1.2371584611899122\n",
      "38 Train Loss 4.424135 Test MSE 6.679545957272403 Test RE 1.2353258557055882\n",
      "39 Train Loss 4.303596 Test MSE 6.711083253064853 Test RE 1.2382387003530657\n",
      "40 Train Loss 4.062873 Test MSE 6.658299716952198 Test RE 1.2333596341827708\n",
      "41 Train Loss 3.9986544 Test MSE 6.660354893625386 Test RE 1.2335499662862814\n",
      "42 Train Loss 3.8686104 Test MSE 6.739944123821611 Test RE 1.2408983535693543\n",
      "43 Train Loss 3.7347212 Test MSE 6.715696974625512 Test RE 1.2386642581087843\n",
      "44 Train Loss 3.670808 Test MSE 6.853051623931904 Test RE 1.2512672045894127\n",
      "45 Train Loss 3.562777 Test MSE 6.895391821856375 Test RE 1.255126603726411\n",
      "46 Train Loss 3.5039659 Test MSE 6.895131471298866 Test RE 1.2551029084815266\n",
      "47 Train Loss 3.4466467 Test MSE 6.924431408980438 Test RE 1.2577667773960965\n",
      "48 Train Loss 3.3382251 Test MSE 6.93338603131167 Test RE 1.258579781880462\n",
      "49 Train Loss 3.311068 Test MSE 6.968461811175588 Test RE 1.2617593232381927\n",
      "50 Train Loss 3.275406 Test MSE 6.984472821621098 Test RE 1.2632080253558868\n",
      "51 Train Loss 3.1869493 Test MSE 7.017945310912714 Test RE 1.2662313157408827\n",
      "52 Train Loss 3.1533809 Test MSE 7.014547854940421 Test RE 1.265924781154385\n",
      "53 Train Loss 3.0709054 Test MSE 6.978522462368979 Test RE 1.2626698213032725\n",
      "54 Train Loss 3.0524807 Test MSE 7.006171728367738 Test RE 1.2651687300336611\n",
      "55 Train Loss 2.9289892 Test MSE 7.092878794074653 Test RE 1.2729734023120027\n",
      "56 Train Loss 2.8731945 Test MSE 7.099796504681201 Test RE 1.2735940188319679\n",
      "57 Train Loss 2.8116784 Test MSE 7.175038586409766 Test RE 1.2803248674573235\n",
      "58 Train Loss 2.752623 Test MSE 7.074328729770231 Test RE 1.271307703610516\n",
      "59 Train Loss 2.7229552 Test MSE 7.052027215904112 Test RE 1.269302250695198\n",
      "60 Train Loss 2.6817822 Test MSE 7.091461602057932 Test RE 1.2728462227901869\n",
      "61 Train Loss 2.6523662 Test MSE 7.121324120031204 Test RE 1.2755234185100568\n",
      "62 Train Loss 2.6192818 Test MSE 7.099474833892451 Test RE 1.2735651671153914\n",
      "63 Train Loss 2.5969615 Test MSE 7.126168897281055 Test RE 1.2759572266096724\n",
      "64 Train Loss 2.559314 Test MSE 7.128471125302037 Test RE 1.2761633196244198\n",
      "65 Train Loss 2.5317893 Test MSE 7.121569688997431 Test RE 1.2755454106467532\n",
      "66 Train Loss 2.49962 Test MSE 7.1095083485486334 Test RE 1.2744647986676558\n",
      "67 Train Loss 2.4704359 Test MSE 7.155822887693579 Test RE 1.2786092786988406\n",
      "68 Train Loss 2.450994 Test MSE 7.1674951147400074 Test RE 1.2796516561503486\n",
      "69 Train Loss 2.405323 Test MSE 7.202084246041758 Test RE 1.282735632254487\n",
      "70 Train Loss 2.3943136 Test MSE 7.151086714110763 Test RE 1.2781860766486612\n",
      "71 Train Loss 2.3754182 Test MSE 7.133222742429959 Test RE 1.2765885741583811\n",
      "72 Train Loss 2.3444612 Test MSE 7.111433969684829 Test RE 1.2746373823456834\n",
      "73 Train Loss 2.3314872 Test MSE 7.134454402518132 Test RE 1.2766987806798245\n",
      "74 Train Loss 2.32064 Test MSE 7.089778227644938 Test RE 1.2726951394130313\n",
      "75 Train Loss 2.2727919 Test MSE 7.161106494001833 Test RE 1.2790812315112825\n",
      "76 Train Loss 2.2650573 Test MSE 7.153732694065526 Test RE 1.2784225261619355\n",
      "77 Train Loss 2.2504003 Test MSE 7.17149809732183 Test RE 1.2800089433337376\n",
      "78 Train Loss 2.2202368 Test MSE 7.136876907915151 Test RE 1.2769155139445998\n",
      "79 Train Loss 2.211436 Test MSE 7.159469055617328 Test RE 1.2789349876000462\n",
      "80 Train Loss 2.2017522 Test MSE 7.156615617461999 Test RE 1.278680099594157\n",
      "81 Train Loss 2.177298 Test MSE 7.1324710359528645 Test RE 1.2765213082662867\n",
      "82 Train Loss 2.1540983 Test MSE 7.121569558677155 Test RE 1.275545398975911\n",
      "83 Train Loss 2.1441677 Test MSE 7.123374645367188 Test RE 1.2757070434084612\n",
      "84 Train Loss 2.1205325 Test MSE 7.0865644011628035 Test RE 1.27240664766864\n",
      "85 Train Loss 2.0971422 Test MSE 7.095560796408352 Test RE 1.2732140517756507\n",
      "86 Train Loss 2.0778823 Test MSE 7.100317932674119 Test RE 1.2736407860442365\n",
      "87 Train Loss 2.0636997 Test MSE 7.091871941044923 Test RE 1.2728830481234985\n",
      "88 Train Loss 2.0499256 Test MSE 7.108919767397335 Test RE 1.2744120424538858\n",
      "89 Train Loss 2.0338922 Test MSE 7.096327029696414 Test RE 1.2732827956481276\n",
      "90 Train Loss 2.0270462 Test MSE 7.099298476304797 Test RE 1.2735493487428564\n",
      "91 Train Loss 2.017515 Test MSE 7.044816119241744 Test RE 1.2686531180400755\n",
      "92 Train Loss 2.005353 Test MSE 7.040339547876594 Test RE 1.268249976310459\n",
      "93 Train Loss 1.9920058 Test MSE 7.02640034337932 Test RE 1.2669938469211681\n",
      "94 Train Loss 1.979249 Test MSE 7.008077146041724 Test RE 1.2653407577166156\n",
      "95 Train Loss 1.9613945 Test MSE 6.983932560604707 Test RE 1.2631591687515995\n",
      "96 Train Loss 1.9476384 Test MSE 6.980240565117449 Test RE 1.2628252455347557\n",
      "97 Train Loss 1.9264679 Test MSE 6.95427726332684 Test RE 1.2604744914489\n",
      "98 Train Loss 1.9037541 Test MSE 6.941251968761492 Test RE 1.2592935098858673\n",
      "99 Train Loss 1.8844569 Test MSE 6.929610275078417 Test RE 1.258237038985436\n",
      "Training time: 159.44\n",
      "9\n",
      "KG_rowdy_tune34\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.47487 Test MSE 7.983407567378541 Test RE 1.3505237032416715\n",
      "1 Train Loss 52.326447 Test MSE 7.715860466037354 Test RE 1.3277008793727698\n",
      "2 Train Loss 41.297855 Test MSE 9.427216446137134 Test RE 1.4675732919188085\n",
      "3 Train Loss 37.80074 Test MSE 9.246053548303772 Test RE 1.4534037032612805\n",
      "4 Train Loss 34.85235 Test MSE 8.977006537569952 Test RE 1.4321016034940246\n",
      "5 Train Loss 30.600445 Test MSE 8.909412562954019 Test RE 1.4266997833416377\n",
      "6 Train Loss 28.468796 Test MSE 9.021750863552086 Test RE 1.4356661977805103\n",
      "7 Train Loss 27.35643 Test MSE 8.72256265818128 Test RE 1.4116600008101068\n",
      "8 Train Loss 26.252018 Test MSE 8.97411515316299 Test RE 1.4318709536831065\n",
      "9 Train Loss 24.643932 Test MSE 9.022670540953243 Test RE 1.4357393718312164\n",
      "10 Train Loss 23.358738 Test MSE 9.030808667213375 Test RE 1.436386718685458\n",
      "11 Train Loss 22.58496 Test MSE 9.105851753264258 Test RE 1.4423423254781937\n",
      "12 Train Loss 21.684086 Test MSE 9.035019623461453 Test RE 1.4367215644851108\n",
      "13 Train Loss 20.84967 Test MSE 9.182621987742994 Test RE 1.4484096629924166\n",
      "14 Train Loss 20.097387 Test MSE 9.11365232172937 Test RE 1.4429599877146464\n",
      "15 Train Loss 19.353758 Test MSE 8.996438428651874 Test RE 1.4336507501373355\n",
      "16 Train Loss 18.794458 Test MSE 9.005316569013036 Test RE 1.4343579752265683\n",
      "17 Train Loss 18.03936 Test MSE 8.809782876637163 Test RE 1.4187003072913924\n",
      "18 Train Loss 17.169449 Test MSE 8.618455463842986 Test RE 1.4032103557614064\n",
      "19 Train Loss 16.4354 Test MSE 8.610430210009147 Test RE 1.4025568893681506\n",
      "20 Train Loss 15.407382 Test MSE 8.072122539437242 Test RE 1.3580067647564569\n",
      "21 Train Loss 14.58848 Test MSE 8.081407128441572 Test RE 1.3587875328320518\n",
      "22 Train Loss 13.104707 Test MSE 7.220597456287532 Test RE 1.2843832326047067\n",
      "23 Train Loss 11.914869 Test MSE 6.912451528143738 Test RE 1.2566782823221796\n",
      "24 Train Loss 10.866765 Test MSE 6.771606731004756 Test RE 1.2438096567404753\n",
      "25 Train Loss 9.90416 Test MSE 6.418172918267272 Test RE 1.210915301515502\n",
      "26 Train Loss 9.331863 Test MSE 6.254074444120927 Test RE 1.195334855417045\n",
      "27 Train Loss 8.857081 Test MSE 6.256712968080095 Test RE 1.1955869780214956\n",
      "28 Train Loss 8.578785 Test MSE 6.152218267609497 Test RE 1.1855610637077858\n",
      "29 Train Loss 8.285328 Test MSE 6.122572088838917 Test RE 1.182701135965792\n",
      "30 Train Loss 8.043186 Test MSE 6.225729858059384 Test RE 1.1926230434436238\n",
      "31 Train Loss 7.8688974 Test MSE 6.152923279752178 Test RE 1.1856289913206595\n",
      "32 Train Loss 7.744047 Test MSE 6.172482239296723 Test RE 1.187511939374843\n",
      "33 Train Loss 7.648928 Test MSE 6.182428898912179 Test RE 1.1884683635405533\n",
      "34 Train Loss 7.497594 Test MSE 6.210172279408664 Test RE 1.1911319786884849\n",
      "35 Train Loss 7.327635 Test MSE 6.2664830100894084 Test RE 1.1965200860756968\n",
      "36 Train Loss 7.2555876 Test MSE 6.218150172278798 Test RE 1.1918968265006726\n",
      "37 Train Loss 7.1519084 Test MSE 6.210158442883431 Test RE 1.1911306517416531\n",
      "38 Train Loss 6.9877353 Test MSE 6.123927476143871 Test RE 1.1828320392344327\n",
      "39 Train Loss 6.950528 Test MSE 6.0909236450840805 Test RE 1.1796404005145804\n",
      "40 Train Loss 6.8596306 Test MSE 6.106251113757238 Test RE 1.1811237174737856\n",
      "41 Train Loss 6.7987437 Test MSE 6.100927493477337 Test RE 1.1806087349466292\n",
      "42 Train Loss 6.676573 Test MSE 6.086044998510545 Test RE 1.1791678776428185\n",
      "43 Train Loss 6.6211224 Test MSE 6.070065073177673 Test RE 1.1776188092594946\n",
      "44 Train Loss 6.530178 Test MSE 6.084464692073292 Test RE 1.1790147759511822\n",
      "45 Train Loss 6.4007015 Test MSE 6.069024395740964 Test RE 1.1775178569763889\n",
      "46 Train Loss 6.342905 Test MSE 6.033241015590705 Test RE 1.1740413623473964\n",
      "47 Train Loss 6.257644 Test MSE 6.068829198004476 Test RE 1.177498920599341\n",
      "48 Train Loss 6.12193 Test MSE 6.035715229296091 Test RE 1.1742820730588988\n",
      "49 Train Loss 6.026918 Test MSE 6.048930976519603 Test RE 1.1755669687731174\n",
      "50 Train Loss 5.8773336 Test MSE 6.04404452970269 Test RE 1.1750920496458457\n",
      "51 Train Loss 5.787075 Test MSE 6.090476909292666 Test RE 1.179597139649572\n",
      "52 Train Loss 5.6266613 Test MSE 6.0834575478292505 Test RE 1.1789171924210182\n",
      "53 Train Loss 5.5108633 Test MSE 5.981783246177734 Test RE 1.1690239165605165\n",
      "54 Train Loss 5.376426 Test MSE 6.037473316111178 Test RE 1.1744530834062104\n",
      "55 Train Loss 5.2449083 Test MSE 6.058096867218555 Test RE 1.1764572946519034\n",
      "56 Train Loss 5.0596676 Test MSE 5.99588056118295 Test RE 1.1704006297790694\n",
      "57 Train Loss 4.9178505 Test MSE 5.9228070798691554 Test RE 1.1632467657374024\n",
      "58 Train Loss 4.715712 Test MSE 5.88910924093903 Test RE 1.1599328964537667\n",
      "59 Train Loss 4.4742723 Test MSE 5.9402414607446214 Test RE 1.164957574852284\n",
      "60 Train Loss 4.36736 Test MSE 5.918247641300473 Test RE 1.162798939798532\n",
      "61 Train Loss 4.157838 Test MSE 6.022950862883996 Test RE 1.1730397265298178\n",
      "62 Train Loss 3.992088 Test MSE 5.972982820773233 Test RE 1.16816366351892\n",
      "63 Train Loss 3.7795668 Test MSE 5.896799354258881 Test RE 1.1606899808420552\n",
      "64 Train Loss 3.53475 Test MSE 5.736215403617827 Test RE 1.1447767117628849\n",
      "65 Train Loss 3.2971027 Test MSE 5.547487636173952 Test RE 1.1257870062818525\n",
      "66 Train Loss 2.997239 Test MSE 5.425492927776088 Test RE 1.1133396115784397\n",
      "67 Train Loss 2.724745 Test MSE 5.471263996465182 Test RE 1.118025980145606\n",
      "68 Train Loss 2.5253425 Test MSE 5.430706709619916 Test RE 1.1138744308150965\n",
      "69 Train Loss 2.41227 Test MSE 5.401790915782472 Test RE 1.1109050611486573\n",
      "70 Train Loss 2.2892091 Test MSE 5.42864638292279 Test RE 1.1136631173472724\n",
      "71 Train Loss 2.2035134 Test MSE 5.403050863693473 Test RE 1.111034610859554\n",
      "72 Train Loss 2.0368931 Test MSE 5.462041277573065 Test RE 1.1170832740062204\n",
      "73 Train Loss 1.9523654 Test MSE 5.439038932079473 Test RE 1.1147286007088841\n",
      "74 Train Loss 1.8711727 Test MSE 5.503827806203886 Test RE 1.1213481716870917\n",
      "75 Train Loss 1.828097 Test MSE 5.508606709615102 Test RE 1.1218348922067605\n",
      "76 Train Loss 1.7795813 Test MSE 5.454161886498768 Test RE 1.1162772463527675\n",
      "77 Train Loss 1.728631 Test MSE 5.459568352715314 Test RE 1.1168303671165303\n",
      "78 Train Loss 1.6456308 Test MSE 5.448605609428698 Test RE 1.1157085131340687\n",
      "79 Train Loss 1.6149491 Test MSE 5.456186040477827 Test RE 1.1164843640985636\n",
      "80 Train Loss 1.6011575 Test MSE 5.435628110770911 Test RE 1.1143790227430401\n",
      "81 Train Loss 1.5652314 Test MSE 5.430304024277682 Test RE 1.113833133315023\n",
      "82 Train Loss 1.5507513 Test MSE 5.449648787197699 Test RE 1.1158153135429965\n",
      "83 Train Loss 1.5114717 Test MSE 5.405796448102354 Test RE 1.1113168636050017\n",
      "84 Train Loss 1.4790184 Test MSE 5.451068948596388 Test RE 1.1159606930595278\n",
      "85 Train Loss 1.4545133 Test MSE 5.47336536464194 Test RE 1.1182406616777134\n",
      "86 Train Loss 1.4307511 Test MSE 5.465614075188834 Test RE 1.1174485641796135\n",
      "87 Train Loss 1.408185 Test MSE 5.504029397558166 Test RE 1.1213687075790746\n",
      "88 Train Loss 1.3906717 Test MSE 5.516995608884889 Test RE 1.1226887723446297\n",
      "89 Train Loss 1.3762434 Test MSE 5.531155853156288 Test RE 1.1241286284329313\n",
      "90 Train Loss 1.3589191 Test MSE 5.511480112718533 Test RE 1.1221274401940604\n",
      "91 Train Loss 1.3391309 Test MSE 5.524787286521747 Test RE 1.1234812818208664\n",
      "92 Train Loss 1.328507 Test MSE 5.531770948907737 Test RE 1.124191131419618\n",
      "93 Train Loss 1.3054276 Test MSE 5.533128163420333 Test RE 1.1243290325508848\n",
      "94 Train Loss 1.290428 Test MSE 5.54098446604868 Test RE 1.1251269479119865\n",
      "95 Train Loss 1.2813473 Test MSE 5.532111781652938 Test RE 1.1242257636604667\n",
      "96 Train Loss 1.2627183 Test MSE 5.509265007855178 Test RE 1.1219019218489217\n",
      "97 Train Loss 1.2489609 Test MSE 5.51592911939631 Test RE 1.1225802537115432\n",
      "98 Train Loss 1.2359672 Test MSE 5.51791698182499 Test RE 1.1227825164712772\n",
      "99 Train Loss 1.2286875 Test MSE 5.528897186663275 Test RE 1.1238990841032461\n",
      "Training time: 159.24\n",
      "0\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.657265 Test MSE 8.148202334337386 Test RE 1.364391366552039\n",
      "1 Train Loss 42.287933 Test MSE 7.957272596408036 Test RE 1.348311312632602\n",
      "2 Train Loss 29.012793 Test MSE 6.41117443506073 Test RE 1.2102549202844326\n",
      "3 Train Loss 18.602423 Test MSE 5.6229938168696165 Test RE 1.1334225874820465\n",
      "4 Train Loss 15.712975 Test MSE 5.71138606370422 Test RE 1.1422964287376067\n",
      "5 Train Loss 13.8268175 Test MSE 5.712134075798403 Test RE 1.1423712287563381\n",
      "6 Train Loss 12.252359 Test MSE 5.587985142339702 Test RE 1.1298887425268238\n",
      "7 Train Loss 11.088541 Test MSE 5.781702612279912 Test RE 1.1493066909296157\n",
      "8 Train Loss 10.18338 Test MSE 5.802489310621264 Test RE 1.1513708629110202\n",
      "9 Train Loss 9.035344 Test MSE 5.613174237513344 Test RE 1.1324324924644233\n",
      "10 Train Loss 8.128845 Test MSE 5.657169758415695 Test RE 1.1368617789146704\n",
      "11 Train Loss 7.2449484 Test MSE 5.502336918106443 Test RE 1.1211962848610568\n",
      "12 Train Loss 6.3641186 Test MSE 5.3999754400394435 Test RE 1.1107183646707226\n",
      "13 Train Loss 5.7162933 Test MSE 4.965915609632279 Test RE 1.0651425343979886\n",
      "14 Train Loss 5.1460505 Test MSE 4.481215272798972 Test RE 1.011826300803598\n",
      "15 Train Loss 4.5985575 Test MSE 4.164198940744755 Test RE 0.9753798848802601\n",
      "16 Train Loss 3.8981552 Test MSE 3.8948545768243767 Test RE 0.9433083608588239\n",
      "17 Train Loss 3.3099093 Test MSE 3.612409342081904 Test RE 0.9084615245361248\n",
      "18 Train Loss 2.9108024 Test MSE 3.5123047971441266 Test RE 0.8957857690305984\n",
      "19 Train Loss 2.555708 Test MSE 3.4422410244915125 Test RE 0.8868061542790354\n",
      "20 Train Loss 2.2841952 Test MSE 3.216977865137806 Test RE 0.857298564696222\n",
      "21 Train Loss 2.0132275 Test MSE 2.971174712227088 Test RE 0.8238955465320357\n",
      "22 Train Loss 1.7755569 Test MSE 2.614790183421739 Test RE 0.7729056520773753\n",
      "23 Train Loss 1.561403 Test MSE 2.371789028076622 Test RE 0.7361157128533472\n",
      "24 Train Loss 1.4388359 Test MSE 2.165913714223041 Test RE 0.703442552253112\n",
      "25 Train Loss 1.3329021 Test MSE 1.876288578486403 Test RE 0.6547234221941294\n",
      "26 Train Loss 1.1271422 Test MSE 1.6132906818135342 Test RE 0.6071057874639795\n",
      "27 Train Loss 0.9842315 Test MSE 1.3288669638030757 Test RE 0.550996465134303\n",
      "28 Train Loss 0.80633914 Test MSE 1.0126750622493312 Test RE 0.48099783096540505\n",
      "29 Train Loss 0.60760164 Test MSE 0.6580463515987116 Test RE 0.3877361583871957\n",
      "30 Train Loss 0.402697 Test MSE 0.30889314558817377 Test RE 0.2656514531699141\n",
      "31 Train Loss 0.29937053 Test MSE 0.27096840612953427 Test RE 0.2488097464482036\n",
      "32 Train Loss 0.20551994 Test MSE 0.15280286167957285 Test RE 0.18684169743724402\n",
      "33 Train Loss 0.14847644 Test MSE 0.07444015966779491 Test RE 0.1304102442364941\n",
      "34 Train Loss 0.10000241 Test MSE 0.05836516790226336 Test RE 0.11547419142056888\n",
      "35 Train Loss 0.07839946 Test MSE 0.0433770385525753 Test RE 0.09954925391470776\n",
      "36 Train Loss 0.0623568 Test MSE 0.03694879003809459 Test RE 0.0918772887349915\n",
      "37 Train Loss 0.052445915 Test MSE 0.02933705103059991 Test RE 0.08186839728748618\n",
      "38 Train Loss 0.04405345 Test MSE 0.026442203498276605 Test RE 0.0777243111849555\n",
      "39 Train Loss 0.038695462 Test MSE 0.025023633330606074 Test RE 0.07561069745708858\n",
      "40 Train Loss 0.030186206 Test MSE 0.02218378551153495 Test RE 0.07119113042567755\n",
      "41 Train Loss 0.02516141 Test MSE 0.02187133586005567 Test RE 0.07068800341111861\n",
      "42 Train Loss 0.02120188 Test MSE 0.018559345610341737 Test RE 0.06511625120156264\n",
      "43 Train Loss 0.01711315 Test MSE 0.014775697855506021 Test RE 0.05810079315635721\n",
      "44 Train Loss 0.015317254 Test MSE 0.013264326199699646 Test RE 0.055049155014522684\n",
      "45 Train Loss 0.0134206135 Test MSE 0.011252352296210594 Test RE 0.05070254051161839\n",
      "46 Train Loss 0.011767172 Test MSE 0.009525743291385124 Test RE 0.04665062827562346\n",
      "47 Train Loss 0.010745395 Test MSE 0.008436938860440538 Test RE 0.04390363824713374\n",
      "48 Train Loss 0.009770637 Test MSE 0.007932224550878973 Test RE 0.04257018723139304\n",
      "49 Train Loss 0.0089300675 Test MSE 0.007096952495519787 Test RE 0.04026651181282792\n",
      "50 Train Loss 0.008145254 Test MSE 0.006094888166413057 Test RE 0.03731564312019893\n",
      "51 Train Loss 0.0072812946 Test MSE 0.0049943727874907405 Test RE 0.03377913608250147\n",
      "52 Train Loss 0.0067186984 Test MSE 0.004488448016631729 Test RE 0.03202256826497936\n",
      "53 Train Loss 0.006290228 Test MSE 0.004656091610761308 Test RE 0.032615107823811426\n",
      "54 Train Loss 0.0058286013 Test MSE 0.004718827927303648 Test RE 0.032834101077062645\n",
      "55 Train Loss 0.0053851875 Test MSE 0.0043984620838089 Test RE 0.03169994338331757\n",
      "56 Train Loss 0.005164765 Test MSE 0.004066691609415161 Test RE 0.03048096274417701\n",
      "57 Train Loss 0.0049074013 Test MSE 0.0036687540996260936 Test RE 0.02895125284291583\n",
      "58 Train Loss 0.0046035945 Test MSE 0.0032894778890683067 Test RE 0.02741394556335835\n",
      "59 Train Loss 0.0043748342 Test MSE 0.0033380251467697705 Test RE 0.027615496912968635\n",
      "60 Train Loss 0.004073856 Test MSE 0.003303053744313937 Test RE 0.02747045674391308\n",
      "61 Train Loss 0.0038401072 Test MSE 0.00333830159850172 Test RE 0.02761664043249799\n",
      "62 Train Loss 0.0033781677 Test MSE 0.0034069136170162407 Test RE 0.027898999000242036\n",
      "63 Train Loss 0.003091332 Test MSE 0.0030719691835659354 Test RE 0.026492106218729702\n",
      "64 Train Loss 0.0028237435 Test MSE 0.0028553154633640158 Test RE 0.025540836029291185\n",
      "65 Train Loss 0.0026173417 Test MSE 0.002822737776975241 Test RE 0.02539471411350801\n",
      "66 Train Loss 0.0024756 Test MSE 0.0027254897085479198 Test RE 0.02495343477166161\n",
      "67 Train Loss 0.0023105247 Test MSE 0.0025010158453434485 Test RE 0.023903763421992182\n",
      "68 Train Loss 0.0021964754 Test MSE 0.0024448347276524334 Test RE 0.02363375957810178\n",
      "69 Train Loss 0.0020996777 Test MSE 0.002362471073659388 Test RE 0.023232252014977882\n",
      "70 Train Loss 0.0020361715 Test MSE 0.002303230516932166 Test RE 0.02293912053094358\n",
      "71 Train Loss 0.0019618613 Test MSE 0.002364408940438656 Test RE 0.023241778434436613\n",
      "72 Train Loss 0.001863572 Test MSE 0.0023424641843188916 Test RE 0.02313367020485349\n",
      "73 Train Loss 0.0017700703 Test MSE 0.0022195481413641014 Test RE 0.02251854598698059\n",
      "74 Train Loss 0.0016686016 Test MSE 0.0020654792411991846 Test RE 0.021722933741848006\n",
      "75 Train Loss 0.0015615614 Test MSE 0.0020501130583304075 Test RE 0.02164197874810791\n",
      "76 Train Loss 0.0014751795 Test MSE 0.0020115835295731765 Test RE 0.02143764603295656\n",
      "77 Train Loss 0.0013933098 Test MSE 0.001881945295696361 Test RE 0.020735358952362334\n",
      "78 Train Loss 0.0013416852 Test MSE 0.0018502017997039908 Test RE 0.020559739601053572\n",
      "79 Train Loss 0.0012940846 Test MSE 0.0017982166765949561 Test RE 0.02026884823011883\n",
      "80 Train Loss 0.0012433467 Test MSE 0.001682972013145251 Test RE 0.019608596384290015\n",
      "81 Train Loss 0.0012070177 Test MSE 0.0016625929949247015 Test RE 0.019489515075884818\n",
      "82 Train Loss 0.0011481611 Test MSE 0.0015502170194110461 Test RE 0.018819336622250243\n",
      "83 Train Loss 0.0010999835 Test MSE 0.0013410879508146453 Test RE 0.017503975249147534\n",
      "84 Train Loss 0.001070529 Test MSE 0.00125821873920715 Test RE 0.016954544822560206\n",
      "85 Train Loss 0.0010421332 Test MSE 0.0011691727378599606 Test RE 0.016343587796027514\n",
      "86 Train Loss 0.0010108673 Test MSE 0.0010814034499803812 Test RE 0.015718168338148607\n",
      "87 Train Loss 0.0009742312 Test MSE 0.0010730619976284717 Test RE 0.01565742959752844\n",
      "88 Train Loss 0.0009273484 Test MSE 0.0011148174687350717 Test RE 0.01595915684439262\n",
      "89 Train Loss 0.0008867229 Test MSE 0.0011001119494745168 Test RE 0.015853549073942975\n",
      "90 Train Loss 0.00086332107 Test MSE 0.0011398231576199695 Test RE 0.016137148605303735\n",
      "91 Train Loss 0.0008449373 Test MSE 0.0011420430289033326 Test RE 0.01615285497517564\n",
      "92 Train Loss 0.00082108524 Test MSE 0.0011235485212896623 Test RE 0.0160215296014491\n",
      "93 Train Loss 0.00079588976 Test MSE 0.00117037344606909 Test RE 0.016351977849818265\n",
      "94 Train Loss 0.00076413644 Test MSE 0.0011717133954582961 Test RE 0.016361335783826512\n",
      "95 Train Loss 0.0007498555 Test MSE 0.001152820548115253 Test RE 0.016228893665656732\n",
      "96 Train Loss 0.0007259094 Test MSE 0.0011530580685743406 Test RE 0.016230565433110477\n",
      "97 Train Loss 0.0006914684 Test MSE 0.0011429260649234486 Test RE 0.01615909852130501\n",
      "98 Train Loss 0.00066430046 Test MSE 0.0011689324075828767 Test RE 0.016341907949788508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.00064471585 Test MSE 0.0011830882620133415 Test RE 0.016440561007349364\n",
      "Training time: 122.79\n",
      "1\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 55.09339 Test MSE 8.866017273045646 Test RE 1.4232210116739588\n",
      "1 Train Loss 46.374386 Test MSE 9.103483069161276 Test RE 1.442154716694446\n",
      "2 Train Loss 41.317986 Test MSE 9.01004314724915 Test RE 1.434734348215515\n",
      "3 Train Loss 38.90364 Test MSE 9.28955199866885 Test RE 1.4568184913472106\n",
      "4 Train Loss 37.066734 Test MSE 9.169491151065094 Test RE 1.4473737042712334\n",
      "5 Train Loss 34.513027 Test MSE 9.089298931722384 Test RE 1.4410307680484888\n",
      "6 Train Loss 31.309319 Test MSE 8.854623499553195 Test RE 1.422306222628205\n",
      "7 Train Loss 28.030888 Test MSE 8.862166626462043 Test RE 1.422911914808165\n",
      "8 Train Loss 24.76106 Test MSE 8.927476842022985 Test RE 1.4281454034889127\n",
      "9 Train Loss 21.374023 Test MSE 8.771407491511706 Test RE 1.4156070080873107\n",
      "10 Train Loss 17.592426 Test MSE 8.674058947114785 Test RE 1.4077296076620214\n",
      "11 Train Loss 15.446152 Test MSE 8.261569001113726 Test RE 1.3738500298573606\n",
      "12 Train Loss 13.438618 Test MSE 7.950511040178977 Test RE 1.3477383386547896\n",
      "13 Train Loss 11.709408 Test MSE 7.6707918352700455 Test RE 1.3238176251590936\n",
      "14 Train Loss 9.173986 Test MSE 6.755661293343014 Test RE 1.2423443635398355\n",
      "15 Train Loss 7.75979 Test MSE 6.254059429622555 Test RE 1.195333420563321\n",
      "16 Train Loss 6.439685 Test MSE 6.075421041136483 Test RE 1.178138235149214\n",
      "17 Train Loss 5.548866 Test MSE 5.822778583238086 Test RE 1.1533820766198313\n",
      "18 Train Loss 4.9620247 Test MSE 5.700030206409969 Test RE 1.141160258866666\n",
      "19 Train Loss 4.4098053 Test MSE 5.863300788775592 Test RE 1.1573884587896237\n",
      "20 Train Loss 3.6309204 Test MSE 5.592101066374785 Test RE 1.130304785167556\n",
      "21 Train Loss 3.0710075 Test MSE 5.287994462528095 Test RE 1.099141374485008\n",
      "22 Train Loss 2.7334013 Test MSE 5.156404422440557 Test RE 1.085379329451064\n",
      "23 Train Loss 2.4551325 Test MSE 5.06278465115112 Test RE 1.0754811122997527\n",
      "24 Train Loss 2.217094 Test MSE 5.13276875363436 Test RE 1.0828889185636248\n",
      "25 Train Loss 2.0651875 Test MSE 5.1116934838537915 Test RE 1.0806634480119452\n",
      "26 Train Loss 1.9811335 Test MSE 5.173195912095113 Test RE 1.087145126037405\n",
      "27 Train Loss 1.9130299 Test MSE 5.213531080082446 Test RE 1.0913751068053905\n",
      "28 Train Loss 1.8143873 Test MSE 5.210831957753878 Test RE 1.0910925596949637\n",
      "29 Train Loss 1.713407 Test MSE 5.246636515646577 Test RE 1.0948346885035873\n",
      "30 Train Loss 1.6200591 Test MSE 5.352270622357062 Test RE 1.1058012903321117\n",
      "31 Train Loss 1.5544418 Test MSE 5.400965713738977 Test RE 1.1108202044637006\n",
      "32 Train Loss 1.4562849 Test MSE 5.5322740692200965 Test RE 1.124242253432663\n",
      "33 Train Loss 1.3820889 Test MSE 5.546022365810731 Test RE 1.1256383181382137\n",
      "34 Train Loss 1.3094133 Test MSE 5.51554314139939 Test RE 1.122540976660615\n",
      "35 Train Loss 1.2263004 Test MSE 5.582945798156338 Test RE 1.129379150749893\n",
      "36 Train Loss 1.1799196 Test MSE 5.598699698283792 Test RE 1.1309714635948167\n",
      "37 Train Loss 1.117962 Test MSE 5.692077644936322 Test RE 1.1403639196934945\n",
      "38 Train Loss 1.0752481 Test MSE 5.7795653328234335 Test RE 1.1490942434210454\n",
      "39 Train Loss 1.0353645 Test MSE 5.774963260639762 Test RE 1.148636659893966\n",
      "40 Train Loss 1.0025469 Test MSE 5.845525630988215 Test RE 1.155632760167625\n",
      "41 Train Loss 0.9739114 Test MSE 5.898768851522386 Test RE 1.160883796568171\n",
      "42 Train Loss 0.95031947 Test MSE 5.928099172230367 Test RE 1.1637663365033326\n",
      "43 Train Loss 0.9305844 Test MSE 5.9971899173659216 Test RE 1.1705284164845358\n",
      "44 Train Loss 0.9108336 Test MSE 6.042524843140911 Test RE 1.174944310507461\n",
      "45 Train Loss 0.88758063 Test MSE 6.08230908151449 Test RE 1.178805906151654\n",
      "46 Train Loss 0.86737704 Test MSE 6.164844513462117 Test RE 1.186777008293932\n",
      "47 Train Loss 0.8475457 Test MSE 6.207801693579448 Test RE 1.1909046138117914\n",
      "48 Train Loss 0.83425564 Test MSE 6.233058199512275 Test RE 1.1933247586351017\n",
      "49 Train Loss 0.8209725 Test MSE 6.2909921909854285 Test RE 1.1988576898613144\n",
      "50 Train Loss 0.80362004 Test MSE 6.304623054219368 Test RE 1.200155785806643\n",
      "51 Train Loss 0.78867084 Test MSE 6.352010047397964 Test RE 1.2046576654557057\n",
      "52 Train Loss 0.77398026 Test MSE 6.384633093609501 Test RE 1.207747181390446\n",
      "53 Train Loss 0.76403093 Test MSE 6.392591228010863 Test RE 1.2084996460251847\n",
      "54 Train Loss 0.7551762 Test MSE 6.431480963697615 Test RE 1.2121700644482287\n",
      "55 Train Loss 0.74036086 Test MSE 6.492123664443766 Test RE 1.217871457218946\n",
      "56 Train Loss 0.72991973 Test MSE 6.511585758273568 Test RE 1.2196955592122447\n",
      "57 Train Loss 0.72172296 Test MSE 6.5502030649034815 Test RE 1.2233069475273728\n",
      "58 Train Loss 0.7149659 Test MSE 6.571229562628693 Test RE 1.2252688143143096\n",
      "59 Train Loss 0.70709884 Test MSE 6.5827221029409735 Test RE 1.226339793471299\n",
      "60 Train Loss 0.6986226 Test MSE 6.626741337112127 Test RE 1.2304332818266344\n",
      "61 Train Loss 0.69163793 Test MSE 6.646509702788944 Test RE 1.2322671803243936\n",
      "62 Train Loss 0.68455833 Test MSE 6.66142835085384 Test RE 1.2336493686303898\n",
      "63 Train Loss 0.67644525 Test MSE 6.683675346698545 Test RE 1.2357076446328017\n",
      "64 Train Loss 0.66621315 Test MSE 6.71773265885358 Test RE 1.238851977882995\n",
      "65 Train Loss 0.6581847 Test MSE 6.7354208889209115 Test RE 1.2404818948668561\n",
      "66 Train Loss 0.650779 Test MSE 6.728815582341945 Test RE 1.2398734864829375\n",
      "67 Train Loss 0.6460466 Test MSE 6.73316208885743 Test RE 1.2402738725628915\n",
      "68 Train Loss 0.64091086 Test MSE 6.7467918169373515 Test RE 1.2415285616073708\n",
      "69 Train Loss 0.6350759 Test MSE 6.754504500532235 Test RE 1.242237993749197\n",
      "70 Train Loss 0.62993526 Test MSE 6.7937706463360605 Test RE 1.245843529360166\n",
      "71 Train Loss 0.62375814 Test MSE 6.81413764741398 Test RE 1.2477095849769837\n",
      "72 Train Loss 0.61918247 Test MSE 6.82710247818725 Test RE 1.2488959901645147\n",
      "73 Train Loss 0.614153 Test MSE 6.840047687149688 Test RE 1.2500794763511118\n",
      "74 Train Loss 0.61027753 Test MSE 6.841090328728748 Test RE 1.250174748725897\n",
      "75 Train Loss 0.6061919 Test MSE 6.841599421399041 Test RE 1.2502212649192426\n",
      "76 Train Loss 0.60157144 Test MSE 6.834679927646117 Test RE 1.2495888772161439\n",
      "77 Train Loss 0.5976192 Test MSE 6.8457913800459576 Test RE 1.2506042216646458\n",
      "78 Train Loss 0.5941421 Test MSE 6.8580871523051705 Test RE 1.2517268271669286\n",
      "79 Train Loss 0.59046483 Test MSE 6.855977565752543 Test RE 1.2515342932195874\n",
      "80 Train Loss 0.5870714 Test MSE 6.859961855534523 Test RE 1.2518978993572647\n",
      "81 Train Loss 0.58357257 Test MSE 6.869463696595505 Test RE 1.2527646110723651\n",
      "82 Train Loss 0.5806761 Test MSE 6.881097986995523 Test RE 1.2538250185507986\n",
      "83 Train Loss 0.577751 Test MSE 6.885728292441932 Test RE 1.2542467983672418\n",
      "84 Train Loss 0.5755848 Test MSE 6.879445919356233 Test RE 1.2536744954738852\n",
      "85 Train Loss 0.57284456 Test MSE 6.889777459510707 Test RE 1.2546155254072462\n",
      "86 Train Loss 0.570596 Test MSE 6.8888291800343655 Test RE 1.2545291824810443\n",
      "87 Train Loss 0.5678965 Test MSE 6.894642833369059 Test RE 1.255058434945716\n",
      "88 Train Loss 0.56485116 Test MSE 6.90334627817362 Test RE 1.2558503459256676\n",
      "89 Train Loss 0.5620087 Test MSE 6.898371710694977 Test RE 1.2553977800322769\n",
      "90 Train Loss 0.560228 Test MSE 6.912908616584145 Test RE 1.2567198307958516\n",
      "91 Train Loss 0.55829436 Test MSE 6.915275455104133 Test RE 1.2569349499674578\n",
      "92 Train Loss 0.55586004 Test MSE 6.910093341812574 Test RE 1.2564639058214977\n",
      "93 Train Loss 0.55326116 Test MSE 6.927627548494149 Test RE 1.2580570203116477\n",
      "94 Train Loss 0.5517284 Test MSE 6.937532541787816 Test RE 1.2589560723536504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.55026585 Test MSE 6.940558564617169 Test RE 1.2592306090467247\n",
      "96 Train Loss 0.5484024 Test MSE 6.950297508172217 Test RE 1.260113771164349\n",
      "97 Train Loss 0.5468545 Test MSE 6.959828115175885 Test RE 1.260977441739334\n",
      "98 Train Loss 0.5452397 Test MSE 6.966955240148569 Test RE 1.2616229206254899\n",
      "99 Train Loss 0.5436082 Test MSE 6.967761413507717 Test RE 1.2616959121498916\n",
      "Training time: 122.52\n",
      "2\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 52.043118 Test MSE 8.08120416898969 Test RE 1.3587704701782326\n",
      "1 Train Loss 40.19985 Test MSE 7.144914785463186 Test RE 1.2776343719576573\n",
      "2 Train Loss 29.69207 Test MSE 6.722114596811974 Test RE 1.2392559599863613\n",
      "3 Train Loss 22.138847 Test MSE 6.352153638341485 Test RE 1.2046712813782212\n",
      "4 Train Loss 16.441105 Test MSE 6.0283773273073065 Test RE 1.1735680410861435\n",
      "5 Train Loss 13.777931 Test MSE 5.979024008147694 Test RE 1.1687542655907006\n",
      "6 Train Loss 11.875589 Test MSE 6.1609469520255 Test RE 1.1864017946436909\n",
      "7 Train Loss 10.852645 Test MSE 5.858402749289049 Test RE 1.1569049326164635\n",
      "8 Train Loss 10.021424 Test MSE 5.873365855639833 Test RE 1.1583814316575243\n",
      "9 Train Loss 8.842736 Test MSE 5.7438367330692 Test RE 1.1455369538204918\n",
      "10 Train Loss 7.433644 Test MSE 5.4600310381630335 Test RE 1.1168776904741082\n",
      "11 Train Loss 6.3044124 Test MSE 5.330818015050762 Test RE 1.1035829664821357\n",
      "12 Train Loss 5.0789475 Test MSE 5.302325692352569 Test RE 1.1006297827667006\n",
      "13 Train Loss 4.2594094 Test MSE 5.052328254085284 Test RE 1.0743699184739235\n",
      "14 Train Loss 3.5486846 Test MSE 5.0178263549975455 Test RE 1.0706952460430748\n",
      "15 Train Loss 3.0907648 Test MSE 4.846958392734187 Test RE 1.0523075978974643\n",
      "16 Train Loss 2.7152479 Test MSE 4.602182254193828 Test RE 1.025392099674286\n",
      "17 Train Loss 2.3902714 Test MSE 4.4054613000440686 Test RE 1.003237495983505\n",
      "18 Train Loss 2.1394835 Test MSE 4.0935633768187865 Test RE 0.9670720231063505\n",
      "19 Train Loss 1.952354 Test MSE 3.7289513018843454 Test RE 0.92299939456107\n",
      "20 Train Loss 1.7528533 Test MSE 3.3718500530418396 Test RE 0.877692095028558\n",
      "21 Train Loss 1.6222831 Test MSE 3.0599641574128387 Test RE 0.8361154143212858\n",
      "22 Train Loss 1.4991758 Test MSE 2.798569359741569 Test RE 0.799606098452446\n",
      "23 Train Loss 1.400998 Test MSE 2.6654229086467542 Test RE 0.7803530341124078\n",
      "24 Train Loss 1.2695272 Test MSE 2.5036047660745044 Test RE 0.7562945052461715\n",
      "25 Train Loss 1.1698109 Test MSE 2.3892092321827487 Test RE 0.7388140612141166\n",
      "26 Train Loss 1.0391994 Test MSE 2.1569833384855346 Test RE 0.701990856590122\n",
      "27 Train Loss 0.92398274 Test MSE 1.9920011026511943 Test RE 0.674610113255132\n",
      "28 Train Loss 0.8571129 Test MSE 1.871008851179527 Test RE 0.653801603354363\n",
      "29 Train Loss 0.79892623 Test MSE 1.7240539434866926 Test RE 0.6276007955011137\n",
      "30 Train Loss 0.7245161 Test MSE 1.3867238126995576 Test RE 0.5628634482040331\n",
      "31 Train Loss 0.6187392 Test MSE 1.0636553374678095 Test RE 0.4929564144908823\n",
      "32 Train Loss 0.5162606 Test MSE 0.8901141213010778 Test RE 0.4509526109579469\n",
      "33 Train Loss 0.42528522 Test MSE 0.7507200363414266 Test RE 0.41413989003017926\n",
      "34 Train Loss 0.32373044 Test MSE 0.5930991501938999 Test RE 0.3681049954393114\n",
      "35 Train Loss 0.25440368 Test MSE 0.5163214461364429 Test RE 0.3434536550396398\n",
      "36 Train Loss 0.19762899 Test MSE 0.43171029190551946 Test RE 0.3140539509625922\n",
      "37 Train Loss 0.15003878 Test MSE 0.3392302020272034 Test RE 0.2783910799762576\n",
      "38 Train Loss 0.11938484 Test MSE 0.2818282837522032 Test RE 0.25374666805689616\n",
      "39 Train Loss 0.09463489 Test MSE 0.24155096555623148 Test RE 0.23491591986651744\n",
      "40 Train Loss 0.07800154 Test MSE 0.21941597457922254 Test RE 0.22389385902137346\n",
      "41 Train Loss 0.069332935 Test MSE 0.2131755666292851 Test RE 0.2206870113552938\n",
      "42 Train Loss 0.0629636 Test MSE 0.19598428981887758 Test RE 0.21160147468560464\n",
      "43 Train Loss 0.057955034 Test MSE 0.18285025619195305 Test RE 0.2043882131390477\n",
      "44 Train Loss 0.05376051 Test MSE 0.17738807105077536 Test RE 0.20131227921212128\n",
      "45 Train Loss 0.049562898 Test MSE 0.1656865448066624 Test RE 0.19455915928487796\n",
      "46 Train Loss 0.04568445 Test MSE 0.15181763065621975 Test RE 0.1862383712848568\n",
      "47 Train Loss 0.040746346 Test MSE 0.1369942924190325 Test RE 0.17691281667186284\n",
      "48 Train Loss 0.03680006 Test MSE 0.12495091592947594 Test RE 0.16895761961540595\n",
      "49 Train Loss 0.032673515 Test MSE 0.10562080380600586 Test RE 0.15533981886893203\n",
      "50 Train Loss 0.029119598 Test MSE 0.09083494023267127 Test RE 0.14405705352092635\n",
      "51 Train Loss 0.025745226 Test MSE 0.08482342497833631 Test RE 0.13920856684854263\n",
      "52 Train Loss 0.024197701 Test MSE 0.08106426734902764 Test RE 0.13608892743197643\n",
      "53 Train Loss 0.021931212 Test MSE 0.06783194024437278 Test RE 0.12448733797118598\n",
      "54 Train Loss 0.02017755 Test MSE 0.060879177878679594 Test RE 0.11793492896429127\n",
      "55 Train Loss 0.018607749 Test MSE 0.06033578347188809 Test RE 0.11740741834888237\n",
      "56 Train Loss 0.016675321 Test MSE 0.054354780764812864 Test RE 0.1114363643083561\n",
      "57 Train Loss 0.015206852 Test MSE 0.04924195890480205 Test RE 0.10606588523200128\n",
      "58 Train Loss 0.01376598 Test MSE 0.04447404207231183 Test RE 0.10080019251782518\n",
      "59 Train Loss 0.011923142 Test MSE 0.033770326048858164 Test RE 0.08783663448050358\n",
      "60 Train Loss 0.010878936 Test MSE 0.028502685753798288 Test RE 0.08069580393394074\n",
      "61 Train Loss 0.010137526 Test MSE 0.026613772880749596 Test RE 0.07797605932039751\n",
      "62 Train Loss 0.009600326 Test MSE 0.026331170613343714 Test RE 0.07756095428023596\n",
      "63 Train Loss 0.00902173 Test MSE 0.025978939541397555 Test RE 0.07704044272996456\n",
      "64 Train Loss 0.008099797 Test MSE 0.022130815585429977 Test RE 0.0711060853670372\n",
      "65 Train Loss 0.007517725 Test MSE 0.019824272429499 Test RE 0.06729870213919634\n",
      "66 Train Loss 0.006755595 Test MSE 0.017459803117878987 Test RE 0.06315790728195349\n",
      "67 Train Loss 0.0063500493 Test MSE 0.015675713021482147 Test RE 0.05984415131301081\n",
      "68 Train Loss 0.0059473915 Test MSE 0.014784175195813851 Test RE 0.058117458006095093\n",
      "69 Train Loss 0.0055445917 Test MSE 0.013976349657682461 Test RE 0.056507349742783965\n",
      "70 Train Loss 0.0052351505 Test MSE 0.012918811931146417 Test RE 0.054327453436555886\n",
      "71 Train Loss 0.004889802 Test MSE 0.012707873907388128 Test RE 0.053882099401988987\n",
      "72 Train Loss 0.004619294 Test MSE 0.011580813625330477 Test RE 0.05143723279242688\n",
      "73 Train Loss 0.004374622 Test MSE 0.010106705899081692 Test RE 0.04805215555730515\n",
      "74 Train Loss 0.004159325 Test MSE 0.009241970883416141 Test RE 0.04595051236122041\n",
      "75 Train Loss 0.0039052 Test MSE 0.008557944485009107 Test RE 0.04421735829911276\n",
      "76 Train Loss 0.0037510907 Test MSE 0.008481146174224293 Test RE 0.044018509658635845\n",
      "77 Train Loss 0.0035545174 Test MSE 0.008010946879474708 Test RE 0.04278090684440798\n",
      "78 Train Loss 0.0033757791 Test MSE 0.007401589509572694 Test RE 0.041121652435376015\n",
      "79 Train Loss 0.0032526823 Test MSE 0.00745047585320781 Test RE 0.04125722998516353\n",
      "80 Train Loss 0.0030469403 Test MSE 0.0072536479401968884 Test RE 0.04070861217439613\n",
      "81 Train Loss 0.0029153507 Test MSE 0.006775862820229058 Test RE 0.03934507366446777\n",
      "82 Train Loss 0.0027696192 Test MSE 0.006296454210576925 Test RE 0.037927663131627334\n",
      "83 Train Loss 0.0026792027 Test MSE 0.006117850504029738 Test RE 0.03738586991064106\n",
      "84 Train Loss 0.0025613927 Test MSE 0.006124396778516404 Test RE 0.037405866536252955\n",
      "85 Train Loss 0.0024379857 Test MSE 0.006101345476241709 Test RE 0.03733540516296161\n",
      "86 Train Loss 0.0023300052 Test MSE 0.005728935586144301 Test RE 0.03617803960852507\n",
      "87 Train Loss 0.002215518 Test MSE 0.005290494813728103 Test RE 0.03476611855188286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Train Loss 0.00216577 Test MSE 0.0053546298467544206 Test RE 0.034976213195370705\n",
      "89 Train Loss 0.0021070489 Test MSE 0.005193857438078999 Test RE 0.034447132274593145\n",
      "90 Train Loss 0.0020345342 Test MSE 0.004854399581712274 Test RE 0.03330242210275749\n",
      "91 Train Loss 0.0019842172 Test MSE 0.0047908374899960394 Test RE 0.03308367760014327\n",
      "92 Train Loss 0.0018982613 Test MSE 0.00470612671725281 Test RE 0.03278988312495667\n",
      "93 Train Loss 0.0018525423 Test MSE 0.004542546329594194 Test RE 0.03221497086975112\n",
      "94 Train Loss 0.0017956248 Test MSE 0.0043153072302028915 Test RE 0.031398862916644205\n",
      "95 Train Loss 0.0017280291 Test MSE 0.00422318265664333 Test RE 0.031061898269808708\n",
      "96 Train Loss 0.0016722216 Test MSE 0.004195115593982947 Test RE 0.03095850828393369\n",
      "97 Train Loss 0.0016282692 Test MSE 0.0040706961058708056 Test RE 0.030495966448077665\n",
      "98 Train Loss 0.0015836256 Test MSE 0.004059058011910473 Test RE 0.030452341358922982\n",
      "99 Train Loss 0.0015038777 Test MSE 0.003952033508038239 Test RE 0.030048193642959888\n",
      "Training time: 122.71\n",
      "3\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 52.980984 Test MSE 9.278589008977823 Test RE 1.455958611294644\n",
      "1 Train Loss 48.82651 Test MSE 8.79544759200087 Test RE 1.417545582309582\n",
      "2 Train Loss 44.135353 Test MSE 8.572458815149995 Test RE 1.3994608834231874\n",
      "3 Train Loss 40.77047 Test MSE 8.730336931233072 Test RE 1.4122889550776758\n",
      "4 Train Loss 36.77471 Test MSE 9.04037516842565 Test RE 1.4371473127054954\n",
      "5 Train Loss 33.63231 Test MSE 9.03859492927345 Test RE 1.437005803540656\n",
      "6 Train Loss 31.037628 Test MSE 9.308322581032787 Test RE 1.458289581225689\n",
      "7 Train Loss 28.580616 Test MSE 9.208912457215598 Test RE 1.4504816285526332\n",
      "8 Train Loss 26.326284 Test MSE 9.25412547514104 Test RE 1.4540379851695753\n",
      "9 Train Loss 23.893097 Test MSE 9.315919018929502 Test RE 1.4588845083428028\n",
      "10 Train Loss 21.55638 Test MSE 9.060941401815972 Test RE 1.4387810898288043\n",
      "11 Train Loss 19.858608 Test MSE 8.856068561390423 Test RE 1.422422277059756\n",
      "12 Train Loss 18.254475 Test MSE 8.854123091449821 Test RE 1.422266032121218\n",
      "13 Train Loss 16.601624 Test MSE 8.844638023224427 Test RE 1.4215040196074622\n",
      "14 Train Loss 15.158394 Test MSE 8.55525106520977 Test RE 1.3980555882499865\n",
      "15 Train Loss 13.930147 Test MSE 8.407184630341714 Test RE 1.3859046528623384\n",
      "16 Train Loss 11.463309 Test MSE 7.161528522333707 Test RE 1.2791189212569916\n",
      "17 Train Loss 8.940725 Test MSE 6.714711754102104 Test RE 1.2385733961912149\n",
      "18 Train Loss 7.5287933 Test MSE 6.799091561148365 Test RE 1.2463313092816926\n",
      "19 Train Loss 6.7593374 Test MSE 6.666531526031686 Test RE 1.2341218141217596\n",
      "20 Train Loss 6.1540976 Test MSE 6.600530614890796 Test RE 1.2279975070879925\n",
      "21 Train Loss 5.559955 Test MSE 6.537129243209438 Test RE 1.222085513233987\n",
      "22 Train Loss 5.1683955 Test MSE 6.469941764908698 Test RE 1.2157891018319735\n",
      "23 Train Loss 4.7370787 Test MSE 6.4583064823864875 Test RE 1.214695396830596\n",
      "24 Train Loss 4.2784624 Test MSE 6.293668392521498 Test RE 1.1991126610608378\n",
      "25 Train Loss 3.5871897 Test MSE 6.167352931931494 Test RE 1.1870184280572393\n",
      "26 Train Loss 3.0047898 Test MSE 6.065148006060352 Test RE 1.1771417465125287\n",
      "27 Train Loss 2.3925643 Test MSE 5.902933381553835 Test RE 1.1612935161690943\n",
      "28 Train Loss 1.841738 Test MSE 5.781825249023651 Test RE 1.1493188799414151\n",
      "29 Train Loss 1.5102385 Test MSE 5.755117960756353 Test RE 1.1466613524248692\n",
      "30 Train Loss 1.3646052 Test MSE 5.699529169623706 Test RE 1.1411101033575584\n",
      "31 Train Loss 1.2673374 Test MSE 5.7044779120077465 Test RE 1.1416053929245549\n",
      "32 Train Loss 1.1990329 Test MSE 5.691943756855027 Test RE 1.1403505078916396\n",
      "33 Train Loss 1.1475112 Test MSE 5.704193392085912 Test RE 1.1415769228759047\n",
      "34 Train Loss 1.1050692 Test MSE 5.722134157589928 Test RE 1.1433707510106805\n",
      "35 Train Loss 1.0661461 Test MSE 5.741622586325474 Test RE 1.1453161404936056\n",
      "36 Train Loss 1.0366098 Test MSE 5.7632408532128725 Test RE 1.1474702778599848\n",
      "37 Train Loss 1.0188764 Test MSE 5.781790681613302 Test RE 1.1493154442584768\n",
      "38 Train Loss 1.0013134 Test MSE 5.835353093006705 Test RE 1.1546267910088521\n",
      "39 Train Loss 0.9816099 Test MSE 5.87274251673897 Test RE 1.1583199606556083\n",
      "40 Train Loss 0.9587503 Test MSE 5.886733749220294 Test RE 1.1596989316217468\n",
      "41 Train Loss 0.94319457 Test MSE 5.892570160224406 Test RE 1.1602736818202928\n",
      "42 Train Loss 0.9295093 Test MSE 5.888793844419667 Test RE 1.1599018354153643\n",
      "43 Train Loss 0.91301596 Test MSE 5.884692849305238 Test RE 1.159497883406446\n",
      "44 Train Loss 0.89972675 Test MSE 5.904927923648201 Test RE 1.1614896943254391\n",
      "45 Train Loss 0.88682866 Test MSE 5.917761095814265 Test RE 1.1627511413421205\n",
      "46 Train Loss 0.87638247 Test MSE 5.925133847396896 Test RE 1.1634752333369187\n",
      "47 Train Loss 0.8667898 Test MSE 5.922278622709464 Test RE 1.1631948697541077\n",
      "48 Train Loss 0.8573045 Test MSE 5.946280189158129 Test RE 1.1655495605053932\n",
      "49 Train Loss 0.8459846 Test MSE 5.991575413323105 Test RE 1.1699803701927332\n",
      "50 Train Loss 0.83727396 Test MSE 5.9877186805263545 Test RE 1.1696037557197816\n",
      "51 Train Loss 0.82677644 Test MSE 6.019124853858379 Test RE 1.1726670874649505\n",
      "52 Train Loss 0.8190342 Test MSE 6.0160507767708635 Test RE 1.1723675979628978\n",
      "53 Train Loss 0.8096037 Test MSE 6.009234098966719 Test RE 1.1717032154998535\n",
      "54 Train Loss 0.7985848 Test MSE 6.059175895787405 Test RE 1.1765620614242192\n",
      "55 Train Loss 0.79102254 Test MSE 6.0679494674788454 Test RE 1.1774135730592037\n",
      "56 Train Loss 0.78324044 Test MSE 6.088162598421155 Test RE 1.1793730017116049\n",
      "57 Train Loss 0.7763027 Test MSE 6.123417322371049 Test RE 1.182782770297349\n",
      "58 Train Loss 0.7688394 Test MSE 6.157380604363409 Test RE 1.186058362555463\n",
      "59 Train Loss 0.76315725 Test MSE 6.171205623074821 Test RE 1.1873891301596111\n",
      "60 Train Loss 0.7575918 Test MSE 6.160328722289757 Test RE 1.1863422674902444\n",
      "61 Train Loss 0.7509733 Test MSE 6.167364776197715 Test RE 1.1870195678781377\n",
      "62 Train Loss 0.7437215 Test MSE 6.201733904758802 Test RE 1.1903224492456097\n",
      "63 Train Loss 0.7371319 Test MSE 6.2276270794240425 Test RE 1.1928047488512648\n",
      "64 Train Loss 0.73136276 Test MSE 6.231444326264765 Test RE 1.193170259870556\n",
      "65 Train Loss 0.72661 Test MSE 6.222376891966428 Test RE 1.1923018471124105\n",
      "66 Train Loss 0.72156936 Test MSE 6.225740930427648 Test RE 1.1926241039743541\n",
      "67 Train Loss 0.716784 Test MSE 6.21910001302482 Test RE 1.1919878558992425\n",
      "68 Train Loss 0.71117836 Test MSE 6.2337304124588515 Test RE 1.1933891047955232\n",
      "69 Train Loss 0.7064723 Test MSE 6.239508099739067 Test RE 1.1939420186755925\n",
      "70 Train Loss 0.7025925 Test MSE 6.216568433631285 Test RE 1.1917452227979293\n",
      "71 Train Loss 0.69852996 Test MSE 6.229626373429184 Test RE 1.1929962002648449\n",
      "72 Train Loss 0.6940564 Test MSE 6.25617823959696 Test RE 1.195535886651732\n",
      "73 Train Loss 0.6899764 Test MSE 6.2720943612117805 Test RE 1.1970556809179733\n",
      "74 Train Loss 0.68486106 Test MSE 6.301070746878475 Test RE 1.1998176273729484\n",
      "75 Train Loss 0.6807234 Test MSE 6.320988247275449 Test RE 1.2017124254236666\n",
      "76 Train Loss 0.6775313 Test MSE 6.342206847699303 Test RE 1.2037277189064435\n",
      "77 Train Loss 0.6730434 Test MSE 6.361954053326933 Test RE 1.2056002362518983\n",
      "78 Train Loss 0.6698588 Test MSE 6.3705774788942096 Test RE 1.2064170358704869\n",
      "79 Train Loss 0.66683334 Test MSE 6.375084108032683 Test RE 1.2068436779603238\n",
      "80 Train Loss 0.6636339 Test MSE 6.381232818780194 Test RE 1.207425532581436\n",
      "81 Train Loss 0.6607524 Test MSE 6.3900502263027725 Test RE 1.2082594378865588\n",
      "82 Train Loss 0.6580495 Test MSE 6.408944319875581 Test RE 1.210044409507115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 Train Loss 0.6551026 Test MSE 6.415277209724926 Test RE 1.2106421043438431\n",
      "84 Train Loss 0.6521702 Test MSE 6.414302931751044 Test RE 1.2105501717052662\n",
      "85 Train Loss 0.64974654 Test MSE 6.428645639647893 Test RE 1.2119028418731685\n",
      "86 Train Loss 0.64611703 Test MSE 6.428891384628899 Test RE 1.2119260050875882\n",
      "87 Train Loss 0.64348465 Test MSE 6.438201079722605 Test RE 1.212803184312612\n",
      "88 Train Loss 0.64044476 Test MSE 6.471464627731484 Test RE 1.215932176619628\n",
      "89 Train Loss 0.6376103 Test MSE 6.477044810224069 Test RE 1.2164562976497173\n",
      "90 Train Loss 0.6348316 Test MSE 6.482789457280215 Test RE 1.216995630285159\n",
      "91 Train Loss 0.6317221 Test MSE 6.496975485873679 Test RE 1.2183264540400824\n",
      "92 Train Loss 0.6291796 Test MSE 6.515481022864796 Test RE 1.2200603187953083\n",
      "93 Train Loss 0.62647843 Test MSE 6.539948989195104 Test RE 1.2223490539315196\n",
      "94 Train Loss 0.62412035 Test MSE 6.555756465359139 Test RE 1.2238254103888724\n",
      "95 Train Loss 0.62156975 Test MSE 6.586578315374354 Test RE 1.2266989408203999\n",
      "96 Train Loss 0.618879 Test MSE 6.603363722816535 Test RE 1.2282610219802081\n",
      "97 Train Loss 0.6166104 Test MSE 6.6197007958434195 Test RE 1.2297794749216124\n",
      "98 Train Loss 0.6140335 Test MSE 6.629032589910854 Test RE 1.2306459798863418\n",
      "99 Train Loss 0.6117798 Test MSE 6.626799301240231 Test RE 1.2304386631168325\n",
      "Training time: 122.72\n",
      "4\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.901955 Test MSE 9.104663876147212 Test RE 1.442248244146202\n",
      "1 Train Loss 47.324554 Test MSE 8.24296451758382 Test RE 1.3723022502416091\n",
      "2 Train Loss 36.419075 Test MSE 7.4161934003383685 Test RE 1.3016630706891603\n",
      "3 Train Loss 28.654606 Test MSE 6.897980748513883 Test RE 1.2553622049698454\n",
      "4 Train Loss 24.40818 Test MSE 6.596731672016409 Test RE 1.2276440685468675\n",
      "5 Train Loss 21.238327 Test MSE 6.559898927410994 Test RE 1.2242120057227301\n",
      "6 Train Loss 18.925398 Test MSE 6.43976720881185 Test RE 1.2129506859847918\n",
      "7 Train Loss 16.862564 Test MSE 6.3098269811996754 Test RE 1.2006509966040217\n",
      "8 Train Loss 15.102385 Test MSE 6.150086227824924 Test RE 1.185355618917621\n",
      "9 Train Loss 13.803858 Test MSE 6.151952223114534 Test RE 1.1855354294251017\n",
      "10 Train Loss 12.620042 Test MSE 6.11704256250855 Test RE 1.1821669442711495\n",
      "11 Train Loss 11.26083 Test MSE 6.089134058825423 Test RE 1.17946709155021\n",
      "12 Train Loss 10.127242 Test MSE 5.907699073624337 Test RE 1.161762202698431\n",
      "13 Train Loss 8.617575 Test MSE 5.498296990112036 Test RE 1.120784606691068\n",
      "14 Train Loss 7.332795 Test MSE 5.317159615099716 Test RE 1.1021682825773036\n",
      "15 Train Loss 6.223988 Test MSE 5.214740813242447 Test RE 1.0915017192737166\n",
      "16 Train Loss 5.293173 Test MSE 5.079873916496707 Test RE 1.0772947089570584\n",
      "17 Train Loss 4.4927416 Test MSE 4.954373604255936 Test RE 1.0639039881119086\n",
      "18 Train Loss 3.563524 Test MSE 4.558001368979979 Test RE 1.020458355248261\n",
      "19 Train Loss 2.881234 Test MSE 4.447374754973359 Test RE 1.00799858750302\n",
      "20 Train Loss 2.4887328 Test MSE 4.1104939134201315 Test RE 0.9690698123679203\n",
      "21 Train Loss 2.1723127 Test MSE 3.7250253681170973 Test RE 0.9225133881127929\n",
      "22 Train Loss 1.8698409 Test MSE 3.3859033407983694 Test RE 0.8795192276291491\n",
      "23 Train Loss 1.7241378 Test MSE 3.0836101703469145 Test RE 0.8393397572909445\n",
      "24 Train Loss 1.5470206 Test MSE 2.7162365522641494 Test RE 0.7877562452089779\n",
      "25 Train Loss 1.4136386 Test MSE 2.477838249761029 Test RE 0.7523926366763888\n",
      "26 Train Loss 1.3017648 Test MSE 2.352025296814777 Test RE 0.7330423308544792\n",
      "27 Train Loss 1.2009686 Test MSE 2.190679807719519 Test RE 0.7074528701856895\n",
      "28 Train Loss 1.0376502 Test MSE 1.9387561378332236 Test RE 0.6655330898157354\n",
      "29 Train Loss 0.7674009 Test MSE 1.7501216162213697 Test RE 0.6323276528767686\n",
      "30 Train Loss 0.5842871 Test MSE 1.6479310556186635 Test RE 0.6135890199163501\n",
      "31 Train Loss 0.46576726 Test MSE 1.4745375815995274 Test RE 0.5804114658906355\n",
      "32 Train Loss 0.37476468 Test MSE 1.2366323617240689 Test RE 0.5315307129380147\n",
      "33 Train Loss 0.30501828 Test MSE 1.0428238026610928 Test RE 0.4881053051992485\n",
      "34 Train Loss 0.26498523 Test MSE 0.963092865431741 Test RE 0.46907484431081164\n",
      "35 Train Loss 0.23808075 Test MSE 0.9097265527331522 Test RE 0.4558936002866075\n",
      "36 Train Loss 0.21131271 Test MSE 0.8048251079945721 Test RE 0.42880399074574777\n",
      "37 Train Loss 0.1940223 Test MSE 0.751967692513576 Test RE 0.4144838862335046\n",
      "38 Train Loss 0.17831782 Test MSE 0.7387229474352817 Test RE 0.4108174242211272\n",
      "39 Train Loss 0.16479884 Test MSE 0.6914419241795718 Test RE 0.3974531236860711\n",
      "40 Train Loss 0.15266645 Test MSE 0.6601698109277537 Test RE 0.38836125023424034\n",
      "41 Train Loss 0.14212008 Test MSE 0.6531619023111517 Test RE 0.3862944627523497\n",
      "42 Train Loss 0.13339771 Test MSE 0.6429853322637981 Test RE 0.38327332403586745\n",
      "43 Train Loss 0.12737447 Test MSE 0.6393334891491875 Test RE 0.38218337144998865\n",
      "44 Train Loss 0.124254435 Test MSE 0.6222676502265698 Test RE 0.37704802671995524\n",
      "45 Train Loss 0.12042095 Test MSE 0.6165976569496463 Test RE 0.3753262981032527\n",
      "46 Train Loss 0.116798066 Test MSE 0.6185805155121409 Test RE 0.37592930202295577\n",
      "47 Train Loss 0.113127634 Test MSE 0.606710522237119 Test RE 0.37230496144224207\n",
      "48 Train Loss 0.109898575 Test MSE 0.6043923886887378 Test RE 0.3715930250564178\n",
      "49 Train Loss 0.107154645 Test MSE 0.6084565164379255 Test RE 0.3728402870035125\n",
      "50 Train Loss 0.105044134 Test MSE 0.6104206001285093 Test RE 0.3734415621197684\n",
      "51 Train Loss 0.10307224 Test MSE 0.6122295952230324 Test RE 0.3739945039677911\n",
      "52 Train Loss 0.10107075 Test MSE 0.603175418187531 Test RE 0.37121872714339077\n",
      "53 Train Loss 0.09945139 Test MSE 0.5935281250858665 Test RE 0.36823809229011284\n",
      "54 Train Loss 0.098140374 Test MSE 0.5991039026346555 Test RE 0.36996371740878875\n",
      "55 Train Loss 0.09643621 Test MSE 0.5849244441482981 Test RE 0.3655593915432182\n",
      "56 Train Loss 0.095187396 Test MSE 0.5828508947551887 Test RE 0.3649108646819632\n",
      "57 Train Loss 0.09335716 Test MSE 0.5891357710424832 Test RE 0.3668730048190842\n",
      "58 Train Loss 0.09226559 Test MSE 0.5795539576953054 Test RE 0.3638773290630829\n",
      "59 Train Loss 0.0904882 Test MSE 0.5860480526280897 Test RE 0.3659103330797382\n",
      "60 Train Loss 0.08946323 Test MSE 0.5952006479578899 Test RE 0.36875656254790556\n",
      "61 Train Loss 0.088227935 Test MSE 0.593088046016774 Test RE 0.3681015495380646\n",
      "62 Train Loss 0.087091744 Test MSE 0.5925798475612799 Test RE 0.36794380843142777\n",
      "63 Train Loss 0.08615704 Test MSE 0.5858644920242537 Test RE 0.3658530238013748\n",
      "64 Train Loss 0.084987424 Test MSE 0.5825921574897159 Test RE 0.36482986067162365\n",
      "65 Train Loss 0.08385995 Test MSE 0.5826932929365042 Test RE 0.36486152573038394\n",
      "66 Train Loss 0.082753934 Test MSE 0.5754965839320078 Test RE 0.36260136555251815\n",
      "67 Train Loss 0.082023665 Test MSE 0.5724254812930646 Test RE 0.36163257124067555\n",
      "68 Train Loss 0.08106098 Test MSE 0.5792123034248173 Test RE 0.3637700581444373\n",
      "69 Train Loss 0.080567166 Test MSE 0.5800546089934229 Test RE 0.3640344639841053\n",
      "70 Train Loss 0.07971264 Test MSE 0.5808284067634015 Test RE 0.3642771955914152\n",
      "71 Train Loss 0.078800194 Test MSE 0.5828922105362354 Test RE 0.36492379792986046\n",
      "72 Train Loss 0.07792022 Test MSE 0.5839310951410739 Test RE 0.36524885369163984\n",
      "73 Train Loss 0.07667802 Test MSE 0.5872617077325396 Test RE 0.36628902153521936\n",
      "74 Train Loss 0.075871445 Test MSE 0.5891280162861158 Test RE 0.3668705902482228\n",
      "75 Train Loss 0.07511936 Test MSE 0.5893994483962857 Test RE 0.3669550956428907\n",
      "76 Train Loss 0.07399189 Test MSE 0.5883800312899917 Test RE 0.36663761808686685\n",
      "77 Train Loss 0.07340385 Test MSE 0.5861695217356222 Test RE 0.3659482518976011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Train Loss 0.07287819 Test MSE 0.5862060708155337 Test RE 0.3659596605967237\n",
      "79 Train Loss 0.072306626 Test MSE 0.5871006181506645 Test RE 0.3662387803978466\n",
      "80 Train Loss 0.07159092 Test MSE 0.5910820086935332 Test RE 0.3674784962532402\n",
      "81 Train Loss 0.07087081 Test MSE 0.5948840687923796 Test RE 0.3686584811928448\n",
      "82 Train Loss 0.069819696 Test MSE 0.5937504511873745 Test RE 0.3683070538698288\n",
      "83 Train Loss 0.06886675 Test MSE 0.5946358556732874 Test RE 0.3685815624927073\n",
      "84 Train Loss 0.06789776 Test MSE 0.595556887991463 Test RE 0.36886690029724367\n",
      "85 Train Loss 0.06718719 Test MSE 0.5949216048230577 Test RE 0.3686701118268666\n",
      "86 Train Loss 0.06651929 Test MSE 0.5992524963456318 Test RE 0.3700095949878749\n",
      "87 Train Loss 0.06599712 Test MSE 0.6011384162751922 Test RE 0.3705913700442358\n",
      "88 Train Loss 0.065448835 Test MSE 0.6037018354134143 Test RE 0.3713806811191852\n",
      "89 Train Loss 0.06473405 Test MSE 0.6036428484328833 Test RE 0.37136253709603895\n",
      "90 Train Loss 0.06416608 Test MSE 0.6041789848052889 Test RE 0.37152741668902933\n",
      "91 Train Loss 0.06364981 Test MSE 0.6043542293785452 Test RE 0.37158129430203013\n",
      "92 Train Loss 0.06311477 Test MSE 0.6024986479710981 Test RE 0.3710104127119495\n",
      "93 Train Loss 0.062467534 Test MSE 0.6031802582972814 Test RE 0.3712202165407718\n",
      "94 Train Loss 0.061875127 Test MSE 0.6033444195416916 Test RE 0.37127072866055283\n",
      "95 Train Loss 0.061374035 Test MSE 0.6032879309515634 Test RE 0.37125334799848436\n",
      "96 Train Loss 0.0608095 Test MSE 0.6027851059698667 Test RE 0.37109860068642153\n",
      "97 Train Loss 0.060147606 Test MSE 0.6016092214434727 Test RE 0.3707364632365744\n",
      "98 Train Loss 0.059631865 Test MSE 0.6010439951305238 Test RE 0.3705622644051982\n",
      "99 Train Loss 0.059255347 Test MSE 0.6001810105446022 Test RE 0.37029614046371\n",
      "Training time: 122.50\n",
      "5\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.006912 Test MSE 8.276349747440573 Test RE 1.3750784559777047\n",
      "1 Train Loss 46.21984 Test MSE 8.200027572137646 Test RE 1.368723477226629\n",
      "2 Train Loss 43.88646 Test MSE 8.541791026679057 Test RE 1.3969553698374457\n",
      "3 Train Loss 42.646275 Test MSE 8.63446248020746 Test RE 1.4045128392296096\n",
      "4 Train Loss 41.698456 Test MSE 9.090030706032788 Test RE 1.4410887751665764\n",
      "5 Train Loss 41.05639 Test MSE 9.222819998273609 Test RE 1.4515764930294464\n",
      "6 Train Loss 39.37268 Test MSE 9.65571165066145 Test RE 1.4852521996425934\n",
      "7 Train Loss 37.77615 Test MSE 9.46542022083105 Test RE 1.470543954140791\n",
      "8 Train Loss 35.713627 Test MSE 9.495356333072817 Test RE 1.4728675496911554\n",
      "9 Train Loss 33.363052 Test MSE 9.516057728312234 Test RE 1.4744722189531165\n",
      "10 Train Loss 30.661854 Test MSE 9.239807803634477 Test RE 1.4529127304430403\n",
      "11 Train Loss 27.946358 Test MSE 9.74396334735133 Test RE 1.4920242475608463\n",
      "12 Train Loss 25.677303 Test MSE 9.370907229594387 Test RE 1.4631837845430988\n",
      "13 Train Loss 22.623928 Test MSE 9.434799349123526 Test RE 1.4681634040176423\n",
      "14 Train Loss 20.08168 Test MSE 9.317496616227023 Test RE 1.4590080299633492\n",
      "15 Train Loss 18.220562 Test MSE 9.228310441673834 Test RE 1.452008498251489\n",
      "16 Train Loss 16.15104 Test MSE 8.880600562536799 Test RE 1.4243910249712604\n",
      "17 Train Loss 14.36004 Test MSE 8.857382650880359 Test RE 1.4225278047449665\n",
      "18 Train Loss 12.914167 Test MSE 8.567651215131836 Test RE 1.3990684060789966\n",
      "19 Train Loss 11.341376 Test MSE 8.202292316837209 Test RE 1.3689124763007419\n",
      "20 Train Loss 9.451983 Test MSE 8.287153756733064 Test RE 1.3759756821480744\n",
      "21 Train Loss 7.672368 Test MSE 7.805507479337558 Test RE 1.3353915763746338\n",
      "22 Train Loss 6.207469 Test MSE 7.75922676915717 Test RE 1.3314267634352412\n",
      "23 Train Loss 5.2701087 Test MSE 7.519852362880935 Test RE 1.3107284236364514\n",
      "24 Train Loss 4.319685 Test MSE 7.1671406327250375 Test RE 1.2796200119637129\n",
      "25 Train Loss 3.7950583 Test MSE 7.1831339555259985 Test RE 1.2810469388700831\n",
      "26 Train Loss 3.390109 Test MSE 7.274214628758013 Test RE 1.2891430623431492\n",
      "27 Train Loss 3.1068022 Test MSE 7.329635201965755 Test RE 1.2940445868493582\n",
      "28 Train Loss 2.9031975 Test MSE 7.281803623731994 Test RE 1.2898153514070456\n",
      "29 Train Loss 2.7466083 Test MSE 7.30996935829832 Test RE 1.2923074218525608\n",
      "30 Train Loss 2.5967321 Test MSE 7.304385469937429 Test RE 1.2918137481727898\n",
      "31 Train Loss 2.492766 Test MSE 7.316144926615521 Test RE 1.2928531866520592\n",
      "32 Train Loss 2.3978293 Test MSE 7.311264746169861 Test RE 1.2924219206364564\n",
      "33 Train Loss 2.3211982 Test MSE 7.211767429637542 Test RE 1.2835976599691994\n",
      "34 Train Loss 2.2491076 Test MSE 7.13732243838711 Test RE 1.2769553700259437\n",
      "35 Train Loss 2.1810236 Test MSE 7.085528686233087 Test RE 1.2723136619394364\n",
      "36 Train Loss 2.1178296 Test MSE 7.042954403500648 Test RE 1.2684854750880141\n",
      "37 Train Loss 2.0581903 Test MSE 7.0513183212732935 Test RE 1.2692384517238668\n",
      "38 Train Loss 2.015252 Test MSE 7.1049382010265 Test RE 1.2740551058882965\n",
      "39 Train Loss 1.9647381 Test MSE 7.142412851572258 Test RE 1.2774106578396531\n",
      "40 Train Loss 1.9093701 Test MSE 7.092187342393491 Test RE 1.2729113526790297\n",
      "41 Train Loss 1.8416622 Test MSE 7.08058742206406 Test RE 1.2718699452712965\n",
      "42 Train Loss 1.7988338 Test MSE 7.104226790456445 Test RE 1.2739913193405956\n",
      "43 Train Loss 1.7596622 Test MSE 7.086656589145322 Test RE 1.2724149239089775\n",
      "44 Train Loss 1.723326 Test MSE 7.051977172093693 Test RE 1.2692977469665576\n",
      "45 Train Loss 1.689252 Test MSE 7.069484640469708 Test RE 1.2708723702483398\n",
      "46 Train Loss 1.6443436 Test MSE 7.095252594485149 Test RE 1.2731863998893587\n",
      "47 Train Loss 1.6038821 Test MSE 7.055488601172665 Test RE 1.2696137217788184\n",
      "48 Train Loss 1.5647299 Test MSE 7.073774715438551 Test RE 1.2712579224577953\n",
      "49 Train Loss 1.5256449 Test MSE 7.03111783244487 Test RE 1.267419102132004\n",
      "50 Train Loss 1.4935789 Test MSE 6.9916471062680845 Test RE 1.263856627486832\n",
      "51 Train Loss 1.4610481 Test MSE 7.0305896616786026 Test RE 1.267371497589866\n",
      "52 Train Loss 1.4273936 Test MSE 7.011833130181046 Test RE 1.265679792454571\n",
      "53 Train Loss 1.3996695 Test MSE 6.991112464971237 Test RE 1.2638083039048338\n",
      "54 Train Loss 1.3757969 Test MSE 6.924454168638636 Test RE 1.2577688444480124\n",
      "55 Train Loss 1.3560687 Test MSE 6.906543265963968 Test RE 1.2561411087913705\n",
      "56 Train Loss 1.3348513 Test MSE 6.882497747598709 Test RE 1.2539525393056876\n",
      "57 Train Loss 1.314161 Test MSE 6.796103965993294 Test RE 1.246057453393892\n",
      "58 Train Loss 1.2985938 Test MSE 6.733888065023558 Test RE 1.2403407345357378\n",
      "59 Train Loss 1.2780356 Test MSE 6.634926464841995 Test RE 1.2311929421984131\n",
      "60 Train Loss 1.2532952 Test MSE 6.503455058313774 Test RE 1.2189338341387534\n",
      "61 Train Loss 1.2362157 Test MSE 6.400358511818139 Test RE 1.209233613660126\n",
      "62 Train Loss 1.2182178 Test MSE 6.314581752738851 Test RE 1.2011032868283251\n",
      "63 Train Loss 1.2019699 Test MSE 6.30476019478065 Test RE 1.2001688388584775\n",
      "64 Train Loss 1.1882721 Test MSE 6.318745210649302 Test RE 1.2014991894510518\n",
      "65 Train Loss 1.1745902 Test MSE 6.310681085004684 Test RE 1.2007322544489354\n",
      "66 Train Loss 1.1582857 Test MSE 6.322081499570969 Test RE 1.201816342565646\n",
      "67 Train Loss 1.1439406 Test MSE 6.291165671127148 Test RE 1.1988742195725146\n",
      "68 Train Loss 1.1334412 Test MSE 6.23705464695253 Test RE 1.1937072591128257\n",
      "69 Train Loss 1.1216416 Test MSE 6.227574404655465 Test RE 1.192799704325785\n",
      "70 Train Loss 1.1120507 Test MSE 6.233784466295833 Test RE 1.1933942788338616\n",
      "71 Train Loss 1.1026123 Test MSE 6.231841690419075 Test RE 1.1932083020569464\n",
      "72 Train Loss 1.0955123 Test MSE 6.213567883525679 Test RE 1.1914575783450299\n",
      "73 Train Loss 1.0836273 Test MSE 6.154676726677959 Test RE 1.185797918294371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 1.072711 Test MSE 6.130090223235745 Test RE 1.1834270545848629\n",
      "75 Train Loss 1.0594397 Test MSE 6.120360498854427 Test RE 1.182487509552142\n",
      "76 Train Loss 1.0476263 Test MSE 6.140393732584885 Test RE 1.1844211943008736\n",
      "77 Train Loss 1.0367175 Test MSE 6.123262879584351 Test RE 1.1827678543272848\n",
      "78 Train Loss 1.0283109 Test MSE 6.110460862956315 Test RE 1.1815307903112264\n",
      "79 Train Loss 1.0161475 Test MSE 6.118289098300668 Test RE 1.1822873895947972\n",
      "80 Train Loss 1.0057311 Test MSE 6.101157886640897 Test RE 1.1806310267714168\n",
      "81 Train Loss 0.9979514 Test MSE 6.083576175057588 Test RE 1.1789286867888271\n",
      "82 Train Loss 0.987238 Test MSE 6.089988035637397 Test RE 1.1795497964327228\n",
      "83 Train Loss 0.9780574 Test MSE 6.1118539996572805 Test RE 1.1816654724681235\n",
      "84 Train Loss 0.96849895 Test MSE 6.107119791991256 Test RE 1.1812077281014306\n",
      "85 Train Loss 0.9592288 Test MSE 6.097522815027926 Test RE 1.1802792642169264\n",
      "86 Train Loss 0.9534266 Test MSE 6.107152073680813 Test RE 1.1812108499765606\n",
      "87 Train Loss 0.9458534 Test MSE 6.086357115349105 Test RE 1.1791981134882392\n",
      "88 Train Loss 0.9384928 Test MSE 6.071881612637204 Test RE 1.1777950043240324\n",
      "89 Train Loss 0.93075687 Test MSE 6.076698377198049 Test RE 1.1782620783653905\n",
      "90 Train Loss 0.92481935 Test MSE 6.069425818939701 Test RE 1.177556798586934\n",
      "91 Train Loss 0.9182177 Test MSE 6.072428791981086 Test RE 1.1778480727647693\n",
      "92 Train Loss 0.9123126 Test MSE 6.095941135047527 Test RE 1.1801261737556001\n",
      "93 Train Loss 0.9068568 Test MSE 6.121281482024382 Test RE 1.1825764757273007\n",
      "94 Train Loss 0.90085375 Test MSE 6.135534411405564 Test RE 1.1839524440566045\n",
      "95 Train Loss 0.8946582 Test MSE 6.139581833439587 Test RE 1.184342888056466\n",
      "96 Train Loss 0.8883678 Test MSE 6.127244999155647 Test RE 1.1831523844067278\n",
      "97 Train Loss 0.88241506 Test MSE 6.122007562762225 Test RE 1.1826466097786292\n",
      "98 Train Loss 0.877044 Test MSE 6.118891307899684 Test RE 1.182345573123269\n",
      "99 Train Loss 0.87280107 Test MSE 6.119601850557062 Test RE 1.1824142197567615\n",
      "Training time: 122.63\n",
      "6\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 57.82409 Test MSE 8.070847109309796 Test RE 1.357899475059383\n",
      "1 Train Loss 46.21669 Test MSE 8.735438079103268 Test RE 1.412701496013354\n",
      "2 Train Loss 40.73613 Test MSE 9.47746968443267 Test RE 1.4714796564062207\n",
      "3 Train Loss 36.367043 Test MSE 8.994057609635572 Test RE 1.4334610367942586\n",
      "4 Train Loss 33.14503 Test MSE 8.952574936676129 Test RE 1.4301514894385123\n",
      "5 Train Loss 29.878975 Test MSE 9.20012134496684 Test RE 1.4497891259617224\n",
      "6 Train Loss 26.371136 Test MSE 8.752905078590308 Test RE 1.4141131787079915\n",
      "7 Train Loss 23.22093 Test MSE 8.875853975798245 Test RE 1.4240103131509485\n",
      "8 Train Loss 20.827501 Test MSE 8.579118060817098 Test RE 1.400004341540972\n",
      "9 Train Loss 18.182178 Test MSE 8.71649698477897 Test RE 1.4111690809970778\n",
      "10 Train Loss 16.246878 Test MSE 8.60864157432245 Test RE 1.4024112059622231\n",
      "11 Train Loss 14.264412 Test MSE 8.542518529411591 Test RE 1.3970148577836645\n",
      "12 Train Loss 12.1267605 Test MSE 8.344176299613627 Test RE 1.3807014979471655\n",
      "13 Train Loss 11.022331 Test MSE 8.386520973510283 Test RE 1.3842004273691546\n",
      "14 Train Loss 9.278185 Test MSE 8.12778610261322 Test RE 1.3626809769492687\n",
      "15 Train Loss 7.6716766 Test MSE 7.849694736123693 Test RE 1.3391660917153352\n",
      "16 Train Loss 6.4255514 Test MSE 7.630523616108773 Test RE 1.3203383283585142\n",
      "17 Train Loss 5.1846766 Test MSE 7.228011125662102 Test RE 1.2850424266532552\n",
      "18 Train Loss 4.040256 Test MSE 6.7689334062829705 Test RE 1.2435641141774947\n",
      "19 Train Loss 3.2931612 Test MSE 6.8496344890959415 Test RE 1.2509552062180822\n",
      "20 Train Loss 2.6805418 Test MSE 6.277970004595274 Test RE 1.1976162453350163\n",
      "21 Train Loss 2.3209167 Test MSE 5.841474635710409 Test RE 1.1552322594681403\n",
      "22 Train Loss 2.1074698 Test MSE 5.813197560351084 Test RE 1.152432776434261\n",
      "23 Train Loss 1.9064661 Test MSE 5.661942518848196 Test RE 1.1373412434882773\n",
      "24 Train Loss 1.7579669 Test MSE 5.626902228577649 Test RE 1.1338164268446544\n",
      "25 Train Loss 1.6173701 Test MSE 5.543636241659717 Test RE 1.1253961444181675\n",
      "26 Train Loss 1.4855602 Test MSE 5.614533930580809 Test RE 1.1325696401201448\n",
      "27 Train Loss 1.3750118 Test MSE 5.66053889176779 Test RE 1.1372002581360532\n",
      "28 Train Loss 1.2851222 Test MSE 5.729413644731016 Test RE 1.1440977968148442\n",
      "29 Train Loss 1.187592 Test MSE 5.777541751933254 Test RE 1.1488930614471504\n",
      "30 Train Loss 1.1193837 Test MSE 5.875724405942647 Test RE 1.1586139922299612\n",
      "31 Train Loss 1.069183 Test MSE 5.918994505545057 Test RE 1.1628723082689927\n",
      "32 Train Loss 1.018743 Test MSE 5.879510193841163 Test RE 1.1589871854080684\n",
      "33 Train Loss 0.97937465 Test MSE 5.9638583400878655 Test RE 1.1672710642168596\n",
      "34 Train Loss 0.94836015 Test MSE 5.992717907640402 Test RE 1.1700919128269083\n",
      "35 Train Loss 0.92821425 Test MSE 5.99329424057511 Test RE 1.170148176637706\n",
      "36 Train Loss 0.9073674 Test MSE 6.09209299397103 Test RE 1.1797536300566396\n",
      "37 Train Loss 0.8938169 Test MSE 6.088168110103458 Test RE 1.1793735355613275\n",
      "38 Train Loss 0.87718844 Test MSE 6.071291986704646 Test RE 1.1777378165046537\n",
      "39 Train Loss 0.8596217 Test MSE 6.109373988534638 Test RE 1.181425705544894\n",
      "40 Train Loss 0.84243315 Test MSE 6.1353581884256645 Test RE 1.1839354413709453\n",
      "41 Train Loss 0.8312972 Test MSE 6.190776660571963 Test RE 1.1892704515314412\n",
      "42 Train Loss 0.8202074 Test MSE 6.206038450939096 Test RE 1.1907354715751903\n",
      "43 Train Loss 0.80750966 Test MSE 6.220985474366468 Test RE 1.1921685312945554\n",
      "44 Train Loss 0.7979622 Test MSE 6.247645776036054 Test RE 1.1947203450803214\n",
      "45 Train Loss 0.7853069 Test MSE 6.251937030250702 Test RE 1.1951305770977931\n",
      "46 Train Loss 0.77398384 Test MSE 6.283129647631776 Test RE 1.1981082836217447\n",
      "47 Train Loss 0.76329666 Test MSE 6.328898081443574 Test RE 1.202464078000521\n",
      "48 Train Loss 0.7543452 Test MSE 6.355710812740623 Test RE 1.2050085391278824\n",
      "49 Train Loss 0.7457243 Test MSE 6.335633447692907 Test RE 1.2031037535183755\n",
      "50 Train Loss 0.73710155 Test MSE 6.356732177590056 Test RE 1.2051053578755995\n",
      "51 Train Loss 0.73164 Test MSE 6.385747223513768 Test RE 1.207852553816326\n",
      "52 Train Loss 0.72585446 Test MSE 6.42163007705899 Test RE 1.21124138831177\n",
      "53 Train Loss 0.7193627 Test MSE 6.428292746419506 Test RE 1.2118695783990527\n",
      "54 Train Loss 0.7149581 Test MSE 6.425076533600819 Test RE 1.2115663782909187\n",
      "55 Train Loss 0.7100476 Test MSE 6.447433025383782 Test RE 1.2136724117616868\n",
      "56 Train Loss 0.70464545 Test MSE 6.467236537334359 Test RE 1.2155349009292478\n",
      "57 Train Loss 0.69999015 Test MSE 6.479297823481315 Test RE 1.2166678489012983\n",
      "58 Train Loss 0.6943908 Test MSE 6.50009216124247 Test RE 1.2186186417500549\n",
      "59 Train Loss 0.6891974 Test MSE 6.51637085241347 Test RE 1.220143628734703\n",
      "60 Train Loss 0.68247634 Test MSE 6.53910316438714 Test RE 1.2222700069399797\n",
      "61 Train Loss 0.6786917 Test MSE 6.562402300911437 Test RE 1.2244455739226086\n",
      "62 Train Loss 0.67469054 Test MSE 6.573447032885932 Test RE 1.2254755311815295\n",
      "63 Train Loss 0.67061496 Test MSE 6.5746359809719515 Test RE 1.2255863528632394\n",
      "64 Train Loss 0.6652362 Test MSE 6.585460968719198 Test RE 1.226594887848822\n",
      "65 Train Loss 0.65924734 Test MSE 6.615232902577846 Test RE 1.2293643918964527\n",
      "66 Train Loss 0.6526402 Test MSE 6.641745161905416 Test RE 1.2318254266681121\n",
      "67 Train Loss 0.64543253 Test MSE 6.669169095165278 Test RE 1.2343659260480373\n",
      "68 Train Loss 0.64006835 Test MSE 6.690070708620544 Test RE 1.2362987047634595\n",
      "69 Train Loss 0.63416183 Test MSE 6.709420978141509 Test RE 1.2380853405649317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 0.62853146 Test MSE 6.712984741524619 Test RE 1.238414106450401\n",
      "71 Train Loss 0.6209272 Test MSE 6.749003562249457 Test RE 1.2417320449845235\n",
      "72 Train Loss 0.6159307 Test MSE 6.779040339825574 Test RE 1.244492172627819\n",
      "73 Train Loss 0.6111016 Test MSE 6.775605115999491 Test RE 1.2441768145033683\n",
      "74 Train Loss 0.6049734 Test MSE 6.785941245126576 Test RE 1.2451254435397219\n",
      "75 Train Loss 0.59993905 Test MSE 6.803984224143758 Test RE 1.2467796620064604\n",
      "76 Train Loss 0.5944485 Test MSE 6.818273051536399 Test RE 1.2480881362343654\n",
      "77 Train Loss 0.58929354 Test MSE 6.830211994508174 Test RE 1.2491803729155349\n",
      "78 Train Loss 0.5844794 Test MSE 6.839605019362815 Test RE 1.2500390249614486\n",
      "79 Train Loss 0.57944465 Test MSE 6.843115654427415 Test RE 1.250359794058592\n",
      "80 Train Loss 0.5754492 Test MSE 6.8579717311704655 Test RE 1.2517162938844402\n",
      "81 Train Loss 0.5700519 Test MSE 6.884359237175811 Test RE 1.2541221043281983\n",
      "82 Train Loss 0.5661757 Test MSE 6.889565159241126 Test RE 1.2545961955183116\n",
      "83 Train Loss 0.5628332 Test MSE 6.896100945730731 Test RE 1.2551911408391105\n",
      "84 Train Loss 0.55942667 Test MSE 6.8971149888217695 Test RE 1.2552834227769116\n",
      "85 Train Loss 0.55611 Test MSE 6.88852602087904 Test RE 1.2545015779214241\n",
      "86 Train Loss 0.55291486 Test MSE 6.901293888118242 Test RE 1.2556636476013847\n",
      "87 Train Loss 0.54935247 Test MSE 6.924948414296264 Test RE 1.2578137314298692\n",
      "88 Train Loss 0.54660916 Test MSE 6.929384631497913 Test RE 1.2582165533152052\n",
      "89 Train Loss 0.5439081 Test MSE 6.933802572450106 Test RE 1.2586175875340855\n",
      "90 Train Loss 0.54023063 Test MSE 6.940514621689696 Test RE 1.2592266227417037\n",
      "91 Train Loss 0.53681827 Test MSE 6.959349227483738 Test RE 1.2609340587020728\n",
      "92 Train Loss 0.5339494 Test MSE 6.97344210143094 Test RE 1.2622101261175278\n",
      "93 Train Loss 0.5316536 Test MSE 6.984582342842404 Test RE 1.2632179292918666\n",
      "94 Train Loss 0.52867 Test MSE 6.982750847438321 Test RE 1.2630522980912724\n",
      "95 Train Loss 0.52667016 Test MSE 6.9707922867073195 Test RE 1.2619702918494418\n",
      "96 Train Loss 0.52418375 Test MSE 6.984591701650595 Test RE 1.2632187755994742\n",
      "97 Train Loss 0.5222508 Test MSE 6.989439928426276 Test RE 1.2636571196675004\n",
      "98 Train Loss 0.5205868 Test MSE 6.9921381361563135 Test RE 1.2639010076216775\n",
      "99 Train Loss 0.51848876 Test MSE 7.003984208261771 Test RE 1.2649712043231658\n",
      "Training time: 122.81\n",
      "7\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 52.066986 Test MSE 8.243173356977705 Test RE 1.3723196340938848\n",
      "1 Train Loss 40.38676 Test MSE 7.715009681837856 Test RE 1.3276276783296195\n",
      "2 Train Loss 34.513306 Test MSE 6.82956672016908 Test RE 1.2491213642728296\n",
      "3 Train Loss 28.658413 Test MSE 6.655940091463664 Test RE 1.233141070522368\n",
      "4 Train Loss 24.469063 Test MSE 6.007084585616869 Test RE 1.171493636631005\n",
      "5 Train Loss 19.374481 Test MSE 6.317313289882581 Test RE 1.2013630430276576\n",
      "6 Train Loss 17.017515 Test MSE 5.867170370799806 Test RE 1.1577703145946692\n",
      "7 Train Loss 14.386677 Test MSE 5.9869572880681705 Test RE 1.1695293905201425\n",
      "8 Train Loss 12.48509 Test MSE 5.805091105354975 Test RE 1.151628967213997\n",
      "9 Train Loss 11.547016 Test MSE 5.868836694597305 Test RE 1.1579347109856246\n",
      "10 Train Loss 10.78002 Test MSE 5.940730304641076 Test RE 1.1650055081465915\n",
      "11 Train Loss 10.176843 Test MSE 5.790993889747457 Test RE 1.1502297962313155\n",
      "12 Train Loss 9.499861 Test MSE 5.782958435430932 Test RE 1.149431502570793\n",
      "13 Train Loss 8.992524 Test MSE 5.655160569451871 Test RE 1.1366598782219675\n",
      "14 Train Loss 8.553327 Test MSE 5.658324729790556 Test RE 1.136977824203818\n",
      "15 Train Loss 8.034755 Test MSE 5.530124245316395 Test RE 1.1240237937461501\n",
      "16 Train Loss 7.5392046 Test MSE 5.312676648632395 Test RE 1.1017035583917412\n",
      "17 Train Loss 6.7963457 Test MSE 5.143847539324992 Test RE 1.0840569652893837\n",
      "18 Train Loss 5.968481 Test MSE 4.994977174418457 Test RE 1.0682547049317368\n",
      "19 Train Loss 5.090764 Test MSE 4.895314140761382 Test RE 1.0575437513846486\n",
      "20 Train Loss 4.180975 Test MSE 4.656039461935014 Test RE 1.0313744927400599\n",
      "21 Train Loss 3.5803437 Test MSE 4.209474942902494 Test RE 0.9806680462578148\n",
      "22 Train Loss 3.0971534 Test MSE 3.924884390137403 Test RE 0.9469378906661653\n",
      "23 Train Loss 2.6440146 Test MSE 3.6979508096117915 Test RE 0.9191547273961096\n",
      "24 Train Loss 2.3033686 Test MSE 3.339667266143517 Test RE 0.8734934650474022\n",
      "25 Train Loss 1.9425366 Test MSE 2.9537098321263926 Test RE 0.8214705049115916\n",
      "26 Train Loss 1.7077248 Test MSE 2.512950350504359 Test RE 0.7577047578884782\n",
      "27 Train Loss 1.5187787 Test MSE 2.0015825009483352 Test RE 0.6762305828202186\n",
      "28 Train Loss 1.2582002 Test MSE 1.5617832013753283 Test RE 0.5973356485459796\n",
      "29 Train Loss 1.0329896 Test MSE 1.4151998652460709 Test RE 0.5686132159832441\n",
      "30 Train Loss 0.90638644 Test MSE 1.311861047902136 Test RE 0.5474594777990985\n",
      "31 Train Loss 0.8084038 Test MSE 1.143245701759512 Test RE 0.5110670115092112\n",
      "32 Train Loss 0.6827717 Test MSE 0.8211860835647233 Test RE 0.4331405570388409\n",
      "33 Train Loss 0.55561596 Test MSE 0.660208918866109 Test RE 0.3883727531708013\n",
      "34 Train Loss 0.4449416 Test MSE 0.5072960100226774 Test RE 0.3404385903284812\n",
      "35 Train Loss 0.37373102 Test MSE 0.39900353256096227 Test RE 0.3019231616413848\n",
      "36 Train Loss 0.2863034 Test MSE 0.29118656559730816 Test RE 0.25792517113008\n",
      "37 Train Loss 0.21405403 Test MSE 0.16863380280917328 Test RE 0.19628195598907305\n",
      "38 Train Loss 0.1595685 Test MSE 0.11116903419839741 Test RE 0.15936757952028777\n",
      "39 Train Loss 0.11023045 Test MSE 0.08269698973873521 Test RE 0.13745258468121116\n",
      "40 Train Loss 0.08713152 Test MSE 0.07296467298419318 Test RE 0.12911133760158916\n",
      "41 Train Loss 0.07090606 Test MSE 0.061074259815889514 Test RE 0.11812373385395937\n",
      "42 Train Loss 0.060536265 Test MSE 0.056771359626693885 Test RE 0.11388662106917175\n",
      "43 Train Loss 0.051153578 Test MSE 0.05578912395761471 Test RE 0.11289711167327778\n",
      "44 Train Loss 0.044665687 Test MSE 0.047727805529932395 Test RE 0.10442242954567753\n",
      "45 Train Loss 0.04063254 Test MSE 0.044880561524315875 Test RE 0.10125983170852851\n",
      "46 Train Loss 0.035926405 Test MSE 0.04168535397715861 Test RE 0.0975887616663657\n",
      "47 Train Loss 0.032706022 Test MSE 0.03676482343502647 Test RE 0.09164827657693532\n",
      "48 Train Loss 0.029577246 Test MSE 0.03840675824400855 Test RE 0.09367245146581475\n",
      "49 Train Loss 0.02739176 Test MSE 0.04088239599396745 Test RE 0.09664429683261236\n",
      "50 Train Loss 0.024902219 Test MSE 0.038325593694948576 Test RE 0.09357342067474272\n",
      "51 Train Loss 0.022883859 Test MSE 0.03706845146780196 Test RE 0.09202594422197437\n",
      "52 Train Loss 0.021330379 Test MSE 0.03512625630217123 Test RE 0.08958266810747983\n",
      "53 Train Loss 0.019455679 Test MSE 0.0314450473951671 Test RE 0.08475868049831602\n",
      "54 Train Loss 0.017463287 Test MSE 0.030287133783705743 Test RE 0.08318349207033879\n",
      "55 Train Loss 0.016070046 Test MSE 0.02747984698321124 Test RE 0.07923466303671889\n",
      "56 Train Loss 0.014572208 Test MSE 0.022717140031040996 Test RE 0.07204185515160352\n",
      "57 Train Loss 0.013468928 Test MSE 0.02153098222396329 Test RE 0.0701358365571995\n",
      "58 Train Loss 0.01241917 Test MSE 0.01961327670792817 Test RE 0.06693960387440424\n",
      "59 Train Loss 0.011031259 Test MSE 0.0179093542973274 Test RE 0.06396582776251272\n",
      "60 Train Loss 0.009840541 Test MSE 0.017197523801253417 Test RE 0.06268173656564206\n",
      "61 Train Loss 0.009044895 Test MSE 0.015024545925703594 Test RE 0.05858800879159166\n",
      "62 Train Loss 0.008174836 Test MSE 0.013399709545037154 Test RE 0.05532937348736928\n",
      "63 Train Loss 0.0077470955 Test MSE 0.012940259999011444 Test RE 0.05437253249202987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Train Loss 0.007264236 Test MSE 0.012623116836262497 Test RE 0.05370211141371079\n",
      "65 Train Loss 0.0067827096 Test MSE 0.01273088160755191 Test RE 0.05393085431491511\n",
      "66 Train Loss 0.0060765003 Test MSE 0.011468676427393904 Test RE 0.05118759324507399\n",
      "67 Train Loss 0.0055455146 Test MSE 0.010658788907643603 Test RE 0.04934714039651745\n",
      "68 Train Loss 0.005189412 Test MSE 0.010530807426896965 Test RE 0.04904998690893504\n",
      "69 Train Loss 0.004849211 Test MSE 0.010447986420215095 Test RE 0.048856725938526364\n",
      "70 Train Loss 0.004616851 Test MSE 0.010223567255071926 Test RE 0.048329164742973905\n",
      "71 Train Loss 0.0043920707 Test MSE 0.010039487623496908 Test RE 0.04789209492323963\n",
      "72 Train Loss 0.0042002015 Test MSE 0.010059977930029565 Test RE 0.047940943208091454\n",
      "73 Train Loss 0.0040787994 Test MSE 0.0101466882787378 Test RE 0.04814710950062334\n",
      "74 Train Loss 0.0039057373 Test MSE 0.009917631498374381 Test RE 0.047600558027210985\n",
      "75 Train Loss 0.0037519338 Test MSE 0.009662123642848842 Test RE 0.04698339068587423\n",
      "76 Train Loss 0.0035712568 Test MSE 0.009699906161115525 Test RE 0.04707516237557374\n",
      "77 Train Loss 0.0034050369 Test MSE 0.009434992825116149 Test RE 0.04642787937249919\n",
      "78 Train Loss 0.0032312959 Test MSE 0.009079288088611337 Test RE 0.0455442923528429\n",
      "79 Train Loss 0.003076665 Test MSE 0.008957360184171623 Test RE 0.045237446163097106\n",
      "80 Train Loss 0.0028481926 Test MSE 0.008391627976326739 Test RE 0.04378558649798205\n",
      "81 Train Loss 0.0026788071 Test MSE 0.007855342126944803 Test RE 0.04236338090589403\n",
      "82 Train Loss 0.0026115966 Test MSE 0.007682438311376629 Test RE 0.04189455686667578\n",
      "83 Train Loss 0.002528104 Test MSE 0.007426230437045351 Test RE 0.041190045428574296\n",
      "84 Train Loss 0.0023943686 Test MSE 0.007146601594492425 Test RE 0.04040711524071597\n",
      "85 Train Loss 0.0022902163 Test MSE 0.006929192772348441 Test RE 0.03978775015371913\n",
      "86 Train Loss 0.0021963122 Test MSE 0.006600255394827195 Test RE 0.038831881228926154\n",
      "87 Train Loss 0.0021116056 Test MSE 0.006425638163356547 Test RE 0.03831476739713179\n",
      "88 Train Loss 0.0020524664 Test MSE 0.006318188060633025 Test RE 0.0379930653411315\n",
      "89 Train Loss 0.0020000287 Test MSE 0.0061984344566525205 Test RE 0.03763128659692218\n",
      "90 Train Loss 0.0019644531 Test MSE 0.0060859798262567705 Test RE 0.03728836271824825\n",
      "91 Train Loss 0.0018941886 Test MSE 0.005731306483044997 Test RE 0.036185524902100086\n",
      "92 Train Loss 0.0018090695 Test MSE 0.0054915313828055095 Test RE 0.03542050878771703\n",
      "93 Train Loss 0.0017382487 Test MSE 0.005416772112474342 Test RE 0.03517858305785301\n",
      "94 Train Loss 0.0016568073 Test MSE 0.005141944060932843 Test RE 0.0342745478360102\n",
      "95 Train Loss 0.0015849811 Test MSE 0.004908117592111541 Test RE 0.03348617479871835\n",
      "96 Train Loss 0.0015126462 Test MSE 0.004697443082099447 Test RE 0.032759617593769115\n",
      "97 Train Loss 0.0014392415 Test MSE 0.004599687722378826 Test RE 0.032416956203977054\n",
      "98 Train Loss 0.0013718351 Test MSE 0.004569890073069428 Test RE 0.03231178400107544\n",
      "99 Train Loss 0.0013031522 Test MSE 0.004241470158150571 Test RE 0.031129078751869484\n",
      "Training time: 122.78\n",
      "8\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.52484 Test MSE 7.870838100763901 Test RE 1.3409684188837776\n",
      "1 Train Loss 43.405445 Test MSE 8.52586655688999 Test RE 1.3956525896948047\n",
      "2 Train Loss 30.694794 Test MSE 8.109648631655585 Test RE 1.3611596899600267\n",
      "3 Train Loss 23.827871 Test MSE 7.683927391301619 Test RE 1.3249506009335372\n",
      "4 Train Loss 19.076046 Test MSE 7.644648483910367 Test RE 1.3215598029704831\n",
      "5 Train Loss 16.60424 Test MSE 7.322147251680701 Test RE 1.2933834204141168\n",
      "6 Train Loss 14.782661 Test MSE 7.181259084356782 Test RE 1.2808797448061224\n",
      "7 Train Loss 13.497301 Test MSE 7.245659634686769 Test RE 1.2866103030416982\n",
      "8 Train Loss 11.94718 Test MSE 7.386898464166784 Test RE 1.2990896569575097\n",
      "9 Train Loss 10.876153 Test MSE 7.216735193787581 Test RE 1.2840396814819681\n",
      "10 Train Loss 9.697533 Test MSE 6.92183428218083 Test RE 1.2575308817704172\n",
      "11 Train Loss 8.565694 Test MSE 6.7843547797493455 Test RE 1.244979887912186\n",
      "12 Train Loss 7.626394 Test MSE 6.722350426056428 Test RE 1.2392776979550697\n",
      "13 Train Loss 6.548386 Test MSE 6.516967811934861 Test RE 1.2201995156457153\n",
      "14 Train Loss 5.828965 Test MSE 6.360634252595906 Test RE 1.2054751776150143\n",
      "15 Train Loss 5.0757275 Test MSE 6.313276047074999 Test RE 1.2009791005793036\n",
      "16 Train Loss 4.359845 Test MSE 6.028479764359833 Test RE 1.173578011956732\n",
      "17 Train Loss 3.802796 Test MSE 5.626940563404205 Test RE 1.1338202890569584\n",
      "18 Train Loss 3.2811668 Test MSE 5.379651917301379 Test RE 1.1086262264710902\n",
      "19 Train Loss 2.9196503 Test MSE 5.241516443966421 Test RE 1.0943003461362593\n",
      "20 Train Loss 2.7279778 Test MSE 5.068463803858779 Test RE 1.0760841509432424\n",
      "21 Train Loss 2.5069375 Test MSE 4.880667924745145 Test RE 1.0559605417597133\n",
      "22 Train Loss 2.3471322 Test MSE 4.838506168826603 Test RE 1.05138967993399\n",
      "23 Train Loss 2.206712 Test MSE 4.7330380582636415 Test RE 1.039867628365048\n",
      "24 Train Loss 2.093103 Test MSE 4.5935665063249065 Test RE 1.0244318314839367\n",
      "25 Train Loss 2.0113516 Test MSE 4.556455064204089 Test RE 1.0202852450018478\n",
      "26 Train Loss 1.9467423 Test MSE 4.53191675168195 Test RE 1.0175342163824317\n",
      "27 Train Loss 1.8950651 Test MSE 4.483700991349418 Test RE 1.012106890617671\n",
      "28 Train Loss 1.8501229 Test MSE 4.412699237519482 Test RE 1.004061290554753\n",
      "29 Train Loss 1.8084002 Test MSE 4.3458175558308545 Test RE 0.9964231415008086\n",
      "30 Train Loss 1.7770578 Test MSE 4.306680884175154 Test RE 0.991926302934236\n",
      "31 Train Loss 1.7470121 Test MSE 4.248403037284038 Test RE 0.9851920884781722\n",
      "32 Train Loss 1.7194308 Test MSE 4.188590563577005 Test RE 0.9782323375880368\n",
      "33 Train Loss 1.6904079 Test MSE 4.1436062260105535 Test RE 0.9729651811786546\n",
      "34 Train Loss 1.6701674 Test MSE 4.112812711896161 Test RE 0.9693431080882444\n",
      "35 Train Loss 1.6447856 Test MSE 4.079993821856153 Test RE 0.9654678424934471\n",
      "36 Train Loss 1.5908042 Test MSE 4.107557183917747 Test RE 0.9687235760688501\n",
      "37 Train Loss 1.5215594 Test MSE 4.042783811537614 Test RE 0.9610551698529214\n",
      "38 Train Loss 1.4799043 Test MSE 4.016346581578763 Test RE 0.9579076715541173\n",
      "39 Train Loss 1.4297625 Test MSE 3.8987977755213823 Test RE 0.9437857485567329\n",
      "40 Train Loss 1.3618524 Test MSE 3.634100124043257 Test RE 0.9111848799667926\n",
      "41 Train Loss 1.2775414 Test MSE 3.501123826451196 Test RE 0.8943588230949856\n",
      "42 Train Loss 1.1744738 Test MSE 3.3781221083838147 Test RE 0.8785080233352341\n",
      "43 Train Loss 1.0900079 Test MSE 3.191077256532913 Test RE 0.8538404388086956\n",
      "44 Train Loss 1.0316025 Test MSE 3.0674981808769393 Test RE 0.8371440931167763\n",
      "45 Train Loss 0.9773601 Test MSE 2.994842165609504 Test RE 0.8271704854809572\n",
      "46 Train Loss 0.94104314 Test MSE 2.9473731138445523 Test RE 0.8205888641417036\n",
      "47 Train Loss 0.9049219 Test MSE 2.90101204320206 Test RE 0.8141095065714828\n",
      "48 Train Loss 0.87481725 Test MSE 2.84545734850481 Test RE 0.8062766828504031\n",
      "49 Train Loss 0.8332309 Test MSE 2.8089429781143087 Test RE 0.8010867006728734\n",
      "50 Train Loss 0.80350465 Test MSE 2.78544356190607 Test RE 0.7977287457764519\n",
      "51 Train Loss 0.7671024 Test MSE 2.742637286787748 Test RE 0.7915753257165178\n",
      "52 Train Loss 0.73799306 Test MSE 2.713032851481206 Test RE 0.7872915434325833\n",
      "53 Train Loss 0.7110551 Test MSE 2.6985726350880745 Test RE 0.7851906444151643\n",
      "54 Train Loss 0.69330657 Test MSE 2.713694604647051 Test RE 0.7873875542319435\n",
      "55 Train Loss 0.67925626 Test MSE 2.7087718235508547 Test RE 0.7866730493582997\n",
      "56 Train Loss 0.66209334 Test MSE 2.690663662436411 Test RE 0.784039182335829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 0.6483893 Test MSE 2.704308417808536 Test RE 0.7860246579750204\n",
      "58 Train Loss 0.63707554 Test MSE 2.7001844798809347 Test RE 0.785425104756627\n",
      "59 Train Loss 0.62569106 Test MSE 2.705664313924621 Test RE 0.7862216832510046\n",
      "60 Train Loss 0.6141974 Test MSE 2.6980125521954643 Test RE 0.7851091578799404\n",
      "61 Train Loss 0.6039153 Test MSE 2.690736547381409 Test RE 0.7840498013266936\n",
      "62 Train Loss 0.5936706 Test MSE 2.732974096500118 Test RE 0.790179608439667\n",
      "63 Train Loss 0.58624214 Test MSE 2.728326271199785 Test RE 0.7895074140770639\n",
      "64 Train Loss 0.57938486 Test MSE 2.725884897304398 Test RE 0.7891540996303733\n",
      "65 Train Loss 0.5725821 Test MSE 2.7418069114595798 Test RE 0.7914554858850145\n",
      "66 Train Loss 0.5669774 Test MSE 2.735745323641969 Test RE 0.7905801267536988\n",
      "67 Train Loss 0.558696 Test MSE 2.766223671541502 Test RE 0.7949717702825198\n",
      "68 Train Loss 0.5518892 Test MSE 2.7683737642715984 Test RE 0.795280662696451\n",
      "69 Train Loss 0.54605865 Test MSE 2.769792635834406 Test RE 0.7954844387515136\n",
      "70 Train Loss 0.53937805 Test MSE 2.8054409898184804 Test RE 0.8005871762594772\n",
      "71 Train Loss 0.5284302 Test MSE 2.814681522943782 Test RE 0.8019045753097209\n",
      "72 Train Loss 0.5202161 Test MSE 2.8129914220392456 Test RE 0.8016637837408327\n",
      "73 Train Loss 0.512032 Test MSE 2.824675939686755 Test RE 0.803327021594823\n",
      "74 Train Loss 0.504638 Test MSE 2.857224698956166 Test RE 0.8079421359308729\n",
      "75 Train Loss 0.49806708 Test MSE 2.877799529953393 Test RE 0.8108459072358023\n",
      "76 Train Loss 0.49196798 Test MSE 2.893496501349265 Test RE 0.8130542813872619\n",
      "77 Train Loss 0.48789322 Test MSE 2.918484448339676 Test RE 0.8165574621783576\n",
      "78 Train Loss 0.4835301 Test MSE 2.929386310998335 Test RE 0.8180811467661453\n",
      "79 Train Loss 0.47878024 Test MSE 2.9345178454062646 Test RE 0.8187973675468655\n",
      "80 Train Loss 0.4741698 Test MSE 2.9507210998014313 Test RE 0.8210547943352908\n",
      "81 Train Loss 0.46955517 Test MSE 2.9506287541182052 Test RE 0.8210419463810762\n",
      "82 Train Loss 0.4650259 Test MSE 2.956130633760189 Test RE 0.8218070663821762\n",
      "83 Train Loss 0.45989782 Test MSE 2.9643590318347615 Test RE 0.8229500227392597\n",
      "84 Train Loss 0.4569866 Test MSE 2.9631823680097633 Test RE 0.8227866768654523\n",
      "85 Train Loss 0.45304084 Test MSE 2.9686923152446183 Test RE 0.8235512949496574\n",
      "86 Train Loss 0.44937128 Test MSE 2.987710064895118 Test RE 0.8261849611347138\n",
      "87 Train Loss 0.44645005 Test MSE 2.9874963214762236 Test RE 0.8261554076049388\n",
      "88 Train Loss 0.44305435 Test MSE 2.983839523744265 Test RE 0.8256496315404478\n",
      "89 Train Loss 0.43962157 Test MSE 2.993912937554312 Test RE 0.8270421498942772\n",
      "90 Train Loss 0.43680027 Test MSE 2.9895622023693864 Test RE 0.8264410052314077\n",
      "91 Train Loss 0.43408886 Test MSE 2.9937898549243975 Test RE 0.8270251494718829\n",
      "92 Train Loss 0.4317768 Test MSE 3.004897276204949 Test RE 0.8285579243963543\n",
      "93 Train Loss 0.42950273 Test MSE 2.9983563199193806 Test RE 0.8276556450241045\n",
      "94 Train Loss 0.42692202 Test MSE 3.007162853393399 Test RE 0.8288702159768351\n",
      "95 Train Loss 0.42471507 Test MSE 3.013512382745994 Test RE 0.8297448211812652\n",
      "96 Train Loss 0.42189142 Test MSE 3.006920352706007 Test RE 0.828836794832165\n",
      "97 Train Loss 0.419741 Test MSE 3.0150880751006026 Test RE 0.8299617195285715\n",
      "98 Train Loss 0.4171588 Test MSE 3.0200599736994405 Test RE 0.8306457436198909\n",
      "99 Train Loss 0.41496444 Test MSE 3.0377904841944576 Test RE 0.8330804998921203\n",
      "Training time: 123.20\n",
      "9\n",
      "KG_rowdy_tune35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 55.499622 Test MSE 8.5468504044939 Test RE 1.397369023058728\n",
      "1 Train Loss 48.338745 Test MSE 8.970764517510672 Test RE 1.4316036222698172\n",
      "2 Train Loss 42.915062 Test MSE 8.63624006943674 Test RE 1.4046574063301833\n",
      "3 Train Loss 40.21158 Test MSE 9.186291070556958 Test RE 1.448699003240523\n",
      "4 Train Loss 37.83094 Test MSE 9.496466901044586 Test RE 1.4729536797764675\n",
      "5 Train Loss 35.27828 Test MSE 9.684119460989406 Test RE 1.4874354553321147\n",
      "6 Train Loss 32.94851 Test MSE 9.715507118419572 Test RE 1.4898440039842735\n",
      "7 Train Loss 30.516699 Test MSE 9.383965655391757 Test RE 1.4642029081269772\n",
      "8 Train Loss 27.505669 Test MSE 9.246636168921626 Test RE 1.4534494941287037\n",
      "9 Train Loss 24.70923 Test MSE 9.362740891575907 Test RE 1.4625460950731084\n",
      "10 Train Loss 22.797338 Test MSE 9.329611706352518 Test RE 1.4599562606105225\n",
      "11 Train Loss 20.240889 Test MSE 9.003488494701283 Test RE 1.4342123808971703\n",
      "12 Train Loss 17.972298 Test MSE 8.980261647667648 Test RE 1.4323612237729544\n",
      "13 Train Loss 16.05806 Test MSE 8.748198856928575 Test RE 1.4137329606644105\n",
      "14 Train Loss 14.18821 Test MSE 8.716037071049763 Test RE 1.4111318513280349\n",
      "15 Train Loss 12.945508 Test MSE 8.704804268686377 Test RE 1.4102222593112683\n",
      "16 Train Loss 11.609932 Test MSE 8.457928162109566 Test RE 1.3900808368113913\n",
      "17 Train Loss 10.224354 Test MSE 8.245003071249997 Test RE 1.3724719306300652\n",
      "18 Train Loss 9.223452 Test MSE 8.172262473217943 Test RE 1.3664042797557556\n",
      "19 Train Loss 8.076882 Test MSE 7.79761817783881 Test RE 1.3347165420965645\n",
      "20 Train Loss 6.9223084 Test MSE 7.5408923481593115 Test RE 1.312560802934306\n",
      "21 Train Loss 6.0326624 Test MSE 7.375396120119453 Test RE 1.2980778386914862\n",
      "22 Train Loss 5.302825 Test MSE 7.349281649659564 Test RE 1.2957777130620107\n",
      "23 Train Loss 4.8261647 Test MSE 7.295399301473982 Test RE 1.2910188812729457\n",
      "24 Train Loss 4.3113694 Test MSE 6.965392106003366 Test RE 1.2614813812853969\n",
      "25 Train Loss 3.9897435 Test MSE 6.802438557497861 Test RE 1.246638037986413\n",
      "26 Train Loss 3.6146123 Test MSE 6.503447754568894 Test RE 1.2189331496730218\n",
      "27 Train Loss 3.269402 Test MSE 6.19273010628578 Test RE 1.1894580687043705\n",
      "28 Train Loss 2.9884493 Test MSE 6.110364297843842 Test RE 1.1815214542638321\n",
      "29 Train Loss 2.700002 Test MSE 5.949022053323017 Test RE 1.1658182503549817\n",
      "30 Train Loss 2.3323996 Test MSE 5.7041614682783575 Test RE 1.1415737284248684\n",
      "31 Train Loss 2.1082478 Test MSE 5.670477797891767 Test RE 1.1381981816435753\n",
      "32 Train Loss 1.9572301 Test MSE 5.765062792694028 Test RE 1.1476516390293725\n",
      "33 Train Loss 1.8215888 Test MSE 5.780691487977478 Test RE 1.1492061891556407\n",
      "34 Train Loss 1.7312305 Test MSE 5.803068221735805 Test RE 1.1514282972921568\n",
      "35 Train Loss 1.6558102 Test MSE 5.828021859027028 Test RE 1.153901256547061\n",
      "36 Train Loss 1.5895265 Test MSE 5.8088565172374205 Test RE 1.1520024027349325\n",
      "37 Train Loss 1.5315334 Test MSE 5.8392257154633365 Test RE 1.1550098605463601\n",
      "38 Train Loss 1.4795029 Test MSE 5.798669208317922 Test RE 1.150991794686262\n",
      "39 Train Loss 1.4386511 Test MSE 5.762210356372052 Test RE 1.147367686506545\n",
      "40 Train Loss 1.4048682 Test MSE 5.7293721107904645 Test RE 1.1440936498829815\n",
      "41 Train Loss 1.3740909 Test MSE 5.66964408270226 Test RE 1.1381145054500634\n",
      "42 Train Loss 1.3493367 Test MSE 5.677558183693498 Test RE 1.1389085598903952\n",
      "43 Train Loss 1.3210468 Test MSE 5.7001766284118 Test RE 1.1411749157974564\n",
      "44 Train Loss 1.2961318 Test MSE 5.6985751552994985 Test RE 1.141014597140224\n",
      "45 Train Loss 1.2695456 Test MSE 5.673864367549525 Test RE 1.1385380129786482\n",
      "46 Train Loss 1.2442604 Test MSE 5.695554667565859 Test RE 1.1407121638732087\n",
      "47 Train Loss 1.2235012 Test MSE 5.720568295396327 Test RE 1.143214298585518\n",
      "48 Train Loss 1.2055271 Test MSE 5.71657601785524 Test RE 1.142815315031899\n",
      "49 Train Loss 1.18608 Test MSE 5.730260464607453 Test RE 1.1441823437701093\n",
      "50 Train Loss 1.1705275 Test MSE 5.718968911074037 Test RE 1.1430544747052152\n",
      "51 Train Loss 1.1556102 Test MSE 5.698347758237175 Test RE 1.1409918312778058\n",
      "52 Train Loss 1.1442432 Test MSE 5.688326373138809 Test RE 1.1399880885544715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 1.1323527 Test MSE 5.705794731048561 Test RE 1.141737149151605\n",
      "54 Train Loss 1.1217182 Test MSE 5.721674735795971 Test RE 1.143324850305522\n",
      "55 Train Loss 1.1108222 Test MSE 5.718526759945967 Test RE 1.1430102873173977\n",
      "56 Train Loss 1.1001114 Test MSE 5.725270726645057 Test RE 1.143684075541591\n",
      "57 Train Loss 1.0838798 Test MSE 5.730045642774702 Test RE 1.1441608964333514\n",
      "58 Train Loss 1.0710262 Test MSE 5.727801486220079 Test RE 1.1439368207635896\n",
      "59 Train Loss 1.0615357 Test MSE 5.739482094887508 Test RE 1.1451026322140865\n",
      "60 Train Loss 1.0546339 Test MSE 5.756082611189079 Test RE 1.146757447850718\n",
      "61 Train Loss 1.0468755 Test MSE 5.778325482981913 Test RE 1.1489709832232864\n",
      "62 Train Loss 1.0383581 Test MSE 5.790963181885014 Test RE 1.1502267465695595\n",
      "63 Train Loss 1.0309025 Test MSE 5.794289046189923 Test RE 1.150556998105596\n",
      "64 Train Loss 1.0227876 Test MSE 5.8183876066539195 Test RE 1.1529471099829514\n",
      "65 Train Loss 1.012533 Test MSE 5.83008462449176 Test RE 1.1541054439319558\n",
      "66 Train Loss 1.001045 Test MSE 5.83920403287633 Test RE 1.155007716116065\n",
      "67 Train Loss 0.9890693 Test MSE 5.862988240603697 Test RE 1.1573576105967003\n",
      "68 Train Loss 0.97861856 Test MSE 5.855698991704823 Test RE 1.156637935654249\n",
      "69 Train Loss 0.9677532 Test MSE 5.869410265179991 Test RE 1.1579912929877287\n",
      "70 Train Loss 0.960295 Test MSE 5.895802559563446 Test RE 1.160591875205074\n",
      "71 Train Loss 0.95208347 Test MSE 5.915199195956779 Test RE 1.1624994266814714\n",
      "72 Train Loss 0.94282794 Test MSE 5.93622475954531 Test RE 1.164563644925178\n",
      "73 Train Loss 0.934735 Test MSE 5.924865210484945 Test RE 1.1634488579043454\n",
      "74 Train Loss 0.92540044 Test MSE 5.924620796019044 Test RE 1.1634248601715842\n",
      "75 Train Loss 0.9194182 Test MSE 5.943515662311173 Test RE 1.1652785870943583\n",
      "76 Train Loss 0.91260666 Test MSE 5.952100854374141 Test RE 1.166119884652729\n",
      "77 Train Loss 0.90665174 Test MSE 5.985294396829043 Test RE 1.1693669594933487\n",
      "78 Train Loss 0.9005621 Test MSE 6.015500766740072 Test RE 1.172314005606293\n",
      "79 Train Loss 0.89333934 Test MSE 6.023222055562452 Test RE 1.1730661351965772\n",
      "80 Train Loss 0.88704467 Test MSE 6.044853892439651 Test RE 1.1751707257604174\n",
      "81 Train Loss 0.87966526 Test MSE 6.052478316932371 Test RE 1.1759116185159433\n",
      "82 Train Loss 0.8730826 Test MSE 6.046030445900125 Test RE 1.1752850861681585\n",
      "83 Train Loss 0.8681246 Test MSE 6.052637804294398 Test RE 1.175927111492269\n",
      "84 Train Loss 0.8632399 Test MSE 6.066989247287645 Test RE 1.1773204097078327\n",
      "85 Train Loss 0.85743034 Test MSE 6.072102174518118 Test RE 1.177816395907317\n",
      "86 Train Loss 0.8524346 Test MSE 6.08532094363447 Test RE 1.1790977329390908\n",
      "87 Train Loss 0.8482496 Test MSE 6.100841811657649 Test RE 1.1806004446448655\n",
      "88 Train Loss 0.8423764 Test MSE 6.1126415838191495 Test RE 1.1817416057519907\n",
      "89 Train Loss 0.83706164 Test MSE 6.1125931138071055 Test RE 1.1817369204500126\n",
      "90 Train Loss 0.8307521 Test MSE 6.111415262618218 Test RE 1.1816230590110182\n",
      "91 Train Loss 0.8220568 Test MSE 6.135308469148552 Test RE 1.1839306442155275\n",
      "92 Train Loss 0.8115211 Test MSE 6.152384984584124 Test RE 1.1855771271670261\n",
      "93 Train Loss 0.7988021 Test MSE 6.177447182267766 Test RE 1.1879894412680314\n",
      "94 Train Loss 0.7811602 Test MSE 6.2063036617866185 Test RE 1.1907609139401003\n",
      "95 Train Loss 0.7713636 Test MSE 6.182219482611309 Test RE 1.188448234982659\n",
      "96 Train Loss 0.7614367 Test MSE 6.201092180961269 Test RE 1.190260863404036\n",
      "97 Train Loss 0.7539266 Test MSE 6.204411085800697 Test RE 1.1905793423102167\n",
      "98 Train Loss 0.7464048 Test MSE 6.193984406219836 Test RE 1.1895785213652705\n",
      "99 Train Loss 0.74100196 Test MSE 6.209638675927179 Test RE 1.1910808041158727\n",
      "Training time: 122.59\n",
      "0\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 72.920654 Test MSE 4.514120422451064 Test RE 1.0155343797469403\n",
      "1 Train Loss 49.448776 Test MSE 7.875619898443725 Test RE 1.3413756986407244\n",
      "2 Train Loss 30.273811 Test MSE 6.853032497508277 Test RE 1.251265458485295\n",
      "3 Train Loss 20.62811 Test MSE 6.235366288442775 Test RE 1.193545681065716\n",
      "4 Train Loss 15.837766 Test MSE 6.034112771957039 Test RE 1.1741261792029505\n",
      "5 Train Loss 13.61372 Test MSE 6.062372802840406 Test RE 1.176872405901037\n",
      "6 Train Loss 11.833527 Test MSE 5.922106188537837 Test RE 1.1631779357311922\n",
      "7 Train Loss 10.169451 Test MSE 5.843788707298824 Test RE 1.1554610566140733\n",
      "8 Train Loss 8.775621 Test MSE 5.718837480725001 Test RE 1.1430413400900368\n",
      "9 Train Loss 7.4432125 Test MSE 5.564280678276585 Test RE 1.1274896782043935\n",
      "10 Train Loss 6.2332325 Test MSE 5.470513512373193 Test RE 1.1179492986431068\n",
      "11 Train Loss 5.0594726 Test MSE 5.281626030435853 Test RE 1.0984793166837967\n",
      "12 Train Loss 4.244595 Test MSE 5.073972157277246 Test RE 1.0766687306543843\n",
      "13 Train Loss 3.7075093 Test MSE 4.667634954356902 Test RE 1.0326579718163946\n",
      "14 Train Loss 3.1324518 Test MSE 4.236717003433912 Test RE 0.9838361770848074\n",
      "15 Train Loss 2.8187833 Test MSE 3.907941892186725 Test RE 0.9448918629579806\n",
      "16 Train Loss 2.4815495 Test MSE 3.6056942126737153 Test RE 0.9076167594784644\n",
      "17 Train Loss 2.2061582 Test MSE 3.283845828585653 Test RE 0.8661626251404099\n",
      "18 Train Loss 2.056855 Test MSE 3.0185463494126368 Test RE 0.8304375618028912\n",
      "19 Train Loss 1.8779044 Test MSE 2.699388821541213 Test RE 0.7853093763530664\n",
      "20 Train Loss 1.7451506 Test MSE 2.4571503150892764 Test RE 0.7492451197284861\n",
      "21 Train Loss 1.6405056 Test MSE 2.3098235472018884 Test RE 0.7264361741118391\n",
      "22 Train Loss 1.52939 Test MSE 2.1437362064444834 Test RE 0.6998318951716944\n",
      "23 Train Loss 1.4070555 Test MSE 1.9682591259257307 Test RE 0.6705778393404332\n",
      "24 Train Loss 1.3154113 Test MSE 1.8959456180500198 Test RE 0.6581441090942006\n",
      "25 Train Loss 1.2599734 Test MSE 1.803224525186289 Test RE 0.6418491390773874\n",
      "26 Train Loss 1.1960913 Test MSE 1.667018886591423 Test RE 0.6171323609664194\n",
      "27 Train Loss 1.1235672 Test MSE 1.4930273755561996 Test RE 0.5840391304693858\n",
      "28 Train Loss 1.0440998 Test MSE 1.1957736778595176 Test RE 0.5226759952718376\n",
      "29 Train Loss 0.90060484 Test MSE 0.8029272613916448 Test RE 0.4282981140586434\n",
      "30 Train Loss 0.6192306 Test MSE 0.19793623293748072 Test RE 0.21265260666554542\n",
      "31 Train Loss 0.4227506 Test MSE 0.1551544991905908 Test RE 0.18827395562131974\n",
      "32 Train Loss 0.2771696 Test MSE 0.0897848854646127 Test RE 0.14322198110341483\n",
      "33 Train Loss 0.1969733 Test MSE 0.071676988765139 Test RE 0.12796698453666736\n",
      "34 Train Loss 0.14426506 Test MSE 0.05640798725031746 Test RE 0.1135215630109531\n",
      "35 Train Loss 0.1194855 Test MSE 0.03297213256824032 Test RE 0.08679237625922584\n",
      "36 Train Loss 0.094086945 Test MSE 0.02104106052943795 Test RE 0.06933330026961294\n",
      "37 Train Loss 0.07486649 Test MSE 0.018775718913363763 Test RE 0.06549472873741806\n",
      "38 Train Loss 0.06147901 Test MSE 0.017810732524330547 Test RE 0.06378946372635466\n",
      "39 Train Loss 0.049785294 Test MSE 0.014917933086895494 Test RE 0.058379771080544\n",
      "40 Train Loss 0.041523356 Test MSE 0.014146300218917801 Test RE 0.056849872576377844\n",
      "41 Train Loss 0.036187463 Test MSE 0.01570515552414512 Test RE 0.05990032531346429\n",
      "42 Train Loss 0.032823093 Test MSE 0.01628526540960364 Test RE 0.06099657934885548\n",
      "43 Train Loss 0.02888502 Test MSE 0.014796545231609576 Test RE 0.05814176658972535\n",
      "44 Train Loss 0.026128866 Test MSE 0.01526164401815466 Test RE 0.05904847962689346\n",
      "45 Train Loss 0.023637615 Test MSE 0.016406679538791154 Test RE 0.06122353586752082\n",
      "46 Train Loss 0.021518188 Test MSE 0.016152847175764963 Test RE 0.06074808645727251\n",
      "47 Train Loss 0.018787738 Test MSE 0.01619594779765196 Test RE 0.060829079486368225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 0.017135195 Test MSE 0.01670243562295712 Test RE 0.06177289619674928\n",
      "49 Train Loss 0.015593352 Test MSE 0.015060081014752088 Test RE 0.05865725216712204\n",
      "50 Train Loss 0.0138468025 Test MSE 0.012575316840178955 Test RE 0.053600337999108016\n",
      "51 Train Loss 0.012066303 Test MSE 0.009870039907921154 Test RE 0.04748621063879809\n",
      "52 Train Loss 0.010793321 Test MSE 0.008461041300780863 Test RE 0.04396630494221852\n",
      "53 Train Loss 0.010107739 Test MSE 0.00876531775821501 Test RE 0.04474988180791205\n",
      "54 Train Loss 0.009438576 Test MSE 0.008034696514248055 Test RE 0.04284427507034182\n",
      "55 Train Loss 0.008807146 Test MSE 0.007259831035420549 Test RE 0.040725958729625575\n",
      "56 Train Loss 0.008362692 Test MSE 0.006534048621239649 Test RE 0.03863663019883928\n",
      "57 Train Loss 0.007864769 Test MSE 0.005406169187588777 Test RE 0.03514413647484075\n",
      "58 Train Loss 0.0074873446 Test MSE 0.0046693701023738715 Test RE 0.032661581469690115\n",
      "59 Train Loss 0.006951509 Test MSE 0.00406128287418479 Test RE 0.03046068602702803\n",
      "60 Train Loss 0.0066127023 Test MSE 0.003795437607672668 Test RE 0.029446859795518417\n",
      "61 Train Loss 0.0063028284 Test MSE 0.003580210215400048 Test RE 0.028599755738980104\n",
      "62 Train Loss 0.0060203033 Test MSE 0.0034590433904575666 Test RE 0.02811163240316319\n",
      "63 Train Loss 0.0058831926 Test MSE 0.0031529833927777906 Test RE 0.026839158921907226\n",
      "64 Train Loss 0.005717255 Test MSE 0.0027995523867272087 Test RE 0.02529020557653465\n",
      "65 Train Loss 0.0053610085 Test MSE 0.002580983819012905 Test RE 0.02428290837646526\n",
      "66 Train Loss 0.004949657 Test MSE 0.002426136368429774 Test RE 0.023543209342401193\n",
      "67 Train Loss 0.004719675 Test MSE 0.002356166287642903 Test RE 0.02320123105669975\n",
      "68 Train Loss 0.004404649 Test MSE 0.002122452064828714 Test RE 0.022020491363903365\n",
      "69 Train Loss 0.0042149387 Test MSE 0.001928489392899803 Test RE 0.020990205357914616\n",
      "70 Train Loss 0.003983603 Test MSE 0.0017252929249395373 Test RE 0.019853609749693753\n",
      "71 Train Loss 0.0038054378 Test MSE 0.0016448594404961166 Test RE 0.019385296865405254\n",
      "72 Train Loss 0.00362188 Test MSE 0.0017456674814575015 Test RE 0.019970494611487498\n",
      "73 Train Loss 0.003494171 Test MSE 0.001870364760948512 Test RE 0.02067146307543789\n",
      "74 Train Loss 0.0033732743 Test MSE 0.0019513800153307583 Test RE 0.021114411765261784\n",
      "75 Train Loss 0.0032176543 Test MSE 0.001827694675097465 Test RE 0.020434305575440327\n",
      "76 Train Loss 0.0030314026 Test MSE 0.0017192689497154791 Test RE 0.019818919341486774\n",
      "77 Train Loss 0.0027543036 Test MSE 0.0018408993016483493 Test RE 0.02050798904450934\n",
      "78 Train Loss 0.0025935243 Test MSE 0.00188304161515382 Test RE 0.020741397721873996\n",
      "79 Train Loss 0.002453851 Test MSE 0.0018452996204717245 Test RE 0.020532484634275313\n",
      "80 Train Loss 0.0023567819 Test MSE 0.0018799560402476244 Test RE 0.020724397201344384\n",
      "81 Train Loss 0.0022621977 Test MSE 0.0017695633283312023 Test RE 0.02010671467382469\n",
      "82 Train Loss 0.002173632 Test MSE 0.0016212509728512877 Test RE 0.01924567666180085\n",
      "83 Train Loss 0.0020695876 Test MSE 0.0016424667490007028 Test RE 0.019371192342602178\n",
      "84 Train Loss 0.001967525 Test MSE 0.0015862930973249282 Test RE 0.019037055563932107\n",
      "85 Train Loss 0.0018498629 Test MSE 0.0014217623306789272 Test RE 0.01802277089621981\n",
      "86 Train Loss 0.0017524665 Test MSE 0.0012920320133151327 Test RE 0.01718085203198715\n",
      "87 Train Loss 0.0016757183 Test MSE 0.001200746685526993 Test RE 0.016562800032775733\n",
      "88 Train Loss 0.0016020178 Test MSE 0.0010863945012937557 Test RE 0.01575439897636492\n",
      "89 Train Loss 0.0015333595 Test MSE 0.0009650204552473624 Test RE 0.014848285852782464\n",
      "90 Train Loss 0.0015047792 Test MSE 0.0009701448191919541 Test RE 0.014887656665402893\n",
      "91 Train Loss 0.0014744408 Test MSE 0.0009435287905286562 Test RE 0.01468201416007482\n",
      "92 Train Loss 0.0014315422 Test MSE 0.0009444335678048029 Test RE 0.01468905197908308\n",
      "93 Train Loss 0.0014017168 Test MSE 0.00101035836440388 Test RE 0.015193078468654015\n",
      "94 Train Loss 0.0013587452 Test MSE 0.0010025188724345426 Test RE 0.015134021226676756\n",
      "95 Train Loss 0.0012589748 Test MSE 0.0009062106671752682 Test RE 0.014388736030884872\n",
      "96 Train Loss 0.0011714566 Test MSE 0.0007861023438589752 Test RE 0.013401320875246446\n",
      "97 Train Loss 0.0011234609 Test MSE 0.0007296074458941355 Test RE 0.012910786189813617\n",
      "98 Train Loss 0.0010907939 Test MSE 0.000708615616840557 Test RE 0.01272369997641513\n",
      "99 Train Loss 0.0010530303 Test MSE 0.0007056929537027992 Test RE 0.01269743361173145\n",
      "Training time: 121.36\n",
      "1\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 68.931114 Test MSE 5.843497130989909 Test RE 1.1554322303431865\n",
      "1 Train Loss 56.564377 Test MSE 7.037250309431477 Test RE 1.2679716973694823\n",
      "2 Train Loss 46.388065 Test MSE 8.886893405013886 Test RE 1.424895601263955\n",
      "3 Train Loss 40.56064 Test MSE 8.798279570712758 Test RE 1.4177737762574194\n",
      "4 Train Loss 35.52357 Test MSE 9.28048196893365 Test RE 1.4561071215256214\n",
      "5 Train Loss 31.4522 Test MSE 8.99803822208034 Test RE 1.4337782140839577\n",
      "6 Train Loss 27.697153 Test MSE 8.809721068681155 Test RE 1.418695330601205\n",
      "7 Train Loss 24.637566 Test MSE 8.291332334106436 Test RE 1.3763225380427355\n",
      "8 Train Loss 22.486229 Test MSE 8.20791459965091 Test RE 1.3693815582574622\n",
      "9 Train Loss 20.207245 Test MSE 8.360085412655348 Test RE 1.3820171027085217\n",
      "10 Train Loss 18.680481 Test MSE 8.024276748930308 Test RE 1.3539761349872659\n",
      "11 Train Loss 17.006529 Test MSE 7.950164447545766 Test RE 1.3477089618469178\n",
      "12 Train Loss 15.4456415 Test MSE 8.183064581176165 Test RE 1.3673070390804327\n",
      "13 Train Loss 14.265193 Test MSE 8.278334619456121 Test RE 1.3752433348921884\n",
      "14 Train Loss 13.369849 Test MSE 8.322047778464041 Test RE 1.3788694917399964\n",
      "15 Train Loss 12.539654 Test MSE 8.367337938024294 Test RE 1.3826164351756718\n",
      "16 Train Loss 11.803574 Test MSE 8.224764612507697 Test RE 1.370786438055462\n",
      "17 Train Loss 11.081018 Test MSE 7.953640727190483 Test RE 1.3480035784698225\n",
      "18 Train Loss 9.348861 Test MSE 6.43975655941374 Test RE 1.2129496830603335\n",
      "19 Train Loss 7.981491 Test MSE 6.241781170013955 Test RE 1.1941594770827781\n",
      "20 Train Loss 7.0191355 Test MSE 6.162783422719005 Test RE 1.1865786042967177\n",
      "21 Train Loss 6.5336123 Test MSE 6.062270726159015 Test RE 1.1768624979211744\n",
      "22 Train Loss 6.004051 Test MSE 6.087504636406971 Test RE 1.1793092711861928\n",
      "23 Train Loss 5.5049434 Test MSE 6.1236316119869025 Test RE 1.182803465918334\n",
      "24 Train Loss 4.8910046 Test MSE 5.98863904455241 Test RE 1.1696936413604375\n",
      "25 Train Loss 4.2774096 Test MSE 5.945398696941647 Test RE 1.1654631652370393\n",
      "26 Train Loss 3.5959547 Test MSE 5.688510928518586 Test RE 1.1400065816238159\n",
      "27 Train Loss 2.9435306 Test MSE 5.731212737084025 Test RE 1.1442774117078998\n",
      "28 Train Loss 2.422246 Test MSE 5.578358933210392 Test RE 1.1289151148915693\n",
      "29 Train Loss 2.0984304 Test MSE 5.391028387518342 Test RE 1.1097978257333192\n",
      "30 Train Loss 1.937419 Test MSE 5.469102560071894 Test RE 1.1178051188641844\n",
      "31 Train Loss 1.8229166 Test MSE 5.525951841069859 Test RE 1.1235996833293533\n",
      "32 Train Loss 1.7119855 Test MSE 5.515218028799359 Test RE 1.1225078921950986\n",
      "33 Train Loss 1.5844631 Test MSE 5.554193865365824 Test RE 1.1264672696612625\n",
      "34 Train Loss 1.500437 Test MSE 5.602650314474019 Test RE 1.1313704175035446\n",
      "35 Train Loss 1.4440035 Test MSE 5.59941365465843 Test RE 1.131043573065658\n",
      "36 Train Loss 1.3777982 Test MSE 5.600840430653472 Test RE 1.1311876634234284\n",
      "37 Train Loss 1.325008 Test MSE 5.618733484666239 Test RE 1.132993130159528\n",
      "38 Train Loss 1.2690786 Test MSE 5.657781527875233 Test RE 1.1369232476829687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 1.2284503 Test MSE 5.710999835572115 Test RE 1.1422578046216698\n",
      "40 Train Loss 1.1850286 Test MSE 5.7258954908445 Test RE 1.1437464755055304\n",
      "41 Train Loss 1.1546633 Test MSE 5.756496269349484 Test RE 1.1467986527018421\n",
      "42 Train Loss 1.1311697 Test MSE 5.785879716922105 Test RE 1.149721785569164\n",
      "43 Train Loss 1.1096399 Test MSE 5.774961838089781 Test RE 1.1486365184217966\n",
      "44 Train Loss 1.089019 Test MSE 5.806129497941606 Test RE 1.1517319621100477\n",
      "45 Train Loss 1.0733598 Test MSE 5.8417460373924035 Test RE 1.1552590958712907\n",
      "46 Train Loss 1.060947 Test MSE 5.840255971597242 Test RE 1.1551117493556011\n",
      "47 Train Loss 1.050765 Test MSE 5.849102214419621 Test RE 1.1559862429175156\n",
      "48 Train Loss 1.0396385 Test MSE 5.880518213277811 Test RE 1.1590865331004057\n",
      "49 Train Loss 1.028578 Test MSE 5.878438447878477 Test RE 1.1588815476587657\n",
      "50 Train Loss 1.0220814 Test MSE 5.8675356492512485 Test RE 1.1578063542814996\n",
      "51 Train Loss 1.0125713 Test MSE 5.8641698102704884 Test RE 1.157474226023769\n",
      "52 Train Loss 1.0017332 Test MSE 5.8368774310613025 Test RE 1.1547775896496362\n",
      "53 Train Loss 0.9898809 Test MSE 5.842381319375883 Test RE 1.1553219105959613\n",
      "54 Train Loss 0.98009086 Test MSE 5.865774174833279 Test RE 1.157632550534674\n",
      "55 Train Loss 0.97375536 Test MSE 5.870702426328303 Test RE 1.1581187528982178\n",
      "56 Train Loss 0.9625277 Test MSE 5.912897416797248 Test RE 1.1622732231991193\n",
      "57 Train Loss 0.95707035 Test MSE 5.921621530908234 Test RE 1.1631303382567748\n",
      "58 Train Loss 0.95020306 Test MSE 5.920331768388845 Test RE 1.1630036631896128\n",
      "59 Train Loss 0.94212276 Test MSE 5.920843465226137 Test RE 1.1630539215586746\n",
      "60 Train Loss 0.933918 Test MSE 5.908444111323456 Test RE 1.1618354570517646\n",
      "61 Train Loss 0.92708385 Test MSE 5.908471405279036 Test RE 1.1618381405880844\n",
      "62 Train Loss 0.9189956 Test MSE 5.929588533716454 Test RE 1.1639125182605987\n",
      "63 Train Loss 0.91093767 Test MSE 5.913278458935415 Test RE 1.162310672516105\n",
      "64 Train Loss 0.9060363 Test MSE 5.9198745016624414 Test RE 1.1629587490557654\n",
      "65 Train Loss 0.9029708 Test MSE 5.933144453765059 Test RE 1.164261459803831\n",
      "66 Train Loss 0.8993838 Test MSE 5.942197198340085 Test RE 1.165149331689419\n",
      "67 Train Loss 0.8952145 Test MSE 5.962109595743681 Test RE 1.1670999159254734\n",
      "68 Train Loss 0.8901737 Test MSE 5.975893251139041 Test RE 1.1684482319701148\n",
      "69 Train Loss 0.8855156 Test MSE 5.979802815568964 Test RE 1.1688303820986254\n",
      "70 Train Loss 0.88205665 Test MSE 5.983119670242697 Test RE 1.1691544983936286\n",
      "71 Train Loss 0.8774 Test MSE 6.000958884866722 Test RE 1.1708961712748787\n",
      "72 Train Loss 0.870176 Test MSE 6.036388191324829 Test RE 1.1743475354929211\n",
      "73 Train Loss 0.8629216 Test MSE 6.075703190525099 Test RE 1.1781655918641811\n",
      "74 Train Loss 0.8589378 Test MSE 6.074515360115549 Test RE 1.1780504175970468\n",
      "75 Train Loss 0.8544954 Test MSE 6.061163563436596 Test RE 1.176755026823075\n",
      "76 Train Loss 0.84918606 Test MSE 6.066910011674436 Test RE 1.1773127217092731\n",
      "77 Train Loss 0.84474677 Test MSE 6.0852069265695095 Test RE 1.1790866868583845\n",
      "78 Train Loss 0.8406389 Test MSE 6.090432121818471 Test RE 1.1795928024462323\n",
      "79 Train Loss 0.8367845 Test MSE 6.085618174557015 Test RE 1.179126528464485\n",
      "80 Train Loss 0.8338952 Test MSE 6.091870361195875 Test RE 1.179732073079047\n",
      "81 Train Loss 0.8310124 Test MSE 6.094684180384685 Test RE 1.180004499223513\n",
      "82 Train Loss 0.826491 Test MSE 6.122627280858078 Test RE 1.1827064666924623\n",
      "83 Train Loss 0.8231137 Test MSE 6.140123514420337 Test RE 1.1843951328090294\n",
      "84 Train Loss 0.8198474 Test MSE 6.128391381261985 Test RE 1.1832630606802452\n",
      "85 Train Loss 0.8162427 Test MSE 6.135810954317679 Test RE 1.1839791255113479\n",
      "86 Train Loss 0.81123227 Test MSE 6.1693540707867704 Test RE 1.1872109900906163\n",
      "87 Train Loss 0.8068707 Test MSE 6.189414283549254 Test RE 1.189139585569455\n",
      "88 Train Loss 0.80310595 Test MSE 6.206719373620881 Test RE 1.1908007931614282\n",
      "89 Train Loss 0.799708 Test MSE 6.203769311045688 Test RE 1.1905177648683694\n",
      "90 Train Loss 0.7963208 Test MSE 6.199926777754425 Test RE 1.190149012219951\n",
      "91 Train Loss 0.793196 Test MSE 6.1865888891477026 Test RE 1.1888681405112282\n",
      "92 Train Loss 0.7882639 Test MSE 6.1814640235023806 Test RE 1.188375619356747\n",
      "93 Train Loss 0.78423476 Test MSE 6.203494477832735 Test RE 1.1904913940097972\n",
      "94 Train Loss 0.779173 Test MSE 6.2254464143579415 Test RE 1.192595894390804\n",
      "95 Train Loss 0.7762472 Test MSE 6.22854585653025 Test RE 1.1928927343121334\n",
      "96 Train Loss 0.77324075 Test MSE 6.2532348857693965 Test RE 1.195254620759489\n",
      "97 Train Loss 0.7704146 Test MSE 6.272504084632123 Test RE 1.1970947790014927\n",
      "98 Train Loss 0.76649886 Test MSE 6.291303845619595 Test RE 1.1988873850919028\n",
      "99 Train Loss 0.7620793 Test MSE 6.311103372522157 Test RE 1.2007724280652052\n",
      "Training time: 122.28\n",
      "2\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.388023 Test MSE 8.441768547540496 Test RE 1.388752266159155\n",
      "1 Train Loss 40.97202 Test MSE 7.836688703128782 Test RE 1.3380562104060059\n",
      "2 Train Loss 30.226736 Test MSE 6.875470487905835 Test RE 1.2533122121376512\n",
      "3 Train Loss 23.744047 Test MSE 6.067502225376071 Test RE 1.177370181248793\n",
      "4 Train Loss 19.783894 Test MSE 6.322354535918279 Test RE 1.2018422941451616\n",
      "5 Train Loss 17.110243 Test MSE 6.061967212362159 Test RE 1.1768330371388869\n",
      "6 Train Loss 14.584288 Test MSE 5.952322096575735 Test RE 1.1661415570453442\n",
      "7 Train Loss 12.469402 Test MSE 5.812584554055982 Test RE 1.152372012356989\n",
      "8 Train Loss 11.198561 Test MSE 5.977491323410004 Test RE 1.1686044546318906\n",
      "9 Train Loss 10.002895 Test MSE 5.911510150464798 Test RE 1.1621368706648052\n",
      "10 Train Loss 8.855194 Test MSE 6.045521711425282 Test RE 1.1752356387973164\n",
      "11 Train Loss 7.873536 Test MSE 5.749118571412998 Test RE 1.1460635313468832\n",
      "12 Train Loss 6.9629183 Test MSE 5.351852792609214 Test RE 1.1057581268110015\n",
      "13 Train Loss 6.138278 Test MSE 5.067843513262345 Test RE 1.0760183020658531\n",
      "14 Train Loss 5.5710006 Test MSE 4.719514349591414 Test RE 1.03838095885973\n",
      "15 Train Loss 4.993261 Test MSE 4.440925734006974 Test RE 1.0072674862711704\n",
      "16 Train Loss 4.0896044 Test MSE 4.275136335104984 Test RE 0.9882869138407899\n",
      "17 Train Loss 3.5903964 Test MSE 4.144324002757321 Test RE 0.9730494485418046\n",
      "18 Train Loss 3.1424637 Test MSE 3.7432239623874337 Test RE 0.9247641099426148\n",
      "19 Train Loss 2.7849925 Test MSE 3.5630409702224455 Test RE 0.9022325026584245\n",
      "20 Train Loss 2.5039663 Test MSE 3.2375806476951965 Test RE 0.8600394207241946\n",
      "21 Train Loss 2.183178 Test MSE 2.835063632175209 Test RE 0.8048027760597813\n",
      "22 Train Loss 1.9065586 Test MSE 2.62327139117627 Test RE 0.774158117101765\n",
      "23 Train Loss 1.7283863 Test MSE 2.294698461545247 Test RE 0.7240538589515026\n",
      "24 Train Loss 1.4445946 Test MSE 1.6867293901476244 Test RE 0.6207700655386257\n",
      "25 Train Loss 1.1667819 Test MSE 1.1525935978836632 Test RE 0.5131521605246873\n",
      "26 Train Loss 0.8721779 Test MSE 0.9498345131691697 Test RE 0.465834911660524\n",
      "27 Train Loss 0.70353734 Test MSE 0.8703610622854093 Test RE 0.44592085806734866\n",
      "28 Train Loss 0.54707974 Test MSE 0.640850971137296 Test RE 0.38263666590657774\n",
      "29 Train Loss 0.43815765 Test MSE 0.5153108708104779 Test RE 0.34311737635831857\n",
      "30 Train Loss 0.35725096 Test MSE 0.481358171395127 Test RE 0.33162116038063255\n",
      "31 Train Loss 0.29663348 Test MSE 0.4407600584726502 Test RE 0.31732857120335833\n",
      "32 Train Loss 0.2636908 Test MSE 0.4053759015086016 Test RE 0.30432457489418\n",
      "33 Train Loss 0.23057245 Test MSE 0.41124929573554314 Test RE 0.3065212894849698\n",
      "34 Train Loss 0.20583704 Test MSE 0.38142377632466756 Test RE 0.2951970010324055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.18853346 Test MSE 0.34653238652709484 Test RE 0.2813714152678124\n",
      "36 Train Loss 0.17809954 Test MSE 0.3243721512837812 Test RE 0.27222614982123367\n",
      "37 Train Loss 0.17078266 Test MSE 0.3122158590904346 Test RE 0.2670764162085871\n",
      "38 Train Loss 0.15964057 Test MSE 0.30372598268911616 Test RE 0.26342017456386313\n",
      "39 Train Loss 0.15121073 Test MSE 0.2923855256228823 Test RE 0.25845562880595857\n",
      "40 Train Loss 0.14508761 Test MSE 0.2576409578270409 Test RE 0.2426138070817331\n",
      "41 Train Loss 0.14129302 Test MSE 0.2408549171808132 Test RE 0.2345772112054805\n",
      "42 Train Loss 0.13600306 Test MSE 0.2287026437392824 Test RE 0.22858285500422987\n",
      "43 Train Loss 0.13170129 Test MSE 0.1994621957139858 Test RE 0.21347074120901588\n",
      "44 Train Loss 0.12674597 Test MSE 0.17420651988270683 Test RE 0.199498788534196\n",
      "45 Train Loss 0.11764369 Test MSE 0.11765032338992976 Test RE 0.1639474336819009\n",
      "46 Train Loss 0.094092935 Test MSE 0.03497976303830107 Test RE 0.08939567168387959\n",
      "47 Train Loss 0.08156079 Test MSE 0.0267559691090341 Test RE 0.07818409315446251\n",
      "48 Train Loss 0.07003391 Test MSE 0.020899808664746736 Test RE 0.06910018584121354\n",
      "49 Train Loss 0.06098214 Test MSE 0.015725039983039497 Test RE 0.0599382335271616\n",
      "50 Train Loss 0.049942125 Test MSE 0.01424874240362675 Test RE 0.05705534395665126\n",
      "51 Train Loss 0.043266952 Test MSE 0.011190282859933131 Test RE 0.05056250623440628\n",
      "52 Train Loss 0.036609694 Test MSE 0.0088474116019054 Test RE 0.04495895170290548\n",
      "53 Train Loss 0.033672936 Test MSE 0.00870932809989593 Test RE 0.04460672986546127\n",
      "54 Train Loss 0.028238798 Test MSE 0.008468819438358005 Test RE 0.04398650915816013\n",
      "55 Train Loss 0.025146775 Test MSE 0.006998014510560845 Test RE 0.03998485078064935\n",
      "56 Train Loss 0.02066151 Test MSE 0.004785174435723882 Test RE 0.03306411838309683\n",
      "57 Train Loss 0.018814161 Test MSE 0.004664992194696265 Test RE 0.032646266457508656\n",
      "58 Train Loss 0.01694848 Test MSE 0.004424811996387644 Test RE 0.03179475418968449\n",
      "59 Train Loss 0.015143996 Test MSE 0.003488894524790062 Test RE 0.028232671852389726\n",
      "60 Train Loss 0.013914585 Test MSE 0.0030040137252943973 Test RE 0.026197449785701075\n",
      "61 Train Loss 0.01301813 Test MSE 0.0030685744970815566 Test RE 0.026477464591766007\n",
      "62 Train Loss 0.011901907 Test MSE 0.004025866768650482 Test RE 0.030327580169697207\n",
      "63 Train Loss 0.011119871 Test MSE 0.004360408226642729 Test RE 0.031562517441205445\n",
      "64 Train Loss 0.010078105 Test MSE 0.0039872597901303925 Test RE 0.030181813196609498\n",
      "65 Train Loss 0.009410923 Test MSE 0.003928189212291018 Test RE 0.02995740974766223\n",
      "66 Train Loss 0.008620818 Test MSE 0.0034646665756423193 Test RE 0.028134472926516576\n",
      "67 Train Loss 0.0080138035 Test MSE 0.0033031642134262397 Test RE 0.02747091610846379\n",
      "68 Train Loss 0.0074861157 Test MSE 0.0033143256921813907 Test RE 0.02751728944135037\n",
      "69 Train Loss 0.0070395633 Test MSE 0.003198718138019657 Test RE 0.027033112189274365\n",
      "70 Train Loss 0.006548922 Test MSE 0.0032957936564312817 Test RE 0.02744025020521186\n",
      "71 Train Loss 0.006115151 Test MSE 0.0032661566946651332 Test RE 0.027316595291235334\n",
      "72 Train Loss 0.0056771818 Test MSE 0.00261232398744244 Test RE 0.02442989382217955\n",
      "73 Train Loss 0.00536937 Test MSE 0.0023257602410087065 Test RE 0.023051040366791488\n",
      "74 Train Loss 0.0050026034 Test MSE 0.0020080709352142266 Test RE 0.021418920820997115\n",
      "75 Train Loss 0.0047281417 Test MSE 0.0018782079861751518 Test RE 0.020714759797207702\n",
      "76 Train Loss 0.0044857394 Test MSE 0.0019077957938153866 Test RE 0.020877284224009873\n",
      "77 Train Loss 0.0043108286 Test MSE 0.001673380110998193 Test RE 0.01955263808759069\n",
      "78 Train Loss 0.0039442643 Test MSE 0.0012843007987138526 Test RE 0.017129371823454854\n",
      "79 Train Loss 0.0035367315 Test MSE 0.0012022252403429538 Test RE 0.01657299430354652\n",
      "80 Train Loss 0.0033819939 Test MSE 0.00108586076178859 Test RE 0.015750528477135643\n",
      "81 Train Loss 0.0031946383 Test MSE 0.0011542201236110384 Test RE 0.016238741977390014\n",
      "82 Train Loss 0.003089495 Test MSE 0.0012317478671083795 Test RE 0.01677524878721189\n",
      "83 Train Loss 0.0029792031 Test MSE 0.0011100128523941744 Test RE 0.01592472949537864\n",
      "84 Train Loss 0.0028766135 Test MSE 0.0010951173610004796 Test RE 0.015817519999324004\n",
      "85 Train Loss 0.0027398735 Test MSE 0.0011109495835323615 Test RE 0.01593144745551562\n",
      "86 Train Loss 0.0026857876 Test MSE 0.0011519022149864434 Test RE 0.01622242843569083\n",
      "87 Train Loss 0.0026286833 Test MSE 0.0011796689755225035 Test RE 0.016416786084544464\n",
      "88 Train Loss 0.0025243193 Test MSE 0.0011775455017396489 Test RE 0.01640200383736352\n",
      "89 Train Loss 0.002400873 Test MSE 0.001189358704615519 Test RE 0.01648407143801425\n",
      "90 Train Loss 0.0023456074 Test MSE 0.0012323326825170423 Test RE 0.01677923063286905\n",
      "91 Train Loss 0.0022371695 Test MSE 0.0013128079446950932 Test RE 0.017318435577044242\n",
      "92 Train Loss 0.002154833 Test MSE 0.0012419600075042792 Test RE 0.016844645126021685\n",
      "93 Train Loss 0.0020918185 Test MSE 0.0012013865979747251 Test RE 0.016567212841205915\n",
      "94 Train Loss 0.0020242485 Test MSE 0.0012112265956464383 Test RE 0.016634921640433543\n",
      "95 Train Loss 0.0019705775 Test MSE 0.001146758256356271 Test RE 0.016186166299249353\n",
      "96 Train Loss 0.0018935668 Test MSE 0.001065838608569246 Test RE 0.015604641089593224\n",
      "97 Train Loss 0.0018328568 Test MSE 0.0010397872136703199 Test RE 0.015412755767262963\n",
      "98 Train Loss 0.0017243964 Test MSE 0.0009710408133263077 Test RE 0.0148945299560082\n",
      "99 Train Loss 0.0016702208 Test MSE 0.0009292609453719065 Test RE 0.014570582117673769\n",
      "Training time: 122.46\n",
      "3\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 61.433907 Test MSE 5.9884752238902195 Test RE 1.1696776426255053\n",
      "1 Train Loss 48.89326 Test MSE 7.727250262618779 Test RE 1.3286804633368492\n",
      "2 Train Loss 41.878902 Test MSE 8.730489127864857 Test RE 1.412301265294737\n",
      "3 Train Loss 36.367455 Test MSE 9.293641878348202 Test RE 1.4571391503353366\n",
      "4 Train Loss 32.880836 Test MSE 9.160699095428528 Test RE 1.4466796394760866\n",
      "5 Train Loss 29.695143 Test MSE 9.180518505346114 Test RE 1.448243758377571\n",
      "6 Train Loss 27.071762 Test MSE 9.204003662643357 Test RE 1.4500949886821384\n",
      "7 Train Loss 24.334423 Test MSE 9.203936702830358 Test RE 1.4500897138979552\n",
      "8 Train Loss 21.940792 Test MSE 8.85488591578378 Test RE 1.422327298254539\n",
      "9 Train Loss 19.58376 Test MSE 8.63005466592316 Test RE 1.4041542979734551\n",
      "10 Train Loss 17.757847 Test MSE 8.43428336865535 Test RE 1.3881364375928171\n",
      "11 Train Loss 16.496952 Test MSE 8.702077660724195 Test RE 1.410001379882428\n",
      "12 Train Loss 15.131115 Test MSE 8.855257934639297 Test RE 1.422357175941345\n",
      "13 Train Loss 13.575716 Test MSE 8.472000467857049 Test RE 1.3912367648512367\n",
      "14 Train Loss 12.061552 Test MSE 7.95376182721351 Test RE 1.3480138406031414\n",
      "15 Train Loss 11.0404005 Test MSE 7.935710446814187 Test RE 1.3464832860487443\n",
      "16 Train Loss 9.6962 Test MSE 7.875818945049489 Test RE 1.341392649344055\n",
      "17 Train Loss 8.508193 Test MSE 7.520414721889973 Test RE 1.3107774329867485\n",
      "18 Train Loss 7.722814 Test MSE 7.224605840260098 Test RE 1.284739684193171\n",
      "19 Train Loss 7.3210487 Test MSE 7.053970820658615 Test RE 1.2694771544394452\n",
      "20 Train Loss 6.826481 Test MSE 6.69594624407998 Test RE 1.2368414735185302\n",
      "21 Train Loss 6.484302 Test MSE 6.589382747534919 Test RE 1.2269600648580192\n",
      "22 Train Loss 6.2215686 Test MSE 6.621487127318673 Test RE 1.22994539220925\n",
      "23 Train Loss 5.94713 Test MSE 6.558339795002141 Test RE 1.2240665139962779\n",
      "24 Train Loss 5.677126 Test MSE 6.4225906694035455 Test RE 1.2113319779037317\n",
      "25 Train Loss 5.4078593 Test MSE 6.420127322471602 Test RE 1.2110996559921292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 5.00451 Test MSE 6.263699267618372 Test RE 1.196254293144772\n",
      "27 Train Loss 4.639856 Test MSE 6.122342709323419 Test RE 1.1826789810649945\n",
      "28 Train Loss 4.2192397 Test MSE 6.04579045298969 Test RE 1.1752617598807666\n",
      "29 Train Loss 3.6773677 Test MSE 5.746650429936197 Test RE 1.145817497928294\n",
      "30 Train Loss 3.2358196 Test MSE 5.6114620750691575 Test RE 1.1322597687809148\n",
      "31 Train Loss 2.8410926 Test MSE 5.480937876384503 Test RE 1.119013948597868\n",
      "32 Train Loss 2.5222816 Test MSE 5.352384232318367 Test RE 1.105813026414235\n",
      "33 Train Loss 2.160942 Test MSE 5.331818120811729 Test RE 1.1036864822951324\n",
      "34 Train Loss 1.9662127 Test MSE 5.4343094860292975 Test RE 1.1142438463798092\n",
      "35 Train Loss 1.8293641 Test MSE 5.394575788655442 Test RE 1.1101628999232698\n",
      "36 Train Loss 1.7209321 Test MSE 5.404140770678545 Test RE 1.1111466645263264\n",
      "37 Train Loss 1.623177 Test MSE 5.455963578263737 Test RE 1.1164616029506151\n",
      "38 Train Loss 1.5655265 Test MSE 5.470306830783421 Test RE 1.117928179810271\n",
      "39 Train Loss 1.52302 Test MSE 5.45137294672577 Test RE 1.1159918103721698\n",
      "40 Train Loss 1.4838504 Test MSE 5.429898157688396 Test RE 1.1137915080118956\n",
      "41 Train Loss 1.4243351 Test MSE 5.5080213741212605 Test RE 1.1217752884575902\n",
      "42 Train Loss 1.3724958 Test MSE 5.560951706457132 Test RE 1.127152353117884\n",
      "43 Train Loss 1.3347123 Test MSE 5.556601678802337 Test RE 1.126711412123744\n",
      "44 Train Loss 1.2981431 Test MSE 5.608793659962108 Test RE 1.1319905253733147\n",
      "45 Train Loss 1.2668477 Test MSE 5.631640149254004 Test RE 1.1342936700720443\n",
      "46 Train Loss 1.237176 Test MSE 5.664145308560413 Test RE 1.137562464381481\n",
      "47 Train Loss 1.219734 Test MSE 5.684877533674272 Test RE 1.1396424480469967\n",
      "48 Train Loss 1.20244 Test MSE 5.701380698149214 Test RE 1.1412954367669617\n",
      "49 Train Loss 1.1813041 Test MSE 5.717885411702919 Test RE 1.1429461896725528\n",
      "50 Train Loss 1.1622605 Test MSE 5.690446111820357 Test RE 1.140200475433137\n",
      "51 Train Loss 1.149243 Test MSE 5.706771251560022 Test RE 1.1418348465012034\n",
      "52 Train Loss 1.1318537 Test MSE 5.738967974705658 Test RE 1.145051344175533\n",
      "53 Train Loss 1.1194696 Test MSE 5.732918475339397 Test RE 1.144447680431057\n",
      "54 Train Loss 1.1061727 Test MSE 5.785677348944472 Test RE 1.1497016789545735\n",
      "55 Train Loss 1.0940474 Test MSE 5.820467193099125 Test RE 1.1531531326083109\n",
      "56 Train Loss 1.0854442 Test MSE 5.817536755119101 Test RE 1.1528628063278261\n",
      "57 Train Loss 1.0741762 Test MSE 5.842269721021326 Test RE 1.155310876341874\n",
      "58 Train Loss 1.061861 Test MSE 5.869856406953474 Test RE 1.158035302389761\n",
      "59 Train Loss 1.0394878 Test MSE 5.891742204944768 Test RE 1.160192164889485\n",
      "60 Train Loss 1.0230013 Test MSE 5.924005841905924 Test RE 1.1633644789679578\n",
      "61 Train Loss 1.0056916 Test MSE 5.942721005057388 Test RE 1.1652006847139822\n",
      "62 Train Loss 0.9959736 Test MSE 5.907995984719598 Test RE 1.1617913964462694\n",
      "63 Train Loss 0.9781695 Test MSE 5.924943370680878 Test RE 1.1634565319262478\n",
      "64 Train Loss 0.9654005 Test MSE 5.942990623575232 Test RE 1.1652271167236707\n",
      "65 Train Loss 0.9547143 Test MSE 5.927507139771812 Test RE 1.163708223048385\n",
      "66 Train Loss 0.9474536 Test MSE 5.946195262193061 Test RE 1.1655412370714902\n",
      "67 Train Loss 0.93597615 Test MSE 5.955159622137589 Test RE 1.166419479019727\n",
      "68 Train Loss 0.9264755 Test MSE 5.978166046651219 Test RE 1.1686704072442335\n",
      "69 Train Loss 0.91852564 Test MSE 6.013412660416487 Test RE 1.1721105205723035\n",
      "70 Train Loss 0.91331995 Test MSE 6.019084575678242 Test RE 1.1726631638899834\n",
      "71 Train Loss 0.90602404 Test MSE 6.0426659841312205 Test RE 1.1749580325722835\n",
      "72 Train Loss 0.8965189 Test MSE 6.045471531449731 Test RE 1.175230761350769\n",
      "73 Train Loss 0.88890535 Test MSE 6.058468943334759 Test RE 1.1764934219167626\n",
      "74 Train Loss 0.8787981 Test MSE 6.0850194194078115 Test RE 1.1790685207628135\n",
      "75 Train Loss 0.8702453 Test MSE 6.088433889879096 Test RE 1.1793992781334048\n",
      "76 Train Loss 0.8624924 Test MSE 6.091967193456765 Test RE 1.1797414491543043\n",
      "77 Train Loss 0.8537597 Test MSE 6.0975164617188735 Test RE 1.1802786493212454\n",
      "78 Train Loss 0.8452353 Test MSE 6.128584514145709 Test RE 1.183281705475629\n",
      "79 Train Loss 0.83848375 Test MSE 6.145268145540671 Test RE 1.184891214055147\n",
      "80 Train Loss 0.8316375 Test MSE 6.142972375100523 Test RE 1.1846698655097256\n",
      "81 Train Loss 0.8237426 Test MSE 6.163649451605792 Test RE 1.186661973707777\n",
      "82 Train Loss 0.81659335 Test MSE 6.172036035521825 Test RE 1.1874690164577817\n",
      "83 Train Loss 0.80974346 Test MSE 6.1898922304276685 Test RE 1.1891854973920761\n",
      "84 Train Loss 0.8034975 Test MSE 6.181269073206592 Test RE 1.1883568797827335\n",
      "85 Train Loss 0.79788196 Test MSE 6.174073089659129 Test RE 1.1876649598305853\n",
      "86 Train Loss 0.79403317 Test MSE 6.192578250556804 Test RE 1.1894434848999467\n",
      "87 Train Loss 0.78714687 Test MSE 6.2160183146200305 Test RE 1.1916924914385614\n",
      "88 Train Loss 0.78287905 Test MSE 6.238239214784009 Test RE 1.1938206106999332\n",
      "89 Train Loss 0.77756274 Test MSE 6.256195684699582 Test RE 1.1955375535025548\n",
      "90 Train Loss 0.773927 Test MSE 6.263189790874956 Test RE 1.1962056416922378\n",
      "91 Train Loss 0.7681906 Test MSE 6.2638036326583695 Test RE 1.1962642590292896\n",
      "92 Train Loss 0.76292443 Test MSE 6.273128990910961 Test RE 1.1971544085691022\n",
      "93 Train Loss 0.75910944 Test MSE 6.288929171937049 Test RE 1.198661101709989\n",
      "94 Train Loss 0.7547402 Test MSE 6.290546541573877 Test RE 1.198815225996318\n",
      "95 Train Loss 0.74857825 Test MSE 6.289211063174392 Test RE 1.1986879654466915\n",
      "96 Train Loss 0.74373716 Test MSE 6.27784998214171 Test RE 1.1976047972453383\n",
      "97 Train Loss 0.7396419 Test MSE 6.281452610621119 Test RE 1.1979483787543268\n",
      "98 Train Loss 0.7349107 Test MSE 6.313936709878534 Test RE 1.2010419381185615\n",
      "99 Train Loss 0.7317342 Test MSE 6.3387126449319275 Test RE 1.203396079753493\n",
      "Training time: 123.01\n",
      "4\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 51.374786 Test MSE 8.103843904640064 Test RE 1.3606724570869557\n",
      "1 Train Loss 40.65484 Test MSE 7.624649329675008 Test RE 1.319830005520858\n",
      "2 Train Loss 33.080578 Test MSE 7.129496495429612 Test RE 1.2762550989604542\n",
      "3 Train Loss 26.944147 Test MSE 6.33175855073545 Test RE 1.2027357858842096\n",
      "4 Train Loss 21.204605 Test MSE 5.778827523534558 Test RE 1.149020895390782\n",
      "5 Train Loss 16.479982 Test MSE 5.750751714998479 Test RE 1.1462263000720894\n",
      "6 Train Loss 13.334698 Test MSE 5.5892062068896236 Test RE 1.1300121852071539\n",
      "7 Train Loss 11.114297 Test MSE 5.2675747062115414 Test RE 1.0970171373698132\n",
      "8 Train Loss 8.906814 Test MSE 5.049268926179738 Test RE 1.0740445885044492\n",
      "9 Train Loss 7.4680786 Test MSE 4.9985949610602205 Test RE 1.068641495294407\n",
      "10 Train Loss 6.094923 Test MSE 4.77799774111794 Test RE 1.0447948671130658\n",
      "11 Train Loss 4.6405516 Test MSE 4.40712659100707 Test RE 1.0034270929825324\n",
      "12 Train Loss 3.9040217 Test MSE 4.325911023038112 Test RE 0.994138404925964\n",
      "13 Train Loss 3.1157818 Test MSE 3.9686036304310095 Test RE 0.9521972501613153\n",
      "14 Train Loss 2.6623507 Test MSE 3.643110252051671 Test RE 0.9123137440144671\n",
      "15 Train Loss 2.33688 Test MSE 3.3937161367285333 Test RE 0.8805333653950368\n",
      "16 Train Loss 2.0095098 Test MSE 2.935256820253271 Test RE 0.8189004564704339\n",
      "17 Train Loss 1.7998273 Test MSE 2.437917320709123 Test RE 0.7463070543419795\n",
      "18 Train Loss 1.6774378 Test MSE 2.2755541692307046 Test RE 0.7210272018014792\n",
      "19 Train Loss 1.563519 Test MSE 2.128201130392829 Test RE 0.6972915383219652\n",
      "20 Train Loss 1.4815006 Test MSE 1.9250039701266286 Test RE 0.6631684781220683\n",
      "21 Train Loss 1.400872 Test MSE 1.8417851378258887 Test RE 0.6486755703390006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 1.3285575 Test MSE 1.7740862631986025 Test RE 0.6366422062875811\n",
      "23 Train Loss 1.2314241 Test MSE 1.5079536491370225 Test RE 0.5869512834010955\n",
      "24 Train Loss 1.0823426 Test MSE 1.1133156961964557 Test RE 0.5043328142513512\n",
      "25 Train Loss 0.88577515 Test MSE 0.8684896599716515 Test RE 0.4454412028890904\n",
      "26 Train Loss 0.67880297 Test MSE 0.7432358214550371 Test RE 0.41207035972400374\n",
      "27 Train Loss 0.5811233 Test MSE 0.6899750628953281 Test RE 0.3970313108672805\n",
      "28 Train Loss 0.4636466 Test MSE 0.5684601405527585 Test RE 0.36037783287685043\n",
      "29 Train Loss 0.40315124 Test MSE 0.46728505312174057 Test RE 0.3267375175527141\n",
      "30 Train Loss 0.35410807 Test MSE 0.3903802841759789 Test RE 0.2986427652350763\n",
      "31 Train Loss 0.30838943 Test MSE 0.33583565646895946 Test RE 0.2769947019539154\n",
      "32 Train Loss 0.2554378 Test MSE 0.24181808703342117 Test RE 0.23504577599956353\n",
      "33 Train Loss 0.20923421 Test MSE 0.13982335295494153 Test RE 0.17873018974132196\n",
      "34 Train Loss 0.15942833 Test MSE 0.05527181136374732 Test RE 0.11237246535649445\n",
      "35 Train Loss 0.11733833 Test MSE 0.041213612458631664 Test RE 0.09703499812009797\n",
      "36 Train Loss 0.090938754 Test MSE 0.039294958074012044 Test RE 0.09474940145439191\n",
      "37 Train Loss 0.077213086 Test MSE 0.027467963457156738 Test RE 0.07921752886196518\n",
      "38 Train Loss 0.06679354 Test MSE 0.024339526443040226 Test RE 0.07456999644519069\n",
      "39 Train Loss 0.056572035 Test MSE 0.021820805084307383 Test RE 0.07060629863625119\n",
      "40 Train Loss 0.049195893 Test MSE 0.020895752886729967 Test RE 0.06909348078910162\n",
      "41 Train Loss 0.04279723 Test MSE 0.02068996816755131 Test RE 0.06875241716992679\n",
      "42 Train Loss 0.037602186 Test MSE 0.018565513590613803 Test RE 0.06512707061289985\n",
      "43 Train Loss 0.03305528 Test MSE 0.01682795572093194 Test RE 0.062004575789787686\n",
      "44 Train Loss 0.029917505 Test MSE 0.015800279618255867 Test RE 0.06008145571508548\n",
      "45 Train Loss 0.026359595 Test MSE 0.01413153661158446 Test RE 0.05682019950707254\n",
      "46 Train Loss 0.023491986 Test MSE 0.012297576837785651 Test RE 0.053005121296155706\n",
      "47 Train Loss 0.022338321 Test MSE 0.011230545618632636 Test RE 0.05065338678251928\n",
      "48 Train Loss 0.020856587 Test MSE 0.010035768864605903 Test RE 0.04788322416926743\n",
      "49 Train Loss 0.019574147 Test MSE 0.00978089680487767 Test RE 0.0472712839743241\n",
      "50 Train Loss 0.018325172 Test MSE 0.009468213680393524 Test RE 0.046509544435227944\n",
      "51 Train Loss 0.017108187 Test MSE 0.009182467639950285 Test RE 0.04580235025705698\n",
      "52 Train Loss 0.015577094 Test MSE 0.009107724331369714 Test RE 0.045615558737333625\n",
      "53 Train Loss 0.014405448 Test MSE 0.008214121151436805 Test RE 0.043320016393545054\n",
      "54 Train Loss 0.013731374 Test MSE 0.007771531681674551 Test RE 0.0421367825682927\n",
      "55 Train Loss 0.012987429 Test MSE 0.007628934296563545 Test RE 0.04174841554378147\n",
      "56 Train Loss 0.011918082 Test MSE 0.0068840670982420376 Test RE 0.0396579816630861\n",
      "57 Train Loss 0.010957104 Test MSE 0.006598745058874353 Test RE 0.03882743802647533\n",
      "58 Train Loss 0.009780051 Test MSE 0.006657479901053925 Test RE 0.0389998549936551\n",
      "59 Train Loss 0.008800328 Test MSE 0.0061572951796114075 Test RE 0.037506198460809236\n",
      "60 Train Loss 0.0079634655 Test MSE 0.005955483698668182 Test RE 0.03688642623750463\n",
      "61 Train Loss 0.0073672496 Test MSE 0.005882442351710446 Test RE 0.03665953062849672\n",
      "62 Train Loss 0.0069885473 Test MSE 0.005942543201029196 Test RE 0.03684632972214873\n",
      "63 Train Loss 0.006686089 Test MSE 0.006074737340010931 Test RE 0.037253905843844776\n",
      "64 Train Loss 0.0064296974 Test MSE 0.006002351917277444 Test RE 0.03703128542799369\n",
      "65 Train Loss 0.006195953 Test MSE 0.006089482286058001 Test RE 0.03729909083520766\n",
      "66 Train Loss 0.0059217233 Test MSE 0.005908218281294972 Test RE 0.0367397609604057\n",
      "67 Train Loss 0.005666334 Test MSE 0.0054436021727879615 Test RE 0.035265597761686675\n",
      "68 Train Loss 0.0053358907 Test MSE 0.004841317386241737 Test RE 0.03325751822669109\n",
      "69 Train Loss 0.0051206974 Test MSE 0.004554366597418626 Test RE 0.03225685730990912\n",
      "70 Train Loss 0.004776513 Test MSE 0.004116630936094498 Test RE 0.0306675461138611\n",
      "71 Train Loss 0.0045938645 Test MSE 0.00408758031162996 Test RE 0.030559145735456837\n",
      "72 Train Loss 0.0043924595 Test MSE 0.0039057374753724006 Test RE 0.02987167562627107\n",
      "73 Train Loss 0.004264805 Test MSE 0.0038616820180545517 Test RE 0.02970272642523389\n",
      "74 Train Loss 0.0040730652 Test MSE 0.0037443546955073293 Test RE 0.02924802540112075\n",
      "75 Train Loss 0.00387112 Test MSE 0.0032937030335559742 Test RE 0.02743154572897694\n",
      "76 Train Loss 0.003712631 Test MSE 0.0032443531986727802 Test RE 0.02722526553382606\n",
      "77 Train Loss 0.0035688034 Test MSE 0.0032806031163996013 Test RE 0.02737694016901116\n",
      "78 Train Loss 0.003445513 Test MSE 0.003148944354813632 Test RE 0.026821962649737328\n",
      "79 Train Loss 0.0033426643 Test MSE 0.0030805387343258253 Test RE 0.026529031612278733\n",
      "80 Train Loss 0.003240242 Test MSE 0.003047099582176527 Test RE 0.026384652829888878\n",
      "81 Train Loss 0.0030985004 Test MSE 0.0029049291641363717 Test RE 0.02576177801308428\n",
      "82 Train Loss 0.0029394962 Test MSE 0.002635829981886207 Test RE 0.024539559189278793\n",
      "83 Train Loss 0.0028421155 Test MSE 0.002456919319073515 Test RE 0.023692097318819282\n",
      "84 Train Loss 0.002712841 Test MSE 0.002352232226192887 Test RE 0.023181853561736056\n",
      "85 Train Loss 0.0026114762 Test MSE 0.002133326419201032 Test RE 0.022076830137807885\n",
      "86 Train Loss 0.0025554951 Test MSE 0.0020442911301418835 Test RE 0.02161122736456039\n",
      "87 Train Loss 0.0024839246 Test MSE 0.002075218471376038 Test RE 0.02177408793389716\n",
      "88 Train Loss 0.002382604 Test MSE 0.0019387510977944928 Test RE 0.02104597686439528\n",
      "89 Train Loss 0.002302805 Test MSE 0.0018613890420177163 Test RE 0.020621803142478468\n",
      "90 Train Loss 0.0022600656 Test MSE 0.0018439073232792518 Test RE 0.020524737189149236\n",
      "91 Train Loss 0.0021770196 Test MSE 0.0018473405934093252 Test RE 0.02054383635838993\n",
      "92 Train Loss 0.0020829432 Test MSE 0.001976910724728601 Test RE 0.021252087190390026\n",
      "93 Train Loss 0.0020226892 Test MSE 0.0019724283025989568 Test RE 0.021227980162103297\n",
      "94 Train Loss 0.0019634021 Test MSE 0.0019927780572028798 Test RE 0.02133720483976474\n",
      "95 Train Loss 0.0019031665 Test MSE 0.0020730626504399424 Test RE 0.02176277509318233\n",
      "96 Train Loss 0.0018361105 Test MSE 0.002025100531778376 Test RE 0.021509551460990376\n",
      "97 Train Loss 0.001794518 Test MSE 0.001989850650555807 Test RE 0.021321526818959307\n",
      "98 Train Loss 0.0017514448 Test MSE 0.0018528082308713397 Test RE 0.02057421604540927\n",
      "99 Train Loss 0.0017234618 Test MSE 0.0017523054312200584 Test RE 0.02000842776932826\n",
      "Training time: 123.24\n",
      "5\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 63.574265 Test MSE 6.23724030598207 Test RE 1.193725025582304\n",
      "1 Train Loss 53.16702 Test MSE 8.503654068566608 Test RE 1.3938333532156284\n",
      "2 Train Loss 43.395103 Test MSE 8.439607014010466 Test RE 1.3885744582298978\n",
      "3 Train Loss 39.23504 Test MSE 8.704097021343008 Test RE 1.4101649693266136\n",
      "4 Train Loss 37.129936 Test MSE 9.126785776160387 Test RE 1.4439993200273649\n",
      "5 Train Loss 35.21373 Test MSE 9.264265499398258 Test RE 1.4548343836966648\n",
      "6 Train Loss 33.07464 Test MSE 9.303308698340041 Test RE 1.457896778027482\n",
      "7 Train Loss 30.802841 Test MSE 9.068518060054783 Test RE 1.4393825104876228\n",
      "8 Train Loss 28.032427 Test MSE 9.146769179877651 Test RE 1.4455792981296596\n",
      "9 Train Loss 25.81414 Test MSE 9.027480813370017 Test RE 1.436122039979204\n",
      "10 Train Loss 23.663235 Test MSE 8.701133004692773 Test RE 1.4099248462941465\n",
      "11 Train Loss 21.892479 Test MSE 8.76581359126454 Test RE 1.415155539646459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 20.477448 Test MSE 8.60775328082814 Test RE 1.402338849314682\n",
      "13 Train Loss 18.675453 Test MSE 8.392884899791328 Test RE 1.3847255127424773\n",
      "14 Train Loss 16.938587 Test MSE 8.209951655397388 Test RE 1.3695514755661597\n",
      "15 Train Loss 15.661136 Test MSE 8.195631880527182 Test RE 1.3683565703616356\n",
      "16 Train Loss 13.329669 Test MSE 7.87110553519069 Test RE 1.3409912003251956\n",
      "17 Train Loss 10.777473 Test MSE 6.782152380342933 Test RE 1.2447777931205701\n",
      "18 Train Loss 9.476749 Test MSE 6.5458179806849515 Test RE 1.222897402813169\n",
      "19 Train Loss 8.740136 Test MSE 6.386808353106598 Test RE 1.207952905020591\n",
      "20 Train Loss 8.054649 Test MSE 6.393667539945081 Test RE 1.2086013784682192\n",
      "21 Train Loss 7.6457996 Test MSE 6.45705945547934 Test RE 1.214578119106495\n",
      "22 Train Loss 7.157097 Test MSE 6.488700959615875 Test RE 1.2175503786102386\n",
      "23 Train Loss 6.542318 Test MSE 6.404305887102698 Test RE 1.2096064492695218\n",
      "24 Train Loss 5.595562 Test MSE 5.988306131287359 Test RE 1.169661128803047\n",
      "25 Train Loss 4.0200405 Test MSE 5.4645136383661574 Test RE 1.117336065983414\n",
      "26 Train Loss 3.0499547 Test MSE 5.173937331958075 Test RE 1.0872230277954422\n",
      "27 Train Loss 2.5965579 Test MSE 5.258311671557074 Test RE 1.096052160164724\n",
      "28 Train Loss 2.2778072 Test MSE 5.261826625728152 Test RE 1.0964184307234233\n",
      "29 Train Loss 2.1103406 Test MSE 5.248312938203718 Test RE 1.0950095871241028\n",
      "30 Train Loss 1.9476694 Test MSE 5.250293905425847 Test RE 1.0952162224253874\n",
      "31 Train Loss 1.878118 Test MSE 5.276436696051587 Test RE 1.097939541874317\n",
      "32 Train Loss 1.7839917 Test MSE 5.325987481757611 Test RE 1.1030828460086586\n",
      "33 Train Loss 1.7100966 Test MSE 5.3879025101388285 Test RE 1.1094760323122683\n",
      "34 Train Loss 1.6615651 Test MSE 5.4313280706724925 Test RE 1.1139381516556355\n",
      "35 Train Loss 1.609621 Test MSE 5.501376284365932 Test RE 1.1210984077216615\n",
      "36 Train Loss 1.5687331 Test MSE 5.526508317449991 Test RE 1.1236562564738606\n",
      "37 Train Loss 1.5270561 Test MSE 5.5452201397230185 Test RE 1.1255569040163425\n",
      "38 Train Loss 1.4833425 Test MSE 5.58303797846728 Test RE 1.129388474330609\n",
      "39 Train Loss 1.444965 Test MSE 5.550573353117893 Test RE 1.1261000648527255\n",
      "40 Train Loss 1.4172001 Test MSE 5.533153440676597 Test RE 1.1243316007112256\n",
      "41 Train Loss 1.3866841 Test MSE 5.543760467528172 Test RE 1.1254087536988004\n",
      "42 Train Loss 1.3570054 Test MSE 5.549065309905397 Test RE 1.125947078592196\n",
      "43 Train Loss 1.3295445 Test MSE 5.535703304571672 Test RE 1.1245906358501696\n",
      "44 Train Loss 1.3027049 Test MSE 5.531940909219299 Test RE 1.1242084013327365\n",
      "45 Train Loss 1.2833674 Test MSE 5.520710220152691 Test RE 1.1230666637657782\n",
      "46 Train Loss 1.2626294 Test MSE 5.496505862322111 Test RE 1.1206020381635515\n",
      "47 Train Loss 1.238556 Test MSE 5.536387227336804 Test RE 1.124660103932212\n",
      "48 Train Loss 1.2187829 Test MSE 5.563943091558915 Test RE 1.1274554751029482\n",
      "49 Train Loss 1.1965938 Test MSE 5.5827696452806785 Test RE 1.1293613335471477\n",
      "50 Train Loss 1.1780638 Test MSE 5.586285727925876 Test RE 1.1297169189466785\n",
      "51 Train Loss 1.1621367 Test MSE 5.614015157838132 Test RE 1.132517315222084\n",
      "52 Train Loss 1.1428208 Test MSE 5.645048244329787 Test RE 1.1356431593245326\n",
      "53 Train Loss 1.1244928 Test MSE 5.692719715899898 Test RE 1.1404282348662265\n",
      "54 Train Loss 1.1053421 Test MSE 5.7293970392130005 Test RE 1.1440961388484694\n",
      "55 Train Loss 1.0832704 Test MSE 5.749280018264514 Test RE 1.146079623122301\n",
      "56 Train Loss 1.0621662 Test MSE 5.787094313680454 Test RE 1.1498424565079546\n",
      "57 Train Loss 1.0303538 Test MSE 5.809734421635081 Test RE 1.1520894516888518\n",
      "58 Train Loss 1.0012332 Test MSE 5.871118021780606 Test RE 1.1581597446172782\n",
      "59 Train Loss 0.9755459 Test MSE 5.969759223252812 Test RE 1.1678483940947795\n",
      "60 Train Loss 0.95771056 Test MSE 5.969790075298628 Test RE 1.1678514118434244\n",
      "61 Train Loss 0.9434149 Test MSE 6.006814291236643 Test RE 1.1714672801094683\n",
      "62 Train Loss 0.93174887 Test MSE 6.024821587255075 Test RE 1.173221885050089\n",
      "63 Train Loss 0.9188416 Test MSE 6.025063833403127 Test RE 1.1732454712776261\n",
      "64 Train Loss 0.9030799 Test MSE 6.082941406344472 Test RE 1.1788671796632693\n",
      "65 Train Loss 0.8903556 Test MSE 6.095244466042637 Test RE 1.1800587370136666\n",
      "66 Train Loss 0.880189 Test MSE 6.097944410724097 Test RE 1.1803200670209646\n",
      "67 Train Loss 0.87421083 Test MSE 6.106017577660131 Test RE 1.1811011309755035\n",
      "68 Train Loss 0.8669998 Test MSE 6.1035741219184745 Test RE 1.1808647856750039\n",
      "69 Train Loss 0.86179996 Test MSE 6.1010943922754075 Test RE 1.1806248833791007\n",
      "70 Train Loss 0.85467166 Test MSE 6.11055137639977 Test RE 1.1815395412079868\n",
      "71 Train Loss 0.84776545 Test MSE 6.116043400060911 Test RE 1.18207039229828\n",
      "72 Train Loss 0.840922 Test MSE 6.132228436027239 Test RE 1.1836334298710223\n",
      "73 Train Loss 0.8341671 Test MSE 6.14482735976868 Test RE 1.1848487185494982\n",
      "74 Train Loss 0.8307044 Test MSE 6.154991624831793 Test RE 1.1858282530150852\n",
      "75 Train Loss 0.8273 Test MSE 6.177890014325104 Test RE 1.1880320211853614\n",
      "76 Train Loss 0.820796 Test MSE 6.189796374588125 Test RE 1.1891762895729985\n",
      "77 Train Loss 0.81638217 Test MSE 6.204988055958391 Test RE 1.1906346991178283\n",
      "78 Train Loss 0.80811465 Test MSE 6.236893534880333 Test RE 1.1936918414274762\n",
      "79 Train Loss 0.8036848 Test MSE 6.226585089544096 Test RE 1.1927049562292253\n",
      "80 Train Loss 0.7980303 Test MSE 6.229758395802059 Test RE 1.1930088415811362\n",
      "81 Train Loss 0.79245543 Test MSE 6.231816126482449 Test RE 1.1932058546959396\n",
      "82 Train Loss 0.78795755 Test MSE 6.240017724045475 Test RE 1.1939907764814648\n",
      "83 Train Loss 0.78065276 Test MSE 6.279359552642034 Test RE 1.1977487764907195\n",
      "84 Train Loss 0.77487427 Test MSE 6.293569723248658 Test RE 1.1991032614523212\n",
      "85 Train Loss 0.76956064 Test MSE 6.302064444661654 Test RE 1.1999122310651258\n",
      "86 Train Loss 0.76608837 Test MSE 6.29828140563359 Test RE 1.1995520319378243\n",
      "87 Train Loss 0.7643677 Test MSE 6.307217596715806 Test RE 1.2004027105526927\n",
      "88 Train Loss 0.7605474 Test MSE 6.316879242954893 Test RE 1.2013217709812116\n",
      "89 Train Loss 0.7570731 Test MSE 6.315478409836347 Test RE 1.201188560849607\n",
      "90 Train Loss 0.7550166 Test MSE 6.321795492988851 Test RE 1.201789157589299\n",
      "91 Train Loss 0.7526511 Test MSE 6.33002751660191 Test RE 1.2025713671844729\n",
      "92 Train Loss 0.7494972 Test MSE 6.343609877009469 Test RE 1.203860856465566\n",
      "93 Train Loss 0.74733746 Test MSE 6.349700237481424 Test RE 1.2044386180043536\n",
      "94 Train Loss 0.7423922 Test MSE 6.344412048708495 Test RE 1.203936970271438\n",
      "95 Train Loss 0.7388213 Test MSE 6.363520231054988 Test RE 1.2057486236836317\n",
      "96 Train Loss 0.7348806 Test MSE 6.39528702439083 Test RE 1.2087544351600705\n",
      "97 Train Loss 0.731389 Test MSE 6.402245572345 Test RE 1.2094118637412683\n",
      "98 Train Loss 0.72669697 Test MSE 6.417417907384708 Test RE 1.2108440755504855\n",
      "99 Train Loss 0.72367764 Test MSE 6.454241415236451 Test RE 1.214313052355405\n",
      "Training time: 123.52\n",
      "6\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 62.09768 Test MSE 6.7658804089535565 Test RE 1.2432836397006573\n",
      "1 Train Loss 46.986065 Test MSE 8.866727879767101 Test RE 1.4232780457469747\n",
      "2 Train Loss 41.027622 Test MSE 8.726914808539718 Test RE 1.4120121330130309\n",
      "3 Train Loss 37.78235 Test MSE 8.684110412383932 Test RE 1.4085450072662957\n",
      "4 Train Loss 35.748383 Test MSE 8.731006218078171 Test RE 1.4123430886301074\n",
      "5 Train Loss 31.952694 Test MSE 8.909000761225922 Test RE 1.4266668112337024\n",
      "6 Train Loss 29.076208 Test MSE 8.428533382357548 Test RE 1.3876631830208324\n",
      "7 Train Loss 26.245968 Test MSE 8.567038693361278 Test RE 1.3990183938205152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 23.770964 Test MSE 8.981859662907473 Test RE 1.4324886606637603\n",
      "9 Train Loss 21.90531 Test MSE 8.799723618529763 Test RE 1.4178901199761347\n",
      "10 Train Loss 19.401638 Test MSE 8.974813136807128 Test RE 1.4319266362243233\n",
      "11 Train Loss 17.333282 Test MSE 8.462042819155773 Test RE 1.3904189225891044\n",
      "12 Train Loss 14.936908 Test MSE 7.715677422184404 Test RE 1.3276851307127888\n",
      "13 Train Loss 13.127333 Test MSE 7.45541929437195 Test RE 1.3051009233331805\n",
      "14 Train Loss 11.637434 Test MSE 6.981474540580997 Test RE 1.2629368624976633\n",
      "15 Train Loss 10.508839 Test MSE 6.891233038862497 Test RE 1.254748047540276\n",
      "16 Train Loss 9.323751 Test MSE 6.511314575623338 Test RE 1.219670161119499\n",
      "17 Train Loss 8.392994 Test MSE 6.402665293982335 Test RE 1.2094515067073617\n",
      "18 Train Loss 7.350276 Test MSE 6.374890309554151 Test RE 1.2068253341830366\n",
      "19 Train Loss 6.211505 Test MSE 5.7346995121315345 Test RE 1.1446254385092283\n",
      "20 Train Loss 5.025415 Test MSE 5.299177304172346 Test RE 1.1003029710484646\n",
      "21 Train Loss 3.9921174 Test MSE 5.110390820915372 Test RE 1.0805257412103186\n",
      "22 Train Loss 3.1614022 Test MSE 5.287603499193611 Test RE 1.0991007416966232\n",
      "23 Train Loss 2.7554023 Test MSE 5.482454358784678 Test RE 1.1191687439661762\n",
      "24 Train Loss 2.5161073 Test MSE 5.388342493662879 Test RE 1.109521332056302\n",
      "25 Train Loss 2.327479 Test MSE 5.439041688196663 Test RE 1.1147288831413416\n",
      "26 Train Loss 2.147437 Test MSE 5.528038161318715 Test RE 1.1238117705514559\n",
      "27 Train Loss 2.0505066 Test MSE 5.555129472261521 Test RE 1.1265621426699084\n",
      "28 Train Loss 1.9177489 Test MSE 5.66162256668931 Test RE 1.137309107880574\n",
      "29 Train Loss 1.8200318 Test MSE 5.669583082160489 Test RE 1.1381083828621938\n",
      "30 Train Loss 1.729891 Test MSE 5.676041467821563 Test RE 1.1387564244111599\n",
      "31 Train Loss 1.654633 Test MSE 5.7755833983718645 Test RE 1.1486983307461796\n",
      "32 Train Loss 1.6063673 Test MSE 5.739093407029117 Test RE 1.145063857371847\n",
      "33 Train Loss 1.5506505 Test MSE 5.703154008004566 Test RE 1.1414729124702656\n",
      "34 Train Loss 1.496114 Test MSE 5.712108780671605 Test RE 1.1423686993639346\n",
      "35 Train Loss 1.4373009 Test MSE 5.731367497853548 Test RE 1.1442928611481342\n",
      "36 Train Loss 1.3812615 Test MSE 5.75931376249704 Test RE 1.1470792662842528\n",
      "37 Train Loss 1.3369267 Test MSE 5.719599358854436 Test RE 1.1431174769970949\n",
      "38 Train Loss 1.302937 Test MSE 5.713362473225805 Test RE 1.1424940559189793\n",
      "39 Train Loss 1.258794 Test MSE 5.763776822383271 Test RE 1.147523632770059\n",
      "40 Train Loss 1.2281634 Test MSE 5.756284742946311 Test RE 1.146777582556802\n",
      "41 Train Loss 1.190119 Test MSE 5.755414247670831 Test RE 1.1466908684472883\n",
      "42 Train Loss 1.1613754 Test MSE 5.760961779113698 Test RE 1.147243371814422\n",
      "43 Train Loss 1.1358944 Test MSE 5.7788680485405015 Test RE 1.1490249242354558\n",
      "44 Train Loss 1.1105388 Test MSE 5.833116846888545 Test RE 1.1544055295822193\n",
      "45 Train Loss 1.0917158 Test MSE 5.852006355813076 Test RE 1.1562731870299483\n",
      "46 Train Loss 1.0745196 Test MSE 5.846049907231955 Test RE 1.1556845824721182\n",
      "47 Train Loss 1.0559295 Test MSE 5.836053368201891 Test RE 1.1546960697853186\n",
      "48 Train Loss 1.0379282 Test MSE 5.849076816065835 Test RE 1.1559837331152958\n",
      "49 Train Loss 1.0268682 Test MSE 5.845603061612405 Test RE 1.1556404139763057\n",
      "50 Train Loss 1.013051 Test MSE 5.846953725962647 Test RE 1.155773915356731\n",
      "51 Train Loss 0.9995966 Test MSE 5.842768014722065 Test RE 1.1553601441679844\n",
      "52 Train Loss 0.98882735 Test MSE 5.844729620585805 Test RE 1.1555540737435803\n",
      "53 Train Loss 0.97749287 Test MSE 5.853367863165055 Test RE 1.1564076864472146\n",
      "54 Train Loss 0.9695724 Test MSE 5.862479353996205 Test RE 1.1573073822366484\n",
      "55 Train Loss 0.95873624 Test MSE 5.907938821883888 Test RE 1.1617857759743242\n",
      "56 Train Loss 0.948195 Test MSE 5.920214848291909 Test RE 1.1629921791058047\n",
      "57 Train Loss 0.9425405 Test MSE 5.9174782925679 Test RE 1.162723357715775\n",
      "58 Train Loss 0.9366714 Test MSE 5.9318923445747975 Test RE 1.1641386025731975\n",
      "59 Train Loss 0.9292649 Test MSE 5.952830064703582 Test RE 1.1661913149462513\n",
      "60 Train Loss 0.9225804 Test MSE 5.978918228261382 Test RE 1.168743926843107\n",
      "61 Train Loss 0.9146879 Test MSE 5.962050384509555 Test RE 1.1670941205273146\n",
      "62 Train Loss 0.907158 Test MSE 5.95905988407723 Test RE 1.1668013828768575\n",
      "63 Train Loss 0.89996535 Test MSE 5.991264899494613 Test RE 1.1699500526413364\n",
      "64 Train Loss 0.89232737 Test MSE 5.990116208178423 Test RE 1.1698378913606367\n",
      "65 Train Loss 0.8844811 Test MSE 6.011626965503911 Test RE 1.1719364773694394\n",
      "66 Train Loss 0.87765086 Test MSE 6.034867653203786 Test RE 1.1741996198353084\n",
      "67 Train Loss 0.8710733 Test MSE 6.047723052757184 Test RE 1.1754495871912352\n",
      "68 Train Loss 0.86043215 Test MSE 6.084143230574263 Test RE 1.1789836300014056\n",
      "69 Train Loss 0.8525845 Test MSE 6.092723839622938 Test RE 1.179814711131954\n",
      "70 Train Loss 0.8443001 Test MSE 6.092035671063763 Test RE 1.1797480796598316\n",
      "71 Train Loss 0.83569854 Test MSE 6.11352169792781 Test RE 1.1818266778121254\n",
      "72 Train Loss 0.8294462 Test MSE 6.136292079075844 Test RE 1.184025544029482\n",
      "73 Train Loss 0.8240389 Test MSE 6.135244684591742 Test RE 1.1839244899456902\n",
      "74 Train Loss 0.8190814 Test MSE 6.1483321593326705 Test RE 1.1851865689938168\n",
      "75 Train Loss 0.81135976 Test MSE 6.1785646372921335 Test RE 1.1880968857108098\n",
      "76 Train Loss 0.80550677 Test MSE 6.198751946466702 Test RE 1.1900362455219888\n",
      "77 Train Loss 0.7998432 Test MSE 6.2004634821894005 Test RE 1.1902005244758938\n",
      "78 Train Loss 0.7946477 Test MSE 6.200843007343459 Test RE 1.1902369495049832\n",
      "79 Train Loss 0.78999686 Test MSE 6.219819194979985 Test RE 1.1920567751458315\n",
      "80 Train Loss 0.78464985 Test MSE 6.226381472410772 Test RE 1.1926854545966254\n",
      "81 Train Loss 0.78059363 Test MSE 6.228941131621955 Test RE 1.1929305853061813\n",
      "82 Train Loss 0.7759969 Test MSE 6.239296288877187 Test RE 1.1939217532932735\n",
      "83 Train Loss 0.7719965 Test MSE 6.224845940960365 Test RE 1.192538377280372\n",
      "84 Train Loss 0.7679902 Test MSE 6.235455727432443 Test RE 1.1935542410389473\n",
      "85 Train Loss 0.7624632 Test MSE 6.23655389329109 Test RE 1.1936593386348961\n",
      "86 Train Loss 0.75863373 Test MSE 6.230162250372532 Test RE 1.1930475103572367\n",
      "87 Train Loss 0.7545352 Test MSE 6.264444419209246 Test RE 1.1963254463277697\n",
      "88 Train Loss 0.75075436 Test MSE 6.267466582437789 Test RE 1.196613983872374\n",
      "89 Train Loss 0.7472129 Test MSE 6.2687414716858365 Test RE 1.196735681587904\n",
      "90 Train Loss 0.74438024 Test MSE 6.2784994343167515 Test RE 1.1976667425711973\n",
      "91 Train Loss 0.74202496 Test MSE 6.273671074484326 Test RE 1.1972061326546037\n",
      "92 Train Loss 0.7381139 Test MSE 6.2877375157643804 Test RE 1.198547532330149\n",
      "93 Train Loss 0.73583513 Test MSE 6.298300160204289 Test RE 1.199553817906503\n",
      "94 Train Loss 0.7328946 Test MSE 6.3044265557181 Test RE 1.2001370828129243\n",
      "95 Train Loss 0.73059803 Test MSE 6.307749736472845 Test RE 1.2004533484547477\n",
      "96 Train Loss 0.72790176 Test MSE 6.31653636278143 Test RE 1.2012891666689292\n",
      "97 Train Loss 0.72524214 Test MSE 6.334598995976528 Test RE 1.2030055310155765\n",
      "98 Train Loss 0.7229147 Test MSE 6.3471680673330715 Test RE 1.2041984375612496\n",
      "99 Train Loss 0.72052103 Test MSE 6.355643881310242 Test RE 1.2050021941918188\n",
      "Training time: 123.22\n",
      "7\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 53.659374 Test MSE 7.464604033706453 Test RE 1.305904588541076\n",
      "1 Train Loss 40.276093 Test MSE 8.240927234394285 Test RE 1.3721326546387638\n",
      "2 Train Loss 30.826729 Test MSE 6.860848355106278 Test RE 1.251978786913406\n",
      "3 Train Loss 23.903214 Test MSE 5.910333298345463 Test RE 1.1620211869157198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 17.985065 Test MSE 5.992549782261372 Test RE 1.1700754992789029\n",
      "5 Train Loss 14.891932 Test MSE 6.037651528204124 Test RE 1.1744704168325129\n",
      "6 Train Loss 13.202248 Test MSE 5.836422456499953 Test RE 1.154732582308613\n",
      "7 Train Loss 12.0139675 Test MSE 5.793954375859464 Test RE 1.1505237703145805\n",
      "8 Train Loss 11.057463 Test MSE 5.744455109485128 Test RE 1.1455986159118827\n",
      "9 Train Loss 10.138431 Test MSE 5.692555994275998 Test RE 1.1404118354899753\n",
      "10 Train Loss 9.401694 Test MSE 5.684048603743212 Test RE 1.1395593575872962\n",
      "11 Train Loss 8.635667 Test MSE 5.615998214202594 Test RE 1.1327173189017052\n",
      "12 Train Loss 7.782666 Test MSE 5.572394979505746 Test RE 1.1283114787619601\n",
      "13 Train Loss 6.8637905 Test MSE 5.3202129581546265 Test RE 1.1024846935117394\n",
      "14 Train Loss 5.8937054 Test MSE 5.227931157119815 Test RE 1.092881288344\n",
      "15 Train Loss 5.2052937 Test MSE 5.23823633858387 Test RE 1.093957889689887\n",
      "16 Train Loss 4.694817 Test MSE 5.020504435212184 Test RE 1.0709809300285513\n",
      "17 Train Loss 4.123477 Test MSE 4.433007020857821 Test RE 1.006369045089942\n",
      "18 Train Loss 3.5536027 Test MSE 3.889790366166939 Test RE 0.9426949019981963\n",
      "19 Train Loss 3.1424613 Test MSE 3.7579289116823698 Test RE 0.9265787596129289\n",
      "20 Train Loss 2.8253567 Test MSE 3.6507838271359345 Test RE 0.9132740533334721\n",
      "21 Train Loss 2.5594301 Test MSE 3.4853483088435637 Test RE 0.8923416275919396\n",
      "22 Train Loss 2.2441483 Test MSE 3.0707874531262664 Test RE 0.8375928068402703\n",
      "23 Train Loss 2.0643098 Test MSE 2.8978003485876163 Test RE 0.8136587336770975\n",
      "24 Train Loss 1.9306402 Test MSE 2.7817791816040685 Test RE 0.797203848490703\n",
      "25 Train Loss 1.8414578 Test MSE 2.631745346087287 Test RE 0.7754074906322632\n",
      "26 Train Loss 1.7406462 Test MSE 2.613103866387933 Test RE 0.772656382712978\n",
      "27 Train Loss 1.6624069 Test MSE 2.5177912398642697 Test RE 0.758434219202431\n",
      "28 Train Loss 1.5961694 Test MSE 2.3526070818398983 Test RE 0.7331329860617503\n",
      "29 Train Loss 1.5423071 Test MSE 2.2370273348881367 Test RE 0.7148973804769877\n",
      "30 Train Loss 1.4899672 Test MSE 2.111688327613429 Test RE 0.6945811132068601\n",
      "31 Train Loss 1.4220301 Test MSE 2.05608094420314 Test RE 0.6853748507303303\n",
      "32 Train Loss 1.3835349 Test MSE 1.9919300821512869 Test RE 0.6745980872641646\n",
      "33 Train Loss 1.3569497 Test MSE 1.8975331784713652 Test RE 0.65841959824777\n",
      "34 Train Loss 1.3073725 Test MSE 1.8135287272618401 Test RE 0.6436803924173322\n",
      "35 Train Loss 1.2707038 Test MSE 1.7134500812391005 Test RE 0.625667776831234\n",
      "36 Train Loss 1.2278377 Test MSE 1.555112219769796 Test RE 0.5960585572682165\n",
      "37 Train Loss 1.2019705 Test MSE 1.5044437431975224 Test RE 0.5862677929007519\n",
      "38 Train Loss 1.1538198 Test MSE 1.3626317604515745 Test RE 0.5579526106070758\n",
      "39 Train Loss 1.0629628 Test MSE 1.0706626240899064 Test RE 0.4945775300347473\n",
      "40 Train Loss 0.9140971 Test MSE 0.9838542684721832 Test RE 0.47410381211977315\n",
      "41 Train Loss 0.7506142 Test MSE 0.9583459700230859 Test RE 0.4679174275308202\n",
      "42 Train Loss 0.63864046 Test MSE 0.8368342342432239 Test RE 0.4372479475299699\n",
      "43 Train Loss 0.4952946 Test MSE 0.6852069465854137 Test RE 0.3956570775777141\n",
      "44 Train Loss 0.41021314 Test MSE 0.659517335773727 Test RE 0.3881692854518644\n",
      "45 Train Loss 0.35884786 Test MSE 0.635965679028896 Test RE 0.38117543070728144\n",
      "46 Train Loss 0.31486344 Test MSE 0.5599990500066934 Test RE 0.3576858051530857\n",
      "47 Train Loss 0.29216912 Test MSE 0.5363506442417063 Test RE 0.3500519196216586\n",
      "48 Train Loss 0.258853 Test MSE 0.5039062353541375 Test RE 0.3392992709355927\n",
      "49 Train Loss 0.22585851 Test MSE 0.4601008924861819 Test RE 0.32421611551307705\n",
      "50 Train Loss 0.2027676 Test MSE 0.4415557888400373 Test RE 0.31761488811380945\n",
      "51 Train Loss 0.18970793 Test MSE 0.44633366699227334 Test RE 0.31932864911285885\n",
      "52 Train Loss 0.17051932 Test MSE 0.44970426895115767 Test RE 0.3205321269614364\n",
      "53 Train Loss 0.16201179 Test MSE 0.42943111105528126 Test RE 0.31322384220647337\n",
      "54 Train Loss 0.15254754 Test MSE 0.43030613989544886 Test RE 0.31354279955595493\n",
      "55 Train Loss 0.14570485 Test MSE 0.42515803356906484 Test RE 0.31166157073591233\n",
      "56 Train Loss 0.13889888 Test MSE 0.4146884336118833 Test RE 0.3078002876994421\n",
      "57 Train Loss 0.13372624 Test MSE 0.4115999330599062 Test RE 0.3066519339704234\n",
      "58 Train Loss 0.1301224 Test MSE 0.41341183748490956 Test RE 0.30732614916763423\n",
      "59 Train Loss 0.12748174 Test MSE 0.4146942988195788 Test RE 0.30780246440137843\n",
      "60 Train Loss 0.12502763 Test MSE 0.41101452506281827 Test RE 0.30643378479703864\n",
      "61 Train Loss 0.122019984 Test MSE 0.4168259003604066 Test RE 0.3085925298016547\n",
      "62 Train Loss 0.119337864 Test MSE 0.42655595027823273 Test RE 0.31217352081662864\n",
      "63 Train Loss 0.11681575 Test MSE 0.4258061277340794 Test RE 0.3118990225929048\n",
      "64 Train Loss 0.11537386 Test MSE 0.42531451739826986 Test RE 0.3117189205980861\n",
      "65 Train Loss 0.114020176 Test MSE 0.42839554727842294 Test RE 0.3128459480092937\n",
      "66 Train Loss 0.11005266 Test MSE 0.43582251358380675 Test RE 0.31554615375096057\n",
      "67 Train Loss 0.108971775 Test MSE 0.43217194461094094 Test RE 0.3142218240937627\n",
      "68 Train Loss 0.10794224 Test MSE 0.4311360319950256 Test RE 0.3138450045790072\n",
      "69 Train Loss 0.10690363 Test MSE 0.4354798884468888 Test RE 0.3154220948763206\n",
      "70 Train Loss 0.10567357 Test MSE 0.44204771776397234 Test RE 0.3177917632235945\n",
      "71 Train Loss 0.10466609 Test MSE 0.4497508218330374 Test RE 0.32054871709536004\n",
      "72 Train Loss 0.103834346 Test MSE 0.45121479757292493 Test RE 0.32106999939236436\n",
      "73 Train Loss 0.10277974 Test MSE 0.45156339550981517 Test RE 0.3211940010106691\n",
      "74 Train Loss 0.10191572 Test MSE 0.4555041119008813 Test RE 0.3225924591221743\n",
      "75 Train Loss 0.10070116 Test MSE 0.45763563758510334 Test RE 0.323346361831825\n",
      "76 Train Loss 0.0998813 Test MSE 0.46298517168487335 Test RE 0.3252307504051006\n",
      "77 Train Loss 0.09853564 Test MSE 0.47560622507683653 Test RE 0.3296338671289925\n",
      "78 Train Loss 0.09767787 Test MSE 0.4785779867540965 Test RE 0.3306620999296376\n",
      "79 Train Loss 0.096831635 Test MSE 0.481126650481198 Test RE 0.33154140015957184\n",
      "80 Train Loss 0.09573527 Test MSE 0.4797289224362284 Test RE 0.33105946701024647\n",
      "81 Train Loss 0.09463349 Test MSE 0.4769389637317756 Test RE 0.33009539227574247\n",
      "82 Train Loss 0.09388216 Test MSE 0.48620692110398134 Test RE 0.33328719528730144\n",
      "83 Train Loss 0.092927024 Test MSE 0.4853049571636859 Test RE 0.3329779107364637\n",
      "84 Train Loss 0.09215848 Test MSE 0.4835843705383341 Test RE 0.3323871213423545\n",
      "85 Train Loss 0.09187214 Test MSE 0.4865347543699255 Test RE 0.33339953862626664\n",
      "86 Train Loss 0.09113814 Test MSE 0.48906274602830585 Test RE 0.3342645737145893\n",
      "87 Train Loss 0.0904229 Test MSE 0.48929466845934355 Test RE 0.33434382148452946\n",
      "88 Train Loss 0.08940161 Test MSE 0.490733362744432 Test RE 0.33483500349118406\n",
      "89 Train Loss 0.08864875 Test MSE 0.4908694834288521 Test RE 0.33488143890103417\n",
      "90 Train Loss 0.087947436 Test MSE 0.49097995774799474 Test RE 0.3349191207277569\n",
      "91 Train Loss 0.08660633 Test MSE 0.4932306594219094 Test RE 0.33568589451442216\n",
      "92 Train Loss 0.08565225 Test MSE 0.495745952755619 Test RE 0.3365407427955031\n",
      "93 Train Loss 0.0848444 Test MSE 0.49577192902350264 Test RE 0.3365495597691218\n",
      "94 Train Loss 0.08433717 Test MSE 0.49602523085648076 Test RE 0.336635524432785\n",
      "95 Train Loss 0.08369033 Test MSE 0.49723389017975256 Test RE 0.33704541296543383\n",
      "96 Train Loss 0.083037905 Test MSE 0.4990109815888505 Test RE 0.3376471683057654\n",
      "97 Train Loss 0.08226609 Test MSE 0.5009979383951247 Test RE 0.338318720490123\n",
      "98 Train Loss 0.08150663 Test MSE 0.50446806664902 Test RE 0.339488369451783\n",
      "99 Train Loss 0.081021026 Test MSE 0.5076959776171658 Test RE 0.3405727699523018\n",
      "Training time: 123.00\n",
      "8\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.06594 Test MSE 7.418930542450973 Test RE 1.3019032551029006\n",
      "1 Train Loss 36.630066 Test MSE 8.89102312308473 Test RE 1.425226635596518\n",
      "2 Train Loss 29.961525 Test MSE 7.61675099376131 Test RE 1.319146225759813\n",
      "3 Train Loss 26.17129 Test MSE 7.664472344615062 Test RE 1.323272207096131\n",
      "4 Train Loss 22.909851 Test MSE 7.465905797625747 Test RE 1.3060184529442425\n",
      "5 Train Loss 19.978207 Test MSE 7.487964201310754 Test RE 1.307946379389365\n",
      "6 Train Loss 16.018255 Test MSE 7.103497043489282 Test RE 1.2739258853950988\n",
      "7 Train Loss 14.037176 Test MSE 7.137468098331373 Test RE 1.2769684001433756\n",
      "8 Train Loss 12.8664665 Test MSE 7.029807161699259 Test RE 1.2673009668225808\n",
      "9 Train Loss 11.962523 Test MSE 6.891328935710717 Test RE 1.254756777905639\n",
      "10 Train Loss 10.7217865 Test MSE 6.886745635554667 Test RE 1.2543394503105172\n",
      "11 Train Loss 9.636999 Test MSE 6.513854375357623 Test RE 1.219908009859605\n",
      "12 Train Loss 8.519547 Test MSE 6.314620240203362 Test RE 1.2011069471934523\n",
      "13 Train Loss 7.4631004 Test MSE 5.919820384026923 Test RE 1.1629534333415958\n",
      "14 Train Loss 5.5309787 Test MSE 5.418027404267535 Test RE 1.112573365602987\n",
      "15 Train Loss 4.57384 Test MSE 5.438752429741536 Test RE 1.1146992410591265\n",
      "16 Train Loss 4.036311 Test MSE 5.255559761774918 Test RE 1.0957653160609568\n",
      "17 Train Loss 3.7402081 Test MSE 5.13637452015559 Test RE 1.0832692161461164\n",
      "18 Train Loss 3.378279 Test MSE 5.152059723180264 Test RE 1.0849219719463796\n",
      "19 Train Loss 3.103054 Test MSE 5.039222069555697 Test RE 1.072975508478471\n",
      "20 Train Loss 2.816556 Test MSE 5.101910013235257 Test RE 1.0796287906308184\n",
      "21 Train Loss 2.5945346 Test MSE 5.055565836274314 Test RE 1.0747140968085434\n",
      "22 Train Loss 2.4557393 Test MSE 4.962126031002973 Test RE 1.0647360422153864\n",
      "23 Train Loss 2.3414793 Test MSE 4.963980730832118 Test RE 1.0649350074623465\n",
      "24 Train Loss 2.2579863 Test MSE 4.820452298814793 Test RE 1.0494263268272015\n",
      "25 Train Loss 2.1636815 Test MSE 4.713395809616118 Test RE 1.0377076442499178\n",
      "26 Train Loss 2.0707219 Test MSE 4.674733060121459 Test RE 1.033442858705296\n",
      "27 Train Loss 2.0033662 Test MSE 4.657207839554336 Test RE 1.0315038901921765\n",
      "28 Train Loss 1.9486051 Test MSE 4.609853149976953 Test RE 1.0262463032466302\n",
      "29 Train Loss 1.8901987 Test MSE 4.558875664302116 Test RE 1.0205562204214729\n",
      "30 Train Loss 1.847102 Test MSE 4.5492900432209336 Test RE 1.0194827306311942\n",
      "31 Train Loss 1.8015456 Test MSE 4.547261723973514 Test RE 1.0192554350570497\n",
      "32 Train Loss 1.764811 Test MSE 4.4769391064329005 Test RE 1.0113434217167412\n",
      "33 Train Loss 1.7358289 Test MSE 4.451583160249096 Test RE 1.008475392781364\n",
      "34 Train Loss 1.7087314 Test MSE 4.457430238461226 Test RE 1.0091374830167816\n",
      "35 Train Loss 1.6884093 Test MSE 4.430286390596931 Test RE 1.0060601826993034\n",
      "36 Train Loss 1.6645641 Test MSE 4.4188013648458355 Test RE 1.0047552867704066\n",
      "37 Train Loss 1.6255528 Test MSE 4.369418493977516 Test RE 0.9991251278468243\n",
      "38 Train Loss 1.6026248 Test MSE 4.322992008038335 Test RE 0.9938029386393755\n",
      "39 Train Loss 1.5805291 Test MSE 4.327788904842362 Test RE 0.9943541596944481\n",
      "40 Train Loss 1.5541646 Test MSE 4.317640964846288 Test RE 0.9931876785266356\n",
      "41 Train Loss 1.5270585 Test MSE 4.302120641137564 Test RE 0.991401000130301\n",
      "42 Train Loss 1.5014018 Test MSE 4.301743528450681 Test RE 0.9913575473636773\n",
      "43 Train Loss 1.4702945 Test MSE 4.315197501773416 Test RE 0.9929066036429989\n",
      "44 Train Loss 1.4540066 Test MSE 4.332198998425409 Test RE 0.9948606629477663\n",
      "45 Train Loss 1.433983 Test MSE 4.356844656651338 Test RE 0.997686505309014\n",
      "46 Train Loss 1.4123341 Test MSE 4.3417720161899345 Test RE 0.995959246291451\n",
      "47 Train Loss 1.3922408 Test MSE 4.333288509671989 Test RE 0.9949857545861427\n",
      "48 Train Loss 1.3728108 Test MSE 4.318326666575593 Test RE 0.9932665414377824\n",
      "49 Train Loss 1.3583591 Test MSE 4.309136344030792 Test RE 0.9922090366926531\n",
      "50 Train Loss 1.3388377 Test MSE 4.317888030738798 Test RE 0.9932160944245731\n",
      "51 Train Loss 1.31947 Test MSE 4.315814742602382 Test RE 0.9929776132063678\n",
      "52 Train Loss 1.3047816 Test MSE 4.2843211534564745 Test RE 0.9893479753903258\n",
      "53 Train Loss 1.2727656 Test MSE 4.1906754049058375 Test RE 0.9784757614148812\n",
      "54 Train Loss 1.2365766 Test MSE 4.111073945936863 Test RE 0.9691381827616211\n",
      "55 Train Loss 1.2024608 Test MSE 4.0131310246010585 Test RE 0.957524135995323\n",
      "56 Train Loss 1.1644115 Test MSE 3.898608282596076 Test RE 0.9437628129101888\n",
      "57 Train Loss 1.1308215 Test MSE 3.837713407486289 Test RE 0.9363631845196624\n",
      "58 Train Loss 1.1037453 Test MSE 3.8216051962983997 Test RE 0.934395997954315\n",
      "59 Train Loss 1.0803833 Test MSE 3.818656922590787 Test RE 0.9340354967326546\n",
      "60 Train Loss 1.0616701 Test MSE 3.794704997953271 Test RE 0.9311015935482452\n",
      "61 Train Loss 1.0436609 Test MSE 3.7798382745948658 Test RE 0.9292758898042448\n",
      "62 Train Loss 1.0301937 Test MSE 3.770912481979348 Test RE 0.928178035110518\n",
      "63 Train Loss 1.0144954 Test MSE 3.7563263909996043 Test RE 0.9263811747203972\n",
      "64 Train Loss 0.99816483 Test MSE 3.695136925536776 Test RE 0.9188049543478545\n",
      "65 Train Loss 0.96793205 Test MSE 3.6049490166782947 Test RE 0.9075229651514871\n",
      "66 Train Loss 0.9431202 Test MSE 3.576839376907268 Test RE 0.9039778293851415\n",
      "67 Train Loss 0.9244803 Test MSE 3.532755831025403 Test RE 0.8983899215762483\n",
      "68 Train Loss 0.9098373 Test MSE 3.5287839273171637 Test RE 0.8978847463012505\n",
      "69 Train Loss 0.89553547 Test MSE 3.5188633928298763 Test RE 0.8966217381315426\n",
      "70 Train Loss 0.8816842 Test MSE 3.5015229581737706 Test RE 0.8944098005556931\n",
      "71 Train Loss 0.8727745 Test MSE 3.476470800815211 Test RE 0.8912044642344704\n",
      "72 Train Loss 0.8600397 Test MSE 3.442568306479782 Test RE 0.8868483112315665\n",
      "73 Train Loss 0.84642804 Test MSE 3.4251198250676196 Test RE 0.8845979835350969\n",
      "74 Train Loss 0.8331835 Test MSE 3.395479406828545 Test RE 0.8807620846620557\n",
      "75 Train Loss 0.81728035 Test MSE 3.3610394809516526 Test RE 0.87628397026848\n",
      "76 Train Loss 0.80757344 Test MSE 3.3428573626513383 Test RE 0.8739105520077801\n",
      "77 Train Loss 0.7975459 Test MSE 3.3134331736921845 Test RE 0.8700559238533508\n",
      "78 Train Loss 0.7864845 Test MSE 3.281474088081508 Test RE 0.8658497779253314\n",
      "79 Train Loss 0.7722689 Test MSE 3.2320661776429405 Test RE 0.859306669424036\n",
      "80 Train Loss 0.75887173 Test MSE 3.2152320326493675 Test RE 0.8570659080124259\n",
      "81 Train Loss 0.74984014 Test MSE 3.197352813774099 Test RE 0.8546796056936413\n",
      "82 Train Loss 0.7337781 Test MSE 3.130742689528049 Test RE 0.8457300225128225\n",
      "83 Train Loss 0.7167831 Test MSE 3.112804683902758 Test RE 0.8433036808209475\n",
      "84 Train Loss 0.69073814 Test MSE 3.065693539028512 Test RE 0.8368978064954364\n",
      "85 Train Loss 0.67027855 Test MSE 3.003284002173458 Test RE 0.8283354757867173\n",
      "86 Train Loss 0.64805824 Test MSE 2.9514193002383675 Test RE 0.8211519276951535\n",
      "87 Train Loss 0.62658465 Test MSE 2.910985829648558 Test RE 0.8155077750394061\n",
      "88 Train Loss 0.6072043 Test MSE 2.901658636382511 Test RE 0.8142002280712448\n",
      "89 Train Loss 0.5981205 Test MSE 2.8947871028044494 Test RE 0.8132355866100026\n",
      "90 Train Loss 0.59009814 Test MSE 2.8895504597990227 Test RE 0.8124996858352492\n",
      "91 Train Loss 0.58140934 Test MSE 2.924117539719238 Test RE 0.8173451184914134\n",
      "92 Train Loss 0.5741459 Test MSE 2.946123535990547 Test RE 0.8204148959440595\n",
      "93 Train Loss 0.5695226 Test MSE 2.951587153310941 Test RE 0.8211752776330037\n",
      "94 Train Loss 0.5638555 Test MSE 2.93378080966498 Test RE 0.8186945362038457\n",
      "95 Train Loss 0.55916584 Test MSE 2.9312203823650056 Test RE 0.8183372045663518\n",
      "96 Train Loss 0.5538598 Test MSE 2.938864262695584 Test RE 0.8194035179297102\n",
      "97 Train Loss 0.5497101 Test MSE 2.9355996357429195 Test RE 0.8189482757213203\n",
      "98 Train Loss 0.5456614 Test MSE 2.938737330967133 Test RE 0.8193858224156264\n",
      "99 Train Loss 0.5417083 Test MSE 2.938624445797254 Test RE 0.8193700848069829\n",
      "Training time: 121.96\n",
      "9\n",
      "KG_rowdy_tune36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.878372 Test MSE 9.198977994093998 Test RE 1.4496990364344207\n",
      "1 Train Loss 43.20704 Test MSE 8.64332681513708 Test RE 1.4052336066488897\n",
      "2 Train Loss 38.698135 Test MSE 8.943650717269927 Test RE 1.4294385008294925\n",
      "3 Train Loss 35.409492 Test MSE 9.104792223241269 Test RE 1.4422584096899942\n",
      "4 Train Loss 32.59513 Test MSE 9.38399489262078 Test RE 1.4642051891030587\n",
      "5 Train Loss 29.09335 Test MSE 9.350579848799745 Test RE 1.4615959531720495\n",
      "6 Train Loss 25.071936 Test MSE 9.081220849699578 Test RE 1.4403902702278557\n",
      "7 Train Loss 21.935532 Test MSE 8.9562699487611 Test RE 1.430446593468579\n",
      "8 Train Loss 19.776043 Test MSE 8.933091661529284 Test RE 1.4285944395593009\n",
      "9 Train Loss 18.130924 Test MSE 9.09513391771969 Test RE 1.4414932374524347\n",
      "10 Train Loss 16.970774 Test MSE 9.19488645147553 Test RE 1.4493766003388446\n",
      "11 Train Loss 15.716063 Test MSE 9.289542159508924 Test RE 1.4568177198420875\n",
      "12 Train Loss 14.119068 Test MSE 9.258245036571058 Test RE 1.4543615885365149\n",
      "13 Train Loss 12.714516 Test MSE 9.039775832072346 Test RE 1.4370996737032617\n",
      "14 Train Loss 11.088091 Test MSE 8.744333637266225 Test RE 1.4134206111029308\n",
      "15 Train Loss 9.541851 Test MSE 8.451091442194187 Test RE 1.389518907552616\n",
      "16 Train Loss 7.1285405 Test MSE 7.3915111996419816 Test RE 1.2994952007583354\n",
      "17 Train Loss 5.6869164 Test MSE 6.684563306097211 Test RE 1.2357897268494353\n",
      "18 Train Loss 4.638472 Test MSE 6.54212606234925 Test RE 1.2225524899128724\n",
      "19 Train Loss 3.905292 Test MSE 6.469603827924986 Test RE 1.2157573499644942\n",
      "20 Train Loss 3.4967842 Test MSE 6.491431024758334 Test RE 1.2178064886010367\n",
      "21 Train Loss 3.2065578 Test MSE 6.489904539422416 Test RE 1.217663294208441\n",
      "22 Train Loss 3.0390785 Test MSE 6.427371232807257 Test RE 1.211782712851531\n",
      "23 Train Loss 2.8917403 Test MSE 6.553762766790576 Test RE 1.2236393049016574\n",
      "24 Train Loss 2.793487 Test MSE 6.536367271794678 Test RE 1.222014287675371\n",
      "25 Train Loss 2.671027 Test MSE 6.41901996716152 Test RE 1.210995205145415\n",
      "26 Train Loss 2.5711718 Test MSE 6.341687775175089 Test RE 1.2036784588629328\n",
      "27 Train Loss 2.4524474 Test MSE 6.141455518589222 Test RE 1.1845235938815226\n",
      "28 Train Loss 2.3371363 Test MSE 6.0731304930429255 Test RE 1.1779161240665228\n",
      "29 Train Loss 2.2664115 Test MSE 6.010538097119643 Test RE 1.171830337852258\n",
      "30 Train Loss 2.192709 Test MSE 5.89984124780872 Test RE 1.160989316120371\n",
      "31 Train Loss 2.142296 Test MSE 5.9013944611255615 Test RE 1.1611421291642274\n",
      "32 Train Loss 2.0898168 Test MSE 5.8580893356783665 Test RE 1.1568739860754633\n",
      "33 Train Loss 2.04285 Test MSE 5.841269049274137 Test RE 1.155211930511173\n",
      "34 Train Loss 1.9932741 Test MSE 5.823707450853001 Test RE 1.1534740684859872\n",
      "35 Train Loss 1.961784 Test MSE 5.786739049509426 Test RE 1.1498071621033281\n",
      "36 Train Loss 1.9250798 Test MSE 5.771727526591583 Test RE 1.14831482204449\n",
      "37 Train Loss 1.8819907 Test MSE 5.764737003849176 Test RE 1.1476192111619223\n",
      "38 Train Loss 1.852497 Test MSE 5.726103084324079 Test RE 1.143767208695559\n",
      "39 Train Loss 1.8204565 Test MSE 5.727611558552217 Test RE 1.1439178547559363\n",
      "40 Train Loss 1.7851005 Test MSE 5.746340810244157 Test RE 1.145786630169426\n",
      "41 Train Loss 1.7584312 Test MSE 5.741398732908477 Test RE 1.1452938135793287\n",
      "42 Train Loss 1.7343205 Test MSE 5.740267477947358 Test RE 1.145180976691001\n",
      "43 Train Loss 1.709909 Test MSE 5.68547055420107 Test RE 1.139701887651184\n",
      "44 Train Loss 1.6715862 Test MSE 5.618279217911918 Test RE 1.1329473287777267\n",
      "45 Train Loss 1.6299088 Test MSE 5.6156459536397625 Test RE 1.1326817937927034\n",
      "46 Train Loss 1.597976 Test MSE 5.612434063204435 Test RE 1.1323578265948264\n",
      "47 Train Loss 1.5743481 Test MSE 5.557798412152494 Test RE 1.1268327363258712\n",
      "48 Train Loss 1.555472 Test MSE 5.564461519025473 Test RE 1.1275079999276234\n",
      "49 Train Loss 1.5269943 Test MSE 5.582198088204491 Test RE 1.1293035207566466\n",
      "50 Train Loss 1.5043745 Test MSE 5.568463882565827 Test RE 1.127913419726293\n",
      "51 Train Loss 1.4796573 Test MSE 5.563967679121706 Test RE 1.1274579662635515\n",
      "52 Train Loss 1.4575624 Test MSE 5.538661252168378 Test RE 1.1248910525936657\n",
      "53 Train Loss 1.4370182 Test MSE 5.543705157117473 Test RE 1.1254031395515085\n",
      "54 Train Loss 1.4173099 Test MSE 5.587622438672995 Test RE 1.1298520726512153\n",
      "55 Train Loss 1.4001217 Test MSE 5.622069712483606 Test RE 1.1333294481460083\n",
      "56 Train Loss 1.3793159 Test MSE 5.628803818975169 Test RE 1.1340079951548379\n",
      "57 Train Loss 1.3619416 Test MSE 5.615914081137788 Test RE 1.1327088342714686\n",
      "58 Train Loss 1.3430063 Test MSE 5.627715829246532 Test RE 1.1338983938331326\n",
      "59 Train Loss 1.3257309 Test MSE 5.656535957610009 Test RE 1.1367980929970776\n",
      "60 Train Loss 1.3108345 Test MSE 5.674618844978817 Test RE 1.1386137085384282\n",
      "61 Train Loss 1.2914381 Test MSE 5.6504758797637695 Test RE 1.13618898071359\n",
      "62 Train Loss 1.2788748 Test MSE 5.616775618048205 Test RE 1.1327957153233505\n",
      "63 Train Loss 1.2574264 Test MSE 5.611392297632722 Test RE 1.1322527290443372\n",
      "64 Train Loss 1.2424988 Test MSE 5.608148221028113 Test RE 1.131925390887803\n",
      "65 Train Loss 1.225337 Test MSE 5.635871054900201 Test RE 1.1347196728302507\n",
      "66 Train Loss 1.2057168 Test MSE 5.654144936954262 Test RE 1.1365578050329201\n",
      "67 Train Loss 1.1852869 Test MSE 5.624723630016143 Test RE 1.133596912636303\n",
      "68 Train Loss 1.1670605 Test MSE 5.650362657968808 Test RE 1.136177597424556\n",
      "69 Train Loss 1.1416322 Test MSE 5.668302510244202 Test RE 1.1379798450211138\n",
      "70 Train Loss 1.1263847 Test MSE 5.680555767256449 Test RE 1.1392091753106093\n",
      "71 Train Loss 1.112441 Test MSE 5.707062114931528 Test RE 1.1418639447151293\n",
      "72 Train Loss 1.0959133 Test MSE 5.690558403707785 Test RE 1.1402117253974873\n",
      "73 Train Loss 1.0779607 Test MSE 5.6740839637459874 Test RE 1.1385600452464208\n",
      "74 Train Loss 1.0652906 Test MSE 5.669377160094756 Test RE 1.1380877143444292\n",
      "75 Train Loss 1.0519098 Test MSE 5.662904448688103 Test RE 1.137437853089379\n",
      "76 Train Loss 1.0398705 Test MSE 5.692147556597233 Test RE 1.1403709228034173\n",
      "77 Train Loss 1.0274131 Test MSE 5.707495506339444 Test RE 1.141907300177004\n",
      "78 Train Loss 1.0165061 Test MSE 5.721339964083305 Test RE 1.1432914021950678\n",
      "79 Train Loss 1.0072954 Test MSE 5.729090415843195 Test RE 1.1440655238199786\n",
      "80 Train Loss 0.9965615 Test MSE 5.75473966209372 Test RE 1.14662366530988\n",
      "81 Train Loss 0.98660755 Test MSE 5.770991046298181 Test RE 1.1482415564395776\n",
      "82 Train Loss 0.9790554 Test MSE 5.790077343312451 Test RE 1.1501387686152953\n",
      "83 Train Loss 0.9738333 Test MSE 5.8102414471162644 Test RE 1.1521397230026573\n",
      "84 Train Loss 0.96767235 Test MSE 5.823186521628063 Test RE 1.15342247834386\n",
      "85 Train Loss 0.96271944 Test MSE 5.829904416036587 Test RE 1.154087607041092\n",
      "86 Train Loss 0.9583164 Test MSE 5.841220258758772 Test RE 1.1552071059171798\n",
      "87 Train Loss 0.951807 Test MSE 5.837686303544242 Test RE 1.1548576012199285\n",
      "88 Train Loss 0.94628286 Test MSE 5.820724152560512 Test RE 1.1531785867795754\n",
      "89 Train Loss 0.94084215 Test MSE 5.835838808091124 Test RE 1.1546748436262881\n",
      "90 Train Loss 0.9354731 Test MSE 5.836316299664124 Test RE 1.154722080728622\n",
      "91 Train Loss 0.9291631 Test MSE 5.838210338121477 Test RE 1.1549094344036994\n",
      "92 Train Loss 0.9245733 Test MSE 5.838105275137342 Test RE 1.154899042625187\n",
      "93 Train Loss 0.91900414 Test MSE 5.813550312390611 Test RE 1.1524677414291011\n",
      "94 Train Loss 0.913837 Test MSE 5.821200518238649 Test RE 1.153225773645525\n",
      "95 Train Loss 0.9095268 Test MSE 5.823733025298283 Test RE 1.1534766011876476\n",
      "96 Train Loss 0.904218 Test MSE 5.820861786618594 Test RE 1.153192220453514\n",
      "97 Train Loss 0.9001565 Test MSE 5.846143243823056 Test RE 1.1556938081228127\n",
      "98 Train Loss 0.89707077 Test MSE 5.856076288210998 Test RE 1.1566751975100393\n",
      "99 Train Loss 0.89283645 Test MSE 5.875522250291733 Test RE 1.1585940608679528\n",
      "Training time: 122.40\n",
      "0\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.51505 Test MSE 4.475964049740506 Test RE 1.011233282752708\n",
      "1 Train Loss 64.90967 Test MSE 4.973875516586307 Test RE 1.0659958554483822\n",
      "2 Train Loss 44.31784 Test MSE 6.384419999377554 Test RE 1.207727026269414\n",
      "3 Train Loss 33.165268 Test MSE 6.322180660480511 Test RE 1.2018257676841242\n",
      "4 Train Loss 26.035187 Test MSE 5.7550610451203745 Test RE 1.1466556824175884\n",
      "5 Train Loss 19.461346 Test MSE 5.191290092186129 Test RE 1.0890447089386996\n",
      "6 Train Loss 16.561237 Test MSE 5.155453781331714 Test RE 1.085279273900201\n",
      "7 Train Loss 15.166429 Test MSE 5.199835028193438 Test RE 1.089940631816619\n",
      "8 Train Loss 13.869132 Test MSE 5.346048188775409 Test RE 1.1051583131180944\n",
      "9 Train Loss 12.93318 Test MSE 5.436395738153579 Test RE 1.1144577070860484\n",
      "10 Train Loss 12.175859 Test MSE 5.429089935555784 Test RE 1.1137086128615776\n",
      "11 Train Loss 11.612736 Test MSE 5.52456628956174 Test RE 1.123458811414496\n",
      "12 Train Loss 11.053287 Test MSE 5.468595846736163 Test RE 1.1177533352420739\n",
      "13 Train Loss 10.559831 Test MSE 5.535384277565335 Test RE 1.1245582298546315\n",
      "14 Train Loss 10.015721 Test MSE 5.5424063098268 Test RE 1.125271295197855\n",
      "15 Train Loss 9.480065 Test MSE 5.50430503475607 Test RE 1.1213967858319682\n",
      "16 Train Loss 9.017409 Test MSE 5.6065026134382 Test RE 1.131759307395963\n",
      "17 Train Loss 8.435628 Test MSE 5.578802170062712 Test RE 1.1289599638201615\n",
      "18 Train Loss 7.6787786 Test MSE 5.494116385179049 Test RE 1.120358433944914\n",
      "19 Train Loss 7.1978683 Test MSE 5.441416950536807 Test RE 1.1149722609894812\n",
      "20 Train Loss 6.4716105 Test MSE 5.390091496871859 Test RE 1.1097013873262327\n",
      "21 Train Loss 6.0967073 Test MSE 5.415993059881303 Test RE 1.1123644731674918\n",
      "22 Train Loss 5.5971413 Test MSE 5.400731100530816 Test RE 1.1107960776745356\n",
      "23 Train Loss 5.2480993 Test MSE 5.447369822532483 Test RE 1.1155819801963156\n",
      "24 Train Loss 4.8854322 Test MSE 5.278686492580843 Test RE 1.0981735897233629\n",
      "25 Train Loss 4.655766 Test MSE 5.213928643527735 Test RE 1.0914167180060823\n",
      "26 Train Loss 4.4559703 Test MSE 5.134598917734538 Test RE 1.0830819613329492\n",
      "27 Train Loss 4.317754 Test MSE 5.077768621252346 Test RE 1.0770714496299\n",
      "28 Train Loss 4.173377 Test MSE 5.163632820859006 Test RE 1.0861398212569422\n",
      "29 Train Loss 3.961698 Test MSE 5.13592617469849 Test RE 1.0832219367441813\n",
      "30 Train Loss 3.680171 Test MSE 5.072155155173004 Test RE 1.0764759345116672\n",
      "31 Train Loss 3.2743673 Test MSE 5.166657748673878 Test RE 1.0864579125735527\n",
      "32 Train Loss 3.0184994 Test MSE 5.157875502472979 Test RE 1.085534143335379\n",
      "33 Train Loss 2.74209 Test MSE 5.10193900202381 Test RE 1.079631857823908\n",
      "34 Train Loss 2.4819016 Test MSE 5.098876348584918 Test RE 1.0793077619662412\n",
      "35 Train Loss 2.3509998 Test MSE 5.054627665174985 Test RE 1.0746143737983884\n",
      "36 Train Loss 2.225638 Test MSE 5.021275960818026 Test RE 1.0710632183203956\n",
      "37 Train Loss 2.076972 Test MSE 4.91449820324758 Test RE 1.0596139094195893\n",
      "38 Train Loss 1.8968709 Test MSE 4.643550433418947 Test RE 1.0299903211883699\n",
      "39 Train Loss 1.7485521 Test MSE 4.351876371769524 Test RE 0.9971174920568757\n",
      "40 Train Loss 1.6299553 Test MSE 4.264288858745477 Test RE 0.9870323073121678\n",
      "41 Train Loss 1.4552146 Test MSE 3.9227308598645116 Test RE 0.9466780690999029\n",
      "42 Train Loss 1.3133683 Test MSE 3.5539631969416106 Test RE 0.9010824337235119\n",
      "43 Train Loss 1.2038224 Test MSE 3.4240544486818005 Test RE 0.8844603966553168\n",
      "44 Train Loss 1.0784833 Test MSE 3.407190537178771 Test RE 0.8822796672610813\n",
      "45 Train Loss 0.99836504 Test MSE 3.327157901662861 Test RE 0.8718560115806512\n",
      "46 Train Loss 0.89924717 Test MSE 3.265425281823509 Test RE 0.8637298636950926\n",
      "47 Train Loss 0.8301758 Test MSE 3.2075319524098997 Test RE 0.8560390097723442\n",
      "48 Train Loss 0.7637373 Test MSE 3.086394727005719 Test RE 0.839718641389127\n",
      "49 Train Loss 0.725518 Test MSE 3.098307569782454 Test RE 0.8413376504309055\n",
      "50 Train Loss 0.68387616 Test MSE 3.1110515448608016 Test RE 0.8430661720500006\n",
      "51 Train Loss 0.65281266 Test MSE 3.0767951336588153 Test RE 0.8384117386840012\n",
      "52 Train Loss 0.6174978 Test MSE 3.0891608791567893 Test RE 0.8400948520685968\n",
      "53 Train Loss 0.59172034 Test MSE 3.1152752891493813 Test RE 0.8436382757386929\n",
      "54 Train Loss 0.5680744 Test MSE 3.1521943700463266 Test RE 0.8486225244673279\n",
      "55 Train Loss 0.5496295 Test MSE 3.1572485327381576 Test RE 0.8493025838041522\n",
      "56 Train Loss 0.53542775 Test MSE 3.14484772416426 Test RE 0.8476330286906849\n",
      "57 Train Loss 0.5157293 Test MSE 3.173133011140953 Test RE 0.8514363725464325\n",
      "58 Train Loss 0.49737895 Test MSE 3.222539680107451 Test RE 0.858039333994165\n",
      "59 Train Loss 0.48404667 Test MSE 3.2146717617729275 Test RE 0.8569912306667077\n",
      "60 Train Loss 0.46759817 Test MSE 3.23285796600871 Test RE 0.8594119190261371\n",
      "61 Train Loss 0.4537783 Test MSE 3.2527950628336155 Test RE 0.8620578507781319\n",
      "62 Train Loss 0.44539085 Test MSE 3.242523232402794 Test RE 0.8606956509517815\n",
      "63 Train Loss 0.4345091 Test MSE 3.2503082792964944 Test RE 0.8617282632826586\n",
      "64 Train Loss 0.42607635 Test MSE 3.2652270215341788 Test RE 0.8637036426186268\n",
      "65 Train Loss 0.41599852 Test MSE 3.296902240530228 Test RE 0.8678828272967772\n",
      "66 Train Loss 0.40806887 Test MSE 3.302750156688822 Test RE 0.8686521945752719\n",
      "67 Train Loss 0.40333158 Test MSE 3.294849647075321 Test RE 0.8676126209278829\n",
      "68 Train Loss 0.39997172 Test MSE 3.3050784646466442 Test RE 0.8689583233169372\n",
      "69 Train Loss 0.395958 Test MSE 3.3099776523618827 Test RE 0.8696021224771827\n",
      "70 Train Loss 0.39207494 Test MSE 3.313993670867975 Test RE 0.870129509654104\n",
      "71 Train Loss 0.38754052 Test MSE 3.3185273989280084 Test RE 0.8707244990636098\n",
      "72 Train Loss 0.3844491 Test MSE 3.3113331314086913 Test RE 0.8697801609608975\n",
      "73 Train Loss 0.3813388 Test MSE 3.30876847028634 Test RE 0.8694432689349536\n",
      "74 Train Loss 0.37631854 Test MSE 3.3338820579592015 Test RE 0.8727365734955452\n",
      "75 Train Loss 0.37410632 Test MSE 3.3425672768175447 Test RE 0.8738726331641654\n",
      "76 Train Loss 0.37027833 Test MSE 3.3628652052385744 Test RE 0.8765219376791391\n",
      "77 Train Loss 0.366793 Test MSE 3.375825137834358 Test RE 0.8782092996463906\n",
      "78 Train Loss 0.36442235 Test MSE 3.376363198482877 Test RE 0.8782792841714776\n",
      "79 Train Loss 0.362074 Test MSE 3.3732493299912805 Test RE 0.8778741919351782\n",
      "80 Train Loss 0.3591249 Test MSE 3.387386695457172 Test RE 0.879711863973744\n",
      "81 Train Loss 0.35509977 Test MSE 3.4047853755068784 Test RE 0.8819682083278204\n",
      "82 Train Loss 0.35046557 Test MSE 3.4222738739306573 Test RE 0.8842303984667089\n",
      "83 Train Loss 0.34813258 Test MSE 3.42752190395388 Test RE 0.8849081189213075\n",
      "84 Train Loss 0.3451119 Test MSE 3.4230103484366956 Test RE 0.8843255366903536\n",
      "85 Train Loss 0.34166327 Test MSE 3.4237228919781173 Test RE 0.8844175737567134\n",
      "86 Train Loss 0.3392681 Test MSE 3.4289290461589457 Test RE 0.8850897463217954\n",
      "87 Train Loss 0.3361488 Test MSE 3.4284836822075677 Test RE 0.8850322648367686\n",
      "88 Train Loss 0.33325922 Test MSE 3.419839016971791 Test RE 0.8839157892769408\n",
      "89 Train Loss 0.33142543 Test MSE 3.4182131707157475 Test RE 0.8837056504346511\n",
      "90 Train Loss 0.32837808 Test MSE 3.4246499746901273 Test RE 0.8845373078547618\n",
      "91 Train Loss 0.32586795 Test MSE 3.4229189580626356 Test RE 0.8843137313826256\n",
      "92 Train Loss 0.32226008 Test MSE 3.4403956615180586 Test RE 0.886568416913266\n",
      "93 Train Loss 0.31909117 Test MSE 3.447535023999591 Test RE 0.887487824682555\n",
      "94 Train Loss 0.31568184 Test MSE 3.463524309769674 Test RE 0.889543479104572\n",
      "95 Train Loss 0.3132069 Test MSE 3.461094599624921 Test RE 0.8892314108460213\n",
      "96 Train Loss 0.31025702 Test MSE 3.4542331328768854 Test RE 0.888349542619537\n",
      "97 Train Loss 0.3071061 Test MSE 3.4806850951181953 Test RE 0.8917444745746869\n",
      "98 Train Loss 0.30537876 Test MSE 3.4778089620149992 Test RE 0.8913759686946213\n",
      "99 Train Loss 0.30376318 Test MSE 3.4794014729910487 Test RE 0.8915800287169111\n",
      "Training time: 122.67\n",
      "1\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.25823 Test MSE 6.029000029612342 Test RE 1.1736286514804506\n",
      "1 Train Loss 49.87786 Test MSE 9.067090199026007 Test RE 1.4392691888243918\n",
      "2 Train Loss 42.73652 Test MSE 9.040124898033376 Test RE 1.437127419841299\n",
      "3 Train Loss 37.800842 Test MSE 9.423167909493294 Test RE 1.467258131960372\n",
      "4 Train Loss 33.58755 Test MSE 9.504703223117836 Test RE 1.4735922905198164\n",
      "5 Train Loss 30.684175 Test MSE 9.458363254678153 Test RE 1.4699956681879758\n",
      "6 Train Loss 27.537098 Test MSE 9.377411819773974 Test RE 1.4636915133918187\n",
      "7 Train Loss 25.221855 Test MSE 8.972127263146193 Test RE 1.4317123553381805\n",
      "8 Train Loss 23.528637 Test MSE 8.990682831067295 Test RE 1.4331920776838813\n",
      "9 Train Loss 21.88165 Test MSE 8.820512445822855 Test RE 1.4195639727950973\n",
      "10 Train Loss 20.370316 Test MSE 8.443302023781033 Test RE 1.388878396240062\n",
      "11 Train Loss 18.25074 Test MSE 8.171416474901276 Test RE 1.3663335523627753\n",
      "12 Train Loss 16.782183 Test MSE 8.232103068704598 Test RE 1.3713978363048556\n",
      "13 Train Loss 15.804415 Test MSE 8.135246416137548 Test RE 1.3633062207408095\n",
      "14 Train Loss 15.084581 Test MSE 7.920599155669007 Test RE 1.345200678988155\n",
      "15 Train Loss 14.330269 Test MSE 7.456898380397496 Test RE 1.305230376870916\n",
      "16 Train Loss 12.337803 Test MSE 6.1303789836097655 Test RE 1.1834549271611432\n",
      "17 Train Loss 10.93939 Test MSE 5.9526077923823575 Test RE 1.166169542573492\n",
      "18 Train Loss 10.103897 Test MSE 6.047578401197359 Test RE 1.175435529699554\n",
      "19 Train Loss 9.716806 Test MSE 5.998623386090236 Test RE 1.1706682999671136\n",
      "20 Train Loss 9.330341 Test MSE 5.9014308726815194 Test RE 1.1611457112774612\n",
      "21 Train Loss 9.001054 Test MSE 5.884590769460728 Test RE 1.1594878266473272\n",
      "22 Train Loss 8.716994 Test MSE 5.909724899436436 Test RE 1.161961377207769\n",
      "23 Train Loss 8.4066725 Test MSE 6.03964226657204 Test RE 1.1746640244475501\n",
      "24 Train Loss 8.1316 Test MSE 6.014093164121638 Test RE 1.1721768392363243\n",
      "25 Train Loss 7.838854 Test MSE 6.0691628385784675 Test RE 1.1775312873049755\n",
      "26 Train Loss 7.4882956 Test MSE 6.092749010078308 Test RE 1.1798171481735502\n",
      "27 Train Loss 7.2784796 Test MSE 6.139473184203283 Test RE 1.184332408635954\n",
      "28 Train Loss 6.8193064 Test MSE 6.175426178640577 Test RE 1.1877950950193046\n",
      "29 Train Loss 6.3530664 Test MSE 5.914667689394165 Test RE 1.1624471976749586\n",
      "30 Train Loss 5.7614956 Test MSE 5.55932826815037 Test RE 1.1269878133076074\n",
      "31 Train Loss 5.146905 Test MSE 5.233913565067913 Test RE 1.093506410612799\n",
      "32 Train Loss 4.2602925 Test MSE 4.894856317185028 Test RE 1.0574942979921578\n",
      "33 Train Loss 3.7774444 Test MSE 4.832943485453758 Test RE 1.0507851307582519\n",
      "34 Train Loss 3.3716674 Test MSE 4.950664478955523 Test RE 1.0635056640885348\n",
      "35 Train Loss 3.1935773 Test MSE 4.975456248915427 Test RE 1.0661652324509414\n",
      "36 Train Loss 3.006332 Test MSE 4.976342950387137 Test RE 1.0662602315944711\n",
      "37 Train Loss 2.831112 Test MSE 5.04689504846799 Test RE 1.0737920816274327\n",
      "38 Train Loss 2.703846 Test MSE 5.116257828139481 Test RE 1.0811458145164605\n",
      "39 Train Loss 2.5877862 Test MSE 5.146344313800857 Test RE 1.0843200288206523\n",
      "40 Train Loss 2.5112379 Test MSE 5.092666440578383 Test RE 1.0786503186976435\n",
      "41 Train Loss 2.433065 Test MSE 5.103273250990484 Test RE 1.0797730201862379\n",
      "42 Train Loss 2.3557234 Test MSE 5.178990307410358 Test RE 1.0877538006145218\n",
      "43 Train Loss 2.2707684 Test MSE 5.2863264255094835 Test RE 1.0989680050612085\n",
      "44 Train Loss 2.1894584 Test MSE 5.3547846411166775 Test RE 1.1060609631898135\n",
      "45 Train Loss 2.1181822 Test MSE 5.313264859554657 Test RE 1.1017645461172019\n",
      "46 Train Loss 2.0610394 Test MSE 5.3191658330337805 Test RE 1.1023761925704392\n",
      "47 Train Loss 2.02179 Test MSE 5.347793801420969 Test RE 1.1053387287076661\n",
      "48 Train Loss 1.9843355 Test MSE 5.342080932109288 Test RE 1.1047481727445845\n",
      "49 Train Loss 1.9538012 Test MSE 5.3503960249261535 Test RE 1.105607623574232\n",
      "50 Train Loss 1.9052825 Test MSE 5.374810631940187 Test RE 1.1081272737449763\n",
      "51 Train Loss 1.8686827 Test MSE 5.381633937599991 Test RE 1.10883043274376\n",
      "52 Train Loss 1.8266859 Test MSE 5.379590388874939 Test RE 1.1086198866350454\n",
      "53 Train Loss 1.7676684 Test MSE 5.366248620813546 Test RE 1.107244305004478\n",
      "54 Train Loss 1.7377365 Test MSE 5.369052912986583 Test RE 1.1075335788721552\n",
      "55 Train Loss 1.6859683 Test MSE 5.397660248427652 Test RE 1.1104802338163942\n",
      "56 Train Loss 1.6530296 Test MSE 5.350710266782239 Test RE 1.1056400906186283\n",
      "57 Train Loss 1.6258692 Test MSE 5.324620645294684 Test RE 1.1029412919205603\n",
      "58 Train Loss 1.5989623 Test MSE 5.366917278475021 Test RE 1.1073132865573443\n",
      "59 Train Loss 1.561908 Test MSE 5.397539441317581 Test RE 1.1104678067042464\n",
      "60 Train Loss 1.534608 Test MSE 5.42369370061837 Test RE 1.1131549908451095\n",
      "61 Train Loss 1.5165201 Test MSE 5.429352452693033 Test RE 1.1137355385587075\n",
      "62 Train Loss 1.4998186 Test MSE 5.418756063553934 Test RE 1.1126481769318244\n",
      "63 Train Loss 1.484565 Test MSE 5.422733579152746 Test RE 1.1130564591650816\n",
      "64 Train Loss 1.4626266 Test MSE 5.441353464881628 Test RE 1.114965756713885\n",
      "65 Train Loss 1.4474258 Test MSE 5.436560351308849 Test RE 1.1144745797549722\n",
      "66 Train Loss 1.4299905 Test MSE 5.441687101186247 Test RE 1.114999938223618\n",
      "67 Train Loss 1.4111774 Test MSE 5.460328845566256 Test RE 1.1169081490838724\n",
      "68 Train Loss 1.3991008 Test MSE 5.4359237981883695 Test RE 1.1144093323381383\n",
      "69 Train Loss 1.3777626 Test MSE 5.4355235364213215 Test RE 1.1143683030966967\n",
      "70 Train Loss 1.3590198 Test MSE 5.467828279098099 Test RE 1.11767488901758\n",
      "71 Train Loss 1.3501289 Test MSE 5.488799941046553 Test RE 1.119816238965026\n",
      "72 Train Loss 1.3359675 Test MSE 5.505930461981005 Test RE 1.1215623484515063\n",
      "73 Train Loss 1.3218089 Test MSE 5.497092098506317 Test RE 1.120661796122849\n",
      "74 Train Loss 1.3112302 Test MSE 5.5081635932457615 Test RE 1.121789770688028\n",
      "75 Train Loss 1.3002609 Test MSE 5.529834024827362 Test RE 1.123994299018665\n",
      "76 Train Loss 1.2876039 Test MSE 5.55459886761414 Test RE 1.1265083389389563\n",
      "77 Train Loss 1.2748075 Test MSE 5.5563737120304815 Test RE 1.1266882994900909\n",
      "78 Train Loss 1.2563843 Test MSE 5.537188745573424 Test RE 1.1247415110775951\n",
      "79 Train Loss 1.2449394 Test MSE 5.536357867917786 Test RE 1.124657121896304\n",
      "80 Train Loss 1.2340134 Test MSE 5.53817942912262 Test RE 1.1248421228797496\n",
      "81 Train Loss 1.2245294 Test MSE 5.538141619545948 Test RE 1.1248382831813775\n",
      "82 Train Loss 1.2165153 Test MSE 5.525487030597967 Test RE 1.1235524270469168\n",
      "83 Train Loss 1.2050272 Test MSE 5.533643512950053 Test RE 1.1243813907224287\n",
      "84 Train Loss 1.1933151 Test MSE 5.556943742273481 Test RE 1.1267460916731946\n",
      "85 Train Loss 1.1829778 Test MSE 5.5564914680470165 Test RE 1.1267002383579536\n",
      "86 Train Loss 1.1706254 Test MSE 5.582902413774613 Test RE 1.1293747626084751\n",
      "87 Train Loss 1.1577411 Test MSE 5.61350294592038 Test RE 1.1324656496955616\n",
      "88 Train Loss 1.1486077 Test MSE 5.634146056342746 Test RE 1.1345460049464784\n",
      "89 Train Loss 1.144137 Test MSE 5.63523635892677 Test RE 1.1346557765595386\n",
      "90 Train Loss 1.1350505 Test MSE 5.642567832623246 Test RE 1.1353936333716568\n",
      "91 Train Loss 1.1299835 Test MSE 5.659105689615561 Test RE 1.1370562841198768\n",
      "92 Train Loss 1.1212978 Test MSE 5.669946744604342 Test RE 1.1381448829569216\n",
      "93 Train Loss 1.1123915 Test MSE 5.68702599634195 Test RE 1.139857777924147\n",
      "94 Train Loss 1.0995525 Test MSE 5.715720128581145 Test RE 1.142729760323853\n",
      "95 Train Loss 1.0901214 Test MSE 5.703988488616958 Test RE 1.1415564190854326\n",
      "96 Train Loss 1.0792472 Test MSE 5.700676524792001 Test RE 1.1412249543085422\n",
      "97 Train Loss 1.0703195 Test MSE 5.719763329208023 Test RE 1.1431338624134313\n",
      "98 Train Loss 1.059814 Test MSE 5.73411848843832 Test RE 1.1445674519186109\n",
      "99 Train Loss 1.0521973 Test MSE 5.764877669576375 Test RE 1.1476332126424773\n",
      "Training time: 122.55\n",
      "2\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.970066 Test MSE 5.631350414660712 Test RE 1.134264491330722\n",
      "1 Train Loss 43.730667 Test MSE 8.063116011367633 Test RE 1.3572489504656047\n",
      "2 Train Loss 33.9517 Test MSE 7.200229564017982 Test RE 1.2825704564650031\n",
      "3 Train Loss 26.623678 Test MSE 6.6188055324472215 Test RE 1.229696313022729\n",
      "4 Train Loss 22.03021 Test MSE 6.09669837835244 Test RE 1.1801994696482017\n",
      "5 Train Loss 18.959541 Test MSE 6.1069379604966585 Test RE 1.1811901435138776\n",
      "6 Train Loss 16.039345 Test MSE 5.937951559745725 Test RE 1.1647330137239094\n",
      "7 Train Loss 13.999531 Test MSE 6.007605062538835 Test RE 1.171544386889847\n",
      "8 Train Loss 12.4011755 Test MSE 6.048344546101659 Test RE 1.1755099830891202\n",
      "9 Train Loss 11.162956 Test MSE 5.944005400406885 Test RE 1.165326594838703\n",
      "10 Train Loss 10.04871 Test MSE 5.811634694000027 Test RE 1.1522778514157035\n",
      "11 Train Loss 9.148122 Test MSE 5.734535174656711 Test RE 1.1446090378066787\n",
      "12 Train Loss 8.2934 Test MSE 5.6576025662094915 Test RE 1.13690526649315\n",
      "13 Train Loss 7.3291125 Test MSE 5.42261642895005 Test RE 1.113044436124289\n",
      "14 Train Loss 6.713553 Test MSE 5.304014444090151 Test RE 1.100805040058941\n",
      "15 Train Loss 6.3033304 Test MSE 5.279897842271455 Test RE 1.0982995865912644\n",
      "16 Train Loss 5.894524 Test MSE 5.176596379035828 Test RE 1.0875023707488005\n",
      "17 Train Loss 5.46171 Test MSE 4.873842414739601 Test RE 1.0552219142817787\n",
      "18 Train Loss 4.936118 Test MSE 4.7177587185189696 Test RE 1.0381878051461846\n",
      "19 Train Loss 4.4731727 Test MSE 4.618268239133221 Test RE 1.0271825604667004\n",
      "20 Train Loss 3.9360485 Test MSE 4.423855976003514 Test RE 1.0053297859777666\n",
      "21 Train Loss 3.5826123 Test MSE 4.356374337490187 Test RE 0.9976326539806737\n",
      "22 Train Loss 3.286045 Test MSE 4.202811618029648 Test RE 0.9798915720124589\n",
      "23 Train Loss 3.0376775 Test MSE 4.035960251931221 Test RE 0.9602437751541815\n",
      "24 Train Loss 2.8628173 Test MSE 3.84676330697025 Test RE 0.9374665762986696\n",
      "25 Train Loss 2.663042 Test MSE 3.5836455888212106 Test RE 0.9048374906525741\n",
      "26 Train Loss 2.4493291 Test MSE 3.3952487619838894 Test RE 0.880732170376074\n",
      "27 Train Loss 2.3138983 Test MSE 3.2271243928963624 Test RE 0.8586494840798105\n",
      "28 Train Loss 2.2135358 Test MSE 3.139880383735986 Test RE 0.8469633387521769\n",
      "29 Train Loss 2.1087756 Test MSE 3.096379802570766 Test RE 0.8410758695286703\n",
      "30 Train Loss 2.0321949 Test MSE 2.9949841736701197 Test RE 0.8271900964449922\n",
      "31 Train Loss 1.9637096 Test MSE 2.9691643702984596 Test RE 0.8236167692488563\n",
      "32 Train Loss 1.8895535 Test MSE 2.921319688061043 Test RE 0.8169539991807383\n",
      "33 Train Loss 1.8175985 Test MSE 2.7732341648977377 Test RE 0.7959784889016814\n",
      "34 Train Loss 1.7597088 Test MSE 2.6613286950702557 Test RE 0.7797534745058291\n",
      "35 Train Loss 1.6930755 Test MSE 2.5746354026614493 Test RE 0.7669480165929665\n",
      "36 Train Loss 1.6366131 Test MSE 2.5578005637957344 Test RE 0.7644364723063777\n",
      "37 Train Loss 1.5628451 Test MSE 2.4918011292505704 Test RE 0.7545095644609416\n",
      "38 Train Loss 1.4999079 Test MSE 2.388839965079689 Test RE 0.7387569648604949\n",
      "39 Train Loss 1.4308236 Test MSE 2.2737850215604745 Test RE 0.7207468631393735\n",
      "40 Train Loss 1.3765956 Test MSE 2.257596897820656 Test RE 0.7181766156892202\n",
      "41 Train Loss 1.3399565 Test MSE 2.247959976345638 Test RE 0.7166421492548433\n",
      "42 Train Loss 1.288167 Test MSE 2.1932028138493966 Test RE 0.7078601397231777\n",
      "43 Train Loss 1.2440346 Test MSE 2.1342743757665574 Test RE 0.6982857595975661\n",
      "44 Train Loss 1.2100422 Test MSE 2.1090440674842497 Test RE 0.6941460990891243\n",
      "45 Train Loss 1.1740615 Test MSE 2.013290924354339 Test RE 0.6782055324077652\n",
      "46 Train Loss 1.1096723 Test MSE 1.8082824185739013 Test RE 0.6427486752097772\n",
      "47 Train Loss 1.0413806 Test MSE 1.809386362700817 Test RE 0.642944842123656\n",
      "48 Train Loss 0.9898489 Test MSE 1.7266730115932347 Test RE 0.6280773192914594\n",
      "49 Train Loss 0.9397919 Test MSE 1.6248606436140929 Test RE 0.6092788744472911\n",
      "50 Train Loss 0.91089195 Test MSE 1.6173430554911277 Test RE 0.607867794131722\n",
      "51 Train Loss 0.86557823 Test MSE 1.599195867989676 Test RE 0.6044479232350998\n",
      "52 Train Loss 0.8117839 Test MSE 1.4719647403784015 Test RE 0.5799048804601392\n",
      "53 Train Loss 0.760379 Test MSE 1.3566962264800297 Test RE 0.5567360820171059\n",
      "54 Train Loss 0.70282567 Test MSE 1.2493230005812648 Test RE 0.5342511037507218\n",
      "55 Train Loss 0.62431055 Test MSE 1.1011974705673766 Test RE 0.5015805217364414\n",
      "56 Train Loss 0.53326505 Test MSE 0.9194357275121574 Test RE 0.45831993545166294\n",
      "57 Train Loss 0.47080842 Test MSE 0.810029288667957 Test RE 0.43018812847411564\n",
      "58 Train Loss 0.42450118 Test MSE 0.7935798599094794 Test RE 0.42579776645192524\n",
      "59 Train Loss 0.3854002 Test MSE 0.77606128255695 Test RE 0.4210717146967472\n",
      "60 Train Loss 0.35666323 Test MSE 0.756947873272992 Test RE 0.4158541566782372\n",
      "61 Train Loss 0.3300647 Test MSE 0.7198275731217744 Test RE 0.40552935738880075\n",
      "62 Train Loss 0.29747367 Test MSE 0.6663112805705154 Test RE 0.390163504257916\n",
      "63 Train Loss 0.27435052 Test MSE 0.6304907228711379 Test RE 0.3795311362192556\n",
      "64 Train Loss 0.2571206 Test MSE 0.6043991922392663 Test RE 0.37159511653279526\n",
      "65 Train Loss 0.23732576 Test MSE 0.5797132120767503 Test RE 0.36392732016211277\n",
      "66 Train Loss 0.22358473 Test MSE 0.557029221978819 Test RE 0.35673609153565744\n",
      "67 Train Loss 0.20734869 Test MSE 0.5279153889834594 Test RE 0.3472883551466965\n",
      "68 Train Loss 0.16949165 Test MSE 0.391451838265448 Test RE 0.2990523563315262\n",
      "69 Train Loss 0.13819116 Test MSE 0.32970867801692244 Test RE 0.2744563284786851\n",
      "70 Train Loss 0.11665356 Test MSE 0.32296776058586574 Test RE 0.2716362000052503\n",
      "71 Train Loss 0.10023812 Test MSE 0.31263294092296406 Test RE 0.2672547472269407\n",
      "72 Train Loss 0.083786964 Test MSE 0.2946154069375337 Test RE 0.2594393141448556\n",
      "73 Train Loss 0.07273896 Test MSE 0.26553093105427794 Test RE 0.24630068485086304\n",
      "74 Train Loss 0.062541954 Test MSE 0.2502239026987819 Test RE 0.23909608061204057\n",
      "75 Train Loss 0.05669494 Test MSE 0.2523938910383431 Test RE 0.24013058549467212\n",
      "76 Train Loss 0.05238508 Test MSE 0.2404858281611737 Test RE 0.23439740780271\n",
      "77 Train Loss 0.048365 Test MSE 0.2286690228932141 Test RE 0.22856605276854217\n",
      "78 Train Loss 0.04593163 Test MSE 0.2225891174751962 Test RE 0.2255069982557026\n",
      "79 Train Loss 0.04223193 Test MSE 0.21468641972673422 Test RE 0.22146767530962966\n",
      "80 Train Loss 0.03863009 Test MSE 0.208664822810796 Test RE 0.21833968565973097\n",
      "81 Train Loss 0.036123477 Test MSE 0.20543285428239774 Test RE 0.21664217662109456\n",
      "82 Train Loss 0.034285422 Test MSE 0.19726525776271284 Test RE 0.2122918699190684\n",
      "83 Train Loss 0.032619648 Test MSE 0.1895477927965957 Test RE 0.20809776990525078\n",
      "84 Train Loss 0.031070683 Test MSE 0.1839511045320548 Test RE 0.20500254858542502\n",
      "85 Train Loss 0.029549472 Test MSE 0.17841145443082582 Test RE 0.20189214727364646\n",
      "86 Train Loss 0.027917154 Test MSE 0.17187300923471074 Test RE 0.19815813251640457\n",
      "87 Train Loss 0.026079128 Test MSE 0.16629277634260325 Test RE 0.1949147711571522\n",
      "88 Train Loss 0.02445151 Test MSE 0.1635810546575994 Test RE 0.19331900991387432\n",
      "89 Train Loss 0.023177048 Test MSE 0.1571390670597039 Test RE 0.1894742276680709\n",
      "90 Train Loss 0.02211806 Test MSE 0.1497808171848954 Test RE 0.18498484846052823\n",
      "91 Train Loss 0.020815063 Test MSE 0.14237164003554856 Test RE 0.18035151888748843\n",
      "92 Train Loss 0.019647423 Test MSE 0.1357188287523411 Test RE 0.1760873314084217\n",
      "93 Train Loss 0.018161237 Test MSE 0.13135677618382452 Test RE 0.17323446569266543\n",
      "94 Train Loss 0.016916212 Test MSE 0.13154578531636885 Test RE 0.17335905433999135\n",
      "95 Train Loss 0.015632104 Test MSE 0.12643228407434065 Test RE 0.16995621561948832\n",
      "96 Train Loss 0.015081098 Test MSE 0.12389304788134174 Test RE 0.16824087904473806\n",
      "97 Train Loss 0.014316723 Test MSE 0.12256494571466647 Test RE 0.1673366995165751\n",
      "98 Train Loss 0.013720911 Test MSE 0.12070809192608875 Test RE 0.16606428989534494\n",
      "99 Train Loss 0.012941524 Test MSE 0.11724989994396132 Test RE 0.16366819794170698\n",
      "Training time: 122.32\n",
      "3\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.512596 Test MSE 5.769853737501916 Test RE 1.1481284069338833\n",
      "1 Train Loss 43.81887 Test MSE 7.680382647784103 Test RE 1.3246449530793476\n",
      "2 Train Loss 36.37877 Test MSE 8.33216789389821 Test RE 1.379707631525376\n",
      "3 Train Loss 29.728752 Test MSE 8.48841401132948 Test RE 1.3925837947404147\n",
      "4 Train Loss 26.962196 Test MSE 8.758447868988775 Test RE 1.4145608525028215\n",
      "5 Train Loss 24.234901 Test MSE 8.452915127649145 Test RE 1.3896688236164714\n",
      "6 Train Loss 22.117775 Test MSE 8.355011553026193 Test RE 1.3815976557347707\n",
      "7 Train Loss 20.818779 Test MSE 8.543880737591374 Test RE 1.3971262388243342\n",
      "8 Train Loss 19.75621 Test MSE 8.583652787591777 Test RE 1.4003742978938616\n",
      "9 Train Loss 18.228518 Test MSE 8.661169266891196 Test RE 1.406683273381904\n",
      "10 Train Loss 16.623224 Test MSE 8.610488723490771 Test RE 1.402561655003859\n",
      "11 Train Loss 14.830133 Test MSE 8.162261713016653 Test RE 1.3655679590436955\n",
      "12 Train Loss 12.761637 Test MSE 8.020345710411636 Test RE 1.3536444425161336\n",
      "13 Train Loss 11.340961 Test MSE 7.634140738527729 Test RE 1.320651233459617\n",
      "14 Train Loss 10.488084 Test MSE 7.264070947313813 Test RE 1.2882439124579765\n",
      "15 Train Loss 9.888805 Test MSE 7.18096411524814 Test RE 1.2808534385670651\n",
      "16 Train Loss 9.176138 Test MSE 7.075515814064859 Test RE 1.2714143629249253\n",
      "17 Train Loss 8.373699 Test MSE 6.889346092146337 Test RE 1.254576249199339\n",
      "18 Train Loss 7.6807303 Test MSE 6.853128748201304 Test RE 1.2512742454525763\n",
      "19 Train Loss 6.838396 Test MSE 6.71232033909395 Test RE 1.2383528203210554\n",
      "20 Train Loss 6.2985764 Test MSE 6.632269846372327 Test RE 1.2309464332581723\n",
      "21 Train Loss 5.7700734 Test MSE 6.56379891404991 Test RE 1.2245758604946857\n",
      "22 Train Loss 4.9979105 Test MSE 6.342306829393621 Test RE 1.2037372069494396\n",
      "23 Train Loss 4.4909716 Test MSE 6.1857764736346645 Test RE 1.1887900775715028\n",
      "24 Train Loss 3.7064996 Test MSE 6.163133480226732 Test RE 1.1866123037489102\n",
      "25 Train Loss 2.9627323 Test MSE 5.898129751366814 Test RE 1.1608209070796565\n",
      "26 Train Loss 2.4606156 Test MSE 5.959546263963937 Test RE 1.1668489992086173\n",
      "27 Train Loss 2.1448908 Test MSE 5.817380238900487 Test RE 1.1528472977931747\n",
      "28 Train Loss 1.9453272 Test MSE 5.784739674698977 Test RE 1.1496085101454523\n",
      "29 Train Loss 1.7924563 Test MSE 5.868159583494213 Test RE 1.1578679112852477\n",
      "30 Train Loss 1.6707634 Test MSE 5.7978179909777845 Test RE 1.1509073114973707\n",
      "31 Train Loss 1.6130649 Test MSE 5.820095351968533 Test RE 1.1531162973682103\n",
      "32 Train Loss 1.567753 Test MSE 5.848288195720095 Test RE 1.1559058009004826\n",
      "33 Train Loss 1.5178884 Test MSE 5.812703302240618 Test RE 1.152383783487742\n",
      "34 Train Loss 1.4641824 Test MSE 5.816877882782391 Test RE 1.152797520026135\n",
      "35 Train Loss 1.4107373 Test MSE 5.823940650764224 Test RE 1.1534971626540822\n",
      "36 Train Loss 1.371747 Test MSE 5.905281712451686 Test RE 1.1615244886446672\n",
      "37 Train Loss 1.3273704 Test MSE 5.965396593406485 Test RE 1.1674215911676227\n",
      "38 Train Loss 1.2955627 Test MSE 5.914246572834823 Test RE 1.1624058145826432\n",
      "39 Train Loss 1.2668532 Test MSE 5.92744638861441 Test RE 1.1637022595968949\n",
      "40 Train Loss 1.2390398 Test MSE 5.932277180591784 Test RE 1.1641763641483511\n",
      "41 Train Loss 1.2097341 Test MSE 5.923639602054694 Test RE 1.1633285170673018\n",
      "42 Train Loss 1.1904995 Test MSE 5.941076869008221 Test RE 1.1650394891125448\n",
      "43 Train Loss 1.1752868 Test MSE 5.945924088414485 Test RE 1.1655146597551571\n",
      "44 Train Loss 1.1572562 Test MSE 5.950257496776642 Test RE 1.165939297792935\n",
      "45 Train Loss 1.1408705 Test MSE 5.936246016170636 Test RE 1.1645657299768655\n",
      "46 Train Loss 1.1226169 Test MSE 5.940758696885575 Test RE 1.1650082920704534\n",
      "47 Train Loss 1.112807 Test MSE 5.962338910266301 Test RE 1.1671223601947707\n",
      "48 Train Loss 1.0995497 Test MSE 5.959863786567862 Test RE 1.1668800834540694\n",
      "49 Train Loss 1.0867004 Test MSE 5.97141649229547 Test RE 1.1680104864515797\n",
      "50 Train Loss 1.0682784 Test MSE 5.990438737781002 Test RE 1.169869385096176\n",
      "51 Train Loss 1.0512787 Test MSE 5.984232686762126 Test RE 1.1692632399723888\n",
      "52 Train Loss 1.0399092 Test MSE 5.9755465707044415 Test RE 1.1684143387930637\n",
      "53 Train Loss 1.0284244 Test MSE 5.9555284380586855 Test RE 1.166455597901615\n",
      "54 Train Loss 1.0165753 Test MSE 5.947761311924486 Test RE 1.1656947112927845\n",
      "55 Train Loss 1.0100029 Test MSE 5.960364089859986 Test RE 1.1669290595479016\n",
      "56 Train Loss 1.0005391 Test MSE 5.962006819004917 Test RE 1.1670898564626113\n",
      "57 Train Loss 0.99139106 Test MSE 5.943710810815632 Test RE 1.1652977172287664\n",
      "58 Train Loss 0.98413074 Test MSE 5.936042654827781 Test RE 1.1645457822120355\n",
      "59 Train Loss 0.97837615 Test MSE 5.9337697343890525 Test RE 1.1643228076235623\n",
      "60 Train Loss 0.96759343 Test MSE 5.943999960397428 Test RE 1.1653260615796701\n",
      "61 Train Loss 0.9553293 Test MSE 5.9700085033410755 Test RE 1.1678727768463142\n",
      "62 Train Loss 0.95035315 Test MSE 5.974198579214467 Test RE 1.168282543199012\n",
      "63 Train Loss 0.9448755 Test MSE 5.966511428390014 Test RE 1.1675306720651981\n",
      "64 Train Loss 0.94096625 Test MSE 5.980899892017373 Test RE 1.1689375961252115\n",
      "65 Train Loss 0.9374418 Test MSE 5.976130135159362 Test RE 1.1684713903466284\n",
      "66 Train Loss 0.9317088 Test MSE 5.971788320161663 Test RE 1.1680468506950477\n",
      "67 Train Loss 0.92772007 Test MSE 5.961941365794089 Test RE 1.167083450063692\n",
      "68 Train Loss 0.92306066 Test MSE 5.954915697881677 Test RE 1.1663955904142915\n",
      "69 Train Loss 0.9166128 Test MSE 5.961250443466498 Test RE 1.167015822144543\n",
      "70 Train Loss 0.91362697 Test MSE 5.961925183309087 Test RE 1.1670818661565305\n",
      "71 Train Loss 0.9083415 Test MSE 5.952695956336999 Test RE 1.1661781785983694\n",
      "72 Train Loss 0.9032335 Test MSE 5.959354435734032 Test RE 1.166830219559176\n",
      "73 Train Loss 0.8976086 Test MSE 5.9672002836720495 Test RE 1.1675980679352735\n",
      "74 Train Loss 0.89084077 Test MSE 5.981214739791576 Test RE 1.1689683634481496\n",
      "75 Train Loss 0.88406587 Test MSE 5.991177652280072 Test RE 1.1699415339681873\n",
      "76 Train Loss 0.8790184 Test MSE 6.013178666501368 Test RE 1.1720877157680045\n",
      "77 Train Loss 0.87608176 Test MSE 6.023596367210464 Test RE 1.1731025845830212\n",
      "78 Train Loss 0.87182796 Test MSE 6.0206609273535845 Test RE 1.1728167095418773\n",
      "79 Train Loss 0.8680233 Test MSE 6.010933391446586 Test RE 1.171868871030267\n",
      "80 Train Loss 0.865848 Test MSE 6.012083534160568 Test RE 1.171980979407515\n",
      "81 Train Loss 0.86318976 Test MSE 6.015515905625279 Test RE 1.1723154807549698\n",
      "82 Train Loss 0.8602964 Test MSE 6.009462707176021 Test RE 1.1717255027349665\n",
      "83 Train Loss 0.85616 Test MSE 6.02953622342256 Test RE 1.1736808391089368\n",
      "84 Train Loss 0.8529207 Test MSE 6.047958678279903 Test RE 1.175472485331852\n",
      "85 Train Loss 0.84925985 Test MSE 6.05909563864988 Test RE 1.176554269290645\n",
      "86 Train Loss 0.8454113 Test MSE 6.075125807290366 Test RE 1.1781096091078411\n",
      "87 Train Loss 0.8416183 Test MSE 6.0914266452166945 Test RE 1.1796891079900624\n",
      "88 Train Loss 0.83808136 Test MSE 6.09755727947424 Test RE 1.180282599802138\n",
      "89 Train Loss 0.8350357 Test MSE 6.095575977442525 Test RE 1.180090827408641\n",
      "90 Train Loss 0.83253556 Test MSE 6.104036494915294 Test RE 1.180909512718437\n",
      "91 Train Loss 0.82988244 Test MSE 6.110012824940331 Test RE 1.1814874727589888\n",
      "92 Train Loss 0.8276912 Test MSE 6.11462608926042 Test RE 1.1819334199048384\n",
      "93 Train Loss 0.82549024 Test MSE 6.109963053568368 Test RE 1.181482660627336\n",
      "94 Train Loss 0.82329285 Test MSE 6.108427171496911 Test RE 1.181334154648553\n",
      "95 Train Loss 0.82095796 Test MSE 6.1019830511113655 Test RE 1.1807108625875355\n",
      "96 Train Loss 0.81819665 Test MSE 6.084201138624584 Test RE 1.1789892406912215\n",
      "97 Train Loss 0.81372315 Test MSE 6.089001178812159 Test RE 1.1794542220308073\n",
      "98 Train Loss 0.8112946 Test MSE 6.093269985123764 Test RE 1.1798675886358565\n",
      "99 Train Loss 0.80878186 Test MSE 6.092076061017081 Test RE 1.1797519904946867\n",
      "Training time: 122.84\n",
      "4\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.275497 Test MSE 7.855377443188159 Test RE 1.339650741886604\n",
      "1 Train Loss 44.19073 Test MSE 7.7883653012596925 Test RE 1.3339244006354285\n",
      "2 Train Loss 35.05989 Test MSE 7.308106492695258 Test RE 1.2921427461664632\n",
      "3 Train Loss 31.104158 Test MSE 7.108980126879826 Test RE 1.2744174527476155\n",
      "4 Train Loss 27.700043 Test MSE 6.5006125877610454 Test RE 1.2186674248094116\n",
      "5 Train Loss 23.684025 Test MSE 5.8600687593594785 Test RE 1.1570694209881958\n",
      "6 Train Loss 20.446434 Test MSE 6.409900915957782 Test RE 1.2101347114737109\n",
      "7 Train Loss 16.788303 Test MSE 5.813976718899524 Test RE 1.152510005683227\n",
      "8 Train Loss 14.0731125 Test MSE 5.761730491680282 Test RE 1.1473199103346883\n",
      "9 Train Loss 12.193329 Test MSE 5.8309965876030985 Test RE 1.154195705094823\n",
      "10 Train Loss 11.12945 Test MSE 5.404347762646673 Test RE 1.1111679441563729\n",
      "11 Train Loss 10.152327 Test MSE 5.5425472508782585 Test RE 1.1252856026937694\n",
      "12 Train Loss 9.039865 Test MSE 5.437133018128305 Test RE 1.114533275489555\n",
      "13 Train Loss 7.8387184 Test MSE 5.33717052825209 Test RE 1.1042403175724806\n",
      "14 Train Loss 6.853051 Test MSE 5.410498805161243 Test RE 1.1118001108743703\n",
      "15 Train Loss 6.029269 Test MSE 5.332647107900494 Test RE 1.1037722791342481\n",
      "16 Train Loss 5.277281 Test MSE 4.995611931973593 Test RE 1.068322579236254\n",
      "17 Train Loss 4.8524957 Test MSE 4.726636532032173 Test RE 1.0391641698058391\n",
      "18 Train Loss 4.4144073 Test MSE 4.271254931120221 Test RE 0.9878381782304408\n",
      "19 Train Loss 3.9705234 Test MSE 3.862067457408658 Test RE 0.9393295565312376\n",
      "20 Train Loss 3.6106925 Test MSE 3.61270095134265 Test RE 0.9084981912621835\n",
      "21 Train Loss 3.273513 Test MSE 3.2418336766366833 Test RE 0.8606041282142196\n",
      "22 Train Loss 3.0271144 Test MSE 3.099385309593836 Test RE 0.8414839664795555\n",
      "23 Train Loss 2.8847778 Test MSE 2.898538152971684 Test RE 0.813762309269237\n",
      "24 Train Loss 2.6727207 Test MSE 2.5374212461494925 Test RE 0.7613850520700015\n",
      "25 Train Loss 2.4826372 Test MSE 2.282379101692733 Test RE 0.7221076589839205\n",
      "26 Train Loss 2.1683066 Test MSE 2.1056019819950387 Test RE 0.693579423901443\n",
      "27 Train Loss 1.8698107 Test MSE 1.7478499711207431 Test RE 0.6319171412811576\n",
      "28 Train Loss 1.4219629 Test MSE 1.2503096757725174 Test RE 0.5344620292971018\n",
      "29 Train Loss 1.0800372 Test MSE 1.1147479656267285 Test RE 0.5046571195240541\n",
      "30 Train Loss 0.92362475 Test MSE 0.9745423045578877 Test RE 0.4718548338773257\n",
      "31 Train Loss 0.80718714 Test MSE 0.8463303288972029 Test RE 0.43972181560301166\n",
      "32 Train Loss 0.69816554 Test MSE 0.6574544054815382 Test RE 0.3875617249661334\n",
      "33 Train Loss 0.5935828 Test MSE 0.4970211629193978 Test RE 0.33697330764544714\n",
      "34 Train Loss 0.5159117 Test MSE 0.4344479951452228 Test RE 0.3150481683229756\n",
      "35 Train Loss 0.47021478 Test MSE 0.3615058204267598 Test RE 0.28738606592974636\n",
      "36 Train Loss 0.40592903 Test MSE 0.26274592669555996 Test RE 0.24500562554337543\n",
      "37 Train Loss 0.3305692 Test MSE 0.22645212768283615 Test RE 0.2274554058749503\n",
      "38 Train Loss 0.2750707 Test MSE 0.20289829490629122 Test RE 0.21530160084261968\n",
      "39 Train Loss 0.24453415 Test MSE 0.1992585915845332 Test RE 0.2133617616065077\n",
      "40 Train Loss 0.216051 Test MSE 0.17723888318305595 Test RE 0.20122760703866982\n",
      "41 Train Loss 0.19350855 Test MSE 0.16726743232895658 Test RE 0.1954851425853053\n",
      "42 Train Loss 0.1746621 Test MSE 0.16050317378492068 Test RE 0.19149166378509475\n",
      "43 Train Loss 0.15438344 Test MSE 0.1340833706327551 Test RE 0.17502315961943837\n",
      "44 Train Loss 0.1315243 Test MSE 0.11032751282446053 Test RE 0.15876324762342048\n",
      "45 Train Loss 0.11219116 Test MSE 0.0888439095239724 Test RE 0.1424694969579933\n",
      "46 Train Loss 0.10140485 Test MSE 0.07212013604379901 Test RE 0.12836195676797418\n",
      "47 Train Loss 0.09262803 Test MSE 0.05946401574662385 Test RE 0.1165561457026799\n",
      "48 Train Loss 0.08411265 Test MSE 0.056995534307477745 Test RE 0.1141112532030481\n",
      "49 Train Loss 0.076108515 Test MSE 0.050959130955624085 Test RE 0.10789940921909631\n",
      "50 Train Loss 0.070896804 Test MSE 0.04682978549757164 Test RE 0.10343538720241637\n",
      "51 Train Loss 0.06622264 Test MSE 0.04303760181106505 Test RE 0.09915898938022738\n",
      "52 Train Loss 0.063152775 Test MSE 0.041865909904843915 Test RE 0.0977998812666728\n",
      "53 Train Loss 0.059725955 Test MSE 0.04186676506987494 Test RE 0.09780088010572348\n",
      "54 Train Loss 0.05613389 Test MSE 0.038758950234513014 Test RE 0.09410096199178239\n",
      "55 Train Loss 0.052346054 Test MSE 0.03420339805626752 Test RE 0.08839805055973594\n",
      "56 Train Loss 0.048585568 Test MSE 0.03377421145141757 Test RE 0.08784168730214474\n",
      "57 Train Loss 0.046220496 Test MSE 0.03138677303738384 Test RE 0.08468010615070883\n",
      "58 Train Loss 0.043014932 Test MSE 0.024126709024271865 Test RE 0.07424327199440887\n",
      "59 Train Loss 0.038370125 Test MSE 0.01915729841815625 Test RE 0.06615690697137783\n",
      "60 Train Loss 0.034519885 Test MSE 0.016637434411557312 Test RE 0.061652577597278296\n",
      "61 Train Loss 0.030889664 Test MSE 0.013279682684486331 Test RE 0.05508101177699926\n",
      "62 Train Loss 0.028564671 Test MSE 0.01232075355918083 Test RE 0.053055046036266436\n",
      "63 Train Loss 0.027086418 Test MSE 0.012398113636769048 Test RE 0.05322134755243172\n",
      "64 Train Loss 0.02591005 Test MSE 0.011987606825049393 Test RE 0.052332840211579496\n",
      "65 Train Loss 0.02310089 Test MSE 0.010409782225494577 Test RE 0.0487673191754997\n",
      "66 Train Loss 0.021537155 Test MSE 0.008983444060552062 Test RE 0.045303264113899504\n",
      "67 Train Loss 0.020464761 Test MSE 0.007467393313949042 Test RE 0.04130404389481189\n",
      "68 Train Loss 0.019289177 Test MSE 0.006277413176474125 Test RE 0.03787027140641406\n",
      "69 Train Loss 0.018545028 Test MSE 0.00580348588921569 Test RE 0.03641267012214919\n",
      "70 Train Loss 0.01787492 Test MSE 0.0056280644128408755 Test RE 0.035858126080932404\n",
      "71 Train Loss 0.01743396 Test MSE 0.005863609185850092 Test RE 0.03660079919755906\n",
      "72 Train Loss 0.017040346 Test MSE 0.005847568587459345 Test RE 0.03655070199873694\n",
      "73 Train Loss 0.01655977 Test MSE 0.005790126576864171 Test RE 0.036370735971701006\n",
      "74 Train Loss 0.016162256 Test MSE 0.006065961046722891 Test RE 0.0372269853895846\n",
      "75 Train Loss 0.015568974 Test MSE 0.005734134744998973 Test RE 0.03619445214416396\n",
      "76 Train Loss 0.014813429 Test MSE 0.005509115213198783 Test RE 0.03547717152891978\n",
      "77 Train Loss 0.013906253 Test MSE 0.0050312044114194775 Test RE 0.0339034615124988\n",
      "78 Train Loss 0.013423514 Test MSE 0.004289009254770152 Test RE 0.031303042579023894\n",
      "79 Train Loss 0.012956395 Test MSE 0.004105318787505042 Test RE 0.030625381234903944\n",
      "80 Train Loss 0.012674286 Test MSE 0.004018506264630674 Test RE 0.030299843484248298\n",
      "81 Train Loss 0.0121519985 Test MSE 0.003793166939967633 Test RE 0.02943805000281238\n",
      "82 Train Loss 0.011737782 Test MSE 0.003801407111449795 Test RE 0.029470007861018426\n",
      "83 Train Loss 0.011522273 Test MSE 0.0036586951446283076 Test RE 0.02891153646628039\n",
      "84 Train Loss 0.011157224 Test MSE 0.003360239011335636 Test RE 0.027707232246407008\n",
      "85 Train Loss 0.010741955 Test MSE 0.0031598714022753127 Test RE 0.02686845934991169\n",
      "86 Train Loss 0.010298493 Test MSE 0.0034026968946973186 Test RE 0.027881728419170016\n",
      "87 Train Loss 0.010117936 Test MSE 0.00356573517588756 Test RE 0.028541881779408602\n",
      "88 Train Loss 0.009862953 Test MSE 0.0034833267075120374 Test RE 0.02821013503986851\n",
      "89 Train Loss 0.009375156 Test MSE 0.0032475468819673226 Test RE 0.02723866227012405\n",
      "90 Train Loss 0.008874489 Test MSE 0.0030983410409615043 Test RE 0.02660557627571511\n",
      "91 Train Loss 0.008549505 Test MSE 0.0030042126810493016 Test RE 0.02619831729956391\n",
      "92 Train Loss 0.008372588 Test MSE 0.0028781786970855767 Test RE 0.025642888117185406\n",
      "93 Train Loss 0.008182479 Test MSE 0.002822339146722492 Test RE 0.02539292091493103\n",
      "94 Train Loss 0.007990695 Test MSE 0.002728249315746297 Test RE 0.024966064475582733\n",
      "95 Train Loss 0.0077582737 Test MSE 0.0024483205517721826 Test RE 0.023650601981368233\n",
      "96 Train Loss 0.007484019 Test MSE 0.0022936297587041335 Test RE 0.02289126102833782\n",
      "97 Train Loss 0.0071933847 Test MSE 0.002364050775244756 Test RE 0.023240018013214646\n",
      "98 Train Loss 0.0068742097 Test MSE 0.002089698387058757 Test RE 0.021849920645114092\n",
      "99 Train Loss 0.006553668 Test MSE 0.0018445293169548438 Test RE 0.02052819863760571\n",
      "Training time: 122.26\n",
      "5\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.138084 Test MSE 5.539049932707685 Test RE 1.124930522022352\n",
      "1 Train Loss 59.589943 Test MSE 5.946337524118632 Test RE 1.165555179697124\n",
      "2 Train Loss 44.320652 Test MSE 8.277496863199046 Test RE 1.3751737467496776\n",
      "3 Train Loss 37.91386 Test MSE 8.332369564794726 Test RE 1.379724328571984\n",
      "4 Train Loss 34.436615 Test MSE 8.424798026323396 Test RE 1.387355656774417\n",
      "5 Train Loss 31.159895 Test MSE 8.9564130691193 Test RE 1.4304580226244747\n",
      "6 Train Loss 28.184517 Test MSE 9.077569699362128 Test RE 1.440100683055352\n",
      "7 Train Loss 25.97578 Test MSE 9.05850351872386 Test RE 1.4385875218594013\n",
      "8 Train Loss 24.332634 Test MSE 8.851226795090803 Test RE 1.4220333924339144\n",
      "9 Train Loss 22.615376 Test MSE 8.647343499422275 Test RE 1.4055600853451597\n",
      "10 Train Loss 20.943214 Test MSE 8.614628503570332 Test RE 1.4028987786713474\n",
      "11 Train Loss 18.988503 Test MSE 8.405274093680703 Test RE 1.3857471701727602\n",
      "12 Train Loss 16.90902 Test MSE 8.46207815347343 Test RE 1.390421825520089\n",
      "13 Train Loss 15.279181 Test MSE 7.853899158113758 Test RE 1.3395246830886174\n",
      "14 Train Loss 14.179169 Test MSE 7.730930736739797 Test RE 1.328996849615136\n",
      "15 Train Loss 13.140884 Test MSE 7.920592233402194 Test RE 1.3452000911639344\n",
      "16 Train Loss 12.390648 Test MSE 7.79408345840101 Test RE 1.3344139892414468\n",
      "17 Train Loss 11.295235 Test MSE 7.719720396294722 Test RE 1.3280329351456581\n",
      "18 Train Loss 9.794365 Test MSE 7.331903817473697 Test RE 1.294244833001699\n",
      "19 Train Loss 8.689639 Test MSE 7.030352696128261 Test RE 1.2673501390744712\n",
      "20 Train Loss 6.780102 Test MSE 6.440836075465379 Test RE 1.2130513440292372\n",
      "21 Train Loss 5.257682 Test MSE 6.425421105125699 Test RE 1.2115988655052938\n",
      "22 Train Loss 4.6596313 Test MSE 6.388307739908253 Test RE 1.2080946880720855\n",
      "23 Train Loss 4.329354 Test MSE 6.4041390531237745 Test RE 1.2095906938719272\n",
      "24 Train Loss 3.9734385 Test MSE 6.411035843380766 Test RE 1.2102418390486334\n",
      "25 Train Loss 3.6690814 Test MSE 6.278366960427768 Test RE 1.1976541073540026\n",
      "26 Train Loss 3.390156 Test MSE 6.296190966152345 Test RE 1.1993529459593073\n",
      "27 Train Loss 3.2015333 Test MSE 6.220453412039934 Test RE 1.1921175488956899\n",
      "28 Train Loss 3.0706942 Test MSE 6.131000583075802 Test RE 1.1835149247816814\n",
      "29 Train Loss 2.9791584 Test MSE 6.153396276068333 Test RE 1.18567456212843\n",
      "30 Train Loss 2.8755238 Test MSE 6.214363263117918 Test RE 1.1915338333031915\n",
      "31 Train Loss 2.775436 Test MSE 6.3121835776558175 Test RE 1.2008751854570137\n",
      "32 Train Loss 2.6997325 Test MSE 6.310648515123802 Test RE 1.2007291559119921\n",
      "33 Train Loss 2.6084578 Test MSE 6.2326229913602935 Test RE 1.193283097406207\n",
      "34 Train Loss 2.5427184 Test MSE 6.246993500494997 Test RE 1.1946579770117278\n",
      "35 Train Loss 2.479987 Test MSE 6.218677699511431 Test RE 1.1919473837148102\n",
      "36 Train Loss 2.426697 Test MSE 6.104589397324741 Test RE 1.1809629947815454\n",
      "37 Train Loss 2.3829253 Test MSE 6.093505951961729 Test RE 1.1798904340808662\n",
      "38 Train Loss 2.3487637 Test MSE 6.097226726341513 Test RE 1.180250607368065\n",
      "39 Train Loss 2.316519 Test MSE 6.065030891567343 Test RE 1.177130381495203\n",
      "40 Train Loss 2.289793 Test MSE 6.0958680065348965 Test RE 1.1801190951824383\n",
      "41 Train Loss 2.255941 Test MSE 6.119214353587769 Test RE 1.182376783564742\n",
      "42 Train Loss 2.2173042 Test MSE 6.116229170618709 Test RE 1.1820883444443233\n",
      "43 Train Loss 2.179391 Test MSE 6.144517998495048 Test RE 1.1848188925754937\n",
      "44 Train Loss 2.1378913 Test MSE 6.085250124225752 Test RE 1.1790908719002082\n",
      "45 Train Loss 2.1101303 Test MSE 6.014768753288391 Test RE 1.1722426752413606\n",
      "46 Train Loss 2.074641 Test MSE 6.020099992279079 Test RE 1.1727620735675002\n",
      "47 Train Loss 2.049458 Test MSE 5.998766204577071 Test RE 1.170682235837836\n",
      "48 Train Loss 2.0251532 Test MSE 6.019312065320765 Test RE 1.1726853239211334\n",
      "49 Train Loss 1.9968868 Test MSE 6.061637513592239 Test RE 1.1768010338578607\n",
      "50 Train Loss 1.9598126 Test MSE 5.991993143848337 Test RE 1.1700211547913153\n",
      "51 Train Loss 1.9361501 Test MSE 5.9789416266385516 Test RE 1.168746213768886\n",
      "52 Train Loss 1.9135866 Test MSE 6.002263845756139 Test RE 1.1710234751507773\n",
      "53 Train Loss 1.888008 Test MSE 5.91265507283087 Test RE 1.1622494046910987\n",
      "54 Train Loss 1.8654987 Test MSE 5.849221286909428 Test RE 1.15599800929247\n",
      "55 Train Loss 1.8431643 Test MSE 5.839745666118734 Test RE 1.1550612830118518\n",
      "56 Train Loss 1.8226796 Test MSE 5.800915561476 Test RE 1.1512147151189744\n",
      "57 Train Loss 1.797097 Test MSE 5.797497675432984 Test RE 1.1508755186233084\n",
      "58 Train Loss 1.7786758 Test MSE 5.785668086260741 Test RE 1.1497007586364623\n",
      "59 Train Loss 1.7574954 Test MSE 5.745026476626502 Test RE 1.1456555874712757\n",
      "60 Train Loss 1.7373704 Test MSE 5.7351262743990015 Test RE 1.144668027825278\n",
      "61 Train Loss 1.7189987 Test MSE 5.669552923415634 Test RE 1.1381053558348548\n",
      "62 Train Loss 1.6878746 Test MSE 5.631958375564192 Test RE 1.1343257173070123\n",
      "63 Train Loss 1.6619136 Test MSE 5.6399012709503555 Test RE 1.1351253198116062\n",
      "64 Train Loss 1.6388837 Test MSE 5.56928333446093 Test RE 1.1279964082135592\n",
      "65 Train Loss 1.620127 Test MSE 5.546466153210458 Test RE 1.1256833534875534\n",
      "66 Train Loss 1.6005393 Test MSE 5.520827340547556 Test RE 1.1230785764824636\n",
      "67 Train Loss 1.5819299 Test MSE 5.463843390349504 Test RE 1.117267540649147\n",
      "68 Train Loss 1.5595022 Test MSE 5.444882114742746 Test RE 1.1153272188165333\n",
      "69 Train Loss 1.5445744 Test MSE 5.4501907249060375 Test RE 1.1158707930229337\n",
      "70 Train Loss 1.5268335 Test MSE 5.399509556720923 Test RE 1.1106704499787956\n",
      "71 Train Loss 1.5118229 Test MSE 5.38068723085896 Test RE 1.1087328988509368\n",
      "72 Train Loss 1.4968119 Test MSE 5.365934040031775 Test RE 1.1072118500337318\n",
      "73 Train Loss 1.4831842 Test MSE 5.335356999901851 Test RE 1.1040526955680718\n",
      "74 Train Loss 1.4645141 Test MSE 5.317775832806898 Test RE 1.1022321471200787\n",
      "75 Train Loss 1.4457864 Test MSE 5.298225243602424 Test RE 1.1002041253155095\n",
      "76 Train Loss 1.4225751 Test MSE 5.267404998880349 Test RE 1.096999465731483\n",
      "77 Train Loss 1.4026084 Test MSE 5.223920108459063 Test RE 1.0924619598342036\n",
      "78 Train Loss 1.3842138 Test MSE 5.204958453039789 Test RE 1.0904774617370425\n",
      "79 Train Loss 1.3724263 Test MSE 5.215525648721691 Test RE 1.0915838534656086\n",
      "80 Train Loss 1.3592635 Test MSE 5.2045286599204985 Test RE 1.0904324383819488\n",
      "81 Train Loss 1.3467356 Test MSE 5.1804300666812075 Test RE 1.0879049878823872\n",
      "82 Train Loss 1.328711 Test MSE 5.1374104765236 Test RE 1.083378453027001\n",
      "83 Train Loss 1.3197324 Test MSE 5.132315893734357 Test RE 1.082841146317473\n",
      "84 Train Loss 1.3053133 Test MSE 5.120138941197905 Test RE 1.0815558069188276\n",
      "85 Train Loss 1.2975677 Test MSE 5.125268976182294 Test RE 1.0820974943711443\n",
      "86 Train Loss 1.2850957 Test MSE 5.137358353711345 Test RE 1.083372957176981\n",
      "87 Train Loss 1.2738733 Test MSE 5.099293846450871 Test RE 1.0793519481195126\n",
      "88 Train Loss 1.2638122 Test MSE 5.082596274615125 Test RE 1.077583337102471\n",
      "89 Train Loss 1.255209 Test MSE 5.081095310392186 Test RE 1.0774242123778315\n",
      "90 Train Loss 1.2492315 Test MSE 5.0588620714756845 Test RE 1.0750643971814273\n",
      "91 Train Loss 1.2427413 Test MSE 5.043544138171661 Test RE 1.0734355477225628\n",
      "92 Train Loss 1.2300851 Test MSE 5.017018611772678 Test RE 1.0706090651375268\n",
      "93 Train Loss 1.2228703 Test MSE 5.002328849251842 Test RE 1.0690405517307107\n",
      "94 Train Loss 1.2155408 Test MSE 4.9959903850087235 Test RE 1.0683630449760944\n",
      "95 Train Loss 1.207641 Test MSE 4.964968580798593 Test RE 1.0650409651338126\n",
      "96 Train Loss 1.2002096 Test MSE 4.946228345574251 Test RE 1.0630290704564\n",
      "97 Train Loss 1.1929992 Test MSE 4.917012857673555 Test RE 1.0598849668025332\n",
      "98 Train Loss 1.1828924 Test MSE 4.897790660467046 Test RE 1.0578112211229989\n",
      "99 Train Loss 1.1733797 Test MSE 4.895390103261825 Test RE 1.0575519565124234\n",
      "Training time: 122.57\n",
      "6\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.59988 Test MSE 8.734952607245553 Test RE 1.4126622400342939\n",
      "1 Train Loss 41.844437 Test MSE 9.580443528054984 Test RE 1.479451961280821\n",
      "2 Train Loss 35.79641 Test MSE 8.840495744468233 Test RE 1.4211711085560017\n",
      "3 Train Loss 31.194714 Test MSE 9.016828873494148 Test RE 1.43527451666918\n",
      "4 Train Loss 27.902798 Test MSE 8.84125689104521 Test RE 1.421232287039282\n",
      "5 Train Loss 25.112959 Test MSE 8.809677717996715 Test RE 1.4186918400542985\n",
      "6 Train Loss 23.308683 Test MSE 8.832172976172163 Test RE 1.4205019796210547\n",
      "7 Train Loss 21.18317 Test MSE 8.74321324982822 Test RE 1.4133300593530123\n",
      "8 Train Loss 18.601393 Test MSE 8.427261148965762 Test RE 1.3875584496121192\n",
      "9 Train Loss 16.340416 Test MSE 8.036859237398227 Test RE 1.3550372721077402\n",
      "10 Train Loss 13.526439 Test MSE 7.156634180986781 Test RE 1.2786817579754082\n",
      "11 Train Loss 11.443382 Test MSE 6.678885532665937 Test RE 1.2352647842072866\n",
      "12 Train Loss 7.9816513 Test MSE 6.098873159088812 Test RE 1.1804099480137575\n",
      "13 Train Loss 5.4389973 Test MSE 5.509134871577737 Test RE 1.1218886713516463\n",
      "14 Train Loss 4.390434 Test MSE 5.245562277101524 Test RE 1.0947226001373316\n",
      "15 Train Loss 3.5088024 Test MSE 5.302355664329181 Test RE 1.1006328934774912\n",
      "16 Train Loss 2.9731011 Test MSE 5.408848732174147 Test RE 1.1116305616986843\n",
      "17 Train Loss 2.6094294 Test MSE 5.2953689496641125 Test RE 1.0999075231630804\n",
      "18 Train Loss 2.361536 Test MSE 5.239477947090542 Test RE 1.0940875313151106\n",
      "19 Train Loss 2.2092857 Test MSE 5.230864317275076 Test RE 1.0931878289477088\n",
      "20 Train Loss 2.0877516 Test MSE 5.232943948856125 Test RE 1.0934051163670317\n",
      "21 Train Loss 1.9940058 Test MSE 5.2606963395661595 Test RE 1.0963006642872963\n",
      "22 Train Loss 1.9105554 Test MSE 5.315188097856434 Test RE 1.1019639304991349\n",
      "23 Train Loss 1.8286214 Test MSE 5.343117685788372 Test RE 1.1048553684406102\n",
      "24 Train Loss 1.741344 Test MSE 5.31854878602573 Test RE 1.1023122504335567\n",
      "25 Train Loss 1.6726395 Test MSE 5.389612822965553 Test RE 1.1096521120132\n",
      "26 Train Loss 1.5963414 Test MSE 5.414342015411776 Test RE 1.1121949102470967\n",
      "27 Train Loss 1.5279453 Test MSE 5.419686077051727 Test RE 1.112743653957838\n",
      "28 Train Loss 1.4732215 Test MSE 5.46970235992782 Test RE 1.1178664123726225\n",
      "29 Train Loss 1.4207814 Test MSE 5.481162555337693 Test RE 1.1190368841165432\n",
      "30 Train Loss 1.3597324 Test MSE 5.508155732216099 Test RE 1.1217889702011088\n",
      "31 Train Loss 1.3182343 Test MSE 5.542522177803469 Test RE 1.1252830574378871\n",
      "32 Train Loss 1.2727726 Test MSE 5.5811529862192994 Test RE 1.1291978014164235\n",
      "33 Train Loss 1.2337227 Test MSE 5.663597286029453 Test RE 1.1375074318119756\n",
      "34 Train Loss 1.2006266 Test MSE 5.699051959251566 Test RE 1.1410623309047938\n",
      "35 Train Loss 1.160907 Test MSE 5.676650827314091 Test RE 1.1388175491772359\n",
      "36 Train Loss 1.1231027 Test MSE 5.692367885020312 Test RE 1.1403929930056849\n",
      "37 Train Loss 1.0973576 Test MSE 5.7130497369271245 Test RE 1.1424627867448671\n",
      "38 Train Loss 1.0732797 Test MSE 5.7233820574384255 Test RE 1.1434954190423365\n",
      "39 Train Loss 1.0518076 Test MSE 5.764686757315655 Test RE 1.1476142097184243\n",
      "40 Train Loss 1.0335528 Test MSE 5.8036252468319525 Test RE 1.1514835576340288\n",
      "41 Train Loss 1.0158718 Test MSE 5.8155833600432265 Test RE 1.152669237666574\n",
      "42 Train Loss 1.0009797 Test MSE 5.812474147219556 Test RE 1.1523610679697494\n",
      "43 Train Loss 0.98717463 Test MSE 5.822113677169554 Test RE 1.1533162220947728\n",
      "44 Train Loss 0.96332073 Test MSE 5.824330889992109 Test RE 1.153535807647983\n",
      "45 Train Loss 0.9507435 Test MSE 5.820906440612652 Test RE 1.1531966437280816\n",
      "46 Train Loss 0.9402534 Test MSE 5.8238611641874805 Test RE 1.1534892910205026\n",
      "47 Train Loss 0.9239858 Test MSE 5.816084522385849 Test RE 1.1527189026730582\n",
      "48 Train Loss 0.9140289 Test MSE 5.860100675071164 Test RE 1.157072571859395\n",
      "49 Train Loss 0.90050375 Test MSE 5.901997744892372 Test RE 1.1612014778741382\n",
      "50 Train Loss 0.8890067 Test MSE 5.906678727355226 Test RE 1.1616618716809957\n",
      "51 Train Loss 0.87926555 Test MSE 5.93161738465781 Test RE 1.1641116217090561\n",
      "52 Train Loss 0.87084234 Test MSE 5.94928961679485 Test RE 1.1658444670060988\n",
      "53 Train Loss 0.8634484 Test MSE 5.940385445811944 Test RE 1.1649716934263796\n",
      "54 Train Loss 0.8558452 Test MSE 5.943084019382932 Test RE 1.1652362726274113\n",
      "55 Train Loss 0.8451109 Test MSE 5.975038697735215 Test RE 1.1683646848692157\n",
      "56 Train Loss 0.8403515 Test MSE 5.9868683172466035 Test RE 1.1695207004316466\n",
      "57 Train Loss 0.83413327 Test MSE 6.011324275528292 Test RE 1.171906973052955\n",
      "58 Train Loss 0.82846045 Test MSE 6.0146208499140785 Test RE 1.172228262408536\n",
      "59 Train Loss 0.8211464 Test MSE 6.020119256775031 Test RE 1.1727639500024574\n",
      "60 Train Loss 0.8153576 Test MSE 6.0241481203849565 Test RE 1.1731563106474994\n",
      "61 Train Loss 0.8096289 Test MSE 6.0462723135074725 Test RE 1.1753085941997006\n",
      "62 Train Loss 0.80313015 Test MSE 6.055113197505214 Test RE 1.1761675508281244\n",
      "63 Train Loss 0.79513836 Test MSE 6.059805353976788 Test RE 1.1766231734800805\n",
      "64 Train Loss 0.789145 Test MSE 6.082131511262072 Test RE 1.1787886986744212\n",
      "65 Train Loss 0.7833172 Test MSE 6.120307308264182 Test RE 1.1824823711828207\n",
      "66 Train Loss 0.77782005 Test MSE 6.148351127244762 Test RE 1.1851883971723154\n",
      "67 Train Loss 0.77189106 Test MSE 6.154336978943258 Test RE 1.1857651888973295\n",
      "68 Train Loss 0.7661577 Test MSE 6.169973582699084 Test RE 1.1872705970510216\n",
      "69 Train Loss 0.7613303 Test MSE 6.1878640200741 Test RE 1.1889906542626691\n",
      "70 Train Loss 0.75656164 Test MSE 6.190144062790506 Test RE 1.1892096878251706\n",
      "71 Train Loss 0.7513906 Test MSE 6.197292285392595 Test RE 1.1898961244242225\n",
      "72 Train Loss 0.7446679 Test MSE 6.203212907789971 Test RE 1.1904643761315934\n",
      "73 Train Loss 0.7395956 Test MSE 6.234092697342826 Test RE 1.1934237823098914\n",
      "74 Train Loss 0.73452806 Test MSE 6.267772425460134 Test RE 1.1966431800051278\n",
      "75 Train Loss 0.7312033 Test MSE 6.276976405214281 Test RE 1.197521469647528\n",
      "76 Train Loss 0.7284832 Test MSE 6.269275557330931 Test RE 1.196786660379912\n",
      "77 Train Loss 0.7231347 Test MSE 6.283850278189425 Test RE 1.1981769889273897\n",
      "78 Train Loss 0.71925527 Test MSE 6.305573096453836 Test RE 1.2002462080034833\n",
      "79 Train Loss 0.71433115 Test MSE 6.318381996158598 Test RE 1.2014646566306002\n",
      "80 Train Loss 0.7114718 Test MSE 6.337880196698432 Test RE 1.2033170575695797\n",
      "81 Train Loss 0.70685446 Test MSE 6.347007741437803 Test RE 1.2041832287776058\n",
      "82 Train Loss 0.7024019 Test MSE 6.345148183760165 Test RE 1.2040068139772506\n",
      "83 Train Loss 0.6988308 Test MSE 6.3677122302264975 Test RE 1.2061457046155368\n",
      "84 Train Loss 0.6955268 Test MSE 6.379985583080636 Test RE 1.2073075289084498\n",
      "85 Train Loss 0.692141 Test MSE 6.385194395374074 Test RE 1.2078002694626377\n",
      "86 Train Loss 0.6881092 Test MSE 6.402719696377389 Test RE 1.2094566449518176\n",
      "87 Train Loss 0.68441963 Test MSE 6.408616434987759 Test RE 1.210013455864023\n",
      "88 Train Loss 0.6810154 Test MSE 6.423974164933406 Test RE 1.2114624378864955\n",
      "89 Train Loss 0.67811286 Test MSE 6.456967413636152 Test RE 1.2145694625029793\n",
      "90 Train Loss 0.6757725 Test MSE 6.470821495865123 Test RE 1.2158717556635608\n",
      "91 Train Loss 0.672541 Test MSE 6.486287774696478 Test RE 1.2173239505884894\n",
      "92 Train Loss 0.66964865 Test MSE 6.508328274478882 Test RE 1.2193904387937573\n",
      "93 Train Loss 0.66580105 Test MSE 6.518954637165937 Test RE 1.2203855023274932\n",
      "94 Train Loss 0.66289574 Test MSE 6.525946476577873 Test RE 1.2210397830540682\n",
      "95 Train Loss 0.6602651 Test MSE 6.539716502835194 Test RE 1.2223273273088693\n",
      "96 Train Loss 0.65836036 Test MSE 6.546873887823243 Test RE 1.2229960317417032\n",
      "97 Train Loss 0.65584403 Test MSE 6.572111051555043 Test RE 1.2253509925933452\n",
      "98 Train Loss 0.6531984 Test MSE 6.584450625747491 Test RE 1.2265007920014452\n",
      "99 Train Loss 0.65101045 Test MSE 6.579179363450376 Test RE 1.22600974861619\n",
      "Training time: 122.54\n",
      "7\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.669525 Test MSE 5.622030817265266 Test RE 1.13332552777728\n",
      "1 Train Loss 44.29353 Test MSE 7.1624568545456855 Test RE 1.2792018231692608\n",
      "2 Train Loss 31.645878 Test MSE 7.3647526081381605 Test RE 1.2971408656160057\n",
      "3 Train Loss 24.597012 Test MSE 6.193153183770736 Test RE 1.189498698953453\n",
      "4 Train Loss 21.497734 Test MSE 5.95095142393215 Test RE 1.1660072825274876\n",
      "5 Train Loss 17.713776 Test MSE 5.882792292059313 Test RE 1.1593106289380593\n",
      "6 Train Loss 14.807571 Test MSE 6.064534250610437 Test RE 1.1770821852751114\n",
      "7 Train Loss 13.255941 Test MSE 6.097734114375201 Test RE 1.1802997143312737\n",
      "8 Train Loss 11.865619 Test MSE 5.923609925629871 Test RE 1.163325603024851\n",
      "9 Train Loss 10.715154 Test MSE 5.757988814512701 Test RE 1.1469473141242972\n",
      "10 Train Loss 9.297824 Test MSE 5.457753464510962 Test RE 1.116644721420234\n",
      "11 Train Loss 8.584299 Test MSE 5.469886292624587 Test RE 1.1178852077696837\n",
      "12 Train Loss 7.752498 Test MSE 5.337179643555526 Test RE 1.1042412605329133\n",
      "13 Train Loss 6.9564037 Test MSE 5.0837551009616355 Test RE 1.077706174007555\n",
      "14 Train Loss 5.9678116 Test MSE 4.733326316647352 Test RE 1.039899293650042\n",
      "15 Train Loss 4.8211584 Test MSE 4.581624466347353 Test RE 1.023099340991617\n",
      "16 Train Loss 4.3708844 Test MSE 4.479796240274938 Test RE 1.0116660844306695\n",
      "17 Train Loss 3.7981477 Test MSE 4.0412896270916825 Test RE 0.960877553826287\n",
      "18 Train Loss 3.4065437 Test MSE 3.8501416276287435 Test RE 0.937878138878177\n",
      "19 Train Loss 3.1313257 Test MSE 3.6153066857726404 Test RE 0.9088257686531054\n",
      "20 Train Loss 2.9246037 Test MSE 3.4111674515875765 Test RE 0.8827944208998899\n",
      "21 Train Loss 2.6631584 Test MSE 3.241287737482777 Test RE 0.8605316603890909\n",
      "22 Train Loss 2.4299555 Test MSE 2.988307627163515 Test RE 0.8262675783006291\n",
      "23 Train Loss 2.2094867 Test MSE 2.719376436804188 Test RE 0.7882114245001146\n",
      "24 Train Loss 1.9783348 Test MSE 2.6384241070885426 Test RE 0.7763907696288579\n",
      "25 Train Loss 1.8504808 Test MSE 2.5992630735057647 Test RE 0.770607406464046\n",
      "26 Train Loss 1.7207866 Test MSE 2.4155905569283838 Test RE 0.7428818055697378\n",
      "27 Train Loss 1.6037991 Test MSE 2.184719640364289 Test RE 0.7064898336498278\n",
      "28 Train Loss 1.4985776 Test MSE 2.0524823798282585 Test RE 0.6847748146190745\n",
      "29 Train Loss 1.3807178 Test MSE 1.9327720611571055 Test RE 0.664505193928542\n",
      "30 Train Loss 1.2913512 Test MSE 1.8237340881974256 Test RE 0.6454889590648057\n",
      "31 Train Loss 1.168022 Test MSE 1.5690341404660704 Test RE 0.5987206771582128\n",
      "32 Train Loss 1.0363054 Test MSE 1.253867704838421 Test RE 0.5352219532249088\n",
      "33 Train Loss 0.9237255 Test MSE 1.0195957192304055 Test RE 0.48263861049664886\n",
      "34 Train Loss 0.7982829 Test MSE 0.8365642345992187 Test RE 0.43717740410006317\n",
      "35 Train Loss 0.5919151 Test MSE 0.43694904596626954 Test RE 0.31595370904620684\n",
      "36 Train Loss 0.43739554 Test MSE 0.3004930550924148 Test RE 0.26201447214351725\n",
      "37 Train Loss 0.33599606 Test MSE 0.2357856146717374 Test RE 0.2320954960868718\n",
      "38 Train Loss 0.26225466 Test MSE 0.1780749301212085 Test RE 0.20170165030063625\n",
      "39 Train Loss 0.20947953 Test MSE 0.15345429442205563 Test RE 0.18723954780953406\n",
      "40 Train Loss 0.1898897 Test MSE 0.1707789020349675 Test RE 0.19752640919143336\n",
      "41 Train Loss 0.17079487 Test MSE 0.16236778164766447 Test RE 0.19260075660777057\n",
      "42 Train Loss 0.13834849 Test MSE 0.13145014197417443 Test RE 0.17329602056720533\n",
      "43 Train Loss 0.12293031 Test MSE 0.12695633788886546 Test RE 0.17030808026025882\n",
      "44 Train Loss 0.10522403 Test MSE 0.12965677301415807 Test RE 0.17210982557759957\n",
      "45 Train Loss 0.09159374 Test MSE 0.12216961024875689 Test RE 0.1670666077573541\n",
      "46 Train Loss 0.07964232 Test MSE 0.11936676256752421 Test RE 0.16513904467494206\n",
      "47 Train Loss 0.07409112 Test MSE 0.11287329218790564 Test RE 0.16058451206477287\n",
      "48 Train Loss 0.06511614 Test MSE 0.09323985478957333 Test RE 0.14595159805156724\n",
      "49 Train Loss 0.059483737 Test MSE 0.08572406648332007 Test RE 0.13994566252789475\n",
      "50 Train Loss 0.054657012 Test MSE 0.08053758356876548 Test RE 0.1356461143754123\n",
      "51 Train Loss 0.04893708 Test MSE 0.067338565371038 Test RE 0.12403378309079569\n",
      "52 Train Loss 0.046028875 Test MSE 0.0631474797916911 Test RE 0.12011190957770118\n",
      "53 Train Loss 0.042957384 Test MSE 0.052935557874240896 Test RE 0.1099719199974239\n",
      "54 Train Loss 0.040118262 Test MSE 0.04666373830225032 Test RE 0.10325184581355969\n",
      "55 Train Loss 0.036125094 Test MSE 0.0432853692060754 Test RE 0.09944400881520792\n",
      "56 Train Loss 0.03292261 Test MSE 0.03483249493959143 Test RE 0.08920729109875052\n",
      "57 Train Loss 0.030924704 Test MSE 0.027608147481758917 Test RE 0.07941941676878726\n",
      "58 Train Loss 0.02966451 Test MSE 0.022454779195915063 Test RE 0.0716246404274512\n",
      "59 Train Loss 0.027755568 Test MSE 0.018278642299623133 Test RE 0.06462194529611702\n",
      "60 Train Loss 0.026393032 Test MSE 0.016589095035668563 Test RE 0.06156294794207321\n",
      "61 Train Loss 0.025287334 Test MSE 0.014113284344154263 Test RE 0.05678349321673394\n",
      "62 Train Loss 0.02385149 Test MSE 0.011606175528488938 Test RE 0.05149352558424782\n",
      "63 Train Loss 0.022933595 Test MSE 0.011125408769345828 Test RE 0.05041572868636355\n",
      "64 Train Loss 0.021637917 Test MSE 0.009770797182289096 Test RE 0.04724687182452157\n",
      "65 Train Loss 0.020313315 Test MSE 0.008001351980857392 Test RE 0.04275527932161423\n",
      "66 Train Loss 0.0192154 Test MSE 0.008043508288208193 Test RE 0.0428677626166119\n",
      "67 Train Loss 0.01844885 Test MSE 0.007688242605524818 Test RE 0.041910380125428706\n",
      "68 Train Loss 0.017638326 Test MSE 0.006882509401088888 Test RE 0.03965349459031337\n",
      "69 Train Loss 0.01669155 Test MSE 0.006431492005511651 Test RE 0.038332216056364485\n",
      "70 Train Loss 0.015560083 Test MSE 0.006619620351623691 Test RE 0.03888880530950171\n",
      "71 Train Loss 0.0146879135 Test MSE 0.006307582694812429 Test RE 0.037961165405659\n",
      "72 Train Loss 0.01417872 Test MSE 0.00611047444664035 Test RE 0.03736332575968617\n",
      "73 Train Loss 0.013217621 Test MSE 0.005584088147738046 Test RE 0.035717758201046314\n",
      "74 Train Loss 0.012556321 Test MSE 0.004695334829717094 Test RE 0.032752265371329185\n",
      "75 Train Loss 0.0116309505 Test MSE 0.00405101309465865 Test RE 0.030422148630108\n",
      "76 Train Loss 0.010603806 Test MSE 0.0038101909647015085 Test RE 0.029504036163331148\n",
      "77 Train Loss 0.010241854 Test MSE 0.0037223883266358448 Test RE 0.029162106996909614\n",
      "78 Train Loss 0.009556266 Test MSE 0.0036701377463760642 Test RE 0.02895671171663638\n",
      "79 Train Loss 0.008935148 Test MSE 0.003400551593642415 Test RE 0.02787293772548344\n",
      "80 Train Loss 0.008399194 Test MSE 0.0033381037683845338 Test RE 0.027615822129538305\n",
      "81 Train Loss 0.008109988 Test MSE 0.0033902182905336457 Test RE 0.027830556564456703\n",
      "82 Train Loss 0.0078082196 Test MSE 0.0032507948126516985 Test RE 0.027252279806886704\n",
      "83 Train Loss 0.0074649123 Test MSE 0.003169933877358776 Test RE 0.026911206074440915\n",
      "84 Train Loss 0.0070869257 Test MSE 0.0033084304086923462 Test RE 0.02749280566415032\n",
      "85 Train Loss 0.0067933113 Test MSE 0.0029511316556563275 Test RE 0.0259658385610057\n",
      "86 Train Loss 0.006597572 Test MSE 0.0026805601363868014 Test RE 0.024746901952820102\n",
      "87 Train Loss 0.006401033 Test MSE 0.002810251207427783 Test RE 0.02533848425137879\n",
      "88 Train Loss 0.0061913747 Test MSE 0.002819192945948546 Test RE 0.025378763597122444\n",
      "89 Train Loss 0.0060088756 Test MSE 0.0026432365093936425 Test RE 0.024574012363746713\n",
      "90 Train Loss 0.0054205 Test MSE 0.0022168810622260776 Test RE 0.022505012422181992\n",
      "91 Train Loss 0.0051385015 Test MSE 0.002035175185655254 Test RE 0.021562988916228966\n",
      "92 Train Loss 0.004841762 Test MSE 0.0020294162295535693 Test RE 0.021532458797605587\n",
      "93 Train Loss 0.0047298954 Test MSE 0.001960787852619811 Test RE 0.021165248123688824\n",
      "94 Train Loss 0.0045863297 Test MSE 0.0018654583984447648 Test RE 0.02064433246073899\n",
      "95 Train Loss 0.0044266004 Test MSE 0.0018765609684694548 Test RE 0.020705675324350845\n",
      "96 Train Loss 0.0042104013 Test MSE 0.0018096158939198796 Test RE 0.020332990666252854\n",
      "97 Train Loss 0.004038004 Test MSE 0.0017998983238900965 Test RE 0.020278323475537444\n",
      "98 Train Loss 0.003932355 Test MSE 0.0018335014685559924 Test RE 0.020466740887438103\n",
      "99 Train Loss 0.00376407 Test MSE 0.0018320254184799264 Test RE 0.020458500911224524\n",
      "Training time: 123.10\n",
      "8\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.512074 Test MSE 8.1678542950406 Test RE 1.3660357058127026\n",
      "1 Train Loss 56.939743 Test MSE 8.767852029290369 Test RE 1.4153200731006885\n",
      "2 Train Loss 56.442734 Test MSE 8.72758518654055 Test RE 1.4120663654487697\n",
      "3 Train Loss 54.475235 Test MSE 8.279249030122658 Test RE 1.375319286306807\n",
      "4 Train Loss 48.87532 Test MSE 7.356619692478514 Test RE 1.2964244497430046\n",
      "5 Train Loss 41.19557 Test MSE 5.886256053687494 Test RE 1.1596518771547273\n",
      "6 Train Loss 34.184982 Test MSE 5.574897064887949 Test RE 1.128564764362894\n",
      "7 Train Loss 26.346733 Test MSE 5.606557514925792 Test RE 1.1317648487398049\n",
      "8 Train Loss 22.020979 Test MSE 4.90006212945278 Test RE 1.058056485470253\n",
      "9 Train Loss 18.51462 Test MSE 4.804829939723325 Test RE 1.0477244305624709\n",
      "10 Train Loss 16.220156 Test MSE 4.593686431155981 Test RE 1.0244452038833927\n",
      "11 Train Loss 15.433409 Test MSE 4.20725882643736 Test RE 0.9804098714564438\n",
      "12 Train Loss 13.818296 Test MSE 3.8022776189642804 Test RE 0.9320301723651843\n",
      "13 Train Loss 12.565993 Test MSE 3.8833949457951875 Test RE 0.9419196146720348\n",
      "14 Train Loss 11.27046 Test MSE 3.9996111528402145 Test RE 0.9559098696044896\n",
      "15 Train Loss 10.614268 Test MSE 4.120287455334442 Test RE 0.9702235641709829\n",
      "16 Train Loss 10.35312 Test MSE 4.068994440478216 Test RE 0.9641655468860922\n",
      "17 Train Loss 10.187784 Test MSE 4.149670618664077 Test RE 0.9736769145395151\n",
      "18 Train Loss 9.945252 Test MSE 4.1673983341363465 Test RE 0.9757545097278372\n",
      "19 Train Loss 9.647452 Test MSE 4.08256893770048 Test RE 0.9657724752302242\n",
      "20 Train Loss 9.318066 Test MSE 4.137090428063578 Test RE 0.9721998890141057\n",
      "21 Train Loss 9.047367 Test MSE 4.218082073107843 Test RE 0.9816701222150153\n",
      "22 Train Loss 8.729591 Test MSE 4.398757344399502 Test RE 1.0024738733074001\n",
      "23 Train Loss 8.453413 Test MSE 4.243192732751907 Test RE 0.9845877760380074\n",
      "24 Train Loss 8.179222 Test MSE 4.272858632005302 Test RE 0.988023609480988\n",
      "25 Train Loss 7.990076 Test MSE 4.356134493288713 Test RE 0.9976051908103619\n",
      "26 Train Loss 7.8816247 Test MSE 4.3073974410877724 Test RE 0.9920088191579517\n",
      "27 Train Loss 7.7663693 Test MSE 4.3135945334511625 Test RE 0.9927221687860442\n",
      "28 Train Loss 7.58074 Test MSE 4.233966091377303 Test RE 0.9835167214464431\n",
      "29 Train Loss 7.4717503 Test MSE 4.2597001218331965 Test RE 0.9865010990793633\n",
      "30 Train Loss 7.3839884 Test MSE 4.288143848308983 Test RE 0.9897892509197085\n",
      "31 Train Loss 7.322521 Test MSE 4.296670377319775 Test RE 0.9907728088384393\n",
      "32 Train Loss 7.2586584 Test MSE 4.284969248242086 Test RE 0.9894228025326456\n",
      "33 Train Loss 7.1842337 Test MSE 4.262628160541843 Test RE 0.9868400920970101\n",
      "34 Train Loss 7.1293054 Test MSE 4.247526096483321 Test RE 0.9850904032426125\n",
      "35 Train Loss 7.094853 Test MSE 4.257935364099764 Test RE 0.9862967283789721\n",
      "36 Train Loss 7.039504 Test MSE 4.291337682398107 Test RE 0.990157782661805\n",
      "37 Train Loss 7.009512 Test MSE 4.274914863854105 Test RE 0.9882613146602427\n",
      "38 Train Loss 6.976626 Test MSE 4.276592629239031 Test RE 0.9884552258871309\n",
      "39 Train Loss 6.9520116 Test MSE 4.276984352477495 Test RE 0.9885004946383914\n",
      "40 Train Loss 6.9348655 Test MSE 4.277168891469947 Test RE 0.9885218198178453\n",
      "41 Train Loss 6.903455 Test MSE 4.257488638622092 Test RE 0.9862449878760481\n",
      "42 Train Loss 6.8889756 Test MSE 4.230629864933537 Test RE 0.9831291556211348\n",
      "43 Train Loss 6.8704433 Test MSE 4.244570049343374 Test RE 0.9847475589112145\n",
      "44 Train Loss 6.829918 Test MSE 4.261331310917857 Test RE 0.9866899639943049\n",
      "45 Train Loss 6.811384 Test MSE 4.223420988245921 Test RE 0.9822911860072934\n",
      "46 Train Loss 6.7992387 Test MSE 4.219919868470045 Test RE 0.9818839530863993\n",
      "47 Train Loss 6.7779455 Test MSE 4.217778789382458 Test RE 0.9816348301179841\n",
      "48 Train Loss 6.7323985 Test MSE 4.220933085183723 Test RE 0.9820018228034755\n",
      "49 Train Loss 6.7017107 Test MSE 4.228318857255289 Test RE 0.9828605987559904\n",
      "50 Train Loss 6.6795945 Test MSE 4.210826409914162 Test RE 0.9808254571193392\n",
      "51 Train Loss 6.6474104 Test MSE 4.207230986353683 Test RE 0.9804066276890481\n",
      "52 Train Loss 6.6299257 Test MSE 4.2327996683015225 Test RE 0.9833812367027938\n",
      "53 Train Loss 6.6066875 Test MSE 4.232989531099716 Test RE 0.9834032913042716\n",
      "54 Train Loss 6.568097 Test MSE 4.189248651132913 Test RE 0.9783091817238252\n",
      "55 Train Loss 6.5121226 Test MSE 4.13460605449421 Test RE 0.9719079361954751\n",
      "56 Train Loss 6.3238087 Test MSE 3.924416345390733 Test RE 0.9468814275356469\n",
      "57 Train Loss 5.8761063 Test MSE 3.617259185046957 Test RE 0.909071147854507\n",
      "58 Train Loss 5.456062 Test MSE 3.3438555032740553 Test RE 0.8740410123331754\n",
      "59 Train Loss 4.7524834 Test MSE 2.9492672762444756 Test RE 0.8208525021111369\n",
      "60 Train Loss 4.3391275 Test MSE 2.9154022972450386 Test RE 0.8161261735516103\n",
      "61 Train Loss 4.0411706 Test MSE 2.8476511254528063 Test RE 0.806587432616045\n",
      "62 Train Loss 3.5782378 Test MSE 2.5063707529807218 Test RE 0.756712167662811\n",
      "63 Train Loss 3.3837414 Test MSE 2.355919512440142 Test RE 0.7336489238807511\n",
      "64 Train Loss 3.28961 Test MSE 2.2988773590625917 Test RE 0.7247128497999696\n",
      "65 Train Loss 3.1750736 Test MSE 2.1552603955152394 Test RE 0.7017104344343407\n",
      "66 Train Loss 3.090613 Test MSE 2.2361458979326336 Test RE 0.7147565241171141\n",
      "67 Train Loss 3.0063136 Test MSE 2.185331065541897 Test RE 0.7065886873986836\n",
      "68 Train Loss 2.8709497 Test MSE 2.1692629582210845 Test RE 0.7039862236464494\n",
      "69 Train Loss 2.8139176 Test MSE 2.1886514003670055 Test RE 0.7071252698378869\n",
      "70 Train Loss 2.786276 Test MSE 2.1804664030833876 Test RE 0.7058017973574013\n",
      "71 Train Loss 2.748798 Test MSE 2.148067201082471 Test RE 0.7005384743797676\n",
      "72 Train Loss 2.7200136 Test MSE 2.166362901311782 Test RE 0.7035154916618238\n",
      "73 Train Loss 2.6989508 Test MSE 2.146994597018132 Test RE 0.7003635510258965\n",
      "74 Train Loss 2.6889467 Test MSE 2.151340790775098 Test RE 0.7010720709246733\n",
      "75 Train Loss 2.6776302 Test MSE 2.178296496182351 Test RE 0.7054505180610925\n",
      "76 Train Loss 2.6668575 Test MSE 2.152555841402928 Test RE 0.7012700213890166\n",
      "77 Train Loss 2.6608272 Test MSE 2.1520601039122447 Test RE 0.7011892648641032\n",
      "78 Train Loss 2.6517587 Test MSE 2.160183688006351 Test RE 0.7025114409044095\n",
      "79 Train Loss 2.6332695 Test MSE 2.152943960035601 Test RE 0.7013332401192743\n",
      "80 Train Loss 2.6258733 Test MSE 2.1581079372203753 Test RE 0.7021738332364551\n",
      "81 Train Loss 2.618819 Test MSE 2.155844503514867 Test RE 0.7018055150362581\n",
      "82 Train Loss 2.6083565 Test MSE 2.1358207420088653 Test RE 0.6985386816254807\n",
      "83 Train Loss 2.599414 Test MSE 2.1448625189022796 Test RE 0.7000157158006942\n",
      "84 Train Loss 2.580502 Test MSE 2.155767356001045 Test RE 0.7017929577681039\n",
      "85 Train Loss 2.5667017 Test MSE 2.150673946488079 Test RE 0.7009634079595273\n",
      "86 Train Loss 2.5598369 Test MSE 2.1542213286893332 Test RE 0.7015412641717749\n",
      "87 Train Loss 2.5566967 Test MSE 2.1528953822642287 Test RE 0.7013253278376248\n",
      "88 Train Loss 2.5470135 Test MSE 2.143227836168236 Test RE 0.6997489104211578\n",
      "89 Train Loss 2.5398479 Test MSE 2.1519630364739526 Test RE 0.7011734513157099\n",
      "90 Train Loss 2.5347912 Test MSE 2.1530067285027097 Test RE 0.701343463630052\n",
      "91 Train Loss 2.5268712 Test MSE 2.1543341063069006 Test RE 0.7015596274466801\n",
      "92 Train Loss 2.5180836 Test MSE 2.1451075397488704 Test RE 0.7000556982106805\n",
      "93 Train Loss 2.5128968 Test MSE 2.139968110366198 Test RE 0.6992165690822439\n",
      "94 Train Loss 2.508966 Test MSE 2.1403785909257667 Test RE 0.699283626400749\n",
      "95 Train Loss 2.5057495 Test MSE 2.138998184648121 Test RE 0.6990580935907148\n",
      "96 Train Loss 2.5028331 Test MSE 2.141063063207289 Test RE 0.6993954295184808\n",
      "97 Train Loss 2.4978795 Test MSE 2.1380292966277095 Test RE 0.6988997517712245\n",
      "98 Train Loss 2.4920442 Test MSE 2.1341736344877407 Test RE 0.698269279281976\n",
      "99 Train Loss 2.4878426 Test MSE 2.137061985847856 Test RE 0.6987416319201162\n",
      "Training time: 124.18\n",
      "9\n",
      "KG_rowdy_tune37\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.45814 Test MSE 8.608210883706484 Test RE 1.402376124184471\n",
      "1 Train Loss 43.111435 Test MSE 8.898908266692416 Test RE 1.4258584878574334\n",
      "2 Train Loss 37.018623 Test MSE 8.927981413726569 Test RE 1.4281857615649027\n",
      "3 Train Loss 32.313293 Test MSE 8.908727597726342 Test RE 1.426644939179997\n",
      "4 Train Loss 28.264763 Test MSE 8.572924276471415 Test RE 1.3994988763773744\n",
      "5 Train Loss 25.768862 Test MSE 8.57177028563708 Test RE 1.3994046807927545\n",
      "6 Train Loss 23.219755 Test MSE 8.526243167880972 Test RE 1.3956834142624304\n",
      "7 Train Loss 21.283468 Test MSE 8.307692957792845 Test RE 1.3776797625008415\n",
      "8 Train Loss 19.168499 Test MSE 8.481027797229961 Test RE 1.3919777827928461\n",
      "9 Train Loss 17.312428 Test MSE 7.950838410714874 Test RE 1.3477660856309412\n",
      "10 Train Loss 15.823904 Test MSE 7.63740389575115 Test RE 1.3209334546252234\n",
      "11 Train Loss 14.692415 Test MSE 7.421475659924785 Test RE 1.3021265495908214\n",
      "12 Train Loss 13.931255 Test MSE 7.481601015127468 Test RE 1.3073905223504692\n",
      "13 Train Loss 12.97183 Test MSE 7.781281834290183 Test RE 1.3333176649180354\n",
      "14 Train Loss 11.922867 Test MSE 8.239274843748648 Test RE 1.371995084389434\n",
      "15 Train Loss 10.694362 Test MSE 8.260278082776624 Test RE 1.3737426896243992\n",
      "16 Train Loss 8.482327 Test MSE 7.8192548052321715 Test RE 1.336567027627778\n",
      "17 Train Loss 7.6460633 Test MSE 8.017510467691327 Test RE 1.353405160449533\n",
      "18 Train Loss 6.3943267 Test MSE 7.890821499282042 Test RE 1.3426696429864635\n",
      "19 Train Loss 4.855794 Test MSE 7.275150028220106 Test RE 1.2892259458587771\n",
      "20 Train Loss 4.163458 Test MSE 7.094271495675096 Test RE 1.273098371674087\n",
      "21 Train Loss 3.6705592 Test MSE 7.094985755105678 Test RE 1.2731624585667176\n",
      "22 Train Loss 3.4085937 Test MSE 7.097521806927905 Test RE 1.2733899796363606\n",
      "23 Train Loss 3.2489436 Test MSE 7.096585590866219 Test RE 1.273305992048811\n",
      "24 Train Loss 3.079756 Test MSE 7.1536534071466935 Test RE 1.2784154415762894\n",
      "25 Train Loss 2.9800735 Test MSE 7.059164069038495 Test RE 1.2699443733558848\n",
      "26 Train Loss 2.8918784 Test MSE 7.084470702742977 Test RE 1.2722186699381304\n",
      "27 Train Loss 2.8258405 Test MSE 7.168151708090387 Test RE 1.2797102673885388\n",
      "28 Train Loss 2.7466536 Test MSE 7.221732502158069 Test RE 1.2844841783094372\n",
      "29 Train Loss 2.66505 Test MSE 7.260081887893595 Test RE 1.2878901447670443\n",
      "30 Train Loss 2.6074796 Test MSE 7.301407427186569 Test RE 1.2915503811323195\n",
      "31 Train Loss 2.5364416 Test MSE 7.309205544261152 Test RE 1.2922399038995416\n",
      "32 Train Loss 2.4779549 Test MSE 7.2593936129675125 Test RE 1.2878290956275393\n",
      "33 Train Loss 2.423693 Test MSE 7.299674453953179 Test RE 1.2913970986941417\n",
      "34 Train Loss 2.3684142 Test MSE 7.319989928518203 Test RE 1.293192871694755\n",
      "35 Train Loss 2.308118 Test MSE 7.2711794538119605 Test RE 1.2888740860232237\n",
      "36 Train Loss 2.2575192 Test MSE 7.2717527195905225 Test RE 1.288924892969224\n",
      "37 Train Loss 2.220215 Test MSE 7.303847997012391 Test RE 1.291766220034422\n",
      "38 Train Loss 2.1746678 Test MSE 7.31846254906762 Test RE 1.293057946695993\n",
      "39 Train Loss 2.1224384 Test MSE 7.342275427040609 Test RE 1.295159919904155\n",
      "40 Train Loss 2.0754 Test MSE 7.360353809823321 Test RE 1.2967534314680425\n",
      "41 Train Loss 2.0409522 Test MSE 7.32614793308966 Test RE 1.2937367121617092\n",
      "42 Train Loss 1.9984846 Test MSE 7.36810487434835 Test RE 1.2974360463925387\n",
      "43 Train Loss 1.9648931 Test MSE 7.413879905282702 Test RE 1.301460026768615\n",
      "44 Train Loss 1.9257051 Test MSE 7.417972831364405 Test RE 1.301819220927392\n",
      "45 Train Loss 1.8932493 Test MSE 7.406976791653878 Test RE 1.3008539865553705\n",
      "46 Train Loss 1.872179 Test MSE 7.425547207643201 Test RE 1.3024836849960797\n",
      "47 Train Loss 1.849834 Test MSE 7.470853266296221 Test RE 1.3064511141271282\n",
      "48 Train Loss 1.8235596 Test MSE 7.448190479476742 Test RE 1.3044680534283377\n",
      "49 Train Loss 1.8008277 Test MSE 7.425127521082312 Test RE 1.302446876757767\n",
      "50 Train Loss 1.7810441 Test MSE 7.429840837710354 Test RE 1.3028601942806166\n",
      "51 Train Loss 1.765166 Test MSE 7.453913635263899 Test RE 1.3049691308586846\n",
      "52 Train Loss 1.7547663 Test MSE 7.473700791684511 Test RE 1.3067000681733216\n",
      "53 Train Loss 1.742671 Test MSE 7.471164104980866 Test RE 1.3064782925033724\n",
      "54 Train Loss 1.731461 Test MSE 7.449803232195952 Test RE 1.3046092736707298\n",
      "55 Train Loss 1.7199613 Test MSE 7.463511751597878 Test RE 1.3058090397084663\n",
      "56 Train Loss 1.7075051 Test MSE 7.480042249449406 Test RE 1.3072543201105231\n",
      "57 Train Loss 1.6944567 Test MSE 7.470722664508921 Test RE 1.3064396947088812\n",
      "58 Train Loss 1.6800363 Test MSE 7.477863845552988 Test RE 1.307063951181119\n",
      "59 Train Loss 1.6644747 Test MSE 7.504811273871918 Test RE 1.3094169184296331\n",
      "60 Train Loss 1.6455904 Test MSE 7.5321325663419705 Test RE 1.3117982216164583\n",
      "61 Train Loss 1.632941 Test MSE 7.5475632651633004 Test RE 1.3131412414404093\n",
      "62 Train Loss 1.620645 Test MSE 7.538556978074162 Test RE 1.312357541008737\n",
      "63 Train Loss 1.6107354 Test MSE 7.5305191641482985 Test RE 1.3116577188133278\n",
      "64 Train Loss 1.5969307 Test MSE 7.526669713050965 Test RE 1.3113224293360914\n",
      "65 Train Loss 1.5842162 Test MSE 7.554794025287212 Test RE 1.3137701024360005\n",
      "66 Train Loss 1.5751944 Test MSE 7.580961768851165 Test RE 1.316043406057905\n",
      "67 Train Loss 1.5645871 Test MSE 7.5521797534683985 Test RE 1.313542773317598\n",
      "68 Train Loss 1.5490518 Test MSE 7.557447240069737 Test RE 1.3140007777036722\n",
      "69 Train Loss 1.5370482 Test MSE 7.5618143081691045 Test RE 1.314380370307029\n",
      "70 Train Loss 1.5252653 Test MSE 7.5449556891040475 Test RE 1.3129143860077193\n",
      "71 Train Loss 1.5104948 Test MSE 7.58221635411601 Test RE 1.3161522985975862\n",
      "72 Train Loss 1.4961398 Test MSE 7.60077628912417 Test RE 1.3177621689553558\n",
      "73 Train Loss 1.4721156 Test MSE 7.586467603579307 Test RE 1.3165212215753694\n",
      "74 Train Loss 1.4572171 Test MSE 7.577427889129334 Test RE 1.3157366322367448\n",
      "75 Train Loss 1.4294348 Test MSE 7.566306193275713 Test RE 1.3147706978690463\n",
      "76 Train Loss 1.4118495 Test MSE 7.542002498399317 Test RE 1.3126574152447605\n",
      "77 Train Loss 1.3928548 Test MSE 7.524850552262001 Test RE 1.3111639495173317\n",
      "78 Train Loss 1.3682349 Test MSE 7.483903193849642 Test RE 1.3075916567821328\n",
      "79 Train Loss 1.3371968 Test MSE 7.420294390688831 Test RE 1.3020229163434287\n",
      "80 Train Loss 1.3050578 Test MSE 7.384285382581222 Test RE 1.2988598631178732\n",
      "81 Train Loss 1.2714083 Test MSE 7.2877093946751925 Test RE 1.2903382857352523\n",
      "82 Train Loss 1.2423531 Test MSE 7.244555235825199 Test RE 1.2865122453647535\n",
      "83 Train Loss 1.2123215 Test MSE 7.234122963806392 Test RE 1.2855856128493905\n",
      "84 Train Loss 1.1852512 Test MSE 7.170455484877427 Test RE 1.2799158943121838\n",
      "85 Train Loss 1.1625675 Test MSE 7.077567154587347 Test RE 1.2715986544213664\n",
      "86 Train Loss 1.1372787 Test MSE 6.957757735384427 Test RE 1.260789872710785\n",
      "87 Train Loss 1.1091039 Test MSE 6.7926526487239665 Test RE 1.245741015787755\n",
      "88 Train Loss 1.0859487 Test MSE 6.643535062515299 Test RE 1.2319913993531082\n",
      "89 Train Loss 1.061718 Test MSE 6.532666918908653 Test RE 1.2216683367771946\n",
      "90 Train Loss 1.0425972 Test MSE 6.440712308053531 Test RE 1.2130396889471333\n",
      "91 Train Loss 1.0258454 Test MSE 6.340894176141705 Test RE 1.2036031423240379\n",
      "92 Train Loss 1.0091012 Test MSE 6.286674314772373 Test RE 1.198446196134515\n",
      "93 Train Loss 0.99537146 Test MSE 6.237378769312107 Test RE 1.1937382755307406\n",
      "94 Train Loss 0.97823584 Test MSE 6.195565004598636 Test RE 1.1897302916816548\n",
      "95 Train Loss 0.9592364 Test MSE 6.153244360882839 Test RE 1.185659926057983\n",
      "96 Train Loss 0.9464594 Test MSE 6.165450165478645 Test RE 1.1868353030517262\n",
      "97 Train Loss 0.9330578 Test MSE 6.1598627866982225 Test RE 1.1862974022270867\n",
      "98 Train Loss 0.92560947 Test MSE 6.122340622409401 Test RE 1.1826787794959481\n",
      "99 Train Loss 0.9152736 Test MSE 6.129971594235802 Test RE 1.1834156037381305\n",
      "Training time: 122.59\n",
      "0\n",
      "KG_rowdy_tune38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.59557 Test MSE 4.447271463236658 Test RE 1.0079868818862256\n",
      "1 Train Loss 60.844334 Test MSE 5.009910286401699 Test RE 1.069850354067504\n",
      "2 Train Loss 39.157322 Test MSE 6.260438611342019 Test RE 1.1959428891597506\n",
      "3 Train Loss 30.049686 Test MSE 5.780875843267961 Test RE 1.1492245140006994\n",
      "4 Train Loss 24.388153 Test MSE 5.753925211964049 Test RE 1.1465425234258062\n",
      "5 Train Loss 20.361877 Test MSE 5.352767084759169 Test RE 1.105852574737693\n",
      "6 Train Loss 18.261255 Test MSE 5.342669136823473 Test RE 1.1048089917592094\n",
      "7 Train Loss 16.251062 Test MSE 4.940773441123902 Test RE 1.0624427326196044\n",
      "8 Train Loss 15.111747 Test MSE 4.826578030313425 Test RE 1.050092909805458\n",
      "9 Train Loss 13.86269 Test MSE 4.726626599131275 Test RE 1.03916307791734\n",
      "10 Train Loss 12.638054 Test MSE 4.679912801121124 Test RE 1.034015242656136\n",
      "11 Train Loss 11.021615 Test MSE 4.846431231080775 Test RE 1.0522503711531288\n",
      "12 Train Loss 9.064699 Test MSE 4.696980092846108 Test RE 1.0358990148255138\n",
      "13 Train Loss 6.7916684 Test MSE 4.241590216188195 Test RE 0.9844018350120195\n",
      "14 Train Loss 5.938121 Test MSE 4.247761399141282 Test RE 0.9851176886759246\n",
      "15 Train Loss 5.170454 Test MSE 4.168445050296652 Test RE 0.9758770410781175\n",
      "16 Train Loss 4.6664934 Test MSE 4.228606471674587 Test RE 0.9828940257612546\n",
      "17 Train Loss 4.1683307 Test MSE 4.350005935611019 Test RE 0.9969031885135111\n",
      "18 Train Loss 3.8076138 Test MSE 4.3419619355839405 Test RE 0.9959810288617196\n",
      "19 Train Loss 3.5268614 Test MSE 4.436689515856878 Test RE 1.0067869532554021\n",
      "20 Train Loss 3.2965405 Test MSE 4.536374629398533 Test RE 1.0180345486283318\n",
      "21 Train Loss 3.1106548 Test MSE 4.534732330923554 Test RE 1.0178502530100024\n",
      "22 Train Loss 2.953618 Test MSE 4.571359376463247 Test RE 1.021952575701521\n",
      "23 Train Loss 2.8054616 Test MSE 4.652794853435957 Test RE 1.0310150682044874\n",
      "24 Train Loss 2.6605625 Test MSE 4.644715521569312 Test RE 1.0301195277374988\n",
      "25 Train Loss 2.5499716 Test MSE 4.636357777368693 Test RE 1.0291923071198\n",
      "26 Train Loss 2.414669 Test MSE 4.537647511313674 Test RE 1.018177366074343\n",
      "27 Train Loss 2.3044167 Test MSE 4.47905329519643 Test RE 1.0115821918311747\n",
      "28 Train Loss 2.2187295 Test MSE 4.432738981499835 Test RE 1.0063386198515973\n",
      "29 Train Loss 2.1349092 Test MSE 4.3331996335786265 Test RE 0.9949755509151826\n",
      "30 Train Loss 2.0519178 Test MSE 4.301456308788936 Test RE 0.9913244512329402\n",
      "31 Train Loss 2.002765 Test MSE 4.321608142352578 Test RE 0.9936438590176859\n",
      "32 Train Loss 1.9385015 Test MSE 4.354033201213345 Test RE 0.9973645516907412\n",
      "33 Train Loss 1.8852156 Test MSE 4.3298209462701225 Test RE 0.9945875735421787\n",
      "34 Train Loss 1.8103002 Test MSE 4.235598593315287 Test RE 0.9837063117951564\n",
      "35 Train Loss 1.7522553 Test MSE 4.212715815552514 Test RE 0.981045481543782\n",
      "36 Train Loss 1.6955781 Test MSE 4.164346990316479 Test RE 0.9753972235440463\n",
      "37 Train Loss 1.6456234 Test MSE 4.113627432620118 Test RE 0.9694391135311402\n",
      "38 Train Loss 1.5947826 Test MSE 4.088367034479326 Test RE 0.9664580307725321\n",
      "39 Train Loss 1.5445734 Test MSE 4.069284119504652 Test RE 0.9641998666142546\n",
      "40 Train Loss 1.4728736 Test MSE 3.960539619029941 Test RE 0.9512293487575424\n",
      "41 Train Loss 1.4061087 Test MSE 3.830382311041727 Test RE 0.9354684003701002\n",
      "42 Train Loss 1.3386968 Test MSE 3.786141209287213 Test RE 0.9300503575362146\n",
      "43 Train Loss 1.2826898 Test MSE 3.651195504039317 Test RE 0.9133255440890939\n",
      "44 Train Loss 1.241036 Test MSE 3.5247612153721684 Test RE 0.8973728190013308\n",
      "45 Train Loss 1.1560804 Test MSE 3.3348409491729765 Test RE 0.8728620727261702\n",
      "46 Train Loss 1.0923746 Test MSE 3.2264193418878406 Test RE 0.8585556815670171\n",
      "47 Train Loss 1.0428382 Test MSE 3.16419475195433 Test RE 0.8502363399863219\n",
      "48 Train Loss 0.9694115 Test MSE 3.086958303787717 Test RE 0.8397953043518727\n",
      "49 Train Loss 0.9107948 Test MSE 3.0461394171758758 Test RE 0.8342245157350312\n",
      "50 Train Loss 0.86641735 Test MSE 2.9973895741671726 Test RE 0.8275222057327273\n",
      "51 Train Loss 0.8383603 Test MSE 2.992980357389331 Test RE 0.8269133313226983\n",
      "52 Train Loss 0.8153476 Test MSE 3.0191916137919184 Test RE 0.8305263169654898\n",
      "53 Train Loss 0.7946337 Test MSE 3.0238769928288667 Test RE 0.8311704996735911\n",
      "54 Train Loss 0.7773248 Test MSE 3.011438070512611 Test RE 0.8294591999693198\n",
      "55 Train Loss 0.7626561 Test MSE 3.0174153298202757 Test RE 0.8302819688383497\n",
      "56 Train Loss 0.74278164 Test MSE 3.021860438146078 Test RE 0.8308933091167567\n",
      "57 Train Loss 0.7233421 Test MSE 3.0472559341063774 Test RE 0.8343773879995094\n",
      "58 Train Loss 0.69676965 Test MSE 3.03042393344108 Test RE 0.8320697891795891\n",
      "59 Train Loss 0.67915267 Test MSE 2.9988871665372887 Test RE 0.8277289082904011\n",
      "60 Train Loss 0.6603368 Test MSE 3.01539972065117 Test RE 0.8300046116742053\n",
      "61 Train Loss 0.6438828 Test MSE 3.073322926955439 Test RE 0.8379385254033268\n",
      "62 Train Loss 0.62468314 Test MSE 3.0900148436746497 Test RE 0.8402109615316692\n",
      "63 Train Loss 0.60724217 Test MSE 3.052179520196514 Test RE 0.8350511861490852\n",
      "64 Train Loss 0.594771 Test MSE 3.065429498354507 Test RE 0.8368617657404982\n",
      "65 Train Loss 0.58484566 Test MSE 3.065241097641672 Test RE 0.8368360486630232\n",
      "66 Train Loss 0.5716883 Test MSE 3.0529505895602433 Test RE 0.8351566586027539\n",
      "67 Train Loss 0.554039 Test MSE 3.09366905750628 Test RE 0.8407076263505784\n",
      "68 Train Loss 0.5443607 Test MSE 3.0988405020879886 Test RE 0.8414100055351559\n",
      "69 Train Loss 0.5340395 Test MSE 3.0910095820097747 Test RE 0.8403461911084993\n",
      "70 Train Loss 0.52515024 Test MSE 3.118432033279297 Test RE 0.8440656016760567\n",
      "71 Train Loss 0.5159201 Test MSE 3.1232787430409075 Test RE 0.8447212761676552\n",
      "72 Train Loss 0.50663066 Test MSE 3.135571373251413 Test RE 0.8463819747442559\n",
      "73 Train Loss 0.50107336 Test MSE 3.1447845409971196 Test RE 0.8476245137460796\n",
      "74 Train Loss 0.49416006 Test MSE 3.123425060398467 Test RE 0.8447410624159625\n",
      "75 Train Loss 0.48857042 Test MSE 3.1302831313537136 Test RE 0.8456679483586141\n",
      "76 Train Loss 0.48320293 Test MSE 3.127910868755685 Test RE 0.8453474459327865\n",
      "77 Train Loss 0.4770401 Test MSE 3.130251892786664 Test RE 0.8456637286890657\n",
      "78 Train Loss 0.4696989 Test MSE 3.168670163348354 Test RE 0.8508374112155791\n",
      "79 Train Loss 0.46520257 Test MSE 3.1626006069404955 Test RE 0.8500221352855328\n",
      "80 Train Loss 0.45821592 Test MSE 3.1711527261188515 Test RE 0.8511706493897355\n",
      "81 Train Loss 0.45354074 Test MSE 3.2038833548032404 Test RE 0.8555519950454762\n",
      "82 Train Loss 0.4504645 Test MSE 3.205238192748594 Test RE 0.8557328711359597\n",
      "83 Train Loss 0.4452654 Test MSE 3.2092368042815025 Test RE 0.8562664784079211\n",
      "84 Train Loss 0.43911698 Test MSE 3.2125442405697306 Test RE 0.8567075984771684\n",
      "85 Train Loss 0.4348581 Test MSE 3.2317221924522057 Test RE 0.8592609406831085\n",
      "86 Train Loss 0.42849827 Test MSE 3.2628956700117913 Test RE 0.8633952480811171\n",
      "87 Train Loss 0.42438602 Test MSE 3.261159550295757 Test RE 0.8631655200866112\n",
      "88 Train Loss 0.42056262 Test MSE 3.276932695937794 Test RE 0.8652504246021059\n",
      "89 Train Loss 0.41547203 Test MSE 3.290923527363005 Test RE 0.8670955462917572\n",
      "90 Train Loss 0.4116437 Test MSE 3.294197881353134 Test RE 0.8675268039415713\n",
      "91 Train Loss 0.40868613 Test MSE 3.3048210587219606 Test RE 0.8689244845778048\n",
      "92 Train Loss 0.40583068 Test MSE 3.3058035109180968 Test RE 0.8690536312573794\n",
      "93 Train Loss 0.40315303 Test MSE 3.3219382377670845 Test RE 0.8711718568590835\n",
      "94 Train Loss 0.4009412 Test MSE 3.3392033857634704 Test RE 0.8734327987414974\n",
      "95 Train Loss 0.39831057 Test MSE 3.3298183209808516 Test RE 0.8722045130880667\n",
      "96 Train Loss 0.39541277 Test MSE 3.343362189493658 Test RE 0.8739765370023089\n",
      "97 Train Loss 0.39165583 Test MSE 3.3492352143294526 Test RE 0.8747438235628167\n",
      "98 Train Loss 0.38904816 Test MSE 3.337074405364256 Test RE 0.8731543164835162\n",
      "99 Train Loss 0.38645458 Test MSE 3.3356193153084805 Test RE 0.8729639316527691\n",
      "Training time: 121.87\n",
      "1\n",
      "KG_rowdy_tune38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.934177 Test MSE 8.26649210968869 Test RE 1.3742593108029395\n",
      "1 Train Loss 45.19065 Test MSE 8.563151591338206 Test RE 1.3987009711718785\n",
      "2 Train Loss 41.299603 Test MSE 9.498352254304917 Test RE 1.4730998867938945\n",
      "3 Train Loss 38.964516 Test MSE 9.76946116686345 Test RE 1.493975122596832\n",
      "4 Train Loss 36.25264 Test MSE 9.708368051708936 Test RE 1.4892965261118951\n",
      "5 Train Loss 33.513317 Test MSE 9.764317282196378 Test RE 1.4935817617231093\n",
      "6 Train Loss 29.280634 Test MSE 10.000422635236722 Test RE 1.5115316227865936\n",
      "7 Train Loss 26.958614 Test MSE 9.77639995209939 Test RE 1.494505578284926\n",
      "8 Train Loss 25.014172 Test MSE 9.799439723893137 Test RE 1.4962655719759355\n",
      "9 Train Loss 23.398325 Test MSE 9.617231872835188 Test RE 1.4822897443136098\n",
      "10 Train Loss 22.246868 Test MSE 9.598505285651894 Test RE 1.4808458904942483\n",
      "11 Train Loss 21.345768 Test MSE 9.752978763841748 Test RE 1.4927143214862824\n",
      "12 Train Loss 20.33756 Test MSE 9.679966871666998 Test RE 1.4871165119885386\n",
      "13 Train Loss 19.495909 Test MSE 9.606156705017494 Test RE 1.4814359988211936\n",
      "14 Train Loss 18.736118 Test MSE 9.779713721935073 Test RE 1.4947588426733742\n",
      "15 Train Loss 17.587654 Test MSE 9.372113384981011 Test RE 1.463277946729044\n",
      "16 Train Loss 16.32621 Test MSE 9.150410020181548 Test RE 1.4458669734623233\n",
      "17 Train Loss 14.370752 Test MSE 8.382340100050905 Test RE 1.3838553564937413\n",
      "18 Train Loss 13.286161 Test MSE 8.27272796831349 Test RE 1.3747775518614151\n",
      "19 Train Loss 12.612511 Test MSE 8.186667114983887 Test RE 1.3676079793804152\n",
      "20 Train Loss 11.473933 Test MSE 7.252059372147361 Test RE 1.2871783776688257\n",
      "21 Train Loss 10.967837 Test MSE 7.1910693915479165 Test RE 1.2817543501514044\n",
      "22 Train Loss 10.072275 Test MSE 6.793801854712532 Test RE 1.24584639085721\n",
      "23 Train Loss 9.4554615 Test MSE 6.517733380930084 Test RE 1.220271183905512\n",
      "24 Train Loss 9.125503 Test MSE 6.466979239955935 Test RE 1.215510720813648\n",
      "25 Train Loss 8.910413 Test MSE 6.559240962485117 Test RE 1.2241506092919796\n",
      "26 Train Loss 8.720303 Test MSE 6.596895506785578 Test RE 1.2276593131819227\n",
      "27 Train Loss 8.550816 Test MSE 6.599542111794128 Test RE 1.2279055504817222\n",
      "28 Train Loss 8.291399 Test MSE 6.598405691581615 Test RE 1.227799825210201\n",
      "29 Train Loss 8.082542 Test MSE 6.642439718317532 Test RE 1.23188983367721\n",
      "30 Train Loss 7.92286 Test MSE 6.669149721070484 Test RE 1.2343641331155526\n",
      "31 Train Loss 7.767651 Test MSE 6.664954665709691 Test RE 1.2339758497020945\n",
      "32 Train Loss 7.638244 Test MSE 6.6837493569072155 Test RE 1.2357144862822476\n",
      "33 Train Loss 7.503787 Test MSE 6.692938634806051 Test RE 1.2365636670992415\n",
      "34 Train Loss 7.3875303 Test MSE 6.797242637641517 Test RE 1.2461618360574762\n",
      "35 Train Loss 7.2875624 Test MSE 6.796120827758529 Test RE 1.2460589991850777\n",
      "36 Train Loss 7.1987066 Test MSE 6.845745850593268 Test RE 1.2506000629474678\n",
      "37 Train Loss 7.068925 Test MSE 6.940698975535619 Test RE 1.2592433464100423\n",
      "38 Train Loss 7.002911 Test MSE 6.912888723522655 Test RE 1.256718022582823\n",
      "39 Train Loss 6.9181843 Test MSE 6.870281085857994 Test RE 1.2528391413361182\n",
      "40 Train Loss 6.826765 Test MSE 6.823217212854006 Test RE 1.2485405697749394\n",
      "41 Train Loss 6.769103 Test MSE 6.807754020595643 Test RE 1.247125007802377\n",
      "42 Train Loss 6.693075 Test MSE 6.772247964779195 Test RE 1.2438685463003698\n",
      "43 Train Loss 6.6080956 Test MSE 6.671947523777556 Test RE 1.2346230225793318\n",
      "44 Train Loss 6.564146 Test MSE 6.673454325706338 Test RE 1.234762429201008\n",
      "45 Train Loss 6.5058546 Test MSE 6.691328514867071 Test RE 1.2364149181203612\n",
      "46 Train Loss 6.4175596 Test MSE 6.621891424060705 Test RE 1.229982940822961\n",
      "47 Train Loss 6.333497 Test MSE 6.599935351039242 Test RE 1.227942132827199\n",
      "48 Train Loss 6.17268 Test MSE 6.639382051974501 Test RE 1.2316062675616188\n",
      "49 Train Loss 5.9608784 Test MSE 6.618886407952785 Test RE 1.2297038258592004\n",
      "50 Train Loss 5.373899 Test MSE 6.274687078445405 Test RE 1.1973030708679522\n",
      "51 Train Loss 4.466424 Test MSE 6.097764321357038 Test RE 1.1803026378145876\n",
      "52 Train Loss 4.1024804 Test MSE 6.051926970896605 Test RE 1.1758580578965667\n",
      "53 Train Loss 3.720945 Test MSE 5.876750993192444 Test RE 1.1587152024230716\n",
      "54 Train Loss 3.3874042 Test MSE 5.719659955537008 Test RE 1.1431235323988003\n",
      "55 Train Loss 3.2239478 Test MSE 5.753534217205445 Test RE 1.1465035674334543\n",
      "56 Train Loss 3.0629573 Test MSE 5.756848992003693 Test RE 1.1468337865445082\n",
      "57 Train Loss 2.9252548 Test MSE 5.801376250525216 Test RE 1.1512604269964926\n",
      "58 Train Loss 2.828655 Test MSE 5.734072806624053 Test RE 1.1445628927154834\n",
      "59 Train Loss 2.740609 Test MSE 5.675100165534601 Test RE 1.1386619960602287\n",
      "60 Train Loss 2.6770904 Test MSE 5.725038401273275 Test RE 1.1436608705669866\n",
      "61 Train Loss 2.6206775 Test MSE 5.6866707734806194 Test RE 1.1398221784856524\n",
      "62 Train Loss 2.5881548 Test MSE 5.7178943846850245 Test RE 1.142947086475387\n",
      "63 Train Loss 2.5383701 Test MSE 5.738576342810194 Test RE 1.1450122738861526\n",
      "64 Train Loss 2.494507 Test MSE 5.757547204399431 Test RE 1.1469033306031766\n",
      "65 Train Loss 2.4488165 Test MSE 5.791795121088912 Test RE 1.1503093653264167\n",
      "66 Train Loss 2.4252586 Test MSE 5.776175374670527 Test RE 1.148757197938952\n",
      "67 Train Loss 2.380208 Test MSE 5.794406588843644 Test RE 1.1505686681168674\n",
      "68 Train Loss 2.34577 Test MSE 5.825504436692612 Test RE 1.1536520149842944\n",
      "69 Train Loss 2.3059924 Test MSE 5.838689466531712 Test RE 1.1549568238035886\n",
      "70 Train Loss 2.277251 Test MSE 5.83776697954019 Test RE 1.1548655811764057\n",
      "71 Train Loss 2.2506533 Test MSE 5.802110118011454 Test RE 1.1513332412600326\n",
      "72 Train Loss 2.215228 Test MSE 5.771832231156869 Test RE 1.1483252377526485\n",
      "73 Train Loss 2.18129 Test MSE 5.784511620860622 Test RE 1.1495858492106414\n",
      "74 Train Loss 2.1472266 Test MSE 5.756096804172741 Test RE 1.146758861650762\n",
      "75 Train Loss 2.1093173 Test MSE 5.7702143303406785 Test RE 1.1481642830957512\n",
      "76 Train Loss 2.0741622 Test MSE 5.811662780601161 Test RE 1.1522806357897226\n",
      "77 Train Loss 2.0477276 Test MSE 5.815332023070582 Test RE 1.1526443294579785\n",
      "78 Train Loss 2.0116365 Test MSE 5.810156581119352 Test RE 1.152131308735874\n",
      "79 Train Loss 1.9701803 Test MSE 5.83128905278517 Test RE 1.1542246502176075\n",
      "80 Train Loss 1.9476829 Test MSE 5.831498918025529 Test RE 1.1542454200209942\n",
      "81 Train Loss 1.9227619 Test MSE 5.821281849537032 Test RE 1.1532338298034943\n",
      "82 Train Loss 1.8904462 Test MSE 5.7849624397455015 Test RE 1.1496306451197316\n",
      "83 Train Loss 1.8679852 Test MSE 5.763637849630199 Test RE 1.1475097984835596\n",
      "84 Train Loss 1.8475404 Test MSE 5.766384034887956 Test RE 1.1477831414046\n",
      "85 Train Loss 1.8333182 Test MSE 5.760312357149782 Test RE 1.1471787067402355\n",
      "86 Train Loss 1.8207923 Test MSE 5.758845381513247 Test RE 1.147032621748001\n",
      "87 Train Loss 1.8083061 Test MSE 5.761959225876274 Test RE 1.1473426837612746\n",
      "88 Train Loss 1.7997427 Test MSE 5.761529698591395 Test RE 1.147299918431543\n",
      "89 Train Loss 1.7822453 Test MSE 5.7786078722358605 Test RE 1.148999058233575\n",
      "90 Train Loss 1.7642467 Test MSE 5.800409168679595 Test RE 1.1511644661922493\n",
      "91 Train Loss 1.7457768 Test MSE 5.784470450547667 Test RE 1.1495817582089722\n",
      "92 Train Loss 1.7184875 Test MSE 5.782904188287585 Test RE 1.1494261114269335\n",
      "93 Train Loss 1.7025552 Test MSE 5.804307359576068 Test RE 1.1515512238339105\n",
      "94 Train Loss 1.6829528 Test MSE 5.781827817600415 Test RE 1.149319135233933\n",
      "95 Train Loss 1.6699032 Test MSE 5.778660296551252 Test RE 1.1490042701595033\n",
      "96 Train Loss 1.6590095 Test MSE 5.80200913956078 Test RE 1.1513232224608032\n",
      "97 Train Loss 1.6322874 Test MSE 5.803663831700028 Test RE 1.1514873853938705\n",
      "98 Train Loss 1.6198308 Test MSE 5.801935708451152 Test RE 1.151315936776894\n",
      "99 Train Loss 1.6085025 Test MSE 5.838349400755447 Test RE 1.1549231889433853\n",
      "Training time: 122.54\n",
      "2\n",
      "KG_rowdy_tune38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.664764 Test MSE 7.41824011145959 Test RE 1.3018426739137379\n",
      "1 Train Loss 42.888702 Test MSE 7.377717653392717 Test RE 1.2982821188238225\n",
      "2 Train Loss 32.456276 Test MSE 7.06574917031869 Test RE 1.2705365654956977\n",
      "3 Train Loss 24.973497 Test MSE 6.370618193449782 Test RE 1.2064208909884202\n",
      "4 Train Loss 19.911856 Test MSE 5.4750220839119565 Test RE 1.1184098876072817\n",
      "5 Train Loss 16.3856 Test MSE 5.40348522408982 Test RE 1.1110792689376885\n",
      "6 Train Loss 14.251455 Test MSE 5.106627277756071 Test RE 1.0801277917782526\n",
      "7 Train Loss 12.359129 Test MSE 4.978284020470771 Test RE 1.0664681638121378\n",
      "8 Train Loss 10.62095 Test MSE 4.63138739235904 Test RE 1.0286404888603593\n",
      "9 Train Loss 9.288636 Test MSE 4.572608026887528 Test RE 1.0220921375130254\n",
      "10 Train Loss 8.331836 Test MSE 4.374079998466864 Test RE 0.9996579429967388\n",
      "11 Train Loss 7.6788917 Test MSE 4.18752617076267 Test RE 0.9781080368702091\n",
      "12 Train Loss 7.0799446 Test MSE 4.047857534461869 Test RE 0.9616580463532972\n",
      "13 Train Loss 6.3966303 Test MSE 3.7311885221642958 Test RE 0.9232762342362911\n",
      "14 Train Loss 6.039829 Test MSE 3.678878282530556 Test RE 0.9167813499845425\n",
      "15 Train Loss 5.799838 Test MSE 3.6350014901808154 Test RE 0.9112978735892397\n",
      "16 Train Loss 5.6236973 Test MSE 3.5799451716908535 Test RE 0.9043702093800957\n",
      "17 Train Loss 5.4769344 Test MSE 3.570780430702573 Test RE 0.9032118634138032\n",
      "18 Train Loss 5.343905 Test MSE 3.529406596891196 Test RE 0.897963960679762\n",
      "19 Train Loss 5.2101555 Test MSE 3.4850398441414345 Test RE 0.8923021391448042\n",
      "20 Train Loss 5.087052 Test MSE 3.4716159949473133 Test RE 0.8905819742910392\n",
      "21 Train Loss 5.007482 Test MSE 3.4429818486295565 Test RE 0.8869015764264923\n",
      "22 Train Loss 4.8820143 Test MSE 3.4176484187003546 Test RE 0.8836326451628967\n",
      "23 Train Loss 4.7389 Test MSE 3.424221331439213 Test RE 0.8844819499620193\n",
      "24 Train Loss 4.559557 Test MSE 3.3312691307716964 Test RE 0.872394503189703\n",
      "25 Train Loss 4.2788706 Test MSE 3.297256947752235 Test RE 0.8679295129435745\n",
      "26 Train Loss 4.009224 Test MSE 3.290787990931473 Test RE 0.8670776904763252\n",
      "27 Train Loss 3.6511178 Test MSE 3.1629656925960004 Test RE 0.8500711964809718\n",
      "28 Train Loss 3.3623135 Test MSE 3.0227762716714985 Test RE 0.8310192087598613\n",
      "29 Train Loss 3.1698549 Test MSE 3.0453024228985797 Test RE 0.8341098970290374\n",
      "30 Train Loss 2.9477754 Test MSE 2.860896274059186 Test RE 0.8084610779431365\n",
      "31 Train Loss 2.7487102 Test MSE 2.7895351198530784 Test RE 0.798314425504874\n",
      "32 Train Loss 2.6244059 Test MSE 2.8320447203967505 Test RE 0.8043741656234458\n",
      "33 Train Loss 2.4908168 Test MSE 2.758870354624268 Test RE 0.7939144498965862\n",
      "34 Train Loss 2.366586 Test MSE 2.721421283046962 Test RE 0.7885077182142678\n",
      "35 Train Loss 2.267772 Test MSE 2.719050798493131 Test RE 0.7881642299451491\n",
      "36 Train Loss 2.178196 Test MSE 2.6567894920692408 Test RE 0.7790882109768327\n",
      "37 Train Loss 2.0914328 Test MSE 2.596122568279471 Test RE 0.7701417306227261\n",
      "38 Train Loss 2.0189722 Test MSE 2.5401037184811113 Test RE 0.7617874004852059\n",
      "39 Train Loss 1.9317735 Test MSE 2.4329849256515055 Test RE 0.7455517077656105\n",
      "40 Train Loss 1.8750148 Test MSE 2.3800815052595126 Test RE 0.7374014293409332\n",
      "41 Train Loss 1.8021237 Test MSE 2.3718162153490194 Test RE 0.7361199318038555\n",
      "42 Train Loss 1.7352825 Test MSE 2.3388631866634526 Test RE 0.7309883733377717\n",
      "43 Train Loss 1.67291 Test MSE 2.266881512277923 Test RE 0.719651890425777\n",
      "44 Train Loss 1.6282917 Test MSE 2.212810596281684 Test RE 0.7110173223884032\n",
      "45 Train Loss 1.5751821 Test MSE 2.1888656762172785 Test RE 0.7071598838837859\n",
      "46 Train Loss 1.5375489 Test MSE 2.1284291514666434 Test RE 0.6973288921473257\n",
      "47 Train Loss 1.4919524 Test MSE 1.9948227327591253 Test RE 0.6750877301132597\n",
      "48 Train Loss 1.4409423 Test MSE 1.9095732435759685 Test RE 0.6605051690214505\n",
      "49 Train Loss 1.3983772 Test MSE 1.8651660432740371 Test RE 0.6527799555535035\n",
      "50 Train Loss 1.3626074 Test MSE 1.7930877508373368 Test RE 0.6400425283905264\n",
      "51 Train Loss 1.3129373 Test MSE 1.7041663208139541 Test RE 0.6239704880915572\n",
      "52 Train Loss 1.2717036 Test MSE 1.5903920201704251 Test RE 0.6027818322437213\n",
      "53 Train Loss 1.2357215 Test MSE 1.504332830803006 Test RE 0.5862461817359849\n",
      "54 Train Loss 1.1662464 Test MSE 1.4191089613871637 Test RE 0.569397992380381\n",
      "55 Train Loss 1.0687158 Test MSE 1.2247660321766716 Test RE 0.5289743661257261\n",
      "56 Train Loss 0.9897348 Test MSE 1.0037864798787914 Test RE 0.47888224027684945\n",
      "57 Train Loss 0.90789276 Test MSE 0.90509375987139 Test RE 0.4547312969535136\n",
      "58 Train Loss 0.7722264 Test MSE 0.8177565315797369 Test RE 0.43223513968015104\n",
      "59 Train Loss 0.6779438 Test MSE 0.6677851962522138 Test RE 0.39059479699985356\n",
      "60 Train Loss 0.5621616 Test MSE 0.48405399759461093 Test RE 0.3325484790237396\n",
      "61 Train Loss 0.4836696 Test MSE 0.4924369813218177 Test RE 0.33541570266428034\n",
      "62 Train Loss 0.4219111 Test MSE 0.45027676378694564 Test RE 0.3207360883591827\n",
      "63 Train Loss 0.33935818 Test MSE 0.404935538265125 Test RE 0.3041592348096915\n",
      "64 Train Loss 0.30240613 Test MSE 0.40224097661387653 Test RE 0.30314556261614384\n",
      "65 Train Loss 0.26778346 Test MSE 0.3736358786416184 Test RE 0.29216779758459865\n",
      "66 Train Loss 0.2427864 Test MSE 0.33130489520967366 Test RE 0.27511988844218055\n",
      "67 Train Loss 0.2178335 Test MSE 0.31438852105924375 Test RE 0.2680040769214173\n",
      "68 Train Loss 0.19731967 Test MSE 0.2920672872605815 Test RE 0.25831493632668767\n",
      "69 Train Loss 0.1807729 Test MSE 0.28649656431309856 Test RE 0.2558396011840669\n",
      "70 Train Loss 0.16540112 Test MSE 0.2695827298476318 Test RE 0.24817275029394117\n",
      "71 Train Loss 0.15022476 Test MSE 0.234471694494221 Test RE 0.23144791420270858\n",
      "72 Train Loss 0.14209144 Test MSE 0.23946374425425607 Test RE 0.23389877361188366\n",
      "73 Train Loss 0.13017058 Test MSE 0.2464110573955514 Test RE 0.23726744655688953\n",
      "74 Train Loss 0.12269505 Test MSE 0.23567642216153023 Test RE 0.2320417480568197\n",
      "75 Train Loss 0.116519265 Test MSE 0.22847915514728445 Test RE 0.22847114193888596\n",
      "76 Train Loss 0.11055613 Test MSE 0.22413840773470475 Test RE 0.2262904371879906\n",
      "77 Train Loss 0.10378847 Test MSE 0.20425948191270496 Test RE 0.21602259226305434\n",
      "78 Train Loss 0.09902431 Test MSE 0.20491353535767862 Test RE 0.2163681757205279\n",
      "79 Train Loss 0.0934287 Test MSE 0.202849877410344 Test RE 0.21527591066529414\n",
      "80 Train Loss 0.088354446 Test MSE 0.1955611123827528 Test RE 0.21137290187708171\n",
      "81 Train Loss 0.08411315 Test MSE 0.19225768944311522 Test RE 0.20958004033471409\n",
      "82 Train Loss 0.08004767 Test MSE 0.18085558447731478 Test RE 0.20327034394838742\n",
      "83 Train Loss 0.07525509 Test MSE 0.1695481946724042 Test RE 0.19681339149842636\n",
      "84 Train Loss 0.07219307 Test MSE 0.16131269344775803 Test RE 0.19197396358452337\n",
      "85 Train Loss 0.06810361 Test MSE 0.14710899920202541 Test RE 0.1833275272932269\n",
      "86 Train Loss 0.063248284 Test MSE 0.1285118958669912 Test RE 0.1713482706214925\n",
      "87 Train Loss 0.060005803 Test MSE 0.11908631805747594 Test RE 0.1649449388307285\n",
      "88 Train Loss 0.057893667 Test MSE 0.11767657336492746 Test RE 0.16396572252243985\n",
      "89 Train Loss 0.053590514 Test MSE 0.11307862604673176 Test RE 0.1607305096456818\n",
      "90 Train Loss 0.050681043 Test MSE 0.1056510743541029 Test RE 0.15536207719507275\n",
      "91 Train Loss 0.049129423 Test MSE 0.09446839681799866 Test RE 0.14690999125227144\n",
      "92 Train Loss 0.04797247 Test MSE 0.09333666014193105 Test RE 0.14602734479374396\n",
      "93 Train Loss 0.046807256 Test MSE 0.09315188311486239 Test RE 0.14588272923734807\n",
      "94 Train Loss 0.045199048 Test MSE 0.08448095790061931 Test RE 0.13892726148552165\n",
      "95 Train Loss 0.044426177 Test MSE 0.08505880826812239 Test RE 0.13940158351656812\n",
      "96 Train Loss 0.04385348 Test MSE 0.08241916662210395 Test RE 0.13722150231289632\n",
      "97 Train Loss 0.04272022 Test MSE 0.07500831571773162 Test RE 0.1309069689159344\n",
      "98 Train Loss 0.041405402 Test MSE 0.07122821722092919 Test RE 0.12756575316363775\n",
      "99 Train Loss 0.039529692 Test MSE 0.06587252426644757 Test RE 0.1226761713202703\n",
      "Training time: 122.30\n",
      "3\n",
      "KG_rowdy_tune38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.858437 Test MSE 5.709725131108809 Test RE 1.1421303206065696\n",
      "1 Train Loss 45.507782 Test MSE 8.394631805539872 Test RE 1.3848696145100867\n",
      "2 Train Loss 34.85077 Test MSE 8.071675577927723 Test RE 1.3579691671386676\n",
      "3 Train Loss 31.30144 Test MSE 8.410451897869093 Test RE 1.3861739273944311\n",
      "4 Train Loss 28.43335 Test MSE 8.943840661867437 Test RE 1.4294536799038835\n",
      "5 Train Loss 26.111965 Test MSE 9.222228600131146 Test RE 1.4515299523074092\n",
      "6 Train Loss 24.37373 Test MSE 9.629428577921313 Test RE 1.483229376564837\n",
      "7 Train Loss 22.450596 Test MSE 9.456054557547576 Test RE 1.4698162512100017\n",
      "8 Train Loss 21.325605 Test MSE 9.349984650069421 Test RE 1.4615494344580344\n",
      "9 Train Loss 20.485918 Test MSE 9.483600637930646 Test RE 1.4719555278734955\n",
      "10 Train Loss 19.626966 Test MSE 9.760747730255567 Test RE 1.4933087316246225\n",
      "11 Train Loss 18.787365 Test MSE 9.729605234138509 Test RE 1.4909245641004802\n",
      "12 Train Loss 17.852917 Test MSE 9.260777366158761 Test RE 1.4545604745598413\n",
      "13 Train Loss 16.947124 Test MSE 9.273820073700886 Test RE 1.4555844021998883\n",
      "14 Train Loss 16.017973 Test MSE 9.037469997850787 Test RE 1.4369163768489732\n",
      "15 Train Loss 14.5707 Test MSE 8.463625938750127 Test RE 1.3905489796299768\n",
      "16 Train Loss 11.588129 Test MSE 7.445788961338896 Test RE 1.3042577368246533\n",
      "17 Train Loss 9.584072 Test MSE 7.133011428253971 Test RE 1.2765696652254732\n",
      "18 Train Loss 8.567827 Test MSE 6.465760220302144 Test RE 1.2153961540865934\n",
      "19 Train Loss 7.7005944 Test MSE 6.352376041612278 Test RE 1.2046923703272108\n",
      "20 Train Loss 7.223521 Test MSE 6.508800669278613 Test RE 1.219434691574628\n",
      "21 Train Loss 6.853269 Test MSE 6.363187703918871 Test RE 1.2057171199435517\n",
      "22 Train Loss 6.57307 Test MSE 6.268913477483666 Test RE 1.196752099880525\n",
      "23 Train Loss 6.124829 Test MSE 6.389065524278141 Test RE 1.2081663383558783\n",
      "24 Train Loss 5.8194704 Test MSE 6.303523426654891 Test RE 1.200051118015826\n",
      "25 Train Loss 5.657713 Test MSE 6.2066918263051205 Test RE 1.1907981505897347\n",
      "26 Train Loss 5.4676514 Test MSE 6.245450754228825 Test RE 1.1945104526116603\n",
      "27 Train Loss 5.3050785 Test MSE 6.238370706644134 Test RE 1.1938331925247194\n",
      "28 Train Loss 4.8836236 Test MSE 6.181712146426829 Test RE 1.1883994697159834\n",
      "29 Train Loss 4.416403 Test MSE 6.026475171860507 Test RE 1.1733828764190852\n",
      "30 Train Loss 3.7925997 Test MSE 5.656704054966769 Test RE 1.1368149841948323\n",
      "31 Train Loss 2.78001 Test MSE 5.362225242454372 Test RE 1.1068291455124024\n",
      "32 Train Loss 2.4951231 Test MSE 5.495799749570419 Test RE 1.1205300563606582\n",
      "33 Train Loss 2.288981 Test MSE 5.5078508675894255 Test RE 1.1217579254626775\n",
      "34 Train Loss 2.0499246 Test MSE 5.491231027581144 Test RE 1.1200642047161253\n",
      "35 Train Loss 1.9112269 Test MSE 5.452724412522578 Test RE 1.1161301361948988\n",
      "36 Train Loss 1.8074118 Test MSE 5.402605441612941 Test RE 1.110988813627568\n",
      "37 Train Loss 1.7499282 Test MSE 5.434429646535266 Test RE 1.11425616508972\n",
      "38 Train Loss 1.7057757 Test MSE 5.498097974600887 Test RE 1.1207643226340016\n",
      "39 Train Loss 1.647403 Test MSE 5.5125394075858605 Test RE 1.1222352702782117\n",
      "40 Train Loss 1.5798163 Test MSE 5.528906045696091 Test RE 1.1238999845228548\n",
      "41 Train Loss 1.5424569 Test MSE 5.50020481151513 Test RE 1.1209790370221016\n",
      "42 Train Loss 1.5169685 Test MSE 5.5202439260139275 Test RE 1.1230192341380507\n",
      "43 Train Loss 1.4854778 Test MSE 5.574544810227313 Test RE 1.1285291091325456\n",
      "44 Train Loss 1.4567198 Test MSE 5.584144550749821 Test RE 1.129500392614791\n",
      "45 Train Loss 1.4271123 Test MSE 5.577073143853326 Test RE 1.1287850021907981\n",
      "46 Train Loss 1.4093404 Test MSE 5.5721871089515576 Test RE 1.12829043350937\n",
      "47 Train Loss 1.3931981 Test MSE 5.584541542383838 Test RE 1.129540541489267\n",
      "48 Train Loss 1.379583 Test MSE 5.602869245294734 Test RE 1.1313925221701278\n",
      "49 Train Loss 1.3513929 Test MSE 5.6064808784405455 Test RE 1.1317571136210351\n",
      "50 Train Loss 1.3242376 Test MSE 5.600959849231024 Test RE 1.1311997226941162\n",
      "51 Train Loss 1.3006212 Test MSE 5.614894805456824 Test RE 1.1326060375634726\n",
      "52 Train Loss 1.2846804 Test MSE 5.618525490935362 Test RE 1.1329721594505813\n",
      "53 Train Loss 1.269332 Test MSE 5.61030183998901 Test RE 1.132142708788522\n",
      "54 Train Loss 1.2544836 Test MSE 5.599971971302628 Test RE 1.1310999597474325\n",
      "55 Train Loss 1.2396659 Test MSE 5.607798466563916 Test RE 1.1318900938418142\n",
      "56 Train Loss 1.2273171 Test MSE 5.6045836999998855 Test RE 1.1315656096351505\n",
      "57 Train Loss 1.2134404 Test MSE 5.600657689708255 Test RE 1.131169209408218\n",
      "58 Train Loss 1.2057108 Test MSE 5.626739670598306 Test RE 1.1338000490731037\n",
      "59 Train Loss 1.1995047 Test MSE 5.636086129202297 Test RE 1.1347413240276472\n",
      "60 Train Loss 1.193014 Test MSE 5.622233748968665 Test RE 1.133345981738844\n",
      "61 Train Loss 1.1808913 Test MSE 5.615893337999666 Test RE 1.1327067423629067\n",
      "62 Train Loss 1.1684258 Test MSE 5.606972867787757 Test RE 1.1318067704593044\n",
      "63 Train Loss 1.1588781 Test MSE 5.600466308547036 Test RE 1.1311498825417823\n",
      "64 Train Loss 1.1510091 Test MSE 5.603257466450661 Test RE 1.131431718418091\n",
      "65 Train Loss 1.1314654 Test MSE 5.601923649415981 Test RE 1.1312970456203104\n",
      "66 Train Loss 1.1236919 Test MSE 5.610110060289832 Test RE 1.1321233583284362\n",
      "67 Train Loss 1.1090529 Test MSE 5.616296014016951 Test RE 1.1327473508321595\n",
      "68 Train Loss 1.1027157 Test MSE 5.595220883066745 Test RE 1.1306200380570226\n",
      "69 Train Loss 1.0946358 Test MSE 5.589099953629059 Test RE 1.1300014441425597\n",
      "70 Train Loss 1.0814878 Test MSE 5.592796436489759 Test RE 1.1303750589096364\n",
      "71 Train Loss 1.0698769 Test MSE 5.606596432595479 Test RE 1.1317687767806743\n",
      "72 Train Loss 1.0580361 Test MSE 5.630256411328809 Test RE 1.1341543091085033\n",
      "73 Train Loss 1.0465055 Test MSE 5.646409269037435 Test RE 1.1357800532162803\n",
      "74 Train Loss 1.0394859 Test MSE 5.6575704081051175 Test RE 1.1369020353745136\n",
      "75 Train Loss 1.0333003 Test MSE 5.669554037470583 Test RE 1.1381054676524762\n",
      "76 Train Loss 1.0264165 Test MSE 5.676623852937296 Test RE 1.138814843450646\n",
      "77 Train Loss 1.0217867 Test MSE 5.679225886387882 Test RE 1.139075816777546\n",
      "78 Train Loss 1.0165471 Test MSE 5.695040920272148 Test RE 1.1406607157669872\n",
      "79 Train Loss 1.0137625 Test MSE 5.699617332897308 Test RE 1.1411189289649208\n",
      "80 Train Loss 1.0094738 Test MSE 5.70773321533943 Test RE 1.141931079329863\n",
      "81 Train Loss 1.0033075 Test MSE 5.725691813124941 Test RE 1.143726133032818\n",
      "82 Train Loss 0.99842405 Test MSE 5.731393800239191 Test RE 1.144295486838914\n",
      "83 Train Loss 0.9913284 Test MSE 5.739955354802497 Test RE 1.1451498420489097\n",
      "84 Train Loss 0.98299766 Test MSE 5.768522377087031 Test RE 1.147995937293469\n",
      "85 Train Loss 0.97188985 Test MSE 5.8016323358477395 Test RE 1.1512858362814267\n",
      "86 Train Loss 0.9662889 Test MSE 5.823401292285036 Test RE 1.1534437484009368\n",
      "87 Train Loss 0.9609558 Test MSE 5.827048190546298 Test RE 1.1538048632733175\n",
      "88 Train Loss 0.95341164 Test MSE 5.83078894944954 Test RE 1.154175154817098\n",
      "89 Train Loss 0.9499382 Test MSE 5.835400906466239 Test RE 1.154631521364272\n",
      "90 Train Loss 0.94642913 Test MSE 5.830493672183774 Test RE 1.154145930127126\n",
      "91 Train Loss 0.94159216 Test MSE 5.835347701239238 Test RE 1.1546262575809252\n",
      "92 Train Loss 0.9359526 Test MSE 5.8405720312843945 Test RE 1.1551430047766549\n",
      "93 Train Loss 0.93106484 Test MSE 5.842628344913268 Test RE 1.1553463347976312\n",
      "94 Train Loss 0.92157197 Test MSE 5.867373218570972 Test RE 1.1577903284244317\n",
      "95 Train Loss 0.9148931 Test MSE 5.8819525501543755 Test RE 1.1592278828192475\n",
      "96 Train Loss 0.90694827 Test MSE 5.896176389166301 Test RE 1.1606286689000984\n",
      "97 Train Loss 0.9000165 Test MSE 5.923675905391024 Test RE 1.1633320818217894\n",
      "98 Train Loss 0.8927207 Test MSE 5.924670585740414 Test RE 1.1634297487948326\n",
      "99 Train Loss 0.8874219 Test MSE 5.935638011134359 Test RE 1.1645060895948578\n",
      "Training time: 123.50\n",
      "4\n",
      "KG_rowdy_tune38\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.16\n",
      "0\n",
      "KG_rowdy_tune39\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 72.44354 Test MSE 4.4765340071974125 Test RE 1.0112976645927878\n",
      "1 Train Loss 51.396996 Test MSE 4.999692171498288 Test RE 1.0687587742774\n",
      "2 Train Loss 37.003525 Test MSE 6.981846521074078 Test RE 1.2629705073685698\n",
      "3 Train Loss 27.407246 Test MSE 5.473765448395741 Test RE 1.1182815306601783\n",
      "4 Train Loss 22.109896 Test MSE 4.880547663309576 Test RE 1.0559475320533678\n",
      "5 Train Loss 18.500673 Test MSE 5.409908912711962 Test RE 1.1117395009018607\n",
      "6 Train Loss 15.931853 Test MSE 5.022150126830651 Test RE 1.0711564462492693\n",
      "7 Train Loss 13.899345 Test MSE 5.143063283444 Test RE 1.083974321854494\n",
      "8 Train Loss 12.592175 Test MSE 5.21846988263486 Test RE 1.0918919168302201\n",
      "9 Train Loss 11.595191 Test MSE 5.216440061627372 Test RE 1.0916795403324493\n",
      "10 Train Loss 10.282303 Test MSE 5.472222310432292 Test RE 1.1181238892394905\n",
      "11 Train Loss 8.607815 Test MSE 5.156712528940742 Test RE 1.0854117558672114\n",
      "12 Train Loss 7.686182 Test MSE 4.911168497006581 Test RE 1.0592548899717\n",
      "13 Train Loss 6.0056295 Test MSE 4.45894166566853 Test RE 1.0093085578843068\n",
      "14 Train Loss 5.206423 Test MSE 4.297157551082921 Test RE 0.9908289761487153\n",
      "15 Train Loss 4.4857807 Test MSE 4.357153737779922 Test RE 0.9977218933738339\n",
      "16 Train Loss 4.068714 Test MSE 4.3798236591537485 Test RE 1.0003140595277948\n",
      "17 Train Loss 3.7636032 Test MSE 4.429766670544481 Test RE 1.0060011701501954\n",
      "18 Train Loss 3.5117073 Test MSE 4.497907576658885 Test RE 1.013709050451923\n",
      "19 Train Loss 3.333448 Test MSE 4.435195828588844 Test RE 1.0066174629809859\n",
      "20 Train Loss 3.17796 Test MSE 4.394469922656115 Test RE 1.0019852039212236\n",
      "21 Train Loss 3.032633 Test MSE 4.378974603175824 Test RE 1.0002170962863786\n",
      "22 Train Loss 2.92292 Test MSE 4.38194403540292 Test RE 1.0005561680793063\n",
      "23 Train Loss 2.7997746 Test MSE 4.265834222474944 Test RE 0.9872111396814137\n",
      "24 Train Loss 2.6540544 Test MSE 4.185441446306149 Test RE 0.9778645351569053\n",
      "25 Train Loss 2.4760606 Test MSE 4.182617405503656 Test RE 0.9775345824672579\n",
      "26 Train Loss 2.2769334 Test MSE 4.064800309269272 Test RE 0.9636685101541285\n",
      "27 Train Loss 2.071228 Test MSE 3.907875633110256 Test RE 0.9448838526127259\n",
      "28 Train Loss 1.906651 Test MSE 3.8061257860640882 Test RE 0.9325016924894327\n",
      "29 Train Loss 1.7401879 Test MSE 3.6455816473166966 Test RE 0.9126231370138316\n",
      "30 Train Loss 1.6453791 Test MSE 3.524537791359785 Test RE 0.8973443776685909\n",
      "31 Train Loss 1.5427656 Test MSE 3.4647819692570563 Test RE 0.8897049679748811\n",
      "32 Train Loss 1.4244426 Test MSE 3.4588979608231774 Test RE 0.8889491836214544\n",
      "33 Train Loss 1.3190131 Test MSE 3.304030327494178 Test RE 0.8688205263276745\n",
      "34 Train Loss 1.2595831 Test MSE 3.173700623439192 Test RE 0.85151252191424\n",
      "35 Train Loss 1.1854576 Test MSE 3.0950635741248442 Test RE 0.840897085637808\n",
      "36 Train Loss 1.1334387 Test MSE 3.0548938582477407 Test RE 0.8354224139041114\n",
      "37 Train Loss 1.0524832 Test MSE 3.0090364877588116 Test RE 0.8291283925323213\n",
      "38 Train Loss 1.0220265 Test MSE 2.9696955116600874 Test RE 0.8236904326294854\n",
      "39 Train Loss 0.97410244 Test MSE 2.998970631508795 Test RE 0.8277404268779988\n",
      "40 Train Loss 0.936353 Test MSE 3.020972053031546 Test RE 0.8307711645766006\n",
      "41 Train Loss 0.90667254 Test MSE 2.989207330165311 Test RE 0.8263919529580119\n",
      "42 Train Loss 0.8657762 Test MSE 3.0034707244559415 Test RE 0.828361225314005\n",
      "43 Train Loss 0.8294933 Test MSE 3.040246430182426 Test RE 0.8334171898908728\n",
      "44 Train Loss 0.8005085 Test MSE 3.052839212871257 Test RE 0.8351414245154242\n",
      "45 Train Loss 0.7729748 Test MSE 3.034474141620242 Test RE 0.8326256405486954\n",
      "46 Train Loss 0.746543 Test MSE 3.017073868977479 Test RE 0.8302349887625228\n",
      "47 Train Loss 0.728417 Test MSE 3.028669375166189 Test RE 0.8318288779501777\n",
      "48 Train Loss 0.70829123 Test MSE 3.0304615781675928 Test RE 0.8320749572588855\n",
      "49 Train Loss 0.6867994 Test MSE 3.041244689394154 Test RE 0.8335540041465075\n",
      "50 Train Loss 0.66595215 Test MSE 3.0786159389923715 Test RE 0.8386597822996852\n",
      "51 Train Loss 0.6418464 Test MSE 3.080211098281674 Test RE 0.8388770264642256\n",
      "52 Train Loss 0.6310152 Test MSE 3.072719113618537 Test RE 0.8378562067985257\n",
      "53 Train Loss 0.6233126 Test MSE 3.0841116665848847 Test RE 0.839408006614742\n",
      "54 Train Loss 0.61417234 Test MSE 3.0930010239687507 Test RE 0.8406168520626713\n",
      "55 Train Loss 0.60237706 Test MSE 3.080732849284461 Test RE 0.838948071334646\n",
      "56 Train Loss 0.59121835 Test MSE 3.079155321181111 Test RE 0.8387332468607214\n",
      "57 Train Loss 0.5812665 Test MSE 3.1071405425030814 Test RE 0.8425360826806322\n",
      "58 Train Loss 0.5719858 Test MSE 3.104826904872847 Test RE 0.8422223398405093\n",
      "59 Train Loss 0.56050265 Test MSE 3.1102041051746205 Test RE 0.8429513400740801\n",
      "60 Train Loss 0.5503015 Test MSE 3.1228825288493893 Test RE 0.8446676944670958\n",
      "61 Train Loss 0.5406427 Test MSE 3.1232981501901933 Test RE 0.8447239005902242\n",
      "62 Train Loss 0.5305651 Test MSE 3.1329107633691224 Test RE 0.846022810515886\n",
      "63 Train Loss 0.5221845 Test MSE 3.1550236724154135 Test RE 0.8490032863926151\n",
      "64 Train Loss 0.5129099 Test MSE 3.1477072770827594 Test RE 0.8480183097873998\n",
      "65 Train Loss 0.5031762 Test MSE 3.1172891792108866 Test RE 0.843910919419989\n",
      "66 Train Loss 0.49703604 Test MSE 3.121220740976618 Test RE 0.844442926916433\n",
      "67 Train Loss 0.49097115 Test MSE 3.1176020722416165 Test RE 0.8439532714772412\n",
      "68 Train Loss 0.48519433 Test MSE 3.1143330175523736 Test RE 0.843510679229329\n",
      "69 Train Loss 0.479775 Test MSE 3.1303296970195884 Test RE 0.8456742383558798\n",
      "70 Train Loss 0.4735517 Test MSE 3.1587126258529863 Test RE 0.8494994821367385\n",
      "71 Train Loss 0.46852937 Test MSE 3.1443785458111653 Test RE 0.847569797345759\n",
      "72 Train Loss 0.46462187 Test MSE 3.1628337896211938 Test RE 0.8500534713300341\n",
      "73 Train Loss 0.45814377 Test MSE 3.204670523118681 Test RE 0.8556570897051565\n",
      "74 Train Loss 0.45363763 Test MSE 3.1971522008924915 Test RE 0.8546527925081542\n",
      "75 Train Loss 0.44887644 Test MSE 3.2135872327008106 Test RE 0.856846657538161\n",
      "76 Train Loss 0.44636154 Test MSE 3.2118900213533466 Test RE 0.856620361840228\n",
      "77 Train Loss 0.44196677 Test MSE 3.202795543292098 Test RE 0.8554067403315709\n",
      "78 Train Loss 0.4375295 Test MSE 3.221355765567192 Test RE 0.8578817038850995\n",
      "79 Train Loss 0.43151754 Test MSE 3.2198736554680916 Test RE 0.8576843302462863\n",
      "80 Train Loss 0.42470556 Test MSE 3.2146630216457077 Test RE 0.8569900656616887\n",
      "81 Train Loss 0.42029944 Test MSE 3.223412217599306 Test RE 0.858155487849795\n",
      "82 Train Loss 0.41775462 Test MSE 3.2233666876617875 Test RE 0.8581494272064341\n",
      "83 Train Loss 0.41363907 Test MSE 3.2388011528561966 Test RE 0.8602015145462517\n",
      "84 Train Loss 0.40790427 Test MSE 3.244937442941397 Test RE 0.8610160054616013\n",
      "85 Train Loss 0.40459543 Test MSE 3.2432656598342335 Test RE 0.8607941803133667\n",
      "86 Train Loss 0.39999488 Test MSE 3.2449333547410144 Test RE 0.8610154630771741\n",
      "87 Train Loss 0.39502883 Test MSE 3.2588810557919574 Test RE 0.8628639308040502\n",
      "88 Train Loss 0.39116868 Test MSE 3.283475255295589 Test RE 0.8661137516843559\n",
      "89 Train Loss 0.3887034 Test MSE 3.274685919026959 Test RE 0.8649537511282811\n",
      "90 Train Loss 0.38523617 Test MSE 3.276964566826337 Test RE 0.8652546322309089\n",
      "91 Train Loss 0.38055503 Test MSE 3.291060774953126 Test RE 0.8671136271636433\n",
      "92 Train Loss 0.37729025 Test MSE 3.28641745578789 Test RE 0.8665017110123905\n",
      "93 Train Loss 0.3745289 Test MSE 3.296153083004143 Test RE 0.8677842168673706\n",
      "94 Train Loss 0.37228146 Test MSE 3.298295344367263 Test RE 0.8680661695851842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.36971855 Test MSE 3.283726362269702 Test RE 0.8661468694983387\n",
      "96 Train Loss 0.36627534 Test MSE 3.279854857400047 Test RE 0.8656361264557224\n",
      "97 Train Loss 0.36397284 Test MSE 3.293566208258666 Test RE 0.8674436244191329\n",
      "98 Train Loss 0.36172915 Test MSE 3.2925610287694673 Test RE 0.8673112446487028\n",
      "99 Train Loss 0.35793722 Test MSE 3.292386622947286 Test RE 0.8672882737557499\n",
      "Training time: 122.12\n",
      "1\n",
      "KG_rowdy_tune39\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.059425 Test MSE 7.479277878276955 Test RE 1.3071875254980987\n",
      "1 Train Loss 47.92379 Test MSE 6.97420009567199 Test RE 1.2622787236619761\n",
      "2 Train Loss 38.31446 Test MSE 6.24074350940377 Test RE 1.1940602118472745\n",
      "3 Train Loss 31.226864 Test MSE 7.100119032682002 Test RE 1.273622946778528\n",
      "4 Train Loss 25.497334 Test MSE 7.257151284290983 Test RE 1.2876301837558541\n",
      "5 Train Loss 22.207531 Test MSE 6.718455434819384 Test RE 1.2389186215257761\n",
      "6 Train Loss 19.083445 Test MSE 6.397671392805748 Test RE 1.208979745400199\n",
      "7 Train Loss 16.018757 Test MSE 6.329444389093302 Test RE 1.202515974961125\n",
      "8 Train Loss 15.146877 Test MSE 5.9731975663384045 Test RE 1.168184662718059\n",
      "9 Train Loss 14.421283 Test MSE 5.852249025906081 Test RE 1.1562971608601136\n",
      "10 Train Loss 14.000126 Test MSE 5.846541881215814 Test RE 1.155733209732895\n",
      "11 Train Loss 13.706158 Test MSE 5.981841908035783 Test RE 1.1690296487096183\n",
      "12 Train Loss 13.449598 Test MSE 5.997803989893705 Test RE 1.170588342129261\n",
      "13 Train Loss 13.274077 Test MSE 5.935528717286504 Test RE 1.1644953684274768\n",
      "14 Train Loss 13.148615 Test MSE 5.927608526986425 Test RE 1.1637181753460426\n",
      "15 Train Loss 12.976698 Test MSE 5.929623616098567 Test RE 1.1639159613969212\n",
      "16 Train Loss 12.712664 Test MSE 5.826327382262307 Test RE 1.1537334979956078\n",
      "17 Train Loss 12.419298 Test MSE 5.866961803918001 Test RE 1.1577497361322158\n",
      "18 Train Loss 12.09033 Test MSE 5.8900808327972936 Test RE 1.1600285760237485\n",
      "19 Train Loss 11.791438 Test MSE 6.042928198574335 Test RE 1.1749835252624936\n",
      "20 Train Loss 11.334174 Test MSE 6.003773568826314 Test RE 1.17117073708779\n",
      "21 Train Loss 9.597572 Test MSE 4.926252410208342 Test RE 1.0608803136719855\n",
      "22 Train Loss 8.576853 Test MSE 4.951294878528702 Test RE 1.0635733734009194\n",
      "23 Train Loss 8.192109 Test MSE 4.8898329049257665 Test RE 1.0569515248122126\n",
      "24 Train Loss 7.8787775 Test MSE 4.791671457929652 Test RE 1.0462888007017135\n",
      "25 Train Loss 7.5496445 Test MSE 4.732924958624963 Test RE 1.0398552040665119\n",
      "26 Train Loss 7.3057985 Test MSE 4.688914096393115 Test RE 1.03500917200198\n",
      "27 Train Loss 7.1467667 Test MSE 4.763134577484289 Test RE 1.0431685527636723\n",
      "28 Train Loss 6.907215 Test MSE 4.91778510484718 Test RE 1.0599681942679522\n",
      "29 Train Loss 6.654743 Test MSE 4.957069604754294 Test RE 1.0641934188060438\n",
      "30 Train Loss 6.3415413 Test MSE 5.071124753580502 Test RE 1.0763665866287409\n",
      "31 Train Loss 6.153741 Test MSE 5.169276260497286 Test RE 1.0867331913575713\n",
      "32 Train Loss 6.0452704 Test MSE 5.111495978265798 Test RE 1.0806425704757496\n",
      "33 Train Loss 5.9378147 Test MSE 5.11643462325966 Test RE 1.0811644941510108\n",
      "34 Train Loss 5.709009 Test MSE 5.079983560370872 Test RE 1.0773063350456276\n",
      "35 Train Loss 5.504879 Test MSE 4.921777563249297 Test RE 1.0603983696699364\n",
      "36 Train Loss 5.110537 Test MSE 4.834196052235322 Test RE 1.05092128932135\n",
      "37 Train Loss 4.7187715 Test MSE 4.606080049282182 Test RE 1.0258262331099608\n",
      "38 Train Loss 4.052319 Test MSE 3.67273633918426 Test RE 0.9160157400854932\n",
      "39 Train Loss 3.5610335 Test MSE 3.513270757690461 Test RE 0.895908940890009\n",
      "40 Train Loss 3.2711842 Test MSE 3.5610279857602958 Test RE 0.9019776028951102\n",
      "41 Train Loss 3.0465865 Test MSE 3.631756180504846 Test RE 0.9108909818441976\n",
      "42 Train Loss 2.9152691 Test MSE 3.7528241419281736 Test RE 0.9259492135613627\n",
      "43 Train Loss 2.836341 Test MSE 3.7451082598716514 Test RE 0.9249968386633489\n",
      "44 Train Loss 2.7243025 Test MSE 3.7329764785076907 Test RE 0.9234974211151298\n",
      "45 Train Loss 2.6046999 Test MSE 3.671065231934846 Test RE 0.9158073212708332\n",
      "46 Train Loss 2.4265459 Test MSE 3.4308671197474427 Test RE 0.8853398428853537\n",
      "47 Train Loss 2.2559736 Test MSE 3.2581816345680346 Test RE 0.8627713318842379\n",
      "48 Train Loss 2.175468 Test MSE 3.211996709733021 Test RE 0.8566345887718593\n",
      "49 Train Loss 2.0723283 Test MSE 3.1238106029103965 Test RE 0.8447931964571512\n",
      "50 Train Loss 1.9585621 Test MSE 3.0819586156093792 Test RE 0.8391149556563452\n",
      "51 Train Loss 1.8357913 Test MSE 3.0077238166598788 Test RE 0.8289475220764014\n",
      "52 Train Loss 1.7535347 Test MSE 2.905130799225613 Test RE 0.8146872237729272\n",
      "53 Train Loss 1.684732 Test MSE 2.8403039628430036 Test RE 0.80554623125861\n",
      "54 Train Loss 1.6571583 Test MSE 2.85728390709461 Test RE 0.8079505070789383\n",
      "55 Train Loss 1.6298553 Test MSE 2.8211200315903513 Test RE 0.8028212190358617\n",
      "56 Train Loss 1.5917739 Test MSE 2.7894333737195347 Test RE 0.7982998664218495\n",
      "57 Train Loss 1.5544678 Test MSE 2.8009066417437567 Test RE 0.7999399323961424\n",
      "58 Train Loss 1.5331597 Test MSE 2.8541265796874424 Test RE 0.807503986981091\n",
      "59 Train Loss 1.5166365 Test MSE 2.87543633510134 Test RE 0.8105129131548043\n",
      "60 Train Loss 1.4954429 Test MSE 2.895703930648992 Test RE 0.8133643591202188\n",
      "61 Train Loss 1.4733833 Test MSE 2.9101709072625184 Test RE 0.8153936174826897\n",
      "62 Train Loss 1.448436 Test MSE 2.9137416683483526 Test RE 0.8158937055046628\n",
      "63 Train Loss 1.4241847 Test MSE 2.9092756134543865 Test RE 0.8152681827513669\n",
      "64 Train Loss 1.3958229 Test MSE 2.8978374905878947 Test RE 0.8136639481177838\n",
      "65 Train Loss 1.3802314 Test MSE 2.8996146269605623 Test RE 0.8139134048552088\n",
      "66 Train Loss 1.3653736 Test MSE 2.926120027502462 Test RE 0.8176249368423797\n",
      "67 Train Loss 1.3387263 Test MSE 2.986364830454627 Test RE 0.8259989428175075\n",
      "68 Train Loss 1.3228343 Test MSE 3.0074878114396206 Test RE 0.828914999179966\n",
      "69 Train Loss 1.312295 Test MSE 2.997843516997772 Test RE 0.8275848658477446\n",
      "70 Train Loss 1.2951434 Test MSE 3.0132150149741084 Test RE 0.8297038813368888\n",
      "71 Train Loss 1.2816476 Test MSE 3.011576482451042 Test RE 0.8294782615827199\n",
      "72 Train Loss 1.2688338 Test MSE 3.019588193629945 Test RE 0.8305808612308371\n",
      "73 Train Loss 1.2552519 Test MSE 3.0226245908889386 Test RE 0.8309983585192402\n",
      "74 Train Loss 1.2474052 Test MSE 3.0108068228988007 Test RE 0.8293722611763139\n",
      "75 Train Loss 1.2415814 Test MSE 3.0206016550065065 Test RE 0.8307202330509238\n",
      "76 Train Loss 1.231423 Test MSE 3.0385474412930313 Test RE 0.8331842869904427\n",
      "77 Train Loss 1.2176075 Test MSE 3.0078847613193336 Test RE 0.8289697004578045\n",
      "78 Train Loss 1.1943371 Test MSE 3.001100376283768 Test RE 0.8280342882051795\n",
      "79 Train Loss 1.1818465 Test MSE 2.996661674443342 Test RE 0.8274217200027112\n",
      "80 Train Loss 1.1743265 Test MSE 2.9632649035585565 Test RE 0.8227981356061922\n",
      "81 Train Loss 1.1672456 Test MSE 2.9285918563006264 Test RE 0.8179702067240071\n",
      "82 Train Loss 1.1565676 Test MSE 2.919177119108958 Test RE 0.8166543569775923\n",
      "83 Train Loss 1.1484445 Test MSE 2.9384862164622856 Test RE 0.8193508134921297\n",
      "84 Train Loss 1.1382587 Test MSE 2.9295058297565824 Test RE 0.8180978354229378\n",
      "85 Train Loss 1.1236528 Test MSE 2.916416079289608 Test RE 0.8162680582835706\n",
      "86 Train Loss 1.1150934 Test MSE 2.9208577374313047 Test RE 0.8168894038308263\n",
      "87 Train Loss 1.1078018 Test MSE 2.9146875017721925 Test RE 0.8160261189114371\n",
      "88 Train Loss 1.0926614 Test MSE 2.9084635519464888 Test RE 0.8151543925500689\n",
      "89 Train Loss 1.078144 Test MSE 2.8984183305649944 Test RE 0.8137454890721318\n",
      "90 Train Loss 1.0667127 Test MSE 2.8849319137064255 Test RE 0.8118500920678522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Train Loss 1.0584216 Test MSE 2.8671342790782117 Test RE 0.8093419973623106\n",
      "92 Train Loss 1.0496814 Test MSE 2.866368196202873 Test RE 0.8092338642219767\n",
      "93 Train Loss 1.0392318 Test MSE 2.862594785946529 Test RE 0.8087010336888555\n",
      "94 Train Loss 1.0257424 Test MSE 2.8584159782661844 Test RE 0.8081105483850802\n",
      "95 Train Loss 1.0160455 Test MSE 2.8457430637834147 Test RE 0.8063171613669186\n",
      "96 Train Loss 1.0107596 Test MSE 2.834343771232126 Test RE 0.8047005944262879\n",
      "97 Train Loss 1.006808 Test MSE 2.836852496262255 Test RE 0.8050566426284761\n",
      "98 Train Loss 1.0018772 Test MSE 2.8352765652187495 Test RE 0.8048329986419093\n",
      "99 Train Loss 0.99616134 Test MSE 2.850760512643654 Test RE 0.8070276741110376\n",
      "Training time: 123.13\n",
      "2\n",
      "KG_rowdy_tune39\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.52\n",
      "0\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 54.51595 Test MSE 8.375613617083012 Test RE 1.383300001572447\n",
      "1 Train Loss 35.07632 Test MSE 7.226819084570137 Test RE 1.2849364579079803\n",
      "2 Train Loss 21.587902 Test MSE 6.3550344677586965 Test RE 1.2049444217391319\n",
      "3 Train Loss 17.85347 Test MSE 5.843788373013536 Test RE 1.1554610235658527\n",
      "4 Train Loss 15.131159 Test MSE 5.64749042847614 Test RE 1.1358887860844054\n",
      "5 Train Loss 13.274391 Test MSE 5.824477597956283 Test RE 1.1535503356536418\n",
      "6 Train Loss 11.859418 Test MSE 5.8365721196547415 Test RE 1.1547473875951215\n",
      "7 Train Loss 10.818233 Test MSE 5.834640194017828 Test RE 1.1545562590804013\n",
      "8 Train Loss 9.584763 Test MSE 5.876795469119911 Test RE 1.15871958705974\n",
      "9 Train Loss 8.644273 Test MSE 5.694979529992437 Test RE 1.1406545678156301\n",
      "10 Train Loss 7.871982 Test MSE 5.569409092387011 Test RE 1.1280091435764075\n",
      "11 Train Loss 6.938942 Test MSE 5.435584311872947 Test RE 1.114374533043741\n",
      "12 Train Loss 5.8787365 Test MSE 5.189270454075819 Test RE 1.0888328454015452\n",
      "13 Train Loss 5.073557 Test MSE 5.0778024203000935 Test RE 1.0770750342683\n",
      "14 Train Loss 4.0528364 Test MSE 4.760973689150556 Test RE 1.042931899102183\n",
      "15 Train Loss 3.423452 Test MSE 4.341399001305921 Test RE 0.9959164624233628\n",
      "16 Train Loss 2.8767533 Test MSE 3.6677289524117236 Test RE 0.9153910819066077\n",
      "17 Train Loss 2.373192 Test MSE 3.048369072175082 Test RE 0.8345297697572462\n",
      "18 Train Loss 2.0529819 Test MSE 2.7028954257760076 Test RE 0.7858192835275347\n",
      "19 Train Loss 1.7993802 Test MSE 2.3542035288333785 Test RE 0.7333816908863013\n",
      "20 Train Loss 1.5266207 Test MSE 1.8287435738856364 Test RE 0.6463748750142084\n",
      "21 Train Loss 1.3210268 Test MSE 1.4912887784260818 Test RE 0.5836989811358241\n",
      "22 Train Loss 1.0833879 Test MSE 1.2030626863460918 Test RE 0.5242665979438711\n",
      "23 Train Loss 0.66871625 Test MSE 0.42393598745236016 Test RE 0.3112133387147108\n",
      "24 Train Loss 0.44366276 Test MSE 0.28004682806697667 Test RE 0.2529434217565944\n",
      "25 Train Loss 0.2816695 Test MSE 0.21801925471530556 Test RE 0.22318010914286168\n",
      "26 Train Loss 0.21241948 Test MSE 0.1514344784782589 Test RE 0.18600321178240886\n",
      "27 Train Loss 0.16283754 Test MSE 0.09979136216476298 Test RE 0.15099220790651474\n",
      "28 Train Loss 0.12925558 Test MSE 0.06332580113012776 Test RE 0.12028138124144827\n",
      "29 Train Loss 0.10314816 Test MSE 0.03932661698804427 Test RE 0.0947875623197814\n",
      "30 Train Loss 0.077685475 Test MSE 0.022984025172184393 Test RE 0.0724637999839708\n",
      "31 Train Loss 0.064297184 Test MSE 0.022114852674248193 Test RE 0.07108043640543901\n",
      "32 Train Loss 0.05493065 Test MSE 0.02051256215241489 Test RE 0.06845702398866103\n",
      "33 Train Loss 0.046054315 Test MSE 0.0137025960956639 Test RE 0.05595121070715537\n",
      "34 Train Loss 0.038203344 Test MSE 0.011234811691993125 Test RE 0.050663006553184634\n",
      "35 Train Loss 0.032427236 Test MSE 0.011076309450593812 Test RE 0.050304356819092726\n",
      "36 Train Loss 0.027740894 Test MSE 0.011261705902109249 Test RE 0.05072360957585186\n",
      "37 Train Loss 0.024847332 Test MSE 0.009664481974061282 Test RE 0.04698912418921565\n",
      "38 Train Loss 0.021805268 Test MSE 0.007577461130851149 Test RE 0.041607336852020116\n",
      "39 Train Loss 0.018948432 Test MSE 0.006726085038999529 Test RE 0.03920028614700977\n",
      "40 Train Loss 0.01736515 Test MSE 0.006572582501132391 Test RE 0.03875039049990477\n",
      "41 Train Loss 0.015788907 Test MSE 0.0055780185279778165 Test RE 0.035698341230175935\n",
      "42 Train Loss 0.014682703 Test MSE 0.005284611556643696 Test RE 0.03474678246746439\n",
      "43 Train Loss 0.013538612 Test MSE 0.005096975346382557 Test RE 0.03412434521172775\n",
      "44 Train Loss 0.012407513 Test MSE 0.004673505466890656 Test RE 0.03267604141291158\n",
      "45 Train Loss 0.011304473 Test MSE 0.004596721089668122 Test RE 0.032406500633960014\n",
      "46 Train Loss 0.010199902 Test MSE 0.004338732556663509 Test RE 0.031483970776246185\n",
      "47 Train Loss 0.00933633 Test MSE 0.003871516917675738 Test RE 0.02974052570203255\n",
      "48 Train Loss 0.008297993 Test MSE 0.0032542423108683828 Test RE 0.027266726626104028\n",
      "49 Train Loss 0.007884053 Test MSE 0.0035366445045959005 Test RE 0.02842521538566416\n",
      "50 Train Loss 0.007474415 Test MSE 0.0035610661422895156 Test RE 0.028523189048289592\n",
      "51 Train Loss 0.006709934 Test MSE 0.0035547042308172383 Test RE 0.02849769905243258\n",
      "52 Train Loss 0.005838381 Test MSE 0.002703432230895033 Test RE 0.02485225516006324\n",
      "53 Train Loss 0.005177152 Test MSE 0.0025676648789084793 Test RE 0.024220172428957486\n",
      "54 Train Loss 0.004941715 Test MSE 0.0025746654490573315 Test RE 0.024253167311703926\n",
      "55 Train Loss 0.0043981434 Test MSE 0.0019316319072920207 Test RE 0.021007300389113245\n",
      "56 Train Loss 0.0041416567 Test MSE 0.001885010271436974 Test RE 0.02075223710425836\n",
      "57 Train Loss 0.0037714927 Test MSE 0.00183167872504894 Test RE 0.020456565031024238\n",
      "58 Train Loss 0.0035536077 Test MSE 0.0017471592362542968 Test RE 0.019979025651819082\n",
      "59 Train Loss 0.0033643001 Test MSE 0.0017706032265715017 Test RE 0.020112621743085344\n",
      "60 Train Loss 0.0030708732 Test MSE 0.0015907202734980305 Test RE 0.01906360225837265\n",
      "61 Train Loss 0.0028594735 Test MSE 0.0014509566912470732 Test RE 0.018206869740362213\n",
      "62 Train Loss 0.0027114416 Test MSE 0.0014852894199184027 Test RE 0.01842101702844533\n",
      "63 Train Loss 0.0025965609 Test MSE 0.0013693508259853468 Test RE 0.017687458110738526\n",
      "64 Train Loss 0.0024585235 Test MSE 0.001355056868062239 Test RE 0.01759490074044346\n",
      "65 Train Loss 0.0023430034 Test MSE 0.0013179421527174469 Test RE 0.017352267519434302\n",
      "66 Train Loss 0.0022094152 Test MSE 0.0012337241638355463 Test RE 0.016788701045852165\n",
      "67 Train Loss 0.0021520832 Test MSE 0.0012010868615535324 Test RE 0.016565146018226156\n",
      "68 Train Loss 0.0020755022 Test MSE 0.0011279251115981909 Test RE 0.016052703831018547\n",
      "69 Train Loss 0.0019876186 Test MSE 0.0010458101675961012 Test RE 0.015457330404732699\n",
      "70 Train Loss 0.0018954668 Test MSE 0.0008973056120557837 Test RE 0.014317864638620765\n",
      "71 Train Loss 0.0018181223 Test MSE 0.000749945533146123 Test RE 0.013089495906671904\n",
      "72 Train Loss 0.0017326699 Test MSE 0.0007803746090221052 Test RE 0.013352408957874854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 0.0016112047 Test MSE 0.0007341605266573139 Test RE 0.012951008111991897\n",
      "74 Train Loss 0.0015256327 Test MSE 0.0007308876261602036 Test RE 0.012922107956071512\n",
      "75 Train Loss 0.0014831395 Test MSE 0.0007303870061896932 Test RE 0.012917681712422639\n",
      "76 Train Loss 0.0014166472 Test MSE 0.0006800047160493737 Test RE 0.012464188909481208\n",
      "77 Train Loss 0.0013413595 Test MSE 0.0006656867730270357 Test RE 0.012332269990044095\n",
      "78 Train Loss 0.0012873801 Test MSE 0.0006535286284240959 Test RE 0.0122191323484272\n",
      "79 Train Loss 0.001241256 Test MSE 0.0005874154959815175 Test RE 0.011584592450396993\n",
      "80 Train Loss 0.0012198887 Test MSE 0.0005499876980244601 Test RE 0.011209456294063265\n",
      "81 Train Loss 0.0011963018 Test MSE 0.0005297187753418732 Test RE 0.01100096399915744\n",
      "82 Train Loss 0.0011526488 Test MSE 0.0005344088763689046 Test RE 0.011049557641225905\n",
      "83 Train Loss 0.0011291964 Test MSE 0.0005118131329727483 Test RE 0.010813437465863777\n",
      "84 Train Loss 0.0011135484 Test MSE 0.0005078422294662473 Test RE 0.010771407744025309\n",
      "85 Train Loss 0.0010895005 Test MSE 0.0005285079699612104 Test RE 0.010988384072504373\n",
      "86 Train Loss 0.0010456175 Test MSE 0.0005067410464272519 Test RE 0.010759723280147359\n",
      "87 Train Loss 0.0010141269 Test MSE 0.00046730013897226845 Test RE 0.010332514308585566\n",
      "88 Train Loss 0.000995166 Test MSE 0.00047133300980984146 Test RE 0.01037700410656066\n",
      "89 Train Loss 0.0009685085 Test MSE 0.0004578654098278292 Test RE 0.010227676383001696\n",
      "90 Train Loss 0.00095794967 Test MSE 0.00046423957561028304 Test RE 0.010298622531916988\n",
      "91 Train Loss 0.0009330784 Test MSE 0.0004896652257511587 Test RE 0.010576882794247323\n",
      "92 Train Loss 0.0008965458 Test MSE 0.0004876475106083522 Test RE 0.010555068741048805\n",
      "93 Train Loss 0.0008824524 Test MSE 0.0004843410487326225 Test RE 0.01051922390208417\n",
      "94 Train Loss 0.0008693799 Test MSE 0.0004918761330546664 Test RE 0.010600733957786079\n",
      "95 Train Loss 0.0008496081 Test MSE 0.0004894704882084137 Test RE 0.010574779396984767\n",
      "96 Train Loss 0.0008266315 Test MSE 0.000479391287650429 Test RE 0.01046533485357643\n",
      "97 Train Loss 0.0007991565 Test MSE 0.00048261177701814544 Test RE 0.010500428404373723\n",
      "98 Train Loss 0.0007769281 Test MSE 0.00048041825057825685 Test RE 0.010476538395927923\n",
      "99 Train Loss 0.00076053303 Test MSE 0.00046421279059764614 Test RE 0.01029832543023916\n",
      "Training time: 121.60\n",
      "1\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.01237 Test MSE 8.442807717766334 Test RE 1.3888377402863006\n",
      "1 Train Loss 48.04439 Test MSE 9.251518796860424 Test RE 1.453833185905344\n",
      "2 Train Loss 40.642597 Test MSE 9.0923871472989 Test RE 1.4412755523688354\n",
      "3 Train Loss 37.449715 Test MSE 9.137941086071006 Test RE 1.4448815222179172\n",
      "4 Train Loss 34.881336 Test MSE 9.168918607006239 Test RE 1.4473285164773924\n",
      "5 Train Loss 31.85686 Test MSE 8.825452892045783 Test RE 1.4199614722451463\n",
      "6 Train Loss 29.191402 Test MSE 8.635624075475206 Test RE 1.4046073106923278\n",
      "7 Train Loss 27.14547 Test MSE 8.853066539688573 Test RE 1.4221811709499235\n",
      "8 Train Loss 24.224625 Test MSE 8.903228995377289 Test RE 1.4262045977313502\n",
      "9 Train Loss 21.21909 Test MSE 8.83558894455537 Test RE 1.4207766527265175\n",
      "10 Train Loss 19.124115 Test MSE 8.540357625745164 Test RE 1.3968381531355698\n",
      "11 Train Loss 16.43523 Test MSE 8.629814431559634 Test RE 1.404134754153938\n",
      "12 Train Loss 13.921262 Test MSE 8.049326245843117 Test RE 1.356087851342943\n",
      "13 Train Loss 11.358952 Test MSE 7.24866101763148 Test RE 1.286876752930117\n",
      "14 Train Loss 8.078608 Test MSE 5.932326826449192 Test RE 1.1641812354996963\n",
      "15 Train Loss 6.3380594 Test MSE 5.759474386958852 Test RE 1.1470952619143542\n",
      "16 Train Loss 4.8367653 Test MSE 5.291227873002563 Test RE 1.0994773650144725\n",
      "17 Train Loss 3.781597 Test MSE 5.198638534106193 Test RE 1.0898152256698357\n",
      "18 Train Loss 2.9854498 Test MSE 5.1474233104169915 Test RE 1.0844336936137378\n",
      "19 Train Loss 2.3559003 Test MSE 5.246397058979942 Test RE 1.094809704072551\n",
      "20 Train Loss 1.9332465 Test MSE 5.242697075751179 Test RE 1.0944235827072128\n",
      "21 Train Loss 1.7152337 Test MSE 5.395473123450122 Test RE 1.1102552284411937\n",
      "22 Train Loss 1.5359377 Test MSE 5.528981337385447 Test RE 1.1239076370349173\n",
      "23 Train Loss 1.4275874 Test MSE 5.486887909857901 Test RE 1.1196211771941655\n",
      "24 Train Loss 1.3406981 Test MSE 5.498636605654022 Test RE 1.1208192201354488\n",
      "25 Train Loss 1.284224 Test MSE 5.521443671644156 Test RE 1.1231412635482296\n",
      "26 Train Loss 1.2362788 Test MSE 5.576051849467997 Test RE 1.1286816438039406\n",
      "27 Train Loss 1.1898367 Test MSE 5.594674400109809 Test RE 1.1305648231082417\n",
      "28 Train Loss 1.1383283 Test MSE 5.671846161197768 Test RE 1.1383355046994077\n",
      "29 Train Loss 1.1009984 Test MSE 5.737286907521148 Test RE 1.1448836268062985\n",
      "30 Train Loss 1.0676577 Test MSE 5.775776081791174 Test RE 1.1487174918647076\n",
      "31 Train Loss 1.0380626 Test MSE 5.7719744134656485 Test RE 1.1483393814873855\n",
      "32 Train Loss 1.0151912 Test MSE 5.7766615228109055 Test RE 1.1488055391326535\n",
      "33 Train Loss 0.9928155 Test MSE 5.81937047270185 Test RE 1.1530444861629356\n",
      "34 Train Loss 0.96827704 Test MSE 5.86010629688536 Test RE 1.1570731268708025\n",
      "35 Train Loss 0.9432268 Test MSE 5.91475456318081 Test RE 1.16245573457207\n",
      "36 Train Loss 0.9192418 Test MSE 5.967414791060038 Test RE 1.1676190540048745\n",
      "37 Train Loss 0.9051017 Test MSE 6.023298397662226 Test RE 1.1730735692615464\n",
      "38 Train Loss 0.890556 Test MSE 6.037745134892774 Test RE 1.1744795211887358\n",
      "39 Train Loss 0.875787 Test MSE 6.052066499549203 Test RE 1.1758716126656195\n",
      "40 Train Loss 0.8642873 Test MSE 6.083825288518127 Test RE 1.178952824236111\n",
      "41 Train Loss 0.85291636 Test MSE 6.102259508553142 Test RE 1.1807376090242863\n",
      "42 Train Loss 0.84111655 Test MSE 6.109697165676561 Test RE 1.1814569529963075\n",
      "43 Train Loss 0.8313174 Test MSE 6.1263475628466075 Test RE 1.1830657351221332\n",
      "44 Train Loss 0.82229704 Test MSE 6.135078884126349 Test RE 1.183908492494267\n",
      "45 Train Loss 0.81223166 Test MSE 6.122648692569528 Test RE 1.1827085347382778\n",
      "46 Train Loss 0.8005723 Test MSE 6.155034704867885 Test RE 1.1858324029341805\n",
      "47 Train Loss 0.7931349 Test MSE 6.1548674754915496 Test RE 1.1858162935725212\n",
      "48 Train Loss 0.78303385 Test MSE 6.16217499473541 Test RE 1.1865200296724185\n",
      "49 Train Loss 0.7750158 Test MSE 6.164199196280277 Test RE 1.1867148925637219\n",
      "50 Train Loss 0.76743764 Test MSE 6.166971599328624 Test RE 1.1869817303176293\n",
      "51 Train Loss 0.7602045 Test MSE 6.191745467543739 Test RE 1.1893635035421162\n",
      "52 Train Loss 0.75416714 Test MSE 6.210977212149055 Test RE 1.1912091705938377\n",
      "53 Train Loss 0.74770176 Test MSE 6.205101036585655 Test RE 1.1906455386264312\n",
      "54 Train Loss 0.74011576 Test MSE 6.234216894632917 Test RE 1.1934356701072566\n",
      "55 Train Loss 0.7340885 Test MSE 6.260134614231061 Test RE 1.195913852248811\n",
      "56 Train Loss 0.7284917 Test MSE 6.2670755282980775 Test RE 1.1965766523489176\n",
      "57 Train Loss 0.72323585 Test MSE 6.280901236882156 Test RE 1.197895800806757\n",
      "58 Train Loss 0.7170664 Test MSE 6.3128017326128365 Test RE 1.2009339851391134\n",
      "59 Train Loss 0.71186733 Test MSE 6.334198042804461 Test RE 1.2029674578465506\n",
      "60 Train Loss 0.7066293 Test MSE 6.349761178987602 Test RE 1.2044443978147874\n",
      "61 Train Loss 0.7021658 Test MSE 6.381021361030035 Test RE 1.2074055269172448\n",
      "62 Train Loss 0.6973837 Test MSE 6.385184346409605 Test RE 1.2077993190493836\n",
      "63 Train Loss 0.6914839 Test MSE 6.385002024628465 Test RE 1.2077820752484898\n",
      "64 Train Loss 0.68571204 Test MSE 6.382722296863543 Test RE 1.2075664402230963\n",
      "65 Train Loss 0.6800277 Test MSE 6.376329791274039 Test RE 1.2069615800529356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.67547476 Test MSE 6.384701174339957 Test RE 1.2077536206086372\n",
      "67 Train Loss 0.6710421 Test MSE 6.391359611126195 Test RE 1.2083832237315204\n",
      "68 Train Loss 0.6662369 Test MSE 6.396419268906744 Test RE 1.2088614315313615\n",
      "69 Train Loss 0.66235924 Test MSE 6.414754455356162 Test RE 1.2105927782335801\n",
      "70 Train Loss 0.6597462 Test MSE 6.418705956206869 Test RE 1.2109655845481084\n",
      "71 Train Loss 0.6565743 Test MSE 6.421061596560906 Test RE 1.2111877740160897\n",
      "72 Train Loss 0.65387636 Test MSE 6.435373046119872 Test RE 1.2125367880905642\n",
      "73 Train Loss 0.65002096 Test MSE 6.454688256127357 Test RE 1.2143550863684012\n",
      "74 Train Loss 0.6466772 Test MSE 6.47909500707974 Test RE 1.216648806550351\n",
      "75 Train Loss 0.6433561 Test MSE 6.494848790610098 Test RE 1.218127036544017\n",
      "76 Train Loss 0.6398027 Test MSE 6.514047764431067 Test RE 1.2199261185795058\n",
      "77 Train Loss 0.6367675 Test MSE 6.52872379560682 Test RE 1.221299581100535\n",
      "78 Train Loss 0.6336888 Test MSE 6.540789244215904 Test RE 1.2224275753346294\n",
      "79 Train Loss 0.6303854 Test MSE 6.544801513858724 Test RE 1.222802450363728\n",
      "80 Train Loss 0.62751156 Test MSE 6.5664821373491495 Test RE 1.224826132843793\n",
      "81 Train Loss 0.62376434 Test MSE 6.583874013914602 Test RE 1.2264470874182085\n",
      "82 Train Loss 0.6198479 Test MSE 6.588969123216085 Test RE 1.2269215552961317\n",
      "83 Train Loss 0.6157215 Test MSE 6.603887480331832 Test RE 1.228309731865971\n",
      "84 Train Loss 0.61175203 Test MSE 6.6110121278120095 Test RE 1.22897213827372\n",
      "85 Train Loss 0.6081204 Test MSE 6.6214064343939025 Test RE 1.2299378978056912\n",
      "86 Train Loss 0.60423505 Test MSE 6.633224195552814 Test RE 1.2310349934713307\n",
      "87 Train Loss 0.6002433 Test MSE 6.635229621749864 Test RE 1.231221069140282\n",
      "88 Train Loss 0.59653753 Test MSE 6.647167315383913 Test RE 1.2323281397159422\n",
      "89 Train Loss 0.5932399 Test MSE 6.650748378211373 Test RE 1.2326600442759972\n",
      "90 Train Loss 0.5907946 Test MSE 6.6559859535570745 Test RE 1.2331453189330186\n",
      "91 Train Loss 0.5877241 Test MSE 6.673903390013475 Test RE 1.2348039727839841\n",
      "92 Train Loss 0.584129 Test MSE 6.700271344241841 Test RE 1.237240864396159\n",
      "93 Train Loss 0.57985425 Test MSE 6.702290010788566 Test RE 1.2374272291361021\n",
      "94 Train Loss 0.5755444 Test MSE 6.739626485798902 Test RE 1.240869112886034\n",
      "95 Train Loss 0.572543 Test MSE 6.738479622656344 Test RE 1.2407635308037046\n",
      "96 Train Loss 0.56985766 Test MSE 6.758317995744418 Test RE 1.2425886190379645\n",
      "97 Train Loss 0.5676352 Test MSE 6.776077223892051 Test RE 1.2442201593745836\n",
      "98 Train Loss 0.5653385 Test MSE 6.793581336074238 Test RE 1.2458261713553078\n",
      "99 Train Loss 0.5626838 Test MSE 6.825321888722554 Test RE 1.2487331160854245\n",
      "Training time: 121.56\n",
      "2\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.194942 Test MSE 8.454824424215166 Test RE 1.3898257600142805\n",
      "1 Train Loss 38.36975 Test MSE 7.361205123472656 Test RE 1.2968284218832657\n",
      "2 Train Loss 28.45486 Test MSE 6.777349795289616 Test RE 1.2443369883747295\n",
      "3 Train Loss 22.222837 Test MSE 5.853818337890146 Test RE 1.156452184112873\n",
      "4 Train Loss 18.071815 Test MSE 5.969231249936545 Test RE 1.1677967499329183\n",
      "5 Train Loss 15.999038 Test MSE 6.014137701351215 Test RE 1.172181179492695\n",
      "6 Train Loss 13.325993 Test MSE 5.928161249175368 Test RE 1.163772429760854\n",
      "7 Train Loss 11.142715 Test MSE 5.919057836363248 Test RE 1.1628785293811825\n",
      "8 Train Loss 9.891374 Test MSE 5.968356700123187 Test RE 1.1677112000691998\n",
      "9 Train Loss 8.711251 Test MSE 5.747410612674755 Test RE 1.145893281368613\n",
      "10 Train Loss 7.8097897 Test MSE 5.759910066998179 Test RE 1.1471386475624439\n",
      "11 Train Loss 7.09182 Test MSE 5.558096194192358 Test RE 1.1268629232840353\n",
      "12 Train Loss 6.274191 Test MSE 5.454036096875121 Test RE 1.1162643738980034\n",
      "13 Train Loss 5.3552284 Test MSE 5.250304508109509 Test RE 1.0952173282896962\n",
      "14 Train Loss 4.6208844 Test MSE 5.203794711392913 Test RE 1.090355548662204\n",
      "15 Train Loss 3.8165364 Test MSE 4.752947789871938 Test RE 1.0420524574619845\n",
      "16 Train Loss 3.1925454 Test MSE 4.523999425399195 Test RE 1.0166450041056843\n",
      "17 Train Loss 2.711691 Test MSE 4.112737047082789 Test RE 0.9693341913799176\n",
      "18 Train Loss 2.3175805 Test MSE 3.253681519671607 Test RE 0.8621753074584966\n",
      "19 Train Loss 2.0006723 Test MSE 2.73343410794803 Test RE 0.7902461067595565\n",
      "20 Train Loss 1.7392365 Test MSE 2.179605603304244 Test RE 0.7056624661564076\n",
      "21 Train Loss 1.5465957 Test MSE 1.9398124679363824 Test RE 0.6657143727758302\n",
      "22 Train Loss 1.4182237 Test MSE 1.7335639837712322 Test RE 0.6293293669248736\n",
      "23 Train Loss 1.3045915 Test MSE 1.5594932859955015 Test RE 0.5968975756283477\n",
      "24 Train Loss 1.2032145 Test MSE 1.27295639766706 Test RE 0.5392806335353209\n",
      "25 Train Loss 0.71557903 Test MSE 0.6507244243342076 Test RE 0.38557299971291714\n",
      "26 Train Loss 0.47471577 Test MSE 0.5886328056519579 Test RE 0.36671636535349755\n",
      "27 Train Loss 0.3442734 Test MSE 0.5930565486372168 Test RE 0.36809177494537265\n",
      "28 Train Loss 0.26250198 Test MSE 0.5070797730776201 Test RE 0.3403660259423195\n",
      "29 Train Loss 0.22558331 Test MSE 0.5283748358407593 Test RE 0.34743944549681083\n",
      "30 Train Loss 0.19265729 Test MSE 0.5031490327238296 Test RE 0.3390442484030792\n",
      "31 Train Loss 0.17567551 Test MSE 0.49228999259826295 Test RE 0.3353656393998351\n",
      "32 Train Loss 0.16307692 Test MSE 0.4736389793559189 Test RE 0.3289514299185806\n",
      "33 Train Loss 0.1523641 Test MSE 0.4648883466428555 Test RE 0.3258985214986742\n",
      "34 Train Loss 0.14207678 Test MSE 0.454026201681496 Test RE 0.32206869871096266\n",
      "35 Train Loss 0.13580002 Test MSE 0.4359209645551405 Test RE 0.31558179219338683\n",
      "36 Train Loss 0.13134815 Test MSE 0.4374563838746599 Test RE 0.3161370814473875\n",
      "37 Train Loss 0.12523885 Test MSE 0.4324021919606159 Test RE 0.3143055166025008\n",
      "38 Train Loss 0.1198846 Test MSE 0.4332635611128651 Test RE 0.31461841786284817\n",
      "39 Train Loss 0.115764044 Test MSE 0.43892272551347267 Test RE 0.31666647954129157\n",
      "40 Train Loss 0.112926856 Test MSE 0.4383444556831316 Test RE 0.31645781066395334\n",
      "41 Train Loss 0.1104678 Test MSE 0.43590127894547426 Test RE 0.3155746664864103\n",
      "42 Train Loss 0.10812505 Test MSE 0.4291869381586093 Test RE 0.31313478060188765\n",
      "43 Train Loss 0.10588677 Test MSE 0.4341448640532812 Test RE 0.31493823852605807\n",
      "44 Train Loss 0.10371629 Test MSE 0.44014939547962545 Test RE 0.3171086692662421\n",
      "45 Train Loss 0.10104427 Test MSE 0.4472226799680846 Test RE 0.3196465123076256\n",
      "46 Train Loss 0.09882017 Test MSE 0.4521824539157572 Test RE 0.32141409164145884\n",
      "47 Train Loss 0.0975424 Test MSE 0.4489366743135087 Test RE 0.3202584539738063\n",
      "48 Train Loss 0.09649412 Test MSE 0.4579920236932531 Test RE 0.32347224115104783\n",
      "49 Train Loss 0.09561389 Test MSE 0.46244247997487237 Test RE 0.3250400836249421\n",
      "50 Train Loss 0.094000995 Test MSE 0.4676810022824577 Test RE 0.3268759170705253\n",
      "51 Train Loss 0.092887215 Test MSE 0.47134669707891114 Test RE 0.3281544472712445\n",
      "52 Train Loss 0.091507286 Test MSE 0.4741571489057409 Test RE 0.32913132011735025\n",
      "53 Train Loss 0.09034355 Test MSE 0.4742845066220334 Test RE 0.3291755191756484\n",
      "54 Train Loss 0.08905475 Test MSE 0.48347813105422205 Test RE 0.33235060798694543\n",
      "55 Train Loss 0.08822386 Test MSE 0.48285033725604454 Test RE 0.3321347601407998\n",
      "56 Train Loss 0.08782125 Test MSE 0.48529441868665363 Test RE 0.33297429538176443\n",
      "57 Train Loss 0.08699 Test MSE 0.4817557402683232 Test RE 0.3317580802949118\n",
      "58 Train Loss 0.08610292 Test MSE 0.48669052676665064 Test RE 0.3334529061282521\n",
      "59 Train Loss 0.08488789 Test MSE 0.4956590469396149 Test RE 0.3365112431802173\n",
      "60 Train Loss 0.0843218 Test MSE 0.4989835380343161 Test RE 0.33763788357434316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 0.08344888 Test MSE 0.5084432401113006 Test RE 0.34082331721962106\n",
      "62 Train Loss 0.08248242 Test MSE 0.5079309217058593 Test RE 0.3406515634701083\n",
      "63 Train Loss 0.081727356 Test MSE 0.5057473899054131 Test RE 0.3399185655229837\n",
      "64 Train Loss 0.081088714 Test MSE 0.5094240992854864 Test RE 0.3411519070980559\n",
      "65 Train Loss 0.08052044 Test MSE 0.5074946275075594 Test RE 0.3405052283841115\n",
      "66 Train Loss 0.08001567 Test MSE 0.5059905659872864 Test RE 0.3400002764054296\n",
      "67 Train Loss 0.07952097 Test MSE 0.5068517634032724 Test RE 0.340289494125401\n",
      "68 Train Loss 0.078846954 Test MSE 0.508955129039253 Test RE 0.3409948405867349\n",
      "69 Train Loss 0.07844168 Test MSE 0.5093035606389837 Test RE 0.3411115434579924\n",
      "70 Train Loss 0.07802488 Test MSE 0.510734730231531 Test RE 0.341590477858434\n",
      "71 Train Loss 0.07747692 Test MSE 0.5076749160306455 Test RE 0.3405657056091013\n",
      "72 Train Loss 0.07685494 Test MSE 0.5160421861968795 Test RE 0.3433607615329505\n",
      "73 Train Loss 0.07615582 Test MSE 0.5190042757643768 Test RE 0.34434479930948647\n",
      "74 Train Loss 0.075496234 Test MSE 0.5167681708079465 Test RE 0.3436022020830866\n",
      "75 Train Loss 0.07518426 Test MSE 0.5178508933861607 Test RE 0.3439619680494002\n",
      "76 Train Loss 0.07468715 Test MSE 0.5186126624826496 Test RE 0.34421486257247036\n",
      "77 Train Loss 0.0742277 Test MSE 0.5196936468813919 Test RE 0.3445734126335547\n",
      "78 Train Loss 0.07400474 Test MSE 0.5199602168719493 Test RE 0.34466177349406946\n",
      "79 Train Loss 0.07352916 Test MSE 0.5253330088942673 Test RE 0.3464379063916421\n",
      "80 Train Loss 0.07301412 Test MSE 0.5238247361696023 Test RE 0.34594022356318227\n",
      "81 Train Loss 0.072400175 Test MSE 0.5260890755287263 Test RE 0.3466871159043468\n",
      "82 Train Loss 0.071954586 Test MSE 0.5259064758846315 Test RE 0.346626945069231\n",
      "83 Train Loss 0.07136398 Test MSE 0.5239217264144934 Test RE 0.3459722488492045\n",
      "84 Train Loss 0.07053985 Test MSE 0.535316524251797 Test RE 0.3497142950211501\n",
      "85 Train Loss 0.06998524 Test MSE 0.5335209186522737 Test RE 0.34912728118610603\n",
      "86 Train Loss 0.06927795 Test MSE 0.5358007119273474 Test RE 0.34987241556533866\n",
      "87 Train Loss 0.068752445 Test MSE 0.5395299194175207 Test RE 0.35108787160120375\n",
      "88 Train Loss 0.068142325 Test MSE 0.5453986698412148 Test RE 0.3529921906652443\n",
      "89 Train Loss 0.06757607 Test MSE 0.5460461876774247 Test RE 0.3532016713176759\n",
      "90 Train Loss 0.06716174 Test MSE 0.542882565548893 Test RE 0.35217701459792217\n",
      "91 Train Loss 0.066566765 Test MSE 0.5470273057002036 Test RE 0.353518839547503\n",
      "92 Train Loss 0.066053554 Test MSE 0.5451339614587581 Test RE 0.3529065181677956\n",
      "93 Train Loss 0.0656708 Test MSE 0.5465295818984938 Test RE 0.353357974832734\n",
      "94 Train Loss 0.06531834 Test MSE 0.5474621515606339 Test RE 0.3536593221744973\n",
      "95 Train Loss 0.06506174 Test MSE 0.5493231407463655 Test RE 0.35425990963324316\n",
      "96 Train Loss 0.06477111 Test MSE 0.5491049334079823 Test RE 0.3541895414069328\n",
      "97 Train Loss 0.06439815 Test MSE 0.5501297202943405 Test RE 0.35451989684738533\n",
      "98 Train Loss 0.06400712 Test MSE 0.5534395131580471 Test RE 0.355584761898908\n",
      "99 Train Loss 0.06368445 Test MSE 0.5542940630153931 Test RE 0.35585918005442657\n",
      "Training time: 122.81\n",
      "3\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.50461 Test MSE 8.790852520460612 Test RE 1.4171752444575418\n",
      "1 Train Loss 46.57755 Test MSE 8.620957576580631 Test RE 1.4034140312185976\n",
      "2 Train Loss 41.613228 Test MSE 9.152658968710126 Test RE 1.44604464203804\n",
      "3 Train Loss 37.174736 Test MSE 9.4087014604314 Test RE 1.4661314318932914\n",
      "4 Train Loss 33.595062 Test MSE 9.658930779811302 Test RE 1.4854997640058478\n",
      "5 Train Loss 30.802258 Test MSE 9.858755423892209 Test RE 1.500787164224751\n",
      "6 Train Loss 27.870274 Test MSE 9.6689527709185 Test RE 1.4862702325986037\n",
      "7 Train Loss 24.72258 Test MSE 9.504020152830321 Test RE 1.4735393385669138\n",
      "8 Train Loss 22.044487 Test MSE 9.550316563163848 Test RE 1.4771239640162288\n",
      "9 Train Loss 20.088823 Test MSE 9.443172149473659 Test RE 1.4688147116172456\n",
      "10 Train Loss 18.117971 Test MSE 9.057344248889159 Test RE 1.438495466671956\n",
      "11 Train Loss 16.979628 Test MSE 9.264123883222958 Test RE 1.4548232641498169\n",
      "12 Train Loss 16.000553 Test MSE 9.15580920455074 Test RE 1.4462934762710487\n",
      "13 Train Loss 14.928361 Test MSE 9.038050625198645 Test RE 1.4369625346533788\n",
      "14 Train Loss 14.008173 Test MSE 8.877898842775439 Test RE 1.424174339281636\n",
      "15 Train Loss 13.024513 Test MSE 8.788966003524227 Test RE 1.4170231733959304\n",
      "16 Train Loss 12.053838 Test MSE 9.0526893544005 Test RE 1.4381257719252758\n",
      "17 Train Loss 11.314133 Test MSE 8.742892720712435 Test RE 1.4133041525397347\n",
      "18 Train Loss 10.415877 Test MSE 8.747488612218747 Test RE 1.4136755707517152\n",
      "19 Train Loss 9.314898 Test MSE 8.66413945061496 Test RE 1.4069244503809366\n",
      "20 Train Loss 8.105423 Test MSE 8.293818094788048 Test RE 1.3765288349278018\n",
      "21 Train Loss 7.006754 Test MSE 7.893650030778053 Test RE 1.3429102670519293\n",
      "22 Train Loss 6.242073 Test MSE 7.909910458491485 Test RE 1.344292711260446\n",
      "23 Train Loss 5.7570477 Test MSE 7.876298463321329 Test RE 1.3414334839860926\n",
      "24 Train Loss 5.3092995 Test MSE 7.518301132545991 Test RE 1.3105932250673198\n",
      "25 Train Loss 4.8140154 Test MSE 7.48233281462027 Test RE 1.307454460825985\n",
      "26 Train Loss 4.1024075 Test MSE 7.3827942262810815 Test RE 1.2987287129283023\n",
      "27 Train Loss 3.4870524 Test MSE 7.111923653451118 Test RE 1.2746812664970515\n",
      "28 Train Loss 2.9515116 Test MSE 7.12705476969144 Test RE 1.2760365329097079\n",
      "29 Train Loss 2.5996616 Test MSE 7.011180353349102 Test RE 1.265620875930179\n",
      "30 Train Loss 2.177314 Test MSE 6.904282692319377 Test RE 1.2559355188334347\n",
      "31 Train Loss 1.9234328 Test MSE 6.870938930934207 Test RE 1.2528991210023015\n",
      "32 Train Loss 1.7072707 Test MSE 6.581299183793369 Test RE 1.2262072436951414\n",
      "33 Train Loss 1.5623989 Test MSE 6.326110941701278 Test RE 1.2021992764159888\n",
      "34 Train Loss 1.462795 Test MSE 6.079730540981342 Test RE 1.178556007553114\n",
      "35 Train Loss 1.3939853 Test MSE 5.973578467311345 Test RE 1.1682219087304548\n",
      "36 Train Loss 1.3275876 Test MSE 5.869401347311811 Test RE 1.1579904132726333\n",
      "37 Train Loss 1.2727594 Test MSE 5.868435190879387 Test RE 1.157895101513802\n",
      "38 Train Loss 1.228909 Test MSE 5.886452764247243 Test RE 1.159671253976088\n",
      "39 Train Loss 1.1841757 Test MSE 5.807508260503952 Test RE 1.151868703001787\n",
      "40 Train Loss 1.1463546 Test MSE 5.833885768755845 Test RE 1.1544816139834246\n",
      "41 Train Loss 1.1137531 Test MSE 5.8305794998741485 Test RE 1.1541544248893676\n",
      "42 Train Loss 1.0853833 Test MSE 5.779481029394227 Test RE 1.149085862778827\n",
      "43 Train Loss 1.057393 Test MSE 5.7950896766143 Test RE 1.150636484916803\n",
      "44 Train Loss 1.0388796 Test MSE 5.790269923168609 Test RE 1.1501578954510676\n",
      "45 Train Loss 1.0236098 Test MSE 5.802660298913226 Test RE 1.151387827137613\n",
      "46 Train Loss 1.0052431 Test MSE 5.813610650348884 Test RE 1.1524737220576615\n",
      "47 Train Loss 0.9885458 Test MSE 5.803745230982806 Test RE 1.1514954604582925\n",
      "48 Train Loss 0.975427 Test MSE 5.818107864874267 Test RE 1.1529193934251192\n",
      "49 Train Loss 0.9562423 Test MSE 5.814282082683971 Test RE 1.152540271559147\n",
      "50 Train Loss 0.9352329 Test MSE 5.831803903508831 Test RE 1.1542756029550567\n",
      "51 Train Loss 0.9212002 Test MSE 5.8626224212510865 Test RE 1.1573215035469415\n",
      "52 Train Loss 0.9089209 Test MSE 5.886975944311326 Test RE 1.159722787847574\n",
      "53 Train Loss 0.8954268 Test MSE 5.899094239622862 Test RE 1.1609158144835952\n",
      "54 Train Loss 0.882185 Test MSE 5.93191365091179 Test RE 1.164140693264132\n",
      "55 Train Loss 0.87048346 Test MSE 5.976824939843168 Test RE 1.168539313549483\n",
      "56 Train Loss 0.8616301 Test MSE 5.972829397645331 Test RE 1.1681486605899445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 0.8495702 Test MSE 5.986330468802625 Test RE 1.1694681655349513\n",
      "58 Train Loss 0.8417748 Test MSE 5.997254259016324 Test RE 1.1705346955526654\n",
      "59 Train Loss 0.8352081 Test MSE 5.991022362629301 Test RE 1.1699263715911\n",
      "60 Train Loss 0.8280979 Test MSE 6.019575276398456 Test RE 1.1727109630963692\n",
      "61 Train Loss 0.8213855 Test MSE 6.014268482304956 Test RE 1.1721939243072337\n",
      "62 Train Loss 0.8131045 Test MSE 6.0361640967015235 Test RE 1.174325737076158\n",
      "63 Train Loss 0.8050208 Test MSE 6.048151981782184 Test RE 1.1754912702760583\n",
      "64 Train Loss 0.7957105 Test MSE 6.073301631716889 Test RE 1.1779327205799353\n",
      "65 Train Loss 0.7905823 Test MSE 6.090161284006153 Test RE 1.1795665742673875\n",
      "66 Train Loss 0.783589 Test MSE 6.100485887726447 Test RE 1.1805660059482663\n",
      "67 Train Loss 0.77635384 Test MSE 6.109163851996537 Test RE 1.1814053873549237\n",
      "68 Train Loss 0.76925784 Test MSE 6.10509553256857 Test RE 1.1810119509492294\n",
      "69 Train Loss 0.76337177 Test MSE 6.106559034744869 Test RE 1.1811534974639912\n",
      "70 Train Loss 0.7575343 Test MSE 6.110736992129321 Test RE 1.1815574864509752\n",
      "71 Train Loss 0.7532691 Test MSE 6.121083444352198 Test RE 1.182557346024857\n",
      "72 Train Loss 0.74868906 Test MSE 6.13216372719715 Test RE 1.1836271848544389\n",
      "73 Train Loss 0.7448137 Test MSE 6.136967552770766 Test RE 1.1840907101013067\n",
      "74 Train Loss 0.7403915 Test MSE 6.157867703475705 Test RE 1.1861052750810444\n",
      "75 Train Loss 0.737206 Test MSE 6.165987061409004 Test RE 1.186886977556872\n",
      "76 Train Loss 0.7340448 Test MSE 6.164730942668723 Test RE 1.1867660766453816\n",
      "77 Train Loss 0.730584 Test MSE 6.177358673320209 Test RE 1.1879809306269293\n",
      "78 Train Loss 0.7267126 Test MSE 6.183470092055571 Test RE 1.188568435295253\n",
      "79 Train Loss 0.7229182 Test MSE 6.19582356213557 Test RE 1.189755116739925\n",
      "80 Train Loss 0.7193722 Test MSE 6.195789974062212 Test RE 1.1897518918549763\n",
      "81 Train Loss 0.7169918 Test MSE 6.191091845244232 Test RE 1.1893007252004177\n",
      "82 Train Loss 0.7151716 Test MSE 6.188142486484055 Test RE 1.1890174074551276\n",
      "83 Train Loss 0.71145266 Test MSE 6.207996704102791 Test RE 1.1909233190733002\n",
      "84 Train Loss 0.7076427 Test MSE 6.214775793283799 Test RE 1.1915733816424006\n",
      "85 Train Loss 0.7043615 Test MSE 6.234492126970007 Test RE 1.193462014110752\n",
      "86 Train Loss 0.7005051 Test MSE 6.24787699914007 Test RE 1.1947424529590818\n",
      "87 Train Loss 0.6968099 Test MSE 6.237318658032133 Test RE 1.1937325233300775\n",
      "88 Train Loss 0.6932926 Test MSE 6.248777515334732 Test RE 1.1948285498975337\n",
      "89 Train Loss 0.6893265 Test MSE 6.243868428280174 Test RE 1.1943591244936207\n",
      "90 Train Loss 0.6857828 Test MSE 6.243716996568274 Test RE 1.1943446410891774\n",
      "91 Train Loss 0.68253946 Test MSE 6.270870787384425 Test RE 1.1969389131082746\n",
      "92 Train Loss 0.67917824 Test MSE 6.282794894883918 Test RE 1.1980763667741812\n",
      "93 Train Loss 0.6759687 Test MSE 6.288987266027827 Test RE 1.1986666380234168\n",
      "94 Train Loss 0.6733501 Test MSE 6.290373002469077 Test RE 1.1987986898531853\n",
      "95 Train Loss 0.67051554 Test MSE 6.300221439245974 Test RE 1.1997367642427383\n",
      "96 Train Loss 0.66843724 Test MSE 6.313086880551571 Test RE 1.2009611078017584\n",
      "97 Train Loss 0.66663355 Test MSE 6.323937501352822 Test RE 1.201992740923338\n",
      "98 Train Loss 0.6647955 Test MSE 6.334475427577248 Test RE 1.2029937975030975\n",
      "99 Train Loss 0.6628623 Test MSE 6.34637168011234 Test RE 1.2041228890394042\n",
      "Training time: 122.60\n",
      "4\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 50.773373 Test MSE 8.235224103098885 Test RE 1.3716577804631556\n",
      "1 Train Loss 37.09434 Test MSE 6.865834083404231 Test RE 1.2524336062117283\n",
      "2 Train Loss 30.115986 Test MSE 6.665828169274463 Test RE 1.2340567089909678\n",
      "3 Train Loss 25.812798 Test MSE 6.1324449989320735 Test RE 1.183654330008177\n",
      "4 Train Loss 21.567436 Test MSE 5.968627196147234 Test RE 1.1677376610930594\n",
      "5 Train Loss 18.388126 Test MSE 6.151694688909647 Test RE 1.185510614609538\n",
      "6 Train Loss 15.198723 Test MSE 5.505341952190012 Test RE 1.1215024068969957\n",
      "7 Train Loss 10.672033 Test MSE 5.050678637252316 Test RE 1.0741945098995502\n",
      "8 Train Loss 7.777297 Test MSE 4.978025529727921 Test RE 1.0664404759858381\n",
      "9 Train Loss 6.274188 Test MSE 4.946007486238829 Test RE 1.0630053369671084\n",
      "10 Train Loss 4.9881577 Test MSE 4.6291370899085225 Test RE 1.0283905601393917\n",
      "11 Train Loss 3.739256 Test MSE 4.226715542277916 Test RE 0.9826742381025683\n",
      "12 Train Loss 3.05302 Test MSE 3.921037112070841 Test RE 0.9464736697838048\n",
      "13 Train Loss 2.5292573 Test MSE 3.4469728658767558 Test RE 0.8874154644562107\n",
      "14 Train Loss 2.1335251 Test MSE 3.002656634006128 Test RE 0.8282489540906508\n",
      "15 Train Loss 1.8947423 Test MSE 2.602793922758811 Test RE 0.7711306269145731\n",
      "16 Train Loss 1.6999288 Test MSE 2.284107701112181 Test RE 0.7223810576111562\n",
      "17 Train Loss 1.5411448 Test MSE 1.8515130360574497 Test RE 0.6503863940945533\n",
      "18 Train Loss 1.439489 Test MSE 1.5880716713349532 Test RE 0.6023419486701449\n",
      "19 Train Loss 1.2998004 Test MSE 1.2263645651211128 Test RE 0.5293194553919486\n",
      "20 Train Loss 0.97258955 Test MSE 0.757280702620174 Test RE 0.41594557199308174\n",
      "21 Train Loss 0.73839575 Test MSE 0.6262411091926993 Test RE 0.3782499217737036\n",
      "22 Train Loss 0.533078 Test MSE 0.5106528594565687 Test RE 0.3415630982851203\n",
      "23 Train Loss 0.43675807 Test MSE 0.43318211400771395 Test RE 0.3145888446814827\n",
      "24 Train Loss 0.36353174 Test MSE 0.38912078414736745 Test RE 0.298160614283185\n",
      "25 Train Loss 0.3130296 Test MSE 0.34722952951943764 Test RE 0.28165430016105003\n",
      "26 Train Loss 0.265973 Test MSE 0.3476621224972165 Test RE 0.28182969386582135\n",
      "27 Train Loss 0.22987308 Test MSE 0.2842618480247245 Test RE 0.2548398541404532\n",
      "28 Train Loss 0.19559155 Test MSE 0.24848646749144115 Test RE 0.23826455019602796\n",
      "29 Train Loss 0.16684969 Test MSE 0.17343847235889753 Test RE 0.19905852427387485\n",
      "30 Train Loss 0.14133069 Test MSE 0.12154851102817285 Test RE 0.16664139088530303\n",
      "31 Train Loss 0.103898905 Test MSE 0.07460378983328533 Test RE 0.13055349578402967\n",
      "32 Train Loss 0.071257904 Test MSE 0.04734202843624112 Test RE 0.103999557452406\n",
      "33 Train Loss 0.05656667 Test MSE 0.03332239408716639 Test RE 0.08725215423878778\n",
      "34 Train Loss 0.045053266 Test MSE 0.025818549241326823 Test RE 0.07680225612709363\n",
      "35 Train Loss 0.0389797 Test MSE 0.022162143382020327 Test RE 0.0711563955147986\n",
      "36 Train Loss 0.035464413 Test MSE 0.018619719045492377 Test RE 0.06522207658798279\n",
      "37 Train Loss 0.03210689 Test MSE 0.020580718220261127 Test RE 0.06857065904528982\n",
      "38 Train Loss 0.029003005 Test MSE 0.017687651030419308 Test RE 0.06356867231013673\n",
      "39 Train Loss 0.025837237 Test MSE 0.015188369067849958 Test RE 0.05890655584756997\n",
      "40 Train Loss 0.024059268 Test MSE 0.014046697092019911 Test RE 0.05664938101974262\n",
      "41 Train Loss 0.022510199 Test MSE 0.01293930790258022 Test RE 0.05437053219039744\n",
      "42 Train Loss 0.021027729 Test MSE 0.012516341636237634 Test RE 0.05347450396209483\n",
      "43 Train Loss 0.019290296 Test MSE 0.014668919100266941 Test RE 0.05789047552805148\n",
      "44 Train Loss 0.017530898 Test MSE 0.012132006211404514 Test RE 0.05264709014033677\n",
      "45 Train Loss 0.015532384 Test MSE 0.0111535794285692 Test RE 0.05047951719192162\n",
      "46 Train Loss 0.013985377 Test MSE 0.009876701225940606 Test RE 0.04750223222534249\n",
      "47 Train Loss 0.012746947 Test MSE 0.0077961939456321445 Test RE 0.042203588273982524\n",
      "48 Train Loss 0.011412076 Test MSE 0.006848381774116787 Test RE 0.03955505945868655\n",
      "49 Train Loss 0.01058303 Test MSE 0.006199181705997704 Test RE 0.037633554839574306\n",
      "50 Train Loss 0.009823424 Test MSE 0.0064326050286554574 Test RE 0.03833553276715877\n",
      "51 Train Loss 0.009095594 Test MSE 0.006502813112753487 Test RE 0.03854416987193841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 0.008132644 Test MSE 0.006278005915771703 Test RE 0.03787205929798477\n",
      "53 Train Loss 0.007652194 Test MSE 0.0059754716022252284 Test RE 0.036948273837405364\n",
      "54 Train Loss 0.006762349 Test MSE 0.006754546062431697 Test RE 0.03928313542063094\n",
      "55 Train Loss 0.0061257333 Test MSE 0.006991676171028793 Test RE 0.03996673885956376\n",
      "56 Train Loss 0.00552993 Test MSE 0.006572807940857111 Test RE 0.03875105506383047\n",
      "57 Train Loss 0.005180862 Test MSE 0.00607370357654213 Test RE 0.03725073588246698\n",
      "58 Train Loss 0.004860757 Test MSE 0.006055389010535223 Test RE 0.03719453079054615\n",
      "59 Train Loss 0.0046289396 Test MSE 0.005642701085118563 Test RE 0.035904723170955104\n",
      "60 Train Loss 0.004210247 Test MSE 0.0051445635593155474 Test RE 0.03428327709189867\n",
      "61 Train Loss 0.0039434363 Test MSE 0.00477201495095106 Test RE 0.03301862303888615\n",
      "62 Train Loss 0.003766274 Test MSE 0.004673904243746969 Test RE 0.03267743545975853\n",
      "63 Train Loss 0.0036175682 Test MSE 0.004899295400891156 Test RE 0.033456066075367746\n",
      "64 Train Loss 0.0034621425 Test MSE 0.004252932913071274 Test RE 0.03117111420524406\n",
      "65 Train Loss 0.0032177274 Test MSE 0.004419782277473793 Test RE 0.031776678376780554\n",
      "66 Train Loss 0.0029890966 Test MSE 0.0043570692548061925 Test RE 0.03155043066699632\n",
      "67 Train Loss 0.0027969454 Test MSE 0.004047763606461301 Test RE 0.030409944739034446\n",
      "68 Train Loss 0.0026989398 Test MSE 0.003805248439664329 Test RE 0.029484893847391426\n",
      "69 Train Loss 0.0025395586 Test MSE 0.0037091400919945184 Test RE 0.029110165773474528\n",
      "70 Train Loss 0.002425043 Test MSE 0.0038893918414324314 Test RE 0.029809103140576963\n",
      "71 Train Loss 0.0023306813 Test MSE 0.003738246010476437 Test RE 0.029224157482608485\n",
      "72 Train Loss 0.0022494767 Test MSE 0.003641871437625411 Test RE 0.028844988197217328\n",
      "73 Train Loss 0.002152399 Test MSE 0.0036394005470718237 Test RE 0.02883520134679641\n",
      "74 Train Loss 0.0021125397 Test MSE 0.0033657119663521307 Test RE 0.02772978700214525\n",
      "75 Train Loss 0.0020321864 Test MSE 0.003375211251999139 Test RE 0.02776889129415566\n",
      "76 Train Loss 0.0019506761 Test MSE 0.003000946438604906 Test RE 0.02618407174905524\n",
      "77 Train Loss 0.0018491975 Test MSE 0.002832414444794089 Test RE 0.02543820486424115\n",
      "78 Train Loss 0.0017992718 Test MSE 0.0026997383074592774 Test RE 0.024835270508581715\n",
      "79 Train Loss 0.0017182807 Test MSE 0.0028761600294023673 Test RE 0.025633893965902797\n",
      "80 Train Loss 0.0016349747 Test MSE 0.0026624216629741577 Test RE 0.024663032738719448\n",
      "81 Train Loss 0.0015880372 Test MSE 0.0027554934957640105 Test RE 0.025090409841474377\n",
      "82 Train Loss 0.0015364797 Test MSE 0.00269229998032307 Test RE 0.024801033803901775\n",
      "83 Train Loss 0.001467275 Test MSE 0.0024989855819159317 Test RE 0.023894059207242357\n",
      "84 Train Loss 0.001400612 Test MSE 0.0024275610788346952 Test RE 0.023550121017463385\n",
      "85 Train Loss 0.0013422378 Test MSE 0.0022783034094594865 Test RE 0.022814651559091213\n",
      "86 Train Loss 0.001302903 Test MSE 0.0022444341005385853 Test RE 0.022644435022080273\n",
      "87 Train Loss 0.0012804968 Test MSE 0.0021891432480828695 Test RE 0.02236377687939736\n",
      "88 Train Loss 0.0012409771 Test MSE 0.00212504953242001 Test RE 0.022033961638369896\n",
      "89 Train Loss 0.0011917345 Test MSE 0.002031170455768072 Test RE 0.02154176310984181\n",
      "90 Train Loss 0.0011650526 Test MSE 0.0019297709308145558 Test RE 0.020997178504012837\n",
      "91 Train Loss 0.0011379354 Test MSE 0.001908568870344973 Test RE 0.0208815137395019\n",
      "92 Train Loss 0.0011070566 Test MSE 0.0019400876127144825 Test RE 0.021053229836708015\n",
      "93 Train Loss 0.0010683078 Test MSE 0.0019244167116631984 Test RE 0.020968029556175424\n",
      "94 Train Loss 0.0010350025 Test MSE 0.0018975712560440393 Test RE 0.020821264771337812\n",
      "95 Train Loss 0.0010035522 Test MSE 0.0018861690061181943 Test RE 0.020758614428287917\n",
      "96 Train Loss 0.00096577057 Test MSE 0.001786022965381266 Test RE 0.020200009781122606\n",
      "97 Train Loss 0.000929083 Test MSE 0.0016546396601667234 Test RE 0.019442843262965886\n",
      "98 Train Loss 0.00090691296 Test MSE 0.0016993983462447483 Test RE 0.01970405703453196\n",
      "99 Train Loss 0.0008890393 Test MSE 0.0016398241209693743 Test RE 0.01935560254048524\n",
      "Training time: 123.08\n",
      "5\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 55.357845 Test MSE 7.842377202947055 Test RE 1.338541756791302\n",
      "1 Train Loss 45.520348 Test MSE 8.037407961692203 Test RE 1.3550835295546741\n",
      "2 Train Loss 42.450047 Test MSE 8.670104930878313 Test RE 1.4074087186623228\n",
      "3 Train Loss 40.334995 Test MSE 9.394855820404885 Test RE 1.465052271197806\n",
      "4 Train Loss 38.50758 Test MSE 9.64997962971901 Test RE 1.4848112813092083\n",
      "5 Train Loss 34.988068 Test MSE 9.931009519902645 Test RE 1.506276704048832\n",
      "6 Train Loss 31.956772 Test MSE 9.858070767896677 Test RE 1.500735051116863\n",
      "7 Train Loss 29.88174 Test MSE 9.615575135720935 Test RE 1.4821620635923165\n",
      "8 Train Loss 26.097569 Test MSE 9.665069413874567 Test RE 1.4859717360728573\n",
      "9 Train Loss 23.285702 Test MSE 9.513866091616501 Test RE 1.4743024168356251\n",
      "10 Train Loss 20.761919 Test MSE 9.706466358427871 Test RE 1.489150655874531\n",
      "11 Train Loss 18.579443 Test MSE 10.011378240208394 Test RE 1.5123593483282725\n",
      "12 Train Loss 16.750675 Test MSE 9.890025838736856 Test RE 1.5031654097678888\n",
      "13 Train Loss 15.286163 Test MSE 9.660966670071602 Test RE 1.4856563111031509\n",
      "14 Train Loss 13.681469 Test MSE 9.777684853042997 Test RE 1.4946037856284213\n",
      "15 Train Loss 12.2638035 Test MSE 9.705380795020375 Test RE 1.4890673808390031\n",
      "16 Train Loss 10.581282 Test MSE 9.229265249563404 Test RE 1.452083612397234\n",
      "17 Train Loss 8.943693 Test MSE 9.077883621555616 Test RE 1.440125583754098\n",
      "18 Train Loss 7.1453867 Test MSE 7.873814553842865 Test RE 1.3412219466693183\n",
      "19 Train Loss 6.0609646 Test MSE 7.86067783869595 Test RE 1.3401026285997792\n",
      "20 Train Loss 5.2688584 Test MSE 7.26608787863149 Test RE 1.2884227460057016\n",
      "21 Train Loss 4.755862 Test MSE 7.146090006269076 Test RE 1.2777394425430524\n",
      "22 Train Loss 4.3699646 Test MSE 7.12072636736217 Test RE 1.275469884678756\n",
      "23 Train Loss 4.072 Test MSE 6.883517313561206 Test RE 1.2540454154699534\n",
      "24 Train Loss 3.7490902 Test MSE 6.744304848808896 Test RE 1.2412997175406464\n",
      "25 Train Loss 3.5714197 Test MSE 6.718328416947509 Test RE 1.2389069100876307\n",
      "26 Train Loss 3.352586 Test MSE 6.766423134482088 Test RE 1.2433335037389432\n",
      "27 Train Loss 3.2252855 Test MSE 6.628686393899143 Test RE 1.230613844707725\n",
      "28 Train Loss 3.0836673 Test MSE 6.612819655967353 Test RE 1.2291401344806971\n",
      "29 Train Loss 2.9577746 Test MSE 6.607347107697765 Test RE 1.2286314315895916\n",
      "30 Train Loss 2.846257 Test MSE 6.568384962199415 Test RE 1.2250035840830564\n",
      "31 Train Loss 2.7407012 Test MSE 6.587292930487774 Test RE 1.2267654847666454\n",
      "32 Train Loss 2.651067 Test MSE 6.506188356930799 Test RE 1.219189956472235\n",
      "33 Train Loss 2.551278 Test MSE 6.452063001591432 Test RE 1.214108109652134\n",
      "34 Train Loss 2.478363 Test MSE 6.48831682528059 Test RE 1.2175143382817861\n",
      "35 Train Loss 2.430159 Test MSE 6.516714271124584 Test RE 1.2201757796543862\n",
      "36 Train Loss 2.376203 Test MSE 6.447077472243273 Test RE 1.2136389464286397\n",
      "37 Train Loss 2.3151474 Test MSE 6.370037649897556 Test RE 1.206365920198687\n",
      "38 Train Loss 2.245081 Test MSE 6.354465056271599 Test RE 1.20489043898199\n",
      "39 Train Loss 2.1940491 Test MSE 6.300759831111145 Test RE 1.1997880255135849\n",
      "40 Train Loss 2.1405108 Test MSE 6.242669284077951 Test RE 1.1942444297649428\n",
      "41 Train Loss 2.0896907 Test MSE 6.210482017435243 Test RE 1.191161682716948\n",
      "42 Train Loss 2.030184 Test MSE 6.165844327264847 Test RE 1.1868732400744806\n",
      "43 Train Loss 1.9602592 Test MSE 6.060814834880313 Test RE 1.1767211740834074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 1.9044539 Test MSE 5.9777225877953315 Test RE 1.1686270606017126\n",
      "45 Train Loss 1.858676 Test MSE 5.983593280191262 Test RE 1.169200771264216\n",
      "46 Train Loss 1.8205112 Test MSE 5.964595185407521 Test RE 1.1673431711991489\n",
      "47 Train Loss 1.7771404 Test MSE 5.8849698869774105 Test RE 1.1595251763189391\n",
      "48 Train Loss 1.721811 Test MSE 5.8288456235897295 Test RE 1.153982803030639\n",
      "49 Train Loss 1.6805977 Test MSE 5.7816237345201404 Test RE 1.1492988511069593\n",
      "50 Train Loss 1.6370775 Test MSE 5.7025950253077164 Test RE 1.1414169715609472\n",
      "51 Train Loss 1.5909846 Test MSE 5.736182471421244 Test RE 1.1447734256183477\n",
      "52 Train Loss 1.5672791 Test MSE 5.728661419121117 Test RE 1.1440226889620768\n",
      "53 Train Loss 1.5429649 Test MSE 5.74788940368968 Test RE 1.1459410099909764\n",
      "54 Train Loss 1.5230672 Test MSE 5.736984553397508 Test RE 1.1448534588147026\n",
      "55 Train Loss 1.4949001 Test MSE 5.703451790141912 Test RE 1.1415027122798311\n",
      "56 Train Loss 1.4722645 Test MSE 5.709708484865765 Test RE 1.142128655710946\n",
      "57 Train Loss 1.4493606 Test MSE 5.7017218797344436 Test RE 1.1413295849129692\n",
      "58 Train Loss 1.4324834 Test MSE 5.727434778243578 Test RE 1.1439002013492978\n",
      "59 Train Loss 1.4113475 Test MSE 5.737384216863513 Test RE 1.1448933358728153\n",
      "60 Train Loss 1.3890471 Test MSE 5.7034871854884175 Test RE 1.1415062543297023\n",
      "61 Train Loss 1.3731207 Test MSE 5.6729290181153855 Test RE 1.1384441638213647\n",
      "62 Train Loss 1.3549647 Test MSE 5.66863141069319 Test RE 1.1380128599009716\n",
      "63 Train Loss 1.3436137 Test MSE 5.652117859469263 Test RE 1.1363540520965631\n",
      "64 Train Loss 1.3303006 Test MSE 5.64293320284423 Test RE 1.135430392549374\n",
      "65 Train Loss 1.3172127 Test MSE 5.628589839641022 Test RE 1.1339864402570567\n",
      "66 Train Loss 1.3054936 Test MSE 5.637181195660196 Test RE 1.1348515562686887\n",
      "67 Train Loss 1.2943043 Test MSE 5.645089628257024 Test RE 1.1356473220248056\n",
      "68 Train Loss 1.2826087 Test MSE 5.64070857443438 Test RE 1.135206558630377\n",
      "69 Train Loss 1.2681768 Test MSE 5.650755754236792 Test RE 1.1362171187289969\n",
      "70 Train Loss 1.2588903 Test MSE 5.654761394855839 Test RE 1.1366197614340283\n",
      "71 Train Loss 1.2491312 Test MSE 5.641192436672641 Test RE 1.1352552468226638\n",
      "72 Train Loss 1.2375652 Test MSE 5.655619225972474 Test RE 1.136705971156753\n",
      "73 Train Loss 1.2254015 Test MSE 5.657294005578488 Test RE 1.1368742631674846\n",
      "74 Train Loss 1.211488 Test MSE 5.653990729942296 Test RE 1.1365423061042559\n",
      "75 Train Loss 1.2004892 Test MSE 5.663742018438174 Test RE 1.1375219661379916\n",
      "76 Train Loss 1.1897607 Test MSE 5.6641925464952845 Test RE 1.1375672079029342\n",
      "77 Train Loss 1.1790317 Test MSE 5.674332986620921 Test RE 1.138585029401289\n",
      "78 Train Loss 1.1672701 Test MSE 5.695494740219717 Test RE 1.1407061626989161\n",
      "79 Train Loss 1.157656 Test MSE 5.708668518568053 Test RE 1.1420246373181497\n",
      "80 Train Loss 1.1476642 Test MSE 5.7434527500569645 Test RE 1.1454986628573032\n",
      "81 Train Loss 1.1379253 Test MSE 5.739801047178961 Test RE 1.1451344493735836\n",
      "82 Train Loss 1.1253133 Test MSE 5.715493977935741 Test RE 1.1427071532311914\n",
      "83 Train Loss 1.1138238 Test MSE 5.764612713823145 Test RE 1.14760683953158\n",
      "84 Train Loss 1.1009809 Test MSE 5.788646964452448 Test RE 1.149996694883024\n",
      "85 Train Loss 1.0908533 Test MSE 5.787756665453916 Test RE 1.1499082562304346\n",
      "86 Train Loss 1.0839423 Test MSE 5.80166728715938 Test RE 1.1512893041752121\n",
      "87 Train Loss 1.0776032 Test MSE 5.80642625935087 Test RE 1.1517613952490295\n",
      "88 Train Loss 1.0728885 Test MSE 5.825370935302817 Test RE 1.1536387959548182\n",
      "89 Train Loss 1.066635 Test MSE 5.822271408377373 Test RE 1.1533318446623417\n",
      "90 Train Loss 1.0620283 Test MSE 5.834242552216496 Test RE 1.1545169158100599\n",
      "91 Train Loss 1.0582361 Test MSE 5.843989024320572 Test RE 1.155480860250525\n",
      "92 Train Loss 1.052416 Test MSE 5.8598370768430845 Test RE 1.1570465479285295\n",
      "93 Train Loss 1.0450275 Test MSE 5.863931912482722 Test RE 1.1574507475639497\n",
      "94 Train Loss 1.0394454 Test MSE 5.884700151348969 Test RE 1.1594986027899246\n",
      "95 Train Loss 1.0333998 Test MSE 5.894283440976943 Test RE 1.160442345920907\n",
      "96 Train Loss 1.0266361 Test MSE 5.9030073511246135 Test RE 1.1613007922222263\n",
      "97 Train Loss 1.0191727 Test MSE 5.9083276408155605 Test RE 1.1618240056247813\n",
      "98 Train Loss 1.0102364 Test MSE 5.915939900931434 Test RE 1.1625722088588446\n",
      "99 Train Loss 1.0023885 Test MSE 5.947182303994285 Test RE 1.1656379703718096\n",
      "Training time: 123.53\n",
      "6\n",
      "KG_rowdy_tune40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.69\n",
      "0\n",
      "KG_rowdy_tune41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 71.36568 Test MSE 4.534820053587961 Test RE 1.0178600979245243\n",
      "1 Train Loss 47.567413 Test MSE 7.115720353340022 Test RE 1.2750214653467853\n",
      "2 Train Loss 33.54671 Test MSE 6.971788073039454 Test RE 1.2620604256420656\n",
      "3 Train Loss 23.374844 Test MSE 5.945618754922627 Test RE 1.1654847337735652\n",
      "4 Train Loss 19.004377 Test MSE 6.0393483860058 Test RE 1.174635445343616\n",
      "5 Train Loss 14.18168 Test MSE 6.147723120757984 Test RE 1.1851278667151803\n",
      "6 Train Loss 11.514171 Test MSE 5.9039909753342465 Test RE 1.1613975425670036\n",
      "7 Train Loss 9.849008 Test MSE 5.68596905181774 Test RE 1.139751850641613\n",
      "8 Train Loss 8.285887 Test MSE 5.6519961989468674 Test RE 1.1363418221524073\n",
      "9 Train Loss 7.484791 Test MSE 5.394821980736852 Test RE 1.1101882318684975\n",
      "10 Train Loss 6.6523237 Test MSE 5.222462111350142 Test RE 1.0923094960235378\n",
      "11 Train Loss 5.9542074 Test MSE 5.05105897181411 Test RE 1.0742349545245646\n",
      "12 Train Loss 5.557891 Test MSE 4.856195730899793 Test RE 1.0533098650320245\n",
      "13 Train Loss 5.0299416 Test MSE 4.412404960892498 Test RE 1.0040278102878826\n",
      "14 Train Loss 4.543484 Test MSE 3.885618872257668 Test RE 0.942189283372627\n",
      "15 Train Loss 3.8229742 Test MSE 3.5173638898758908 Test RE 0.8964306778291332\n",
      "16 Train Loss 3.1969855 Test MSE 3.337638870828861 Test RE 0.8732281602995056\n",
      "17 Train Loss 2.6374812 Test MSE 2.9425132842846424 Test RE 0.8199120636297845\n",
      "18 Train Loss 2.3083947 Test MSE 2.780253720982607 Test RE 0.7969852348328826\n",
      "19 Train Loss 2.0417256 Test MSE 2.648267537030024 Test RE 0.777837700275274\n",
      "20 Train Loss 1.8190897 Test MSE 2.5091127716703454 Test RE 0.757125983478701\n",
      "21 Train Loss 1.5584594 Test MSE 2.0631796088871117 Test RE 0.6865569671623224\n",
      "22 Train Loss 1.3184049 Test MSE 1.8296982907706358 Test RE 0.6465435767653257\n",
      "23 Train Loss 1.1645304 Test MSE 1.6915656100020442 Test RE 0.6216593699039356\n",
      "24 Train Loss 1.0211146 Test MSE 1.3722220065603397 Test RE 0.5599126122148438\n",
      "25 Train Loss 0.89096 Test MSE 0.9822406615366052 Test RE 0.47371486674686936\n",
      "26 Train Loss 0.6929029 Test MSE 0.6738607563649698 Test RE 0.39236760431668516\n",
      "27 Train Loss 0.4192819 Test MSE 0.3263331622026163 Test RE 0.27304778947472846\n",
      "28 Train Loss 0.29041123 Test MSE 0.2332925770658057 Test RE 0.23086522503750237\n",
      "29 Train Loss 0.2051766 Test MSE 0.19557194123124413 Test RE 0.2113787539951647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 0.14329934 Test MSE 0.18390307201756004 Test RE 0.20497578214990134\n",
      "31 Train Loss 0.12221151 Test MSE 0.15407989911862585 Test RE 0.18762083005471847\n",
      "32 Train Loss 0.09958343 Test MSE 0.10838931216266715 Test RE 0.15736251589273095\n",
      "33 Train Loss 0.085187405 Test MSE 0.08671186408020844 Test RE 0.1407496493430324\n",
      "34 Train Loss 0.0764016 Test MSE 0.060727405101354985 Test RE 0.11778783038245537\n",
      "35 Train Loss 0.065328665 Test MSE 0.045259228801440746 Test RE 0.10168611030335331\n",
      "36 Train Loss 0.058872897 Test MSE 0.03302223813136009 Test RE 0.08685829753370866\n",
      "37 Train Loss 0.050416794 Test MSE 0.022945339149797735 Test RE 0.0724027898522803\n",
      "38 Train Loss 0.04393435 Test MSE 0.015035356289976787 Test RE 0.05860908243447622\n",
      "39 Train Loss 0.039228722 Test MSE 0.013182133211496713 Test RE 0.05487833270558879\n",
      "40 Train Loss 0.03110054 Test MSE 0.01150573018975324 Test RE 0.05127021670242291\n",
      "41 Train Loss 0.026823632 Test MSE 0.010131585409561897 Test RE 0.04811126380086098\n",
      "42 Train Loss 0.024293484 Test MSE 0.008987787476108048 Test RE 0.045314214653707184\n",
      "43 Train Loss 0.02129338 Test MSE 0.005847090411157399 Test RE 0.03654920752829412\n",
      "44 Train Loss 0.01761062 Test MSE 0.004138025720005913 Test RE 0.030747134889656375\n",
      "45 Train Loss 0.015252056 Test MSE 0.003294690444524719 Test RE 0.02743565723799037\n",
      "46 Train Loss 0.013538149 Test MSE 0.0032400370559588056 Test RE 0.027207149867592564\n",
      "47 Train Loss 0.011749518 Test MSE 0.002913036859807902 Test RE 0.02579770369466291\n",
      "48 Train Loss 0.010543267 Test MSE 0.0025049279215665133 Test RE 0.023922451189404163\n",
      "49 Train Loss 0.009889826 Test MSE 0.0024838185547861446 Test RE 0.023821439060714385\n",
      "50 Train Loss 0.008920475 Test MSE 0.002395927165481514 Test RE 0.02339617526668886\n",
      "51 Train Loss 0.00815096 Test MSE 0.0023788668287589416 Test RE 0.0233127295527571\n",
      "52 Train Loss 0.007641254 Test MSE 0.0023393196548959585 Test RE 0.023118137643756996\n",
      "53 Train Loss 0.0068476964 Test MSE 0.0020830231061025606 Test RE 0.021814994307207587\n",
      "54 Train Loss 0.006454045 Test MSE 0.0021376019070773913 Test RE 0.02209894160976734\n",
      "55 Train Loss 0.0057884366 Test MSE 0.0019126699754556428 Test RE 0.020903936647411536\n",
      "56 Train Loss 0.0055113947 Test MSE 0.002037073566172379 Test RE 0.02157304338646752\n",
      "57 Train Loss 0.00493655 Test MSE 0.0018890205913753135 Test RE 0.020774300350981927\n",
      "58 Train Loss 0.004725787 Test MSE 0.001822324106009381 Test RE 0.020404261009211663\n",
      "59 Train Loss 0.0045425277 Test MSE 0.001733686617443874 Test RE 0.019901845877873643\n",
      "60 Train Loss 0.004425726 Test MSE 0.0017347734640730961 Test RE 0.019908083125411747\n",
      "61 Train Loss 0.0042231944 Test MSE 0.001712388738026848 Test RE 0.01977922367469746\n",
      "62 Train Loss 0.0037857431 Test MSE 0.001573796650737872 Test RE 0.018961922562214892\n",
      "63 Train Loss 0.0036731837 Test MSE 0.0015503387331899958 Test RE 0.018820075398689348\n",
      "64 Train Loss 0.0035901587 Test MSE 0.0016243846427668098 Test RE 0.019264267393409373\n",
      "65 Train Loss 0.0034425424 Test MSE 0.0015172505587846496 Test RE 0.01861815807630893\n",
      "66 Train Loss 0.0033238493 Test MSE 0.0015178909793923288 Test RE 0.018622086957436904\n",
      "67 Train Loss 0.0032441532 Test MSE 0.0016103171618436758 Test RE 0.01918066989173648\n",
      "68 Train Loss 0.003061363 Test MSE 0.0015782415643617272 Test RE 0.018988681000272935\n",
      "69 Train Loss 0.002963069 Test MSE 0.0015582986452922346 Test RE 0.018868327547450686\n",
      "70 Train Loss 0.0028579514 Test MSE 0.0013658043333787775 Test RE 0.017664538817110883\n",
      "71 Train Loss 0.0027894918 Test MSE 0.001403270079699106 Test RE 0.017905180067687435\n",
      "72 Train Loss 0.0027290941 Test MSE 0.0013954815801876777 Test RE 0.017855421817689603\n",
      "73 Train Loss 0.002589309 Test MSE 0.0013896774551415245 Test RE 0.017818250747994525\n",
      "74 Train Loss 0.0024167923 Test MSE 0.001203374256748993 Test RE 0.016580912160336494\n",
      "75 Train Loss 0.002326957 Test MSE 0.0011825038865215663 Test RE 0.016436500174398676\n",
      "76 Train Loss 0.002280002 Test MSE 0.0011319040541055516 Test RE 0.016080993188910504\n",
      "77 Train Loss 0.0022039257 Test MSE 0.0011348732275684092 Test RE 0.01610207094139411\n",
      "78 Train Loss 0.002061833 Test MSE 0.0010942450816356219 Test RE 0.015811219284291363\n",
      "79 Train Loss 0.0019752407 Test MSE 0.0010897496277702135 Test RE 0.015778707481905133\n",
      "80 Train Loss 0.0019394368 Test MSE 0.0011323809867159558 Test RE 0.016084380729710628\n",
      "81 Train Loss 0.0019091208 Test MSE 0.0011185120271553605 Test RE 0.015985579675474353\n",
      "82 Train Loss 0.0018553052 Test MSE 0.0010562382984174203 Test RE 0.01553420440956839\n",
      "83 Train Loss 0.0017962618 Test MSE 0.0010908283479166005 Test RE 0.015786515054929007\n",
      "84 Train Loss 0.00173102 Test MSE 0.001108643116590929 Test RE 0.015914901048182925\n",
      "85 Train Loss 0.0016822822 Test MSE 0.0010615199492460734 Test RE 0.015572994866528227\n",
      "86 Train Loss 0.0016552777 Test MSE 0.0010517817091578343 Test RE 0.015501398011511406\n",
      "87 Train Loss 0.0015941054 Test MSE 0.0010320814879146497 Test RE 0.015355538613928608\n",
      "88 Train Loss 0.0015620678 Test MSE 0.000982509746192183 Test RE 0.014982231172271593\n",
      "89 Train Loss 0.0015230651 Test MSE 0.0010072690516700472 Test RE 0.015169833199511842\n",
      "90 Train Loss 0.0014865405 Test MSE 0.0009848603279758862 Test RE 0.015000142404946992\n",
      "91 Train Loss 0.0014622097 Test MSE 0.0009866843728583434 Test RE 0.015014026747345052\n",
      "92 Train Loss 0.0014461388 Test MSE 0.0010215892607349005 Test RE 0.015277286377890132\n",
      "93 Train Loss 0.0014099192 Test MSE 0.0010342874220632735 Test RE 0.015371940044829753\n",
      "94 Train Loss 0.001379003 Test MSE 0.001027877325414805 Test RE 0.015324231465370949\n",
      "95 Train Loss 0.0013565234 Test MSE 0.0010183862050458018 Test RE 0.015253317637384257\n",
      "96 Train Loss 0.0013326338 Test MSE 0.001007154899158328 Test RE 0.01516897358627141\n",
      "97 Train Loss 0.0012785138 Test MSE 0.0009485560688745307 Test RE 0.01472107630365212\n",
      "98 Train Loss 0.0012245753 Test MSE 0.000910644284550866 Test RE 0.014423891384260817\n",
      "99 Train Loss 0.0011689952 Test MSE 0.0008400441982174511 Test RE 0.013853487865253923\n",
      "Training time: 122.50\n",
      "1\n",
      "KG_rowdy_tune41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.34\n",
      "0\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.39672 Test MSE 4.498911032744468 Test RE 1.0138221203373292\n",
      "1 Train Loss 49.51589 Test MSE 6.204260208340198 Test RE 1.1905648661031056\n",
      "2 Train Loss 31.815357 Test MSE 6.430505853620264 Test RE 1.2120781692799438\n",
      "3 Train Loss 24.933083 Test MSE 5.700232336196494 Test RE 1.1411804921309043\n",
      "4 Train Loss 18.379765 Test MSE 5.395005344397781 Test RE 1.1102070987050228\n",
      "5 Train Loss 14.621685 Test MSE 5.028099903031782 Test RE 1.071790761683078\n",
      "6 Train Loss 12.776987 Test MSE 5.4242524157532515 Test RE 1.1132123245146535\n",
      "7 Train Loss 11.294545 Test MSE 5.393163476013936 Test RE 1.1100175687802527\n",
      "8 Train Loss 10.240799 Test MSE 5.491186902426188 Test RE 1.1200597045315919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 9.279959 Test MSE 5.480439299519673 Test RE 1.1189630515463864\n",
      "10 Train Loss 8.375184 Test MSE 5.38430729211875 Test RE 1.10910580717848\n",
      "11 Train Loss 7.1121807 Test MSE 5.082040350365887 Test RE 1.0775244035321998\n",
      "12 Train Loss 5.983329 Test MSE 4.825950379938519 Test RE 1.0500246303087937\n",
      "13 Train Loss 4.975404 Test MSE 4.840269183475936 Test RE 1.0515812108035105\n",
      "14 Train Loss 4.0554233 Test MSE 4.702059431557795 Test RE 1.036458976772285\n",
      "15 Train Loss 3.4174707 Test MSE 4.5737107015965766 Test RE 1.0222153677578207\n",
      "16 Train Loss 2.8691928 Test MSE 4.282090454303412 Test RE 0.9890903820685677\n",
      "17 Train Loss 2.5087872 Test MSE 4.109850948814994 Test RE 0.9689940183186185\n",
      "18 Train Loss 2.2272675 Test MSE 4.084185512209569 Test RE 0.9659636647322407\n",
      "19 Train Loss 1.9636574 Test MSE 4.19272544995199 Test RE 0.9787150634287236\n",
      "20 Train Loss 1.819686 Test MSE 4.167474992407939 Test RE 0.975763484069169\n",
      "21 Train Loss 1.6882042 Test MSE 3.9999064653339853 Test RE 0.9559451588996284\n",
      "22 Train Loss 1.5809492 Test MSE 3.9780694798925884 Test RE 0.9533321565968048\n",
      "23 Train Loss 1.4583526 Test MSE 3.8124101397885704 Test RE 0.9332712090337763\n",
      "24 Train Loss 1.3490813 Test MSE 3.6993494489510064 Test RE 0.9193285323617516\n",
      "25 Train Loss 1.2566624 Test MSE 3.577941044010405 Test RE 0.9041170313258038\n",
      "26 Train Loss 1.1240411 Test MSE 3.4366242521563373 Test RE 0.8860823493809891\n",
      "27 Train Loss 1.049792 Test MSE 3.37453953753284 Test RE 0.8780420614741993\n",
      "28 Train Loss 0.9322238 Test MSE 3.2570664644128264 Test RE 0.862623669892186\n",
      "29 Train Loss 0.85177714 Test MSE 3.200458800018026 Test RE 0.8550946331983336\n",
      "30 Train Loss 0.7676895 Test MSE 3.1201463654344113 Test RE 0.8442975788317095\n",
      "31 Train Loss 0.7281772 Test MSE 3.092848507513599 Test RE 0.8405961263205923\n",
      "32 Train Loss 0.6895503 Test MSE 3.120651206342233 Test RE 0.8443658799090239\n",
      "33 Train Loss 0.646271 Test MSE 3.1224168474441254 Test RE 0.8446047140795451\n",
      "34 Train Loss 0.6119942 Test MSE 3.097211863228861 Test RE 0.8411888690923607\n",
      "35 Train Loss 0.5758322 Test MSE 3.122895594410041 Test RE 0.8446694614316463\n",
      "36 Train Loss 0.55766183 Test MSE 3.1105306935560493 Test RE 0.8429955961546939\n",
      "37 Train Loss 0.536546 Test MSE 3.0934837209343238 Test RE 0.8406824432750301\n",
      "38 Train Loss 0.5195763 Test MSE 3.1226160307794735 Test RE 0.8446316529076034\n",
      "39 Train Loss 0.50546855 Test MSE 3.1432368222755747 Test RE 0.8474159071207735\n",
      "40 Train Loss 0.49209762 Test MSE 3.1233710996316755 Test RE 0.844733765446856\n",
      "41 Train Loss 0.47649363 Test MSE 3.1330844214441815 Test RE 0.8460462578254246\n",
      "42 Train Loss 0.45856288 Test MSE 3.132204073567475 Test RE 0.845927386570428\n",
      "43 Train Loss 0.43818223 Test MSE 3.113960254021637 Test RE 0.8434601966016597\n",
      "44 Train Loss 0.42580372 Test MSE 3.0998649329778436 Test RE 0.8415490729014101\n",
      "45 Train Loss 0.41653994 Test MSE 3.1151938086260573 Test RE 0.8436272429195506\n",
      "46 Train Loss 0.4077999 Test MSE 3.1304569346562485 Test RE 0.8456914251234888\n",
      "47 Train Loss 0.39764586 Test MSE 3.145825744024097 Test RE 0.8477648216367304\n",
      "48 Train Loss 0.3904371 Test MSE 3.182608869795539 Test RE 0.852706737872597\n",
      "49 Train Loss 0.3847447 Test MSE 3.175028487642006 Test RE 0.851690638076659\n",
      "50 Train Loss 0.37879014 Test MSE 3.175136170563322 Test RE 0.851705080743664\n",
      "51 Train Loss 0.3736742 Test MSE 3.201711845850913 Test RE 0.8552620104367837\n",
      "52 Train Loss 0.36970288 Test MSE 3.2116358418990254 Test RE 0.8565864659716602\n",
      "53 Train Loss 0.3642892 Test MSE 3.2002122351696154 Test RE 0.8550616941179278\n",
      "54 Train Loss 0.36141363 Test MSE 3.2083984677801625 Test RE 0.8561546315151503\n",
      "55 Train Loss 0.35718656 Test MSE 3.2111633593035185 Test RE 0.8565234549232409\n",
      "56 Train Loss 0.35321528 Test MSE 3.2219353713692334 Test RE 0.8579588780448216\n",
      "57 Train Loss 0.349116 Test MSE 3.2453246295587257 Test RE 0.8610673722346924\n",
      "58 Train Loss 0.3450657 Test MSE 3.2562262698503712 Test RE 0.8625124012902923\n",
      "59 Train Loss 0.34044737 Test MSE 3.249316926870403 Test RE 0.8615968385868931\n",
      "60 Train Loss 0.3353446 Test MSE 3.2723715439949146 Test RE 0.8646480452932032\n",
      "61 Train Loss 0.33081776 Test MSE 3.285712220700178 Test RE 0.8664087343584278\n",
      "62 Train Loss 0.32727864 Test MSE 3.30509752633525 Test RE 0.8689608291256898\n",
      "63 Train Loss 0.32277444 Test MSE 3.316025135999168 Test RE 0.8703961617856786\n",
      "64 Train Loss 0.32005903 Test MSE 3.3227157151178206 Test RE 0.8712737968581336\n",
      "65 Train Loss 0.31687573 Test MSE 3.3200070588831365 Test RE 0.8709185960885183\n",
      "66 Train Loss 0.31373814 Test MSE 3.337495498785849 Test RE 0.8732094048477144\n",
      "67 Train Loss 0.31054497 Test MSE 3.3493148800231936 Test RE 0.8747542269317499\n",
      "68 Train Loss 0.30755106 Test MSE 3.3557186054458064 Test RE 0.8755900711419383\n",
      "69 Train Loss 0.30533218 Test MSE 3.3640609310828804 Test RE 0.8766777552217364\n",
      "70 Train Loss 0.3013734 Test MSE 3.3700711456780414 Test RE 0.8774605398153605\n",
      "71 Train Loss 0.2992795 Test MSE 3.3756304512334427 Test RE 0.8781839757564371\n",
      "72 Train Loss 0.29734397 Test MSE 3.3746495468152555 Test RE 0.8780563733512455\n",
      "73 Train Loss 0.29488719 Test MSE 3.3854475782192095 Test RE 0.8794600313967962\n",
      "74 Train Loss 0.29231495 Test MSE 3.3926266406840853 Test RE 0.8803920137634985\n",
      "75 Train Loss 0.28902268 Test MSE 3.3904492402766597 Test RE 0.8801094489825441\n",
      "76 Train Loss 0.287193 Test MSE 3.394643957317047 Test RE 0.8806537233037295\n",
      "77 Train Loss 0.28498295 Test MSE 3.3950625268001 Test RE 0.8807080152141964\n",
      "78 Train Loss 0.2825925 Test MSE 3.397024147842052 Test RE 0.8809624090412193\n",
      "79 Train Loss 0.28065622 Test MSE 3.4037495725700864 Test RE 0.8818340420515681\n",
      "80 Train Loss 0.2790014 Test MSE 3.392616443598826 Test RE 0.8803906906825761\n",
      "81 Train Loss 0.27783522 Test MSE 3.4071533376946364 Test RE 0.882274850911994\n",
      "82 Train Loss 0.27640006 Test MSE 3.4052308394233535 Test RE 0.882025902443463\n",
      "83 Train Loss 0.2742222 Test MSE 3.4046799034345416 Test RE 0.8819545475937609\n",
      "84 Train Loss 0.27275035 Test MSE 3.4026511899132386 Test RE 0.881691747597975\n",
      "85 Train Loss 0.2713985 Test MSE 3.412512472822629 Test RE 0.8829684463965393\n",
      "86 Train Loss 0.26986077 Test MSE 3.413529397558934 Test RE 0.8830999983802197\n",
      "87 Train Loss 0.26802918 Test MSE 3.4240472852004644 Test RE 0.8844594714628361\n",
      "88 Train Loss 0.26620132 Test MSE 3.4266690693555226 Test RE 0.8847980208341205\n",
      "89 Train Loss 0.26459864 Test MSE 3.428130499283494 Test RE 0.8849866781630965\n",
      "90 Train Loss 0.26294473 Test MSE 3.4333232732693966 Test RE 0.8856566930358633\n",
      "91 Train Loss 0.26156303 Test MSE 3.438351146558521 Test RE 0.8863049484139918\n",
      "92 Train Loss 0.26022688 Test MSE 3.4380793553259035 Test RE 0.8862699178623216\n",
      "93 Train Loss 0.25770816 Test MSE 3.4363296889172315 Test RE 0.8860443741964817\n",
      "94 Train Loss 0.25603816 Test MSE 3.4416207859127304 Test RE 0.886726256305028\n",
      "95 Train Loss 0.2550383 Test MSE 3.4375112357225435 Test RE 0.8861966897508987\n",
      "96 Train Loss 0.25376585 Test MSE 3.449115708107028 Test RE 0.8876912565734425\n",
      "97 Train Loss 0.25279397 Test MSE 3.4525479457826607 Test RE 0.888132820447383\n",
      "98 Train Loss 0.25172088 Test MSE 3.4510509712368367 Test RE 0.8879402588389794\n",
      "99 Train Loss 0.2507912 Test MSE 3.453820107631016 Test RE 0.88829643072136\n",
      "Training time: 121.28\n",
      "1\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 61.885155 Test MSE 6.735678169774812 Test RE 1.2405055867191341\n",
      "1 Train Loss 45.07171 Test MSE 8.600923506765216 Test RE 1.4017823999267396\n",
      "2 Train Loss 41.333126 Test MSE 9.184606329136786 Test RE 1.4485661533715528\n",
      "3 Train Loss 38.41783 Test MSE 9.153102383352918 Test RE 1.4460796695423341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 36.217987 Test MSE 9.491531844430163 Test RE 1.4725709029758323\n",
      "5 Train Loss 33.0885 Test MSE 9.33735536819358 Test RE 1.4605620233697971\n",
      "6 Train Loss 30.500334 Test MSE 9.168549937073557 Test RE 1.447299418614634\n",
      "7 Train Loss 28.184898 Test MSE 9.44216570669481 Test RE 1.468736437212894\n",
      "8 Train Loss 25.42876 Test MSE 9.544647446433254 Test RE 1.4766854847678346\n",
      "9 Train Loss 22.2647 Test MSE 9.589087795254718 Test RE 1.480119252651667\n",
      "10 Train Loss 19.7916 Test MSE 9.297031563735302 Test RE 1.4574048584967352\n",
      "11 Train Loss 17.75988 Test MSE 8.652386437958947 Test RE 1.4059698713105464\n",
      "12 Train Loss 14.966401 Test MSE 7.678066458149954 Test RE 1.3244451999940903\n",
      "13 Train Loss 11.76173 Test MSE 6.447209290357313 Test RE 1.2136513535061095\n",
      "14 Train Loss 10.267519 Test MSE 6.125171040864155 Test RE 1.1829521299387438\n",
      "15 Train Loss 9.377024 Test MSE 6.037999988912057 Test RE 1.1745043083949966\n",
      "16 Train Loss 8.941711 Test MSE 5.9573073730856025 Test RE 1.1666297968672719\n",
      "17 Train Loss 8.642681 Test MSE 5.886512154585255 Test RE 1.1596771041117124\n",
      "18 Train Loss 8.377237 Test MSE 5.848441412093857 Test RE 1.1559209422999266\n",
      "19 Train Loss 8.181081 Test MSE 5.803318928123455 Test RE 1.1514531692478427\n",
      "20 Train Loss 8.009845 Test MSE 5.83591123208373 Test RE 1.1546820084834442\n",
      "21 Train Loss 7.791253 Test MSE 5.918331600049725 Test RE 1.1628071877465984\n",
      "22 Train Loss 7.5825453 Test MSE 5.9606135811388965 Test RE 1.1669534821815268\n",
      "23 Train Loss 7.354824 Test MSE 5.972435462364124 Test RE 1.1681101375945286\n",
      "24 Train Loss 7.0893764 Test MSE 6.074355602341727 Test RE 1.178034926324209\n",
      "25 Train Loss 6.8778906 Test MSE 6.071477255262021 Test RE 1.177755786001272\n",
      "26 Train Loss 6.601959 Test MSE 6.0459683780425095 Test RE 1.1752790534814839\n",
      "27 Train Loss 6.420521 Test MSE 6.078781933218639 Test RE 1.1784640601400893\n",
      "28 Train Loss 6.204204 Test MSE 6.084691548451992 Test RE 1.1790367552495256\n",
      "29 Train Loss 5.926976 Test MSE 6.046076605013145 Test RE 1.1752895725840027\n",
      "30 Train Loss 5.5135937 Test MSE 5.922273501773576 Test RE 1.1631943668524363\n",
      "31 Train Loss 4.8462677 Test MSE 5.378274125997461 Test RE 1.1084842513572808\n",
      "32 Train Loss 3.9542353 Test MSE 5.346603837214794 Test RE 1.1052157446558226\n",
      "33 Train Loss 3.091685 Test MSE 5.397210877997322 Test RE 1.110434007549442\n",
      "34 Train Loss 2.7552886 Test MSE 5.196246979978172 Test RE 1.089564520422038\n",
      "35 Train Loss 2.5089061 Test MSE 5.206304070988519 Test RE 1.0906184111060493\n",
      "36 Train Loss 2.2986398 Test MSE 5.279873988768687 Test RE 1.0982971056415753\n",
      "37 Train Loss 2.1877153 Test MSE 5.332814833343801 Test RE 1.1037896372338367\n",
      "38 Train Loss 2.0852306 Test MSE 5.397865154396206 Test RE 1.1105013116406672\n",
      "39 Train Loss 1.993175 Test MSE 5.492032195383773 Test RE 1.1201459101337732\n",
      "40 Train Loss 1.8936197 Test MSE 5.562983948959003 Test RE 1.1273582924785135\n",
      "41 Train Loss 1.8469644 Test MSE 5.552503461557919 Test RE 1.1262958379905574\n",
      "42 Train Loss 1.806842 Test MSE 5.586781453192135 Test RE 1.1297670431995421\n",
      "43 Train Loss 1.7542547 Test MSE 5.599995285802404 Test RE 1.1311023143129946\n",
      "44 Train Loss 1.7156849 Test MSE 5.577169309071383 Test RE 1.1287947339430229\n",
      "45 Train Loss 1.6633936 Test MSE 5.58902695635589 Test RE 1.129994064842304\n",
      "46 Train Loss 1.5935645 Test MSE 5.590924867058102 Test RE 1.1301859091301945\n",
      "47 Train Loss 1.5470071 Test MSE 5.604509463812343 Test RE 1.1315581154661385\n",
      "48 Train Loss 1.4907138 Test MSE 5.620312329042073 Test RE 1.133152302523809\n",
      "49 Train Loss 1.4376252 Test MSE 5.6300521070556995 Test RE 1.134133731477854\n",
      "50 Train Loss 1.3960278 Test MSE 5.69688607074339 Test RE 1.14084548355341\n",
      "51 Train Loss 1.3538523 Test MSE 5.73854825098555 Test RE 1.1450094713161896\n",
      "52 Train Loss 1.3271661 Test MSE 5.750185804420955 Test RE 1.1461699007021913\n",
      "53 Train Loss 1.2888552 Test MSE 5.76968028168498 Test RE 1.148111149039959\n",
      "54 Train Loss 1.2646965 Test MSE 5.757556919976874 Test RE 1.1469042982742204\n",
      "55 Train Loss 1.2401515 Test MSE 5.780957203418653 Test RE 1.1492326010754947\n",
      "56 Train Loss 1.2155846 Test MSE 5.756154256128791 Test RE 1.1467645845718282\n",
      "57 Train Loss 1.1883298 Test MSE 5.765964609060468 Test RE 1.1477413978574078\n",
      "58 Train Loss 1.1659245 Test MSE 5.811469808170515 Test RE 1.1522615052715464\n",
      "59 Train Loss 1.1483886 Test MSE 5.8248454157595315 Test RE 1.1535867586327728\n",
      "60 Train Loss 1.1221597 Test MSE 5.886489908228149 Test RE 1.1596749127788246\n",
      "61 Train Loss 1.107381 Test MSE 5.892195496314052 Test RE 1.1602367947257712\n",
      "62 Train Loss 1.0953506 Test MSE 5.914468818609735 Test RE 1.1624276548416612\n",
      "63 Train Loss 1.0807182 Test MSE 5.9367512906758755 Test RE 1.1646152910000052\n",
      "64 Train Loss 1.0658915 Test MSE 5.959663170448502 Test RE 1.1668604440015171\n",
      "65 Train Loss 1.0523672 Test MSE 5.993323719552497 Test RE 1.1701510544147544\n",
      "66 Train Loss 1.0426531 Test MSE 5.9561611137562345 Test RE 1.1665175544952275\n",
      "67 Train Loss 1.0288159 Test MSE 5.963137178388571 Test RE 1.1672004877053541\n",
      "68 Train Loss 1.0183203 Test MSE 6.0021910591844785 Test RE 1.1710163749095452\n",
      "69 Train Loss 1.0072396 Test MSE 6.001294344261835 Test RE 1.1709288979307126\n",
      "70 Train Loss 0.995179 Test MSE 6.011161239494323 Test RE 1.1718910810172065\n",
      "71 Train Loss 0.9860443 Test MSE 6.003193701007864 Test RE 1.1711141776080334\n",
      "72 Train Loss 0.97671306 Test MSE 6.031487161163058 Test RE 1.1738707038818879\n",
      "73 Train Loss 0.96728534 Test MSE 6.026288511840662 Test RE 1.1733647044893294\n",
      "74 Train Loss 0.9605988 Test MSE 6.02541114674404 Test RE 1.1732792865153934\n",
      "75 Train Loss 0.94803995 Test MSE 6.048575916325667 Test RE 1.1755324665476157\n",
      "76 Train Loss 0.9403392 Test MSE 6.06772884732038 Test RE 1.1773921685030502\n",
      "77 Train Loss 0.9331515 Test MSE 6.061080624611638 Test RE 1.176746975645109\n",
      "78 Train Loss 0.9284064 Test MSE 6.072461386009539 Test RE 1.1778512338361786\n",
      "79 Train Loss 0.9212477 Test MSE 6.080394980309406 Test RE 1.1786204065887644\n",
      "80 Train Loss 0.9154258 Test MSE 6.0592850533115605 Test RE 1.1765726594020154\n",
      "81 Train Loss 0.9096257 Test MSE 6.084266037122514 Test RE 1.1789955286512188\n",
      "82 Train Loss 0.903632 Test MSE 6.1025746931523965 Test RE 1.1807681014594489\n",
      "83 Train Loss 0.8989604 Test MSE 6.107695760410095 Test RE 1.1812634272141516\n",
      "84 Train Loss 0.89250094 Test MSE 6.110483610644688 Test RE 1.181532989578172\n",
      "85 Train Loss 0.8847882 Test MSE 6.144981602880757 Test RE 1.184863589073612\n",
      "86 Train Loss 0.87698865 Test MSE 6.162677828102582 Test RE 1.1865684386912845\n",
      "87 Train Loss 0.8706505 Test MSE 6.179544263702191 Test RE 1.1881910697992264\n",
      "88 Train Loss 0.86612654 Test MSE 6.207566245371191 Test RE 1.1908820294067053\n",
      "89 Train Loss 0.8621626 Test MSE 6.2077459796695615 Test RE 1.1908992697218477\n",
      "90 Train Loss 0.856765 Test MSE 6.198151392777463 Test RE 1.1899785969844534\n",
      "91 Train Loss 0.8517119 Test MSE 6.2281918951879645 Test RE 1.192858838446054\n",
      "92 Train Loss 0.84851694 Test MSE 6.234509842628637 Test RE 1.1934637097541325\n",
      "93 Train Loss 0.8441942 Test MSE 6.240545848923702 Test RE 1.1940413022106893\n",
      "94 Train Loss 0.840185 Test MSE 6.254606661757543 Test RE 1.195385715441449\n",
      "95 Train Loss 0.8350971 Test MSE 6.251085774133667 Test RE 1.1950492105675048\n",
      "96 Train Loss 0.8297529 Test MSE 6.248081505575509 Test RE 1.194762006042554\n",
      "97 Train Loss 0.82633257 Test MSE 6.235986821680412 Test RE 1.193605069424451\n",
      "98 Train Loss 0.82105607 Test MSE 6.253461168800078 Test RE 1.1952762466376299\n",
      "99 Train Loss 0.81785023 Test MSE 6.246602576113615 Test RE 1.1946205967713668\n",
      "Training time: 122.44\n",
      "2\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 67.001 Test MSE 5.200484367749115 Test RE 1.0900086839248073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 48.08087 Test MSE 8.236325324351052 Test RE 1.3717494870267368\n",
      "2 Train Loss 34.70171 Test MSE 6.752739854595847 Test RE 1.2420757129023194\n",
      "3 Train Loss 23.791702 Test MSE 6.468119646641499 Test RE 1.2156178895083125\n",
      "4 Train Loss 20.220509 Test MSE 6.354418938719822 Test RE 1.204886066725826\n",
      "5 Train Loss 17.569946 Test MSE 6.245426239379236 Test RE 1.1945081082434175\n",
      "6 Train Loss 14.226818 Test MSE 6.116617647386133 Test RE 1.1821258844509566\n",
      "7 Train Loss 12.218071 Test MSE 5.862303750558211 Test RE 1.1572900492394005\n",
      "8 Train Loss 10.19969 Test MSE 5.69684436092871 Test RE 1.1408413071893222\n",
      "9 Train Loss 8.962048 Test MSE 5.5349910391819535 Test RE 1.1245182843610273\n",
      "10 Train Loss 8.133569 Test MSE 5.449818064632935 Test RE 1.115832643181575\n",
      "11 Train Loss 7.34056 Test MSE 5.383043767426137 Test RE 1.1089756637150203\n",
      "12 Train Loss 6.895644 Test MSE 5.4236528744125065 Test RE 1.1131508012666742\n",
      "13 Train Loss 6.5692854 Test MSE 5.2690262071470455 Test RE 1.097168270653389\n",
      "14 Train Loss 6.2406864 Test MSE 5.170418632230637 Test RE 1.0868532647137361\n",
      "15 Train Loss 5.9100723 Test MSE 4.951782980887033 Test RE 1.0636257960389426\n",
      "16 Train Loss 5.6528354 Test MSE 4.747215804793523 Test RE 1.0414239179393272\n",
      "17 Train Loss 5.4106913 Test MSE 4.704797613851681 Test RE 1.0367607169576387\n",
      "18 Train Loss 5.222727 Test MSE 4.653621099549326 Test RE 1.0311066082792304\n",
      "19 Train Loss 5.0238514 Test MSE 4.5563223572372475 Test RE 1.020270386965923\n",
      "20 Train Loss 4.7612486 Test MSE 4.387791297670833 Test RE 1.0012235161618126\n",
      "21 Train Loss 4.1495013 Test MSE 4.028089195404915 Test RE 0.95930696938974\n",
      "22 Train Loss 3.529604 Test MSE 3.636988685620519 Test RE 0.9115469353227961\n",
      "23 Train Loss 2.9637542 Test MSE 3.36804444089825 Test RE 0.8771966550423517\n",
      "24 Train Loss 2.432599 Test MSE 2.81798732297743 Test RE 0.8023753493984206\n",
      "25 Train Loss 2.1599874 Test MSE 2.8658648024765476 Test RE 0.8091628019736148\n",
      "26 Train Loss 1.9689261 Test MSE 2.758925137668604 Test RE 0.7939223322594756\n",
      "27 Train Loss 1.723813 Test MSE 2.392873871508028 Test RE 0.7393804514690989\n",
      "28 Train Loss 1.5743755 Test MSE 2.265535463413049 Test RE 0.7194381980809212\n",
      "29 Train Loss 1.4891708 Test MSE 2.1317262133636654 Test RE 0.6978687848736\n",
      "30 Train Loss 1.404621 Test MSE 1.9070890145533457 Test RE 0.6600753923366369\n",
      "31 Train Loss 1.2584134 Test MSE 1.582307987672754 Test RE 0.6012478972301264\n",
      "32 Train Loss 1.0459135 Test MSE 1.0815063230271356 Test RE 0.4970757674686322\n",
      "33 Train Loss 0.8266063 Test MSE 0.6996078910202452 Test RE 0.3997932063750459\n",
      "34 Train Loss 0.65731955 Test MSE 0.5334208751903432 Test RE 0.3490945462565301\n",
      "35 Train Loss 0.52213395 Test MSE 0.5270081389770349 Test RE 0.34698981029020826\n",
      "36 Train Loss 0.46130723 Test MSE 0.5281610343224215 Test RE 0.34736914446056444\n",
      "37 Train Loss 0.38577312 Test MSE 0.47461282865046894 Test RE 0.329289434847973\n",
      "38 Train Loss 0.33663923 Test MSE 0.43054605176933014 Test RE 0.31363019333409164\n",
      "39 Train Loss 0.29468462 Test MSE 0.38214463350301003 Test RE 0.295475817462378\n",
      "40 Train Loss 0.25506917 Test MSE 0.4151973713571085 Test RE 0.3079891079528716\n",
      "41 Train Loss 0.21921705 Test MSE 0.3783451487661156 Test RE 0.29400325939254157\n",
      "42 Train Loss 0.18741082 Test MSE 0.3713528607239185 Test RE 0.29127381710062417\n",
      "43 Train Loss 0.16243005 Test MSE 0.36570620737707993 Test RE 0.28905083365440376\n",
      "44 Train Loss 0.1434935 Test MSE 0.36863659059120285 Test RE 0.2902065970211689\n",
      "45 Train Loss 0.13542326 Test MSE 0.3543948657741089 Test RE 0.2845455322797615\n",
      "46 Train Loss 0.12160632 Test MSE 0.33645957524907494 Test RE 0.2772518842989037\n",
      "47 Train Loss 0.11466753 Test MSE 0.32338322607341663 Test RE 0.2718108601556872\n",
      "48 Train Loss 0.1041536 Test MSE 0.3115749823943966 Test RE 0.26680216528269596\n",
      "49 Train Loss 0.09227502 Test MSE 0.2753383091340016 Test RE 0.2508079975628706\n",
      "50 Train Loss 0.086071104 Test MSE 0.2748020004589989 Test RE 0.25056361444449543\n",
      "51 Train Loss 0.07989655 Test MSE 0.2610847098387119 Test RE 0.24422987070958072\n",
      "52 Train Loss 0.07337641 Test MSE 0.2495195053372616 Test RE 0.23875930754372485\n",
      "53 Train Loss 0.065926164 Test MSE 0.22516319950306363 Test RE 0.22680716279852464\n",
      "54 Train Loss 0.061928965 Test MSE 0.22472582700902488 Test RE 0.2265867728005868\n",
      "55 Train Loss 0.056705665 Test MSE 0.19813484854660487 Test RE 0.21275927116152235\n",
      "56 Train Loss 0.05386612 Test MSE 0.19049193178052168 Test RE 0.20861539441284807\n",
      "57 Train Loss 0.049900852 Test MSE 0.18677623763843615 Test RE 0.20657077159142692\n",
      "58 Train Loss 0.04603359 Test MSE 0.17322931053351057 Test RE 0.19893845862727286\n",
      "59 Train Loss 0.043706063 Test MSE 0.16854784148497506 Test RE 0.1962319221069705\n",
      "60 Train Loss 0.04045796 Test MSE 0.15772594245831809 Test RE 0.18982771752386235\n",
      "61 Train Loss 0.03807121 Test MSE 0.14641422186626496 Test RE 0.18289409848148386\n",
      "62 Train Loss 0.036110014 Test MSE 0.13174409177639265 Test RE 0.17348967530091336\n",
      "63 Train Loss 0.034541793 Test MSE 0.12122747837558509 Test RE 0.16642117963727845\n",
      "64 Train Loss 0.032992695 Test MSE 0.12549996570570293 Test RE 0.16932842305993442\n",
      "65 Train Loss 0.029439354 Test MSE 0.12230677945385393 Test RE 0.16716037070235912\n",
      "66 Train Loss 0.026461374 Test MSE 0.10604518544449128 Test RE 0.15565158169211138\n",
      "67 Train Loss 0.02437453 Test MSE 0.09747705087784178 Test RE 0.14923106931992233\n",
      "68 Train Loss 0.0227684 Test MSE 0.09012460193549979 Test RE 0.143492677719466\n",
      "69 Train Loss 0.02111282 Test MSE 0.08207338460695662 Test RE 0.13693334968469778\n",
      "70 Train Loss 0.020281436 Test MSE 0.0826720304496596 Test RE 0.13743184040922032\n",
      "71 Train Loss 0.018853659 Test MSE 0.08673360268321247 Test RE 0.14076729115618172\n",
      "72 Train Loss 0.016043378 Test MSE 0.07994746936257636 Test RE 0.13514824825770894\n",
      "73 Train Loss 0.014444456 Test MSE 0.07219764546728011 Test RE 0.12843091524519962\n",
      "74 Train Loss 0.013247285 Test MSE 0.06407545847110048 Test RE 0.12099123825779995\n",
      "75 Train Loss 0.012632426 Test MSE 0.059582833180352145 Test RE 0.11667253534467752\n",
      "76 Train Loss 0.012322864 Test MSE 0.05778132626691389 Test RE 0.11489518091449714\n",
      "77 Train Loss 0.011738373 Test MSE 0.05508295127256351 Test RE 0.11218031646826143\n",
      "78 Train Loss 0.011187247 Test MSE 0.048408198705571136 Test RE 0.10516410293482513\n",
      "79 Train Loss 0.010486341 Test MSE 0.042898249714205555 Test RE 0.09899832503040244\n",
      "80 Train Loss 0.010091754 Test MSE 0.04414981392899099 Test RE 0.10043208967005487\n",
      "81 Train Loss 0.009702857 Test MSE 0.0430475979778517 Test RE 0.09917050433697634\n",
      "82 Train Loss 0.009308066 Test MSE 0.041937563018921084 Test RE 0.09788353727987546\n",
      "83 Train Loss 0.008795311 Test MSE 0.04150160595801956 Test RE 0.09737343968543244\n",
      "84 Train Loss 0.008441184 Test MSE 0.03931228016684873 Test RE 0.09477028297676453\n",
      "85 Train Loss 0.008294127 Test MSE 0.03930971741261558 Test RE 0.0947671939050905\n",
      "86 Train Loss 0.008220353 Test MSE 0.03908004297420719 Test RE 0.09448994073335151\n",
      "87 Train Loss 0.007850062 Test MSE 0.03563205796909102 Test RE 0.09022533711069536\n",
      "88 Train Loss 0.0075805164 Test MSE 0.033617629642162146 Test RE 0.0876378277800117\n",
      "89 Train Loss 0.007424501 Test MSE 0.03289833455650054 Test RE 0.08669519278510276\n",
      "90 Train Loss 0.0072695464 Test MSE 0.03371010809621139 Test RE 0.0877582860758871\n",
      "91 Train Loss 0.007077096 Test MSE 0.032631014232626786 Test RE 0.08634224698492367\n",
      "92 Train Loss 0.0068243016 Test MSE 0.03360076367107125 Test RE 0.08761584106467134\n",
      "93 Train Loss 0.0066300994 Test MSE 0.030676446848243506 Test RE 0.08371640839110027\n",
      "94 Train Loss 0.0064797243 Test MSE 0.028722660233223722 Test RE 0.08100659744994368\n",
      "95 Train Loss 0.0063640014 Test MSE 0.027521207787000526 Test RE 0.07929426993922399\n",
      "96 Train Loss 0.006207284 Test MSE 0.02658510981621239 Test RE 0.07793405785487445\n",
      "97 Train Loss 0.005961779 Test MSE 0.025678986998335335 Test RE 0.07659439744188858\n",
      "98 Train Loss 0.0056235343 Test MSE 0.026375893730006362 Test RE 0.07762679442069437\n",
      "99 Train Loss 0.005316318 Test MSE 0.024397899320478814 Test RE 0.07465936257472855\n",
      "Training time: 121.54\n",
      "3\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.449486 Test MSE 5.497699795017005 Test RE 1.1207237382761246\n",
      "1 Train Loss 47.029068 Test MSE 8.393634972356315 Test RE 1.3847873878560195\n",
      "2 Train Loss 37.105095 Test MSE 8.153989010758343 Test RE 1.3648757611311917\n",
      "3 Train Loss 32.091152 Test MSE 8.573057771907013 Test RE 1.3995097726584325\n",
      "4 Train Loss 28.410545 Test MSE 8.665811756361425 Test RE 1.407060222337054\n",
      "5 Train Loss 25.835672 Test MSE 8.795464750211632 Test RE 1.4175469649870267\n",
      "6 Train Loss 23.616528 Test MSE 9.057247899728377 Test RE 1.4384878155219178\n",
      "7 Train Loss 21.850248 Test MSE 9.3666625637483 Test RE 1.4628523636064783\n",
      "8 Train Loss 20.168089 Test MSE 9.022053013019335 Test RE 1.4356902386873935\n",
      "9 Train Loss 18.778683 Test MSE 9.342708023518412 Test RE 1.4609805982606705\n",
      "10 Train Loss 17.72334 Test MSE 9.24677261460968 Test RE 1.4534602178222211\n",
      "11 Train Loss 16.580515 Test MSE 9.45167087148008 Test RE 1.4694755192535318\n",
      "12 Train Loss 15.216542 Test MSE 9.218850083844616 Test RE 1.4512640476644185\n",
      "13 Train Loss 14.0388775 Test MSE 9.147719219172073 Test RE 1.445654369526453\n",
      "14 Train Loss 12.282942 Test MSE 8.66847713865079 Test RE 1.4072765935881406\n",
      "15 Train Loss 10.01512 Test MSE 7.901320216428134 Test RE 1.3435625552862065\n",
      "16 Train Loss 7.288216 Test MSE 7.266362832420897 Test RE 1.288447123178881\n",
      "17 Train Loss 5.1862 Test MSE 6.251023305315944 Test RE 1.195043239325027\n",
      "18 Train Loss 3.9280841 Test MSE 5.708229710065421 Test RE 1.1419807444427874\n",
      "19 Train Loss 3.3822734 Test MSE 5.772946104668936 Test RE 1.1484360368290285\n",
      "20 Train Loss 2.9581003 Test MSE 5.671864300751599 Test RE 1.1383373249957511\n",
      "21 Train Loss 2.525132 Test MSE 5.750948981850941 Test RE 1.146245959285928\n",
      "22 Train Loss 2.3278785 Test MSE 5.658121868786704 Test RE 1.136957442682686\n",
      "23 Train Loss 2.1499324 Test MSE 5.6674210041047015 Test RE 1.137891355105313\n",
      "24 Train Loss 2.011751 Test MSE 5.70974949230474 Test RE 1.142132757118853\n",
      "25 Train Loss 1.916926 Test MSE 5.71002363456626 Test RE 1.1421601754056978\n",
      "26 Train Loss 1.8340874 Test MSE 5.678730147180651 Test RE 1.1390261007707314\n",
      "27 Train Loss 1.7532542 Test MSE 5.700876890097774 Test RE 1.1412450098121945\n",
      "28 Train Loss 1.7097934 Test MSE 5.669842656842783 Test RE 1.1381344359895835\n",
      "29 Train Loss 1.6600076 Test MSE 5.643115982506815 Test RE 1.1354487812043568\n",
      "30 Train Loss 1.6012185 Test MSE 5.668267585603789 Test RE 1.1379763392450872\n",
      "31 Train Loss 1.544337 Test MSE 5.677858624025591 Test RE 1.1389386934027508\n",
      "32 Train Loss 1.4864025 Test MSE 5.631083283745074 Test RE 1.1342375883071851\n",
      "33 Train Loss 1.4400998 Test MSE 5.618117177145678 Test RE 1.1329309905921472\n",
      "34 Train Loss 1.3806528 Test MSE 5.6357203395976185 Test RE 1.1347045003076233\n",
      "35 Train Loss 1.3439953 Test MSE 5.631905599026853 Test RE 1.1343204024662559\n",
      "36 Train Loss 1.3019559 Test MSE 5.638507427766547 Test RE 1.1349850439112747\n",
      "37 Train Loss 1.258267 Test MSE 5.599966507783377 Test RE 1.131099407977893\n",
      "38 Train Loss 1.2211806 Test MSE 5.554792118726696 Test RE 1.126527935052152\n",
      "39 Train Loss 1.1815195 Test MSE 5.579872897481891 Test RE 1.129068298042826\n",
      "40 Train Loss 1.1518624 Test MSE 5.636846555167565 Test RE 1.1348178716214439\n",
      "41 Train Loss 1.1313075 Test MSE 5.655020877926225 Test RE 1.1366458394753107\n",
      "42 Train Loss 1.1029164 Test MSE 5.682987388480805 Test RE 1.1394529744159547\n",
      "43 Train Loss 1.07944 Test MSE 5.681452073459967 Test RE 1.1392990467966204\n",
      "44 Train Loss 1.0628382 Test MSE 5.714361599531279 Test RE 1.142593948580258\n",
      "45 Train Loss 1.0528841 Test MSE 5.731613787564013 Test RE 1.1443174472988162\n",
      "46 Train Loss 1.0381483 Test MSE 5.740919387118359 Test RE 1.1452460026492097\n",
      "47 Train Loss 1.0271158 Test MSE 5.742607406858195 Test RE 1.1454143603323599\n",
      "48 Train Loss 1.0180795 Test MSE 5.7710447179910735 Test RE 1.1482468958972547\n",
      "49 Train Loss 1.0102458 Test MSE 5.787006538109648 Test RE 1.1498337363752598\n",
      "50 Train Loss 1.000888 Test MSE 5.820961185382457 Test RE 1.1532020665378286\n",
      "51 Train Loss 0.98637944 Test MSE 5.840437667872985 Test RE 1.155129717563808\n",
      "52 Train Loss 0.9701484 Test MSE 5.854271992623315 Test RE 1.156496994167847\n",
      "53 Train Loss 0.96274793 Test MSE 5.861135683210155 Test RE 1.1571747481462342\n",
      "54 Train Loss 0.9551799 Test MSE 5.863261849431134 Test RE 1.1573846155599894\n",
      "55 Train Loss 0.94691175 Test MSE 5.875887359267015 Test RE 1.1586300582228204\n",
      "56 Train Loss 0.9359315 Test MSE 5.877652503780652 Test RE 1.1588040741454784\n",
      "57 Train Loss 0.9293184 Test MSE 5.88347075682767 Test RE 1.1593774788879854\n",
      "58 Train Loss 0.9225661 Test MSE 5.909416134651738 Test RE 1.161931022373417\n",
      "59 Train Loss 0.9169139 Test MSE 5.9283023677786755 Test RE 1.1637862813545943\n",
      "60 Train Loss 0.9114445 Test MSE 5.925236923297274 Test RE 1.1634853534235503\n",
      "61 Train Loss 0.90516526 Test MSE 5.942426393565754 Test RE 1.1651718018364123\n",
      "62 Train Loss 0.89813477 Test MSE 5.96113091941312 Test RE 1.1670041226561612\n",
      "63 Train Loss 0.8924755 Test MSE 5.9665531948018025 Test RE 1.1675347584967812\n",
      "64 Train Loss 0.8868046 Test MSE 5.957648493109291 Test RE 1.1666631974509836\n",
      "65 Train Loss 0.8802333 Test MSE 5.967931066764326 Test RE 1.1676695616646318\n",
      "66 Train Loss 0.8765423 Test MSE 5.974073701171449 Test RE 1.1682703328917918\n",
      "67 Train Loss 0.87355405 Test MSE 5.988230041385113 Test RE 1.169653697679644\n",
      "68 Train Loss 0.8689078 Test MSE 5.991847005376002 Test RE 1.1700068869056046\n",
      "69 Train Loss 0.861465 Test MSE 5.986713615332924 Test RE 1.1695055900058218\n",
      "70 Train Loss 0.85596657 Test MSE 5.987487837978279 Test RE 1.169581209828106\n",
      "71 Train Loss 0.84976226 Test MSE 5.981341048558857 Test RE 1.168980706273136\n",
      "72 Train Loss 0.8438201 Test MSE 5.9779381376927985 Test RE 1.1686481300950395\n",
      "73 Train Loss 0.83820474 Test MSE 5.993851198656846 Test RE 1.1702025464314414\n",
      "74 Train Loss 0.8319906 Test MSE 5.981185904425623 Test RE 1.1689655456533836\n",
      "75 Train Loss 0.8279089 Test MSE 5.985017596441205 Test RE 1.1693399194725207\n",
      "76 Train Loss 0.82013154 Test MSE 5.968782061083317 Test RE 1.167752810342566\n",
      "77 Train Loss 0.81565833 Test MSE 5.9858437569258545 Test RE 1.1694206234205848\n",
      "78 Train Loss 0.808004 Test MSE 6.0048581021000045 Test RE 1.1712765135850636\n",
      "79 Train Loss 0.802429 Test MSE 6.005385725311083 Test RE 1.1713279701798827\n",
      "80 Train Loss 0.7992031 Test MSE 6.03287947238789 Test RE 1.1740061844859007\n",
      "81 Train Loss 0.7946418 Test MSE 6.062449979395341 Test RE 1.17687989691749\n",
      "82 Train Loss 0.79014647 Test MSE 6.0578531142138115 Test RE 1.1764336265023647\n",
      "83 Train Loss 0.784593 Test MSE 6.0514058229515975 Test RE 1.1758074286336566\n",
      "84 Train Loss 0.7806851 Test MSE 6.078651331082201 Test RE 1.1784514004697513\n",
      "85 Train Loss 0.77537584 Test MSE 6.08464354230197 Test RE 1.1790321041405465\n",
      "86 Train Loss 0.7694538 Test MSE 6.100677161441872 Test RE 1.1805845134475401\n",
      "87 Train Loss 0.7661423 Test MSE 6.111323525436137 Test RE 1.181614190428877\n",
      "88 Train Loss 0.76320726 Test MSE 6.0998133240148515 Test RE 1.1805009268910513\n",
      "89 Train Loss 0.75986147 Test MSE 6.102169464249629 Test RE 1.1807288975717747\n",
      "90 Train Loss 0.7566587 Test MSE 6.11530340277167 Test RE 1.181998879124701\n",
      "91 Train Loss 0.7534114 Test MSE 6.121856540038201 Test RE 1.1826320224384266\n",
      "92 Train Loss 0.74957687 Test MSE 6.149043322088946 Test RE 1.1852551108482383\n",
      "93 Train Loss 0.74726444 Test MSE 6.159388801000159 Test RE 1.186251760072477\n",
      "94 Train Loss 0.7448716 Test MSE 6.152043505240027 Test RE 1.1855442248276415\n",
      "95 Train Loss 0.74165314 Test MSE 6.160833089865068 Test RE 1.1863908314835894\n",
      "96 Train Loss 0.7385272 Test MSE 6.1747637105717486 Test RE 1.1877313830256584\n",
      "97 Train Loss 0.7359905 Test MSE 6.163878511314672 Test RE 1.1866840234627998\n",
      "98 Train Loss 0.7329946 Test MSE 6.178725698887089 Test RE 1.188112371146632\n",
      "99 Train Loss 0.73055786 Test MSE 6.1766494485951124 Test RE 1.1879127324148675\n",
      "Training time: 123.40\n",
      "4\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.086678 Test MSE 8.147838086013946 Test RE 1.3643608700816776\n",
      "1 Train Loss 43.526093 Test MSE 7.602167370124143 Test RE 1.3178827507209763\n",
      "2 Train Loss 35.443054 Test MSE 7.058467853257568 Test RE 1.2698817471648667\n",
      "3 Train Loss 29.70972 Test MSE 6.658811368343782 Test RE 1.233407021509665\n",
      "4 Train Loss 23.7345 Test MSE 6.630643551544864 Test RE 1.230795504194762\n",
      "5 Train Loss 18.400253 Test MSE 6.014392993765554 Test RE 1.172206058020807\n",
      "6 Train Loss 14.017298 Test MSE 5.515888657475105 Test RE 1.1225761363782627\n",
      "7 Train Loss 11.489267 Test MSE 5.752208087974405 Test RE 1.1463714313014084\n",
      "8 Train Loss 9.34318 Test MSE 5.424369472228995 Test RE 1.1132243361245908\n",
      "9 Train Loss 8.018429 Test MSE 5.357215903800604 Test RE 1.1063120302033227\n",
      "10 Train Loss 6.9929075 Test MSE 5.079248069589452 Test RE 1.0772283448759417\n",
      "11 Train Loss 5.477766 Test MSE 4.808311759608535 Test RE 1.0481039785551256\n",
      "12 Train Loss 4.5963316 Test MSE 4.680304810810027 Test RE 1.034058548538407\n",
      "13 Train Loss 4.1959267 Test MSE 4.4607505553734255 Test RE 1.009513263716984\n",
      "14 Train Loss 3.827347 Test MSE 4.325034427714334 Test RE 0.9940376745567507\n",
      "15 Train Loss 3.4481585 Test MSE 3.8558273197803534 Test RE 0.9385703886257791\n",
      "16 Train Loss 3.1577249 Test MSE 3.5960024557778314 Test RE 0.906396145722242\n",
      "17 Train Loss 2.8894572 Test MSE 3.4703582256772685 Test RE 0.8904206303928031\n",
      "18 Train Loss 2.6705408 Test MSE 3.2710980980267865 Test RE 0.8644797896879091\n",
      "19 Train Loss 2.531765 Test MSE 3.285358249185817 Test RE 0.8663620637659645\n",
      "20 Train Loss 2.3815951 Test MSE 3.0633088968381346 Test RE 0.8365722537237815\n",
      "21 Train Loss 2.2668195 Test MSE 3.025636618496268 Test RE 0.8314122979085111\n",
      "22 Train Loss 2.148136 Test MSE 2.9483794982622884 Test RE 0.8207289477570753\n",
      "23 Train Loss 2.0203733 Test MSE 2.6266542818686114 Test RE 0.7746571216139603\n",
      "24 Train Loss 1.9223754 Test MSE 2.520885440038234 Test RE 0.7589001090464625\n",
      "25 Train Loss 1.8133248 Test MSE 2.267738712996469 Test RE 0.7197879424884419\n",
      "26 Train Loss 1.7092518 Test MSE 2.0278062265357297 Test RE 0.6806459840059358\n",
      "27 Train Loss 1.5956485 Test MSE 1.8800914423042965 Test RE 0.6553865834273944\n",
      "28 Train Loss 1.5269964 Test MSE 1.8027823600189126 Test RE 0.641770440965229\n",
      "29 Train Loss 1.4459625 Test MSE 1.6970269383297036 Test RE 0.6226620948376852\n",
      "30 Train Loss 1.3780318 Test MSE 1.6071836389553138 Test RE 0.6059556114533985\n",
      "31 Train Loss 1.3077201 Test MSE 1.406433834833387 Test RE 0.5668494285555166\n",
      "32 Train Loss 1.2200624 Test MSE 1.2672711300361068 Test RE 0.5380750204887992\n",
      "33 Train Loss 1.0780145 Test MSE 1.1200479651471724 Test RE 0.5058553773169915\n",
      "34 Train Loss 0.92403656 Test MSE 1.0176914138366178 Test RE 0.4821876862522288\n",
      "35 Train Loss 0.8097521 Test MSE 0.8695860253248984 Test RE 0.4457222725985573\n",
      "36 Train Loss 0.68962675 Test MSE 0.7585429642678959 Test RE 0.4162920838862083\n",
      "37 Train Loss 0.62173706 Test MSE 0.7088857279114881 Test RE 0.4024354004188398\n",
      "38 Train Loss 0.55945605 Test MSE 0.6395770366320291 Test RE 0.3822561589207855\n",
      "39 Train Loss 0.49608833 Test MSE 0.5696168374256274 Test RE 0.36074429311620243\n",
      "40 Train Loss 0.43756858 Test MSE 0.45175400723775905 Test RE 0.3212617842772994\n",
      "41 Train Loss 0.38369548 Test MSE 0.3999527670454235 Test RE 0.30228208781867216\n",
      "42 Train Loss 0.32350442 Test MSE 0.36452282308478745 Test RE 0.28858278666279724\n",
      "43 Train Loss 0.28702223 Test MSE 0.318743913678031 Test RE 0.2698540936733456\n",
      "44 Train Loss 0.25989214 Test MSE 0.3057204757939966 Test RE 0.26428366673479664\n",
      "45 Train Loss 0.23044218 Test MSE 0.2695669458891126 Test RE 0.24816548498110577\n",
      "46 Train Loss 0.20969 Test MSE 0.2373951043039713 Test RE 0.23288629917043835\n",
      "47 Train Loss 0.19387056 Test MSE 0.21087172610328625 Test RE 0.2194912626179418\n",
      "48 Train Loss 0.16389623 Test MSE 0.16320711872611848 Test RE 0.19309792598866687\n",
      "49 Train Loss 0.14129315 Test MSE 0.11798012061803671 Test RE 0.16417706148409994\n",
      "50 Train Loss 0.1115091 Test MSE 0.08951168068108376 Test RE 0.14300391131532375\n",
      "51 Train Loss 0.10143938 Test MSE 0.0770696789311669 Test RE 0.13269355674081576\n",
      "52 Train Loss 0.08656046 Test MSE 0.056935449544859 Test RE 0.11405108923064419\n",
      "53 Train Loss 0.07317435 Test MSE 0.03642571003373176 Test RE 0.0912246221739115\n",
      "54 Train Loss 0.061577227 Test MSE 0.031502806633164335 Test RE 0.08483648847080943\n",
      "55 Train Loss 0.054238185 Test MSE 0.02170277871955597 Test RE 0.07041508882700155\n",
      "56 Train Loss 0.04844891 Test MSE 0.019567182596318317 Test RE 0.06686089860220816\n",
      "57 Train Loss 0.04285452 Test MSE 0.02006609716317831 Test RE 0.06770792675122332\n",
      "58 Train Loss 0.03745708 Test MSE 0.017399038624014374 Test RE 0.06304790881412897\n",
      "59 Train Loss 0.035372905 Test MSE 0.0159387455834579 Test RE 0.0603441437797856\n",
      "60 Train Loss 0.031169435 Test MSE 0.015025842695428025 Test RE 0.058590537104830066\n",
      "61 Train Loss 0.027604107 Test MSE 0.01221472763471383 Test RE 0.05282627088343715\n",
      "62 Train Loss 0.024780225 Test MSE 0.013286192199458233 Test RE 0.05509451009435294\n",
      "63 Train Loss 0.02266188 Test MSE 0.012864859332070818 Test RE 0.05421389136833872\n",
      "64 Train Loss 0.020412443 Test MSE 0.009503094596200995 Test RE 0.04659513629919548\n",
      "65 Train Loss 0.018880328 Test MSE 0.00907766513653061 Test RE 0.04554022157621357\n",
      "66 Train Loss 0.017663645 Test MSE 0.007946974673080092 Test RE 0.04260974888434838\n",
      "67 Train Loss 0.01706932 Test MSE 0.007870097976400115 Test RE 0.04240315093617042\n",
      "68 Train Loss 0.015448614 Test MSE 0.006791004194069693 Test RE 0.039389009473551874\n",
      "69 Train Loss 0.014441917 Test MSE 0.005867727217218962 Test RE 0.03661364937058227\n",
      "70 Train Loss 0.013444651 Test MSE 0.006015536655654531 Test RE 0.037071934492744846\n",
      "71 Train Loss 0.012446555 Test MSE 0.004984255797331562 Test RE 0.03374490591559276\n",
      "72 Train Loss 0.011944126 Test MSE 0.005476242261752149 Test RE 0.03537116682193356\n",
      "73 Train Loss 0.011275105 Test MSE 0.005291545352816563 Test RE 0.03476957015280563\n",
      "74 Train Loss 0.010318127 Test MSE 0.0050628574809216615 Test RE 0.03400994357288432\n",
      "75 Train Loss 0.009817388 Test MSE 0.004574871359209008 Test RE 0.03232938950166093\n",
      "76 Train Loss 0.009526563 Test MSE 0.004403514510064908 Test RE 0.031718144706415076\n",
      "77 Train Loss 0.00901229 Test MSE 0.004128950997379631 Test RE 0.030713402032282455\n",
      "78 Train Loss 0.008499725 Test MSE 0.003868624776025662 Test RE 0.029729415085102785\n",
      "79 Train Loss 0.00807993 Test MSE 0.0037921396117920575 Test RE 0.029434063283185485\n",
      "80 Train Loss 0.007467155 Test MSE 0.0034888032492102856 Test RE 0.02823230254194937\n",
      "81 Train Loss 0.007270932 Test MSE 0.0035075352188304425 Test RE 0.028307993062245358\n",
      "82 Train Loss 0.0071188654 Test MSE 0.0034908365420677884 Test RE 0.028240528310720093\n",
      "83 Train Loss 0.0067167957 Test MSE 0.003458143649446265 Test RE 0.028107976069504402\n",
      "84 Train Loss 0.0060859392 Test MSE 0.0035396545414372264 Test RE 0.028437309158157134\n",
      "85 Train Loss 0.0056513874 Test MSE 0.003362306103789844 Test RE 0.027715753158923565\n",
      "86 Train Loss 0.0052619353 Test MSE 0.0032546073572137786 Test RE 0.027268255912929123\n",
      "87 Train Loss 0.004943257 Test MSE 0.0031723393361282955 Test RE 0.026921414729137436\n",
      "88 Train Loss 0.0046676486 Test MSE 0.003046545578530314 Test RE 0.026382254178657017\n",
      "89 Train Loss 0.0043202317 Test MSE 0.0029259251438907645 Test RE 0.025854709699139618\n",
      "90 Train Loss 0.0041369973 Test MSE 0.002833790152055728 Test RE 0.02544438179835973\n",
      "91 Train Loss 0.0040084184 Test MSE 0.0027573477288429793 Test RE 0.025098850370172187\n",
      "92 Train Loss 0.0038247483 Test MSE 0.00247193052616996 Test RE 0.023764363713508038\n",
      "93 Train Loss 0.0036772669 Test MSE 0.002276505907365087 Test RE 0.022805649800210714\n",
      "94 Train Loss 0.003534899 Test MSE 0.0022731173399842424 Test RE 0.022788670432983948\n",
      "95 Train Loss 0.0033479417 Test MSE 0.002186779021706851 Test RE 0.022351697424489066\n",
      "96 Train Loss 0.0031977985 Test MSE 0.0020846812583068005 Test RE 0.021823675292316304\n",
      "97 Train Loss 0.0031223057 Test MSE 0.002109653691073622 Test RE 0.021953999257388057\n",
      "98 Train Loss 0.0030486344 Test MSE 0.0019933679560494616 Test RE 0.021340362708032176\n",
      "99 Train Loss 0.002981681 Test MSE 0.0018407076727845434 Test RE 0.020506921624658375\n",
      "Training time: 123.54\n",
      "5\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.0636 Test MSE 5.532043286879892 Test RE 1.1242188039468952\n",
      "1 Train Loss 52.627808 Test MSE 8.488143027328801 Test RE 1.3925615661509931\n",
      "2 Train Loss 41.100883 Test MSE 7.954050786559872 Test RE 1.3480383269826044\n",
      "3 Train Loss 36.26633 Test MSE 8.780548015151037 Test RE 1.416344405142108\n",
      "4 Train Loss 33.043182 Test MSE 8.78632170056326 Test RE 1.4168099901583684\n",
      "5 Train Loss 30.575489 Test MSE 8.858698036489946 Test RE 1.4226334286754108\n",
      "6 Train Loss 27.685598 Test MSE 8.89390191920286 Test RE 1.4254573517235454\n",
      "7 Train Loss 25.912611 Test MSE 8.638446186405858 Test RE 1.4048368038829164\n",
      "8 Train Loss 23.527426 Test MSE 8.73295262662715 Test RE 1.4125005071109407\n",
      "9 Train Loss 21.947437 Test MSE 8.998249182129781 Test RE 1.433795021533684\n",
      "10 Train Loss 20.39826 Test MSE 8.892491399306993 Test RE 1.4253443127166712\n",
      "11 Train Loss 18.764942 Test MSE 8.787647256448745 Test RE 1.4169168602489821\n",
      "12 Train Loss 17.152172 Test MSE 8.665261091260646 Test RE 1.407015516123131\n",
      "13 Train Loss 15.034672 Test MSE 8.304754306326439 Test RE 1.377436080003455\n",
      "14 Train Loss 12.578873 Test MSE 7.215939097061457 Test RE 1.2839688566594079\n",
      "15 Train Loss 10.2831 Test MSE 7.000964082815319 Test RE 1.2646984464516817\n",
      "16 Train Loss 8.109556 Test MSE 6.046089082526289 Test RE 1.1752907853277772\n",
      "17 Train Loss 5.5667734 Test MSE 5.527952403559906 Test RE 1.1238030535392234\n",
      "18 Train Loss 4.669497 Test MSE 5.224314709336092 Test RE 1.0925032198743696\n",
      "19 Train Loss 4.1667957 Test MSE 5.261125007579512 Test RE 1.0963453294251793\n",
      "20 Train Loss 3.6945603 Test MSE 5.222725752926121 Test RE 1.0923370667896335\n",
      "21 Train Loss 3.3521743 Test MSE 5.022727643352245 Test RE 1.0712180326959317\n",
      "22 Train Loss 3.1527638 Test MSE 4.976132041730606 Test RE 1.0662376360963295\n",
      "23 Train Loss 3.009093 Test MSE 4.9474259766344 Test RE 1.0631577583664622\n",
      "24 Train Loss 2.8417299 Test MSE 4.965531151238316 Test RE 1.0651013022319105\n",
      "25 Train Loss 2.7153146 Test MSE 5.0351731739062915 Test RE 1.0725443666466807\n",
      "26 Train Loss 2.5832934 Test MSE 5.0185514007128855 Test RE 1.070772597759227\n",
      "27 Train Loss 2.5124056 Test MSE 5.016013878956149 Test RE 1.070501857051899\n",
      "28 Train Loss 2.4407969 Test MSE 5.03712756615857 Test RE 1.0727524994120496\n",
      "29 Train Loss 2.3590152 Test MSE 5.054568108587121 Test RE 1.0746080429113143\n",
      "30 Train Loss 2.2693524 Test MSE 5.091557448700295 Test RE 1.0785328674973298\n",
      "31 Train Loss 2.1823752 Test MSE 5.056672476842605 Test RE 1.0748317154075446\n",
      "32 Train Loss 2.1199465 Test MSE 5.127283292228446 Test RE 1.0823101146487684\n",
      "33 Train Loss 2.088118 Test MSE 5.172312943956323 Test RE 1.0870523443712725\n",
      "34 Train Loss 2.058371 Test MSE 5.179875002767592 Test RE 1.08784670382406\n",
      "35 Train Loss 2.007152 Test MSE 5.224026277546495 Test RE 1.0924730611812394\n",
      "36 Train Loss 1.9441743 Test MSE 5.290242268203106 Test RE 1.099374959612377\n",
      "37 Train Loss 1.9170821 Test MSE 5.2577687435257285 Test RE 1.095995574245119\n",
      "38 Train Loss 1.8804958 Test MSE 5.3126438970566205 Test RE 1.1017001624968312\n",
      "39 Train Loss 1.8332815 Test MSE 5.328086112393308 Test RE 1.1033001517629883\n",
      "40 Train Loss 1.8025334 Test MSE 5.312066724206373 Test RE 1.1016403157701684\n",
      "41 Train Loss 1.7607452 Test MSE 5.336623460581807 Test RE 1.104183723010278\n",
      "42 Train Loss 1.7132645 Test MSE 5.379103377479871 Test RE 1.1085697041212699\n",
      "43 Train Loss 1.677178 Test MSE 5.374110180163044 Test RE 1.1080550651536891\n",
      "44 Train Loss 1.6423656 Test MSE 5.344332598556391 Test RE 1.104980971756751\n",
      "45 Train Loss 1.6015725 Test MSE 5.31641460223051 Test RE 1.1020910648164017\n",
      "46 Train Loss 1.5664985 Test MSE 5.324790899765956 Test RE 1.102958925025148\n",
      "47 Train Loss 1.5324957 Test MSE 5.345941820049193 Test RE 1.105147318560748\n",
      "48 Train Loss 1.5022796 Test MSE 5.347712565982409 Test RE 1.1053303333748687\n",
      "49 Train Loss 1.4785464 Test MSE 5.347087755852114 Test RE 1.1052657598067506\n",
      "50 Train Loss 1.4515655 Test MSE 5.387118770390964 Test RE 1.1093953355951363\n",
      "51 Train Loss 1.4285604 Test MSE 5.386937268718857 Test RE 1.1093766466806096\n",
      "52 Train Loss 1.4018517 Test MSE 5.388117867424223 Test RE 1.1094982052597695\n",
      "53 Train Loss 1.3806224 Test MSE 5.3873943686247365 Test RE 1.1094237128685698\n",
      "54 Train Loss 1.3691999 Test MSE 5.407309629446378 Test RE 1.1114723916847757\n",
      "55 Train Loss 1.3466277 Test MSE 5.422400865893381 Test RE 1.1130223127039325\n",
      "56 Train Loss 1.3310893 Test MSE 5.434100305939441 Test RE 1.1142224011647834\n",
      "57 Train Loss 1.3017981 Test MSE 5.449782183685434 Test RE 1.115828969921485\n",
      "58 Train Loss 1.2731578 Test MSE 5.503264299323622 Test RE 1.1212907658591051\n",
      "59 Train Loss 1.2585069 Test MSE 5.506983068937165 Test RE 1.121669551758842\n",
      "60 Train Loss 1.2459999 Test MSE 5.513811155807384 Test RE 1.1223647131990633\n",
      "61 Train Loss 1.2294605 Test MSE 5.515779839580229 Test RE 1.1225650631875166\n",
      "62 Train Loss 1.2153604 Test MSE 5.5006903456114955 Test RE 1.1210285135008369\n",
      "63 Train Loss 1.204121 Test MSE 5.517213245362777 Test RE 1.1227109162466609\n",
      "64 Train Loss 1.1921638 Test MSE 5.546886954472264 Test RE 1.125726054549662\n",
      "65 Train Loss 1.1787338 Test MSE 5.5481566846138275 Test RE 1.125854891366152\n",
      "66 Train Loss 1.1656914 Test MSE 5.582881538233142 Test RE 1.129372651132223\n",
      "67 Train Loss 1.1558981 Test MSE 5.609547655406771 Test RE 1.1320666100956698\n",
      "68 Train Loss 1.1433661 Test MSE 5.638346510293054 Test RE 1.1349688481155638\n",
      "69 Train Loss 1.1369107 Test MSE 5.6471172822690585 Test RE 1.1358512597176864\n",
      "70 Train Loss 1.1273705 Test MSE 5.648527144568765 Test RE 1.1359930394833946\n",
      "71 Train Loss 1.118218 Test MSE 5.6577692257923085 Test RE 1.1369220116391587\n",
      "72 Train Loss 1.1118718 Test MSE 5.672093784230567 Test RE 1.1383603533117903\n",
      "73 Train Loss 1.1025729 Test MSE 5.690989313597961 Test RE 1.1402548950808093\n",
      "74 Train Loss 1.0964497 Test MSE 5.687542795222055 Test RE 1.13990956807257\n",
      "75 Train Loss 1.0890847 Test MSE 5.692490681254784 Test RE 1.1404052932656976\n",
      "76 Train Loss 1.0830021 Test MSE 5.710471513888492 Test RE 1.1422049685560611\n",
      "77 Train Loss 1.0772094 Test MSE 5.727297668649911 Test RE 1.1438865093007162\n",
      "78 Train Loss 1.0689834 Test MSE 5.755568741693779 Test RE 1.146706258798779\n",
      "79 Train Loss 1.0621164 Test MSE 5.762227539136864 Test RE 1.1473693972159074\n",
      "80 Train Loss 1.0549088 Test MSE 5.771967846139965 Test RE 1.1483387281995916\n",
      "81 Train Loss 1.0475799 Test MSE 5.7950471442318685 Test RE 1.1506322624281495\n",
      "82 Train Loss 1.0406239 Test MSE 5.806985638264555 Test RE 1.151816873050102\n",
      "83 Train Loss 1.0358862 Test MSE 5.818430636709688 Test RE 1.1529513733021102\n",
      "84 Train Loss 1.0294503 Test MSE 5.830580883092365 Test RE 1.1541545617923405\n",
      "85 Train Loss 1.0243363 Test MSE 5.852974870197848 Test RE 1.156368865402053\n",
      "86 Train Loss 1.0187501 Test MSE 5.875536176370347 Test RE 1.1585954339086564\n",
      "87 Train Loss 1.014121 Test MSE 5.875869675952906 Test RE 1.1586283147895806\n",
      "88 Train Loss 1.0077267 Test MSE 5.870735105634069 Test RE 1.1581219762317665\n",
      "89 Train Loss 1.0036954 Test MSE 5.885341166284004 Test RE 1.1595617526244937\n",
      "90 Train Loss 0.9965368 Test MSE 5.91415567246385 Test RE 1.1623968816167556\n",
      "91 Train Loss 0.98937744 Test MSE 5.930423155566505 Test RE 1.1639944288883572\n",
      "92 Train Loss 0.9829879 Test MSE 5.936312337894096 Test RE 1.164572235417371\n",
      "93 Train Loss 0.97663987 Test MSE 5.931285066084517 Test RE 1.1640790116040254\n",
      "94 Train Loss 0.971305 Test MSE 5.944753240866249 Test RE 1.1653998998668718\n",
      "95 Train Loss 0.96600676 Test MSE 5.958436085749207 Test RE 1.1667403105084928\n",
      "96 Train Loss 0.9588702 Test MSE 5.985441101665064 Test RE 1.1693812905124643\n",
      "97 Train Loss 0.9534345 Test MSE 5.976129151723571 Test RE 1.1684712942044253\n",
      "98 Train Loss 0.9465861 Test MSE 5.992601172507475 Test RE 1.1700805163702188\n",
      "99 Train Loss 0.94044274 Test MSE 6.023324000029976 Test RE 1.1730760623664054\n",
      "Training time: 123.22\n",
      "6\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 64.92072 Test MSE 7.417225758389886 Test RE 1.3017536653862911\n",
      "1 Train Loss 46.946243 Test MSE 8.620165645288663 Test RE 1.4033495701072878\n",
      "2 Train Loss 36.533493 Test MSE 8.90424815894507 Test RE 1.4262862250921842\n",
      "3 Train Loss 30.24406 Test MSE 8.753422541349561 Test RE 1.414154978549645\n",
      "4 Train Loss 27.648907 Test MSE 9.067006118206935 Test RE 1.439262515503064\n",
      "5 Train Loss 25.518919 Test MSE 9.005803529191223 Test RE 1.4343967559716773\n",
      "6 Train Loss 23.663788 Test MSE 9.013788624397781 Test RE 1.435032526940911\n",
      "7 Train Loss 22.163313 Test MSE 9.041081648820523 Test RE 1.437203466158576\n",
      "8 Train Loss 20.428518 Test MSE 9.075918801237673 Test RE 1.439969724676633\n",
      "9 Train Loss 19.130226 Test MSE 9.08890495599997 Test RE 1.4409995369659636\n",
      "10 Train Loss 17.056313 Test MSE 8.672691149088278 Test RE 1.4076186120079819\n",
      "11 Train Loss 15.500679 Test MSE 8.27819962499624 Test RE 1.375232121828415\n",
      "12 Train Loss 13.29397 Test MSE 7.844682262083178 Test RE 1.3387384567930887\n",
      "13 Train Loss 10.733599 Test MSE 6.545546924282159 Test RE 1.2228720830132942\n",
      "14 Train Loss 8.563349 Test MSE 5.796915371032586 Test RE 1.1508177198327791\n",
      "15 Train Loss 5.393189 Test MSE 5.159968298284611 Test RE 1.0857543474591214\n",
      "16 Train Loss 4.207761 Test MSE 5.066985982649951 Test RE 1.0759272615998492\n",
      "17 Train Loss 3.5525613 Test MSE 5.315148130317176 Test RE 1.1019597873842881\n",
      "18 Train Loss 2.999506 Test MSE 5.283947034013414 Test RE 1.0987206528148443\n",
      "19 Train Loss 2.6225333 Test MSE 5.331462932809297 Test RE 1.103649719720247\n",
      "20 Train Loss 2.4139824 Test MSE 5.29828839014459 Test RE 1.1002106816505077\n",
      "21 Train Loss 2.2834747 Test MSE 5.20897801803859 Test RE 1.0908984448395525\n",
      "22 Train Loss 2.1507044 Test MSE 5.175866552081886 Test RE 1.0874257068116089\n",
      "23 Train Loss 2.0591242 Test MSE 5.164586445786917 Test RE 1.0862401113266784\n",
      "24 Train Loss 1.9708083 Test MSE 5.1920772396309305 Test RE 1.0891272709080464\n",
      "25 Train Loss 1.8930267 Test MSE 5.20223282166813 Test RE 1.0901919043382968\n",
      "26 Train Loss 1.8295014 Test MSE 5.220717393373417 Test RE 1.0921270216302634\n",
      "27 Train Loss 1.7746123 Test MSE 5.249981551174832 Test RE 1.0951836432462765\n",
      "28 Train Loss 1.7176292 Test MSE 5.286892958670419 Test RE 1.099026891430255\n",
      "29 Train Loss 1.6827174 Test MSE 5.325469680311313 Test RE 1.1030292229220104\n",
      "30 Train Loss 1.6510143 Test MSE 5.38497527612498 Test RE 1.1091746035828713\n",
      "31 Train Loss 1.6155367 Test MSE 5.394908849559929 Test RE 1.1101971701019755\n",
      "32 Train Loss 1.5751423 Test MSE 5.4383148904560965 Test RE 1.1146544022357672\n",
      "33 Train Loss 1.5424472 Test MSE 5.486081275238175 Test RE 1.1195388756771503\n",
      "34 Train Loss 1.512476 Test MSE 5.451652462980254 Test RE 1.1160204209493043\n",
      "35 Train Loss 1.4864056 Test MSE 5.484047923465398 Test RE 1.1193313844630945\n",
      "36 Train Loss 1.4652057 Test MSE 5.540714429677518 Test RE 1.125099531403084\n",
      "37 Train Loss 1.4366739 Test MSE 5.536013643208564 Test RE 1.1246221584060696\n",
      "38 Train Loss 1.4121733 Test MSE 5.603008247099415 Test RE 1.1314065564639968\n",
      "39 Train Loss 1.3785319 Test MSE 5.679932225440694 Test RE 1.1391466493817122\n",
      "40 Train Loss 1.3429072 Test MSE 5.660067804544132 Test RE 1.1371529365232946\n",
      "41 Train Loss 1.3097059 Test MSE 5.67796892235056 Test RE 1.138949755884961\n",
      "42 Train Loss 1.272788 Test MSE 5.66631795288406 Test RE 1.1377806157120436\n",
      "43 Train Loss 1.2388353 Test MSE 5.754118759987819 Test RE 1.1465618067120238\n",
      "44 Train Loss 1.2154399 Test MSE 5.771906236709949 Test RE 1.1483325995546314\n",
      "45 Train Loss 1.1852515 Test MSE 5.762327506040678 Test RE 1.147379349831274\n",
      "46 Train Loss 1.1562556 Test MSE 5.841133147576412 Test RE 1.1551984919780027\n",
      "47 Train Loss 1.1312802 Test MSE 5.852675986770493 Test RE 1.156339339912038\n",
      "48 Train Loss 1.1179365 Test MSE 5.899399245818435 Test RE 1.1609458260349264\n",
      "49 Train Loss 1.0978864 Test MSE 5.892232275430547 Test RE 1.1602404158223272\n",
      "50 Train Loss 1.0748627 Test MSE 5.919589756273435 Test RE 1.162930779617947\n",
      "51 Train Loss 1.047296 Test MSE 5.934577183729785 Test RE 1.1644020236822494\n",
      "52 Train Loss 1.029547 Test MSE 5.904903841049723 Test RE 1.1614873258190979\n",
      "53 Train Loss 1.01524 Test MSE 5.934651487530823 Test RE 1.1644093131000801\n",
      "54 Train Loss 1.0035421 Test MSE 5.934576946555844 Test RE 1.1644020004147266\n",
      "55 Train Loss 0.9958652 Test MSE 5.932694134112203 Test RE 1.1642172758328235\n",
      "56 Train Loss 0.9822605 Test MSE 5.922920170188098 Test RE 1.1632578712248864\n",
      "57 Train Loss 0.9714565 Test MSE 5.9378854351950805 Test RE 1.164726528519307\n",
      "58 Train Loss 0.9619447 Test MSE 5.929566060363026 Test RE 1.1639103126233934\n",
      "59 Train Loss 0.9509388 Test MSE 5.944562121538925 Test RE 1.1653811663529572\n",
      "60 Train Loss 0.9386685 Test MSE 5.965174310552295 Test RE 1.1673998407092367\n",
      "61 Train Loss 0.9300184 Test MSE 5.9624838634085116 Test RE 1.1671365473307065\n",
      "62 Train Loss 0.9199496 Test MSE 5.947638014182802 Test RE 1.1656826287408175\n",
      "63 Train Loss 0.91023964 Test MSE 5.966729261722386 Test RE 1.1675519847517413\n",
      "64 Train Loss 0.9001949 Test MSE 5.976060335537352 Test RE 1.1684645666080482\n",
      "65 Train Loss 0.8933454 Test MSE 5.992026875533173 Test RE 1.1700244480802389\n",
      "66 Train Loss 0.8844745 Test MSE 5.996107516310619 Test RE 1.1704227804797094\n",
      "67 Train Loss 0.8767477 Test MSE 6.015239361983297 Test RE 1.1722885337629128\n",
      "68 Train Loss 0.8698043 Test MSE 6.0118665972211005 Test RE 1.1719598346364133\n",
      "69 Train Loss 0.8612443 Test MSE 6.048195893471626 Test RE 1.1754955375062852\n",
      "70 Train Loss 0.8533684 Test MSE 6.059103563453262 Test RE 1.176555038708951\n",
      "71 Train Loss 0.8470837 Test MSE 6.088101083926808 Test RE 1.1793670435332602\n",
      "72 Train Loss 0.83905536 Test MSE 6.120936853511963 Test RE 1.1825431856956887\n",
      "73 Train Loss 0.8313831 Test MSE 6.135528682630994 Test RE 1.18395189132576\n",
      "74 Train Loss 0.8256855 Test MSE 6.131819760872335 Test RE 1.183593988284666\n",
      "75 Train Loss 0.819592 Test MSE 6.132924584622469 Test RE 1.1837006127372598\n",
      "76 Train Loss 0.8138294 Test MSE 6.136379109590095 Test RE 1.184033940467044\n",
      "77 Train Loss 0.80752116 Test MSE 6.150294034230342 Test RE 1.1853756448490014\n",
      "78 Train Loss 0.8022597 Test MSE 6.171149270041868 Test RE 1.1873837087609722\n",
      "79 Train Loss 0.79581153 Test MSE 6.18251809973852 Test RE 1.1884769371917392\n",
      "80 Train Loss 0.7909354 Test MSE 6.1860284791674 Test RE 1.1888142926904084\n",
      "81 Train Loss 0.78684366 Test MSE 6.184549925155192 Test RE 1.1886722119360555\n",
      "82 Train Loss 0.7817922 Test MSE 6.192046393425083 Test RE 1.189392405401359\n",
      "83 Train Loss 0.77759755 Test MSE 6.2001516493490145 Test RE 1.1901705954006132\n",
      "84 Train Loss 0.7735706 Test MSE 6.206738893291158 Test RE 1.1908026656498694\n",
      "85 Train Loss 0.7707133 Test MSE 6.209350630728185 Test RE 1.191053178588536\n",
      "86 Train Loss 0.7678194 Test MSE 6.201992116405449 Test RE 1.1903472287609216\n",
      "87 Train Loss 0.76425016 Test MSE 6.190537526898848 Test RE 1.1892474820904961\n",
      "88 Train Loss 0.7593729 Test MSE 6.223498713150078 Test RE 1.1924093212506655\n",
      "89 Train Loss 0.7556319 Test MSE 6.214568743648845 Test RE 1.1915535324236353\n",
      "90 Train Loss 0.7502883 Test MSE 6.267107187513685 Test RE 1.196579674702024\n",
      "91 Train Loss 0.74742544 Test MSE 6.263996445186695 Test RE 1.1962826706027425\n",
      "92 Train Loss 0.74477255 Test MSE 6.263349286773924 Test RE 1.196220872643711\n",
      "93 Train Loss 0.74192595 Test MSE 6.263033681994594 Test RE 1.1961907339939835\n",
      "94 Train Loss 0.73816407 Test MSE 6.2726168003108 Test RE 1.1971055347333721\n",
      "95 Train Loss 0.7349455 Test MSE 6.287198897622646 Test RE 1.1984961964348018\n",
      "96 Train Loss 0.7334996 Test MSE 6.283583346996362 Test RE 1.1981515400230085\n",
      "97 Train Loss 0.7306977 Test MSE 6.300472166679112 Test RE 1.1997606367311524\n",
      "98 Train Loss 0.72892344 Test MSE 6.297561149774457 Test RE 1.1994834410774067\n",
      "99 Train Loss 0.72689754 Test MSE 6.288376233588464 Test RE 1.198608405913848\n",
      "Training time: 122.65\n",
      "7\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.6573 Test MSE 5.3760460157099805 Test RE 1.1082546162588498\n",
      "1 Train Loss 49.036186 Test MSE 7.449587024147817 Test RE 1.3045903423605718\n",
      "2 Train Loss 33.345848 Test MSE 7.407420700955812 Test RE 1.3008929668674194\n",
      "3 Train Loss 26.656841 Test MSE 5.842618149613368 Test RE 1.1553453267660727\n",
      "4 Train Loss 21.115177 Test MSE 6.210263004283006 Test RE 1.1911406793250812\n",
      "5 Train Loss 16.636269 Test MSE 6.194414369547256 Test RE 1.1896198087039096\n",
      "6 Train Loss 13.624201 Test MSE 5.95067150278317 Test RE 1.1659798588507284\n",
      "7 Train Loss 12.415487 Test MSE 5.957174454132459 Test RE 1.1666167819205377\n",
      "8 Train Loss 11.090502 Test MSE 5.917836386373193 Test RE 1.162758538050391\n",
      "9 Train Loss 10.0572605 Test MSE 5.7758852660914295 Test RE 1.14872834939459\n",
      "10 Train Loss 9.258086 Test MSE 5.559480840415814 Test RE 1.1270032779371255\n",
      "11 Train Loss 8.13408 Test MSE 5.577270762003971 Test RE 1.1288050007117825\n",
      "12 Train Loss 7.1384125 Test MSE 5.326692130227269 Test RE 1.1031558146303693\n",
      "13 Train Loss 6.204315 Test MSE 5.113380187946664 Test RE 1.0808417264168888\n",
      "14 Train Loss 5.311634 Test MSE 4.49572334182105 Test RE 1.013462886267964\n",
      "15 Train Loss 4.43718 Test MSE 3.849003929359426 Test RE 0.9377395594082151\n",
      "16 Train Loss 3.3429272 Test MSE 2.8329341914819084 Test RE 0.8045004721376455\n",
      "17 Train Loss 2.7110338 Test MSE 2.5672477809339487 Test RE 0.7658468913432152\n",
      "18 Train Loss 2.1896026 Test MSE 2.1255464978686343 Test RE 0.6968565159073704\n",
      "19 Train Loss 1.9264615 Test MSE 1.7663534918826034 Test RE 0.6352532138414844\n",
      "20 Train Loss 1.6668775 Test MSE 1.3721819173006684 Test RE 0.5599044332737025\n",
      "21 Train Loss 1.2714093 Test MSE 0.9574784162274282 Test RE 0.4677055857399168\n",
      "22 Train Loss 0.8050786 Test MSE 0.7949545957013476 Test RE 0.42616641626953966\n",
      "23 Train Loss 0.51420873 Test MSE 0.6721480702372636 Test RE 0.3918686658632767\n",
      "24 Train Loss 0.42129105 Test MSE 0.594527652587382 Test RE 0.36854802644158985\n",
      "25 Train Loss 0.35396165 Test MSE 0.5368521015267106 Test RE 0.3502155206886266\n",
      "26 Train Loss 0.30283147 Test MSE 0.5083754358149926 Test RE 0.34080059093095993\n",
      "27 Train Loss 0.23989579 Test MSE 0.4480553321187441 Test RE 0.3199439375049116\n",
      "28 Train Loss 0.20115077 Test MSE 0.38619701276929497 Test RE 0.29703834424561665\n",
      "29 Train Loss 0.18238033 Test MSE 0.3681080177604591 Test RE 0.289998464740393\n",
      "30 Train Loss 0.17016715 Test MSE 0.336330979892023 Test RE 0.27719889619124427\n",
      "31 Train Loss 0.16055673 Test MSE 0.2816327057301371 Test RE 0.25365860754780145\n",
      "32 Train Loss 0.15023723 Test MSE 0.20251162374164808 Test RE 0.2150963486933746\n",
      "33 Train Loss 0.13384208 Test MSE 0.13021508906041684 Test RE 0.17247998924877453\n",
      "34 Train Loss 0.11429583 Test MSE 0.1050416087346721 Test RE 0.15491331320428095\n",
      "35 Train Loss 0.09258835 Test MSE 0.09273672609394742 Test RE 0.14555728294286097\n",
      "36 Train Loss 0.08117228 Test MSE 0.09011425076008789 Test RE 0.14348443712535155\n",
      "37 Train Loss 0.07135754 Test MSE 0.07714736134035692 Test RE 0.1327604141557294\n",
      "38 Train Loss 0.05778586 Test MSE 0.058247416334178154 Test RE 0.11535764817533084\n",
      "39 Train Loss 0.05192094 Test MSE 0.05474206329561048 Test RE 0.11183265654120082\n",
      "40 Train Loss 0.045943305 Test MSE 0.05165268591428243 Test RE 0.10863118449978601\n",
      "41 Train Loss 0.040075712 Test MSE 0.04110249502930094 Test RE 0.0969041001432591\n",
      "42 Train Loss 0.03506803 Test MSE 0.037947302071318495 Test RE 0.09311046863140038\n",
      "43 Train Loss 0.032840043 Test MSE 0.03569877082812225 Test RE 0.09030976074189435\n",
      "44 Train Loss 0.029225372 Test MSE 0.03265309828366912 Test RE 0.08637145944007166\n",
      "45 Train Loss 0.025523523 Test MSE 0.025981386905330434 Test RE 0.07704407146854898\n",
      "46 Train Loss 0.023360983 Test MSE 0.023015773216982175 Test RE 0.07251383016895072\n",
      "47 Train Loss 0.02071269 Test MSE 0.019318476729064615 Test RE 0.06643462682410776\n",
      "48 Train Loss 0.01985661 Test MSE 0.018907606639534707 Test RE 0.06572435602565617\n",
      "49 Train Loss 0.018341944 Test MSE 0.01601363494098764 Test RE 0.0604857433240788\n",
      "50 Train Loss 0.0160946 Test MSE 0.014013162975807118 Test RE 0.0565817202000908\n",
      "51 Train Loss 0.015133747 Test MSE 0.014899268177396384 Test RE 0.05834323806397651\n",
      "52 Train Loss 0.014335698 Test MSE 0.015135900095547073 Test RE 0.05880472001663253\n",
      "53 Train Loss 0.012766719 Test MSE 0.014543564311302272 Test RE 0.057642590239687166\n",
      "54 Train Loss 0.012139527 Test MSE 0.013947807703581732 Test RE 0.05644962170653894\n",
      "55 Train Loss 0.01092014 Test MSE 0.01312111352256326 Test RE 0.05475117032064476\n",
      "56 Train Loss 0.010337258 Test MSE 0.012682143345216324 Test RE 0.0538275222467171\n",
      "57 Train Loss 0.0100141335 Test MSE 0.01252580708876722 Test RE 0.053494720121657936\n",
      "58 Train Loss 0.009747586 Test MSE 0.01221749649327722 Test RE 0.05283225792583036\n",
      "59 Train Loss 0.009157922 Test MSE 0.012493029056361257 Test RE 0.05342468071077454\n",
      "60 Train Loss 0.008797039 Test MSE 0.01202220589874992 Test RE 0.05240830828455763\n",
      "61 Train Loss 0.008412427 Test MSE 0.011085783827258926 Test RE 0.05032586671604322\n",
      "62 Train Loss 0.007943651 Test MSE 0.01039782115640904 Test RE 0.0487392937607374\n",
      "63 Train Loss 0.0074769882 Test MSE 0.009757781616579664 Test RE 0.04721539283258095\n",
      "64 Train Loss 0.0072126905 Test MSE 0.009143555098278815 Test RE 0.045705198916994885\n",
      "65 Train Loss 0.0068146363 Test MSE 0.008681044659006557 Test RE 0.04453424104984204\n",
      "66 Train Loss 0.0064430195 Test MSE 0.007603444439385672 Test RE 0.04167861211565639\n",
      "67 Train Loss 0.006218211 Test MSE 0.007530575324529101 Test RE 0.04147841368590302\n",
      "68 Train Loss 0.005522537 Test MSE 0.006939012998534574 Test RE 0.03981593427130476\n",
      "69 Train Loss 0.0052206153 Test MSE 0.006162274094447229 Test RE 0.037521359536190624\n",
      "70 Train Loss 0.0050978125 Test MSE 0.006367346489069599 Test RE 0.03814058078206723\n",
      "71 Train Loss 0.0048952205 Test MSE 0.006179616161213098 Test RE 0.03757411934138896\n",
      "72 Train Loss 0.0047397204 Test MSE 0.006037151952631581 Test RE 0.03713847904015802\n",
      "73 Train Loss 0.0045169364 Test MSE 0.005595488395009235 Test RE 0.035754199572518644\n",
      "74 Train Loss 0.0042822445 Test MSE 0.005455317871312031 Test RE 0.03530352660333589\n",
      "75 Train Loss 0.0039929408 Test MSE 0.004797919904029944 Test RE 0.033108122780087706\n",
      "76 Train Loss 0.0038291535 Test MSE 0.0044696666242118235 Test RE 0.031955500662731263\n",
      "77 Train Loss 0.003746924 Test MSE 0.004153123419041136 Test RE 0.03080317469815709\n",
      "78 Train Loss 0.0036188634 Test MSE 0.003919050148363147 Test RE 0.029922540995846774\n",
      "79 Train Loss 0.0035543602 Test MSE 0.0036448651536257638 Test RE 0.028856841438771832\n",
      "80 Train Loss 0.0034345132 Test MSE 0.0033548514560332488 Test RE 0.027685011486619088\n",
      "81 Train Loss 0.003245792 Test MSE 0.003025736054819294 Test RE 0.02629199738793168\n",
      "82 Train Loss 0.0030565425 Test MSE 0.0026764857890863064 Test RE 0.024728087635915986\n",
      "83 Train Loss 0.0029481885 Test MSE 0.002626766958473057 Test RE 0.024497334518613332\n",
      "84 Train Loss 0.002862413 Test MSE 0.002575677097018794 Test RE 0.02425793167003811\n",
      "85 Train Loss 0.0027460805 Test MSE 0.0025764649987415696 Test RE 0.024261641646870825\n",
      "86 Train Loss 0.0026289753 Test MSE 0.002378229013858274 Test RE 0.023309604072400233\n",
      "87 Train Loss 0.0025240346 Test MSE 0.0019826453643298977 Test RE 0.02128288898751778\n",
      "88 Train Loss 0.0024380437 Test MSE 0.0019011949776388743 Test RE 0.02084113608833203\n",
      "89 Train Loss 0.0023929041 Test MSE 0.0016998846848679582 Test RE 0.019706876314213414\n",
      "90 Train Loss 0.0023083172 Test MSE 0.0017412202202663153 Test RE 0.019945039980410695\n",
      "91 Train Loss 0.002247165 Test MSE 0.0014648344924397313 Test RE 0.018293733124400607\n",
      "92 Train Loss 0.0021912581 Test MSE 0.00134434617885299 Test RE 0.017525225661755194\n",
      "93 Train Loss 0.0021460098 Test MSE 0.0012814771886557627 Test RE 0.01711053150189057\n",
      "94 Train Loss 0.0021186634 Test MSE 0.001251611144639069 Test RE 0.01690996742782019\n",
      "95 Train Loss 0.0020881728 Test MSE 0.0012563833430092254 Test RE 0.016942174293220136\n",
      "96 Train Loss 0.0020164256 Test MSE 0.001131668103366246 Test RE 0.01607931702211234\n",
      "97 Train Loss 0.0019794183 Test MSE 0.0011587851654754242 Test RE 0.016270823112450532\n",
      "98 Train Loss 0.0018509185 Test MSE 0.0010257904502435826 Test RE 0.015308667348034943\n",
      "99 Train Loss 0.0018082353 Test MSE 0.0009342748721763284 Test RE 0.014609837803830942\n",
      "Training time: 122.42\n",
      "8\n",
      "KG_rowdy_tune42\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.28\n",
      "0\n",
      "KG_rowdy_tune43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.18711 Test MSE 4.431545013899917 Test RE 1.0062030810085023\n",
      "1 Train Loss 49.695904 Test MSE 5.380648971828152 Test RE 1.1087289570569134\n",
      "2 Train Loss 29.918842 Test MSE 5.4604502113851 Test RE 1.1169205616805027\n",
      "3 Train Loss 21.119852 Test MSE 4.617061304878533 Test RE 1.0270483301922015\n",
      "4 Train Loss 18.59917 Test MSE 4.641173254056635 Test RE 1.0297266452347367\n",
      "5 Train Loss 16.24869 Test MSE 5.129035579893888 Test RE 1.0824950426648638\n",
      "6 Train Loss 14.622732 Test MSE 5.34135675920395 Test RE 1.104673290332757\n",
      "7 Train Loss 13.310397 Test MSE 5.460823164957753 Test RE 1.1169587043596882\n",
      "8 Train Loss 12.289887 Test MSE 5.234264326772637 Test RE 1.0935430518127243\n",
      "9 Train Loss 11.198025 Test MSE 5.123719558973543 Test RE 1.081933917862201\n",
      "10 Train Loss 10.0974865 Test MSE 5.35348909825401 Test RE 1.105927154253934\n",
      "11 Train Loss 9.354927 Test MSE 5.225457729850841 Test RE 1.0926227269644309\n",
      "12 Train Loss 8.273741 Test MSE 5.17158450488604 Test RE 1.086975794548245\n",
      "13 Train Loss 7.7455435 Test MSE 4.820711298485462 Test RE 1.0494545189350544\n",
      "14 Train Loss 6.6530027 Test MSE 4.450472408298487 Test RE 1.008349568343903\n",
      "15 Train Loss 5.861573 Test MSE 4.353588121653201 Test RE 0.9973135739075767\n",
      "16 Train Loss 5.2081394 Test MSE 4.484914164189452 Test RE 1.0122438062536294\n",
      "17 Train Loss 4.451853 Test MSE 4.474197343072157 Test RE 1.0110336912355202\n",
      "18 Train Loss 4.154932 Test MSE 4.5955989994351265 Test RE 1.0246584441135438\n",
      "19 Train Loss 3.8282804 Test MSE 4.719150584117403 Test RE 1.0383409405027009\n",
      "20 Train Loss 3.596686 Test MSE 4.778635598026788 Test RE 1.0448646042100698\n",
      "21 Train Loss 3.2569978 Test MSE 4.614877545658952 Test RE 1.0268054168567071\n",
      "22 Train Loss 3.0051606 Test MSE 4.447601401215234 Test RE 1.0080242718891652\n",
      "23 Train Loss 2.823698 Test MSE 4.4356982465994825 Test RE 1.0066744760691304\n",
      "24 Train Loss 2.6445248 Test MSE 4.277076637893624 Test RE 0.9885111591253158\n",
      "25 Train Loss 2.42726 Test MSE 4.2514750373671095 Test RE 0.9855482179737758\n",
      "26 Train Loss 2.351842 Test MSE 4.149943536472224 Test RE 0.9737089326711564\n",
      "27 Train Loss 2.227046 Test MSE 4.09070468153642 Test RE 0.9667342920399119\n",
      "28 Train Loss 2.1177623 Test MSE 4.0093664401600275 Test RE 0.9570749198849399\n",
      "29 Train Loss 1.9561807 Test MSE 3.8901715238150243 Test RE 0.9427410878509098\n",
      "30 Train Loss 1.8388058 Test MSE 3.7844270930908075 Test RE 0.92983980082782\n",
      "31 Train Loss 1.7465931 Test MSE 3.6783546245688057 Test RE 0.9167160995330054\n",
      "32 Train Loss 1.6414325 Test MSE 3.6870392311679865 Test RE 0.9177976462929563\n",
      "33 Train Loss 1.5619645 Test MSE 3.5856442258543932 Test RE 0.9050897741996681\n",
      "34 Train Loss 1.509857 Test MSE 3.591497043141827 Test RE 0.905828158268347\n",
      "35 Train Loss 1.4322857 Test MSE 3.5094514398499213 Test RE 0.8954218319105911\n",
      "36 Train Loss 1.3145009 Test MSE 3.4955022773632543 Test RE 0.8936405249054702\n",
      "37 Train Loss 1.271922 Test MSE 3.4203742067295293 Test RE 0.8839849510369198\n",
      "38 Train Loss 1.2085037 Test MSE 3.386028544772967 Test RE 0.8795354889151299\n",
      "39 Train Loss 1.162926 Test MSE 3.3613541334436796 Test RE 0.8763249871151514\n",
      "40 Train Loss 1.1125504 Test MSE 3.3036865953242986 Test RE 0.8687753316256309\n",
      "41 Train Loss 1.0778133 Test MSE 3.276750421235329 Test RE 0.8652263601077231\n",
      "42 Train Loss 1.0530733 Test MSE 3.312190054260097 Test RE 0.8698926966454645\n",
      "43 Train Loss 1.0277263 Test MSE 3.2506650301029647 Test RE 0.8617755532304627\n",
      "44 Train Loss 0.9963694 Test MSE 3.2624112013697317 Test RE 0.8633311480464382\n",
      "45 Train Loss 0.9694587 Test MSE 3.2978007904518543 Test RE 0.8680010872362517\n",
      "46 Train Loss 0.94375575 Test MSE 3.264285623065293 Test RE 0.8635791263299711\n",
      "47 Train Loss 0.92631525 Test MSE 3.2481753386236645 Test RE 0.8614454721223137\n",
      "48 Train Loss 0.9062733 Test MSE 3.2364772154952863 Test RE 0.8598928489216344\n",
      "49 Train Loss 0.883795 Test MSE 3.2222796454839258 Test RE 0.8580047146475415\n",
      "50 Train Loss 0.8621853 Test MSE 3.249815709625919 Test RE 0.8616629652781597\n",
      "51 Train Loss 0.8304747 Test MSE 3.3162649619475117 Test RE 0.8704276361868449\n",
      "52 Train Loss 0.8073169 Test MSE 3.2958233396359833 Test RE 0.8677408097136233\n",
      "53 Train Loss 0.78531635 Test MSE 3.2933289493010887 Test RE 0.8674123797949671\n",
      "54 Train Loss 0.7668576 Test MSE 3.275013354905286 Test RE 0.8649969934145421\n",
      "55 Train Loss 0.75184333 Test MSE 3.24310982341016 Test RE 0.8607734998153135\n",
      "56 Train Loss 0.73167 Test MSE 3.2267945464696455 Test RE 0.8586056014048495\n",
      "57 Train Loss 0.71451867 Test MSE 3.221281967665581 Test RE 0.8578718772411671\n",
      "58 Train Loss 0.6986636 Test MSE 3.2511816830336784 Test RE 0.8618440347828801\n",
      "59 Train Loss 0.6801053 Test MSE 3.2446987404533814 Test RE 0.8609843360617762\n",
      "60 Train Loss 0.65801287 Test MSE 3.2604303832884463 Test RE 0.8630690165278372\n",
      "61 Train Loss 0.64279234 Test MSE 3.248289897957973 Test RE 0.8614606630740662\n",
      "62 Train Loss 0.6321325 Test MSE 3.271932097171745 Test RE 0.8645899865445479\n",
      "63 Train Loss 0.6162158 Test MSE 3.2929191268186626 Test RE 0.8673584076348683\n",
      "64 Train Loss 0.59975696 Test MSE 3.309303087621082 Test RE 0.8695135066492163\n",
      "65 Train Loss 0.591636 Test MSE 3.2807838050397025 Test RE 0.8657587040912212\n",
      "66 Train Loss 0.5789837 Test MSE 3.304219238204707 Test RE 0.8688453637445092\n",
      "67 Train Loss 0.5687876 Test MSE 3.3063397544205775 Test RE 0.8691241141920563\n",
      "68 Train Loss 0.56204706 Test MSE 3.3178829921321302 Test RE 0.8706399543305093\n",
      "69 Train Loss 0.54679036 Test MSE 3.354985497144845 Test RE 0.875494422864019\n",
      "70 Train Loss 0.5409697 Test MSE 3.349211002317981 Test RE 0.8747406617446085\n",
      "71 Train Loss 0.5290159 Test MSE 3.335643491852869 Test RE 0.8729670952651306\n",
      "72 Train Loss 0.5192629 Test MSE 3.337911791902936 Test RE 0.8732638618095995\n",
      "73 Train Loss 0.51290053 Test MSE 3.3292668279033903 Test RE 0.8721322817193999\n",
      "74 Train Loss 0.5073978 Test MSE 3.308700054138151 Test RE 0.8694342800516942\n",
      "75 Train Loss 0.5031742 Test MSE 3.3134703596076442 Test RE 0.8700608060606507\n",
      "76 Train Loss 0.495817 Test MSE 3.273340539689741 Test RE 0.8647760531014924\n",
      "77 Train Loss 0.49127594 Test MSE 3.288133884233944 Test RE 0.8667279595126203\n",
      "78 Train Loss 0.48759142 Test MSE 3.27449499408378 Test RE 0.86492853593864\n",
      "79 Train Loss 0.48337924 Test MSE 3.2699651717366223 Test RE 0.8643300728851572\n",
      "80 Train Loss 0.47434 Test MSE 3.3017459174517403 Test RE 0.8685201226811368\n",
      "81 Train Loss 0.4698279 Test MSE 3.3099918192943316 Test RE 0.8696039834536967\n",
      "82 Train Loss 0.46456984 Test MSE 3.3039948767832943 Test RE 0.8688158652948061\n",
      "83 Train Loss 0.46058077 Test MSE 3.3132991673352157 Test RE 0.8700383296847835\n",
      "84 Train Loss 0.45652503 Test MSE 3.3252268593745713 Test RE 0.8716029675063551\n",
      "85 Train Loss 0.4513045 Test MSE 3.331375427562071 Test RE 0.8724084216082177\n",
      "86 Train Loss 0.4488421 Test MSE 3.336987836013249 Test RE 0.8731429908605971\n",
      "87 Train Loss 0.44416472 Test MSE 3.3554612861865074 Test RE 0.8755565000153956\n",
      "88 Train Loss 0.43928522 Test MSE 3.3509500828342036 Test RE 0.874967737168483\n",
      "89 Train Loss 0.43442136 Test MSE 3.363452655218443 Test RE 0.8765984929791584\n",
      "90 Train Loss 0.43135527 Test MSE 3.362377563695347 Test RE 0.8764583841346895\n",
      "91 Train Loss 0.42599824 Test MSE 3.3587099016882673 Test RE 0.8759802358396549\n",
      "92 Train Loss 0.42229885 Test MSE 3.3664732988215267 Test RE 0.8769920316528084\n",
      "93 Train Loss 0.41936904 Test MSE 3.3762052365382664 Test RE 0.8782587389400872\n",
      "94 Train Loss 0.41652238 Test MSE 3.3858665332619546 Test RE 0.8795144470697652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.41328198 Test MSE 3.373950074124481 Test RE 0.8779653700819581\n",
      "96 Train Loss 0.40914455 Test MSE 3.3703359230173446 Test RE 0.8774950089843775\n",
      "97 Train Loss 0.40619868 Test MSE 3.3898012475947246 Test RE 0.8800253404037102\n",
      "98 Train Loss 0.40287375 Test MSE 3.409540917075899 Test RE 0.8825839259855056\n",
      "99 Train Loss 0.40088806 Test MSE 3.4088759206928247 Test RE 0.8824978522656755\n",
      "Training time: 123.14\n",
      "1\n",
      "KG_rowdy_tune43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 53.791145 Test MSE 7.816899092236954 Test RE 1.3363656781659028\n",
      "1 Train Loss 44.890396 Test MSE 8.660591072381523 Test RE 1.4066363195529867\n",
      "2 Train Loss 40.585922 Test MSE 9.522913560286323 Test RE 1.4750032641622552\n",
      "3 Train Loss 38.33585 Test MSE 9.832926514727907 Test RE 1.498819922103766\n",
      "4 Train Loss 34.707508 Test MSE 10.013407421140508 Test RE 1.5125126087081049\n",
      "5 Train Loss 31.978035 Test MSE 9.563168799844146 Test RE 1.478117541766484\n",
      "6 Train Loss 30.227215 Test MSE 9.682293708610086 Test RE 1.4872952352097664\n",
      "7 Train Loss 27.9086 Test MSE 9.93906042370157 Test RE 1.5068871370588726\n",
      "8 Train Loss 26.601025 Test MSE 9.789390284332871 Test RE 1.4954981562923177\n",
      "9 Train Loss 24.696182 Test MSE 9.643946820041368 Test RE 1.4843470842519983\n",
      "10 Train Loss 22.871307 Test MSE 9.468076896872606 Test RE 1.4707503097335237\n",
      "11 Train Loss 21.786102 Test MSE 9.419247325908739 Test RE 1.4669528680262913\n",
      "12 Train Loss 20.824318 Test MSE 9.431692763405223 Test RE 1.4679216738651033\n",
      "13 Train Loss 20.00616 Test MSE 9.23027267688278 Test RE 1.4521628618685427\n",
      "14 Train Loss 19.564579 Test MSE 9.087776713612685 Test RE 1.440910095651369\n",
      "15 Train Loss 19.060331 Test MSE 8.91458803601148 Test RE 1.4271141077558924\n",
      "16 Train Loss 18.659601 Test MSE 8.863761670943623 Test RE 1.423039959437617\n",
      "17 Train Loss 18.124016 Test MSE 8.712152428214422 Test RE 1.4108173532301167\n",
      "18 Train Loss 17.269936 Test MSE 8.187028895081166 Test RE 1.3676381972868485\n",
      "19 Train Loss 15.897399 Test MSE 7.524269536616803 Test RE 1.3111133291449604\n",
      "20 Train Loss 15.313834 Test MSE 7.223030159683088 Test RE 1.284599576220474\n",
      "21 Train Loss 14.391482 Test MSE 6.895789933215507 Test RE 1.2551628361087646\n",
      "22 Train Loss 13.848026 Test MSE 6.888848306250523 Test RE 1.254530924023695\n",
      "23 Train Loss 13.448265 Test MSE 6.764840632120288 Test RE 1.2431881024521236\n",
      "24 Train Loss 13.070417 Test MSE 7.02410882207227 Test RE 1.2667872275990533\n",
      "25 Train Loss 12.844309 Test MSE 6.983733601587643 Test RE 1.2631411761167664\n",
      "26 Train Loss 12.338928 Test MSE 6.773699063029956 Test RE 1.2440018018163268\n",
      "27 Train Loss 10.0972805 Test MSE 5.767161603240058 Test RE 1.147860525234383\n",
      "28 Train Loss 9.361208 Test MSE 5.658171594112635 Test RE 1.136962438638633\n",
      "29 Train Loss 8.803919 Test MSE 5.65641816608421 Test RE 1.136786256611698\n",
      "30 Train Loss 8.481358 Test MSE 5.728324842952555 Test RE 1.1439890810735038\n",
      "31 Train Loss 8.02226 Test MSE 5.8438057440368505 Test RE 1.155462740904348\n",
      "32 Train Loss 7.6847773 Test MSE 5.820780566192378 Test RE 1.1531841749875833\n",
      "33 Train Loss 7.451065 Test MSE 5.858737856504147 Test RE 1.156938020273869\n",
      "34 Train Loss 7.083971 Test MSE 5.746176042845815 Test RE 1.145770203225596\n",
      "35 Train Loss 6.8684416 Test MSE 5.800663460428914 Test RE 1.1511896996205344\n",
      "36 Train Loss 5.670454 Test MSE 5.284130624750474 Test RE 1.0987397401733145\n",
      "37 Train Loss 5.0368195 Test MSE 5.376060805688012 Test RE 1.1082561407110314\n",
      "38 Train Loss 4.5333443 Test MSE 5.304519878079413 Test RE 1.100857488165413\n",
      "39 Train Loss 4.2423697 Test MSE 5.200541383415023 Test RE 1.0900146590798343\n",
      "40 Train Loss 3.9902077 Test MSE 5.121960737267934 Test RE 1.0817482039321427\n",
      "41 Train Loss 3.779758 Test MSE 5.265345916392925 Test RE 1.0967850306177547\n",
      "42 Train Loss 3.61977 Test MSE 5.261246797154275 Test RE 1.0963580189790814\n",
      "43 Train Loss 3.4520035 Test MSE 5.173669426633635 Test RE 1.0871948793477593\n",
      "44 Train Loss 3.3183112 Test MSE 5.274008026838875 Test RE 1.0976868297668123\n",
      "45 Train Loss 3.2045512 Test MSE 5.37566556351461 Test RE 1.1082154010660819\n",
      "46 Train Loss 3.1294088 Test MSE 5.455067505340004 Test RE 1.1163699168461492\n",
      "47 Train Loss 3.0230143 Test MSE 5.517381914355254 Test RE 1.122728077543804\n",
      "48 Train Loss 2.9571795 Test MSE 5.556578371517416 Test RE 1.126709049113674\n",
      "49 Train Loss 2.8814735 Test MSE 5.542576765768697 Test RE 1.1252885988465808\n",
      "50 Train Loss 2.8069122 Test MSE 5.4770896485807095 Test RE 1.1186210435135708\n",
      "51 Train Loss 2.7315624 Test MSE 5.525310426232184 Test RE 1.1235344715392643\n",
      "52 Train Loss 2.6754751 Test MSE 5.591788607000522 Test RE 1.1302732067630124\n",
      "53 Train Loss 2.6015902 Test MSE 5.609665941325932 Test RE 1.1320785457134634\n",
      "54 Train Loss 2.5433998 Test MSE 5.60957739956607 Test RE 1.132069611436154\n",
      "55 Train Loss 2.5038188 Test MSE 5.644901490619387 Test RE 1.1356283976322248\n",
      "56 Train Loss 2.4530177 Test MSE 5.608048672563185 Test RE 1.1319153446184573\n",
      "57 Train Loss 2.416925 Test MSE 5.652011854733737 Test RE 1.1363433959603537\n",
      "58 Train Loss 2.3542855 Test MSE 5.684801547653602 Test RE 1.139634831595853\n",
      "59 Train Loss 2.3052113 Test MSE 5.683241535316036 Test RE 1.139478452664451\n",
      "60 Train Loss 2.2396514 Test MSE 5.697622340801996 Test RE 1.140919203057605\n",
      "61 Train Loss 2.1994114 Test MSE 5.650705211112668 Test RE 1.13621203727673\n",
      "62 Train Loss 2.1704836 Test MSE 5.633915286116648 Test RE 1.1345227696490177\n",
      "63 Train Loss 2.116961 Test MSE 5.636092333568572 Test RE 1.1347419486054744\n",
      "64 Train Loss 2.0754337 Test MSE 5.666373974899142 Test RE 1.137786240229217\n",
      "65 Train Loss 2.0367396 Test MSE 5.676800736644643 Test RE 1.138832586058536\n",
      "66 Train Loss 2.0060291 Test MSE 5.670749103111573 Test RE 1.1382254099852875\n",
      "67 Train Loss 1.9654086 Test MSE 5.707000583907708 Test RE 1.1418577891621013\n",
      "68 Train Loss 1.9404244 Test MSE 5.670292983414789 Test RE 1.138179633187593\n",
      "69 Train Loss 1.9104718 Test MSE 5.641449473661142 Test RE 1.1352811100837765\n",
      "70 Train Loss 1.8708318 Test MSE 5.653902558866577 Test RE 1.136533444173524\n",
      "71 Train Loss 1.8364639 Test MSE 5.679614297048613 Test RE 1.1391147676517612\n",
      "72 Train Loss 1.7996342 Test MSE 5.723814752868224 Test RE 1.1435386431260681\n",
      "73 Train Loss 1.777904 Test MSE 5.732086974834671 Test RE 1.1443646822743794\n",
      "74 Train Loss 1.7560463 Test MSE 5.7285097948910115 Test RE 1.144007549063369\n",
      "75 Train Loss 1.7363861 Test MSE 5.7166412972570795 Test RE 1.1428218400992616\n",
      "76 Train Loss 1.7142752 Test MSE 5.7346866622764 Test RE 1.1446241561160289\n",
      "77 Train Loss 1.6975584 Test MSE 5.767706205565839 Test RE 1.147914721110749\n",
      "78 Train Loss 1.6870627 Test MSE 5.743068896418364 Test RE 1.145460383515952\n",
      "79 Train Loss 1.6754454 Test MSE 5.737395853009754 Test RE 1.1448944968670094\n",
      "80 Train Loss 1.666955 Test MSE 5.733686790375766 Test RE 1.1445243662331097\n",
      "81 Train Loss 1.653032 Test MSE 5.7133315939129385 Test RE 1.1424909684657294\n",
      "82 Train Loss 1.6415789 Test MSE 5.726977978395944 Test RE 1.1438545837318839\n",
      "83 Train Loss 1.6201015 Test MSE 5.789322171019568 Test RE 1.150063762600549\n",
      "84 Train Loss 1.6063758 Test MSE 5.771863068921228 Test RE 1.1483283053864926\n",
      "85 Train Loss 1.5875511 Test MSE 5.7602746548044585 Test RE 1.1471749524821468\n",
      "86 Train Loss 1.5757871 Test MSE 5.752297225831922 Test RE 1.1463803135163664\n",
      "87 Train Loss 1.5645674 Test MSE 5.750190342051924 Test RE 1.1461703529393175\n",
      "88 Train Loss 1.5535897 Test MSE 5.725525857681358 Test RE 1.1437095578346301\n",
      "89 Train Loss 1.5432439 Test MSE 5.725684290111542 Test RE 1.143725381658998\n",
      "90 Train Loss 1.5118223 Test MSE 5.729790869453519 Test RE 1.1441354599071845\n",
      "91 Train Loss 1.4814392 Test MSE 5.778157443892791 Test RE 1.148954276528439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 1.4738443 Test MSE 5.787323300464393 Test RE 1.1498652050677105\n",
      "93 Train Loss 1.4509631 Test MSE 5.771908181744402 Test RE 1.148332793038915\n",
      "94 Train Loss 1.4330997 Test MSE 5.739048807361226 Test RE 1.1450594081005636\n",
      "95 Train Loss 1.4129432 Test MSE 5.727377185663149 Test RE 1.1438944500546508\n",
      "96 Train Loss 1.3973867 Test MSE 5.73624328337399 Test RE 1.1447794937414684\n",
      "97 Train Loss 1.3869653 Test MSE 5.718379732454793 Test RE 1.1429955934091418\n",
      "98 Train Loss 1.3692106 Test MSE 5.683036298838387 Test RE 1.1394578777290105\n",
      "99 Train Loss 1.3552942 Test MSE 5.706996500572271 Test RE 1.1418573806647532\n",
      "Training time: 123.57\n",
      "2\n",
      "KG_rowdy_tune43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 62.523514 Test MSE 6.6411142441792945 Test RE 1.2317669180280089\n",
      "1 Train Loss 41.547386 Test MSE 7.963978946366768 Test RE 1.348879368019568\n",
      "2 Train Loss 29.14312 Test MSE 6.422474380013495 Test RE 1.2113210114805424\n",
      "3 Train Loss 22.324791 Test MSE 6.022633915778633 Test RE 1.1730088615563512\n",
      "4 Train Loss 17.561386 Test MSE 5.650328123833321 Test RE 1.1361741253490973\n",
      "5 Train Loss 15.024794 Test MSE 5.293861117759913 Test RE 1.0997509152148428\n",
      "6 Train Loss 12.421816 Test MSE 5.410611320471602 Test RE 1.1118116711656376\n",
      "7 Train Loss 10.567702 Test MSE 5.589029583264591 Test RE 1.1299943303975533\n",
      "8 Train Loss 9.13705 Test MSE 5.053521421901951 Test RE 1.0744967736454571\n",
      "9 Train Loss 7.8953667 Test MSE 4.791963115318774 Test RE 1.0463206427446357\n",
      "10 Train Loss 7.236266 Test MSE 4.655438394195796 Test RE 1.0313079183533727\n",
      "11 Train Loss 6.765779 Test MSE 4.562572503688023 Test RE 1.020969926361457\n",
      "12 Train Loss 6.3365602 Test MSE 4.383175286593131 Test RE 1.0006967277757335\n",
      "13 Train Loss 5.9692917 Test MSE 4.349308458303473 Test RE 0.9968232638839783\n",
      "14 Train Loss 5.649623 Test MSE 4.2269560146336245 Test RE 0.9827021915602346\n",
      "15 Train Loss 5.5347614 Test MSE 4.146287277567796 Test RE 0.9732799007550815\n",
      "16 Train Loss 5.358105 Test MSE 4.0169465098574175 Test RE 0.9579792110030126\n",
      "17 Train Loss 5.0048513 Test MSE 3.8379991315101494 Test RE 0.9363980407542128\n",
      "18 Train Loss 4.756049 Test MSE 3.7255376134506224 Test RE 0.9225768154571536\n",
      "19 Train Loss 4.37288 Test MSE 3.5769145206463824 Test RE 0.9039873249076205\n",
      "20 Train Loss 3.7821252 Test MSE 3.41121186084996 Test RE 0.8828001673374402\n",
      "21 Train Loss 3.3400826 Test MSE 3.0968009494271467 Test RE 0.8411330660674274\n",
      "22 Train Loss 2.985929 Test MSE 2.87713932772862 Test RE 0.8107528929427262\n",
      "23 Train Loss 2.7623072 Test MSE 2.635918053020542 Test RE 0.776021962454055\n",
      "24 Train Loss 2.4412622 Test MSE 2.387996675068417 Test RE 0.7386265581843449\n",
      "25 Train Loss 2.1329837 Test MSE 2.1269403263238043 Test RE 0.6970849605125138\n",
      "26 Train Loss 1.9788104 Test MSE 1.9386139773172002 Test RE 0.6655086890517415\n",
      "27 Train Loss 1.8299832 Test MSE 1.8067525956753736 Test RE 0.6424767321527627\n",
      "28 Train Loss 1.6212344 Test MSE 1.6763491936443402 Test RE 0.6188569964829795\n",
      "29 Train Loss 1.492721 Test MSE 1.6260184428595768 Test RE 0.6094959075220674\n",
      "30 Train Loss 1.34191 Test MSE 1.618038013666026 Test RE 0.6079983778446573\n",
      "31 Train Loss 1.2265588 Test MSE 1.5722675713490415 Test RE 0.5993372748242468\n",
      "32 Train Loss 1.1729532 Test MSE 1.5149637340494626 Test RE 0.5883139935611985\n",
      "33 Train Loss 1.126305 Test MSE 1.530403714059329 Test RE 0.5913043388686199\n",
      "34 Train Loss 1.0845786 Test MSE 1.483291339705474 Test RE 0.5821317554512994\n",
      "35 Train Loss 1.0287567 Test MSE 1.414635776806317 Test RE 0.5684998821291187\n",
      "36 Train Loss 0.9759113 Test MSE 1.2934658138205124 Test RE 0.5436076223664221\n",
      "37 Train Loss 0.9313277 Test MSE 1.217110078784955 Test RE 0.5273184777254406\n",
      "38 Train Loss 0.8946724 Test MSE 1.1571097239083432 Test RE 0.5141565015963165\n",
      "39 Train Loss 0.831685 Test MSE 1.0849681983986834 Test RE 0.49787069554670693\n",
      "40 Train Loss 0.7928113 Test MSE 1.0477596363200212 Test RE 0.4892590775505865\n",
      "41 Train Loss 0.74070674 Test MSE 0.9605790539262309 Test RE 0.46846226776862016\n",
      "42 Train Loss 0.70289636 Test MSE 0.9295221048801044 Test RE 0.46082700503148544\n",
      "43 Train Loss 0.6571956 Test MSE 0.882250713583696 Test RE 0.44895629920737584\n",
      "44 Train Loss 0.6053929 Test MSE 0.8008715916820024 Test RE 0.42774949418101194\n",
      "45 Train Loss 0.5652817 Test MSE 0.7678753037117929 Test RE 0.4188450722840992\n",
      "46 Train Loss 0.51871264 Test MSE 0.6391196111230697 Test RE 0.3821194396648859\n",
      "47 Train Loss 0.4804551 Test MSE 0.542398910025987 Test RE 0.3520201019217202\n",
      "48 Train Loss 0.4285156 Test MSE 0.4376250563878982 Test RE 0.31619802294800137\n",
      "49 Train Loss 0.39858216 Test MSE 0.42144586427989805 Test RE 0.3102979872031924\n",
      "50 Train Loss 0.37075654 Test MSE 0.37131020194208186 Test RE 0.2912570867285287\n",
      "51 Train Loss 0.33783212 Test MSE 0.3327855832409779 Test RE 0.2757339943444759\n",
      "52 Train Loss 0.32656267 Test MSE 0.331353330719368 Test RE 0.2751399984454057\n",
      "53 Train Loss 0.31157047 Test MSE 0.3437995212510897 Test RE 0.28025972664242826\n",
      "54 Train Loss 0.28944266 Test MSE 0.33351139714543554 Test RE 0.27603452203094453\n",
      "55 Train Loss 0.27670974 Test MSE 0.34617867990202966 Test RE 0.28122778029116763\n",
      "56 Train Loss 0.26522985 Test MSE 0.3168938991935615 Test RE 0.26906982694911036\n",
      "57 Train Loss 0.24834952 Test MSE 0.2731968686465539 Test RE 0.24983076561373022\n",
      "58 Train Loss 0.23551162 Test MSE 0.24758702740339783 Test RE 0.23783293923097099\n",
      "59 Train Loss 0.20565681 Test MSE 0.21054487474629383 Test RE 0.21932109082775905\n",
      "60 Train Loss 0.1877096 Test MSE 0.15691180150107034 Test RE 0.18933716262205372\n",
      "61 Train Loss 0.16902837 Test MSE 0.11432697424536767 Test RE 0.16161527856770494\n",
      "62 Train Loss 0.14813638 Test MSE 0.07018198073722791 Test RE 0.12662541182343198\n",
      "63 Train Loss 0.12773958 Test MSE 0.05199274025553548 Test RE 0.10898818341757593\n",
      "64 Train Loss 0.11768003 Test MSE 0.044382124374056926 Test RE 0.10069597314031861\n",
      "65 Train Loss 0.10280392 Test MSE 0.03211582520684146 Test RE 0.08565793551996362\n",
      "66 Train Loss 0.084286876 Test MSE 0.02535069122808086 Test RE 0.0761032078205144\n",
      "67 Train Loss 0.0776398 Test MSE 0.024609277561200134 Test RE 0.07498208155516171\n",
      "68 Train Loss 0.067283385 Test MSE 0.02421249778300126 Test RE 0.07437515045153932\n",
      "69 Train Loss 0.060643166 Test MSE 0.021908596116671054 Test RE 0.07074819023172564\n",
      "70 Train Loss 0.055710196 Test MSE 0.021333626057969526 Test RE 0.06981365885244482\n",
      "71 Train Loss 0.049006816 Test MSE 0.018631536495663955 Test RE 0.06524277068068028\n",
      "72 Train Loss 0.044600133 Test MSE 0.0168594899334186 Test RE 0.06206264435010113\n",
      "73 Train Loss 0.041119974 Test MSE 0.018195155930082477 Test RE 0.06447419837919093\n",
      "74 Train Loss 0.038329866 Test MSE 0.01859299069036776 Test RE 0.06517524707128923\n",
      "75 Train Loss 0.035331886 Test MSE 0.018023669529148235 Test RE 0.06416964965541659\n",
      "76 Train Loss 0.03296505 Test MSE 0.0178108882510229 Test RE 0.06378974259474106\n",
      "77 Train Loss 0.03080096 Test MSE 0.01607650012299101 Test RE 0.060604352332590046\n",
      "78 Train Loss 0.02832814 Test MSE 0.015336642740714966 Test RE 0.059193389741386236\n",
      "79 Train Loss 0.027013075 Test MSE 0.013037896930916454 Test RE 0.05457727300412641\n",
      "80 Train Loss 0.025903642 Test MSE 0.01278424557425925 Test RE 0.05404376694815992\n",
      "81 Train Loss 0.025050875 Test MSE 0.012742515339096351 Test RE 0.05395549022895929\n",
      "82 Train Loss 0.023902616 Test MSE 0.01276039977323056 Test RE 0.053993340882281235\n",
      "83 Train Loss 0.022540484 Test MSE 0.011042245523091717 Test RE 0.05022694459669083\n",
      "84 Train Loss 0.021166544 Test MSE 0.010359769950489 Test RE 0.0486500304082978\n",
      "85 Train Loss 0.019969432 Test MSE 0.009088469017146583 Test RE 0.04556731360944615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.018826578 Test MSE 0.008163945552719699 Test RE 0.04318750451292683\n",
      "87 Train Loss 0.01641816 Test MSE 0.005311050293522755 Test RE 0.03483359252784291\n",
      "88 Train Loss 0.01445252 Test MSE 0.004452887592435525 Test RE 0.0318954641368396\n",
      "89 Train Loss 0.01326931 Test MSE 0.0041167676535170524 Test RE 0.03066805535954219\n",
      "90 Train Loss 0.012454006 Test MSE 0.003490125648152547 Test RE 0.0282376526329706\n",
      "91 Train Loss 0.01177098 Test MSE 0.0033422245602994826 Test RE 0.02763286233644991\n",
      "92 Train Loss 0.011259919 Test MSE 0.00346457584689651 Test RE 0.028134104547323607\n",
      "93 Train Loss 0.011016841 Test MSE 0.003433347357877673 Test RE 0.028007021983141825\n",
      "94 Train Loss 0.010830364 Test MSE 0.003320782812444831 Test RE 0.02754408161654409\n",
      "95 Train Loss 0.010503823 Test MSE 0.0032066570837585135 Test RE 0.027066638339890786\n",
      "96 Train Loss 0.009847654 Test MSE 0.004090671075436714 Test RE 0.03057069697686358\n",
      "97 Train Loss 0.009208805 Test MSE 0.004235310303200865 Test RE 0.03110646627638738\n",
      "98 Train Loss 0.008807578 Test MSE 0.003940301458630798 Test RE 0.030003559796921975\n",
      "99 Train Loss 0.008560101 Test MSE 0.0037334677737898597 Test RE 0.029205474309857184\n",
      "Training time: 124.21\n",
      "3\n",
      "KG_rowdy_tune43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 57.990074 Test MSE 6.762484743329861 Test RE 1.2429716104376027\n",
      "1 Train Loss 43.12494 Test MSE 8.695403109234661 Test RE 1.409460535932916\n",
      "2 Train Loss 34.19959 Test MSE 7.9740622694019985 Test RE 1.3497330169334716\n",
      "3 Train Loss 29.72869 Test MSE 8.513535272345996 Test RE 1.3946429318180917\n",
      "4 Train Loss 26.857159 Test MSE 8.864652233635264 Test RE 1.423111445704562\n",
      "5 Train Loss 25.395782 Test MSE 9.161335565322052 Test RE 1.4467298950315688\n",
      "6 Train Loss 23.226849 Test MSE 9.305701863577445 Test RE 1.458084279251818\n",
      "7 Train Loss 21.733295 Test MSE 9.504167221006607 Test RE 1.4735507395267908\n",
      "8 Train Loss 20.72939 Test MSE 9.465002172670435 Test RE 1.4705114798835064\n",
      "9 Train Loss 19.524092 Test MSE 9.151718625127685 Test RE 1.4459703568641142\n",
      "10 Train Loss 18.578321 Test MSE 9.400331473824538 Test RE 1.4654791510818177\n",
      "11 Train Loss 17.508896 Test MSE 9.051056091792834 Test RE 1.4379960346224276\n",
      "12 Train Loss 16.580957 Test MSE 8.836568428632221 Test RE 1.4208554018371409\n",
      "13 Train Loss 14.778413 Test MSE 8.279902453821057 Test RE 1.375373557441822\n",
      "14 Train Loss 13.087355 Test MSE 7.676238812821241 Test RE 1.3242875587337004\n",
      "15 Train Loss 11.001274 Test MSE 6.80533656438426 Test RE 1.2469035590115933\n",
      "16 Train Loss 8.475634 Test MSE 6.489225033015545 Test RE 1.2175995466090874\n",
      "17 Train Loss 7.317314 Test MSE 6.314356725251828 Test RE 1.2010818852792704\n",
      "18 Train Loss 6.5976367 Test MSE 6.475171087773775 Test RE 1.2162803326527003\n",
      "19 Train Loss 5.670061 Test MSE 6.371013852015565 Test RE 1.2064583538635938\n",
      "20 Train Loss 4.741249 Test MSE 6.105750820768829 Test RE 1.1810753309918636\n",
      "21 Train Loss 4.078942 Test MSE 6.183586223454534 Test RE 1.1885795964608297\n",
      "22 Train Loss 3.6653748 Test MSE 6.246224918052107 Test RE 1.1945844839474302\n",
      "23 Train Loss 3.3195999 Test MSE 6.183457713610903 Test RE 1.1885672456205427\n",
      "24 Train Loss 3.069344 Test MSE 6.158880050051582 Test RE 1.1862027682658005\n",
      "25 Train Loss 2.9047985 Test MSE 6.175457208532047 Test RE 1.1877980791944462\n",
      "26 Train Loss 2.729025 Test MSE 6.166222778580586 Test RE 1.1869096638652277\n",
      "27 Train Loss 2.5472403 Test MSE 6.004931091115588 Test RE 1.1712836319930648\n",
      "28 Train Loss 2.446455 Test MSE 5.977316106852319 Test RE 1.1685873270160323\n",
      "29 Train Loss 2.3300352 Test MSE 6.068767806528542 Test RE 1.1774929648723713\n",
      "30 Train Loss 2.2503967 Test MSE 5.955161746065289 Test RE 1.166419687023423\n",
      "31 Train Loss 2.1418293 Test MSE 5.875739946567226 Test RE 1.1586155244302425\n",
      "32 Train Loss 2.0713806 Test MSE 5.846865925282359 Test RE 1.15576523749457\n",
      "33 Train Loss 1.9832392 Test MSE 5.79642062790571 Test RE 1.1507686099813004\n",
      "34 Train Loss 1.911046 Test MSE 5.840020837149866 Test RE 1.1550884961541998\n",
      "35 Train Loss 1.8226053 Test MSE 5.824226262698816 Test RE 1.1535254466405493\n",
      "36 Train Loss 1.7671692 Test MSE 5.820547104723113 Test RE 1.1531610486415251\n",
      "37 Train Loss 1.7155875 Test MSE 5.751128416681464 Test RE 1.1462638411038495\n",
      "38 Train Loss 1.676034 Test MSE 5.756448282903013 Test RE 1.1467938728058544\n",
      "39 Train Loss 1.6307346 Test MSE 5.714201836226022 Test RE 1.1425779760294723\n",
      "40 Train Loss 1.593529 Test MSE 5.7049236511070225 Test RE 1.14164999369499\n",
      "41 Train Loss 1.5690106 Test MSE 5.6300119758892 Test RE 1.1341296894024118\n",
      "42 Train Loss 1.5455877 Test MSE 5.641977418600596 Test RE 1.135334230465137\n",
      "43 Train Loss 1.5207794 Test MSE 5.664786893490577 Test RE 1.1376268891294459\n",
      "44 Train Loss 1.4960757 Test MSE 5.660273703958945 Test RE 1.1371736197556295\n",
      "45 Train Loss 1.4761667 Test MSE 5.647291760362624 Test RE 1.1358688066909202\n",
      "46 Train Loss 1.4533337 Test MSE 5.6663864736118965 Test RE 1.1377874950754037\n",
      "47 Train Loss 1.4362895 Test MSE 5.6554494895689675 Test RE 1.136688913623057\n",
      "48 Train Loss 1.4193093 Test MSE 5.613781783566379 Test RE 1.1324937756391784\n",
      "49 Train Loss 1.4003928 Test MSE 5.60494582986513 Test RE 1.1316021660597393\n",
      "50 Train Loss 1.3792764 Test MSE 5.621345319273731 Test RE 1.133256432099802\n",
      "51 Train Loss 1.362402 Test MSE 5.592157931199473 Test RE 1.1303105320611921\n",
      "52 Train Loss 1.3448312 Test MSE 5.572382422397503 Test RE 1.1283102074650222\n",
      "53 Train Loss 1.3315355 Test MSE 5.551682390471295 Test RE 1.1262125599571606\n",
      "54 Train Loss 1.3178024 Test MSE 5.5225472527608535 Test RE 1.123253500096818\n",
      "55 Train Loss 1.308609 Test MSE 5.5564439012621145 Test RE 1.1266954157443594\n",
      "56 Train Loss 1.2923325 Test MSE 5.548861005239014 Test RE 1.1259263509248496\n",
      "57 Train Loss 1.2740076 Test MSE 5.601951274891044 Test RE 1.1312998350710195\n",
      "58 Train Loss 1.259403 Test MSE 5.617469364512502 Test RE 1.1328656708290332\n",
      "59 Train Loss 1.2430284 Test MSE 5.6086041112132685 Test RE 1.1319713974454888\n",
      "60 Train Loss 1.221812 Test MSE 5.612844186131218 Test RE 1.1323991987888775\n",
      "61 Train Loss 1.2070817 Test MSE 5.594920447673699 Test RE 1.1305896833272897\n",
      "62 Train Loss 1.1948073 Test MSE 5.582359436465389 Test RE 1.1293198413744014\n",
      "63 Train Loss 1.1804731 Test MSE 5.618008901726064 Test RE 1.1329200733074438\n",
      "64 Train Loss 1.1633036 Test MSE 5.591563880759159 Test RE 1.130250494477251\n",
      "65 Train Loss 1.1538649 Test MSE 5.598664228837492 Test RE 1.1309678810669719\n",
      "66 Train Loss 1.145967 Test MSE 5.606729056924765 Test RE 1.1317821627260587\n",
      "67 Train Loss 1.1372073 Test MSE 5.609488766154733 Test RE 1.1320606678401626\n",
      "68 Train Loss 1.1317853 Test MSE 5.607691034438658 Test RE 1.1318792516243672\n",
      "69 Train Loss 1.1233082 Test MSE 5.60091597049991 Test RE 1.1311952916941612\n",
      "70 Train Loss 1.113104 Test MSE 5.606942597955456 Test RE 1.1318037153662817\n",
      "71 Train Loss 1.1078802 Test MSE 5.599921349497708 Test RE 1.1310948473601559\n",
      "72 Train Loss 1.0983039 Test MSE 5.617134366558523 Test RE 1.132831891086289\n",
      "73 Train Loss 1.0922065 Test MSE 5.635254532332009 Test RE 1.1346576061671447\n",
      "74 Train Loss 1.0856458 Test MSE 5.64155472635013 Test RE 1.1352917005209344\n",
      "75 Train Loss 1.079274 Test MSE 5.62856298743735 Test RE 1.133983735310344\n",
      "76 Train Loss 1.0738292 Test MSE 5.619600365457511 Test RE 1.1330805281562026\n",
      "77 Train Loss 1.0685217 Test MSE 5.637484987166921 Test RE 1.13488213481562\n",
      "78 Train Loss 1.0606153 Test MSE 5.644254555976261 Test RE 1.1355633213502008\n",
      "79 Train Loss 1.0543197 Test MSE 5.65444234829764 Test RE 1.1365876964437724\n",
      "80 Train Loss 1.04918 Test MSE 5.6593181214090915 Test RE 1.137077625357545\n",
      "81 Train Loss 1.0459112 Test MSE 5.670079227873493 Test RE 1.1381581797550095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 1.0396571 Test MSE 5.666685063581445 Test RE 1.1378174725098469\n",
      "83 Train Loss 1.0317204 Test MSE 5.6598090695174115 Test RE 1.137126945257108\n",
      "84 Train Loss 1.0253495 Test MSE 5.649811646542197 Test RE 1.1361221972546762\n",
      "85 Train Loss 1.0198817 Test MSE 5.67956668183269 Test RE 1.139109992740432\n",
      "86 Train Loss 1.0153154 Test MSE 5.690659699925056 Test RE 1.1402218736652399\n",
      "87 Train Loss 1.0099683 Test MSE 5.693657666391865 Test RE 1.1405221812767823\n",
      "88 Train Loss 1.0041634 Test MSE 5.695011631462375 Test RE 1.1406577826328679\n",
      "89 Train Loss 0.99711454 Test MSE 5.705264751907104 Test RE 1.1416841231531014\n",
      "90 Train Loss 0.98982334 Test MSE 5.701454604390102 Test RE 1.1413028339735845\n",
      "91 Train Loss 0.9820061 Test MSE 5.722722706918318 Test RE 1.1434295501201066\n",
      "92 Train Loss 0.97404027 Test MSE 5.750254585496767 Test RE 1.1461767556600806\n",
      "93 Train Loss 0.96240336 Test MSE 5.779333130881003 Test RE 1.1490711599727206\n",
      "94 Train Loss 0.9534614 Test MSE 5.783169431211844 Test RE 1.1494524713351417\n",
      "95 Train Loss 0.94215786 Test MSE 5.791117925239508 Test RE 1.1502421143719939\n",
      "96 Train Loss 0.9376061 Test MSE 5.78506337026528 Test RE 1.1496406739067522\n",
      "97 Train Loss 0.9336012 Test MSE 5.8092659416125905 Test RE 1.1520430001874506\n",
      "98 Train Loss 0.92535496 Test MSE 5.823655785673736 Test RE 1.1534689519363317\n",
      "99 Train Loss 0.91806555 Test MSE 5.84334838563993 Test RE 1.155417524571853\n",
      "Training time: 124.57\n",
      "4\n",
      "KG_rowdy_tune43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 60.01551 Test MSE 8.250144428314925 Test RE 1.3728997818085034\n",
      "1 Train Loss 46.787315 Test MSE 7.876831229978399 Test RE 1.341478851676974\n",
      "2 Train Loss 38.38204 Test MSE 7.582295577640463 Test RE 1.316159174552226\n",
      "3 Train Loss 30.109844 Test MSE 6.500963496326924 Test RE 1.2187003167147212\n",
      "4 Train Loss 23.830936 Test MSE 6.088610131823309 Test RE 1.179416348050015\n",
      "5 Train Loss 19.495544 Test MSE 5.720096204580996 Test RE 1.1431671256406604\n",
      "6 Train Loss 15.101944 Test MSE 5.723652131562011 Test RE 1.1435223982721758\n",
      "7 Train Loss 12.888659 Test MSE 5.655895314112609 Test RE 1.136733715882394\n",
      "8 Train Loss 11.326731 Test MSE 5.615895089222363 Test RE 1.132706918970748\n",
      "9 Train Loss 9.775558 Test MSE 5.173849923841579 Test RE 1.0872138440237475\n",
      "10 Train Loss 8.592161 Test MSE 5.085908093965559 Test RE 1.077934356541445\n",
      "11 Train Loss 7.5454035 Test MSE 4.747507989618066 Test RE 1.041455966575334\n",
      "12 Train Loss 6.5020247 Test MSE 4.115611142754282 Test RE 0.9696728311489121\n",
      "13 Train Loss 5.7027426 Test MSE 3.7109085479461763 Test RE 0.9207636929958751\n",
      "14 Train Loss 5.027825 Test MSE 3.5159395852134763 Test RE 0.8962491612567112\n",
      "15 Train Loss 4.1000776 Test MSE 2.990122383501927 Test RE 0.8265184304431775\n",
      "16 Train Loss 3.5769627 Test MSE 2.804516191715973 Test RE 0.8004552108162706\n",
      "17 Train Loss 3.1929371 Test MSE 2.6301510608745824 Test RE 0.7751725879701836\n",
      "18 Train Loss 2.8771124 Test MSE 2.32157216818859 Test RE 0.7282812930251871\n",
      "19 Train Loss 2.5257282 Test MSE 1.8679504375080402 Test RE 0.65326702181538\n",
      "20 Train Loss 2.1811466 Test MSE 1.528883702968173 Test RE 0.5910106214568714\n",
      "21 Train Loss 1.9211006 Test MSE 1.281361403362346 Test RE 0.5410580704571016\n",
      "22 Train Loss 1.5831927 Test MSE 1.0005971127669873 Test RE 0.4781208500605729\n",
      "23 Train Loss 1.291218 Test MSE 0.7236788972315559 Test RE 0.406612770656717\n",
      "24 Train Loss 1.0554584 Test MSE 0.5392374752485293 Test RE 0.350992707724184\n",
      "25 Train Loss 0.81785345 Test MSE 0.535791532366752 Test RE 0.34986941847264763\n",
      "26 Train Loss 0.6635647 Test MSE 0.400815833050183 Test RE 0.30260806231164145\n",
      "27 Train Loss 0.5341024 Test MSE 0.38135316304944805 Test RE 0.29516967474440803\n",
      "28 Train Loss 0.46800447 Test MSE 0.36169864459225665 Test RE 0.2874627003678475\n",
      "29 Train Loss 0.4326132 Test MSE 0.33759393908461877 Test RE 0.27771886442695715\n",
      "30 Train Loss 0.3889418 Test MSE 0.3280528548626354 Test RE 0.27376629029718347\n",
      "31 Train Loss 0.33916005 Test MSE 0.2575932312917016 Test RE 0.2425913346207814\n",
      "32 Train Loss 0.29803488 Test MSE 0.2019874312324905 Test RE 0.2148177845532702\n",
      "33 Train Loss 0.27019587 Test MSE 0.20018583525269865 Test RE 0.2138576215747697\n",
      "34 Train Loss 0.23070191 Test MSE 0.13450311080702618 Test RE 0.17529689545670005\n",
      "35 Train Loss 0.2068753 Test MSE 0.11489159427914002 Test RE 0.16201386707975057\n",
      "36 Train Loss 0.1696055 Test MSE 0.06101381206902332 Test RE 0.11806526338517305\n",
      "37 Train Loss 0.15052441 Test MSE 0.043440782799135325 Test RE 0.09962237281354296\n",
      "38 Train Loss 0.1341351 Test MSE 0.027741910642160545 Test RE 0.07961158025102978\n",
      "39 Train Loss 0.11598101 Test MSE 0.02569712756044504 Test RE 0.07662144718724387\n",
      "40 Train Loss 0.10427185 Test MSE 0.022739515289856054 Test RE 0.07207732525091337\n",
      "41 Train Loss 0.09327893 Test MSE 0.017369108309576747 Test RE 0.06299365708185233\n",
      "42 Train Loss 0.08396383 Test MSE 0.014704270285846673 Test RE 0.05796018978001832\n",
      "43 Train Loss 0.07816422 Test MSE 0.014844191372748278 Test RE 0.05823530208270559\n",
      "44 Train Loss 0.074242 Test MSE 0.01479078310813395 Test RE 0.05813044460018441\n",
      "45 Train Loss 0.07098032 Test MSE 0.014028072594292262 Test RE 0.05661181289177064\n",
      "46 Train Loss 0.0677328 Test MSE 0.013324409629125669 Test RE 0.05517369224640816\n",
      "47 Train Loss 0.06392997 Test MSE 0.013437467431986868 Test RE 0.05540727258674801\n",
      "48 Train Loss 0.060745455 Test MSE 0.011877871206122824 Test RE 0.05209275978239904\n",
      "49 Train Loss 0.055924945 Test MSE 0.011053825248207586 Test RE 0.0502532735625463\n",
      "50 Train Loss 0.054465696 Test MSE 0.011071126905424607 Test RE 0.05029258687418056\n",
      "51 Train Loss 0.05020827 Test MSE 0.01274806755053525 Test RE 0.05396724378218314\n",
      "52 Train Loss 0.04758761 Test MSE 0.01351896482569205 Test RE 0.05557503940686292\n",
      "53 Train Loss 0.046043016 Test MSE 0.0133163622739839 Test RE 0.05515702849288931\n",
      "54 Train Loss 0.045196906 Test MSE 0.014260553926095605 Test RE 0.057078987126554764\n",
      "55 Train Loss 0.042463392 Test MSE 0.016290778787659856 Test RE 0.061006903673792266\n",
      "56 Train Loss 0.039388634 Test MSE 0.014432447938576235 Test RE 0.057421966313799096\n",
      "57 Train Loss 0.03800295 Test MSE 0.014756933689903547 Test RE 0.05806388934106095\n",
      "58 Train Loss 0.033119302 Test MSE 0.010658706130511356 Test RE 0.049346948778936264\n",
      "59 Train Loss 0.030865872 Test MSE 0.009363810005466459 Test RE 0.046252408946111156\n",
      "60 Train Loss 0.030167904 Test MSE 0.009350435481110999 Test RE 0.04621936550446159\n",
      "61 Train Loss 0.027815672 Test MSE 0.007401692348058135 Test RE 0.041121938108727704\n",
      "62 Train Loss 0.02637672 Test MSE 0.006621394475692669 Test RE 0.03889401625361388\n",
      "63 Train Loss 0.025308443 Test MSE 0.005850088607368488 Test RE 0.036558576944871454\n",
      "64 Train Loss 0.023023931 Test MSE 0.005233240163470564 Test RE 0.034577484330345305\n",
      "65 Train Loss 0.02216935 Test MSE 0.005194815712152154 Test RE 0.034450309900442413\n",
      "66 Train Loss 0.021416292 Test MSE 0.00592133283590001 Test RE 0.036780514237954996\n",
      "67 Train Loss 0.019417958 Test MSE 0.005537278831395371 Test RE 0.03556773886585811\n",
      "68 Train Loss 0.01829853 Test MSE 0.0053310127250725215 Test RE 0.03489899494212308\n",
      "69 Train Loss 0.017517563 Test MSE 0.006321536801119723 Test RE 0.03800313247280184\n",
      "70 Train Loss 0.01658946 Test MSE 0.00618570580325984 Test RE 0.037592628306058876\n",
      "71 Train Loss 0.015912047 Test MSE 0.005960195111177036 Test RE 0.0369010138697937\n",
      "72 Train Loss 0.015296178 Test MSE 0.005657139102682561 Test RE 0.03595062865447996\n",
      "73 Train Loss 0.014320048 Test MSE 0.005491456563992289 Test RE 0.03542026749532763\n",
      "74 Train Loss 0.013513732 Test MSE 0.005180465480026665 Test RE 0.034402693983220115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Train Loss 0.012852089 Test MSE 0.004750219608263626 Test RE 0.03294313335424873\n",
      "76 Train Loss 0.012350444 Test MSE 0.004102321182078062 Test RE 0.030614198233300454\n",
      "77 Train Loss 0.011975964 Test MSE 0.00421168067490849 Test RE 0.031019570361095754\n",
      "78 Train Loss 0.011821263 Test MSE 0.0042189796098720264 Test RE 0.031046437523606335\n",
      "79 Train Loss 0.010984094 Test MSE 0.00411261207360698 Test RE 0.030652572856888067\n",
      "80 Train Loss 0.010566451 Test MSE 0.0041063127687581925 Test RE 0.030629088524644032\n",
      "81 Train Loss 0.010391086 Test MSE 0.004317701549654946 Test RE 0.031407572433604036\n",
      "82 Train Loss 0.009956182 Test MSE 0.003897588762258915 Test RE 0.02984049805592784\n",
      "83 Train Loss 0.009631135 Test MSE 0.003973761904354156 Test RE 0.030130683341330834\n",
      "84 Train Loss 0.009451612 Test MSE 0.004137512576829356 Test RE 0.030745228404208954\n",
      "85 Train Loss 0.009274986 Test MSE 0.0038272852976706834 Test RE 0.02957014668082751\n",
      "86 Train Loss 0.008904768 Test MSE 0.003665475298339086 Test RE 0.028938312942758178\n",
      "87 Train Loss 0.008426588 Test MSE 0.004045916305698815 Test RE 0.030403004767928874\n",
      "88 Train Loss 0.008101951 Test MSE 0.0036575013051524086 Test RE 0.028906819135609843\n",
      "89 Train Loss 0.007979985 Test MSE 0.0035590577277384906 Test RE 0.028515144481692324\n",
      "90 Train Loss 0.0077991975 Test MSE 0.0034102239474449575 Test RE 0.02791254975209742\n",
      "91 Train Loss 0.007516769 Test MSE 0.0035858324854252084 Test RE 0.02862220309010858\n",
      "92 Train Loss 0.0072398484 Test MSE 0.0035904179582340627 Test RE 0.02864049792160271\n",
      "93 Train Loss 0.007061308 Test MSE 0.003399512768353686 Test RE 0.027868679986190928\n",
      "94 Train Loss 0.0070048645 Test MSE 0.0032730492208230596 Test RE 0.027345403021311894\n",
      "95 Train Loss 0.006942891 Test MSE 0.003373385273077934 Test RE 0.027761378835511514\n",
      "96 Train Loss 0.006717856 Test MSE 0.0031385281375522498 Test RE 0.026777564467215922\n",
      "97 Train Loss 0.006057609 Test MSE 0.0024363203092844766 Test RE 0.023592570040872205\n",
      "98 Train Loss 0.0059604445 Test MSE 0.0024771325355944394 Test RE 0.02378935581427461\n",
      "99 Train Loss 0.0059395004 Test MSE 0.002490289503635692 Test RE 0.023852449185464593\n",
      "Training time: 123.72\n",
      "5\n",
      "KG_rowdy_tune43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.27\n",
      "0\n",
      "KG_rowdy_tune44\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.06\n",
      "0\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 57.979897 Test MSE 7.9482862150949565 Test RE 1.3475497538049475\n",
      "1 Train Loss 37.16923 Test MSE 7.78938353362306 Test RE 1.3340115948380593\n",
      "2 Train Loss 23.274773 Test MSE 6.1666464787362605 Test RE 1.1869504412737693\n",
      "3 Train Loss 17.526789 Test MSE 5.718077644258866 Test RE 1.1429654021615165\n",
      "4 Train Loss 15.005381 Test MSE 5.863220485996592 Test RE 1.157380533063894\n",
      "5 Train Loss 12.262774 Test MSE 5.884081589312138 Test RE 1.1594376616504074\n",
      "6 Train Loss 10.958381 Test MSE 5.708642717970129 Test RE 1.142022056597997\n",
      "7 Train Loss 9.7644825 Test MSE 5.651207675346968 Test RE 1.136262552495558\n",
      "8 Train Loss 8.89495 Test MSE 5.472489824314641 Test RE 1.1181512190874097\n",
      "9 Train Loss 7.9907675 Test MSE 5.424632261661423 Test RE 1.1132513014751166\n",
      "10 Train Loss 6.8580513 Test MSE 5.191277412178031 Test RE 1.0890433789124523\n",
      "11 Train Loss 5.584258 Test MSE 4.649545541732912 Test RE 1.0306549970508525\n",
      "12 Train Loss 4.626956 Test MSE 4.279478047279273 Test RE 0.9887886251457177\n",
      "13 Train Loss 3.9421709 Test MSE 3.972572842338744 Test RE 0.9526733027575202\n",
      "14 Train Loss 3.3641093 Test MSE 3.6445986755428113 Test RE 0.912500091729187\n",
      "15 Train Loss 2.944588 Test MSE 3.422015461890794 Test RE 0.8841970142165116\n",
      "16 Train Loss 2.4270113 Test MSE 2.9421033510617667 Test RE 0.8198549490360277\n",
      "17 Train Loss 2.1259477 Test MSE 2.7121947466598813 Test RE 0.7871699297550309\n",
      "18 Train Loss 1.9218737 Test MSE 2.5411233498439043 Test RE 0.7619402809338733\n",
      "19 Train Loss 1.7597044 Test MSE 2.327552004187902 Test RE 0.7292186323825093\n",
      "20 Train Loss 1.6381495 Test MSE 2.053422308005549 Test RE 0.6849315919630351\n",
      "21 Train Loss 1.4963106 Test MSE 1.714312194121341 Test RE 0.625825157669118\n",
      "22 Train Loss 1.2202082 Test MSE 0.908674219733172 Test RE 0.45562984482181085\n",
      "23 Train Loss 0.8252153 Test MSE 0.5653629726572291 Test RE 0.35939476034094947\n",
      "24 Train Loss 0.5883395 Test MSE 0.33104139411559447 Test RE 0.27501045931379864\n",
      "25 Train Loss 0.41031507 Test MSE 0.15501383683932524 Test RE 0.18818859212076178\n",
      "26 Train Loss 0.2510071 Test MSE 0.08820309288666817 Test RE 0.14195476247517197\n",
      "27 Train Loss 0.15892711 Test MSE 0.04581147938732403 Test RE 0.10230461341247071\n",
      "28 Train Loss 0.11764517 Test MSE 0.02317077127695469 Test RE 0.0727575900339165\n",
      "29 Train Loss 0.09178091 Test MSE 0.015072091942111208 Test RE 0.05868063808313726\n",
      "30 Train Loss 0.07377339 Test MSE 0.012380465067266729 Test RE 0.05318345408005811\n",
      "31 Train Loss 0.061566085 Test MSE 0.010468040920320193 Test RE 0.04890359274406173\n",
      "32 Train Loss 0.05315699 Test MSE 0.009377771753160655 Test RE 0.046286878031284305\n",
      "33 Train Loss 0.044807646 Test MSE 0.007562749911784569 Test RE 0.04156692806520523\n",
      "34 Train Loss 0.039505824 Test MSE 0.007848464287615821 Test RE 0.04234483096062529\n",
      "35 Train Loss 0.03601885 Test MSE 0.008708576080636743 Test RE 0.044604804008281464\n",
      "36 Train Loss 0.03302002 Test MSE 0.009226856195535309 Test RE 0.04591292233534458\n",
      "37 Train Loss 0.028791744 Test MSE 0.008802327526209842 Test RE 0.04484425592227154\n",
      "38 Train Loss 0.026243497 Test MSE 0.00895251985022488 Test RE 0.04522522191786543\n",
      "39 Train Loss 0.023184013 Test MSE 0.007960326233988983 Test RE 0.042645527776891914\n",
      "40 Train Loss 0.020008223 Test MSE 0.006499753896435603 Test RE 0.03853510234817779\n",
      "41 Train Loss 0.018083103 Test MSE 0.005134680379624139 Test RE 0.034250330596988725\n",
      "42 Train Loss 0.016095236 Test MSE 0.003971527269687121 Test RE 0.030122210194262353\n",
      "43 Train Loss 0.013790237 Test MSE 0.003917448810532366 Test RE 0.02991642714290438\n",
      "44 Train Loss 0.012151156 Test MSE 0.0023531995760773276 Test RE 0.02318661981271145\n",
      "45 Train Loss 0.0108972555 Test MSE 0.002198558788662896 Test RE 0.02241181876095102\n",
      "46 Train Loss 0.009865192 Test MSE 0.0018649871656871394 Test RE 0.020641724817447343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Train Loss 0.009054108 Test MSE 0.0016294646223031439 Test RE 0.01929436669665426\n",
      "48 Train Loss 0.008112469 Test MSE 0.0017016931178012154 Test RE 0.019717356169381462\n",
      "49 Train Loss 0.0074837133 Test MSE 0.0017595661596361118 Test RE 0.02004983766850148\n",
      "50 Train Loss 0.006438031 Test MSE 0.0015564030341890744 Test RE 0.018856847753372492\n",
      "51 Train Loss 0.0061221933 Test MSE 0.0013491290108722214 Test RE 0.01755637306689776\n",
      "52 Train Loss 0.0057589957 Test MSE 0.0011875979823440014 Test RE 0.016471865439411707\n",
      "53 Train Loss 0.005512735 Test MSE 0.0011960616632493177 Test RE 0.016530456438848547\n",
      "54 Train Loss 0.005077433 Test MSE 0.001026875742775585 Test RE 0.01531676353870312\n",
      "55 Train Loss 0.0048162267 Test MSE 0.0010377610058623522 Test RE 0.01539773121487259\n",
      "56 Train Loss 0.004358054 Test MSE 0.0009959329492442435 Test RE 0.015084228779424468\n",
      "57 Train Loss 0.0037603101 Test MSE 0.0008811706037738091 Test RE 0.014188551488123799\n",
      "58 Train Loss 0.0036129206 Test MSE 0.0009191392340547942 Test RE 0.014491011883557888\n",
      "59 Train Loss 0.0032109218 Test MSE 0.0008548719165340208 Test RE 0.013975217814239702\n",
      "60 Train Loss 0.0030619833 Test MSE 0.0008214167819403349 Test RE 0.013699030922830544\n",
      "61 Train Loss 0.0029051187 Test MSE 0.0007739510306539765 Test RE 0.013297340868192519\n",
      "62 Train Loss 0.002730269 Test MSE 0.0007269086782282046 Test RE 0.0128868860138378\n",
      "63 Train Loss 0.002642417 Test MSE 0.0007163608722175412 Test RE 0.012793046797704039\n",
      "64 Train Loss 0.002447134 Test MSE 0.0006658473777039807 Test RE 0.012333757552115689\n",
      "65 Train Loss 0.0023801776 Test MSE 0.0006332180461433617 Test RE 0.012027758567932654\n",
      "66 Train Loss 0.002287976 Test MSE 0.0006081399915729729 Test RE 0.01178717800628312\n",
      "67 Train Loss 0.002184818 Test MSE 0.0006124234198854973 Test RE 0.01182861660495345\n",
      "68 Train Loss 0.0021071127 Test MSE 0.0006369567486674288 Test RE 0.012063213993193071\n",
      "69 Train Loss 0.002013454 Test MSE 0.00063424663302232 Test RE 0.012037523430727122\n",
      "70 Train Loss 0.0018493577 Test MSE 0.0007135273480926319 Test RE 0.012767720649377442\n",
      "71 Train Loss 0.0017043641 Test MSE 0.0008068336436680692 Test RE 0.013576882514928746\n",
      "72 Train Loss 0.001653485 Test MSE 0.0008408049676913918 Test RE 0.013859759514768302\n",
      "73 Train Loss 0.0016159471 Test MSE 0.0007880207288555443 Test RE 0.013417663039452183\n",
      "74 Train Loss 0.0015463288 Test MSE 0.0007912378592315539 Test RE 0.013445024251090896\n",
      "75 Train Loss 0.0013832389 Test MSE 0.0007564351405184371 Test RE 0.013146008485358419\n",
      "76 Train Loss 0.0013215725 Test MSE 0.0008341342439194001 Test RE 0.013804670201837121\n",
      "77 Train Loss 0.0012775138 Test MSE 0.0008626785615518913 Test RE 0.014038883271233064\n",
      "78 Train Loss 0.0011699806 Test MSE 0.0008594898882683008 Test RE 0.01401291365946223\n",
      "79 Train Loss 0.0010885886 Test MSE 0.0007931293723457007 Test RE 0.013461085324632877\n",
      "80 Train Loss 0.0010624399 Test MSE 0.0008082180882252877 Test RE 0.013588525797880469\n",
      "81 Train Loss 0.0010436266 Test MSE 0.0008017164220135461 Test RE 0.013533759357737226\n",
      "82 Train Loss 0.0010082426 Test MSE 0.0007762844241743251 Test RE 0.013317370932349117\n",
      "83 Train Loss 0.0009759399 Test MSE 0.0007210738300526242 Test RE 0.012835060711276278\n",
      "84 Train Loss 0.000942806 Test MSE 0.0006938649994947099 Test RE 0.012590574605479389\n",
      "85 Train Loss 0.0009028184 Test MSE 0.000670450226159458 Test RE 0.012376314334844405\n",
      "86 Train Loss 0.0008827915 Test MSE 0.000614884742137957 Test RE 0.011852362303367335\n",
      "87 Train Loss 0.00084675086 Test MSE 0.0006366429646258111 Test RE 0.012060242276239195\n",
      "88 Train Loss 0.00079328136 Test MSE 0.0005734126714787755 Test RE 0.011445682729348186\n",
      "89 Train Loss 0.00076628424 Test MSE 0.0005687471376727943 Test RE 0.011399024111259518\n",
      "90 Train Loss 0.00075305067 Test MSE 0.0005843797365597196 Test RE 0.011554619125932489\n",
      "91 Train Loss 0.0007408686 Test MSE 0.0005720224750554024 Test RE 0.011431799705911357\n",
      "92 Train Loss 0.00072147296 Test MSE 0.0006009853712933385 Test RE 0.011717636212813142\n",
      "93 Train Loss 0.000705772 Test MSE 0.0006097767198469569 Test RE 0.011803029162660768\n",
      "94 Train Loss 0.0006959349 Test MSE 0.0005997385643579102 Test RE 0.011705475171990613\n",
      "95 Train Loss 0.0006872774 Test MSE 0.0005916644561592957 Test RE 0.011626414450683223\n",
      "96 Train Loss 0.00067785993 Test MSE 0.000593910796803845 Test RE 0.011648464233174052\n",
      "97 Train Loss 0.0006553182 Test MSE 0.0006004985212757485 Test RE 0.0117128891029264\n",
      "98 Train Loss 0.0006244177 Test MSE 0.0005794232388140491 Test RE 0.011505513728706358\n",
      "99 Train Loss 0.00059620576 Test MSE 0.0005306863429070163 Test RE 0.011011006421949842\n",
      "Training time: 125.21\n",
      "1\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 56.019505 Test MSE 8.724069601308454 Test RE 1.4117819374213816\n",
      "1 Train Loss 42.51062 Test MSE 9.030072934298126 Test RE 1.4363282068427266\n",
      "2 Train Loss 38.904213 Test MSE 9.027013173727758 Test RE 1.4360848426531463\n",
      "3 Train Loss 35.866417 Test MSE 9.693050977528292 Test RE 1.4881212168349547\n",
      "4 Train Loss 32.687912 Test MSE 9.859780845681366 Test RE 1.5008652115937253\n",
      "5 Train Loss 30.11024 Test MSE 9.782580645354884 Test RE 1.4949779209223701\n",
      "6 Train Loss 27.166214 Test MSE 9.7641907076677 Test RE 1.493572081065735\n",
      "7 Train Loss 23.937817 Test MSE 9.523371179340828 Test RE 1.4750387040245398\n",
      "8 Train Loss 21.139336 Test MSE 9.100201210485032 Test RE 1.441894740673496\n",
      "9 Train Loss 18.092371 Test MSE 8.953216778921135 Test RE 1.4302027548675813\n",
      "10 Train Loss 15.98106 Test MSE 8.656030100539533 Test RE 1.4062658786969184\n",
      "11 Train Loss 13.665073 Test MSE 8.47226464469396 Test RE 1.3912584556941634\n",
      "12 Train Loss 11.484535 Test MSE 8.318670571532572 Test RE 1.3785896807928137\n",
      "13 Train Loss 9.154425 Test MSE 8.052441506656317 Test RE 1.3563502434080186\n",
      "14 Train Loss 7.0949917 Test MSE 7.569035244057779 Test RE 1.3150077853214255\n",
      "15 Train Loss 5.274686 Test MSE 7.060338971526922 Test RE 1.2700500515007511\n",
      "16 Train Loss 3.8342903 Test MSE 6.176688651290977 Test RE 1.1879165022020364\n",
      "17 Train Loss 2.956168 Test MSE 5.708144219823151 Test RE 1.1419721928794302\n",
      "18 Train Loss 2.4859831 Test MSE 5.626259204401237 Test RE 1.1337516405577572\n",
      "19 Train Loss 2.185159 Test MSE 5.698465460634604 Test RE 1.1410036151128926\n",
      "20 Train Loss 1.9580996 Test MSE 5.725799895120358 Test RE 1.143736927852321\n",
      "21 Train Loss 1.7673764 Test MSE 5.667432555684984 Test RE 1.1378925147541754\n",
      "22 Train Loss 1.6284705 Test MSE 5.580450520783033 Test RE 1.1291267365854434\n",
      "23 Train Loss 1.5012476 Test MSE 5.663936312224659 Test RE 1.137541477227468\n",
      "24 Train Loss 1.4236362 Test MSE 5.676028290395867 Test RE 1.1387551025491756\n",
      "25 Train Loss 1.352804 Test MSE 5.714013290151149 Test RE 1.1425591255954226\n",
      "26 Train Loss 1.3074584 Test MSE 5.7449486848700495 Test RE 1.14564783094809\n",
      "27 Train Loss 1.2533449 Test MSE 5.7507819647034015 Test RE 1.1462293147181286\n",
      "28 Train Loss 1.1943136 Test MSE 5.84681484946463 Test RE 1.1557601893384912\n",
      "29 Train Loss 1.1480539 Test MSE 5.8615035398858755 Test RE 1.1572110608849469\n",
      "30 Train Loss 1.1157569 Test MSE 5.872652435554551 Test RE 1.1583110769667846\n",
      "31 Train Loss 1.0894537 Test MSE 5.905383325114169 Test RE 1.1615344818248285\n",
      "32 Train Loss 1.0590823 Test MSE 5.905181921597641 Test RE 1.1615146745480636\n",
      "33 Train Loss 1.0337894 Test MSE 5.948647540657163 Test RE 1.1657815535190355\n",
      "34 Train Loss 1.0041975 Test MSE 5.94854107885564 Test RE 1.1657711215881787\n",
      "35 Train Loss 0.98139197 Test MSE 5.935749407840575 Test RE 1.1645170169403156\n",
      "36 Train Loss 0.9587894 Test MSE 5.989932800098765 Test RE 1.1698199819114632\n",
      "37 Train Loss 0.940977 Test MSE 5.994474525753746 Test RE 1.170263392118879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 0.92377317 Test MSE 6.004716411007329 Test RE 1.1712626947382878\n",
      "39 Train Loss 0.903331 Test MSE 6.044692716859352 Test RE 1.1751550587079433\n",
      "40 Train Loss 0.8906857 Test MSE 6.064487332923395 Test RE 1.177077632074641\n",
      "41 Train Loss 0.87892073 Test MSE 6.080760015672056 Test RE 1.178655785184383\n",
      "42 Train Loss 0.8680073 Test MSE 6.108999990165553 Test RE 1.1813895432432961\n",
      "43 Train Loss 0.85634375 Test MSE 6.118233251421367 Test RE 1.1822819937062767\n",
      "44 Train Loss 0.8433201 Test MSE 6.173266352290442 Test RE 1.1875873639719499\n",
      "45 Train Loss 0.8316692 Test MSE 6.219760196907861 Test RE 1.192051121507344\n",
      "46 Train Loss 0.819257 Test MSE 6.276374200089348 Test RE 1.1974640239270766\n",
      "47 Train Loss 0.8065516 Test MSE 6.308316826915387 Test RE 1.2005073098790993\n",
      "48 Train Loss 0.79446757 Test MSE 6.3486826730358805 Test RE 1.2043421061239359\n",
      "49 Train Loss 0.7853851 Test MSE 6.368718491817004 Test RE 1.2062410018043992\n",
      "50 Train Loss 0.77399635 Test MSE 6.410138547813179 Test RE 1.2101571427012274\n",
      "51 Train Loss 0.7612754 Test MSE 6.466471938819023 Test RE 1.2154630446080308\n",
      "52 Train Loss 0.7505271 Test MSE 6.447344132220848 Test RE 1.213664045055829\n",
      "53 Train Loss 0.7412448 Test MSE 6.499680935894339 Test RE 1.2185800934657458\n",
      "54 Train Loss 0.7303903 Test MSE 6.537405308952011 Test RE 1.2221113175565224\n",
      "55 Train Loss 0.719744 Test MSE 6.540271355549606 Test RE 1.2223791794992742\n",
      "56 Train Loss 0.710111 Test MSE 6.573928157467758 Test RE 1.2255203779423909\n",
      "57 Train Loss 0.70354927 Test MSE 6.56858398311946 Test RE 1.225022142640069\n",
      "58 Train Loss 0.6963822 Test MSE 6.571937495696274 Test RE 1.2253348129939603\n",
      "59 Train Loss 0.6909466 Test MSE 6.593447864106434 Test RE 1.2273384741008162\n",
      "60 Train Loss 0.6867211 Test MSE 6.5889774735923 Test RE 1.226922332751082\n",
      "61 Train Loss 0.68040293 Test MSE 6.598187183418306 Test RE 1.2277794955640426\n",
      "62 Train Loss 0.67473626 Test MSE 6.6030628381026855 Test RE 1.228233038577235\n",
      "63 Train Loss 0.66950417 Test MSE 6.63830543190712 Test RE 1.2315064069292176\n",
      "64 Train Loss 0.6655233 Test MSE 6.642091345414538 Test RE 1.2318575290810958\n",
      "65 Train Loss 0.6618994 Test MSE 6.6511449085276375 Test RE 1.232696790500935\n",
      "66 Train Loss 0.65755606 Test MSE 6.667873995062717 Test RE 1.2342460681592686\n",
      "67 Train Loss 0.65370166 Test MSE 6.670396373143403 Test RE 1.234479496450013\n",
      "68 Train Loss 0.649734 Test MSE 6.681216514091704 Test RE 1.2354803237659722\n",
      "69 Train Loss 0.6453959 Test MSE 6.68252113792079 Test RE 1.23560094239809\n",
      "70 Train Loss 0.6411521 Test MSE 6.700137464238916 Test RE 1.2372285035058703\n",
      "71 Train Loss 0.636792 Test MSE 6.7183509648158655 Test RE 1.238908989078471\n",
      "72 Train Loss 0.6329373 Test MSE 6.7230187720334715 Test RE 1.2393393018306145\n",
      "73 Train Loss 0.62870026 Test MSE 6.7240598077287705 Test RE 1.2394352517716913\n",
      "74 Train Loss 0.62492025 Test MSE 6.730085744799081 Test RE 1.239990503097772\n",
      "75 Train Loss 0.62024546 Test MSE 6.748835661964705 Test RE 1.2417165991147217\n",
      "76 Train Loss 0.614875 Test MSE 6.746234515446658 Test RE 1.2414772839019248\n",
      "77 Train Loss 0.6101478 Test MSE 6.7468096848433134 Test RE 1.241530205611032\n",
      "78 Train Loss 0.60558623 Test MSE 6.760116156601887 Test RE 1.2427539135398604\n",
      "79 Train Loss 0.6018923 Test MSE 6.760302913377799 Test RE 1.2427710797472027\n",
      "80 Train Loss 0.5986044 Test MSE 6.756145943076676 Test RE 1.242388925503534\n",
      "81 Train Loss 0.59582293 Test MSE 6.781280202317722 Test RE 1.2446977519564426\n",
      "82 Train Loss 0.59274673 Test MSE 6.8089674824282715 Test RE 1.2472361510048118\n",
      "83 Train Loss 0.5898065 Test MSE 6.823794490555147 Test RE 1.2485933849912239\n",
      "84 Train Loss 0.58685124 Test MSE 6.834268244798915 Test RE 1.249551242531042\n",
      "85 Train Loss 0.5831183 Test MSE 6.86098901526594 Test RE 1.2519916207951898\n",
      "86 Train Loss 0.5802776 Test MSE 6.880974639037211 Test RE 1.2538137807040555\n",
      "87 Train Loss 0.5778344 Test MSE 6.8859762968660885 Test RE 1.2542693853719098\n",
      "88 Train Loss 0.5749606 Test MSE 6.89751535537657 Test RE 1.2553198558512408\n",
      "89 Train Loss 0.5721232 Test MSE 6.895912244635777 Test RE 1.255173967543299\n",
      "90 Train Loss 0.56902385 Test MSE 6.925280777473429 Test RE 1.2578439154779717\n",
      "91 Train Loss 0.5655775 Test MSE 6.954433109939749 Test RE 1.2604886151005863\n",
      "92 Train Loss 0.56135607 Test MSE 6.9720896820221965 Test RE 1.2620877245674196\n",
      "93 Train Loss 0.5583246 Test MSE 6.999686007205013 Test RE 1.2645830013503478\n",
      "94 Train Loss 0.5557978 Test MSE 7.0107287001647585 Test RE 1.2655801102619109\n",
      "95 Train Loss 0.554051 Test MSE 7.008644051432781 Test RE 1.2653919353774756\n",
      "96 Train Loss 0.5520352 Test MSE 7.017759997403271 Test RE 1.2662145977908608\n",
      "97 Train Loss 0.5499292 Test MSE 7.02065781671808 Test RE 1.266475997611736\n",
      "98 Train Loss 0.5477085 Test MSE 7.012570499666196 Test RE 1.2657463406100213\n",
      "99 Train Loss 0.5459566 Test MSE 7.015863617452954 Test RE 1.2660435042925766\n",
      "Training time: 123.95\n",
      "2\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 52.09711 Test MSE 9.326158391427725 Test RE 1.4596860373938914\n",
      "1 Train Loss 36.798763 Test MSE 7.50401090440059 Test RE 1.3093470935378329\n",
      "2 Train Loss 29.68733 Test MSE 6.629475192451461 Test RE 1.2306870626490516\n",
      "3 Train Loss 22.762516 Test MSE 6.177001994137039 Test RE 1.187946633267246\n",
      "4 Train Loss 17.428833 Test MSE 6.007914900247351 Test RE 1.1715745972602345\n",
      "5 Train Loss 13.024536 Test MSE 5.767675190181462 Test RE 1.147911634696245\n",
      "6 Train Loss 9.952025 Test MSE 5.759321378092123 Test RE 1.1470800246808857\n",
      "7 Train Loss 8.533766 Test MSE 5.37784245801523 Test RE 1.108439766198054\n",
      "8 Train Loss 6.8893595 Test MSE 5.328633387000456 Test RE 1.103356813070645\n",
      "9 Train Loss 5.599722 Test MSE 5.0289360098864 Test RE 1.0718798703294068\n",
      "10 Train Loss 4.1575484 Test MSE 4.916346089842366 Test RE 1.0598131019141863\n",
      "11 Train Loss 3.1041641 Test MSE 4.437357027369065 Test RE 1.0068626872687363\n",
      "12 Train Loss 2.6095192 Test MSE 4.134325650822807 Test RE 0.9718749788628127\n",
      "13 Train Loss 2.285905 Test MSE 3.735504613785803 Test RE 0.9238100846507887\n",
      "14 Train Loss 1.9777765 Test MSE 3.2930428624500148 Test RE 0.8673747035303736\n",
      "15 Train Loss 1.792258 Test MSE 3.0539083736427446 Test RE 0.8352876527023028\n",
      "16 Train Loss 1.602087 Test MSE 2.69822316684896 Test RE 0.7851398012263182\n",
      "17 Train Loss 1.3939036 Test MSE 2.3766122953738384 Test RE 0.7368638147231635\n",
      "18 Train Loss 1.2457469 Test MSE 2.2034762609262253 Test RE 0.7095160895101842\n",
      "19 Train Loss 1.1272706 Test MSE 2.042852423047868 Test RE 0.6831664926489693\n",
      "20 Train Loss 1.0343561 Test MSE 1.7094386345770836 Test RE 0.6249349560623662\n",
      "21 Train Loss 0.87994206 Test MSE 1.3847649411320977 Test RE 0.5624657601992329\n",
      "22 Train Loss 0.7918362 Test MSE 1.1355844231096195 Test RE 0.5093517159688112\n",
      "23 Train Loss 0.6587493 Test MSE 0.8808361778211021 Test RE 0.44859624310905905\n",
      "24 Train Loss 0.5044103 Test MSE 0.6377224426786102 Test RE 0.3817015387645548\n",
      "25 Train Loss 0.41033942 Test MSE 0.5122284110082413 Test RE 0.34208961625215245\n",
      "26 Train Loss 0.3357585 Test MSE 0.42091797536276865 Test RE 0.3101035918988597\n",
      "27 Train Loss 0.2822149 Test MSE 0.3755404928307611 Test RE 0.29291151575628827\n",
      "28 Train Loss 0.23702437 Test MSE 0.21066882421836716 Test RE 0.21938563937985406\n",
      "29 Train Loss 0.19916709 Test MSE 0.11017274765805231 Test RE 0.15865185363479342\n",
      "30 Train Loss 0.14920896 Test MSE 0.05382318210486473 Test RE 0.11089009242053403\n",
      "31 Train Loss 0.11748843 Test MSE 0.043058675746992306 Test RE 0.09918326367008994\n",
      "32 Train Loss 0.09309463 Test MSE 0.040409676327784076 Test RE 0.09608392735618454\n",
      "33 Train Loss 0.072382934 Test MSE 0.027606604362331782 Test RE 0.07941719721824465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 0.061313517 Test MSE 0.02289007544964305 Test RE 0.07231554646502623\n",
      "35 Train Loss 0.052288286 Test MSE 0.018105205637382642 Test RE 0.06431463232666079\n",
      "36 Train Loss 0.043665692 Test MSE 0.016671444177049466 Test RE 0.06171555964122588\n",
      "37 Train Loss 0.038806863 Test MSE 0.014639638809456278 Test RE 0.05783266974649325\n",
      "38 Train Loss 0.034731377 Test MSE 0.014205549005523736 Test RE 0.05696880001481974\n",
      "39 Train Loss 0.031709105 Test MSE 0.01310512959512128 Test RE 0.054717811664968495\n",
      "40 Train Loss 0.0291122 Test MSE 0.011661100605958324 Test RE 0.05161522577840228\n",
      "41 Train Loss 0.026336385 Test MSE 0.010546092050036747 Test RE 0.049085570064887465\n",
      "42 Train Loss 0.023138395 Test MSE 0.010184820948520171 Test RE 0.048237496435045824\n",
      "43 Train Loss 0.021123674 Test MSE 0.00915951702439812 Test RE 0.04574507535930331\n",
      "44 Train Loss 0.01957947 Test MSE 0.008254365896567509 Test RE 0.04342600903532173\n",
      "45 Train Loss 0.017707394 Test MSE 0.00823215472274574 Test RE 0.043367543468191785\n",
      "46 Train Loss 0.015965646 Test MSE 0.008468988922175437 Test RE 0.04398694930003843\n",
      "47 Train Loss 0.01544504 Test MSE 0.008643102639739062 Test RE 0.04443681214311583\n",
      "48 Train Loss 0.014174936 Test MSE 0.008680502842455312 Test RE 0.04453285125366202\n",
      "49 Train Loss 0.012965554 Test MSE 0.0094213549501204 Test RE 0.04639431249013977\n",
      "50 Train Loss 0.0123987 Test MSE 0.008029808295392763 Test RE 0.04283124010028359\n",
      "51 Train Loss 0.011363804 Test MSE 0.0076355788966236205 Test RE 0.041766592469783904\n",
      "52 Train Loss 0.010736939 Test MSE 0.006994813510235086 Test RE 0.039975704889350046\n",
      "53 Train Loss 0.0097613055 Test MSE 0.006240364573404153 Test RE 0.037758352938291564\n",
      "54 Train Loss 0.009424876 Test MSE 0.006049844843755292 Test RE 0.03717749968782976\n",
      "55 Train Loss 0.008849072 Test MSE 0.005743165330389898 Test RE 0.03622294192651104\n",
      "56 Train Loss 0.008502422 Test MSE 0.005538257424983396 Test RE 0.035570881639102284\n",
      "57 Train Loss 0.007885159 Test MSE 0.0063146611368026075 Test RE 0.03798245966181501\n",
      "58 Train Loss 0.0073742894 Test MSE 0.005734783775050105 Test RE 0.036196500458642124\n",
      "59 Train Loss 0.0065151057 Test MSE 0.005966010942487995 Test RE 0.0369190130913302\n",
      "60 Train Loss 0.0061249128 Test MSE 0.005741587569984944 Test RE 0.036217966007665935\n",
      "61 Train Loss 0.005472297 Test MSE 0.006115455267196979 Test RE 0.03737855060959213\n",
      "62 Train Loss 0.0051804273 Test MSE 0.005898557592103255 Test RE 0.03670971157809066\n",
      "63 Train Loss 0.0049717 Test MSE 0.005934951859687633 Test RE 0.0368227874066727\n",
      "64 Train Loss 0.0046104137 Test MSE 0.005537330911324057 Test RE 0.03556790612860617\n",
      "65 Train Loss 0.004252615 Test MSE 0.006188809172868954 Test RE 0.03760205723745547\n",
      "66 Train Loss 0.004086067 Test MSE 0.005773499142040881 Test RE 0.03631847572979931\n",
      "67 Train Loss 0.0038714262 Test MSE 0.006079493674319068 Test RE 0.037268487326972556\n",
      "68 Train Loss 0.003452725 Test MSE 0.005182722346538997 Test RE 0.03441018692318103\n",
      "69 Train Loss 0.0032326612 Test MSE 0.005003880804199853 Test RE 0.03381127423993676\n",
      "70 Train Loss 0.0031441927 Test MSE 0.004877634270153158 Test RE 0.03338202491660808\n",
      "71 Train Loss 0.0030465547 Test MSE 0.004854570127473991 Test RE 0.03330300709138128\n",
      "72 Train Loss 0.0028056542 Test MSE 0.004901010547421459 Test RE 0.033461921716817146\n",
      "73 Train Loss 0.0026221024 Test MSE 0.004941958255902399 Test RE 0.03360141733004438\n",
      "74 Train Loss 0.002519242 Test MSE 0.0047831843792494975 Test RE 0.03305724232180287\n",
      "75 Train Loss 0.002457269 Test MSE 0.004696209031741 Test RE 0.03275531422355369\n",
      "76 Train Loss 0.002304682 Test MSE 0.0047359905319623455 Test RE 0.03289375648814044\n",
      "77 Train Loss 0.0020844683 Test MSE 0.004250951464825662 Test RE 0.03116385202330099\n",
      "78 Train Loss 0.0020354462 Test MSE 0.0040821809221591315 Test RE 0.030538955886991827\n",
      "79 Train Loss 0.0018884653 Test MSE 0.0034845353087248634 Test RE 0.028215028615658482\n",
      "80 Train Loss 0.0018246097 Test MSE 0.0036464819087600364 Test RE 0.02886324075288914\n",
      "81 Train Loss 0.0017658394 Test MSE 0.003590204516566698 Test RE 0.028639646604770485\n",
      "82 Train Loss 0.001727795 Test MSE 0.0034745314714709624 Test RE 0.028174497898299414\n",
      "83 Train Loss 0.0016182421 Test MSE 0.0034827230413769644 Test RE 0.028207690503008573\n",
      "84 Train Loss 0.0015337917 Test MSE 0.003503267874261499 Test RE 0.02829076775768625\n",
      "85 Train Loss 0.0015011469 Test MSE 0.003438728589655435 Test RE 0.02802896168990342\n",
      "86 Train Loss 0.0014790094 Test MSE 0.0032586893003510617 Test RE 0.027285350538972093\n",
      "87 Train Loss 0.0014234735 Test MSE 0.0032957010867600257 Test RE 0.027439864842376368\n",
      "88 Train Loss 0.0013380161 Test MSE 0.003006815080911612 Test RE 0.026209661992175937\n",
      "89 Train Loss 0.0013051906 Test MSE 0.003036038546479887 Test RE 0.026336720868938887\n",
      "90 Train Loss 0.0012756633 Test MSE 0.0029969243267678517 Test RE 0.02616651885719889\n",
      "91 Train Loss 0.0012202186 Test MSE 0.0027103088836251308 Test RE 0.0248838431143731\n",
      "92 Train Loss 0.0011987909 Test MSE 0.0026243808806043737 Test RE 0.02448620566157402\n",
      "93 Train Loss 0.0011910407 Test MSE 0.002709624272967683 Test RE 0.02488070014786116\n",
      "94 Train Loss 0.0011477974 Test MSE 0.0026063537713010834 Test RE 0.02440196176340004\n",
      "95 Train Loss 0.001064385 Test MSE 0.0025560548850466027 Test RE 0.024165353234805894\n",
      "96 Train Loss 0.0010369454 Test MSE 0.0025959411364778725 Test RE 0.024353168885577745\n",
      "97 Train Loss 0.0009912031 Test MSE 0.002487764880253087 Test RE 0.02384035546688859\n",
      "98 Train Loss 0.0009641577 Test MSE 0.002392208167016323 Test RE 0.023378010246457605\n",
      "99 Train Loss 0.00095139677 Test MSE 0.00233453478146763 Test RE 0.0230944824787293\n",
      "Training time: 125.20\n",
      "3\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.99342 Test MSE 8.711296948869785 Test RE 1.4107480847718175\n",
      "1 Train Loss 45.764732 Test MSE 8.91771990463985 Test RE 1.427364772250734\n",
      "2 Train Loss 41.360683 Test MSE 8.934500492233482 Test RE 1.4287070863583908\n",
      "3 Train Loss 35.762188 Test MSE 9.027041572496907 Test RE 1.436087101595781\n",
      "4 Train Loss 31.837555 Test MSE 9.52793720832284 Test RE 1.47539226907246\n",
      "5 Train Loss 29.072235 Test MSE 9.347648713126347 Test RE 1.4613668512394178\n",
      "6 Train Loss 25.796196 Test MSE 9.39721887587043 Test RE 1.4652365093688917\n",
      "7 Train Loss 22.922161 Test MSE 9.524732823770961 Test RE 1.4751441502163452\n",
      "8 Train Loss 20.644884 Test MSE 9.303907297436625 Test RE 1.457943679709728\n",
      "9 Train Loss 18.631388 Test MSE 9.176242790776941 Test RE 1.4479064681637277\n",
      "10 Train Loss 16.7044 Test MSE 8.746805270432269 Test RE 1.4136203524770945\n",
      "11 Train Loss 15.438652 Test MSE 8.91518476691396 Test RE 1.4271618715356211\n",
      "12 Train Loss 14.213402 Test MSE 8.695971954299425 Test RE 1.409506637967953\n",
      "13 Train Loss 12.623108 Test MSE 8.350641822014182 Test RE 1.3812363157374168\n",
      "14 Train Loss 10.818512 Test MSE 7.845974763597604 Test RE 1.3388487385201433\n",
      "15 Train Loss 9.118242 Test MSE 7.522046997383923 Test RE 1.3109196747299532\n",
      "16 Train Loss 8.023723 Test MSE 7.2335653899063255 Test RE 1.2855360682950436\n",
      "17 Train Loss 7.202861 Test MSE 7.2046843949970105 Test RE 1.282967162643507\n",
      "18 Train Loss 6.7196054 Test MSE 7.0943436360511445 Test RE 1.273104844612278\n",
      "19 Train Loss 6.3095894 Test MSE 6.988355665296282 Test RE 1.2635591010866938\n",
      "20 Train Loss 6.0532293 Test MSE 7.023707719708106 Test RE 1.266751057985319\n",
      "21 Train Loss 5.803933 Test MSE 6.933656473212987 Test RE 1.258604327563378\n",
      "22 Train Loss 5.3975334 Test MSE 6.768381589191958 Test RE 1.2435134242181713\n",
      "23 Train Loss 4.7238903 Test MSE 6.372882257391776 Test RE 1.2066352478465738\n",
      "24 Train Loss 3.198413 Test MSE 5.612994723737739 Test RE 1.1324143842738448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 2.5381188 Test MSE 5.788473691356683 Test RE 1.14997948317709\n",
      "26 Train Loss 2.202923 Test MSE 5.752843664918902 Test RE 1.1464347623835853\n",
      "27 Train Loss 1.9267764 Test MSE 5.823427306585627 Test RE 1.1534463247302476\n",
      "28 Train Loss 1.7324145 Test MSE 5.7274296773748095 Test RE 1.1438996919688917\n",
      "29 Train Loss 1.5593472 Test MSE 5.794683211506788 Test RE 1.1505961316341193\n",
      "30 Train Loss 1.4449557 Test MSE 5.794373918500431 Test RE 1.1505654245123949\n",
      "31 Train Loss 1.3728787 Test MSE 5.847266250925153 Test RE 1.1558048035243045\n",
      "32 Train Loss 1.2869097 Test MSE 5.8863383047695415 Test RE 1.1596599792732571\n",
      "33 Train Loss 1.2133287 Test MSE 5.848515393508457 Test RE 1.1559282533414517\n",
      "34 Train Loss 1.1624163 Test MSE 5.945778224552483 Test RE 1.1655003636163557\n",
      "35 Train Loss 1.1245761 Test MSE 5.952428137999893 Test RE 1.1661519444839548\n",
      "36 Train Loss 1.0880506 Test MSE 5.97478081124239 Test RE 1.1683394709135102\n",
      "37 Train Loss 1.0584153 Test MSE 5.9658293123136295 Test RE 1.1674639317083217\n",
      "38 Train Loss 1.0308462 Test MSE 5.998099681487949 Test RE 1.170617196762364\n",
      "39 Train Loss 1.0014203 Test MSE 5.987937704134695 Test RE 1.1696251468794208\n",
      "40 Train Loss 0.9680201 Test MSE 6.005665747636035 Test RE 1.1713552785138572\n",
      "41 Train Loss 0.94690937 Test MSE 6.036148323601559 Test RE 1.1743242027599066\n",
      "42 Train Loss 0.92907566 Test MSE 6.004304471864975 Test RE 1.1712225182176832\n",
      "43 Train Loss 0.91350543 Test MSE 6.028807192679151 Test RE 1.1736098821357437\n",
      "44 Train Loss 0.89907 Test MSE 6.022916583868317 Test RE 1.1730363884065864\n",
      "45 Train Loss 0.8872984 Test MSE 6.038210849064301 Test RE 1.174524816344284\n",
      "46 Train Loss 0.87902427 Test MSE 6.029035789058744 Test RE 1.173632132011916\n",
      "47 Train Loss 0.86790824 Test MSE 6.05554542052745 Test RE 1.1762095283771166\n",
      "48 Train Loss 0.854657 Test MSE 6.0732762607589805 Test RE 1.1779302601955766\n",
      "49 Train Loss 0.8417241 Test MSE 6.082153363242728 Test RE 1.178790816258089\n",
      "50 Train Loss 0.8308299 Test MSE 6.107270973536001 Test RE 1.181222348389711\n",
      "51 Train Loss 0.8214734 Test MSE 6.122646853604719 Test RE 1.182708357122376\n",
      "52 Train Loss 0.81217283 Test MSE 6.129798435754898 Test RE 1.1833988891504512\n",
      "53 Train Loss 0.79987967 Test MSE 6.148110678039696 Test RE 1.185165221821044\n",
      "54 Train Loss 0.78777885 Test MSE 6.15193659908112 Test RE 1.1855339239796554\n",
      "55 Train Loss 0.7779786 Test MSE 6.155966169360968 Test RE 1.1859221277728589\n",
      "56 Train Loss 0.7684761 Test MSE 6.189701992695603 Test RE 1.1891672232701826\n",
      "57 Train Loss 0.7598928 Test MSE 6.1989757862119514 Test RE 1.1900577317024028\n",
      "58 Train Loss 0.7492281 Test MSE 6.213182961171702 Test RE 1.1914206731588917\n",
      "59 Train Loss 0.74209845 Test MSE 6.23576751332896 Test RE 1.1935840807766993\n",
      "60 Train Loss 0.7353291 Test MSE 6.234735378621016 Test RE 1.1934852965825005\n",
      "61 Train Loss 0.72937477 Test MSE 6.249664534715877 Test RE 1.1949133503620895\n",
      "62 Train Loss 0.723379 Test MSE 6.272253641462588 Test RE 1.197070880475539\n",
      "63 Train Loss 0.7177982 Test MSE 6.258344593570148 Test RE 1.1957428604342173\n",
      "64 Train Loss 0.7120479 Test MSE 6.241846644165652 Test RE 1.1941657402287924\n",
      "65 Train Loss 0.7074406 Test MSE 6.257392570108434 Test RE 1.195651908383225\n",
      "66 Train Loss 0.7024858 Test MSE 6.251212282292963 Test RE 1.1950613030836261\n",
      "67 Train Loss 0.69793713 Test MSE 6.263674899643705 Test RE 1.1962519662193072\n",
      "68 Train Loss 0.6937644 Test MSE 6.269128799489682 Test RE 1.1967726524731779\n",
      "69 Train Loss 0.6900311 Test MSE 6.276496414774754 Test RE 1.1974756824875674\n",
      "70 Train Loss 0.6859637 Test MSE 6.290955715074876 Test RE 1.1988542142975303\n",
      "71 Train Loss 0.6825217 Test MSE 6.313527621487093 Test RE 1.2010030289327496\n",
      "72 Train Loss 0.6790029 Test MSE 6.3112176222892575 Test RE 1.2007832967945913\n",
      "73 Train Loss 0.67446154 Test MSE 6.336801243049034 Test RE 1.2032146275337205\n",
      "74 Train Loss 0.67130977 Test MSE 6.337415643901267 Test RE 1.2032729565033364\n",
      "75 Train Loss 0.66809046 Test MSE 6.341040251456898 Test RE 1.2036170059599014\n",
      "76 Train Loss 0.6652423 Test MSE 6.3455799320624795 Test RE 1.204047775909138\n",
      "77 Train Loss 0.66285825 Test MSE 6.346943964644941 Test RE 1.2041771787505373\n",
      "78 Train Loss 0.6602517 Test MSE 6.359126662432276 Test RE 1.205332308983668\n",
      "79 Train Loss 0.65734583 Test MSE 6.377642341548017 Test RE 1.2070857985522223\n",
      "80 Train Loss 0.65454936 Test MSE 6.382113364107979 Test RE 1.2075088359388455\n",
      "81 Train Loss 0.6520571 Test MSE 6.389853960039883 Test RE 1.2082408822902009\n",
      "82 Train Loss 0.6498679 Test MSE 6.399587251235102 Test RE 1.209160753497831\n",
      "83 Train Loss 0.64769137 Test MSE 6.398698257358658 Test RE 1.209076765750115\n",
      "84 Train Loss 0.64565 Test MSE 6.3958448232267955 Test RE 1.2088071479713232\n",
      "85 Train Loss 0.64354384 Test MSE 6.419789050101492 Test RE 1.2110677495417508\n",
      "86 Train Loss 0.6414747 Test MSE 6.4270943711631485 Test RE 1.2117566135525317\n",
      "87 Train Loss 0.6395827 Test MSE 6.4382352836962875 Test RE 1.2128064059138477\n",
      "88 Train Loss 0.6365902 Test MSE 6.433120633960558 Test RE 1.2123245726055552\n",
      "89 Train Loss 0.6340214 Test MSE 6.452011966530848 Test RE 1.2141033079163601\n",
      "90 Train Loss 0.6316658 Test MSE 6.470815228231493 Test RE 1.2158711668171098\n",
      "91 Train Loss 0.6296808 Test MSE 6.477451305768072 Test RE 1.2164944690937025\n",
      "92 Train Loss 0.62835115 Test MSE 6.479426777024245 Test RE 1.216679956142957\n",
      "93 Train Loss 0.6262861 Test MSE 6.484525892802504 Test RE 1.2171586074238314\n",
      "94 Train Loss 0.62412727 Test MSE 6.485100406246731 Test RE 1.2172125248965553\n",
      "95 Train Loss 0.62123686 Test MSE 6.492945376480032 Test RE 1.2179485281454012\n",
      "96 Train Loss 0.61915874 Test MSE 6.507027535752422 Test RE 1.2192685804949452\n",
      "97 Train Loss 0.6165919 Test MSE 6.51536984546501 Test RE 1.220049909455461\n",
      "98 Train Loss 0.6147524 Test MSE 6.526814357585544 Test RE 1.2211209729635093\n",
      "99 Train Loss 0.61210877 Test MSE 6.543795437935328 Test RE 1.2227084613112216\n",
      "Training time: 124.69\n",
      "4\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 52.92257 Test MSE 9.086764382833463 Test RE 1.4408298384932978\n",
      "1 Train Loss 41.17186 Test MSE 8.076980404871032 Test RE 1.3584153327541686\n",
      "2 Train Loss 30.481865 Test MSE 7.273988498706426 Test RE 1.2891230246986995\n",
      "3 Train Loss 22.754606 Test MSE 6.335399066314767 Test RE 1.203081499411812\n",
      "4 Train Loss 19.408175 Test MSE 6.098465565945299 Test RE 1.1803705034288645\n",
      "5 Train Loss 16.214901 Test MSE 6.020248933836417 Test RE 1.172776580961852\n",
      "6 Train Loss 12.603759 Test MSE 5.953401514793417 Test RE 1.1662472886706587\n",
      "7 Train Loss 9.74893 Test MSE 5.911645172691904 Test RE 1.1621501425199225\n",
      "8 Train Loss 8.237007 Test MSE 5.7115115312971305 Test RE 1.1423089756390588\n",
      "9 Train Loss 6.7927694 Test MSE 5.410548975188446 Test RE 1.1118052655666186\n",
      "10 Train Loss 5.0964966 Test MSE 5.076027464394431 Test RE 1.076886770957836\n",
      "11 Train Loss 4.0649743 Test MSE 4.843841771669019 Test RE 1.0519692236906169\n",
      "12 Train Loss 3.4268975 Test MSE 4.556395792072478 Test RE 1.0202786088475195\n",
      "13 Train Loss 2.9022062 Test MSE 3.921043139611436 Test RE 0.9464743972579537\n",
      "14 Train Loss 2.4509273 Test MSE 3.3090882287854044 Test RE 0.869485279302371\n",
      "15 Train Loss 2.129994 Test MSE 2.7335024994476065 Test RE 0.7902559928179147\n",
      "16 Train Loss 1.9101558 Test MSE 2.5554106806369 Test RE 0.7640792629091434\n",
      "17 Train Loss 1.6825442 Test MSE 2.2586472409351166 Test RE 0.7183436614861214\n",
      "18 Train Loss 1.5553532 Test MSE 2.162793887945464 Test RE 0.7029357431849834\n",
      "19 Train Loss 1.4330237 Test MSE 2.0917400870171314 Test RE 0.6912926191988279\n",
      "20 Train Loss 1.3262355 Test MSE 1.9801112884825522 Test RE 0.6725938007131559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 1.2387589 Test MSE 1.792071899124015 Test RE 0.6398611986106834\n",
      "22 Train Loss 1.167428 Test MSE 1.649372561797117 Test RE 0.6138573257475439\n",
      "23 Train Loss 1.0896897 Test MSE 1.569338229390577 Test RE 0.5987786923095872\n",
      "24 Train Loss 0.9824926 Test MSE 1.395069930976103 Test RE 0.5645547286319497\n",
      "25 Train Loss 0.8568578 Test MSE 1.2133423352061226 Test RE 0.5265016490604211\n",
      "26 Train Loss 0.7579812 Test MSE 0.988710180076403 Test RE 0.47527236551876717\n",
      "27 Train Loss 0.6090724 Test MSE 0.7772416256022915 Test RE 0.4213918055481201\n",
      "28 Train Loss 0.4933495 Test MSE 0.6822488847799607 Test RE 0.3948021212980676\n",
      "29 Train Loss 0.3980926 Test MSE 0.5588876914153436 Test RE 0.35733070221683655\n",
      "30 Train Loss 0.32976356 Test MSE 0.4846921895324371 Test RE 0.3327676279748802\n",
      "31 Train Loss 0.27457199 Test MSE 0.42248485659862445 Test RE 0.3106802412425156\n",
      "32 Train Loss 0.21781868 Test MSE 0.2767556881220357 Test RE 0.25145272016842124\n",
      "33 Train Loss 0.18854406 Test MSE 0.228158480599472 Test RE 0.22831075399172715\n",
      "34 Train Loss 0.15327838 Test MSE 0.1583001322369999 Test RE 0.1901729306021321\n",
      "35 Train Loss 0.11426805 Test MSE 0.11538236307347687 Test RE 0.16235952605409545\n",
      "36 Train Loss 0.076928206 Test MSE 0.047108134614559 Test RE 0.10374233386587338\n",
      "37 Train Loss 0.06362418 Test MSE 0.03827470723966883 Test RE 0.09351127941577343\n",
      "38 Train Loss 0.054075975 Test MSE 0.030644622604236723 Test RE 0.08367297274234534\n",
      "39 Train Loss 0.0428546 Test MSE 0.023314179178189738 Test RE 0.07298239736665685\n",
      "40 Train Loss 0.034749012 Test MSE 0.01726346918994604 Test RE 0.06280180083985772\n",
      "41 Train Loss 0.02968786 Test MSE 0.012487787844628655 Test RE 0.053413472882934354\n",
      "42 Train Loss 0.025877267 Test MSE 0.012371810485076507 Test RE 0.05316486184462616\n",
      "43 Train Loss 0.022807272 Test MSE 0.013113832775467333 Test RE 0.05473597783192673\n",
      "44 Train Loss 0.01905984 Test MSE 0.010853028338834236 Test RE 0.04979474684683953\n",
      "45 Train Loss 0.017164152 Test MSE 0.010588221551899816 Test RE 0.049183515799648865\n",
      "46 Train Loss 0.015438425 Test MSE 0.009891846180983202 Test RE 0.04753863828727257\n",
      "47 Train Loss 0.013564181 Test MSE 0.008223648393360873 Test RE 0.04334513172015787\n",
      "48 Train Loss 0.0121755935 Test MSE 0.006582965329121284 Test RE 0.0387809857696454\n",
      "49 Train Loss 0.010815596 Test MSE 0.0052729108370468914 Test RE 0.03470829452494775\n",
      "50 Train Loss 0.009424646 Test MSE 0.005053126770922726 Test RE 0.03397724464074325\n",
      "51 Train Loss 0.008195284 Test MSE 0.004761492669266256 Test RE 0.03298219995673444\n",
      "52 Train Loss 0.007261628 Test MSE 0.004307062061341187 Test RE 0.031368851993352286\n",
      "53 Train Loss 0.0065242555 Test MSE 0.003617078762315395 Test RE 0.028746636880158924\n",
      "54 Train Loss 0.006141265 Test MSE 0.003641881022153619 Test RE 0.028845026153722083\n",
      "55 Train Loss 0.0055778446 Test MSE 0.0036395396263292613 Test RE 0.0288357523084213\n",
      "56 Train Loss 0.0048852093 Test MSE 0.003675373274308662 Test RE 0.02897735803233095\n",
      "57 Train Loss 0.004631587 Test MSE 0.003841532234658345 Test RE 0.029625132481200585\n",
      "58 Train Loss 0.0041590272 Test MSE 0.0035690577410291227 Test RE 0.028555176398305144\n",
      "59 Train Loss 0.003938063 Test MSE 0.003459061059087427 Test RE 0.02811170419951515\n",
      "60 Train Loss 0.003602668 Test MSE 0.0031583671930137122 Test RE 0.02686206342564293\n",
      "61 Train Loss 0.00340903 Test MSE 0.0031577995267391074 Test RE 0.02685964930280984\n",
      "62 Train Loss 0.0032422554 Test MSE 0.003149141954745511 Test RE 0.026822804191259222\n",
      "63 Train Loss 0.0029797351 Test MSE 0.002774507927544441 Test RE 0.025176829875782365\n",
      "64 Train Loss 0.0028273975 Test MSE 0.0025796210894184117 Test RE 0.02427649698273316\n",
      "65 Train Loss 0.0025647306 Test MSE 0.002196685711351366 Test RE 0.02240226977496351\n",
      "66 Train Loss 0.002376148 Test MSE 0.0020701617812918386 Test RE 0.021747543266171652\n",
      "67 Train Loss 0.0022797554 Test MSE 0.0020896843234454354 Test RE 0.02184984712030449\n",
      "68 Train Loss 0.0021433672 Test MSE 0.0019101291233205398 Test RE 0.020890047303198093\n",
      "69 Train Loss 0.0020634152 Test MSE 0.001907380706568305 Test RE 0.020875012920686074\n",
      "70 Train Loss 0.0020007198 Test MSE 0.001764459851627545 Test RE 0.020077699537497874\n",
      "71 Train Loss 0.0018935581 Test MSE 0.0017381378385424662 Test RE 0.01992737838368968\n",
      "72 Train Loss 0.0017595224 Test MSE 0.001863678081463487 Test RE 0.020634479057183547\n",
      "73 Train Loss 0.0016665469 Test MSE 0.0018264932968029206 Test RE 0.020427588543589115\n",
      "74 Train Loss 0.0016088383 Test MSE 0.0017657866719255116 Test RE 0.02008524702947294\n",
      "75 Train Loss 0.0015602047 Test MSE 0.00169300142523731 Test RE 0.019666936798360065\n",
      "76 Train Loss 0.0014864877 Test MSE 0.001562741509137034 Test RE 0.018895206138426785\n",
      "77 Train Loss 0.0013887262 Test MSE 0.001486362056721582 Test RE 0.01842766741404403\n",
      "78 Train Loss 0.0013304986 Test MSE 0.0014783242554476774 Test RE 0.0183777742148828\n",
      "79 Train Loss 0.0012920665 Test MSE 0.0014161387865517967 Test RE 0.01798709254688509\n",
      "80 Train Loss 0.0012355666 Test MSE 0.0013249409294342008 Test RE 0.017398280101607096\n",
      "81 Train Loss 0.001210209 Test MSE 0.0013183446211238554 Test RE 0.017354916803530664\n",
      "82 Train Loss 0.0011918801 Test MSE 0.0013638163365882975 Test RE 0.017651678324000785\n",
      "83 Train Loss 0.0011613844 Test MSE 0.0013938447566397168 Test RE 0.0178449470287311\n",
      "84 Train Loss 0.0011035684 Test MSE 0.0014121449038189404 Test RE 0.01796171047935457\n",
      "85 Train Loss 0.0010700861 Test MSE 0.0013905693581064693 Test RE 0.017823967758626408\n",
      "86 Train Loss 0.001044466 Test MSE 0.0013538881801107628 Test RE 0.017587311618318065\n",
      "87 Train Loss 0.0009945587 Test MSE 0.001333732161453439 Test RE 0.017455905100250708\n",
      "88 Train Loss 0.00096385524 Test MSE 0.0012392653098401778 Test RE 0.016826361174107893\n",
      "89 Train Loss 0.0009207904 Test MSE 0.001186410893539602 Test RE 0.01646363097956882\n",
      "90 Train Loss 0.0008964683 Test MSE 0.0011653469716355566 Test RE 0.016316826147384344\n",
      "91 Train Loss 0.00088415516 Test MSE 0.0011191338468772155 Test RE 0.01599002252782262\n",
      "92 Train Loss 0.00085315283 Test MSE 0.0010646909058697016 Test RE 0.015596237231624437\n",
      "93 Train Loss 0.00079304515 Test MSE 0.0009418769469174494 Test RE 0.014669156568684642\n",
      "94 Train Loss 0.000746904 Test MSE 0.000909788639574661 Test RE 0.014417113419001969\n",
      "95 Train Loss 0.0007287922 Test MSE 0.000923362754640058 Test RE 0.014524267421724572\n",
      "96 Train Loss 0.0007189863 Test MSE 0.0009338732501265909 Test RE 0.014606697259274068\n",
      "97 Train Loss 0.00069422496 Test MSE 0.0009501482241931209 Test RE 0.014733425817640155\n",
      "98 Train Loss 0.00065520464 Test MSE 0.0008552900250411331 Test RE 0.01397863495958185\n",
      "99 Train Loss 0.00063214486 Test MSE 0.0007916528303712713 Test RE 0.01344854946518217\n",
      "Training time: 124.29\n",
      "5\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 56.28038 Test MSE 7.6487888864512765 Test RE 1.3219176381859972\n",
      "1 Train Loss 46.977394 Test MSE 8.096013315300004 Test RE 1.3600149023199777\n",
      "2 Train Loss 43.859238 Test MSE 8.418915233194015 Test RE 1.3868711969964285\n",
      "3 Train Loss 42.551346 Test MSE 8.411004289627927 Test RE 1.3862194480448486\n",
      "4 Train Loss 40.70733 Test MSE 8.235320212421334 Test RE 1.3716657844174887\n",
      "5 Train Loss 39.208733 Test MSE 8.355261941473195 Test RE 1.3816183578904435\n",
      "6 Train Loss 37.259735 Test MSE 8.181736382737013 Test RE 1.3671960703379542\n",
      "7 Train Loss 35.828075 Test MSE 8.238625361249408 Test RE 1.3719410077640932\n",
      "8 Train Loss 33.58753 Test MSE 8.117170479812847 Test RE 1.3617907939687486\n",
      "9 Train Loss 31.794691 Test MSE 8.028659552199933 Test RE 1.3543458506097603\n",
      "10 Train Loss 29.51635 Test MSE 7.887965408353112 Test RE 1.3424266306681467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 27.221493 Test MSE 7.971557328894447 Test RE 1.3495210003753142\n",
      "12 Train Loss 24.788998 Test MSE 7.814609285178994 Test RE 1.3361699327909298\n",
      "13 Train Loss 22.016747 Test MSE 7.820330732494571 Test RE 1.3366589800883064\n",
      "14 Train Loss 19.676489 Test MSE 7.644280117690077 Test RE 1.3215279621438483\n",
      "15 Train Loss 17.596874 Test MSE 7.226293658830842 Test RE 1.2848897464189852\n",
      "16 Train Loss 15.57777 Test MSE 7.623794550156767 Test RE 1.319756022100235\n",
      "17 Train Loss 13.783213 Test MSE 7.391948375578678 Test RE 1.299533629952058\n",
      "18 Train Loss 11.911423 Test MSE 7.462143890796378 Test RE 1.305689374401731\n",
      "19 Train Loss 10.617346 Test MSE 7.246818697436119 Test RE 1.2867132061945612\n",
      "20 Train Loss 9.281656 Test MSE 7.289647225064379 Test RE 1.2905098273273228\n",
      "21 Train Loss 7.509566 Test MSE 7.247941933043574 Test RE 1.2868129207141898\n",
      "22 Train Loss 5.8694077 Test MSE 7.368061125161608 Test RE 1.297432194529875\n",
      "23 Train Loss 5.1184683 Test MSE 7.300001941473794 Test RE 1.2914260665401327\n",
      "24 Train Loss 4.4578304 Test MSE 7.0647904687966285 Test RE 1.270450367512279\n",
      "25 Train Loss 3.9075983 Test MSE 6.946270069270083 Test RE 1.2597486237279858\n",
      "26 Train Loss 3.5303736 Test MSE 6.870455567096918 Test RE 1.2528550501129898\n",
      "27 Train Loss 3.2509785 Test MSE 6.870762960944588 Test RE 1.2528830770482526\n",
      "28 Train Loss 3.0084097 Test MSE 6.872186271845337 Test RE 1.2530128406428405\n",
      "29 Train Loss 2.8007193 Test MSE 6.805144311403792 Test RE 1.2468859461708186\n",
      "30 Train Loss 2.657609 Test MSE 6.865357520948193 Test RE 1.2523901393011037\n",
      "31 Train Loss 2.500789 Test MSE 6.850778863250192 Test RE 1.2510597009192508\n",
      "32 Train Loss 2.4058385 Test MSE 6.834652209174884 Test RE 1.2495863433207142\n",
      "33 Train Loss 2.3071465 Test MSE 6.781876830731789 Test RE 1.244752506050804\n",
      "34 Train Loss 2.2196345 Test MSE 6.744137771415961 Test RE 1.2412843420193906\n",
      "35 Train Loss 2.1251347 Test MSE 6.646522250225258 Test RE 1.232268343475232\n",
      "36 Train Loss 2.0299377 Test MSE 6.427355771385595 Test RE 1.2117812553431597\n",
      "37 Train Loss 1.9546596 Test MSE 6.344074792374799 Test RE 1.2039049703980356\n",
      "38 Train Loss 1.8846323 Test MSE 6.226409703149013 Test RE 1.1926881584425795\n",
      "39 Train Loss 1.8147211 Test MSE 6.1012645628970406 Test RE 1.1806413481521811\n",
      "40 Train Loss 1.7463052 Test MSE 6.062034173863839 Test RE 1.1768395368680193\n",
      "41 Train Loss 1.6788942 Test MSE 5.964273915976587 Test RE 1.1673117326257967\n",
      "42 Train Loss 1.6233554 Test MSE 5.966553673796557 Test RE 1.1675348053616126\n",
      "43 Train Loss 1.5729924 Test MSE 5.980503479148865 Test RE 1.1688988570063146\n",
      "44 Train Loss 1.5357984 Test MSE 5.952666484705634 Test RE 1.1661752917370065\n",
      "45 Train Loss 1.4933032 Test MSE 5.984608040971847 Test RE 1.1692999097528263\n",
      "46 Train Loss 1.4658233 Test MSE 6.001301331923301 Test RE 1.1709295796213526\n",
      "47 Train Loss 1.4401777 Test MSE 5.9521305360299674 Test RE 1.1661227922249262\n",
      "48 Train Loss 1.415024 Test MSE 5.955094934169366 Test RE 1.1664131438821417\n",
      "49 Train Loss 1.3902358 Test MSE 5.954885872794194 Test RE 1.166392669475034\n",
      "50 Train Loss 1.372657 Test MSE 5.9523552240651405 Test RE 1.16614480210565\n",
      "51 Train Loss 1.350437 Test MSE 5.960126698706259 Test RE 1.1669058209176824\n",
      "52 Train Loss 1.3285341 Test MSE 5.977853750546783 Test RE 1.1686398814960945\n",
      "53 Train Loss 1.3058139 Test MSE 5.977103583518567 Test RE 1.16856655228389\n",
      "54 Train Loss 1.2898326 Test MSE 5.972880134175002 Test RE 1.1681536220311117\n",
      "55 Train Loss 1.2725805 Test MSE 5.991247763658707 Test RE 1.1699483795316683\n",
      "56 Train Loss 1.2588252 Test MSE 6.009414129252568 Test RE 1.1717207668617629\n",
      "57 Train Loss 1.2391232 Test MSE 5.9893766334259535 Test RE 1.1697656716201814\n",
      "58 Train Loss 1.2228904 Test MSE 5.96952470459737 Test RE 1.1678254547336777\n",
      "59 Train Loss 1.205299 Test MSE 5.962954385519896 Test RE 1.167182597997793\n",
      "60 Train Loss 1.1869447 Test MSE 5.965963316462134 Test RE 1.1674770433918265\n",
      "61 Train Loss 1.1715281 Test MSE 5.9580328889058825 Test RE 1.166700834212876\n",
      "62 Train Loss 1.1486369 Test MSE 5.954411855955026 Test RE 1.1663462453469013\n",
      "63 Train Loss 1.1328298 Test MSE 5.9925481438463315 Test RE 1.1700753393245011\n",
      "64 Train Loss 1.1132843 Test MSE 6.033522817626207 Test RE 1.1740687807268033\n",
      "65 Train Loss 1.0839447 Test MSE 6.034977680225575 Test RE 1.1742103237235892\n",
      "66 Train Loss 1.0528351 Test MSE 6.062785145448386 Test RE 1.1769124287107087\n",
      "67 Train Loss 1.0270692 Test MSE 6.06767910739744 Test RE 1.1773873426845916\n",
      "68 Train Loss 1.0028911 Test MSE 6.108475983469529 Test RE 1.181338874614396\n",
      "69 Train Loss 0.9823393 Test MSE 6.163233643706963 Test RE 1.1866219461439276\n",
      "70 Train Loss 0.96770644 Test MSE 6.145475947272506 Test RE 1.1849112473847774\n",
      "71 Train Loss 0.9498627 Test MSE 6.147243165268539 Test RE 1.1850816040813261\n",
      "72 Train Loss 0.93696934 Test MSE 6.15286579730605 Test RE 1.1856234530577314\n",
      "73 Train Loss 0.9262586 Test MSE 6.169913304667381 Test RE 1.1872647974711268\n",
      "74 Train Loss 0.9170029 Test MSE 6.193856226240821 Test RE 1.189566212572676\n",
      "75 Train Loss 0.91091704 Test MSE 6.216488873695182 Test RE 1.1917375967677366\n",
      "76 Train Loss 0.9007261 Test MSE 6.2123288011697575 Test RE 1.1913387748091075\n",
      "77 Train Loss 0.89047825 Test MSE 6.237932341777827 Test RE 1.193791246979454\n",
      "78 Train Loss 0.88185656 Test MSE 6.250305916337292 Test RE 1.194974663717048\n",
      "79 Train Loss 0.87477565 Test MSE 6.262909021018015 Test RE 1.1961788292961426\n",
      "80 Train Loss 0.8677013 Test MSE 6.277414960030405 Test RE 1.197563302657655\n",
      "81 Train Loss 0.8604436 Test MSE 6.296759849439516 Test RE 1.1994071276414435\n",
      "82 Train Loss 0.85155976 Test MSE 6.306172314614825 Test RE 1.200303236304377\n",
      "83 Train Loss 0.845737 Test MSE 6.301569948269717 Test RE 1.199865154118037\n",
      "84 Train Loss 0.83964103 Test MSE 6.311052885311352 Test RE 1.2007676251196364\n",
      "85 Train Loss 0.8358685 Test MSE 6.308976650991632 Test RE 1.2005700923087366\n",
      "86 Train Loss 0.83044577 Test MSE 6.331936159559066 Test RE 1.2027526544198897\n",
      "87 Train Loss 0.82582027 Test MSE 6.357164687783053 Test RE 1.205146354685811\n",
      "88 Train Loss 0.81977963 Test MSE 6.358970679557081 Test RE 1.2053175261084368\n",
      "89 Train Loss 0.8138558 Test MSE 6.377015660341507 Test RE 1.2070264916384912\n",
      "90 Train Loss 0.8078666 Test MSE 6.383333984289377 Test RE 1.2076243023293145\n",
      "91 Train Loss 0.8029612 Test MSE 6.376813180705755 Test RE 1.207007329052305\n",
      "92 Train Loss 0.7981236 Test MSE 6.374532734279455 Test RE 1.2067914875652226\n",
      "93 Train Loss 0.79437983 Test MSE 6.379585757320134 Test RE 1.2072696980851978\n",
      "94 Train Loss 0.7897272 Test MSE 6.395985808243455 Test RE 1.2088204708990558\n",
      "95 Train Loss 0.78472346 Test MSE 6.4244688422251075 Test RE 1.2115090812419875\n",
      "96 Train Loss 0.7796274 Test MSE 6.42111055448293 Test RE 1.2111923914086091\n",
      "97 Train Loss 0.77482176 Test MSE 6.448737590977147 Test RE 1.213795192035662\n",
      "98 Train Loss 0.77152044 Test MSE 6.442683591731464 Test RE 1.2132253099066916\n",
      "99 Train Loss 0.76792526 Test MSE 6.448007899202983 Test RE 1.2137265180191756\n",
      "Training time: 125.48\n",
      "6\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 53.21424 Test MSE 8.336735963321892 Test RE 1.3800857886100557\n",
      "1 Train Loss 42.992325 Test MSE 9.197952847567919 Test RE 1.4496182559749462\n",
      "2 Train Loss 37.49282 Test MSE 9.371702847070948 Test RE 1.4632458975196405\n",
      "3 Train Loss 34.228203 Test MSE 9.177652744753773 Test RE 1.4480177012204196\n",
      "4 Train Loss 30.497822 Test MSE 9.000456820512571 Test RE 1.4339708950140642\n",
      "5 Train Loss 27.093338 Test MSE 8.881151902524861 Test RE 1.424435239973197\n",
      "6 Train Loss 23.378424 Test MSE 8.793754145505122 Test RE 1.417409110962738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 20.815598 Test MSE 8.645158825247638 Test RE 1.4053825230227122\n",
      "8 Train Loss 17.826626 Test MSE 8.648409384493448 Test RE 1.4056467084420685\n",
      "9 Train Loss 14.91457 Test MSE 8.51650620428794 Test RE 1.3948862518778007\n",
      "10 Train Loss 12.871202 Test MSE 8.219222788163968 Test RE 1.3703245441233185\n",
      "11 Train Loss 10.7326355 Test MSE 8.152294899118075 Test RE 1.3647339672175014\n",
      "12 Train Loss 9.001149 Test MSE 7.786315880848453 Test RE 1.3337488855143511\n",
      "13 Train Loss 7.6619754 Test MSE 7.6759285963517465 Test RE 1.3242607995374522\n",
      "14 Train Loss 6.1434164 Test MSE 7.215243455395771 Test RE 1.2839069656325006\n",
      "15 Train Loss 4.894466 Test MSE 6.595756376158821 Test RE 1.2275533144816844\n",
      "16 Train Loss 3.6422408 Test MSE 6.255821827019604 Test RE 1.1955018315082169\n",
      "17 Train Loss 3.0105124 Test MSE 6.1001889416917585 Test RE 1.1805372731008579\n",
      "18 Train Loss 2.59684 Test MSE 5.973363216711336 Test RE 1.1682008608164205\n",
      "19 Train Loss 2.2870333 Test MSE 5.896566828153973 Test RE 1.1606670961070735\n",
      "20 Train Loss 2.034769 Test MSE 5.846819210491053 Test RE 1.155760620368027\n",
      "21 Train Loss 1.8222033 Test MSE 5.728944985986817 Test RE 1.1440510029860738\n",
      "22 Train Loss 1.6706313 Test MSE 5.779286710021636 Test RE 1.1490665451688482\n",
      "23 Train Loss 1.5561893 Test MSE 5.820978196854728 Test RE 1.1532037516247087\n",
      "24 Train Loss 1.4551234 Test MSE 5.8597711055029 Test RE 1.1570400347673895\n",
      "25 Train Loss 1.3584828 Test MSE 5.846018234422116 Test RE 1.155681451825941\n",
      "26 Train Loss 1.2780637 Test MSE 5.920668375109092 Test RE 1.1630367246209434\n",
      "27 Train Loss 1.2297823 Test MSE 5.956303504312752 Test RE 1.1665314980477848\n",
      "28 Train Loss 1.1852944 Test MSE 5.989767719192541 Test RE 1.16980386184136\n",
      "29 Train Loss 1.1409771 Test MSE 6.018108026373718 Test RE 1.1725680323267897\n",
      "30 Train Loss 1.1089419 Test MSE 5.9951633544574 Test RE 1.1703306280255057\n",
      "31 Train Loss 1.076648 Test MSE 6.0110838631844645 Test RE 1.17188353863932\n",
      "32 Train Loss 1.0524396 Test MSE 6.011609853199246 Test RE 1.1719348093893371\n",
      "33 Train Loss 1.0334021 Test MSE 6.003307743883178 Test RE 1.1711253014031746\n",
      "34 Train Loss 1.01043 Test MSE 6.00229436393996 Test RE 1.171026452149554\n",
      "35 Train Loss 0.991037 Test MSE 5.996718635463146 Test RE 1.1704824233023068\n",
      "36 Train Loss 0.972914 Test MSE 5.986294910136966 Test RE 1.1694646922227556\n",
      "37 Train Loss 0.95748556 Test MSE 6.030632724287422 Test RE 1.173787554078679\n",
      "38 Train Loss 0.9304717 Test MSE 6.029838915001597 Test RE 1.173710298990654\n",
      "39 Train Loss 0.8842511 Test MSE 6.120913793774394 Test RE 1.1825409581640332\n",
      "40 Train Loss 0.8523182 Test MSE 6.2178927545221345 Test RE 1.191872155290249\n",
      "41 Train Loss 0.82940376 Test MSE 6.236722950413233 Test RE 1.1936755170603963\n",
      "42 Train Loss 0.8087528 Test MSE 6.248613019201471 Test RE 1.1948128231438295\n",
      "43 Train Loss 0.7924602 Test MSE 6.257071088111856 Test RE 1.1956211938727037\n",
      "44 Train Loss 0.77443516 Test MSE 6.3000226267647665 Test RE 1.1997178343902757\n",
      "45 Train Loss 0.7607971 Test MSE 6.309566088520706 Test RE 1.200626174664061\n",
      "46 Train Loss 0.7518719 Test MSE 6.312042154017987 Test RE 1.200861732656846\n",
      "47 Train Loss 0.7417466 Test MSE 6.324699365180416 Test RE 1.2020651425885087\n",
      "48 Train Loss 0.73283845 Test MSE 6.383889786770861 Test RE 1.2076768756378486\n",
      "49 Train Loss 0.72134614 Test MSE 6.422666563758273 Test RE 1.2113391349056304\n",
      "50 Train Loss 0.712206 Test MSE 6.442666724955938 Test RE 1.213223721809739\n",
      "51 Train Loss 0.7028043 Test MSE 6.436030146085785 Test RE 1.2125986910710684\n",
      "52 Train Loss 0.6936266 Test MSE 6.4604368789764495 Test RE 1.2148957256293307\n",
      "53 Train Loss 0.6865712 Test MSE 6.474451645303775 Test RE 1.2162127616169485\n",
      "54 Train Loss 0.67773247 Test MSE 6.4785362609917065 Test RE 1.2165963445616625\n",
      "55 Train Loss 0.6710246 Test MSE 6.52983915083441 Test RE 1.2214038989382656\n",
      "56 Train Loss 0.66270834 Test MSE 6.540913299900712 Test RE 1.222439167847801\n",
      "57 Train Loss 0.6546344 Test MSE 6.582859751767973 Test RE 1.22635261516945\n",
      "58 Train Loss 0.6471808 Test MSE 6.606598242962278 Test RE 1.2285618041878121\n",
      "59 Train Loss 0.6404265 Test MSE 6.6225091176434 Test RE 1.2300403062193421\n",
      "60 Train Loss 0.6340837 Test MSE 6.638745624435824 Test RE 1.2315472374497807\n",
      "61 Train Loss 0.62767214 Test MSE 6.65834501749172 Test RE 1.2333638298306235\n",
      "62 Train Loss 0.62155473 Test MSE 6.683612467171166 Test RE 1.2357018318956927\n",
      "63 Train Loss 0.6153505 Test MSE 6.71394689368265 Test RE 1.2385028523778034\n",
      "64 Train Loss 0.6087675 Test MSE 6.746193810800177 Test RE 1.2414735385555347\n",
      "65 Train Loss 0.60242176 Test MSE 6.757763901890801 Test RE 1.2425376799707575\n",
      "66 Train Loss 0.59610665 Test MSE 6.767410453395136 Test RE 1.2434242105926536\n",
      "67 Train Loss 0.59084296 Test MSE 6.8059687931055635 Test RE 1.2469614775235427\n",
      "68 Train Loss 0.5841453 Test MSE 6.807405040967157 Test RE 1.2470930422820075\n",
      "69 Train Loss 0.57784915 Test MSE 6.833965065502125 Test RE 1.2495235261571007\n",
      "70 Train Loss 0.5724774 Test MSE 6.855438430494015 Test RE 1.2514850836412428\n",
      "71 Train Loss 0.568034 Test MSE 6.864818165856412 Test RE 1.2523409433004742\n",
      "72 Train Loss 0.5631622 Test MSE 6.862884118964804 Test RE 1.252164517889806\n",
      "73 Train Loss 0.55890787 Test MSE 6.881116128878211 Test RE 1.2538266713925\n",
      "74 Train Loss 0.55524623 Test MSE 6.892156249092092 Test RE 1.254832093271416\n",
      "75 Train Loss 0.5505125 Test MSE 6.91257024122501 Test RE 1.256689073248521\n",
      "76 Train Loss 0.5459727 Test MSE 6.920453915370811 Test RE 1.2574054857863801\n",
      "77 Train Loss 0.5425156 Test MSE 6.927353718179682 Test RE 1.258032156276206\n",
      "78 Train Loss 0.539369 Test MSE 6.920073334424817 Test RE 1.2573709106591893\n",
      "79 Train Loss 0.53619003 Test MSE 6.927758002474589 Test RE 1.2580688654759664\n",
      "80 Train Loss 0.5330882 Test MSE 6.940480296433935 Test RE 1.2592235088998858\n",
      "81 Train Loss 0.5292735 Test MSE 6.967272195853937 Test RE 1.26165161853017\n",
      "82 Train Loss 0.5258434 Test MSE 6.971837735704555 Test RE 1.2620649206992862\n",
      "83 Train Loss 0.52251905 Test MSE 6.9936621488003246 Test RE 1.2640387406105862\n",
      "84 Train Loss 0.51982737 Test MSE 7.019587948293813 Test RE 1.2663794956642358\n",
      "85 Train Loss 0.51710147 Test MSE 7.039153194929856 Test RE 1.2681431167282173\n",
      "86 Train Loss 0.5147723 Test MSE 7.0430238904921625 Test RE 1.2684917326197962\n",
      "87 Train Loss 0.511918 Test MSE 7.0522217218166166 Test RE 1.269319755242656\n",
      "88 Train Loss 0.5096873 Test MSE 7.058333545936679 Test RE 1.269869665560885\n",
      "89 Train Loss 0.5069023 Test MSE 7.07481360985368 Test RE 1.2713512710814832\n",
      "90 Train Loss 0.50387335 Test MSE 7.083810244142155 Test RE 1.2721593664712845\n",
      "91 Train Loss 0.5015678 Test MSE 7.10253889466368 Test RE 1.2738399663226658\n",
      "92 Train Loss 0.49870524 Test MSE 7.098774473580562 Test RE 1.2735023472225577\n",
      "93 Train Loss 0.49625385 Test MSE 7.106104840964011 Test RE 1.2741597023334994\n",
      "94 Train Loss 0.49412417 Test MSE 7.11760402693189 Test RE 1.2751902160297102\n",
      "95 Train Loss 0.49235678 Test MSE 7.114602275827868 Test RE 1.2749212907502017\n",
      "96 Train Loss 0.49056122 Test MSE 7.118424625152338 Test RE 1.2752637231157342\n",
      "97 Train Loss 0.48881868 Test MSE 7.1290885626175085 Test RE 1.2762185862993376\n",
      "98 Train Loss 0.48715287 Test MSE 7.129751396757315 Test RE 1.2762779137701454\n",
      "99 Train Loss 0.48536783 Test MSE 7.13883896199388 Test RE 1.2770910252470329\n",
      "Training time: 123.76\n",
      "7\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 52.614136 Test MSE 8.732115532151745 Test RE 1.412432808088773\n",
      "1 Train Loss 38.817226 Test MSE 7.485786854069853 Test RE 1.307756203500541\n",
      "2 Train Loss 29.650967 Test MSE 7.426520007398702 Test RE 1.3025689995378402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 25.327599 Test MSE 6.513911031253124 Test RE 1.219913315077258\n",
      "4 Train Loss 22.775566 Test MSE 6.360125311093698 Test RE 1.2054269490424843\n",
      "5 Train Loss 19.187288 Test MSE 6.136613255295212 Test RE 1.1840565298322336\n",
      "6 Train Loss 15.731966 Test MSE 6.137713389537246 Test RE 1.1841626602581332\n",
      "7 Train Loss 13.121246 Test MSE 5.861891081217958 Test RE 1.1572493155495118\n",
      "8 Train Loss 11.649618 Test MSE 5.771642645801826 Test RE 1.1483063782790066\n",
      "9 Train Loss 10.332472 Test MSE 5.735317941824652 Test RE 1.1446871550188755\n",
      "10 Train Loss 8.926288 Test MSE 5.518150514132301 Test RE 1.1228062757284656\n",
      "11 Train Loss 7.2020307 Test MSE 5.159364425080945 Test RE 1.0856908124621603\n",
      "12 Train Loss 5.879881 Test MSE 5.110995265749058 Test RE 1.080589640324266\n",
      "13 Train Loss 4.7288547 Test MSE 4.9789075832653 Test RE 1.0665349527943313\n",
      "14 Train Loss 3.9520967 Test MSE 4.811293809568343 Test RE 1.048428938139238\n",
      "15 Train Loss 3.305801 Test MSE 4.579951008565193 Test RE 1.0229124782386316\n",
      "16 Train Loss 2.8164706 Test MSE 4.20493320279722 Test RE 0.9801388660774101\n",
      "17 Train Loss 2.4608388 Test MSE 3.9928376259647576 Test RE 0.9551000877724085\n",
      "18 Train Loss 2.0976696 Test MSE 3.373320227662516 Test RE 0.8778834172996163\n",
      "19 Train Loss 1.8344396 Test MSE 3.033253277728708 Test RE 0.8324581280246884\n",
      "20 Train Loss 1.6550232 Test MSE 2.671767630979256 Test RE 0.7812812508727145\n",
      "21 Train Loss 1.4786226 Test MSE 2.3249302005349817 Test RE 0.7288078130396362\n",
      "22 Train Loss 1.350488 Test MSE 2.216617075549044 Test RE 0.7116286060160265\n",
      "23 Train Loss 1.2342939 Test MSE 1.9461150927752568 Test RE 0.6667949786193593\n",
      "24 Train Loss 1.1268919 Test MSE 1.6275503339087376 Test RE 0.609782946554382\n",
      "25 Train Loss 0.83669096 Test MSE 1.4324910534594824 Test RE 0.5720763833216421\n",
      "26 Train Loss 0.6545867 Test MSE 1.2297152291027287 Test RE 0.5300420634571705\n",
      "27 Train Loss 0.5215079 Test MSE 1.0452205918164816 Test RE 0.4886659052089398\n",
      "28 Train Loss 0.4157688 Test MSE 0.875362026023459 Test RE 0.4472001201734951\n",
      "29 Train Loss 0.3047277 Test MSE 0.6681888297568831 Test RE 0.3907128239728095\n",
      "30 Train Loss 0.23726869 Test MSE 0.503930673808433 Test RE 0.33930749850712316\n",
      "31 Train Loss 0.18708922 Test MSE 0.44129073831072185 Test RE 0.31751954723807796\n",
      "32 Train Loss 0.1567593 Test MSE 0.3653921294114712 Test RE 0.288926684820785\n",
      "33 Train Loss 0.118533105 Test MSE 0.3241744642255295 Test RE 0.2721431837151163\n",
      "34 Train Loss 0.097041406 Test MSE 0.30631987915435693 Test RE 0.264542620517067\n",
      "35 Train Loss 0.080558516 Test MSE 0.3040103941648804 Test RE 0.26354348009946293\n",
      "36 Train Loss 0.070839755 Test MSE 0.2720759693116975 Test RE 0.2493177235532893\n",
      "37 Train Loss 0.061709147 Test MSE 0.2603640434502329 Test RE 0.24389256661229586\n",
      "38 Train Loss 0.053874407 Test MSE 0.2588036143755421 Test RE 0.24316061264055241\n",
      "39 Train Loss 0.044722103 Test MSE 0.2433209256498852 Test RE 0.2357750199405223\n",
      "40 Train Loss 0.03932046 Test MSE 0.22697687028087246 Test RE 0.2277187870984988\n",
      "41 Train Loss 0.034813955 Test MSE 0.21773987161530264 Test RE 0.22303706503583667\n",
      "42 Train Loss 0.030743822 Test MSE 0.1951765484630872 Test RE 0.21116497098606743\n",
      "43 Train Loss 0.026658673 Test MSE 0.1812665284661182 Test RE 0.20350115055799134\n",
      "44 Train Loss 0.023596553 Test MSE 0.17538073608249372 Test RE 0.2001700070783612\n",
      "45 Train Loss 0.020923045 Test MSE 0.16908308477049908 Test RE 0.19654325378803855\n",
      "46 Train Loss 0.017202951 Test MSE 0.127016220887494 Test RE 0.17034824113907382\n",
      "47 Train Loss 0.01584783 Test MSE 0.11820422432780854 Test RE 0.16433291499973918\n",
      "48 Train Loss 0.013658788 Test MSE 0.09259987326986212 Test RE 0.14544984287823584\n",
      "49 Train Loss 0.012523319 Test MSE 0.08666808331647353 Test RE 0.14071411265368228\n",
      "50 Train Loss 0.01132136 Test MSE 0.08600342783069069 Test RE 0.1401735075822695\n",
      "51 Train Loss 0.009363681 Test MSE 0.06989798915847376 Test RE 0.12636895708503196\n",
      "52 Train Loss 0.008754039 Test MSE 0.0642387151491108 Test RE 0.12114527587424109\n",
      "53 Train Loss 0.007846906 Test MSE 0.05546524418973755 Test RE 0.11256892661376769\n",
      "54 Train Loss 0.0072682947 Test MSE 0.04544824585762551 Test RE 0.10189822597434296\n",
      "55 Train Loss 0.006632361 Test MSE 0.039171578930876035 Test RE 0.09460053641956745\n",
      "56 Train Loss 0.0060996036 Test MSE 0.03881774014701413 Test RE 0.09417230152833259\n",
      "57 Train Loss 0.0055044596 Test MSE 0.03944019664412633 Test RE 0.09492434215809453\n",
      "58 Train Loss 0.0050029233 Test MSE 0.03448710996594657 Test RE 0.08876391751936566\n",
      "59 Train Loss 0.0045837997 Test MSE 0.030972597244454374 Test RE 0.08411953685132734\n",
      "60 Train Loss 0.004070388 Test MSE 0.02713529342905181 Test RE 0.07873635782436905\n",
      "61 Train Loss 0.003911484 Test MSE 0.027563943454892416 Test RE 0.07935581118986496\n",
      "62 Train Loss 0.0035549062 Test MSE 0.026509108477384576 Test RE 0.07782257943585046\n",
      "63 Train Loss 0.00342124 Test MSE 0.025108382823669763 Test RE 0.07573862755763966\n",
      "64 Train Loss 0.0030930063 Test MSE 0.020046025228850427 Test RE 0.06767405446718233\n",
      "65 Train Loss 0.0029904551 Test MSE 0.01991970538423986 Test RE 0.06746049378022062\n",
      "66 Train Loss 0.0028978446 Test MSE 0.020920296843447587 Test RE 0.06913404715987624\n",
      "67 Train Loss 0.0026770434 Test MSE 0.020089884172824035 Test RE 0.06774804646336688\n",
      "68 Train Loss 0.0025789754 Test MSE 0.018108087493038293 Test RE 0.0643197506919454\n",
      "69 Train Loss 0.0024930672 Test MSE 0.016042437579171363 Test RE 0.06054011468695434\n",
      "70 Train Loss 0.0024086966 Test MSE 0.01555905552688638 Test RE 0.05962105760665894\n",
      "71 Train Loss 0.002232161 Test MSE 0.014941039266746262 Test RE 0.058424965396351995\n",
      "72 Train Loss 0.0021751656 Test MSE 0.014714707407492783 Test RE 0.05798075626278846\n",
      "73 Train Loss 0.0020509427 Test MSE 0.014908630494284177 Test RE 0.058361565880301884\n",
      "74 Train Loss 0.0019253867 Test MSE 0.01467977728252611 Test RE 0.0579118973196202\n",
      "75 Train Loss 0.0018379964 Test MSE 0.013625619910287051 Test RE 0.05579383262893786\n",
      "76 Train Loss 0.0017935154 Test MSE 0.012739121464086274 Test RE 0.05394830442695159\n",
      "77 Train Loss 0.001745869 Test MSE 0.01201183944751895 Test RE 0.052385708216690786\n",
      "78 Train Loss 0.0017065364 Test MSE 0.011942622265561266 Test RE 0.05223455610410458\n",
      "79 Train Loss 0.001607744 Test MSE 0.012357666316774745 Test RE 0.053134462583249116\n",
      "80 Train Loss 0.0015735684 Test MSE 0.012357969239245658 Test RE 0.05313511381964146\n",
      "81 Train Loss 0.0015312162 Test MSE 0.011409261997771935 Test RE 0.05105483028787064\n",
      "82 Train Loss 0.001444588 Test MSE 0.010653739774276303 Test RE 0.04933545099120626\n",
      "83 Train Loss 0.001375684 Test MSE 0.010503644785915955 Test RE 0.048986687516262624\n",
      "84 Train Loss 0.001343849 Test MSE 0.0103187681612204 Test RE 0.04855366167094843\n",
      "85 Train Loss 0.0013223182 Test MSE 0.010168202389068277 Test RE 0.0481981258373084\n",
      "86 Train Loss 0.0012785805 Test MSE 0.010189652629736505 Test RE 0.04824893701761859\n",
      "87 Train Loss 0.0012350776 Test MSE 0.009611590293315094 Test RE 0.046860366976663535\n",
      "88 Train Loss 0.0012198013 Test MSE 0.009435753936103883 Test RE 0.046429751978931746\n",
      "89 Train Loss 0.0011790572 Test MSE 0.009375378663277449 Test RE 0.046280971738720714\n",
      "90 Train Loss 0.0011200667 Test MSE 0.00911446622471861 Test RE 0.04563243882337526\n",
      "91 Train Loss 0.0010670911 Test MSE 0.0089022750061012 Test RE 0.045098133034694274\n",
      "92 Train Loss 0.0010481146 Test MSE 0.008694180697233395 Test RE 0.04456792261572838\n",
      "93 Train Loss 0.001008395 Test MSE 0.00857145752528789 Test RE 0.044252254252372995\n",
      "94 Train Loss 0.0009665745 Test MSE 0.008047903218444886 Test RE 0.0428794723762764\n",
      "95 Train Loss 0.00093661266 Test MSE 0.008077093230633148 Test RE 0.04295716462696609\n",
      "96 Train Loss 0.00090804463 Test MSE 0.007852692464970647 Test RE 0.04235623557060317\n",
      "97 Train Loss 0.00089435827 Test MSE 0.007652335960753779 Test RE 0.04181239789633252\n",
      "98 Train Loss 0.0008853794 Test MSE 0.007572673627692763 Test RE 0.04159419084398389\n",
      "99 Train Loss 0.00086366 Test MSE 0.0075781295691263765 Test RE 0.04160917198668317\n",
      "Training time: 122.98\n",
      "8\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.101997 Test MSE 6.845652962495847 Test RE 1.250591578389534\n",
      "1 Train Loss 36.693367 Test MSE 8.299434304876897 Test RE 1.3769948185515355\n",
      "2 Train Loss 24.370474 Test MSE 7.490551878001081 Test RE 1.3081723587017464\n",
      "3 Train Loss 19.873043 Test MSE 7.527067874336285 Test RE 1.31135711339551\n",
      "4 Train Loss 15.806576 Test MSE 7.526248286292971 Test RE 1.3112857176085346\n",
      "5 Train Loss 14.212697 Test MSE 7.503458571600069 Test RE 1.309298905397888\n",
      "6 Train Loss 12.693529 Test MSE 7.491565028837229 Test RE 1.3082608255548578\n",
      "7 Train Loss 11.222416 Test MSE 7.452377226022521 Test RE 1.3048346330594325\n",
      "8 Train Loss 9.844104 Test MSE 7.308378301948913 Test RE 1.2921667751738524\n",
      "9 Train Loss 8.80702 Test MSE 6.983000844072857 Test RE 1.2630749078051602\n",
      "10 Train Loss 8.077568 Test MSE 6.66842867929767 Test RE 1.234297404057282\n",
      "11 Train Loss 7.2932944 Test MSE 6.335209668744799 Test RE 1.2030635161393228\n",
      "12 Train Loss 6.522485 Test MSE 6.0808842886657395 Test RE 1.1786678292655666\n",
      "13 Train Loss 5.710819 Test MSE 5.8457610718120545 Test RE 1.1556560327017527\n",
      "14 Train Loss 4.5792165 Test MSE 5.371713017038263 Test RE 1.1078079093527484\n",
      "15 Train Loss 3.6976585 Test MSE 4.8426069919705785 Test RE 1.0518351324987643\n",
      "16 Train Loss 2.8221564 Test MSE 4.567307910082274 Test RE 1.0214996115009005\n",
      "17 Train Loss 2.1601875 Test MSE 4.19984818634757 Test RE 0.9795460469147683\n",
      "18 Train Loss 1.9074565 Test MSE 3.9762708820730053 Test RE 0.9531166180042291\n",
      "19 Train Loss 1.6773658 Test MSE 3.697783100560363 Test RE 0.9191338844586046\n",
      "20 Train Loss 1.4596813 Test MSE 3.3338198588140737 Test RE 0.8727284322774341\n",
      "21 Train Loss 1.3086772 Test MSE 3.201542027971437 Test RE 0.8552393287099589\n",
      "22 Train Loss 1.2116306 Test MSE 3.060177836106505 Test RE 0.8361446069721514\n",
      "23 Train Loss 1.1307647 Test MSE 2.9088170935532776 Test RE 0.8152039345558847\n",
      "24 Train Loss 1.0700487 Test MSE 2.8104125897014676 Test RE 0.8012962336468228\n",
      "25 Train Loss 1.008167 Test MSE 2.7020613508465394 Test RE 0.7856980278679028\n",
      "26 Train Loss 0.9551191 Test MSE 2.693505860993705 Test RE 0.7844531706950434\n",
      "27 Train Loss 0.8874236 Test MSE 2.7055022962085364 Test RE 0.7861981430527998\n",
      "28 Train Loss 0.8528907 Test MSE 2.7173925218220263 Test RE 0.7879238531025583\n",
      "29 Train Loss 0.81769055 Test MSE 2.7422373537213374 Test RE 0.7915176096104648\n",
      "30 Train Loss 0.7827803 Test MSE 2.765462613249361 Test RE 0.7948624043111745\n",
      "31 Train Loss 0.7569206 Test MSE 2.7678926510160164 Test RE 0.7952115541282881\n",
      "32 Train Loss 0.72966635 Test MSE 2.8097990852358747 Test RE 0.801208768615716\n",
      "33 Train Loss 0.70832974 Test MSE 2.8339660025235114 Test RE 0.8046469663453707\n",
      "34 Train Loss 0.6947346 Test MSE 2.8302307145779384 Test RE 0.8041165120037042\n",
      "35 Train Loss 0.67766726 Test MSE 2.835774740456674 Test RE 0.804903702548684\n",
      "36 Train Loss 0.6631352 Test MSE 2.840688992686842 Test RE 0.8056008290821429\n",
      "37 Train Loss 0.6498749 Test MSE 2.844604745119716 Test RE 0.8061558787673047\n",
      "38 Train Loss 0.63986486 Test MSE 2.8379380297706573 Test RE 0.8052106570470922\n",
      "39 Train Loss 0.6240312 Test MSE 2.8422211097774235 Test RE 0.8058180489926761\n",
      "40 Train Loss 0.6111214 Test MSE 2.859526746194259 Test RE 0.8082675472439117\n",
      "41 Train Loss 0.599818 Test MSE 2.851463815776729 Test RE 0.807127217739247\n",
      "42 Train Loss 0.59067 Test MSE 2.8543486638716646 Test RE 0.8075354029626127\n",
      "43 Train Loss 0.5846768 Test MSE 2.85537057247775 Test RE 0.807679946188897\n",
      "44 Train Loss 0.5763589 Test MSE 2.8767844318657505 Test RE 0.810702888113577\n",
      "45 Train Loss 0.5692773 Test MSE 2.8730353897095395 Test RE 0.8101744595418267\n",
      "46 Train Loss 0.56283206 Test MSE 2.876302023663157 Test RE 0.8106349118488972\n",
      "47 Train Loss 0.5553954 Test MSE 2.883853558946138 Test RE 0.8116983477178332\n",
      "48 Train Loss 0.5505767 Test MSE 2.881864681167829 Test RE 0.81141840159526\n",
      "49 Train Loss 0.54317194 Test MSE 2.91342208944135 Test RE 0.8158489607060055\n",
      "50 Train Loss 0.53507316 Test MSE 2.936214224338507 Test RE 0.8190339975486527\n",
      "51 Train Loss 0.5281773 Test MSE 2.9407785277421707 Test RE 0.8196703387203209\n",
      "52 Train Loss 0.52014303 Test MSE 2.9580054248319683 Test RE 0.8220676219084292\n",
      "53 Train Loss 0.51242447 Test MSE 2.976450182436387 Test RE 0.8246266561458857\n",
      "54 Train Loss 0.50716764 Test MSE 2.986402980554645 Test RE 0.82600421877062\n",
      "55 Train Loss 0.50158906 Test MSE 2.9871602979845115 Test RE 0.8261089447140397\n",
      "56 Train Loss 0.49682152 Test MSE 2.9936707484424057 Test RE 0.8270086979103846\n",
      "57 Train Loss 0.49169564 Test MSE 2.990869331308031 Test RE 0.8266216582543939\n",
      "58 Train Loss 0.48501754 Test MSE 2.99483852437473 Test RE 0.8271699826292734\n",
      "59 Train Loss 0.48029178 Test MSE 3.0125689156145623 Test RE 0.8296149232168881\n",
      "60 Train Loss 0.47475326 Test MSE 3.0262640520575075 Test RE 0.8314984994262817\n",
      "61 Train Loss 0.46913403 Test MSE 3.024013859478769 Test RE 0.8311893096706316\n",
      "62 Train Loss 0.461452 Test MSE 3.0362988953354164 Test RE 0.8328759488918922\n",
      "63 Train Loss 0.45332125 Test MSE 3.0538746371019077 Test RE 0.835283038976155\n",
      "64 Train Loss 0.44723082 Test MSE 3.070186322360463 Test RE 0.8375108201419619\n",
      "65 Train Loss 0.43976328 Test MSE 3.0739078130378212 Test RE 0.8380182559226247\n",
      "66 Train Loss 0.4326586 Test MSE 3.0927940323340013 Test RE 0.8405887234642165\n",
      "67 Train Loss 0.42542392 Test MSE 3.113528978779665 Test RE 0.8434017860782983\n",
      "68 Train Loss 0.41931593 Test MSE 3.1114515287353877 Test RE 0.8431203662719714\n",
      "69 Train Loss 0.4142849 Test MSE 3.123035264204745 Test RE 0.8446883499099263\n",
      "70 Train Loss 0.40776014 Test MSE 3.1226990765465805 Test RE 0.8446428842944425\n",
      "71 Train Loss 0.40301713 Test MSE 3.128737930253999 Test RE 0.8454591991355198\n",
      "72 Train Loss 0.39863303 Test MSE 3.1354133294166893 Test RE 0.846360644160032\n",
      "73 Train Loss 0.3941252 Test MSE 3.1465434868926057 Test RE 0.8478615279550801\n",
      "74 Train Loss 0.3895784 Test MSE 3.1507908413994095 Test RE 0.8484335769445763\n",
      "75 Train Loss 0.38529775 Test MSE 3.15849921975576 Test RE 0.8494707850926159\n",
      "76 Train Loss 0.3820065 Test MSE 3.1645637725727456 Test RE 0.8502859174645249\n",
      "77 Train Loss 0.37913507 Test MSE 3.1836582524958263 Test RE 0.8528473052478761\n",
      "78 Train Loss 0.3761189 Test MSE 3.191077400889158 Test RE 0.8538404581214837\n",
      "79 Train Loss 0.3729288 Test MSE 3.2087734108421997 Test RE 0.8562046564519468\n",
      "80 Train Loss 0.3696884 Test MSE 3.224812572300238 Test RE 0.8583418728824902\n",
      "81 Train Loss 0.3657421 Test MSE 3.240349577313919 Test RE 0.8604071149893602\n",
      "82 Train Loss 0.36153156 Test MSE 3.2522545099423725 Test RE 0.8619862189636688\n",
      "83 Train Loss 0.35715163 Test MSE 3.269563381299219 Test RE 0.8642769698384455\n",
      "84 Train Loss 0.352666 Test MSE 3.2974419927946754 Test RE 0.8679538670965603\n",
      "85 Train Loss 0.34750277 Test MSE 3.296805325125364 Test RE 0.8678700711051179\n",
      "86 Train Loss 0.34410778 Test MSE 3.2901831921591467 Test RE 0.8669980087069463\n",
      "87 Train Loss 0.33929187 Test MSE 3.3103792121938036 Test RE 0.8696548700677225\n",
      "88 Train Loss 0.33578688 Test MSE 3.308659915632236 Test RE 0.8694290063946296\n",
      "89 Train Loss 0.33067888 Test MSE 3.32139509306473 Test RE 0.8711006346255853\n",
      "90 Train Loss 0.3269266 Test MSE 3.3198152953534117 Test RE 0.8708934436064864\n",
      "91 Train Loss 0.32299155 Test MSE 3.3323730625672345 Test RE 0.8725390403344899\n",
      "92 Train Loss 0.31950837 Test MSE 3.345542321452775 Test RE 0.874261440874288\n",
      "93 Train Loss 0.31561065 Test MSE 3.349013665775669 Test RE 0.8747148913705944\n",
      "94 Train Loss 0.3132061 Test MSE 3.352651480731224 Test RE 0.8751898352774566\n",
      "95 Train Loss 0.3102885 Test MSE 3.3685906480915215 Test RE 0.8772677811375235\n",
      "96 Train Loss 0.30704263 Test MSE 3.3786213891289845 Test RE 0.8785729419380482\n",
      "97 Train Loss 0.30358493 Test MSE 3.3879709256792947 Test RE 0.8797877236474535\n",
      "98 Train Loss 0.30095965 Test MSE 3.3966708654275153 Test RE 0.8809165988547717\n",
      "99 Train Loss 0.29851535 Test MSE 3.3983336143023144 Test RE 0.8811321869893051\n",
      "Training time: 126.41\n",
      "9\n",
      "KG_rowdy_tune45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.939636 Test MSE 8.417868870740513 Test RE 1.386785009227494\n",
      "1 Train Loss 49.631256 Test MSE 8.014525473563463 Test RE 1.3531531942957873\n",
      "2 Train Loss 42.213303 Test MSE 8.989559118216741 Test RE 1.4331025101442998\n",
      "3 Train Loss 39.01626 Test MSE 9.570942186404348 Test RE 1.4787181609401958\n",
      "4 Train Loss 34.74901 Test MSE 9.895112570685406 Test RE 1.5035519212252277\n",
      "5 Train Loss 32.16148 Test MSE 10.010083336483028 Test RE 1.5122615384645108\n",
      "6 Train Loss 29.28695 Test MSE 10.013433502672571 Test RE 1.512514578498145\n",
      "7 Train Loss 26.607769 Test MSE 9.96084780500593 Test RE 1.5085378540624186\n",
      "8 Train Loss 24.244297 Test MSE 9.750350921930233 Test RE 1.492513209517624\n",
      "9 Train Loss 22.06315 Test MSE 9.349980618620952 Test RE 1.461549119368647\n",
      "10 Train Loss 19.54094 Test MSE 9.12985999289411 Test RE 1.4442424939786735\n",
      "11 Train Loss 15.9205265 Test MSE 9.128158423622496 Test RE 1.4441079030230801\n",
      "12 Train Loss 13.205977 Test MSE 8.791822230704298 Test RE 1.4172534059016404\n",
      "13 Train Loss 11.256321 Test MSE 8.618505484958778 Test RE 1.4032144278394105\n",
      "14 Train Loss 9.619862 Test MSE 8.404196528653742 Test RE 1.3856583401993583\n",
      "15 Train Loss 8.32005 Test MSE 8.2013234528036 Test RE 1.3688316251691164\n",
      "16 Train Loss 7.1085978 Test MSE 7.95107976730624 Test RE 1.3477865419490658\n",
      "17 Train Loss 5.8157835 Test MSE 7.74938741322909 Test RE 1.330582314758788\n",
      "18 Train Loss 4.7177854 Test MSE 7.715447654335451 Test RE 1.3276653617663292\n",
      "19 Train Loss 3.8382142 Test MSE 7.581660681310571 Test RE 1.316104069728482\n",
      "20 Train Loss 3.123639 Test MSE 7.428308137531246 Test RE 1.3027258039826224\n",
      "21 Train Loss 2.5929644 Test MSE 7.364309421611672 Test RE 1.2971018361988642\n",
      "22 Train Loss 2.1872406 Test MSE 7.030972116597166 Test RE 1.2674059688002821\n",
      "23 Train Loss 1.956545 Test MSE 6.8721848189074315 Test RE 1.2530127081849969\n",
      "24 Train Loss 1.7919353 Test MSE 6.582914720564921 Test RE 1.2263577353595885\n",
      "25 Train Loss 1.6368392 Test MSE 6.350671698445735 Test RE 1.2045307499403475\n",
      "26 Train Loss 1.5157998 Test MSE 6.116284412050293 Test RE 1.1820936827093838\n",
      "27 Train Loss 1.4395331 Test MSE 6.005197777020049 Test RE 1.1713096407317158\n",
      "28 Train Loss 1.3679099 Test MSE 5.9162550342986355 Test RE 1.1626031726974\n",
      "29 Train Loss 1.3046517 Test MSE 5.830488234085847 Test RE 1.1541453918913944\n",
      "30 Train Loss 1.2683799 Test MSE 5.780912856945404 Test RE 1.149228193110797\n",
      "31 Train Loss 1.2294714 Test MSE 5.7408876392362265 Test RE 1.1452428359799953\n",
      "32 Train Loss 1.1957378 Test MSE 5.732550459487804 Test RE 1.1444109468154549\n",
      "33 Train Loss 1.1656032 Test MSE 5.704877741227928 Test RE 1.141645400021014\n",
      "34 Train Loss 1.1412683 Test MSE 5.696969943865633 Test RE 1.1408538816431142\n",
      "35 Train Loss 1.1193333 Test MSE 5.703010765212225 Test RE 1.141458577525616\n",
      "36 Train Loss 1.1043801 Test MSE 5.725989579665328 Test RE 1.1437558725784691\n",
      "37 Train Loss 1.0871718 Test MSE 5.757572034991399 Test RE 1.1469058037273137\n",
      "38 Train Loss 1.0686147 Test MSE 5.765259159679321 Test RE 1.1476711842608487\n",
      "39 Train Loss 1.0534993 Test MSE 5.775684824047428 Test RE 1.1487084169127781\n",
      "40 Train Loss 1.0384445 Test MSE 5.770696571641616 Test RE 1.1482122605743807\n",
      "41 Train Loss 1.0240207 Test MSE 5.781433420109531 Test RE 1.1492799351463652\n",
      "42 Train Loss 1.0108461 Test MSE 5.795090818693765 Test RE 1.1506365982988482\n",
      "43 Train Loss 0.997373 Test MSE 5.803301637372903 Test RE 1.1514514538928362\n",
      "44 Train Loss 0.9830085 Test MSE 5.807010692731337 Test RE 1.1518193578269083\n",
      "45 Train Loss 0.9652618 Test MSE 5.831949171724261 Test RE 1.1542899791682775\n",
      "46 Train Loss 0.94583726 Test MSE 5.827453427653882 Test RE 1.153844982764474\n",
      "47 Train Loss 0.9243672 Test MSE 5.905091772771969 Test RE 1.1615058086413965\n",
      "48 Train Loss 0.9056473 Test MSE 5.923020687396043 Test RE 1.163267741941854\n",
      "49 Train Loss 0.88767576 Test MSE 5.951958552481965 Test RE 1.1661059448639064\n",
      "50 Train Loss 0.8731867 Test MSE 5.966088380596992 Test RE 1.1674892802036763\n",
      "51 Train Loss 0.8604934 Test MSE 5.989053960063078 Test RE 1.169734161053221\n",
      "52 Train Loss 0.84809244 Test MSE 6.022364673724141 Test RE 1.172982641562737\n",
      "53 Train Loss 0.8365281 Test MSE 6.0355731047799965 Test RE 1.1742682474187274\n",
      "54 Train Loss 0.82341754 Test MSE 6.057783858232052 Test RE 1.1764269017355946\n",
      "55 Train Loss 0.81320137 Test MSE 6.085599334095652 Test RE 1.1791247032345442\n",
      "56 Train Loss 0.80044436 Test MSE 6.0904258172589305 Test RE 1.1795921919136108\n",
      "57 Train Loss 0.7930694 Test MSE 6.084575146330648 Test RE 1.1790254775179645\n",
      "58 Train Loss 0.786191 Test MSE 6.094617860384857 Test RE 1.179998079029393\n",
      "59 Train Loss 0.7789416 Test MSE 6.115600246303187 Test RE 1.1820275665372981\n",
      "60 Train Loss 0.77117455 Test MSE 6.1274061703879275 Test RE 1.1831679451419224\n",
      "61 Train Loss 0.76216424 Test MSE 6.126466641138912 Test RE 1.1830772327364478\n",
      "62 Train Loss 0.7544372 Test MSE 6.163154641966124 Test RE 1.186614340923576\n",
      "63 Train Loss 0.7475317 Test MSE 6.193935881531221 Test RE 1.1895738616796303\n",
      "64 Train Loss 0.74003553 Test MSE 6.222555870481649 Test RE 1.1923189944890078\n",
      "65 Train Loss 0.7336506 Test MSE 6.228721110302964 Test RE 1.1929095165183161\n",
      "66 Train Loss 0.72587734 Test MSE 6.219634576251122 Test RE 1.1920390835029737\n",
      "67 Train Loss 0.71857643 Test MSE 6.241395496484878 Test RE 1.1941225835421514\n",
      "68 Train Loss 0.7122885 Test MSE 6.2417774513488675 Test RE 1.1941591213606133\n",
      "69 Train Loss 0.70650566 Test MSE 6.272483181438465 Test RE 1.1970927843336139\n",
      "70 Train Loss 0.70088875 Test MSE 6.288460764316033 Test RE 1.1986164619601445\n",
      "71 Train Loss 0.69574505 Test MSE 6.293647652902442 Test RE 1.199110685332317\n",
      "72 Train Loss 0.6914302 Test MSE 6.306925252303161 Test RE 1.2003748904333966\n",
      "73 Train Loss 0.6859629 Test MSE 6.3153348257467865 Test RE 1.2011749061005113\n",
      "74 Train Loss 0.6812364 Test MSE 6.324162119010296 Test RE 1.2020140873073228\n",
      "75 Train Loss 0.6757761 Test MSE 6.339755189218079 Test RE 1.203495038500709\n",
      "76 Train Loss 0.6694245 Test MSE 6.360356860847765 Test RE 1.2054488915168526\n",
      "77 Train Loss 0.6636363 Test MSE 6.390902688313363 Test RE 1.2083400288744246\n",
      "78 Train Loss 0.65871143 Test MSE 6.397008637952512 Test RE 1.2089171227757478\n",
      "79 Train Loss 0.6552661 Test MSE 6.416011295194111 Test RE 1.2107113678632662\n",
      "80 Train Loss 0.65171427 Test MSE 6.422555127686149 Test RE 1.2113286262283243\n",
      "81 Train Loss 0.646896 Test MSE 6.43117922548526 Test RE 1.2121416291375713\n",
      "82 Train Loss 0.64209914 Test MSE 6.4494821277027405 Test RE 1.213865259161363\n",
      "83 Train Loss 0.63826144 Test MSE 6.466944037054581 Test RE 1.215507412502252\n",
      "84 Train Loss 0.63219297 Test MSE 6.495818953334397 Test RE 1.2182180115115495\n",
      "85 Train Loss 0.62753737 Test MSE 6.508919062352834 Test RE 1.2194457820944304\n",
      "86 Train Loss 0.6225779 Test MSE 6.531631935327727 Test RE 1.221571557255891\n",
      "87 Train Loss 0.61766887 Test MSE 6.554488014834684 Test RE 1.2237070077995296\n",
      "88 Train Loss 0.61361516 Test MSE 6.562135118991241 Test RE 1.2244206476048836\n",
      "89 Train Loss 0.60955554 Test MSE 6.586465491558948 Test RE 1.226688434496713\n",
      "90 Train Loss 0.60607934 Test MSE 6.5977704163437405 Test RE 1.227740719296045\n",
      "91 Train Loss 0.60278094 Test MSE 6.6123979529401415 Test RE 1.229100942395748\n",
      "92 Train Loss 0.59894085 Test MSE 6.61581146213337 Test RE 1.229418150016222\n",
      "93 Train Loss 0.59490645 Test MSE 6.652082731478854 Test RE 1.2327836936288534\n",
      "94 Train Loss 0.5914177 Test MSE 6.669572667272642 Test RE 1.2344032731384258\n",
      "95 Train Loss 0.5883096 Test MSE 6.690875711016935 Test RE 1.2363730831614497\n",
      "96 Train Loss 0.58395284 Test MSE 6.713664833591535 Test RE 1.238476836689717\n",
      "97 Train Loss 0.57945573 Test MSE 6.748117279794525 Test RE 1.241650509877319\n",
      "98 Train Loss 0.5755116 Test MSE 6.756344882381898 Test RE 1.2424072168616778\n",
      "99 Train Loss 0.57230735 Test MSE 6.7681846435474196 Test RE 1.2434953322761626\n",
      "Training time: 126.09\n",
      "0\n",
      "KG_rowdy_tune46\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.95294 Test MSE 4.463908803841204 Test RE 1.009870572374332\n",
      "1 Train Loss 51.761395 Test MSE 6.850143506773088 Test RE 1.2510016865437743\n",
      "2 Train Loss 32.29052 Test MSE 6.5515816836642315 Test RE 1.2234356752296107\n",
      "3 Train Loss 20.055988 Test MSE 5.86438369212064 Test RE 1.1574953339111338\n",
      "4 Train Loss 14.115017 Test MSE 5.64590620671705 Test RE 1.135729456381305\n",
      "5 Train Loss 10.573925 Test MSE 5.56188499440303 Test RE 1.1272469334726847\n",
      "6 Train Loss 8.275427 Test MSE 5.4504362140310825 Test RE 1.1158959234333985\n",
      "7 Train Loss 6.968502 Test MSE 5.16956100551902 Test RE 1.0867631218148905\n",
      "8 Train Loss 5.7664385 Test MSE 4.74939717741152 Test RE 1.0416631605610067\n",
      "9 Train Loss 4.749704 Test MSE 4.306519701979183 Test RE 0.9919077408025151\n",
      "10 Train Loss 3.7302153 Test MSE 3.8763088590989665 Test RE 0.941059855144639\n",
      "11 Train Loss 3.070064 Test MSE 3.4791750433952884 Test RE 0.8915510174930539\n",
      "12 Train Loss 2.5851264 Test MSE 3.134197348879681 Test RE 0.8461965098395775\n",
      "13 Train Loss 2.1649876 Test MSE 2.5508799109606644 Test RE 0.7634016021667211\n",
      "14 Train Loss 1.8372232 Test MSE 2.228560053549308 Test RE 0.7135431332610308\n",
      "15 Train Loss 1.5648067 Test MSE 2.0489694605816897 Test RE 0.6841885516533813\n",
      "16 Train Loss 1.4271071 Test MSE 1.8884471948084767 Test RE 0.6568413469773229\n",
      "17 Train Loss 1.2763497 Test MSE 1.5381696175312394 Test RE 0.5928027022303873\n",
      "18 Train Loss 1.0088856 Test MSE 1.060444231024359 Test RE 0.4922117503291108\n",
      "19 Train Loss 0.7898033 Test MSE 0.7932696647533574 Test RE 0.4257145402255792\n",
      "20 Train Loss 0.6372665 Test MSE 0.5519424256374615 Test RE 0.3551034970193141\n",
      "21 Train Loss 0.47902498 Test MSE 0.4186763240287405 Test RE 0.3092767418197651\n",
      "22 Train Loss 0.3675465 Test MSE 0.31365304075011285 Test RE 0.2676904090806216\n",
      "23 Train Loss 0.29856497 Test MSE 0.2090424910600446 Test RE 0.21853718586076326\n",
      "24 Train Loss 0.21673098 Test MSE 0.12436895297263452 Test RE 0.16856369759831277\n",
      "25 Train Loss 0.16115591 Test MSE 0.0703211952781024 Test RE 0.12675093809935228\n",
      "26 Train Loss 0.11516376 Test MSE 0.045559917413881976 Test RE 0.10202333698660418\n",
      "27 Train Loss 0.083048 Test MSE 0.033828677614862405 Test RE 0.08791248795372385\n",
      "28 Train Loss 0.06770244 Test MSE 0.0345693503698477 Test RE 0.0888696908590953\n",
      "29 Train Loss 0.05575031 Test MSE 0.03326411028909195 Test RE 0.08717581499722529\n",
      "30 Train Loss 0.044994354 Test MSE 0.027535197050478254 Test RE 0.0793144203540643\n",
      "31 Train Loss 0.035871394 Test MSE 0.027303732738540858 Test RE 0.0789803533490544\n",
      "32 Train Loss 0.030789949 Test MSE 0.02222999564532182 Test RE 0.07126523951438614\n",
      "33 Train Loss 0.026524108 Test MSE 0.02097460306489279 Test RE 0.06922372025527201\n",
      "34 Train Loss 0.023267105 Test MSE 0.01999638118767942 Test RE 0.06759020502295032\n",
      "35 Train Loss 0.020568196 Test MSE 0.01953033328392081 Test RE 0.06679791203834522\n",
      "36 Train Loss 0.018486198 Test MSE 0.01852609880210986 Test RE 0.06505790113972863\n",
      "37 Train Loss 0.016460024 Test MSE 0.018068382847508203 Test RE 0.06424919673832438\n",
      "38 Train Loss 0.01478859 Test MSE 0.017613803197073882 Test RE 0.06343583050766126\n",
      "39 Train Loss 0.012210414 Test MSE 0.013537624854002858 Test RE 0.05561338088562586\n",
      "40 Train Loss 0.010684184 Test MSE 0.013252318358343411 Test RE 0.055024232105537176\n",
      "41 Train Loss 0.009751248 Test MSE 0.011847470513881037 Test RE 0.052026052939590325\n",
      "42 Train Loss 0.009182583 Test MSE 0.010866438476645188 Test RE 0.049825500856344636\n",
      "43 Train Loss 0.008563738 Test MSE 0.011729825511616457 Test RE 0.05176709996844636\n",
      "44 Train Loss 0.007915265 Test MSE 0.012011642834441484 Test RE 0.0523852794831275\n",
      "45 Train Loss 0.0073193447 Test MSE 0.011534988987095946 Test RE 0.051335364780095157\n",
      "46 Train Loss 0.006659427 Test MSE 0.010446557911984861 Test RE 0.048853385839388634\n",
      "47 Train Loss 0.0063970536 Test MSE 0.009412105100356546 Test RE 0.046371532019255104\n",
      "48 Train Loss 0.0051750448 Test MSE 0.009083073345607704 Test RE 0.045553785326564546\n",
      "49 Train Loss 0.0050755627 Test MSE 0.009307479981897326 Test RE 0.04611307840381518\n",
      "50 Train Loss 0.0049179276 Test MSE 0.008600185039596996 Test RE 0.04432634864529726\n",
      "51 Train Loss 0.004683297 Test MSE 0.008524996171099017 Test RE 0.044132157210593756\n",
      "52 Train Loss 0.0044128625 Test MSE 0.008725002342968866 Test RE 0.04464685135491152\n",
      "53 Train Loss 0.0040286602 Test MSE 0.007821745909311425 Test RE 0.04227269266056271\n",
      "54 Train Loss 0.0035204524 Test MSE 0.006827039583129534 Test RE 0.03949337697699855\n",
      "55 Train Loss 0.0034643367 Test MSE 0.0066025334964587255 Test RE 0.03883858213174592\n",
      "56 Train Loss 0.003250361 Test MSE 0.00593823542442696 Test RE 0.03683297226496486\n",
      "57 Train Loss 0.0031083794 Test MSE 0.005124017712833736 Test RE 0.034214750032471083\n",
      "58 Train Loss 0.0029870751 Test MSE 0.004936855019230481 Test RE 0.03358406385727693\n",
      "59 Train Loss 0.0027994385 Test MSE 0.005261663119618235 Test RE 0.03467125639650993\n",
      "60 Train Loss 0.0027112735 Test MSE 0.005024371893931465 Test RE 0.033880432762955534\n",
      "61 Train Loss 0.0026349402 Test MSE 0.004562541338496874 Test RE 0.03228579363183492\n",
      "62 Train Loss 0.002585823 Test MSE 0.00426312599120929 Test RE 0.031208446025427765\n",
      "63 Train Loss 0.0024771967 Test MSE 0.004005609468424773 Test RE 0.030251182997603907\n",
      "64 Train Loss 0.002290823 Test MSE 0.00386749374917388 Test RE 0.02972506893799884\n",
      "65 Train Loss 0.0021023937 Test MSE 0.003926781194611546 Test RE 0.02995204030887667\n",
      "66 Train Loss 0.0020354271 Test MSE 0.004271633736541349 Test RE 0.031239571210908673\n",
      "67 Train Loss 0.001981874 Test MSE 0.0043595107822495885 Test RE 0.031559269229058946\n",
      "68 Train Loss 0.0018262977 Test MSE 0.004121152447175361 Test RE 0.03068438337681224\n",
      "69 Train Loss 0.001762238 Test MSE 0.003859228933793012 Test RE 0.029693290787418083\n",
      "70 Train Loss 0.00170699 Test MSE 0.003737494994340822 Test RE 0.029221221758715374\n",
      "71 Train Loss 0.0016646589 Test MSE 0.003481221535083035 Test RE 0.028201609257050893\n",
      "72 Train Loss 0.0016366348 Test MSE 0.003431331973157208 Test RE 0.027998800675471613\n",
      "73 Train Loss 0.0015798106 Test MSE 0.0033336227104390505 Test RE 0.0275972802169125\n",
      "74 Train Loss 0.0015425119 Test MSE 0.0031287925647159836 Test RE 0.026736000810947996\n",
      "75 Train Loss 0.0014565754 Test MSE 0.0030866660911578847 Test RE 0.02655540233925495\n",
      "76 Train Loss 0.0013851277 Test MSE 0.0031682130713196503 Test RE 0.02690390067720487\n",
      "77 Train Loss 0.0013545984 Test MSE 0.00319878400611756 Test RE 0.027033390521161837\n",
      "78 Train Loss 0.0012786047 Test MSE 0.003036404958584282 Test RE 0.026338310078368322\n",
      "79 Train Loss 0.001217603 Test MSE 0.002878939569841433 Test RE 0.025646277358733188\n",
      "80 Train Loss 0.001185364 Test MSE 0.0027545291917184557 Test RE 0.025086019175899324\n",
      "81 Train Loss 0.001158091 Test MSE 0.0025876553642226042 Test RE 0.024314272378867446\n",
      "82 Train Loss 0.001132923 Test MSE 0.0025088227057262174 Test RE 0.023941041862988646\n",
      "83 Train Loss 0.001124316 Test MSE 0.002475906514513513 Test RE 0.023783467986098643\n",
      "84 Train Loss 0.0011047506 Test MSE 0.0024743249005654212 Test RE 0.023775870309503056\n",
      "85 Train Loss 0.001029939 Test MSE 0.0022949174559245733 Test RE 0.022897685970501458\n",
      "86 Train Loss 0.0010034635 Test MSE 0.0021864961719507427 Test RE 0.0223502518333819\n",
      "87 Train Loss 0.0009805663 Test MSE 0.002156182572708003 Test RE 0.022194779054565808\n",
      "88 Train Loss 0.0009650032 Test MSE 0.002161617770448339 Test RE 0.022222735195370213\n",
      "89 Train Loss 0.000947552 Test MSE 0.002051061923802056 Test RE 0.021646986508708742\n",
      "90 Train Loss 0.00092637376 Test MSE 0.001991903919390574 Test RE 0.021332524513387845\n",
      "91 Train Loss 0.00089155487 Test MSE 0.001884360212720058 Test RE 0.020748658520079063\n",
      "92 Train Loss 0.00086248055 Test MSE 0.0018050445603777134 Test RE 0.020307292489869913\n",
      "93 Train Loss 0.00083958835 Test MSE 0.001752966862512866 Test RE 0.02001220363836045\n",
      "94 Train Loss 0.0008091115 Test MSE 0.0016844810014833027 Test RE 0.019617385156012628\n",
      "95 Train Loss 0.00077727536 Test MSE 0.0015752368417986072 Test RE 0.018970596664616122\n",
      "96 Train Loss 0.00075238623 Test MSE 0.0015887211137243032 Test RE 0.01905161926892648\n",
      "97 Train Loss 0.00074205163 Test MSE 0.0015908870949575176 Test RE 0.019064601847876377\n",
      "98 Train Loss 0.00073516683 Test MSE 0.001591551993245052 Test RE 0.01906858537913329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0007259259 Test MSE 0.0016387926451139837 Test RE 0.01934951408960484\n",
      "Training time: 124.62\n",
      "1\n",
      "KG_rowdy_tune46\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.73\n",
      "0\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "1 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "2 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "3 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "4 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "5 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "6 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "7 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "8 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "9 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "10 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "11 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "12 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "13 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "14 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "15 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "16 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "17 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "18 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "19 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "20 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "21 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "22 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "23 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "24 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "25 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "26 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "27 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "28 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "29 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "30 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "31 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "32 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "33 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "34 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "35 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "36 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "37 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "38 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "39 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "40 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "41 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "42 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "43 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "44 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "45 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "46 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "47 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "48 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "49 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "50 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "51 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "52 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "53 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "54 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "55 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "56 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "57 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "58 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "59 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "60 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "61 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "62 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "63 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "64 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "65 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "66 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "67 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "68 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "69 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "70 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "71 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "72 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "73 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "74 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "75 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "76 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "77 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "78 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "79 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "80 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "81 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "82 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "83 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "84 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "85 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "87 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "88 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "89 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "90 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "91 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "92 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "93 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "94 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "95 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "96 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "97 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "98 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "99 Train Loss 75.11137 Test MSE 4.443522232489302 Test RE 1.0075619053273044\n",
      "Training time: 61.90\n",
      "1\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 70.36888 Test MSE 5.1651672430337285 Test RE 1.086301187613879\n",
      "1 Train Loss 57.648438 Test MSE 8.450603106453272 Test RE 1.3894787611672361\n",
      "2 Train Loss 44.91633 Test MSE 9.132623720723801 Test RE 1.444461072968547\n",
      "3 Train Loss 41.63119 Test MSE 9.24765225988001 Test RE 1.4535293499969988\n",
      "4 Train Loss 36.794334 Test MSE 9.546224844778168 Test RE 1.4768075021090563\n",
      "5 Train Loss 34.751274 Test MSE 9.641905549893549 Test RE 1.4841899849959508\n",
      "6 Train Loss 31.767288 Test MSE 8.978735900510202 Test RE 1.432239539462126\n",
      "7 Train Loss 27.46212 Test MSE 9.076212082417229 Test RE 1.439992990233376\n",
      "8 Train Loss 24.005962 Test MSE 9.335290561625648 Test RE 1.4604005244934564\n",
      "9 Train Loss 22.046299 Test MSE 9.207991771922973 Test RE 1.450409118878501\n",
      "10 Train Loss 20.709776 Test MSE 9.242555265463817 Test RE 1.4531287265792456\n",
      "11 Train Loss 19.58749 Test MSE 8.989100727947134 Test RE 1.4330659717216758\n",
      "12 Train Loss 17.50977 Test MSE 9.05906325871786 Test RE 1.4386319675302766\n",
      "13 Train Loss 15.745518 Test MSE 8.271102245486457 Test RE 1.3746424623799802\n",
      "14 Train Loss 14.641716 Test MSE 8.07201485216174 Test RE 1.357997706387011\n",
      "15 Train Loss 12.897375 Test MSE 7.302942922746936 Test RE 1.2916861813626963\n",
      "16 Train Loss 10.79069 Test MSE 6.740609612047475 Test RE 1.2409596139333205\n",
      "17 Train Loss 9.618252 Test MSE 6.223211901260006 Test RE 1.1923818446553227\n",
      "18 Train Loss 9.230801 Test MSE 6.273881496284749 Test RE 1.197226209907188\n",
      "19 Train Loss 8.764173 Test MSE 6.322317791692197 Test RE 1.2018388017097974\n",
      "20 Train Loss 8.485445 Test MSE 6.408529817921297 Test RE 1.2100052787347526\n",
      "21 Train Loss 8.2534275 Test MSE 6.400806834886207 Test RE 1.2092759642432598\n",
      "22 Train Loss 8.001911 Test MSE 6.417340195372212 Test RE 1.210836744142733\n",
      "23 Train Loss 7.8012033 Test MSE 6.397225186970631 Test RE 1.208937584495848\n",
      "24 Train Loss 7.624531 Test MSE 6.459782830488449 Test RE 1.2148342266286065\n",
      "25 Train Loss 7.412743 Test MSE 6.412559404303524 Test RE 1.2103856354399913\n",
      "26 Train Loss 7.1874304 Test MSE 6.430994818878288 Test RE 1.2121242506351595\n",
      "27 Train Loss 6.9680734 Test MSE 6.354014831695498 Test RE 1.204847753965122\n",
      "28 Train Loss 6.632637 Test MSE 6.292529482004282 Test RE 1.1990041596491552\n",
      "29 Train Loss 6.353921 Test MSE 6.087587111584315 Test RE 1.1793172599613693\n",
      "30 Train Loss 5.888418 Test MSE 5.9933037204670025 Test RE 1.1701491020781554\n",
      "31 Train Loss 5.2344937 Test MSE 5.586922392075567 Test RE 1.1297812935423144\n",
      "32 Train Loss 4.269601 Test MSE 5.215520919780509 Test RE 1.0915833585934371\n",
      "33 Train Loss 3.4832137 Test MSE 5.202334245656938 Test RE 1.0902025316089676\n",
      "34 Train Loss 2.937624 Test MSE 5.1318833691316 Test RE 1.0827955172764698\n",
      "35 Train Loss 2.5530522 Test MSE 5.252138524686228 Test RE 1.0954086001815924\n",
      "36 Train Loss 2.3527954 Test MSE 5.318415945179017 Test RE 1.1022984841776708\n",
      "37 Train Loss 2.176362 Test MSE 5.251955503808319 Test RE 1.0953895142045842\n",
      "38 Train Loss 2.0720005 Test MSE 5.25027264187758 Test RE 1.0952140046251069\n",
      "39 Train Loss 1.9190887 Test MSE 5.3074563200196945 Test RE 1.101162148806296\n",
      "40 Train Loss 1.8358804 Test MSE 5.344062470995242 Test RE 1.1049530459511125\n",
      "41 Train Loss 1.7784522 Test MSE 5.338393925093129 Test RE 1.1043668684014836\n",
      "42 Train Loss 1.6955426 Test MSE 5.356377000158704 Test RE 1.1062254063352681\n",
      "43 Train Loss 1.6257852 Test MSE 5.380109215481759 Test RE 1.1086733449455295\n",
      "44 Train Loss 1.5821108 Test MSE 5.464964862309835 Test RE 1.1173821961984847\n",
      "45 Train Loss 1.5214074 Test MSE 5.487531883876449 Test RE 1.1196868779890778\n",
      "46 Train Loss 1.4776423 Test MSE 5.52171207037786 Test RE 1.1231685613029054\n",
      "47 Train Loss 1.4458086 Test MSE 5.585119454910547 Test RE 1.1295989848490542\n",
      "48 Train Loss 1.4171361 Test MSE 5.59151123607292 Test RE 1.1302451737991743\n",
      "49 Train Loss 1.3902136 Test MSE 5.675499077256778 Test RE 1.1387020145288727\n",
      "50 Train Loss 1.3518568 Test MSE 5.714269326935611 Test RE 1.1425847235309499\n",
      "51 Train Loss 1.3286691 Test MSE 5.766774084525786 Test RE 1.1478219599107438\n",
      "52 Train Loss 1.2922312 Test MSE 5.74595720213223 Test RE 1.1457483849281407\n",
      "53 Train Loss 1.265102 Test MSE 5.729204712354582 Test RE 1.1440769359322425\n",
      "54 Train Loss 1.2494984 Test MSE 5.748470826589559 Test RE 1.145998966873062\n",
      "55 Train Loss 1.2260689 Test MSE 5.721876906050928 Test RE 1.1433450493071569\n",
      "56 Train Loss 1.2096932 Test MSE 5.7662465093943105 Test RE 1.1477694542842718\n",
      "57 Train Loss 1.1941252 Test MSE 5.770508585835298 Test RE 1.148193558381081\n",
      "58 Train Loss 1.1714371 Test MSE 5.774143072235301 Test RE 1.1485550895116452\n",
      "59 Train Loss 1.1514795 Test MSE 5.8253296156700145 Test RE 1.1536347045401691\n",
      "60 Train Loss 1.1362312 Test MSE 5.833481332929103 Test RE 1.1544415959031065\n",
      "61 Train Loss 1.1203238 Test MSE 5.836310946069867 Test RE 1.1547215511210234\n",
      "62 Train Loss 1.1020036 Test MSE 5.835070626998121 Test RE 1.1545988452476637\n",
      "63 Train Loss 1.0813134 Test MSE 5.840631716424071 Test RE 1.1551489069977967\n",
      "64 Train Loss 1.062907 Test MSE 5.868062785688121 Test RE 1.1578583614822668\n",
      "65 Train Loss 1.0490892 Test MSE 5.8619240653321425 Test RE 1.1572525713921518\n",
      "66 Train Loss 1.0365164 Test MSE 5.876871014281607 Test RE 1.158727034603024\n",
      "67 Train Loss 1.0198405 Test MSE 5.934380170315657 Test RE 1.164382695875488\n",
      "68 Train Loss 1.0120589 Test MSE 5.947923836034822 Test RE 1.1657106376381556\n",
      "69 Train Loss 1.0026586 Test MSE 5.942120996469136 Test RE 1.165141860812848\n",
      "70 Train Loss 0.99212706 Test MSE 5.938023977535037 Test RE 1.164740116100207\n",
      "71 Train Loss 0.9847121 Test MSE 5.924374408317677 Test RE 1.163400668196501\n",
      "72 Train Loss 0.9768911 Test MSE 5.948660569764118 Test RE 1.1657828302028634\n",
      "73 Train Loss 0.9671465 Test MSE 5.932449718544094 Test RE 1.1641932938314545\n",
      "74 Train Loss 0.9580652 Test MSE 5.952065512738581 Test RE 1.1661164226276253\n",
      "75 Train Loss 0.95046675 Test MSE 5.971092197070237 Test RE 1.1679787699093571\n",
      "76 Train Loss 0.94274354 Test MSE 5.946488143357563 Test RE 1.165569941213915\n",
      "77 Train Loss 0.93666846 Test MSE 5.955437117353058 Test RE 1.166446654786177\n",
      "78 Train Loss 0.93087214 Test MSE 5.96986338127347 Test RE 1.1678585821310157\n",
      "79 Train Loss 0.9225505 Test MSE 5.996927818758686 Test RE 1.1705028380699791\n",
      "80 Train Loss 0.9160169 Test MSE 6.008054521470539 Test RE 1.1715882106128443\n",
      "81 Train Loss 0.9087266 Test MSE 6.014870265770802 Test RE 1.1722525672893138\n",
      "82 Train Loss 0.9023433 Test MSE 6.028805535479903 Test RE 1.1736097208347192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 Train Loss 0.8969825 Test MSE 6.032376666418452 Test RE 1.1739572601189872\n",
      "84 Train Loss 0.8934526 Test MSE 6.030858140078953 Test RE 1.1738094910619314\n",
      "85 Train Loss 0.88775206 Test MSE 6.028730888626632 Test RE 1.1736024551712898\n",
      "86 Train Loss 0.88326305 Test MSE 6.031562071581738 Test RE 1.1738779935328907\n",
      "87 Train Loss 0.8789767 Test MSE 6.052996889755718 Test RE 1.1759619931488547\n",
      "88 Train Loss 0.87515336 Test MSE 6.0715357657268045 Test RE 1.17776146096879\n",
      "89 Train Loss 0.8716661 Test MSE 6.062717186802311 Test RE 1.1769058326003883\n",
      "90 Train Loss 0.8689129 Test MSE 6.065507857573581 Test RE 1.1771766665141044\n",
      "91 Train Loss 0.86396426 Test MSE 6.069175850982843 Test RE 1.1775325496294071\n",
      "92 Train Loss 0.8577073 Test MSE 6.1080202633862 Test RE 1.1812948071667027\n",
      "93 Train Loss 0.8528209 Test MSE 6.104887855250128 Test RE 1.18099186350919\n",
      "94 Train Loss 0.8480377 Test MSE 6.097875696917508 Test RE 1.18031341686906\n",
      "95 Train Loss 0.84397036 Test MSE 6.099158163854091 Test RE 1.180437528397967\n",
      "96 Train Loss 0.8405994 Test MSE 6.106061827937153 Test RE 1.181105410684568\n",
      "97 Train Loss 0.83511186 Test MSE 6.1273352964500605 Test RE 1.1831611024411457\n",
      "98 Train Loss 0.82995176 Test MSE 6.124866366645234 Test RE 1.1829227087604783\n",
      "99 Train Loss 0.82531214 Test MSE 6.111213324029311 Test RE 1.1816035367519286\n",
      "Training time: 125.18\n",
      "2\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 58.592438 Test MSE 6.419909295671285 Test RE 1.2110790914136218\n",
      "1 Train Loss 39.16426 Test MSE 7.456426226769634 Test RE 1.305189054126412\n",
      "2 Train Loss 27.29995 Test MSE 6.314787474456953 Test RE 1.2011228519419768\n",
      "3 Train Loss 21.743412 Test MSE 6.386307787154442 Test RE 1.207905567453011\n",
      "4 Train Loss 18.7639 Test MSE 6.109308458049823 Test RE 1.1814193694123374\n",
      "5 Train Loss 16.21788 Test MSE 6.278246207266903 Test RE 1.1976425899311294\n",
      "6 Train Loss 14.048945 Test MSE 6.118239205754079 Test RE 1.182282569011136\n",
      "7 Train Loss 12.328188 Test MSE 6.0725954598507235 Test RE 1.177864236649829\n",
      "8 Train Loss 9.191719 Test MSE 5.133562362389956 Test RE 1.0829726313658214\n",
      "9 Train Loss 7.2981687 Test MSE 4.614502638696617 Test RE 1.0267637078065106\n",
      "10 Train Loss 6.3952346 Test MSE 4.381059657397045 Test RE 1.0004551952561862\n",
      "11 Train Loss 5.744788 Test MSE 4.123367158489838 Test RE 0.9705860925708516\n",
      "12 Train Loss 5.2765884 Test MSE 3.9083059576958767 Test RE 0.9449358751944966\n",
      "13 Train Loss 4.499273 Test MSE 3.745360500002744 Test RE 0.9250279882829496\n",
      "14 Train Loss 3.7350793 Test MSE 3.502412951345207 Test RE 0.8945234608185635\n",
      "15 Train Loss 3.1141896 Test MSE 3.244315566482519 Test RE 0.8609334967460601\n",
      "16 Train Loss 2.8559775 Test MSE 3.1889421300096776 Test RE 0.8535547418055226\n",
      "17 Train Loss 2.58714 Test MSE 3.133573145754662 Test RE 0.8461122418837828\n",
      "18 Train Loss 2.3636346 Test MSE 3.0387083027677644 Test RE 0.8332063411926409\n",
      "19 Train Loss 2.224905 Test MSE 2.9467721396026727 Test RE 0.8205052001648839\n",
      "20 Train Loss 2.09973 Test MSE 2.7641995841304956 Test RE 0.7946808706662144\n",
      "21 Train Loss 1.9668039 Test MSE 2.512073140932178 Test RE 0.757572498235765\n",
      "22 Train Loss 1.8542238 Test MSE 2.271123388560355 Test RE 0.7203248959474876\n",
      "23 Train Loss 1.7648361 Test MSE 2.1277432659899596 Test RE 0.697216526110268\n",
      "24 Train Loss 1.6499379 Test MSE 2.052577357441292 Test RE 0.684790658244728\n",
      "25 Train Loss 1.5625601 Test MSE 1.9886237750177418 Test RE 0.6740379885935708\n",
      "26 Train Loss 1.5189327 Test MSE 1.9298545521461452 Test RE 0.6640034710153597\n",
      "27 Train Loss 1.4663135 Test MSE 1.8606191889299564 Test RE 0.6519838048616129\n",
      "28 Train Loss 1.4338125 Test MSE 1.7641707586561446 Test RE 0.6348605922824481\n",
      "29 Train Loss 1.3829044 Test MSE 1.6171686528567242 Test RE 0.607835019204226\n",
      "30 Train Loss 1.3217086 Test MSE 1.4655560259777392 Test RE 0.5786410938021703\n",
      "31 Train Loss 1.2401202 Test MSE 1.1824395103335243 Test RE 0.5197536247085287\n",
      "32 Train Loss 1.1040572 Test MSE 1.0324508993948345 Test RE 0.4856716617494871\n",
      "33 Train Loss 1.0068675 Test MSE 1.0198125386016859 Test RE 0.4826899248732347\n",
      "34 Train Loss 0.86949885 Test MSE 0.932619579920196 Test RE 0.46159418042906813\n",
      "35 Train Loss 0.7747002 Test MSE 0.9031932104466273 Test RE 0.4542536152421933\n",
      "36 Train Loss 0.65926397 Test MSE 0.7190513304482544 Test RE 0.4053106424387462\n",
      "37 Train Loss 0.5414564 Test MSE 0.5946909740159048 Test RE 0.3685986444882641\n",
      "38 Train Loss 0.46957377 Test MSE 0.5265699978576001 Test RE 0.3468455410613491\n",
      "39 Train Loss 0.40578082 Test MSE 0.48602767754638304 Test RE 0.333225755304796\n",
      "40 Train Loss 0.35911825 Test MSE 0.46479226105369875 Test RE 0.32586484054078335\n",
      "41 Train Loss 0.32129028 Test MSE 0.4345633952242786 Test RE 0.3150900078181013\n",
      "42 Train Loss 0.27833912 Test MSE 0.4134441502533544 Test RE 0.30733815942442444\n",
      "43 Train Loss 0.25625926 Test MSE 0.4066465108371037 Test RE 0.3048011388880695\n",
      "44 Train Loss 0.23191164 Test MSE 0.3907687289376412 Test RE 0.2987913093330368\n",
      "45 Train Loss 0.21532747 Test MSE 0.3501587132282745 Test RE 0.28283980496878675\n",
      "46 Train Loss 0.1997209 Test MSE 0.30801766299582356 Test RE 0.26527472378431316\n",
      "47 Train Loss 0.18876097 Test MSE 0.26274931243151933 Test RE 0.24500720410578136\n",
      "48 Train Loss 0.17846388 Test MSE 0.1992892464513069 Test RE 0.21337817325728223\n",
      "49 Train Loss 0.17087552 Test MSE 0.16596399996814853 Test RE 0.1947219934573186\n",
      "50 Train Loss 0.15515804 Test MSE 0.15098214457231063 Test RE 0.18572520877323226\n",
      "51 Train Loss 0.13782094 Test MSE 0.07530955623539809 Test RE 0.13116957292759832\n",
      "52 Train Loss 0.1224052 Test MSE 0.06039404685808844 Test RE 0.11746409204036616\n",
      "53 Train Loss 0.11295046 Test MSE 0.04867894730944108 Test RE 0.10545778595865794\n",
      "54 Train Loss 0.09657454 Test MSE 0.04795506965575298 Test RE 0.10467074694258671\n",
      "55 Train Loss 0.08088611 Test MSE 0.03266234461305678 Test RE 0.08638368741349096\n",
      "56 Train Loss 0.074888505 Test MSE 0.03292945834689939 Test RE 0.0867361925068616\n",
      "57 Train Loss 0.065412484 Test MSE 0.02287332598241849 Test RE 0.07228908371838703\n",
      "58 Train Loss 0.056472562 Test MSE 0.0218440201679597 Test RE 0.07064384755775238\n",
      "59 Train Loss 0.051777553 Test MSE 0.019507806655735857 Test RE 0.0667593779833312\n",
      "60 Train Loss 0.045398697 Test MSE 0.016488777800216948 Test RE 0.06137652458239514\n",
      "61 Train Loss 0.041974794 Test MSE 0.017923112334400852 Test RE 0.06399039244716585\n",
      "62 Train Loss 0.03683819 Test MSE 0.013723346173313701 Test RE 0.055993558622966635\n",
      "63 Train Loss 0.034638993 Test MSE 0.01173679932427614 Test RE 0.051782486404232206\n",
      "64 Train Loss 0.029912487 Test MSE 0.01177028821011262 Test RE 0.051856309874978614\n",
      "65 Train Loss 0.027512792 Test MSE 0.010979966275193955 Test RE 0.05008510209305601\n",
      "66 Train Loss 0.025487602 Test MSE 0.010055206951180808 Test RE 0.0479295737820108\n",
      "67 Train Loss 0.022738082 Test MSE 0.01029173945302431 Test RE 0.04849002988666131\n",
      "68 Train Loss 0.018901734 Test MSE 0.009764746994165983 Test RE 0.047232241660681906\n",
      "69 Train Loss 0.017608868 Test MSE 0.008610698535917312 Test RE 0.04435343425813424\n",
      "70 Train Loss 0.016215317 Test MSE 0.007084773371220718 Test RE 0.04023194617125332\n",
      "71 Train Loss 0.015189361 Test MSE 0.005798376193370145 Test RE 0.03639663677214263\n",
      "72 Train Loss 0.014458987 Test MSE 0.005843151748476671 Test RE 0.03653689548588045\n",
      "73 Train Loss 0.012540884 Test MSE 0.005319525027858324 Test RE 0.034861373075649765\n",
      "74 Train Loss 0.012117782 Test MSE 0.005287260642739037 Test RE 0.03475549036252623\n",
      "75 Train Loss 0.011492504 Test MSE 0.003987020601632666 Test RE 0.030180907906860864\n",
      "76 Train Loss 0.010764901 Test MSE 0.00403377833810343 Test RE 0.030357365183131806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 0.010154082 Test MSE 0.0031320564840784733 Test RE 0.02674994251570286\n",
      "78 Train Loss 0.0085755065 Test MSE 0.003196502257801902 Test RE 0.0270237471071247\n",
      "79 Train Loss 0.00838327 Test MSE 0.0031119152468334823 Test RE 0.02666379370063932\n",
      "80 Train Loss 0.008290504 Test MSE 0.0030159888141333487 Test RE 0.026249614121747908\n",
      "81 Train Loss 0.007869259 Test MSE 0.002840304266775084 Test RE 0.02547360987634506\n",
      "82 Train Loss 0.007468933 Test MSE 0.002897119653077222 Test RE 0.025727126171860112\n",
      "83 Train Loss 0.0072610783 Test MSE 0.002791899530084771 Test RE 0.025255615267282174\n",
      "84 Train Loss 0.0066087954 Test MSE 0.0024503317654557388 Test RE 0.02366031407763547\n",
      "85 Train Loss 0.0063086157 Test MSE 0.0023293733249927233 Test RE 0.02306893839048127\n",
      "86 Train Loss 0.00620842 Test MSE 0.0024757450426718705 Test RE 0.02378269242713258\n",
      "87 Train Loss 0.005639142 Test MSE 0.002127386912365036 Test RE 0.022046076082085118\n",
      "88 Train Loss 0.005155366 Test MSE 0.002075014074027618 Test RE 0.02177301559488956\n",
      "89 Train Loss 0.004911826 Test MSE 0.002021345710977147 Test RE 0.02148960134446116\n",
      "90 Train Loss 0.004803662 Test MSE 0.0020321247883550767 Test RE 0.021546823146104073\n",
      "91 Train Loss 0.004429798 Test MSE 0.0017398745858066506 Test RE 0.01993733161586626\n",
      "92 Train Loss 0.0041968897 Test MSE 0.0015748130750681073 Test RE 0.01896804477900459\n",
      "93 Train Loss 0.0041079847 Test MSE 0.0015929065563315638 Test RE 0.019076698248976\n",
      "94 Train Loss 0.0039941175 Test MSE 0.0016192556911390243 Test RE 0.019233830140337176\n",
      "95 Train Loss 0.0038309149 Test MSE 0.0014613805398387377 Test RE 0.01827215287830395\n",
      "96 Train Loss 0.0034714227 Test MSE 0.0011784485657557022 Test RE 0.016408292010800306\n",
      "97 Train Loss 0.003407498 Test MSE 0.0011691335602018447 Test RE 0.016343313966148323\n",
      "98 Train Loss 0.003371623 Test MSE 0.0011559777943382628 Test RE 0.016251101623039655\n",
      "99 Train Loss 0.003073876 Test MSE 0.0010170754221061774 Test RE 0.015243498068852047\n",
      "Training time: 125.13\n",
      "3\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 63.261215 Test MSE 5.833745020549808 Test RE 1.15446768739979\n",
      "1 Train Loss 41.821365 Test MSE 8.473413837147875 Test RE 1.3913528088318816\n",
      "2 Train Loss 33.15285 Test MSE 8.692624265356885 Test RE 1.409235302916072\n",
      "3 Train Loss 27.897991 Test MSE 9.431012304588082 Test RE 1.4678687205783756\n",
      "4 Train Loss 24.477093 Test MSE 9.188138332301673 Test RE 1.4488446546087632\n",
      "5 Train Loss 22.230972 Test MSE 9.100533140058458 Test RE 1.4419210369679905\n",
      "6 Train Loss 20.473734 Test MSE 9.195413888448307 Test RE 1.449418169304823\n",
      "7 Train Loss 18.919613 Test MSE 9.214785724024063 Test RE 1.4509440994336336\n",
      "8 Train Loss 17.593311 Test MSE 9.168041063786243 Test RE 1.447259254017319\n",
      "9 Train Loss 15.89586 Test MSE 9.141103305819245 Test RE 1.4451315040040713\n",
      "10 Train Loss 15.014016 Test MSE 9.294273024998743 Test RE 1.4571886278648472\n",
      "11 Train Loss 13.71513 Test MSE 8.895751512242134 Test RE 1.4256055644517713\n",
      "12 Train Loss 12.14258 Test MSE 7.722254736319446 Test RE 1.328250910063162\n",
      "13 Train Loss 9.035635 Test MSE 7.089694382923967 Test RE 1.272687613854339\n",
      "14 Train Loss 7.909666 Test MSE 7.129490005099996 Test RE 1.2762545180415803\n",
      "15 Train Loss 7.127116 Test MSE 6.8441268168359946 Test RE 1.250452169387557\n",
      "16 Train Loss 6.6771164 Test MSE 6.6799500796684175 Test RE 1.2353632246597923\n",
      "17 Train Loss 6.3689623 Test MSE 6.651867766342026 Test RE 1.2327637744796893\n",
      "18 Train Loss 6.1466084 Test MSE 6.660218903971104 Test RE 1.233537373046701\n",
      "19 Train Loss 5.8672624 Test MSE 6.64625785085834 Test RE 1.2322438333481398\n",
      "20 Train Loss 5.525968 Test MSE 6.6489818926835405 Test RE 1.2324963318174462\n",
      "21 Train Loss 5.1565623 Test MSE 6.548003941152673 Test RE 1.2231015776195961\n",
      "22 Train Loss 4.6159396 Test MSE 6.394950416558854 Test RE 1.2087226241121651\n",
      "23 Train Loss 4.2272205 Test MSE 6.124273839774007 Test RE 1.1828654887003018\n",
      "24 Train Loss 3.3080757 Test MSE 5.520517550103024 Test RE 1.1230470663599017\n",
      "25 Train Loss 2.5144968 Test MSE 5.512369722234901 Test RE 1.1222179979888856\n",
      "26 Train Loss 2.1369514 Test MSE 5.630161259759618 Test RE 1.134144725440346\n",
      "27 Train Loss 1.9112319 Test MSE 5.682430544944102 Test RE 1.1393971487978194\n",
      "28 Train Loss 1.7608683 Test MSE 5.74365326408328 Test RE 1.1455186583682224\n",
      "29 Train Loss 1.6243656 Test MSE 5.739537173702611 Test RE 1.145108126677158\n",
      "30 Train Loss 1.5379258 Test MSE 5.845977133011285 Test RE 1.155677389212746\n",
      "31 Train Loss 1.4503691 Test MSE 5.766526302220842 Test RE 1.147797300281125\n",
      "32 Train Loss 1.383001 Test MSE 5.767237004226354 Test RE 1.1478680288851213\n",
      "33 Train Loss 1.3330215 Test MSE 5.760393380238738 Test RE 1.1471867746738647\n",
      "34 Train Loss 1.2976522 Test MSE 5.771252583429122 Test RE 1.1482675748822966\n",
      "35 Train Loss 1.2504935 Test MSE 5.723055638572463 Test RE 1.1434628103682791\n",
      "36 Train Loss 1.2220792 Test MSE 5.72088118523287 Test RE 1.143245562546153\n",
      "37 Train Loss 1.1928834 Test MSE 5.725849866238084 Test RE 1.1437419187434643\n",
      "38 Train Loss 1.1606568 Test MSE 5.747502227128153 Test RE 1.145902414174267\n",
      "39 Train Loss 1.1234419 Test MSE 5.812570082367736 Test RE 1.1523705778162323\n",
      "40 Train Loss 1.0908008 Test MSE 5.850759568904191 Test RE 1.1561500067923625\n",
      "41 Train Loss 1.0620861 Test MSE 5.88072294875996 Test RE 1.1591067102400838\n",
      "42 Train Loss 1.0337296 Test MSE 5.904319118257107 Test RE 1.161429817268178\n",
      "43 Train Loss 1.0127181 Test MSE 5.908826897526201 Test RE 1.1618730919495055\n",
      "44 Train Loss 0.99402237 Test MSE 5.912749522544236 Test RE 1.1622586876344971\n",
      "45 Train Loss 0.97632 Test MSE 5.944966716168139 Test RE 1.1654208243570863\n",
      "46 Train Loss 0.96044165 Test MSE 5.961194587744009 Test RE 1.1670103547794985\n",
      "47 Train Loss 0.94168454 Test MSE 5.945693725165275 Test RE 1.1654920817386345\n",
      "48 Train Loss 0.92781836 Test MSE 5.94732985157592 Test RE 1.1656524298240405\n",
      "49 Train Loss 0.9134783 Test MSE 5.956960290118592 Test RE 1.1665958114436648\n",
      "50 Train Loss 0.9023284 Test MSE 5.951062804443774 Test RE 1.1660181942179688\n",
      "51 Train Loss 0.89459 Test MSE 5.947827689282701 Test RE 1.1657012158846374\n",
      "52 Train Loss 0.88674396 Test MSE 5.981740822015131 Test RE 1.169019771061874\n",
      "53 Train Loss 0.8800093 Test MSE 5.981389031033953 Test RE 1.1689853950607072\n",
      "54 Train Loss 0.8730616 Test MSE 5.990587902760068 Test RE 1.1698839501776068\n",
      "55 Train Loss 0.86642617 Test MSE 5.9999287702635336 Test RE 1.1707956699188315\n",
      "56 Train Loss 0.85859084 Test MSE 6.024066120125272 Test RE 1.1731483261617623\n",
      "57 Train Loss 0.85087115 Test MSE 6.039713128830626 Test RE 1.1746709155098032\n",
      "58 Train Loss 0.84419 Test MSE 6.037848441241064 Test RE 1.1744895688695152\n",
      "59 Train Loss 0.8373065 Test MSE 6.031678108723151 Test RE 1.1738892852007874\n",
      "60 Train Loss 0.8298706 Test MSE 6.03691912280915 Test RE 1.174399179319577\n",
      "61 Train Loss 0.82213205 Test MSE 6.029374158391076 Test RE 1.1736650655988967\n",
      "62 Train Loss 0.8165195 Test MSE 6.042043984923668 Test RE 1.174897559117786\n",
      "63 Train Loss 0.81093764 Test MSE 6.045314421766593 Test RE 1.1752154903060552\n",
      "64 Train Loss 0.80622494 Test MSE 6.0518828728347955 Test RE 1.1758537738762853\n",
      "65 Train Loss 0.79911214 Test MSE 6.069954677575332 Test RE 1.1776081005992656\n",
      "66 Train Loss 0.79348266 Test MSE 6.105824862025246 Test RE 1.1810824921124934\n",
      "67 Train Loss 0.7853773 Test MSE 6.102016722761972 Test RE 1.1807141202521714\n",
      "68 Train Loss 0.78069496 Test MSE 6.1080286657857386 Test RE 1.1812956196809956\n",
      "69 Train Loss 0.7766533 Test MSE 6.131110018905518 Test RE 1.1835254873609913\n",
      "70 Train Loss 0.7730179 Test MSE 6.159406108035548 Test RE 1.1862534266734521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Train Loss 0.7683634 Test MSE 6.166620988649899 Test RE 1.1869479881170477\n",
      "72 Train Loss 0.7646722 Test MSE 6.176934875862495 Test RE 1.1879401792346145\n",
      "73 Train Loss 0.7600738 Test MSE 6.177858536852219 Test RE 1.188028994561928\n",
      "74 Train Loss 0.7563264 Test MSE 6.188185910185582 Test RE 1.189021579260039\n",
      "75 Train Loss 0.7523766 Test MSE 6.205516595271744 Test RE 1.1906854070193078\n",
      "76 Train Loss 0.7478469 Test MSE 6.212966208136671 Test RE 1.1913998910331414\n",
      "77 Train Loss 0.7444936 Test MSE 6.221039080458792 Test RE 1.1921736677282393\n",
      "78 Train Loss 0.74082315 Test MSE 6.2379909011652925 Test RE 1.19379685040029\n",
      "79 Train Loss 0.73735064 Test MSE 6.240328179270482 Test RE 1.1940204780048518\n",
      "80 Train Loss 0.7335959 Test MSE 6.257980275716691 Test RE 1.1957080559579119\n",
      "81 Train Loss 0.7316603 Test MSE 6.253361621427127 Test RE 1.195266732939486\n",
      "82 Train Loss 0.72894514 Test MSE 6.249321604027452 Test RE 1.1948805663560862\n",
      "83 Train Loss 0.7242169 Test MSE 6.251830473553712 Test RE 1.1951203922775697\n",
      "84 Train Loss 0.7194227 Test MSE 6.254004767968192 Test RE 1.195328196832576\n",
      "85 Train Loss 0.7153972 Test MSE 6.263875546407976 Test RE 1.196271126070988\n",
      "86 Train Loss 0.7113591 Test MSE 6.2820612377638385 Test RE 1.1980064135978352\n",
      "87 Train Loss 0.7087173 Test MSE 6.303781986351577 Test RE 1.2000757297805733\n",
      "88 Train Loss 0.7042468 Test MSE 6.328140393286973 Test RE 1.202392097060926\n",
      "89 Train Loss 0.6991739 Test MSE 6.3268371100992 Test RE 1.2022682741050372\n",
      "90 Train Loss 0.6955434 Test MSE 6.345255927979197 Test RE 1.2040170362935332\n",
      "91 Train Loss 0.6926678 Test MSE 6.35680167280583 Test RE 1.205111945287625\n",
      "92 Train Loss 0.68803453 Test MSE 6.373603579081952 Test RE 1.2067035330834683\n",
      "93 Train Loss 0.6830963 Test MSE 6.393640360557304 Test RE 1.2085988095920432\n",
      "94 Train Loss 0.6795441 Test MSE 6.407905904644847 Test RE 1.2099463762442515\n",
      "95 Train Loss 0.67556727 Test MSE 6.408767362601078 Test RE 1.2100277041319296\n",
      "96 Train Loss 0.6712997 Test MSE 6.417956391339049 Test RE 1.2108948752987776\n",
      "97 Train Loss 0.6685405 Test MSE 6.424278273833231 Test RE 1.211491112670954\n",
      "98 Train Loss 0.6652443 Test MSE 6.41169594252931 Test RE 1.2103041424785557\n",
      "99 Train Loss 0.6616338 Test MSE 6.424654138837124 Test RE 1.2115265524847492\n",
      "Training time: 124.64\n",
      "4\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.63106 Test MSE 8.421713422084597 Test RE 1.3871016545472852\n",
      "1 Train Loss 45.123985 Test MSE 8.005171047652965 Test RE 1.3523632743531868\n",
      "2 Train Loss 35.987144 Test MSE 8.1815906266854 Test RE 1.3671838921169017\n",
      "3 Train Loss 28.249393 Test MSE 6.794760802766342 Test RE 1.2459343136316892\n",
      "4 Train Loss 24.447393 Test MSE 6.547310838830476 Test RE 1.2230368436193124\n",
      "5 Train Loss 21.40148 Test MSE 6.097392732703044 Test RE 1.1802666743263903\n",
      "6 Train Loss 19.296263 Test MSE 6.333797779547393 Test RE 1.2029294489876179\n",
      "7 Train Loss 16.905556 Test MSE 6.022076627363782 Test RE 1.1729545896728946\n",
      "8 Train Loss 12.73435 Test MSE 5.75993729620464 Test RE 1.147141359031703\n",
      "9 Train Loss 10.678805 Test MSE 5.364380634195092 Test RE 1.1070515728262371\n",
      "10 Train Loss 8.509599 Test MSE 5.045313956596818 Test RE 1.0736238695975573\n",
      "11 Train Loss 6.907339 Test MSE 4.812445208845579 Test RE 1.0485543813314544\n",
      "12 Train Loss 5.7636857 Test MSE 4.415980827224 Test RE 1.0044345660332996\n",
      "13 Train Loss 5.174873 Test MSE 4.368303330079152 Test RE 0.9989976212490962\n",
      "14 Train Loss 4.4555497 Test MSE 3.9703898396340107 Test RE 0.9524115109333559\n",
      "15 Train Loss 3.926003 Test MSE 3.750342251759702 Test RE 0.9256429796099325\n",
      "16 Train Loss 3.5457234 Test MSE 3.6270524677246168 Test RE 0.9103009150085173\n",
      "17 Train Loss 3.079429 Test MSE 3.2419923482444104 Test RE 0.860625189098799\n",
      "18 Train Loss 2.695429 Test MSE 2.9301852637773056 Test RE 0.8181926997633424\n",
      "19 Train Loss 2.3881884 Test MSE 2.5063054943941037 Test RE 0.7567023163094301\n",
      "20 Train Loss 2.107575 Test MSE 2.241136862807564 Test RE 0.7155537297925932\n",
      "21 Train Loss 1.9255096 Test MSE 2.1244388619038443 Test RE 0.696674924038635\n",
      "22 Train Loss 1.7855959 Test MSE 2.0360971769885805 Test RE 0.6820360195959932\n",
      "23 Train Loss 1.6584908 Test MSE 1.9380456875699947 Test RE 0.6654111375304261\n",
      "24 Train Loss 1.518314 Test MSE 1.6869029229568946 Test RE 0.6208019975140397\n",
      "25 Train Loss 1.4189348 Test MSE 1.4504521775093593 Test RE 0.5756516680731238\n",
      "26 Train Loss 1.1912436 Test MSE 1.1485030659249524 Test RE 0.5122407677260233\n",
      "27 Train Loss 0.9213565 Test MSE 0.9150042485881156 Test RE 0.4572141004948132\n",
      "28 Train Loss 0.7952631 Test MSE 0.8224849228081147 Test RE 0.43348296279040255\n",
      "29 Train Loss 0.5987736 Test MSE 0.5634509114829003 Test RE 0.35878650794278744\n",
      "30 Train Loss 0.503264 Test MSE 0.5412339414650792 Test RE 0.3516418629719068\n",
      "31 Train Loss 0.4079772 Test MSE 0.4590072218221192 Test RE 0.3238305515796325\n",
      "32 Train Loss 0.33839554 Test MSE 0.4242087387533948 Test RE 0.31131343660310207\n",
      "33 Train Loss 0.29400727 Test MSE 0.34782618979872787 Test RE 0.28189618598621435\n",
      "34 Train Loss 0.25316343 Test MSE 0.2738704242213103 Test RE 0.25013854973057353\n",
      "35 Train Loss 0.22291331 Test MSE 0.21584637575025273 Test RE 0.2220651669886575\n",
      "36 Train Loss 0.19750443 Test MSE 0.136499366204002 Test RE 0.17659295657261204\n",
      "37 Train Loss 0.17616473 Test MSE 0.10364659940987188 Test RE 0.1538812087702184\n",
      "38 Train Loss 0.15899089 Test MSE 0.10856262878596602 Test RE 0.15748827850401625\n",
      "39 Train Loss 0.13100477 Test MSE 0.06622762604860986 Test RE 0.12300638468823745\n",
      "40 Train Loss 0.10408731 Test MSE 0.050910289851482535 Test RE 0.10784768944374026\n",
      "41 Train Loss 0.083374634 Test MSE 0.03186329882918342 Test RE 0.08532050721335725\n",
      "42 Train Loss 0.06594705 Test MSE 0.02336067280804238 Test RE 0.07305513264336624\n",
      "43 Train Loss 0.05723808 Test MSE 0.017645307488212 Test RE 0.06349253626315006\n",
      "44 Train Loss 0.051038142 Test MSE 0.012879406178633538 Test RE 0.054244533691248584\n",
      "45 Train Loss 0.047642928 Test MSE 0.01381521550332175 Test RE 0.056180667153901194\n",
      "46 Train Loss 0.0416979 Test MSE 0.011044625822883831 Test RE 0.05023235784091308\n",
      "47 Train Loss 0.038872406 Test MSE 0.010157476109767293 Test RE 0.048172697401092875\n",
      "48 Train Loss 0.034064732 Test MSE 0.00970392844183185 Test RE 0.047084921742792024\n",
      "49 Train Loss 0.03194251 Test MSE 0.008388555181920214 Test RE 0.04377756919642003\n",
      "50 Train Loss 0.029662281 Test MSE 0.009220595357631216 Test RE 0.0458973426981735\n",
      "51 Train Loss 0.028468316 Test MSE 0.008612054489634199 Test RE 0.044356926357893546\n",
      "52 Train Loss 0.026317174 Test MSE 0.007815890315269181 Test RE 0.0422568663939635\n",
      "53 Train Loss 0.024038311 Test MSE 0.006444100032687847 Test RE 0.03836977009484345\n",
      "54 Train Loss 0.02285362 Test MSE 0.005848056154658977 Test RE 0.03655222575614929\n",
      "55 Train Loss 0.021212865 Test MSE 0.00520628099158414 Test RE 0.034488305928974596\n",
      "56 Train Loss 0.0200582 Test MSE 0.005285954408688512 Test RE 0.03475119687178053\n",
      "57 Train Loss 0.01879431 Test MSE 0.0047594871391441924 Test RE 0.03297525321053653\n",
      "58 Train Loss 0.018448774 Test MSE 0.004582670145944578 Test RE 0.03235693373560304\n",
      "59 Train Loss 0.016568093 Test MSE 0.00379597745947593 Test RE 0.029448953938112893\n",
      "60 Train Loss 0.015962437 Test MSE 0.003454674024498431 Test RE 0.028093871882525438\n",
      "61 Train Loss 0.014811517 Test MSE 0.0027945486207192095 Test RE 0.025267594307024067\n",
      "62 Train Loss 0.013933976 Test MSE 0.0027751508203858366 Test RE 0.025179746621128887\n",
      "63 Train Loss 0.013282869 Test MSE 0.0024900343636091032 Test RE 0.02385122726520293\n",
      "64 Train Loss 0.012115443 Test MSE 0.002229510847954024 Test RE 0.022569027991668517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 0.01079924 Test MSE 0.002080027617012563 Test RE 0.021799303149712804\n",
      "66 Train Loss 0.0101211425 Test MSE 0.0018481942582008592 Test RE 0.02054858251193266\n",
      "67 Train Loss 0.009637525 Test MSE 0.001618477352486363 Test RE 0.019229206956692863\n",
      "68 Train Loss 0.008380551 Test MSE 0.0015399846125531752 Test RE 0.018757124065631733\n",
      "69 Train Loss 0.007849146 Test MSE 0.0014700153413921692 Test RE 0.01832605534722085\n",
      "70 Train Loss 0.0076680193 Test MSE 0.001491945258825079 Test RE 0.018462244775354075\n",
      "71 Train Loss 0.0075036655 Test MSE 0.0015419123653405919 Test RE 0.01876886047812373\n",
      "72 Train Loss 0.0069373697 Test MSE 0.0015633360345763145 Test RE 0.018898800018937085\n",
      "73 Train Loss 0.006695687 Test MSE 0.0014622478665448733 Test RE 0.01827757431885507\n",
      "74 Train Loss 0.0065428144 Test MSE 0.0014467071631838382 Test RE 0.018180188262621716\n",
      "75 Train Loss 0.006168266 Test MSE 0.0017535344044640765 Test RE 0.020015442959705542\n",
      "76 Train Loss 0.0057791476 Test MSE 0.002151176717705576 Test RE 0.02216900006729578\n",
      "77 Train Loss 0.005639527 Test MSE 0.002092561630796673 Test RE 0.021864884582848125\n",
      "78 Train Loss 0.0055042105 Test MSE 0.0016935026909239146 Test RE 0.01966984808680324\n",
      "79 Train Loss 0.0053062793 Test MSE 0.001465435575133009 Test RE 0.018297486080325154\n",
      "80 Train Loss 0.005103551 Test MSE 0.0014646683818079682 Test RE 0.018292695850314056\n",
      "81 Train Loss 0.004803855 Test MSE 0.0013351100853909298 Test RE 0.017464919916313888\n",
      "82 Train Loss 0.0046508736 Test MSE 0.0011966137196391029 Test RE 0.016534270912467553\n",
      "83 Train Loss 0.0045842277 Test MSE 0.001255698167063712 Test RE 0.016937553906671822\n",
      "84 Train Loss 0.004512177 Test MSE 0.001364592368066439 Test RE 0.017656699641600833\n",
      "85 Train Loss 0.0044196765 Test MSE 0.0013914262633193688 Test RE 0.017829458710425246\n",
      "86 Train Loss 0.004358772 Test MSE 0.0013742013454715377 Test RE 0.017718756708027708\n",
      "87 Train Loss 0.0041991724 Test MSE 0.0012677910538061322 Test RE 0.017018916272353222\n",
      "88 Train Loss 0.004044176 Test MSE 0.0012128017327245027 Test RE 0.01664573455059405\n",
      "89 Train Loss 0.0039542112 Test MSE 0.001260289470438094 Test RE 0.016968490677622638\n",
      "90 Train Loss 0.003895542 Test MSE 0.00121080547073454 Test RE 0.016632029535456186\n",
      "91 Train Loss 0.003853933 Test MSE 0.0012421452532835947 Test RE 0.016845901319074163\n",
      "92 Train Loss 0.003802349 Test MSE 0.001192587396149883 Test RE 0.016506430508868686\n",
      "93 Train Loss 0.0033650345 Test MSE 0.001035899883988526 Test RE 0.015383917863752898\n",
      "94 Train Loss 0.0032069515 Test MSE 0.0009868091115589049 Test RE 0.015014975769671814\n",
      "95 Train Loss 0.0031281947 Test MSE 0.0009604568550624256 Test RE 0.014813135332809584\n",
      "96 Train Loss 0.0030903073 Test MSE 0.0009788658001377033 Test RE 0.014954422208224261\n",
      "97 Train Loss 0.0030493955 Test MSE 0.0010606025594984238 Test RE 0.01556626414335319\n",
      "98 Train Loss 0.0029865524 Test MSE 0.0011182337059728886 Test RE 0.015983590692729876\n",
      "99 Train Loss 0.0028498268 Test MSE 0.0011235602102011553 Test RE 0.016021612941754776\n",
      "Training time: 125.20\n",
      "5\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 66.566605 Test MSE 5.434700192624401 Test RE 1.1142839006494327\n",
      "1 Train Loss 51.75062 Test MSE 7.774489313372457 Test RE 1.332735590805522\n",
      "2 Train Loss 40.254738 Test MSE 8.283792825207884 Test RE 1.3756966340477195\n",
      "3 Train Loss 35.125404 Test MSE 8.455846265001433 Test RE 1.3899097438836288\n",
      "4 Train Loss 31.861732 Test MSE 8.51347053367855 Test RE 1.3946376292326368\n",
      "5 Train Loss 29.438065 Test MSE 8.694614188651688 Test RE 1.4093965953866132\n",
      "6 Train Loss 27.416546 Test MSE 8.599478016956002 Test RE 1.4016646016860104\n",
      "7 Train Loss 25.850422 Test MSE 8.857284622378408 Test RE 1.422519932856565\n",
      "8 Train Loss 24.161861 Test MSE 9.28556647128602 Test RE 1.4565059459798024\n",
      "9 Train Loss 22.229982 Test MSE 9.754646167752293 Test RE 1.4928419159056938\n",
      "10 Train Loss 20.69019 Test MSE 9.611196486679203 Test RE 1.4818245587421333\n",
      "11 Train Loss 19.65881 Test MSE 9.743382061215096 Test RE 1.4919797427780226\n",
      "12 Train Loss 18.478378 Test MSE 9.918515616810325 Test RE 1.5053289052450212\n",
      "13 Train Loss 17.684677 Test MSE 10.247579632024049 Test RE 1.5300961105522095\n",
      "14 Train Loss 16.189339 Test MSE 10.064817041579628 Test RE 1.5163903172494262\n",
      "15 Train Loss 14.363102 Test MSE 9.815480041991112 Test RE 1.497489660446267\n",
      "16 Train Loss 11.558953 Test MSE 9.224574099548132 Test RE 1.4517145251672063\n",
      "17 Train Loss 9.667593 Test MSE 9.26359344046695 Test RE 1.454781613610692\n",
      "18 Train Loss 8.39956 Test MSE 8.973144168917576 Test RE 1.4317934885668533\n",
      "19 Train Loss 6.687222 Test MSE 8.67330081530749 Test RE 1.4076680869876148\n",
      "20 Train Loss 5.2578154 Test MSE 8.183512029120545 Test RE 1.3673444205745464\n",
      "21 Train Loss 4.3283386 Test MSE 7.762313002055998 Test RE 1.3316915246469685\n",
      "22 Train Loss 3.5350194 Test MSE 7.8093766254750365 Test RE 1.3357225084146407\n",
      "23 Train Loss 3.1997938 Test MSE 8.064025573142125 Test RE 1.3573255007068183\n",
      "24 Train Loss 2.9294467 Test MSE 8.08996177238036 Test RE 1.3595065208014445\n",
      "25 Train Loss 2.7349637 Test MSE 7.959635091318303 Test RE 1.3485114529556372\n",
      "26 Train Loss 2.5534854 Test MSE 7.93610411475754 Test RE 1.3465166832307556\n",
      "27 Train Loss 2.4344678 Test MSE 8.015788231184294 Test RE 1.3532597905761221\n",
      "28 Train Loss 2.324464 Test MSE 7.951959612944587 Test RE 1.3478611111485506\n",
      "29 Train Loss 2.2261198 Test MSE 8.022075817708497 Test RE 1.3537904352156505\n",
      "30 Train Loss 2.1591911 Test MSE 8.109416290305116 Test RE 1.3611401912147587\n",
      "31 Train Loss 2.1100435 Test MSE 8.060492074547291 Test RE 1.357028091353927\n",
      "32 Train Loss 2.0649521 Test MSE 8.036939889061104 Test RE 1.355044071140289\n",
      "33 Train Loss 2.015267 Test MSE 8.015635700102115 Test RE 1.3532469150387243\n",
      "34 Train Loss 1.9748662 Test MSE 8.020355972183799 Test RE 1.353645308487933\n",
      "35 Train Loss 1.9441146 Test MSE 8.035962407517298 Test RE 1.354961665967122\n",
      "36 Train Loss 1.9048271 Test MSE 8.086535419096407 Test RE 1.3592185934239192\n",
      "37 Train Loss 1.8725721 Test MSE 8.101685401726673 Test RE 1.3604912337628194\n",
      "38 Train Loss 1.8365757 Test MSE 8.108889509523916 Test RE 1.361095981242533\n",
      "39 Train Loss 1.8073899 Test MSE 8.057774396360811 Test RE 1.3567993040466786\n",
      "40 Train Loss 1.773702 Test MSE 8.044884559671107 Test RE 1.3557136493518733\n",
      "41 Train Loss 1.7513365 Test MSE 8.000194108471632 Test RE 1.3519428163650287\n",
      "42 Train Loss 1.7242424 Test MSE 7.957740644284301 Test RE 1.3483509659785873\n",
      "43 Train Loss 1.6981633 Test MSE 7.888132668273202 Test RE 1.3424408632977973\n",
      "44 Train Loss 1.6727328 Test MSE 7.866777351803726 Test RE 1.340622455813003\n",
      "45 Train Loss 1.6450404 Test MSE 7.868574313855434 Test RE 1.340775562353049\n",
      "46 Train Loss 1.6249 Test MSE 7.888117562905232 Test RE 1.3424395779446106\n",
      "47 Train Loss 1.5944226 Test MSE 7.85928403831106 Test RE 1.3399838145227305\n",
      "48 Train Loss 1.5697012 Test MSE 7.824909441366231 Test RE 1.3370502216470261\n",
      "49 Train Loss 1.5429194 Test MSE 7.828735295304817 Test RE 1.3373770454768215\n",
      "50 Train Loss 1.5118783 Test MSE 7.801610165426123 Test RE 1.3350581521871556\n",
      "51 Train Loss 1.4861034 Test MSE 7.808350784840524 Test RE 1.3356347752002686\n",
      "52 Train Loss 1.4667962 Test MSE 7.727257972291527 Test RE 1.3286811261657119\n",
      "53 Train Loss 1.4379199 Test MSE 7.659183254675327 Test RE 1.3228155472460283\n",
      "54 Train Loss 1.4042444 Test MSE 7.672594857896832 Test RE 1.3239731979435447\n",
      "55 Train Loss 1.382811 Test MSE 7.657206589414398 Test RE 1.3226448415600047\n",
      "56 Train Loss 1.3593259 Test MSE 7.620151946500005 Test RE 1.3194406986449458\n",
      "57 Train Loss 1.3404316 Test MSE 7.6108512657468435 Test RE 1.3186352394099963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 1.3158395 Test MSE 7.570030740727879 Test RE 1.3150942588803785\n",
      "59 Train Loss 1.289758 Test MSE 7.540687767049013 Test RE 1.312542998213375\n",
      "60 Train Loss 1.268757 Test MSE 7.459075053367191 Test RE 1.3054208617239444\n",
      "61 Train Loss 1.2482125 Test MSE 7.434360501491424 Test RE 1.3032564069938153\n",
      "62 Train Loss 1.2296596 Test MSE 7.408091458840823 Test RE 1.3009518648629301\n",
      "63 Train Loss 1.2069607 Test MSE 7.353708417912368 Test RE 1.2961679038591645\n",
      "64 Train Loss 1.1813165 Test MSE 7.284962363156404 Test RE 1.2900950725500482\n",
      "65 Train Loss 1.1646925 Test MSE 7.230637838909675 Test RE 1.2852759024530271\n",
      "66 Train Loss 1.148816 Test MSE 7.173654466217412 Test RE 1.280201369238269\n",
      "67 Train Loss 1.1322262 Test MSE 7.155041125538698 Test RE 1.2785394337863512\n",
      "68 Train Loss 1.1196816 Test MSE 7.13242335100755 Test RE 1.2765170410950495\n",
      "69 Train Loss 1.1043618 Test MSE 7.093463237489856 Test RE 1.2730258468566784\n",
      "70 Train Loss 1.0860802 Test MSE 7.083167659843081 Test RE 1.272101665308634\n",
      "71 Train Loss 1.0697964 Test MSE 7.0310168894798695 Test RE 1.2674100041831213\n",
      "72 Train Loss 1.0499101 Test MSE 6.951598922559389 Test RE 1.2602317411813875\n",
      "73 Train Loss 1.0218526 Test MSE 6.7750296967966035 Test RE 1.244123982437507\n",
      "74 Train Loss 1.0103017 Test MSE 6.725381492620539 Test RE 1.2395570578235988\n",
      "75 Train Loss 0.9947883 Test MSE 6.654115787819414 Test RE 1.2329720652513663\n",
      "76 Train Loss 0.9780403 Test MSE 6.618528885514993 Test RE 1.2296706138791498\n",
      "77 Train Loss 0.96658254 Test MSE 6.6319081154002575 Test RE 1.2309128642439628\n",
      "78 Train Loss 0.9564918 Test MSE 6.586278629345502 Test RE 1.2266710334079058\n",
      "79 Train Loss 0.9440959 Test MSE 6.497967273928742 Test RE 1.2184194415784155\n",
      "80 Train Loss 0.9291567 Test MSE 6.428471696450178 Test RE 1.2118864462205365\n",
      "81 Train Loss 0.9166838 Test MSE 6.398956069997831 Test RE 1.2091011232146807\n",
      "82 Train Loss 0.90745425 Test MSE 6.377064564886035 Test RE 1.20703111989807\n",
      "83 Train Loss 0.8975525 Test MSE 6.354592897570519 Test RE 1.2049025591197742\n",
      "84 Train Loss 0.8892468 Test MSE 6.344305419460628 Test RE 1.2039268530665637\n",
      "85 Train Loss 0.8840647 Test MSE 6.350925390367997 Test RE 1.2045548085505373\n",
      "86 Train Loss 0.8764454 Test MSE 6.340235514960701 Test RE 1.2035406284866026\n",
      "87 Train Loss 0.87096596 Test MSE 6.316883372961964 Test RE 1.2013221636962228\n",
      "88 Train Loss 0.8668808 Test MSE 6.327324077721353 Test RE 1.2023145416513057\n",
      "89 Train Loss 0.861798 Test MSE 6.319943260846352 Test RE 1.2016130877067983\n",
      "90 Train Loss 0.855527 Test MSE 6.3166635416392305 Test RE 1.2013012601491466\n",
      "91 Train Loss 0.8510717 Test MSE 6.313396032792941 Test RE 1.2009905130103367\n",
      "92 Train Loss 0.84646994 Test MSE 6.308109429236873 Test RE 1.2004875752587232\n",
      "93 Train Loss 0.8408609 Test MSE 6.289161363779247 Test RE 1.1986832292258887\n",
      "94 Train Loss 0.83763677 Test MSE 6.291963491346718 Test RE 1.1989502353556454\n",
      "95 Train Loss 0.83256024 Test MSE 6.294088710660726 Test RE 1.199152701332767\n",
      "96 Train Loss 0.82835644 Test MSE 6.314972019651898 Test RE 1.2011404027964048\n",
      "97 Train Loss 0.8239236 Test MSE 6.314725111008931 Test RE 1.2011169209151777\n",
      "98 Train Loss 0.81957674 Test MSE 6.3208316457358755 Test RE 1.201697539208553\n",
      "99 Train Loss 0.81674135 Test MSE 6.315334239728948 Test RE 1.2011748503702961\n",
      "Training time: 124.95\n",
      "6\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 65.74536 Test MSE 6.671004021854532 Test RE 1.2345357234528949\n",
      "1 Train Loss 45.942383 Test MSE 9.535909502347852 Test RE 1.476009391188666\n",
      "2 Train Loss 36.604984 Test MSE 8.441328387289975 Test RE 1.3887160603860271\n",
      "3 Train Loss 31.391413 Test MSE 8.391586690759757 Test RE 1.3846184141280415\n",
      "4 Train Loss 29.646917 Test MSE 8.548886902131628 Test RE 1.3975354919380918\n",
      "5 Train Loss 26.964682 Test MSE 8.98273366389374 Test RE 1.4325583548080456\n",
      "6 Train Loss 23.799934 Test MSE 8.478376360620286 Test RE 1.3917601777190878\n",
      "7 Train Loss 20.79329 Test MSE 8.431386268500676 Test RE 1.387898010952707\n",
      "8 Train Loss 19.207558 Test MSE 8.251191061618403 Test RE 1.3729868637424305\n",
      "9 Train Loss 17.50195 Test MSE 8.02358932161095 Test RE 1.3539181372293918\n",
      "10 Train Loss 15.96821 Test MSE 7.856320002010368 Test RE 1.339731111146982\n",
      "11 Train Loss 14.92268 Test MSE 7.866106880577486 Test RE 1.340565325180324\n",
      "12 Train Loss 13.4187975 Test MSE 7.413912979935292 Test RE 1.3014629297890836\n",
      "13 Train Loss 11.536564 Test MSE 6.275927479133612 Test RE 1.1974214084157193\n",
      "14 Train Loss 9.133392 Test MSE 6.133498099338588 Test RE 1.1837559577721848\n",
      "15 Train Loss 7.5457773 Test MSE 5.264518749153028 Test RE 1.0966988767074333\n",
      "16 Train Loss 5.527489 Test MSE 4.844379925968011 Test RE 1.0520276593356646\n",
      "17 Train Loss 4.3947945 Test MSE 4.982929903334196 Test RE 1.0669656776864154\n",
      "18 Train Loss 3.723762 Test MSE 5.067621447376418 Test RE 1.0759947269915107\n",
      "19 Train Loss 3.3978593 Test MSE 5.084886785110063 Test RE 1.0778261202975208\n",
      "20 Train Loss 3.1067686 Test MSE 5.020423754216463 Test RE 1.0709723245033393\n",
      "21 Train Loss 2.8948982 Test MSE 5.016350919805219 Test RE 1.070537821545109\n",
      "22 Train Loss 2.7649417 Test MSE 5.044761719082386 Test RE 1.073565110954677\n",
      "23 Train Loss 2.6278186 Test MSE 5.050923778879313 Test RE 1.0742205783364465\n",
      "24 Train Loss 2.551113 Test MSE 5.082385818633141 Test RE 1.0775610270275802\n",
      "25 Train Loss 2.4528556 Test MSE 5.151184305828037 Test RE 1.0848297952326622\n",
      "26 Train Loss 2.3473449 Test MSE 5.179027739084615 Test RE 1.0877577315325142\n",
      "27 Train Loss 2.2857566 Test MSE 5.164011794902506 Test RE 1.0861796780072135\n",
      "28 Train Loss 2.2366676 Test MSE 5.195489982742011 Test RE 1.0894851528154381\n",
      "29 Train Loss 2.1771255 Test MSE 5.1665861998416895 Test RE 1.0864503898124398\n",
      "30 Train Loss 2.1279626 Test MSE 5.166889771446007 Test RE 1.0864823074685588\n",
      "31 Train Loss 2.082228 Test MSE 5.15025921781387 Test RE 1.084732379954711\n",
      "32 Train Loss 2.0340025 Test MSE 5.2280565231547405 Test RE 1.0928943919377812\n",
      "33 Train Loss 1.9854594 Test MSE 5.213994520617005 Test RE 1.0914236129153125\n",
      "34 Train Loss 1.9292115 Test MSE 5.260965274334772 Test RE 1.0963286862047827\n",
      "35 Train Loss 1.8890684 Test MSE 5.287549677182795 Test RE 1.09909514786167\n",
      "36 Train Loss 1.8515474 Test MSE 5.27185445076678 Test RE 1.0974626934504512\n",
      "37 Train Loss 1.8206409 Test MSE 5.32968688442512 Test RE 1.1034658772555932\n",
      "38 Train Loss 1.7840894 Test MSE 5.321126460600724 Test RE 1.1025793400272241\n",
      "39 Train Loss 1.7434986 Test MSE 5.314611520587133 Test RE 1.1019041598406103\n",
      "40 Train Loss 1.7193601 Test MSE 5.291868066322991 Test RE 1.0995438766817474\n",
      "41 Train Loss 1.6790688 Test MSE 5.354593692474769 Test RE 1.1060412422546313\n",
      "42 Train Loss 1.6563953 Test MSE 5.382885291031878 Test RE 1.1089593395157749\n",
      "43 Train Loss 1.6227434 Test MSE 5.443966307357526 Test RE 1.1152334180844043\n",
      "44 Train Loss 1.5803156 Test MSE 5.444726798643226 Test RE 1.1153113112628879\n",
      "45 Train Loss 1.5446702 Test MSE 5.414608822560239 Test RE 1.1122223131980078\n",
      "46 Train Loss 1.5209023 Test MSE 5.4292061544241 Test RE 1.1137205332076647\n",
      "47 Train Loss 1.4866971 Test MSE 5.456539800628236 Test RE 1.116520557995891\n",
      "48 Train Loss 1.4553225 Test MSE 5.524259405652995 Test RE 1.1234276074971796\n",
      "49 Train Loss 1.4342781 Test MSE 5.52142811312318 Test RE 1.1231396811333527\n",
      "50 Train Loss 1.4078238 Test MSE 5.541861763026608 Test RE 1.1252160143414203\n",
      "51 Train Loss 1.3893998 Test MSE 5.559393274531278 Test RE 1.126994402339714\n",
      "52 Train Loss 1.3692644 Test MSE 5.573720793813853 Test RE 1.1284456977592319\n",
      "53 Train Loss 1.3413451 Test MSE 5.582174030728882 Test RE 1.1293010872868245\n",
      "54 Train Loss 1.3207979 Test MSE 5.609348780812212 Test RE 1.1320465424095194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 1.3015608 Test MSE 5.597698867060226 Test RE 1.1308703720731452\n",
      "56 Train Loss 1.2879393 Test MSE 5.581547077487982 Test RE 1.1292376676537337\n",
      "57 Train Loss 1.2627194 Test MSE 5.589938271478591 Test RE 1.130086186307611\n",
      "58 Train Loss 1.2406304 Test MSE 5.622611888348672 Test RE 1.1333840943076372\n",
      "59 Train Loss 1.2195601 Test MSE 5.6449641637229355 Test RE 1.1356347018306876\n",
      "60 Train Loss 1.1979696 Test MSE 5.6578678837534975 Test RE 1.1369319241960558\n",
      "61 Train Loss 1.1841848 Test MSE 5.656421984497672 Test RE 1.1367866403102758\n",
      "62 Train Loss 1.1708767 Test MSE 5.649195200657332 Test RE 1.1360602149265988\n",
      "63 Train Loss 1.1549963 Test MSE 5.673532818953968 Test RE 1.1385047476263805\n",
      "64 Train Loss 1.1345836 Test MSE 5.637193191081371 Test RE 1.1348527636997319\n",
      "65 Train Loss 1.1203583 Test MSE 5.655001744884618 Test RE 1.1366439166255986\n",
      "66 Train Loss 1.105825 Test MSE 5.689606900114886 Test RE 1.140116395481539\n",
      "67 Train Loss 1.0909828 Test MSE 5.700357292458787 Test RE 1.141193000118212\n",
      "68 Train Loss 1.0778264 Test MSE 5.696593437059058 Test RE 1.1408161820981664\n",
      "69 Train Loss 1.0605054 Test MSE 5.708964310200834 Test RE 1.142054223635468\n",
      "70 Train Loss 1.0424367 Test MSE 5.724263321848486 Test RE 1.1435834511724179\n",
      "71 Train Loss 1.0306414 Test MSE 5.717530269669971 Test RE 1.142910694510694\n",
      "72 Train Loss 1.017633 Test MSE 5.760624861337296 Test RE 1.147209824261764\n",
      "73 Train Loss 1.0069544 Test MSE 5.759441286875557 Test RE 1.1470919656931435\n",
      "74 Train Loss 0.9915004 Test MSE 5.788216135763858 Test RE 1.1499538989766571\n",
      "75 Train Loss 0.98017967 Test MSE 5.804363582475174 Test RE 1.1515568010188775\n",
      "76 Train Loss 0.97277665 Test MSE 5.800703426894959 Test RE 1.15119366545178\n",
      "77 Train Loss 0.9618124 Test MSE 5.828490804878622 Test RE 1.153947679358765\n",
      "78 Train Loss 0.9544922 Test MSE 5.839424118303356 Test RE 1.1550294826076763\n",
      "79 Train Loss 0.9455042 Test MSE 5.87464896236181 Test RE 1.1585079558576603\n",
      "80 Train Loss 0.93557 Test MSE 5.893342343653811 Test RE 1.160349702532504\n",
      "81 Train Loss 0.927634 Test MSE 5.906070799791281 Test RE 1.1616020898241892\n",
      "82 Train Loss 0.92009646 Test MSE 5.903057230946792 Test RE 1.161305698649679\n",
      "83 Train Loss 0.912358 Test MSE 5.92187958270261 Test RE 1.1631556813658734\n",
      "84 Train Loss 0.9042325 Test MSE 5.93907629133735 Test RE 1.164843316913095\n",
      "85 Train Loss 0.8971188 Test MSE 5.942723081851821 Test RE 1.1652008883144944\n",
      "86 Train Loss 0.89302725 Test MSE 5.940545260615119 Test RE 1.1649873639978776\n",
      "87 Train Loss 0.8848215 Test MSE 5.977080165863933 Test RE 1.1685642631220614\n",
      "88 Train Loss 0.8797897 Test MSE 5.998438549024385 Test RE 1.1706502637822582\n",
      "89 Train Loss 0.87481374 Test MSE 6.027987574921723 Test RE 1.1735301031542476\n",
      "90 Train Loss 0.86685896 Test MSE 6.031852145050905 Test RE 1.1739062206127098\n",
      "91 Train Loss 0.8607655 Test MSE 6.0497914940105115 Test RE 1.1756505835446847\n",
      "92 Train Loss 0.8552148 Test MSE 6.0889798595051206 Test RE 1.1794521572283898\n",
      "93 Train Loss 0.8502124 Test MSE 6.1129204706041085 Test RE 1.1817685636844573\n",
      "94 Train Loss 0.84274435 Test MSE 6.114972239407238 Test RE 1.1819668741693217\n",
      "95 Train Loss 0.8371104 Test MSE 6.121873941659508 Test RE 1.182633703276571\n",
      "96 Train Loss 0.8319803 Test MSE 6.1152905087588465 Test RE 1.181997633011815\n",
      "97 Train Loss 0.8235312 Test MSE 6.128178648706406 Test RE 1.1832425234182093\n",
      "98 Train Loss 0.81803197 Test MSE 6.141291708684094 Test RE 1.1845077964870094\n",
      "99 Train Loss 0.8139757 Test MSE 6.154572927732652 Test RE 1.185787918980216\n",
      "Training time: 125.99\n",
      "7\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 66.02778 Test MSE 5.3715569540703765 Test RE 1.107791816809702\n",
      "1 Train Loss 48.66411 Test MSE 8.194913109040309 Test RE 1.368296565393966\n",
      "2 Train Loss 32.685963 Test MSE 7.330542116109399 Test RE 1.2941246420639425\n",
      "3 Train Loss 24.973297 Test MSE 6.762203643766109 Test RE 1.2429457765598422\n",
      "4 Train Loss 19.887518 Test MSE 6.138334499951808 Test RE 1.1842225748474782\n",
      "5 Train Loss 16.415314 Test MSE 6.1428608752231275 Test RE 1.1846591141066525\n",
      "6 Train Loss 12.986102 Test MSE 5.852754876985225 Test RE 1.1563471332318485\n",
      "7 Train Loss 10.80584 Test MSE 5.784498760624603 Test RE 1.1495845713193924\n",
      "8 Train Loss 9.063671 Test MSE 5.594895320849763 Test RE 1.1305871445816478\n",
      "9 Train Loss 7.4571047 Test MSE 5.219349890093027 Test RE 1.091983977582372\n",
      "10 Train Loss 5.6977477 Test MSE 4.997668059419144 Test RE 1.0685424103028667\n",
      "11 Train Loss 4.950772 Test MSE 4.925981108781389 Test RE 1.0608511005621213\n",
      "12 Train Loss 4.2198725 Test MSE 4.556590489419355 Test RE 1.0203004071531618\n",
      "13 Train Loss 3.4718933 Test MSE 4.044000949923249 Test RE 0.9611998287271226\n",
      "14 Train Loss 2.845208 Test MSE 3.356735513765416 Test RE 0.8757227293721228\n",
      "15 Train Loss 2.3364077 Test MSE 2.809318222556817 Test RE 0.8011402071513007\n",
      "16 Train Loss 2.0317268 Test MSE 2.4423833820312573 Test RE 0.7469903277182474\n",
      "17 Train Loss 1.6765847 Test MSE 2.284681467487991 Test RE 0.7224717827409951\n",
      "18 Train Loss 1.489033 Test MSE 2.08843490240952 Test RE 0.6907462432336208\n",
      "19 Train Loss 1.3593001 Test MSE 1.9563534486230876 Test RE 0.6685466553090521\n",
      "20 Train Loss 1.267691 Test MSE 1.766347456776885 Test RE 0.6352521286046969\n",
      "21 Train Loss 1.172779 Test MSE 1.656616048091567 Test RE 0.6152037759293325\n",
      "22 Train Loss 1.0126408 Test MSE 1.4453372380230542 Test RE 0.5746357697495206\n",
      "23 Train Loss 0.79602665 Test MSE 1.341780231508382 Test RE 0.5536671474236258\n",
      "24 Train Loss 0.7036653 Test MSE 1.1512608442618217 Test RE 0.5128553936427961\n",
      "25 Train Loss 0.6018289 Test MSE 0.9168591310548257 Test RE 0.45767729454668643\n",
      "26 Train Loss 0.49566537 Test MSE 0.7677966813686933 Test RE 0.41882362907333376\n",
      "27 Train Loss 0.409139 Test MSE 0.675329609935919 Test RE 0.39279500480542445\n",
      "28 Train Loss 0.33227456 Test MSE 0.6869445517622639 Test RE 0.3961584301173296\n",
      "29 Train Loss 0.28597116 Test MSE 0.6160726344699525 Test RE 0.37516647207523696\n",
      "30 Train Loss 0.25184205 Test MSE 0.58046246957649 Test RE 0.36416242539998916\n",
      "31 Train Loss 0.22943375 Test MSE 0.5575847893464154 Test RE 0.35691394714036445\n",
      "32 Train Loss 0.20920688 Test MSE 0.5283210161982048 Test RE 0.3474217501584941\n",
      "33 Train Loss 0.19439468 Test MSE 0.525016991654131 Test RE 0.3463336898101613\n",
      "34 Train Loss 0.18219778 Test MSE 0.5041228217235241 Test RE 0.33937218103002514\n",
      "35 Train Loss 0.16906856 Test MSE 0.5043851921606326 Test RE 0.3394604825721221\n",
      "36 Train Loss 0.16058458 Test MSE 0.45855095104789784 Test RE 0.3236695615710781\n",
      "37 Train Loss 0.15122429 Test MSE 0.42341661754754345 Test RE 0.3110226443852416\n",
      "38 Train Loss 0.14251068 Test MSE 0.39088885331806317 Test RE 0.2988372308210143\n",
      "39 Train Loss 0.13751651 Test MSE 0.38261524205094594 Test RE 0.2956576997246335\n",
      "40 Train Loss 0.13392636 Test MSE 0.34627789496342254 Test RE 0.2812680774472428\n",
      "41 Train Loss 0.12814143 Test MSE 0.2946685347627961 Test RE 0.2594627053608091\n",
      "42 Train Loss 0.12095225 Test MSE 0.22106853702311327 Test RE 0.22473542153897524\n",
      "43 Train Loss 0.08318354 Test MSE 0.14179310204648754 Test RE 0.17998470981111472\n",
      "44 Train Loss 0.063356295 Test MSE 0.1180867691036768 Test RE 0.1642512488971929\n",
      "45 Train Loss 0.051596157 Test MSE 0.10404299151962511 Test RE 0.15417518410656506\n",
      "46 Train Loss 0.04095849 Test MSE 0.10281406033923038 Test RE 0.15326193895250192\n",
      "47 Train Loss 0.03472089 Test MSE 0.10557472638805693 Test RE 0.15530593142295382\n",
      "48 Train Loss 0.02920264 Test MSE 0.10965736959312745 Test RE 0.15828033919732193\n",
      "49 Train Loss 0.025804609 Test MSE 0.10442208372230742 Test RE 0.15445580592875718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 0.023291295 Test MSE 0.10318628183599143 Test RE 0.15353911820547825\n",
      "51 Train Loss 0.021266852 Test MSE 0.11163530885292455 Test RE 0.15970144635759334\n",
      "52 Train Loss 0.019724425 Test MSE 0.11244821250313643 Test RE 0.16028184700776182\n",
      "53 Train Loss 0.01795059 Test MSE 0.10603952265875843 Test RE 0.15564742575933782\n",
      "54 Train Loss 0.01608863 Test MSE 0.1027198784314541 Test RE 0.15319172574957687\n",
      "55 Train Loss 0.015384902 Test MSE 0.0985944622548859 Test RE 0.1500839743275745\n",
      "56 Train Loss 0.014454706 Test MSE 0.09376857073032345 Test RE 0.1463648218390892\n",
      "57 Train Loss 0.014042039 Test MSE 0.09361920343420234 Test RE 0.1462482005090814\n",
      "58 Train Loss 0.012965585 Test MSE 0.08770592821659734 Test RE 0.14155412672622483\n",
      "59 Train Loss 0.012414544 Test MSE 0.08377364304556065 Test RE 0.13834445640821122\n",
      "60 Train Loss 0.011711399 Test MSE 0.08168229824892034 Test RE 0.13660671082637574\n",
      "61 Train Loss 0.010923022 Test MSE 0.0802438171595741 Test RE 0.1353984990762641\n",
      "62 Train Loss 0.0103803985 Test MSE 0.07671483528718805 Test RE 0.13238773096973458\n",
      "63 Train Loss 0.009903482 Test MSE 0.07323685577228557 Test RE 0.12935192781208252\n",
      "64 Train Loss 0.009265572 Test MSE 0.06713415645763023 Test RE 0.12384538525055966\n",
      "65 Train Loss 0.008744174 Test MSE 0.06360326168630148 Test RE 0.12054459830366251\n",
      "66 Train Loss 0.008049302 Test MSE 0.061943651777128364 Test RE 0.1189615085118002\n",
      "67 Train Loss 0.007909764 Test MSE 0.06145675514495732 Test RE 0.11849304865397024\n",
      "68 Train Loss 0.0074394266 Test MSE 0.060416933885945 Test RE 0.11748634712538092\n",
      "69 Train Loss 0.0069821393 Test MSE 0.05549304294761287 Test RE 0.1125971324243324\n",
      "70 Train Loss 0.006840154 Test MSE 0.054879794644958735 Test RE 0.1119732539676206\n",
      "71 Train Loss 0.0064318865 Test MSE 0.055039208125657386 Test RE 0.11213576461907371\n",
      "72 Train Loss 0.0062450124 Test MSE 0.05639105885205046 Test RE 0.11350452745865502\n",
      "73 Train Loss 0.0059300954 Test MSE 0.05520315061940398 Test RE 0.11230264699375347\n",
      "74 Train Loss 0.0056379572 Test MSE 0.05402615942091081 Test RE 0.111098989328332\n",
      "75 Train Loss 0.0054525114 Test MSE 0.05315793920300961 Test RE 0.1102026729354785\n",
      "76 Train Loss 0.005077482 Test MSE 0.051376141444239326 Test RE 0.10833999275839767\n",
      "77 Train Loss 0.0049274703 Test MSE 0.04928593355492096 Test RE 0.10611323478346808\n",
      "78 Train Loss 0.0046855267 Test MSE 0.04371777463608096 Test RE 0.09993947962031714\n",
      "79 Train Loss 0.004472256 Test MSE 0.043724504849079165 Test RE 0.09994717200751745\n",
      "80 Train Loss 0.0042832377 Test MSE 0.042967826065743606 Test RE 0.0990785748272693\n",
      "81 Train Loss 0.0040947217 Test MSE 0.04374162638579291 Test RE 0.099966738629163\n",
      "82 Train Loss 0.0037889932 Test MSE 0.042358951721512675 Test RE 0.09837407510083619\n",
      "83 Train Loss 0.0036384277 Test MSE 0.04099988992127454 Test RE 0.09678307259300316\n",
      "84 Train Loss 0.0033645672 Test MSE 0.03995595051080843 Test RE 0.09554298234998207\n",
      "85 Train Loss 0.003164567 Test MSE 0.03655377980622003 Test RE 0.09138485055920026\n",
      "86 Train Loss 0.0029965856 Test MSE 0.0343135482319955 Test RE 0.08854027669128672\n",
      "87 Train Loss 0.0029136748 Test MSE 0.0326616090442984 Test RE 0.08638271471082383\n",
      "88 Train Loss 0.0028496864 Test MSE 0.03183709387254519 Test RE 0.08528541542816895\n",
      "89 Train Loss 0.0026959789 Test MSE 0.02881346952448821 Test RE 0.08113455124201296\n",
      "90 Train Loss 0.0025655455 Test MSE 0.02808743769930545 Test RE 0.08010582939274535\n",
      "91 Train Loss 0.0025071139 Test MSE 0.027042165870853202 Test RE 0.07860113122661676\n",
      "92 Train Loss 0.0023931975 Test MSE 0.026241517069186343 Test RE 0.07742880019499002\n",
      "93 Train Loss 0.0022820947 Test MSE 0.026328067177862725 Test RE 0.07755638341413412\n",
      "94 Train Loss 0.0021763032 Test MSE 0.02625358101251868 Test RE 0.07744659621879847\n",
      "95 Train Loss 0.0020705934 Test MSE 0.025447028729933614 Test RE 0.07624767411329238\n",
      "96 Train Loss 0.0019505187 Test MSE 0.023581001771593436 Test RE 0.07339883820582298\n",
      "97 Train Loss 0.0018833932 Test MSE 0.022361009111871204 Test RE 0.07147493343510958\n",
      "98 Train Loss 0.0018193417 Test MSE 0.021698351613434006 Test RE 0.07040790654463056\n",
      "99 Train Loss 0.0017922714 Test MSE 0.021462686388436365 Test RE 0.0700245134884582\n",
      "Training time: 123.97\n",
      "8\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 62.6905 Test MSE 6.089800135851448 Test RE 1.1795315994459155\n",
      "1 Train Loss 41.314922 Test MSE 9.039477028151902 Test RE 1.437075922308698\n",
      "2 Train Loss 31.998644 Test MSE 7.6187477953113385 Test RE 1.319319127605787\n",
      "3 Train Loss 25.772385 Test MSE 7.531931069239182 Test RE 1.31178067510446\n",
      "4 Train Loss 19.916882 Test MSE 7.435127413269295 Test RE 1.3033236257487535\n",
      "5 Train Loss 17.838768 Test MSE 7.048508245777363 Test RE 1.2689855194973032\n",
      "6 Train Loss 16.477596 Test MSE 6.865025274047464 Test RE 1.2523598344134543\n",
      "7 Train Loss 15.246754 Test MSE 7.059174840399817 Test RE 1.2699453422400444\n",
      "8 Train Loss 14.270096 Test MSE 7.100606213000958 Test RE 1.2736666413551396\n",
      "9 Train Loss 13.255242 Test MSE 7.084907033932842 Test RE 1.2722578471866732\n",
      "10 Train Loss 12.263771 Test MSE 7.156669444358188 Test RE 1.2786849082394194\n",
      "11 Train Loss 11.600109 Test MSE 7.067845135012037 Test RE 1.270724995785376\n",
      "12 Train Loss 10.500917 Test MSE 7.018581515675309 Test RE 1.266288708902374\n",
      "13 Train Loss 9.827466 Test MSE 7.031536904761883 Test RE 1.2674568722532225\n",
      "14 Train Loss 9.256878 Test MSE 6.875150733570426 Test RE 1.2532830681922535\n",
      "15 Train Loss 8.678465 Test MSE 6.702626124699131 Test RE 1.237458256687135\n",
      "16 Train Loss 8.139231 Test MSE 6.475052146680412 Test RE 1.2162691617990675\n",
      "17 Train Loss 7.6990647 Test MSE 6.3653250369663805 Test RE 1.2059195972869614\n",
      "18 Train Loss 7.3244743 Test MSE 6.302822177074805 Test RE 1.1999843649722064\n",
      "19 Train Loss 6.775112 Test MSE 6.183699420313744 Test RE 1.1885904754925636\n",
      "20 Train Loss 6.336326 Test MSE 6.064472804848204 Test RE 1.177076222171244\n",
      "21 Train Loss 5.576975 Test MSE 5.951545329707254 Test RE 1.1660654649198963\n",
      "22 Train Loss 4.87051 Test MSE 5.697002515698907 Test RE 1.140857142995173\n",
      "23 Train Loss 4.1642942 Test MSE 5.4106080571220705 Test RE 1.1118113358772173\n",
      "24 Train Loss 3.5907907 Test MSE 5.270818834629413 Test RE 1.0973548940121067\n",
      "25 Train Loss 3.199872 Test MSE 4.952314396315285 Test RE 1.0636828676024717\n",
      "26 Train Loss 2.9581573 Test MSE 5.042509967577759 Test RE 1.073325488966243\n",
      "27 Train Loss 2.7598128 Test MSE 4.930532905619715 Test RE 1.0613411210879244\n",
      "28 Train Loss 2.6161935 Test MSE 4.992167376483756 Test RE 1.0679542028480156\n",
      "29 Train Loss 2.5080945 Test MSE 4.941429174101317 Test RE 1.062513233284192\n",
      "30 Train Loss 2.410087 Test MSE 5.0366787185310775 Test RE 1.0727047030107466\n",
      "31 Train Loss 2.336678 Test MSE 5.016865195631645 Test RE 1.0705926958573129\n",
      "32 Train Loss 2.2651167 Test MSE 4.971676442757866 Test RE 1.0657601777817356\n",
      "33 Train Loss 2.2253385 Test MSE 4.92975375374672 Test RE 1.0612572580846233\n",
      "34 Train Loss 2.1744397 Test MSE 4.941762945168062 Test RE 1.062549116646525\n",
      "35 Train Loss 2.1123247 Test MSE 4.915134244696739 Test RE 1.0596824755817762\n",
      "36 Train Loss 2.0672443 Test MSE 4.951599495184961 Test RE 1.0636060898104385\n",
      "37 Train Loss 2.0289702 Test MSE 4.950377344368747 Test RE 1.0634748224016652\n",
      "38 Train Loss 1.9934415 Test MSE 4.890522214119696 Test RE 1.0570260202748858\n",
      "39 Train Loss 1.963042 Test MSE 4.855232999253484 Test RE 1.0532054515095655\n",
      "40 Train Loss 1.9191355 Test MSE 4.848627272641369 Test RE 1.052488744889117\n",
      "41 Train Loss 1.8845372 Test MSE 4.8461960669378055 Test RE 1.0522248415885085\n",
      "42 Train Loss 1.8548127 Test MSE 4.807917012474565 Test RE 1.0480609546670883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 1.8270266 Test MSE 4.774129176357773 Test RE 1.0443718159429223\n",
      "44 Train Loss 1.8065183 Test MSE 4.775711243563271 Test RE 1.0445448453560964\n",
      "45 Train Loss 1.7718816 Test MSE 4.762977383270107 Test RE 1.0431513391608236\n",
      "46 Train Loss 1.7551794 Test MSE 4.7481492376937355 Test RE 1.0415262991673342\n",
      "47 Train Loss 1.7364863 Test MSE 4.752688442585723 Test RE 1.0420240269830885\n",
      "48 Train Loss 1.7190524 Test MSE 4.732554320729044 Test RE 1.039814487459554\n",
      "49 Train Loss 1.7010988 Test MSE 4.72245849651207 Test RE 1.0387047919116457\n",
      "50 Train Loss 1.6836684 Test MSE 4.708404652389872 Test RE 1.0371580687327357\n",
      "51 Train Loss 1.6535833 Test MSE 4.741872088814661 Test RE 1.0408376121100826\n",
      "52 Train Loss 1.6280686 Test MSE 4.743485507452081 Test RE 1.0410146691825861\n",
      "53 Train Loss 1.6172447 Test MSE 4.741023145814916 Test RE 1.0407444367417706\n",
      "54 Train Loss 1.5939282 Test MSE 4.735089191663119 Test RE 1.0400929251158348\n",
      "55 Train Loss 1.5705922 Test MSE 4.7128842729550975 Test RE 1.0376513324178471\n",
      "56 Train Loss 1.5462482 Test MSE 4.7310783733966915 Test RE 1.0396523307264645\n",
      "57 Train Loss 1.5241374 Test MSE 4.771659207121034 Test RE 1.0441016200713076\n",
      "58 Train Loss 1.5024927 Test MSE 4.766986498577629 Test RE 1.043590269895587\n",
      "59 Train Loss 1.4754543 Test MSE 4.719752083942576 Test RE 1.0384071115204248\n",
      "60 Train Loss 1.4586425 Test MSE 4.712237780530086 Test RE 1.0375801597882608\n",
      "61 Train Loss 1.4412851 Test MSE 4.764107256123138 Test RE 1.0432750599340566\n",
      "62 Train Loss 1.4202462 Test MSE 4.734545591793525 Test RE 1.0400332207909884\n",
      "63 Train Loss 1.4055678 Test MSE 4.7283590628866765 Test RE 1.0393535041539517\n",
      "64 Train Loss 1.391721 Test MSE 4.706115198655216 Test RE 1.0369058799010984\n",
      "65 Train Loss 1.3800573 Test MSE 4.6705608409340895 Test RE 1.0329815796801545\n",
      "66 Train Loss 1.3687011 Test MSE 4.655301689004364 Test RE 1.0312927762583135\n",
      "67 Train Loss 1.3543744 Test MSE 4.601461213058151 Test RE 1.0253117705168695\n",
      "68 Train Loss 1.343374 Test MSE 4.616628858131144 Test RE 1.027000230970544\n",
      "69 Train Loss 1.3316666 Test MSE 4.6218719314966785 Test RE 1.0275832440052133\n",
      "70 Train Loss 1.32161 Test MSE 4.5999769217692394 Test RE 1.0251463899991105\n",
      "71 Train Loss 1.3169651 Test MSE 4.613885783907086 Test RE 1.0266950779531436\n",
      "72 Train Loss 1.3122243 Test MSE 4.628107481366442 Test RE 1.0282761869238393\n",
      "73 Train Loss 1.3073152 Test MSE 4.622862986910633 Test RE 1.0276934090384997\n",
      "74 Train Loss 1.3019207 Test MSE 4.627648050648599 Test RE 1.0282251473365493\n",
      "75 Train Loss 1.2956098 Test MSE 4.637411325979265 Test RE 1.0293092353839606\n",
      "76 Train Loss 1.2882577 Test MSE 4.647771235875059 Test RE 1.030458324959231\n",
      "77 Train Loss 1.2837174 Test MSE 4.641077651686736 Test RE 1.0297160396389957\n",
      "78 Train Loss 1.2776375 Test MSE 4.65183570365795 Test RE 1.0309087934949577\n",
      "79 Train Loss 1.2713236 Test MSE 4.674833036909106 Test RE 1.0334539095763824\n",
      "80 Train Loss 1.2671337 Test MSE 4.682965557360832 Test RE 1.034352437174033\n",
      "81 Train Loss 1.2617102 Test MSE 4.688469792439666 Test RE 1.0349601340422667\n",
      "82 Train Loss 1.2580911 Test MSE 4.665615440888702 Test RE 1.0324345511411\n",
      "83 Train Loss 1.2520726 Test MSE 4.657262845629263 Test RE 1.0315099816975044\n",
      "84 Train Loss 1.2473943 Test MSE 4.651458876868815 Test RE 1.0308670377298368\n",
      "85 Train Loss 1.2432915 Test MSE 4.642434141007745 Test RE 1.0298665108083505\n",
      "86 Train Loss 1.238177 Test MSE 4.62492826244195 Test RE 1.0279229456974528\n",
      "87 Train Loss 1.2336489 Test MSE 4.621885323359677 Test RE 1.027584732714145\n",
      "88 Train Loss 1.2291816 Test MSE 4.633130553181096 Test RE 1.0288340504175861\n",
      "89 Train Loss 1.2247546 Test MSE 4.63471845654658 Test RE 1.0290103404097077\n",
      "90 Train Loss 1.2206929 Test MSE 4.630476443077848 Test RE 1.0285393220483732\n",
      "91 Train Loss 1.2168819 Test MSE 4.648782054747744 Test RE 1.0305703732983504\n",
      "92 Train Loss 1.21386 Test MSE 4.634724144719109 Test RE 1.0290109718597742\n",
      "93 Train Loss 1.2114338 Test MSE 4.635294897500867 Test RE 1.0290743297615625\n",
      "94 Train Loss 1.206898 Test MSE 4.6076670439726275 Test RE 1.0260029387430019\n",
      "95 Train Loss 1.2028736 Test MSE 4.589330180465009 Test RE 1.023959341524881\n",
      "96 Train Loss 1.1995691 Test MSE 4.588684191016643 Test RE 1.0238872732510087\n",
      "97 Train Loss 1.1935328 Test MSE 4.587838446343114 Test RE 1.0237929120925418\n",
      "98 Train Loss 1.1882029 Test MSE 4.57359348094857 Test RE 1.0222022683814724\n",
      "99 Train Loss 1.1829371 Test MSE 4.565984377317581 Test RE 1.0213515936540758\n",
      "Training time: 125.50\n",
      "9\n",
      "KG_rowdy_tune47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.39294 Test MSE 8.375177373726245 Test RE 1.3832639765525718\n",
      "1 Train Loss 43.532204 Test MSE 8.8676736198565 Test RE 1.4233539483365985\n",
      "2 Train Loss 36.62951 Test MSE 9.011861374551593 Test RE 1.4348791056560029\n",
      "3 Train Loss 32.29347 Test MSE 9.163830439721199 Test RE 1.4469268730622755\n",
      "4 Train Loss 27.686476 Test MSE 9.238471873702425 Test RE 1.4528076925563937\n",
      "5 Train Loss 23.81221 Test MSE 8.635909137276741 Test RE 1.4046304935325424\n",
      "6 Train Loss 21.292542 Test MSE 8.52155619079558 Test RE 1.3952997496583666\n",
      "7 Train Loss 18.541134 Test MSE 8.205225348740514 Test RE 1.369157206977325\n",
      "8 Train Loss 16.861599 Test MSE 8.397765845592815 Test RE 1.3851281030252256\n",
      "9 Train Loss 15.565721 Test MSE 8.118321583560453 Test RE 1.3618873489764232\n",
      "10 Train Loss 14.473264 Test MSE 8.057128969023102 Test RE 1.356744963179311\n",
      "11 Train Loss 13.682465 Test MSE 8.063473841201743 Test RE 1.3572790665384697\n",
      "12 Train Loss 13.034665 Test MSE 8.075450737224244 Test RE 1.358286694186719\n",
      "13 Train Loss 12.267361 Test MSE 8.200484491735502 Test RE 1.3687616105050537\n",
      "14 Train Loss 11.516499 Test MSE 8.128338527997375 Test RE 1.3627272851789618\n",
      "15 Train Loss 10.269264 Test MSE 7.851944826570206 Test RE 1.3393580118489958\n",
      "16 Train Loss 9.144905 Test MSE 7.465554555329668 Test RE 1.3059877309978332\n",
      "17 Train Loss 7.969781 Test MSE 7.142691158546153 Test RE 1.2774355450058594\n",
      "18 Train Loss 5.6371655 Test MSE 5.9413472533560885 Test RE 1.1650659998668609\n",
      "19 Train Loss 4.492226 Test MSE 6.175435848806193 Test RE 1.1877960250094344\n",
      "20 Train Loss 3.8829272 Test MSE 6.322970653541468 Test RE 1.201900852881026\n",
      "21 Train Loss 3.4881399 Test MSE 6.372354646232126 Test RE 1.2065852981241436\n",
      "22 Train Loss 3.1686044 Test MSE 6.583365382912648 Test RE 1.2263997124944166\n",
      "23 Train Loss 2.9647412 Test MSE 6.730830108534505 Test RE 1.2400590741738007\n",
      "24 Train Loss 2.846047 Test MSE 6.7682199509834815 Test RE 1.2434985757289487\n",
      "25 Train Loss 2.716713 Test MSE 6.777208465487314 Test RE 1.2443240140689384\n",
      "26 Train Loss 2.6153526 Test MSE 6.821836834387748 Test RE 1.24841426969989\n",
      "27 Train Loss 2.5312316 Test MSE 6.848920987009703 Test RE 1.2508900507418494\n",
      "28 Train Loss 2.4583437 Test MSE 6.857946281807551 Test RE 1.251713971374736\n",
      "29 Train Loss 2.3856487 Test MSE 6.923603784718698 Test RE 1.2576916095342603\n",
      "30 Train Loss 2.3248932 Test MSE 6.944204804944162 Test RE 1.2595613356380937\n",
      "31 Train Loss 2.2456725 Test MSE 6.928837095664334 Test RE 1.258166842388802\n",
      "32 Train Loss 2.1726918 Test MSE 6.873189055022694 Test RE 1.2531042565557982\n",
      "33 Train Loss 2.1177492 Test MSE 6.934438403129667 Test RE 1.2586752939168604\n",
      "34 Train Loss 2.0587573 Test MSE 6.934176639404918 Test RE 1.2586515372242937\n",
      "35 Train Loss 1.9840053 Test MSE 6.909314237203578 Test RE 1.2563930714372054\n",
      "36 Train Loss 1.9168284 Test MSE 6.879303678332506 Test RE 1.2536615347741773\n",
      "37 Train Loss 1.8526846 Test MSE 6.908274625764945 Test RE 1.256298546155805\n",
      "38 Train Loss 1.814748 Test MSE 6.888368665549664 Test RE 1.2544872494834005\n",
      "39 Train Loss 1.7561225 Test MSE 6.816897567313071 Test RE 1.247962238362766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 1.715101 Test MSE 6.800372275016469 Test RE 1.2464486866267273\n",
      "41 Train Loss 1.659719 Test MSE 6.741574875033448 Test RE 1.2410484641687567\n",
      "42 Train Loss 1.6015766 Test MSE 6.719010593731093 Test RE 1.2389698075842681\n",
      "43 Train Loss 1.5341784 Test MSE 6.487793175672421 Test RE 1.217465206604997\n",
      "44 Train Loss 1.495799 Test MSE 6.497980012845615 Test RE 1.2184206359008645\n",
      "45 Train Loss 1.4283454 Test MSE 6.230602131087391 Test RE 1.1930896271840217\n",
      "46 Train Loss 1.3822842 Test MSE 6.176610734167066 Test RE 1.1879090095684888\n",
      "47 Train Loss 1.3367394 Test MSE 6.078855188606711 Test RE 1.1784711609526306\n",
      "48 Train Loss 1.3025013 Test MSE 5.969832428348136 Test RE 1.1678555545335618\n",
      "49 Train Loss 1.2713112 Test MSE 5.904700626830441 Test RE 1.1614673396535962\n",
      "50 Train Loss 1.2369665 Test MSE 5.900286817886077 Test RE 1.1610331556332552\n",
      "51 Train Loss 1.206307 Test MSE 5.8712600200684335 Test RE 1.1581737501019047\n",
      "52 Train Loss 1.180937 Test MSE 5.843132654930405 Test RE 1.1553961959322991\n",
      "53 Train Loss 1.1558344 Test MSE 5.7788938145320055 Test RE 1.1490274857867135\n",
      "54 Train Loss 1.141856 Test MSE 5.771482202960035 Test RE 1.1482904175871997\n",
      "55 Train Loss 1.1303526 Test MSE 5.791630380226673 Test RE 1.1502930056054415\n",
      "56 Train Loss 1.1170729 Test MSE 5.793058496514403 Test RE 1.1504348180842268\n",
      "57 Train Loss 1.1026657 Test MSE 5.736628598052863 Test RE 1.1448179416344595\n",
      "58 Train Loss 1.0894687 Test MSE 5.727958241743053 Test RE 1.1439524739935563\n",
      "59 Train Loss 1.0800617 Test MSE 5.730587465432401 Test RE 1.1442149900376752\n",
      "60 Train Loss 1.0650411 Test MSE 5.754351076083583 Test RE 1.1465849520523534\n",
      "61 Train Loss 1.0496148 Test MSE 5.791596237516882 Test RE 1.1502896150076676\n",
      "62 Train Loss 1.0356554 Test MSE 5.793055288164124 Test RE 1.1504344995134421\n",
      "63 Train Loss 1.0154928 Test MSE 5.788350744984689 Test RE 1.1499672704105106\n",
      "64 Train Loss 0.99838805 Test MSE 5.8302475766957595 Test RE 1.1541215725753424\n",
      "65 Train Loss 0.9834507 Test MSE 5.843804815784829 Test RE 1.1554626491353264\n",
      "66 Train Loss 0.969925 Test MSE 5.856812155119461 Test RE 1.1567478683755292\n",
      "67 Train Loss 0.9563928 Test MSE 5.866319901173961 Test RE 1.1576863998530817\n",
      "68 Train Loss 0.9446542 Test MSE 5.880345245165571 Test RE 1.1590694864323607\n",
      "69 Train Loss 0.9343727 Test MSE 5.883812606745234 Test RE 1.1594111603113368\n",
      "70 Train Loss 0.9221369 Test MSE 5.904807232410242 Test RE 1.1614778243799293\n",
      "71 Train Loss 0.9136834 Test MSE 5.888402675650677 Test RE 1.15986331098065\n",
      "72 Train Loss 0.90358526 Test MSE 5.8870996226243975 Test RE 1.1597349699769102\n",
      "73 Train Loss 0.8892028 Test MSE 5.8790027559435565 Test RE 1.158937170467084\n",
      "74 Train Loss 0.88006544 Test MSE 5.924787307602203 Test RE 1.1634412090959194\n",
      "75 Train Loss 0.87041974 Test MSE 5.931389492362957 Test RE 1.1640892589536804\n",
      "76 Train Loss 0.8618237 Test MSE 5.9358756357334395 Test RE 1.1645293990118688\n",
      "77 Train Loss 0.8495984 Test MSE 5.975625220774872 Test RE 1.1684220280953366\n",
      "78 Train Loss 0.84244 Test MSE 5.98345895208247 Test RE 1.169187647259749\n",
      "79 Train Loss 0.8339352 Test MSE 5.960563925320682 Test RE 1.166948621427691\n",
      "80 Train Loss 0.8254772 Test MSE 5.965561916487214 Test RE 1.1674377678286179\n",
      "81 Train Loss 0.81721145 Test MSE 5.9971282439447915 Test RE 1.1705223977758927\n",
      "82 Train Loss 0.8134089 Test MSE 6.013140432093469 Test RE 1.1720839894400892\n",
      "83 Train Loss 0.8070627 Test MSE 6.031973691628407 Test RE 1.173918048121176\n",
      "84 Train Loss 0.79913676 Test MSE 6.051967235563239 Test RE 1.1758619694981267\n",
      "85 Train Loss 0.7931564 Test MSE 6.048827293107879 Test RE 1.1755568936609344\n",
      "86 Train Loss 0.7873981 Test MSE 6.069393906839143 Test RE 1.1775537028772665\n",
      "87 Train Loss 0.780339 Test MSE 6.080431481562559 Test RE 1.178623944274836\n",
      "88 Train Loss 0.77759653 Test MSE 6.089596453084711 Test RE 1.1795118736533454\n",
      "89 Train Loss 0.77274555 Test MSE 6.099421342600149 Test RE 1.1804629960698108\n",
      "90 Train Loss 0.7673278 Test MSE 6.111681295661132 Test RE 1.1816487770602402\n",
      "91 Train Loss 0.7630676 Test MSE 6.092021465616102 Test RE 1.1797467041869787\n",
      "92 Train Loss 0.7586603 Test MSE 6.099147500598369 Test RE 1.1804364965086147\n",
      "93 Train Loss 0.7536361 Test MSE 6.117990652748989 Test RE 1.182258553697246\n",
      "94 Train Loss 0.7494855 Test MSE 6.155653189733404 Test RE 1.1858919802563281\n",
      "95 Train Loss 0.7457068 Test MSE 6.145677464874702 Test RE 1.1849306745632413\n",
      "96 Train Loss 0.7418966 Test MSE 6.148933574439596 Test RE 1.185244533630296\n",
      "97 Train Loss 0.7375808 Test MSE 6.161043101520639 Test RE 1.1864110522699471\n",
      "98 Train Loss 0.7331495 Test MSE 6.161239294303286 Test RE 1.186429942206996\n",
      "99 Train Loss 0.7294189 Test MSE 6.190842043131796 Test RE 1.1892767316272523\n",
      "Training time: 124.89\n",
      "0\n",
      "KG_rowdy_tune48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.85661 Test MSE 4.45830066880233 Test RE 1.0092360085078018\n",
      "1 Train Loss 59.37766 Test MSE 5.06785956615737 Test RE 1.076020006261644\n",
      "2 Train Loss 36.82821 Test MSE 6.152209952864189 Test RE 1.1855602625624757\n",
      "3 Train Loss 27.172237 Test MSE 5.221916023489362 Test RE 1.0922523857432427\n",
      "4 Train Loss 21.85707 Test MSE 5.367618209222181 Test RE 1.1073855929251315\n",
      "5 Train Loss 18.817867 Test MSE 5.1111925722322775 Test RE 1.0806104978356712\n",
      "6 Train Loss 16.898819 Test MSE 4.8657075040856785 Test RE 1.0543409131956691\n",
      "7 Train Loss 15.735413 Test MSE 4.987582354763051 Test RE 1.0674636626002039\n",
      "8 Train Loss 14.528727 Test MSE 5.156653230260768 Test RE 1.0854055151015076\n",
      "9 Train Loss 13.7753105 Test MSE 5.269671033190621 Test RE 1.097235404598362\n",
      "10 Train Loss 13.004593 Test MSE 5.394181453229082 Test RE 1.1101223235574798\n",
      "11 Train Loss 11.946777 Test MSE 5.509255093592505 Test RE 1.121900912382565\n",
      "12 Train Loss 11.304468 Test MSE 5.580504563018486 Test RE 1.1291322039204723\n",
      "13 Train Loss 10.674364 Test MSE 5.589423591063925 Test RE 1.1300341600966342\n",
      "14 Train Loss 9.991737 Test MSE 5.646298637363922 Test RE 1.1357689263339081\n",
      "15 Train Loss 9.345549 Test MSE 5.478451456825329 Test RE 1.1187601002735434\n",
      "16 Train Loss 8.50806 Test MSE 5.176820780748358 Test RE 1.0875259417143401\n",
      "17 Train Loss 7.814732 Test MSE 5.09099067445466 Test RE 1.0784728365862588\n",
      "18 Train Loss 7.024978 Test MSE 5.069954519047078 Test RE 1.0762423859742853\n",
      "19 Train Loss 6.1533995 Test MSE 5.002584970405786 Test RE 1.0690679190233607\n",
      "20 Train Loss 5.691397 Test MSE 4.894843844437766 Test RE 1.0574929506729869\n",
      "21 Train Loss 4.991789 Test MSE 4.985800869437815 Test RE 1.0672730050273693\n",
      "22 Train Loss 4.356221 Test MSE 4.810047747909912 Test RE 1.0482931647122111\n",
      "23 Train Loss 3.9665096 Test MSE 4.733033345985869 Test RE 1.0398671107116642\n",
      "24 Train Loss 3.7003546 Test MSE 4.702380723834466 Test RE 1.03649438684959\n",
      "25 Train Loss 3.4072866 Test MSE 4.714138365820397 Test RE 1.0377893821236612\n",
      "26 Train Loss 3.1490166 Test MSE 4.73757302967804 Test RE 1.0403656848824174\n",
      "27 Train Loss 3.026013 Test MSE 4.743586476253516 Test RE 1.0410257485296115\n",
      "28 Train Loss 2.8793821 Test MSE 4.684479356277373 Test RE 1.0345196042246025\n",
      "29 Train Loss 2.7798276 Test MSE 4.558558217084979 Test RE 1.0205206877160493\n",
      "30 Train Loss 2.6461542 Test MSE 4.508792889714055 Test RE 1.0149349396138618\n",
      "31 Train Loss 2.5277927 Test MSE 4.546728125626834 Test RE 1.0191956310470613\n",
      "32 Train Loss 2.4325643 Test MSE 4.431955268198044 Test RE 1.0062496550119373\n",
      "33 Train Loss 2.3051672 Test MSE 4.317950781227749 Test RE 0.9932233114446399\n",
      "34 Train Loss 2.1773758 Test MSE 4.363999806372339 Test RE 0.9985054084828575\n",
      "35 Train Loss 2.105841 Test MSE 4.304707376868949 Test RE 0.9916990051414186\n",
      "36 Train Loss 2.0326006 Test MSE 4.271873422878736 Test RE 0.9879096967496848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 1.9588305 Test MSE 4.213323945747544 Test RE 0.9811162888183408\n",
      "38 Train Loss 1.9065967 Test MSE 4.184597610473789 Test RE 0.9777659555041776\n",
      "39 Train Loss 1.8504283 Test MSE 4.16370907236102 Test RE 0.9753225122826182\n",
      "40 Train Loss 1.7871332 Test MSE 4.065383767440415 Test RE 0.9637376697743553\n",
      "41 Train Loss 1.7579031 Test MSE 4.074952478929567 Test RE 0.9648711799559173\n",
      "42 Train Loss 1.6979483 Test MSE 4.026820615137473 Test RE 0.9591558985391403\n",
      "43 Train Loss 1.6403056 Test MSE 3.902046517410229 Test RE 0.9441788797235772\n",
      "44 Train Loss 1.5607816 Test MSE 3.747010807745169 Test RE 0.9252317620885413\n",
      "45 Train Loss 1.4897842 Test MSE 3.6325258400588734 Test RE 0.9109874969696747\n",
      "46 Train Loss 1.43965 Test MSE 3.5677055288786916 Test RE 0.9028228887879104\n",
      "47 Train Loss 1.383263 Test MSE 3.506150457133531 Test RE 0.8950006168835413\n",
      "48 Train Loss 1.2881758 Test MSE 3.5224900278630478 Test RE 0.8970836603558722\n",
      "49 Train Loss 1.2294205 Test MSE 3.4923988933916563 Test RE 0.8932437399392449\n",
      "50 Train Loss 1.1646435 Test MSE 3.4808007734987054 Test RE 0.8917592927350151\n",
      "51 Train Loss 1.1174966 Test MSE 3.433624185061726 Test RE 0.8856955036404179\n",
      "52 Train Loss 1.0853817 Test MSE 3.4106676328065664 Test RE 0.8827297431316808\n",
      "53 Train Loss 1.0363084 Test MSE 3.3669279100883234 Test RE 0.8770512445091319\n",
      "54 Train Loss 0.98672295 Test MSE 3.306140291757262 Test RE 0.8690978978262139\n",
      "55 Train Loss 0.9323318 Test MSE 3.3315010351603944 Test RE 0.8724248682825828\n",
      "56 Train Loss 0.90436554 Test MSE 3.3135729416412167 Test RE 0.8700742741026652\n",
      "57 Train Loss 0.86053836 Test MSE 3.263163943223787 Test RE 0.8634307412563536\n",
      "58 Train Loss 0.82983416 Test MSE 3.2470177336242414 Test RE 0.8612919547863596\n",
      "59 Train Loss 0.8012694 Test MSE 3.209680618686098 Test RE 0.8563256841136302\n",
      "60 Train Loss 0.7593153 Test MSE 3.2107793880085116 Test RE 0.8564722444715517\n",
      "61 Train Loss 0.7405647 Test MSE 3.181523223561521 Test RE 0.8525612885169618\n",
      "62 Train Loss 0.7181454 Test MSE 3.1948784388746287 Test RE 0.854348830956511\n",
      "63 Train Loss 0.69691694 Test MSE 3.1760231607475573 Test RE 0.8518240364755295\n",
      "64 Train Loss 0.6717956 Test MSE 3.2023532216703665 Test RE 0.8553476703790999\n",
      "65 Train Loss 0.65038455 Test MSE 3.1818018040191993 Test RE 0.8525986136751252\n",
      "66 Train Loss 0.6175114 Test MSE 3.2003928878802084 Test RE 0.8550858279911712\n",
      "67 Train Loss 0.6031745 Test MSE 3.2013345346570485 Test RE 0.8552116140467267\n",
      "68 Train Loss 0.57798094 Test MSE 3.186491952323357 Test RE 0.8532267705585901\n",
      "69 Train Loss 0.5660528 Test MSE 3.210638637665783 Test RE 0.8564534717580571\n",
      "70 Train Loss 0.5459583 Test MSE 3.222881928633012 Test RE 0.8580848966449651\n",
      "71 Train Loss 0.52824926 Test MSE 3.1951684863107404 Test RE 0.8543876111587607\n",
      "72 Train Loss 0.5038283 Test MSE 3.21152115973604 Test RE 0.8565711721976292\n",
      "73 Train Loss 0.4930635 Test MSE 3.2259105370402246 Test RE 0.8584879819796326\n",
      "74 Train Loss 0.48256612 Test MSE 3.238253556893017 Test RE 0.8601287927633181\n",
      "75 Train Loss 0.47041944 Test MSE 3.239755162022916 Test RE 0.8603281940904873\n",
      "76 Train Loss 0.4578176 Test MSE 3.2602742757413896 Test RE 0.8630483546543989\n",
      "77 Train Loss 0.4508053 Test MSE 3.2716043950698346 Test RE 0.8645466887250891\n",
      "78 Train Loss 0.4414289 Test MSE 3.274513698150068 Test RE 0.8649310061909381\n",
      "79 Train Loss 0.43406063 Test MSE 3.282149782592688 Test RE 0.8659389177162705\n",
      "80 Train Loss 0.42563507 Test MSE 3.3042410617580287 Test RE 0.8688482329944667\n",
      "81 Train Loss 0.41780668 Test MSE 3.3049282159894116 Test RE 0.8689385716973449\n",
      "82 Train Loss 0.4095712 Test MSE 3.2962860591058614 Test RE 0.8678017211209007\n",
      "83 Train Loss 0.4015597 Test MSE 3.3063342285013193 Test RE 0.869123387903767\n",
      "84 Train Loss 0.39692003 Test MSE 3.3045501534465145 Test RE 0.8688888697824996\n",
      "85 Train Loss 0.3935973 Test MSE 3.317688814409694 Test RE 0.8706144770370978\n",
      "86 Train Loss 0.38630015 Test MSE 3.3340588672105858 Test RE 0.8727597155641146\n",
      "87 Train Loss 0.38309187 Test MSE 3.3411791532380537 Test RE 0.8736911605005779\n",
      "88 Train Loss 0.37822837 Test MSE 3.338651417363113 Test RE 0.8733606067882521\n",
      "89 Train Loss 0.37540597 Test MSE 3.3554761059875338 Test RE 0.8755584335139052\n",
      "90 Train Loss 0.37248102 Test MSE 3.3576231452987804 Test RE 0.8758385066988558\n",
      "91 Train Loss 0.3670545 Test MSE 3.370320044611222 Test RE 0.8774929419443476\n",
      "92 Train Loss 0.36109126 Test MSE 3.3944613400553685 Test RE 0.8806300352916129\n",
      "93 Train Loss 0.35896 Test MSE 3.401550060330218 Test RE 0.8815490742280812\n",
      "94 Train Loss 0.35656488 Test MSE 3.416489132782156 Test RE 0.8834827658247139\n",
      "95 Train Loss 0.35160047 Test MSE 3.415907979596592 Test RE 0.8834076213357445\n",
      "96 Train Loss 0.34786227 Test MSE 3.4440732786754698 Test RE 0.8870421398057613\n",
      "97 Train Loss 0.34477356 Test MSE 3.4512332418633975 Test RE 0.8879637072452372\n",
      "98 Train Loss 0.34187326 Test MSE 3.446410272058572 Test RE 0.8873430422401288\n",
      "99 Train Loss 0.33924663 Test MSE 3.4526579572523883 Test RE 0.8881469700001371\n",
      "Training time: 125.83\n",
      "1\n",
      "KG_rowdy_tune48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.42\n",
      "0\n",
      "KG_rowdy_tune49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 75.0773 Test MSE 4.416933239674906 Test RE 1.0045428754270005\n",
      "1 Train Loss 69.82911 Test MSE 4.628894345852689 Test RE 1.028363596262172\n",
      "2 Train Loss 47.377678 Test MSE 6.167385437024886 Test RE 1.187021556149182\n",
      "3 Train Loss 32.361217 Test MSE 5.755361561698982 Test RE 1.1466856199405373\n",
      "4 Train Loss 24.162409 Test MSE 5.015263515842665 Test RE 1.0704217839930028\n",
      "5 Train Loss 19.08457 Test MSE 5.336640635489924 Test RE 1.1041854998115523\n",
      "6 Train Loss 16.67757 Test MSE 5.08909753077912 Test RE 1.0782722966517457\n",
      "7 Train Loss 14.784075 Test MSE 5.222990876048844 Test RE 1.0923647917892498\n",
      "8 Train Loss 13.302984 Test MSE 5.245512216767041 Test RE 1.0947173764542084\n",
      "9 Train Loss 11.8177185 Test MSE 5.391442645498441 Test RE 1.1098404645158484\n",
      "10 Train Loss 10.610556 Test MSE 5.377067524867652 Test RE 1.108359901673426\n",
      "11 Train Loss 9.701435 Test MSE 5.176978634109683 Test RE 1.0875425221914388\n",
      "12 Train Loss 8.683455 Test MSE 5.220453908888368 Test RE 1.0920994619928577\n",
      "13 Train Loss 7.9372044 Test MSE 5.104333513694806 Test RE 1.0798851818860713\n",
      "14 Train Loss 7.209839 Test MSE 4.950263660043556 Test RE 1.063462611099046\n",
      "15 Train Loss 6.5968523 Test MSE 4.873608737556835 Test RE 1.0551966175837315\n",
      "16 Train Loss 6.1425047 Test MSE 4.880605742161806 Test RE 1.0559538149587362\n",
      "17 Train Loss 5.814676 Test MSE 4.813822405415392 Test RE 1.0487044050861005\n",
      "18 Train Loss 5.5573077 Test MSE 4.7967970502769965 Test RE 1.0468482522980787\n",
      "19 Train Loss 5.235531 Test MSE 4.698614167024458 Test RE 1.0360791932165674\n",
      "20 Train Loss 5.066646 Test MSE 4.621892272302597 Test RE 1.0275855051938227\n",
      "21 Train Loss 4.9415073 Test MSE 4.623482286924381 Test RE 1.0277622440039869\n",
      "22 Train Loss 4.790054 Test MSE 4.671621517625323 Test RE 1.0330988672311354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Train Loss 4.518821 Test MSE 4.782624064262328 Test RE 1.0453005589815754\n",
      "24 Train Loss 4.12759 Test MSE 4.805431464621948 Test RE 1.0477900117189376\n",
      "25 Train Loss 3.854932 Test MSE 4.715492267966365 Test RE 1.0379383981572574\n",
      "26 Train Loss 3.6664243 Test MSE 4.641627509785278 Test RE 1.0297770363488994\n",
      "27 Train Loss 3.4590049 Test MSE 4.608152491416156 Test RE 1.0260569853332684\n",
      "28 Train Loss 3.3009686 Test MSE 4.548599439822037 Test RE 1.0194053465829076\n",
      "29 Train Loss 3.1537948 Test MSE 4.519625208522189 Test RE 1.0161533925044735\n",
      "30 Train Loss 3.0121942 Test MSE 4.531265020305982 Test RE 1.0174610483549633\n",
      "31 Train Loss 2.7728019 Test MSE 4.554380986076562 Test RE 1.0200530039118807\n",
      "32 Train Loss 2.66128 Test MSE 4.425060094715923 Test RE 1.0054665958165097\n",
      "33 Train Loss 2.429375 Test MSE 4.257697786949601 Test RE 0.9862692121281877\n",
      "34 Train Loss 2.2926133 Test MSE 4.314602963396676 Test RE 0.9928382010478887\n",
      "35 Train Loss 2.098805 Test MSE 4.196134483596751 Test RE 0.9791128708558978\n",
      "36 Train Loss 2.002482 Test MSE 4.154425005764945 Test RE 0.9742345385279599\n",
      "37 Train Loss 1.9131193 Test MSE 4.126019463554499 Test RE 0.9708982011550538\n",
      "38 Train Loss 1.8512471 Test MSE 4.0893398554743445 Test RE 0.9665730075753256\n",
      "39 Train Loss 1.7585626 Test MSE 4.053890558915601 Test RE 0.9623744186958328\n",
      "40 Train Loss 1.6841097 Test MSE 4.04655802270338 Test RE 0.9615036700884237\n",
      "41 Train Loss 1.6289736 Test MSE 4.005789325761774 Test RE 0.9566478785449255\n",
      "42 Train Loss 1.535407 Test MSE 3.7389844090185926 Test RE 0.9242402703895238\n",
      "43 Train Loss 1.481242 Test MSE 3.6861791839836924 Test RE 0.9176905962632875\n",
      "44 Train Loss 1.4057766 Test MSE 3.5948886869285164 Test RE 0.9062557684582346\n",
      "45 Train Loss 1.348169 Test MSE 3.4386445176310514 Test RE 0.8863427587882238\n",
      "46 Train Loss 1.2601998 Test MSE 3.326585970680222 Test RE 0.8717810733133917\n",
      "47 Train Loss 1.2043976 Test MSE 3.2381248632183723 Test RE 0.8601117011068329\n",
      "48 Train Loss 1.1556067 Test MSE 3.1980792911553633 Test RE 0.8547766969708044\n",
      "49 Train Loss 1.0977092 Test MSE 3.1013206578913546 Test RE 0.8417466492775268\n",
      "50 Train Loss 1.0297139 Test MSE 3.139173997288424 Test RE 0.8468680617027268\n",
      "51 Train Loss 1.0013695 Test MSE 3.1070065393456 Test RE 0.8425179142535599\n",
      "52 Train Loss 0.9296653 Test MSE 2.9884147320566603 Test RE 0.8262823854287382\n",
      "53 Train Loss 0.8889586 Test MSE 2.9644616318075685 Test RE 0.8229642642529335\n",
      "54 Train Loss 0.8579581 Test MSE 2.9603473847933777 Test RE 0.8223929878658887\n",
      "55 Train Loss 0.81915385 Test MSE 2.9424917391058907 Test RE 0.819909061912782\n",
      "56 Train Loss 0.7696106 Test MSE 2.972324180589507 Test RE 0.8240549027425895\n",
      "57 Train Loss 0.7408056 Test MSE 2.9290556377174015 Test RE 0.8180349723830692\n",
      "58 Train Loss 0.724456 Test MSE 2.949217378162036 Test RE 0.8208455581594314\n",
      "59 Train Loss 0.7056689 Test MSE 2.9305257512211824 Test RE 0.818240235366634\n",
      "60 Train Loss 0.6719686 Test MSE 2.98835321651657 Test RE 0.8262738810086122\n",
      "61 Train Loss 0.661618 Test MSE 2.9682216065815847 Test RE 0.8234860022120883\n",
      "62 Train Loss 0.6457824 Test MSE 2.963872423764124 Test RE 0.8228824751591979\n",
      "63 Train Loss 0.6290001 Test MSE 2.9695581314463824 Test RE 0.8236713801582896\n",
      "64 Train Loss 0.6159046 Test MSE 2.9812324767872718 Test RE 0.8252888584959822\n",
      "65 Train Loss 0.601718 Test MSE 2.968088873914286 Test RE 0.8234675897196896\n",
      "66 Train Loss 0.58887124 Test MSE 2.9844795435470686 Test RE 0.8257381758097749\n",
      "67 Train Loss 0.58033425 Test MSE 2.988499299733789 Test RE 0.8262940766252265\n",
      "68 Train Loss 0.569053 Test MSE 2.984602100277185 Test RE 0.8257551299772217\n",
      "69 Train Loss 0.5589226 Test MSE 3.016145884933747 Test RE 0.8301072981411515\n",
      "70 Train Loss 0.5493357 Test MSE 3.016223544644044 Test RE 0.8301179848717986\n",
      "71 Train Loss 0.5406766 Test MSE 3.027106138529284 Test RE 0.831614177523687\n",
      "72 Train Loss 0.5330733 Test MSE 3.0581315866037806 Test RE 0.8358650077641024\n",
      "73 Train Loss 0.5277056 Test MSE 3.0750402281467153 Test RE 0.838172602963564\n",
      "74 Train Loss 0.5206106 Test MSE 3.06245259576441 Test RE 0.8364553200726311\n",
      "75 Train Loss 0.5082533 Test MSE 3.0671754259862962 Test RE 0.83710005079924\n",
      "76 Train Loss 0.501657 Test MSE 3.084637926168804 Test RE 0.839479620050511\n",
      "77 Train Loss 0.4931403 Test MSE 3.101676107209302 Test RE 0.8417948851313646\n",
      "78 Train Loss 0.48842114 Test MSE 3.1045870372963904 Test RE 0.8421898057025845\n",
      "79 Train Loss 0.4816292 Test MSE 3.138386521495205 Test RE 0.8467618347259128\n",
      "80 Train Loss 0.47571507 Test MSE 3.1211731714648145 Test RE 0.8444364919516921\n",
      "81 Train Loss 0.46932328 Test MSE 3.1492522351882553 Test RE 0.8482263964871948\n",
      "82 Train Loss 0.462742 Test MSE 3.1548873696391166 Test RE 0.8489849469494117\n",
      "83 Train Loss 0.4589968 Test MSE 3.153199848986197 Test RE 0.8487578594028204\n",
      "84 Train Loss 0.45300865 Test MSE 3.185840311694916 Test RE 0.8531395232556492\n",
      "85 Train Loss 0.4476754 Test MSE 3.1926493446665125 Test RE 0.8540507356820849\n",
      "86 Train Loss 0.44543397 Test MSE 3.1945286391445973 Test RE 0.8543020593536615\n",
      "87 Train Loss 0.43945628 Test MSE 3.2150038682059403 Test RE 0.8570354972312929\n",
      "88 Train Loss 0.43464476 Test MSE 3.219300704656704 Test RE 0.8576080178116814\n",
      "89 Train Loss 0.43091303 Test MSE 3.223915126973129 Test RE 0.8582224289634202\n",
      "90 Train Loss 0.42767343 Test MSE 3.2348484458839692 Test RE 0.8596764494998826\n",
      "91 Train Loss 0.4213655 Test MSE 3.243804645835536 Test RE 0.8608657033996138\n",
      "92 Train Loss 0.41853335 Test MSE 3.251258654632268 Test RE 0.8618542367843259\n",
      "93 Train Loss 0.41722825 Test MSE 3.2364674037922723 Test RE 0.85989154549524\n",
      "94 Train Loss 0.41378206 Test MSE 3.2366824408714026 Test RE 0.8599201114395129\n",
      "95 Train Loss 0.41039225 Test MSE 3.2322544336610615 Test RE 0.8593316947928689\n",
      "96 Train Loss 0.40489805 Test MSE 3.2589212786732906 Test RE 0.862869255755438\n",
      "97 Train Loss 0.40246245 Test MSE 3.263517301433317 Test RE 0.8634774891499531\n",
      "98 Train Loss 0.3983856 Test MSE 3.2621380264234836 Test RE 0.8632950021772361\n",
      "99 Train Loss 0.393722 Test MSE 3.2622881191485287 Test RE 0.8633148622824695\n",
      "Training time: 124.54\n",
      "1\n",
      "KG_rowdy_tune49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 65.35905 Test MSE 6.255828516622167 Test RE 1.1955024707072062\n",
      "1 Train Loss 50.177525 Test MSE 6.571412348912182 Test RE 1.225285855324161\n",
      "2 Train Loss 43.02716 Test MSE 6.559942240160566 Test RE 1.2242160472408303\n",
      "3 Train Loss 36.00685 Test MSE 6.721263810827148 Test RE 1.239177534146542\n",
      "4 Train Loss 27.78095 Test MSE 6.630493731573263 Test RE 1.2307815991501245\n",
      "5 Train Loss 22.838913 Test MSE 6.545018701448109 Test RE 1.2228227393910331\n",
      "6 Train Loss 19.318691 Test MSE 5.815652679238987 Test RE 1.1526761073012681\n",
      "7 Train Loss 17.28584 Test MSE 5.794994691453542 Test RE 1.1506270550507056\n",
      "8 Train Loss 16.12164 Test MSE 5.7371140945290735 Test RE 1.14486638413932\n",
      "9 Train Loss 15.341957 Test MSE 5.975592673724406 Test RE 1.16841884610675\n",
      "10 Train Loss 14.563036 Test MSE 6.205835566716183 Test RE 1.1907160079981276\n",
      "11 Train Loss 14.124234 Test MSE 6.117702072404387 Test RE 1.1822306703100733\n",
      "12 Train Loss 13.576603 Test MSE 6.146706111646115 Test RE 1.1850298356501165\n",
      "13 Train Loss 13.271598 Test MSE 6.246182138127338 Test RE 1.1945803931307746\n",
      "14 Train Loss 12.986132 Test MSE 6.128884834524335 Test RE 1.1833106974276533\n",
      "15 Train Loss 12.756998 Test MSE 6.054425601720477 Test RE 1.176100768359817\n",
      "16 Train Loss 12.574301 Test MSE 6.011587291728767 Test RE 1.1719326102614778\n",
      "17 Train Loss 12.249299 Test MSE 6.084512731153843 Test RE 1.1790194303190569\n",
      "18 Train Loss 11.846692 Test MSE 5.9414895038103985 Test RE 1.1650799470549924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Train Loss 10.888174 Test MSE 5.026108724435275 Test RE 1.071578520658479\n",
      "20 Train Loss 9.75895 Test MSE 4.577429727797275 Test RE 1.0226308808377267\n",
      "21 Train Loss 9.107599 Test MSE 4.179493349477618 Test RE 0.9771694470789193\n",
      "22 Train Loss 8.673763 Test MSE 3.845573877626767 Test RE 0.9373216315265528\n",
      "23 Train Loss 7.928299 Test MSE 3.6617920670528417 Test RE 0.9146499185089758\n",
      "24 Train Loss 7.576201 Test MSE 3.5521851419637183 Test RE 0.900856998841261\n",
      "25 Train Loss 7.408738 Test MSE 3.4788429497429743 Test RE 0.8915084663860282\n",
      "26 Train Loss 7.138489 Test MSE 3.445046156773674 Test RE 0.8871674163119643\n",
      "27 Train Loss 6.4592614 Test MSE 3.002870842379418 Test RE 0.828278497045214\n",
      "28 Train Loss 4.92985 Test MSE 2.4889856039668525 Test RE 0.7540831778702604\n",
      "29 Train Loss 3.7700698 Test MSE 2.100693280802008 Test RE 0.6927704959259708\n",
      "30 Train Loss 3.454919 Test MSE 2.13799494576484 Test RE 0.6988941372770726\n",
      "31 Train Loss 3.177331 Test MSE 2.300898372585217 Test RE 0.725031338452585\n",
      "32 Train Loss 2.9160883 Test MSE 2.3610216458268263 Test RE 0.734442913281584\n",
      "33 Train Loss 2.816578 Test MSE 2.417087391211774 Test RE 0.7431119353708087\n",
      "34 Train Loss 2.7166088 Test MSE 2.4487698020059643 Test RE 0.7479663168854717\n",
      "35 Train Loss 2.661152 Test MSE 2.4750398618153953 Test RE 0.7519676530666732\n",
      "36 Train Loss 2.547208 Test MSE 2.4823250942830826 Test RE 0.7530735410726797\n",
      "37 Train Loss 2.4570622 Test MSE 2.5864067688600403 Test RE 0.7686992801547011\n",
      "38 Train Loss 2.3440084 Test MSE 2.641601104935935 Test RE 0.77685806556537\n",
      "39 Train Loss 2.2175753 Test MSE 2.675858573590374 Test RE 0.7818791610695198\n",
      "40 Train Loss 2.1729074 Test MSE 2.683753362964371 Test RE 0.7830317303903118\n",
      "41 Train Loss 2.0345335 Test MSE 2.7853539013331394 Test RE 0.7977159066378395\n",
      "42 Train Loss 1.9749037 Test MSE 2.7352661798635483 Test RE 0.790510891848449\n",
      "43 Train Loss 1.8858459 Test MSE 2.7989186069759313 Test RE 0.7996559902847616\n",
      "44 Train Loss 1.8287512 Test MSE 2.7779629198850926 Test RE 0.796656827595762\n",
      "45 Train Loss 1.7630708 Test MSE 2.789610007346363 Test RE 0.798325141155041\n",
      "46 Train Loss 1.7128402 Test MSE 2.8998327866861526 Test RE 0.8139440226800195\n",
      "47 Train Loss 1.6312042 Test MSE 2.9853383107475797 Test RE 0.8258569680225357\n",
      "48 Train Loss 1.6022661 Test MSE 3.024441748208516 Test RE 0.831248112965562\n",
      "49 Train Loss 1.5609478 Test MSE 3.020885746065882 Test RE 0.830759297229065\n",
      "50 Train Loss 1.5229491 Test MSE 2.991390357664058 Test RE 0.8266936562033355\n",
      "51 Train Loss 1.4814543 Test MSE 2.989139653395399 Test RE 0.8263825979938961\n",
      "52 Train Loss 1.4577307 Test MSE 3.000042899845615 Test RE 0.8278883910694375\n",
      "53 Train Loss 1.3855067 Test MSE 2.961195797276719 Test RE 0.822510825133396\n",
      "54 Train Loss 1.370548 Test MSE 2.974530631805602 Test RE 0.8243607071439902\n",
      "55 Train Loss 1.34258 Test MSE 2.9909336348913027 Test RE 0.8266305443746224\n",
      "56 Train Loss 1.2921556 Test MSE 3.017474535319918 Test RE 0.830290114388814\n",
      "57 Train Loss 1.2856847 Test MSE 3.020217928550541 Test RE 0.8306674655079289\n",
      "58 Train Loss 1.2470741 Test MSE 3.0243036646386052 Test RE 0.8312291370641197\n",
      "59 Train Loss 1.2116853 Test MSE 3.021311152062119 Test RE 0.8308177896010238\n",
      "60 Train Loss 1.1748896 Test MSE 3.012240209284386 Test RE 0.8295696616604569\n",
      "61 Train Loss 1.1473068 Test MSE 3.0220818873704047 Test RE 0.8309237534922815\n",
      "62 Train Loss 1.1408437 Test MSE 3.0349896924909134 Test RE 0.8326963682304634\n",
      "63 Train Loss 1.0961342 Test MSE 3.0382706834710302 Test RE 0.8331463419650714\n",
      "64 Train Loss 1.0874223 Test MSE 3.0213333201236554 Test RE 0.8308208375469611\n",
      "65 Train Loss 1.0695766 Test MSE 3.016723919000933 Test RE 0.8301868379460535\n",
      "66 Train Loss 1.0418663 Test MSE 2.9981651873209882 Test RE 0.8276292648213821\n",
      "67 Train Loss 1.0336558 Test MSE 2.985591192796067 Test RE 0.8258919456293566\n",
      "68 Train Loss 1.0230694 Test MSE 2.9772413584358297 Test RE 0.8247362466696707\n",
      "69 Train Loss 1.0090876 Test MSE 2.968166762541675 Test RE 0.823478394372483\n",
      "70 Train Loss 0.99666876 Test MSE 2.976593856248107 Test RE 0.824646558347834\n",
      "71 Train Loss 0.9895834 Test MSE 2.999972357247993 Test RE 0.8278786575851323\n",
      "72 Train Loss 0.96719056 Test MSE 3.0005498856536326 Test RE 0.8279583417247548\n",
      "73 Train Loss 0.961669 Test MSE 2.972910905730346 Test RE 0.8241362313329301\n",
      "74 Train Loss 0.9450409 Test MSE 2.971885079056303 Test RE 0.8239940316676269\n",
      "75 Train Loss 0.911646 Test MSE 2.994175042891064 Test RE 0.82707835125042\n",
      "76 Train Loss 0.90584093 Test MSE 3.003263539248477 Test RE 0.8283326538432115\n",
      "77 Train Loss 0.89348257 Test MSE 3.011605459477091 Test RE 0.8294822521430647\n",
      "78 Train Loss 0.87098235 Test MSE 3.0034553422873205 Test RE 0.8283591040999947\n",
      "79 Train Loss 0.85645753 Test MSE 2.9802215461047634 Test RE 0.825148919632488\n",
      "80 Train Loss 0.85001373 Test MSE 2.969816189137595 Test RE 0.8237071683307494\n",
      "81 Train Loss 0.8382642 Test MSE 2.9779930056713866 Test RE 0.824840348340286\n",
      "82 Train Loss 0.81714684 Test MSE 2.9970868423719645 Test RE 0.8274804154344523\n",
      "83 Train Loss 0.8043062 Test MSE 2.9699437782552582 Test RE 0.8237248621769956\n",
      "84 Train Loss 0.7886536 Test MSE 2.9672027228249895 Test RE 0.823344653512803\n",
      "85 Train Loss 0.7830505 Test MSE 2.9844458966778267 Test RE 0.8257335211317425\n",
      "86 Train Loss 0.77918035 Test MSE 2.9758509589413626 Test RE 0.8245436444189564\n",
      "87 Train Loss 0.77124226 Test MSE 2.9885499001151623 Test RE 0.8263010718784007\n",
      "88 Train Loss 0.76132274 Test MSE 2.999929661445811 Test RE 0.8278727663526554\n",
      "89 Train Loss 0.75248104 Test MSE 3.0167428532356158 Test RE 0.8301894432437505\n",
      "90 Train Loss 0.74192536 Test MSE 3.029582031757458 Test RE 0.8319541998045359\n",
      "91 Train Loss 0.7362119 Test MSE 3.013085063006377 Test RE 0.829685989680631\n",
      "92 Train Loss 0.7247874 Test MSE 3.018694676778196 Test RE 0.8304579648526371\n",
      "93 Train Loss 0.7154457 Test MSE 3.001853217685937 Test RE 0.8281381400139998\n",
      "94 Train Loss 0.7071962 Test MSE 3.002749676979749 Test RE 0.8282617864184866\n",
      "95 Train Loss 0.70078593 Test MSE 3.0027248867399132 Test RE 0.8282583674104241\n",
      "96 Train Loss 0.69367874 Test MSE 3.00853579068497 Test RE 0.829059407089175\n",
      "97 Train Loss 0.6830063 Test MSE 3.0433156331481093 Test RE 0.8338377612693675\n",
      "98 Train Loss 0.67485905 Test MSE 3.0521996781167604 Test RE 0.8350539436650353\n",
      "99 Train Loss 0.6691754 Test MSE 3.0488153612552957 Test RE 0.8345908561749232\n",
      "Training time: 125.22\n",
      "2\n",
      "KG_rowdy_tune49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.37577 Test MSE 7.594406347345996 Test RE 1.3172098682820674\n",
      "1 Train Loss 40.99607 Test MSE 7.990962058027362 Test RE 1.3511625348526046\n",
      "2 Train Loss 34.275856 Test MSE 7.494522236839761 Test RE 1.308519010436942\n",
      "3 Train Loss 28.001812 Test MSE 6.7836746049602805 Test RE 1.2449174777651948\n",
      "4 Train Loss 23.915756 Test MSE 6.379497480853571 Test RE 1.2072613453585583\n",
      "5 Train Loss 21.32729 Test MSE 6.3532731531296704 Test RE 1.2047774333996009\n",
      "6 Train Loss 18.687376 Test MSE 6.1568971737078755 Test RE 1.1860118015043204\n",
      "7 Train Loss 16.893564 Test MSE 5.75833062199892 Test RE 1.1469813563370421\n",
      "8 Train Loss 14.790006 Test MSE 5.70998010981976 Test RE 1.1421558223302983\n",
      "9 Train Loss 13.470776 Test MSE 5.981071943007576 Test RE 1.1689544092660586\n",
      "10 Train Loss 12.729437 Test MSE 5.980752564775012 Test RE 1.1689231988425115\n",
      "11 Train Loss 12.054332 Test MSE 6.088822687867694 Test RE 1.1794369348407843\n",
      "12 Train Loss 11.578646 Test MSE 5.953186054012669 Test RE 1.1662261845317636\n",
      "13 Train Loss 10.927571 Test MSE 5.878828063496525 Test RE 1.1589199516391058\n",
      "14 Train Loss 10.282833 Test MSE 5.839853313594857 Test RE 1.1550719289257314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 9.875968 Test MSE 5.923261672045014 Test RE 1.1632914061186255\n",
      "16 Train Loss 9.40635 Test MSE 5.708124246732391 Test RE 1.1419701949679084\n",
      "17 Train Loss 9.142195 Test MSE 5.789730151609381 Test RE 1.1501042850842078\n",
      "18 Train Loss 8.710737 Test MSE 5.603359044104082 Test RE 1.131441973850649\n",
      "19 Train Loss 8.1929455 Test MSE 5.371422535975217 Test RE 1.1077779560055911\n",
      "20 Train Loss 7.9005404 Test MSE 5.394702723426829 Test RE 1.1101759609544313\n",
      "21 Train Loss 7.441717 Test MSE 5.177376698133683 Test RE 1.0875843326045964\n",
      "22 Train Loss 7.0126934 Test MSE 5.049125970208468 Test RE 1.0740293841078952\n",
      "23 Train Loss 6.3837986 Test MSE 4.790154934762143 Test RE 1.0461232168562948\n",
      "24 Train Loss 6.098239 Test MSE 4.595236294743954 Test RE 1.0246180080618026\n",
      "25 Train Loss 5.475528 Test MSE 4.238824621927941 Test RE 0.9840808586984902\n",
      "26 Train Loss 4.939513 Test MSE 3.3334976060912522 Test RE 0.8726862515475073\n",
      "27 Train Loss 4.4987535 Test MSE 3.304674290009099 Test RE 0.8689051896837895\n",
      "28 Train Loss 3.9709346 Test MSE 3.3341046677970096 Test RE 0.8727657101747521\n",
      "29 Train Loss 3.6627762 Test MSE 3.215169633291473 Test RE 0.8570575912531265\n",
      "30 Train Loss 3.4603384 Test MSE 3.1154230379298684 Test RE 0.8436582812016085\n",
      "31 Train Loss 3.1618571 Test MSE 3.0220241265341676 Test RE 0.8309158127610282\n",
      "32 Train Loss 3.0202618 Test MSE 2.9414894159079346 Test RE 0.8197694041086271\n",
      "33 Train Loss 2.7435234 Test MSE 2.720794851693412 Test RE 0.7884169615224728\n",
      "34 Train Loss 2.6028645 Test MSE 2.656575624369577 Test RE 0.7790568526103999\n",
      "35 Train Loss 2.4496944 Test MSE 2.5606444706946068 Test RE 0.7648613260329962\n",
      "36 Train Loss 2.3084476 Test MSE 2.4384584138709986 Test RE 0.7463898707762933\n",
      "37 Train Loss 2.185179 Test MSE 2.3755901976573752 Test RE 0.7367053480231524\n",
      "38 Train Loss 2.0365157 Test MSE 2.214490080006564 Test RE 0.7112870959347461\n",
      "39 Train Loss 1.9174405 Test MSE 2.0437298135007382 Test RE 0.6833131844524306\n",
      "40 Train Loss 1.7726246 Test MSE 1.9618761902798396 Test RE 0.6694896363384161\n",
      "41 Train Loss 1.6748157 Test MSE 1.8809475571208105 Test RE 0.655535784230279\n",
      "42 Train Loss 1.6167707 Test MSE 1.8590845948522103 Test RE 0.6517148790974939\n",
      "43 Train Loss 1.5533258 Test MSE 1.8027306322467775 Test RE 0.6417612336438105\n",
      "44 Train Loss 1.4626215 Test MSE 1.760369130024965 Test RE 0.6341761897618057\n",
      "45 Train Loss 1.3791709 Test MSE 1.7316914137783215 Test RE 0.6289893789836112\n",
      "46 Train Loss 1.343823 Test MSE 1.7350905094106341 Test RE 0.6296063904521272\n",
      "47 Train Loss 1.2900922 Test MSE 1.7228355031187035 Test RE 0.6273789841990611\n",
      "48 Train Loss 1.2563691 Test MSE 1.7122013373368516 Test RE 0.6254397453198004\n",
      "49 Train Loss 1.2006525 Test MSE 1.6589373649130439 Test RE 0.6156346491403567\n",
      "50 Train Loss 1.1782978 Test MSE 1.6432279027482835 Test RE 0.6127128106551395\n",
      "51 Train Loss 1.1573322 Test MSE 1.6418598707101675 Test RE 0.6124577074875491\n",
      "52 Train Loss 1.1097469 Test MSE 1.5709730823858086 Test RE 0.5990904990022325\n",
      "53 Train Loss 1.0851039 Test MSE 1.5070990952798289 Test RE 0.5867849478625622\n",
      "54 Train Loss 1.0574749 Test MSE 1.4283092964925672 Test RE 0.5712407645406126\n",
      "55 Train Loss 0.9979053 Test MSE 1.2123810885817805 Test RE 0.5262930524449224\n",
      "56 Train Loss 0.96831495 Test MSE 1.197563438867797 Test RE 0.5230670037705882\n",
      "57 Train Loss 0.92277265 Test MSE 1.1304169191115647 Test RE 0.5081914859851522\n",
      "58 Train Loss 0.8830487 Test MSE 1.0711377939793043 Test RE 0.4946872668818306\n",
      "59 Train Loss 0.8534771 Test MSE 1.0081022429789417 Test RE 0.4799106091706109\n",
      "60 Train Loss 0.82626206 Test MSE 0.9246981623992282 Test RE 0.45962967220680623\n",
      "61 Train Loss 0.78514946 Test MSE 0.8823819769506965 Test RE 0.4489896963600974\n",
      "62 Train Loss 0.7061714 Test MSE 0.8609190639593562 Test RE 0.44349550525098763\n",
      "63 Train Loss 0.6646021 Test MSE 0.8113228493202435 Test RE 0.4305314817690453\n",
      "64 Train Loss 0.64151824 Test MSE 0.8067781550240748 Test RE 0.42932395893421343\n",
      "65 Train Loss 0.59422624 Test MSE 0.7173891795908574 Test RE 0.4048419156761551\n",
      "66 Train Loss 0.55535465 Test MSE 0.6553584360767143 Test RE 0.3869434570194802\n",
      "67 Train Loss 0.5084042 Test MSE 0.5922521063780856 Test RE 0.3678420440716431\n",
      "68 Train Loss 0.4777301 Test MSE 0.5465931563882551 Test RE 0.35337852623602806\n",
      "69 Train Loss 0.41976196 Test MSE 0.43049571111794566 Test RE 0.3136118575373832\n",
      "70 Train Loss 0.3878376 Test MSE 0.3989936351090591 Test RE 0.3019194169521046\n",
      "71 Train Loss 0.37491313 Test MSE 0.38399772969744356 Test RE 0.2961913618929495\n",
      "72 Train Loss 0.36160585 Test MSE 0.3771873700936585 Test RE 0.2935530732171369\n",
      "73 Train Loss 0.34837532 Test MSE 0.33595904406151045 Test RE 0.27704558185615213\n",
      "74 Train Loss 0.32893068 Test MSE 0.34114832244156995 Test RE 0.2791770284282612\n",
      "75 Train Loss 0.31107467 Test MSE 0.29879484338901635 Test RE 0.26127304654932093\n",
      "76 Train Loss 0.2874245 Test MSE 0.2945953567606713 Test RE 0.25943048586819906\n",
      "77 Train Loss 0.2658363 Test MSE 0.1951545635493079 Test RE 0.2111530777169815\n",
      "78 Train Loss 0.22311847 Test MSE 0.055506766947357296 Test RE 0.11261105477752532\n",
      "79 Train Loss 0.18771482 Test MSE 0.04490768382238176 Test RE 0.10129042384510804\n",
      "80 Train Loss 0.17916538 Test MSE 0.04728749199513215 Test RE 0.1039396381767581\n",
      "81 Train Loss 0.17332867 Test MSE 0.052520075782223376 Test RE 0.10953949447176221\n",
      "82 Train Loss 0.16674957 Test MSE 0.05659411405924309 Test RE 0.11370869967425483\n",
      "83 Train Loss 0.15703394 Test MSE 0.049731616665721845 Test RE 0.10659193569052292\n",
      "84 Train Loss 0.14413902 Test MSE 0.04507382299663249 Test RE 0.10147761643989452\n",
      "85 Train Loss 0.12939371 Test MSE 0.035269876211786545 Test RE 0.08976561858080154\n",
      "86 Train Loss 0.121066585 Test MSE 0.03306435534652035 Test RE 0.08691367027812728\n",
      "87 Train Loss 0.11111893 Test MSE 0.02747790650154384 Test RE 0.07923186542060504\n",
      "88 Train Loss 0.10493289 Test MSE 0.026375748203526336 Test RE 0.07762658027117883\n",
      "89 Train Loss 0.09824515 Test MSE 0.030435659577457193 Test RE 0.08338720537705709\n",
      "90 Train Loss 0.09067044 Test MSE 0.031676383162621315 Test RE 0.08506988664092886\n",
      "91 Train Loss 0.08278886 Test MSE 0.025217601269536954 Test RE 0.0759031757715278\n",
      "92 Train Loss 0.079866715 Test MSE 0.024715014640301118 Test RE 0.07514299420630556\n",
      "93 Train Loss 0.07514592 Test MSE 0.025032874872020706 Test RE 0.07562465815734876\n",
      "94 Train Loss 0.06965346 Test MSE 0.023729799295355954 Test RE 0.07363004955744992\n",
      "95 Train Loss 0.06388278 Test MSE 0.023878886567424252 Test RE 0.07386098525273713\n",
      "96 Train Loss 0.061595984 Test MSE 0.02294899523265249 Test RE 0.07240855790942381\n",
      "97 Train Loss 0.058715615 Test MSE 0.022955250425981802 Test RE 0.07241842541482776\n",
      "98 Train Loss 0.054502994 Test MSE 0.023632665491587553 Test RE 0.0734791991320728\n",
      "99 Train Loss 0.051982913 Test MSE 0.02285697305487941 Test RE 0.07226323812181329\n",
      "Training time: 125.94\n",
      "3\n",
      "KG_rowdy_tune49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 67.60137 Test MSE 5.413767176400342 Test RE 1.1121358679857047\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.38\n",
      "0\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.60702 Test MSE 6.966529808242348 Test RE 1.2615844000078293\n",
      "1 Train Loss 46.338577 Test MSE 8.487069973630529 Test RE 1.3924735409749809\n",
      "2 Train Loss 40.101006 Test MSE 7.7920482696257265 Test RE 1.3342397569730646\n",
      "3 Train Loss 31.106104 Test MSE 7.383098215033288 Test RE 1.2987554504239505\n",
      "4 Train Loss 25.789078 Test MSE 7.220198509406906 Test RE 1.2843477502387972\n",
      "5 Train Loss 21.358494 Test MSE 6.562122310500215 Test RE 1.224419452644079\n",
      "6 Train Loss 17.684475 Test MSE 6.238093731429535 Test RE 1.1938066899417086\n",
      "7 Train Loss 15.099966 Test MSE 5.913058340907866 Test RE 1.162289039177224\n",
      "8 Train Loss 13.2665825 Test MSE 5.939144040919117 Test RE 1.1648499608269474\n",
      "9 Train Loss 11.853788 Test MSE 5.9977991356887 Test RE 1.1705878684328093\n",
      "10 Train Loss 10.721004 Test MSE 5.9215795003545795 Test RE 1.1631262104094797\n",
      "11 Train Loss 9.744745 Test MSE 5.85945716878312 Test RE 1.1570090401933817\n",
      "12 Train Loss 8.67804 Test MSE 5.836056628809733 Test RE 1.1546963923500977\n",
      "13 Train Loss 7.661397 Test MSE 5.818344974980698 Test RE 1.1529428861190743\n",
      "14 Train Loss 6.852466 Test MSE 5.7002281935301795 Test RE 1.1411800774521186\n",
      "15 Train Loss 6.2260666 Test MSE 5.639674672050952 Test RE 1.1351025161560577\n",
      "16 Train Loss 5.4036026 Test MSE 5.47117326305102 Test RE 1.1180167096429452\n",
      "17 Train Loss 4.7276273 Test MSE 5.325593457836339 Test RE 1.1030420414565365\n",
      "18 Train Loss 4.1044726 Test MSE 5.160771527306371 Test RE 1.0858388514148893\n",
      "19 Train Loss 3.5945828 Test MSE 4.923569077797498 Test RE 1.06059134326941\n",
      "20 Train Loss 3.1983402 Test MSE 4.69054399010679 Test RE 1.0351890439654035\n",
      "21 Train Loss 2.7123616 Test MSE 3.9669446732273275 Test RE 0.9519982104295794\n",
      "22 Train Loss 2.425103 Test MSE 3.734332315093332 Test RE 0.9236651154369094\n",
      "23 Train Loss 2.2468553 Test MSE 3.569692527536779 Test RE 0.9030742629762606\n",
      "24 Train Loss 2.070354 Test MSE 3.4328203256372443 Test RE 0.8855918207218556\n",
      "25 Train Loss 1.8997073 Test MSE 3.1547576772052404 Test RE 0.8489674965553415\n",
      "26 Train Loss 1.7528955 Test MSE 2.89677499641473 Test RE 0.8135147692102842\n",
      "27 Train Loss 1.596105 Test MSE 2.5450595777325855 Test RE 0.7625301795008115\n",
      "28 Train Loss 1.4875367 Test MSE 2.4132511966485457 Test RE 0.7425219993219977\n",
      "29 Train Loss 1.3995464 Test MSE 2.2824857468194004 Test RE 0.7221245291794002\n",
      "30 Train Loss 1.3342777 Test MSE 2.21681524705808 Test RE 0.7116604160576505\n",
      "31 Train Loss 1.2840012 Test MSE 2.144714173976009 Test RE 0.6999915078212947\n",
      "32 Train Loss 1.2430352 Test MSE 2.1369014426839548 Test RE 0.6987153855360714\n",
      "33 Train Loss 1.1857028 Test MSE 2.031578349871522 Test RE 0.68127875839756\n",
      "34 Train Loss 1.1276989 Test MSE 1.8591359572647244 Test RE 0.651723881758631\n",
      "35 Train Loss 1.0656599 Test MSE 1.7243041089361246 Test RE 0.6276463272377036\n",
      "36 Train Loss 0.9791443 Test MSE 1.5841222058293305 Test RE 0.6015924832313065\n",
      "37 Train Loss 0.937262 Test MSE 1.5629154681579296 Test RE 0.5975521385083271\n",
      "38 Train Loss 0.9012249 Test MSE 1.5351328709301688 Test RE 0.5922172398209576\n",
      "39 Train Loss 0.83924115 Test MSE 1.38553985449805 Test RE 0.5626231158855804\n",
      "40 Train Loss 0.7607319 Test MSE 1.114140135208066 Test RE 0.5045195154272624\n",
      "41 Train Loss 0.65563947 Test MSE 0.9405404724181659 Test RE 0.46355023383731914\n",
      "42 Train Loss 0.59792894 Test MSE 0.7708351768974839 Test RE 0.419651541717831\n",
      "43 Train Loss 0.506704 Test MSE 0.6285216769021814 Test RE 0.3789380278576483\n",
      "44 Train Loss 0.43440568 Test MSE 0.5468632083571993 Test RE 0.35346581124992543\n",
      "45 Train Loss 0.37021494 Test MSE 0.46041502849161375 Test RE 0.3243267766514585\n",
      "46 Train Loss 0.29759794 Test MSE 0.38191161527018336 Test RE 0.2953857183928706\n",
      "47 Train Loss 0.2571334 Test MSE 0.3247735476906327 Test RE 0.2723945317468325\n",
      "48 Train Loss 0.23268527 Test MSE 0.2938386235854136 Test RE 0.2590970693943944\n",
      "49 Train Loss 0.20017809 Test MSE 0.22303492785116374 Test RE 0.22573271250693128\n",
      "50 Train Loss 0.17117986 Test MSE 0.1628108543342035 Test RE 0.19286336411623625\n",
      "51 Train Loss 0.1520159 Test MSE 0.10929049728649483 Test RE 0.15801534413245544\n",
      "52 Train Loss 0.12291382 Test MSE 0.06571460351584571 Test RE 0.12252903305332148\n",
      "53 Train Loss 0.100573726 Test MSE 0.0382360807390629 Test RE 0.09346408212133504\n",
      "54 Train Loss 0.08495342 Test MSE 0.027674704969249824 Test RE 0.07951509096860576\n",
      "55 Train Loss 0.06860188 Test MSE 0.02078094400208898 Test RE 0.06890340695880397\n",
      "56 Train Loss 0.057126004 Test MSE 0.01851759716627788 Test RE 0.06504297187539029\n",
      "57 Train Loss 0.049031787 Test MSE 0.021592827946603367 Test RE 0.07023649362609537\n",
      "58 Train Loss 0.041277487 Test MSE 0.018673328887072276 Test RE 0.06531590270831332\n",
      "59 Train Loss 0.03652589 Test MSE 0.016784411975169108 Test RE 0.06192430280968584\n",
      "60 Train Loss 0.031870596 Test MSE 0.017965582238993878 Test RE 0.06406616215159482\n",
      "61 Train Loss 0.027912967 Test MSE 0.01611905198106226 Test RE 0.06068450421889368\n",
      "62 Train Loss 0.022929918 Test MSE 0.01547952335708466 Test RE 0.05946848191913566\n",
      "63 Train Loss 0.020514516 Test MSE 0.015872900871390108 Test RE 0.06021937063410381\n",
      "64 Train Loss 0.018810844 Test MSE 0.014781111062110594 Test RE 0.058111435049537946\n",
      "65 Train Loss 0.017412018 Test MSE 0.013652724376179003 Test RE 0.0558492983887335\n",
      "66 Train Loss 0.015696157 Test MSE 0.013461815075400166 Test RE 0.05545744669835113\n",
      "67 Train Loss 0.014707928 Test MSE 0.013097932725733457 Test RE 0.05470278506715663\n",
      "68 Train Loss 0.013949209 Test MSE 0.012449646556050306 Test RE 0.05333184046404948\n",
      "69 Train Loss 0.0128910355 Test MSE 0.011838242445757818 Test RE 0.0520057872852137\n",
      "70 Train Loss 0.01205917 Test MSE 0.011075841992820423 Test RE 0.0503032953007754\n",
      "71 Train Loss 0.010678751 Test MSE 0.010798238715243247 Test RE 0.04966889776004572\n",
      "72 Train Loss 0.0098439595 Test MSE 0.009874121828519895 Test RE 0.0474960289833231\n",
      "73 Train Loss 0.009041734 Test MSE 0.0089953109596684 Test RE 0.04533317646357376\n",
      "74 Train Loss 0.008602139 Test MSE 0.0091687299060901 Test RE 0.04576807537363682\n",
      "75 Train Loss 0.008097927 Test MSE 0.00871590079415213 Test RE 0.04462355843706373\n",
      "76 Train Loss 0.0076587945 Test MSE 0.008174664925016797 Test RE 0.04321584810448722\n",
      "77 Train Loss 0.0071238484 Test MSE 0.008248206136538873 Test RE 0.043409802840899236\n",
      "78 Train Loss 0.006712225 Test MSE 0.008213073221632967 Test RE 0.043317252994794615\n",
      "79 Train Loss 0.006283982 Test MSE 0.007867528919551232 Test RE 0.042396229485053796\n",
      "80 Train Loss 0.0059920084 Test MSE 0.008167556164104736 Test RE 0.04319705357577929\n",
      "81 Train Loss 0.005649573 Test MSE 0.00829426074283745 Test RE 0.04353082542458975\n",
      "82 Train Loss 0.0051481277 Test MSE 0.007357502250554676 Test RE 0.04099899981549632\n",
      "83 Train Loss 0.004843631 Test MSE 0.006795202842254642 Test RE 0.039401184038167066\n",
      "84 Train Loss 0.004607559 Test MSE 0.006799200742865127 Test RE 0.03941277301196224\n",
      "85 Train Loss 0.0043023275 Test MSE 0.006993590528455188 Test RE 0.03997221003592676\n",
      "86 Train Loss 0.0041714245 Test MSE 0.00684640276678864 Test RE 0.03954934384504632\n",
      "87 Train Loss 0.003972949 Test MSE 0.006625251066987367 Test RE 0.03890534139743393\n",
      "88 Train Loss 0.0037558773 Test MSE 0.006485156453954241 Test RE 0.03849180608388854\n",
      "89 Train Loss 0.0036465097 Test MSE 0.006382716773704194 Test RE 0.03818658724886021\n",
      "90 Train Loss 0.0035017852 Test MSE 0.005944074439369586 Test RE 0.03685107658530221\n",
      "91 Train Loss 0.0033415633 Test MSE 0.005537533567351502 Test RE 0.035568556982305065\n",
      "92 Train Loss 0.003255968 Test MSE 0.005549752129461316 Test RE 0.035607776352014904\n",
      "93 Train Loss 0.0031849924 Test MSE 0.005547143584680947 Test RE 0.03559940702360676\n",
      "94 Train Loss 0.0030679002 Test MSE 0.005109469229672936 Test RE 0.034166143004430445\n",
      "95 Train Loss 0.0029755926 Test MSE 0.004492730655117231 Test RE 0.03203784173870155\n",
      "96 Train Loss 0.0029053837 Test MSE 0.004234007543816456 Test RE 0.031101681814955193\n",
      "97 Train Loss 0.0028256923 Test MSE 0.004033936642686321 Test RE 0.03035796086074241\n",
      "98 Train Loss 0.0027474721 Test MSE 0.003964708595483505 Test RE 0.03009634082979282\n",
      "99 Train Loss 0.002625342 Test MSE 0.003839285183569131 Test RE 0.02961646680827738\n",
      "Training time: 194.87\n",
      "1\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.548676 Test MSE 8.256014281633895 Test RE 1.373388093710561\n",
      "1 Train Loss 54.931477 Test MSE 8.226473953464037 Test RE 1.3709288749385267\n",
      "2 Train Loss 51.178524 Test MSE 9.06071262351698 Test RE 1.4387629259342636\n",
      "3 Train Loss 47.978096 Test MSE 8.764428103132591 Test RE 1.415043698420026\n",
      "4 Train Loss 42.829353 Test MSE 9.078907447316624 Test RE 1.4402067918948318\n",
      "5 Train Loss 39.935204 Test MSE 8.934821453263142 Test RE 1.4287327484074162\n",
      "6 Train Loss 37.26381 Test MSE 9.121309595107942 Test RE 1.4435660465601208\n",
      "7 Train Loss 34.361416 Test MSE 9.430584000619984 Test RE 1.4678353889955367\n",
      "8 Train Loss 32.31621 Test MSE 9.139961963274796 Test RE 1.4450412828622206\n",
      "9 Train Loss 30.31955 Test MSE 9.24676508645353 Test RE 1.4534596261629387\n",
      "10 Train Loss 28.602118 Test MSE 9.219793553986525 Test RE 1.4513383079709776\n",
      "11 Train Loss 26.180958 Test MSE 8.95984754617729 Test RE 1.4307322621182166\n",
      "12 Train Loss 23.63874 Test MSE 9.268294727578697 Test RE 1.455150718676131\n",
      "13 Train Loss 21.435558 Test MSE 8.983933433161184 Test RE 1.432654020680243\n",
      "14 Train Loss 19.66195 Test MSE 8.840059400244684 Test RE 1.42113603544054\n",
      "15 Train Loss 17.74528 Test MSE 8.562245293548495 Test RE 1.3986269520956267\n",
      "16 Train Loss 16.274967 Test MSE 8.635942836228345 Test RE 1.4046332340968586\n",
      "17 Train Loss 15.0553255 Test MSE 8.499057274904581 Test RE 1.3934565722235028\n",
      "18 Train Loss 13.688682 Test MSE 8.53857811793643 Test RE 1.3966926197746965\n",
      "19 Train Loss 12.369098 Test MSE 8.367909286896513 Test RE 1.3826636391288325\n",
      "20 Train Loss 11.094469 Test MSE 8.141843682791523 Test RE 1.3638588943484145\n",
      "21 Train Loss 9.856043 Test MSE 7.777913928029365 Test RE 1.3330290893974968\n",
      "22 Train Loss 8.855476 Test MSE 7.40990224923239 Test RE 1.3011108536666574\n",
      "23 Train Loss 7.115074 Test MSE 6.372095483387138 Test RE 1.2065607620401217\n",
      "24 Train Loss 5.624808 Test MSE 5.764268244763059 Test RE 1.147572550935385\n",
      "25 Train Loss 4.6660113 Test MSE 5.521272277462101 Test RE 1.1231238313888574\n",
      "26 Train Loss 3.9939299 Test MSE 5.59369889690588 Test RE 1.1304662545761546\n",
      "27 Train Loss 3.3914328 Test MSE 5.440743903204557 Test RE 1.1149033035543923\n",
      "28 Train Loss 2.8664374 Test MSE 5.355815432499374 Test RE 1.106167415953402\n",
      "29 Train Loss 2.482837 Test MSE 5.373891501207823 Test RE 1.1080325208830228\n",
      "30 Train Loss 2.2179704 Test MSE 5.307480201997323 Test RE 1.1011646262548735\n",
      "31 Train Loss 2.0174913 Test MSE 5.317357303211492 Test RE 1.1021887712928256\n",
      "32 Train Loss 1.8554633 Test MSE 5.297465102135497 Test RE 1.1001251988129532\n",
      "33 Train Loss 1.7684637 Test MSE 5.30341953986531 Test RE 1.1007433045621933\n",
      "34 Train Loss 1.6843106 Test MSE 5.3200913193091965 Test RE 1.1024720900940927\n",
      "35 Train Loss 1.607036 Test MSE 5.338022405074244 Test RE 1.1043284390963108\n",
      "36 Train Loss 1.5280651 Test MSE 5.366610154710839 Test RE 1.1072816029042787\n",
      "37 Train Loss 1.4843537 Test MSE 5.37185510628669 Test RE 1.1078225607825474\n",
      "38 Train Loss 1.4286008 Test MSE 5.428869773016597 Test RE 1.1136860308630372\n",
      "39 Train Loss 1.3954176 Test MSE 5.469306053121974 Test RE 1.1178259141824936\n",
      "40 Train Loss 1.3580511 Test MSE 5.46845570770309 Test RE 1.1177390132954954\n",
      "41 Train Loss 1.3193387 Test MSE 5.500271637090499 Test RE 1.1209858467541176\n",
      "42 Train Loss 1.2918452 Test MSE 5.526238578091513 Test RE 1.1236288342753553\n",
      "43 Train Loss 1.261869 Test MSE 5.521192421412041 Test RE 1.1231157092973634\n",
      "44 Train Loss 1.2141871 Test MSE 5.611711694404981 Test RE 1.1322849521274827\n",
      "45 Train Loss 1.180084 Test MSE 5.669608849967209 Test RE 1.1381109691655507\n",
      "46 Train Loss 1.1572955 Test MSE 5.673193766549131 Test RE 1.1384707283872082\n",
      "47 Train Loss 1.1358154 Test MSE 5.700869440956345 Test RE 1.1412442641989822\n",
      "48 Train Loss 1.116282 Test MSE 5.731834967104341 Test RE 1.1443395263479874\n",
      "49 Train Loss 1.1008433 Test MSE 5.747461205373324 Test RE 1.1458983248316352\n",
      "50 Train Loss 1.0811852 Test MSE 5.800609068227094 Test RE 1.151184302316443\n",
      "51 Train Loss 1.0612345 Test MSE 5.8056919121532635 Test RE 1.1516885604743345\n",
      "52 Train Loss 1.0471905 Test MSE 5.812087465963528 Test RE 1.1523227362864534\n",
      "53 Train Loss 1.0298203 Test MSE 5.83734007091169 Test RE 1.1548233534635712\n",
      "54 Train Loss 1.0190313 Test MSE 5.83380645544834 Test RE 1.1544737662066507\n",
      "55 Train Loss 1.0060596 Test MSE 5.831407929447857 Test RE 1.1542364151699087\n",
      "56 Train Loss 0.99268174 Test MSE 5.832291485645621 Test RE 1.1543238549548742\n",
      "57 Train Loss 0.9798114 Test MSE 5.848210434894854 Test RE 1.1558981162169688\n",
      "58 Train Loss 0.9585224 Test MSE 5.919688281614707 Test RE 1.1629404574571134\n",
      "59 Train Loss 0.9396196 Test MSE 5.927632800048064 Test RE 1.1637205580079504\n",
      "60 Train Loss 0.9280685 Test MSE 5.940563733780398 Test RE 1.1649891753625288\n",
      "61 Train Loss 0.91991717 Test MSE 5.977930390189378 Test RE 1.1686473728014615\n",
      "62 Train Loss 0.9095944 Test MSE 6.0145900906024385 Test RE 1.172225264964355\n",
      "63 Train Loss 0.90090156 Test MSE 6.0272011404867865 Test RE 1.173453549032705\n",
      "64 Train Loss 0.8890524 Test MSE 6.072543809407449 Test RE 1.1778592274787336\n",
      "65 Train Loss 0.8771351 Test MSE 6.0971939242871365 Test RE 1.1802474325889063\n",
      "66 Train Loss 0.8685241 Test MSE 6.08745747239637 Test RE 1.1793047027245633\n",
      "67 Train Loss 0.8606728 Test MSE 6.101262743585552 Test RE 1.1806411721268253\n",
      "68 Train Loss 0.8528631 Test MSE 6.116558153068307 Test RE 1.1821201353631308\n",
      "69 Train Loss 0.8473358 Test MSE 6.11740497072089 Test RE 1.1822019628817904\n",
      "70 Train Loss 0.8423288 Test MSE 6.130619178067209 Test RE 1.1834781114153763\n",
      "71 Train Loss 0.8344699 Test MSE 6.148422313172901 Test RE 1.185195258238813\n",
      "72 Train Loss 0.8277965 Test MSE 6.16800248116412 Test RE 1.1870809351504268\n",
      "73 Train Loss 0.82089144 Test MSE 6.18427271330899 Test RE 1.1886455715406392\n",
      "74 Train Loss 0.8143637 Test MSE 6.18100346009902 Test RE 1.1883313472787345\n",
      "75 Train Loss 0.80790234 Test MSE 6.197592738419051 Test RE 1.1899249679531603\n",
      "76 Train Loss 0.8036412 Test MSE 6.2308614088165735 Test RE 1.1931144512976954\n",
      "77 Train Loss 0.7995144 Test MSE 6.245964365454374 Test RE 1.194559568471241\n",
      "78 Train Loss 0.79373515 Test MSE 6.248347718439284 Test RE 1.1947874584655922\n",
      "79 Train Loss 0.7880057 Test MSE 6.262824918074257 Test RE 1.1961707976850964\n",
      "80 Train Loss 0.78331107 Test MSE 6.26946252850175 Test RE 1.1968045063760513\n",
      "81 Train Loss 0.7785717 Test MSE 6.2647349293265675 Test RE 1.1963531854689693\n",
      "82 Train Loss 0.7742848 Test MSE 6.2753177206292525 Test RE 1.1973632372828378\n",
      "83 Train Loss 0.7706063 Test MSE 6.286525742735719 Test RE 1.1984320347007218\n",
      "84 Train Loss 0.7663096 Test MSE 6.30289853620332 Test RE 1.1999916338971608\n",
      "85 Train Loss 0.7615739 Test MSE 6.316622595886316 Test RE 1.201297366617066\n",
      "86 Train Loss 0.7574701 Test MSE 6.323011751346477 Test RE 1.201904758909484\n",
      "87 Train Loss 0.75286835 Test MSE 6.347250284143797 Test RE 1.2042062367114656\n",
      "88 Train Loss 0.74851894 Test MSE 6.353546618010449 Test RE 1.2048033618276743\n",
      "89 Train Loss 0.74360174 Test MSE 6.36735076624638 Test RE 1.2061114706239164\n",
      "90 Train Loss 0.7389574 Test MSE 6.383051695429758 Test RE 1.2075975997741175\n",
      "91 Train Loss 0.73556983 Test MSE 6.389052917667976 Test RE 1.2081651464061716\n",
      "92 Train Loss 0.7320142 Test MSE 6.391387176150838 Test RE 1.2083858295211687\n",
      "93 Train Loss 0.72685486 Test MSE 6.4126297062400495 Test RE 1.2103922702495526\n",
      "94 Train Loss 0.7229707 Test MSE 6.422670472354519 Test RE 1.2113395034935708\n",
      "95 Train Loss 0.7196598 Test MSE 6.414343137611074 Test RE 1.2105539656587956\n",
      "96 Train Loss 0.7146583 Test MSE 6.41714101795507 Test RE 1.2108179533977126\n",
      "97 Train Loss 0.71116173 Test MSE 6.4370745067580035 Test RE 1.2126970699619342\n",
      "98 Train Loss 0.7071084 Test MSE 6.460178269519272 Test RE 1.2148714094202064\n",
      "99 Train Loss 0.7023556 Test MSE 6.474514511753858 Test RE 1.216218666270922\n",
      "Training time: 195.83\n",
      "2\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 50.447712 Test MSE 8.28165827503894 Test RE 1.3755193793326193\n",
      "1 Train Loss 41.109386 Test MSE 7.79151234732589 Test RE 1.334193872944263\n",
      "2 Train Loss 34.960705 Test MSE 7.266580492626105 Test RE 1.288466420423705\n",
      "3 Train Loss 30.337929 Test MSE 7.187321892240356 Test RE 1.2814203247624392\n",
      "4 Train Loss 26.639425 Test MSE 6.203066791950165 Test RE 1.1904503554354646\n",
      "5 Train Loss 23.387947 Test MSE 6.055875538958339 Test RE 1.1762415885075586\n",
      "6 Train Loss 20.162113 Test MSE 6.000141257585797 Test RE 1.170816401584469\n",
      "7 Train Loss 16.88933 Test MSE 5.617635102362285 Test RE 1.1328823827435364\n",
      "8 Train Loss 14.050349 Test MSE 5.567439047294759 Test RE 1.1278096228202306\n",
      "9 Train Loss 11.950188 Test MSE 5.66644934808742 Test RE 1.1377938075281366\n",
      "10 Train Loss 10.826692 Test MSE 5.561775274478138 Test RE 1.127235814754932\n",
      "11 Train Loss 9.5129795 Test MSE 5.644527653709695 Test RE 1.1355907931815072\n",
      "12 Train Loss 8.910145 Test MSE 5.5959450109178315 Test RE 1.1306931975433152\n",
      "13 Train Loss 7.960376 Test MSE 5.575949838045347 Test RE 1.1286713193889324\n",
      "14 Train Loss 7.2417483 Test MSE 5.385356675426775 Test RE 1.1092138824010054\n",
      "15 Train Loss 6.317074 Test MSE 5.219016249892314 Test RE 1.091949075191879\n",
      "16 Train Loss 5.5495014 Test MSE 5.12121978773974 Test RE 1.0816699575484032\n",
      "17 Train Loss 4.9449053 Test MSE 5.083159683839349 Test RE 1.0776430608671768\n",
      "18 Train Loss 4.3978252 Test MSE 4.981045745824066 Test RE 1.0667639367922586\n",
      "19 Train Loss 4.011118 Test MSE 4.863091316014383 Test RE 1.0540574266734364\n",
      "20 Train Loss 3.6495085 Test MSE 4.678336186288811 Test RE 1.0338410533962135\n",
      "21 Train Loss 3.2858016 Test MSE 4.584582014895515 Test RE 1.0234295053070326\n",
      "22 Train Loss 3.1024253 Test MSE 4.53385675858171 Test RE 1.0177519843044438\n",
      "23 Train Loss 2.915984 Test MSE 4.506620815021947 Test RE 1.0146904417941407\n",
      "24 Train Loss 2.7796278 Test MSE 4.446824774224426 Test RE 1.0079362589396643\n",
      "25 Train Loss 2.6081104 Test MSE 4.366143115259672 Test RE 0.9987505783849925\n",
      "26 Train Loss 2.481683 Test MSE 4.2907618204834135 Test RE 0.9900913449529961\n",
      "27 Train Loss 2.3588767 Test MSE 4.0805014896266245 Test RE 0.9655279065134741\n",
      "28 Train Loss 2.259315 Test MSE 4.003293532748845 Test RE 0.9563498140551959\n",
      "29 Train Loss 2.1469035 Test MSE 3.932472963688965 Test RE 0.9478528778442412\n",
      "30 Train Loss 2.073997 Test MSE 3.865801253803727 Test RE 0.9397835126137724\n",
      "31 Train Loss 1.9844956 Test MSE 3.7371894662170257 Test RE 0.9240183976311598\n",
      "32 Train Loss 1.9032133 Test MSE 3.6002304788197144 Test RE 0.9069288397409233\n",
      "33 Train Loss 1.846272 Test MSE 3.543083079352804 Test RE 0.8997020877250065\n",
      "34 Train Loss 1.7669635 Test MSE 3.3056356848002726 Test RE 0.8690315713031543\n",
      "35 Train Loss 1.6868608 Test MSE 3.011783041781089 Test RE 0.8295067074045632\n",
      "36 Train Loss 1.623875 Test MSE 2.945070833728535 Test RE 0.8202683084419421\n",
      "37 Train Loss 1.5337007 Test MSE 2.779746508972471 Test RE 0.7969125330290125\n",
      "38 Train Loss 1.4704249 Test MSE 2.5770155619958732 Test RE 0.76730244285091\n",
      "39 Train Loss 1.4083667 Test MSE 2.3981099591553563 Test RE 0.7401889657258722\n",
      "40 Train Loss 1.3402442 Test MSE 2.2012114193130277 Test RE 0.7091513579428279\n",
      "41 Train Loss 1.2866055 Test MSE 2.0427535565428996 Test RE 0.6831499610826413\n",
      "42 Train Loss 1.2208555 Test MSE 1.801499034638651 Test RE 0.6415419755283279\n",
      "43 Train Loss 1.1693515 Test MSE 1.5716710202781459 Test RE 0.5992235635132207\n",
      "44 Train Loss 1.011726 Test MSE 1.167176930073447 Test RE 0.5163883166325968\n",
      "45 Train Loss 0.7925081 Test MSE 1.0962538149735035 Test RE 0.5004533712142113\n",
      "46 Train Loss 0.648494 Test MSE 1.0462355112968387 Test RE 0.4889030973453222\n",
      "47 Train Loss 0.5655022 Test MSE 0.9562567925272579 Test RE 0.46740712335104934\n",
      "48 Train Loss 0.469886 Test MSE 0.8544307777460246 Test RE 0.44182115047562914\n",
      "49 Train Loss 0.4000338 Test MSE 0.7791373381078707 Test RE 0.4219053853577073\n",
      "50 Train Loss 0.34983537 Test MSE 0.6668980408403647 Test RE 0.3903352573648021\n",
      "51 Train Loss 0.3064416 Test MSE 0.643947250740478 Test RE 0.3835599090396955\n",
      "52 Train Loss 0.27693263 Test MSE 0.6008446413958303 Test RE 0.37050080542840896\n",
      "53 Train Loss 0.2502244 Test MSE 0.5637692425752607 Test RE 0.35888784487525105\n",
      "54 Train Loss 0.22360563 Test MSE 0.5515741504899353 Test RE 0.3549850085606505\n",
      "55 Train Loss 0.20405895 Test MSE 0.5294564633768983 Test RE 0.34779488250758184\n",
      "56 Train Loss 0.18399493 Test MSE 0.5121885008123727 Test RE 0.34207628906329834\n",
      "57 Train Loss 0.17146847 Test MSE 0.49832070997490757 Test RE 0.3374135573033671\n",
      "58 Train Loss 0.1569939 Test MSE 0.480323946499522 Test RE 0.3312647155319226\n",
      "59 Train Loss 0.1483871 Test MSE 0.4682857000140435 Test RE 0.3270871692631206\n",
      "60 Train Loss 0.14126669 Test MSE 0.47000408889199247 Test RE 0.32768674797201686\n",
      "61 Train Loss 0.13559479 Test MSE 0.4778955158362412 Test RE 0.33042624727543224\n",
      "62 Train Loss 0.13154781 Test MSE 0.47688783445147853 Test RE 0.3300776981959178\n",
      "63 Train Loss 0.12774907 Test MSE 0.4735537240219038 Test RE 0.3289218228471697\n",
      "64 Train Loss 0.12356116 Test MSE 0.4722132087129913 Test RE 0.3284559441129706\n",
      "65 Train Loss 0.11901617 Test MSE 0.46463135714104314 Test RE 0.32580843096720913\n",
      "66 Train Loss 0.11679758 Test MSE 0.46243140217983497 Test RE 0.32503619043914567\n",
      "67 Train Loss 0.113227494 Test MSE 0.4702172600551342 Test RE 0.32776105099206415\n",
      "68 Train Loss 0.110680744 Test MSE 0.47650460287371815 Test RE 0.3299450447588573\n",
      "69 Train Loss 0.10834219 Test MSE 0.47675666578444403 Test RE 0.33003230090737556\n",
      "70 Train Loss 0.106623255 Test MSE 0.4847406231910205 Test RE 0.33278425373388343\n",
      "71 Train Loss 0.104656175 Test MSE 0.49338861349516794 Test RE 0.3357396408793048\n",
      "72 Train Loss 0.10342613 Test MSE 0.4924438044966401 Test RE 0.3354180264053239\n",
      "73 Train Loss 0.10210127 Test MSE 0.491742987180125 Test RE 0.33517926773690243\n",
      "74 Train Loss 0.10061376 Test MSE 0.49300039749511226 Test RE 0.33560752884233624\n",
      "75 Train Loss 0.10004693 Test MSE 0.49233569775002756 Test RE 0.33538120703468816\n",
      "76 Train Loss 0.09916749 Test MSE 0.49287798237817515 Test RE 0.3355658595194179\n",
      "77 Train Loss 0.097866 Test MSE 0.4927379155935204 Test RE 0.33551817533348766\n",
      "78 Train Loss 0.09648191 Test MSE 0.48771895140164695 Test RE 0.33380502949392593\n",
      "79 Train Loss 0.09520331 Test MSE 0.4876909359833325 Test RE 0.3337954421877447\n",
      "80 Train Loss 0.094375 Test MSE 0.49201626095260015 Test RE 0.33527238851683355\n",
      "81 Train Loss 0.09324431 Test MSE 0.49841011638408333 Test RE 0.3374438245398878\n",
      "82 Train Loss 0.09195336 Test MSE 0.49948961219224786 Test RE 0.33780905806415956\n",
      "83 Train Loss 0.09132162 Test MSE 0.5002699178226527 Test RE 0.3380728187478288\n",
      "84 Train Loss 0.09046116 Test MSE 0.49959182441554084 Test RE 0.33784361979257715\n",
      "85 Train Loss 0.089787394 Test MSE 0.49950812457256444 Test RE 0.3378153180460105\n",
      "86 Train Loss 0.089151375 Test MSE 0.5006844145178884 Test RE 0.3382128442091767\n",
      "87 Train Loss 0.08832926 Test MSE 0.5007595806545712 Test RE 0.3382382306582788\n",
      "88 Train Loss 0.08767338 Test MSE 0.5018046462262055 Test RE 0.3385909916541797\n",
      "89 Train Loss 0.08699011 Test MSE 0.5011169430867671 Test RE 0.3383588994223349\n",
      "90 Train Loss 0.085804485 Test MSE 0.50105124148847 Test RE 0.3383367175249617\n",
      "91 Train Loss 0.08467887 Test MSE 0.5058203867310392 Test RE 0.3399430956357158\n",
      "92 Train Loss 0.08373562 Test MSE 0.5106862082546083 Test RE 0.3415742511971294\n",
      "93 Train Loss 0.08317272 Test MSE 0.5088213643585845 Test RE 0.34095002714367983\n",
      "94 Train Loss 0.08268416 Test MSE 0.508610625965862 Test RE 0.3408794142459644\n",
      "95 Train Loss 0.0823401 Test MSE 0.509570652876649 Test RE 0.34120097568536567\n",
      "96 Train Loss 0.08167694 Test MSE 0.5099266021789465 Test RE 0.341320124077116\n",
      "97 Train Loss 0.08097939 Test MSE 0.5094712090855252 Test RE 0.3411676810147241\n",
      "98 Train Loss 0.08044312 Test MSE 0.5089713457302842 Test RE 0.34100027305377345\n",
      "99 Train Loss 0.07966445 Test MSE 0.511227039456393 Test RE 0.34175507175388997\n",
      "Training time: 194.48\n",
      "3\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.74114 Test MSE 7.500625154271152 Test RE 1.3090516767062135\n",
      "1 Train Loss 50.29141 Test MSE 8.661175672595675 Test RE 1.4066837935654615\n",
      "2 Train Loss 44.962833 Test MSE 9.028223213809465 Test RE 1.4361810905458292\n",
      "3 Train Loss 42.198963 Test MSE 8.866993252788157 Test RE 1.4232993442899047\n",
      "4 Train Loss 40.190796 Test MSE 8.688359692985019 Test RE 1.408889577446359\n",
      "5 Train Loss 37.242752 Test MSE 9.013569201205287 Test RE 1.4350150602935436\n",
      "6 Train Loss 34.73088 Test MSE 9.080592504794389 Test RE 1.4403404378562514\n",
      "7 Train Loss 33.321564 Test MSE 9.381853821487894 Test RE 1.4640381415748258\n",
      "8 Train Loss 31.089779 Test MSE 9.373323051716099 Test RE 1.4633723769536338\n",
      "9 Train Loss 29.459106 Test MSE 9.69709473326671 Test RE 1.4884315923425249\n",
      "10 Train Loss 27.92025 Test MSE 9.42720765488993 Test RE 1.4675726076339684\n",
      "11 Train Loss 26.234756 Test MSE 9.548815423814021 Test RE 1.4770078706892775\n",
      "12 Train Loss 24.529955 Test MSE 9.438594858828116 Test RE 1.4684586868277827\n",
      "13 Train Loss 23.29924 Test MSE 9.286824616221828 Test RE 1.4566046170472293\n",
      "14 Train Loss 22.12788 Test MSE 9.163997106503722 Test RE 1.4469400309634162\n",
      "15 Train Loss 20.53029 Test MSE 9.361882597063302 Test RE 1.4624790567948776\n",
      "16 Train Loss 19.106585 Test MSE 8.986166352130663 Test RE 1.4328320496924487\n",
      "17 Train Loss 17.899452 Test MSE 9.070050614094656 Test RE 1.439504131146896\n",
      "18 Train Loss 16.947567 Test MSE 8.867477707592682 Test RE 1.423338225270642\n",
      "19 Train Loss 16.14329 Test MSE 8.78991990265085 Test RE 1.4171000687037958\n",
      "20 Train Loss 15.248613 Test MSE 8.736280823737209 Test RE 1.4127696390121063\n",
      "21 Train Loss 14.521822 Test MSE 8.65391066944772 Test RE 1.4060937058845893\n",
      "22 Train Loss 13.824716 Test MSE 8.619298201420756 Test RE 1.4032789590740702\n",
      "23 Train Loss 13.030841 Test MSE 8.569086438067874 Test RE 1.3991855846924741\n",
      "24 Train Loss 12.546177 Test MSE 8.537021532958047 Test RE 1.3965653052608646\n",
      "25 Train Loss 11.839564 Test MSE 8.397739431999902 Test RE 1.3851259246935541\n",
      "26 Train Loss 11.346424 Test MSE 8.305186443559396 Test RE 1.377471916925964\n",
      "27 Train Loss 10.361004 Test MSE 8.296697821571751 Test RE 1.376767788982367\n",
      "28 Train Loss 9.903664 Test MSE 8.100853890127063 Test RE 1.3604214153723184\n",
      "29 Train Loss 9.174635 Test MSE 7.919505211604177 Test RE 1.3451077803901734\n",
      "30 Train Loss 8.573875 Test MSE 7.825302133570717 Test RE 1.3370837710839731\n",
      "31 Train Loss 8.115757 Test MSE 7.663411380997791 Test RE 1.3231806161689705\n",
      "32 Train Loss 7.6468596 Test MSE 7.611812974204527 Test RE 1.318718548264677\n",
      "33 Train Loss 7.3377542 Test MSE 7.535295110589048 Test RE 1.3120735874905907\n",
      "34 Train Loss 7.04307 Test MSE 7.415431283171488 Test RE 1.3015961869655714\n",
      "35 Train Loss 6.7315464 Test MSE 7.3357865330609 Test RE 1.294587480668537\n",
      "36 Train Loss 6.354092 Test MSE 7.247410529124673 Test RE 1.2867657466356897\n",
      "37 Train Loss 6.0945845 Test MSE 7.122665089249938 Test RE 1.2756435055262119\n",
      "38 Train Loss 5.5777264 Test MSE 6.786183681313061 Test RE 1.245147685168205\n",
      "39 Train Loss 4.8298564 Test MSE 6.655839366457019 Test RE 1.233131739863533\n",
      "40 Train Loss 4.09712 Test MSE 6.316236979636932 Test RE 1.201260697744734\n",
      "41 Train Loss 3.5428796 Test MSE 6.132286798161248 Test RE 1.1836390623429052\n",
      "42 Train Loss 2.9630215 Test MSE 6.030506855811781 Test RE 1.1737753046491566\n",
      "43 Train Loss 2.7021704 Test MSE 5.961375147038144 Test RE 1.1670280284996932\n",
      "44 Train Loss 2.4249613 Test MSE 5.873403636839983 Test RE 1.1583851573721675\n",
      "45 Train Loss 2.224761 Test MSE 5.878498951276109 Test RE 1.1588875114951904\n",
      "46 Train Loss 2.0548813 Test MSE 5.8595194474104355 Test RE 1.1570151889492535\n",
      "47 Train Loss 1.8857605 Test MSE 5.708212157777201 Test RE 1.1419789886978724\n",
      "48 Train Loss 1.771428 Test MSE 5.716825815288138 Test RE 1.1428402835806046\n",
      "49 Train Loss 1.6461931 Test MSE 5.5936479468609575 Test RE 1.1304611061548087\n",
      "50 Train Loss 1.573817 Test MSE 5.590873668077212 Test RE 1.1301807342708814\n",
      "51 Train Loss 1.5160313 Test MSE 5.586220522945888 Test RE 1.1297103257121364\n",
      "52 Train Loss 1.4479665 Test MSE 5.614722563820657 Test RE 1.1325886656072832\n",
      "53 Train Loss 1.3949856 Test MSE 5.628560573196973 Test RE 1.1339834921124248\n",
      "54 Train Loss 1.345169 Test MSE 5.643901739192964 Test RE 1.1355278293241513\n",
      "55 Train Loss 1.3034027 Test MSE 5.68972981246395 Test RE 1.1401287103593516\n",
      "56 Train Loss 1.266971 Test MSE 5.736019607320721 Test RE 1.144757174059179\n",
      "57 Train Loss 1.2405741 Test MSE 5.743355611686885 Test RE 1.1454889759713507\n",
      "58 Train Loss 1.212061 Test MSE 5.778690547811058 Test RE 1.1490072776715754\n",
      "59 Train Loss 1.1859579 Test MSE 5.824007658536978 Test RE 1.153503798457747\n",
      "60 Train Loss 1.1525676 Test MSE 5.865895974005628 Test RE 1.1576445692342014\n",
      "61 Train Loss 1.1255294 Test MSE 5.881308561959531 Test RE 1.1591644217916428\n",
      "62 Train Loss 1.1039503 Test MSE 5.8839182491916375 Test RE 1.1594215687394913\n",
      "63 Train Loss 1.0843023 Test MSE 5.895823009887943 Test RE 1.160593888031965\n",
      "64 Train Loss 1.0657105 Test MSE 5.906289864580405 Test RE 1.1616236323831841\n",
      "65 Train Loss 1.0486325 Test MSE 5.900365835766815 Test RE 1.1610409300072049\n",
      "66 Train Loss 1.0351303 Test MSE 5.922808102019661 Test RE 1.1632468661132211\n",
      "67 Train Loss 1.0168794 Test MSE 5.962150881609004 Test RE 1.1671039568312767\n",
      "68 Train Loss 1.0003878 Test MSE 5.97132642005258 Test RE 1.1680016773422919\n",
      "69 Train Loss 0.98930895 Test MSE 5.974721014571766 Test RE 1.1683336244241138\n",
      "70 Train Loss 0.98104036 Test MSE 5.990628348428504 Test RE 1.1698878994276019\n",
      "71 Train Loss 0.97027755 Test MSE 5.999295938237745 Test RE 1.1707339244747008\n",
      "72 Train Loss 0.96248394 Test MSE 6.003324301473964 Test RE 1.1711269164295028\n",
      "73 Train Loss 0.9549977 Test MSE 6.0175434888677355 Test RE 1.1725130337994791\n",
      "74 Train Loss 0.944956 Test MSE 6.040667603002183 Test RE 1.174763730245548\n",
      "75 Train Loss 0.9323262 Test MSE 6.045252506719783 Test RE 1.1752094721154922\n",
      "76 Train Loss 0.92465687 Test MSE 6.041035444396074 Test RE 1.17479949782772\n",
      "77 Train Loss 0.91429955 Test MSE 6.061003239120351 Test RE 1.176739463500069\n",
      "78 Train Loss 0.90753824 Test MSE 6.071405484897347 Test RE 1.1777488249102142\n",
      "79 Train Loss 0.9014081 Test MSE 6.073658887419144 Test RE 1.177967365408924\n",
      "80 Train Loss 0.8953519 Test MSE 6.070517176947118 Test RE 1.1776626634837137\n",
      "81 Train Loss 0.8885992 Test MSE 6.087076329918594 Test RE 1.179267783357622\n",
      "82 Train Loss 0.8826151 Test MSE 6.091395596439524 Test RE 1.179686101473441\n",
      "83 Train Loss 0.8752551 Test MSE 6.084574506325607 Test RE 1.1790254155101623\n",
      "84 Train Loss 0.8683042 Test MSE 6.078662496053502 Test RE 1.1784524827303802\n",
      "85 Train Loss 0.86133736 Test MSE 6.08029920398208 Test RE 1.1786111239369998\n",
      "86 Train Loss 0.856152 Test MSE 6.094488706797251 Test RE 1.1799855760475675\n",
      "87 Train Loss 0.84895784 Test MSE 6.104008299753694 Test RE 1.1809067853450814\n",
      "88 Train Loss 0.84319365 Test MSE 6.097663782735545 Test RE 1.18029290748696\n",
      "89 Train Loss 0.8374293 Test MSE 6.11454566662432 Test RE 1.1819256471880368\n",
      "90 Train Loss 0.8319307 Test MSE 6.129206360399213 Test RE 1.1833417357019702\n",
      "91 Train Loss 0.8243165 Test MSE 6.112782483092869 Test RE 1.1817552255244075\n",
      "92 Train Loss 0.8194493 Test MSE 6.09977338890341 Test RE 1.180497062550396\n",
      "93 Train Loss 0.815566 Test MSE 6.096821709527445 Test RE 1.180211406818305\n",
      "94 Train Loss 0.810281 Test MSE 6.114487444981769 Test RE 1.1819200201292077\n",
      "95 Train Loss 0.80625343 Test MSE 6.128573603038399 Test RE 1.1832806521394639\n",
      "96 Train Loss 0.8025223 Test MSE 6.130458550860444 Test RE 1.1834626072694665\n",
      "97 Train Loss 0.797095 Test MSE 6.147518109773718 Test RE 1.1851081060451514\n",
      "98 Train Loss 0.79295844 Test MSE 6.179823132372683 Test RE 1.1882178796667193\n",
      "99 Train Loss 0.788622 Test MSE 6.183509389703506 Test RE 1.1885722121284068\n",
      "Training time: 195.34\n",
      "4\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.47625 Test MSE 8.592201844877577 Test RE 1.401071489460598\n",
      "1 Train Loss 48.296932 Test MSE 8.554899099444516 Test RE 1.3980268297271625\n",
      "2 Train Loss 41.191723 Test MSE 8.138553710789074 Test RE 1.3635833111310949\n",
      "3 Train Loss 36.36745 Test MSE 7.677622539139606 Test RE 1.3244069120407267\n",
      "4 Train Loss 31.880377 Test MSE 7.115752830728185 Test RE 1.2750243750535855\n",
      "5 Train Loss 27.333954 Test MSE 6.623683275882335 Test RE 1.2301493432869826\n",
      "6 Train Loss 24.393074 Test MSE 6.340354971290522 Test RE 1.2035519663831795\n",
      "7 Train Loss 21.463291 Test MSE 6.548704983859642 Test RE 1.223167049746661\n",
      "8 Train Loss 19.243328 Test MSE 6.4686510579298835 Test RE 1.2156678251802093\n",
      "9 Train Loss 17.290585 Test MSE 6.5828557862794 Test RE 1.2263522457944218\n",
      "10 Train Loss 15.7420635 Test MSE 6.307513352299222 Test RE 1.2004308546302287\n",
      "11 Train Loss 14.48023 Test MSE 6.310339493642969 Test RE 1.2006997567429931\n",
      "12 Train Loss 13.491331 Test MSE 6.1318330109310235 Test RE 1.1835952670797012\n",
      "13 Train Loss 12.376345 Test MSE 6.0305284435723445 Test RE 1.1737774055635701\n",
      "14 Train Loss 11.3243065 Test MSE 5.934853204171715 Test RE 1.164429101855992\n",
      "15 Train Loss 10.098498 Test MSE 5.758737715667219 Test RE 1.1470218993890313\n",
      "16 Train Loss 8.861447 Test MSE 5.571338711821549 Test RE 1.1282045359267956\n",
      "17 Train Loss 8.230782 Test MSE 5.5011952267431115 Test RE 1.121079959148768\n",
      "18 Train Loss 6.9898853 Test MSE 5.2210518824698715 Test RE 1.0921620071219222\n",
      "19 Train Loss 6.227742 Test MSE 5.142542983811539 Test RE 1.0839194901642164\n",
      "20 Train Loss 5.3390455 Test MSE 4.964628491099161 Test RE 1.0650044879981895\n",
      "21 Train Loss 4.577347 Test MSE 4.644507756970787 Test RE 1.0300964881387815\n",
      "22 Train Loss 3.8573627 Test MSE 4.368798463341898 Test RE 0.999054236243377\n",
      "23 Train Loss 3.322381 Test MSE 4.104261476700113 Test RE 0.9683348693754527\n",
      "24 Train Loss 2.7938714 Test MSE 3.8668643256566972 Test RE 0.9399127211090264\n",
      "25 Train Loss 2.4664526 Test MSE 3.616567144187882 Test RE 0.9089841836035667\n",
      "26 Train Loss 2.2196903 Test MSE 3.3910023338112434 Test RE 0.8801812334217903\n",
      "27 Train Loss 2.0341241 Test MSE 3.199942861195774 Test RE 0.8550257064713798\n",
      "28 Train Loss 1.8843682 Test MSE 2.980095326736229 Test RE 0.8251314459519681\n",
      "29 Train Loss 1.76132 Test MSE 2.831895237469656 Test RE 0.8043529368288255\n",
      "30 Train Loss 1.6431986 Test MSE 2.822106608208698 Test RE 0.8029615844581014\n",
      "31 Train Loss 1.5641409 Test MSE 2.676610174192094 Test RE 0.781988961264807\n",
      "32 Train Loss 1.4725494 Test MSE 2.5767914110865378 Test RE 0.7672690718299914\n",
      "33 Train Loss 1.423431 Test MSE 2.586991919406708 Test RE 0.7687862307788753\n",
      "34 Train Loss 1.3773034 Test MSE 2.491637294456983 Test RE 0.7544847597224584\n",
      "35 Train Loss 1.306967 Test MSE 2.423890873994249 Test RE 0.7441570354805558\n",
      "36 Train Loss 1.2610852 Test MSE 2.384979910189746 Test RE 0.738159855933373\n",
      "37 Train Loss 1.22042 Test MSE 2.2580328245062553 Test RE 0.7182459498649703\n",
      "38 Train Loss 1.1798929 Test MSE 2.2014106568520884 Test RE 0.7091834508106822\n",
      "39 Train Loss 1.1452557 Test MSE 2.137730454877655 Test RE 0.6988509059195545\n",
      "40 Train Loss 1.1113734 Test MSE 2.059176018802363 Test RE 0.6858905134502773\n",
      "41 Train Loss 1.0638653 Test MSE 1.9890282303138809 Test RE 0.6741065295558023\n",
      "42 Train Loss 1.0193263 Test MSE 1.8747845108797103 Test RE 0.6544609503843009\n",
      "43 Train Loss 0.9762047 Test MSE 1.8214724882421494 Test RE 0.6450886017224394\n",
      "44 Train Loss 0.9286545 Test MSE 1.7530658438137854 Test RE 0.6328593114120459\n",
      "45 Train Loss 0.9000855 Test MSE 1.7390598337731558 Test RE 0.6303261466590764\n",
      "46 Train Loss 0.8638112 Test MSE 1.6416762511088805 Test RE 0.6124234590152853\n",
      "47 Train Loss 0.81934667 Test MSE 1.5433578094939677 Test RE 0.59380161193901\n",
      "48 Train Loss 0.7801985 Test MSE 1.5066176560295383 Test RE 0.5866912168428291\n",
      "49 Train Loss 0.74167085 Test MSE 1.3915251909141648 Test RE 0.5638370324966349\n",
      "50 Train Loss 0.6457435 Test MSE 1.1576001393790516 Test RE 0.5142654470083686\n",
      "51 Train Loss 0.5959739 Test MSE 1.1109775218990536 Test RE 0.5038029385727408\n",
      "52 Train Loss 0.5239766 Test MSE 0.995345976594869 Test RE 0.4768646099910299\n",
      "53 Train Loss 0.47200024 Test MSE 0.9378383939736965 Test RE 0.46288388824237026\n",
      "54 Train Loss 0.42376205 Test MSE 0.9084979763700183 Test RE 0.45558565647102406\n",
      "55 Train Loss 0.38336447 Test MSE 0.8791968521995336 Test RE 0.4481786071094757\n",
      "56 Train Loss 0.35334733 Test MSE 0.8342589022705915 Test RE 0.43657462044702094\n",
      "57 Train Loss 0.31867737 Test MSE 0.7821035276205113 Test RE 0.4227077230559368\n",
      "58 Train Loss 0.29698378 Test MSE 0.7631893918708249 Test RE 0.4175651284473028\n",
      "59 Train Loss 0.27463725 Test MSE 0.7416465193558818 Test RE 0.4116295475698412\n",
      "60 Train Loss 0.24386671 Test MSE 0.7339007176059158 Test RE 0.4094743634564341\n",
      "61 Train Loss 0.2228761 Test MSE 0.7300176744720633 Test RE 0.40838966948688266\n",
      "62 Train Loss 0.20334132 Test MSE 0.7047472185481709 Test RE 0.4012589621574638\n",
      "63 Train Loss 0.18590494 Test MSE 0.6530961658322437 Test RE 0.3862750232560538\n",
      "64 Train Loss 0.17843005 Test MSE 0.6477744524238875 Test RE 0.3846980352100714\n",
      "65 Train Loss 0.17288111 Test MSE 0.650558649722986 Test RE 0.38552388346408156\n",
      "66 Train Loss 0.16683188 Test MSE 0.6345076168168953 Test RE 0.3807382244004854\n",
      "67 Train Loss 0.15902515 Test MSE 0.6272791561411881 Test RE 0.37856328239242315\n",
      "68 Train Loss 0.15138984 Test MSE 0.6189960854308261 Test RE 0.3760555577616325\n",
      "69 Train Loss 0.14553237 Test MSE 0.5987613642367098 Test RE 0.3698579386801491\n",
      "70 Train Loss 0.14077441 Test MSE 0.5936649014148313 Test RE 0.36828051938916295\n",
      "71 Train Loss 0.13703632 Test MSE 0.5875488924551757 Test RE 0.36637857254152584\n",
      "72 Train Loss 0.13258068 Test MSE 0.5804096857941483 Test RE 0.3641458676480181\n",
      "73 Train Loss 0.12890871 Test MSE 0.5733879133940106 Test RE 0.3619364541344042\n",
      "74 Train Loss 0.12630343 Test MSE 0.5649481111233314 Test RE 0.35926287478166685\n",
      "75 Train Loss 0.12342428 Test MSE 0.5550977539565999 Test RE 0.3561170731321304\n",
      "76 Train Loss 0.11893587 Test MSE 0.5434851706787462 Test RE 0.3523724204086206\n",
      "77 Train Loss 0.11589299 Test MSE 0.5455261281362395 Test RE 0.35303343494851586\n",
      "78 Train Loss 0.11373833 Test MSE 0.5460377385781181 Test RE 0.35319893872141594\n",
      "79 Train Loss 0.11148874 Test MSE 0.5369717612942416 Test RE 0.35025454854450166\n",
      "80 Train Loss 0.109896556 Test MSE 0.5316320385032296 Test RE 0.34850870720718596\n",
      "81 Train Loss 0.10757665 Test MSE 0.5352729780751696 Test RE 0.3497000706982646\n",
      "82 Train Loss 0.10591258 Test MSE 0.534559999620821 Test RE 0.3494670945279011\n",
      "83 Train Loss 0.10368812 Test MSE 0.5241488685013415 Test RE 0.34604723747729504\n",
      "84 Train Loss 0.10247366 Test MSE 0.5211739962604759 Test RE 0.34506382300251315\n",
      "85 Train Loss 0.10142739 Test MSE 0.5204522441695618 Test RE 0.3448248079881274\n",
      "86 Train Loss 0.100469165 Test MSE 0.5184556773881664 Test RE 0.34416276136428653\n",
      "87 Train Loss 0.09903412 Test MSE 0.5169379182151524 Test RE 0.3436586304752699\n",
      "88 Train Loss 0.09831742 Test MSE 0.5184774549928473 Test RE 0.3441699895249419\n",
      "89 Train Loss 0.0973081 Test MSE 0.516580873700597 Test RE 0.3435399289648096\n",
      "90 Train Loss 0.096379906 Test MSE 0.517212531152064 Test RE 0.34374989924503535\n",
      "91 Train Loss 0.09495099 Test MSE 0.5195412910831179 Test RE 0.3445229005618308\n",
      "92 Train Loss 0.0940408 Test MSE 0.5158825771250216 Test RE 0.3433076576083214\n",
      "93 Train Loss 0.0933014 Test MSE 0.5103705447600856 Test RE 0.34146866856449126\n",
      "94 Train Loss 0.09246258 Test MSE 0.509819593989983 Test RE 0.34128430915343494\n",
      "95 Train Loss 0.09177353 Test MSE 0.5098910209866332 Test RE 0.3413082157075742\n",
      "96 Train Loss 0.091124855 Test MSE 0.5108916470709775 Test RE 0.34164294852329063\n",
      "97 Train Loss 0.09053204 Test MSE 0.5113664596559966 Test RE 0.3418016697509761\n",
      "98 Train Loss 0.08988982 Test MSE 0.5108144102453396 Test RE 0.34161712268097405\n",
      "99 Train Loss 0.089023255 Test MSE 0.5125170179837629 Test RE 0.34218597516588417\n",
      "Training time: 194.91\n",
      "5\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.007645 Test MSE 8.370922567600239 Test RE 1.3829125650261296\n",
      "1 Train Loss 47.258926 Test MSE 8.861430614694525 Test RE 1.422852826455232\n",
      "2 Train Loss 41.171852 Test MSE 9.819639567554173 Test RE 1.4978069239287204\n",
      "3 Train Loss 37.63003 Test MSE 9.299903811555192 Test RE 1.4576299682340914\n",
      "4 Train Loss 35.108444 Test MSE 9.299725227425817 Test RE 1.4576159728835056\n",
      "5 Train Loss 32.778404 Test MSE 9.435209630450373 Test RE 1.468195325919674\n",
      "6 Train Loss 30.671986 Test MSE 9.233003481520287 Test RE 1.452377659413157\n",
      "7 Train Loss 28.679333 Test MSE 9.235975092494542 Test RE 1.4526113620317804\n",
      "8 Train Loss 26.526657 Test MSE 9.154011351295923 Test RE 1.446151470740218\n",
      "9 Train Loss 24.251415 Test MSE 9.106782220914317 Test RE 1.4424160153771937\n",
      "10 Train Loss 22.258266 Test MSE 8.71535534820237 Test RE 1.411076664571295\n",
      "11 Train Loss 19.98386 Test MSE 8.97543919437482 Test RE 1.4319765789284271\n",
      "12 Train Loss 17.551872 Test MSE 8.925965568707001 Test RE 1.4280245177432873\n",
      "13 Train Loss 16.170813 Test MSE 8.617036004709874 Test RE 1.40309479666949\n",
      "14 Train Loss 14.929249 Test MSE 8.39844190506012 Test RE 1.3851838565517427\n",
      "15 Train Loss 13.49177 Test MSE 8.135181221826285 Test RE 1.3633007580920076\n",
      "16 Train Loss 11.94606 Test MSE 8.151985069567727 Test RE 1.3647080334814061\n",
      "17 Train Loss 10.414734 Test MSE 7.662518263588015 Test RE 1.323103510163617\n",
      "18 Train Loss 9.087009 Test MSE 7.208032425864918 Test RE 1.283265226689183\n",
      "19 Train Loss 7.427891 Test MSE 7.309233287931888 Test RE 1.2922423563852579\n",
      "20 Train Loss 6.267629 Test MSE 6.78559472516919 Test RE 1.2450936523475895\n",
      "21 Train Loss 5.182966 Test MSE 6.394523261735398 Test RE 1.2086822547357345\n",
      "22 Train Loss 4.5597415 Test MSE 6.170272459933395 Test RE 1.1872993527539846\n",
      "23 Train Loss 3.880418 Test MSE 5.862358827158302 Test RE 1.157295485621942\n",
      "24 Train Loss 3.2009637 Test MSE 5.716028311037667 Test RE 1.1427605669859873\n",
      "25 Train Loss 2.7926161 Test MSE 5.490919590294838 Test RE 1.120032441829006\n",
      "26 Train Loss 2.4848003 Test MSE 5.411768249678936 Test RE 1.1119305319159467\n",
      "27 Train Loss 2.260576 Test MSE 5.388274896498115 Test RE 1.109514372519895\n",
      "28 Train Loss 2.1380713 Test MSE 5.360744504438983 Test RE 1.1066763137049032\n",
      "29 Train Loss 1.9858042 Test MSE 5.332004178813339 Test RE 1.1037057391325955\n",
      "30 Train Loss 1.8590329 Test MSE 5.2652231701744014 Test RE 1.0967722463675087\n",
      "31 Train Loss 1.7537789 Test MSE 5.384106053215024 Test RE 1.109085080526919\n",
      "32 Train Loss 1.6803633 Test MSE 5.391727588781834 Test RE 1.1098697922327958\n",
      "33 Train Loss 1.6219728 Test MSE 5.414513698878564 Test RE 1.1122125434113612\n",
      "34 Train Loss 1.5533817 Test MSE 5.402841654588016 Test RE 1.111013100715284\n",
      "35 Train Loss 1.5078143 Test MSE 5.444806417366165 Test RE 1.1153194658811942\n",
      "36 Train Loss 1.4576609 Test MSE 5.471056838902823 Test RE 1.1180048141290126\n",
      "37 Train Loss 1.4154088 Test MSE 5.463918363906529 Test RE 1.117275206062331\n",
      "38 Train Loss 1.3737912 Test MSE 5.519860603483248 Test RE 1.1229802425596072\n",
      "39 Train Loss 1.3356463 Test MSE 5.56200483768101 Test RE 1.1272590779380973\n",
      "40 Train Loss 1.3055015 Test MSE 5.569826059975354 Test RE 1.1280513683835103\n",
      "41 Train Loss 1.2754295 Test MSE 5.548394509639244 Test RE 1.12587902132625\n",
      "42 Train Loss 1.2546415 Test MSE 5.561572852939989 Test RE 1.1272153016208708\n",
      "43 Train Loss 1.2352393 Test MSE 5.5685069889934065 Test RE 1.1279177854028128\n",
      "44 Train Loss 1.21465 Test MSE 5.578016432498173 Test RE 1.1288804577306855\n",
      "45 Train Loss 1.1892457 Test MSE 5.624059722246187 Test RE 1.1335300092595955\n",
      "46 Train Loss 1.1674279 Test MSE 5.651954766901061 Test RE 1.1363376571590977\n",
      "47 Train Loss 1.1434811 Test MSE 5.689541248222809 Test RE 1.1401098176093067\n",
      "48 Train Loss 1.1163647 Test MSE 5.710225081165108 Test RE 1.1421803226299585\n",
      "49 Train Loss 1.0944082 Test MSE 5.747294056328794 Test RE 1.1458816620656003\n",
      "50 Train Loss 1.0649891 Test MSE 5.766156209789645 Test RE 1.147760467195915\n",
      "51 Train Loss 1.0426693 Test MSE 5.77776559576229 Test RE 1.1489153174638231\n",
      "52 Train Loss 1.020053 Test MSE 5.823457394447599 Test RE 1.1534493044780112\n",
      "53 Train Loss 1.0052027 Test MSE 5.8471016479229565 Test RE 1.1557885352143489\n",
      "54 Train Loss 0.99173325 Test MSE 5.86926277271222 Test RE 1.1579767433090786\n",
      "55 Train Loss 0.9788816 Test MSE 5.890382760568436 Test RE 1.1600583073945103\n",
      "56 Train Loss 0.96308297 Test MSE 5.90247768909371 Test RE 1.1612486907510684\n",
      "57 Train Loss 0.9482535 Test MSE 5.944304769319031 Test RE 1.1653559402160198\n",
      "58 Train Loss 0.93519235 Test MSE 5.982777400515644 Test RE 1.1691210566495023\n",
      "59 Train Loss 0.92595714 Test MSE 5.997409549494699 Test RE 1.1705498501307694\n",
      "60 Train Loss 0.91374123 Test MSE 6.002873336435254 Test RE 1.171082928533184\n",
      "61 Train Loss 0.90384376 Test MSE 6.022044106002635 Test RE 1.1729514224820996\n",
      "62 Train Loss 0.89221007 Test MSE 6.021466363956338 Test RE 1.1728951559057283\n",
      "63 Train Loss 0.883712 Test MSE 6.0177968052329005 Test RE 1.1725377127747634\n",
      "64 Train Loss 0.8745879 Test MSE 6.046477426564377 Test RE 1.1753285295484233\n",
      "65 Train Loss 0.8670274 Test MSE 6.066054945825091 Test RE 1.1772297539898675\n",
      "66 Train Loss 0.8574359 Test MSE 6.053013592976572 Test RE 1.1759636156789581\n",
      "67 Train Loss 0.8489169 Test MSE 6.083168515315232 Test RE 1.1788891861889812\n",
      "68 Train Loss 0.8407959 Test MSE 6.108784016208654 Test RE 1.1813686599866386\n",
      "69 Train Loss 0.8335155 Test MSE 6.112908929906519 Test RE 1.181767448142376\n",
      "70 Train Loss 0.82740533 Test MSE 6.12789554644337 Test RE 1.1832151920915521\n",
      "71 Train Loss 0.8217708 Test MSE 6.149297145698738 Test RE 1.1852795734036676\n",
      "72 Train Loss 0.81470084 Test MSE 6.149534921053742 Test RE 1.1853024888312633\n",
      "73 Train Loss 0.8090768 Test MSE 6.153873019734492 Test RE 1.185720492202168\n",
      "74 Train Loss 0.80219704 Test MSE 6.156787571820953 Test RE 1.1860012450741746\n",
      "75 Train Loss 0.79534924 Test MSE 6.179438743964467 Test RE 1.1881809251882378\n",
      "76 Train Loss 0.78945166 Test MSE 6.212358378841819 Test RE 1.1913416108619614\n",
      "77 Train Loss 0.7843723 Test MSE 6.217502687449849 Test RE 1.19183476984537\n",
      "78 Train Loss 0.77740353 Test MSE 6.228403347965843 Test RE 1.1928790875952775\n",
      "79 Train Loss 0.7726581 Test MSE 6.258347758111794 Test RE 1.1957431627487947\n",
      "80 Train Loss 0.7686527 Test MSE 6.267201370668326 Test RE 1.1965886658698601\n",
      "81 Train Loss 0.76450753 Test MSE 6.26917676633177 Test RE 1.1967772308840594\n",
      "82 Train Loss 0.7590339 Test MSE 6.296403919509543 Test RE 1.1993732283870555\n",
      "83 Train Loss 0.75499314 Test MSE 6.307108695240095 Test RE 1.2003923473308034\n",
      "84 Train Loss 0.75195646 Test MSE 6.294329933307321 Test RE 1.1991756800378754\n",
      "85 Train Loss 0.74838126 Test MSE 6.301959639071498 Test RE 1.1999022535384383\n",
      "86 Train Loss 0.7445557 Test MSE 6.3141256491635 Test RE 1.2010599080727935\n",
      "87 Train Loss 0.74060935 Test MSE 6.3172790479437975 Test RE 1.2013597871296489\n",
      "88 Train Loss 0.73707163 Test MSE 6.312309734630131 Test RE 1.2008871859019545\n",
      "89 Train Loss 0.73441714 Test MSE 6.320159310521681 Test RE 1.2016336263325498\n",
      "90 Train Loss 0.731124 Test MSE 6.332843370799816 Test RE 1.2028388138203834\n",
      "91 Train Loss 0.72701246 Test MSE 6.343383695578546 Test RE 1.2038393944428687\n",
      "92 Train Loss 0.7239583 Test MSE 6.344231678567002 Test RE 1.203919856327432\n",
      "93 Train Loss 0.71984977 Test MSE 6.333080912507811 Test RE 1.2028613725424497\n",
      "94 Train Loss 0.71713936 Test MSE 6.326445994217151 Test RE 1.2022311122913454\n",
      "95 Train Loss 0.7150609 Test MSE 6.320009906703941 Test RE 1.2016194233905448\n",
      "96 Train Loss 0.71249986 Test MSE 6.316231035368634 Test RE 1.2012601324858951\n",
      "97 Train Loss 0.7101866 Test MSE 6.3303553822189365 Test RE 1.2026025105481417\n",
      "98 Train Loss 0.70708776 Test MSE 6.354823757567191 Test RE 1.2049244457519253\n",
      "99 Train Loss 0.7047553 Test MSE 6.366977472644936 Test RE 1.2060761152374921\n",
      "Training time: 194.37\n",
      "6\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.197914 Test MSE 8.203117972832201 Test RE 1.3689813730376077\n",
      "1 Train Loss 44.828934 Test MSE 8.735014180178515 Test RE 1.4126672189739644\n",
      "2 Train Loss 40.48443 Test MSE 8.66128524441309 Test RE 1.4066926914575109\n",
      "3 Train Loss 37.38259 Test MSE 9.064022245223475 Test RE 1.4390256716173742\n",
      "4 Train Loss 35.010834 Test MSE 8.685453509382853 Test RE 1.4086539268527767\n",
      "5 Train Loss 31.622494 Test MSE 8.894901730965659 Test RE 1.4255374711688413\n",
      "6 Train Loss 28.32721 Test MSE 8.597251609803493 Test RE 1.4014831442707707\n",
      "7 Train Loss 25.278526 Test MSE 8.66208369857145 Test RE 1.4067575290487577\n",
      "8 Train Loss 22.247211 Test MSE 8.811599436374763 Test RE 1.4188465663454874\n",
      "9 Train Loss 19.18513 Test MSE 8.530116692031754 Test RE 1.3960004119967242\n",
      "10 Train Loss 16.129395 Test MSE 8.374255224895215 Test RE 1.383187822322291\n",
      "11 Train Loss 14.164838 Test MSE 7.919694165960524 Test RE 1.3451238270024328\n",
      "12 Train Loss 12.692659 Test MSE 7.6751473737551805 Test RE 1.3241934090731253\n",
      "13 Train Loss 10.70286 Test MSE 7.565208153125554 Test RE 1.3146752930996204\n",
      "14 Train Loss 9.392877 Test MSE 7.3223068692815385 Test RE 1.293397517756491\n",
      "15 Train Loss 7.9797907 Test MSE 7.149528397321546 Test RE 1.2780468021981208\n",
      "16 Train Loss 6.535006 Test MSE 7.040284682015532 Test RE 1.2682450345202168\n",
      "17 Train Loss 5.169528 Test MSE 6.686539232812874 Test RE 1.2359723602843062\n",
      "18 Train Loss 4.613866 Test MSE 6.4248314615453035 Test RE 1.211543271648329\n",
      "19 Train Loss 4.00879 Test MSE 6.412787582761527 Test RE 1.210407169858127\n",
      "20 Train Loss 3.477619 Test MSE 6.354020501746821 Test RE 1.2048482915423282\n",
      "21 Train Loss 3.1354923 Test MSE 6.327697684689956 Test RE 1.2023500374197427\n",
      "22 Train Loss 2.9214795 Test MSE 6.4256100256141835 Test RE 1.211616677113537\n",
      "23 Train Loss 2.6687827 Test MSE 6.355798216421294 Test RE 1.205016824732952\n",
      "24 Train Loss 2.408681 Test MSE 6.039642289980145 Test RE 1.1746640267238984\n",
      "25 Train Loss 2.2147255 Test MSE 5.9580384424005866 Test RE 1.166701377954872\n",
      "26 Train Loss 2.064473 Test MSE 5.891241733726208 Test RE 1.1601428878592404\n",
      "27 Train Loss 1.902852 Test MSE 5.943994047666128 Test RE 1.165325481981618\n",
      "28 Train Loss 1.764589 Test MSE 5.984976394959109 Test RE 1.1693358945369299\n",
      "29 Train Loss 1.6460032 Test MSE 5.925243517532322 Test RE 1.1634860008486116\n",
      "30 Train Loss 1.5600905 Test MSE 5.939537551411312 Test RE 1.1648885499810213\n",
      "31 Train Loss 1.4719856 Test MSE 5.857955024293928 Test RE 1.1568607238812205\n",
      "32 Train Loss 1.406123 Test MSE 5.8581584096221615 Test RE 1.1568808065256613\n",
      "33 Train Loss 1.3523456 Test MSE 5.812783367425106 Test RE 1.1523917200275675\n",
      "34 Train Loss 1.310796 Test MSE 5.769319941418879 Test RE 1.1480752963482628\n",
      "35 Train Loss 1.2572333 Test MSE 5.765214688368154 Test RE 1.147666757873469\n",
      "36 Train Loss 1.2187914 Test MSE 5.736751290927699 Test RE 1.1448301840387742\n",
      "37 Train Loss 1.184954 Test MSE 5.752663505323334 Test RE 1.146416811014468\n",
      "38 Train Loss 1.1512394 Test MSE 5.780137081173462 Test RE 1.1491510795715414\n",
      "39 Train Loss 1.1244245 Test MSE 5.821250381591832 Test RE 1.1532307127968846\n",
      "40 Train Loss 1.1035569 Test MSE 5.821693528409997 Test RE 1.1532746072149078\n",
      "41 Train Loss 1.0835433 Test MSE 5.8318460390908 Test RE 1.1542797728471894\n",
      "42 Train Loss 1.0553916 Test MSE 5.899332461595423 Test RE 1.1609392547654505\n",
      "43 Train Loss 1.0071251 Test MSE 5.973110002448859 Test RE 1.1681761002047215\n",
      "44 Train Loss 0.9611038 Test MSE 6.051639538169831 Test RE 1.1758301342201372\n",
      "45 Train Loss 0.9405565 Test MSE 6.033588140139051 Test RE 1.174075136293671\n",
      "46 Train Loss 0.92281246 Test MSE 6.051605461320706 Test RE 1.1758268236592364\n",
      "47 Train Loss 0.9024158 Test MSE 6.106804339357364 Test RE 1.1811772210937481\n",
      "48 Train Loss 0.8839954 Test MSE 6.111875953406232 Test RE 1.1816675947344468\n",
      "49 Train Loss 0.87009084 Test MSE 6.127708278601724 Test RE 1.1831971124876794\n",
      "50 Train Loss 0.8556837 Test MSE 6.150960633994782 Test RE 1.1854398815921323\n",
      "51 Train Loss 0.8434172 Test MSE 6.179861711133937 Test RE 1.1882215885028278\n",
      "52 Train Loss 0.8299379 Test MSE 6.206155418847822 Test RE 1.1907466926772514\n",
      "53 Train Loss 0.81950426 Test MSE 6.215788373103055 Test RE 1.1916704498277146\n",
      "54 Train Loss 0.8077643 Test MSE 6.260119578212448 Test RE 1.1959124160341887\n",
      "55 Train Loss 0.79793835 Test MSE 6.29287819129739 Test RE 1.1990373814323705\n",
      "56 Train Loss 0.7883935 Test MSE 6.29315805723471 Test RE 1.1990640437941331\n",
      "57 Train Loss 0.77622086 Test MSE 6.323088429331097 Test RE 1.2019120465248523\n",
      "58 Train Loss 0.76620275 Test MSE 6.346106280489382 Test RE 1.2040977111016788\n",
      "59 Train Loss 0.7580869 Test MSE 6.361059295052673 Test RE 1.2055154542251154\n",
      "60 Train Loss 0.750653 Test MSE 6.405295737415054 Test RE 1.2096999241192148\n",
      "61 Train Loss 0.7428347 Test MSE 6.425834912831407 Test RE 1.2116378793587503\n",
      "62 Train Loss 0.7357825 Test MSE 6.416860693986343 Test RE 1.210791506651411\n",
      "63 Train Loss 0.7305586 Test MSE 6.4312860055007866 Test RE 1.2121516919860933\n",
      "64 Train Loss 0.7244591 Test MSE 6.458684717520506 Test RE 1.214730966042959\n",
      "65 Train Loss 0.71831775 Test MSE 6.479612455425731 Test RE 1.216697388979125\n",
      "66 Train Loss 0.7119013 Test MSE 6.4779329335787725 Test RE 1.2165396941868443\n",
      "67 Train Loss 0.7055782 Test MSE 6.499064039666098 Test RE 1.218522263296164\n",
      "68 Train Loss 0.69942236 Test MSE 6.513856638446131 Test RE 1.2199082217740416\n",
      "69 Train Loss 0.6943116 Test MSE 6.5203267918941235 Test RE 1.2205139331666055\n",
      "70 Train Loss 0.68897575 Test MSE 6.530774673698869 Test RE 1.2214913904004694\n",
      "71 Train Loss 0.6841121 Test MSE 6.530417283367518 Test RE 1.2214579674753825\n",
      "72 Train Loss 0.6764134 Test MSE 6.54662970250078 Test RE 1.2229732238741469\n",
      "73 Train Loss 0.6712711 Test MSE 6.571828735152992 Test RE 1.2253246737746335\n",
      "74 Train Loss 0.6653603 Test MSE 6.58053724656339 Test RE 1.2261362607503155\n",
      "75 Train Loss 0.66100794 Test MSE 6.596363837458616 Test RE 1.2276098412786833\n",
      "76 Train Loss 0.6562151 Test MSE 6.614581576706612 Test RE 1.2293038697231808\n",
      "77 Train Loss 0.65191305 Test MSE 6.624783305129258 Test RE 1.2302514876695538\n",
      "78 Train Loss 0.647124 Test MSE 6.648245834992961 Test RE 1.2324281098304835\n",
      "79 Train Loss 0.64358664 Test MSE 6.652409275144617 Test RE 1.2328139512776606\n",
      "80 Train Loss 0.63959634 Test MSE 6.660136996281909 Test RE 1.2335297879727074\n",
      "81 Train Loss 0.6355372 Test MSE 6.686096509595127 Test RE 1.235931442052975\n",
      "82 Train Loss 0.6315013 Test MSE 6.699393876254887 Test RE 1.237159847170061\n",
      "83 Train Loss 0.6269476 Test MSE 6.7024814815002065 Test RE 1.2374449043918467\n",
      "84 Train Loss 0.6221579 Test MSE 6.727611846553211 Test RE 1.239762579383068\n",
      "85 Train Loss 0.61841846 Test MSE 6.749812947123339 Test RE 1.2418065010871495\n",
      "86 Train Loss 0.6129279 Test MSE 6.767921596422875 Test RE 1.2434711676687376\n",
      "87 Train Loss 0.6076087 Test MSE 6.789768563909878 Test RE 1.2454765238152612\n",
      "88 Train Loss 0.60266113 Test MSE 6.812970902360006 Test RE 1.2476027613858702\n",
      "89 Train Loss 0.5992891 Test MSE 6.822533247874831 Test RE 1.2484779908330998\n",
      "90 Train Loss 0.5950068 Test MSE 6.838172792533504 Test RE 1.2499081377860097\n",
      "91 Train Loss 0.5913037 Test MSE 6.84291406710851 Test RE 1.2503413771161052\n",
      "92 Train Loss 0.5867153 Test MSE 6.835809458900113 Test RE 1.2496921294090424\n",
      "93 Train Loss 0.58223295 Test MSE 6.844165697811974 Test RE 1.2504557212454501\n",
      "94 Train Loss 0.5786108 Test MSE 6.856199175805423 Test RE 1.2515545201191811\n",
      "95 Train Loss 0.57491946 Test MSE 6.86880704098192 Test RE 1.2527047334304806\n",
      "96 Train Loss 0.5711053 Test MSE 6.889088817458992 Test RE 1.2545528236288004\n",
      "97 Train Loss 0.5671914 Test MSE 6.885456510511426 Test RE 1.2542220453588846\n",
      "98 Train Loss 0.56337506 Test MSE 6.883198279128672 Test RE 1.2540163541423568\n",
      "99 Train Loss 0.5601084 Test MSE 6.90361074458735 Test RE 1.2558744014375078\n",
      "Training time: 194.78\n",
      "7\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.39914 Test MSE 8.293038361299555 Test RE 1.3764641270425888\n",
      "1 Train Loss 45.90289 Test MSE 8.945043482290357 Test RE 1.4295497973516744\n",
      "2 Train Loss 38.892143 Test MSE 8.147978090752678 Test RE 1.3643725919743177\n",
      "3 Train Loss 31.221863 Test MSE 7.02910866271592 Test RE 1.2672380041831544\n",
      "4 Train Loss 26.15974 Test MSE 6.977403688605358 Test RE 1.262568603710446\n",
      "5 Train Loss 21.009846 Test MSE 6.522008236076741 Test RE 1.220671294433123\n",
      "6 Train Loss 17.76646 Test MSE 6.3697304102964205 Test RE 1.2063368271325356\n",
      "7 Train Loss 15.905626 Test MSE 6.452803725112127 Test RE 1.2141777999685006\n",
      "8 Train Loss 14.462991 Test MSE 6.348685652713533 Test RE 1.2043423887456248\n",
      "9 Train Loss 12.820071 Test MSE 6.126353278578233 Test RE 1.1830662870076236\n",
      "10 Train Loss 11.812095 Test MSE 6.0524849422830345 Test RE 1.1759122621221059\n",
      "11 Train Loss 10.846758 Test MSE 5.968503175076864 Test RE 1.1677255289207689\n",
      "12 Train Loss 9.768547 Test MSE 5.7655565054032305 Test RE 1.147700779697035\n",
      "13 Train Loss 8.60849 Test MSE 5.689532271887389 Test RE 1.140108918238714\n",
      "14 Train Loss 7.7073445 Test MSE 5.614196825163719 Test RE 1.1325356389816084\n",
      "15 Train Loss 6.7557554 Test MSE 5.5131354927053025 Test RE 1.1222959437367468\n",
      "16 Train Loss 5.6668787 Test MSE 5.3143475036569 Test RE 1.101876789545931\n",
      "17 Train Loss 4.999118 Test MSE 5.189141145438833 Test RE 1.0888192792972629\n",
      "18 Train Loss 4.425561 Test MSE 5.049097157778111 Test RE 1.07402631967247\n",
      "19 Train Loss 3.8671823 Test MSE 4.761332068278186 Test RE 1.0429711513660174\n",
      "20 Train Loss 3.397382 Test MSE 4.626837317359452 Test RE 1.0281350742734323\n",
      "21 Train Loss 2.997406 Test MSE 4.374578482509245 Test RE 0.9997149034702624\n",
      "22 Train Loss 2.6653144 Test MSE 4.25048015671542 Test RE 0.98543289797155\n",
      "23 Train Loss 2.4039557 Test MSE 3.973139597507608 Test RE 0.9527412578691992\n",
      "24 Train Loss 2.1834888 Test MSE 3.724097038821004 Test RE 0.9223984292222132\n",
      "25 Train Loss 2.0219011 Test MSE 3.4767134810197695 Test RE 0.8912355696168843\n",
      "26 Train Loss 1.8812879 Test MSE 3.1596188847634177 Test RE 0.8496213373597435\n",
      "27 Train Loss 1.7684559 Test MSE 2.9576068857799918 Test RE 0.8220122404875321\n",
      "28 Train Loss 1.6345685 Test MSE 2.677274427647971 Test RE 0.7820859882154892\n",
      "29 Train Loss 1.4793465 Test MSE 2.290614426469148 Test RE 0.7234092474043194\n",
      "30 Train Loss 1.3876107 Test MSE 2.051973315425637 Test RE 0.6846898891398183\n",
      "31 Train Loss 1.2890959 Test MSE 1.8735527771672138 Test RE 0.654245924587885\n",
      "32 Train Loss 1.2116562 Test MSE 1.6358357521724958 Test RE 0.6113330961842749\n",
      "33 Train Loss 1.0338664 Test MSE 1.0730931669502184 Test RE 0.4951385893286192\n",
      "34 Train Loss 0.72394377 Test MSE 0.7540541600627733 Test RE 0.41505851738290983\n",
      "35 Train Loss 0.5721425 Test MSE 0.6382320375885882 Test RE 0.3818540144386214\n",
      "36 Train Loss 0.4381627 Test MSE 0.5529288020486679 Test RE 0.35542065814557466\n",
      "37 Train Loss 0.31747556 Test MSE 0.5041854905375655 Test RE 0.33939327449203144\n",
      "38 Train Loss 0.24885826 Test MSE 0.41660934933740135 Test RE 0.3085123587882319\n",
      "39 Train Loss 0.2097224 Test MSE 0.3801880252589669 Test RE 0.2947184179235779\n",
      "40 Train Loss 0.17315038 Test MSE 0.30422742624413096 Test RE 0.2636375347534137\n",
      "41 Train Loss 0.13405383 Test MSE 0.2486617258876787 Test RE 0.23834855980623312\n",
      "42 Train Loss 0.10037325 Test MSE 0.22272455049608358 Test RE 0.22557559201744531\n",
      "43 Train Loss 0.084164254 Test MSE 0.2034631099310551 Test RE 0.21560106385003053\n",
      "44 Train Loss 0.07038233 Test MSE 0.20275339699330244 Test RE 0.21522470930356963\n",
      "45 Train Loss 0.06260461 Test MSE 0.20704200438127277 Test RE 0.2174889977855516\n",
      "46 Train Loss 0.05554395 Test MSE 0.1937545367243992 Test RE 0.21039431484770427\n",
      "47 Train Loss 0.045722365 Test MSE 0.17864183099589953 Test RE 0.20202245340969283\n",
      "48 Train Loss 0.041193657 Test MSE 0.1664671774275454 Test RE 0.19501695370611732\n",
      "49 Train Loss 0.037979785 Test MSE 0.1612047148396849 Test RE 0.19190970158823453\n",
      "50 Train Loss 0.034578003 Test MSE 0.16444264051241383 Test RE 0.19382744953794245\n",
      "51 Train Loss 0.031287253 Test MSE 0.1642395271328015 Test RE 0.19370770835496784\n",
      "52 Train Loss 0.029072726 Test MSE 0.15586807518425147 Test RE 0.18870640733583452\n",
      "53 Train Loss 0.026727121 Test MSE 0.14778671412288433 Test RE 0.1837493268963074\n",
      "54 Train Loss 0.02369257 Test MSE 0.1367142468508556 Test RE 0.1767319003915271\n",
      "55 Train Loss 0.022214722 Test MSE 0.13223285752981306 Test RE 0.17381119753743268\n",
      "56 Train Loss 0.021073837 Test MSE 0.12772537458920988 Test RE 0.17082312118920015\n",
      "57 Train Loss 0.019470775 Test MSE 0.1200600970291355 Test RE 0.16561795022491896\n",
      "58 Train Loss 0.017818388 Test MSE 0.12263310853219038 Test RE 0.16738322405687586\n",
      "59 Train Loss 0.01605572 Test MSE 0.1209692599218713 Test RE 0.16624384390394523\n",
      "60 Train Loss 0.014580964 Test MSE 0.11837775348916123 Test RE 0.1644534948472938\n",
      "61 Train Loss 0.013586794 Test MSE 0.11886104529017547 Test RE 0.16478885376315416\n",
      "62 Train Loss 0.012460184 Test MSE 0.114787420396994 Test RE 0.16194040025595444\n",
      "63 Train Loss 0.01190254 Test MSE 0.10930900070506368 Test RE 0.15802871995369064\n",
      "64 Train Loss 0.011310424 Test MSE 0.1062737629614595 Test RE 0.15581924277188705\n",
      "65 Train Loss 0.010823598 Test MSE 0.10495789482684613 Test RE 0.15485157108212996\n",
      "66 Train Loss 0.009996051 Test MSE 0.10067824006666526 Test RE 0.15166168187450632\n",
      "67 Train Loss 0.009363081 Test MSE 0.09873780558567252 Test RE 0.1501930358433256\n",
      "68 Train Loss 0.008857551 Test MSE 0.09659428367599726 Test RE 0.14855380268860616\n",
      "69 Train Loss 0.008483287 Test MSE 0.09359213684728751 Test RE 0.14622705780739162\n",
      "70 Train Loss 0.008181779 Test MSE 0.0925075521279986 Test RE 0.1453773187823996\n",
      "71 Train Loss 0.007816175 Test MSE 0.08921929624314084 Test RE 0.1427701635073458\n",
      "72 Train Loss 0.007376963 Test MSE 0.08392703105736476 Test RE 0.1384710515740134\n",
      "73 Train Loss 0.007038285 Test MSE 0.082411958757908 Test RE 0.13721550191505516\n",
      "74 Train Loss 0.0067908787 Test MSE 0.0811790901066007 Test RE 0.13618527429961957\n",
      "75 Train Loss 0.006421769 Test MSE 0.07754945107312948 Test RE 0.1331059361760151\n",
      "76 Train Loss 0.0060073594 Test MSE 0.07545865814330338 Test RE 0.13129935700691828\n",
      "77 Train Loss 0.0057806917 Test MSE 0.07488447649141987 Test RE 0.13079886013884012\n",
      "78 Train Loss 0.0055364906 Test MSE 0.07356177280920091 Test RE 0.1296385467043851\n",
      "79 Train Loss 0.005315562 Test MSE 0.07041639866618424 Test RE 0.12683670909086026\n",
      "80 Train Loss 0.005014872 Test MSE 0.06687920679569381 Test RE 0.12361000303516351\n",
      "81 Train Loss 0.0048621194 Test MSE 0.06468734848187542 Test RE 0.12156756985984483\n",
      "82 Train Loss 0.0046568355 Test MSE 0.06090415705530471 Test RE 0.11795912126946498\n",
      "83 Train Loss 0.004430842 Test MSE 0.05810037659901498 Test RE 0.11521195178695227\n",
      "84 Train Loss 0.004266558 Test MSE 0.05622435244100896 Test RE 0.11333662905398124\n",
      "85 Train Loss 0.0041527534 Test MSE 0.0546157634186635 Test RE 0.11170357292397194\n",
      "86 Train Loss 0.004014266 Test MSE 0.05358330346561357 Test RE 0.11064270953175466\n",
      "87 Train Loss 0.0038188098 Test MSE 0.05115118296585459 Test RE 0.10810254073341757\n",
      "88 Train Loss 0.0036323902 Test MSE 0.046888989456417986 Test RE 0.10350074998473063\n",
      "89 Train Loss 0.0035094009 Test MSE 0.04575015798568918 Test RE 0.10223612006615965\n",
      "90 Train Loss 0.0032452513 Test MSE 0.043821645137893994 Test RE 0.10005813393540774\n",
      "91 Train Loss 0.0031122065 Test MSE 0.042130241866607014 Test RE 0.09810813871874974\n",
      "92 Train Loss 0.0030400455 Test MSE 0.041295379578845395 Test RE 0.09713120833337605\n",
      "93 Train Loss 0.0029549724 Test MSE 0.04068394043775739 Test RE 0.09640944109851801\n",
      "94 Train Loss 0.0028752862 Test MSE 0.039446546409593594 Test RE 0.09493198313231498\n",
      "95 Train Loss 0.0028182378 Test MSE 0.038270528207411156 Test RE 0.09350617425169865\n",
      "96 Train Loss 0.002734607 Test MSE 0.037311346899070244 Test RE 0.09232695738621571\n",
      "97 Train Loss 0.0026500905 Test MSE 0.03673918160367568 Test RE 0.09161631070119797\n",
      "98 Train Loss 0.002594027 Test MSE 0.03631815653834128 Test RE 0.09108984401501553\n",
      "99 Train Loss 0.0025404831 Test MSE 0.03581625209356146 Test RE 0.09045823910932979\n",
      "Training time: 195.00\n",
      "8\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.59972 Test MSE 5.496114589774692 Test RE 1.1205621520405848\n",
      "1 Train Loss 59.60016 Test MSE 6.34403346963615 Test RE 1.2039010495164972\n",
      "2 Train Loss 42.643456 Test MSE 8.613243368623134 Test RE 1.4027859889995407\n",
      "3 Train Loss 30.845037 Test MSE 7.980485907011158 Test RE 1.3502765573571056\n",
      "4 Train Loss 23.987839 Test MSE 7.533308412415468 Test RE 1.3119006104538902\n",
      "5 Train Loss 19.235756 Test MSE 7.090895380343452 Test RE 1.27279540621682\n",
      "6 Train Loss 16.813972 Test MSE 7.038255248001954 Test RE 1.2680622290488435\n",
      "7 Train Loss 15.293325 Test MSE 7.2532799027729995 Test RE 1.2872866899738917\n",
      "8 Train Loss 14.209045 Test MSE 7.11263102989882 Test RE 1.274744657017694\n",
      "9 Train Loss 13.062229 Test MSE 6.932737926839638 Test RE 1.2585209570693152\n",
      "10 Train Loss 11.956711 Test MSE 6.997551926941823 Test RE 1.264390212177302\n",
      "11 Train Loss 10.767612 Test MSE 6.806643239053289 Test RE 1.247023260592706\n",
      "12 Train Loss 9.645283 Test MSE 6.713580858098439 Test RE 1.238469091141582\n",
      "13 Train Loss 8.4737425 Test MSE 6.540161570418473 Test RE 1.2223689200150425\n",
      "14 Train Loss 7.5058346 Test MSE 6.434372379983425 Test RE 1.212442512928491\n",
      "15 Train Loss 6.5715003 Test MSE 6.268895359024614 Test RE 1.19675037044849\n",
      "16 Train Loss 5.762637 Test MSE 6.23855793712394 Test RE 1.1938511074815934\n",
      "17 Train Loss 5.1539927 Test MSE 6.12409734308385 Test RE 1.1828484439572593\n",
      "18 Train Loss 4.5996504 Test MSE 6.037328418776023 Test RE 1.174438990081554\n",
      "19 Train Loss 4.1418943 Test MSE 5.911457633930307 Test RE 1.162131708571275\n",
      "20 Train Loss 3.6401806 Test MSE 5.920441054983658 Test RE 1.1630143973957796\n",
      "21 Train Loss 3.1056957 Test MSE 5.723900647725928 Test RE 1.1435472233933182\n",
      "22 Train Loss 2.8112817 Test MSE 5.646950549038661 Test RE 1.135834491379236\n",
      "23 Train Loss 2.501411 Test MSE 5.434347256884385 Test RE 1.1142477186169197\n",
      "24 Train Loss 2.2714381 Test MSE 5.3306988188081705 Test RE 1.1035706284434001\n",
      "25 Train Loss 2.0785098 Test MSE 5.110090156382995 Test RE 1.0804939549383228\n",
      "26 Train Loss 1.9480658 Test MSE 4.8847913032419985 Test RE 1.0564065058995793\n",
      "27 Train Loss 1.81635 Test MSE 4.795197284591152 Test RE 1.0466736720990306\n",
      "28 Train Loss 1.7096977 Test MSE 4.6458504506024205 Test RE 1.0302453741047508\n",
      "29 Train Loss 1.644414 Test MSE 4.565844144794459 Test RE 1.021335909433668\n",
      "30 Train Loss 1.5865406 Test MSE 4.451325500229293 Test RE 1.0084462068108448\n",
      "31 Train Loss 1.5360829 Test MSE 4.327336276171862 Test RE 0.9943021602809227\n",
      "32 Train Loss 1.4943273 Test MSE 4.304595887481794 Test RE 0.9916861628480244\n",
      "33 Train Loss 1.4629034 Test MSE 4.235504802181091 Test RE 0.983695420366303\n",
      "34 Train Loss 1.4310844 Test MSE 4.130967677422951 Test RE 0.9714802115480914\n",
      "35 Train Loss 1.3937814 Test MSE 4.040211746416793 Test RE 0.9607494040880291\n",
      "36 Train Loss 1.3562522 Test MSE 3.8648317736691506 Test RE 0.9396656640080135\n",
      "37 Train Loss 1.3042457 Test MSE 3.675476366151555 Test RE 0.9163573709088056\n",
      "38 Train Loss 1.2417051 Test MSE 3.4578214050115754 Test RE 0.888810833502819\n",
      "39 Train Loss 1.1834038 Test MSE 3.300788872464866 Test RE 0.8683942388165355\n",
      "40 Train Loss 1.1335765 Test MSE 3.19033221173285 Test RE 0.8537407567164342\n",
      "41 Train Loss 1.0889113 Test MSE 3.0841621729747897 Test RE 0.8394148797923516\n",
      "42 Train Loss 1.0490698 Test MSE 2.9735946555135864 Test RE 0.8242309988168277\n",
      "43 Train Loss 0.9990907 Test MSE 2.866973041272466 Test RE 0.8093192397322572\n",
      "44 Train Loss 0.963681 Test MSE 2.7836577121556663 Test RE 0.7974729782357205\n",
      "45 Train Loss 0.9251853 Test MSE 2.735099859823326 Test RE 0.7904868576606596\n",
      "46 Train Loss 0.875141 Test MSE 2.697136925462278 Test RE 0.7849817458792525\n",
      "47 Train Loss 0.83832717 Test MSE 2.64730277363649 Test RE 0.7776960043010924\n",
      "48 Train Loss 0.80159295 Test MSE 2.604047383206065 Test RE 0.7713162861378816\n",
      "49 Train Loss 0.76547706 Test MSE 2.5926639967299634 Test RE 0.7696285657175524\n",
      "50 Train Loss 0.74512804 Test MSE 2.6224694907769845 Test RE 0.7740397829570347\n",
      "51 Train Loss 0.72558355 Test MSE 2.658824461913361 Test RE 0.7793865254551903\n",
      "52 Train Loss 0.7053339 Test MSE 2.6812530855261523 Test RE 0.7826668956785598\n",
      "53 Train Loss 0.6887934 Test MSE 2.694413364058704 Test RE 0.7845853095765456\n",
      "54 Train Loss 0.66874856 Test MSE 2.6670016531791174 Test RE 0.7805841035815515\n",
      "55 Train Loss 0.6566632 Test MSE 2.6599641509166716 Test RE 0.7795535472159117\n",
      "56 Train Loss 0.64255226 Test MSE 2.6835670384568977 Test RE 0.7830045482103264\n",
      "57 Train Loss 0.6327421 Test MSE 2.6767449773889407 Test RE 0.7820086528294711\n",
      "58 Train Loss 0.62592924 Test MSE 2.671781283559522 Test RE 0.7812832470214884\n",
      "59 Train Loss 0.62020093 Test MSE 2.6745061339284866 Test RE 0.7816815463587597\n",
      "60 Train Loss 0.61271775 Test MSE 2.6723193169507793 Test RE 0.7813619090207298\n",
      "61 Train Loss 0.6060374 Test MSE 2.6777109538261525 Test RE 0.7821497446778085\n",
      "62 Train Loss 0.60014415 Test MSE 2.686290875802471 Test RE 0.7834018246857395\n",
      "63 Train Loss 0.5961053 Test MSE 2.690131508046671 Test RE 0.783961645605726\n",
      "64 Train Loss 0.5903868 Test MSE 2.68266048997092 Test RE 0.7828722818023067\n",
      "65 Train Loss 0.5852281 Test MSE 2.680034030434297 Test RE 0.7824889522864786\n",
      "66 Train Loss 0.58087057 Test MSE 2.7003634239282825 Test RE 0.7854511297967135\n",
      "67 Train Loss 0.57709706 Test MSE 2.7087599019328246 Test RE 0.7866713182368656\n",
      "68 Train Loss 0.57353485 Test MSE 2.7086120538868186 Test RE 0.7866498491128815\n",
      "69 Train Loss 0.56930166 Test MSE 2.7130631771605125 Test RE 0.7872959435053907\n",
      "70 Train Loss 0.5658789 Test MSE 2.726924880691855 Test RE 0.7893046248580098\n",
      "71 Train Loss 0.56258833 Test MSE 2.7317427781471335 Test RE 0.7900015840174838\n",
      "72 Train Loss 0.5580865 Test MSE 2.7271016051625385 Test RE 0.7893302007701145\n",
      "73 Train Loss 0.55359006 Test MSE 2.7376326015710792 Test RE 0.7908527740603137\n",
      "74 Train Loss 0.55111873 Test MSE 2.743306728432549 Test RE 0.791671926378644\n",
      "75 Train Loss 0.54732895 Test MSE 2.7350433429083694 Test RE 0.7904786904800096\n",
      "76 Train Loss 0.5429663 Test MSE 2.7364333982146674 Test RE 0.7906795409568699\n",
      "77 Train Loss 0.5388644 Test MSE 2.7326027761446947 Test RE 0.7901259270417595\n",
      "78 Train Loss 0.53552806 Test MSE 2.734038931810228 Test RE 0.7903335303532906\n",
      "79 Train Loss 0.53330755 Test MSE 2.7487629940908143 Test RE 0.7924588282939867\n",
      "80 Train Loss 0.52972746 Test MSE 2.759765996576936 Test RE 0.7940433079609571\n",
      "81 Train Loss 0.5266955 Test MSE 2.7546191090325083 Test RE 0.793302527970578\n",
      "82 Train Loss 0.52337587 Test MSE 2.759974778232638 Test RE 0.7940733428518563\n",
      "83 Train Loss 0.5200153 Test MSE 2.762659211940734 Test RE 0.7944594186945592\n",
      "84 Train Loss 0.51710355 Test MSE 2.7697596668725057 Test RE 0.7954797043945339\n",
      "85 Train Loss 0.51405853 Test MSE 2.7793710581189606 Test RE 0.7968587130865383\n",
      "86 Train Loss 0.511183 Test MSE 2.7844713941172925 Test RE 0.7975895230901188\n",
      "87 Train Loss 0.5083044 Test MSE 2.791567453679599 Test RE 0.7986051811216728\n",
      "88 Train Loss 0.5055144 Test MSE 2.7952535743180342 Test RE 0.7991322656290075\n",
      "89 Train Loss 0.50327307 Test MSE 2.7989237909655147 Test RE 0.7996567308219097\n",
      "90 Train Loss 0.50059843 Test MSE 2.817115088498337 Test RE 0.8022511626067692\n",
      "91 Train Loss 0.49728602 Test MSE 2.829881890140536 Test RE 0.8040669570095257\n",
      "92 Train Loss 0.49392325 Test MSE 2.8360753245325196 Test RE 0.8049463601725763\n",
      "93 Train Loss 0.49085924 Test MSE 2.8648453435832244 Test RE 0.8090188695754406\n",
      "94 Train Loss 0.48774588 Test MSE 2.8801753823190945 Test RE 0.8111805470711121\n",
      "95 Train Loss 0.48452342 Test MSE 2.893892343364179 Test RE 0.8131098940410686\n",
      "96 Train Loss 0.48047966 Test MSE 2.914143656100118 Test RE 0.8159499850246467\n",
      "97 Train Loss 0.4745343 Test MSE 2.9414818328352252 Test RE 0.8197683474373079\n",
      "98 Train Loss 0.4704851 Test MSE 2.9495714930122516 Test RE 0.8208948364661444\n",
      "99 Train Loss 0.46636948 Test MSE 2.961501333822774 Test RE 0.8225532574228609\n",
      "Training time: 195.16\n",
      "9\n",
      "KG_rowdy_tune50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.282898 Test MSE 8.485847156656547 Test RE 1.3923732235730897\n",
      "1 Train Loss 49.24099 Test MSE 8.54456395734584 Test RE 1.3971820989886534\n",
      "2 Train Loss 42.724564 Test MSE 8.452118563172329 Test RE 1.3896033440225866\n",
      "3 Train Loss 39.55482 Test MSE 8.871609921697507 Test RE 1.4236698220025292\n",
      "4 Train Loss 37.562935 Test MSE 9.13788879651244 Test RE 1.4448773882273198\n",
      "5 Train Loss 35.622276 Test MSE 9.263627002129105 Test RE 1.4547842489187452\n",
      "6 Train Loss 33.635246 Test MSE 9.319359894903586 Test RE 1.4591539061984522\n",
      "7 Train Loss 31.80385 Test MSE 9.604508080682331 Test RE 1.481308870131133\n",
      "8 Train Loss 29.763102 Test MSE 9.43979769192392 Test RE 1.4685522523671815\n",
      "9 Train Loss 28.164024 Test MSE 9.47467292776971 Test RE 1.471262527028764\n",
      "10 Train Loss 26.438793 Test MSE 9.469161756953815 Test RE 1.4708345672134404\n",
      "11 Train Loss 24.74706 Test MSE 9.402691527501831 Test RE 1.4656631016380384\n",
      "12 Train Loss 23.146734 Test MSE 9.305324717527157 Test RE 1.4580547319749526\n",
      "13 Train Loss 21.415695 Test MSE 9.201213090736958 Test RE 1.4498751440767523\n",
      "14 Train Loss 18.942291 Test MSE 9.0010758477613 Test RE 1.4340202064997627\n",
      "15 Train Loss 17.605667 Test MSE 8.929783755877972 Test RE 1.428329912262633\n",
      "16 Train Loss 16.352304 Test MSE 8.918588986821064 Test RE 1.4274343229363924\n",
      "17 Train Loss 15.357763 Test MSE 8.834651280054231 Test RE 1.4207012617601475\n",
      "18 Train Loss 14.194329 Test MSE 8.363118148620332 Test RE 1.3822677528347693\n",
      "19 Train Loss 12.813086 Test MSE 7.724759406795396 Test RE 1.3284662980059736\n",
      "20 Train Loss 9.747233 Test MSE 6.835512923615483 Test RE 1.2496650234874622\n",
      "21 Train Loss 8.610755 Test MSE 6.664403771981522 Test RE 1.2339248513354113\n",
      "22 Train Loss 7.9368525 Test MSE 6.6264545577611145 Test RE 1.2304066573774675\n",
      "23 Train Loss 7.467023 Test MSE 6.452384203075988 Test RE 1.2141383301005217\n",
      "24 Train Loss 7.0532722 Test MSE 6.40259586516399 Test RE 1.2094449492025772\n",
      "25 Train Loss 6.6781907 Test MSE 6.509018431666062 Test RE 1.219455090477762\n",
      "26 Train Loss 6.3144007 Test MSE 6.371766007587998 Test RE 1.2065295683997277\n",
      "27 Train Loss 6.0917687 Test MSE 6.36587350841815 Test RE 1.2059715505039046\n",
      "28 Train Loss 5.751838 Test MSE 6.381328475027189 Test RE 1.2074345823501422\n",
      "29 Train Loss 5.4934063 Test MSE 6.492729111200189 Test RE 1.217928244425352\n",
      "30 Train Loss 5.289608 Test MSE 6.555301238492799 Test RE 1.223782918886841\n",
      "31 Train Loss 5.0349026 Test MSE 6.4971359069566175 Test RE 1.21834149519601\n",
      "32 Train Loss 4.880206 Test MSE 6.602042356544426 Test RE 1.2281381252297192\n",
      "33 Train Loss 4.741241 Test MSE 6.584507388901526 Test RE 1.2265060786918085\n",
      "34 Train Loss 4.5583754 Test MSE 6.583769958783974 Test RE 1.2264373956610557\n",
      "35 Train Loss 4.361253 Test MSE 6.597826244882708 Test RE 1.2277459136890954\n",
      "36 Train Loss 4.1998525 Test MSE 6.549239060035044 Test RE 1.2232169261010544\n",
      "37 Train Loss 3.9750047 Test MSE 6.494880125963517 Test RE 1.2181299750570138\n",
      "38 Train Loss 3.7477283 Test MSE 6.4308661974623185 Test RE 1.2121121291888373\n",
      "39 Train Loss 3.5308018 Test MSE 6.541845560096809 Test RE 1.2225262803595989\n",
      "40 Train Loss 3.2598553 Test MSE 6.452375207217251 Test RE 1.2141374837296015\n",
      "41 Train Loss 2.9046335 Test MSE 6.282353715199967 Test RE 1.1980343014003276\n",
      "42 Train Loss 2.5984774 Test MSE 6.252441821925408 Test RE 1.1951788245277801\n",
      "43 Train Loss 2.2812867 Test MSE 6.052900548701463 Test RE 1.1759526346549505\n",
      "44 Train Loss 1.9738605 Test MSE 6.007118323477119 Test RE 1.1714969263826756\n",
      "45 Train Loss 1.8180615 Test MSE 5.9638906878953275 Test RE 1.1672742298360184\n",
      "46 Train Loss 1.6549101 Test MSE 5.874865433390508 Test RE 1.1585293002052437\n",
      "47 Train Loss 1.5318996 Test MSE 5.915592378377536 Test RE 1.1625380616224432\n",
      "48 Train Loss 1.4557983 Test MSE 5.883449045139779 Test RE 1.159375339668957\n",
      "49 Train Loss 1.3782023 Test MSE 5.86837656150946 Test RE 1.157889317448068\n",
      "50 Train Loss 1.3105655 Test MSE 5.86260707991009 Test RE 1.1573199893034705\n",
      "51 Train Loss 1.2680476 Test MSE 5.898098904876329 Test RE 1.1608178716006665\n",
      "52 Train Loss 1.2021612 Test MSE 5.933657441731067 Test RE 1.1643117905528602\n",
      "53 Train Loss 1.1246752 Test MSE 6.030794629727341 Test RE 1.1738033104116792\n",
      "54 Train Loss 1.0937192 Test MSE 6.066293134118761 Test RE 1.177252866176978\n",
      "55 Train Loss 1.0609417 Test MSE 6.0671421044259155 Test RE 1.1773352408446458\n",
      "56 Train Loss 1.0284358 Test MSE 6.075236263807409 Test RE 1.1781203191158933\n",
      "57 Train Loss 1.0056103 Test MSE 6.081782527810762 Test RE 1.178754879638373\n",
      "58 Train Loss 0.98715514 Test MSE 6.105502402661965 Test RE 1.1810513041775716\n",
      "59 Train Loss 0.9656423 Test MSE 6.102918093382089 Test RE 1.1808013227106113\n",
      "60 Train Loss 0.94188464 Test MSE 6.07755461406727 Test RE 1.1783450869198917\n",
      "61 Train Loss 0.9221597 Test MSE 6.089942177817127 Test RE 1.1795453553990067\n",
      "62 Train Loss 0.9090682 Test MSE 6.085419263473868 Test RE 1.179107258174699\n",
      "63 Train Loss 0.8969754 Test MSE 6.108232073917389 Test RE 1.181315289131454\n",
      "64 Train Loss 0.8836533 Test MSE 6.118364129714667 Test RE 1.1822946390415954\n",
      "65 Train Loss 0.8761629 Test MSE 6.125731060438356 Test RE 1.1830062068944698\n",
      "66 Train Loss 0.865957 Test MSE 6.15731437609606 Test RE 1.1860519839663686\n",
      "67 Train Loss 0.8581964 Test MSE 6.169622256603662 Test RE 1.1872367942254933\n",
      "68 Train Loss 0.8451116 Test MSE 6.182246144153059 Test RE 1.1884507976406304\n",
      "69 Train Loss 0.8362422 Test MSE 6.185211824781667 Test RE 1.1887358188801713\n",
      "70 Train Loss 0.82027155 Test MSE 6.1770215291825545 Test RE 1.1879485117329829\n",
      "71 Train Loss 0.81234676 Test MSE 6.2143022656543 Test RE 1.1915279855021441\n",
      "72 Train Loss 0.80189013 Test MSE 6.234626031427805 Test RE 1.193474830633939\n",
      "73 Train Loss 0.795672 Test MSE 6.223235717018907 Test RE 1.1923841262304813\n",
      "74 Train Loss 0.7883527 Test MSE 6.231168718840562 Test RE 1.1931438735144464\n",
      "75 Train Loss 0.77620196 Test MSE 6.259880588562725 Test RE 1.1958895879225446\n",
      "76 Train Loss 0.77028054 Test MSE 6.254499735474664 Test RE 1.1953754974769666\n",
      "77 Train Loss 0.7606517 Test MSE 6.263325483649499 Test RE 1.1962185995929817\n",
      "78 Train Loss 0.7539823 Test MSE 6.299245803274393 Test RE 1.1996438665824094\n",
      "79 Train Loss 0.7466782 Test MSE 6.311744375040358 Test RE 1.2008334061986368\n",
      "80 Train Loss 0.74224234 Test MSE 6.307060993546781 Test RE 1.2003878079405184\n",
      "81 Train Loss 0.7382888 Test MSE 6.333493269249013 Test RE 1.2029005319917645\n",
      "82 Train Loss 0.73338354 Test MSE 6.366551277896616 Test RE 1.2060357482100565\n",
      "83 Train Loss 0.7273066 Test MSE 6.370464350904047 Test RE 1.2064063241146905\n",
      "84 Train Loss 0.7229365 Test MSE 6.373051007068868 Test RE 1.2066512231896223\n",
      "85 Train Loss 0.71874404 Test MSE 6.392335483286433 Test RE 1.2084754719079012\n",
      "86 Train Loss 0.713339 Test MSE 6.40091599117663 Test RE 1.2092862754055087\n",
      "87 Train Loss 0.7074307 Test MSE 6.418124161847293 Test RE 1.210910702075141\n",
      "88 Train Loss 0.7013842 Test MSE 6.45702941555563 Test RE 1.214575293836206\n",
      "89 Train Loss 0.69651604 Test MSE 6.478676857515411 Test RE 1.2166095457140438\n",
      "90 Train Loss 0.69144475 Test MSE 6.4683563530887875 Test RE 1.2156401326002069\n",
      "91 Train Loss 0.68652254 Test MSE 6.4644181410611505 Test RE 1.2152700093994353\n",
      "92 Train Loss 0.6829097 Test MSE 6.479211858949386 Test RE 1.2166597777621169\n",
      "93 Train Loss 0.67948014 Test MSE 6.495612154269083 Test RE 1.2181986199342105\n",
      "94 Train Loss 0.67378783 Test MSE 6.524189903583106 Test RE 1.2208754398537154\n",
      "95 Train Loss 0.66857666 Test MSE 6.534614147352345 Test RE 1.221850397956764\n",
      "96 Train Loss 0.6635099 Test MSE 6.533484886529105 Test RE 1.2217448180884403\n",
      "97 Train Loss 0.6608857 Test MSE 6.52389732862076 Test RE 1.2208480646856248\n",
      "98 Train Loss 0.65853524 Test MSE 6.524681834777497 Test RE 1.2209214666709454\n",
      "99 Train Loss 0.6559843 Test MSE 6.526139107068982 Test RE 1.2210578040229985\n",
      "Training time: 195.48\n",
      "0\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.897934 Test MSE 4.590603757855257 Test RE 1.0241014102966965\n",
      "1 Train Loss 64.151566 Test MSE 5.1462292811425305 Test RE 1.084307910226869\n",
      "2 Train Loss 49.494026 Test MSE 8.06873395793475 Test RE 1.3577216972529127\n",
      "3 Train Loss 39.424488 Test MSE 7.311124043796839 Test RE 1.2924094845045158\n",
      "4 Train Loss 32.85249 Test MSE 7.272903427988293 Test RE 1.2890268709987625\n",
      "5 Train Loss 26.87942 Test MSE 6.6149982564249115 Test RE 1.2293425885686322\n",
      "6 Train Loss 21.952065 Test MSE 6.145762336851882 Test RE 1.1849388564978238\n",
      "7 Train Loss 18.233665 Test MSE 5.1162027168677 Test RE 1.0811399915611606\n",
      "8 Train Loss 14.620501 Test MSE 5.989718710447828 Test RE 1.1697990761185422\n",
      "9 Train Loss 12.637747 Test MSE 5.588577149438809 Test RE 1.1299485927612398\n",
      "10 Train Loss 10.942707 Test MSE 5.460185714969552 Test RE 1.1168935103338995\n",
      "11 Train Loss 9.730202 Test MSE 5.439436027553995 Test RE 1.1147692922362957\n",
      "12 Train Loss 8.796774 Test MSE 5.461836803532028 Test RE 1.117062364546062\n",
      "13 Train Loss 7.8764176 Test MSE 5.075814790521155 Test RE 1.0768642111823787\n",
      "14 Train Loss 6.955282 Test MSE 5.134242167214966 Test RE 1.083044334561079\n",
      "15 Train Loss 6.2972126 Test MSE 5.048915693048437 Test RE 1.0740070192271762\n",
      "16 Train Loss 5.6333065 Test MSE 4.75132912153856 Test RE 1.041875001173502\n",
      "17 Train Loss 5.1408434 Test MSE 4.632926786907186 Test RE 1.0288114259756895\n",
      "18 Train Loss 4.5769362 Test MSE 4.430757701236546 Test RE 1.006113695521743\n",
      "19 Train Loss 4.2840185 Test MSE 4.32334130404364 Test RE 0.9938430872660842\n",
      "20 Train Loss 3.914867 Test MSE 4.141711691805947 Test RE 0.972742726816093\n",
      "21 Train Loss 3.5901327 Test MSE 4.089686598520544 Test RE 0.9666139855053352\n",
      "22 Train Loss 3.347468 Test MSE 3.9802139839682558 Test RE 0.9535890838892924\n",
      "23 Train Loss 3.1045496 Test MSE 3.8126383187516772 Test RE 0.9332991375176842\n",
      "24 Train Loss 2.8414483 Test MSE 3.645363288623227 Test RE 0.9125958049994585\n",
      "25 Train Loss 2.6579833 Test MSE 3.569349247463111 Test RE 0.9030308397891836\n",
      "26 Train Loss 2.5377908 Test MSE 3.4581489110091868 Test RE 0.8888529241651627\n",
      "27 Train Loss 2.3470373 Test MSE 3.202768535090377 Test RE 0.8554031336313946\n",
      "28 Train Loss 2.2348852 Test MSE 3.1561211378128533 Test RE 0.8491509351606125\n",
      "29 Train Loss 2.0941968 Test MSE 3.0458554743199455 Test RE 0.8341856341246959\n",
      "30 Train Loss 1.953316 Test MSE 2.9412994786709117 Test RE 0.8197429366924286\n",
      "31 Train Loss 1.8472496 Test MSE 2.811804267336715 Test RE 0.8014946045256376\n",
      "32 Train Loss 1.7162206 Test MSE 2.624582338514235 Test RE 0.7743515308988229\n",
      "33 Train Loss 1.6397955 Test MSE 2.5079384210883253 Test RE 0.7569487823162578\n",
      "34 Train Loss 1.5250511 Test MSE 2.442354489665213 Test RE 0.7469859094148054\n",
      "35 Train Loss 1.4706882 Test MSE 2.381760702211208 Test RE 0.7376615094905402\n",
      "36 Train Loss 1.4157926 Test MSE 2.255626630872302 Test RE 0.7178631610347566\n",
      "37 Train Loss 1.3481256 Test MSE 1.9690315682530972 Test RE 0.6707094104048152\n",
      "38 Train Loss 1.2685783 Test MSE 1.6699487596880755 Test RE 0.6176744441267218\n",
      "39 Train Loss 1.1987247 Test MSE 1.6940832043968588 Test RE 0.6221218125756237\n",
      "40 Train Loss 1.122496 Test MSE 1.6121386834086402 Test RE 0.6068889915067336\n",
      "41 Train Loss 1.0608999 Test MSE 1.5877775876043463 Test RE 0.6022861743710057\n",
      "42 Train Loss 0.9989929 Test MSE 1.5409708980219698 Test RE 0.5933422562718762\n",
      "43 Train Loss 0.9500179 Test MSE 1.3824502564412289 Test RE 0.561995472659122\n",
      "44 Train Loss 0.8949046 Test MSE 1.283474275741431 Test RE 0.5415039695530308\n",
      "45 Train Loss 0.8198137 Test MSE 1.2458374385483504 Test RE 0.5335053134228948\n",
      "46 Train Loss 0.7542964 Test MSE 1.1880856484946807 Test RE 0.5209930563729068\n",
      "47 Train Loss 0.71962005 Test MSE 1.0926309741066789 Test RE 0.4996257511371124\n",
      "48 Train Loss 0.6826752 Test MSE 1.0150423641303528 Test RE 0.4815597103044205\n",
      "49 Train Loss 0.6477505 Test MSE 0.9099865326732025 Test RE 0.455958737840245\n",
      "50 Train Loss 0.59667885 Test MSE 0.7481794881320746 Test RE 0.41343854068155733\n",
      "51 Train Loss 0.5236952 Test MSE 0.5558828450025038 Test RE 0.35636881756559624\n",
      "52 Train Loss 0.47557196 Test MSE 0.5009330523199608 Test RE 0.3382968113333508\n",
      "53 Train Loss 0.4159412 Test MSE 0.40633452397579106 Test RE 0.3046841918658042\n",
      "54 Train Loss 0.3466326 Test MSE 0.32022017841120914 Test RE 0.2704782873586232\n",
      "55 Train Loss 0.29683357 Test MSE 0.25122256212279614 Test RE 0.23957272929293633\n",
      "56 Train Loss 0.25636432 Test MSE 0.22505492878707198 Test RE 0.22675262563013612\n",
      "57 Train Loss 0.21612667 Test MSE 0.20969292484325644 Test RE 0.21887691002312046\n",
      "58 Train Loss 0.17042682 Test MSE 0.16651045103461118 Test RE 0.1950422996595554\n",
      "59 Train Loss 0.13652997 Test MSE 0.14107662973897195 Test RE 0.17952940778759913\n",
      "60 Train Loss 0.10874546 Test MSE 0.13040183335620514 Test RE 0.17260362359289633\n",
      "61 Train Loss 0.089299075 Test MSE 0.11687971725707881 Test RE 0.16340962616239801\n",
      "62 Train Loss 0.08006478 Test MSE 0.111766406708381 Test RE 0.15979519077547838\n",
      "63 Train Loss 0.07328418 Test MSE 0.10894287027609285 Test RE 0.15776383941440114\n",
      "64 Train Loss 0.065746106 Test MSE 0.09946426651958962 Test RE 0.1507445440269791\n",
      "65 Train Loss 0.060190395 Test MSE 0.08815859119685808 Test RE 0.1419189472694967\n",
      "66 Train Loss 0.052145876 Test MSE 0.08161863065349916 Test RE 0.13655346112323363\n",
      "67 Train Loss 0.047638733 Test MSE 0.07971441860594367 Test RE 0.13495112264093437\n",
      "68 Train Loss 0.043912843 Test MSE 0.07108124449734644 Test RE 0.12743407523852127\n",
      "69 Train Loss 0.04014968 Test MSE 0.06384714917666026 Test RE 0.12077549204770596\n",
      "70 Train Loss 0.03614927 Test MSE 0.04967732171545346 Test RE 0.10653373343699513\n",
      "71 Train Loss 0.03237636 Test MSE 0.04025759444930221 Test RE 0.09590295091583277\n",
      "72 Train Loss 0.029414589 Test MSE 0.042131698756694806 Test RE 0.0981098350244537\n",
      "73 Train Loss 0.027109137 Test MSE 0.036917859148124364 Test RE 0.09183882412894494\n",
      "74 Train Loss 0.025321713 Test MSE 0.03508391391740667 Test RE 0.08952865882800748\n",
      "75 Train Loss 0.022904309 Test MSE 0.03376944505218623 Test RE 0.08783548873664487\n",
      "76 Train Loss 0.01931834 Test MSE 0.02950829160205886 Test RE 0.08210698284062636\n",
      "77 Train Loss 0.01734272 Test MSE 0.02933415044392304 Test RE 0.0818643499779575\n",
      "78 Train Loss 0.015795268 Test MSE 0.027072701934178926 Test RE 0.07864549697648884\n",
      "79 Train Loss 0.014434208 Test MSE 0.023907665053585242 Test RE 0.07390547994229929\n",
      "80 Train Loss 0.0136391185 Test MSE 0.02297068879117744 Test RE 0.07244277353043842\n",
      "81 Train Loss 0.013071383 Test MSE 0.021618341383318637 Test RE 0.07027797604137685\n",
      "82 Train Loss 0.01270586 Test MSE 0.021052523204886184 Test RE 0.06935218327476114\n",
      "83 Train Loss 0.011747337 Test MSE 0.019603347727561785 Test RE 0.0669226580534557\n",
      "84 Train Loss 0.010867366 Test MSE 0.018584196153829828 Test RE 0.06515983121116824\n",
      "85 Train Loss 0.010301448 Test MSE 0.01798288438779829 Test RE 0.06409700489015786\n",
      "86 Train Loss 0.009847525 Test MSE 0.01679677550045524 Test RE 0.061947105567073495\n",
      "87 Train Loss 0.009316365 Test MSE 0.0146701417294143 Test RE 0.057892888013507775\n",
      "88 Train Loss 0.008913032 Test MSE 0.014156144605621486 Test RE 0.056869650001911576\n",
      "89 Train Loss 0.008589147 Test MSE 0.01498341693527731 Test RE 0.05850776287226974\n",
      "90 Train Loss 0.008165432 Test MSE 0.014050054466729255 Test RE 0.05665615064802175\n",
      "91 Train Loss 0.007809252 Test MSE 0.012058555941018567 Test RE 0.05248747871298097\n",
      "92 Train Loss 0.007443091 Test MSE 0.011422498445677318 Test RE 0.05108443731733506\n",
      "93 Train Loss 0.0070980033 Test MSE 0.011611086800103943 Test RE 0.05150441943732766\n",
      "94 Train Loss 0.0069115264 Test MSE 0.01117190843286131 Test RE 0.05052097740148888\n",
      "95 Train Loss 0.0066358927 Test MSE 0.01067856351643701 Test RE 0.049392894573142054\n",
      "96 Train Loss 0.0063355463 Test MSE 0.011109271985582887 Test RE 0.05037915282005403\n",
      "97 Train Loss 0.0059252046 Test MSE 0.011338777121333646 Test RE 0.05089688104691868\n",
      "98 Train Loss 0.005622183 Test MSE 0.010756450785746033 Test RE 0.0495726981671366\n",
      "99 Train Loss 0.0053252713 Test MSE 0.010418552344813155 Test RE 0.04878785779747238\n",
      "Training time: 194.28\n",
      "1\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.91246 Test MSE 4.882027413752709 Test RE 1.0561075981480263\n",
      "1 Train Loss 55.41543 Test MSE 7.996223697585709 Test RE 1.3516072973414086\n",
      "2 Train Loss 47.186726 Test MSE 8.652675783612445 Test RE 1.4059933797306299\n",
      "3 Train Loss 42.11561 Test MSE 9.371821232452605 Test RE 1.4632551395101197\n",
      "4 Train Loss 39.57077 Test MSE 9.42980909080118 Test RE 1.4677750818384172\n",
      "5 Train Loss 37.01328 Test MSE 9.355439252929814 Test RE 1.461975692342933\n",
      "6 Train Loss 34.874947 Test MSE 9.365665517932323 Test RE 1.4627745039828162\n",
      "7 Train Loss 32.53419 Test MSE 9.109290774223153 Test RE 1.4426146655828955\n",
      "8 Train Loss 28.799427 Test MSE 8.49593473490063 Test RE 1.393200571853568\n",
      "9 Train Loss 26.312908 Test MSE 8.442799696472715 Test RE 1.3888370805367058\n",
      "10 Train Loss 23.819963 Test MSE 8.556210783944005 Test RE 1.398134002226543\n",
      "11 Train Loss 22.237583 Test MSE 8.453593336133546 Test RE 1.389724571619879\n",
      "12 Train Loss 20.743437 Test MSE 8.52015731697232 Test RE 1.3951852207882454\n",
      "13 Train Loss 19.687279 Test MSE 8.514875869210504 Test RE 1.3947527322879028\n",
      "14 Train Loss 18.409153 Test MSE 8.362368983556054 Test RE 1.3822058399283919\n",
      "15 Train Loss 16.968752 Test MSE 8.116616221575395 Test RE 1.3617443001411187\n",
      "16 Train Loss 15.134283 Test MSE 7.995020363923857 Test RE 1.3515055933487348\n",
      "17 Train Loss 13.204519 Test MSE 7.6538233158564015 Test RE 1.3223526094207734\n",
      "18 Train Loss 11.771225 Test MSE 7.682172145982571 Test RE 1.3247992625588108\n",
      "19 Train Loss 9.941709 Test MSE 7.33973717499544 Test RE 1.2949360297411134\n",
      "20 Train Loss 8.476262 Test MSE 7.243273719104039 Test RE 1.2863984523286176\n",
      "21 Train Loss 6.676928 Test MSE 6.647198351971523 Test RE 1.2323310166719308\n",
      "22 Train Loss 5.898147 Test MSE 6.737106108072228 Test RE 1.2406370709973353\n",
      "23 Train Loss 5.1495304 Test MSE 6.680605758133259 Test RE 1.2354238524472252\n",
      "24 Train Loss 4.622656 Test MSE 6.52735985915267 Test RE 1.2211720016468823\n",
      "25 Train Loss 4.1982555 Test MSE 6.466887226309856 Test RE 1.2155020735019002\n",
      "26 Train Loss 3.553174 Test MSE 6.348265715410888 Test RE 1.2043025571422519\n",
      "27 Train Loss 3.107398 Test MSE 6.280486641831582 Test RE 1.1978562642938158\n",
      "28 Train Loss 2.7694974 Test MSE 6.086060419055959 Test RE 1.1791693715029765\n",
      "29 Train Loss 2.5832682 Test MSE 5.916119037630856 Test RE 1.162589810269213\n",
      "30 Train Loss 2.3869665 Test MSE 5.906164800393386 Test RE 1.1616113337754623\n",
      "31 Train Loss 2.245039 Test MSE 5.744561859271974 Test RE 1.1456092602495604\n",
      "32 Train Loss 2.096825 Test MSE 5.729266844266211 Test RE 1.1440831395414632\n",
      "33 Train Loss 1.9860702 Test MSE 5.688429262394319 Test RE 1.1399983984406883\n",
      "34 Train Loss 1.8940225 Test MSE 5.604782720766355 Test RE 1.1315857006060197\n",
      "35 Train Loss 1.8517984 Test MSE 5.554089524250292 Test RE 1.1264566887015057\n",
      "36 Train Loss 1.8168641 Test MSE 5.529696766812364 Test RE 1.12398034939712\n",
      "37 Train Loss 1.7654909 Test MSE 5.510347399886699 Test RE 1.1220121251210444\n",
      "38 Train Loss 1.6924591 Test MSE 5.462565791689469 Test RE 1.1171369088883876\n",
      "39 Train Loss 1.6225799 Test MSE 5.440908402175779 Test RE 1.114920157780898\n",
      "40 Train Loss 1.5787385 Test MSE 5.481696098874763 Test RE 1.119091347048669\n",
      "41 Train Loss 1.5324656 Test MSE 5.505086052363766 Test RE 1.1214763417035314\n",
      "42 Train Loss 1.5039537 Test MSE 5.462241448927759 Test RE 1.117103743095729\n",
      "43 Train Loss 1.4541904 Test MSE 5.543708611031045 Test RE 1.1254034901333363\n",
      "44 Train Loss 1.419822 Test MSE 5.595994014403264 Test RE 1.1306981482519294\n",
      "45 Train Loss 1.3880042 Test MSE 5.618811213108288 Test RE 1.1330009669332892\n",
      "46 Train Loss 1.3380368 Test MSE 5.618801743341976 Test RE 1.1330000121709292\n",
      "47 Train Loss 1.3099697 Test MSE 5.619685116088939 Test RE 1.1330890722627154\n",
      "48 Train Loss 1.2832727 Test MSE 5.648339185156598 Test RE 1.1359741387722215\n",
      "49 Train Loss 1.2640868 Test MSE 5.655496053737218 Test RE 1.1366935930800097\n",
      "50 Train Loss 1.2437187 Test MSE 5.693253837915079 Test RE 1.140481734210136\n",
      "51 Train Loss 1.2260504 Test MSE 5.724327481348274 Test RE 1.143589859991551\n",
      "52 Train Loss 1.2059237 Test MSE 5.726033967102239 Test RE 1.1437603057242631\n",
      "53 Train Loss 1.1909083 Test MSE 5.732768878821902 Test RE 1.1444327485508052\n",
      "54 Train Loss 1.1693525 Test MSE 5.743606611440995 Test RE 1.1455140061392084\n",
      "55 Train Loss 1.1519684 Test MSE 5.751577260082855 Test RE 1.1463085699714846\n",
      "56 Train Loss 1.1392714 Test MSE 5.749443936850659 Test RE 1.1460959610299868\n",
      "57 Train Loss 1.1211483 Test MSE 5.785528408656432 Test RE 1.1496868805143095\n",
      "58 Train Loss 1.1029366 Test MSE 5.845601922857921 Test RE 1.155640301413859\n",
      "59 Train Loss 1.0879612 Test MSE 5.837283137010429 Test RE 1.1548177217239175\n",
      "60 Train Loss 1.0680633 Test MSE 5.833318887367135 Test RE 1.15442552186355\n",
      "61 Train Loss 1.0436895 Test MSE 5.872610065784784 Test RE 1.1583068984918359\n",
      "62 Train Loss 1.0321501 Test MSE 5.88223883202809 Test RE 1.1592560930002667\n",
      "63 Train Loss 1.0181583 Test MSE 5.928043603660813 Test RE 1.1637608820582999\n",
      "64 Train Loss 1.00467 Test MSE 5.957244644798753 Test RE 1.1666236547567006\n",
      "65 Train Loss 0.9905434 Test MSE 5.917040220258967 Test RE 1.1626803185774728\n",
      "66 Train Loss 0.98027146 Test MSE 5.9442146630601105 Test RE 1.1653471077060717\n",
      "67 Train Loss 0.97266084 Test MSE 5.95411138762256 Test RE 1.1663168172068041\n",
      "68 Train Loss 0.9627085 Test MSE 5.938687028055772 Test RE 1.164805142781308\n",
      "69 Train Loss 0.95456207 Test MSE 5.951856255111941 Test RE 1.1660959237857313\n",
      "70 Train Loss 0.94692075 Test MSE 5.951190028980635 Test RE 1.166030657985934\n",
      "71 Train Loss 0.9355317 Test MSE 5.972933318215723 Test RE 1.1681588227877073\n",
      "72 Train Loss 0.92408335 Test MSE 6.007095935273593 Test RE 1.1714947433279526\n",
      "73 Train Loss 0.9156547 Test MSE 6.019178695117897 Test RE 1.1726723322250547\n",
      "74 Train Loss 0.91086817 Test MSE 6.028875661108005 Test RE 1.1736165463890533\n",
      "75 Train Loss 0.9036753 Test MSE 6.020311181084677 Test RE 1.1727826439940534\n",
      "76 Train Loss 0.89696044 Test MSE 6.024493601645149 Test RE 1.1731899500685172\n",
      "77 Train Loss 0.8894229 Test MSE 6.02090093582324 Test RE 1.1728400859736179\n",
      "78 Train Loss 0.8849423 Test MSE 6.027572429615649 Test RE 1.1734896921633347\n",
      "79 Train Loss 0.8807101 Test MSE 6.033361135907707 Test RE 1.1740530497239086\n",
      "80 Train Loss 0.8762204 Test MSE 6.030225312469574 Test RE 1.1737479045908057\n",
      "81 Train Loss 0.87234426 Test MSE 6.046984496307079 Test RE 1.1753778112209292\n",
      "82 Train Loss 0.8685433 Test MSE 6.067868053341773 Test RE 1.1774056743092158\n",
      "83 Train Loss 0.86434203 Test MSE 6.080469320659003 Test RE 1.1786276116129066\n",
      "84 Train Loss 0.8602215 Test MSE 6.077978137853812 Test RE 1.1783861436039251\n",
      "85 Train Loss 0.8555535 Test MSE 6.093430062900086 Test RE 1.1798830868281205\n",
      "86 Train Loss 0.85194516 Test MSE 6.101076980314523 Test RE 1.1806231986806164\n",
      "87 Train Loss 0.8472754 Test MSE 6.094726226350398 Test RE 1.180008569519994\n",
      "88 Train Loss 0.844115 Test MSE 6.0982715150898095 Test RE 1.1803517238091699\n",
      "89 Train Loss 0.8399482 Test MSE 6.1100919457102 Test RE 1.1814951224889063\n",
      "90 Train Loss 0.8361516 Test MSE 6.115738198344418 Test RE 1.182040898196454\n",
      "91 Train Loss 0.83124787 Test MSE 6.134682067794504 Test RE 1.1838702043295253\n",
      "92 Train Loss 0.826921 Test MSE 6.1536494850742525 Test RE 1.185698956818395\n",
      "93 Train Loss 0.8245728 Test MSE 6.155997444294642 Test RE 1.1859251402641364\n",
      "94 Train Loss 0.8207407 Test MSE 6.155586603641553 Test RE 1.1858855663045156\n",
      "95 Train Loss 0.8177911 Test MSE 6.1720261200047615 Test RE 1.1874680626093306\n",
      "96 Train Loss 0.8144804 Test MSE 6.197384568531335 Test RE 1.1899049836917297\n",
      "97 Train Loss 0.8111926 Test MSE 6.211517155760315 Test RE 1.191260947615499\n",
      "98 Train Loss 0.808185 Test MSE 6.199416179877971 Test RE 1.190100003570962\n",
      "99 Train Loss 0.80465126 Test MSE 6.195508546914938 Test RE 1.1897248709032857\n",
      "Training time: 195.30\n",
      "2\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.015945 Test MSE 5.329389350515733 Test RE 1.1034350759059322\n",
      "1 Train Loss 48.562035 Test MSE 8.75302924811675 Test RE 1.4141232090430311\n",
      "2 Train Loss 39.95643 Test MSE 8.598257536061187 Test RE 1.4015651325341512\n",
      "3 Train Loss 29.15958 Test MSE 5.8826204272782405 Test RE 1.1592936942824748\n",
      "4 Train Loss 21.462345 Test MSE 6.668881086774295 Test RE 1.2343392726840716\n",
      "5 Train Loss 17.191545 Test MSE 5.91021989451316 Test RE 1.162010038789101\n",
      "6 Train Loss 14.022387 Test MSE 6.016624579370636 Test RE 1.1724235060295718\n",
      "7 Train Loss 12.421996 Test MSE 6.021699822580546 Test RE 1.172917892878655\n",
      "8 Train Loss 11.195254 Test MSE 6.003686642455502 Test RE 1.1711622585876338\n",
      "9 Train Loss 10.623683 Test MSE 6.000075306270318 Test RE 1.170809966978121\n",
      "10 Train Loss 10.068837 Test MSE 6.083422877003291 Test RE 1.1789138329752822\n",
      "11 Train Loss 9.737747 Test MSE 5.989169290229831 Test RE 1.1697454236822855\n",
      "12 Train Loss 9.199409 Test MSE 5.922108618371177 Test RE 1.1631781743564507\n",
      "13 Train Loss 8.923159 Test MSE 5.999704019408049 Test RE 1.1707737413424482\n",
      "14 Train Loss 8.626465 Test MSE 5.890637149619375 Test RE 1.1600833569505167\n",
      "15 Train Loss 8.279687 Test MSE 5.789928226394603 Test RE 1.150123958255921\n",
      "16 Train Loss 8.138404 Test MSE 5.7251140832658205 Test RE 1.1436684298392017\n",
      "17 Train Loss 7.870617 Test MSE 5.720991770254923 Test RE 1.1432566119999608\n",
      "18 Train Loss 7.67054 Test MSE 5.557897956020448 Test RE 1.1268428274427613\n",
      "19 Train Loss 7.428667 Test MSE 5.502491324311975 Test RE 1.1212120162177577\n",
      "20 Train Loss 7.122095 Test MSE 5.233661702394093 Test RE 1.0934800998265788\n",
      "21 Train Loss 6.726815 Test MSE 5.075558822320956 Test RE 1.0768370582541733\n",
      "22 Train Loss 6.1242003 Test MSE 5.07615608199427 Test RE 1.0769004140788974\n",
      "23 Train Loss 5.7094026 Test MSE 4.835942538097987 Test RE 1.0511111092428849\n",
      "24 Train Loss 5.023369 Test MSE 4.583330399192812 Test RE 1.0232897948739823\n",
      "25 Train Loss 4.274096 Test MSE 4.428543257943688 Test RE 1.0058622418963312\n",
      "26 Train Loss 3.8910298 Test MSE 4.346146065082209 Test RE 0.996460801622329\n",
      "27 Train Loss 3.6435335 Test MSE 4.215808707917597 Test RE 0.9814055475311385\n",
      "28 Train Loss 3.2683914 Test MSE 3.9677415827094973 Test RE 0.9520938278840784\n",
      "29 Train Loss 3.0151262 Test MSE 3.7917929385446687 Test RE 0.930744260956642\n",
      "30 Train Loss 2.6131148 Test MSE 3.810578781338266 Test RE 0.9330470254652058\n",
      "31 Train Loss 2.3819351 Test MSE 3.5925244244848837 Test RE 0.9059577093154785\n",
      "32 Train Loss 2.1711793 Test MSE 3.398723049430324 Test RE 0.8811826726147353\n",
      "33 Train Loss 2.0212297 Test MSE 3.29281764966136 Test RE 0.8673450429362088\n",
      "34 Train Loss 1.8599659 Test MSE 3.062059678162708 Test RE 0.8364016590688227\n",
      "35 Train Loss 1.7373084 Test MSE 2.8177935577234936 Test RE 0.8023477631962523\n",
      "36 Train Loss 1.6387856 Test MSE 2.7640660227888714 Test RE 0.7946616716318903\n",
      "37 Train Loss 1.5645422 Test MSE 2.668260473999603 Test RE 0.7807682991180722\n",
      "38 Train Loss 1.5198003 Test MSE 2.5840831423675135 Test RE 0.768353903049382\n",
      "39 Train Loss 1.4533598 Test MSE 2.5133419780759905 Test RE 0.7577637973585566\n",
      "40 Train Loss 1.3542414 Test MSE 2.3676382142952344 Test RE 0.7354713011431189\n",
      "41 Train Loss 1.2734265 Test MSE 2.27604242026596 Test RE 0.7211045507393001\n",
      "42 Train Loss 1.1810267 Test MSE 2.074682626527386 Test RE 0.6884682160872048\n",
      "43 Train Loss 1.129285 Test MSE 1.9453233144916147 Test RE 0.6666593218187439\n",
      "44 Train Loss 1.0283228 Test MSE 1.7149330295966894 Test RE 0.6259384682114334\n",
      "45 Train Loss 0.96503407 Test MSE 1.5693420911719584 Test RE 0.5987794290376361\n",
      "46 Train Loss 0.92330724 Test MSE 1.4671391624269408 Test RE 0.5789535419560095\n",
      "47 Train Loss 0.874767 Test MSE 1.345527908720319 Test RE 0.5544398219812311\n",
      "48 Train Loss 0.8227032 Test MSE 1.2442259281844479 Test RE 0.5331601530031003\n",
      "49 Train Loss 0.7730899 Test MSE 1.052020319777911 Test RE 0.49025284704952793\n",
      "50 Train Loss 0.7035951 Test MSE 0.8713939409985304 Test RE 0.44618537219659\n",
      "51 Train Loss 0.6146735 Test MSE 0.6673663336620602 Test RE 0.3904722791510103\n",
      "52 Train Loss 0.52568305 Test MSE 0.48323348361801466 Test RE 0.33226651006460417\n",
      "53 Train Loss 0.4566989 Test MSE 0.4272079136748516 Test RE 0.31241199832375605\n",
      "54 Train Loss 0.39798027 Test MSE 0.38199033729143833 Test RE 0.29541616020416045\n",
      "55 Train Loss 0.3411882 Test MSE 0.2913703016473876 Test RE 0.25800653250527295\n",
      "56 Train Loss 0.2878971 Test MSE 0.2154399005390898 Test RE 0.22185597533330595\n",
      "57 Train Loss 0.24901514 Test MSE 0.1934110218524731 Test RE 0.21020772402015261\n",
      "58 Train Loss 0.21825042 Test MSE 0.15243260246907614 Test RE 0.18661519049491987\n",
      "59 Train Loss 0.18933693 Test MSE 0.1443206391112382 Test RE 0.18158178540893555\n",
      "60 Train Loss 0.1606545 Test MSE 0.1346791031265957 Test RE 0.1754115427010665\n",
      "61 Train Loss 0.1446778 Test MSE 0.12111366269072066 Test RE 0.16634303816020848\n",
      "62 Train Loss 0.12748225 Test MSE 0.11931779469608744 Test RE 0.16510516867446343\n",
      "63 Train Loss 0.10815026 Test MSE 0.09554577562546948 Test RE 0.14774534464147412\n",
      "64 Train Loss 0.095031254 Test MSE 0.08436400797840177 Test RE 0.13883106726773736\n",
      "65 Train Loss 0.0884569 Test MSE 0.08726143397762813 Test RE 0.14119497246205917\n",
      "66 Train Loss 0.08330853 Test MSE 0.0860235240460379 Test RE 0.14018988362986856\n",
      "67 Train Loss 0.078143775 Test MSE 0.08701396207748055 Test RE 0.14099461707423974\n",
      "68 Train Loss 0.071965255 Test MSE 0.08081083408440831 Test RE 0.13587603178248628\n",
      "69 Train Loss 0.06675562 Test MSE 0.06796729474249204 Test RE 0.12461147951660947\n",
      "70 Train Loss 0.062588796 Test MSE 0.05872719091404128 Test RE 0.11583176504862193\n",
      "71 Train Loss 0.057899415 Test MSE 0.05931400068465745 Test RE 0.11640902967815102\n",
      "72 Train Loss 0.054125804 Test MSE 0.062474262910038936 Test RE 0.11946993591325068\n",
      "73 Train Loss 0.04984324 Test MSE 0.05694625244807193 Test RE 0.11406190871525337\n",
      "74 Train Loss 0.048146687 Test MSE 0.05655419006301222 Test RE 0.11366858502026113\n",
      "75 Train Loss 0.045802195 Test MSE 0.05421065726373285 Test RE 0.11128852763984179\n",
      "76 Train Loss 0.04278368 Test MSE 0.04547152486722562 Test RE 0.10192431923781385\n",
      "77 Train Loss 0.038977947 Test MSE 0.0365694052193478 Test RE 0.09140438032448246\n",
      "78 Train Loss 0.035774972 Test MSE 0.030214682476422894 Test RE 0.08308393888504145\n",
      "79 Train Loss 0.03365399 Test MSE 0.024988691197638104 Test RE 0.07555788893897966\n",
      "80 Train Loss 0.03175608 Test MSE 0.024556614230719413 Test RE 0.07490180855679741\n",
      "81 Train Loss 0.028757714 Test MSE 0.022406204658285404 Test RE 0.07154712870202772\n",
      "82 Train Loss 0.027222734 Test MSE 0.018258514404963476 Test RE 0.06458635561835009\n",
      "83 Train Loss 0.025793102 Test MSE 0.016088555081881145 Test RE 0.06062707015253875\n",
      "84 Train Loss 0.0243619 Test MSE 0.01495032289378233 Test RE 0.05844311377781103\n",
      "85 Train Loss 0.022772536 Test MSE 0.012333182122510935 Test RE 0.05308179893690364\n",
      "86 Train Loss 0.02193838 Test MSE 0.010066027418954161 Test RE 0.04795535549706711\n",
      "87 Train Loss 0.020985236 Test MSE 0.009364719268512213 Test RE 0.046254654537666064\n",
      "88 Train Loss 0.019982828 Test MSE 0.010660625703529086 Test RE 0.0493513921328361\n",
      "89 Train Loss 0.01916242 Test MSE 0.010684192415152874 Test RE 0.049405910882474806\n",
      "90 Train Loss 0.018400414 Test MSE 0.009193815909961175 Test RE 0.0458306442279146\n",
      "91 Train Loss 0.017610392 Test MSE 0.008601196537931092 Test RE 0.04432895525837308\n",
      "92 Train Loss 0.016484752 Test MSE 0.008688056475807698 Test RE 0.04455222292424789\n",
      "93 Train Loss 0.015802782 Test MSE 0.00787910902159256 Test RE 0.04242741921088273\n",
      "94 Train Loss 0.014995769 Test MSE 0.007451821114864233 Test RE 0.04126095453011287\n",
      "95 Train Loss 0.013289633 Test MSE 0.007330772902455374 Test RE 0.040924458644774564\n",
      "96 Train Loss 0.012105074 Test MSE 0.007332519034986097 Test RE 0.040929332296893155\n",
      "97 Train Loss 0.011684154 Test MSE 0.007488228705138738 Test RE 0.041361626669292446\n",
      "98 Train Loss 0.011045356 Test MSE 0.006691488434641514 Test RE 0.039099339962749245\n",
      "99 Train Loss 0.010293154 Test MSE 0.005930988573411663 Test RE 0.036810490456026745\n",
      "Training time: 194.48\n",
      "3\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.95655 Test MSE 6.080524261122554 Test RE 1.1786329363828913\n",
      "1 Train Loss 53.294388 Test MSE 6.711377452190891 Test RE 1.2382658408859284\n",
      "2 Train Loss 43.20794 Test MSE 8.851009359794036 Test RE 1.4220159258070393\n",
      "3 Train Loss 39.93093 Test MSE 9.055071536719954 Test RE 1.4383149782652789\n",
      "4 Train Loss 36.707996 Test MSE 9.242297353780033 Test RE 1.453108451802389\n",
      "5 Train Loss 34.406357 Test MSE 9.379453651500203 Test RE 1.4638508563512616\n",
      "6 Train Loss 32.17521 Test MSE 9.52474958657782 Test RE 1.4751454482866462\n",
      "7 Train Loss 29.73787 Test MSE 9.066951910972826 Test RE 1.439258213170204\n",
      "8 Train Loss 27.172722 Test MSE 8.671110643486706 Test RE 1.407490344413105\n",
      "9 Train Loss 25.165787 Test MSE 8.591172629310533 Test RE 1.400987573381886\n",
      "10 Train Loss 22.754969 Test MSE 8.504421238679154 Test RE 1.3938962251978153\n",
      "11 Train Loss 21.032104 Test MSE 8.332719740158094 Test RE 1.3797533203484709\n",
      "12 Train Loss 19.541832 Test MSE 8.500643240755576 Test RE 1.3935865790806468\n",
      "13 Train Loss 17.96952 Test MSE 8.482660957380746 Test RE 1.3921118003476278\n",
      "14 Train Loss 16.94232 Test MSE 8.562872530711436 Test RE 1.3986781801734023\n",
      "15 Train Loss 15.675709 Test MSE 8.302655117635865 Test RE 1.3772619820784464\n",
      "16 Train Loss 14.718297 Test MSE 8.375962095723885 Test RE 1.3833287782992947\n",
      "17 Train Loss 13.253254 Test MSE 8.066938713577363 Test RE 1.3575706464299013\n",
      "18 Train Loss 12.0180435 Test MSE 7.937062893969288 Test RE 1.3465980186817084\n",
      "19 Train Loss 11.0037985 Test MSE 7.659507187078242 Test RE 1.3228435200907813\n",
      "20 Train Loss 9.372168 Test MSE 7.2035444339860275 Test RE 1.282865659904423\n",
      "21 Train Loss 8.345718 Test MSE 7.023647773613564 Test RE 1.266745652226442\n",
      "22 Train Loss 7.581129 Test MSE 6.89698205728371 Test RE 1.255271325866798\n",
      "23 Train Loss 7.174306 Test MSE 7.028438263984617 Test RE 1.2671775715558828\n",
      "24 Train Loss 6.758189 Test MSE 6.9720255024333575 Test RE 1.262081915659234\n",
      "25 Train Loss 6.2425814 Test MSE 7.136055694109813 Test RE 1.2768420468784878\n",
      "26 Train Loss 5.8648777 Test MSE 7.251506823729457 Test RE 1.2871293404307371\n",
      "27 Train Loss 5.4233484 Test MSE 6.930230081561382 Test RE 1.2582933080976462\n",
      "28 Train Loss 4.566579 Test MSE 6.501810209449485 Test RE 1.2187796784857863\n",
      "29 Train Loss 3.9241214 Test MSE 6.352248907869422 Test RE 1.20468031516743\n",
      "30 Train Loss 3.5054784 Test MSE 6.323357699159623 Test RE 1.2019376380699343\n",
      "31 Train Loss 3.2066646 Test MSE 6.366197445170646 Test RE 1.2060022339236647\n",
      "32 Train Loss 2.8746197 Test MSE 6.2855900882706175 Test RE 1.1983428471227007\n",
      "33 Train Loss 2.724514 Test MSE 6.437153332408169 Test RE 1.212704495022981\n",
      "34 Train Loss 2.5821366 Test MSE 6.425702468149361 Test RE 1.211625392590668\n",
      "35 Train Loss 2.4398904 Test MSE 6.4036919556606104 Test RE 1.2095484700565586\n",
      "36 Train Loss 2.3533244 Test MSE 6.4948917152398895 Test RE 1.2181310618544885\n",
      "37 Train Loss 2.2164307 Test MSE 6.4739648978729605 Test RE 1.216167043493139\n",
      "38 Train Loss 2.1395085 Test MSE 6.56780046073544 Test RE 1.224949078118336\n",
      "39 Train Loss 2.0396132 Test MSE 6.680180579511928 Test RE 1.2353845383350581\n",
      "40 Train Loss 1.9645011 Test MSE 6.706522381329367 Test RE 1.2378178735275798\n",
      "41 Train Loss 1.8932252 Test MSE 6.691988937367121 Test RE 1.2364759326171337\n",
      "42 Train Loss 1.8241088 Test MSE 6.687039435193321 Test RE 1.2360185893374478\n",
      "43 Train Loss 1.7810841 Test MSE 6.653176837225305 Test RE 1.2328850709208472\n",
      "44 Train Loss 1.7325921 Test MSE 6.630552410154488 Test RE 1.230787045227082\n",
      "45 Train Loss 1.7018367 Test MSE 6.660713373505084 Test RE 1.2335831624823235\n",
      "46 Train Loss 1.6650883 Test MSE 6.612674939029347 Test RE 1.229126684970572\n",
      "47 Train Loss 1.6298139 Test MSE 6.608418042145887 Test RE 1.2287309972996014\n",
      "48 Train Loss 1.5892177 Test MSE 6.624946251935173 Test RE 1.2302666175469006\n",
      "49 Train Loss 1.5551406 Test MSE 6.573488786929721 Test RE 1.2254794232397968\n",
      "50 Train Loss 1.5130428 Test MSE 6.575908953275106 Test RE 1.2257049953231571\n",
      "51 Train Loss 1.4762982 Test MSE 6.6014873441646955 Test RE 1.2280865013417646\n",
      "52 Train Loss 1.4339577 Test MSE 6.53122242141159 Test RE 1.2215332622020278\n",
      "53 Train Loss 1.3960316 Test MSE 6.4779296651660125 Test RE 1.216539387286912\n",
      "54 Train Loss 1.3581235 Test MSE 6.316713599466699 Test RE 1.2013060201313495\n",
      "55 Train Loss 1.3199074 Test MSE 6.142592616180206 Test RE 1.184633246762738\n",
      "56 Train Loss 1.2871667 Test MSE 6.065855866443941 Test RE 1.1772104363199916\n",
      "57 Train Loss 1.251421 Test MSE 6.053510964749856 Test RE 1.1760119287287587\n",
      "58 Train Loss 1.2181145 Test MSE 6.0282123915423425 Test RE 1.173551986627699\n",
      "59 Train Loss 1.1904392 Test MSE 6.000095298873703 Test RE 1.1708119175802894\n",
      "60 Train Loss 1.1665252 Test MSE 5.973004114356434 Test RE 1.1681657457589611\n",
      "61 Train Loss 1.1579227 Test MSE 5.984130122697069 Test RE 1.1692532198987096\n",
      "62 Train Loss 1.1396282 Test MSE 5.951557085915224 Test RE 1.1660666165956868\n",
      "63 Train Loss 1.1170138 Test MSE 5.939698124410705 Test RE 1.1649042960203906\n",
      "64 Train Loss 1.101213 Test MSE 5.925318581165394 Test RE 1.1634933706056014\n",
      "65 Train Loss 1.0898296 Test MSE 5.887276466579829 Test RE 1.1597523886204113\n",
      "66 Train Loss 1.07104 Test MSE 5.85993430008484 Test RE 1.1570561464334175\n",
      "67 Train Loss 1.0569576 Test MSE 5.886465993646939 Test RE 1.1596725571162418\n",
      "68 Train Loss 1.0423919 Test MSE 5.887486658802131 Test RE 1.1597730916362692\n",
      "69 Train Loss 1.0335255 Test MSE 5.866968975211679 Test RE 1.1577504437012356\n",
      "70 Train Loss 1.022993 Test MSE 5.877745586094053 Test RE 1.1588132498952255\n",
      "71 Train Loss 1.0085927 Test MSE 5.901065628759711 Test RE 1.161109778638012\n",
      "72 Train Loss 1.000468 Test MSE 5.897852164643579 Test RE 1.1607935906016522\n",
      "73 Train Loss 0.9892323 Test MSE 5.897064776657721 Test RE 1.1607161026103152\n",
      "74 Train Loss 0.9846454 Test MSE 5.901840145822544 Test RE 1.1611859741834896\n",
      "75 Train Loss 0.9723837 Test MSE 5.89125847952307 Test RE 1.1601445367054601\n",
      "76 Train Loss 0.96123195 Test MSE 5.8581211076860855 Test RE 1.1568771232894317\n",
      "77 Train Loss 0.9546589 Test MSE 5.861503048398526 Test RE 1.1572110123688444\n",
      "78 Train Loss 0.94736904 Test MSE 5.881894535359952 Test RE 1.1592221659648039\n",
      "79 Train Loss 0.9377171 Test MSE 5.890552008522197 Test RE 1.1600749732116933\n",
      "80 Train Loss 0.93016887 Test MSE 5.885466274849371 Test RE 1.1595740773421501\n",
      "81 Train Loss 0.92337257 Test MSE 5.905819394419195 Test RE 1.161577366440121\n",
      "82 Train Loss 0.91771966 Test MSE 5.917087746671768 Test RE 1.1626849879655254\n",
      "83 Train Loss 0.9123672 Test MSE 5.920087529929058 Test RE 1.1629796735582743\n",
      "84 Train Loss 0.90593976 Test MSE 5.939549004521033 Test RE 1.1648896730979168\n",
      "85 Train Loss 0.90130013 Test MSE 5.940893304747438 Test RE 1.1650214905855714\n",
      "86 Train Loss 0.8971007 Test MSE 5.9247848220468065 Test RE 1.1634409650535824\n",
      "87 Train Loss 0.89057887 Test MSE 5.917334684969032 Test RE 1.1627092489253101\n",
      "88 Train Loss 0.88453233 Test MSE 5.927429654629307 Test RE 1.163700616951079\n",
      "89 Train Loss 0.87816095 Test MSE 5.94574476575558 Test RE 1.1654970842899712\n",
      "90 Train Loss 0.8736106 Test MSE 5.965865732805568 Test RE 1.1674674952988633\n",
      "91 Train Loss 0.8692471 Test MSE 5.9732926900800924 Test RE 1.1681939644071848\n",
      "92 Train Loss 0.86302143 Test MSE 5.9907914325076295 Test RE 1.169903823365894\n",
      "93 Train Loss 0.85710037 Test MSE 6.00365693914163 Test RE 1.1711593614141753\n",
      "94 Train Loss 0.8497471 Test MSE 5.999137468551096 Test RE 1.1707184620716757\n",
      "95 Train Loss 0.84526384 Test MSE 6.001804093466737 Test RE 1.1709786261531838\n",
      "96 Train Loss 0.8416515 Test MSE 6.013023389930722 Test RE 1.1720725824295468\n",
      "97 Train Loss 0.8366793 Test MSE 6.037900751725843 Test RE 1.174494656607825\n",
      "98 Train Loss 0.8313481 Test MSE 6.062944027303903 Test RE 1.1769278497425377\n",
      "99 Train Loss 0.82597136 Test MSE 6.081699411172198 Test RE 1.1787468248881765\n",
      "Training time: 195.23\n",
      "4\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.926247 Test MSE 8.069088103815785 Test RE 1.3577514928982541\n",
      "1 Train Loss 46.909378 Test MSE 8.151080103252152 Test RE 1.3646322820498495\n",
      "2 Train Loss 38.05558 Test MSE 7.739512596369186 Test RE 1.3297342835283392\n",
      "3 Train Loss 31.857996 Test MSE 7.586885416740794 Test RE 1.3165574737779275\n",
      "4 Train Loss 26.910374 Test MSE 7.038775243109225 Test RE 1.268109071196007\n",
      "5 Train Loss 23.822617 Test MSE 7.085251031901322 Test RE 1.2722887331813961\n",
      "6 Train Loss 20.42953 Test MSE 6.342223720421159 Test RE 1.2037293200959016\n",
      "7 Train Loss 17.750145 Test MSE 6.256370357174027 Test RE 1.1955542430416688\n",
      "8 Train Loss 14.420145 Test MSE 5.443421400191036 Test RE 1.1151776027234168\n",
      "9 Train Loss 12.2771225 Test MSE 5.748264740112874 Test RE 1.1459784242789277\n",
      "10 Train Loss 10.817484 Test MSE 5.651371120510419 Test RE 1.136278983963527\n",
      "11 Train Loss 9.836164 Test MSE 5.5977811146311005 Test RE 1.130878680040547\n",
      "12 Train Loss 8.914728 Test MSE 5.277226370788017 Test RE 1.098021697951534\n",
      "13 Train Loss 7.2601986 Test MSE 5.067673562882486 Test RE 1.0760002597514193\n",
      "14 Train Loss 6.234783 Test MSE 4.74405260260696 Test RE 1.0410768952324605\n",
      "15 Train Loss 5.5045166 Test MSE 4.861141479949289 Test RE 1.0538460955362199\n",
      "16 Train Loss 5.0587745 Test MSE 4.53510694756574 Test RE 1.017892294716283\n",
      "17 Train Loss 4.4538164 Test MSE 4.244174528914921 Test RE 0.9847016771321769\n",
      "18 Train Loss 3.8828328 Test MSE 4.033603930145804 Test RE 0.9599634238210848\n",
      "19 Train Loss 3.3513103 Test MSE 3.7058705966592758 Test RE 0.9201384636154439\n",
      "20 Train Loss 3.0692918 Test MSE 3.6484480835322426 Test RE 0.9129818537078832\n",
      "21 Train Loss 2.758201 Test MSE 3.2983923796768106 Test RE 0.868078938673631\n",
      "22 Train Loss 2.5565636 Test MSE 3.163607527744235 Test RE 0.8501574411559701\n",
      "23 Train Loss 2.3808284 Test MSE 3.0873411025939888 Test RE 0.8398473722198089\n",
      "24 Train Loss 2.1929197 Test MSE 2.783118687614145 Test RE 0.7973957635846707\n",
      "25 Train Loss 2.0675616 Test MSE 2.688352752479772 Test RE 0.7837024191096246\n",
      "26 Train Loss 1.9578354 Test MSE 2.50115353584783 Test RE 0.7559241780350975\n",
      "27 Train Loss 1.8185518 Test MSE 2.3175177696713956 Test RE 0.7276450791415691\n",
      "28 Train Loss 1.6881564 Test MSE 2.169281997326539 Test RE 0.7039893129995612\n",
      "29 Train Loss 1.6012816 Test MSE 1.9655211491189477 Test RE 0.6701112682726992\n",
      "30 Train Loss 1.5412859 Test MSE 1.881197854923209 Test RE 0.6555793988721181\n",
      "31 Train Loss 1.4573815 Test MSE 1.741896228111038 Test RE 0.6308399659879064\n",
      "32 Train Loss 1.3823168 Test MSE 1.4863310426215282 Test RE 0.5827279302936134\n",
      "33 Train Loss 1.2817352 Test MSE 1.1704667868226366 Test RE 0.5171155620570379\n",
      "34 Train Loss 1.0738274 Test MSE 1.084365438683262 Test RE 0.49773237900857353\n",
      "35 Train Loss 0.95233387 Test MSE 1.02208815912559 Test RE 0.4832281644931957\n",
      "36 Train Loss 0.8361008 Test MSE 0.9574546187650008 Test RE 0.46769977345471325\n",
      "37 Train Loss 0.69635016 Test MSE 0.7440445951329362 Test RE 0.4122945019378559\n",
      "38 Train Loss 0.606447 Test MSE 0.5755587269963863 Test RE 0.36262094216893376\n",
      "39 Train Loss 0.5313556 Test MSE 0.5073306151023504 Test RE 0.3404502016002124\n",
      "40 Train Loss 0.4530632 Test MSE 0.43864033017710935 Test RE 0.3165645942661803\n",
      "41 Train Loss 0.4119094 Test MSE 0.42094058233823417 Test RE 0.3101119194241443\n",
      "42 Train Loss 0.36876106 Test MSE 0.40642818932699626 Test RE 0.30471930666128544\n",
      "43 Train Loss 0.33393425 Test MSE 0.3447149079591859 Test RE 0.2806325827292259\n",
      "44 Train Loss 0.30989537 Test MSE 0.30178612835189866 Test RE 0.262577613622237\n",
      "45 Train Loss 0.28462613 Test MSE 0.24255202054979857 Test RE 0.23540219532297263\n",
      "46 Train Loss 0.25718644 Test MSE 0.15264622727980823 Test RE 0.18674590950312567\n",
      "47 Train Loss 0.21782452 Test MSE 0.08176930919407323 Test RE 0.13667945067049736\n",
      "48 Train Loss 0.19183104 Test MSE 0.0699973028365515 Test RE 0.12645870008981566\n",
      "49 Train Loss 0.16136326 Test MSE 0.05424607048561329 Test RE 0.11132487143366934\n",
      "50 Train Loss 0.13960755 Test MSE 0.04863844391177546 Test RE 0.1054139036670962\n",
      "51 Train Loss 0.12378236 Test MSE 0.0399342885469184 Test RE 0.09551707970974682\n",
      "52 Train Loss 0.10655843 Test MSE 0.027882115211011527 Test RE 0.07981250080386883\n",
      "53 Train Loss 0.09980413 Test MSE 0.02339399627796239 Test RE 0.07310721981957241\n",
      "54 Train Loss 0.09163696 Test MSE 0.022639614230484478 Test RE 0.0719188230347964\n",
      "55 Train Loss 0.085931145 Test MSE 0.01982246846461786 Test RE 0.06729564005311858\n",
      "56 Train Loss 0.08016608 Test MSE 0.016414719405625645 Test RE 0.061238534904547275\n",
      "57 Train Loss 0.07032727 Test MSE 0.01711091210448673 Test RE 0.06252369566518151\n",
      "58 Train Loss 0.063284755 Test MSE 0.019822573058666696 Test RE 0.06729581759695451\n",
      "59 Train Loss 0.05592075 Test MSE 0.02008757252098221 Test RE 0.06774414862103992\n",
      "60 Train Loss 0.051812008 Test MSE 0.020564600202695033 Test RE 0.06854380285028525\n",
      "61 Train Loss 0.045758616 Test MSE 0.02102784590568104 Test RE 0.0693115248135842\n",
      "62 Train Loss 0.0433046 Test MSE 0.02127646013595114 Test RE 0.06972005921503795\n",
      "63 Train Loss 0.040092167 Test MSE 0.020395551703530367 Test RE 0.0682614939779735\n",
      "64 Train Loss 0.03690965 Test MSE 0.01804834815912553 Test RE 0.06421356627631918\n",
      "65 Train Loss 0.035072505 Test MSE 0.017633989000185733 Test RE 0.06347216952284887\n",
      "66 Train Loss 0.032303236 Test MSE 0.017599617924719473 Test RE 0.0634102813468664\n",
      "67 Train Loss 0.028270312 Test MSE 0.014771828253193857 Test RE 0.058093184660040244\n",
      "68 Train Loss 0.02652165 Test MSE 0.014280637899105051 Test RE 0.05711916682436927\n",
      "69 Train Loss 0.025474181 Test MSE 0.014711869183953327 Test RE 0.05797516422895433\n",
      "70 Train Loss 0.02405705 Test MSE 0.013942865260357706 Test RE 0.05643961928262299\n",
      "71 Train Loss 0.022706812 Test MSE 0.013562214374478153 Test RE 0.05566386558907293\n",
      "72 Train Loss 0.021308463 Test MSE 0.01385426977604083 Test RE 0.05626001975829821\n",
      "73 Train Loss 0.020290427 Test MSE 0.013373018156418812 Test RE 0.05527423968127825\n",
      "74 Train Loss 0.01932438 Test MSE 0.01352064267181656 Test RE 0.05557848802414448\n",
      "75 Train Loss 0.018504601 Test MSE 0.013935044301717768 Test RE 0.05642378775024483\n",
      "76 Train Loss 0.01780602 Test MSE 0.013660812153103885 Test RE 0.055865838303356716\n",
      "77 Train Loss 0.017304454 Test MSE 0.013138959811670759 Test RE 0.054788391749813134\n",
      "78 Train Loss 0.016242683 Test MSE 0.012978206591941988 Test RE 0.05445219634645678\n",
      "79 Train Loss 0.015104465 Test MSE 0.012085410685090423 Test RE 0.052545891756683435\n",
      "80 Train Loss 0.014473758 Test MSE 0.011508882041831748 Test RE 0.05127723864153999\n",
      "81 Train Loss 0.013539141 Test MSE 0.009982145039456014 Test RE 0.04775512632127576\n",
      "82 Train Loss 0.012936315 Test MSE 0.008967622187387773 Test RE 0.045263351894483016\n",
      "83 Train Loss 0.0123486575 Test MSE 0.008605394041998848 Test RE 0.044339770513752125\n",
      "84 Train Loss 0.0119999815 Test MSE 0.008007539340648078 Test RE 0.04277180722680951\n",
      "85 Train Loss 0.011236523 Test MSE 0.0069387128876682745 Test RE 0.0398150732465645\n",
      "86 Train Loss 0.010605478 Test MSE 0.00659654524245763 Test RE 0.03882096555674481\n",
      "87 Train Loss 0.01031516 Test MSE 0.006361864156513004 Test RE 0.03812415758470258\n",
      "88 Train Loss 0.010026369 Test MSE 0.005803210907973311 Test RE 0.03641180745787556\n",
      "89 Train Loss 0.009771438 Test MSE 0.005367965390126202 Test RE 0.035019739711394354\n",
      "90 Train Loss 0.009317496 Test MSE 0.005307580444250388 Test RE 0.034822211816221985\n",
      "91 Train Loss 0.0088514695 Test MSE 0.005171346028445127 Test RE 0.03437240019055844\n",
      "92 Train Loss 0.008281165 Test MSE 0.004250403028791295 Test RE 0.031161841657991383\n",
      "93 Train Loss 0.00809529 Test MSE 0.003934239857050882 Test RE 0.02998047277852208\n",
      "94 Train Loss 0.007799524 Test MSE 0.0037234966145084695 Test RE 0.029166447973903664\n",
      "95 Train Loss 0.007598494 Test MSE 0.0038068565644163743 Test RE 0.029491123451042583\n",
      "96 Train Loss 0.0074139503 Test MSE 0.00406544225696959 Test RE 0.030476280265855183\n",
      "97 Train Loss 0.007104649 Test MSE 0.004268574241267133 Test RE 0.031228381763675973\n",
      "98 Train Loss 0.0068479367 Test MSE 0.00431511491582348 Test RE 0.031398163253816946\n",
      "99 Train Loss 0.006488053 Test MSE 0.004463618727096343 Test RE 0.03193387388192789\n",
      "Training time: 196.41\n",
      "5\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 70.055595 Test MSE 5.273597712558792 Test RE 1.0976441292874521\n",
      "1 Train Loss 68.647865 Test MSE 5.246594922827643 Test RE 1.0948303488327267\n",
      "2 Train Loss 56.380642 Test MSE 8.319396979209907 Test RE 1.378649870474492\n",
      "3 Train Loss 46.450027 Test MSE 7.881299877643499 Test RE 1.341859318529551\n",
      "4 Train Loss 43.53386 Test MSE 8.096906022027687 Test RE 1.3600898812595859\n",
      "5 Train Loss 39.733063 Test MSE 8.228854375147096 Test RE 1.3711272073466754\n",
      "6 Train Loss 37.110718 Test MSE 8.637676258109453 Test RE 1.4047741972702432\n",
      "7 Train Loss 33.98453 Test MSE 8.715593759868565 Test RE 1.4110959646930126\n",
      "8 Train Loss 30.870739 Test MSE 8.871334558575388 Test RE 1.4236477274101969\n",
      "9 Train Loss 28.903439 Test MSE 9.062916046944741 Test RE 1.4389378576067025\n",
      "10 Train Loss 26.954975 Test MSE 8.970256685201367 Test RE 1.4315631003688465\n",
      "11 Train Loss 25.601074 Test MSE 8.920716240423067 Test RE 1.4276045479442103\n",
      "12 Train Loss 24.022594 Test MSE 9.02917111674679 Test RE 1.4362564832621185\n",
      "13 Train Loss 22.418789 Test MSE 8.768087260853035 Test RE 1.415339058692505\n",
      "14 Train Loss 20.522295 Test MSE 8.500754440636653 Test RE 1.393595694047049\n",
      "15 Train Loss 18.1125 Test MSE 8.476870143783419 Test RE 1.3916365463989315\n",
      "16 Train Loss 16.886765 Test MSE 8.440629940767481 Test RE 1.388658607108353\n",
      "17 Train Loss 15.061648 Test MSE 8.324601506373211 Test RE 1.3790810374739\n",
      "18 Train Loss 13.277554 Test MSE 8.189496500832467 Test RE 1.3678442877788142\n",
      "19 Train Loss 11.631115 Test MSE 8.11563814890446 Test RE 1.3616622508625342\n",
      "20 Train Loss 10.320979 Test MSE 8.24727586683654 Test RE 1.3726610835740638\n",
      "21 Train Loss 9.268125 Test MSE 7.986301472794053 Test RE 1.3507684567326441\n",
      "22 Train Loss 8.332846 Test MSE 7.935746775358177 Test RE 1.346486368048878\n",
      "23 Train Loss 6.9562526 Test MSE 7.72209726341795 Test RE 1.328237367089109\n",
      "24 Train Loss 5.629044 Test MSE 7.313471401258365 Test RE 1.2926169425888698\n",
      "25 Train Loss 4.7734933 Test MSE 7.125523606023572 Test RE 1.2758994548465166\n",
      "26 Train Loss 4.289949 Test MSE 7.037023179063225 Test RE 1.2679512350305207\n",
      "27 Train Loss 3.886457 Test MSE 6.884873877235743 Test RE 1.2541689793815647\n",
      "28 Train Loss 3.6318254 Test MSE 6.904573982128177 Test RE 1.2559620123429598\n",
      "29 Train Loss 3.4191127 Test MSE 6.830257754160376 Test RE 1.2491845574096405\n",
      "30 Train Loss 3.1911767 Test MSE 6.842702301519291 Test RE 1.2503220299984594\n",
      "31 Train Loss 3.0120676 Test MSE 6.9473316918927095 Test RE 1.2598448859326883\n",
      "32 Train Loss 2.8780189 Test MSE 6.971094152021062 Test RE 1.2619976159267035\n",
      "33 Train Loss 2.7437582 Test MSE 6.885811353483345 Test RE 1.2542543631974723\n",
      "34 Train Loss 2.6633065 Test MSE 6.947637991938587 Test RE 1.2598726581990918\n",
      "35 Train Loss 2.5879853 Test MSE 6.975824438650795 Test RE 1.2624257121467515\n",
      "36 Train Loss 2.516001 Test MSE 6.978115450435453 Test RE 1.2626329990975838\n",
      "37 Train Loss 2.465746 Test MSE 6.969666098959448 Test RE 1.2618683469894283\n",
      "38 Train Loss 2.3855193 Test MSE 6.952253074475722 Test RE 1.2602910342753084\n",
      "39 Train Loss 2.3286333 Test MSE 7.000635509104771 Test RE 1.2646687682864923\n",
      "40 Train Loss 2.2783136 Test MSE 7.063622455028705 Test RE 1.2703453421144728\n",
      "41 Train Loss 2.2218084 Test MSE 7.058051317642428 Test RE 1.269844277363376\n",
      "42 Train Loss 2.1663332 Test MSE 7.039371221504958 Test RE 1.2681627559342339\n",
      "43 Train Loss 2.1231117 Test MSE 7.0828082308659805 Test RE 1.2720693890713013\n",
      "44 Train Loss 2.089702 Test MSE 7.115478448237926 Test RE 1.2749997924307734\n",
      "45 Train Loss 2.0519986 Test MSE 7.100410979067986 Test RE 1.2736491312546272\n",
      "46 Train Loss 2.0268593 Test MSE 7.117748925573059 Test RE 1.275203195986761\n",
      "47 Train Loss 2.0008252 Test MSE 7.142334354504356 Test RE 1.2774036382743648\n",
      "48 Train Loss 1.9687737 Test MSE 7.17782651839109 Test RE 1.280573584724258\n",
      "49 Train Loss 1.9455214 Test MSE 7.203046819322529 Test RE 1.2828213495101126\n",
      "50 Train Loss 1.9189867 Test MSE 7.206812171737444 Test RE 1.283156599544065\n",
      "51 Train Loss 1.8941853 Test MSE 7.236271998555081 Test RE 1.285776552581507\n",
      "52 Train Loss 1.8770032 Test MSE 7.276817584834147 Test RE 1.2893736908582036\n",
      "53 Train Loss 1.8560948 Test MSE 7.268119535620144 Test RE 1.2886028601309167\n",
      "54 Train Loss 1.8334012 Test MSE 7.250523669955217 Test RE 1.287042083465068\n",
      "55 Train Loss 1.7959062 Test MSE 7.174117218018027 Test RE 1.2802426596250667\n",
      "56 Train Loss 1.7682136 Test MSE 7.1550958541617025 Test RE 1.2785443235254614\n",
      "57 Train Loss 1.7300493 Test MSE 7.162333955668215 Test RE 1.2791908483637076\n",
      "58 Train Loss 1.705245 Test MSE 7.110570878827227 Test RE 1.274560030769483\n",
      "59 Train Loss 1.6902075 Test MSE 7.09221097688835 Test RE 1.2729134736461096\n",
      "60 Train Loss 1.6702788 Test MSE 7.068754772146954 Test RE 1.2708067647993737\n",
      "61 Train Loss 1.6496222 Test MSE 7.061026672408232 Test RE 1.2701119035786683\n",
      "62 Train Loss 1.6248943 Test MSE 7.014772075068388 Test RE 1.2659450136450638\n",
      "63 Train Loss 1.587719 Test MSE 6.9662926569530175 Test RE 1.261562926697477\n",
      "64 Train Loss 1.5641229 Test MSE 6.944687111980259 Test RE 1.2596050760492468\n",
      "65 Train Loss 1.5326438 Test MSE 6.875140516215007 Test RE 1.2532821369222493\n",
      "66 Train Loss 1.514402 Test MSE 6.819586004482548 Test RE 1.2482082987816157\n",
      "67 Train Loss 1.4986559 Test MSE 6.808154522584131 Test RE 1.2471616916116146\n",
      "68 Train Loss 1.4821638 Test MSE 6.783060746346943 Test RE 1.244861149841893\n",
      "69 Train Loss 1.4623443 Test MSE 6.704265304957447 Test RE 1.2376095625414305\n",
      "70 Train Loss 1.4432955 Test MSE 6.660737310746945 Test RE 1.2335853791031512\n",
      "71 Train Loss 1.4259225 Test MSE 6.624747058967713 Test RE 1.2302481221288937\n",
      "72 Train Loss 1.4100039 Test MSE 6.58832729631544 Test RE 1.226861797053064\n",
      "73 Train Loss 1.3954016 Test MSE 6.558124609278487 Test RE 1.2240464324049376\n",
      "74 Train Loss 1.3824269 Test MSE 6.541115353883934 Test RE 1.2224580487581813\n",
      "75 Train Loss 1.3694752 Test MSE 6.465680359043979 Test RE 1.2153886481350547\n",
      "76 Train Loss 1.3584824 Test MSE 6.401318075529915 Test RE 1.2093242564893856\n",
      "77 Train Loss 1.3431786 Test MSE 6.387061892665276 Test RE 1.2079768810654405\n",
      "78 Train Loss 1.3349186 Test MSE 6.3693868543419105 Test RE 1.2063042943751108\n",
      "79 Train Loss 1.3259178 Test MSE 6.328191323484026 Test RE 1.202396935602695\n",
      "80 Train Loss 1.3177701 Test MSE 6.3236881113515695 Test RE 1.2019690398726446\n",
      "81 Train Loss 1.308288 Test MSE 6.297841748996552 Test RE 1.199510163356349\n",
      "82 Train Loss 1.2980111 Test MSE 6.254915316203408 Test RE 1.1954152102269529\n",
      "83 Train Loss 1.2864652 Test MSE 6.256420496276939 Test RE 1.1955590336705562\n",
      "84 Train Loss 1.2780292 Test MSE 6.24368127300596 Test RE 1.1943412243498974\n",
      "85 Train Loss 1.2678789 Test MSE 6.218209394347702 Test RE 1.1919025023388208\n",
      "86 Train Loss 1.2561617 Test MSE 6.196757939453262 Test RE 1.1898448254182181\n",
      "87 Train Loss 1.2410501 Test MSE 6.190777936415956 Test RE 1.1892705740785436\n",
      "88 Train Loss 1.2235596 Test MSE 6.117270900442404 Test RE 1.1821890081227397\n",
      "89 Train Loss 1.2097739 Test MSE 6.065989462488795 Test RE 1.1772233998486166\n",
      "90 Train Loss 1.198984 Test MSE 6.056863440755294 Test RE 1.1763375254026684\n",
      "91 Train Loss 1.1837021 Test MSE 6.011683572707281 Test RE 1.1719419950014147\n",
      "92 Train Loss 1.175931 Test MSE 5.979459471387343 Test RE 1.1687968260697659\n",
      "93 Train Loss 1.1706324 Test MSE 5.961805709955797 Test RE 1.1670701722926877\n",
      "94 Train Loss 1.1642355 Test MSE 5.970623096725758 Test RE 1.1679328896929202\n",
      "95 Train Loss 1.1562059 Test MSE 5.97680846346947 Test RE 1.1685377028863069\n",
      "96 Train Loss 1.1448989 Test MSE 5.945291944947046 Test RE 1.1654527020130954\n",
      "97 Train Loss 1.1380103 Test MSE 5.914933539874366 Test RE 1.1624733220228842\n",
      "98 Train Loss 1.1285887 Test MSE 5.902913042960771 Test RE 1.1612915155454153\n",
      "99 Train Loss 1.1210191 Test MSE 5.889824642411979 Test RE 1.160003347898028\n",
      "Training time: 197.10\n",
      "6\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.38829 Test MSE 6.04683163255236 Test RE 1.17536295474155\n",
      "1 Train Loss 53.435814 Test MSE 9.208442833632768 Test RE 1.4504446432372062\n",
      "2 Train Loss 44.832996 Test MSE 9.30482298947388 Test RE 1.4580154234690332\n",
      "3 Train Loss 40.779396 Test MSE 8.996869053685119 Test RE 1.4336850614105845\n",
      "4 Train Loss 38.568787 Test MSE 9.051811195532855 Test RE 1.4380560173209525\n",
      "5 Train Loss 35.569305 Test MSE 8.7056188845 Test RE 1.4102882437057687\n",
      "6 Train Loss 33.592598 Test MSE 8.598547118599795 Test RE 1.4015887341400657\n",
      "7 Train Loss 29.95379 Test MSE 8.284000005577322 Test RE 1.3757138372516629\n",
      "8 Train Loss 27.488976 Test MSE 8.725045613267106 Test RE 1.4118609073047148\n",
      "9 Train Loss 25.455044 Test MSE 8.646230858450503 Test RE 1.4054696567616163\n",
      "10 Train Loss 23.652311 Test MSE 8.591818038849102 Test RE 1.4010401968013408\n",
      "11 Train Loss 21.99712 Test MSE 8.5159908188683 Test RE 1.3948440447276111\n",
      "12 Train Loss 20.594727 Test MSE 8.797482028233038 Test RE 1.4177095159421014\n",
      "13 Train Loss 19.70255 Test MSE 8.675929455088973 Test RE 1.407881383637447\n",
      "14 Train Loss 18.852308 Test MSE 8.776718483765865 Test RE 1.4160355105909057\n",
      "15 Train Loss 17.63161 Test MSE 8.672081669887996 Test RE 1.4075691504669008\n",
      "16 Train Loss 16.415298 Test MSE 8.754746113036962 Test RE 1.414261889002854\n",
      "17 Train Loss 15.058918 Test MSE 8.4545698023234 Test RE 1.3898048321563583\n",
      "18 Train Loss 13.602312 Test MSE 8.57447545498181 Test RE 1.3996254827909045\n",
      "19 Train Loss 12.735468 Test MSE 8.490545602747156 Test RE 1.3927586350185268\n",
      "20 Train Loss 11.619036 Test MSE 8.350070529928582 Test RE 1.3811890677001526\n",
      "21 Train Loss 10.2204895 Test MSE 7.955284606010679 Test RE 1.348142875687301\n",
      "22 Train Loss 8.581133 Test MSE 7.113445685002427 Test RE 1.2748176572550263\n",
      "23 Train Loss 7.2137604 Test MSE 6.766518267610768 Test RE 1.2433422440872859\n",
      "24 Train Loss 6.1178074 Test MSE 6.443146811541302 Test RE 1.2132689237120369\n",
      "25 Train Loss 5.2302055 Test MSE 6.22389044300414 Test RE 1.1924468479700296\n",
      "26 Train Loss 4.65337 Test MSE 6.168817758649673 Test RE 1.1871593858631513\n",
      "27 Train Loss 4.2471147 Test MSE 6.058776334612246 Test RE 1.1765232676774817\n",
      "28 Train Loss 3.9443035 Test MSE 5.898746795395505 Test RE 1.160881626231878\n",
      "29 Train Loss 3.6653666 Test MSE 5.610044813743916 Test RE 1.1321167749145051\n",
      "30 Train Loss 3.3048248 Test MSE 5.45225050632251 Test RE 1.1160816326905116\n",
      "31 Train Loss 3.039279 Test MSE 5.436428612299449 Test RE 1.1144610766705678\n",
      "32 Train Loss 2.9051416 Test MSE 5.404939454622513 Test RE 1.111228770290308\n",
      "33 Train Loss 2.7013502 Test MSE 5.3508985872080626 Test RE 1.1056595471739519\n",
      "34 Train Loss 2.519067 Test MSE 5.335016384087938 Test RE 1.10401745295828\n",
      "35 Train Loss 2.362274 Test MSE 5.375994334966073 Test RE 1.1082492893363782\n",
      "36 Train Loss 2.2642899 Test MSE 5.412845849487278 Test RE 1.1120412310840433\n",
      "37 Train Loss 2.1839576 Test MSE 5.426205698140169 Test RE 1.1134127412856722\n",
      "38 Train Loss 2.065656 Test MSE 5.463569214546025 Test RE 1.1172395080403446\n",
      "39 Train Loss 1.9644866 Test MSE 5.460637943100407 Test RE 1.1169397615269065\n",
      "40 Train Loss 1.8805629 Test MSE 5.444869618074659 Test RE 1.1153259389098467\n",
      "41 Train Loss 1.8332493 Test MSE 5.414829364574942 Test RE 1.11224496388803\n",
      "42 Train Loss 1.7942564 Test MSE 5.41475614545938 Test RE 1.1122374439956786\n",
      "43 Train Loss 1.7515196 Test MSE 5.459828301068558 Test RE 1.1168569548191063\n",
      "44 Train Loss 1.695097 Test MSE 5.4387861549063725 Test RE 1.1147026971235319\n",
      "45 Train Loss 1.6441114 Test MSE 5.474581420681412 Test RE 1.1183648784709048\n",
      "46 Train Loss 1.6057554 Test MSE 5.543624679761624 Test RE 1.1253949708452853\n",
      "47 Train Loss 1.5501317 Test MSE 5.4971046676954805 Test RE 1.1206630773276929\n",
      "48 Train Loss 1.5170124 Test MSE 5.506424236270152 Test RE 1.121612638428786\n",
      "49 Train Loss 1.4873173 Test MSE 5.568865166226958 Test RE 1.1279540597557611\n",
      "50 Train Loss 1.4422958 Test MSE 5.585155915095553 Test RE 1.129602671907235\n",
      "51 Train Loss 1.4151618 Test MSE 5.567681373121145 Test RE 1.1278341668181753\n",
      "52 Train Loss 1.3867757 Test MSE 5.557978468052459 Test RE 1.1268509891684673\n",
      "53 Train Loss 1.3657953 Test MSE 5.557045781385363 Test RE 1.1267564365361318\n",
      "54 Train Loss 1.3435644 Test MSE 5.550108517858815 Test RE 1.1260529109875557\n",
      "55 Train Loss 1.3260872 Test MSE 5.569681289873777 Test RE 1.1280367082154357\n",
      "56 Train Loss 1.3086765 Test MSE 5.59845064754323 Test RE 1.130946308431276\n",
      "57 Train Loss 1.2913264 Test MSE 5.610479224599535 Test RE 1.1321606064981113\n",
      "58 Train Loss 1.274493 Test MSE 5.611567844701089 Test RE 1.1322704396304255\n",
      "59 Train Loss 1.2607511 Test MSE 5.620070239825666 Test RE 1.133127897571642\n",
      "60 Train Loss 1.2507219 Test MSE 5.626613634580321 Test RE 1.1337873507387248\n",
      "61 Train Loss 1.2224691 Test MSE 5.694042061605626 Test RE 1.140560680594269\n",
      "62 Train Loss 1.2001815 Test MSE 5.7126089492625205 Test RE 1.1424187128053194\n",
      "63 Train Loss 1.1838838 Test MSE 5.709317588440176 Test RE 1.142089558999461\n",
      "64 Train Loss 1.165296 Test MSE 5.744738819795169 Test RE 1.1456269052900192\n",
      "65 Train Loss 1.1478066 Test MSE 5.777899997029757 Test RE 1.148928680309229\n",
      "66 Train Loss 1.134107 Test MSE 5.795203752428157 Test RE 1.150647809948411\n",
      "67 Train Loss 1.1169423 Test MSE 5.798563258621678 Test RE 1.1509812795332426\n",
      "68 Train Loss 1.1024647 Test MSE 5.79732752876058 Test RE 1.1508586303822468\n",
      "69 Train Loss 1.0841675 Test MSE 5.829480739350682 Test RE 1.1540456707706508\n",
      "70 Train Loss 1.069452 Test MSE 5.869103784333131 Test RE 1.1579610593893634\n",
      "71 Train Loss 1.0557249 Test MSE 5.900856288902697 Test RE 1.1610891833145516\n",
      "72 Train Loss 1.0363233 Test MSE 5.955941855358494 Test RE 1.1664960833564404\n",
      "73 Train Loss 1.0202663 Test MSE 5.996724158820578 Test RE 1.1704829623463817\n",
      "74 Train Loss 1.009233 Test MSE 6.025881881409347 Test RE 1.1733251167858985\n",
      "75 Train Loss 0.99894416 Test MSE 6.047835400418014 Test RE 1.1754605052174985\n",
      "76 Train Loss 0.9911156 Test MSE 6.035069560605936 Test RE 1.1742192621560286\n",
      "77 Train Loss 0.9817275 Test MSE 6.043941826770293 Test RE 1.1750820657756553\n",
      "78 Train Loss 0.97403467 Test MSE 6.054583988091086 Test RE 1.1761161519094847\n",
      "79 Train Loss 0.9668765 Test MSE 6.065178343693923 Test RE 1.1771446905173806\n",
      "80 Train Loss 0.95836514 Test MSE 6.080068796232717 Test RE 1.1785887924940868\n",
      "81 Train Loss 0.9513447 Test MSE 6.08072974097211 Test RE 1.1786528510532415\n",
      "82 Train Loss 0.9443335 Test MSE 6.089163460439922 Test RE 1.179469939097541\n",
      "83 Train Loss 0.9396291 Test MSE 6.110423956214313 Test RE 1.1815272221255468\n",
      "84 Train Loss 0.93145424 Test MSE 6.124933135247804 Test RE 1.1829291564016378\n",
      "85 Train Loss 0.92667866 Test MSE 6.129384806449683 Test RE 1.1833589615147224\n",
      "86 Train Loss 0.92317647 Test MSE 6.124651169215876 Test RE 1.1829019275591537\n",
      "87 Train Loss 0.9177861 Test MSE 6.12814540203851 Test RE 1.1832393137431305\n",
      "88 Train Loss 0.91209185 Test MSE 6.156623204940969 Test RE 1.1859854137154406\n",
      "89 Train Loss 0.9080865 Test MSE 6.163255172002018 Test RE 1.1866240185888928\n",
      "90 Train Loss 0.89793354 Test MSE 6.155762309666614 Test RE 1.1859024912351155\n",
      "91 Train Loss 0.8900393 Test MSE 6.153568850788007 Test RE 1.1856911883955659\n",
      "92 Train Loss 0.8832507 Test MSE 6.154202601714217 Test RE 1.1857522434971421\n",
      "93 Train Loss 0.8775685 Test MSE 6.166369795922203 Test RE 1.1869238131483222\n",
      "94 Train Loss 0.8725184 Test MSE 6.182780095787668 Test RE 1.1885021189185294\n",
      "95 Train Loss 0.8692737 Test MSE 6.191428276757485 Test RE 1.1893330387904204\n",
      "96 Train Loss 0.8638582 Test MSE 6.200455579987164 Test RE 1.1901997660480548\n",
      "97 Train Loss 0.85834444 Test MSE 6.207684556914668 Test RE 1.190893378010498\n",
      "98 Train Loss 0.8542427 Test MSE 6.219430995874835 Test RE 1.192019574499025\n",
      "99 Train Loss 0.85104585 Test MSE 6.228107713481149 Test RE 1.1928507769384757\n",
      "Training time: 197.30\n",
      "7\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.174206 Test MSE 7.082164977493392 Test RE 1.2720116237416956\n",
      "1 Train Loss 43.059914 Test MSE 7.3382966801646825 Test RE 1.2948089516084287\n",
      "2 Train Loss 34.2203 Test MSE 7.585564832433513 Test RE 1.3164428878373549\n",
      "3 Train Loss 27.088654 Test MSE 7.3885281301692896 Test RE 1.2992329488618104\n",
      "4 Train Loss 21.462866 Test MSE 6.682209817025556 Test RE 1.235572160381253\n",
      "5 Train Loss 17.15581 Test MSE 6.168717371370746 Test RE 1.1871497262987167\n",
      "6 Train Loss 15.425319 Test MSE 6.022063627693656 Test RE 1.1729533236618563\n",
      "7 Train Loss 13.53329 Test MSE 5.774866004021435 Test RE 1.1486269877122974\n",
      "8 Train Loss 12.197557 Test MSE 5.900555917750597 Test RE 1.1610596314904669\n",
      "9 Train Loss 11.295447 Test MSE 5.793812251362129 Test RE 1.1505096591734927\n",
      "10 Train Loss 10.500019 Test MSE 5.73934681221362 Test RE 1.1450891367927003\n",
      "11 Train Loss 9.698144 Test MSE 5.620989964377223 Test RE 1.1332206119745651\n",
      "12 Train Loss 8.895058 Test MSE 5.565720162845082 Test RE 1.1276355100856517\n",
      "13 Train Loss 8.064959 Test MSE 5.311619404287017 Test RE 1.1015939311841503\n",
      "14 Train Loss 7.3422685 Test MSE 5.229189627484093 Test RE 1.0930128199109252\n",
      "15 Train Loss 6.266765 Test MSE 5.148116714166928 Test RE 1.0845067325909565\n",
      "16 Train Loss 5.2576346 Test MSE 4.788864183068517 Test RE 1.0459822635566338\n",
      "17 Train Loss 4.614926 Test MSE 4.406921272775513 Test RE 1.0034037189913894\n",
      "18 Train Loss 3.9024594 Test MSE 4.143482694666743 Test RE 0.9729506777985585\n",
      "19 Train Loss 3.5101228 Test MSE 4.072701247842753 Test RE 0.9646046188005231\n",
      "20 Train Loss 3.0052078 Test MSE 3.655700984447763 Test RE 0.9138888803555126\n",
      "21 Train Loss 2.6660995 Test MSE 3.581192618046411 Test RE 0.9045277613826246\n",
      "22 Train Loss 2.4464188 Test MSE 3.3946014979322734 Test RE 0.8806482157847257\n",
      "23 Train Loss 2.2123842 Test MSE 3.1470297223350836 Test RE 0.847927035455851\n",
      "24 Train Loss 2.1148765 Test MSE 3.095725219518789 Test RE 0.840986961974534\n",
      "25 Train Loss 1.9933919 Test MSE 2.864347659151185 Test RE 0.808948594650192\n",
      "26 Train Loss 1.8701695 Test MSE 2.5432740056826226 Test RE 0.7622626432352106\n",
      "27 Train Loss 1.7635157 Test MSE 2.208053840010558 Test RE 0.7102526939862515\n",
      "28 Train Loss 1.6495581 Test MSE 1.9881793493462543 Test RE 0.6739626660192278\n",
      "29 Train Loss 1.5377017 Test MSE 1.808689831093259 Test RE 0.642821077923628\n",
      "30 Train Loss 1.433073 Test MSE 1.623518008191722 Test RE 0.6090270964070823\n",
      "31 Train Loss 1.3532703 Test MSE 1.5176085204610397 Test RE 0.5888273016760363\n",
      "32 Train Loss 1.2444429 Test MSE 1.338262759704349 Test RE 0.5529409530154695\n",
      "33 Train Loss 1.12246 Test MSE 1.2060221866334242 Test RE 0.5249110423829877\n",
      "34 Train Loss 1.0505594 Test MSE 1.195683599183179 Test RE 0.5226563080812788\n",
      "35 Train Loss 0.9436253 Test MSE 1.0853360089030832 Test RE 0.4979550789206594\n",
      "36 Train Loss 0.8375145 Test MSE 0.9066058934318196 Test RE 0.45511099656427084\n",
      "37 Train Loss 0.71122515 Test MSE 0.7237328864002206 Test RE 0.4066279377951518\n",
      "38 Train Loss 0.62391746 Test MSE 0.5478677259304698 Test RE 0.35379029798809414\n",
      "39 Train Loss 0.54010504 Test MSE 0.48862945653260553 Test RE 0.33411646856543986\n",
      "40 Train Loss 0.46773314 Test MSE 0.40016104858746016 Test RE 0.30236078659248206\n",
      "41 Train Loss 0.40399706 Test MSE 0.2983359728665535 Test RE 0.2610723460226889\n",
      "42 Train Loss 0.3329288 Test MSE 0.28462398406554956 Test RE 0.2550021293858979\n",
      "43 Train Loss 0.28854656 Test MSE 0.2141590136660264 Test RE 0.22119547546946478\n",
      "44 Train Loss 0.24737546 Test MSE 0.15754122616055669 Test RE 0.18971652926656993\n",
      "45 Train Loss 0.21297486 Test MSE 0.12048089738052908 Test RE 0.16590793471583043\n",
      "46 Train Loss 0.16896617 Test MSE 0.1070130427959077 Test RE 0.15636027181543727\n",
      "47 Train Loss 0.15256527 Test MSE 0.09271097425923953 Test RE 0.14553707181667813\n",
      "48 Train Loss 0.13836734 Test MSE 0.09191664613431214 Test RE 0.14491226512649008\n",
      "49 Train Loss 0.12418421 Test MSE 0.09122897011462894 Test RE 0.1443691655752264\n",
      "50 Train Loss 0.10577874 Test MSE 0.08443726527037967 Test RE 0.13889133100682424\n",
      "51 Train Loss 0.09504555 Test MSE 0.07952434747974164 Test RE 0.13479013783590268\n",
      "52 Train Loss 0.08373074 Test MSE 0.07380949473305888 Test RE 0.1298566444871975\n",
      "53 Train Loss 0.07411738 Test MSE 0.06355385246576634 Test RE 0.12049776759370219\n",
      "54 Train Loss 0.06546867 Test MSE 0.055096742123740806 Test RE 0.1121943586100967\n",
      "55 Train Loss 0.060841784 Test MSE 0.048225632885556084 Test RE 0.10496560859441201\n",
      "56 Train Loss 0.05599094 Test MSE 0.04624501455976678 Test RE 0.10278755142286398\n",
      "57 Train Loss 0.048259288 Test MSE 0.03481063390866442 Test RE 0.08917929325604801\n",
      "58 Train Loss 0.04284631 Test MSE 0.0331654401459087 Test RE 0.08704642572086915\n",
      "59 Train Loss 0.037325528 Test MSE 0.030743898727234747 Test RE 0.0838083963647887\n",
      "60 Train Loss 0.033292264 Test MSE 0.027306557536160046 Test RE 0.07898443882971122\n",
      "61 Train Loss 0.030335678 Test MSE 0.027193058286538827 Test RE 0.07882011915453739\n",
      "62 Train Loss 0.026591484 Test MSE 0.024020823638545723 Test RE 0.07408017636248032\n",
      "63 Train Loss 0.024217157 Test MSE 0.02243394050475236 Test RE 0.0715913978336374\n",
      "64 Train Loss 0.0220489 Test MSE 0.020764032388205008 Test RE 0.06887536432067701\n",
      "65 Train Loss 0.020086579 Test MSE 0.020762820564844787 Test RE 0.06887335445111777\n",
      "66 Train Loss 0.018612541 Test MSE 0.020477782494124918 Test RE 0.068398963909004\n",
      "67 Train Loss 0.016954616 Test MSE 0.015892688821908543 Test RE 0.06025689517938782\n",
      "68 Train Loss 0.015998323 Test MSE 0.014238277947311398 Test RE 0.057034389026082946\n",
      "69 Train Loss 0.0150937755 Test MSE 0.013445227062834457 Test RE 0.05542326808341071\n",
      "70 Train Loss 0.013852071 Test MSE 0.01240157287635547 Test RE 0.05322877176862757\n",
      "71 Train Loss 0.013119872 Test MSE 0.011901619451052402 Test RE 0.05214481009738049\n",
      "72 Train Loss 0.012387876 Test MSE 0.011719825024277548 Test RE 0.05174502774677037\n",
      "73 Train Loss 0.011689272 Test MSE 0.010935199972750899 Test RE 0.04998289709632113\n",
      "74 Train Loss 0.011111633 Test MSE 0.010676226471617336 Test RE 0.04938748936462942\n",
      "75 Train Loss 0.010628191 Test MSE 0.011629414514227937 Test RE 0.0515450524152665\n",
      "76 Train Loss 0.010119474 Test MSE 0.012703209911113305 Test RE 0.05387221069144255\n",
      "77 Train Loss 0.009535846 Test MSE 0.012756994276005254 Test RE 0.05398613552643207\n",
      "78 Train Loss 0.009074665 Test MSE 0.012430716737541465 Test RE 0.053291279227606056\n",
      "79 Train Loss 0.00851361 Test MSE 0.012221628036012424 Test RE 0.0528411902091767\n",
      "80 Train Loss 0.008266214 Test MSE 0.012397517565631158 Test RE 0.0532200681606051\n",
      "81 Train Loss 0.0078117605 Test MSE 0.011733546351867621 Test RE 0.05177530988752702\n",
      "82 Train Loss 0.007315204 Test MSE 0.01067446051997522 Test RE 0.04938340461028927\n",
      "83 Train Loss 0.006912009 Test MSE 0.01028805641986672 Test RE 0.04848135271555312\n",
      "84 Train Loss 0.0066231033 Test MSE 0.010080894594995343 Test RE 0.04799075663508566\n",
      "85 Train Loss 0.0063029164 Test MSE 0.009867137575353272 Test RE 0.04747922835148453\n",
      "86 Train Loss 0.005994482 Test MSE 0.009872583039893022 Test RE 0.04749232793536325\n",
      "87 Train Loss 0.0057909964 Test MSE 0.009786984166380129 Test RE 0.0472859918605655\n",
      "88 Train Loss 0.0054799668 Test MSE 0.009498205373678455 Test RE 0.046583148451609324\n",
      "89 Train Loss 0.0052852095 Test MSE 0.009462948122471646 Test RE 0.04649660995958329\n",
      "90 Train Loss 0.0051118704 Test MSE 0.00958131711401881 Test RE 0.04678651181612521\n",
      "91 Train Loss 0.0049861725 Test MSE 0.009507112761889739 Test RE 0.046604986100703225\n",
      "92 Train Loss 0.0047732196 Test MSE 0.008826159881887086 Test RE 0.04490492293470646\n",
      "93 Train Loss 0.0046261875 Test MSE 0.008245821913755173 Test RE 0.04340352837832794\n",
      "94 Train Loss 0.0045301337 Test MSE 0.00812793408119858 Test RE 0.04309214838680072\n",
      "95 Train Loss 0.0042126747 Test MSE 0.007765982462276809 Test RE 0.04212173611308532\n",
      "96 Train Loss 0.0040018945 Test MSE 0.007407589585604306 Test RE 0.04113831663012422\n",
      "97 Train Loss 0.0038672714 Test MSE 0.0071169544959616676 Test RE 0.04032321531301852\n",
      "98 Train Loss 0.0037570384 Test MSE 0.006992816419865573 Test RE 0.03996999774688094\n",
      "99 Train Loss 0.0036529207 Test MSE 0.006802268314646841 Test RE 0.03942166287132215\n",
      "Training time: 195.56\n",
      "8\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.05917 Test MSE 5.220353794510671 Test RE 1.0920889901656832\n",
      "1 Train Loss 49.2099 Test MSE 6.032489742637657 Test RE 1.1739682629155421\n",
      "2 Train Loss 31.774864 Test MSE 7.496506438629309 Test RE 1.3086922165369153\n",
      "3 Train Loss 23.341251 Test MSE 7.3146283065538125 Test RE 1.2927191769566835\n",
      "4 Train Loss 19.189688 Test MSE 6.879736395678929 Test RE 1.2537009626427216\n",
      "5 Train Loss 16.736307 Test MSE 7.14459769657846 Test RE 1.2776060211539617\n",
      "6 Train Loss 15.232368 Test MSE 7.204812664430836 Test RE 1.2829785833199787\n",
      "7 Train Loss 13.926928 Test MSE 7.159653744929679 Test RE 1.278951483523017\n",
      "8 Train Loss 13.061188 Test MSE 7.109231368441863 Test RE 1.2744399724196986\n",
      "9 Train Loss 12.006682 Test MSE 7.159923619607347 Test RE 1.2789755875774282\n",
      "10 Train Loss 11.102033 Test MSE 6.930548296458882 Test RE 1.2583221962496323\n",
      "11 Train Loss 10.415159 Test MSE 7.019569755068464 Test RE 1.266377854574855\n",
      "12 Train Loss 9.491451 Test MSE 6.75802497475556 Test RE 1.2425616812338516\n",
      "13 Train Loss 8.831065 Test MSE 6.7003868049938005 Test RE 1.237251524572278\n",
      "14 Train Loss 8.045721 Test MSE 6.508891639726383 Test RE 1.2194432132776225\n",
      "15 Train Loss 7.3560944 Test MSE 6.218793494314725 Test RE 1.1919584809831527\n",
      "16 Train Loss 6.568877 Test MSE 6.004641307648162 Test RE 1.1712553699928812\n",
      "17 Train Loss 6.169202 Test MSE 5.816999260043596 Test RE 1.1528095473265705\n",
      "18 Train Loss 5.644744 Test MSE 5.530358360968437 Test RE 1.124047586048698\n",
      "19 Train Loss 5.229603 Test MSE 5.278725993779243 Test RE 1.098177698614065\n",
      "20 Train Loss 4.8488684 Test MSE 5.2485744059655906 Test RE 1.095036863140557\n",
      "21 Train Loss 4.520898 Test MSE 5.054293424470554 Test RE 1.0745788434065342\n",
      "22 Train Loss 4.0937166 Test MSE 4.950496156468475 Test RE 1.06348758434987\n",
      "23 Train Loss 3.6054776 Test MSE 4.711098813354924 Test RE 1.0374547585227776\n",
      "24 Train Loss 3.0587573 Test MSE 4.360689201467098 Test RE 0.9981265949837957\n",
      "25 Train Loss 2.5411072 Test MSE 4.025659951471944 Test RE 0.9590176582574842\n",
      "26 Train Loss 2.1362412 Test MSE 3.7299229533829434 Test RE 0.9231196395385487\n",
      "27 Train Loss 1.9459076 Test MSE 3.5579878085431327 Test RE 0.9015924953794964\n",
      "28 Train Loss 1.6911737 Test MSE 3.4530673888392474 Test RE 0.8881996286544344\n",
      "29 Train Loss 1.5650337 Test MSE 3.400587616736272 Test RE 0.8814243514887807\n",
      "30 Train Loss 1.4746065 Test MSE 3.318630374208139 Test RE 0.8707380084297937\n",
      "31 Train Loss 1.3974117 Test MSE 3.2227714450005602 Test RE 0.8580701885124699\n",
      "32 Train Loss 1.3191683 Test MSE 3.1508556160508356 Test RE 0.8484422980418376\n",
      "33 Train Loss 1.2386037 Test MSE 3.0122836923562826 Test RE 0.8295756492485238\n",
      "34 Train Loss 1.1635507 Test MSE 2.967491679997659 Test RE 0.823384742710196\n",
      "35 Train Loss 1.1148714 Test MSE 2.8935404024547364 Test RE 0.8130604493308475\n",
      "36 Train Loss 1.0680795 Test MSE 2.8570767152924987 Test RE 0.8079212128677506\n",
      "37 Train Loss 1.0301106 Test MSE 2.846178941713422 Test RE 0.8063789101598346\n",
      "38 Train Loss 0.9829997 Test MSE 2.8100315439593984 Test RE 0.8012419105077156\n",
      "39 Train Loss 0.9587319 Test MSE 2.836206884267689 Test RE 0.8049650298639239\n",
      "40 Train Loss 0.93446267 Test MSE 2.8286173537118375 Test RE 0.8038872877495384\n",
      "41 Train Loss 0.9151844 Test MSE 2.816502420094854 Test RE 0.8021639207564787\n",
      "42 Train Loss 0.8931094 Test MSE 2.813299923022501 Test RE 0.80170774179972\n",
      "43 Train Loss 0.8777925 Test MSE 2.814807244012623 Test RE 0.8019224841164103\n",
      "44 Train Loss 0.85944766 Test MSE 2.8216812665310385 Test RE 0.8029010718792741\n",
      "45 Train Loss 0.8370006 Test MSE 2.8203762541364896 Test RE 0.8027153816950501\n",
      "46 Train Loss 0.8205737 Test MSE 2.828466042356989 Test RE 0.8038657862726375\n",
      "47 Train Loss 0.7969191 Test MSE 2.846242662020137 Test RE 0.8063879367222803\n",
      "48 Train Loss 0.77989274 Test MSE 2.8111297342779746 Test RE 0.8013984621587981\n",
      "49 Train Loss 0.7691914 Test MSE 2.800873311114082 Test RE 0.7999351727621414\n",
      "50 Train Loss 0.75767076 Test MSE 2.7921279627979643 Test RE 0.7986853516757404\n",
      "51 Train Loss 0.74593246 Test MSE 2.7720753076126967 Test RE 0.7958121629082993\n",
      "52 Train Loss 0.7360878 Test MSE 2.7761778576515592 Test RE 0.7964008287612404\n",
      "53 Train Loss 0.7226514 Test MSE 2.793889334983796 Test RE 0.7989372313156584\n",
      "54 Train Loss 0.7118448 Test MSE 2.8192600245223884 Test RE 0.8025565193177965\n",
      "55 Train Loss 0.7052146 Test MSE 2.817295566989552 Test RE 0.802276860307422\n",
      "56 Train Loss 0.696485 Test MSE 2.828451393012937 Test RE 0.8038637045573993\n",
      "57 Train Loss 0.688179 Test MSE 2.8514070200696535 Test RE 0.8071191794837644\n",
      "58 Train Loss 0.678737 Test MSE 2.8648238964121373 Test RE 0.8090158412795817\n",
      "59 Train Loss 0.6720984 Test MSE 2.875153079395392 Test RE 0.8104729908552142\n",
      "60 Train Loss 0.6635779 Test MSE 2.87389612276963 Test RE 0.8102958105914425\n",
      "61 Train Loss 0.6543244 Test MSE 2.882037593259617 Test RE 0.8114427438118725\n",
      "62 Train Loss 0.6457635 Test MSE 2.905275287590441 Test RE 0.814707482991763\n",
      "63 Train Loss 0.6389464 Test MSE 2.909252963180615 Test RE 0.8152650090947713\n",
      "64 Train Loss 0.63293624 Test MSE 2.9076542652472073 Test RE 0.8150409753638691\n",
      "65 Train Loss 0.6283974 Test MSE 2.9146701631486036 Test RE 0.8160236917574547\n",
      "66 Train Loss 0.6237074 Test MSE 2.907769637146435 Test RE 0.8150571450807512\n",
      "67 Train Loss 0.6186032 Test MSE 2.9102531007934584 Test RE 0.815405132202864\n",
      "68 Train Loss 0.61593527 Test MSE 2.9228541180665797 Test RE 0.8171685245148124\n",
      "69 Train Loss 0.6123579 Test MSE 2.9341671785351795 Test RE 0.8187484440602429\n",
      "70 Train Loss 0.60942006 Test MSE 2.944304896020034 Test RE 0.8201616360868711\n",
      "71 Train Loss 0.6049699 Test MSE 2.972068854313583 Test RE 0.8240195083213642\n",
      "72 Train Loss 0.6004429 Test MSE 2.982299619552516 Test RE 0.8254365528209007\n",
      "73 Train Loss 0.59426856 Test MSE 2.985605031092037 Test RE 0.8258938596428972\n",
      "74 Train Loss 0.5901216 Test MSE 3.0076926328866525 Test RE 0.8289432248436561\n",
      "75 Train Loss 0.5855279 Test MSE 3.005218829258468 Test RE 0.8286022550637578\n",
      "76 Train Loss 0.58089703 Test MSE 2.986348542157646 Test RE 0.825996690223602\n",
      "77 Train Loss 0.57756686 Test MSE 3.0030523788593015 Test RE 0.8283035331686708\n",
      "78 Train Loss 0.5731834 Test MSE 3.01225668865365 Test RE 0.8295719308629671\n",
      "79 Train Loss 0.56945467 Test MSE 3.0103081883907303 Test RE 0.8293035801253754\n",
      "80 Train Loss 0.5665738 Test MSE 3.0320802886447 Test RE 0.832297152559072\n",
      "81 Train Loss 0.56435275 Test MSE 3.036629211062356 Test RE 0.8329212515040711\n",
      "82 Train Loss 0.5607414 Test MSE 3.037883990145687 Test RE 0.833093321280818\n",
      "83 Train Loss 0.55675995 Test MSE 3.0459453632626703 Test RE 0.8341979432299862\n",
      "84 Train Loss 0.5518086 Test MSE 3.0681269757730005 Test RE 0.837229890227153\n",
      "85 Train Loss 0.54599077 Test MSE 3.079605093905701 Test RE 0.8387945015756432\n",
      "86 Train Loss 0.5423787 Test MSE 3.0731354899939007 Test RE 0.8379129727605226\n",
      "87 Train Loss 0.53880906 Test MSE 3.068316360229193 Test RE 0.8372557294251373\n",
      "88 Train Loss 0.5351189 Test MSE 3.074855935650119 Test RE 0.838147486017998\n",
      "89 Train Loss 0.5317318 Test MSE 3.084649937647354 Test RE 0.839481254501924\n",
      "90 Train Loss 0.5291587 Test MSE 3.0852170479825634 Test RE 0.8395584199219254\n",
      "91 Train Loss 0.52607185 Test MSE 3.0805128247327294 Test RE 0.8389181121531318\n",
      "92 Train Loss 0.52400213 Test MSE 3.0877756400206695 Test RE 0.8399064736056568\n",
      "93 Train Loss 0.5224164 Test MSE 3.098740127708903 Test RE 0.8413963783912741\n",
      "94 Train Loss 0.51967704 Test MSE 3.1029522436734505 Test RE 0.8419680390388772\n",
      "95 Train Loss 0.5173824 Test MSE 3.1077365821918637 Test RE 0.8426168902360902\n",
      "96 Train Loss 0.51558876 Test MSE 3.112975417506318 Test RE 0.84332680760157\n",
      "97 Train Loss 0.51282614 Test MSE 3.1234997479650053 Test RE 0.8447511621103571\n",
      "98 Train Loss 0.5106238 Test MSE 3.1381216423917313 Test RE 0.8467261007194736\n",
      "99 Train Loss 0.5093945 Test MSE 3.1393685762626298 Test RE 0.8468943074867258\n",
      "Training time: 196.41\n",
      "9\n",
      "KG_rowdy_tune51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 64.33415 Test MSE 7.028259183534825 Test RE 1.267161427985543\n",
      "1 Train Loss 51.87065 Test MSE 9.213673878311743 Test RE 1.4508565621490177\n",
      "2 Train Loss 46.106018 Test MSE 9.124797587731354 Test RE 1.4438420303100792\n",
      "3 Train Loss 41.446487 Test MSE 9.213325930655293 Test RE 1.4508291666218114\n",
      "4 Train Loss 39.0625 Test MSE 8.90383499567175 Test RE 1.4262531343746443\n",
      "5 Train Loss 37.39338 Test MSE 9.006442209493782 Test RE 1.4344476178802879\n",
      "6 Train Loss 35.332527 Test MSE 9.068778403019332 Test RE 1.439403171549218\n",
      "7 Train Loss 32.625404 Test MSE 8.93644853240872 Test RE 1.4288628324526316\n",
      "8 Train Loss 30.33849 Test MSE 9.09349327974096 Test RE 1.4413632187394352\n",
      "9 Train Loss 28.566807 Test MSE 9.193132371502111 Test RE 1.4492383472053603\n",
      "10 Train Loss 26.738117 Test MSE 9.083592992783432 Test RE 1.440578383080378\n",
      "11 Train Loss 25.3004 Test MSE 8.886568300992698 Test RE 1.424869537964593\n",
      "12 Train Loss 23.88438 Test MSE 8.587755993757092 Test RE 1.4007089653176468\n",
      "13 Train Loss 21.923512 Test MSE 8.877328380344315 Test RE 1.42412858233949\n",
      "14 Train Loss 21.014149 Test MSE 8.893610604521195 Test RE 1.4254340065113513\n",
      "15 Train Loss 19.963741 Test MSE 8.79078349502456 Test RE 1.4171696806438496\n",
      "16 Train Loss 18.862362 Test MSE 8.653455394494063 Test RE 1.4060567186951547\n",
      "17 Train Loss 17.915724 Test MSE 8.612074282419558 Test RE 1.4026907848279557\n",
      "18 Train Loss 16.77455 Test MSE 8.47533045756117 Test RE 1.391510156535379\n",
      "19 Train Loss 16.085903 Test MSE 8.12211705805064 Test RE 1.362205666292774\n",
      "20 Train Loss 15.409052 Test MSE 8.011638623806686 Test RE 1.3529094679632014\n",
      "21 Train Loss 14.754442 Test MSE 7.859046482300472 Test RE 1.3399635630842333\n",
      "22 Train Loss 14.048138 Test MSE 7.668084243171974 Test RE 1.3235839677629258\n",
      "23 Train Loss 13.380564 Test MSE 7.431841620651811 Test RE 1.3030356061797406\n",
      "24 Train Loss 12.788657 Test MSE 7.105094668399779 Test RE 1.274069134649186\n",
      "25 Train Loss 10.950758 Test MSE 6.535569334169861 Test RE 1.2219396957117905\n",
      "26 Train Loss 9.478893 Test MSE 6.374403830947131 Test RE 1.2067792858684812\n",
      "27 Train Loss 8.675055 Test MSE 6.293205550577455 Test RE 1.1990685683469606\n",
      "28 Train Loss 8.235884 Test MSE 6.087599421362758 Test RE 1.179318452316121\n",
      "29 Train Loss 7.862255 Test MSE 6.0551027641726645 Test RE 1.1761665375231638\n",
      "30 Train Loss 7.631365 Test MSE 6.11079834643004 Test RE 1.1815634180964927\n",
      "31 Train Loss 7.362114 Test MSE 6.141829876232566 Test RE 1.1845596951528303\n",
      "32 Train Loss 7.209322 Test MSE 6.1327657430026425 Test RE 1.1836852838238217\n",
      "33 Train Loss 7.034398 Test MSE 6.115149867765055 Test RE 1.181984040993797\n",
      "34 Train Loss 6.8409576 Test MSE 6.103229898556802 Test RE 1.180831486580954\n",
      "35 Train Loss 6.6550455 Test MSE 6.04974273267647 Test RE 1.1756458456618675\n",
      "36 Train Loss 6.497591 Test MSE 5.957111663379505 Test RE 1.166610633624921\n",
      "37 Train Loss 6.351412 Test MSE 5.886484256188506 Test RE 1.1596743560353107\n",
      "38 Train Loss 6.1495113 Test MSE 5.907071696815713 Test RE 1.1617005135360592\n",
      "39 Train Loss 5.9842863 Test MSE 5.933305250937663 Test RE 1.1642772363186256\n",
      "40 Train Loss 5.8041096 Test MSE 6.00239269541424 Test RE 1.1710360441721108\n",
      "41 Train Loss 5.58948 Test MSE 5.964781194165506 Test RE 1.1673613731352257\n",
      "42 Train Loss 5.3024626 Test MSE 5.822215178602835 Test RE 1.1533262753800442\n",
      "43 Train Loss 4.9759464 Test MSE 5.93206549327302 Test RE 1.1641555927342604\n",
      "44 Train Loss 4.556979 Test MSE 5.840200178209347 Test RE 1.1551062318104683\n",
      "45 Train Loss 3.9629521 Test MSE 5.309870582983023 Test RE 1.1014125694010208\n",
      "46 Train Loss 3.3775373 Test MSE 5.285909468515987 Test RE 1.0989246638640955\n",
      "47 Train Loss 2.9482815 Test MSE 5.258400309150489 Test RE 1.0960613980173273\n",
      "48 Train Loss 2.6456077 Test MSE 5.236534525331073 Test RE 1.0937801711651314\n",
      "49 Train Loss 2.4035242 Test MSE 5.2244342580254965 Test RE 1.0925157197512152\n",
      "50 Train Loss 2.2659047 Test MSE 5.207332333331275 Test RE 1.090726106167701\n",
      "51 Train Loss 2.096321 Test MSE 5.183448133364225 Test RE 1.0882218430160948\n",
      "52 Train Loss 1.9847095 Test MSE 5.271857821194255 Test RE 1.0974630442679727\n",
      "53 Train Loss 1.8859199 Test MSE 5.242163638420865 Test RE 1.0943679032318507\n",
      "54 Train Loss 1.811768 Test MSE 5.276249121857411 Test RE 1.0979200261512043\n",
      "55 Train Loss 1.7415407 Test MSE 5.341000084808451 Test RE 1.1046364068896901\n",
      "56 Train Loss 1.6694226 Test MSE 5.3253741114352 Test RE 1.1030193256038\n",
      "57 Train Loss 1.6342596 Test MSE 5.317976430502963 Test RE 1.1022529361821876\n",
      "58 Train Loss 1.597848 Test MSE 5.329376957866904 Test RE 1.1034337929736435\n",
      "59 Train Loss 1.5446252 Test MSE 5.321003286386169 Test RE 1.1025665786193586\n",
      "60 Train Loss 1.5124642 Test MSE 5.274963087190408 Test RE 1.0977862143057824\n",
      "61 Train Loss 1.4828272 Test MSE 5.2687458186111655 Test RE 1.097139077640707\n",
      "62 Train Loss 1.4607915 Test MSE 5.2832882905504475 Test RE 1.098652162574267\n",
      "63 Train Loss 1.4372184 Test MSE 5.302879878869735 Test RE 1.100687298872319\n",
      "64 Train Loss 1.413247 Test MSE 5.348692169085371 Test RE 1.105431566886296\n",
      "65 Train Loss 1.3880764 Test MSE 5.404592503433355 Test RE 1.1111931039952603\n",
      "66 Train Loss 1.3594011 Test MSE 5.423985641784526 Test RE 1.1131849493393648\n",
      "67 Train Loss 1.3351781 Test MSE 5.416205485669795 Test RE 1.112386287503363\n",
      "68 Train Loss 1.3110223 Test MSE 5.3975630624419715 Test RE 1.110470236558607\n",
      "69 Train Loss 1.2882144 Test MSE 5.410663038235004 Test RE 1.1118169848235724\n",
      "70 Train Loss 1.268464 Test MSE 5.442389037581799 Test RE 1.115071849175633\n",
      "71 Train Loss 1.2544158 Test MSE 5.471297918380074 Test RE 1.1180294460287536\n",
      "72 Train Loss 1.240531 Test MSE 5.5264288635988015 Test RE 1.1236481791189779\n",
      "73 Train Loss 1.2234527 Test MSE 5.5533021076376325 Test RE 1.1263768356359238\n",
      "74 Train Loss 1.204006 Test MSE 5.564630681483121 Test RE 1.1275251382054305\n",
      "75 Train Loss 1.1853936 Test MSE 5.601153161819297 Test RE 1.1312192437463395\n",
      "76 Train Loss 1.1720731 Test MSE 5.611950845099453 Test RE 1.13230907879885\n",
      "77 Train Loss 1.1590163 Test MSE 5.621012054154191 Test RE 1.133222838678948\n",
      "78 Train Loss 1.1483991 Test MSE 5.633824996565937 Test RE 1.1345136786389156\n",
      "79 Train Loss 1.1388795 Test MSE 5.640993736570126 Test RE 1.1352352530604533\n",
      "80 Train Loss 1.131359 Test MSE 5.6602943743550505 Test RE 1.1371756961400001\n",
      "81 Train Loss 1.1250527 Test MSE 5.6922827626076 Test RE 1.1403844663812757\n",
      "82 Train Loss 1.1162845 Test MSE 5.689775796328208 Test RE 1.1401333175568504\n",
      "83 Train Loss 1.1046569 Test MSE 5.666494231236527 Test RE 1.1377983136716538\n",
      "84 Train Loss 1.0953194 Test MSE 5.683984000930612 Test RE 1.139552881661953\n",
      "85 Train Loss 1.0827181 Test MSE 5.697508723007737 Test RE 1.1409078273150786\n",
      "86 Train Loss 1.0740849 Test MSE 5.698357578565373 Test RE 1.1409928144495867\n",
      "87 Train Loss 1.0665516 Test MSE 5.708331164049475 Test RE 1.14199089277137\n",
      "88 Train Loss 1.058004 Test MSE 5.722995728300766 Test RE 1.1434568253358721\n",
      "89 Train Loss 1.0528307 Test MSE 5.727859569680139 Test RE 1.1439426208633627\n",
      "90 Train Loss 1.0443343 Test MSE 5.73504077658856 Test RE 1.144659495582907\n",
      "91 Train Loss 1.0386341 Test MSE 5.7288594199806635 Test RE 1.1440424593326681\n",
      "92 Train Loss 1.0319884 Test MSE 5.726064914359242 Test RE 1.1437633965369014\n",
      "93 Train Loss 1.0236554 Test MSE 5.742171861689304 Test RE 1.145370922820847\n",
      "94 Train Loss 1.0178907 Test MSE 5.776266574437365 Test RE 1.148766266740389\n",
      "95 Train Loss 1.0103635 Test MSE 5.8073219612230575 Test RE 1.1518502274333988\n",
      "96 Train Loss 1.0043254 Test MSE 5.805013218963492 Test RE 1.151621241536327\n",
      "97 Train Loss 0.99934655 Test MSE 5.8164703854668725 Test RE 1.1527571401065533\n",
      "98 Train Loss 0.9923276 Test MSE 5.847195240494905 Test RE 1.1557977853347747\n",
      "99 Train Loss 0.98665357 Test MSE 5.8491314820264595 Test RE 1.1559891350629512\n",
      "Training time: 195.37\n",
      "0\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.56886 Test MSE 4.511538600679136 Test RE 1.015243924073145\n",
      "1 Train Loss 67.80221 Test MSE 4.389281259261777 Test RE 1.0013934943879939\n",
      "2 Train Loss 57.76757 Test MSE 4.688865722269506 Test RE 1.0350038330482552\n",
      "3 Train Loss 45.444695 Test MSE 5.7849293259700865 Test RE 1.149627354807489\n",
      "4 Train Loss 33.67137 Test MSE 6.223657457394733 Test RE 1.192424528686122\n",
      "5 Train Loss 28.118797 Test MSE 5.576173137209714 Test RE 1.1286939190218706\n",
      "6 Train Loss 23.543848 Test MSE 5.706218784647539 Test RE 1.1417795752092101\n",
      "7 Train Loss 21.207712 Test MSE 5.551468381204396 Test RE 1.1261908528213627\n",
      "8 Train Loss 18.85386 Test MSE 5.154129035897018 Test RE 1.085139828257259\n",
      "9 Train Loss 17.114521 Test MSE 5.271267184268185 Test RE 1.0974015649586464\n",
      "10 Train Loss 14.900963 Test MSE 5.485571212623365 Test RE 1.1194868304948862\n",
      "11 Train Loss 13.815809 Test MSE 5.307625026293661 Test RE 1.1011796497969502\n",
      "12 Train Loss 12.461666 Test MSE 5.3577482214867 Test RE 1.1063669929714963\n",
      "13 Train Loss 11.71167 Test MSE 5.2508161941996665 Test RE 1.0952706960342036\n",
      "14 Train Loss 10.715591 Test MSE 5.16898759332756 Test RE 1.086702847789299\n",
      "15 Train Loss 9.961834 Test MSE 5.250582541202155 Test RE 1.0952463268581798\n",
      "16 Train Loss 9.249645 Test MSE 5.077326938789153 Test RE 1.0770246048490648\n",
      "17 Train Loss 8.269588 Test MSE 4.994031668801589 Test RE 1.068153594497095\n",
      "18 Train Loss 7.6377745 Test MSE 5.019174331830186 Test RE 1.070839050886855\n",
      "19 Train Loss 6.9769516 Test MSE 4.825510909607893 Test RE 1.0499768195004473\n",
      "20 Train Loss 6.343563 Test MSE 4.701592464408151 Test RE 1.0364075095037177\n",
      "21 Train Loss 5.677372 Test MSE 4.559475794624367 Test RE 1.0206233912135254\n",
      "22 Train Loss 5.259096 Test MSE 4.559835046352597 Test RE 1.0206635990698067\n",
      "23 Train Loss 5.0444646 Test MSE 4.595950768015993 Test RE 1.0246976594312396\n",
      "24 Train Loss 4.692164 Test MSE 4.532241845498906 Test RE 1.0175707117737098\n",
      "25 Train Loss 4.3134146 Test MSE 4.543600581990955 Test RE 1.018845035292534\n",
      "26 Train Loss 4.0588746 Test MSE 4.50658340505184 Test RE 1.0146862302552262\n",
      "27 Train Loss 3.7841954 Test MSE 4.637794514376504 Test RE 1.0293517603166313\n",
      "28 Train Loss 3.5648022 Test MSE 4.448436855771241 Test RE 1.0081189430219493\n",
      "29 Train Loss 3.3723323 Test MSE 4.323486895202923 Test RE 0.9938598212617251\n",
      "30 Train Loss 3.1438918 Test MSE 4.363793486539642 Test RE 0.9984818046889806\n",
      "31 Train Loss 2.8731837 Test MSE 4.462281897130564 Test RE 1.00968652796298\n",
      "32 Train Loss 2.7007651 Test MSE 4.407520645544454 Test RE 1.0034719517076638\n",
      "33 Train Loss 2.547456 Test MSE 4.316523889439929 Test RE 0.9930591896933681\n",
      "34 Train Loss 2.424964 Test MSE 4.285610765788771 Test RE 0.9894968647133681\n",
      "35 Train Loss 2.3030484 Test MSE 4.275727483715086 Test RE 0.9883552396431801\n",
      "36 Train Loss 2.2140625 Test MSE 4.194769429159167 Test RE 0.9789535991392019\n",
      "37 Train Loss 2.1302361 Test MSE 4.239580373258355 Test RE 0.9841685819870788\n",
      "38 Train Loss 2.0221589 Test MSE 4.275168191970644 Test RE 0.9882905960233367\n",
      "39 Train Loss 1.9714055 Test MSE 4.196218017346658 Test RE 0.9791226165591111\n",
      "40 Train Loss 1.8836687 Test MSE 4.050949727789753 Test RE 0.962025285675609\n",
      "41 Train Loss 1.8238244 Test MSE 4.080152342045437 Test RE 0.9654865979947145\n",
      "42 Train Loss 1.7830604 Test MSE 4.037084985975982 Test RE 0.960377565326016\n",
      "43 Train Loss 1.7418636 Test MSE 4.015020878153521 Test RE 0.9577495668856026\n",
      "44 Train Loss 1.6865871 Test MSE 3.967505204772023 Test RE 0.9520654669988466\n",
      "45 Train Loss 1.6270207 Test MSE 3.900408671998797 Test RE 0.9439807040551925\n",
      "46 Train Loss 1.5715299 Test MSE 3.906983179768606 Test RE 0.9447759534648086\n",
      "47 Train Loss 1.5117065 Test MSE 3.805103653380291 Test RE 0.9323764727107025\n",
      "48 Train Loss 1.4575189 Test MSE 3.7466815928873367 Test RE 0.9251911154571958\n",
      "49 Train Loss 1.3974957 Test MSE 3.7227044664743016 Test RE 0.9222259543061578\n",
      "50 Train Loss 1.3468025 Test MSE 3.63415727085077 Test RE 0.9111920442028427\n",
      "51 Train Loss 1.2916734 Test MSE 3.5812662866826264 Test RE 0.9045370648453284\n",
      "52 Train Loss 1.2463017 Test MSE 3.5588646557364614 Test RE 0.901703584875917\n",
      "53 Train Loss 1.1843073 Test MSE 3.4740679733321547 Test RE 0.8908964247241067\n",
      "54 Train Loss 1.1505867 Test MSE 3.447572044836753 Test RE 0.8874925897471315\n",
      "55 Train Loss 1.0988824 Test MSE 3.406670277860675 Test RE 0.8822123050550901\n",
      "56 Train Loss 1.0660008 Test MSE 3.37960147336018 Test RE 0.8787003627038232\n",
      "57 Train Loss 1.0326478 Test MSE 3.2567139531349127 Test RE 0.8625769878849648\n",
      "58 Train Loss 0.98398143 Test MSE 3.159941846508502 Test RE 0.8496647584475848\n",
      "59 Train Loss 0.93292767 Test MSE 3.137932681193285 Test RE 0.8467006076370476\n",
      "60 Train Loss 0.89337134 Test MSE 3.1246167840748096 Test RE 0.844902199933024\n",
      "61 Train Loss 0.8624812 Test MSE 3.10783106562729 Test RE 0.8426296990329956\n",
      "62 Train Loss 0.83129805 Test MSE 3.050438779360728 Test RE 0.8348130260069329\n",
      "63 Train Loss 0.8067886 Test MSE 2.995147720149821 Test RE 0.8272126812357068\n",
      "64 Train Loss 0.77978677 Test MSE 2.998325040532332 Test RE 0.8276513278873101\n",
      "65 Train Loss 0.76086974 Test MSE 2.9824450412482246 Test RE 0.8254566773783343\n",
      "66 Train Loss 0.74835217 Test MSE 2.9767567526279666 Test RE 0.824669122746556\n",
      "67 Train Loss 0.73012894 Test MSE 2.968838196277902 Test RE 0.8235715292860629\n",
      "68 Train Loss 0.7175108 Test MSE 2.9469182204986906 Test RE 0.820525537443052\n",
      "69 Train Loss 0.70234776 Test MSE 2.9394919215830173 Test RE 0.81949101405016\n",
      "70 Train Loss 0.6880587 Test MSE 2.9748091672738073 Test RE 0.8243993028669703\n",
      "71 Train Loss 0.675395 Test MSE 2.978400382728078 Test RE 0.8248967637754339\n",
      "72 Train Loss 0.66808045 Test MSE 2.973043513685656 Test RE 0.8241546116015167\n",
      "73 Train Loss 0.65725046 Test MSE 2.9868957899823627 Test RE 0.8260723686280304\n",
      "74 Train Loss 0.6478168 Test MSE 2.9931123126836225 Test RE 0.8269315597065006\n",
      "75 Train Loss 0.6378869 Test MSE 2.9920800036233293 Test RE 0.8267889451852899\n",
      "76 Train Loss 0.62654597 Test MSE 2.9799981459778784 Test RE 0.8251179920948593\n",
      "77 Train Loss 0.6201555 Test MSE 2.9822607206435414 Test RE 0.8254311696116109\n",
      "78 Train Loss 0.6117364 Test MSE 2.9966392910261153 Test RE 0.8274186298039874\n",
      "79 Train Loss 0.605948 Test MSE 2.988359282980631 Test RE 0.8262747196909728\n",
      "80 Train Loss 0.59675163 Test MSE 2.9878107455373675 Test RE 0.8261988815168707\n",
      "81 Train Loss 0.5929252 Test MSE 3.000256802857169 Test RE 0.8279179047579934\n",
      "82 Train Loss 0.58575153 Test MSE 3.0118086053767175 Test RE 0.829510227765882\n",
      "83 Train Loss 0.5788989 Test MSE 3.0121105815676423 Test RE 0.8295518117596218\n",
      "84 Train Loss 0.56990767 Test MSE 3.0112828930637745 Test RE 0.8294378289469505\n",
      "85 Train Loss 0.56307524 Test MSE 3.028292859453357 Test RE 0.8317771710223693\n",
      "86 Train Loss 0.55618757 Test MSE 3.002244317465111 Test RE 0.828192085705456\n",
      "87 Train Loss 0.55161417 Test MSE 2.9911874867952566 Test RE 0.8266656232681793\n",
      "88 Train Loss 0.54198587 Test MSE 3.0155495736463998 Test RE 0.8300252353300052\n",
      "89 Train Loss 0.5375139 Test MSE 3.0116745257662094 Test RE 0.8294917635039252\n",
      "90 Train Loss 0.53294325 Test MSE 3.0143045481754593 Test RE 0.8298538719978596\n",
      "91 Train Loss 0.5256474 Test MSE 3.028198848197321 Test RE 0.8317642599488508\n",
      "92 Train Loss 0.51773465 Test MSE 3.021268955233717 Test RE 0.8308119878155829\n",
      "93 Train Loss 0.51222277 Test MSE 3.042881684191696 Test RE 0.8337783103333268\n",
      "94 Train Loss 0.50503075 Test MSE 3.0579796577694505 Test RE 0.8358442445022903\n",
      "95 Train Loss 0.49919587 Test MSE 3.0431909234226038 Test RE 0.8338206764914167\n",
      "96 Train Loss 0.4931727 Test MSE 3.049058300099624 Test RE 0.8346241068764579\n",
      "97 Train Loss 0.4882765 Test MSE 3.0675249166759815 Test RE 0.8371477413124975\n",
      "98 Train Loss 0.48304027 Test MSE 3.073674653660311 Test RE 0.8379864730045788\n",
      "99 Train Loss 0.4772401 Test MSE 3.07154701707831 Test RE 0.8376963903633168\n",
      "Training time: 196.20\n",
      "1\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.51309 Test MSE 6.2260901164239 Test RE 1.1926575491338416\n",
      "1 Train Loss 50.784218 Test MSE 8.9357931431589 Test RE 1.4288104358821792\n",
      "2 Train Loss 47.264244 Test MSE 9.076085998187763 Test RE 1.4399829882063457\n",
      "3 Train Loss 41.605755 Test MSE 9.57081961278203 Test RE 1.478708692048933\n",
      "4 Train Loss 40.23615 Test MSE 9.613049913948872 Test RE 1.481967429697678\n",
      "5 Train Loss 37.527473 Test MSE 10.10634228825954 Test RE 1.5195152457403256\n",
      "6 Train Loss 36.29745 Test MSE 10.054519238583916 Test RE 1.5156143724422348\n",
      "7 Train Loss 34.918045 Test MSE 9.821077973881664 Test RE 1.497916621237372\n",
      "8 Train Loss 33.911797 Test MSE 9.876635242400031 Test RE 1.5021474599999243\n",
      "9 Train Loss 33.40345 Test MSE 9.866632009201355 Test RE 1.5013865663537231\n",
      "10 Train Loss 32.793358 Test MSE 9.598209717662234 Test RE 1.4808230903811406\n",
      "11 Train Loss 31.638842 Test MSE 9.697827834977328 Test RE 1.4884878540969004\n",
      "12 Train Loss 30.582722 Test MSE 9.13835632153567 Test RE 1.4449143501399309\n",
      "13 Train Loss 29.12508 Test MSE 8.688818702800566 Test RE 1.408926793078933\n",
      "14 Train Loss 26.801497 Test MSE 8.656242344016045 Test RE 1.4062831192174543\n",
      "15 Train Loss 24.758892 Test MSE 8.401401001213035 Test RE 1.3854278620042617\n",
      "16 Train Loss 23.886093 Test MSE 8.458506092033401 Test RE 1.3901283280866579\n",
      "17 Train Loss 23.210842 Test MSE 8.425217248053645 Test RE 1.3873901740650374\n",
      "18 Train Loss 22.768978 Test MSE 8.627428707318936 Test RE 1.4039406532321619\n",
      "19 Train Loss 22.582321 Test MSE 8.59883787623649 Test RE 1.4016124311191787\n",
      "20 Train Loss 22.242023 Test MSE 8.762126817270703 Test RE 1.4148579114064668\n",
      "21 Train Loss 21.90767 Test MSE 8.833423971736071 Test RE 1.4206025765386483\n",
      "22 Train Loss 21.644455 Test MSE 8.755585837228017 Test RE 1.414329712868296\n",
      "23 Train Loss 21.501411 Test MSE 8.655011698410222 Test RE 1.4061831510333789\n",
      "24 Train Loss 21.404112 Test MSE 8.692520808556546 Test RE 1.4092269167599056\n",
      "25 Train Loss 21.184446 Test MSE 8.55265762195171 Test RE 1.397843668539285\n",
      "26 Train Loss 20.953213 Test MSE 8.21414304941946 Test RE 1.3699010267966982\n",
      "27 Train Loss 20.82593 Test MSE 8.250382943020451 Test RE 1.3729196271835347\n",
      "28 Train Loss 20.245472 Test MSE 8.041804438154287 Test RE 1.3554540954379484\n",
      "29 Train Loss 19.867327 Test MSE 7.667618177581468 Test RE 1.3235437434841049\n",
      "30 Train Loss 19.380222 Test MSE 7.175106796774719 Test RE 1.2803309532238223\n",
      "31 Train Loss 18.301435 Test MSE 6.931971393185542 Test RE 1.258451379555665\n",
      "32 Train Loss 17.773895 Test MSE 6.9884578604684515 Test RE 1.2635683399673396\n",
      "33 Train Loss 16.90926 Test MSE 6.755036812119964 Test RE 1.2422869421695506\n",
      "34 Train Loss 16.640713 Test MSE 6.761115061169865 Test RE 1.2428457275469964\n",
      "35 Train Loss 16.26755 Test MSE 6.908483322994551 Test RE 1.256317522243195\n",
      "36 Train Loss 16.037624 Test MSE 6.95581041450579 Test RE 1.2606134269112612\n",
      "37 Train Loss 15.838789 Test MSE 6.901558671887781 Test RE 1.2556877355601257\n",
      "38 Train Loss 15.700327 Test MSE 6.922565120059843 Test RE 1.2575972678544283\n",
      "39 Train Loss 15.573834 Test MSE 6.931788636881863 Test RE 1.2584347903759543\n",
      "40 Train Loss 15.37163 Test MSE 6.923524630719306 Test RE 1.257684420243212\n",
      "41 Train Loss 15.242254 Test MSE 6.952319418094372 Test RE 1.260297047582606\n",
      "42 Train Loss 15.107525 Test MSE 6.889278218449941 Test RE 1.25457006915438\n",
      "43 Train Loss 14.893108 Test MSE 6.900925288125634 Test RE 1.2556301144843376\n",
      "44 Train Loss 14.82202 Test MSE 6.977603548282859 Test RE 1.2625866859913542\n",
      "45 Train Loss 14.7488985 Test MSE 6.962207446565319 Test RE 1.261192966230648\n",
      "46 Train Loss 14.628288 Test MSE 6.951843760015071 Test RE 1.2602539338610674\n",
      "47 Train Loss 14.543536 Test MSE 6.918926190509739 Test RE 1.257266688846743\n",
      "48 Train Loss 14.480816 Test MSE 6.935231539448305 Test RE 1.2587472732529685\n",
      "49 Train Loss 14.374688 Test MSE 6.9365884762351575 Test RE 1.2588704095124241\n",
      "50 Train Loss 14.266449 Test MSE 6.844250344957233 Test RE 1.2504634539030508\n",
      "51 Train Loss 14.153482 Test MSE 6.786556534075887 Test RE 1.2451818907246421\n",
      "52 Train Loss 14.065009 Test MSE 6.762976799799578 Test RE 1.2430168305837896\n",
      "53 Train Loss 13.903255 Test MSE 6.666242936127071 Test RE 1.2340951016589339\n",
      "54 Train Loss 13.684742 Test MSE 6.730092639309879 Test RE 1.2399911382401796\n",
      "55 Train Loss 13.45609 Test MSE 6.724454934775636 Test RE 1.2394716678068278\n",
      "56 Train Loss 13.346885 Test MSE 6.693319621296662 Test RE 1.2365988614565675\n",
      "57 Train Loss 13.185535 Test MSE 6.692432122302128 Test RE 1.236516875484679\n",
      "58 Train Loss 13.080465 Test MSE 6.661135679251397 Test RE 1.2336222679783677\n",
      "59 Train Loss 12.910726 Test MSE 6.643879382147424 Test RE 1.232023324625214\n",
      "60 Train Loss 12.668524 Test MSE 6.539747615026744 Test RE 1.2223302348689067\n",
      "61 Train Loss 12.412123 Test MSE 6.518209357021282 Test RE 1.2203157399858817\n",
      "62 Train Loss 12.241842 Test MSE 6.529893896196859 Test RE 1.221409018977018\n",
      "63 Train Loss 12.008812 Test MSE 6.471660244196084 Test RE 1.2159505538008257\n",
      "64 Train Loss 11.673946 Test MSE 6.3030886439460065 Test RE 1.2000097308075972\n",
      "65 Train Loss 10.610059 Test MSE 5.910641770138558 Test RE 1.1620515105932612\n",
      "66 Train Loss 9.72909 Test MSE 5.719902445079921 Test RE 1.1431477639586396\n",
      "67 Train Loss 9.448317 Test MSE 5.686858343733684 Test RE 1.1398409763886816\n",
      "68 Train Loss 8.9789 Test MSE 5.71396040385755 Test RE 1.1425538380808407\n",
      "69 Train Loss 8.81085 Test MSE 5.83621201990161 Test RE 1.1547117647453853\n",
      "70 Train Loss 8.722761 Test MSE 5.8406617059284045 Test RE 1.1551518726272323\n",
      "71 Train Loss 8.511531 Test MSE 5.873624937685088 Test RE 1.158406980255068\n",
      "72 Train Loss 8.190999 Test MSE 5.954933192184737 Test RE 1.1663973037267885\n",
      "73 Train Loss 7.8803453 Test MSE 5.984787994239914 Test RE 1.1693174896642342\n",
      "74 Train Loss 7.5407977 Test MSE 5.94655221253978 Test RE 1.1655762202907423\n",
      "75 Train Loss 7.109909 Test MSE 5.6187244966350045 Test RE 1.1329922239604937\n",
      "76 Train Loss 6.5092597 Test MSE 5.1117302123212225 Test RE 1.080667330388802\n",
      "77 Train Loss 5.9188995 Test MSE 4.964572923366489 Test RE 1.064998527829127\n",
      "78 Train Loss 5.601752 Test MSE 4.883097360246239 Test RE 1.0562233202262574\n",
      "79 Train Loss 5.2995434 Test MSE 4.83837589248352 Test RE 1.0513755255524642\n",
      "80 Train Loss 4.9771767 Test MSE 4.8723071072202515 Test RE 1.0550556986342645\n",
      "81 Train Loss 4.795115 Test MSE 4.981363397671768 Test RE 1.0667979511489416\n",
      "82 Train Loss 4.5276513 Test MSE 4.923151808959431 Test RE 1.06054640015118\n",
      "83 Train Loss 4.353976 Test MSE 4.800166263007289 Test RE 1.0472158345929508\n",
      "84 Train Loss 4.15953 Test MSE 4.921664154368101 Test RE 1.0603861526117753\n",
      "85 Train Loss 4.024811 Test MSE 4.963682986389363 Test RE 1.064903069059241\n",
      "86 Train Loss 3.9072602 Test MSE 4.956240639691676 Test RE 1.0641044331634222\n",
      "87 Train Loss 3.762984 Test MSE 4.876642973558886 Test RE 1.0555250412999855\n",
      "88 Train Loss 3.6013238 Test MSE 4.867013163187491 Test RE 1.0544823641019796\n",
      "89 Train Loss 3.5203722 Test MSE 4.857130407772928 Test RE 1.053411225959185\n",
      "90 Train Loss 3.4256122 Test MSE 4.867893062123991 Test RE 1.0545776788204586\n",
      "91 Train Loss 3.3601775 Test MSE 4.909220854110216 Test RE 1.0590448325442399\n",
      "92 Train Loss 3.2762735 Test MSE 5.000910411428851 Test RE 1.0688889748244919\n",
      "93 Train Loss 3.1818774 Test MSE 5.01571849632372 Test RE 1.0704703367730952\n",
      "94 Train Loss 3.1311023 Test MSE 4.903243898159753 Test RE 1.058399944860283\n",
      "95 Train Loss 3.0575628 Test MSE 4.8818263625760165 Test RE 1.0560858516640936\n",
      "96 Train Loss 2.989269 Test MSE 4.904110032318575 Test RE 1.058493421330675\n",
      "97 Train Loss 2.907486 Test MSE 4.852832015762515 Test RE 1.0529450065831625\n",
      "98 Train Loss 2.8425257 Test MSE 4.8157680392895434 Test RE 1.0489163145121687\n",
      "99 Train Loss 2.7729259 Test MSE 4.875462763606149 Test RE 1.0553973082932528\n",
      "Training time: 195.84\n",
      "2\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.170395 Test MSE 5.019147292679792 Test RE 1.070836166486431\n",
      "1 Train Loss 51.455788 Test MSE 7.996663411787018 Test RE 1.3516444594303818\n",
      "2 Train Loss 42.34471 Test MSE 7.874605767132675 Test RE 1.3412893324303077\n",
      "3 Train Loss 33.886436 Test MSE 7.152531688178734 Test RE 1.2783152075428843\n",
      "4 Train Loss 26.208435 Test MSE 6.4581887684627866 Test RE 1.2146843268068057\n",
      "5 Train Loss 19.608398 Test MSE 6.089913355798666 Test RE 1.1795425641641115\n",
      "6 Train Loss 16.711088 Test MSE 5.85447160914178 Test RE 1.1565167108752368\n",
      "7 Train Loss 13.809633 Test MSE 5.747310441064408 Test RE 1.14588329543902\n",
      "8 Train Loss 12.558796 Test MSE 5.761336033217001 Test RE 1.147280635867097\n",
      "9 Train Loss 11.676518 Test MSE 5.854299344902373 Test RE 1.1564996958523264\n",
      "10 Train Loss 10.956625 Test MSE 5.883679262700015 Test RE 1.1593980224481473\n",
      "11 Train Loss 10.300083 Test MSE 5.858707875300639 Test RE 1.1569350600425483\n",
      "12 Train Loss 9.781787 Test MSE 5.810479497855212 Test RE 1.1521633248534358\n",
      "13 Train Loss 9.549595 Test MSE 5.682740258040385 Test RE 1.1394281990154858\n",
      "14 Train Loss 9.2537775 Test MSE 5.6429924240828555 Test RE 1.1354363505693776\n",
      "15 Train Loss 8.931151 Test MSE 5.661773743235286 Test RE 1.1373242919830888\n",
      "16 Train Loss 8.733042 Test MSE 5.666798691081593 Test RE 1.1378288801234222\n",
      "17 Train Loss 8.493243 Test MSE 5.459949589029842 Test RE 1.1168693600215533\n",
      "18 Train Loss 8.228525 Test MSE 5.368346623620565 Test RE 1.1074607294395662\n",
      "19 Train Loss 7.9367642 Test MSE 5.375077493250895 Test RE 1.108154782865431\n",
      "20 Train Loss 7.6674004 Test MSE 5.325242527740282 Test RE 1.1030056983682333\n",
      "21 Train Loss 7.412874 Test MSE 5.170569031548706 Test RE 1.086869072021885\n",
      "22 Train Loss 7.1441765 Test MSE 5.065995663217389 Test RE 1.0758221139098538\n",
      "23 Train Loss 6.6816945 Test MSE 4.7137164473027715 Test RE 1.0377429396646773\n",
      "24 Train Loss 6.266777 Test MSE 4.638473454287121 Test RE 1.0294271024231576\n",
      "25 Train Loss 5.805859 Test MSE 4.513221949857383 Test RE 1.0154333107535516\n",
      "26 Train Loss 5.36611 Test MSE 4.399883314380022 Test RE 1.0026021690026734\n",
      "27 Train Loss 4.945381 Test MSE 4.277710982621706 Test RE 0.988584460780527\n",
      "28 Train Loss 4.608294 Test MSE 4.0110192940096265 Test RE 0.9572721757342798\n",
      "29 Train Loss 4.307792 Test MSE 3.998014875344266 Test RE 0.9557190948473185\n",
      "30 Train Loss 4.1207514 Test MSE 3.8557656791163883 Test RE 0.9385628864312623\n",
      "31 Train Loss 3.8614857 Test MSE 3.6153728452128293 Test RE 0.9088340842863605\n",
      "32 Train Loss 3.6090612 Test MSE 3.582517141788773 Test RE 0.9046950181970121\n",
      "33 Train Loss 3.3907762 Test MSE 3.34917672290982 Test RE 0.8747361852173186\n",
      "34 Train Loss 3.122548 Test MSE 3.11108635337716 Test RE 0.8430708884296766\n",
      "35 Train Loss 2.9950757 Test MSE 3.018960978580718 Test RE 0.8304945945219931\n",
      "36 Train Loss 2.8541918 Test MSE 2.814315964379354 Test RE 0.8018524996838247\n",
      "37 Train Loss 2.624883 Test MSE 2.73002897316447 Test RE 0.789753734718158\n",
      "38 Train Loss 2.4718606 Test MSE 2.65077511911091 Test RE 0.7782058712307298\n",
      "39 Train Loss 2.3647747 Test MSE 2.5437548359452906 Test RE 0.7623346963494856\n",
      "40 Train Loss 2.2284539 Test MSE 2.4590817486415766 Test RE 0.7495395325063181\n",
      "41 Train Loss 2.120309 Test MSE 2.494951131097685 Test RE 0.7549863191750058\n",
      "42 Train Loss 2.018852 Test MSE 2.405351303748569 Test RE 0.7413056624809714\n",
      "43 Train Loss 1.8747174 Test MSE 2.1732352112995943 Test RE 0.7046304822043472\n",
      "44 Train Loss 1.7343854 Test MSE 1.9819230842860218 Test RE 0.672901440997238\n",
      "45 Train Loss 1.656203 Test MSE 1.9694682198810847 Test RE 0.6707837744033416\n",
      "46 Train Loss 1.5330076 Test MSE 1.8442659470130796 Test RE 0.649112293046445\n",
      "47 Train Loss 1.4625463 Test MSE 1.7899510977268585 Test RE 0.6394824693174117\n",
      "48 Train Loss 1.3854301 Test MSE 1.7176442395928753 Test RE 0.6264330590781523\n",
      "49 Train Loss 1.3163575 Test MSE 1.6705987768427197 Test RE 0.6177946453962805\n",
      "50 Train Loss 1.2554297 Test MSE 1.62312160296562 Test RE 0.6089527405141795\n",
      "51 Train Loss 1.2212785 Test MSE 1.6131969947685365 Test RE 0.6070881592790379\n",
      "52 Train Loss 1.1904368 Test MSE 1.5888834654753543 Test RE 0.6024958822740423\n",
      "53 Train Loss 1.1195076 Test MSE 1.5095597940339942 Test RE 0.5872637856832322\n",
      "54 Train Loss 1.0775092 Test MSE 1.471890905638735 Test RE 0.5798903360686694\n",
      "55 Train Loss 1.0400088 Test MSE 1.4350188536628774 Test RE 0.5725809091284431\n",
      "56 Train Loss 0.9977496 Test MSE 1.3607687144822729 Test RE 0.5575710523077863\n",
      "57 Train Loss 0.9587254 Test MSE 1.2707481807292818 Test RE 0.5388126813235896\n",
      "58 Train Loss 0.91365516 Test MSE 1.1648704656918898 Test RE 0.5158778455071346\n",
      "59 Train Loss 0.8595857 Test MSE 1.0423849706639303 Test RE 0.4880025942886672\n",
      "60 Train Loss 0.8159297 Test MSE 1.0122592254748055 Test RE 0.48089906427727447\n",
      "61 Train Loss 0.7620586 Test MSE 0.8583391575640182 Test RE 0.44283049769657123\n",
      "62 Train Loss 0.7115184 Test MSE 0.6703407582859179 Test RE 0.39134147127791097\n",
      "63 Train Loss 0.6924738 Test MSE 0.6250281248603534 Test RE 0.37788342266604286\n",
      "64 Train Loss 0.65355486 Test MSE 0.5427462477858923 Test RE 0.3521327960137057\n",
      "65 Train Loss 0.6036716 Test MSE 0.5092662896164033 Test RE 0.3410990618952999\n",
      "66 Train Loss 0.543484 Test MSE 0.44628711728099024 Test RE 0.31931199672350086\n",
      "67 Train Loss 0.48910993 Test MSE 0.3665618494183329 Test RE 0.2893887819082906\n",
      "68 Train Loss 0.44861057 Test MSE 0.3107240511619495 Test RE 0.2664375892917448\n",
      "69 Train Loss 0.40650162 Test MSE 0.2866951947933197 Test RE 0.2559282736921633\n",
      "70 Train Loss 0.36855727 Test MSE 0.27456783120272094 Test RE 0.25045683428982757\n",
      "71 Train Loss 0.3432207 Test MSE 0.23303553940276425 Test RE 0.23073800836196084\n",
      "72 Train Loss 0.31560308 Test MSE 0.2218624799885532 Test RE 0.22513861594236115\n",
      "73 Train Loss 0.27744552 Test MSE 0.21520967178219383 Test RE 0.22173740101503747\n",
      "74 Train Loss 0.26079437 Test MSE 0.2006868576925598 Test RE 0.21412507433725064\n",
      "75 Train Loss 0.2426061 Test MSE 0.18957942681445733 Test RE 0.20811513411148785\n",
      "76 Train Loss 0.21994312 Test MSE 0.1843559257845456 Test RE 0.20522799920223844\n",
      "77 Train Loss 0.20340762 Test MSE 0.1587686800060264 Test RE 0.19045416620070707\n",
      "78 Train Loss 0.18860199 Test MSE 0.1537936661764936 Test RE 0.18744647821934624\n",
      "79 Train Loss 0.17757624 Test MSE 0.14470410467678504 Test RE 0.1818228603208896\n",
      "80 Train Loss 0.15964618 Test MSE 0.1257824038209145 Test RE 0.1695188530857777\n",
      "81 Train Loss 0.15191907 Test MSE 0.11105917811387486 Test RE 0.15928881736438455\n",
      "82 Train Loss 0.14620744 Test MSE 0.1133031344199375 Test RE 0.160889989173946\n",
      "83 Train Loss 0.1432483 Test MSE 0.11508778010510425 Test RE 0.16215213336186055\n",
      "84 Train Loss 0.13466239 Test MSE 0.09978894716999416 Test RE 0.15099038085660538\n",
      "85 Train Loss 0.12168547 Test MSE 0.09207007767847115 Test RE 0.1450331618449994\n",
      "86 Train Loss 0.11224262 Test MSE 0.0777278375049354 Test RE 0.1332589395413193\n",
      "87 Train Loss 0.105082974 Test MSE 0.06237814125293806 Test RE 0.11937799350202366\n",
      "88 Train Loss 0.09921928 Test MSE 0.049843642236351536 Test RE 0.10671192279519634\n",
      "89 Train Loss 0.09202398 Test MSE 0.038005935187530565 Test RE 0.0931823742665559\n",
      "90 Train Loss 0.088700086 Test MSE 0.03151717746338946 Test RE 0.08485583645747363\n",
      "91 Train Loss 0.083180994 Test MSE 0.02411484529722982 Test RE 0.07422501608106265\n",
      "92 Train Loss 0.07743235 Test MSE 0.023487212210280054 Test RE 0.0732527268660922\n",
      "93 Train Loss 0.07512896 Test MSE 0.02399412141904732 Test RE 0.07403899011519562\n",
      "94 Train Loss 0.07309543 Test MSE 0.02365093679791756 Test RE 0.07350759841612357\n",
      "95 Train Loss 0.07093521 Test MSE 0.022064899536765437 Test RE 0.07100011260198402\n",
      "96 Train Loss 0.06777505 Test MSE 0.022077945970067625 Test RE 0.07102109981173953\n",
      "97 Train Loss 0.06475191 Test MSE 0.021690985027292598 Test RE 0.07039595379478447\n",
      "98 Train Loss 0.059387784 Test MSE 0.018571915904469365 Test RE 0.0651382991739422\n",
      "99 Train Loss 0.05671792 Test MSE 0.018365685066812975 Test RE 0.06477562718186795\n",
      "Training time: 195.43\n",
      "3\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.948555 Test MSE 5.300618031984786 Test RE 1.1004525347702019\n",
      "1 Train Loss 59.540215 Test MSE 5.968117004946107 Test RE 1.167687751608659\n",
      "2 Train Loss 46.647945 Test MSE 8.482434615624646 Test RE 1.3920932274532796\n",
      "3 Train Loss 40.118267 Test MSE 8.469630941974254 Test RE 1.3910421943910534\n",
      "4 Train Loss 36.432827 Test MSE 8.617781793682456 Test RE 1.4031555130217237\n",
      "5 Train Loss 33.329784 Test MSE 8.68617121427782 Test RE 1.4087121262854803\n",
      "6 Train Loss 30.12098 Test MSE 8.740418178960443 Test RE 1.4131041313486168\n",
      "7 Train Loss 27.792683 Test MSE 8.49985782727495 Test RE 1.3935221976604273\n",
      "8 Train Loss 25.767391 Test MSE 8.544137754836257 Test RE 1.3971472528604156\n",
      "9 Train Loss 23.708572 Test MSE 8.745320473420147 Test RE 1.4135003641903061\n",
      "10 Train Loss 22.025917 Test MSE 8.902421619424008 Test RE 1.4261399296539827\n",
      "11 Train Loss 21.083147 Test MSE 8.770896115218205 Test RE 1.4155657422803756\n",
      "12 Train Loss 19.994093 Test MSE 8.87021495943329 Test RE 1.4235578894576006\n",
      "13 Train Loss 19.358084 Test MSE 8.950783036943125 Test RE 1.430008356522198\n",
      "14 Train Loss 18.49234 Test MSE 8.86078874002356 Test RE 1.4228012935950975\n",
      "15 Train Loss 17.983568 Test MSE 8.860041611143298 Test RE 1.4227413080578357\n",
      "16 Train Loss 17.316225 Test MSE 9.119250753233807 Test RE 1.443403118094357\n",
      "17 Train Loss 16.77708 Test MSE 9.18316973608677 Test RE 1.4484528615561967\n",
      "18 Train Loss 16.14116 Test MSE 9.119312299926028 Test RE 1.4434079889187248\n",
      "19 Train Loss 15.764079 Test MSE 9.017705556601806 Test RE 1.4353442890003336\n",
      "20 Train Loss 15.132202 Test MSE 9.017948048046017 Test RE 1.4353635874996893\n",
      "21 Train Loss 14.715971 Test MSE 9.125535433863153 Test RE 1.4439004048499782\n",
      "22 Train Loss 14.278793 Test MSE 8.983906310373513 Test RE 1.4326518580640335\n",
      "23 Train Loss 13.9338875 Test MSE 8.972512465073388 Test RE 1.4317430889882399\n",
      "24 Train Loss 13.559155 Test MSE 9.002854559979045 Test RE 1.434161888633393\n",
      "25 Train Loss 13.177717 Test MSE 9.035275839009374 Test RE 1.4367419356524416\n",
      "26 Train Loss 12.927717 Test MSE 8.96905088827256 Test RE 1.431466880580322\n",
      "27 Train Loss 12.671374 Test MSE 8.971064278557314 Test RE 1.4316275408229382\n",
      "28 Train Loss 12.343239 Test MSE 8.80520736063971 Test RE 1.4183318459398242\n",
      "29 Train Loss 11.773468 Test MSE 8.610070028873036 Test RE 1.4025275540269058\n",
      "30 Train Loss 11.095147 Test MSE 8.458872494327553 Test RE 1.3901584362811334\n",
      "31 Train Loss 10.324591 Test MSE 7.895540728408183 Test RE 1.3430710852557572\n",
      "32 Train Loss 8.129248 Test MSE 7.241522663721049 Test RE 1.2862429500532129\n",
      "33 Train Loss 7.2484365 Test MSE 7.093365326580144 Test RE 1.2730170610531366\n",
      "34 Train Loss 6.7479706 Test MSE 6.951951657349241 Test RE 1.2602637138213861\n",
      "35 Train Loss 6.5372334 Test MSE 6.936526306286318 Test RE 1.2588647681164713\n",
      "36 Train Loss 6.2978106 Test MSE 7.006316913329889 Test RE 1.2651818386562954\n",
      "37 Train Loss 6.06625 Test MSE 7.041188408036626 Test RE 1.2683264310341145\n",
      "38 Train Loss 5.896184 Test MSE 7.049362730487049 Test RE 1.2690624361883487\n",
      "39 Train Loss 5.6965885 Test MSE 7.120340652553314 Test RE 1.2754353394470073\n",
      "40 Train Loss 5.518511 Test MSE 7.0145355731959045 Test RE 1.2659236729025156\n",
      "41 Train Loss 5.330153 Test MSE 6.907885017681022 Test RE 1.256263119729003\n",
      "42 Train Loss 5.1939497 Test MSE 6.880251961983814 Test RE 1.2537479378338032\n",
      "43 Train Loss 5.005376 Test MSE 6.826740858228507 Test RE 1.2488629137826603\n",
      "44 Train Loss 4.7500973 Test MSE 6.731755526183403 Test RE 1.240144318719597\n",
      "45 Train Loss 4.324752 Test MSE 6.336420120120591 Test RE 1.2031784436958384\n",
      "46 Train Loss 3.7703555 Test MSE 6.190287273131094 Test RE 1.1892234440590872\n",
      "47 Train Loss 3.4196205 Test MSE 6.121071217492206 Test RE 1.1825561649455223\n",
      "48 Train Loss 3.0644782 Test MSE 6.113391059198101 Test RE 1.1818140506253454\n",
      "49 Train Loss 2.8359396 Test MSE 5.881630032013351 Test RE 1.1591961010984868\n",
      "50 Train Loss 2.669602 Test MSE 5.7908255667605655 Test RE 1.1502130796257115\n",
      "51 Train Loss 2.4836733 Test MSE 5.789408382478576 Test RE 1.150072325632877\n",
      "52 Train Loss 2.3688617 Test MSE 5.814966715311186 Test RE 1.152608125460631\n",
      "53 Train Loss 2.2656207 Test MSE 5.8206625429032455 Test RE 1.1531724838339936\n",
      "54 Train Loss 2.181348 Test MSE 5.761100332373005 Test RE 1.147257167544958\n",
      "55 Train Loss 2.0930598 Test MSE 5.774360393398498 Test RE 1.148576703366409\n",
      "56 Train Loss 1.9862837 Test MSE 5.855616481916246 Test RE 1.1566297868160105\n",
      "57 Train Loss 1.9295957 Test MSE 5.83611537359283 Test RE 1.1547022038271555\n",
      "58 Train Loss 1.8516521 Test MSE 5.853289103065461 Test RE 1.1563999063885315\n",
      "59 Train Loss 1.7990772 Test MSE 5.857986145481101 Test RE 1.1568637968675404\n",
      "60 Train Loss 1.7489138 Test MSE 5.858282589354362 Test RE 1.1568930680912743\n",
      "61 Train Loss 1.7037592 Test MSE 5.842959546020711 Test RE 1.1553790808958146\n",
      "62 Train Loss 1.675753 Test MSE 5.837661535371896 Test RE 1.154855151298765\n",
      "63 Train Loss 1.6464617 Test MSE 5.855089515644015 Test RE 1.1565777411772256\n",
      "64 Train Loss 1.585902 Test MSE 5.871821688985276 Test RE 1.1582291466127594\n",
      "65 Train Loss 1.5273575 Test MSE 5.832444050362921 Test RE 1.154338952617719\n",
      "66 Train Loss 1.4952261 Test MSE 5.819966735607388 Test RE 1.1531035561300906\n",
      "67 Train Loss 1.4488279 Test MSE 5.856873277001003 Test RE 1.1567539042889114\n",
      "68 Train Loss 1.4179018 Test MSE 5.869288201216691 Test RE 1.157979251765936\n",
      "69 Train Loss 1.3956167 Test MSE 5.872969787387906 Test RE 1.1583423734875622\n",
      "70 Train Loss 1.3681412 Test MSE 5.86999752418472 Test RE 1.1580492224707692\n",
      "71 Train Loss 1.3446722 Test MSE 5.869162317015494 Test RE 1.1579668335586726\n",
      "72 Train Loss 1.32518 Test MSE 5.8807340517783215 Test RE 1.159107804457336\n",
      "73 Train Loss 1.3128165 Test MSE 5.908248543866717 Test RE 1.1618162287167377\n",
      "74 Train Loss 1.2990524 Test MSE 5.90315227881196 Test RE 1.161315047973159\n",
      "75 Train Loss 1.2798785 Test MSE 5.8976309052662845 Test RE 1.1607718166686407\n",
      "76 Train Loss 1.2592299 Test MSE 5.882210521020962 Test RE 1.1592533032676546\n",
      "77 Train Loss 1.2476404 Test MSE 5.87983870650799 Test RE 1.159019563670907\n",
      "78 Train Loss 1.2323569 Test MSE 5.894769771627602 Test RE 1.1604902183252563\n",
      "79 Train Loss 1.2244961 Test MSE 5.905193298539177 Test RE 1.1615157934363853\n",
      "80 Train Loss 1.2114922 Test MSE 5.922096364964077 Test RE 1.1631769709925823\n",
      "81 Train Loss 1.2004184 Test MSE 5.936521003126697 Test RE 1.1645927029725756\n",
      "82 Train Loss 1.1929247 Test MSE 5.949437399319539 Test RE 1.1658589469171383\n",
      "83 Train Loss 1.1819994 Test MSE 5.960726344966529 Test RE 1.1669645204343155\n",
      "84 Train Loss 1.1672301 Test MSE 5.944537169262472 Test RE 1.1653787205089274\n",
      "85 Train Loss 1.1553597 Test MSE 5.9434319022664885 Test RE 1.1652703761182335\n",
      "86 Train Loss 1.1444588 Test MSE 5.936100696305316 Test RE 1.164551475549884\n",
      "87 Train Loss 1.1340138 Test MSE 5.91206621290287 Test RE 1.1621915272118934\n",
      "88 Train Loss 1.1236517 Test MSE 5.898679847601316 Test RE 1.160875038503382\n",
      "89 Train Loss 1.1119004 Test MSE 5.888792466675585 Test RE 1.1599016997298557\n",
      "90 Train Loss 1.1041828 Test MSE 5.8688384428165685 Test RE 1.1579348834494134\n",
      "91 Train Loss 1.1000401 Test MSE 5.851829431316689 Test RE 1.156255708016333\n",
      "92 Train Loss 1.0919867 Test MSE 5.83738126119624 Test RE 1.154827427872296\n",
      "93 Train Loss 1.0787468 Test MSE 5.835293466939571 Test RE 1.154620891963042\n",
      "94 Train Loss 1.0720536 Test MSE 5.852259625830494 Test RE 1.1562982080350455\n",
      "95 Train Loss 1.0681366 Test MSE 5.856657821297613 Test RE 1.1567326274483145\n",
      "96 Train Loss 1.063077 Test MSE 5.85050457887657 Test RE 1.1561248126333084\n",
      "97 Train Loss 1.0589547 Test MSE 5.837070351689341 Test RE 1.1547966733617467\n",
      "98 Train Loss 1.0533124 Test MSE 5.828910990184143 Test RE 1.153989273584093\n",
      "99 Train Loss 1.0487112 Test MSE 5.831275808451385 Test RE 1.154223339448662\n",
      "Training time: 195.67\n",
      "4\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.259468 Test MSE 8.216917749157421 Test RE 1.3701323803935335\n",
      "1 Train Loss 52.06343 Test MSE 7.315055152174793 Test RE 1.2927568947631796\n",
      "2 Train Loss 44.761627 Test MSE 7.781995540677092 Test RE 1.3333788100824282\n",
      "3 Train Loss 35.27385 Test MSE 8.192457230652938 Test RE 1.368091522233828\n",
      "4 Train Loss 29.238365 Test MSE 8.06689170843135 Test RE 1.3575666912182849\n",
      "5 Train Loss 25.849655 Test MSE 7.6739813857439705 Test RE 1.3240928212792615\n",
      "6 Train Loss 22.683018 Test MSE 7.402207502757638 Test RE 1.3004351147491384\n",
      "7 Train Loss 19.96316 Test MSE 6.5106117246704365 Test RE 1.2196043319033172\n",
      "8 Train Loss 16.463158 Test MSE 5.986793533432244 Test RE 1.1695133959873656\n",
      "9 Train Loss 14.242996 Test MSE 6.089289857266118 Test RE 1.179482180556013\n",
      "10 Train Loss 12.745827 Test MSE 5.68198120236415 Test RE 1.1393520985528518\n",
      "11 Train Loss 11.7910385 Test MSE 5.619603720267799 Test RE 1.1330808663715026\n",
      "12 Train Loss 10.80646 Test MSE 5.6726353670517575 Test RE 1.1384146984724381\n",
      "13 Train Loss 10.126186 Test MSE 5.4732702865812595 Test RE 1.1182309491326767\n",
      "14 Train Loss 9.286392 Test MSE 5.1993339871904265 Test RE 1.0898881187945393\n",
      "15 Train Loss 8.694599 Test MSE 5.115018779449737 Test RE 1.0810148913432245\n",
      "16 Train Loss 8.314407 Test MSE 5.045510965350533 Test RE 1.0736448307545419\n",
      "17 Train Loss 7.95522 Test MSE 4.809793123150979 Test RE 1.0482654181137492\n",
      "18 Train Loss 7.6344705 Test MSE 4.71759096057311 Test RE 1.0381693466140405\n",
      "19 Train Loss 7.403838 Test MSE 4.760884025697622 Test RE 1.042922078283833\n",
      "20 Train Loss 7.0999637 Test MSE 4.612029506298205 Test RE 1.0264885250709685\n",
      "21 Train Loss 6.885117 Test MSE 4.530924858968614 Test RE 1.017422857319452\n",
      "22 Train Loss 6.7129984 Test MSE 4.453464919791125 Test RE 1.0086885200687798\n",
      "23 Train Loss 6.4861026 Test MSE 4.352978174850793 Test RE 0.9972437086015107\n",
      "24 Train Loss 6.2742343 Test MSE 4.286080608783592 Test RE 0.9895511038235097\n",
      "25 Train Loss 6.0594254 Test MSE 4.173807033544511 Test RE 0.9765044878411443\n",
      "26 Train Loss 5.861253 Test MSE 4.1535317170989 Test RE 0.9741297924491539\n",
      "27 Train Loss 5.6670628 Test MSE 3.9630881071992063 Test RE 0.9515353432842616\n",
      "28 Train Loss 5.4567633 Test MSE 3.807235686425193 Test RE 0.9326376455006764\n",
      "29 Train Loss 5.2039456 Test MSE 3.710852987785212 Test RE 0.9207568000787071\n",
      "30 Train Loss 4.904595 Test MSE 3.5495563933305414 Test RE 0.9005236033681535\n",
      "31 Train Loss 4.5539837 Test MSE 3.378693349362112 Test RE 0.8785822981176558\n",
      "32 Train Loss 4.241595 Test MSE 3.3417136461949752 Test RE 0.8737610404854522\n",
      "33 Train Loss 3.9443333 Test MSE 3.1913748079104245 Test RE 0.8538802459735055\n",
      "34 Train Loss 3.5910244 Test MSE 2.97996255552794 Test RE 0.8251130648420839\n",
      "35 Train Loss 3.140423 Test MSE 2.977858567435456 Test RE 0.8248217298726346\n",
      "36 Train Loss 2.8050597 Test MSE 2.8215893747432315 Test RE 0.8028879980044006\n",
      "37 Train Loss 2.5004902 Test MSE 2.772155169972939 Test RE 0.7958236263378317\n",
      "38 Train Loss 2.2325704 Test MSE 2.6213412562201315 Test RE 0.7738732619770863\n",
      "39 Train Loss 2.0552914 Test MSE 2.5185589608362084 Test RE 0.7585498406780256\n",
      "40 Train Loss 1.9264728 Test MSE 2.4573498631589 Test RE 0.7492755426499171\n",
      "41 Train Loss 1.7716105 Test MSE 2.3875420903355264 Test RE 0.7385562514831041\n",
      "42 Train Loss 1.6873535 Test MSE 2.363662734360977 Test RE 0.7348535801233119\n",
      "43 Train Loss 1.6071965 Test MSE 2.3001489231405285 Test RE 0.7249132501018155\n",
      "44 Train Loss 1.5206873 Test MSE 2.180319008276441 Test RE 0.7057779416177182\n",
      "45 Train Loss 1.4473222 Test MSE 2.0875003771427245 Test RE 0.6905916796304223\n",
      "46 Train Loss 1.3775471 Test MSE 1.9508388227137166 Test RE 0.6676037309919243\n",
      "47 Train Loss 1.2945079 Test MSE 1.766787591120221 Test RE 0.6353312689975701\n",
      "48 Train Loss 1.2480171 Test MSE 1.641573049552642 Test RE 0.6124042091640044\n",
      "49 Train Loss 1.1852429 Test MSE 1.49243640731782 Test RE 0.5839235322082418\n",
      "50 Train Loss 1.1307719 Test MSE 1.394705373155781 Test RE 0.5644809594666217\n",
      "51 Train Loss 1.0303844 Test MSE 1.158729854404166 Test RE 0.5145163245381491\n",
      "52 Train Loss 0.90707725 Test MSE 0.9531987848688592 Test RE 0.4666591657313977\n",
      "53 Train Loss 0.8142081 Test MSE 0.8161772483482077 Test RE 0.4318175633130837\n",
      "54 Train Loss 0.6875327 Test MSE 0.64754425868892 Test RE 0.38462967580975843\n",
      "55 Train Loss 0.61871994 Test MSE 0.5617384720387859 Test RE 0.35824088126306114\n",
      "56 Train Loss 0.54567796 Test MSE 0.4620754720982386 Test RE 0.32491107736585667\n",
      "57 Train Loss 0.49421617 Test MSE 0.38668053547144227 Test RE 0.29722423363793565\n",
      "58 Train Loss 0.41665226 Test MSE 0.32583048372532053 Test RE 0.27283740916382027\n",
      "59 Train Loss 0.35423446 Test MSE 0.3487388279472079 Test RE 0.2822657680992001\n",
      "60 Train Loss 0.3082667 Test MSE 0.3331085404752902 Test RE 0.2758677571907371\n",
      "61 Train Loss 0.2744765 Test MSE 0.3355706006013188 Test RE 0.27688537234323946\n",
      "62 Train Loss 0.24604425 Test MSE 0.3195200362839804 Test RE 0.27018243331370484\n",
      "63 Train Loss 0.2286395 Test MSE 0.3151558922695374 Test RE 0.2683309547449157\n",
      "64 Train Loss 0.21083649 Test MSE 0.3216015875348261 Test RE 0.2710610724233205\n",
      "65 Train Loss 0.18873055 Test MSE 0.309886155987337 Test RE 0.26607811040035007\n",
      "66 Train Loss 0.17290744 Test MSE 0.2933920333526817 Test RE 0.25890010036075256\n",
      "67 Train Loss 0.16211928 Test MSE 0.2864234734188248 Test RE 0.2558069642515904\n",
      "68 Train Loss 0.13765576 Test MSE 0.2709640977587403 Test RE 0.2488077684151901\n",
      "69 Train Loss 0.13274838 Test MSE 0.2661507204564469 Test RE 0.2465879688552381\n",
      "70 Train Loss 0.12766917 Test MSE 0.25796577606064397 Test RE 0.24276669536141354\n",
      "71 Train Loss 0.11853568 Test MSE 0.25887546826331964 Test RE 0.2431943656908236\n",
      "72 Train Loss 0.11266594 Test MSE 0.2596224883232985 Test RE 0.24354499798620205\n",
      "73 Train Loss 0.10853272 Test MSE 0.25535725622616057 Test RE 0.24153616245445877\n",
      "74 Train Loss 0.098756544 Test MSE 0.2611928244290248 Test RE 0.24428043299538585\n",
      "75 Train Loss 0.09345958 Test MSE 0.2643236545511004 Test RE 0.24574012531637177\n",
      "76 Train Loss 0.08928722 Test MSE 0.2587202210407462 Test RE 0.24312143311012827\n",
      "77 Train Loss 0.0857467 Test MSE 0.25424787790980596 Test RE 0.24101092450719894\n",
      "78 Train Loss 0.08340492 Test MSE 0.2527116026834924 Test RE 0.24028167530335778\n",
      "79 Train Loss 0.07807465 Test MSE 0.2409438732028673 Test RE 0.2346205259308816\n",
      "80 Train Loss 0.07313915 Test MSE 0.23551390830982083 Test RE 0.23196173050353663\n",
      "81 Train Loss 0.06548017 Test MSE 0.22885248533740302 Test RE 0.22865772430042136\n",
      "82 Train Loss 0.06195136 Test MSE 0.22471771525268563 Test RE 0.22658268329894435\n",
      "83 Train Loss 0.05783886 Test MSE 0.2328988841371748 Test RE 0.23067034445994974\n",
      "84 Train Loss 0.053615294 Test MSE 0.23097085800863287 Test RE 0.22971357149965949\n",
      "85 Train Loss 0.05166804 Test MSE 0.22764443072810217 Test RE 0.22805341248529887\n",
      "86 Train Loss 0.048160832 Test MSE 0.22747021138021328 Test RE 0.22796612960884519\n",
      "87 Train Loss 0.045118492 Test MSE 0.2254218903146184 Test RE 0.22693741518086163\n",
      "88 Train Loss 0.043361053 Test MSE 0.22121624986219132 Test RE 0.22481049048412272\n",
      "89 Train Loss 0.041476946 Test MSE 0.21438803669625867 Test RE 0.22131371779956413\n",
      "90 Train Loss 0.0402422 Test MSE 0.21255136686132842 Test RE 0.22036367747161945\n",
      "91 Train Loss 0.038389675 Test MSE 0.2092561476678518 Test RE 0.21864883777668565\n",
      "92 Train Loss 0.036154944 Test MSE 0.20383999327762073 Test RE 0.21580065496168843\n",
      "93 Train Loss 0.03480521 Test MSE 0.20399434338459302 Test RE 0.21588234293312608\n",
      "94 Train Loss 0.033601 Test MSE 0.2003807754496493 Test RE 0.21396172310248135\n",
      "95 Train Loss 0.032702215 Test MSE 0.19152660925813392 Test RE 0.20918118567424077\n",
      "96 Train Loss 0.031135129 Test MSE 0.17906872626566223 Test RE 0.20226369301177524\n",
      "97 Train Loss 0.029341618 Test MSE 0.17695685843299538 Test RE 0.20106744534521692\n",
      "98 Train Loss 0.028364485 Test MSE 0.171958356376048 Test RE 0.19820732619494935\n",
      "99 Train Loss 0.027421542 Test MSE 0.16726098019243987 Test RE 0.19548137224886597\n",
      "Training time: 197.25\n",
      "5\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.852066 Test MSE 4.78736604037446 Test RE 1.0458186388219848\n",
      "1 Train Loss 63.307716 Test MSE 5.012261336922075 Test RE 1.0701013542915985\n",
      "2 Train Loss 52.534264 Test MSE 5.8926371818639085 Test RE 1.160280280233311\n",
      "3 Train Loss 42.388695 Test MSE 6.542454798594146 Test RE 1.2225832056360388\n",
      "4 Train Loss 35.676537 Test MSE 6.139642909471693 Test RE 1.1843487789124167\n",
      "5 Train Loss 32.092026 Test MSE 6.454283616662874 Test RE 1.2143170222765673\n",
      "6 Train Loss 27.985441 Test MSE 6.9082835592176846 Test RE 1.2562993584483577\n",
      "7 Train Loss 25.53355 Test MSE 6.990394059110402 Test RE 1.2637433678433077\n",
      "8 Train Loss 23.595453 Test MSE 7.231426912104532 Test RE 1.2853460310583915\n",
      "9 Train Loss 22.185207 Test MSE 6.911803169694811 Test RE 1.2566193454106382\n",
      "10 Train Loss 20.987646 Test MSE 6.976321912845809 Test RE 1.2624707256805716\n",
      "11 Train Loss 20.234123 Test MSE 6.912589324739785 Test RE 1.2566908079164598\n",
      "12 Train Loss 19.543385 Test MSE 6.963706034480558 Test RE 1.2613286923533753\n",
      "13 Train Loss 18.693523 Test MSE 6.990517586265083 Test RE 1.2637545335895821\n",
      "14 Train Loss 17.574593 Test MSE 7.0681255690898785 Test RE 1.270750205099589\n",
      "15 Train Loss 16.199532 Test MSE 7.033931005066589 Test RE 1.2676726259838151\n",
      "16 Train Loss 15.369113 Test MSE 7.089253178777787 Test RE 1.2726480124443216\n",
      "17 Train Loss 14.5863495 Test MSE 7.091143991589233 Test RE 1.2728177185244396\n",
      "18 Train Loss 13.151741 Test MSE 6.875202193832003 Test RE 1.2532877585733326\n",
      "19 Train Loss 12.204913 Test MSE 6.751890484631312 Test RE 1.2419975953527524\n",
      "20 Train Loss 10.9519005 Test MSE 6.935260243547246 Test RE 1.2587498781529407\n",
      "21 Train Loss 9.933271 Test MSE 6.702895261233932 Test RE 1.2374831008211933\n",
      "22 Train Loss 8.5588255 Test MSE 6.692050935528704 Test RE 1.2364816602907611\n",
      "23 Train Loss 7.2959085 Test MSE 6.692318325662692 Test RE 1.236506362709904\n",
      "24 Train Loss 6.5367765 Test MSE 6.363339221429357 Test RE 1.2057314748688945\n",
      "25 Train Loss 5.60917 Test MSE 6.049804501553611 Test RE 1.1756518474161282\n",
      "26 Train Loss 4.850724 Test MSE 5.8005998489945165 Test RE 1.1511833874952648\n",
      "27 Train Loss 4.352322 Test MSE 5.731544990606899 Test RE 1.1443105796174353\n",
      "28 Train Loss 3.8656006 Test MSE 5.718701021141726 Test RE 1.1430277027139142\n",
      "29 Train Loss 3.7010932 Test MSE 5.815987703054265 Test RE 1.1527093080791604\n",
      "30 Train Loss 3.4360056 Test MSE 5.869362504647386 Test RE 1.1579865815779864\n",
      "31 Train Loss 3.2530057 Test MSE 5.79439887539501 Test RE 1.1505679023046018\n",
      "32 Train Loss 3.116968 Test MSE 5.8337668600398365 Test RE 1.1544698483583047\n",
      "33 Train Loss 2.9629858 Test MSE 5.847566850211179 Test RE 1.1558345122478915\n",
      "34 Train Loss 2.8670914 Test MSE 5.86195283168783 Test RE 1.157255410894837\n",
      "35 Train Loss 2.769998 Test MSE 5.85531036478053 Test RE 1.1565995535497064\n",
      "36 Train Loss 2.623188 Test MSE 5.707501560376406 Test RE 1.1419079057970314\n",
      "37 Train Loss 2.516751 Test MSE 5.683927328884325 Test RE 1.139547200703437\n",
      "38 Train Loss 2.451081 Test MSE 5.6817833399700675 Test RE 1.1393322606751382\n",
      "39 Train Loss 2.3719802 Test MSE 5.628977271135424 Test RE 1.1340254673058985\n",
      "40 Train Loss 2.309936 Test MSE 5.563301900459103 Test RE 1.1273905090139158\n",
      "41 Train Loss 2.2508974 Test MSE 5.513796179470816 Test RE 1.1223631889427328\n",
      "42 Train Loss 2.1660724 Test MSE 5.52256034708965 Test RE 1.1232548317506057\n",
      "43 Train Loss 2.0803633 Test MSE 5.516649578689697 Test RE 1.1226535638421884\n",
      "44 Train Loss 2.0074806 Test MSE 5.539923980067785 Test RE 1.1250192740447933\n",
      "45 Train Loss 1.9696789 Test MSE 5.507127101897307 Test RE 1.1216842200742763\n",
      "46 Train Loss 1.924935 Test MSE 5.517808827952246 Test RE 1.1227715128740094\n",
      "47 Train Loss 1.8879611 Test MSE 5.517180822944858 Test RE 1.1227076173841388\n",
      "48 Train Loss 1.8449214 Test MSE 5.50978954987516 Test RE 1.1219553292174727\n",
      "49 Train Loss 1.8097804 Test MSE 5.481382989016468 Test RE 1.1190593858152726\n",
      "50 Train Loss 1.7780731 Test MSE 5.465388773719438 Test RE 1.1174255324219196\n",
      "51 Train Loss 1.7417891 Test MSE 5.440013887647054 Test RE 1.1148285045862447\n",
      "52 Train Loss 1.7076592 Test MSE 5.432876466254656 Test RE 1.1140969244251693\n",
      "53 Train Loss 1.6848112 Test MSE 5.4749841388520535 Test RE 1.1184060119878725\n",
      "54 Train Loss 1.6578976 Test MSE 5.45988577050791 Test RE 1.1168628327488317\n",
      "55 Train Loss 1.6268935 Test MSE 5.43480395630929 Test RE 1.1142945380026965\n",
      "56 Train Loss 1.5963175 Test MSE 5.436383863092299 Test RE 1.114456489895337\n",
      "57 Train Loss 1.5705631 Test MSE 5.396230485650663 Test RE 1.1103331489328496\n",
      "58 Train Loss 1.5491259 Test MSE 5.378971077146154 Test RE 1.108556071268977\n",
      "59 Train Loss 1.5268226 Test MSE 5.364096754642034 Test RE 1.1070222802121426\n",
      "60 Train Loss 1.491112 Test MSE 5.311054232703925 Test RE 1.10153532324363\n",
      "61 Train Loss 1.4700123 Test MSE 5.293133320186005 Test RE 1.0996753159932542\n",
      "62 Train Loss 1.4576812 Test MSE 5.290958600407033 Test RE 1.099449388248243\n",
      "63 Train Loss 1.4278231 Test MSE 5.310229542305664 Test RE 1.1014497977686482\n",
      "64 Train Loss 1.409903 Test MSE 5.2960237968445005 Test RE 1.0999755306126575\n",
      "65 Train Loss 1.3876448 Test MSE 5.274649024388049 Test RE 1.097753533608199\n",
      "66 Train Loss 1.3490705 Test MSE 5.25582467654622 Test RE 1.0957929326016582\n",
      "67 Train Loss 1.3104186 Test MSE 5.270360354691711 Test RE 1.0973071664995016\n",
      "68 Train Loss 1.2596475 Test MSE 5.3247365627916015 Test RE 1.102953297423535\n",
      "69 Train Loss 1.2183514 Test MSE 5.32804174277108 Test RE 1.1032955578889574\n",
      "70 Train Loss 1.1731447 Test MSE 5.267493532951695 Test RE 1.0970086848271179\n",
      "71 Train Loss 1.1205236 Test MSE 5.2779683282583765 Test RE 1.0980988840253152\n",
      "72 Train Loss 1.1050476 Test MSE 5.274349003938555 Test RE 1.0977223132188891\n",
      "73 Train Loss 1.0785809 Test MSE 5.247615882290776 Test RE 1.0949368677319853\n",
      "74 Train Loss 1.0586599 Test MSE 5.259696322987831 Test RE 1.096196460311845\n",
      "75 Train Loss 1.043833 Test MSE 5.264410440076212 Test RE 1.096687595234284\n",
      "76 Train Loss 1.0270134 Test MSE 5.269884689898015 Test RE 1.097257647858531\n",
      "77 Train Loss 1.0091488 Test MSE 5.298757749618908 Test RE 1.1002594127531968\n",
      "78 Train Loss 0.9969899 Test MSE 5.320531839729271 Test RE 1.1025177332406042\n",
      "79 Train Loss 0.9826497 Test MSE 5.28725664583245 Test RE 1.0990646919967302\n",
      "80 Train Loss 0.9674052 Test MSE 5.251601548924424 Test RE 1.095352601763036\n",
      "81 Train Loss 0.9520734 Test MSE 5.292106799081811 Test RE 1.0995686783377394\n",
      "82 Train Loss 0.9271473 Test MSE 5.278940812367176 Test RE 1.0982000436441681\n",
      "83 Train Loss 0.90847635 Test MSE 5.238237184075127 Test RE 1.093957977976453\n",
      "84 Train Loss 0.8928125 Test MSE 5.265960698705169 Test RE 1.0968490591133793\n",
      "85 Train Loss 0.88129675 Test MSE 5.2822955962101785 Test RE 1.098548943048958\n",
      "86 Train Loss 0.8694723 Test MSE 5.260404426188978 Test RE 1.0962702472808499\n",
      "87 Train Loss 0.8589884 Test MSE 5.258840221892781 Test RE 1.0961072447827782\n",
      "88 Train Loss 0.8479016 Test MSE 5.253975320686342 Test RE 1.095600128474499\n",
      "89 Train Loss 0.8378973 Test MSE 5.248495977127966 Test RE 1.0950286816056751\n",
      "90 Train Loss 0.8283815 Test MSE 5.235298141670301 Test RE 1.0936510388392748\n",
      "91 Train Loss 0.823151 Test MSE 5.225318534083026 Test RE 1.0926081742228224\n",
      "92 Train Loss 0.8136522 Test MSE 5.195616828334108 Test RE 1.089498452383551\n",
      "93 Train Loss 0.79623497 Test MSE 5.171472485412707 Test RE 1.0869640222263113\n",
      "94 Train Loss 0.783413 Test MSE 5.1868017657808005 Test RE 1.0885738197167845\n",
      "95 Train Loss 0.769919 Test MSE 5.153557596355308 Test RE 1.0850796717312758\n",
      "96 Train Loss 0.7639878 Test MSE 5.154925957283925 Test RE 1.0852237161174751\n",
      "97 Train Loss 0.75333077 Test MSE 5.17175044299559 Test RE 1.0869932330394332\n",
      "98 Train Loss 0.73925614 Test MSE 5.147534360584476 Test RE 1.0844453913007672\n",
      "99 Train Loss 0.7285341 Test MSE 5.123404450098826 Test RE 1.0819006478698288\n",
      "Training time: 197.30\n",
      "6\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.028175 Test MSE 5.9393914345543894 Test RE 1.1648742213486196\n",
      "1 Train Loss 55.967358 Test MSE 8.605863700132666 Test RE 1.4021849196090432\n",
      "2 Train Loss 46.412376 Test MSE 8.742862297689312 Test RE 1.413301693569707\n",
      "3 Train Loss 40.24536 Test MSE 9.426006584335624 Test RE 1.467479116832865\n",
      "4 Train Loss 38.386135 Test MSE 8.844020254923528 Test RE 1.4214543750965571\n",
      "5 Train Loss 34.281338 Test MSE 9.299440045753984 Test RE 1.4575936233765727\n",
      "6 Train Loss 30.500774 Test MSE 9.357349554506563 Test RE 1.4621249462604695\n",
      "7 Train Loss 27.81741 Test MSE 8.902962047479932 Test RE 1.4261832164340345\n",
      "8 Train Loss 25.616043 Test MSE 8.803258268529191 Test RE 1.4181748585857699\n",
      "9 Train Loss 24.291046 Test MSE 9.007270697127833 Test RE 1.4345135925879735\n",
      "10 Train Loss 22.568151 Test MSE 9.068011167749653 Test RE 1.4393422821884825\n",
      "11 Train Loss 21.325848 Test MSE 9.033301458500036 Test RE 1.4365849492853882\n",
      "12 Train Loss 19.985857 Test MSE 8.76522010210601 Test RE 1.4151076323028817\n",
      "13 Train Loss 18.238611 Test MSE 8.605907580374458 Test RE 1.402188494388811\n",
      "14 Train Loss 16.619183 Test MSE 8.346552530599366 Test RE 1.3808980800912876\n",
      "15 Train Loss 15.010963 Test MSE 8.272937980810687 Test RE 1.374795001887302\n",
      "16 Train Loss 13.56556 Test MSE 8.21101304657676 Test RE 1.369640001232218\n",
      "17 Train Loss 11.950983 Test MSE 8.154810489613096 Test RE 1.3649445120417987\n",
      "18 Train Loss 10.497666 Test MSE 7.365263541483844 Test RE 1.2971858597294046\n",
      "19 Train Loss 9.164127 Test MSE 7.156697756445866 Test RE 1.2786874375027668\n",
      "20 Train Loss 8.239398 Test MSE 6.908705439160475 Test RE 1.2563377181512747\n",
      "21 Train Loss 6.8654375 Test MSE 6.33754805198002 Test RE 1.2032855264716922\n",
      "22 Train Loss 5.66011 Test MSE 6.495572262601259 Test RE 1.2181948792514121\n",
      "23 Train Loss 4.731039 Test MSE 5.9212627379519125 Test RE 1.1630951005020402\n",
      "24 Train Loss 3.9832704 Test MSE 5.8931722930945 Test RE 1.160332961646958\n",
      "25 Train Loss 3.6994016 Test MSE 5.712847838837093 Test RE 1.142442599357822\n",
      "26 Train Loss 3.3744454 Test MSE 5.614280467752551 Test RE 1.1325440754385865\n",
      "27 Train Loss 3.109989 Test MSE 5.554836941007089 Test RE 1.1265324800871455\n",
      "28 Train Loss 2.9903116 Test MSE 5.490952354999974 Test RE 1.1200357834803771\n",
      "29 Train Loss 2.8360157 Test MSE 5.534407539839949 Test RE 1.1244590093804296\n",
      "30 Train Loss 2.660354 Test MSE 5.546710286199748 Test RE 1.1257081272273077\n",
      "31 Train Loss 2.5687788 Test MSE 5.478907883762466 Test RE 1.1188067030056141\n",
      "32 Train Loss 2.5135713 Test MSE 5.455050172615859 Test RE 1.1163681432890702\n",
      "33 Train Loss 2.424357 Test MSE 5.388173466768232 Test RE 1.1095039296346598\n",
      "34 Train Loss 2.3346212 Test MSE 5.372766756356943 Test RE 1.1079165603087693\n",
      "35 Train Loss 2.2796624 Test MSE 5.3869631764878285 Test RE 1.1093793143782156\n",
      "36 Train Loss 2.22189 Test MSE 5.364853657222597 Test RE 1.1071003808228073\n",
      "37 Train Loss 2.151288 Test MSE 5.385534883838604 Test RE 1.1092322349095765\n",
      "38 Train Loss 2.1284022 Test MSE 5.395821814040222 Test RE 1.1102911038211005\n",
      "39 Train Loss 2.0693512 Test MSE 5.386493850216071 Test RE 1.109330987316998\n",
      "40 Train Loss 2.0202267 Test MSE 5.40147994815665 Test RE 1.1108730846720902\n",
      "41 Train Loss 1.9710107 Test MSE 5.428149252826229 Test RE 1.113612124144784\n",
      "42 Train Loss 1.930897 Test MSE 5.461414466838665 Test RE 1.1170191752708534\n",
      "43 Train Loss 1.8897165 Test MSE 5.496098101359601 Test RE 1.1205604711888255\n",
      "44 Train Loss 1.8522259 Test MSE 5.487858266810705 Test RE 1.1197201754042587\n",
      "45 Train Loss 1.8132349 Test MSE 5.546878439258067 Test RE 1.1257251904792165\n",
      "46 Train Loss 1.7877722 Test MSE 5.5847760208632975 Test RE 1.1295642542834692\n",
      "47 Train Loss 1.7434783 Test MSE 5.557503463989521 Test RE 1.126802835848154\n",
      "48 Train Loss 1.7113707 Test MSE 5.5554832857937955 Test RE 1.1265980182139883\n",
      "49 Train Loss 1.6902367 Test MSE 5.560797391078242 Test RE 1.1271367138749706\n",
      "50 Train Loss 1.655618 Test MSE 5.5709037158199335 Test RE 1.1281604913921421\n",
      "51 Train Loss 1.6419246 Test MSE 5.574601003194938 Test RE 1.128534797062416\n",
      "52 Train Loss 1.6269178 Test MSE 5.602385637039481 Test RE 1.1313436933873242\n",
      "53 Train Loss 1.6107442 Test MSE 5.596777164083293 Test RE 1.130777265108706\n",
      "54 Train Loss 1.5951288 Test MSE 5.6154341405898345 Test RE 1.1326604321319358\n",
      "55 Train Loss 1.5735604 Test MSE 5.662863079556022 Test RE 1.1374336984278317\n",
      "56 Train Loss 1.5601331 Test MSE 5.675723137779304 Test RE 1.1387244914641017\n",
      "57 Train Loss 1.5458813 Test MSE 5.666351506721059 Test RE 1.1377839844648319\n",
      "58 Train Loss 1.523381 Test MSE 5.717677120830625 Test RE 1.1429253718867989\n",
      "59 Train Loss 1.4959165 Test MSE 5.747041399652019 Test RE 1.1458564747485964\n",
      "60 Train Loss 1.4737557 Test MSE 5.7500875932950155 Test RE 1.1461601125735161\n",
      "61 Train Loss 1.4572059 Test MSE 5.791401126489248 Test RE 1.150270238995433\n",
      "62 Train Loss 1.4429936 Test MSE 5.761883748948914 Test RE 1.1473351691138607\n",
      "63 Train Loss 1.4329045 Test MSE 5.729651481459284 Test RE 1.144121543193604\n",
      "64 Train Loss 1.4156865 Test MSE 5.75559444511526 Test RE 1.1467088192965078\n",
      "65 Train Loss 1.3998392 Test MSE 5.74580878227179 Test RE 1.1457335873141365\n",
      "66 Train Loss 1.387536 Test MSE 5.745511398667897 Test RE 1.1457039372853082\n",
      "67 Train Loss 1.3716638 Test MSE 5.769136732214074 Test RE 1.14805706719525\n",
      "68 Train Loss 1.3528441 Test MSE 5.753408729748399 Test RE 1.146491064457351\n",
      "69 Train Loss 1.3363793 Test MSE 5.756908034362209 Test RE 1.1468396675045665\n",
      "70 Train Loss 1.324076 Test MSE 5.780342175902296 Test RE 1.1491714668681658\n",
      "71 Train Loss 1.3070592 Test MSE 5.779702592471935 Test RE 1.1491078883343233\n",
      "72 Train Loss 1.2906585 Test MSE 5.752796382608957 Test RE 1.1464300511313508\n",
      "73 Train Loss 1.2738339 Test MSE 5.761512266690257 Test RE 1.1472981828131457\n",
      "74 Train Loss 1.258476 Test MSE 5.786386384619055 Test RE 1.1497721248576875\n",
      "75 Train Loss 1.2423784 Test MSE 5.809401774003583 Test RE 1.1520564686567973\n",
      "76 Train Loss 1.2231936 Test MSE 5.832075757547432 Test RE 1.1543025063654473\n",
      "77 Train Loss 1.202785 Test MSE 5.878444437087132 Test RE 1.1588821380180667\n",
      "78 Train Loss 1.1845918 Test MSE 5.945415931667947 Test RE 1.1654648544781763\n",
      "79 Train Loss 1.1684653 Test MSE 5.956601323276503 Test RE 1.166560661341684\n",
      "80 Train Loss 1.1553615 Test MSE 5.967169854427716 Test RE 1.1675950908965869\n",
      "81 Train Loss 1.1437386 Test MSE 5.980930732921858 Test RE 1.1689406099732047\n",
      "82 Train Loss 1.1325268 Test MSE 5.9703650979202045 Test RE 1.1679076554300243\n",
      "83 Train Loss 1.1177602 Test MSE 5.943629626681018 Test RE 1.1652897588999716\n",
      "84 Train Loss 1.1069105 Test MSE 5.949980264780529 Test RE 1.1659121359899243\n",
      "85 Train Loss 1.0981163 Test MSE 5.9561431253540436 Test RE 1.166515792974478\n",
      "86 Train Loss 1.0862577 Test MSE 5.941035894652381 Test RE 1.1650354715896312\n",
      "87 Train Loss 1.0746112 Test MSE 5.951474312159496 Test RE 1.166058507789244\n",
      "88 Train Loss 1.0667008 Test MSE 5.968202078758103 Test RE 1.1676960741075442\n",
      "89 Train Loss 1.0580063 Test MSE 5.9635369116272425 Test RE 1.1672396081379748\n",
      "90 Train Loss 1.0464716 Test MSE 5.9616522542920904 Test RE 1.167055152121865\n",
      "91 Train Loss 1.0353428 Test MSE 5.975344696849153 Test RE 1.168394602163407\n",
      "92 Train Loss 1.0245317 Test MSE 5.9654724527586795 Test RE 1.1674290139401677\n",
      "93 Train Loss 1.0193737 Test MSE 5.964145545840227 Test RE 1.1672991704283935\n",
      "94 Train Loss 1.0111259 Test MSE 5.989931074133734 Test RE 1.1698198133729678\n",
      "95 Train Loss 1.0041595 Test MSE 6.003907182619928 Test RE 1.171183769199405\n",
      "96 Train Loss 0.99690485 Test MSE 6.010634828086966 Test RE 1.171839767276399\n",
      "97 Train Loss 0.99048406 Test MSE 6.010758052368351 Test RE 1.1718517791834002\n",
      "98 Train Loss 0.98574215 Test MSE 6.007744847348156 Test RE 1.1715580165437964\n",
      "99 Train Loss 0.9794265 Test MSE 6.003714692822239 Test RE 1.171164994530934\n",
      "Training time: 196.33\n",
      "7\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.80768 Test MSE 6.291942428486155 Test RE 1.1989482285621544\n",
      "1 Train Loss 43.003433 Test MSE 7.840665322039068 Test RE 1.3383956563756514\n",
      "2 Train Loss 37.931538 Test MSE 7.342800387738332 Test RE 1.295206219985739\n",
      "3 Train Loss 30.58107 Test MSE 7.212384206980552 Test RE 1.2836525478337555\n",
      "4 Train Loss 25.246992 Test MSE 7.566110325209547 Test RE 1.3147536801027748\n",
      "5 Train Loss 21.550934 Test MSE 6.876899553690705 Test RE 1.253442455772959\n",
      "6 Train Loss 19.542313 Test MSE 6.45479135279456 Test RE 1.214364784393877\n",
      "7 Train Loss 17.847631 Test MSE 6.063275230298029 Test RE 1.17695999556993\n",
      "8 Train Loss 15.93824 Test MSE 6.020612844011911 Test RE 1.1728120262471495\n",
      "9 Train Loss 13.884996 Test MSE 5.907312530564122 Test RE 1.1617241947991253\n",
      "10 Train Loss 12.863321 Test MSE 5.938298740231487 Test RE 1.1647670630638947\n",
      "11 Train Loss 12.210001 Test MSE 5.898645642595017 Test RE 1.1608716726828434\n",
      "12 Train Loss 11.169007 Test MSE 5.852336008064008 Test RE 1.156305753868382\n",
      "13 Train Loss 10.652779 Test MSE 5.657441635041397 Test RE 1.1368890966763827\n",
      "14 Train Loss 9.675723 Test MSE 5.533877703882546 Test RE 1.1244051831062174\n",
      "15 Train Loss 9.050652 Test MSE 5.5135796204342 Test RE 1.1223411478416798\n",
      "16 Train Loss 8.5846405 Test MSE 5.497961486793589 Test RE 1.120750411312762\n",
      "17 Train Loss 8.233662 Test MSE 5.299269102281221 Test RE 1.1003125013291766\n",
      "18 Train Loss 7.6966896 Test MSE 5.145922614707878 Test RE 1.0842756025141103\n",
      "19 Train Loss 7.3100634 Test MSE 4.9501939824292975 Test RE 1.0634551266695857\n",
      "20 Train Loss 6.9346557 Test MSE 4.851037847929505 Test RE 1.052750343477177\n",
      "21 Train Loss 6.503644 Test MSE 4.457019800085103 Test RE 1.0090910214612805\n",
      "22 Train Loss 6.0779314 Test MSE 4.237013804533676 Test RE 0.9838706375580049\n",
      "23 Train Loss 5.779954 Test MSE 4.008416377295442 Test RE 0.9569615185251514\n",
      "24 Train Loss 5.557514 Test MSE 3.8523207449016055 Test RE 0.9381435131877391\n",
      "25 Train Loss 5.2404046 Test MSE 3.807116717377236 Test RE 0.9326230737892417\n",
      "26 Train Loss 4.9126077 Test MSE 3.589079680459118 Test RE 0.9055232598168742\n",
      "27 Train Loss 4.748659 Test MSE 3.4831156861908967 Test RE 0.8920557764939933\n",
      "28 Train Loss 4.3622923 Test MSE 3.3870769791477953 Test RE 0.8796716460469858\n",
      "29 Train Loss 3.976784 Test MSE 3.0570727729820244 Test RE 0.8357202949141636\n",
      "30 Train Loss 3.4968147 Test MSE 3.079052542476514 Test RE 0.8387192487627069\n",
      "31 Train Loss 3.1721597 Test MSE 2.9950480411511196 Test RE 0.8271989162355249\n",
      "32 Train Loss 2.9325924 Test MSE 2.889059253869111 Test RE 0.8124306229079763\n",
      "33 Train Loss 2.7766087 Test MSE 2.8221464855856264 Test RE 0.8029672575054193\n",
      "34 Train Loss 2.5390453 Test MSE 2.642718313357637 Test RE 0.7770223259120352\n",
      "35 Train Loss 2.2220502 Test MSE 2.331301982767289 Test RE 0.7298058273635455\n",
      "36 Train Loss 2.0953903 Test MSE 2.2567203459110323 Test RE 0.7180371797691316\n",
      "37 Train Loss 1.973681 Test MSE 2.1690381964274956 Test RE 0.7039497519719309\n",
      "38 Train Loss 1.8976871 Test MSE 2.0470369374204287 Test RE 0.6838658230422417\n",
      "39 Train Loss 1.7053328 Test MSE 1.8036882832885286 Test RE 0.6419316700097648\n",
      "40 Train Loss 1.549389 Test MSE 1.701086522117651 Test RE 0.6234064080215516\n",
      "41 Train Loss 1.4557161 Test MSE 1.5787606068234417 Test RE 0.6005735493634559\n",
      "42 Train Loss 1.3266187 Test MSE 1.3984286737741671 Test RE 0.5652339254767756\n",
      "43 Train Loss 1.2444055 Test MSE 1.2702758088040378 Test RE 0.5387125262948854\n",
      "44 Train Loss 1.1545899 Test MSE 1.1349335998459753 Test RE 0.509205735868251\n",
      "45 Train Loss 1.0585533 Test MSE 0.9688180347728182 Test RE 0.47046700167705235\n",
      "46 Train Loss 0.9533976 Test MSE 0.945440670357739 Test RE 0.46475620904371356\n",
      "47 Train Loss 0.89644384 Test MSE 0.9235043990583498 Test RE 0.4593328909024259\n",
      "48 Train Loss 0.80115354 Test MSE 0.7739847696427284 Test RE 0.4205080050127977\n",
      "49 Train Loss 0.7444678 Test MSE 0.6735862551981142 Test RE 0.39228767954361954\n",
      "50 Train Loss 0.6671858 Test MSE 0.520545154755839 Test RE 0.3448555854953029\n",
      "51 Train Loss 0.6025891 Test MSE 0.44175279528660644 Test RE 0.3176857344306891\n",
      "52 Train Loss 0.5481822 Test MSE 0.4436503050014788 Test RE 0.31836729867804553\n",
      "53 Train Loss 0.48872995 Test MSE 0.44600180471977424 Test RE 0.31920991189351755\n",
      "54 Train Loss 0.45111442 Test MSE 0.3956703951672818 Test RE 0.30065943613521307\n",
      "55 Train Loss 0.4224301 Test MSE 0.36150022855181213 Test RE 0.2873838432364089\n",
      "56 Train Loss 0.39805034 Test MSE 0.35417131323173584 Test RE 0.2844557723566947\n",
      "57 Train Loss 0.3780662 Test MSE 0.31565763864666985 Test RE 0.26854446898345874\n",
      "58 Train Loss 0.3503112 Test MSE 0.2783647005152006 Test RE 0.25218261336987363\n",
      "59 Train Loss 0.334055 Test MSE 0.2530070701172393 Test RE 0.24042210152359764\n",
      "60 Train Loss 0.32158482 Test MSE 0.24288068212280597 Test RE 0.2355616280598988\n",
      "61 Train Loss 0.31255883 Test MSE 0.23600468302142774 Test RE 0.2322032909853967\n",
      "62 Train Loss 0.2940443 Test MSE 0.21753758952883995 Test RE 0.22293343935216134\n",
      "63 Train Loss 0.2752824 Test MSE 0.18457467537717548 Test RE 0.2053497208981697\n",
      "64 Train Loss 0.25969797 Test MSE 0.16075828962701014 Test RE 0.1916437890011776\n",
      "65 Train Loss 0.24700719 Test MSE 0.16686148090441666 Test RE 0.19524778113699548\n",
      "66 Train Loss 0.23324904 Test MSE 0.16854244513805383 Test RE 0.1962287807318113\n",
      "67 Train Loss 0.22009897 Test MSE 0.13761472896704144 Test RE 0.1773129763381219\n",
      "68 Train Loss 0.19129644 Test MSE 0.091846708948534 Test RE 0.14485712449097218\n",
      "69 Train Loss 0.17578986 Test MSE 0.0783987482202803 Test RE 0.13383281857971926\n",
      "70 Train Loss 0.1570678 Test MSE 0.052531367319256596 Test RE 0.10955126904336246\n",
      "71 Train Loss 0.14786315 Test MSE 0.043470343458144524 Test RE 0.09965626265144314\n",
      "72 Train Loss 0.13516372 Test MSE 0.04696870729975107 Test RE 0.10358869549969069\n",
      "73 Train Loss 0.11961697 Test MSE 0.0466126382176987 Test RE 0.10319529630122531\n",
      "74 Train Loss 0.10208998 Test MSE 0.035349250493635756 Test RE 0.08986656984656896\n",
      "75 Train Loss 0.09509229 Test MSE 0.029456879396515274 Test RE 0.08203542428635958\n",
      "76 Train Loss 0.08569891 Test MSE 0.022121129462151255 Test RE 0.07109052295624316\n",
      "77 Train Loss 0.08136143 Test MSE 0.017723063603419346 Test RE 0.06363227613803764\n",
      "78 Train Loss 0.07776872 Test MSE 0.015306313285730285 Test RE 0.059134830911135916\n",
      "79 Train Loss 0.074624784 Test MSE 0.015377896035487627 Test RE 0.05927294699845325\n",
      "80 Train Loss 0.06849231 Test MSE 0.01579540622676001 Test RE 0.0600721893272897\n",
      "81 Train Loss 0.05939948 Test MSE 0.014214615245763753 Test RE 0.0569869763783106\n",
      "82 Train Loss 0.054833047 Test MSE 0.012424323143792661 Test RE 0.053277572591862624\n",
      "83 Train Loss 0.049389854 Test MSE 0.010426787940114644 Test RE 0.04880713675619826\n",
      "84 Train Loss 0.045145597 Test MSE 0.009015136568244073 Test RE 0.04538310598501687\n",
      "85 Train Loss 0.04142926 Test MSE 0.0065155927960067585 Test RE 0.03858202583510439\n",
      "86 Train Loss 0.039572604 Test MSE 0.006238354628528771 Test RE 0.037752271697438555\n",
      "87 Train Loss 0.03861712 Test MSE 0.006448860346538083 Test RE 0.03838393952330121\n",
      "88 Train Loss 0.03660923 Test MSE 0.0063611412082600636 Test RE 0.038121991350443044\n",
      "89 Train Loss 0.034137733 Test MSE 0.005875099806428709 Test RE 0.036636644019775\n",
      "90 Train Loss 0.031432565 Test MSE 0.005711075406238121 Test RE 0.0361216023638201\n",
      "91 Train Loss 0.030339481 Test MSE 0.005623675652215519 Test RE 0.03584414228365762\n",
      "92 Train Loss 0.029161468 Test MSE 0.005373920299777372 Test RE 0.035039158761957984\n",
      "93 Train Loss 0.028406028 Test MSE 0.005548506715432419 Test RE 0.035603780776051794\n",
      "94 Train Loss 0.027182542 Test MSE 0.00524732500019409 Test RE 0.034623984295351524\n",
      "95 Train Loss 0.025920283 Test MSE 0.0046339982670535376 Test RE 0.03253763580724697\n",
      "96 Train Loss 0.024683235 Test MSE 0.004703257283610977 Test RE 0.03277988522798722\n",
      "97 Train Loss 0.022341527 Test MSE 0.005352082541161602 Test RE 0.034967892760098374\n",
      "98 Train Loss 0.020845452 Test MSE 0.005204776070169556 Test RE 0.03448332099429015\n",
      "99 Train Loss 0.020382736 Test MSE 0.004997223641364376 Test RE 0.03378877549536944\n",
      "Training time: 196.91\n",
      "8\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 70.14409 Test MSE 4.709145502324679 Test RE 1.0372396620027848\n",
      "1 Train Loss 51.81251 Test MSE 7.550226103797836 Test RE 1.3133728642004745\n",
      "2 Train Loss 43.87021 Test MSE 7.311953417616819 Test RE 1.292482787883561\n",
      "3 Train Loss 35.623173 Test MSE 7.039609896066006 Test RE 1.2681842547026616\n",
      "4 Train Loss 32.54055 Test MSE 6.614337736942522 Test RE 1.2292812110013338\n",
      "5 Train Loss 29.211868 Test MSE 6.224688008122511 Test RE 1.1925232490212476\n",
      "6 Train Loss 25.077114 Test MSE 6.61898757199527 Test RE 1.2297132233112094\n",
      "7 Train Loss 21.56854 Test MSE 5.746072310583721 Test RE 1.1457598612285416\n",
      "8 Train Loss 19.530231 Test MSE 6.290315084610264 Test RE 1.1987931709425372\n",
      "9 Train Loss 17.924665 Test MSE 5.826800966229078 Test RE 1.1537803867600103\n",
      "10 Train Loss 16.674458 Test MSE 5.916496502081975 Test RE 1.1626268978702483\n",
      "11 Train Loss 15.619765 Test MSE 5.890311649910229 Test RE 1.1600513050686752\n",
      "12 Train Loss 14.281961 Test MSE 5.791606424956278 Test RE 1.1502906266890858\n",
      "13 Train Loss 12.172291 Test MSE 5.536534582208928 Test RE 1.1246750706457285\n",
      "14 Train Loss 10.702858 Test MSE 5.688397363574178 Test RE 1.1399952020701982\n",
      "15 Train Loss 9.424571 Test MSE 5.472410998439582 Test RE 1.1181431661198835\n",
      "16 Train Loss 8.611073 Test MSE 5.452673731296945 Test RE 1.1161249491571514\n",
      "17 Train Loss 7.5132685 Test MSE 5.4603396693984445 Test RE 1.116909256088663\n",
      "18 Train Loss 6.9417276 Test MSE 5.4287521366573595 Test RE 1.113673964753037\n",
      "19 Train Loss 6.316477 Test MSE 5.049639195153685 Test RE 1.0740839682743877\n",
      "20 Train Loss 5.9063797 Test MSE 4.946117008775423 Test RE 1.0630171062979012\n",
      "21 Train Loss 5.6105223 Test MSE 4.596132039324162 Test RE 1.0247178670512798\n",
      "22 Train Loss 5.3116856 Test MSE 4.640171372738493 Test RE 1.029615496661518\n",
      "23 Train Loss 5.080429 Test MSE 4.480153574022763 Test RE 1.011706431714958\n",
      "24 Train Loss 4.837484 Test MSE 4.5193922636170605 Test RE 1.0161272055094472\n",
      "25 Train Loss 4.5489626 Test MSE 4.332013313319623 Test RE 0.9948393420450308\n",
      "26 Train Loss 4.407641 Test MSE 4.196938423480533 Test RE 0.979206660770373\n",
      "27 Train Loss 4.2605143 Test MSE 4.206995084175218 Test RE 0.9803791412850331\n",
      "28 Train Loss 4.122183 Test MSE 4.113289946499321 Test RE 0.969399345836837\n",
      "29 Train Loss 4.0243998 Test MSE 4.033837982724598 Test RE 0.9599912746784754\n",
      "30 Train Loss 3.8640618 Test MSE 3.860846565919954 Test RE 0.9391810725751871\n",
      "31 Train Loss 3.7228603 Test MSE 3.6994126164130363 Test RE 0.9193363812285682\n",
      "32 Train Loss 3.5057507 Test MSE 3.662696102465868 Test RE 0.9147628174492412\n",
      "33 Train Loss 3.4155617 Test MSE 3.5587333700548895 Test RE 0.9016869529057597\n",
      "34 Train Loss 3.34864 Test MSE 3.4694693011311246 Test RE 0.8903065834564236\n",
      "35 Train Loss 3.2398314 Test MSE 3.464905312064532 Test RE 0.8897208041419066\n",
      "36 Train Loss 3.170611 Test MSE 3.3528090775774944 Test RE 0.8752104048979324\n",
      "37 Train Loss 3.044951 Test MSE 3.217846276838987 Test RE 0.8574142692332128\n",
      "38 Train Loss 2.949976 Test MSE 3.220175586486358 Test RE 0.8577245422950189\n",
      "39 Train Loss 2.9029202 Test MSE 3.127535215698977 Test RE 0.8452966825158649\n",
      "40 Train Loss 2.8691497 Test MSE 3.124780310000683 Test RE 0.8449243085012779\n",
      "41 Train Loss 2.820796 Test MSE 3.1383395746750082 Test RE 0.8467555013880658\n",
      "42 Train Loss 2.7839637 Test MSE 3.0990416386394513 Test RE 0.841437311806754\n",
      "43 Train Loss 2.7507834 Test MSE 3.092484466664819 Test RE 0.8405466540732798\n",
      "44 Train Loss 2.7126474 Test MSE 3.079011255128852 Test RE 0.8387136255054188\n",
      "45 Train Loss 2.6671655 Test MSE 3.0805060485984277 Test RE 0.8389171894780376\n",
      "46 Train Loss 2.632904 Test MSE 3.0880358909579204 Test RE 0.8399418683147915\n",
      "47 Train Loss 2.5788054 Test MSE 3.025771796217899 Test RE 0.8314308703907783\n",
      "48 Train Loss 2.538643 Test MSE 2.999483208317873 Test RE 0.8278111615518554\n",
      "49 Train Loss 2.5090487 Test MSE 2.980525335995403 Test RE 0.8251909744778114\n",
      "50 Train Loss 2.4746125 Test MSE 2.939664648752408 Test RE 0.8195150907082457\n",
      "51 Train Loss 2.41709 Test MSE 2.8954098580608103 Test RE 0.8133230575505603\n",
      "52 Train Loss 2.375731 Test MSE 2.8969147498194334 Test RE 0.8135343927722974\n",
      "53 Train Loss 2.327654 Test MSE 2.8398168677173214 Test RE 0.8054771551188841\n",
      "54 Train Loss 2.2643974 Test MSE 2.786385988010911 Test RE 0.797863686010866\n",
      "55 Train Loss 2.2409604 Test MSE 2.755161626309473 Test RE 0.7933806438772925\n",
      "56 Train Loss 2.202134 Test MSE 2.7026922503304003 Test RE 0.7857897481296677\n",
      "57 Train Loss 2.1346104 Test MSE 2.6772555335724366 Test RE 0.7820832285398926\n",
      "58 Train Loss 2.0572429 Test MSE 2.662541488602472 Test RE 0.7799311249136861\n",
      "59 Train Loss 2.0109148 Test MSE 2.658209166244995 Test RE 0.7792963388130678\n",
      "60 Train Loss 1.9365368 Test MSE 2.6648925255571174 Test RE 0.7802753904027778\n",
      "61 Train Loss 1.867461 Test MSE 2.673667006831335 Test RE 0.781558910329585\n",
      "62 Train Loss 1.8120611 Test MSE 2.67652604512634 Test RE 0.7819766717430956\n",
      "63 Train Loss 1.7731106 Test MSE 2.6726082235743847 Test RE 0.7814041447162536\n",
      "64 Train Loss 1.7399282 Test MSE 2.7044724939894276 Test RE 0.7860485025126821\n",
      "65 Train Loss 1.6843278 Test MSE 2.7365281729650297 Test RE 0.7906932331971648\n",
      "66 Train Loss 1.6569536 Test MSE 2.706852887467065 Test RE 0.7863943542807327\n",
      "67 Train Loss 1.6140875 Test MSE 2.717615063357616 Test RE 0.7879561160518634\n",
      "68 Train Loss 1.5865074 Test MSE 2.740576565343182 Test RE 0.7912778888696212\n",
      "69 Train Loss 1.54757 Test MSE 2.714744873494498 Test RE 0.7875399089992534\n",
      "70 Train Loss 1.484051 Test MSE 2.7199796158285645 Test RE 0.7882988353916061\n",
      "71 Train Loss 1.4642298 Test MSE 2.7045782981041633 Test RE 0.7860638782195407\n",
      "72 Train Loss 1.4503546 Test MSE 2.6788816190094726 Test RE 0.7823206995410303\n",
      "73 Train Loss 1.4276638 Test MSE 2.669309274358481 Test RE 0.7809217304694659\n",
      "74 Train Loss 1.3965379 Test MSE 2.635132601810632 Test RE 0.7759063342762068\n",
      "75 Train Loss 1.3748 Test MSE 2.6289422892962806 Test RE 0.7749944395951192\n",
      "76 Train Loss 1.3533735 Test MSE 2.5915688928874117 Test RE 0.7694660085526812\n",
      "77 Train Loss 1.3402227 Test MSE 2.5469000397639467 Test RE 0.7628058418523364\n",
      "78 Train Loss 1.324672 Test MSE 2.5351319855632375 Test RE 0.7610415138998533\n",
      "79 Train Loss 1.3128684 Test MSE 2.5415663572674476 Test RE 0.7620066945714767\n",
      "80 Train Loss 1.302212 Test MSE 2.5219751422302084 Test RE 0.7590641160555557\n",
      "81 Train Loss 1.281344 Test MSE 2.5091947220713986 Test RE 0.7571383476641759\n",
      "82 Train Loss 1.2627068 Test MSE 2.4663580882719325 Test RE 0.7506476444441107\n",
      "83 Train Loss 1.2415283 Test MSE 2.442194511199055 Test RE 0.7469614445761646\n",
      "84 Train Loss 1.2289169 Test MSE 2.434478903470704 Test RE 0.745780576174699\n",
      "85 Train Loss 1.2152947 Test MSE 2.419549106944831 Test RE 0.7434902553293212\n",
      "86 Train Loss 1.2074739 Test MSE 2.407939782166383 Test RE 0.7417044270496604\n",
      "87 Train Loss 1.1968563 Test MSE 2.401976147603004 Test RE 0.7407853849074192\n",
      "88 Train Loss 1.1880455 Test MSE 2.4114071302959483 Test RE 0.7422382490198931\n",
      "89 Train Loss 1.1728195 Test MSE 2.393605693723236 Test RE 0.7394935066704885\n",
      "90 Train Loss 1.1566663 Test MSE 2.3558786990697196 Test RE 0.7336425690764352\n",
      "91 Train Loss 1.1404397 Test MSE 2.360567532472097 Test RE 0.734372279373066\n",
      "92 Train Loss 1.1305745 Test MSE 2.365970940664511 Test RE 0.7352122987644848\n",
      "93 Train Loss 1.1168331 Test MSE 2.3517347303905645 Test RE 0.7329970498645317\n",
      "94 Train Loss 1.1007761 Test MSE 2.343356373132915 Test RE 0.7316901867560119\n",
      "95 Train Loss 1.0893384 Test MSE 2.3606137425964233 Test RE 0.7343794673199875\n",
      "96 Train Loss 1.0785894 Test MSE 2.370771531630168 Test RE 0.7359577992573192\n",
      "97 Train Loss 1.0706576 Test MSE 2.3739888148393025 Test RE 0.7364570000187055\n",
      "98 Train Loss 1.0601453 Test MSE 2.3730261003994513 Test RE 0.7363076586069706\n",
      "99 Train Loss 1.0485705 Test MSE 2.360817913313545 Test RE 0.7344112250654083\n",
      "Training time: 195.57\n",
      "9\n",
      "KG_rowdy_tune52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.16897 Test MSE 4.901454486266375 Test RE 1.0582067986173587\n",
      "1 Train Loss 56.006756 Test MSE 7.315226960521123 Test RE 1.2927720761333503\n",
      "2 Train Loss 47.332367 Test MSE 8.808165540446863 Test RE 1.418570075894029\n",
      "3 Train Loss 42.67398 Test MSE 9.183937577000576 Test RE 1.4485134157087\n",
      "4 Train Loss 39.149704 Test MSE 9.352294397001028 Test RE 1.4617299481695716\n",
      "5 Train Loss 35.82433 Test MSE 9.021602544197341 Test RE 1.435654396414983\n",
      "6 Train Loss 33.47917 Test MSE 8.977769340311053 Test RE 1.4321624471515821\n",
      "7 Train Loss 31.579384 Test MSE 9.107095801842293 Test RE 1.4424408490806908\n",
      "8 Train Loss 28.898308 Test MSE 8.768851733310258 Test RE 1.415400757676145\n",
      "9 Train Loss 26.953022 Test MSE 8.827315107613439 Test RE 1.4201112738993673\n",
      "10 Train Loss 25.382214 Test MSE 8.670370213649116 Test RE 1.4074302500296816\n",
      "11 Train Loss 24.032131 Test MSE 8.534213072706661 Test RE 1.3963355693534545\n",
      "12 Train Loss 22.59483 Test MSE 8.5219689420678 Test RE 1.395333540714856\n",
      "13 Train Loss 20.963844 Test MSE 8.520767027410534 Test RE 1.3952351402758072\n",
      "14 Train Loss 19.660736 Test MSE 8.493631187534849 Test RE 1.3930116861584816\n",
      "15 Train Loss 18.351938 Test MSE 8.800086948821866 Test RE 1.4179193911860217\n",
      "16 Train Loss 16.61368 Test MSE 8.620390683596534 Test RE 1.4033678879311275\n",
      "17 Train Loss 15.190672 Test MSE 8.58802481843882 Test RE 1.400730888518268\n",
      "18 Train Loss 14.418123 Test MSE 8.461595917872474 Test RE 1.3903822063836626\n",
      "19 Train Loss 13.246954 Test MSE 8.323326285571524 Test RE 1.3789754047790532\n",
      "20 Train Loss 12.067877 Test MSE 7.991951975709787 Test RE 1.3512462230402373\n",
      "21 Train Loss 10.357995 Test MSE 7.53622605030309 Test RE 1.3121546343287511\n",
      "22 Train Loss 8.353239 Test MSE 6.241537214308674 Test RE 1.194136140405626\n",
      "23 Train Loss 6.594168 Test MSE 6.0114847530893405 Test RE 1.171922615489552\n",
      "24 Train Loss 5.5001616 Test MSE 5.8905780804716095 Test RE 1.1600775404908301\n",
      "25 Train Loss 4.8850884 Test MSE 5.674755448618498 Test RE 1.138627413233402\n",
      "26 Train Loss 4.151581 Test MSE 5.3865561766967405 Test RE 1.1093374052669913\n",
      "27 Train Loss 3.6253319 Test MSE 5.29728139784516 Test RE 1.1001061237018257\n",
      "28 Train Loss 3.2787144 Test MSE 5.2583041407512425 Test RE 1.0960513752969305\n",
      "29 Train Loss 3.0120358 Test MSE 5.187624110435093 Test RE 1.088660110597259\n",
      "30 Train Loss 2.7667642 Test MSE 5.166355998034268 Test RE 1.0864261856648958\n",
      "31 Train Loss 2.604564 Test MSE 5.160118687473519 Test RE 1.0857701697003146\n",
      "32 Train Loss 2.445292 Test MSE 5.2937224452301095 Test RE 1.099736511149747\n",
      "33 Train Loss 2.3418136 Test MSE 5.358825922187121 Test RE 1.1064782591677733\n",
      "34 Train Loss 2.256746 Test MSE 5.299550305144972 Test RE 1.1003416946873408\n",
      "35 Train Loss 2.2193365 Test MSE 5.25535051803878 Test RE 1.0957435025604687\n",
      "36 Train Loss 2.1524036 Test MSE 5.281931458836785 Test RE 1.0985110779187743\n",
      "37 Train Loss 2.114712 Test MSE 5.388228494773298 Test RE 1.109509595156785\n",
      "38 Train Loss 2.0580163 Test MSE 5.399884641248968 Test RE 1.1107090264515824\n",
      "39 Train Loss 2.0211663 Test MSE 5.377471520476361 Test RE 1.1084015381342622\n",
      "40 Train Loss 1.9941083 Test MSE 5.399298771756081 Test RE 1.1106487707027295\n",
      "41 Train Loss 1.9469686 Test MSE 5.447502968176757 Test RE 1.1155956137459662\n",
      "42 Train Loss 1.9150889 Test MSE 5.483675853425221 Test RE 1.1192934128093832\n",
      "43 Train Loss 1.8883722 Test MSE 5.508262961010285 Test RE 1.1217998892363574\n",
      "44 Train Loss 1.8501323 Test MSE 5.520638969856839 Test RE 1.123059416592222\n",
      "45 Train Loss 1.8269413 Test MSE 5.494457944365396 Test RE 1.120393258723006\n",
      "46 Train Loss 1.7952418 Test MSE 5.479581791469067 Test RE 1.1188755077101327\n",
      "47 Train Loss 1.7756811 Test MSE 5.470082625300326 Test RE 1.1179052699257197\n",
      "48 Train Loss 1.7580847 Test MSE 5.484349130480466 Test RE 1.1193621232385924\n",
      "49 Train Loss 1.7386495 Test MSE 5.508750891113161 Test RE 1.1218495734851202\n",
      "50 Train Loss 1.7208328 Test MSE 5.506390705652417 Test RE 1.1216092234701605\n",
      "51 Train Loss 1.7044151 Test MSE 5.54080579117336 Test RE 1.1251088073144975\n",
      "52 Train Loss 1.6853114 Test MSE 5.5601240216949295 Test RE 1.1270684680570984\n",
      "53 Train Loss 1.6693927 Test MSE 5.510341704074653 Test RE 1.1220115452327577\n",
      "54 Train Loss 1.6584992 Test MSE 5.497558451919578 Test RE 1.120709331561627\n",
      "55 Train Loss 1.636847 Test MSE 5.4988494602627 Test RE 1.1208409136246582\n",
      "56 Train Loss 1.6251894 Test MSE 5.48592199615601 Test RE 1.1195226236012206\n",
      "57 Train Loss 1.5968182 Test MSE 5.504436520258144 Test RE 1.1214101795790392\n",
      "58 Train Loss 1.566124 Test MSE 5.5162231009730425 Test RE 1.1226101683015193\n",
      "59 Train Loss 1.5341275 Test MSE 5.493682611040532 Test RE 1.1203142055309891\n",
      "60 Train Loss 1.5155464 Test MSE 5.4929789105993 Test RE 1.1202424512175213\n",
      "61 Train Loss 1.4986086 Test MSE 5.472959838392744 Test RE 1.1181992352142\n",
      "62 Train Loss 1.4747312 Test MSE 5.479636031211052 Test RE 1.1188810453014109\n",
      "63 Train Loss 1.4582355 Test MSE 5.5347152243473055 Test RE 1.124490266005943\n",
      "64 Train Loss 1.4433446 Test MSE 5.514940146379797 Test RE 1.1224796132461439\n",
      "65 Train Loss 1.4192485 Test MSE 5.49465424583456 Test RE 1.1204132727881397\n",
      "66 Train Loss 1.3965175 Test MSE 5.563941411106198 Test RE 1.1274553048427811\n",
      "67 Train Loss 1.3808103 Test MSE 5.589379612538458 Test RE 1.130029714438416\n",
      "68 Train Loss 1.3640139 Test MSE 5.605734213560945 Test RE 1.1316817480356833\n",
      "69 Train Loss 1.3430675 Test MSE 5.642002394198872 Test RE 1.1353367433802164\n",
      "70 Train Loss 1.3220239 Test MSE 5.655147046697048 Test RE 1.1366585192170509\n",
      "71 Train Loss 1.3036828 Test MSE 5.709350856616472 Test RE 1.1420928864708144\n",
      "72 Train Loss 1.2884827 Test MSE 5.745651833151367 Test RE 1.1457179391161563\n",
      "73 Train Loss 1.2718655 Test MSE 5.702233251488836 Test RE 1.1413807651212229\n",
      "74 Train Loss 1.2575083 Test MSE 5.699790034953075 Test RE 1.1411362171511759\n",
      "75 Train Loss 1.2390324 Test MSE 5.709612309362877 Test RE 1.1421190365455645\n",
      "76 Train Loss 1.2273916 Test MSE 5.688184180769457 Test RE 1.1399738401965438\n",
      "77 Train Loss 1.210955 Test MSE 5.71623350924887 Test RE 1.1427810786338448\n",
      "78 Train Loss 1.2006164 Test MSE 5.725306661292982 Test RE 1.143687664701132\n",
      "79 Train Loss 1.1879578 Test MSE 5.74356240502807 Test RE 1.1455095978321959\n",
      "80 Train Loss 1.1771281 Test MSE 5.755701328071175 Test RE 1.146719466594571\n",
      "81 Train Loss 1.1679649 Test MSE 5.770141798900422 Test RE 1.1481570668758636\n",
      "82 Train Loss 1.1583997 Test MSE 5.7942748588631545 Test RE 1.1505555895343327\n",
      "83 Train Loss 1.1506165 Test MSE 5.801884125264768 Test RE 1.151310818771495\n",
      "84 Train Loss 1.1424408 Test MSE 5.809635425831997 Test RE 1.1520796360502987\n",
      "85 Train Loss 1.1337533 Test MSE 5.836866412251996 Test RE 1.1547764996592937\n",
      "86 Train Loss 1.1255832 Test MSE 5.867131104374102 Test RE 1.1577664403609902\n",
      "87 Train Loss 1.1183739 Test MSE 5.883521896539554 Test RE 1.1593825175891066\n",
      "88 Train Loss 1.1114706 Test MSE 5.904971502299569 Test RE 1.1614939802423652\n",
      "89 Train Loss 1.103571 Test MSE 5.922007565168699 Test RE 1.163168250240854\n",
      "90 Train Loss 1.0943973 Test MSE 5.911558978245219 Test RE 1.162141670153034\n",
      "91 Train Loss 1.0850315 Test MSE 5.901092460500142 Test RE 1.1611124183782504\n",
      "92 Train Loss 1.0764824 Test MSE 5.915123987553065 Test RE 1.1624920363974585\n",
      "93 Train Loss 1.0691342 Test MSE 5.923502740757169 Test RE 1.1633150780685917\n",
      "94 Train Loss 1.0637224 Test MSE 5.915079417025841 Test RE 1.1624876566937805\n",
      "95 Train Loss 1.0572301 Test MSE 5.904657881810039 Test RE 1.1614631356271672\n",
      "96 Train Loss 1.0509491 Test MSE 5.91608637196958 Test RE 1.1625866006636316\n",
      "97 Train Loss 1.0465224 Test MSE 5.933976099949241 Test RE 1.1643430539467383\n",
      "98 Train Loss 1.0382316 Test MSE 5.962838891161303 Test RE 1.167171294569195\n",
      "99 Train Loss 1.0325925 Test MSE 5.964170591303216 Test RE 1.1673016213676979\n",
      "Training time: 194.94\n",
      "0\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 74.34635 Test MSE 4.360172095487894 Test RE 0.9980674125347985\n",
      "1 Train Loss 67.9728 Test MSE 4.3110663919548005 Test RE 0.9924312153909832\n",
      "2 Train Loss 54.97531 Test MSE 4.734990916976838 Test RE 1.0400821317250306\n",
      "3 Train Loss 41.57208 Test MSE 7.146644681123618 Test RE 1.277789030232723\n",
      "4 Train Loss 35.188663 Test MSE 6.567460957071338 Test RE 1.2249174175892639\n",
      "5 Train Loss 30.356045 Test MSE 5.854118151649589 Test RE 1.1564817986155413\n",
      "6 Train Loss 26.206364 Test MSE 6.173792467515963 Test RE 1.1876379688257228\n",
      "7 Train Loss 23.639078 Test MSE 6.202950263845607 Test RE 1.1904391737426319\n",
      "8 Train Loss 20.663939 Test MSE 6.2718662533456255 Test RE 1.1970339130455492\n",
      "9 Train Loss 18.91986 Test MSE 5.992821654007013 Test RE 1.170102041141059\n",
      "10 Train Loss 16.714893 Test MSE 5.168027968256191 Test RE 1.08660196964983\n",
      "11 Train Loss 15.062367 Test MSE 5.186058384352641 Test RE 1.0884958087772616\n",
      "12 Train Loss 13.841885 Test MSE 4.838832049615386 Test RE 1.0514250856891267\n",
      "13 Train Loss 12.468674 Test MSE 5.1361271715583685 Test RE 1.0832431327339884\n",
      "14 Train Loss 11.363337 Test MSE 5.1820757068723395 Test RE 1.0880777687126368\n",
      "15 Train Loss 10.606949 Test MSE 5.145243038954323 Test RE 1.0842040048829735\n",
      "16 Train Loss 9.798933 Test MSE 5.100600634295422 Test RE 1.0794902411551976\n",
      "17 Train Loss 9.361602 Test MSE 5.048711515983235 Test RE 1.0739853027011381\n",
      "18 Train Loss 8.914693 Test MSE 5.172623988772088 Test RE 1.0870850296434735\n",
      "19 Train Loss 8.450958 Test MSE 5.087205072841411 Test RE 1.078071792073542\n",
      "20 Train Loss 7.877446 Test MSE 4.939720070391695 Test RE 1.0623294704199457\n",
      "21 Train Loss 7.413862 Test MSE 4.830466939341339 Test RE 1.050515869251223\n",
      "22 Train Loss 6.985562 Test MSE 4.788993548000237 Test RE 1.0459963913858141\n",
      "23 Train Loss 6.616931 Test MSE 4.705660655114836 Test RE 1.036855803539703\n",
      "24 Train Loss 6.146897 Test MSE 4.633240053635474 Test RE 1.0288462081939609\n",
      "25 Train Loss 5.707579 Test MSE 4.6417998070336015 Test RE 1.029796148837232\n",
      "26 Train Loss 5.263628 Test MSE 4.567657589989275 Test RE 1.0215387145195216\n",
      "27 Train Loss 4.9987597 Test MSE 4.5567351135906815 Test RE 1.0203165989670162\n",
      "28 Train Loss 4.4470277 Test MSE 4.3486600412597625 Test RE 0.9967489553712097\n",
      "29 Train Loss 4.0718603 Test MSE 4.1840761856356705 Test RE 0.9777050359862817\n",
      "30 Train Loss 3.7883928 Test MSE 4.128259119816076 Test RE 0.9711616734012674\n",
      "31 Train Loss 3.4848018 Test MSE 4.02721174909323 Test RE 0.9592024798705541\n",
      "32 Train Loss 3.2312047 Test MSE 3.9830822752962463 Test RE 0.9539326180210681\n",
      "33 Train Loss 2.986911 Test MSE 3.9900623201774494 Test RE 0.9547680988694219\n",
      "34 Train Loss 2.8476279 Test MSE 3.970122400420321 Test RE 0.952379433922624\n",
      "35 Train Loss 2.689956 Test MSE 3.935911543697707 Test RE 0.9482671916637022\n",
      "36 Train Loss 2.5840955 Test MSE 3.9139796844735533 Test RE 0.945621512869908\n",
      "37 Train Loss 2.5260928 Test MSE 3.9119240278098513 Test RE 0.9453731558748703\n",
      "38 Train Loss 2.4235768 Test MSE 3.9235922842039375 Test RE 0.9467820077582338\n",
      "39 Train Loss 2.3710732 Test MSE 3.8606221662563223 Test RE 0.939153778693445\n",
      "40 Train Loss 2.2441592 Test MSE 3.764894083263632 Test RE 0.9274370505103787\n",
      "41 Train Loss 2.1896129 Test MSE 3.8061551642232163 Test RE 0.9325052913103575\n",
      "42 Train Loss 2.1085052 Test MSE 3.8575449508963557 Test RE 0.9387794148703923\n",
      "43 Train Loss 2.0279894 Test MSE 3.823340328220918 Test RE 0.9346080968305945\n",
      "44 Train Loss 1.9791026 Test MSE 3.8013490621309973 Test RE 0.9319163595513696\n",
      "45 Train Loss 1.9212306 Test MSE 3.797007880860744 Test RE 0.931384078317248\n",
      "46 Train Loss 1.8706466 Test MSE 3.7782061531652706 Test RE 0.9290752390429633\n",
      "47 Train Loss 1.8295138 Test MSE 3.773404687010073 Test RE 0.9284847019854876\n",
      "48 Train Loss 1.7902645 Test MSE 3.7624073727713854 Test RE 0.9271307140847974\n",
      "49 Train Loss 1.7555125 Test MSE 3.752411084170826 Test RE 0.9258982544681676\n",
      "50 Train Loss 1.7285177 Test MSE 3.7347028457920466 Test RE 0.9237109385938346\n",
      "51 Train Loss 1.6989574 Test MSE 3.707261974648159 Test RE 0.9203111814998053\n",
      "52 Train Loss 1.6588695 Test MSE 3.6539046117696934 Test RE 0.9136643151149932\n",
      "53 Train Loss 1.628678 Test MSE 3.6170690642696663 Test RE 0.9090472574480608\n",
      "54 Train Loss 1.5902787 Test MSE 3.5803617473630194 Test RE 0.9044228257821286\n",
      "55 Train Loss 1.5266625 Test MSE 3.494086652154442 Test RE 0.8934595511765555\n",
      "56 Train Loss 1.4826967 Test MSE 3.394673753577421 Test RE 0.8806575882348373\n",
      "57 Train Loss 1.4557937 Test MSE 3.3545437015645736 Test RE 0.8754367769664181\n",
      "58 Train Loss 1.4055427 Test MSE 3.33253152076652 Test RE 0.8725597852089328\n",
      "59 Train Loss 1.3429898 Test MSE 3.2773467084129337 Test RE 0.865305081378611\n",
      "60 Train Loss 1.3009522 Test MSE 3.2519805950295693 Test RE 0.8619499186293944\n",
      "61 Train Loss 1.2807531 Test MSE 3.217581042264129 Test RE 0.8573789318404264\n",
      "62 Train Loss 1.2438545 Test MSE 3.2375549530416117 Test RE 0.8600360079198143\n",
      "63 Train Loss 1.2206552 Test MSE 3.212607338736024 Test RE 0.8567160118108124\n",
      "64 Train Loss 1.1789422 Test MSE 3.1375104553867175 Test RE 0.8466436416486147\n",
      "65 Train Loss 1.149277 Test MSE 3.153854166494416 Test RE 0.848845917303814\n",
      "66 Train Loss 1.1280572 Test MSE 3.1393527764954134 Test RE 0.846892176365542\n",
      "67 Train Loss 1.096163 Test MSE 3.1063926645597615 Test RE 0.8424346788230976\n",
      "68 Train Loss 1.0652733 Test MSE 3.093783596561938 Test RE 0.8407231892573638\n",
      "69 Train Loss 1.0369135 Test MSE 3.0628724591974876 Test RE 0.8365126572810994\n",
      "70 Train Loss 0.9971495 Test MSE 3.05353243628411 Test RE 0.8352362389956844\n",
      "71 Train Loss 0.9783513 Test MSE 3.0595778156322244 Test RE 0.836062629958778\n",
      "72 Train Loss 0.95597076 Test MSE 3.0278096745520195 Test RE 0.8317108104981713\n",
      "73 Train Loss 0.93512833 Test MSE 3.0261617932436833 Test RE 0.8314844509547864\n",
      "74 Train Loss 0.9173789 Test MSE 3.040838450704669 Test RE 0.8334983306921196\n",
      "75 Train Loss 0.9017884 Test MSE 3.053995287227564 Test RE 0.8352995386724836\n",
      "76 Train Loss 0.88648456 Test MSE 3.056622949954918 Test RE 0.8356588079803517\n",
      "77 Train Loss 0.86612546 Test MSE 3.0365319708321916 Test RE 0.8329079153182894\n",
      "78 Train Loss 0.8437318 Test MSE 3.0419236650411836 Test RE 0.8336470468546736\n",
      "79 Train Loss 0.8354498 Test MSE 3.052745172551287 Test RE 0.8351285614777514\n",
      "80 Train Loss 0.8265592 Test MSE 3.0534680217729995 Test RE 0.835227429261572\n",
      "81 Train Loss 0.81610453 Test MSE 3.055549522166541 Test RE 0.8355120613634739\n",
      "82 Train Loss 0.8059932 Test MSE 3.034667553475755 Test RE 0.832652175146876\n",
      "83 Train Loss 0.79647577 Test MSE 3.0300117339975325 Test RE 0.83201319802676\n",
      "84 Train Loss 0.78384936 Test MSE 3.0102161164265526 Test RE 0.8292908976708567\n",
      "85 Train Loss 0.7729541 Test MSE 3.015761791342995 Test RE 0.8300544411083085\n",
      "86 Train Loss 0.7585454 Test MSE 3.0346766903869407 Test RE 0.8326534286389162\n",
      "87 Train Loss 0.7506357 Test MSE 3.0462060726617217 Test RE 0.8342336429167846\n",
      "88 Train Loss 0.738494 Test MSE 3.0389739444431743 Test RE 0.8332427595436924\n",
      "89 Train Loss 0.7285572 Test MSE 3.0311824362481152 Test RE 0.8321739145094769\n",
      "90 Train Loss 0.7182678 Test MSE 3.0352051846744246 Test RE 0.8327259295126617\n",
      "91 Train Loss 0.7111122 Test MSE 3.039928110885817 Test RE 0.833373558605666\n",
      "92 Train Loss 0.696311 Test MSE 3.043898501977631 Test RE 0.8339176075340456\n",
      "93 Train Loss 0.68371916 Test MSE 3.048076670525792 Test RE 0.8344897444638595\n",
      "94 Train Loss 0.67423695 Test MSE 3.044656413621349 Test RE 0.8340214212002861\n",
      "95 Train Loss 0.66381484 Test MSE 3.0447921907537285 Test RE 0.8340400176786821\n",
      "96 Train Loss 0.65676916 Test MSE 3.068964872378532 Test RE 0.8373442049540072\n",
      "97 Train Loss 0.65153915 Test MSE 3.0801175739189732 Test RE 0.8388642909678056\n",
      "98 Train Loss 0.6444803 Test MSE 3.0820167934831524 Test RE 0.8391228755702183\n",
      "99 Train Loss 0.6352134 Test MSE 3.0937723302636067 Test RE 0.8407216584704502\n",
      "Training time: 195.42\n",
      "1\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.305984 Test MSE 6.23235067329384 Test RE 1.1932570284384678\n",
      "1 Train Loss 49.98683 Test MSE 9.166509567029387 Test RE 1.4471383685735186\n",
      "2 Train Loss 45.53689 Test MSE 9.546542380056383 Test RE 1.4768320633669971\n",
      "3 Train Loss 43.524506 Test MSE 9.143652488693313 Test RE 1.445332992137419\n",
      "4 Train Loss 41.230972 Test MSE 9.30756797984502 Test RE 1.4582304701805138\n",
      "5 Train Loss 38.98584 Test MSE 9.069206450943161 Test RE 1.439437141188872\n",
      "6 Train Loss 36.866673 Test MSE 9.832161955253882 Test RE 1.4987616505786994\n",
      "7 Train Loss 35.779213 Test MSE 9.792033666319204 Test RE 1.495700053751919\n",
      "8 Train Loss 34.361137 Test MSE 10.237063433800069 Test RE 1.5293108068589074\n",
      "9 Train Loss 33.349274 Test MSE 10.364239113506653 Test RE 1.5387808478452598\n",
      "10 Train Loss 32.68403 Test MSE 10.40753693645956 Test RE 1.5419917165168513\n",
      "11 Train Loss 31.475578 Test MSE 10.152450555373457 Test RE 1.5229775510543244\n",
      "12 Train Loss 30.689466 Test MSE 9.60294756840146 Test RE 1.4811885258840705\n",
      "13 Train Loss 28.81866 Test MSE 8.954213241697342 Test RE 1.4302823410203376\n",
      "14 Train Loss 27.602577 Test MSE 8.21616456153858 Test RE 1.3700695837083303\n",
      "15 Train Loss 22.978352 Test MSE 7.517295937785278 Test RE 1.310505609164669\n",
      "16 Train Loss 20.24815 Test MSE 7.362786197944066 Test RE 1.2969676838785074\n",
      "17 Train Loss 18.89663 Test MSE 7.104699940067334 Test RE 1.2740337432720474\n",
      "18 Train Loss 18.428135 Test MSE 7.039867763884984 Test RE 1.2682074819068603\n",
      "19 Train Loss 17.991156 Test MSE 6.899142969690786 Test RE 1.2554679567210902\n",
      "20 Train Loss 17.611744 Test MSE 6.913581429138652 Test RE 1.256780985684059\n",
      "21 Train Loss 17.323174 Test MSE 6.849723946073653 Test RE 1.2509633749975118\n",
      "22 Train Loss 17.09341 Test MSE 6.875135629056145 Test RE 1.253281691477536\n",
      "23 Train Loss 16.942549 Test MSE 6.897633320283085 Test RE 1.2553305903729246\n",
      "24 Train Loss 16.805424 Test MSE 6.915535769324375 Test RE 1.2569586073737586\n",
      "25 Train Loss 16.695354 Test MSE 6.870892281412972 Test RE 1.2528948677813119\n",
      "26 Train Loss 16.565302 Test MSE 6.838736111273907 Test RE 1.2499596195340688\n",
      "27 Train Loss 16.423067 Test MSE 6.839279799051445 Test RE 1.2500093051960113\n",
      "28 Train Loss 16.311714 Test MSE 6.749544289225238 Test RE 1.2417817874805037\n",
      "29 Train Loss 16.17714 Test MSE 6.697283758772007 Test RE 1.2369649968398977\n",
      "30 Train Loss 16.02303 Test MSE 6.814218344593639 Test RE 1.2477169730245738\n",
      "31 Train Loss 15.883322 Test MSE 6.840640033271227 Test RE 1.2501336034371104\n",
      "32 Train Loss 15.777753 Test MSE 6.8398272619412745 Test RE 1.2500593338563748\n",
      "33 Train Loss 15.664312 Test MSE 6.926798166575722 Test RE 1.2579817101878679\n",
      "34 Train Loss 15.568848 Test MSE 6.973185735537332 Test RE 1.2621869244764814\n",
      "35 Train Loss 15.475105 Test MSE 6.964857465785001 Test RE 1.2614329668089899\n",
      "36 Train Loss 15.358072 Test MSE 7.05803976331128 Test RE 1.2698432379683195\n",
      "37 Train Loss 15.285877 Test MSE 7.130333736067691 Test RE 1.2763300342146895\n",
      "38 Train Loss 15.146425 Test MSE 7.159153408554086 Test RE 1.2789067944114612\n",
      "39 Train Loss 15.066921 Test MSE 7.157647333085067 Test RE 1.2787722651346565\n",
      "40 Train Loss 14.98524 Test MSE 7.155997370149815 Test RE 1.2786248669499116\n",
      "41 Train Loss 14.899731 Test MSE 7.169946964674384 Test RE 1.2798705084484934\n",
      "42 Train Loss 14.780007 Test MSE 7.1513398346676205 Test RE 1.278208697847474\n",
      "43 Train Loss 14.713022 Test MSE 7.2054622529680215 Test RE 1.2830364189248549\n",
      "44 Train Loss 14.653042 Test MSE 7.257137181889046 Test RE 1.2876289326666515\n",
      "45 Train Loss 14.565977 Test MSE 7.205576610875043 Test RE 1.2830466004213485\n",
      "46 Train Loss 14.423168 Test MSE 7.113892631237738 Test RE 1.2748577057792028\n",
      "47 Train Loss 14.369899 Test MSE 7.083519950925158 Test RE 1.2721332997779493\n",
      "48 Train Loss 14.306822 Test MSE 7.132039501643293 Test RE 1.276482691139693\n",
      "49 Train Loss 14.263146 Test MSE 7.097479505763792 Test RE 1.2733861849344745\n",
      "50 Train Loss 14.18754 Test MSE 7.0829080306056875 Test RE 1.2720783510354392\n",
      "51 Train Loss 14.106697 Test MSE 7.128033326037618 Test RE 1.2761241308607052\n",
      "52 Train Loss 14.036583 Test MSE 7.149514419608101 Test RE 1.2780455528723114\n",
      "53 Train Loss 13.954748 Test MSE 7.172149850665153 Test RE 1.2800671062965843\n",
      "54 Train Loss 13.888721 Test MSE 7.139894330153821 Test RE 1.2771854209466205\n",
      "55 Train Loss 13.842121 Test MSE 7.130720686355728 Test RE 1.2763646658036432\n",
      "56 Train Loss 13.774109 Test MSE 7.112342661676405 Test RE 1.2747188156957432\n",
      "57 Train Loss 13.718524 Test MSE 7.068776943807785 Test RE 1.270808757786497\n",
      "58 Train Loss 13.611586 Test MSE 7.09909230777508 Test RE 1.273530856232369\n",
      "59 Train Loss 13.530785 Test MSE 7.1495569631541365 Test RE 1.2780493554039059\n",
      "60 Train Loss 13.378393 Test MSE 7.109031369161956 Test RE 1.2744220458073667\n",
      "61 Train Loss 13.275688 Test MSE 7.143882366093103 Test RE 1.2775420614006787\n",
      "62 Train Loss 13.216579 Test MSE 7.238870619410916 Test RE 1.2860073997532917\n",
      "63 Train Loss 13.168646 Test MSE 7.262587194928176 Test RE 1.2881123379862232\n",
      "64 Train Loss 13.032466 Test MSE 7.202393952081015 Test RE 1.2827632122360388\n",
      "65 Train Loss 12.938187 Test MSE 7.216101434815322 Test RE 1.2839832993705456\n",
      "66 Train Loss 12.880987 Test MSE 7.210044645744891 Test RE 1.2834443346244815\n",
      "67 Train Loss 12.726055 Test MSE 7.05584392179355 Test RE 1.2696456908090197\n",
      "68 Train Loss 12.603476 Test MSE 6.988691310714454 Test RE 1.2635894446146219\n",
      "69 Train Loss 12.53203 Test MSE 6.930906604279297 Test RE 1.2583547233194226\n",
      "70 Train Loss 12.420384 Test MSE 6.887374893493075 Test RE 1.2543967549554866\n",
      "71 Train Loss 12.328077 Test MSE 6.885375685408758 Test RE 1.2542146839789294\n",
      "72 Train Loss 12.2423725 Test MSE 6.859617950604579 Test RE 1.2518665187705735\n",
      "73 Train Loss 12.160759 Test MSE 6.871424824834658 Test RE 1.252943421008788\n",
      "74 Train Loss 12.075064 Test MSE 6.893202150451084 Test RE 1.2549273015601485\n",
      "75 Train Loss 11.937912 Test MSE 6.863255776041965 Test RE 1.252198422695452\n",
      "76 Train Loss 11.811119 Test MSE 6.884542928925625 Test RE 1.2541388357580372\n",
      "77 Train Loss 11.629694 Test MSE 6.841617415092089 Test RE 1.2502229089853094\n",
      "78 Train Loss 11.375583 Test MSE 6.801456139511135 Test RE 1.2465480141042982\n",
      "79 Train Loss 11.257021 Test MSE 6.746662927845475 Test RE 1.241516702618874\n",
      "80 Train Loss 11.0969925 Test MSE 6.66023741794781 Test RE 1.2335390875298622\n",
      "81 Train Loss 10.91285 Test MSE 6.5728119023598035 Test RE 1.2254163266487528\n",
      "82 Train Loss 10.650699 Test MSE 6.2888941125278865 Test RE 1.1986577605681639\n",
      "83 Train Loss 10.061617 Test MSE 5.4579455169035125 Test RE 1.116664368002404\n",
      "84 Train Loss 8.573538 Test MSE 4.957439023371129 Test RE 1.0642330718236548\n",
      "85 Train Loss 8.08449 Test MSE 4.93612317768474 Test RE 1.0619426285634141\n",
      "86 Train Loss 7.5018926 Test MSE 4.96843654250549 Test RE 1.0654128583774518\n",
      "87 Train Loss 6.7023635 Test MSE 4.705154912836226 Test RE 1.036800083849591\n",
      "88 Train Loss 6.078493 Test MSE 4.478434492473893 Test RE 1.0115123119486644\n",
      "89 Train Loss 5.568295 Test MSE 4.507321822035204 Test RE 1.0147693565160982\n",
      "90 Train Loss 5.286311 Test MSE 4.479084482680432 Test RE 1.0115857136299153\n",
      "91 Train Loss 4.990247 Test MSE 4.62910344417191 Test RE 1.0283868228315387\n",
      "92 Train Loss 4.6544695 Test MSE 4.706827724162927 Test RE 1.0369843728718688\n",
      "93 Train Loss 4.528676 Test MSE 4.660907253287497 Test RE 1.0319134920712005\n",
      "94 Train Loss 4.427635 Test MSE 4.772439345236484 Test RE 1.0441869688089611\n",
      "95 Train Loss 4.325853 Test MSE 4.771152502180505 Test RE 1.0440461817560232\n",
      "96 Train Loss 4.201765 Test MSE 4.774426686852254 Test RE 1.0444043566140462\n",
      "97 Train Loss 4.0733757 Test MSE 4.832593640603847 Test RE 1.0507470981989708\n",
      "98 Train Loss 3.9430103 Test MSE 5.012087273182669 Test RE 1.070082773111576\n",
      "99 Train Loss 3.866554 Test MSE 4.986205223108156 Test RE 1.0673162826289608\n",
      "Training time: 196.05\n",
      "2\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.22516 Test MSE 6.671655408906193 Test RE 1.2345959948118177\n",
      "1 Train Loss 47.756794 Test MSE 8.99201394166788 Test RE 1.43329816898952\n",
      "2 Train Loss 36.033394 Test MSE 7.405001411198602 Test RE 1.3006805114005513\n",
      "3 Train Loss 31.140928 Test MSE 6.9701669134392 Test RE 1.2619136827758584\n",
      "4 Train Loss 26.33092 Test MSE 6.3348929955444975 Test RE 1.2030334474632434\n",
      "5 Train Loss 22.665455 Test MSE 5.246453089100446 Test RE 1.0948155501946777\n",
      "6 Train Loss 19.359344 Test MSE 5.705530163482225 Test RE 1.1417106786829987\n",
      "7 Train Loss 17.440956 Test MSE 5.815528590746095 Test RE 1.1526638099193727\n",
      "8 Train Loss 15.40439 Test MSE 5.781585790024676 Test RE 1.1492950797065191\n",
      "9 Train Loss 14.56432 Test MSE 5.780446939934947 Test RE 1.149181880723256\n",
      "10 Train Loss 13.285896 Test MSE 5.533619952534548 Test RE 1.12437899709869\n",
      "11 Train Loss 12.533718 Test MSE 5.5245101832202765 Test RE 1.1234531065934814\n",
      "12 Train Loss 11.697566 Test MSE 5.592118790051289 Test RE 1.1303065763673446\n",
      "13 Train Loss 11.012505 Test MSE 5.656472716857839 Test RE 1.1367917382096293\n",
      "14 Train Loss 10.436977 Test MSE 5.512748101794152 Test RE 1.1222565129186124\n",
      "15 Train Loss 9.831827 Test MSE 5.705879543697616 Test RE 1.141745634682269\n",
      "16 Train Loss 9.379938 Test MSE 5.627004016110835 Test RE 1.133826681852701\n",
      "17 Train Loss 9.019099 Test MSE 5.64787720545462 Test RE 1.1359276819547255\n",
      "18 Train Loss 8.708803 Test MSE 5.78500069006158 Test RE 1.149634445806712\n",
      "19 Train Loss 8.529255 Test MSE 5.667894032257579 Test RE 1.1379388408501232\n",
      "20 Train Loss 8.282493 Test MSE 5.640788690412396 Test RE 1.1352146203711637\n",
      "21 Train Loss 8.044219 Test MSE 5.645045403630302 Test RE 1.135642873585492\n",
      "22 Train Loss 7.9169044 Test MSE 5.701258667679564 Test RE 1.1412832227462901\n",
      "23 Train Loss 7.521786 Test MSE 5.598711173169389 Test RE 1.1309726225926386\n",
      "24 Train Loss 7.301546 Test MSE 5.58595814469438 Test RE 1.1296837948135299\n",
      "25 Train Loss 7.076042 Test MSE 5.571723562561237 Test RE 1.1282435016830312\n",
      "26 Train Loss 6.777743 Test MSE 5.276503698048962 Test RE 1.0979465128580512\n",
      "27 Train Loss 6.365446 Test MSE 5.314368030220784 Test RE 1.1018789175327122\n",
      "28 Train Loss 6.132475 Test MSE 5.2173944093620035 Test RE 1.0917793971540612\n",
      "29 Train Loss 5.9630513 Test MSE 5.207250635467639 Test RE 1.0907175499304094\n",
      "30 Train Loss 5.6295815 Test MSE 5.002746386369334 Test RE 1.0690851664301793\n",
      "31 Train Loss 5.3863144 Test MSE 4.920739962757581 Test RE 1.060286588118353\n",
      "32 Train Loss 4.9068427 Test MSE 4.5615131383568155 Test RE 1.0208513920332305\n",
      "33 Train Loss 4.746458 Test MSE 4.529338546503551 Test RE 1.0172447378515745\n",
      "34 Train Loss 4.575918 Test MSE 4.480595674653108 Test RE 1.0117563479745302\n",
      "35 Train Loss 4.4340806 Test MSE 4.424597670567837 Test RE 1.0054140582043984\n",
      "36 Train Loss 4.217735 Test MSE 4.380724323369613 Test RE 1.0004169062215624\n",
      "37 Train Loss 4.000737 Test MSE 4.340365308392143 Test RE 0.9957978908434918\n",
      "38 Train Loss 3.8862698 Test MSE 4.22502068253543 Test RE 0.9824771983463322\n",
      "39 Train Loss 3.7026472 Test MSE 4.093868382153312 Test RE 0.9671080499861948\n",
      "40 Train Loss 3.57915 Test MSE 4.043812553850889 Test RE 0.9611774389720479\n",
      "41 Train Loss 3.4452264 Test MSE 3.995448888840595 Test RE 0.9554123481252207\n",
      "42 Train Loss 3.3086076 Test MSE 3.9159222909139206 Test RE 0.945856151615127\n",
      "43 Train Loss 3.162004 Test MSE 3.766529736393237 Test RE 0.9276384905184549\n",
      "44 Train Loss 3.0323887 Test MSE 3.6644096123177063 Test RE 0.9149767680165531\n",
      "45 Train Loss 2.7589927 Test MSE 3.3750464214828355 Test RE 0.87810800361409\n",
      "46 Train Loss 2.58146 Test MSE 3.3045194719718616 Test RE 0.8688848361239871\n",
      "47 Train Loss 2.4221928 Test MSE 3.1862994984021915 Test RE 0.853201004085685\n",
      "48 Train Loss 2.335894 Test MSE 3.1396329883437226 Test RE 0.8469299714054375\n",
      "49 Train Loss 2.2390802 Test MSE 3.109688683993246 Test RE 0.8428814904818069\n",
      "50 Train Loss 2.140883 Test MSE 3.10139850446417 Test RE 0.841757213596386\n",
      "51 Train Loss 2.0110343 Test MSE 3.1024786933850126 Test RE 0.8419037890295611\n",
      "52 Train Loss 1.9428611 Test MSE 3.0616754596073266 Test RE 0.8363491827697881\n",
      "53 Train Loss 1.880389 Test MSE 3.0378971128518075 Test RE 0.8330951206298144\n",
      "54 Train Loss 1.8398349 Test MSE 3.0016146887697306 Test RE 0.8281052372031533\n",
      "55 Train Loss 1.815287 Test MSE 2.9554962181640976 Test RE 0.8217188775874035\n",
      "56 Train Loss 1.7773539 Test MSE 2.916308162260131 Test RE 0.8162529558364874\n",
      "57 Train Loss 1.7413045 Test MSE 2.8908519262619787 Test RE 0.8126826419844398\n",
      "58 Train Loss 1.704143 Test MSE 2.837974056240473 Test RE 0.80521576794188\n",
      "59 Train Loss 1.6791939 Test MSE 2.7909377064653618 Test RE 0.7985150977253525\n",
      "60 Train Loss 1.6452543 Test MSE 2.7330352991240674 Test RE 0.7901884560893285\n",
      "61 Train Loss 1.6018244 Test MSE 2.7333761463518393 Test RE 0.790237728257142\n",
      "62 Train Loss 1.5666673 Test MSE 2.7315043727223705 Test RE 0.789967110645006\n",
      "63 Train Loss 1.5452014 Test MSE 2.680554900206025 Test RE 0.7825649877091664\n",
      "64 Train Loss 1.4978538 Test MSE 2.594947072722971 Test RE 0.7699673550570767\n",
      "65 Train Loss 1.4565012 Test MSE 2.60004973503907 Test RE 0.7707240090023244\n",
      "66 Train Loss 1.4207695 Test MSE 2.5772420392544673 Test RE 0.7673361587388686\n",
      "67 Train Loss 1.3944004 Test MSE 2.5490121955731837 Test RE 0.7631220754828089\n",
      "68 Train Loss 1.3660185 Test MSE 2.5474838550557166 Test RE 0.7628932642462997\n",
      "69 Train Loss 1.3391308 Test MSE 2.5318503473128877 Test RE 0.7605487837976088\n",
      "70 Train Loss 1.3215514 Test MSE 2.4960454795920994 Test RE 0.7551518790433392\n",
      "71 Train Loss 1.3028169 Test MSE 2.4656938033796845 Test RE 0.750546548526108\n",
      "72 Train Loss 1.278979 Test MSE 2.4309687583020088 Test RE 0.7452427316324133\n",
      "73 Train Loss 1.2528659 Test MSE 2.3811059701806134 Test RE 0.7375601131131541\n",
      "74 Train Loss 1.2431464 Test MSE 2.3801726889674275 Test RE 0.7374155545615212\n",
      "75 Train Loss 1.2285972 Test MSE 2.357578856052914 Test RE 0.7339072436931406\n",
      "76 Train Loss 1.2142311 Test MSE 2.310611089321398 Test RE 0.726560003988038\n",
      "77 Train Loss 1.1881857 Test MSE 2.24971562266247 Test RE 0.7169219417339532\n",
      "78 Train Loss 1.1528534 Test MSE 2.2358388427053257 Test RE 0.7147074492195866\n",
      "79 Train Loss 1.1334425 Test MSE 2.1896706672049095 Test RE 0.7072899067103883\n",
      "80 Train Loss 1.1174221 Test MSE 2.1146624378486014 Test RE 0.6950700665069912\n",
      "81 Train Loss 1.1091571 Test MSE 2.0964042864077173 Test RE 0.6920629183433273\n",
      "82 Train Loss 1.0971209 Test MSE 2.063560090579115 Test RE 0.6866202700161225\n",
      "83 Train Loss 1.0719309 Test MSE 1.958547660593832 Test RE 0.6689214653884797\n",
      "84 Train Loss 1.0482122 Test MSE 1.94063188016662 Test RE 0.6658549628878553\n",
      "85 Train Loss 1.0148168 Test MSE 1.8440544677771837 Test RE 0.6490750756084075\n",
      "86 Train Loss 0.9963648 Test MSE 1.753697720324097 Test RE 0.6329733553046477\n",
      "87 Train Loss 0.9713912 Test MSE 1.684318964141471 Test RE 0.6203263502393017\n",
      "88 Train Loss 0.9350418 Test MSE 1.6693676877759276 Test RE 0.6175669724167775\n",
      "89 Train Loss 0.87787724 Test MSE 1.6074475871258136 Test RE 0.6060053675313375\n",
      "90 Train Loss 0.8462373 Test MSE 1.5726207020537082 Test RE 0.5994045765086325\n",
      "91 Train Loss 0.82246226 Test MSE 1.5340356695606254 Test RE 0.5920055650778225\n",
      "92 Train Loss 0.8014944 Test MSE 1.4662240010368253 Test RE 0.5787729460752914\n",
      "93 Train Loss 0.7849916 Test MSE 1.4307801316879916 Test RE 0.5717346463290134\n",
      "94 Train Loss 0.76038975 Test MSE 1.4147043387495795 Test RE 0.5685136584611763\n",
      "95 Train Loss 0.7348804 Test MSE 1.3454178207552892 Test RE 0.5544171400287168\n",
      "96 Train Loss 0.7113033 Test MSE 1.2665885502917404 Test RE 0.537930091526607\n",
      "97 Train Loss 0.6817919 Test MSE 1.1851115120486897 Test RE 0.5203405464407174\n",
      "98 Train Loss 0.640843 Test MSE 1.10327390961914 Test RE 0.5020531939430007\n",
      "99 Train Loss 0.6066457 Test MSE 0.9718771006480031 Test RE 0.4712091716304902\n",
      "Training time: 195.09\n",
      "3\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.749626 Test MSE 5.299788327642562 Test RE 1.100366404627106\n",
      "1 Train Loss 64.22968 Test MSE 5.578379421185808 Test RE 1.128917188006993\n",
      "2 Train Loss 50.84749 Test MSE 7.839526554456163 Test RE 1.338298459462613\n",
      "3 Train Loss 39.682495 Test MSE 8.604865741175553 Test RE 1.402103616696374\n",
      "4 Train Loss 35.883556 Test MSE 8.381214015669109 Test RE 1.383762399740296\n",
      "5 Train Loss 32.85396 Test MSE 8.73964353142571 Test RE 1.4130415095229374\n",
      "6 Train Loss 30.828634 Test MSE 8.751624448156027 Test RE 1.4140097260484092\n",
      "7 Train Loss 29.059093 Test MSE 8.38608116689475 Test RE 1.384164131717552\n",
      "8 Train Loss 27.229273 Test MSE 8.551407956580258 Test RE 1.397741542351227\n",
      "9 Train Loss 26.1853 Test MSE 8.524404539698347 Test RE 1.3955329211808454\n",
      "10 Train Loss 24.552332 Test MSE 8.620099376205198 Test RE 1.4033441758450218\n",
      "11 Train Loss 23.727066 Test MSE 8.70957127089228 Test RE 1.410608345678185\n",
      "12 Train Loss 22.664478 Test MSE 8.760018300456498 Test RE 1.4146876655716356\n",
      "13 Train Loss 21.664951 Test MSE 8.974780925604115 Test RE 1.431924066581911\n",
      "14 Train Loss 21.108974 Test MSE 8.991509628843525 Test RE 1.4332579755029653\n",
      "15 Train Loss 20.220127 Test MSE 9.1340238964022 Test RE 1.444571798090389\n",
      "16 Train Loss 19.891338 Test MSE 8.868249138751851 Test RE 1.4234001359747792\n",
      "17 Train Loss 19.298077 Test MSE 8.781293390360483 Test RE 1.4164045201601099\n",
      "18 Train Loss 18.505314 Test MSE 8.69561487631589 Test RE 1.4094776987672788\n",
      "19 Train Loss 18.138538 Test MSE 8.837331652907114 Test RE 1.4209167609454685\n",
      "20 Train Loss 17.490248 Test MSE 8.831249183741084 Test RE 1.4204276896758856\n",
      "21 Train Loss 16.967438 Test MSE 8.750178181615238 Test RE 1.4138928837716829\n",
      "22 Train Loss 16.428156 Test MSE 8.73202493966192 Test RE 1.4124254813340935\n",
      "23 Train Loss 15.855583 Test MSE 8.512795799168297 Test RE 1.3945823621838056\n",
      "24 Train Loss 15.354868 Test MSE 8.569481748918081 Test RE 1.3992178580782157\n",
      "25 Train Loss 14.842844 Test MSE 8.417397641204085 Test RE 1.386746192799434\n",
      "26 Train Loss 14.177773 Test MSE 8.379154916099473 Test RE 1.383592407685297\n",
      "27 Train Loss 13.612295 Test MSE 8.39087586569252 Test RE 1.3845597695381056\n",
      "28 Train Loss 13.182959 Test MSE 8.20350327983186 Test RE 1.3690135237340444\n",
      "29 Train Loss 12.829564 Test MSE 8.061125215809621 Test RE 1.3570813867110476\n",
      "30 Train Loss 12.517422 Test MSE 8.178137249543104 Test RE 1.3668953235402974\n",
      "31 Train Loss 12.284735 Test MSE 8.182033502824464 Test RE 1.3672208950028575\n",
      "32 Train Loss 11.733683 Test MSE 8.186632287371463 Test RE 1.3676050703473106\n",
      "33 Train Loss 11.13801 Test MSE 8.195230251913532 Test RE 1.3683230416543033\n",
      "34 Train Loss 10.609177 Test MSE 7.583103195297089 Test RE 1.3162292671168179\n",
      "35 Train Loss 9.815679 Test MSE 7.681455869661232 Test RE 1.3247374997888295\n",
      "36 Train Loss 9.493899 Test MSE 7.564719761771939 Test RE 1.3146328563023764\n",
      "37 Train Loss 9.16597 Test MSE 7.617715996219638 Test RE 1.3192297875720869\n",
      "38 Train Loss 8.891539 Test MSE 7.918010149787231 Test RE 1.344980808177356\n",
      "39 Train Loss 8.46723 Test MSE 7.827297935078255 Test RE 1.337254268250222\n",
      "40 Train Loss 8.237955 Test MSE 7.751009875845213 Test RE 1.330721597192605\n",
      "41 Train Loss 8.109915 Test MSE 7.708804469541759 Test RE 1.3270936628774732\n",
      "42 Train Loss 7.900815 Test MSE 7.4588593932369855 Test RE 1.3054019901302185\n",
      "43 Train Loss 7.6931953 Test MSE 7.459417698421489 Test RE 1.3054508447219795\n",
      "44 Train Loss 7.252841 Test MSE 7.0696773614107675 Test RE 1.270889692730984\n",
      "45 Train Loss 6.6555033 Test MSE 6.444567197137686 Test RE 1.2134026483336506\n",
      "46 Train Loss 6.1196036 Test MSE 6.389644634317923 Test RE 1.2082210916996867\n",
      "47 Train Loss 5.8993526 Test MSE 6.247378046868529 Test RE 1.1946947462450404\n",
      "48 Train Loss 5.5566845 Test MSE 6.430624599281136 Test RE 1.2120893603403422\n",
      "49 Train Loss 5.211077 Test MSE 6.5253874770201765 Test RE 1.2209874860180419\n",
      "50 Train Loss 4.9468565 Test MSE 6.70650441689369 Test RE 1.2378162156851693\n",
      "51 Train Loss 4.685101 Test MSE 6.7703931684344445 Test RE 1.2436981980765247\n",
      "52 Train Loss 4.456541 Test MSE 6.709166154364763 Test RE 1.2380618291040246\n",
      "53 Train Loss 4.357546 Test MSE 6.789215798095735 Test RE 1.2454258246750136\n",
      "54 Train Loss 4.169241 Test MSE 6.880826939681609 Test RE 1.2538003241451423\n",
      "55 Train Loss 4.077896 Test MSE 6.778704161464281 Test RE 1.244461314533957\n",
      "56 Train Loss 4.0141125 Test MSE 6.8123359881288215 Test RE 1.2475446267471708\n",
      "57 Train Loss 3.9360042 Test MSE 6.8465644587109065 Test RE 1.2506748335263644\n",
      "58 Train Loss 3.860296 Test MSE 6.872707567808715 Test RE 1.2530603639580873\n",
      "59 Train Loss 3.826561 Test MSE 6.950618464762604 Test RE 1.2601428661167573\n",
      "60 Train Loss 3.779236 Test MSE 7.001213331069106 Test RE 1.2647209591420783\n",
      "61 Train Loss 3.7270105 Test MSE 7.0757163672578365 Test RE 1.2714323817104054\n",
      "62 Train Loss 3.6596632 Test MSE 7.124283278616567 Test RE 1.275788403222586\n",
      "63 Train Loss 3.5917993 Test MSE 7.11527186097557 Test RE 1.2749812834415035\n",
      "64 Train Loss 3.563226 Test MSE 7.14598133297422 Test RE 1.2777297269725107\n",
      "65 Train Loss 3.5265374 Test MSE 7.186370077723274 Test RE 1.2813354729310602\n",
      "66 Train Loss 3.4726543 Test MSE 7.15915617732851 Test RE 1.278907041717524\n",
      "67 Train Loss 3.4207997 Test MSE 7.155583136564894 Test RE 1.2785878590389188\n",
      "68 Train Loss 3.3698556 Test MSE 7.265018471441402 Test RE 1.288327928872163\n",
      "69 Train Loss 3.3222685 Test MSE 7.299938664197963 Test RE 1.291420469411449\n",
      "70 Train Loss 3.2637093 Test MSE 7.243678948124883 Test RE 1.286434435967699\n",
      "71 Train Loss 3.2171917 Test MSE 7.2804593874781665 Test RE 1.2896962945998567\n",
      "72 Train Loss 3.181692 Test MSE 7.274894161736209 Test RE 1.2892032746692577\n",
      "73 Train Loss 3.140084 Test MSE 7.328963021000286 Test RE 1.2939852488291717\n",
      "74 Train Loss 3.0945365 Test MSE 7.3474435817184425 Test RE 1.2956156648153996\n",
      "75 Train Loss 3.0708349 Test MSE 7.342371010427895 Test RE 1.2951683502177922\n",
      "76 Train Loss 3.0374987 Test MSE 7.436943144955685 Test RE 1.303482758296939\n",
      "77 Train Loss 2.982276 Test MSE 7.453998610187715 Test RE 1.3049765691885247\n",
      "78 Train Loss 2.9541924 Test MSE 7.3937266693087205 Test RE 1.2996899360717693\n",
      "79 Train Loss 2.931381 Test MSE 7.428409500283934 Test RE 1.3027346921049638\n",
      "80 Train Loss 2.9122283 Test MSE 7.405415501261104 Test RE 1.300716878128585\n",
      "81 Train Loss 2.8860278 Test MSE 7.401662219628467 Test RE 1.3003872156333733\n",
      "82 Train Loss 2.8558154 Test MSE 7.425541591543609 Test RE 1.302483192447903\n",
      "83 Train Loss 2.8386106 Test MSE 7.380921437299214 Test RE 1.2985639786139263\n",
      "84 Train Loss 2.822154 Test MSE 7.359537101459425 Test RE 1.296681485283043\n",
      "85 Train Loss 2.8029332 Test MSE 7.375898336010699 Test RE 1.2981220332141017\n",
      "86 Train Loss 2.7786372 Test MSE 7.363715999217262 Test RE 1.2970495743545858\n",
      "87 Train Loss 2.7489629 Test MSE 7.343490621101376 Test RE 1.29526709414067\n",
      "88 Train Loss 2.7209349 Test MSE 7.367607760069853 Test RE 1.297392277684417\n",
      "89 Train Loss 2.7057362 Test MSE 7.362605942827312 Test RE 1.2969518076540796\n",
      "90 Train Loss 2.694508 Test MSE 7.34186148862029 Test RE 1.295123410513227\n",
      "91 Train Loss 2.683833 Test MSE 7.35388708367669 Test RE 1.2961836496169137\n",
      "92 Train Loss 2.66412 Test MSE 7.4317263412368035 Test RE 1.3030255000867563\n",
      "93 Train Loss 2.649225 Test MSE 7.4438711307680405 Test RE 1.3040897555359574\n",
      "94 Train Loss 2.6333215 Test MSE 7.428161578262271 Test RE 1.3027129526388361\n",
      "95 Train Loss 2.6202962 Test MSE 7.402410521016894 Test RE 1.3004529479605793\n",
      "96 Train Loss 2.6072652 Test MSE 7.4128471578248805 Test RE 1.3013693774485668\n",
      "97 Train Loss 2.5946581 Test MSE 7.415274876024524 Test RE 1.3015824601834183\n",
      "98 Train Loss 2.58613 Test MSE 7.413600406949667 Test RE 1.3014354944494348\n",
      "99 Train Loss 2.5709255 Test MSE 7.439177085274527 Test RE 1.3036785164190838\n",
      "Training time: 195.81\n",
      "4\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.446438 Test MSE 7.978365064500805 Test RE 1.3500971250366032\n",
      "1 Train Loss 54.320892 Test MSE 7.063071324632631 Test RE 1.2702957825865424\n",
      "2 Train Loss 47.039955 Test MSE 7.388170494823862 Test RE 1.2992015043549234\n",
      "3 Train Loss 41.1305 Test MSE 8.161457654676676 Test RE 1.3655006968443866\n",
      "4 Train Loss 35.174717 Test MSE 8.077474141837849 Test RE 1.358456851340508\n",
      "5 Train Loss 28.62457 Test MSE 6.984928705282729 Test RE 1.2632492501210204\n",
      "6 Train Loss 25.039507 Test MSE 6.904770900523905 Test RE 1.2559799222286256\n",
      "7 Train Loss 22.166018 Test MSE 6.532669657182377 Test RE 1.2216685928182567\n",
      "8 Train Loss 20.433392 Test MSE 6.584470870383242 Test RE 1.2265026775074743\n",
      "9 Train Loss 17.74238 Test MSE 6.2729729906047815 Test RE 1.197139523045814\n",
      "10 Train Loss 15.508016 Test MSE 5.877956306512735 Test RE 1.158834021755891\n",
      "11 Train Loss 14.6072445 Test MSE 5.943042313451931 Test RE 1.165232184064244\n",
      "12 Train Loss 13.60693 Test MSE 6.082656880406945 Test RE 1.1788396089380693\n",
      "13 Train Loss 12.747988 Test MSE 6.089058768375882 Test RE 1.179459799636352\n",
      "14 Train Loss 11.619085 Test MSE 5.912015531631679 Test RE 1.1621865457495693\n",
      "15 Train Loss 10.893421 Test MSE 5.9363563785749704 Test RE 1.1645765553095981\n",
      "16 Train Loss 10.455986 Test MSE 5.756487174901207 Test RE 1.146797746811813\n",
      "17 Train Loss 10.003622 Test MSE 5.833441490324364 Test RE 1.1544376534855247\n",
      "18 Train Loss 9.6280365 Test MSE 5.636644844748186 Test RE 1.1347975671272206\n",
      "19 Train Loss 9.331098 Test MSE 5.606301166276562 Test RE 1.1317389745999347\n",
      "20 Train Loss 8.949445 Test MSE 5.4731032819668775 Test RE 1.1182138888430095\n",
      "21 Train Loss 8.554383 Test MSE 5.2940982601582816 Test RE 1.0997755470141337\n",
      "22 Train Loss 8.213886 Test MSE 5.21835352989712 Test RE 1.0918797441699517\n",
      "23 Train Loss 7.7704153 Test MSE 4.912973974245935 Test RE 1.0594495773317478\n",
      "24 Train Loss 6.8692446 Test MSE 4.686594221129014 Test RE 1.034753101066371\n",
      "25 Train Loss 6.1874337 Test MSE 4.394177306668239 Test RE 1.001951843609695\n",
      "26 Train Loss 5.54718 Test MSE 4.207422316912128 Test RE 0.980428920215367\n",
      "27 Train Loss 5.259962 Test MSE 4.18219649792524 Test RE 0.9774853953164966\n",
      "28 Train Loss 4.992704 Test MSE 4.17244595618171 Test RE 0.9763452559319185\n",
      "29 Train Loss 4.7001843 Test MSE 4.135100906457305 Test RE 0.9719660960484342\n",
      "30 Train Loss 4.400957 Test MSE 4.023390754812402 Test RE 0.9587473291125707\n",
      "31 Train Loss 4.1567583 Test MSE 3.915423011698011 Test RE 0.9457958514691536\n",
      "32 Train Loss 3.9782205 Test MSE 3.8119518561540953 Test RE 0.9332151138393869\n",
      "33 Train Loss 3.6785316 Test MSE 3.65141051676478 Test RE 0.9133524357911764\n",
      "34 Train Loss 3.5685825 Test MSE 3.66171645419397 Test RE 0.9146404750928885\n",
      "35 Train Loss 3.4145937 Test MSE 3.5181003777643363 Test RE 0.896524523078244\n",
      "36 Train Loss 3.2631156 Test MSE 3.445511173251017 Test RE 0.8872272897544923\n",
      "37 Train Loss 3.079978 Test MSE 3.3552468657621146 Test RE 0.8755285246970135\n",
      "38 Train Loss 2.904291 Test MSE 3.2448577123741527 Test RE 0.8610054274893867\n",
      "39 Train Loss 2.8339705 Test MSE 3.2219189236999144 Test RE 0.857956688143365\n",
      "40 Train Loss 2.724017 Test MSE 3.0512690268986207 Test RE 0.8349266251241562\n",
      "41 Train Loss 2.6367679 Test MSE 2.9094851773820487 Test RE 0.8152975453399564\n",
      "42 Train Loss 2.542439 Test MSE 2.815830139520349 Test RE 0.8020681794210401\n",
      "43 Train Loss 2.4589894 Test MSE 2.767280584101062 Test RE 0.7951236262975541\n",
      "44 Train Loss 2.3587725 Test MSE 2.7185641442385493 Test RE 0.7880936941831732\n",
      "45 Train Loss 2.286799 Test MSE 2.64670489416845 Test RE 0.7776081800571834\n",
      "46 Train Loss 2.1975667 Test MSE 2.548109797189363 Test RE 0.7629869837230561\n",
      "47 Train Loss 2.1197867 Test MSE 2.5352227619732606 Test RE 0.761055139225572\n",
      "48 Train Loss 2.0801206 Test MSE 2.49369732950732 Test RE 0.7547965916105669\n",
      "49 Train Loss 2.030375 Test MSE 2.3916326076396364 Test RE 0.7391886558838326\n",
      "50 Train Loss 1.9658134 Test MSE 2.3466822298387275 Test RE 0.7322092358231364\n",
      "51 Train Loss 1.8773003 Test MSE 2.2208763951413553 Test RE 0.7123119894974622\n",
      "52 Train Loss 1.8105376 Test MSE 2.0995126952522645 Test RE 0.692575800729967\n",
      "53 Train Loss 1.7315419 Test MSE 2.019371139003823 Test RE 0.679228863530094\n",
      "54 Train Loss 1.6745819 Test MSE 2.0110422132676447 Test RE 0.677826671515212\n",
      "55 Train Loss 1.6306201 Test MSE 1.9992466451825783 Test RE 0.6758358855700164\n",
      "56 Train Loss 1.585576 Test MSE 1.940263295858128 Test RE 0.6657917269521786\n",
      "57 Train Loss 1.5589321 Test MSE 1.8852981907248465 Test RE 0.6562934738154628\n",
      "58 Train Loss 1.5249773 Test MSE 1.8319897924444908 Test RE 0.6469483134679654\n",
      "59 Train Loss 1.5054066 Test MSE 1.7856424404586295 Test RE 0.6387123446771296\n",
      "60 Train Loss 1.471216 Test MSE 1.7118216156792698 Test RE 0.6253703883520966\n",
      "61 Train Loss 1.4077946 Test MSE 1.5707278515048657 Test RE 0.5990437377857759\n",
      "62 Train Loss 1.3666921 Test MSE 1.4518337499312157 Test RE 0.5759257602450364\n",
      "63 Train Loss 1.3360417 Test MSE 1.4344488398375836 Test RE 0.5724671784095992\n",
      "64 Train Loss 1.2968248 Test MSE 1.346693207690467 Test RE 0.5546798572577998\n",
      "65 Train Loss 1.260815 Test MSE 1.3173988079692105 Test RE 0.548613756503335\n",
      "66 Train Loss 1.2113098 Test MSE 1.2507653478930256 Test RE 0.5345594120758052\n",
      "67 Train Loss 1.1697938 Test MSE 1.2031102362540755 Test RE 0.5242769584107263\n",
      "68 Train Loss 1.1162518 Test MSE 1.2047951175976 Test RE 0.5246439386709403\n",
      "69 Train Loss 1.0755436 Test MSE 1.1191030865383227 Test RE 0.5056419611118147\n",
      "70 Train Loss 1.0306896 Test MSE 1.0630712313820996 Test RE 0.4928210424522178\n",
      "71 Train Loss 0.96067137 Test MSE 1.0036718497070178 Test RE 0.4788548958555729\n",
      "72 Train Loss 0.9325943 Test MSE 0.9955572894808983 Test RE 0.4769152267070531\n",
      "73 Train Loss 0.8651843 Test MSE 1.0005503380944323 Test RE 0.47810967462978027\n",
      "74 Train Loss 0.8240957 Test MSE 0.946818818346965 Test RE 0.4650948181248025\n",
      "75 Train Loss 0.7790232 Test MSE 0.8907661006517633 Test RE 0.45111773471267774\n",
      "76 Train Loss 0.7395154 Test MSE 0.8522804793946909 Test RE 0.44126484690937545\n",
      "77 Train Loss 0.716872 Test MSE 0.8036283948472706 Test RE 0.4284850728430545\n",
      "78 Train Loss 0.6848711 Test MSE 0.7769001360388929 Test RE 0.4212992238408774\n",
      "79 Train Loss 0.66261667 Test MSE 0.7641448787269803 Test RE 0.41782643527199076\n",
      "80 Train Loss 0.6474725 Test MSE 0.7336587294760535 Test RE 0.4094068501658467\n",
      "81 Train Loss 0.6190092 Test MSE 0.7202534581441049 Test RE 0.4056493051010621\n",
      "82 Train Loss 0.57774776 Test MSE 0.668071392444506 Test RE 0.3906784876608374\n",
      "83 Train Loss 0.5498364 Test MSE 0.6267050378192979 Test RE 0.3783900023883872\n",
      "84 Train Loss 0.524787 Test MSE 0.6122670550049928 Test RE 0.3740059453766916\n",
      "85 Train Loss 0.49922028 Test MSE 0.579616804989545 Test RE 0.363897058102391\n",
      "86 Train Loss 0.46885258 Test MSE 0.5403363306325282 Test RE 0.35135015129485\n",
      "87 Train Loss 0.44912535 Test MSE 0.5147797709724181 Test RE 0.34294051558279814\n",
      "88 Train Loss 0.4321813 Test MSE 0.4891741645021583 Test RE 0.3343026476918215\n",
      "89 Train Loss 0.41446948 Test MSE 0.4681162486838382 Test RE 0.3270279849117616\n",
      "90 Train Loss 0.3909049 Test MSE 0.45800348886586817 Test RE 0.3234762899572269\n",
      "91 Train Loss 0.3722086 Test MSE 0.44889294641427624 Test RE 0.32024285648396417\n",
      "92 Train Loss 0.3511644 Test MSE 0.45409761810384036 Test RE 0.3220940277445151\n",
      "93 Train Loss 0.33347854 Test MSE 0.4262220461747345 Test RE 0.3120513136052708\n",
      "94 Train Loss 0.31179115 Test MSE 0.38671844606452893 Test RE 0.2972388033793324\n",
      "95 Train Loss 0.30261248 Test MSE 0.3753176646458912 Test RE 0.2928246028568961\n",
      "96 Train Loss 0.29197818 Test MSE 0.3554316104276576 Test RE 0.2849614322463804\n",
      "97 Train Loss 0.28139368 Test MSE 0.33700540139126905 Test RE 0.27747668099434\n",
      "98 Train Loss 0.2665746 Test MSE 0.3425965082125203 Test RE 0.2797689587045987\n",
      "99 Train Loss 0.25490224 Test MSE 0.342278365213662 Test RE 0.2796390285880408\n",
      "Training time: 197.73\n",
      "5\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.429665 Test MSE 4.700752256337587 Test RE 1.0363148986629873\n",
      "1 Train Loss 56.57385 Test MSE 5.456922734810432 Test RE 1.1165597354234686\n",
      "2 Train Loss 45.364582 Test MSE 5.833150235309227 Test RE 1.154408833452459\n",
      "3 Train Loss 37.55983 Test MSE 6.364335120762971 Test RE 1.205825823146717\n",
      "4 Train Loss 34.060932 Test MSE 6.482896935422871 Test RE 1.2170057185263932\n",
      "5 Train Loss 30.445707 Test MSE 6.893468537510417 Test RE 1.254951549591513\n",
      "6 Train Loss 26.726795 Test MSE 6.381294831458332 Test RE 1.207431399434374\n",
      "7 Train Loss 24.440502 Test MSE 6.007743427192367 Test RE 1.1715578780729523\n",
      "8 Train Loss 21.924139 Test MSE 6.000412504293724 Test RE 1.170842865670211\n",
      "9 Train Loss 20.190937 Test MSE 5.787073779260743 Test RE 1.1498404165059026\n",
      "10 Train Loss 18.981335 Test MSE 5.803695167223778 Test RE 1.151490493982915\n",
      "11 Train Loss 17.58115 Test MSE 5.71672724447775 Test RE 1.1428304309821415\n",
      "12 Train Loss 16.433983 Test MSE 5.789905214300896 Test RE 1.1501216726674326\n",
      "13 Train Loss 15.757883 Test MSE 5.598656147690276 Test RE 1.1309670648435957\n",
      "14 Train Loss 15.192377 Test MSE 5.697970592559557 Test RE 1.1409540703252765\n",
      "15 Train Loss 14.75444 Test MSE 5.680939167520507 Test RE 1.1392476192364283\n",
      "16 Train Loss 14.342037 Test MSE 5.625875344564226 Test RE 1.1337129639586647\n",
      "17 Train Loss 13.81238 Test MSE 5.631668660627787 Test RE 1.1342965413696604\n",
      "18 Train Loss 13.208397 Test MSE 5.636320711707713 Test RE 1.1347649386146967\n",
      "19 Train Loss 12.967903 Test MSE 5.540256819555319 Test RE 1.125053069202984\n",
      "20 Train Loss 12.599604 Test MSE 5.3913380140312555 Test RE 1.1098296951534352\n",
      "21 Train Loss 12.136467 Test MSE 5.360960962777281 Test RE 1.1066986563942063\n",
      "22 Train Loss 11.53861 Test MSE 5.256921058841608 Test RE 1.0959072196447739\n",
      "23 Train Loss 11.2373905 Test MSE 5.297988224379856 Test RE 1.1001795159009466\n",
      "24 Train Loss 10.877115 Test MSE 5.2994035955631675 Test RE 1.100326463981165\n",
      "25 Train Loss 10.291703 Test MSE 5.065612686155502 Test RE 1.0757814483618722\n",
      "26 Train Loss 9.697919 Test MSE 4.858812973663819 Test RE 1.0535936670486559\n",
      "27 Train Loss 9.322441 Test MSE 4.611807201020385 Test RE 1.0264637857922732\n",
      "28 Train Loss 8.399132 Test MSE 4.518879357586117 Test RE 1.016069543712299\n",
      "29 Train Loss 7.7785254 Test MSE 4.4019718655876385 Test RE 1.0028401000323317\n",
      "30 Train Loss 7.1464353 Test MSE 4.213133423095372 Test RE 0.981094105977307\n",
      "31 Train Loss 6.4415236 Test MSE 4.251318725349741 Test RE 0.9855301002093722\n",
      "32 Train Loss 5.876925 Test MSE 4.134338853358641 Test RE 0.9718765306520374\n",
      "33 Train Loss 5.2162595 Test MSE 4.165129777155977 Test RE 0.9754888936467373\n",
      "34 Train Loss 4.7268157 Test MSE 3.861616774677856 Test RE 0.9392747475506301\n",
      "35 Train Loss 4.1869507 Test MSE 3.653070001544086 Test RE 0.9135599613878131\n",
      "36 Train Loss 3.847068 Test MSE 3.7770761779788247 Test RE 0.928936296059067\n",
      "37 Train Loss 3.613487 Test MSE 3.638179250582319 Test RE 0.9116961201479611\n",
      "38 Train Loss 3.3398345 Test MSE 3.6520898719158064 Test RE 0.9134373977285963\n",
      "39 Train Loss 3.1030617 Test MSE 3.730936084192806 Test RE 0.923245001035315\n",
      "40 Train Loss 2.8472044 Test MSE 3.728634668475526 Test RE 0.9229602067807545\n",
      "41 Train Loss 2.7662625 Test MSE 3.830703982969962 Test RE 0.9355076794266488\n",
      "42 Train Loss 2.642548 Test MSE 3.824008423702191 Test RE 0.9346897505832813\n",
      "43 Train Loss 2.4921632 Test MSE 3.8914159863098234 Test RE 0.9428918668213322\n",
      "44 Train Loss 2.3735604 Test MSE 3.9892437560149463 Test RE 0.9546701581639951\n",
      "45 Train Loss 2.2785518 Test MSE 4.11298506823378 Test RE 0.969363419088205\n",
      "46 Train Loss 2.1569655 Test MSE 4.171347381234329 Test RE 0.9762167151359532\n",
      "47 Train Loss 2.0782506 Test MSE 4.198068189262331 Test RE 0.9793384472809303\n",
      "48 Train Loss 2.0023246 Test MSE 4.248821232765124 Test RE 0.9852405764320357\n",
      "49 Train Loss 1.9621222 Test MSE 4.212863140864906 Test RE 0.9810626357472402\n",
      "50 Train Loss 1.9268293 Test MSE 4.253867491848776 Test RE 0.9858254802895815\n",
      "51 Train Loss 1.8855921 Test MSE 4.33039650438868 Test RE 0.9946536760366458\n",
      "52 Train Loss 1.807366 Test MSE 4.340994985997029 Test RE 0.9958701208110563\n",
      "53 Train Loss 1.7381536 Test MSE 4.313824913806177 Test RE 0.9927486780731751\n",
      "54 Train Loss 1.700992 Test MSE 4.295567879986908 Test RE 0.9906456877931771\n",
      "55 Train Loss 1.6667377 Test MSE 4.288599380131309 Test RE 0.989841822445228\n",
      "56 Train Loss 1.6276896 Test MSE 4.333367300188911 Test RE 0.9949948002665081\n",
      "57 Train Loss 1.5828719 Test MSE 4.369186639465923 Test RE 0.9990986192001968\n",
      "58 Train Loss 1.5468904 Test MSE 4.396603758582633 Test RE 1.0022284428759871\n",
      "59 Train Loss 1.5122827 Test MSE 4.434253215668218 Test RE 1.006510489006937\n",
      "60 Train Loss 1.4430063 Test MSE 4.526717040623578 Test RE 1.0169503130687647\n",
      "61 Train Loss 1.3989567 Test MSE 4.49041271963458 Test RE 1.012864127354145\n",
      "62 Train Loss 1.3639685 Test MSE 4.454372204138331 Test RE 1.008791262620475\n",
      "63 Train Loss 1.3188324 Test MSE 4.3624859351481735 Test RE 0.9983322027325001\n",
      "64 Train Loss 1.2787998 Test MSE 4.225875942830319 Test RE 0.9825766335067956\n",
      "65 Train Loss 1.246733 Test MSE 4.18423156673093 Test RE 0.9777231899899629\n",
      "66 Train Loss 1.2138897 Test MSE 4.162657193634166 Test RE 0.9751993065317469\n",
      "67 Train Loss 1.16451 Test MSE 4.120296128745911 Test RE 0.9702245853550452\n",
      "68 Train Loss 1.1109197 Test MSE 4.119861687778611 Test RE 0.9701734341263983\n",
      "69 Train Loss 1.0751075 Test MSE 4.1201517413334745 Test RE 0.9702075854307334\n",
      "70 Train Loss 1.050682 Test MSE 4.109461155175423 Test RE 0.9689480657200871\n",
      "71 Train Loss 1.0250226 Test MSE 4.080939924711361 Test RE 0.9655797763559565\n",
      "72 Train Loss 1.0091754 Test MSE 4.090338770155111 Test RE 0.9666910541361154\n",
      "73 Train Loss 0.99269724 Test MSE 4.074758499320674 Test RE 0.9648482143431224\n",
      "74 Train Loss 0.96188205 Test MSE 3.967495874353412 Test RE 0.9520643475076153\n",
      "75 Train Loss 0.9375843 Test MSE 3.877611710968494 Test RE 0.9412179899362315\n",
      "76 Train Loss 0.9253833 Test MSE 3.854528264077594 Test RE 0.9384122697804697\n",
      "77 Train Loss 0.9099741 Test MSE 3.798444796529866 Test RE 0.9315602951998132\n",
      "78 Train Loss 0.88274086 Test MSE 3.7166454251662095 Test RE 0.9214751452208824\n",
      "79 Train Loss 0.86748743 Test MSE 3.701947977881554 Test RE 0.9196513570178168\n",
      "80 Train Loss 0.8559444 Test MSE 3.7017681020255626 Test RE 0.9196290140398022\n",
      "81 Train Loss 0.8436004 Test MSE 3.6817064747145145 Test RE 0.9171336769060842\n",
      "82 Train Loss 0.8257707 Test MSE 3.6637597697641193 Test RE 0.9148956339096056\n",
      "83 Train Loss 0.8165693 Test MSE 3.6740033024807035 Test RE 0.9161737228732452\n",
      "84 Train Loss 0.8089899 Test MSE 3.6915088739896045 Test RE 0.9183537815708501\n",
      "85 Train Loss 0.8017334 Test MSE 3.677502038552462 Test RE 0.9166098530312456\n",
      "86 Train Loss 0.79647124 Test MSE 3.6744391369182274 Test RE 0.9162280625383342\n",
      "87 Train Loss 0.7881292 Test MSE 3.684811583847015 Test RE 0.9175203454221635\n",
      "88 Train Loss 0.77724135 Test MSE 3.680934748287075 Test RE 0.9170375511836578\n",
      "89 Train Loss 0.7677534 Test MSE 3.6626636405094954 Test RE 0.9147587637336668\n",
      "90 Train Loss 0.7594593 Test MSE 3.6597030841917175 Test RE 0.914388986081729\n",
      "91 Train Loss 0.74855983 Test MSE 3.657553502565138 Test RE 0.9141204065784216\n",
      "92 Train Loss 0.7360049 Test MSE 3.6330763018719874 Test RE 0.9110565184791221\n",
      "93 Train Loss 0.72764564 Test MSE 3.6150929354116186 Test RE 0.9087989016782544\n",
      "94 Train Loss 0.71853137 Test MSE 3.6193420525824056 Test RE 0.9093328380169585\n",
      "95 Train Loss 0.7089781 Test MSE 3.5948006571612097 Test RE 0.9062446724299902\n",
      "96 Train Loss 0.6993105 Test MSE 3.5580688618020524 Test RE 0.9016027647505173\n",
      "97 Train Loss 0.68947375 Test MSE 3.548156859667765 Test RE 0.9003460547941597\n",
      "98 Train Loss 0.6775346 Test MSE 3.533645839972016 Test RE 0.8985030803612023\n",
      "99 Train Loss 0.66698897 Test MSE 3.5052490874574516 Test RE 0.8948855650223251\n",
      "Training time: 195.61\n",
      "6\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.64124 Test MSE 6.744674738803346 Test RE 1.2413337564861477\n",
      "1 Train Loss 51.345078 Test MSE 8.047215011425212 Test RE 1.3559099975067403\n",
      "2 Train Loss 46.301247 Test MSE 8.041665866723104 Test RE 1.3554424172117183\n",
      "3 Train Loss 40.816692 Test MSE 8.527981617411333 Test RE 1.3958256927233317\n",
      "4 Train Loss 37.58554 Test MSE 8.873890889975272 Test RE 1.4238528292034356\n",
      "5 Train Loss 32.630634 Test MSE 8.571102291229245 Test RE 1.3993501522249872\n",
      "6 Train Loss 30.047573 Test MSE 8.288570336789933 Test RE 1.376093279605401\n",
      "7 Train Loss 28.502537 Test MSE 8.642847681295592 Test RE 1.405194657276637\n",
      "8 Train Loss 26.7948 Test MSE 8.79343973785816 Test RE 1.4173837720551798\n",
      "9 Train Loss 25.258316 Test MSE 8.61150223652326 Test RE 1.402644198093679\n",
      "10 Train Loss 23.98127 Test MSE 8.643048442736676 Test RE 1.4052109775495705\n",
      "11 Train Loss 22.575554 Test MSE 8.777337277585962 Test RE 1.4160854277997497\n",
      "12 Train Loss 21.387627 Test MSE 8.504352850326692 Test RE 1.3938906206742792\n",
      "13 Train Loss 20.605835 Test MSE 8.611638232048868 Test RE 1.4026552735469868\n",
      "14 Train Loss 19.740479 Test MSE 8.547473329528163 Test RE 1.3974199447576847\n",
      "15 Train Loss 18.416945 Test MSE 8.39558899294079 Test RE 1.3849485662731236\n",
      "16 Train Loss 17.295002 Test MSE 8.457116818321769 Test RE 1.390014162060874\n",
      "17 Train Loss 16.569809 Test MSE 8.329459694541189 Test RE 1.379483390545269\n",
      "18 Train Loss 15.625015 Test MSE 8.526208341555847 Test RE 1.3956805638526406\n",
      "19 Train Loss 14.268607 Test MSE 7.761656150886546 Test RE 1.3316351792225596\n",
      "20 Train Loss 11.642481 Test MSE 6.099486056932453 Test RE 1.1804692583582868\n",
      "21 Train Loss 9.702863 Test MSE 5.82962982131485 Test RE 1.1540604273418682\n",
      "22 Train Loss 8.4982195 Test MSE 5.609401084981564 Test RE 1.1320518202606884\n",
      "23 Train Loss 7.8557253 Test MSE 5.890907144086177 Test RE 1.1601099425719448\n",
      "24 Train Loss 7.2675447 Test MSE 5.705353205259836 Test RE 1.1416929733468637\n",
      "25 Train Loss 6.2739177 Test MSE 5.137668984145885 Test RE 1.0834057097613237\n",
      "26 Train Loss 5.3815813 Test MSE 4.848161213499109 Test RE 1.0524381600779802\n",
      "27 Train Loss 4.7800374 Test MSE 4.229020140116774 Test RE 0.9829421009723008\n",
      "28 Train Loss 4.172476 Test MSE 3.6124984451256097 Test RE 0.9084727284418999\n",
      "29 Train Loss 3.724363 Test MSE 3.4091339854670792 Test RE 0.8825312558427285\n",
      "30 Train Loss 3.3720403 Test MSE 3.3701872208479706 Test RE 0.8774756508471256\n",
      "31 Train Loss 3.0555143 Test MSE 3.2204942308416267 Test RE 0.8577669782298957\n",
      "32 Train Loss 2.6249309 Test MSE 2.7074465285453666 Test RE 0.7864805817964413\n",
      "33 Train Loss 2.4136271 Test MSE 2.528794095877398 Test RE 0.7600896077239995\n",
      "34 Train Loss 2.150166 Test MSE 2.620143379124411 Test RE 0.7736964229293015\n",
      "35 Train Loss 1.9895935 Test MSE 2.61915486105068 Test RE 0.7735504604881234\n",
      "36 Train Loss 1.9238796 Test MSE 2.6085751811526627 Test RE 0.7719865595643138\n",
      "37 Train Loss 1.8274899 Test MSE 2.628911508825196 Test RE 0.7749899026442966\n",
      "38 Train Loss 1.736373 Test MSE 2.694420739415342 Test RE 0.7845863833896045\n",
      "39 Train Loss 1.6704654 Test MSE 2.7301759843343114 Test RE 0.7897749984224244\n",
      "40 Train Loss 1.5999523 Test MSE 2.7275267071450635 Test RE 0.7893917189690213\n",
      "41 Train Loss 1.5026494 Test MSE 2.765704311521183 Test RE 0.7948971385851116\n",
      "42 Train Loss 1.4299396 Test MSE 2.8715196670932612 Test RE 0.8099607201354044\n",
      "43 Train Loss 1.3772483 Test MSE 2.8827678300938158 Test RE 0.8115455370322731\n",
      "44 Train Loss 1.3235489 Test MSE 2.8670850057663384 Test RE 0.8093350428341817\n",
      "45 Train Loss 1.2663743 Test MSE 2.9187918862172477 Test RE 0.8166004697884067\n",
      "46 Train Loss 1.205637 Test MSE 2.9244590698325252 Test RE 0.8173928491001593\n",
      "47 Train Loss 1.1790295 Test MSE 2.9259748616188204 Test RE 0.8176046552549117\n",
      "48 Train Loss 1.1559974 Test MSE 2.930811789253067 Test RE 0.8182801671289764\n",
      "49 Train Loss 1.1384131 Test MSE 2.8891241491832482 Test RE 0.8124397474429523\n",
      "50 Train Loss 1.1024897 Test MSE 2.9026846542297493 Test RE 0.8143441647356897\n",
      "51 Train Loss 1.068416 Test MSE 2.9569228448619715 Test RE 0.8219171767172343\n",
      "52 Train Loss 1.0432794 Test MSE 2.917610367107975 Test RE 0.816435174221417\n",
      "53 Train Loss 1.0195161 Test MSE 2.913967929353974 Test RE 0.8159253832180042\n",
      "54 Train Loss 0.9877279 Test MSE 2.9372341505135062 Test RE 0.8191762354132518\n",
      "55 Train Loss 0.9615769 Test MSE 2.924857048424058 Test RE 0.8174484651611852\n",
      "56 Train Loss 0.9422746 Test MSE 2.9252316580780775 Test RE 0.8175008120412431\n",
      "57 Train Loss 0.9273778 Test MSE 2.9249045433861536 Test RE 0.8174551021567051\n",
      "58 Train Loss 0.8989616 Test MSE 2.8845911543483145 Test RE 0.8118021440236447\n",
      "59 Train Loss 0.8822979 Test MSE 2.8863229422322156 Test RE 0.8120457934871198\n",
      "60 Train Loss 0.8609911 Test MSE 2.9106873284455967 Test RE 0.8154659616629504\n",
      "61 Train Loss 0.8403823 Test MSE 2.903086716677409 Test RE 0.8144005618145893\n",
      "62 Train Loss 0.83193696 Test MSE 2.9056245723858933 Test RE 0.8147564553534136\n",
      "63 Train Loss 0.8224351 Test MSE 2.9048724716673675 Test RE 0.8146510015071317\n",
      "64 Train Loss 0.79900587 Test MSE 2.9001260219642258 Test RE 0.8139851752370537\n",
      "65 Train Loss 0.7843892 Test MSE 2.9354491158717217 Test RE 0.8189272800842403\n",
      "66 Train Loss 0.7732539 Test MSE 2.969542479131646 Test RE 0.823669209400874\n",
      "67 Train Loss 0.7662239 Test MSE 2.967245187957193 Test RE 0.8233505451416758\n",
      "68 Train Loss 0.7553706 Test MSE 2.9625627959504692 Test RE 0.8227006540996424\n",
      "69 Train Loss 0.73512524 Test MSE 2.9717191775575094 Test RE 0.8239710321657837\n",
      "70 Train Loss 0.7284362 Test MSE 2.9791145820200438 Test RE 0.8249956600444415\n",
      "71 Train Loss 0.7180414 Test MSE 2.982242950555847 Test RE 0.8254287104023915\n",
      "72 Train Loss 0.71039474 Test MSE 2.9838520375603617 Test RE 0.8256513628696183\n",
      "73 Train Loss 0.7014742 Test MSE 2.9710372333604234 Test RE 0.8238764851258169\n",
      "74 Train Loss 0.69057983 Test MSE 2.9589919464631134 Test RE 0.8222046939837238\n",
      "75 Train Loss 0.68082744 Test MSE 2.9697259677065664 Test RE 0.823694656343614\n",
      "76 Train Loss 0.6694897 Test MSE 2.9544672402022507 Test RE 0.8215758213693087\n",
      "77 Train Loss 0.65996563 Test MSE 2.953810969620044 Test RE 0.8214845687095804\n",
      "78 Train Loss 0.65555984 Test MSE 2.9573250654469954 Test RE 0.8219730761747833\n",
      "79 Train Loss 0.64965695 Test MSE 2.9385217188925044 Test RE 0.8193557631252189\n",
      "80 Train Loss 0.6433278 Test MSE 2.9386390869385166 Test RE 0.8193721259827842\n",
      "81 Train Loss 0.63843626 Test MSE 2.955007537725649 Test RE 0.8216509406806806\n",
      "82 Train Loss 0.63198096 Test MSE 2.9446267736714384 Test RE 0.8202064657658412\n",
      "83 Train Loss 0.6286911 Test MSE 2.9392921932460716 Test RE 0.8194631727833465\n",
      "84 Train Loss 0.6221058 Test MSE 2.9476170422594565 Test RE 0.8206228199375736\n",
      "85 Train Loss 0.61640924 Test MSE 2.937483412187863 Test RE 0.8192109934369132\n",
      "86 Train Loss 0.60873 Test MSE 2.9160540220757274 Test RE 0.8162173890882667\n",
      "87 Train Loss 0.6030003 Test MSE 2.9460289112357625 Test RE 0.8204017206340696\n",
      "88 Train Loss 0.5994187 Test MSE 2.95367158680437 Test RE 0.8214651865987783\n",
      "89 Train Loss 0.5951468 Test MSE 2.9430807017352216 Test RE 0.8199911133981067\n",
      "90 Train Loss 0.58972967 Test MSE 2.951254399666709 Test RE 0.821128987831321\n",
      "91 Train Loss 0.58688635 Test MSE 2.9527263923572358 Test RE 0.8213337389349408\n",
      "92 Train Loss 0.58012307 Test MSE 2.953237424879927 Test RE 0.8214048105544608\n",
      "93 Train Loss 0.5767873 Test MSE 2.950876209537602 Test RE 0.821076374131318\n",
      "94 Train Loss 0.5729573 Test MSE 2.9480192779528447 Test RE 0.8206788096614941\n",
      "95 Train Loss 0.56874883 Test MSE 2.9564950943220873 Test RE 0.8218577250084412\n",
      "96 Train Loss 0.56447715 Test MSE 2.9705920344974537 Test RE 0.8238147554019675\n",
      "97 Train Loss 0.56127757 Test MSE 2.970333305296081 Test RE 0.8237788787867115\n",
      "98 Train Loss 0.55865014 Test MSE 2.9631919150235158 Test RE 0.8227880023237631\n",
      "99 Train Loss 0.55680287 Test MSE 2.9629922349834765 Test RE 0.822760279328785\n",
      "Training time: 196.51\n",
      "7\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 61.535522 Test MSE 5.546963423441924 Test RE 1.1257338141106135\n",
      "1 Train Loss 45.103283 Test MSE 7.383334401845829 Test RE 1.2987762239832326\n",
      "2 Train Loss 37.928513 Test MSE 8.157824283985832 Test RE 1.365196711776591\n",
      "3 Train Loss 34.510273 Test MSE 7.82892915479191 Test RE 1.3373936038105319\n",
      "4 Train Loss 29.33527 Test MSE 7.473036521906466 Test RE 1.3066419964979556\n",
      "5 Train Loss 26.381664 Test MSE 7.142801647311695 Test RE 1.2774454251565948\n",
      "6 Train Loss 22.893566 Test MSE 6.593136834892708 Test RE 1.2273095254664723\n",
      "7 Train Loss 21.436966 Test MSE 6.123217191928516 Test RE 1.1827634418112354\n",
      "8 Train Loss 19.194178 Test MSE 5.741256956230525 Test RE 1.14527967269118\n",
      "9 Train Loss 16.09711 Test MSE 5.923016199792299 Test RE 1.1632673012642054\n",
      "10 Train Loss 14.22145 Test MSE 6.021046437184454 Test RE 1.1728542573409801\n",
      "11 Train Loss 13.481396 Test MSE 6.055479033611173 Test RE 1.176203080969652\n",
      "12 Train Loss 12.501097 Test MSE 6.056412899741582 Test RE 1.176293773536497\n",
      "13 Train Loss 11.743613 Test MSE 5.773567491285189 Test RE 1.1484978426702603\n",
      "14 Train Loss 11.164637 Test MSE 5.820402136571554 Test RE 1.1531466880785415\n",
      "15 Train Loss 10.764509 Test MSE 5.658170706943773 Test RE 1.1369623495040337\n",
      "16 Train Loss 10.221269 Test MSE 5.543401852518956 Test RE 1.1253723528658288\n",
      "17 Train Loss 9.734581 Test MSE 5.270342093998841 Test RE 1.0973052655283004\n",
      "18 Train Loss 9.051974 Test MSE 5.065708413552513 Test RE 1.0757916131018224\n",
      "19 Train Loss 8.449265 Test MSE 4.940329929666095 Test RE 1.0623950461484701\n",
      "20 Train Loss 7.972875 Test MSE 4.908703773117331 Test RE 1.0589890572603053\n",
      "21 Train Loss 7.6308627 Test MSE 4.927106570108398 Test RE 1.060972282380748\n",
      "22 Train Loss 7.3752136 Test MSE 4.833178471554015 Test RE 1.050810675946136\n",
      "23 Train Loss 6.9035854 Test MSE 4.743585259733622 Test RE 1.041025615041098\n",
      "24 Train Loss 6.337558 Test MSE 4.628375605469136 Test RE 1.0283059724936425\n",
      "25 Train Loss 5.2894063 Test MSE 3.9767878486116244 Test RE 0.9531785747218762\n",
      "26 Train Loss 4.873824 Test MSE 3.863860879323781 Test RE 0.9395476286785773\n",
      "27 Train Loss 4.3513994 Test MSE 3.3986471062658423 Test RE 0.8811728277151215\n",
      "28 Train Loss 3.844417 Test MSE 3.0604635641502034 Test RE 0.8361836413680451\n",
      "29 Train Loss 3.5737023 Test MSE 2.978151883379271 Test RE 0.8248623509097734\n",
      "30 Train Loss 3.2226348 Test MSE 2.7365362054482993 Test RE 0.7906943936503198\n",
      "31 Train Loss 2.9588935 Test MSE 2.474584118345244 Test RE 0.7518984177928448\n",
      "32 Train Loss 2.6925144 Test MSE 2.3998634040264295 Test RE 0.7404595211651551\n",
      "33 Train Loss 2.5750666 Test MSE 2.3068238932362743 Test RE 0.7259643274481947\n",
      "34 Train Loss 2.431055 Test MSE 2.1896917944752388 Test RE 0.7072933188831043\n",
      "35 Train Loss 2.2924004 Test MSE 2.1554185016209475 Test RE 0.7017361720829681\n",
      "36 Train Loss 2.141618 Test MSE 2.109822302855173 Test RE 0.6942741569211665\n",
      "37 Train Loss 2.0152395 Test MSE 1.8642215190907028 Test RE 0.6526146500210385\n",
      "38 Train Loss 1.7891914 Test MSE 1.4838852412440209 Test RE 0.5822482849340412\n",
      "39 Train Loss 1.6459562 Test MSE 1.3625124789349117 Test RE 0.5579281891558456\n",
      "40 Train Loss 1.5221525 Test MSE 1.2592602576701917 Test RE 0.5363716423406376\n",
      "41 Train Loss 1.4075024 Test MSE 1.2447048395964455 Test RE 0.5332627516993793\n",
      "42 Train Loss 1.2954928 Test MSE 1.139246714270573 Test RE 0.510172391509336\n",
      "43 Train Loss 1.1619022 Test MSE 1.034671695682022 Test RE 0.4861937197200066\n",
      "44 Train Loss 1.1110811 Test MSE 1.0529234527479983 Test RE 0.49046323677155196\n",
      "45 Train Loss 1.0453131 Test MSE 1.003138503355807 Test RE 0.4787276483645029\n",
      "46 Train Loss 1.0085433 Test MSE 0.9517337845810016 Test RE 0.4663004164820759\n",
      "47 Train Loss 0.9619325 Test MSE 0.9165676479171693 Test RE 0.4576045375582407\n",
      "48 Train Loss 0.9083666 Test MSE 0.8666229687178074 Test RE 0.44496224009069385\n",
      "49 Train Loss 0.85475844 Test MSE 0.7969138716521832 Test RE 0.4266912662222506\n",
      "50 Train Loss 0.79241735 Test MSE 0.7250633758553338 Test RE 0.40700153265014843\n",
      "51 Train Loss 0.73254853 Test MSE 0.6478107928217375 Test RE 0.38470882591317246\n",
      "52 Train Loss 0.6676473 Test MSE 0.5601051765621989 Test RE 0.35771969642857704\n",
      "53 Train Loss 0.617479 Test MSE 0.5479249264605708 Test RE 0.35380876637329445\n",
      "54 Train Loss 0.5502054 Test MSE 0.48473324738170825 Test RE 0.33278172190302646\n",
      "55 Train Loss 0.5176212 Test MSE 0.46137193420070394 Test RE 0.32466363474462734\n",
      "56 Train Loss 0.49935284 Test MSE 0.45441042219307826 Test RE 0.3222049455077923\n",
      "57 Train Loss 0.46877655 Test MSE 0.3941757290492417 Test RE 0.3000910202571701\n",
      "58 Train Loss 0.42674524 Test MSE 0.3526095063776884 Test RE 0.2838278900077587\n",
      "59 Train Loss 0.40766466 Test MSE 0.36523662340789853 Test RE 0.28886519661145205\n",
      "60 Train Loss 0.3905102 Test MSE 0.3248144228807854 Test RE 0.272411672656326\n",
      "61 Train Loss 0.37904438 Test MSE 0.29674249465198776 Test RE 0.26037419003979473\n",
      "62 Train Loss 0.3583934 Test MSE 0.30419419324319197 Test RE 0.26362313482597943\n",
      "63 Train Loss 0.34047988 Test MSE 0.26365510092573746 Test RE 0.24542915339735766\n",
      "64 Train Loss 0.3241999 Test MSE 0.21242946578062916 Test RE 0.2203004776356363\n",
      "65 Train Loss 0.31683648 Test MSE 0.2133621203844542 Test RE 0.22078355381587272\n",
      "66 Train Loss 0.3050866 Test MSE 0.19033793441080532 Test RE 0.20853105299950705\n",
      "67 Train Loss 0.29559916 Test MSE 0.17138431628885406 Test RE 0.1978762167691021\n",
      "68 Train Loss 0.27318978 Test MSE 0.15356503416622075 Test RE 0.18730709600113055\n",
      "69 Train Loss 0.24076578 Test MSE 0.12338927214778149 Test RE 0.1678984788535528\n",
      "70 Train Loss 0.2163544 Test MSE 0.09783573411120808 Test RE 0.14950537764303434\n",
      "71 Train Loss 0.20282951 Test MSE 0.09358907804499374 Test RE 0.146224668272707\n",
      "72 Train Loss 0.19210222 Test MSE 0.08446215697376873 Test RE 0.13891180174949103\n",
      "73 Train Loss 0.1791556 Test MSE 0.08608229764316486 Test RE 0.14023776621174117\n",
      "74 Train Loss 0.173397 Test MSE 0.0835922987655505 Test RE 0.13819463859804404\n",
      "75 Train Loss 0.16948786 Test MSE 0.07749181739233191 Test RE 0.13305646573632549\n",
      "76 Train Loss 0.1617476 Test MSE 0.0815261204490928 Test RE 0.1364760512836238\n",
      "77 Train Loss 0.15522672 Test MSE 0.0844382016064759 Test RE 0.13889210109693628\n",
      "78 Train Loss 0.14867212 Test MSE 0.0748170302268681 Test RE 0.130739943509932\n",
      "79 Train Loss 0.14464396 Test MSE 0.07824584326238523 Test RE 0.13370224449825055\n",
      "80 Train Loss 0.13974683 Test MSE 0.07956698097522473 Test RE 0.13482626390878158\n",
      "81 Train Loss 0.13543826 Test MSE 0.07632307005380201 Test RE 0.13204926126358116\n",
      "82 Train Loss 0.1299304 Test MSE 0.07202409318764423 Test RE 0.12827645806564408\n",
      "83 Train Loss 0.12676562 Test MSE 0.06826640847429004 Test RE 0.12488537659155799\n",
      "84 Train Loss 0.121883176 Test MSE 0.06438706409793689 Test RE 0.12128507794316809\n",
      "85 Train Loss 0.118260756 Test MSE 0.06066391979495305 Test RE 0.11772624573330805\n",
      "86 Train Loss 0.11425689 Test MSE 0.05241511652420477 Test RE 0.10942998459573852\n",
      "87 Train Loss 0.109287634 Test MSE 0.04916602493488867 Test RE 0.1059840737926382\n",
      "88 Train Loss 0.10183631 Test MSE 0.046712725840320296 Test RE 0.10330602843076075\n",
      "89 Train Loss 0.09933772 Test MSE 0.04339958794428407 Test RE 0.09957512570698594\n",
      "90 Train Loss 0.09586609 Test MSE 0.041167726010248214 Test RE 0.09698096461981855\n",
      "91 Train Loss 0.09369878 Test MSE 0.040206737727807855 Test RE 0.0958423555044468\n",
      "92 Train Loss 0.08969101 Test MSE 0.03456902576572455 Test RE 0.08886927361758677\n",
      "93 Train Loss 0.084797345 Test MSE 0.03186891504267434 Test RE 0.08532802616287263\n",
      "94 Train Loss 0.082133 Test MSE 0.030963982008937786 Test RE 0.08410783683116888\n",
      "95 Train Loss 0.078130335 Test MSE 0.025020168412199107 Test RE 0.07560546252650238\n",
      "96 Train Loss 0.07601583 Test MSE 0.02013673255589478 Test RE 0.06782699261936936\n",
      "97 Train Loss 0.073028415 Test MSE 0.016573669476388393 Test RE 0.06153431878048636\n",
      "98 Train Loss 0.07099672 Test MSE 0.017557065257086113 Test RE 0.0633335777048277\n",
      "99 Train Loss 0.06937969 Test MSE 0.01733228258544423 Test RE 0.06292684254261112\n",
      "Training time: 195.82\n",
      "8\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.54926 Test MSE 4.980180806809823 Test RE 1.0666713130889567\n",
      "1 Train Loss 57.834568 Test MSE 6.441306778139887 Test RE 1.2130956687157821\n",
      "2 Train Loss 48.46357 Test MSE 6.9182019858763715 Test RE 1.257200888015543\n",
      "3 Train Loss 37.160236 Test MSE 7.687269731573749 Test RE 1.3252387318634078\n",
      "4 Train Loss 30.791658 Test MSE 8.378894698923949 Test RE 1.3835709235793643\n",
      "5 Train Loss 29.473 Test MSE 8.351532185586207 Test RE 1.3813099489830274\n",
      "6 Train Loss 27.921831 Test MSE 8.320255663832585 Test RE 1.378721017151427\n",
      "7 Train Loss 26.498234 Test MSE 8.530785291717551 Test RE 1.3960551209287182\n",
      "8 Train Loss 25.962723 Test MSE 8.473458610365283 Test RE 1.3913564847564093\n",
      "9 Train Loss 24.684296 Test MSE 8.782084585800648 Test RE 1.4164683278195487\n",
      "10 Train Loss 23.678116 Test MSE 9.337545223017845 Test RE 1.4605768719712375\n",
      "11 Train Loss 23.01009 Test MSE 9.529215407773966 Test RE 1.475491229755327\n",
      "12 Train Loss 22.477928 Test MSE 9.41991674801893 Test RE 1.46700499497462\n",
      "13 Train Loss 22.008995 Test MSE 9.350811881263132 Test RE 1.4616140876413068\n",
      "14 Train Loss 21.59861 Test MSE 9.567169623740647 Test RE 1.47842670025396\n",
      "15 Train Loss 21.120567 Test MSE 9.525578975564446 Test RE 1.4752096726919401\n",
      "16 Train Loss 20.332031 Test MSE 9.24996181359691 Test RE 1.4537108444155877\n",
      "17 Train Loss 19.76226 Test MSE 9.230623502886676 Test RE 1.4521904586509389\n",
      "18 Train Loss 19.364235 Test MSE 9.253201310030706 Test RE 1.4539653794582483\n",
      "19 Train Loss 18.836956 Test MSE 9.01816671903762 Test RE 1.4353809900437386\n",
      "20 Train Loss 18.159414 Test MSE 9.097131135662758 Test RE 1.4416514989003728\n",
      "21 Train Loss 17.784668 Test MSE 8.986670869778205 Test RE 1.4328722714555762\n",
      "22 Train Loss 17.35658 Test MSE 8.930854106315165 Test RE 1.428415511633152\n",
      "23 Train Loss 16.858055 Test MSE 8.824232846000099 Test RE 1.419863319873947\n",
      "24 Train Loss 16.617455 Test MSE 8.863564794255481 Test RE 1.4230241554843726\n",
      "25 Train Loss 16.201874 Test MSE 8.92982884671502 Test RE 1.4283335184255463\n",
      "26 Train Loss 15.945548 Test MSE 8.861416146960602 Test RE 1.4228516649348524\n",
      "27 Train Loss 15.685605 Test MSE 8.859510600484876 Test RE 1.4226986726983195\n",
      "28 Train Loss 15.369858 Test MSE 8.814248687259466 Test RE 1.4190598419295202\n",
      "29 Train Loss 15.077221 Test MSE 8.747205748241964 Test RE 1.413652713841333\n",
      "30 Train Loss 14.785292 Test MSE 8.909710876176332 Test RE 1.4267236681850035\n",
      "31 Train Loss 14.313051 Test MSE 8.837031483794314 Test RE 1.420892629286611\n",
      "32 Train Loss 13.816179 Test MSE 8.920927274999096 Test RE 1.4276214340400475\n",
      "33 Train Loss 13.466415 Test MSE 8.733816140133637 Test RE 1.412570339341125\n",
      "34 Train Loss 12.843269 Test MSE 8.815913659864869 Test RE 1.419193862665768\n",
      "35 Train Loss 12.4571085 Test MSE 8.764141179950265 Test RE 1.4150205359181918\n",
      "36 Train Loss 12.109485 Test MSE 8.713918158533417 Test RE 1.4109603142714184\n",
      "37 Train Loss 11.307066 Test MSE 8.527200034720344 Test RE 1.395761728103835\n",
      "38 Train Loss 10.802777 Test MSE 8.166161636871529 Test RE 1.365894153869016\n",
      "39 Train Loss 9.94733 Test MSE 7.23171060796578 Test RE 1.2853712434941542\n",
      "40 Train Loss 9.168133 Test MSE 6.308157372112755 Test RE 1.200492137221234\n",
      "41 Train Loss 7.565792 Test MSE 5.282501566180989 Test RE 1.098570360431227\n",
      "42 Train Loss 5.814307 Test MSE 4.535607200153285 Test RE 1.017948433327655\n",
      "43 Train Loss 5.039622 Test MSE 4.275814901414141 Test RE 0.988365343105061\n",
      "44 Train Loss 4.081992 Test MSE 4.09483971417035 Test RE 0.9672227736669674\n",
      "45 Train Loss 3.5075226 Test MSE 3.8726218772323575 Test RE 0.9406122004051374\n",
      "46 Train Loss 3.0686145 Test MSE 3.5132813187577137 Test RE 0.8959102874624941\n",
      "47 Train Loss 2.7175863 Test MSE 3.278870111873185 Test RE 0.8655061671536028\n",
      "48 Train Loss 2.4461071 Test MSE 3.283726031346514 Test RE 0.8661468258546153\n",
      "49 Train Loss 2.2031233 Test MSE 3.3252440207847154 Test RE 0.8716052166636821\n",
      "50 Train Loss 1.922505 Test MSE 3.1273490638447163 Test RE 0.8452715259827644\n",
      "51 Train Loss 1.7601979 Test MSE 3.12382265828227 Test RE 0.8447948265633919\n",
      "52 Train Loss 1.6589234 Test MSE 3.1778559608863115 Test RE 0.8520697837454492\n",
      "53 Train Loss 1.5757264 Test MSE 3.122015577037633 Test RE 0.8445504410943984\n",
      "54 Train Loss 1.5014948 Test MSE 3.091400450588173 Test RE 0.8403993217328392\n",
      "55 Train Loss 1.4270564 Test MSE 3.0635331285579657 Test RE 0.836602871367785\n",
      "56 Train Loss 1.3750124 Test MSE 3.106234675910015 Test RE 0.8424132557732611\n",
      "57 Train Loss 1.2985702 Test MSE 3.1737285008489335 Test RE 0.851516261698511\n",
      "58 Train Loss 1.25017 Test MSE 3.162268388334564 Test RE 0.8499774883919868\n",
      "59 Train Loss 1.1885493 Test MSE 3.0938858654304338 Test RE 0.8407370847183859\n",
      "60 Train Loss 1.1529999 Test MSE 3.087443035082195 Test RE 0.8398612364192797\n",
      "61 Train Loss 1.134018 Test MSE 3.062663440333051 Test RE 0.8364841138286458\n",
      "62 Train Loss 1.1176221 Test MSE 3.012498103221177 Test RE 0.8296051728401878\n",
      "63 Train Loss 1.0986017 Test MSE 2.9892162704521894 Test RE 0.8263931887665048\n",
      "64 Train Loss 1.066889 Test MSE 2.9886852071691887 Test RE 0.8263197771204162\n",
      "65 Train Loss 1.0451697 Test MSE 3.017774665062425 Test RE 0.8303314053026493\n",
      "66 Train Loss 1.0189778 Test MSE 3.0063552801698483 Test RE 0.8287589120051304\n",
      "67 Train Loss 0.99332094 Test MSE 2.9698760239507465 Test RE 0.8237154661702656\n",
      "68 Train Loss 0.9654119 Test MSE 2.97079206167571 Test RE 0.8238424910460954\n",
      "69 Train Loss 0.94543064 Test MSE 2.969912243941449 Test RE 0.8237204890862592\n",
      "70 Train Loss 0.934839 Test MSE 2.963561748577602 Test RE 0.822839346469837\n",
      "71 Train Loss 0.9152906 Test MSE 2.972583449890045 Test RE 0.8240908422071906\n",
      "72 Train Loss 0.89754665 Test MSE 2.967955928749574 Test RE 0.8234491473372465\n",
      "73 Train Loss 0.88500106 Test MSE 2.9606050771019325 Test RE 0.8224287809179092\n",
      "74 Train Loss 0.87066555 Test MSE 2.9624337004903687 Test RE 0.8226827290658434\n",
      "75 Train Loss 0.8578848 Test MSE 2.9508322771934723 Test RE 0.8210702620578997\n",
      "76 Train Loss 0.83572197 Test MSE 2.9533772699945944 Test RE 0.8214242583796049\n",
      "77 Train Loss 0.81189716 Test MSE 2.980076226713782 Test RE 0.8251288017321249\n",
      "78 Train Loss 0.787495 Test MSE 2.9668526859588384 Test RE 0.8232960876564439\n",
      "79 Train Loss 0.77770716 Test MSE 2.976407064806415 Test RE 0.8246206832463553\n",
      "80 Train Loss 0.7710464 Test MSE 2.9763615447956693 Test RE 0.8246143775084197\n",
      "81 Train Loss 0.7600974 Test MSE 2.969340735427628 Test RE 0.8236412298550759\n",
      "82 Train Loss 0.75270665 Test MSE 2.984898275094176 Test RE 0.8257961005654624\n",
      "83 Train Loss 0.7470604 Test MSE 2.9864900201113667 Test RE 0.8260162557458169\n",
      "84 Train Loss 0.7356478 Test MSE 2.981596287987758 Test RE 0.8253392135375823\n",
      "85 Train Loss 0.7227774 Test MSE 3.006632784328445 Test RE 0.8287971607675267\n",
      "86 Train Loss 0.71760374 Test MSE 3.000441850614282 Test RE 0.8279434362373274\n",
      "87 Train Loss 0.70960164 Test MSE 2.977259818537612 Test RE 0.8247388035150226\n",
      "88 Train Loss 0.7018513 Test MSE 2.976723117906392 Test RE 0.8246644637171173\n",
      "89 Train Loss 0.6924362 Test MSE 2.9880717181643184 Test RE 0.8262349632172843\n",
      "90 Train Loss 0.68566227 Test MSE 2.999543166200422 Test RE 0.8278194352365063\n",
      "91 Train Loss 0.6797312 Test MSE 3.0198935720173576 Test RE 0.8306228595125948\n",
      "92 Train Loss 0.6726952 Test MSE 3.0137002556674655 Test RE 0.8297706853779693\n",
      "93 Train Loss 0.66431856 Test MSE 3.030023728359999 Test RE 0.8320148447956298\n",
      "94 Train Loss 0.6559683 Test MSE 3.038918586204609 Test RE 0.8332351702944304\n",
      "95 Train Loss 0.65483606 Test MSE 3.0358635569732733 Test RE 0.8328162387214698\n",
      "96 Train Loss 0.6534108 Test MSE 3.0413092563998774 Test RE 0.8335628524645481\n",
      "97 Train Loss 0.6482926 Test MSE 3.0653555767015157 Test RE 0.8368516753799085\n",
      "98 Train Loss 0.6405957 Test MSE 3.0668330786016065 Test RE 0.8370533324068277\n",
      "99 Train Loss 0.63440883 Test MSE 3.0563670327481294 Test RE 0.8356238242829788\n",
      "Training time: 195.88\n",
      "9\n",
      "KG_rowdy_tune53\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.684082 Test MSE 6.374502970305699 Test RE 1.2067886701860056\n",
      "1 Train Loss 54.42515 Test MSE 8.469724394969637 Test RE 1.3910498686747423\n",
      "2 Train Loss 47.628105 Test MSE 8.584218158260462 Test RE 1.4004204156444398\n",
      "3 Train Loss 38.83038 Test MSE 7.749989125404259 Test RE 1.330633971231442\n",
      "4 Train Loss 32.982433 Test MSE 7.952692893546196 Test RE 1.347923255429363\n",
      "5 Train Loss 31.36857 Test MSE 8.589057841039423 Test RE 1.4008151304240148\n",
      "6 Train Loss 29.961115 Test MSE 8.614713962958767 Test RE 1.4029057372171676\n",
      "7 Train Loss 28.788528 Test MSE 8.757738590120404 Test RE 1.4145035741785525\n",
      "8 Train Loss 27.442554 Test MSE 9.12469558916721 Test RE 1.4438339605296768\n",
      "9 Train Loss 26.57256 Test MSE 9.061342868124221 Test RE 1.4388129637649005\n",
      "10 Train Loss 25.354095 Test MSE 8.974858454260584 Test RE 1.4319302514074916\n",
      "11 Train Loss 24.479782 Test MSE 8.893209150878995 Test RE 1.4254018344185448\n",
      "12 Train Loss 23.471272 Test MSE 9.036822216979646 Test RE 1.4368648788289202\n",
      "13 Train Loss 22.86356 Test MSE 8.791079745363943 Test RE 1.4171935598272014\n",
      "14 Train Loss 21.662476 Test MSE 8.832150326080951 Test RE 1.4205001581825414\n",
      "15 Train Loss 21.308723 Test MSE 8.667432641224918 Test RE 1.4071918070081573\n",
      "16 Train Loss 20.755182 Test MSE 8.821037597076804 Test RE 1.4196062308106714\n",
      "17 Train Loss 19.88583 Test MSE 8.605921584371789 Test RE 1.4021896352467487\n",
      "18 Train Loss 19.364235 Test MSE 8.615338131173052 Test RE 1.4029565591778346\n",
      "19 Train Loss 18.5465 Test MSE 8.5034211131244 Test RE 1.3938142612296214\n",
      "20 Train Loss 17.082996 Test MSE 7.581777801176013 Test RE 1.3161142351356896\n",
      "21 Train Loss 16.179384 Test MSE 7.509280405112099 Test RE 1.3098067406975928\n",
      "22 Train Loss 14.8491745 Test MSE 7.7390882325406904 Test RE 1.3296978278174814\n",
      "23 Train Loss 14.359772 Test MSE 7.709183180839429 Test RE 1.3271262606163765\n",
      "24 Train Loss 13.944522 Test MSE 7.509836444986543 Test RE 1.3098552334462086\n",
      "25 Train Loss 13.569008 Test MSE 7.584166171689527 Test RE 1.3163215163961868\n",
      "26 Train Loss 13.204639 Test MSE 7.573990977806817 Test RE 1.315438207554735\n",
      "27 Train Loss 12.939156 Test MSE 7.513477451537135 Test RE 1.3101727246190564\n",
      "28 Train Loss 12.535337 Test MSE 7.510621234596308 Test RE 1.3099236726146626\n",
      "29 Train Loss 12.21736 Test MSE 7.313606492438229 Test RE 1.2926288808553872\n",
      "30 Train Loss 11.900301 Test MSE 7.252274856197726 Test RE 1.287197500812734\n",
      "31 Train Loss 11.538784 Test MSE 7.2257267709979836 Test RE 1.2848393469553114\n",
      "32 Train Loss 11.168948 Test MSE 7.078789912062106 Test RE 1.271708493690647\n",
      "33 Train Loss 10.542772 Test MSE 7.117438463588889 Test RE 1.275175384775956\n",
      "34 Train Loss 10.328037 Test MSE 7.061086545106144 Test RE 1.2701172884092775\n",
      "35 Train Loss 9.744595 Test MSE 6.949440190934227 Test RE 1.2600360514284072\n",
      "36 Train Loss 9.195239 Test MSE 7.008057384597661 Test RE 1.2653389737052734\n",
      "37 Train Loss 8.720062 Test MSE 6.896475961727329 Test RE 1.255225269570765\n",
      "38 Train Loss 8.006492 Test MSE 6.627087998937324 Test RE 1.2304654649651714\n",
      "39 Train Loss 7.553259 Test MSE 6.486341725223328 Test RE 1.2173290132016663\n",
      "40 Train Loss 7.050898 Test MSE 6.162798311508263 Test RE 1.1865800376351052\n",
      "41 Train Loss 6.771636 Test MSE 6.025329809102379 Test RE 1.173271367380092\n",
      "42 Train Loss 6.4204473 Test MSE 5.940164836198126 Test RE 1.1649500612996522\n",
      "43 Train Loss 6.1099463 Test MSE 5.8316299047587545 Test RE 1.1542583832393738\n",
      "44 Train Loss 5.7253633 Test MSE 5.7430066701334646 Test RE 1.1454541779542107\n",
      "45 Train Loss 5.505253 Test MSE 5.766666834408257 Test RE 1.1478112862992342\n",
      "46 Train Loss 5.262176 Test MSE 5.818201237484656 Test RE 1.1529286447714264\n",
      "47 Train Loss 5.013464 Test MSE 5.581122698299666 Test RE 1.1291947374349534\n",
      "48 Train Loss 4.7622547 Test MSE 5.5078104161158254 Test RE 1.121753806174999\n",
      "49 Train Loss 4.656289 Test MSE 5.63497036524 Test RE 1.1346289973070283\n",
      "50 Train Loss 4.5357738 Test MSE 5.543576560310905 Test RE 1.1253900865404771\n",
      "51 Train Loss 4.257845 Test MSE 5.36340675922834 Test RE 1.106951078582462\n",
      "52 Train Loss 4.163063 Test MSE 5.385435797932474 Test RE 1.1092220307433216\n",
      "53 Train Loss 3.9632955 Test MSE 5.31254115087577 Test RE 1.1016895090412604\n",
      "54 Train Loss 3.7373435 Test MSE 5.262917048308769 Test RE 1.0965320317185117\n",
      "55 Train Loss 3.5625467 Test MSE 5.335334239521608 Test RE 1.1040503406473088\n",
      "56 Train Loss 3.2842336 Test MSE 5.387015878828567 Test RE 1.1093847410668451\n",
      "57 Train Loss 3.203524 Test MSE 5.323263854870021 Test RE 1.1028007602634136\n",
      "58 Train Loss 3.11363 Test MSE 5.381759458673212 Test RE 1.1088433638327186\n",
      "59 Train Loss 3.0521448 Test MSE 5.348327903817262 Test RE 1.1053939243028925\n",
      "60 Train Loss 2.953415 Test MSE 5.309144274039689 Test RE 1.1013372386425218\n",
      "61 Train Loss 2.8212469 Test MSE 5.269046691916116 Test RE 1.097170403420994\n",
      "62 Train Loss 2.7349918 Test MSE 5.322119151520555 Test RE 1.1026821819221324\n",
      "63 Train Loss 2.6860325 Test MSE 5.335085858374873 Test RE 1.1040246413687815\n",
      "64 Train Loss 2.6419897 Test MSE 5.283068031063158 Test RE 1.0986292610145845\n",
      "65 Train Loss 2.6129434 Test MSE 5.267813871719202 Test RE 1.0970420412104962\n",
      "66 Train Loss 2.5594845 Test MSE 5.275605607225426 Test RE 1.097853070523316\n",
      "67 Train Loss 2.4808705 Test MSE 5.333940853574363 Test RE 1.1039061632992226\n",
      "68 Train Loss 2.4386933 Test MSE 5.344447353254377 Test RE 1.1049928348916402\n",
      "69 Train Loss 2.3891845 Test MSE 5.388706194601507 Test RE 1.1095587765154464\n",
      "70 Train Loss 2.3533537 Test MSE 5.402748808564882 Test RE 1.111003554480375\n",
      "71 Train Loss 2.320463 Test MSE 5.363152609151099 Test RE 1.1069248513124055\n",
      "72 Train Loss 2.302446 Test MSE 5.34413416326522 Test RE 1.1049604575716576\n",
      "73 Train Loss 2.266294 Test MSE 5.388827311614094 Test RE 1.1095712457134628\n",
      "74 Train Loss 2.2065475 Test MSE 5.399168451985098 Test RE 1.1106353670763567\n",
      "75 Train Loss 2.1774242 Test MSE 5.441437134601205 Test RE 1.114974328893049\n",
      "76 Train Loss 2.1489625 Test MSE 5.423726042046545 Test RE 1.1131583097058808\n",
      "77 Train Loss 2.1128018 Test MSE 5.338259522746541 Test RE 1.1043529662396216\n",
      "78 Train Loss 2.0630016 Test MSE 5.370708199882173 Test RE 1.107704292829518\n",
      "79 Train Loss 2.033076 Test MSE 5.382936124102464 Test RE 1.108964575710886\n",
      "80 Train Loss 2.010894 Test MSE 5.364181045293225 Test RE 1.107030977973069\n",
      "81 Train Loss 1.9945285 Test MSE 5.3686280386978025 Test RE 1.1074897562595836\n",
      "82 Train Loss 1.9726173 Test MSE 5.344195908026923 Test RE 1.1049668407687288\n",
      "83 Train Loss 1.9554243 Test MSE 5.365366348219483 Test RE 1.1071532794547325\n",
      "84 Train Loss 1.9253291 Test MSE 5.399298565580922 Test RE 1.1106487494973658\n",
      "85 Train Loss 1.8902748 Test MSE 5.36079106797517 Test RE 1.1066811200009912\n",
      "86 Train Loss 1.867007 Test MSE 5.354965398692632 Test RE 1.1060796312805752\n",
      "87 Train Loss 1.8442394 Test MSE 5.348684668392168 Test RE 1.1054307917897221\n",
      "88 Train Loss 1.824816 Test MSE 5.322787299912382 Test RE 1.1027513961001347\n",
      "89 Train Loss 1.79723 Test MSE 5.2849131722134794 Test RE 1.0988210954828461\n",
      "90 Train Loss 1.7653148 Test MSE 5.314610698847485 Test RE 1.1019040746529754\n",
      "91 Train Loss 1.7432469 Test MSE 5.3404199798600684 Test RE 1.10457641602313\n",
      "92 Train Loss 1.7169771 Test MSE 5.346301315380343 Test RE 1.1051844765242729\n",
      "93 Train Loss 1.6896799 Test MSE 5.364361559902595 Test RE 1.1070496046358982\n",
      "94 Train Loss 1.6690505 Test MSE 5.369320448839287 Test RE 1.1075611723094108\n",
      "95 Train Loss 1.6472744 Test MSE 5.392936533668705 Test RE 1.1099942139680394\n",
      "96 Train Loss 1.6296864 Test MSE 5.4156113959773435 Test RE 1.1123252784304882\n",
      "97 Train Loss 1.6117098 Test MSE 5.421081436735018 Test RE 1.1128868889796406\n",
      "98 Train Loss 1.6013243 Test MSE 5.4249714808744915 Test RE 1.1132861084729657\n",
      "99 Train Loss 1.5914922 Test MSE 5.422355426671337 Test RE 1.1130176491817023\n",
      "Training time: 198.19\n",
      "0\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 74.88264 Test MSE 4.327880704723616 Test RE 0.9943647056235285\n",
      "1 Train Loss 70.318855 Test MSE 4.421163416872682 Test RE 1.0050237947879757\n",
      "2 Train Loss 60.717846 Test MSE 4.118526779677684 Test RE 0.970016244710844\n",
      "3 Train Loss 45.314102 Test MSE 6.174691610410975 Test RE 1.1877244486814738\n",
      "4 Train Loss 35.404858 Test MSE 5.573210256915934 Test RE 1.1283940153750134\n",
      "5 Train Loss 29.806849 Test MSE 5.929138161654967 Test RE 1.1638683158989003\n",
      "6 Train Loss 25.275658 Test MSE 5.531862508126703 Test RE 1.1242004349172687\n",
      "7 Train Loss 21.683073 Test MSE 5.176145057183046 Test RE 1.0874549627371166\n",
      "8 Train Loss 18.842464 Test MSE 5.01910845196543 Test RE 1.070832023140987\n",
      "9 Train Loss 16.907516 Test MSE 4.675304191267687 Test RE 1.0335059867353062\n",
      "10 Train Loss 14.857822 Test MSE 4.9445544346843295 Test RE 1.062849179195148\n",
      "11 Train Loss 13.73378 Test MSE 5.018933083734275 Test RE 1.0708133154800608\n",
      "12 Train Loss 12.729499 Test MSE 5.196491092850855 Test RE 1.0895901132780306\n",
      "13 Train Loss 11.815495 Test MSE 5.103130969461718 Test RE 1.079757967805215\n",
      "14 Train Loss 10.682899 Test MSE 5.037583666968061 Test RE 1.072801066001\n",
      "15 Train Loss 9.995487 Test MSE 5.129582060713503 Test RE 1.0825527091610825\n",
      "16 Train Loss 8.934218 Test MSE 4.91293655046501 Test RE 1.0594455422315627\n",
      "17 Train Loss 8.417591 Test MSE 5.082255020516083 Test RE 1.077547161112516\n",
      "18 Train Loss 7.8402386 Test MSE 4.994142976257487 Test RE 1.0681654979855515\n",
      "19 Train Loss 7.451414 Test MSE 4.959621084712763 Test RE 1.0644672619320041\n",
      "20 Train Loss 7.008753 Test MSE 4.933421482312533 Test RE 1.0616519714962163\n",
      "21 Train Loss 6.271676 Test MSE 4.496976156713684 Test RE 1.013604086343892\n",
      "22 Train Loss 5.7079225 Test MSE 4.406909285796487 Test RE 1.0034023543439667\n",
      "23 Train Loss 5.187234 Test MSE 4.439192758792512 Test RE 1.0070709349192077\n",
      "24 Train Loss 4.7140384 Test MSE 4.3874651208554925 Test RE 1.0011863013143856\n",
      "25 Train Loss 4.482407 Test MSE 4.307994907620677 Test RE 0.9920776160970171\n",
      "26 Train Loss 4.1572976 Test MSE 4.196514628798635 Test RE 0.9791572207965272\n",
      "27 Train Loss 3.7518125 Test MSE 4.2247940873903405 Test RE 0.9824508520198821\n",
      "28 Train Loss 3.5247514 Test MSE 4.130772519897845 Test RE 0.9714572636666465\n",
      "29 Train Loss 3.3235242 Test MSE 3.9528884221483422 Test RE 0.9503100849498782\n",
      "30 Train Loss 3.0673845 Test MSE 3.915163810713696 Test RE 0.9457645451106431\n",
      "31 Train Loss 2.8805206 Test MSE 3.758300351962501 Test RE 0.9266245508157407\n",
      "32 Train Loss 2.708166 Test MSE 3.6907397957900425 Test RE 0.9182581130126506\n",
      "33 Train Loss 2.4964342 Test MSE 3.63737510425236 Test RE 0.9115953585369556\n",
      "34 Train Loss 2.377811 Test MSE 3.591638211306372 Test RE 0.9058459604327962\n",
      "35 Train Loss 2.3183322 Test MSE 3.5967543960452346 Test RE 0.9064909065216574\n",
      "36 Train Loss 2.2159092 Test MSE 3.5483239779675557 Test RE 0.9003672577082608\n",
      "37 Train Loss 2.116304 Test MSE 3.4542727486834717 Test RE 0.8883546367433849\n",
      "38 Train Loss 2.0448048 Test MSE 3.40731214659828 Test RE 0.8822954122802765\n",
      "39 Train Loss 1.9344524 Test MSE 3.3971525129950817 Test RE 0.8809790535808587\n",
      "40 Train Loss 1.8571016 Test MSE 3.352655240470443 Test RE 0.8751903260061598\n",
      "41 Train Loss 1.785813 Test MSE 3.2667955550161745 Test RE 0.8639110685365367\n",
      "42 Train Loss 1.7235062 Test MSE 3.24242184133269 Test RE 0.8606821942193185\n",
      "43 Train Loss 1.6267505 Test MSE 3.3336318148853556 Test RE 0.8727038188303529\n",
      "44 Train Loss 1.5871248 Test MSE 3.318983933774952 Test RE 0.8707843904487548\n",
      "45 Train Loss 1.5403125 Test MSE 3.3472065826211685 Test RE 0.8744788672767395\n",
      "46 Train Loss 1.5067159 Test MSE 3.376691191058583 Test RE 0.8783219428062248\n",
      "47 Train Loss 1.4682828 Test MSE 3.3220561302215765 Test RE 0.8711873152556476\n",
      "48 Train Loss 1.4425695 Test MSE 3.28347432212798 Test RE 0.8661136286090627\n",
      "49 Train Loss 1.417955 Test MSE 3.2839720951902196 Test RE 0.86617927731717\n",
      "50 Train Loss 1.3917196 Test MSE 3.2465432393730844 Test RE 0.8612290211891326\n",
      "51 Train Loss 1.3544354 Test MSE 3.250216077857963 Test RE 0.8617160408806372\n",
      "52 Train Loss 1.3282491 Test MSE 3.24414894016003 Test RE 0.860911387918865\n",
      "53 Train Loss 1.2896228 Test MSE 3.219616514066304 Test RE 0.8576500819219749\n",
      "54 Train Loss 1.2372724 Test MSE 3.2338989005842294 Test RE 0.859550267136488\n",
      "55 Train Loss 1.2022675 Test MSE 3.2475995977003884 Test RE 0.8613691228893711\n",
      "56 Train Loss 1.1639643 Test MSE 3.289279419891709 Test RE 0.8668789237613735\n",
      "57 Train Loss 1.1433234 Test MSE 3.3089162313352727 Test RE 0.8694626822629499\n",
      "58 Train Loss 1.1237111 Test MSE 3.2839388078648946 Test RE 0.8661748873796762\n",
      "59 Train Loss 1.1083496 Test MSE 3.268296406390029 Test RE 0.8641094974255246\n",
      "60 Train Loss 1.0910081 Test MSE 3.282651901823127 Test RE 0.8660051529558865\n",
      "61 Train Loss 1.0764167 Test MSE 3.261004070115625 Test RE 0.8631449435511614\n",
      "62 Train Loss 1.0523522 Test MSE 3.2548319224967366 Test RE 0.862327713471048\n",
      "63 Train Loss 1.0354187 Test MSE 3.2744505868034377 Test RE 0.8649226710259948\n",
      "64 Train Loss 1.0077956 Test MSE 3.2672672169243735 Test RE 0.8639734322855783\n",
      "65 Train Loss 0.9870725 Test MSE 3.2584538619132126 Test RE 0.8628073742338922\n",
      "66 Train Loss 0.9638972 Test MSE 3.2556506753955143 Test RE 0.862436165909888\n",
      "67 Train Loss 0.9537057 Test MSE 3.239331389376513 Test RE 0.8602719251040406\n",
      "68 Train Loss 0.94667524 Test MSE 3.2492914651493616 Test RE 0.861593462834108\n",
      "69 Train Loss 0.9306614 Test MSE 3.2667440955210654 Test RE 0.8639042642229928\n",
      "70 Train Loss 0.9175167 Test MSE 3.2547445754376123 Test RE 0.8623161426285418\n",
      "71 Train Loss 0.8953153 Test MSE 3.276488404558635 Test RE 0.8651917666479778\n",
      "72 Train Loss 0.882638 Test MSE 3.2651916099993703 Test RE 0.863698959153384\n",
      "73 Train Loss 0.87295854 Test MSE 3.2637950211280886 Test RE 0.8635142285910309\n",
      "74 Train Loss 0.8680447 Test MSE 3.2799379995977 Test RE 0.865647098043941\n",
      "75 Train Loss 0.858182 Test MSE 3.2617717599767593 Test RE 0.8632465362836523\n",
      "76 Train Loss 0.85163045 Test MSE 3.244683214617706 Test RE 0.8609822761606292\n",
      "77 Train Loss 0.8406677 Test MSE 3.2735105610110344 Test RE 0.8647985115741456\n",
      "78 Train Loss 0.8339008 Test MSE 3.2775385225150906 Test RE 0.8653304029731141\n",
      "79 Train Loss 0.83014053 Test MSE 3.2590377080429564 Test RE 0.8628846692032759\n",
      "80 Train Loss 0.82381666 Test MSE 3.2557669039208843 Test RE 0.86245156049597\n",
      "81 Train Loss 0.8185473 Test MSE 3.2711475031149884 Test RE 0.8644863180061856\n",
      "82 Train Loss 0.8101109 Test MSE 3.257260099029561 Test RE 0.8626493112665697\n",
      "83 Train Loss 0.8048542 Test MSE 3.2717315974782357 Test RE 0.8645634956703625\n",
      "84 Train Loss 0.7980188 Test MSE 3.2771095806821817 Test RE 0.8652737768569563\n",
      "85 Train Loss 0.78973895 Test MSE 3.237930612520649 Test RE 0.8600859022555101\n",
      "86 Train Loss 0.78441066 Test MSE 3.2088579734631137 Test RE 0.8562159384004528\n",
      "87 Train Loss 0.7794329 Test MSE 3.2063349656736735 Test RE 0.8558792665539174\n",
      "88 Train Loss 0.7736435 Test MSE 3.2163061608603383 Test RE 0.8572090581469622\n",
      "89 Train Loss 0.7694184 Test MSE 3.2179084426577766 Test RE 0.8574225514191955\n",
      "90 Train Loss 0.76660734 Test MSE 3.215547667370088 Test RE 0.8571079754459671\n",
      "91 Train Loss 0.7635007 Test MSE 3.2035384879393525 Test RE 0.8555059478831681\n",
      "92 Train Loss 0.7570711 Test MSE 3.183024201441399 Test RE 0.8527623753313208\n",
      "93 Train Loss 0.74762666 Test MSE 3.1691315100743216 Test RE 0.8508993483606642\n",
      "94 Train Loss 0.7436013 Test MSE 3.1624481798941515 Test RE 0.8500016508898223\n",
      "95 Train Loss 0.7348214 Test MSE 3.149296752310092 Test RE 0.8482323916348639\n",
      "96 Train Loss 0.72794235 Test MSE 3.132396498246593 Test RE 0.845953370638219\n",
      "97 Train Loss 0.72302383 Test MSE 3.10929713219403 Test RE 0.8428284237302475\n",
      "98 Train Loss 0.7152163 Test MSE 3.072449484467817 Test RE 0.837819445317049\n",
      "99 Train Loss 0.7087949 Test MSE 3.0534228210821306 Test RE 0.835221247275011\n",
      "Training time: 216.39\n",
      "1\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.86469 Test MSE 5.764267119522413 Test RE 1.1475724389267754\n",
      "1 Train Loss 54.41102 Test MSE 8.518519691338923 Test RE 1.3950511328369262\n",
      "2 Train Loss 46.273705 Test MSE 10.738819467764635 Test RE 1.5663410540158238\n",
      "3 Train Loss 42.939728 Test MSE 9.91424686395455 Test RE 1.5050049369792002\n",
      "4 Train Loss 40.09748 Test MSE 9.719830505087687 Test RE 1.4901754563319103\n",
      "5 Train Loss 37.720295 Test MSE 9.850931068541456 Test RE 1.5001914996412422\n",
      "6 Train Loss 36.169857 Test MSE 9.600283886293688 Test RE 1.480983084326621\n",
      "7 Train Loss 35.206367 Test MSE 9.401648927202954 Test RE 1.4655818406955805\n",
      "8 Train Loss 31.932901 Test MSE 9.372285680902662 Test RE 1.4632913970392036\n",
      "9 Train Loss 29.0983 Test MSE 9.492317030524987 Test RE 1.472631810862151\n",
      "10 Train Loss 26.911634 Test MSE 9.573479955440398 Test RE 1.4789141916112105\n",
      "11 Train Loss 25.385317 Test MSE 9.239014697155293 Test RE 1.4528503731271079\n",
      "12 Train Loss 24.193005 Test MSE 9.30642915871253 Test RE 1.4581412570541887\n",
      "13 Train Loss 23.634542 Test MSE 9.33137573809769 Test RE 1.460094277472533\n",
      "14 Train Loss 23.42042 Test MSE 9.36294097102294 Test RE 1.462561722112991\n",
      "15 Train Loss 23.04235 Test MSE 9.257063518758885 Test RE 1.4542687842878643\n",
      "16 Train Loss 22.710384 Test MSE 9.297885425441972 Test RE 1.457471782741312\n",
      "17 Train Loss 22.380629 Test MSE 9.426833221321807 Test RE 1.4675434625294699\n",
      "18 Train Loss 21.873032 Test MSE 9.44325910903193 Test RE 1.4688214745557173\n",
      "19 Train Loss 21.561417 Test MSE 9.214932772276535 Test RE 1.4509556763682185\n",
      "20 Train Loss 21.394993 Test MSE 9.265525184264842 Test RE 1.4549332890315774\n",
      "21 Train Loss 21.17707 Test MSE 9.242329366048105 Test RE 1.4531109683442849\n",
      "22 Train Loss 20.778395 Test MSE 9.130318121090092 Test RE 1.4442787289214225\n",
      "23 Train Loss 20.550812 Test MSE 8.934333138244291 Test RE 1.4286937055907605\n",
      "24 Train Loss 20.199287 Test MSE 8.825603180225174 Test RE 1.4199735624187935\n",
      "25 Train Loss 19.767376 Test MSE 8.693248893196937 Test RE 1.4092859338742296\n",
      "26 Train Loss 19.455608 Test MSE 8.46990282391781 Test RE 1.3910645209967163\n",
      "27 Train Loss 18.773396 Test MSE 8.19311289238513 Test RE 1.3681462669389493\n",
      "28 Train Loss 17.882736 Test MSE 7.726020817359495 Test RE 1.3285747591844952\n",
      "29 Train Loss 16.989569 Test MSE 7.759115984005667 Test RE 1.3314172584390216\n",
      "30 Train Loss 16.497017 Test MSE 7.582464775478752 Test RE 1.3161738594219061\n",
      "31 Train Loss 15.909201 Test MSE 7.507358575701458 Test RE 1.3096391223601522\n",
      "32 Train Loss 15.672655 Test MSE 7.477688680514545 Test RE 1.3070486424477183\n",
      "33 Train Loss 15.581224 Test MSE 7.458043909465208 Test RE 1.3053306277957994\n",
      "34 Train Loss 15.398727 Test MSE 7.438674374728339 Test RE 1.3036344669224935\n",
      "35 Train Loss 15.205126 Test MSE 7.439272237289725 Test RE 1.3036868538494155\n",
      "36 Train Loss 15.101156 Test MSE 7.411190655657693 Test RE 1.3012239649240023\n",
      "37 Train Loss 15.017295 Test MSE 7.421847557301483 Test RE 1.3021591745971954\n",
      "38 Train Loss 14.926144 Test MSE 7.385328341224444 Test RE 1.2989515855541502\n",
      "39 Train Loss 14.858238 Test MSE 7.307758362791057 Test RE 1.2921119694606165\n",
      "40 Train Loss 14.7969055 Test MSE 7.327060102723217 Test RE 1.2938172504351844\n",
      "41 Train Loss 14.716633 Test MSE 7.3211829929042995 Test RE 1.293298254319121\n",
      "42 Train Loss 14.665613 Test MSE 7.270417562654944 Test RE 1.2888065586365176\n",
      "43 Train Loss 14.602926 Test MSE 7.319328994867029 Test RE 1.2931344881458038\n",
      "44 Train Loss 14.555552 Test MSE 7.363281347226125 Test RE 1.2970112938519416\n",
      "45 Train Loss 14.495981 Test MSE 7.364378235144731 Test RE 1.2971078963700533\n",
      "46 Train Loss 14.454529 Test MSE 7.402760447197651 Test RE 1.3004836850531958\n",
      "47 Train Loss 14.378153 Test MSE 7.402762440484607 Test RE 1.3004838601390314\n",
      "48 Train Loss 14.282181 Test MSE 7.488736886818052 Test RE 1.3080138613586965\n",
      "49 Train Loss 14.201565 Test MSE 7.484809608776804 Test RE 1.3076708390404235\n",
      "50 Train Loss 14.1511965 Test MSE 7.459862038899962 Test RE 1.3054897255058686\n",
      "51 Train Loss 14.04909 Test MSE 7.531708127989787 Test RE 1.3117612609473153\n",
      "52 Train Loss 14.014132 Test MSE 7.57768223295151 Test RE 1.3157587140487235\n",
      "53 Train Loss 13.972488 Test MSE 7.578721546472483 Test RE 1.315848942095625\n",
      "54 Train Loss 13.927301 Test MSE 7.553926414990527 Test RE 1.313694662047295\n",
      "55 Train Loss 13.880079 Test MSE 7.586558439564267 Test RE 1.3165291031844506\n",
      "56 Train Loss 13.837803 Test MSE 7.622413670662884 Test RE 1.3196364945771526\n",
      "57 Train Loss 13.808152 Test MSE 7.623413611700567 Test RE 1.3197230495365952\n",
      "58 Train Loss 13.743347 Test MSE 7.615954190415929 Test RE 1.319077224710846\n",
      "59 Train Loss 13.705786 Test MSE 7.616637966510328 Test RE 1.3191364381203852\n",
      "60 Train Loss 13.63786 Test MSE 7.603343781278615 Test RE 1.3179847158526692\n",
      "61 Train Loss 13.533316 Test MSE 7.607523532583319 Test RE 1.3183469309263038\n",
      "62 Train Loss 13.491951 Test MSE 7.600899760669769 Test RE 1.3177728721693946\n",
      "63 Train Loss 13.427103 Test MSE 7.616051213072028 Test RE 1.3190856268076248\n",
      "64 Train Loss 13.346775 Test MSE 7.606117098451555 Test RE 1.3182250611865607\n",
      "65 Train Loss 13.280066 Test MSE 7.580218362186494 Test RE 1.315978877344068\n",
      "66 Train Loss 13.203243 Test MSE 7.497239145851239 Test RE 1.3087561706478699\n",
      "67 Train Loss 13.146942 Test MSE 7.470670497682931 Test RE 1.306435133374305\n",
      "68 Train Loss 13.086559 Test MSE 7.524233748311041 Test RE 1.3111102110628476\n",
      "69 Train Loss 12.971193 Test MSE 7.599008812867024 Test RE 1.3176089445559191\n",
      "70 Train Loss 12.917721 Test MSE 7.609063724347043 Test RE 1.3184803780536223\n",
      "71 Train Loss 12.843654 Test MSE 7.638650474697725 Test RE 1.3210412517687786\n",
      "72 Train Loss 12.790876 Test MSE 7.584981867845996 Test RE 1.3163923013386953\n",
      "73 Train Loss 12.697749 Test MSE 7.4994405960876875 Test RE 1.3089483047157584\n",
      "74 Train Loss 12.641087 Test MSE 7.532407842410098 Test RE 1.3118221924742586\n",
      "75 Train Loss 12.568336 Test MSE 7.475761790597019 Test RE 1.30688022803339\n",
      "76 Train Loss 12.493769 Test MSE 7.49175327722874 Test RE 1.3082772624707784\n",
      "77 Train Loss 12.441596 Test MSE 7.5430700094884 Test RE 1.3127503101202156\n",
      "78 Train Loss 12.386043 Test MSE 7.550856393521551 Test RE 1.3134276829656901\n",
      "79 Train Loss 12.248962 Test MSE 7.621880470289605 Test RE 1.319590338398325\n",
      "80 Train Loss 12.119282 Test MSE 7.618996540369875 Test RE 1.3193406647037356\n",
      "81 Train Loss 11.938877 Test MSE 7.546037970995799 Test RE 1.3130085477610145\n",
      "82 Train Loss 11.81813 Test MSE 7.489148430261488 Test RE 1.308049801807752\n",
      "83 Train Loss 11.654514 Test MSE 7.49114713942778 Test RE 1.3082243367860935\n",
      "84 Train Loss 11.470277 Test MSE 7.555699342541738 Test RE 1.3138488168991957\n",
      "85 Train Loss 11.237124 Test MSE 7.591828472594181 Test RE 1.3169862898935818\n",
      "86 Train Loss 11.001305 Test MSE 7.453735160477175 Test RE 1.304953507825411\n",
      "87 Train Loss 10.341195 Test MSE 7.140174990174008 Test RE 1.2772105229542219\n",
      "88 Train Loss 9.337268 Test MSE 6.6668678822994005 Test RE 1.2341529472057216\n",
      "89 Train Loss 8.814646 Test MSE 6.795373294779323 Test RE 1.2459904677511175\n",
      "90 Train Loss 8.507204 Test MSE 6.709244258647651 Test RE 1.2380690354876254\n",
      "91 Train Loss 8.104935 Test MSE 6.748634295650288 Test RE 1.2416980743074224\n",
      "92 Train Loss 7.8477163 Test MSE 6.764204817742012 Test RE 1.243129678648282\n",
      "93 Train Loss 7.5927486 Test MSE 6.716549682423848 Test RE 1.2387428936659632\n",
      "94 Train Loss 7.3989096 Test MSE 6.670013320045157 Test RE 1.2344440504316403\n",
      "95 Train Loss 7.2059174 Test MSE 6.5601790637909865 Test RE 1.2242381450476019\n",
      "96 Train Loss 7.10194 Test MSE 6.518420671448005 Test RE 1.220335520589491\n",
      "97 Train Loss 6.9249945 Test MSE 6.52678675833143 Test RE 1.2211183911478012\n",
      "98 Train Loss 6.837845 Test MSE 6.524022146037827 Test RE 1.220859743469451\n",
      "99 Train Loss 6.6316757 Test MSE 6.495150431479906 Test RE 1.2181553230095346\n",
      "Training time: 213.26\n",
      "2\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 61.215538 Test MSE 6.879451588080227 Test RE 1.2536750119931885\n",
      "1 Train Loss 50.194153 Test MSE 8.421714212636163 Test RE 1.3871017196513382\n",
      "2 Train Loss 41.65281 Test MSE 8.194467065623334 Test RE 1.368259327172377\n",
      "3 Train Loss 33.011585 Test MSE 7.151030640177505 Test RE 1.2781810653081394\n",
      "4 Train Loss 27.417835 Test MSE 6.220006082080178 Test RE 1.192074683894747\n",
      "5 Train Loss 22.55383 Test MSE 6.480740079645089 Test RE 1.2168032531622048\n",
      "6 Train Loss 18.679787 Test MSE 6.225509011191097 Test RE 1.192601890148666\n",
      "7 Train Loss 16.669605 Test MSE 5.986953413443222 Test RE 1.1695290120734398\n",
      "8 Train Loss 15.542743 Test MSE 5.797601827925146 Test RE 1.150885856360535\n",
      "9 Train Loss 14.440348 Test MSE 6.034793730830359 Test RE 1.1741924283032337\n",
      "10 Train Loss 13.438293 Test MSE 6.027419217966932 Test RE 1.173474777914264\n",
      "11 Train Loss 12.755499 Test MSE 6.162761505757886 Test RE 1.1865764943556028\n",
      "12 Train Loss 12.122717 Test MSE 6.092565571076297 Test RE 1.179799387216313\n",
      "13 Train Loss 11.73131 Test MSE 6.186705180089026 Test RE 1.1888793141925533\n",
      "14 Train Loss 11.377561 Test MSE 6.1215052943201425 Test RE 1.1825980947900274\n",
      "15 Train Loss 11.033774 Test MSE 5.994415116531605 Test RE 1.1702575930609478\n",
      "16 Train Loss 10.890533 Test MSE 6.012425543891678 Test RE 1.172014314207092\n",
      "17 Train Loss 10.613451 Test MSE 5.944541601801427 Test RE 1.1653791549906596\n",
      "18 Train Loss 10.411438 Test MSE 5.8270624785854 Test RE 1.1538062778487905\n",
      "19 Train Loss 10.0654125 Test MSE 5.8876664849558855 Test RE 1.159790803433669\n",
      "20 Train Loss 9.842403 Test MSE 5.8295504978659345 Test RE 1.1540525756971176\n",
      "21 Train Loss 9.592552 Test MSE 5.8055352440717325 Test RE 1.1516730210642783\n",
      "22 Train Loss 9.194677 Test MSE 5.661702913118049 Test RE 1.1373171778640392\n",
      "23 Train Loss 8.93166 Test MSE 5.590799478041687 Test RE 1.1301732355835592\n",
      "24 Train Loss 8.503956 Test MSE 5.321943700678039 Test RE 1.1026640060689774\n",
      "25 Train Loss 8.147827 Test MSE 5.254796371737069 Test RE 1.095685731131635\n",
      "26 Train Loss 7.854981 Test MSE 5.021834124029692 Test RE 1.0711227461652941\n",
      "27 Train Loss 7.4126115 Test MSE 4.974298626292516 Test RE 1.0660411947014636\n",
      "28 Train Loss 7.090332 Test MSE 5.019107395315997 Test RE 1.0708319104223514\n",
      "29 Train Loss 6.785125 Test MSE 4.854508799949679 Test RE 1.0531269013041558\n",
      "30 Train Loss 6.581984 Test MSE 4.8812653257140175 Test RE 1.056025165347915\n",
      "31 Train Loss 6.4736223 Test MSE 4.82845618692917 Test RE 1.0502972002061615\n",
      "32 Train Loss 6.38085 Test MSE 4.7817874959172935 Test RE 1.0452091338987886\n",
      "33 Train Loss 6.2329636 Test MSE 4.671108027394999 Test RE 1.0330420881501003\n",
      "34 Train Loss 6.0673766 Test MSE 4.497098209948501 Test RE 1.0136178414555297\n",
      "35 Train Loss 5.9156165 Test MSE 4.3789389958284906 Test RE 1.0002130296779619\n",
      "36 Train Loss 5.8393 Test MSE 4.408206610464484 Test RE 1.0035500363987888\n",
      "37 Train Loss 5.690661 Test MSE 4.307215996587294 Test RE 0.9919879252837868\n",
      "38 Train Loss 5.575816 Test MSE 4.242669056315721 Test RE 0.9845270173876733\n",
      "39 Train Loss 5.4265165 Test MSE 4.309178857130794 Test RE 0.9922139311511473\n",
      "40 Train Loss 5.2200503 Test MSE 4.168081255857824 Test RE 0.9758344560874911\n",
      "41 Train Loss 5.0946407 Test MSE 4.067354918197452 Test RE 0.9639712814248202\n",
      "42 Train Loss 4.8193736 Test MSE 3.9251889708436667 Test RE 0.9469746323109589\n",
      "43 Train Loss 4.6026134 Test MSE 3.8597734633736867 Test RE 0.9390505432179932\n",
      "44 Train Loss 4.4284754 Test MSE 3.662728938700916 Test RE 0.9147669178849208\n",
      "45 Train Loss 4.254175 Test MSE 3.581094419878856 Test RE 0.9045153599863517\n",
      "46 Train Loss 4.1639614 Test MSE 3.5694389279323198 Test RE 0.9030421841148757\n",
      "47 Train Loss 4.038349 Test MSE 3.515121441115961 Test RE 0.8961448785173397\n",
      "48 Train Loss 3.8415372 Test MSE 3.405495750286306 Test RE 0.8820602104991837\n",
      "49 Train Loss 3.7244797 Test MSE 3.4112209894802596 Test RE 0.8828013485526935\n",
      "50 Train Loss 3.503456 Test MSE 3.248435433679904 Test RE 0.8614799612123459\n",
      "51 Train Loss 3.3400493 Test MSE 3.2401258636751136 Test RE 0.8603774132358367\n",
      "52 Train Loss 3.2020886 Test MSE 3.2585159671739787 Test RE 0.8628155966338269\n",
      "53 Train Loss 3.0045419 Test MSE 3.1341512229199093 Test RE 0.8461902830827024\n",
      "54 Train Loss 2.8929534 Test MSE 2.99711472648288 Test RE 0.8274842647560152\n",
      "55 Train Loss 2.8174603 Test MSE 2.909981387870883 Test RE 0.8153670665646765\n",
      "56 Train Loss 2.717866 Test MSE 2.744720315867238 Test RE 0.7918758688232226\n",
      "57 Train Loss 2.5957737 Test MSE 2.7202106312104126 Test RE 0.788332310879587\n",
      "58 Train Loss 2.55304 Test MSE 2.6960108558922586 Test RE 0.7848178616635764\n",
      "59 Train Loss 2.4681807 Test MSE 2.6221469656474143 Test RE 0.7739921837459905\n",
      "60 Train Loss 2.4062212 Test MSE 2.5663674543621684 Test RE 0.7657155730536804\n",
      "61 Train Loss 2.315761 Test MSE 2.4872025311115427 Test RE 0.753813022402194\n",
      "62 Train Loss 2.2293348 Test MSE 2.4596506880211577 Test RE 0.7496262351736809\n",
      "63 Train Loss 2.1837137 Test MSE 2.4105273146586312 Test RE 0.742102831738744\n",
      "64 Train Loss 2.1442494 Test MSE 2.3152084934167427 Test RE 0.7272824600662734\n",
      "65 Train Loss 2.0662973 Test MSE 2.1790871981202806 Test RE 0.7055785425248691\n",
      "66 Train Loss 2.01178 Test MSE 2.1111764893148997 Test RE 0.6944969306227715\n",
      "67 Train Loss 1.9712008 Test MSE 2.1505852887868686 Test RE 0.700948959826894\n",
      "68 Train Loss 1.9243577 Test MSE 2.1147248031826127 Test RE 0.6950803158868647\n",
      "69 Train Loss 1.8916866 Test MSE 2.1000021261855917 Test RE 0.6926565214297907\n",
      "70 Train Loss 1.8438337 Test MSE 2.069049472738024 Test RE 0.6875329203910001\n",
      "71 Train Loss 1.7890054 Test MSE 1.9984060942598487 Test RE 0.6756937984992226\n",
      "72 Train Loss 1.7036935 Test MSE 1.9124543844991955 Test RE 0.6610032623024629\n",
      "73 Train Loss 1.6703298 Test MSE 1.9048255679631623 Test RE 0.6596835676883437\n",
      "74 Train Loss 1.6293248 Test MSE 1.8400543482497258 Test RE 0.6483707071979707\n",
      "75 Train Loss 1.5792408 Test MSE 1.7709725984362683 Test RE 0.6360832816797048\n",
      "76 Train Loss 1.5477431 Test MSE 1.7269005701132498 Test RE 0.6281187051345164\n",
      "77 Train Loss 1.5287366 Test MSE 1.7077652868923303 Test RE 0.6246290107421271\n",
      "78 Train Loss 1.5094929 Test MSE 1.7149009053070616 Test RE 0.6259326056143347\n",
      "79 Train Loss 1.4811378 Test MSE 1.6977020849649558 Test RE 0.6227859427287079\n",
      "80 Train Loss 1.457328 Test MSE 1.6941075338752798 Test RE 0.622126279842884\n",
      "81 Train Loss 1.4381704 Test MSE 1.6815921097264583 Test RE 0.6198240033341725\n",
      "82 Train Loss 1.4125199 Test MSE 1.6168645487386302 Test RE 0.6077778656652747\n",
      "83 Train Loss 1.3805693 Test MSE 1.5986383394725339 Test RE 0.6043425495475937\n",
      "84 Train Loss 1.3518984 Test MSE 1.5287651480712905 Test RE 0.5909877065152338\n",
      "85 Train Loss 1.330761 Test MSE 1.4353048129586017 Test RE 0.5726379560017179\n",
      "86 Train Loss 1.2987585 Test MSE 1.266395555741796 Test RE 0.537889106815765\n",
      "87 Train Loss 1.2243226 Test MSE 1.1405963678844073 Test RE 0.5104744999958896\n",
      "88 Train Loss 1.1614008 Test MSE 1.0697377450895702 Test RE 0.49436386646365826\n",
      "89 Train Loss 1.1291549 Test MSE 1.0508878036674896 Test RE 0.4899888936148707\n",
      "90 Train Loss 1.0457492 Test MSE 0.9364829488964114 Test RE 0.46254926739842045\n",
      "91 Train Loss 1.0002482 Test MSE 0.8777669298118838 Test RE 0.44781400081692807\n",
      "92 Train Loss 0.9690056 Test MSE 0.8587145940439562 Test RE 0.4429273338631798\n",
      "93 Train Loss 0.9287333 Test MSE 0.8028419055299579 Test RE 0.4282753481569424\n",
      "94 Train Loss 0.8531926 Test MSE 0.7248587589156282 Test RE 0.4069440995435072\n",
      "95 Train Loss 0.7918613 Test MSE 0.590591024209465 Test RE 0.36732584085116626\n",
      "96 Train Loss 0.7487801 Test MSE 0.5457969804911752 Test RE 0.35312106418062467\n",
      "97 Train Loss 0.701538 Test MSE 0.5288712811286339 Test RE 0.3476026290622413\n",
      "98 Train Loss 0.67151856 Test MSE 0.4905761854740184 Test RE 0.33478137694909654\n",
      "99 Train Loss 0.6381336 Test MSE 0.5133405942143364 Test RE 0.3424607983446331\n",
      "Training time: 209.56\n",
      "3\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.430435 Test MSE 5.327873061928048 Test RE 1.1032780930954367\n",
      "1 Train Loss 56.74549 Test MSE 6.993677179257441 Test RE 1.2640400989168263\n",
      "2 Train Loss 45.617523 Test MSE 9.113886978706933 Test RE 1.442978564155681\n",
      "3 Train Loss 38.69776 Test MSE 9.192481727412956 Test RE 1.4491870613644198\n",
      "4 Train Loss 35.787903 Test MSE 8.537885973155257 Test RE 1.396636010050818\n",
      "5 Train Loss 32.687824 Test MSE 8.421529036326028 Test RE 1.3870864697993663\n",
      "6 Train Loss 30.639523 Test MSE 8.23867241028554 Test RE 1.3719449251900628\n",
      "7 Train Loss 29.690304 Test MSE 8.214769735525733 Test RE 1.3699532831039885\n",
      "8 Train Loss 28.291683 Test MSE 8.3683497151971 Test RE 1.3827000255285464\n",
      "9 Train Loss 27.10463 Test MSE 8.571794069764746 Test RE 1.3994066222584833\n",
      "10 Train Loss 25.854729 Test MSE 8.982198179083767 Test RE 1.4325156548516704\n",
      "11 Train Loss 24.840252 Test MSE 8.969602067896787 Test RE 1.4315108642339938\n",
      "12 Train Loss 24.260098 Test MSE 9.071437881229947 Test RE 1.439614213245855\n",
      "13 Train Loss 23.591068 Test MSE 9.119363179835284 Test RE 1.4434120155581602\n",
      "14 Train Loss 23.028969 Test MSE 9.132452818992018 Test RE 1.4444475575724611\n",
      "15 Train Loss 22.606052 Test MSE 9.110537456659955 Test RE 1.4427133791315738\n",
      "16 Train Loss 22.123283 Test MSE 9.183030333327544 Test RE 1.44844186758039\n",
      "17 Train Loss 21.609852 Test MSE 9.147795826025542 Test RE 1.4456604227730572\n",
      "18 Train Loss 21.37038 Test MSE 9.123991391790947 Test RE 1.4437782455913337\n",
      "19 Train Loss 21.0891 Test MSE 9.132253199030513 Test RE 1.444431770896788\n",
      "20 Train Loss 20.500969 Test MSE 9.38390541956934 Test RE 1.4641982087487437\n",
      "21 Train Loss 20.073471 Test MSE 9.47019083484255 Test RE 1.4709144878151161\n",
      "22 Train Loss 19.572079 Test MSE 9.514738237395804 Test RE 1.474369990687907\n",
      "23 Train Loss 18.820198 Test MSE 9.418433817150413 Test RE 1.466889518762117\n",
      "24 Train Loss 18.16271 Test MSE 9.441944944249032 Test RE 1.4687192672249159\n",
      "25 Train Loss 17.50968 Test MSE 9.497713912997657 Test RE 1.4730503857708848\n",
      "26 Train Loss 17.018211 Test MSE 9.241476806036445 Test RE 1.4530439455826967\n",
      "27 Train Loss 16.64997 Test MSE 9.166026511060858 Test RE 1.447100237481691\n",
      "28 Train Loss 16.268103 Test MSE 9.154353251487931 Test RE 1.4461784771983615\n",
      "29 Train Loss 15.774408 Test MSE 9.146301598197095 Test RE 1.4455423487422396\n",
      "30 Train Loss 15.031677 Test MSE 9.05447579418626 Test RE 1.4382676633710834\n",
      "31 Train Loss 14.596558 Test MSE 8.85937147780044 Test RE 1.4226875021921568\n",
      "32 Train Loss 14.208794 Test MSE 8.786718788820183 Test RE 1.4168420053902364\n",
      "33 Train Loss 13.866017 Test MSE 8.864554553213562 Test RE 1.423103604984733\n",
      "34 Train Loss 13.61677 Test MSE 8.845343088250313 Test RE 1.4215606772565645\n",
      "35 Train Loss 13.391273 Test MSE 8.814787844174486 Test RE 1.4191032423516157\n",
      "36 Train Loss 13.200005 Test MSE 8.840019359491869 Test RE 1.4211328169428712\n",
      "37 Train Loss 12.953381 Test MSE 8.844478827470757 Test RE 1.4214912266349602\n",
      "38 Train Loss 12.758818 Test MSE 8.79892566852639 Test RE 1.4178258321004646\n",
      "39 Train Loss 12.423859 Test MSE 8.81530093524908 Test RE 1.4191445433236316\n",
      "40 Train Loss 12.195199 Test MSE 8.800319178395128 Test RE 1.4179381001285964\n",
      "41 Train Loss 12.02996 Test MSE 8.865544095292815 Test RE 1.4231830326420616\n",
      "42 Train Loss 11.841109 Test MSE 8.878035863945481 Test RE 1.4241853295668838\n",
      "43 Train Loss 11.567262 Test MSE 8.809982640913626 Test RE 1.4187163919121948\n",
      "44 Train Loss 11.28901 Test MSE 8.754661028786874 Test RE 1.4142550166331092\n",
      "45 Train Loss 11.080597 Test MSE 8.82965600734478 Test RE 1.4202995597877963\n",
      "46 Train Loss 10.878513 Test MSE 8.743228745907265 Test RE 1.4133313118138633\n",
      "47 Train Loss 10.555796 Test MSE 8.661995558316134 Test RE 1.4067503718630554\n",
      "48 Train Loss 10.063096 Test MSE 8.748889218099471 Test RE 1.4137887416945327\n",
      "49 Train Loss 9.317297 Test MSE 8.395413988426046 Test RE 1.38493413169831\n",
      "50 Train Loss 8.713022 Test MSE 8.196149493134323 Test RE 1.3683997804178802\n",
      "51 Train Loss 7.931141 Test MSE 7.968091420297534 Test RE 1.3492275931550874\n",
      "52 Train Loss 7.4418297 Test MSE 8.03790292799684 Test RE 1.3551252538496457\n",
      "53 Train Loss 7.0002003 Test MSE 7.981237931826923 Test RE 1.350340176137354\n",
      "54 Train Loss 6.379865 Test MSE 7.4252717533665304 Test RE 1.3024595266398948\n",
      "55 Train Loss 5.8158345 Test MSE 7.191781901180769 Test RE 1.2818178483358\n",
      "56 Train Loss 5.403509 Test MSE 7.209121960150725 Test RE 1.2833622093710495\n",
      "57 Train Loss 4.9111395 Test MSE 7.18842887494504 Test RE 1.2815190023744276\n",
      "58 Train Loss 4.607684 Test MSE 7.196194032541908 Test RE 1.2822109832818454\n",
      "59 Train Loss 4.360441 Test MSE 7.128674611459679 Test RE 1.2761815338889304\n",
      "60 Train Loss 4.221665 Test MSE 7.044556135760351 Test RE 1.2686297084938356\n",
      "61 Train Loss 4.0613165 Test MSE 7.128825036231506 Test RE 1.2761949984046936\n",
      "62 Train Loss 3.8285763 Test MSE 7.202661534561218 Test RE 1.2827870405475792\n",
      "63 Train Loss 3.5860395 Test MSE 7.075181865177556 Test RE 1.271384358580862\n",
      "64 Train Loss 3.4930992 Test MSE 7.076976964975865 Test RE 1.2715456347929002\n",
      "65 Train Loss 3.406159 Test MSE 7.031057840899248 Test RE 1.267413695125971\n",
      "66 Train Loss 3.2947443 Test MSE 6.939587604970006 Test RE 1.2591425250070185\n",
      "67 Train Loss 3.196517 Test MSE 6.954456859053402 Test RE 1.2604907673580996\n",
      "68 Train Loss 3.1238377 Test MSE 7.051726804362256 Test RE 1.2692752147028834\n",
      "69 Train Loss 3.0845046 Test MSE 7.02564131074875 Test RE 1.2669254110508241\n",
      "70 Train Loss 3.043186 Test MSE 7.05936018060681 Test RE 1.26996201347946\n",
      "71 Train Loss 3.000128 Test MSE 7.11381849903512 Test RE 1.2748510632656829\n",
      "72 Train Loss 2.9511564 Test MSE 7.136171487930168 Test RE 1.2768524062300093\n",
      "73 Train Loss 2.9168084 Test MSE 7.120920276669792 Test RE 1.2754872511513407\n",
      "74 Train Loss 2.8595643 Test MSE 7.127998341788682 Test RE 1.2761209992606548\n",
      "75 Train Loss 2.8283877 Test MSE 7.063035917392246 Test RE 1.2702925985804323\n",
      "76 Train Loss 2.7468603 Test MSE 7.048257815238677 Test RE 1.2689629760356964\n",
      "77 Train Loss 2.711873 Test MSE 7.104452428533547 Test RE 1.2740115508645553\n",
      "78 Train Loss 2.6859841 Test MSE 7.121062280947157 Test RE 1.2754999688714788\n",
      "79 Train Loss 2.6404984 Test MSE 7.138683587897798 Test RE 1.2770771274728707\n",
      "80 Train Loss 2.616545 Test MSE 7.122619202932907 Test RE 1.2756393964830477\n",
      "81 Train Loss 2.5986125 Test MSE 7.097536651968306 Test RE 1.2733913113346862\n",
      "82 Train Loss 2.5637662 Test MSE 7.109253357706759 Test RE 1.274441943376545\n",
      "83 Train Loss 2.538983 Test MSE 7.143402280621855 Test RE 1.2774991337840278\n",
      "84 Train Loss 2.4867647 Test MSE 7.17001839526964 Test RE 1.279876883787462\n",
      "85 Train Loss 2.4418628 Test MSE 7.198593524789502 Test RE 1.282424735084099\n",
      "86 Train Loss 2.404033 Test MSE 7.217823689296694 Test RE 1.284136513268835\n",
      "87 Train Loss 2.384175 Test MSE 7.2291475360973845 Test RE 1.2851434418705072\n",
      "88 Train Loss 2.3459318 Test MSE 7.22893001559533 Test RE 1.2851241071461734\n",
      "89 Train Loss 2.281675 Test MSE 7.241286097538968 Test RE 1.2862219403786483\n",
      "90 Train Loss 2.243856 Test MSE 7.283194811623173 Test RE 1.289938555073048\n",
      "91 Train Loss 2.205705 Test MSE 7.320682490324005 Test RE 1.2932540462876247\n",
      "92 Train Loss 2.169677 Test MSE 7.314163137653004 Test RE 1.2926780714969086\n",
      "93 Train Loss 2.1255178 Test MSE 7.299785310149355 Test RE 1.2914069045305183\n",
      "94 Train Loss 2.101508 Test MSE 7.297670115885874 Test RE 1.2912197911932706\n",
      "95 Train Loss 2.0795977 Test MSE 7.29238061120052 Test RE 1.290751754745217\n",
      "96 Train Loss 2.0604763 Test MSE 7.308934798306611 Test RE 1.2922159702473717\n",
      "97 Train Loss 2.0197964 Test MSE 7.298061049361256 Test RE 1.291254375812223\n",
      "98 Train Loss 1.9899359 Test MSE 7.251525609545246 Test RE 1.2871310076538134\n",
      "99 Train Loss 1.9775105 Test MSE 7.2381328887022836 Test RE 1.2859418680306514\n",
      "Training time: 213.15\n",
      "4\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.715675 Test MSE 7.650469643279106 Test RE 1.3220628703322843\n",
      "1 Train Loss 54.38524 Test MSE 7.710580221796026 Test RE 1.327246504597359\n",
      "2 Train Loss 49.63362 Test MSE 7.809790447695354 Test RE 1.335757898200422\n",
      "3 Train Loss 40.73468 Test MSE 7.965243172597826 Test RE 1.3489864263770024\n",
      "4 Train Loss 33.63943 Test MSE 7.625365271830649 Test RE 1.3198919690104398\n",
      "5 Train Loss 30.416666 Test MSE 7.645859913165101 Test RE 1.3216645110410943\n",
      "6 Train Loss 26.174978 Test MSE 7.224140986893223 Test RE 1.2846983514763457\n",
      "7 Train Loss 23.531937 Test MSE 7.55398624446897 Test RE 1.3136998644749145\n",
      "8 Train Loss 20.958916 Test MSE 7.118202037158259 Test RE 1.2752437846723248\n",
      "9 Train Loss 19.095587 Test MSE 6.738631238870925 Test RE 1.24077748935386\n",
      "10 Train Loss 17.361452 Test MSE 6.546626864843787 Test RE 1.222972958823346\n",
      "11 Train Loss 16.0633 Test MSE 6.588842997965351 Test RE 1.2269098124478626\n",
      "12 Train Loss 15.121849 Test MSE 6.42715526700374 Test RE 1.2117623541530682\n",
      "13 Train Loss 14.368493 Test MSE 6.383836247888006 Test RE 1.207671811499173\n",
      "14 Train Loss 13.448118 Test MSE 6.15261813294082 Test RE 1.1855995910359929\n",
      "15 Train Loss 12.2143135 Test MSE 5.982288374236998 Test RE 1.1690732742764505\n",
      "16 Train Loss 11.554063 Test MSE 5.632308108510324 Test RE 1.1343609363986664\n",
      "17 Train Loss 10.042805 Test MSE 5.138042048029287 Test RE 1.0834450439618803\n",
      "18 Train Loss 8.992929 Test MSE 4.956370959544219 Test RE 1.0641184229019498\n",
      "19 Train Loss 8.337314 Test MSE 4.828897966673093 Test RE 1.0503452475941095\n",
      "20 Train Loss 7.898006 Test MSE 4.590958088293944 Test RE 1.0241409326906181\n",
      "21 Train Loss 7.3969927 Test MSE 4.429840063312099 Test RE 1.0060095038740433\n",
      "22 Train Loss 7.0891824 Test MSE 4.143054065693298 Test RE 0.9729003523034699\n",
      "23 Train Loss 6.792739 Test MSE 4.046996229539909 Test RE 0.9615557298974075\n",
      "24 Train Loss 6.4306107 Test MSE 3.9348402255465147 Test RE 0.9481381281695067\n",
      "25 Train Loss 5.9773335 Test MSE 3.6125897269398957 Test RE 0.9084842061651835\n",
      "26 Train Loss 5.6796694 Test MSE 3.6247763839919163 Test RE 0.9100152496820472\n",
      "27 Train Loss 5.317728 Test MSE 3.463562916443399 Test RE 0.8895484368031602\n",
      "28 Train Loss 4.6999016 Test MSE 2.9117170044386977 Test RE 0.8156101873015889\n",
      "29 Train Loss 4.330311 Test MSE 2.7869040653471733 Test RE 0.7979378566180187\n",
      "30 Train Loss 3.9871538 Test MSE 2.8098818127598975 Test RE 0.8012205633255461\n",
      "31 Train Loss 3.6013887 Test MSE 2.4478441869111163 Test RE 0.7478249409282822\n",
      "32 Train Loss 3.3114927 Test MSE 2.536862893254407 Test RE 0.761301277068504\n",
      "33 Train Loss 3.0828843 Test MSE 2.463583495124876 Test RE 0.7502252954129054\n",
      "34 Train Loss 2.782666 Test MSE 2.1718672144665914 Test RE 0.7044086737218566\n",
      "35 Train Loss 2.6471727 Test MSE 2.1868243492670767 Test RE 0.7068300597966607\n",
      "36 Train Loss 2.5743084 Test MSE 2.201163670645635 Test RE 0.7091436664472145\n",
      "37 Train Loss 2.432144 Test MSE 2.138705289854373 Test RE 0.6990102306501909\n",
      "38 Train Loss 2.2803922 Test MSE 2.031070869241258 Test RE 0.6811936626474281\n",
      "39 Train Loss 2.180647 Test MSE 2.009342729705062 Test RE 0.6775402034455076\n",
      "40 Train Loss 2.06596 Test MSE 1.9740427582654907 Test RE 0.6715623465888165\n",
      "41 Train Loss 1.9656091 Test MSE 1.8594574848631527 Test RE 0.651780235398204\n",
      "42 Train Loss 1.902257 Test MSE 1.8411661289859076 Test RE 0.6485665539157562\n",
      "43 Train Loss 1.846809 Test MSE 1.8028572805597838 Test RE 0.641783776265729\n",
      "44 Train Loss 1.7918513 Test MSE 1.776578295963715 Test RE 0.637089190325684\n",
      "45 Train Loss 1.7148384 Test MSE 1.690153029369956 Test RE 0.6213997502398678\n",
      "46 Train Loss 1.6335531 Test MSE 1.5970656241654384 Test RE 0.6040452050414622\n",
      "47 Train Loss 1.5795434 Test MSE 1.5932181233947065 Test RE 0.6033171617554289\n",
      "48 Train Loss 1.5303867 Test MSE 1.5446363547281965 Test RE 0.5940475189630553\n",
      "49 Train Loss 1.4567736 Test MSE 1.4374340850174887 Test RE 0.5730625522671289\n",
      "50 Train Loss 1.3892866 Test MSE 1.3667707551807395 Test RE 0.5587993587774045\n",
      "51 Train Loss 1.3235877 Test MSE 1.236411232272253 Test RE 0.53148318775848\n",
      "52 Train Loss 1.2287785 Test MSE 1.0171229707056362 Test RE 0.48205300173000526\n",
      "53 Train Loss 1.1899978 Test MSE 0.9969340966440675 Test RE 0.47724488801618714\n",
      "54 Train Loss 1.1149771 Test MSE 0.9175920422144086 Test RE 0.4578601851224675\n",
      "55 Train Loss 1.049234 Test MSE 0.8964410202674571 Test RE 0.45255245051219\n",
      "56 Train Loss 0.96877545 Test MSE 0.892115944820376 Test RE 0.4514594114588123\n",
      "57 Train Loss 0.9053542 Test MSE 0.848421810904892 Test RE 0.44026480854249184\n",
      "58 Train Loss 0.8225912 Test MSE 0.8281062262901854 Test RE 0.4349617679890759\n",
      "59 Train Loss 0.78582346 Test MSE 0.782495495897395 Test RE 0.422813634394806\n",
      "60 Train Loss 0.75655985 Test MSE 0.7183864813020503 Test RE 0.4051232199687481\n",
      "61 Train Loss 0.7251889 Test MSE 0.6879615212763746 Test RE 0.39645156298131834\n",
      "62 Train Loss 0.7042414 Test MSE 0.6641416460418254 Test RE 0.38952776353115165\n",
      "63 Train Loss 0.6714416 Test MSE 0.6128186395349289 Test RE 0.37417437633373074\n",
      "64 Train Loss 0.6057886 Test MSE 0.5220390621803398 Test RE 0.34535007979145316\n",
      "65 Train Loss 0.5872662 Test MSE 0.4876592156016086 Test RE 0.3337845866538027\n",
      "66 Train Loss 0.55266404 Test MSE 0.4331288503100415 Test RE 0.3145695033009351\n",
      "67 Train Loss 0.50629026 Test MSE 0.3522433464143112 Test RE 0.28368048416361746\n",
      "68 Train Loss 0.48514578 Test MSE 0.330931889508779 Test RE 0.27496497043600354\n",
      "69 Train Loss 0.45921278 Test MSE 0.33952782354569705 Test RE 0.2785131755478065\n",
      "70 Train Loss 0.43553334 Test MSE 0.33261008269606346 Test RE 0.2756612780814983\n",
      "71 Train Loss 0.4066103 Test MSE 0.30303148686240805 Test RE 0.26311883565720057\n",
      "72 Train Loss 0.37633473 Test MSE 0.289412215963288 Test RE 0.25713813492582616\n",
      "73 Train Loss 0.35370046 Test MSE 0.2728899348107439 Test RE 0.249690385042384\n",
      "74 Train Loss 0.33069527 Test MSE 0.2520168974112334 Test RE 0.23995118033955823\n",
      "75 Train Loss 0.30767968 Test MSE 0.19485346056557123 Test RE 0.21099012133162637\n",
      "76 Train Loss 0.2871867 Test MSE 0.1655236464144008 Test RE 0.19446349319404785\n",
      "77 Train Loss 0.27407503 Test MSE 0.1804449011927837 Test RE 0.20303942164190442\n",
      "78 Train Loss 0.2628528 Test MSE 0.17869984626449142 Test RE 0.20205525489693252\n",
      "79 Train Loss 0.23929286 Test MSE 0.14278636200430853 Test RE 0.1806140056686547\n",
      "80 Train Loss 0.22691183 Test MSE 0.12379484838298802 Test RE 0.1681741906984687\n",
      "81 Train Loss 0.21369481 Test MSE 0.10478719599683367 Test RE 0.15472559800427566\n",
      "82 Train Loss 0.20219614 Test MSE 0.08889158521042943 Test RE 0.14250771803649587\n",
      "83 Train Loss 0.18375637 Test MSE 0.06790095999563292 Test RE 0.12455065549200761\n",
      "84 Train Loss 0.1739756 Test MSE 0.06283899428683694 Test RE 0.11981816748184802\n",
      "85 Train Loss 0.1613136 Test MSE 0.06929433018790035 Test RE 0.12582209463160904\n",
      "86 Train Loss 0.15153453 Test MSE 0.07030134729315168 Test RE 0.12673304926624082\n",
      "87 Train Loss 0.14328045 Test MSE 0.0599128396768062 Test RE 0.11699519144190954\n",
      "88 Train Loss 0.13617939 Test MSE 0.05056677786912271 Test RE 0.10748322797539422\n",
      "89 Train Loss 0.12910111 Test MSE 0.05219758544022376 Test RE 0.10920267257040919\n",
      "90 Train Loss 0.12104976 Test MSE 0.050131838857141404 Test RE 0.10701998303309593\n",
      "91 Train Loss 0.115377106 Test MSE 0.03923915344967865 Test RE 0.09468209850271068\n",
      "92 Train Loss 0.109426536 Test MSE 0.032543071866074705 Test RE 0.08622581995069917\n",
      "93 Train Loss 0.103323504 Test MSE 0.027292988197744665 Test RE 0.07896481168046562\n",
      "94 Train Loss 0.09506373 Test MSE 0.02667124508487461 Test RE 0.0780602082159902\n",
      "95 Train Loss 0.091068156 Test MSE 0.027567598738561412 Test RE 0.07936107274442519\n",
      "96 Train Loss 0.08597327 Test MSE 0.027640817078955143 Test RE 0.07946639263420306\n",
      "97 Train Loss 0.08294533 Test MSE 0.026546686953323646 Test RE 0.07787771931846604\n",
      "98 Train Loss 0.077133834 Test MSE 0.025142320794223755 Test RE 0.0757897966698679\n",
      "99 Train Loss 0.075456835 Test MSE 0.023830133581114472 Test RE 0.0737855465704772\n",
      "Training time: 210.99\n",
      "5\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.56434 Test MSE 4.684479460693604 Test RE 1.0345196157542338\n",
      "1 Train Loss 57.663353 Test MSE 5.012177916670337 Test RE 1.0700924492794897\n",
      "2 Train Loss 46.3572 Test MSE 5.5084244542433645 Test RE 1.1218163337819822\n",
      "3 Train Loss 39.50449 Test MSE 6.198781076637921 Test RE 1.1900390417234792\n",
      "4 Train Loss 34.89985 Test MSE 6.123918487416237 Test RE 1.1828311711510846\n",
      "5 Train Loss 27.698507 Test MSE 5.588028908012273 Test RE 1.1298931672203996\n",
      "6 Train Loss 23.143192 Test MSE 5.546181648775802 Test RE 1.1256544823104582\n",
      "7 Train Loss 21.757177 Test MSE 5.472567682246367 Test RE 1.1181591731114855\n",
      "8 Train Loss 20.941885 Test MSE 5.399809992765922 Test RE 1.1107013491551225\n",
      "9 Train Loss 19.93003 Test MSE 5.496766666635665 Test RE 1.120628623633111\n",
      "10 Train Loss 18.88155 Test MSE 5.32775796554455 Test RE 1.1032661761444473\n",
      "11 Train Loss 18.115757 Test MSE 5.24359281767836 Test RE 1.094517072680533\n",
      "12 Train Loss 17.43581 Test MSE 4.966563507067881 Test RE 1.06521201610721\n",
      "13 Train Loss 16.734966 Test MSE 4.88549175815707 Test RE 1.0564822449187614\n",
      "14 Train Loss 15.863062 Test MSE 4.704009282426014 Test RE 1.0366738539976355\n",
      "15 Train Loss 14.7466755 Test MSE 4.676010711295327 Test RE 1.033584074177782\n",
      "16 Train Loss 13.9130745 Test MSE 4.807152615046227 Test RE 1.047977637199097\n",
      "17 Train Loss 12.771849 Test MSE 4.208353793757419 Test RE 0.9805374422781348\n",
      "18 Train Loss 12.059267 Test MSE 4.2543565876411495 Test RE 0.9858821521578002\n",
      "19 Train Loss 10.86207 Test MSE 4.207463968767964 Test RE 0.9804337731371677\n",
      "20 Train Loss 10.010169 Test MSE 4.091592547357101 Test RE 0.9668391986310052\n",
      "21 Train Loss 9.773393 Test MSE 4.035136795234682 Test RE 0.9601458109208503\n",
      "22 Train Loss 9.509305 Test MSE 3.905619531079679 Test RE 0.9446110621832634\n",
      "23 Train Loss 9.199692 Test MSE 3.90110265455429 Test RE 0.9440646794868686\n",
      "24 Train Loss 8.516342 Test MSE 3.2375368197303525 Test RE 0.8600335994166866\n",
      "25 Train Loss 8.097166 Test MSE 2.9174890593128597 Test RE 0.8164182012593239\n",
      "26 Train Loss 7.360055 Test MSE 2.812884359762216 Test RE 0.8016485279590173\n",
      "27 Train Loss 6.5300198 Test MSE 2.9064578060945014 Test RE 0.8148732691163243\n",
      "28 Train Loss 6.242544 Test MSE 2.88984121593689 Test RE 0.8125405630117275\n",
      "29 Train Loss 6.044423 Test MSE 2.913216095008782 Test RE 0.8158201177664387\n",
      "30 Train Loss 5.9961367 Test MSE 2.9050762564528974 Test RE 0.814679576009071\n",
      "31 Train Loss 5.84237 Test MSE 2.859839524639049 Test RE 0.8083117506691788\n",
      "32 Train Loss 5.487081 Test MSE 2.8887416952156 Test RE 0.8123859714415411\n",
      "33 Train Loss 5.3279915 Test MSE 2.876900752205548 Test RE 0.8107192779899173\n",
      "34 Train Loss 4.937215 Test MSE 2.6774562245971896 Test RE 0.7821125410469146\n",
      "35 Train Loss 3.729395 Test MSE 2.0647608595343163 Test RE 0.6868200103591469\n",
      "36 Train Loss 3.412161 Test MSE 2.004343576920281 Test RE 0.6766968340382287\n",
      "37 Train Loss 3.07008 Test MSE 1.9011627480562487 Test RE 0.6590490043851689\n",
      "38 Train Loss 2.5354643 Test MSE 1.9697900330010105 Test RE 0.6708385755419319\n",
      "39 Train Loss 2.3203628 Test MSE 1.9426888094381054 Test RE 0.6662077484538181\n",
      "40 Train Loss 2.1682649 Test MSE 1.9686749753174178 Test RE 0.6706486746931705\n",
      "41 Train Loss 2.0079238 Test MSE 2.0055485952059353 Test RE 0.676900219711457\n",
      "42 Train Loss 1.8016119 Test MSE 1.988858224473525 Test RE 0.674077720388035\n",
      "43 Train Loss 1.736637 Test MSE 1.983927738609093 Test RE 0.6732416645569366\n",
      "44 Train Loss 1.6557873 Test MSE 1.9437692818357988 Test RE 0.666392986311151\n",
      "45 Train Loss 1.5668247 Test MSE 1.8791471355620213 Test RE 0.655221973428506\n",
      "46 Train Loss 1.518748 Test MSE 1.9057755377316268 Test RE 0.6598480450405162\n",
      "47 Train Loss 1.4714897 Test MSE 1.907633016130534 Test RE 0.6601695296443764\n",
      "48 Train Loss 1.3351231 Test MSE 1.864681664269114 Test RE 0.6526951873802517\n",
      "49 Train Loss 1.2056193 Test MSE 1.9136217282253094 Test RE 0.6612049665382125\n",
      "50 Train Loss 1.1662967 Test MSE 1.915518742318883 Test RE 0.6615326186594244\n",
      "51 Train Loss 1.1092186 Test MSE 1.8708949990953563 Test RE 0.6537817109290697\n",
      "52 Train Loss 1.0399992 Test MSE 1.8588557714581522 Test RE 0.6516747700567087\n",
      "53 Train Loss 1.0213392 Test MSE 1.8460866585603082 Test RE 0.6494326250205797\n",
      "54 Train Loss 0.98002887 Test MSE 1.80727831838665 Test RE 0.6425701981988455\n",
      "55 Train Loss 0.9379817 Test MSE 1.8236074818066734 Test RE 0.6454665532639026\n",
      "56 Train Loss 0.9192475 Test MSE 1.8204720954171976 Test RE 0.6449114289553122\n",
      "57 Train Loss 0.9061003 Test MSE 1.8091569189344745 Test RE 0.6429040757162937\n",
      "58 Train Loss 0.87799484 Test MSE 1.7939131868863132 Test RE 0.6401898311056541\n",
      "59 Train Loss 0.8522826 Test MSE 1.7743791681653416 Test RE 0.636694759529182\n",
      "60 Train Loss 0.842409 Test MSE 1.7656046976759148 Test RE 0.6351185510032669\n",
      "61 Train Loss 0.81803495 Test MSE 1.713468095740576 Test RE 0.6256710658279744\n",
      "62 Train Loss 0.77957726 Test MSE 1.6995230811269086 Test RE 0.6231198608145656\n",
      "63 Train Loss 0.7715703 Test MSE 1.6964027751569606 Test RE 0.6225475773595105\n",
      "64 Train Loss 0.76188517 Test MSE 1.6514045965373196 Test RE 0.6142353469061618\n",
      "65 Train Loss 0.7439231 Test MSE 1.5892108977652943 Test RE 0.6025579593389135\n",
      "66 Train Loss 0.7052646 Test MSE 1.5863270167905894 Test RE 0.6020109915038909\n",
      "67 Train Loss 0.6965474 Test MSE 1.5765867103290974 Test RE 0.6001599228537127\n",
      "68 Train Loss 0.683537 Test MSE 1.5596540915960109 Test RE 0.5969283490852599\n",
      "69 Train Loss 0.6453236 Test MSE 1.537262491360318 Test RE 0.5926278755578684\n",
      "70 Train Loss 0.6345275 Test MSE 1.5322058028677379 Test RE 0.5916523742982708\n",
      "71 Train Loss 0.6191513 Test MSE 1.50813951770109 Test RE 0.5869874557432424\n",
      "72 Train Loss 0.5921278 Test MSE 1.5058161320272851 Test RE 0.5865351355536912\n",
      "73 Train Loss 0.58816093 Test MSE 1.503247454709983 Test RE 0.5860346552736069\n",
      "74 Train Loss 0.58002025 Test MSE 1.4835779319633993 Test RE 0.582187990660068\n",
      "75 Train Loss 0.5583682 Test MSE 1.4463349733187372 Test RE 0.5748340748452556\n",
      "76 Train Loss 0.53696096 Test MSE 1.4031687326219595 Test RE 0.5661910624391298\n",
      "77 Train Loss 0.5317749 Test MSE 1.3878996389013292 Test RE 0.5631020282838316\n",
      "78 Train Loss 0.5225521 Test MSE 1.3666225250108313 Test RE 0.5587690562670835\n",
      "79 Train Loss 0.49863905 Test MSE 1.3239467628520138 Test RE 0.5499754722584017\n",
      "80 Train Loss 0.47570294 Test MSE 1.2619590303108792 Test RE 0.5369460948262637\n",
      "81 Train Loss 0.4670322 Test MSE 1.248398816923601 Test RE 0.5340534617139501\n",
      "82 Train Loss 0.45828316 Test MSE 1.2167420577200203 Test RE 0.5272387482978077\n",
      "83 Train Loss 0.44445157 Test MSE 1.1769340717320798 Test RE 0.5185422265044448\n",
      "84 Train Loss 0.4276793 Test MSE 1.1602593752101402 Test RE 0.5148557927473157\n",
      "85 Train Loss 0.41183615 Test MSE 1.1590429219277025 Test RE 0.5145858262741648\n",
      "86 Train Loss 0.39952344 Test MSE 1.145039125739521 Test RE 0.5114677130641515\n",
      "87 Train Loss 0.39357677 Test MSE 1.1451181592150854 Test RE 0.5114853641524822\n",
      "88 Train Loss 0.37495998 Test MSE 1.1237285327816524 Test RE 0.5066858363511139\n",
      "89 Train Loss 0.35754848 Test MSE 1.0775901515960262 Test RE 0.4961749871019628\n",
      "90 Train Loss 0.34924692 Test MSE 1.039225674411757 Test RE 0.48726250556063055\n",
      "91 Train Loss 0.33934274 Test MSE 1.0072123899292222 Test RE 0.47969875357604125\n",
      "92 Train Loss 0.33238447 Test MSE 1.014042876625379 Test RE 0.4813225618498297\n",
      "93 Train Loss 0.32119206 Test MSE 1.008754884275626 Test RE 0.48006593012550836\n",
      "94 Train Loss 0.3089256 Test MSE 0.9974312834971105 Test RE 0.4773638779817053\n",
      "95 Train Loss 0.2994346 Test MSE 0.9856016408623041 Test RE 0.47452464090950686\n",
      "96 Train Loss 0.2961426 Test MSE 0.9802639405536686 Test RE 0.4732379603498222\n",
      "97 Train Loss 0.29293045 Test MSE 0.9689840474500728 Test RE 0.47050730859647316\n",
      "98 Train Loss 0.28383204 Test MSE 0.9598903648283326 Test RE 0.4682943051721814\n",
      "99 Train Loss 0.27359077 Test MSE 0.9432211456650877 Test RE 0.4642103556454579\n",
      "Training time: 213.66\n",
      "6\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 65.15595 Test MSE 7.3871630416872405 Test RE 1.2991129215823276\n",
      "1 Train Loss 53.598827 Test MSE 7.457361234116098 Test RE 1.3052708844203258\n",
      "2 Train Loss 46.504112 Test MSE 8.521205488026228 Test RE 1.3952710377359163\n",
      "3 Train Loss 43.200253 Test MSE 8.644347882725976 Test RE 1.4053166068725358\n",
      "4 Train Loss 39.58975 Test MSE 8.37120340557201 Test RE 1.3829357626545513\n",
      "5 Train Loss 35.848366 Test MSE 8.631013368209521 Test RE 1.4042322887049206\n",
      "6 Train Loss 34.331356 Test MSE 8.585671019995933 Test RE 1.4005389198061766\n",
      "7 Train Loss 32.004158 Test MSE 8.149079193577283 Test RE 1.3644647782655992\n",
      "8 Train Loss 30.458546 Test MSE 8.42565184716531 Test RE 1.387425956570343\n",
      "9 Train Loss 29.775688 Test MSE 8.25886332110937 Test RE 1.37362504214912\n",
      "10 Train Loss 28.721714 Test MSE 8.334650566987179 Test RE 1.3799131667433218\n",
      "11 Train Loss 28.024128 Test MSE 8.105763964139543 Test RE 1.3608336409261026\n",
      "12 Train Loss 27.370707 Test MSE 7.9699280564295085 Test RE 1.3493830819187846\n",
      "13 Train Loss 26.693918 Test MSE 8.17919317960979 Test RE 1.3669835648622066\n",
      "14 Train Loss 25.810513 Test MSE 8.264681844154778 Test RE 1.3741088291690553\n",
      "15 Train Loss 25.307938 Test MSE 8.418686083706222 Test RE 1.3868523226534668\n",
      "16 Train Loss 24.361935 Test MSE 8.928054681667614 Test RE 1.428191621793024\n",
      "17 Train Loss 23.634836 Test MSE 8.505645536189052 Test RE 1.3939965543216637\n",
      "18 Train Loss 22.875248 Test MSE 8.595063787629627 Test RE 1.4013048087320346\n",
      "19 Train Loss 22.334496 Test MSE 8.368023846642261 Test RE 1.3826731036824862\n",
      "20 Train Loss 21.193905 Test MSE 8.211037494485234 Test RE 1.36964204025032\n",
      "21 Train Loss 19.823925 Test MSE 7.960789075792438 Test RE 1.3486092027182357\n",
      "22 Train Loss 19.153242 Test MSE 7.878767231242263 Test RE 1.341643698752797\n",
      "23 Train Loss 18.231316 Test MSE 7.995190044541499 Test RE 1.3515199349686833\n",
      "24 Train Loss 17.626417 Test MSE 8.157573599136073 Test RE 1.3651757357939105\n",
      "25 Train Loss 16.944263 Test MSE 7.8976451136057 Test RE 1.3432500565706107\n",
      "26 Train Loss 16.424189 Test MSE 7.754240651410067 Test RE 1.3309989039550403\n",
      "27 Train Loss 16.133831 Test MSE 7.765730222602094 Test RE 1.331984619173604\n",
      "28 Train Loss 15.52393 Test MSE 7.727883632262445 Test RE 1.3287349153475405\n",
      "29 Train Loss 14.848948 Test MSE 7.7380979958244005 Test RE 1.329612755927026\n",
      "30 Train Loss 14.437301 Test MSE 7.594695623606831 Test RE 1.3172349547667497\n",
      "31 Train Loss 13.840277 Test MSE 7.498908064467153 Test RE 1.3089018300002233\n",
      "32 Train Loss 13.447682 Test MSE 7.49945504194928 Test RE 1.3089495654015852\n",
      "33 Train Loss 12.934511 Test MSE 7.581862372210393 Test RE 1.316121575421488\n",
      "34 Train Loss 12.4906025 Test MSE 7.618744716206854 Test RE 1.319318861005424\n",
      "35 Train Loss 11.591577 Test MSE 7.3827259206346065 Test RE 1.2987227049923635\n",
      "36 Train Loss 11.282743 Test MSE 7.369716822275339 Test RE 1.2975779611051914\n",
      "37 Train Loss 10.915774 Test MSE 7.2663016629771775 Test RE 1.2884416999870123\n",
      "38 Train Loss 10.553464 Test MSE 7.309047063149487 Test RE 1.2922258943929412\n",
      "39 Train Loss 10.312534 Test MSE 7.266086767847551 Test RE 1.2884226475235907\n",
      "40 Train Loss 10.081082 Test MSE 7.205804908371715 Test RE 1.2830669259291254\n",
      "41 Train Loss 9.83975 Test MSE 7.305127841854447 Test RE 1.2918793924276697\n",
      "42 Train Loss 9.6491995 Test MSE 7.350954087140577 Test RE 1.2959251413442843\n",
      "43 Train Loss 9.355086 Test MSE 7.330096176931175 Test RE 1.294085278695775\n",
      "44 Train Loss 9.214167 Test MSE 7.223734881200788 Test RE 1.2846622412559803\n",
      "45 Train Loss 8.728408 Test MSE 7.188942329183383 Test RE 1.2815647696502288\n",
      "46 Train Loss 8.423892 Test MSE 7.265254166381596 Test RE 1.2883488269547057\n",
      "47 Train Loss 8.0586605 Test MSE 7.1187717840123925 Test RE 1.2752948194415423\n",
      "48 Train Loss 7.474817 Test MSE 6.354240088829141 Test RE 1.2048691103951432\n",
      "49 Train Loss 6.9091144 Test MSE 6.32786509703963 Test RE 1.2023659426449578\n",
      "50 Train Loss 6.5791855 Test MSE 6.324217108349159 Test RE 1.2020193131234103\n",
      "51 Train Loss 6.3782916 Test MSE 6.271650445320556 Test RE 1.1970133185576783\n",
      "52 Train Loss 6.2186165 Test MSE 6.2809028014895105 Test RE 1.197895950007994\n",
      "53 Train Loss 6.0497475 Test MSE 6.386677430867839 Test RE 1.2079405241332708\n",
      "54 Train Loss 5.9011726 Test MSE 6.3305767351564395 Test RE 1.2026235360084268\n",
      "55 Train Loss 5.8091483 Test MSE 6.27888072928966 Test RE 1.1977031093320618\n",
      "56 Train Loss 5.693364 Test MSE 6.329176776615146 Test RE 1.2024905531656291\n",
      "57 Train Loss 5.538473 Test MSE 6.401144148230768 Test RE 1.2093078273783817\n",
      "58 Train Loss 5.438918 Test MSE 6.371554292854615 Test RE 1.206509523548151\n",
      "59 Train Loss 5.311333 Test MSE 6.476479343504433 Test RE 1.2164031962287576\n",
      "60 Train Loss 5.213696 Test MSE 6.521074838883824 Test RE 1.2205839431230172\n",
      "61 Train Loss 5.147101 Test MSE 6.424368183740659 Test RE 1.2114995902514722\n",
      "62 Train Loss 5.0443015 Test MSE 6.456256401980449 Test RE 1.2145025892509045\n",
      "63 Train Loss 4.9879417 Test MSE 6.453542728300164 Test RE 1.2142473244430216\n",
      "64 Train Loss 4.9598956 Test MSE 6.412159606716464 Test RE 1.2103479034855058\n",
      "65 Train Loss 4.908182 Test MSE 6.492509379006331 Test RE 1.2179076351942568\n",
      "66 Train Loss 4.830793 Test MSE 6.532168699467677 Test RE 1.2216217500976057\n",
      "67 Train Loss 4.760196 Test MSE 6.485733622648062 Test RE 1.2172719488123585\n",
      "68 Train Loss 4.7195916 Test MSE 6.4673087344335585 Test RE 1.2155416857320296\n",
      "69 Train Loss 4.68757 Test MSE 6.4213314252545635 Test RE 1.21121322228322\n",
      "70 Train Loss 4.6461153 Test MSE 6.406636370067324 Test RE 1.209826512994581\n",
      "71 Train Loss 4.5631657 Test MSE 6.514296016105623 Test RE 1.2199493641732884\n",
      "72 Train Loss 4.5277987 Test MSE 6.580079835820709 Test RE 1.2260936458677407\n",
      "73 Train Loss 4.4627337 Test MSE 6.586040724808876 Test RE 1.2266488787697871\n",
      "74 Train Loss 4.4031196 Test MSE 6.579379526314874 Test RE 1.2260283983400504\n",
      "75 Train Loss 4.3016376 Test MSE 6.504239352329007 Test RE 1.2190073315091206\n",
      "76 Train Loss 4.276639 Test MSE 6.426483636383256 Test RE 1.2116990385856918\n",
      "77 Train Loss 4.2585173 Test MSE 6.3853421636392875 Test RE 1.2078142450369846\n",
      "78 Train Loss 4.2248816 Test MSE 6.323771493416681 Test RE 1.201976964230125\n",
      "79 Train Loss 4.168159 Test MSE 6.100349353046083 Test RE 1.180552794778932\n",
      "80 Train Loss 4.1206403 Test MSE 5.941905171761463 Test RE 1.1651207009706737\n",
      "81 Train Loss 3.9644732 Test MSE 5.85131532925996 Test RE 1.1562049165073804\n",
      "82 Train Loss 3.8455932 Test MSE 5.805089994384611 Test RE 1.151628857015406\n",
      "83 Train Loss 3.7661414 Test MSE 5.768680810220433 Test RE 1.148011702105735\n",
      "84 Train Loss 3.7012603 Test MSE 5.84881462444262 Test RE 1.155957823672013\n",
      "85 Train Loss 3.660189 Test MSE 5.926494605583691 Test RE 1.1636088267375686\n",
      "86 Train Loss 3.6188965 Test MSE 5.947573807890603 Test RE 1.1656763368009513\n",
      "87 Train Loss 3.5695484 Test MSE 5.9181397172841885 Test RE 1.162788337462212\n",
      "88 Train Loss 3.4964457 Test MSE 5.84269279228722 Test RE 1.1553527068298364\n",
      "89 Train Loss 3.4117246 Test MSE 5.812897573107515 Test RE 1.1524030406830978\n",
      "90 Train Loss 3.3452396 Test MSE 5.7903487842702495 Test RE 1.1501657277638158\n",
      "91 Train Loss 3.3020966 Test MSE 5.730406121328495 Test RE 1.144196885586354\n",
      "92 Train Loss 3.2556047 Test MSE 5.7035849804398815 Test RE 1.1415160407170986\n",
      "93 Train Loss 3.202615 Test MSE 5.697633038476907 Test RE 1.140920274133948\n",
      "94 Train Loss 3.1394043 Test MSE 5.77865253251744 Test RE 1.1490034982754904\n",
      "95 Train Loss 3.1176128 Test MSE 5.816280371696374 Test RE 1.152738310687242\n",
      "96 Train Loss 3.1014712 Test MSE 5.824149322307685 Test RE 1.153517827345886\n",
      "97 Train Loss 3.087064 Test MSE 5.816978456714116 Test RE 1.1528074859288284\n",
      "98 Train Loss 3.0401182 Test MSE 5.834456223317952 Test RE 1.154538056912803\n",
      "99 Train Loss 3.0112014 Test MSE 5.838970736666622 Test RE 1.1549846426275945\n",
      "Training time: 211.38\n",
      "7\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 63.288696 Test MSE 5.228563358914877 Test RE 1.0929473661676063\n",
      "1 Train Loss 53.546803 Test MSE 6.908727730222654 Test RE 1.2563397449477454\n",
      "2 Train Loss 42.437775 Test MSE 7.694269944893534 Test RE 1.3258419917432547\n",
      "3 Train Loss 36.440304 Test MSE 8.004236863301317 Test RE 1.3522843632680306\n",
      "4 Train Loss 32.990623 Test MSE 7.716557014459211 Test RE 1.3277608070428923\n",
      "5 Train Loss 29.126207 Test MSE 6.62314140611916 Test RE 1.2300990242772254\n",
      "6 Train Loss 24.197662 Test MSE 6.389674853537801 Test RE 1.2082239487799897\n",
      "7 Train Loss 22.07301 Test MSE 6.1659199419645185 Test RE 1.186880517649431\n",
      "8 Train Loss 19.563263 Test MSE 5.64170180469712 Test RE 1.1353064992551916\n",
      "9 Train Loss 17.658033 Test MSE 5.792586777911121 Test RE 1.1503879781849118\n",
      "10 Train Loss 16.098122 Test MSE 5.7177236031491585 Test RE 1.1429300176294763\n",
      "11 Train Loss 15.1265335 Test MSE 5.881478188656074 Test RE 1.1591811377836554\n",
      "12 Train Loss 13.697147 Test MSE 6.2314715472556745 Test RE 1.1931728659470628\n",
      "13 Train Loss 12.880909 Test MSE 5.92340511332193 Test RE 1.1633054915164813\n",
      "14 Train Loss 12.593939 Test MSE 5.9025232253734945 Test RE 1.1612531701278728\n",
      "15 Train Loss 12.312664 Test MSE 5.951573066050813 Test RE 1.166068182059133\n",
      "16 Train Loss 11.97424 Test MSE 5.92674711865364 Test RE 1.163633615700259\n",
      "17 Train Loss 11.774094 Test MSE 5.879421450553532 Test RE 1.1589784386997655\n",
      "18 Train Loss 11.432019 Test MSE 5.774440651864123 Test RE 1.148584685435181\n",
      "19 Train Loss 11.203356 Test MSE 5.6954194873923205 Test RE 1.1406986267734662\n",
      "20 Train Loss 10.983655 Test MSE 5.622143661915827 Test RE 1.1333369016994062\n",
      "21 Train Loss 10.844988 Test MSE 5.6514358763394235 Test RE 1.1362854939303333\n",
      "22 Train Loss 10.563796 Test MSE 5.452866343475473 Test RE 1.1161446621796145\n",
      "23 Train Loss 10.316634 Test MSE 5.456441405611169 Test RE 1.1165104911258015\n",
      "24 Train Loss 9.969775 Test MSE 5.430748669798618 Test RE 1.1138787339640597\n",
      "25 Train Loss 9.787184 Test MSE 5.482836199126895 Test RE 1.1192077170526453\n",
      "26 Train Loss 9.616561 Test MSE 5.525824935869284 Test RE 1.1235867813474016\n",
      "27 Train Loss 9.434207 Test MSE 5.477631260015717 Test RE 1.1186763505297403\n",
      "28 Train Loss 9.216734 Test MSE 5.463468595575559 Test RE 1.117229220259388\n",
      "29 Train Loss 9.007527 Test MSE 5.4990474742897755 Test RE 1.1208610942303119\n",
      "30 Train Loss 8.795694 Test MSE 5.5100886827605935 Test RE 1.1219857849342316\n",
      "31 Train Loss 8.6387415 Test MSE 5.50008471680288 Test RE 1.1209667988969432\n",
      "32 Train Loss 8.456628 Test MSE 5.50380323891558 Test RE 1.1213456690184458\n",
      "33 Train Loss 8.277539 Test MSE 5.462710685755814 Test RE 1.1171517247681595\n",
      "34 Train Loss 8.211584 Test MSE 5.413504947552207 Test RE 1.1121089331702876\n",
      "35 Train Loss 7.940196 Test MSE 5.283936546954994 Test RE 1.0987195624979544\n",
      "36 Train Loss 7.711648 Test MSE 5.334562387441926 Test RE 1.1039704773870453\n",
      "37 Train Loss 7.607583 Test MSE 5.334122174850868 Test RE 1.1039249261594724\n",
      "38 Train Loss 7.5151954 Test MSE 5.2783202541687535 Test RE 1.0981354930937748\n",
      "39 Train Loss 7.3214755 Test MSE 5.305761072557563 Test RE 1.1009862744031154\n",
      "40 Train Loss 7.235524 Test MSE 5.300717959099064 Test RE 1.100462907572701\n",
      "41 Train Loss 6.976557 Test MSE 5.054058580474582 Test RE 1.074553878361981\n",
      "42 Train Loss 6.637768 Test MSE 5.046546444179192 Test RE 1.0737549959553947\n",
      "43 Train Loss 6.3732605 Test MSE 4.848753445720797 Test RE 1.0525024389590707\n",
      "44 Train Loss 6.1404247 Test MSE 4.781486021307722 Test RE 1.0451761850295072\n",
      "45 Train Loss 5.723818 Test MSE 4.638438584629218 Test RE 1.0294232330641204\n",
      "46 Train Loss 5.388651 Test MSE 4.556498856009692 Test RE 1.0202901479390136\n",
      "47 Train Loss 5.0075173 Test MSE 4.531407110373832 Test RE 1.0174770008511662\n",
      "48 Train Loss 4.6738997 Test MSE 4.266876487791429 Test RE 0.9873317342750315\n",
      "49 Train Loss 4.416858 Test MSE 4.22371311483349 Test RE 0.9823251570950826\n",
      "50 Train Loss 4.124069 Test MSE 4.0013647013678595 Test RE 0.9561193963050701\n",
      "51 Train Loss 4.036972 Test MSE 3.876821183354826 Test RE 0.9411220421217488\n",
      "52 Train Loss 3.867506 Test MSE 3.679357822635923 Test RE 0.9168410990528505\n",
      "53 Train Loss 3.756549 Test MSE 3.5752743757303866 Test RE 0.9037800456715647\n",
      "54 Train Loss 3.5629125 Test MSE 3.565460998741457 Test RE 0.9025388502114657\n",
      "55 Train Loss 3.372232 Test MSE 3.469692991180574 Test RE 0.8903352837411735\n",
      "56 Train Loss 3.2319329 Test MSE 3.335770203980188 Test RE 0.8729836759440183\n",
      "57 Train Loss 3.080203 Test MSE 3.4119614242781244 Test RE 0.882897153159531\n",
      "58 Train Loss 3.0047402 Test MSE 3.4278821842724714 Test RE 0.8849546257869688\n",
      "59 Train Loss 2.9016259 Test MSE 3.3254136484657293 Test RE 0.8716274475864764\n",
      "60 Train Loss 2.8055983 Test MSE 3.2759661216796374 Test RE 0.8651228067128293\n",
      "61 Train Loss 2.7249448 Test MSE 3.1683378138582365 Test RE 0.8507927895319704\n",
      "62 Train Loss 2.641522 Test MSE 3.07231885564769 Test RE 0.8378016346859098\n",
      "63 Train Loss 2.5871875 Test MSE 3.063201028933083 Test RE 0.836557524538139\n",
      "64 Train Loss 2.5269887 Test MSE 2.9771124155333135 Test RE 0.824718387009653\n",
      "65 Train Loss 2.4517221 Test MSE 2.9604606663054525 Test RE 0.8224087226797218\n",
      "66 Train Loss 2.4150002 Test MSE 2.9956284341340753 Test RE 0.8272790613923268\n",
      "67 Train Loss 2.2688065 Test MSE 2.9333735814417734 Test RE 0.8186377141177497\n",
      "68 Train Loss 2.1742074 Test MSE 2.943786344476917 Test RE 0.8200894093942432\n",
      "69 Train Loss 2.1248138 Test MSE 2.9747047725023115 Test RE 0.824384837446322\n",
      "70 Train Loss 2.0880694 Test MSE 2.942235752459336 Test RE 0.8198733965048763\n",
      "71 Train Loss 2.0377426 Test MSE 2.8848066378495245 Test RE 0.8118324649065982\n",
      "72 Train Loss 1.9896332 Test MSE 2.842233816377737 Test RE 0.8058198502593673\n",
      "73 Train Loss 1.9519917 Test MSE 2.8129781572316475 Test RE 0.8016618935949362\n",
      "74 Train Loss 1.9030216 Test MSE 2.7779402457968034 Test RE 0.7966535763817205\n",
      "75 Train Loss 1.8582608 Test MSE 2.8135317635974486 Test RE 0.8017407749920111\n",
      "76 Train Loss 1.8217106 Test MSE 2.782281971736668 Test RE 0.797275890175614\n",
      "77 Train Loss 1.7842208 Test MSE 2.738917043226816 Test RE 0.7910382783396745\n",
      "78 Train Loss 1.7540033 Test MSE 2.7231129707055963 Test RE 0.7887527558996377\n",
      "79 Train Loss 1.7344303 Test MSE 2.6976796298706502 Test RE 0.7850607169581882\n",
      "80 Train Loss 1.7121387 Test MSE 2.6405784578915426 Test RE 0.7767076778881048\n",
      "81 Train Loss 1.6944458 Test MSE 2.624695361900921 Test RE 0.7743682038164561\n",
      "82 Train Loss 1.6610786 Test MSE 2.5763823598145184 Test RE 0.7672081695689408\n",
      "83 Train Loss 1.6443474 Test MSE 2.5041789367395855 Test RE 0.7563812236513295\n",
      "84 Train Loss 1.6236929 Test MSE 2.4566673345322134 Test RE 0.7491714798279733\n",
      "85 Train Loss 1.5866963 Test MSE 2.4231295855147503 Test RE 0.744040164982444\n",
      "86 Train Loss 1.5456957 Test MSE 2.3804261710763535 Test RE 0.7374548199212141\n",
      "87 Train Loss 1.5184057 Test MSE 2.2546534167718577 Test RE 0.7177082794786661\n",
      "88 Train Loss 1.4787531 Test MSE 1.9874315709884336 Test RE 0.6738359113347334\n",
      "89 Train Loss 1.3964415 Test MSE 1.8755101713175453 Test RE 0.6545875970656257\n",
      "90 Train Loss 1.356903 Test MSE 1.8415216634595197 Test RE 0.6486291709262485\n",
      "91 Train Loss 1.3234712 Test MSE 1.841666064283485 Test RE 0.6486546011866005\n",
      "92 Train Loss 1.280502 Test MSE 1.8121197868448513 Test RE 0.6434303044202027\n",
      "93 Train Loss 1.2417972 Test MSE 1.758154197577524 Test RE 0.6337770974588068\n",
      "94 Train Loss 1.2083001 Test MSE 1.7451398474658308 Test RE 0.6314270425906234\n",
      "95 Train Loss 1.1813313 Test MSE 1.701766774302928 Test RE 0.6235310434173256\n",
      "96 Train Loss 1.1313784 Test MSE 1.6238406627851785 Test RE 0.6090876117900056\n",
      "97 Train Loss 1.0578625 Test MSE 1.507218539598678 Test RE 0.5868082000627608\n",
      "98 Train Loss 1.026151 Test MSE 1.4296467164257076 Test RE 0.571508147112245\n",
      "99 Train Loss 0.9888807 Test MSE 1.3548203679813482 Test RE 0.5563510587008588\n",
      "Training time: 195.62\n",
      "8\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.07067 Test MSE 4.787688626038273 Test RE 1.0458538732717866\n",
      "1 Train Loss 63.086216 Test MSE 4.933094556405843 Test RE 1.0616167943595305\n",
      "2 Train Loss 52.77174 Test MSE 6.245369829942464 Test RE 1.194502713761186\n",
      "3 Train Loss 45.94883 Test MSE 6.910033601060287 Test RE 1.2564584744722036\n",
      "4 Train Loss 40.55214 Test MSE 7.347804550248808 Test RE 1.295647490220613\n",
      "5 Train Loss 36.369583 Test MSE 8.455712416756962 Test RE 1.3898987433456835\n",
      "6 Train Loss 35.237583 Test MSE 8.33734179338741 Test RE 1.3801359330717595\n",
      "7 Train Loss 33.234783 Test MSE 7.377418937772898 Test RE 1.298255835554952\n",
      "8 Train Loss 31.247849 Test MSE 7.2819181122798655 Test RE 1.2898254909626978\n",
      "9 Train Loss 29.518108 Test MSE 7.200232522859795 Test RE 1.2825707199928993\n",
      "10 Train Loss 28.201134 Test MSE 7.604405152408189 Test RE 1.3180767031514313\n",
      "11 Train Loss 26.915861 Test MSE 7.627599676513272 Test RE 1.320085333962743\n",
      "12 Train Loss 26.245388 Test MSE 7.931620437648007 Test RE 1.3461362573368396\n",
      "13 Train Loss 25.511354 Test MSE 7.9505524262528855 Test RE 1.3477418464497997\n",
      "14 Train Loss 24.702019 Test MSE 8.095839307930165 Test RE 1.3600002868618204\n",
      "15 Train Loss 23.874582 Test MSE 8.315335670534827 Test RE 1.37831331926799\n",
      "16 Train Loss 23.254696 Test MSE 8.254781699645948 Test RE 1.3732855698681892\n",
      "17 Train Loss 22.769037 Test MSE 8.31504128166851 Test RE 1.3782889207528288\n",
      "18 Train Loss 22.281847 Test MSE 8.01601967217128 Test RE 1.3532793268657435\n",
      "19 Train Loss 21.872467 Test MSE 8.053504196382082 Test RE 1.3564397399858603\n",
      "20 Train Loss 21.315298 Test MSE 7.976610165096245 Test RE 1.3499486350313608\n",
      "21 Train Loss 21.017462 Test MSE 7.917065189207014 Test RE 1.3449005486334167\n",
      "22 Train Loss 20.467136 Test MSE 7.821159327270738 Test RE 1.3367297903488038\n",
      "23 Train Loss 19.440868 Test MSE 7.967597743742656 Test RE 1.3491857956710869\n",
      "24 Train Loss 18.822895 Test MSE 7.822973306503652 Test RE 1.336884796748571\n",
      "25 Train Loss 17.850422 Test MSE 7.73018228168622 Test RE 1.3289325159328043\n",
      "26 Train Loss 16.707321 Test MSE 7.7612929279471325 Test RE 1.3316040205308155\n",
      "27 Train Loss 16.034101 Test MSE 7.648064802198346 Test RE 1.3218550660315045\n",
      "28 Train Loss 15.422134 Test MSE 7.570924331575659 Test RE 1.3151718755741666\n",
      "29 Train Loss 14.47334 Test MSE 7.238083356116427 Test RE 1.2859374679915847\n",
      "30 Train Loss 13.899706 Test MSE 7.351373631558357 Test RE 1.2959621222854663\n",
      "31 Train Loss 12.40057 Test MSE 6.758102888209475 Test RE 1.2425688439769318\n",
      "32 Train Loss 11.452287 Test MSE 6.657630321594624 Test RE 1.2332976344230622\n",
      "33 Train Loss 9.700726 Test MSE 6.258354302133084 Test RE 1.195743787911135\n",
      "34 Train Loss 8.474183 Test MSE 5.751765535231982 Test RE 1.146327331751169\n",
      "35 Train Loss 8.006737 Test MSE 5.70333480185223 Test RE 1.1414910050593885\n",
      "36 Train Loss 7.2130756 Test MSE 5.947388681536808 Test RE 1.1656581950261555\n",
      "37 Train Loss 6.7960854 Test MSE 6.126636000064134 Test RE 1.1830935850089428\n",
      "38 Train Loss 6.3900003 Test MSE 6.202261905732119 Test RE 1.1903731187877822\n",
      "39 Train Loss 6.0929856 Test MSE 6.3491566925618885 Test RE 1.2043870659248883\n",
      "40 Train Loss 5.896182 Test MSE 6.337241743384035 Test RE 1.2032564473112024\n",
      "41 Train Loss 5.568896 Test MSE 6.2184141835854 Test RE 1.1919221291139683\n",
      "42 Train Loss 5.3587103 Test MSE 6.256852397242294 Test RE 1.1956002996140653\n",
      "43 Train Loss 5.2590666 Test MSE 6.27735160889698 Test RE 1.1975572597893356\n",
      "44 Train Loss 5.084898 Test MSE 6.3409996224255245 Test RE 1.2036131499781157\n",
      "45 Train Loss 5.039197 Test MSE 6.313625092490233 Test RE 1.201012299702216\n",
      "46 Train Loss 4.9149265 Test MSE 6.255315867348943 Test RE 1.195453485506646\n",
      "47 Train Loss 4.8418365 Test MSE 6.270767739919996 Test RE 1.1969290785868054\n",
      "48 Train Loss 4.741021 Test MSE 6.319999639797837 Test RE 1.201618447370018\n",
      "49 Train Loss 4.673759 Test MSE 6.279707581138025 Test RE 1.1977819681662414\n",
      "50 Train Loss 4.566275 Test MSE 6.212747524339185 Test RE 1.191378923419893\n",
      "51 Train Loss 4.4829907 Test MSE 6.2538654544728125 Test RE 1.1953148832612892\n",
      "52 Train Loss 4.369262 Test MSE 6.234907905450582 Test RE 1.1935018094573384\n",
      "53 Train Loss 4.2217574 Test MSE 6.288288751378336 Test RE 1.198600068524893\n",
      "54 Train Loss 4.1618996 Test MSE 6.319574445998732 Test RE 1.2015780257453748\n",
      "55 Train Loss 4.0798974 Test MSE 6.315976299499556 Test RE 1.201235908615085\n",
      "56 Train Loss 4.015403 Test MSE 6.373118823950976 Test RE 1.2066576432783649\n",
      "57 Train Loss 3.9630537 Test MSE 6.461194537476178 Test RE 1.2149669630010476\n",
      "58 Train Loss 3.8586926 Test MSE 6.538949309099364 Test RE 1.222255627765566\n",
      "59 Train Loss 3.8151708 Test MSE 6.538294031909137 Test RE 1.2221943842643648\n",
      "60 Train Loss 3.7859335 Test MSE 6.517104513862328 Test RE 1.2202123132193545\n",
      "61 Train Loss 3.755127 Test MSE 6.534922843732433 Test RE 1.221879257835246\n",
      "62 Train Loss 3.7121015 Test MSE 6.5310977078024495 Test RE 1.2215215995652942\n",
      "63 Train Loss 3.6513543 Test MSE 6.541794136619539 Test RE 1.22252147539475\n",
      "64 Train Loss 3.6180243 Test MSE 6.558975461240619 Test RE 1.2241258338033922\n",
      "65 Train Loss 3.5597591 Test MSE 6.6408987267898185 Test RE 1.2317469312204767\n",
      "66 Train Loss 3.5389562 Test MSE 6.650255862886825 Test RE 1.232614401652995\n",
      "67 Train Loss 3.5026963 Test MSE 6.656924920241617 Test RE 1.2332322963956162\n",
      "68 Train Loss 3.4685836 Test MSE 6.654793541288253 Test RE 1.2330348556989013\n",
      "69 Train Loss 3.4287853 Test MSE 6.6630661528828545 Test RE 1.2338010139801348\n",
      "70 Train Loss 3.3887253 Test MSE 6.725158272469872 Test RE 1.2395364867668146\n",
      "71 Train Loss 3.3519015 Test MSE 6.734770659433658 Test RE 1.240422016101469\n",
      "72 Train Loss 3.315886 Test MSE 6.751301458626034 Test RE 1.2419434190565142\n",
      "73 Train Loss 3.2938004 Test MSE 6.777822157354915 Test RE 1.244380350999226\n",
      "74 Train Loss 3.2252703 Test MSE 6.753920065690279 Test RE 1.2421842501421974\n",
      "75 Train Loss 3.183911 Test MSE 6.718107357896543 Test RE 1.2388865274997551\n",
      "76 Train Loss 3.1646643 Test MSE 6.698773389733241 Test RE 1.237102554017897\n",
      "77 Train Loss 3.118674 Test MSE 6.666262780215058 Test RE 1.2340969384861984\n",
      "78 Train Loss 3.0597444 Test MSE 6.703102257362024 Test RE 1.2375022084025353\n",
      "79 Train Loss 3.0013258 Test MSE 6.738933267733222 Test RE 1.2408052951797883\n",
      "80 Train Loss 2.960244 Test MSE 6.779705107610566 Test RE 1.2445531899682452\n",
      "81 Train Loss 2.9133167 Test MSE 6.803145866610047 Test RE 1.2467028482391311\n",
      "82 Train Loss 2.8648767 Test MSE 6.71485651648208 Test RE 1.2385867473128125\n",
      "83 Train Loss 2.830319 Test MSE 6.717670424456865 Test RE 1.2388462393855026\n",
      "84 Train Loss 2.7983272 Test MSE 6.789272884773994 Test RE 1.245431060704918\n",
      "85 Train Loss 2.7546902 Test MSE 6.759850319385377 Test RE 1.2427294780507736\n",
      "86 Train Loss 2.718824 Test MSE 6.721851095968806 Test RE 1.2392316708890998\n",
      "87 Train Loss 2.6719477 Test MSE 6.7848699357134565 Test RE 1.245027154502796\n",
      "88 Train Loss 2.641234 Test MSE 6.7756250299397465 Test RE 1.2441786428599595\n",
      "89 Train Loss 2.5829034 Test MSE 6.76764412735548 Test RE 1.2434456776924805\n",
      "90 Train Loss 2.5351353 Test MSE 6.77286548240988 Test RE 1.2439252551843787\n",
      "91 Train Loss 2.5039124 Test MSE 6.752624678166723 Test RE 1.242065120279295\n",
      "92 Train Loss 2.471977 Test MSE 6.735751142737775 Test RE 1.240512306393143\n",
      "93 Train Loss 2.4541116 Test MSE 6.709250647851995 Test RE 1.2380696249932293\n",
      "94 Train Loss 2.4352412 Test MSE 6.690472509569235 Test RE 1.2363358298220533\n",
      "95 Train Loss 2.4092228 Test MSE 6.7336283348792465 Test RE 1.2403168139581058\n",
      "96 Train Loss 2.3869662 Test MSE 6.709233980748328 Test RE 1.238068087187543\n",
      "97 Train Loss 2.3514547 Test MSE 6.702526681195574 Test RE 1.2374490768791988\n",
      "98 Train Loss 2.3300264 Test MSE 6.744479860186779 Test RE 1.241315822993283\n",
      "99 Train Loss 2.3139591 Test MSE 6.725187233073651 Test RE 1.2395391556769697\n",
      "Training time: 194.21\n",
      "9\n",
      "KG_rowdy_tune54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.26379 Test MSE 6.503311725617731 Test RE 1.2189204017375272\n",
      "1 Train Loss 52.734566 Test MSE 8.39097497266488 Test RE 1.3845679462245342\n",
      "2 Train Loss 46.41202 Test MSE 9.072528740227234 Test RE 1.4397007689236372\n",
      "3 Train Loss 42.09961 Test MSE 9.00434252649332 Test RE 1.4342804008610779\n",
      "4 Train Loss 36.77755 Test MSE 9.439572360895443 Test RE 1.4685347248536182\n",
      "5 Train Loss 33.770733 Test MSE 9.43549507201958 Test RE 1.4682175342661004\n",
      "6 Train Loss 31.80402 Test MSE 9.460042983222909 Test RE 1.4701261920429278\n",
      "7 Train Loss 29.186672 Test MSE 9.196713091158792 Test RE 1.4495205584700772\n",
      "8 Train Loss 28.01477 Test MSE 9.209559113868476 Test RE 1.4505325546057253\n",
      "9 Train Loss 26.69381 Test MSE 9.100063351218244 Test RE 1.4418838189751748\n",
      "10 Train Loss 25.490622 Test MSE 9.362007305181121 Test RE 1.4624887974854528\n",
      "11 Train Loss 24.527184 Test MSE 9.183607735004268 Test RE 1.4484874037262214\n",
      "12 Train Loss 23.526228 Test MSE 9.357246356875619 Test RE 1.4621168837078342\n",
      "13 Train Loss 22.591469 Test MSE 9.49653751503505 Test RE 1.4729591560733286\n",
      "14 Train Loss 22.084265 Test MSE 9.394125481690534 Test RE 1.4649953248641892\n",
      "15 Train Loss 21.149345 Test MSE 9.224403630667249 Test RE 1.4517011113612615\n",
      "16 Train Loss 20.469334 Test MSE 9.283040136788001 Test RE 1.4563077958969295\n",
      "17 Train Loss 19.800888 Test MSE 9.355933976438005 Test RE 1.4620143470849651\n",
      "18 Train Loss 19.134972 Test MSE 9.28885936060939 Test RE 1.4567641794308457\n",
      "19 Train Loss 18.370106 Test MSE 8.867987981852917 Test RE 1.4233791772998252\n",
      "20 Train Loss 17.70123 Test MSE 8.785369744217217 Test RE 1.4167332357529618\n",
      "21 Train Loss 16.615738 Test MSE 8.636319707321203 Test RE 1.4046638827415296\n",
      "22 Train Loss 15.729307 Test MSE 8.371968980044734 Test RE 1.3829989982528745\n",
      "23 Train Loss 15.160307 Test MSE 8.204632375908517 Test RE 1.3691077331566464\n",
      "24 Train Loss 14.519009 Test MSE 7.8680556333901 Test RE 1.3407313710214546\n",
      "25 Train Loss 13.392465 Test MSE 7.401466787907992 Test RE 1.300370047963406\n",
      "26 Train Loss 11.310765 Test MSE 6.530125832774841 Test RE 1.2214307105172764\n",
      "27 Train Loss 10.2941065 Test MSE 6.2009155320060785 Test RE 1.1902439099521915\n",
      "28 Train Loss 9.790263 Test MSE 6.1685779456913306 Test RE 1.1871363102121566\n",
      "29 Train Loss 9.343942 Test MSE 6.0954447831363305 Test RE 1.1800781278679429\n",
      "30 Train Loss 8.904137 Test MSE 6.054164199487853 Test RE 1.176075378776614\n",
      "31 Train Loss 8.58927 Test MSE 6.046970857886634 Test RE 1.1753764857416082\n",
      "32 Train Loss 8.320953 Test MSE 5.868984825133759 Test RE 1.157949324137815\n",
      "33 Train Loss 8.071963 Test MSE 5.828388857075204 Test RE 1.1539375872998134\n",
      "34 Train Loss 7.8314877 Test MSE 5.846424556236015 Test RE 1.1557216133859844\n",
      "35 Train Loss 7.6224174 Test MSE 5.838749355365848 Test RE 1.1549627471225699\n",
      "36 Train Loss 7.438144 Test MSE 5.8656324448334685 Test RE 1.1576185649764703\n",
      "37 Train Loss 7.256377 Test MSE 5.85739934161372 Test RE 1.1568058529654506\n",
      "38 Train Loss 7.018899 Test MSE 5.842928045057176 Test RE 1.1553759664122158\n",
      "39 Train Loss 6.8559017 Test MSE 5.8464903744247705 Test RE 1.1557281188397432\n",
      "40 Train Loss 6.6775 Test MSE 5.878256458277739 Test RE 1.1588636087091282\n",
      "41 Train Loss 6.4913006 Test MSE 5.897738263504393 Test RE 1.1607823817456993\n",
      "42 Train Loss 6.241581 Test MSE 5.887021262372114 Test RE 1.1597272516238106\n",
      "43 Train Loss 6.1292267 Test MSE 5.852595572192447 Test RE 1.156331395951044\n",
      "44 Train Loss 5.950971 Test MSE 5.918777379615137 Test RE 1.1628509793045352\n",
      "45 Train Loss 5.770958 Test MSE 6.065477721154412 Test RE 1.1771737421148325\n",
      "46 Train Loss 5.5370646 Test MSE 5.949273818313372 Test RE 1.1658429190410786\n",
      "47 Train Loss 5.276246 Test MSE 5.857621251167709 Test RE 1.1568277657482924\n",
      "48 Train Loss 4.896612 Test MSE 5.974942117172857 Test RE 1.1683552421040713\n",
      "49 Train Loss 4.401439 Test MSE 5.893127093511577 Test RE 1.1603285118647457\n",
      "50 Train Loss 4.2226944 Test MSE 5.83217196157752 Test RE 1.1543120268260618\n",
      "51 Train Loss 3.9352934 Test MSE 5.733339472391703 Test RE 1.1444897009357058\n",
      "52 Train Loss 3.6287513 Test MSE 5.66891294810148 Test RE 1.138041119739186\n",
      "53 Train Loss 3.3201468 Test MSE 5.648841057256607 Test RE 1.1360246050282636\n",
      "54 Train Loss 3.003714 Test MSE 5.655391584151242 Test RE 1.1366830944025887\n",
      "55 Train Loss 2.6907287 Test MSE 5.606130189067722 Test RE 1.1317217169606628\n",
      "56 Train Loss 2.54665 Test MSE 5.611764430235901 Test RE 1.132290272415726\n",
      "57 Train Loss 2.4193583 Test MSE 5.630928310461551 Test RE 1.134221980499246\n",
      "58 Train Loss 2.2339861 Test MSE 5.620770014316788 Test RE 1.1331984402235002\n",
      "59 Train Loss 2.1023526 Test MSE 5.611869202664368 Test RE 1.1323008423754353\n",
      "60 Train Loss 2.0298724 Test MSE 5.587743604476692 Test RE 1.1298643228250413\n",
      "61 Train Loss 1.96891 Test MSE 5.577355426463552 Test RE 1.1288135684599467\n",
      "62 Train Loss 1.8645239 Test MSE 5.592001831993535 Test RE 1.1302947562363674\n",
      "63 Train Loss 1.824199 Test MSE 5.51993953989446 Test RE 1.1229882720842335\n",
      "64 Train Loss 1.782758 Test MSE 5.511523195352083 Test RE 1.1221318259588495\n",
      "65 Train Loss 1.7358241 Test MSE 5.545781470857641 Test RE 1.1256138714702661\n",
      "66 Train Loss 1.6921748 Test MSE 5.5208300333564075 Test RE 1.1230788503757931\n",
      "67 Train Loss 1.6619306 Test MSE 5.520200798457017 Test RE 1.1230148472693564\n",
      "68 Train Loss 1.6244879 Test MSE 5.53366066123727 Test RE 1.1243831329018845\n",
      "69 Train Loss 1.5930796 Test MSE 5.520300228998191 Test RE 1.123024961165143\n",
      "70 Train Loss 1.5654701 Test MSE 5.509661449748899 Test RE 1.121942286663541\n",
      "71 Train Loss 1.5418836 Test MSE 5.525659523601482 Test RE 1.123569964272067\n",
      "72 Train Loss 1.5012062 Test MSE 5.57699578969868 Test RE 1.1287771740244699\n",
      "73 Train Loss 1.4662664 Test MSE 5.552025486961279 Test RE 1.1262473596430385\n",
      "74 Train Loss 1.4515718 Test MSE 5.533368294816481 Test RE 1.1243534295793947\n",
      "75 Train Loss 1.4095793 Test MSE 5.528825580935705 Test RE 1.1238918061715462\n",
      "76 Train Loss 1.3791566 Test MSE 5.545636821019443 Test RE 1.1255991917603863\n",
      "77 Train Loss 1.3656399 Test MSE 5.55228709307268 Test RE 1.1262738931777185\n",
      "78 Train Loss 1.3432797 Test MSE 5.584362948111921 Test RE 1.1295224799275494\n",
      "79 Train Loss 1.3282688 Test MSE 5.612255704768631 Test RE 1.1323398337620334\n",
      "80 Train Loss 1.3077799 Test MSE 5.631695285858651 Test RE 1.1342992227127413\n",
      "81 Train Loss 1.2899855 Test MSE 5.646828467114523 Test RE 1.1358222134596345\n",
      "82 Train Loss 1.2716099 Test MSE 5.650473846230054 Test RE 1.136188776263659\n",
      "83 Train Loss 1.2605507 Test MSE 5.646904996753502 Test RE 1.1358299101490181\n",
      "84 Train Loss 1.2446654 Test MSE 5.665942315568532 Test RE 1.1377429016318223\n",
      "85 Train Loss 1.2183937 Test MSE 5.686484737201 Test RE 1.1398035340080437\n",
      "86 Train Loss 1.2055714 Test MSE 5.6776650706449265 Test RE 1.13891928051069\n",
      "87 Train Loss 1.1970611 Test MSE 5.699602903210494 Test RE 1.1411174844820529\n",
      "88 Train Loss 1.1850991 Test MSE 5.7209124796596615 Test RE 1.143248689439063\n",
      "89 Train Loss 1.1786196 Test MSE 5.707117298324565 Test RE 1.1418694652240413\n",
      "90 Train Loss 1.1699952 Test MSE 5.670937681624969 Test RE 1.138244335445343\n",
      "91 Train Loss 1.158269 Test MSE 5.667465603069766 Test RE 1.137895832333749\n",
      "92 Train Loss 1.150921 Test MSE 5.691644044253598 Test RE 1.1403204845875539\n",
      "93 Train Loss 1.1429232 Test MSE 5.71074871514019 Test RE 1.1422326910308078\n",
      "94 Train Loss 1.1366426 Test MSE 5.708568250714749 Test RE 1.1420146079337803\n",
      "95 Train Loss 1.1286683 Test MSE 5.712851481799694 Test RE 1.1424429636135418\n",
      "96 Train Loss 1.1172526 Test MSE 5.731982826519157 Test RE 1.1443542860438363\n",
      "97 Train Loss 1.1074791 Test MSE 5.751390713725963 Test RE 1.1462899801645605\n",
      "98 Train Loss 1.0927235 Test MSE 5.7832668665772955 Test RE 1.149462154334336\n",
      "99 Train Loss 1.0877048 Test MSE 5.804710507637924 Test RE 1.151591214616126\n",
      "Training time: 195.93\n",
      "0\n",
      "KG_rowdy_tune55\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.68249 Test MSE 6.560191671222678 Test RE 1.2242393214248943\n",
      "1 Train Loss 46.626423 Test MSE 8.655322034765051 Test RE 1.406208361042144\n",
      "2 Train Loss 36.217182 Test MSE 7.682197857983323 Test RE 1.32480147958874\n",
      "3 Train Loss 26.282913 Test MSE 6.872426325059704 Test RE 1.2530347250273328\n",
      "4 Train Loss 22.087748 Test MSE 6.369717268254072 Test RE 1.2063355826734434\n",
      "5 Train Loss 18.986942 Test MSE 6.175368210832816 Test RE 1.1877895201782072\n",
      "6 Train Loss 16.294361 Test MSE 6.177494265918321 Test RE 1.187993968605254\n",
      "7 Train Loss 13.23556 Test MSE 6.095182607287704 Test RE 1.180052748972511\n",
      "8 Train Loss 11.287529 Test MSE 5.929792102921405 Test RE 1.1639324972786271\n",
      "9 Train Loss 9.746696 Test MSE 5.720642178688965 Test RE 1.1432216810831555\n",
      "10 Train Loss 8.63705 Test MSE 5.6313794896633915 Test RE 1.1342674194650177\n",
      "11 Train Loss 7.6768007 Test MSE 5.558700919398192 Test RE 1.1269242233996741\n",
      "12 Train Loss 6.673129 Test MSE 5.4554835823126675 Test RE 1.1164124907426296\n",
      "13 Train Loss 5.8757505 Test MSE 5.3829938217681494 Test RE 1.1089705189818462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5759/2769935145.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mnan_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5759/3927191029.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(max_iter, rep)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnan_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_BC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_BC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt_coll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_BC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_BC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt_coll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5759/4004223700.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(xt_BC, y_BC, xt_coll, f_hat, seed)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001b[0;32m--> 426\u001b[0;31m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001b[0m\u001b[1;32m    427\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mopt_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtolerance_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# evaluate objective and gradient using initial step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mf_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mls_func_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgtd_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mflat_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5759/4004223700.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_BC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_BC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt_coll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print(loss.cpu().detach().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5759/834794683.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, xt_BC, y_BC, xt_coll, f_hat)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mloss_BC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_BC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_BC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_BC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mloss_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_PDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_coll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_BC\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5759/834794683.py\u001b[0m in \u001b[0;36mloss_PDE\u001b[0;34m(self, xt_coll, f_hat)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0my_x_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxt_coll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_unused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0my_xx_tt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_x_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_coll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_unused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    226\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    227\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(75):\n",
    "#for tune_reps in range(1,5):\n",
    "    max_reps = 10 #10\n",
    "    max_iter = 100 #100\n",
    "    label = \"KG_rowdy_tune\"+str(tune_reps)\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "    alpha_full = []\n",
    "    omega_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "    n_val = lrnr_tune[tune_reps,1]\n",
    "    rowdy_terms = int(lrnr_tune[tune_reps,2])\n",
    "\n",
    "    N_I = 200  #Total number of data points for 'y'\n",
    "    N_B = 400\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    for reps in range(max_reps):\n",
    "        print(reps)\n",
    "        print(label)\n",
    "\n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss = []\n",
    "        alpha_val = []\n",
    "        omega_val = []\n",
    "\n",
    "        torch.manual_seed(reps*36)\n",
    "\n",
    "        layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "        PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lrnr_tune[tune_reps,0], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nan_flag = train_model(max_iter,reps)\n",
    "        \n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        #elapsed_time[reps] = time.time() - start_time\n",
    "        alpha_full.append(alpha_val)\n",
    "        omega_full.append(omega_val)\n",
    "        \n",
    "        if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "\n",
    "        \n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,  \"omega\": omega_full,\"label\": label}\n",
    "    savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [],
   "source": [
    "for tune_reps in range(75):\n",
    "    label = \"KG_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [],
   "source": [
    "lrnr_tune[1]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
