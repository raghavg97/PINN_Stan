{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660687406024,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "T7Wci76Yf-U8"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1]).reshape(-1,1)\n",
    "n_value = np.array([1.0,3.0,5.0,8.0,10.0]).reshape(-1,1)\n",
    "r_value = np.array([2,6,8]).reshape(-1,1)\n",
    "\n",
    "LR_tune,N_value,R_value = np.meshgrid(lr_tune,n_value,r_value)\n",
    "\n",
    "LR_tune = LR_tune.flatten('F').reshape(-1,1)\n",
    "N_value = N_value.flatten('F').reshape(-1,1)\n",
    "R_value = R_value.flatten('F').reshape(-1,1)\n",
    "\n",
    "\n",
    "lrnr_tune = np.hstack((LR_tune,N_value,R_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred1 = self.forward(xt_test_tensor[:250000])\n",
    "        y_pred1 = y_pred1.cpu().detach().numpy()\n",
    "        \n",
    "        y_pred2 = self.forward(xt_test_tensor[250000:])\n",
    "          \n",
    "        y_pred2 = y_pred2.cpu().detach().numpy()\n",
    "        \n",
    "        y_pred = np.vstack((y_pred1.reshape(-1,1),y_pred2.reshape(-1,1)))\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    nan_flag = 0\n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        \n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "    return nan_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 57.862 Test MSE 6.894908259881753 Test RE 1.2550825930192808\n",
      "1 Train Loss 42.824253 Test MSE 8.039215796348868 Test RE 1.3552359188099874\n",
      "2 Train Loss 32.18009 Test MSE 7.287693770666184 Test RE 1.2903369025662268\n",
      "3 Train Loss 22.486507 Test MSE 6.621594680993979 Test RE 1.2299553812500528\n",
      "4 Train Loss 17.312073 Test MSE 6.3138759826190425 Test RE 1.2010361623114731\n",
      "5 Train Loss 14.320543 Test MSE 6.034206305335593 Test RE 1.1741352790960895\n",
      "6 Train Loss 11.989084 Test MSE 5.900615650500739 Test RE 1.1610655083188806\n",
      "7 Train Loss 10.136318 Test MSE 6.017608418469343 Test RE 1.1725193595201775\n",
      "8 Train Loss 8.826788 Test MSE 5.820653979239951 Test RE 1.1531716355298334\n",
      "9 Train Loss 7.334756 Test MSE 5.685947812372084 Test RE 1.1397497219173902\n",
      "10 Train Loss 6.1090407 Test MSE 5.587705274224364 Test RE 1.129860447552487\n",
      "11 Train Loss 5.0493 Test MSE 5.418997355684083 Test RE 1.1126729492464402\n",
      "12 Train Loss 4.2507715 Test MSE 5.260972932060488 Test RE 1.0963294840984088\n",
      "13 Train Loss 3.5124753 Test MSE 4.895875869658875 Test RE 1.0576044253095263\n",
      "14 Train Loss 2.9967499 Test MSE 4.557990777519298 Test RE 1.0204571696243492\n",
      "15 Train Loss 2.5711455 Test MSE 4.071586925631894 Test RE 0.964472648172193\n",
      "16 Train Loss 2.2928467 Test MSE 3.815666578842745 Test RE 0.9336697091943806\n",
      "17 Train Loss 2.0616782 Test MSE 3.3675125250509077 Test RE 0.8771273843967224\n",
      "18 Train Loss 1.8607159 Test MSE 2.943546114634461 Test RE 0.8200559467128503\n",
      "19 Train Loss 1.696712 Test MSE 2.629536675400146 Test RE 0.7750820451490816\n",
      "20 Train Loss 1.5820465 Test MSE 2.3275914018438044 Test RE 0.729224803970326\n",
      "21 Train Loss 1.4807594 Test MSE 1.9906454130264788 Test RE 0.6743805155937345\n",
      "22 Train Loss 1.3885396 Test MSE 1.907539538963078 Test RE 0.6601533547477502\n",
      "23 Train Loss 1.283834 Test MSE 1.6953346373552383 Test RE 0.6223515533617625\n",
      "24 Train Loss 1.2026126 Test MSE 1.5995955157120938 Test RE 0.604523445924466\n",
      "25 Train Loss 1.1015588 Test MSE 1.2888390569319936 Test RE 0.5426345029013062\n",
      "26 Train Loss 0.7885384 Test MSE 0.9724471288359264 Test RE 0.4713473388618317\n",
      "27 Train Loss 0.65704864 Test MSE 0.8295435063177474 Test RE 0.43533906912261533\n",
      "28 Train Loss 0.5259331 Test MSE 0.6665995826201099 Test RE 0.3902479038293065\n",
      "29 Train Loss 0.403363 Test MSE 0.5121653031447126 Test RE 0.34206854244080653\n",
      "30 Train Loss 0.30791983 Test MSE 0.38922301697786077 Test RE 0.2981997792455059\n",
      "31 Train Loss 0.23586695 Test MSE 0.3726095422430319 Test RE 0.29176624534101875\n",
      "32 Train Loss 0.19672783 Test MSE 0.31833561242463376 Test RE 0.269681200847097\n",
      "33 Train Loss 0.17187527 Test MSE 0.2718575407643773 Test RE 0.24921762459426527\n",
      "34 Train Loss 0.14997801 Test MSE 0.15536557115616084 Test RE 0.18840197591054988\n",
      "35 Train Loss 0.117818594 Test MSE 0.06388555121259881 Test RE 0.12081180790244149\n",
      "36 Train Loss 0.083883405 Test MSE 0.03636505463201589 Test RE 0.09114863777317488\n",
      "37 Train Loss 0.04950248 Test MSE 0.029432093134192382 Test RE 0.08200090298768818\n",
      "38 Train Loss 0.035829674 Test MSE 0.021370132989310404 Test RE 0.06987336724482582\n",
      "39 Train Loss 0.028743345 Test MSE 0.01723166896032623 Test RE 0.06274393204738546\n",
      "40 Train Loss 0.02276919 Test MSE 0.013489442533218396 Test RE 0.05551432472578806\n",
      "41 Train Loss 0.01803112 Test MSE 0.011987262149846918 Test RE 0.05233208785282181\n",
      "42 Train Loss 0.01491138 Test MSE 0.009621790406080947 Test RE 0.046885225208655415\n",
      "43 Train Loss 0.013340491 Test MSE 0.009825847452360724 Test RE 0.047379783179709284\n",
      "44 Train Loss 0.011808774 Test MSE 0.008710783127004768 Test RE 0.04461045582973028\n",
      "45 Train Loss 0.010284289 Test MSE 0.008302332072451072 Test RE 0.0435520006815407\n",
      "46 Train Loss 0.0091722775 Test MSE 0.008375102768060153 Test RE 0.04374245288257299\n",
      "47 Train Loss 0.00865996 Test MSE 0.008019088444017079 Test RE 0.04280264054635312\n",
      "48 Train Loss 0.00784608 Test MSE 0.007461268914156766 Test RE 0.04128710261721798\n",
      "49 Train Loss 0.0071895276 Test MSE 0.007097653148100637 Test RE 0.04026849943632841\n",
      "50 Train Loss 0.006324077 Test MSE 0.00785088686276297 Test RE 0.04235136571802983\n",
      "51 Train Loss 0.00576278 Test MSE 0.00740716653476081 Test RE 0.04113714189927295\n",
      "52 Train Loss 0.005141419 Test MSE 0.007077078302537563 Test RE 0.04021009143557513\n",
      "53 Train Loss 0.0044888062 Test MSE 0.006119645675161909 Test RE 0.03739135460757398\n",
      "54 Train Loss 0.0040925057 Test MSE 0.005795546330348342 Test RE 0.03638775410715328\n",
      "55 Train Loss 0.0036569298 Test MSE 0.004863009533544838 Test RE 0.03333194225433819\n",
      "56 Train Loss 0.0033721253 Test MSE 0.0043819621703216705 Test RE 0.03164042965324313\n",
      "57 Train Loss 0.0030934166 Test MSE 0.0042105744635718605 Test RE 0.031015496399117257\n",
      "58 Train Loss 0.0029253992 Test MSE 0.004069787999747993 Test RE 0.030492564681180674\n",
      "59 Train Loss 0.002790237 Test MSE 0.0036335695983102712 Test RE 0.028812092598614187\n",
      "60 Train Loss 0.002629209 Test MSE 0.003732691690507471 Test RE 0.029202438652425246\n",
      "61 Train Loss 0.0024841218 Test MSE 0.003612310665665349 Test RE 0.028727683471516018\n",
      "62 Train Loss 0.0023327107 Test MSE 0.0031598055752819518 Test RE 0.026868179484233406\n",
      "63 Train Loss 0.0022116727 Test MSE 0.0027380298281653895 Test RE 0.025010774915415087\n",
      "64 Train Loss 0.0021016554 Test MSE 0.0024889961704006474 Test RE 0.023846254489697915\n",
      "65 Train Loss 0.002018196 Test MSE 0.002475319757475419 Test RE 0.023780649635720352\n",
      "66 Train Loss 0.0019487366 Test MSE 0.002439872089073758 Test RE 0.023609760944526312\n",
      "67 Train Loss 0.0018739204 Test MSE 0.0024500668249032506 Test RE 0.0236590349149058\n",
      "68 Train Loss 0.0018179722 Test MSE 0.0022541171050093705 Test RE 0.02269322909964212\n",
      "69 Train Loss 0.0017363514 Test MSE 0.002301044659095175 Test RE 0.022928232875914015\n",
      "70 Train Loss 0.0016888353 Test MSE 0.002341560947423464 Test RE 0.023129209688607134\n",
      "71 Train Loss 0.001634323 Test MSE 0.00215248356793868 Test RE 0.02217573293213022\n",
      "72 Train Loss 0.0015824556 Test MSE 0.0020549698199036005 Test RE 0.02166759873819498\n",
      "73 Train Loss 0.0015312773 Test MSE 0.0020544275143440614 Test RE 0.02166473951503725\n",
      "74 Train Loss 0.001442055 Test MSE 0.0019374024013282763 Test RE 0.021038655250797345\n",
      "75 Train Loss 0.001408014 Test MSE 0.001796801275933576 Test RE 0.02026086971755377\n",
      "76 Train Loss 0.0013621247 Test MSE 0.0016851389076910966 Test RE 0.019621215754131376\n",
      "77 Train Loss 0.0012999531 Test MSE 0.0016508172987982853 Test RE 0.01942037294981257\n",
      "78 Train Loss 0.0012443135 Test MSE 0.001659421106619582 Test RE 0.019470915190767973\n",
      "79 Train Loss 0.0011965391 Test MSE 0.0015097297545696982 Test RE 0.018571956916027907\n",
      "80 Train Loss 0.001175113 Test MSE 0.0014591832323754225 Test RE 0.018258410858276845\n",
      "81 Train Loss 0.0011580745 Test MSE 0.0014337663503195958 Test RE 0.01809869461219374\n",
      "82 Train Loss 0.0011319082 Test MSE 0.001362091569575375 Test RE 0.0176405130873626\n",
      "83 Train Loss 0.0010973593 Test MSE 0.0012818012817815254 Test RE 0.0171126950421841\n",
      "84 Train Loss 0.0010607151 Test MSE 0.0012442633435954405 Test RE 0.01686025791001307\n",
      "85 Train Loss 0.0010193362 Test MSE 0.001203200679517867 Test RE 0.01657971628440747\n",
      "86 Train Loss 0.0009923353 Test MSE 0.0012322708015031169 Test RE 0.016778809346939472\n",
      "87 Train Loss 0.00096258183 Test MSE 0.0012611576064442632 Test RE 0.01697433394701964\n",
      "88 Train Loss 0.000929093 Test MSE 0.0011914265899518426 Test RE 0.01649839527735744\n",
      "89 Train Loss 0.00090107403 Test MSE 0.0011460507998754645 Test RE 0.016181172755573403\n",
      "90 Train Loss 0.0008782318 Test MSE 0.0011470191378772899 Test RE 0.01618800732874645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Train Loss 0.0008516185 Test MSE 0.0010951439302209836 Test RE 0.01581771187676227\n",
      "92 Train Loss 0.00081227254 Test MSE 0.0011171416430954954 Test RE 0.01597578402866897\n",
      "93 Train Loss 0.0007796152 Test MSE 0.0011030297740105173 Test RE 0.015874559318712428\n",
      "94 Train Loss 0.0007639015 Test MSE 0.001058870154374014 Test RE 0.015553545855694932\n",
      "95 Train Loss 0.0007446669 Test MSE 0.000999271323203157 Test RE 0.015109488847425693\n",
      "96 Train Loss 0.00071970746 Test MSE 0.0009316698276662054 Test RE 0.014589455234320805\n",
      "97 Train Loss 0.00068437087 Test MSE 0.0008399172632559463 Test RE 0.013852441159385998\n",
      "98 Train Loss 0.00065067434 Test MSE 0.0007683927349873053 Test RE 0.013249505973617437\n",
      "99 Train Loss 0.00063657295 Test MSE 0.0007226968661254222 Test RE 0.012849497552894351\n",
      "Training time: 149.71\n",
      "1\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 60.542854 Test MSE 8.25047364041458 Test RE 1.3729271734932744\n",
      "1 Train Loss 54.226685 Test MSE 8.252996709488167 Test RE 1.3731370841876993\n",
      "2 Train Loss 48.19515 Test MSE 8.74425014650409 Test RE 1.4134138634277724\n",
      "3 Train Loss 41.845764 Test MSE 8.712083591749622 Test RE 1.4108117796435828\n",
      "4 Train Loss 37.527725 Test MSE 8.984948789939706 Test RE 1.432734977083323\n",
      "5 Train Loss 34.070824 Test MSE 9.356161093069032 Test RE 1.4620320922806218\n",
      "6 Train Loss 31.440292 Test MSE 9.430951951566843 Test RE 1.4678640238156666\n",
      "7 Train Loss 28.779722 Test MSE 9.581939783529739 Test RE 1.4795674857691454\n",
      "8 Train Loss 26.220875 Test MSE 9.41785013093009 Test RE 1.4668440644710328\n",
      "9 Train Loss 23.640072 Test MSE 9.13060903867859 Test RE 1.4443017381272627\n",
      "10 Train Loss 21.379122 Test MSE 8.953535001545308 Test RE 1.4302281713654155\n",
      "11 Train Loss 18.59399 Test MSE 8.765803869572176 Test RE 1.4151547549097954\n",
      "12 Train Loss 15.969486 Test MSE 8.816706912578315 Test RE 1.4192577105040485\n",
      "13 Train Loss 13.689514 Test MSE 8.456512572507815 Test RE 1.3899645041656445\n",
      "14 Train Loss 11.838385 Test MSE 8.311550982069782 Test RE 1.3779996169456963\n",
      "15 Train Loss 10.644123 Test MSE 8.231845210812914 Test RE 1.3713763576789795\n",
      "16 Train Loss 9.228608 Test MSE 7.9769891673293225 Test RE 1.3499807055136401\n",
      "17 Train Loss 7.475691 Test MSE 7.2394336889178215 Test RE 1.2860574142866337\n",
      "18 Train Loss 5.7089405 Test MSE 6.7413436814273 Test RE 1.2410271839089435\n",
      "19 Train Loss 4.702767 Test MSE 6.492128262092661 Test RE 1.217871888460297\n",
      "20 Train Loss 3.4901292 Test MSE 6.411187873365409 Test RE 1.2102561886765186\n",
      "21 Train Loss 2.8073504 Test MSE 6.239221839180728 Test RE 1.193914630103961\n",
      "22 Train Loss 2.256103 Test MSE 6.044269078596656 Test RE 1.175113878006641\n",
      "23 Train Loss 1.9352517 Test MSE 6.024807742442179 Test RE 1.1732205370394815\n",
      "24 Train Loss 1.7475146 Test MSE 6.117417274068397 Test RE 1.182203151705673\n",
      "25 Train Loss 1.560995 Test MSE 6.005691531512369 Test RE 1.1713577929767407\n",
      "26 Train Loss 1.421973 Test MSE 5.891991646085178 Test RE 1.1602167243986758\n",
      "27 Train Loss 1.3198249 Test MSE 5.876755490375622 Test RE 1.15871564577634\n",
      "28 Train Loss 1.2517847 Test MSE 5.805425858131306 Test RE 1.1516621712955162\n",
      "29 Train Loss 1.1948042 Test MSE 5.810866910698908 Test RE 1.1522017343711182\n",
      "30 Train Loss 1.1478113 Test MSE 5.767373108705124 Test RE 1.1478815734176178\n",
      "31 Train Loss 1.099716 Test MSE 5.823594519606855 Test RE 1.1534628845540535\n",
      "32 Train Loss 1.06772 Test MSE 5.841031363556803 Test RE 1.15518842704238\n",
      "33 Train Loss 1.0397667 Test MSE 5.825926472049617 Test RE 1.1536938030498112\n",
      "34 Train Loss 1.0125178 Test MSE 5.890888268118951 Test RE 1.1601080839265563\n",
      "35 Train Loss 0.98025674 Test MSE 5.906185262436409 Test RE 1.1616133459882354\n",
      "36 Train Loss 0.95501167 Test MSE 5.934705902683537 Test RE 1.1644146513550293\n",
      "37 Train Loss 0.9335587 Test MSE 5.967533686482261 Test RE 1.1676306858315366\n",
      "38 Train Loss 0.91794443 Test MSE 5.996492065561506 Test RE 1.1704603113266896\n",
      "39 Train Loss 0.9052962 Test MSE 6.0053699149916255 Test RE 1.1713264283071008\n",
      "40 Train Loss 0.8858814 Test MSE 6.017100286724162 Test RE 1.1724698542312946\n",
      "41 Train Loss 0.87060094 Test MSE 6.053029076149344 Test RE 1.1759651196931085\n",
      "42 Train Loss 0.85871756 Test MSE 6.087773610415967 Test RE 1.1793353245576204\n",
      "43 Train Loss 0.8475009 Test MSE 6.114780197140287 Test RE 1.1819483140376261\n",
      "44 Train Loss 0.83815974 Test MSE 6.1476603582329306 Test RE 1.1851218171740892\n",
      "45 Train Loss 0.8280023 Test MSE 6.151158390686978 Test RE 1.1854589377038125\n",
      "46 Train Loss 0.81914914 Test MSE 6.154833455129215 Test RE 1.185813016332526\n",
      "47 Train Loss 0.81153727 Test MSE 6.1499061811302465 Test RE 1.185338267866326\n",
      "48 Train Loss 0.8033154 Test MSE 6.160979883031685 Test RE 1.1864049653699558\n",
      "49 Train Loss 0.7943934 Test MSE 6.182039709178304 Test RE 1.1884309553492707\n",
      "50 Train Loss 0.78305465 Test MSE 6.197877400340279 Test RE 1.1899522948889862\n",
      "51 Train Loss 0.7750567 Test MSE 6.215348825021471 Test RE 1.19162831472843\n",
      "52 Train Loss 0.76766944 Test MSE 6.250042394269142 Test RE 1.1949494725089507\n",
      "53 Train Loss 0.76010823 Test MSE 6.261802900428293 Test RE 1.1960731933645605\n",
      "54 Train Loss 0.7542734 Test MSE 6.258440401258252 Test RE 1.1957520130878354\n",
      "55 Train Loss 0.7488329 Test MSE 6.277310074305609 Test RE 1.197553297916813\n",
      "56 Train Loss 0.7412398 Test MSE 6.307928824984761 Test RE 1.200470389863081\n",
      "57 Train Loss 0.733904 Test MSE 6.330157705744362 Test RE 1.2025837337128675\n",
      "58 Train Loss 0.72686315 Test MSE 6.338416613129961 Test RE 1.203367978805449\n",
      "59 Train Loss 0.7201535 Test MSE 6.352721589339022 Test RE 1.2047251354725972\n",
      "60 Train Loss 0.7129206 Test MSE 6.376094304644509 Test RE 1.2069392924715208\n",
      "61 Train Loss 0.7072331 Test MSE 6.383160110995335 Test RE 1.2076078551995078\n",
      "62 Train Loss 0.7033868 Test MSE 6.400477886451246 Test RE 1.209244890461701\n",
      "63 Train Loss 0.6987338 Test MSE 6.40865297625142 Test RE 1.2100169055444763\n",
      "64 Train Loss 0.69376767 Test MSE 6.4264463686112885 Test RE 1.2116955252032975\n",
      "65 Train Loss 0.68866825 Test MSE 6.425397186541721 Test RE 1.2115966104191522\n",
      "66 Train Loss 0.68362755 Test MSE 6.435020977253413 Test RE 1.2125036196721737\n",
      "67 Train Loss 0.6799123 Test MSE 6.440887938580863 Test RE 1.2130562279056902\n",
      "68 Train Loss 0.6767068 Test MSE 6.432416702310528 Test RE 1.212258242667735\n",
      "69 Train Loss 0.672969 Test MSE 6.453699487694181 Test RE 1.2142620716545076\n",
      "70 Train Loss 0.66907895 Test MSE 6.460542199535037 Test RE 1.2149056284406548\n",
      "71 Train Loss 0.6656823 Test MSE 6.466318173619888 Test RE 1.2154485933717216\n",
      "72 Train Loss 0.66187817 Test MSE 6.47858225568781 Test RE 1.2166006631976614\n",
      "73 Train Loss 0.657071 Test MSE 6.506246889624369 Test RE 1.2191954406595737\n",
      "74 Train Loss 0.6535201 Test MSE 6.515208052015286 Test RE 1.2200347608672886\n",
      "75 Train Loss 0.6491125 Test MSE 6.53354240023306 Test RE 1.2217501955337355\n",
      "76 Train Loss 0.6450408 Test MSE 6.547859206391564 Test RE 1.223088060042753\n",
      "77 Train Loss 0.64076024 Test MSE 6.555916425901699 Test RE 1.2238403409757188\n",
      "78 Train Loss 0.6369262 Test MSE 6.563111346134463 Test RE 1.2245117207233782\n",
      "79 Train Loss 0.6328262 Test MSE 6.565271434508853 Test RE 1.2247132132617349\n",
      "80 Train Loss 0.6290983 Test MSE 6.567546021874097 Test RE 1.2249253504130597\n",
      "81 Train Loss 0.6261006 Test MSE 6.5844802340758655 Test RE 1.226503549604125\n",
      "82 Train Loss 0.6220437 Test MSE 6.586308391848145 Test RE 1.2266738049850496\n",
      "83 Train Loss 0.61835426 Test MSE 6.614387979068761 Test RE 1.229285879766897\n",
      "84 Train Loss 0.6148257 Test MSE 6.6273120989416725 Test RE 1.2304862693505196\n",
      "85 Train Loss 0.6108361 Test MSE 6.635810901544116 Test RE 1.231274998566756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.6073017 Test MSE 6.643394283748768 Test RE 1.231978346125666\n",
      "87 Train Loss 0.6047297 Test MSE 6.660127359940273 Test RE 1.233528895594761\n",
      "88 Train Loss 0.6023578 Test MSE 6.665850692269518 Test RE 1.234058793850415\n",
      "89 Train Loss 0.6001961 Test MSE 6.676350088672029 Test RE 1.2350302958366617\n",
      "90 Train Loss 0.597365 Test MSE 6.684918734676438 Test RE 1.2358225808391552\n",
      "91 Train Loss 0.5952891 Test MSE 6.697333857706029 Test RE 1.236969623380605\n",
      "92 Train Loss 0.59305143 Test MSE 6.689046485386205 Test RE 1.2362040649321955\n",
      "93 Train Loss 0.59011483 Test MSE 6.703475263635418 Test RE 1.2375366394501268\n",
      "94 Train Loss 0.58623403 Test MSE 6.722546418415997 Test RE 1.2392957635998545\n",
      "95 Train Loss 0.5833111 Test MSE 6.727109632868244 Test RE 1.239716304615156\n",
      "96 Train Loss 0.5805286 Test MSE 6.737121129617841 Test RE 1.2406384541042403\n",
      "97 Train Loss 0.577999 Test MSE 6.758365210753535 Test RE 1.2425929595210952\n",
      "98 Train Loss 0.5755487 Test MSE 6.756848721958776 Test RE 1.2424535408924688\n",
      "99 Train Loss 0.5734703 Test MSE 6.7563326227336145 Test RE 1.2424060896632683\n",
      "Training time: 147.94\n",
      "2\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 48.307423 Test MSE 7.844710154731598 Test RE 1.3387408368084075\n",
      "1 Train Loss 38.540695 Test MSE 7.516557668874096 Test RE 1.3104412556183354\n",
      "2 Train Loss 31.34959 Test MSE 6.872732146529947 Test RE 1.2530626046029523\n",
      "3 Train Loss 26.287485 Test MSE 6.577400987282591 Test RE 1.2258440399651511\n",
      "4 Train Loss 20.851059 Test MSE 6.3788057141415555 Test RE 1.2071958883335305\n",
      "5 Train Loss 15.371531 Test MSE 5.896707990044416 Test RE 1.160680989020159\n",
      "6 Train Loss 12.202893 Test MSE 5.958523742027116 Test RE 1.1667488926041383\n",
      "7 Train Loss 10.421942 Test MSE 5.753973795177011 Test RE 1.1465473638260506\n",
      "8 Train Loss 8.884661 Test MSE 5.716155179698023 Test RE 1.142773248842155\n",
      "9 Train Loss 7.927842 Test MSE 5.651362502789166 Test RE 1.1362781176127708\n",
      "10 Train Loss 7.084723 Test MSE 5.462741628409557 Test RE 1.1171548887275964\n",
      "11 Train Loss 6.197771 Test MSE 5.417221117869685 Test RE 1.1124905784481174\n",
      "12 Train Loss 5.3240695 Test MSE 5.415309050879223 Test RE 1.1122942283084567\n",
      "13 Train Loss 4.583185 Test MSE 5.265140933421208 Test RE 1.0967636811711432\n",
      "14 Train Loss 3.8218117 Test MSE 4.821062149399027 Test RE 1.0494927078406668\n",
      "15 Train Loss 3.4029398 Test MSE 4.615390837804309 Test RE 1.0268625187511238\n",
      "16 Train Loss 3.006664 Test MSE 3.9421496683893698 Test RE 0.9490183603450386\n",
      "17 Train Loss 2.5958192 Test MSE 3.456637442382452 Test RE 0.8886586554718827\n",
      "18 Train Loss 2.3374252 Test MSE 3.127714942898746 Test RE 0.8453209701117997\n",
      "19 Train Loss 1.998502 Test MSE 2.712333046313044 Test RE 0.7871899990993554\n",
      "20 Train Loss 1.7829223 Test MSE 2.491860154834114 Test RE 0.7545185007887797\n",
      "21 Train Loss 1.6551573 Test MSE 2.3323946521052936 Test RE 0.7299768354610476\n",
      "22 Train Loss 1.5230821 Test MSE 1.9823447924774524 Test RE 0.6729730262567016\n",
      "23 Train Loss 1.4181218 Test MSE 1.7941588868363936 Test RE 0.6402336708034645\n",
      "24 Train Loss 1.3308746 Test MSE 1.583036563576819 Test RE 0.601386304012998\n",
      "25 Train Loss 1.1258285 Test MSE 1.0571356030297612 Test RE 0.4914432903781124\n",
      "26 Train Loss 0.85904515 Test MSE 0.9874677418958108 Test RE 0.4749736520181547\n",
      "27 Train Loss 0.67783 Test MSE 0.8454916391056242 Test RE 0.4395038855609298\n",
      "28 Train Loss 0.53351164 Test MSE 0.6365769864067032 Test RE 0.3813585847613808\n",
      "29 Train Loss 0.4100735 Test MSE 0.4843098555239943 Test RE 0.3326363555057263\n",
      "30 Train Loss 0.3292304 Test MSE 0.4402584986721734 Test RE 0.31714796890499164\n",
      "31 Train Loss 0.2627987 Test MSE 0.4219891886753629 Test RE 0.3104979395323078\n",
      "32 Train Loss 0.21396552 Test MSE 0.40797044876846655 Test RE 0.30529691329897257\n",
      "33 Train Loss 0.18241765 Test MSE 0.3784242271989133 Test RE 0.29403398279728216\n",
      "34 Train Loss 0.153164 Test MSE 0.3401039817075937 Test RE 0.27874938538083943\n",
      "35 Train Loss 0.13704076 Test MSE 0.2959790898695742 Test RE 0.2600390528239685\n",
      "36 Train Loss 0.12142073 Test MSE 0.2464446154147573 Test RE 0.23728360239531446\n",
      "37 Train Loss 0.10331105 Test MSE 0.17551755138588504 Test RE 0.20024806862005096\n",
      "38 Train Loss 0.087672405 Test MSE 0.12191610505777112 Test RE 0.1668931839183265\n",
      "39 Train Loss 0.07364952 Test MSE 0.089889640102664 Test RE 0.14330550737349412\n",
      "40 Train Loss 0.05705069 Test MSE 0.068711995201948 Test RE 0.1252922879688212\n",
      "41 Train Loss 0.04842153 Test MSE 0.056591189552911494 Test RE 0.11370576168225843\n",
      "42 Train Loss 0.041045696 Test MSE 0.04893626679583701 Test RE 0.10573614629973885\n",
      "43 Train Loss 0.033499103 Test MSE 0.037711546757649456 Test RE 0.09282078416021419\n",
      "44 Train Loss 0.025951216 Test MSE 0.02766732771299182 Test RE 0.07950449207873367\n",
      "45 Train Loss 0.022392403 Test MSE 0.0216642667287186 Test RE 0.07035258463328373\n",
      "46 Train Loss 0.018725405 Test MSE 0.016569720827689968 Test RE 0.06152698812018598\n",
      "47 Train Loss 0.017064663 Test MSE 0.013323277384055504 Test RE 0.05517134799739643\n",
      "48 Train Loss 0.0150177 Test MSE 0.01077562167579598 Test RE 0.04961685444581081\n",
      "49 Train Loss 0.013600604 Test MSE 0.009586151395136725 Test RE 0.04679831346225145\n",
      "50 Train Loss 0.011766448 Test MSE 0.007715015123408182 Test RE 0.04198328828790187\n",
      "51 Train Loss 0.010310992 Test MSE 0.005877447070938069 Test RE 0.03664396196409637\n",
      "52 Train Loss 0.00938082 Test MSE 0.0057029378533451055 Test RE 0.036095858855739925\n",
      "53 Train Loss 0.008771611 Test MSE 0.005997216555525315 Test RE 0.03701544082724183\n",
      "54 Train Loss 0.008111642 Test MSE 0.004827594855272542 Test RE 0.033210351191089664\n",
      "55 Train Loss 0.0074721845 Test MSE 0.004910991125698704 Test RE 0.03349597586464623\n",
      "56 Train Loss 0.006918174 Test MSE 0.004839610614537755 Test RE 0.033251655360217645\n",
      "57 Train Loss 0.006412897 Test MSE 0.004454262770783241 Test RE 0.03190038886992899\n",
      "58 Train Loss 0.006152694 Test MSE 0.004073853716767458 Test RE 0.03050779191072224\n",
      "59 Train Loss 0.0057145096 Test MSE 0.0038113478252245437 Test RE 0.029508514871170233\n",
      "60 Train Loss 0.005388578 Test MSE 0.0034008628550595255 Test RE 0.027874213337885822\n",
      "61 Train Loss 0.0051013944 Test MSE 0.002893618276589117 Test RE 0.0257115749349294\n",
      "62 Train Loss 0.004796602 Test MSE 0.002908317747153379 Test RE 0.025776799116151203\n",
      "63 Train Loss 0.0045566335 Test MSE 0.003217120587477539 Test RE 0.02711076236151461\n",
      "64 Train Loss 0.0042003365 Test MSE 0.003101837314870975 Test RE 0.026620583364008635\n",
      "65 Train Loss 0.004046779 Test MSE 0.0031352644793777055 Test RE 0.026763638266075192\n",
      "66 Train Loss 0.0038005274 Test MSE 0.0028526110920531183 Test RE 0.025528737844700472\n",
      "67 Train Loss 0.0036240867 Test MSE 0.0028169008877597596 Test RE 0.02536844478743111\n",
      "68 Train Loss 0.0035073608 Test MSE 0.0027468890391899726 Test RE 0.02505120486006224\n",
      "69 Train Loss 0.003416028 Test MSE 0.0026698488467572228 Test RE 0.024697409206594318\n",
      "70 Train Loss 0.0032482976 Test MSE 0.002553097769622649 Test RE 0.024151370667528146\n",
      "71 Train Loss 0.0030644718 Test MSE 0.002421260353834342 Test RE 0.023519539038606797\n",
      "72 Train Loss 0.002948215 Test MSE 0.00225410875511557 Test RE 0.02269318706850095\n",
      "73 Train Loss 0.0028125602 Test MSE 0.0020569829459793332 Test RE 0.021678209339375466\n",
      "74 Train Loss 0.0026465207 Test MSE 0.0019488291984858911 Test RE 0.02110060701958859\n",
      "75 Train Loss 0.0025132578 Test MSE 0.0019040068564246868 Test RE 0.02085654247659912\n",
      "76 Train Loss 0.0023548165 Test MSE 0.0018789419489199188 Test RE 0.020718806840193765\n",
      "77 Train Loss 0.0022206523 Test MSE 0.0017974097729631256 Test RE 0.02026430015685349\n",
      "78 Train Loss 0.0021220916 Test MSE 0.0017658895017536082 Test RE 0.020085831848824044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Train Loss 0.002041041 Test MSE 0.0016632230522044742 Test RE 0.019493207605490045\n",
      "80 Train Loss 0.0019706613 Test MSE 0.001634569166187743 Test RE 0.019324564323498043\n",
      "81 Train Loss 0.0018809326 Test MSE 0.0014679671505261746 Test RE 0.018313283935311654\n",
      "82 Train Loss 0.0018019539 Test MSE 0.0013853057148149666 Test RE 0.017790201748270767\n",
      "83 Train Loss 0.0017168404 Test MSE 0.0012884863044124778 Test RE 0.017157261226506182\n",
      "84 Train Loss 0.0016533739 Test MSE 0.0012389372308613473 Test RE 0.01682413374921452\n",
      "85 Train Loss 0.0015566065 Test MSE 0.0012079903118768737 Test RE 0.016612683301231022\n",
      "86 Train Loss 0.0014808509 Test MSE 0.0012353078848642938 Test RE 0.016799473344980394\n",
      "87 Train Loss 0.0014148942 Test MSE 0.0012076966263418842 Test RE 0.016610663748048444\n",
      "88 Train Loss 0.0013666839 Test MSE 0.001120806523491761 Test RE 0.01600196754694429\n",
      "89 Train Loss 0.001328354 Test MSE 0.0010745195316181518 Test RE 0.015668059687704877\n",
      "90 Train Loss 0.001289484 Test MSE 0.0010543270539480115 Test RE 0.015520143612301623\n",
      "91 Train Loss 0.0012257237 Test MSE 0.001034825136693876 Test RE 0.015375935376713293\n",
      "92 Train Loss 0.0011801664 Test MSE 0.0010078384662494458 Test RE 0.015174120387604873\n",
      "93 Train Loss 0.0011178865 Test MSE 0.0009736436175735413 Test RE 0.01491447844924364\n",
      "94 Train Loss 0.0010577498 Test MSE 0.0008886335693337024 Test RE 0.014248508897237585\n",
      "95 Train Loss 0.0010053436 Test MSE 0.0008956559798633099 Test RE 0.014304697399017439\n",
      "96 Train Loss 0.0009645101 Test MSE 0.0008756382049569132 Test RE 0.014143940193117774\n",
      "97 Train Loss 0.0009243719 Test MSE 0.0009000252273462963 Test RE 0.014339546004976762\n",
      "98 Train Loss 0.00089278293 Test MSE 0.0008464300586588108 Test RE 0.013906043998585707\n",
      "99 Train Loss 0.000854856 Test MSE 0.0007789044101763076 Test RE 0.013339825289326562\n",
      "Training time: 146.80\n",
      "3\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 49.613834 Test MSE 9.049937140151117 Test RE 1.4379071445669034\n",
      "1 Train Loss 43.35734 Test MSE 8.692272344098969 Test RE 1.4092067761521743\n",
      "2 Train Loss 38.652542 Test MSE 8.778905442388393 Test RE 1.4162119215231768\n",
      "3 Train Loss 35.65325 Test MSE 9.014735415493558 Test RE 1.4351078914962032\n",
      "4 Train Loss 32.883102 Test MSE 9.265026518626332 Test RE 1.4548941366367996\n",
      "5 Train Loss 30.13979 Test MSE 9.308376645209785 Test RE 1.4582938162052395\n",
      "6 Train Loss 27.66962 Test MSE 9.480211595274897 Test RE 1.4716924966676483\n",
      "7 Train Loss 25.303059 Test MSE 9.544525463928617 Test RE 1.476676048569665\n",
      "8 Train Loss 22.701965 Test MSE 9.247297701448408 Test RE 1.453501485301614\n",
      "9 Train Loss 19.858213 Test MSE 9.215934683878439 Test RE 1.4510345532221893\n",
      "10 Train Loss 16.95824 Test MSE 8.942391105679652 Test RE 1.4293378371988945\n",
      "11 Train Loss 14.738143 Test MSE 8.922351322129991 Test RE 1.4277353750586785\n",
      "12 Train Loss 13.028082 Test MSE 8.939108264810542 Test RE 1.4290754510351826\n",
      "13 Train Loss 11.04858 Test MSE 8.545408866403253 Test RE 1.397251175809606\n",
      "14 Train Loss 8.972448 Test MSE 7.884326097001312 Test RE 1.3421169137851416\n",
      "15 Train Loss 7.2957172 Test MSE 7.477672067542467 Test RE 1.3070471905301815\n",
      "16 Train Loss 6.466104 Test MSE 7.198363684669651 Test RE 1.2824042619870566\n",
      "17 Train Loss 5.8000765 Test MSE 6.994202570150732 Test RE 1.2640875777085598\n",
      "18 Train Loss 5.157063 Test MSE 6.769818575656291 Test RE 1.2436454215871942\n",
      "19 Train Loss 4.542156 Test MSE 6.410389046883181 Test RE 1.2101807880776105\n",
      "20 Train Loss 3.5606797 Test MSE 6.442238065279107 Test RE 1.213183360515147\n",
      "21 Train Loss 2.7740884 Test MSE 6.238052875382429 Test RE 1.1938027805501283\n",
      "22 Train Loss 2.1446924 Test MSE 6.117763667120391 Test RE 1.1822366218077296\n",
      "23 Train Loss 1.7676301 Test MSE 5.990629232202962 Test RE 1.1698879857221396\n",
      "24 Train Loss 1.4949628 Test MSE 5.910413976245873 Test RE 1.1620291178652056\n",
      "25 Train Loss 1.3309541 Test MSE 5.830618512668637 Test RE 1.1541582861448456\n",
      "26 Train Loss 1.2294362 Test MSE 5.8440381178154945 Test RE 1.1554857136541146\n",
      "27 Train Loss 1.138708 Test MSE 5.933464550148036 Test RE 1.1642928656509874\n",
      "28 Train Loss 1.0674253 Test MSE 5.922115378199522 Test RE 1.1631788382148036\n",
      "29 Train Loss 1.0137671 Test MSE 5.9519707011433 Test RE 1.1661071349443526\n",
      "30 Train Loss 0.9669483 Test MSE 5.979798389833482 Test RE 1.16882994956471\n",
      "31 Train Loss 0.9327934 Test MSE 5.999778781773631 Test RE 1.170781035830768\n",
      "32 Train Loss 0.9080873 Test MSE 6.0353614706032985 Test RE 1.1742476596909341\n",
      "33 Train Loss 0.89018905 Test MSE 6.004422887011184 Test RE 1.1712340674156456\n",
      "34 Train Loss 0.87266195 Test MSE 6.013796663636869 Test RE 1.172147944166416\n",
      "35 Train Loss 0.85993046 Test MSE 6.031572411376983 Test RE 1.173878999711121\n",
      "36 Train Loss 0.846184 Test MSE 6.078384443443805 Test RE 1.178425529799892\n",
      "37 Train Loss 0.8330604 Test MSE 6.088113318139886 Test RE 1.1793682285185503\n",
      "38 Train Loss 0.82096577 Test MSE 6.102259335942807 Test RE 1.1807375923249377\n",
      "39 Train Loss 0.81127715 Test MSE 6.117831412300274 Test RE 1.1822431675501979\n",
      "40 Train Loss 0.7980346 Test MSE 6.129633361875962 Test RE 1.1833829547308947\n",
      "41 Train Loss 0.78574425 Test MSE 6.149579438540017 Test RE 1.1853067791225176\n",
      "42 Train Loss 0.7736323 Test MSE 6.136517010775624 Test RE 1.184047244629308\n",
      "43 Train Loss 0.76248205 Test MSE 6.157724518831516 Test RE 1.1860914851575501\n",
      "44 Train Loss 0.7522541 Test MSE 6.179275694207713 Test RE 1.1881652495017538\n",
      "45 Train Loss 0.74436617 Test MSE 6.181922052395104 Test RE 1.1884196461669343\n",
      "46 Train Loss 0.736388 Test MSE 6.194495062354268 Test RE 1.1896275570916743\n",
      "47 Train Loss 0.7275877 Test MSE 6.223183248728843 Test RE 1.192379099706426\n",
      "48 Train Loss 0.7211583 Test MSE 6.2102012950581145 Test RE 1.1911347613349255\n",
      "49 Train Loss 0.715013 Test MSE 6.2183440441152245 Test RE 1.1919154070607325\n",
      "50 Train Loss 0.709401 Test MSE 6.217229799746786 Test RE 1.1918086145996158\n",
      "51 Train Loss 0.7048768 Test MSE 6.21794775666752 Test RE 1.1918774268012886\n",
      "52 Train Loss 0.6999277 Test MSE 6.257359158342798 Test RE 1.1956487162473455\n",
      "53 Train Loss 0.6952679 Test MSE 6.268753974861202 Test RE 1.1967368750482423\n",
      "54 Train Loss 0.69128424 Test MSE 6.293419346091473 Test RE 1.1990889358132408\n",
      "55 Train Loss 0.6873666 Test MSE 6.314431143780874 Test RE 1.2010889629981651\n",
      "56 Train Loss 0.6823953 Test MSE 6.321921100139601 Test RE 1.2018010966469794\n",
      "57 Train Loss 0.67706436 Test MSE 6.325729774407822 Test RE 1.2021630578014728\n",
      "58 Train Loss 0.6725278 Test MSE 6.351692079263073 Test RE 1.2046275137760087\n",
      "59 Train Loss 0.6673572 Test MSE 6.360611737707989 Test RE 1.2054730440885886\n",
      "60 Train Loss 0.663358 Test MSE 6.366186011866449 Test RE 1.2060011509697732\n",
      "61 Train Loss 0.65855056 Test MSE 6.386125108605513 Test RE 1.207888291428925\n",
      "62 Train Loss 0.65474486 Test MSE 6.3859163599138755 Test RE 1.2078685496327068\n",
      "63 Train Loss 0.6505888 Test MSE 6.400509841479892 Test RE 1.2092479090962132\n",
      "64 Train Loss 0.64726746 Test MSE 6.424482429793156 Test RE 1.2115103623948569\n",
      "65 Train Loss 0.6448138 Test MSE 6.433553645131715 Test RE 1.212365372497211\n",
      "66 Train Loss 0.6414426 Test MSE 6.445712687504099 Test RE 1.213510481741497\n",
      "67 Train Loss 0.6383225 Test MSE 6.447145751755965 Test RE 1.2136453730969092\n",
      "68 Train Loss 0.63528377 Test MSE 6.455637099111946 Test RE 1.214444338545825\n",
      "69 Train Loss 0.63291526 Test MSE 6.462584404676225 Test RE 1.2150976317125393\n",
      "70 Train Loss 0.6306075 Test MSE 6.4920184217574155 Test RE 1.2178615858278679\n",
      "71 Train Loss 0.6284505 Test MSE 6.503015457742308 Test RE 1.2188926365706414\n",
      "72 Train Loss 0.626445 Test MSE 6.506529828467152 Test RE 1.2192219501052444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 0.6227819 Test MSE 6.506211637389538 Test RE 1.219192137724493\n",
      "74 Train Loss 0.61993665 Test MSE 6.5198190859104415 Test RE 1.220466414513799\n",
      "75 Train Loss 0.6172387 Test MSE 6.515119675351409 Test RE 1.2200264861532066\n",
      "76 Train Loss 0.61465967 Test MSE 6.525415675256085 Test RE 1.220990124149195\n",
      "77 Train Loss 0.61217153 Test MSE 6.540483176185181 Test RE 1.222398974017285\n",
      "78 Train Loss 0.61021346 Test MSE 6.54210199113158 Test RE 1.2225502407698658\n",
      "79 Train Loss 0.6081921 Test MSE 6.563421801014651 Test RE 1.2245406819221132\n",
      "80 Train Loss 0.6067282 Test MSE 6.56486705779096 Test RE 1.2246754956181718\n",
      "81 Train Loss 0.6051221 Test MSE 6.576429662477358 Test RE 1.2257535227009517\n",
      "82 Train Loss 0.60335934 Test MSE 6.588632776412457 Test RE 1.2268902395923966\n",
      "83 Train Loss 0.6013475 Test MSE 6.584750600303086 Test RE 1.22652873015913\n",
      "84 Train Loss 0.5996038 Test MSE 6.5883999547992795 Test RE 1.226868562174792\n",
      "85 Train Loss 0.59762686 Test MSE 6.591885322296149 Test RE 1.227193035678141\n",
      "86 Train Loss 0.594849 Test MSE 6.60048929032834 Test RE 1.2279936629622645\n",
      "87 Train Loss 0.5926486 Test MSE 6.616053105823215 Test RE 1.2294406021694573\n",
      "88 Train Loss 0.590827 Test MSE 6.622009208235508 Test RE 1.2299938796825873\n",
      "89 Train Loss 0.5890275 Test MSE 6.643709625363409 Test RE 1.2320075849013752\n",
      "90 Train Loss 0.5866599 Test MSE 6.661828095954304 Test RE 1.233686383056333\n",
      "91 Train Loss 0.58436614 Test MSE 6.685265532273235 Test RE 1.2358546361834182\n",
      "92 Train Loss 0.58161783 Test MSE 6.674602363291928 Test RE 1.23486863302353\n",
      "93 Train Loss 0.57956684 Test MSE 6.686664377971854 Test RE 1.2359839264494343\n",
      "94 Train Loss 0.57702184 Test MSE 6.688863648237548 Test RE 1.236187169731106\n",
      "95 Train Loss 0.5747877 Test MSE 6.693751195220518 Test RE 1.2366387277150603\n",
      "96 Train Loss 0.5719856 Test MSE 6.71184275942671 Test RE 1.238308765313394\n",
      "97 Train Loss 0.5692863 Test MSE 6.736858794220338 Test RE 1.240614299384138\n",
      "98 Train Loss 0.5667804 Test MSE 6.747386256829238 Test RE 1.2415832541092753\n",
      "99 Train Loss 0.56459016 Test MSE 6.753766027639168 Test RE 1.2421700846849393\n",
      "Training time: 148.70\n",
      "4\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 54.602634 Test MSE 8.655980695303374 Test RE 1.4062618654832306\n",
      "1 Train Loss 44.82286 Test MSE 8.30004399593224 Test RE 1.3770453958544757\n",
      "2 Train Loss 36.36902 Test MSE 7.489415836233242 Test RE 1.3080731540759956\n",
      "3 Train Loss 29.450016 Test MSE 6.993199948210271 Test RE 1.2639969707128895\n",
      "4 Train Loss 23.183037 Test MSE 6.73375931111365 Test RE 1.2403288766401932\n",
      "5 Train Loss 20.09957 Test MSE 6.7014826593640455 Test RE 1.2373526972431077\n",
      "6 Train Loss 17.893627 Test MSE 6.3398360793666715 Test RE 1.2035027162878678\n",
      "7 Train Loss 15.809088 Test MSE 6.377499466585578 Test RE 1.2070722776227945\n",
      "8 Train Loss 13.10692 Test MSE 6.079978414498569 Test RE 1.1785800324538345\n",
      "9 Train Loss 10.515932 Test MSE 5.542141552139968 Test RE 1.1252444180828864\n",
      "10 Train Loss 8.409315 Test MSE 5.509627376803475 Test RE 1.1219388174905478\n",
      "11 Train Loss 6.7527037 Test MSE 5.238858388712907 Test RE 1.0940228425099874\n",
      "12 Train Loss 5.2560825 Test MSE 4.860296181597104 Test RE 1.053754465504392\n",
      "13 Train Loss 4.170359 Test MSE 4.567132601482796 Test RE 1.0214800070218268\n",
      "14 Train Loss 3.496791 Test MSE 4.327469639482334 Test RE 0.9943174817624979\n",
      "15 Train Loss 2.909539 Test MSE 3.7502352437642803 Test RE 0.9256297738943422\n",
      "16 Train Loss 2.3048606 Test MSE 3.147011477953287 Test RE 0.8479245775942551\n",
      "17 Train Loss 2.0072575 Test MSE 2.78363406296838 Test RE 0.7974695906734147\n",
      "18 Train Loss 1.7861621 Test MSE 2.466440895307802 Test RE 0.7506602456930902\n",
      "19 Train Loss 1.4903347 Test MSE 1.8035404028328088 Test RE 0.6419053541838482\n",
      "20 Train Loss 1.2983649 Test MSE 1.4736183129544416 Test RE 0.5802305151801811\n",
      "21 Train Loss 0.9926772 Test MSE 1.021094512807454 Test RE 0.48299321673548457\n",
      "22 Train Loss 0.69067925 Test MSE 0.7083231423676664 Test RE 0.4022756784303443\n",
      "23 Train Loss 0.51774544 Test MSE 0.5625656017616295 Test RE 0.3585045294730794\n",
      "24 Train Loss 0.40794727 Test MSE 0.4974184397792884 Test RE 0.3371079547860116\n",
      "25 Train Loss 0.34220597 Test MSE 0.3875527578290391 Test RE 0.2975592641990306\n",
      "26 Train Loss 0.28437057 Test MSE 0.35024911055432334 Test RE 0.28287631171723215\n",
      "27 Train Loss 0.22247094 Test MSE 0.2566483703903683 Test RE 0.24214600916614892\n",
      "28 Train Loss 0.1818118 Test MSE 0.13069646299080884 Test RE 0.17279850371348504\n",
      "29 Train Loss 0.12835352 Test MSE 0.07096151734102753 Test RE 0.12732670690447\n",
      "30 Train Loss 0.089804314 Test MSE 0.03063199049092654 Test RE 0.08365572541917492\n",
      "31 Train Loss 0.06274195 Test MSE 0.015487130506633851 Test RE 0.05948309251338091\n",
      "32 Train Loss 0.051839843 Test MSE 0.014719437467519384 Test RE 0.05799007450520281\n",
      "33 Train Loss 0.041635353 Test MSE 0.01637322155494041 Test RE 0.06116107772464978\n",
      "34 Train Loss 0.033185866 Test MSE 0.013817089852213136 Test RE 0.05618447811869414\n",
      "35 Train Loss 0.027718142 Test MSE 0.012443013774147816 Test RE 0.05331763180389137\n",
      "36 Train Loss 0.022664206 Test MSE 0.01181382443789227 Test RE 0.051952125044830474\n",
      "37 Train Loss 0.018606285 Test MSE 0.012182527198601842 Test RE 0.05275659468787385\n",
      "38 Train Loss 0.016444929 Test MSE 0.012196695574285077 Test RE 0.052787263942187836\n",
      "39 Train Loss 0.013948849 Test MSE 0.011992209695891562 Test RE 0.05234288634461944\n",
      "40 Train Loss 0.012726698 Test MSE 0.011051170481058966 Test RE 0.05024723860415161\n",
      "41 Train Loss 0.011313761 Test MSE 0.009524346935730434 Test RE 0.04664720894896408\n",
      "42 Train Loss 0.009966944 Test MSE 0.007941485295971551 Test RE 0.042595029988446866\n",
      "43 Train Loss 0.008761808 Test MSE 0.006281103780164128 Test RE 0.03788140207624874\n",
      "44 Train Loss 0.007653351 Test MSE 0.00521121179737071 Test RE 0.03450463379271096\n",
      "45 Train Loss 0.0070024016 Test MSE 0.0040304054098041575 Test RE 0.030344670555285988\n",
      "46 Train Loss 0.0064671254 Test MSE 0.003360454690762435 Test RE 0.02770812143673848\n",
      "47 Train Loss 0.00571547 Test MSE 0.0033485990135422314 Test RE 0.02765920115330101\n",
      "48 Train Loss 0.0051572383 Test MSE 0.002585983369958481 Test RE 0.024306415866443276\n",
      "49 Train Loss 0.004891925 Test MSE 0.0024274513804468678 Test RE 0.02354958891149143\n",
      "50 Train Loss 0.0044884253 Test MSE 0.0024218627014825408 Test RE 0.023522464386560544\n",
      "51 Train Loss 0.0042700064 Test MSE 0.0019300821505955398 Test RE 0.0209988715738335\n",
      "52 Train Loss 0.004003479 Test MSE 0.0017717102722733468 Test RE 0.020118908332845298\n",
      "53 Train Loss 0.0036943231 Test MSE 0.0017398775818018442 Test RE 0.019937348781506957\n",
      "54 Train Loss 0.003424942 Test MSE 0.0016721856917579104 Test RE 0.019545658736080388\n",
      "55 Train Loss 0.0032909717 Test MSE 0.0016369486876969162 Test RE 0.019338625060291877\n",
      "56 Train Loss 0.0031501502 Test MSE 0.00143368846025371 Test RE 0.018098202995250095\n",
      "57 Train Loss 0.003023694 Test MSE 0.0011868598913841628 Test RE 0.016466746019900412\n",
      "58 Train Loss 0.0028571459 Test MSE 0.0011233846397256093 Test RE 0.016020361103146166\n",
      "59 Train Loss 0.0026711863 Test MSE 0.0010195615927829792 Test RE 0.015262117536802518\n",
      "60 Train Loss 0.0025751167 Test MSE 0.0009676457892262747 Test RE 0.014868469483489638\n",
      "61 Train Loss 0.002482912 Test MSE 0.0009455146571407296 Test RE 0.014697456824111832\n",
      "62 Train Loss 0.0024209754 Test MSE 0.0010196371462194043 Test RE 0.015262683017139159\n",
      "63 Train Loss 0.0023248442 Test MSE 0.0009246845946789154 Test RE 0.014534659811949497\n",
      "64 Train Loss 0.0022138187 Test MSE 0.0009464502931319259 Test RE 0.014704726975459147\n",
      "65 Train Loss 0.002098108 Test MSE 0.0008957986617888036 Test RE 0.014305836754157652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.0019464833 Test MSE 0.0007914085035708736 Test RE 0.013446474000723439\n",
      "67 Train Loss 0.0018300661 Test MSE 0.0007486826814084877 Test RE 0.013078470401056946\n",
      "68 Train Loss 0.001784829 Test MSE 0.0007415522570515734 Test RE 0.013016041985625353\n",
      "69 Train Loss 0.0017091688 Test MSE 0.0007787551055484008 Test RE 0.013338546702969143\n",
      "70 Train Loss 0.0016346427 Test MSE 0.0008104654050390076 Test RE 0.013607404689756441\n",
      "71 Train Loss 0.0015309672 Test MSE 0.000805623976976666 Test RE 0.013566700947054111\n",
      "72 Train Loss 0.0014106126 Test MSE 0.0007112112313828664 Test RE 0.01274698173333084\n",
      "73 Train Loss 0.0013843185 Test MSE 0.0007189932362410563 Test RE 0.012816530126744725\n",
      "74 Train Loss 0.0013484549 Test MSE 0.0006823517473781718 Test RE 0.0124856804096733\n",
      "75 Train Loss 0.0013143838 Test MSE 0.0007096376936325674 Test RE 0.012732872729742458\n",
      "76 Train Loss 0.0012767196 Test MSE 0.000686354418112262 Test RE 0.01252224732118052\n",
      "77 Train Loss 0.0012415366 Test MSE 0.0007083600606441933 Test RE 0.012721405422419603\n",
      "78 Train Loss 0.0011992864 Test MSE 0.0007453488675916201 Test RE 0.01304931931156485\n",
      "79 Train Loss 0.001168239 Test MSE 0.0006732221301289261 Test RE 0.01240187221225325\n",
      "80 Train Loss 0.0011283399 Test MSE 0.0006693032991237736 Test RE 0.01236572383548795\n",
      "81 Train Loss 0.0010999121 Test MSE 0.0006687737627877611 Test RE 0.012360831139017474\n",
      "82 Train Loss 0.0010676855 Test MSE 0.0006330081554818729 Test RE 0.012025765002327432\n",
      "83 Train Loss 0.0010489926 Test MSE 0.0006064155567202048 Test RE 0.011770454348476298\n",
      "84 Train Loss 0.0010173036 Test MSE 0.0005994802524738345 Test RE 0.011702954082657589\n",
      "85 Train Loss 0.0009587777 Test MSE 0.0005870703067736084 Test RE 0.01158118816163761\n",
      "86 Train Loss 0.0009169165 Test MSE 0.0005517025671763849 Test RE 0.011226918311843578\n",
      "87 Train Loss 0.00088151183 Test MSE 0.0005799838618263145 Test RE 0.011511078483314608\n",
      "88 Train Loss 0.00084282213 Test MSE 0.000541624330706118 Test RE 0.011123901713962296\n",
      "89 Train Loss 0.0008171208 Test MSE 0.0005227311360292481 Test RE 0.010928165032108167\n",
      "90 Train Loss 0.00078753877 Test MSE 0.0005336160675716705 Test RE 0.011041358453027865\n",
      "91 Train Loss 0.00076258177 Test MSE 0.0005386169725694676 Test RE 0.011092976106164474\n",
      "92 Train Loss 0.0007258393 Test MSE 0.000505910317061457 Test RE 0.010750900149990873\n",
      "93 Train Loss 0.00068868266 Test MSE 0.00046635849911770777 Test RE 0.010322098718262219\n",
      "94 Train Loss 0.0006696218 Test MSE 0.00044808185086687573 Test RE 0.010117815065631634\n",
      "95 Train Loss 0.0006229824 Test MSE 0.0004111730872247159 Test RE 0.009692156110623055\n",
      "96 Train Loss 0.0005987293 Test MSE 0.00038340770304391247 Test RE 0.009359194598069552\n",
      "97 Train Loss 0.00058104243 Test MSE 0.00034836603105259866 Test RE 0.008921255152477324\n",
      "98 Train Loss 0.00056469603 Test MSE 0.00033326649829332433 Test RE 0.008725772572947758\n",
      "99 Train Loss 0.00054347835 Test MSE 0.0003178152092275081 Test RE 0.008521094832682556\n",
      "Training time: 147.35\n",
      "5\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.07379 Test MSE 8.880321892273066 Test RE 1.424368676339894\n",
      "1 Train Loss 46.841164 Test MSE 8.866910770044154 Test RE 1.4232927243509284\n",
      "2 Train Loss 40.570812 Test MSE 9.26035627884059 Test RE 1.4545274047694854\n",
      "3 Train Loss 36.07634 Test MSE 9.211140656211843 Test RE 1.450657098036418\n",
      "4 Train Loss 32.92328 Test MSE 9.383228371968237 Test RE 1.464145386937237\n",
      "5 Train Loss 29.74913 Test MSE 9.10666007477091 Test RE 1.4424063420293534\n",
      "6 Train Loss 26.959896 Test MSE 9.128490258493983 Test RE 1.444134151527056\n",
      "7 Train Loss 23.225742 Test MSE 8.988878129005737 Test RE 1.433048227958824\n",
      "8 Train Loss 20.107704 Test MSE 8.664656438822131 Test RE 1.4069664252650704\n",
      "9 Train Loss 17.20987 Test MSE 8.57215138147732 Test RE 1.3994357887994666\n",
      "10 Train Loss 14.898863 Test MSE 8.277390490490301 Test RE 1.3751649106589596\n",
      "11 Train Loss 12.66189 Test MSE 7.866462648376703 Test RE 1.3405956403406802\n",
      "12 Train Loss 10.270168 Test MSE 7.596840641990575 Test RE 1.3174209591740593\n",
      "13 Train Loss 8.524619 Test MSE 7.427470662946353 Test RE 1.3026523666343368\n",
      "14 Train Loss 6.5488787 Test MSE 7.338513893631786 Test RE 1.2948281146289942\n",
      "15 Train Loss 5.0659585 Test MSE 7.0881931402483085 Test RE 1.272552860929229\n",
      "16 Train Loss 4.0439725 Test MSE 6.614774638537836 Test RE 1.229321809627748\n",
      "17 Train Loss 3.2310555 Test MSE 6.552831948158951 Test RE 1.223552406218503\n",
      "18 Train Loss 2.7931824 Test MSE 6.489602767587797 Test RE 1.2176349840263985\n",
      "19 Train Loss 2.4696777 Test MSE 6.466045882926991 Test RE 1.2154230023928283\n",
      "20 Train Loss 2.1668434 Test MSE 6.425596404515962 Test RE 1.2116153929118467\n",
      "21 Train Loss 1.9543668 Test MSE 6.461694590120912 Test RE 1.2150139771936268\n",
      "22 Train Loss 1.7818184 Test MSE 6.358428772835482 Test RE 1.2052661668855194\n",
      "23 Train Loss 1.6210543 Test MSE 6.324895713804495 Test RE 1.2020838013413897\n",
      "24 Train Loss 1.5201582 Test MSE 6.389310707252605 Test RE 1.2081895200695036\n",
      "25 Train Loss 1.4387555 Test MSE 6.344161966161468 Test RE 1.2039132417849572\n",
      "26 Train Loss 1.384367 Test MSE 6.457463540211876 Test RE 1.2146161228448484\n",
      "27 Train Loss 1.3321177 Test MSE 6.456571553762579 Test RE 1.2145322308853765\n",
      "28 Train Loss 1.2968385 Test MSE 6.375267190628081 Test RE 1.2068610071816117\n",
      "29 Train Loss 1.2630944 Test MSE 6.358415004283591 Test RE 1.205264861942165\n",
      "30 Train Loss 1.2261012 Test MSE 6.39390503826463 Test RE 1.2086238255323696\n",
      "31 Train Loss 1.1902299 Test MSE 6.302989702450471 Test RE 1.2000003123121523\n",
      "32 Train Loss 1.1584022 Test MSE 6.251728640999325 Test RE 1.1951106589156013\n",
      "33 Train Loss 1.1288092 Test MSE 6.185820252536151 Test RE 1.1887942843054375\n",
      "34 Train Loss 1.1068718 Test MSE 6.177423369389751 Test RE 1.1879871515297238\n",
      "35 Train Loss 1.0918809 Test MSE 6.137079848185896 Test RE 1.184101543411768\n",
      "36 Train Loss 1.0730841 Test MSE 6.1331568956076445 Test RE 1.183723031409434\n",
      "37 Train Loss 1.0559268 Test MSE 6.120458319770907 Test RE 1.182496959285515\n",
      "38 Train Loss 1.0375562 Test MSE 6.1267976999325295 Test RE 1.1831091975583683\n",
      "39 Train Loss 1.0234182 Test MSE 6.1421997265723975 Test RE 1.1845953606807984\n",
      "40 Train Loss 1.011728 Test MSE 6.114178931450066 Test RE 1.1818902021826863\n",
      "41 Train Loss 0.9966649 Test MSE 6.118669334661932 Test RE 1.18232412712578\n",
      "42 Train Loss 0.98323274 Test MSE 6.1007804329717095 Test RE 1.1805945058016363\n",
      "43 Train Loss 0.9719175 Test MSE 6.066394186076238 Test RE 1.1772626714409606\n",
      "44 Train Loss 0.95947564 Test MSE 6.0212596126145 Test RE 1.1728750196370619\n",
      "45 Train Loss 0.94910955 Test MSE 6.019331778631486 Test RE 1.1726872441979852\n",
      "46 Train Loss 0.93997824 Test MSE 6.047611137131155 Test RE 1.175438711049597\n",
      "47 Train Loss 0.93174934 Test MSE 6.027764122967758 Test RE 1.1735083521120044\n",
      "48 Train Loss 0.9229836 Test MSE 6.049611716573852 Test RE 1.175633115420475\n",
      "49 Train Loss 0.91435957 Test MSE 6.075804866172093 Test RE 1.1781754500027295\n",
      "50 Train Loss 0.90600306 Test MSE 6.075714755872652 Test RE 1.1781667132066524\n",
      "51 Train Loss 0.89800465 Test MSE 6.089044628706798 Test RE 1.1794584301980215\n",
      "52 Train Loss 0.88962907 Test MSE 6.086098608692446 Test RE 1.1791730711030388\n",
      "53 Train Loss 0.88181037 Test MSE 6.097231453785369 Test RE 1.1802510649176736\n",
      "54 Train Loss 0.87378305 Test MSE 6.114899456932103 Test RE 1.1819598400629312\n",
      "55 Train Loss 0.86804533 Test MSE 6.105300170876531 Test RE 1.1810317441089626\n",
      "56 Train Loss 0.8603057 Test MSE 6.1364164771770175 Test RE 1.1840375455591547\n",
      "57 Train Loss 0.85310954 Test MSE 6.138565854963207 Test RE 1.1842448914258437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.84633243 Test MSE 6.135290152681975 Test RE 1.1839288769496787\n",
      "59 Train Loss 0.83953375 Test MSE 6.1477817659928045 Test RE 1.1851335193718564\n",
      "60 Train Loss 0.8316448 Test MSE 6.152202897803844 Test RE 1.1855595827903567\n",
      "61 Train Loss 0.825338 Test MSE 6.144478384765672 Test RE 1.1848150733035316\n",
      "62 Train Loss 0.8198396 Test MSE 6.154813570599957 Test RE 1.1858111008174406\n",
      "63 Train Loss 0.8139318 Test MSE 6.160817436019311 Test RE 1.186389324253105\n",
      "64 Train Loss 0.80567837 Test MSE 6.16599727565233 Test RE 1.1868879606231069\n",
      "65 Train Loss 0.8007462 Test MSE 6.168251457056414 Test RE 1.1871048935999777\n",
      "66 Train Loss 0.7972822 Test MSE 6.173351341014662 Test RE 1.1875955388328596\n",
      "67 Train Loss 0.79067945 Test MSE 6.185391255634679 Test RE 1.1887530611623387\n",
      "68 Train Loss 0.7842053 Test MSE 6.207871715850721 Test RE 1.190911330328756\n",
      "69 Train Loss 0.77816993 Test MSE 6.210838610620948 Test RE 1.1911958792608635\n",
      "70 Train Loss 0.77257067 Test MSE 6.224997411054125 Test RE 1.1925528862981614\n",
      "71 Train Loss 0.76838887 Test MSE 6.241309400896981 Test RE 1.194114347480164\n",
      "72 Train Loss 0.7643051 Test MSE 6.245678744766716 Test RE 1.1945322552489674\n",
      "73 Train Loss 0.75986505 Test MSE 6.2444374928543915 Test RE 1.194413550046383\n",
      "74 Train Loss 0.75458294 Test MSE 6.249133642209647 Test RE 1.1948625969166542\n",
      "75 Train Loss 0.7501874 Test MSE 6.270311360273541 Test RE 1.1968855221969272\n",
      "76 Train Loss 0.74600595 Test MSE 6.275920019541805 Test RE 1.1974206967856365\n",
      "77 Train Loss 0.7410612 Test MSE 6.282288098095355 Test RE 1.1980280448481726\n",
      "78 Train Loss 0.73721516 Test MSE 6.2894657653106565 Test RE 1.1987122375923862\n",
      "79 Train Loss 0.73264986 Test MSE 6.305489663911561 Test RE 1.2002382674148795\n",
      "80 Train Loss 0.72901064 Test MSE 6.299165987862301 Test RE 1.199636266436624\n",
      "81 Train Loss 0.724959 Test MSE 6.311134510764946 Test RE 1.2007753902966143\n",
      "82 Train Loss 0.72134554 Test MSE 6.316296304062814 Test RE 1.2012663390731169\n",
      "83 Train Loss 0.7183979 Test MSE 6.328925563015436 Test RE 1.2024666886893547\n",
      "84 Train Loss 0.7160701 Test MSE 6.3256398122051944 Test RE 1.2021545094106172\n",
      "85 Train Loss 0.71336854 Test MSE 6.336313575838873 Test RE 1.2031683281795449\n",
      "86 Train Loss 0.70837253 Test MSE 6.347542537612041 Test RE 1.2042339596924718\n",
      "87 Train Loss 0.7038074 Test MSE 6.34538056818112 Test RE 1.2040288615210162\n",
      "88 Train Loss 0.7004463 Test MSE 6.34773856039214 Test RE 1.2042525539330649\n",
      "89 Train Loss 0.69779 Test MSE 6.36271090697933 Test RE 1.2056719465942063\n",
      "90 Train Loss 0.69430757 Test MSE 6.382352297503558 Test RE 1.2075314390696272\n",
      "91 Train Loss 0.69086266 Test MSE 6.383151299290575 Test RE 1.2076070216713355\n",
      "92 Train Loss 0.6871591 Test MSE 6.384132942670929 Test RE 1.2076998750137233\n",
      "93 Train Loss 0.68426883 Test MSE 6.38806133125848 Test RE 1.208071388642595\n",
      "94 Train Loss 0.6808469 Test MSE 6.399955408425755 Test RE 1.2091955334614781\n",
      "95 Train Loss 0.6778298 Test MSE 6.4082227052872955 Test RE 1.2099762851612599\n",
      "96 Train Loss 0.67488694 Test MSE 6.411520774293508 Test RE 1.2102876095447306\n",
      "97 Train Loss 0.67255104 Test MSE 6.398826347199698 Test RE 1.2090888674049718\n",
      "98 Train Loss 0.6705698 Test MSE 6.4027379881256 Test RE 1.209458372581768\n",
      "99 Train Loss 0.66822535 Test MSE 6.411567110124395 Test RE 1.2102919828894212\n",
      "Training time: 148.83\n",
      "6\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 54.198338 Test MSE 8.029941696574978 Test RE 1.354453988062955\n",
      "1 Train Loss 44.51731 Test MSE 8.495363427846463 Test RE 1.3931537283501367\n",
      "2 Train Loss 39.24376 Test MSE 8.644795531391734 Test RE 1.4053529936519915\n",
      "3 Train Loss 34.241547 Test MSE 8.174433565654631 Test RE 1.3665857712951297\n",
      "4 Train Loss 29.635406 Test MSE 8.37736262742036 Test RE 1.3834444256003475\n",
      "5 Train Loss 26.17678 Test MSE 8.345024893486078 Test RE 1.3807717041006113\n",
      "6 Train Loss 21.588453 Test MSE 8.087900231967453 Test RE 1.3593332903038653\n",
      "7 Train Loss 17.181473 Test MSE 7.811941481149766 Test RE 1.3359418379699062\n",
      "8 Train Loss 13.81232 Test MSE 6.844698426042566 Test RE 1.2505043860594622\n",
      "9 Train Loss 10.990421 Test MSE 6.195341734073332 Test RE 1.1897088542421155\n",
      "10 Train Loss 8.943642 Test MSE 5.851774851490871 Test RE 1.1562503158237682\n",
      "11 Train Loss 6.859013 Test MSE 5.454168714079351 Test RE 1.116277945036692\n",
      "12 Train Loss 4.9788117 Test MSE 4.798356000994658 Test RE 1.0470183504115265\n",
      "13 Train Loss 3.902886 Test MSE 4.650133920024581 Test RE 1.0307202072781196\n",
      "14 Train Loss 3.1207554 Test MSE 4.470358277406683 Test RE 1.010599841608392\n",
      "15 Train Loss 2.5824919 Test MSE 4.371149991585373 Test RE 0.9993230731131454\n",
      "16 Train Loss 2.0912678 Test MSE 4.167778243297418 Test RE 0.9757989846735287\n",
      "17 Train Loss 1.7914913 Test MSE 4.057008476112061 Test RE 0.9627444369503491\n",
      "18 Train Loss 1.549645 Test MSE 4.016190215264344 Test RE 0.9578890245142009\n",
      "19 Train Loss 1.3464589 Test MSE 4.003688071146201 Test RE 0.9563969386819379\n",
      "20 Train Loss 1.1993566 Test MSE 4.030087587175714 Test RE 0.9595449027308077\n",
      "21 Train Loss 1.0889616 Test MSE 3.9763006669068783 Test RE 0.9531201877266916\n",
      "22 Train Loss 0.9694437 Test MSE 4.091343485414958 Test RE 0.9668097716401218\n",
      "23 Train Loss 0.85161906 Test MSE 4.031489424203215 Test RE 0.9597117736228635\n",
      "24 Train Loss 0.7525729 Test MSE 3.94082228826968 Test RE 0.9488585726315878\n",
      "25 Train Loss 0.6726042 Test MSE 3.893515069501569 Test RE 0.9431461369437178\n",
      "26 Train Loss 0.6085096 Test MSE 3.8555406819577454 Test RE 0.938535501849184\n",
      "27 Train Loss 0.561783 Test MSE 3.7731361220491686 Test RE 0.9284516598239073\n",
      "28 Train Loss 0.5291317 Test MSE 3.7680773281471778 Test RE 0.9278290450001527\n",
      "29 Train Loss 0.50381577 Test MSE 3.7777756907715303 Test RE 0.9290223113668173\n",
      "30 Train Loss 0.48597747 Test MSE 3.781296992680193 Test RE 0.9294551859393714\n",
      "31 Train Loss 0.46846783 Test MSE 3.717589882683015 Test RE 0.9215922183804254\n",
      "32 Train Loss 0.4538367 Test MSE 3.6927013308148857 Test RE 0.9185020961015793\n",
      "33 Train Loss 0.4414829 Test MSE 3.6843697358363907 Test RE 0.9174653335601034\n",
      "34 Train Loss 0.43226802 Test MSE 3.690556884984243 Test RE 0.9182353585756386\n",
      "35 Train Loss 0.42301252 Test MSE 3.684917009037662 Test RE 0.9175334707968632\n",
      "36 Train Loss 0.4154184 Test MSE 3.701259465779575 Test RE 0.9195658317029463\n",
      "37 Train Loss 0.4071921 Test MSE 3.7274286528321707 Test RE 0.9228109303607404\n",
      "38 Train Loss 0.40092087 Test MSE 3.731038661409205 Test RE 0.923257692656023\n",
      "39 Train Loss 0.39544898 Test MSE 3.7281774380551296 Test RE 0.9229036152319755\n",
      "40 Train Loss 0.3897046 Test MSE 3.722530011361084 Test RE 0.9222043451615619\n",
      "41 Train Loss 0.38413858 Test MSE 3.7255050015157107 Test RE 0.9225727775055854\n",
      "42 Train Loss 0.3771932 Test MSE 3.6866876298172016 Test RE 0.9177538839994768\n",
      "43 Train Loss 0.37273142 Test MSE 3.6998876840829347 Test RE 0.9193954085684765\n",
      "44 Train Loss 0.368142 Test MSE 3.7368830249613807 Test RE 0.9239805131239153\n",
      "45 Train Loss 0.36317152 Test MSE 3.746250160476449 Test RE 0.925137845795091\n",
      "46 Train Loss 0.35958108 Test MSE 3.7650515760092516 Test RE 0.9274564485434622\n",
      "47 Train Loss 0.35437876 Test MSE 3.8186192412800315 Test RE 0.9340308883363848\n",
      "48 Train Loss 0.3509594 Test MSE 3.8414252560406137 Test RE 0.9368159017965811\n",
      "49 Train Loss 0.34772107 Test MSE 3.8338380616823025 Test RE 0.9358902925532581\n",
      "50 Train Loss 0.34234014 Test MSE 3.8586486113062435 Test RE 0.9389136997056783\n",
      "51 Train Loss 0.33942392 Test MSE 3.8680977075269793 Test RE 0.9400626072682208\n",
      "52 Train Loss 0.33502066 Test MSE 3.884579512746403 Test RE 0.9420632624065716\n",
      "53 Train Loss 0.3312895 Test MSE 3.9114496165432957 Test RE 0.9453158299565366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 0.3277668 Test MSE 3.931418483739932 Test RE 0.9477257874770396\n",
      "55 Train Loss 0.32354257 Test MSE 3.936159043859963 Test RE 0.9482970059254979\n",
      "56 Train Loss 0.32038754 Test MSE 3.9578718856860067 Test RE 0.950908931092023\n",
      "57 Train Loss 0.3163854 Test MSE 3.9660474625440707 Test RE 0.951890546807269\n",
      "58 Train Loss 0.31387115 Test MSE 3.973407419743978 Test RE 0.9527733686204312\n",
      "59 Train Loss 0.3116405 Test MSE 3.9782266254186784 Test RE 0.9533509861326604\n",
      "60 Train Loss 0.30967623 Test MSE 3.9917858876082986 Test RE 0.9549742898251472\n",
      "61 Train Loss 0.30670246 Test MSE 3.9969525523840606 Test RE 0.95559211310489\n",
      "62 Train Loss 0.30397 Test MSE 3.996397430301395 Test RE 0.9555257514584731\n",
      "63 Train Loss 0.30213553 Test MSE 4.001742732765151 Test RE 0.9561645602231147\n",
      "64 Train Loss 0.30030632 Test MSE 3.9960707377839 Test RE 0.9554866950960162\n",
      "65 Train Loss 0.2981534 Test MSE 3.990073084938789 Test RE 0.9547693867996548\n",
      "66 Train Loss 0.2962332 Test MSE 3.9956275902915888 Test RE 0.9554337138927014\n",
      "67 Train Loss 0.294675 Test MSE 3.9968984816162396 Test RE 0.9555856494587308\n",
      "68 Train Loss 0.291945 Test MSE 4.020857379381407 Test RE 0.9584454383023382\n",
      "69 Train Loss 0.290439 Test MSE 4.031868744724417 Test RE 0.9597569219252938\n",
      "70 Train Loss 0.28905076 Test MSE 4.032091440620434 Test RE 0.9597834271254828\n",
      "71 Train Loss 0.28762928 Test MSE 4.039398020351471 Test RE 0.9606526484908381\n",
      "72 Train Loss 0.28625786 Test MSE 4.049406808185534 Test RE 0.961842060859601\n",
      "73 Train Loss 0.28483972 Test MSE 4.050816304253863 Test RE 0.9620094427399055\n",
      "74 Train Loss 0.28366214 Test MSE 4.061886331773879 Test RE 0.9633230304763873\n",
      "75 Train Loss 0.28252992 Test MSE 4.059686794928003 Test RE 0.9630621724354177\n",
      "76 Train Loss 0.28167167 Test MSE 4.066394562865637 Test RE 0.963857471635584\n",
      "77 Train Loss 0.28097892 Test MSE 4.072295872115719 Test RE 0.9645566117156001\n",
      "78 Train Loss 0.28025228 Test MSE 4.081893122628487 Test RE 0.9656925365178781\n",
      "79 Train Loss 0.279463 Test MSE 4.089825385404962 Test RE 0.9666303867872088\n",
      "80 Train Loss 0.2786441 Test MSE 4.095256291332555 Test RE 0.9672719712790059\n",
      "81 Train Loss 0.27773765 Test MSE 4.094559284702001 Test RE 0.9671896536389413\n",
      "82 Train Loss 0.27672845 Test MSE 4.111151773033614 Test RE 0.9691473561376222\n",
      "83 Train Loss 0.27590775 Test MSE 4.104886846130705 Test RE 0.9684086395242849\n",
      "84 Train Loss 0.27489442 Test MSE 4.103815741203697 Test RE 0.9682822858661373\n",
      "85 Train Loss 0.2739683 Test MSE 4.1171818300414085 Test RE 0.9698578471099057\n",
      "86 Train Loss 0.27318215 Test MSE 4.128668258124176 Test RE 0.9712097965432686\n",
      "87 Train Loss 0.27199546 Test MSE 4.130976873599902 Test RE 0.9714812928805606\n",
      "88 Train Loss 0.27129525 Test MSE 4.1347926848529495 Test RE 0.9719298712332461\n",
      "89 Train Loss 0.26997 Test MSE 4.141902666554428 Test RE 0.9727651531907424\n",
      "90 Train Loss 0.26879779 Test MSE 4.155828813251263 Test RE 0.9743991247490126\n",
      "91 Train Loss 0.26798216 Test MSE 4.157144227185747 Test RE 0.9745533222430973\n",
      "92 Train Loss 0.2669818 Test MSE 4.166017979059523 Test RE 0.9755928981979185\n",
      "93 Train Loss 0.26596498 Test MSE 4.168702117427911 Test RE 0.9759071316803435\n",
      "94 Train Loss 0.2647143 Test MSE 4.183340239065836 Test RE 0.9776190468361421\n",
      "95 Train Loss 0.26363403 Test MSE 4.193282870549232 Test RE 0.978780121087526\n",
      "96 Train Loss 0.26257026 Test MSE 4.205667562932677 Test RE 0.9802244493022397\n",
      "97 Train Loss 0.26147366 Test MSE 4.23385893466347 Test RE 0.9835042755405912\n",
      "98 Train Loss 0.2606198 Test MSE 4.2479862062687666 Test RE 0.9851437563533378\n",
      "99 Train Loss 0.25939742 Test MSE 4.2682504740687905 Test RE 0.9874906879108712\n",
      "Training time: 148.26\n",
      "7\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 56.12465 Test MSE 8.332763152669958 Test RE 1.3797569145218762\n",
      "1 Train Loss 43.109856 Test MSE 8.241279150412963 Test RE 1.3721619517246488\n",
      "2 Train Loss 35.51644 Test MSE 8.049701811316595 Test RE 1.356119487148216\n",
      "3 Train Loss 27.42642 Test MSE 7.217652505190916 Test RE 1.2841212853363182\n",
      "4 Train Loss 21.294899 Test MSE 6.808151412717047 Test RE 1.2471614067688188\n",
      "5 Train Loss 17.742413 Test MSE 6.5252385472525924 Test RE 1.220973552560395\n",
      "6 Train Loss 14.709578 Test MSE 6.374337816091412 Test RE 1.2067730370043666\n",
      "7 Train Loss 12.621499 Test MSE 6.327170225375693 Test RE 1.2022999240946055\n",
      "8 Train Loss 11.110641 Test MSE 6.151429873095446 Test RE 1.1854850976298104\n",
      "9 Train Loss 9.606187 Test MSE 5.9873608932236815 Test RE 1.1695688112236613\n",
      "10 Train Loss 8.531494 Test MSE 5.641117970537522 Test RE 1.1352477538723222\n",
      "11 Train Loss 7.2849617 Test MSE 5.27685507227024 Test RE 1.097983069610457\n",
      "12 Train Loss 6.322674 Test MSE 5.072373466772016 Test RE 1.0764991006655682\n",
      "13 Train Loss 5.778478 Test MSE 4.66761239017838 Test RE 1.0326554757871194\n",
      "14 Train Loss 5.0766945 Test MSE 3.9341916724544155 Test RE 0.9480599873531341\n",
      "15 Train Loss 4.458974 Test MSE 3.593740943518593 Test RE 0.9061110863537052\n",
      "16 Train Loss 3.8541284 Test MSE 3.105850102950395 Test RE 0.8423611059164701\n",
      "17 Train Loss 3.1300652 Test MSE 2.8886752268845006 Test RE 0.8123766251143082\n",
      "18 Train Loss 2.3903124 Test MSE 2.162057493794695 Test RE 0.7028160642267324\n",
      "19 Train Loss 1.5108094 Test MSE 1.718772051532734 Test RE 0.626638684530989\n",
      "20 Train Loss 1.1086494 Test MSE 1.3750884038430562 Test RE 0.5604971002685469\n",
      "21 Train Loss 0.78162855 Test MSE 1.0608903035231048 Test RE 0.4923152630996486\n",
      "22 Train Loss 0.61884785 Test MSE 0.848338039765445 Test RE 0.4402430726590915\n",
      "23 Train Loss 0.46273366 Test MSE 0.7019865260630926 Test RE 0.40047226903782657\n",
      "24 Train Loss 0.3584294 Test MSE 0.6109269482813932 Test RE 0.37359641620581685\n",
      "25 Train Loss 0.2812593 Test MSE 0.45271035202405885 Test RE 0.32160165353947734\n",
      "26 Train Loss 0.22709958 Test MSE 0.4095497102918072 Test RE 0.3058872476894555\n",
      "27 Train Loss 0.17971651 Test MSE 0.27168885429245954 Test RE 0.24914029334736662\n",
      "28 Train Loss 0.14417042 Test MSE 0.20678493823360425 Test RE 0.21735393721141655\n",
      "29 Train Loss 0.1137535 Test MSE 0.17869423205754148 Test RE 0.20205208089049145\n",
      "30 Train Loss 0.098786205 Test MSE 0.15603237241774223 Test RE 0.18880583685270202\n",
      "31 Train Loss 0.07574056 Test MSE 0.11493005645033134 Test RE 0.16204098343972748\n",
      "32 Train Loss 0.062505715 Test MSE 0.09426988655635914 Test RE 0.14675555612728067\n",
      "33 Train Loss 0.051723998 Test MSE 0.06928239694420095 Test RE 0.12581126019276156\n",
      "34 Train Loss 0.04258034 Test MSE 0.06346237648857483 Test RE 0.12041101738249417\n",
      "35 Train Loss 0.035106905 Test MSE 0.06412254747718212 Test RE 0.12103568827757857\n",
      "36 Train Loss 0.02922023 Test MSE 0.055068726386805426 Test RE 0.11216583054125336\n",
      "37 Train Loss 0.023263726 Test MSE 0.052738322490743145 Test RE 0.10976685371756872\n",
      "38 Train Loss 0.021403689 Test MSE 0.04854207305355748 Test RE 0.10530941979956887\n",
      "39 Train Loss 0.019313607 Test MSE 0.04333472881948333 Test RE 0.09950069216324639\n",
      "40 Train Loss 0.017471882 Test MSE 0.04327983965444913 Test RE 0.0994376568035097\n",
      "41 Train Loss 0.015581556 Test MSE 0.03811189421478613 Test RE 0.09331217822377916\n",
      "42 Train Loss 0.01386211 Test MSE 0.03659090208285052 Test RE 0.09143124183342582\n",
      "43 Train Loss 0.012344269 Test MSE 0.03756121521663729 Test RE 0.0926355912048296\n",
      "44 Train Loss 0.011043094 Test MSE 0.034250826882903485 Test RE 0.08845931879061826\n",
      "45 Train Loss 0.009993024 Test MSE 0.029948047794638378 Test RE 0.0827165322468841\n",
      "46 Train Loss 0.008756399 Test MSE 0.029840832085600087 Test RE 0.08256833455135051\n",
      "47 Train Loss 0.008201845 Test MSE 0.029191675932500962 Test RE 0.08166530245232448\n",
      "48 Train Loss 0.0076574623 Test MSE 0.028038675371743906 Test RE 0.08003626371068948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 0.007242814 Test MSE 0.02889373712659218 Test RE 0.08124748360889558\n",
      "50 Train Loss 0.0067342417 Test MSE 0.028331248420916506 Test RE 0.08045275422908434\n",
      "51 Train Loss 0.006126275 Test MSE 0.026445860664375303 Test RE 0.0777296859429267\n",
      "52 Train Loss 0.0055405647 Test MSE 0.02698460058230211 Test RE 0.07851742662720801\n",
      "53 Train Loss 0.005241776 Test MSE 0.026984363199934792 Test RE 0.07851708126924092\n",
      "54 Train Loss 0.0050379727 Test MSE 0.026028445172361928 Test RE 0.07711381216995278\n",
      "55 Train Loss 0.0048176153 Test MSE 0.025660708866987875 Test RE 0.07656713289921377\n",
      "56 Train Loss 0.0045217923 Test MSE 0.024999169657424415 Test RE 0.0755737290506773\n",
      "57 Train Loss 0.00427939 Test MSE 0.023385907741778622 Test RE 0.07309458021947739\n",
      "58 Train Loss 0.0040447693 Test MSE 0.0219336600059888 Test RE 0.07078864736413015\n",
      "59 Train Loss 0.0037801873 Test MSE 0.020841244302306838 Test RE 0.06900330344120245\n",
      "60 Train Loss 0.003564353 Test MSE 0.0201084647124356 Test RE 0.06777936830497093\n",
      "61 Train Loss 0.0033951935 Test MSE 0.019828178287644615 Test RE 0.06730533154359834\n",
      "62 Train Loss 0.0032973117 Test MSE 0.019580451112820602 Test RE 0.066883563965239\n",
      "63 Train Loss 0.0031648888 Test MSE 0.018524825119117874 Test RE 0.06505566471188336\n",
      "64 Train Loss 0.0030105389 Test MSE 0.017005228350043516 Test RE 0.06233031107259494\n",
      "65 Train Loss 0.0028607561 Test MSE 0.01586938722822913 Test RE 0.06021270515146101\n",
      "66 Train Loss 0.0027971207 Test MSE 0.015033166878399501 Test RE 0.05860481502395163\n",
      "67 Train Loss 0.0027045773 Test MSE 0.01501872640671533 Test RE 0.05857666112579495\n",
      "68 Train Loss 0.002617521 Test MSE 0.014358697492198152 Test RE 0.05727506401216455\n",
      "69 Train Loss 0.0025124606 Test MSE 0.013393402517336611 Test RE 0.05531635063181206\n",
      "70 Train Loss 0.0024594457 Test MSE 0.012914822707880738 Test RE 0.05431906485269738\n",
      "71 Train Loss 0.0023719703 Test MSE 0.0128369087416214 Test RE 0.05415496595831483\n",
      "72 Train Loss 0.0023163601 Test MSE 0.012446846494930225 Test RE 0.053325842670865556\n",
      "73 Train Loss 0.0022181366 Test MSE 0.011941831382601827 Test RE 0.05223282649634474\n",
      "74 Train Loss 0.0021390533 Test MSE 0.011534532531299747 Test RE 0.05133434906362385\n",
      "75 Train Loss 0.0020147646 Test MSE 0.010614868586313312 Test RE 0.04924536619089451\n",
      "76 Train Loss 0.0019386227 Test MSE 0.010103020657820247 Test RE 0.04804339405114609\n",
      "77 Train Loss 0.0018868464 Test MSE 0.009947254221947744 Test RE 0.04767159347682111\n",
      "78 Train Loss 0.0018239093 Test MSE 0.010068257841123286 Test RE 0.04796066815712495\n",
      "79 Train Loss 0.0017284071 Test MSE 0.009040871754398282 Test RE 0.04544783658219342\n",
      "80 Train Loss 0.0016412546 Test MSE 0.00904826787121726 Test RE 0.04546642266544351\n",
      "81 Train Loss 0.0015527648 Test MSE 0.008411936464977196 Test RE 0.043838536994690494\n",
      "82 Train Loss 0.0014981737 Test MSE 0.008191748009919916 Test RE 0.043260979905918075\n",
      "83 Train Loss 0.0014567329 Test MSE 0.007977178462560498 Test RE 0.04269064478594728\n",
      "84 Train Loss 0.0014192546 Test MSE 0.007640157892489178 Test RE 0.041779114139246475\n",
      "85 Train Loss 0.0013648208 Test MSE 0.007114511715570964 Test RE 0.04031629457091144\n",
      "86 Train Loss 0.0013178783 Test MSE 0.006824193779521211 Test RE 0.03948514485031567\n",
      "87 Train Loss 0.001290658 Test MSE 0.0066087329382535104 Test RE 0.03885681157628523\n",
      "88 Train Loss 0.0012555568 Test MSE 0.006477367879993399 Test RE 0.038468685103887394\n",
      "89 Train Loss 0.0012289842 Test MSE 0.005993748847661398 Test RE 0.03700473775404918\n",
      "90 Train Loss 0.0012039735 Test MSE 0.005715148078039113 Test RE 0.03613447955447851\n",
      "91 Train Loss 0.0011823536 Test MSE 0.005630503929314135 Test RE 0.03586589669313734\n",
      "92 Train Loss 0.0011499181 Test MSE 0.005646377629759856 Test RE 0.03591641826345748\n",
      "93 Train Loss 0.001090821 Test MSE 0.004957453037257688 Test RE 0.03365405224961158\n",
      "94 Train Loss 0.0010649209 Test MSE 0.004904285325130586 Test RE 0.033473099213318196\n",
      "95 Train Loss 0.0010422049 Test MSE 0.004674119061869604 Test RE 0.03267818639776616\n",
      "96 Train Loss 0.001020371 Test MSE 0.004640669848032135 Test RE 0.03256104964817419\n",
      "97 Train Loss 0.0009978455 Test MSE 0.004551266233968356 Test RE 0.03224587608946166\n",
      "98 Train Loss 0.0009811126 Test MSE 0.00450034815165675 Test RE 0.032064990571786224\n",
      "99 Train Loss 0.000962195 Test MSE 0.00427001587736968 Test RE 0.031233654737682782\n",
      "Training time: 148.16\n",
      "8\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 69.41314 Test MSE 5.651704046091047 Test RE 1.1363124529006372\n",
      "1 Train Loss 46.867607 Test MSE 8.35549499693695 Test RE 1.3816376266736399\n",
      "2 Train Loss 30.543793 Test MSE 8.026874165427591 Test RE 1.3541952547603213\n",
      "3 Train Loss 22.654612 Test MSE 7.461820508980591 Test RE 1.3056610822124113\n",
      "4 Train Loss 17.947956 Test MSE 6.984593200591748 Test RE 1.2632189111471617\n",
      "5 Train Loss 14.982887 Test MSE 7.25841826340115 Test RE 1.2877425783637952\n",
      "6 Train Loss 12.252365 Test MSE 6.87388965413824 Test RE 1.2531681207501169\n",
      "7 Train Loss 10.546835 Test MSE 6.878708299452149 Test RE 1.2536072836619898\n",
      "8 Train Loss 8.678967 Test MSE 6.665719869214673 Test RE 1.234046684058219\n",
      "9 Train Loss 7.086389 Test MSE 6.458976268747562 Test RE 1.2147583827943977\n",
      "10 Train Loss 5.2999225 Test MSE 6.339486915347696 Test RE 1.2034695746083335\n",
      "11 Train Loss 4.2876 Test MSE 6.029092793915573 Test RE 1.1736376803761865\n",
      "12 Train Loss 3.3649774 Test MSE 5.480364754981285 Test RE 1.1189554414933198\n",
      "13 Train Loss 2.6690922 Test MSE 5.331695779218549 Test RE 1.1036738198660945\n",
      "14 Train Loss 2.1747417 Test MSE 5.128172778750202 Test RE 1.0824039907285101\n",
      "15 Train Loss 1.9043735 Test MSE 4.914331424021902 Test RE 1.0595959296504083\n",
      "16 Train Loss 1.7276654 Test MSE 4.859887579552581 Test RE 1.0537101703356735\n",
      "17 Train Loss 1.6053509 Test MSE 4.805212614338363 Test RE 1.047766152076597\n",
      "18 Train Loss 1.5224009 Test MSE 4.697404079574012 Test RE 1.0359457680066977\n",
      "19 Train Loss 1.4614891 Test MSE 4.715314761958457 Test RE 1.0379188623352353\n",
      "20 Train Loss 1.4122381 Test MSE 4.705887659422293 Test RE 1.0368808125567492\n",
      "21 Train Loss 1.3751801 Test MSE 4.684219166778148 Test RE 1.0344908737238332\n",
      "22 Train Loss 1.3336058 Test MSE 4.538214898628887 Test RE 1.018241020518954\n",
      "23 Train Loss 1.2938867 Test MSE 4.281526594368224 Test RE 0.9890252588763484\n",
      "24 Train Loss 1.16229 Test MSE 3.7891824565267878 Test RE 0.9304238176302729\n",
      "25 Train Loss 1.0474172 Test MSE 3.5041047272200747 Test RE 0.8947394762526009\n",
      "26 Train Loss 0.9405166 Test MSE 3.251466400148677 Test RE 0.8618817712736532\n",
      "27 Train Loss 0.84534776 Test MSE 3.103006930964375 Test RE 0.8419754585453034\n",
      "28 Train Loss 0.752267 Test MSE 3.0516476759825357 Test RE 0.8349784288804843\n",
      "29 Train Loss 0.70234495 Test MSE 3.1337334226411655 Test RE 0.8461338802013545\n",
      "30 Train Loss 0.6720121 Test MSE 3.158760966702249 Test RE 0.8495059824699699\n",
      "31 Train Loss 0.6444356 Test MSE 3.1541124986784688 Test RE 0.8488806810750532\n",
      "32 Train Loss 0.6239414 Test MSE 3.193248657472988 Test RE 0.854130891607448\n",
      "33 Train Loss 0.60413134 Test MSE 3.184299800558713 Test RE 0.852933230766877\n",
      "34 Train Loss 0.59044313 Test MSE 3.2068440033415144 Test RE 0.8559472035442675\n",
      "35 Train Loss 0.5774429 Test MSE 3.2340314576744293 Test RE 0.8595678833821141\n",
      "36 Train Loss 0.567953 Test MSE 3.265141390975669 Test RE 0.8636923172330225\n",
      "37 Train Loss 0.559402 Test MSE 3.301975694136663 Test RE 0.8685503433897589\n",
      "38 Train Loss 0.5491182 Test MSE 3.347801469253596 Test RE 0.8745565727699158\n",
      "39 Train Loss 0.5410973 Test MSE 3.380887936661347 Test RE 0.8788675877781441\n",
      "40 Train Loss 0.5345148 Test MSE 3.377699301483352 Test RE 0.8784530444348936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 0.5254746 Test MSE 3.433721624642876 Test RE 0.8857080707097869\n",
      "42 Train Loss 0.5185521 Test MSE 3.431357777519449 Test RE 0.8854031480687932\n",
      "43 Train Loss 0.511705 Test MSE 3.4412287675818187 Test RE 0.8866757535233614\n",
      "44 Train Loss 0.5057652 Test MSE 3.460122448783523 Test RE 0.889106518597242\n",
      "45 Train Loss 0.49946517 Test MSE 3.4669644775904276 Test RE 0.8899851418546941\n",
      "46 Train Loss 0.49254876 Test MSE 3.481247687243992 Test RE 0.8918165391446276\n",
      "47 Train Loss 0.48465216 Test MSE 3.4951216826416784 Test RE 0.8935918732242074\n",
      "48 Train Loss 0.47467148 Test MSE 3.5103999093777487 Test RE 0.8955428227495422\n",
      "49 Train Loss 0.46312788 Test MSE 3.519898991914273 Test RE 0.8967536660071433\n",
      "50 Train Loss 0.45546645 Test MSE 3.5366249214890297 Test RE 0.8988817473413989\n",
      "51 Train Loss 0.44656423 Test MSE 3.5720957783530323 Test RE 0.9033782035512019\n",
      "52 Train Loss 0.44011304 Test MSE 3.555074383442928 Test RE 0.9012232894849608\n",
      "53 Train Loss 0.4315348 Test MSE 3.5381633024138748 Test RE 0.899077226395613\n",
      "54 Train Loss 0.42504779 Test MSE 3.5425405435879735 Test RE 0.8996332014984225\n",
      "55 Train Loss 0.41880062 Test MSE 3.540942286933351 Test RE 0.8994302388301288\n",
      "56 Train Loss 0.41243616 Test MSE 3.5649798394194065 Test RE 0.9024779493022341\n",
      "57 Train Loss 0.40709043 Test MSE 3.5649159040877354 Test RE 0.9024698566217254\n",
      "58 Train Loss 0.40220627 Test MSE 3.5812366878518693 Test RE 0.9045333268805038\n",
      "59 Train Loss 0.39714426 Test MSE 3.5757956635002444 Test RE 0.9038459304489413\n",
      "60 Train Loss 0.39327693 Test MSE 3.5741677789226394 Test RE 0.9036401686428301\n",
      "61 Train Loss 0.38998026 Test MSE 3.5965515683836897 Test RE 0.9064653468082771\n",
      "62 Train Loss 0.38510966 Test MSE 3.6089480816783257 Test RE 0.9080261952060499\n",
      "63 Train Loss 0.38082746 Test MSE 3.6497680290348726 Test RE 0.9131469893065066\n",
      "64 Train Loss 0.37763447 Test MSE 3.671642534711176 Test RE 0.915879327254375\n",
      "65 Train Loss 0.37257853 Test MSE 3.7102126663970836 Test RE 0.9206773566582788\n",
      "66 Train Loss 0.36781317 Test MSE 3.7052335740905367 Test RE 0.9200593763748535\n",
      "67 Train Loss 0.36060506 Test MSE 3.74191629826368 Test RE 0.924602566511984\n",
      "68 Train Loss 0.3547365 Test MSE 3.7474081104103725 Test RE 0.9252808128279351\n",
      "69 Train Loss 0.3506637 Test MSE 3.77673078638797 Test RE 0.9288938221844073\n",
      "70 Train Loss 0.34666592 Test MSE 3.775348005353948 Test RE 0.9287237578583777\n",
      "71 Train Loss 0.3419719 Test MSE 3.7889066643409737 Test RE 0.9303899569900587\n",
      "72 Train Loss 0.33632052 Test MSE 3.8151070821770228 Test RE 0.933601254020257\n",
      "73 Train Loss 0.3330458 Test MSE 3.816129955925763 Test RE 0.9337264002080143\n",
      "74 Train Loss 0.32949194 Test MSE 3.8294932888705078 Test RE 0.9353598341301578\n",
      "75 Train Loss 0.32548743 Test MSE 3.8379069770568432 Test RE 0.9363867987288019\n",
      "76 Train Loss 0.32233936 Test MSE 3.84754390889097 Test RE 0.937561688868775\n",
      "77 Train Loss 0.31999955 Test MSE 3.849712092420503 Test RE 0.9378258209432591\n",
      "78 Train Loss 0.3175421 Test MSE 3.8551199419043454 Test RE 0.9384842911003891\n",
      "79 Train Loss 0.31497344 Test MSE 3.8541395043738276 Test RE 0.9383649454323073\n",
      "80 Train Loss 0.3126709 Test MSE 3.8406148309335606 Test RE 0.9367170766048597\n",
      "81 Train Loss 0.31071165 Test MSE 3.8518941365124877 Test RE 0.9380915664522274\n",
      "82 Train Loss 0.3082141 Test MSE 3.8513391001315544 Test RE 0.9380239771458353\n",
      "83 Train Loss 0.30621058 Test MSE 3.8562348430867504 Test RE 0.9386199861791088\n",
      "84 Train Loss 0.30398563 Test MSE 3.850374719580655 Test RE 0.9379065285529652\n",
      "85 Train Loss 0.30173302 Test MSE 3.8514984204555516 Test RE 0.9380433788051734\n",
      "86 Train Loss 0.2993105 Test MSE 3.8542314299058806 Test RE 0.9383761358916083\n",
      "87 Train Loss 0.2976784 Test MSE 3.8586118177222826 Test RE 0.9389092232573312\n",
      "88 Train Loss 0.29619402 Test MSE 3.859236498344796 Test RE 0.9389852213998563\n",
      "89 Train Loss 0.29488114 Test MSE 3.8607698853289234 Test RE 0.939171745952633\n",
      "90 Train Loss 0.2933985 Test MSE 3.8647063932245334 Test RE 0.939650421862794\n",
      "91 Train Loss 0.2914353 Test MSE 3.870285057443018 Test RE 0.9403283651948324\n",
      "92 Train Loss 0.28955728 Test MSE 3.8695890343237367 Test RE 0.9402438081531251\n",
      "93 Train Loss 0.28751847 Test MSE 3.880331512678074 Test RE 0.941548022667172\n",
      "94 Train Loss 0.28550428 Test MSE 3.8892393630280244 Test RE 0.9426281315302323\n",
      "95 Train Loss 0.28386256 Test MSE 3.8871036444237355 Test RE 0.9423692808008723\n",
      "96 Train Loss 0.2823705 Test MSE 3.8874709685590956 Test RE 0.9424138058297318\n",
      "97 Train Loss 0.28006718 Test MSE 3.8858655613286825 Test RE 0.9422191916211861\n",
      "98 Train Loss 0.27831605 Test MSE 3.8931974872514576 Test RE 0.9431076713701777\n",
      "99 Train Loss 0.27649778 Test MSE 3.9009382135868305 Test RE 0.9440447819657077\n",
      "Training time: 147.54\n",
      "9\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 52.797653 Test MSE 8.528432714952007 Test RE 1.3958626091496975\n",
      "1 Train Loss 44.716213 Test MSE 8.713124072061598 Test RE 1.410896023443557\n",
      "2 Train Loss 37.63157 Test MSE 8.848481146107519 Test RE 1.4218128180738907\n",
      "3 Train Loss 35.043266 Test MSE 9.212987245470538 Test RE 1.450802499874976\n",
      "4 Train Loss 32.074287 Test MSE 8.93699981425665 Test RE 1.428906904434471\n",
      "5 Train Loss 29.06886 Test MSE 9.057512185255247 Test RE 1.4385088025116286\n",
      "6 Train Loss 26.728733 Test MSE 9.243724259447257 Test RE 1.453220619187972\n",
      "7 Train Loss 23.858852 Test MSE 9.25065987701968 Test RE 1.453765696708137\n",
      "8 Train Loss 21.429268 Test MSE 9.11064075323371 Test RE 1.4427215579534747\n",
      "9 Train Loss 19.145983 Test MSE 9.220100027768627 Test RE 1.4513624296306142\n",
      "10 Train Loss 17.467495 Test MSE 9.030613439689274 Test RE 1.436371192737084\n",
      "11 Train Loss 16.00051 Test MSE 8.895435937522972 Test RE 1.4255802777143338\n",
      "12 Train Loss 14.865413 Test MSE 8.696520525514604 Test RE 1.409551095481121\n",
      "13 Train Loss 13.96302 Test MSE 8.694677902741303 Test RE 1.4094017594027797\n",
      "14 Train Loss 12.945618 Test MSE 8.65219765641687 Test RE 1.4059545331948655\n",
      "15 Train Loss 11.899283 Test MSE 8.758148238508648 Test RE 1.414536655911211\n",
      "16 Train Loss 10.748944 Test MSE 8.54833900953988 Test RE 1.3974907076509566\n",
      "17 Train Loss 8.659096 Test MSE 8.005198861051259 Test RE 1.3523656236962238\n",
      "18 Train Loss 6.389765 Test MSE 6.998285779053188 Test RE 1.2644565104420782\n",
      "19 Train Loss 5.4128366 Test MSE 6.602581166231901 Test RE 1.2281882399656463\n",
      "20 Train Loss 4.6711445 Test MSE 6.227023437250148 Test RE 1.1927469383328038\n",
      "21 Train Loss 3.9867525 Test MSE 6.079457185570755 Test RE 1.178529512276677\n",
      "22 Train Loss 3.4067776 Test MSE 5.854199651251462 Test RE 1.156489848715973\n",
      "23 Train Loss 2.8950343 Test MSE 5.712611966236454 Test RE 1.1424190144754538\n",
      "24 Train Loss 2.5165656 Test MSE 5.5713153561301745 Test RE 1.128202171142861\n",
      "25 Train Loss 2.0835874 Test MSE 5.610717274477934 Test RE 1.1321846247526286\n",
      "26 Train Loss 1.8136892 Test MSE 5.477700152935466 Test RE 1.1186833853805782\n",
      "27 Train Loss 1.6441058 Test MSE 5.494659691769964 Test RE 1.1204138280275167\n",
      "28 Train Loss 1.5403991 Test MSE 5.42592510918581 Test RE 1.1133839536416887\n",
      "29 Train Loss 1.4434838 Test MSE 5.506836677985539 Test RE 1.1216546431090162\n",
      "30 Train Loss 1.3610904 Test MSE 5.473286991821535 Test RE 1.118232655635504\n",
      "31 Train Loss 1.2959511 Test MSE 5.533632154148049 Test RE 1.124380236723972\n",
      "32 Train Loss 1.2456393 Test MSE 5.593583388754486 Test RE 1.1304545826267178\n",
      "33 Train Loss 1.2027335 Test MSE 5.592189228407154 Test RE 1.1303136950185337\n",
      "34 Train Loss 1.1601968 Test MSE 5.677278922759249 Test RE 1.1388805499106416\n",
      "35 Train Loss 1.1267029 Test MSE 5.738894331052268 Test RE 1.145043997381197\n",
      "36 Train Loss 1.0998889 Test MSE 5.76281020398651 Test RE 1.1474274055914433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 1.067951 Test MSE 5.840114851136854 Test RE 1.15509779355577\n",
      "38 Train Loss 1.0437192 Test MSE 5.845074960202354 Test RE 1.1555882115679235\n",
      "39 Train Loss 1.0217321 Test MSE 5.87709118944053 Test RE 1.1587487400751102\n",
      "40 Train Loss 1.0033858 Test MSE 5.893564107787472 Test RE 1.160371534076543\n",
      "41 Train Loss 0.9929139 Test MSE 5.9209172450352625 Test RE 1.16306116796111\n",
      "42 Train Loss 0.9799747 Test MSE 5.91924772295208 Test RE 1.1628971821188594\n",
      "43 Train Loss 0.9610137 Test MSE 5.919242164787825 Test RE 1.1628966361394235\n",
      "44 Train Loss 0.94190955 Test MSE 5.992137766674922 Test RE 1.17003527452923\n",
      "45 Train Loss 0.92421925 Test MSE 6.023485514886329 Test RE 1.1730917902221185\n",
      "46 Train Loss 0.90944433 Test MSE 6.033411443928278 Test RE 1.1740579445213954\n",
      "47 Train Loss 0.8974999 Test MSE 6.0305382050033485 Test RE 1.1737783555418877\n",
      "48 Train Loss 0.8865441 Test MSE 6.024025303760861 Test RE 1.1731443517921467\n",
      "49 Train Loss 0.8784052 Test MSE 6.027262794395202 Test RE 1.173459550807902\n",
      "50 Train Loss 0.8674622 Test MSE 6.034332360601429 Test RE 1.1741475429427564\n",
      "51 Train Loss 0.85719764 Test MSE 6.049984605251138 Test RE 1.1756693469625028\n",
      "52 Train Loss 0.84638715 Test MSE 6.071474985185345 Test RE 1.1777555658245278\n",
      "53 Train Loss 0.8373507 Test MSE 6.0915387143403334 Test RE 1.1796999598088667\n",
      "54 Train Loss 0.830356 Test MSE 6.099656793353649 Test RE 1.1804857800524267\n",
      "55 Train Loss 0.82246745 Test MSE 6.090159027177484 Test RE 1.1795663557116067\n",
      "56 Train Loss 0.81476736 Test MSE 6.122372580475625 Test RE 1.1826818662302359\n",
      "57 Train Loss 0.8077286 Test MSE 6.127673251496314 Test RE 1.183193730796897\n",
      "58 Train Loss 0.8025022 Test MSE 6.14197647092859 Test RE 1.1845738317485814\n",
      "59 Train Loss 0.796767 Test MSE 6.131143769199683 Test RE 1.1835287448688696\n",
      "60 Train Loss 0.79021347 Test MSE 6.140813842412566 Test RE 1.1844617111223426\n",
      "61 Train Loss 0.7848351 Test MSE 6.156645395196714 Test RE 1.1859875510312263\n",
      "62 Train Loss 0.7792511 Test MSE 6.184680425189021 Test RE 1.188684752941258\n",
      "63 Train Loss 0.77540314 Test MSE 6.186919409118525 Test RE 1.1888998978675036\n",
      "64 Train Loss 0.7695023 Test MSE 6.2003407385312626 Test RE 1.1901887438816117\n",
      "65 Train Loss 0.7631125 Test MSE 6.21012230060607 Test RE 1.191127185627429\n",
      "66 Train Loss 0.75719064 Test MSE 6.232897292857323 Test RE 1.1933093556717196\n",
      "67 Train Loss 0.75183445 Test MSE 6.240889936559985 Test RE 1.194074219939045\n",
      "68 Train Loss 0.7464818 Test MSE 6.2582700729252485 Test RE 1.1957357413156529\n",
      "69 Train Loss 0.74195945 Test MSE 6.269309005731623 Test RE 1.1967898529773664\n",
      "70 Train Loss 0.7370164 Test MSE 6.284174479441683 Test RE 1.1982078971646053\n",
      "71 Train Loss 0.7324728 Test MSE 6.266846660417394 Test RE 1.1965548032055995\n",
      "72 Train Loss 0.7288009 Test MSE 6.285024213717812 Test RE 1.198288904137553\n",
      "73 Train Loss 0.72529554 Test MSE 6.3035381110904956 Test RE 1.2000525158105122\n",
      "74 Train Loss 0.7215697 Test MSE 6.321626038916258 Test RE 1.2017730506595448\n",
      "75 Train Loss 0.7182301 Test MSE 6.305675056573516 Test RE 1.2002559118599325\n",
      "76 Train Loss 0.7149797 Test MSE 6.324755348331047 Test RE 1.2020704626235919\n",
      "77 Train Loss 0.7103435 Test MSE 6.346209284826203 Test RE 1.2041074829820608\n",
      "78 Train Loss 0.70640993 Test MSE 6.373995144217372 Test RE 1.2067405996949696\n",
      "79 Train Loss 0.70148885 Test MSE 6.384300880629216 Test RE 1.2077157594979013\n",
      "80 Train Loss 0.69597995 Test MSE 6.41889815666152 Test RE 1.2109837148687046\n",
      "81 Train Loss 0.6918156 Test MSE 6.426728494894414 Test RE 1.2117221221266505\n",
      "82 Train Loss 0.6871569 Test MSE 6.410075791222252 Test RE 1.210151218841542\n",
      "83 Train Loss 0.68339336 Test MSE 6.433345675080073 Test RE 1.2123457769718844\n",
      "84 Train Loss 0.67939466 Test MSE 6.4335886350867835 Test RE 1.2123686693184217\n",
      "85 Train Loss 0.6753151 Test MSE 6.471619955665076 Test RE 1.21594676891905\n",
      "86 Train Loss 0.6714401 Test MSE 6.4789511062684415 Test RE 1.2166352955798945\n",
      "87 Train Loss 0.667431 Test MSE 6.479897321660148 Test RE 1.2167241338035033\n",
      "88 Train Loss 0.6640159 Test MSE 6.489399538886214 Test RE 1.2176159181202828\n",
      "89 Train Loss 0.6599456 Test MSE 6.487525402889818 Test RE 1.2174400819284574\n",
      "90 Train Loss 0.65596914 Test MSE 6.494507754261108 Test RE 1.2180950549641485\n",
      "91 Train Loss 0.65229094 Test MSE 6.512634669182124 Test RE 1.2197937918477426\n",
      "92 Train Loss 0.64920306 Test MSE 6.547707902809603 Test RE 1.2230739288078134\n",
      "93 Train Loss 0.64499664 Test MSE 6.552537759454993 Test RE 1.2235249402816692\n",
      "94 Train Loss 0.6413528 Test MSE 6.557861209864927 Test RE 1.2240218509606162\n",
      "95 Train Loss 0.6370991 Test MSE 6.587214401753248 Test RE 1.2267581724587515\n",
      "96 Train Loss 0.6342809 Test MSE 6.610219116347051 Test RE 1.2288984265481233\n",
      "97 Train Loss 0.63064945 Test MSE 6.6262343775142005 Test RE 1.2303862155642984\n",
      "98 Train Loss 0.6268609 Test MSE 6.635775759410742 Test RE 1.2312717382502592\n",
      "99 Train Loss 0.62487864 Test MSE 6.643973701566719 Test RE 1.2320320697653226\n",
      "Training time: 148.27\n",
      "0\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.69175 Test MSE 4.445072497060129 Test RE 1.0077376500664421\n",
      "1 Train Loss 63.22934 Test MSE 5.708324114828658 Test RE 1.1419901876486094\n",
      "2 Train Loss 47.48172 Test MSE 7.293710515046893 Test RE 1.2908694459053105\n",
      "3 Train Loss 34.804153 Test MSE 6.8837899681556 Test RE 1.2540702514544322\n",
      "4 Train Loss 22.860813 Test MSE 5.730399645617733 Test RE 1.1441962390798037\n",
      "5 Train Loss 16.004221 Test MSE 5.00863649786838 Test RE 1.0697143386831565\n",
      "6 Train Loss 11.26535 Test MSE 4.50631496694149 Test RE 1.0146560095219093\n",
      "7 Train Loss 8.88298 Test MSE 4.37406934506911 Test RE 0.9996567256252948\n",
      "8 Train Loss 7.3068247 Test MSE 3.8429712657876625 Test RE 0.9370043970458382\n",
      "9 Train Loss 6.370599 Test MSE 3.7995440384216765 Test RE 0.9316950787864593\n",
      "10 Train Loss 5.760235 Test MSE 3.735600012057755 Test RE 0.9238218808245503\n",
      "11 Train Loss 5.2189226 Test MSE 3.664070452348353 Test RE 0.9149344241322341\n",
      "12 Train Loss 4.791857 Test MSE 3.5721324261330336 Test RE 0.9033828376263784\n",
      "13 Train Loss 4.382928 Test MSE 3.5407167099028642 Test RE 0.8994015891067817\n",
      "14 Train Loss 3.9545708 Test MSE 3.402425903154043 Test RE 0.8816625590691941\n",
      "15 Train Loss 3.474949 Test MSE 3.2171658926316695 Test RE 0.8573236182328067\n",
      "16 Train Loss 3.1034327 Test MSE 3.082336465451495 Test RE 0.8391663920602257\n",
      "17 Train Loss 2.8129964 Test MSE 2.913723954898461 Test RE 0.8158912254779687\n",
      "18 Train Loss 2.429227 Test MSE 2.4095996805293862 Test RE 0.7419600276827029\n",
      "19 Train Loss 2.1748574 Test MSE 2.260777841953909 Test RE 0.7186823914447295\n",
      "20 Train Loss 1.8313091 Test MSE 2.0370952844409964 Test RE 0.6822031682556268\n",
      "21 Train Loss 1.6747155 Test MSE 1.8599869204325228 Test RE 0.6518730181274007\n",
      "22 Train Loss 1.5003556 Test MSE 1.7856343506404657 Test RE 0.6387108978385959\n",
      "23 Train Loss 1.4031836 Test MSE 1.7114838652667121 Test RE 0.6253086910571243\n",
      "24 Train Loss 1.3198985 Test MSE 1.5544959054835281 Test RE 0.5959404320923128\n",
      "25 Train Loss 1.1359476 Test MSE 1.3705786459142253 Test RE 0.5595772386381924\n",
      "26 Train Loss 1.0049453 Test MSE 1.254557912948886 Test RE 0.5353692429701882\n",
      "27 Train Loss 0.9180881 Test MSE 1.1009038007642022 Test RE 0.5015136359694234\n",
      "28 Train Loss 0.77256256 Test MSE 0.9143766787448653 Test RE 0.4570572799127249\n",
      "29 Train Loss 0.62346977 Test MSE 0.6218942913552932 Test RE 0.37693489586059287\n",
      "30 Train Loss 0.53202564 Test MSE 0.5925610180648301 Test RE 0.36793796259335154\n",
      "31 Train Loss 0.4495126 Test MSE 0.5413364990902902 Test RE 0.35167517744406257\n",
      "32 Train Loss 0.38776293 Test MSE 0.4468159989297555 Test RE 0.3195011442982679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 0.33492917 Test MSE 0.4547383608606897 Test RE 0.32232118888432665\n",
      "34 Train Loss 0.28845733 Test MSE 0.40016478439741693 Test RE 0.3023621979739805\n",
      "35 Train Loss 0.24561207 Test MSE 0.34255521992797594 Test RE 0.2797520999098611\n",
      "36 Train Loss 0.22141635 Test MSE 0.30944634156778084 Test RE 0.2658892240308823\n",
      "37 Train Loss 0.20005514 Test MSE 0.25407499802665706 Test RE 0.24092897097021643\n",
      "38 Train Loss 0.17584035 Test MSE 0.20095269074215683 Test RE 0.21426684416922437\n",
      "39 Train Loss 0.1617223 Test MSE 0.1508001454298484 Test RE 0.18561323519699865\n",
      "40 Train Loss 0.13821915 Test MSE 0.10535814362943548 Test RE 0.15514654736869468\n",
      "41 Train Loss 0.10598885 Test MSE 0.050195962492899454 Test RE 0.10708840579107065\n",
      "42 Train Loss 0.09059489 Test MSE 0.040917362652013387 Test RE 0.09668561786728334\n",
      "43 Train Loss 0.069137625 Test MSE 0.03018188296523697 Test RE 0.08303883080642284\n",
      "44 Train Loss 0.05633439 Test MSE 0.02624044141591542 Test RE 0.07742721325557106\n",
      "45 Train Loss 0.050968744 Test MSE 0.025099908339726106 Test RE 0.07572584497512279\n",
      "46 Train Loss 0.045138676 Test MSE 0.02780920333976651 Test RE 0.07970807744714987\n",
      "47 Train Loss 0.04216492 Test MSE 0.02346334659759908 Test RE 0.07321550095962898\n",
      "48 Train Loss 0.03734305 Test MSE 0.016462396754580874 Test RE 0.0613274055670117\n",
      "49 Train Loss 0.034390725 Test MSE 0.01441020717443805 Test RE 0.057377704910326094\n",
      "50 Train Loss 0.031033846 Test MSE 0.011583345511508294 Test RE 0.05144285528604338\n",
      "51 Train Loss 0.028201083 Test MSE 0.007918868029487188 Test RE 0.042534331642168556\n",
      "52 Train Loss 0.024840426 Test MSE 0.0061729876065424495 Test RE 0.037553962027195756\n",
      "53 Train Loss 0.022987956 Test MSE 0.0056103266917453464 Test RE 0.035801575255469224\n",
      "54 Train Loss 0.02058324 Test MSE 0.005568508016460874 Test RE 0.03566789544347154\n",
      "55 Train Loss 0.018158246 Test MSE 0.005990592970563818 Test RE 0.03699499445451322\n",
      "56 Train Loss 0.016813021 Test MSE 0.00637832472132855 Test RE 0.03817344657856153\n",
      "57 Train Loss 0.015176921 Test MSE 0.005637346402329105 Test RE 0.03588768310155974\n",
      "58 Train Loss 0.014096416 Test MSE 0.005525161560963189 Test RE 0.035528800972054464\n",
      "59 Train Loss 0.0127801215 Test MSE 0.005642694162572424 Test RE 0.035904701146735225\n",
      "60 Train Loss 0.01167836 Test MSE 0.005022268718246275 Test RE 0.03387334093512553\n",
      "61 Train Loss 0.010962147 Test MSE 0.004986118832308791 Test RE 0.03375121197901734\n",
      "62 Train Loss 0.010420645 Test MSE 0.005081280017533595 Test RE 0.03407176444197552\n",
      "63 Train Loss 0.009377802 Test MSE 0.004962544071175945 Test RE 0.03367132825355207\n",
      "64 Train Loss 0.008595918 Test MSE 0.0048672658572828775 Test RE 0.033346525868309204\n",
      "65 Train Loss 0.007631038 Test MSE 0.0041949636639844875 Test RE 0.030957947683326045\n",
      "66 Train Loss 0.0074117617 Test MSE 0.004081432368166674 Test RE 0.03053615577770524\n",
      "67 Train Loss 0.0070060245 Test MSE 0.0038956232814402673 Test RE 0.029832973105743132\n",
      "68 Train Loss 0.0066434103 Test MSE 0.0035937111622274935 Test RE 0.028653629733179385\n",
      "69 Train Loss 0.006374645 Test MSE 0.003198078103403024 Test RE 0.02703040751314531\n",
      "70 Train Loss 0.006153068 Test MSE 0.0030186093223820857 Test RE 0.026261015423147183\n",
      "71 Train Loss 0.0057823835 Test MSE 0.002812760235064616 Test RE 0.025349792986572063\n",
      "72 Train Loss 0.0055433987 Test MSE 0.0029614950600896006 Test RE 0.026011390350772254\n",
      "73 Train Loss 0.005179055 Test MSE 0.0029270610721360635 Test RE 0.025859727982870145\n",
      "74 Train Loss 0.0048748506 Test MSE 0.002798582576569918 Test RE 0.025285824729288593\n",
      "75 Train Loss 0.0046830866 Test MSE 0.00277284316379696 Test RE 0.025169275425789946\n",
      "76 Train Loss 0.004509535 Test MSE 0.0026256809504495928 Test RE 0.024492269917785726\n",
      "77 Train Loss 0.004320992 Test MSE 0.0025085979889603862 Test RE 0.023939969632184414\n",
      "78 Train Loss 0.0041834507 Test MSE 0.0023839027349891236 Test RE 0.023337392272804392\n",
      "79 Train Loss 0.0040521948 Test MSE 0.002184787416547183 Test RE 0.022341516721327986\n",
      "80 Train Loss 0.003875869 Test MSE 0.002220272777351896 Test RE 0.022522221603849958\n",
      "81 Train Loss 0.0035578827 Test MSE 0.002104900067343996 Test RE 0.021929251141842063\n",
      "82 Train Loss 0.003440037 Test MSE 0.002023209657457469 Test RE 0.021499507180144192\n",
      "83 Train Loss 0.00333243 Test MSE 0.002107892254208288 Test RE 0.021944832193835175\n",
      "84 Train Loss 0.0031765457 Test MSE 0.001949643821183684 Test RE 0.021105016651156973\n",
      "85 Train Loss 0.0029650112 Test MSE 0.0017566682619229912 Test RE 0.020033320437565155\n",
      "86 Train Loss 0.002761195 Test MSE 0.001606279318874297 Test RE 0.0191566071958613\n",
      "87 Train Loss 0.0026676962 Test MSE 0.001620449695484873 Test RE 0.01924092014006214\n",
      "88 Train Loss 0.0025704864 Test MSE 0.001613925146777413 Test RE 0.019202145427611842\n",
      "89 Train Loss 0.0024923235 Test MSE 0.0015841279411644518 Test RE 0.019024059140809502\n",
      "90 Train Loss 0.0023567788 Test MSE 0.001426006103748651 Test RE 0.018049648651759176\n",
      "91 Train Loss 0.002211507 Test MSE 0.0014096329191297173 Test RE 0.01794572783316483\n",
      "92 Train Loss 0.0021289107 Test MSE 0.0014063512913454436 Test RE 0.017924826819531076\n",
      "93 Train Loss 0.002027574 Test MSE 0.0012859640909417607 Test RE 0.01714046032091955\n",
      "94 Train Loss 0.0019359175 Test MSE 0.001246397028751238 Test RE 0.01687470785463194\n",
      "95 Train Loss 0.001861206 Test MSE 0.001278945541314175 Test RE 0.01709362162340025\n",
      "96 Train Loss 0.0017985571 Test MSE 0.0012077618507025413 Test RE 0.01661111229003808\n",
      "97 Train Loss 0.0017434277 Test MSE 0.0011667913292954443 Test RE 0.016326934739697933\n",
      "98 Train Loss 0.0017063126 Test MSE 0.0011816615529185108 Test RE 0.016430645021190796\n",
      "99 Train Loss 0.0016894825 Test MSE 0.0011674752313853333 Test RE 0.016331718966653478\n",
      "Training time: 148.51\n",
      "1\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 69.60808 Test MSE 4.958513246109417 Test RE 1.0643483694032028\n",
      "1 Train Loss 49.6711 Test MSE 8.264489994539622 Test RE 1.3740928803530614\n",
      "2 Train Loss 42.17236 Test MSE 8.908593609263335 Test RE 1.4266342106736356\n",
      "3 Train Loss 38.591614 Test MSE 9.035913230254303 Test RE 1.436792612056641\n",
      "4 Train Loss 35.08893 Test MSE 9.761665417667455 Test RE 1.4933789290343937\n",
      "5 Train Loss 31.623457 Test MSE 9.100296474324878 Test RE 1.4419022877632242\n",
      "6 Train Loss 28.584003 Test MSE 9.206211860299437 Test RE 1.4502689295254974\n",
      "7 Train Loss 25.673794 Test MSE 9.221224536876138 Test RE 1.45145093303652\n",
      "8 Train Loss 21.971622 Test MSE 9.146219863618798 Test RE 1.4455358897895703\n",
      "9 Train Loss 18.590534 Test MSE 8.90615420188441 Test RE 1.426438872304616\n",
      "10 Train Loss 15.673632 Test MSE 8.497481617661531 Test RE 1.3933273983844854\n",
      "11 Train Loss 12.200575 Test MSE 7.832266054271232 Test RE 1.337678589949606\n",
      "12 Train Loss 9.324354 Test MSE 6.991769702869303 Test RE 1.2638677081267284\n",
      "13 Train Loss 7.429273 Test MSE 6.23287783051916 Test RE 1.1933074926048943\n",
      "14 Train Loss 6.180949 Test MSE 6.11153753624092 Test RE 1.1816348795634777\n",
      "15 Train Loss 5.261109 Test MSE 6.054201385090326 Test RE 1.176078990588494\n",
      "16 Train Loss 4.3925514 Test MSE 5.990684816524404 Test RE 1.169893413138567\n",
      "17 Train Loss 3.6540565 Test MSE 5.848764435538455 Test RE 1.1559528640020098\n",
      "18 Train Loss 3.147166 Test MSE 5.745666578385388 Test RE 1.1457194092599092\n",
      "19 Train Loss 2.732159 Test MSE 5.683123243630827 Test RE 1.1394665939807243\n",
      "20 Train Loss 2.5158217 Test MSE 5.579569314692496 Test RE 1.129037583152724\n",
      "21 Train Loss 2.3141937 Test MSE 5.651269715251368 Test RE 1.1362687895187493\n",
      "22 Train Loss 2.1561055 Test MSE 5.6533754763558886 Test RE 1.1364804665304604\n",
      "23 Train Loss 2.0192513 Test MSE 5.476309474221711 Test RE 1.1185413706770786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 1.934962 Test MSE 5.454387523007602 Test RE 1.1163003360869084\n",
      "25 Train Loss 1.8523328 Test MSE 5.364148658169777 Test RE 1.107027636027415\n",
      "26 Train Loss 1.7538514 Test MSE 5.4103335213105 Test RE 1.1117831287056599\n",
      "27 Train Loss 1.6638029 Test MSE 5.42322181381433 Test RE 1.1131065649377807\n",
      "28 Train Loss 1.6110663 Test MSE 5.409927466962588 Test RE 1.1117414073549987\n",
      "29 Train Loss 1.5437541 Test MSE 5.4468583833343605 Test RE 1.1155296094408391\n",
      "30 Train Loss 1.5109702 Test MSE 5.447741540787065 Test RE 1.1156200421533693\n",
      "31 Train Loss 1.4761214 Test MSE 5.455286692096 Test RE 1.116392344711836\n",
      "32 Train Loss 1.4402008 Test MSE 5.458486163714095 Test RE 1.1167196732520848\n",
      "33 Train Loss 1.3990062 Test MSE 5.448367178055706 Test RE 1.1156841011246446\n",
      "34 Train Loss 1.3633004 Test MSE 5.530865863186208 Test RE 1.124099159881617\n",
      "35 Train Loss 1.3377893 Test MSE 5.542938608154606 Test RE 1.1253253299991943\n",
      "36 Train Loss 1.3188837 Test MSE 5.604347145875203 Test RE 1.1315417292408907\n",
      "37 Train Loss 1.2944677 Test MSE 5.602312218768585 Test RE 1.1313362803337377\n",
      "38 Train Loss 1.2680817 Test MSE 5.645584159439378 Test RE 1.1356970644337456\n",
      "39 Train Loss 1.240464 Test MSE 5.6819797792884685 Test RE 1.1393519558751213\n",
      "40 Train Loss 1.2236753 Test MSE 5.6899663881124765 Test RE 1.1401524130565126\n",
      "41 Train Loss 1.2067604 Test MSE 5.723300723261481 Test RE 1.143487293987235\n",
      "42 Train Loss 1.1934845 Test MSE 5.711358986319217 Test RE 1.1422937209503456\n",
      "43 Train Loss 1.1751136 Test MSE 5.737351240453634 Test RE 1.144890045651633\n",
      "44 Train Loss 1.1666259 Test MSE 5.751290219968698 Test RE 1.1462799655875684\n",
      "45 Train Loss 1.1566583 Test MSE 5.7501664315048515 Test RE 1.146167969923536\n",
      "46 Train Loss 1.1476611 Test MSE 5.738296373052592 Test RE 1.1449843425056463\n",
      "47 Train Loss 1.1308563 Test MSE 5.76116667754344 Test RE 1.147263773466465\n",
      "48 Train Loss 1.1191931 Test MSE 5.769667267149142 Test RE 1.1481098541551995\n",
      "49 Train Loss 1.1074357 Test MSE 5.759859477818192 Test RE 1.1471336099029785\n",
      "50 Train Loss 1.095446 Test MSE 5.811021274037113 Test RE 1.1522170381569024\n",
      "51 Train Loss 1.082703 Test MSE 5.837742256655583 Test RE 1.1548631357517403\n",
      "52 Train Loss 1.0731987 Test MSE 5.854233529829876 Test RE 1.156493195046614\n",
      "53 Train Loss 1.0629244 Test MSE 5.860927779433461 Test RE 1.157154224552607\n",
      "54 Train Loss 1.054201 Test MSE 5.886329426339869 Test RE 1.1596591047088918\n",
      "55 Train Loss 1.046982 Test MSE 5.888433716408139 Test RE 1.1598663680905543\n",
      "56 Train Loss 1.036871 Test MSE 5.879759439850289 Test RE 1.1590117512187936\n",
      "57 Train Loss 1.0303628 Test MSE 5.887415029585602 Test RE 1.1597660365128015\n",
      "58 Train Loss 1.0217263 Test MSE 5.918098270914904 Test RE 1.1627842657909169\n",
      "59 Train Loss 1.0140693 Test MSE 5.933861946401628 Test RE 1.164331854497394\n",
      "60 Train Loss 1.0053724 Test MSE 5.943144458734585 Test RE 1.1652421976610772\n",
      "61 Train Loss 0.9991383 Test MSE 5.977294100379775 Test RE 1.168585175840811\n",
      "62 Train Loss 0.9920783 Test MSE 6.001853903477751 Test RE 1.1709834852202525\n",
      "63 Train Loss 0.9846509 Test MSE 6.018333248913709 Test RE 1.1725899732988212\n",
      "64 Train Loss 0.98083 Test MSE 6.0069663459308895 Test RE 1.1714821071012158\n",
      "65 Train Loss 0.9761287 Test MSE 6.002168626218688 Test RE 1.171014186592432\n",
      "66 Train Loss 0.97096795 Test MSE 5.983767900862175 Test RE 1.1692178316762465\n",
      "67 Train Loss 0.9639366 Test MSE 6.019272165436183 Test RE 1.172681437257167\n",
      "68 Train Loss 0.9591489 Test MSE 6.011338074184874 Test RE 1.1719083180754362\n",
      "69 Train Loss 0.95593554 Test MSE 6.023892110345856 Test RE 1.173131382393916\n",
      "70 Train Loss 0.95236343 Test MSE 6.01557346257176 Test RE 1.1723210891465892\n",
      "71 Train Loss 0.94719696 Test MSE 6.0120089956632325 Test RE 1.1719737142080724\n",
      "72 Train Loss 0.942639 Test MSE 6.0120395370332425 Test RE 1.1719766910530351\n",
      "73 Train Loss 0.9362228 Test MSE 6.0159135059964255 Test RE 1.1723542226829928\n",
      "74 Train Loss 0.9317662 Test MSE 6.030186821775123 Test RE 1.1737441585911363\n",
      "75 Train Loss 0.92654014 Test MSE 6.041247746152002 Test RE 1.1748201407959078\n",
      "76 Train Loss 0.922486 Test MSE 6.071217028346601 Test RE 1.1777305460945318\n",
      "77 Train Loss 0.91770095 Test MSE 6.096922026427451 Test RE 1.1802211163578251\n",
      "78 Train Loss 0.9130653 Test MSE 6.116338106353487 Test RE 1.1820988714443263\n",
      "79 Train Loss 0.9105185 Test MSE 6.105609413932009 Test RE 1.1810616542878432\n",
      "80 Train Loss 0.9062245 Test MSE 6.104093413810978 Test RE 1.1809150185758097\n",
      "81 Train Loss 0.90085983 Test MSE 6.12512172356252 Test RE 1.182947367612594\n",
      "82 Train Loss 0.8959888 Test MSE 6.142488016952379 Test RE 1.184623160447551\n",
      "83 Train Loss 0.8936349 Test MSE 6.1467722602807475 Test RE 1.1850362120648426\n",
      "84 Train Loss 0.8909826 Test MSE 6.141322985465104 Test RE 1.1845108127534187\n",
      "85 Train Loss 0.8869104 Test MSE 6.1547478717338295 Test RE 1.1858047718968507\n",
      "86 Train Loss 0.88433427 Test MSE 6.158666443538634 Test RE 1.186182197737398\n",
      "87 Train Loss 0.8824067 Test MSE 6.1673020543152655 Test RE 1.1870135318892026\n",
      "88 Train Loss 0.87924373 Test MSE 6.176179900878483 Test RE 1.1878675791066928\n",
      "89 Train Loss 0.8764765 Test MSE 6.183361196533011 Test RE 1.1885579694606343\n",
      "90 Train Loss 0.87478995 Test MSE 6.174964714092914 Test RE 1.1877507146356223\n",
      "91 Train Loss 0.8724358 Test MSE 6.185426659984713 Test RE 1.1887564632890208\n",
      "92 Train Loss 0.86972886 Test MSE 6.175649297600912 Test RE 1.1878165524220219\n",
      "93 Train Loss 0.8659039 Test MSE 6.185937183784064 Test RE 1.188805520207597\n",
      "94 Train Loss 0.861538 Test MSE 6.192676959809135 Test RE 1.1894529646840095\n",
      "95 Train Loss 0.8581966 Test MSE 6.2189622403250535 Test RE 1.1919746526789872\n",
      "96 Train Loss 0.8552698 Test MSE 6.21634980298306 Test RE 1.191724266355139\n",
      "97 Train Loss 0.8537955 Test MSE 6.225353026709332 Test RE 1.1925869493179058\n",
      "98 Train Loss 0.85198665 Test MSE 6.232456001860083 Test RE 1.1932671115938884\n",
      "99 Train Loss 0.8496978 Test MSE 6.223248715660156 Test RE 1.192385371512365\n",
      "Training time: 148.09\n",
      "2\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 68.76258 Test MSE 5.059185627748971 Test RE 1.075098776283218\n",
      "1 Train Loss 50.49436 Test MSE 8.582405253879793 Test RE 1.4002725301691588\n",
      "2 Train Loss 34.03273 Test MSE 6.666614532637332 Test RE 1.2341294972732957\n",
      "3 Train Loss 22.104286 Test MSE 6.081590270735307 Test RE 1.1787362481141588\n",
      "4 Train Loss 15.022814 Test MSE 5.781528656005349 Test RE 1.1492894009868817\n",
      "5 Train Loss 12.577587 Test MSE 6.025184232433271 Test RE 1.1732571937186729\n",
      "6 Train Loss 10.75005 Test MSE 5.8389655223354815 Test RE 1.154984126913952\n",
      "7 Train Loss 9.807873 Test MSE 5.954879477194957 Test RE 1.1663920431169277\n",
      "8 Train Loss 8.666129 Test MSE 5.711555132944151 Test RE 1.1423133358208968\n",
      "9 Train Loss 8.17309 Test MSE 5.752618353803937 Test RE 1.1464123120061045\n",
      "10 Train Loss 7.4925795 Test MSE 5.648886516077834 Test RE 1.1360291760752275\n",
      "11 Train Loss 6.9218864 Test MSE 5.222686702923061 Test RE 1.092332983113068\n",
      "12 Train Loss 6.381096 Test MSE 5.246399981986747 Test RE 1.094810009056689\n",
      "13 Train Loss 6.140438 Test MSE 5.1549246296983116 Test RE 1.0852235763746838\n",
      "14 Train Loss 5.918388 Test MSE 4.790279960938054 Test RE 1.0461368690172042\n",
      "15 Train Loss 5.68036 Test MSE 4.541031187106497 Test RE 1.0185569173812896\n",
      "16 Train Loss 5.5170207 Test MSE 4.4461685810917935 Test RE 1.0078618884296442\n",
      "17 Train Loss 5.3708296 Test MSE 4.221486094080107 Test RE 0.9820661495704796\n",
      "18 Train Loss 5.232193 Test MSE 4.025887862688343 Test RE 0.9590448050843633\n",
      "19 Train Loss 5.1518536 Test MSE 3.949700020862504 Test RE 0.9499267473985236\n",
      "20 Train Loss 5.031657 Test MSE 3.746123862031907 Test RE 0.9251222509401404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 4.939227 Test MSE 3.684772272599514 Test RE 0.9175154511467353\n",
      "22 Train Loss 4.855933 Test MSE 3.534178790040002 Test RE 0.8985708346361507\n",
      "23 Train Loss 4.763749 Test MSE 3.3205510719198146 Test RE 0.8709899470908823\n",
      "24 Train Loss 4.644169 Test MSE 3.0477639158175505 Test RE 0.8344469310244356\n",
      "25 Train Loss 4.5075083 Test MSE 2.7925390919467477 Test RE 0.7987441510478558\n",
      "26 Train Loss 4.326232 Test MSE 2.558337971733802 Test RE 0.7645167742380187\n",
      "27 Train Loss 3.9263468 Test MSE 2.2583245529666804 Test RE 0.7182923455629495\n",
      "28 Train Loss 3.5727537 Test MSE 2.1607237232631666 Test RE 0.7025992476128465\n",
      "29 Train Loss 2.7206974 Test MSE 1.9137943384612774 Test RE 0.6612347864786057\n",
      "30 Train Loss 2.206731 Test MSE 1.7397322256378578 Test RE 0.6304479898543666\n",
      "31 Train Loss 1.945449 Test MSE 1.6227277227187955 Test RE 0.6088788492517081\n",
      "32 Train Loss 1.7739419 Test MSE 1.5938746915065112 Test RE 0.6034414630052019\n",
      "33 Train Loss 1.5646385 Test MSE 1.5322595967042716 Test RE 0.5916627602959283\n",
      "34 Train Loss 1.4111257 Test MSE 1.4859984751069304 Test RE 0.5826627337742528\n",
      "35 Train Loss 1.2784191 Test MSE 1.355019337075453 Test RE 0.5563919100951972\n",
      "36 Train Loss 1.0625958 Test MSE 0.9870684566344741 Test RE 0.47487761386623584\n",
      "37 Train Loss 0.86926174 Test MSE 0.6945286540922349 Test RE 0.3983392894280904\n",
      "38 Train Loss 0.6582992 Test MSE 0.4006216035751779 Test RE 0.3025347337123465\n",
      "39 Train Loss 0.48535722 Test MSE 0.3102768288128062 Test RE 0.2662457796291753\n",
      "40 Train Loss 0.36244056 Test MSE 0.17915618569963537 Test RE 0.20231308105683313\n",
      "41 Train Loss 0.25538254 Test MSE 0.11490224230164188 Test RE 0.16202137453642854\n",
      "42 Train Loss 0.1884706 Test MSE 0.06536306263274293 Test RE 0.1222008584701957\n",
      "43 Train Loss 0.14719464 Test MSE 0.04431073760948766 Test RE 0.10061495794896634\n",
      "44 Train Loss 0.12622344 Test MSE 0.03401556717919057 Test RE 0.08815499369213096\n",
      "45 Train Loss 0.099714495 Test MSE 0.02305751028651986 Test RE 0.07257954909803298\n",
      "46 Train Loss 0.08514692 Test MSE 0.025379273819774097 Test RE 0.07614609844835057\n",
      "47 Train Loss 0.06840852 Test MSE 0.016667473790467926 Test RE 0.061708210271307525\n",
      "48 Train Loss 0.056676015 Test MSE 0.014804480109961977 Test RE 0.05815735421518774\n",
      "49 Train Loss 0.04633738 Test MSE 0.009568878205635244 Test RE 0.046756131747500526\n",
      "50 Train Loss 0.04084116 Test MSE 0.009126774348653362 Test RE 0.045663239323064674\n",
      "51 Train Loss 0.033784673 Test MSE 0.007037767061632878 Test RE 0.04009825786932522\n",
      "52 Train Loss 0.030249149 Test MSE 0.007137885299391657 Test RE 0.04038246661639669\n",
      "53 Train Loss 0.026624843 Test MSE 0.006776378162951087 Test RE 0.039346569843801915\n",
      "54 Train Loss 0.022849225 Test MSE 0.009686450321042723 Test RE 0.047042499395335315\n",
      "55 Train Loss 0.019997558 Test MSE 0.00962320574905055 Test RE 0.04688867343559419\n",
      "56 Train Loss 0.0184252 Test MSE 0.009047281733903179 Test RE 0.04546394498914878\n",
      "57 Train Loss 0.01687846 Test MSE 0.008905467025956376 Test RE 0.045106217554334596\n",
      "58 Train Loss 0.014192067 Test MSE 0.007278864791847619 Test RE 0.040779311249668486\n",
      "59 Train Loss 0.012869846 Test MSE 0.007453381792489995 Test RE 0.041265275063057584\n",
      "60 Train Loss 0.012143 Test MSE 0.00806402033987021 Test RE 0.0429223871570459\n",
      "61 Train Loss 0.010524632 Test MSE 0.006755946664366322 Test RE 0.03928720802470078\n",
      "62 Train Loss 0.009144521 Test MSE 0.0061259543771694435 Test RE 0.0374106228923014\n",
      "63 Train Loss 0.008230618 Test MSE 0.006480520842144403 Test RE 0.03847804658790154\n",
      "64 Train Loss 0.0076824324 Test MSE 0.006378427112303933 Test RE 0.03817375297568881\n",
      "65 Train Loss 0.007380758 Test MSE 0.006790134486976786 Test RE 0.03938648716633397\n",
      "66 Train Loss 0.007087719 Test MSE 0.006112063013347666 Test RE 0.0373681821974929\n",
      "67 Train Loss 0.006733729 Test MSE 0.005958453194099723 Test RE 0.03689562116014236\n",
      "68 Train Loss 0.0064774416 Test MSE 0.006179555002962446 Test RE 0.037573933409687524\n",
      "69 Train Loss 0.0061076446 Test MSE 0.006404860595057653 Test RE 0.038252771042494374\n",
      "70 Train Loss 0.005919086 Test MSE 0.006231912267168802 Test RE 0.03773277323869395\n",
      "71 Train Loss 0.0056258515 Test MSE 0.006200352419635288 Test RE 0.03763710821468709\n",
      "72 Train Loss 0.0052156597 Test MSE 0.0056132907881756315 Test RE 0.035811031505922596\n",
      "73 Train Loss 0.0046982598 Test MSE 0.005267553760017914 Test RE 0.03469065889040049\n",
      "74 Train Loss 0.0045554857 Test MSE 0.0051315823557238375 Test RE 0.03423999652115939\n",
      "75 Train Loss 0.0042298185 Test MSE 0.004646701286979729 Test RE 0.032582202436380436\n",
      "76 Train Loss 0.0038049277 Test MSE 0.004333025216345659 Test RE 0.031463256331984685\n",
      "77 Train Loss 0.0036069518 Test MSE 0.0038608484681151374 Test RE 0.02969952056288017\n",
      "78 Train Loss 0.0032677292 Test MSE 0.0038803893444142572 Test RE 0.029774584655505545\n",
      "79 Train Loss 0.0031248857 Test MSE 0.003935913559445124 Test RE 0.029986849239453727\n",
      "80 Train Loss 0.0030908366 Test MSE 0.003809795497452154 Test RE 0.029502504982491618\n",
      "81 Train Loss 0.0030501774 Test MSE 0.00362629638926168 Test RE 0.028783241996236678\n",
      "82 Train Loss 0.0028401706 Test MSE 0.003252468060111362 Test RE 0.02725929254443502\n",
      "83 Train Loss 0.0027147247 Test MSE 0.002652967027725582 Test RE 0.024619202836781595\n",
      "84 Train Loss 0.0026535052 Test MSE 0.002561686352868228 Test RE 0.024191958988936803\n",
      "85 Train Loss 0.002601752 Test MSE 0.00244408797914498 Test RE 0.023630149963445434\n",
      "86 Train Loss 0.0025635543 Test MSE 0.002408935727211742 Test RE 0.023459603445635035\n",
      "87 Train Loss 0.002498361 Test MSE 0.002362544823500386 Test RE 0.023232614635612634\n",
      "88 Train Loss 0.0024612593 Test MSE 0.002277895604099284 Test RE 0.022812609611224294\n",
      "89 Train Loss 0.0024065922 Test MSE 0.0022312935158890364 Test RE 0.02257804903846076\n",
      "90 Train Loss 0.0023196365 Test MSE 0.001917970055161524 Test RE 0.020932879404243727\n",
      "91 Train Loss 0.002246691 Test MSE 0.0016022371139616375 Test RE 0.01913248819349101\n",
      "92 Train Loss 0.0021864998 Test MSE 0.001478917671788735 Test RE 0.01838146236966188\n",
      "93 Train Loss 0.00215216 Test MSE 0.0014739885010674803 Test RE 0.018350804480482208\n",
      "94 Train Loss 0.002091196 Test MSE 0.001652498496784024 Test RE 0.01943025932050629\n",
      "95 Train Loss 0.0019770951 Test MSE 0.0014760096416105597 Test RE 0.018363381528834228\n",
      "96 Train Loss 0.0018895208 Test MSE 0.0013361556655785587 Test RE 0.017471757330175915\n",
      "97 Train Loss 0.0018293747 Test MSE 0.001303044815524162 Test RE 0.01725391827373994\n",
      "98 Train Loss 0.0018037783 Test MSE 0.001267110968126754 Test RE 0.017014350901020655\n",
      "99 Train Loss 0.001774019 Test MSE 0.0011224784160262266 Test RE 0.016013898063034288\n",
      "Training time: 148.57\n",
      "3\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "1 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "2 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "3 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "4 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "5 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "6 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "7 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "8 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "9 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "10 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "11 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "13 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "14 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "15 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "16 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "17 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "18 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "19 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "20 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "21 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "22 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "23 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "24 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "25 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "26 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "27 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "28 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "29 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "30 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "31 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "32 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "33 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "34 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "35 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "36 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "37 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "38 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "39 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "40 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "41 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "42 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "43 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "44 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "45 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "46 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "47 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "48 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "49 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "50 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "51 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "52 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "53 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "54 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "55 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "56 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "57 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "58 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "59 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "60 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "61 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "62 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "63 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "64 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "65 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "66 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "67 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "68 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "69 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "70 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "71 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "72 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "73 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "74 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "75 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "76 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "77 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "78 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "79 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "80 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "81 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "82 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "83 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "84 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "85 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "86 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "87 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "88 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "89 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "90 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "91 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "92 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "93 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "94 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "95 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "96 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "97 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "98 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "99 Train Loss 67.82509 Test MSE 5.32907435554159 Test RE 1.1034024660123407\n",
      "Training time: 64.17\n",
      "4\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 49.5935 Test MSE 8.169142252433033 Test RE 1.3661434040140585\n",
      "1 Train Loss 38.39946 Test MSE 8.219498118446591 Test RE 1.3703474957267807\n",
      "2 Train Loss 28.600803 Test MSE 7.301702624796892 Test RE 1.2915764897104514\n",
      "3 Train Loss 22.191135 Test MSE 6.62098611146468 Test RE 1.2298988593242446\n",
      "4 Train Loss 17.995125 Test MSE 5.676823534600746 Test RE 1.1388348728244837\n",
      "5 Train Loss 13.410796 Test MSE 5.100671048192747 Test RE 1.0794976923220425\n",
      "6 Train Loss 10.729383 Test MSE 4.698261132585844 Test RE 1.036040269132334\n",
      "7 Train Loss 9.172944 Test MSE 4.953282216171746 Test RE 1.063786799120831\n",
      "8 Train Loss 7.7078457 Test MSE 4.249178364934207 Test RE 0.9852819824704754\n",
      "9 Train Loss 6.9182034 Test MSE 3.7888856917467812 Test RE 0.930387382010026\n",
      "10 Train Loss 5.967616 Test MSE 3.344597913331525 Test RE 0.8741380351896039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 5.5889654 Test MSE 3.0699536277368513 Test RE 0.8374790813584819\n",
      "12 Train Loss 4.79706 Test MSE 2.5548588578214066 Test RE 0.7639967597056238\n",
      "13 Train Loss 3.8660107 Test MSE 2.288143927111379 Test RE 0.7230190324027349\n",
      "14 Train Loss 2.8205361 Test MSE 1.9560982342855882 Test RE 0.6685030465591064\n",
      "15 Train Loss 2.2234697 Test MSE 1.756192636676137 Test RE 0.6334234483519161\n",
      "16 Train Loss 1.8778484 Test MSE 1.650845963157903 Test RE 0.6141314470527471\n",
      "17 Train Loss 1.5923183 Test MSE 1.4158505762368414 Test RE 0.5687439255586307\n",
      "18 Train Loss 1.3188822 Test MSE 1.271821362464516 Test RE 0.5390401543599009\n",
      "19 Train Loss 1.0966216 Test MSE 1.1507655447174687 Test RE 0.5127450605367218\n",
      "20 Train Loss 0.9740266 Test MSE 1.0715795705261122 Test RE 0.4947892699596698\n",
      "21 Train Loss 0.8689187 Test MSE 0.9390454776350149 Test RE 0.4631816793706532\n",
      "22 Train Loss 0.7426086 Test MSE 0.6586821854418523 Test RE 0.38792343717568273\n",
      "23 Train Loss 0.57841885 Test MSE 0.5412312716320838 Test RE 0.35164099567023344\n",
      "24 Train Loss 0.4991227 Test MSE 0.4152713494922794 Test RE 0.30801654483784674\n",
      "25 Train Loss 0.40090007 Test MSE 0.3364769669558415 Test RE 0.27725904982712374\n",
      "26 Train Loss 0.33232424 Test MSE 0.2725140070345896 Test RE 0.24951834150336794\n",
      "27 Train Loss 0.2675549 Test MSE 0.1833463013269622 Test RE 0.204665262548015\n",
      "28 Train Loss 0.20294702 Test MSE 0.11770432992255099 Test RE 0.1639850588081457\n",
      "29 Train Loss 0.15890037 Test MSE 0.06442824261672371 Test RE 0.12132385546515763\n",
      "30 Train Loss 0.12050928 Test MSE 0.037422688812518014 Test RE 0.09246461259385938\n",
      "31 Train Loss 0.09734768 Test MSE 0.030841233157848626 Test RE 0.0839409591904699\n",
      "32 Train Loss 0.07753486 Test MSE 0.021288235197140556 Test RE 0.06973934918159215\n",
      "33 Train Loss 0.06409752 Test MSE 0.02116924089939085 Test RE 0.06954416592837684\n",
      "34 Train Loss 0.058251753 Test MSE 0.01866835012352998 Test RE 0.06530719472389217\n",
      "35 Train Loss 0.05256863 Test MSE 0.015624459619228611 Test RE 0.05974623782066287\n",
      "36 Train Loss 0.047735672 Test MSE 0.01220643708568532 Test RE 0.05280834035148238\n",
      "37 Train Loss 0.041861143 Test MSE 0.010874270370494684 Test RE 0.04984345327684011\n",
      "38 Train Loss 0.03813416 Test MSE 0.010638356518616656 Test RE 0.04929981965264505\n",
      "39 Train Loss 0.034729216 Test MSE 0.011581268514795155 Test RE 0.05143824299888919\n",
      "40 Train Loss 0.0316153 Test MSE 0.009750649196289585 Test RE 0.047198133705455364\n",
      "41 Train Loss 0.027953655 Test MSE 0.009172088070724872 Test RE 0.045776456177898876\n",
      "42 Train Loss 0.025185594 Test MSE 0.008685159591050469 Test RE 0.04454479471426327\n",
      "43 Train Loss 0.023027794 Test MSE 0.008530108953270403 Test RE 0.044145389139449105\n",
      "44 Train Loss 0.020731192 Test MSE 0.008134479198965563 Test RE 0.04310949513361118\n",
      "45 Train Loss 0.019187585 Test MSE 0.0074760626583863145 Test RE 0.041328013110010095\n",
      "46 Train Loss 0.018486623 Test MSE 0.00694887666448919 Test RE 0.03984422299260431\n",
      "47 Train Loss 0.017029075 Test MSE 0.0054173332044866315 Test RE 0.03518040498338604\n",
      "48 Train Loss 0.016216645 Test MSE 0.004772927850520798 Test RE 0.033021781164501704\n",
      "49 Train Loss 0.015588053 Test MSE 0.004654282850263059 Test RE 0.03260877218289248\n",
      "50 Train Loss 0.014759801 Test MSE 0.004601896866704849 Test RE 0.03242473989958481\n",
      "51 Train Loss 0.013143868 Test MSE 0.004053140105898376 Test RE 0.030430134257272864\n",
      "52 Train Loss 0.012498238 Test MSE 0.004294282900579345 Test RE 0.03132228133975957\n",
      "53 Train Loss 0.011859555 Test MSE 0.0038159583110165185 Test RE 0.029526357308553533\n",
      "54 Train Loss 0.010680463 Test MSE 0.003823779376870736 Test RE 0.029556599958209535\n",
      "55 Train Loss 0.0097282315 Test MSE 0.0033533643535513776 Test RE 0.027678874849387598\n",
      "56 Train Loss 0.009150902 Test MSE 0.0032274454851176464 Test RE 0.027154231608427084\n",
      "57 Train Loss 0.00867698 Test MSE 0.0029912627005009725 Test RE 0.026141790991665442\n",
      "58 Train Loss 0.008280761 Test MSE 0.003095311462395111 Test RE 0.02659256553933881\n",
      "59 Train Loss 0.008027601 Test MSE 0.0030636669818336587 Test RE 0.026456283656610128\n",
      "60 Train Loss 0.007881931 Test MSE 0.00321803960842507 Test RE 0.027114634392221084\n",
      "61 Train Loss 0.007316224 Test MSE 0.0026918131710732766 Test RE 0.024798791498333944\n",
      "62 Train Loss 0.006981891 Test MSE 0.0026146293977287556 Test RE 0.02444067129623559\n",
      "63 Train Loss 0.006736114 Test MSE 0.0023237846589249426 Test RE 0.02304124810697056\n",
      "64 Train Loss 0.006415762 Test MSE 0.002046612698379391 Test RE 0.021623495114029983\n",
      "65 Train Loss 0.006197513 Test MSE 0.0018844990827537953 Test RE 0.02074942305379316\n",
      "66 Train Loss 0.006091566 Test MSE 0.0018088521564055746 Test RE 0.020328699505174058\n",
      "67 Train Loss 0.0059690704 Test MSE 0.001816297587239582 Test RE 0.02037049410291366\n",
      "68 Train Loss 0.0056766714 Test MSE 0.001765225489842459 Test RE 0.020082055144339993\n",
      "69 Train Loss 0.0054581407 Test MSE 0.001675674406825227 Test RE 0.01956603736549188\n",
      "70 Train Loss 0.005277919 Test MSE 0.0015874134071216183 Test RE 0.01904377677945876\n",
      "71 Train Loss 0.0051123034 Test MSE 0.0015019103829540877 Test RE 0.01852379943706448\n",
      "72 Train Loss 0.0049604126 Test MSE 0.0013897832859683476 Test RE 0.01781892920913739\n",
      "73 Train Loss 0.004851217 Test MSE 0.0013657540977778117 Test RE 0.017664213954734376\n",
      "74 Train Loss 0.00467987 Test MSE 0.0012465391411963754 Test RE 0.01687566984250002\n",
      "75 Train Loss 0.004455228 Test MSE 0.0011734318520618342 Test RE 0.016373329307255657\n",
      "76 Train Loss 0.004320966 Test MSE 0.0011699314986643083 Test RE 0.016348890204353077\n",
      "77 Train Loss 0.004242676 Test MSE 0.0011729924485087394 Test RE 0.016370263439944945\n",
      "78 Train Loss 0.004142448 Test MSE 0.0011854246245239029 Test RE 0.016456786409443497\n",
      "79 Train Loss 0.0039873966 Test MSE 0.0010462450610308736 Test RE 0.015460543986418092\n",
      "80 Train Loss 0.0038446062 Test MSE 0.0011449596325302889 Test RE 0.01617346778646302\n",
      "81 Train Loss 0.0036884556 Test MSE 0.0009854479559741308 Test RE 0.015004616739519297\n",
      "82 Train Loss 0.0035283463 Test MSE 0.0009059410630458448 Test RE 0.014386595495928913\n",
      "83 Train Loss 0.0034490414 Test MSE 0.0009508175662069605 Test RE 0.014738614463197212\n",
      "84 Train Loss 0.003395998 Test MSE 0.0009295514630251951 Test RE 0.014572859562212836\n",
      "85 Train Loss 0.003331502 Test MSE 0.000917457845334123 Test RE 0.01447775155475485\n",
      "86 Train Loss 0.003203755 Test MSE 0.0009174652257686825 Test RE 0.014477809787339369\n",
      "87 Train Loss 0.0030904457 Test MSE 0.0008578097144128789 Test RE 0.013999210386705745\n",
      "88 Train Loss 0.003041825 Test MSE 0.0008676451588695471 Test RE 0.014079237474630486\n",
      "89 Train Loss 0.0030095626 Test MSE 0.000858840765330409 Test RE 0.0140076210888944\n",
      "90 Train Loss 0.0029663644 Test MSE 0.0008671956815137536 Test RE 0.014075590178174231\n",
      "91 Train Loss 0.0029111174 Test MSE 0.0008991632978582063 Test RE 0.01433267806521198\n",
      "92 Train Loss 0.0028387983 Test MSE 0.0009004709104190929 Test RE 0.014343095962106773\n",
      "93 Train Loss 0.002748379 Test MSE 0.000873234015382882 Test RE 0.014124509744188376\n",
      "94 Train Loss 0.0026112348 Test MSE 0.0009274438783527331 Test RE 0.014556329565898491\n",
      "95 Train Loss 0.0024463872 Test MSE 0.0009054619766597456 Test RE 0.014382790980496347\n",
      "96 Train Loss 0.0023883528 Test MSE 0.0009344499334877708 Test RE 0.014611206511073229\n",
      "97 Train Loss 0.002349055 Test MSE 0.00091840185877557 Test RE 0.014485198043032362\n",
      "98 Train Loss 0.0022935658 Test MSE 0.0009235695765257525 Test RE 0.014525893959165596\n",
      "99 Train Loss 0.0022421004 Test MSE 0.000878524219885103 Test RE 0.014167229517000163\n",
      "Training time: 148.54\n",
      "5\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.38852 Test MSE 4.983232397042116 Test RE 1.0669980628004203\n",
      "1 Train Loss 69.63415 Test MSE 5.262242600235894 Test RE 1.0964617686301894\n",
      "2 Train Loss 52.945312 Test MSE 9.08322760617105 Test RE 1.440549409228893\n",
      "3 Train Loss 42.84256 Test MSE 8.257882108957855 Test RE 1.3735434414756642\n",
      "4 Train Loss 37.73062 Test MSE 8.730741415148275 Test RE 1.4123216709713458\n",
      "5 Train Loss 34.284714 Test MSE 9.425794216739732 Test RE 1.46746258561338\n",
      "6 Train Loss 30.800257 Test MSE 9.297257889681294 Test RE 1.4574225978430853\n",
      "7 Train Loss 27.660473 Test MSE 9.167068786463595 Test RE 1.4471825105422491\n",
      "8 Train Loss 25.138857 Test MSE 9.303238521017775 Test RE 1.457891279366292\n",
      "9 Train Loss 22.311394 Test MSE 9.442207072579256 Test RE 1.4687396544575961\n",
      "10 Train Loss 19.916088 Test MSE 9.111823346490416 Test RE 1.4428151900848138\n",
      "11 Train Loss 18.091537 Test MSE 9.108254972201067 Test RE 1.4425326446163522\n",
      "12 Train Loss 16.01584 Test MSE 9.043908836806432 Test RE 1.4374281586749962\n",
      "13 Train Loss 14.696724 Test MSE 8.917368199840928 Test RE 1.4273366251461286\n",
      "14 Train Loss 13.44045 Test MSE 8.779762358471912 Test RE 1.4162810386339675\n",
      "15 Train Loss 12.0457325 Test MSE 8.3742825532311 Test RE 1.383190079250791\n",
      "16 Train Loss 10.579767 Test MSE 8.376918514004965 Test RE 1.3834077544903953\n",
      "17 Train Loss 9.359218 Test MSE 7.919390717774829 Test RE 1.3450980571124447\n",
      "18 Train Loss 8.321344 Test MSE 7.761402814487364 Test RE 1.3316134471071732\n",
      "19 Train Loss 7.4501753 Test MSE 7.597362484085957 Test RE 1.3174662065301936\n",
      "20 Train Loss 6.449898 Test MSE 7.566860999281675 Test RE 1.3148189003399575\n",
      "21 Train Loss 5.2892485 Test MSE 7.48150725426244 Test RE 1.3073823300898741\n",
      "22 Train Loss 4.663197 Test MSE 7.36222865287779 Test RE 1.2969185766788807\n",
      "23 Train Loss 3.9937303 Test MSE 7.135273590993977 Test RE 1.2767720747853912\n",
      "24 Train Loss 3.415021 Test MSE 6.901199427883662 Test RE 1.2556550542353806\n",
      "25 Train Loss 3.138368 Test MSE 6.7614992420932785 Test RE 1.2428810376128896\n",
      "26 Train Loss 2.8831933 Test MSE 6.898886068874693 Test RE 1.2554445818072335\n",
      "27 Train Loss 2.6805806 Test MSE 6.952415459643975 Test RE 1.2603057526244854\n",
      "28 Train Loss 2.5368927 Test MSE 7.032178942243585 Test RE 1.2675147355805902\n",
      "29 Train Loss 2.4152403 Test MSE 7.112794958588116 Test RE 1.2747593468009755\n",
      "30 Train Loss 2.3131392 Test MSE 7.129512168360783 Test RE 1.276256501769709\n",
      "31 Train Loss 2.181506 Test MSE 7.076788116639746 Test RE 1.2715286691534335\n",
      "32 Train Loss 2.1029534 Test MSE 7.1616502006136304 Test RE 1.2791297876752825\n",
      "33 Train Loss 2.0158956 Test MSE 7.212807228480123 Test RE 1.2836901917423547\n",
      "34 Train Loss 1.9488254 Test MSE 7.1873995336208685 Test RE 1.2814272460452085\n",
      "35 Train Loss 1.8899403 Test MSE 7.176568826475902 Test RE 1.280461389368403\n",
      "36 Train Loss 1.8190084 Test MSE 7.178549803869672 Test RE 1.2806381026492777\n",
      "37 Train Loss 1.774911 Test MSE 7.137561611739469 Test RE 1.2769767653839872\n",
      "38 Train Loss 1.7243764 Test MSE 7.138287850872622 Test RE 1.2770417292302245\n",
      "39 Train Loss 1.6786182 Test MSE 7.0411616486859465 Test RE 1.2683240209562963\n",
      "40 Train Loss 1.6143398 Test MSE 7.059061382490177 Test RE 1.2699351366617648\n",
      "41 Train Loss 1.5630559 Test MSE 6.995549129670903 Test RE 1.2642092561433305\n",
      "42 Train Loss 1.5180656 Test MSE 6.942292243039997 Test RE 1.2593878704979513\n",
      "43 Train Loss 1.4607551 Test MSE 6.900877940686638 Test RE 1.255625807020502\n",
      "44 Train Loss 1.4144061 Test MSE 6.822353065974224 Test RE 1.2484615046824032\n",
      "45 Train Loss 1.38586 Test MSE 6.762632455993002 Test RE 1.2429851854511633\n",
      "46 Train Loss 1.3485757 Test MSE 6.620990841869114 Test RE 1.2298992986785855\n",
      "47 Train Loss 1.3148195 Test MSE 6.585526930098297 Test RE 1.2266010307512083\n",
      "48 Train Loss 1.2754469 Test MSE 6.5292472038088345 Test RE 1.221348535951931\n",
      "49 Train Loss 1.2485442 Test MSE 6.460345647429305 Test RE 1.21488714747819\n",
      "50 Train Loss 1.2355767 Test MSE 6.475187552369116 Test RE 1.2162818789864187\n",
      "51 Train Loss 1.2188511 Test MSE 6.445680714577175 Test RE 1.2135074720254309\n",
      "52 Train Loss 1.1962763 Test MSE 6.373632274499302 Test RE 1.2067062495077088\n",
      "53 Train Loss 1.1773354 Test MSE 6.3273138431007965 Test RE 1.202313569262508\n",
      "54 Train Loss 1.1629581 Test MSE 6.274240538558836 Test RE 1.1972604669035534\n",
      "55 Train Loss 1.1481434 Test MSE 6.210936511984625 Test RE 1.1912052676260043\n",
      "56 Train Loss 1.1355875 Test MSE 6.200548072427038 Test RE 1.1902086431433223\n",
      "57 Train Loss 1.1248201 Test MSE 6.186346474440763 Test RE 1.1888448480353357\n",
      "58 Train Loss 1.1110975 Test MSE 6.185064838093722 Test RE 1.1887216941109724\n",
      "59 Train Loss 1.1001768 Test MSE 6.139475206233168 Test RE 1.1843326036653363\n",
      "60 Train Loss 1.0915475 Test MSE 6.149578013560563 Test RE 1.1853066417929718\n",
      "61 Train Loss 1.0837268 Test MSE 6.158440402051109 Test RE 1.1861604293195749\n",
      "62 Train Loss 1.0711875 Test MSE 6.12413325258028 Test RE 1.1828519118503487\n",
      "63 Train Loss 1.0570737 Test MSE 6.116446436683134 Test RE 1.1821093398480649\n",
      "64 Train Loss 1.0471963 Test MSE 6.097162882192994 Test RE 1.180244428141369\n",
      "65 Train Loss 1.0349025 Test MSE 6.103971285180295 Test RE 1.180903204843139\n",
      "66 Train Loss 1.0259391 Test MSE 6.116759785664281 Test RE 1.1821396195224716\n",
      "67 Train Loss 1.019503 Test MSE 6.098225256649098 Test RE 1.1803472470214729\n",
      "68 Train Loss 1.010702 Test MSE 6.1039539388834365 Test RE 1.1809015268935594\n",
      "69 Train Loss 1.0031837 Test MSE 6.089243994675824 Test RE 1.1794777388057325\n",
      "70 Train Loss 0.9968729 Test MSE 6.08367770298584 Test RE 1.1789385242334727\n",
      "71 Train Loss 0.9913493 Test MSE 6.074370110052491 Test RE 1.178036333105512\n",
      "72 Train Loss 0.98556936 Test MSE 6.071870437658747 Test RE 1.1777939204886827\n",
      "73 Train Loss 0.97847706 Test MSE 6.069588737311723 Test RE 1.1775726027465798\n",
      "74 Train Loss 0.9730223 Test MSE 6.085925752791125 Test RE 1.1791563256898927\n",
      "75 Train Loss 0.9666131 Test MSE 6.092932977653252 Test RE 1.1798349600398257\n",
      "76 Train Loss 0.9581697 Test MSE 6.090705847170431 Test RE 1.1796193096645016\n",
      "77 Train Loss 0.9523951 Test MSE 6.092102680385494 Test RE 1.1797545679591055\n",
      "78 Train Loss 0.94460446 Test MSE 6.060986567796887 Test RE 1.1767378451361663\n",
      "79 Train Loss 0.93640053 Test MSE 6.050817967965876 Test RE 1.1757503161984046\n",
      "80 Train Loss 0.9299666 Test MSE 6.0382415441339745 Test RE 1.174527801671905\n",
      "81 Train Loss 0.9247954 Test MSE 6.034413622558376 Test RE 1.1741554488054233\n",
      "82 Train Loss 0.9207411 Test MSE 6.04175423484669 Test RE 1.1748693872987388\n",
      "83 Train Loss 0.91553354 Test MSE 6.023014736459345 Test RE 1.1730459465741463\n",
      "84 Train Loss 0.91116524 Test MSE 6.01286859690578 Test RE 1.172057496023228\n",
      "85 Train Loss 0.9055504 Test MSE 6.012952994992126 Test RE 1.1720657216364316\n",
      "86 Train Loss 0.9004366 Test MSE 6.014642332122905 Test RE 1.1722303558098053\n",
      "87 Train Loss 0.8961482 Test MSE 6.004262676964336 Test RE 1.1712184418742708\n",
      "88 Train Loss 0.8919151 Test MSE 6.004061393090075 Test RE 1.1711988100415154\n",
      "89 Train Loss 0.8876194 Test MSE 6.02297356804784 Test RE 1.1730419375750922\n",
      "90 Train Loss 0.88295686 Test MSE 6.026191851435228 Test RE 1.173355294189554\n",
      "91 Train Loss 0.8795838 Test MSE 6.017914078202026 Test RE 1.1725491377458555\n",
      "92 Train Loss 0.87554586 Test MSE 6.0254347201985645 Test RE 1.1732815816466453\n",
      "93 Train Loss 0.8719767 Test MSE 6.038457214937084 Test RE 1.174548777074308\n",
      "94 Train Loss 0.86762726 Test MSE 6.037203371665021 Test RE 1.1744268273372873\n",
      "95 Train Loss 0.86459905 Test MSE 6.043594323709335 Test RE 1.175048283974294\n",
      "96 Train Loss 0.860461 Test MSE 6.066845337126096 Test RE 1.1773064464908083\n",
      "97 Train Loss 0.85740006 Test MSE 6.065057806353184 Test RE 1.1771329933678827\n",
      "98 Train Loss 0.85299045 Test MSE 6.0608766117891975 Test RE 1.176727171132772\n",
      "99 Train Loss 0.847914 Test MSE 6.072092880896299 Test RE 1.1778154945568426\n",
      "Training time: 149.65\n",
      "6\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.48941 Test MSE 5.88658330660182 Test RE 1.1596841127709168\n",
      "1 Train Loss 50.09228 Test MSE 8.476758671708955 Test RE 1.3916273962574235\n",
      "2 Train Loss 41.682213 Test MSE 8.766255832283466 Test RE 1.415191236956695\n",
      "3 Train Loss 38.896175 Test MSE 9.068019258620726 Test RE 1.439342924310003\n",
      "4 Train Loss 36.394066 Test MSE 9.199438343941145 Test RE 1.4497353100498744\n",
      "5 Train Loss 33.98913 Test MSE 8.583212825275162 Test RE 1.400338408754907\n",
      "6 Train Loss 30.227737 Test MSE 8.779974286177998 Test RE 1.4162981317720387\n",
      "7 Train Loss 28.077087 Test MSE 8.645794310988926 Test RE 1.4054341752919564\n",
      "8 Train Loss 25.530535 Test MSE 8.583408190537506 Test RE 1.4003543454402392\n",
      "9 Train Loss 23.516912 Test MSE 8.143316111133274 Test RE 1.3639822136961615\n",
      "10 Train Loss 20.879587 Test MSE 7.935847114669606 Test RE 1.346494880485815\n",
      "11 Train Loss 18.437218 Test MSE 7.872653618165353 Test RE 1.3411230663999367\n",
      "12 Train Loss 16.136225 Test MSE 7.698806648920156 Test RE 1.326232806360573\n",
      "13 Train Loss 13.227899 Test MSE 6.456936004705871 Test RE 1.2145665084557065\n",
      "14 Train Loss 10.983002 Test MSE 6.545810179483884 Test RE 1.222896674098179\n",
      "15 Train Loss 9.933134 Test MSE 6.422891626014615 Test RE 1.211360358514851\n",
      "16 Train Loss 9.034477 Test MSE 6.5796927649967705 Test RE 1.2260575830790583\n",
      "17 Train Loss 8.165271 Test MSE 6.394764276646801 Test RE 1.2087050326419002\n",
      "18 Train Loss 7.243451 Test MSE 5.997939139338782 Test RE 1.1706015305790605\n",
      "19 Train Loss 5.711098 Test MSE 5.444928218001554 Test RE 1.1153319406920026\n",
      "20 Train Loss 4.761629 Test MSE 4.887235200795217 Test RE 1.0566707368849342\n",
      "21 Train Loss 3.9389586 Test MSE 4.35287320618965 Test RE 0.9972316846533316\n",
      "22 Train Loss 3.5172668 Test MSE 4.1278970301819315 Test RE 0.9711190821689947\n",
      "23 Train Loss 3.039952 Test MSE 4.050436581761459 Test RE 0.9619643524226736\n",
      "24 Train Loss 2.6824694 Test MSE 3.961170726179744 Test RE 0.951305134355893\n",
      "25 Train Loss 2.473737 Test MSE 3.793371333998803 Test RE 0.9309379595160968\n",
      "26 Train Loss 2.2393458 Test MSE 3.6393964315161322 Test RE 0.9118486148794429\n",
      "27 Train Loss 1.9789749 Test MSE 3.450974517217351 Test RE 0.8879304231427804\n",
      "28 Train Loss 1.7393489 Test MSE 3.225841978066775 Test RE 0.8584788593820273\n",
      "29 Train Loss 1.5037576 Test MSE 2.9456843418002285 Test RE 0.8203537418747707\n",
      "30 Train Loss 1.3680183 Test MSE 2.8760528045012843 Test RE 0.8105997920791361\n",
      "31 Train Loss 1.2863517 Test MSE 2.8960399956920106 Test RE 0.8134115558303331\n",
      "32 Train Loss 1.1950557 Test MSE 2.8722113377836913 Test RE 0.8100582629739934\n",
      "33 Train Loss 1.1192313 Test MSE 2.9299760881486265 Test RE 0.8181634952913671\n",
      "34 Train Loss 1.0520029 Test MSE 2.9194262902204615 Test RE 0.8166892096644099\n",
      "35 Train Loss 0.9961463 Test MSE 2.9504615748630054 Test RE 0.8210186864021292\n",
      "36 Train Loss 0.94682974 Test MSE 2.9580478446455425 Test RE 0.8220735163922512\n",
      "37 Train Loss 0.9004691 Test MSE 2.9533078077733874 Test RE 0.8214145985421\n",
      "38 Train Loss 0.8554981 Test MSE 2.9429389826566745 Test RE 0.8199713705171306\n",
      "39 Train Loss 0.80552334 Test MSE 2.9405729730543486 Test RE 0.8196416915401036\n",
      "40 Train Loss 0.7668347 Test MSE 2.992059440429483 Test RE 0.8267861041097605\n",
      "41 Train Loss 0.7339173 Test MSE 3.012336324461258 Test RE 0.8295828965941252\n",
      "42 Train Loss 0.68741727 Test MSE 3.010678956189364 Test RE 0.8293546495801285\n",
      "43 Train Loss 0.65407103 Test MSE 3.0504254411582243 Test RE 0.8348112008732114\n",
      "44 Train Loss 0.63576674 Test MSE 3.035788042470996 Test RE 0.832805880862221\n",
      "45 Train Loss 0.61480796 Test MSE 3.045924528258303 Test RE 0.8341950901670716\n",
      "46 Train Loss 0.5935192 Test MSE 3.034724023684779 Test RE 0.8326599222596663\n",
      "47 Train Loss 0.57397455 Test MSE 3.049673980105839 Test RE 0.8347083682101282\n",
      "48 Train Loss 0.55528307 Test MSE 3.0647166642170696 Test RE 0.8367644582801057\n",
      "49 Train Loss 0.53975326 Test MSE 3.0793652730408705 Test RE 0.8387618408394303\n",
      "50 Train Loss 0.526389 Test MSE 3.0774631965563284 Test RE 0.8385027556919964\n",
      "51 Train Loss 0.5168619 Test MSE 3.0841790307192842 Test RE 0.8394171738711712\n",
      "52 Train Loss 0.5043936 Test MSE 3.1036346645678723 Test RE 0.8420606194187059\n",
      "53 Train Loss 0.4942625 Test MSE 3.139735179969925 Test RE 0.8469437546162648\n",
      "54 Train Loss 0.48325813 Test MSE 3.166267779929858 Test RE 0.8505148113296757\n",
      "55 Train Loss 0.476211 Test MSE 3.1615103087279586 Test RE 0.849875601211251\n",
      "56 Train Loss 0.47100595 Test MSE 3.1632817919930023 Test RE 0.8501136724838093\n",
      "57 Train Loss 0.4628532 Test MSE 3.1730265821395873 Test RE 0.8514220935542831\n",
      "58 Train Loss 0.45626616 Test MSE 3.1753443433259823 Test RE 0.8517330006318318\n",
      "59 Train Loss 0.45141384 Test MSE 3.185502060945746 Test RE 0.8530942317917352\n",
      "60 Train Loss 0.44871837 Test MSE 3.1939158092644107 Test RE 0.8542201119055487\n",
      "61 Train Loss 0.44482914 Test MSE 3.1994271758317354 Test RE 0.8549568080523301\n",
      "62 Train Loss 0.43988156 Test MSE 3.2126562352016212 Test RE 0.8567225314724436\n",
      "63 Train Loss 0.4353858 Test MSE 3.2364417965061243 Test RE 0.8598881437102585\n",
      "64 Train Loss 0.43215376 Test MSE 3.2385672039178006 Test RE 0.8601704464355712\n",
      "65 Train Loss 0.42808127 Test MSE 3.2518241920107696 Test RE 0.8619291907704242\n",
      "66 Train Loss 0.42414308 Test MSE 3.26535734554836 Test RE 0.8637208788171961\n",
      "67 Train Loss 0.41922566 Test MSE 3.285666616533538 Test RE 0.8664027216612187\n",
      "68 Train Loss 0.41401976 Test MSE 3.2981496902941703 Test RE 0.868047002294808\n",
      "69 Train Loss 0.41126484 Test MSE 3.3040193550323482 Test RE 0.8688190836792979\n",
      "70 Train Loss 0.4071781 Test MSE 3.3082204266777606 Test RE 0.8693712613944905\n",
      "71 Train Loss 0.4035644 Test MSE 3.3105041041116454 Test RE 0.8696712748106871\n",
      "72 Train Loss 0.39946812 Test MSE 3.3268141011799237 Test RE 0.871810965287334\n",
      "73 Train Loss 0.39350712 Test MSE 3.3316157124281514 Test RE 0.8724398835021818\n",
      "74 Train Loss 0.39021742 Test MSE 3.341609345524666 Test RE 0.8737474045813944\n",
      "75 Train Loss 0.3870719 Test MSE 3.3453570680237132 Test RE 0.87423723520651\n",
      "76 Train Loss 0.38442683 Test MSE 3.3547725196090155 Test RE 0.8754666338312143\n",
      "77 Train Loss 0.38234478 Test MSE 3.364778573181801 Test RE 0.8767712593715951\n",
      "78 Train Loss 0.37937957 Test MSE 3.3706128744501678 Test RE 0.8775310615490596\n",
      "79 Train Loss 0.37651703 Test MSE 3.383133064566604 Test RE 0.8791593517635128\n",
      "80 Train Loss 0.37431398 Test MSE 3.3872243695566535 Test RE 0.8796907855223944\n",
      "81 Train Loss 0.37165287 Test MSE 3.3948140653070995 Test RE 0.8806757881152402\n",
      "82 Train Loss 0.36919427 Test MSE 3.400779661233404 Test RE 0.881449239879496\n",
      "83 Train Loss 0.36756784 Test MSE 3.3982564427598705 Test RE 0.8811221822746823\n",
      "84 Train Loss 0.36577886 Test MSE 3.404914244170857 Test RE 0.8819848990992927\n",
      "85 Train Loss 0.36410552 Test MSE 3.403866081407761 Test RE 0.8818491343164196\n",
      "86 Train Loss 0.36208656 Test MSE 3.410196563903575 Test RE 0.8826687813295341\n",
      "87 Train Loss 0.3595584 Test MSE 3.4218985800713386 Test RE 0.8841819138408096\n",
      "88 Train Loss 0.35788357 Test MSE 3.432450688454191 Test RE 0.8855441403239096\n",
      "89 Train Loss 0.35629025 Test MSE 3.4427915848047217 Test RE 0.8868770703987323\n",
      "90 Train Loss 0.35331625 Test MSE 3.4439416959378204 Test RE 0.8870251946744337\n",
      "91 Train Loss 0.3506267 Test MSE 3.455709507054461 Test RE 0.8885393671281767\n",
      "92 Train Loss 0.34809977 Test MSE 3.4735358536221894 Test RE 0.8908281932293385\n",
      "93 Train Loss 0.34648442 Test MSE 3.4962108299241206 Test RE 0.8937310926047327\n",
      "94 Train Loss 0.34489015 Test MSE 3.5066607342328706 Test RE 0.8950657426830151\n",
      "95 Train Loss 0.34376785 Test MSE 3.5018948089207247 Test RE 0.8944572910515345\n",
      "96 Train Loss 0.3426575 Test MSE 3.502183614701899 Test RE 0.8944941738142811\n",
      "97 Train Loss 0.34124404 Test MSE 3.5078205224252845 Test RE 0.8952137468583284\n",
      "98 Train Loss 0.33968866 Test MSE 3.5160024421183573 Test RE 0.8962571726566697\n",
      "99 Train Loss 0.33812827 Test MSE 3.51564670116068 Test RE 0.8962118309006073\n",
      "Training time: 150.74\n",
      "7\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 49.431095 Test MSE 7.551135170217527 Test RE 1.3134519285367396\n",
      "1 Train Loss 35.498848 Test MSE 7.8318587184990225 Test RE 1.3376438049064063\n",
      "2 Train Loss 22.148878 Test MSE 6.191172675057729 Test RE 1.189308488826322\n",
      "3 Train Loss 16.066683 Test MSE 6.038175264414709 Test RE 1.1745213554585479\n",
      "4 Train Loss 13.240517 Test MSE 6.07652351074899 Test RE 1.1782451250812875\n",
      "5 Train Loss 11.553309 Test MSE 5.890291134465419 Test RE 1.160049284887854\n",
      "6 Train Loss 10.578258 Test MSE 5.778679203244722 Test RE 1.1490061498212805\n",
      "7 Train Loss 9.842002 Test MSE 5.558155078594623 Test RE 1.1268688924568964\n",
      "8 Train Loss 8.86248 Test MSE 5.485121968015136 Test RE 1.1194409889862882\n",
      "9 Train Loss 7.680398 Test MSE 5.427180755297567 Test RE 1.1135127736431316\n",
      "10 Train Loss 6.486425 Test MSE 5.078920545668813 Test RE 1.0771936129890598\n",
      "11 Train Loss 5.262028 Test MSE 5.142147031761588 Test RE 1.0838777609645769\n",
      "12 Train Loss 4.284702 Test MSE 4.568548086320151 Test RE 1.0216382876734413\n",
      "13 Train Loss 3.5886872 Test MSE 4.228949008138275 Test RE 0.982933834410771\n",
      "14 Train Loss 3.1331527 Test MSE 4.052468233681027 Test RE 0.9622055772477004\n",
      "15 Train Loss 2.7884555 Test MSE 3.6640639466367757 Test RE 0.9149336118795502\n",
      "16 Train Loss 2.4254944 Test MSE 3.096566065378069 Test RE 0.8411011666186087\n",
      "17 Train Loss 2.1784835 Test MSE 2.6566733894204866 Test RE 0.7790711875744484\n",
      "18 Train Loss 1.9513016 Test MSE 2.362163561845147 Test RE 0.7346204996977378\n",
      "19 Train Loss 1.7228364 Test MSE 2.106665130984658 Test RE 0.6937545009614221\n",
      "20 Train Loss 1.5215113 Test MSE 1.878497677978779 Test RE 0.6551087370444072\n",
      "21 Train Loss 1.1868542 Test MSE 1.462598898128754 Test RE 0.5780570220621023\n",
      "22 Train Loss 0.8689887 Test MSE 1.0765153206314688 Test RE 0.4959274731050013\n",
      "23 Train Loss 0.69053406 Test MSE 0.7877468593097895 Test RE 0.4242300229202513\n",
      "24 Train Loss 0.5430556 Test MSE 0.5339950968365286 Test RE 0.3492823939165646\n",
      "25 Train Loss 0.45983046 Test MSE 0.5096235403229682 Test RE 0.34121868155204654\n",
      "26 Train Loss 0.35392594 Test MSE 0.37657203207238577 Test RE 0.29331352635956975\n",
      "27 Train Loss 0.30362314 Test MSE 0.3321849399573991 Test RE 0.2754850464057411\n",
      "28 Train Loss 0.26505888 Test MSE 0.23475423800741993 Test RE 0.23158732211390956\n",
      "29 Train Loss 0.22043394 Test MSE 0.13805886399523343 Test RE 0.17759887402832186\n",
      "30 Train Loss 0.18751483 Test MSE 0.08893642852755985 Test RE 0.1425436590821082\n",
      "31 Train Loss 0.14620727 Test MSE 0.041596856572325924 Test RE 0.097485116861792\n",
      "32 Train Loss 0.11826328 Test MSE 0.034984658656742974 Test RE 0.08940192718347674\n",
      "33 Train Loss 0.0957043 Test MSE 0.02175547018475913 Test RE 0.07050051625007461\n",
      "34 Train Loss 0.08092453 Test MSE 0.018961452272892008 Test RE 0.0658178753597199\n",
      "35 Train Loss 0.07180141 Test MSE 0.014202955433137533 Test RE 0.05696359924957215\n",
      "36 Train Loss 0.059490085 Test MSE 0.013468478412179297 Test RE 0.055471170179388435\n",
      "37 Train Loss 0.04930039 Test MSE 0.01445868205495738 Test RE 0.05747413108223879\n",
      "38 Train Loss 0.042534035 Test MSE 0.011564076790026166 Test RE 0.05140005026825308\n",
      "39 Train Loss 0.038838763 Test MSE 0.010814813333943444 Test RE 0.04970700246392148\n",
      "40 Train Loss 0.032294713 Test MSE 0.00761716511620266 Test RE 0.0417162004099739\n",
      "41 Train Loss 0.029181063 Test MSE 0.0072188210877808644 Test RE 0.040610767703760584\n",
      "42 Train Loss 0.027578892 Test MSE 0.00785445622182834 Test RE 0.04236099202241317\n",
      "43 Train Loss 0.02604036 Test MSE 0.007414166944561199 Test RE 0.04115657637812307\n",
      "44 Train Loss 0.02418527 Test MSE 0.0056123919508569865 Test RE 0.03580816424129964\n",
      "45 Train Loss 0.022375971 Test MSE 0.003803288448678807 Test RE 0.029477299393237393\n",
      "46 Train Loss 0.021454193 Test MSE 0.0034653746016578136 Test RE 0.02813734750632716\n",
      "47 Train Loss 0.01956186 Test MSE 0.0034243011853596042 Test RE 0.02797010124195357\n",
      "48 Train Loss 0.018519677 Test MSE 0.0031534397531495263 Test RE 0.026841101191155986\n",
      "49 Train Loss 0.017476577 Test MSE 0.003447993252334258 Test RE 0.028066694269879983\n",
      "50 Train Loss 0.016836364 Test MSE 0.0034517456602296084 Test RE 0.02808196243299269\n",
      "51 Train Loss 0.016384456 Test MSE 0.003929003942958063 Test RE 0.02996051626235474\n",
      "52 Train Loss 0.0153081585 Test MSE 0.0037515902121890436 Test RE 0.029276270914269875\n",
      "53 Train Loss 0.014070236 Test MSE 0.003951576117643856 Test RE 0.030046454771971577\n",
      "54 Train Loss 0.012966227 Test MSE 0.002913577560203555 Test RE 0.02580009779093622\n",
      "55 Train Loss 0.012418957 Test MSE 0.002769400159759512 Test RE 0.025153644387716036\n",
      "56 Train Loss 0.012022473 Test MSE 0.0029897639631050765 Test RE 0.02613524115092277\n",
      "57 Train Loss 0.011502685 Test MSE 0.0027273072501844027 Test RE 0.024961753707481164\n",
      "58 Train Loss 0.010864757 Test MSE 0.0025588069404219142 Test RE 0.02417835892167209\n",
      "59 Train Loss 0.010395575 Test MSE 0.0020803946263504916 Test RE 0.021801226247961342\n",
      "60 Train Loss 0.0099161295 Test MSE 0.0023062577004951536 Test RE 0.02295419026151979\n",
      "61 Train Loss 0.009525658 Test MSE 0.002369748956125839 Test RE 0.023268009401070534\n",
      "62 Train Loss 0.008983639 Test MSE 0.0020444020024748717 Test RE 0.021611813400148523\n",
      "63 Train Loss 0.008591224 Test MSE 0.0020671968452957157 Test RE 0.021731964006021523\n",
      "64 Train Loss 0.008156277 Test MSE 0.0019895810045882584 Test RE 0.02132008212296869\n",
      "65 Train Loss 0.0078022312 Test MSE 0.00193630593244221 Test RE 0.021032701016496385\n",
      "66 Train Loss 0.0072849374 Test MSE 0.0018595219805383717 Test RE 0.02061145822448054\n",
      "67 Train Loss 0.006517831 Test MSE 0.001782877604096096 Test RE 0.020182214845659706\n",
      "68 Train Loss 0.0058763125 Test MSE 0.0018342684311382302 Test RE 0.020471021108506116\n",
      "69 Train Loss 0.0053165494 Test MSE 0.0019389202338614834 Test RE 0.021046894866743517\n",
      "70 Train Loss 0.0050415467 Test MSE 0.0017274435251204679 Test RE 0.019865979788062885\n",
      "71 Train Loss 0.004915174 Test MSE 0.001556867112177929 Test RE 0.018859658849070107\n",
      "72 Train Loss 0.0047119977 Test MSE 0.0016206130671599724 Test RE 0.01924189003815202\n",
      "73 Train Loss 0.0044816555 Test MSE 0.00147678484674762 Test RE 0.018368203150138786\n",
      "74 Train Loss 0.004351831 Test MSE 0.0014382511827020423 Test RE 0.018126978940370526\n",
      "75 Train Loss 0.0042460123 Test MSE 0.0014374487013606781 Test RE 0.018121921203515242\n",
      "76 Train Loss 0.0041387873 Test MSE 0.0012636125670653794 Test RE 0.01699084697506406\n",
      "77 Train Loss 0.0040084873 Test MSE 0.0012644615441725299 Test RE 0.01699655379470798\n",
      "78 Train Loss 0.0039215125 Test MSE 0.0012283502403162589 Test RE 0.01675209656803328\n",
      "79 Train Loss 0.0038500044 Test MSE 0.0011247966147565982 Test RE 0.016030425886696356\n",
      "80 Train Loss 0.0037599 Test MSE 0.0011779394800277134 Test RE 0.01640474746508893\n",
      "81 Train Loss 0.0036639152 Test MSE 0.0011564070768808252 Test RE 0.016254118837859707\n",
      "82 Train Loss 0.0035474873 Test MSE 0.001117480472960898 Test RE 0.01597820657839693\n",
      "83 Train Loss 0.0034473967 Test MSE 0.0010299214646021762 Test RE 0.015339461543325012\n",
      "84 Train Loss 0.0034111121 Test MSE 0.0010825138841617232 Test RE 0.015726236332130078\n",
      "85 Train Loss 0.0033479102 Test MSE 0.0010708393513229868 Test RE 0.015641205480138753\n",
      "86 Train Loss 0.0032112123 Test MSE 0.0011551096334805765 Test RE 0.016244998036821348\n",
      "87 Train Loss 0.0031247865 Test MSE 0.0011415365599166288 Test RE 0.016149272874021504\n",
      "88 Train Loss 0.0030834917 Test MSE 0.0011550928353999531 Test RE 0.0162448799156617\n",
      "89 Train Loss 0.003031548 Test MSE 0.0012436720034809297 Test RE 0.016856250988262093\n",
      "90 Train Loss 0.0029356154 Test MSE 0.001221878771092451 Test RE 0.01670790972313831\n",
      "91 Train Loss 0.0027149888 Test MSE 0.0009855050549269447 Test RE 0.015005051432943704\n",
      "92 Train Loss 0.0026102397 Test MSE 0.0009408895905040519 Test RE 0.01466146581692735\n",
      "93 Train Loss 0.002538489 Test MSE 0.0008909735802704007 Test RE 0.014267256639423642\n",
      "94 Train Loss 0.0024957499 Test MSE 0.0009374349625172709 Test RE 0.014634525095864867\n",
      "95 Train Loss 0.0024574846 Test MSE 0.0009537542426986588 Test RE 0.014761357613544704\n",
      "96 Train Loss 0.002381172 Test MSE 0.0010622828679239225 Test RE 0.015578590048564642\n",
      "97 Train Loss 0.0022201512 Test MSE 0.001201210302110382 Test RE 0.01656599722989892\n",
      "98 Train Loss 0.0021439642 Test MSE 0.0012496427496115623 Test RE 0.016896665136139282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0020964076 Test MSE 0.0013075133432925972 Test RE 0.01728347735940162\n",
      "Training time: 148.84\n",
      "8\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.44\n",
      "0\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 71.875854 Test MSE 4.5359090589285 Test RE 1.0179823065822569\n",
      "1 Train Loss 57.471992 Test MSE 4.849417395877731 Test RE 1.0525744971949271\n",
      "2 Train Loss 41.053894 Test MSE 6.510928157056747 Test RE 1.219633969488565\n",
      "3 Train Loss 30.806492 Test MSE 5.920073167903706 Test RE 1.162978262873584\n",
      "4 Train Loss 23.33447 Test MSE 5.276360907568579 Test RE 1.0979316566786905\n",
      "5 Train Loss 18.738003 Test MSE 4.868321668099983 Test RE 1.054624104280162\n",
      "6 Train Loss 16.1887 Test MSE 4.756147975914536 Test RE 1.0424032082736852\n",
      "7 Train Loss 14.178158 Test MSE 4.392099214078239 Test RE 1.0017148942575325\n",
      "8 Train Loss 11.950811 Test MSE 4.38360631356414 Test RE 1.0007459291706087\n",
      "9 Train Loss 10.359001 Test MSE 4.4340423704336285 Test RE 1.0064865593334822\n",
      "10 Train Loss 8.827293 Test MSE 4.302227908762478 Test RE 0.9914133596823226\n",
      "11 Train Loss 7.7308407 Test MSE 4.220263505295147 Test RE 0.9819239306956935\n",
      "12 Train Loss 7.007766 Test MSE 4.186655324806693 Test RE 0.9780063269724306\n",
      "13 Train Loss 6.2541404 Test MSE 4.178689689420388 Test RE 0.9770754943264028\n",
      "14 Train Loss 5.738286 Test MSE 4.132185155237944 Test RE 0.971623358210701\n",
      "15 Train Loss 5.1496353 Test MSE 4.109658413011826 Test RE 0.9689713206309176\n",
      "16 Train Loss 4.4448524 Test MSE 4.258111561286687 Test RE 0.98631713508978\n",
      "17 Train Loss 3.9981384 Test MSE 4.317897850269378 Test RE 0.9932172237857558\n",
      "18 Train Loss 3.7016594 Test MSE 4.300476807988186 Test RE 0.9912115756963703\n",
      "19 Train Loss 3.415896 Test MSE 4.255461341757706 Test RE 0.9860101487943992\n",
      "20 Train Loss 3.14466 Test MSE 4.237691729101676 Test RE 0.9839493443347754\n",
      "21 Train Loss 2.8515484 Test MSE 4.232122953768689 Test RE 0.9833026250242075\n",
      "22 Train Loss 2.6592982 Test MSE 4.181239584149533 Test RE 0.9773735614091751\n",
      "23 Train Loss 2.5039608 Test MSE 4.096345366996719 Test RE 0.9674005788999397\n",
      "24 Train Loss 2.3625083 Test MSE 4.040261602821187 Test RE 0.9607553319163271\n",
      "25 Train Loss 2.21258 Test MSE 4.00470910357101 Test RE 0.9565188825019486\n",
      "26 Train Loss 2.0873773 Test MSE 3.944543032762362 Test RE 0.9493064014244842\n",
      "27 Train Loss 1.9603283 Test MSE 3.790851920677475 Test RE 0.9306287613314612\n",
      "28 Train Loss 1.8244729 Test MSE 3.7569422418711818 Test RE 0.9264571118478544\n",
      "29 Train Loss 1.687777 Test MSE 3.568489378643488 Test RE 0.9029220615807814\n",
      "30 Train Loss 1.589804 Test MSE 3.415836795367304 Test RE 0.8833984166061871\n",
      "31 Train Loss 1.4576325 Test MSE 3.2892848091941125 Test RE 0.866879633927668\n",
      "32 Train Loss 1.3666196 Test MSE 3.315232206729342 Test RE 0.8702920908230594\n",
      "33 Train Loss 1.2916023 Test MSE 3.1376791890615543 Test RE 0.8466664073691305\n",
      "34 Train Loss 1.2099682 Test MSE 3.1324253512208884 Test RE 0.8459572667309816\n",
      "35 Train Loss 1.1069398 Test MSE 3.112937861482068 Test RE 0.84332172049144\n",
      "36 Train Loss 1.0121827 Test MSE 3.105614876204282 Test RE 0.8423292064996761\n",
      "37 Train Loss 0.94682425 Test MSE 3.0524286927317648 Test RE 0.8350852712304662\n",
      "38 Train Loss 0.89944744 Test MSE 3.074820729203477 Test RE 0.8381426876990152\n",
      "39 Train Loss 0.8563687 Test MSE 3.0409549148042383 Test RE 0.8335142920305298\n",
      "40 Train Loss 0.8239833 Test MSE 3.0765697052886862 Test RE 0.8383810240530986\n",
      "41 Train Loss 0.7840335 Test MSE 3.0722716352821617 Test RE 0.8377951963158543\n",
      "42 Train Loss 0.7527746 Test MSE 3.066851252565948 Test RE 0.837055812580102\n",
      "43 Train Loss 0.71288216 Test MSE 3.057707368078032 Test RE 0.8358070309064797\n",
      "44 Train Loss 0.6788206 Test MSE 3.0547092601064056 Test RE 0.8353971724780934\n",
      "45 Train Loss 0.6395848 Test MSE 3.0761005520000864 Test RE 0.8383170982772705\n",
      "46 Train Loss 0.6105417 Test MSE 3.104576643222636 Test RE 0.8421883958870153\n",
      "47 Train Loss 0.5875589 Test MSE 3.1135581088881925 Test RE 0.8434057314933346\n",
      "48 Train Loss 0.57185423 Test MSE 3.133725630599285 Test RE 0.846132828242901\n",
      "49 Train Loss 0.55688745 Test MSE 3.121524243408911 Test RE 0.8444839820473429\n",
      "50 Train Loss 0.5389812 Test MSE 3.148842755145492 Test RE 0.8481712495751162\n",
      "51 Train Loss 0.52669734 Test MSE 3.147261554763066 Test RE 0.8479582670266562\n",
      "52 Train Loss 0.5157785 Test MSE 3.15480181883926 Test RE 0.848973435946774\n",
      "53 Train Loss 0.50201803 Test MSE 3.160307854178278 Test RE 0.8497139642287113\n",
      "54 Train Loss 0.4859662 Test MSE 3.1700244789989815 Test RE 0.8510192192396364\n",
      "55 Train Loss 0.47665703 Test MSE 3.16435403881958 Test RE 0.8502577403405284\n",
      "56 Train Loss 0.4687373 Test MSE 3.1429252453124157 Test RE 0.8473739055419356\n",
      "57 Train Loss 0.45770028 Test MSE 3.175767020346628 Test RE 0.851789686765461\n",
      "58 Train Loss 0.45232973 Test MSE 3.1619374261398616 Test RE 0.8499330080156697\n",
      "59 Train Loss 0.44345108 Test MSE 3.1663069250504567 Test RE 0.8505200688448751\n",
      "60 Train Loss 0.4337688 Test MSE 3.1793015807365075 Test RE 0.8522635667481944\n",
      "61 Train Loss 0.4270821 Test MSE 3.1832611790964878 Test RE 0.8527941190212934\n",
      "62 Train Loss 0.4224043 Test MSE 3.2003679412204957 Test RE 0.8550824953414792\n",
      "63 Train Loss 0.41555303 Test MSE 3.1746483884134467 Test RE 0.8516396563854546\n",
      "64 Train Loss 0.40870714 Test MSE 3.19646152325053 Test RE 0.8545604726213151\n",
      "65 Train Loss 0.40397573 Test MSE 3.2083621412685526 Test RE 0.8561497846734142\n",
      "66 Train Loss 0.40169445 Test MSE 3.2163713658058146 Test RE 0.8572177473052416\n",
      "67 Train Loss 0.39658082 Test MSE 3.223927309703689 Test RE 0.8582240505139764\n",
      "68 Train Loss 0.39296463 Test MSE 3.221397701303669 Test RE 0.8578872878358638\n",
      "69 Train Loss 0.3892239 Test MSE 3.231768840291838 Test RE 0.8592671421013519\n",
      "70 Train Loss 0.38525176 Test MSE 3.243149102118115 Test RE 0.8607787123998978\n",
      "71 Train Loss 0.38034832 Test MSE 3.2250272127665087 Test RE 0.8583704376176743\n",
      "72 Train Loss 0.375616 Test MSE 3.2239405904866345 Test RE 0.8582258182144392\n",
      "73 Train Loss 0.37216288 Test MSE 3.224356032545505 Test RE 0.858281112598044\n",
      "74 Train Loss 0.36760288 Test MSE 3.2356226564416564 Test RE 0.8597793184249358\n",
      "75 Train Loss 0.36380094 Test MSE 3.2529603458092127 Test RE 0.8620797522004497\n",
      "76 Train Loss 0.36161956 Test MSE 3.258863342698418 Test RE 0.862861585825816\n",
      "77 Train Loss 0.35873237 Test MSE 3.2819105452316197 Test RE 0.8659073578042514\n",
      "78 Train Loss 0.3550297 Test MSE 3.3051034118350873 Test RE 0.8689616028194314\n",
      "79 Train Loss 0.35200676 Test MSE 3.2896048128915547 Test RE 0.8669218008359122\n",
      "80 Train Loss 0.34997335 Test MSE 3.2974463013336175 Test RE 0.8679544341439599\n",
      "81 Train Loss 0.3468569 Test MSE 3.312970088972297 Test RE 0.8699951223128812\n",
      "82 Train Loss 0.34461528 Test MSE 3.3244622625957727 Test RE 0.8715027543234548\n",
      "83 Train Loss 0.34154254 Test MSE 3.3374880173758608 Test RE 0.8732084261435893\n",
      "84 Train Loss 0.33735573 Test MSE 3.321369932704573 Test RE 0.8710973352217815\n",
      "85 Train Loss 0.33506998 Test MSE 3.3445830700808066 Test RE 0.8741360954849294\n",
      "86 Train Loss 0.33329523 Test MSE 3.3346397399249734 Test RE 0.8728357400504642\n",
      "87 Train Loss 0.3308651 Test MSE 3.341827064086614 Test RE 0.8737758681015569\n",
      "88 Train Loss 0.329696 Test MSE 3.3406377249187726 Test RE 0.8736203680826633\n",
      "89 Train Loss 0.32807478 Test MSE 3.3395327075563497 Test RE 0.8734758679005722\n",
      "90 Train Loss 0.32627076 Test MSE 3.3521758146821243 Test RE 0.8751277481711113\n",
      "91 Train Loss 0.32311833 Test MSE 3.356265748941656 Test RE 0.8756614498751351\n",
      "92 Train Loss 0.32091048 Test MSE 3.3674904326709987 Test RE 0.8771245072191258\n",
      "93 Train Loss 0.31849802 Test MSE 3.3653122581298267 Test RE 0.8768407886231029\n",
      "94 Train Loss 0.3164113 Test MSE 3.377401719721252 Test RE 0.8784143468867219\n",
      "95 Train Loss 0.31356573 Test MSE 3.3614576915630634 Test RE 0.8763384861195811\n",
      "96 Train Loss 0.31080937 Test MSE 3.3541424976131107 Test RE 0.8753844242132861\n",
      "97 Train Loss 0.308907 Test MSE 3.3709062879960054 Test RE 0.8775692554779919\n",
      "98 Train Loss 0.3068631 Test MSE 3.3630699482915234 Test RE 0.8765486201411264\n",
      "99 Train Loss 0.30461 Test MSE 3.36252377578102 Test RE 0.8764774402062968\n",
      "Training time: 148.88\n",
      "1\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.909245 Test MSE 5.848241113563112 Test RE 1.1559011480306096\n",
      "1 Train Loss 48.193306 Test MSE 7.989937836243882 Test RE 1.3510759411209499\n",
      "2 Train Loss 39.611317 Test MSE 8.28007654159364 Test RE 1.3753880162148497\n",
      "3 Train Loss 30.411905 Test MSE 9.412343942044403 Test RE 1.466415203253208\n",
      "4 Train Loss 27.215252 Test MSE 9.353343608121138 Test RE 1.4618119398306038\n",
      "5 Train Loss 25.53301 Test MSE 9.490087189208076 Test RE 1.4724588326464945\n",
      "6 Train Loss 23.411854 Test MSE 9.58338718632482 Test RE 1.4796792298051407\n",
      "7 Train Loss 22.49118 Test MSE 9.504324058969916 Test RE 1.473562897758964\n",
      "8 Train Loss 21.54018 Test MSE 9.763189475840422 Test RE 1.4934955027662133\n",
      "9 Train Loss 20.68699 Test MSE 9.801429076142819 Test RE 1.4964174402619543\n",
      "10 Train Loss 19.68846 Test MSE 9.545391587758306 Test RE 1.4767430479875512\n",
      "11 Train Loss 19.055363 Test MSE 9.385894991858727 Test RE 1.4643534199139423\n",
      "12 Train Loss 18.21575 Test MSE 9.161822300710524 Test RE 1.446768326397805\n",
      "13 Train Loss 17.273075 Test MSE 9.04251052058592 Test RE 1.4373170310174106\n",
      "14 Train Loss 16.309301 Test MSE 8.800060012577084 Test RE 1.4179172211249043\n",
      "15 Train Loss 15.115458 Test MSE 8.976279261757863 Test RE 1.4320435911739815\n",
      "16 Train Loss 13.770479 Test MSE 9.010597287893615 Test RE 1.4347784674488768\n",
      "17 Train Loss 12.242918 Test MSE 8.611205527862452 Test RE 1.402620033885445\n",
      "18 Train Loss 10.508665 Test MSE 7.8308408499448365 Test RE 1.3375568785549556\n",
      "19 Train Loss 9.361974 Test MSE 7.364274494738577 Test RE 1.2970987602984405\n",
      "20 Train Loss 8.61221 Test MSE 6.925203698938954 Test RE 1.2578369155426268\n",
      "21 Train Loss 8.03017 Test MSE 6.959030581059211 Test RE 1.2609051912953986\n",
      "22 Train Loss 7.629656 Test MSE 6.811413349017556 Test RE 1.2474601423321825\n",
      "23 Train Loss 7.36213 Test MSE 6.624837680919469 Test RE 1.230256536571265\n",
      "24 Train Loss 7.0541677 Test MSE 6.812770392325199 Test RE 1.2475844023823393\n",
      "25 Train Loss 6.86642 Test MSE 6.79722631657743 Test RE 1.2461603399582135\n",
      "26 Train Loss 6.682351 Test MSE 6.78455796618561 Test RE 1.2449985308886278\n",
      "27 Train Loss 6.5418634 Test MSE 6.7559395428051054 Test RE 1.2423699478665582\n",
      "28 Train Loss 6.381523 Test MSE 6.77731752706425 Test RE 1.244334026111059\n",
      "29 Train Loss 6.2466254 Test MSE 6.840007096118056 Test RE 1.2500757671598046\n",
      "30 Train Loss 5.9717116 Test MSE 6.80806233879095 Test RE 1.2471532481718954\n",
      "31 Train Loss 5.7882495 Test MSE 6.712026339914561 Test RE 1.238325700138967\n",
      "32 Train Loss 5.5678077 Test MSE 6.793771351570982 Test RE 1.2458435940232513\n",
      "33 Train Loss 5.2888527 Test MSE 6.795817205175379 Test RE 1.2460311644917765\n",
      "34 Train Loss 5.0153036 Test MSE 6.810550925117349 Test RE 1.2473811665423902\n",
      "35 Train Loss 4.8548913 Test MSE 6.784008180632923 Test RE 1.2449480857397985\n",
      "36 Train Loss 4.649668 Test MSE 6.746855054938044 Test RE 1.241534380046875\n",
      "37 Train Loss 4.23037 Test MSE 6.657229098553616 Test RE 1.2332604714342146\n",
      "38 Train Loss 3.7733672 Test MSE 6.504026550806528 Test RE 1.2189873899968382\n",
      "39 Train Loss 3.0451422 Test MSE 6.2294449908298555 Test RE 1.192978832423345\n",
      "40 Train Loss 2.451611 Test MSE 6.186084970648937 Test RE 1.1888197208684044\n",
      "41 Train Loss 2.2798398 Test MSE 6.04044708267351 Test RE 1.1747422871149806\n",
      "42 Train Loss 2.1024394 Test MSE 6.14496349996291 Test RE 1.1848618437873446\n",
      "43 Train Loss 2.0027204 Test MSE 6.116015255903713 Test RE 1.182067672532327\n",
      "44 Train Loss 1.9310937 Test MSE 6.062411728756351 Test RE 1.1768761841875517\n",
      "45 Train Loss 1.893125 Test MSE 6.055915779030616 Test RE 1.1762454964451974\n",
      "46 Train Loss 1.8476272 Test MSE 6.077604342760848 Test RE 1.1783499077274049\n",
      "47 Train Loss 1.8046122 Test MSE 6.104095950255588 Test RE 1.1809152639296252\n",
      "48 Train Loss 1.7633033 Test MSE 6.1329214200291995 Test RE 1.1837003073420582\n",
      "49 Train Loss 1.7365365 Test MSE 6.112834031359804 Test RE 1.1817602083047993\n",
      "50 Train Loss 1.6820393 Test MSE 6.114801144389335 Test RE 1.181950338521229\n",
      "51 Train Loss 1.6521703 Test MSE 6.12451778103639 Test RE 1.1828890463362587\n",
      "52 Train Loss 1.633717 Test MSE 6.100754321891167 Test RE 1.1805919793518198\n",
      "53 Train Loss 1.597077 Test MSE 6.022399768202364 Test RE 1.1729860592529657\n",
      "54 Train Loss 1.5681728 Test MSE 5.94689400865821 Test RE 1.165609717323064\n",
      "55 Train Loss 1.5358685 Test MSE 5.953370602681747 Test RE 1.1662442608878754\n",
      "56 Train Loss 1.4991083 Test MSE 5.943685572826601 Test RE 1.1652952432017523\n",
      "57 Train Loss 1.4633088 Test MSE 5.909713042242971 Test RE 1.161960211535255\n",
      "58 Train Loss 1.4500268 Test MSE 5.895126454744188 Test RE 1.1605253275002152\n",
      "59 Train Loss 1.4320312 Test MSE 5.898362157273222 Test RE 1.1608437769544253\n",
      "60 Train Loss 1.4096241 Test MSE 5.822159658322618 Test RE 1.1533207763432787\n",
      "61 Train Loss 1.3928337 Test MSE 5.824314402526362 Test RE 1.1535341749372106\n",
      "62 Train Loss 1.3735373 Test MSE 5.839460293686699 Test RE 1.1550330603208843\n",
      "63 Train Loss 1.3575526 Test MSE 5.812239803158676 Test RE 1.1523378376131577\n",
      "64 Train Loss 1.3445077 Test MSE 5.8241887475632055 Test RE 1.1535217315776982\n",
      "65 Train Loss 1.328906 Test MSE 5.866352774933595 Test RE 1.1576896435775774\n",
      "66 Train Loss 1.3185551 Test MSE 5.898035737470573 Test RE 1.1608116555257066\n",
      "67 Train Loss 1.3084147 Test MSE 5.896092052283906 Test RE 1.1606203682534493\n",
      "68 Train Loss 1.293466 Test MSE 5.856942475606195 Test RE 1.1567607377575997\n",
      "69 Train Loss 1.2835011 Test MSE 5.87668393953031 Test RE 1.158708591940561\n",
      "70 Train Loss 1.2715622 Test MSE 5.888738555086878 Test RE 1.159896390297841\n",
      "71 Train Loss 1.2545705 Test MSE 5.907684285190004 Test RE 1.1617607486082193\n",
      "72 Train Loss 1.2433319 Test MSE 5.897500674828213 Test RE 1.1607590006193533\n",
      "73 Train Loss 1.2292527 Test MSE 5.896418767590524 Test RE 1.160652524059642\n",
      "74 Train Loss 1.210184 Test MSE 5.936827201926839 Test RE 1.1646227367490938\n",
      "75 Train Loss 1.1916132 Test MSE 5.934214246233984 Test RE 1.1643664178081532\n",
      "76 Train Loss 1.1816602 Test MSE 5.903410435663774 Test RE 1.1613404410296935\n",
      "77 Train Loss 1.1727359 Test MSE 5.935716762358624 Test RE 1.1645138146259222\n",
      "78 Train Loss 1.1635187 Test MSE 5.950661166680122 Test RE 1.165978846217683\n",
      "79 Train Loss 1.1512163 Test MSE 5.961684503710562 Test RE 1.1670583086963748\n",
      "80 Train Loss 1.1413071 Test MSE 5.946775283439421 Test RE 1.1655980820089638\n",
      "81 Train Loss 1.1289333 Test MSE 5.973375070291953 Test RE 1.1682020199085195\n",
      "82 Train Loss 1.1195787 Test MSE 5.9659420529623794 Test RE 1.1674749628669703\n",
      "83 Train Loss 1.0993485 Test MSE 5.963156483364398 Test RE 1.167202377042987\n",
      "84 Train Loss 1.0867262 Test MSE 5.998228050833234 Test RE 1.170629723276352\n",
      "85 Train Loss 1.0756216 Test MSE 6.0007392151315075 Test RE 1.1708747402993687\n",
      "86 Train Loss 1.0671196 Test MSE 6.018603903527419 Test RE 1.172616339678439\n",
      "87 Train Loss 1.0613177 Test MSE 6.025427431871266 Test RE 1.1732808720494823\n",
      "88 Train Loss 1.0499353 Test MSE 6.000392845834848 Test RE 1.1708409477199733\n",
      "89 Train Loss 1.0449785 Test MSE 5.9996324370204395 Test RE 1.1707667570787692\n",
      "90 Train Loss 1.0380574 Test MSE 6.0097125727666745 Test RE 1.171749861887845\n",
      "91 Train Loss 1.0329438 Test MSE 6.007910075683092 Test RE 1.171574126852601\n",
      "92 Train Loss 1.0235474 Test MSE 6.009448122878897 Test RE 1.1717240809104141\n",
      "93 Train Loss 1.0219083 Test MSE 6.008821914182726 Test RE 1.1716630301358895\n",
      "94 Train Loss 1.0181519 Test MSE 6.01426579835346 Test RE 1.172193662753231\n",
      "95 Train Loss 1.0123148 Test MSE 6.029601260854001 Test RE 1.1736871690303805\n",
      "96 Train Loss 1.0054885 Test MSE 6.042242920753755 Test RE 1.1749169008585865\n",
      "97 Train Loss 1.0003371 Test MSE 6.0444521119686785 Test RE 1.1751316703504724\n",
      "98 Train Loss 0.9916386 Test MSE 6.021696456425457 Test RE 1.172917565045634\n",
      "99 Train Loss 0.98544824 Test MSE 5.999237920318773 Test RE 1.1707282635012395\n",
      "Training time: 150.40\n",
      "2\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.73604 Test MSE 4.944534699282904 Test RE 1.0628470580964307\n",
      "1 Train Loss 54.168713 Test MSE 7.923957178514274 Test RE 1.345485804888597\n",
      "2 Train Loss 43.700993 Test MSE 7.936601681417278 Test RE 1.346558893570842\n",
      "3 Train Loss 31.48824 Test MSE 6.446159242809508 Test RE 1.2135525166711287\n",
      "4 Train Loss 23.976788 Test MSE 6.0784739836715636 Test RE 1.1784342094172087\n",
      "5 Train Loss 17.695427 Test MSE 5.492439017871116 Test RE 1.1201873967903\n",
      "6 Train Loss 13.982212 Test MSE 5.9398514818746815 Test RE 1.1649193342943707\n",
      "7 Train Loss 12.205727 Test MSE 6.011797593683033 Test RE 1.1719531088046098\n",
      "8 Train Loss 10.813103 Test MSE 5.9244273616921745 Test RE 1.1634058675516876\n",
      "9 Train Loss 10.079728 Test MSE 5.81306869212901 Test RE 1.152420002673823\n",
      "10 Train Loss 9.343271 Test MSE 5.669184421572662 Test RE 1.1380683687265405\n",
      "11 Train Loss 9.009804 Test MSE 5.623078242637111 Test RE 1.1334310962689826\n",
      "12 Train Loss 8.493479 Test MSE 5.511031657801564 Test RE 1.1220817869580288\n",
      "13 Train Loss 7.799015 Test MSE 5.4299726122901415 Test RE 1.1137991441237045\n",
      "14 Train Loss 7.3859158 Test MSE 5.273717463670689 Test RE 1.097656591686551\n",
      "15 Train Loss 6.7993307 Test MSE 5.15677734496087 Test RE 1.0854185772528084\n",
      "16 Train Loss 6.3156376 Test MSE 4.9357670841265655 Test RE 1.0619043234263865\n",
      "17 Train Loss 5.9365067 Test MSE 4.883650718563195 Test RE 1.0562831647632824\n",
      "18 Train Loss 5.720375 Test MSE 4.750044430599895 Test RE 1.0417341376563531\n",
      "19 Train Loss 5.4321756 Test MSE 4.676834843420173 Test RE 1.0336751531297943\n",
      "20 Train Loss 5.178068 Test MSE 4.55249119159294 Test RE 1.0198413515977542\n",
      "21 Train Loss 4.911361 Test MSE 4.4649681285181835 Test RE 1.0099903908344885\n",
      "22 Train Loss 4.7240624 Test MSE 4.34325592208518 Test RE 0.9961294283663248\n",
      "23 Train Loss 4.582311 Test MSE 4.136408440404563 Test RE 0.9721197535100876\n",
      "24 Train Loss 4.334669 Test MSE 3.840490720787032 Test RE 0.9367019413937054\n",
      "25 Train Loss 4.160878 Test MSE 3.4895238275562543 Test RE 0.8928759893757806\n",
      "26 Train Loss 3.6611962 Test MSE 2.8167800588190492 Test RE 0.8022034567209685\n",
      "27 Train Loss 2.999327 Test MSE 2.479285190792979 Test RE 0.7526122855763798\n",
      "28 Train Loss 2.6026115 Test MSE 2.4354146207291976 Test RE 0.745923886661509\n",
      "29 Train Loss 2.3609092 Test MSE 2.4414867576130543 Test RE 0.7468532011610342\n",
      "30 Train Loss 2.0915534 Test MSE 2.244546546246402 Test RE 0.716097847481381\n",
      "31 Train Loss 1.902549 Test MSE 2.014301142257551 Test RE 0.6783756641652554\n",
      "32 Train Loss 1.7590873 Test MSE 1.935621887043183 Test RE 0.664994911933227\n",
      "33 Train Loss 1.6534337 Test MSE 1.83005074775214 Test RE 0.6466058459999702\n",
      "34 Train Loss 1.5404658 Test MSE 1.6645221923350453 Test RE 0.6166700482186479\n",
      "35 Train Loss 1.449277 Test MSE 1.5905052063160214 Test RE 0.6028032814642613\n",
      "36 Train Loss 1.3238314 Test MSE 1.2023453114040705 Test RE 0.5241102670199391\n",
      "37 Train Loss 1.234413 Test MSE 1.0823468964431389 Test RE 0.49726889972862154\n",
      "38 Train Loss 1.0330034 Test MSE 0.7295680643688247 Test RE 0.40826388869527064\n",
      "39 Train Loss 0.8768489 Test MSE 0.6160582765388521 Test RE 0.37516210031333697\n",
      "40 Train Loss 0.698156 Test MSE 0.42385908083187934 Test RE 0.31118510868420524\n",
      "41 Train Loss 0.51019734 Test MSE 0.27445527408027853 Test RE 0.2504054925318063\n",
      "42 Train Loss 0.41182852 Test MSE 0.2130147536733887 Test RE 0.220603755974013\n",
      "43 Train Loss 0.34844565 Test MSE 0.17009711232879599 Test RE 0.1971317288476459\n",
      "44 Train Loss 0.2829978 Test MSE 0.16601252759807192 Test RE 0.19475045958910564\n",
      "45 Train Loss 0.24766986 Test MSE 0.14188469351424526 Test RE 0.1800428311238908\n",
      "46 Train Loss 0.21489267 Test MSE 0.12525524121205914 Test RE 0.1691632475817384\n",
      "47 Train Loss 0.18889786 Test MSE 0.0882975683532219 Test RE 0.14203076691367328\n",
      "48 Train Loss 0.16388379 Test MSE 0.07148968583938305 Test RE 0.12779967652117294\n",
      "49 Train Loss 0.14389761 Test MSE 0.06686093619210416 Test RE 0.12359311749077337\n",
      "50 Train Loss 0.12995991 Test MSE 0.06202946299153786 Test RE 0.11904387933006635\n",
      "51 Train Loss 0.11355913 Test MSE 0.06583880993359009 Test RE 0.12264477374850974\n",
      "52 Train Loss 0.105830505 Test MSE 0.0630661096484366 Test RE 0.120034498144766\n",
      "53 Train Loss 0.09618313 Test MSE 0.05239751260444201 Test RE 0.10941160670619778\n",
      "54 Train Loss 0.089208566 Test MSE 0.04620743994225763 Test RE 0.1027457848907699\n",
      "55 Train Loss 0.07980654 Test MSE 0.04492567994986414 Test RE 0.10131071717403023\n",
      "56 Train Loss 0.0682609 Test MSE 0.038884000451796984 Test RE 0.09425264140438262\n",
      "57 Train Loss 0.06197603 Test MSE 0.03493866288702215 Test RE 0.08934313765840081\n",
      "58 Train Loss 0.05718741 Test MSE 0.030992171547367157 Test RE 0.08414611391248848\n",
      "59 Train Loss 0.052181188 Test MSE 0.025483782810712133 Test RE 0.07630271790693591\n",
      "60 Train Loss 0.044276256 Test MSE 0.020459187666780388 Test RE 0.06836790205488735\n",
      "61 Train Loss 0.03999541 Test MSE 0.014861046491896901 Test RE 0.05826835489289644\n",
      "62 Train Loss 0.036232617 Test MSE 0.012176634089853916 Test RE 0.05274383305180278\n",
      "63 Train Loss 0.033290148 Test MSE 0.010996631837261569 Test RE 0.050123097650968715\n",
      "64 Train Loss 0.030373827 Test MSE 0.009550012341005911 Test RE 0.046710017143273455\n",
      "65 Train Loss 0.02772332 Test MSE 0.009898781007761483 Test RE 0.047555299204537216\n",
      "66 Train Loss 0.026130533 Test MSE 0.008491451462758186 Test RE 0.044045244590434914\n",
      "67 Train Loss 0.023828764 Test MSE 0.009660725961243483 Test RE 0.04697999235449672\n",
      "68 Train Loss 0.022679575 Test MSE 0.008316796495672586 Test RE 0.04358992258255863\n",
      "69 Train Loss 0.02065924 Test MSE 0.00752744060615926 Test RE 0.041469779771920234\n",
      "70 Train Loss 0.018983118 Test MSE 0.00717535976656333 Test RE 0.04048833343140307\n",
      "71 Train Loss 0.017252997 Test MSE 0.005569569347655452 Test RE 0.035671294347304656\n",
      "72 Train Loss 0.015836189 Test MSE 0.005883971641981262 Test RE 0.03666429560679064\n",
      "73 Train Loss 0.013764346 Test MSE 0.004083034171405404 Test RE 0.030542147315803826\n",
      "74 Train Loss 0.013297224 Test MSE 0.003903552164365579 Test RE 0.029863317661148695\n",
      "75 Train Loss 0.012699159 Test MSE 0.0034474940642953947 Test RE 0.028064662498907586\n",
      "76 Train Loss 0.012104199 Test MSE 0.003222734734308992 Test RE 0.027134407334127683\n",
      "77 Train Loss 0.011644701 Test MSE 0.002851067898429292 Test RE 0.025521831695618398\n",
      "78 Train Loss 0.01107586 Test MSE 0.0030913985907803335 Test RE 0.02657575201328267\n",
      "79 Train Loss 0.0106469765 Test MSE 0.003007185619358522 Test RE 0.02621127688833781\n",
      "80 Train Loss 0.009849232 Test MSE 0.0030741478723254664 Test RE 0.02650149886243421\n",
      "81 Train Loss 0.009456743 Test MSE 0.002868713386387542 Test RE 0.025600688203471188\n",
      "82 Train Loss 0.008967605 Test MSE 0.0029259632376057378 Test RE 0.02585487800466486\n",
      "83 Train Loss 0.008565072 Test MSE 0.0026475183346212866 Test RE 0.02459390824661595\n",
      "84 Train Loss 0.008383116 Test MSE 0.002629354609500616 Test RE 0.024509397817314697\n",
      "85 Train Loss 0.0082023535 Test MSE 0.0024998674587725597 Test RE 0.023898274869648472\n",
      "86 Train Loss 0.007791701 Test MSE 0.0025385665176643024 Test RE 0.02408254242868639\n",
      "87 Train Loss 0.0075581335 Test MSE 0.002730396163555643 Test RE 0.024975885389050555\n",
      "88 Train Loss 0.007484557 Test MSE 0.0027752918503793573 Test RE 0.025180386415975756\n",
      "89 Train Loss 0.0074362336 Test MSE 0.002747488237490573 Test RE 0.02505393700917002\n",
      "90 Train Loss 0.0072671673 Test MSE 0.0026658192470724366 Test RE 0.024678764283596524\n",
      "91 Train Loss 0.0068681575 Test MSE 0.002576965523559209 Test RE 0.02426399816326985\n",
      "92 Train Loss 0.00654764 Test MSE 0.0026308791858497597 Test RE 0.024516502418789932\n",
      "93 Train Loss 0.006369729 Test MSE 0.0027020677154887293 Test RE 0.02484598247366325\n",
      "94 Train Loss 0.0062451856 Test MSE 0.0026317041647867497 Test RE 0.024520346003265244\n",
      "95 Train Loss 0.00608771 Test MSE 0.002520167992955223 Test RE 0.023995113363042237\n",
      "96 Train Loss 0.00592197 Test MSE 0.002607985915992257 Test RE 0.024409601037001454\n",
      "97 Train Loss 0.0057718856 Test MSE 0.002440735288585759 Test RE 0.02361393701014621\n",
      "98 Train Loss 0.005633547 Test MSE 0.0023943438625977703 Test RE 0.02338844353048382\n",
      "99 Train Loss 0.0053232787 Test MSE 0.0023131055614639623 Test RE 0.022988243393222113\n",
      "Training time: 148.91\n",
      "3\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.369522 Test MSE 5.995044070456835 Test RE 1.1703189851055842\n",
      "1 Train Loss 46.42151 Test MSE 8.857197497613994 Test RE 1.4225129365239368\n",
      "2 Train Loss 38.881992 Test MSE 8.884167641854686 Test RE 1.424677064503066\n",
      "3 Train Loss 34.546654 Test MSE 8.761487259598013 Test RE 1.4148062744144103\n",
      "4 Train Loss 31.241144 Test MSE 8.828437990065087 Test RE 1.4202015939628072\n",
      "5 Train Loss 28.082775 Test MSE 8.898703004375525 Test RE 1.4258420433287482\n",
      "6 Train Loss 24.424324 Test MSE 9.227374215059504 Test RE 1.4519348421099236\n",
      "7 Train Loss 22.622688 Test MSE 9.144462824489237 Test RE 1.4453970354239656\n",
      "8 Train Loss 20.756533 Test MSE 9.39790985338981 Test RE 1.4652903778001443\n",
      "9 Train Loss 19.660063 Test MSE 9.148618183738334 Test RE 1.4457254014468328\n",
      "10 Train Loss 18.441887 Test MSE 9.209221036875121 Test RE 1.4505059303026866\n",
      "11 Train Loss 16.972462 Test MSE 9.007980225287634 Test RE 1.4345700918195543\n",
      "12 Train Loss 15.799463 Test MSE 8.818460423918753 Test RE 1.4193988380694087\n",
      "13 Train Loss 14.494566 Test MSE 8.614385964399824 Test RE 1.4028790296885034\n",
      "14 Train Loss 12.722776 Test MSE 8.411788204340892 Test RE 1.3862840451170055\n",
      "15 Train Loss 10.076471 Test MSE 7.4014645283472875 Test RE 1.3003698494713116\n",
      "16 Train Loss 9.039345 Test MSE 7.336047066912302 Test RE 1.2946104694009752\n",
      "17 Train Loss 7.9306555 Test MSE 6.928580728061534 Test RE 1.2581435660296867\n",
      "18 Train Loss 7.4249554 Test MSE 6.729643196013956 Test RE 1.23994973353458\n",
      "19 Train Loss 6.9501324 Test MSE 6.7329964117308885 Test RE 1.2402586132929765\n",
      "20 Train Loss 6.5445843 Test MSE 6.710291611712489 Test RE 1.2381656666987793\n",
      "21 Train Loss 6.241744 Test MSE 6.591152398209957 Test RE 1.2271248105579444\n",
      "22 Train Loss 6.0089684 Test MSE 6.475920536072547 Test RE 1.2163507178857313\n",
      "23 Train Loss 5.786944 Test MSE 6.552642534625157 Test RE 1.2235347223329958\n",
      "24 Train Loss 5.588519 Test MSE 6.488384625238164 Test RE 1.217520699500501\n",
      "25 Train Loss 5.374271 Test MSE 6.436212979632934 Test RE 1.212615914587772\n",
      "26 Train Loss 5.2231197 Test MSE 6.446194352421019 Test RE 1.213555821530487\n",
      "27 Train Loss 5.024897 Test MSE 6.402433912473515 Test RE 1.2094296527426498\n",
      "28 Train Loss 4.8277884 Test MSE 6.318099913353217 Test RE 1.2014378367656515\n",
      "29 Train Loss 4.5923605 Test MSE 6.375541466482239 Test RE 1.2068869676051963\n",
      "30 Train Loss 4.323319 Test MSE 6.28039721825664 Test RE 1.1978477365334033\n",
      "31 Train Loss 3.6639185 Test MSE 5.96882777489933 Test RE 1.1677572821371767\n",
      "32 Train Loss 2.8779376 Test MSE 5.531934054462318 Test RE 1.1242077048160986\n",
      "33 Train Loss 2.3802438 Test MSE 5.550417753044061 Test RE 1.1260842806742177\n",
      "34 Train Loss 2.027246 Test MSE 5.437980901383822 Test RE 1.1146201739763493\n",
      "35 Train Loss 1.8547908 Test MSE 5.4837430537851795 Test RE 1.119300271045703\n",
      "36 Train Loss 1.7121253 Test MSE 5.498453673743216 Test RE 1.120800575940384\n",
      "37 Train Loss 1.6255618 Test MSE 5.490847656845787 Test RE 1.1200251053474626\n",
      "38 Train Loss 1.5407953 Test MSE 5.427421870758747 Test RE 1.1135375086000177\n",
      "39 Train Loss 1.4927264 Test MSE 5.452194392265323 Test RE 1.116075889371342\n",
      "40 Train Loss 1.440775 Test MSE 5.500464742826843 Test RE 1.1210055245911148\n",
      "41 Train Loss 1.4022447 Test MSE 5.511762760385124 Test RE 1.1221562131035019\n",
      "42 Train Loss 1.3759764 Test MSE 5.513249862720496 Test RE 1.1223075846930253\n",
      "43 Train Loss 1.3540212 Test MSE 5.547434167033853 Test RE 1.1257815808521667\n",
      "44 Train Loss 1.3288121 Test MSE 5.558485590554068 Test RE 1.1269023962098332\n",
      "45 Train Loss 1.3069116 Test MSE 5.567530975276593 Test RE 1.1278189338188487\n",
      "46 Train Loss 1.288286 Test MSE 5.564023336971934 Test RE 1.1274636053805736\n",
      "47 Train Loss 1.2731545 Test MSE 5.569154393914591 Test RE 1.1279833504010672\n",
      "48 Train Loss 1.2508152 Test MSE 5.612577440887003 Test RE 1.1323722903553177\n",
      "49 Train Loss 1.232266 Test MSE 5.639710921281575 Test RE 1.1351061641082147\n",
      "50 Train Loss 1.2113497 Test MSE 5.666817172578091 Test RE 1.1378307355593105\n",
      "51 Train Loss 1.1984957 Test MSE 5.623275517506763 Test RE 1.1334509782180722\n",
      "52 Train Loss 1.1802373 Test MSE 5.622860195941377 Test RE 1.1334091204675967\n",
      "53 Train Loss 1.1655686 Test MSE 5.636609912688985 Test RE 1.1347940507732277\n",
      "54 Train Loss 1.1542841 Test MSE 5.644344640617319 Test RE 1.1355723833445714\n",
      "55 Train Loss 1.1458668 Test MSE 5.633356399542119 Test RE 1.1344664957046984\n",
      "56 Train Loss 1.137929 Test MSE 5.627341018389827 Test RE 1.1338606338859498\n",
      "57 Train Loss 1.1298757 Test MSE 5.636630814519904 Test RE 1.1347961548084327\n",
      "58 Train Loss 1.1227809 Test MSE 5.646909347886737 Test RE 1.1358303477468106\n",
      "59 Train Loss 1.1115143 Test MSE 5.653771278768045 Test RE 1.136520249297321\n",
      "60 Train Loss 1.0963511 Test MSE 5.69707856343583 Test RE 1.1408647574655988\n",
      "61 Train Loss 1.0766413 Test MSE 5.7139462700652945 Test RE 1.142552424995394\n",
      "62 Train Loss 1.0656097 Test MSE 5.688367581598564 Test RE 1.1399922178066553\n",
      "63 Train Loss 1.0545337 Test MSE 5.66352025416579 Test RE 1.137499696038144\n",
      "64 Train Loss 1.0445622 Test MSE 5.6996908646075815 Test RE 1.1411262898236367\n",
      "65 Train Loss 1.0342736 Test MSE 5.727606978107125 Test RE 1.1439173973528882\n",
      "66 Train Loss 1.0243466 Test MSE 5.7360541523228985 Test RE 1.1447606211864765\n",
      "67 Train Loss 1.0144653 Test MSE 5.760358008203077 Test RE 1.1471832524843963\n",
      "68 Train Loss 1.0062759 Test MSE 5.744683026309028 Test RE 1.1456213420541554\n",
      "69 Train Loss 1.0010264 Test MSE 5.746351898147253 Test RE 1.1457877356002917\n",
      "70 Train Loss 0.99499065 Test MSE 5.765684338505663 Test RE 1.1477135029560972\n",
      "71 Train Loss 0.985497 Test MSE 5.755630840737969 Test RE 1.1467124449094628\n",
      "72 Train Loss 0.97530556 Test MSE 5.761058760665638 Test RE 1.1472530282727245\n",
      "73 Train Loss 0.9650814 Test MSE 5.77852192900582 Test RE 1.148990513869627\n",
      "74 Train Loss 0.9574847 Test MSE 5.776749060531497 Test RE 1.1488142434194575\n",
      "75 Train Loss 0.9488504 Test MSE 5.783066981075667 Test RE 1.149442289886616\n",
      "76 Train Loss 0.9406187 Test MSE 5.7737932291188105 Test RE 1.148520294722756\n",
      "77 Train Loss 0.93512285 Test MSE 5.80452734985924 Test RE 1.1515730462206133\n",
      "78 Train Loss 0.93005973 Test MSE 5.810772180450239 Test RE 1.1521923425881595\n",
      "79 Train Loss 0.9241824 Test MSE 5.835088255456056 Test RE 1.1546005893381044\n",
      "80 Train Loss 0.9189892 Test MSE 5.839309947869308 Test RE 1.1550181911807078\n",
      "81 Train Loss 0.9138202 Test MSE 5.832367537705779 Test RE 1.1543313810208544\n",
      "82 Train Loss 0.907918 Test MSE 5.861834564475723 Test RE 1.157243736793611\n",
      "83 Train Loss 0.9034005 Test MSE 5.863427774485069 Test RE 1.157400991917645\n",
      "84 Train Loss 0.8995961 Test MSE 5.882060340275637 Test RE 1.1592385045252653\n",
      "85 Train Loss 0.89504135 Test MSE 5.893457974430137 Test RE 1.1603610858419198\n",
      "86 Train Loss 0.8911994 Test MSE 5.899445787613888 Test RE 1.1609504055178825\n",
      "87 Train Loss 0.8872335 Test MSE 5.916703549585504 Test RE 1.162647240727775\n",
      "88 Train Loss 0.88404953 Test MSE 5.928740440631544 Test RE 1.1638292796470864\n",
      "89 Train Loss 0.8785564 Test MSE 5.928991981840339 Test RE 1.163853968526762\n",
      "90 Train Loss 0.8737649 Test MSE 5.930903557295379 Test RE 1.1640415733835683\n",
      "91 Train Loss 0.86973 Test MSE 5.929348944428381 Test RE 1.1638890036619889\n",
      "92 Train Loss 0.86591864 Test MSE 5.925580132244742 Test RE 1.1635190493589553\n",
      "93 Train Loss 0.86232877 Test MSE 5.930042349381353 Test RE 1.1639570569013815\n",
      "94 Train Loss 0.8588013 Test MSE 5.949656500786615 Test RE 1.1658804144137074\n",
      "95 Train Loss 0.85566545 Test MSE 5.949938048129112 Test RE 1.165907999758261\n",
      "96 Train Loss 0.8526095 Test MSE 5.9467248081550625 Test RE 1.1655931352927464\n",
      "97 Train Loss 0.84864926 Test MSE 5.956303756289796 Test RE 1.1665315227224138\n",
      "98 Train Loss 0.8455772 Test MSE 5.948890921215682 Test RE 1.1658054014325012\n",
      "99 Train Loss 0.8425926 Test MSE 5.952010965376225 Test RE 1.1661110792119103\n",
      "Training time: 148.86\n",
      "4\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.935368 Test MSE 7.8629658651812235 Test RE 1.3402976478641315\n",
      "1 Train Loss 42.2477 Test MSE 7.351153433978236 Test RE 1.295942712997181\n",
      "2 Train Loss 29.758297 Test MSE 5.5729709148112105 Test RE 1.1283697856146255\n",
      "3 Train Loss 20.713434 Test MSE 5.671815953506926 Test RE 1.1383324733643003\n",
      "4 Train Loss 17.025602 Test MSE 5.929867550163688 Test RE 1.1639399018567538\n",
      "5 Train Loss 14.491522 Test MSE 5.520551026536671 Test RE 1.1230504714349931\n",
      "6 Train Loss 12.34048 Test MSE 5.192489644557412 Test RE 1.0891705245532188\n",
      "7 Train Loss 10.282803 Test MSE 4.278441978987167 Test RE 0.9886689242682173\n",
      "8 Train Loss 8.650564 Test MSE 3.8510370945441723 Test RE 0.937987198504872\n",
      "9 Train Loss 6.914415 Test MSE 3.5110412168629783 Test RE 0.8956246214195726\n",
      "10 Train Loss 5.5140944 Test MSE 3.094564040915207 Test RE 0.8408292238701274\n",
      "11 Train Loss 4.250654 Test MSE 2.6640075516862556 Test RE 0.7801458203237244\n",
      "12 Train Loss 3.3495126 Test MSE 2.30463878519027 Test RE 0.7256204159930256\n",
      "13 Train Loss 2.5771523 Test MSE 1.8131126925154992 Test RE 0.6436065560438335\n",
      "14 Train Loss 2.0882487 Test MSE 1.542911411265728 Test RE 0.5937157306366052\n",
      "15 Train Loss 1.7628607 Test MSE 1.3767071576857524 Test RE 0.5608269117806773\n",
      "16 Train Loss 1.3642191 Test MSE 1.0651464687950636 Test RE 0.49330182963019525\n",
      "17 Train Loss 1.094004 Test MSE 0.8199792326627626 Test RE 0.43282215888122566\n",
      "18 Train Loss 0.90712416 Test MSE 0.6876157621573308 Test RE 0.39635192516261264\n",
      "19 Train Loss 0.7388417 Test MSE 0.4510782167941937 Test RE 0.3210214024605541\n",
      "20 Train Loss 0.56989187 Test MSE 0.3025378525692305 Test RE 0.2629044397540563\n",
      "21 Train Loss 0.459705 Test MSE 0.1671852948006716 Test RE 0.19543713970194063\n",
      "22 Train Loss 0.37543875 Test MSE 0.1315538022531539 Test RE 0.17336433686349423\n",
      "23 Train Loss 0.33024395 Test MSE 0.11051872483992597 Test RE 0.15890076680524032\n",
      "24 Train Loss 0.28534383 Test MSE 0.1086448325162246 Test RE 0.15754789236162406\n",
      "25 Train Loss 0.247146 Test MSE 0.09460407595689564 Test RE 0.14701545228429722\n",
      "26 Train Loss 0.21260329 Test MSE 0.07926943729115825 Test RE 0.13457393387473285\n",
      "27 Train Loss 0.18474634 Test MSE 0.07092740975121538 Test RE 0.12729610349278292\n",
      "28 Train Loss 0.15390296 Test MSE 0.05941004075084303 Test RE 0.11650323516812694\n",
      "29 Train Loss 0.13954267 Test MSE 0.053044868108298594 Test RE 0.11008540569042571\n",
      "30 Train Loss 0.12315466 Test MSE 0.04723411465228815 Test RE 0.10388095893642361\n",
      "31 Train Loss 0.112292185 Test MSE 0.047954833238189463 Test RE 0.1046704889298923\n",
      "32 Train Loss 0.10370922 Test MSE 0.052337154133184904 Test RE 0.10934857107811674\n",
      "33 Train Loss 0.09358009 Test MSE 0.046046879020241245 Test RE 0.10256711979079608\n",
      "34 Train Loss 0.08700959 Test MSE 0.048089503293201614 Test RE 0.10481735731726373\n",
      "35 Train Loss 0.08148418 Test MSE 0.04615746445094008 Test RE 0.10269020769138633\n",
      "36 Train Loss 0.077331506 Test MSE 0.046595057882759944 Test RE 0.10317583399405367\n",
      "37 Train Loss 0.070478834 Test MSE 0.03748806748276962 Test RE 0.09254534671018744\n",
      "38 Train Loss 0.06283582 Test MSE 0.032964544394676054 Test RE 0.08678238852928086\n",
      "39 Train Loss 0.058573034 Test MSE 0.02852651493076832 Test RE 0.08072952905150227\n",
      "40 Train Loss 0.05260223 Test MSE 0.02501391908676453 Test RE 0.07559601989128371\n",
      "41 Train Loss 0.04957161 Test MSE 0.024358391210292808 Test RE 0.0745988892249097\n",
      "42 Train Loss 0.044369925 Test MSE 0.02048901031769662 Test RE 0.0684177126739152\n",
      "43 Train Loss 0.038005155 Test MSE 0.017582766065569144 Test RE 0.06337991599882101\n",
      "44 Train Loss 0.036256507 Test MSE 0.016108455987958716 Test RE 0.060664555207744685\n",
      "45 Train Loss 0.033456486 Test MSE 0.014545018144402158 Test RE 0.05764547126010455\n",
      "46 Train Loss 0.03165698 Test MSE 0.012936619592016523 Test RE 0.054364883802174246\n",
      "47 Train Loss 0.027973041 Test MSE 0.011508343200551304 Test RE 0.05127603823752839\n",
      "48 Train Loss 0.02612286 Test MSE 0.010496973013217737 Test RE 0.04897112720521423\n",
      "49 Train Loss 0.024592727 Test MSE 0.00978577775040972 Test RE 0.0472830773604043\n",
      "50 Train Loss 0.022498835 Test MSE 0.008165776357464809 Test RE 0.043192346746093256\n",
      "51 Train Loss 0.021668341 Test MSE 0.007977984314293762 Test RE 0.042692801028375124\n",
      "52 Train Loss 0.020024562 Test MSE 0.008126735902163836 Test RE 0.0430889720561846\n",
      "53 Train Loss 0.01926024 Test MSE 0.007038092099132801 Test RE 0.04009918382260644\n",
      "54 Train Loss 0.018614685 Test MSE 0.007476855473032092 Test RE 0.04133020440955822\n",
      "55 Train Loss 0.01786064 Test MSE 0.006980814901686712 Test RE 0.03993568348594569\n",
      "56 Train Loss 0.017285947 Test MSE 0.00680429961692181 Test RE 0.03942754850626508\n",
      "57 Train Loss 0.016237745 Test MSE 0.0060803890544432 Test RE 0.037271231653723605\n",
      "58 Train Loss 0.015577529 Test MSE 0.005403051004334798 Test RE 0.03513399975321906\n",
      "59 Train Loss 0.015229088 Test MSE 0.004923486459322825 Test RE 0.033538561718457344\n",
      "60 Train Loss 0.01488162 Test MSE 0.0046902534079453105 Test RE 0.03273453786807078\n",
      "61 Train Loss 0.014205971 Test MSE 0.00372745867634016 Test RE 0.02918196142238959\n",
      "62 Train Loss 0.0134220775 Test MSE 0.004084851056188817 Test RE 0.030548941943100667\n",
      "63 Train Loss 0.012365222 Test MSE 0.003661104518994836 Test RE 0.028921054511338255\n",
      "64 Train Loss 0.011718756 Test MSE 0.003974313992545159 Test RE 0.03013277634754485\n",
      "65 Train Loss 0.011265393 Test MSE 0.0037747145354496323 Test RE 0.02936635990200543\n",
      "66 Train Loss 0.010745202 Test MSE 0.0038698241804021815 Test RE 0.029734023289476774\n",
      "67 Train Loss 0.010223344 Test MSE 0.0038521525260779245 Test RE 0.029666055004624686\n",
      "68 Train Loss 0.00983819 Test MSE 0.003312608828296101 Test RE 0.027510161360917766\n",
      "69 Train Loss 0.009678213 Test MSE 0.00307367511119496 Test RE 0.026499461003357247\n",
      "70 Train Loss 0.009451283 Test MSE 0.0029435355212022807 Test RE 0.025932399340023417\n",
      "71 Train Loss 0.009010147 Test MSE 0.0028529253257812024 Test RE 0.02553014388451818\n",
      "72 Train Loss 0.008363187 Test MSE 0.0028746300615860505 Test RE 0.025627075108575016\n",
      "73 Train Loss 0.0077689523 Test MSE 0.002582597993722966 Test RE 0.02429050058407275\n",
      "74 Train Loss 0.0076268194 Test MSE 0.00250490871598612 Test RE 0.02392235948108868\n",
      "75 Train Loss 0.0075355778 Test MSE 0.002415522071878446 Test RE 0.023491652362866145\n",
      "76 Train Loss 0.0073905373 Test MSE 0.0023643272092489834 Test RE 0.023241376728415038\n",
      "77 Train Loss 0.0070806663 Test MSE 0.0021549243504368205 Test RE 0.02218830232090609\n",
      "78 Train Loss 0.0064038746 Test MSE 0.0020797625045503427 Test RE 0.021797913877030065\n",
      "79 Train Loss 0.0059290333 Test MSE 0.001868634958494355 Test RE 0.02066190188724029\n",
      "80 Train Loss 0.0057895635 Test MSE 0.0017440055591626965 Test RE 0.01996098612443298\n",
      "81 Train Loss 0.005564047 Test MSE 0.0016774246244852615 Test RE 0.019576252920078634\n",
      "82 Train Loss 0.0053634034 Test MSE 0.0015790653803177254 Test RE 0.018993636242203942\n",
      "83 Train Loss 0.005065633 Test MSE 0.001290323591726724 Test RE 0.0171694893693225\n",
      "84 Train Loss 0.0049039386 Test MSE 0.0010157490982949226 Test RE 0.01523355563508055\n",
      "85 Train Loss 0.00479249 Test MSE 0.0009306217237955469 Test RE 0.014581246549744329\n",
      "86 Train Loss 0.004651127 Test MSE 0.0009416774818063554 Test RE 0.014667603212971588\n",
      "87 Train Loss 0.0045231883 Test MSE 0.001018880393947898 Test RE 0.015257018151979539\n",
      "88 Train Loss 0.004393326 Test MSE 0.0011202927161787573 Test RE 0.015998299264203694\n",
      "89 Train Loss 0.0043328013 Test MSE 0.0010862556721990175 Test RE 0.01575339232600732\n",
      "90 Train Loss 0.004271659 Test MSE 0.001114232019729371 Test RE 0.015954965799781732\n",
      "91 Train Loss 0.004184856 Test MSE 0.0009575832162306792 Test RE 0.014790958652804822\n",
      "92 Train Loss 0.0041195354 Test MSE 0.0009202484537970362 Test RE 0.014499753143501782\n",
      "93 Train Loss 0.0039699413 Test MSE 0.000968860581331447 Test RE 0.014877799568044614\n",
      "94 Train Loss 0.00373735 Test MSE 0.0007592012350473451 Test RE 0.01317002238830032\n",
      "95 Train Loss 0.0036008859 Test MSE 0.0008170175589068088 Test RE 0.013662298048469317\n",
      "96 Train Loss 0.0035535735 Test MSE 0.0008053199014605703 Test RE 0.013564140390859122\n",
      "97 Train Loss 0.0034883039 Test MSE 0.0008097472940802734 Test RE 0.013601374949401097\n",
      "98 Train Loss 0.0034194503 Test MSE 0.0007885065039036623 Test RE 0.01342179805867194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0033689244 Test MSE 0.0007875580288702902 Test RE 0.013413723254706588\n",
      "Training time: 148.99\n",
      "5\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "1 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "2 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "3 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "4 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "5 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "6 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "7 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "8 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "9 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "10 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "11 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "12 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "13 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "14 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "15 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "16 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "17 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "18 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "19 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "20 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "21 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "22 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "23 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "24 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "25 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "26 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "27 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "28 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "29 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "30 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "31 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "32 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "33 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "34 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "35 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "36 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "37 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "38 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "39 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "40 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "41 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "42 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "43 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "44 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "45 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "46 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "47 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "48 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "49 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "50 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "51 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "52 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "53 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "54 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "55 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "56 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "57 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "58 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "59 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "60 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "61 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "62 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "63 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "64 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "65 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "66 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "67 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "68 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "69 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "70 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "71 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "72 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "73 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "74 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "75 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "76 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "77 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "78 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "79 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "80 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "81 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "82 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "83 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "84 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "85 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "86 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "87 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "88 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "89 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "90 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "91 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "92 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "93 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "94 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "95 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "97 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "98 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "99 Train Loss 72.78579 Test MSE 4.689680429279122 Test RE 1.0350937469317578\n",
      "Training time: 86.84\n",
      "6\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 66.49896 Test MSE 6.335518317112644 Test RE 1.2030928221203019\n",
      "1 Train Loss 49.280327 Test MSE 8.697693567097796 Test RE 1.409646156850216\n",
      "2 Train Loss 41.06683 Test MSE 9.359817436350172 Test RE 1.4623177419716968\n",
      "3 Train Loss 36.45269 Test MSE 9.189502771196555 Test RE 1.4489522273586717\n",
      "4 Train Loss 32.22186 Test MSE 8.662178373768004 Test RE 1.4067652168457292\n",
      "5 Train Loss 27.998373 Test MSE 8.756346227530939 Test RE 1.4143911261917586\n",
      "6 Train Loss 23.448454 Test MSE 8.461021015942523 Test RE 1.3903349725639897\n",
      "7 Train Loss 22.040997 Test MSE 8.450065784875665 Test RE 1.3894345862853466\n",
      "8 Train Loss 20.531883 Test MSE 8.319805677217206 Test RE 1.37868373377831\n",
      "9 Train Loss 18.732866 Test MSE 8.409622421057332 Test RE 1.386105570337355\n",
      "10 Train Loss 17.107182 Test MSE 8.495709287613106 Test RE 1.3931820868143456\n",
      "11 Train Loss 15.768377 Test MSE 8.219133861633892 Test RE 1.3703171311026754\n",
      "12 Train Loss 14.466623 Test MSE 8.152742274416033 Test RE 1.3647714131083029\n",
      "13 Train Loss 13.186506 Test MSE 7.838162550477817 Test RE 1.33818202871774\n",
      "14 Train Loss 12.023298 Test MSE 7.658062372321732 Test RE 1.3227187500546191\n",
      "15 Train Loss 10.265351 Test MSE 7.044972235267697 Test RE 1.2686671748999356\n",
      "16 Train Loss 8.90078 Test MSE 6.966836984905626 Test RE 1.2616122133543117\n",
      "17 Train Loss 8.2871 Test MSE 7.064814751486921 Test RE 1.270452550869764\n",
      "18 Train Loss 7.852553 Test MSE 7.209137348282276 Test RE 1.2833635790618436\n",
      "19 Train Loss 7.182023 Test MSE 7.0975627156179755 Test RE 1.2733936494131053\n",
      "20 Train Loss 6.7175193 Test MSE 7.173150039596168 Test RE 1.2801563587762603\n",
      "21 Train Loss 5.7789645 Test MSE 6.932007214870134 Test RE 1.2584546311407918\n",
      "22 Train Loss 4.669786 Test MSE 6.018691084775909 Test RE 1.1726248324940425\n",
      "23 Train Loss 4.066022 Test MSE 5.813829737252717 Test RE 1.1524954374369625\n",
      "24 Train Loss 3.6813946 Test MSE 5.783532838788107 Test RE 1.149488585889588\n",
      "25 Train Loss 3.4539628 Test MSE 5.579193051697155 Test RE 1.1289995137067588\n",
      "26 Train Loss 3.201478 Test MSE 5.290296921216718 Test RE 1.099380638369266\n",
      "27 Train Loss 2.9860287 Test MSE 5.273824721959509 Test RE 1.097667753847771\n",
      "28 Train Loss 2.8650627 Test MSE 5.269632548242227 Test RE 1.0972313979796615\n",
      "29 Train Loss 2.7228265 Test MSE 5.358053240737403 Test RE 1.106398485532774\n",
      "30 Train Loss 2.6759765 Test MSE 5.3227834235431 Test RE 1.1027509945555887\n",
      "31 Train Loss 2.6019516 Test MSE 5.342637728383857 Test RE 1.104805744283405\n",
      "32 Train Loss 2.536758 Test MSE 5.357663683614497 Test RE 1.106358264464991\n",
      "33 Train Loss 2.4877584 Test MSE 5.344884920081895 Test RE 1.1050380685969288\n",
      "34 Train Loss 2.4289432 Test MSE 5.3093228465191125 Test RE 1.1013557601647794\n",
      "35 Train Loss 2.3891096 Test MSE 5.3839367652436705 Test RE 1.1090676443697043\n",
      "36 Train Loss 2.3554826 Test MSE 5.378292585438835 Test RE 1.1084861536387574\n",
      "37 Train Loss 2.3243883 Test MSE 5.362597378746666 Test RE 1.106867551596609\n",
      "38 Train Loss 2.2848084 Test MSE 5.390889083512028 Test RE 1.1097834870699943\n",
      "39 Train Loss 2.249235 Test MSE 5.413063884607893 Test RE 1.1120636279533673\n",
      "40 Train Loss 2.2091627 Test MSE 5.361668556071835 Test RE 1.1067716905680607\n",
      "41 Train Loss 2.177777 Test MSE 5.359532699786486 Test RE 1.1065512236823083\n",
      "42 Train Loss 2.1486115 Test MSE 5.40031448572051 Test RE 1.1107532331953751\n",
      "43 Train Loss 2.122831 Test MSE 5.414538933352947 Test RE 1.1122151351553107\n",
      "44 Train Loss 2.091094 Test MSE 5.363578788650436 Test RE 1.1069688309771555\n",
      "45 Train Loss 2.0713875 Test MSE 5.397299567605629 Test RE 1.1104431311092604\n",
      "46 Train Loss 2.0441751 Test MSE 5.390165950761581 Test RE 1.109709051509619\n",
      "47 Train Loss 2.0259423 Test MSE 5.392701315718554 Test RE 1.1099700069883125\n",
      "48 Train Loss 2.0034335 Test MSE 5.410068252672011 Test RE 1.1117558730096133\n",
      "49 Train Loss 1.980536 Test MSE 5.41803955302787 Test RE 1.1125746129554446\n",
      "50 Train Loss 1.9603081 Test MSE 5.45368843214493 Test RE 1.1162287954813723\n",
      "51 Train Loss 1.9401711 Test MSE 5.48307741880325 Test RE 1.1192323367881363\n",
      "52 Train Loss 1.913604 Test MSE 5.550751151920082 Test RE 1.1261181006146714\n",
      "53 Train Loss 1.8980451 Test MSE 5.568736026620267 Test RE 1.1279409812932946\n",
      "54 Train Loss 1.8800626 Test MSE 5.593155126366272 Test RE 1.1304113062140242\n",
      "55 Train Loss 1.8623707 Test MSE 5.600707873516839 Test RE 1.13117427722838\n",
      "56 Train Loss 1.8387768 Test MSE 5.595806798971731 Test RE 1.1306792341937892\n",
      "57 Train Loss 1.8077464 Test MSE 5.572202964707492 Test RE 1.1282920387933157\n",
      "58 Train Loss 1.7926297 Test MSE 5.610707027092629 Test RE 1.1321835908440558\n",
      "59 Train Loss 1.7737119 Test MSE 5.617923941579375 Test RE 1.132911506800946\n",
      "60 Train Loss 1.7530999 Test MSE 5.619769783841821 Test RE 1.1330976079495227\n",
      "61 Train Loss 1.742051 Test MSE 5.601061290360465 Test RE 1.131209966443493\n",
      "62 Train Loss 1.729676 Test MSE 5.560859851394163 Test RE 1.1271430440028811\n",
      "63 Train Loss 1.711453 Test MSE 5.556819962669105 Test RE 1.1267335426022853\n",
      "64 Train Loss 1.6989486 Test MSE 5.538294934624381 Test RE 1.1248538527973186\n",
      "65 Train Loss 1.6880441 Test MSE 5.569392239865503 Test RE 1.1280074369489703\n",
      "66 Train Loss 1.6709964 Test MSE 5.610020261159297 Test RE 1.1321142975347114\n",
      "67 Train Loss 1.6586503 Test MSE 5.628787211796127 Test RE 1.1340063222694161\n",
      "68 Train Loss 1.6481991 Test MSE 5.612204381413714 Test RE 1.1323346561992942\n",
      "69 Train Loss 1.6319569 Test MSE 5.634409261700141 Test RE 1.1345725054219926\n",
      "70 Train Loss 1.6201955 Test MSE 5.627970654959226 Test RE 1.1339240652781972\n",
      "71 Train Loss 1.6051482 Test MSE 5.631320786327803 Test RE 1.1342615074629387\n",
      "72 Train Loss 1.5930403 Test MSE 5.647258911627252 Test RE 1.1358655031686575\n",
      "73 Train Loss 1.5804114 Test MSE 5.635418105013142 Test RE 1.1346740737143453\n",
      "74 Train Loss 1.5617393 Test MSE 5.684049951429767 Test RE 1.1395594926819124\n",
      "75 Train Loss 1.5460674 Test MSE 5.655144824928326 Test RE 1.1366582959343867\n",
      "76 Train Loss 1.5248829 Test MSE 5.681535104489761 Test RE 1.1393073718538642\n",
      "77 Train Loss 1.5001132 Test MSE 5.697882053485161 Test RE 1.1409452058174572\n",
      "78 Train Loss 1.4828172 Test MSE 5.725513943890811 Test RE 1.143708367906967\n",
      "79 Train Loss 1.4650329 Test MSE 5.7213587574892655 Test RE 1.1432932799301743\n",
      "80 Train Loss 1.4502826 Test MSE 5.690642416541503 Test RE 1.1402201421518496\n",
      "81 Train Loss 1.436668 Test MSE 5.718651149005084 Test RE 1.1430227185962063\n",
      "82 Train Loss 1.4196286 Test MSE 5.719450297398539 Test RE 1.1431025812102664\n",
      "83 Train Loss 1.4008795 Test MSE 5.69317364429549 Test RE 1.1404737019246436\n",
      "84 Train Loss 1.3821108 Test MSE 5.700637728432396 Test RE 1.1412210709581312\n",
      "85 Train Loss 1.3664181 Test MSE 5.737724427465061 Test RE 1.144927279832451\n",
      "86 Train Loss 1.3524276 Test MSE 5.6808648496113445 Test RE 1.139240167407119\n",
      "87 Train Loss 1.3390846 Test MSE 5.691522575957323 Test RE 1.1403083164403176\n",
      "88 Train Loss 1.3239892 Test MSE 5.70230266063039 Test RE 1.1413877116993902\n",
      "89 Train Loss 1.306046 Test MSE 5.700346535747712 Test RE 1.1411919233884082\n",
      "90 Train Loss 1.2916332 Test MSE 5.70813101910294 Test RE 1.1419708724096291\n",
      "91 Train Loss 1.2725703 Test MSE 5.711453198285438 Test RE 1.142303142288937\n",
      "92 Train Loss 1.2616622 Test MSE 5.706810445303346 Test RE 1.1418387675191553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 1.2450876 Test MSE 5.6683719268498125 Test RE 1.1379868131086595\n",
      "94 Train Loss 1.2331601 Test MSE 5.679399516801301 Test RE 1.1390932290708147\n",
      "95 Train Loss 1.2144966 Test MSE 5.668203945828188 Test RE 1.1379699509826202\n",
      "96 Train Loss 1.1951945 Test MSE 5.717381454424138 Test RE 1.1428958206373008\n",
      "97 Train Loss 1.1806017 Test MSE 5.743581451924928 Test RE 1.1455114972095801\n",
      "98 Train Loss 1.1694033 Test MSE 5.7439360060169244 Test RE 1.1455468531564286\n",
      "99 Train Loss 1.16096 Test MSE 5.7653740100796105 Test RE 1.1476826156496918\n",
      "Training time: 150.17\n",
      "7\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 56.22825 Test MSE 6.253376960970621 Test RE 1.1952681989377685\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 5.89\n",
      "0\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 70.00272 Test MSE 4.375719386431367 Test RE 0.9998452593779227\n",
      "1 Train Loss 54.153664 Test MSE 5.910127609969552 Test RE 1.1620009667083142\n",
      "2 Train Loss 38.384907 Test MSE 6.321706665263193 Test RE 1.2017807143730717\n",
      "3 Train Loss 31.660969 Test MSE 6.011088687890033 Test RE 1.171884008936527\n",
      "4 Train Loss 26.096008 Test MSE 5.154148780403036 Test RE 1.085141906739307\n",
      "5 Train Loss 20.437881 Test MSE 4.50889213061084 Test RE 1.014946109177625\n",
      "6 Train Loss 16.629425 Test MSE 4.929997326844142 Test RE 1.0612834754716916\n",
      "7 Train Loss 14.660942 Test MSE 4.82441136244076 Test RE 1.0498571881460717\n",
      "8 Train Loss 13.135661 Test MSE 4.817274593352592 Test RE 1.049080371994949\n",
      "9 Train Loss 11.539837 Test MSE 4.840000657460247 Test RE 1.0515520408525731\n",
      "10 Train Loss 10.671367 Test MSE 4.8984040363984676 Test RE 1.0578774566641844\n",
      "11 Train Loss 9.639137 Test MSE 4.983841403194693 Test RE 1.0670632602948407\n",
      "12 Train Loss 8.956278 Test MSE 4.937925183401694 Test RE 1.0621364499087513\n",
      "13 Train Loss 8.162892 Test MSE 5.037441349571433 Test RE 1.0727859119764458\n",
      "14 Train Loss 7.5051804 Test MSE 4.905028207360146 Test RE 1.058592505236692\n",
      "15 Train Loss 6.9869914 Test MSE 4.8415279130143505 Test RE 1.0517179356671171\n",
      "16 Train Loss 6.5400286 Test MSE 4.969013355117931 Test RE 1.0654747013469181\n",
      "17 Train Loss 6.290204 Test MSE 4.9796388636102655 Test RE 1.0666132739319356\n",
      "18 Train Loss 5.822736 Test MSE 4.89267042628874 Test RE 1.0572581495604956\n",
      "19 Train Loss 5.524294 Test MSE 4.900369178371679 Test RE 1.0580896350510365\n",
      "20 Train Loss 5.3570113 Test MSE 4.862355718118452 Test RE 1.0539777045689476\n",
      "21 Train Loss 5.1018305 Test MSE 4.782838263938802 Test RE 1.0453239666895209\n",
      "22 Train Loss 4.8802314 Test MSE 4.77319686919529 Test RE 1.0442698368354686\n",
      "23 Train Loss 4.671543 Test MSE 4.799040968550071 Test RE 1.0470930789234807\n",
      "24 Train Loss 4.479519 Test MSE 4.8080385369362055 Test RE 1.0480741999288246\n",
      "25 Train Loss 4.3390803 Test MSE 4.794443024271582 Test RE 1.0465913506199873\n",
      "26 Train Loss 4.155974 Test MSE 4.824542316867807 Test RE 1.049871436776969\n",
      "27 Train Loss 4.0068955 Test MSE 4.811636896884377 Test RE 1.048466318547961\n",
      "28 Train Loss 3.7918868 Test MSE 4.7402691828488575 Test RE 1.0406616788709768\n",
      "29 Train Loss 3.6358998 Test MSE 4.755765073192419 Test RE 1.0423612471045103\n",
      "30 Train Loss 3.5499964 Test MSE 4.770908361803976 Test RE 1.044019469437707\n",
      "31 Train Loss 3.4169447 Test MSE 4.728010631126622 Test RE 1.0393152085806063\n",
      "32 Train Loss 3.314404 Test MSE 4.729972110532962 Test RE 1.0395307732383943\n",
      "33 Train Loss 3.214406 Test MSE 4.681445323967134 Test RE 1.0341845323780035\n",
      "34 Train Loss 3.1178217 Test MSE 4.6604136428446905 Test RE 1.0318588485506648\n",
      "35 Train Loss 3.0217056 Test MSE 4.67188889111232 Test RE 1.0331284307663346\n",
      "36 Train Loss 2.90855 Test MSE 4.6519193814983355 Test RE 1.0309180655156227\n",
      "37 Train Loss 2.846116 Test MSE 4.6521834041160215 Test RE 1.0309473203029529\n",
      "38 Train Loss 2.7701347 Test MSE 4.556511616871859 Test RE 1.0202915766426348\n",
      "39 Train Loss 2.6615543 Test MSE 4.612691368143653 Test RE 1.026562176943295\n",
      "40 Train Loss 2.5701609 Test MSE 4.587808965026975 Test RE 1.0237896226555505\n",
      "41 Train Loss 2.437231 Test MSE 4.516203560504207 Test RE 1.0157686728216153\n",
      "42 Train Loss 2.322395 Test MSE 4.387752245016975 Test RE 1.001219060557642\n",
      "43 Train Loss 2.236931 Test MSE 4.361714957400312 Test RE 0.9982439817119111\n",
      "44 Train Loss 2.1610155 Test MSE 4.381945621943281 Test RE 1.0005563492115372\n",
      "45 Train Loss 2.087577 Test MSE 4.36777914459386 Test RE 0.9989376808416031\n",
      "46 Train Loss 1.9975091 Test MSE 4.260385451924924 Test RE 0.9865804534562569\n",
      "47 Train Loss 1.9229617 Test MSE 4.211782088449325 Test RE 0.9809367536400261\n",
      "48 Train Loss 1.8779198 Test MSE 4.197046155193558 Test RE 0.9792192283760137\n",
      "49 Train Loss 1.8173219 Test MSE 4.184808962023323 Test RE 0.9777906472140779\n",
      "50 Train Loss 1.7821249 Test MSE 4.1954954104094995 Test RE 0.9790383083493984\n",
      "51 Train Loss 1.7567159 Test MSE 4.162414759828298 Test RE 0.9751709082382091\n",
      "52 Train Loss 1.6944559 Test MSE 4.134242188345034 Test RE 0.9718651688587086\n",
      "53 Train Loss 1.6498649 Test MSE 4.050805669823556 Test RE 0.9620081799784869\n",
      "54 Train Loss 1.5710783 Test MSE 3.9958688345999227 Test RE 0.9554625566040456\n",
      "55 Train Loss 1.5218049 Test MSE 3.9662780777664928 Test RE 0.9519182213700685\n",
      "56 Train Loss 1.459905 Test MSE 3.8866225762746685 Test RE 0.9423109651609437\n",
      "57 Train Loss 1.4281129 Test MSE 3.8545042647569496 Test RE 0.9384093483734299\n",
      "58 Train Loss 1.38854 Test MSE 3.817551957954628 Test RE 0.9339003509360045\n",
      "59 Train Loss 1.3346269 Test MSE 3.7879291959007704 Test RE 0.9302699374749266\n",
      "60 Train Loss 1.3023608 Test MSE 3.7467815011985737 Test RE 0.9252034508616629\n",
      "61 Train Loss 1.2620968 Test MSE 3.696439569672322 Test RE 0.9189668929234381\n",
      "62 Train Loss 1.2352086 Test MSE 3.680640831879924 Test RE 0.9170009385049035\n",
      "63 Train Loss 1.2113175 Test MSE 3.6457888411476707 Test RE 0.912649070762636\n",
      "64 Train Loss 1.17944 Test MSE 3.611998340674151 Test RE 0.9084098430195797\n",
      "65 Train Loss 1.1519902 Test MSE 3.5604161913376235 Test RE 0.9019001184478771\n",
      "66 Train Loss 1.1233089 Test MSE 3.529823585452943 Test RE 0.8980170049566232\n",
      "67 Train Loss 1.0986404 Test MSE 3.502136289815907 Test RE 0.8944881301594556\n",
      "68 Train Loss 1.0575075 Test MSE 3.4313845600328223 Test RE 0.8854066034466525\n",
      "69 Train Loss 1.029489 Test MSE 3.4733291345278006 Test RE 0.8908016850910855\n",
      "70 Train Loss 0.990688 Test MSE 3.453347780194685 Test RE 0.8882356891210157\n",
      "71 Train Loss 0.9661603 Test MSE 3.415179689401056 Test RE 0.8833134426562165\n",
      "72 Train Loss 0.9148344 Test MSE 3.3815580865922206 Test RE 0.8789546867712171\n",
      "73 Train Loss 0.8919571 Test MSE 3.3983949824028836 Test RE 0.8811401428245302\n",
      "74 Train Loss 0.8726031 Test MSE 3.4238110097306085 Test RE 0.8844289549913931\n",
      "75 Train Loss 0.8575191 Test MSE 3.3935731732600325 Test RE 0.8805148185536464\n",
      "76 Train Loss 0.8359123 Test MSE 3.390850850244561 Test RE 0.8801615733819935\n",
      "77 Train Loss 0.8241077 Test MSE 3.390349076167204 Test RE 0.8800964483410307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Train Loss 0.8088276 Test MSE 3.3612531933567826 Test RE 0.8763118291762783\n",
      "79 Train Loss 0.78813565 Test MSE 3.366470758357846 Test RE 0.8769917007476402\n",
      "80 Train Loss 0.77216625 Test MSE 3.3752495889743366 Test RE 0.8781344329269548\n",
      "81 Train Loss 0.75992924 Test MSE 3.3546545933192258 Test RE 0.8754512465823548\n",
      "82 Train Loss 0.73445374 Test MSE 3.31434764478172 Test RE 0.8701759785002193\n",
      "83 Train Loss 0.7224381 Test MSE 3.305237275809077 Test RE 0.8689792000714831\n",
      "84 Train Loss 0.7096621 Test MSE 3.2743368583798693 Test RE 0.8649076506212875\n",
      "85 Train Loss 0.69338995 Test MSE 3.2552593972701045 Test RE 0.8623843387054887\n",
      "86 Train Loss 0.6812093 Test MSE 3.26180619712547 Test RE 0.8632510932657264\n",
      "87 Train Loss 0.6602317 Test MSE 3.2395815037942937 Test RE 0.860305136009724\n",
      "88 Train Loss 0.64725155 Test MSE 3.204166622643687 Test RE 0.8555898155561874\n",
      "89 Train Loss 0.6373705 Test MSE 3.199821596821186 Test RE 0.8550095053789906\n",
      "90 Train Loss 0.6313754 Test MSE 3.1971740149570866 Test RE 0.8546557081371658\n",
      "91 Train Loss 0.6205553 Test MSE 3.1940441758484766 Test RE 0.854237277701801\n",
      "92 Train Loss 0.60707444 Test MSE 3.1898555283421053 Test RE 0.8536769735091562\n",
      "93 Train Loss 0.6010193 Test MSE 3.1944359258756507 Test RE 0.8542896622647277\n",
      "94 Train Loss 0.58469325 Test MSE 3.1994995304222256 Test RE 0.8549664753609755\n",
      "95 Train Loss 0.5743337 Test MSE 3.179057245724904 Test RE 0.8522308171294181\n",
      "96 Train Loss 0.55892843 Test MSE 3.2109649277755885 Test RE 0.8564969903892717\n",
      "97 Train Loss 0.5471358 Test MSE 3.237792643185401 Test RE 0.8600675777824885\n",
      "98 Train Loss 0.53808045 Test MSE 3.2528371376576737 Test RE 0.8620634261086411\n",
      "99 Train Loss 0.5315626 Test MSE 3.2320586962523232 Test RE 0.8593056748879988\n",
      "Training time: 148.68\n",
      "1\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 65.407265 Test MSE 6.103192344831683 Test RE 1.1808278536939414\n",
      "1 Train Loss 50.52795 Test MSE 8.667665481901427 Test RE 1.4072107081813998\n",
      "2 Train Loss 44.395844 Test MSE 8.622910728861322 Test RE 1.4035729999906374\n",
      "3 Train Loss 39.50865 Test MSE 9.337796932127322 Test RE 1.4605965579817166\n",
      "4 Train Loss 37.080383 Test MSE 10.165455079948728 Test RE 1.5239526486709492\n",
      "5 Train Loss 34.80204 Test MSE 10.324844795146534 Test RE 1.5358536220804206\n",
      "6 Train Loss 33.692635 Test MSE 10.142421948472784 Test RE 1.5222251653757641\n",
      "7 Train Loss 32.566086 Test MSE 10.07539527843504 Test RE 1.5171869796894601\n",
      "8 Train Loss 30.784893 Test MSE 9.792894160940012 Test RE 1.495765771130981\n",
      "9 Train Loss 29.844593 Test MSE 9.95561117285309 Test RE 1.5081412665172076\n",
      "10 Train Loss 28.853176 Test MSE 9.887788737152114 Test RE 1.5029953938368206\n",
      "11 Train Loss 27.92792 Test MSE 9.51144977052089 Test RE 1.474115184105084\n",
      "12 Train Loss 26.810938 Test MSE 9.035420235015776 Test RE 1.4367534161524598\n",
      "13 Train Loss 23.373425 Test MSE 7.9255896865669255 Test RE 1.3456243974655633\n",
      "14 Train Loss 20.040333 Test MSE 7.908467990460969 Test RE 1.344170131638183\n",
      "15 Train Loss 18.3475 Test MSE 7.552309758621641 Test RE 1.3135540790995182\n",
      "16 Train Loss 17.37854 Test MSE 7.566247984579427 Test RE 1.3147656404980206\n",
      "17 Train Loss 16.920929 Test MSE 7.536210167952733 Test RE 1.3121532516664969\n",
      "18 Train Loss 16.5485 Test MSE 7.570381666423464 Test RE 1.315124740594061\n",
      "19 Train Loss 16.340004 Test MSE 7.530688047206557 Test RE 1.31167242666548\n",
      "20 Train Loss 16.154076 Test MSE 7.512559839823446 Test RE 1.3100927172885108\n",
      "21 Train Loss 15.901688 Test MSE 7.407584347521387 Test RE 1.3009073366122357\n",
      "22 Train Loss 15.671716 Test MSE 7.476924970135709 Test RE 1.3069818950779755\n",
      "23 Train Loss 15.405188 Test MSE 7.443110674689087 Test RE 1.3040231417879669\n",
      "24 Train Loss 15.221149 Test MSE 7.397606568047016 Test RE 1.3000309010682165\n",
      "25 Train Loss 15.099714 Test MSE 7.39912280769717 Test RE 1.300164123711712\n",
      "26 Train Loss 14.868105 Test MSE 7.380916831799261 Test RE 1.2985635734790573\n",
      "27 Train Loss 14.63845 Test MSE 7.330308008866646 Test RE 1.2941039774005505\n",
      "28 Train Loss 14.402565 Test MSE 7.376852804489048 Test RE 1.2982060213891398\n",
      "29 Train Loss 14.191776 Test MSE 7.35759969953378 Test RE 1.2965107980151003\n",
      "30 Train Loss 14.016394 Test MSE 7.277702103545062 Test RE 1.2894520520708286\n",
      "31 Train Loss 13.71962 Test MSE 7.310313133753746 Test RE 1.292337809007937\n",
      "32 Train Loss 13.513056 Test MSE 7.3505485362331155 Test RE 1.2958893928645727\n",
      "33 Train Loss 13.344642 Test MSE 7.282281520434601 Test RE 1.289857675288752\n",
      "34 Train Loss 12.95373 Test MSE 6.2931019571545415 Test RE 1.1990586992804337\n",
      "35 Train Loss 11.195794 Test MSE 6.019615991315843 Test RE 1.1727149290530237\n",
      "36 Train Loss 10.366207 Test MSE 5.889679871863597 Test RE 1.1599890915013644\n",
      "37 Train Loss 9.953455 Test MSE 5.825252456757388 Test RE 1.153627064329228\n",
      "38 Train Loss 9.632203 Test MSE 5.7992320006148566 Test RE 1.1510476483292267\n",
      "39 Train Loss 7.965211 Test MSE 4.870130903244959 Test RE 1.0548200533034406\n",
      "40 Train Loss 6.6980414 Test MSE 4.637858606479761 Test RE 1.0293588728666998\n",
      "41 Train Loss 5.988259 Test MSE 4.446115698698177 Test RE 1.0078558946951957\n",
      "42 Train Loss 5.632734 Test MSE 4.58039382705143 Test RE 1.0229619278513005\n",
      "43 Train Loss 5.377157 Test MSE 4.758792013241624 Test RE 1.04269291436177\n",
      "44 Train Loss 5.189125 Test MSE 4.949180393264527 Test RE 1.0633462459085041\n",
      "45 Train Loss 5.009982 Test MSE 5.105119141454104 Test RE 1.0799682833459694\n",
      "46 Train Loss 4.8327255 Test MSE 5.044477347245737 Test RE 1.073534852242592\n",
      "47 Train Loss 4.6290956 Test MSE 5.264668828862261 Test RE 1.096714508817732\n",
      "48 Train Loss 4.5550113 Test MSE 5.369479976431062 Test RE 1.1075776255324843\n",
      "49 Train Loss 4.4587665 Test MSE 5.5146840518006375 Test RE 1.1224535509250864\n",
      "50 Train Loss 4.3105507 Test MSE 5.507623791995392 Test RE 1.1217348015184307\n",
      "51 Train Loss 4.217408 Test MSE 5.538587618858615 Test RE 1.124883575179644\n",
      "52 Train Loss 4.1290975 Test MSE 5.630648419345114 Test RE 1.1341937913105453\n",
      "53 Train Loss 4.0134616 Test MSE 5.642624542018248 Test RE 1.1353993388701256\n",
      "54 Train Loss 3.90731 Test MSE 5.710622509655334 Test RE 1.1422200694960285\n",
      "55 Train Loss 3.8149216 Test MSE 5.617336287690177 Test RE 1.1328522520592383\n",
      "56 Train Loss 3.7571123 Test MSE 5.740244542888236 Test RE 1.1451786889213336\n",
      "57 Train Loss 3.7017248 Test MSE 5.681791029999786 Test RE 1.1393330316915131\n",
      "58 Train Loss 3.629304 Test MSE 5.6438883497602745 Test RE 1.1355264823763167\n",
      "59 Train Loss 3.4701157 Test MSE 5.640192830456503 Test RE 1.1351546600681641\n",
      "60 Train Loss 3.3952188 Test MSE 5.637975288247886 Test RE 1.1349314849993253\n",
      "61 Train Loss 3.3372223 Test MSE 5.650527167864344 Test RE 1.136194137167995\n",
      "62 Train Loss 3.2982817 Test MSE 5.660185351637871 Test RE 1.1371647445380961\n",
      "63 Train Loss 3.2631779 Test MSE 5.6579369226034 Test RE 1.1369388607518953\n",
      "64 Train Loss 3.1969435 Test MSE 5.6753825296691485 Test RE 1.1386903227241216\n",
      "65 Train Loss 3.1670723 Test MSE 5.711092240217653 Test RE 1.1422670455167534\n",
      "66 Train Loss 3.0961294 Test MSE 5.850396105726751 Test RE 1.1561140948328505\n",
      "67 Train Loss 3.0699742 Test MSE 5.8526226922512326 Test RE 1.1563340750819284\n",
      "68 Train Loss 3.0183153 Test MSE 5.869267724216742 Test RE 1.1579772317627477\n",
      "69 Train Loss 2.9488797 Test MSE 5.841350821440131 Test RE 1.1552200164125712\n",
      "70 Train Loss 2.9171293 Test MSE 5.908391945883277 Test RE 1.1618303281387492\n",
      "71 Train Loss 2.8432095 Test MSE 5.971637357212084 Test RE 1.1680320868669631\n",
      "72 Train Loss 2.8204107 Test MSE 5.959282159421213 Test RE 1.1668231437557002\n",
      "73 Train Loss 2.7765105 Test MSE 5.937278864384754 Test RE 1.164667037041635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 2.7213516 Test MSE 5.933963911122498 Test RE 1.1643418581226561\n",
      "75 Train Loss 2.6991086 Test MSE 5.968954515517358 Test RE 1.167769680006539\n",
      "76 Train Loss 2.6761825 Test MSE 5.934345916422032 Test RE 1.164379335398284\n",
      "77 Train Loss 2.6533246 Test MSE 5.959673320070262 Test RE 1.1668614376136368\n",
      "78 Train Loss 2.6332922 Test MSE 5.9221318342775495 Test RE 1.1631804543052715\n",
      "79 Train Loss 2.6015475 Test MSE 5.932952936996704 Test RE 1.1642426689760135\n",
      "80 Train Loss 2.5644906 Test MSE 5.978308196504409 Test RE 1.1686843015839017\n",
      "81 Train Loss 2.53842 Test MSE 5.997253493595807 Test RE 1.170534620855874\n",
      "82 Train Loss 2.5063279 Test MSE 6.026599658343291 Test RE 1.1733949954064504\n",
      "83 Train Loss 2.4752467 Test MSE 6.09293855538567 Test RE 1.1798355000754888\n",
      "84 Train Loss 2.4551048 Test MSE 6.108046986781685 Test RE 1.1812973913242877\n",
      "85 Train Loss 2.4245312 Test MSE 6.111824153033232 Test RE 1.1816625871923818\n",
      "86 Train Loss 2.4012737 Test MSE 6.067508700189933 Test RE 1.1773708094521669\n",
      "87 Train Loss 2.3767 Test MSE 6.0394635418077565 Test RE 1.174646644022122\n",
      "88 Train Loss 2.3639326 Test MSE 6.048805343458575 Test RE 1.1755547607611418\n",
      "89 Train Loss 2.3423138 Test MSE 6.011752370332374 Test RE 1.1719487008263603\n",
      "90 Train Loss 2.3098223 Test MSE 6.03162799803427 Test RE 1.1738844089025275\n",
      "91 Train Loss 2.2807221 Test MSE 6.020649135624013 Test RE 1.1728155610347275\n",
      "92 Train Loss 2.2543807 Test MSE 5.976075965709343 Test RE 1.168466094645683\n",
      "93 Train Loss 2.233383 Test MSE 5.993074740516257 Test RE 1.170126748526964\n",
      "94 Train Loss 2.21991 Test MSE 6.04436831560626 Test RE 1.175123524690717\n",
      "95 Train Loss 2.1976502 Test MSE 6.080087553107592 Test RE 1.1785906104525843\n",
      "96 Train Loss 2.178991 Test MSE 6.050445439328295 Test RE 1.175714122132783\n",
      "97 Train Loss 2.1483207 Test MSE 6.0953794415306115 Test RE 1.180071802783463\n",
      "98 Train Loss 2.1292748 Test MSE 6.118834561231564 Test RE 1.1823400905673593\n",
      "99 Train Loss 2.1169107 Test MSE 6.118811657383623 Test RE 1.1823378777143463\n",
      "Training time: 149.63\n",
      "2\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.778275 Test MSE 7.168365126884776 Test RE 1.279729317779819\n",
      "1 Train Loss 43.551723 Test MSE 8.326808400040871 Test RE 1.379263826014732\n",
      "2 Train Loss 32.432156 Test MSE 6.990631395924533 Test RE 1.2637648208741734\n",
      "3 Train Loss 24.233147 Test MSE 5.482852800697243 Test RE 1.119209411485135\n",
      "4 Train Loss 19.296034 Test MSE 5.4937550982255265 Test RE 1.1203215965800304\n",
      "5 Train Loss 15.893838 Test MSE 5.877237189084361 Test RE 1.1587631328969348\n",
      "6 Train Loss 14.042683 Test MSE 5.696421414420869 Test RE 1.1407989570940424\n",
      "7 Train Loss 11.997361 Test MSE 5.4729465749261905 Test RE 1.1181978802611603\n",
      "8 Train Loss 10.584297 Test MSE 5.485228325556896 Test RE 1.1194518420188444\n",
      "9 Train Loss 9.8906765 Test MSE 5.252191476964427 Test RE 1.0954141221451192\n",
      "10 Train Loss 9.236027 Test MSE 5.200714564428413 Test RE 1.0900328079856731\n",
      "11 Train Loss 8.660019 Test MSE 5.2945420701589 Test RE 1.0998216437366861\n",
      "12 Train Loss 8.2571945 Test MSE 5.21550127193678 Test RE 1.0915813024920646\n",
      "13 Train Loss 7.909412 Test MSE 5.1466020718782275 Test RE 1.0843471829255165\n",
      "14 Train Loss 7.6355495 Test MSE 5.199675408421548 Test RE 1.089923902688748\n",
      "15 Train Loss 7.463851 Test MSE 5.189101462676777 Test RE 1.08881511604194\n",
      "16 Train Loss 7.2191153 Test MSE 5.1953114238439575 Test RE 1.0894664309104334\n",
      "17 Train Loss 7.011298 Test MSE 5.179028460689832 Test RE 1.0877578073123384\n",
      "18 Train Loss 6.7168055 Test MSE 5.029427298083826 Test RE 1.0719322262420403\n",
      "19 Train Loss 6.4594345 Test MSE 4.916745612572669 Test RE 1.0598561634495716\n",
      "20 Train Loss 6.107613 Test MSE 4.861961722794669 Test RE 1.0539350019445888\n",
      "21 Train Loss 5.8704624 Test MSE 4.776656307415004 Test RE 1.0446481925532034\n",
      "22 Train Loss 5.5942087 Test MSE 4.586045029253615 Test RE 1.0235927887451324\n",
      "23 Train Loss 5.2283416 Test MSE 4.477232112504651 Test RE 1.0113765163052273\n",
      "24 Train Loss 4.914858 Test MSE 4.232837138677643 Test RE 0.9833855893282605\n",
      "25 Train Loss 4.685621 Test MSE 4.166761270448368 Test RE 0.9756799258418078\n",
      "26 Train Loss 4.360121 Test MSE 3.885579173192985 Test RE 0.9421844702231552\n",
      "27 Train Loss 4.0445933 Test MSE 3.639081436289186 Test RE 0.9118091530920198\n",
      "28 Train Loss 3.7129793 Test MSE 3.455779249190617 Test RE 0.8885483332060169\n",
      "29 Train Loss 3.4825218 Test MSE 3.428687202984202 Test RE 0.8850585329770841\n",
      "30 Train Loss 3.1787045 Test MSE 3.254096407766711 Test RE 0.8622302751722127\n",
      "31 Train Loss 2.9793365 Test MSE 3.0706687736642593 Test RE 0.8375766210856906\n",
      "32 Train Loss 2.7191515 Test MSE 2.88430623504382 Test RE 0.8117620510257704\n",
      "33 Train Loss 2.500883 Test MSE 2.7600420058376853 Test RE 0.7940830138322609\n",
      "34 Train Loss 2.3277054 Test MSE 2.5316439784978897 Test RE 0.7605177873467632\n",
      "35 Train Loss 2.1537137 Test MSE 2.2994558247313477 Test RE 0.724804023679438\n",
      "36 Train Loss 1.9566675 Test MSE 2.1971369021370815 Test RE 0.7084947223013939\n",
      "37 Train Loss 1.852183 Test MSE 2.2055954032856397 Test RE 0.7098571878681488\n",
      "38 Train Loss 1.7438153 Test MSE 2.1806071356798475 Test RE 0.705824574070838\n",
      "39 Train Loss 1.6262677 Test MSE 2.023979571772002 Test RE 0.6800034603018137\n",
      "40 Train Loss 1.5202364 Test MSE 1.9076398278478854 Test RE 0.6601707082998586\n",
      "41 Train Loss 1.438911 Test MSE 1.6996921082546257 Test RE 0.6231508464313033\n",
      "42 Train Loss 1.3780245 Test MSE 1.5152573968882412 Test RE 0.5883710106310029\n",
      "43 Train Loss 1.2914518 Test MSE 1.2079871426099378 Test RE 0.5253384836525486\n",
      "44 Train Loss 1.1138434 Test MSE 0.955056977164987 Test RE 0.4671138034648544\n",
      "45 Train Loss 0.98921365 Test MSE 0.8875216203315156 Test RE 0.4502954213028573\n",
      "46 Train Loss 0.9052975 Test MSE 0.930097057940026 Test RE 0.4609695045677025\n",
      "47 Train Loss 0.8275361 Test MSE 0.8788323794989019 Test RE 0.4480857008396543\n",
      "48 Train Loss 0.7339788 Test MSE 0.6821410939997081 Test RE 0.3947709320131346\n",
      "49 Train Loss 0.6464305 Test MSE 0.587391270363944 Test RE 0.3663294249461842\n",
      "50 Train Loss 0.576413 Test MSE 0.5392122978060998 Test RE 0.35098451355904065\n",
      "51 Train Loss 0.47762924 Test MSE 0.4014075018931346 Test RE 0.3028313291111171\n",
      "52 Train Loss 0.40485013 Test MSE 0.33355653324869794 Test RE 0.2760532001050426\n",
      "53 Train Loss 0.35358828 Test MSE 0.2888862966370399 Test RE 0.25690439322489234\n",
      "54 Train Loss 0.30686283 Test MSE 0.195253997814061 Test RE 0.2112068637440793\n",
      "55 Train Loss 0.27259004 Test MSE 0.210707302087819 Test RE 0.21940567344660897\n",
      "56 Train Loss 0.23354448 Test MSE 0.16778813772059015 Test RE 0.1957891798712658\n",
      "57 Train Loss 0.21199201 Test MSE 0.1478119539552614 Test RE 0.183765017089561\n",
      "58 Train Loss 0.18111861 Test MSE 0.13928348045963282 Test RE 0.1783848081127523\n",
      "59 Train Loss 0.16297755 Test MSE 0.1099259273535171 Test RE 0.15847403990142434\n",
      "60 Train Loss 0.14872473 Test MSE 0.10389886850347911 Test RE 0.1540683633945073\n",
      "61 Train Loss 0.11636958 Test MSE 0.07847310129652273 Test RE 0.13389626680920577\n",
      "62 Train Loss 0.099979594 Test MSE 0.05371752068226799 Test RE 0.11078119361070413\n",
      "63 Train Loss 0.09444561 Test MSE 0.05179936353542093 Test RE 0.10878531460683388\n",
      "64 Train Loss 0.08505215 Test MSE 0.049841951674913794 Test RE 0.10671011309005386\n",
      "65 Train Loss 0.07787071 Test MSE 0.0496420908616688 Test RE 0.10649595019967353\n",
      "66 Train Loss 0.07273355 Test MSE 0.04064568446906366 Test RE 0.096364102520687\n",
      "67 Train Loss 0.067198776 Test MSE 0.03740074061070674 Test RE 0.09243749362282883\n",
      "68 Train Loss 0.06261831 Test MSE 0.03529308073875486 Test RE 0.08979514273073104\n",
      "69 Train Loss 0.057832893 Test MSE 0.027372041371064876 Test RE 0.07907908838034507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 0.055699985 Test MSE 0.025437064896540757 Test RE 0.07623274518953752\n",
      "71 Train Loss 0.053017873 Test MSE 0.02395667642789908 Test RE 0.0739811952960649\n",
      "72 Train Loss 0.04867139 Test MSE 0.023363857151911676 Test RE 0.07306011162531896\n",
      "73 Train Loss 0.04619343 Test MSE 0.02173464800607297 Test RE 0.07046677012203384\n",
      "74 Train Loss 0.04131079 Test MSE 0.022288738933729842 Test RE 0.07135933743050693\n",
      "75 Train Loss 0.039550804 Test MSE 0.020753725982493944 Test RE 0.06885826875988373\n",
      "76 Train Loss 0.038267717 Test MSE 0.019223625051246338 Test RE 0.06627133264204135\n",
      "77 Train Loss 0.035229605 Test MSE 0.020735026603108102 Test RE 0.0688272406673645\n",
      "78 Train Loss 0.03351369 Test MSE 0.020220902663304154 Test RE 0.06796860079401347\n",
      "79 Train Loss 0.02922025 Test MSE 0.017407917084681104 Test RE 0.06306399294953854\n",
      "80 Train Loss 0.027738972 Test MSE 0.01663495819459088 Test RE 0.06164798942473439\n",
      "81 Train Loss 0.025259139 Test MSE 0.01320531696335629 Test RE 0.05492656946357894\n",
      "82 Train Loss 0.023376437 Test MSE 0.01219586731485804 Test RE 0.05278547155952921\n",
      "83 Train Loss 0.022022568 Test MSE 0.011897216033717361 Test RE 0.05213516281349054\n",
      "84 Train Loss 0.0209137 Test MSE 0.011709768948708376 Test RE 0.05172282333770967\n",
      "85 Train Loss 0.018510677 Test MSE 0.010656797683024029 Test RE 0.04934253078132956\n",
      "86 Train Loss 0.017118307 Test MSE 0.010648149229849213 Test RE 0.049322504916447865\n",
      "87 Train Loss 0.016522642 Test MSE 0.010557932280611668 Test RE 0.04911311682962445\n",
      "88 Train Loss 0.016110739 Test MSE 0.01011509038938484 Test RE 0.04807208338103598\n",
      "89 Train Loss 0.014757379 Test MSE 0.008281739605093286 Test RE 0.04349795562826249\n",
      "90 Train Loss 0.013323474 Test MSE 0.008549214520705775 Test RE 0.04419479946771131\n",
      "91 Train Loss 0.012654744 Test MSE 0.008408263745323894 Test RE 0.04382896581954532\n",
      "92 Train Loss 0.012097502 Test MSE 0.008248432993232989 Test RE 0.043410399803225926\n",
      "93 Train Loss 0.011729719 Test MSE 0.008004059458106992 Test RE 0.04276251242143548\n",
      "94 Train Loss 0.010867659 Test MSE 0.00786789512471345 Test RE 0.04239721616953837\n",
      "95 Train Loss 0.0103937 Test MSE 0.007475043890695043 Test RE 0.04132519711709409\n",
      "96 Train Loss 0.010199563 Test MSE 0.007006374517579826 Test RE 0.040008727114379805\n",
      "97 Train Loss 0.009859114 Test MSE 0.0065715287412004865 Test RE 0.03874728401583573\n",
      "98 Train Loss 0.009002105 Test MSE 0.005975101706884312 Test RE 0.03694713022843454\n",
      "99 Train Loss 0.008390244 Test MSE 0.005332107161060216 Test RE 0.03490257707162298\n",
      "Training time: 148.84\n",
      "3\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 66.178635 Test MSE 5.404295476425714 Test RE 1.1111625689551712\n",
      "1 Train Loss 47.866795 Test MSE 8.37066116646573 Test RE 1.3828909725593095\n",
      "2 Train Loss 38.036133 Test MSE 8.290685449044446 Test RE 1.3762688470422575\n",
      "3 Train Loss 32.182484 Test MSE 8.62615135919653 Test RE 1.4038367180156923\n",
      "4 Train Loss 29.819113 Test MSE 8.46612500625916 Test RE 1.3907542592178874\n",
      "5 Train Loss 27.384384 Test MSE 8.862364367845421 Test RE 1.4229277894251071\n",
      "6 Train Loss 24.979378 Test MSE 8.786681303710216 Test RE 1.4168389831850026\n",
      "7 Train Loss 23.292616 Test MSE 8.76746773126046 Test RE 1.415289055773184\n",
      "8 Train Loss 21.819197 Test MSE 8.787480972328348 Test RE 1.4169034543917884\n",
      "9 Train Loss 20.447216 Test MSE 8.862276437930163 Test RE 1.422920730460642\n",
      "10 Train Loss 19.11018 Test MSE 9.055762656150273 Test RE 1.4383698662061233\n",
      "11 Train Loss 17.85918 Test MSE 8.940064956482804 Test RE 1.4291519210791952\n",
      "12 Train Loss 16.354616 Test MSE 8.969858282606712 Test RE 1.4315313094844568\n",
      "13 Train Loss 14.785374 Test MSE 8.50568251626341 Test RE 1.393999584664275\n",
      "14 Train Loss 13.375444 Test MSE 8.33752298881677 Test RE 1.380150930235752\n",
      "15 Train Loss 11.713152 Test MSE 8.134937395492946 Test RE 1.3632803276242174\n",
      "16 Train Loss 10.625938 Test MSE 8.313982078040532 Test RE 1.3782011319451493\n",
      "17 Train Loss 9.148465 Test MSE 7.716389583675682 Test RE 1.3277464023519305\n",
      "18 Train Loss 8.316544 Test MSE 7.653452966323045 Test RE 1.3223206163516885\n",
      "19 Train Loss 7.6732683 Test MSE 7.6767071797428175 Test RE 1.3243279589245607\n",
      "20 Train Loss 7.208583 Test MSE 7.69272819152532 Test RE 1.3257091510852042\n",
      "21 Train Loss 6.754331 Test MSE 7.725798080381274 Test RE 1.3285556080025962\n",
      "22 Train Loss 6.2235312 Test MSE 7.576645629048607 Test RE 1.3156687150738013\n",
      "23 Train Loss 5.851209 Test MSE 7.6106024401361365 Test RE 1.3186136838120017\n",
      "24 Train Loss 5.4621277 Test MSE 7.452832692666027 Test RE 1.304874506213482\n",
      "25 Train Loss 4.6829004 Test MSE 7.100936415312509 Test RE 1.2736962559237528\n",
      "26 Train Loss 3.9284883 Test MSE 7.044383307142172 Test RE 1.2686141463448466\n",
      "27 Train Loss 3.5143137 Test MSE 7.012705927841948 Test RE 1.2657585627253127\n",
      "28 Train Loss 3.3281434 Test MSE 7.009431272091078 Test RE 1.2654629986740706\n",
      "29 Train Loss 3.091618 Test MSE 7.009576361219642 Test RE 1.265476095597806\n",
      "30 Train Loss 2.9280615 Test MSE 7.072085158232475 Test RE 1.271106094661561\n",
      "31 Train Loss 2.7935796 Test MSE 7.086439799023168 Test RE 1.2723954613392188\n",
      "32 Train Loss 2.7136302 Test MSE 7.109094737043155 Test RE 1.2744277257123107\n",
      "33 Train Loss 2.6245315 Test MSE 7.133745604420564 Test RE 1.2766353599826938\n",
      "34 Train Loss 2.523112 Test MSE 7.143802616948191 Test RE 1.2775349306021784\n",
      "35 Train Loss 2.4583814 Test MSE 7.100860530744303 Test RE 1.273689450191172\n",
      "36 Train Loss 2.3924594 Test MSE 7.06767746515688 Test RE 1.2707099230485268\n",
      "37 Train Loss 2.3159428 Test MSE 7.138852189369716 Test RE 1.277092208391465\n",
      "38 Train Loss 2.2524674 Test MSE 7.142710799903633 Test RE 1.2774373013852403\n",
      "39 Train Loss 2.1771066 Test MSE 7.107817183281411 Test RE 1.2743132088047915\n",
      "40 Train Loss 2.1131177 Test MSE 7.1579156031081235 Test RE 1.2787962292275135\n",
      "41 Train Loss 2.0499167 Test MSE 7.151508296456842 Test RE 1.278223752932334\n",
      "42 Train Loss 2.0002291 Test MSE 7.154386476370157 Test RE 1.278480942583531\n",
      "43 Train Loss 1.9579148 Test MSE 7.18143188459567 Test RE 1.2808951554041685\n",
      "44 Train Loss 1.9173436 Test MSE 7.179276108628385 Test RE 1.28070288662708\n",
      "45 Train Loss 1.8953298 Test MSE 7.167684997571995 Test RE 1.2796686064424148\n",
      "46 Train Loss 1.8696826 Test MSE 7.1990932264581 Test RE 1.282469245074634\n",
      "47 Train Loss 1.8482597 Test MSE 7.212841433620528 Test RE 1.283693235546923\n",
      "48 Train Loss 1.8217785 Test MSE 7.238036268118995 Test RE 1.2859332850942833\n",
      "49 Train Loss 1.8025573 Test MSE 7.22218191515567 Test RE 1.2845241448205325\n",
      "50 Train Loss 1.781018 Test MSE 7.253048493062924 Test RE 1.287266154918046\n",
      "51 Train Loss 1.7480992 Test MSE 7.247647730201553 Test RE 1.2867868037927388\n",
      "52 Train Loss 1.7066522 Test MSE 7.184894642732476 Test RE 1.281203930565628\n",
      "53 Train Loss 1.6771263 Test MSE 7.150452620450163 Test RE 1.2781294064048099\n",
      "54 Train Loss 1.6566062 Test MSE 7.0665038004767675 Test RE 1.2706044110693004\n",
      "55 Train Loss 1.6326247 Test MSE 7.043998032641246 Test RE 1.268579454069887\n",
      "56 Train Loss 1.6167125 Test MSE 6.994647351737531 Test RE 1.2641277705636171\n",
      "57 Train Loss 1.5939225 Test MSE 6.932004564969513 Test RE 1.2584543906058407\n",
      "58 Train Loss 1.5764991 Test MSE 6.9284015667054435 Test RE 1.258127299194277\n",
      "59 Train Loss 1.5594591 Test MSE 6.88153177039404 Test RE 1.2538645383997626\n",
      "60 Train Loss 1.5453807 Test MSE 6.833587202175858 Test RE 1.2494889813768735\n",
      "61 Train Loss 1.5260712 Test MSE 6.825165282538145 Test RE 1.2487187899881629\n",
      "62 Train Loss 1.5040916 Test MSE 6.723732066817165 Test RE 1.2394050454230792\n",
      "63 Train Loss 1.4736677 Test MSE 6.726881593634999 Test RE 1.2396952921471842\n",
      "64 Train Loss 1.4501324 Test MSE 6.61203329906512 Test RE 1.2290670513169004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 1.4226178 Test MSE 6.489834292194418 Test RE 1.2176567041498354\n",
      "66 Train Loss 1.4110286 Test MSE 6.441371520874632 Test RE 1.213101765222008\n",
      "67 Train Loss 1.3860991 Test MSE 6.491209586014301 Test RE 1.217785717230433\n",
      "68 Train Loss 1.373389 Test MSE 6.48202463781175 Test RE 1.2169238394756987\n",
      "69 Train Loss 1.3647664 Test MSE 6.4699696158789335 Test RE 1.2157917186151592\n",
      "70 Train Loss 1.3512449 Test MSE 6.457772120201559 Test RE 1.2146451436632206\n",
      "71 Train Loss 1.3316791 Test MSE 6.436310609950268 Test RE 1.212625111582027\n",
      "72 Train Loss 1.317531 Test MSE 6.373887473951674 Test RE 1.2067304074507992\n",
      "73 Train Loss 1.3040624 Test MSE 6.331767589192285 Test RE 1.2027366443243663\n",
      "74 Train Loss 1.2953894 Test MSE 6.286205123790615 Test RE 1.198401473709663\n",
      "75 Train Loss 1.2826937 Test MSE 6.245975695388428 Test RE 1.1945606519128207\n",
      "76 Train Loss 1.2756658 Test MSE 6.203523205218558 Test RE 1.190494150493753\n",
      "77 Train Loss 1.2666727 Test MSE 6.195073958046413 Test RE 1.1896831430734418\n",
      "78 Train Loss 1.2588378 Test MSE 6.197859044025722 Test RE 1.1899505327409634\n",
      "79 Train Loss 1.2511666 Test MSE 6.173630551177331 Test RE 1.187622394990565\n",
      "80 Train Loss 1.2421598 Test MSE 6.143930995205576 Test RE 1.184762296663582\n",
      "81 Train Loss 1.232197 Test MSE 6.113478539363438 Test RE 1.1818225062367809\n",
      "82 Train Loss 1.2226046 Test MSE 6.098185249564488 Test RE 1.180343375212246\n",
      "83 Train Loss 1.2141774 Test MSE 6.049857732436887 Test RE 1.1756570195542182\n",
      "84 Train Loss 1.2077 Test MSE 6.024484187154595 Test RE 1.173189033394789\n",
      "85 Train Loss 1.1989082 Test MSE 6.021458299904706 Test RE 1.1728943705247519\n",
      "86 Train Loss 1.189515 Test MSE 5.982744953616049 Test RE 1.1691178863489518\n",
      "87 Train Loss 1.1799672 Test MSE 5.944858922110328 Test RE 1.1654102586117103\n",
      "88 Train Loss 1.1674116 Test MSE 5.845187157137121 Test RE 1.1555993023438245\n",
      "89 Train Loss 1.1570113 Test MSE 5.8290122073956745 Test RE 1.1539992928715332\n",
      "90 Train Loss 1.1471374 Test MSE 5.802881803124558 Test RE 1.1514098028182163\n",
      "91 Train Loss 1.1399744 Test MSE 5.777572424912289 Test RE 1.1488961111807163\n",
      "92 Train Loss 1.13284 Test MSE 5.766876123000068 Test RE 1.1478321147635027\n",
      "93 Train Loss 1.1241171 Test MSE 5.746938518428286 Test RE 1.1458462183718152\n",
      "94 Train Loss 1.1176739 Test MSE 5.734831972944377 Test RE 1.1446386577842882\n",
      "95 Train Loss 1.1086533 Test MSE 5.747261888878965 Test RE 1.1458784553267343\n",
      "96 Train Loss 1.1004515 Test MSE 5.738722377863931 Test RE 1.1450268429059904\n",
      "97 Train Loss 1.0920364 Test MSE 5.710372447135976 Test RE 1.142195060877909\n",
      "98 Train Loss 1.0835128 Test MSE 5.695636286219415 Test RE 1.140720337182289\n",
      "99 Train Loss 1.075163 Test MSE 5.719935611818814 Test RE 1.1431510782134544\n",
      "Training time: 148.88\n",
      "4\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 58.025143 Test MSE 7.541589709558349 Test RE 1.3126214925738595\n",
      "1 Train Loss 49.493275 Test MSE 7.344642861842984 Test RE 1.2953687080089662\n",
      "2 Train Loss 41.116364 Test MSE 7.304574030224763 Test RE 1.2918304219368282\n",
      "3 Train Loss 33.639248 Test MSE 6.717774390668091 Test RE 1.2388558258673725\n",
      "4 Train Loss 25.268826 Test MSE 6.241929382619943 Test RE 1.1941736548016522\n",
      "5 Train Loss 22.674925 Test MSE 6.223105047548758 Test RE 1.1923716079018365\n",
      "6 Train Loss 18.761436 Test MSE 6.227247855510822 Test RE 1.1927684310880793\n",
      "7 Train Loss 15.418304 Test MSE 5.832195246649054 Test RE 1.154314331131513\n",
      "8 Train Loss 13.570354 Test MSE 6.270208257523725 Test RE 1.1968756819602357\n",
      "9 Train Loss 12.381521 Test MSE 6.055674421874476 Test RE 1.1762220567122974\n",
      "10 Train Loss 11.3622265 Test MSE 5.736847148484078 Test RE 1.1448397487000197\n",
      "11 Train Loss 10.248285 Test MSE 5.488170099518036 Test RE 1.119751987488028\n",
      "12 Train Loss 9.4742775 Test MSE 5.2466901486974065 Test RE 1.0948402843909968\n",
      "13 Train Loss 8.747084 Test MSE 4.97722782348555 Test RE 1.0663550264132193\n",
      "14 Train Loss 8.07541 Test MSE 4.914245194299631 Test RE 1.0595866334658761\n",
      "15 Train Loss 7.514518 Test MSE 4.698959397837849 Test RE 1.036117255491941\n",
      "16 Train Loss 6.6350193 Test MSE 4.3598491023445165 Test RE 0.9980304443952207\n",
      "17 Train Loss 5.631163 Test MSE 3.7287051114287895 Test RE 0.9229689252181205\n",
      "18 Train Loss 4.694599 Test MSE 3.7084967368228665 Test RE 0.9204644308302119\n",
      "19 Train Loss 4.301472 Test MSE 3.5435260117394907 Test RE 0.8997583233156213\n",
      "20 Train Loss 3.8165345 Test MSE 3.3946241525511893 Test RE 0.8806511543794994\n",
      "21 Train Loss 3.345993 Test MSE 3.285157039013586 Test RE 0.8663355333975886\n",
      "22 Train Loss 3.100313 Test MSE 3.1713405158764156 Test RE 0.851195851386832\n",
      "23 Train Loss 2.8737392 Test MSE 2.951044186067854 Test RE 0.8210997433931728\n",
      "24 Train Loss 2.7501297 Test MSE 2.9417293106502806 Test RE 0.8198028317931593\n",
      "25 Train Loss 2.568087 Test MSE 2.740188310736505 Test RE 0.791221837130188\n",
      "26 Train Loss 2.475104 Test MSE 2.6368279569697517 Test RE 0.7761558900854773\n",
      "27 Train Loss 2.325908 Test MSE 2.6134435498013553 Test RE 0.7727066007758753\n",
      "28 Train Loss 2.1754658 Test MSE 2.4428603120595014 Test RE 0.7470632574495859\n",
      "29 Train Loss 2.0374734 Test MSE 2.328074061535696 Test RE 0.7293004076983762\n",
      "30 Train Loss 1.9470385 Test MSE 2.2455863540733914 Test RE 0.7162636978914904\n",
      "31 Train Loss 1.8460046 Test MSE 1.9829718496606858 Test RE 0.6730794555736002\n",
      "32 Train Loss 1.721264 Test MSE 1.6921081815899648 Test RE 0.6217590608845576\n",
      "33 Train Loss 1.648063 Test MSE 1.5235346457868233 Test RE 0.5899758404663064\n",
      "34 Train Loss 1.5538824 Test MSE 1.2892774392122315 Test RE 0.542726780181699\n",
      "35 Train Loss 1.4765778 Test MSE 1.1460821200447446 Test RE 0.5117006031358435\n",
      "36 Train Loss 1.2971044 Test MSE 0.8594249521309713 Test RE 0.4431104983121285\n",
      "37 Train Loss 1.0212871 Test MSE 0.5306549023831157 Test RE 0.3481882815715551\n",
      "38 Train Loss 0.81177247 Test MSE 0.38550031901564724 Test RE 0.2967702968918155\n",
      "39 Train Loss 0.6215334 Test MSE 0.31507115422387655 Test RE 0.2682948783619621\n",
      "40 Train Loss 0.49295866 Test MSE 0.22604750563870246 Test RE 0.22725210767662543\n",
      "41 Train Loss 0.43585134 Test MSE 0.1925623274657826 Test RE 0.20974601751302654\n",
      "42 Train Loss 0.34182075 Test MSE 0.16426231400435676 Test RE 0.19372114555749764\n",
      "43 Train Loss 0.28753608 Test MSE 0.14812060117976636 Test RE 0.18395677757722814\n",
      "44 Train Loss 0.24372397 Test MSE 0.14367617005031483 Test RE 0.1811759017476857\n",
      "45 Train Loss 0.22038431 Test MSE 0.09809418700772932 Test RE 0.14970272175758073\n",
      "46 Train Loss 0.19980282 Test MSE 0.10561191777497296 Test RE 0.15533328424963638\n",
      "47 Train Loss 0.18006055 Test MSE 0.10085894097111978 Test RE 0.15179772476243125\n",
      "48 Train Loss 0.16167347 Test MSE 0.0749845110385776 Test RE 0.13088619491479137\n",
      "49 Train Loss 0.14134818 Test MSE 0.07969104340993227 Test RE 0.13493133487676795\n",
      "50 Train Loss 0.12792172 Test MSE 0.06185198315859827 Test RE 0.11887345207396639\n",
      "51 Train Loss 0.113940395 Test MSE 0.06734068686759853 Test RE 0.12403573691302418\n",
      "52 Train Loss 0.1035934 Test MSE 0.06528657130140153 Test RE 0.1221293345677127\n",
      "53 Train Loss 0.098677814 Test MSE 0.06203403066066304 Test RE 0.11904826227178639\n",
      "54 Train Loss 0.09158898 Test MSE 0.06335586993282137 Test RE 0.12030993427851105\n",
      "55 Train Loss 0.08575065 Test MSE 0.05581963794251073 Test RE 0.11292798211531328\n",
      "56 Train Loss 0.08091714 Test MSE 0.05238760442235308 Test RE 0.1094012615455089\n",
      "57 Train Loss 0.076449275 Test MSE 0.05201250827246721 Test RE 0.10900890049746283\n",
      "58 Train Loss 0.06923469 Test MSE 0.048710604056405205 Test RE 0.10549207088102816\n",
      "59 Train Loss 0.06535282 Test MSE 0.04812989384355236 Test RE 0.10486136631996823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Train Loss 0.06276417 Test MSE 0.04842174273979819 Test RE 0.1051788137341615\n",
      "61 Train Loss 0.05917572 Test MSE 0.04253493729569564 Test RE 0.09857821699992189\n",
      "62 Train Loss 0.05409709 Test MSE 0.04243348868440303 Test RE 0.09846058906848928\n",
      "63 Train Loss 0.051665246 Test MSE 0.04346709318757854 Test RE 0.09965253694046022\n",
      "64 Train Loss 0.046667367 Test MSE 0.03721951790647882 Test RE 0.09221327193639035\n",
      "65 Train Loss 0.04347567 Test MSE 0.03383813137849937 Test RE 0.0879247711093698\n",
      "66 Train Loss 0.042500883 Test MSE 0.03257616159553923 Test RE 0.08626964593240198\n",
      "67 Train Loss 0.040267028 Test MSE 0.030957910898365883 Test RE 0.08409959091161325\n",
      "68 Train Loss 0.03865192 Test MSE 0.02996722123213372 Test RE 0.08274300653513814\n",
      "69 Train Loss 0.036629513 Test MSE 0.02505236948460081 Test RE 0.07565409917251525\n",
      "70 Train Loss 0.0346825 Test MSE 0.021553977209818977 Test RE 0.0701732789315019\n",
      "71 Train Loss 0.033452526 Test MSE 0.02216333872530802 Test RE 0.07115831444410554\n",
      "72 Train Loss 0.03178047 Test MSE 0.019690007451996207 Test RE 0.06707041607701059\n",
      "73 Train Loss 0.03083895 Test MSE 0.020491932808644732 Test RE 0.06842259194854378\n",
      "74 Train Loss 0.0290338 Test MSE 0.020693914180387806 Test RE 0.0687589731245849\n",
      "75 Train Loss 0.026789324 Test MSE 0.01919831374408343 Test RE 0.0662276892977423\n",
      "76 Train Loss 0.026158005 Test MSE 0.018173242283053396 Test RE 0.06443536138077409\n",
      "77 Train Loss 0.025904376 Test MSE 0.017338307546835206 Test RE 0.06293777874944531\n",
      "78 Train Loss 0.025578734 Test MSE 0.016961354344190396 Test RE 0.06224985209417756\n",
      "79 Train Loss 0.024710272 Test MSE 0.017578057956229676 Test RE 0.06337142986098852\n",
      "80 Train Loss 0.02400339 Test MSE 0.01866021462012207 Test RE 0.06529296302159764\n",
      "81 Train Loss 0.023182249 Test MSE 0.017641660974046784 Test RE 0.06348597535748549\n",
      "82 Train Loss 0.022458613 Test MSE 0.017840158164911118 Test RE 0.06384213621438524\n",
      "83 Train Loss 0.022036353 Test MSE 0.01720506552961011 Test RE 0.06269547914916257\n",
      "84 Train Loss 0.02155158 Test MSE 0.017242571602018884 Test RE 0.06276377825149246\n",
      "85 Train Loss 0.021113124 Test MSE 0.017559119191501205 Test RE 0.06333728217390376\n",
      "86 Train Loss 0.020642215 Test MSE 0.01664776924922805 Test RE 0.061671723291477014\n",
      "87 Train Loss 0.019971933 Test MSE 0.01649833491229765 Test RE 0.06139430932540592\n",
      "88 Train Loss 0.019645395 Test MSE 0.01638757579389978 Test RE 0.06118788150269535\n",
      "89 Train Loss 0.018629441 Test MSE 0.016721363597563033 Test RE 0.061807888241216274\n",
      "90 Train Loss 0.017883075 Test MSE 0.014903007538227679 Test RE 0.05835055898503337\n",
      "91 Train Loss 0.017188331 Test MSE 0.013877877650684354 Test RE 0.056307933296423474\n",
      "92 Train Loss 0.016781818 Test MSE 0.012724760522788753 Test RE 0.05391788761587996\n",
      "93 Train Loss 0.016519248 Test MSE 0.012274186224743093 Test RE 0.05295468809250958\n",
      "94 Train Loss 0.016029358 Test MSE 0.011778457026532295 Test RE 0.05187430141418161\n",
      "95 Train Loss 0.015595375 Test MSE 0.011445962646420556 Test RE 0.05113687945847192\n",
      "96 Train Loss 0.015258585 Test MSE 0.011893831116280923 Test RE 0.05212774570955657\n",
      "97 Train Loss 0.014909845 Test MSE 0.011471220547592047 Test RE 0.05119327045505291\n",
      "98 Train Loss 0.0147333 Test MSE 0.010855060607350437 Test RE 0.04979940875115926\n",
      "99 Train Loss 0.014464489 Test MSE 0.01054524487389926 Test RE 0.04908359848344232\n",
      "Training time: 148.54\n",
      "5\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 70.54661 Test MSE 4.672173694128796 Test RE 1.033159920557319\n",
      "1 Train Loss 48.87908 Test MSE 6.076276618797195 Test RE 1.1782211885168181\n",
      "2 Train Loss 33.752117 Test MSE 5.434663676572881 Test RE 1.1142801571755307\n",
      "3 Train Loss 28.083015 Test MSE 5.884036316490053 Test RE 1.1594332012163413\n",
      "4 Train Loss 24.537304 Test MSE 5.8430259806114 Test RE 1.1553856492211254\n",
      "5 Train Loss 21.952885 Test MSE 6.023304116638783 Test RE 1.173074126163945\n",
      "6 Train Loss 20.355083 Test MSE 5.982330585996897 Test RE 1.1690773988313214\n",
      "7 Train Loss 19.382582 Test MSE 5.5802835347267346 Test RE 1.1291098428032451\n",
      "8 Train Loss 18.260183 Test MSE 5.096196474696843 Test RE 1.0790240927183925\n",
      "9 Train Loss 17.619795 Test MSE 4.870181866878414 Test RE 1.0548255723873206\n",
      "10 Train Loss 16.485098 Test MSE 4.996549304086324 Test RE 1.0684228040770778\n",
      "11 Train Loss 15.282886 Test MSE 4.56320782534034 Test RE 1.0210410070644254\n",
      "12 Train Loss 14.050451 Test MSE 4.209003796628717 Test RE 0.9806131639944419\n",
      "13 Train Loss 13.1371765 Test MSE 4.087042239022735 Test RE 0.9663014324367977\n",
      "14 Train Loss 12.4320545 Test MSE 4.11868509392834 Test RE 0.9700348880179516\n",
      "15 Train Loss 11.646202 Test MSE 4.122422987617719 Test RE 0.9704749635411459\n",
      "16 Train Loss 11.043194 Test MSE 4.020636766137419 Test RE 0.9584191443259774\n",
      "17 Train Loss 10.738664 Test MSE 3.9732000633256415 Test RE 0.9527485075591409\n",
      "18 Train Loss 10.27774 Test MSE 3.874674411598751 Test RE 0.9408614350555266\n",
      "19 Train Loss 9.647888 Test MSE 3.805682803874464 Test RE 0.9324474255412573\n",
      "20 Train Loss 8.334695 Test MSE 3.4044286792517573 Test RE 0.881922008206187\n",
      "21 Train Loss 7.0847573 Test MSE 2.922616553157459 Test RE 0.8171353147644733\n",
      "22 Train Loss 6.2899647 Test MSE 2.75630784199726 Test RE 0.7935456597459918\n",
      "23 Train Loss 5.8575788 Test MSE 2.625592167830773 Test RE 0.7745004855845958\n",
      "24 Train Loss 5.541792 Test MSE 2.537017882548812 Test RE 0.7613245325124487\n",
      "25 Train Loss 4.841139 Test MSE 2.11928589492165 Test RE 0.6958294955115029\n",
      "26 Train Loss 3.8011875 Test MSE 1.8606246227105243 Test RE 0.6519847568926262\n",
      "27 Train Loss 3.4823081 Test MSE 1.8018740070152 Test RE 0.6416087388176921\n",
      "28 Train Loss 2.926503 Test MSE 1.5575176741385026 Test RE 0.5965193721283802\n",
      "29 Train Loss 2.6252806 Test MSE 1.3812239391659835 Test RE 0.5617461553117089\n",
      "30 Train Loss 2.453684 Test MSE 1.2222573074040484 Test RE 0.5284323314358536\n",
      "31 Train Loss 2.2267332 Test MSE 1.249401765744484 Test RE 0.534267944756665\n",
      "32 Train Loss 2.0689037 Test MSE 1.2770012341842443 Test RE 0.5401367398291965\n",
      "33 Train Loss 1.9703739 Test MSE 1.3054165081195694 Test RE 0.5461131202491817\n",
      "34 Train Loss 1.8270166 Test MSE 1.0983762827690413 Test RE 0.5009376032935279\n",
      "35 Train Loss 1.6902385 Test MSE 0.9355824790089188 Test RE 0.46232683309833744\n",
      "36 Train Loss 1.5852203 Test MSE 0.9220603871150126 Test RE 0.45897363887033304\n",
      "37 Train Loss 1.4106627 Test MSE 0.7087490826563634 Test RE 0.40239661170010055\n",
      "38 Train Loss 1.2948265 Test MSE 0.738294688320368 Test RE 0.4106983255703153\n",
      "39 Train Loss 1.1809652 Test MSE 0.675399442650565 Test RE 0.3928153128387295\n",
      "40 Train Loss 1.0588945 Test MSE 0.6282719949652515 Test RE 0.3788627533026639\n",
      "41 Train Loss 0.9583751 Test MSE 0.5383039734628343 Test RE 0.35068876534137317\n",
      "42 Train Loss 0.8535614 Test MSE 0.5802632186975101 Test RE 0.36409991842066197\n",
      "43 Train Loss 0.8158477 Test MSE 0.5816096633624979 Test RE 0.36452210297201\n",
      "44 Train Loss 0.78804964 Test MSE 0.5721226694735383 Test RE 0.3615369071704185\n",
      "45 Train Loss 0.75198895 Test MSE 0.5714604826859889 Test RE 0.3613276213921074\n",
      "46 Train Loss 0.72778684 Test MSE 0.5824481613492187 Test RE 0.3647847713773874\n",
      "47 Train Loss 0.6643121 Test MSE 0.5648765108367504 Test RE 0.3592401079652401\n",
      "48 Train Loss 0.6422602 Test MSE 0.5099284780977534 Test RE 0.3413207519010502\n",
      "49 Train Loss 0.6052805 Test MSE 0.46635181360822775 Test RE 0.326411082160419\n",
      "50 Train Loss 0.57469016 Test MSE 0.4220677157217515 Test RE 0.31052682813009685\n",
      "51 Train Loss 0.529535 Test MSE 0.35281822628686366 Test RE 0.28391188060698264\n",
      "52 Train Loss 0.5080162 Test MSE 0.33277648956571404 Test RE 0.2757302269749447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 0.49157017 Test MSE 0.321205237481476 Test RE 0.27089398961569516\n",
      "54 Train Loss 0.4688505 Test MSE 0.29726008147823424 Test RE 0.26060116719757537\n",
      "55 Train Loss 0.43841538 Test MSE 0.26828049408840055 Test RE 0.24757261789663712\n",
      "56 Train Loss 0.42163303 Test MSE 0.25326228449648125 Test RE 0.24054333076739717\n",
      "57 Train Loss 0.3809144 Test MSE 0.21524574084758327 Test RE 0.22175598179179506\n",
      "58 Train Loss 0.35034353 Test MSE 0.1970103916985798 Test RE 0.2121546853954537\n",
      "59 Train Loss 0.33255017 Test MSE 0.1699559856918874 Test RE 0.19704993348237085\n",
      "60 Train Loss 0.3061717 Test MSE 0.15325146590196145 Test RE 0.1871157647702762\n",
      "61 Train Loss 0.2849673 Test MSE 0.10492414031798104 Test RE 0.15482666891039917\n",
      "62 Train Loss 0.26320297 Test MSE 0.060213643988177405 Test RE 0.11728852251914972\n",
      "63 Train Loss 0.24775943 Test MSE 0.05778774766190164 Test RE 0.11490156504315577\n",
      "64 Train Loss 0.2350751 Test MSE 0.05203356310461173 Test RE 0.10903096184340617\n",
      "65 Train Loss 0.22394753 Test MSE 0.053342641598351115 Test RE 0.11039396183351559\n",
      "66 Train Loss 0.20013714 Test MSE 0.04245913112177314 Test RE 0.09849033430337699\n",
      "67 Train Loss 0.18320398 Test MSE 0.040409840091365966 Test RE 0.09608412205004987\n",
      "68 Train Loss 0.1569348 Test MSE 0.034845322916109284 Test RE 0.08922371604473421\n",
      "69 Train Loss 0.14738727 Test MSE 0.03758976567893681 Test RE 0.09267079089885862\n",
      "70 Train Loss 0.14304295 Test MSE 0.031970740422474886 Test RE 0.08546423458812402\n",
      "71 Train Loss 0.13074808 Test MSE 0.030351909802967147 Test RE 0.08327239809841848\n",
      "72 Train Loss 0.12199692 Test MSE 0.030703879748739626 Test RE 0.08375383239106546\n",
      "73 Train Loss 0.11880536 Test MSE 0.030483354689794545 Test RE 0.08345251700936672\n",
      "74 Train Loss 0.10704372 Test MSE 0.029131983510687173 Test RE 0.08158176332467802\n",
      "75 Train Loss 0.10071137 Test MSE 0.027633470428844634 Test RE 0.07945583124995499\n",
      "76 Train Loss 0.09664902 Test MSE 0.026972715564759726 Test RE 0.07850013373149692\n",
      "77 Train Loss 0.094431564 Test MSE 0.02608933429441463 Test RE 0.07720395680746994\n",
      "78 Train Loss 0.093553945 Test MSE 0.024726767894621308 Test RE 0.07516085925231918\n",
      "79 Train Loss 0.0912611 Test MSE 0.02338451530754749 Test RE 0.07309240410316405\n",
      "80 Train Loss 0.08261938 Test MSE 0.01939645923150311 Test RE 0.06656857943334607\n",
      "81 Train Loss 0.076287955 Test MSE 0.018098493881499693 Test RE 0.06430271022720102\n",
      "82 Train Loss 0.07332492 Test MSE 0.01643322212169602 Test RE 0.06127303930493493\n",
      "83 Train Loss 0.07061454 Test MSE 0.01646364602055671 Test RE 0.061329732469615\n",
      "84 Train Loss 0.069178954 Test MSE 0.015435720417063328 Test RE 0.05938428230625834\n",
      "85 Train Loss 0.068313375 Test MSE 0.01586219003955175 Test RE 0.060199049572326774\n",
      "86 Train Loss 0.06596441 Test MSE 0.015966925980703903 Test RE 0.060397465760138026\n",
      "87 Train Loss 0.062788665 Test MSE 0.01515407726878757 Test RE 0.05884001963043223\n",
      "88 Train Loss 0.058219634 Test MSE 0.0130969895342106 Test RE 0.054700815438318326\n",
      "89 Train Loss 0.056094997 Test MSE 0.011561703357866293 Test RE 0.051394775277660315\n",
      "90 Train Loss 0.055062734 Test MSE 0.011106965414827202 Test RE 0.05037392254425128\n",
      "91 Train Loss 0.054255296 Test MSE 0.010910707174209675 Test RE 0.049926889556114434\n",
      "92 Train Loss 0.053445563 Test MSE 0.01083237845568567 Test RE 0.049747352458427284\n",
      "93 Train Loss 0.052234236 Test MSE 0.010800788891649597 Test RE 0.04967476246525191\n",
      "94 Train Loss 0.048329663 Test MSE 0.009672730330327884 Test RE 0.0470091718428585\n",
      "95 Train Loss 0.046119027 Test MSE 0.007456930276682661 Test RE 0.041275096896696756\n",
      "96 Train Loss 0.044011947 Test MSE 0.007618715485900905 Test RE 0.04172044557477174\n",
      "97 Train Loss 0.04323471 Test MSE 0.0077703241228182455 Test RE 0.04213350878496591\n",
      "98 Train Loss 0.04223066 Test MSE 0.007353545790994587 Test RE 0.04098797483092037\n",
      "99 Train Loss 0.0416409 Test MSE 0.007080427202862285 Test RE 0.040219604094325026\n",
      "Training time: 148.85\n",
      "6\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "1 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "2 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "3 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "4 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "5 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "6 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "7 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "8 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "9 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "10 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "11 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "12 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "13 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "14 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "15 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "16 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "17 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "18 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "19 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "20 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "21 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "22 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "23 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "24 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "25 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "26 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "27 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "28 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "29 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "30 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "31 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "32 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "33 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "34 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "35 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "36 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "37 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "38 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "39 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "40 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "41 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "42 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "43 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "44 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "45 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "46 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "47 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "49 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "50 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "51 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "52 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "53 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "54 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "55 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "56 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "57 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "58 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "59 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "60 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "61 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "62 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "63 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "64 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "65 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "66 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "67 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "68 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "69 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "70 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "71 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "72 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "73 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "74 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "75 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "76 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "77 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "78 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "79 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "80 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "81 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "82 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "83 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "84 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "85 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "86 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "87 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "88 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "89 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "90 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "91 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "92 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "93 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "94 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "95 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "96 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "97 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "98 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "99 Train Loss 72.36151 Test MSE 5.090895369316613 Test RE 1.07846274184339\n",
      "Training time: 64.12\n",
      "7\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 56.511856 Test MSE 6.50467435183748 Test RE 1.2190480940561008\n",
      "1 Train Loss 42.821625 Test MSE 7.8281414834121055 Test RE 1.3373263242923397\n",
      "2 Train Loss 33.65248 Test MSE 6.9604725003053245 Test RE 1.2610358150419185\n",
      "3 Train Loss 26.861933 Test MSE 6.222694449684793 Test RE 1.1923322711633888\n",
      "4 Train Loss 23.143122 Test MSE 6.660169903015983 Test RE 1.233532835311417\n",
      "5 Train Loss 20.047972 Test MSE 6.337992590559177 Test RE 1.2033277271346399\n",
      "6 Train Loss 18.195286 Test MSE 6.420821402592925 Test RE 1.2111651202295066\n",
      "7 Train Loss 15.4234295 Test MSE 6.037799144690657 Test RE 1.1744847742474758\n",
      "8 Train Loss 13.154189 Test MSE 6.02642486542382 Test RE 1.1733779789597174\n",
      "9 Train Loss 11.952934 Test MSE 5.909649398022892 Test RE 1.1619539546958786\n",
      "10 Train Loss 11.237406 Test MSE 5.895938364592779 Test RE 1.1606052417742936\n",
      "11 Train Loss 10.588908 Test MSE 5.7623305601500485 Test RE 1.1473796538943073\n",
      "12 Train Loss 10.119462 Test MSE 5.701023027745737 Test RE 1.1412596371928503\n",
      "13 Train Loss 9.515066 Test MSE 5.627397953675014 Test RE 1.1338663698556606\n",
      "14 Train Loss 9.143764 Test MSE 5.489316336736125 Test RE 1.1198689148399574\n",
      "15 Train Loss 8.462719 Test MSE 5.604836947609639 Test RE 1.1315911746961929\n",
      "16 Train Loss 7.911088 Test MSE 5.465312394161772 Test RE 1.1174177243071073\n",
      "17 Train Loss 7.4411926 Test MSE 5.379866736131718 Test RE 1.1086483609340154\n",
      "18 Train Loss 6.6852584 Test MSE 5.266249525277108 Test RE 1.096879138602003\n",
      "19 Train Loss 6.061304 Test MSE 5.270838346997021 Test RE 1.097356925192929\n",
      "20 Train Loss 5.5891967 Test MSE 5.2414429434846 Test RE 1.09429267355853\n",
      "21 Train Loss 5.1116424 Test MSE 5.074109509866968 Test RE 1.0766833032843726\n",
      "22 Train Loss 4.9274707 Test MSE 5.034672515506923 Test RE 1.0724910425924512\n",
      "23 Train Loss 4.5884333 Test MSE 4.850918375105663 Test RE 1.0527373796708026\n",
      "24 Train Loss 4.3022137 Test MSE 4.804140138506148 Test RE 1.0476492200412217\n",
      "25 Train Loss 4.03565 Test MSE 4.6396801183321665 Test RE 1.029560992582147\n",
      "26 Train Loss 3.8155699 Test MSE 4.299716906571524 Test RE 0.9911239974589913\n",
      "27 Train Loss 3.6489167 Test MSE 3.992466165578884 Test RE 0.9550556594569777\n",
      "28 Train Loss 3.5031033 Test MSE 3.9133847026013506 Test RE 0.9455496360224277\n",
      "29 Train Loss 3.32435 Test MSE 3.697287618328734 Test RE 0.9190723029984945\n",
      "30 Train Loss 3.1360655 Test MSE 3.486007681612427 Test RE 0.8924260320605797\n",
      "31 Train Loss 2.9511642 Test MSE 3.379911881803051 Test RE 0.8787407150576106\n",
      "32 Train Loss 2.7800555 Test MSE 3.070838475647673 Test RE 0.8375997653028877\n",
      "33 Train Loss 2.6130688 Test MSE 2.839475715760477 Test RE 0.8054287720058687\n",
      "34 Train Loss 2.3880408 Test MSE 2.7996828601184642 Test RE 0.799765157069626\n",
      "35 Train Loss 2.17885 Test MSE 2.5001865280675686 Test RE 0.7557780344219992\n",
      "36 Train Loss 2.0461981 Test MSE 2.401180457927475 Test RE 0.740662676756052\n",
      "37 Train Loss 1.8763962 Test MSE 2.10863349120459 Test RE 0.694078529662962\n",
      "38 Train Loss 1.7503443 Test MSE 1.9275996783364442 Test RE 0.6636154413471369\n",
      "39 Train Loss 1.6527672 Test MSE 1.766037130641432 Test RE 0.6351963230505029\n",
      "40 Train Loss 1.5644284 Test MSE 1.5292836096182 Test RE 0.5910879110584274\n",
      "41 Train Loss 1.4527413 Test MSE 1.3920145937228725 Test RE 0.5639361752110214\n",
      "42 Train Loss 1.3089728 Test MSE 1.0316079184888545 Test RE 0.48547334939317843\n",
      "43 Train Loss 1.1567737 Test MSE 0.9017445485094423 Test RE 0.4538891727300324\n",
      "44 Train Loss 0.98585415 Test MSE 0.8161519966364286 Test RE 0.4318108832585893\n",
      "45 Train Loss 0.8807611 Test MSE 0.737584609506465 Test RE 0.4105007768550404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 0.7060688 Test MSE 0.5073481439134189 Test RE 0.34045608300726504\n",
      "47 Train Loss 0.59229195 Test MSE 0.4430876494245562 Test RE 0.3181653513723583\n",
      "48 Train Loss 0.48103976 Test MSE 0.3664976264270334 Test RE 0.2893634298055258\n",
      "49 Train Loss 0.42668504 Test MSE 0.3083773076025894 Test RE 0.265429547358687\n",
      "50 Train Loss 0.3933944 Test MSE 0.30820701342982404 Test RE 0.2653562486007727\n",
      "51 Train Loss 0.3574889 Test MSE 0.2901606972072843 Test RE 0.2574704270399655\n",
      "52 Train Loss 0.30967 Test MSE 0.23961681627404563 Test RE 0.23397351903527122\n",
      "53 Train Loss 0.26951194 Test MSE 0.2468548333110846 Test RE 0.23748100477694867\n",
      "54 Train Loss 0.25373113 Test MSE 0.2423483673101605 Test RE 0.23530334954376225\n",
      "55 Train Loss 0.23185697 Test MSE 0.2032671450663454 Test RE 0.21549721108890732\n",
      "56 Train Loss 0.22048697 Test MSE 0.17099404774666976 Test RE 0.19765079101928854\n",
      "57 Train Loss 0.19506904 Test MSE 0.17526778626330378 Test RE 0.20010553931522682\n",
      "58 Train Loss 0.1783611 Test MSE 0.1421055051894563 Test RE 0.18018287478377867\n",
      "59 Train Loss 0.15686633 Test MSE 0.0762030425470157 Test RE 0.13194538847754275\n",
      "60 Train Loss 0.14502575 Test MSE 0.07332532921035206 Test RE 0.1294300357227691\n",
      "61 Train Loss 0.13632293 Test MSE 0.06527471808595789 Test RE 0.12211824736403319\n",
      "62 Train Loss 0.11660894 Test MSE 0.054700319964646985 Test RE 0.11179000964779862\n",
      "63 Train Loss 0.10665537 Test MSE 0.04414415246486267 Test RE 0.10042565010834831\n",
      "64 Train Loss 0.101211965 Test MSE 0.04110773959747237 Test RE 0.09691028229774978\n",
      "65 Train Loss 0.09820104 Test MSE 0.03882635389558772 Test RE 0.0941827494772521\n",
      "66 Train Loss 0.09298487 Test MSE 0.03705945512807515 Test RE 0.09201477641130418\n",
      "67 Train Loss 0.08230816 Test MSE 0.03354356344652046 Test RE 0.08754123293162323\n",
      "68 Train Loss 0.07718999 Test MSE 0.03352880305481868 Test RE 0.08752197014415916\n",
      "69 Train Loss 0.07386249 Test MSE 0.03257531319444485 Test RE 0.08626852253825448\n",
      "70 Train Loss 0.07194117 Test MSE 0.03305900696609641 Test RE 0.08690664056036357\n",
      "71 Train Loss 0.06964549 Test MSE 0.03182135416159355 Test RE 0.08526433100154844\n",
      "72 Train Loss 0.066108994 Test MSE 0.027250229542422025 Test RE 0.07890293218597179\n",
      "73 Train Loss 0.061859366 Test MSE 0.025804984119171866 Test RE 0.0767820774397173\n",
      "74 Train Loss 0.052664902 Test MSE 0.019725802426573374 Test RE 0.06713135291827588\n",
      "75 Train Loss 0.049781766 Test MSE 0.01876846480369959 Test RE 0.06548207537789186\n",
      "76 Train Loss 0.04841072 Test MSE 0.016769775002371694 Test RE 0.06189729614337858\n",
      "77 Train Loss 0.044114135 Test MSE 0.017207609465559506 Test RE 0.06270011404543123\n",
      "78 Train Loss 0.04156129 Test MSE 0.014832137253528868 Test RE 0.05821165250076338\n",
      "79 Train Loss 0.039265256 Test MSE 0.013348494975517999 Test RE 0.05522353601229713\n",
      "80 Train Loss 0.03672115 Test MSE 0.011742817166578807 Test RE 0.05179575999333206\n",
      "81 Train Loss 0.035431124 Test MSE 0.010773869198744217 Test RE 0.049612819600442074\n",
      "82 Train Loss 0.034633487 Test MSE 0.010087507692359771 Test RE 0.04800649509518845\n",
      "83 Train Loss 0.033862293 Test MSE 0.010842218906217851 Test RE 0.04976994330660282\n",
      "84 Train Loss 0.03258624 Test MSE 0.010678932475058708 Test RE 0.049393747860986555\n",
      "85 Train Loss 0.03040981 Test MSE 0.011173300684878068 Test RE 0.05052412528539086\n",
      "86 Train Loss 0.029373283 Test MSE 0.00955518057031952 Test RE 0.04672265458388828\n",
      "87 Train Loss 0.028875008 Test MSE 0.009685415879768261 Test RE 0.047039987432712836\n",
      "88 Train Loss 0.02812306 Test MSE 0.010201014492921536 Test RE 0.04827582925382826\n",
      "89 Train Loss 0.024601819 Test MSE 0.008143077754803019 Test RE 0.04313227357381537\n",
      "90 Train Loss 0.020890974 Test MSE 0.006885647324582086 Test RE 0.039662533114311636\n",
      "91 Train Loss 0.019776084 Test MSE 0.005718390364399064 Test RE 0.036144727908229875\n",
      "92 Train Loss 0.019296903 Test MSE 0.005650083875421254 Test RE 0.03592820398177886\n",
      "93 Train Loss 0.01883748 Test MSE 0.0059371753663195245 Test RE 0.03682968451778419\n",
      "94 Train Loss 0.018376159 Test MSE 0.00617370652681653 Test RE 0.03755614877374125\n",
      "95 Train Loss 0.017607512 Test MSE 0.0065545854636724615 Test RE 0.03869730099637538\n",
      "96 Train Loss 0.01703067 Test MSE 0.006506031188419748 Test RE 0.03855370595355203\n",
      "97 Train Loss 0.016434094 Test MSE 0.006172395898739582 Test RE 0.03755216212848412\n",
      "98 Train Loss 0.016148686 Test MSE 0.006127040770275524 Test RE 0.03741393999511863\n",
      "99 Train Loss 0.01575446 Test MSE 0.006124443921273062 Test RE 0.03740601050245354\n",
      "Training time: 150.76\n",
      "8\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 73.279465 Test MSE 5.1708808909254484 Test RE 1.0869018484144448\n",
      "1 Train Loss 50.514767 Test MSE 6.722919243506031 Test RE 1.2393301281188922\n",
      "2 Train Loss 37.191803 Test MSE 6.620905079256004 Test RE 1.229891333124652\n",
      "3 Train Loss 25.297176 Test MSE 4.718697161563221 Test RE 1.038291056683308\n",
      "4 Train Loss 19.91796 Test MSE 4.221665698329054 Test RE 0.9820870404810792\n",
      "5 Train Loss 16.717249 Test MSE 4.2578326804965965 Test RE 0.9862848356300458\n",
      "6 Train Loss 14.61677 Test MSE 4.013787461790777 Test RE 0.9576024450198282\n",
      "7 Train Loss 13.307339 Test MSE 3.403633537724675 Test RE 0.8818190109297656\n",
      "8 Train Loss 12.606643 Test MSE 3.371290322717758 Test RE 0.8776192431427065\n",
      "9 Train Loss 11.684345 Test MSE 3.167008800307572 Test RE 0.850614331013361\n",
      "10 Train Loss 10.964144 Test MSE 3.067625631887717 Test RE 0.8371614841218078\n",
      "11 Train Loss 10.475838 Test MSE 3.1873938038683356 Test RE 0.853347503555094\n",
      "12 Train Loss 9.983821 Test MSE 3.2228648600429795 Test RE 0.8580826244055481\n",
      "13 Train Loss 9.510652 Test MSE 3.257723233484166 Test RE 0.8627106371057093\n",
      "14 Train Loss 9.00193 Test MSE 3.1801285072500542 Test RE 0.8523743951017658\n",
      "15 Train Loss 8.570326 Test MSE 3.2872286189513584 Test RE 0.8666086406572837\n",
      "16 Train Loss 8.0912695 Test MSE 3.398446802288354 Test RE 0.8811468607615945\n",
      "17 Train Loss 7.612152 Test MSE 3.328584563792296 Test RE 0.8720429144391083\n",
      "18 Train Loss 7.3914986 Test MSE 3.331457724463206 Test RE 0.8724191973475153\n",
      "19 Train Loss 7.207913 Test MSE 3.3331417766691276 Test RE 0.8726396734832002\n",
      "20 Train Loss 7.0190125 Test MSE 3.3744860337965785 Test RE 0.8780351007145792\n",
      "21 Train Loss 6.812646 Test MSE 3.4532602454871304 Test RE 0.8882244316472614\n",
      "22 Train Loss 6.5360146 Test MSE 3.461712416625706 Test RE 0.8893107727000505\n",
      "23 Train Loss 6.154482 Test MSE 3.3589409322645785 Test RE 0.8760103626955899\n",
      "24 Train Loss 5.80432 Test MSE 3.2185642993360535 Test RE 0.8575099245787804\n",
      "25 Train Loss 5.2379146 Test MSE 2.778110778240458 Test RE 0.7966780285268708\n",
      "26 Train Loss 4.909716 Test MSE 2.5207787043376277 Test RE 0.7588840427486897\n",
      "27 Train Loss 4.041796 Test MSE 2.4343447343107694 Test RE 0.7457600251376917\n",
      "28 Train Loss 3.653821 Test MSE 2.4950397589375837 Test RE 0.7549997286986558\n",
      "29 Train Loss 3.167255 Test MSE 2.4479745237185413 Test RE 0.747844849838012\n",
      "30 Train Loss 2.8174334 Test MSE 2.508143322213191 Test RE 0.7569797034281633\n",
      "31 Train Loss 2.57236 Test MSE 2.5310970209920454 Test RE 0.7604356286021818\n",
      "32 Train Loss 2.2960944 Test MSE 2.494330123959721 Test RE 0.7548923531918612\n",
      "33 Train Loss 2.1832366 Test MSE 2.5890683883474717 Test RE 0.7690947049789724\n",
      "34 Train Loss 1.9586203 Test MSE 2.781803759630551 Test RE 0.7972073702752777\n",
      "35 Train Loss 1.8757391 Test MSE 2.768115609251388 Test RE 0.7952435812725679\n",
      "36 Train Loss 1.7357569 Test MSE 2.7799407850817213 Test RE 0.7969403805972742\n",
      "37 Train Loss 1.6485182 Test MSE 2.8497700084380493 Test RE 0.8068874599911439\n",
      "38 Train Loss 1.5681224 Test MSE 2.8195111314210304 Test RE 0.8025922597230033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 1.4967625 Test MSE 2.8863918159639317 Test RE 0.8120554819889962\n",
      "40 Train Loss 1.440605 Test MSE 2.907817817850344 Test RE 0.8150638976556119\n",
      "41 Train Loss 1.354286 Test MSE 2.930708984817797 Test RE 0.8182658155475321\n",
      "42 Train Loss 1.2965279 Test MSE 3.009700849347038 Test RE 0.8292199186165707\n",
      "43 Train Loss 1.2536964 Test MSE 3.0036278233017075 Test RE 0.8283828890661536\n",
      "44 Train Loss 1.1895635 Test MSE 2.9653748394769632 Test RE 0.8230910122938769\n",
      "45 Train Loss 1.1610688 Test MSE 2.968519788540438 Test RE 0.8235273641006609\n",
      "46 Train Loss 1.1414881 Test MSE 2.936131282773914 Test RE 0.8190224295165272\n",
      "47 Train Loss 1.1017778 Test MSE 2.9669402080746914 Test RE 0.8233082311788537\n",
      "48 Train Loss 1.0684375 Test MSE 2.981023853952153 Test RE 0.8252599816614807\n",
      "49 Train Loss 1.0236245 Test MSE 3.0029850301564553 Test RE 0.8282942450387519\n",
      "50 Train Loss 0.99901193 Test MSE 3.0141224615848214 Test RE 0.829828806922001\n",
      "51 Train Loss 0.96203256 Test MSE 3.027088076474789 Test RE 0.8316116964935693\n",
      "52 Train Loss 0.9453525 Test MSE 3.0668417332388027 Test RE 0.83705451349292\n",
      "53 Train Loss 0.90787816 Test MSE 3.054875341067013 Test RE 0.8354198819517785\n",
      "54 Train Loss 0.8681268 Test MSE 3.0375172757676014 Test RE 0.8330430368524986\n",
      "55 Train Loss 0.85916483 Test MSE 3.066696397152407 Test RE 0.8370346794618567\n",
      "56 Train Loss 0.84124815 Test MSE 3.070466699395395 Test RE 0.8375490610522853\n",
      "57 Train Loss 0.80983675 Test MSE 3.096684294712189 Test RE 0.8411172234182333\n",
      "58 Train Loss 0.7995231 Test MSE 3.111703030980582 Test RE 0.8431544407832253\n",
      "59 Train Loss 0.789417 Test MSE 3.110257355828616 Test RE 0.8429585562432599\n",
      "60 Train Loss 0.7706903 Test MSE 3.083963303019948 Test RE 0.8393878161878802\n",
      "61 Train Loss 0.7564356 Test MSE 3.0723778077817805 Test RE 0.8378096725816666\n",
      "62 Train Loss 0.74962336 Test MSE 3.049546275674027 Test RE 0.8346908914118657\n",
      "63 Train Loss 0.7420477 Test MSE 3.0552050443839316 Test RE 0.8354649628869855\n",
      "64 Train Loss 0.7259661 Test MSE 3.067210388848205 Test RE 0.8371048218550177\n",
      "65 Train Loss 0.7012984 Test MSE 3.078863288780917 Test RE 0.8386934724639308\n",
      "66 Train Loss 0.6964884 Test MSE 3.077908952139081 Test RE 0.838563480017036\n",
      "67 Train Loss 0.6874903 Test MSE 3.064098855399352 Test RE 0.8366801133678103\n",
      "68 Train Loss 0.674331 Test MSE 3.0783217487238344 Test RE 0.838619710487227\n",
      "69 Train Loss 0.6663939 Test MSE 3.0552037712998894 Test RE 0.835464788820563\n",
      "70 Train Loss 0.66022724 Test MSE 3.0195680777651184 Test RE 0.8305780946482626\n",
      "71 Train Loss 0.652597 Test MSE 3.0443974978397286 Test RE 0.8339859581020087\n",
      "72 Train Loss 0.6438184 Test MSE 3.0341780054110172 Test RE 0.8325850113316671\n",
      "73 Train Loss 0.6382798 Test MSE 3.035646681933979 Test RE 0.8327864909615753\n",
      "74 Train Loss 0.6337382 Test MSE 3.035677711454976 Test RE 0.832790747204574\n",
      "75 Train Loss 0.6316496 Test MSE 3.04615989868983 Test RE 0.8342273202935229\n",
      "76 Train Loss 0.6298751 Test MSE 3.0604009739768703 Test RE 0.8361750908420307\n",
      "77 Train Loss 0.62407434 Test MSE 3.0613268278761723 Test RE 0.8363015640446456\n",
      "78 Train Loss 0.6166112 Test MSE 3.0699322806055136 Test RE 0.8374761696195456\n",
      "79 Train Loss 0.61113524 Test MSE 3.0652248227599923 Test RE 0.8368338270717484\n",
      "80 Train Loss 0.6088059 Test MSE 3.061997527565364 Test RE 0.8363931708073303\n",
      "81 Train Loss 0.60291976 Test MSE 3.0564266335652293 Test RE 0.8356319718024662\n",
      "82 Train Loss 0.59625536 Test MSE 3.048370490064647 Test RE 0.8345299638398666\n",
      "83 Train Loss 0.5909479 Test MSE 3.057692246411924 Test RE 0.8358049641929333\n",
      "84 Train Loss 0.58554816 Test MSE 3.0594324390989116 Test RE 0.8360427668701543\n",
      "85 Train Loss 0.5792991 Test MSE 3.062977188854675 Test RE 0.8365269587148212\n",
      "86 Train Loss 0.5666511 Test MSE 3.0643404389286446 Test RE 0.8367130960097323\n",
      "87 Train Loss 0.55960536 Test MSE 3.092080709081148 Test RE 0.8404917810144595\n",
      "88 Train Loss 0.55679214 Test MSE 3.089476045063197 Test RE 0.8401377055348088\n",
      "89 Train Loss 0.55191076 Test MSE 3.0905366386226514 Test RE 0.8402818995935206\n",
      "90 Train Loss 0.548255 Test MSE 3.099391235050189 Test RE 0.8414847708606883\n",
      "91 Train Loss 0.5455682 Test MSE 3.0932310774635163 Test RE 0.8406481134892351\n",
      "92 Train Loss 0.54200447 Test MSE 3.110555260501731 Test RE 0.8429989251342428\n",
      "93 Train Loss 0.534428 Test MSE 3.116985378122891 Test RE 0.8438697959810691\n",
      "94 Train Loss 0.52973646 Test MSE 3.12070466983738 Test RE 0.8443731127836378\n",
      "95 Train Loss 0.52542293 Test MSE 3.147619560954287 Test RE 0.8480064939807374\n",
      "96 Train Loss 0.5214905 Test MSE 3.1393479560393724 Test RE 0.8468915261665415\n",
      "97 Train Loss 0.5168821 Test MSE 3.1297671691387725 Test RE 0.845598250080374\n",
      "98 Train Loss 0.5135997 Test MSE 3.131583228001145 Test RE 0.8458435452429469\n",
      "99 Train Loss 0.5089549 Test MSE 3.1379155279739477 Test RE 0.8466982934285289\n",
      "Training time: 150.62\n",
      "9\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 60.68991 Test MSE 6.524748893300633 Test RE 1.2209277407684516\n",
      "1 Train Loss 49.702496 Test MSE 8.53145081996731 Test RE 1.3961095764078413\n",
      "2 Train Loss 41.760265 Test MSE 9.14124933917966 Test RE 1.445143047280625\n",
      "3 Train Loss 34.895767 Test MSE 9.434353862507589 Test RE 1.4681287421852562\n",
      "4 Train Loss 30.743778 Test MSE 9.047704727335642 Test RE 1.4377297842012864\n",
      "5 Train Loss 27.936745 Test MSE 8.848175958817533 Test RE 1.4217882984453114\n",
      "6 Train Loss 25.437382 Test MSE 8.542327794455716 Test RE 1.3969992616188036\n",
      "7 Train Loss 23.887432 Test MSE 8.550160935108105 Test RE 1.397639624791353\n",
      "8 Train Loss 21.57227 Test MSE 8.626728873542872 Test RE 1.4038837101354524\n",
      "9 Train Loss 20.063414 Test MSE 8.43544658259041 Test RE 1.3882321566900082\n",
      "10 Train Loss 18.157991 Test MSE 8.240572129324253 Test RE 1.3721030914295735\n",
      "11 Train Loss 16.800539 Test MSE 8.253530495483414 Test RE 1.3731814892395664\n",
      "12 Train Loss 15.192404 Test MSE 8.01307726465474 Test RE 1.3530309327188876\n",
      "13 Train Loss 12.507969 Test MSE 7.3342610914960105 Test RE 1.2944528720469777\n",
      "14 Train Loss 10.728607 Test MSE 6.984688915832719 Test RE 1.2632275665466088\n",
      "15 Train Loss 9.094381 Test MSE 6.732811053522016 Test RE 1.2402415411245626\n",
      "16 Train Loss 8.150988 Test MSE 6.508865523690441 Test RE 1.219440766850758\n",
      "17 Train Loss 7.2713623 Test MSE 6.335718335761484 Test RE 1.2031118133921583\n",
      "18 Train Loss 6.750513 Test MSE 6.132535384602969 Test RE 1.183663052874549\n",
      "19 Train Loss 6.093902 Test MSE 6.052236000456433 Test RE 1.1758880789345905\n",
      "20 Train Loss 5.3229184 Test MSE 5.730249166466565 Test RE 1.1441812157987217\n",
      "21 Train Loss 4.53056 Test MSE 5.647650548695007 Test RE 1.1359048885881793\n",
      "22 Train Loss 3.8983 Test MSE 5.329548309586052 Test RE 1.1034515317974412\n",
      "23 Train Loss 3.2898588 Test MSE 5.363027839148877 Test RE 1.1069119753204755\n",
      "24 Train Loss 2.8766344 Test MSE 5.179866652798843 Test RE 1.0878458270181874\n",
      "25 Train Loss 2.696161 Test MSE 5.1800102809585535 Test RE 1.087860908893994\n",
      "26 Train Loss 2.4970038 Test MSE 5.181218759159023 Test RE 1.0879877985578181\n",
      "27 Train Loss 2.3391256 Test MSE 5.240106764919824 Test RE 1.094153182999551\n",
      "28 Train Loss 2.225683 Test MSE 5.214002657141117 Test RE 1.0914244645072195\n",
      "29 Train Loss 2.0583937 Test MSE 5.1623702034162795 Test RE 1.0860070210584973\n",
      "30 Train Loss 1.9711597 Test MSE 5.18917549426209 Test RE 1.088822882937831\n",
      "31 Train Loss 1.9106455 Test MSE 5.18801127078092 Test RE 1.0887007340264232\n",
      "32 Train Loss 1.8458464 Test MSE 5.1706104259789445 Test RE 1.0868734226296872\n",
      "33 Train Loss 1.7928494 Test MSE 5.228554493471044 Test RE 1.0929464395777453\n",
      "34 Train Loss 1.7486274 Test MSE 5.252659856605455 Test RE 1.0954629644462275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 1.7128175 Test MSE 5.272022169095251 Test RE 1.0974801506039344\n",
      "36 Train Loss 1.681864 Test MSE 5.251469669362629 Test RE 1.0953388482892912\n",
      "37 Train Loss 1.6341031 Test MSE 5.262062996859869 Test RE 1.096443057034142\n",
      "38 Train Loss 1.6098993 Test MSE 5.291322237962486 Test RE 1.0994871691353112\n",
      "39 Train Loss 1.5598123 Test MSE 5.309532350743339 Test RE 1.1013774895278856\n",
      "40 Train Loss 1.5445135 Test MSE 5.3265683466501255 Test RE 1.1031429967911863\n",
      "41 Train Loss 1.5274975 Test MSE 5.335831160744714 Test RE 1.1041017538528504\n",
      "42 Train Loss 1.5030253 Test MSE 5.3814026993216855 Test RE 1.1088066103510141\n",
      "43 Train Loss 1.4828253 Test MSE 5.351472944399089 Test RE 1.1057188854758433\n",
      "44 Train Loss 1.4683598 Test MSE 5.346881288493829 Test RE 1.105244420760621\n",
      "45 Train Loss 1.4450271 Test MSE 5.388114937866976 Test RE 1.1094979036387742\n",
      "46 Train Loss 1.4163852 Test MSE 5.410391745994665 Test RE 1.1117891110584217\n",
      "47 Train Loss 1.3937169 Test MSE 5.397272564266205 Test RE 1.1104403532654603\n",
      "48 Train Loss 1.3757387 Test MSE 5.3935627357761815 Test RE 1.1100586557184235\n",
      "49 Train Loss 1.359711 Test MSE 5.375018326863714 Test RE 1.1081486838189099\n",
      "50 Train Loss 1.3431828 Test MSE 5.395244982447059 Test RE 1.1102317552986818\n",
      "51 Train Loss 1.3273005 Test MSE 5.410746320625808 Test RE 1.111825541484713\n",
      "52 Train Loss 1.3138626 Test MSE 5.449094243976512 Test RE 1.115758540750449\n",
      "53 Train Loss 1.292982 Test MSE 5.462844094532992 Test RE 1.11716536606679\n",
      "54 Train Loss 1.278293 Test MSE 5.479835662451117 Test RE 1.1189014263609336\n",
      "55 Train Loss 1.2646922 Test MSE 5.479760650575148 Test RE 1.1188937681766906\n",
      "56 Train Loss 1.2522105 Test MSE 5.478269054219321 Test RE 1.1187414758084016\n",
      "57 Train Loss 1.2398739 Test MSE 5.472259463834842 Test RE 1.1181276849584953\n",
      "58 Train Loss 1.2250617 Test MSE 5.477557577513622 Test RE 1.1186688265521467\n",
      "59 Train Loss 1.2162102 Test MSE 5.487082365015626 Test RE 1.1196410166903652\n",
      "60 Train Loss 1.2049525 Test MSE 5.502725166810138 Test RE 1.1212358403564864\n",
      "61 Train Loss 1.1919458 Test MSE 5.525327612073555 Test RE 1.1235362188501574\n",
      "62 Train Loss 1.1827272 Test MSE 5.526339819316837 Test RE 1.1236391267226846\n",
      "63 Train Loss 1.1712077 Test MSE 5.521844781847143 Test RE 1.123182058607048\n",
      "64 Train Loss 1.1573224 Test MSE 5.577684585596868 Test RE 1.1288468775989144\n",
      "65 Train Loss 1.1430472 Test MSE 5.574572627445728 Test RE 1.1285319248334342\n",
      "66 Train Loss 1.1292071 Test MSE 5.593896270164739 Test RE 1.1304861986100234\n",
      "67 Train Loss 1.1174886 Test MSE 5.598876653009849 Test RE 1.130989336420203\n",
      "68 Train Loss 1.1039877 Test MSE 5.625368879341463 Test RE 1.133661931979024\n",
      "69 Train Loss 1.0956918 Test MSE 5.652083283719909 Test RE 1.1363505763770227\n",
      "70 Train Loss 1.0792255 Test MSE 5.643660400696233 Test RE 1.1355035509506366\n",
      "71 Train Loss 1.0694361 Test MSE 5.662843962847957 Test RE 1.1374317785503776\n",
      "72 Train Loss 1.0538539 Test MSE 5.7152605918080654 Test RE 1.142683822376399\n",
      "73 Train Loss 1.0404388 Test MSE 5.722901809700888 Test RE 1.1434474428105514\n",
      "74 Train Loss 1.0266477 Test MSE 5.770311850368918 Test RE 1.14817398538182\n",
      "75 Train Loss 1.0168233 Test MSE 5.784393019784355 Test RE 1.1495740640482306\n",
      "76 Train Loss 1.0075746 Test MSE 5.782606559626382 Test RE 1.1493965322963267\n",
      "77 Train Loss 0.99986315 Test MSE 5.7914946644165815 Test RE 1.1502795280653182\n",
      "78 Train Loss 0.9929869 Test MSE 5.798163471417838 Test RE 1.150941601125119\n",
      "79 Train Loss 0.9875418 Test MSE 5.811528918185897 Test RE 1.1522673652367839\n",
      "80 Train Loss 0.97986585 Test MSE 5.804283197031622 Test RE 1.1515488269556218\n",
      "81 Train Loss 0.96879005 Test MSE 5.83173975481526 Test RE 1.1542692545355286\n",
      "82 Train Loss 0.9609592 Test MSE 5.824847131043079 Test RE 1.1535869284851976\n",
      "83 Train Loss 0.9546911 Test MSE 5.84164352003996 Test RE 1.155248958951375\n",
      "84 Train Loss 0.9473049 Test MSE 5.856516390546384 Test RE 1.1567186605616406\n",
      "85 Train Loss 0.9390752 Test MSE 5.86340799901065 Test RE 1.1573990401435388\n",
      "86 Train Loss 0.9303699 Test MSE 5.883206733356792 Test RE 1.1593514647958885\n",
      "87 Train Loss 0.924469 Test MSE 5.890826499150146 Test RE 1.1601020017480606\n",
      "88 Train Loss 0.9176574 Test MSE 5.904267507854379 Test RE 1.161424741154371\n",
      "89 Train Loss 0.9132639 Test MSE 5.903370763831958 Test RE 1.1613365388293835\n",
      "90 Train Loss 0.90858924 Test MSE 5.9113654503684865 Test RE 1.1621226473663675\n",
      "91 Train Loss 0.9024812 Test MSE 5.931215472048316 Test RE 1.1640721822918607\n",
      "92 Train Loss 0.8968321 Test MSE 5.949244202095181 Test RE 1.165840017182609\n",
      "93 Train Loss 0.89125943 Test MSE 5.925158293726068 Test RE 1.163477633507947\n",
      "94 Train Loss 0.88691896 Test MSE 5.943641212253017 Test RE 1.1652908946152392\n",
      "95 Train Loss 0.8828703 Test MSE 5.960370780564229 Test RE 1.1669297145057949\n",
      "96 Train Loss 0.8791361 Test MSE 5.977682159378439 Test RE 1.1686231087771521\n",
      "97 Train Loss 0.8756771 Test MSE 5.986096164220595 Test RE 1.169445278857344\n",
      "98 Train Loss 0.8725654 Test MSE 5.999745923312277 Test RE 1.1707778298695575\n",
      "99 Train Loss 0.866156 Test MSE 6.007081849936377 Test RE 1.171493369876591\n",
      "Training time: 149.53\n",
      "0\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 69.69715 Test MSE 4.343807412077188 Test RE 0.9961926687075219\n",
      "1 Train Loss 56.643993 Test MSE 5.109265326548271 Test RE 1.0804067490780107\n",
      "2 Train Loss 38.63501 Test MSE 6.964567572906732 Test RE 1.2614067147111918\n",
      "3 Train Loss 32.324665 Test MSE 6.997647441808028 Test RE 1.2643988414558767\n",
      "4 Train Loss 26.275112 Test MSE 6.554950302187944 Test RE 1.2237501610021984\n",
      "5 Train Loss 21.415367 Test MSE 6.657316124211513 Test RE 1.2332685322168278\n",
      "6 Train Loss 19.256245 Test MSE 6.093029929974219 Test RE 1.179844346921572\n",
      "7 Train Loss 16.873837 Test MSE 6.030099538446789 Test RE 1.1737356639399323\n",
      "8 Train Loss 14.1854725 Test MSE 5.44856023765585 Test RE 1.1157038677456663\n",
      "9 Train Loss 13.2896595 Test MSE 5.574089694683351 Test RE 1.128483040651591\n",
      "10 Train Loss 11.946758 Test MSE 5.387460944341888 Test RE 1.1094305678012208\n",
      "11 Train Loss 11.130951 Test MSE 5.318327724438244 Test RE 1.102289341794572\n",
      "12 Train Loss 10.407124 Test MSE 5.426546517308043 Test RE 1.113447707380457\n",
      "13 Train Loss 9.977953 Test MSE 5.304250600923282 Test RE 1.1008295460007427\n",
      "14 Train Loss 9.422217 Test MSE 5.310763949784581 Test RE 1.1015052198738764\n",
      "15 Train Loss 8.933252 Test MSE 5.288424548101675 Test RE 1.0991860715095851\n",
      "16 Train Loss 8.600376 Test MSE 5.138625061509495 Test RE 1.0835065114569018\n",
      "17 Train Loss 8.223734 Test MSE 5.116963323918731 Test RE 1.0812203531286733\n",
      "18 Train Loss 7.8095875 Test MSE 4.997775516337648 Test RE 1.068553897826261\n",
      "19 Train Loss 7.3113446 Test MSE 4.873976731796339 Test RE 1.055236454485706\n",
      "20 Train Loss 6.8382998 Test MSE 4.728488694602969 Test RE 1.0393677514068926\n",
      "21 Train Loss 6.1461735 Test MSE 4.759478582860758 Test RE 1.042768128350552\n",
      "22 Train Loss 5.3666635 Test MSE 4.560535026356583 Test RE 1.0207419370673902\n",
      "23 Train Loss 4.7335615 Test MSE 4.30126082867565 Test RE 0.9913019255574704\n",
      "24 Train Loss 4.367195 Test MSE 4.134471213599678 Test RE 0.9718920877685261\n",
      "25 Train Loss 3.7724257 Test MSE 4.192004517742755 Test RE 0.9786309155927803\n",
      "26 Train Loss 3.4454744 Test MSE 4.231308651156014 Test RE 0.9832080218634524\n",
      "27 Train Loss 3.1820898 Test MSE 4.265315408009176 Test RE 0.9871511051175755\n",
      "28 Train Loss 3.0503511 Test MSE 4.222643922290082 Test RE 0.9822008161205608\n",
      "29 Train Loss 2.8690517 Test MSE 4.134886974006184 Test RE 0.9719409530369906\n",
      "30 Train Loss 2.7384179 Test MSE 4.102437849192302 Test RE 0.9681197175978751\n",
      "31 Train Loss 2.6454473 Test MSE 4.140321599527484 Test RE 0.9725794711703798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 2.505568 Test MSE 4.203887720137588 Test RE 0.9800170113603968\n",
      "33 Train Loss 2.3597324 Test MSE 4.189750356584818 Test RE 0.9783677612444744\n",
      "34 Train Loss 2.2869563 Test MSE 4.11032372960773 Test RE 0.9690497513113082\n",
      "35 Train Loss 2.224626 Test MSE 4.049100180020401 Test RE 0.96180564398874\n",
      "36 Train Loss 2.1676311 Test MSE 3.99424526439121 Test RE 0.955268428842012\n",
      "37 Train Loss 2.0634747 Test MSE 3.8715095113183557 Test RE 0.9404771007066978\n",
      "38 Train Loss 1.9761847 Test MSE 3.746523170088473 Test RE 0.9251715550926731\n",
      "39 Train Loss 1.9185163 Test MSE 3.6343477947751137 Test RE 0.9112159289161174\n",
      "40 Train Loss 1.8162887 Test MSE 3.5028219725060743 Test RE 0.8945756917159464\n",
      "41 Train Loss 1.6906586 Test MSE 3.331412288712822 Test RE 0.8724132481265865\n",
      "42 Train Loss 1.6225082 Test MSE 3.3676529979772543 Test RE 0.8771456785180729\n",
      "43 Train Loss 1.5552802 Test MSE 3.3686235887248164 Test RE 0.8772720704217752\n",
      "44 Train Loss 1.4667785 Test MSE 3.253950596094874 Test RE 0.8622109572678576\n",
      "45 Train Loss 1.3765261 Test MSE 3.1925767375799103 Test RE 0.8540410242353211\n",
      "46 Train Loss 1.331849 Test MSE 3.16332462160688 Test RE 0.8501194275697445\n",
      "47 Train Loss 1.304211 Test MSE 3.131940787081921 Test RE 0.8458918323849437\n",
      "48 Train Loss 1.244662 Test MSE 3.0897576504576882 Test RE 0.8401759938910803\n",
      "49 Train Loss 1.1831392 Test MSE 3.142290166368834 Test RE 0.8472882884064743\n",
      "50 Train Loss 1.1510619 Test MSE 3.1491702855546913 Test RE 0.8482153601697777\n",
      "51 Train Loss 1.1061301 Test MSE 3.0819038461775463 Test RE 0.8391074996747316\n",
      "52 Train Loss 1.061305 Test MSE 3.058118850534742 Test RE 0.8358632672167733\n",
      "53 Train Loss 1.044595 Test MSE 3.0324201923018874 Test RE 0.8323438025305551\n",
      "54 Train Loss 1.0171846 Test MSE 3.1066050010790907 Test RE 0.8424634705133426\n",
      "55 Train Loss 0.98883826 Test MSE 3.08928354698307 Test RE 0.8401115316120701\n",
      "56 Train Loss 0.95366347 Test MSE 3.023955295598441 Test RE 0.831181261111795\n",
      "57 Train Loss 0.93776065 Test MSE 3.0369756543363713 Test RE 0.832968763352813\n",
      "58 Train Loss 0.91794604 Test MSE 3.065512373041287 Test RE 0.8368730780521987\n",
      "59 Train Loss 0.89592683 Test MSE 3.085901401054219 Test RE 0.8396515288534279\n",
      "60 Train Loss 0.8683772 Test MSE 3.0629451177936815 Test RE 0.8365225792539746\n",
      "61 Train Loss 0.85528326 Test MSE 3.0504272251798574 Test RE 0.8348114449901473\n",
      "62 Train Loss 0.8439734 Test MSE 3.081560174171154 Test RE 0.8390607127189579\n",
      "63 Train Loss 0.83078265 Test MSE 3.082086243473142 Test RE 0.8391323298903782\n",
      "64 Train Loss 0.8172182 Test MSE 3.0795424126453015 Test RE 0.8387859652597024\n",
      "65 Train Loss 0.8099009 Test MSE 3.07632706421555 Test RE 0.8383479629327708\n",
      "66 Train Loss 0.80266094 Test MSE 3.068763836915761 Test RE 0.8373167789905989\n",
      "67 Train Loss 0.7846123 Test MSE 3.05563579373066 Test RE 0.8355238563651697\n",
      "68 Train Loss 0.7759506 Test MSE 3.048835851698144 Test RE 0.8345936607244745\n",
      "69 Train Loss 0.7639644 Test MSE 3.04206448708326 Test RE 0.8336663429537533\n",
      "70 Train Loss 0.75418615 Test MSE 3.0319620812251102 Test RE 0.832280928605833\n",
      "71 Train Loss 0.7465659 Test MSE 3.0438150492463647 Test RE 0.833906175947389\n",
      "72 Train Loss 0.7405696 Test MSE 3.044345314859195 Test RE 0.8339788105367614\n",
      "73 Train Loss 0.73219925 Test MSE 3.033892028481443 Test RE 0.832545774062902\n",
      "74 Train Loss 0.7211024 Test MSE 2.988271346713541 Test RE 0.826262562510043\n",
      "75 Train Loss 0.7154606 Test MSE 2.980748545888356 Test RE 0.8252218729470341\n",
      "76 Train Loss 0.7117211 Test MSE 2.9778611890462727 Test RE 0.8248220929458031\n",
      "77 Train Loss 0.707098 Test MSE 2.9612717590553173 Test RE 0.8225213747540204\n",
      "78 Train Loss 0.69926524 Test MSE 2.9450099595593757 Test RE 0.820259830987135\n",
      "79 Train Loss 0.6909722 Test MSE 2.9646827883462477 Test RE 0.8229949613164103\n",
      "80 Train Loss 0.6826423 Test MSE 3.0074619442531363 Test RE 0.8289114344531386\n",
      "81 Train Loss 0.67802835 Test MSE 3.0062441017154398 Test RE 0.828743587637548\n",
      "82 Train Loss 0.6702459 Test MSE 3.007172155625481 Test RE 0.8288714979721128\n",
      "83 Train Loss 0.66503584 Test MSE 3.00605787700334 Test RE 0.8287179185765975\n",
      "84 Train Loss 0.65929717 Test MSE 3.0164627436253695 Test RE 0.8301509001111456\n",
      "85 Train Loss 0.6559897 Test MSE 3.0133853540272724 Test RE 0.8297273328621737\n",
      "86 Train Loss 0.6528693 Test MSE 3.0267389322955314 Test RE 0.8315637360859617\n",
      "87 Train Loss 0.6485018 Test MSE 3.0206453501475465 Test RE 0.8307262415072884\n",
      "88 Train Loss 0.6425133 Test MSE 3.0105860131533855 Test RE 0.8293418479272332\n",
      "89 Train Loss 0.63344365 Test MSE 3.014265843941114 Test RE 0.8298485442412704\n",
      "90 Train Loss 0.6258303 Test MSE 3.0007543263595946 Test RE 0.8279865474722327\n",
      "91 Train Loss 0.6204847 Test MSE 2.995772144456264 Test RE 0.8272989048270568\n",
      "92 Train Loss 0.6152255 Test MSE 2.995501034960774 Test RE 0.8272614697931988\n",
      "93 Train Loss 0.6115615 Test MSE 3.00415392548597 Test RE 0.8284554338338208\n",
      "94 Train Loss 0.60823244 Test MSE 3.0251100373661894 Test RE 0.8313399453537972\n",
      "95 Train Loss 0.6010414 Test MSE 3.0014886365198543 Test RE 0.8280878489579868\n",
      "96 Train Loss 0.59494174 Test MSE 3.0067864294342836 Test RE 0.8288183371149261\n",
      "97 Train Loss 0.58887297 Test MSE 3.0139071970628892 Test RE 0.8297991737711875\n",
      "98 Train Loss 0.58069307 Test MSE 3.008620034462349 Test RE 0.8290710144975725\n",
      "99 Train Loss 0.57732034 Test MSE 3.0140426555076076 Test RE 0.8298178210013792\n",
      "Training time: 149.62\n",
      "1\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 69.805466 Test MSE 5.151842207718838 Test RE 1.084899069475633\n",
      "1 Train Loss 62.22543 Test MSE 6.388960597311641 Test RE 1.208156417519341\n",
      "2 Train Loss 51.062416 Test MSE 7.310941784175268 Test RE 1.292393375112157\n",
      "3 Train Loss 41.763 Test MSE 10.231429853135687 Test RE 1.528889949770525\n",
      "4 Train Loss 36.873253 Test MSE 10.474513903370829 Test RE 1.5469454486952134\n",
      "5 Train Loss 32.83436 Test MSE 10.923833536608727 Test RE 1.5797763102967066\n",
      "6 Train Loss 30.424059 Test MSE 10.637381240303993 Test RE 1.5589257206962621\n",
      "7 Train Loss 28.57296 Test MSE 11.00748959503818 Test RE 1.5858138337914194\n",
      "8 Train Loss 27.213493 Test MSE 11.048100570726499 Test RE 1.5887364872823324\n",
      "9 Train Loss 25.934555 Test MSE 11.288737470485804 Test RE 1.6059452933076048\n",
      "10 Train Loss 24.678787 Test MSE 11.074539626347068 Test RE 1.5906363429135488\n",
      "11 Train Loss 23.430168 Test MSE 10.986752237526682 Test RE 1.5843193471834307\n",
      "12 Train Loss 22.719822 Test MSE 10.921374560019716 Test RE 1.5795984948995692\n",
      "13 Train Loss 21.826878 Test MSE 10.977075534477512 Test RE 1.5836214901303287\n",
      "14 Train Loss 20.997356 Test MSE 11.239833943226273 Test RE 1.602462989350904\n",
      "15 Train Loss 20.318558 Test MSE 11.083422945865115 Test RE 1.5912741707105316\n",
      "16 Train Loss 19.471123 Test MSE 10.882592378260789 Test RE 1.5767913959983562\n",
      "17 Train Loss 18.494968 Test MSE 10.47530596407021 Test RE 1.5470039359693246\n",
      "18 Train Loss 16.449928 Test MSE 9.052254415505644 Test RE 1.4380912239405474\n",
      "19 Train Loss 14.213759 Test MSE 8.138926080253992 Test RE 1.3636145053087192\n",
      "20 Train Loss 13.391379 Test MSE 8.046428816904667 Test RE 1.355843761234514\n",
      "21 Train Loss 12.245615 Test MSE 7.91541490670066 Test RE 1.3447603715938807\n",
      "22 Train Loss 11.721062 Test MSE 7.891619565529878 Test RE 1.3427375391004512\n",
      "23 Train Loss 11.350442 Test MSE 7.984075909478383 Test RE 1.3505802325463592\n",
      "24 Train Loss 10.89167 Test MSE 7.9309362871635 Test RE 1.3460781998667197\n",
      "25 Train Loss 10.257174 Test MSE 7.713978229708757 Test RE 1.3275389272959404\n",
      "26 Train Loss 10.001917 Test MSE 7.719186524295024 Test RE 1.3279870130253715\n",
      "27 Train Loss 9.791596 Test MSE 7.788264379061691 Test RE 1.3339157580632464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 9.668186 Test MSE 7.784919935929132 Test RE 1.3336293216882193\n",
      "29 Train Loss 9.528284 Test MSE 7.733371688432576 Test RE 1.3292066407253824\n",
      "30 Train Loss 9.425217 Test MSE 7.8420424863879585 Test RE 1.3385131916725819\n",
      "31 Train Loss 9.300513 Test MSE 7.793186640512041 Test RE 1.334337215572662\n",
      "32 Train Loss 9.14801 Test MSE 7.818818963767907 Test RE 1.336529777310283\n",
      "33 Train Loss 9.054181 Test MSE 7.9094088797792725 Test RE 1.3442500888249636\n",
      "34 Train Loss 8.918674 Test MSE 7.8103337758719 Test RE 1.3358043618210347\n",
      "35 Train Loss 8.827547 Test MSE 7.748137338082914 Test RE 1.3304749904712452\n",
      "36 Train Loss 8.7278385 Test MSE 7.846060385488729 Test RE 1.3388560438232842\n",
      "37 Train Loss 8.61316 Test MSE 7.920226948178241 Test RE 1.3451690715527964\n",
      "38 Train Loss 8.51268 Test MSE 7.98144823082877 Test RE 1.3503579661921685\n",
      "39 Train Loss 8.443172 Test MSE 7.876866637284687 Test RE 1.341481866728193\n",
      "40 Train Loss 8.368648 Test MSE 7.8456748565548535 Test RE 1.338823149984933\n",
      "41 Train Loss 8.308191 Test MSE 7.871932139318212 Test RE 1.3410616122740355\n",
      "42 Train Loss 8.244098 Test MSE 7.927816975640932 Test RE 1.345813461251455\n",
      "43 Train Loss 8.191253 Test MSE 7.868267238495968 Test RE 1.3407493998528095\n",
      "44 Train Loss 8.134981 Test MSE 7.897798652721367 Test RE 1.3432631136541116\n",
      "45 Train Loss 8.087453 Test MSE 7.854593523545386 Test RE 1.339583895656725\n",
      "46 Train Loss 8.010809 Test MSE 7.846147555290376 Test RE 1.3388634811539886\n",
      "47 Train Loss 7.9552965 Test MSE 7.860343173757269 Test RE 1.3400741011529835\n",
      "48 Train Loss 7.8653193 Test MSE 7.713128893305404 Test RE 1.32746584190847\n",
      "49 Train Loss 7.832014 Test MSE 7.690558859499149 Test RE 1.3255222144077743\n",
      "50 Train Loss 7.7513156 Test MSE 7.626144228774744 Test RE 1.31995938301111\n",
      "51 Train Loss 7.6564875 Test MSE 7.567392526068071 Test RE 1.3148650786160339\n",
      "52 Train Loss 7.5699778 Test MSE 7.5321676137762825 Test RE 1.3118012735481734\n",
      "53 Train Loss 7.489397 Test MSE 7.502398575166781 Test RE 1.3092064213004069\n",
      "54 Train Loss 7.4243298 Test MSE 7.51376864175434 Test RE 1.310198112715738\n",
      "55 Train Loss 7.3641157 Test MSE 7.470767732103854 Test RE 1.3064436352919284\n",
      "56 Train Loss 7.278202 Test MSE 7.466889974747029 Test RE 1.3061045316572106\n",
      "57 Train Loss 7.206093 Test MSE 7.451994844795124 Test RE 1.3048011571192202\n",
      "58 Train Loss 7.0741005 Test MSE 7.3413880802176195 Test RE 1.295081654605005\n",
      "59 Train Loss 7.0201626 Test MSE 7.33861057323844 Test RE 1.2948366438123087\n",
      "60 Train Loss 6.91936 Test MSE 7.301743082736012 Test RE 1.291580067947836\n",
      "61 Train Loss 6.7909813 Test MSE 7.352134168240388 Test RE 1.296029157460878\n",
      "62 Train Loss 6.6735487 Test MSE 7.31093454145036 Test RE 1.2923927349448374\n",
      "63 Train Loss 6.5964813 Test MSE 7.226606959619888 Test RE 1.2849175997437468\n",
      "64 Train Loss 6.2919073 Test MSE 7.212862899996893 Test RE 1.283695145766487\n",
      "65 Train Loss 6.1180143 Test MSE 7.2862326449549 Test RE 1.2902075448439778\n",
      "66 Train Loss 5.904703 Test MSE 7.212157156025089 Test RE 1.28363234252973\n",
      "67 Train Loss 5.564352 Test MSE 7.1796799593446785 Test RE 1.280738907355138\n",
      "68 Train Loss 5.116174 Test MSE 7.0406550552256455 Test RE 1.268278393810945\n",
      "69 Train Loss 4.467221 Test MSE 6.652817440356921 Test RE 1.232851770962914\n",
      "70 Train Loss 3.854195 Test MSE 6.675259353480678 Test RE 1.234929406427611\n",
      "71 Train Loss 3.3664453 Test MSE 6.626992870342574 Test RE 1.2304566335696434\n",
      "72 Train Loss 3.1709602 Test MSE 6.630776192657618 Test RE 1.230807814709386\n",
      "73 Train Loss 3.0377567 Test MSE 6.70486916608309 Test RE 1.2376652977668259\n",
      "74 Train Loss 2.9104195 Test MSE 6.686569544032703 Test RE 1.2359751617176156\n",
      "75 Train Loss 2.8059137 Test MSE 6.662551781053512 Test RE 1.2337533899044824\n",
      "76 Train Loss 2.7199545 Test MSE 6.609009566223744 Test RE 1.2287859883505288\n",
      "77 Train Loss 2.658765 Test MSE 6.592956683723139 Test RE 1.227292757821394\n",
      "78 Train Loss 2.5248036 Test MSE 6.651099150738338 Test RE 1.2326925502101427\n",
      "79 Train Loss 2.4535291 Test MSE 6.62632614919943 Test RE 1.2303947358051395\n",
      "80 Train Loss 2.4297333 Test MSE 6.595897712543906 Test RE 1.227566466651704\n",
      "81 Train Loss 2.3635712 Test MSE 6.666702274044597 Test RE 1.2341376186294968\n",
      "82 Train Loss 2.3068428 Test MSE 6.651051189854591 Test RE 1.2326881057469543\n",
      "83 Train Loss 2.2640557 Test MSE 6.671758413398094 Test RE 1.2346055253132084\n",
      "84 Train Loss 2.245398 Test MSE 6.660210120974326 Test RE 1.233536559698183\n",
      "85 Train Loss 2.204953 Test MSE 6.553632633109655 Test RE 1.2236271563479943\n",
      "86 Train Loss 2.177884 Test MSE 6.5661615651170315 Test RE 1.2247962347924888\n",
      "87 Train Loss 2.154312 Test MSE 6.616090705441461 Test RE 1.2294440956746393\n",
      "88 Train Loss 2.1265612 Test MSE 6.591050623789883 Test RE 1.2271153364636955\n",
      "89 Train Loss 2.0945683 Test MSE 6.532502758161395 Test RE 1.2216529869017543\n",
      "90 Train Loss 2.072483 Test MSE 6.54997371964193 Test RE 1.2232855312365385\n",
      "91 Train Loss 2.0533514 Test MSE 6.556484762740535 Test RE 1.2238933876004465\n",
      "92 Train Loss 2.0210767 Test MSE 6.527450005426219 Test RE 1.221180434131655\n",
      "93 Train Loss 1.9991546 Test MSE 6.539951003816168 Test RE 1.222349242202863\n",
      "94 Train Loss 1.9687164 Test MSE 6.5400039774782535 Test RE 1.2223541927127783\n",
      "95 Train Loss 1.9411006 Test MSE 6.525720608556957 Test RE 1.2210186523087692\n",
      "96 Train Loss 1.9305403 Test MSE 6.531162764264659 Test RE 1.2215276833569808\n",
      "97 Train Loss 1.9054327 Test MSE 6.526385483892728 Test RE 1.2210808526815642\n",
      "98 Train Loss 1.8854259 Test MSE 6.522516759243423 Test RE 1.220718881580388\n",
      "99 Train Loss 1.8768876 Test MSE 6.557930174675263 Test RE 1.2240282870691408\n",
      "Training time: 149.19\n",
      "2\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 57.85804 Test MSE 7.31168988838868 Test RE 1.292459496565836\n",
      "1 Train Loss 44.24837 Test MSE 8.625262028097671 Test RE 1.4037643504105295\n",
      "2 Train Loss 32.078136 Test MSE 6.718717653935718 Test RE 1.2389427985839923\n",
      "3 Train Loss 25.643518 Test MSE 6.785153556891856 Test RE 1.2450531765475723\n",
      "4 Train Loss 18.618423 Test MSE 6.148351699953713 Test RE 1.1851884523715046\n",
      "5 Train Loss 15.26145 Test MSE 5.9431337115241485 Test RE 1.165241144085074\n",
      "6 Train Loss 13.3863735 Test MSE 5.932396342008125 Test RE 1.164188056471852\n",
      "7 Train Loss 12.542255 Test MSE 5.993177068590609 Test RE 1.1701367380824932\n",
      "8 Train Loss 11.384571 Test MSE 6.1366533466134685 Test RE 1.1840603976260535\n",
      "9 Train Loss 10.787951 Test MSE 5.947823259186342 Test RE 1.1657007817623035\n",
      "10 Train Loss 9.904283 Test MSE 5.927728815704448 Test RE 1.1637299829288694\n",
      "11 Train Loss 9.093913 Test MSE 5.695614228143363 Test RE 1.1407181282877037\n",
      "12 Train Loss 8.570648 Test MSE 5.7242944357745635 Test RE 1.1435865591114325\n",
      "13 Train Loss 8.001376 Test MSE 5.721085332536358 Test RE 1.143265960489161\n",
      "14 Train Loss 7.676327 Test MSE 5.650982759650277 Test RE 1.1362399408839188\n",
      "15 Train Loss 7.4128213 Test MSE 5.598956790672404 Test RE 1.1309974304114714\n",
      "16 Train Loss 7.15845 Test MSE 5.474376427060721 Test RE 1.1183439399009731\n",
      "17 Train Loss 6.9300346 Test MSE 5.464071531372727 Test RE 1.1172908659790497\n",
      "18 Train Loss 6.7626085 Test MSE 5.38812326441569 Test RE 1.10949876092234\n",
      "19 Train Loss 6.5803576 Test MSE 5.351704095457604 Test RE 1.1057427653808298\n",
      "20 Train Loss 6.4316096 Test MSE 5.354959810665095 Test RE 1.1060790541708658\n",
      "21 Train Loss 6.273695 Test MSE 5.3505574625527785 Test RE 1.1056243032109867\n",
      "22 Train Loss 6.100727 Test MSE 5.258250393129901 Test RE 1.0960457736520608\n",
      "23 Train Loss 6.015691 Test MSE 5.271153127992179 Test RE 1.0973896924611544\n",
      "24 Train Loss 5.9310083 Test MSE 5.191131965990056 Test RE 1.089028122713938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 5.856645 Test MSE 5.166579545974934 Test RE 1.086449690211371\n",
      "26 Train Loss 5.7889395 Test MSE 5.147408746562173 Test RE 1.0844321594921886\n",
      "27 Train Loss 5.700852 Test MSE 5.111265723319546 Test RE 1.0806182306249257\n",
      "28 Train Loss 5.635649 Test MSE 5.067592313985619 Test RE 1.0759916340789621\n",
      "29 Train Loss 5.559419 Test MSE 5.063451540716584 Test RE 1.0755519432320988\n",
      "30 Train Loss 5.463064 Test MSE 4.92204106832323 Test RE 1.0604267554114049\n",
      "31 Train Loss 5.3941193 Test MSE 4.947842389343304 Test RE 1.063202499115402\n",
      "32 Train Loss 5.3463116 Test MSE 4.938367812232694 Test RE 1.062184053068246\n",
      "33 Train Loss 5.274555 Test MSE 4.860646185352225 Test RE 1.0537924067497868\n",
      "34 Train Loss 5.1899157 Test MSE 4.847971973215677 Test RE 1.052417619750371\n",
      "35 Train Loss 5.148139 Test MSE 4.874545159344589 Test RE 1.055297986168766\n",
      "36 Train Loss 5.101512 Test MSE 4.842468973240365 Test RE 1.0518201432601135\n",
      "37 Train Loss 5.0057244 Test MSE 4.8131249223457155 Test RE 1.048628428034669\n",
      "38 Train Loss 4.933765 Test MSE 4.815861373238224 Test RE 1.0489264789372754\n",
      "39 Train Loss 4.7536087 Test MSE 4.780702901735403 Test RE 1.0450905911953055\n",
      "40 Train Loss 4.5930834 Test MSE 4.832359373187963 Test RE 1.050721629598772\n",
      "41 Train Loss 4.4417257 Test MSE 4.848995550784828 Test RE 1.0525287150929759\n",
      "42 Train Loss 4.231378 Test MSE 4.556178162302271 Test RE 1.0202542424776102\n",
      "43 Train Loss 3.9249709 Test MSE 4.565862103573428 Test RE 1.0213379180357178\n",
      "44 Train Loss 3.7495096 Test MSE 4.550361356551053 Test RE 1.0196027626731827\n",
      "45 Train Loss 3.5336797 Test MSE 4.497105308966605 Test RE 1.0136186414923796\n",
      "46 Train Loss 3.3603954 Test MSE 4.370855553032188 Test RE 0.999289415586465\n",
      "47 Train Loss 3.2446558 Test MSE 4.264901255492716 Test RE 0.9871031788800257\n",
      "48 Train Loss 3.1450787 Test MSE 4.174960964364646 Test RE 0.9766394654219774\n",
      "49 Train Loss 3.0759528 Test MSE 4.095875768829443 Test RE 0.967345126720172\n",
      "50 Train Loss 2.9986799 Test MSE 3.976960845154881 Test RE 0.9531993068820434\n",
      "51 Train Loss 2.9137874 Test MSE 3.8302701134315953 Test RE 0.9354546996375162\n",
      "52 Train Loss 2.8493512 Test MSE 3.7986491476564903 Test RE 0.9315853531966723\n",
      "53 Train Loss 2.7924411 Test MSE 3.7379921491851276 Test RE 0.9241176238030276\n",
      "54 Train Loss 2.7242806 Test MSE 3.601061225345434 Test RE 0.9070334697818481\n",
      "55 Train Loss 2.6760023 Test MSE 3.503320382060028 Test RE 0.8946393331478832\n",
      "56 Train Loss 2.5996904 Test MSE 3.320928390174922 Test RE 0.8710394315084555\n",
      "57 Train Loss 2.5263693 Test MSE 3.2293861710151925 Test RE 0.858950330005573\n",
      "58 Train Loss 2.4809434 Test MSE 3.1064055676731677 Test RE 0.8424364284439736\n",
      "59 Train Loss 2.4291582 Test MSE 3.033206771233318 Test RE 0.832451746286181\n",
      "60 Train Loss 2.3669276 Test MSE 2.946451863387113 Test RE 0.8204606097743278\n",
      "61 Train Loss 2.3173575 Test MSE 2.885280921538354 Test RE 0.8118991978145512\n",
      "62 Train Loss 2.243574 Test MSE 2.8071314611377463 Test RE 0.8008283443773871\n",
      "63 Train Loss 2.1927931 Test MSE 2.8174332792884833 Test RE 0.802296468125999\n",
      "64 Train Loss 2.1207325 Test MSE 2.7245063836714065 Test RE 0.7889545319126111\n",
      "65 Train Loss 2.0321367 Test MSE 2.547149221531099 Test RE 0.7628431563632643\n",
      "66 Train Loss 1.9685289 Test MSE 2.2946066911907352 Test RE 0.7240393805037266\n",
      "67 Train Loss 1.8851231 Test MSE 2.230407406374998 Test RE 0.7138388158617566\n",
      "68 Train Loss 1.822017 Test MSE 2.135554081761201 Test RE 0.6984950734919328\n",
      "69 Train Loss 1.7251036 Test MSE 1.988065271753939 Test RE 0.6739433304544642\n",
      "70 Train Loss 1.5528457 Test MSE 1.653560873151315 Test RE 0.614636226634243\n",
      "71 Train Loss 1.4504646 Test MSE 1.608089259752695 Test RE 0.6061263102794084\n",
      "72 Train Loss 1.3027 Test MSE 1.4206318011477406 Test RE 0.5697034197400374\n",
      "73 Train Loss 1.18631 Test MSE 1.3947758369538072 Test RE 0.5644952187398375\n",
      "74 Train Loss 1.0262319 Test MSE 1.1402921396321672 Test RE 0.5104064166990979\n",
      "75 Train Loss 0.95681137 Test MSE 1.1478511248946095 Test RE 0.5120953618544329\n",
      "76 Train Loss 0.8873364 Test MSE 1.0598167440375095 Test RE 0.4920661027967859\n",
      "77 Train Loss 0.83380836 Test MSE 0.9455111505337594 Test RE 0.4647735319122968\n",
      "78 Train Loss 0.7865917 Test MSE 0.7976919543424164 Test RE 0.42689951964881384\n",
      "79 Train Loss 0.7239514 Test MSE 0.7514920587440855 Test RE 0.4143527810549694\n",
      "80 Train Loss 0.6897702 Test MSE 0.6940263709086952 Test RE 0.398195223871802\n",
      "81 Train Loss 0.620301 Test MSE 0.6394589932093403 Test RE 0.3822208817727862\n",
      "82 Train Loss 0.54578644 Test MSE 0.5154507917548017 Test RE 0.34316395605565947\n",
      "83 Train Loss 0.48883027 Test MSE 0.4896550780219833 Test RE 0.3344669359761669\n",
      "84 Train Loss 0.40554726 Test MSE 0.36886292922549413 Test RE 0.29029567510938475\n",
      "85 Train Loss 0.367758 Test MSE 0.31951145791508806 Test RE 0.2701788064047874\n",
      "86 Train Loss 0.33999404 Test MSE 0.30937361392256024 Test RE 0.26585797687929535\n",
      "87 Train Loss 0.31908602 Test MSE 0.26476052966208713 Test RE 0.24594312156543313\n",
      "88 Train Loss 0.29836798 Test MSE 0.23175770228861156 Test RE 0.23010451937625637\n",
      "89 Train Loss 0.26863632 Test MSE 0.18387035202778113 Test RE 0.20495754671813796\n",
      "90 Train Loss 0.22999346 Test MSE 0.1448613930564119 Test RE 0.1819216510771503\n",
      "91 Train Loss 0.21391281 Test MSE 0.12799471816826039 Test RE 0.17100313976552944\n",
      "92 Train Loss 0.20291063 Test MSE 0.1163172151013335 Test RE 0.1630159345584271\n",
      "93 Train Loss 0.17906076 Test MSE 0.09388176386657596 Test RE 0.14645313765870357\n",
      "94 Train Loss 0.17165107 Test MSE 0.08461125511257957 Test RE 0.13903435579960952\n",
      "95 Train Loss 0.16651273 Test MSE 0.08431412453989143 Test RE 0.13879001661593351\n",
      "96 Train Loss 0.14841416 Test MSE 0.06918004447389833 Test RE 0.12571829391804262\n",
      "97 Train Loss 0.13553762 Test MSE 0.06412082651546756 Test RE 0.12103406405028692\n",
      "98 Train Loss 0.124340035 Test MSE 0.04880543447258308 Test RE 0.10559470759641951\n",
      "99 Train Loss 0.10720783 Test MSE 0.043144847992317555 Test RE 0.09928246055095295\n",
      "Training time: 148.50\n",
      "3\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 64.96767 Test MSE 5.500104476204056 Test RE 1.1209688124670905\n",
      "1 Train Loss 49.428135 Test MSE 8.201708139750528 Test RE 1.3688637276393547\n",
      "2 Train Loss 39.11545 Test MSE 8.707037123405922 Test RE 1.410403114585626\n",
      "3 Train Loss 34.1234 Test MSE 8.341545045158695 Test RE 1.3804837854200054\n",
      "4 Train Loss 31.945564 Test MSE 8.44631903595915 Test RE 1.389126515327112\n",
      "5 Train Loss 29.533129 Test MSE 8.525503260831718 Test RE 1.3956228542724514\n",
      "6 Train Loss 27.677685 Test MSE 8.674721448023108 Test RE 1.4077833659049808\n",
      "7 Train Loss 26.575586 Test MSE 8.86462661853442 Test RE 1.4231093896075726\n",
      "8 Train Loss 25.650076 Test MSE 8.66814030735741 Test RE 1.407249252026735\n",
      "9 Train Loss 23.953365 Test MSE 8.824268448417975 Test RE 1.4198661841748523\n",
      "10 Train Loss 23.072792 Test MSE 8.724893444953642 Test RE 1.4118485955392888\n",
      "11 Train Loss 21.961996 Test MSE 8.949496627529898 Test RE 1.4299055921995623\n",
      "12 Train Loss 21.593513 Test MSE 8.909595341753052 Test RE 1.4267144178157807\n",
      "13 Train Loss 20.745193 Test MSE 8.904809974078677 Test RE 1.4263312202749618\n",
      "14 Train Loss 20.421688 Test MSE 8.99091980575323 Test RE 1.4332109654597558\n",
      "15 Train Loss 19.855152 Test MSE 9.1425831447675 Test RE 1.4452484743121585\n",
      "16 Train Loss 19.322273 Test MSE 9.15346375187691 Test RE 1.4461082151925502\n",
      "17 Train Loss 18.998367 Test MSE 9.317543126897966 Test RE 1.4590116714649504\n",
      "18 Train Loss 18.737888 Test MSE 9.392806478949622 Test RE 1.4648924733169206\n",
      "19 Train Loss 18.379652 Test MSE 9.195209995419315 Test RE 1.4494020999955664\n",
      "20 Train Loss 17.990358 Test MSE 9.20366262801895 Test RE 1.450068123352712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 17.4745 Test MSE 9.137640459132403 Test RE 1.4448577546165946\n",
      "22 Train Loss 16.589725 Test MSE 8.49651897371658 Test RE 1.3932484740494393\n",
      "23 Train Loss 15.309003 Test MSE 7.963058991221631 Test RE 1.3488014581983003\n",
      "24 Train Loss 14.384375 Test MSE 8.057640888579256 Test RE 1.3567880637210923\n",
      "25 Train Loss 13.708406 Test MSE 7.9917471208053446 Test RE 1.3512289049187942\n",
      "26 Train Loss 13.2935505 Test MSE 7.918813914578163 Test RE 1.345049071589784\n",
      "27 Train Loss 12.817356 Test MSE 7.700319439343885 Test RE 1.3263631001730958\n",
      "28 Train Loss 11.044575 Test MSE 7.035599946452274 Test RE 1.267823007457986\n",
      "29 Train Loss 9.910303 Test MSE 6.567444502066842 Test RE 1.2249158830514586\n",
      "30 Train Loss 8.962612 Test MSE 6.45244316262908 Test RE 1.2141438772663096\n",
      "31 Train Loss 8.729298 Test MSE 6.44519010078319 Test RE 1.213461288010063\n",
      "32 Train Loss 8.19413 Test MSE 6.3775672520047255 Test RE 1.2070786924945864\n",
      "33 Train Loss 7.9650736 Test MSE 6.411663023804272 Test RE 1.2103010355220836\n",
      "34 Train Loss 7.771968 Test MSE 6.439891654587623 Test RE 1.2129624058074937\n",
      "35 Train Loss 7.48585 Test MSE 6.377325337986332 Test RE 1.2070557988099995\n",
      "36 Train Loss 7.2019844 Test MSE 6.41792976972609 Test RE 1.2108923639068196\n",
      "37 Train Loss 7.049178 Test MSE 6.372376361122585 Test RE 1.2065873539454777\n",
      "38 Train Loss 6.8492823 Test MSE 6.480819628415452 Test RE 1.2168107210520094\n",
      "39 Train Loss 6.674863 Test MSE 6.46029063794827 Test RE 1.2148819751192008\n",
      "40 Train Loss 6.54486 Test MSE 6.403532586031943 Test RE 1.2095334188570934\n",
      "41 Train Loss 6.4447722 Test MSE 6.467805318824731 Test RE 1.215588351777068\n",
      "42 Train Loss 6.32561 Test MSE 6.43261029997095 Test RE 1.2122764853131214\n",
      "43 Train Loss 6.2014713 Test MSE 6.456674013661192 Test RE 1.2145418676062372\n",
      "44 Train Loss 6.124626 Test MSE 6.4619907810623225 Test RE 1.2150418237596328\n",
      "45 Train Loss 6.0198936 Test MSE 6.461803125071154 Test RE 1.2150241812450537\n",
      "46 Train Loss 5.9319963 Test MSE 6.422634663926362 Test RE 1.2113361266875964\n",
      "47 Train Loss 5.8575573 Test MSE 6.433372999511306 Test RE 1.2123483515750002\n",
      "48 Train Loss 5.764625 Test MSE 6.403357516112066 Test RE 1.2095168846735613\n",
      "49 Train Loss 5.7102776 Test MSE 6.3868568460853465 Test RE 1.2079574908105604\n",
      "50 Train Loss 5.640517 Test MSE 6.396547896816571 Test RE 1.2088735861862525\n",
      "51 Train Loss 5.550407 Test MSE 6.315835909016952 Test RE 1.2012225581037717\n",
      "52 Train Loss 5.4993534 Test MSE 6.304253405153183 Test RE 1.2001206018658563\n",
      "53 Train Loss 5.4524717 Test MSE 6.35024634738038 Test RE 1.2044904111351558\n",
      "54 Train Loss 5.415289 Test MSE 6.3387928192362 Test RE 1.2034036902214051\n",
      "55 Train Loss 5.353752 Test MSE 6.3483983177382335 Test RE 1.2043151347890575\n",
      "56 Train Loss 5.307338 Test MSE 6.330279448233546 Test RE 1.202595297787578\n",
      "57 Train Loss 5.243561 Test MSE 6.324072094508652 Test RE 1.202005531936489\n",
      "58 Train Loss 5.192146 Test MSE 6.337042499518557 Test RE 1.2032375318776556\n",
      "59 Train Loss 5.156988 Test MSE 6.3348206191647805 Test RE 1.2030265750934679\n",
      "60 Train Loss 5.0910864 Test MSE 6.34216231927071 Test RE 1.2037234932323886\n",
      "61 Train Loss 5.039004 Test MSE 6.313349672121498 Test RE 1.2009861034319962\n",
      "62 Train Loss 4.9603076 Test MSE 6.31392128013623 Test RE 1.2010404705888906\n",
      "63 Train Loss 4.8899 Test MSE 6.297488170320583 Test RE 1.1994764909344873\n",
      "64 Train Loss 4.77377 Test MSE 6.191862278224524 Test RE 1.1893747224872453\n",
      "65 Train Loss 4.6813693 Test MSE 6.189107369233158 Test RE 1.189110102287968\n",
      "66 Train Loss 4.563982 Test MSE 6.249713677290776 Test RE 1.194918048294519\n",
      "67 Train Loss 4.2445974 Test MSE 6.136276717695768 Test RE 1.18402406200438\n",
      "68 Train Loss 3.8667114 Test MSE 5.763663391934445 Test RE 1.1475123411495536\n",
      "69 Train Loss 3.500429 Test MSE 5.753804459188144 Test RE 1.1465304926021789\n",
      "70 Train Loss 3.227678 Test MSE 5.696961840975998 Test RE 1.1408530703156479\n",
      "71 Train Loss 2.9086483 Test MSE 5.696993211946657 Test RE 1.140856211430151\n",
      "72 Train Loss 2.7352552 Test MSE 5.643889714781886 Test RE 1.135526619694598\n",
      "73 Train Loss 2.5392048 Test MSE 5.677791145980317 Test RE 1.138931925570884\n",
      "74 Train Loss 2.4291186 Test MSE 5.598007165548483 Test RE 1.130901513514838\n",
      "75 Train Loss 2.3327847 Test MSE 5.668495608490033 Test RE 1.1379992282526945\n",
      "76 Train Loss 2.249158 Test MSE 5.604204524405594 Test RE 1.1315273312060352\n",
      "77 Train Loss 2.1867106 Test MSE 5.593153988219726 Test RE 1.1304111912007841\n",
      "78 Train Loss 2.1437967 Test MSE 5.560296327364352 Test RE 1.1270859315868318\n",
      "79 Train Loss 2.106081 Test MSE 5.588449034215534 Test RE 1.1299356409452368\n",
      "80 Train Loss 2.0691876 Test MSE 5.616097084819406 Test RE 1.132727289699666\n",
      "81 Train Loss 2.026288 Test MSE 5.596189158096933 Test RE 1.1307178629522063\n",
      "82 Train Loss 1.986771 Test MSE 5.6222811219841216 Test RE 1.1333507565228542\n",
      "83 Train Loss 1.9483216 Test MSE 5.665164918332535 Test RE 1.137664846784227\n",
      "84 Train Loss 1.9237347 Test MSE 5.5830006604689855 Test RE 1.1293846998096624\n",
      "85 Train Loss 1.8976506 Test MSE 5.656479445330106 Test RE 1.136792414326159\n",
      "86 Train Loss 1.8616993 Test MSE 5.590518335505256 Test RE 1.1301448189173986\n",
      "87 Train Loss 1.8361984 Test MSE 5.592827702055778 Test RE 1.1303782184888411\n",
      "88 Train Loss 1.8232683 Test MSE 5.580877253805059 Test RE 1.1291699075132835\n",
      "89 Train Loss 1.7980103 Test MSE 5.578593522246732 Test RE 1.1289388520092305\n",
      "90 Train Loss 1.7716215 Test MSE 5.590337731678061 Test RE 1.1301265638902431\n",
      "91 Train Loss 1.753997 Test MSE 5.571765381021313 Test RE 1.1282477356796368\n",
      "92 Train Loss 1.741483 Test MSE 5.560130681568132 Test RE 1.1270691430538078\n",
      "93 Train Loss 1.730846 Test MSE 5.548457545822318 Test RE 1.1258854169524446\n",
      "94 Train Loss 1.7221646 Test MSE 5.542752744001084 Test RE 1.1253064628054485\n",
      "95 Train Loss 1.7129798 Test MSE 5.557820209946499 Test RE 1.126834946053713\n",
      "96 Train Loss 1.6985121 Test MSE 5.552829757841144 Test RE 1.126328931238429\n",
      "97 Train Loss 1.681162 Test MSE 5.5524003826478445 Test RE 1.1262853834373072\n",
      "98 Train Loss 1.6587253 Test MSE 5.528610368942409 Test RE 1.1238699319646164\n",
      "99 Train Loss 1.6439259 Test MSE 5.519598216099701 Test RE 1.1229535517271296\n",
      "Training time: 149.09\n",
      "4\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 64.34837 Test MSE 8.237708985197393 Test RE 1.3718647056632662\n",
      "1 Train Loss 54.98914 Test MSE 7.1874341119290435 Test RE 1.2814303284905852\n",
      "2 Train Loss 38.280228 Test MSE 7.032111363078487 Test RE 1.267508645164371\n",
      "3 Train Loss 29.912582 Test MSE 5.990769685893413 Test RE 1.169901699984493\n",
      "4 Train Loss 24.877565 Test MSE 6.072348201142975 Test RE 1.1778402567753559\n",
      "5 Train Loss 19.708538 Test MSE 5.812121400637878 Test RE 1.152326100279163\n",
      "6 Train Loss 17.03348 Test MSE 5.869928834541368 Test RE 1.1580424468102632\n",
      "7 Train Loss 14.227732 Test MSE 5.898728078027703 Test RE 1.1608797844283252\n",
      "8 Train Loss 12.818787 Test MSE 5.501589277453409 Test RE 1.1211201099183203\n",
      "9 Train Loss 11.196542 Test MSE 5.7421382606491 Test RE 1.1453675716750045\n",
      "10 Train Loss 10.382386 Test MSE 5.464236256990387 Test RE 1.117307707361877\n",
      "11 Train Loss 9.844818 Test MSE 5.3689388895943315 Test RE 1.1075218183802926\n",
      "12 Train Loss 9.23531 Test MSE 5.246933554706521 Test RE 1.0948656801744319\n",
      "13 Train Loss 8.690077 Test MSE 5.010318474248306 Test RE 1.0698939367858027\n",
      "14 Train Loss 8.234526 Test MSE 4.545878745519497 Test RE 1.0191004279796843\n",
      "15 Train Loss 7.696747 Test MSE 4.243410813102529 Test RE 0.9846130773266973\n",
      "16 Train Loss 7.3593836 Test MSE 3.7956531975942176 Test RE 0.9312179155090283\n",
      "17 Train Loss 6.945565 Test MSE 3.47739732705142 Test RE 0.8913232153122034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 6.490002 Test MSE 3.2664815768156057 Test RE 0.8638695514357463\n",
      "19 Train Loss 6.2341566 Test MSE 3.096178841019473 Test RE 0.8410485752907436\n",
      "20 Train Loss 6.003381 Test MSE 2.899898858164677 Test RE 0.8139532953144512\n",
      "21 Train Loss 5.806149 Test MSE 2.7957124435603475 Test RE 0.79919785577306\n",
      "22 Train Loss 5.624692 Test MSE 2.6380390911322475 Test RE 0.7763341195740376\n",
      "23 Train Loss 5.485923 Test MSE 2.596910136002294 Test RE 0.7702585380460458\n",
      "24 Train Loss 5.2923117 Test MSE 2.404902540560078 Test RE 0.7412365070502963\n",
      "25 Train Loss 5.188717 Test MSE 2.331574185903825 Test RE 0.7298484322337685\n",
      "26 Train Loss 5.092458 Test MSE 2.2712246581493654 Test RE 0.7203409554432801\n",
      "27 Train Loss 4.917027 Test MSE 2.2127469916143685 Test RE 0.7110071036319257\n",
      "28 Train Loss 4.8475747 Test MSE 2.1663233225823557 Test RE 0.7035090651354898\n",
      "29 Train Loss 4.7286487 Test MSE 2.205219110380526 Test RE 0.7097966315174714\n",
      "30 Train Loss 4.5687103 Test MSE 2.083476142577732 Test RE 0.6899257052423641\n",
      "31 Train Loss 4.1470475 Test MSE 1.8198762137277207 Test RE 0.6448058732687568\n",
      "32 Train Loss 2.925031 Test MSE 1.3503838300269841 Test RE 0.5554393892897171\n",
      "33 Train Loss 2.4273763 Test MSE 1.089219547841277 Test RE 0.4988451724536761\n",
      "34 Train Loss 2.0347815 Test MSE 0.94775353276903 Test RE 0.4653243359508942\n",
      "35 Train Loss 1.7672169 Test MSE 0.7084160406267267 Test RE 0.4023020572698311\n",
      "36 Train Loss 1.5021634 Test MSE 0.48368020677196016 Test RE 0.332420055772909\n",
      "37 Train Loss 1.3676231 Test MSE 0.39736765651938577 Test RE 0.3013035980143553\n",
      "38 Train Loss 1.2579938 Test MSE 0.4142304263202449 Test RE 0.3076302640003119\n",
      "39 Train Loss 1.0627491 Test MSE 0.32363724413091854 Test RE 0.2719175931395702\n",
      "40 Train Loss 0.85372806 Test MSE 0.20497389979135466 Test RE 0.21640004277270344\n",
      "41 Train Loss 0.75472236 Test MSE 0.14104582577676472 Test RE 0.17950980667076175\n",
      "42 Train Loss 0.5944981 Test MSE 0.11037808011018319 Test RE 0.15879962706586362\n",
      "43 Train Loss 0.5105372 Test MSE 0.08521907162896036 Test RE 0.1395328483039376\n",
      "44 Train Loss 0.45942375 Test MSE 0.08448936083092473 Test RE 0.1389341705399249\n",
      "45 Train Loss 0.3538327 Test MSE 0.06514248286021006 Test RE 0.12199448948958024\n",
      "46 Train Loss 0.3237035 Test MSE 0.06019005177068725 Test RE 0.11726554294803293\n",
      "47 Train Loss 0.27134332 Test MSE 0.047443335676643605 Test RE 0.1041107723505602\n",
      "48 Train Loss 0.2528778 Test MSE 0.04878265630136342 Test RE 0.10557006346546985\n",
      "49 Train Loss 0.22891006 Test MSE 0.05374278137267437 Test RE 0.11080723800448934\n",
      "50 Train Loss 0.18592623 Test MSE 0.04731992658584011 Test RE 0.10397527827515893\n",
      "51 Train Loss 0.16663939 Test MSE 0.03810749425665289 Test RE 0.0933067916963373\n",
      "52 Train Loss 0.15331624 Test MSE 0.0323108022081307 Test RE 0.08591755916773981\n",
      "53 Train Loss 0.14499417 Test MSE 0.028876145751239302 Test RE 0.08122274688854729\n",
      "54 Train Loss 0.13473454 Test MSE 0.029103410300239062 Test RE 0.08154174502731037\n",
      "55 Train Loss 0.12913685 Test MSE 0.022531802603988415 Test RE 0.07174737713099516\n",
      "56 Train Loss 0.11490356 Test MSE 0.016855524195036456 Test RE 0.0620553446427261\n",
      "57 Train Loss 0.10410944 Test MSE 0.01547358550382463 Test RE 0.05945707494681493\n",
      "58 Train Loss 0.096299715 Test MSE 0.015672518314432293 Test RE 0.059838052889492094\n",
      "59 Train Loss 0.09140901 Test MSE 0.017568182128799945 Test RE 0.06335362546997614\n",
      "60 Train Loss 0.08895514 Test MSE 0.018838604098297903 Test RE 0.0656043172246042\n",
      "61 Train Loss 0.08342007 Test MSE 0.01758474605561914 Test RE 0.06338348449509418\n",
      "62 Train Loss 0.077758156 Test MSE 0.01493539084192986 Test RE 0.05841392064189313\n",
      "63 Train Loss 0.07442325 Test MSE 0.01443298618099659 Test RE 0.05742303704864973\n",
      "64 Train Loss 0.07058381 Test MSE 0.016710300810650093 Test RE 0.06178743893320845\n",
      "65 Train Loss 0.06631454 Test MSE 0.01810516765874517 Test RE 0.06431456487138204\n",
      "66 Train Loss 0.058243416 Test MSE 0.017077608971031465 Test RE 0.06246282079411045\n",
      "67 Train Loss 0.052537605 Test MSE 0.0165814948838327 Test RE 0.061548844057780897\n",
      "68 Train Loss 0.051413316 Test MSE 0.01605619824201743 Test RE 0.06056607375751434\n",
      "69 Train Loss 0.04480784 Test MSE 0.012817416561113366 Test RE 0.054113834584107186\n",
      "70 Train Loss 0.041512802 Test MSE 0.010854975870761204 Test RE 0.04979921437913174\n",
      "71 Train Loss 0.040054083 Test MSE 0.009916278273936518 Test RE 0.04759731045566077\n",
      "72 Train Loss 0.03841813 Test MSE 0.009121424025187985 Test RE 0.0456498529442906\n",
      "73 Train Loss 0.03655076 Test MSE 0.00830659530633367 Test RE 0.043563181186839946\n",
      "74 Train Loss 0.034954805 Test MSE 0.007310748988929004 Test RE 0.040868528104503254\n",
      "75 Train Loss 0.033213347 Test MSE 0.006100135292685887 Test RE 0.03733170229658245\n",
      "76 Train Loss 0.031276736 Test MSE 0.005012239914759763 Test RE 0.03383950375349026\n",
      "77 Train Loss 0.029810637 Test MSE 0.00542884281223535 Test RE 0.03521775710909231\n",
      "78 Train Loss 0.026236463 Test MSE 0.005671318446193963 Test RE 0.03599565470773188\n",
      "79 Train Loss 0.025404874 Test MSE 0.00575586971567752 Test RE 0.03626298395645854\n",
      "80 Train Loss 0.025106743 Test MSE 0.005933252845459173 Test RE 0.03681751635146162\n",
      "81 Train Loss 0.024890311 Test MSE 0.005912082986165884 Test RE 0.036751775167946185\n",
      "82 Train Loss 0.02385575 Test MSE 0.00543329153158389 Test RE 0.03523218392517675\n",
      "83 Train Loss 0.022006877 Test MSE 0.004274935840327618 Test RE 0.031251643451261336\n",
      "84 Train Loss 0.020199882 Test MSE 0.0035068319049936843 Test RE 0.02830515482968267\n",
      "85 Train Loss 0.019218052 Test MSE 0.003388504801702763 Test RE 0.02782352259631398\n",
      "86 Train Loss 0.018315606 Test MSE 0.003929917457384557 Test RE 0.029963999050044987\n",
      "87 Train Loss 0.016940074 Test MSE 0.00418469653628824 Test RE 0.03092003985515068\n",
      "88 Train Loss 0.016340613 Test MSE 0.0036628108318661062 Test RE 0.028927793272654618\n",
      "89 Train Loss 0.01499852 Test MSE 0.0035237812416103256 Test RE 0.028373475085199124\n",
      "90 Train Loss 0.013938757 Test MSE 0.002938721697420452 Test RE 0.02591118589116947\n",
      "91 Train Loss 0.013237745 Test MSE 0.002415045198852821 Test RE 0.023489333384201835\n",
      "92 Train Loss 0.012717217 Test MSE 0.002385759755843381 Test RE 0.02334648022485945\n",
      "93 Train Loss 0.012321475 Test MSE 0.0020842348178516648 Test RE 0.021821338365947213\n",
      "94 Train Loss 0.011775276 Test MSE 0.0018855696176256077 Test RE 0.020755315820575063\n",
      "95 Train Loss 0.010591667 Test MSE 0.0016391384202926742 Test RE 0.019351555296230703\n",
      "96 Train Loss 0.009961436 Test MSE 0.0016875597700284778 Test RE 0.01963530456740301\n",
      "97 Train Loss 0.009313367 Test MSE 0.0017672937499398468 Test RE 0.020093816461632448\n",
      "98 Train Loss 0.009042784 Test MSE 0.001586441245343129 Test RE 0.019037944503124113\n",
      "99 Train Loss 0.00884938 Test MSE 0.0014933445593468785 Test RE 0.018470900647253954\n",
      "Training time: 149.23\n",
      "5\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 70.52206 Test MSE 4.668270816504092 Test RE 1.032728307838861\n",
      "1 Train Loss 50.565014 Test MSE 5.016764995983673 Test RE 1.0705820045647725\n",
      "2 Train Loss 40.021088 Test MSE 6.254130937791203 Test RE 1.1953402541935783\n",
      "3 Train Loss 32.59238 Test MSE 6.109912717960309 Test RE 1.1814777939227339\n",
      "4 Train Loss 26.542675 Test MSE 5.619366344089985 Test RE 1.1330569350358606\n",
      "5 Train Loss 23.153511 Test MSE 5.649653035962631 Test RE 1.1361062496199426\n",
      "6 Train Loss 21.199093 Test MSE 5.693452338003609 Test RE 1.140501615964788\n",
      "7 Train Loss 19.67252 Test MSE 5.361936738743827 Test RE 1.1067993697573526\n",
      "8 Train Loss 18.408024 Test MSE 5.251620644536055 Test RE 1.0953545931944753\n",
      "9 Train Loss 17.5146 Test MSE 5.414664127127169 Test RE 1.112227993277429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 16.698181 Test MSE 5.3483037823724855 Test RE 1.1053914315865663\n",
      "11 Train Loss 16.05127 Test MSE 5.388767886457213 Test RE 1.109565127812173\n",
      "12 Train Loss 15.554246 Test MSE 5.326890910576969 Test RE 1.1031763981038902\n",
      "13 Train Loss 15.027197 Test MSE 5.3207412617645735 Test RE 1.1025394311875971\n",
      "14 Train Loss 14.22786 Test MSE 5.130583949248088 Test RE 1.0826584238352979\n",
      "15 Train Loss 13.616074 Test MSE 5.167263840861507 Test RE 1.0865216360070042\n",
      "16 Train Loss 12.748962 Test MSE 5.06954613399622 Test RE 1.0761990394165304\n",
      "17 Train Loss 12.04967 Test MSE 4.758097157061782 Test RE 1.0426167870522622\n",
      "18 Train Loss 11.030959 Test MSE 4.759623642218987 Test RE 1.0427840189696933\n",
      "19 Train Loss 9.912475 Test MSE 4.3612799623149785 Test RE 0.9981942028912764\n",
      "20 Train Loss 8.474998 Test MSE 3.954788490985644 Test RE 0.9505384543664459\n",
      "21 Train Loss 7.94392 Test MSE 3.925936454226937 Test RE 0.9470647953720497\n",
      "22 Train Loss 7.2954955 Test MSE 3.8954781869072104 Test RE 0.9433838749824844\n",
      "23 Train Loss 6.546514 Test MSE 3.661196640691836 Test RE 0.9145755520780907\n",
      "24 Train Loss 5.9117045 Test MSE 3.5828392397537274 Test RE 0.9047356870707679\n",
      "25 Train Loss 4.838593 Test MSE 2.912035610735017 Test RE 0.8156548089857089\n",
      "26 Train Loss 4.5075607 Test MSE 3.0400400649647548 Test RE 0.833388904151148\n",
      "27 Train Loss 4.196924 Test MSE 2.873174494303908 Test RE 0.8101940725312549\n",
      "28 Train Loss 4.027005 Test MSE 2.9832564371707724 Test RE 0.8255689554966396\n",
      "29 Train Loss 3.8497477 Test MSE 2.998878933195678 Test RE 0.8277277720389913\n",
      "30 Train Loss 3.7058005 Test MSE 2.924528929988326 Test RE 0.8174026120767315\n",
      "31 Train Loss 3.5553136 Test MSE 3.046360318136056 Test RE 0.8342547634733122\n",
      "32 Train Loss 3.4071605 Test MSE 3.0091844041110165 Test RE 0.8291487711719099\n",
      "33 Train Loss 3.249169 Test MSE 3.0199644951128763 Test RE 0.8306326131673388\n",
      "34 Train Loss 3.0769541 Test MSE 2.9492389315279786 Test RE 0.8208485575911626\n",
      "35 Train Loss 2.9467807 Test MSE 3.000602181096405 Test RE 0.8279655567788404\n",
      "36 Train Loss 2.8196907 Test MSE 3.019664941164618 Test RE 0.8305914164165644\n",
      "37 Train Loss 2.6140587 Test MSE 2.9192622937111627 Test RE 0.8166662709005543\n",
      "38 Train Loss 2.4327686 Test MSE 2.919937607436255 Test RE 0.8167607252514757\n",
      "39 Train Loss 2.3622785 Test MSE 2.895090954258687 Test RE 0.813278266144439\n",
      "40 Train Loss 2.2841547 Test MSE 2.8462287489212375 Test RE 0.8063859658135847\n",
      "41 Train Loss 2.218357 Test MSE 2.8037455203300925 Test RE 0.8003452220927307\n",
      "42 Train Loss 2.1108165 Test MSE 2.7423506520317322 Test RE 0.7915339606169584\n",
      "43 Train Loss 2.055239 Test MSE 2.7571490974014856 Test RE 0.7936667499294956\n",
      "44 Train Loss 1.9540994 Test MSE 2.6761130742669366 Test RE 0.7819163424150173\n",
      "45 Train Loss 1.9044541 Test MSE 2.615006542089805 Test RE 0.7729376281379036\n",
      "46 Train Loss 1.8208065 Test MSE 2.6250037272424205 Test RE 0.7744136912482387\n",
      "47 Train Loss 1.7463876 Test MSE 2.623322655660602 Test RE 0.7741656814397339\n",
      "48 Train Loss 1.644414 Test MSE 2.462564887244223 Test RE 0.7500701830720449\n",
      "49 Train Loss 1.5993752 Test MSE 2.4907934632954407 Test RE 0.7543569899894427\n",
      "50 Train Loss 1.5089833 Test MSE 2.341777150877815 Test RE 0.731443596825649\n",
      "51 Train Loss 1.4238698 Test MSE 2.204946255808753 Test RE 0.7097527181380264\n",
      "52 Train Loss 1.3730994 Test MSE 2.2116035830424434 Test RE 0.7108233780025662\n",
      "53 Train Loss 1.3167746 Test MSE 2.1397746883831448 Test RE 0.6991849688656623\n",
      "54 Train Loss 1.2759149 Test MSE 2.070402248685515 Test RE 0.6877576433942358\n",
      "55 Train Loss 1.2142239 Test MSE 2.0149777025800453 Test RE 0.6784895804799758\n",
      "56 Train Loss 1.0920017 Test MSE 1.889362079549209 Test RE 0.6570004357148754\n",
      "57 Train Loss 1.0542924 Test MSE 1.9047684857081253 Test RE 0.6596736831854251\n",
      "58 Train Loss 0.98978055 Test MSE 1.945033954658856 Test RE 0.6666097383889806\n",
      "59 Train Loss 0.9223254 Test MSE 1.8545612929256967 Test RE 0.6509215589650309\n",
      "60 Train Loss 0.8619868 Test MSE 1.7475076472130173 Test RE 0.6318552564107196\n",
      "61 Train Loss 0.7748798 Test MSE 1.7306104807004605 Test RE 0.6287930387026948\n",
      "62 Train Loss 0.73389673 Test MSE 1.6722475977337279 Test RE 0.6180994407538768\n",
      "63 Train Loss 0.6912117 Test MSE 1.6554833943848832 Test RE 0.6149934278573982\n",
      "64 Train Loss 0.6586921 Test MSE 1.6260045630298572 Test RE 0.6094933061624389\n",
      "65 Train Loss 0.6237422 Test MSE 1.6498711424388524 Test RE 0.6139500986785503\n",
      "66 Train Loss 0.600246 Test MSE 1.607643789832288 Test RE 0.60604235046821\n",
      "67 Train Loss 0.58476067 Test MSE 1.6172024316684088 Test RE 0.6078413672859174\n",
      "68 Train Loss 0.5636734 Test MSE 1.6169756467346963 Test RE 0.6077987461227977\n",
      "69 Train Loss 0.5424585 Test MSE 1.6135581736191933 Test RE 0.6071561159925546\n",
      "70 Train Loss 0.51950794 Test MSE 1.5722587767693368 Test RE 0.599335598606121\n",
      "71 Train Loss 0.49499583 Test MSE 1.5953479799084165 Test RE 0.6037202923143251\n",
      "72 Train Loss 0.48108923 Test MSE 1.5639215810335754 Test RE 0.5977444419913778\n",
      "73 Train Loss 0.4602881 Test MSE 1.567169327793527 Test RE 0.5983647786414231\n",
      "74 Train Loss 0.45370924 Test MSE 1.5542759651285272 Test RE 0.595898271805409\n",
      "75 Train Loss 0.44373518 Test MSE 1.5427997195903789 Test RE 0.5936942406455727\n",
      "76 Train Loss 0.4229731 Test MSE 1.5743671221528643 Test RE 0.5997373082774783\n",
      "77 Train Loss 0.41564253 Test MSE 1.5725084512078122 Test RE 0.5993831839149357\n",
      "78 Train Loss 0.40545496 Test MSE 1.5631866985702918 Test RE 0.5976039862522391\n",
      "79 Train Loss 0.398723 Test MSE 1.5488740298712436 Test RE 0.5948618388408153\n",
      "80 Train Loss 0.38365513 Test MSE 1.5179726998904857 Test RE 0.5888979476709482\n",
      "81 Train Loss 0.37360907 Test MSE 1.4918815589007957 Test RE 0.5838149784487112\n",
      "82 Train Loss 0.35711753 Test MSE 1.4539633286222118 Test RE 0.5763479951600806\n",
      "83 Train Loss 0.34479046 Test MSE 1.436643296631607 Test RE 0.5729048985843035\n",
      "84 Train Loss 0.34121266 Test MSE 1.4313185737811287 Test RE 0.5718422159812544\n",
      "85 Train Loss 0.33506542 Test MSE 1.3941574830433536 Test RE 0.5643700744289321\n",
      "86 Train Loss 0.3295821 Test MSE 1.3851206650380616 Test RE 0.562537999777012\n",
      "87 Train Loss 0.3202803 Test MSE 1.3177311333478903 Test RE 0.5486829484507093\n",
      "88 Train Loss 0.31293732 Test MSE 1.2721165843794278 Test RE 0.5391027131584288\n",
      "89 Train Loss 0.30370787 Test MSE 1.235418218768226 Test RE 0.531269716714246\n",
      "90 Train Loss 0.2903524 Test MSE 1.1963632172702676 Test RE 0.5228048240518269\n",
      "91 Train Loss 0.27885273 Test MSE 1.1540295970624406 Test RE 0.513471725333339\n",
      "92 Train Loss 0.273998 Test MSE 1.1615389628603523 Test RE 0.5151396178939055\n",
      "93 Train Loss 0.26876256 Test MSE 1.1473437156674045 Test RE 0.5119821631005187\n",
      "94 Train Loss 0.26515764 Test MSE 1.1544541416171257 Test RE 0.5135661646703024\n",
      "95 Train Loss 0.2564256 Test MSE 1.117412657968347 Test RE 0.5052599254210992\n",
      "96 Train Loss 0.2480833 Test MSE 1.070773028004086 Test RE 0.4946030291445454\n",
      "97 Train Loss 0.24073094 Test MSE 1.0446975617770768 Test RE 0.48854362531334217\n",
      "98 Train Loss 0.23443691 Test MSE 1.038588563560053 Test RE 0.4871131213450485\n",
      "99 Train Loss 0.22963133 Test MSE 1.0241962244382237 Test RE 0.4837262388551483\n",
      "Training time: 150.45\n",
      "6\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "1 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "2 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "3 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "4 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "5 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "7 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "8 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "9 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "10 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "11 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "12 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "13 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "14 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "15 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "16 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "17 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "18 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "19 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "20 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "21 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "22 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "23 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "24 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "25 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "26 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "27 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "28 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "29 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "30 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "31 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "32 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "33 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "34 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "35 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "36 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "37 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "38 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "39 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "40 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "41 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "42 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "43 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "44 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "45 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "46 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "47 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "48 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "49 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "50 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "51 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "52 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "53 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "54 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "55 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "56 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "57 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "58 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "59 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "60 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "61 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "62 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "63 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "64 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "65 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "66 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "67 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "68 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "69 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "70 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "71 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "72 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "73 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "74 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "75 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "76 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "77 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "78 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "79 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "80 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "81 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "82 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "83 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "84 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "85 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "86 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "87 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "88 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "89 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "90 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "91 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "92 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "93 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "94 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "95 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "96 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "97 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "98 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "99 Train Loss 72.35148 Test MSE 5.07121115749677 Test RE 1.0763757563787264\n",
      "Training time: 109.07\n",
      "7\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 62.031128 Test MSE 5.170090178257672 Test RE 1.0868187426597444\n",
      "1 Train Loss 52.13817 Test MSE 5.868156963549144 Test RE 1.1578676528097736\n",
      "2 Train Loss 41.863 Test MSE 7.043719790793856 Test RE 1.268554399024802\n",
      "3 Train Loss 34.722847 Test MSE 6.781590243077985 Test RE 1.244726205479596\n",
      "4 Train Loss 30.276546 Test MSE 6.66271492493746 Test RE 1.233768495084474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 25.980953 Test MSE 6.391737774375751 Test RE 1.2084189719443552\n",
      "6 Train Loss 23.189106 Test MSE 5.962990793648379 Test RE 1.1671861612372865\n",
      "7 Train Loss 21.1413 Test MSE 5.314501439017369 Test RE 1.1018927479088723\n",
      "8 Train Loss 17.698536 Test MSE 4.892465564307296 Test RE 1.057236014995132\n",
      "9 Train Loss 16.629175 Test MSE 5.419214030893116 Test RE 1.11269519378894\n",
      "10 Train Loss 14.221643 Test MSE 4.903772939570793 Test RE 1.0584570419891364\n",
      "11 Train Loss 13.20952 Test MSE 5.0050873567399865 Test RE 1.0693352694533393\n",
      "12 Train Loss 12.304497 Test MSE 5.050105537283696 Test RE 1.0741335638021314\n",
      "13 Train Loss 11.667368 Test MSE 4.811526670481133 Test RE 1.0484543091906915\n",
      "14 Train Loss 11.229453 Test MSE 4.574316605220798 Test RE 1.0222830746511096\n",
      "15 Train Loss 10.99674 Test MSE 4.6205644546280515 Test RE 1.0274378877108639\n",
      "16 Train Loss 10.652128 Test MSE 4.500882565044309 Test RE 1.014044236768519\n",
      "17 Train Loss 10.411508 Test MSE 4.464820683707467 Test RE 1.0099737144476533\n",
      "18 Train Loss 10.154886 Test MSE 4.224738766220115 Test RE 0.9824444196935225\n",
      "19 Train Loss 9.876099 Test MSE 4.199922285088857 Test RE 0.9795546880377017\n",
      "20 Train Loss 9.662861 Test MSE 4.1360036338345285 Test RE 0.9720721844538497\n",
      "21 Train Loss 9.4893 Test MSE 4.122185662458947 Test RE 0.9704470283389105\n",
      "22 Train Loss 9.181009 Test MSE 3.9649156270022363 Test RE 0.9517547112631638\n",
      "23 Train Loss 8.97591 Test MSE 3.821886569610967 Test RE 0.9344303957066302\n",
      "24 Train Loss 8.89283 Test MSE 3.776908142283657 Test RE 0.9289156324312963\n",
      "25 Train Loss 8.766673 Test MSE 3.6602369509047725 Test RE 0.9144556778364453\n",
      "26 Train Loss 8.659703 Test MSE 3.685392247722664 Test RE 0.9175926354050262\n",
      "27 Train Loss 8.468861 Test MSE 3.6973998152741783 Test RE 0.919086247859349\n",
      "28 Train Loss 8.382402 Test MSE 3.6487460835114516 Test RE 0.9130191384673041\n",
      "29 Train Loss 8.287089 Test MSE 3.6343446098279197 Test RE 0.911215529645682\n",
      "30 Train Loss 8.239716 Test MSE 3.579839291747705 Test RE 0.904356835519634\n",
      "31 Train Loss 8.173146 Test MSE 3.608612879160033 Test RE 0.9079840250600194\n",
      "32 Train Loss 8.140575 Test MSE 3.6300122337312013 Test RE 0.9106722534854953\n",
      "33 Train Loss 8.089087 Test MSE 3.667818712376855 Test RE 0.9154022829754377\n",
      "34 Train Loss 8.05953 Test MSE 3.6743871086910374 Test RE 0.9162215758489696\n",
      "35 Train Loss 7.99893 Test MSE 3.664976736800862 Test RE 0.915047568732893\n",
      "36 Train Loss 7.899712 Test MSE 3.627142870636068 Test RE 0.9103122593909001\n",
      "37 Train Loss 7.798197 Test MSE 3.6023770339894132 Test RE 0.9071991672529699\n",
      "38 Train Loss 7.7661543 Test MSE 3.5186389340087474 Test RE 0.8965931411322636\n",
      "39 Train Loss 7.7551174 Test MSE 3.51894138105366 Test RE 0.8966316739462532\n",
      "40 Train Loss 7.701928 Test MSE 3.4985847905212286 Test RE 0.894034467095433\n",
      "41 Train Loss 7.6301246 Test MSE 3.435690822943084 Test RE 0.8859620058025979\n",
      "42 Train Loss 7.5836453 Test MSE 3.3691562648389555 Test RE 0.8773414286319177\n",
      "43 Train Loss 7.34183 Test MSE 2.784337944237905 Test RE 0.7975704100367015\n",
      "44 Train Loss 6.8118906 Test MSE 2.470663339382443 Test RE 0.7513025204598872\n",
      "45 Train Loss 6.6810865 Test MSE 2.4185619592336245 Test RE 0.7433385721962507\n",
      "46 Train Loss 6.4639845 Test MSE 2.366659897181026 Test RE 0.7353193356740145\n",
      "47 Train Loss 6.2949295 Test MSE 2.422071897820742 Test RE 0.7438777617774388\n",
      "48 Train Loss 5.953122 Test MSE 2.2178717796548066 Test RE 0.711829984284379\n",
      "49 Train Loss 5.5408783 Test MSE 2.151443284640108 Test RE 0.7010887709125823\n",
      "50 Train Loss 5.384016 Test MSE 2.1479736618952057 Test RE 0.7005232214787204\n",
      "51 Train Loss 5.2604456 Test MSE 2.1649327952164263 Test RE 0.7032832434338347\n",
      "52 Train Loss 5.083478 Test MSE 2.221621506609394 Test RE 0.7124314710056563\n",
      "53 Train Loss 4.9423757 Test MSE 2.2225872968792832 Test RE 0.7125863094014023\n",
      "54 Train Loss 4.900634 Test MSE 2.2459149034766406 Test RE 0.7163160938732936\n",
      "55 Train Loss 4.8382683 Test MSE 2.230342834206165 Test RE 0.7138284826701551\n",
      "56 Train Loss 4.788903 Test MSE 2.1951542388921372 Test RE 0.7081749826703942\n",
      "57 Train Loss 4.7625937 Test MSE 2.19849582671037 Test RE 0.7087137896845476\n",
      "58 Train Loss 4.742085 Test MSE 2.1952759525905576 Test RE 0.7081946153230746\n",
      "59 Train Loss 4.6981487 Test MSE 2.174162921106888 Test RE 0.7047808623514967\n",
      "60 Train Loss 4.6583643 Test MSE 2.1850215974658 Test RE 0.706538655074724\n",
      "61 Train Loss 4.605322 Test MSE 2.124937185018644 Test RE 0.6967566276988716\n",
      "62 Train Loss 4.566998 Test MSE 2.144591049854071 Test RE 0.6999714149161912\n",
      "63 Train Loss 4.548797 Test MSE 2.138228397459377 Test RE 0.6989322930190525\n",
      "64 Train Loss 4.520919 Test MSE 2.124561186746818 Test RE 0.6966949809641371\n",
      "65 Train Loss 4.4888577 Test MSE 2.136790173807387 Test RE 0.6986971941757879\n",
      "66 Train Loss 4.477254 Test MSE 2.1304068488022847 Test RE 0.6976527895342752\n",
      "67 Train Loss 4.4689736 Test MSE 2.1375310515065125 Test RE 0.6988183114275667\n",
      "68 Train Loss 4.4502335 Test MSE 2.1453881208130507 Test RE 0.7001014805191516\n",
      "69 Train Loss 4.4260654 Test MSE 2.123191695804926 Test RE 0.6964704001713798\n",
      "70 Train Loss 4.4047036 Test MSE 2.1077942798167664 Test RE 0.6939403983625212\n",
      "71 Train Loss 4.3866787 Test MSE 2.0966033804783937 Test RE 0.6920957799324\n",
      "72 Train Loss 4.3621206 Test MSE 2.0937142133358915 Test RE 0.691618753674757\n",
      "73 Train Loss 4.334029 Test MSE 2.068411596966312 Test RE 0.6874269310455124\n",
      "74 Train Loss 4.326009 Test MSE 2.066223920150432 Test RE 0.6870633027865986\n",
      "75 Train Loss 4.3070335 Test MSE 2.0660564805875943 Test RE 0.6870354636185698\n",
      "76 Train Loss 4.2879915 Test MSE 2.0819338343920015 Test RE 0.6896702967361733\n",
      "77 Train Loss 4.260414 Test MSE 2.0726757521063295 Test RE 0.6881351522430245\n",
      "78 Train Loss 4.2349105 Test MSE 2.0784531383592237 Test RE 0.6890935404525101\n",
      "79 Train Loss 4.222557 Test MSE 2.0768076831686657 Test RE 0.6888207180768385\n",
      "80 Train Loss 4.1953387 Test MSE 2.0715450240229463 Test RE 0.6879474239188191\n",
      "81 Train Loss 4.1479483 Test MSE 2.0317792310442058 Test RE 0.6813124397697374\n",
      "82 Train Loss 4.0657706 Test MSE 1.9361201462441666 Test RE 0.6650804964462542\n",
      "83 Train Loss 3.6145015 Test MSE 1.1247554512372215 Test RE 0.5069173007132688\n",
      "84 Train Loss 2.6485746 Test MSE 0.6740121628786298 Test RE 0.3924116814304564\n",
      "85 Train Loss 2.0338485 Test MSE 0.5509336069995217 Test RE 0.35477882650000003\n",
      "86 Train Loss 1.6139705 Test MSE 0.2861857564889177 Test RE 0.25570078882551145\n",
      "87 Train Loss 1.139469 Test MSE 0.20285174831534827 Test RE 0.21527690341878997\n",
      "88 Train Loss 0.93734163 Test MSE 0.1853373959868546 Test RE 0.20577356829778962\n",
      "89 Train Loss 0.8371181 Test MSE 0.13428130067850105 Test RE 0.1751522940778908\n",
      "90 Train Loss 0.7702305 Test MSE 0.12476795089419183 Test RE 0.1688338723764977\n",
      "91 Train Loss 0.6171317 Test MSE 0.08760775987130895 Test RE 0.14147488450565937\n",
      "92 Train Loss 0.5585195 Test MSE 0.08277320747248859 Test RE 0.13751591172473457\n",
      "93 Train Loss 0.51881176 Test MSE 0.08381426455381162 Test RE 0.138377993683113\n",
      "94 Train Loss 0.4611336 Test MSE 0.07651298094703057 Test RE 0.13221344499391083\n",
      "95 Train Loss 0.3625685 Test MSE 0.08038442860846715 Test RE 0.13551707672354077\n",
      "96 Train Loss 0.29525906 Test MSE 0.06875751509663205 Test RE 0.12533378252503916\n",
      "97 Train Loss 0.27440372 Test MSE 0.056619612425104104 Test RE 0.1137343124042132\n",
      "98 Train Loss 0.25236756 Test MSE 0.049387469728604395 Test RE 0.10622248287513804\n",
      "99 Train Loss 0.24044259 Test MSE 0.051498583517891494 Test RE 0.10846901645243631\n",
      "Training time: 151.27\n",
      "8\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 74.76944 Test MSE 5.227409631740324 Test RE 1.0928267754280105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 69.23572 Test MSE 4.963172143099401 Test RE 1.0648482697714878\n",
      "2 Train Loss 60.403587 Test MSE 5.160429866359043 Test RE 1.0858029076738187\n",
      "3 Train Loss 53.812714 Test MSE 6.094142958909226 Test RE 1.1799521045516899\n",
      "4 Train Loss 39.129803 Test MSE 5.368260375254477 Test RE 1.1074518331192684\n",
      "5 Train Loss 32.0792 Test MSE 5.958826318037322 Test RE 1.1667785161953566\n",
      "6 Train Loss 27.41669 Test MSE 6.647526263810053 Test RE 1.2323614122554891\n",
      "7 Train Loss 24.820974 Test MSE 6.261628081563128 Test RE 1.1960564970854648\n",
      "8 Train Loss 23.905262 Test MSE 5.940523856313275 Test RE 1.1649852652205304\n",
      "9 Train Loss 22.16098 Test MSE 6.352471253395264 Test RE 1.2047013984828165\n",
      "10 Train Loss 20.800404 Test MSE 6.032424660567717 Test RE 1.173961930166219\n",
      "11 Train Loss 19.498741 Test MSE 6.061936422829631 Test RE 1.1768300484898384\n",
      "12 Train Loss 18.775032 Test MSE 5.704907532390528 Test RE 1.1416483808823819\n",
      "13 Train Loss 17.540432 Test MSE 5.690611466236443 Test RE 1.1402170414290638\n",
      "14 Train Loss 16.499805 Test MSE 5.575834141609361 Test RE 1.1286596098210355\n",
      "15 Train Loss 15.997501 Test MSE 5.16804021406229 Test RE 1.0866032570179738\n",
      "16 Train Loss 15.38282 Test MSE 5.47532478737784 Test RE 1.1184408045483276\n",
      "17 Train Loss 14.818186 Test MSE 5.563865905352351 Test RE 1.127447654721649\n",
      "18 Train Loss 14.508482 Test MSE 5.518674715616893 Test RE 1.1228596054390014\n",
      "19 Train Loss 13.947008 Test MSE 5.483563266315934 Test RE 1.1192819224642214\n",
      "20 Train Loss 13.647709 Test MSE 5.406803288979337 Test RE 1.1114203513297884\n",
      "21 Train Loss 13.293316 Test MSE 5.580177121774709 Test RE 1.1290990769986409\n",
      "22 Train Loss 13.024557 Test MSE 5.536114908623922 Test RE 1.1246324442197018\n",
      "23 Train Loss 12.685898 Test MSE 5.777119542766168 Test RE 1.1488510814783595\n",
      "24 Train Loss 12.48522 Test MSE 5.654446326038779 Test RE 1.1365880962224386\n",
      "25 Train Loss 12.314653 Test MSE 5.677355310126341 Test RE 1.1388882116615602\n",
      "26 Train Loss 11.776466 Test MSE 5.321029552217308 Test RE 1.1025692998911072\n",
      "27 Train Loss 11.590832 Test MSE 5.365131263801878 Test RE 1.1071290241366365\n",
      "28 Train Loss 11.0042 Test MSE 5.194058994547927 Test RE 1.0893351046234034\n",
      "29 Train Loss 10.411066 Test MSE 4.913875339913641 Test RE 1.059546759576588\n",
      "30 Train Loss 10.033241 Test MSE 4.513594153104771 Test RE 1.0154751810391258\n",
      "31 Train Loss 9.164062 Test MSE 3.781702584563219 Test RE 0.9295050325093936\n",
      "32 Train Loss 7.836911 Test MSE 3.6419718475236573 Test RE 0.9121711922973365\n",
      "33 Train Loss 7.35706 Test MSE 3.5119177082709148 Test RE 0.8957364056811365\n",
      "34 Train Loss 6.8456173 Test MSE 3.34138610710989 Test RE 0.8737182184583127\n",
      "35 Train Loss 6.234932 Test MSE 3.1312297126964403 Test RE 0.845795801489042\n",
      "36 Train Loss 5.638664 Test MSE 3.037027387203549 Test RE 0.8329758578579712\n",
      "37 Train Loss 5.318262 Test MSE 3.0003397011737425 Test RE 0.8279293425333232\n",
      "38 Train Loss 5.222309 Test MSE 2.9918407308792214 Test RE 0.8267558859063528\n",
      "39 Train Loss 5.0365286 Test MSE 2.9225592370177464 Test RE 0.8171273022060962\n",
      "40 Train Loss 4.785225 Test MSE 2.908193626282303 Test RE 0.815116565671335\n",
      "41 Train Loss 4.716953 Test MSE 2.840040389895047 Test RE 0.805508854075818\n",
      "42 Train Loss 4.552682 Test MSE 2.868539280997581 Test RE 0.8095402768418511\n",
      "43 Train Loss 4.489561 Test MSE 2.8750568872023137 Test RE 0.8104594329985794\n",
      "44 Train Loss 4.437496 Test MSE 2.83073205145153 Test RE 0.8041877280012628\n",
      "45 Train Loss 4.39649 Test MSE 2.857714041687903 Test RE 0.8080113190941033\n",
      "46 Train Loss 4.2781453 Test MSE 2.8196653013011144 Test RE 0.8026142021547343\n",
      "47 Train Loss 4.2145863 Test MSE 2.8164378255434994 Test RE 0.8021547221640514\n",
      "48 Train Loss 4.130807 Test MSE 2.723582414197501 Test RE 0.7888207403893027\n",
      "49 Train Loss 3.977015 Test MSE 2.617858100225858 Test RE 0.7733589418153572\n",
      "50 Train Loss 3.9100327 Test MSE 2.6474551230198307 Test RE 0.7777183817569863\n",
      "51 Train Loss 3.8423858 Test MSE 2.768986769080416 Test RE 0.7953687078680105\n",
      "52 Train Loss 3.7733545 Test MSE 2.7273376425187887 Test RE 0.789364359266848\n",
      "53 Train Loss 3.7295337 Test MSE 2.694702031645128 Test RE 0.7846273369589939\n",
      "54 Train Loss 3.6353931 Test MSE 2.6710503876872123 Test RE 0.7811763752946389\n",
      "55 Train Loss 3.5929904 Test MSE 2.671211398525742 Test RE 0.7811999195842545\n",
      "56 Train Loss 3.517898 Test MSE 2.650386667789464 Test RE 0.7781488490087314\n",
      "57 Train Loss 3.425457 Test MSE 2.573490386489661 Test RE 0.7667774554448702\n",
      "58 Train Loss 3.374157 Test MSE 2.5438957286803934 Test RE 0.7623558080406937\n",
      "59 Train Loss 3.3570795 Test MSE 2.535692483935805 Test RE 0.7611256394912623\n",
      "60 Train Loss 3.2745287 Test MSE 2.4632240871292805 Test RE 0.7501705688722502\n",
      "61 Train Loss 3.2029524 Test MSE 2.3934334083936304 Test RE 0.7394668928101723\n",
      "62 Train Loss 3.1304243 Test MSE 2.353864687741392 Test RE 0.7333289110836536\n",
      "63 Train Loss 3.0812507 Test MSE 2.342203912769374 Test RE 0.7315102423714455\n",
      "64 Train Loss 3.022794 Test MSE 2.2957177859167066 Test RE 0.72421465650589\n",
      "65 Train Loss 3.0062764 Test MSE 2.2886703409644022 Test RE 0.7231021970458975\n",
      "66 Train Loss 2.993839 Test MSE 2.3040224081033833 Test RE 0.7255233756868004\n",
      "67 Train Loss 2.9615755 Test MSE 2.301637478785328 Test RE 0.7251477782173067\n",
      "68 Train Loss 2.9321816 Test MSE 2.2908727894624303 Test RE 0.7234500436436159\n",
      "69 Train Loss 2.912386 Test MSE 2.2644737811921365 Test RE 0.7192696056526495\n",
      "70 Train Loss 2.8733864 Test MSE 2.229329745244374 Test RE 0.7136663430462432\n",
      "71 Train Loss 2.8432672 Test MSE 2.2176365864627647 Test RE 0.7117922404421976\n",
      "72 Train Loss 2.830749 Test MSE 2.2147073490208724 Test RE 0.7113219881334545\n",
      "73 Train Loss 2.8177834 Test MSE 2.227810296544638 Test RE 0.7134230940982246\n",
      "74 Train Loss 2.7940955 Test MSE 2.2515319623905254 Test RE 0.7172112918779244\n",
      "75 Train Loss 2.7663026 Test MSE 2.233913248438549 Test RE 0.7143996155364124\n",
      "76 Train Loss 2.751596 Test MSE 2.2262188133638094 Test RE 0.7131682241697417\n",
      "77 Train Loss 2.7362933 Test MSE 2.2230376248725667 Test RE 0.712658495837058\n",
      "78 Train Loss 2.711368 Test MSE 2.2509394228376776 Test RE 0.717116910801087\n",
      "79 Train Loss 2.686284 Test MSE 2.2542881160353407 Test RE 0.7176501352908199\n",
      "80 Train Loss 2.673998 Test MSE 2.2353033451497812 Test RE 0.714621855615157\n",
      "81 Train Loss 2.6462862 Test MSE 2.2361566290638173 Test RE 0.7147582391520828\n",
      "82 Train Loss 2.6316538 Test MSE 2.237465117670077 Test RE 0.7149673292095579\n",
      "83 Train Loss 2.6274047 Test MSE 2.236448513201913 Test RE 0.7148048861047921\n",
      "84 Train Loss 2.6252491 Test MSE 2.2325113357538413 Test RE 0.71417541635093\n",
      "85 Train Loss 2.6205225 Test MSE 2.2400803230593156 Test RE 0.7153850430665164\n",
      "86 Train Loss 2.6028392 Test MSE 2.2447409493797825 Test RE 0.7161288578989182\n",
      "87 Train Loss 2.591771 Test MSE 2.2551484958151318 Test RE 0.7177870727030141\n",
      "88 Train Loss 2.5824711 Test MSE 2.2432583584695136 Test RE 0.7158923269299687\n",
      "89 Train Loss 2.5799637 Test MSE 2.240544398983981 Test RE 0.7154591421465865\n",
      "90 Train Loss 2.5752845 Test MSE 2.2438078213581467 Test RE 0.7159799967652855\n",
      "91 Train Loss 2.5688112 Test MSE 2.2419851812220326 Test RE 0.7156891432035694\n",
      "92 Train Loss 2.566988 Test MSE 2.2468855714763936 Test RE 0.7164708704409049\n",
      "93 Train Loss 2.5606985 Test MSE 2.246406959509405 Test RE 0.7163945581889826\n",
      "94 Train Loss 2.5523736 Test MSE 2.2422996832622553 Test RE 0.7157393392986363\n",
      "95 Train Loss 2.5431712 Test MSE 2.2305573187263295 Test RE 0.7138628050793635\n",
      "96 Train Loss 2.5376172 Test MSE 2.2348552811451774 Test RE 0.7145502294579162\n",
      "97 Train Loss 2.530876 Test MSE 2.2432570885486456 Test RE 0.715892124294652\n",
      "98 Train Loss 2.5250998 Test MSE 2.2264911551496387 Test RE 0.7132118451217518\n",
      "99 Train Loss 2.519837 Test MSE 2.222914507570307 Test RE 0.7126387611719058\n",
      "Training time: 149.83\n",
      "9\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.662766 Test MSE 7.631746362565873 Test RE 1.3204441123402884\n",
      "1 Train Loss 47.498394 Test MSE 8.960610371622705 Test RE 1.4307931658188957\n",
      "2 Train Loss 39.97751 Test MSE 8.968645935123428 Test RE 1.4314345648107019\n",
      "3 Train Loss 32.27592 Test MSE 8.741387476260941 Test RE 1.4131824845817833\n",
      "4 Train Loss 29.457561 Test MSE 8.641481203562732 Test RE 1.4050835687104983\n",
      "5 Train Loss 28.056862 Test MSE 8.979519896543998 Test RE 1.4323020675073042\n",
      "6 Train Loss 26.781696 Test MSE 9.03751365367315 Test RE 1.4369198473827827\n",
      "7 Train Loss 25.685751 Test MSE 9.079258743024225 Test RE 1.4402346550255516\n",
      "8 Train Loss 24.222542 Test MSE 9.122630850328655 Test RE 1.443670595698051\n",
      "9 Train Loss 23.265612 Test MSE 9.103808641198006 Test RE 1.4421805046838856\n",
      "10 Train Loss 22.567738 Test MSE 9.120543739677942 Test RE 1.4435054419895024\n",
      "11 Train Loss 21.861492 Test MSE 9.2498459904761 Test RE 1.453701743088619\n",
      "12 Train Loss 21.201576 Test MSE 9.057177397518 Test RE 1.4384822168693756\n",
      "13 Train Loss 20.490805 Test MSE 8.989370403423875 Test RE 1.4330874677457144\n",
      "14 Train Loss 19.999126 Test MSE 8.979839114277691 Test RE 1.4323275261154387\n",
      "15 Train Loss 19.544771 Test MSE 9.309268879088323 Test RE 1.4583637052965015\n",
      "16 Train Loss 18.777664 Test MSE 9.010807250483541 Test RE 1.4347951837684771\n",
      "17 Train Loss 18.116514 Test MSE 8.948840887192592 Test RE 1.4298532057922246\n",
      "18 Train Loss 17.265942 Test MSE 8.690638917979289 Test RE 1.4090743629457225\n",
      "19 Train Loss 16.61782 Test MSE 8.285279110706304 Test RE 1.375820042871086\n",
      "20 Train Loss 14.327534 Test MSE 6.6808868147870095 Test RE 1.2354498396446896\n",
      "21 Train Loss 13.220823 Test MSE 6.824472390209332 Test RE 1.2486554032718526\n",
      "22 Train Loss 12.039364 Test MSE 6.8527583797654925 Test RE 1.2512404332506126\n",
      "23 Train Loss 11.236828 Test MSE 6.492476026648494 Test RE 1.2179045069628553\n",
      "24 Train Loss 10.426979 Test MSE 6.271720833108015 Test RE 1.1970200356797014\n",
      "25 Train Loss 9.524543 Test MSE 5.855745325939865 Test RE 1.1566425116944477\n",
      "26 Train Loss 9.062454 Test MSE 6.067861478224424 Test RE 1.1774050363930233\n",
      "27 Train Loss 8.69661 Test MSE 5.9948858661968485 Test RE 1.1703035431281517\n",
      "28 Train Loss 8.282166 Test MSE 6.003147797995179 Test RE 1.1711097001769868\n",
      "29 Train Loss 7.6525373 Test MSE 6.034750924785428 Test RE 1.1741882639005043\n",
      "30 Train Loss 7.2598 Test MSE 6.095347808143105 Test RE 1.1800687406511208\n",
      "31 Train Loss 6.930204 Test MSE 6.226084396015058 Test RE 1.1926570012385953\n",
      "32 Train Loss 6.5322495 Test MSE 6.087460325919738 Test RE 1.1793049791267518\n",
      "33 Train Loss 6.150926 Test MSE 6.113005552278785 Test RE 1.181776787781197\n",
      "34 Train Loss 5.7724566 Test MSE 6.07932057370028 Test RE 1.1785162707963404\n",
      "35 Train Loss 5.4496284 Test MSE 6.003424180235009 Test RE 1.1711366585501228\n",
      "36 Train Loss 4.914871 Test MSE 5.891987966191556 Test RE 1.1602163620869947\n",
      "37 Train Loss 4.138604 Test MSE 5.857212545559396 Test RE 1.1567874071946265\n",
      "38 Train Loss 3.6634297 Test MSE 5.736500396977216 Test RE 1.1448051494770963\n",
      "39 Train Loss 3.202114 Test MSE 5.306355138204757 Test RE 1.101047909275817\n",
      "40 Train Loss 2.9564242 Test MSE 5.252988916928973 Test RE 1.0954972773240752\n",
      "41 Train Loss 2.6847854 Test MSE 5.297333238851916 Test RE 1.1001115066959672\n",
      "42 Train Loss 2.4876254 Test MSE 5.473959807712417 Test RE 1.1183013841327887\n",
      "43 Train Loss 2.3018458 Test MSE 5.465338078026203 Test RE 1.1174203499183764\n",
      "44 Train Loss 2.1809402 Test MSE 5.496833120934673 Test RE 1.1206353976485517\n",
      "45 Train Loss 2.0846505 Test MSE 5.481869793050519 Test RE 1.1191090767901444\n",
      "46 Train Loss 2.006535 Test MSE 5.455230712807816 Test RE 1.1163866167810559\n",
      "47 Train Loss 1.9259884 Test MSE 5.48094607871207 Test RE 1.1190147859103623\n",
      "48 Train Loss 1.8762335 Test MSE 5.48950292037085 Test RE 1.1198879470312353\n",
      "49 Train Loss 1.8223494 Test MSE 5.565391980288586 Test RE 1.1276022640950951\n",
      "50 Train Loss 1.7675798 Test MSE 5.661925983336872 Test RE 1.137339582703778\n",
      "51 Train Loss 1.712767 Test MSE 5.689085587895001 Test RE 1.140064162503528\n",
      "52 Train Loss 1.639569 Test MSE 5.7258588021142485 Test RE 1.143742811216407\n",
      "53 Train Loss 1.5892377 Test MSE 5.691532457548251 Test RE 1.1403093063384755\n",
      "54 Train Loss 1.5395832 Test MSE 5.751493056906952 Test RE 1.1463001789535887\n",
      "55 Train Loss 1.4896666 Test MSE 5.765057140404175 Test RE 1.1476510764282752\n",
      "56 Train Loss 1.4502933 Test MSE 5.806181550133368 Test RE 1.1517371247608816\n",
      "57 Train Loss 1.4240392 Test MSE 5.82152261662729 Test RE 1.1532576783208677\n",
      "58 Train Loss 1.3913596 Test MSE 5.839258655008081 Test RE 1.1550131182938064\n",
      "59 Train Loss 1.3655294 Test MSE 5.8517216985728995 Test RE 1.1562450645778373\n",
      "60 Train Loss 1.3377852 Test MSE 5.840930373182277 Test RE 1.1551784404998584\n",
      "61 Train Loss 1.3210049 Test MSE 5.807172584070971 Test RE 1.1518354132717072\n",
      "62 Train Loss 1.3021426 Test MSE 5.826529911536285 Test RE 1.153753550316891\n",
      "63 Train Loss 1.2770718 Test MSE 5.832528187690707 Test RE 1.154347278685121\n",
      "64 Train Loss 1.2626898 Test MSE 5.863259019554627 Test RE 1.1573843362567608\n",
      "65 Train Loss 1.2398683 Test MSE 5.865780805803344 Test RE 1.1576332048579046\n",
      "66 Train Loss 1.2287309 Test MSE 5.8688307562061635 Test RE 1.1579341251564967\n",
      "67 Train Loss 1.2195221 Test MSE 5.87986492710823 Test RE 1.15902214793863\n",
      "68 Train Loss 1.2082205 Test MSE 5.8726215928633145 Test RE 1.1583080352851762\n",
      "69 Train Loss 1.1986744 Test MSE 5.871238936628075 Test RE 1.1581716706241587\n",
      "70 Train Loss 1.1907417 Test MSE 5.880874910098494 Test RE 1.159121686142779\n",
      "71 Train Loss 1.1773956 Test MSE 5.854380360392215 Test RE 1.156507698011056\n",
      "72 Train Loss 1.1546397 Test MSE 5.885591637311253 Test RE 1.1595864269403127\n",
      "73 Train Loss 1.14105 Test MSE 5.881025200411914 Test RE 1.1591364971744027\n",
      "74 Train Loss 1.1301045 Test MSE 5.878678621149483 Test RE 1.1589052214227769\n",
      "75 Train Loss 1.1167107 Test MSE 5.8908582887266645 Test RE 1.160105131962607\n",
      "76 Train Loss 1.1036267 Test MSE 5.922915278117602 Test RE 1.1632573908249721\n",
      "77 Train Loss 1.0970899 Test MSE 5.922184747984852 Test RE 1.16318565074925\n",
      "78 Train Loss 1.0927852 Test MSE 5.954618186177674 Test RE 1.1663664530854316\n",
      "79 Train Loss 1.0850676 Test MSE 5.940034764840486 Test RE 1.1649373068164237\n",
      "80 Train Loss 1.076877 Test MSE 5.958166840025314 Test RE 1.1667139492801568\n",
      "81 Train Loss 1.0714502 Test MSE 5.9462962576570595 Test RE 1.165551135323483\n",
      "82 Train Loss 1.0627362 Test MSE 5.94887008551695 Test RE 1.1658033598425885\n",
      "83 Train Loss 1.056187 Test MSE 5.956596528540983 Test RE 1.1665601918330952\n",
      "84 Train Loss 1.050879 Test MSE 5.943611465073481 Test RE 1.165287978544132\n",
      "85 Train Loss 1.0456777 Test MSE 5.9643261998632875 Test RE 1.16731684904579\n",
      "86 Train Loss 1.0422845 Test MSE 5.952549460230508 Test RE 1.1661638286622225\n",
      "87 Train Loss 1.0369551 Test MSE 5.959370810966544 Test RE 1.1668318226777041\n",
      "88 Train Loss 1.0335053 Test MSE 5.972190802871096 Test RE 1.168086211663244\n",
      "89 Train Loss 1.0301685 Test MSE 5.978211926310783 Test RE 1.1686748917380678\n",
      "90 Train Loss 1.0237199 Test MSE 5.978622575415194 Test RE 1.168715029747759\n",
      "91 Train Loss 1.0172973 Test MSE 5.967855803420622 Test RE 1.1676621987283264\n",
      "92 Train Loss 1.01178 Test MSE 5.970004953644132 Test RE 1.167872429644544\n",
      "93 Train Loss 1.0068892 Test MSE 5.959203865975064 Test RE 1.1668154788304133\n",
      "94 Train Loss 1.0035853 Test MSE 5.95289070412826 Test RE 1.1661972547252757\n",
      "95 Train Loss 0.9975569 Test MSE 5.989305103290534 Test RE 1.1697586864402665\n",
      "96 Train Loss 0.9933858 Test MSE 6.00489215521014 Test RE 1.1712798346919815\n",
      "97 Train Loss 0.9887246 Test MSE 6.009666403804889 Test RE 1.1717453609589035\n",
      "98 Train Loss 0.98392653 Test MSE 6.032705751500187 Test RE 1.173989281208974\n",
      "99 Train Loss 0.97813 Test MSE 6.018157593072791 Test RE 1.1725728611041129\n",
      "Training time: 148.69\n",
      "0\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.555656 Test MSE 6.447700681192652 Test RE 1.2136976034231186\n",
      "1 Train Loss 43.870758 Test MSE 8.09722218638433 Test RE 1.360116435090362\n",
      "2 Train Loss 37.86563 Test MSE 7.8289560077864575 Test RE 1.3373958974187414\n",
      "3 Train Loss 29.697487 Test MSE 6.795446607304143 Test RE 1.2459971889757475\n",
      "4 Train Loss 21.11274 Test MSE 6.134269158266589 Test RE 1.1838303620436867\n",
      "5 Train Loss 16.071247 Test MSE 5.965306971330401 Test RE 1.1674128216635338\n",
      "6 Train Loss 13.181157 Test MSE 5.770556902796126 Test RE 1.1481983653323429\n",
      "7 Train Loss 10.955307 Test MSE 5.716617425198874 Test RE 1.1428194539483254\n",
      "8 Train Loss 9.259426 Test MSE 5.579382330089825 Test RE 1.1290186646304576\n",
      "9 Train Loss 8.011068 Test MSE 5.4720639272630995 Test RE 1.1181077081272748\n",
      "10 Train Loss 7.0758123 Test MSE 5.31359420931909 Test RE 1.1017986927558796\n",
      "11 Train Loss 6.48337 Test MSE 5.066906204328152 Test RE 1.0759187914748605\n",
      "12 Train Loss 5.8764896 Test MSE 4.879622078830534 Test RE 1.0558473983125363\n",
      "13 Train Loss 5.4353952 Test MSE 4.648558215687461 Test RE 1.030545561995293\n",
      "14 Train Loss 5.013376 Test MSE 4.471635869527477 Test RE 1.0107442419091108\n",
      "15 Train Loss 4.5137405 Test MSE 4.0926159841168674 Test RE 0.9669601096084195\n",
      "16 Train Loss 4.0847664 Test MSE 3.574508988020525 Test RE 0.9036833007658122\n",
      "17 Train Loss 3.6047392 Test MSE 3.293881516001794 Test RE 0.867485145543714\n",
      "18 Train Loss 3.0418987 Test MSE 2.8456128054359606 Test RE 0.8062987073567505\n",
      "19 Train Loss 2.595454 Test MSE 2.6216005898478536 Test RE 0.7739115413114752\n",
      "20 Train Loss 2.1375127 Test MSE 2.316724645392053 Test RE 0.7275205574720117\n",
      "21 Train Loss 1.8008548 Test MSE 2.0699218401254473 Test RE 0.6876778463818329\n",
      "22 Train Loss 1.5271088 Test MSE 1.9660951578389987 Test RE 0.670209110423238\n",
      "23 Train Loss 1.358592 Test MSE 1.8959344355388315 Test RE 0.6581421681854941\n",
      "24 Train Loss 1.196204 Test MSE 1.8158666883077785 Test RE 0.6440951680292228\n",
      "25 Train Loss 1.1048611 Test MSE 1.7492382844772751 Test RE 0.632168056657747\n",
      "26 Train Loss 1.0316513 Test MSE 1.7345796126336148 Test RE 0.6295136899400018\n",
      "27 Train Loss 0.95717657 Test MSE 1.6301679439827974 Test RE 0.6102731104158172\n",
      "28 Train Loss 0.9019857 Test MSE 1.5294281330362314 Test RE 0.5911158404845147\n",
      "29 Train Loss 0.8454275 Test MSE 1.3904887861562774 Test RE 0.5636270211236347\n",
      "30 Train Loss 0.76951826 Test MSE 1.0438633823201642 Test RE 0.48834853801912803\n",
      "31 Train Loss 0.6520391 Test MSE 0.7767527049089237 Test RE 0.42125924729512987\n",
      "32 Train Loss 0.52236307 Test MSE 0.5372315885043315 Test RE 0.3503392780056674\n",
      "33 Train Loss 0.37719625 Test MSE 0.3551286706194282 Test RE 0.2848399678616366\n",
      "34 Train Loss 0.28616482 Test MSE 0.2503773735857513 Test RE 0.23916939227896325\n",
      "35 Train Loss 0.20649518 Test MSE 0.14714259846136735 Test RE 0.18334846182984615\n",
      "36 Train Loss 0.1424618 Test MSE 0.0976396737211142 Test RE 0.1493554999790441\n",
      "37 Train Loss 0.11110364 Test MSE 0.057693183398051316 Test RE 0.1148075136990373\n",
      "38 Train Loss 0.08662247 Test MSE 0.031933387821529366 Test RE 0.08541429448075513\n",
      "39 Train Loss 0.062598914 Test MSE 0.021166440329875705 Test RE 0.06953956562849069\n",
      "40 Train Loss 0.05013276 Test MSE 0.01779025195850915 Test RE 0.06375277741670891\n",
      "41 Train Loss 0.04156122 Test MSE 0.0157550933891948 Test RE 0.05999548260964532\n",
      "42 Train Loss 0.034704868 Test MSE 0.015305854259588124 Test RE 0.05913394419738884\n",
      "43 Train Loss 0.029616874 Test MSE 0.012625168699119376 Test RE 0.05370647582274594\n",
      "44 Train Loss 0.025651071 Test MSE 0.011519018237683481 Test RE 0.051299814324439856\n",
      "45 Train Loss 0.023080094 Test MSE 0.010195143691317951 Test RE 0.04826193560603035\n",
      "46 Train Loss 0.019422824 Test MSE 0.008763964932130395 Test RE 0.04474642835961099\n",
      "47 Train Loss 0.017562086 Test MSE 0.008513925250759797 Test RE 0.04410349195878741\n",
      "48 Train Loss 0.015719116 Test MSE 0.007300882511898184 Test RE 0.0408409410177311\n",
      "49 Train Loss 0.01395469 Test MSE 0.006378163116957036 Test RE 0.038172962984891715\n",
      "50 Train Loss 0.012544872 Test MSE 0.0050463115021872175 Test RE 0.033954323962590474\n",
      "51 Train Loss 0.011597324 Test MSE 0.0050126351537740175 Test RE 0.0338408379302934\n",
      "52 Train Loss 0.010793589 Test MSE 0.00457316930478614 Test RE 0.03232337496102329\n",
      "53 Train Loss 0.009909028 Test MSE 0.004251880842938076 Test RE 0.031167258486459765\n",
      "54 Train Loss 0.008726705 Test MSE 0.004472268419393065 Test RE 0.031964799966118555\n",
      "55 Train Loss 0.007941407 Test MSE 0.004623123992608509 Test RE 0.03249943650526267\n",
      "56 Train Loss 0.0075994204 Test MSE 0.0043289387001275775 Test RE 0.03144841618794555\n",
      "57 Train Loss 0.007104386 Test MSE 0.0037760833082404505 Test RE 0.029371683778918904\n",
      "58 Train Loss 0.0067428295 Test MSE 0.003678546058119454 Test RE 0.028989862756677302\n",
      "59 Train Loss 0.0062231566 Test MSE 0.003214790289896088 Test RE 0.027100941842407092\n",
      "60 Train Loss 0.005824589 Test MSE 0.0030732284288378315 Test RE 0.026497535414061947\n",
      "61 Train Loss 0.005254676 Test MSE 0.0031993805384942313 Test RE 0.027035911094745332\n",
      "62 Train Loss 0.0049242503 Test MSE 0.00308956379652239 Test RE 0.02656786427687095\n",
      "63 Train Loss 0.004636801 Test MSE 0.003215841301563562 Test RE 0.02710537153701662\n",
      "64 Train Loss 0.004185619 Test MSE 0.0032772563624158353 Test RE 0.027362972118000144\n",
      "65 Train Loss 0.0040086596 Test MSE 0.0033408896170038964 Test RE 0.027627343259583048\n",
      "66 Train Loss 0.0037602782 Test MSE 0.0033236460176989343 Test RE 0.027555953420816286\n",
      "67 Train Loss 0.003513842 Test MSE 0.0036156996101147703 Test RE 0.028741155970012335\n",
      "68 Train Loss 0.003228129 Test MSE 0.0036983105889549198 Test RE 0.029067638521371165\n",
      "69 Train Loss 0.0030695682 Test MSE 0.0034380432751765907 Test RE 0.02802616856303906\n",
      "70 Train Loss 0.0029700052 Test MSE 0.003472683385828855 Test RE 0.028167003965505477\n",
      "71 Train Loss 0.0028007808 Test MSE 0.00354343359382602 Test RE 0.02845248541498703\n",
      "72 Train Loss 0.0026459193 Test MSE 0.003528044742378421 Test RE 0.028390634743457883\n",
      "73 Train Loss 0.0025652205 Test MSE 0.0037034432841999217 Test RE 0.029087802268735207\n",
      "74 Train Loss 0.0024312693 Test MSE 0.003567802607520268 Test RE 0.02855015494545629\n",
      "75 Train Loss 0.0023954362 Test MSE 0.0035032060652032027 Test RE 0.028290518185930785\n",
      "76 Train Loss 0.0023445443 Test MSE 0.0034435724124657085 Test RE 0.028048695661825086\n",
      "77 Train Loss 0.0022235583 Test MSE 0.003145222254344589 Test RE 0.026806105977262927\n",
      "78 Train Loss 0.002119543 Test MSE 0.003117173945530049 Test RE 0.026686313219869844\n",
      "79 Train Loss 0.0019844437 Test MSE 0.0030751314265244686 Test RE 0.02650573801699282\n",
      "80 Train Loss 0.0018335439 Test MSE 0.002972809410159815 Test RE 0.026061031057884505\n",
      "81 Train Loss 0.0018079241 Test MSE 0.0028467023361896386 Test RE 0.025502284664129727\n",
      "82 Train Loss 0.0017445764 Test MSE 0.002833396059403464 Test RE 0.025442612473176644\n",
      "83 Train Loss 0.0016718777 Test MSE 0.0028418167168082274 Test RE 0.025480391268567076\n",
      "84 Train Loss 0.0016164755 Test MSE 0.002762662123719963 Test RE 0.025123025956016728\n",
      "85 Train Loss 0.0015546286 Test MSE 0.0027509034955575905 Test RE 0.025069503788544202\n",
      "86 Train Loss 0.0014699089 Test MSE 0.0027407024213393053 Test RE 0.025022978457182987\n",
      "87 Train Loss 0.0014381437 Test MSE 0.0026421074381312993 Test RE 0.024568763349019085\n",
      "88 Train Loss 0.0013671349 Test MSE 0.0024956577621980574 Test RE 0.023878144427355977\n",
      "89 Train Loss 0.0013095299 Test MSE 0.0023753203832723286 Test RE 0.023295345611672173\n",
      "90 Train Loss 0.0012229498 Test MSE 0.0022829825119384845 Test RE 0.022838067522364072\n",
      "91 Train Loss 0.0011983743 Test MSE 0.0022439218918968843 Test RE 0.022641850999426397\n",
      "92 Train Loss 0.0011855104 Test MSE 0.0022531864315180616 Test RE 0.022688543857879714\n",
      "93 Train Loss 0.001132921 Test MSE 0.0021752536715953486 Test RE 0.022292717649638062\n",
      "94 Train Loss 0.0010726278 Test MSE 0.0021071164221286606 Test RE 0.021940793308152875\n",
      "95 Train Loss 0.0010636464 Test MSE 0.0020774176459503655 Test RE 0.021785622223328388\n",
      "96 Train Loss 0.0010519794 Test MSE 0.0020972448196648896 Test RE 0.02188933790236367\n",
      "97 Train Loss 0.000985791 Test MSE 0.0020219562518011664 Test RE 0.021492846531134768\n",
      "98 Train Loss 0.0009330007 Test MSE 0.0020780506329726557 Test RE 0.021788940998894727\n",
      "99 Train Loss 0.0009032327 Test MSE 0.0019506974884445573 Test RE 0.02111071888792443\n",
      "Training time: 149.90\n",
      "1\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.38022 Test MSE 8.237771036219534 Test RE 1.3718698724788874\n",
      "1 Train Loss 51.376236 Test MSE 8.750176972516364 Test RE 1.41389278608588\n",
      "2 Train Loss 43.690285 Test MSE 9.04309517003113 Test RE 1.4373634956037844\n",
      "3 Train Loss 39.121773 Test MSE 8.805602492675474 Test RE 1.4183636692711543\n",
      "4 Train Loss 35.64737 Test MSE 9.163132140079142 Test RE 1.44687174285372\n",
      "5 Train Loss 32.436546 Test MSE 9.086404875187915 Test RE 1.4408013358027594\n",
      "6 Train Loss 28.885391 Test MSE 9.083077832896684 Test RE 1.4405375325755343\n",
      "7 Train Loss 25.063381 Test MSE 8.877763355894503 Test RE 1.4241634719762775\n",
      "8 Train Loss 21.276207 Test MSE 8.542372803264298 Test RE 1.3970029419499175\n",
      "9 Train Loss 18.359074 Test MSE 8.50779408887908 Test RE 1.3941726071513103\n",
      "10 Train Loss 15.829723 Test MSE 8.422729351890778 Test RE 1.3871853165854198\n",
      "11 Train Loss 13.410697 Test MSE 8.153439652988261 Test RE 1.364829782547388\n",
      "12 Train Loss 11.582718 Test MSE 8.08954662297207 Test RE 1.3594716377213698\n",
      "13 Train Loss 9.395 Test MSE 7.575191079657718 Test RE 1.315542419277616\n",
      "14 Train Loss 7.8616724 Test MSE 7.616693977032474 Test RE 1.3191412883827436\n",
      "15 Train Loss 6.388238 Test MSE 7.418901977176616 Test RE 1.3019007487268637\n",
      "16 Train Loss 5.3146553 Test MSE 7.0613014963768315 Test RE 1.2701366205082123\n",
      "17 Train Loss 4.414148 Test MSE 6.958580052993762 Test RE 1.2608643750951751\n",
      "18 Train Loss 3.5557761 Test MSE 6.784555460732996 Test RE 1.2449983010073937\n",
      "19 Train Loss 2.7906494 Test MSE 6.721854492830896 Test RE 1.2392319840095845\n",
      "20 Train Loss 2.3560853 Test MSE 6.498959034332196 Test RE 1.2185124194284034\n",
      "21 Train Loss 2.012294 Test MSE 6.303727606373655 Test RE 1.2000705535044442\n",
      "22 Train Loss 1.7643379 Test MSE 6.175585931683602 Test RE 1.1878104585463105\n",
      "23 Train Loss 1.572862 Test MSE 6.02353134581321 Test RE 1.17309625306856\n",
      "24 Train Loss 1.4690979 Test MSE 6.008519412192686 Test RE 1.1716335372615607\n",
      "25 Train Loss 1.3742166 Test MSE 5.959987670207451 Test RE 1.166892210962825\n",
      "26 Train Loss 1.2931695 Test MSE 5.864871671201654 Test RE 1.1575434908692583\n",
      "27 Train Loss 1.2435164 Test MSE 5.850248683019463 Test RE 1.156099528422266\n",
      "28 Train Loss 1.1928604 Test MSE 5.817827195950453 Test RE 1.15289158433705\n",
      "29 Train Loss 1.1550107 Test MSE 5.8339160126057505 Test RE 1.1544846064934584\n",
      "30 Train Loss 1.122902 Test MSE 5.847739876020593 Test RE 1.1558516123279572\n",
      "31 Train Loss 1.092433 Test MSE 5.849654300566833 Test RE 1.156040797352424\n",
      "32 Train Loss 1.0616118 Test MSE 5.848041831409418 Test RE 1.1558814538671738\n",
      "33 Train Loss 1.033916 Test MSE 5.914336201201825 Test RE 1.1624146224788776\n",
      "34 Train Loss 1.0020603 Test MSE 5.92777884126759 Test RE 1.163734893420453\n",
      "35 Train Loss 0.9752887 Test MSE 5.920949718974514 Test RE 1.1630643574268937\n",
      "36 Train Loss 0.94650453 Test MSE 5.972086545036828 Test RE 1.1680760158511727\n",
      "37 Train Loss 0.92340374 Test MSE 5.977433475713565 Test RE 1.168598799982168\n",
      "38 Train Loss 0.90425605 Test MSE 6.008403589370861 Test RE 1.1716222447494546\n",
      "39 Train Loss 0.8848888 Test MSE 6.027762413341306 Test RE 1.1735081856936587\n",
      "40 Train Loss 0.8690197 Test MSE 6.059905932081391 Test RE 1.1766329379882343\n",
      "41 Train Loss 0.85379136 Test MSE 6.1524710649353676 Test RE 1.1855854210675882\n",
      "42 Train Loss 0.8364128 Test MSE 6.1772010733726175 Test RE 1.1879657763404072\n",
      "43 Train Loss 0.8205619 Test MSE 6.200861869866445 Test RE 1.19023875981164\n",
      "44 Train Loss 0.80518526 Test MSE 6.237733737900786 Test RE 1.1937722428091453\n",
      "45 Train Loss 0.7960475 Test MSE 6.252795949351601 Test RE 1.1952126704731099\n",
      "46 Train Loss 0.786582 Test MSE 6.242129278641509 Test RE 1.1941927761851934\n",
      "47 Train Loss 0.7804158 Test MSE 6.252215180700237 Test RE 1.1951571626510629\n",
      "48 Train Loss 0.7724731 Test MSE 6.271098869143648 Test RE 1.1969606802168573\n",
      "49 Train Loss 0.7667996 Test MSE 6.2807912243560615 Test RE 1.19788530994604\n",
      "50 Train Loss 0.7593721 Test MSE 6.272286204587662 Test RE 1.1970739878369787\n",
      "51 Train Loss 0.7548555 Test MSE 6.276363488453062 Test RE 1.1974630020947135\n",
      "52 Train Loss 0.74840736 Test MSE 6.308721003582816 Test RE 1.2005457677819973\n",
      "53 Train Loss 0.7431772 Test MSE 6.317403384693347 Test RE 1.2013716096591631\n",
      "54 Train Loss 0.7387018 Test MSE 6.311458482345821 Test RE 1.2008062098036736\n",
      "55 Train Loss 0.7331987 Test MSE 6.298724555637318 Test RE 1.199594231714473\n",
      "56 Train Loss 0.7280548 Test MSE 6.317082294741371 Test RE 1.2013410786616454\n",
      "57 Train Loss 0.72384995 Test MSE 6.333500038826884 Test RE 1.2029011748539495\n",
      "58 Train Loss 0.720304 Test MSE 6.34346299711207 Test RE 1.2038469192920909\n",
      "59 Train Loss 0.717264 Test MSE 6.355500223716873 Test RE 1.2049885756901644\n",
      "60 Train Loss 0.71430004 Test MSE 6.3663417119662 Test RE 1.2060158986814369\n",
      "61 Train Loss 0.7110916 Test MSE 6.388981909216506 Test RE 1.2081584325648838\n",
      "62 Train Loss 0.7077584 Test MSE 6.378615481701987 Test RE 1.2071778873517354\n",
      "63 Train Loss 0.703763 Test MSE 6.387296680798973 Test RE 1.20799908345175\n",
      "64 Train Loss 0.69940066 Test MSE 6.39397016093912 Test RE 1.2086299805045726\n",
      "65 Train Loss 0.6934258 Test MSE 6.403382136783813 Test RE 1.2095192099450685\n",
      "66 Train Loss 0.69020456 Test MSE 6.4263409673837915 Test RE 1.2116855885515263\n",
      "67 Train Loss 0.685418 Test MSE 6.448933572060311 Test RE 1.2138136358850058\n",
      "68 Train Loss 0.6815076 Test MSE 6.463335954199905 Test RE 1.2151682829753288\n",
      "69 Train Loss 0.6778264 Test MSE 6.482067927827359 Test RE 1.2169279030643922\n",
      "70 Train Loss 0.67400736 Test MSE 6.498642413006089 Test RE 1.2184827368503777\n",
      "71 Train Loss 0.67108667 Test MSE 6.493286595056399 Test RE 1.2179805306634353\n",
      "72 Train Loss 0.6675374 Test MSE 6.532918861327534 Test RE 1.2216918943159545\n",
      "73 Train Loss 0.66313076 Test MSE 6.55954160735494 Test RE 1.224178663634359\n",
      "74 Train Loss 0.6589941 Test MSE 6.562027407149626 Test RE 1.224410598654224\n",
      "75 Train Loss 0.65589595 Test MSE 6.571216350422784 Test RE 1.2252675825423975\n",
      "76 Train Loss 0.6527839 Test MSE 6.585870326528775 Test RE 1.2266330103429164\n",
      "77 Train Loss 0.6491157 Test MSE 6.604117247722829 Test RE 1.2283310998154147\n",
      "78 Train Loss 0.6455129 Test MSE 6.611759175360394 Test RE 1.2290415735334195\n",
      "79 Train Loss 0.6411499 Test MSE 6.636263958897149 Test RE 1.2313170302550276\n",
      "80 Train Loss 0.63670456 Test MSE 6.657415267606111 Test RE 1.2332777153449255\n",
      "81 Train Loss 0.633177 Test MSE 6.672304206993892 Test RE 1.2346560236950994\n",
      "82 Train Loss 0.62856925 Test MSE 6.696459987269488 Test RE 1.236888920635993\n",
      "83 Train Loss 0.6244693 Test MSE 6.696392899538069 Test RE 1.2368827248041883\n",
      "84 Train Loss 0.6199933 Test MSE 6.701413364303737 Test RE 1.2373462999534486\n",
      "85 Train Loss 0.61688745 Test MSE 6.705392754703237 Test RE 1.2377136219621718\n",
      "86 Train Loss 0.61340344 Test MSE 6.729761821511614 Test RE 1.239960661974746\n",
      "87 Train Loss 0.6101234 Test MSE 6.740687532372632 Test RE 1.2409667865558829\n",
      "88 Train Loss 0.60691607 Test MSE 6.740529853345005 Test RE 1.2409522720438537\n",
      "89 Train Loss 0.6036023 Test MSE 6.731745896371008 Test RE 1.240143431702729\n",
      "90 Train Loss 0.6006371 Test MSE 6.74538081302937 Test RE 1.2413987300295592\n",
      "91 Train Loss 0.59795725 Test MSE 6.764385956780915 Test RE 1.243146323458262\n",
      "92 Train Loss 0.59530157 Test MSE 6.761384470286254 Test RE 1.242870489042015\n",
      "93 Train Loss 0.59269774 Test MSE 6.759138651568257 Test RE 1.2426640598971355\n",
      "94 Train Loss 0.5898818 Test MSE 6.7832411536243455 Test RE 1.2448777043536337\n",
      "95 Train Loss 0.5875321 Test MSE 6.786049330877911 Test RE 1.245135359613139\n",
      "96 Train Loss 0.58491033 Test MSE 6.777464901142946 Test RE 1.2443475551793843\n",
      "97 Train Loss 0.5826117 Test MSE 6.7901028678894315 Test RE 1.245507184848067\n",
      "98 Train Loss 0.58045256 Test MSE 6.805753595103977 Test RE 1.2469417635234206\n",
      "99 Train Loss 0.5780711 Test MSE 6.816792752918137 Test RE 1.2479526441955933\n",
      "Training time: 150.15\n",
      "2\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 48.0599 Test MSE 7.805433994793066 Test RE 1.3353852903725427\n",
      "1 Train Loss 37.39752 Test MSE 7.337607472823775 Test RE 1.2947481464360846\n",
      "2 Train Loss 28.526035 Test MSE 6.5770583118490915 Test RE 1.2258121069790058\n",
      "3 Train Loss 20.660015 Test MSE 6.3598764979299185 Test RE 1.2054033701810924\n",
      "4 Train Loss 15.881596 Test MSE 6.20846722251558 Test RE 1.1909684496330741\n",
      "5 Train Loss 13.524803 Test MSE 5.849339250065031 Test RE 1.1560096659283565\n",
      "6 Train Loss 12.017352 Test MSE 6.076248521165378 Test RE 1.178218464376238\n",
      "7 Train Loss 11.341585 Test MSE 6.009049310082237 Test RE 1.1716851999432016\n",
      "8 Train Loss 10.610414 Test MSE 5.92260727366327 Test RE 1.1632271444767504\n",
      "9 Train Loss 9.864553 Test MSE 5.892111111943503 Test RE 1.1602284866000299\n",
      "10 Train Loss 9.100826 Test MSE 5.8735888455076966 Test RE 1.1584034211672054\n",
      "11 Train Loss 8.0822525 Test MSE 5.6577109124845695 Test RE 1.136916152629068\n",
      "12 Train Loss 6.8372526 Test MSE 5.583581104431459 Test RE 1.1294434072621986\n",
      "13 Train Loss 5.936032 Test MSE 5.44693804768823 Test RE 1.1155377671360065\n",
      "14 Train Loss 5.1464844 Test MSE 5.25615452999712 Test RE 1.0958273178248708\n",
      "15 Train Loss 4.554694 Test MSE 5.266462256968451 Test RE 1.0969012927552395\n",
      "16 Train Loss 4.091967 Test MSE 5.100795559319755 Test RE 1.0795108679074468\n",
      "17 Train Loss 3.5560043 Test MSE 4.625223375096469 Test RE 1.027955740609386\n",
      "18 Train Loss 3.171955 Test MSE 4.428735252694263 Test RE 1.0058840457001907\n",
      "19 Train Loss 2.8612099 Test MSE 4.229497358022639 Test RE 0.9829975587761322\n",
      "20 Train Loss 2.5655258 Test MSE 3.705536332166483 Test RE 0.9200969650600144\n",
      "21 Train Loss 2.2330236 Test MSE 3.3404621599323643 Test RE 0.8735974115133063\n",
      "22 Train Loss 2.0239182 Test MSE 3.126345817755234 Test RE 0.8451359345670135\n",
      "23 Train Loss 1.8508525 Test MSE 2.8800963759327707 Test RE 0.8111694212064194\n",
      "24 Train Loss 1.6713097 Test MSE 2.5600295981402987 Test RE 0.7647694896851288\n",
      "25 Train Loss 1.4925684 Test MSE 2.3454736290727856 Test RE 0.7320206583915431\n",
      "26 Train Loss 1.3752131 Test MSE 2.091233105898308 Test RE 0.6912088388222618\n",
      "27 Train Loss 1.2540017 Test MSE 1.9381028700449903 Test RE 0.6654209540108412\n",
      "28 Train Loss 1.1733999 Test MSE 1.7707708338701573 Test RE 0.636047046584076\n",
      "29 Train Loss 1.0661006 Test MSE 1.3987799737569577 Test RE 0.5653049173704179\n",
      "30 Train Loss 0.8093555 Test MSE 1.1782795867767637 Test RE 0.518838550269183\n",
      "31 Train Loss 0.61403054 Test MSE 0.9218127892922968 Test RE 0.4589120113971314\n",
      "32 Train Loss 0.48647586 Test MSE 0.7763285612675082 Test RE 0.4211442178733921\n",
      "33 Train Loss 0.3816404 Test MSE 0.6228297623620539 Test RE 0.377218287402321\n",
      "34 Train Loss 0.2996347 Test MSE 0.5170107318234003 Test RE 0.34368283274687006\n",
      "35 Train Loss 0.2595262 Test MSE 0.5035722022497724 Test RE 0.33918679368337457\n",
      "36 Train Loss 0.22234024 Test MSE 0.4677305845657109 Test RE 0.32689324386452623\n",
      "37 Train Loss 0.19127661 Test MSE 0.40337134670376174 Test RE 0.30357121079169314\n",
      "38 Train Loss 0.16860905 Test MSE 0.3894150381350415 Test RE 0.2982733278328359\n",
      "39 Train Loss 0.1577678 Test MSE 0.38227955777267036 Test RE 0.29552797486174937\n",
      "40 Train Loss 0.14820307 Test MSE 0.3497316668723963 Test RE 0.2826672795497992\n",
      "41 Train Loss 0.13929844 Test MSE 0.3748590904927153 Test RE 0.292645657327049\n",
      "42 Train Loss 0.13354242 Test MSE 0.3766523208291312 Test RE 0.29334479331680074\n",
      "43 Train Loss 0.12946284 Test MSE 0.38510831417153446 Test RE 0.2966193696709347\n",
      "44 Train Loss 0.12542306 Test MSE 0.39111959887589837 Test RE 0.2989254210951634\n",
      "45 Train Loss 0.120136745 Test MSE 0.3992976244779211 Test RE 0.3020344097865261\n",
      "46 Train Loss 0.11803757 Test MSE 0.4093577772018456 Test RE 0.3058155631499758\n",
      "47 Train Loss 0.11628379 Test MSE 0.4128290149815429 Test RE 0.30710944060616163\n",
      "48 Train Loss 0.11442591 Test MSE 0.4267486557180286 Test RE 0.31224402826443826\n",
      "49 Train Loss 0.11229378 Test MSE 0.43451550269687633 Test RE 0.31507264456017864\n",
      "50 Train Loss 0.11042103 Test MSE 0.4405038886775371 Test RE 0.31723634210004237\n",
      "51 Train Loss 0.10850212 Test MSE 0.45171559386384447 Test RE 0.32124812528236435\n",
      "52 Train Loss 0.10697021 Test MSE 0.4537353756148154 Test RE 0.32196553178279946\n",
      "53 Train Loss 0.105994426 Test MSE 0.46364851223335546 Test RE 0.3254636536794413\n",
      "54 Train Loss 0.10478037 Test MSE 0.46848607721350477 Test RE 0.32715714129227375\n",
      "55 Train Loss 0.10358986 Test MSE 0.47556967089864455 Test RE 0.3296211993735933\n",
      "56 Train Loss 0.10215103 Test MSE 0.4744797113923224 Test RE 0.32924325280432987\n",
      "57 Train Loss 0.10096195 Test MSE 0.48122075916738305 Test RE 0.33157382343104597\n",
      "58 Train Loss 0.09998734 Test MSE 0.4753441296031048 Test RE 0.32954302785279144\n",
      "59 Train Loss 0.09898561 Test MSE 0.4756702274341557 Test RE 0.3296560458071891\n",
      "60 Train Loss 0.09804716 Test MSE 0.4759360115087069 Test RE 0.32974813175899104\n",
      "61 Train Loss 0.097227566 Test MSE 0.48047641031555777 Test RE 0.331317286172814\n",
      "62 Train Loss 0.096799806 Test MSE 0.4799012478588374 Test RE 0.3311189222958513\n",
      "63 Train Loss 0.09614673 Test MSE 0.48660860360457364 Test RE 0.3334248403815024\n",
      "64 Train Loss 0.0952789 Test MSE 0.4841567078087405 Test RE 0.33258375846980875\n",
      "65 Train Loss 0.09397884 Test MSE 0.4827477681927658 Test RE 0.3320994815483009\n",
      "66 Train Loss 0.0931237 Test MSE 0.4861741222683315 Test RE 0.33327595355479117\n",
      "67 Train Loss 0.09219212 Test MSE 0.4879131457019755 Test RE 0.33387147819622154\n",
      "68 Train Loss 0.0912875 Test MSE 0.4943285217281366 Test RE 0.3360592817251924\n",
      "69 Train Loss 0.09057054 Test MSE 0.4967976083539018 Test RE 0.33689751570763343\n",
      "70 Train Loss 0.089685544 Test MSE 0.5015018568964699 Test RE 0.3384888232004981\n",
      "71 Train Loss 0.0892687 Test MSE 0.5037251424172856 Test RE 0.3392382970692278\n",
      "72 Train Loss 0.088279285 Test MSE 0.5057522861238375 Test RE 0.33992021092101093\n",
      "73 Train Loss 0.08769322 Test MSE 0.5064993446732015 Test RE 0.34017117033388805\n",
      "74 Train Loss 0.08675957 Test MSE 0.5077960601373357 Test RE 0.3406063369914024\n",
      "75 Train Loss 0.08607354 Test MSE 0.5113223288849567 Test RE 0.34178692074232137\n",
      "76 Train Loss 0.085482344 Test MSE 0.5167634013245833 Test RE 0.34360061645063056\n",
      "77 Train Loss 0.08478628 Test MSE 0.521832952919851 Test RE 0.3452818982301181\n",
      "78 Train Loss 0.084306255 Test MSE 0.5239665285567425 Test RE 0.34598704110324796\n",
      "79 Train Loss 0.08369875 Test MSE 0.5214463368299666 Test RE 0.3451539681414259\n",
      "80 Train Loss 0.08337854 Test MSE 0.5196858936390681 Test RE 0.34457084230087237\n",
      "81 Train Loss 0.08283307 Test MSE 0.5236920834104721 Test RE 0.34589641804234056\n",
      "82 Train Loss 0.08240716 Test MSE 0.5277874295912287 Test RE 0.3472462636478076\n",
      "83 Train Loss 0.08215055 Test MSE 0.5273316396356622 Test RE 0.34709629271708153\n",
      "84 Train Loss 0.08159321 Test MSE 0.5290243259850153 Test RE 0.3476529200765474\n",
      "85 Train Loss 0.081284344 Test MSE 0.5292989985402461 Test RE 0.34774316008970163\n",
      "86 Train Loss 0.08075186 Test MSE 0.5286149705457676 Test RE 0.3475183883094847\n",
      "87 Train Loss 0.080550864 Test MSE 0.5301080358045958 Test RE 0.3480088225520613\n",
      "88 Train Loss 0.08024157 Test MSE 0.5312002813605377 Test RE 0.3483671603515916\n",
      "89 Train Loss 0.07977724 Test MSE 0.53083780105114 Test RE 0.3482482807218746\n",
      "90 Train Loss 0.07951043 Test MSE 0.5279630732861532 Test RE 0.34730403931641257\n",
      "91 Train Loss 0.07920087 Test MSE 0.5306645284893069 Test RE 0.34819143963356325\n",
      "92 Train Loss 0.07890019 Test MSE 0.5288320467776902 Test RE 0.3475897353611019\n",
      "93 Train Loss 0.078596696 Test MSE 0.5285343106876031 Test RE 0.3474918738756922\n",
      "94 Train Loss 0.07822183 Test MSE 0.5302776978263853 Test RE 0.3480645085188155\n",
      "95 Train Loss 0.077814825 Test MSE 0.5338293254556084 Test RE 0.3492281747678739\n",
      "96 Train Loss 0.07747507 Test MSE 0.534395294522133 Test RE 0.34941325263298556\n",
      "97 Train Loss 0.0770184 Test MSE 0.5350971777201138 Test RE 0.3496426397726312\n",
      "98 Train Loss 0.076445386 Test MSE 0.5332506766938283 Test RE 0.34903884904833415\n",
      "99 Train Loss 0.07618308 Test MSE 0.5320891491168048 Test RE 0.34865850329556825\n",
      "Training time: 149.96\n",
      "3\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.19115 Test MSE 8.049596602615358 Test RE 1.3561106249543418\n",
      "1 Train Loss 47.910355 Test MSE 8.75337782976005 Test RE 1.4141513668653378\n",
      "2 Train Loss 41.76848 Test MSE 8.820031979235528 Test RE 1.4195253093755935\n",
      "3 Train Loss 37.76526 Test MSE 9.057838856773486 Test RE 1.4385347431677329\n",
      "4 Train Loss 34.092026 Test MSE 9.416215410929382 Test RE 1.46671675391927\n",
      "5 Train Loss 30.99997 Test MSE 9.164320865436727 Test RE 1.446965590531887\n",
      "6 Train Loss 28.880375 Test MSE 9.46949532332672 Test RE 1.4708604732357304\n",
      "7 Train Loss 26.297066 Test MSE 9.365717656545211 Test RE 1.4627785756063072\n",
      "8 Train Loss 24.042583 Test MSE 9.380541207435298 Test RE 1.463935721291146\n",
      "9 Train Loss 20.94423 Test MSE 9.459966172272578 Test RE 1.4701202236757995\n",
      "10 Train Loss 19.32472 Test MSE 9.411046626387954 Test RE 1.4663141408095193\n",
      "11 Train Loss 17.320335 Test MSE 9.33647329364209 Test RE 1.4604930340806224\n",
      "12 Train Loss 15.822512 Test MSE 9.339874829789728 Test RE 1.4607590589107284\n",
      "13 Train Loss 14.224129 Test MSE 9.10521374423765 Test RE 1.4422917951396963\n",
      "14 Train Loss 12.997601 Test MSE 9.042208005717635 Test RE 1.437292988280164\n",
      "15 Train Loss 11.938351 Test MSE 8.868796230374702 Test RE 1.4234440408238862\n",
      "16 Train Loss 10.849113 Test MSE 8.759033029303806 Test RE 1.4146081057982296\n",
      "17 Train Loss 9.62687 Test MSE 8.03493380748856 Test RE 1.354874945911737\n",
      "18 Train Loss 8.588462 Test MSE 7.844675569212799 Test RE 1.3387378857052754\n",
      "19 Train Loss 7.8224287 Test MSE 7.635444110267901 Test RE 1.3207639655988623\n",
      "20 Train Loss 7.1731863 Test MSE 7.363711928942277 Test RE 1.297049215884137\n",
      "21 Train Loss 6.6718206 Test MSE 7.352409994761448 Test RE 1.2960534684876313\n",
      "22 Train Loss 6.399182 Test MSE 7.406844879924256 Test RE 1.3008424029722034\n",
      "23 Train Loss 6.1368217 Test MSE 7.171411436941459 Test RE 1.2800012094965736\n",
      "24 Train Loss 5.8651314 Test MSE 6.963543207951726 Test RE 1.26131394596889\n",
      "25 Train Loss 5.5175266 Test MSE 6.74819660754452 Test RE 1.2416578079908276\n",
      "26 Train Loss 5.208495 Test MSE 6.6147204334547745 Test RE 1.2293167727496264\n",
      "27 Train Loss 4.847158 Test MSE 6.39569378110858 Test RE 1.20879287449572\n",
      "28 Train Loss 4.531339 Test MSE 6.375662647711716 Test RE 1.2068984373252498\n",
      "29 Train Loss 4.0011253 Test MSE 6.315518095564406 Test RE 1.2011923349079277\n",
      "30 Train Loss 3.402213 Test MSE 6.265040436757612 Test RE 1.1963823559236328\n",
      "31 Train Loss 2.78983 Test MSE 6.01551906402933 Test RE 1.1723157885129023\n",
      "32 Train Loss 2.2981546 Test MSE 5.842787131176935 Test RE 1.1553620342286484\n",
      "33 Train Loss 1.841855 Test MSE 5.561878090721352 Test RE 1.1272462338756573\n",
      "34 Train Loss 1.5615019 Test MSE 5.59361093289997 Test RE 1.1304573659379682\n",
      "35 Train Loss 1.3870411 Test MSE 5.538980735313653 Test RE 1.1249234953206024\n",
      "36 Train Loss 1.2966995 Test MSE 5.586526081785587 Test RE 1.1297412221164793\n",
      "37 Train Loss 1.221258 Test MSE 5.6423017406524885 Test RE 1.1353668616340042\n",
      "38 Train Loss 1.1586885 Test MSE 5.647760687410703 Test RE 1.1359159645652215\n",
      "39 Train Loss 1.0965061 Test MSE 5.673641419296222 Test RE 1.1385156439600694\n",
      "40 Train Loss 1.0592247 Test MSE 5.756132422396574 Test RE 1.1467624096670666\n",
      "41 Train Loss 1.0183179 Test MSE 5.780262565020661 Test RE 1.1491635532476698\n",
      "42 Train Loss 0.9909456 Test MSE 5.792568641580735 Test RE 1.1503861772768227\n",
      "43 Train Loss 0.9702689 Test MSE 5.815045358740931 Test RE 1.1526159195507868\n",
      "44 Train Loss 0.9501881 Test MSE 5.8861898673333775 Test RE 1.159645357446372\n",
      "45 Train Loss 0.92949474 Test MSE 5.920485428829636 Test RE 1.1630187557978444\n",
      "46 Train Loss 0.91076124 Test MSE 5.95128203581959 Test RE 1.1660396715092625\n",
      "47 Train Loss 0.8881323 Test MSE 6.002603645339938 Test RE 1.1710566216158615\n",
      "48 Train Loss 0.8670269 Test MSE 6.00286761608547 Test RE 1.1710823705499314\n",
      "49 Train Loss 0.84589946 Test MSE 6.080136918807909 Test RE 1.1785953950738794\n",
      "50 Train Loss 0.8285574 Test MSE 6.105377214678333 Test RE 1.1810391959037974\n",
      "51 Train Loss 0.8186267 Test MSE 6.112471066057399 Test RE 1.1817251227522803\n",
      "52 Train Loss 0.80730134 Test MSE 6.134145214252581 Test RE 1.1838184022303517\n",
      "53 Train Loss 0.79641056 Test MSE 6.154481635857775 Test RE 1.185779124446051\n",
      "54 Train Loss 0.78554106 Test MSE 6.18796607193471 Test RE 1.1890004587935894\n",
      "55 Train Loss 0.7739417 Test MSE 6.202958368832344 Test RE 1.1904399514766253\n",
      "56 Train Loss 0.76525164 Test MSE 6.221597033185162 Test RE 1.192227128382134\n",
      "57 Train Loss 0.7542107 Test MSE 6.225256325879094 Test RE 1.1925776868234348\n",
      "58 Train Loss 0.7443797 Test MSE 6.263771229830541 Test RE 1.1962611648713928\n",
      "59 Train Loss 0.73415416 Test MSE 6.28211010713665 Test RE 1.1980110733508988\n",
      "60 Train Loss 0.7266531 Test MSE 6.285049085179348 Test RE 1.1982912751043062\n",
      "61 Train Loss 0.7209041 Test MSE 6.294778991484251 Test RE 1.1992184558413497\n",
      "62 Train Loss 0.7146116 Test MSE 6.316835360161841 Test RE 1.2013175982367132\n",
      "63 Train Loss 0.7067693 Test MSE 6.333991578578295 Test RE 1.2029478522257953\n",
      "64 Train Loss 0.7006826 Test MSE 6.345911186440595 Test RE 1.204079202579076\n",
      "65 Train Loss 0.69498694 Test MSE 6.383248271216076 Test RE 1.207616194533445\n",
      "66 Train Loss 0.6879169 Test MSE 6.405604708878539 Test RE 1.2097290998406867\n",
      "67 Train Loss 0.68306637 Test MSE 6.425826300192485 Test RE 1.2116370673706436\n",
      "68 Train Loss 0.67733413 Test MSE 6.462786205524868 Test RE 1.2151166029014415\n",
      "69 Train Loss 0.67122597 Test MSE 6.4843663271418475 Test RE 1.217143631933308\n",
      "70 Train Loss 0.6664481 Test MSE 6.507546885213008 Test RE 1.2193172366472045\n",
      "71 Train Loss 0.66092193 Test MSE 6.508299910611741 Test RE 1.219387781685463\n",
      "72 Train Loss 0.6551682 Test MSE 6.531904285863647 Test RE 1.2215970250259318\n",
      "73 Train Loss 0.6502963 Test MSE 6.533128883633224 Test RE 1.2217115318234602\n",
      "74 Train Loss 0.64568853 Test MSE 6.555188927883687 Test RE 1.2237724354331643\n",
      "75 Train Loss 0.64127636 Test MSE 6.565229873625049 Test RE 1.2247093367849884\n",
      "76 Train Loss 0.6360879 Test MSE 6.584142420879073 Test RE 1.2264720866499808\n",
      "77 Train Loss 0.6322527 Test MSE 6.614927732460359 Test RE 1.2293360354040765\n",
      "78 Train Loss 0.62828565 Test MSE 6.6213260988814 Test RE 1.2299304365516475\n",
      "79 Train Loss 0.62355196 Test MSE 6.6401020534071025 Test RE 1.2316730459327452\n",
      "80 Train Loss 0.61898756 Test MSE 6.644814554615768 Test RE 1.2321100295220588\n",
      "81 Train Loss 0.6147865 Test MSE 6.664399885348325 Test RE 1.2339244915272303\n",
      "82 Train Loss 0.61153215 Test MSE 6.6790102137076355 Test RE 1.2352763140785905\n",
      "83 Train Loss 0.606069 Test MSE 6.6786117602978035 Test RE 1.2352394667475668\n",
      "84 Train Loss 0.60131013 Test MSE 6.702317171489752 Test RE 1.2374297364401061\n",
      "85 Train Loss 0.5973391 Test MSE 6.71487061221483 Test RE 1.2385880473241062\n",
      "86 Train Loss 0.5942025 Test MSE 6.735537092997775 Test RE 1.2404925956407284\n",
      "87 Train Loss 0.5910448 Test MSE 6.740260015834351 Test RE 1.2409274328375512\n",
      "88 Train Loss 0.5877242 Test MSE 6.744488601376715 Test RE 1.2413166273973357\n",
      "89 Train Loss 0.5835945 Test MSE 6.769871073372692 Test RE 1.2436502436084453\n",
      "90 Train Loss 0.57955503 Test MSE 6.7839744767904415 Test RE 1.244944993203264\n",
      "91 Train Loss 0.57620037 Test MSE 6.795430043357657 Test RE 1.2459956704115873\n",
      "92 Train Loss 0.5733995 Test MSE 6.803122429952992 Test RE 1.2467007008081599\n",
      "93 Train Loss 0.57120144 Test MSE 6.812034035785237 Test RE 1.247516978140382\n",
      "94 Train Loss 0.5678823 Test MSE 6.819473197493446 Test RE 1.2481979750462626\n",
      "95 Train Loss 0.56446695 Test MSE 6.82161027789873 Test RE 1.24839353930799\n",
      "96 Train Loss 0.5613979 Test MSE 6.835651058745393 Test RE 1.2496776503210434\n",
      "97 Train Loss 0.5587789 Test MSE 6.849198390777451 Test RE 1.2509153830606314\n",
      "98 Train Loss 0.55605143 Test MSE 6.855066096301533 Test RE 1.251451097702933\n",
      "99 Train Loss 0.55295074 Test MSE 6.8873730507367625 Test RE 1.2543965871449831\n",
      "Training time: 149.45\n",
      "4\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.16748 Test MSE 8.685136245054553 Test RE 1.4086281987936278\n",
      "1 Train Loss 41.832676 Test MSE 7.690508397055262 Test RE 1.3255178656210793\n",
      "2 Train Loss 34.702072 Test MSE 7.089353246053341 Test RE 1.272656994347403\n",
      "3 Train Loss 25.736305 Test MSE 6.739862265406969 Test RE 1.2408908180261427\n",
      "4 Train Loss 20.836073 Test MSE 6.3531318224704645 Test RE 1.2047640329891585\n",
      "5 Train Loss 18.759468 Test MSE 6.383088350368747 Test RE 1.2076010671087807\n",
      "6 Train Loss 16.261133 Test MSE 6.308966061015076 Test RE 1.2005690846956818\n",
      "7 Train Loss 13.967666 Test MSE 6.243840357825612 Test RE 1.1943564397604622\n",
      "8 Train Loss 11.174085 Test MSE 5.705833343608606 Test RE 1.1417410123574963\n",
      "9 Train Loss 8.713409 Test MSE 5.323079434417071 Test RE 1.1027816572485367\n",
      "10 Train Loss 6.684482 Test MSE 5.203208540058768 Test RE 1.0902941364426946\n",
      "11 Train Loss 5.224049 Test MSE 5.049836539751157 Test RE 1.074104956169688\n",
      "12 Train Loss 4.3003616 Test MSE 4.681729964994119 Test RE 1.034215972120707\n",
      "13 Train Loss 3.4420605 Test MSE 4.176022616967114 Test RE 0.9767636325617417\n",
      "14 Train Loss 2.9387972 Test MSE 3.775264906439088 Test RE 0.9287135367660367\n",
      "15 Train Loss 2.3866246 Test MSE 2.952495623094174 Test RE 0.8213016427871862\n",
      "16 Train Loss 2.0276742 Test MSE 2.4108349892466565 Test RE 0.742150190442447\n",
      "17 Train Loss 1.70591 Test MSE 2.0241414574883363 Test RE 0.6800306544117966\n",
      "18 Train Loss 1.459079 Test MSE 1.7674588159439655 Test RE 0.6354519427065792\n",
      "19 Train Loss 1.3113731 Test MSE 1.5588654751762578 Test RE 0.5967774159322783\n",
      "20 Train Loss 1.1990414 Test MSE 1.4496689530339826 Test RE 0.5754962250449667\n",
      "21 Train Loss 1.0872197 Test MSE 1.181844056646311 Test RE 0.5196227392879296\n",
      "22 Train Loss 0.85492784 Test MSE 0.6626878099367495 Test RE 0.3891011830050705\n",
      "23 Train Loss 0.6031025 Test MSE 0.5930543840438276 Test RE 0.36809110319682564\n",
      "24 Train Loss 0.4380832 Test MSE 0.4925114305537352 Test RE 0.3354410566675601\n",
      "25 Train Loss 0.32967195 Test MSE 0.49860750701017537 Test RE 0.33751063864740793\n",
      "26 Train Loss 0.26748142 Test MSE 0.4923276403714438 Test RE 0.33537846266288696\n",
      "27 Train Loss 0.21664687 Test MSE 0.4546782684065604 Test RE 0.3222998912406042\n",
      "28 Train Loss 0.18598674 Test MSE 0.4703274898349547 Test RE 0.3277994661188919\n",
      "29 Train Loss 0.17453307 Test MSE 0.4703683500477962 Test RE 0.32781370477743665\n",
      "30 Train Loss 0.1608675 Test MSE 0.4726106078643411 Test RE 0.32859412392300436\n",
      "31 Train Loss 0.14840901 Test MSE 0.4643805171854721 Test RE 0.3257204721969189\n",
      "32 Train Loss 0.14162526 Test MSE 0.4700885285342731 Test RE 0.327716182300118\n",
      "33 Train Loss 0.13085029 Test MSE 0.4678017905212829 Test RE 0.32691812556003497\n",
      "34 Train Loss 0.12402451 Test MSE 0.45045400576575517 Test RE 0.32079920765647246\n",
      "35 Train Loss 0.12014663 Test MSE 0.4545614395325812 Test RE 0.32225848135246515\n",
      "36 Train Loss 0.11472462 Test MSE 0.4528019459651671 Test RE 0.32163418567949226\n",
      "37 Train Loss 0.10939546 Test MSE 0.4418950148314526 Test RE 0.3177368687813682\n",
      "38 Train Loss 0.10570982 Test MSE 0.4450781048755994 Test RE 0.31887918792922126\n",
      "39 Train Loss 0.102928385 Test MSE 0.44817101147290095 Test RE 0.3199852365553129\n",
      "40 Train Loss 0.10085596 Test MSE 0.45673722456770244 Test RE 0.32302881521743126\n",
      "41 Train Loss 0.09863396 Test MSE 0.4602766811613587 Test RE 0.3242780454936236\n",
      "42 Train Loss 0.09626615 Test MSE 0.47164517239100895 Test RE 0.32825833099501156\n",
      "43 Train Loss 0.09460218 Test MSE 0.472341227389266 Test RE 0.3285004638817066\n",
      "44 Train Loss 0.0928243 Test MSE 0.4739328649735468 Test RE 0.3290534687148179\n",
      "45 Train Loss 0.09079811 Test MSE 0.4736788177275415 Test RE 0.3289652638874118\n",
      "46 Train Loss 0.08781768 Test MSE 0.4778310528890338 Test RE 0.33040396105661424\n",
      "47 Train Loss 0.08628334 Test MSE 0.4826142488155971 Test RE 0.33205355199117886\n",
      "48 Train Loss 0.08516828 Test MSE 0.4843349814144104 Test RE 0.33264498394485914\n",
      "49 Train Loss 0.08378232 Test MSE 0.4784582671486621 Test RE 0.33062073863297814\n",
      "50 Train Loss 0.08262353 Test MSE 0.48299293566194174 Test RE 0.33218380058604596\n",
      "51 Train Loss 0.08179298 Test MSE 0.4878904312631178 Test RE 0.3338637065347997\n",
      "52 Train Loss 0.08076268 Test MSE 0.48493473471850645 Test RE 0.33285087781191797\n",
      "53 Train Loss 0.079875775 Test MSE 0.4851434784613203 Test RE 0.33292250916513466\n",
      "54 Train Loss 0.07904489 Test MSE 0.48869941093298186 Test RE 0.3341403845209955\n",
      "55 Train Loss 0.07807249 Test MSE 0.48765192189698003 Test RE 0.33378209050976426\n",
      "56 Train Loss 0.07713927 Test MSE 0.48506714885227664 Test RE 0.3328963181044374\n",
      "57 Train Loss 0.07671666 Test MSE 0.48485312361741656 Test RE 0.33282286840397146\n",
      "58 Train Loss 0.075926214 Test MSE 0.4890581294806172 Test RE 0.3342629960520098\n",
      "59 Train Loss 0.07545041 Test MSE 0.4899415572755851 Test RE 0.33456476384694195\n",
      "60 Train Loss 0.075063445 Test MSE 0.4932740760654982 Test RE 0.33570066856977404\n",
      "61 Train Loss 0.07442273 Test MSE 0.49626713081821033 Test RE 0.3367175990831199\n",
      "62 Train Loss 0.07381995 Test MSE 0.49724404162057445 Test RE 0.3370488534782071\n",
      "63 Train Loss 0.07333598 Test MSE 0.5023951350730891 Test RE 0.3387901482613776\n",
      "64 Train Loss 0.07266003 Test MSE 0.5042568891851877 Test RE 0.33941730469860615\n",
      "65 Train Loss 0.072251335 Test MSE 0.5055378837098625 Test RE 0.33984815248316447\n",
      "66 Train Loss 0.07188753 Test MSE 0.505268532971553 Test RE 0.3397576048210613\n",
      "67 Train Loss 0.071472086 Test MSE 0.5042482909593464 Test RE 0.3394144109363754\n",
      "68 Train Loss 0.07110565 Test MSE 0.5068745125968078 Test RE 0.3402971307020659\n",
      "69 Train Loss 0.070599206 Test MSE 0.5113500035992858 Test RE 0.34179617002293633\n",
      "70 Train Loss 0.070168935 Test MSE 0.5089032242226819 Test RE 0.3409774522896906\n",
      "71 Train Loss 0.06971087 Test MSE 0.5097886102584598 Test RE 0.34127393840445114\n",
      "72 Train Loss 0.06915938 Test MSE 0.5107994587021146 Test RE 0.3416121230759807\n",
      "73 Train Loss 0.06878776 Test MSE 0.5135330691379785 Test RE 0.3425249944546455\n",
      "74 Train Loss 0.0683387 Test MSE 0.5143410637692176 Test RE 0.34279435352384724\n",
      "75 Train Loss 0.067884825 Test MSE 0.5161902856460179 Test RE 0.3434100287179203\n",
      "76 Train Loss 0.0676518 Test MSE 0.5159639886559588 Test RE 0.3433347452641634\n",
      "77 Train Loss 0.067370445 Test MSE 0.5164765321247956 Test RE 0.343505232260373\n",
      "78 Train Loss 0.06698705 Test MSE 0.5195789125594695 Test RE 0.3445353742821521\n",
      "79 Train Loss 0.06660313 Test MSE 0.5174374691800853 Test RE 0.34382464029892834\n",
      "80 Train Loss 0.06621045 Test MSE 0.5187968874474694 Test RE 0.34427599426577726\n",
      "81 Train Loss 0.06592248 Test MSE 0.5188037753488698 Test RE 0.34427827967967367\n",
      "82 Train Loss 0.06558604 Test MSE 0.521928113417868 Test RE 0.34531337928109423\n",
      "83 Train Loss 0.06519415 Test MSE 0.5249848962658022 Test RE 0.3463231035964489\n",
      "84 Train Loss 0.06497962 Test MSE 0.5251202422483566 Test RE 0.34636774337595305\n",
      "85 Train Loss 0.06471492 Test MSE 0.5246024706954496 Test RE 0.3461969409776173\n",
      "86 Train Loss 0.06444781 Test MSE 0.5236855020015899 Test RE 0.3458942445390716\n",
      "87 Train Loss 0.06422136 Test MSE 0.5227479411214423 Test RE 0.3455844763772496\n",
      "88 Train Loss 0.063858405 Test MSE 0.5262208888598319 Test RE 0.3467305449771389\n",
      "89 Train Loss 0.063536614 Test MSE 0.530655019684979 Test RE 0.34818832005525874\n",
      "90 Train Loss 0.063302055 Test MSE 0.5286239395568986 Test RE 0.3475213364695309\n",
      "91 Train Loss 0.06295265 Test MSE 0.5280468059611046 Test RE 0.3473315786887455\n",
      "92 Train Loss 0.062479183 Test MSE 0.531255573032039 Test RE 0.3483852903319986\n",
      "93 Train Loss 0.062181726 Test MSE 0.5320674511154821 Test RE 0.3486513942708824\n",
      "94 Train Loss 0.061849076 Test MSE 0.5306590948051171 Test RE 0.34818965699400256\n",
      "95 Train Loss 0.06138011 Test MSE 0.5325092254801028 Test RE 0.3487961064586138\n",
      "96 Train Loss 0.06100492 Test MSE 0.5340221427673207 Test RE 0.34929123908002896\n",
      "97 Train Loss 0.060548626 Test MSE 0.5355784037430719 Test RE 0.34979982554332506\n",
      "98 Train Loss 0.060088832 Test MSE 0.533985275622969 Test RE 0.34927918190883595\n",
      "99 Train Loss 0.059686925 Test MSE 0.5391052195019149 Test RE 0.3509496620796965\n",
      "Training time: 150.15\n",
      "5\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.491264 Test MSE 8.771168163289968 Test RE 1.415587695507243\n",
      "1 Train Loss 44.214085 Test MSE 9.260689758730697 Test RE 1.454553594435286\n",
      "2 Train Loss 39.224957 Test MSE 9.480826383432337 Test RE 1.471740215246557\n",
      "3 Train Loss 35.28823 Test MSE 9.669504066016064 Test RE 1.4863126033616565\n",
      "4 Train Loss 32.364376 Test MSE 9.720085825722272 Test RE 1.4901950281775524\n",
      "5 Train Loss 29.469452 Test MSE 9.884707835405187 Test RE 1.50276121903695\n",
      "6 Train Loss 25.551556 Test MSE 9.739319799009959 Test RE 1.4916686883238262\n",
      "7 Train Loss 22.318638 Test MSE 9.612760200873073 Test RE 1.4819450981493643\n",
      "8 Train Loss 19.696918 Test MSE 9.295256641486501 Test RE 1.457265733241256\n",
      "9 Train Loss 17.071552 Test MSE 9.192864005327834 Test RE 1.4492171939480392\n",
      "10 Train Loss 15.037942 Test MSE 9.208008864532955 Test RE 1.4504104650605187\n",
      "11 Train Loss 13.482567 Test MSE 8.843013790351275 Test RE 1.4213734908305165\n",
      "12 Train Loss 11.316563 Test MSE 8.604801081800735 Test RE 1.4020983487865475\n",
      "13 Train Loss 9.876945 Test MSE 8.519096416946354 Test RE 1.3950983563055492\n",
      "14 Train Loss 7.9522448 Test MSE 8.399951873227918 Test RE 1.3853083730721765\n",
      "15 Train Loss 6.174592 Test MSE 7.999882279428942 Test RE 1.3519164683079332\n",
      "16 Train Loss 4.408577 Test MSE 7.452345520648071 Test RE 1.304831857413931\n",
      "17 Train Loss 3.4676163 Test MSE 7.310866815304692 Test RE 1.2923867487757066\n",
      "18 Train Loss 2.7826898 Test MSE 7.3096931539899455 Test RE 1.2922830069588762\n",
      "19 Train Loss 2.3753817 Test MSE 7.301133164082942 Test RE 1.2915261236212814\n",
      "20 Train Loss 2.1321018 Test MSE 7.361190896807375 Test RE 1.296827168722099\n",
      "21 Train Loss 1.9320797 Test MSE 7.424872646746673 Test RE 1.3024245227220799\n",
      "22 Train Loss 1.8267044 Test MSE 7.4479219948185165 Test RE 1.3044445421596143\n",
      "23 Train Loss 1.71628 Test MSE 7.338143313601871 Test RE 1.2947954211227701\n",
      "24 Train Loss 1.6208892 Test MSE 7.242589428094693 Test RE 1.286337686180543\n",
      "25 Train Loss 1.5361263 Test MSE 7.195566861799961 Test RE 1.282155107722333\n",
      "26 Train Loss 1.4676883 Test MSE 7.09463911078136 Test RE 1.2731313563245001\n",
      "27 Train Loss 1.3961695 Test MSE 7.025130743004762 Test RE 1.266879375182158\n",
      "28 Train Loss 1.3417194 Test MSE 6.9150903378018755 Test RE 1.2569181262005846\n",
      "29 Train Loss 1.2633504 Test MSE 6.83898016900593 Test RE 1.249981923332842\n",
      "30 Train Loss 1.1919926 Test MSE 6.795931872680992 Test RE 1.246041676743543\n",
      "31 Train Loss 1.1293514 Test MSE 6.640858295880248 Test RE 1.2317431816734175\n",
      "32 Train Loss 1.070041 Test MSE 6.493053138393326 Test RE 1.2179586351085367\n",
      "33 Train Loss 1.0238689 Test MSE 6.406156105468464 Test RE 1.2097811656624589\n",
      "34 Train Loss 0.9860636 Test MSE 6.263478418400339 Test RE 1.196233203837741\n",
      "35 Train Loss 0.95407534 Test MSE 6.162584850743371 Test RE 1.1865594876784977\n",
      "36 Train Loss 0.9197528 Test MSE 6.067008384959103 Test RE 1.1773222665722936\n",
      "37 Train Loss 0.89727634 Test MSE 6.029753535673952 Test RE 1.1737019894029252\n",
      "38 Train Loss 0.8744924 Test MSE 6.03508518403309 Test RE 1.1742207820488026\n",
      "39 Train Loss 0.85681933 Test MSE 6.038328419758137 Test RE 1.1745362509421189\n",
      "40 Train Loss 0.8433039 Test MSE 6.066699317201796 Test RE 1.1772922783998934\n",
      "41 Train Loss 0.8253391 Test MSE 6.06742975229589 Test RE 1.1773631496981498\n",
      "42 Train Loss 0.81207967 Test MSE 6.101424462290736 Test RE 1.1806568189285194\n",
      "43 Train Loss 0.7993552 Test MSE 6.10903891105109 Test RE 1.1813933065968751\n",
      "44 Train Loss 0.784485 Test MSE 6.144917125700019 Test RE 1.1848573728740264\n",
      "45 Train Loss 0.77362674 Test MSE 6.17632613054761 Test RE 1.1878816412339062\n",
      "46 Train Loss 0.7642739 Test MSE 6.186252906269768 Test RE 1.1888358573928695\n",
      "47 Train Loss 0.7570103 Test MSE 6.187074071331999 Test RE 1.1889147579883894\n",
      "48 Train Loss 0.7477802 Test MSE 6.2031646192516385 Test RE 1.1904597425733563\n",
      "49 Train Loss 0.7401222 Test MSE 6.224749645176252 Test RE 1.1925291532077336\n",
      "50 Train Loss 0.733081 Test MSE 6.250203847095342 Test RE 1.1949649065421462\n",
      "51 Train Loss 0.7261795 Test MSE 6.250059064820682 Test RE 1.1949510661344196\n",
      "52 Train Loss 0.7197646 Test MSE 6.258012683439655 Test RE 1.19571115201475\n",
      "53 Train Loss 0.71442884 Test MSE 6.248022696339329 Test RE 1.1947563832600836\n",
      "54 Train Loss 0.70972073 Test MSE 6.250885255469133 Test RE 1.1950300433698273\n",
      "55 Train Loss 0.70484465 Test MSE 6.246679344678174 Test RE 1.1946279374838202\n",
      "56 Train Loss 0.7000581 Test MSE 6.255883537858554 Test RE 1.1955077280347717\n",
      "57 Train Loss 0.6944832 Test MSE 6.268685653670301 Test RE 1.1967303535998328\n",
      "58 Train Loss 0.68827486 Test MSE 6.297541552562773 Test RE 1.1994815747557757\n",
      "59 Train Loss 0.6824408 Test MSE 6.310063462164364 Test RE 1.200673495512987\n",
      "60 Train Loss 0.6763231 Test MSE 6.329003255814236 Test RE 1.2024740693035572\n",
      "61 Train Loss 0.6719329 Test MSE 6.334662261343001 Test RE 1.2030115383726177\n",
      "62 Train Loss 0.6671386 Test MSE 6.356180214861318 Test RE 1.2050530363632848\n",
      "63 Train Loss 0.6617733 Test MSE 6.366936331414054 Test RE 1.206072218605512\n",
      "64 Train Loss 0.6564997 Test MSE 6.3870840368937705 Test RE 1.2079789751184915\n",
      "65 Train Loss 0.65125823 Test MSE 6.400192007068297 Test RE 1.20921788450609\n",
      "66 Train Loss 0.6472311 Test MSE 6.425669894194736 Test RE 1.2116223215271709\n",
      "67 Train Loss 0.642907 Test MSE 6.443930943725538 Test RE 1.2133427489945838\n",
      "68 Train Loss 0.63833845 Test MSE 6.481791156758833 Test RE 1.2169019226184017\n",
      "69 Train Loss 0.6344152 Test MSE 6.475355254795595 Test RE 1.2162976292716474\n",
      "70 Train Loss 0.630386 Test MSE 6.501187707841385 Test RE 1.2187213323909263\n",
      "71 Train Loss 0.62689877 Test MSE 6.538687612007219 Test RE 1.2222311694062105\n",
      "72 Train Loss 0.6227793 Test MSE 6.566176049724081 Test RE 1.2247975857097795\n",
      "73 Train Loss 0.6184926 Test MSE 6.576657388488245 Test RE 1.225774744971847\n",
      "74 Train Loss 0.6146796 Test MSE 6.60922509064783 Test RE 1.228806023972413\n",
      "75 Train Loss 0.6103767 Test MSE 6.6222924211291385 Test RE 1.2300201818508825\n",
      "76 Train Loss 0.6069607 Test MSE 6.644774892739319 Test RE 1.2321063523789058\n",
      "77 Train Loss 0.6027566 Test MSE 6.675286039404318 Test RE 1.2349318748859257\n",
      "78 Train Loss 0.5994072 Test MSE 6.7116990332191655 Test RE 1.2382955067805443\n",
      "79 Train Loss 0.59508234 Test MSE 6.729745298890363 Test RE 1.2399591398248173\n",
      "80 Train Loss 0.59120303 Test MSE 6.741425650916829 Test RE 1.2410347288480785\n",
      "81 Train Loss 0.58719885 Test MSE 6.747136324923599 Test RE 1.2415602589723038\n",
      "82 Train Loss 0.58430797 Test MSE 6.757825488755577 Test RE 1.2425433418899094\n",
      "83 Train Loss 0.5801468 Test MSE 6.786740660139036 Test RE 1.2451987821248116\n",
      "84 Train Loss 0.5773863 Test MSE 6.809993443478457 Test RE 1.2473301129392593\n",
      "85 Train Loss 0.5735043 Test MSE 6.831223648320547 Test RE 1.249272880387966\n",
      "86 Train Loss 0.569351 Test MSE 6.8512275960381555 Test RE 1.2511006730719132\n",
      "87 Train Loss 0.5655567 Test MSE 6.859753162423873 Test RE 1.2518788566526993\n",
      "88 Train Loss 0.56166345 Test MSE 6.888008655005044 Test RE 1.254454467081578\n",
      "89 Train Loss 0.55685884 Test MSE 6.933990876537769 Test RE 1.2586346778121096\n",
      "90 Train Loss 0.5516859 Test MSE 6.94337587434462 Test RE 1.2594861563970892\n",
      "91 Train Loss 0.5477118 Test MSE 6.973770539853244 Test RE 1.262239849847592\n",
      "92 Train Loss 0.54408437 Test MSE 6.97326483324365 Test RE 1.2621940830272038\n",
      "93 Train Loss 0.54108864 Test MSE 6.973069091329683 Test RE 1.2621763677944295\n",
      "94 Train Loss 0.53882515 Test MSE 6.974987261530404 Test RE 1.262349957256217\n",
      "95 Train Loss 0.5349669 Test MSE 6.982396210992149 Test RE 1.2630202240508626\n",
      "96 Train Loss 0.53104705 Test MSE 6.995601251522661 Test RE 1.2642139657667981\n",
      "97 Train Loss 0.52784115 Test MSE 7.010069859137474 Test RE 1.26552064171547\n",
      "98 Train Loss 0.52544665 Test MSE 7.019182996971848 Test RE 1.2663429672062343\n",
      "99 Train Loss 0.52188575 Test MSE 7.024795442957772 Test RE 1.2668491415966001\n",
      "Training time: 150.24\n",
      "6\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "1 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "2 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "3 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "4 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "5 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "6 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "7 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "8 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "9 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "10 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "11 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "12 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "13 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "14 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "15 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "16 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "17 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "18 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "19 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "20 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "21 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "22 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "23 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "24 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "25 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "26 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "27 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "28 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "29 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "30 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "31 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "32 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "33 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "34 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "35 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "36 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "37 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "38 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "39 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "40 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "41 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "42 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "43 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "44 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "45 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "46 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "47 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "48 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "49 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "50 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "51 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "52 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "53 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "54 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "55 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "56 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "57 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "58 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "59 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "60 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "61 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "62 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "63 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "64 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "65 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "66 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "67 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "68 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "69 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "70 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "71 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "72 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "73 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "74 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "75 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "76 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "77 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "78 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "79 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "80 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "81 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "82 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "83 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "84 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "85 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "86 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "87 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "88 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "89 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "90 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "91 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "92 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "93 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "94 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "95 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "96 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "97 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "98 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "99 Train Loss 56.529495 Test MSE 8.642825972051781 Test RE 1.4051928924802588\n",
      "Training time: 87.85\n",
      "7\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 50.185715 Test MSE 8.617376868217772 Test RE 1.4031225474578402\n",
      "1 Train Loss 38.348366 Test MSE 8.457614834205422 Test RE 1.3900550884755867\n",
      "2 Train Loss 29.805626 Test MSE 7.493638821961521 Test RE 1.3084418874935089\n",
      "3 Train Loss 22.882774 Test MSE 6.511078238945091 Test RE 1.2196480261568305\n",
      "4 Train Loss 18.558643 Test MSE 6.014217460061091 Test RE 1.172188952123893\n",
      "5 Train Loss 14.637927 Test MSE 6.4527245247978025 Test RE 1.2141703486680602\n",
      "6 Train Loss 12.79858 Test MSE 6.170851519414807 Test RE 1.187355063488187\n",
      "7 Train Loss 10.909492 Test MSE 5.853553983036448 Test RE 1.1564260714816095\n",
      "8 Train Loss 9.607105 Test MSE 5.809225203772817 Test RE 1.1520389607936696\n",
      "9 Train Loss 8.131803 Test MSE 5.417862418117143 Test RE 1.1125564258036513\n",
      "10 Train Loss 6.8882504 Test MSE 5.177448033599199 Test RE 1.0875918251120897\n",
      "11 Train Loss 5.8622713 Test MSE 4.894882932867894 Test RE 1.0574971730402476\n",
      "12 Train Loss 5.0189147 Test MSE 4.256622363127403 Test RE 0.9861446466419227\n",
      "13 Train Loss 4.093249 Test MSE 3.8489513006122302 Test RE 0.9377331483694352\n",
      "14 Train Loss 3.1740613 Test MSE 3.4304856608730714 Test RE 0.8852906235311856\n",
      "15 Train Loss 2.5641727 Test MSE 2.814743002746753 Test RE 0.8019133330795932\n",
      "16 Train Loss 2.101785 Test MSE 2.3201284064185397 Test RE 0.7280548024969723\n",
      "17 Train Loss 1.6228997 Test MSE 1.749117388745911 Test RE 0.6321462106517455\n",
      "18 Train Loss 1.1726512 Test MSE 1.0780576889388445 Test RE 0.4962826139105651\n",
      "19 Train Loss 0.79591817 Test MSE 0.6428917573380478 Test RE 0.38324543375905895\n",
      "20 Train Loss 0.5037164 Test MSE 0.6017619495027241 Test RE 0.37078351892103906\n",
      "21 Train Loss 0.3177455 Test MSE 0.5163565907233205 Test RE 0.34346534381560817\n",
      "22 Train Loss 0.21746211 Test MSE 0.37783210133223427 Test RE 0.29380385312545204\n",
      "23 Train Loss 0.15309693 Test MSE 0.2625856436114903 Test RE 0.24493088366514043\n",
      "24 Train Loss 0.10411662 Test MSE 0.2001393535579479 Test RE 0.21383279204133515\n",
      "25 Train Loss 0.08280659 Test MSE 0.172369513063011 Test RE 0.1984441440319381\n",
      "26 Train Loss 0.066866115 Test MSE 0.15131124918721364 Test RE 0.18592751664009705\n",
      "27 Train Loss 0.05596523 Test MSE 0.16083443879111115 Test RE 0.1916891732441612\n",
      "28 Train Loss 0.04643441 Test MSE 0.14385051478600536 Test RE 0.18128579292909192\n",
      "29 Train Loss 0.04023385 Test MSE 0.15357091569425352 Test RE 0.1873106828898834\n",
      "30 Train Loss 0.034515627 Test MSE 0.15322748459895402 Test RE 0.1871011239464971\n",
      "31 Train Loss 0.029615745 Test MSE 0.1276794378077928 Test RE 0.17079239992458947\n",
      "32 Train Loss 0.025434803 Test MSE 0.1174141797303592 Test RE 0.16378281622783133\n",
      "33 Train Loss 0.023369297 Test MSE 0.11300829084387068 Test RE 0.1606805144702845\n",
      "34 Train Loss 0.020844847 Test MSE 0.10714509429168903 Test RE 0.1564567144615861\n",
      "35 Train Loss 0.0183235 Test MSE 0.09238369335218748 Test RE 0.14527996301239232\n",
      "36 Train Loss 0.015812254 Test MSE 0.0888415009296234 Test RE 0.1424675657420389\n",
      "37 Train Loss 0.014190484 Test MSE 0.07990506806924695 Test RE 0.13511240459328352\n",
      "38 Train Loss 0.013183481 Test MSE 0.07659198594437298 Test RE 0.1322816871908515\n",
      "39 Train Loss 0.011977163 Test MSE 0.07090067491645073 Test RE 0.12727211022231602\n",
      "40 Train Loss 0.010061083 Test MSE 0.05827522013116233 Test RE 0.11538517727594313\n",
      "41 Train Loss 0.009294019 Test MSE 0.05509012703493378 Test RE 0.11218762320346858\n",
      "42 Train Loss 0.008340699 Test MSE 0.055350249398811176 Test RE 0.11245217280791307\n",
      "43 Train Loss 0.007697109 Test MSE 0.05050717353708929 Test RE 0.10741986270616609\n",
      "44 Train Loss 0.007113101 Test MSE 0.05041801174985046 Test RE 0.10732500511488793\n",
      "45 Train Loss 0.0063785356 Test MSE 0.048090856443954895 Test RE 0.10481883199134613\n",
      "46 Train Loss 0.005619451 Test MSE 0.044241023612876344 Test RE 0.10053577813530137\n",
      "47 Train Loss 0.0052498863 Test MSE 0.04251930089319654 Test RE 0.09856009600970497\n",
      "48 Train Loss 0.0048614675 Test MSE 0.04388268520711118 Test RE 0.10012779619987869\n",
      "49 Train Loss 0.0046344013 Test MSE 0.04422450739758707 Test RE 0.10051701019750896\n",
      "50 Train Loss 0.0041862754 Test MSE 0.04322248898010762 Test RE 0.09937175190194447\n",
      "51 Train Loss 0.0038989196 Test MSE 0.04135023752673901 Test RE 0.09719570284085932\n",
      "52 Train Loss 0.0036080754 Test MSE 0.03928657701441416 Test RE 0.09473929656095914\n",
      "53 Train Loss 0.003468542 Test MSE 0.038013940416018986 Test RE 0.09319218729862186\n",
      "54 Train Loss 0.0033278244 Test MSE 0.037396640785265486 Test RE 0.09243242703900946\n",
      "55 Train Loss 0.0031056544 Test MSE 0.03610085962539028 Test RE 0.09081693316789842\n",
      "56 Train Loss 0.0029739179 Test MSE 0.03551732875000071 Test RE 0.09007996481102888\n",
      "57 Train Loss 0.0028675345 Test MSE 0.03450659726685266 Test RE 0.08878899246599062\n",
      "58 Train Loss 0.0027354197 Test MSE 0.03325404180174624 Test RE 0.0871626206714038\n",
      "59 Train Loss 0.0025651706 Test MSE 0.03140242103578407 Test RE 0.08470121231937949\n",
      "60 Train Loss 0.0024887365 Test MSE 0.029754074954095756 Test RE 0.08244822050751731\n",
      "61 Train Loss 0.00233264 Test MSE 0.02691311786811166 Test RE 0.07841336059374579\n",
      "62 Train Loss 0.0022766415 Test MSE 0.026931732968529923 Test RE 0.07844047414245547\n",
      "63 Train Loss 0.0021049716 Test MSE 0.024406689619530433 Test RE 0.07467281084364684\n",
      "64 Train Loss 0.0020626255 Test MSE 0.02290908245551886 Test RE 0.07234556420797959\n",
      "65 Train Loss 0.0019814367 Test MSE 0.021860352362840726 Test RE 0.07067025188938485\n",
      "66 Train Loss 0.0018740771 Test MSE 0.02054566795427466 Test RE 0.06851224407699276\n",
      "67 Train Loss 0.0018339508 Test MSE 0.01997568091256686 Test RE 0.06755521123807433\n",
      "68 Train Loss 0.0017092739 Test MSE 0.018544947589256667 Test RE 0.06509098826716596\n",
      "69 Train Loss 0.001645262 Test MSE 0.018389456282048633 Test RE 0.06481753407078596\n",
      "70 Train Loss 0.0015700504 Test MSE 0.017538624385916454 Test RE 0.06330030810165406\n",
      "71 Train Loss 0.0014912556 Test MSE 0.016082821160945504 Test RE 0.06061626552141261\n",
      "72 Train Loss 0.0014747574 Test MSE 0.015888971112076655 Test RE 0.060249846946185535\n",
      "73 Train Loss 0.0013687182 Test MSE 0.015332353843804197 Test RE 0.05918511243773562\n",
      "74 Train Loss 0.0013137655 Test MSE 0.013645032267395161 Test RE 0.05583356308952831\n",
      "75 Train Loss 0.0012932156 Test MSE 0.012701497711177078 Test RE 0.053868579990828155\n",
      "76 Train Loss 0.001232721 Test MSE 0.011969215794584813 Test RE 0.0522926810581082\n",
      "77 Train Loss 0.0011844737 Test MSE 0.011857158647955389 Test RE 0.05204732044877972\n",
      "78 Train Loss 0.0011668695 Test MSE 0.011469026089027244 Test RE 0.0511883735531223\n",
      "79 Train Loss 0.0011193926 Test MSE 0.011236735128601726 Test RE 0.05066734320402131\n",
      "80 Train Loss 0.0010987894 Test MSE 0.01106714026255443 Test RE 0.05028353103743441\n",
      "81 Train Loss 0.0010827003 Test MSE 0.010572153674945439 Test RE 0.04914618305594789\n",
      "82 Train Loss 0.0010386483 Test MSE 0.010785038666203102 Test RE 0.049638530197731054\n",
      "83 Train Loss 0.0009933778 Test MSE 0.010026341325528114 Test RE 0.04786072828288058\n",
      "84 Train Loss 0.0009759401 Test MSE 0.010294618034031321 Test RE 0.04849681069960458\n",
      "85 Train Loss 0.00094372296 Test MSE 0.010261538780376646 Test RE 0.04841883164883235\n",
      "86 Train Loss 0.0008908717 Test MSE 0.009623425343547367 Test RE 0.04688920841511033\n",
      "87 Train Loss 0.0008362379 Test MSE 0.009065010214127395 Test RE 0.045508467322477354\n",
      "88 Train Loss 0.0008221221 Test MSE 0.00842876635921489 Test RE 0.04388236930856541\n",
      "89 Train Loss 0.0008106271 Test MSE 0.008240949380198858 Test RE 0.043390702707214006\n",
      "90 Train Loss 0.0007760555 Test MSE 0.008122659344734974 Test RE 0.0430781634914125\n",
      "91 Train Loss 0.00075763493 Test MSE 0.007921676856561893 Test RE 0.04254187444939774\n",
      "92 Train Loss 0.0007444103 Test MSE 0.007843850285339043 Test RE 0.04233238216408936\n",
      "93 Train Loss 0.00072977925 Test MSE 0.007554193667350323 Test RE 0.041543407688848906\n",
      "94 Train Loss 0.0006890539 Test MSE 0.0072914309378911074 Test RE 0.0408144965305472\n",
      "95 Train Loss 0.00066783826 Test MSE 0.006831690548149235 Test RE 0.03950682724629558\n",
      "96 Train Loss 0.0006569169 Test MSE 0.006553847912284779 Test RE 0.03869512373809183\n",
      "97 Train Loss 0.00065040396 Test MSE 0.00667601472735717 Test RE 0.03905410623659245\n",
      "98 Train Loss 0.0006366125 Test MSE 0.006909275519500574 Test RE 0.039730526102580606\n",
      "99 Train Loss 0.0006061108 Test MSE 0.006682423364955048 Test RE 0.03907284672681736\n",
      "Training time: 150.22\n",
      "8\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.60452 Test MSE 5.3072417854083636 Test RE 1.101139893344671\n",
      "1 Train Loss 39.594433 Test MSE 8.23704567292216 Test RE 1.3718094722834686\n",
      "2 Train Loss 26.84993 Test MSE 7.623854583629301 Test RE 1.3197612182909513\n",
      "3 Train Loss 21.126001 Test MSE 7.837792741958606 Test RE 1.3381504602890113\n",
      "4 Train Loss 17.236904 Test MSE 7.367792765053444 Test RE 1.2974085667254531\n",
      "5 Train Loss 15.169062 Test MSE 7.1119172101727335 Test RE 1.2746806890774594\n",
      "6 Train Loss 12.941457 Test MSE 7.0800253032268525 Test RE 1.2718194581999391\n",
      "7 Train Loss 11.448787 Test MSE 6.9628387400574985 Test RE 1.2612501438478445\n",
      "8 Train Loss 10.125395 Test MSE 6.7646824804350665 Test RE 1.2431735704436642\n",
      "9 Train Loss 8.359192 Test MSE 6.6368580772996415 Test RE 1.231372146487526\n",
      "10 Train Loss 6.5165358 Test MSE 6.0343759057697675 Test RE 1.1741517793981848\n",
      "11 Train Loss 4.934803 Test MSE 5.7413480227806035 Test RE 1.1452887557417981\n",
      "12 Train Loss 3.6716423 Test MSE 5.519730832230827 Test RE 1.12296704191746\n",
      "13 Train Loss 2.885084 Test MSE 5.362600635332481 Test RE 1.10686788768455\n",
      "14 Train Loss 2.4491692 Test MSE 5.3130905067225465 Test RE 1.1017464689697298\n",
      "15 Train Loss 2.2186608 Test MSE 5.228553765692808 Test RE 1.09294636351249\n",
      "16 Train Loss 1.9887904 Test MSE 5.2415807230581555 Test RE 1.0943070560662416\n",
      "17 Train Loss 1.8450087 Test MSE 5.065725902620686 Test RE 1.0757934701546854\n",
      "18 Train Loss 1.736141 Test MSE 4.984287709097691 Test RE 1.0671110372937536\n",
      "19 Train Loss 1.6448405 Test MSE 4.879851039639477 Test RE 1.055872169169253\n",
      "20 Train Loss 1.5604545 Test MSE 4.836357139043114 Test RE 1.0511561658493103\n",
      "21 Train Loss 1.5049441 Test MSE 4.660158922268314 Test RE 1.0318306494151066\n",
      "22 Train Loss 1.4262997 Test MSE 4.317341580220337 Test RE 0.9931532441817348\n",
      "23 Train Loss 1.3344849 Test MSE 4.045212169339953 Test RE 0.9613437625131339\n",
      "24 Train Loss 1.2055535 Test MSE 3.8481387084841834 Test RE 0.9376341558468684\n",
      "25 Train Loss 1.1082714 Test MSE 3.685772790054959 Test RE 0.9176400080867764\n",
      "26 Train Loss 1.039341 Test MSE 3.5079499513371037 Test RE 0.8952302621662797\n",
      "27 Train Loss 0.9819911 Test MSE 3.3882899617480473 Test RE 0.8798291462888139\n",
      "28 Train Loss 0.9206937 Test MSE 3.24595697614414 Test RE 0.861151256984905\n",
      "29 Train Loss 0.8608953 Test MSE 3.2426646842914426 Test RE 0.8607144242479009\n",
      "30 Train Loss 0.7976026 Test MSE 3.250108778520657 Test RE 0.8617018168535207\n",
      "31 Train Loss 0.76611716 Test MSE 3.257677528750782 Test RE 0.8627045853181375\n",
      "32 Train Loss 0.73275775 Test MSE 3.3170115763389956 Test RE 0.8705256134645678\n",
      "33 Train Loss 0.7030874 Test MSE 3.292760393276875 Test RE 0.8673375020908863\n",
      "34 Train Loss 0.6804833 Test MSE 3.2808865923072563 Test RE 0.8657722661361238\n",
      "35 Train Loss 0.65953195 Test MSE 3.2882047032727666 Test RE 0.8667372931518024\n",
      "36 Train Loss 0.6463255 Test MSE 3.2990271378417364 Test RE 0.8681624632551578\n",
      "37 Train Loss 0.6329342 Test MSE 3.3160036340322434 Test RE 0.8703933398438881\n",
      "38 Train Loss 0.6180881 Test MSE 3.3298300972541837 Test RE 0.8722060554109018\n",
      "39 Train Loss 0.604747 Test MSE 3.364339263376744 Test RE 0.8767140213133265\n",
      "40 Train Loss 0.5934609 Test MSE 3.4001797644611873 Test RE 0.8813714927262378\n",
      "41 Train Loss 0.581825 Test MSE 3.416296742471939 Test RE 0.8834578900077936\n",
      "42 Train Loss 0.57181925 Test MSE 3.4576071595462476 Test RE 0.8887832978643281\n",
      "43 Train Loss 0.56206816 Test MSE 3.484839899341944 Test RE 0.892276542058499\n",
      "44 Train Loss 0.55448884 Test MSE 3.5080498525616157 Test RE 0.895243009492199\n",
      "45 Train Loss 0.54540783 Test MSE 3.5473954847715343 Test RE 0.9002494500371908\n",
      "46 Train Loss 0.53752893 Test MSE 3.5782126230211357 Test RE 0.904151343594616\n",
      "47 Train Loss 0.5306988 Test MSE 3.592467518711086 Test RE 0.9059505340784388\n",
      "48 Train Loss 0.5239996 Test MSE 3.5860227104805125 Test RE 0.9051375415608238\n",
      "49 Train Loss 0.51610494 Test MSE 3.6370253696422914 Test RE 0.911551532412063\n",
      "50 Train Loss 0.5094612 Test MSE 3.642963251299513 Test RE 0.9122953377420546\n",
      "51 Train Loss 0.49941045 Test MSE 3.6790603695779787 Test RE 0.9168040378707365\n",
      "52 Train Loss 0.49228743 Test MSE 3.7032880422161023 Test RE 0.9198177937807357\n",
      "53 Train Loss 0.48487574 Test MSE 3.7060229897314447 Test RE 0.9201573824203642\n",
      "54 Train Loss 0.47759646 Test MSE 3.7310500621422324 Test RE 0.9232591032292415\n",
      "55 Train Loss 0.46985996 Test MSE 3.7616951986800067 Test RE 0.927042963124185\n",
      "56 Train Loss 0.46192598 Test MSE 3.812232484955416 Test RE 0.9332494639871486\n",
      "57 Train Loss 0.45490447 Test MSE 3.826355929621243 Test RE 0.9349766031260227\n",
      "58 Train Loss 0.44862518 Test MSE 3.8365107101941764 Test RE 0.9362164500462455\n",
      "59 Train Loss 0.4424753 Test MSE 3.842239745069386 Test RE 0.9369152120501624\n",
      "60 Train Loss 0.43580505 Test MSE 3.861938680192771 Test RE 0.9393138958449853\n",
      "61 Train Loss 0.4301853 Test MSE 3.863958344788624 Test RE 0.9395594785965421\n",
      "62 Train Loss 0.42451602 Test MSE 3.849661743162454 Test RE 0.9378196881484523\n",
      "63 Train Loss 0.4189059 Test MSE 3.8541022930468376 Test RE 0.938360415512067\n",
      "64 Train Loss 0.4145456 Test MSE 3.8427672518925897 Test RE 0.9369795250860098\n",
      "65 Train Loss 0.41032225 Test MSE 3.8417246685089843 Test RE 0.9368524102377762\n",
      "66 Train Loss 0.40626898 Test MSE 3.8441707809870858 Test RE 0.9371506202734926\n",
      "67 Train Loss 0.40209073 Test MSE 3.868461629341404 Test RE 0.9401068281319755\n",
      "68 Train Loss 0.39866954 Test MSE 3.869094210389323 Test RE 0.9401836893639056\n",
      "69 Train Loss 0.39486343 Test MSE 3.872374792898252 Test RE 0.9405821930543313\n",
      "70 Train Loss 0.39090073 Test MSE 3.8868583299339314 Test RE 0.9423395439443367\n",
      "71 Train Loss 0.38765144 Test MSE 3.9070989337154374 Test RE 0.9447899490120684\n",
      "72 Train Loss 0.3842906 Test MSE 3.929902153872503 Test RE 0.9475430031311762\n",
      "73 Train Loss 0.38127723 Test MSE 3.944121000637773 Test RE 0.9492556162624359\n",
      "74 Train Loss 0.3774588 Test MSE 3.9659721287857614 Test RE 0.9518815063414662\n",
      "75 Train Loss 0.37479395 Test MSE 3.965415432545063 Test RE 0.9518146970654737\n",
      "76 Train Loss 0.3710154 Test MSE 3.976177042936711 Test RE 0.9531053712644361\n",
      "77 Train Loss 0.36786127 Test MSE 3.9993398862693756 Test RE 0.9558774526045181\n",
      "78 Train Loss 0.364623 Test MSE 4.011438550174172 Test RE 0.9573222043858858\n",
      "79 Train Loss 0.36177087 Test MSE 4.031211377972048 Test RE 0.9596786780575882\n",
      "80 Train Loss 0.35854393 Test MSE 4.029173890843314 Test RE 0.9594361231648558\n",
      "81 Train Loss 0.35509756 Test MSE 4.041205626610314 Test RE 0.9608675675837838\n",
      "82 Train Loss 0.35200578 Test MSE 4.045037519751309 Test RE 0.9613230095713964\n",
      "83 Train Loss 0.34866232 Test MSE 4.053215990334424 Test RE 0.9622943456715072\n",
      "84 Train Loss 0.34561008 Test MSE 4.080673508786642 Test RE 0.9655482578783101\n",
      "85 Train Loss 0.34249794 Test MSE 4.090630177305682 Test RE 0.9667254884072471\n",
      "86 Train Loss 0.33897275 Test MSE 4.10816530308026 Test RE 0.9687952826259533\n",
      "87 Train Loss 0.33645093 Test MSE 4.124957510476775 Test RE 0.9707732484381298\n",
      "88 Train Loss 0.33354837 Test MSE 4.128845839435653 Test RE 0.9712306830427521\n",
      "89 Train Loss 0.330598 Test MSE 4.1406742410040085 Test RE 0.9726208887933685\n",
      "90 Train Loss 0.32813933 Test MSE 4.1556943937369 Test RE 0.974383366241845\n",
      "91 Train Loss 0.3249927 Test MSE 4.161000791226017 Test RE 0.9750052618232027\n",
      "92 Train Loss 0.32208592 Test MSE 4.176559824465698 Test RE 0.9768264564400699\n",
      "93 Train Loss 0.31888497 Test MSE 4.172603389830729 Test RE 0.9763636753611992\n",
      "94 Train Loss 0.31612158 Test MSE 4.168152351259138 Test RE 0.9758427785075896\n",
      "95 Train Loss 0.31384653 Test MSE 4.177222830212308 Test RE 0.9769039862589809\n",
      "96 Train Loss 0.3112346 Test MSE 4.174269056459085 Test RE 0.9765585338189583\n",
      "97 Train Loss 0.30847386 Test MSE 4.176302970281717 Test RE 0.976796419061153\n",
      "98 Train Loss 0.30594695 Test MSE 4.190373886182297 Test RE 0.9784405601595816\n",
      "99 Train Loss 0.3035831 Test MSE 4.1913661606250585 Test RE 0.9785563999532307\n",
      "Training time: 150.03\n",
      "9\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.079685 Test MSE 8.137702854726369 Test RE 1.363512030440808\n",
      "1 Train Loss 42.880028 Test MSE 9.27003902813421 Test RE 1.4552876425045702\n",
      "2 Train Loss 36.95559 Test MSE 9.007908033820355 Test RE 1.4345643433651427\n",
      "3 Train Loss 32.958786 Test MSE 9.16549275355173 Test RE 1.4470581029830478\n",
      "4 Train Loss 28.698883 Test MSE 9.010704711953144 Test RE 1.4347870201154305\n",
      "5 Train Loss 24.327133 Test MSE 8.590026212333402 Test RE 1.4008940954835654\n",
      "6 Train Loss 20.68571 Test MSE 8.2718287249435 Test RE 1.3747028308503682\n",
      "7 Train Loss 18.517769 Test MSE 8.079592334683568 Test RE 1.3586349568295935\n",
      "8 Train Loss 16.672136 Test MSE 8.100653590822319 Test RE 1.3604045965806353\n",
      "9 Train Loss 14.529524 Test MSE 8.179261230188846 Test RE 1.3669892514762536\n",
      "10 Train Loss 13.194977 Test MSE 8.00968998804038 Test RE 1.3527449268358018\n",
      "11 Train Loss 11.051105 Test MSE 7.453149080159131 Test RE 1.3049022031717674\n",
      "12 Train Loss 9.459681 Test MSE 6.9918892338735565 Test RE 1.2638785115954605\n",
      "13 Train Loss 8.168812 Test MSE 6.635134574278211 Test RE 1.2312122506912284\n",
      "14 Train Loss 7.359953 Test MSE 6.418795472361615 Test RE 1.2109740286648398\n",
      "15 Train Loss 6.9228716 Test MSE 6.471263406682237 Test RE 1.2159132726261408\n",
      "16 Train Loss 6.336894 Test MSE 6.287950260879759 Test RE 1.1985678085404396\n",
      "17 Train Loss 5.621558 Test MSE 6.063761496454391 Test RE 1.1770071898929013\n",
      "18 Train Loss 4.6866207 Test MSE 5.848415375960684 Test RE 1.1559183693285175\n",
      "19 Train Loss 3.791334 Test MSE 5.795565681784102 Test RE 1.1506837402397823\n",
      "20 Train Loss 2.9139569 Test MSE 5.692128560156696 Test RE 1.140369019918233\n",
      "21 Train Loss 2.4363053 Test MSE 5.509122203560564 Test RE 1.1218873814836854\n",
      "22 Train Loss 2.0799077 Test MSE 5.37326368059572 Test RE 1.1079677944204374\n",
      "23 Train Loss 1.857516 Test MSE 5.237675582515336 Test RE 1.0938993337271588\n",
      "24 Train Loss 1.7031552 Test MSE 5.1737848685669725 Test RE 1.0872070087638779\n",
      "25 Train Loss 1.5497978 Test MSE 5.310649767656928 Test RE 1.1014933785562382\n",
      "26 Train Loss 1.4434451 Test MSE 5.35473781577818 Test RE 1.106056127160384\n",
      "27 Train Loss 1.3439285 Test MSE 5.420631890076104 Test RE 1.1128407445930657\n",
      "28 Train Loss 1.2676516 Test MSE 5.490250484745357 Test RE 1.1199641980000847\n",
      "29 Train Loss 1.2283918 Test MSE 5.488166650614403 Test RE 1.1197516356478672\n",
      "30 Train Loss 1.1662354 Test MSE 5.596240848553711 Test RE 1.1307230850047678\n",
      "31 Train Loss 1.1221471 Test MSE 5.643645406097344 Test RE 1.1355020424942108\n",
      "32 Train Loss 1.0909631 Test MSE 5.677331818995054 Test RE 1.1388858554764432\n",
      "33 Train Loss 1.0611924 Test MSE 5.72077273024462 Test RE 1.1432347258177111\n",
      "34 Train Loss 1.0352285 Test MSE 5.707227446831552 Test RE 1.1418804843255703\n",
      "35 Train Loss 1.0123302 Test MSE 5.784488058899459 Test RE 1.1495835079131833\n",
      "36 Train Loss 0.9898489 Test MSE 5.787875725172707 Test RE 1.1499200835287697\n",
      "37 Train Loss 0.9730557 Test MSE 5.802953935463232 Test RE 1.1514169590576997\n",
      "38 Train Loss 0.94908774 Test MSE 5.849595707394925 Test RE 1.1560350075857722\n",
      "39 Train Loss 0.9367107 Test MSE 5.8504633438163065 Test RE 1.1561207383727317\n",
      "40 Train Loss 0.9181303 Test MSE 5.874335090801704 Test RE 1.158477006982342\n",
      "41 Train Loss 0.9056943 Test MSE 5.921097451085135 Test RE 1.1630788669978842\n",
      "42 Train Loss 0.89200115 Test MSE 5.949825301335447 Test RE 1.1658969531716954\n",
      "43 Train Loss 0.8796593 Test MSE 5.998612557198712 Test RE 1.170667243304198\n",
      "44 Train Loss 0.86994064 Test MSE 5.999695311119618 Test RE 1.1707728916806068\n",
      "45 Train Loss 0.8593512 Test MSE 6.047956306294031 Test RE 1.1754722548239611\n",
      "46 Train Loss 0.8498398 Test MSE 6.059993081819994 Test RE 1.1766413987535869\n",
      "47 Train Loss 0.83851135 Test MSE 6.105714571688934 Test RE 1.1810718250383099\n",
      "48 Train Loss 0.83056045 Test MSE 6.134412572541361 Test RE 1.183844200463239\n",
      "49 Train Loss 0.82228494 Test MSE 6.124598428599569 Test RE 1.182896834443703\n",
      "50 Train Loss 0.8153721 Test MSE 6.138767071271598 Test RE 1.1842643004733497\n",
      "51 Train Loss 0.8082551 Test MSE 6.11843765618916 Test RE 1.1823017430397889\n",
      "52 Train Loss 0.80142665 Test MSE 6.140469758827875 Test RE 1.1844285266331895\n",
      "53 Train Loss 0.7950026 Test MSE 6.14650799540414 Test RE 1.1850107379785186\n",
      "54 Train Loss 0.78882986 Test MSE 6.168533900652929 Test RE 1.1871320719940315\n",
      "55 Train Loss 0.78015816 Test MSE 6.178893825352071 Test RE 1.188128535626484\n",
      "56 Train Loss 0.77212757 Test MSE 6.216407881534588 Test RE 1.191729833404914\n",
      "57 Train Loss 0.7644663 Test MSE 6.2133315304874595 Test RE 1.1914349176690848\n",
      "58 Train Loss 0.758911 Test MSE 6.221763525232542 Test RE 1.1922430804766326\n",
      "59 Train Loss 0.7525245 Test MSE 6.2240974082108655 Test RE 1.1924666742313532\n",
      "60 Train Loss 0.7478591 Test MSE 6.237670257201097 Test RE 1.1937661683522003\n",
      "61 Train Loss 0.7396441 Test MSE 6.253914220577664 Test RE 1.1953195436379571\n",
      "62 Train Loss 0.7344165 Test MSE 6.25989475607044 Test RE 1.1958909412043799\n",
      "63 Train Loss 0.7291702 Test MSE 6.227662263128303 Test RE 1.1928081182911585\n",
      "64 Train Loss 0.7245811 Test MSE 6.2303725901261044 Test RE 1.193067649736534\n",
      "65 Train Loss 0.72082007 Test MSE 6.233348775111039 Test RE 1.1933525737945314\n",
      "66 Train Loss 0.7162919 Test MSE 6.237059986287809 Test RE 1.19370777005928\n",
      "67 Train Loss 0.71288174 Test MSE 6.240371438118156 Test RE 1.194024616558064\n",
      "68 Train Loss 0.709108 Test MSE 6.245178961917003 Test RE 1.19448446070952\n",
      "69 Train Loss 0.7048801 Test MSE 6.252241991913631 Test RE 1.1951597252291617\n",
      "70 Train Loss 0.70138776 Test MSE 6.268333854129973 Test RE 1.1966967727889186\n",
      "71 Train Loss 0.6981961 Test MSE 6.300058047894293 Test RE 1.1997212070211047\n",
      "72 Train Loss 0.6957797 Test MSE 6.289384124202328 Test RE 1.1987044575585264\n",
      "73 Train Loss 0.6923305 Test MSE 6.287761164513028 Test RE 1.1985497862507857\n",
      "74 Train Loss 0.68898904 Test MSE 6.30696188485519 Test RE 1.200378376500697\n",
      "75 Train Loss 0.6855582 Test MSE 6.310993779890755 Test RE 1.2007620022827674\n",
      "76 Train Loss 0.68276036 Test MSE 6.327152693284372 Test RE 1.2022982583541624\n",
      "77 Train Loss 0.6800427 Test MSE 6.332708054746301 Test RE 1.2028259630153626\n",
      "78 Train Loss 0.6773257 Test MSE 6.339426975093443 Test RE 1.2034638851539845\n",
      "79 Train Loss 0.6753821 Test MSE 6.348814467920617 Test RE 1.2043546067727695\n",
      "80 Train Loss 0.6728066 Test MSE 6.364625798335178 Test RE 1.2058533596068546\n",
      "81 Train Loss 0.67014915 Test MSE 6.372031193485708 Test RE 1.2065546753557397\n",
      "82 Train Loss 0.6672911 Test MSE 6.3974107523812265 Test RE 1.2089551182988543\n",
      "83 Train Loss 0.6644667 Test MSE 6.404407801222924 Test RE 1.209616073691656\n",
      "84 Train Loss 0.6615515 Test MSE 6.4142795024451384 Test RE 1.2105479608355514\n",
      "85 Train Loss 0.6592499 Test MSE 6.409243531738345 Test RE 1.2100726556111527\n",
      "86 Train Loss 0.65621376 Test MSE 6.419844198209016 Test RE 1.211072951266489\n",
      "87 Train Loss 0.6534626 Test MSE 6.430175460022843 Test RE 1.2120470311377969\n",
      "88 Train Loss 0.65166295 Test MSE 6.434333404789154 Test RE 1.212438840833432\n",
      "89 Train Loss 0.64848465 Test MSE 6.441562539816413 Test RE 1.213119752361609\n",
      "90 Train Loss 0.645988 Test MSE 6.4638762883525915 Test RE 1.2152190758790955\n",
      "91 Train Loss 0.64318544 Test MSE 6.481746386671858 Test RE 1.2168977200069884\n",
      "92 Train Loss 0.641014 Test MSE 6.476310144836082 Test RE 1.2163873067976096\n",
      "93 Train Loss 0.6392131 Test MSE 6.485069350817765 Test RE 1.217209610438799\n",
      "94 Train Loss 0.6367288 Test MSE 6.496739888156854 Test RE 1.2183043639511055\n",
      "95 Train Loss 0.63463795 Test MSE 6.503552206339719 Test RE 1.2189429382666717\n",
      "96 Train Loss 0.6318706 Test MSE 6.493668011706252 Test RE 1.2180163023196633\n",
      "97 Train Loss 0.62984437 Test MSE 6.511186181659911 Test RE 1.2196581359703358\n",
      "98 Train Loss 0.6280793 Test MSE 6.52465531518228 Test RE 1.2209189854483506\n",
      "99 Train Loss 0.6249829 Test MSE 6.533591039421407 Test RE 1.2217547432066238\n",
      "Training time: 151.56\n",
      "0\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.15729 Test MSE 4.525949448766363 Test RE 1.0168640876799393\n",
      "1 Train Loss 60.823708 Test MSE 6.873393794014424 Test RE 1.2531229201913678\n",
      "2 Train Loss 44.665855 Test MSE 7.571468113322424 Test RE 1.3152191058453484\n",
      "3 Train Loss 28.671112 Test MSE 7.420537730212428 Test RE 1.3020442652968522\n",
      "4 Train Loss 17.213367 Test MSE 5.7750004520899125 Test RE 1.1486403585663525\n",
      "5 Train Loss 12.515758 Test MSE 5.624348487088154 Test RE 1.133559109182844\n",
      "6 Train Loss 10.566011 Test MSE 5.44722452863608 Test RE 1.1155671025270217\n",
      "7 Train Loss 9.228015 Test MSE 4.99428053273846 Test RE 1.0681802084249552\n",
      "8 Train Loss 7.8274636 Test MSE 4.534876091769728 Test RE 1.0178663869119922\n",
      "9 Train Loss 6.667326 Test MSE 4.182503179785875 Test RE 0.9775212343241136\n",
      "10 Train Loss 5.529997 Test MSE 3.932410052847903 Test RE 0.9478452960425625\n",
      "11 Train Loss 4.8255444 Test MSE 3.769632268215739 Test RE 0.9280204648709987\n",
      "12 Train Loss 4.051399 Test MSE 3.4466883822336363 Test RE 0.8873788438613869\n",
      "13 Train Loss 3.5235834 Test MSE 3.301682028990886 Test RE 0.8685117197507368\n",
      "14 Train Loss 2.977996 Test MSE 2.921076029025098 Test RE 0.8169199285558147\n",
      "15 Train Loss 2.5318542 Test MSE 2.7420437796537027 Test RE 0.7914896725708281\n",
      "16 Train Loss 2.2296827 Test MSE 2.578859549878039 Test RE 0.7675769160458076\n",
      "17 Train Loss 1.910754 Test MSE 2.3342075006003724 Test RE 0.7302604667851977\n",
      "18 Train Loss 1.6597879 Test MSE 2.198193057804859 Test RE 0.7086649872524483\n",
      "19 Train Loss 1.536737 Test MSE 2.073934245567237 Test RE 0.6883440325204032\n",
      "20 Train Loss 1.4178843 Test MSE 1.9068427888310833 Test RE 0.6600327795416029\n",
      "21 Train Loss 1.3278185 Test MSE 1.801536757937662 Test RE 0.6415486924214862\n",
      "22 Train Loss 1.2272987 Test MSE 1.67411410555376 Test RE 0.6184442956945634\n",
      "23 Train Loss 1.1396484 Test MSE 1.5205115325066672 Test RE 0.5893902123505141\n",
      "24 Train Loss 0.9157211 Test MSE 1.274546544125989 Test RE 0.5396173565980347\n",
      "25 Train Loss 0.8065539 Test MSE 1.023057881064356 Test RE 0.4834573452414025\n",
      "26 Train Loss 0.6526991 Test MSE 0.7673098884581766 Test RE 0.41869083825495895\n",
      "27 Train Loss 0.50507486 Test MSE 0.49961874296739595 Test RE 0.33785272136115274\n",
      "28 Train Loss 0.41850647 Test MSE 0.5015333865454312 Test RE 0.3384994635060985\n",
      "29 Train Loss 0.33970332 Test MSE 0.43746518272845114 Test RE 0.31614026077002755\n",
      "30 Train Loss 0.28238556 Test MSE 0.419522096011465 Test RE 0.3095889706437443\n",
      "31 Train Loss 0.25296545 Test MSE 0.4125886004464893 Test RE 0.3070200036683136\n",
      "32 Train Loss 0.23124374 Test MSE 0.4148760391078279 Test RE 0.30786990441821793\n",
      "33 Train Loss 0.20825315 Test MSE 0.39090567029043694 Test RE 0.2988436590976981\n",
      "34 Train Loss 0.18988103 Test MSE 0.3998190265003467 Test RE 0.302231543411027\n",
      "35 Train Loss 0.17763309 Test MSE 0.3911257542323493 Test RE 0.29892777329802545\n",
      "36 Train Loss 0.1662104 Test MSE 0.3771455661212486 Test RE 0.2935368054075739\n",
      "37 Train Loss 0.15642859 Test MSE 0.3876706674957917 Test RE 0.29760452570832235\n",
      "38 Train Loss 0.15060069 Test MSE 0.394972050633701 Test RE 0.3003939922166791\n",
      "39 Train Loss 0.1441647 Test MSE 0.40035654307775004 Test RE 0.3024346351722644\n",
      "40 Train Loss 0.13945013 Test MSE 0.38925629473038603 Test RE 0.2982125267012384\n",
      "41 Train Loss 0.13289073 Test MSE 0.3855901983283578 Test RE 0.2968048908395405\n",
      "42 Train Loss 0.12984082 Test MSE 0.38557683323301634 Test RE 0.29679974695873707\n",
      "43 Train Loss 0.12450847 Test MSE 0.3969056430426598 Test RE 0.301128386459759\n",
      "44 Train Loss 0.121305235 Test MSE 0.39695797830658847 Test RE 0.301148238928958\n",
      "45 Train Loss 0.116417386 Test MSE 0.402450706046142 Test RE 0.30322458273728325\n",
      "46 Train Loss 0.11340548 Test MSE 0.41796558541219053 Test RE 0.30901411854865696\n",
      "47 Train Loss 0.11245538 Test MSE 0.4201574066254317 Test RE 0.3098232976956612\n",
      "48 Train Loss 0.11013367 Test MSE 0.43751658406191896 Test RE 0.316158833166528\n",
      "49 Train Loss 0.107773826 Test MSE 0.44654065374137625 Test RE 0.3194026846859733\n",
      "50 Train Loss 0.10588432 Test MSE 0.44977067702197066 Test RE 0.32055579266341766\n",
      "51 Train Loss 0.104807004 Test MSE 0.4497842369936757 Test RE 0.32056062478669606\n",
      "52 Train Loss 0.10314724 Test MSE 0.45104200566205677 Test RE 0.32100851691067006\n",
      "53 Train Loss 0.10137165 Test MSE 0.4551270452258335 Test RE 0.322458910328222\n",
      "54 Train Loss 0.100134104 Test MSE 0.4591019673502817 Test RE 0.32386397143892515\n",
      "55 Train Loss 0.098743886 Test MSE 0.4486780011454275 Test RE 0.3201661756968114\n",
      "56 Train Loss 0.09736318 Test MSE 0.44912918060504686 Test RE 0.32032711082799703\n",
      "57 Train Loss 0.09636358 Test MSE 0.45309438359461024 Test RE 0.321738031033904\n",
      "58 Train Loss 0.09408919 Test MSE 0.4616148290823409 Test RE 0.32474908506456557\n",
      "59 Train Loss 0.0935619 Test MSE 0.46183329152000846 Test RE 0.3248259208597022\n",
      "60 Train Loss 0.092397995 Test MSE 0.4630067929785326 Test RE 0.3252383444144733\n",
      "61 Train Loss 0.091519296 Test MSE 0.46385532701662185 Test RE 0.3255362336497769\n",
      "62 Train Loss 0.09083103 Test MSE 0.46630920909229934 Test RE 0.3263961718466023\n",
      "63 Train Loss 0.0899203 Test MSE 0.46762220320029707 Test RE 0.32685536822638167\n",
      "64 Train Loss 0.08844361 Test MSE 0.46276065444672027 Test RE 0.3251518831228251\n",
      "65 Train Loss 0.08766341 Test MSE 0.46996083101045993 Test RE 0.32767166793225616\n",
      "66 Train Loss 0.08731508 Test MSE 0.4683852699524811 Test RE 0.3271219411110362\n",
      "67 Train Loss 0.08618062 Test MSE 0.47913524993921824 Test RE 0.3308545578057425\n",
      "68 Train Loss 0.08572878 Test MSE 0.48266183261028217 Test RE 0.3320699211500231\n",
      "69 Train Loss 0.08452451 Test MSE 0.486557119941978 Test RE 0.3334072015790613\n",
      "70 Train Loss 0.08386783 Test MSE 0.4859633573099663 Test RE 0.33320370525548054\n",
      "71 Train Loss 0.08347605 Test MSE 0.4888226198156938 Test RE 0.3341825029152561\n",
      "72 Train Loss 0.0816481 Test MSE 0.4926795351367524 Test RE 0.33549829835229655\n",
      "73 Train Loss 0.08114797 Test MSE 0.4978188927225874 Test RE 0.3372436239759851\n",
      "74 Train Loss 0.08034395 Test MSE 0.4999266272866078 Test RE 0.3379568042606591\n",
      "75 Train Loss 0.078861386 Test MSE 0.5068354857807044 Test RE 0.340284029856731\n",
      "76 Train Loss 0.0784415 Test MSE 0.5048189306183759 Test RE 0.33960640817470844\n",
      "77 Train Loss 0.07733999 Test MSE 0.5038137056061097 Test RE 0.33926811760267667\n",
      "78 Train Loss 0.07682461 Test MSE 0.5070988216593332 Test RE 0.3403724188508069\n",
      "79 Train Loss 0.07606877 Test MSE 0.5080242759843144 Test RE 0.3406828667620249\n",
      "80 Train Loss 0.07506874 Test MSE 0.5077730778067097 Test RE 0.3405986291568627\n",
      "81 Train Loss 0.07479375 Test MSE 0.5066831324836301 Test RE 0.3402328818097566\n",
      "82 Train Loss 0.0741115 Test MSE 0.5103415461972856 Test RE 0.34145896753316085\n",
      "83 Train Loss 0.0737207 Test MSE 0.5135262470241029 Test RE 0.3425227192824915\n",
      "84 Train Loss 0.0734953 Test MSE 0.5144367719743022 Test RE 0.3428262455003089\n",
      "85 Train Loss 0.07299127 Test MSE 0.5174144589257754 Test RE 0.3438169953361649\n",
      "86 Train Loss 0.072444595 Test MSE 0.5180350870811368 Test RE 0.34402313429813836\n",
      "87 Train Loss 0.07212861 Test MSE 0.5179440432287615 Test RE 0.34399290220718803\n",
      "88 Train Loss 0.07177904 Test MSE 0.5236990213265319 Test RE 0.3458987092669378\n",
      "89 Train Loss 0.07137481 Test MSE 0.5250874039637086 Test RE 0.3463569131893978\n",
      "90 Train Loss 0.0711137 Test MSE 0.5269388677297228 Test RE 0.34696700494329885\n",
      "91 Train Loss 0.070624426 Test MSE 0.5283553120663028 Test RE 0.3474330263871425\n",
      "92 Train Loss 0.07020656 Test MSE 0.5292908695053765 Test RE 0.3477404897397335\n",
      "93 Train Loss 0.06994372 Test MSE 0.5318671575937594 Test RE 0.3485857642565697\n",
      "94 Train Loss 0.069481306 Test MSE 0.5326378290337559 Test RE 0.3488382218893999\n",
      "95 Train Loss 0.06917761 Test MSE 0.5327640405484938 Test RE 0.3488795490259246\n",
      "96 Train Loss 0.06897298 Test MSE 0.5344591113811481 Test RE 0.3494341152704711\n",
      "97 Train Loss 0.06859043 Test MSE 0.5345925509167987 Test RE 0.34947773452497016\n",
      "98 Train Loss 0.06833778 Test MSE 0.5342862667485219 Test RE 0.3493776070231952\n",
      "99 Train Loss 0.068011485 Test MSE 0.5395056280733519 Test RE 0.35107996796879004\n",
      "Training time: 150.99\n",
      "1\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.30538 Test MSE 4.866719842638761 Test RE 1.0544505883500344\n",
      "1 Train Loss 57.610123 Test MSE 7.271632140418295 Test RE 1.2889142065400419\n",
      "2 Train Loss 46.773376 Test MSE 7.620299765931327 Test RE 1.319453496160616\n",
      "3 Train Loss 40.70114 Test MSE 8.39668824972181 Test RE 1.3850392308038644\n",
      "4 Train Loss 36.1064 Test MSE 9.294992081402802 Test RE 1.4572449948634727\n",
      "5 Train Loss 33.00315 Test MSE 9.814981225092422 Test RE 1.497451609192764\n",
      "6 Train Loss 30.023304 Test MSE 9.884480407277351 Test RE 1.5027439311139166\n",
      "7 Train Loss 27.184109 Test MSE 9.53705160529029 Test RE 1.476097778363283\n",
      "8 Train Loss 24.345354 Test MSE 9.337437022250038 Test RE 1.4605684095759817\n",
      "9 Train Loss 21.963589 Test MSE 9.135203052479882 Test RE 1.4446650385211095\n",
      "10 Train Loss 18.404644 Test MSE 8.54823540029768 Test RE 1.3974822385558625\n",
      "11 Train Loss 15.739291 Test MSE 7.927264686850231 Test RE 1.3457665826065006\n",
      "12 Train Loss 13.146606 Test MSE 7.315257220102036 Test RE 1.2927747499192077\n",
      "13 Train Loss 9.553202 Test MSE 6.1881958595162585 Test RE 1.189022535110775\n",
      "14 Train Loss 7.3566203 Test MSE 5.6533223365291585 Test RE 1.1364751252509677\n",
      "15 Train Loss 6.296318 Test MSE 5.7866057132183775 Test RE 1.149793915272578\n",
      "16 Train Loss 5.232807 Test MSE 5.6649288474565305 Test RE 1.1376411429434052\n",
      "17 Train Loss 4.2019067 Test MSE 5.563147432004922 Test RE 1.1273748575643692\n",
      "18 Train Loss 2.9937859 Test MSE 5.119634034438182 Test RE 1.081502478453772\n",
      "19 Train Loss 2.6066494 Test MSE 5.144803545245863 Test RE 1.0841576989056816\n",
      "20 Train Loss 2.2865376 Test MSE 5.1078549611469635 Test RE 1.080257620644577\n",
      "21 Train Loss 2.0418224 Test MSE 5.114503996331188 Test RE 1.0809604924990455\n",
      "22 Train Loss 1.9194738 Test MSE 5.147471696807292 Test RE 1.0844387905045005\n",
      "23 Train Loss 1.8049779 Test MSE 5.188518941767545 Test RE 1.0887539999337712\n",
      "24 Train Loss 1.7137676 Test MSE 5.206717339391647 Test RE 1.0906616960524398\n",
      "25 Train Loss 1.6399891 Test MSE 5.160839225822699 Test RE 1.0858459733575827\n",
      "26 Train Loss 1.5748188 Test MSE 5.192605351137766 Test RE 1.089182659723762\n",
      "27 Train Loss 1.5166345 Test MSE 5.2205136494819255 Test RE 1.092105710729517\n",
      "28 Train Loss 1.4510429 Test MSE 5.283152341292627 Test RE 1.098638027257515\n",
      "29 Train Loss 1.4001361 Test MSE 5.389399323363799 Test RE 1.1096301333815226\n",
      "30 Train Loss 1.3448169 Test MSE 5.506983208510241 Test RE 1.1216695659730558\n",
      "31 Train Loss 1.3058834 Test MSE 5.5700591245028965 Test RE 1.128074969300859\n",
      "32 Train Loss 1.251482 Test MSE 5.640846124736828 Test RE 1.1352203997153667\n",
      "33 Train Loss 1.2053246 Test MSE 5.636255958469859 Test RE 1.1347584201854959\n",
      "34 Train Loss 1.1673268 Test MSE 5.719382934972326 Test RE 1.1430958495851973\n",
      "35 Train Loss 1.1331377 Test MSE 5.739909745753876 Test RE 1.145145292423055\n",
      "36 Train Loss 1.1028695 Test MSE 5.738020546449448 Test RE 1.1449568238035306\n",
      "37 Train Loss 1.0860972 Test MSE 5.756030472125349 Test RE 1.146752254127913\n",
      "38 Train Loss 1.0611163 Test MSE 5.788463377865254 Test RE 1.1499784587007373\n",
      "39 Train Loss 1.0401388 Test MSE 5.813639874214463 Test RE 1.1524766186822237\n",
      "40 Train Loss 1.0146194 Test MSE 5.812677751210786 Test RE 1.1523812507053808\n",
      "41 Train Loss 0.9974317 Test MSE 5.836010118408569 Test RE 1.1546917911696388\n",
      "42 Train Loss 0.9833522 Test MSE 5.877712595058037 Test RE 1.1588099977552044\n",
      "43 Train Loss 0.96911526 Test MSE 5.910680604941601 Test RE 1.1620553281116601\n",
      "44 Train Loss 0.95820403 Test MSE 5.934169438764101 Test RE 1.1643620219092594\n",
      "45 Train Loss 0.9463356 Test MSE 5.917187651416665 Test RE 1.1626948033731876\n",
      "46 Train Loss 0.9317513 Test MSE 5.953707218132819 Test RE 1.1662772313104348\n",
      "47 Train Loss 0.9143109 Test MSE 5.982191720376625 Test RE 1.1690638300726304\n",
      "48 Train Loss 0.9033067 Test MSE 6.002491535863005 Test RE 1.171045685764848\n",
      "49 Train Loss 0.8909023 Test MSE 6.037316398305826 Test RE 1.1744378209124342\n",
      "50 Train Loss 0.8783597 Test MSE 6.035064327486006 Test RE 1.174218753062348\n",
      "51 Train Loss 0.86364627 Test MSE 6.0714323233742675 Test RE 1.1777514280100898\n",
      "52 Train Loss 0.8509366 Test MSE 6.114098273671013 Test RE 1.1818824064545717\n",
      "53 Train Loss 0.8428002 Test MSE 6.112288162525185 Test RE 1.181707442233743\n",
      "54 Train Loss 0.8340637 Test MSE 6.145846476093077 Test RE 1.1849469677385083\n",
      "55 Train Loss 0.8248659 Test MSE 6.165201865111262 Test RE 1.1868114041797106\n",
      "56 Train Loss 0.81750345 Test MSE 6.173764320637818 Test RE 1.1876352615481887\n",
      "57 Train Loss 0.8092053 Test MSE 6.196417555844223 Test RE 1.1898121462945839\n",
      "58 Train Loss 0.80189115 Test MSE 6.205387855739026 Test RE 1.1906730559865133\n",
      "59 Train Loss 0.79009944 Test MSE 6.216526834093775 Test RE 1.1917412353783772\n",
      "60 Train Loss 0.7823076 Test MSE 6.240032326375457 Test RE 1.193992173515727\n",
      "61 Train Loss 0.774942 Test MSE 6.251994153730475 Test RE 1.1951360369945478\n",
      "62 Train Loss 0.7690016 Test MSE 6.266950701460489 Test RE 1.1965647356564717\n",
      "63 Train Loss 0.76199144 Test MSE 6.2875375386351315 Test RE 1.1985284726922476\n",
      "64 Train Loss 0.7570946 Test MSE 6.310267331476426 Test RE 1.200692891395763\n",
      "65 Train Loss 0.74774355 Test MSE 6.389342605476515 Test RE 1.2081925359700838\n",
      "66 Train Loss 0.7421789 Test MSE 6.3897396265124415 Test RE 1.2082300727270332\n",
      "67 Train Loss 0.73671854 Test MSE 6.399708147571678 Test RE 1.2091721747355846\n",
      "68 Train Loss 0.7330685 Test MSE 6.3953587250315085 Test RE 1.208761211104932\n",
      "69 Train Loss 0.728515 Test MSE 6.405452021547375 Test RE 1.2097146818882203\n",
      "70 Train Loss 0.72327846 Test MSE 6.405207749558516 Test RE 1.2096916154264334\n",
      "71 Train Loss 0.7174159 Test MSE 6.422337084853139 Test RE 1.2113080640251315\n",
      "72 Train Loss 0.7126106 Test MSE 6.442183523074877 Test RE 1.2131782248903842\n",
      "73 Train Loss 0.70708334 Test MSE 6.446248835191459 Test RE 1.2135609499628548\n",
      "74 Train Loss 0.7017865 Test MSE 6.447157299388773 Test RE 1.2136464599906596\n",
      "75 Train Loss 0.6952516 Test MSE 6.4824589507198755 Test RE 1.21696460736138\n",
      "76 Train Loss 0.6888246 Test MSE 6.500112772726931 Test RE 1.2186205738395284\n",
      "77 Train Loss 0.682668 Test MSE 6.521686528341457 Test RE 1.2206411883502892\n",
      "78 Train Loss 0.67677426 Test MSE 6.529749283570546 Test RE 1.2213954940907954\n",
      "79 Train Loss 0.67261255 Test MSE 6.550541921017119 Test RE 1.223338589269849\n",
      "80 Train Loss 0.6683669 Test MSE 6.560151632653933 Test RE 1.2242355854925104\n",
      "81 Train Loss 0.6632488 Test MSE 6.57160896806022 Test RE 1.2253041856956357\n",
      "82 Train Loss 0.65918475 Test MSE 6.601183425102125 Test RE 1.2280582317129167\n",
      "83 Train Loss 0.65516126 Test MSE 6.622983488220506 Test RE 1.2300843593471664\n",
      "84 Train Loss 0.65156066 Test MSE 6.623438051201171 Test RE 1.2301265715329563\n",
      "85 Train Loss 0.64612645 Test MSE 6.670304502698557 Test RE 1.234470995263228\n",
      "86 Train Loss 0.6404053 Test MSE 6.686960520644704 Test RE 1.2360112961146565\n",
      "87 Train Loss 0.63381356 Test MSE 6.693851485949872 Test RE 1.2366479917982167\n",
      "88 Train Loss 0.62881553 Test MSE 6.698072944092878 Test RE 1.2370378745838397\n",
      "89 Train Loss 0.6238821 Test MSE 6.720902576729338 Test RE 1.2391442339216256\n",
      "90 Train Loss 0.62070996 Test MSE 6.719470652964188 Test RE 1.239012223780428\n",
      "91 Train Loss 0.6170675 Test MSE 6.737932448910651 Test RE 1.2407131539346323\n",
      "92 Train Loss 0.6143083 Test MSE 6.760149061290952 Test RE 1.2427569380723096\n",
      "93 Train Loss 0.6114662 Test MSE 6.778008452677546 Test RE 1.2443974524103159\n",
      "94 Train Loss 0.60877895 Test MSE 6.778822439788205 Test RE 1.2444721714878006\n",
      "95 Train Loss 0.6055137 Test MSE 6.813421420218183 Test RE 1.2476440105002713\n",
      "96 Train Loss 0.602883 Test MSE 6.820527250387908 Test RE 1.248294435272385\n",
      "97 Train Loss 0.59973276 Test MSE 6.8337462298031495 Test RE 1.2495035200156694\n",
      "98 Train Loss 0.5960733 Test MSE 6.838801051778446 Test RE 1.2499655543160462\n",
      "99 Train Loss 0.59259534 Test MSE 6.827081099167733 Test RE 1.2488940347088338\n",
      "Training time: 150.63\n",
      "2\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 64.03724 Test MSE 5.513778695174382 Test RE 1.122361409429525\n",
      "1 Train Loss 38.863964 Test MSE 8.37350357571706 Test RE 1.383125745439482\n",
      "2 Train Loss 25.255972 Test MSE 7.029732936622317 Test RE 1.2672942763289508\n",
      "3 Train Loss 17.90662 Test MSE 6.472290249207486 Test RE 1.2160097377096666\n",
      "4 Train Loss 13.475584 Test MSE 6.143889195805115 Test RE 1.184758266472003\n",
      "5 Train Loss 11.475944 Test MSE 5.931698678252875 Test RE 1.1641195988330346\n",
      "6 Train Loss 10.417845 Test MSE 5.944864332539711 Test RE 1.1654107889328298\n",
      "7 Train Loss 9.454505 Test MSE 5.789720467330077 Test RE 1.1501033232141822\n",
      "8 Train Loss 8.916578 Test MSE 5.80931125333316 Test RE 1.1520474930914804\n",
      "9 Train Loss 8.515024 Test MSE 5.744630920852152 Test RE 1.145616146531746\n",
      "10 Train Loss 8.2187395 Test MSE 5.662623828326713 Test RE 1.1374096703627714\n",
      "11 Train Loss 7.669351 Test MSE 5.57349147172169 Test RE 1.1284224834469554\n",
      "12 Train Loss 7.162619 Test MSE 5.559924534132893 Test RE 1.127048249249318\n",
      "13 Train Loss 6.669779 Test MSE 5.464477056963172 Test RE 1.1173323260541164\n",
      "14 Train Loss 6.262424 Test MSE 5.232754438958105 Test RE 1.093385317476562\n",
      "15 Train Loss 5.883199 Test MSE 5.207339125731752 Test RE 1.0907268175344462\n",
      "16 Train Loss 5.5579863 Test MSE 5.12934581753705 Test RE 1.082527780362564\n",
      "17 Train Loss 5.167439 Test MSE 4.774329141288447 Test RE 1.0443936875286401\n",
      "18 Train Loss 4.513701 Test MSE 4.725850249764385 Test RE 1.0390777330407355\n",
      "19 Train Loss 4.0072193 Test MSE 4.646332464287626 Test RE 1.0302988174403511\n",
      "20 Train Loss 3.4830697 Test MSE 4.6335141518690985 Test RE 1.0288766405430743\n",
      "21 Train Loss 3.1293879 Test MSE 4.369026029595254 Test RE 0.9990802557623372\n",
      "22 Train Loss 2.7944746 Test MSE 4.225639962029556 Test RE 0.9825491986671298\n",
      "23 Train Loss 2.6149645 Test MSE 3.9648871571870297 Test RE 0.9517512942510579\n",
      "24 Train Loss 2.4285977 Test MSE 3.808320011991031 Test RE 0.9327704466891543\n",
      "25 Train Loss 2.227096 Test MSE 3.4519276265727394 Test RE 0.8880530314616008\n",
      "26 Train Loss 2.0431974 Test MSE 3.0451709530459663 Test RE 0.8340918920046477\n",
      "27 Train Loss 1.8315437 Test MSE 2.676418648470516 Test RE 0.781960983025607\n",
      "28 Train Loss 1.6884229 Test MSE 2.4711476625132685 Test RE 0.7513761556153484\n",
      "29 Train Loss 1.578965 Test MSE 2.3422076982357494 Test RE 0.7315108335040732\n",
      "30 Train Loss 1.4922024 Test MSE 2.2124931312231504 Test RE 0.7109663168362833\n",
      "31 Train Loss 1.4092042 Test MSE 1.9729674970677358 Test RE 0.6713794216522682\n",
      "32 Train Loss 1.2950594 Test MSE 1.522857482148624 Test RE 0.5898447129629028\n",
      "33 Train Loss 1.048275 Test MSE 1.2685608843539269 Test RE 0.5383487614744991\n",
      "34 Train Loss 0.8789079 Test MSE 1.0735008669631423 Test RE 0.49523263933527817\n",
      "35 Train Loss 0.6497219 Test MSE 0.850940247155517 Test RE 0.4409177604349714\n",
      "36 Train Loss 0.5470271 Test MSE 0.7099442692705568 Test RE 0.40273575602540296\n",
      "37 Train Loss 0.4677503 Test MSE 0.6600408685283429 Test RE 0.388323321601305\n",
      "38 Train Loss 0.40456328 Test MSE 0.6014260647969889 Test RE 0.3706800245934611\n",
      "39 Train Loss 0.34766495 Test MSE 0.5417827251864815 Test RE 0.3518200912973779\n",
      "40 Train Loss 0.3049332 Test MSE 0.49259249217790574 Test RE 0.3354686603701605\n",
      "41 Train Loss 0.2762944 Test MSE 0.4658982747203549 Test RE 0.3262523220510222\n",
      "42 Train Loss 0.23215234 Test MSE 0.3093657356811499 Test RE 0.26585459180286564\n",
      "43 Train Loss 0.19231702 Test MSE 0.20955616729234602 Test RE 0.21880552480061424\n",
      "44 Train Loss 0.14896439 Test MSE 0.16496149491807235 Test RE 0.19413299383515878\n",
      "45 Train Loss 0.124222845 Test MSE 0.1310792000529721 Test RE 0.17305133398049782\n",
      "46 Train Loss 0.10308255 Test MSE 0.14214507073736782 Test RE 0.1802079566340614\n",
      "47 Train Loss 0.08430149 Test MSE 0.1101676759488394 Test RE 0.15864820189084938\n",
      "48 Train Loss 0.07185759 Test MSE 0.1062576484777523 Test RE 0.15580742874662337\n",
      "49 Train Loss 0.06177301 Test MSE 0.10129746834166384 Test RE 0.15212736958970446\n",
      "50 Train Loss 0.053268712 Test MSE 0.09635307573424022 Test RE 0.1483682080909825\n",
      "51 Train Loss 0.04477537 Test MSE 0.10143604471291492 Test RE 0.15223139022443968\n",
      "52 Train Loss 0.03962406 Test MSE 0.08968779130393051 Test RE 0.14314451940409284\n",
      "53 Train Loss 0.03452324 Test MSE 0.0832158845023422 Test RE 0.13788314384603678\n",
      "54 Train Loss 0.028535891 Test MSE 0.07930222405514695 Test RE 0.13460176167202265\n",
      "55 Train Loss 0.026775558 Test MSE 0.07652324921758903 Test RE 0.13222231641587287\n",
      "56 Train Loss 0.02435404 Test MSE 0.08116102768858385 Test RE 0.13617012278589233\n",
      "57 Train Loss 0.021503417 Test MSE 0.08111624574477419 Test RE 0.13613255053997558\n",
      "58 Train Loss 0.019743389 Test MSE 0.08717591988661187 Test RE 0.14112577167815055\n",
      "59 Train Loss 0.017826287 Test MSE 0.08984930945812025 Test RE 0.14327335543752392\n",
      "60 Train Loss 0.01673973 Test MSE 0.08913243700477184 Test RE 0.14270064980417194\n",
      "61 Train Loss 0.01506824 Test MSE 0.0824018898541926 Test RE 0.1372071193216736\n",
      "62 Train Loss 0.014619567 Test MSE 0.08067827390712562 Test RE 0.1357645421311135\n",
      "63 Train Loss 0.013154437 Test MSE 0.07969379337290639 Test RE 0.13493366294876985\n",
      "64 Train Loss 0.012792345 Test MSE 0.08072997016327749 Test RE 0.13580803212074577\n",
      "65 Train Loss 0.011796146 Test MSE 0.07507320410511775 Test RE 0.13096357934470237\n",
      "66 Train Loss 0.011291887 Test MSE 0.07389239601946078 Test RE 0.12992955015994184\n",
      "67 Train Loss 0.010366911 Test MSE 0.07237915662424438 Test RE 0.1285922571447838\n",
      "68 Train Loss 0.010166078 Test MSE 0.07223930446164717 Test RE 0.12846796306832386\n",
      "69 Train Loss 0.009675778 Test MSE 0.07096276625104225 Test RE 0.1273278273631756\n",
      "70 Train Loss 0.008908783 Test MSE 0.06730162201035787 Test RE 0.1239997546450692\n",
      "71 Train Loss 0.008331922 Test MSE 0.06592070343529796 Test RE 0.1227210258002639\n",
      "72 Train Loss 0.0080394335 Test MSE 0.06339586542586595 Test RE 0.12034790310423762\n",
      "73 Train Loss 0.0071113836 Test MSE 0.060258375133207594 Test RE 0.11733207972282325\n",
      "74 Train Loss 0.0069430713 Test MSE 0.05849749625960978 Test RE 0.11560502166779131\n",
      "75 Train Loss 0.006692541 Test MSE 0.056815389383098845 Test RE 0.11393077562481092\n",
      "76 Train Loss 0.006110496 Test MSE 0.053790948259323436 Test RE 0.11085688229344239\n",
      "77 Train Loss 0.006023537 Test MSE 0.05381800536114333 Test RE 0.11088475955678447\n",
      "78 Train Loss 0.0057214145 Test MSE 0.05181562667358295 Test RE 0.10880239060581276\n",
      "79 Train Loss 0.0054190606 Test MSE 0.0516514423266984 Test RE 0.10862987679232584\n",
      "80 Train Loss 0.005259845 Test MSE 0.05118181167968299 Test RE 0.10813490114120902\n",
      "81 Train Loss 0.004868065 Test MSE 0.048206107307835644 Test RE 0.1049443572233092\n",
      "82 Train Loss 0.004801069 Test MSE 0.046562364655681227 Test RE 0.10313963119680342\n",
      "83 Train Loss 0.004509512 Test MSE 0.046430648143912207 Test RE 0.10299364619718732\n",
      "84 Train Loss 0.004176361 Test MSE 0.04380050959848039 Test RE 0.10003400159529867\n",
      "85 Train Loss 0.004129015 Test MSE 0.04339135501632127 Test RE 0.09956568052837655\n",
      "86 Train Loss 0.0040686307 Test MSE 0.04305333785595335 Test RE 0.09917711571205068\n",
      "87 Train Loss 0.0037802365 Test MSE 0.04080571538036907 Test RE 0.09655361939022732\n",
      "88 Train Loss 0.003606629 Test MSE 0.041960325133777246 Test RE 0.09791009740779409\n",
      "89 Train Loss 0.0035524894 Test MSE 0.0417575682429287 Test RE 0.0976732547870287\n",
      "90 Train Loss 0.0035131015 Test MSE 0.04041544325778386 Test RE 0.09609078325761056\n",
      "91 Train Loss 0.0034052082 Test MSE 0.0386603291430865 Test RE 0.09398116707428693\n",
      "92 Train Loss 0.0031615691 Test MSE 0.03602718749744649 Test RE 0.09072421939676062\n",
      "93 Train Loss 0.0029788516 Test MSE 0.035298091774782187 Test RE 0.08980151721993765\n",
      "94 Train Loss 0.002892402 Test MSE 0.03334702608298586 Test RE 0.08728439678515243\n",
      "95 Train Loss 0.0028602032 Test MSE 0.03265794530171423 Test RE 0.08637786968151567\n",
      "96 Train Loss 0.002746028 Test MSE 0.031374974375553144 Test RE 0.08466418852440107\n",
      "97 Train Loss 0.0025128513 Test MSE 0.029838738243668093 Test RE 0.08256543771399934\n",
      "98 Train Loss 0.0023791734 Test MSE 0.028813256824398302 Test RE 0.0811342517751581\n",
      "99 Train Loss 0.0022554852 Test MSE 0.026669309217416438 Test RE 0.07805737525940068\n",
      "Training time: 150.15\n",
      "3\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.154182 Test MSE 6.3212643875659875 Test RE 1.2017386742933984\n",
      "1 Train Loss 48.17395 Test MSE 8.595885934558764 Test RE 1.4013718269022901\n",
      "2 Train Loss 39.47326 Test MSE 8.783263795020584 Test RE 1.416563422351451\n",
      "3 Train Loss 34.456383 Test MSE 8.657782816980095 Test RE 1.4064082453788083\n",
      "4 Train Loss 30.988995 Test MSE 9.075649344104326 Test RE 1.439948348714453\n",
      "5 Train Loss 28.299713 Test MSE 9.544674345752371 Test RE 1.476687565609811\n",
      "6 Train Loss 24.08411 Test MSE 9.084719433136314 Test RE 1.4406677021041807\n",
      "7 Train Loss 20.964653 Test MSE 9.397548577368369 Test RE 1.46526221306065\n",
      "8 Train Loss 18.778725 Test MSE 9.293016895592828 Test RE 1.4570901543570038\n",
      "9 Train Loss 17.186316 Test MSE 9.523727362668566 Test RE 1.4750662877064034\n",
      "10 Train Loss 15.864575 Test MSE 9.38190109706175 Test RE 1.4640418302464573\n",
      "11 Train Loss 14.647385 Test MSE 9.080814507937262 Test RE 1.4403580445349724\n",
      "12 Train Loss 13.343197 Test MSE 9.26021971495772 Test RE 1.4545166796614826\n",
      "13 Train Loss 12.277708 Test MSE 8.99620431933237 Test RE 1.4336320964674587\n",
      "14 Train Loss 10.965358 Test MSE 8.781946667387038 Test RE 1.4164572052990474\n",
      "15 Train Loss 9.635453 Test MSE 8.682057425700794 Test RE 1.4083785022973618\n",
      "16 Train Loss 8.809862 Test MSE 8.594158032069966 Test RE 1.4012309714055868\n",
      "17 Train Loss 7.913007 Test MSE 8.55455671896089 Test RE 1.3979988538337147\n",
      "18 Train Loss 7.054202 Test MSE 8.543254344818278 Test RE 1.397075022881198\n",
      "19 Train Loss 6.3230147 Test MSE 8.419741480640191 Test RE 1.3869392503405467\n",
      "20 Train Loss 5.5943546 Test MSE 8.338398854127435 Test RE 1.3802234214648292\n",
      "21 Train Loss 5.070898 Test MSE 8.142835541132017 Test RE 1.3639419660503465\n",
      "22 Train Loss 4.352842 Test MSE 8.019757579639126 Test RE 1.3535948103321978\n",
      "23 Train Loss 3.7500534 Test MSE 7.924804546587852 Test RE 1.345557744401268\n",
      "24 Train Loss 3.2478726 Test MSE 7.848084887289226 Test RE 1.3390287637307\n",
      "25 Train Loss 2.8443787 Test MSE 7.565001843355791 Test RE 1.3146573668112262\n",
      "26 Train Loss 2.5453625 Test MSE 7.783943501849944 Test RE 1.3335456829376242\n",
      "27 Train Loss 2.363789 Test MSE 7.791468564844237 Test RE 1.3341901243523202\n",
      "28 Train Loss 2.2421923 Test MSE 7.7683852172228605 Test RE 1.3322122931776375\n",
      "29 Train Loss 2.1228685 Test MSE 7.746077486927981 Test RE 1.330298124568063\n",
      "30 Train Loss 2.0124757 Test MSE 7.722216662858574 Test RE 1.3282476356845567\n",
      "31 Train Loss 1.9239951 Test MSE 7.790160097428386 Test RE 1.334078090427702\n",
      "32 Train Loss 1.8598456 Test MSE 7.695498905162427 Test RE 1.3259478719686466\n",
      "33 Train Loss 1.797212 Test MSE 7.713047337486324 Test RE 1.327458823819461\n",
      "34 Train Loss 1.7532282 Test MSE 7.704242725380139 Test RE 1.3267009458444792\n",
      "35 Train Loss 1.6997831 Test MSE 7.6591268566057265 Test RE 1.322810676989099\n",
      "36 Train Loss 1.6396781 Test MSE 7.608655995501993 Test RE 1.3184450524404472\n",
      "37 Train Loss 1.5812223 Test MSE 7.576976308921733 Test RE 1.3156974256957652\n",
      "38 Train Loss 1.532788 Test MSE 7.478712502444655 Test RE 1.3071381179072572\n",
      "39 Train Loss 1.4735599 Test MSE 7.380461499931704 Test RE 1.298523518394449\n",
      "40 Train Loss 1.4376498 Test MSE 7.31307731134952 Test RE 1.2925821154782051\n",
      "41 Train Loss 1.4004503 Test MSE 7.262561137094402 Test RE 1.2881100271397994\n",
      "42 Train Loss 1.3539761 Test MSE 7.225474904404525 Test RE 1.2848169539878107\n",
      "43 Train Loss 1.3205514 Test MSE 7.119820226101125 Test RE 1.275388727743277\n",
      "44 Train Loss 1.2982379 Test MSE 7.092454801481138 Test RE 1.2729353543362696\n",
      "45 Train Loss 1.2672422 Test MSE 6.990542155181195 Test RE 1.26375675438736\n",
      "46 Train Loss 1.243867 Test MSE 7.014358986287252 Test RE 1.2659077383511417\n",
      "47 Train Loss 1.2103432 Test MSE 6.8565299499245675 Test RE 1.2515847100859814\n",
      "48 Train Loss 1.1809305 Test MSE 6.739286344674873 Test RE 1.2408377998792075\n",
      "49 Train Loss 1.1578664 Test MSE 6.644931533597387 Test RE 1.2321208748467085\n",
      "50 Train Loss 1.1300741 Test MSE 6.443591170717292 Test RE 1.2133107602478086\n",
      "51 Train Loss 1.1087728 Test MSE 6.405500735390936 Test RE 1.2097192818555242\n",
      "52 Train Loss 1.0811702 Test MSE 6.245038900831581 Test RE 1.194471066239231\n",
      "53 Train Loss 1.0573751 Test MSE 6.172061040555166 Test RE 1.1874714218773308\n",
      "54 Train Loss 1.0444918 Test MSE 6.138323672496431 Test RE 1.1842215304173696\n",
      "55 Train Loss 1.0283616 Test MSE 6.089436467772442 Test RE 1.1794963795383975\n",
      "56 Train Loss 1.0145335 Test MSE 6.068848996099176 Test RE 1.177500841251197\n",
      "57 Train Loss 0.99896574 Test MSE 6.055540598279725 Test RE 1.1762090600481345\n",
      "58 Train Loss 0.98604536 Test MSE 6.031244368540116 Test RE 1.1738470770376441\n",
      "59 Train Loss 0.97273856 Test MSE 6.0191211493706165 Test RE 1.1726667266042234\n",
      "60 Train Loss 0.95722795 Test MSE 5.999963010573996 Test RE 1.1707990106543276\n",
      "61 Train Loss 0.94245195 Test MSE 6.011699565531703 Test RE 1.171943553853429\n",
      "62 Train Loss 0.92646974 Test MSE 6.018221288860667 Test RE 1.172579066305078\n",
      "63 Train Loss 0.91495436 Test MSE 6.047734501507483 Test RE 1.1754506997936418\n",
      "64 Train Loss 0.89956284 Test MSE 6.04498568904658 Test RE 1.1751835368781671\n",
      "65 Train Loss 0.8912415 Test MSE 6.05838580743863 Test RE 1.1764853498137795\n",
      "66 Train Loss 0.88207924 Test MSE 6.053909907910495 Test RE 1.1760506793140815\n",
      "67 Train Loss 0.87047035 Test MSE 6.0556117481337 Test RE 1.1762159699891779\n",
      "68 Train Loss 0.8606801 Test MSE 6.069918739907463 Test RE 1.1776046145311079\n",
      "69 Train Loss 0.85494906 Test MSE 6.073360745162593 Test RE 1.1779384531696129\n",
      "70 Train Loss 0.84556127 Test MSE 6.090404821432776 Test RE 1.1795901586786053\n",
      "71 Train Loss 0.83720773 Test MSE 6.092430978246757 Test RE 1.1797863554800962\n",
      "72 Train Loss 0.8279866 Test MSE 6.089931297284587 Test RE 1.179544301687249\n",
      "73 Train Loss 0.8208849 Test MSE 6.102835519531561 Test RE 1.1807933344302313\n",
      "74 Train Loss 0.81482255 Test MSE 6.132880711809508 Test RE 1.183696378838102\n",
      "75 Train Loss 0.8099094 Test MSE 6.133643143199279 Test RE 1.1837699543135058\n",
      "76 Train Loss 0.8037287 Test MSE 6.137438674009289 Test RE 1.1841361592234716\n",
      "77 Train Loss 0.799754 Test MSE 6.1413419438754175 Test RE 1.184512641058552\n",
      "78 Train Loss 0.7947699 Test MSE 6.135595876306856 Test RE 1.1839583743744038\n",
      "79 Train Loss 0.7889587 Test MSE 6.135533086412797 Test RE 1.1839523162170063\n",
      "80 Train Loss 0.7838523 Test MSE 6.14080182463805 Test RE 1.1844605521065266\n",
      "81 Train Loss 0.7784771 Test MSE 6.145531368482662 Test RE 1.1849165902636505\n",
      "82 Train Loss 0.77332115 Test MSE 6.153107917554711 Test RE 1.1856467804494495\n",
      "83 Train Loss 0.7679751 Test MSE 6.181939316706895 Test RE 1.1884213056211308\n",
      "84 Train Loss 0.76446486 Test MSE 6.172294461359376 Test RE 1.1874938761200733\n",
      "85 Train Loss 0.7610233 Test MSE 6.183107497363183 Test RE 1.1885335863416813\n",
      "86 Train Loss 0.75762635 Test MSE 6.1891606383407325 Test RE 1.1891152195604506\n",
      "87 Train Loss 0.75404036 Test MSE 6.19299026893621 Test RE 1.1894830535905498\n",
      "88 Train Loss 0.74990845 Test MSE 6.183667940636695 Test RE 1.188587450079345\n",
      "89 Train Loss 0.74610555 Test MSE 6.20443135801919 Test RE 1.1905812873509714\n",
      "90 Train Loss 0.7425581 Test MSE 6.200232261634325 Test RE 1.1901783324742512\n",
      "91 Train Loss 0.7394026 Test MSE 6.208529932740747 Test RE 1.190974464459953\n",
      "92 Train Loss 0.7353459 Test MSE 6.212350409192933 Test RE 1.1913408466934443\n",
      "93 Train Loss 0.7325099 Test MSE 6.209064860522176 Test RE 1.1910257706155698\n",
      "94 Train Loss 0.729967 Test MSE 6.214903258939621 Test RE 1.1915856012227057\n",
      "95 Train Loss 0.7261121 Test MSE 6.212483217626765 Test RE 1.1913535809450542\n",
      "96 Train Loss 0.72300994 Test MSE 6.225747765133073 Test RE 1.1926247586138812\n",
      "97 Train Loss 0.71904415 Test MSE 6.2204688043615 Test RE 1.1921190238239705\n",
      "98 Train Loss 0.7168833 Test MSE 6.230182543694039 Test RE 1.1930494533946738\n",
      "99 Train Loss 0.71387863 Test MSE 6.233504410994273 Test RE 1.1933674716711962\n",
      "Training time: 150.72\n",
      "4\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.477386 Test MSE 7.696690411516714 Test RE 1.32605051730623\n",
      "1 Train Loss 43.225296 Test MSE 8.555521862495679 Test RE 1.3980777142320393\n",
      "2 Train Loss 33.604885 Test MSE 7.856933103587704 Test RE 1.3397833859545685\n",
      "3 Train Loss 27.13203 Test MSE 7.053694366620086 Test RE 1.2694522779880304\n",
      "4 Train Loss 22.184362 Test MSE 6.908721474313572 Test RE 1.256339176134694\n",
      "5 Train Loss 18.161888 Test MSE 6.470446845736544 Test RE 1.2158365566472042\n",
      "6 Train Loss 15.603706 Test MSE 6.1775332200818465 Test RE 1.1879977142370888\n",
      "7 Train Loss 12.226776 Test MSE 5.763095323473196 Test RE 1.1474557901690066\n",
      "8 Train Loss 9.720072 Test MSE 5.576450324407523 Test RE 1.128721971918454\n",
      "9 Train Loss 8.428881 Test MSE 5.177219638581568 Test RE 1.0875678361418504\n",
      "10 Train Loss 7.5899324 Test MSE 4.728061785516282 Test RE 1.0393208309655269\n",
      "11 Train Loss 6.700787 Test MSE 4.413767222861208 Test RE 1.004182787376574\n",
      "12 Train Loss 6.172565 Test MSE 4.079101043937084 Test RE 0.965362205626494\n",
      "13 Train Loss 5.6374464 Test MSE 3.744897256133567 Test RE 0.9249707805995567\n",
      "14 Train Loss 5.056364 Test MSE 3.4938305426243383 Test RE 0.8934268061816788\n",
      "15 Train Loss 4.352526 Test MSE 3.2930634520208475 Test RE 0.8673774151326403\n",
      "16 Train Loss 3.670982 Test MSE 2.9998672476461494 Test RE 0.8278641543251128\n",
      "17 Train Loss 3.0863905 Test MSE 2.948852136581024 Test RE 0.8207947283673459\n",
      "18 Train Loss 2.520985 Test MSE 2.5560272447382015 Test RE 0.7641714350665036\n",
      "19 Train Loss 2.2241216 Test MSE 2.2356295352673796 Test RE 0.7146739948660294\n",
      "20 Train Loss 1.8752723 Test MSE 1.9545347294618949 Test RE 0.668235826676901\n",
      "21 Train Loss 1.4929085 Test MSE 1.712734171753173 Test RE 0.6255370556919027\n",
      "22 Train Loss 1.2479925 Test MSE 1.5114996533629692 Test RE 0.5876409961082881\n",
      "23 Train Loss 0.99317724 Test MSE 1.3017102526622297 Test RE 0.5453373244053605\n",
      "24 Train Loss 0.82051873 Test MSE 1.1582448390965037 Test RE 0.5144086314414242\n",
      "25 Train Loss 0.7345628 Test MSE 1.1363401507888575 Test RE 0.5095211737216147\n",
      "26 Train Loss 0.6340871 Test MSE 1.0272898957288903 Test RE 0.48445625600269293\n",
      "27 Train Loss 0.5401747 Test MSE 0.8894499657641888 Test RE 0.45078434120727984\n",
      "28 Train Loss 0.46891275 Test MSE 0.7657650350971864 Test RE 0.4182691430238722\n",
      "29 Train Loss 0.4219162 Test MSE 0.6811326580614231 Test RE 0.3944790214100754\n",
      "30 Train Loss 0.36743784 Test MSE 0.5883137059619313 Test RE 0.36661695283283025\n",
      "31 Train Loss 0.3271168 Test MSE 0.5007282864178607 Test RE 0.33822766164168794\n",
      "32 Train Loss 0.2930647 Test MSE 0.4292134021025879 Test RE 0.31314443449954465\n",
      "33 Train Loss 0.25540587 Test MSE 0.2778236343583457 Test RE 0.25193740654944796\n",
      "34 Train Loss 0.19095089 Test MSE 0.23952110570272048 Test RE 0.23392678613862075\n",
      "35 Train Loss 0.14868304 Test MSE 0.20608395023979298 Test RE 0.2169852163416641\n",
      "36 Train Loss 0.12310604 Test MSE 0.20092126974526925 Test RE 0.21425009211426985\n",
      "37 Train Loss 0.110398985 Test MSE 0.1761663834900801 Test RE 0.2006178536391718\n",
      "38 Train Loss 0.0989293 Test MSE 0.14980037207240068 Test RE 0.1849969235710461\n",
      "39 Train Loss 0.085446954 Test MSE 0.1383778525911213 Test RE 0.17780392905912765\n",
      "40 Train Loss 0.07333354 Test MSE 0.12847487434874696 Test RE 0.171323587964639\n",
      "41 Train Loss 0.06477888 Test MSE 0.1223091704101497 Test RE 0.1671620045904774\n",
      "42 Train Loss 0.05689969 Test MSE 0.10952438920366202 Test RE 0.15818433759555606\n",
      "43 Train Loss 0.049853086 Test MSE 0.10350805696386312 Test RE 0.15377832933111035\n",
      "44 Train Loss 0.044396598 Test MSE 0.0973829331075269 Test RE 0.14915900780732538\n",
      "45 Train Loss 0.03953643 Test MSE 0.09984446150467904 Test RE 0.15103237431037708\n",
      "46 Train Loss 0.035555772 Test MSE 0.09191661718804932 Test RE 0.14491224230870342\n",
      "47 Train Loss 0.032465775 Test MSE 0.09097934279340644 Test RE 0.14417151358709485\n",
      "48 Train Loss 0.029475067 Test MSE 0.0898396785622812 Test RE 0.14326567653743338\n",
      "49 Train Loss 0.026659755 Test MSE 0.08805990388717742 Test RE 0.1418394909132108\n",
      "50 Train Loss 0.022733614 Test MSE 0.08510647054601068 Test RE 0.13944063453695585\n",
      "51 Train Loss 0.020669263 Test MSE 0.08223647370639141 Test RE 0.13706933319249887\n",
      "52 Train Loss 0.018710066 Test MSE 0.07708623440953999 Test RE 0.13270780804805526\n",
      "53 Train Loss 0.017159421 Test MSE 0.0737824389140883 Test RE 0.12983284199467562\n",
      "54 Train Loss 0.015833646 Test MSE 0.07047438901153333 Test RE 0.12688892555597756\n",
      "55 Train Loss 0.014892281 Test MSE 0.06958916494143559 Test RE 0.12608948555616992\n",
      "56 Train Loss 0.014207877 Test MSE 0.0692217583193198 Test RE 0.1257561907077002\n",
      "57 Train Loss 0.013701098 Test MSE 0.07050271172951014 Test RE 0.12691442047900434\n",
      "58 Train Loss 0.012499858 Test MSE 0.06812962449972068 Test RE 0.12476019874778381\n",
      "59 Train Loss 0.011994198 Test MSE 0.06742577232981849 Test RE 0.12411407221781548\n",
      "60 Train Loss 0.010793222 Test MSE 0.06731032926071132 Test RE 0.12400777571466312\n",
      "61 Train Loss 0.010273265 Test MSE 0.07074800470396951 Test RE 0.1271350090494001\n",
      "62 Train Loss 0.00965969 Test MSE 0.0726113378565978 Test RE 0.1287983441214654\n",
      "63 Train Loss 0.008784712 Test MSE 0.07435436274839603 Test RE 0.13033506960583024\n",
      "64 Train Loss 0.008557246 Test MSE 0.07412451784408194 Test RE 0.13013346719091776\n",
      "65 Train Loss 0.007996541 Test MSE 0.07608091839858366 Test RE 0.13183961724539028\n",
      "66 Train Loss 0.0076208278 Test MSE 0.07707618495989808 Test RE 0.13269915745101565\n",
      "67 Train Loss 0.0072884634 Test MSE 0.07658215406473662 Test RE 0.13227319661999745\n",
      "68 Train Loss 0.006874857 Test MSE 0.07506272892162964 Test RE 0.13095444216054486\n",
      "69 Train Loss 0.006498958 Test MSE 0.07294723957623464 Test RE 0.12909591243079702\n",
      "70 Train Loss 0.005964199 Test MSE 0.07112611696394978 Test RE 0.12747429245155179\n",
      "71 Train Loss 0.005842365 Test MSE 0.07084072278468809 Test RE 0.12721828952170344\n",
      "72 Train Loss 0.0053688935 Test MSE 0.07014718042014122 Test RE 0.12659401380050136\n",
      "73 Train Loss 0.004906574 Test MSE 0.06948355913079893 Test RE 0.12599377498067005\n",
      "74 Train Loss 0.004713251 Test MSE 0.06880715908181674 Test RE 0.1253790208217695\n",
      "75 Train Loss 0.0045481287 Test MSE 0.06830403934908671 Test RE 0.12491979248229149\n",
      "76 Train Loss 0.004265554 Test MSE 0.06577848820195926 Test RE 0.12258857710352691\n",
      "77 Train Loss 0.0041810838 Test MSE 0.0656232394132641 Test RE 0.12244382635407482\n",
      "78 Train Loss 0.0039584935 Test MSE 0.06263819432285399 Test RE 0.11962657677385592\n",
      "79 Train Loss 0.0037121337 Test MSE 0.06212785520033573 Test RE 0.11913825665101749\n",
      "80 Train Loss 0.003644408 Test MSE 0.061628489966875186 Test RE 0.11865849170661052\n",
      "81 Train Loss 0.0035461918 Test MSE 0.06108908057252693 Test RE 0.11813806539823112\n",
      "82 Train Loss 0.003253837 Test MSE 0.05652868594861125 Test RE 0.11364295169842085\n",
      "83 Train Loss 0.0031518224 Test MSE 0.05545849813236568 Test RE 0.11256208070926968\n",
      "84 Train Loss 0.0030902026 Test MSE 0.053958153678895296 Test RE 0.111029044061296\n",
      "85 Train Loss 0.0030121747 Test MSE 0.053343744388500654 Test RE 0.11039510295383534\n",
      "86 Train Loss 0.0029010982 Test MSE 0.05289118781500094 Test RE 0.10992582164965345\n",
      "87 Train Loss 0.002807718 Test MSE 0.051742412503542064 Test RE 0.10872549592052609\n",
      "88 Train Loss 0.002763044 Test MSE 0.05135813432803818 Test RE 0.1083210047441302\n",
      "89 Train Loss 0.0026411563 Test MSE 0.050521576010754014 Test RE 0.1074351773769212\n",
      "90 Train Loss 0.0025549084 Test MSE 0.04862016910257719 Test RE 0.10539409834637001\n",
      "91 Train Loss 0.0025065076 Test MSE 0.04679742781373157 Test RE 0.10339964597626117\n",
      "92 Train Loss 0.0024425816 Test MSE 0.04654379261345284 Test RE 0.10311905981210748\n",
      "93 Train Loss 0.0023668804 Test MSE 0.04643025854957548 Test RE 0.10299321409224092\n",
      "94 Train Loss 0.0023023335 Test MSE 0.04596601240880929 Test RE 0.10247701704821043\n",
      "95 Train Loss 0.0022571823 Test MSE 0.04525361632993262 Test RE 0.10167980520154188\n",
      "96 Train Loss 0.0020957205 Test MSE 0.04254103167886925 Test RE 0.09858527886420435\n",
      "97 Train Loss 0.0020630937 Test MSE 0.04166271116778995 Test RE 0.09756225374855146\n",
      "98 Train Loss 0.0020451637 Test MSE 0.041530087231733674 Test RE 0.0974068461509945\n",
      "99 Train Loss 0.0020099701 Test MSE 0.04136807872035993 Test RE 0.09721666886727069\n",
      "Training time: 153.53\n",
      "5\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.839355 Test MSE 5.262759703466773 Test RE 1.0965156401482794\n",
      "1 Train Loss 48.941925 Test MSE 9.358700831545748 Test RE 1.4622305137897087\n",
      "2 Train Loss 41.131905 Test MSE 8.707441605387428 Test RE 1.4104358740658716\n",
      "3 Train Loss 37.021893 Test MSE 8.878979550861718 Test RE 1.4242610191321057\n",
      "4 Train Loss 33.117172 Test MSE 8.82675423137093 Test RE 1.420066157161254\n",
      "5 Train Loss 29.824524 Test MSE 8.90871187413835 Test RE 1.426643680190602\n",
      "6 Train Loss 25.68948 Test MSE 8.678233853310525 Test RE 1.4080683436613\n",
      "7 Train Loss 22.994576 Test MSE 8.836386003251306 Test RE 1.420840735429713\n",
      "8 Train Loss 20.188976 Test MSE 8.809677966694304 Test RE 1.4186918600791645\n",
      "9 Train Loss 17.30822 Test MSE 8.742083797712395 Test RE 1.4132387691067425\n",
      "10 Train Loss 14.868706 Test MSE 8.315752653530764 Test RE 1.3783478774647349\n",
      "11 Train Loss 12.407706 Test MSE 8.354873574853459 Test RE 1.3815862475454568\n",
      "12 Train Loss 10.056252 Test MSE 7.8778198150709065 Test RE 1.3415630304760566\n",
      "13 Train Loss 8.238614 Test MSE 7.886258466202532 Test RE 1.3422813734021157\n",
      "14 Train Loss 6.307537 Test MSE 7.145122200100539 Test RE 1.2776529164858068\n",
      "15 Train Loss 5.021192 Test MSE 6.793959050804921 Test RE 1.2458608040720565\n",
      "16 Train Loss 4.100981 Test MSE 6.980307701875348 Test RE 1.2628313185194997\n",
      "17 Train Loss 3.6036851 Test MSE 6.965913366150102 Test RE 1.261528582337263\n",
      "18 Train Loss 3.1416373 Test MSE 6.797418111199512 Test RE 1.246177921038669\n",
      "19 Train Loss 2.864062 Test MSE 6.6989213353926145 Test RE 1.237116214947435\n",
      "20 Train Loss 2.613579 Test MSE 6.803414438690411 Test RE 1.2467274564336053\n",
      "21 Train Loss 2.4191961 Test MSE 6.825034913857305 Test RE 1.2487068639327454\n",
      "22 Train Loss 2.25212 Test MSE 6.748342934777631 Test RE 1.2416712699108903\n",
      "23 Train Loss 2.1434486 Test MSE 6.5510703738578435 Test RE 1.2233879335624787\n",
      "24 Train Loss 2.043437 Test MSE 6.227924184414376 Test RE 1.1928332014233447\n",
      "25 Train Loss 1.9360132 Test MSE 5.970178895319081 Test RE 1.1678894430480884\n",
      "26 Train Loss 1.8427625 Test MSE 5.838548706252177 Test RE 1.1549429017560005\n",
      "27 Train Loss 1.7349691 Test MSE 5.706751894116775 Test RE 1.1418329099401416\n",
      "28 Train Loss 1.6742167 Test MSE 5.570602980005865 Test RE 1.128130040063233\n",
      "29 Train Loss 1.6307342 Test MSE 5.515628033768722 Test RE 1.1225496154106036\n",
      "30 Train Loss 1.5726972 Test MSE 5.491473620985374 Test RE 1.120088945724657\n",
      "31 Train Loss 1.5203125 Test MSE 5.414203124631535 Test RE 1.112180644930176\n",
      "32 Train Loss 1.4769926 Test MSE 5.46339985632209 Test RE 1.1172221919638308\n",
      "33 Train Loss 1.454228 Test MSE 5.468038285227157 Test RE 1.1176963524132197\n",
      "34 Train Loss 1.4300767 Test MSE 5.429933359094819 Test RE 1.113795118297288\n",
      "35 Train Loss 1.4015133 Test MSE 5.417136974669541 Test RE 1.1124819385127274\n",
      "36 Train Loss 1.3687822 Test MSE 5.434701976497015 Test RE 1.11428408352432\n",
      "37 Train Loss 1.3431326 Test MSE 5.43015721375424 Test RE 1.1138180767426988\n",
      "38 Train Loss 1.3155257 Test MSE 5.465542788486324 Test RE 1.1174412768481248\n",
      "39 Train Loss 1.2923163 Test MSE 5.50461455958004 Test RE 1.121428315267659\n",
      "40 Train Loss 1.2699871 Test MSE 5.525385447052588 Test RE 1.123542099001361\n",
      "41 Train Loss 1.2380502 Test MSE 5.612493543346159 Test RE 1.1323638268992218\n",
      "42 Train Loss 1.2050586 Test MSE 5.609602096912094 Test RE 1.1320721035208647\n",
      "43 Train Loss 1.184439 Test MSE 5.646729184305764 Test RE 1.1358122283754468\n",
      "44 Train Loss 1.1566122 Test MSE 5.702555136494349 Test RE 1.141412979532058\n",
      "45 Train Loss 1.131452 Test MSE 5.720763625047465 Test RE 1.143233816029628\n",
      "46 Train Loss 1.1117306 Test MSE 5.751063151862252 Test RE 1.1462573370833185\n",
      "47 Train Loss 1.08666 Test MSE 5.762899027119237 Test RE 1.1474362483001574\n",
      "48 Train Loss 1.0656157 Test MSE 5.790752518470352 Test RE 1.150205824929222\n",
      "49 Train Loss 1.0552809 Test MSE 5.824380702696492 Test RE 1.1535407404562668\n",
      "50 Train Loss 1.0417287 Test MSE 5.825503424015567 Test RE 1.1536519147116935\n",
      "51 Train Loss 1.0290133 Test MSE 5.7945206616644205 Test RE 1.1505799935188306\n",
      "52 Train Loss 1.0105101 Test MSE 5.784705699433046 Test RE 1.1496051341670683\n",
      "53 Train Loss 0.99936783 Test MSE 5.80930944906784 Test RE 1.1520473141890761\n",
      "54 Train Loss 0.98113644 Test MSE 5.820343273297015 Test RE 1.1531408570242514\n",
      "55 Train Loss 0.96814203 Test MSE 5.798835267852508 Test RE 1.1510082753464355\n",
      "56 Train Loss 0.9562865 Test MSE 5.838663131269177 Test RE 1.1549542190987447\n",
      "57 Train Loss 0.94620794 Test MSE 5.86933393779884 Test RE 1.157983763548982\n",
      "58 Train Loss 0.9331652 Test MSE 5.888853016895685 Test RE 1.15990766293225\n",
      "59 Train Loss 0.923164 Test MSE 5.905044770388344 Test RE 1.1615011860502207\n",
      "60 Train Loss 0.91404295 Test MSE 5.906143221507163 Test RE 1.1616092117298922\n",
      "61 Train Loss 0.90174425 Test MSE 5.919015043328781 Test RE 1.1628743257399692\n",
      "62 Train Loss 0.8926057 Test MSE 5.923374242289479 Test RE 1.1633024601107538\n",
      "63 Train Loss 0.8840786 Test MSE 5.926902059166344 Test RE 1.1636488257984023\n",
      "64 Train Loss 0.8784198 Test MSE 5.9420232474247685 Test RE 1.1651322773684938\n",
      "65 Train Loss 0.87176275 Test MSE 5.94826208568265 Test RE 1.165743783288457\n",
      "66 Train Loss 0.863988 Test MSE 5.966171949782609 Test RE 1.1674974569000711\n",
      "67 Train Loss 0.85653335 Test MSE 5.978871594543416 Test RE 1.1687393689131558\n",
      "68 Train Loss 0.8495637 Test MSE 5.9819819230438975 Test RE 1.1690433301760017\n",
      "69 Train Loss 0.84091854 Test MSE 6.015588969667136 Test RE 1.1723226001648936\n",
      "70 Train Loss 0.83410025 Test MSE 6.0084011936794175 Test RE 1.1716220111727964\n",
      "71 Train Loss 0.83002377 Test MSE 6.042206970610283 Test RE 1.1749134055924635\n",
      "72 Train Loss 0.82644975 Test MSE 6.0325369610595425 Test RE 1.173972857438087\n",
      "73 Train Loss 0.82066876 Test MSE 6.063539473735145 Test RE 1.1769856418216977\n",
      "74 Train Loss 0.81441003 Test MSE 6.068733621037385 Test RE 1.1774896484469197\n",
      "75 Train Loss 0.81031036 Test MSE 6.081769459624621 Test RE 1.1787536132171896\n",
      "76 Train Loss 0.80643356 Test MSE 6.081248835516264 Test RE 1.178703159094666\n",
      "77 Train Loss 0.79950964 Test MSE 6.100174328849246 Test RE 1.1805358591269834\n",
      "78 Train Loss 0.7933967 Test MSE 6.118566287857253 Test RE 1.1823141711018716\n",
      "79 Train Loss 0.7887965 Test MSE 6.133658901279056 Test RE 1.1837714749374613\n",
      "80 Train Loss 0.7825529 Test MSE 6.141347204184477 Test RE 1.184513148350061\n",
      "81 Train Loss 0.7781501 Test MSE 6.134797262821739 Test RE 1.1838813194385664\n",
      "82 Train Loss 0.77500176 Test MSE 6.146709047113179 Test RE 1.1850301186159504\n",
      "83 Train Loss 0.7722583 Test MSE 6.134905729556958 Test RE 1.1838917852427742\n",
      "84 Train Loss 0.7685982 Test MSE 6.157102225151293 Test RE 1.1860315510145145\n",
      "85 Train Loss 0.7648617 Test MSE 6.1657708451981685 Test RE 1.1868661677131147\n",
      "86 Train Loss 0.76137215 Test MSE 6.183973433085461 Test RE 1.1886168096770522\n",
      "87 Train Loss 0.7563516 Test MSE 6.195069538751279 Test RE 1.1896827187393741\n",
      "88 Train Loss 0.7531525 Test MSE 6.202409081611398 Test RE 1.1903872421168025\n",
      "89 Train Loss 0.7501663 Test MSE 6.205871330102837 Test RE 1.1907194389604192\n",
      "90 Train Loss 0.74571645 Test MSE 6.2070177324258555 Test RE 1.1908294138876645\n",
      "91 Train Loss 0.74232876 Test MSE 6.214789889624318 Test RE 1.1915747330036708\n",
      "92 Train Loss 0.7403835 Test MSE 6.2177679050000245 Test RE 1.1918601893862166\n",
      "93 Train Loss 0.7368588 Test MSE 6.227934681717644 Test RE 1.1928342066962265\n",
      "94 Train Loss 0.7347535 Test MSE 6.2381227096636245 Test RE 1.1938094627735245\n",
      "95 Train Loss 0.73219824 Test MSE 6.245490811460933 Test RE 1.1945142832963949\n",
      "96 Train Loss 0.7292729 Test MSE 6.2612330660178115 Test RE 1.1960187698079243\n",
      "97 Train Loss 0.72659063 Test MSE 6.267353696424706 Test RE 1.196603207461497\n",
      "98 Train Loss 0.72376335 Test MSE 6.276023517876061 Test RE 1.1974305702811707\n",
      "99 Train Loss 0.7216823 Test MSE 6.28135033333103 Test RE 1.197938625961447\n",
      "Training time: 155.95\n",
      "6\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.038864 Test MSE 6.004516771069427 Test RE 1.1712432239807011\n",
      "1 Train Loss 45.986763 Test MSE 8.879174536323866 Test RE 1.4242766576785628\n",
      "2 Train Loss 39.853493 Test MSE 8.663436970232064 Test RE 1.4068674131606553\n",
      "3 Train Loss 34.161213 Test MSE 8.464390006498292 Test RE 1.3906117452612334\n",
      "4 Train Loss 29.172773 Test MSE 8.455231101463411 Test RE 1.389859184937778\n",
      "5 Train Loss 26.322811 Test MSE 8.149218801470358 Test RE 1.364476466042371\n",
      "6 Train Loss 23.271687 Test MSE 8.251541529401552 Test RE 1.3730160221117718\n",
      "7 Train Loss 20.82317 Test MSE 8.300620853757234 Test RE 1.3770932477460287\n",
      "8 Train Loss 18.072266 Test MSE 8.7092189199386 Test RE 1.4105798118843034\n",
      "9 Train Loss 15.352688 Test MSE 8.615916450788468 Test RE 1.4030036463420248\n",
      "10 Train Loss 13.578733 Test MSE 8.5194162595296 Test RE 1.395124544979338\n",
      "11 Train Loss 11.284152 Test MSE 8.32584482298424 Test RE 1.3791840196012264\n",
      "12 Train Loss 9.57378 Test MSE 8.109943007420624 Test RE 1.3611843944082163\n",
      "13 Train Loss 8.233671 Test MSE 8.259127799847661 Test RE 1.3736470361993574\n",
      "14 Train Loss 7.227002 Test MSE 8.146847322938115 Test RE 1.3642779155940394\n",
      "15 Train Loss 6.348624 Test MSE 8.041523065214353 Test RE 1.355430382386801\n",
      "16 Train Loss 5.5719914 Test MSE 7.92403569686145 Test RE 1.345492471069235\n",
      "17 Train Loss 4.8109407 Test MSE 7.741709095208863 Test RE 1.3299229615990573\n",
      "18 Train Loss 4.1766715 Test MSE 7.594394448815719 Test RE 1.3172088364128915\n",
      "19 Train Loss 3.7569077 Test MSE 7.467084462455236 Test RE 1.306121541391104\n",
      "20 Train Loss 3.3949363 Test MSE 7.2771793842991 Test RE 1.2894057439437534\n",
      "21 Train Loss 3.1398487 Test MSE 7.205825869237229 Test RE 1.2830687920755215\n",
      "22 Train Loss 2.8995712 Test MSE 7.25696635690129 Test RE 1.287613777896557\n",
      "23 Train Loss 2.7546692 Test MSE 7.190444068147317 Test RE 1.2816986193295614\n",
      "24 Train Loss 2.5842888 Test MSE 7.152865619651896 Test RE 1.2783450476552256\n",
      "25 Train Loss 2.4380503 Test MSE 6.968951432798444 Test RE 1.2618036496485858\n",
      "26 Train Loss 2.2346952 Test MSE 6.68748676976985 Test RE 1.236059930846722\n",
      "27 Train Loss 2.0677245 Test MSE 6.511453617924284 Test RE 1.2196831834392095\n",
      "28 Train Loss 1.9134855 Test MSE 6.486616184020005 Test RE 1.217354767558749\n",
      "29 Train Loss 1.7842177 Test MSE 6.4350011301458885 Test RE 1.2125017498485668\n",
      "30 Train Loss 1.693544 Test MSE 6.392063122610773 Test RE 1.2084497266460215\n",
      "31 Train Loss 1.6131324 Test MSE 6.3490981607113 Test RE 1.204381514387127\n",
      "32 Train Loss 1.5611185 Test MSE 6.342903323333216 Test RE 1.2037938113590365\n",
      "33 Train Loss 1.5182565 Test MSE 6.370683589631697 Test RE 1.206427083096877\n",
      "34 Train Loss 1.4676824 Test MSE 6.370676050566055 Test RE 1.206426369253886\n",
      "35 Train Loss 1.4321922 Test MSE 6.310773237231116 Test RE 1.2007410213114311\n",
      "36 Train Loss 1.409857 Test MSE 6.2960483393202535 Test RE 1.1993393614857009\n",
      "37 Train Loss 1.3896086 Test MSE 6.262981401177825 Test RE 1.196185741368822\n",
      "38 Train Loss 1.3763884 Test MSE 6.271597869553054 Test RE 1.1970083012160408\n",
      "39 Train Loss 1.3469076 Test MSE 6.230913185336842 Test RE 1.1931194084923902\n",
      "40 Train Loss 1.3202566 Test MSE 6.194686031422171 Test RE 1.189645894366346\n",
      "41 Train Loss 1.3053991 Test MSE 6.187840864597249 Test RE 1.1889884296120277\n",
      "42 Train Loss 1.2868711 Test MSE 6.16751100846475 Test RE 1.1870336403012722\n",
      "43 Train Loss 1.2680674 Test MSE 6.170136496332013 Test RE 1.1872862714527728\n",
      "44 Train Loss 1.242501 Test MSE 6.148021594506972 Test RE 1.185156635517641\n",
      "45 Train Loss 1.2148062 Test MSE 6.10277249209742 Test RE 1.1807872370541808\n",
      "46 Train Loss 1.1958796 Test MSE 6.086651668130555 Test RE 1.1792266471312172\n",
      "47 Train Loss 1.1710258 Test MSE 6.084830594615244 Test RE 1.179050226729491\n",
      "48 Train Loss 1.1460199 Test MSE 6.0576978733761 Test RE 1.1764185525390067\n",
      "49 Train Loss 1.1276686 Test MSE 6.0614058406206786 Test RE 1.1767785452484\n",
      "50 Train Loss 1.1130247 Test MSE 6.067770428445762 Test RE 1.177396202731403\n",
      "51 Train Loss 1.0962696 Test MSE 6.0880924622845995 Test RE 1.1793662084547898\n",
      "52 Train Loss 1.0764545 Test MSE 6.10113879489514 Test RE 1.1806291795544255\n",
      "53 Train Loss 1.0517236 Test MSE 6.083058510901293 Test RE 1.1788785269741342\n",
      "54 Train Loss 1.031703 Test MSE 6.083523062168336 Test RE 1.1789235404371052\n",
      "55 Train Loss 1.016525 Test MSE 6.053810142345372 Test RE 1.176040988895343\n",
      "56 Train Loss 1.0044737 Test MSE 6.074449229818024 Test RE 1.1780440051483145\n",
      "57 Train Loss 0.9931296 Test MSE 6.071102206559339 Test RE 1.1777194091375618\n",
      "58 Train Loss 0.9815763 Test MSE 6.054363818400705 Test RE 1.176094767493673\n",
      "59 Train Loss 0.96741545 Test MSE 6.049068779943191 Test RE 1.1755803592573995\n",
      "60 Train Loss 0.9578712 Test MSE 6.092087883406461 Test RE 1.179753135217807\n",
      "61 Train Loss 0.94490176 Test MSE 6.073909459308115 Test RE 1.177991663979945\n",
      "62 Train Loss 0.9347595 Test MSE 6.0918524154100036 Test RE 1.179730335416104\n",
      "63 Train Loss 0.9294261 Test MSE 6.100812524284634 Test RE 1.1805976108779719\n",
      "64 Train Loss 0.9235887 Test MSE 6.102571248377057 Test RE 1.1807677681999955\n",
      "65 Train Loss 0.91653955 Test MSE 6.088540092052332 Test RE 1.1794095643763454\n",
      "66 Train Loss 0.9121268 Test MSE 6.086928266819759 Test RE 1.1792534409135076\n",
      "67 Train Loss 0.90441054 Test MSE 6.088344112986426 Test RE 1.1793905826959037\n",
      "68 Train Loss 0.90022844 Test MSE 6.076522050169708 Test RE 1.1782449834772502\n",
      "69 Train Loss 0.89285076 Test MSE 6.085533052987932 Test RE 1.179118282017834\n",
      "70 Train Loss 0.8867166 Test MSE 6.110639732215894 Test RE 1.1815480834414644\n",
      "71 Train Loss 0.8807218 Test MSE 6.120304791193806 Test RE 1.1824821280257782\n",
      "72 Train Loss 0.87544876 Test MSE 6.11750040493203 Test RE 1.1822111842814083\n",
      "73 Train Loss 0.8699442 Test MSE 6.115285828229777 Test RE 1.1819971806722793\n",
      "74 Train Loss 0.8657158 Test MSE 6.11374456744568 Test RE 1.181848219466383\n",
      "75 Train Loss 0.86168754 Test MSE 6.1164145284280895 Test RE 1.1821062564322378\n",
      "76 Train Loss 0.85666335 Test MSE 6.12206621379328 Test RE 1.1826522748546842\n",
      "77 Train Loss 0.85280055 Test MSE 6.148261802677333 Test RE 1.1851797878050865\n",
      "78 Train Loss 0.8464896 Test MSE 6.130069381591057 Test RE 1.1834250428210669\n",
      "79 Train Loss 0.8404339 Test MSE 6.154053690885308 Test RE 1.185737897819155\n",
      "80 Train Loss 0.8355156 Test MSE 6.142955889126555 Test RE 1.1846682758517821\n",
      "81 Train Loss 0.8321415 Test MSE 6.144469584963056 Test RE 1.1848142248879412\n",
      "82 Train Loss 0.8270122 Test MSE 6.139644093293494 Test RE 1.1843488930931485\n",
      "83 Train Loss 0.8227239 Test MSE 6.1422537430039075 Test RE 1.1846005695209805\n",
      "84 Train Loss 0.8173544 Test MSE 6.153815783456049 Test RE 1.1857149780823741\n",
      "85 Train Loss 0.81329036 Test MSE 6.149097758043485 Test RE 1.185260357221305\n",
      "86 Train Loss 0.8091862 Test MSE 6.164057884207569 Test RE 1.186701289977486\n",
      "87 Train Loss 0.8068588 Test MSE 6.1691784040959945 Test RE 1.1871940875990346\n",
      "88 Train Loss 0.8038686 Test MSE 6.181802401500588 Test RE 1.1884081452000363\n",
      "89 Train Loss 0.80073124 Test MSE 6.173197347818158 Test RE 1.187580726556385\n",
      "90 Train Loss 0.79827327 Test MSE 6.179250542265095 Test RE 1.1881628313627948\n",
      "91 Train Loss 0.79526895 Test MSE 6.184400742828508 Test RE 1.188657875407305\n",
      "92 Train Loss 0.79102916 Test MSE 6.1967835761582215 Test RE 1.1898472866785645\n",
      "93 Train Loss 0.78807265 Test MSE 6.191313707191145 Test RE 1.1893220347058406\n",
      "94 Train Loss 0.78560287 Test MSE 6.182045638154597 Test RE 1.1884315252402455\n",
      "95 Train Loss 0.78316545 Test MSE 6.20691469807832 Test RE 1.1908195301684488\n",
      "96 Train Loss 0.77933604 Test MSE 6.222504659114519 Test RE 1.1923140881118965\n",
      "97 Train Loss 0.77617586 Test MSE 6.206294898619014 Test RE 1.1907600732753736\n",
      "98 Train Loss 0.77296686 Test MSE 6.217642761035823 Test RE 1.1918481951415245\n",
      "99 Train Loss 0.7705507 Test MSE 6.219240988505205 Test RE 1.1920013659013302\n",
      "Training time: 152.53\n",
      "7\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.63528 Test MSE 7.5522006053905075 Test RE 1.3135445866929139\n",
      "1 Train Loss 34.765045 Test MSE 7.664105456581704 Test RE 1.3232405350823289\n",
      "2 Train Loss 23.882727 Test MSE 6.809435356095962 Test RE 1.2472790017696118\n",
      "3 Train Loss 17.558203 Test MSE 6.062031702888364 Test RE 1.176839297019328\n",
      "4 Train Loss 14.664335 Test MSE 5.845192318508593 Test RE 1.1555998125478433\n",
      "5 Train Loss 12.809681 Test MSE 5.913680427640885 Test RE 1.1623501772155658\n",
      "6 Train Loss 11.543114 Test MSE 5.89905659743539 Test RE 1.1609121105691744\n",
      "7 Train Loss 10.550518 Test MSE 5.783451880776042 Test RE 1.1494805405789568\n",
      "8 Train Loss 9.44301 Test MSE 5.249182186941092 Test RE 1.0951002635284715\n",
      "9 Train Loss 8.452301 Test MSE 5.091320821273871 Test RE 1.0785078050852306\n",
      "10 Train Loss 7.5151787 Test MSE 4.826801281042536 Test RE 1.0501171952614723\n",
      "11 Train Loss 6.528668 Test MSE 4.602973803283833 Test RE 1.0254802766783524\n",
      "12 Train Loss 5.5174756 Test MSE 4.285077367607901 Test RE 0.9894352851299445\n",
      "13 Train Loss 4.3900957 Test MSE 3.782076182628608 Test RE 0.9295509447272374\n",
      "14 Train Loss 3.439195 Test MSE 3.363523159621708 Test RE 0.8766076805218568\n",
      "15 Train Loss 2.8920836 Test MSE 3.137931107275473 Test RE 0.8467003952938474\n",
      "16 Train Loss 2.430291 Test MSE 2.976239619941797 Test RE 0.8245974874203646\n",
      "17 Train Loss 2.0457156 Test MSE 2.4020916060011093 Test RE 0.7408031887615868\n",
      "18 Train Loss 1.694551 Test MSE 2.0227813517930446 Test RE 0.6798021454340989\n",
      "19 Train Loss 1.2580094 Test MSE 1.7560289802870728 Test RE 0.6333939338763076\n",
      "20 Train Loss 0.9055362 Test MSE 1.47737284194205 Test RE 0.5809692093275955\n",
      "21 Train Loss 0.74334663 Test MSE 1.2654747685396281 Test RE 0.537693523585416\n",
      "22 Train Loss 0.5777443 Test MSE 1.1394968991952008 Test RE 0.5102284067837336\n",
      "23 Train Loss 0.4542536 Test MSE 1.0194031388306999 Test RE 0.4825930281525344\n",
      "24 Train Loss 0.39626938 Test MSE 0.9294851609624973 Test RE 0.4608178471405748\n",
      "25 Train Loss 0.3346443 Test MSE 0.8472754545764427 Test RE 0.4399672732001749\n",
      "26 Train Loss 0.2713238 Test MSE 0.749194730777103 Test RE 0.41371895343612775\n",
      "27 Train Loss 0.23157844 Test MSE 0.6828460399937071 Test RE 0.3949748636686795\n",
      "28 Train Loss 0.19558254 Test MSE 0.5831348266769626 Test RE 0.3649997358056753\n",
      "29 Train Loss 0.15815613 Test MSE 0.5040175020356273 Test RE 0.3393367289163269\n",
      "30 Train Loss 0.119165204 Test MSE 0.3856750061889305 Test RE 0.2968375291223513\n",
      "31 Train Loss 0.096746475 Test MSE 0.3205295677729628 Test RE 0.27060892075857945\n",
      "32 Train Loss 0.06708512 Test MSE 0.24994982155137518 Test RE 0.23896509855520698\n",
      "33 Train Loss 0.055242494 Test MSE 0.2395285759413952 Test RE 0.23393043399106103\n",
      "34 Train Loss 0.048486926 Test MSE 0.1997748912624181 Test RE 0.21363800400619143\n",
      "35 Train Loss 0.041060977 Test MSE 0.1685949090846498 Test RE 0.19625931943449942\n",
      "36 Train Loss 0.035045058 Test MSE 0.15547599547989419 Test RE 0.18846891630589524\n",
      "37 Train Loss 0.029902292 Test MSE 0.11453104602941348 Test RE 0.16175945457636454\n",
      "38 Train Loss 0.026497759 Test MSE 0.09549384502339128 Test RE 0.14770518824802925\n",
      "39 Train Loss 0.023759812 Test MSE 0.08705354728205385 Test RE 0.14102668472176055\n",
      "40 Train Loss 0.021120317 Test MSE 0.08137874348659245 Test RE 0.13635263976899478\n",
      "41 Train Loss 0.019346286 Test MSE 0.07269876631222055 Test RE 0.12887586130446477\n",
      "42 Train Loss 0.017407991 Test MSE 0.06426060289118349 Test RE 0.1211659127340974\n",
      "43 Train Loss 0.015392169 Test MSE 0.058770979757510756 Test RE 0.11587494090817899\n",
      "44 Train Loss 0.014075511 Test MSE 0.054839457120611244 Test RE 0.11193209533939882\n",
      "45 Train Loss 0.013134893 Test MSE 0.05253858564189147 Test RE 0.10955879549167458\n",
      "46 Train Loss 0.012053983 Test MSE 0.047199260658162864 Test RE 0.10384262504865002\n",
      "47 Train Loss 0.011366438 Test MSE 0.04115902691143588 Test RE 0.09697071761751719\n",
      "48 Train Loss 0.010169656 Test MSE 0.04364410278298796 Test RE 0.09985523664136044\n",
      "49 Train Loss 0.009193992 Test MSE 0.03977645519712279 Test RE 0.09532813548644206\n",
      "50 Train Loss 0.008631189 Test MSE 0.03795695898221323 Test RE 0.0931223153537249\n",
      "51 Train Loss 0.008243861 Test MSE 0.03706923995640375 Test RE 0.09202692296561422\n",
      "52 Train Loss 0.0073116594 Test MSE 0.032302535691506935 Test RE 0.08590656772964554\n",
      "53 Train Loss 0.007093498 Test MSE 0.03047690409484674 Test RE 0.08344368683185613\n",
      "54 Train Loss 0.006127627 Test MSE 0.030133675613969773 Test RE 0.08297248832827576\n",
      "55 Train Loss 0.0058728387 Test MSE 0.030783850519551292 Test RE 0.08386283332156019\n",
      "56 Train Loss 0.00546393 Test MSE 0.027622786665303597 Test RE 0.07944046999844048\n",
      "57 Train Loss 0.0050819446 Test MSE 0.028406478960242364 Test RE 0.0805595001688631\n",
      "58 Train Loss 0.0048726667 Test MSE 0.027354100079845196 Test RE 0.07905316752373603\n",
      "59 Train Loss 0.004431652 Test MSE 0.025913702130582007 Test RE 0.07694365128472536\n",
      "60 Train Loss 0.0042556343 Test MSE 0.025966209499892173 Test RE 0.0770215649731566\n",
      "61 Train Loss 0.00407703 Test MSE 0.026144971054844514 Test RE 0.07728623354198057\n",
      "62 Train Loss 0.0038736921 Test MSE 0.02438367448427783 Test RE 0.07463759488003766\n",
      "63 Train Loss 0.003725632 Test MSE 0.023915252605519847 Test RE 0.07391720666636505\n",
      "64 Train Loss 0.0036289538 Test MSE 0.023781663109522344 Test RE 0.07371046850413755\n",
      "65 Train Loss 0.003367604 Test MSE 0.023347462541964282 Test RE 0.07303447368754402\n",
      "66 Train Loss 0.003220806 Test MSE 0.02186858132797812 Test RE 0.07068355195682313\n",
      "67 Train Loss 0.0031036101 Test MSE 0.02027933262650098 Test RE 0.06806673039096224\n",
      "68 Train Loss 0.0029955688 Test MSE 0.019513084376541503 Test RE 0.06676840804849699\n",
      "69 Train Loss 0.0027147147 Test MSE 0.01818927418715464 Test RE 0.06446377661327277\n",
      "70 Train Loss 0.0026649197 Test MSE 0.01838308481806028 Test RE 0.0648063043107562\n",
      "71 Train Loss 0.0026135768 Test MSE 0.01747301885054862 Test RE 0.06318180560789409\n",
      "72 Train Loss 0.0023040443 Test MSE 0.01590923529622179 Test RE 0.06028825487568409\n",
      "73 Train Loss 0.0020826336 Test MSE 0.014047838721970457 Test RE 0.05665168303122735\n",
      "74 Train Loss 0.0020481632 Test MSE 0.01313691892297724 Test RE 0.0547841364147881\n",
      "75 Train Loss 0.0019940706 Test MSE 0.011808162045057604 Test RE 0.051939673166944374\n",
      "76 Train Loss 0.0018616336 Test MSE 0.009668175593872426 Test RE 0.046998102600094016\n",
      "77 Train Loss 0.0018105753 Test MSE 0.00880907919472683 Test RE 0.04486145111939232\n",
      "78 Train Loss 0.0017443222 Test MSE 0.008448727968000613 Test RE 0.0439343012660565\n",
      "79 Train Loss 0.0017004649 Test MSE 0.008404634515523337 Test RE 0.04381950592618239\n",
      "80 Train Loss 0.0015915432 Test MSE 0.00843947663008977 Test RE 0.0439102406977001\n",
      "81 Train Loss 0.0014024411 Test MSE 0.00829128614845953 Test RE 0.04352301893259463\n",
      "82 Train Loss 0.001324839 Test MSE 0.008115295821642828 Test RE 0.04305863300508604\n",
      "83 Train Loss 0.0012988708 Test MSE 0.008170631104153983 Test RE 0.04320518427288466\n",
      "84 Train Loss 0.0012661425 Test MSE 0.007501673680029097 Test RE 0.04139874203116392\n",
      "85 Train Loss 0.0011878533 Test MSE 0.006787846152821377 Test RE 0.03937984981335533\n",
      "86 Train Loss 0.0011403515 Test MSE 0.006417399294423045 Test RE 0.03829019617239182\n",
      "87 Train Loss 0.0011070758 Test MSE 0.005997221931479308 Test RE 0.03701545741771014\n",
      "88 Train Loss 0.0010905239 Test MSE 0.005908571231802495 Test RE 0.03674085834061428\n",
      "89 Train Loss 0.0010754473 Test MSE 0.005895606674433651 Test RE 0.03670052790168486\n",
      "90 Train Loss 0.0010214802 Test MSE 0.00560632124801319 Test RE 0.03578879286263926\n",
      "91 Train Loss 0.0009330447 Test MSE 0.005415558891809966 Test RE 0.03517464327849108\n",
      "92 Train Loss 0.00089790765 Test MSE 0.005441856158197821 Test RE 0.03525994165526252\n",
      "93 Train Loss 0.00088208437 Test MSE 0.005411905491223415 Test RE 0.035162776659978974\n",
      "94 Train Loss 0.00085256546 Test MSE 0.005372634515568416 Test RE 0.03503496671130266\n",
      "95 Train Loss 0.00082699733 Test MSE 0.0051423582194700945 Test RE 0.03427592813212034\n",
      "96 Train Loss 0.00078424683 Test MSE 0.004956976024891991 Test RE 0.03365243309304605\n",
      "97 Train Loss 0.0007605358 Test MSE 0.0049086836013471375 Test RE 0.0334881055733425\n",
      "98 Train Loss 0.0007304878 Test MSE 0.004873414260455723 Test RE 0.033367581136682756\n",
      "99 Train Loss 0.0007139561 Test MSE 0.004737143758396758 Test RE 0.03289776110346637\n",
      "Training time: 152.58\n",
      "8\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 74.90875 Test MSE 4.881997921276308 Test RE 1.0561044081541142\n",
      "1 Train Loss 50.292107 Test MSE 5.884820127568611 Test RE 1.1595104225552844\n",
      "2 Train Loss 27.65162 Test MSE 7.429594405381598 Test RE 1.302838587523416\n",
      "3 Train Loss 18.252815 Test MSE 6.549261600038773 Test RE 1.223219031024245\n",
      "4 Train Loss 13.563832 Test MSE 6.039541311955954 Test RE 1.1746542069578754\n",
      "5 Train Loss 11.971063 Test MSE 6.062366851983778 Test RE 1.1768718282888624\n",
      "6 Train Loss 10.827379 Test MSE 5.9215053304716045 Test RE 1.1631189261025607\n",
      "7 Train Loss 9.837247 Test MSE 5.855451525440323 Test RE 1.1566134951994163\n",
      "8 Train Loss 7.973464 Test MSE 5.362056946441952 Test RE 1.106811776194181\n",
      "9 Train Loss 6.7488346 Test MSE 5.30916392295211 Test RE 1.1013392766412846\n",
      "10 Train Loss 5.313022 Test MSE 5.103831299307871 Test RE 1.079832055732205\n",
      "11 Train Loss 4.4825697 Test MSE 4.790036356588584 Test RE 1.0461102686166495\n",
      "12 Train Loss 3.491744 Test MSE 4.5394067636027025 Test RE 1.018374721342178\n",
      "13 Train Loss 3.093085 Test MSE 4.262308749911796 Test RE 0.9868031180625929\n",
      "14 Train Loss 2.614089 Test MSE 3.8971316352112404 Test RE 0.9435840649089859\n",
      "15 Train Loss 2.2724586 Test MSE 3.7098121637549744 Test RE 0.9206276635950504\n",
      "16 Train Loss 2.0336647 Test MSE 3.800806627304264 Test RE 0.9318498671146968\n",
      "17 Train Loss 1.867065 Test MSE 3.547183949629926 Test RE 0.9002226081986145\n",
      "18 Train Loss 1.7604918 Test MSE 3.512249152998771 Test RE 0.8957786732012445\n",
      "19 Train Loss 1.635848 Test MSE 3.27797519764607 Test RE 0.8653880461829809\n",
      "20 Train Loss 1.5096047 Test MSE 3.1292577942667306 Test RE 0.8455294360114757\n",
      "21 Train Loss 1.3872532 Test MSE 3.0210128350819825 Test RE 0.8307767721155978\n",
      "22 Train Loss 1.292462 Test MSE 2.9170075740510097 Test RE 0.8163508300467484\n",
      "23 Train Loss 1.222295 Test MSE 2.8705052816514773 Test RE 0.8098176452079869\n",
      "24 Train Loss 1.1498563 Test MSE 2.5833588587527765 Test RE 0.768246215890651\n",
      "25 Train Loss 1.0764557 Test MSE 2.392917258623986 Test RE 0.7393871545887981\n",
      "26 Train Loss 1.0232611 Test MSE 2.364705669222585 Test RE 0.7350156844461803\n",
      "27 Train Loss 0.9811394 Test MSE 2.3190830190433758 Test RE 0.7278907630737915\n",
      "28 Train Loss 0.92481834 Test MSE 2.2582058063987933 Test RE 0.7182734607946091\n",
      "29 Train Loss 0.8978443 Test MSE 2.2563202007158867 Test RE 0.717973518388712\n",
      "30 Train Loss 0.8759806 Test MSE 2.1750218774236525 Test RE 0.7049200690750208\n",
      "31 Train Loss 0.85470873 Test MSE 2.0944813386165317 Test RE 0.6917454447096727\n",
      "32 Train Loss 0.8344984 Test MSE 2.052756483175429 Test RE 0.6848205379841895\n",
      "33 Train Loss 0.8197243 Test MSE 2.0009971375365296 Test RE 0.6761316936697339\n",
      "34 Train Loss 0.8030396 Test MSE 1.9614387078253424 Test RE 0.6694149868012382\n",
      "35 Train Loss 0.79375434 Test MSE 1.8763533767712235 Test RE 0.6547347276481499\n",
      "36 Train Loss 0.7824111 Test MSE 1.7951402139207564 Test RE 0.6404087368913361\n",
      "37 Train Loss 0.7550524 Test MSE 1.501973682367094 Test RE 0.5857863152776362\n",
      "38 Train Loss 0.71931833 Test MSE 1.2372055001619753 Test RE 0.531653872173687\n",
      "39 Train Loss 0.6648937 Test MSE 1.0353761637108576 Test RE 0.48635920682694267\n",
      "40 Train Loss 0.5770264 Test MSE 0.7670019792810775 Test RE 0.4186068228595763\n",
      "41 Train Loss 0.48681775 Test MSE 0.646777301650191 Test RE 0.3844018289610942\n",
      "42 Train Loss 0.4168622 Test MSE 0.5157751480505599 Test RE 0.3432719099926676\n",
      "43 Train Loss 0.34182867 Test MSE 0.39209801564211616 Test RE 0.2992990804075552\n",
      "44 Train Loss 0.28157863 Test MSE 0.3333118030656207 Test RE 0.2759519115078663\n",
      "45 Train Loss 0.21846461 Test MSE 0.23856391214423844 Test RE 0.23345889967551794\n",
      "46 Train Loss 0.19216543 Test MSE 0.20218235940994517 Test RE 0.2149214146187603\n",
      "47 Train Loss 0.14662568 Test MSE 0.1220910052528709 Test RE 0.16701285305099595\n",
      "48 Train Loss 0.11992845 Test MSE 0.08053832627911804 Test RE 0.1356467398321041\n",
      "49 Train Loss 0.089766204 Test MSE 0.06127045189355299 Test RE 0.1183133092916909\n",
      "50 Train Loss 0.07629479 Test MSE 0.055208928779662075 Test RE 0.11230852424627481\n",
      "51 Train Loss 0.06436902 Test MSE 0.05210064805536215 Test RE 0.10910122399980819\n",
      "52 Train Loss 0.05412771 Test MSE 0.04685614160323525 Test RE 0.10346449016006541\n",
      "53 Train Loss 0.04377832 Test MSE 0.03997241825462058 Test RE 0.09556266922082109\n",
      "54 Train Loss 0.03913551 Test MSE 0.03392838178007588 Test RE 0.08804194604717563\n",
      "55 Train Loss 0.03244908 Test MSE 0.04000727415058749 Test RE 0.09560432540248985\n",
      "56 Train Loss 0.029015841 Test MSE 0.03381796435615839 Test RE 0.08789856627731885\n",
      "57 Train Loss 0.025796497 Test MSE 0.028220501402315037 Test RE 0.0802953551125285\n",
      "58 Train Loss 0.023865871 Test MSE 0.02562107731471046 Test RE 0.07650798319106956\n",
      "59 Train Loss 0.022184463 Test MSE 0.023320446506288246 Test RE 0.07299220628788068\n",
      "60 Train Loss 0.019419333 Test MSE 0.02051916655710502 Test RE 0.06846804361411885\n",
      "61 Train Loss 0.018347766 Test MSE 0.016435060797907276 Test RE 0.0612764670602391\n",
      "62 Train Loss 0.017057143 Test MSE 0.016264746258009218 Test RE 0.06095813992145181\n",
      "63 Train Loss 0.015205773 Test MSE 0.015686350144072516 Test RE 0.059864452195649565\n",
      "64 Train Loss 0.013957624 Test MSE 0.014227383335519057 Test RE 0.05701256453168134\n",
      "65 Train Loss 0.01263787 Test MSE 0.014112589876520214 Test RE 0.05678209613642488\n",
      "66 Train Loss 0.011951555 Test MSE 0.014007237318110556 Test RE 0.05656975575784782\n",
      "67 Train Loss 0.010177673 Test MSE 0.010497240923253458 Test RE 0.04897175213645442\n",
      "68 Train Loss 0.0098257195 Test MSE 0.009998914281894429 Test RE 0.04779522197416431\n",
      "69 Train Loss 0.009284655 Test MSE 0.009044433019690285 Test RE 0.045456786817961614\n",
      "70 Train Loss 0.008570839 Test MSE 0.008861254147778622 Test RE 0.04499410905405138\n",
      "71 Train Loss 0.008017942 Test MSE 0.008293207509761922 Test RE 0.04352806149166414\n",
      "72 Train Loss 0.006463666 Test MSE 0.006343736902282019 Test RE 0.0380698040751622\n",
      "73 Train Loss 0.0062545715 Test MSE 0.00593492910496226 Test RE 0.03682271681694947\n",
      "74 Train Loss 0.005717214 Test MSE 0.0045552708560266 Test RE 0.032260059411954756\n",
      "75 Train Loss 0.005518379 Test MSE 0.004696833085711075 Test RE 0.032757490490060645\n",
      "76 Train Loss 0.004809965 Test MSE 0.0036437396450444783 Test RE 0.0288523857004964\n",
      "77 Train Loss 0.0045577325 Test MSE 0.003582694159157026 Test RE 0.028609675249683157\n",
      "78 Train Loss 0.00427825 Test MSE 0.0033444546535879235 Test RE 0.027642079787813665\n",
      "79 Train Loss 0.0036886472 Test MSE 0.0026489152310146184 Test RE 0.024600395569256393\n",
      "80 Train Loss 0.0035896236 Test MSE 0.002566200153508143 Test RE 0.02421326324022289\n",
      "81 Train Loss 0.0034948112 Test MSE 0.002432787072032152 Test RE 0.023575456447230338\n",
      "82 Train Loss 0.003303799 Test MSE 0.002256304992370079 Test RE 0.022704239660495038\n",
      "83 Train Loss 0.003014989 Test MSE 0.0020031986981910947 Test RE 0.02139292038550495\n",
      "84 Train Loss 0.0028806082 Test MSE 0.0021694582116771727 Test RE 0.02226300094999586\n",
      "85 Train Loss 0.0028429576 Test MSE 0.002153302647641495 Test RE 0.022179951771565683\n",
      "86 Train Loss 0.002577057 Test MSE 0.0019163533943193929 Test RE 0.02092405536118817\n",
      "87 Train Loss 0.002426188 Test MSE 0.0016891246769466766 Test RE 0.019644406557232034\n",
      "88 Train Loss 0.0024001473 Test MSE 0.0016270307960085826 Test RE 0.019279951935993894\n",
      "89 Train Loss 0.0021568954 Test MSE 0.0014650990164941423 Test RE 0.018295384817487752\n",
      "90 Train Loss 0.0020206883 Test MSE 0.0013560553098121376 Test RE 0.01760138174099907\n",
      "91 Train Loss 0.0020049699 Test MSE 0.0013950657975775461 Test RE 0.017852761615266322\n",
      "92 Train Loss 0.001977132 Test MSE 0.0013847574862561516 Test RE 0.017786681203423412\n",
      "93 Train Loss 0.0018753241 Test MSE 0.0014685521023980192 Test RE 0.018316932287648684\n",
      "94 Train Loss 0.0017107298 Test MSE 0.0013748322656688908 Test RE 0.017722823738917023\n",
      "95 Train Loss 0.0016811915 Test MSE 0.0013621440104011559 Test RE 0.017640852665916033\n",
      "96 Train Loss 0.0016573934 Test MSE 0.0013846731739448055 Test RE 0.01778613971545685\n",
      "97 Train Loss 0.0016289201 Test MSE 0.0014043384631371818 Test RE 0.017911994849249994\n",
      "98 Train Loss 0.0015759472 Test MSE 0.001272653965550762 Test RE 0.017051525067238244\n",
      "99 Train Loss 0.0015044028 Test MSE 0.0011630741212827033 Test RE 0.016300906509166223\n",
      "Training time: 151.82\n",
      "9\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.361015 Test MSE 5.848343607650766 Test RE 1.1559112769319502\n",
      "1 Train Loss 44.888382 Test MSE 8.492156048720428 Test RE 1.392890714645204\n",
      "2 Train Loss 35.70211 Test MSE 8.45553366629049 Test RE 1.3898840523090505\n",
      "3 Train Loss 30.025202 Test MSE 8.455408843456452 Test RE 1.3898737933524\n",
      "4 Train Loss 27.141506 Test MSE 8.79424020704539 Test RE 1.4174482830003226\n",
      "5 Train Loss 25.338474 Test MSE 8.869577931212959 Test RE 1.4235067710328921\n",
      "6 Train Loss 23.364536 Test MSE 9.143211189275402 Test RE 1.4452981137173935\n",
      "7 Train Loss 21.303354 Test MSE 9.158332059030032 Test RE 1.4464927233597045\n",
      "8 Train Loss 19.981632 Test MSE 9.218657141574091 Test RE 1.4512488607569927\n",
      "9 Train Loss 18.631775 Test MSE 9.037454277877664 Test RE 1.4369151271465321\n",
      "10 Train Loss 16.85572 Test MSE 8.936398210664615 Test RE 1.4288588094355026\n",
      "11 Train Loss 14.833391 Test MSE 8.58216173510604 Test RE 1.4002526642307505\n",
      "12 Train Loss 11.98944 Test MSE 7.330393944349163 Test RE 1.294111562970192\n",
      "13 Train Loss 10.1086445 Test MSE 7.170517154598532 Test RE 1.2799213982781934\n",
      "14 Train Loss 9.037336 Test MSE 6.856429061627106 Test RE 1.2515755020233066\n",
      "15 Train Loss 8.354849 Test MSE 6.569249677175168 Test RE 1.2250842160869582\n",
      "16 Train Loss 7.749793 Test MSE 6.708680268957708 Test RE 1.2380169973728004\n",
      "17 Train Loss 7.408912 Test MSE 6.766559029928476 Test RE 1.243345989103056\n",
      "18 Train Loss 7.045809 Test MSE 6.665865011486894 Test RE 1.2340601193186451\n",
      "19 Train Loss 6.7510138 Test MSE 6.645591030018155 Test RE 1.2321820161197288\n",
      "20 Train Loss 6.523695 Test MSE 6.557553314545612 Test RE 1.223993116361769\n",
      "21 Train Loss 6.3195577 Test MSE 6.537831740021472 Test RE 1.2221511757046164\n",
      "22 Train Loss 6.075922 Test MSE 6.506457033327357 Test RE 1.2192151297507015\n",
      "23 Train Loss 5.8009243 Test MSE 6.654279756219051 Test RE 1.2329872563915087\n",
      "24 Train Loss 5.4818964 Test MSE 6.595434212888111 Test RE 1.2275233347949397\n",
      "25 Train Loss 5.016741 Test MSE 6.470182647734017 Test RE 1.2158117341831318\n",
      "26 Train Loss 4.6427984 Test MSE 6.343939330128101 Test RE 1.2038921171020063\n",
      "27 Train Loss 4.3493147 Test MSE 6.280418463898075 Test RE 1.197849762601269\n",
      "28 Train Loss 3.923013 Test MSE 5.762223930007868 Test RE 1.1473690378926438\n",
      "29 Train Loss 3.0516014 Test MSE 4.986011700843529 Test RE 1.067295570337849\n",
      "30 Train Loss 2.4802523 Test MSE 5.077384096574813 Test RE 1.0770306671106642\n",
      "31 Train Loss 2.1256816 Test MSE 5.2857001274362885 Test RE 1.0989029029585446\n",
      "32 Train Loss 1.8075217 Test MSE 5.431241107598345 Test RE 1.1139292337747244\n",
      "33 Train Loss 1.6340305 Test MSE 5.484184595876547 Test RE 1.119345332259338\n",
      "34 Train Loss 1.5109992 Test MSE 5.63989391459421 Test RE 1.135124579515948\n",
      "35 Train Loss 1.4329084 Test MSE 5.65924322480363 Test RE 1.1370701011705113\n",
      "36 Train Loss 1.374192 Test MSE 5.629778577481742 Test RE 1.1341061808550104\n",
      "37 Train Loss 1.3281858 Test MSE 5.7079782190126584 Test RE 1.1419555876851213\n",
      "38 Train Loss 1.298103 Test MSE 5.698263494071275 Test RE 1.1409833950534403\n",
      "39 Train Loss 1.2655776 Test MSE 5.689284129702164 Test RE 1.14008405572018\n",
      "40 Train Loss 1.2407247 Test MSE 5.722084387408453 Test RE 1.1433657785745284\n",
      "41 Train Loss 1.2168773 Test MSE 5.7043769229512815 Test RE 1.141595287691129\n",
      "42 Train Loss 1.1930187 Test MSE 5.689996364598304 Test RE 1.140155416388633\n",
      "43 Train Loss 1.1628914 Test MSE 5.650851424030643 Test RE 1.1362267370174313\n",
      "44 Train Loss 1.1362652 Test MSE 5.655342602680084 Test RE 1.1366781719732635\n",
      "45 Train Loss 1.11506 Test MSE 5.674353875528072 Test RE 1.1385871251344026\n",
      "46 Train Loss 1.0932242 Test MSE 5.6992143820484475 Test RE 1.1410785909087418\n",
      "47 Train Loss 1.0683649 Test MSE 5.784395280132513 Test RE 1.1495742886558384\n",
      "48 Train Loss 1.0438817 Test MSE 5.806764217180152 Test RE 1.1517949133804783\n",
      "49 Train Loss 1.0235529 Test MSE 5.859055838241966 Test RE 1.1569694161290567\n",
      "50 Train Loss 1.0092162 Test MSE 5.851223093781651 Test RE 1.1561958037243771\n",
      "51 Train Loss 0.99462605 Test MSE 5.849248869685245 Test RE 1.1560007349199326\n",
      "52 Train Loss 0.9812678 Test MSE 5.887817129201253 Test RE 1.1598056407799453\n",
      "53 Train Loss 0.9703142 Test MSE 5.910608599484444 Test RE 1.1620482498591231\n",
      "54 Train Loss 0.9612407 Test MSE 5.899424544950193 Test RE 1.1609483153468632\n",
      "55 Train Loss 0.95299923 Test MSE 5.899568115390682 Test RE 1.1609624418812123\n",
      "56 Train Loss 0.94221056 Test MSE 5.91389368443837 Test RE 1.1623711351321029\n",
      "57 Train Loss 0.9308505 Test MSE 5.950029221135957 Test RE 1.1659169325345329\n",
      "58 Train Loss 0.9213259 Test MSE 5.982042279830925 Test RE 1.1690492278468931\n",
      "59 Train Loss 0.91312516 Test MSE 5.9870237996910305 Test RE 1.169535886898683\n",
      "60 Train Loss 0.90683 Test MSE 5.964606291332985 Test RE 1.167344257980382\n",
      "61 Train Loss 0.8993807 Test MSE 5.976852584165534 Test RE 1.1685420159408408\n",
      "62 Train Loss 0.89098847 Test MSE 5.986662890178832 Test RE 1.1695006354113033\n",
      "63 Train Loss 0.8841866 Test MSE 5.9856292357659475 Test RE 1.169399668336689\n",
      "64 Train Loss 0.8747855 Test MSE 5.999560602665582 Test RE 1.1707597481888656\n",
      "65 Train Loss 0.8692389 Test MSE 5.994175770469778 Test RE 1.1702342297021575\n",
      "66 Train Loss 0.8629634 Test MSE 6.011885153424728 Test RE 1.1719616433183098\n",
      "67 Train Loss 0.85722566 Test MSE 6.0230242002724586 Test RE 1.1730468681627308\n",
      "68 Train Loss 0.8527264 Test MSE 6.043855798768637 Test RE 1.1750737028293756\n",
      "69 Train Loss 0.84790355 Test MSE 6.038497217753215 Test RE 1.1745526675697837\n",
      "70 Train Loss 0.8438736 Test MSE 6.046028003440011 Test RE 1.175284848773784\n",
      "71 Train Loss 0.8391483 Test MSE 6.057976240590811 Test RE 1.1764455819981046\n",
      "72 Train Loss 0.8356929 Test MSE 6.066999481101656 Test RE 1.177321402661053\n",
      "73 Train Loss 0.83174205 Test MSE 6.07141243753655 Test RE 1.1777494992565682\n",
      "74 Train Loss 0.827483 Test MSE 6.097615169917647 Test RE 1.1802882026130461\n",
      "75 Train Loss 0.8234831 Test MSE 6.121437338819062 Test RE 1.1825915306962895\n",
      "76 Train Loss 0.8202106 Test MSE 6.124630952910788 Test RE 1.1828999752907445\n",
      "77 Train Loss 0.81622887 Test MSE 6.142103291551749 Test RE 1.1845860613310906\n",
      "78 Train Loss 0.81238174 Test MSE 6.140757107480204 Test RE 1.1844562394933364\n",
      "79 Train Loss 0.8087162 Test MSE 6.158301618328375 Test RE 1.186147063866891\n",
      "80 Train Loss 0.8050149 Test MSE 6.1567339967762615 Test RE 1.185996084898742\n",
      "81 Train Loss 0.80102867 Test MSE 6.17401872787022 Test RE 1.1876597312130244\n",
      "82 Train Loss 0.7973851 Test MSE 6.175039505345549 Test RE 1.1877579076398654\n",
      "83 Train Loss 0.79343075 Test MSE 6.174966270128801 Test RE 1.187750864286892\n",
      "84 Train Loss 0.7914259 Test MSE 6.187890744477663 Test RE 1.1889932217909527\n",
      "85 Train Loss 0.78768504 Test MSE 6.188879498081185 Test RE 1.1890882117012644\n",
      "86 Train Loss 0.7848177 Test MSE 6.20586524117607 Test RE 1.1907188548196228\n",
      "87 Train Loss 0.7821442 Test MSE 6.211645902256403 Test RE 1.1912732932207966\n",
      "88 Train Loss 0.77910817 Test MSE 6.205542215776146 Test RE 1.1906878649878556\n",
      "89 Train Loss 0.7764731 Test MSE 6.2183324030014155 Test RE 1.1919142913915688\n",
      "90 Train Loss 0.772765 Test MSE 6.241407755371001 Test RE 1.1941237562450822\n",
      "91 Train Loss 0.77011895 Test MSE 6.248651825019087 Test RE 1.1948165332164784\n",
      "92 Train Loss 0.76706237 Test MSE 6.252255739284655 Test RE 1.1951610391814338\n",
      "93 Train Loss 0.7636838 Test MSE 6.257880571969083 Test RE 1.1956985307561832\n",
      "94 Train Loss 0.76149404 Test MSE 6.251003164735727 Test RE 1.1950413141295477\n",
      "95 Train Loss 0.7589618 Test MSE 6.240123336152927 Test RE 1.1940008805672386\n",
      "96 Train Loss 0.7568542 Test MSE 6.229050058988459 Test RE 1.1929410158285005\n",
      "97 Train Loss 0.754091 Test MSE 6.253561580475415 Test RE 1.1952858428600575\n",
      "98 Train Loss 0.7515817 Test MSE 6.260779619200653 Test RE 1.1959754603896235\n",
      "99 Train Loss 0.74886614 Test MSE 6.275797197659654 Test RE 1.1974089797638447\n",
      "Training time: 151.80\n",
      "0\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.46456 Test MSE 4.513691350141056 Test RE 1.0154861147477527\n",
      "1 Train Loss 60.516644 Test MSE 4.524938693901142 Test RE 1.0167505360677136\n",
      "2 Train Loss 39.935783 Test MSE 6.578463045301054 Test RE 1.2259430049623727\n",
      "3 Train Loss 25.306894 Test MSE 5.800460150774989 Test RE 1.1511695252015328\n",
      "4 Train Loss 18.024035 Test MSE 5.243837339628231 Test RE 1.0945425924279708\n",
      "5 Train Loss 14.932045 Test MSE 5.150329976971076 Test RE 1.0847398314714338\n",
      "6 Train Loss 12.249073 Test MSE 4.977791559351524 Test RE 1.0664154139999165\n",
      "7 Train Loss 10.595577 Test MSE 5.125225642576713 Test RE 1.0820929198517037\n",
      "8 Train Loss 9.143982 Test MSE 4.897099300173594 Test RE 1.0577365594503263\n",
      "9 Train Loss 7.935139 Test MSE 4.90102010463131 Test RE 1.058159906844172\n",
      "10 Train Loss 7.09132 Test MSE 4.8710958722442115 Test RE 1.0549245492868398\n",
      "11 Train Loss 6.446729 Test MSE 4.783864768042939 Test RE 1.0454361356271786\n",
      "12 Train Loss 6.0830736 Test MSE 4.736599854361775 Test RE 1.0402588252944698\n",
      "13 Train Loss 5.623993 Test MSE 4.731708583556539 Test RE 1.0397215726193352\n",
      "14 Train Loss 5.203002 Test MSE 4.728126912187857 Test RE 1.039327989001568\n",
      "15 Train Loss 4.9050627 Test MSE 4.684867346129632 Test RE 1.0345624451432114\n",
      "16 Train Loss 4.48069 Test MSE 4.68985918928568 Test RE 1.0351134744595232\n",
      "17 Train Loss 4.013319 Test MSE 4.576850966963636 Test RE 1.0225662291176751\n",
      "18 Train Loss 3.5969625 Test MSE 4.357735178732545 Test RE 0.9977884617176327\n",
      "19 Train Loss 3.079786 Test MSE 4.228389109375271 Test RE 0.9828687636740393\n",
      "20 Train Loss 2.8463724 Test MSE 4.1471644707550075 Test RE 0.9733828494041382\n",
      "21 Train Loss 2.6279898 Test MSE 4.016994351030475 Test RE 0.9579849156735442\n",
      "22 Train Loss 2.4522998 Test MSE 3.904579859228319 Test RE 0.9444853265745774\n",
      "23 Train Loss 2.3258555 Test MSE 3.757759972237062 Test RE 0.9265579319888989\n",
      "24 Train Loss 2.2326884 Test MSE 3.619985358392309 Test RE 0.9094136473322897\n",
      "25 Train Loss 2.0478003 Test MSE 3.3808466967072857 Test RE 0.878862227563586\n",
      "26 Train Loss 1.8846376 Test MSE 3.2874478240225917 Test RE 0.8666375345773654\n",
      "27 Train Loss 1.7468197 Test MSE 3.087527386896583 Test RE 0.8398727092358543\n",
      "28 Train Loss 1.6809157 Test MSE 3.0107509346343133 Test RE 0.8293645635068649\n",
      "29 Train Loss 1.5588477 Test MSE 2.921967180669833 Test RE 0.8170445305886438\n",
      "30 Train Loss 1.5043817 Test MSE 2.9627303177309225 Test RE 0.8227239140842567\n",
      "31 Train Loss 1.4311962 Test MSE 2.953244133149375 Test RE 0.8214057434631429\n",
      "32 Train Loss 1.3520697 Test MSE 2.8973171603582055 Test RE 0.8135908948570068\n",
      "33 Train Loss 1.3022045 Test MSE 2.9325666496936074 Test RE 0.8185251082427768\n",
      "34 Train Loss 1.2583559 Test MSE 2.8740385235673354 Test RE 0.8103158853150172\n",
      "35 Train Loss 1.2189124 Test MSE 2.852655052444977 Test RE 0.8072957941622876\n",
      "36 Train Loss 1.1818439 Test MSE 2.8156495778068917 Test RE 0.8020424631811865\n",
      "37 Train Loss 1.1490871 Test MSE 2.8238489393160755 Test RE 0.8032094151166493\n",
      "38 Train Loss 1.1241367 Test MSE 2.811809619963714 Test RE 0.8014953673987267\n",
      "39 Train Loss 1.0887957 Test MSE 2.762416458684657 Test RE 0.7944245135845417\n",
      "40 Train Loss 1.0669109 Test MSE 2.750908964082828 Test RE 0.7927681057914848\n",
      "41 Train Loss 1.0434076 Test MSE 2.7613266232580083 Test RE 0.7942677889555617\n",
      "42 Train Loss 1.0195155 Test MSE 2.7794198687026026 Test RE 0.7968657101674046\n",
      "43 Train Loss 0.99827254 Test MSE 2.783309000885839 Test RE 0.7974230265977549\n",
      "44 Train Loss 0.9799975 Test MSE 2.811674824090232 Test RE 0.8014761556494281\n",
      "45 Train Loss 0.962701 Test MSE 2.8025518419988567 Test RE 0.8001748327959805\n",
      "46 Train Loss 0.93254745 Test MSE 2.864684962592082 Test RE 0.808996223839181\n",
      "47 Train Loss 0.9179189 Test MSE 2.8546464142352996 Test RE 0.8075775207481508\n",
      "48 Train Loss 0.8833559 Test MSE 2.9004640012121206 Test RE 0.8140326045695049\n",
      "49 Train Loss 0.8605995 Test MSE 2.888216414512178 Test RE 0.8123121070880965\n",
      "50 Train Loss 0.82758856 Test MSE 2.9092428658699276 Test RE 0.8152635943000911\n",
      "51 Train Loss 0.80052376 Test MSE 2.9426753865597806 Test RE 0.8199346476876371\n",
      "52 Train Loss 0.7630377 Test MSE 2.978746222598332 Test RE 0.8249446542320759\n",
      "53 Train Loss 0.74142194 Test MSE 2.97669730191045 Test RE 0.824660887707565\n",
      "54 Train Loss 0.723758 Test MSE 2.9822328688133375 Test RE 0.825427315182939\n",
      "55 Train Loss 0.6997543 Test MSE 2.9869252790837364 Test RE 0.8260764464522014\n",
      "56 Train Loss 0.68576795 Test MSE 3.038057955187614 Test RE 0.8331171745682125\n",
      "57 Train Loss 0.65880364 Test MSE 3.0692770907729847 Test RE 0.8373867971023844\n",
      "58 Train Loss 0.6484853 Test MSE 3.053191022086931 Test RE 0.8351895439814127\n",
      "59 Train Loss 0.6220697 Test MSE 3.106389298629554 Test RE 0.8424342224131381\n",
      "60 Train Loss 0.6103479 Test MSE 3.072797216637257 Test RE 0.8378668551332343\n",
      "61 Train Loss 0.58779097 Test MSE 3.108014338266175 Test RE 0.8426545441240905\n",
      "62 Train Loss 0.5763439 Test MSE 3.103183996696746 Test RE 0.8419994808690989\n",
      "63 Train Loss 0.55892915 Test MSE 3.1139724939645217 Test RE 0.8434618542808919\n",
      "64 Train Loss 0.54980326 Test MSE 3.1250823721787575 Test RE 0.8449651455336616\n",
      "65 Train Loss 0.5358816 Test MSE 3.1555580546517796 Test RE 0.8490751833278782\n",
      "66 Train Loss 0.5246425 Test MSE 3.1940871956392547 Test RE 0.8542430304377056\n",
      "67 Train Loss 0.50953245 Test MSE 3.240809503727738 Test RE 0.8604681747467077\n",
      "68 Train Loss 0.5009368 Test MSE 3.2463468691264534 Test RE 0.8612029746682259\n",
      "69 Train Loss 0.49043533 Test MSE 3.3145587190797365 Test RE 0.8702036866466338\n",
      "70 Train Loss 0.48110154 Test MSE 3.332446876049222 Test RE 0.8725487038365771\n",
      "71 Train Loss 0.4632215 Test MSE 3.3822225700313324 Test RE 0.8790410407727068\n",
      "72 Train Loss 0.45375997 Test MSE 3.3963403210008583 Test RE 0.8808737349494915\n",
      "73 Train Loss 0.438532 Test MSE 3.4590971960839383 Test RE 0.888974785341144\n",
      "74 Train Loss 0.4267776 Test MSE 3.4279316321320206 Test RE 0.8849610085842592\n",
      "75 Train Loss 0.41363126 Test MSE 3.4399378706778605 Test RE 0.8865094300346223\n",
      "76 Train Loss 0.40441298 Test MSE 3.437257707867261 Test RE 0.8861640091756947\n",
      "77 Train Loss 0.39417878 Test MSE 3.439895045109515 Test RE 0.8865039117099062\n",
      "78 Train Loss 0.38129634 Test MSE 3.460053435261148 Test RE 0.8890976517609538\n",
      "79 Train Loss 0.37563306 Test MSE 3.4705162945737293 Test RE 0.8904409087321862\n",
      "80 Train Loss 0.37045696 Test MSE 3.445044052657067 Test RE 0.8871671453861344\n",
      "81 Train Loss 0.35996497 Test MSE 3.478976840537387 Test RE 0.8915256220366325\n",
      "82 Train Loss 0.35399234 Test MSE 3.458398877971608 Test RE 0.8888850482662788\n",
      "83 Train Loss 0.35109743 Test MSE 3.4619541876740656 Test RE 0.8893418275390926\n",
      "84 Train Loss 0.3459549 Test MSE 3.4615053665686313 Test RE 0.8892841768166456\n",
      "85 Train Loss 0.33980417 Test MSE 3.4757775054791145 Test RE 0.8911155955596531\n",
      "86 Train Loss 0.33602652 Test MSE 3.478372765026976 Test RE 0.8914482182193969\n",
      "87 Train Loss 0.32938975 Test MSE 3.4784698067732314 Test RE 0.8914606532133268\n",
      "88 Train Loss 0.3252636 Test MSE 3.485682398343335 Test RE 0.8923843944544971\n",
      "89 Train Loss 0.32032275 Test MSE 3.4669612751584244 Test RE 0.8899847308153576\n",
      "90 Train Loss 0.31530628 Test MSE 3.4836411988329106 Test RE 0.8921230681014982\n",
      "91 Train Loss 0.31258088 Test MSE 3.4761571447267072 Test RE 0.891164259954379\n",
      "92 Train Loss 0.31012142 Test MSE 3.47993543192435 Test RE 0.8916484383071134\n",
      "93 Train Loss 0.30717915 Test MSE 3.4725038356145004 Test RE 0.8906958469584414\n",
      "94 Train Loss 0.30322263 Test MSE 3.4762115808232767 Test RE 0.8911712376760088\n",
      "95 Train Loss 0.30174077 Test MSE 3.4778362944099794 Test RE 0.8913794713873296\n",
      "96 Train Loss 0.29899895 Test MSE 3.497988065873878 Test RE 0.8939582198148428\n",
      "97 Train Loss 0.2948654 Test MSE 3.509871365668027 Test RE 0.8954754014647612\n",
      "98 Train Loss 0.29304963 Test MSE 3.512132194824099 Test RE 0.8957637583267323\n",
      "99 Train Loss 0.2906958 Test MSE 3.513953163266185 Test RE 0.8959959457942557\n",
      "Training time: 151.51\n",
      "1\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.201805 Test MSE 5.424215164269484 Test RE 1.113208501971116\n",
      "1 Train Loss 47.197174 Test MSE 9.740860058369599 Test RE 1.4917866362850005\n",
      "2 Train Loss 41.667572 Test MSE 9.489333713611488 Test RE 1.4724003777662673\n",
      "3 Train Loss 36.935623 Test MSE 10.086645222259987 Test RE 1.518033770608111\n",
      "4 Train Loss 33.22319 Test MSE 9.63972975838198 Test RE 1.4840225144604349\n",
      "5 Train Loss 30.354124 Test MSE 9.738225929512517 Test RE 1.4915849177561455\n",
      "6 Train Loss 28.286812 Test MSE 9.544333533511113 Test RE 1.4766612012901215\n",
      "7 Train Loss 25.281693 Test MSE 8.926654452746812 Test RE 1.428079622387775\n",
      "8 Train Loss 22.991718 Test MSE 8.83989195831795 Test RE 1.421122576318154\n",
      "9 Train Loss 20.36158 Test MSE 8.948507723438958 Test RE 1.4298265889542943\n",
      "10 Train Loss 19.30745 Test MSE 9.11545847772337 Test RE 1.4431029645161584\n",
      "11 Train Loss 17.450708 Test MSE 8.81924421058879 Test RE 1.419461914905751\n",
      "12 Train Loss 15.959433 Test MSE 8.481530729112526 Test RE 1.3920190548912963\n",
      "13 Train Loss 13.474136 Test MSE 7.337276095463925 Test RE 1.2947189097217826\n",
      "14 Train Loss 12.250864 Test MSE 6.88126559123468 Test RE 1.2538402882874777\n",
      "15 Train Loss 11.235364 Test MSE 6.607556807769911 Test RE 1.2286509282235232\n",
      "16 Train Loss 10.3546715 Test MSE 6.431505393205992 Test RE 1.2121723666155515\n",
      "17 Train Loss 9.557504 Test MSE 6.6755068915542 Test RE 1.2349523036062888\n",
      "18 Train Loss 8.979333 Test MSE 6.694437038932953 Test RE 1.2367020792758774\n",
      "19 Train Loss 8.599409 Test MSE 6.681968627855822 Test RE 1.2355498616716345\n",
      "20 Train Loss 8.199232 Test MSE 6.438826667372185 Test RE 1.2128621057608757\n",
      "21 Train Loss 8.0021105 Test MSE 6.275672138372751 Test RE 1.1973970491792163\n",
      "22 Train Loss 7.780485 Test MSE 6.278189028987228 Test RE 1.1976371362346176\n",
      "23 Train Loss 7.6226645 Test MSE 6.278881638311923 Test RE 1.1977031960305355\n",
      "24 Train Loss 7.504301 Test MSE 6.264874554608525 Test RE 1.1963665172557088\n",
      "25 Train Loss 7.326395 Test MSE 6.277730914107019 Test RE 1.1975934400827677\n",
      "26 Train Loss 7.160355 Test MSE 6.173986085863103 Test RE 1.1876565916332507\n",
      "27 Train Loss 6.9445114 Test MSE 6.193714068097514 Test RE 1.1895525613440825\n",
      "28 Train Loss 6.772646 Test MSE 6.066205862287806 Test RE 1.1772443979592069\n",
      "29 Train Loss 6.678919 Test MSE 6.035273297544963 Test RE 1.1742390821280106\n",
      "30 Train Loss 6.4377365 Test MSE 5.790765048300458 Test RE 1.150207069316349\n",
      "31 Train Loss 6.190979 Test MSE 5.823593833967455 Test RE 1.1534628166527239\n",
      "32 Train Loss 5.927957 Test MSE 5.823435421154273 Test RE 1.1534471283563281\n",
      "33 Train Loss 5.5145044 Test MSE 5.588774494095787 Test RE 1.1299685430404391\n",
      "34 Train Loss 4.721565 Test MSE 5.020514387682305 Test RE 1.0709819915653511\n",
      "35 Train Loss 3.89786 Test MSE 4.785163424136026 Test RE 1.045578026122214\n",
      "36 Train Loss 3.5757515 Test MSE 4.885179816018683 Test RE 1.056448515807363\n",
      "37 Train Loss 3.2234564 Test MSE 4.92986416286113 Test RE 1.061269142229737\n",
      "38 Train Loss 2.9455388 Test MSE 5.062776960135516 Test RE 1.0754802954029528\n",
      "39 Train Loss 2.7809675 Test MSE 5.063931918772372 Test RE 1.0756029617215073\n",
      "40 Train Loss 2.6292315 Test MSE 5.117423511705994 Test RE 1.0812689711452483\n",
      "41 Train Loss 2.4903688 Test MSE 5.116761134974059 Test RE 1.0811989915370535\n",
      "42 Train Loss 2.3951137 Test MSE 5.199320679686377 Test RE 1.0898867240293753\n",
      "43 Train Loss 2.2558186 Test MSE 5.255850074859443 Test RE 1.0957955802602293\n",
      "44 Train Loss 2.1744485 Test MSE 5.241122333508838 Test RE 1.0942592050540956\n",
      "45 Train Loss 2.1258922 Test MSE 5.259407332426281 Test RE 1.0961663450007362\n",
      "46 Train Loss 2.0512123 Test MSE 5.26397060535837 Test RE 1.096641780858668\n",
      "47 Train Loss 1.9825729 Test MSE 5.289138126963216 Test RE 1.0992602268162799\n",
      "48 Train Loss 1.9371715 Test MSE 5.341999781594557 Test RE 1.1047397817051678\n",
      "49 Train Loss 1.8967602 Test MSE 5.364015988006925 Test RE 1.1070139460223234\n",
      "50 Train Loss 1.8456758 Test MSE 5.392744700124925 Test RE 1.1099744718464766\n",
      "51 Train Loss 1.7711654 Test MSE 5.450524036682569 Test RE 1.1159049135894303\n",
      "52 Train Loss 1.7312945 Test MSE 5.44259751254217 Test RE 1.115093205819914\n",
      "53 Train Loss 1.6835217 Test MSE 5.4346538055678355 Test RE 1.1142791452389418\n",
      "54 Train Loss 1.6532059 Test MSE 5.458668682070307 Test RE 1.116738343276081\n",
      "55 Train Loss 1.5972589 Test MSE 5.457215413785204 Test RE 1.1165896780479831\n",
      "56 Train Loss 1.5729121 Test MSE 5.45225737171699 Test RE 1.1160823353671645\n",
      "57 Train Loss 1.5462202 Test MSE 5.416281571040787 Test RE 1.112394100724848\n",
      "58 Train Loss 1.4986136 Test MSE 5.3746442012100895 Test RE 1.1081101170606245\n",
      "59 Train Loss 1.477616 Test MSE 5.3676009029088885 Test RE 1.1073838077033897\n",
      "60 Train Loss 1.4510047 Test MSE 5.387658215549896 Test RE 1.1094508794756008\n",
      "61 Train Loss 1.404089 Test MSE 5.408527683841 Test RE 1.1115975701645704\n",
      "62 Train Loss 1.3684955 Test MSE 5.410872981450011 Test RE 1.1118385548387835\n",
      "63 Train Loss 1.3397355 Test MSE 5.493434251170052 Test RE 1.1202888815128889\n",
      "64 Train Loss 1.3229562 Test MSE 5.4919637365829 Test RE 1.1201389287394499\n",
      "65 Train Loss 1.3049041 Test MSE 5.528257087329092 Test RE 1.1238340233999637\n",
      "66 Train Loss 1.2851629 Test MSE 5.5289339659643755 Test RE 1.1239028222948495\n",
      "67 Train Loss 1.2723026 Test MSE 5.530989289242397 Test RE 1.1241117024342178\n",
      "68 Train Loss 1.2633666 Test MSE 5.510859811301639 Test RE 1.1220642922907051\n",
      "69 Train Loss 1.2561643 Test MSE 5.5266013433765036 Test RE 1.1236657135051775\n",
      "70 Train Loss 1.2441789 Test MSE 5.548790402063482 Test RE 1.1259191878125834\n",
      "71 Train Loss 1.2281148 Test MSE 5.56044261873671 Test RE 1.1271007583023058\n",
      "72 Train Loss 1.2181767 Test MSE 5.543661647403816 Test RE 1.1253987231852842\n",
      "73 Train Loss 1.2088512 Test MSE 5.559757319088323 Test RE 1.1270313011019935\n",
      "74 Train Loss 1.199631 Test MSE 5.549756991565017 Test RE 1.1260172501105554\n",
      "75 Train Loss 1.189474 Test MSE 5.571482957816842 Test RE 1.1282191408486335\n",
      "76 Train Loss 1.1844623 Test MSE 5.578065776294819 Test RE 1.128885450825026\n",
      "77 Train Loss 1.1773486 Test MSE 5.580389853095483 Test RE 1.1291205989363424\n",
      "78 Train Loss 1.1711593 Test MSE 5.587922152105895 Test RE 1.1298823742066846\n",
      "79 Train Loss 1.1650966 Test MSE 5.627153688602883 Test RE 1.1338417610614653\n",
      "80 Train Loss 1.1526753 Test MSE 5.631327374995683 Test RE 1.1342621710079983\n",
      "81 Train Loss 1.1431956 Test MSE 5.657938158139562 Test RE 1.1369389848898117\n",
      "82 Train Loss 1.133318 Test MSE 5.687181406597975 Test RE 1.139873352354351\n",
      "83 Train Loss 1.124747 Test MSE 5.700144417638968 Test RE 1.1411716914957986\n",
      "84 Train Loss 1.1174934 Test MSE 5.737685164706051 Test RE 1.1449233625058741\n",
      "85 Train Loss 1.1121631 Test MSE 5.735878819893717 Test RE 1.144743125257304\n",
      "86 Train Loss 1.1028365 Test MSE 5.715771787891621 Test RE 1.1427349243711442\n",
      "87 Train Loss 1.096807 Test MSE 5.708805973730322 Test RE 1.1420383862542105\n",
      "88 Train Loss 1.0877113 Test MSE 5.714479130217386 Test RE 1.1426056987257365\n",
      "89 Train Loss 1.0818791 Test MSE 5.717402357339156 Test RE 1.1428979098657848\n",
      "90 Train Loss 1.0755012 Test MSE 5.70228383981766 Test RE 1.1413858280864553\n",
      "91 Train Loss 1.0679784 Test MSE 5.725906709448439 Test RE 1.1437475959619243\n",
      "92 Train Loss 1.0590273 Test MSE 5.7394681415417255 Test RE 1.1451012402746716\n",
      "93 Train Loss 1.0522175 Test MSE 5.749706706772122 Test RE 1.1461221510501038\n",
      "94 Train Loss 1.0488727 Test MSE 5.745439600460027 Test RE 1.14569677867568\n",
      "95 Train Loss 1.0407201 Test MSE 5.758232289433243 Test RE 1.146971563038562\n",
      "96 Train Loss 1.0300545 Test MSE 5.727083136283614 Test RE 1.1438650853245322\n",
      "97 Train Loss 1.0245856 Test MSE 5.7488306393596424 Test RE 1.1460348319424838\n",
      "98 Train Loss 1.0184238 Test MSE 5.7416170349043485 Test RE 1.1453155868057188\n",
      "99 Train Loss 1.0106546 Test MSE 5.759413267347456 Test RE 1.147089175403855\n",
      "Training time: 153.67\n",
      "2\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.24735 Test MSE 7.134116745874702 Test RE 1.2766685687742378\n",
      "1 Train Loss 40.176064 Test MSE 7.923105143945791 Test RE 1.3454134653232714\n",
      "2 Train Loss 29.965881 Test MSE 6.41977583318375 Test RE 1.211066502881546\n",
      "3 Train Loss 24.340324 Test MSE 6.198728682820532 Test RE 1.1900340124427853\n",
      "4 Train Loss 21.004616 Test MSE 6.016437410409183 Test RE 1.1724052696418952\n",
      "5 Train Loss 18.732452 Test MSE 6.2341638187363495 Test RE 1.1934305898538682\n",
      "6 Train Loss 16.360302 Test MSE 6.1004178474468205 Test RE 1.1805594223525813\n",
      "7 Train Loss 14.287698 Test MSE 5.878129308124527 Test RE 1.1588510751897703\n",
      "8 Train Loss 12.642649 Test MSE 5.8825399742619195 Test RE 1.1592857667785201\n",
      "9 Train Loss 11.511535 Test MSE 6.070947266552177 Test RE 1.1777043808106016\n",
      "10 Train Loss 10.644814 Test MSE 5.960625003010234 Test RE 1.1669546002531788\n",
      "11 Train Loss 9.873423 Test MSE 5.816288813090378 Test RE 1.1527391471939188\n",
      "12 Train Loss 9.283421 Test MSE 5.717280305899173 Test RE 1.1428857108747579\n",
      "13 Train Loss 8.701092 Test MSE 5.727379266119565 Test RE 1.1438946578131282\n",
      "14 Train Loss 7.985946 Test MSE 5.665544806901528 Test RE 1.1377029903009512\n",
      "15 Train Loss 7.5329843 Test MSE 5.64705380555445 Test RE 1.1358448759022581\n",
      "16 Train Loss 6.935516 Test MSE 5.546389792263355 Test RE 1.1256756045407021\n",
      "17 Train Loss 6.5281496 Test MSE 5.434172316813719 Test RE 1.1142297837910615\n",
      "18 Train Loss 6.0074325 Test MSE 5.356222703767692 Test RE 1.1062094731945409\n",
      "19 Train Loss 5.5350213 Test MSE 5.302072958686747 Test RE 1.100603551870052\n",
      "20 Train Loss 5.12503 Test MSE 5.237065890715923 Test RE 1.09383566418018\n",
      "21 Train Loss 4.7658186 Test MSE 5.088055616025082 Test RE 1.07816191113476\n",
      "22 Train Loss 4.409724 Test MSE 5.024570769726331 Test RE 1.0714145602853873\n",
      "23 Train Loss 4.190624 Test MSE 5.016077676195316 Test RE 1.0705086647330078\n",
      "24 Train Loss 3.8075213 Test MSE 4.914916437247998 Test RE 1.0596589961321803\n",
      "25 Train Loss 3.6207552 Test MSE 4.876143255368018 Test RE 1.0554709591598566\n",
      "26 Train Loss 3.4395056 Test MSE 4.835172997393809 Test RE 1.0510274745679247\n",
      "27 Train Loss 3.2043025 Test MSE 4.72243196925337 Test RE 1.0387018745721452\n",
      "28 Train Loss 2.989531 Test MSE 4.607248472643292 Test RE 1.0259563354225472\n",
      "29 Train Loss 2.8217356 Test MSE 4.493803016412299 Test RE 1.0132464153852156\n",
      "30 Train Loss 2.7006462 Test MSE 4.333751885919324 Test RE 0.9950389521102835\n",
      "31 Train Loss 2.5533335 Test MSE 4.271129585537094 Test RE 0.9878236834200259\n",
      "32 Train Loss 2.456359 Test MSE 4.238941078498875 Test RE 0.9840943768203059\n",
      "33 Train Loss 2.3441675 Test MSE 4.082472055348827 Test RE 0.9657610159180734\n",
      "34 Train Loss 2.1957934 Test MSE 3.8299142249196674 Test RE 0.9354112398677398\n",
      "35 Train Loss 2.076252 Test MSE 3.7462892064422557 Test RE 0.925142666990289\n",
      "36 Train Loss 1.975764 Test MSE 3.6339409998153633 Test RE 0.9111649309873003\n",
      "37 Train Loss 1.8670506 Test MSE 3.494117240101244 Test RE 0.8934634619315153\n",
      "38 Train Loss 1.7488436 Test MSE 3.4230932265578824 Test RE 0.8843362422956412\n",
      "39 Train Loss 1.7000308 Test MSE 3.3747353439081285 Test RE 0.8780675351332832\n",
      "40 Train Loss 1.6434318 Test MSE 3.33265327120918 Test RE 0.8725757240784019\n",
      "41 Train Loss 1.5772325 Test MSE 3.2900436727110303 Test RE 0.8669796260882581\n",
      "42 Train Loss 1.5278496 Test MSE 3.266400436905864 Test RE 0.8638588220421958\n",
      "43 Train Loss 1.4741994 Test MSE 3.23466764204077 Test RE 0.8596524244210388\n",
      "44 Train Loss 1.4195257 Test MSE 3.1894798990094007 Test RE 0.8536267086069027\n",
      "45 Train Loss 1.3661201 Test MSE 3.076041926639059 Test RE 0.8383091097743143\n",
      "46 Train Loss 1.3326212 Test MSE 3.024890066111088 Test RE 0.8313097193102106\n",
      "47 Train Loss 1.2834402 Test MSE 3.0483884687700304 Test RE 0.8345324247851945\n",
      "48 Train Loss 1.262825 Test MSE 3.0210320955221945 Test RE 0.8307794204163034\n",
      "49 Train Loss 1.2417986 Test MSE 3.0042466268082157 Test RE 0.8284682158555801\n",
      "50 Train Loss 1.219448 Test MSE 3.032799393709125 Test RE 0.8323958428242217\n",
      "51 Train Loss 1.1956191 Test MSE 2.9961471131851813 Test RE 0.827350678042351\n",
      "52 Train Loss 1.1696887 Test MSE 2.940190454768962 Test RE 0.8195883791186519\n",
      "53 Train Loss 1.1483688 Test MSE 2.870865140677656 Test RE 0.8098684047481619\n",
      "54 Train Loss 1.1325872 Test MSE 2.9195681194485816 Test RE 0.8167090472937841\n",
      "55 Train Loss 1.1217833 Test MSE 2.9352970452371054 Test RE 0.8189060675884362\n",
      "56 Train Loss 1.1086112 Test MSE 2.866354917192038 Test RE 0.8092319897527946\n",
      "57 Train Loss 1.0973313 Test MSE 2.830642742258179 Test RE 0.804175041897018\n",
      "58 Train Loss 1.0865521 Test MSE 2.806067774895607 Test RE 0.8006766039238696\n",
      "59 Train Loss 1.0746909 Test MSE 2.72276504892609 Test RE 0.7887023663213367\n",
      "60 Train Loss 1.0460086 Test MSE 2.4564286304552074 Test RE 0.7491350820161173\n",
      "61 Train Loss 0.9796903 Test MSE 2.2926007640271644 Test RE 0.7237228365361019\n",
      "62 Train Loss 0.9431243 Test MSE 2.218682584915851 Test RE 0.7119600871068941\n",
      "63 Train Loss 0.9112991 Test MSE 2.226121446123532 Test RE 0.7131526282227711\n",
      "64 Train Loss 0.8875553 Test MSE 2.16247103967559 Test RE 0.7028832763134244\n",
      "65 Train Loss 0.85473996 Test MSE 2.074415545113488 Test RE 0.6884239001565664\n",
      "66 Train Loss 0.8391477 Test MSE 2.0438007183616054 Test RE 0.683325037733067\n",
      "67 Train Loss 0.8130823 Test MSE 1.9912992237719715 Test RE 0.6744912538062803\n",
      "68 Train Loss 0.79135144 Test MSE 1.8732865495056406 Test RE 0.6541994394947644\n",
      "69 Train Loss 0.74488914 Test MSE 1.576093018448349 Test RE 0.6000659485489332\n",
      "70 Train Loss 0.7133877 Test MSE 1.5093687028577947 Test RE 0.5872266144232229\n",
      "71 Train Loss 0.6762237 Test MSE 1.459801163243535 Test RE 0.5775038887222177\n",
      "72 Train Loss 0.6320381 Test MSE 1.325630919549378 Test RE 0.5503251655109711\n",
      "73 Train Loss 0.59454256 Test MSE 1.136514188907158 Test RE 0.5095601905209297\n",
      "74 Train Loss 0.54570156 Test MSE 0.9511311735859121 Test RE 0.466152768969404\n",
      "75 Train Loss 0.5141249 Test MSE 0.854305722544049 Test RE 0.4417888166362592\n",
      "76 Train Loss 0.4698145 Test MSE 0.7653725961812843 Test RE 0.41816195209900614\n",
      "77 Train Loss 0.43420103 Test MSE 0.7042665287425652 Test RE 0.40112209464776727\n",
      "78 Train Loss 0.37112433 Test MSE 0.6101076051764474 Test RE 0.37334580821584157\n",
      "79 Train Loss 0.33462518 Test MSE 0.5501899305285858 Test RE 0.35453929694632574\n",
      "80 Train Loss 0.3055578 Test MSE 0.5429181796995605 Test RE 0.3521885661565457\n",
      "81 Train Loss 0.27834845 Test MSE 0.4570889654533362 Test RE 0.3231531761937527\n",
      "82 Train Loss 0.25118455 Test MSE 0.405402705507823 Test RE 0.30433463590274357\n",
      "83 Train Loss 0.21627194 Test MSE 0.3437470339779684 Test RE 0.2802383324440788\n",
      "84 Train Loss 0.19888753 Test MSE 0.3229397055474324 Test RE 0.2716244017230914\n",
      "85 Train Loss 0.17806503 Test MSE 0.28303642095208403 Test RE 0.254289965108607\n",
      "86 Train Loss 0.16364291 Test MSE 0.2748259007266281 Test RE 0.2505745103026575\n",
      "87 Train Loss 0.14638244 Test MSE 0.2516082063277708 Test RE 0.2397565392280682\n",
      "88 Train Loss 0.13281374 Test MSE 0.22156131703919307 Test RE 0.22498575901307358\n",
      "89 Train Loss 0.12033286 Test MSE 0.2192763976638013 Test RE 0.22382263497834112\n",
      "90 Train Loss 0.112620875 Test MSE 0.20736116584206904 Test RE 0.2176565661397723\n",
      "91 Train Loss 0.103531696 Test MSE 0.19842578226364435 Test RE 0.21291541769564734\n",
      "92 Train Loss 0.09520729 Test MSE 0.20132171053844272 Test RE 0.21446348856522257\n",
      "93 Train Loss 0.0857381 Test MSE 0.17672306926156092 Test RE 0.2009345798313891\n",
      "94 Train Loss 0.07975323 Test MSE 0.1652712150580131 Test RE 0.19431515362341278\n",
      "95 Train Loss 0.07518285 Test MSE 0.16537944859586115 Test RE 0.19437877018957417\n",
      "96 Train Loss 0.070130944 Test MSE 0.15680917956855878 Test RE 0.18927523826946618\n",
      "97 Train Loss 0.066919036 Test MSE 0.16120193901610558 Test RE 0.19190804931097785\n",
      "98 Train Loss 0.058895703 Test MSE 0.14468169411808823 Test RE 0.18180878017551014\n",
      "99 Train Loss 0.054292478 Test MSE 0.1362377313476468 Test RE 0.17642363331797434\n",
      "Training time: 150.01\n",
      "3\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.35808 Test MSE 5.340720108223812 Test RE 1.1046074538493704\n",
      "1 Train Loss 52.365303 Test MSE 7.271475576048914 Test RE 1.2889003307606937\n",
      "2 Train Loss 39.701866 Test MSE 8.21279725792408 Test RE 1.3697888010502268\n",
      "3 Train Loss 34.10634 Test MSE 8.290918588438448 Test RE 1.3762881976877055\n",
      "4 Train Loss 28.894844 Test MSE 8.309119306136703 Test RE 1.3777980243889423\n",
      "5 Train Loss 25.878422 Test MSE 8.697966739353575 Test RE 1.4096682933622715\n",
      "6 Train Loss 23.301561 Test MSE 8.535428776871996 Test RE 1.396435020263815\n",
      "7 Train Loss 21.768364 Test MSE 8.836826977847755 Test RE 1.4208761880940108\n",
      "8 Train Loss 20.13572 Test MSE 8.931723006116279 Test RE 1.4284849965755886\n",
      "9 Train Loss 18.609035 Test MSE 9.082720950740779 Test RE 1.440509232301127\n",
      "10 Train Loss 17.449148 Test MSE 8.972090801826699 Test RE 1.4317094462078754\n",
      "11 Train Loss 16.478657 Test MSE 9.065411906993544 Test RE 1.4391359803889596\n",
      "12 Train Loss 15.327454 Test MSE 8.878090655359792 Test RE 1.4241897242893902\n",
      "13 Train Loss 13.34805 Test MSE 8.156684699463337 Test RE 1.3651013547718112\n",
      "14 Train Loss 10.289589 Test MSE 7.281133657971912 Test RE 1.2897560150088088\n",
      "15 Train Loss 8.611574 Test MSE 7.213870587616748 Test RE 1.283784813249923\n",
      "16 Train Loss 7.27915 Test MSE 7.017216829683854 Test RE 1.266165594960594\n",
      "17 Train Loss 6.372265 Test MSE 6.842911769947301 Test RE 1.2503411672467484\n",
      "18 Train Loss 4.899249 Test MSE 6.253937458119431 Test RE 1.1953217643481422\n",
      "19 Train Loss 3.6559682 Test MSE 6.132808366536194 Test RE 1.1836893972013627\n",
      "20 Train Loss 2.9605622 Test MSE 5.959852810829708 Test RE 1.1668790089852046\n",
      "21 Train Loss 2.405487 Test MSE 5.753282319437974 Test RE 1.1464784693946466\n",
      "22 Train Loss 2.0883553 Test MSE 5.677137059375242 Test RE 1.1388663206944711\n",
      "23 Train Loss 1.8885808 Test MSE 5.608967762790804 Test RE 1.1320080943226363\n",
      "24 Train Loss 1.6717131 Test MSE 5.6921169951530235 Test RE 1.1403678614431159\n",
      "25 Train Loss 1.5693483 Test MSE 5.678334399607399 Test RE 1.1389864110287233\n",
      "26 Train Loss 1.458825 Test MSE 5.644193718639803 Test RE 1.135557201424768\n",
      "27 Train Loss 1.3789045 Test MSE 5.644534740979723 Test RE 1.135591506105295\n",
      "28 Train Loss 1.3170779 Test MSE 5.59151894054234 Test RE 1.1302459524738482\n",
      "29 Train Loss 1.2488177 Test MSE 5.710330585357996 Test RE 1.1421908742504936\n",
      "30 Train Loss 1.205495 Test MSE 5.718451872878961 Test RE 1.1430028031373103\n",
      "31 Train Loss 1.1620934 Test MSE 5.757472898798477 Test RE 1.146895929741911\n",
      "32 Train Loss 1.1304812 Test MSE 5.800123379623355 Test RE 1.1511361066188739\n",
      "33 Train Loss 1.1034204 Test MSE 5.7783866460264885 Test RE 1.148977064083365\n",
      "34 Train Loss 1.0726489 Test MSE 5.792526489640543 Test RE 1.1503819916468745\n",
      "35 Train Loss 1.0517912 Test MSE 5.801950888744884 Test RE 1.1513174429382458\n",
      "36 Train Loss 1.0285759 Test MSE 5.795822847478731 Test RE 1.1507092695079344\n",
      "37 Train Loss 1.0029895 Test MSE 5.831378263945529 Test RE 1.154233479254001\n",
      "38 Train Loss 0.9885887 Test MSE 5.846082905614153 Test RE 1.1556878441332692\n",
      "39 Train Loss 0.9713687 Test MSE 5.843508187979678 Test RE 1.155433323489638\n",
      "40 Train Loss 0.9590273 Test MSE 5.845507750834081 Test RE 1.1556309927553354\n",
      "41 Train Loss 0.9453676 Test MSE 5.8449544552957775 Test RE 1.1555762994223848\n",
      "42 Train Loss 0.93550783 Test MSE 5.863136008097735 Test RE 1.1573721952034954\n",
      "43 Train Loss 0.9262687 Test MSE 5.8873046270659986 Test RE 1.1597551623267448\n",
      "44 Train Loss 0.91843176 Test MSE 5.895148822668046 Test RE 1.1605275291932355\n",
      "45 Train Loss 0.9104102 Test MSE 5.87559019094749 Test RE 1.1586007594565497\n",
      "46 Train Loss 0.9035069 Test MSE 5.878368371229589 Test RE 1.158874640145991\n",
      "47 Train Loss 0.8933471 Test MSE 5.89887689586879 Test RE 1.1608944281389169\n",
      "48 Train Loss 0.88625 Test MSE 5.894312890741399 Test RE 1.1604452448916986\n",
      "49 Train Loss 0.878384 Test MSE 5.88522912287252 Test RE 1.1595507148724526\n",
      "50 Train Loss 0.87297034 Test MSE 5.915863617216283 Test RE 1.162564713379293\n",
      "51 Train Loss 0.86602604 Test MSE 5.932770416015424 Test RE 1.164224760495111\n",
      "52 Train Loss 0.8586226 Test MSE 5.92584187089519 Test RE 1.1635447459604773\n",
      "53 Train Loss 0.8529521 Test MSE 5.934105010316324 Test RE 1.1643557010380643\n",
      "54 Train Loss 0.8469558 Test MSE 5.9399557157255 Test RE 1.164929555382877\n",
      "55 Train Loss 0.84172463 Test MSE 5.958150972824409 Test RE 1.1667123957404986\n",
      "56 Train Loss 0.8368317 Test MSE 5.944141828058158 Test RE 1.1653399681322443\n",
      "57 Train Loss 0.83282316 Test MSE 5.980355612722053 Test RE 1.1688844065535837\n",
      "58 Train Loss 0.82627857 Test MSE 5.983397359227245 Test RE 1.169181629520563\n",
      "59 Train Loss 0.8204046 Test MSE 5.9880472371165885 Test RE 1.16963584438084\n",
      "60 Train Loss 0.81656003 Test MSE 5.987325742318721 Test RE 1.169565378036386\n",
      "61 Train Loss 0.8110311 Test MSE 6.015909297763082 Test RE 1.1723538126421083\n",
      "62 Train Loss 0.8073912 Test MSE 6.049756504536543 Test RE 1.175647183803139\n",
      "63 Train Loss 0.80228555 Test MSE 6.056597423846691 Test RE 1.176311692798794\n",
      "64 Train Loss 0.79952747 Test MSE 6.053910640313715 Test RE 1.1760507504535012\n",
      "65 Train Loss 0.7957072 Test MSE 6.045040266135948 Test RE 1.1751888419322605\n",
      "66 Train Loss 0.7923835 Test MSE 6.056335478413859 Test RE 1.1762862550170126\n",
      "67 Train Loss 0.7898518 Test MSE 6.06093001577315 Test RE 1.1767323553482383\n",
      "68 Train Loss 0.7876027 Test MSE 6.0635141746169845 Test RE 1.1769831864299238\n",
      "69 Train Loss 0.7820115 Test MSE 6.068018524027259 Test RE 1.177420272841932\n",
      "70 Train Loss 0.77841747 Test MSE 6.074300910642007 Test RE 1.178029622973394\n",
      "71 Train Loss 0.773674 Test MSE 6.085524448220372 Test RE 1.1791174483979816\n",
      "72 Train Loss 0.770941 Test MSE 6.094032454131066 Test RE 1.1799414064980402\n",
      "73 Train Loss 0.76679987 Test MSE 6.1118673105875425 Test RE 1.1816667592346377\n",
      "74 Train Loss 0.76406586 Test MSE 6.1177208760852 Test RE 1.1822324871908911\n",
      "75 Train Loss 0.7614348 Test MSE 6.128007581876143 Test RE 1.1832260083186896\n",
      "76 Train Loss 0.75810766 Test MSE 6.1172249426445795 Test RE 1.1821845673429907\n",
      "77 Train Loss 0.75555265 Test MSE 6.135742396876588 Test RE 1.1839725109980834\n",
      "78 Train Loss 0.7522984 Test MSE 6.146905298147974 Test RE 1.1850490361805348\n",
      "79 Train Loss 0.74939436 Test MSE 6.131304782048731 Test RE 1.1835442853692408\n",
      "80 Train Loss 0.7467897 Test MSE 6.137929673297322 Test RE 1.1841835241271519\n",
      "81 Train Loss 0.7436428 Test MSE 6.161703879871621 Test RE 1.1864746724805935\n",
      "82 Train Loss 0.7420957 Test MSE 6.153607164816145 Test RE 1.1856948796303552\n",
      "83 Train Loss 0.7393226 Test MSE 6.1468731282686475 Test RE 1.185045935194549\n",
      "84 Train Loss 0.73671544 Test MSE 6.1697377595805865 Test RE 1.1872479074457636\n",
      "85 Train Loss 0.7343348 Test MSE 6.152356117636372 Test RE 1.1855743458039274\n",
      "86 Train Loss 0.7312701 Test MSE 6.175877298319692 Test RE 1.187838478904168\n",
      "87 Train Loss 0.72858316 Test MSE 6.187840706296802 Test RE 1.188988414403378\n",
      "88 Train Loss 0.7260399 Test MSE 6.188665600171617 Test RE 1.1890676630962607\n",
      "89 Train Loss 0.72426105 Test MSE 6.20061909260914 Test RE 1.1902154593627552\n",
      "90 Train Loss 0.7222506 Test MSE 6.208363527573672 Test RE 1.1909585037063708\n",
      "91 Train Loss 0.72004867 Test MSE 6.220768040914244 Test RE 1.19214769700829\n",
      "92 Train Loss 0.7178662 Test MSE 6.220605251782937 Test RE 1.1921320984554784\n",
      "93 Train Loss 0.7157964 Test MSE 6.230627282436439 Test RE 1.1930920352806025\n",
      "94 Train Loss 0.7142133 Test MSE 6.239307903662939 Test RE 1.1939228645675484\n",
      "95 Train Loss 0.7116045 Test MSE 6.245680826386849 Test RE 1.1945324543115747\n",
      "96 Train Loss 0.70885545 Test MSE 6.2473051533691 Test RE 1.1946877764623431\n",
      "97 Train Loss 0.707148 Test MSE 6.254317124642874 Test RE 1.1953580468321123\n",
      "98 Train Loss 0.70535 Test MSE 6.243978570242391 Test RE 1.194369658706421\n",
      "99 Train Loss 0.7024814 Test MSE 6.246815202778552 Test RE 1.1946409283058903\n",
      "Training time: 151.10\n",
      "4\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.28911 Test MSE 7.858849684276239 Test RE 1.339946785995994\n",
      "1 Train Loss 45.863693 Test MSE 8.273017164563617 Test RE 1.3748015812408236\n",
      "2 Train Loss 33.84431 Test MSE 7.2891801286008215 Test RE 1.29046848086607\n",
      "3 Train Loss 25.880737 Test MSE 6.689378445166504 Test RE 1.2362347393294681\n",
      "4 Train Loss 20.081673 Test MSE 6.2973098356744694 Test RE 1.1994595072003258\n",
      "5 Train Loss 17.29226 Test MSE 5.855599469991196 Test RE 1.1566281066757902\n",
      "6 Train Loss 14.368171 Test MSE 5.975061932311395 Test RE 1.1683669565224435\n",
      "7 Train Loss 11.474846 Test MSE 5.484653134734306 Test RE 1.1193931466219882\n",
      "8 Train Loss 9.655634 Test MSE 5.336307544160884 Test RE 1.1041510398975352\n",
      "9 Train Loss 8.454501 Test MSE 5.223696354317429 Test RE 1.0924385630841955\n",
      "10 Train Loss 7.522867 Test MSE 4.78155891474096 Test RE 1.045184151819514\n",
      "11 Train Loss 6.7103596 Test MSE 4.62816950377573 Test RE 1.028283076992093\n",
      "12 Train Loss 5.4312115 Test MSE 4.168248302068262 Test RE 0.9758540103865415\n",
      "13 Train Loss 4.5390596 Test MSE 4.067063247549121 Test RE 0.9639367175405505\n",
      "14 Train Loss 3.7713804 Test MSE 3.8946309300096846 Test RE 0.9432812775705256\n",
      "15 Train Loss 3.019716 Test MSE 3.642601924649918 Test RE 0.9122500936963109\n",
      "16 Train Loss 2.7928112 Test MSE 3.5894695992419545 Test RE 0.9055724466516005\n",
      "17 Train Loss 2.4997978 Test MSE 3.3505055763899803 Test RE 0.8749097026280036\n",
      "18 Train Loss 2.3491077 Test MSE 3.2784553414121644 Test RE 0.8654514230293774\n",
      "19 Train Loss 2.239317 Test MSE 3.122167873774659 Test RE 0.8445710400800056\n",
      "20 Train Loss 2.1203642 Test MSE 2.9543306135330023 Test RE 0.8215568246337506\n",
      "21 Train Loss 2.0340655 Test MSE 2.8198466527445962 Test RE 0.8026400124705401\n",
      "22 Train Loss 1.9509639 Test MSE 2.658153536076227 Test RE 0.7792881843355688\n",
      "23 Train Loss 1.8639529 Test MSE 2.5200006762627156 Test RE 0.7587669204769948\n",
      "24 Train Loss 1.8222954 Test MSE 2.357975907573898 Test RE 0.733969041566554\n",
      "25 Train Loss 1.7325649 Test MSE 2.2557200057622473 Test RE 0.7178780193670375\n",
      "26 Train Loss 1.659993 Test MSE 2.184341691811302 Test RE 0.7064287209206183\n",
      "27 Train Loss 1.5987234 Test MSE 2.094736629728561 Test RE 0.6917876009895275\n",
      "28 Train Loss 1.5196072 Test MSE 1.9856136948740388 Test RE 0.6735276666470805\n",
      "29 Train Loss 1.4604316 Test MSE 1.8160801171640495 Test RE 0.6441330189509911\n",
      "30 Train Loss 1.4114052 Test MSE 1.61516837454775 Test RE 0.6074589868704221\n",
      "31 Train Loss 1.3370919 Test MSE 1.5644361753353473 Test RE 0.597842775113941\n",
      "32 Train Loss 1.265024 Test MSE 1.485384520322331 Test RE 0.5825423549392136\n",
      "33 Train Loss 1.2207174 Test MSE 1.4340959878855013 Test RE 0.572396765098474\n",
      "34 Train Loss 1.1808604 Test MSE 1.4162882787872304 Test RE 0.5688318308200405\n",
      "35 Train Loss 1.1189957 Test MSE 1.268175180171616 Test RE 0.5382669131543972\n",
      "36 Train Loss 1.0091902 Test MSE 0.8441314087332251 Test RE 0.4391502054378435\n",
      "37 Train Loss 0.84345424 Test MSE 0.6728503074425627 Test RE 0.39207331788161137\n",
      "38 Train Loss 0.7563521 Test MSE 0.6516490750649139 Test RE 0.38584684358796706\n",
      "39 Train Loss 0.6116234 Test MSE 0.6112472937534092 Test RE 0.37369435282156904\n",
      "40 Train Loss 0.5059161 Test MSE 0.5587173600457492 Test RE 0.3572762464943776\n",
      "41 Train Loss 0.42202768 Test MSE 0.5053512967972278 Test RE 0.3397854301118973\n",
      "42 Train Loss 0.3506881 Test MSE 0.4410638346005376 Test RE 0.3174379053400224\n",
      "43 Train Loss 0.29665467 Test MSE 0.35163937044163923 Test RE 0.2834371726763094\n",
      "44 Train Loss 0.27190098 Test MSE 0.28319452890543156 Test RE 0.2543609800906578\n",
      "45 Train Loss 0.2482462 Test MSE 0.23029180445711267 Test RE 0.22937564437398864\n",
      "46 Train Loss 0.22858 Test MSE 0.20238757858351236 Test RE 0.2150304617403203\n",
      "47 Train Loss 0.17748374 Test MSE 0.1256372675300374 Test RE 0.16942102366698938\n",
      "48 Train Loss 0.15041052 Test MSE 0.07429959246344553 Test RE 0.1302870576015898\n",
      "49 Train Loss 0.12074789 Test MSE 0.031083953279942695 Test RE 0.08427061901032767\n",
      "50 Train Loss 0.09950293 Test MSE 0.03472258174443119 Test RE 0.08906643404050289\n",
      "51 Train Loss 0.08504411 Test MSE 0.03278768460070485 Test RE 0.08654927508026894\n",
      "52 Train Loss 0.067031376 Test MSE 0.026674444110169383 Test RE 0.07806488945776052\n",
      "53 Train Loss 0.06156299 Test MSE 0.022464316973864223 Test RE 0.07163985027172906\n",
      "54 Train Loss 0.055089194 Test MSE 0.019774056658746934 Test RE 0.06721341277980554\n",
      "55 Train Loss 0.04785032 Test MSE 0.016736842833211318 Test RE 0.061836489902399816\n",
      "56 Train Loss 0.041142665 Test MSE 0.01716924829489655 Test RE 0.06263018591883529\n",
      "57 Train Loss 0.038546067 Test MSE 0.01472360189565415 Test RE 0.05799827721063088\n",
      "58 Train Loss 0.034676496 Test MSE 0.013666183355142336 Test RE 0.05587681997895958\n",
      "59 Train Loss 0.03284183 Test MSE 0.010937033091336066 Test RE 0.049987086353869864\n",
      "60 Train Loss 0.030200068 Test MSE 0.0095408614580724 Test RE 0.04668763286114099\n",
      "61 Train Loss 0.028670631 Test MSE 0.00909365335262219 Test RE 0.04558030823816598\n",
      "62 Train Loss 0.026141182 Test MSE 0.008941043064362207 Test RE 0.04519622412448847\n",
      "63 Train Loss 0.025091745 Test MSE 0.009318216379597979 Test RE 0.04613966700020069\n",
      "64 Train Loss 0.024068378 Test MSE 0.009694634646352564 Test RE 0.047062368894152114\n",
      "65 Train Loss 0.023046218 Test MSE 0.009944000307290885 Test RE 0.04766379574787613\n",
      "66 Train Loss 0.021843342 Test MSE 0.00927651470731327 Test RE 0.04603630715374801\n",
      "67 Train Loss 0.021240104 Test MSE 0.00958173916745355 Test RE 0.046787542268949475\n",
      "68 Train Loss 0.020353943 Test MSE 0.0077912571712511775 Test RE 0.042190223894612564\n",
      "69 Train Loss 0.019085636 Test MSE 0.006615285826150502 Test RE 0.03887607103538039\n",
      "70 Train Loss 0.017733274 Test MSE 0.006278677120548778 Test RE 0.037874083764675465\n",
      "71 Train Loss 0.016723257 Test MSE 0.004940506343600919 Test RE 0.03359648103835223\n",
      "72 Train Loss 0.014138906 Test MSE 0.004293342555961943 Test RE 0.031318851739063\n",
      "73 Train Loss 0.013573751 Test MSE 0.0033884534484316035 Test RE 0.02782331176079836\n",
      "74 Train Loss 0.013197506 Test MSE 0.003077440425251208 Test RE 0.026515687222839472\n",
      "75 Train Loss 0.0127689075 Test MSE 0.0028403484146672458 Test RE 0.025473807848411804\n",
      "76 Train Loss 0.011495617 Test MSE 0.0024657028428552723 Test RE 0.02373440933942387\n",
      "77 Train Loss 0.010394491 Test MSE 0.0029356242534254464 Test RE 0.02589752695798777\n",
      "78 Train Loss 0.009784647 Test MSE 0.00283927929301035 Test RE 0.02546901316146305\n",
      "79 Train Loss 0.009462515 Test MSE 0.002579068020424497 Test RE 0.024273894411069342\n",
      "80 Train Loss 0.008964572 Test MSE 0.0022127616687321852 Test RE 0.022484093368319767\n",
      "81 Train Loss 0.008522636 Test MSE 0.0020323382579116554 Test RE 0.02154795483595441\n",
      "82 Train Loss 0.0081366645 Test MSE 0.0020947209375739564 Test RE 0.02187616282175884\n",
      "83 Train Loss 0.007868588 Test MSE 0.002223051411186609 Test RE 0.0225363102870275\n",
      "84 Train Loss 0.0076409495 Test MSE 0.0023245508311995435 Test RE 0.023045046245173645\n",
      "85 Train Loss 0.0071304995 Test MSE 0.0021931686937336514 Test RE 0.022384328942823186\n",
      "86 Train Loss 0.0066506383 Test MSE 0.0020923646222776628 Test RE 0.02186385530135468\n",
      "87 Train Loss 0.006352303 Test MSE 0.0020182743233518666 Test RE 0.021473268664006145\n",
      "88 Train Loss 0.0061331945 Test MSE 0.0018726540453925127 Test RE 0.020684109909939706\n",
      "89 Train Loss 0.006036008 Test MSE 0.001808242282189526 Test RE 0.020325272194978403\n",
      "90 Train Loss 0.0058220867 Test MSE 0.0019093499301463372 Test RE 0.020885786061797407\n",
      "91 Train Loss 0.005279712 Test MSE 0.0022559028419841956 Test RE 0.022702216235991224\n",
      "92 Train Loss 0.0050615594 Test MSE 0.002299618825301991 Test RE 0.022921128077873987\n",
      "93 Train Loss 0.004964954 Test MSE 0.002135722561792498 Test RE 0.02208922495624567\n",
      "94 Train Loss 0.0048021087 Test MSE 0.0023735031308870854 Test RE 0.02328643278823782\n",
      "95 Train Loss 0.004507468 Test MSE 0.0025160595777495693 Test RE 0.02397554679067999\n",
      "96 Train Loss 0.0043795127 Test MSE 0.0027035917114735983 Test RE 0.024852988190012196\n",
      "97 Train Loss 0.004280824 Test MSE 0.002724392653805669 Test RE 0.024948412180827433\n",
      "98 Train Loss 0.004122728 Test MSE 0.0022608109603522945 Test RE 0.022726899174890503\n",
      "99 Train Loss 0.0040427013 Test MSE 0.0021030202064448436 Test RE 0.02191945657946051\n",
      "Training time: 150.57\n",
      "5\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.62777 Test MSE 4.823950353137377 Test RE 1.0498070260166967\n",
      "1 Train Loss 46.94872 Test MSE 5.18161383039223 Test RE 1.0880292776487261\n",
      "2 Train Loss 35.570206 Test MSE 5.7512773379920725 Test RE 1.1462786818443191\n",
      "3 Train Loss 28.73479 Test MSE 6.329259029548474 Test RE 1.2024983668242961\n",
      "4 Train Loss 24.464237 Test MSE 5.8940937177413195 Test RE 1.160423669804421\n",
      "5 Train Loss 19.143867 Test MSE 5.687820749338883 Test RE 1.139937421813428\n",
      "6 Train Loss 16.843327 Test MSE 5.785021932073362 Test RE 1.1496365564828672\n",
      "7 Train Loss 15.471838 Test MSE 5.869068317872503 Test RE 1.1579575606573698\n",
      "8 Train Loss 14.440659 Test MSE 5.941485947556922 Test RE 1.1650795983780964\n",
      "9 Train Loss 13.637653 Test MSE 5.947976920330723 Test RE 1.165715839519691\n",
      "10 Train Loss 12.931572 Test MSE 5.987339666413301 Test RE 1.16956673800327\n",
      "11 Train Loss 12.216518 Test MSE 5.815190393414325 Test RE 1.152630293319243\n",
      "12 Train Loss 11.49806 Test MSE 5.804276861584265 Test RE 1.1515481984905112\n",
      "13 Train Loss 10.834093 Test MSE 5.461385316445713 Test RE 1.117016194212417\n",
      "14 Train Loss 9.921449 Test MSE 5.4052998277885935 Test RE 1.1112658151414743\n",
      "15 Train Loss 9.094121 Test MSE 5.157800242791483 Test RE 1.0855262236742842\n",
      "16 Train Loss 8.2445545 Test MSE 4.937849444924263 Test RE 1.0621283042905996\n",
      "17 Train Loss 6.940037 Test MSE 4.873204776875373 Test RE 1.0551528854336056\n",
      "18 Train Loss 5.5012703 Test MSE 4.137141474678968 Test RE 0.9722058868719714\n",
      "19 Train Loss 4.183729 Test MSE 4.318441748313935 Test RE 0.9932797764345188\n",
      "20 Train Loss 3.1290884 Test MSE 3.774260325365927 Test RE 0.9285899652899335\n",
      "21 Train Loss 2.610304 Test MSE 3.9343808531062927 Test RE 0.9480827814192709\n",
      "22 Train Loss 2.2087612 Test MSE 3.8818111623106617 Test RE 0.9417275212997457\n",
      "23 Train Loss 1.9633942 Test MSE 3.8660656662881063 Test RE 0.9398156516488814\n",
      "24 Train Loss 1.8144 Test MSE 3.8961322760749044 Test RE 0.9434630733817151\n",
      "25 Train Loss 1.687537 Test MSE 3.8731713136440984 Test RE 0.9406789237103244\n",
      "26 Train Loss 1.4972581 Test MSE 3.9541389776627134 Test RE 0.9504603954838207\n",
      "27 Train Loss 1.4087415 Test MSE 4.007620853592163 Test RE 0.9568665529233995\n",
      "28 Train Loss 1.3323305 Test MSE 3.969416422632296 Test RE 0.9522947528282999\n",
      "29 Train Loss 1.2621715 Test MSE 3.982711706919649 Test RE 0.9538882421508819\n",
      "30 Train Loss 1.2200048 Test MSE 3.98128677280059 Test RE 0.9537175858744684\n",
      "31 Train Loss 1.1697149 Test MSE 4.046451596907366 Test RE 0.9614910260752011\n",
      "32 Train Loss 1.113932 Test MSE 4.104741812586913 Test RE 0.9683915315036836\n",
      "33 Train Loss 1.0563544 Test MSE 4.162034779583149 Test RE 0.9751263963191457\n",
      "34 Train Loss 1.0333338 Test MSE 4.146037344032901 Test RE 0.9732505662039933\n",
      "35 Train Loss 0.98870456 Test MSE 4.089146301475924 Test RE 0.9665501326993333\n",
      "36 Train Loss 0.953472 Test MSE 4.015276656280159 Test RE 0.9577800732635355\n",
      "37 Train Loss 0.9218562 Test MSE 3.983446717802491 Test RE 0.9539762582998861\n",
      "38 Train Loss 0.88134223 Test MSE 3.962247074801732 Test RE 0.9514343722117516\n",
      "39 Train Loss 0.86227536 Test MSE 3.937921221385636 Test RE 0.9485092535334871\n",
      "40 Train Loss 0.8323666 Test MSE 3.9133380003943405 Test RE 0.945543993926142\n",
      "41 Train Loss 0.8041909 Test MSE 3.840241098297593 Test RE 0.9366714992331775\n",
      "42 Train Loss 0.7810928 Test MSE 3.8241466649487563 Test RE 0.9347066453562772\n",
      "43 Train Loss 0.7584739 Test MSE 3.8431420432983425 Test RE 0.9370252165484608\n",
      "44 Train Loss 0.74021304 Test MSE 3.85576653433802 Test RE 0.9385629905194387\n",
      "45 Train Loss 0.71475536 Test MSE 3.792993338237965 Test RE 0.9308915760569111\n",
      "46 Train Loss 0.69947857 Test MSE 3.8041156811810404 Test RE 0.9322554218906068\n",
      "47 Train Loss 0.6794307 Test MSE 3.739913470456289 Test RE 0.9243550906944796\n",
      "48 Train Loss 0.67207974 Test MSE 3.716885176916066 Test RE 0.9215048658009382\n",
      "49 Train Loss 0.65687776 Test MSE 3.6781450457747447 Test RE 0.9166899836454754\n",
      "50 Train Loss 0.6422555 Test MSE 3.716959255507297 Test RE 0.9215140486837679\n",
      "51 Train Loss 0.62666184 Test MSE 3.7028406492523214 Test RE 0.9197622306657609\n",
      "52 Train Loss 0.6206313 Test MSE 3.7123352924026713 Test RE 0.9209406804144517\n",
      "53 Train Loss 0.6072857 Test MSE 3.657025199566804 Test RE 0.9140543856724463\n",
      "54 Train Loss 0.5976671 Test MSE 3.6658140086683595 Test RE 0.9151520850627283\n",
      "55 Train Loss 0.5832436 Test MSE 3.681195375398645 Test RE 0.917070015847391\n",
      "56 Train Loss 0.57514876 Test MSE 3.6726831511410434 Test RE 0.9160091072569068\n",
      "57 Train Loss 0.55773777 Test MSE 3.6542772423565917 Test RE 0.9137109023451555\n",
      "58 Train Loss 0.55094564 Test MSE 3.6564459020280276 Test RE 0.9139819866051498\n",
      "59 Train Loss 0.5398538 Test MSE 3.6679962851315753 Test RE 0.9154244417229712\n",
      "60 Train Loss 0.52803504 Test MSE 3.614052745088499 Test RE 0.9086681454500394\n",
      "61 Train Loss 0.5185882 Test MSE 3.575274132854832 Test RE 0.9037800149737688\n",
      "62 Train Loss 0.50898397 Test MSE 3.5977681768830623 Test RE 0.9066186492394687\n",
      "63 Train Loss 0.49664494 Test MSE 3.5729406364933465 Test RE 0.903485028977074\n",
      "64 Train Loss 0.49007568 Test MSE 3.5459967850425858 Test RE 0.9000719532213198\n",
      "65 Train Loss 0.48331895 Test MSE 3.5329580796194797 Test RE 0.8984156374064396\n",
      "66 Train Loss 0.47626913 Test MSE 3.5145856754715368 Test RE 0.8960765818819928\n",
      "67 Train Loss 0.4706443 Test MSE 3.5112728549625505 Test RE 0.8956541649866754\n",
      "68 Train Loss 0.46255356 Test MSE 3.5112846511247406 Test RE 0.895655669465729\n",
      "69 Train Loss 0.454815 Test MSE 3.473455270261314 Test RE 0.890817859904861\n",
      "70 Train Loss 0.44640952 Test MSE 3.395457664209016 Test RE 0.8807592647207064\n",
      "71 Train Loss 0.44171154 Test MSE 3.416074173742366 Test RE 0.8834291112866074\n",
      "72 Train Loss 0.43318182 Test MSE 3.430785220179742 Test RE 0.8853292756758708\n",
      "73 Train Loss 0.42909628 Test MSE 3.4471649514088267 Test RE 0.8874401901073258\n",
      "74 Train Loss 0.42129683 Test MSE 3.4522273378564723 Test RE 0.8880915829270203\n",
      "75 Train Loss 0.41864112 Test MSE 3.4616683735560763 Test RE 0.8893051153697825\n",
      "76 Train Loss 0.41297927 Test MSE 3.475388451969053 Test RE 0.8910657216318973\n",
      "77 Train Loss 0.40876526 Test MSE 3.4773018282384873 Test RE 0.8913109761451751\n",
      "78 Train Loss 0.40491027 Test MSE 3.4844655890818212 Test RE 0.8922286205982316\n",
      "79 Train Loss 0.40076342 Test MSE 3.482145260693922 Test RE 0.8919315006943022\n",
      "80 Train Loss 0.3984535 Test MSE 3.4754554262852095 Test RE 0.8910743074677929\n",
      "81 Train Loss 0.3941396 Test MSE 3.471210956388938 Test RE 0.8905300200193755\n",
      "82 Train Loss 0.3909009 Test MSE 3.4759584438965976 Test RE 0.8911387896431464\n",
      "83 Train Loss 0.38811034 Test MSE 3.470050480353132 Test RE 0.8903811490420412\n",
      "84 Train Loss 0.38573265 Test MSE 3.463001424967612 Test RE 0.8894763298252938\n",
      "85 Train Loss 0.38361192 Test MSE 3.469754421445389 Test RE 0.8903431653160434\n",
      "86 Train Loss 0.38135108 Test MSE 3.4677594917248524 Test RE 0.8900871778308456\n",
      "87 Train Loss 0.3780756 Test MSE 3.458485068763897 Test RE 0.8888961246678059\n",
      "88 Train Loss 0.37336463 Test MSE 3.459053642544902 Test RE 0.8889691887768244\n",
      "89 Train Loss 0.37128887 Test MSE 3.457118823730879 Test RE 0.8887205319076427\n",
      "90 Train Loss 0.36835593 Test MSE 3.450059999749348 Test RE 0.8878127633798923\n",
      "91 Train Loss 0.3663633 Test MSE 3.4396566328228637 Test RE 0.8864731902657642\n",
      "92 Train Loss 0.3637939 Test MSE 3.433474157554223 Test RE 0.8856761538028737\n",
      "93 Train Loss 0.36092785 Test MSE 3.4518791845686634 Test RE 0.8880468002736747\n",
      "94 Train Loss 0.35895672 Test MSE 3.4408638011133608 Test RE 0.8866287331825264\n",
      "95 Train Loss 0.35609147 Test MSE 3.4444744642786658 Test RE 0.887093802204369\n",
      "96 Train Loss 0.3524218 Test MSE 3.441450372806383 Test RE 0.8867043027465409\n",
      "97 Train Loss 0.34971657 Test MSE 3.4403662275380493 Test RE 0.8865646244289938\n",
      "98 Train Loss 0.34661156 Test MSE 3.431298863677124 Test RE 0.8853955471818062\n",
      "99 Train Loss 0.34200883 Test MSE 3.4327749509128003 Test RE 0.885585967864174\n",
      "Training time: 154.06\n",
      "6\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.03427 Test MSE 7.564233160936146 Test RE 1.3145905737225638\n",
      "1 Train Loss 42.70862 Test MSE 8.623310229164614 Test RE 1.4036055134517131\n",
      "2 Train Loss 36.970284 Test MSE 8.746797971336333 Test RE 1.4136197626530156\n",
      "3 Train Loss 32.850662 Test MSE 8.930575008158975 Test RE 1.4283931917494344\n",
      "4 Train Loss 28.158035 Test MSE 8.710727842721127 Test RE 1.4107020021662582\n",
      "5 Train Loss 25.950104 Test MSE 8.854910499606037 Test RE 1.4223292726570078\n",
      "6 Train Loss 23.690784 Test MSE 8.820128372861515 Test RE 1.419533066309934\n",
      "7 Train Loss 21.58519 Test MSE 8.891658974744605 Test RE 1.4252775980396137\n",
      "8 Train Loss 19.186434 Test MSE 8.831622327074713 Test RE 1.420457697747999\n",
      "9 Train Loss 17.335823 Test MSE 8.753672262748944 Test RE 1.4141751502162065\n",
      "10 Train Loss 16.338848 Test MSE 8.82519813402216 Test RE 1.4199409775921625\n",
      "11 Train Loss 15.149316 Test MSE 8.884031975298388 Test RE 1.4246661866258776\n",
      "12 Train Loss 13.944914 Test MSE 8.620293954548476 Test RE 1.4033600143424665\n",
      "13 Train Loss 12.908993 Test MSE 8.324858957042787 Test RE 1.3791023623740286\n",
      "14 Train Loss 11.912868 Test MSE 8.315472124741897 Test RE 1.3783246282449781\n",
      "15 Train Loss 10.978915 Test MSE 8.04096009973146 Test RE 1.3553829365317698\n",
      "16 Train Loss 9.753207 Test MSE 7.86938446656284 Test RE 1.340844584068432\n",
      "17 Train Loss 8.716076 Test MSE 7.659461813509572 Test RE 1.322839601939213\n",
      "18 Train Loss 7.4553876 Test MSE 7.514673844194868 Test RE 1.3102770317554349\n",
      "19 Train Loss 6.1011596 Test MSE 6.973267984466263 Test RE 1.2621943682203078\n",
      "20 Train Loss 4.7760553 Test MSE 6.75705460177053 Test RE 1.2424724694021296\n",
      "21 Train Loss 4.1049337 Test MSE 6.496358128307744 Test RE 1.218268568572894\n",
      "22 Train Loss 3.618692 Test MSE 6.337950793918892 Test RE 1.2033237593847288\n",
      "23 Train Loss 3.2654114 Test MSE 6.327811519920552 Test RE 1.2023608525048668\n",
      "24 Train Loss 3.0570402 Test MSE 6.3833777444353785 Test RE 1.207628441680737\n",
      "25 Train Loss 2.8488126 Test MSE 6.389446524176031 Test RE 1.208202361181717\n",
      "26 Train Loss 2.6982872 Test MSE 6.347962765100517 Test RE 1.204273821090338\n",
      "27 Train Loss 2.5197413 Test MSE 6.283353379354704 Test RE 1.1981296147464695\n",
      "28 Train Loss 2.406704 Test MSE 6.267147821213749 Test RE 1.1965835537948286\n",
      "29 Train Loss 2.2736707 Test MSE 6.179079106911719 Test RE 1.1881463492242017\n",
      "30 Train Loss 2.1834738 Test MSE 6.072137009655883 Test RE 1.1778197744191066\n",
      "31 Train Loss 2.1062064 Test MSE 5.993503552247762 Test RE 1.1701686097687891\n",
      "32 Train Loss 2.0167913 Test MSE 5.895981316531787 Test RE 1.1606094692739455\n",
      "33 Train Loss 1.9325145 Test MSE 5.955932225898928 Test RE 1.166495140371126\n",
      "34 Train Loss 1.8592734 Test MSE 5.90765318348245 Test RE 1.1617576904902782\n",
      "35 Train Loss 1.8065261 Test MSE 5.911639718636956 Test RE 1.1621496064227776\n",
      "36 Train Loss 1.747699 Test MSE 5.893639145964172 Test RE 1.160378921108012\n",
      "37 Train Loss 1.7115082 Test MSE 5.907390402972624 Test RE 1.1617318519158308\n",
      "38 Train Loss 1.6756191 Test MSE 5.856162662747309 Test RE 1.156683727702487\n",
      "39 Train Loss 1.633526 Test MSE 5.822306882270439 Test RE 1.1533353581629449\n",
      "40 Train Loss 1.5933459 Test MSE 5.729582773183031 Test RE 1.1441146831904279\n",
      "41 Train Loss 1.5603815 Test MSE 5.731713742843311 Test RE 1.14432742529765\n",
      "42 Train Loss 1.5235066 Test MSE 5.756582680864283 Test RE 1.1468072600414658\n",
      "43 Train Loss 1.4968952 Test MSE 5.756175988359709 Test RE 1.1467667493617317\n",
      "44 Train Loss 1.4605933 Test MSE 5.757070445365075 Test RE 1.1468558444233024\n",
      "45 Train Loss 1.4141027 Test MSE 5.839001146977623 Test RE 1.154987650297785\n",
      "46 Train Loss 1.3890547 Test MSE 5.802353307422274 Test RE 1.1513573694748607\n",
      "47 Train Loss 1.3632908 Test MSE 5.7699826529144715 Test RE 1.1481412331360052\n",
      "48 Train Loss 1.3457376 Test MSE 5.779986701685538 Test RE 1.1491361309749546\n",
      "49 Train Loss 1.3268116 Test MSE 5.802590754361693 Test RE 1.1513809274583386\n",
      "50 Train Loss 1.2997607 Test MSE 5.832983402476092 Test RE 1.1543923248194203\n",
      "51 Train Loss 1.283295 Test MSE 5.835949454718758 Test RE 1.1546857898052423\n",
      "52 Train Loss 1.2626979 Test MSE 5.864908035295173 Test RE 1.157547079434948\n",
      "53 Train Loss 1.2436721 Test MSE 5.859715964794916 Test RE 1.1570345908553643\n",
      "54 Train Loss 1.2187965 Test MSE 5.862108944098531 Test RE 1.1572708204976072\n",
      "55 Train Loss 1.2034546 Test MSE 5.844053592624644 Test RE 1.15548724349604\n",
      "56 Train Loss 1.1855633 Test MSE 5.861721881242832 Test RE 1.1572326137748048\n",
      "57 Train Loss 1.1727374 Test MSE 5.877325310937439 Test RE 1.158771819969492\n",
      "58 Train Loss 1.1597083 Test MSE 5.871752057434806 Test RE 1.1582222791076948\n",
      "59 Train Loss 1.144623 Test MSE 5.855767441213599 Test RE 1.156644695826457\n",
      "60 Train Loss 1.1254591 Test MSE 5.8780632078377515 Test RE 1.158844559460043\n",
      "61 Train Loss 1.1127281 Test MSE 5.890370552814611 Test RE 1.1600571052898125\n",
      "62 Train Loss 1.1016895 Test MSE 5.8870737141285385 Test RE 1.1597324180393138\n",
      "63 Train Loss 1.0896022 Test MSE 5.905448003429414 Test RE 1.1615408426217109\n",
      "64 Train Loss 1.0738722 Test MSE 5.90756313964263 Test RE 1.161748836761161\n",
      "65 Train Loss 1.0614522 Test MSE 5.937228502040051 Test RE 1.1646620974482196\n",
      "66 Train Loss 1.0535711 Test MSE 5.947905200604351 Test RE 1.1657088114936762\n",
      "67 Train Loss 1.0431825 Test MSE 5.963189095875823 Test RE 1.1672055687543663\n",
      "68 Train Loss 1.0344245 Test MSE 5.980289395329114 Test RE 1.1688779353086174\n",
      "69 Train Loss 1.0266502 Test MSE 5.987230305684799 Test RE 1.1695560566939003\n",
      "70 Train Loss 1.0147421 Test MSE 5.983685745365781 Test RE 1.1692098051282038\n",
      "71 Train Loss 1.0026788 Test MSE 5.956224259238645 Test RE 1.1665237380182285\n",
      "72 Train Loss 0.9937626 Test MSE 5.972253715504834 Test RE 1.168092364111224\n",
      "73 Train Loss 0.98225856 Test MSE 6.011300261165207 Test RE 1.1719046322519628\n",
      "74 Train Loss 0.9701226 Test MSE 6.021795276531337 Test RE 1.1729271891908628\n",
      "75 Train Loss 0.9625757 Test MSE 6.023878949166497 Test RE 1.1731301008469788\n",
      "76 Train Loss 0.95705134 Test MSE 6.006604865533235 Test RE 1.1714468585111233\n",
      "77 Train Loss 0.94933635 Test MSE 6.01337585318021 Test RE 1.1721069334066352\n",
      "78 Train Loss 0.940518 Test MSE 6.031654814923587 Test RE 1.1738870184710621\n",
      "79 Train Loss 0.92826307 Test MSE 6.041920154265361 Test RE 1.174885519393812\n",
      "80 Train Loss 0.9218608 Test MSE 6.050682527201077 Test RE 1.1757371571995703\n",
      "81 Train Loss 0.9165161 Test MSE 6.060165853554304 Test RE 1.1766581717864468\n",
      "82 Train Loss 0.91132224 Test MSE 6.0824180198177125 Test RE 1.1788164627131934\n",
      "83 Train Loss 0.90563893 Test MSE 6.099353036305458 Test RE 1.1804563861576156\n",
      "84 Train Loss 0.9005725 Test MSE 6.092994978841837 Test RE 1.179840962976673\n",
      "85 Train Loss 0.8972397 Test MSE 6.101684622283585 Test RE 1.1806819898043757\n",
      "86 Train Loss 0.8950411 Test MSE 6.120922412167457 Test RE 1.1825417906867208\n",
      "87 Train Loss 0.89128953 Test MSE 6.131458747102387 Test RE 1.183559145445678\n",
      "88 Train Loss 0.88801944 Test MSE 6.131078062078877 Test RE 1.1835224029465876\n",
      "89 Train Loss 0.8825799 Test MSE 6.146415284575028 Test RE 1.1850018008924212\n",
      "90 Train Loss 0.87953913 Test MSE 6.153115819467549 Test RE 1.1856475417618328\n",
      "91 Train Loss 0.8757478 Test MSE 6.147016706250915 Test RE 1.185059775199635\n",
      "92 Train Loss 0.8710902 Test MSE 6.126934378119002 Test RE 1.1831223940376399\n",
      "93 Train Loss 0.8662554 Test MSE 6.142379212846288 Test RE 1.184612668572398\n",
      "94 Train Loss 0.8608767 Test MSE 6.153860978982785 Test RE 1.185719332203174\n",
      "95 Train Loss 0.85642165 Test MSE 6.171344577415145 Test RE 1.1874024980454518\n",
      "96 Train Loss 0.85301954 Test MSE 6.180023557031789 Test RE 1.188237147712705\n",
      "97 Train Loss 0.8503408 Test MSE 6.179750149851774 Test RE 1.1882108633338544\n",
      "98 Train Loss 0.8460362 Test MSE 6.192927073927448 Test RE 1.1894769846658066\n",
      "99 Train Loss 0.8429596 Test MSE 6.198265718526591 Test RE 1.1899895715927349\n",
      "Training time: 150.34\n",
      "7\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.22\n",
      "0\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.56601 Test MSE 4.425542727682943 Test RE 1.0055214264950545\n",
      "1 Train Loss 62.27808 Test MSE 4.247684934669194 Test RE 0.9851088220240664\n",
      "2 Train Loss 42.356567 Test MSE 6.102766758511072 Test RE 1.1807866823761897\n",
      "3 Train Loss 30.207237 Test MSE 6.093857963881582 Test RE 1.179924513763569\n",
      "4 Train Loss 25.149136 Test MSE 5.708427427919097 Test RE 1.1420005218552292\n",
      "5 Train Loss 21.742044 Test MSE 6.135059709344399 Test RE 1.183906642379105\n",
      "6 Train Loss 19.267857 Test MSE 6.146175040607114 Test RE 1.1849786416765684\n",
      "7 Train Loss 17.279434 Test MSE 5.91674149206734 Test RE 1.1626509686187128\n",
      "8 Train Loss 14.935058 Test MSE 5.845307096828845 Test RE 1.1556111583810524\n",
      "9 Train Loss 13.390547 Test MSE 5.8725607860747315 Test RE 1.1583020385447922\n",
      "10 Train Loss 11.331227 Test MSE 5.428945810810906 Test RE 1.1136938300861132\n",
      "11 Train Loss 9.569076 Test MSE 5.10683306273344 Test RE 1.0801495548541402\n",
      "12 Train Loss 8.124613 Test MSE 4.703085337877384 Test RE 1.0365720391268993\n",
      "13 Train Loss 6.7220993 Test MSE 4.48565639570015 Test RE 1.0123275635051239\n",
      "14 Train Loss 5.951169 Test MSE 4.635615596075174 Test RE 1.0291099280319695\n",
      "15 Train Loss 5.2591887 Test MSE 4.3590102709998595 Test RE 0.9979344296625948\n",
      "16 Train Loss 4.829141 Test MSE 4.639685211788518 Test RE 1.0295615577097421\n",
      "17 Train Loss 4.5214972 Test MSE 4.5706281677152205 Test RE 1.0218708395606746\n",
      "18 Train Loss 4.0923758 Test MSE 4.554514282712328 Test RE 1.020067931147796\n",
      "19 Train Loss 3.760673 Test MSE 4.505935552982799 Test RE 1.0146132936043817\n",
      "20 Train Loss 3.5102043 Test MSE 4.440298450863592 Test RE 1.0071963452223844\n",
      "21 Train Loss 3.3115706 Test MSE 4.3742656560893565 Test RE 0.9996791579891174\n",
      "22 Train Loss 3.0644886 Test MSE 4.2975178666829414 Test RE 0.9908705156605094\n",
      "23 Train Loss 2.92768 Test MSE 4.330264144357811 Test RE 0.9946384749578132\n",
      "24 Train Loss 2.8178 Test MSE 4.2369252421918295 Test RE 0.9838603550398115\n",
      "25 Train Loss 2.6481562 Test MSE 4.19126237626973 Test RE 0.9785442846345113\n",
      "26 Train Loss 2.57123 Test MSE 4.130002626853246 Test RE 0.9713667293853109\n",
      "27 Train Loss 2.4753017 Test MSE 4.08067767925367 Test RE 0.9655487512755565\n",
      "28 Train Loss 2.3885205 Test MSE 4.042568597601317 Test RE 0.9610295890615095\n",
      "29 Train Loss 2.319581 Test MSE 4.019642623234165 Test RE 0.9583006476112683\n",
      "30 Train Loss 2.2666001 Test MSE 4.02402402774354 Test RE 0.9588227785132419\n",
      "31 Train Loss 2.1931355 Test MSE 4.0054860466201045 Test RE 0.9566116638546894\n",
      "32 Train Loss 2.097566 Test MSE 3.972015835705189 Test RE 0.9526065117920094\n",
      "33 Train Loss 2.0558453 Test MSE 3.9766287278224364 Test RE 0.9531595050543422\n",
      "34 Train Loss 1.9659754 Test MSE 3.829864382731855 Test RE 0.9354051531655776\n",
      "35 Train Loss 1.8824972 Test MSE 3.847854685929607 Test RE 0.93759955286313\n",
      "36 Train Loss 1.8146394 Test MSE 3.761769229545022 Test RE 0.9270520852687477\n",
      "37 Train Loss 1.7713358 Test MSE 3.7382935580748056 Test RE 0.9241548806565929\n",
      "38 Train Loss 1.7165796 Test MSE 3.6534375495631464 Test RE 0.913605918447007\n",
      "39 Train Loss 1.6571418 Test MSE 3.631711465914856 Test RE 0.9108853743309007\n",
      "40 Train Loss 1.5837315 Test MSE 3.5542998333654126 Test RE 0.9011251086146739\n",
      "41 Train Loss 1.5292845 Test MSE 3.4356111170789636 Test RE 0.8859517288626086\n",
      "42 Train Loss 1.4899759 Test MSE 3.4167734062126587 Test RE 0.8835195207275922\n",
      "43 Train Loss 1.4305811 Test MSE 3.3536265963140446 Test RE 0.8753171001015467\n",
      "44 Train Loss 1.3732939 Test MSE 3.337263004703519 Test RE 0.8731789898920914\n",
      "45 Train Loss 1.3020266 Test MSE 3.2746084807515854 Test RE 0.8649435240524015\n",
      "46 Train Loss 1.2507614 Test MSE 3.13526975930455 Test RE 0.8463412665739111\n",
      "47 Train Loss 1.2022268 Test MSE 3.120237644647189 Test RE 0.844309928613688\n",
      "48 Train Loss 1.1169673 Test MSE 2.985236871326297 Test RE 0.8258429369218971\n",
      "49 Train Loss 1.0729846 Test MSE 2.981566315917284 Test RE 0.8253350652249251\n",
      "50 Train Loss 1.0365086 Test MSE 2.919074098889196 Test RE 0.8166399466403335\n",
      "51 Train Loss 0.9591421 Test MSE 2.872191888722807 Test RE 0.8100555203312537\n",
      "52 Train Loss 0.9353163 Test MSE 2.8368040037408124 Test RE 0.8050497618700667\n",
      "53 Train Loss 0.86797106 Test MSE 2.7904451861056123 Test RE 0.7984446371244773\n",
      "54 Train Loss 0.8419033 Test MSE 2.8176456857130927 Test RE 0.8023267101398535\n",
      "55 Train Loss 0.8087785 Test MSE 2.8203846066252085 Test RE 0.8027165703070653\n",
      "56 Train Loss 0.7619248 Test MSE 2.8612280943932458 Test RE 0.808507961161031\n",
      "57 Train Loss 0.75035024 Test MSE 2.8682001711763356 Test RE 0.8094924247566131\n",
      "58 Train Loss 0.7231467 Test MSE 2.8606385549182884 Test RE 0.8084246626789922\n",
      "59 Train Loss 0.7084153 Test MSE 2.875003987217704 Test RE 0.8104519768871998\n",
      "60 Train Loss 0.6932917 Test MSE 2.872018501974655 Test RE 0.8100310694906252\n",
      "61 Train Loss 0.6786788 Test MSE 2.897527999793288 Test RE 0.8136204970570022\n",
      "62 Train Loss 0.66345334 Test MSE 2.8846582895593014 Test RE 0.8118115908027892\n",
      "63 Train Loss 0.6521744 Test MSE 2.90490214481761 Test RE 0.8146551623093816\n",
      "64 Train Loss 0.64755356 Test MSE 2.9083822051356174 Test RE 0.8151429929446276\n",
      "65 Train Loss 0.6300654 Test MSE 2.912763095930983 Test RE 0.8157566861299345\n",
      "66 Train Loss 0.6192642 Test MSE 2.9221150705823895 Test RE 0.8170652069186334\n",
      "67 Train Loss 0.6164188 Test MSE 2.933298260012479 Test RE 0.8186272038031206\n",
      "68 Train Loss 0.6004465 Test MSE 2.9427065325705613 Test RE 0.8199389868726384\n",
      "69 Train Loss 0.5857397 Test MSE 2.975553981977458 Test RE 0.8245025004602936\n",
      "70 Train Loss 0.58199424 Test MSE 2.9871489029382183 Test RE 0.8261073690438873\n",
      "71 Train Loss 0.578107 Test MSE 2.9759254338971792 Test RE 0.8245539620504734\n",
      "72 Train Loss 0.5574055 Test MSE 3.017048146196887 Test RE 0.8302314495720847\n",
      "73 Train Loss 0.5498318 Test MSE 3.0099874039514947 Test RE 0.8292593928271417\n",
      "74 Train Loss 0.54094994 Test MSE 3.00673793501706 Test RE 0.8288116533638099\n",
      "75 Train Loss 0.53074765 Test MSE 2.993550907266531 Test RE 0.826992144539115\n",
      "76 Train Loss 0.51819855 Test MSE 3.0132258721693335 Test RE 0.8297053761271472\n",
      "77 Train Loss 0.5119352 Test MSE 3.012066350055248 Test RE 0.8295457209364344\n",
      "78 Train Loss 0.5078344 Test MSE 3.0118413830900685 Test RE 0.8295147415610887\n",
      "79 Train Loss 0.49964017 Test MSE 3.0355899457933053 Test RE 0.832778708548596\n",
      "80 Train Loss 0.4916683 Test MSE 3.062774245156686 Test RE 0.8364992453698997\n",
      "81 Train Loss 0.48508725 Test MSE 3.0842191548236624 Test RE 0.8394226341172238\n",
      "82 Train Loss 0.47851253 Test MSE 3.10211016352777 Test RE 0.8418537845124958\n",
      "83 Train Loss 0.47478375 Test MSE 3.09222195826844 Test RE 0.8405109780271504\n",
      "84 Train Loss 0.47036955 Test MSE 3.109146997704824 Test RE 0.8428080752178614\n",
      "85 Train Loss 0.4601029 Test MSE 3.110103677086885 Test RE 0.8429377305694192\n",
      "86 Train Loss 0.45277742 Test MSE 3.117692622765452 Test RE 0.8439655276687235\n",
      "87 Train Loss 0.44473898 Test MSE 3.1455116834622165 Test RE 0.8477225026776696\n",
      "88 Train Loss 0.44115815 Test MSE 3.1680682127119115 Test RE 0.8507565908049826\n",
      "89 Train Loss 0.43789604 Test MSE 3.164533379582915 Test RE 0.8502818343119727\n",
      "90 Train Loss 0.43171024 Test MSE 3.1747016892049493 Test RE 0.8516468056617957\n",
      "91 Train Loss 0.4247349 Test MSE 3.1926544438850235 Test RE 0.8540514177158932\n",
      "92 Train Loss 0.4209398 Test MSE 3.189439468023718 Test RE 0.8536212981513267\n",
      "93 Train Loss 0.4189793 Test MSE 3.185912653101521 Test RE 0.8531492093912918\n",
      "94 Train Loss 0.416672 Test MSE 3.196610415908097 Test RE 0.8545803753007671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.41341949 Test MSE 3.2088710572354255 Test RE 0.8562176839627464\n",
      "96 Train Loss 0.41055357 Test MSE 3.2158922908025818 Test RE 0.857153904104043\n",
      "97 Train Loss 0.40611222 Test MSE 3.243416534762156 Test RE 0.8608142019155375\n",
      "98 Train Loss 0.40296447 Test MSE 3.2450482686015967 Test RE 0.8610307086499045\n",
      "99 Train Loss 0.4011538 Test MSE 3.2644986008871673 Test RE 0.8636072979152224\n",
      "Training time: 151.49\n",
      "1\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 66.35738 Test MSE 6.070482353353981 Test RE 1.177659285641014\n",
      "1 Train Loss 50.174244 Test MSE 10.15170415146375 Test RE 1.522921565689681\n",
      "2 Train Loss 42.17859 Test MSE 9.187276477371645 Test RE 1.4487767016052946\n",
      "3 Train Loss 37.592514 Test MSE 9.368437933025898 Test RE 1.4629909924976885\n",
      "4 Train Loss 35.121235 Test MSE 9.74953206713923 Test RE 1.4924505360168028\n",
      "5 Train Loss 32.55356 Test MSE 9.718349867493778 Test RE 1.4900619515833495\n",
      "6 Train Loss 28.144295 Test MSE 9.57688988995584 Test RE 1.479177552039701\n",
      "7 Train Loss 25.336575 Test MSE 9.55445379343316 Test RE 1.477443876986123\n",
      "8 Train Loss 23.747084 Test MSE 9.4374805992672 Test RE 1.4683720058943366\n",
      "9 Train Loss 22.387241 Test MSE 9.398392684784751 Test RE 1.4653280180372459\n",
      "10 Train Loss 21.47816 Test MSE 9.538976047037808 Test RE 1.4762466986490628\n",
      "11 Train Loss 20.806091 Test MSE 9.605623772553066 Test RE 1.4813949045359154\n",
      "12 Train Loss 19.981554 Test MSE 9.92710738944908 Test RE 1.5059807489563009\n",
      "13 Train Loss 19.37064 Test MSE 9.703114671616651 Test RE 1.4888935284415696\n",
      "14 Train Loss 18.978111 Test MSE 9.654924263250129 Test RE 1.4851916400085983\n",
      "15 Train Loss 18.55193 Test MSE 9.633314289685819 Test RE 1.4835286061863016\n",
      "16 Train Loss 18.006744 Test MSE 9.684923959903756 Test RE 1.4874972376842635\n",
      "17 Train Loss 17.377071 Test MSE 9.461600134138868 Test RE 1.4702471806132604\n",
      "18 Train Loss 16.827164 Test MSE 9.45610684839597 Test RE 1.4698203151582392\n",
      "19 Train Loss 16.303001 Test MSE 9.310367053076485 Test RE 1.458449721173711\n",
      "20 Train Loss 15.498165 Test MSE 8.977652493849895 Test RE 1.432153127260866\n",
      "21 Train Loss 13.983735 Test MSE 8.272112307906795 Test RE 1.3747263951052746\n",
      "22 Train Loss 13.079245 Test MSE 8.191101502446486 Test RE 1.3679783182857606\n",
      "23 Train Loss 11.915255 Test MSE 8.076627975975711 Test RE 1.358385696057434\n",
      "24 Train Loss 10.824572 Test MSE 7.334292563884002 Test RE 1.2944556493873816\n",
      "25 Train Loss 9.3981 Test MSE 6.718930601174519 Test RE 1.2389624323423312\n",
      "26 Train Loss 8.503664 Test MSE 6.796654194792095 Test RE 1.2461078942657884\n",
      "27 Train Loss 8.165735 Test MSE 6.683275255415504 Test RE 1.235670658750758\n",
      "28 Train Loss 7.8410854 Test MSE 6.633609233549883 Test RE 1.231070721825744\n",
      "29 Train Loss 7.550607 Test MSE 6.676848366154962 Test RE 1.2350763821186364\n",
      "30 Train Loss 7.345479 Test MSE 6.648381808178109 Test RE 1.2324407128781814\n",
      "31 Train Loss 7.1110473 Test MSE 6.653039382306865 Test RE 1.2328723351258792\n",
      "32 Train Loss 6.8377137 Test MSE 6.620090287360396 Test RE 1.2298156534168727\n",
      "33 Train Loss 6.667837 Test MSE 6.550318254764362 Test RE 1.2233177038303606\n",
      "34 Train Loss 6.5366106 Test MSE 6.602237256169286 Test RE 1.2281562530968557\n",
      "35 Train Loss 6.3894577 Test MSE 6.575670481026408 Test RE 1.2256827703137625\n",
      "36 Train Loss 6.2445145 Test MSE 6.533846167880934 Test RE 1.2217785969618422\n",
      "37 Train Loss 6.0539484 Test MSE 6.478136938315103 Test RE 1.216558849827092\n",
      "38 Train Loss 5.96914 Test MSE 6.368002804667769 Test RE 1.2061732240058114\n",
      "39 Train Loss 5.816702 Test MSE 6.3313335659006285 Test RE 1.2026954216597654\n",
      "40 Train Loss 5.667812 Test MSE 6.271707535274381 Test RE 1.1970187666674035\n",
      "41 Train Loss 4.9106755 Test MSE 5.419434689084339 Test RE 1.1127178467795935\n",
      "42 Train Loss 4.274452 Test MSE 5.18121849252223 Test RE 1.0879877705627077\n",
      "43 Train Loss 3.665355 Test MSE 5.452354263539145 Test RE 1.116092252247765\n",
      "44 Train Loss 3.290455 Test MSE 5.505417372990874 Test RE 1.1215100889193608\n",
      "45 Train Loss 3.013491 Test MSE 5.451515781046604 Test RE 1.1160064306237762\n",
      "46 Train Loss 2.8545327 Test MSE 5.420850443615425 Test RE 1.1128631785857144\n",
      "47 Train Loss 2.6677196 Test MSE 5.464119723771433 Test RE 1.1172957931480894\n",
      "48 Train Loss 2.5631413 Test MSE 5.475290813120883 Test RE 1.1184373345939684\n",
      "49 Train Loss 2.4535818 Test MSE 5.441189408682837 Test RE 1.1149489485407198\n",
      "50 Train Loss 2.350462 Test MSE 5.421973561947257 Test RE 1.112978456835639\n",
      "51 Train Loss 2.260445 Test MSE 5.452255967195239 Test RE 1.116082191613677\n",
      "52 Train Loss 2.2088253 Test MSE 5.499687344604978 Test RE 1.1209263041491817\n",
      "53 Train Loss 2.139141 Test MSE 5.518779330828883 Test RE 1.1228702481788815\n",
      "54 Train Loss 2.0836012 Test MSE 5.602783428376756 Test RE 1.131383857592497\n",
      "55 Train Loss 2.0327945 Test MSE 5.614996376579346 Test RE 1.132616281704311\n",
      "56 Train Loss 1.9747845 Test MSE 5.603280918951968 Test RE 1.131434086226125\n",
      "57 Train Loss 1.9443684 Test MSE 5.596185044671887 Test RE 1.1307174473904817\n",
      "58 Train Loss 1.911903 Test MSE 5.6327578852155975 Test RE 1.1344062285710097\n",
      "59 Train Loss 1.8808429 Test MSE 5.633745871452715 Test RE 1.1345057116858663\n",
      "60 Train Loss 1.8497045 Test MSE 5.664063391351584 Test RE 1.1375542384026438\n",
      "61 Train Loss 1.7977309 Test MSE 5.602401215267491 Test RE 1.131345266317046\n",
      "62 Train Loss 1.7652594 Test MSE 5.632664982737915 Test RE 1.1343968735103067\n",
      "63 Train Loss 1.7325469 Test MSE 5.63445866929248 Test RE 1.1345774798896198\n",
      "64 Train Loss 1.7074457 Test MSE 5.6503172221749445 Test RE 1.1361730292899066\n",
      "65 Train Loss 1.6738786 Test MSE 5.622519408108946 Test RE 1.1333747733669581\n",
      "66 Train Loss 1.6559536 Test MSE 5.625091650967672 Test RE 1.1336339971775224\n",
      "67 Train Loss 1.6156982 Test MSE 5.663566976104364 Test RE 1.1375043880034705\n",
      "68 Train Loss 1.5803686 Test MSE 5.647319714212759 Test RE 1.1358716179381911\n",
      "69 Train Loss 1.5431924 Test MSE 5.667168466802444 Test RE 1.1378660029024241\n",
      "70 Train Loss 1.5268643 Test MSE 5.692055071352998 Test RE 1.1403616584694665\n",
      "71 Train Loss 1.5063155 Test MSE 5.742019675622085 Test RE 1.145355744709202\n",
      "72 Train Loss 1.4855386 Test MSE 5.778286759213137 Test RE 1.148967133270445\n",
      "73 Train Loss 1.4582552 Test MSE 5.799177760280779 Test RE 1.151042265430684\n",
      "74 Train Loss 1.4404677 Test MSE 5.813326080755814 Test RE 1.1524455155771078\n",
      "75 Train Loss 1.4209151 Test MSE 5.811088563942168 Test RE 1.1522237093035896\n",
      "76 Train Loss 1.4105953 Test MSE 5.78836563693781 Test RE 1.1499687496960984\n",
      "77 Train Loss 1.3854963 Test MSE 5.819473214200721 Test RE 1.1530546646690523\n",
      "78 Train Loss 1.3676268 Test MSE 5.828024714021703 Test RE 1.1539015391799698\n",
      "79 Train Loss 1.3426843 Test MSE 5.8566002665656285 Test RE 1.1567269436947174\n",
      "80 Train Loss 1.3164912 Test MSE 5.864090730079085 Test RE 1.157466421543775\n",
      "81 Train Loss 1.3047014 Test MSE 5.841435914186855 Test RE 1.1552284306038498\n",
      "82 Train Loss 1.2878648 Test MSE 5.828530157019864 Test RE 1.153951574898531\n",
      "83 Train Loss 1.2633429 Test MSE 5.851562110352009 Test RE 1.1562292979060467\n",
      "84 Train Loss 1.2506316 Test MSE 5.877697717535782 Test RE 1.1588085311785248\n",
      "85 Train Loss 1.2387967 Test MSE 5.869059871148158 Test RE 1.157956727394635\n",
      "86 Train Loss 1.2246711 Test MSE 5.860475628080326 Test RE 1.1571095883653457\n",
      "87 Train Loss 1.216935 Test MSE 5.854112737620281 Test RE 1.156481263844322\n",
      "88 Train Loss 1.2034664 Test MSE 5.838623646191515 Test RE 1.154950313792589\n",
      "89 Train Loss 1.1958128 Test MSE 5.837059452713372 Test RE 1.1547955952432465\n",
      "90 Train Loss 1.1868018 Test MSE 5.8252695727397095 Test RE 1.1536287591438374\n",
      "91 Train Loss 1.1764605 Test MSE 5.808596027536563 Test RE 1.1519765725113182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 1.1718007 Test MSE 5.809051123861304 Test RE 1.1520216995982653\n",
      "93 Train Loss 1.1657801 Test MSE 5.78808997321336 Test RE 1.1499413664533356\n",
      "94 Train Loss 1.1550634 Test MSE 5.7804076340160115 Test RE 1.1491779736095755\n",
      "95 Train Loss 1.1465224 Test MSE 5.7906485639176335 Test RE 1.1501955007383413\n",
      "96 Train Loss 1.1434643 Test MSE 5.814754958860942 Test RE 1.1525871387173547\n",
      "97 Train Loss 1.1396877 Test MSE 5.806817783056222 Test RE 1.1518002258711348\n",
      "98 Train Loss 1.1340997 Test MSE 5.820095974094685 Test RE 1.15311635899811\n",
      "99 Train Loss 1.1288033 Test MSE 5.822990695299046 Test RE 1.153403084118047\n",
      "Training time: 151.35\n",
      "2\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 62.655457 Test MSE 6.301505448606287 Test RE 1.1998590134977416\n",
      "1 Train Loss 43.609074 Test MSE 8.662805725624061 Test RE 1.4068161578881009\n",
      "2 Train Loss 31.239332 Test MSE 6.748490324133287 Test RE 1.241684829397339\n",
      "3 Train Loss 23.19918 Test MSE 5.575812970021262 Test RE 1.1286574670439695\n",
      "4 Train Loss 17.737698 Test MSE 5.592696988939164 Test RE 1.1303650090596324\n",
      "5 Train Loss 14.346069 Test MSE 5.546560285745148 Test RE 1.1256929057839893\n",
      "6 Train Loss 12.111589 Test MSE 5.720126384501726 Test RE 1.143170141380824\n",
      "7 Train Loss 11.039407 Test MSE 5.510809564572857 Test RE 1.122059176919364\n",
      "8 Train Loss 10.180018 Test MSE 5.575686309683924 Test RE 1.1286446476624599\n",
      "9 Train Loss 9.119865 Test MSE 5.418512517985939 Test RE 1.1126231727081688\n",
      "10 Train Loss 8.647562 Test MSE 5.511094019408214 Test RE 1.122088135553847\n",
      "11 Train Loss 8.163661 Test MSE 5.405782338952603 Test RE 1.111315413333388\n",
      "12 Train Loss 7.8802032 Test MSE 5.29215940531723 Test RE 1.0995741434603457\n",
      "13 Train Loss 7.620989 Test MSE 5.2502402408445334 Test RE 1.0952106251701408\n",
      "14 Train Loss 7.381398 Test MSE 5.15203210063687 Test RE 1.084919063561575\n",
      "15 Train Loss 7.1445103 Test MSE 5.087523829974954 Test RE 1.0781055667775683\n",
      "16 Train Loss 6.9703283 Test MSE 5.035430411005497 Test RE 1.0725717633884047\n",
      "17 Train Loss 6.808483 Test MSE 5.085072632040201 Test RE 1.0778458167877176\n",
      "18 Train Loss 6.5870094 Test MSE 5.017911231788285 Test RE 1.0707043014373452\n",
      "19 Train Loss 6.4461184 Test MSE 4.931581690022775 Test RE 1.0614539951776307\n",
      "20 Train Loss 6.1514053 Test MSE 4.960986412031173 Test RE 1.0646137697194726\n",
      "21 Train Loss 5.9650593 Test MSE 4.790783550190752 Test RE 1.0461918563502235\n",
      "22 Train Loss 5.7322392 Test MSE 4.766992019420021 Test RE 1.0435908742077387\n",
      "23 Train Loss 5.4002085 Test MSE 4.5120139399850965 Test RE 1.0152974061193205\n",
      "24 Train Loss 4.8797355 Test MSE 4.390965612551029 Test RE 1.0015856145259976\n",
      "25 Train Loss 4.457675 Test MSE 4.131329369201754 Test RE 0.9715227401687759\n",
      "26 Train Loss 4.220967 Test MSE 4.149217305165349 Test RE 0.9736237304456214\n",
      "27 Train Loss 3.9747074 Test MSE 4.003814985843686 Test RE 0.9564120971888048\n",
      "28 Train Loss 3.5911882 Test MSE 3.946348444870136 Test RE 0.9495236247112557\n",
      "29 Train Loss 3.4219701 Test MSE 4.000617916645456 Test RE 0.9560301706621993\n",
      "30 Train Loss 3.2057064 Test MSE 3.970025833124237 Test RE 0.9523678512487462\n",
      "31 Train Loss 3.1070535 Test MSE 3.919138786447239 Test RE 0.9462445298030374\n",
      "32 Train Loss 2.9400358 Test MSE 3.7969747899647275 Test RE 0.9313800198056773\n",
      "33 Train Loss 2.75183 Test MSE 3.6102220613219713 Test RE 0.9081864503261757\n",
      "34 Train Loss 2.6626062 Test MSE 3.4209705393253147 Test RE 0.8840620078198751\n",
      "35 Train Loss 2.4863987 Test MSE 3.1959077076812834 Test RE 0.854486439289074\n",
      "36 Train Loss 2.3656337 Test MSE 2.847844168892697 Test RE 0.8066147715994634\n",
      "37 Train Loss 2.273076 Test MSE 2.667805220536008 Test RE 0.7807016896849533\n",
      "38 Train Loss 2.0786908 Test MSE 2.316010371603329 Test RE 0.7274083972017672\n",
      "39 Train Loss 2.013413 Test MSE 2.185652976022417 Test RE 0.7066407275521526\n",
      "40 Train Loss 1.9339883 Test MSE 2.176415097591026 Test RE 0.705145802812136\n",
      "41 Train Loss 1.8770417 Test MSE 2.2074908559213373 Test RE 0.7101621421957951\n",
      "42 Train Loss 1.797335 Test MSE 2.1298835417953814 Test RE 0.6975670995601242\n",
      "43 Train Loss 1.7106451 Test MSE 2.0047178316328638 Test RE 0.6767600081269917\n",
      "44 Train Loss 1.6478318 Test MSE 1.827790914110681 Test RE 0.6462064928616579\n",
      "45 Train Loss 1.5395228 Test MSE 1.6017205835961812 Test RE 0.6049248683353591\n",
      "46 Train Loss 1.4528432 Test MSE 1.4401441427162387 Test RE 0.5736025079029676\n",
      "47 Train Loss 1.400586 Test MSE 1.3839764158788852 Test RE 0.5623055952503474\n",
      "48 Train Loss 1.2999512 Test MSE 1.1380835873860289 Test RE 0.5099118918508126\n",
      "49 Train Loss 1.1780869 Test MSE 1.0194932668979824 Test RE 0.4826143613297224\n",
      "50 Train Loss 1.0851734 Test MSE 0.9704273753070995 Test RE 0.47085759486399137\n",
      "51 Train Loss 0.9882158 Test MSE 0.8627766894172543 Test RE 0.44397371780598865\n",
      "52 Train Loss 0.8853395 Test MSE 0.6610832317062098 Test RE 0.388629828567819\n",
      "53 Train Loss 0.8086602 Test MSE 0.5565834138572603 Test RE 0.35659330936761396\n",
      "54 Train Loss 0.7531929 Test MSE 0.5500354047848133 Test RE 0.3544895056898861\n",
      "55 Train Loss 0.70633835 Test MSE 0.547545948739455 Test RE 0.35368638753364634\n",
      "56 Train Loss 0.6332474 Test MSE 0.4656223773625982 Test RE 0.32615570709408837\n",
      "57 Train Loss 0.56900847 Test MSE 0.4328106132985057 Test RE 0.3144539186964829\n",
      "58 Train Loss 0.52554995 Test MSE 0.38901303777334084 Test RE 0.29811933153684694\n",
      "59 Train Loss 0.477217 Test MSE 0.37150907305721514 Test RE 0.2913350739042985\n",
      "60 Train Loss 0.4419766 Test MSE 0.3418472487613964 Test RE 0.2794628635364817\n",
      "61 Train Loss 0.4081767 Test MSE 0.28203297178538367 Test RE 0.2538387977014315\n",
      "62 Train Loss 0.37203628 Test MSE 0.2284737138224553 Test RE 0.22846842135569223\n",
      "63 Train Loss 0.3429453 Test MSE 0.21951816157118148 Test RE 0.22394598917464428\n",
      "64 Train Loss 0.32704532 Test MSE 0.2170120405390238 Test RE 0.2226639840987347\n",
      "65 Train Loss 0.294272 Test MSE 0.1891468126569827 Test RE 0.20787754246712467\n",
      "66 Train Loss 0.26476786 Test MSE 0.19505070934901975 Test RE 0.21109688622477316\n",
      "67 Train Loss 0.2544448 Test MSE 0.183864149075025 Test RE 0.20495408951938945\n",
      "68 Train Loss 0.24265245 Test MSE 0.17031328939560406 Test RE 0.19725695680397504\n",
      "69 Train Loss 0.237244 Test MSE 0.17804112360845065 Test RE 0.20168250343625393\n",
      "70 Train Loss 0.22978686 Test MSE 0.1784241857900823 Test RE 0.20189935061048633\n",
      "71 Train Loss 0.2136026 Test MSE 0.159112835919856 Test RE 0.19066047403735223\n",
      "72 Train Loss 0.20623644 Test MSE 0.13516631017293304 Test RE 0.17572853541485733\n",
      "73 Train Loss 0.18194538 Test MSE 0.07112634646075926 Test RE 0.12747449810680936\n",
      "74 Train Loss 0.1702576 Test MSE 0.05038141075050858 Test RE 0.10728604170196668\n",
      "75 Train Loss 0.16584687 Test MSE 0.05164309697612094 Test RE 0.1086211007447921\n",
      "76 Train Loss 0.1538143 Test MSE 0.040073401210190644 Test RE 0.09568330382367882\n",
      "77 Train Loss 0.1458862 Test MSE 0.03869058394441401 Test RE 0.09401793377448765\n",
      "78 Train Loss 0.1359122 Test MSE 0.04568013232409293 Test RE 0.10215784827619866\n",
      "79 Train Loss 0.13110931 Test MSE 0.04568484083728768 Test RE 0.10216311313815915\n",
      "80 Train Loss 0.119046174 Test MSE 0.038611969262681234 Test RE 0.0939223685553608\n",
      "81 Train Loss 0.1132741 Test MSE 0.03778162619736651 Test RE 0.0929069886509847\n",
      "82 Train Loss 0.107454315 Test MSE 0.03287915412296988 Test RE 0.08666991652347382\n",
      "83 Train Loss 0.10141838 Test MSE 0.032910334127363036 Test RE 0.08671100225203357\n",
      "84 Train Loss 0.09644771 Test MSE 0.031073206979823416 Test RE 0.08425605079181703\n",
      "85 Train Loss 0.08994332 Test MSE 0.029680708090858536 Test RE 0.0823465083759795\n",
      "86 Train Loss 0.08281549 Test MSE 0.027375792388385223 Test RE 0.07908450662563692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 0.08010695 Test MSE 0.029547684821719225 Test RE 0.08216177048613517\n",
      "88 Train Loss 0.07818073 Test MSE 0.028799720953864252 Test RE 0.0811151919419454\n",
      "89 Train Loss 0.07257319 Test MSE 0.027784354348494685 Test RE 0.07967245780081157\n",
      "90 Train Loss 0.06910195 Test MSE 0.027774404207792945 Test RE 0.07965819036196636\n",
      "91 Train Loss 0.06636869 Test MSE 0.022998215355765912 Test RE 0.07248616586535123\n",
      "92 Train Loss 0.06137043 Test MSE 0.019989397689246294 Test RE 0.06757840145446607\n",
      "93 Train Loss 0.058558077 Test MSE 0.016751733641954265 Test RE 0.061863991822452905\n",
      "94 Train Loss 0.056446355 Test MSE 0.016589937787587435 Test RE 0.06156451166913275\n",
      "95 Train Loss 0.054745205 Test MSE 0.0156750048463971 Test RE 0.05984279952073364\n",
      "96 Train Loss 0.052972145 Test MSE 0.015418795138171138 Test RE 0.0593517159217346\n",
      "97 Train Loss 0.04933468 Test MSE 0.01553585089583451 Test RE 0.059576581871729394\n",
      "98 Train Loss 0.04720313 Test MSE 0.014461935924751888 Test RE 0.05748059788252916\n",
      "99 Train Loss 0.04450359 Test MSE 0.015370770908988323 Test RE 0.05925921377462591\n",
      "Training time: 151.06\n",
      "3\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 69.31077 Test MSE 5.167695287146795 Test RE 1.0865669952099934\n",
      "1 Train Loss 64.95873 Test MSE 5.605253453350118 Test RE 1.13163321922566\n",
      "2 Train Loss 46.23635 Test MSE 8.656051805286438 Test RE 1.4062676417814675\n",
      "3 Train Loss 40.001972 Test MSE 8.717982616463129 Test RE 1.4112893350497824\n",
      "4 Train Loss 34.85646 Test MSE 8.882882106880187 Test RE 1.4245739857158508\n",
      "5 Train Loss 31.645798 Test MSE 8.907578079978963 Test RE 1.4265528942406858\n",
      "6 Train Loss 29.19366 Test MSE 8.698778761625416 Test RE 1.409734093529681\n",
      "7 Train Loss 26.686186 Test MSE 8.518081292497834 Test RE 1.395015234776524\n",
      "8 Train Loss 24.470669 Test MSE 8.587128363132368 Test RE 1.4006577794253836\n",
      "9 Train Loss 22.273113 Test MSE 8.856422660970278 Test RE 1.4224507137239788\n",
      "10 Train Loss 20.563953 Test MSE 8.81664705020077 Test RE 1.4192528923624252\n",
      "11 Train Loss 19.110785 Test MSE 8.232471857217286 Test RE 1.371428554463991\n",
      "12 Train Loss 18.095264 Test MSE 8.168082148444803 Test RE 1.3660547593917634\n",
      "13 Train Loss 16.79133 Test MSE 8.140437103091951 Test RE 1.3637410795652924\n",
      "14 Train Loss 15.047632 Test MSE 8.263366670015557 Test RE 1.373999492576802\n",
      "15 Train Loss 12.367157 Test MSE 7.20514417196063 Test RE 1.2830080991581023\n",
      "16 Train Loss 11.298103 Test MSE 6.890975261936128 Test RE 1.2547245794527773\n",
      "17 Train Loss 10.212919 Test MSE 6.696598807515285 Test RE 1.2369017411661274\n",
      "18 Train Loss 9.437946 Test MSE 6.583226018282356 Test RE 1.2263867314704922\n",
      "19 Train Loss 8.893679 Test MSE 6.434294411513444 Test RE 1.2124351670236797\n",
      "20 Train Loss 8.265518 Test MSE 6.5213838726742885 Test RE 1.2206128645219465\n",
      "21 Train Loss 7.992647 Test MSE 6.57121339428931 Test RE 1.2252673069423614\n",
      "22 Train Loss 7.7975783 Test MSE 6.4648156691003775 Test RE 1.2153073752123027\n",
      "23 Train Loss 7.6296883 Test MSE 6.399211288592823 Test RE 1.2091252351174369\n",
      "24 Train Loss 7.449134 Test MSE 6.361338416499068 Test RE 1.205541902770121\n",
      "25 Train Loss 7.224776 Test MSE 6.437206242676475 Test RE 1.212709478933185\n",
      "26 Train Loss 7.0657034 Test MSE 6.359941109835703 Test RE 1.2054094931939532\n",
      "27 Train Loss 6.9270754 Test MSE 6.428138474905033 Test RE 1.211855036584898\n",
      "28 Train Loss 6.778429 Test MSE 6.4501004068103205 Test RE 1.2139234413167925\n",
      "29 Train Loss 6.636723 Test MSE 6.394076704127568 Test RE 1.2086400502071288\n",
      "30 Train Loss 6.521704 Test MSE 6.409873268178422 Test RE 1.2101321016382385\n",
      "31 Train Loss 6.3973627 Test MSE 6.323925682368106 Test RE 1.2019916177037877\n",
      "32 Train Loss 6.2753115 Test MSE 6.339370997016196 Test RE 1.2034585717602575\n",
      "33 Train Loss 6.135991 Test MSE 6.391465585050583 Test RE 1.2083932416767895\n",
      "34 Train Loss 5.81567 Test MSE 6.458469957685797 Test RE 1.2147107701670534\n",
      "35 Train Loss 5.663053 Test MSE 6.660603367766559 Test RE 1.2335729757515999\n",
      "36 Train Loss 5.292817 Test MSE 6.593709902949191 Test RE 1.2273628624909825\n",
      "37 Train Loss 5.0171514 Test MSE 6.4360896399748295 Test RE 1.2126042956163883\n",
      "38 Train Loss 4.814142 Test MSE 6.419080031004754 Test RE 1.211000870874481\n",
      "39 Train Loss 4.436121 Test MSE 6.218634093251242 Test RE 1.1919432046544556\n",
      "40 Train Loss 3.7798274 Test MSE 5.787066079326841 Test RE 1.149839651551239\n",
      "41 Train Loss 3.2773163 Test MSE 5.627941143675498 Test RE 1.1339210923061669\n",
      "42 Train Loss 2.8459637 Test MSE 5.7022404763918395 Test RE 1.1413814882030702\n",
      "43 Train Loss 2.5875125 Test MSE 5.809047570749233 Test RE 1.1520213472805854\n",
      "44 Train Loss 2.3916762 Test MSE 5.822000444561178 Test RE 1.1533050067830897\n",
      "45 Train Loss 2.2378561 Test MSE 5.819003847036143 Test RE 1.1530081641618959\n",
      "46 Train Loss 2.1081023 Test MSE 5.8564005776881 Test RE 1.1567072234249827\n",
      "47 Train Loss 2.0081956 Test MSE 5.871505095790392 Test RE 1.1581979218559293\n",
      "48 Train Loss 1.9362164 Test MSE 5.853888499054682 Test RE 1.156459114443143\n",
      "49 Train Loss 1.8678563 Test MSE 5.775896888009615 Test RE 1.1487295050979636\n",
      "50 Train Loss 1.7786185 Test MSE 5.85756701034645 Test RE 1.1568224096975477\n",
      "51 Train Loss 1.7477633 Test MSE 5.831998572317483 Test RE 1.1542948679702276\n",
      "52 Train Loss 1.6804329 Test MSE 5.874569570136642 Test RE 1.1585001275741462\n",
      "53 Train Loss 1.639931 Test MSE 5.9296042756717195 Test RE 1.1639140632452574\n",
      "54 Train Loss 1.596601 Test MSE 5.900924115597289 Test RE 1.161095856296512\n",
      "55 Train Loss 1.5545168 Test MSE 5.878477302959066 Test RE 1.1588853776181949\n",
      "56 Train Loss 1.497571 Test MSE 5.820321341780429 Test RE 1.1531386844589513\n",
      "57 Train Loss 1.465623 Test MSE 5.817714434193812 Test RE 1.1528804115481532\n",
      "58 Train Loss 1.423489 Test MSE 5.8067748516061535 Test RE 1.1517959680704661\n",
      "59 Train Loss 1.3981695 Test MSE 5.802850515894094 Test RE 1.1514066988025187\n",
      "60 Train Loss 1.3674035 Test MSE 5.783540511765276 Test RE 1.1494893483990265\n",
      "61 Train Loss 1.3427424 Test MSE 5.717191933481458 Test RE 1.142876878006827\n",
      "62 Train Loss 1.3228184 Test MSE 5.7305170060222625 Test RE 1.1442079557709817\n",
      "63 Train Loss 1.3035848 Test MSE 5.718711421849877 Test RE 1.143028742136337\n",
      "64 Train Loss 1.290711 Test MSE 5.7282536107047655 Test RE 1.1439819682465207\n",
      "65 Train Loss 1.2747275 Test MSE 5.721092379648672 Test RE 1.1432666646143996\n",
      "66 Train Loss 1.258564 Test MSE 5.727615521335769 Test RE 1.1439182504791825\n",
      "67 Train Loss 1.246678 Test MSE 5.7490984193382815 Test RE 1.1460615227278346\n",
      "68 Train Loss 1.2361362 Test MSE 5.748492680804602 Test RE 1.146001145268396\n",
      "69 Train Loss 1.2282331 Test MSE 5.75015230060919 Test RE 1.1461665615825654\n",
      "70 Train Loss 1.2144122 Test MSE 5.780411523688972 Test RE 1.1491783602540844\n",
      "71 Train Loss 1.2063707 Test MSE 5.792809260779686 Test RE 1.1504100701422397\n",
      "72 Train Loss 1.1945508 Test MSE 5.779169168528689 Test RE 1.149054860017138\n",
      "73 Train Loss 1.18703 Test MSE 5.773435483732888 Test RE 1.1484847128977338\n",
      "74 Train Loss 1.1762042 Test MSE 5.786067557201668 Test RE 1.1497404484449396\n",
      "75 Train Loss 1.1687691 Test MSE 5.807575753602025 Test RE 1.151875396316542\n",
      "76 Train Loss 1.1617359 Test MSE 5.82057322623275 Test RE 1.153163636222478\n",
      "77 Train Loss 1.1549352 Test MSE 5.810093662840143 Test RE 1.1521250704947352\n",
      "78 Train Loss 1.1485436 Test MSE 5.808656321692151 Test RE 1.1519825513463176\n",
      "79 Train Loss 1.143652 Test MSE 5.8020434373311005 Test RE 1.1513266253993497\n",
      "80 Train Loss 1.1327477 Test MSE 5.805526491179217 Test RE 1.15167215288645\n",
      "81 Train Loss 1.1269774 Test MSE 5.809350156493613 Test RE 1.15205135053787\n",
      "82 Train Loss 1.1189293 Test MSE 5.79947753392034 Test RE 1.1510720151369724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 Train Loss 1.1117057 Test MSE 5.797116637471912 Test RE 1.1508376976105754\n",
      "84 Train Loss 1.1065297 Test MSE 5.798239420161028 Test RE 1.150949139053488\n",
      "85 Train Loss 1.0990896 Test MSE 5.813451820754583 Test RE 1.1524579789855014\n",
      "86 Train Loss 1.0920643 Test MSE 5.817073660942329 Test RE 1.1528169196665263\n",
      "87 Train Loss 1.0872176 Test MSE 5.80729070345896 Test RE 1.1518471275268174\n",
      "88 Train Loss 1.0824205 Test MSE 5.819193264872369 Test RE 1.1530269301345653\n",
      "89 Train Loss 1.0787164 Test MSE 5.8113158312889075 Test RE 1.1522462403889553\n",
      "90 Train Loss 1.0737543 Test MSE 5.817360096291341 Test RE 1.152845301931492\n",
      "91 Train Loss 1.0693938 Test MSE 5.805729557025478 Test RE 1.1516922943185568\n",
      "92 Train Loss 1.063195 Test MSE 5.8038674703233 Test RE 1.1515075868782945\n",
      "93 Train Loss 1.0578734 Test MSE 5.794127245726283 Test RE 1.1505409338435388\n",
      "94 Train Loss 1.0548168 Test MSE 5.791562854938921 Test RE 1.1502862998863688\n",
      "95 Train Loss 1.0509996 Test MSE 5.802474423934605 Test RE 1.1513693859493799\n",
      "96 Train Loss 1.0468906 Test MSE 5.817827987206625 Test RE 1.1528916627368138\n",
      "97 Train Loss 1.0398822 Test MSE 5.806981424554096 Test RE 1.1518164551548302\n",
      "98 Train Loss 1.0371035 Test MSE 5.799589009664238 Test RE 1.1510830778570025\n",
      "99 Train Loss 1.0342792 Test MSE 5.8013000028471415 Test RE 1.1512528614448843\n",
      "Training time: 153.69\n",
      "4\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 58.642776 Test MSE 6.684244184362655 Test RE 1.2357602281335116\n",
      "1 Train Loss 47.160774 Test MSE 7.430035087136777 Test RE 1.3028772254793222\n",
      "2 Train Loss 38.20687 Test MSE 7.249222489874536 Test RE 1.2869265918992674\n",
      "3 Train Loss 31.656626 Test MSE 6.290421077757222 Test RE 1.1988032708599325\n",
      "4 Train Loss 27.403595 Test MSE 5.4666980073915505 Test RE 1.1175593640293784\n",
      "5 Train Loss 23.193235 Test MSE 5.5718980934864 Test RE 1.128261172322818\n",
      "6 Train Loss 19.15894 Test MSE 6.030182527610121 Test RE 1.1737437406727422\n",
      "7 Train Loss 16.822472 Test MSE 5.894373714492436 Test RE 1.1604512322265998\n",
      "8 Train Loss 14.960578 Test MSE 6.014623356138253 Test RE 1.17222850663561\n",
      "9 Train Loss 13.9848795 Test MSE 5.949723481975925 Test RE 1.1658869771318199\n",
      "10 Train Loss 13.135607 Test MSE 5.868394709286953 Test RE 1.1578911078155765\n",
      "11 Train Loss 12.163944 Test MSE 5.823837691168412 Test RE 1.15348696645415\n",
      "12 Train Loss 11.311792 Test MSE 5.841426863320715 Test RE 1.1552275356336672\n",
      "13 Train Loss 10.643995 Test MSE 5.693073953126928 Test RE 1.1404637166632685\n",
      "14 Train Loss 9.598692 Test MSE 5.382017797579879 Test RE 1.1088699772429687\n",
      "15 Train Loss 9.22995 Test MSE 5.2924460841666905 Test RE 1.0996039252901568\n",
      "16 Train Loss 8.520151 Test MSE 5.1481180892482525 Test RE 1.084506877428859\n",
      "17 Train Loss 6.9623394 Test MSE 4.623638270707197 Test RE 1.0277795808164354\n",
      "18 Train Loss 5.7801313 Test MSE 4.085580604366113 Test RE 0.9661286294807151\n",
      "19 Train Loss 4.6831665 Test MSE 3.7743699660862773 Test RE 0.9286034527715258\n",
      "20 Train Loss 4.0497103 Test MSE 3.4225219214153775 Test RE 0.8842624425345101\n",
      "21 Train Loss 3.7377472 Test MSE 3.52255928552136 Test RE 0.897092479345812\n",
      "22 Train Loss 3.4892423 Test MSE 3.451854649300382 Test RE 0.8880436442383616\n",
      "23 Train Loss 3.1737278 Test MSE 3.418138778550389 Test RE 0.8836960341334901\n",
      "24 Train Loss 2.9526677 Test MSE 3.274925786000351 Test RE 0.8649854289814204\n",
      "25 Train Loss 2.8083434 Test MSE 3.147619336474967 Test RE 0.848006463742025\n",
      "26 Train Loss 2.686014 Test MSE 3.0863965981388324 Test RE 0.8397188959296605\n",
      "27 Train Loss 2.3746922 Test MSE 2.794246222517956 Test RE 0.7989882572510624\n",
      "28 Train Loss 2.1693163 Test MSE 2.567588500456945 Test RE 0.7658977104211803\n",
      "29 Train Loss 1.9237794 Test MSE 2.177072884874024 Test RE 0.7052523543842086\n",
      "30 Train Loss 1.871456 Test MSE 2.059472053979793 Test RE 0.6859398148263579\n",
      "31 Train Loss 1.7448418 Test MSE 2.014956027184267 Test RE 0.6784859311667055\n",
      "32 Train Loss 1.6223488 Test MSE 1.9087507049561305 Test RE 0.6603628991374619\n",
      "33 Train Loss 1.4883771 Test MSE 1.8298873710115988 Test RE 0.646576982671039\n",
      "34 Train Loss 1.3959259 Test MSE 1.6848023947344455 Test RE 0.6204153664015294\n",
      "35 Train Loss 1.2764009 Test MSE 1.5822699429013136 Test RE 0.6012406690304001\n",
      "36 Train Loss 1.1969732 Test MSE 1.4929659740924508 Test RE 0.5840271209018487\n",
      "37 Train Loss 1.1110983 Test MSE 1.3992579791550435 Test RE 0.5654015000087161\n",
      "38 Train Loss 1.0362123 Test MSE 1.300910027677063 Test RE 0.54516967586759\n",
      "39 Train Loss 0.9622268 Test MSE 1.2103364993890715 Test RE 0.525849088434395\n",
      "40 Train Loss 0.8962737 Test MSE 1.1132783665335468 Test RE 0.504324358998348\n",
      "41 Train Loss 0.83931696 Test MSE 1.086073042925387 Test RE 0.4981241268216222\n",
      "42 Train Loss 0.7589466 Test MSE 0.8510990721094237 Test RE 0.44095890637668883\n",
      "43 Train Loss 0.73660177 Test MSE 0.8128407959856432 Test RE 0.43093404557901843\n",
      "44 Train Loss 0.62638396 Test MSE 0.5363874410344222 Test RE 0.35006392722074264\n",
      "45 Train Loss 0.571697 Test MSE 0.46046854637413415 Test RE 0.32434562570816905\n",
      "46 Train Loss 0.51711065 Test MSE 0.3865154123760684 Test RE 0.2971607654496417\n",
      "47 Train Loss 0.46925038 Test MSE 0.3518465620099085 Test RE 0.28352066324825725\n",
      "48 Train Loss 0.4532752 Test MSE 0.33424134215098067 Test RE 0.2763364305929009\n",
      "49 Train Loss 0.41675538 Test MSE 0.29107366193720496 Test RE 0.25787516278039857\n",
      "50 Train Loss 0.36061996 Test MSE 0.19603863477349628 Test RE 0.21163081039277037\n",
      "51 Train Loss 0.3221951 Test MSE 0.14479155674661 Test RE 0.18187779443566074\n",
      "52 Train Loss 0.27875155 Test MSE 0.10093136800331447 Test RE 0.15185221812489627\n",
      "53 Train Loss 0.22705811 Test MSE 0.07880792087140422 Test RE 0.13418160899755888\n",
      "54 Train Loss 0.19543894 Test MSE 0.05575257584408247 Test RE 0.11286012549962682\n",
      "55 Train Loss 0.17205222 Test MSE 0.04696422703974847 Test RE 0.10358375481275366\n",
      "56 Train Loss 0.16120856 Test MSE 0.04032133337154528 Test RE 0.09597884135568685\n",
      "57 Train Loss 0.14791206 Test MSE 0.03468147026265464 Test RE 0.08901369116560817\n",
      "58 Train Loss 0.13539523 Test MSE 0.02759319720377989 Test RE 0.07939791037935225\n",
      "59 Train Loss 0.12595102 Test MSE 0.023572895176506885 Test RE 0.07338622072218651\n",
      "60 Train Loss 0.11735983 Test MSE 0.020097308045990515 Test RE 0.06776056287321935\n",
      "61 Train Loss 0.1056635 Test MSE 0.019642351313558393 Test RE 0.06698920093745865\n",
      "62 Train Loss 0.09734912 Test MSE 0.02101315841270187 Test RE 0.06928731428898614\n",
      "63 Train Loss 0.087174445 Test MSE 0.020887851478557106 Test RE 0.06908041623440896\n",
      "64 Train Loss 0.07703159 Test MSE 0.018646769198034263 Test RE 0.0652694357026216\n",
      "65 Train Loss 0.073541045 Test MSE 0.01797193576165151 Test RE 0.0640774896395064\n",
      "66 Train Loss 0.071544155 Test MSE 0.01747908718275129 Test RE 0.06319277609059933\n",
      "67 Train Loss 0.06806218 Test MSE 0.015608566071132568 Test RE 0.05971584248751827\n",
      "68 Train Loss 0.06407112 Test MSE 0.015293456543909005 Test RE 0.05910999014907085\n",
      "69 Train Loss 0.062748246 Test MSE 0.014391261846154621 Test RE 0.05733997481510328\n",
      "70 Train Loss 0.061025206 Test MSE 0.014356703897103258 Test RE 0.05727108777231476\n",
      "71 Train Loss 0.055642884 Test MSE 0.013032698633963054 Test RE 0.05456639175700957\n",
      "72 Train Loss 0.05293326 Test MSE 0.013202837159776168 Test RE 0.05492141193880684\n",
      "73 Train Loss 0.051716305 Test MSE 0.012590265105182775 Test RE 0.05363218586832621\n",
      "74 Train Loss 0.04940314 Test MSE 0.010892434172500604 Test RE 0.049885063832790295\n",
      "75 Train Loss 0.04775027 Test MSE 0.01038624711991864 Test RE 0.04871215983410677\n",
      "76 Train Loss 0.045155033 Test MSE 0.009888370065654026 Test RE 0.0475302847248281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 0.042666543 Test MSE 0.008908982354269705 Test RE 0.04511511925025722\n",
      "78 Train Loss 0.041346114 Test MSE 0.008316189392821353 Test RE 0.0435883315823906\n",
      "79 Train Loss 0.04055895 Test MSE 0.008163119749306273 Test RE 0.043185320195898706\n",
      "80 Train Loss 0.039540783 Test MSE 0.00813641685128487 Test RE 0.04311462922009942\n",
      "81 Train Loss 0.037504397 Test MSE 0.009632965042406022 Test RE 0.046912443287967086\n",
      "82 Train Loss 0.036133684 Test MSE 0.008830821380400113 Test RE 0.044916779540702785\n",
      "83 Train Loss 0.035370342 Test MSE 0.009163904346459096 Test RE 0.0457560297770072\n",
      "84 Train Loss 0.0344426 Test MSE 0.007778637364473596 Test RE 0.042156041461854664\n",
      "85 Train Loss 0.033547666 Test MSE 0.00702620042682236 Test RE 0.04006529339183675\n",
      "86 Train Loss 0.03234738 Test MSE 0.0066790969189887235 Test RE 0.039063120472939784\n",
      "87 Train Loss 0.030779723 Test MSE 0.006234195392101658 Test RE 0.03773968449985749\n",
      "88 Train Loss 0.030016175 Test MSE 0.00679827065134237 Test RE 0.039410077199529873\n",
      "89 Train Loss 0.029738372 Test MSE 0.006584502601487436 Test RE 0.03878551362713086\n",
      "90 Train Loss 0.028740723 Test MSE 0.00574923567487539 Test RE 0.036242080123893614\n",
      "91 Train Loss 0.027563384 Test MSE 0.005319691600683336 Test RE 0.0348619188867803\n",
      "92 Train Loss 0.026296094 Test MSE 0.005378067571355968 Test RE 0.035052676722147826\n",
      "93 Train Loss 0.024927037 Test MSE 0.00486593162532238 Test RE 0.03334195502182337\n",
      "94 Train Loss 0.024132634 Test MSE 0.0049274173986295754 Test RE 0.033551947735366246\n",
      "95 Train Loss 0.023394715 Test MSE 0.005060500367701661 Test RE 0.03400202565096821\n",
      "96 Train Loss 0.022914482 Test MSE 0.005248340822365365 Test RE 0.03462733553706548\n",
      "97 Train Loss 0.02210819 Test MSE 0.005111077029498337 Test RE 0.03417151812223341\n",
      "98 Train Loss 0.021475768 Test MSE 0.004874992804022612 Test RE 0.03337298473190074\n",
      "99 Train Loss 0.021054946 Test MSE 0.004960683831593572 Test RE 0.03366501671175516\n",
      "Training time: 151.30\n",
      "5\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 70.74407 Test MSE 4.654755432210631 Test RE 1.0312322681269432\n",
      "1 Train Loss 50.604553 Test MSE 5.517338664173047 Test RE 1.1227236770609446\n",
      "2 Train Loss 34.00335 Test MSE 5.691559475176191 Test RE 1.1403120128517248\n",
      "3 Train Loss 27.656715 Test MSE 5.877182191654663 Test RE 1.1587577112046519\n",
      "4 Train Loss 23.472399 Test MSE 5.99238143619075 Test RE 1.170059063954774\n",
      "5 Train Loss 20.833994 Test MSE 6.0362527831296 Test RE 1.1743343639433876\n",
      "6 Train Loss 18.969627 Test MSE 5.686354644846811 Test RE 1.1397904960258827\n",
      "7 Train Loss 18.42186 Test MSE 5.533279661315885 Test RE 1.12434442459598\n",
      "8 Train Loss 17.683422 Test MSE 5.29675885388179 Test RE 1.1000518630398017\n",
      "9 Train Loss 16.6756 Test MSE 5.270160819340901 Test RE 1.0972863943294706\n",
      "10 Train Loss 15.622675 Test MSE 5.2780783154671145 Test RE 1.0981103255682017\n",
      "11 Train Loss 14.677973 Test MSE 5.658391486573315 Test RE 1.1369845312029185\n",
      "12 Train Loss 13.493877 Test MSE 5.3931046195144825 Test RE 1.110011511859582\n",
      "13 Train Loss 12.767761 Test MSE 5.26552219582028 Test RE 1.096803390192036\n",
      "14 Train Loss 11.654834 Test MSE 5.0746477078690235 Test RE 1.0767404023119622\n",
      "15 Train Loss 10.619734 Test MSE 4.9278051053324745 Test RE 1.0610474888162313\n",
      "16 Train Loss 9.598182 Test MSE 4.817810086088939 Test RE 1.0491386787508932\n",
      "17 Train Loss 8.679039 Test MSE 4.89047225355468 Test RE 1.0570206210813262\n",
      "18 Train Loss 7.9843206 Test MSE 4.827775515951393 Test RE 1.0502231670171298\n",
      "19 Train Loss 7.4390173 Test MSE 4.62649033411381 Test RE 1.028096521768857\n",
      "20 Train Loss 6.7628 Test MSE 4.502957693500769 Test RE 1.0142779719897848\n",
      "21 Train Loss 6.363459 Test MSE 4.483939780106295 Test RE 1.0121338411802756\n",
      "22 Train Loss 5.946605 Test MSE 4.47579045769307 Test RE 1.0112136731494927\n",
      "23 Train Loss 5.508101 Test MSE 4.259563471736512 Test RE 0.9864852756002612\n",
      "24 Train Loss 4.949137 Test MSE 4.241589034787229 Test RE 0.9844016979203508\n",
      "25 Train Loss 4.410725 Test MSE 4.258235242575659 Test RE 0.9863314592904306\n",
      "26 Train Loss 3.9510725 Test MSE 4.29764232441359 Test RE 0.9908848635476762\n",
      "27 Train Loss 3.450182 Test MSE 4.179171665935672 Test RE 0.9771318413990897\n",
      "28 Train Loss 3.0833 Test MSE 3.965503752940346 Test RE 0.9518252967344907\n",
      "29 Train Loss 2.8251932 Test MSE 4.005248096604329 Test RE 0.9565832491830937\n",
      "30 Train Loss 2.598938 Test MSE 3.8861996732447133 Test RE 0.9422596973834007\n",
      "31 Train Loss 2.4807947 Test MSE 3.852176381270186 Test RE 0.9381259348132771\n",
      "32 Train Loss 2.377609 Test MSE 3.938074041553705 Test RE 0.9485276579058867\n",
      "33 Train Loss 2.2607627 Test MSE 3.960326953395451 Test RE 0.9512038097492086\n",
      "34 Train Loss 2.165266 Test MSE 4.006473847754966 Test RE 0.9567296125661361\n",
      "35 Train Loss 2.0694947 Test MSE 3.9943302823851994 Test RE 0.9552785952899897\n",
      "36 Train Loss 2.0034518 Test MSE 3.9503722969158956 Test RE 0.9500075871875208\n",
      "37 Train Loss 1.9321697 Test MSE 3.964681303433462 Test RE 0.9517265868493453\n",
      "38 Train Loss 1.8523552 Test MSE 3.955385785148716 Test RE 0.9506102318630848\n",
      "39 Train Loss 1.7463504 Test MSE 4.010421851643877 Test RE 0.9572008801096868\n",
      "40 Train Loss 1.7096872 Test MSE 4.069959192164922 Test RE 0.9642798411204195\n",
      "41 Train Loss 1.6175 Test MSE 4.08509922398034 Test RE 0.9660717111235093\n",
      "42 Train Loss 1.5951532 Test MSE 4.082900409758889 Test RE 0.9658116809481846\n",
      "43 Train Loss 1.5155437 Test MSE 4.079616471891152 Test RE 0.9654231944257479\n",
      "44 Train Loss 1.4981364 Test MSE 4.134247086698943 Test RE 0.97186574460366\n",
      "45 Train Loss 1.4202477 Test MSE 4.1075967951506325 Test RE 0.9687282470011032\n",
      "46 Train Loss 1.3786987 Test MSE 4.044811193974562 Test RE 0.9612961154796559\n",
      "47 Train Loss 1.3372877 Test MSE 4.0873104780533165 Test RE 0.9663331418603304\n",
      "48 Train Loss 1.2788843 Test MSE 4.091913563296692 Test RE 0.9668771257587314\n",
      "49 Train Loss 1.2536794 Test MSE 4.06873023744995 Test RE 0.9641342443620732\n",
      "50 Train Loss 1.2007434 Test MSE 4.051881485514681 Test RE 0.9621359168872946\n",
      "51 Train Loss 1.1630915 Test MSE 4.082532792737501 Test RE 0.9657681999946849\n",
      "52 Train Loss 1.1336774 Test MSE 4.045610313468683 Test RE 0.9613910707804378\n",
      "53 Train Loss 1.1123521 Test MSE 4.059373607175289 Test RE 0.9630250236219577\n",
      "54 Train Loss 1.0721365 Test MSE 3.9985907865516945 Test RE 0.9557879276974887\n",
      "55 Train Loss 1.0561105 Test MSE 3.988756400289646 Test RE 0.9546118415748487\n",
      "56 Train Loss 1.007849 Test MSE 3.9208476629008304 Test RE 0.9464508045555529\n",
      "57 Train Loss 0.9962901 Test MSE 3.8881426860447617 Test RE 0.9424952223205518\n",
      "58 Train Loss 0.93974173 Test MSE 3.8201284571278133 Test RE 0.9342154465332896\n",
      "59 Train Loss 0.92732215 Test MSE 3.802314836653907 Test RE 0.9320347338317932\n",
      "60 Train Loss 0.8946352 Test MSE 3.798606750580408 Test RE 0.9315801544268244\n",
      "61 Train Loss 0.87257874 Test MSE 3.7768694623683268 Test RE 0.9289108758329553\n",
      "62 Train Loss 0.85662967 Test MSE 3.724489220064994 Test RE 0.9224469964099548\n",
      "63 Train Loss 0.82633555 Test MSE 3.6437247795992103 Test RE 0.9123906862764818\n",
      "64 Train Loss 0.81796414 Test MSE 3.6563164126417145 Test RE 0.9139658025814339\n",
      "65 Train Loss 0.801615 Test MSE 3.6160629633793993 Test RE 0.9089208212580178\n",
      "66 Train Loss 0.77427167 Test MSE 3.6200550504176534 Test RE 0.9094224013143705\n",
      "67 Train Loss 0.7639653 Test MSE 3.5573859622621775 Test RE 0.9015162383673941\n",
      "68 Train Loss 0.7547734 Test MSE 3.5496881689357123 Test RE 0.9005403189698103\n",
      "69 Train Loss 0.7289333 Test MSE 3.5165852379888367 Test RE 0.8963314492455747\n",
      "70 Train Loss 0.71154535 Test MSE 3.5321980408952127 Test RE 0.8983189949629824\n",
      "71 Train Loss 0.7060613 Test MSE 3.510458678234687 Test RE 0.8955503190190729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Train Loss 0.6966216 Test MSE 3.470189522250998 Test RE 0.8903989872615964\n",
      "73 Train Loss 0.674355 Test MSE 3.4076643508007236 Test RE 0.8823410112903991\n",
      "74 Train Loss 0.66806155 Test MSE 3.436433110401878 Test RE 0.8860577075118891\n",
      "75 Train Loss 0.6518774 Test MSE 3.4472647713689724 Test RE 0.8874530388691894\n",
      "76 Train Loss 0.64084965 Test MSE 3.4465788388239496 Test RE 0.8873647423143609\n",
      "77 Train Loss 0.6307227 Test MSE 3.4423656025830423 Test RE 0.8868222013277353\n",
      "78 Train Loss 0.6227456 Test MSE 3.4465054137952147 Test RE 0.8873552901689489\n",
      "79 Train Loss 0.61226857 Test MSE 3.462035233962372 Test RE 0.8893522374735415\n",
      "80 Train Loss 0.5969833 Test MSE 3.477454889102875 Test RE 0.8913305924071455\n",
      "81 Train Loss 0.591748 Test MSE 3.4820495590323723 Test RE 0.8919192438947265\n",
      "82 Train Loss 0.58516514 Test MSE 3.4657798718792012 Test RE 0.8898330820972483\n",
      "83 Train Loss 0.56960815 Test MSE 3.475544217544357 Test RE 0.8910856900198207\n",
      "84 Train Loss 0.561797 Test MSE 3.49140932693015 Test RE 0.8931171812760568\n",
      "85 Train Loss 0.5586928 Test MSE 3.5002598080533884 Test RE 0.894248459937819\n",
      "86 Train Loss 0.5505705 Test MSE 3.5006172983174877 Test RE 0.8942941246846522\n",
      "87 Train Loss 0.5415339 Test MSE 3.4910924217513717 Test RE 0.8930766475178626\n",
      "88 Train Loss 0.53690445 Test MSE 3.4776215772996055 Test RE 0.8913519546553242\n",
      "89 Train Loss 0.53346986 Test MSE 3.4935870465073915 Test RE 0.8933956727672321\n",
      "90 Train Loss 0.53073317 Test MSE 3.4706278643557193 Test RE 0.8904552215161065\n",
      "91 Train Loss 0.52686733 Test MSE 3.449014011330537 Test RE 0.8876781697401203\n",
      "92 Train Loss 0.5199243 Test MSE 3.4200623076013876 Test RE 0.8839446454439293\n",
      "93 Train Loss 0.514918 Test MSE 3.4223027743674557 Test RE 0.8842341320356369\n",
      "94 Train Loss 0.510739 Test MSE 3.3910334738633567 Test RE 0.8801852748266401\n",
      "95 Train Loss 0.5077088 Test MSE 3.3746614928915855 Test RE 0.878057927485835\n",
      "96 Train Loss 0.50333554 Test MSE 3.386333998481245 Test RE 0.8795751594782211\n",
      "97 Train Loss 0.4998911 Test MSE 3.3928908798990745 Test RE 0.880426298344394\n",
      "98 Train Loss 0.49778557 Test MSE 3.3942537689443357 Test RE 0.8806031096425838\n",
      "99 Train Loss 0.49513134 Test MSE 3.3750196218922044 Test RE 0.878104517294377\n",
      "Training time: 151.30\n",
      "6\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 72.29942 Test MSE 5.261903418650993 Test RE 1.0964264314496677\n",
      "1 Train Loss 61.03923 Test MSE 7.255558651027168 Test RE 1.2874888862201164\n",
      "2 Train Loss 46.23522 Test MSE 8.540806614162758 Test RE 1.3968748703280338\n",
      "3 Train Loss 41.60372 Test MSE 8.977426143040912 Test RE 1.4321350729274818\n",
      "4 Train Loss 36.50679 Test MSE 9.074926826154519 Test RE 1.43989102999286\n",
      "5 Train Loss 32.155632 Test MSE 8.796088326008698 Test RE 1.4175972143107876\n",
      "6 Train Loss 30.022816 Test MSE 9.125123926737857 Test RE 1.4438678488422947\n",
      "7 Train Loss 28.361443 Test MSE 8.662694554640325 Test RE 1.406807130925998\n",
      "8 Train Loss 26.312553 Test MSE 8.89947284985215 Test RE 1.4259037182889827\n",
      "9 Train Loss 25.173119 Test MSE 9.110369513507614 Test RE 1.4427000816202806\n",
      "10 Train Loss 24.219393 Test MSE 9.18786329071225 Test RE 1.4488229692844667\n",
      "11 Train Loss 23.021511 Test MSE 8.87021052411471 Test RE 1.4235575335511437\n",
      "12 Train Loss 21.984947 Test MSE 8.904266098241944 Test RE 1.4262876618535294\n",
      "13 Train Loss 21.063564 Test MSE 8.963924664977446 Test RE 1.4310577476762927\n",
      "14 Train Loss 20.04358 Test MSE 9.024151075212629 Test RE 1.4358571625742598\n",
      "15 Train Loss 19.139318 Test MSE 8.82443484473613 Test RE 1.4198795710857866\n",
      "16 Train Loss 18.007387 Test MSE 8.898110180942124 Test RE 1.4257945483930545\n",
      "17 Train Loss 16.894375 Test MSE 8.534689511703505 Test RE 1.3963745453801562\n",
      "18 Train Loss 16.002342 Test MSE 8.054133737482651 Test RE 1.3564927552856978\n",
      "19 Train Loss 14.2062645 Test MSE 7.970962476467081 Test RE 1.3494706475530076\n",
      "20 Train Loss 13.433254 Test MSE 8.163184858605334 Test RE 1.3656451792088922\n",
      "21 Train Loss 12.607254 Test MSE 7.887883313391456 Test RE 1.3424196449155592\n",
      "22 Train Loss 11.772181 Test MSE 7.146140668911659 Test RE 1.2777439718410248\n",
      "23 Train Loss 9.614665 Test MSE 5.93038645821749 Test RE 1.1639908274947666\n",
      "24 Train Loss 8.625982 Test MSE 5.833613548990345 Test RE 1.1544546785588283\n",
      "25 Train Loss 7.899167 Test MSE 5.696155376832323 Test RE 1.1407723176545534\n",
      "26 Train Loss 7.282674 Test MSE 5.642979290012753 Test RE 1.135435029204029\n",
      "27 Train Loss 6.4521456 Test MSE 5.365347314198756 Test RE 1.1071513156002823\n",
      "28 Train Loss 5.243366 Test MSE 4.950750443523753 Test RE 1.063514897536766\n",
      "29 Train Loss 4.431768 Test MSE 4.949941094065276 Test RE 1.0634279621924985\n",
      "30 Train Loss 3.8405788 Test MSE 5.136898171708064 Test RE 1.0833244341941208\n",
      "31 Train Loss 3.3614144 Test MSE 5.059907751137056 Test RE 1.0751755007134636\n",
      "32 Train Loss 3.1679876 Test MSE 5.219789208660521 Test RE 1.092029933376911\n",
      "33 Train Loss 2.8283896 Test MSE 5.253430295282749 Test RE 1.0955433005154307\n",
      "34 Train Loss 2.7218165 Test MSE 5.1653082609578345 Test RE 1.086316016455392\n",
      "35 Train Loss 2.5956173 Test MSE 5.219790240147504 Test RE 1.0920300412753872\n",
      "36 Train Loss 2.5003614 Test MSE 5.1671124291561465 Test RE 1.086505717205097\n",
      "37 Train Loss 2.414618 Test MSE 5.177681709661015 Test RE 1.0876163682176285\n",
      "38 Train Loss 2.2940774 Test MSE 5.178449000127774 Test RE 1.0876969531978105\n",
      "39 Train Loss 2.2507677 Test MSE 5.213835876844128 Test RE 1.091407008671084\n",
      "40 Train Loss 2.1874197 Test MSE 5.282100950190666 Test RE 1.098528702781732\n",
      "41 Train Loss 2.091086 Test MSE 5.282286340252001 Test RE 1.09854798057655\n",
      "42 Train Loss 2.0408177 Test MSE 5.337486426289262 Test RE 1.1042729961411686\n",
      "43 Train Loss 1.9729491 Test MSE 5.366155094437394 Test RE 1.1072346560852895\n",
      "44 Train Loss 1.8882889 Test MSE 5.367987014980071 Test RE 1.1074236361644036\n",
      "45 Train Loss 1.8527774 Test MSE 5.358712981966173 Test RE 1.1064665992856166\n",
      "46 Train Loss 1.7860923 Test MSE 5.390918316640469 Test RE 1.1097864960726593\n",
      "47 Train Loss 1.6983407 Test MSE 5.448058426433256 Test RE 1.1156524885198587\n",
      "48 Train Loss 1.676202 Test MSE 5.436938926981989 Test RE 1.1145133823794469\n",
      "49 Train Loss 1.6205878 Test MSE 5.455418092394311 Test RE 1.116405789780085\n",
      "50 Train Loss 1.6085409 Test MSE 5.474720657424086 Test RE 1.1183791002424657\n",
      "51 Train Loss 1.5558971 Test MSE 5.555954307356115 Test RE 1.1266457764992706\n",
      "52 Train Loss 1.5353477 Test MSE 5.559683422544856 Test RE 1.1270238112072473\n",
      "53 Train Loss 1.4523706 Test MSE 5.652391588250524 Test RE 1.1363815682463987\n",
      "54 Train Loss 1.4397343 Test MSE 5.684885187440783 Test RE 1.1396432152186922\n",
      "55 Train Loss 1.4041637 Test MSE 5.684267788001685 Test RE 1.1395813288161099\n",
      "56 Train Loss 1.3940902 Test MSE 5.712143345791648 Test RE 1.142372155710182\n",
      "57 Train Loss 1.3524202 Test MSE 5.732842275065121 Test RE 1.144440074573996\n",
      "58 Train Loss 1.3457861 Test MSE 5.733863222613024 Test RE 1.1445419752732027\n",
      "59 Train Loss 1.3122643 Test MSE 5.761106883631957 Test RE 1.1472578198488774\n",
      "60 Train Loss 1.3048494 Test MSE 5.781851002346143 Test RE 1.1493214395783402\n",
      "61 Train Loss 1.2769011 Test MSE 5.752794713277816 Test RE 1.1464298847973282\n",
      "62 Train Loss 1.265964 Test MSE 5.754560108416702 Test RE 1.1466057772633917\n",
      "63 Train Loss 1.2468053 Test MSE 5.754499357199124 Test RE 1.1465997248562936\n",
      "64 Train Loss 1.2367926 Test MSE 5.757501824388242 Test RE 1.1468988107454414\n",
      "65 Train Loss 1.2122037 Test MSE 5.743759694041119 Test RE 1.1455292715556946\n",
      "66 Train Loss 1.2063816 Test MSE 5.745902772907887 Test RE 1.1457429583002203\n",
      "67 Train Loss 1.1851969 Test MSE 5.812927217920159 Test RE 1.152405979211452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Train Loss 1.1763097 Test MSE 5.810519908271392 Test RE 1.1521673313488143\n",
      "69 Train Loss 1.1714114 Test MSE 5.816601063483845 Test RE 1.1527700894694008\n",
      "70 Train Loss 1.1557509 Test MSE 5.83771487189176 Test RE 1.1548604270254963\n",
      "71 Train Loss 1.1468188 Test MSE 5.856603974828222 Test RE 1.1567273099009108\n",
      "72 Train Loss 1.1293781 Test MSE 5.876712404046046 Test RE 1.1587113981182753\n",
      "73 Train Loss 1.1235497 Test MSE 5.871990768700255 Test RE 1.1582458221569623\n",
      "74 Train Loss 1.1087127 Test MSE 5.8645352329863485 Test RE 1.1575102891665372\n",
      "75 Train Loss 1.102303 Test MSE 5.859763655516978 Test RE 1.1570392992493506\n",
      "76 Train Loss 1.0995529 Test MSE 5.86617627603368 Test RE 1.1576722279453007\n",
      "77 Train Loss 1.0872561 Test MSE 5.864193149683229 Test RE 1.1574765293968547\n",
      "78 Train Loss 1.0839986 Test MSE 5.862472794494774 Test RE 1.1573067347834896\n",
      "79 Train Loss 1.0788964 Test MSE 5.845536486475881 Test RE 1.1556338332064022\n",
      "80 Train Loss 1.0613058 Test MSE 5.872232783084567 Test RE 1.1582696904898975\n",
      "81 Train Loss 1.0555198 Test MSE 5.880632120101507 Test RE 1.1590977589159919\n",
      "82 Train Loss 1.0522572 Test MSE 5.883860372049658 Test RE 1.1594158664022958\n",
      "83 Train Loss 1.0398006 Test MSE 5.91925574679382 Test RE 1.1628979703017692\n",
      "84 Train Loss 1.0350211 Test MSE 5.927110497112441 Test RE 1.1636692872837069\n",
      "85 Train Loss 1.0288796 Test MSE 5.921330582549342 Test RE 1.1631017637338814\n",
      "86 Train Loss 1.0197637 Test MSE 5.932574256635825 Test RE 1.1642055135431413\n",
      "87 Train Loss 1.0165249 Test MSE 5.939295533960291 Test RE 1.164864816969227\n",
      "88 Train Loss 1.0128864 Test MSE 5.9354868262962635 Test RE 1.1644912591094607\n",
      "89 Train Loss 1.0048331 Test MSE 5.944371975951088 Test RE 1.1653625279861264\n",
      "90 Train Loss 0.9986636 Test MSE 5.940807966821056 Test RE 1.1650131230834022\n",
      "91 Train Loss 0.9937854 Test MSE 5.957545066256777 Test RE 1.1666530705673401\n",
      "92 Train Loss 0.9886843 Test MSE 5.969430834629989 Test RE 1.1678162727490375\n",
      "93 Train Loss 0.98404384 Test MSE 5.964500493460384 Test RE 1.167333904984667\n",
      "94 Train Loss 0.9787517 Test MSE 5.926229529351177 Test RE 1.1635828038932485\n",
      "95 Train Loss 0.97507364 Test MSE 5.923456293573362 Test RE 1.1633105171848088\n",
      "96 Train Loss 0.9709705 Test MSE 5.90997925766995 Test RE 1.161986382708719\n",
      "97 Train Loss 0.9634429 Test MSE 5.917532726137563 Test RE 1.1627287055205504\n",
      "98 Train Loss 0.95963514 Test MSE 5.918689823738731 Test RE 1.1628423783041402\n",
      "99 Train Loss 0.9552174 Test MSE 5.921831444240065 Test RE 1.1631509537587674\n",
      "Training time: 153.60\n",
      "7\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 62.294674 Test MSE 5.497878184914874 Test RE 1.1207419208050806\n",
      "1 Train Loss 40.918907 Test MSE 7.828487226872932 Test RE 1.3373558566358306\n",
      "2 Train Loss 31.72667 Test MSE 7.822958044956108 Test RE 1.3368834927085322\n",
      "3 Train Loss 25.66433 Test MSE 7.607892156803365 Test RE 1.3183788709341278\n",
      "4 Train Loss 22.133669 Test MSE 7.061653432300311 Test RE 1.2701682719775014\n",
      "5 Train Loss 20.18555 Test MSE 6.93643211474646 Test RE 1.2588562209843563\n",
      "6 Train Loss 18.21637 Test MSE 6.502236680454224 Test RE 1.2188196493288461\n",
      "7 Train Loss 16.101585 Test MSE 6.2561313041620075 Test RE 1.1955314020366892\n",
      "8 Train Loss 13.791037 Test MSE 5.505720182560744 Test RE 1.1215409312056956\n",
      "9 Train Loss 11.178347 Test MSE 5.266678418941995 Test RE 1.096923803684178\n",
      "10 Train Loss 9.833418 Test MSE 5.323137365834185 Test RE 1.1027876580541924\n",
      "11 Train Loss 8.887508 Test MSE 5.258847358308335 Test RE 1.0961079885089429\n",
      "12 Train Loss 7.912046 Test MSE 4.9258444966968815 Test RE 1.0608363901844509\n",
      "13 Train Loss 7.1631804 Test MSE 4.737817710277534 Test RE 1.0403925503271494\n",
      "14 Train Loss 6.529212 Test MSE 4.46629083924492 Test RE 1.0101399805024105\n",
      "15 Train Loss 6.0121164 Test MSE 4.497905658714786 Test RE 1.013708834325039\n",
      "16 Train Loss 4.9627094 Test MSE 4.129316100180072 Test RE 0.9712859913150252\n",
      "17 Train Loss 4.170585 Test MSE 3.934567540252872 Test RE 0.9481052745098273\n",
      "18 Train Loss 3.8065848 Test MSE 3.912703988441514 Test RE 0.9454673955749223\n",
      "19 Train Loss 3.3869731 Test MSE 3.5918234000171863 Test RE 0.9058693133254624\n",
      "20 Train Loss 3.0372572 Test MSE 3.4608808465251535 Test RE 0.889203951483121\n",
      "21 Train Loss 2.768265 Test MSE 3.433744975232307 Test RE 0.885711082277499\n",
      "22 Train Loss 2.5672572 Test MSE 3.3370462625644373 Test RE 0.8731506346568674\n",
      "23 Train Loss 2.3524432 Test MSE 3.0479536358866905 Test RE 0.8344729023381954\n",
      "24 Train Loss 2.1913912 Test MSE 2.8322785074418224 Test RE 0.8044073657309795\n",
      "25 Train Loss 2.0810535 Test MSE 2.842241810502226 Test RE 0.8058209834911992\n",
      "26 Train Loss 1.9236466 Test MSE 2.782090326563453 Test RE 0.7972484312931479\n",
      "27 Train Loss 1.816984 Test MSE 2.6351793463629107 Test RE 0.7759132161373583\n",
      "28 Train Loss 1.7345864 Test MSE 2.554406789954621 Test RE 0.7639291642562949\n",
      "29 Train Loss 1.617164 Test MSE 2.4257673600617804 Test RE 0.7444450290879397\n",
      "30 Train Loss 1.536341 Test MSE 2.3331151286926946 Test RE 0.7300895716590278\n",
      "31 Train Loss 1.4458092 Test MSE 2.312026102071786 Test RE 0.7267824417496904\n",
      "32 Train Loss 1.3926533 Test MSE 2.187805723748058 Test RE 0.7069886429899762\n",
      "33 Train Loss 1.3379952 Test MSE 2.1671961439891185 Test RE 0.7036507743458172\n",
      "34 Train Loss 1.2858082 Test MSE 2.106511304767045 Test RE 0.6937291719289537\n",
      "35 Train Loss 1.232685 Test MSE 2.022010051566542 Test RE 0.6796725264961425\n",
      "36 Train Loss 1.1356717 Test MSE 1.9447244527216374 Test RE 0.6665566994142456\n",
      "37 Train Loss 1.0487076 Test MSE 1.9056433369658339 Test RE 0.6598251583133069\n",
      "38 Train Loss 1.0109522 Test MSE 1.8309848749993953 Test RE 0.6467708510091807\n",
      "39 Train Loss 0.96408796 Test MSE 1.8145815042801683 Test RE 0.6438671977312477\n",
      "40 Train Loss 0.91672915 Test MSE 1.7449133405427069 Test RE 0.6313860638581925\n",
      "41 Train Loss 0.8915766 Test MSE 1.658487420708277 Test RE 0.6155511559255399\n",
      "42 Train Loss 0.8628269 Test MSE 1.539689397820832 Test RE 0.5930954877016178\n",
      "43 Train Loss 0.80331486 Test MSE 1.1411237254642697 Test RE 0.5105924959386468\n",
      "44 Train Loss 0.73992604 Test MSE 0.9245900041440818 Test RE 0.45960279089615735\n",
      "45 Train Loss 0.69377166 Test MSE 0.8549493161449867 Test RE 0.4419551967255825\n",
      "46 Train Loss 0.6538204 Test MSE 0.7692352160949038 Test RE 0.41921579695295275\n",
      "47 Train Loss 0.6127958 Test MSE 0.7375076755028399 Test RE 0.4104793675879413\n",
      "48 Train Loss 0.571736 Test MSE 0.7052576574849772 Test RE 0.40140424909105904\n",
      "49 Train Loss 0.52749336 Test MSE 0.5976962355399787 Test RE 0.36952882454535757\n",
      "50 Train Loss 0.49111566 Test MSE 0.5005783857704913 Test RE 0.3381770310483331\n",
      "51 Train Loss 0.45326358 Test MSE 0.40095942756646324 Test RE 0.302662262973937\n",
      "52 Train Loss 0.41401678 Test MSE 0.24237852929660794 Test RE 0.23531799168001358\n",
      "53 Train Loss 0.35568368 Test MSE 0.14585192330889876 Test RE 0.18254256153429035\n",
      "54 Train Loss 0.3065805 Test MSE 0.08381379319042742 Test RE 0.13837760457028436\n",
      "55 Train Loss 0.24828568 Test MSE 0.06214405479677954 Test RE 0.11915378805701479\n",
      "56 Train Loss 0.20403603 Test MSE 0.04986040593680304 Test RE 0.1067298662704442\n",
      "57 Train Loss 0.16855906 Test MSE 0.0474656097908981 Test RE 0.10413520890298689\n",
      "58 Train Loss 0.1493372 Test MSE 0.03878547687280808 Test RE 0.09413315784868749\n",
      "59 Train Loss 0.13553639 Test MSE 0.03235289262844141 Test RE 0.08597350221124918\n",
      "60 Train Loss 0.12087512 Test MSE 0.034471805995742 Test RE 0.08874422043415282\n",
      "61 Train Loss 0.1004802 Test MSE 0.03397723107385619 Test RE 0.08810530362175051\n",
      "62 Train Loss 0.087920494 Test MSE 0.03542962093264418 Test RE 0.0899686726475619\n",
      "63 Train Loss 0.08004711 Test MSE 0.03135561096031182 Test RE 0.08463805876826894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Train Loss 0.07309313 Test MSE 0.02774754763926722 Test RE 0.07961966814841277\n",
      "65 Train Loss 0.068059415 Test MSE 0.02931904644172884 Test RE 0.08184327149932134\n",
      "66 Train Loss 0.06281075 Test MSE 0.026931400937017003 Test RE 0.07843999060896714\n",
      "67 Train Loss 0.059635356 Test MSE 0.025098287479545525 Test RE 0.07572339988674427\n",
      "68 Train Loss 0.05571679 Test MSE 0.021989406190857118 Test RE 0.0708785478369065\n",
      "69 Train Loss 0.05231266 Test MSE 0.02581363547776196 Test RE 0.07679494731043471\n",
      "70 Train Loss 0.04979058 Test MSE 0.023190504866323937 Test RE 0.0727885657580735\n",
      "71 Train Loss 0.04709091 Test MSE 0.020131325338630036 Test RE 0.06781788538440607\n",
      "72 Train Loss 0.045357376 Test MSE 0.018986540433202817 Test RE 0.06586140323796157\n",
      "73 Train Loss 0.04274804 Test MSE 0.017589866758532993 Test RE 0.06339271250349113\n",
      "74 Train Loss 0.040333256 Test MSE 0.01723823563662542 Test RE 0.06275588619549119\n",
      "75 Train Loss 0.036836207 Test MSE 0.014114470143345789 Test RE 0.056785878643273106\n",
      "76 Train Loss 0.034439817 Test MSE 0.012781332268805672 Test RE 0.05403760878376589\n",
      "77 Train Loss 0.032357212 Test MSE 0.012185492080206684 Test RE 0.0527630140267706\n",
      "78 Train Loss 0.030334303 Test MSE 0.010927067239719371 Test RE 0.04996430698514318\n",
      "79 Train Loss 0.028437467 Test MSE 0.0074886464163950945 Test RE 0.04136278027829579\n",
      "80 Train Loss 0.027020104 Test MSE 0.006953681736001965 Test RE 0.03985799653215538\n",
      "81 Train Loss 0.023820372 Test MSE 0.0057224992355553355 Test RE 0.03615771122625212\n",
      "82 Train Loss 0.021746634 Test MSE 0.0055768511870164725 Test RE 0.03569460564591557\n",
      "83 Train Loss 0.019680642 Test MSE 0.006526400105243521 Test RE 0.03861401027120971\n",
      "84 Train Loss 0.018806089 Test MSE 0.007631862774950344 Test RE 0.04175642764595345\n",
      "85 Train Loss 0.018610736 Test MSE 0.0072942925477396964 Test RE 0.04082250481513924\n",
      "86 Train Loss 0.017847355 Test MSE 0.006873127376014509 Test RE 0.03962645816142361\n",
      "87 Train Loss 0.016952781 Test MSE 0.006536241955497594 Test RE 0.03864311438185848\n",
      "88 Train Loss 0.01618511 Test MSE 0.00619222904566464 Test RE 0.037612445059163606\n",
      "89 Train Loss 0.015291335 Test MSE 0.005823812661183165 Test RE 0.036476382267857224\n",
      "90 Train Loss 0.014112343 Test MSE 0.006012738632925827 Test RE 0.03706331180570242\n",
      "91 Train Loss 0.013351271 Test MSE 0.00547255457775459 Test RE 0.03535925540109922\n",
      "92 Train Loss 0.013087422 Test MSE 0.005520112396704037 Test RE 0.03551256327901887\n",
      "93 Train Loss 0.012651782 Test MSE 0.005367214492876417 Test RE 0.03501729025950692\n",
      "94 Train Loss 0.0120209735 Test MSE 0.005011855760317327 Test RE 0.033838206943579884\n",
      "95 Train Loss 0.011351688 Test MSE 0.0046924385922530246 Test RE 0.03274216247410314\n",
      "96 Train Loss 0.01035943 Test MSE 0.004613401693144675 Test RE 0.03246524582076817\n",
      "97 Train Loss 0.009717675 Test MSE 0.004095809796316528 Test RE 0.03058989247942096\n",
      "98 Train Loss 0.009515826 Test MSE 0.0038116769729601213 Test RE 0.02950978902031751\n",
      "99 Train Loss 0.009371829 Test MSE 0.003813737252830263 Test RE 0.02951776322842609\n",
      "Training time: 150.60\n",
      "8\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.57\n",
      "0\n",
      "KG_rowdy_tune74\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 74.88271 Test MSE 4.327875371711194 Test RE 0.9943640929725192\n",
      "1 Train Loss 66.51678 Test MSE 4.1674162697001185 Test RE 0.9757566094417355\n",
      "2 Train Loss 52.16551 Test MSE 5.281047154689844 Test RE 1.0984191173763587\n",
      "3 Train Loss 34.948875 Test MSE 5.942919259927047 Test RE 1.165220120657808\n",
      "4 Train Loss 27.952728 Test MSE 5.382088767637773 Test RE 1.1088772882841067\n",
      "5 Train Loss 24.47054 Test MSE 5.746245994010081 Test RE 1.1457771772301502\n",
      "6 Train Loss 21.468834 Test MSE 5.443839296128328 Test RE 1.1152204084526889\n",
      "7 Train Loss 17.375565 Test MSE 4.8802776266464685 Test RE 1.0559183192977555\n",
      "8 Train Loss 15.022941 Test MSE 4.950410856893014 Test RE 1.063478422093466\n",
      "9 Train Loss 13.313272 Test MSE 5.403113760328241 Test RE 1.1110410775888635\n",
      "10 Train Loss 12.708752 Test MSE 5.597199614492263 Test RE 1.1308199404100594\n",
      "11 Train Loss 12.028139 Test MSE 5.653291640075393 Test RE 1.136472039826025\n",
      "12 Train Loss 11.548569 Test MSE 5.403331518422421 Test RE 1.1110634661374599\n",
      "13 Train Loss 10.975954 Test MSE 5.427423224603597 Test RE 1.1135376474833554\n",
      "14 Train Loss 10.407536 Test MSE 5.413480123872396 Test RE 1.1121063833741769\n",
      "15 Train Loss 10.085398 Test MSE 5.411216367374531 Test RE 1.1118738341416123\n",
      "16 Train Loss 9.695509 Test MSE 5.405058475303426 Test RE 1.111241005254076\n",
      "17 Train Loss 9.094257 Test MSE 5.251682281534346 Test RE 1.095361021131265\n",
      "18 Train Loss 8.659754 Test MSE 5.255036658235775 Test RE 1.0957107821002856\n",
      "19 Train Loss 8.0618515 Test MSE 5.206362693964708 Test RE 1.0906245512696182\n",
      "20 Train Loss 7.4402905 Test MSE 5.077513648733984 Test RE 1.0770444075285366\n",
      "21 Train Loss 6.939929 Test MSE 5.046507709786536 Test RE 1.073750875184101\n",
      "22 Train Loss 6.3502054 Test MSE 4.853189985682451 Test RE 1.0529838411943542\n",
      "23 Train Loss 5.941494 Test MSE 4.608671441383114 Test RE 1.0261147587304484\n",
      "24 Train Loss 5.5556936 Test MSE 4.477524479997428 Test RE 1.0114095376878345\n",
      "25 Train Loss 4.9044437 Test MSE 4.081998125175583 Test RE 0.9657049571669379\n",
      "26 Train Loss 4.5400743 Test MSE 4.014904601156679 Test RE 0.9577356983338504\n",
      "27 Train Loss 4.092587 Test MSE 3.8976890065078456 Test RE 0.9436515386203793\n",
      "28 Train Loss 3.6539302 Test MSE 3.6545757184411864 Test RE 0.913748216876301\n",
      "29 Train Loss 3.1335664 Test MSE 3.332399794601283 Test RE 0.872542540047175\n",
      "30 Train Loss 2.7811825 Test MSE 3.2610338794593123 Test RE 0.8631488886130078\n",
      "31 Train Loss 2.5348954 Test MSE 3.1282736771541764 Test RE 0.8453964707088831\n",
      "32 Train Loss 2.2900894 Test MSE 3.0811469921018824 Test RE 0.8390044593207167\n",
      "33 Train Loss 2.1521924 Test MSE 3.0610626888108348 Test RE 0.8362654841533034\n",
      "34 Train Loss 2.0827677 Test MSE 3.0305603888908457 Test RE 0.83208852239674\n",
      "35 Train Loss 1.9506507 Test MSE 2.9970437495822995 Test RE 0.8274744665631737\n",
      "36 Train Loss 1.8966368 Test MSE 2.95607525092802 Test RE 0.8217993681066855\n",
      "37 Train Loss 1.7866161 Test MSE 2.9057557556298423 Test RE 0.8147748474728744\n",
      "38 Train Loss 1.7293699 Test MSE 2.938053914816476 Test RE 0.8192905410069962\n",
      "39 Train Loss 1.6538309 Test MSE 2.95070444309812 Test RE 0.821052476921183\n",
      "40 Train Loss 1.5967776 Test MSE 2.95981442619888 Test RE 0.8223189558211893\n",
      "41 Train Loss 1.5522811 Test MSE 2.9582201243699036 Test RE 0.8220974552438501\n",
      "42 Train Loss 1.4670324 Test MSE 2.935862023684107 Test RE 0.8189848742662971\n",
      "43 Train Loss 1.4451637 Test MSE 2.9319772299727633 Test RE 0.8184428459887254\n",
      "44 Train Loss 1.4268662 Test MSE 2.910149567965502 Test RE 0.8153906279746782\n",
      "45 Train Loss 1.3679785 Test MSE 2.916814860411128 Test RE 0.8163238632778316\n",
      "46 Train Loss 1.3338615 Test MSE 2.92112518487049 Test RE 0.8169268020880973\n",
      "47 Train Loss 1.2866286 Test MSE 2.954016192443195 Test RE 0.8215131054805438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 1.2343979 Test MSE 2.8910085705826867 Test RE 0.812704659783897\n",
      "49 Train Loss 1.2235821 Test MSE 2.916347889277717 Test RE 0.8162585154658708\n",
      "50 Train Loss 1.1941029 Test MSE 2.879983878173672 Test RE 0.811153578744683\n",
      "51 Train Loss 1.1554756 Test MSE 2.80964986720392 Test RE 0.8011874937168122\n",
      "52 Train Loss 1.1306058 Test MSE 2.8002837918014785 Test RE 0.7998509843684803\n",
      "53 Train Loss 1.0942945 Test MSE 2.8092646570859414 Test RE 0.8011325694161645\n",
      "54 Train Loss 1.0716008 Test MSE 2.817700229060073 Test RE 0.8023344757316354\n",
      "55 Train Loss 1.0444847 Test MSE 2.8148717185218386 Test RE 0.8019316682732704\n",
      "56 Train Loss 1.0122734 Test MSE 2.8458546407470697 Test RE 0.8063329684051423\n",
      "57 Train Loss 1.0003369 Test MSE 2.8476217940020447 Test RE 0.8065832785888399\n",
      "58 Train Loss 0.97166336 Test MSE 2.8203670630365827 Test RE 0.8027140737413203\n",
      "59 Train Loss 0.9595258 Test MSE 2.8060783224794164 Test RE 0.8006781087335048\n",
      "60 Train Loss 0.9510659 Test MSE 2.8075029004957015 Test RE 0.8008813253885891\n",
      "61 Train Loss 0.90131617 Test MSE 2.8278227245569654 Test RE 0.8037743638249378\n",
      "62 Train Loss 0.8911898 Test MSE 2.821215187657097 Test RE 0.8028347584571689\n",
      "63 Train Loss 0.88015145 Test MSE 2.81647690903266 Test RE 0.8021602878641606\n",
      "64 Train Loss 0.8588941 Test MSE 2.8086843112606124 Test RE 0.8010498150278689\n",
      "65 Train Loss 0.8457276 Test MSE 2.8059196241815894 Test RE 0.8006554671613577\n",
      "66 Train Loss 0.8366772 Test MSE 2.8259784468491658 Test RE 0.8035122142732449\n",
      "67 Train Loss 0.82274896 Test MSE 2.8303813382169847 Test RE 0.8041379090833132\n",
      "68 Train Loss 0.79024637 Test MSE 2.8594557799269738 Test RE 0.8082575175970899\n",
      "69 Train Loss 0.7831677 Test MSE 2.875269891098041 Test RE 0.8104894546339814\n",
      "70 Train Loss 0.7656344 Test MSE 2.8918377576632297 Test RE 0.8128211997170208\n",
      "71 Train Loss 0.7501863 Test MSE 2.887592547204668 Test RE 0.8122243708758937\n",
      "72 Train Loss 0.74251014 Test MSE 2.8863938804007825 Test RE 0.8120557723925638\n",
      "73 Train Loss 0.7325301 Test MSE 2.91250073933035 Test RE 0.8157199471361452\n",
      "74 Train Loss 0.71616924 Test MSE 2.929085213177136 Test RE 0.8180391023318151\n",
      "75 Train Loss 0.7009548 Test MSE 2.9180263309763674 Test RE 0.8164933717507353\n",
      "76 Train Loss 0.69702804 Test MSE 2.9195387245195006 Test RE 0.8167049358697702\n",
      "77 Train Loss 0.67586255 Test MSE 2.9741067256283027 Test RE 0.8243019644227874\n",
      "78 Train Loss 0.6521685 Test MSE 2.916320680999488 Test RE 0.8162547077856078\n",
      "79 Train Loss 0.646808 Test MSE 2.9190270516670296 Test RE 0.8166333656501793\n",
      "80 Train Loss 0.6421516 Test MSE 2.9139226895202723 Test RE 0.8159190495052089\n",
      "81 Train Loss 0.6357972 Test MSE 2.9139007486137842 Test RE 0.8159159776945992\n",
      "82 Train Loss 0.622697 Test MSE 2.943074249058457 Test RE 0.8199902144862115\n",
      "83 Train Loss 0.60924834 Test MSE 2.925299008727152 Test RE 0.8175102230725442\n",
      "84 Train Loss 0.60632765 Test MSE 2.9354832212985422 Test RE 0.8189320374113465\n",
      "85 Train Loss 0.60359293 Test MSE 2.9480164896638326 Test RE 0.8206784215551024\n",
      "86 Train Loss 0.5946442 Test MSE 2.9472074188995383 Test RE 0.8205657979514941\n",
      "87 Train Loss 0.5906327 Test MSE 2.94336183327954 Test RE 0.8200302764191979\n",
      "88 Train Loss 0.58832645 Test MSE 2.9384889678534285 Test RE 0.8193511970831824\n",
      "89 Train Loss 0.58554643 Test MSE 2.955342122103393 Test RE 0.8216974555852691\n",
      "90 Train Loss 0.58261365 Test MSE 2.9552333057309736 Test RE 0.8216823279019541\n",
      "91 Train Loss 0.5780114 Test MSE 2.959265258969864 Test RE 0.8222426652998245\n",
      "92 Train Loss 0.56970733 Test MSE 2.9762867141190865 Test RE 0.8246040113551957\n",
      "93 Train Loss 0.56621665 Test MSE 2.9707121608722105 Test RE 0.8238314121623775\n",
      "94 Train Loss 0.56353426 Test MSE 2.973468022848586 Test RE 0.8242134483953198\n",
      "95 Train Loss 0.55782235 Test MSE 2.962079415767323 Test RE 0.8226335342707807\n",
      "96 Train Loss 0.55407226 Test MSE 2.970984478565807 Test RE 0.8238691705712878\n",
      "97 Train Loss 0.5507946 Test MSE 2.9623291081873417 Test RE 0.8226682060335161\n",
      "98 Train Loss 0.5481827 Test MSE 2.965242339688561 Test RE 0.8230726232858847\n",
      "99 Train Loss 0.5401519 Test MSE 2.9683978095141392 Test RE 0.8235104442036912\n",
      "Training time: 152.44\n",
      "1\n",
      "KG_rowdy_tune74\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.00\n"
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(65,75):\n",
    "#for tune_reps in range(1,5):\n",
    "    max_reps = 10 #10\n",
    "    max_iter = 100 #100\n",
    "    label = \"KG_rowdy_tune\"+str(tune_reps)\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "    alpha_full = []\n",
    "    omega_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "    n_val = lrnr_tune[tune_reps,1]\n",
    "    rowdy_terms = int(lrnr_tune[tune_reps,2])\n",
    "\n",
    "    N_I = 200  #Total number of data points for 'y'\n",
    "    N_B = 400\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    for reps in range(max_reps):\n",
    "        print(reps)\n",
    "        print(label)\n",
    "\n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss = []\n",
    "        alpha_val = []\n",
    "        omega_val = []\n",
    "\n",
    "        torch.manual_seed(reps*36)\n",
    "\n",
    "        layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "        PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lrnr_tune[tune_reps,0], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nan_flag = train_model(max_iter,reps)\n",
    "        \n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        #elapsed_time[reps] = time.time() - start_time\n",
    "        alpha_full.append(alpha_val)\n",
    "        omega_full.append(omega_val)\n",
    "        \n",
    "        if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "\n",
    "        \n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,  \"omega\": omega_full,\"label\": label}\n",
    "    savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.572127943642081\n",
      "1   0.5853083824029831\n",
      "2   0.606240757897077\n",
      "3   0.6209681852381319\n",
      "4   0.556137928468764\n",
      "5   0.4381393935511763\n",
      "6   0.630783227425957\n",
      "7   0.5573664283666544\n",
      "8   nan\n",
      "9   0.6408324093289102\n",
      "10   0.49892525904487084\n",
      "11   0.46167696233447675\n",
      "12   0.6792925670333688\n",
      "13   0.6266449039236259\n",
      "14   nan\n",
      "15   [[1.4002289  1.40221893 1.49637238        nan]]\n",
      "16   [[nan]]\n",
      "17   0.6419719932458458\n",
      "18   0.5328653725509389\n",
      "19   0.5692298633470927\n",
      "20   [[1.40337925 1.35857195        nan]]\n",
      "21   0.6034983793563642\n",
      "22   [[nan]]\n",
      "23   0.6407499706994069\n",
      "24   0.5659237130434658\n",
      "25   0.7309730522732151\n",
      "26   nan\n",
      "27   [[1.19587968        nan]]\n",
      "28   0.8004759224384494\n",
      "29   0.8328352104010938\n",
      "30   0.7578483115541701\n",
      "31   [[nan]]\n",
      "32   [[nan]]\n",
      "33   0.7379399512771065\n",
      "34   0.7842682093828542\n",
      "35   0.7411595277220534\n",
      "36   0.7189297113491893\n",
      "37   0.7589339070131473\n",
      "38   [[nan]]\n",
      "39   [[nan]]\n",
      "40   [[nan]]\n",
      "41   [[nan]]\n",
      "42   [[nan]]\n",
      "43   [[nan]]\n",
      "44   nan\n",
      "45   0.7193360238488018\n",
      "46   [[nan]]\n",
      "47   0.8099572713694888\n",
      "48   [[nan]]\n",
      "49   [[1.11213587        nan]]\n",
      "50   0.7714368209357569\n",
      "51   0.6881163148184392\n",
      "52   0.7496141301865205\n",
      "53   0.7691778818095429\n",
      "54   0.8322241210497314\n",
      "55   0.7608831245225544\n",
      "56   0.6944607439572954\n",
      "57   0.7809644202850675\n",
      "58   0.6745234861815399\n",
      "59   0.7734709901919204\n",
      "60   0.7760102591616876\n",
      "61   0.7087129415215643\n",
      "62   0.7181294865806593\n",
      "63   [[nan]]\n",
      "64   nan\n",
      "65   0.6924379769292117\n",
      "66   [[nan]]\n",
      "67   [[1.1952682       nan]]\n",
      "68   0.6443060826116153\n",
      "69   0.6848335654958186\n",
      "70   0.8134494139567297\n",
      "71   0.6605163157714746\n",
      "72   [[nan]]\n",
      "73   [[nan]]\n",
      "74   [[nan]]\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(75):\n",
    "    label = \"KG_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 1. , 2. ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrnr_tune[5]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
