{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660687406024,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "T7Wci76Yf-U8"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "\n",
    "  xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "  xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "  xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "  y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "  f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "\n",
    "  nan_flag = 0  \n",
    "  for i in range(max_iter):\n",
    "    train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    \n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    \n",
    "    if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "  return nan_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 76.16456 Test MSE 4.377091124158396 Test RE 1.0000019670949676\n",
      "1 Train Loss 76.16456 Test MSE 4.377091282519831 Test RE 1.0000019851848068\n",
      "2 Train Loss 76.16456 Test MSE 4.377091441098072 Test RE 1.0000020032994108\n",
      "3 Train Loss 76.16456 Test MSE 4.377091599903286 Test RE 1.0000020214399428\n",
      "4 Train Loss 76.16456 Test MSE 4.377091759839104 Test RE 1.000002039709624\n",
      "5 Train Loss 76.16456 Test MSE 4.37709192517481 Test RE 1.000002058596142\n",
      "6 Train Loss 76.16456 Test MSE 4.377092119392658 Test RE 1.0000020807819048\n",
      "7 Train Loss 57.53784 Test MSE 8.694741706527635 Test RE 1.4094069306698898\n",
      "8 Train Loss 57.478184 Test MSE 8.954131507869286 Test RE 1.4302758132152387\n",
      "9 Train Loss 57.107986 Test MSE 8.678523186093171 Test RE 1.408091816002751\n",
      "10 Train Loss 52.30075 Test MSE 7.974207756101502 Test RE 1.3497453298111202\n",
      "11 Train Loss 51.46651 Test MSE 8.259366829198832 Test RE 1.3736669135757664\n",
      "12 Train Loss 51.082848 Test MSE 8.093557571426446 Test RE 1.3598086216828504\n",
      "13 Train Loss 50.55265 Test MSE 7.931386822623518 Test RE 1.346116432890318\n",
      "14 Train Loss 50.192364 Test MSE 7.869379462460174 Test RE 1.3408441577501435\n",
      "15 Train Loss 49.69825 Test MSE 8.213520467078792 Test RE 1.3698491107085597\n",
      "16 Train Loss 47.362713 Test MSE 7.023385875033074 Test RE 1.266722034727987\n",
      "17 Train Loss 42.77822 Test MSE 4.772062543104666 Test RE 1.044145746740556\n",
      "18 Train Loss 36.35808 Test MSE 3.8426452393570205 Test RE 0.9369646498479807\n",
      "19 Train Loss 33.39711 Test MSE 3.9661641973405284 Test RE 0.9519045554560106\n",
      "20 Train Loss 32.150005 Test MSE 3.6876522374913128 Test RE 0.9178739395383337\n",
      "21 Train Loss 30.67537 Test MSE 3.337708321756154 Test RE 0.8732372454930103\n",
      "22 Train Loss 30.10684 Test MSE 3.1956518880383373 Test RE 0.8544522394919621\n",
      "23 Train Loss 29.064621 Test MSE 3.208011955454721 Test RE 0.8561030599463888\n",
      "24 Train Loss 27.757656 Test MSE 2.95542546954838 Test RE 0.8217090423826318\n",
      "25 Train Loss 23.96054 Test MSE 2.4644457175495806 Test RE 0.7503565685128856\n",
      "26 Train Loss 21.50077 Test MSE 1.9457473990870033 Test RE 0.6667319844296172\n",
      "27 Train Loss 18.113083 Test MSE 1.8610651988864768 Test RE 0.6520619438612123\n",
      "28 Train Loss 15.633269 Test MSE 1.5935006488077859 Test RE 0.6033706525084924\n",
      "29 Train Loss 12.603243 Test MSE 1.1450297926463389 Test RE 0.5114656286002037\n",
      "30 Train Loss 10.608799 Test MSE 0.9544389664052932 Test RE 0.46696264595305714\n",
      "31 Train Loss 8.50679 Test MSE 0.8472497134071288 Test RE 0.43996058980221336\n",
      "32 Train Loss 6.6090374 Test MSE 0.5708594316343168 Test RE 0.3611375527093761\n",
      "33 Train Loss 4.360314 Test MSE 0.29085890143592086 Test RE 0.25778001226415037\n",
      "34 Train Loss 3.068332 Test MSE 0.20733071652791732 Test RE 0.21764058499776584\n",
      "35 Train Loss 2.4647017 Test MSE 0.2291986126609105 Test RE 0.2288305753469418\n",
      "36 Train Loss 2.0679033 Test MSE 0.16665430145201474 Test RE 0.1951265311867082\n",
      "37 Train Loss 1.7792768 Test MSE 0.14028898840575843 Test RE 0.17902754329164355\n",
      "38 Train Loss 1.403924 Test MSE 0.09998020427801238 Test RE 0.15113500689306328\n",
      "39 Train Loss 1.3423322 Test MSE 0.08957537113004253 Test RE 0.14305477821708104\n",
      "40 Train Loss 1.139909 Test MSE 0.05712522505571284 Test RE 0.11424100691833815\n",
      "41 Train Loss 1.0025674 Test MSE 0.050161356972680204 Test RE 0.10705148560128744\n",
      "42 Train Loss 0.8638937 Test MSE 0.03477887042654413 Test RE 0.08913859748243015\n",
      "43 Train Loss 0.6658903 Test MSE 0.03875704583078435 Test RE 0.09409865015899065\n",
      "44 Train Loss 0.64258665 Test MSE 0.04317989508148685 Test RE 0.0993227765454928\n",
      "45 Train Loss 0.5558699 Test MSE 0.038364637713885694 Test RE 0.09362107228347648\n",
      "46 Train Loss 0.48954412 Test MSE 0.037651329762478605 Test RE 0.09274664742717473\n",
      "47 Train Loss 0.46639526 Test MSE 0.03419152664919781 Test RE 0.08838270851222378\n",
      "48 Train Loss 0.40407282 Test MSE 0.02254121740440133 Test RE 0.07176236520585565\n",
      "49 Train Loss 0.3758816 Test MSE 0.017094534804052153 Test RE 0.0624937669718364\n",
      "50 Train Loss 0.3388609 Test MSE 0.015970383512999623 Test RE 0.06040400474218563\n",
      "51 Train Loss 0.33186147 Test MSE 0.014536281793280221 Test RE 0.057628156509522986\n",
      "52 Train Loss 0.31494927 Test MSE 0.018724796459148853 Test RE 0.06540585286624655\n",
      "53 Train Loss 0.3095954 Test MSE 0.021038597196946663 Test RE 0.0693292416345914\n",
      "54 Train Loss 0.29949892 Test MSE 0.02151827103737531 Test RE 0.07011513055052283\n",
      "55 Train Loss 0.23658209 Test MSE 0.02022145370264262 Test RE 0.06796952689306762\n",
      "56 Train Loss 0.21654446 Test MSE 0.01568164462361237 Test RE 0.05985547258820416\n",
      "57 Train Loss 0.20738424 Test MSE 0.016451271959592468 Test RE 0.06130668045252554\n",
      "58 Train Loss 0.19050433 Test MSE 0.01260922970039671 Test RE 0.053672563491766453\n",
      "59 Train Loss 0.16125846 Test MSE 0.010035604051627766 Test RE 0.047882830985183276\n",
      "60 Train Loss 0.12569056 Test MSE 0.00932974345571157 Test RE 0.04616819665924448\n",
      "61 Train Loss 0.12137852 Test MSE 0.009173629334809393 Test RE 0.04578030212026215\n",
      "62 Train Loss 0.117894016 Test MSE 0.008285753338928635 Test RE 0.04350849496396464\n",
      "63 Train Loss 0.111718945 Test MSE 0.006881240391066261 Test RE 0.03964983872884599\n",
      "64 Train Loss 0.10820139 Test MSE 0.006752402271065231 Test RE 0.039276900987630106\n",
      "65 Train Loss 0.09806988 Test MSE 0.007211670761931184 Test RE 0.04059065000307011\n",
      "66 Train Loss 0.08023116 Test MSE 0.00437849929463502 Test RE 0.03162792514894198\n",
      "67 Train Loss 0.07755928 Test MSE 0.0034409092020467598 Test RE 0.028037847330780522\n",
      "68 Train Loss 0.076257 Test MSE 0.003123487408541763 Test RE 0.02671332451761768\n",
      "69 Train Loss 0.0738318 Test MSE 0.0030733667341878474 Test RE 0.026498131645315882\n",
      "70 Train Loss 0.06390659 Test MSE 0.004247575835939764 Test RE 0.031151476147889802\n",
      "71 Train Loss 0.058754534 Test MSE 0.003818733551105527 Test RE 0.029537092205341835\n",
      "72 Train Loss 0.054216336 Test MSE 0.0035486410638530265 Test RE 0.028473384786264055\n",
      "73 Train Loss 0.051711038 Test MSE 0.0032417691596771086 Test RE 0.02721442128271145\n",
      "74 Train Loss 0.049790636 Test MSE 0.0032608544355499907 Test RE 0.027294413486954893\n",
      "75 Train Loss 0.048552398 Test MSE 0.003553967616871724 Test RE 0.02849474622024472\n",
      "76 Train Loss 0.047689483 Test MSE 0.003361173534656271 Test RE 0.02771108483762956\n",
      "77 Train Loss 0.047072906 Test MSE 0.0031783330253795043 Test RE 0.026946834842312594\n",
      "78 Train Loss 0.045000758 Test MSE 0.003099845292718958 Test RE 0.026612034026474246\n",
      "79 Train Loss 0.039136346 Test MSE 0.0030969868777807174 Test RE 0.026599761514070376\n",
      "80 Train Loss 0.03719771 Test MSE 0.0030242127880087135 Test RE 0.026285378375536878\n",
      "81 Train Loss 0.036482092 Test MSE 0.002748652974789468 Test RE 0.02505924697965286\n",
      "82 Train Loss 0.036036357 Test MSE 0.002533979139998423 Test RE 0.02406077312086991\n",
      "83 Train Loss 0.035474673 Test MSE 0.002458568979419911 Test RE 0.023700049829672235\n",
      "84 Train Loss 0.03494029 Test MSE 0.002509331234509038 Test RE 0.02394346811893153\n",
      "85 Train Loss 0.034194637 Test MSE 0.002614506037282853 Test RE 0.02444009472357189\n",
      "86 Train Loss 0.032255154 Test MSE 0.0023383881685596192 Test RE 0.02311353451622367\n",
      "87 Train Loss 0.030334447 Test MSE 0.0020658564831125374 Test RE 0.021724917404230507\n",
      "88 Train Loss 0.028463345 Test MSE 0.001833137116992857 Test RE 0.020464707221344653\n",
      "89 Train Loss 0.02581791 Test MSE 0.0022100708524820066 Test RE 0.02247041838273623\n",
      "90 Train Loss 0.022218274 Test MSE 0.002204152705367806 Test RE 0.022440312473037207\n",
      "91 Train Loss 0.02054241 Test MSE 0.0016000585412821555 Test RE 0.01911947648192647\n",
      "92 Train Loss 0.019872442 Test MSE 0.001635898214186522 Test RE 0.01933241900946233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 0.019177182 Test MSE 0.0017468206985648321 Test RE 0.01997708994363847\n",
      "94 Train Loss 0.018983537 Test MSE 0.0017075581253801395 Test RE 0.019751305584527888\n",
      "95 Train Loss 0.018846152 Test MSE 0.0017046823746540356 Test RE 0.019734666687944328\n",
      "96 Train Loss 0.018527605 Test MSE 0.0017271305829842417 Test RE 0.01986418025492321\n",
      "97 Train Loss 0.018115856 Test MSE 0.001663666578397496 Test RE 0.01949580652685575\n",
      "98 Train Loss 0.017161481 Test MSE 0.001529906027137258 Test RE 0.018695644360475272\n",
      "99 Train Loss 0.015555727 Test MSE 0.0013937352210574372 Test RE 0.01784424584050425\n",
      "100 Train Loss 0.01454356 Test MSE 0.001369165636658212 Test RE 0.017686262055222224\n",
      "101 Train Loss 0.014229769 Test MSE 0.0013896094417908819 Test RE 0.017817814713805537\n",
      "102 Train Loss 0.014060677 Test MSE 0.0013923857320420287 Test RE 0.017835604871529482\n",
      "103 Train Loss 0.013940329 Test MSE 0.0013728480726717652 Test RE 0.01771003010556545\n",
      "104 Train Loss 0.013823925 Test MSE 0.001341243920723338 Test RE 0.017504993084721313\n",
      "105 Train Loss 0.013729335 Test MSE 0.0013171358315990068 Test RE 0.017346958621623203\n",
      "106 Train Loss 0.013577674 Test MSE 0.001336678565536298 Test RE 0.017475175752050702\n",
      "107 Train Loss 0.0133127235 Test MSE 0.0014114035959077828 Test RE 0.01795699534496826\n",
      "108 Train Loss 0.013017852 Test MSE 0.0013208564683854442 Test RE 0.017371442131914452\n",
      "109 Train Loss 0.012525974 Test MSE 0.001040334487918525 Test RE 0.015416811354118267\n",
      "110 Train Loss 0.012055621 Test MSE 0.000983358135125366 Test RE 0.014988698292035908\n",
      "111 Train Loss 0.011787644 Test MSE 0.0010822099901224762 Test RE 0.015724028764630065\n",
      "112 Train Loss 0.011665979 Test MSE 0.0011149481855923936 Test RE 0.015960092454812468\n",
      "113 Train Loss 0.011503467 Test MSE 0.0010696719276828027 Test RE 0.015632677173606703\n",
      "114 Train Loss 0.011133814 Test MSE 0.0010481269293598433 Test RE 0.015474442086317444\n",
      "115 Train Loss 0.010635454 Test MSE 0.0010750691262308625 Test RE 0.0156720661204064\n",
      "116 Train Loss 0.010251301 Test MSE 0.0010039995015910397 Test RE 0.015145192889478217\n",
      "117 Train Loss 0.010079391 Test MSE 0.000948040495536356 Test RE 0.014717075050426071\n",
      "118 Train Loss 0.009955402 Test MSE 0.0008947373089835481 Test RE 0.014297359380449737\n",
      "119 Train Loss 0.009793927 Test MSE 0.000879209757150886 Test RE 0.014172755983793533\n",
      "120 Train Loss 0.009637893 Test MSE 0.0009057631982808621 Test RE 0.01438518315568951\n",
      "121 Train Loss 0.009514322 Test MSE 0.0009209428261502066 Test RE 0.014505222497534952\n",
      "122 Train Loss 0.00945884 Test MSE 0.0009070460307858362 Test RE 0.014395366419470439\n",
      "123 Train Loss 0.0094042355 Test MSE 0.0008766519730842151 Test RE 0.014152125381897519\n",
      "124 Train Loss 0.009326958 Test MSE 0.0008660873807041993 Test RE 0.014066592799717998\n",
      "125 Train Loss 0.009264201 Test MSE 0.0008652130965706622 Test RE 0.014059491146705317\n",
      "126 Train Loss 0.009187938 Test MSE 0.0008335229955902211 Test RE 0.013799611287119738\n",
      "127 Train Loss 0.009102129 Test MSE 0.0007888137757401034 Test RE 0.01342441296344016\n",
      "128 Train Loss 0.008975783 Test MSE 0.0007997159640079367 Test RE 0.01351686396534796\n",
      "129 Train Loss 0.008855311 Test MSE 0.000805944687798168 Test RE 0.013569401062117185\n",
      "130 Train Loss 0.008766717 Test MSE 0.000798616637681853 Test RE 0.013507570319101075\n",
      "131 Train Loss 0.008699943 Test MSE 0.0008026239738559717 Test RE 0.013541417373628233\n",
      "132 Train Loss 0.00863207 Test MSE 0.0008131258535343486 Test RE 0.01362972034851138\n",
      "133 Train Loss 0.008538313 Test MSE 0.0007853800972270091 Test RE 0.01339516310000961\n",
      "134 Train Loss 0.008354987 Test MSE 0.000725776863991117 Test RE 0.01287684951032602\n",
      "135 Train Loss 0.008158164 Test MSE 0.0007265953842649688 Test RE 0.01288410862320351\n",
      "136 Train Loss 0.0078661945 Test MSE 0.000745059433422224 Test RE 0.013046785407110677\n",
      "137 Train Loss 0.007363339 Test MSE 0.0006503767112327846 Test RE 0.012189630777200259\n",
      "138 Train Loss 0.006853982 Test MSE 0.0005746254785876524 Test RE 0.011457780537603296\n",
      "139 Train Loss 0.0063631423 Test MSE 0.0005590526573884562 Test RE 0.011301456516271492\n",
      "140 Train Loss 0.005662623 Test MSE 0.0005194577735634422 Test RE 0.010893895003058587\n",
      "141 Train Loss 0.005357244 Test MSE 0.0004890987738358875 Test RE 0.010570763277372526\n",
      "142 Train Loss 0.005040083 Test MSE 0.0005528533736287942 Test RE 0.011238621428974846\n",
      "143 Train Loss 0.0049118446 Test MSE 0.0005573011828763822 Test RE 0.011283739275690614\n",
      "144 Train Loss 0.0048173144 Test MSE 0.0005609200980452248 Test RE 0.011320316282015446\n",
      "145 Train Loss 0.0047532897 Test MSE 0.0005851129580350995 Test RE 0.011561865646074969\n",
      "146 Train Loss 0.004690575 Test MSE 0.0006081192601089426 Test RE 0.011786977092395793\n",
      "147 Train Loss 0.0046025245 Test MSE 0.0006178139154264782 Test RE 0.011880559762283747\n",
      "148 Train Loss 0.004498675 Test MSE 0.000595299726460731 Test RE 0.011662076925098895\n",
      "149 Train Loss 0.0042836415 Test MSE 0.0005715564383769416 Test RE 0.011427141913806777\n",
      "Training time: 82.57\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 76.34357 Test MSE 4.377077910437207 Test RE 1.0000004576727541\n",
      "1 Train Loss 57.678032 Test MSE 8.697513921051346 Test RE 1.4096315990444803\n",
      "2 Train Loss 57.52371 Test MSE 9.073994125896192 Test RE 1.4398170337353466\n",
      "3 Train Loss 57.12372 Test MSE 8.756149541678115 Test RE 1.4143752410108932\n",
      "4 Train Loss 54.601795 Test MSE 8.168574383394047 Test RE 1.366095920202385\n",
      "5 Train Loss 53.801838 Test MSE 8.756465061658375 Test RE 1.4144007236517446\n",
      "6 Train Loss 52.741013 Test MSE 8.677567458088319 Test RE 1.408014280354945\n",
      "7 Train Loss 51.553497 Test MSE 8.768624444699443 Test RE 1.4153824139655653\n",
      "8 Train Loss 51.331394 Test MSE 8.81304248209965 Test RE 1.418962741431921\n",
      "9 Train Loss 49.520416 Test MSE 8.947718777136137 Test RE 1.4297635571449245\n",
      "10 Train Loss 45.030334 Test MSE 8.779238481759927 Test RE 1.4162387842031698\n",
      "11 Train Loss 44.245598 Test MSE 8.47254477361974 Test RE 1.391281455950383\n",
      "12 Train Loss 44.1154 Test MSE 8.506268093365245 Test RE 1.3940475690668277\n",
      "13 Train Loss 44.027103 Test MSE 8.550883756339266 Test RE 1.397698701003582\n",
      "14 Train Loss 43.958805 Test MSE 8.524707858692796 Test RE 1.3955577491834952\n",
      "15 Train Loss 43.865074 Test MSE 8.560127289025647 Test RE 1.398453955333443\n",
      "16 Train Loss 43.83098 Test MSE 8.529056121941618 Test RE 1.39591362524108\n",
      "17 Train Loss 43.785553 Test MSE 8.522608602268331 Test RE 1.3953859066992083\n",
      "18 Train Loss 43.71234 Test MSE 8.608742688790691 Test RE 1.4024194420843645\n",
      "19 Train Loss 43.598183 Test MSE 8.542481128995354 Test RE 1.3970117996109386\n",
      "20 Train Loss 43.524483 Test MSE 8.570951086809883 Test RE 1.3993378090716073\n",
      "21 Train Loss 43.444748 Test MSE 8.497115504046441 Test RE 1.3932973823368797\n",
      "22 Train Loss 42.75576 Test MSE 8.349993958575613 Test RE 1.381182734833999\n",
      "23 Train Loss 40.57491 Test MSE 7.506979599759547 Test RE 1.3096060662606754\n",
      "24 Train Loss 39.959568 Test MSE 7.925388902907642 Test RE 1.3456073526075525\n",
      "25 Train Loss 39.5818 Test MSE 7.686975729477433 Test RE 1.325213389530936\n",
      "26 Train Loss 39.27947 Test MSE 7.6818205358905285 Test RE 1.3247689444331598\n",
      "27 Train Loss 39.05749 Test MSE 7.727257708336941 Test RE 1.3286811034725723\n",
      "28 Train Loss 38.85549 Test MSE 7.709805763303493 Test RE 1.3271798479314751\n",
      "29 Train Loss 38.768085 Test MSE 7.77097858551094 Test RE 1.332434644974151\n",
      "30 Train Loss 38.676376 Test MSE 7.739575575929872 Test RE 1.3297396938115829\n",
      "31 Train Loss 38.62962 Test MSE 7.73673055047688 Test RE 1.3294952688449155\n",
      "32 Train Loss 38.58474 Test MSE 7.753401909951862 Test RE 1.3309269179153096\n",
      "33 Train Loss 38.46769 Test MSE 7.703368137708991 Test RE 1.3266256399861605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 38.355755 Test MSE 7.704369748151908 Test RE 1.3267118827102322\n",
      "35 Train Loss 38.261 Test MSE 7.7052674192319905 Test RE 1.326789171069883\n",
      "36 Train Loss 38.160896 Test MSE 7.709988489246237 Test RE 1.3271955752247082\n",
      "37 Train Loss 37.95091 Test MSE 7.9101535723330505 Test RE 1.344313369753091\n",
      "38 Train Loss 37.751984 Test MSE 7.727610953279739 Test RE 1.3287114728826688\n",
      "39 Train Loss 37.461937 Test MSE 7.857711255074631 Test RE 1.3398497304561567\n",
      "40 Train Loss 36.994774 Test MSE 7.755478809164133 Test RE 1.3311051632850883\n",
      "41 Train Loss 36.666092 Test MSE 7.9508429313768 Test RE 1.3477664687851225\n",
      "42 Train Loss 36.233963 Test MSE 7.88047495427962 Test RE 1.3417890915310369\n",
      "43 Train Loss 36.084675 Test MSE 7.89418562223417 Test RE 1.3429558251310503\n",
      "44 Train Loss 35.936207 Test MSE 7.873976909224816 Test RE 1.341235774368551\n",
      "45 Train Loss 35.897484 Test MSE 7.8245972398087185 Test RE 1.337023548282397\n",
      "46 Train Loss 35.807983 Test MSE 7.883453456727278 Test RE 1.3420426387192939\n",
      "47 Train Loss 35.73834 Test MSE 7.863736236835249 Test RE 1.340363303880222\n",
      "48 Train Loss 35.64074 Test MSE 7.796648638227018 Test RE 1.3346335615789071\n",
      "49 Train Loss 35.4985 Test MSE 7.918106624650431 Test RE 1.3449890019306965\n",
      "50 Train Loss 35.40879 Test MSE 7.960276472006694 Test RE 1.3485657828194666\n",
      "51 Train Loss 35.257027 Test MSE 7.944459805481015 Test RE 1.3472253506620535\n",
      "52 Train Loss 35.076508 Test MSE 7.956712612150182 Test RE 1.348263868839221\n",
      "53 Train Loss 34.955563 Test MSE 7.9831703922458015 Test RE 1.3505036420701158\n",
      "54 Train Loss 34.70285 Test MSE 7.977505402281754 Test RE 1.3500243871544113\n",
      "55 Train Loss 34.540504 Test MSE 7.937980467509127 Test RE 1.3466758539602293\n",
      "56 Train Loss 34.276802 Test MSE 7.782786223518795 Test RE 1.3334465467550256\n",
      "57 Train Loss 33.94066 Test MSE 7.81627794185294 Test RE 1.3363125816288246\n",
      "58 Train Loss 33.41076 Test MSE 7.66192474407999 Test RE 1.3230522670262694\n",
      "59 Train Loss 32.88036 Test MSE 7.548128310952243 Test RE 1.3131903944594763\n",
      "60 Train Loss 32.37497 Test MSE 7.589682619286426 Test RE 1.3168001516580154\n",
      "61 Train Loss 31.927307 Test MSE 7.639985625611078 Test RE 1.32115669836329\n",
      "62 Train Loss 31.694883 Test MSE 7.684609165136415 Test RE 1.325009379248961\n",
      "63 Train Loss 31.476627 Test MSE 7.670559634611878 Test RE 1.3237975885281472\n",
      "64 Train Loss 31.202724 Test MSE 7.686447600303413 Test RE 1.3251678647433516\n",
      "65 Train Loss 31.020432 Test MSE 7.649846843816003 Test RE 1.3220090568514087\n",
      "66 Train Loss 30.681171 Test MSE 7.4528926105333575 Test RE 1.3048797515439234\n",
      "67 Train Loss 30.495535 Test MSE 7.562215801169683 Test RE 1.3144152632237767\n",
      "68 Train Loss 30.207209 Test MSE 7.529519534730901 Test RE 1.311570658736323\n",
      "69 Train Loss 29.926714 Test MSE 7.45696445532081 Test RE 1.3052361596241204\n",
      "70 Train Loss 29.769533 Test MSE 7.24833211351228 Test RE 1.2868475569265165\n",
      "71 Train Loss 29.57912 Test MSE 7.277101262123306 Test RE 1.289398822893218\n",
      "72 Train Loss 29.523808 Test MSE 7.256276003590548 Test RE 1.2875525312590355\n",
      "73 Train Loss 29.368462 Test MSE 7.178870802348753 Test RE 1.280666735054082\n",
      "74 Train Loss 29.22505 Test MSE 7.050152746641764 Test RE 1.2691335455762653\n",
      "75 Train Loss 28.999294 Test MSE 6.856330975589983 Test RE 1.251566549657643\n",
      "76 Train Loss 27.729322 Test MSE 6.3588197224698515 Test RE 1.205303219366673\n",
      "77 Train Loss 27.395302 Test MSE 6.2291368544344605 Test RE 1.1929493270064377\n",
      "78 Train Loss 26.817522 Test MSE 6.371339210692438 Test RE 1.2064891595321614\n",
      "79 Train Loss 26.268604 Test MSE 6.217247205259306 Test RE 1.1918102828687571\n",
      "80 Train Loss 25.2864 Test MSE 6.273218023226723 Test RE 1.1971629039349143\n",
      "81 Train Loss 24.955418 Test MSE 6.232817881612165 Test RE 1.1933017538712105\n",
      "82 Train Loss 24.599564 Test MSE 6.462994660036113 Test RE 1.21513619928658\n",
      "83 Train Loss 24.268646 Test MSE 6.5428006884977705 Test RE 1.2226155232913443\n",
      "84 Train Loss 24.082388 Test MSE 6.520539653500081 Test RE 1.2205338553609892\n",
      "85 Train Loss 23.91859 Test MSE 6.61737988246623 Test RE 1.2295638713812955\n",
      "86 Train Loss 23.784773 Test MSE 6.734251581955223 Test RE 1.240374212874611\n",
      "87 Train Loss 23.662579 Test MSE 6.73752457788531 Test RE 1.2406756009754278\n",
      "88 Train Loss 23.472063 Test MSE 6.718894502183922 Test RE 1.2389591040334136\n",
      "89 Train Loss 23.350502 Test MSE 6.757345564128812 Test RE 1.2424992198762237\n",
      "90 Train Loss 23.273071 Test MSE 6.842331025767751 Test RE 1.2502881091490656\n",
      "91 Train Loss 23.18341 Test MSE 6.8603396714707845 Test RE 1.2519323733437524\n",
      "92 Train Loss 23.104202 Test MSE 6.729526265455375 Test RE 1.2399389611473561\n",
      "93 Train Loss 23.037975 Test MSE 6.698163337891447 Test RE 1.2370462217738545\n",
      "94 Train Loss 22.934862 Test MSE 6.734966447892938 Test RE 1.2404400463034333\n",
      "95 Train Loss 22.796698 Test MSE 6.768130534580677 Test RE 1.2434903616388644\n",
      "96 Train Loss 22.698692 Test MSE 6.77440398453088 Test RE 1.2440665301719498\n",
      "97 Train Loss 22.61822 Test MSE 6.742466407193355 Test RE 1.2411305220010092\n",
      "98 Train Loss 22.53787 Test MSE 6.655802393817578 Test RE 1.2331283148861554\n",
      "99 Train Loss 22.386871 Test MSE 6.573431099260352 Test RE 1.2254740459425062\n",
      "100 Train Loss 22.321617 Test MSE 6.57474519700193 Test RE 1.2255965323713034\n",
      "101 Train Loss 22.267042 Test MSE 6.551535148723906 Test RE 1.2234313302782702\n",
      "102 Train Loss 22.208748 Test MSE 6.499846876436295 Test RE 1.218595648887042\n",
      "103 Train Loss 22.136312 Test MSE 6.408373564989047 Test RE 1.2099905274555443\n",
      "104 Train Loss 22.03864 Test MSE 6.403631443743527 Test RE 1.2095427552072073\n",
      "105 Train Loss 21.95894 Test MSE 6.302350439649698 Test RE 1.1999394574600577\n",
      "106 Train Loss 21.885122 Test MSE 6.190953589718893 Test RE 1.1892874457726015\n",
      "107 Train Loss 21.672188 Test MSE 6.05093698240919 Test RE 1.1757618791459288\n",
      "108 Train Loss 21.473213 Test MSE 5.952537434091254 Test RE 1.1661626506412939\n",
      "109 Train Loss 21.249908 Test MSE 5.73418240454303 Test RE 1.1445738309365356\n",
      "110 Train Loss 20.209042 Test MSE 5.420653039903388 Test RE 1.11284291559149\n",
      "111 Train Loss 19.008934 Test MSE 4.859712050938983 Test RE 1.0536911412992618\n",
      "112 Train Loss 18.34573 Test MSE 4.663370035724501 Test RE 1.0321860830781489\n",
      "113 Train Loss 18.099033 Test MSE 4.570995945298177 Test RE 1.0219119513743933\n",
      "114 Train Loss 17.875137 Test MSE 4.560288556422112 Test RE 1.0207143541636177\n",
      "115 Train Loss 17.474417 Test MSE 4.6103166474518344 Test RE 1.026297893893764\n",
      "116 Train Loss 17.277948 Test MSE 4.6484022802599885 Test RE 1.0305282770756514\n",
      "117 Train Loss 17.060812 Test MSE 4.692366903194463 Test RE 1.03539018016105\n",
      "118 Train Loss 16.871313 Test MSE 4.697764459199174 Test RE 1.0359855055490803\n",
      "119 Train Loss 16.50655 Test MSE 4.755252898995075 Test RE 1.0423051168182689\n",
      "120 Train Loss 16.046566 Test MSE 4.843297863194014 Test RE 1.0519101599281864\n",
      "121 Train Loss 15.793018 Test MSE 4.8700824052848555 Test RE 1.0548148012117373\n",
      "122 Train Loss 15.511206 Test MSE 4.923934316214766 Test RE 1.0606306807412533\n",
      "123 Train Loss 15.202838 Test MSE 4.8420878335134585 Test RE 1.0517787492591426\n",
      "124 Train Loss 14.938501 Test MSE 4.818180673692917 Test RE 1.0491790280284612\n",
      "125 Train Loss 14.474368 Test MSE 4.756214918399273 Test RE 1.0424105441277913\n",
      "126 Train Loss 14.29713 Test MSE 4.6173838456805845 Test RE 1.0270842035741083\n",
      "127 Train Loss 13.990523 Test MSE 4.649618412779166 Test RE 1.0306630736051108\n",
      "128 Train Loss 13.7335205 Test MSE 4.452297609286471 Test RE 1.008556316279921\n",
      "129 Train Loss 13.344357 Test MSE 4.3583755271841165 Test RE 0.9978617691583052\n",
      "130 Train Loss 12.803269 Test MSE 4.320958354910446 Test RE 0.9935691551630099\n",
      "131 Train Loss 12.630561 Test MSE 4.312710942675706 Test RE 0.9926204896565153\n",
      "132 Train Loss 12.363928 Test MSE 4.379474402781729 Test RE 1.0002741751566908\n",
      "133 Train Loss 12.088381 Test MSE 4.252398389468955 Test RE 0.985655234786308\n",
      "134 Train Loss 11.937705 Test MSE 4.229443453986857 Test RE 0.9829912947097516\n",
      "135 Train Loss 11.732578 Test MSE 4.208132254352656 Test RE 0.9805116328344784\n",
      "136 Train Loss 11.443573 Test MSE 4.061424862585528 Test RE 0.9632683075610331\n",
      "137 Train Loss 10.957089 Test MSE 4.121315304640989 Test RE 0.9703445728922132\n",
      "138 Train Loss 10.260278 Test MSE 4.134518097058759 Test RE 0.9718975982112646\n",
      "139 Train Loss 9.777634 Test MSE 4.159855593567969 Test RE 0.9748710812936433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 Train Loss 9.570339 Test MSE 4.154616675602029 Test RE 0.9742570120617579\n",
      "141 Train Loss 9.323962 Test MSE 4.110568413879934 Test RE 0.9690785942589774\n",
      "142 Train Loss 9.075986 Test MSE 4.056907945654361 Test RE 0.9627325087353797\n",
      "143 Train Loss 8.901927 Test MSE 4.033598147823964 Test RE 0.9599627357491328\n",
      "144 Train Loss 8.730238 Test MSE 3.9919872458807864 Test RE 0.9549983754792616\n",
      "145 Train Loss 8.603149 Test MSE 3.9401933329533865 Test RE 0.9487828506865437\n",
      "146 Train Loss 8.297874 Test MSE 3.857861442518708 Test RE 0.9388179250795887\n",
      "147 Train Loss 8.071772 Test MSE 3.7351712179979146 Test RE 0.9237688584584332\n",
      "148 Train Loss 7.8563805 Test MSE 3.61444036881509 Test RE 0.9087168735558233\n",
      "149 Train Loss 7.3311663 Test MSE 3.5820875143586615 Test RE 0.9046407695452932\n",
      "Training time: 84.30\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 75.27209 Test MSE 4.377060614154774 Test RE 0.9999984818903035\n",
      "1 Train Loss 56.93312 Test MSE 8.396885133181302 Test RE 1.3850554687365286\n",
      "2 Train Loss 56.679443 Test MSE 8.690291566769156 Test RE 1.4090462034179572\n",
      "3 Train Loss 54.102165 Test MSE 8.948159959860586 Test RE 1.4297988051909265\n",
      "4 Train Loss 45.648373 Test MSE 8.022158297162658 Test RE 1.3537973947365822\n",
      "5 Train Loss 42.654068 Test MSE 7.9763086312356934 Test RE 1.3499231192381844\n",
      "6 Train Loss 41.658634 Test MSE 8.210010918764949 Test RE 1.3695564185968516\n",
      "7 Train Loss 41.51802 Test MSE 8.226232593271288 Test RE 1.3709087636437953\n",
      "8 Train Loss 41.26194 Test MSE 8.233879081046886 Test RE 1.3715457625462306\n",
      "9 Train Loss 41.186367 Test MSE 8.297328476157427 Test RE 1.3768201139217002\n",
      "10 Train Loss 41.024227 Test MSE 8.256485191061774 Test RE 1.3734272610470863\n",
      "11 Train Loss 40.915108 Test MSE 8.225355748131172 Test RE 1.3708356981969025\n",
      "12 Train Loss 40.227577 Test MSE 8.400462938901638 Test RE 1.385350514551039\n",
      "13 Train Loss 38.512245 Test MSE 7.94441831514147 Test RE 1.3472218326814989\n",
      "14 Train Loss 37.444336 Test MSE 7.95671348153455 Test RE 1.34826394249775\n",
      "15 Train Loss 34.65728 Test MSE 7.296782465141574 Test RE 1.2911412601658585\n",
      "16 Train Loss 31.113796 Test MSE 7.546880475149186 Test RE 1.3130818434616238\n",
      "17 Train Loss 27.808496 Test MSE 6.611854126308537 Test RE 1.229050398585924\n",
      "18 Train Loss 26.747343 Test MSE 6.6800136164507435 Test RE 1.235369099764899\n",
      "19 Train Loss 25.8042 Test MSE 6.605441022422644 Test RE 1.2284542012154018\n",
      "20 Train Loss 25.234365 Test MSE 6.727147036045086 Test RE 1.2397197510629063\n",
      "21 Train Loss 24.376759 Test MSE 6.722912556189914 Test RE 1.2393295117352874\n",
      "22 Train Loss 24.003834 Test MSE 6.6394274173407135 Test RE 1.2316104751952115\n",
      "23 Train Loss 23.744453 Test MSE 6.6610775390847 Test RE 1.2336168842747277\n",
      "24 Train Loss 23.537376 Test MSE 6.633310267586337 Test RE 1.231042980337022\n",
      "25 Train Loss 23.346619 Test MSE 6.696435172847381 Test RE 1.2368866289242326\n",
      "26 Train Loss 23.31282 Test MSE 6.667690509233005 Test RE 1.234229086118063\n",
      "27 Train Loss 23.243902 Test MSE 6.6620920255276666 Test RE 1.2337108210252459\n",
      "28 Train Loss 23.130898 Test MSE 6.67046923532334 Test RE 1.2344862386746531\n",
      "29 Train Loss 23.079811 Test MSE 6.608591047704773 Test RE 1.2287470810204157\n",
      "30 Train Loss 22.97642 Test MSE 6.669295148212521 Test RE 1.2343775912831623\n",
      "31 Train Loss 22.90704 Test MSE 6.669682661604896 Test RE 1.234413451961772\n",
      "32 Train Loss 22.856556 Test MSE 6.645948581471941 Test RE 1.2322151630996887\n",
      "33 Train Loss 22.830719 Test MSE 6.642781512574439 Test RE 1.2319215274126334\n",
      "34 Train Loss 22.753788 Test MSE 6.677200144668594 Test RE 1.235108917499668\n",
      "35 Train Loss 22.683716 Test MSE 6.636551541938056 Test RE 1.2313437095780513\n",
      "36 Train Loss 22.627941 Test MSE 6.630196179664669 Test RE 1.2307539823890299\n",
      "37 Train Loss 22.53909 Test MSE 6.59966691738354 Test RE 1.227917161041125\n",
      "38 Train Loss 22.520298 Test MSE 6.589087504970008 Test RE 1.226932577086532\n",
      "39 Train Loss 22.406256 Test MSE 6.588278878252919 Test RE 1.2268572888996536\n",
      "40 Train Loss 22.34227 Test MSE 6.591054782594897 Test RE 1.227115723604752\n",
      "41 Train Loss 22.26472 Test MSE 6.5371474404620695 Test RE 1.2220872141781263\n",
      "42 Train Loss 22.189804 Test MSE 6.540991627741552 Test RE 1.2224464872181644\n",
      "43 Train Loss 22.1232 Test MSE 6.534299884460388 Test RE 1.221821016967491\n",
      "44 Train Loss 22.030842 Test MSE 6.510005391692986 Test RE 1.2195475397327016\n",
      "45 Train Loss 21.932808 Test MSE 6.495030453251684 Test RE 1.218144072092883\n",
      "46 Train Loss 21.825356 Test MSE 6.46989326887809 Test RE 1.2157845452951355\n",
      "47 Train Loss 21.764418 Test MSE 6.3675307743690235 Test RE 1.2061285191842255\n",
      "48 Train Loss 21.49651 Test MSE 6.181450180538728 Test RE 1.1883742887132578\n",
      "49 Train Loss 21.329144 Test MSE 6.040235128018955 Test RE 1.174721676531316\n",
      "50 Train Loss 21.233786 Test MSE 6.0374671313298895 Test RE 1.1744524818518067\n",
      "51 Train Loss 21.09082 Test MSE 6.066944134852902 Test RE 1.1773160325870962\n",
      "52 Train Loss 20.998533 Test MSE 5.986344127532891 Test RE 1.1694694996946\n",
      "53 Train Loss 20.930275 Test MSE 5.943963972596436 Test RE 1.165322533855397\n",
      "54 Train Loss 20.725578 Test MSE 6.014685749385399 Test RE 1.1722345867298167\n",
      "55 Train Loss 20.606499 Test MSE 6.0513069180912495 Test RE 1.175797819829677\n",
      "56 Train Loss 20.495564 Test MSE 5.964354895462861 Test RE 1.167319657143089\n",
      "57 Train Loss 20.29069 Test MSE 6.026508492582161 Test RE 1.173386120264705\n",
      "58 Train Loss 20.15646 Test MSE 6.041424517289853 Test RE 1.1748373287000158\n",
      "59 Train Loss 19.968315 Test MSE 5.922013595574553 Test RE 1.163168842470327\n",
      "60 Train Loss 19.896358 Test MSE 5.85520959715827 Test RE 1.1565896011918382\n",
      "61 Train Loss 19.77879 Test MSE 5.873507728765757 Test RE 1.1583954221194106\n",
      "62 Train Loss 19.67788 Test MSE 5.899127151198911 Test RE 1.160919052905823\n",
      "63 Train Loss 19.634977 Test MSE 5.900097666448754 Test RE 1.1610145452794662\n",
      "64 Train Loss 19.541225 Test MSE 5.851269393292372 Test RE 1.1562003780837256\n",
      "65 Train Loss 19.439316 Test MSE 5.8339650408810515 Test RE 1.154489457632048\n",
      "66 Train Loss 19.297455 Test MSE 5.8208430820555686 Test RE 1.1531903676373256\n",
      "67 Train Loss 19.069706 Test MSE 5.55830180774682 Test RE 1.1268837664055067\n",
      "68 Train Loss 18.86199 Test MSE 5.475874679126815 Test RE 1.1184969661417496\n",
      "69 Train Loss 18.298399 Test MSE 4.945657287599195 Test RE 1.0629677036220666\n",
      "70 Train Loss 17.72181 Test MSE 4.778443492028713 Test RE 1.044843601690532\n",
      "71 Train Loss 17.396591 Test MSE 4.827670373847978 Test RE 1.05021173076935\n",
      "72 Train Loss 16.870476 Test MSE 4.567185508594317 Test RE 1.021485923578762\n",
      "73 Train Loss 16.573103 Test MSE 4.553500515771701 Test RE 1.0199543988771265\n",
      "74 Train Loss 16.07341 Test MSE 4.434878719121059 Test RE 1.0065814765616476\n",
      "75 Train Loss 15.643084 Test MSE 4.336309616211964 Test RE 0.9953325390453963\n",
      "76 Train Loss 15.372971 Test MSE 4.376480616764694 Test RE 0.9999322255854924\n",
      "77 Train Loss 14.730444 Test MSE 4.21117471852202 Test RE 0.9808660219457974\n",
      "78 Train Loss 14.349161 Test MSE 4.032693844359941 Test RE 0.9598551213740504\n",
      "79 Train Loss 13.847258 Test MSE 3.8820046694237575 Test RE 0.9417509934233711\n",
      "80 Train Loss 13.143309 Test MSE 3.7660569845752074 Test RE 0.9275802729315479\n",
      "81 Train Loss 12.959964 Test MSE 3.7966491705951966 Test RE 0.9313400825011204\n",
      "82 Train Loss 12.629575 Test MSE 3.718407861036867 Test RE 0.9216936014064212\n",
      "83 Train Loss 12.149752 Test MSE 3.4931776164727544 Test RE 0.8933433205953858\n",
      "84 Train Loss 11.942301 Test MSE 3.528540030395166 Test RE 0.8978537164741842\n",
      "85 Train Loss 11.515205 Test MSE 3.656291175758514 Test RE 0.9139626483566062\n",
      "86 Train Loss 11.296116 Test MSE 3.5932117650451154 Test RE 0.9060443714538686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 11.203445 Test MSE 3.61377872966069 Test RE 0.9086336974455543\n",
      "88 Train Loss 10.846157 Test MSE 3.557282704683691 Test RE 0.9015031544540596\n",
      "89 Train Loss 10.616343 Test MSE 3.5636524266638796 Test RE 0.9023099157745902\n",
      "90 Train Loss 10.523104 Test MSE 3.5126669391477554 Test RE 0.8958319485779886\n",
      "91 Train Loss 10.409939 Test MSE 3.449811903266132 Test RE 0.8877808411547237\n",
      "92 Train Loss 10.313585 Test MSE 3.4108029113853724 Test RE 0.8827472489771492\n",
      "93 Train Loss 10.151274 Test MSE 3.3455818592042803 Test RE 0.8742666068871718\n",
      "94 Train Loss 9.975637 Test MSE 3.311103781737952 Test RE 0.8697500390674034\n",
      "95 Train Loss 9.833937 Test MSE 3.250575883749151 Test RE 0.8617637364676805\n",
      "96 Train Loss 9.740478 Test MSE 3.2775121358789856 Test RE 0.8653269196876768\n",
      "97 Train Loss 9.638006 Test MSE 3.2124498927254965 Test RE 0.8566950182444208\n",
      "98 Train Loss 9.530775 Test MSE 3.196124802180697 Test RE 0.8545154609587511\n",
      "99 Train Loss 9.450076 Test MSE 3.2066130144083775 Test RE 0.8559163760559906\n",
      "100 Train Loss 9.349115 Test MSE 3.197382147521746 Test RE 0.8546835262647873\n",
      "101 Train Loss 9.23398 Test MSE 3.1310834884522274 Test RE 0.8457760524915092\n",
      "102 Train Loss 9.169758 Test MSE 3.1177608085085446 Test RE 0.8439747566256753\n",
      "103 Train Loss 8.940972 Test MSE 3.060799264360093 Test RE 0.8362295003238551\n",
      "104 Train Loss 8.809109 Test MSE 3.048810418644027 Test RE 0.8345901796728472\n",
      "105 Train Loss 8.583782 Test MSE 3.0228944458701124 Test RE 0.8310354527786701\n",
      "106 Train Loss 8.154691 Test MSE 2.822265688653635 Test RE 0.8029842153689442\n",
      "107 Train Loss 7.9588957 Test MSE 2.8497400550412384 Test RE 0.8068832194588014\n",
      "108 Train Loss 7.672057 Test MSE 2.7258045213056716 Test RE 0.7891424649651411\n",
      "109 Train Loss 7.3310204 Test MSE 2.734447354457513 Test RE 0.7903925598818938\n",
      "110 Train Loss 7.127917 Test MSE 2.6578529957719144 Test RE 0.7792441285416977\n",
      "111 Train Loss 6.8381763 Test MSE 2.5726452380118947 Test RE 0.7666515381271988\n",
      "112 Train Loss 6.6221457 Test MSE 2.5392484740920263 Test RE 0.7616591440590782\n",
      "113 Train Loss 6.4600477 Test MSE 2.5199373617032617 Test RE 0.758757388476565\n",
      "114 Train Loss 6.2216988 Test MSE 2.4416763169418427 Test RE 0.7468821937908764\n",
      "115 Train Loss 5.8821507 Test MSE 2.2575815299635726 Test RE 0.718174171308121\n",
      "116 Train Loss 5.804909 Test MSE 2.240763786782023 Test RE 0.7154941691613825\n",
      "117 Train Loss 5.701295 Test MSE 2.250442576107473 Test RE 0.7170377623237656\n",
      "118 Train Loss 5.497951 Test MSE 2.2728811456288063 Test RE 0.7206035931090402\n",
      "119 Train Loss 5.3912153 Test MSE 2.274979758205902 Test RE 0.7209361927366427\n",
      "120 Train Loss 5.275478 Test MSE 2.317156059207246 Test RE 0.7275882927140216\n",
      "121 Train Loss 5.198665 Test MSE 2.2751944505908743 Test RE 0.7209702097116436\n",
      "122 Train Loss 5.1306987 Test MSE 2.2727029581586224 Test RE 0.7205753459109396\n",
      "123 Train Loss 5.075778 Test MSE 2.253622420623683 Test RE 0.7175441657669696\n",
      "124 Train Loss 5.03436 Test MSE 2.2425040813767665 Test RE 0.7157719603703779\n",
      "125 Train Loss 4.9757137 Test MSE 2.2291418649323482 Test RE 0.7136362697292178\n",
      "126 Train Loss 4.948842 Test MSE 2.2182600362625298 Test RE 0.7118922873902759\n",
      "127 Train Loss 4.8801494 Test MSE 2.2515659162859176 Test RE 0.7172166997570433\n",
      "128 Train Loss 4.835138 Test MSE 2.228798015235517 Test RE 0.7135812276786612\n",
      "129 Train Loss 4.8002224 Test MSE 2.213266900822244 Test RE 0.7110906281898904\n",
      "130 Train Loss 4.7634377 Test MSE 2.2290870321627505 Test RE 0.7136274926086567\n",
      "131 Train Loss 4.747526 Test MSE 2.235105938115809 Test RE 0.7145902996082302\n",
      "132 Train Loss 4.7324862 Test MSE 2.2437686522850386 Test RE 0.7159737474789245\n",
      "133 Train Loss 4.6882076 Test MSE 2.2507390934680185 Test RE 0.7170849990637577\n",
      "134 Train Loss 4.653328 Test MSE 2.249097135585768 Test RE 0.7168233876254214\n",
      "135 Train Loss 4.625859 Test MSE 2.266935067332495 Test RE 0.7196603912601669\n",
      "136 Train Loss 4.607709 Test MSE 2.25369712511906 Test RE 0.7175560584713792\n",
      "137 Train Loss 4.5869703 Test MSE 2.2491351293923065 Test RE 0.7168294422180983\n",
      "138 Train Loss 4.5473785 Test MSE 2.2574971879822523 Test RE 0.7181607558904529\n",
      "139 Train Loss 4.526258 Test MSE 2.251523761175776 Test RE 0.7172099856541443\n",
      "140 Train Loss 4.513325 Test MSE 2.256323864421709 Test RE 0.7179741012941637\n",
      "141 Train Loss 4.4910088 Test MSE 2.242623959207305 Test RE 0.7157910916718078\n",
      "142 Train Loss 4.4731426 Test MSE 2.2289967017504146 Test RE 0.713613033119681\n",
      "143 Train Loss 4.4507933 Test MSE 2.2205429368530782 Test RE 0.712258511678097\n",
      "144 Train Loss 4.4360313 Test MSE 2.2213661951283084 Test RE 0.7123905330781998\n",
      "145 Train Loss 4.422364 Test MSE 2.230712004413428 Test RE 0.7138875572888667\n",
      "146 Train Loss 4.4126873 Test MSE 2.2329646294701058 Test RE 0.7142479164973484\n",
      "147 Train Loss 4.4070916 Test MSE 2.2313766522617655 Test RE 0.7139939019200282\n",
      "148 Train Loss 4.398651 Test MSE 2.2351758914388715 Test RE 0.7146014819808673\n",
      "149 Train Loss 4.3948593 Test MSE 2.2370638682340256 Test RE 0.7149032180200158\n",
      "Training time: 85.21\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 75.19667 Test MSE 4.377083779696145 Test RE 1.0000011281268533\n",
      "1 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "2 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "3 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "4 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "5 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "6 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "7 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "8 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "9 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "10 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "11 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "12 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "13 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "14 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "15 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "16 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "17 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "18 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "19 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "20 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "21 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "22 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "23 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "24 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "25 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "26 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "27 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "28 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "29 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "30 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "31 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "32 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "34 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "35 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "36 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "37 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "38 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "39 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "40 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "41 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "42 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "43 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "44 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "45 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "46 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "47 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "48 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "49 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "50 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "51 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "52 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "53 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "54 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "55 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "56 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "57 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "58 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "59 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "60 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "61 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "62 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "63 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "64 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "65 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "66 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "67 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "68 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "69 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "70 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "71 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "72 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "73 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "74 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "75 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "76 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "77 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "78 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "79 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "80 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "81 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "82 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "83 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "84 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "85 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "86 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "87 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "88 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "89 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "90 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "91 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "92 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "93 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "94 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "95 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "96 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "97 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "98 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "99 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "100 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "101 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "102 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "103 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "104 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "105 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "106 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "107 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "108 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "109 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "110 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "111 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "112 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "113 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "114 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "115 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "116 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "117 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "118 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "119 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "120 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "121 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "122 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "123 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "124 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "125 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "126 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "127 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "128 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "129 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "130 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "131 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "132 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "133 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "134 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "135 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "136 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "137 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "138 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "140 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "141 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "142 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "143 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "144 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "145 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "146 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "147 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "148 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "149 Train Loss 57.01286 Test MSE 8.640719399893335 Test RE 1.4050216336449155\n",
      "Training time: 40.02\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.33716 Test MSE 8.474921639758307 Test RE 1.391476595543984\n",
      "1 Train Loss 56.145634 Test MSE 8.676772341679923 Test RE 1.4079497714410347\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 2.45\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 76.16456 Test MSE 4.3770912824744626 Test RE 1.0000019851796242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 76.16456 Test MSE 4.377091599516119 Test RE 1.0000020213957164\n",
      "2 Train Loss 76.16456 Test MSE 4.3770919174898175 Test RE 1.0000020577182749\n",
      "3 Train Loss 76.16455 Test MSE 4.377092693081342 Test RE 1.0000021463151219\n",
      "4 Train Loss 57.53532 Test MSE 8.693424339987166 Test RE 1.4093001548777426\n",
      "5 Train Loss 57.446747 Test MSE 8.964994586295882 Test RE 1.4311431496382707\n",
      "6 Train Loss 56.878952 Test MSE 8.955965760834886 Test RE 1.4304223016439694\n",
      "7 Train Loss 52.614487 Test MSE 8.054613785205103 Test RE 1.3565331799655067\n",
      "8 Train Loss 49.67685 Test MSE 7.925660035396294 Test RE 1.3456303694433476\n",
      "9 Train Loss 48.885956 Test MSE 7.222291171261888 Test RE 1.284533860829994\n",
      "10 Train Loss 47.546127 Test MSE 7.296321056334334 Test RE 1.2911004371476393\n",
      "11 Train Loss 46.337532 Test MSE 6.999149415231805 Test RE 1.2645345293122885\n",
      "12 Train Loss 45.781647 Test MSE 6.226870144438479 Test RE 1.1927322571083876\n",
      "13 Train Loss 43.732334 Test MSE 5.850373154695092 Test RE 1.1561118271199693\n",
      "14 Train Loss 41.10085 Test MSE 6.174830794062197 Test RE 1.1877378348474783\n",
      "15 Train Loss 40.01493 Test MSE 6.259937847404656 Test RE 1.1958950572837674\n",
      "16 Train Loss 39.19327 Test MSE 6.4118240849098305 Test RE 1.2103162368199334\n",
      "17 Train Loss 38.737606 Test MSE 6.079584561667336 Test RE 1.1785418584202632\n",
      "18 Train Loss 38.341095 Test MSE 6.246798611072688 Test RE 1.194639341805937\n",
      "19 Train Loss 37.887726 Test MSE 6.519719539375252 Test RE 1.220457097256293\n",
      "20 Train Loss 37.439926 Test MSE 6.249903784734104 Test RE 1.194936222014101\n",
      "21 Train Loss 36.712227 Test MSE 6.420247892537194 Test RE 1.2111110281715314\n",
      "22 Train Loss 36.072865 Test MSE 5.96438888507532 Test RE 1.1673229832937735\n",
      "23 Train Loss 35.28215 Test MSE 6.057800835253902 Test RE 1.1764285502106548\n",
      "24 Train Loss 34.990414 Test MSE 5.7283879639993165 Test RE 1.1439953839274217\n",
      "25 Train Loss 34.434803 Test MSE 5.899953252081674 Test RE 1.1610003363446146\n",
      "26 Train Loss 32.552513 Test MSE 5.824551519688731 Test RE 1.1535576558095946\n",
      "27 Train Loss 32.01422 Test MSE 4.935914545822105 Test RE 1.0619201861119427\n",
      "28 Train Loss 30.72797 Test MSE 4.803974937993451 Test RE 1.0476312070699958\n",
      "29 Train Loss 28.81219 Test MSE 4.720955366719429 Test RE 1.0385394720493186\n",
      "30 Train Loss 28.039452 Test MSE 4.917488166025703 Test RE 1.0599361930264406\n",
      "31 Train Loss 27.565027 Test MSE 5.145737254461351 Test RE 1.0842560741012335\n",
      "32 Train Loss 26.225988 Test MSE 4.903698180450204 Test RE 1.0584489737506386\n",
      "33 Train Loss 25.255455 Test MSE 4.7853122424744035 Test RE 1.045594284707441\n",
      "34 Train Loss 24.133595 Test MSE 4.87024318369855 Test RE 1.0548322126266467\n",
      "35 Train Loss 23.102768 Test MSE 4.910883333515755 Test RE 1.0592241370859916\n",
      "36 Train Loss 21.900055 Test MSE 4.720291712403953 Test RE 1.0384664724790018\n",
      "37 Train Loss 19.544685 Test MSE 4.350826168457613 Test RE 0.9969971716264071\n",
      "38 Train Loss 17.703289 Test MSE 4.178697219573228 Test RE 0.9770763746890331\n",
      "39 Train Loss 16.179108 Test MSE 3.9943002202948974 Test RE 0.9552750004789198\n",
      "40 Train Loss 14.759997 Test MSE 3.893561719912838 Test RE 0.94315178711106\n",
      "41 Train Loss 13.765012 Test MSE 3.807102637015786 Test RE 0.9326213491662406\n",
      "42 Train Loss 13.105465 Test MSE 3.795094826473185 Test RE 0.9311494181663424\n",
      "43 Train Loss 12.827429 Test MSE 3.83161172893113 Test RE 0.9356185145393765\n",
      "44 Train Loss 12.543377 Test MSE 3.829013728469048 Test RE 0.9353012656006239\n",
      "45 Train Loss 12.320319 Test MSE 3.8837615378002615 Test RE 0.9419640721707297\n",
      "46 Train Loss 12.023729 Test MSE 3.9802546372147685 Test RE 0.9535939537773523\n",
      "47 Train Loss 11.861311 Test MSE 3.959752118280604 Test RE 0.9511347743892059\n",
      "48 Train Loss 11.734501 Test MSE 3.9193285292650204 Test RE 0.9462674354642187\n",
      "49 Train Loss 11.615474 Test MSE 3.9024779545384884 Test RE 0.9442310757396005\n",
      "50 Train Loss 11.46848 Test MSE 3.9605780125274705 Test RE 0.9512339593581999\n",
      "51 Train Loss 11.299308 Test MSE 4.047221184964555 Test RE 0.9615824539366026\n",
      "52 Train Loss 11.182762 Test MSE 4.140371314209923 Test RE 0.9725853102499358\n",
      "53 Train Loss 11.028008 Test MSE 4.106090009373151 Test RE 0.9685505518786084\n",
      "54 Train Loss 10.943123 Test MSE 4.176399387075251 Test RE 0.9768076944685846\n",
      "55 Train Loss 10.777062 Test MSE 4.122339908640219 Test RE 0.9704651845259743\n",
      "56 Train Loss 10.687415 Test MSE 4.128952718503653 Test RE 0.971243253572446\n",
      "57 Train Loss 10.600306 Test MSE 4.191399131121099 Test RE 0.9785602487492113\n",
      "58 Train Loss 10.440254 Test MSE 4.293145249691671 Test RE 0.9903662943807855\n",
      "59 Train Loss 10.259714 Test MSE 4.253288199588829 Test RE 0.9857583530794268\n",
      "60 Train Loss 10.105642 Test MSE 4.105313703934938 Test RE 0.9684589895162693\n",
      "61 Train Loss 9.944609 Test MSE 4.2324307854741585 Test RE 0.9833383855896897\n",
      "62 Train Loss 9.874963 Test MSE 4.210534651390484 Test RE 0.9807914769552827\n",
      "63 Train Loss 9.81692 Test MSE 4.185466046941213 Test RE 0.9778674089342034\n",
      "64 Train Loss 9.662832 Test MSE 4.223659993756863 Test RE 0.9823189797894042\n",
      "65 Train Loss 9.593036 Test MSE 4.1718339722963 Test RE 0.9762736517121605\n",
      "66 Train Loss 9.43546 Test MSE 4.204053128937332 Test RE 0.9800362913523762\n",
      "67 Train Loss 9.398387 Test MSE 4.180494404857212 Test RE 0.9772864639136554\n",
      "68 Train Loss 9.331985 Test MSE 4.178594067270545 Test RE 0.9770643149136233\n",
      "69 Train Loss 9.192639 Test MSE 4.164244721554611 Test RE 0.9753852464826899\n",
      "70 Train Loss 9.156554 Test MSE 4.183555452173065 Test RE 0.9776441934552101\n",
      "71 Train Loss 9.086901 Test MSE 4.132326454943086 Test RE 0.971639970355998\n",
      "72 Train Loss 9.0297 Test MSE 4.207566981195629 Test RE 0.9804457751704243\n",
      "73 Train Loss 8.993456 Test MSE 4.187116044570032 Test RE 0.9780601377608814\n",
      "74 Train Loss 8.91447 Test MSE 4.231566099961841 Test RE 0.9832379324539826\n",
      "75 Train Loss 8.892305 Test MSE 4.227610671864673 Test RE 0.9827782874772535\n",
      "76 Train Loss 8.820505 Test MSE 4.2272409219698535 Test RE 0.9827353092866871\n",
      "77 Train Loss 8.764009 Test MSE 4.248073512313541 Test RE 0.9851538798046402\n",
      "78 Train Loss 8.73135 Test MSE 4.237933937032521 Test RE 0.9839774630542031\n",
      "79 Train Loss 8.706896 Test MSE 4.240586521595272 Test RE 0.9842853577940492\n",
      "80 Train Loss 8.684758 Test MSE 4.243964412742995 Test RE 0.9846773020379969\n",
      "81 Train Loss 8.6508045 Test MSE 4.262384086882281 Test RE 0.9868118389733996\n",
      "82 Train Loss 8.632705 Test MSE 4.266883354084511 Test RE 0.987332528685925\n",
      "83 Train Loss 8.606644 Test MSE 4.243068658914647 Test RE 0.9845733809251497\n",
      "84 Train Loss 8.597359 Test MSE 4.238380700084636 Test RE 0.9840293271459941\n",
      "85 Train Loss 8.578518 Test MSE 4.221868537188216 Test RE 0.9821106334223927\n",
      "86 Train Loss 8.55859 Test MSE 4.250645811075953 Test RE 0.9854521004686877\n",
      "87 Train Loss 8.5506935 Test MSE 4.238977319289534 Test RE 0.9840985835645621\n",
      "88 Train Loss 8.530088 Test MSE 4.239417926468957 Test RE 0.9841497267533298\n",
      "89 Train Loss 8.522224 Test MSE 4.243739963430146 Test RE 0.9846512635225279\n",
      "90 Train Loss 8.509976 Test MSE 4.236165125894391 Test RE 0.9837720974246716\n",
      "91 Train Loss 8.49937 Test MSE 4.242034971757499 Test RE 0.984453443807293\n",
      "92 Train Loss 8.486002 Test MSE 4.253858066441466 Test RE 0.9858243881291117\n",
      "93 Train Loss 8.479906 Test MSE 4.270794845993969 Test RE 0.9877849735049026\n",
      "94 Train Loss 8.468398 Test MSE 4.287187558954081 Test RE 0.9896788794239957\n",
      "95 Train Loss 8.462834 Test MSE 4.30977760374731 Test RE 0.9922828612325759\n",
      "96 Train Loss 8.456543 Test MSE 4.2980509565209815 Test RE 0.9909319705094624\n",
      "97 Train Loss 8.453638 Test MSE 4.299727049296304 Test RE 0.9911251664536272\n",
      "98 Train Loss 8.434133 Test MSE 4.2976881753843 Test RE 0.9908901493425666\n",
      "99 Train Loss 8.421371 Test MSE 4.290193768371198 Test RE 0.9900258038999964\n",
      "100 Train Loss 8.412268 Test MSE 4.283748008455267 Test RE 0.9892817970166962\n",
      "101 Train Loss 8.405114 Test MSE 4.273117179196671 Test RE 0.988053501280258\n",
      "102 Train Loss 8.3912 Test MSE 4.255241710987946 Test RE 0.9859847037315874\n",
      "103 Train Loss 8.370684 Test MSE 4.2679414248617 Test RE 0.9874549368765215\n",
      "104 Train Loss 8.358896 Test MSE 4.276667376890699 Test RE 0.9884638641174317\n",
      "105 Train Loss 8.351793 Test MSE 4.26475589376297 Test RE 0.9870863568905385\n",
      "106 Train Loss 8.348917 Test MSE 4.261821266729473 Test RE 0.9867466857734468\n",
      "107 Train Loss 8.341482 Test MSE 4.266743685281318 Test RE 0.9873163692705295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 Train Loss 8.324913 Test MSE 4.246732188431183 Test RE 0.984998336974715\n",
      "109 Train Loss 8.295447 Test MSE 4.261332895332808 Test RE 0.9866901474259688\n",
      "110 Train Loss 8.290627 Test MSE 4.258484659229407 Test RE 0.9863603449526613\n",
      "111 Train Loss 8.280767 Test MSE 4.259910170577863 Test RE 0.9865254213035983\n",
      "112 Train Loss 8.271981 Test MSE 4.258515204463988 Test RE 0.9863638824262585\n",
      "113 Train Loss 8.268366 Test MSE 4.2623370919649375 Test RE 0.9868063989112547\n",
      "114 Train Loss 8.254563 Test MSE 4.25584928407479 Test RE 0.9860550917880754\n",
      "115 Train Loss 8.246859 Test MSE 4.263969487686324 Test RE 0.9869953450581674\n",
      "116 Train Loss 8.238576 Test MSE 4.254588793634545 Test RE 0.9859090568866494\n",
      "117 Train Loss 8.235458 Test MSE 4.241619674153884 Test RE 0.984405253355571\n",
      "118 Train Loss 8.23305 Test MSE 4.242125347755719 Test RE 0.9844639305771337\n",
      "119 Train Loss 8.229975 Test MSE 4.264358864494667 Test RE 0.9870404092085033\n",
      "120 Train Loss 8.224997 Test MSE 4.265595863553542 Test RE 0.9871835584561085\n",
      "121 Train Loss 8.214854 Test MSE 4.27464657113024 Test RE 0.988230302641447\n",
      "122 Train Loss 8.203362 Test MSE 4.283988459076538 Test RE 0.9893095612647701\n",
      "123 Train Loss 8.181583 Test MSE 4.267684352073693 Test RE 0.9874251975255052\n",
      "124 Train Loss 8.160037 Test MSE 4.2494417564858065 Test RE 0.9853125190714787\n",
      "125 Train Loss 8.14644 Test MSE 4.25686114642412 Test RE 0.9861723060802543\n",
      "126 Train Loss 8.128059 Test MSE 4.25665126472253 Test RE 0.9861479944964545\n",
      "127 Train Loss 8.094942 Test MSE 4.23245017327133 Test RE 0.9833406378112032\n",
      "128 Train Loss 8.082958 Test MSE 4.233582036490987 Test RE 0.983472113983777\n",
      "129 Train Loss 8.04048 Test MSE 4.243432598592741 Test RE 0.9846156048042348\n",
      "130 Train Loss 7.980445 Test MSE 4.265208486468331 Test RE 0.9871387322484466\n",
      "131 Train Loss 7.425664 Test MSE 4.05462716580027 Test RE 0.9624618482173022\n",
      "132 Train Loss 6.4855824 Test MSE 3.6412706374340447 Test RE 0.9120833752492015\n",
      "133 Train Loss 5.969844 Test MSE 2.965445498783925 Test RE 0.8231008185910891\n",
      "134 Train Loss 5.727346 Test MSE 2.7741306653540403 Test RE 0.7961071360649968\n",
      "135 Train Loss 5.3763742 Test MSE 2.252563483288675 Test RE 0.7173755652998174\n",
      "136 Train Loss 5.084015 Test MSE 2.1688045486566754 Test RE 0.7039118363833174\n",
      "137 Train Loss 4.8971753 Test MSE 2.210470641834821 Test RE 0.7106412874451496\n",
      "138 Train Loss 4.7403564 Test MSE 2.2183571950408507 Test RE 0.7119078774983912\n",
      "139 Train Loss 4.589655 Test MSE 2.168759654105236 Test RE 0.7039045508098646\n",
      "140 Train Loss 4.514911 Test MSE 2.1739878054603436 Test RE 0.7047524788664252\n",
      "141 Train Loss 4.4615993 Test MSE 2.181414932845817 Test RE 0.7059552969065558\n",
      "142 Train Loss 4.4350915 Test MSE 2.1358377143331526 Test RE 0.6985414570928326\n",
      "143 Train Loss 4.3745255 Test MSE 2.1705640901331966 Test RE 0.7041973187622103\n",
      "144 Train Loss 4.342665 Test MSE 2.124933756409855 Test RE 0.6967560655865234\n",
      "145 Train Loss 4.312048 Test MSE 2.118160352054408 Test RE 0.6956446950696211\n",
      "146 Train Loss 4.288933 Test MSE 2.141482929388948 Test RE 0.6994640024854515\n",
      "147 Train Loss 4.2806034 Test MSE 2.146594552458302 Test RE 0.7002982994222677\n",
      "148 Train Loss 4.2761827 Test MSE 2.154565754148302 Test RE 0.701597344531605\n",
      "149 Train Loss 4.268611 Test MSE 2.1401248320207227 Test RE 0.6992421723542718\n",
      "Training time: 85.61\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 76.34357 Test MSE 4.37707820016903 Test RE 1.0000004907692572\n",
      "1 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "2 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "3 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "4 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "5 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "6 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "7 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "8 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "9 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "10 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "11 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "12 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "13 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "14 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "15 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "16 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "17 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "18 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "19 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "20 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "21 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "22 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "23 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "24 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "25 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "26 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "27 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "28 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "29 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "30 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "31 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "32 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "33 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "34 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "35 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "36 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "37 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "38 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "39 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "40 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "41 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "42 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "43 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "44 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "45 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "46 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "47 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "48 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "49 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "50 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "51 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "52 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "53 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "54 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "56 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "57 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "58 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "59 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "60 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "61 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "62 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "63 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "64 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "65 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "66 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "67 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "68 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "69 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "70 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "71 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "72 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "73 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "74 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "75 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "76 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "77 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "78 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "79 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "80 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "81 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "82 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "83 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "84 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "85 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "86 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "87 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "88 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "89 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "90 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "91 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "92 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "93 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "94 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "95 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "96 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "97 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "98 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "99 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "100 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "101 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "102 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "103 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "104 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "105 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "106 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "107 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "108 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "109 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "110 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "111 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "112 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "113 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "114 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "115 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "116 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "117 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "118 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "119 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "120 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "121 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "122 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "123 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "124 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "125 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "126 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "127 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "128 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "129 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "130 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "131 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "132 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "133 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "134 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "135 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "136 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "137 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "138 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "139 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "140 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "141 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "142 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "143 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "144 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "145 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "146 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "147 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "148 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "149 Train Loss 57.676796 Test MSE 8.69702311683964 Test RE 1.4095918254440751\n",
      "Training time: 34.97\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 57.03312 Test MSE 8.649153875105828 Test RE 1.4057072090619882\n",
      "1 Train Loss 56.688457 Test MSE 8.448987777597011 Test RE 1.3893459557107988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 56.53201 Test MSE 8.845313808915618 Test RE 1.4215583244713252\n",
      "3 Train Loss 51.34534 Test MSE 8.321216217845738 Test RE 1.37880059990939\n",
      "4 Train Loss 46.321156 Test MSE 8.124130894357465 Test RE 1.3623745316997506\n",
      "5 Train Loss 44.443928 Test MSE 8.457968983741672 Test RE 1.390084191374055\n",
      "6 Train Loss 43.279514 Test MSE 8.223212896793848 Test RE 1.3706571230360487\n",
      "7 Train Loss 42.97207 Test MSE 8.195502505827587 Test RE 1.368345770009603\n",
      "8 Train Loss 42.898117 Test MSE 8.171184351437132 Test RE 1.3663141456705135\n",
      "9 Train Loss 42.750755 Test MSE 8.15255145374435 Test RE 1.364755441297048\n",
      "10 Train Loss 42.57353 Test MSE 8.282770696081515 Test RE 1.3756117584957466\n",
      "11 Train Loss 42.5605 Test MSE 8.282928091593352 Test RE 1.3756248286443824\n",
      "12 Train Loss 42.538628 Test MSE 8.305160130199035 Test RE 1.377469734798934\n",
      "13 Train Loss 42.443447 Test MSE 8.227244859280907 Test RE 1.3709931085513554\n",
      "14 Train Loss 42.332874 Test MSE 8.256448606349496 Test RE 1.3734242181967888\n",
      "15 Train Loss 41.922234 Test MSE 8.20869542718984 Test RE 1.3694466920615775\n",
      "16 Train Loss 41.401447 Test MSE 8.180901933146652 Test RE 1.3671263488731122\n",
      "17 Train Loss 39.902206 Test MSE 7.9875866025168145 Test RE 1.3508771329997176\n",
      "18 Train Loss 38.782772 Test MSE 8.39423485413555 Test RE 1.3848368714160595\n",
      "19 Train Loss 38.161278 Test MSE 8.273941064352917 Test RE 1.374878345461526\n",
      "20 Train Loss 36.87205 Test MSE 8.549523968734617 Test RE 1.397587563430697\n",
      "21 Train Loss 35.95401 Test MSE 8.497385241350395 Test RE 1.3933194969766527\n",
      "22 Train Loss 35.158432 Test MSE 8.756031866809408 Test RE 1.414365737005783\n",
      "23 Train Loss 34.34898 Test MSE 8.722587597070197 Test RE 1.4116620188642133\n",
      "24 Train Loss 33.987423 Test MSE 8.812369670776937 Test RE 1.4189085766856055\n",
      "25 Train Loss 33.27976 Test MSE 8.876822549614186 Test RE 1.4240880082933536\n",
      "26 Train Loss 32.921516 Test MSE 8.91359144751495 Test RE 1.4270343348460972\n",
      "27 Train Loss 32.452465 Test MSE 9.074265979034832 Test RE 1.439838601737409\n",
      "28 Train Loss 31.777931 Test MSE 8.972820469603107 Test RE 1.4317676629063103\n",
      "29 Train Loss 31.197224 Test MSE 8.653747405781733 Test RE 1.4060804422223756\n",
      "30 Train Loss 30.410048 Test MSE 8.51759528956613 Test RE 1.3949754376002874\n",
      "31 Train Loss 29.372972 Test MSE 8.289903810685038 Test RE 1.3762039688191856\n",
      "32 Train Loss 28.477932 Test MSE 8.273963153154408 Test RE 1.3748801807051145\n",
      "33 Train Loss 28.044071 Test MSE 8.216168432622055 Test RE 1.3700699064655648\n",
      "34 Train Loss 27.107727 Test MSE 8.171755579878406 Test RE 1.3663619027535927\n",
      "35 Train Loss 26.75845 Test MSE 8.146926556216858 Test RE 1.364284549813711\n",
      "36 Train Loss 26.360357 Test MSE 8.04796031636796 Test RE 1.355972785876625\n",
      "37 Train Loss 25.71648 Test MSE 7.680164102616652 Test RE 1.3246261065696237\n",
      "38 Train Loss 24.703335 Test MSE 6.923711288664011 Test RE 1.2577013736895601\n",
      "39 Train Loss 23.028175 Test MSE 6.510349201368972 Test RE 1.2195797429862658\n",
      "40 Train Loss 21.354984 Test MSE 6.362511136389817 Test RE 1.2056530191519859\n",
      "41 Train Loss 18.791792 Test MSE 6.173543387708138 Test RE 1.1876140111350229\n",
      "42 Train Loss 15.721609 Test MSE 5.6511683876400935 Test RE 1.136258602788677\n",
      "43 Train Loss 13.8019085 Test MSE 5.119745850116831 Test RE 1.08151428869963\n",
      "44 Train Loss 12.711091 Test MSE 4.907149413411441 Test RE 1.0588213775302484\n",
      "45 Train Loss 11.082495 Test MSE 4.803102910813364 Test RE 1.0475361186941432\n",
      "46 Train Loss 10.074137 Test MSE 4.645762794956131 Test RE 1.0302356549746328\n",
      "47 Train Loss 9.147211 Test MSE 4.086190922552853 Test RE 0.9662007886070677\n",
      "48 Train Loss 8.323429 Test MSE 3.9360801406396106 Test RE 0.9482875012203068\n",
      "49 Train Loss 7.7955747 Test MSE 3.7409677820241973 Test RE 0.9244853730657705\n",
      "50 Train Loss 6.9394684 Test MSE 2.9046593397204536 Test RE 0.8146211152831039\n",
      "51 Train Loss 6.277609 Test MSE 2.455507565743701 Test RE 0.748994620662446\n",
      "52 Train Loss 5.7880354 Test MSE 2.132619613990701 Test RE 0.6980150070046262\n",
      "53 Train Loss 4.9496336 Test MSE 1.4948421139221384 Test RE 0.5843939653391843\n",
      "54 Train Loss 4.219106 Test MSE 1.1766495776882453 Test RE 0.5184795504827044\n",
      "55 Train Loss 3.7696624 Test MSE 0.8568584324133892 Test RE 0.4424483682748464\n",
      "56 Train Loss 3.331012 Test MSE 0.67327027729301 Test RE 0.39219565808511814\n",
      "57 Train Loss 2.9462636 Test MSE 0.5401458879087475 Test RE 0.35128822877281485\n",
      "58 Train Loss 2.4317229 Test MSE 0.5712395189520152 Test RE 0.3612577582762983\n",
      "59 Train Loss 2.3144236 Test MSE 0.5383218468846923 Test RE 0.3506945872900527\n",
      "60 Train Loss 1.873129 Test MSE 0.4540026587713714 Test RE 0.3220603483859193\n",
      "61 Train Loss 1.5095767 Test MSE 0.36385708818710505 Test RE 0.28831914414455523\n",
      "62 Train Loss 1.3300236 Test MSE 0.3467099517742585 Test RE 0.28144349422536385\n",
      "63 Train Loss 1.1068505 Test MSE 0.3047389758361443 Test RE 0.26385909109085737\n",
      "64 Train Loss 1.0365288 Test MSE 0.2916564631168285 Test RE 0.2581331984850175\n",
      "65 Train Loss 0.93669283 Test MSE 0.25518181887087615 Test RE 0.24145317725408555\n",
      "66 Train Loss 0.84435815 Test MSE 0.2236930272499067 Test RE 0.22606549702149206\n",
      "67 Train Loss 0.7937794 Test MSE 0.2196680652012565 Test RE 0.22402243976840133\n",
      "68 Train Loss 0.688891 Test MSE 0.20126640805326437 Test RE 0.21443403029547195\n",
      "69 Train Loss 0.5986059 Test MSE 0.1902417137310725 Test RE 0.20847833745383676\n",
      "70 Train Loss 0.52977645 Test MSE 0.16469483924123948 Test RE 0.1939760250781107\n",
      "71 Train Loss 0.45310128 Test MSE 0.1504876765280277 Test RE 0.18542083339600116\n",
      "72 Train Loss 0.40039897 Test MSE 0.1537475227632622 Test RE 0.1874183559000178\n",
      "73 Train Loss 0.34013876 Test MSE 0.14141916188569478 Test RE 0.17974722314014588\n",
      "74 Train Loss 0.2997328 Test MSE 0.11792672767093106 Test RE 0.1641399073893702\n",
      "75 Train Loss 0.2764927 Test MSE 0.11420074350282838 Test RE 0.16152603256471967\n",
      "76 Train Loss 0.26072544 Test MSE 0.10283036759999224 Test RE 0.15327409285100885\n",
      "77 Train Loss 0.24280871 Test MSE 0.09716802494424834 Test RE 0.14899433216949226\n",
      "78 Train Loss 0.22198528 Test MSE 0.09360404770902613 Test RE 0.14623636219404626\n",
      "79 Train Loss 0.19841304 Test MSE 0.08548128145436099 Test RE 0.13974734714111126\n",
      "80 Train Loss 0.18579605 Test MSE 0.07076793506773621 Test RE 0.1271529153392069\n",
      "81 Train Loss 0.17673618 Test MSE 0.06902316007624586 Test RE 0.12557566294980319\n",
      "82 Train Loss 0.16806419 Test MSE 0.06480608974359715 Test RE 0.12167909451431651\n",
      "83 Train Loss 0.1604241 Test MSE 0.06457569521892959 Test RE 0.12146260901121507\n",
      "84 Train Loss 0.14670384 Test MSE 0.07106843598582269 Test RE 0.1274225932057435\n",
      "85 Train Loss 0.14429551 Test MSE 0.06992681753941492 Test RE 0.1263950138924507\n",
      "86 Train Loss 0.13964927 Test MSE 0.07146705421911499 Test RE 0.1277794460315719\n",
      "87 Train Loss 0.115603104 Test MSE 0.05735245857255305 Test RE 0.1144679961473485\n",
      "88 Train Loss 0.10570748 Test MSE 0.052945694585986275 Test RE 0.10998244883981735\n",
      "89 Train Loss 0.10377582 Test MSE 0.04874160861137113 Test RE 0.10552563866856718\n",
      "90 Train Loss 0.10110424 Test MSE 0.04794477107116217 Test RE 0.10465950706294679\n",
      "91 Train Loss 0.0946662 Test MSE 0.04587919900574698 Test RE 0.10238020004568978\n",
      "92 Train Loss 0.09104149 Test MSE 0.04541527198040319 Test RE 0.10186125436863812\n",
      "93 Train Loss 0.08735782 Test MSE 0.04514101981661985 Test RE 0.10155323054475561\n",
      "94 Train Loss 0.0840379 Test MSE 0.04543704435096972 Test RE 0.10188566790995693\n",
      "95 Train Loss 0.073094346 Test MSE 0.04575004514593801 Test RE 0.10223599398675388\n",
      "96 Train Loss 0.069840625 Test MSE 0.04661688977754218 Test RE 0.10320000243877278\n",
      "97 Train Loss 0.06707791 Test MSE 0.042449985857891066 Test RE 0.09847972682531582\n",
      "98 Train Loss 0.06466137 Test MSE 0.04002964004228834 Test RE 0.09563104525867251\n",
      "99 Train Loss 0.06325536 Test MSE 0.03704715810743642 Test RE 0.09199950903243806\n",
      "100 Train Loss 0.057861075 Test MSE 0.03271123380778305 Test RE 0.08644831305209912\n",
      "101 Train Loss 0.051566876 Test MSE 0.028507915067169667 Test RE 0.08070320611871883\n",
      "102 Train Loss 0.048187554 Test MSE 0.024766189889194178 Test RE 0.0752207500346741\n",
      "103 Train Loss 0.046974685 Test MSE 0.02395150821485838 Test RE 0.0739732148234198\n",
      "104 Train Loss 0.046477955 Test MSE 0.023491484533070556 Test RE 0.07325938889692685\n",
      "105 Train Loss 0.044854812 Test MSE 0.02313268580874908 Test RE 0.07269777013297822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.043785825 Test MSE 0.0226099915748467 Test RE 0.07187175677631458\n",
      "107 Train Loss 0.042668507 Test MSE 0.02218344505395803 Test RE 0.0711905841335953\n",
      "108 Train Loss 0.040449444 Test MSE 0.020385505187188534 Test RE 0.06824467965743401\n",
      "109 Train Loss 0.039010327 Test MSE 0.020693665075204457 Test RE 0.06875855927662933\n",
      "110 Train Loss 0.038350113 Test MSE 0.01944090306287907 Test RE 0.06664480133180017\n",
      "111 Train Loss 0.037567344 Test MSE 0.019064775896919257 Test RE 0.0659969571670823\n",
      "112 Train Loss 0.036891777 Test MSE 0.01768972464608481 Test RE 0.06357239844458323\n",
      "113 Train Loss 0.03651195 Test MSE 0.017470586084866953 Test RE 0.06317740705833005\n",
      "114 Train Loss 0.035978228 Test MSE 0.016373069044191852 Test RE 0.06116079287711882\n",
      "115 Train Loss 0.0351799 Test MSE 0.014673187834637278 Test RE 0.05789889813524166\n",
      "116 Train Loss 0.034121998 Test MSE 0.012848602755805941 Test RE 0.054179627066061865\n",
      "117 Train Loss 0.032887295 Test MSE 0.012886891707222606 Test RE 0.05426029490027462\n",
      "118 Train Loss 0.03142214 Test MSE 0.011590055732657121 Test RE 0.05145775352753774\n",
      "119 Train Loss 0.030343335 Test MSE 0.010622208063992309 Test RE 0.049262388201457986\n",
      "120 Train Loss 0.029898776 Test MSE 0.010142608072094756 Test RE 0.048137428021118145\n",
      "121 Train Loss 0.029496005 Test MSE 0.009577858026333885 Test RE 0.04677806552140009\n",
      "122 Train Loss 0.028602911 Test MSE 0.008757005904456026 Test RE 0.04472865937745545\n",
      "123 Train Loss 0.02534106 Test MSE 0.006984993642358783 Test RE 0.039947634518941226\n",
      "124 Train Loss 0.023115698 Test MSE 0.006949717677097749 Test RE 0.039846634064328035\n",
      "125 Train Loss 0.022145277 Test MSE 0.006607129650043211 Test RE 0.038852097930918754\n",
      "126 Train Loss 0.021432836 Test MSE 0.006118757739309869 Test RE 0.03738864184195816\n",
      "127 Train Loss 0.021100407 Test MSE 0.005827933313015696 Test RE 0.036489284459442\n",
      "128 Train Loss 0.020942157 Test MSE 0.0054928070082113055 Test RE 0.03542462245603182\n",
      "129 Train Loss 0.020644244 Test MSE 0.0054681004127079234 Test RE 0.03534486285213836\n",
      "130 Train Loss 0.018248394 Test MSE 0.005606696660043105 Test RE 0.035789991092090544\n",
      "131 Train Loss 0.017044807 Test MSE 0.0062827281160490155 Test RE 0.03788629995290182\n",
      "132 Train Loss 0.016460855 Test MSE 0.006848146993241496 Test RE 0.03955438142616854\n",
      "133 Train Loss 0.016025918 Test MSE 0.006525875744208952 Test RE 0.038612459026360894\n",
      "134 Train Loss 0.015640462 Test MSE 0.006772007710072614 Test RE 0.03933387943152022\n",
      "135 Train Loss 0.015461193 Test MSE 0.006522115735356294 Test RE 0.038601333768081246\n",
      "136 Train Loss 0.015105881 Test MSE 0.006914019840699725 Test RE 0.039744164437738934\n",
      "137 Train Loss 0.014896785 Test MSE 0.007178841107164254 Test RE 0.040498154303860744\n",
      "138 Train Loss 0.014605587 Test MSE 0.007123720824226703 Test RE 0.0403423790784257\n",
      "139 Train Loss 0.014170131 Test MSE 0.006818659954497616 Test RE 0.03946913210180983\n",
      "140 Train Loss 0.013415517 Test MSE 0.0062921327940012395 Test RE 0.03791464553801814\n",
      "141 Train Loss 0.013063052 Test MSE 0.005984832513631449 Test RE 0.03697720328356591\n",
      "142 Train Loss 0.012694921 Test MSE 0.005711721070016155 Test RE 0.036123644164133724\n",
      "143 Train Loss 0.012358754 Test MSE 0.005665672544480938 Test RE 0.03597773307848633\n",
      "144 Train Loss 0.011561294 Test MSE 0.004486729074298258 Test RE 0.03201643583132214\n",
      "145 Train Loss 0.011203035 Test MSE 0.004052540515676419 Test RE 0.030427883374586184\n",
      "146 Train Loss 0.011060503 Test MSE 0.004123904180230938 Test RE 0.030694625796045674\n",
      "147 Train Loss 0.010961743 Test MSE 0.0040435154152909086 Test RE 0.03039398269367971\n",
      "148 Train Loss 0.010859235 Test MSE 0.004062355546938445 Test RE 0.030464708424846068\n",
      "149 Train Loss 0.0106878765 Test MSE 0.004148486165192654 Test RE 0.030785972941600206\n",
      "Training time: 86.07\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 75.19667 Test MSE 4.377084514778699 Test RE 1.0000012120963848\n",
      "1 Train Loss 56.97332 Test MSE 8.824850731148267 Test RE 1.4199130294133464\n",
      "2 Train Loss 56.521973 Test MSE 8.845194388359412 Test RE 1.4215487282115173\n",
      "3 Train Loss 54.147278 Test MSE 9.110732191459654 Test RE 1.442728797815761\n",
      "4 Train Loss 52.6112 Test MSE 8.513804069840877 Test RE 1.3946649481459383\n",
      "5 Train Loss 44.469917 Test MSE 8.118354484294398 Test RE 1.3618901086015174\n",
      "6 Train Loss 43.848503 Test MSE 8.425157775382269 Test RE 1.3873852773399395\n",
      "7 Train Loss 43.423992 Test MSE 8.697230646963071 Test RE 1.4096086433262685\n",
      "8 Train Loss 43.197258 Test MSE 8.498798374097472 Test RE 1.3934353481178736\n",
      "9 Train Loss 42.888927 Test MSE 8.44171673218587 Test RE 1.3887480040900648\n",
      "10 Train Loss 42.785316 Test MSE 8.349637281745428 Test RE 1.3811532353431515\n",
      "11 Train Loss 41.65676 Test MSE 7.44083325110338 Test RE 1.303823625725537\n",
      "12 Train Loss 39.59725 Test MSE 7.873449450833166 Test RE 1.3411908505695327\n",
      "13 Train Loss 38.985306 Test MSE 7.662633644276857 Test RE 1.323113471641977\n",
      "14 Train Loss 38.76061 Test MSE 7.658968148651575 Test RE 1.3227969716629058\n",
      "15 Train Loss 38.671326 Test MSE 7.7346410172570055 Test RE 1.3293157219349472\n",
      "16 Train Loss 38.6053 Test MSE 7.722507143001983 Test RE 1.3282726172379276\n",
      "17 Train Loss 38.529205 Test MSE 7.712003457488085 Test RE 1.3273689919707468\n",
      "18 Train Loss 38.452892 Test MSE 7.739865273995319 Test RE 1.3297645801511724\n",
      "19 Train Loss 38.199905 Test MSE 7.776803149446992 Test RE 1.3329338997974922\n",
      "20 Train Loss 38.04325 Test MSE 7.706827783176312 Test RE 1.3269235057445563\n",
      "21 Train Loss 37.877716 Test MSE 7.673709737617354 Test RE 1.3240693855619041\n",
      "22 Train Loss 37.811398 Test MSE 7.646863172358733 Test RE 1.3217512199654218\n",
      "23 Train Loss 37.715916 Test MSE 7.666301308885459 Test RE 1.3234300831449806\n",
      "24 Train Loss 37.607075 Test MSE 7.707437140339252 Test RE 1.3269759627595197\n",
      "25 Train Loss 37.483597 Test MSE 7.649370089860723 Test RE 1.3219678610680212\n",
      "26 Train Loss 37.26105 Test MSE 7.649555019003653 Test RE 1.321983840743675\n",
      "27 Train Loss 37.01834 Test MSE 7.718220024091251 Test RE 1.3279038734423907\n",
      "28 Train Loss 36.499577 Test MSE 7.9413746502508635 Test RE 1.3469637341996725\n",
      "29 Train Loss 36.25448 Test MSE 7.924670406905924 Test RE 1.345546356520938\n",
      "30 Train Loss 36.1139 Test MSE 7.936674161522551 Test RE 1.34656504220419\n",
      "31 Train Loss 35.98296 Test MSE 7.867880495857322 Test RE 1.3407164490571157\n",
      "32 Train Loss 35.867523 Test MSE 7.861005192928951 Test RE 1.3401305322812416\n",
      "33 Train Loss 35.733788 Test MSE 7.844354511257935 Test RE 1.3387104902545837\n",
      "34 Train Loss 35.481853 Test MSE 7.835706807342008 Test RE 1.3379723820850231\n",
      "35 Train Loss 35.31044 Test MSE 7.745346941841916 Test RE 1.3302353918059235\n",
      "36 Train Loss 33.88846 Test MSE 6.83926602019385 Test RE 1.2500080460203824\n",
      "37 Train Loss 32.180298 Test MSE 7.2442194636592685 Test RE 1.2864824312495668\n",
      "38 Train Loss 31.195108 Test MSE 7.169928871606406 Test RE 1.279868893597028\n",
      "39 Train Loss 30.315155 Test MSE 7.3400406811141785 Test RE 1.2949628029712814\n",
      "40 Train Loss 29.694149 Test MSE 7.206060112940398 Test RE 1.2830896466137955\n",
      "41 Train Loss 28.719147 Test MSE 6.353026702814487 Test RE 1.2047540658652192\n",
      "42 Train Loss 27.32582 Test MSE 6.399150921718194 Test RE 1.20911953197057\n",
      "43 Train Loss 25.896633 Test MSE 6.3767529646128 Test RE 1.2070016301683135\n",
      "44 Train Loss 23.572948 Test MSE 4.581386752892213 Test RE 1.0230727993538438\n",
      "45 Train Loss 20.956722 Test MSE 4.530779953863198 Test RE 1.017406587909811\n",
      "46 Train Loss 19.754084 Test MSE 4.552073962849628 Test RE 1.0197946170894039\n",
      "47 Train Loss 19.281868 Test MSE 4.452408306099638 Test RE 1.0085688539948239\n",
      "48 Train Loss 18.793064 Test MSE 4.039387364750608 Test RE 0.9606513814285321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 18.4998 Test MSE 4.023138598491076 Test RE 0.9587172850524375\n",
      "50 Train Loss 18.016342 Test MSE 3.5672369324237185 Test RE 0.902763596689078\n",
      "51 Train Loss 17.761261 Test MSE 3.551562492378688 Test RE 0.9007780414113178\n",
      "52 Train Loss 17.502323 Test MSE 3.424338609349904 Test RE 0.8844970963700544\n",
      "53 Train Loss 17.278997 Test MSE 3.496637519923762 Test RE 0.8937856280008567\n",
      "54 Train Loss 17.149818 Test MSE 3.481306970892588 Test RE 0.8918241326740148\n",
      "55 Train Loss 17.038025 Test MSE 3.4969274494265425 Test RE 0.893822682092082\n",
      "56 Train Loss 16.821209 Test MSE 3.536659085081172 Test RE 0.8988860889037531\n",
      "57 Train Loss 16.69743 Test MSE 3.557873223584535 Test RE 0.9015779773743634\n",
      "58 Train Loss 16.504253 Test MSE 3.5647004881996844 Test RE 0.9024425895994795\n",
      "59 Train Loss 16.355186 Test MSE 3.4580631129173653 Test RE 0.8888418976940948\n",
      "60 Train Loss 16.231655 Test MSE 3.4612575226793587 Test RE 0.8892523398597327\n",
      "61 Train Loss 16.05626 Test MSE 3.5359430343113214 Test RE 0.8987950876730886\n",
      "62 Train Loss 15.8002205 Test MSE 3.398365556464359 Test RE 0.8811363280190209\n",
      "63 Train Loss 15.569182 Test MSE 3.2967078263316414 Test RE 0.8678572379375038\n",
      "64 Train Loss 15.023866 Test MSE 2.898155884387789 Test RE 0.8137086466975761\n",
      "65 Train Loss 13.948616 Test MSE 2.7765137587428423 Test RE 0.7964490071975376\n",
      "66 Train Loss 12.559537 Test MSE 2.4895027452546623 Test RE 0.7541615124518518\n",
      "67 Train Loss 11.821876 Test MSE 2.4767498268592227 Test RE 0.7522273693658146\n",
      "68 Train Loss 11.25935 Test MSE 2.1153989661711194 Test RE 0.6951911010069113\n",
      "69 Train Loss 10.642475 Test MSE 2.0942968034039744 Test RE 0.6917149707679521\n",
      "70 Train Loss 10.091532 Test MSE 2.1032657525485696 Test RE 0.6931945433787172\n",
      "71 Train Loss 9.639808 Test MSE 2.2180233307509902 Test RE 0.7118543041690052\n",
      "72 Train Loss 9.349738 Test MSE 2.2806764887599353 Test RE 0.7218382692023992\n",
      "73 Train Loss 8.832383 Test MSE 2.2074088723901735 Test RE 0.7101489547933332\n",
      "74 Train Loss 8.529726 Test MSE 2.160644658098045 Test RE 0.7025863927454891\n",
      "75 Train Loss 8.446926 Test MSE 2.0343292087510743 Test RE 0.6817398451541561\n",
      "76 Train Loss 8.204173 Test MSE 1.8959271144024188 Test RE 0.6581408974787774\n",
      "77 Train Loss 8.007076 Test MSE 1.785666322091371 Test RE 0.6387166158129114\n",
      "78 Train Loss 7.76566 Test MSE 1.7489511237904014 Test RE 0.6321161651384816\n",
      "79 Train Loss 7.627505 Test MSE 1.8368419617942586 Test RE 0.6478044937256814\n",
      "80 Train Loss 7.365286 Test MSE 1.7731935986855827 Test RE 0.6364820169485675\n",
      "81 Train Loss 7.2889132 Test MSE 1.7035871753715934 Test RE 0.6238644537311785\n",
      "82 Train Loss 7.216228 Test MSE 1.7209778562874742 Test RE 0.6270406573795555\n",
      "83 Train Loss 7.161696 Test MSE 1.7775568195358178 Test RE 0.637264617711457\n",
      "84 Train Loss 7.0536423 Test MSE 1.7569317546002625 Test RE 0.63355672683327\n",
      "85 Train Loss 6.996172 Test MSE 1.7587087673026789 Test RE 0.6338770448580497\n",
      "86 Train Loss 6.9245176 Test MSE 1.7865425112704034 Test RE 0.6388732990483684\n",
      "87 Train Loss 6.877519 Test MSE 1.7741792198923045 Test RE 0.6366588851212432\n",
      "88 Train Loss 6.731711 Test MSE 1.8711788942892926 Test RE 0.6538313124420239\n",
      "89 Train Loss 6.6250744 Test MSE 1.9151413094766117 Test RE 0.6614674414226737\n",
      "90 Train Loss 6.5248322 Test MSE 1.9104707795745064 Test RE 0.6606603758260982\n",
      "91 Train Loss 6.371191 Test MSE 1.801807330656301 Test RE 0.6415968676962538\n",
      "92 Train Loss 6.26737 Test MSE 1.6520335010192575 Test RE 0.6143522954093408\n",
      "93 Train Loss 6.144556 Test MSE 1.5204072446293684 Test RE 0.5893699996435332\n",
      "94 Train Loss 5.9470553 Test MSE 1.4650342027416552 Test RE 0.5785380696784483\n",
      "95 Train Loss 5.839325 Test MSE 1.3517588325128413 Test RE 0.5557221001047659\n",
      "96 Train Loss 5.6280107 Test MSE 1.0531930497409578 Test RE 0.49052602336370604\n",
      "97 Train Loss 4.989198 Test MSE 0.8285344738972785 Test RE 0.4350742217145149\n",
      "98 Train Loss 3.3744147 Test MSE 0.45293387849746186 Test RE 0.32168103941148996\n",
      "99 Train Loss 2.5535345 Test MSE 0.41225314291688747 Test RE 0.30689516610013257\n",
      "100 Train Loss 2.3846576 Test MSE 0.36050792800926174 Test RE 0.2869891448582297\n",
      "101 Train Loss 2.1976333 Test MSE 0.3093987103808746 Test RE 0.2658687598905624\n",
      "102 Train Loss 1.9620355 Test MSE 0.23547573590909823 Test RE 0.23194293141219968\n",
      "103 Train Loss 1.77665 Test MSE 0.2374168766526199 Test RE 0.23289697834064113\n",
      "104 Train Loss 1.6666453 Test MSE 0.23526246406478515 Test RE 0.23183787153785418\n",
      "105 Train Loss 1.4636341 Test MSE 0.1855961971404966 Test RE 0.2059171870713028\n",
      "106 Train Loss 1.3819088 Test MSE 0.19116762156771971 Test RE 0.20898505446335758\n",
      "107 Train Loss 1.2997106 Test MSE 0.18994925140418883 Test RE 0.20831802689445286\n",
      "108 Train Loss 1.2205038 Test MSE 0.15598581272132467 Test RE 0.18877766514002586\n",
      "109 Train Loss 1.0995829 Test MSE 0.14144550777824155 Test RE 0.17976396549820886\n",
      "110 Train Loss 1.0142862 Test MSE 0.1133008456145565 Test RE 0.16088836411858204\n",
      "111 Train Loss 0.96990395 Test MSE 0.11283543764700146 Test RE 0.16055758203279877\n",
      "112 Train Loss 0.90822965 Test MSE 0.124699481331913 Test RE 0.1687875400946505\n",
      "113 Train Loss 0.82330924 Test MSE 0.12060496887691333 Test RE 0.16599333891441953\n",
      "114 Train Loss 0.7506187 Test MSE 0.13163924508731994 Test RE 0.1734206268970456\n",
      "115 Train Loss 0.73166096 Test MSE 0.12045491325673746 Test RE 0.1658900430630066\n",
      "116 Train Loss 0.69623876 Test MSE 0.11289630784852392 Test RE 0.16060088338773942\n",
      "117 Train Loss 0.63256913 Test MSE 0.09654114367477609 Test RE 0.14851293466324963\n",
      "118 Train Loss 0.5655159 Test MSE 0.09625984156575822 Test RE 0.14829640792098397\n",
      "119 Train Loss 0.5007328 Test MSE 0.1224841193477714 Test RE 0.16728151470025923\n",
      "120 Train Loss 0.45548356 Test MSE 0.12376454947728499 Test RE 0.1681536090432863\n",
      "121 Train Loss 0.40144244 Test MSE 0.12178006859063902 Test RE 0.16680004652713876\n",
      "122 Train Loss 0.37761325 Test MSE 0.10508648510210093 Test RE 0.15494640106581728\n",
      "123 Train Loss 0.35374296 Test MSE 0.11379159324812474 Test RE 0.16123642097452245\n",
      "124 Train Loss 0.32894897 Test MSE 0.10979637648405725 Test RE 0.15838062926278346\n",
      "125 Train Loss 0.30825302 Test MSE 0.10005271413186793 Test RE 0.1511898016952939\n",
      "126 Train Loss 0.29720923 Test MSE 0.09464920588285684 Test RE 0.14705051422709686\n",
      "127 Train Loss 0.2738371 Test MSE 0.0724299768005185 Test RE 0.12863739399598662\n",
      "128 Train Loss 0.24797325 Test MSE 0.06781426685513102 Test RE 0.12447111953118226\n",
      "129 Train Loss 0.23164451 Test MSE 0.06831805496383057 Test RE 0.12493260825348264\n",
      "130 Train Loss 0.22043525 Test MSE 0.06333653794219868 Test RE 0.12029157758975463\n",
      "131 Train Loss 0.21418253 Test MSE 0.059125695479420606 Test RE 0.11622409988557053\n",
      "132 Train Loss 0.19912134 Test MSE 0.04913530545066163 Test RE 0.10595095859969957\n",
      "133 Train Loss 0.19055444 Test MSE 0.04415340199281147 Test RE 0.10043617065470717\n",
      "134 Train Loss 0.18447377 Test MSE 0.04341932748672664 Test RE 0.09959776813359691\n",
      "135 Train Loss 0.17889294 Test MSE 0.04251637602785763 Test RE 0.09855670602021453\n",
      "136 Train Loss 0.1723563 Test MSE 0.03809091293166815 Test RE 0.09328648967173384\n",
      "137 Train Loss 0.16498692 Test MSE 0.03901526791178666 Test RE 0.0944115998505998\n",
      "138 Train Loss 0.16088767 Test MSE 0.03578048970621892 Test RE 0.090413066731792\n",
      "139 Train Loss 0.15109877 Test MSE 0.03631728754709548 Test RE 0.09108875424672773\n",
      "140 Train Loss 0.14885026 Test MSE 0.03706377505253363 Test RE 0.09202013921681045\n",
      "141 Train Loss 0.1431449 Test MSE 0.037061583259903975 Test RE 0.09201741833848011\n",
      "142 Train Loss 0.1391067 Test MSE 0.03555386301098954 Test RE 0.0901262824704194\n",
      "143 Train Loss 0.13275349 Test MSE 0.02963892460926158 Test RE 0.08228852566894503\n",
      "144 Train Loss 0.12355052 Test MSE 0.024966622817640883 Test RE 0.07552451767319536\n",
      "145 Train Loss 0.12118855 Test MSE 0.023989173820111717 Test RE 0.07403135628464541\n",
      "146 Train Loss 0.11970651 Test MSE 0.021104301633198173 Test RE 0.06943741633099201\n",
      "147 Train Loss 0.111663096 Test MSE 0.02069763370975126 Test RE 0.0687651522245404\n",
      "148 Train Loss 0.10669762 Test MSE 0.02265846865116568 Test RE 0.07194876403841058\n",
      "149 Train Loss 0.102664635 Test MSE 0.02344967149734561 Test RE 0.07319416182029806\n",
      "Training time: 87.98\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.35387 Test MSE 8.52169445020413 Test RE 1.395311068749113\n",
      "1 Train Loss 56.002563 Test MSE 8.511396502678652 Test RE 1.3944677397701695\n",
      "2 Train Loss 52.019302 Test MSE 8.469630898501183 Test RE 1.3910421908210704\n",
      "3 Train Loss 51.543915 Test MSE 8.139347082461342 Test RE 1.3636497726945707\n",
      "4 Train Loss 51.16692 Test MSE 8.310449108811367 Test RE 1.3779082723062857\n",
      "5 Train Loss 50.28314 Test MSE 8.351201625434804 Test RE 1.381282612050473\n",
      "6 Train Loss 47.842506 Test MSE 8.41676335748212 Test RE 1.3866939434496435\n",
      "7 Train Loss 44.56967 Test MSE 8.331788336347946 Test RE 1.3796762060656804\n",
      "8 Train Loss 43.774025 Test MSE 8.157143993360327 Test RE 1.3651397879047684\n",
      "9 Train Loss 43.58442 Test MSE 8.150285752173636 Test RE 1.3645657863509726\n",
      "10 Train Loss 43.47231 Test MSE 8.038258855795652 Test RE 1.3551552567878282\n",
      "11 Train Loss 43.153088 Test MSE 8.173102503635665 Test RE 1.366474504596607\n",
      "12 Train Loss 43.10622 Test MSE 8.097396361327267 Test RE 1.3601310633741786\n",
      "13 Train Loss 43.10244 Test MSE 8.103896296900881 Test RE 1.3606768555299582\n",
      "14 Train Loss 43.097862 Test MSE 8.111380494735865 Test RE 1.3613050240230573\n",
      "15 Train Loss 43.000668 Test MSE 8.185378488570425 Test RE 1.3675003406370458\n",
      "16 Train Loss 42.867893 Test MSE 8.19464771833277 Test RE 1.3682744092021408\n",
      "17 Train Loss 42.394943 Test MSE 8.415589685969428 Test RE 1.3865972566443732\n",
      "18 Train Loss 41.39531 Test MSE 8.228336195995622 Test RE 1.3710840360444572\n",
      "19 Train Loss 40.944946 Test MSE 8.272125585946606 Test RE 1.3747274984307494\n",
      "20 Train Loss 40.62262 Test MSE 8.23184771142409 Test RE 1.371376565972424\n",
      "21 Train Loss 39.89359 Test MSE 8.264099356445284 Test RE 1.3740604053081615\n",
      "22 Train Loss 39.24462 Test MSE 8.3454029538054 Test RE 1.3808029807646034\n",
      "23 Train Loss 37.175026 Test MSE 7.650336240865609 Test RE 1.3220513437754347\n",
      "24 Train Loss 35.72933 Test MSE 7.407277066380346 Test RE 1.300880354237303\n",
      "25 Train Loss 34.292404 Test MSE 6.727603280811808 Test RE 1.2397617901365061\n",
      "26 Train Loss 32.958755 Test MSE 6.924421451992099 Test RE 1.2577658730927028\n",
      "27 Train Loss 31.778378 Test MSE 6.8530350092753265 Test RE 1.251265687791595\n",
      "28 Train Loss 30.842327 Test MSE 7.02014328121123 Test RE 1.2664295875155316\n",
      "29 Train Loss 29.918995 Test MSE 6.753295532063619 Test RE 1.2421268165508759\n",
      "30 Train Loss 29.30038 Test MSE 7.063524250753664 Test RE 1.2703365113921499\n",
      "31 Train Loss 28.036118 Test MSE 6.709166446257882 Test RE 1.2380618560359642\n",
      "32 Train Loss 27.339947 Test MSE 6.769746000510092 Test RE 1.2436387553826875\n",
      "33 Train Loss 26.240215 Test MSE 6.526288168336401 Test RE 1.2210717488211065\n",
      "34 Train Loss 25.719225 Test MSE 6.3155588744883016 Test RE 1.2011962129153213\n",
      "35 Train Loss 25.29756 Test MSE 6.072685674506748 Test RE 1.1778729858101344\n",
      "36 Train Loss 24.780428 Test MSE 6.170516154081357 Test RE 1.1873227986430626\n",
      "37 Train Loss 24.437344 Test MSE 6.10293903715256 Test RE 1.1808033488242082\n",
      "38 Train Loss 24.180363 Test MSE 6.096039303447335 Test RE 1.1801356760317099\n",
      "39 Train Loss 23.88278 Test MSE 5.8975952842215245 Test RE 1.1607683111960243\n",
      "40 Train Loss 23.712748 Test MSE 5.956683243340615 Test RE 1.1665686830633348\n",
      "41 Train Loss 23.627922 Test MSE 5.9935132388539225 Test RE 1.170169555372457\n",
      "42 Train Loss 23.574123 Test MSE 5.87823798588138 Test RE 1.1588617878456737\n",
      "43 Train Loss 23.405226 Test MSE 5.8315000186062775 Test RE 1.1542455289415519\n",
      "44 Train Loss 23.271597 Test MSE 5.791599144263162 Test RE 1.1502899036672622\n",
      "45 Train Loss 23.247717 Test MSE 5.788238878484917 Test RE 1.149956158140314\n",
      "46 Train Loss 23.224537 Test MSE 5.809683203798785 Test RE 1.1520843733449289\n",
      "47 Train Loss 23.215363 Test MSE 5.8230397225777395 Test RE 1.153407939706728\n",
      "48 Train Loss 23.18127 Test MSE 5.820373787994722 Test RE 1.1531438798441167\n",
      "49 Train Loss 23.153883 Test MSE 5.833121917997868 Test RE 1.1544060313821598\n",
      "50 Train Loss 23.134893 Test MSE 5.809789018676214 Test RE 1.152094865062583\n",
      "51 Train Loss 22.99128 Test MSE 5.6324884298775935 Test RE 1.134379094840456\n",
      "52 Train Loss 22.879887 Test MSE 5.6778903752049485 Test RE 1.1389418779304548\n",
      "53 Train Loss 22.795822 Test MSE 5.654835951600239 Test RE 1.1366272544460037\n",
      "54 Train Loss 22.782066 Test MSE 5.66700486253062 Test RE 1.1378495783790046\n",
      "55 Train Loss 22.77333 Test MSE 5.694659783808133 Test RE 1.1406225461847173\n",
      "56 Train Loss 22.737387 Test MSE 5.74123232266803 Test RE 1.1452772157075553\n",
      "57 Train Loss 22.673119 Test MSE 5.8140685157454035 Test RE 1.1525191041343281\n",
      "58 Train Loss 22.537992 Test MSE 5.8036216146355715 Test RE 1.1514831973062254\n",
      "59 Train Loss 22.350908 Test MSE 5.905111393948056 Test RE 1.1615077383396923\n",
      "60 Train Loss 22.230152 Test MSE 5.945971505597851 Test RE 1.1655193070825813\n",
      "61 Train Loss 22.125484 Test MSE 5.984406930198142 Test RE 1.1692802626194152\n",
      "62 Train Loss 22.044506 Test MSE 6.038980165728155 Test RE 1.1745996359188944\n",
      "63 Train Loss 21.918335 Test MSE 6.053119577318501 Test RE 1.1759739108139735\n",
      "64 Train Loss 21.828102 Test MSE 6.00539065091301 Test RE 1.1713284505398778\n",
      "65 Train Loss 21.72094 Test MSE 5.976278466769877 Test RE 1.168485891383568\n",
      "66 Train Loss 21.52403 Test MSE 6.05947773238435 Test RE 1.176591366157425\n",
      "67 Train Loss 21.407776 Test MSE 5.988584679805268 Test RE 1.1696883321204838\n",
      "68 Train Loss 21.370502 Test MSE 5.969453511996425 Test RE 1.1678184909649048\n",
      "69 Train Loss 21.269672 Test MSE 5.94977802224228 Test RE 1.1658923208793686\n",
      "70 Train Loss 21.148796 Test MSE 5.841311484242827 Test RE 1.1552161266278609\n",
      "71 Train Loss 20.982327 Test MSE 5.740201435328377 Test RE 1.14517438893453\n",
      "72 Train Loss 20.764153 Test MSE 5.856102967507421 Test RE 1.1566778323156492\n",
      "73 Train Loss 20.526089 Test MSE 5.987014848448073 Test RE 1.169535012607538\n",
      "74 Train Loss 20.471798 Test MSE 5.947230286794575 Test RE 1.1656426726373759\n",
      "75 Train Loss 20.458664 Test MSE 5.992584577561768 Test RE 1.1700788962527167\n",
      "76 Train Loss 20.428337 Test MSE 5.959244719254671 Test RE 1.1668194783711558\n",
      "77 Train Loss 20.403913 Test MSE 5.937149346584758 Test RE 1.1646543337529345\n",
      "78 Train Loss 20.162916 Test MSE 5.976763106317161 Test RE 1.1685332689443924\n",
      "79 Train Loss 20.015915 Test MSE 5.909378391855397 Test RE 1.1619273118041356\n",
      "80 Train Loss 19.888466 Test MSE 5.887579586089709 Test RE 1.1597822444504142\n",
      "81 Train Loss 19.840715 Test MSE 5.892956065479009 Test RE 1.1603116744421673\n",
      "82 Train Loss 19.774628 Test MSE 5.800507086356697 Test RE 1.151174182651167\n",
      "83 Train Loss 19.696022 Test MSE 5.798166629602406 Test RE 1.1509419145765698\n",
      "84 Train Loss 19.620823 Test MSE 5.840916842422668 Test RE 1.1551771024894866\n",
      "85 Train Loss 19.446346 Test MSE 5.8139613811310475 Test RE 1.1525084854721779\n",
      "86 Train Loss 19.296 Test MSE 5.902131103612943 Test RE 1.1612145967768681\n",
      "87 Train Loss 19.0584 Test MSE 5.8167558907074435 Test RE 1.1527854316772264\n",
      "88 Train Loss 18.98037 Test MSE 5.87489021888684 Test RE 1.1585317440649165\n",
      "89 Train Loss 18.913239 Test MSE 5.8968488164832715 Test RE 1.1606948487529711\n",
      "90 Train Loss 18.71983 Test MSE 6.040974450572473 Test RE 1.1747935670816692\n",
      "91 Train Loss 18.535763 Test MSE 6.054856189469831 Test RE 1.1761425894682511\n",
      "92 Train Loss 18.359459 Test MSE 5.962020908722421 Test RE 1.1670912355248266\n",
      "93 Train Loss 18.280117 Test MSE 5.920159242277978 Test RE 1.1629867173520652\n",
      "94 Train Loss 17.973824 Test MSE 5.988339469293534 Test RE 1.1696643846582753\n",
      "95 Train Loss 17.867268 Test MSE 5.965764741608725 Test RE 1.1674576137121928\n",
      "96 Train Loss 17.808718 Test MSE 5.890610959540868 Test RE 1.1600807780522417\n",
      "97 Train Loss 17.736048 Test MSE 5.919890887652898 Test RE 1.162960358567738\n",
      "98 Train Loss 17.530962 Test MSE 5.841933331307601 Test RE 1.1552776152714388\n",
      "99 Train Loss 17.457283 Test MSE 5.805935316037166 Test RE 1.1517127025175917\n",
      "100 Train Loss 17.317345 Test MSE 5.754003787983263 Test RE 1.1465503520329277\n",
      "101 Train Loss 17.185892 Test MSE 5.674276613253324 Test RE 1.138579373579541\n",
      "102 Train Loss 17.026344 Test MSE 5.6301598554605805 Test RE 1.1341445839987094\n",
      "103 Train Loss 16.868322 Test MSE 5.60296494768973 Test RE 1.1314021847650364\n",
      "104 Train Loss 16.665691 Test MSE 5.481489741758843 Test RE 1.1190702828896884\n",
      "105 Train Loss 16.36314 Test MSE 4.921144620049438 Test RE 1.060330183581856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 15.523458 Test MSE 4.500673516734159 Test RE 1.0140206873098767\n",
      "107 Train Loss 14.67067 Test MSE 4.236728216558182 Test RE 0.9838374790209534\n",
      "108 Train Loss 14.223458 Test MSE 4.209207939256209 Test RE 0.9806369442676688\n",
      "109 Train Loss 13.817301 Test MSE 4.235549235380055 Test RE 0.9837005801550107\n",
      "110 Train Loss 13.367871 Test MSE 4.252737387360305 Test RE 0.9856945218375915\n",
      "111 Train Loss 12.892755 Test MSE 4.166567847720863 Test RE 0.9756572798524737\n",
      "112 Train Loss 12.447842 Test MSE 4.404834267528283 Test RE 1.0031660976810897\n",
      "113 Train Loss 12.24082 Test MSE 4.359475107093279 Test RE 0.9979876371049835\n",
      "114 Train Loss 12.071075 Test MSE 4.328777613320341 Test RE 0.9944677361957056\n",
      "115 Train Loss 11.939408 Test MSE 4.312163775016726 Test RE 0.9925575191647463\n",
      "116 Train Loss 11.852066 Test MSE 4.310150719720511 Test RE 0.9923258133993236\n",
      "117 Train Loss 11.829163 Test MSE 4.270204158280653 Test RE 0.9877166615577708\n",
      "118 Train Loss 11.7962 Test MSE 4.2784374230891276 Test RE 0.9886683978761293\n",
      "119 Train Loss 11.741205 Test MSE 4.268220112170555 Test RE 0.9874871756819993\n",
      "120 Train Loss 11.650709 Test MSE 4.2639387520236935 Test RE 0.9869917878082041\n",
      "121 Train Loss 11.61491 Test MSE 4.2807387046322525 Test RE 0.9889342541044026\n",
      "122 Train Loss 11.556546 Test MSE 4.3075564063596845 Test RE 0.9920271241203934\n",
      "123 Train Loss 11.491441 Test MSE 4.257091346512289 Test RE 0.9861989705490919\n",
      "124 Train Loss 11.448404 Test MSE 4.274039745585295 Test RE 0.9881601559443913\n",
      "125 Train Loss 11.410457 Test MSE 4.266474445447646 Test RE 0.9872852179865171\n",
      "126 Train Loss 11.35606 Test MSE 4.2735888456210445 Test RE 0.9881080304194172\n",
      "127 Train Loss 11.312757 Test MSE 4.244588724222463 Test RE 0.9847497252108808\n",
      "128 Train Loss 11.245656 Test MSE 4.264508428995872 Test RE 0.9870577183652557\n",
      "129 Train Loss 11.219425 Test MSE 4.24600101215064 Test RE 0.9849135378407803\n",
      "130 Train Loss 11.151752 Test MSE 4.2071904778658835 Test RE 0.9804019078524571\n",
      "131 Train Loss 11.097179 Test MSE 4.181400345384639 Test RE 0.9773923503672671\n",
      "132 Train Loss 11.023589 Test MSE 4.17871145604607 Test RE 0.9770780390964662\n",
      "133 Train Loss 10.980879 Test MSE 4.1862882249119595 Test RE 0.9779634486050558\n",
      "134 Train Loss 10.918109 Test MSE 4.148326979866379 Test RE 0.9735192663646708\n",
      "135 Train Loss 10.880415 Test MSE 4.173751420135868 Test RE 0.9764979821589705\n",
      "136 Train Loss 10.857579 Test MSE 4.179415052057706 Test RE 0.977160294031114\n",
      "137 Train Loss 10.843134 Test MSE 4.170566282623986 Test RE 0.9761253109505175\n",
      "138 Train Loss 10.827811 Test MSE 4.151992310298506 Test RE 0.9739492568109449\n",
      "139 Train Loss 10.80215 Test MSE 4.163623894734167 Test RE 0.9753125360714507\n",
      "140 Train Loss 10.788327 Test MSE 4.175043109338431 Test RE 0.9766490733715304\n",
      "141 Train Loss 10.770111 Test MSE 4.180910070100141 Test RE 0.9773350483487623\n",
      "142 Train Loss 10.760187 Test MSE 4.174446915887928 Test RE 0.9765793384545215\n",
      "143 Train Loss 10.72064 Test MSE 4.200967510120618 Test RE 0.9796765702199458\n",
      "144 Train Loss 10.681089 Test MSE 4.182736026640431 Test RE 0.9775484440555932\n",
      "145 Train Loss 10.658853 Test MSE 4.166984377173631 Test RE 0.9757060465894598\n",
      "146 Train Loss 10.653231 Test MSE 4.1895741398821515 Test RE 0.9783471864441834\n",
      "147 Train Loss 10.639774 Test MSE 4.157118897446282 Test RE 0.9745503532314393\n",
      "148 Train Loss 10.621307 Test MSE 4.195575792698914 Test RE 0.9790476870944581\n",
      "149 Train Loss 10.5977955 Test MSE 4.203217924865592 Test RE 0.9799389363792658\n",
      "Training time: 87.50\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 76.132385 Test MSE 4.377048437866694 Test RE 0.9999970909707874\n",
      "1 Train Loss 76.132385 Test MSE 4.377048668241578 Test RE 0.9999971172869473\n",
      "2 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "3 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "4 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "5 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "6 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "7 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "8 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "9 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "10 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "11 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "12 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "13 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "14 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "15 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "16 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "17 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "18 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "19 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "20 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "21 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "22 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "23 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "24 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "25 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "26 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "27 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "28 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "29 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "30 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "31 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "32 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "33 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "34 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "35 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "36 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "37 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "38 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "39 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "40 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "41 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "42 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "43 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "44 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "45 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "46 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "47 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "48 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "49 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "50 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "51 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "52 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "54 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "55 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "56 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "57 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "58 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "59 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "60 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "61 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "62 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "63 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "64 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "65 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "66 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "67 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "68 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "69 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "70 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "71 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "72 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "73 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "74 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "75 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "76 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "77 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "78 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "79 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "80 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "81 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "82 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "83 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "84 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "85 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "86 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "87 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "88 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "89 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "90 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "91 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "92 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "93 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "94 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "95 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "96 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "97 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "98 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "99 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "100 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "101 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "102 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "103 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "104 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "105 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "106 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "107 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "108 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "109 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "110 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "111 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "112 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "113 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "114 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "115 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "116 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "117 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "118 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "119 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "120 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "121 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "122 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "123 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "124 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "125 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "126 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "127 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "128 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "129 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "130 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "131 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "132 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "133 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "134 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "135 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "136 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "137 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "138 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "139 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "140 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "141 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "142 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "143 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "144 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "145 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "146 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "147 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "148 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "149 Train Loss 57.63015 Test MSE 8.678690734519883 Test RE 1.408105408317059\n",
      "Training time: 52.30\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 57.428974 Test MSE 8.6597903301788 Test RE 1.4065712905560122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 57.087547 Test MSE 8.9939222363333 Test RE 1.4334502489445\n",
      "2 Train Loss 56.66091 Test MSE 9.143213480656389 Test RE 1.4452982948205284\n",
      "3 Train Loss 54.03711 Test MSE 9.34630065065501 Test RE 1.461261472608892\n",
      "4 Train Loss 53.615883 Test MSE 8.915323023400683 Test RE 1.42717293768997\n",
      "5 Train Loss 53.13644 Test MSE 9.001392601836866 Test RE 1.4340454383585106\n",
      "6 Train Loss 52.55543 Test MSE 8.876578620224619 Test RE 1.4240684416464438\n",
      "7 Train Loss 47.47754 Test MSE 9.174061031790087 Test RE 1.4477343295872598\n",
      "8 Train Loss 44.150078 Test MSE 8.812332618580706 Test RE 1.418905593734581\n",
      "9 Train Loss 43.759155 Test MSE 8.54842715785369 Test RE 1.39749791291807\n",
      "10 Train Loss 43.689598 Test MSE 8.546898684939244 Test RE 1.3973729698637072\n",
      "11 Train Loss 43.485733 Test MSE 8.46397442929328 Test RE 1.3905776073236218\n",
      "12 Train Loss 43.158073 Test MSE 8.611409167016932 Test RE 1.4026366184779395\n",
      "13 Train Loss 42.6529 Test MSE 8.379708630166782 Test RE 1.3836381224340386\n",
      "14 Train Loss 40.408356 Test MSE 7.140513505026994 Test RE 1.277240798795406\n",
      "15 Train Loss 38.44822 Test MSE 7.611712893457675 Test RE 1.3187098789258829\n",
      "16 Train Loss 38.126045 Test MSE 7.722920264417122 Test RE 1.3283081452416297\n",
      "17 Train Loss 37.95602 Test MSE 7.685689408297641 Test RE 1.3251025057822596\n",
      "18 Train Loss 37.8353 Test MSE 7.684944363953167 Test RE 1.3250382770577733\n",
      "19 Train Loss 37.716454 Test MSE 7.7067326975106605 Test RE 1.3269153200294\n",
      "20 Train Loss 37.55773 Test MSE 7.665294538250743 Test RE 1.32334318111506\n",
      "21 Train Loss 37.49685 Test MSE 7.640176952667294 Test RE 1.3211732410278816\n",
      "22 Train Loss 37.406826 Test MSE 7.779172281142599 Test RE 1.333136917375545\n",
      "23 Train Loss 37.35665 Test MSE 7.755864788563638 Test RE 1.331138286499779\n",
      "24 Train Loss 37.324867 Test MSE 7.8106070187007335 Test RE 1.3358277280292388\n",
      "25 Train Loss 37.22012 Test MSE 7.85576129200283 Test RE 1.3396834721450421\n",
      "26 Train Loss 37.05747 Test MSE 7.751761461408067 Test RE 1.3307861131016687\n",
      "27 Train Loss 36.911644 Test MSE 7.835753790124441 Test RE 1.3379763933103432\n",
      "28 Train Loss 36.77966 Test MSE 7.687196665037791 Test RE 1.3252324337343628\n",
      "29 Train Loss 36.643982 Test MSE 7.655424749918814 Test RE 1.322490942229372\n",
      "30 Train Loss 36.513065 Test MSE 7.6471600785268254 Test RE 1.321776879655665\n",
      "31 Train Loss 36.427048 Test MSE 7.707911077075154 Test RE 1.3270167605615208\n",
      "32 Train Loss 36.353455 Test MSE 7.696409671052764 Test RE 1.3260263329222708\n",
      "33 Train Loss 36.28634 Test MSE 7.733077391216169 Test RE 1.3291813486825401\n",
      "34 Train Loss 36.229424 Test MSE 7.6146192483338115 Test RE 1.3189616141896388\n",
      "35 Train Loss 36.088623 Test MSE 7.624842908132906 Test RE 1.3198467596707535\n",
      "36 Train Loss 35.951824 Test MSE 7.71061403115252 Test RE 1.3272494144497793\n",
      "37 Train Loss 35.870895 Test MSE 7.712403377494993 Test RE 1.327403408094754\n",
      "38 Train Loss 35.765816 Test MSE 7.6876450113412185 Test RE 1.325271079447848\n",
      "39 Train Loss 35.63528 Test MSE 7.733010882226727 Test RE 1.3291756328016622\n",
      "40 Train Loss 35.56384 Test MSE 7.725204243150118 Test RE 1.3285045478443778\n",
      "41 Train Loss 35.436935 Test MSE 7.627260968771016 Test RE 1.3200560240811412\n",
      "42 Train Loss 35.37695 Test MSE 7.602029362451892 Test RE 1.317870788424744\n",
      "43 Train Loss 35.161045 Test MSE 7.724618974571024 Test RE 1.3284542225279357\n",
      "44 Train Loss 34.897705 Test MSE 7.657208473496175 Test RE 1.3226450042806297\n",
      "45 Train Loss 34.605804 Test MSE 7.597574018920018 Test RE 1.3174845476358132\n",
      "46 Train Loss 34.360794 Test MSE 7.476670908513155 Test RE 1.306959689641714\n",
      "47 Train Loss 33.927505 Test MSE 7.606691950247166 Test RE 1.3182748743643167\n",
      "48 Train Loss 32.591965 Test MSE 7.615707044309962 Test RE 1.3190558217824502\n",
      "49 Train Loss 31.243454 Test MSE 7.58105863166063 Test RE 1.3160518136490778\n",
      "50 Train Loss 30.469841 Test MSE 7.483494629998393 Test RE 1.3075559640452814\n",
      "51 Train Loss 29.44608 Test MSE 7.56817813428826 Test RE 1.314933328148659\n",
      "52 Train Loss 28.915617 Test MSE 7.19760494011754 Test RE 1.2823366742038034\n",
      "53 Train Loss 28.441328 Test MSE 6.8073505192263495 Test RE 1.247088048174903\n",
      "54 Train Loss 27.742973 Test MSE 6.477542185648937 Test RE 1.2165030028888202\n",
      "55 Train Loss 27.17889 Test MSE 6.407239659541907 Test RE 1.2098834741187636\n",
      "56 Train Loss 25.997654 Test MSE 6.045967470867479 Test RE 1.1752789653083588\n",
      "57 Train Loss 24.312916 Test MSE 6.513623964035896 Test RE 1.2198864340700328\n",
      "58 Train Loss 22.74966 Test MSE 6.60131397686441 Test RE 1.2280703753213673\n",
      "59 Train Loss 21.513844 Test MSE 6.2591064061660875 Test RE 1.1958156356097676\n",
      "60 Train Loss 20.468704 Test MSE 6.163971049504211 Test RE 1.186692931261576\n",
      "61 Train Loss 19.506168 Test MSE 6.098805087737072 Test RE 1.18040336054072\n",
      "62 Train Loss 19.037516 Test MSE 6.1883532613329 Test RE 1.1890376568943464\n",
      "63 Train Loss 18.37247 Test MSE 6.28363588228711 Test RE 1.1981565487182444\n",
      "64 Train Loss 17.112366 Test MSE 5.890810601622705 Test RE 1.1601004363679006\n",
      "65 Train Loss 16.591553 Test MSE 5.737461079292882 Test RE 1.1449010047847366\n",
      "66 Train Loss 16.353622 Test MSE 5.683227868202114 Test RE 1.1394770825492542\n",
      "67 Train Loss 15.94874 Test MSE 5.571315196750532 Test RE 1.1282021550055172\n",
      "68 Train Loss 15.7546425 Test MSE 5.605923272637251 Test RE 1.1317008314326011\n",
      "69 Train Loss 15.621075 Test MSE 5.589462281173866 Test RE 1.130038071150209\n",
      "70 Train Loss 15.359965 Test MSE 5.599910430261554 Test RE 1.1310937446037954\n",
      "71 Train Loss 15.062441 Test MSE 5.479514695843978 Test RE 1.1188686575631464\n",
      "72 Train Loss 14.866198 Test MSE 5.4976781564430075 Test RE 1.1207215327275941\n",
      "73 Train Loss 14.520573 Test MSE 5.762789926653389 Test RE 1.1474253868898558\n",
      "74 Train Loss 14.32133 Test MSE 5.678254493602256 Test RE 1.1389783970436533\n",
      "75 Train Loss 14.1599655 Test MSE 5.514804356949404 Test RE 1.1224657942561358\n",
      "76 Train Loss 13.865828 Test MSE 5.511863729469556 Test RE 1.1221664913548943\n",
      "77 Train Loss 13.464154 Test MSE 5.5952376231816086 Test RE 1.1306217293839191\n",
      "78 Train Loss 12.804161 Test MSE 5.351844667864211 Test RE 1.1057572874749273\n",
      "79 Train Loss 12.468348 Test MSE 5.269002629605105 Test RE 1.0971658158772277\n",
      "80 Train Loss 12.248915 Test MSE 5.209974205711815 Test RE 1.0910027539407319\n",
      "81 Train Loss 12.033789 Test MSE 5.166197374931 Test RE 1.0864095072153355\n",
      "82 Train Loss 11.884533 Test MSE 5.2498864612992175 Test RE 1.0951737249878062\n",
      "83 Train Loss 11.556414 Test MSE 5.205553542267702 Test RE 1.090539797762334\n",
      "84 Train Loss 11.370666 Test MSE 5.1360544730682856 Test RE 1.083235466411078\n",
      "85 Train Loss 11.250454 Test MSE 5.114068845933901 Test RE 1.0809145065741428\n",
      "86 Train Loss 11.138372 Test MSE 5.044572425925206 Test RE 1.0735449692267847\n",
      "87 Train Loss 11.071795 Test MSE 5.003021725011177 Test RE 1.0691145859114901\n",
      "88 Train Loss 10.993936 Test MSE 4.989802587712206 Test RE 1.0677012280308291\n",
      "89 Train Loss 10.838246 Test MSE 4.9670995531461735 Test RE 1.0652694992458611\n",
      "90 Train Loss 10.763249 Test MSE 4.897807344516266 Test RE 1.0578130228087665\n",
      "91 Train Loss 10.670156 Test MSE 4.84892550441149 Test RE 1.0525211128911582\n",
      "92 Train Loss 10.479216 Test MSE 4.788997657641282 Test RE 1.0459968401929314\n",
      "93 Train Loss 10.328721 Test MSE 4.760663940121447 Test RE 1.0428979719668103\n",
      "94 Train Loss 10.214639 Test MSE 4.709085426852672 Test RE 1.0372330458490704\n",
      "95 Train Loss 10.105727 Test MSE 4.726540268650797 Test RE 1.0391535878660767\n",
      "96 Train Loss 10.027492 Test MSE 4.737276653628049 Test RE 1.040333142450588\n",
      "97 Train Loss 9.926138 Test MSE 4.62852610736733 Test RE 1.0283226911824315\n",
      "98 Train Loss 9.821481 Test MSE 4.6940531018793425 Test RE 1.0355761968110382\n",
      "99 Train Loss 9.734459 Test MSE 4.753497522435161 Test RE 1.042112718339084\n",
      "100 Train Loss 9.660183 Test MSE 4.857960381392661 Test RE 1.0535012241791624\n",
      "101 Train Loss 9.596097 Test MSE 4.767421848014816 Test RE 1.0436379222294379\n",
      "102 Train Loss 9.525454 Test MSE 4.80794117308886 Test RE 1.0480635880075353\n",
      "103 Train Loss 9.386389 Test MSE 4.723104797892175 Test RE 1.0387758664773636\n",
      "104 Train Loss 9.315353 Test MSE 4.743707054961043 Test RE 1.0410389795249992\n",
      "105 Train Loss 9.127609 Test MSE 4.614803143913899 Test RE 1.0267971396682003\n",
      "106 Train Loss 8.931199 Test MSE 4.5296175839349635 Test RE 1.017276071895634\n",
      "107 Train Loss 8.76506 Test MSE 4.465713749099256 Test RE 1.0100747182208896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 Train Loss 8.684826 Test MSE 4.4266074033806575 Test RE 1.0056423709659073\n",
      "109 Train Loss 8.536474 Test MSE 4.403600707821799 Test RE 1.0030256211215842\n",
      "110 Train Loss 8.210211 Test MSE 4.14809150476898 Test RE 0.9734916356115504\n",
      "111 Train Loss 7.9604926 Test MSE 4.129518623577546 Test RE 0.9713098095118244\n",
      "112 Train Loss 7.826788 Test MSE 3.8938579056297624 Test RE 0.9431876595070797\n",
      "113 Train Loss 7.5365357 Test MSE 3.503725308728528 Test RE 0.8946910345079998\n",
      "114 Train Loss 7.3298006 Test MSE 3.3178715816195115 Test RE 0.8706384572227527\n",
      "115 Train Loss 7.094589 Test MSE 3.3817478196270794 Test RE 0.8789793446946909\n",
      "116 Train Loss 6.9714775 Test MSE 3.4424225057085516 Test RE 0.8868295309888335\n",
      "117 Train Loss 6.8722315 Test MSE 3.4319195511687792 Test RE 0.8854756231403845\n",
      "118 Train Loss 6.4985924 Test MSE 3.4088000431758303 Test RE 0.8824880305355847\n",
      "119 Train Loss 6.350811 Test MSE 3.4550470302714604 Test RE 0.8884541943273151\n",
      "120 Train Loss 6.2686396 Test MSE 3.574499364682785 Test RE 0.9036820843112591\n",
      "121 Train Loss 6.2300005 Test MSE 3.598413496480025 Test RE 0.9066999541651761\n",
      "122 Train Loss 6.158443 Test MSE 3.6540728717862385 Test RE 0.9136853517072586\n",
      "123 Train Loss 6.0994663 Test MSE 3.789859504178183 Test RE 0.9305069375553405\n",
      "124 Train Loss 6.067359 Test MSE 3.7854794478334033 Test RE 0.9299690744647605\n",
      "125 Train Loss 6.006265 Test MSE 3.7686640037723174 Test RE 0.9279012719545814\n",
      "126 Train Loss 5.95385 Test MSE 3.7951301122635592 Test RE 0.9311537469470856\n",
      "127 Train Loss 5.903125 Test MSE 3.8167337637988754 Test RE 0.933800266803041\n",
      "128 Train Loss 5.8490715 Test MSE 3.874289010892091 Test RE 0.9408146417458532\n",
      "129 Train Loss 5.8243217 Test MSE 3.9394910886616152 Test RE 0.9486982981057022\n",
      "130 Train Loss 5.804433 Test MSE 3.893158591606857 Test RE 0.9431029602204672\n",
      "131 Train Loss 5.7767835 Test MSE 3.9002978555386254 Test RE 0.9439672940061534\n",
      "132 Train Loss 5.7513638 Test MSE 3.878862957342373 Test RE 0.9413698360587832\n",
      "133 Train Loss 5.712814 Test MSE 3.8357837246885227 Test RE 0.9361277433950056\n",
      "134 Train Loss 5.679688 Test MSE 3.811998071647531 Test RE 0.9332207708974861\n",
      "135 Train Loss 5.631244 Test MSE 3.8175244888818316 Test RE 0.9338969910049341\n",
      "136 Train Loss 5.5508413 Test MSE 3.8522413049803883 Test RE 0.9381338402612197\n",
      "137 Train Loss 5.4723587 Test MSE 3.893311773398465 Test RE 0.9431215138931076\n",
      "138 Train Loss 5.433988 Test MSE 3.9007389500578515 Test RE 0.9440206703178441\n",
      "139 Train Loss 5.3710413 Test MSE 3.9156086994237262 Test RE 0.9458182782411729\n",
      "140 Train Loss 5.3015556 Test MSE 3.9030073444108613 Test RE 0.9442951183073396\n",
      "141 Train Loss 5.263552 Test MSE 3.8753051745663383 Test RE 0.9409380139286455\n",
      "142 Train Loss 5.218704 Test MSE 3.876212478167015 Test RE 0.9410481557686398\n",
      "143 Train Loss 5.186306 Test MSE 3.883011396429094 Test RE 0.9418730984668828\n",
      "144 Train Loss 5.139986 Test MSE 3.8486674974844384 Test RE 0.9376985757695563\n",
      "145 Train Loss 5.0898786 Test MSE 3.896271313947796 Test RE 0.9434799075032616\n",
      "146 Train Loss 5.0612946 Test MSE 3.9134457204811244 Test RE 0.9455570075452264\n",
      "147 Train Loss 5.0130177 Test MSE 3.9336078706422044 Test RE 0.9479896425759533\n",
      "148 Train Loss 4.9849215 Test MSE 3.9978097023195405 Test RE 0.9556945713901279\n",
      "149 Train Loss 4.9697256 Test MSE 3.966604922276608 Test RE 0.9519574423764098\n",
      "Training time: 86.35\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.23\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 76.16456 Test MSE 4.377091757751894 Test RE 1.0000020394711997\n",
      "1 Train Loss 76.16455 Test MSE 4.377093489491487 Test RE 1.0000022372900996\n",
      "2 Train Loss 57.53444 Test MSE 8.693586333159795 Test RE 1.4093132852582941\n",
      "3 Train Loss 57.42106 Test MSE 9.151219349150308 Test RE 1.4459309135562806\n",
      "4 Train Loss 55.643196 Test MSE 7.3176128757451036 Test RE 1.2929828825192384\n",
      "5 Train Loss 50.53583 Test MSE 7.752797013127307 Test RE 1.3308749994684994\n",
      "6 Train Loss 50.298386 Test MSE 8.011366988561013 Test RE 1.3528865325171568\n",
      "7 Train Loss 50.020576 Test MSE 7.800553747952352 Test RE 1.3349677588914954\n",
      "8 Train Loss 49.057056 Test MSE 7.388121521822225 Test RE 1.2991971984240516\n",
      "9 Train Loss 46.60228 Test MSE 7.080786312475095 Test RE 1.2718878082637814\n",
      "10 Train Loss 44.465584 Test MSE 7.026279043559551 Test RE 1.266982910539731\n",
      "11 Train Loss 43.103947 Test MSE 6.514535498648094 Test RE 1.2199717882302876\n",
      "12 Train Loss 42.639442 Test MSE 6.130941264196995 Test RE 1.1835091993746087\n",
      "13 Train Loss 42.168907 Test MSE 5.807153714984311 Test RE 1.1518335419565726\n",
      "14 Train Loss 41.917686 Test MSE 5.190304174559003 Test RE 1.0889412896209492\n",
      "15 Train Loss 38.538193 Test MSE 4.579607709977303 Test RE 1.022874140384204\n",
      "16 Train Loss 34.70721 Test MSE 4.681301753904517 Test RE 1.0341686741263103\n",
      "17 Train Loss 33.463062 Test MSE 4.579029585959787 Test RE 1.022809575162809\n",
      "18 Train Loss 32.33991 Test MSE 4.507816400587005 Test RE 1.014825029198424\n",
      "19 Train Loss 31.27607 Test MSE 4.3432051616459715 Test RE 0.9961236073744308\n",
      "20 Train Loss 30.287664 Test MSE 4.348104663339379 Test RE 0.9966853047256806\n",
      "21 Train Loss 29.255207 Test MSE 4.49547947785278 Test RE 1.0134353989857212\n",
      "22 Train Loss 27.86615 Test MSE 4.725221757334814 Test RE 1.0390086370930967\n",
      "23 Train Loss 26.690022 Test MSE 4.418206335681001 Test RE 1.004687635072827\n",
      "24 Train Loss 26.306087 Test MSE 4.260701058803175 Test RE 0.9866169954328254\n",
      "25 Train Loss 25.734238 Test MSE 4.5706920717927115 Test RE 1.0218779831613645\n",
      "26 Train Loss 25.221064 Test MSE 4.601586299030696 Test RE 1.0253257064431385\n",
      "27 Train Loss 25.035927 Test MSE 4.556041964542366 Test RE 1.020238993141886\n",
      "28 Train Loss 24.019184 Test MSE 4.268907279493557 Test RE 0.9875666633362931\n",
      "29 Train Loss 23.755836 Test MSE 4.202697949970916 Test RE 0.9798783209871934\n",
      "30 Train Loss 23.639574 Test MSE 4.161174282959873 Test RE 0.9750255878936234\n",
      "31 Train Loss 23.170902 Test MSE 4.2187212718584295 Test RE 0.9817444994479277\n",
      "32 Train Loss 23.0827 Test MSE 4.175667288533506 Test RE 0.9767220763602306\n",
      "33 Train Loss 23.030602 Test MSE 4.219153075238005 Test RE 0.9817947409451111\n",
      "34 Train Loss 22.698233 Test MSE 4.292804371251217 Test RE 0.9903269757460967\n",
      "35 Train Loss 22.449406 Test MSE 4.14125167867555 Test RE 0.9726887048457236\n",
      "36 Train Loss 22.318113 Test MSE 4.017002104827337 Test RE 0.9579858402475164\n",
      "37 Train Loss 22.097527 Test MSE 4.142800985084807 Test RE 0.9728706367881127\n",
      "38 Train Loss 21.9851 Test MSE 4.1871369438556805 Test RE 0.9780625786691908\n",
      "39 Train Loss 21.772696 Test MSE 4.12887739813507 Test RE 0.9712343948207904\n",
      "40 Train Loss 21.682869 Test MSE 4.197800788830905 Test RE 0.9793072567807107\n",
      "41 Train Loss 21.584885 Test MSE 4.386997623004426 Test RE 1.0011329601594978\n",
      "42 Train Loss 21.354979 Test MSE 4.294307646870947 Test RE 0.990500359385225\n",
      "43 Train Loss 21.188412 Test MSE 4.289640986467308 Test RE 0.989962020536349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 20.993055 Test MSE 4.299908285157529 Test RE 0.9911460544691053\n",
      "45 Train Loss 20.781761 Test MSE 4.293800743518172 Test RE 0.9904418979506969\n",
      "46 Train Loss 20.19345 Test MSE 4.340226051853653 Test RE 0.9957819160960033\n",
      "47 Train Loss 19.420265 Test MSE 4.466360095323959 Test RE 1.01014781228785\n",
      "48 Train Loss 18.313736 Test MSE 4.307391531474533 Test RE 0.9920081386553343\n",
      "49 Train Loss 17.617088 Test MSE 4.4681362472515875 Test RE 1.0103486467041543\n",
      "50 Train Loss 17.324863 Test MSE 4.609163466968556 Test RE 1.026169531699928\n",
      "51 Train Loss 17.008278 Test MSE 4.541810540396059 Test RE 1.018644318413652\n",
      "52 Train Loss 16.66018 Test MSE 4.5541956423312815 Test RE 1.0200322478126178\n",
      "53 Train Loss 16.564777 Test MSE 4.5221918033796955 Test RE 1.0164418770349837\n",
      "54 Train Loss 16.457253 Test MSE 4.438972355228246 Test RE 1.0070459343401912\n",
      "55 Train Loss 16.189178 Test MSE 4.425951570718857 Test RE 1.0055678717520309\n",
      "56 Train Loss 15.981393 Test MSE 4.574133349953217 Test RE 1.0222625972059658\n",
      "57 Train Loss 15.753133 Test MSE 4.535069720979323 Test RE 1.0178881170051866\n",
      "58 Train Loss 15.465429 Test MSE 4.4772645194708485 Test RE 1.0113801765560746\n",
      "59 Train Loss 15.09598 Test MSE 4.379351341543707 Test RE 1.00026012143337\n",
      "60 Train Loss 14.731997 Test MSE 4.398343942728363 Test RE 1.0024267652175964\n",
      "61 Train Loss 14.565596 Test MSE 4.385279821399618 Test RE 1.0009369358696196\n",
      "62 Train Loss 14.407452 Test MSE 4.304945222524951 Test RE 0.9917264016659388\n",
      "63 Train Loss 14.306362 Test MSE 4.283962976439484 Test RE 0.9893066188835973\n",
      "64 Train Loss 14.222069 Test MSE 4.272455981721229 Test RE 0.9879770554765144\n",
      "65 Train Loss 14.039271 Test MSE 4.24433841571821 Test RE 0.9847206888447126\n",
      "66 Train Loss 13.929504 Test MSE 4.291393342075447 Test RE 0.9901642039327555\n",
      "67 Train Loss 13.884298 Test MSE 4.276535090217701 Test RE 0.9884485763249018\n",
      "68 Train Loss 13.807419 Test MSE 4.333386409191596 Test RE 0.9949969940959287\n",
      "69 Train Loss 13.780594 Test MSE 4.3626543580215325 Test RE 0.9983514738955264\n",
      "70 Train Loss 13.738102 Test MSE 4.3193407544125835 Test RE 0.9933831607290836\n",
      "71 Train Loss 13.618427 Test MSE 4.316004193468827 Test RE 0.9929994072841919\n",
      "72 Train Loss 13.4893875 Test MSE 4.31806384543311 Test RE 0.9932363149820846\n",
      "73 Train Loss 13.443473 Test MSE 4.295322904022651 Test RE 0.9906174391599865\n",
      "74 Train Loss 13.393806 Test MSE 4.23445943888444 Test RE 0.9835740201326644\n",
      "75 Train Loss 13.323928 Test MSE 4.246019976550993 Test RE 0.9849157373543621\n",
      "76 Train Loss 13.280043 Test MSE 4.253853309649955 Test RE 0.9858238369397775\n",
      "77 Train Loss 13.142048 Test MSE 4.323054246614462 Test RE 0.9938100925569765\n",
      "78 Train Loss 13.073869 Test MSE 4.342891858935233 Test RE 0.9960876783953443\n",
      "79 Train Loss 13.04099 Test MSE 4.326182535992857 Test RE 0.9941696026573872\n",
      "80 Train Loss 13.020346 Test MSE 4.315190743400045 Test RE 0.992905826107767\n",
      "81 Train Loss 12.954492 Test MSE 4.3524421378233 Test RE 0.9971823051221514\n",
      "82 Train Loss 12.822939 Test MSE 4.332391254515834 Test RE 0.9948827378685682\n",
      "83 Train Loss 12.692511 Test MSE 4.296580351444765 Test RE 0.9907624292132363\n",
      "84 Train Loss 12.640208 Test MSE 4.257724947521375 Test RE 0.9862723579119352\n",
      "85 Train Loss 12.544746 Test MSE 4.213517735676002 Test RE 0.9811388515587893\n",
      "86 Train Loss 12.446531 Test MSE 4.215903808927201 Test RE 0.9814166168346242\n",
      "87 Train Loss 12.394093 Test MSE 4.253138872358607 Test RE 0.9857410486023198\n",
      "88 Train Loss 12.293461 Test MSE 4.212482344871994 Test RE 0.9810182961674399\n",
      "89 Train Loss 12.159561 Test MSE 4.241497047431117 Test RE 0.9843910235009573\n",
      "90 Train Loss 12.021483 Test MSE 4.198324085846794 Test RE 0.9793682950029644\n",
      "91 Train Loss 11.95171 Test MSE 4.132079586969368 Test RE 0.9716109467084427\n",
      "92 Train Loss 11.733429 Test MSE 4.151509930708459 Test RE 0.9738926783234784\n",
      "93 Train Loss 11.489445 Test MSE 4.0798282238878265 Test RE 0.9654482491873655\n",
      "94 Train Loss 11.449916 Test MSE 4.047476816885643 Test RE 0.9616128213513511\n",
      "95 Train Loss 11.369637 Test MSE 4.0726094014044145 Test RE 0.9645937419901764\n",
      "96 Train Loss 11.3266945 Test MSE 4.118522342465775 Test RE 0.9700157221734147\n",
      "97 Train Loss 11.247786 Test MSE 4.117498782984031 Test RE 0.9698951776669904\n",
      "98 Train Loss 11.161062 Test MSE 4.1091146872652775 Test RE 0.9689072189429925\n",
      "99 Train Loss 11.089443 Test MSE 4.112327886033418 Test RE 0.9692859724377265\n",
      "100 Train Loss 11.048057 Test MSE 4.099100531504901 Test RE 0.9677258566145783\n",
      "101 Train Loss 10.984172 Test MSE 4.071183865899261 Test RE 0.964424908836653\n",
      "102 Train Loss 10.933893 Test MSE 4.014624649118882 Test RE 0.957702307162565\n",
      "103 Train Loss 10.892105 Test MSE 3.998720213016287 Test RE 0.9558033960534652\n",
      "104 Train Loss 10.865646 Test MSE 3.995863116716313 Test RE 0.955461872994814\n",
      "105 Train Loss 10.846043 Test MSE 3.9828172524076555 Test RE 0.9539008815207908\n",
      "106 Train Loss 10.757647 Test MSE 4.001502311484603 Test RE 0.9561358370172235\n",
      "107 Train Loss 10.686625 Test MSE 4.0026771413041144 Test RE 0.9562761861121757\n",
      "108 Train Loss 10.607595 Test MSE 4.014905176890155 Test RE 0.957735767003039\n",
      "109 Train Loss 10.521537 Test MSE 4.008058122821008 Test RE 0.9569187530818648\n",
      "110 Train Loss 10.470969 Test MSE 4.018072086157488 Test RE 0.9581134178151405\n",
      "111 Train Loss 10.434384 Test MSE 3.9788333333898036 Test RE 0.9534236797780906\n",
      "112 Train Loss 10.41536 Test MSE 3.968392654153318 Test RE 0.9521719397851535\n",
      "113 Train Loss 10.401665 Test MSE 3.9574051021344627 Test RE 0.9508528552829915\n",
      "114 Train Loss 10.3877325 Test MSE 3.9420371521906525 Test RE 0.9490048168840671\n",
      "115 Train Loss 10.357253 Test MSE 3.940696184992372 Test RE 0.9488433911384643\n",
      "116 Train Loss 10.30069 Test MSE 3.9053746748583733 Test RE 0.9445814513214383\n",
      "117 Train Loss 10.241888 Test MSE 3.8689128465916953 Test RE 0.9401616535496591\n",
      "118 Train Loss 10.195392 Test MSE 3.8808611998886735 Test RE 0.9416122837909412\n",
      "119 Train Loss 10.171665 Test MSE 3.8503726798599605 Test RE 0.9379062801268055\n",
      "120 Train Loss 10.155102 Test MSE 3.8427484393389206 Test RE 0.9369772315566309\n",
      "121 Train Loss 10.136848 Test MSE 3.826060871870878 Test RE 0.9349405534985573\n",
      "122 Train Loss 10.084137 Test MSE 3.865419443148005 Test RE 0.9397371020256594\n",
      "123 Train Loss 10.057799 Test MSE 3.8288194755621348 Test RE 0.9352775405232372\n",
      "124 Train Loss 10.030609 Test MSE 3.8225943172300414 Test RE 0.9345169119154845\n",
      "125 Train Loss 9.995593 Test MSE 3.8331939084661624 Test RE 0.9358116661145559\n",
      "126 Train Loss 9.973217 Test MSE 3.844295279981904 Test RE 0.9371657956353863\n",
      "127 Train Loss 9.936222 Test MSE 3.8382401849963004 Test RE 0.9364274465018813\n",
      "128 Train Loss 9.854076 Test MSE 3.86121178384019 Test RE 0.9392254925800867\n",
      "129 Train Loss 9.816814 Test MSE 3.8518243172631683 Test RE 0.9380830645122149\n",
      "130 Train Loss 9.794556 Test MSE 3.83769790689628 Test RE 0.9363612935243043\n",
      "131 Train Loss 9.765692 Test MSE 3.8432373088247545 Test RE 0.9370368301768827\n",
      "132 Train Loss 9.75094 Test MSE 3.8539054606858345 Test RE 0.9383364537642629\n",
      "133 Train Loss 9.731109 Test MSE 3.84797871148707 Test RE 0.9376146632791512\n",
      "134 Train Loss 9.711989 Test MSE 3.8501246509541494 Test RE 0.937876071153004\n",
      "135 Train Loss 9.697579 Test MSE 3.8231416707510255 Test RE 0.9345838157993819\n",
      "136 Train Loss 9.670175 Test MSE 3.833666855880269 Test RE 0.9358693955259918\n",
      "137 Train Loss 9.651958 Test MSE 3.826167812171409 Test RE 0.9349536194335338\n",
      "138 Train Loss 9.635983 Test MSE 3.823870527344526 Test RE 0.9346728976556907\n",
      "139 Train Loss 9.6289015 Test MSE 3.8282710483319295 Test RE 0.9352105551190856\n",
      "140 Train Loss 9.625142 Test MSE 3.831828638359908 Test RE 0.9356449970772461\n",
      "141 Train Loss 9.59806 Test MSE 3.8220190947815427 Test RE 0.9344465964064462\n",
      "142 Train Loss 9.5693 Test MSE 3.82285690071058 Test RE 0.9345490085060515\n",
      "143 Train Loss 9.546179 Test MSE 3.839851370887819 Test RE 0.9366239689076021\n",
      "144 Train Loss 9.516242 Test MSE 3.830928782416222 Test RE 0.9355351284965873\n",
      "145 Train Loss 9.492305 Test MSE 3.821763809494483 Test RE 0.934415388497064\n",
      "146 Train Loss 9.473016 Test MSE 3.827402291957119 Test RE 0.9351044345988364\n",
      "147 Train Loss 9.457338 Test MSE 3.8303221527104974 Test RE 0.9354610543098013\n",
      "148 Train Loss 9.442198 Test MSE 3.837036612959326 Test RE 0.9362806153757939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 Train Loss 9.436995 Test MSE 3.8119245829906214 Test RE 0.9332117754218462\n",
      "Training time: 76.85\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.677864 Test MSE 8.693800835516077 Test RE 1.4093306715902492\n",
      "1 Train Loss 57.23807 Test MSE 8.83952062151592 Test RE 1.4210927275000167\n",
      "2 Train Loss 55.52195 Test MSE 8.260046328670853 Test RE 1.3737234183154596\n",
      "3 Train Loss 53.35785 Test MSE 8.750721547190343 Test RE 1.413936782808796\n",
      "4 Train Loss 51.605434 Test MSE 8.97145207564905 Test RE 1.4316584833610748\n",
      "5 Train Loss 46.407593 Test MSE 8.728301053858422 Test RE 1.4121242755930146\n",
      "6 Train Loss 44.056282 Test MSE 8.539510192425963 Test RE 1.396768849447701\n",
      "7 Train Loss 43.942844 Test MSE 8.472974230318723 Test RE 1.3913167161694864\n",
      "8 Train Loss 43.813675 Test MSE 8.606285752045322 Test RE 1.4022193024201277\n",
      "9 Train Loss 43.69497 Test MSE 8.5509776745218 Test RE 1.397706376757634\n",
      "10 Train Loss 43.60603 Test MSE 8.480114151540679 Test RE 1.3919028031568534\n",
      "11 Train Loss 43.581833 Test MSE 8.557094956308788 Test RE 1.3982062397826198\n",
      "12 Train Loss 43.454803 Test MSE 8.579632234300066 Test RE 1.400046294240424\n",
      "13 Train Loss 43.136925 Test MSE 8.524282404129295 Test RE 1.3955229237190168\n",
      "14 Train Loss 40.729404 Test MSE 8.387079044614994 Test RE 1.3842464815919682\n",
      "15 Train Loss 39.332123 Test MSE 7.6493242860972 Test RE 1.3219639031477461\n",
      "16 Train Loss 38.93094 Test MSE 7.769364962741477 Test RE 1.3322962995596874\n",
      "17 Train Loss 38.602825 Test MSE 7.781760781337862 Test RE 1.3333586979217653\n",
      "18 Train Loss 38.515514 Test MSE 7.776870142521636 Test RE 1.332939641047863\n",
      "19 Train Loss 38.463947 Test MSE 7.783154776962795 Test RE 1.3334781190278027\n",
      "20 Train Loss 38.393806 Test MSE 7.73772380952524 Test RE 1.329580607917821\n",
      "21 Train Loss 38.38372 Test MSE 7.713353171048993 Test RE 1.3274851413966295\n",
      "22 Train Loss 38.35016 Test MSE 7.676401365966348 Test RE 1.324301580312062\n",
      "23 Train Loss 38.20701 Test MSE 7.6950794136934775 Test RE 1.3259117319205647\n",
      "24 Train Loss 38.086452 Test MSE 7.759611894453341 Test RE 1.3314598053722335\n",
      "25 Train Loss 37.782642 Test MSE 7.787844506735247 Test RE 1.333879801280445\n",
      "26 Train Loss 37.484985 Test MSE 7.898724354323031 Test RE 1.343341833335129\n",
      "27 Train Loss 37.35792 Test MSE 7.932535306149874 Test RE 1.3462138897802998\n",
      "28 Train Loss 37.22955 Test MSE 7.926718809275913 Test RE 1.3457202465452074\n",
      "29 Train Loss 36.99317 Test MSE 7.99674191196926 Test RE 1.3516510937021107\n",
      "30 Train Loss 36.1291 Test MSE 8.137494377673638 Test RE 1.3634945646525403\n",
      "31 Train Loss 35.611126 Test MSE 8.308262263495832 Test RE 1.3777269661898335\n",
      "32 Train Loss 35.108517 Test MSE 8.464164564397816 Test RE 1.3905932262350502\n",
      "33 Train Loss 34.462048 Test MSE 8.311553094392481 Test RE 1.3779997920501796\n",
      "34 Train Loss 34.164066 Test MSE 8.199216999445728 Test RE 1.368655826399708\n",
      "35 Train Loss 33.888817 Test MSE 8.25285286502021 Test RE 1.3731251176838382\n",
      "36 Train Loss 33.06765 Test MSE 8.056957993994947 Test RE 1.3567305678072248\n",
      "37 Train Loss 32.063225 Test MSE 8.220038558158958 Test RE 1.3703925458029862\n",
      "38 Train Loss 30.995613 Test MSE 7.606648877628715 Test RE 1.3182711420171003\n",
      "39 Train Loss 28.507742 Test MSE 7.307043557978181 Test RE 1.2920487742648143\n",
      "40 Train Loss 27.073898 Test MSE 7.254084844542289 Test RE 1.2873581171139683\n",
      "41 Train Loss 26.333347 Test MSE 7.147983712670622 Test RE 1.2779087311385566\n",
      "42 Train Loss 25.387669 Test MSE 6.926497096336827 Test RE 1.2579543710796357\n",
      "43 Train Loss 24.578579 Test MSE 6.71280100921522 Test RE 1.238397158829525\n",
      "44 Train Loss 24.15889 Test MSE 6.469206902227939 Test RE 1.2157200545791607\n",
      "45 Train Loss 23.518032 Test MSE 6.551815650293461 Test RE 1.2234575203793268\n",
      "46 Train Loss 22.713058 Test MSE 6.559733971620368 Test RE 1.2241966135550266\n",
      "47 Train Loss 22.430326 Test MSE 6.471630160191939 Test RE 1.215947727578293\n",
      "48 Train Loss 21.97172 Test MSE 6.6337359233858 Test RE 1.2310824773722049\n",
      "49 Train Loss 21.750002 Test MSE 6.8521790234739335 Test RE 1.251187539999499\n",
      "50 Train Loss 21.227165 Test MSE 6.5356497018066815 Test RE 1.221947208760674\n",
      "51 Train Loss 19.918388 Test MSE 5.721517559581203 Test RE 1.1433091464500371\n",
      "52 Train Loss 18.18431 Test MSE 6.1040322613142015 Test RE 1.1809091031942904\n",
      "53 Train Loss 17.823244 Test MSE 6.180321280255895 Test RE 1.1882657690869423\n",
      "54 Train Loss 17.36827 Test MSE 6.0416080242236045 Test RE 1.1748551712765574\n",
      "55 Train Loss 17.032509 Test MSE 5.8894941655272985 Test RE 1.1599708036633913\n",
      "56 Train Loss 15.916174 Test MSE 5.436859402544961 Test RE 1.1145052315270478\n",
      "57 Train Loss 14.950436 Test MSE 4.896527302058901 Test RE 1.0576747840043945\n",
      "58 Train Loss 13.3795395 Test MSE 3.419472819584922 Test RE 0.883868463026166\n",
      "59 Train Loss 12.394834 Test MSE 2.8159843053279494 Test RE 0.8020901356098153\n",
      "60 Train Loss 11.574419 Test MSE 2.532322831417859 Test RE 0.7606197458211634\n",
      "61 Train Loss 10.897523 Test MSE 2.6040742319692707 Test RE 0.7713202624163235\n",
      "62 Train Loss 10.76241 Test MSE 2.6091047648728614 Test RE 0.7720649185798664\n",
      "63 Train Loss 10.407366 Test MSE 2.564707980003767 Test RE 0.7654679680512381\n",
      "64 Train Loss 10.211323 Test MSE 2.667101453936484 Test RE 0.7805987084011349\n",
      "65 Train Loss 10.061814 Test MSE 2.730231864916632 Test RE 0.7897830808429794\n",
      "66 Train Loss 9.87303 Test MSE 2.5836948973747305 Test RE 0.7682961803011549\n",
      "67 Train Loss 9.795152 Test MSE 2.656456655262339 Test RE 0.7790394082103469\n",
      "68 Train Loss 9.613955 Test MSE 2.802179474329612 Test RE 0.8001216724706417\n",
      "69 Train Loss 9.460839 Test MSE 2.7649703913753347 Test RE 0.7947916627883267\n",
      "70 Train Loss 9.351217 Test MSE 2.8290596832147106 Test RE 0.803950139864152\n",
      "71 Train Loss 9.139192 Test MSE 2.9108601093640147 Test RE 0.8154901646863292\n",
      "72 Train Loss 8.991392 Test MSE 2.8409958543876015 Test RE 0.8056443398933335\n",
      "73 Train Loss 8.933856 Test MSE 2.856591033935805 Test RE 0.8078525397120719\n",
      "74 Train Loss 8.824852 Test MSE 2.810745732099613 Test RE 0.8013437245098202\n",
      "75 Train Loss 8.587461 Test MSE 2.8147469986155036 Test RE 0.8019139022859622\n",
      "76 Train Loss 8.363098 Test MSE 2.6766306251445418 Test RE 0.7819919486980663\n",
      "77 Train Loss 7.7829375 Test MSE 2.185836792422809 Test RE 0.706670441652566\n",
      "78 Train Loss 7.0695906 Test MSE 1.8385821956748356 Test RE 0.6481112877961274\n",
      "79 Train Loss 6.4712715 Test MSE 1.8053679054800276 Test RE 0.6422304887678194\n",
      "80 Train Loss 5.7747326 Test MSE 1.8576030662115766 Test RE 0.6514551473187559\n",
      "81 Train Loss 5.5399857 Test MSE 1.7574637718595323 Test RE 0.633652643364981\n",
      "82 Train Loss 5.1421866 Test MSE 1.6259727957890147 Test RE 0.6094873522999286\n",
      "83 Train Loss 5.029832 Test MSE 1.573588922360683 Test RE 0.5995890667618924\n",
      "84 Train Loss 4.773702 Test MSE 1.3669198033233325 Test RE 0.5588298268480918\n",
      "85 Train Loss 4.462817 Test MSE 1.1688285638940072 Test RE 0.5167535495623358\n",
      "86 Train Loss 4.083968 Test MSE 1.024613071147366 Test RE 0.483824666858188\n",
      "87 Train Loss 3.606125 Test MSE 1.0237511589091124 Test RE 0.4836211255658212\n",
      "88 Train Loss 3.1945162 Test MSE 0.8622630919869889 Test RE 0.44384155283896165\n",
      "89 Train Loss 2.9854596 Test MSE 0.7299330462667071 Test RE 0.4083659972610439\n",
      "90 Train Loss 2.624771 Test MSE 0.70906688726021 Test RE 0.40248681933937985\n",
      "91 Train Loss 2.4079564 Test MSE 0.5637218177220643 Test RE 0.35887274954898424\n",
      "92 Train Loss 2.250289 Test MSE 0.5028969328358217 Test RE 0.33895929968946287\n",
      "93 Train Loss 1.9961499 Test MSE 0.43816878290739514 Test RE 0.3163943918248166\n",
      "94 Train Loss 1.7844659 Test MSE 0.34559617387859703 Test RE 0.2809910732722941\n",
      "95 Train Loss 1.6095012 Test MSE 0.3120027418850833 Test RE 0.2669852480404894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 1.4875883 Test MSE 0.33402481106329607 Test RE 0.27624690677545055\n",
      "97 Train Loss 1.3933539 Test MSE 0.32709538731640686 Test RE 0.2733664860065025\n",
      "98 Train Loss 1.3168489 Test MSE 0.30111100218289855 Test RE 0.2622837428025257\n",
      "99 Train Loss 1.166442 Test MSE 0.25940069627453094 Test RE 0.24344094712814413\n",
      "100 Train Loss 0.8388552 Test MSE 0.14652176286005714 Test RE 0.18296125385253972\n",
      "101 Train Loss 0.6817297 Test MSE 0.08813642545600789 Test RE 0.14190110478629364\n",
      "102 Train Loss 0.62754977 Test MSE 0.07664636765941851 Test RE 0.132328640070238\n",
      "103 Train Loss 0.53207076 Test MSE 0.05208490858086344 Test RE 0.10908474315257538\n",
      "104 Train Loss 0.44628042 Test MSE 0.043918219918592266 Test RE 0.1001683280444369\n",
      "105 Train Loss 0.39618945 Test MSE 0.04236965011860927 Test RE 0.09838649725049195\n",
      "106 Train Loss 0.34160045 Test MSE 0.039488707420473654 Test RE 0.09498270188777576\n",
      "107 Train Loss 0.28353 Test MSE 0.031249843144811884 Test RE 0.08449518889252282\n",
      "108 Train Loss 0.26218945 Test MSE 0.029864752157877816 Test RE 0.08260142084215315\n",
      "109 Train Loss 0.24982932 Test MSE 0.029696048451879762 Test RE 0.08236778586677158\n",
      "110 Train Loss 0.24282384 Test MSE 0.03031750624928014 Test RE 0.08322519054671512\n",
      "111 Train Loss 0.22687614 Test MSE 0.027477375418786427 Test RE 0.0792310997348916\n",
      "112 Train Loss 0.21835592 Test MSE 0.023827470193220127 Test RE 0.07378142311430394\n",
      "113 Train Loss 0.18597311 Test MSE 0.028595386108021634 Test RE 0.0808269224054173\n",
      "114 Train Loss 0.1624916 Test MSE 0.03206546023307753 Test RE 0.08559074353014791\n",
      "115 Train Loss 0.14454275 Test MSE 0.02518084522430964 Test RE 0.07584783906678373\n",
      "116 Train Loss 0.13117495 Test MSE 0.02001021230970101 Test RE 0.06761357642115413\n",
      "117 Train Loss 0.12136991 Test MSE 0.016062192145240153 Test RE 0.06057737759498941\n",
      "118 Train Loss 0.109598 Test MSE 0.015054556680560322 Test RE 0.058646492862934135\n",
      "119 Train Loss 0.096941344 Test MSE 0.015003323913343799 Test RE 0.05854661669828564\n",
      "120 Train Loss 0.08547497 Test MSE 0.011584205881993976 Test RE 0.05144476574846142\n",
      "121 Train Loss 0.07910309 Test MSE 0.009190892381640019 Test RE 0.04582335683816361\n",
      "122 Train Loss 0.07164992 Test MSE 0.008498503200472449 Test RE 0.044063529512448324\n",
      "123 Train Loss 0.064460084 Test MSE 0.008002705701730787 Test RE 0.04275889597704549\n",
      "124 Train Loss 0.06183743 Test MSE 0.007462823163224298 Test RE 0.04129140262972327\n",
      "125 Train Loss 0.06025352 Test MSE 0.007383902887106654 Test RE 0.04107249149863722\n",
      "126 Train Loss 0.057960927 Test MSE 0.00736540021622383 Test RE 0.04102099925429253\n",
      "127 Train Loss 0.056508455 Test MSE 0.006821356832483619 Test RE 0.039476936634614386\n",
      "128 Train Loss 0.05413871 Test MSE 0.006164020752509118 Test RE 0.03752667675681147\n",
      "129 Train Loss 0.053152256 Test MSE 0.006044958115496625 Test RE 0.03716248169605976\n",
      "130 Train Loss 0.05191707 Test MSE 0.005993765371787576 Test RE 0.03700478876307123\n",
      "131 Train Loss 0.050247885 Test MSE 0.005894579935857703 Test RE 0.036697332005945764\n",
      "132 Train Loss 0.04889877 Test MSE 0.0058282138593816445 Test RE 0.036490162713568065\n",
      "133 Train Loss 0.04476402 Test MSE 0.005398881539031734 Test RE 0.035120440907963464\n",
      "134 Train Loss 0.041935388 Test MSE 0.004411713040768863 Test RE 0.031747657639501665\n",
      "135 Train Loss 0.04043018 Test MSE 0.0037786925607030254 Test RE 0.02938182986117082\n",
      "136 Train Loss 0.038234543 Test MSE 0.0037162793400169914 Test RE 0.029138167517899466\n",
      "137 Train Loss 0.03773036 Test MSE 0.0038289118852625655 Test RE 0.02957642963605491\n",
      "138 Train Loss 0.036551498 Test MSE 0.0034079588257269326 Test RE 0.0279032782458983\n",
      "139 Train Loss 0.03347128 Test MSE 0.0028051764272083303 Test RE 0.025315595667283603\n",
      "140 Train Loss 0.027912771 Test MSE 0.002291155180315118 Test RE 0.022878909098682117\n",
      "141 Train Loss 0.026475104 Test MSE 0.0022945302257479957 Test RE 0.022895754082054395\n",
      "142 Train Loss 0.0257639 Test MSE 0.0022592181054211105 Test RE 0.022718891642947703\n",
      "143 Train Loss 0.025379403 Test MSE 0.002249563472558073 Test RE 0.022670295760105375\n",
      "144 Train Loss 0.024890315 Test MSE 0.0020812308892705577 Test RE 0.02180560756223483\n",
      "145 Train Loss 0.02438879 Test MSE 0.0021859654380991973 Test RE 0.022347539101636987\n",
      "146 Train Loss 0.023893991 Test MSE 0.002359663207345399 Test RE 0.02321844180309057\n",
      "147 Train Loss 0.023062818 Test MSE 0.0021154974253541686 Test RE 0.02198438448563527\n",
      "148 Train Loss 0.022698782 Test MSE 0.0019626838389522265 Test RE 0.021175478533137802\n",
      "149 Train Loss 0.021958604 Test MSE 0.0018300884695780434 Test RE 0.020447682952542935\n",
      "Training time: 77.15\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "1 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "2 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "3 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "4 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "5 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "6 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "7 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "8 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "9 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "10 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "11 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "12 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "13 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "14 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "15 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "16 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "17 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "18 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "19 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "20 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "21 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "22 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "23 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "24 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "25 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "26 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "27 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "28 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "29 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "30 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "31 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "32 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "33 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "34 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "35 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "36 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "37 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "38 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "40 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "41 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "42 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "43 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "44 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "45 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "46 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "47 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "48 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "49 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "50 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "51 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "52 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "53 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "54 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "55 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "56 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "57 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "58 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "59 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "60 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "61 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "62 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "63 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "64 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "65 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "66 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "67 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "68 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "69 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "70 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "71 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "72 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "73 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "74 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "75 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "76 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "77 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "78 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "79 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "80 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "81 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "82 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "83 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "84 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "85 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "86 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "87 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "88 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "89 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "90 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "91 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "92 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "93 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "94 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "95 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "96 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "97 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "98 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "99 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "100 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "101 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "102 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "103 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "104 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "105 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "106 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "107 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "108 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "109 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "110 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "111 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "112 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "113 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "114 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "115 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "116 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "117 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "118 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "119 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "120 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "121 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "122 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "123 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "124 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "125 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "126 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "127 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "128 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "129 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "130 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "131 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "132 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "133 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "134 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "135 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "136 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "137 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "138 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "139 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "140 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "141 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "142 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "143 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "144 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "146 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "147 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "148 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "149 Train Loss 57.033115 Test MSE 8.648217792527943 Test RE 1.405631138405125\n",
      "Training time: 36.63\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 57.013565 Test MSE 8.647913025444092 Test RE 1.4056063706502224\n",
      "1 Train Loss 56.57378 Test MSE 8.829946310835322 Test RE 1.4203229080660567\n",
      "2 Train Loss 54.538723 Test MSE 8.394772285640833 Test RE 1.3848812020230277\n",
      "3 Train Loss 51.641464 Test MSE 9.050930942092151 Test RE 1.4379860929430481\n",
      "4 Train Loss 44.092896 Test MSE 8.681008356348855 Test RE 1.4082934112132546\n",
      "5 Train Loss 43.72284 Test MSE 8.3078914418283 Test RE 1.3776962198859999\n",
      "6 Train Loss 43.509792 Test MSE 8.382080193164354 Test RE 1.3838339020835795\n",
      "7 Train Loss 43.45046 Test MSE 8.495926993307885 Test RE 1.3931999371032882\n",
      "8 Train Loss 43.329506 Test MSE 8.51019458912042 Test RE 1.3943692783217116\n",
      "9 Train Loss 43.27057 Test MSE 8.4852473667724 Test RE 1.3923240153964291\n",
      "10 Train Loss 43.19725 Test MSE 8.48326188432082 Test RE 1.3921611093246888\n",
      "11 Train Loss 43.085106 Test MSE 8.434689847709583 Test RE 1.3881698868832606\n",
      "12 Train Loss 42.990517 Test MSE 8.452638296281213 Test RE 1.3896460677348967\n",
      "13 Train Loss 42.723557 Test MSE 8.284878130133293 Test RE 1.3757867498596625\n",
      "14 Train Loss 40.11868 Test MSE 7.698733914172165 Test RE 1.326226541530114\n",
      "15 Train Loss 39.078728 Test MSE 7.790221184692233 Test RE 1.3340833210660663\n",
      "16 Train Loss 38.849243 Test MSE 7.660634974497012 Test RE 1.322940904382626\n",
      "17 Train Loss 38.594402 Test MSE 7.603008679021481 Test RE 1.3179556717549483\n",
      "18 Train Loss 38.417236 Test MSE 7.701145974868055 Test RE 1.326434282726768\n",
      "19 Train Loss 38.31379 Test MSE 7.6902124886815075 Test RE 1.3254923643415273\n",
      "20 Train Loss 38.21716 Test MSE 7.674078553489292 Test RE 1.3241012040665208\n",
      "21 Train Loss 38.106907 Test MSE 7.715317491909284 Test RE 1.3276541626187728\n",
      "22 Train Loss 37.86486 Test MSE 7.578716105082167 Test RE 1.315848469717208\n",
      "23 Train Loss 37.41497 Test MSE 7.379152843606009 Test RE 1.2984083903396997\n",
      "24 Train Loss 36.53752 Test MSE 7.0129562548765 Test RE 1.2657811539164414\n",
      "25 Train Loss 35.65645 Test MSE 7.319576104318744 Test RE 1.2931563168583513\n",
      "26 Train Loss 35.015743 Test MSE 7.202605187409212 Test RE 1.282782022851177\n",
      "27 Train Loss 34.771317 Test MSE 7.228359050435405 Test RE 1.2850733544359472\n",
      "28 Train Loss 34.6967 Test MSE 7.215781543533823 Test RE 1.2839548394314173\n",
      "29 Train Loss 34.533882 Test MSE 7.1495585521163845 Test RE 1.2780494974247376\n",
      "30 Train Loss 34.39761 Test MSE 7.1266713092601535 Test RE 1.2760022048375324\n",
      "31 Train Loss 34.291084 Test MSE 7.201588080722447 Test RE 1.2826914464414119\n",
      "32 Train Loss 34.12466 Test MSE 7.105208677078654 Test RE 1.2740793564944197\n",
      "33 Train Loss 34.02525 Test MSE 7.127827247799408 Test RE 1.2761056837448328\n",
      "34 Train Loss 33.95176 Test MSE 7.108348314714573 Test RE 1.2743608194241929\n",
      "35 Train Loss 33.867035 Test MSE 7.1256927634825855 Test RE 1.2759145994618994\n",
      "36 Train Loss 33.79533 Test MSE 7.191343975073513 Test RE 1.2817788211479704\n",
      "37 Train Loss 33.68834 Test MSE 7.185296047020095 Test RE 1.2812397190909908\n",
      "38 Train Loss 33.579266 Test MSE 7.163025445422481 Test RE 1.2792525968120605\n",
      "39 Train Loss 33.515045 Test MSE 7.122205779500184 Test RE 1.2756023745072707\n",
      "40 Train Loss 33.444477 Test MSE 7.193633819957514 Test RE 1.281982874874166\n",
      "41 Train Loss 33.31659 Test MSE 7.230658493863013 Test RE 1.285277738203581\n",
      "42 Train Loss 33.213768 Test MSE 7.168579033412205 Test RE 1.2797484114230322\n",
      "43 Train Loss 33.121513 Test MSE 7.111753145367451 Test RE 1.274665986189406\n",
      "44 Train Loss 33.022655 Test MSE 7.161612940724545 Test RE 1.2791264602092187\n",
      "45 Train Loss 32.975807 Test MSE 7.1289467510167155 Test RE 1.2762058929866418\n",
      "46 Train Loss 32.92142 Test MSE 7.0813422037523095 Test RE 1.2719377333307744\n",
      "47 Train Loss 32.896767 Test MSE 7.117554304278146 Test RE 1.2751857618656355\n",
      "48 Train Loss 32.846123 Test MSE 7.17449446429305 Test RE 1.2802763195452238\n",
      "49 Train Loss 32.796623 Test MSE 7.105552403320725 Test RE 1.2741101739716323\n",
      "50 Train Loss 32.742264 Test MSE 7.133986768300285 Test RE 1.2766569388103868\n",
      "51 Train Loss 32.681885 Test MSE 7.188951063859444 Test RE 1.2815655482104957\n",
      "52 Train Loss 32.562584 Test MSE 7.149243560132671 Test RE 1.2780213432542558\n",
      "53 Train Loss 32.460655 Test MSE 7.23879501487802 Test RE 1.2860006840480567\n",
      "54 Train Loss 32.35743 Test MSE 7.209921712755759 Test RE 1.2834333930610982\n",
      "55 Train Loss 32.2688 Test MSE 7.194243151962395 Test RE 1.2820371684811143\n",
      "56 Train Loss 32.156654 Test MSE 7.217372333964774 Test RE 1.2840963619054502\n",
      "57 Train Loss 32.01261 Test MSE 7.291010448171542 Test RE 1.290630489584451\n",
      "58 Train Loss 31.82868 Test MSE 7.318182929561271 Test RE 1.293033244261842\n",
      "59 Train Loss 31.719326 Test MSE 7.28790605889121 Test RE 1.290355695983222\n",
      "60 Train Loss 31.591698 Test MSE 7.330773913671648 Test RE 1.2941451025265662\n",
      "61 Train Loss 31.366024 Test MSE 7.338594379502345 Test RE 1.2948352151866678\n",
      "62 Train Loss 31.260746 Test MSE 7.453060192925634 Test RE 1.3048944219311536\n",
      "63 Train Loss 31.134708 Test MSE 7.405908725100414 Test RE 1.3007601933139723\n",
      "64 Train Loss 30.989017 Test MSE 7.3701680769412 Test RE 1.2976176864542381\n",
      "65 Train Loss 30.835592 Test MSE 7.284575947098216 Test RE 1.290060856857598\n",
      "66 Train Loss 30.687996 Test MSE 7.138964175687409 Test RE 1.2771022251482989\n",
      "67 Train Loss 30.378172 Test MSE 7.21343798296435 Test RE 1.2837463193788043\n",
      "68 Train Loss 29.851185 Test MSE 6.869604970250267 Test RE 1.2527774928440036\n",
      "69 Train Loss 28.47456 Test MSE 6.979694704758002 Test RE 1.2627758676004988\n",
      "70 Train Loss 27.581715 Test MSE 7.137314949847441 Test RE 1.276954700129527\n",
      "71 Train Loss 26.958138 Test MSE 7.133699925776912 Test RE 1.2766312727143594\n",
      "72 Train Loss 26.728573 Test MSE 7.13824711363365 Test RE 1.277038085273199\n",
      "73 Train Loss 26.50204 Test MSE 7.175938129491583 Test RE 1.280405122864152\n",
      "74 Train Loss 26.309834 Test MSE 7.154857405197215 Test RE 1.278523019121144\n",
      "75 Train Loss 26.175407 Test MSE 7.126851353845354 Test RE 1.2760183228698327\n",
      "76 Train Loss 26.00627 Test MSE 7.17304295093266 Test RE 1.2801468029504064\n",
      "77 Train Loss 25.82547 Test MSE 7.1576808723096885 Test RE 1.278775261159607\n",
      "78 Train Loss 25.475266 Test MSE 7.126208917577322 Test RE 1.2759608094685178\n",
      "79 Train Loss 25.334984 Test MSE 7.225946351454586 Test RE 1.2848588691069287\n",
      "80 Train Loss 24.86956 Test MSE 7.159926876545663 Test RE 1.2789758784704837\n",
      "81 Train Loss 24.62377 Test MSE 7.185530625235229 Test RE 1.281260633223931\n",
      "82 Train Loss 24.291779 Test MSE 7.056967572112696 Test RE 1.2697467829680604\n",
      "83 Train Loss 23.791878 Test MSE 6.898948095555753 Test RE 1.2554502255361526\n",
      "84 Train Loss 23.363926 Test MSE 6.836033477936424 Test RE 1.2497126063207096\n",
      "85 Train Loss 22.78664 Test MSE 6.794153807302104 Test RE 1.2458786609464871\n",
      "86 Train Loss 22.309364 Test MSE 6.865663313159862 Test RE 1.2524180305569474\n",
      "87 Train Loss 21.973804 Test MSE 6.801678970210283 Test RE 1.2465684337677316\n",
      "88 Train Loss 21.504818 Test MSE 6.556539175183831 Test RE 1.2238984661519712\n",
      "89 Train Loss 20.85252 Test MSE 6.348916512839414 Test RE 1.2043642855698764\n",
      "90 Train Loss 20.210789 Test MSE 6.001815478474252 Test RE 1.170979736785414\n",
      "91 Train Loss 19.557573 Test MSE 5.768148566655207 Test RE 1.1479587406093468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 18.002357 Test MSE 5.611232133397874 Test RE 1.1322365701593018\n",
      "93 Train Loss 17.545353 Test MSE 5.594862988319031 Test RE 1.1305838777826893\n",
      "94 Train Loss 17.099775 Test MSE 5.651096330778512 Test RE 1.1362513586681482\n",
      "95 Train Loss 16.524433 Test MSE 5.5172664560718445 Test RE 1.1227163302208207\n",
      "96 Train Loss 16.100592 Test MSE 5.3590458437448865 Test RE 1.106500963387819\n",
      "97 Train Loss 15.195541 Test MSE 5.430886601814529 Test RE 1.113892879211157\n",
      "98 Train Loss 14.418981 Test MSE 5.251237171419562 Test RE 1.095314601091462\n",
      "99 Train Loss 13.446987 Test MSE 4.956329950898988 Test RE 1.0641140206744417\n",
      "100 Train Loss 12.875839 Test MSE 4.847282521177415 Test RE 1.0523427825528482\n",
      "101 Train Loss 12.568078 Test MSE 4.7742562072887536 Test RE 1.04438571027178\n",
      "102 Train Loss 12.114689 Test MSE 4.586836818644264 Test RE 1.023681147551689\n",
      "103 Train Loss 11.513516 Test MSE 4.393939905489224 Test RE 1.0019247773643873\n",
      "104 Train Loss 11.050345 Test MSE 4.296499499859721 Test RE 0.990753107254481\n",
      "105 Train Loss 10.674216 Test MSE 4.095051212956555 Test RE 0.967247751909768\n",
      "106 Train Loss 10.297811 Test MSE 3.964706158907609 Test RE 0.9517295701381255\n",
      "107 Train Loss 9.911732 Test MSE 4.212057368617039 Test RE 0.9809688099069738\n",
      "108 Train Loss 9.377436 Test MSE 4.292088575478135 Test RE 0.99024440717853\n",
      "109 Train Loss 8.977269 Test MSE 4.296351494608896 Test RE 0.9907360424410202\n",
      "110 Train Loss 8.573817 Test MSE 4.407180259572892 Test RE 1.0034332026696409\n",
      "111 Train Loss 8.221386 Test MSE 4.309390415425145 Test RE 0.9922382871267916\n",
      "112 Train Loss 7.7164845 Test MSE 4.15126241869769 Test RE 0.9738636462686295\n",
      "113 Train Loss 7.5582514 Test MSE 4.128202746208558 Test RE 0.9711550425100939\n",
      "114 Train Loss 7.394488 Test MSE 4.092234602392173 Test RE 0.9669150541344128\n",
      "115 Train Loss 7.043374 Test MSE 3.9265484459871347 Test RE 0.9471386087503595\n",
      "116 Train Loss 6.9088936 Test MSE 3.795456198352144 Test RE 0.9311937494966998\n",
      "117 Train Loss 6.719963 Test MSE 3.776777840623302 Test RE 0.9288996087038655\n",
      "118 Train Loss 6.6079874 Test MSE 3.702921583430356 Test RE 0.9197722823801628\n",
      "119 Train Loss 6.41199 Test MSE 3.708169532353658 Test RE 0.9204238231742617\n",
      "120 Train Loss 6.230827 Test MSE 3.635636697606143 Test RE 0.9113774936239267\n",
      "121 Train Loss 6.0343494 Test MSE 3.626505622340887 Test RE 0.9102322900545172\n",
      "122 Train Loss 5.9202647 Test MSE 3.6427093490983706 Test RE 0.9122635452403836\n",
      "123 Train Loss 5.824416 Test MSE 3.62855657917162 Test RE 0.9104896429245682\n",
      "124 Train Loss 5.718243 Test MSE 3.6440691344478644 Test RE 0.9124337985795368\n",
      "125 Train Loss 5.5816927 Test MSE 3.610112078468106 Test RE 0.9081726165928633\n",
      "126 Train Loss 5.5143514 Test MSE 3.6432925564039387 Test RE 0.9123365702088488\n",
      "127 Train Loss 5.3730063 Test MSE 3.6631428202122693 Test RE 0.9148185998993469\n",
      "128 Train Loss 5.226966 Test MSE 3.5176588450609234 Test RE 0.8964682629840779\n",
      "129 Train Loss 5.1408043 Test MSE 3.5546950953041554 Test RE 0.9011752127944445\n",
      "130 Train Loss 5.067832 Test MSE 3.5561052737784347 Test RE 0.901353947093932\n",
      "131 Train Loss 5.0034966 Test MSE 3.5394290214943527 Test RE 0.8992380269788439\n",
      "132 Train Loss 4.962922 Test MSE 3.5747336927931395 Test RE 0.9037117044934453\n",
      "133 Train Loss 4.83572 Test MSE 3.6177296221298443 Test RE 0.9091302598579977\n",
      "134 Train Loss 4.76502 Test MSE 3.573565802191267 Test RE 0.90356406795379\n",
      "135 Train Loss 4.707517 Test MSE 3.579428616662923 Test RE 0.9043049606389483\n",
      "136 Train Loss 4.672793 Test MSE 3.5529185313287184 Test RE 0.9009499901717047\n",
      "137 Train Loss 4.571924 Test MSE 3.6242425465403167 Test RE 0.9099482361537399\n",
      "138 Train Loss 4.5052834 Test MSE 3.6441484925665177 Test RE 0.9124437337142398\n",
      "139 Train Loss 4.4503045 Test MSE 3.6735611514299777 Test RE 0.9161185923617516\n",
      "140 Train Loss 4.40843 Test MSE 3.687009587249596 Test RE 0.9177939567236961\n",
      "141 Train Loss 4.386284 Test MSE 3.653343273598454 Test RE 0.9135941306945412\n",
      "142 Train Loss 4.3411446 Test MSE 3.6650739893033193 Test RE 0.9150597093386816\n",
      "143 Train Loss 4.271412 Test MSE 3.5823390701095597 Test RE 0.9046725336482094\n",
      "144 Train Loss 4.2396135 Test MSE 3.5483871076805213 Test RE 0.9003752670774842\n",
      "145 Train Loss 4.1584797 Test MSE 3.509348360074211 Test RE 0.8954086816275693\n",
      "146 Train Loss 4.1206923 Test MSE 3.486613466018934 Test RE 0.892503569797011\n",
      "147 Train Loss 4.101803 Test MSE 3.483085975356244 Test RE 0.892051971886196\n",
      "148 Train Loss 4.0740986 Test MSE 3.4699595157759395 Test RE 0.8903694786533795\n",
      "149 Train Loss 4.0342007 Test MSE 3.4321058584101545 Test RE 0.8854996575443569\n",
      "Training time: 76.62\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.315163 Test MSE 8.457735596897802 Test RE 1.3900650124434608\n",
      "1 Train Loss 55.954624 Test MSE 8.65181398959756 Test RE 1.4059233605318446\n",
      "2 Train Loss 51.86759 Test MSE 8.120815340569528 Test RE 1.3620965027601082\n",
      "3 Train Loss 51.46368 Test MSE 8.192453088494231 Test RE 1.3680911763758778\n",
      "4 Train Loss 50.912727 Test MSE 8.222305437757997 Test RE 1.3705814926514508\n",
      "5 Train Loss 49.632393 Test MSE 7.868024335081459 Test RE 1.3407287043736862\n",
      "6 Train Loss 49.30581 Test MSE 8.145467411924468 Test RE 1.3641623701706778\n",
      "7 Train Loss 47.904453 Test MSE 7.264822833746492 Test RE 1.2883105822402086\n",
      "8 Train Loss 42.92816 Test MSE 6.532616137869005 Test RE 1.2216635885090235\n",
      "9 Train Loss 38.810154 Test MSE 6.447704806435804 Test RE 1.2136979916853203\n",
      "10 Train Loss 37.450882 Test MSE 6.625034632861164 Test RE 1.2302748237825523\n",
      "11 Train Loss 35.6865 Test MSE 5.837659379014402 Test RE 1.1548549380043855\n",
      "12 Train Loss 34.86276 Test MSE 5.271317842972117 Test RE 1.0974068381506008\n",
      "13 Train Loss 34.21895 Test MSE 5.276849868788654 Test RE 1.0979825282523932\n",
      "14 Train Loss 33.39405 Test MSE 5.268701533927882 Test RE 1.0971344668129752\n",
      "15 Train Loss 31.485607 Test MSE 5.058114072626234 Test RE 1.074984915210173\n",
      "16 Train Loss 27.024769 Test MSE 4.8753974659622275 Test RE 1.055390240739697\n",
      "17 Train Loss 24.741783 Test MSE 5.106018305148543 Test RE 1.0800633864659823\n",
      "18 Train Loss 23.5273 Test MSE 4.716876392219029 Test RE 1.0380907184475534\n",
      "19 Train Loss 21.097525 Test MSE 4.728868288360434 Test RE 1.0394094697674274\n",
      "20 Train Loss 18.88883 Test MSE 4.137439625403628 Test RE 0.9722409181452862\n",
      "21 Train Loss 15.444828 Test MSE 2.5964141487750725 Test RE 0.7701849781961155\n",
      "22 Train Loss 11.923707 Test MSE 2.0308811259287953 Test RE 0.6811618432356175\n",
      "23 Train Loss 10.344003 Test MSE 1.8907044557894757 Test RE 0.6572337909798142\n",
      "24 Train Loss 9.116263 Test MSE 1.7995729043035247 Test RE 0.6411989212417181\n",
      "25 Train Loss 8.107889 Test MSE 1.7954608432169423 Test RE 0.6404659259156694\n",
      "26 Train Loss 7.22357 Test MSE 2.2357392827630247 Test RE 0.7146915363945666\n",
      "27 Train Loss 6.370112 Test MSE 2.294042290702513 Test RE 0.7239503296626538\n",
      "28 Train Loss 5.5039716 Test MSE 2.1573995547905045 Test RE 0.7020585821820797\n",
      "29 Train Loss 5.2298164 Test MSE 2.1501609504155517 Test RE 0.7008798032546905\n",
      "30 Train Loss 5.0038075 Test MSE 2.152053166056717 Test RE 0.7011881346090214\n",
      "31 Train Loss 4.8258977 Test MSE 2.157407708942222 Test RE 0.7020599089383525\n",
      "32 Train Loss 4.7074413 Test MSE 2.195617033649229 Test RE 0.7082496294517266\n",
      "33 Train Loss 4.6286507 Test MSE 2.164174960625458 Test RE 0.7031601405319335\n",
      "34 Train Loss 4.5701675 Test MSE 2.135858408836355 Test RE 0.6985448412294898\n",
      "35 Train Loss 4.525864 Test MSE 2.1979628796733444 Test RE 0.7086278832655096\n",
      "36 Train Loss 4.4882655 Test MSE 2.1827072916373877 Test RE 0.7061643842362423\n",
      "37 Train Loss 4.4382505 Test MSE 2.1211332935676146 Test RE 0.6961327095453718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 4.4175797 Test MSE 2.1245946631225965 Test RE 0.6967004697990217\n",
      "39 Train Loss 4.392703 Test MSE 2.1613882110969684 Test RE 0.7027072745573638\n",
      "40 Train Loss 4.366973 Test MSE 2.1667557816563696 Test RE 0.7035792817309426\n",
      "41 Train Loss 4.3383055 Test MSE 2.1580192623352894 Test RE 0.7021594072148186\n",
      "42 Train Loss 4.3164654 Test MSE 2.144465805188399 Test RE 0.6999509753629628\n",
      "43 Train Loss 4.2831254 Test MSE 2.1329395314567625 Test RE 0.6980673601802264\n",
      "44 Train Loss 4.270836 Test MSE 2.146216922093783 Test RE 0.7002366982378407\n",
      "45 Train Loss 4.2549257 Test MSE 2.1294027521124517 Test RE 0.6974883623927828\n",
      "46 Train Loss 4.231907 Test MSE 2.1087861267501675 Test RE 0.6941036499928812\n",
      "47 Train Loss 4.2189636 Test MSE 2.1059106227261677 Test RE 0.6936302547370841\n",
      "48 Train Loss 4.1974735 Test MSE 2.1105516128928614 Test RE 0.6943941427041463\n",
      "49 Train Loss 4.184886 Test MSE 2.1024465002624617 Test RE 0.6930595256031723\n",
      "50 Train Loss 4.177118 Test MSE 2.099087690505688 Test RE 0.6925056980577904\n",
      "51 Train Loss 4.1676035 Test MSE 2.106173640124994 Test RE 0.6936735688092434\n",
      "52 Train Loss 4.1560206 Test MSE 2.11836615333567 Test RE 0.6956784888029655\n",
      "53 Train Loss 4.1474776 Test MSE 2.1171477959156344 Test RE 0.6954784037155589\n",
      "54 Train Loss 4.1404314 Test MSE 2.108805958811925 Test RE 0.6941069138312367\n",
      "55 Train Loss 4.13537 Test MSE 2.1050365304081042 Test RE 0.6934862885599121\n",
      "56 Train Loss 4.124601 Test MSE 2.100674344339999 Test RE 0.6927673734682894\n",
      "57 Train Loss 4.116676 Test MSE 2.0991968737305764 Test RE 0.6925237080300581\n",
      "58 Train Loss 4.105971 Test MSE 2.090753437776115 Test RE 0.6911295626624117\n",
      "59 Train Loss 4.09555 Test MSE 2.082349778195917 Test RE 0.68973918695627\n",
      "60 Train Loss 4.0882154 Test MSE 2.0730657390533223 Test RE 0.6881998876712448\n",
      "61 Train Loss 4.073583 Test MSE 2.085807212629723 Test RE 0.6903115545260676\n",
      "62 Train Loss 4.0676255 Test MSE 2.1046702509362665 Test RE 0.6934259521148406\n",
      "63 Train Loss 4.0622406 Test MSE 2.105435228463173 Test RE 0.6935519592833647\n",
      "64 Train Loss 4.0436835 Test MSE 2.0726084873738513 Test RE 0.6881239860964564\n",
      "65 Train Loss 4.0177035 Test MSE 2.064434986239546 Test RE 0.6867658091352199\n",
      "66 Train Loss 3.9744554 Test MSE 2.081500540423804 Test RE 0.689598525596165\n",
      "67 Train Loss 3.8880603 Test MSE 2.0412734599500912 Test RE 0.68290242482245\n",
      "68 Train Loss 3.8474956 Test MSE 2.0374300955032627 Test RE 0.6822592284175626\n",
      "69 Train Loss 3.790505 Test MSE 2.018685420462108 Test RE 0.6791135307507291\n",
      "70 Train Loss 3.5943465 Test MSE 1.9913181950960246 Test RE 0.6744944667743556\n",
      "71 Train Loss 3.4535496 Test MSE 1.9668789945206644 Test RE 0.6703426955485046\n",
      "72 Train Loss 3.1439462 Test MSE 1.721459474375796 Test RE 0.627128390349561\n",
      "73 Train Loss 2.9704182 Test MSE 1.605976376320113 Test RE 0.60572798189673\n",
      "74 Train Loss 2.6971083 Test MSE 1.5862959149849538 Test RE 0.6020050899084363\n",
      "75 Train Loss 2.450831 Test MSE 1.5889155373499995 Test RE 0.6025019629827035\n",
      "76 Train Loss 2.2898083 Test MSE 1.6188874036676721 Test RE 0.6081579414586822\n",
      "77 Train Loss 2.1589603 Test MSE 1.5783600876680737 Test RE 0.6004973641370583\n",
      "78 Train Loss 2.056237 Test MSE 1.5142393495012958 Test RE 0.5881733246751707\n",
      "79 Train Loss 1.9951762 Test MSE 1.4373791856941807 Test RE 0.5730516087925518\n",
      "80 Train Loss 1.8821334 Test MSE 1.3508214389658881 Test RE 0.5555293805749603\n",
      "81 Train Loss 1.750572 Test MSE 1.3439822041786418 Test RE 0.5541212680474015\n",
      "82 Train Loss 1.7030357 Test MSE 1.3113256384069916 Test RE 0.5473477491535874\n",
      "83 Train Loss 1.6392374 Test MSE 1.2717000804757796 Test RE 0.5390144520787045\n",
      "84 Train Loss 1.5791969 Test MSE 1.1948453538064296 Test RE 0.5224730693686526\n",
      "85 Train Loss 1.4167321 Test MSE 1.0243970749880917 Test RE 0.48377366722676673\n",
      "86 Train Loss 1.3514354 Test MSE 0.9963312122268027 Test RE 0.47710056201725676\n",
      "87 Train Loss 1.3015795 Test MSE 0.9645833383428218 Test RE 0.46943767176291307\n",
      "88 Train Loss 1.233012 Test MSE 0.9593531235805309 Test RE 0.4681632369592783\n",
      "89 Train Loss 1.1254191 Test MSE 0.8575101134453137 Test RE 0.44261658766560613\n",
      "90 Train Loss 1.0047649 Test MSE 0.6686526844695407 Test RE 0.390848416289318\n",
      "91 Train Loss 0.9227044 Test MSE 0.5847106796747396 Test RE 0.3654925874008215\n",
      "92 Train Loss 0.81347126 Test MSE 0.4347966662301994 Test RE 0.31517456567865926\n",
      "93 Train Loss 0.69153583 Test MSE 0.28343671539271414 Test RE 0.25446972094017173\n",
      "94 Train Loss 0.64302015 Test MSE 0.2335616003259676 Test RE 0.23099829875436315\n",
      "95 Train Loss 0.5798912 Test MSE 0.1696878291855255 Test RE 0.19689441945087857\n",
      "96 Train Loss 0.50707394 Test MSE 0.1138021995348157 Test RE 0.1612439350615025\n",
      "97 Train Loss 0.4749827 Test MSE 0.10159900322249699 Test RE 0.15235362214487644\n",
      "98 Train Loss 0.44714913 Test MSE 0.09452977362963333 Test RE 0.14695770775354816\n",
      "99 Train Loss 0.42414463 Test MSE 0.0739762965773863 Test RE 0.13000329299196353\n",
      "100 Train Loss 0.40148687 Test MSE 0.07204234047023104 Test RE 0.1282927064378279\n",
      "101 Train Loss 0.37652686 Test MSE 0.0669578220917575 Test RE 0.12368263235749802\n",
      "102 Train Loss 0.35048494 Test MSE 0.05320852248386577 Test RE 0.11025509301952503\n",
      "103 Train Loss 0.3178879 Test MSE 0.05458118479014649 Test RE 0.11166820613904918\n",
      "104 Train Loss 0.2942282 Test MSE 0.0551078148994093 Test RE 0.11220563187695635\n",
      "105 Train Loss 0.27568504 Test MSE 0.049884504559590606 Test RE 0.1067556555919817\n",
      "106 Train Loss 0.26050574 Test MSE 0.04962614541255268 Test RE 0.10647884513711059\n",
      "107 Train Loss 0.24595185 Test MSE 0.04855701447008657 Test RE 0.10532562585284708\n",
      "108 Train Loss 0.2298225 Test MSE 0.05284555849385146 Test RE 0.10987839481839425\n",
      "109 Train Loss 0.2170558 Test MSE 0.0568770049840627 Test RE 0.11399253715688207\n",
      "110 Train Loss 0.20699671 Test MSE 0.05857066999170245 Test RE 0.1156773034549381\n",
      "111 Train Loss 0.19554403 Test MSE 0.05487606364454506 Test RE 0.1119694476545652\n",
      "112 Train Loss 0.18238685 Test MSE 0.04927879423451621 Test RE 0.10610554898181682\n",
      "113 Train Loss 0.17029983 Test MSE 0.04453010553022493 Test RE 0.10086370628054797\n",
      "114 Train Loss 0.16038537 Test MSE 0.04368685311803315 Test RE 0.09990412984463054\n",
      "115 Train Loss 0.1486597 Test MSE 0.03437333734746706 Test RE 0.08861738094172653\n",
      "116 Train Loss 0.13829167 Test MSE 0.03152184257947931 Test RE 0.08486211632947059\n",
      "117 Train Loss 0.13416342 Test MSE 0.03126549509473671 Test RE 0.0845163465812269\n",
      "118 Train Loss 0.12897512 Test MSE 0.03244245400688204 Test RE 0.08609241868611192\n",
      "119 Train Loss 0.1239175 Test MSE 0.03500188450647352 Test RE 0.08942393446750704\n",
      "120 Train Loss 0.11768851 Test MSE 0.036536954078960744 Test RE 0.09136381588697909\n",
      "121 Train Loss 0.11247142 Test MSE 0.036212488441436076 Test RE 0.09095723400930905\n",
      "122 Train Loss 0.10831094 Test MSE 0.03820386058215032 Test RE 0.09342469442774841\n",
      "123 Train Loss 0.104650795 Test MSE 0.04009527045463297 Test RE 0.0957094088720061\n",
      "124 Train Loss 0.10152755 Test MSE 0.039178349882770365 Test RE 0.09460871209210106\n",
      "125 Train Loss 0.09692002 Test MSE 0.03846002355961187 Test RE 0.09373738488077175\n",
      "126 Train Loss 0.093976095 Test MSE 0.039198164605231754 Test RE 0.09463263357436533\n",
      "127 Train Loss 0.09054311 Test MSE 0.04060530979952264 Test RE 0.09631622984357999\n",
      "128 Train Loss 0.089321285 Test MSE 0.04222081480500645 Test RE 0.09821354010404036\n",
      "129 Train Loss 0.08839839 Test MSE 0.042515570066486645 Test RE 0.0985557718710493\n",
      "130 Train Loss 0.08531441 Test MSE 0.04115759705496731 Test RE 0.09696903323109603\n",
      "131 Train Loss 0.08093763 Test MSE 0.043497721674432485 Test RE 0.09968764014968615\n",
      "132 Train Loss 0.07834758 Test MSE 0.04475838084265435 Test RE 0.10112190532620692\n",
      "133 Train Loss 0.07567384 Test MSE 0.04087206796443712 Test RE 0.0966320885437496\n",
      "134 Train Loss 0.07346046 Test MSE 0.0409232425261979 Test RE 0.09669256453746963\n",
      "135 Train Loss 0.072625585 Test MSE 0.042493684921478654 Test RE 0.09853040251816148\n",
      "136 Train Loss 0.07214821 Test MSE 0.04224971776589222 Test RE 0.09824715120882437\n",
      "137 Train Loss 0.071868196 Test MSE 0.04195591104380823 Test RE 0.0979049473601701\n",
      "138 Train Loss 0.07141542 Test MSE 0.04122084731942746 Test RE 0.09704351477096641\n",
      "139 Train Loss 0.06865267 Test MSE 0.038561600425569956 Test RE 0.09386108827899832\n",
      "140 Train Loss 0.065146096 Test MSE 0.03840736726169919 Test RE 0.09367319414700583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 Train Loss 0.062003613 Test MSE 0.03758880927519102 Test RE 0.09266961197084847\n",
      "142 Train Loss 0.060572635 Test MSE 0.035593070683216835 Test RE 0.09017596298025397\n",
      "143 Train Loss 0.059551492 Test MSE 0.035396372037604415 Test RE 0.08992644722976215\n",
      "144 Train Loss 0.058702424 Test MSE 0.03416514720856342 Test RE 0.08834860742766583\n",
      "145 Train Loss 0.05807365 Test MSE 0.03137214030407675 Test RE 0.08466036462039356\n",
      "146 Train Loss 0.05718187 Test MSE 0.029799881466628673 Test RE 0.08251166077615074\n",
      "147 Train Loss 0.056495994 Test MSE 0.029929197701961598 Test RE 0.08269049616367483\n",
      "148 Train Loss 0.055651855 Test MSE 0.02983357700709088 Test RE 0.08255829669176991\n",
      "149 Train Loss 0.05430298 Test MSE 0.027323133173675154 Test RE 0.07900840777573266\n",
      "Training time: 76.85\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 76.132385 Test MSE 4.3770486842608305 Test RE 0.9999971191168567\n",
      "1 Train Loss 57.631668 Test MSE 8.678307639592866 Test RE 1.4080743296665905\n",
      "2 Train Loss 57.445816 Test MSE 9.14995807482989 Test RE 1.4458312668150168\n",
      "3 Train Loss 57.148148 Test MSE 8.627954467582638 Test RE 1.4039834310393073\n",
      "4 Train Loss 56.449955 Test MSE 7.841278671014362 Test RE 1.338448004455639\n",
      "5 Train Loss 51.74086 Test MSE 8.979334687929994 Test RE 1.4322872963362558\n",
      "6 Train Loss 46.813194 Test MSE 8.017564330462763 Test RE 1.3534097066257225\n",
      "7 Train Loss 45.767788 Test MSE 8.312710599373574 Test RE 1.3780957419933368\n",
      "8 Train Loss 44.64559 Test MSE 8.168243363787372 Test RE 1.3660682403959536\n",
      "9 Train Loss 44.268105 Test MSE 8.196903935381343 Test RE 1.368462758457136\n",
      "10 Train Loss 44.03727 Test MSE 8.15109512496358 Test RE 1.3646335394968776\n",
      "11 Train Loss 43.94552 Test MSE 8.164224304239044 Test RE 1.365732122525644\n",
      "12 Train Loss 43.025444 Test MSE 8.21726881171933 Test RE 1.370161649096275\n",
      "13 Train Loss 42.839317 Test MSE 8.237814314415221 Test RE 1.3718734761220661\n",
      "14 Train Loss 42.507717 Test MSE 8.36438194685844 Test RE 1.3823721900511454\n",
      "15 Train Loss 41.242268 Test MSE 8.276575736693086 Test RE 1.3750972294008088\n",
      "16 Train Loss 39.155746 Test MSE 8.263650660307274 Test RE 1.3740231027577245\n",
      "17 Train Loss 37.560707 Test MSE 8.419975092542519 Test RE 1.3869584910304191\n",
      "18 Train Loss 36.80005 Test MSE 8.461010839493209 Test RE 1.3903341364546362\n",
      "19 Train Loss 36.4011 Test MSE 8.653134000884487 Test RE 1.4060306076320295\n",
      "20 Train Loss 36.075905 Test MSE 8.694614038096077 Test RE 1.409396583184084\n",
      "21 Train Loss 35.58847 Test MSE 8.766503016386384 Test RE 1.4152111890501065\n",
      "22 Train Loss 35.175674 Test MSE 8.782400059993511 Test RE 1.4164937691134163\n",
      "23 Train Loss 34.85157 Test MSE 8.975154499810493 Test RE 1.4319538681076929\n",
      "24 Train Loss 34.605255 Test MSE 8.864074114956962 Test RE 1.42306504000806\n",
      "25 Train Loss 34.17283 Test MSE 8.850600093779668 Test RE 1.4219830487929908\n",
      "26 Train Loss 33.94275 Test MSE 9.098447379801955 Test RE 1.4417557898396927\n",
      "27 Train Loss 33.794292 Test MSE 9.096590446628122 Test RE 1.441608655902501\n",
      "28 Train Loss 33.723373 Test MSE 9.078016482975297 Test RE 1.4401361223574478\n",
      "29 Train Loss 33.538918 Test MSE 9.109343528856686 Test RE 1.4426188428838351\n",
      "30 Train Loss 33.234764 Test MSE 9.17115749689763 Test RE 1.447505211872741\n",
      "31 Train Loss 32.58493 Test MSE 9.315829427896382 Test RE 1.4588774932923132\n",
      "32 Train Loss 31.726974 Test MSE 9.198547463880022 Test RE 1.4496651116582295\n",
      "33 Train Loss 29.816952 Test MSE 8.509953581268517 Test RE 1.3943495339833012\n",
      "34 Train Loss 29.030735 Test MSE 8.3631232372454 Test RE 1.3822681733622053\n",
      "35 Train Loss 28.45688 Test MSE 8.580196229266546 Test RE 1.400092310553534\n",
      "36 Train Loss 27.750437 Test MSE 8.12807809769779 Test RE 1.362705454252712\n",
      "37 Train Loss 27.059467 Test MSE 7.6998116542983395 Test RE 1.3263193670230462\n",
      "38 Train Loss 26.482988 Test MSE 7.233518928367769 Test RE 1.2855319397584026\n",
      "39 Train Loss 25.632137 Test MSE 6.980677335186527 Test RE 1.2628647538895668\n",
      "40 Train Loss 24.846247 Test MSE 6.754336262631186 Test RE 1.2422225231240729\n",
      "41 Train Loss 24.358946 Test MSE 6.72731839555949 Test RE 1.2397355405514194\n",
      "42 Train Loss 24.03487 Test MSE 6.75540058788041 Test RE 1.2423203918609163\n",
      "43 Train Loss 23.882723 Test MSE 6.8123071701080935 Test RE 1.2475419880190608\n",
      "44 Train Loss 23.070204 Test MSE 6.733499288180597 Test RE 1.240304928868148\n",
      "45 Train Loss 22.661999 Test MSE 6.5726205710622905 Test RE 1.2253984908879294\n",
      "46 Train Loss 22.165594 Test MSE 6.3381094617089255 Test RE 1.203338821629046\n",
      "47 Train Loss 21.761332 Test MSE 6.244089725812394 Test RE 1.1943802897686404\n",
      "48 Train Loss 21.368168 Test MSE 6.053862047509713 Test RE 1.176046030552458\n",
      "49 Train Loss 20.96271 Test MSE 6.022464506479433 Test RE 1.1729923637906372\n",
      "50 Train Loss 20.669796 Test MSE 6.04542416348908 Test RE 1.175226157210859\n",
      "51 Train Loss 20.55939 Test MSE 6.041996655239607 Test RE 1.174892957393658\n",
      "52 Train Loss 20.416935 Test MSE 6.024989552274746 Test RE 1.1732382389670233\n",
      "53 Train Loss 20.29305 Test MSE 6.118242075477218 Test RE 1.1822828462823518\n",
      "54 Train Loss 20.161243 Test MSE 6.132341619522491 Test RE 1.183644353073894\n",
      "55 Train Loss 19.939829 Test MSE 6.107940748500493 Test RE 1.1812871180282232\n",
      "56 Train Loss 19.743883 Test MSE 6.077057766238241 Test RE 1.1782969203297546\n",
      "57 Train Loss 19.637142 Test MSE 6.028394948070973 Test RE 1.1735697562367442\n",
      "58 Train Loss 19.401117 Test MSE 6.0391831836350365 Test RE 1.17461937954686\n",
      "59 Train Loss 19.159817 Test MSE 5.978428349265851 Test RE 1.1686960457041382\n",
      "60 Train Loss 18.585405 Test MSE 5.665646330784357 Test RE 1.1377131838049808\n",
      "61 Train Loss 18.167723 Test MSE 5.271734526199026 Test RE 1.0974502107947879\n",
      "62 Train Loss 17.69487 Test MSE 5.08574835990964 Test RE 1.0779174289667057\n",
      "63 Train Loss 17.528627 Test MSE 4.907408410746068 Test RE 1.058849319240716\n",
      "64 Train Loss 17.014816 Test MSE 4.667154731832113 Test RE 1.0326048487273896\n",
      "65 Train Loss 16.09944 Test MSE 4.578107901189858 Test RE 1.022706632450492\n",
      "66 Train Loss 15.801464 Test MSE 4.541115639590175 Test RE 1.0185663887169791\n",
      "67 Train Loss 15.320755 Test MSE 4.046633434381764 Test RE 0.9615126293406218\n",
      "68 Train Loss 14.760041 Test MSE 3.9136427296096183 Test RE 0.9455808076731588\n",
      "69 Train Loss 14.507302 Test MSE 4.164271686886752 Test RE 0.9753884045036898\n",
      "70 Train Loss 14.237799 Test MSE 4.239972060898657 Test RE 0.9842140437701324\n",
      "71 Train Loss 13.945096 Test MSE 4.160763222063893 Test RE 0.9749774278355352\n",
      "72 Train Loss 13.659998 Test MSE 4.10500298186607 Test RE 0.9684223385686471\n",
      "73 Train Loss 13.332618 Test MSE 3.8830496873801477 Test RE 0.9418777424305643\n",
      "74 Train Loss 13.048545 Test MSE 3.966804345963658 Test RE 0.9519813722207897\n",
      "75 Train Loss 12.795956 Test MSE 4.128428625875487 Test RE 0.971181611115176\n",
      "76 Train Loss 12.580198 Test MSE 4.200926033488597 Test RE 0.9796717339786754\n",
      "77 Train Loss 12.502145 Test MSE 4.219474430353455 Test RE 0.9818321298178609\n",
      "78 Train Loss 12.337625 Test MSE 3.984127299213502 Test RE 0.9540577493834203\n",
      "79 Train Loss 12.232029 Test MSE 3.8925160271749077 Test RE 0.943025127605778\n",
      "80 Train Loss 12.1881275 Test MSE 3.905315599240832 Test RE 0.9445743070717539\n",
      "81 Train Loss 12.029389 Test MSE 3.7781902924096595 Test RE 0.9290732889309021\n",
      "82 Train Loss 11.843575 Test MSE 3.498927658132768 Test RE 0.8940782745162662\n",
      "83 Train Loss 11.775291 Test MSE 3.451149386827795 Test RE 0.8879529196983859\n",
      "84 Train Loss 11.676675 Test MSE 3.4593071703232283 Test RE 0.8890017662209974\n",
      "85 Train Loss 11.484154 Test MSE 3.4810358471762917 Test RE 0.891789404426395\n",
      "86 Train Loss 11.312144 Test MSE 3.6374953349023347 Test RE 0.9116104244558728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 10.932868 Test MSE 3.6959603456472974 Test RE 0.9189073213709329\n",
      "88 Train Loss 10.432092 Test MSE 3.6291712588359126 Test RE 0.9105667584050893\n",
      "89 Train Loss 10.043997 Test MSE 3.5741560920341047 Test RE 0.9036386912708639\n",
      "90 Train Loss 9.739769 Test MSE 3.334401447612642 Test RE 0.8728045532088765\n",
      "91 Train Loss 9.228111 Test MSE 3.205811666687678 Test RE 0.8558094206031637\n",
      "92 Train Loss 8.907274 Test MSE 3.1409951687087805 Test RE 0.8471136785894172\n",
      "93 Train Loss 8.73253 Test MSE 3.069529268392484 Test RE 0.8374211970385078\n",
      "94 Train Loss 8.322055 Test MSE 3.0256948091238502 Test RE 0.831420292948378\n",
      "95 Train Loss 7.9115615 Test MSE 3.164723127536376 Test RE 0.8503073257194148\n",
      "96 Train Loss 7.5570426 Test MSE 3.165020339750628 Test RE 0.8503472527177073\n",
      "97 Train Loss 7.297206 Test MSE 3.0703489900880356 Test RE 0.8375330067722061\n",
      "98 Train Loss 6.9370413 Test MSE 3.177314423326399 Test RE 0.8519971801635272\n",
      "99 Train Loss 6.729661 Test MSE 3.316316327491052 Test RE 0.870434377176487\n",
      "100 Train Loss 6.425267 Test MSE 3.1557189675173696 Test RE 0.8490968316982703\n",
      "101 Train Loss 6.139678 Test MSE 3.056742406098449 Test RE 0.8356751370475686\n",
      "102 Train Loss 5.6914277 Test MSE 3.1955441299167906 Test RE 0.8544378332068429\n",
      "103 Train Loss 5.352789 Test MSE 3.160726339876272 Test RE 0.8497702216230464\n",
      "104 Train Loss 5.140566 Test MSE 3.1340117509130896 Test RE 0.8461714548319956\n",
      "105 Train Loss 5.046854 Test MSE 3.173329991299147 Test RE 0.8514627996561694\n",
      "106 Train Loss 4.9377737 Test MSE 3.1241983466484866 Test RE 0.8448456249090422\n",
      "107 Train Loss 4.7743483 Test MSE 3.063976571934363 Test RE 0.8366634178940382\n",
      "108 Train Loss 4.6224823 Test MSE 3.0352186622034996 Test RE 0.8327277783292627\n",
      "109 Train Loss 4.4115686 Test MSE 2.9891051968450624 Test RE 0.8263778350221144\n",
      "110 Train Loss 4.2026043 Test MSE 2.9697448129642123 Test RE 0.8236972698361659\n",
      "111 Train Loss 4.0719233 Test MSE 2.851294409919545 Test RE 0.8071032416136688\n",
      "112 Train Loss 3.9587414 Test MSE 2.6823889377264103 Test RE 0.7828326576854592\n",
      "113 Train Loss 3.8607798 Test MSE 2.7023325358052452 Test RE 0.7857374540899259\n",
      "114 Train Loss 3.7556462 Test MSE 2.7631143489695735 Test RE 0.7945248580014566\n",
      "115 Train Loss 3.6593795 Test MSE 2.6535650091481444 Test RE 0.7786152869199807\n",
      "116 Train Loss 3.535436 Test MSE 2.5811419620898 Test RE 0.7679165117914742\n",
      "117 Train Loss 3.4449108 Test MSE 2.5890580842870308 Test RE 0.7690931745431124\n",
      "118 Train Loss 3.3629818 Test MSE 2.5120395922043164 Test RE 0.7575674395298655\n",
      "119 Train Loss 3.2552521 Test MSE 2.4630643983944696 Test RE 0.7501462520162937\n",
      "120 Train Loss 3.1842382 Test MSE 2.4357328304324555 Test RE 0.7459726160367417\n",
      "121 Train Loss 3.1087081 Test MSE 2.3567413488935776 Test RE 0.7337768753777075\n",
      "122 Train Loss 2.9785118 Test MSE 2.273426743678157 Test RE 0.720690077244856\n",
      "123 Train Loss 2.7947052 Test MSE 2.2010363000704927 Test RE 0.709123148812713\n",
      "124 Train Loss 2.602309 Test MSE 2.077937261011878 Test RE 0.6890080177620679\n",
      "125 Train Loss 2.436131 Test MSE 2.0113400353520583 Test RE 0.6778768604862426\n",
      "126 Train Loss 2.2730746 Test MSE 1.9187501481510618 Test RE 0.6620903734671882\n",
      "127 Train Loss 2.1505783 Test MSE 1.8909487496753987 Test RE 0.6572762494958072\n",
      "128 Train Loss 2.046281 Test MSE 1.9214829503989221 Test RE 0.6625617006667657\n",
      "129 Train Loss 1.9805113 Test MSE 1.9555666188136593 Test RE 0.6684121997126166\n",
      "130 Train Loss 1.887323 Test MSE 1.9536231191029214 Test RE 0.6680799732812762\n",
      "131 Train Loss 1.821286 Test MSE 1.9655644414240445 Test RE 0.6701186481225021\n",
      "132 Train Loss 1.7527031 Test MSE 1.9651709799445825 Test RE 0.6700515734783304\n",
      "133 Train Loss 1.6788332 Test MSE 1.9386072206382339 Test RE 0.6655075292972641\n",
      "134 Train Loss 1.6268655 Test MSE 1.9093564482651595 Test RE 0.6604676741287134\n",
      "135 Train Loss 1.5916052 Test MSE 1.8890540521439867 Test RE 0.6569468773232109\n",
      "136 Train Loss 1.5538833 Test MSE 1.8543201063701393 Test RE 0.6508792312636101\n",
      "137 Train Loss 1.5220056 Test MSE 1.8519676184286582 Test RE 0.6504662304333986\n",
      "138 Train Loss 1.4654918 Test MSE 1.8144110264049234 Test RE 0.6438369517241797\n",
      "139 Train Loss 1.4387435 Test MSE 1.8188357456065785 Test RE 0.6446215212039473\n",
      "140 Train Loss 1.4173565 Test MSE 1.8589382583765002 Test RE 0.6516892289641836\n",
      "141 Train Loss 1.3995388 Test MSE 1.8442299056030675 Test RE 0.6491059504046379\n",
      "142 Train Loss 1.3710228 Test MSE 1.8175933863221116 Test RE 0.6444013286064867\n",
      "143 Train Loss 1.3467798 Test MSE 1.8125683004359332 Test RE 0.6435099264694348\n",
      "144 Train Loss 1.3352442 Test MSE 1.7985396409713152 Test RE 0.6410148157629225\n",
      "145 Train Loss 1.3115951 Test MSE 1.8103244170284463 Test RE 0.643111483990362\n",
      "146 Train Loss 1.2786036 Test MSE 1.830031646844508 Test RE 0.6466024715605503\n",
      "147 Train Loss 1.2456033 Test MSE 1.8208144641695505 Test RE 0.6449720690337069\n",
      "148 Train Loss 1.2263573 Test MSE 1.7979002572908536 Test RE 0.6409008647453179\n",
      "149 Train Loss 1.2047031 Test MSE 1.813026984142591 Test RE 0.6435913437730085\n",
      "Training time: 77.69\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 57.42857 Test MSE 8.652406940591769 Test RE 1.4059715370976187\n",
      "1 Train Loss 56.67922 Test MSE 8.58629890613152 Test RE 1.4005901308816409\n",
      "2 Train Loss 53.65368 Test MSE 8.695785929629777 Test RE 1.4094915617688608\n",
      "3 Train Loss 53.486732 Test MSE 8.814155727465607 Test RE 1.4190523588267128\n",
      "4 Train Loss 46.902435 Test MSE 7.552865120685376 Test RE 1.313602374569184\n",
      "5 Train Loss 46.418396 Test MSE 7.6256315631878815 Test RE 1.319915015300212\n",
      "6 Train Loss 45.933556 Test MSE 7.659019866520853 Test RE 1.3228014378079558\n",
      "7 Train Loss 45.650097 Test MSE 7.656179856289492 Test RE 1.3225561637385816\n",
      "8 Train Loss 45.09412 Test MSE 7.317777767261095 Test RE 1.2929974501596855\n",
      "9 Train Loss 43.973335 Test MSE 7.445253818919305 Test RE 1.304210866292456\n",
      "10 Train Loss 43.439453 Test MSE 7.272465284469031 Test RE 1.2889880428140104\n",
      "11 Train Loss 43.09555 Test MSE 7.266104713430826 Test RE 1.2884242385781963\n",
      "12 Train Loss 42.46594 Test MSE 7.099709422996721 Test RE 1.2735862082522909\n",
      "13 Train Loss 42.2184 Test MSE 7.003103823893385 Test RE 1.2648916998697026\n",
      "14 Train Loss 41.859684 Test MSE 7.04922825105249 Test RE 1.2690503312918286\n",
      "15 Train Loss 41.724606 Test MSE 7.017057158042631 Test RE 1.266151189542207\n",
      "16 Train Loss 41.626823 Test MSE 6.971074627939067 Test RE 1.2619958486745584\n",
      "17 Train Loss 41.255318 Test MSE 7.097865304780338 Test RE 1.2734207933092916\n",
      "18 Train Loss 37.546482 Test MSE 6.47655613266041 Test RE 1.2164104074227524\n",
      "19 Train Loss 33.291855 Test MSE 5.816525385953387 Test RE 1.1527625903237344\n",
      "20 Train Loss 28.173864 Test MSE 5.161063108063298 Test RE 1.085869525631\n",
      "21 Train Loss 26.693644 Test MSE 5.165747552930425 Test RE 1.0863622092221905\n",
      "22 Train Loss 25.942707 Test MSE 4.9155503080366785 Test RE 1.0597273253944295\n",
      "23 Train Loss 25.520031 Test MSE 5.017697865911774 Test RE 1.0706815375641165\n",
      "24 Train Loss 25.015015 Test MSE 5.176418377874978 Test RE 1.0874836732944944\n",
      "25 Train Loss 24.549568 Test MSE 5.034012292095113 Test RE 1.0724207195567115\n",
      "26 Train Loss 24.243805 Test MSE 5.170658685059286 Test RE 1.0868784946990475\n",
      "27 Train Loss 23.937613 Test MSE 5.242238518161723 Test RE 1.0943757192500083\n",
      "28 Train Loss 23.563557 Test MSE 5.1951470577296 Test RE 1.0894491968347715\n",
      "29 Train Loss 22.89351 Test MSE 5.415871429162673 Test RE 1.1123519825264976\n",
      "30 Train Loss 22.440369 Test MSE 5.372156905407094 Test RE 1.107853679937103\n",
      "31 Train Loss 22.080517 Test MSE 5.247391077680047 Test RE 1.0949134142725385\n",
      "32 Train Loss 21.699474 Test MSE 5.188188089104159 Test RE 1.0887192864724435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 21.432915 Test MSE 5.220484615831959 Test RE 1.0921026738770967\n",
      "34 Train Loss 21.160229 Test MSE 5.269576213121044 Test RE 1.097225532975943\n",
      "35 Train Loss 20.848635 Test MSE 5.347096518527562 Test RE 1.1052666654475038\n",
      "36 Train Loss 20.363337 Test MSE 5.138797190804168 Test RE 1.0835246584950249\n",
      "37 Train Loss 19.88316 Test MSE 5.004731830056567 Test RE 1.0692972896993167\n",
      "38 Train Loss 19.227324 Test MSE 4.867193187988667 Test RE 1.0545018659212868\n",
      "39 Train Loss 18.501991 Test MSE 4.830424098821842 Test RE 1.0505112108252435\n",
      "40 Train Loss 18.112858 Test MSE 4.7547930237564415 Test RE 1.042254715513234\n",
      "41 Train Loss 17.664865 Test MSE 4.681129746782514 Test RE 1.0341496744953633\n",
      "42 Train Loss 17.32827 Test MSE 4.671894795821609 Test RE 1.0331290836415696\n",
      "43 Train Loss 16.98858 Test MSE 4.720006072576519 Test RE 1.0384350515531706\n",
      "44 Train Loss 16.655502 Test MSE 4.6415720296300895 Test RE 1.029770882003211\n",
      "45 Train Loss 16.44147 Test MSE 4.612445028520722 Test RE 1.0265347649298109\n",
      "46 Train Loss 16.116089 Test MSE 4.65900412549756 Test RE 1.0317027966370842\n",
      "47 Train Loss 15.873596 Test MSE 4.584451726965591 Test RE 1.0234149629279679\n",
      "48 Train Loss 15.529893 Test MSE 4.599226151783075 Test RE 1.0250627286503016\n",
      "49 Train Loss 14.7417145 Test MSE 4.477175662357888 Test RE 1.011370140431551\n",
      "50 Train Loss 14.040843 Test MSE 4.28580933828933 Test RE 0.9895197884693355\n",
      "51 Train Loss 13.671608 Test MSE 4.306869156770988 Test RE 0.9919479844221334\n",
      "52 Train Loss 13.14555 Test MSE 4.323332513748199 Test RE 0.9938420769157346\n",
      "53 Train Loss 12.637238 Test MSE 4.148679453870794 Test RE 0.9735606243563627\n",
      "54 Train Loss 11.989125 Test MSE 3.978150599254244 Test RE 0.9533418765504337\n",
      "55 Train Loss 11.669172 Test MSE 3.8119195914845347 Test RE 0.9332111644268382\n",
      "56 Train Loss 11.143161 Test MSE 3.8491669187163966 Test RE 0.9377594138890863\n",
      "57 Train Loss 10.733294 Test MSE 3.7892401968096636 Test RE 0.9304309065908046\n",
      "58 Train Loss 10.44718 Test MSE 3.794290985086569 Test RE 0.9310507992763354\n",
      "59 Train Loss 10.149076 Test MSE 3.778810598227918 Test RE 0.9291495537388299\n",
      "60 Train Loss 9.87571 Test MSE 3.590941679503114 Test RE 0.9057581201386969\n",
      "61 Train Loss 9.634819 Test MSE 3.480545036575775 Test RE 0.8917265330366919\n",
      "62 Train Loss 9.166252 Test MSE 3.4495501693423436 Test RE 0.8877471629750171\n",
      "63 Train Loss 8.91264 Test MSE 3.334658681868964 Test RE 0.8728382190562205\n",
      "64 Train Loss 8.758495 Test MSE 3.3799637429057636 Test RE 0.8787474566960409\n",
      "65 Train Loss 8.677799 Test MSE 3.406154118168536 Test RE 0.8821454685777621\n",
      "66 Train Loss 8.599068 Test MSE 3.4743637670847103 Test RE 0.8909343508656774\n",
      "67 Train Loss 8.5042 Test MSE 3.421802194057333 Test RE 0.8841694611966893\n",
      "68 Train Loss 8.404346 Test MSE 3.405573717157879 Test RE 0.8820703075726466\n",
      "69 Train Loss 8.313683 Test MSE 3.394724015030807 Test RE 0.8806641077076487\n",
      "70 Train Loss 8.169526 Test MSE 3.3472567653914957 Test RE 0.8744854225350704\n",
      "71 Train Loss 8.060412 Test MSE 3.303259926398732 Test RE 0.8687192289361606\n",
      "72 Train Loss 7.7498593 Test MSE 2.8166032545416084 Test RE 0.8021782798833585\n",
      "73 Train Loss 6.5904436 Test MSE 2.2225621996262053 Test RE 0.7125822861602321\n",
      "74 Train Loss 5.8829956 Test MSE 2.209395541808304 Test RE 0.710468450183146\n",
      "75 Train Loss 5.5487494 Test MSE 2.2556682124129543 Test RE 0.7178697777589605\n",
      "76 Train Loss 5.272735 Test MSE 2.198739676973632 Test RE 0.7087530927503515\n",
      "77 Train Loss 5.130335 Test MSE 2.114796690550894 Test RE 0.695092129970177\n",
      "78 Train Loss 5.001836 Test MSE 2.157117171252164 Test RE 0.7020126342087877\n",
      "79 Train Loss 4.8961096 Test MSE 2.1319335351155813 Test RE 0.6979027197805652\n",
      "80 Train Loss 4.8356867 Test MSE 2.142927554627769 Test RE 0.6996998887918149\n",
      "81 Train Loss 4.7876153 Test MSE 2.1988270659056823 Test RE 0.7087671773100425\n",
      "82 Train Loss 4.7459555 Test MSE 2.2243217113093303 Test RE 0.7128642914987411\n",
      "83 Train Loss 4.6993074 Test MSE 2.2183503643893725 Test RE 0.7119067814624715\n",
      "84 Train Loss 4.6473894 Test MSE 2.236165866790383 Test RE 0.7147597155098363\n",
      "85 Train Loss 4.6038585 Test MSE 2.2536088962102996 Test RE 0.717542012704773\n",
      "86 Train Loss 4.5796633 Test MSE 2.217154439188894 Test RE 0.7117148591106485\n",
      "87 Train Loss 4.556311 Test MSE 2.2239830996377705 Test RE 0.7128100292588467\n",
      "88 Train Loss 4.536792 Test MSE 2.244241606116347 Test RE 0.7160492019346113\n",
      "89 Train Loss 4.5201235 Test MSE 2.251678643719543 Test RE 0.7172346537030934\n",
      "90 Train Loss 4.507224 Test MSE 2.2426428412796353 Test RE 0.7157941050148743\n",
      "91 Train Loss 4.4940443 Test MSE 2.2202620181608834 Test RE 0.7122134566929224\n",
      "92 Train Loss 4.4899044 Test MSE 2.2107319764986886 Test RE 0.7106832942715945\n",
      "93 Train Loss 4.4827394 Test MSE 2.210128965299622 Test RE 0.7105863627535772\n",
      "94 Train Loss 4.465552 Test MSE 2.204895064685545 Test RE 0.7097444791050725\n",
      "95 Train Loss 4.4547777 Test MSE 2.199379592880974 Test RE 0.7088562221450015\n",
      "96 Train Loss 4.4485703 Test MSE 2.1951588057035973 Test RE 0.7081757193156574\n",
      "97 Train Loss 4.4406943 Test MSE 2.184355570992026 Test RE 0.7064309652206627\n",
      "98 Train Loss 4.4197636 Test MSE 2.1778252527446624 Test RE 0.7053742068451069\n",
      "99 Train Loss 4.404609 Test MSE 2.1619650691871906 Test RE 0.7028010419173596\n",
      "100 Train Loss 4.396377 Test MSE 2.1755559445233055 Test RE 0.7050066087813791\n",
      "101 Train Loss 4.3935075 Test MSE 2.181772718808587 Test RE 0.7060131883548595\n",
      "102 Train Loss 4.3844085 Test MSE 2.1689320730429293 Test RE 0.7039325308726991\n",
      "103 Train Loss 4.375029 Test MSE 2.1669515116743234 Test RE 0.7036110593029166\n",
      "104 Train Loss 4.367721 Test MSE 2.1618223258126825 Test RE 0.7027778403749939\n",
      "105 Train Loss 4.357971 Test MSE 2.1567992796949906 Test RE 0.7019609049576219\n",
      "106 Train Loss 4.3474493 Test MSE 2.1574820348833454 Test RE 0.7020720023442066\n",
      "107 Train Loss 4.3426867 Test MSE 2.1579492163915392 Test RE 0.7021480116220382\n",
      "108 Train Loss 4.338973 Test MSE 2.157862958717034 Test RE 0.702133978330748\n",
      "109 Train Loss 4.3348255 Test MSE 2.156113611245467 Test RE 0.7018493158288899\n",
      "110 Train Loss 4.3280945 Test MSE 2.1591351631042994 Test RE 0.702340925278899\n",
      "111 Train Loss 4.325126 Test MSE 2.1633836327820797 Test RE 0.7030315739692751\n",
      "112 Train Loss 4.3214374 Test MSE 2.1697966993607296 Test RE 0.7040728252495148\n",
      "113 Train Loss 4.316183 Test MSE 2.1702791309079696 Test RE 0.7041510925047622\n",
      "114 Train Loss 4.312449 Test MSE 2.166037801476227 Test RE 0.7034627024103736\n",
      "115 Train Loss 4.3081293 Test MSE 2.167483676240547 Test RE 0.7036974511502233\n",
      "116 Train Loss 4.304508 Test MSE 2.1684798254154773 Test RE 0.7038591379763339\n",
      "117 Train Loss 4.2934813 Test MSE 2.164843459244529 Test RE 0.7032687327893521\n",
      "118 Train Loss 4.284969 Test MSE 2.1732896053599933 Test RE 0.7046393002726777\n",
      "119 Train Loss 4.280628 Test MSE 2.170190792884849 Test RE 0.7041367616411442\n",
      "120 Train Loss 4.2788224 Test MSE 2.174730492708225 Test RE 0.7048728489031898\n",
      "121 Train Loss 4.2767224 Test MSE 2.1758801858310477 Test RE 0.7050591433412815\n",
      "122 Train Loss 4.274211 Test MSE 2.1720101313798224 Test RE 0.7044318496914874\n",
      "123 Train Loss 4.271783 Test MSE 2.1705183986631273 Test RE 0.7041899068686409\n",
      "124 Train Loss 4.269181 Test MSE 2.160746056024665 Test RE 0.7026028785585136\n",
      "125 Train Loss 4.267068 Test MSE 2.1586960928179013 Test RE 0.7022695094834558\n",
      "126 Train Loss 4.263753 Test MSE 2.1618829022642507 Test RE 0.7027876865795315\n",
      "127 Train Loss 4.25968 Test MSE 2.1605453682712454 Test RE 0.7025702493036614\n",
      "128 Train Loss 4.2523336 Test MSE 2.1675680404405835 Test RE 0.7037111459003886\n",
      "129 Train Loss 4.2469316 Test MSE 2.1599246369467626 Test RE 0.7024693167576375\n",
      "130 Train Loss 4.244092 Test MSE 2.1614654526857104 Test RE 0.7027198307795876\n",
      "131 Train Loss 4.2413373 Test MSE 2.162325787532404 Test RE 0.7028596697506304\n",
      "132 Train Loss 4.2381835 Test MSE 2.158891617839531 Test RE 0.7023013129763997\n",
      "133 Train Loss 4.234486 Test MSE 2.1623643477155956 Test RE 0.7028659366778793\n",
      "134 Train Loss 4.232384 Test MSE 2.162033793220349 Test RE 0.7028122120650577\n",
      "135 Train Loss 4.2280283 Test MSE 2.162773888697069 Test RE 0.7029324931713987\n",
      "136 Train Loss 4.222442 Test MSE 2.158029283331568 Test RE 0.7021610374895715\n",
      "137 Train Loss 4.215408 Test MSE 2.1598670716426542 Test RE 0.7024599557529543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 Train Loss 4.2113857 Test MSE 2.164033299221576 Test RE 0.7031371266156393\n",
      "139 Train Loss 4.208248 Test MSE 2.1658556838035423 Test RE 0.7034331286690696\n",
      "140 Train Loss 4.205416 Test MSE 2.1721457625568052 Test RE 0.7044538434722711\n",
      "141 Train Loss 4.2018013 Test MSE 2.1689654521091706 Test RE 0.703937947483129\n",
      "142 Train Loss 4.194754 Test MSE 2.157698246827461 Test RE 0.7021071805165404\n",
      "143 Train Loss 4.189474 Test MSE 2.1600987424325355 Test RE 0.7024976282308714\n",
      "144 Train Loss 4.1842623 Test MSE 2.158363301917731 Test RE 0.7022153754367487\n",
      "145 Train Loss 4.1806574 Test MSE 2.152021323163103 Test RE 0.7011829470183706\n",
      "146 Train Loss 4.1783695 Test MSE 2.154999090250495 Test RE 0.7016678952151226\n",
      "147 Train Loss 4.1753125 Test MSE 2.1536393651153096 Test RE 0.7014464969736753\n",
      "148 Train Loss 4.1670184 Test MSE 2.150087868153871 Test RE 0.7008678919797616\n",
      "149 Train Loss 4.1568527 Test MSE 2.145035060260867 Test RE 0.7000438712728119\n",
      "Training time: 79.36\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 56.06588 Test MSE 8.556446434374251 Test RE 1.3981532554111005\n",
      "1 Train Loss 55.883385 Test MSE 8.09586312505504 Test RE 1.3600022873506894\n",
      "2 Train Loss 55.648064 Test MSE 8.54137735990277 Test RE 1.3969215431482165\n",
      "3 Train Loss 55.639038 Test MSE 8.62376321186311 Test RE 1.4036423786836638\n",
      "4 Train Loss 55.315796 Test MSE 9.338923563916047 Test RE 1.460684667890963\n",
      "5 Train Loss 49.71112 Test MSE 8.198958639921077 Test RE 1.3686342628739263\n",
      "6 Train Loss 47.159008 Test MSE 8.18531363096164 Test RE 1.367494922868159\n",
      "7 Train Loss 45.685707 Test MSE 8.465179300119395 Test RE 1.3906765801396377\n",
      "8 Train Loss 43.818916 Test MSE 8.891111293839616 Test RE 1.4252337024433277\n",
      "9 Train Loss 42.38608 Test MSE 9.360794360639405 Test RE 1.462394054167729\n",
      "10 Train Loss 41.78734 Test MSE 9.56556374780272 Test RE 1.4783026160371329\n",
      "11 Train Loss 41.616344 Test MSE 9.408618632434246 Test RE 1.4661249784524077\n",
      "12 Train Loss 41.43235 Test MSE 9.234345904857998 Test RE 1.4524832390766615\n",
      "13 Train Loss 41.266945 Test MSE 9.302379789134225 Test RE 1.4578239927642793\n",
      "14 Train Loss 41.082867 Test MSE 9.265459192376262 Test RE 1.4549281077836418\n",
      "15 Train Loss 40.964043 Test MSE 9.317755360066815 Test RE 1.4590282879110956\n",
      "16 Train Loss 40.88877 Test MSE 9.277725400866773 Test RE 1.4558908527742516\n",
      "17 Train Loss 40.84571 Test MSE 9.2490152152586 Test RE 1.4536364594881328\n",
      "18 Train Loss 40.824722 Test MSE 9.242001991695163 Test RE 1.4530852326527284\n",
      "19 Train Loss 40.8107 Test MSE 9.239000182629349 Test RE 1.4528492319100295\n",
      "20 Train Loss 40.789692 Test MSE 9.216142538309358 Test RE 1.4510509163080338\n",
      "21 Train Loss 40.75904 Test MSE 9.182980636927587 Test RE 1.4484379482617589\n",
      "22 Train Loss 40.724277 Test MSE 9.211025636089598 Test RE 1.4506480407826057\n",
      "23 Train Loss 40.70864 Test MSE 9.219903023027056 Test RE 1.4513469240066585\n",
      "24 Train Loss 40.692276 Test MSE 9.236492992337196 Test RE 1.4526520884652279\n",
      "25 Train Loss 40.666214 Test MSE 9.243135040979217 Test RE 1.4531743024627821\n",
      "26 Train Loss 40.6502 Test MSE 9.232960783625535 Test RE 1.452374301159244\n",
      "27 Train Loss 40.6436 Test MSE 9.223378089111268 Test RE 1.451620411228332\n",
      "28 Train Loss 40.63983 Test MSE 9.212672288204956 Test RE 1.4507777009318419\n",
      "29 Train Loss 40.633133 Test MSE 9.229412289437589 Test RE 1.452095179587876\n",
      "30 Train Loss 40.612335 Test MSE 9.203537101084606 Test RE 1.4500582347228195\n",
      "31 Train Loss 40.60322 Test MSE 9.1835683733688 Test RE 1.4484842995597595\n",
      "32 Train Loss 40.583645 Test MSE 9.211610883072192 Test RE 1.4506941254390258\n",
      "33 Train Loss 40.56294 Test MSE 9.222509817031886 Test RE 1.4515520831643012\n",
      "34 Train Loss 40.529617 Test MSE 9.22435892713813 Test RE 1.451697593722391\n",
      "35 Train Loss 40.493614 Test MSE 9.218959128075719 Test RE 1.4512726307036694\n",
      "36 Train Loss 40.46333 Test MSE 9.219868604171406 Test RE 1.451344214989721\n",
      "37 Train Loss 40.44896 Test MSE 9.188087437603572 Test RE 1.4488406419017954\n",
      "38 Train Loss 40.43615 Test MSE 9.214577030749131 Test RE 1.4509276691009394\n",
      "39 Train Loss 40.418205 Test MSE 9.224683643349543 Test RE 1.4517231448527232\n",
      "40 Train Loss 40.397427 Test MSE 9.235914385166826 Test RE 1.4526065880746162\n",
      "41 Train Loss 40.381832 Test MSE 9.22215229409116 Test RE 1.4515239472116503\n",
      "42 Train Loss 40.371483 Test MSE 9.233049981839715 Test RE 1.4523813167246797\n",
      "43 Train Loss 40.361767 Test MSE 9.231100152951003 Test RE 1.4522279522037727\n",
      "44 Train Loss 40.354733 Test MSE 9.232616170101364 Test RE 1.4523471965008123\n",
      "45 Train Loss 40.34915 Test MSE 9.23006429490601 Test RE 1.4521464698134938\n",
      "46 Train Loss 40.344067 Test MSE 9.23335285873771 Test RE 1.4524051381672871\n",
      "47 Train Loss 40.329132 Test MSE 9.218106162529105 Test RE 1.4512054911182743\n",
      "48 Train Loss 40.320175 Test MSE 9.23137055050167 Test RE 1.4522492213915852\n",
      "49 Train Loss 40.30789 Test MSE 9.245119052963618 Test RE 1.4533302539079491\n",
      "50 Train Loss 40.28843 Test MSE 9.226669622878404 Test RE 1.4518794069751104\n",
      "51 Train Loss 40.267147 Test MSE 9.208666403001931 Test RE 1.450462250612933\n",
      "52 Train Loss 40.251816 Test MSE 9.235457726718638 Test RE 1.4525706764559914\n",
      "53 Train Loss 40.24529 Test MSE 9.221294559994536 Test RE 1.4514564439601056\n",
      "54 Train Loss 40.235992 Test MSE 9.226570290892715 Test RE 1.4518715916712934\n",
      "55 Train Loss 40.228973 Test MSE 9.23413779220932 Test RE 1.4524668718190192\n",
      "56 Train Loss 40.22562 Test MSE 9.225422378926348 Test RE 1.4517812724864827\n",
      "57 Train Loss 40.216045 Test MSE 9.235716521735393 Test RE 1.4525910282041243\n",
      "58 Train Loss 40.197556 Test MSE 9.242941907088756 Test RE 1.4531591204562766\n",
      "59 Train Loss 40.18154 Test MSE 9.250340473419966 Test RE 1.4537405989307335\n",
      "60 Train Loss 40.16593 Test MSE 9.225445445320107 Test RE 1.4517830874352282\n",
      "61 Train Loss 40.143288 Test MSE 9.25229787336328 Test RE 1.4538943987426538\n",
      "62 Train Loss 40.12809 Test MSE 9.251020687210676 Test RE 1.4537940475701878\n",
      "63 Train Loss 40.122517 Test MSE 9.234217986359516 Test RE 1.4524731788016634\n",
      "64 Train Loss 40.116425 Test MSE 9.248365821946233 Test RE 1.4535854271163742\n",
      "65 Train Loss 40.112236 Test MSE 9.25001859228238 Test RE 1.453715306037473\n",
      "66 Train Loss 40.11018 Test MSE 9.247371873602887 Test RE 1.4535073145245934\n",
      "67 Train Loss 40.078136 Test MSE 9.257307026722701 Test RE 1.454287911503584\n",
      "68 Train Loss 40.0301 Test MSE 9.258899006514369 Test RE 1.454412953129194\n",
      "69 Train Loss 39.9989 Test MSE 9.231632292598203 Test RE 1.4522698094537507\n",
      "70 Train Loss 39.991756 Test MSE 9.24062030132542 Test RE 1.4529766096012136\n",
      "71 Train Loss 39.94017 Test MSE 9.183643925118822 Test RE 1.4484902577719807\n",
      "72 Train Loss 39.882935 Test MSE 9.228541928907125 Test RE 1.4520267095656973\n",
      "73 Train Loss 39.859695 Test MSE 9.212976126576507 Test RE 1.4508016244084365\n",
      "74 Train Loss 39.839317 Test MSE 9.233446898651325 Test RE 1.452412534381211\n",
      "75 Train Loss 39.812626 Test MSE 9.23969339472926 Test RE 1.4529037353062926\n",
      "76 Train Loss 39.791943 Test MSE 9.242606423193177 Test RE 1.4531327481220506\n",
      "77 Train Loss 39.747475 Test MSE 9.263707343186763 Test RE 1.454790557390135\n",
      "78 Train Loss 39.739613 Test MSE 9.25990029046102 Test RE 1.454491593201372\n",
      "79 Train Loss 39.730976 Test MSE 9.235373132590063 Test RE 1.4525640238765742\n",
      "80 Train Loss 39.725327 Test MSE 9.245328124642864 Test RE 1.4533466868212046\n",
      "81 Train Loss 39.722183 Test MSE 9.250308849821302 Test RE 1.453738114019573\n",
      "82 Train Loss 39.717186 Test MSE 9.256521543681671 Test RE 1.4542262119877074\n",
      "83 Train Loss 39.70161 Test MSE 9.275448340237645 Test RE 1.455712179929624\n",
      "84 Train Loss 39.689705 Test MSE 9.26603140370374 Test RE 1.4549730334302489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 39.68067 Test MSE 9.25036535345794 Test RE 1.4537425539450968\n",
      "86 Train Loss 39.670975 Test MSE 9.276707270858282 Test RE 1.4558109664459384\n",
      "87 Train Loss 39.65351 Test MSE 9.252112560720763 Test RE 1.4538798387724854\n",
      "88 Train Loss 39.641357 Test MSE 9.256437478318169 Test RE 1.4542196085172725\n",
      "89 Train Loss 39.63779 Test MSE 9.26448654312494 Test RE 1.4548517396379264\n",
      "90 Train Loss 39.62951 Test MSE 9.252841699039875 Test RE 1.4539371261546954\n",
      "91 Train Loss 39.61963 Test MSE 9.261126838646176 Test RE 1.4545879195599445\n",
      "92 Train Loss 39.61254 Test MSE 9.246868384174556 Test RE 1.4534677446047004\n",
      "93 Train Loss 39.597065 Test MSE 9.20200369202581 Test RE 1.449937431979681\n",
      "94 Train Loss 39.561733 Test MSE 9.21702580872815 Test RE 1.4511204486334086\n",
      "95 Train Loss 39.54882 Test MSE 9.223452501191028 Test RE 1.451626266885278\n",
      "96 Train Loss 39.542797 Test MSE 9.23298480830291 Test RE 1.4523761907373614\n",
      "97 Train Loss 39.539917 Test MSE 9.238444232839399 Test RE 1.4528055192051608\n",
      "98 Train Loss 39.53659 Test MSE 9.242095101421535 Test RE 1.4530925522804328\n",
      "99 Train Loss 39.531536 Test MSE 9.261587644016558 Test RE 1.4546241070347046\n",
      "100 Train Loss 39.523262 Test MSE 9.25499810521548 Test RE 1.454106538776741\n",
      "101 Train Loss 39.516716 Test MSE 9.250581401343618 Test RE 1.4537595303649054\n",
      "102 Train Loss 39.509346 Test MSE 9.262424386715233 Test RE 1.4546898149164404\n",
      "103 Train Loss 39.501392 Test MSE 9.262267673319878 Test RE 1.4546775087245174\n",
      "104 Train Loss 39.495155 Test MSE 9.265938884249982 Test RE 1.4549657696060478\n",
      "105 Train Loss 39.48802 Test MSE 9.265247356948134 Test RE 1.4549114757380064\n",
      "106 Train Loss 39.456314 Test MSE 9.257677966396619 Test RE 1.4543170478214282\n",
      "107 Train Loss 39.41941 Test MSE 9.254186424691802 Test RE 1.4540427734565018\n",
      "108 Train Loss 39.398346 Test MSE 9.27853269802889 Test RE 1.4559541932449107\n",
      "109 Train Loss 39.382637 Test MSE 9.3027870983693 Test RE 1.4578559081821174\n",
      "110 Train Loss 39.356377 Test MSE 9.282748214345464 Test RE 1.456284897564869\n",
      "111 Train Loss 39.304207 Test MSE 9.308387753310981 Test RE 1.4582946863285207\n",
      "112 Train Loss 39.265205 Test MSE 9.360506686158978 Test RE 1.4623715829614548\n",
      "113 Train Loss 39.236725 Test MSE 9.380413874393826 Test RE 1.4639257854027805\n",
      "114 Train Loss 39.168015 Test MSE 9.44292639411018 Test RE 1.4687955987896817\n",
      "115 Train Loss 39.137703 Test MSE 9.405940034489637 Test RE 1.4659162634933431\n",
      "116 Train Loss 39.104744 Test MSE 9.49405401150323 Test RE 1.4727665417412428\n",
      "117 Train Loss 39.054718 Test MSE 9.488397529914778 Test RE 1.4723277450994277\n",
      "118 Train Loss 39.028168 Test MSE 9.499672172959727 Test RE 1.473202236360678\n",
      "119 Train Loss 39.02076 Test MSE 9.509446936890598 Test RE 1.4739599731237951\n",
      "120 Train Loss 39.00816 Test MSE 9.476539095581336 Test RE 1.4714074126415735\n",
      "121 Train Loss 38.981544 Test MSE 9.53179156285976 Test RE 1.4756906605168325\n",
      "122 Train Loss 38.957672 Test MSE 9.536645944467 Test RE 1.476066384939381\n",
      "123 Train Loss 38.948338 Test MSE 9.524074243044737 Test RE 1.4750931504498561\n",
      "124 Train Loss 38.938354 Test MSE 9.534516674374222 Test RE 1.4759015932778534\n",
      "125 Train Loss 38.925068 Test MSE 9.53086053792339 Test RE 1.4756185891572573\n",
      "126 Train Loss 38.91687 Test MSE 9.536191213316888 Test RE 1.4760311932498573\n",
      "127 Train Loss 38.8969 Test MSE 9.546924731383228 Test RE 1.4768616375846915\n",
      "128 Train Loss 38.86068 Test MSE 9.573757517270181 Test RE 1.478935630375158\n",
      "129 Train Loss 38.820404 Test MSE 9.570965936516856 Test RE 1.47871999564467\n",
      "130 Train Loss 38.794754 Test MSE 9.580312273670646 Test RE 1.4794418268219687\n",
      "131 Train Loss 38.783962 Test MSE 9.556604844075602 Test RE 1.477610180461755\n",
      "132 Train Loss 38.773285 Test MSE 9.58282294131813 Test RE 1.4796356693243702\n",
      "133 Train Loss 38.725807 Test MSE 9.570280876839211 Test RE 1.4786670736314704\n",
      "134 Train Loss 38.700603 Test MSE 9.577935326928255 Test RE 1.4792582851753995\n",
      "135 Train Loss 38.67054 Test MSE 9.56744906782503 Test RE 1.4784482915184136\n",
      "136 Train Loss 38.64563 Test MSE 9.57945437343067 Test RE 1.479375584622485\n",
      "137 Train Loss 38.635075 Test MSE 9.581160262949195 Test RE 1.4795073008384478\n",
      "138 Train Loss 38.62993 Test MSE 9.586124238216689 Test RE 1.4798905157329096\n",
      "139 Train Loss 38.62014 Test MSE 9.585767954906878 Test RE 1.4798630142538336\n",
      "140 Train Loss 38.600296 Test MSE 9.58846542584112 Test RE 1.4800712190994383\n",
      "141 Train Loss 38.58058 Test MSE 9.64472572926207 Test RE 1.4844070259080513\n",
      "142 Train Loss 38.559143 Test MSE 9.61911756239679 Test RE 1.482435056464496\n",
      "143 Train Loss 38.540176 Test MSE 9.633254466420162 Test RE 1.4835239997932659\n",
      "144 Train Loss 38.531174 Test MSE 9.625036239880922 Test RE 1.4828910601296807\n",
      "145 Train Loss 38.484936 Test MSE 9.566401412046527 Test RE 1.4783673427049282\n",
      "146 Train Loss 38.44198 Test MSE 9.602518301749486 Test RE 1.4811554198017622\n",
      "147 Train Loss 38.426212 Test MSE 9.621905852485307 Test RE 1.4826498973503857\n",
      "148 Train Loss 38.414246 Test MSE 9.618049359067282 Test RE 1.482352741947683\n",
      "149 Train Loss 38.402348 Test MSE 9.612347546465475 Test RE 1.4819132895050804\n",
      "Training time: 78.32\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "1 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "2 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "3 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "4 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "5 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "6 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "7 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "8 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "9 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "10 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "11 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "12 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "13 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "14 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "15 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "16 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "17 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "18 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "19 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "20 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "21 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "22 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "23 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "24 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "25 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "26 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "27 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "28 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "29 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "30 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "31 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "33 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "34 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "35 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "36 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "37 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "38 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "39 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "40 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "41 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "42 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "43 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "44 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "45 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "46 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "47 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "48 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "49 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "50 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "51 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "52 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "53 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "54 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "55 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "56 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "57 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "58 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "59 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "60 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "61 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "62 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "63 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "64 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "65 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "66 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "67 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "68 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "69 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "70 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "71 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "72 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "73 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "74 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "75 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "76 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "77 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "78 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "79 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "80 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "81 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "82 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "83 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "84 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "85 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "86 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "87 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "88 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "89 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "90 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "91 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "92 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "93 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "94 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "95 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "96 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "97 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "98 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "99 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "100 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "101 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "102 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "103 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "104 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "105 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "106 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "107 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "108 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "109 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "110 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "111 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "112 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "113 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "114 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "115 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "116 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "117 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "118 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "119 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "120 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "121 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "122 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "123 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "124 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "125 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "126 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "127 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "128 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "129 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "130 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "131 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "132 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "133 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "134 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "135 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "136 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "137 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "139 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "140 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "141 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "142 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "143 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "144 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "145 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "146 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "147 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "148 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "149 Train Loss 57.387695 Test MSE 8.691097555130252 Test RE 1.409111543487414\n",
      "Training time: 55.34\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.259613 Test MSE 8.9637335457866 Test RE 1.4310424918554963\n",
      "1 Train Loss 56.63771 Test MSE 8.507811453164612 Test RE 1.3941740298937166\n",
      "2 Train Loss 54.281143 Test MSE 8.349015270696311 Test RE 1.3811017894812436\n",
      "3 Train Loss 53.790928 Test MSE 8.927823350833718 Test RE 1.4281731190558238\n",
      "4 Train Loss 52.860634 Test MSE 8.323436141604645 Test RE 1.3789845050030916\n",
      "5 Train Loss 45.180786 Test MSE 8.324829198044714 Test RE 1.3790998974228839\n",
      "6 Train Loss 44.29521 Test MSE 8.697943272146567 Test RE 1.4096663917109455\n",
      "7 Train Loss 43.680992 Test MSE 8.611610388252775 Test RE 1.4026530059599172\n",
      "8 Train Loss 43.5435 Test MSE 8.52719343119745 Test RE 1.395761187659945\n",
      "9 Train Loss 43.28026 Test MSE 8.497129647206183 Test RE 1.3932985418844483\n",
      "10 Train Loss 43.148903 Test MSE 8.41979409388633 Test RE 1.3869435836839354\n",
      "11 Train Loss 42.179253 Test MSE 8.250622820236979 Test RE 1.3729395856355961\n",
      "12 Train Loss 40.868286 Test MSE 7.956983792164377 Test RE 1.3482868443517024\n",
      "13 Train Loss 38.149933 Test MSE 7.706252484800975 Test RE 1.3268739788052515\n",
      "14 Train Loss 37.454185 Test MSE 7.7206029956852475 Test RE 1.3281088503018168\n",
      "15 Train Loss 37.193153 Test MSE 7.780559095224831 Test RE 1.333255743041879\n",
      "16 Train Loss 36.81623 Test MSE 7.852749872302247 Test RE 1.3394266710690188\n",
      "17 Train Loss 36.46409 Test MSE 7.698728138076813 Test RE 1.3262260440189333\n",
      "18 Train Loss 36.18953 Test MSE 7.816840312265861 Test RE 1.3363606536873545\n",
      "19 Train Loss 35.886154 Test MSE 7.751366653887081 Test RE 1.3307522233168148\n",
      "20 Train Loss 35.644295 Test MSE 7.691102094699736 Test RE 1.3255690287956357\n",
      "21 Train Loss 34.844692 Test MSE 7.149591362129364 Test RE 1.2780524299675087\n",
      "22 Train Loss 33.6203 Test MSE 7.264291391815401 Test RE 1.2882634596330207\n",
      "23 Train Loss 32.216667 Test MSE 7.243414285892092 Test RE 1.2864109345313013\n",
      "24 Train Loss 31.379183 Test MSE 6.692950828248918 Test RE 1.236564793507414\n",
      "25 Train Loss 29.592876 Test MSE 6.193312723778562 Test RE 1.189514020018826\n",
      "26 Train Loss 28.654581 Test MSE 6.1774087886133735 Test RE 1.187985749506244\n",
      "27 Train Loss 27.241535 Test MSE 6.278227018809825 Test RE 1.1976407597280574\n",
      "28 Train Loss 26.514647 Test MSE 6.261176813219948 Test RE 1.1960133970999844\n",
      "29 Train Loss 25.890194 Test MSE 6.2864926204632425 Test RE 1.1984288775638297\n",
      "30 Train Loss 24.829865 Test MSE 6.201358920716578 Test RE 1.1902864626426906\n",
      "31 Train Loss 24.332531 Test MSE 6.434381560637871 Test RE 1.2124433778933328\n",
      "32 Train Loss 23.762865 Test MSE 6.425297719944011 Test RE 1.211587232488455\n",
      "33 Train Loss 23.451033 Test MSE 6.345147056372975 Test RE 1.2040067070150582\n",
      "34 Train Loss 23.131645 Test MSE 6.112865101056756 Test RE 1.1817632115668457\n",
      "35 Train Loss 22.760891 Test MSE 6.271101368349381 Test RE 1.1969609187277428\n",
      "36 Train Loss 22.599064 Test MSE 6.27639573221517 Test RE 1.1974660779731785\n",
      "37 Train Loss 22.407667 Test MSE 6.1304767654498065 Test RE 1.1834643653980979\n",
      "38 Train Loss 22.231375 Test MSE 6.091598627155193 Test RE 1.179705761214292\n",
      "39 Train Loss 22.11505 Test MSE 6.056480603571474 Test RE 1.1763003483335177\n",
      "40 Train Loss 21.911915 Test MSE 5.849256443835391 Test RE 1.1560014833681942\n",
      "41 Train Loss 21.680159 Test MSE 5.832709317791651 Test RE 1.1543652027661633\n",
      "42 Train Loss 21.629576 Test MSE 5.895951668368041 Test RE 1.1606065511860986\n",
      "43 Train Loss 21.433167 Test MSE 5.850329176213833 Test RE 1.1561074817443382\n",
      "44 Train Loss 21.337498 Test MSE 5.874327384959112 Test RE 1.1584762471478882\n",
      "45 Train Loss 21.198486 Test MSE 5.9524898073800365 Test RE 1.1661579853532968\n",
      "46 Train Loss 21.16158 Test MSE 5.969145823134114 Test RE 1.16778839362245\n",
      "47 Train Loss 21.021957 Test MSE 6.011250298957197 Test RE 1.1718997621687752\n",
      "48 Train Loss 20.92971 Test MSE 6.014042092489363 Test RE 1.1721718621674664\n",
      "49 Train Loss 20.88395 Test MSE 6.084350907291508 Test RE 1.1790037515987535\n",
      "50 Train Loss 20.645546 Test MSE 6.05174443147039 Test RE 1.1758403245304205\n",
      "51 Train Loss 20.413841 Test MSE 6.090155487440673 Test RE 1.1795660129163656\n",
      "52 Train Loss 20.173395 Test MSE 6.175887967525277 Test RE 1.1878395049355193\n",
      "53 Train Loss 19.90543 Test MSE 5.988167849395848 Test RE 1.1696476238248836\n",
      "54 Train Loss 19.65994 Test MSE 6.047456268539291 Test RE 1.1754236605032482\n",
      "55 Train Loss 19.237717 Test MSE 6.199802393471628 Test RE 1.1901370736455852\n",
      "56 Train Loss 18.666616 Test MSE 6.115088340272123 Test RE 1.1819780947210776\n",
      "57 Train Loss 18.167067 Test MSE 5.966665849730618 Test RE 1.16754578059949\n",
      "58 Train Loss 17.268494 Test MSE 6.051025525359795 Test RE 1.175770481536389\n",
      "59 Train Loss 16.98267 Test MSE 5.9621870943336 Test RE 1.1671075011855563\n",
      "60 Train Loss 16.544298 Test MSE 5.647045762105001 Test RE 1.1358440669747703\n",
      "61 Train Loss 16.019564 Test MSE 5.489183125096583 Test RE 1.1198553265832294\n",
      "62 Train Loss 15.211414 Test MSE 5.696461075044628 Test RE 1.1408029284223709\n",
      "63 Train Loss 14.6964035 Test MSE 5.747105076572231 Test RE 1.1458628227461252\n",
      "64 Train Loss 14.355038 Test MSE 5.825759252350321 Test RE 1.153677245879368\n",
      "65 Train Loss 14.058694 Test MSE 5.863738319183689 Test RE 1.1574316412235723\n",
      "66 Train Loss 13.899967 Test MSE 5.820547707781878 Test RE 1.1531611083802271\n",
      "67 Train Loss 13.615154 Test MSE 5.763502274928592 Test RE 1.1474963023013345\n",
      "68 Train Loss 13.416016 Test MSE 5.738357691473361 Test RE 1.1449904600394547\n",
      "69 Train Loss 13.256187 Test MSE 5.73362302682881 Test RE 1.144518002165911\n",
      "70 Train Loss 13.130226 Test MSE 5.68474892156065 Test RE 1.139629556594881\n",
      "71 Train Loss 13.077744 Test MSE 5.68172373555552 Test RE 1.1393262846103702\n",
      "72 Train Loss 12.920636 Test MSE 5.682333046014596 Test RE 1.1393873738891838\n",
      "73 Train Loss 12.81185 Test MSE 5.617816928079884 Test RE 1.1329007165692189\n",
      "74 Train Loss 12.7025175 Test MSE 5.585545604076965 Test RE 1.1296420786886432\n",
      "75 Train Loss 12.6278305 Test MSE 5.513759013969556 Test RE 1.12235940631644\n",
      "76 Train Loss 12.588939 Test MSE 5.5009596833611 Test RE 1.1210559583834032\n",
      "77 Train Loss 12.473988 Test MSE 5.450164607776489 Test RE 1.1158681194121884\n",
      "78 Train Loss 12.424856 Test MSE 5.425009808824518 Test RE 1.1132900412032218\n",
      "79 Train Loss 12.379559 Test MSE 5.400171936784008 Test RE 1.1107385731475736\n",
      "80 Train Loss 12.301101 Test MSE 5.484825813958586 Test RE 1.1194107680115326\n",
      "81 Train Loss 12.208869 Test MSE 5.605590225339613 Test RE 1.1316672138210568\n",
      "82 Train Loss 12.160442 Test MSE 5.634078150769942 Test RE 1.1345391678652503\n",
      "83 Train Loss 12.109235 Test MSE 5.615321032619535 Test RE 1.1326490248600811\n",
      "84 Train Loss 12.045301 Test MSE 5.623550998130931 Test RE 1.1334787413925693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 11.969443 Test MSE 5.615664632656145 Test RE 1.1326836775799256\n",
      "86 Train Loss 11.9200325 Test MSE 5.592592704920884 Test RE 1.130354470355764\n",
      "87 Train Loss 11.90061 Test MSE 5.591506701475126 Test RE 1.1302447154965711\n",
      "88 Train Loss 11.8462715 Test MSE 5.5604348704439355 Test RE 1.1270999730132287\n",
      "89 Train Loss 11.814335 Test MSE 5.569282956454174 Test RE 1.1279963699330258\n",
      "90 Train Loss 11.796936 Test MSE 5.58727785431412 Test RE 1.1298172335618757\n",
      "91 Train Loss 11.780924 Test MSE 5.580519051386362 Test RE 1.1291336696725331\n",
      "92 Train Loss 11.726615 Test MSE 5.529851854648477 Test RE 1.1239961110623033\n",
      "93 Train Loss 11.694067 Test MSE 5.527214796075702 Test RE 1.123728075216713\n",
      "94 Train Loss 11.678461 Test MSE 5.551712770856008 Test RE 1.1262156414306335\n",
      "95 Train Loss 11.645833 Test MSE 5.550800051837732 Test RE 1.1261230609308153\n",
      "96 Train Loss 11.599 Test MSE 5.598075522196288 Test RE 1.1309084181505575\n",
      "97 Train Loss 11.574949 Test MSE 5.605648539568965 Test RE 1.1316731000995024\n",
      "98 Train Loss 11.561001 Test MSE 5.584050289189755 Test RE 1.1294908594698803\n",
      "99 Train Loss 11.546008 Test MSE 5.58135191720612 Test RE 1.1292179254330807\n",
      "100 Train Loss 11.524153 Test MSE 5.577382842134843 Test RE 1.1288163428163702\n",
      "101 Train Loss 11.452494 Test MSE 5.574098397680903 Test RE 1.1284839216188742\n",
      "102 Train Loss 11.428234 Test MSE 5.570416029602446 Test RE 1.128111109784376\n",
      "103 Train Loss 11.400636 Test MSE 5.546810359879172 Test RE 1.125718282187664\n",
      "104 Train Loss 11.374249 Test MSE 5.506479017261468 Test RE 1.1216182176301652\n",
      "105 Train Loss 11.334201 Test MSE 5.517313418003292 Test RE 1.1227211083854756\n",
      "106 Train Loss 11.307329 Test MSE 5.496636905897113 Test RE 1.1206153963610743\n",
      "107 Train Loss 11.265539 Test MSE 5.4828677720485 Test RE 1.1192109395277796\n",
      "108 Train Loss 11.200913 Test MSE 5.480806449123256 Test RE 1.1190005321148202\n",
      "109 Train Loss 11.162817 Test MSE 5.429845372114789 Test RE 1.1137860942578242\n",
      "110 Train Loss 11.106728 Test MSE 5.478300434726924 Test RE 1.118744679979716\n",
      "111 Train Loss 11.051472 Test MSE 5.485859948873075 Test RE 1.1195162925293016\n",
      "112 Train Loss 10.986179 Test MSE 5.469732113030077 Test RE 1.1178694527527253\n",
      "113 Train Loss 10.946295 Test MSE 5.435419159246653 Test RE 1.1143576035594178\n",
      "114 Train Loss 10.8898115 Test MSE 5.426233677635933 Test RE 1.113415611863075\n",
      "115 Train Loss 10.812138 Test MSE 5.474508283468745 Test RE 1.1183574080949203\n",
      "116 Train Loss 10.762725 Test MSE 5.4295661850491985 Test RE 1.113757460047525\n",
      "117 Train Loss 10.719418 Test MSE 5.3946670672599115 Test RE 1.1101722921067845\n",
      "118 Train Loss 10.697677 Test MSE 5.393248470249426 Test RE 1.1100263154762637\n",
      "119 Train Loss 10.648895 Test MSE 5.415674258787674 Test RE 1.1123317341826628\n",
      "120 Train Loss 10.594929 Test MSE 5.403440096506055 Test RE 1.1110746292999925\n",
      "121 Train Loss 10.555395 Test MSE 5.420931955973369 Test RE 1.1128715455164846\n",
      "122 Train Loss 10.513958 Test MSE 5.44282225996192 Test RE 1.1151162289934116\n",
      "123 Train Loss 10.434715 Test MSE 5.482624198702715 Test RE 1.119186079090485\n",
      "124 Train Loss 10.305564 Test MSE 5.528828328849909 Test RE 1.1238920854675578\n",
      "125 Train Loss 10.249206 Test MSE 5.510620287725476 Test RE 1.1220399073687881\n",
      "126 Train Loss 10.204538 Test MSE 5.556275180032109 Test RE 1.1266783095805195\n",
      "127 Train Loss 10.144092 Test MSE 5.609928040243806 Test RE 1.1321049923057482\n",
      "128 Train Loss 10.020556 Test MSE 5.525131898347682 Test RE 1.1235163201742573\n",
      "129 Train Loss 9.926721 Test MSE 5.546135218644422 Test RE 1.1256497705647746\n",
      "130 Train Loss 9.867172 Test MSE 5.560693528644812 Test RE 1.1271261877129541\n",
      "131 Train Loss 9.799025 Test MSE 5.451096529123676 Test RE 1.115963516243907\n",
      "132 Train Loss 9.738619 Test MSE 5.482635531624663 Test RE 1.1191872358031707\n",
      "133 Train Loss 9.684223 Test MSE 5.493539135071108 Test RE 1.120299576071337\n",
      "134 Train Loss 9.598332 Test MSE 5.425797361450855 Test RE 1.113370846833859\n",
      "135 Train Loss 9.541135 Test MSE 5.453528535537582 Test RE 1.116212432013979\n",
      "136 Train Loss 9.504819 Test MSE 5.4085902910190855 Test RE 1.111604003873493\n",
      "137 Train Loss 9.445877 Test MSE 5.338215766037649 Test RE 1.1043484401436088\n",
      "138 Train Loss 9.395047 Test MSE 5.34266118252946 Test RE 1.1048081693258338\n",
      "139 Train Loss 9.34899 Test MSE 5.365299872194709 Test RE 1.107146420708094\n",
      "140 Train Loss 9.311855 Test MSE 5.431901558562479 Test RE 1.1139969598485309\n",
      "141 Train Loss 9.254726 Test MSE 5.397508806573725 Test RE 1.1104646553659874\n",
      "142 Train Loss 9.147426 Test MSE 5.306471254387249 Test RE 1.101059956036468\n",
      "143 Train Loss 9.084883 Test MSE 5.316823492487971 Test RE 1.1021334454120302\n",
      "144 Train Loss 8.989838 Test MSE 5.288274934002178 Test RE 1.0991705229378013\n",
      "145 Train Loss 8.895773 Test MSE 5.270152630999144 Test RE 1.0972855418925334\n",
      "146 Train Loss 8.845664 Test MSE 5.275854603054984 Test RE 1.0978789782229208\n",
      "147 Train Loss 8.756818 Test MSE 5.205004018569285 Test RE 1.090482234885056\n",
      "148 Train Loss 8.648979 Test MSE 5.154796256502361 Test RE 1.0852100636178375\n",
      "149 Train Loss 8.545658 Test MSE 5.108457296280976 Test RE 1.0803213125409092\n",
      "Training time: 77.96\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 76.164536 Test MSE 4.3770960954729 Test RE 1.000002534974723\n",
      "1 Train Loss 57.53381 Test MSE 8.732701590344998 Test RE 1.4124802051902\n",
      "2 Train Loss 56.93745 Test MSE 9.022199146413172 Test RE 1.4357018658324134\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 2.61\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "1 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "2 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "3 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "4 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "5 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "6 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "7 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "8 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "9 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "10 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "11 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "12 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "13 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "14 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "15 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "16 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "17 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "19 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "20 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "21 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "22 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "23 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "24 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "25 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "26 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "27 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "28 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "29 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "30 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "31 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "32 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "33 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "34 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "35 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "36 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "37 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "38 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "39 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "40 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "41 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "42 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "43 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "44 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "45 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "46 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "47 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "48 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "49 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "50 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "51 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "52 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "53 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "54 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "55 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "56 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "57 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "58 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "59 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "60 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "61 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "62 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "63 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "64 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "65 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "66 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "67 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "68 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "69 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "70 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "71 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "72 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "73 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "74 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "75 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "76 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "77 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "78 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "79 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "80 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "81 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "82 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "83 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "84 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "85 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "86 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "87 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "88 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "89 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "90 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "91 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "92 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "93 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "94 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "95 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "96 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "97 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "98 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "99 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "100 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "101 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "102 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "103 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "104 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "105 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "106 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "107 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "108 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "109 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "110 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "111 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "112 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "113 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "114 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "115 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "116 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "117 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "118 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "119 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "120 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "121 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "123 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "124 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "125 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "126 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "127 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "128 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "129 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "130 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "131 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "132 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "133 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "134 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "135 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "136 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "137 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "138 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "139 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "140 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "141 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "142 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "143 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "144 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "145 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "146 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "147 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "148 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "149 Train Loss 59.911392 Test MSE 7.4971435256177905 Test RE 1.3087478246442839\n",
      "Training time: 55.57\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "1 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "2 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "3 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "4 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "5 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "6 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "7 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "8 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "9 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "10 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "11 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "12 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "13 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "14 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "15 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "16 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "17 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "18 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "19 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "20 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "21 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "22 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "23 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "24 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "25 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "26 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "27 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "28 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "29 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "30 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "31 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "32 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "33 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "34 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "35 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "36 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "37 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "38 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "39 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "40 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "41 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "42 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "43 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "44 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "45 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "46 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "47 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "48 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "49 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "50 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "51 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "52 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "53 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "54 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "55 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "56 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "57 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "58 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "59 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "60 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "61 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "62 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "63 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "64 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "65 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "66 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "67 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "68 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "70 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "71 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "72 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "73 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "74 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "75 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "76 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "77 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "78 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "79 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "80 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "81 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "82 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "83 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "84 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "85 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "86 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "87 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "88 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "89 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "90 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "91 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "92 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "93 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "94 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "95 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "96 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "97 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "98 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "99 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "100 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "101 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "102 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "103 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "104 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "105 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "106 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "107 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "108 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "109 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "110 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "111 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "112 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "113 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "114 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "115 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "116 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "117 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "118 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "119 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "120 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "121 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "122 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "123 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "124 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "125 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "126 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "127 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "128 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "129 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "130 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "131 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "132 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "133 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "134 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "135 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "136 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "137 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "138 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "139 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "140 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "141 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "142 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "143 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "144 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "145 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "146 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "147 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "148 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "149 Train Loss 57.671364 Test MSE 8.698858552609966 Test RE 1.40974055902423\n",
      "Training time: 59.62\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 57.033104 Test MSE 8.645205321324799 Test RE 1.4053863022873674\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.56\n"
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(5):\n",
    "#for tune_reps in range(4,5):\n",
    "  max_reps = 10 #10\n",
    "  max_iter = 150 #100\n",
    "  label = \"KG_swish_tune\"+str(tune_reps)\n",
    "\n",
    "  train_loss_full = []\n",
    "  test_mse_full = []\n",
    "  test_re_full = []\n",
    "  beta_full = []\n",
    "  elapsed_time= np.zeros((max_reps,1))\n",
    "  time_threshold = np.empty((max_reps,1))\n",
    "  time_threshold[:] = np.nan\n",
    "  epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "  N_I = 200  #Total number of data points for 'y'\n",
    "  N_B = 400\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  for reps in range(max_reps):\n",
    "      print(reps)\n",
    "\n",
    "      train_loss = []\n",
    "      test_mse_loss = []\n",
    "      test_re_loss = []\n",
    "      beta_val = []\n",
    "      \n",
    "      torch.manual_seed(reps*36)\n",
    "\n",
    "      layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "      PINN = Sequentialmodel(layers)\n",
    "    \n",
    "      PINN.to(device)\n",
    "\n",
    "      'Neural Network Summary'\n",
    "      print(PINN)\n",
    "\n",
    "      params = list(PINN.parameters())\n",
    "      \n",
    "\n",
    "      optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "      nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "      torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "      train_loss_full.append(train_loss)\n",
    "      test_mse_full.append(test_mse_loss)\n",
    "      test_re_full.append(test_re_loss)\n",
    "      #elapsed_time[reps] = time.time() - start_time\n",
    "      beta_full.append(beta_val)\n",
    "    \n",
    "      if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "            \n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "      \n",
    "  mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label}\n",
    "  savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [],
   "source": [
    "for tune_reps in range(4,5):\n",
    "    label = \"KG_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    " \n",
    "    #re = np.array(data[\"test_re_loss\"])\n",
    "    #print(\"tune_reps\",\" \",np.mean(re[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4   (1, 150)\n",
      "4   (1, 150)\n",
      "4   (1, 2)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-841e5ee3fd0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "tune_reps = 4\n",
    "label = \"KG_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "data = sio.loadmat(label)\n",
    "for k in range(10):\n",
    "    print(tune_reps,\" \",data[\"test_re_loss\"][0][k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638780022678827"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data[\"test_re_loss\"][:,-1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
