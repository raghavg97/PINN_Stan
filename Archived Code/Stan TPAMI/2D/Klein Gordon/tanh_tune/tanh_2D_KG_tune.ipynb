{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660687406024,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "T7Wci76Yf-U8"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "\n",
    "  xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "  xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "  xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "  y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "  f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.941574 Test MSE 8.656132292244305 Test RE 1.4062741797472664\n",
      "1 Train Loss 58.2084 Test MSE 8.630431149985787 Test RE 1.4041849255864758\n",
      "2 Train Loss 56.60464 Test MSE 8.214433591342935 Test RE 1.3699252539228532\n",
      "3 Train Loss 49.17374 Test MSE 7.920135555490482 Test RE 1.345161310476479\n",
      "4 Train Loss 38.61943 Test MSE 7.7330210222128715 Test RE 1.3291765042486505\n",
      "5 Train Loss 37.523773 Test MSE 7.571091473504054 Test RE 1.3151863928999656\n",
      "6 Train Loss 35.027287 Test MSE 7.327064904591698 Test RE 1.2938176743937138\n",
      "7 Train Loss 34.19066 Test MSE 6.854554046245821 Test RE 1.2514043572658429\n",
      "8 Train Loss 32.450104 Test MSE 6.695386247608389 Test RE 1.2367897525729077\n",
      "9 Train Loss 31.775368 Test MSE 5.990518623982262 Test RE 1.1698771855356485\n",
      "10 Train Loss 31.18916 Test MSE 6.288217068685007 Test RE 1.1985932368470391\n",
      "11 Train Loss 29.181896 Test MSE 6.257972094433141 Test RE 1.1957072743615007\n",
      "12 Train Loss 28.337997 Test MSE 6.248447411767687 Test RE 1.1947969899344484\n",
      "13 Train Loss 27.238682 Test MSE 6.29586662904215 Test RE 1.1993220542915979\n",
      "14 Train Loss 26.277796 Test MSE 6.233415869479185 Test RE 1.1933589962669724\n",
      "15 Train Loss 25.35485 Test MSE 5.988894237160395 Test RE 1.1697185630487195\n",
      "16 Train Loss 24.590528 Test MSE 5.720781483792168 Test RE 1.1432356004684074\n",
      "17 Train Loss 24.265457 Test MSE 5.800536473029403 Test RE 1.1511770987010552\n",
      "18 Train Loss 23.808582 Test MSE 5.499432524473107 Test RE 1.1209003355913862\n",
      "19 Train Loss 23.449959 Test MSE 5.582399515268079 Test RE 1.1293238953686282\n",
      "20 Train Loss 23.212982 Test MSE 5.525951838928087 Test RE 1.123599683111609\n",
      "21 Train Loss 22.830153 Test MSE 5.729650842196186 Test RE 1.144121479368195\n",
      "22 Train Loss 22.04135 Test MSE 5.637220475152406 Test RE 1.1348555100457332\n",
      "23 Train Loss 20.431564 Test MSE 5.391908158079427 Test RE 1.109888376881928\n",
      "24 Train Loss 19.226664 Test MSE 5.473259884425189 Test RE 1.1182298865121796\n",
      "25 Train Loss 18.009638 Test MSE 5.237014812887371 Test RE 1.0938303300018524\n",
      "26 Train Loss 17.47158 Test MSE 5.209181758303111 Test RE 1.090919778944214\n",
      "27 Train Loss 16.824215 Test MSE 5.587207134151413 Test RE 1.1298100832899984\n",
      "28 Train Loss 16.294128 Test MSE 5.735821630948424 Test RE 1.1447374184757273\n",
      "29 Train Loss 15.546733 Test MSE 5.917536440135589 Test RE 1.1627290703999382\n",
      "30 Train Loss 14.824381 Test MSE 5.919862197727461 Test RE 1.1629575405017438\n",
      "31 Train Loss 14.530286 Test MSE 5.825300838302584 Test RE 1.1536318550352511\n",
      "32 Train Loss 14.167078 Test MSE 6.012953213553565 Test RE 1.1720657429378094\n",
      "33 Train Loss 13.922478 Test MSE 5.978397389900353 Test RE 1.1686930196467231\n",
      "34 Train Loss 13.771563 Test MSE 5.946119117990395 Test RE 1.1655337743589165\n",
      "35 Train Loss 13.455645 Test MSE 5.923449742674971 Test RE 1.1633098739175403\n",
      "36 Train Loss 13.184238 Test MSE 5.970489810498006 Test RE 1.1679198533451722\n",
      "37 Train Loss 13.019976 Test MSE 5.972679309114375 Test RE 1.1681339835578242\n",
      "38 Train Loss 12.903628 Test MSE 5.958367104680502 Test RE 1.1667335567877763\n",
      "39 Train Loss 12.796614 Test MSE 5.9458410801399175 Test RE 1.1655065241233267\n",
      "40 Train Loss 12.559149 Test MSE 5.9382760408620054 Test RE 1.1647648368788919\n",
      "41 Train Loss 12.482627 Test MSE 5.982426513342792 Test RE 1.1690867719377418\n",
      "42 Train Loss 12.279762 Test MSE 5.988804281964824 Test RE 1.169709778233605\n",
      "43 Train Loss 12.202916 Test MSE 5.977565835108698 Test RE 1.1686117381582857\n",
      "44 Train Loss 12.061718 Test MSE 5.9675857026612045 Test RE 1.167635774663669\n",
      "45 Train Loss 11.626541 Test MSE 5.781327914877566 Test RE 1.1492694485083168\n",
      "46 Train Loss 11.006044 Test MSE 5.558326121823516 Test RE 1.1268862311068948\n",
      "47 Train Loss 9.495936 Test MSE 4.802932698851807 Test RE 1.047517557280764\n",
      "48 Train Loss 9.161598 Test MSE 4.568211332903425 Test RE 1.0216006338589612\n",
      "49 Train Loss 8.866643 Test MSE 4.2172423238546495 Test RE 0.9815724003392075\n",
      "50 Train Loss 8.742322 Test MSE 4.177741467780003 Test RE 0.9769646298255765\n",
      "51 Train Loss 8.507599 Test MSE 4.120680176659775 Test RE 0.9702698010427103\n",
      "52 Train Loss 8.307916 Test MSE 4.077306707928184 Test RE 0.9651498580184104\n",
      "53 Train Loss 8.157634 Test MSE 3.9874549359890064 Test RE 0.9544560919542099\n",
      "54 Train Loss 8.054083 Test MSE 3.9230615534759044 Test RE 0.9467179716324836\n",
      "55 Train Loss 7.8966265 Test MSE 3.8943999781509957 Test RE 0.9432533088363888\n",
      "56 Train Loss 7.8079357 Test MSE 3.867749749359857 Test RE 0.9400203242336298\n",
      "57 Train Loss 7.719731 Test MSE 3.8166665173916994 Test RE 0.9337920405298131\n",
      "58 Train Loss 7.6205206 Test MSE 3.7930144844291855 Test RE 0.9308941709446528\n",
      "59 Train Loss 7.578372 Test MSE 3.783598701754206 Test RE 0.9297380267186635\n",
      "60 Train Loss 7.4989233 Test MSE 3.7783970574340158 Test RE 0.9290987107887506\n",
      "61 Train Loss 7.4285617 Test MSE 3.7506286606058747 Test RE 0.925678324021\n",
      "62 Train Loss 7.327534 Test MSE 3.7358809300993805 Test RE 0.9238566159881063\n",
      "63 Train Loss 7.0778847 Test MSE 3.485373902496105 Test RE 0.8923449039129288\n",
      "64 Train Loss 5.5260067 Test MSE 2.913169558050589 Test RE 0.8158136016109089\n",
      "65 Train Loss 4.8041167 Test MSE 2.1370405239229755 Test RE 0.6987381232764347\n",
      "66 Train Loss 4.509363 Test MSE 2.0330207301815317 Test RE 0.6815205626850671\n",
      "67 Train Loss 4.30926 Test MSE 1.9335331503672988 Test RE 0.6646360158616346\n",
      "68 Train Loss 4.0912833 Test MSE 1.9106880458601379 Test RE 0.6606979412122649\n",
      "69 Train Loss 3.9547203 Test MSE 1.8103602530780107 Test RE 0.6431178492751548\n",
      "70 Train Loss 3.9134505 Test MSE 1.7749201809969042 Test RE 0.6367918170770231\n",
      "71 Train Loss 3.8236828 Test MSE 1.672941061762861 Test RE 0.6182275872380719\n",
      "72 Train Loss 3.7288718 Test MSE 1.4987055191526566 Test RE 0.585148658353123\n",
      "73 Train Loss 3.4674199 Test MSE 1.3244691620629585 Test RE 0.5500839654490737\n",
      "74 Train Loss 2.1571014 Test MSE 0.6038685947519298 Test RE 0.37143197044522047\n",
      "75 Train Loss 1.2309568 Test MSE 0.2918030396391665 Test RE 0.25819805477779717\n",
      "76 Train Loss 0.8604558 Test MSE 0.16338662835187404 Test RE 0.1932040898943718\n",
      "77 Train Loss 0.47403908 Test MSE 0.12826323231834444 Test RE 0.17118241554722055\n",
      "78 Train Loss 0.30692676 Test MSE 0.07641308466721247 Test RE 0.13212710706170036\n",
      "79 Train Loss 0.23189801 Test MSE 0.06445190400118976 Test RE 0.12134613161886257\n",
      "80 Train Loss 0.18679093 Test MSE 0.048284382293013524 Test RE 0.1050295247111525\n",
      "81 Train Loss 0.15431881 Test MSE 0.04108995043277247 Test RE 0.09688931131347625\n",
      "82 Train Loss 0.13134624 Test MSE 0.0327195095548873 Test RE 0.08645924781440144\n",
      "83 Train Loss 0.11011118 Test MSE 0.019863391713768684 Test RE 0.06736506975955132\n",
      "84 Train Loss 0.09340487 Test MSE 0.01633517662927581 Test RE 0.06108997925748794\n",
      "85 Train Loss 0.07996107 Test MSE 0.015843912579019837 Test RE 0.06016435691992355\n",
      "86 Train Loss 0.06685943 Test MSE 0.014323395490790949 Test RE 0.05720461302985699\n",
      "87 Train Loss 0.062474046 Test MSE 0.013046075307018283 Test RE 0.05459438786140387\n",
      "88 Train Loss 0.056739572 Test MSE 0.010956363805584166 Test RE 0.0500312418156135\n",
      "89 Train Loss 0.0407423 Test MSE 0.010555950643576336 Test RE 0.04910850754933083\n",
      "90 Train Loss 0.03558996 Test MSE 0.010340354419615545 Test RE 0.048604420846189815\n",
      "91 Train Loss 0.032776803 Test MSE 0.009611311588968304 Test RE 0.04685968757386719\n",
      "92 Train Loss 0.028617755 Test MSE 0.007558561543009166 Test RE 0.041555416264815154\n",
      "93 Train Loss 0.024195418 Test MSE 0.005991537112673835 Test RE 0.03699790962135765\n",
      "94 Train Loss 0.022588935 Test MSE 0.006504673123030955 Test RE 0.03854968190380859\n",
      "95 Train Loss 0.021022206 Test MSE 0.006690145638952997 Test RE 0.03909541669068151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 0.02024583 Test MSE 0.005688014573864776 Test RE 0.03604860063037551\n",
      "97 Train Loss 0.01865324 Test MSE 0.005106788495484318 Test RE 0.03415717902401208\n",
      "98 Train Loss 0.016006708 Test MSE 0.004737985862668008 Test RE 0.03290068502930461\n",
      "99 Train Loss 0.015055071 Test MSE 0.004361546619424858 Test RE 0.03156663726156854\n",
      "Training time: 68.43\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.743774 Test MSE 8.578940996974442 Test RE 1.3999898941685418\n",
      "1 Train Loss 57.264946 Test MSE 8.898132480502465 Test RE 1.4257963349843084\n",
      "2 Train Loss 54.29303 Test MSE 9.295049998266027 Test RE 1.457249534884962\n",
      "3 Train Loss 51.41651 Test MSE 8.724413279546765 Test RE 1.4118097451976181\n",
      "4 Train Loss 46.416847 Test MSE 8.411870998814782 Test RE 1.3862908674699321\n",
      "5 Train Loss 45.210636 Test MSE 8.390315150111201 Test RE 1.3845135075495716\n",
      "6 Train Loss 44.59508 Test MSE 8.425971190710488 Test RE 1.3874522489767684\n",
      "7 Train Loss 44.363785 Test MSE 8.445867027991003 Test RE 1.389089345013525\n",
      "8 Train Loss 44.154095 Test MSE 8.414584015537203 Test RE 1.3865144043680189\n",
      "9 Train Loss 43.964733 Test MSE 8.412532704267413 Test RE 1.386345391498356\n",
      "10 Train Loss 43.448387 Test MSE 8.4921894718809 Test RE 1.3928934556902228\n",
      "11 Train Loss 42.963943 Test MSE 8.563555287562771 Test RE 1.39873394055474\n",
      "12 Train Loss 42.503944 Test MSE 8.604667217917623 Test RE 1.4020874426041927\n",
      "13 Train Loss 42.31159 Test MSE 8.647600260077516 Test RE 1.4055809524385978\n",
      "14 Train Loss 41.982388 Test MSE 8.864175980237269 Test RE 1.4230732168633557\n",
      "15 Train Loss 41.72628 Test MSE 8.922684784107952 Test RE 1.4277620547419085\n",
      "16 Train Loss 41.41709 Test MSE 8.885562890494628 Test RE 1.4247889320847154\n",
      "17 Train Loss 41.382317 Test MSE 8.87443979712488 Test RE 1.4238968657439919\n",
      "18 Train Loss 41.09388 Test MSE 8.900914130946946 Test RE 1.4260191770867072\n",
      "19 Train Loss 40.8732 Test MSE 8.960731403445463 Test RE 1.43080282871645\n",
      "20 Train Loss 40.628574 Test MSE 8.948318956513862 Test RE 1.4298115079262417\n",
      "21 Train Loss 40.42649 Test MSE 8.898950945638928 Test RE 1.4258619070445602\n",
      "22 Train Loss 39.527233 Test MSE 9.218596439161256 Test RE 1.4512440827046613\n",
      "23 Train Loss 38.82836 Test MSE 8.985704272641646 Test RE 1.4327952102446286\n",
      "24 Train Loss 34.625484 Test MSE 9.04013306660058 Test RE 1.4371280691281942\n",
      "25 Train Loss 33.171345 Test MSE 8.797607873254192 Test RE 1.4177196558347107\n",
      "26 Train Loss 32.228508 Test MSE 8.723850176115386 Test RE 1.4117641829509189\n",
      "27 Train Loss 31.405643 Test MSE 8.256175762733271 Test RE 1.3734015248364795\n",
      "28 Train Loss 30.402737 Test MSE 7.959454437338416 Test RE 1.348496149782791\n",
      "29 Train Loss 29.865019 Test MSE 8.29867845045881 Test RE 1.3769321135961436\n",
      "30 Train Loss 28.89138 Test MSE 8.067813004296262 Test RE 1.3576442108451703\n",
      "31 Train Loss 28.376865 Test MSE 7.654662146060525 Test RE 1.3224250698678814\n",
      "32 Train Loss 28.014704 Test MSE 7.51976826812776 Test RE 1.310721094656698\n",
      "33 Train Loss 25.241718 Test MSE 6.759386672434363 Test RE 1.2426868589404019\n",
      "34 Train Loss 22.705662 Test MSE 6.094430677884462 Test RE 1.179979958394769\n",
      "35 Train Loss 20.795574 Test MSE 5.8022748011070435 Test RE 1.151349580468784\n",
      "36 Train Loss 19.612907 Test MSE 5.435165327622144 Test RE 1.1143315832567575\n",
      "37 Train Loss 18.634003 Test MSE 5.3851515492518915 Test RE 1.1091927574336908\n",
      "38 Train Loss 18.34984 Test MSE 5.310770770948753 Test RE 1.1015059272622674\n",
      "39 Train Loss 18.151009 Test MSE 5.349411053326484 Test RE 1.10550585145978\n",
      "40 Train Loss 17.87954 Test MSE 5.275906373951814 Test RE 1.097884364842166\n",
      "41 Train Loss 17.50521 Test MSE 5.48544045365739 Test RE 1.1194734878723003\n",
      "42 Train Loss 17.17104 Test MSE 5.538432102226502 Test RE 1.1248677824049151\n",
      "43 Train Loss 16.800343 Test MSE 5.409824460638342 Test RE 1.1117308233923027\n",
      "44 Train Loss 15.847203 Test MSE 5.439959300138253 Test RE 1.1148229112307195\n",
      "45 Train Loss 15.221776 Test MSE 5.379590259286136 Test RE 1.1086198732822885\n",
      "46 Train Loss 13.440821 Test MSE 4.50640965720369 Test RE 1.0146666698440991\n",
      "47 Train Loss 12.0837555 Test MSE 3.91613707003888 Test RE 0.9458820902517991\n",
      "48 Train Loss 11.069018 Test MSE 3.9531520097968356 Test RE 0.9503417688476017\n",
      "49 Train Loss 10.054938 Test MSE 3.883875804333659 Test RE 0.9419779291205426\n",
      "50 Train Loss 9.574096 Test MSE 3.6587979689261854 Test RE 0.9142759060600323\n",
      "51 Train Loss 9.122542 Test MSE 3.629240500091772 Test RE 0.9105754447525599\n",
      "52 Train Loss 8.97437 Test MSE 3.719069944208443 Test RE 0.9217756540864936\n",
      "53 Train Loss 8.781095 Test MSE 3.713117262977332 Test RE 0.9210376693091954\n",
      "54 Train Loss 8.488606 Test MSE 3.639063914241896 Test RE 0.9118069579251059\n",
      "55 Train Loss 8.250676 Test MSE 3.7919591312521645 Test RE 0.9307646578000789\n",
      "56 Train Loss 7.972522 Test MSE 3.710248886267083 Test RE 0.9206818505695157\n",
      "57 Train Loss 7.8439655 Test MSE 3.5584214102870493 Test RE 0.9016474309483653\n",
      "58 Train Loss 7.7100253 Test MSE 3.4729090530614104 Test RE 0.8907478144990679\n",
      "59 Train Loss 7.603195 Test MSE 3.509814226439748 Test RE 0.8954681124538127\n",
      "60 Train Loss 7.4574165 Test MSE 3.4648598663738794 Test RE 0.8897149693346937\n",
      "61 Train Loss 7.323857 Test MSE 3.430891438820343 Test RE 0.8853429806644161\n",
      "62 Train Loss 7.1779776 Test MSE 3.489843770274643 Test RE 0.8929169208377264\n",
      "63 Train Loss 7.0722837 Test MSE 3.4614288763771506 Test RE 0.8892743513381994\n",
      "64 Train Loss 6.9903393 Test MSE 3.4507524673547776 Test RE 0.8879018561395831\n",
      "65 Train Loss 6.919586 Test MSE 3.4154459911161865 Test RE 0.8833478805659053\n",
      "66 Train Loss 6.8223033 Test MSE 3.3851976828002712 Test RE 0.8794275723077587\n",
      "67 Train Loss 6.748413 Test MSE 3.3997987979655924 Test RE 0.8813221155700363\n",
      "68 Train Loss 6.711525 Test MSE 3.36351177080935 Test RE 0.8766061964338396\n",
      "69 Train Loss 6.6901503 Test MSE 3.368256320501663 Test RE 0.8772242462988925\n",
      "70 Train Loss 6.633819 Test MSE 3.408339454271235 Test RE 0.8824284086860779\n",
      "71 Train Loss 6.5319185 Test MSE 3.359029308247083 Test RE 0.8760218868290627\n",
      "72 Train Loss 6.4889517 Test MSE 3.376446267916676 Test RE 0.8782900883577895\n",
      "73 Train Loss 6.3911877 Test MSE 3.3789322904515537 Test RE 0.8786133642249276\n",
      "74 Train Loss 6.2860756 Test MSE 3.3428636012164272 Test RE 0.8739113674696326\n",
      "75 Train Loss 6.221261 Test MSE 3.370046669750832 Test RE 0.8774573534287284\n",
      "76 Train Loss 6.1004043 Test MSE 3.307118147635668 Test RE 0.8692264147042743\n",
      "77 Train Loss 6.031895 Test MSE 3.273056029786502 Test RE 0.8647384702874431\n",
      "78 Train Loss 5.9035673 Test MSE 3.2949559476485875 Test RE 0.8676266165551486\n",
      "79 Train Loss 5.8234105 Test MSE 3.3034941834119538 Test RE 0.8687500318352062\n",
      "80 Train Loss 5.5463295 Test MSE 3.24599738528925 Test RE 0.8611566172342955\n",
      "81 Train Loss 5.4517126 Test MSE 3.2699912957411255 Test RE 0.8643335254781411\n",
      "82 Train Loss 5.351289 Test MSE 3.2648595694099365 Test RE 0.8636550428328535\n",
      "83 Train Loss 5.015005 Test MSE 3.2116210260341376 Test RE 0.8565844901741841\n",
      "84 Train Loss 4.2963223 Test MSE 2.9149554597866243 Test RE 0.8160636282006961\n",
      "85 Train Loss 3.1849074 Test MSE 2.481391552847174 Test RE 0.7529319215348989\n",
      "86 Train Loss 2.8415735 Test MSE 2.2834258788396946 Test RE 0.7222732316413303\n",
      "87 Train Loss 2.424541 Test MSE 2.2679239788586907 Test RE 0.7198173438938015\n",
      "88 Train Loss 2.0920105 Test MSE 2.4839222651845656 Test RE 0.7533157723859655\n",
      "89 Train Loss 1.8526858 Test MSE 2.375008365228873 Test RE 0.7366151251153739\n",
      "90 Train Loss 1.7184453 Test MSE 2.401356792760669 Test RE 0.7406898721780832\n",
      "91 Train Loss 1.6867367 Test MSE 2.391147880589951 Test RE 0.7391137441076707\n",
      "92 Train Loss 1.5714948 Test MSE 2.4531082404212734 Test RE 0.7486286024529142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 1.446276 Test MSE 2.4748358253842935 Test RE 0.751936657210645\n",
      "94 Train Loss 1.3869934 Test MSE 2.5147236454967428 Test RE 0.7579720526836445\n",
      "95 Train Loss 1.3547534 Test MSE 2.5238785979514016 Test RE 0.7593505130920775\n",
      "96 Train Loss 1.3218989 Test MSE 2.4907521052341832 Test RE 0.7543507271514012\n",
      "97 Train Loss 1.2923701 Test MSE 2.5147432726746715 Test RE 0.7579750106276205\n",
      "98 Train Loss 1.2770398 Test MSE 2.5114420255621392 Test RE 0.757477328697679\n",
      "99 Train Loss 1.2591393 Test MSE 2.4979669457220552 Test RE 0.755442482646446\n",
      "Training time: 70.03\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.563774 Test MSE 8.459371998443434 Test RE 1.3901994807353635\n",
      "1 Train Loss 55.58864 Test MSE 8.567654118208985 Test RE 1.3990686431103057\n",
      "2 Train Loss 50.301025 Test MSE 8.696951923191882 Test RE 1.4095860559877949\n",
      "3 Train Loss 47.849636 Test MSE 8.167971335705213 Test RE 1.3660454930314978\n",
      "4 Train Loss 44.8115 Test MSE 7.773734157405072 Test RE 1.3326708632308815\n",
      "5 Train Loss 42.26242 Test MSE 7.7187499172254395 Test RE 1.327949456171726\n",
      "6 Train Loss 41.023422 Test MSE 7.233363756536756 Test RE 1.2855181512125582\n",
      "7 Train Loss 38.787514 Test MSE 7.523473932819386 Test RE 1.311044009836653\n",
      "8 Train Loss 38.123993 Test MSE 7.545288592542861 Test RE 1.3129433503191659\n",
      "9 Train Loss 37.836452 Test MSE 7.495520879967967 Test RE 1.308606187440939\n",
      "10 Train Loss 36.976696 Test MSE 7.531871274742453 Test RE 1.3117754681117086\n",
      "11 Train Loss 36.545174 Test MSE 7.4137171229406285 Test RE 1.3014457389815934\n",
      "12 Train Loss 35.49099 Test MSE 7.544083439996762 Test RE 1.312838492818404\n",
      "13 Train Loss 35.00553 Test MSE 7.328156927396142 Test RE 1.293914085834301\n",
      "14 Train Loss 34.16624 Test MSE 7.39258530983842 Test RE 1.299589616521434\n",
      "15 Train Loss 32.97695 Test MSE 6.563073171712872 Test RE 1.22450815952411\n",
      "16 Train Loss 31.81698 Test MSE 6.430584593898199 Test RE 1.2120855900864829\n",
      "17 Train Loss 31.303112 Test MSE 6.401937968971897 Test RE 1.2093828095888473\n",
      "18 Train Loss 30.126951 Test MSE 6.614266358408436 Test RE 1.2292745780978567\n",
      "19 Train Loss 29.372066 Test MSE 6.305936419641983 Test RE 1.2002807862242686\n",
      "20 Train Loss 28.360737 Test MSE 6.169261121252732 Test RE 1.1872020465997166\n",
      "21 Train Loss 27.876797 Test MSE 6.131095708736412 Test RE 1.1835241061706605\n",
      "22 Train Loss 27.20969 Test MSE 5.905497053838503 Test RE 1.1615456664670114\n",
      "23 Train Loss 26.852716 Test MSE 6.2654527076151645 Test RE 1.1964217192342754\n",
      "24 Train Loss 26.312237 Test MSE 5.972127328452325 Test RE 1.168080004243487\n",
      "25 Train Loss 26.084599 Test MSE 6.167308362278611 Test RE 1.1870141389322717\n",
      "26 Train Loss 25.347054 Test MSE 6.151744777040318 Test RE 1.1855154409129152\n",
      "27 Train Loss 24.669518 Test MSE 6.173081773002377 Test RE 1.1875696095404857\n",
      "28 Train Loss 24.476954 Test MSE 6.19852859996809 Test RE 1.190014806301226\n",
      "29 Train Loss 24.100548 Test MSE 6.297611341037001 Test RE 1.1994882209808426\n",
      "30 Train Loss 23.809433 Test MSE 6.254407311853754 Test RE 1.1953666653285417\n",
      "31 Train Loss 23.525093 Test MSE 6.196232804735914 Test RE 1.1897944085655436\n",
      "32 Train Loss 23.331902 Test MSE 6.219598293611631 Test RE 1.1920356065794606\n",
      "33 Train Loss 23.03838 Test MSE 6.206624259849008 Test RE 1.1907916690185363\n",
      "34 Train Loss 22.838482 Test MSE 5.977217742607524 Test RE 1.1685777116902951\n",
      "35 Train Loss 22.732864 Test MSE 6.023209655249054 Test RE 1.1730649276705167\n",
      "36 Train Loss 22.585863 Test MSE 5.9855417565164055 Test RE 1.1693911229878926\n",
      "37 Train Loss 22.469646 Test MSE 5.854679226377895 Test RE 1.1565372174803004\n",
      "38 Train Loss 22.350666 Test MSE 5.872163261595811 Test RE 1.1582628340798597\n",
      "39 Train Loss 22.244017 Test MSE 5.8466041449841395 Test RE 1.15573936380779\n",
      "40 Train Loss 22.186813 Test MSE 5.836733248161716 Test RE 1.1547633268685986\n",
      "41 Train Loss 22.084862 Test MSE 5.9727441290894046 Test RE 1.1681403222716815\n",
      "42 Train Loss 21.871443 Test MSE 5.850602506588195 Test RE 1.1561344883956266\n",
      "43 Train Loss 21.813728 Test MSE 5.744522230334733 Test RE 1.1456053087423015\n",
      "44 Train Loss 21.563602 Test MSE 5.53370900686472 Test RE 1.124388044559163\n",
      "45 Train Loss 21.200502 Test MSE 5.536920575561606 Test RE 1.1247142747298557\n",
      "46 Train Loss 20.731632 Test MSE 5.323565696838573 Test RE 1.1028320255588182\n",
      "47 Train Loss 20.221773 Test MSE 5.407218666317007 Test RE 1.111463042910701\n",
      "48 Train Loss 19.186146 Test MSE 5.084246417198708 Test RE 1.0777582498588718\n",
      "49 Train Loss 17.75063 Test MSE 4.285282765189815 Test RE 0.9894589982583566\n",
      "50 Train Loss 16.098782 Test MSE 4.117761245685628 Test RE 0.9699260893035809\n",
      "51 Train Loss 14.220873 Test MSE 3.5681290205123273 Test RE 0.9028764703673913\n",
      "52 Train Loss 11.315773 Test MSE 4.258058152782088 Test RE 0.9863109494969805\n",
      "53 Train Loss 10.653408 Test MSE 4.137368088735984 Test RE 0.9722325130466789\n",
      "54 Train Loss 10.365667 Test MSE 4.19671535844941 Test RE 0.9791806382696101\n",
      "55 Train Loss 10.269186 Test MSE 4.279937432719269 Test RE 0.9888416950415283\n",
      "56 Train Loss 10.047577 Test MSE 4.185119448820599 Test RE 0.9778269195335891\n",
      "57 Train Loss 9.890598 Test MSE 4.202559420311177 Test RE 0.9798621714410439\n",
      "58 Train Loss 9.751946 Test MSE 4.2012848685218085 Test RE 0.9797135739241704\n",
      "59 Train Loss 9.67863 Test MSE 4.147842810606103 Test RE 0.9734624528758331\n",
      "60 Train Loss 9.534802 Test MSE 4.265351621808784 Test RE 0.9871552957122924\n",
      "61 Train Loss 9.387638 Test MSE 4.295082385847424 Test RE 0.9905897037790137\n",
      "62 Train Loss 9.106385 Test MSE 4.244345533609797 Test RE 0.9847215145484485\n",
      "63 Train Loss 8.974697 Test MSE 4.243498901826856 Test RE 0.9846232970371657\n",
      "64 Train Loss 8.7894535 Test MSE 4.290530506949749 Test RE 0.9900646568467887\n",
      "65 Train Loss 8.715473 Test MSE 4.317558991990177 Test RE 0.9931782503669351\n",
      "66 Train Loss 8.62059 Test MSE 4.323691591026284 Test RE 0.9938833481685306\n",
      "67 Train Loss 8.574699 Test MSE 4.318855081550776 Test RE 0.99332731044627\n",
      "68 Train Loss 8.484366 Test MSE 4.344424990788308 Test RE 0.9962634827952728\n",
      "69 Train Loss 8.381986 Test MSE 4.314041929195291 Test RE 0.992773648839894\n",
      "70 Train Loss 8.339984 Test MSE 4.312549788368603 Test RE 0.992601943715952\n",
      "71 Train Loss 8.2859125 Test MSE 4.285022398366483 Test RE 0.989428938840623\n",
      "72 Train Loss 8.2042465 Test MSE 4.258162197905131 Test RE 0.9863229996162535\n",
      "73 Train Loss 8.099619 Test MSE 4.303322501392636 Test RE 0.9915394716368431\n",
      "74 Train Loss 8.051151 Test MSE 4.27012881512792 Test RE 0.9877079479210468\n",
      "75 Train Loss 7.962988 Test MSE 4.216795975632176 Test RE 0.9815204547008369\n",
      "76 Train Loss 7.8678246 Test MSE 4.223337604426994 Test RE 0.9822814891768213\n",
      "77 Train Loss 7.8319554 Test MSE 4.226895353503792 Test RE 0.9826951401455882\n",
      "78 Train Loss 7.7958784 Test MSE 4.26020933870291 Test RE 0.9865600619142209\n",
      "79 Train Loss 7.6613894 Test MSE 4.316998223898791 Test RE 0.9931137508710259\n",
      "80 Train Loss 7.5955353 Test MSE 4.327411575049852 Test RE 0.9943108110427976\n",
      "81 Train Loss 7.5599046 Test MSE 4.341648390618676 Test RE 0.995945066953293\n",
      "82 Train Loss 7.524016 Test MSE 4.366082807457266 Test RE 0.9987436806884517\n",
      "83 Train Loss 7.392214 Test MSE 4.281093271504687 Test RE 0.9889752091929058\n",
      "84 Train Loss 7.299591 Test MSE 4.236676849583349 Test RE 0.9838315148776777\n",
      "85 Train Loss 7.2392063 Test MSE 4.192053324950848 Test RE 0.9786366126409961\n",
      "86 Train Loss 7.1964784 Test MSE 4.160378591684497 Test RE 0.9749323622327893\n",
      "87 Train Loss 7.1105604 Test MSE 4.1629046882418965 Test RE 0.9752282967861914\n",
      "88 Train Loss 6.9110036 Test MSE 3.8582743706502534 Test RE 0.9388681671585919\n",
      "89 Train Loss 6.720211 Test MSE 3.8697187224597696 Test RE 0.9402595640181728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 6.614764 Test MSE 4.006848690466505 Test RE 0.9567743669746352\n",
      "91 Train Loss 6.482505 Test MSE 3.9937085055069868 Test RE 0.9552042407402054\n",
      "92 Train Loss 6.397782 Test MSE 3.916393712056599 Test RE 0.9459130836908413\n",
      "93 Train Loss 6.3522215 Test MSE 3.878658434238948 Test RE 0.9413450176493083\n",
      "94 Train Loss 6.2789893 Test MSE 3.7828916383700997 Test RE 0.9296511498479264\n",
      "95 Train Loss 6.1801577 Test MSE 3.7050465484179878 Test RE 0.9200361555857076\n",
      "96 Train Loss 6.1143394 Test MSE 3.745009574943728 Test RE 0.9249846515860521\n",
      "97 Train Loss 6.0688505 Test MSE 3.810761644019415 Test RE 0.9330694128036687\n",
      "98 Train Loss 6.033643 Test MSE 3.764924981606173 Test RE 0.9274408562228691\n",
      "99 Train Loss 5.9334207 Test MSE 3.7313809614088727 Test RE 0.9233000433106823\n",
      "Training time: 66.50\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.47006 Test MSE 8.649049843254994 Test RE 1.4056987551273872\n",
      "1 Train Loss 56.168816 Test MSE 8.501623033239632 Test RE 1.3936668898450548\n",
      "2 Train Loss 55.117496 Test MSE 8.434942788405317 Test RE 1.3881907010466128\n",
      "3 Train Loss 50.046684 Test MSE 8.807092035075785 Test RE 1.418483628324946\n",
      "4 Train Loss 45.261154 Test MSE 8.57367638881028 Test RE 1.3995602648402958\n",
      "5 Train Loss 43.83882 Test MSE 8.690814431847755 Test RE 1.4090885915223594\n",
      "6 Train Loss 43.466454 Test MSE 8.681313864759074 Test RE 1.4083181918423138\n",
      "7 Train Loss 42.918964 Test MSE 8.547378556041046 Test RE 1.3974121975133744\n",
      "8 Train Loss 42.78111 Test MSE 8.473605471124472 Test RE 1.3913685420988517\n",
      "9 Train Loss 42.74787 Test MSE 8.448756257592352 Test RE 1.3893269200822607\n",
      "10 Train Loss 42.60418 Test MSE 8.262412964386549 Test RE 1.3739202011140061\n",
      "11 Train Loss 42.50659 Test MSE 8.443425243017124 Test RE 1.388888530658453\n",
      "12 Train Loss 42.31791 Test MSE 8.411931685000747 Test RE 1.386295868055038\n",
      "13 Train Loss 42.11387 Test MSE 8.236801428310777 Test RE 1.3717891337076875\n",
      "14 Train Loss 42.060036 Test MSE 8.315064926805366 Test RE 1.3782908804428586\n",
      "15 Train Loss 41.747097 Test MSE 8.36309689840028 Test RE 1.3822659967007498\n",
      "16 Train Loss 41.65525 Test MSE 8.358402555366723 Test RE 1.381877997992955\n",
      "17 Train Loss 41.13543 Test MSE 8.54171073039965 Test RE 1.3969488038501743\n",
      "18 Train Loss 40.76719 Test MSE 8.779920013635323 Test RE 1.4162937544118617\n",
      "19 Train Loss 40.48171 Test MSE 8.867513874515447 Test RE 1.4233411278835868\n",
      "20 Train Loss 40.14068 Test MSE 8.941333762160815 Test RE 1.429253332631994\n",
      "21 Train Loss 39.95862 Test MSE 8.838028967465567 Test RE 1.4209728189524569\n",
      "22 Train Loss 39.569733 Test MSE 8.80707046199701 Test RE 1.418481891027455\n",
      "23 Train Loss 39.263 Test MSE 8.827655869901232 Test RE 1.4201386840286414\n",
      "24 Train Loss 38.11286 Test MSE 8.585889106564029 Test RE 1.4005567073958818\n",
      "25 Train Loss 37.31279 Test MSE 8.732544780231686 Test RE 1.4124675234231059\n",
      "26 Train Loss 35.572384 Test MSE 8.90704384264471 Test RE 1.426510114416809\n",
      "27 Train Loss 34.70117 Test MSE 9.423127482787512 Test RE 1.4672549845858904\n",
      "28 Train Loss 33.475845 Test MSE 8.9156335596945 Test RE 1.427197792938308\n",
      "29 Train Loss 33.10708 Test MSE 8.770963692656723 Test RE 1.4155711955499963\n",
      "30 Train Loss 32.849323 Test MSE 8.735522762502484 Test RE 1.4127083435276826\n",
      "31 Train Loss 32.54581 Test MSE 8.815740993368177 Test RE 1.4191799645922551\n",
      "32 Train Loss 32.28535 Test MSE 8.67138570188192 Test RE 1.4075126679066705\n",
      "33 Train Loss 31.986828 Test MSE 8.233585894708575 Test RE 1.3715213437968392\n",
      "34 Train Loss 31.737083 Test MSE 7.932857940706527 Test RE 1.3462412663180938\n",
      "35 Train Loss 31.446077 Test MSE 8.062527214009497 Test RE 1.3571993939923466\n",
      "36 Train Loss 31.206207 Test MSE 8.083674517678173 Test RE 1.3589781360343867\n",
      "37 Train Loss 30.863773 Test MSE 8.085825076999601 Test RE 1.359158893481992\n",
      "38 Train Loss 30.639297 Test MSE 8.063400566387038 Test RE 1.3572728995563472\n",
      "39 Train Loss 30.416912 Test MSE 7.927611427377016 Test RE 1.3457960143669934\n",
      "40 Train Loss 29.80307 Test MSE 8.514342588707155 Test RE 1.3947090554277384\n",
      "41 Train Loss 29.438368 Test MSE 8.838162876473147 Test RE 1.4209835838152975\n",
      "42 Train Loss 28.929565 Test MSE 8.67595991429602 Test RE 1.4078838550102926\n",
      "43 Train Loss 28.56157 Test MSE 8.62484887658067 Test RE 1.403730729732439\n",
      "44 Train Loss 28.082716 Test MSE 8.979415837487872 Test RE 1.4322937683757948\n",
      "45 Train Loss 27.73161 Test MSE 9.094951177829955 Test RE 1.4414787561022524\n",
      "46 Train Loss 27.309765 Test MSE 8.907045220160509 Test RE 1.4265102247250203\n",
      "47 Train Loss 26.981264 Test MSE 8.967779635037012 Test RE 1.4313654305265298\n",
      "48 Train Loss 26.66568 Test MSE 8.724774088040956 Test RE 1.4118389384319023\n",
      "49 Train Loss 26.440897 Test MSE 8.80629082985172 Test RE 1.4184191051919153\n",
      "50 Train Loss 26.240057 Test MSE 8.852718102326394 Test RE 1.4221531837022576\n",
      "51 Train Loss 25.926285 Test MSE 8.831340470519727 Test RE 1.4204350309891194\n",
      "52 Train Loss 25.648098 Test MSE 8.787587815180041 Test RE 1.4169120680972387\n",
      "53 Train Loss 25.455334 Test MSE 8.823683050629926 Test RE 1.4198190867687623\n",
      "54 Train Loss 24.973946 Test MSE 8.796406923830641 Test RE 1.417622887046129\n",
      "55 Train Loss 23.923008 Test MSE 8.564648764151958 Test RE 1.3988232395634757\n",
      "56 Train Loss 22.810923 Test MSE 7.625269502691477 Test RE 1.3198836805344099\n",
      "57 Train Loss 20.45437 Test MSE 6.934340918576375 Test RE 1.2586664466373205\n",
      "58 Train Loss 17.797037 Test MSE 6.332168710845526 Test RE 1.202774740800891\n",
      "59 Train Loss 16.40904 Test MSE 6.400531224723309 Test RE 1.2092499290619216\n",
      "60 Train Loss 15.536321 Test MSE 6.562310102260145 Test RE 1.2244369724515431\n",
      "61 Train Loss 14.501779 Test MSE 6.474933091293912 Test RE 1.2162579801083655\n",
      "62 Train Loss 13.95122 Test MSE 6.225590445139442 Test RE 1.1926096901504772\n",
      "63 Train Loss 13.3246 Test MSE 6.283072440297685 Test RE 1.1981028292748892\n",
      "64 Train Loss 12.94962 Test MSE 6.410634377018155 Test RE 1.2102039450945548\n",
      "65 Train Loss 12.6491165 Test MSE 6.601022261384073 Test RE 1.2280432404889277\n",
      "66 Train Loss 12.218395 Test MSE 6.64409305047738 Test RE 1.2320431355093855\n",
      "67 Train Loss 11.693235 Test MSE 6.521176489905999 Test RE 1.2205934563647005\n",
      "68 Train Loss 11.427319 Test MSE 6.4978446554353955 Test RE 1.218407945563223\n",
      "69 Train Loss 10.91144 Test MSE 6.700970729447271 Test RE 1.2373054353166695\n",
      "70 Train Loss 10.527613 Test MSE 6.623848210873807 Test RE 1.230164659041069\n",
      "71 Train Loss 10.084642 Test MSE 6.585033394131569 Test RE 1.226555067605482\n",
      "72 Train Loss 9.679676 Test MSE 6.484152155983871 Test RE 1.2171235313405575\n",
      "73 Train Loss 9.335314 Test MSE 6.3095951128428975 Test RE 1.2006289361313602\n",
      "74 Train Loss 8.848259 Test MSE 6.371078591948201 Test RE 1.206464483644187\n",
      "75 Train Loss 8.511822 Test MSE 6.447320738025704 Test RE 1.2136618431631827\n",
      "76 Train Loss 8.291458 Test MSE 6.434651986350783 Test RE 1.2124688560544272\n",
      "77 Train Loss 8.158081 Test MSE 6.466117899179057 Test RE 1.2154297708234252\n",
      "78 Train Loss 8.0108185 Test MSE 6.366839358645347 Test RE 1.206063033920638\n",
      "79 Train Loss 7.814847 Test MSE 6.410416626105257 Test RE 1.2101833913368332\n",
      "80 Train Loss 7.71703 Test MSE 6.4827774062032795 Test RE 1.216994499127431\n",
      "81 Train Loss 7.564051 Test MSE 6.429563172447452 Test RE 1.211989323614123\n",
      "82 Train Loss 7.504041 Test MSE 6.434322279728066 Test RE 1.2124377926703085\n",
      "83 Train Loss 7.3967714 Test MSE 6.494891610829002 Test RE 1.2181310520632438\n",
      "84 Train Loss 7.2927327 Test MSE 6.515499883359488 Test RE 1.2200620846606713\n",
      "85 Train Loss 7.2416344 Test MSE 6.54893900961018 Test RE 1.223188905215048\n",
      "86 Train Loss 7.1579523 Test MSE 6.61554205693036 Test RE 1.2293931179381385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 7.0920234 Test MSE 6.616724651011715 Test RE 1.2295029961646435\n",
      "88 Train Loss 7.0343084 Test MSE 6.630128484806205 Test RE 1.230747699322357\n",
      "89 Train Loss 6.977806 Test MSE 6.622804796091974 Test RE 1.2300677650226082\n",
      "90 Train Loss 6.8590117 Test MSE 6.560157830710828 Test RE 1.224236163823656\n",
      "91 Train Loss 6.8241134 Test MSE 6.554374892250807 Test RE 1.2236964478980088\n",
      "92 Train Loss 6.778221 Test MSE 6.571684769414808 Test RE 1.225311252416257\n",
      "93 Train Loss 6.7261624 Test MSE 6.593210897000526 Test RE 1.2273164187615315\n",
      "94 Train Loss 6.6737285 Test MSE 6.640099794324609 Test RE 1.2316728364140335\n",
      "95 Train Loss 6.6324396 Test MSE 6.665302916374518 Test RE 1.2340080875280248\n",
      "96 Train Loss 6.5890293 Test MSE 6.652517728828356 Test RE 1.2328240004691577\n",
      "97 Train Loss 6.53466 Test MSE 6.6663427837625875 Test RE 1.2341043438225991\n",
      "98 Train Loss 6.505369 Test MSE 6.651122110310735 Test RE 1.2326946778336216\n",
      "99 Train Loss 6.4693327 Test MSE 6.6602811619810325 Test RE 1.2335431384279634\n",
      "Training time: 65.97\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.473057 Test MSE 8.44573971536366 Test RE 1.3890788754382877\n",
      "1 Train Loss 56.645714 Test MSE 8.70020849232757 Test RE 1.4098499406709248\n",
      "2 Train Loss 52.48684 Test MSE 8.064237459839859 Test RE 1.3573433328259201\n",
      "3 Train Loss 48.852844 Test MSE 7.980584740333156 Test RE 1.3502849184961487\n",
      "4 Train Loss 44.388367 Test MSE 8.343577620557072 Test RE 1.3806519656825227\n",
      "5 Train Loss 44.122185 Test MSE 8.318927175754313 Test RE 1.3786109431568605\n",
      "6 Train Loss 43.902935 Test MSE 8.276164350241245 Test RE 1.3750630544341442\n",
      "7 Train Loss 43.773193 Test MSE 8.36043649807632 Test RE 1.3820461216083502\n",
      "8 Train Loss 43.62851 Test MSE 8.390627304282143 Test RE 1.3845392621034072\n",
      "9 Train Loss 43.47271 Test MSE 8.226599465430734 Test RE 1.3709393330840185\n",
      "10 Train Loss 42.788147 Test MSE 8.352879181917311 Test RE 1.3814213383888587\n",
      "11 Train Loss 42.27896 Test MSE 8.18007910946328 Test RE 1.3670575953155004\n",
      "12 Train Loss 41.613647 Test MSE 8.290731807716371 Test RE 1.3762726948487602\n",
      "13 Train Loss 40.66834 Test MSE 8.575895665276587 Test RE 1.399741389602191\n",
      "14 Train Loss 39.49217 Test MSE 8.5913825827154 Test RE 1.401004692134287\n",
      "15 Train Loss 38.62433 Test MSE 8.464988193074866 Test RE 1.3906608823273594\n",
      "16 Train Loss 37.111107 Test MSE 8.122639008005132 Test RE 1.362249435162273\n",
      "17 Train Loss 36.37263 Test MSE 7.956745113781021 Test RE 1.3482666225348694\n",
      "18 Train Loss 35.81279 Test MSE 7.871215223240013 Test RE 1.3410005440060684\n",
      "19 Train Loss 34.808655 Test MSE 7.556077423124122 Test RE 1.3138816884104465\n",
      "20 Train Loss 32.901096 Test MSE 7.317824665448391 Test RE 1.293001593435238\n",
      "21 Train Loss 31.873638 Test MSE 7.156174837776734 Test RE 1.278640721700988\n",
      "22 Train Loss 29.441317 Test MSE 6.736772729536418 Test RE 1.2406063748141107\n",
      "23 Train Loss 26.939201 Test MSE 6.751205095252242 Test RE 1.2419345557072992\n",
      "24 Train Loss 24.988781 Test MSE 6.263817475643175 Test RE 1.1962655808985392\n",
      "25 Train Loss 22.067392 Test MSE 6.530285945644698 Test RE 1.2214456846221124\n",
      "26 Train Loss 17.062458 Test MSE 4.182922226830192 Test RE 0.977570202263493\n",
      "27 Train Loss 13.5366535 Test MSE 3.6007057895559766 Test RE 0.9069887051842904\n",
      "28 Train Loss 11.039966 Test MSE 2.3556643306042 Test RE 0.7336091901487315\n",
      "29 Train Loss 9.5395775 Test MSE 2.207050173741079 Test RE 0.710091253697945\n",
      "30 Train Loss 8.636527 Test MSE 2.1247268516021753 Test RE 0.6967221431904123\n",
      "31 Train Loss 7.5727563 Test MSE 1.9260100082115845 Test RE 0.6633417467516528\n",
      "32 Train Loss 7.1011972 Test MSE 1.8354277524167926 Test RE 0.6475550690031954\n",
      "33 Train Loss 6.7091427 Test MSE 1.8531372627116163 Test RE 0.6506716049797705\n",
      "34 Train Loss 6.5039444 Test MSE 1.8820507396439976 Test RE 0.6557279931019606\n",
      "35 Train Loss 6.14581 Test MSE 1.9813698860656437 Test RE 0.6728075236646572\n",
      "36 Train Loss 5.9612703 Test MSE 2.049102402017741 Test RE 0.68421074708748\n",
      "37 Train Loss 5.679963 Test MSE 1.9946259876365071 Test RE 0.6750544380589927\n",
      "38 Train Loss 5.5370684 Test MSE 2.039726006079678 Test RE 0.6826435275274692\n",
      "39 Train Loss 5.3520284 Test MSE 2.018459659224129 Test RE 0.6790755550966942\n",
      "40 Train Loss 5.2609587 Test MSE 1.9970515194478538 Test RE 0.6754647577263224\n",
      "41 Train Loss 5.195679 Test MSE 1.998181190672248 Test RE 0.6756557756379789\n",
      "42 Train Loss 5.142477 Test MSE 2.0102206368278943 Test RE 0.6776882002021606\n",
      "43 Train Loss 5.053164 Test MSE 2.0380880152788885 Test RE 0.6823693759039205\n",
      "44 Train Loss 5.0207825 Test MSE 2.029339871424183 Test RE 0.6809033241609391\n",
      "45 Train Loss 4.9822593 Test MSE 2.036927074626474 Test RE 0.6821750017682109\n",
      "46 Train Loss 4.939918 Test MSE 2.0439430402796317 Test RE 0.6833488292984897\n",
      "47 Train Loss 4.909915 Test MSE 2.0580669459412158 Test RE 0.6857057781475419\n",
      "48 Train Loss 4.883415 Test MSE 2.0775873601214325 Test RE 0.6889500047812894\n",
      "49 Train Loss 4.8476086 Test MSE 2.0868876290409117 Test RE 0.6904903168228587\n",
      "50 Train Loss 4.8134546 Test MSE 2.089346672820619 Test RE 0.6908970100256767\n",
      "51 Train Loss 4.797539 Test MSE 2.1013843781666686 Test RE 0.6928844422354258\n",
      "52 Train Loss 4.7712765 Test MSE 2.122763163268344 Test RE 0.6964001108778567\n",
      "53 Train Loss 4.747946 Test MSE 2.111101118511929 Test RE 0.694484533445467\n",
      "54 Train Loss 4.7027383 Test MSE 2.0887219021920718 Test RE 0.6907937039447505\n",
      "55 Train Loss 4.66729 Test MSE 2.0985982031074224 Test RE 0.6924249504602559\n",
      "56 Train Loss 4.5921626 Test MSE 2.063065935436628 Test RE 0.686538053546155\n",
      "57 Train Loss 3.9902148 Test MSE 1.823643741789847 Test RE 0.645472970349337\n",
      "58 Train Loss 2.200857 Test MSE 1.349170855907817 Test RE 0.5551898732072288\n",
      "59 Train Loss 1.7934049 Test MSE 1.1630847984773276 Test RE 0.5154822910303231\n",
      "60 Train Loss 1.3261869 Test MSE 0.8470864351562349 Test RE 0.439918194121376\n",
      "61 Train Loss 0.81985056 Test MSE 0.44508421966251516 Test RE 0.3188813784117092\n",
      "62 Train Loss 0.652336 Test MSE 0.2923852744948042 Test RE 0.2584555178129826\n",
      "63 Train Loss 0.50267625 Test MSE 0.22660301238760547 Test RE 0.2275311698504404\n",
      "64 Train Loss 0.43779054 Test MSE 0.19603722361627124 Test RE 0.21163004869371826\n",
      "65 Train Loss 0.3726782 Test MSE 0.11950265425420845 Test RE 0.16523301823818096\n",
      "66 Train Loss 0.32048675 Test MSE 0.09150799425891164 Test RE 0.14458977383604874\n",
      "67 Train Loss 0.2714418 Test MSE 0.07542928042928897 Test RE 0.13127379565611422\n",
      "68 Train Loss 0.23702236 Test MSE 0.06390457014170751 Test RE 0.12082978959143742\n",
      "69 Train Loss 0.21752734 Test MSE 0.06120104444199825 Test RE 0.11824627737054724\n",
      "70 Train Loss 0.19734393 Test MSE 0.0593717821673696 Test RE 0.11646571653902273\n",
      "71 Train Loss 0.17124283 Test MSE 0.03499119360989693 Test RE 0.08941027670220672\n",
      "72 Train Loss 0.1521601 Test MSE 0.02624751971135782 Test RE 0.07743765545294173\n",
      "73 Train Loss 0.12893194 Test MSE 0.02112771579996563 Test RE 0.06947592432293656\n",
      "74 Train Loss 0.11626992 Test MSE 0.017114335065360933 Test RE 0.06252994914426241\n",
      "75 Train Loss 0.108464934 Test MSE 0.013983258689464512 Test RE 0.056521314864152586\n",
      "76 Train Loss 0.09911906 Test MSE 0.010244637077244398 Test RE 0.04837894006956698\n",
      "77 Train Loss 0.094413355 Test MSE 0.008546307088734271 Test RE 0.04418728390595667\n",
      "78 Train Loss 0.089806736 Test MSE 0.008302770923644133 Test RE 0.043553151719268934\n",
      "79 Train Loss 0.08432579 Test MSE 0.00835900395682959 Test RE 0.04370039129569684\n",
      "80 Train Loss 0.0767988 Test MSE 0.008348276706674927 Test RE 0.043672341570621026\n",
      "81 Train Loss 0.07442414 Test MSE 0.007780729495200788 Test RE 0.04216171019379841\n",
      "82 Train Loss 0.071251646 Test MSE 0.007572349267664091 Test RE 0.04159330003328273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 Train Loss 0.066463284 Test MSE 0.007227066444831595 Test RE 0.04063395394938121\n",
      "84 Train Loss 0.06307492 Test MSE 0.006504398603460528 Test RE 0.03854886843066595\n",
      "85 Train Loss 0.061498147 Test MSE 0.006086880980271611 Test RE 0.037291123269132004\n",
      "86 Train Loss 0.059453852 Test MSE 0.005771080822710629 Test RE 0.036310868655746634\n",
      "87 Train Loss 0.055737466 Test MSE 0.004884540941288978 Test RE 0.03340565082784326\n",
      "88 Train Loss 0.0534335 Test MSE 0.0044836442095540635 Test RE 0.03200542743800077\n",
      "89 Train Loss 0.051519863 Test MSE 0.00412548737246367 Test RE 0.030700517158683004\n",
      "90 Train Loss 0.049302123 Test MSE 0.003628714754071388 Test RE 0.028792838120015884\n",
      "91 Train Loss 0.046795726 Test MSE 0.004134073308396281 Test RE 0.030732447406596933\n",
      "92 Train Loss 0.043943908 Test MSE 0.00412825085711352 Test RE 0.03071079790823855\n",
      "93 Train Loss 0.041965377 Test MSE 0.0037040221112175998 Test RE 0.029090075308542126\n",
      "94 Train Loss 0.039973386 Test MSE 0.003885687989246003 Test RE 0.029794906215419564\n",
      "95 Train Loss 0.0386193 Test MSE 0.003786662203418082 Test RE 0.02941279815832854\n",
      "96 Train Loss 0.036740758 Test MSE 0.004150361635496145 Test RE 0.03079293110073876\n",
      "97 Train Loss 0.03537953 Test MSE 0.0042001755105116004 Test RE 0.03097717287825125\n",
      "98 Train Loss 0.032992635 Test MSE 0.004234381976569437 Test RE 0.031103057016908554\n",
      "99 Train Loss 0.031298496 Test MSE 0.004560185545350351 Test RE 0.03227745743648148\n",
      "Training time: 65.92\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.86796 Test MSE 8.61854169499873 Test RE 1.4032173755892963\n",
      "1 Train Loss 57.311775 Test MSE 8.309571475032067 Test RE 1.3778355126540867\n",
      "2 Train Loss 55.790955 Test MSE 8.590092880547733 Test RE 1.4008995317258013\n",
      "3 Train Loss 49.476345 Test MSE 8.850944454009124 Test RE 1.4220107118689853\n",
      "4 Train Loss 48.218727 Test MSE 8.767506243993065 Test RE 1.4152921642299683\n",
      "5 Train Loss 46.752953 Test MSE 8.651474901992154 Test RE 1.4058958093236542\n",
      "6 Train Loss 45.7975 Test MSE 8.664113233750085 Test RE 1.4069223217692997\n",
      "7 Train Loss 45.73076 Test MSE 8.71919405945983 Test RE 1.4113873873897642\n",
      "8 Train Loss 45.165085 Test MSE 8.675095098801606 Test RE 1.4078136846702298\n",
      "9 Train Loss 44.57189 Test MSE 8.443348685879958 Test RE 1.3888822340686386\n",
      "10 Train Loss 44.299965 Test MSE 8.433966754318565 Test RE 1.3881103827400778\n",
      "11 Train Loss 44.180725 Test MSE 8.441503982677206 Test RE 1.388730504254045\n",
      "12 Train Loss 43.992207 Test MSE 8.484124108861858 Test RE 1.3922318559897646\n",
      "13 Train Loss 43.780235 Test MSE 8.398938671391775 Test RE 1.385224822634245\n",
      "14 Train Loss 43.72564 Test MSE 8.40856102935012 Test RE 1.3860180962922912\n",
      "15 Train Loss 43.626297 Test MSE 8.449066533358474 Test RE 1.3893524309683432\n",
      "16 Train Loss 43.5588 Test MSE 8.447217028772654 Test RE 1.3892003576996546\n",
      "17 Train Loss 43.335022 Test MSE 8.576465615189312 Test RE 1.399787901900111\n",
      "18 Train Loss 43.190933 Test MSE 8.566905207425789 Test RE 1.3990074944880153\n",
      "19 Train Loss 43.0335 Test MSE 8.597676037855441 Test RE 1.401517737966907\n",
      "20 Train Loss 42.90323 Test MSE 8.64324966307219 Test RE 1.405227334936697\n",
      "21 Train Loss 42.531387 Test MSE 8.74259367806625 Test RE 1.4132799819453337\n",
      "22 Train Loss 42.157997 Test MSE 8.815381028559662 Test RE 1.4191509902803108\n",
      "23 Train Loss 41.52047 Test MSE 8.845548356462412 Test RE 1.421577171784974\n",
      "24 Train Loss 40.993797 Test MSE 9.229748835956157 Test RE 1.4521216543571802\n",
      "25 Train Loss 40.515747 Test MSE 9.250654204381442 Test RE 1.4537652509730086\n",
      "26 Train Loss 39.938774 Test MSE 9.215835035873681 Test RE 1.4510267084894584\n",
      "27 Train Loss 36.770462 Test MSE 8.533662845908243 Test RE 1.396290555617133\n",
      "28 Train Loss 34.618378 Test MSE 8.94666788993439 Test RE 1.4296795936017832\n",
      "29 Train Loss 33.06298 Test MSE 8.60911412792292 Test RE 1.4024496966674447\n",
      "30 Train Loss 32.118446 Test MSE 8.390370037028804 Test RE 1.384518036077593\n",
      "31 Train Loss 31.806068 Test MSE 8.116700330449088 Test RE 1.3617513556972458\n",
      "32 Train Loss 31.56424 Test MSE 8.164315231864613 Test RE 1.3657397278062364\n",
      "33 Train Loss 31.44546 Test MSE 8.113316634249067 Test RE 1.3614674821389625\n",
      "34 Train Loss 31.052385 Test MSE 7.993844372550057 Test RE 1.3514061928909333\n",
      "35 Train Loss 30.481056 Test MSE 7.862772494127135 Test RE 1.340281167036994\n",
      "36 Train Loss 29.890537 Test MSE 7.936661693452134 Test RE 1.3465639845146582\n",
      "37 Train Loss 28.704897 Test MSE 7.871757821822363 Test RE 1.341046763835808\n",
      "38 Train Loss 27.53973 Test MSE 7.7437998403044634 Test RE 1.3301025306174385\n",
      "39 Train Loss 26.823088 Test MSE 7.745110135254348 Test RE 1.3302150563119832\n",
      "40 Train Loss 25.48368 Test MSE 7.516279397533398 Test RE 1.3104169983960636\n",
      "41 Train Loss 23.78257 Test MSE 7.651051977074344 Test RE 1.3221131853635786\n",
      "42 Train Loss 22.734936 Test MSE 7.661079778253999 Test RE 1.3229793111560124\n",
      "43 Train Loss 21.640905 Test MSE 7.685863789241159 Test RE 1.3251175383513798\n",
      "44 Train Loss 20.80052 Test MSE 7.823704747293901 Test RE 1.3369472940355935\n",
      "45 Train Loss 19.978365 Test MSE 7.849892300077697 Test RE 1.3391829439173861\n",
      "46 Train Loss 19.241283 Test MSE 8.079999321728735 Test RE 1.3586691751317372\n",
      "47 Train Loss 18.692268 Test MSE 8.121085552054948 Test RE 1.3621191637271575\n",
      "48 Train Loss 18.184376 Test MSE 8.094769136002338 Test RE 1.3599103961059429\n",
      "49 Train Loss 17.712296 Test MSE 7.981635407578339 Test RE 1.3503738000437269\n",
      "50 Train Loss 17.376827 Test MSE 8.030361808742372 Test RE 1.354489418902909\n",
      "51 Train Loss 17.01605 Test MSE 7.933143035058648 Test RE 1.3462654569903711\n",
      "52 Train Loss 16.707308 Test MSE 7.855244048697147 Test RE 1.3396393673352989\n",
      "53 Train Loss 16.425829 Test MSE 7.9711961569711 Test RE 1.3494904282677482\n",
      "54 Train Loss 16.061935 Test MSE 8.051765596434397 Test RE 1.3562933171806013\n",
      "55 Train Loss 15.8615 Test MSE 8.178832288957764 Test RE 1.3669534068123148\n",
      "56 Train Loss 15.492802 Test MSE 8.211973006410101 Test RE 1.3697200620574415\n",
      "57 Train Loss 15.304719 Test MSE 8.240555642404559 Test RE 1.3721017188449742\n",
      "58 Train Loss 15.0055065 Test MSE 8.2799970224456 Test RE 1.3753814118105718\n",
      "59 Train Loss 14.818794 Test MSE 8.386485981523112 Test RE 1.3841975396416766\n",
      "60 Train Loss 14.584777 Test MSE 8.419562561360621 Test RE 1.3869245140514128\n",
      "61 Train Loss 14.436419 Test MSE 8.439720447264065 Test RE 1.3885837898249085\n",
      "62 Train Loss 14.307705 Test MSE 8.542230910067797 Test RE 1.3969913394338085\n",
      "63 Train Loss 13.99893 Test MSE 8.786714992822882 Test RE 1.4168416993414634\n",
      "64 Train Loss 13.755064 Test MSE 8.848823417812673 Test RE 1.4218403166684896\n",
      "65 Train Loss 13.370493 Test MSE 8.997765396619512 Test RE 1.4337564774477325\n",
      "66 Train Loss 13.181453 Test MSE 8.909044078182486 Test RE 1.4266702795681907\n",
      "67 Train Loss 12.880966 Test MSE 8.715829239161305 Test RE 1.4111150271714001\n",
      "68 Train Loss 12.525169 Test MSE 8.416004932618199 Test RE 1.3866314653441238\n",
      "69 Train Loss 12.238081 Test MSE 8.23620636242518 Test RE 1.3717395805123858\n",
      "70 Train Loss 11.284892 Test MSE 7.812904139538123 Test RE 1.3360241488782996\n",
      "71 Train Loss 10.44227 Test MSE 7.663544014974877 Test RE 1.3231920665491892\n",
      "72 Train Loss 9.9847145 Test MSE 7.520485614066053 Test RE 1.3107836110799136\n",
      "73 Train Loss 9.637787 Test MSE 7.359203250847019 Test RE 1.2966520742744774\n",
      "74 Train Loss 9.2155285 Test MSE 7.3576830049464075 Test RE 1.2965181377770942\n",
      "75 Train Loss 9.060505 Test MSE 7.6099992938822005 Test RE 1.3185614321888202\n",
      "76 Train Loss 8.93891 Test MSE 7.585492678422229 Test RE 1.3164366268098\n",
      "77 Train Loss 8.719538 Test MSE 7.425262639117496 Test RE 1.3024587272789747\n",
      "78 Train Loss 8.59864 Test MSE 7.406938979181 Test RE 1.3008506661339456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Train Loss 8.467379 Test MSE 7.345577761394401 Test RE 1.2954511491235965\n",
      "80 Train Loss 8.325693 Test MSE 7.314555902943151 Test RE 1.2927127789714628\n",
      "81 Train Loss 8.189404 Test MSE 7.401536866232131 Test RE 1.3003762040092697\n",
      "82 Train Loss 8.090502 Test MSE 7.277012931019531 Test RE 1.2893909973619557\n",
      "83 Train Loss 7.9111557 Test MSE 7.159639037497099 Test RE 1.2789501699048558\n",
      "84 Train Loss 7.758854 Test MSE 7.053303953266679 Test RE 1.2694171461866555\n",
      "85 Train Loss 7.5412865 Test MSE 6.9897875951826025 Test RE 1.2636885475153155\n",
      "86 Train Loss 7.2733393 Test MSE 6.9628924005841935 Test RE 1.2612550038782968\n",
      "87 Train Loss 7.1166544 Test MSE 6.962947793581473 Test RE 1.261260020798854\n",
      "88 Train Loss 6.82311 Test MSE 6.80242860411946 Test RE 1.2466371259410818\n",
      "89 Train Loss 6.6361055 Test MSE 6.739819002170577 Test RE 1.2408868353751006\n",
      "90 Train Loss 6.4386053 Test MSE 6.580138636359929 Test RE 1.2260991241300303\n",
      "91 Train Loss 6.2141466 Test MSE 6.425508664476958 Test RE 1.2116071207190384\n",
      "92 Train Loss 5.94816 Test MSE 6.3556338293332555 Test RE 1.2050012412860758\n",
      "93 Train Loss 5.6243424 Test MSE 6.099080237627475 Test RE 1.1804299874116786\n",
      "94 Train Loss 5.442689 Test MSE 5.995874336667627 Test RE 1.1704000222637536\n",
      "95 Train Loss 4.9083776 Test MSE 5.521416832524749 Test RE 1.1231385338129547\n",
      "96 Train Loss 4.671574 Test MSE 5.645553172571002 Test RE 1.1356939476841992\n",
      "97 Train Loss 4.2860847 Test MSE 5.531526291292313 Test RE 1.1241662709395641\n",
      "98 Train Loss 3.982515 Test MSE 5.446317596044333 Test RE 1.1154742308017795\n",
      "99 Train Loss 3.4993842 Test MSE 5.4351953185666355 Test RE 1.1143346576628281\n",
      "Training time: 67.22\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.027367 Test MSE 8.491433009094498 Test RE 1.392831416593368\n",
      "1 Train Loss 58.655575 Test MSE 8.701247182823172 Test RE 1.4099340969316645\n",
      "2 Train Loss 58.273857 Test MSE 8.671330056980604 Test RE 1.4075081518447716\n",
      "3 Train Loss 57.20144 Test MSE 7.795887898455579 Test RE 1.3345684481150648\n",
      "4 Train Loss 48.95102 Test MSE 8.850346322060457 Test RE 1.421962662510371\n",
      "5 Train Loss 47.731308 Test MSE 8.647857878706334 Test RE 1.4056018889487265\n",
      "6 Train Loss 46.402893 Test MSE 8.472824312091534 Test RE 1.3913044073477823\n",
      "7 Train Loss 46.024742 Test MSE 8.54316917753341 Test RE 1.397068059177544\n",
      "8 Train Loss 45.774376 Test MSE 8.449876671566718 Test RE 1.3894190383565475\n",
      "9 Train Loss 45.70333 Test MSE 8.330990749516323 Test RE 1.3796101675475496\n",
      "10 Train Loss 45.492455 Test MSE 8.423135257029609 Test RE 1.387218741550261\n",
      "11 Train Loss 45.28068 Test MSE 8.338780467244014 Test RE 1.3802550045867479\n",
      "12 Train Loss 43.230156 Test MSE 7.68099483428693 Test RE 1.324697744303417\n",
      "13 Train Loss 41.305183 Test MSE 7.808350583441348 Test RE 1.335634757975393\n",
      "14 Train Loss 41.035294 Test MSE 7.842404490545649 Test RE 1.3385440855213182\n",
      "15 Train Loss 40.709877 Test MSE 7.879286208060948 Test RE 1.341687885266528\n",
      "16 Train Loss 40.683575 Test MSE 7.89816387540504 Test RE 1.3432941719596783\n",
      "17 Train Loss 40.579205 Test MSE 8.004153863337827 Test RE 1.3522773519910238\n",
      "18 Train Loss 40.24123 Test MSE 7.856586123338031 Test RE 1.3397538016689272\n",
      "19 Train Loss 40.219505 Test MSE 7.8535323933630705 Test RE 1.33949340587444\n",
      "20 Train Loss 40.094017 Test MSE 7.845043058586594 Test RE 1.3387692423994688\n",
      "21 Train Loss 39.940037 Test MSE 7.834408082792056 Test RE 1.3378614967730644\n",
      "22 Train Loss 39.858345 Test MSE 7.772108251211757 Test RE 1.3325314893420488\n",
      "23 Train Loss 39.80277 Test MSE 7.742612306496824 Test RE 1.3300005391974148\n",
      "24 Train Loss 39.487267 Test MSE 7.915948493723225 Test RE 1.3448056967346937\n",
      "25 Train Loss 39.303688 Test MSE 7.70532295365364 Test RE 1.3267939523663972\n",
      "26 Train Loss 38.625824 Test MSE 7.646576919612767 Test RE 1.3217264805102642\n",
      "27 Train Loss 36.039074 Test MSE 7.722002338393838 Test RE 1.3282292032867589\n",
      "28 Train Loss 35.02301 Test MSE 7.462936272791036 Test RE 1.3057586961209395\n",
      "29 Train Loss 34.29903 Test MSE 7.653745482537731 Test RE 1.3223458857645392\n",
      "30 Train Loss 33.734173 Test MSE 7.512911400332713 Test RE 1.310123370719864\n",
      "31 Train Loss 33.289715 Test MSE 7.617206875447748 Test RE 1.3191857022773188\n",
      "32 Train Loss 32.473328 Test MSE 7.653039720683066 Test RE 1.3222849167394861\n",
      "33 Train Loss 31.978096 Test MSE 7.699280751765758 Test RE 1.326273641329956\n",
      "34 Train Loss 31.600239 Test MSE 7.787433546112326 Test RE 1.333844606734288\n",
      "35 Train Loss 31.233643 Test MSE 7.7077305372213365 Test RE 1.3270012193330036\n",
      "36 Train Loss 30.813602 Test MSE 7.778461965625027 Test RE 1.3330760516804137\n",
      "37 Train Loss 30.497814 Test MSE 7.6756323177003845 Test RE 1.3242352421091286\n",
      "38 Train Loss 30.069784 Test MSE 7.2392895765227445 Test RE 1.286044613717935\n",
      "39 Train Loss 29.691238 Test MSE 7.215564586000983 Test RE 1.2839355368952692\n",
      "40 Train Loss 28.792974 Test MSE 6.453784640541567 Test RE 1.2142700823723915\n",
      "41 Train Loss 25.232643 Test MSE 5.822735025139184 Test RE 1.1533777625948516\n",
      "42 Train Loss 22.741278 Test MSE 5.489469626145989 Test RE 1.1198845509261413\n",
      "43 Train Loss 21.51133 Test MSE 5.349192734808051 Test RE 1.1054832924472309\n",
      "44 Train Loss 20.453033 Test MSE 5.428310620926399 Test RE 1.1136286767605015\n",
      "45 Train Loss 20.154266 Test MSE 5.345858993215637 Test RE 1.1051387572809361\n",
      "46 Train Loss 19.700298 Test MSE 5.342484923909783 Test RE 1.1047899449276928\n",
      "47 Train Loss 19.553614 Test MSE 5.370342703537049 Test RE 1.1076666005230513\n",
      "48 Train Loss 19.498375 Test MSE 5.4399565090924105 Test RE 1.114822625243079\n",
      "49 Train Loss 19.372028 Test MSE 5.448700175775882 Test RE 1.1157181952461879\n",
      "50 Train Loss 19.259926 Test MSE 5.436081039329943 Test RE 1.1144254500887658\n",
      "51 Train Loss 19.181877 Test MSE 5.479730914154057 Test RE 1.1188907322830175\n",
      "52 Train Loss 19.120152 Test MSE 5.424048164401715 Test RE 1.1131913651966767\n",
      "53 Train Loss 18.994228 Test MSE 5.50251539906883 Test RE 1.1212144690046466\n",
      "54 Train Loss 18.811068 Test MSE 5.722586465557118 Test RE 1.1434159391753247\n",
      "55 Train Loss 18.768984 Test MSE 5.716768823991171 Test RE 1.1428345870529846\n",
      "56 Train Loss 18.714796 Test MSE 5.714130278712223 Test RE 1.1425708218986246\n",
      "57 Train Loss 18.623755 Test MSE 5.635023781083906 Test RE 1.134634375065726\n",
      "58 Train Loss 18.553062 Test MSE 5.673820415646602 Test RE 1.1385336031967177\n",
      "59 Train Loss 18.448494 Test MSE 5.6963686556423685 Test RE 1.1407936741897005\n",
      "60 Train Loss 18.352297 Test MSE 5.553333212005555 Test RE 1.1263799900825735\n",
      "61 Train Loss 18.227566 Test MSE 5.599038641045664 Test RE 1.1310056973285925\n",
      "62 Train Loss 17.994862 Test MSE 5.675861485636704 Test RE 1.1387383697955256\n",
      "63 Train Loss 17.73212 Test MSE 5.616359718760273 Test RE 1.1327537750995433\n",
      "64 Train Loss 17.241018 Test MSE 5.646537453565337 Test RE 1.1357929453568163\n",
      "65 Train Loss 17.039251 Test MSE 5.688542186978075 Test RE 1.1400097137968086\n",
      "66 Train Loss 16.812658 Test MSE 5.563276650396821 Test RE 1.1273879505770938\n",
      "67 Train Loss 16.536474 Test MSE 5.39569180897655 Test RE 1.1102777282557033\n",
      "68 Train Loss 16.083319 Test MSE 4.97870961019522 Test RE 1.0665137486150638\n",
      "69 Train Loss 14.898562 Test MSE 4.818151045532966 Test RE 1.0491758021955226\n",
      "70 Train Loss 14.140356 Test MSE 4.281410588229188 Test RE 0.9890118601765697\n",
      "71 Train Loss 13.678749 Test MSE 4.1918483278730605 Test RE 0.978612684021423\n",
      "72 Train Loss 13.251032 Test MSE 3.9546153288322397 Test RE 0.9505176442665119\n",
      "73 Train Loss 12.503199 Test MSE 3.7458117695237534 Test RE 0.9250837138084308\n",
      "74 Train Loss 11.89534 Test MSE 3.666006980538735 Test RE 0.9151761719756346\n",
      "75 Train Loss 11.430508 Test MSE 3.5446003335232072 Test RE 0.8998947067807495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 11.251803 Test MSE 3.6130005308688182 Test RE 0.9085358586223194\n",
      "77 Train Loss 11.086608 Test MSE 3.714827904391759 Test RE 0.9212498069344014\n",
      "78 Train Loss 10.894061 Test MSE 3.6881278593917846 Test RE 0.9179331298908593\n",
      "79 Train Loss 10.655542 Test MSE 3.71377762064468 Test RE 0.9211195664328625\n",
      "80 Train Loss 10.521166 Test MSE 3.64986511464071 Test RE 0.9131591343029042\n",
      "81 Train Loss 10.440935 Test MSE 3.610076557041193 Test RE 0.9081681486337144\n",
      "82 Train Loss 10.309181 Test MSE 3.589095344207092 Test RE 0.9055252357931568\n",
      "83 Train Loss 10.253039 Test MSE 3.573179734115105 Test RE 0.9035152586295983\n",
      "84 Train Loss 10.157664 Test MSE 3.594579949338307 Test RE 0.9062168519222775\n",
      "85 Train Loss 10.080475 Test MSE 3.6104074665551424 Test RE 0.9082097702710341\n",
      "86 Train Loss 9.966714 Test MSE 3.618338885204726 Test RE 0.9092068101031523\n",
      "87 Train Loss 9.905917 Test MSE 3.614376150776786 Test RE 0.9087088008988913\n",
      "88 Train Loss 9.7877865 Test MSE 3.5917727255374174 Test RE 0.9058629231702421\n",
      "89 Train Loss 9.653034 Test MSE 3.5762997461365886 Test RE 0.9039096361282423\n",
      "90 Train Loss 9.602948 Test MSE 3.537297304445589 Test RE 0.8989671909573097\n",
      "91 Train Loss 9.56826 Test MSE 3.536354879609859 Test RE 0.8988474292619671\n",
      "92 Train Loss 9.517479 Test MSE 3.5394933661762593 Test RE 0.899246200743805\n",
      "93 Train Loss 9.480207 Test MSE 3.5264658731136302 Test RE 0.8975897881125339\n",
      "94 Train Loss 9.459274 Test MSE 3.5312679724002467 Test RE 0.8982007182989492\n",
      "95 Train Loss 9.409725 Test MSE 3.5279330528982977 Test RE 0.89777648900399\n",
      "96 Train Loss 9.358981 Test MSE 3.5284802440186054 Test RE 0.8978461099786779\n",
      "97 Train Loss 9.337339 Test MSE 3.542053202309462 Test RE 0.8995713188652227\n",
      "98 Train Loss 9.307738 Test MSE 3.5433289808749 Test RE 0.8997333083130256\n",
      "99 Train Loss 9.275312 Test MSE 3.537219385193171 Test RE 0.8989572897204066\n",
      "Training time: 67.11\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.796474 Test MSE 8.408137154428081 Test RE 1.3859831613186029\n",
      "1 Train Loss 55.49499 Test MSE 8.532929581813177 Test RE 1.396230565449723\n",
      "2 Train Loss 55.034477 Test MSE 8.557825424183381 Test RE 1.3982659167495026\n",
      "3 Train Loss 53.820946 Test MSE 8.54306036423518 Test RE 1.3970591620069344\n",
      "4 Train Loss 47.356087 Test MSE 8.431997039611415 Test RE 1.3879482798308986\n",
      "5 Train Loss 46.72348 Test MSE 7.817090113962002 Test RE 1.3363820064640302\n",
      "6 Train Loss 45.57374 Test MSE 8.144974262802863 Test RE 1.3641210744645398\n",
      "7 Train Loss 42.619934 Test MSE 6.663457631327086 Test RE 1.233837258510505\n",
      "8 Train Loss 40.78429 Test MSE 7.537332314603022 Test RE 1.3122509382712957\n",
      "9 Train Loss 40.703026 Test MSE 7.488502504240598 Test RE 1.307993392081725\n",
      "10 Train Loss 39.611908 Test MSE 7.8003283813582796 Test RE 1.3349484744073552\n",
      "11 Train Loss 39.01915 Test MSE 7.460965072181296 Test RE 1.3055862383757906\n",
      "12 Train Loss 38.623768 Test MSE 7.449705758320746 Test RE 1.3046007388320542\n",
      "13 Train Loss 38.24372 Test MSE 7.412552861301972 Test RE 1.3013435444402797\n",
      "14 Train Loss 37.747185 Test MSE 7.2748659271012786 Test RE 1.2892007728995882\n",
      "15 Train Loss 36.45106 Test MSE 6.991116697352309 Test RE 1.2638086864560771\n",
      "16 Train Loss 35.60639 Test MSE 6.9632615431317975 Test RE 1.2612884365875712\n",
      "17 Train Loss 35.395103 Test MSE 6.870051805263446 Test RE 1.2528182357795452\n",
      "18 Train Loss 33.973835 Test MSE 6.8038950204445285 Test RE 1.246771489021424\n",
      "19 Train Loss 32.934532 Test MSE 6.152751898151264 Test RE 1.1856124791360978\n",
      "20 Train Loss 32.445114 Test MSE 6.32010191036793 Test RE 1.2016281696574789\n",
      "21 Train Loss 31.735802 Test MSE 6.489632004120783 Test RE 1.2176377268279657\n",
      "22 Train Loss 31.017391 Test MSE 6.590333424406514 Test RE 1.2270485709087307\n",
      "23 Train Loss 28.961937 Test MSE 6.353418210977189 Test RE 1.2047911870522048\n",
      "24 Train Loss 28.11996 Test MSE 6.191982296836131 Test RE 1.1893862494241134\n",
      "25 Train Loss 27.298054 Test MSE 6.341112909192482 Test RE 1.2036239016609365\n",
      "26 Train Loss 26.976954 Test MSE 6.088701006126149 Test RE 1.1794251495856818\n",
      "27 Train Loss 26.683357 Test MSE 6.0932002059071495 Test RE 1.1798608327829272\n",
      "28 Train Loss 26.07069 Test MSE 6.112110206932827 Test RE 1.1816902397579327\n",
      "29 Train Loss 25.949703 Test MSE 6.0589177314769715 Test RE 1.1765369961699657\n",
      "30 Train Loss 25.700996 Test MSE 5.932642760158584 Test RE 1.1642122350728872\n",
      "31 Train Loss 25.367115 Test MSE 5.793647946487286 Test RE 1.1504933455894861\n",
      "32 Train Loss 24.751667 Test MSE 5.6427597722115586 Test RE 1.1354129441836656\n",
      "33 Train Loss 24.608566 Test MSE 5.556216487047623 Test RE 1.1266723588054914\n",
      "34 Train Loss 24.275509 Test MSE 5.143822218193771 Test RE 1.0840542970938116\n",
      "35 Train Loss 23.95296 Test MSE 5.258986326227608 Test RE 1.0961224710399793\n",
      "36 Train Loss 23.400997 Test MSE 5.411178722251533 Test RE 1.1118699665546223\n",
      "37 Train Loss 23.13037 Test MSE 5.484475919073745 Test RE 1.1193750620144944\n",
      "38 Train Loss 22.707794 Test MSE 5.261163590324414 Test RE 1.096349349471705\n",
      "39 Train Loss 22.365208 Test MSE 5.545688957729977 Test RE 1.125604482848065\n",
      "40 Train Loss 20.470917 Test MSE 5.207573966537615 Test RE 1.0907514120798323\n",
      "41 Train Loss 19.50488 Test MSE 5.233584376234874 Test RE 1.093472021837073\n",
      "42 Train Loss 18.156433 Test MSE 5.279330047951338 Test RE 1.0982405300477365\n",
      "43 Train Loss 17.902346 Test MSE 5.32116332653294 Test RE 1.1025831594764617\n",
      "44 Train Loss 17.67209 Test MSE 5.290330235636975 Test RE 1.0993840999113587\n",
      "45 Train Loss 17.423733 Test MSE 5.234155795928452 Test RE 1.0935317146162837\n",
      "46 Train Loss 17.204332 Test MSE 5.28851517915612 Test RE 1.0991954901904206\n",
      "47 Train Loss 16.846132 Test MSE 5.397015008859419 Test RE 1.1104138580935452\n",
      "48 Train Loss 16.522547 Test MSE 5.536354986201943 Test RE 1.1246568292000279\n",
      "49 Train Loss 16.246788 Test MSE 5.634816748761705 Test RE 1.1346135314849082\n",
      "50 Train Loss 15.94992 Test MSE 5.60277040333159 Test RE 1.1313825425020065\n",
      "51 Train Loss 15.588097 Test MSE 5.713346277904436 Test RE 1.1424924366385993\n",
      "52 Train Loss 15.286091 Test MSE 5.754242608000357 Test RE 1.146574145581177\n",
      "53 Train Loss 14.983041 Test MSE 5.804465130037094 Test RE 1.1515668742398637\n",
      "54 Train Loss 14.715246 Test MSE 5.746590541596105 Test RE 1.1458115273818321\n",
      "55 Train Loss 14.450813 Test MSE 5.858683658969245 Test RE 1.156932669007497\n",
      "56 Train Loss 13.813341 Test MSE 5.923957551082778 Test RE 1.1633597372488993\n",
      "57 Train Loss 13.660547 Test MSE 5.868764918697983 Test RE 1.157927630190599\n",
      "58 Train Loss 13.311737 Test MSE 5.8626317937512615 Test RE 1.1573224286441826\n",
      "59 Train Loss 13.033581 Test MSE 5.931023839122536 Test RE 1.164053377009787\n",
      "60 Train Loss 12.947915 Test MSE 5.848293259845291 Test RE 1.1559063013589268\n",
      "61 Train Loss 12.791634 Test MSE 5.852010105339141 Test RE 1.156273557456388\n",
      "62 Train Loss 12.668798 Test MSE 5.885776933082619 Test RE 1.1596046803958318\n",
      "63 Train Loss 12.591439 Test MSE 5.872020020325625 Test RE 1.1582487070840692\n",
      "64 Train Loss 12.471483 Test MSE 5.836293251529989 Test RE 1.1547198006760753\n",
      "65 Train Loss 12.380176 Test MSE 5.8649227615230375 Test RE 1.1575485326795045\n",
      "66 Train Loss 12.324578 Test MSE 5.866172940421799 Test RE 1.1576718988087729\n",
      "67 Train Loss 12.225832 Test MSE 5.883875420548104 Test RE 1.1594173490561666\n",
      "68 Train Loss 12.11286 Test MSE 5.908993082939989 Test RE 1.1618894306412875\n",
      "69 Train Loss 12.020126 Test MSE 5.808023121007542 Test RE 1.151919760919428\n",
      "70 Train Loss 11.752917 Test MSE 5.76745683324926 Test RE 1.1478899052448515\n",
      "71 Train Loss 11.173649 Test MSE 5.687538782923025 Test RE 1.1399091659956955\n",
      "72 Train Loss 10.777006 Test MSE 5.3550305663494 Test RE 1.1060863615199985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 10.479227 Test MSE 5.370096763084555 Test RE 1.1076412368582913\n",
      "74 Train Loss 10.158876 Test MSE 5.241283377132825 Test RE 1.0942760165405545\n",
      "75 Train Loss 9.803182 Test MSE 4.94374520649339 Test RE 1.0627622024287526\n",
      "76 Train Loss 9.545807 Test MSE 4.755299433326335 Test RE 1.042310216741864\n",
      "77 Train Loss 9.358776 Test MSE 4.695322566703635 Test RE 1.0357162185210496\n",
      "78 Train Loss 9.037951 Test MSE 4.348872470775934 Test RE 0.9967733003775515\n",
      "79 Train Loss 8.83643 Test MSE 4.193506525410936 Test RE 0.9788062230725937\n",
      "80 Train Loss 8.6038475 Test MSE 4.109060983871365 Test RE 0.9689008874360843\n",
      "81 Train Loss 8.447768 Test MSE 4.039618088011723 Test RE 0.9606788164619416\n",
      "82 Train Loss 8.234429 Test MSE 3.9705826273686426 Test RE 0.9524346334775142\n",
      "83 Train Loss 8.094799 Test MSE 3.955326289302807 Test RE 0.950603082424872\n",
      "84 Train Loss 7.9909406 Test MSE 3.9086707348920218 Test RE 0.9449799714116764\n",
      "85 Train Loss 7.650719 Test MSE 3.6297854829612035 Test RE 0.9106438102122754\n",
      "86 Train Loss 6.4765882 Test MSE 3.1978622989707723 Test RE 0.854747697844724\n",
      "87 Train Loss 5.7597356 Test MSE 2.7308004315851293 Test RE 0.7898653121298368\n",
      "88 Train Loss 5.0428944 Test MSE 2.3785210079535553 Test RE 0.7371596515658727\n",
      "89 Train Loss 4.468373 Test MSE 2.01457489972101 Test RE 0.6784217605725392\n",
      "90 Train Loss 4.2115235 Test MSE 1.9428876241056143 Test RE 0.6662418374141167\n",
      "91 Train Loss 4.0919003 Test MSE 1.8563806252632349 Test RE 0.6512407590776332\n",
      "92 Train Loss 3.9392605 Test MSE 1.873321766517062 Test RE 0.654205588805146\n",
      "93 Train Loss 3.7731237 Test MSE 1.8399198713318623 Test RE 0.648347014287073\n",
      "94 Train Loss 3.7055523 Test MSE 1.8152687034978816 Test RE 0.6439891054962206\n",
      "95 Train Loss 3.6499488 Test MSE 1.807415843284283 Test RE 0.6425946459329812\n",
      "96 Train Loss 3.610066 Test MSE 1.7975688601945443 Test RE 0.6408417951520706\n",
      "97 Train Loss 3.5294588 Test MSE 1.7834615080316583 Test RE 0.638322173041582\n",
      "98 Train Loss 3.485199 Test MSE 1.7882354812832946 Test RE 0.6391759331071639\n",
      "99 Train Loss 3.4271486 Test MSE 1.7798733725612386 Test RE 0.637679731479399\n",
      "Training time: 66.52\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 58.962303 Test MSE 8.179057861178807 Test RE 1.366972256972039\n",
      "1 Train Loss 56.87802 Test MSE 8.677991653670867 Test RE 1.408048694730958\n",
      "2 Train Loss 55.67254 Test MSE 8.460830411275486 Test RE 1.3903193121710835\n",
      "3 Train Loss 49.75986 Test MSE 7.87655789371546 Test RE 1.3414555759467661\n",
      "4 Train Loss 47.143444 Test MSE 8.97143572924201 Test RE 1.4316571790859824\n",
      "5 Train Loss 42.57161 Test MSE 8.24360391808721 Test RE 1.3723554734316767\n",
      "6 Train Loss 42.461205 Test MSE 8.239085176876113 Test RE 1.371979292737904\n",
      "7 Train Loss 41.76104 Test MSE 8.194871450743214 Test RE 1.3682930875671406\n",
      "8 Train Loss 41.10788 Test MSE 8.447209565464558 Test RE 1.3891997440044852\n",
      "9 Train Loss 40.566063 Test MSE 8.054030163961237 Test RE 1.356484033231427\n",
      "10 Train Loss 39.807762 Test MSE 8.002027125031566 Test RE 1.3520976870847086\n",
      "11 Train Loss 39.52191 Test MSE 8.041405855605092 Test RE 1.355420504280184\n",
      "12 Train Loss 39.21795 Test MSE 8.087527210924565 Test RE 1.359301943121427\n",
      "13 Train Loss 38.831417 Test MSE 8.06728216854362 Test RE 1.35759954583241\n",
      "14 Train Loss 38.606018 Test MSE 7.941633952076518 Test RE 1.3469857245552286\n",
      "15 Train Loss 38.25788 Test MSE 7.537599100025631 Test RE 1.3122741617612985\n",
      "16 Train Loss 38.036045 Test MSE 7.3900219057478465 Test RE 1.2993642784265216\n",
      "17 Train Loss 37.40192 Test MSE 7.321080107873655 Test RE 1.2932891668876132\n",
      "18 Train Loss 34.894714 Test MSE 6.651810687209844 Test RE 1.232758485345881\n",
      "19 Train Loss 31.521137 Test MSE 6.923423151717824 Test RE 1.2576752031873317\n",
      "20 Train Loss 27.988424 Test MSE 6.495111486493341 Test RE 1.218151670968346\n",
      "21 Train Loss 25.472672 Test MSE 5.321293284193111 Test RE 1.102596623473325\n",
      "22 Train Loss 23.816702 Test MSE 5.395931782248932 Test RE 1.1103024177697407\n",
      "23 Train Loss 21.599411 Test MSE 5.3598963500672125 Test RE 1.1065887634138591\n",
      "24 Train Loss 20.613247 Test MSE 5.303056541686206 Test RE 1.1007056331456988\n",
      "25 Train Loss 19.882812 Test MSE 5.44942604161063 Test RE 1.1157925097361336\n",
      "26 Train Loss 19.181675 Test MSE 5.417172139194945 Test RE 1.112485549260996\n",
      "27 Train Loss 18.426868 Test MSE 5.012123609409547 Test RE 1.070086652004523\n",
      "28 Train Loss 18.133598 Test MSE 5.2365016359442125 Test RE 1.0937767362774684\n",
      "29 Train Loss 17.792109 Test MSE 5.0887112438105095 Test RE 1.0782313728495772\n",
      "30 Train Loss 17.561838 Test MSE 4.9755848856205755 Test RE 1.0661790148147419\n",
      "31 Train Loss 17.406933 Test MSE 4.973130245738341 Test RE 1.065915989617963\n",
      "32 Train Loss 17.017042 Test MSE 4.186142917038149 Test RE 0.9779464756907575\n",
      "33 Train Loss 14.173051 Test MSE 4.019583713876978 Test RE 0.9582936254593922\n",
      "34 Train Loss 12.621426 Test MSE 4.208646661740462 Test RE 0.9805715604917064\n",
      "35 Train Loss 11.845299 Test MSE 4.344103228821173 Test RE 0.996226588887066\n",
      "36 Train Loss 11.350399 Test MSE 4.195949916589622 Test RE 0.9790913374755785\n",
      "37 Train Loss 10.875286 Test MSE 4.2102708093403125 Test RE 0.9807607471181637\n",
      "38 Train Loss 10.712996 Test MSE 4.289969375761406 Test RE 0.9899999126010438\n",
      "39 Train Loss 10.560115 Test MSE 4.237404342105631 Test RE 0.9839159795858989\n",
      "40 Train Loss 10.381658 Test MSE 4.220678497803926 Test RE 0.9819722074274574\n",
      "41 Train Loss 10.260354 Test MSE 4.235556035344064 Test RE 0.9837013697959153\n",
      "42 Train Loss 10.142337 Test MSE 4.263128263440659 Test RE 0.9868979797543039\n",
      "43 Train Loss 10.03586 Test MSE 4.278472347211456 Test RE 0.9886724330298777\n",
      "44 Train Loss 9.931498 Test MSE 4.250449905417574 Test RE 0.9854293912292471\n",
      "45 Train Loss 9.866255 Test MSE 4.2756607794070005 Test RE 0.9883475301002089\n",
      "46 Train Loss 9.817924 Test MSE 4.298444281765083 Test RE 0.9909773107865553\n",
      "47 Train Loss 9.683326 Test MSE 4.28152066545344 Test RE 0.9890245740915664\n",
      "48 Train Loss 9.651589 Test MSE 4.310798649622845 Test RE 0.9924003970331214\n",
      "49 Train Loss 9.542836 Test MSE 4.359772546083823 Test RE 0.99802168195729\n",
      "50 Train Loss 9.464008 Test MSE 4.290478088942716 Test RE 0.9900586089496148\n",
      "51 Train Loss 9.375642 Test MSE 4.309579107985939 Test RE 0.9922600101451078\n",
      "52 Train Loss 9.26078 Test MSE 4.240371575500152 Test RE 0.9842604118373852\n",
      "53 Train Loss 9.172285 Test MSE 4.239045896136659 Test RE 0.9841065437516661\n",
      "54 Train Loss 9.041428 Test MSE 4.245660824313237 Test RE 0.9848740816186902\n",
      "55 Train Loss 8.904323 Test MSE 4.281162974104132 Test RE 0.9889832601576839\n",
      "56 Train Loss 8.842718 Test MSE 4.269220939260004 Test RE 0.9876029436088511\n",
      "57 Train Loss 8.801175 Test MSE 4.261094994292131 Test RE 0.9866626046482819\n",
      "58 Train Loss 8.711879 Test MSE 4.2435622598355165 Test RE 0.9846306475208073\n",
      "59 Train Loss 8.65435 Test MSE 4.177809471236307 Test RE 0.9769725810956191\n",
      "60 Train Loss 8.612686 Test MSE 4.174571872315236 Test RE 0.976593954636544\n",
      "61 Train Loss 8.557864 Test MSE 4.245567623153387 Test RE 0.9848632715334911\n",
      "62 Train Loss 8.492976 Test MSE 4.262746977737262 Test RE 0.9868538456723377\n",
      "63 Train Loss 8.421874 Test MSE 4.230966686898359 Test RE 0.9831682907988487\n",
      "64 Train Loss 8.360199 Test MSE 4.233844347469141 Test RE 0.9835025812729541\n",
      "65 Train Loss 8.323143 Test MSE 4.226855119306972 Test RE 0.9826904631852589\n",
      "66 Train Loss 8.281603 Test MSE 4.20911655342726 Test RE 0.9806262989386951\n",
      "67 Train Loss 8.177767 Test MSE 4.156027036331795 Test RE 0.9744223627241225\n",
      "68 Train Loss 8.11498 Test MSE 4.194806622279984 Test RE 0.9789579390986909\n",
      "69 Train Loss 8.095892 Test MSE 4.193987953130289 Test RE 0.9788624064743688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 8.046033 Test MSE 4.182582568654352 Test RE 0.977530511536003\n",
      "71 Train Loss 8.000068 Test MSE 4.163137749025731 Test RE 0.9752555955483774\n",
      "72 Train Loss 7.977208 Test MSE 4.169587297295766 Test RE 0.976010737967008\n",
      "73 Train Loss 7.8938484 Test MSE 4.176461143687408 Test RE 0.9768149164923124\n",
      "74 Train Loss 7.83339 Test MSE 4.169105433048458 Test RE 0.9759543393075337\n",
      "75 Train Loss 7.7992835 Test MSE 4.170692817241495 Test RE 0.9761401186166306\n",
      "76 Train Loss 7.748142 Test MSE 4.145535590209815 Test RE 0.9731916729853264\n",
      "77 Train Loss 7.7099075 Test MSE 4.125036406586524 Test RE 0.9707825321539423\n",
      "78 Train Loss 7.6913443 Test MSE 4.141189129805414 Test RE 0.9726813591427895\n",
      "79 Train Loss 7.658486 Test MSE 4.1213321438155885 Test RE 0.9703465552429659\n",
      "80 Train Loss 7.6409655 Test MSE 4.1274183285344535 Test RE 0.971062771439882\n",
      "81 Train Loss 7.6094565 Test MSE 4.112821375830975 Test RE 0.9693441290830798\n",
      "82 Train Loss 7.586591 Test MSE 4.113640212205434 Test RE 0.9694406193821735\n",
      "83 Train Loss 7.564881 Test MSE 4.095907560691581 Test RE 0.9673488809408765\n",
      "84 Train Loss 7.5497074 Test MSE 4.096941450829912 Test RE 0.9674709624756824\n",
      "85 Train Loss 7.537407 Test MSE 4.10741030967393 Test RE 0.9687062565516482\n",
      "86 Train Loss 7.5247836 Test MSE 4.091882790737625 Test RE 0.9668734901321545\n",
      "87 Train Loss 7.510173 Test MSE 4.07055989741227 Test RE 0.9643509998914526\n",
      "88 Train Loss 7.498569 Test MSE 4.07494350728402 Test RE 0.9648701177978879\n",
      "89 Train Loss 7.4801493 Test MSE 4.076606082443931 Test RE 0.9650669310169943\n",
      "90 Train Loss 7.4625983 Test MSE 4.076626692250533 Test RE 0.9650693705239355\n",
      "91 Train Loss 7.454392 Test MSE 4.082374149470454 Test RE 0.9657494354043331\n",
      "92 Train Loss 7.446047 Test MSE 4.095067766119703 Test RE 0.9672497068296004\n",
      "93 Train Loss 7.434703 Test MSE 4.10239763057306 Test RE 0.9681149720617861\n",
      "94 Train Loss 7.420585 Test MSE 4.118445677762739 Test RE 0.970006693897352\n",
      "95 Train Loss 7.4035573 Test MSE 4.1510759141630205 Test RE 0.9738417695468115\n",
      "96 Train Loss 7.3913713 Test MSE 4.158932001747319 Test RE 0.9747628524237897\n",
      "97 Train Loss 7.3700547 Test MSE 4.188949126820401 Test RE 0.9782742073588004\n",
      "98 Train Loss 7.3510776 Test MSE 4.180819101174123 Test RE 0.9773244157829053\n",
      "99 Train Loss 7.3448205 Test MSE 4.179559920769571 Test RE 0.9771772292630353\n",
      "Training time: 66.90\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.721973 Test MSE 8.549311948356028 Test RE 1.3975702338762965\n",
      "1 Train Loss 55.97763 Test MSE 8.438611578910798 Test RE 1.3884925659976928\n",
      "2 Train Loss 52.253372 Test MSE 9.058136111536749 Test RE 1.4385583474624812\n",
      "3 Train Loss 48.38868 Test MSE 8.645881727460027 Test RE 1.4054412803525793\n",
      "4 Train Loss 43.969505 Test MSE 8.279081224086257 Test RE 1.3753053485663913\n",
      "5 Train Loss 43.620342 Test MSE 8.488656394610127 Test RE 1.3926036769362382\n",
      "6 Train Loss 43.537724 Test MSE 8.498993636182 Test RE 1.3934513552941807\n",
      "7 Train Loss 43.329018 Test MSE 8.489483751073204 Test RE 1.3926715411261525\n",
      "8 Train Loss 43.31443 Test MSE 8.48884698891415 Test RE 1.3926193107907847\n",
      "9 Train Loss 43.10515 Test MSE 8.473417164492732 Test RE 1.3913530820104516\n",
      "10 Train Loss 42.955788 Test MSE 8.516797863592403 Test RE 1.3949101365589833\n",
      "11 Train Loss 42.66307 Test MSE 8.467515880137814 Test RE 1.390868495915797\n",
      "12 Train Loss 42.286053 Test MSE 8.325431187066185 Test RE 1.3791497595864217\n",
      "13 Train Loss 41.780365 Test MSE 8.277771624656175 Test RE 1.3751965701716153\n",
      "14 Train Loss 40.677597 Test MSE 8.263829441381409 Test RE 1.3740379659221824\n",
      "15 Train Loss 39.39217 Test MSE 8.104834285597368 Test RE 1.360755599293081\n",
      "16 Train Loss 38.196697 Test MSE 7.96545513837705 Test RE 1.3490043754245427\n",
      "17 Train Loss 36.969376 Test MSE 7.920825172327041 Test RE 1.345219871702428\n",
      "18 Train Loss 36.25793 Test MSE 7.7676881363493795 Test RE 1.332152520102743\n",
      "19 Train Loss 36.109142 Test MSE 7.662581641173036 Test RE 1.3231089819242656\n",
      "20 Train Loss 35.88945 Test MSE 7.663537244612331 Test RE 1.3231914820616488\n",
      "21 Train Loss 35.49553 Test MSE 7.6566892679352305 Test RE 1.322600161810611\n",
      "22 Train Loss 35.422417 Test MSE 7.669435694954827 Test RE 1.3237005993131787\n",
      "23 Train Loss 35.32032 Test MSE 7.691317339612179 Test RE 1.3255875775022958\n",
      "24 Train Loss 34.985275 Test MSE 7.664700382935466 Test RE 1.32329189237344\n",
      "25 Train Loss 34.686245 Test MSE 7.389965575779272 Test RE 1.299359326256597\n",
      "26 Train Loss 34.23298 Test MSE 7.401410273420091 Test RE 1.3003650834145037\n",
      "27 Train Loss 33.86171 Test MSE 7.411407713533358 Test RE 1.3012430198137441\n",
      "28 Train Loss 33.600117 Test MSE 7.296957683983131 Test RE 1.2911567622668771\n",
      "29 Train Loss 33.40175 Test MSE 7.0888342818587144 Test RE 1.272610412136258\n",
      "30 Train Loss 33.036438 Test MSE 6.8663568143343605 Test RE 1.2524812823800773\n",
      "31 Train Loss 32.453068 Test MSE 6.849798219884314 Test RE 1.2509701572828795\n",
      "32 Train Loss 31.890554 Test MSE 6.701081512781288 Test RE 1.2373156631075615\n",
      "33 Train Loss 31.407234 Test MSE 6.891947008490803 Test RE 1.2548130452547253\n",
      "34 Train Loss 31.112696 Test MSE 6.8764708870456674 Test RE 1.2534033889419312\n",
      "35 Train Loss 30.889996 Test MSE 6.892748380211319 Test RE 1.2548859957909348\n",
      "36 Train Loss 30.372448 Test MSE 6.964638850597539 Test RE 1.2614131695216884\n",
      "37 Train Loss 30.009415 Test MSE 7.011122866794088 Test RE 1.26561568733642\n",
      "38 Train Loss 29.21792 Test MSE 7.306030946960234 Test RE 1.291959245021908\n",
      "39 Train Loss 28.14517 Test MSE 7.2382949156580585 Test RE 1.2859562609744786\n",
      "40 Train Loss 26.591837 Test MSE 7.116383201778517 Test RE 1.2750808497987032\n",
      "41 Train Loss 22.736761 Test MSE 7.158744587735854 Test RE 1.278870278139445\n",
      "42 Train Loss 22.094006 Test MSE 7.14350095185138 Test RE 1.2775079567489125\n",
      "43 Train Loss 20.571102 Test MSE 6.959383768429338 Test RE 1.2609371878596463\n",
      "44 Train Loss 19.66609 Test MSE 6.664279158772703 Test RE 1.2339133151155768\n",
      "45 Train Loss 19.131538 Test MSE 6.791355623799338 Test RE 1.2456220759296224\n",
      "46 Train Loss 18.475958 Test MSE 6.832932546729163 Test RE 1.2494291296229814\n",
      "47 Train Loss 17.96158 Test MSE 6.608175923084475 Test RE 1.2287084879850505\n",
      "48 Train Loss 17.385918 Test MSE 6.272771135374209 Test RE 1.197120261778563\n",
      "49 Train Loss 16.552507 Test MSE 5.9772028302139555 Test RE 1.1685762539634417\n",
      "50 Train Loss 15.705969 Test MSE 5.878044953280844 Test RE 1.158842760039925\n",
      "51 Train Loss 14.904461 Test MSE 5.666680834128582 Test RE 1.1378170478924376\n",
      "52 Train Loss 13.655748 Test MSE 5.146499994891897 Test RE 1.0843364294769438\n",
      "53 Train Loss 12.256562 Test MSE 4.846953577963985 Test RE 1.0523070752376726\n",
      "54 Train Loss 11.742516 Test MSE 4.481909990619323 Test RE 1.0119047289171597\n",
      "55 Train Loss 10.927635 Test MSE 4.376228966492564 Test RE 0.9999034768195221\n",
      "56 Train Loss 10.666703 Test MSE 4.339826630189891 Test RE 0.9957360952083292\n",
      "57 Train Loss 10.242913 Test MSE 4.4867954571459245 Test RE 1.012456087627636\n",
      "58 Train Loss 9.949011 Test MSE 4.521457856426501 Test RE 1.0163593899664363\n",
      "59 Train Loss 9.46334 Test MSE 4.457167229871369 Test RE 1.009107710734612\n",
      "60 Train Loss 8.774017 Test MSE 4.421663843383054 Test RE 1.0050806719345584\n",
      "61 Train Loss 8.523466 Test MSE 4.324296509202388 Test RE 0.9939528717529807\n",
      "62 Train Loss 8.039185 Test MSE 4.08853905378115 Test RE 0.966478362568281\n",
      "63 Train Loss 7.869303 Test MSE 4.073321439912194 Test RE 0.9646780611333893\n",
      "64 Train Loss 7.499507 Test MSE 3.8987534853485566 Test RE 0.9437803878590213\n",
      "65 Train Loss 7.0363693 Test MSE 3.7911752499634357 Test RE 0.9306684480725141\n",
      "66 Train Loss 6.692902 Test MSE 3.6963491358601113 Test RE 0.9189556515401882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Train Loss 6.076175 Test MSE 3.33787766540023 Test RE 0.873259397713546\n",
      "68 Train Loss 5.794242 Test MSE 3.1896827492149975 Test RE 0.8536538534088309\n",
      "69 Train Loss 5.5098915 Test MSE 3.125344755869478 Test RE 0.8450006166658728\n",
      "70 Train Loss 5.068467 Test MSE 3.0362232596794785 Test RE 0.8328655751584104\n",
      "71 Train Loss 4.6768208 Test MSE 2.9394847004591402 Test RE 0.819490007473187\n",
      "72 Train Loss 4.4042187 Test MSE 2.810867057029535 Test RE 0.8013610191944626\n",
      "73 Train Loss 4.1871586 Test MSE 2.822360342643729 Test RE 0.8029976806183374\n",
      "74 Train Loss 3.9508555 Test MSE 2.6961837609962003 Test RE 0.7848430278898174\n",
      "75 Train Loss 3.7105548 Test MSE 2.7616687026621274 Test RE 0.7943169852794234\n",
      "76 Train Loss 3.4806974 Test MSE 2.6268493032252875 Test RE 0.77468587908687\n",
      "77 Train Loss 3.2334292 Test MSE 2.46559216755507 Test RE 0.7505310796135911\n",
      "78 Train Loss 2.9511883 Test MSE 2.4559758447844113 Test RE 0.7490660359916026\n",
      "79 Train Loss 2.7931337 Test MSE 2.465785100962798 Test RE 0.7505604436925535\n",
      "80 Train Loss 2.6685417 Test MSE 2.3878758624614216 Test RE 0.7386078737930117\n",
      "81 Train Loss 2.551702 Test MSE 2.4500955232360813 Test RE 0.748168757444233\n",
      "82 Train Loss 2.4360332 Test MSE 2.410911722536943 Test RE 0.7421620011165743\n",
      "83 Train Loss 2.358109 Test MSE 2.413316795150039 Test RE 0.7425320911018234\n",
      "84 Train Loss 2.2972643 Test MSE 2.424823795597673 Test RE 0.7443002295067829\n",
      "85 Train Loss 2.1779287 Test MSE 2.4014480152905944 Test RE 0.740703940675226\n",
      "86 Train Loss 2.104051 Test MSE 2.4244810817267535 Test RE 0.7442476295968593\n",
      "87 Train Loss 2.0630445 Test MSE 2.4429118740927853 Test RE 0.7470711416288609\n",
      "88 Train Loss 1.9957206 Test MSE 2.488419116839731 Test RE 0.7539973592296618\n",
      "89 Train Loss 1.9448712 Test MSE 2.506327496180322 Test RE 0.7567056376854742\n",
      "90 Train Loss 1.8980131 Test MSE 2.4818270845923958 Test RE 0.7529979956225202\n",
      "91 Train Loss 1.8050528 Test MSE 2.5350146935757363 Test RE 0.7610239082870577\n",
      "92 Train Loss 1.7679347 Test MSE 2.5909788476682456 Test RE 0.7693784080288226\n",
      "93 Train Loss 1.7402043 Test MSE 2.5845381428780607 Test RE 0.7684215452286334\n",
      "94 Train Loss 1.6980275 Test MSE 2.5953419009644065 Test RE 0.770025929140734\n",
      "95 Train Loss 1.6523664 Test MSE 2.5770915203289113 Test RE 0.7673137510063364\n",
      "96 Train Loss 1.6173148 Test MSE 2.524751456397199 Test RE 0.759481808672803\n",
      "97 Train Loss 1.5792952 Test MSE 2.519652650781572 Test RE 0.7587145237964964\n",
      "98 Train Loss 1.5402082 Test MSE 2.570016599932785 Test RE 0.7662597692898984\n",
      "99 Train Loss 1.511846 Test MSE 2.5959543836922583 Test RE 0.7701167841759593\n",
      "Training time: 66.51\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 59.346382 Test MSE 8.58492077351166 Test RE 1.4004777264321369\n",
      "1 Train Loss 58.30907 Test MSE 8.453737159162769 Test RE 1.3897363934298252\n",
      "2 Train Loss 55.382828 Test MSE 7.570347131763033 Test RE 1.3151217409145113\n",
      "3 Train Loss 49.168335 Test MSE 7.678183195260023 Test RE 1.324455268369915\n",
      "4 Train Loss 45.579433 Test MSE 8.475361670008631 Test RE 1.3915127188188137\n",
      "5 Train Loss 39.868294 Test MSE 7.7764836528014465 Test RE 1.332906518862445\n",
      "6 Train Loss 37.044155 Test MSE 7.942042135307219 Test RE 1.3470203402226975\n",
      "7 Train Loss 35.485306 Test MSE 7.293512336716143 Test RE 1.2908519085977048\n",
      "8 Train Loss 33.005627 Test MSE 6.381376419597998 Test RE 1.2074391182257298\n",
      "9 Train Loss 30.843363 Test MSE 6.101205625529106 Test RE 1.1806356457227205\n",
      "10 Train Loss 28.28675 Test MSE 6.650705066230068 Test RE 1.2326560305144867\n",
      "11 Train Loss 27.147408 Test MSE 6.320927346183777 Test RE 1.201706636315065\n",
      "12 Train Loss 25.879623 Test MSE 5.954858000715965 Test RE 1.1663899397983895\n",
      "13 Train Loss 24.23835 Test MSE 5.429975913012056 Test RE 1.113799482646653\n",
      "14 Train Loss 22.933441 Test MSE 4.940686552734172 Test RE 1.0624333905251757\n",
      "15 Train Loss 21.957516 Test MSE 4.740185670340994 Test RE 1.0406525118125174\n",
      "16 Train Loss 20.595276 Test MSE 4.521913490360601 Test RE 1.0164105986889422\n",
      "17 Train Loss 19.948414 Test MSE 4.355369499813264 Test RE 0.9975175907866006\n",
      "18 Train Loss 19.120747 Test MSE 4.284489706392822 Test RE 0.9893674365675168\n",
      "19 Train Loss 18.50653 Test MSE 4.15205470330929 Test RE 0.9739565746711011\n",
      "20 Train Loss 17.934685 Test MSE 4.148719306912296 Test RE 0.9735653004538081\n",
      "21 Train Loss 17.552908 Test MSE 4.109009312226135 Test RE 0.9688947954286278\n",
      "22 Train Loss 17.301579 Test MSE 4.022616511104471 Test RE 0.9586550761042035\n",
      "23 Train Loss 16.975304 Test MSE 3.7912140099802314 Test RE 0.9306732055197566\n",
      "24 Train Loss 16.607216 Test MSE 3.7871170555735865 Test RE 0.9301702061715692\n",
      "25 Train Loss 16.032768 Test MSE 3.4468727544743616 Test RE 0.8874025776341818\n",
      "26 Train Loss 15.322088 Test MSE 3.2621119507049134 Test RE 0.8632915518200893\n",
      "27 Train Loss 14.101351 Test MSE 2.8722526003858855 Test RE 0.8100640816599955\n",
      "28 Train Loss 13.136683 Test MSE 3.324861787348282 Test RE 0.871555120155027\n",
      "29 Train Loss 12.534103 Test MSE 3.523168178234296 Test RE 0.8971700095484944\n",
      "30 Train Loss 12.0510645 Test MSE 3.731394060675507 Test RE 0.9233016639630576\n",
      "31 Train Loss 11.72351 Test MSE 3.6896491804225575 Test RE 0.9181224301334493\n",
      "32 Train Loss 10.936951 Test MSE 3.7457702396736767 Test RE 0.9250785855883286\n",
      "33 Train Loss 10.526865 Test MSE 3.8046216077960446 Test RE 0.9323174122700638\n",
      "34 Train Loss 10.109664 Test MSE 3.752762961935588 Test RE 0.9259416659392573\n",
      "35 Train Loss 9.738172 Test MSE 3.7994641960037883 Test RE 0.9316852895620328\n",
      "36 Train Loss 9.514175 Test MSE 3.7379495642870713 Test RE 0.9241123598049618\n",
      "37 Train Loss 9.254479 Test MSE 3.756147512903817 Test RE 0.9263591170959931\n",
      "38 Train Loss 9.153665 Test MSE 3.7854934620936227 Test RE 0.9299707958869375\n",
      "39 Train Loss 8.945541 Test MSE 3.8558439383933467 Test RE 0.9385724112424519\n",
      "40 Train Loss 8.800148 Test MSE 3.849767583481621 Test RE 0.9378325799892817\n",
      "41 Train Loss 8.650384 Test MSE 3.8294021905623974 Test RE 0.9353487086105791\n",
      "42 Train Loss 8.50418 Test MSE 3.8487996736512056 Test RE 0.9377146774903843\n",
      "43 Train Loss 8.287957 Test MSE 3.8482519058494575 Test RE 0.9376479465316051\n",
      "44 Train Loss 8.117801 Test MSE 3.861483683542892 Test RE 0.9392585612967081\n",
      "45 Train Loss 7.974882 Test MSE 3.8486369828642073 Test RE 0.937694858434574\n",
      "46 Train Loss 7.835497 Test MSE 3.8756267918208516 Test RE 0.9409770580307975\n",
      "47 Train Loss 7.234887 Test MSE 3.366496926996838 Test RE 0.8769951093075635\n",
      "48 Train Loss 6.581978 Test MSE 3.2038210185065483 Test RE 0.8555436719892804\n",
      "49 Train Loss 5.59778 Test MSE 3.0549020102102378 Test RE 0.8354235285627478\n",
      "50 Train Loss 5.29049 Test MSE 2.987345737388077 Test RE 0.8261345862527035\n",
      "51 Train Loss 4.8811927 Test MSE 2.677713406276054 Test RE 0.7821501028536266\n",
      "52 Train Loss 4.6619573 Test MSE 2.7482468203749013 Test RE 0.7923844192554695\n",
      "53 Train Loss 3.35281 Test MSE 1.9408292967163996 Test RE 0.6658888300648003\n",
      "54 Train Loss 2.484717 Test MSE 1.4537548318908795 Test RE 0.5763066698463722\n",
      "55 Train Loss 2.0510526 Test MSE 1.2798146815578721 Test RE 0.5407314182693673\n",
      "56 Train Loss 1.8047942 Test MSE 1.145353974604086 Test RE 0.5115380268013685\n",
      "57 Train Loss 1.461149 Test MSE 1.0595223358280943 Test RE 0.491997752129913\n",
      "58 Train Loss 1.1826687 Test MSE 0.7597097316164588 Test RE 0.4166121246742621\n",
      "59 Train Loss 0.94477654 Test MSE 0.4473382875434031 Test RE 0.3196878241328933\n",
      "60 Train Loss 0.7929738 Test MSE 0.3138476422783493 Test RE 0.26777343854049807\n",
      "61 Train Loss 0.6241511 Test MSE 0.1204734342058075 Test RE 0.16590279606270356\n",
      "62 Train Loss 0.4999815 Test MSE 0.06455031597580693 Test RE 0.12143873832725519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Train Loss 0.3947103 Test MSE 0.06005950291493128 Test RE 0.11713830271444979\n",
      "64 Train Loss 0.32701886 Test MSE 0.053059926163111996 Test RE 0.11010102976968524\n",
      "65 Train Loss 0.24779649 Test MSE 0.03149730693914843 Test RE 0.08482908285932544\n",
      "66 Train Loss 0.20453766 Test MSE 0.038367319030281226 Test RE 0.09362434382916401\n",
      "67 Train Loss 0.17641997 Test MSE 0.038617604091833756 Test RE 0.09392922157533648\n",
      "68 Train Loss 0.14427832 Test MSE 0.02780982351876147 Test RE 0.07970896623564114\n",
      "69 Train Loss 0.121573776 Test MSE 0.01830414666930229 Test RE 0.06466701339906389\n",
      "70 Train Loss 0.09637543 Test MSE 0.010550889588509487 Test RE 0.049096733590392884\n",
      "71 Train Loss 0.07908632 Test MSE 0.010407211036223916 Test RE 0.048761296102739146\n",
      "72 Train Loss 0.06487593 Test MSE 0.008492832902950498 Test RE 0.04404882721685237\n",
      "73 Train Loss 0.052254267 Test MSE 0.008003216215789746 Test RE 0.04276025980761939\n",
      "74 Train Loss 0.04953207 Test MSE 0.008474302674155087 Test RE 0.04400074664284931\n",
      "75 Train Loss 0.044090226 Test MSE 0.007676635075396235 Test RE 0.04187873051567653\n",
      "76 Train Loss 0.03749755 Test MSE 0.006475054478899738 Test RE 0.03846181491777957\n",
      "77 Train Loss 0.032853 Test MSE 0.005209163439178578 Test RE 0.03449785180046986\n",
      "78 Train Loss 0.031009099 Test MSE 0.004842449045808452 Test RE 0.03326140497760547\n",
      "79 Train Loss 0.028576918 Test MSE 0.004415209076797596 Test RE 0.031760234270629545\n",
      "80 Train Loss 0.025597073 Test MSE 0.003774454100452106 Test RE 0.02936534682409989\n",
      "81 Train Loss 0.023577265 Test MSE 0.0038152481341007594 Test RE 0.029523609648416067\n",
      "82 Train Loss 0.02016566 Test MSE 0.0028276203297719254 Test RE 0.025416667527358845\n",
      "83 Train Loss 0.019011503 Test MSE 0.0023453392066114147 Test RE 0.02314786240100485\n",
      "84 Train Loss 0.017654981 Test MSE 0.0020061244292993775 Test RE 0.021408537182726846\n",
      "85 Train Loss 0.016059924 Test MSE 0.0019248458787068784 Test RE 0.020970367481623068\n",
      "86 Train Loss 0.014935521 Test MSE 0.0016016224412495872 Test RE 0.01912881790448537\n",
      "87 Train Loss 0.013611339 Test MSE 0.0016393643284925827 Test RE 0.019352888778611188\n",
      "88 Train Loss 0.012745781 Test MSE 0.0014062388944572437 Test RE 0.017924110520899254\n",
      "89 Train Loss 0.0119399605 Test MSE 0.0015070829384006136 Test RE 0.018555669855515575\n",
      "90 Train Loss 0.011381097 Test MSE 0.0015885883624617199 Test RE 0.01905082328927811\n",
      "91 Train Loss 0.010946832 Test MSE 0.00167537040863465 Test RE 0.019564262465270484\n",
      "92 Train Loss 0.01074628 Test MSE 0.0015365168138120938 Test RE 0.01873599314320785\n",
      "93 Train Loss 0.010161031 Test MSE 0.0013933697400627717 Test RE 0.017841906027235926\n",
      "94 Train Loss 0.009735944 Test MSE 0.0012944819649292451 Test RE 0.01719713348662283\n",
      "95 Train Loss 0.009098908 Test MSE 0.001297740953979002 Test RE 0.01721876763861008\n",
      "96 Train Loss 0.008544741 Test MSE 0.0013522787048567176 Test RE 0.01757685478711194\n",
      "97 Train Loss 0.0073272088 Test MSE 0.001410937272321224 Test RE 0.01795402863074175\n",
      "98 Train Loss 0.0065401993 Test MSE 0.00137567704873318 Test RE 0.01772826790927202\n",
      "99 Train Loss 0.006348313 Test MSE 0.0013978757628873343 Test RE 0.017870732239016248\n",
      "Training time: 72.60\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.606068 Test MSE 8.598134319286368 Test RE 1.4015550899788247\n",
      "1 Train Loss 57.275597 Test MSE 8.717509060736251 Test RE 1.411251004322808\n",
      "2 Train Loss 54.80394 Test MSE 9.559042239855719 Test RE 1.4777985994278062\n",
      "3 Train Loss 52.35572 Test MSE 8.415470826647775 Test RE 1.3865874646632161\n",
      "4 Train Loss 47.35521 Test MSE 8.183716888394596 Test RE 1.3673615349522963\n",
      "5 Train Loss 44.99054 Test MSE 8.49695419500052 Test RE 1.3932841571113312\n",
      "6 Train Loss 44.514217 Test MSE 8.519532060463302 Test RE 1.3951340266252057\n",
      "7 Train Loss 44.328583 Test MSE 8.498112978848262 Test RE 1.3933791593967289\n",
      "8 Train Loss 44.263817 Test MSE 8.471329684590799 Test RE 1.3911816871386136\n",
      "9 Train Loss 43.96861 Test MSE 8.616155352494042 Test RE 1.4030230974150775\n",
      "10 Train Loss 43.874718 Test MSE 8.525582062724823 Test RE 1.395629304183118\n",
      "11 Train Loss 43.8078 Test MSE 8.536216780036506 Test RE 1.3964994792293464\n",
      "12 Train Loss 43.698837 Test MSE 8.438138128101544 Test RE 1.3884536145574111\n",
      "13 Train Loss 43.44374 Test MSE 8.441867209169125 Test RE 1.3887603815297216\n",
      "14 Train Loss 42.986565 Test MSE 8.32185355922922 Test RE 1.3788534016773553\n",
      "15 Train Loss 42.15861 Test MSE 8.084656358680078 Test RE 1.3590606640937635\n",
      "16 Train Loss 41.469437 Test MSE 8.060768994957852 Test RE 1.3570514016894\n",
      "17 Train Loss 40.982273 Test MSE 8.010298989039384 Test RE 1.3527963525060978\n",
      "18 Train Loss 40.211372 Test MSE 8.07736869267888 Test RE 1.3584479841750134\n",
      "19 Train Loss 39.301193 Test MSE 7.805389730636203 Test RE 1.3353815039214751\n",
      "20 Train Loss 39.04771 Test MSE 7.681810626549847 Test RE 1.324768089974834\n",
      "21 Train Loss 38.835976 Test MSE 7.750488116236132 Test RE 1.3306768076441235\n",
      "22 Train Loss 38.696888 Test MSE 7.753996762834969 Test RE 1.3309779723130364\n",
      "23 Train Loss 38.528152 Test MSE 7.724431489173184 Test RE 1.3284381008732278\n",
      "24 Train Loss 38.453785 Test MSE 7.760168561208354 Test RE 1.3315075633095494\n",
      "25 Train Loss 38.32969 Test MSE 7.693646454881887 Test RE 1.3257882721576442\n",
      "26 Train Loss 38.246735 Test MSE 7.716929038937245 Test RE 1.327792813128431\n",
      "27 Train Loss 38.052505 Test MSE 7.873316186702915 Test RE 1.3411795001830464\n",
      "28 Train Loss 37.868584 Test MSE 7.943506087355706 Test RE 1.347144482243605\n",
      "29 Train Loss 37.38636 Test MSE 7.920930501182329 Test RE 1.345228815846193\n",
      "30 Train Loss 37.02274 Test MSE 7.853352963582061 Test RE 1.3394781040733366\n",
      "31 Train Loss 35.505653 Test MSE 7.782346581387611 Test RE 1.3334088836647098\n",
      "32 Train Loss 33.87677 Test MSE 7.331863214549012 Test RE 1.2942412493350588\n",
      "33 Train Loss 32.78242 Test MSE 7.364739609250879 Test RE 1.2971397208799753\n",
      "34 Train Loss 32.427784 Test MSE 7.3273328987806945 Test RE 1.293841335467581\n",
      "35 Train Loss 32.040825 Test MSE 7.321511085775851 Test RE 1.2933272330500611\n",
      "36 Train Loss 30.754349 Test MSE 7.595268696182774 Test RE 1.3172846510960385\n",
      "37 Train Loss 27.964626 Test MSE 7.616768915309211 Test RE 1.3191477776766602\n",
      "38 Train Loss 24.747402 Test MSE 7.5652429368289935 Test RE 1.3146783154370119\n",
      "39 Train Loss 22.123375 Test MSE 7.185249537054964 Test RE 1.2812355723926017\n",
      "40 Train Loss 19.643494 Test MSE 6.2963653440248555 Test RE 1.1993695543474716\n",
      "41 Train Loss 16.429958 Test MSE 6.329495363535114 Test RE 1.2025208172074113\n",
      "42 Train Loss 14.202835 Test MSE 5.8220890785596096 Test RE 1.1533137856938858\n",
      "43 Train Loss 11.234742 Test MSE 5.767386040611796 Test RE 1.1478828603370501\n",
      "44 Train Loss 9.63506 Test MSE 5.78687934329332 Test RE 1.1498210999894538\n",
      "45 Train Loss 8.809012 Test MSE 5.754453705981258 Test RE 1.1465951767823077\n",
      "46 Train Loss 7.9081326 Test MSE 5.37538468529791 Test RE 1.1081864485923831\n",
      "47 Train Loss 7.208366 Test MSE 5.625979663330973 Test RE 1.1337234749443124\n",
      "48 Train Loss 6.4791656 Test MSE 5.982486124889964 Test RE 1.1690925965724017\n",
      "49 Train Loss 6.0158095 Test MSE 6.010692165192217 Test RE 1.1718453565146207\n",
      "50 Train Loss 5.702886 Test MSE 6.013002349855908 Test RE 1.1720705318374571\n",
      "51 Train Loss 5.430602 Test MSE 6.119148668028319 Test RE 1.1823704375467372\n",
      "52 Train Loss 5.1446686 Test MSE 6.237113166247097 Test RE 1.193712859091247\n",
      "53 Train Loss 4.905522 Test MSE 6.177192990577613 Test RE 1.187964999120525\n",
      "54 Train Loss 4.6513047 Test MSE 6.275902782881172 Test RE 1.197419052441198\n",
      "55 Train Loss 4.4824934 Test MSE 6.353363238249569 Test RE 1.2047859748342438\n",
      "56 Train Loss 4.3090773 Test MSE 6.295763686821406 Test RE 1.1993122493364106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 4.169464 Test MSE 6.087555871523321 Test RE 1.1793142339684983\n",
      "58 Train Loss 3.9949372 Test MSE 6.210712314941059 Test RE 1.1911837678804444\n",
      "59 Train Loss 3.8236682 Test MSE 6.060417243903971 Test RE 1.1766825768480262\n",
      "60 Train Loss 3.6971428 Test MSE 5.830637114229233 Test RE 1.1541601272126611\n",
      "61 Train Loss 3.5166764 Test MSE 5.5100497155053345 Test RE 1.121981817594839\n",
      "62 Train Loss 3.33541 Test MSE 5.093749511694376 Test RE 1.0787650123370847\n",
      "63 Train Loss 3.2414777 Test MSE 5.147869752975483 Test RE 1.0844807197495818\n",
      "64 Train Loss 3.0633142 Test MSE 4.898782916178035 Test RE 1.0579183680125055\n",
      "65 Train Loss 2.9419444 Test MSE 4.889656363164803 Test RE 1.0569324446338804\n",
      "66 Train Loss 2.770927 Test MSE 4.7583488525539845 Test RE 1.042644363041823\n",
      "67 Train Loss 2.6736581 Test MSE 4.769694869277572 Test RE 1.0438866865064316\n",
      "68 Train Loss 2.542767 Test MSE 4.790235705103796 Test RE 1.0461320365473694\n",
      "69 Train Loss 2.4171755 Test MSE 4.911670611867961 Test RE 1.059309037373566\n",
      "70 Train Loss 2.2965868 Test MSE 4.80361327755504 Test RE 1.0475917716131302\n",
      "71 Train Loss 2.2350523 Test MSE 4.843066030060025 Test RE 1.0518849838442144\n",
      "72 Train Loss 2.132412 Test MSE 4.8573571224348715 Test RE 1.0534358105351713\n",
      "73 Train Loss 2.0241065 Test MSE 4.808650813648211 Test RE 1.0481409309868075\n",
      "74 Train Loss 1.9495807 Test MSE 4.773856164365446 Test RE 1.0443419539412813\n",
      "75 Train Loss 1.9025278 Test MSE 4.6814394878236785 Test RE 1.034183887742559\n",
      "76 Train Loss 1.8559928 Test MSE 4.639339806586963 Test RE 1.029523233715775\n",
      "77 Train Loss 1.8120327 Test MSE 4.705823664585882 Test RE 1.0368737623200703\n",
      "78 Train Loss 1.6758626 Test MSE 4.660530785670149 Test RE 1.0318718167237384\n",
      "79 Train Loss 1.6143847 Test MSE 4.51926178080674 Test RE 1.0161125367129913\n",
      "80 Train Loss 1.5121136 Test MSE 4.376119610207244 Test RE 0.9998909835960358\n",
      "81 Train Loss 1.4431273 Test MSE 4.231388095283764 Test RE 0.9832172518373806\n",
      "82 Train Loss 1.3533238 Test MSE 4.164263874287562 Test RE 0.9753874895391046\n",
      "83 Train Loss 1.285459 Test MSE 4.04046944822412 Test RE 0.9607800439313656\n",
      "84 Train Loss 1.2078224 Test MSE 4.016694472805881 Test RE 0.9579491570749118\n",
      "85 Train Loss 1.0469412 Test MSE 3.7762998593051043 Test RE 0.928840827021848\n",
      "86 Train Loss 0.97687656 Test MSE 3.775670290423967 Test RE 0.9287633975701871\n",
      "87 Train Loss 0.9157328 Test MSE 3.625613987317005 Test RE 0.9101203855152342\n",
      "88 Train Loss 0.85700554 Test MSE 3.523599130684988 Test RE 0.8972248785998892\n",
      "89 Train Loss 0.81149554 Test MSE 3.5746239364634604 Test RE 0.9036978308947862\n",
      "90 Train Loss 0.7483573 Test MSE 3.537017195278256 Test RE 0.8989315968419634\n",
      "91 Train Loss 0.7127318 Test MSE 3.540798488432371 Test RE 0.8994119756076976\n",
      "92 Train Loss 0.6744121 Test MSE 3.494634272111434 Test RE 0.8935295633371597\n",
      "93 Train Loss 0.64808375 Test MSE 3.478782737693161 Test RE 0.8915007512081317\n",
      "94 Train Loss 0.60970116 Test MSE 3.364697188747871 Test RE 0.8767606560046045\n",
      "95 Train Loss 0.5959645 Test MSE 3.3720197764405127 Test RE 0.8777141842390078\n",
      "96 Train Loss 0.57582206 Test MSE 3.3906351441940874 Test RE 0.8801335775773064\n",
      "97 Train Loss 0.56233925 Test MSE 3.415879112273044 Test RE 0.8834038885555202\n",
      "98 Train Loss 0.54427654 Test MSE 3.4580644390523743 Test RE 0.8888420681253746\n",
      "99 Train Loss 0.5234629 Test MSE 3.426831528457097 Test RE 0.8848189948156963\n",
      "Training time: 71.96\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.291954 Test MSE 8.52156895843843 Test RE 1.3953007949300165\n",
      "1 Train Loss 53.512295 Test MSE 9.059623916553708 Test RE 1.438676484705132\n",
      "2 Train Loss 49.01251 Test MSE 8.11610116139226 Test RE 1.361701093010414\n",
      "3 Train Loss 42.31041 Test MSE 7.279089725567325 Test RE 1.2895749745783542\n",
      "4 Train Loss 36.661957 Test MSE 7.32474178933448 Test RE 1.293612549565302\n",
      "5 Train Loss 34.79111 Test MSE 7.384474429817605 Test RE 1.2988764892559013\n",
      "6 Train Loss 33.07254 Test MSE 7.240472123573833 Test RE 1.286149647930756\n",
      "7 Train Loss 30.638733 Test MSE 6.709243888067116 Test RE 1.2380690012956748\n",
      "8 Train Loss 29.641588 Test MSE 6.617043423568383 Test RE 1.2295326125620152\n",
      "9 Train Loss 27.756178 Test MSE 6.250419777510036 Test RE 1.194985548032055\n",
      "10 Train Loss 26.834133 Test MSE 6.407206291045128 Test RE 1.2098803236165574\n",
      "11 Train Loss 26.022934 Test MSE 6.354638776645585 Test RE 1.204906908707236\n",
      "12 Train Loss 24.887234 Test MSE 6.092688890123196 Test RE 1.1798113272601294\n",
      "13 Train Loss 24.367214 Test MSE 6.062345734866451 Test RE 1.1768697785809903\n",
      "14 Train Loss 23.613441 Test MSE 5.924435294976815 Test RE 1.1634066464984314\n",
      "15 Train Loss 23.16658 Test MSE 5.910176449062302 Test RE 1.1620057678699383\n",
      "16 Train Loss 22.925682 Test MSE 5.724248525401176 Test RE 1.1435819731671042\n",
      "17 Train Loss 22.493591 Test MSE 5.47623812780045 Test RE 1.118534084366459\n",
      "18 Train Loss 21.836723 Test MSE 5.570377337118579 Test RE 1.128107191809805\n",
      "19 Train Loss 21.419828 Test MSE 5.198016515879505 Test RE 1.089750025405562\n",
      "20 Train Loss 20.144793 Test MSE 5.5384474404046955 Test RE 1.1248693400127567\n",
      "21 Train Loss 18.435543 Test MSE 5.2754044001165035 Test RE 1.097832134732715\n",
      "22 Train Loss 16.56996 Test MSE 4.798424997102708 Test RE 1.0470258779825876\n",
      "23 Train Loss 15.774445 Test MSE 4.62389652990604 Test RE 1.027808284383752\n",
      "24 Train Loss 14.561443 Test MSE 4.317084521417217 Test RE 0.9931236770766291\n",
      "25 Train Loss 13.873695 Test MSE 3.945998122912888 Test RE 0.9494814786157164\n",
      "26 Train Loss 12.68701 Test MSE 3.476450594861343 Test RE 0.8912018743000959\n",
      "27 Train Loss 11.792543 Test MSE 3.72328977323257 Test RE 0.92229845050793\n",
      "28 Train Loss 11.035757 Test MSE 3.849999540848579 Test RE 0.9378608328505915\n",
      "29 Train Loss 10.411408 Test MSE 3.764773445096323 Test RE 0.9274221914997555\n",
      "30 Train Loss 10.029095 Test MSE 3.9447779231966544 Test RE 0.9493346657470682\n",
      "31 Train Loss 9.540861 Test MSE 3.913725591996431 Test RE 0.9455908178699663\n",
      "32 Train Loss 9.252465 Test MSE 3.90665474728826 Test RE 0.9447362423095712\n",
      "33 Train Loss 8.997756 Test MSE 3.967089045838921 Test RE 0.9520155337386624\n",
      "34 Train Loss 8.814867 Test MSE 3.9378991586196164 Test RE 0.9485065964504906\n",
      "35 Train Loss 8.532224 Test MSE 4.0239072475828275 Test RE 0.9588088655383467\n",
      "36 Train Loss 8.330811 Test MSE 3.9422271261886053 Test RE 0.9490276837496182\n",
      "37 Train Loss 8.099457 Test MSE 3.950615575221636 Test RE 0.9500368391998312\n",
      "38 Train Loss 7.936367 Test MSE 3.9540187498083954 Test RE 0.9504459457283561\n",
      "39 Train Loss 7.817071 Test MSE 3.9714979943803024 Test RE 0.9525444129588524\n",
      "40 Train Loss 7.712937 Test MSE 3.9742020437003993 Test RE 0.9528686342974017\n",
      "41 Train Loss 7.503108 Test MSE 3.968488931516243 Test RE 0.9521834900594577\n",
      "42 Train Loss 7.4147105 Test MSE 3.8899710083333425 Test RE 0.9427167911562607\n",
      "43 Train Loss 7.292547 Test MSE 3.8320701774272186 Test RE 0.9356744857731116\n",
      "44 Train Loss 7.0169716 Test MSE 3.731561390985931 Test RE 0.9233223659606912\n",
      "45 Train Loss 6.780811 Test MSE 3.6249562453000483 Test RE 0.9100378268682694\n",
      "46 Train Loss 6.2415934 Test MSE 3.278527641731783 Test RE 0.8654609659486803\n",
      "47 Train Loss 5.7318554 Test MSE 3.1997768209190394 Test RE 0.8550035231773709\n",
      "48 Train Loss 5.394066 Test MSE 3.166574225684327 Test RE 0.8505559686740737\n",
      "49 Train Loss 4.982853 Test MSE 3.142389940857052 Test RE 0.8473017399147406\n",
      "50 Train Loss 4.7962685 Test MSE 2.9817635437669106 Test RE 0.8253623623484931\n",
      "51 Train Loss 4.5984755 Test MSE 2.685626386808267 Test RE 0.7833049263767823\n",
      "52 Train Loss 4.5135293 Test MSE 2.546108131578596 Test RE 0.7626872429391595\n",
      "53 Train Loss 4.38428 Test MSE 2.3150663191445173 Test RE 0.7272601289366503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 4.182769 Test MSE 2.0843704693298752 Test RE 0.6900737637690094\n",
      "55 Train Loss 4.00625 Test MSE 1.9169271720956402 Test RE 0.6617757776046103\n",
      "56 Train Loss 3.856018 Test MSE 1.7490955951191292 Test RE 0.6321422724365091\n",
      "57 Train Loss 3.7461348 Test MSE 1.7831644456798401 Test RE 0.6382690097459848\n",
      "58 Train Loss 3.6627033 Test MSE 1.7799510275793857 Test RE 0.6376936421574765\n",
      "59 Train Loss 3.510191 Test MSE 1.7329772193001083 Test RE 0.629222852435444\n",
      "60 Train Loss 3.4720106 Test MSE 1.715530044569548 Test RE 0.6260474118592312\n",
      "61 Train Loss 3.415686 Test MSE 1.7074788078873673 Test RE 0.6245766175344851\n",
      "62 Train Loss 3.3752456 Test MSE 1.7070669019292253 Test RE 0.6245012776982629\n",
      "63 Train Loss 3.355494 Test MSE 1.7033335009128077 Test RE 0.623818003402192\n",
      "64 Train Loss 3.3223798 Test MSE 1.6753830887111505 Test RE 0.6186786425438854\n",
      "65 Train Loss 3.2711563 Test MSE 1.6633497527930652 Test RE 0.6164528280117242\n",
      "66 Train Loss 3.25331 Test MSE 1.660370248041102 Test RE 0.6159004645112017\n",
      "67 Train Loss 3.2302537 Test MSE 1.6576499097150084 Test RE 0.6153957143002905\n",
      "68 Train Loss 3.1987543 Test MSE 1.6493785025238472 Test RE 0.6138584312453024\n",
      "69 Train Loss 3.1690917 Test MSE 1.6167299281222478 Test RE 0.6077525632569465\n",
      "70 Train Loss 3.1332288 Test MSE 1.6008861434027317 Test RE 0.6047672754977597\n",
      "71 Train Loss 3.0756545 Test MSE 1.569468870007571 Test RE 0.5988036146585238\n",
      "72 Train Loss 3.004528 Test MSE 1.5547192102382967 Test RE 0.5959832342485567\n",
      "73 Train Loss 2.9062119 Test MSE 1.4854493108871996 Test RE 0.5825550596753106\n",
      "74 Train Loss 2.8410068 Test MSE 1.4204009511554045 Test RE 0.569657129993044\n",
      "75 Train Loss 2.7737317 Test MSE 1.385593119248611 Test RE 0.562633930331595\n",
      "76 Train Loss 2.5216084 Test MSE 1.2341939631748846 Test RE 0.5310064167541393\n",
      "77 Train Loss 2.1057312 Test MSE 0.883394733727694 Test RE 0.44924728715901335\n",
      "78 Train Loss 1.6144332 Test MSE 0.8997355389168211 Test RE 0.4533832777064112\n",
      "79 Train Loss 1.2987431 Test MSE 0.8028590800673552 Test RE 0.428279929003804\n",
      "80 Train Loss 1.0427351 Test MSE 0.40360512151049566 Test RE 0.3036591657522708\n",
      "81 Train Loss 0.78919864 Test MSE 0.27627421808463654 Test RE 0.25123389964100945\n",
      "82 Train Loss 0.6415126 Test MSE 0.18008031103869857 Test RE 0.20283419665645616\n",
      "83 Train Loss 0.50111616 Test MSE 0.1231942236882174 Test RE 0.1677657230186072\n",
      "84 Train Loss 0.40932155 Test MSE 0.08550327879007967 Test RE 0.13976532693456725\n",
      "85 Train Loss 0.336023 Test MSE 0.08044220008216701 Test RE 0.135565765351519\n",
      "86 Train Loss 0.269353 Test MSE 0.0513220979284224 Test RE 0.1082829953416664\n",
      "87 Train Loss 0.18514386 Test MSE 0.03604145308025545 Test RE 0.09074217952439352\n",
      "88 Train Loss 0.15660182 Test MSE 0.027472092422573206 Test RE 0.0792234826005201\n",
      "89 Train Loss 0.12702425 Test MSE 0.020529763167082802 Test RE 0.06848572063589106\n",
      "90 Train Loss 0.112349354 Test MSE 0.01770558954279628 Test RE 0.06360089926990808\n",
      "91 Train Loss 0.09775598 Test MSE 0.014722437311379977 Test RE 0.05799598343707873\n",
      "92 Train Loss 0.08420146 Test MSE 0.01475558382681042 Test RE 0.05806123363712638\n",
      "93 Train Loss 0.07579933 Test MSE 0.019440358168733195 Test RE 0.06664386735727129\n",
      "94 Train Loss 0.06942284 Test MSE 0.020610561853405318 Test RE 0.06862035741465194\n",
      "95 Train Loss 0.061313957 Test MSE 0.021984148902951747 Test RE 0.07087007441102108\n",
      "96 Train Loss 0.054891337 Test MSE 0.02213083137097378 Test RE 0.07110611072642854\n",
      "97 Train Loss 0.047791436 Test MSE 0.016752814816104165 Test RE 0.06186598817312961\n",
      "98 Train Loss 0.040056527 Test MSE 0.01412401087863961 Test RE 0.05680506772750862\n",
      "99 Train Loss 0.037416454 Test MSE 0.01257703712847231 Test RE 0.053604004104776774\n",
      "Training time: 72.78\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.48024 Test MSE 8.593663274072481 Test RE 1.4011906370176885\n",
      "1 Train Loss 56.243202 Test MSE 8.532650182402925 Test RE 1.3962077064078042\n",
      "2 Train Loss 55.519077 Test MSE 8.355289535432062 Test RE 1.38162063934427\n",
      "3 Train Loss 50.984966 Test MSE 8.489461306882466 Test RE 1.392669700177558\n",
      "4 Train Loss 46.057053 Test MSE 8.565354148975729 Test RE 1.3988808419471805\n",
      "5 Train Loss 43.66002 Test MSE 8.645329686442269 Test RE 1.4053964108040256\n",
      "6 Train Loss 42.78447 Test MSE 8.542886712891203 Test RE 1.3970449632055926\n",
      "7 Train Loss 42.614067 Test MSE 8.396792950755684 Test RE 1.3850478660290297\n",
      "8 Train Loss 42.303818 Test MSE 8.483744929662418 Test RE 1.3922007442773285\n",
      "9 Train Loss 42.026924 Test MSE 8.330020345361113 Test RE 1.3795298158542546\n",
      "10 Train Loss 41.944313 Test MSE 8.375130235006502 Test RE 1.3832600837762303\n",
      "11 Train Loss 41.832905 Test MSE 8.307149318851414 Test RE 1.3776346854484909\n",
      "12 Train Loss 41.72789 Test MSE 8.213638657677672 Test RE 1.369858966573958\n",
      "13 Train Loss 41.66279 Test MSE 8.368761328823242 Test RE 1.3827340305111522\n",
      "14 Train Loss 41.542053 Test MSE 8.390520711420104 Test RE 1.3845304676196377\n",
      "15 Train Loss 41.013412 Test MSE 8.412245762823572 Test RE 1.3863217480039136\n",
      "16 Train Loss 40.729675 Test MSE 8.256334850900913 Test RE 1.373414756802815\n",
      "17 Train Loss 40.19768 Test MSE 8.503453285650723 Test RE 1.393816897961532\n",
      "18 Train Loss 39.689793 Test MSE 8.40094861127164 Test RE 1.3853905609596717\n",
      "19 Train Loss 38.63964 Test MSE 8.943777110247227 Test RE 1.4294486013105707\n",
      "20 Train Loss 35.366425 Test MSE 9.181744008119994 Test RE 1.448340417815482\n",
      "21 Train Loss 33.20333 Test MSE 9.474376406107034 Test RE 1.4712395043541315\n",
      "22 Train Loss 32.057693 Test MSE 9.124565742070784 Test RE 1.4438236874026102\n",
      "23 Train Loss 30.898846 Test MSE 9.157446994685031 Test RE 1.446422826895006\n",
      "24 Train Loss 29.983973 Test MSE 9.257635023837965 Test RE 1.454313674828342\n",
      "25 Train Loss 29.403282 Test MSE 9.246712197579985 Test RE 1.4534554694685935\n",
      "26 Train Loss 28.69611 Test MSE 9.1337091824416 Test RE 1.4445469114230653\n",
      "27 Train Loss 28.332691 Test MSE 9.087903991668828 Test RE 1.4409201858857412\n",
      "28 Train Loss 27.853313 Test MSE 8.832771501373983 Test RE 1.4205501100094065\n",
      "29 Train Loss 27.378471 Test MSE 8.322838372131773 Test RE 1.378934986413218\n",
      "30 Train Loss 26.981281 Test MSE 8.395150993136541 Test RE 1.3849124392596797\n",
      "31 Train Loss 25.780643 Test MSE 8.38341012985386 Test RE 1.3839436802317273\n",
      "32 Train Loss 24.961924 Test MSE 8.489941290349657 Test RE 1.392709069517908\n",
      "33 Train Loss 24.363323 Test MSE 8.60918860327792 Test RE 1.4024557627801477\n",
      "34 Train Loss 23.56316 Test MSE 8.74217653009193 Test RE 1.4132462646106403\n",
      "35 Train Loss 21.756954 Test MSE 8.021148704970107 Test RE 1.3537122040538092\n",
      "36 Train Loss 19.40121 Test MSE 7.762324664224293 Test RE 1.3316925250192053\n",
      "37 Train Loss 17.73084 Test MSE 7.206274584441581 Test RE 1.2831087405507606\n",
      "38 Train Loss 16.787712 Test MSE 7.6237330533271965 Test RE 1.3197506992275954\n",
      "39 Train Loss 16.412603 Test MSE 7.595792279897183 Test RE 1.317330054157615\n",
      "40 Train Loss 15.411941 Test MSE 7.492700868167168 Test RE 1.308359998276029\n",
      "41 Train Loss 13.8235035 Test MSE 6.880597837032091 Test RE 1.253779450827892\n",
      "42 Train Loss 12.281576 Test MSE 6.4302141398436685 Test RE 1.2120506765819836\n",
      "43 Train Loss 11.586694 Test MSE 6.496108282497161 Test RE 1.2182451414296684\n",
      "44 Train Loss 10.670639 Test MSE 6.131993527824516 Test RE 1.183610758841443\n",
      "45 Train Loss 10.189657 Test MSE 5.891429197222215 Test RE 1.1601613459977242\n",
      "46 Train Loss 9.720184 Test MSE 5.755785810704653 Test RE 1.1467278823826206\n",
      "47 Train Loss 9.296725 Test MSE 5.406659732395351 Test RE 1.11140559651446\n",
      "48 Train Loss 8.978497 Test MSE 5.405952638030727 Test RE 1.111332918153968\n",
      "49 Train Loss 8.714257 Test MSE 5.435595040130645 Test RE 1.1143756327683139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 8.480492 Test MSE 5.424905853315646 Test RE 1.1132793745693108\n",
      "51 Train Loss 8.267812 Test MSE 5.44833535902435 Test RE 1.1156808432642553\n",
      "52 Train Loss 8.05507 Test MSE 5.483228837323656 Test RE 1.1192477908225662\n",
      "53 Train Loss 7.870286 Test MSE 5.410648954904437 Test RE 1.1118155378570724\n",
      "54 Train Loss 7.7204075 Test MSE 5.383419365858388 Test RE 1.1090143520736122\n",
      "55 Train Loss 7.5462236 Test MSE 5.316267930789426 Test RE 1.1020758622398839\n",
      "56 Train Loss 7.407829 Test MSE 5.286403898693503 Test RE 1.098976057934953\n",
      "57 Train Loss 7.287737 Test MSE 5.305694050450606 Test RE 1.100979320579539\n",
      "58 Train Loss 7.1795125 Test MSE 5.332740009119057 Test RE 1.1037818936222386\n",
      "59 Train Loss 7.0568223 Test MSE 5.349738229390585 Test RE 1.1055396579404804\n",
      "60 Train Loss 7.0088835 Test MSE 5.338621215296892 Test RE 1.1043903781969693\n",
      "61 Train Loss 6.9579806 Test MSE 5.352992604383392 Test RE 1.1058758700563949\n",
      "62 Train Loss 6.859977 Test MSE 5.3712000972399245 Test RE 1.10775501838739\n",
      "63 Train Loss 6.7927713 Test MSE 5.386102369945614 Test RE 1.1092906745367384\n",
      "64 Train Loss 6.705991 Test MSE 5.348564337875372 Test RE 1.1054183571618796\n",
      "65 Train Loss 6.5964518 Test MSE 5.327288575351229 Test RE 1.1032175746751394\n",
      "66 Train Loss 6.534076 Test MSE 5.3768749662656905 Test RE 1.1083400557125072\n",
      "67 Train Loss 6.462226 Test MSE 5.440376808473265 Test RE 1.1148656908639454\n",
      "68 Train Loss 6.3722687 Test MSE 5.494095997910703 Test RE 1.1203563552604066\n",
      "69 Train Loss 6.252136 Test MSE 5.522096139643385 Test RE 1.123207622287793\n",
      "70 Train Loss 6.0082254 Test MSE 5.427827515601468 Test RE 1.1135791206506926\n",
      "71 Train Loss 5.8029413 Test MSE 5.43467257703049 Test RE 1.1142810696146286\n",
      "72 Train Loss 5.377643 Test MSE 5.428750182183621 Test RE 1.1136737642790921\n",
      "73 Train Loss 4.438549 Test MSE 4.956407445267028 Test RE 1.0641223395840018\n",
      "74 Train Loss 3.7599878 Test MSE 4.909849779981916 Test RE 1.059112668091182\n",
      "75 Train Loss 2.8880327 Test MSE 4.549310425135413 Test RE 1.0194850143926555\n",
      "76 Train Loss 2.263655 Test MSE 4.383802507371908 Test RE 1.0007683237406948\n",
      "77 Train Loss 2.0358388 Test MSE 4.425078977895867 Test RE 1.00546874114177\n",
      "78 Train Loss 1.9026749 Test MSE 4.349202615382395 Test RE 0.9968111346766626\n",
      "79 Train Loss 1.8179955 Test MSE 4.365272136664278 Test RE 0.9986509557043202\n",
      "80 Train Loss 1.7193763 Test MSE 4.2810188289733535 Test RE 0.9889666106722274\n",
      "81 Train Loss 1.6575849 Test MSE 4.301559701204684 Test RE 0.9913363651995762\n",
      "82 Train Loss 1.6044688 Test MSE 4.327423091982065 Test RE 0.9943121341666087\n",
      "83 Train Loss 1.5232344 Test MSE 4.353025540004718 Test RE 0.9972491341367846\n",
      "84 Train Loss 1.4579666 Test MSE 4.351855638953525 Test RE 0.9971151168655389\n",
      "85 Train Loss 1.425751 Test MSE 4.354337190726192 Test RE 0.9973993680389839\n",
      "86 Train Loss 1.3841277 Test MSE 4.33050568300583 Test RE 0.9946662146377084\n",
      "87 Train Loss 1.3486722 Test MSE 4.314123763871245 Test RE 0.9927830649426928\n",
      "88 Train Loss 1.3187186 Test MSE 4.258119282096393 Test RE 0.9863180292847005\n",
      "89 Train Loss 1.2805483 Test MSE 4.27602975171902 Test RE 0.9883901743866673\n",
      "90 Train Loss 1.2477641 Test MSE 4.186015377553912 Test RE 0.9779315779983444\n",
      "91 Train Loss 1.2172841 Test MSE 4.090560787320411 Test RE 0.9667172890163253\n",
      "92 Train Loss 1.1884606 Test MSE 4.030182675127877 Test RE 0.9595562226611618\n",
      "93 Train Loss 1.1666578 Test MSE 4.015807306809812 Test RE 0.9578433602740688\n",
      "94 Train Loss 1.1356976 Test MSE 3.961054057705288 Test RE 0.9512911248440996\n",
      "95 Train Loss 1.11151 Test MSE 3.9134744388972487 Test RE 0.9455604769749485\n",
      "96 Train Loss 1.0847799 Test MSE 3.8810748702851696 Test RE 0.9416382048288785\n",
      "97 Train Loss 1.0620883 Test MSE 3.8266501881729442 Test RE 0.935012553724567\n",
      "98 Train Loss 1.0314677 Test MSE 3.815363724154438 Test RE 0.9336326551365867\n",
      "99 Train Loss 1.0123984 Test MSE 3.847027785625087 Test RE 0.9374988028249369\n",
      "Training time: 71.31\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.396954 Test MSE 8.508728626707926 Test RE 1.3942491764270972\n",
      "1 Train Loss 56.624954 Test MSE 8.604864963790256 Test RE 1.402103553361582\n",
      "2 Train Loss 54.016735 Test MSE 9.465720910077565 Test RE 1.4705673114366962\n",
      "3 Train Loss 50.37594 Test MSE 8.165603555394343 Test RE 1.3658474799673037\n",
      "4 Train Loss 45.632294 Test MSE 8.200940094311695 Test RE 1.3687996328106355\n",
      "5 Train Loss 44.675583 Test MSE 8.069282261850327 Test RE 1.3577678278776275\n",
      "6 Train Loss 44.404205 Test MSE 8.155242715714804 Test RE 1.3649806843617462\n",
      "7 Train Loss 44.15473 Test MSE 8.224293905726691 Test RE 1.3707472121484492\n",
      "8 Train Loss 43.926216 Test MSE 8.244284372428352 Test RE 1.3724121116435133\n",
      "9 Train Loss 43.838684 Test MSE 8.297842242271807 Test RE 1.3768627392421642\n",
      "10 Train Loss 43.725082 Test MSE 8.314780839999168 Test RE 1.3782673353712245\n",
      "11 Train Loss 43.618645 Test MSE 8.491291074918873 Test RE 1.3928197759665863\n",
      "12 Train Loss 43.11342 Test MSE 8.363726625099783 Test RE 1.3823180368378725\n",
      "13 Train Loss 42.759632 Test MSE 8.322536190359942 Test RE 1.3789099533186706\n",
      "14 Train Loss 42.51572 Test MSE 8.220281962459213 Test RE 1.370412835061187\n",
      "15 Train Loss 42.207455 Test MSE 8.206469285136823 Test RE 1.3692609871822616\n",
      "16 Train Loss 41.9243 Test MSE 8.057979091273713 Test RE 1.356816537598893\n",
      "17 Train Loss 41.460472 Test MSE 8.061744363329012 Test RE 1.357133502105515\n",
      "18 Train Loss 40.800484 Test MSE 8.13915857574709 Test RE 1.3636339815860328\n",
      "19 Train Loss 39.08588 Test MSE 7.814680853356606 Test RE 1.3361760512688117\n",
      "20 Train Loss 36.965584 Test MSE 6.812309047264091 Test RE 1.2475421599014134\n",
      "21 Train Loss 34.589188 Test MSE 5.907353582989935 Test RE 1.1617282314497357\n",
      "22 Train Loss 31.550846 Test MSE 6.053678882019485 Test RE 1.1760282392090633\n",
      "23 Train Loss 30.566048 Test MSE 6.150058522505192 Test RE 1.185352948979982\n",
      "24 Train Loss 29.845978 Test MSE 6.301181084378686 Test RE 1.1998281322778677\n",
      "25 Train Loss 29.20865 Test MSE 6.189411021337623 Test RE 1.1891392721936398\n",
      "26 Train Loss 28.519943 Test MSE 5.974969369431304 Test RE 1.168357906588688\n",
      "27 Train Loss 28.247536 Test MSE 6.188608294207806 Test RE 1.1890621578039555\n",
      "28 Train Loss 27.662592 Test MSE 5.7847111921076415 Test RE 1.1496056799515686\n",
      "29 Train Loss 25.066586 Test MSE 5.110048515971539 Test RE 1.0804895526378606\n",
      "30 Train Loss 24.385899 Test MSE 5.021003486347904 Test RE 1.0710341578441012\n",
      "31 Train Loss 23.096176 Test MSE 5.143687913100356 Test RE 1.0840401446836159\n",
      "32 Train Loss 22.093418 Test MSE 4.990862623497363 Test RE 1.0678146334597975\n",
      "33 Train Loss 21.664583 Test MSE 4.970510984679575 Test RE 1.0656352529576232\n",
      "34 Train Loss 20.919342 Test MSE 4.960468595085105 Test RE 1.0645582072374211\n",
      "35 Train Loss 20.473606 Test MSE 4.834383691756524 Test RE 1.0509416849002562\n",
      "36 Train Loss 20.02791 Test MSE 4.650967650299148 Test RE 1.0308126029103104\n",
      "37 Train Loss 19.203081 Test MSE 4.509921234335823 Test RE 1.015061927564957\n",
      "38 Train Loss 18.89681 Test MSE 4.578921179246746 Test RE 1.022797467785221\n",
      "39 Train Loss 18.52141 Test MSE 4.477340218953784 Test RE 1.0113887264901331\n",
      "40 Train Loss 18.182652 Test MSE 4.355038286548182 Test RE 0.9974796609003077\n",
      "41 Train Loss 18.078402 Test MSE 4.449239863647156 Test RE 1.0082099290185778\n",
      "42 Train Loss 17.939125 Test MSE 4.408878762006595 Test RE 1.0036265427939273\n",
      "43 Train Loss 17.807594 Test MSE 4.379793069463159 Test RE 1.000310566310558\n",
      "44 Train Loss 17.54955 Test MSE 4.438765232806086 Test RE 1.0070224396876433\n",
      "45 Train Loss 17.360573 Test MSE 4.461727580708201 Test RE 1.0096238130539623\n",
      "46 Train Loss 17.067387 Test MSE 4.364419987161408 Test RE 0.9985534770793902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Train Loss 16.831697 Test MSE 4.1255033205196225 Test RE 0.9708374721617176\n",
      "48 Train Loss 16.542042 Test MSE 4.025784546087654 Test RE 0.9590324989933513\n",
      "49 Train Loss 16.376036 Test MSE 4.03845764490532 Test RE 0.9605408215872914\n",
      "50 Train Loss 16.083174 Test MSE 4.159993088792352 Test RE 0.9748871923108973\n",
      "51 Train Loss 15.634953 Test MSE 4.289020882254633 Test RE 0.9898904642210016\n",
      "52 Train Loss 15.250624 Test MSE 4.437365291999489 Test RE 1.0068636249151857\n",
      "53 Train Loss 14.9627285 Test MSE 4.488708794034377 Test RE 1.0126719391326335\n",
      "54 Train Loss 14.705796 Test MSE 4.232330673816467 Test RE 0.9833267558403823\n",
      "55 Train Loss 14.3561535 Test MSE 4.536163060095816 Test RE 1.0180108085948745\n",
      "56 Train Loss 13.961285 Test MSE 4.527417480532378 Test RE 1.0170289887431467\n",
      "57 Train Loss 13.666412 Test MSE 4.4415667978378846 Test RE 1.0073401850158408\n",
      "58 Train Loss 13.373888 Test MSE 4.382372704548473 Test RE 1.0006051072105564\n",
      "59 Train Loss 12.90464 Test MSE 4.27282891023975 Test RE 0.9880201731565419\n",
      "60 Train Loss 12.555643 Test MSE 4.15373457807889 Test RE 0.9741535807003301\n",
      "61 Train Loss 12.056061 Test MSE 4.029952544062759 Test RE 0.959528826031057\n",
      "62 Train Loss 11.608519 Test MSE 3.641155056045733 Test RE 0.9120688994370694\n",
      "63 Train Loss 10.700635 Test MSE 3.229203932563994 Test RE 0.8589260938229175\n",
      "64 Train Loss 9.155996 Test MSE 2.915493750319681 Test RE 0.8161389739569996\n",
      "65 Train Loss 7.8777018 Test MSE 2.741837903436733 Test RE 0.7914599589755371\n",
      "66 Train Loss 7.045727 Test MSE 2.485461534773798 Test RE 0.7535491485445471\n",
      "67 Train Loss 6.8250813 Test MSE 2.4827985462056916 Test RE 0.7531453542122\n",
      "68 Train Loss 6.3236074 Test MSE 2.395182014598475 Test RE 0.7397369651486253\n",
      "69 Train Loss 5.546862 Test MSE 2.1175632470529977 Test RE 0.6955466377616496\n",
      "70 Train Loss 5.047186 Test MSE 1.8260353259375095 Test RE 0.6458960785213559\n",
      "71 Train Loss 4.592823 Test MSE 1.5630203849081838 Test RE 0.5975721946718437\n",
      "72 Train Loss 4.1372437 Test MSE 1.1837005056042884 Test RE 0.5200306926738857\n",
      "73 Train Loss 3.756037 Test MSE 1.017583962726012 Test RE 0.48216223012211656\n",
      "74 Train Loss 3.441229 Test MSE 0.9920389962727625 Test RE 0.47607177314973115\n",
      "75 Train Loss 3.2446134 Test MSE 0.9523507778900708 Test RE 0.4664515394264731\n",
      "76 Train Loss 3.0274448 Test MSE 0.9456518219163165 Test RE 0.46480810469531636\n",
      "77 Train Loss 2.8751357 Test MSE 0.926982547108206 Test RE 0.46019705915120235\n",
      "78 Train Loss 2.6294518 Test MSE 0.8136681363394165 Test RE 0.4311533003527633\n",
      "79 Train Loss 2.4705846 Test MSE 0.7393014250152632 Test RE 0.41097824375709624\n",
      "80 Train Loss 2.3667889 Test MSE 0.6744665857330461 Test RE 0.3925439422412382\n",
      "81 Train Loss 2.2704802 Test MSE 0.5598592379289691 Test RE 0.3576411515797096\n",
      "82 Train Loss 2.2337842 Test MSE 0.5173812655092054 Test RE 0.34380596680420805\n",
      "83 Train Loss 2.1729276 Test MSE 0.47250613879838615 Test RE 0.3285578045748325\n",
      "84 Train Loss 1.9822665 Test MSE 0.3987654866562298 Test RE 0.3018330843749344\n",
      "85 Train Loss 1.8356895 Test MSE 0.2794572260975723 Test RE 0.2526770118137637\n",
      "86 Train Loss 1.7357957 Test MSE 0.25617928836788467 Test RE 0.2419246200957501\n",
      "87 Train Loss 1.6059885 Test MSE 0.25110994455355967 Test RE 0.23951902567148414\n",
      "88 Train Loss 1.5497727 Test MSE 0.21477550523577704 Test RE 0.22151362026114116\n",
      "89 Train Loss 1.475422 Test MSE 0.18077499503698286 Test RE 0.20322505016161818\n",
      "90 Train Loss 1.3305402 Test MSE 0.16372840490148863 Test RE 0.19340605908776534\n",
      "91 Train Loss 1.1269569 Test MSE 0.1556836140933574 Test RE 0.18859471257591337\n",
      "92 Train Loss 0.9265312 Test MSE 0.11008488524498772 Test RE 0.15858857884458352\n",
      "93 Train Loss 0.79048616 Test MSE 0.08350368772512161 Test RE 0.1381213733702451\n",
      "94 Train Loss 0.7308468 Test MSE 0.07770434110901694 Test RE 0.1332387965554514\n",
      "95 Train Loss 0.61909485 Test MSE 0.08565969680362039 Test RE 0.13989311048773542\n",
      "96 Train Loss 0.54449487 Test MSE 0.07864626446231451 Test RE 0.1340439169232546\n",
      "97 Train Loss 0.52000433 Test MSE 0.07684346618979836 Test RE 0.13249867444549304\n",
      "98 Train Loss 0.5015477 Test MSE 0.07651668868640668 Test RE 0.13221664841803132\n",
      "99 Train Loss 0.48933977 Test MSE 0.0731101361467267 Test RE 0.12923997240227142\n",
      "Training time: 74.38\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.83052 Test MSE 8.651512093849915 Test RE 1.4058988312257792\n",
      "1 Train Loss 57.161503 Test MSE 8.372939303120251 Test RE 1.3830791417031927\n",
      "2 Train Loss 55.565556 Test MSE 8.309551379241073 Test RE 1.3778338465807325\n",
      "3 Train Loss 48.84516 Test MSE 8.431437730541642 Test RE 1.3879022465524673\n",
      "4 Train Loss 46.481483 Test MSE 8.349390413451783 Test RE 1.3811328173626296\n",
      "5 Train Loss 45.661835 Test MSE 8.718670083147739 Test RE 1.4113449783859067\n",
      "6 Train Loss 45.216652 Test MSE 8.609859800101765 Test RE 1.4025104314342198\n",
      "7 Train Loss 44.47566 Test MSE 8.602625742235427 Test RE 1.4019211086171035\n",
      "8 Train Loss 44.26779 Test MSE 8.497407601103982 Test RE 1.393321330144106\n",
      "9 Train Loss 43.94347 Test MSE 8.21140235117684 Test RE 1.3696724698709775\n",
      "10 Train Loss 43.835655 Test MSE 8.378162343516218 Test RE 1.3835104569052796\n",
      "11 Train Loss 43.687447 Test MSE 8.449327482045561 Test RE 1.389373885817352\n",
      "12 Train Loss 43.483597 Test MSE 8.60814284757914 Test RE 1.402370582241413\n",
      "13 Train Loss 43.361267 Test MSE 8.857322691210285 Test RE 1.4225229898664888\n",
      "14 Train Loss 42.53282 Test MSE 8.842646304414307 Test RE 1.4213439567707395\n",
      "15 Train Loss 42.375397 Test MSE 8.852132667123122 Test RE 1.4221061590317703\n",
      "16 Train Loss 42.15776 Test MSE 8.800763394403173 Test RE 1.4179738864927836\n",
      "17 Train Loss 41.727142 Test MSE 9.078292877972096 Test RE 1.4401580458354417\n",
      "18 Train Loss 41.587418 Test MSE 9.037488685191693 Test RE 1.4369178624490535\n",
      "19 Train Loss 41.120396 Test MSE 9.085944046583071 Test RE 1.4407647993014048\n",
      "20 Train Loss 40.541744 Test MSE 8.850587998922173 Test RE 1.4219820771815734\n",
      "21 Train Loss 39.38968 Test MSE 8.671040326139854 Test RE 1.4074846374632433\n",
      "22 Train Loss 35.79172 Test MSE 8.81868978601891 Test RE 1.4194172967439371\n",
      "23 Train Loss 34.123283 Test MSE 8.54945346265918 Test RE 1.3975818006176037\n",
      "24 Train Loss 33.14305 Test MSE 8.559536628374548 Test RE 1.3984057068702271\n",
      "25 Train Loss 32.37723 Test MSE 8.554937654009432 Test RE 1.3980299799838054\n",
      "26 Train Loss 32.130276 Test MSE 8.378616552920722 Test RE 1.3835479588608541\n",
      "27 Train Loss 31.772646 Test MSE 8.139975393999967 Test RE 1.3637024047020168\n",
      "28 Train Loss 31.191124 Test MSE 8.039255092684868 Test RE 1.3552392310572448\n",
      "29 Train Loss 30.589354 Test MSE 7.950392175780957 Test RE 1.347728263912156\n",
      "30 Train Loss 30.029484 Test MSE 8.011744912982248 Test RE 1.3529184423541951\n",
      "31 Train Loss 29.471197 Test MSE 8.326601381943151 Test RE 1.3792466805290597\n",
      "32 Train Loss 28.27047 Test MSE 8.463357628568495 Test RE 1.3905269381663659\n",
      "33 Train Loss 27.12873 Test MSE 8.3291654268566 Test RE 1.3794590227601118\n",
      "34 Train Loss 25.609413 Test MSE 8.032422201992278 Test RE 1.3546631720869982\n",
      "35 Train Loss 23.494629 Test MSE 8.145763198697008 Test RE 1.3641871383946031\n",
      "36 Train Loss 20.692696 Test MSE 7.763643162646034 Test RE 1.3318056200013026\n",
      "37 Train Loss 18.37342 Test MSE 7.988749559739401 Test RE 1.3509754702834231\n",
      "38 Train Loss 16.443466 Test MSE 7.723287052369776 Test RE 1.328339687820328\n",
      "39 Train Loss 14.749805 Test MSE 7.1162961977202475 Test RE 1.2750730552811451\n",
      "40 Train Loss 13.597128 Test MSE 7.457457095612985 Test RE 1.3052792737697747\n",
      "41 Train Loss 12.652996 Test MSE 7.563376920428803 Test RE 1.3145161684569442\n",
      "42 Train Loss 11.524305 Test MSE 7.240952715034096 Test RE 1.2861923317689292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 10.91243 Test MSE 7.18412586574156 Test RE 1.2811353849222793\n",
      "44 Train Loss 9.506787 Test MSE 7.268695954015433 Test RE 1.2886539572312596\n",
      "45 Train Loss 7.5489807 Test MSE 6.513429824631738 Test RE 1.2198682544981498\n",
      "46 Train Loss 5.861576 Test MSE 5.8488168969185415 Test RE 1.1559580482376925\n",
      "47 Train Loss 4.983461 Test MSE 5.318754864575682 Test RE 1.1023336059497766\n",
      "48 Train Loss 4.067572 Test MSE 5.107783568574968 Test RE 1.0802500712290168\n",
      "49 Train Loss 3.6202822 Test MSE 5.160825856274335 Test RE 1.085844566873189\n",
      "50 Train Loss 3.3454852 Test MSE 5.048791462115984 Test RE 1.0739938059233378\n",
      "51 Train Loss 3.0162344 Test MSE 4.689461679734031 Test RE 1.0350696057423792\n",
      "52 Train Loss 2.8599925 Test MSE 4.49377747107921 Test RE 1.0132435354465674\n",
      "53 Train Loss 2.542251 Test MSE 4.269561368085333 Test RE 0.9876423186860253\n",
      "54 Train Loss 2.3576488 Test MSE 4.322948239870145 Test RE 0.9937979077436234\n",
      "55 Train Loss 1.9768087 Test MSE 4.1365678912721355 Test RE 0.9721384900355725\n",
      "56 Train Loss 1.7929223 Test MSE 4.259440410807783 Test RE 0.9864710254697228\n",
      "57 Train Loss 1.6809494 Test MSE 4.251257563043693 Test RE 0.9855230109372775\n",
      "58 Train Loss 1.6054504 Test MSE 4.341376579442727 Test RE 0.9959138906335437\n",
      "59 Train Loss 1.531147 Test MSE 4.440789228042625 Test RE 1.007252005368715\n",
      "60 Train Loss 1.4538137 Test MSE 4.4564299124329025 Test RE 1.0090242425308633\n",
      "61 Train Loss 1.3880115 Test MSE 4.503675990268889 Test RE 1.0143588658807663\n",
      "62 Train Loss 1.3197982 Test MSE 4.459818135206392 Test RE 1.0094077501146912\n",
      "63 Train Loss 1.2710018 Test MSE 4.532736152581501 Test RE 1.0176262007252153\n",
      "64 Train Loss 1.2267807 Test MSE 4.505515542196915 Test RE 1.0145660050387895\n",
      "65 Train Loss 1.1557627 Test MSE 4.451204213095963 Test RE 1.008432467938826\n",
      "66 Train Loss 1.1220347 Test MSE 4.336063337119489 Test RE 0.9953042738733109\n",
      "67 Train Loss 1.0885153 Test MSE 4.395450775798693 Test RE 1.0020970200809454\n",
      "68 Train Loss 1.0507 Test MSE 4.382223798453038 Test RE 1.0005881075764174\n",
      "69 Train Loss 0.98043114 Test MSE 4.353146278632206 Test RE 0.9972629642482443\n",
      "70 Train Loss 0.92288816 Test MSE 4.2979508749452595 Test RE 0.9909204333486222\n",
      "71 Train Loss 0.87844 Test MSE 4.291954817841209 Test RE 0.990228977186639\n",
      "72 Train Loss 0.8100585 Test MSE 4.357644273882304 Test RE 0.9977780544441293\n",
      "73 Train Loss 0.7329472 Test MSE 4.244957421634445 Test RE 0.984792493405238\n",
      "74 Train Loss 0.68259597 Test MSE 4.381644654481143 Test RE 1.0005219877540867\n",
      "75 Train Loss 0.6294184 Test MSE 4.373322384984151 Test RE 0.9995713662613743\n",
      "76 Train Loss 0.58866644 Test MSE 4.427450592593683 Test RE 1.005738144811008\n",
      "77 Train Loss 0.5547416 Test MSE 4.400502687451352 Test RE 1.0026727348436109\n",
      "78 Train Loss 0.5359441 Test MSE 4.380914614155895 Test RE 1.0004386341412346\n",
      "79 Train Loss 0.5173428 Test MSE 4.348304674495001 Test RE 0.9967082280339487\n",
      "80 Train Loss 0.50796485 Test MSE 4.323516803535575 Test RE 0.9938632588387848\n",
      "81 Train Loss 0.49842384 Test MSE 4.306876611533386 Test RE 0.9919488429034418\n",
      "82 Train Loss 0.4845908 Test MSE 4.358013378414745 Test RE 0.9978203108309252\n",
      "83 Train Loss 0.47483823 Test MSE 4.317547824840945 Test RE 0.9931769659633025\n",
      "84 Train Loss 0.4670654 Test MSE 4.317969455800655 Test RE 0.9932254592228366\n",
      "85 Train Loss 0.45917752 Test MSE 4.308856498020407 Test RE 0.9921768179106931\n",
      "86 Train Loss 0.45119253 Test MSE 4.269110344986336 Test RE 0.9875901515867069\n",
      "87 Train Loss 0.44579518 Test MSE 4.263900289663594 Test RE 0.9869873362762551\n",
      "88 Train Loss 0.4405439 Test MSE 4.2954117403966015 Test RE 0.9906276831402667\n",
      "89 Train Loss 0.4353315 Test MSE 4.310014148126254 Test RE 0.9923100918386706\n",
      "90 Train Loss 0.42535913 Test MSE 4.364152777431761 Test RE 0.9985229086087124\n",
      "91 Train Loss 0.41928524 Test MSE 4.414784119179795 Test RE 1.0042984585162968\n",
      "92 Train Loss 0.41447115 Test MSE 4.423124761130927 Test RE 1.0052466975505718\n",
      "93 Train Loss 0.40798232 Test MSE 4.395132152820393 Test RE 1.0020606987865117\n",
      "94 Train Loss 0.40473545 Test MSE 4.390747241400534 Test RE 1.0015607088285226\n",
      "95 Train Loss 0.3980707 Test MSE 4.397082362638947 Test RE 1.0022829915198042\n",
      "96 Train Loss 0.39325 Test MSE 4.417998864958796 Test RE 1.0046640456679323\n",
      "97 Train Loss 0.389257 Test MSE 4.436743213051336 Test RE 1.0067930458015493\n",
      "98 Train Loss 0.38325852 Test MSE 4.424530362522525 Test RE 1.0054064108749248\n",
      "99 Train Loss 0.37955084 Test MSE 4.408523969597344 Test RE 1.003586159936716\n",
      "Training time: 72.48\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.02627 Test MSE 8.43649274934512 Test RE 1.3883182385168178\n",
      "1 Train Loss 58.767014 Test MSE 8.574904164860596 Test RE 1.3996604718566643\n",
      "2 Train Loss 56.739017 Test MSE 8.600625795944458 Test RE 1.4017581391947465\n",
      "3 Train Loss 51.98542 Test MSE 8.59545702785817 Test RE 1.4013368645220854\n",
      "4 Train Loss 48.95054 Test MSE 8.770252542261755 Test RE 1.4155138070772793\n",
      "5 Train Loss 47.07051 Test MSE 8.660905415950904 Test RE 1.4066618468562428\n",
      "6 Train Loss 46.450935 Test MSE 8.54126085404012 Test RE 1.3969120159901505\n",
      "7 Train Loss 46.099762 Test MSE 8.500471173122234 Test RE 1.3935724747151779\n",
      "8 Train Loss 45.95787 Test MSE 8.314566783251658 Test RE 1.3782495941145687\n",
      "9 Train Loss 45.85459 Test MSE 8.397905984452002 Test RE 1.385139660233771\n",
      "10 Train Loss 45.752098 Test MSE 8.35354445454126 Test RE 1.3814763495700455\n",
      "11 Train Loss 45.481438 Test MSE 8.566843763411155 Test RE 1.3990024774609198\n",
      "12 Train Loss 42.849716 Test MSE 8.313273579501555 Test RE 1.3781424071197346\n",
      "13 Train Loss 40.677635 Test MSE 7.9091719352335215 Test RE 1.3442299536216258\n",
      "14 Train Loss 40.010757 Test MSE 7.867633927432235 Test RE 1.3406954407986966\n",
      "15 Train Loss 39.547054 Test MSE 7.730283666262479 Test RE 1.3289412306573296\n",
      "16 Train Loss 39.30694 Test MSE 7.813702501084854 Test RE 1.336092407943041\n",
      "17 Train Loss 38.833775 Test MSE 7.759161120822341 Test RE 1.331421131035426\n",
      "18 Train Loss 38.303776 Test MSE 7.7376093908089745 Test RE 1.3295707775418306\n",
      "19 Train Loss 37.654083 Test MSE 7.475436986601722 Test RE 1.3068518373126787\n",
      "20 Train Loss 37.00553 Test MSE 7.247299263309231 Test RE 1.286755869067072\n",
      "21 Train Loss 36.0241 Test MSE 7.516514376622162 Test RE 1.3104374818140774\n",
      "22 Train Loss 35.04911 Test MSE 7.4190183419356615 Test RE 1.3019109587804099\n",
      "23 Train Loss 34.061245 Test MSE 7.552239693619155 Test RE 1.313547985971309\n",
      "24 Train Loss 33.035767 Test MSE 7.383898594458811 Test RE 1.2988258455981962\n",
      "25 Train Loss 32.714798 Test MSE 7.44607286770945 Test RE 1.3042826021245277\n",
      "26 Train Loss 32.481743 Test MSE 7.279225163456923 Test RE 1.2895869717172266\n",
      "27 Train Loss 32.20434 Test MSE 7.278141272016132 Test RE 1.289490957080636\n",
      "28 Train Loss 31.964506 Test MSE 7.364739296646383 Test RE 1.2971396933507118\n",
      "29 Train Loss 31.678226 Test MSE 7.298842901627248 Test RE 1.2913235409723343\n",
      "30 Train Loss 31.197495 Test MSE 7.171588446717108 Test RE 1.2800170063401117\n",
      "31 Train Loss 30.719296 Test MSE 7.336821064330907 Test RE 1.294678762224327\n",
      "32 Train Loss 29.728882 Test MSE 7.435832509219105 Test RE 1.303385423373234\n",
      "33 Train Loss 29.302887 Test MSE 7.412789520064632 Test RE 1.301364318113039\n",
      "34 Train Loss 28.575874 Test MSE 7.513681715227531 Test RE 1.310190533875731\n",
      "35 Train Loss 27.692009 Test MSE 7.782210018189616 Test RE 1.3333971844054744\n",
      "36 Train Loss 27.193321 Test MSE 7.888158474779876 Test RE 1.3424430592345427\n",
      "37 Train Loss 26.72578 Test MSE 7.841116609446669 Test RE 1.3384341730314704\n",
      "38 Train Loss 26.376781 Test MSE 7.813490403487216 Test RE 1.3360742741637612\n",
      "39 Train Loss 25.617973 Test MSE 7.7455756993319005 Test RE 1.3302550357976497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 25.221718 Test MSE 7.637194439111968 Test RE 1.3209153411286236\n",
      "41 Train Loss 24.920496 Test MSE 7.530105445979404 Test RE 1.3116216878258715\n",
      "42 Train Loss 24.019844 Test MSE 7.446395933356421 Test RE 1.3043108965247936\n",
      "43 Train Loss 23.414507 Test MSE 7.321917054665297 Test RE 1.2933630892644539\n",
      "44 Train Loss 22.907478 Test MSE 7.433613155164517 Test RE 1.3031908997879509\n",
      "45 Train Loss 22.359169 Test MSE 6.987870957757873 Test RE 1.263515280532109\n",
      "46 Train Loss 21.862131 Test MSE 6.991725940095711 Test RE 1.2638637527302226\n",
      "47 Train Loss 21.585978 Test MSE 6.990301204579551 Test RE 1.263734974562026\n",
      "48 Train Loss 21.291384 Test MSE 7.014974756581341 Test RE 1.2659633023217702\n",
      "49 Train Loss 20.798973 Test MSE 6.638958031651237 Test RE 1.2315669390200619\n",
      "50 Train Loss 19.281708 Test MSE 6.127621469217219 Test RE 1.1831887314606961\n",
      "51 Train Loss 18.190407 Test MSE 6.1910533706704065 Test RE 1.1892970297367758\n",
      "52 Train Loss 17.62844 Test MSE 6.0463375532010515 Test RE 1.1753149350128278\n",
      "53 Train Loss 17.408741 Test MSE 6.057877134087707 Test RE 1.176435958826937\n",
      "54 Train Loss 17.199158 Test MSE 5.979259642317273 Test RE 1.1687772957480576\n",
      "55 Train Loss 17.032192 Test MSE 5.85459190329539 Test RE 1.1565285925183224\n",
      "56 Train Loss 16.945568 Test MSE 5.9514972395332215 Test RE 1.1660607538405623\n",
      "57 Train Loss 16.772034 Test MSE 6.024711761942475 Test RE 1.1732111917834411\n",
      "58 Train Loss 16.532875 Test MSE 5.802590389864951 Test RE 1.1513808912956471\n",
      "59 Train Loss 16.368816 Test MSE 5.673277155803912 Test RE 1.138479095444696\n",
      "60 Train Loss 16.234507 Test MSE 5.675084579328887 Test RE 1.138660432437405\n",
      "61 Train Loss 15.973581 Test MSE 5.69430159573176 Test RE 1.1405866736448416\n",
      "62 Train Loss 15.891401 Test MSE 5.630599748193841 Test RE 1.134188889331877\n",
      "63 Train Loss 15.737497 Test MSE 5.592750902720837 Test RE 1.130370457424308\n",
      "64 Train Loss 15.593745 Test MSE 5.496666117399244 Test RE 1.1206183740741844\n",
      "65 Train Loss 15.496514 Test MSE 5.507838880704535 Test RE 1.1217567048059485\n",
      "66 Train Loss 15.400051 Test MSE 5.4960401809312245 Test RE 1.120554566680544\n",
      "67 Train Loss 15.281474 Test MSE 5.436086001507939 Test RE 1.1144259587250558\n",
      "68 Train Loss 15.167334 Test MSE 5.530908956034715 Test RE 1.1241035389916556\n",
      "69 Train Loss 15.022869 Test MSE 5.399147883968356 Test RE 1.110633251603504\n",
      "70 Train Loss 14.8945675 Test MSE 5.319355258424844 Test RE 1.1023958212292242\n",
      "71 Train Loss 14.777386 Test MSE 5.365409154366655 Test RE 1.1071576960097838\n",
      "72 Train Loss 14.715996 Test MSE 5.290752541635852 Test RE 1.0994279787634162\n",
      "73 Train Loss 14.6543045 Test MSE 5.196334275246105 Test RE 1.0895736725492984\n",
      "74 Train Loss 14.528084 Test MSE 5.078687748791762 Test RE 1.0771689256386252\n",
      "75 Train Loss 14.385542 Test MSE 5.1821592388843865 Test RE 1.088086538264083\n",
      "76 Train Loss 14.316912 Test MSE 5.108739979717848 Test RE 1.0803512026524618\n",
      "77 Train Loss 14.283427 Test MSE 5.147114957401253 Test RE 1.0844012119828705\n",
      "78 Train Loss 14.242008 Test MSE 5.1417082881615555 Test RE 1.0838315201072015\n",
      "79 Train Loss 14.189128 Test MSE 5.080093183369219 Test RE 1.0773179587952002\n",
      "80 Train Loss 14.02004 Test MSE 4.868249235558614 Test RE 1.0546162587233763\n",
      "81 Train Loss 11.876488 Test MSE 4.133790469303086 Test RE 0.9718120730341889\n",
      "82 Train Loss 10.502323 Test MSE 3.878424656365138 Test RE 0.9413166484391065\n",
      "83 Train Loss 10.006424 Test MSE 3.8959086610088844 Test RE 0.943435998378902\n",
      "84 Train Loss 9.747511 Test MSE 3.948721314882674 Test RE 0.9498090477525487\n",
      "85 Train Loss 9.58294 Test MSE 3.8920408258123125 Test RE 0.9429675632309338\n",
      "86 Train Loss 9.454423 Test MSE 3.8800295563675835 Test RE 0.9415113876660983\n",
      "87 Train Loss 9.209061 Test MSE 3.934512667721839 Test RE 0.9480986632219344\n",
      "88 Train Loss 9.098881 Test MSE 3.9774104280995233 Test RE 0.9532531834547895\n",
      "89 Train Loss 9.076078 Test MSE 4.02122293734442 Test RE 0.9584890060499528\n",
      "90 Train Loss 8.98272 Test MSE 3.9469410898614306 Test RE 0.9495949196441111\n",
      "91 Train Loss 8.712979 Test MSE 3.489758811195045 Test RE 0.8929060518896509\n",
      "92 Train Loss 6.889923 Test MSE 3.2242500659965962 Test RE 0.8582670090322723\n",
      "93 Train Loss 5.795275 Test MSE 3.03656399505502 Test RE 0.8329123073613517\n",
      "94 Train Loss 5.363167 Test MSE 2.889722452507615 Test RE 0.8125238664031663\n",
      "95 Train Loss 4.9824777 Test MSE 2.6865461677906293 Test RE 0.7834390491463722\n",
      "96 Train Loss 4.8889594 Test MSE 2.7641196924346603 Test RE 0.7946693865350545\n",
      "97 Train Loss 4.7554035 Test MSE 2.7327218055808733 Test RE 0.7901431354008169\n",
      "98 Train Loss 4.6790037 Test MSE 2.758121110687732 Test RE 0.7938066383827141\n",
      "99 Train Loss 4.598729 Test MSE 2.747572052741693 Test RE 0.7922871375669236\n",
      "Training time: 75.25\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.765934 Test MSE 8.484546921565402 Test RE 1.3922665470181865\n",
      "1 Train Loss 55.485397 Test MSE 8.593655967968685 Test RE 1.4011900413900686\n",
      "2 Train Loss 55.018017 Test MSE 8.634223340843704 Test RE 1.4044933894588132\n",
      "3 Train Loss 53.653824 Test MSE 9.335054006426295 Test RE 1.4603820211847771\n",
      "4 Train Loss 46.533768 Test MSE 7.210436479958914 Test RE 1.2834792089279314\n",
      "5 Train Loss 42.224945 Test MSE 8.21531995200567 Test RE 1.3699991613377127\n",
      "6 Train Loss 39.887543 Test MSE 7.4638746921373915 Test RE 1.305840789191259\n",
      "7 Train Loss 39.12351 Test MSE 7.670778237115545 Test RE 1.323816451780584\n",
      "8 Train Loss 38.527245 Test MSE 7.428903152197377 Test RE 1.3027779777362694\n",
      "9 Train Loss 36.761692 Test MSE 7.1704438047290155 Test RE 1.2799148518669918\n",
      "10 Train Loss 35.823174 Test MSE 6.889341962146171 Test RE 1.254575873154877\n",
      "11 Train Loss 34.89319 Test MSE 6.735428909161893 Test RE 1.2404826334220953\n",
      "12 Train Loss 32.50193 Test MSE 6.376604766874192 Test RE 1.2069876045386265\n",
      "13 Train Loss 29.95219 Test MSE 5.693892527373928 Test RE 1.140545704064153\n",
      "14 Train Loss 28.033 Test MSE 5.802362174951764 Test RE 1.1513582492637136\n",
      "15 Train Loss 26.295324 Test MSE 5.9320181968141545 Test RE 1.1641509518088593\n",
      "16 Train Loss 24.988953 Test MSE 5.751353089232929 Test RE 1.1462862307540218\n",
      "17 Train Loss 24.465096 Test MSE 5.399210756938443 Test RE 1.1106397182357777\n",
      "18 Train Loss 23.802883 Test MSE 5.005082498348065 Test RE 1.0693347504562947\n",
      "19 Train Loss 23.41724 Test MSE 4.049264538996952 Test RE 0.9618251643488327\n",
      "20 Train Loss 22.394283 Test MSE 4.179929930523008 Test RE 0.9772204822741988\n",
      "21 Train Loss 21.223343 Test MSE 3.592551989232004 Test RE 0.9059611849282101\n",
      "22 Train Loss 19.183065 Test MSE 3.972963939817033 Test RE 0.9527201966687596\n",
      "23 Train Loss 17.173712 Test MSE 3.435264659735265 Test RE 0.8859070567197411\n",
      "24 Train Loss 15.869367 Test MSE 1.89266317066551 Test RE 0.6575741404093675\n",
      "25 Train Loss 13.301963 Test MSE 2.188204797249664 Test RE 0.7070531202800046\n",
      "26 Train Loss 11.584029 Test MSE 1.711644127510323 Test RE 0.6253379671227489\n",
      "27 Train Loss 10.055725 Test MSE 1.1224712720727847 Test RE 0.5064023094766615\n",
      "28 Train Loss 7.571432 Test MSE 0.7664607852865164 Test RE 0.418459113022036\n",
      "29 Train Loss 6.157246 Test MSE 0.5716708214426827 Test RE 0.36139411261306514\n",
      "30 Train Loss 4.911292 Test MSE 0.4133688938366665 Test RE 0.30731018681774636\n",
      "31 Train Loss 3.9251122 Test MSE 0.42823942213630733 Test RE 0.31278893578154043\n",
      "32 Train Loss 2.8630154 Test MSE 0.2524513354316575 Test RE 0.2401579105835467\n",
      "33 Train Loss 2.5333397 Test MSE 0.18152831254243898 Test RE 0.20364804513578783\n",
      "34 Train Loss 2.2826009 Test MSE 0.1907577160462395 Test RE 0.20876087921594919\n",
      "35 Train Loss 2.1532984 Test MSE 0.21610333565891224 Test RE 0.2221973092871812\n",
      "36 Train Loss 2.0925932 Test MSE 0.22464973194349797 Test RE 0.22654840694962336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 1.962998 Test MSE 0.17451200085406088 Test RE 0.19967362811643624\n",
      "38 Train Loss 1.8640833 Test MSE 0.1667773630334607 Test RE 0.1951985609755248\n",
      "39 Train Loss 1.7467983 Test MSE 0.13831030944809175 Test RE 0.17776053012708834\n",
      "40 Train Loss 1.6924437 Test MSE 0.12901426458835857 Test RE 0.17168285463312094\n",
      "41 Train Loss 1.6226387 Test MSE 0.12698046598327997 Test RE 0.17032426304517453\n",
      "42 Train Loss 1.5245163 Test MSE 0.12617360885432766 Test RE 0.16978226490872386\n",
      "43 Train Loss 1.3729345 Test MSE 0.12775686852796397 Test RE 0.1708441802831247\n",
      "44 Train Loss 1.3192203 Test MSE 0.13694073914794058 Test RE 0.1768782342598707\n",
      "45 Train Loss 1.2738807 Test MSE 0.12590766305454684 Test RE 0.16960323896662677\n",
      "46 Train Loss 1.2153257 Test MSE 0.12307748562328129 Test RE 0.1676862173118768\n",
      "47 Train Loss 1.1278692 Test MSE 0.138762531391249 Test RE 0.17805089752990544\n",
      "48 Train Loss 1.0380795 Test MSE 0.11729282377641714 Test RE 0.16369815371762078\n",
      "49 Train Loss 0.94267654 Test MSE 0.1111853439584478 Test RE 0.15937926960859677\n",
      "50 Train Loss 0.89073396 Test MSE 0.11092154388687174 Test RE 0.1591900844625193\n",
      "51 Train Loss 0.79498136 Test MSE 0.11781363383114599 Test RE 0.1640611819574692\n",
      "52 Train Loss 0.65844774 Test MSE 0.08276470136069713 Test RE 0.1375088456957202\n",
      "53 Train Loss 0.5769129 Test MSE 0.05826085543803934 Test RE 0.11537095532352439\n",
      "54 Train Loss 0.54612225 Test MSE 0.05638065070141186 Test RE 0.11349405215671192\n",
      "55 Train Loss 0.5216589 Test MSE 0.052782533852794605 Test RE 0.10981285371561136\n",
      "56 Train Loss 0.4992748 Test MSE 0.05408058254915591 Test RE 0.11115493289974268\n",
      "57 Train Loss 0.4609815 Test MSE 0.04201971855558338 Test RE 0.0979793671207988\n",
      "58 Train Loss 0.42837033 Test MSE 0.04153278590066965 Test RE 0.09741001089945933\n",
      "59 Train Loss 0.40249455 Test MSE 0.045902752471778156 Test RE 0.10240647665037599\n",
      "60 Train Loss 0.3817287 Test MSE 0.048839803347650965 Test RE 0.10563188104503275\n",
      "61 Train Loss 0.3560134 Test MSE 0.046801049046904526 Test RE 0.10340364648443359\n",
      "62 Train Loss 0.35217288 Test MSE 0.048707215685443866 Test RE 0.1054884017365691\n",
      "63 Train Loss 0.32816082 Test MSE 0.03733933862783262 Test RE 0.09236158367056937\n",
      "64 Train Loss 0.30672637 Test MSE 0.034153681204103385 Test RE 0.08833378105318265\n",
      "65 Train Loss 0.28957623 Test MSE 0.03567379967622209 Test RE 0.09027816955255613\n",
      "66 Train Loss 0.28108698 Test MSE 0.036592491032963 Test RE 0.09143322700045615\n",
      "67 Train Loss 0.27516145 Test MSE 0.03602509228840743 Test RE 0.09072158126454016\n",
      "68 Train Loss 0.2693178 Test MSE 0.03369856725492469 Test RE 0.08774326252348641\n",
      "69 Train Loss 0.26061857 Test MSE 0.03662225832724174 Test RE 0.09147040903434328\n",
      "70 Train Loss 0.24668683 Test MSE 0.03768751645650016 Test RE 0.09279120612604093\n",
      "71 Train Loss 0.23379156 Test MSE 0.03806829171356685 Test RE 0.09325878532880984\n",
      "72 Train Loss 0.23200616 Test MSE 0.03823202540477505 Test RE 0.09345912557061012\n",
      "73 Train Loss 0.2293902 Test MSE 0.0396798910596211 Test RE 0.0952123525091021\n",
      "74 Train Loss 0.22037774 Test MSE 0.03545100118726497 Test RE 0.08999581466842715\n",
      "75 Train Loss 0.20509408 Test MSE 0.03128991545904407 Test RE 0.0845493464923256\n",
      "76 Train Loss 0.19672497 Test MSE 0.02951890255221675 Test RE 0.08212174402718053\n",
      "77 Train Loss 0.18900602 Test MSE 0.027441815365744367 Test RE 0.0791798143734534\n",
      "78 Train Loss 0.1723464 Test MSE 0.025643003501167418 Test RE 0.07654071346107397\n",
      "79 Train Loss 0.16605695 Test MSE 0.023663467864645647 Test RE 0.07352706924405898\n",
      "80 Train Loss 0.16222136 Test MSE 0.022458975547546813 Test RE 0.07163133272518317\n",
      "81 Train Loss 0.15997666 Test MSE 0.022150194489397673 Test RE 0.07113721066545733\n",
      "82 Train Loss 0.15564536 Test MSE 0.021537852839880533 Test RE 0.07014702596681409\n",
      "83 Train Loss 0.14434272 Test MSE 0.02257078274440736 Test RE 0.07180941198775175\n",
      "84 Train Loss 0.1280797 Test MSE 0.020330094363344455 Test RE 0.06815186696891924\n",
      "85 Train Loss 0.11437191 Test MSE 0.01447216415879245 Test RE 0.05750092092554854\n",
      "86 Train Loss 0.107663095 Test MSE 0.01527903656648884 Test RE 0.059082116602755246\n",
      "87 Train Loss 0.102284946 Test MSE 0.014522470718379173 Test RE 0.05760077344358469\n",
      "88 Train Loss 0.09477091 Test MSE 0.012966362032047672 Test RE 0.054427342776750195\n",
      "89 Train Loss 0.09134114 Test MSE 0.012603303254233486 Test RE 0.053659948726618556\n",
      "90 Train Loss 0.08927952 Test MSE 0.011740204561827412 Test RE 0.05178999777399573\n",
      "91 Train Loss 0.08764778 Test MSE 0.011215083042962828 Test RE 0.0506185041671462\n",
      "92 Train Loss 0.084465645 Test MSE 0.011173272261635635 Test RE 0.05052406102235814\n",
      "93 Train Loss 0.0817521 Test MSE 0.011226224523025108 Test RE 0.05064364107680494\n",
      "94 Train Loss 0.07677362 Test MSE 0.01120721276330849 Test RE 0.05060074006774379\n",
      "95 Train Loss 0.073590636 Test MSE 0.010271700315465902 Test RE 0.048442799200087754\n",
      "96 Train Loss 0.07156262 Test MSE 0.00931740858290181 Test RE 0.04613766703170629\n",
      "97 Train Loss 0.06941059 Test MSE 0.010193578624477614 Test RE 0.048258231094531055\n",
      "98 Train Loss 0.06755459 Test MSE 0.010135412201845747 Test RE 0.04812034897478698\n",
      "99 Train Loss 0.06677046 Test MSE 0.010370732657626591 Test RE 0.04867576432993521\n",
      "Training time: 73.07\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.375084 Test MSE 8.71018894425206 Test RE 1.410658364199294\n",
      "1 Train Loss 56.447353 Test MSE 8.308768685388088 Test RE 1.3777689545409084\n",
      "2 Train Loss 50.737255 Test MSE 7.74350012735737 Test RE 1.3300767904888862\n",
      "3 Train Loss 47.526756 Test MSE 8.107694128492453 Test RE 1.3609956538004684\n",
      "4 Train Loss 42.616516 Test MSE 8.335614037293169 Test RE 1.3799929221530078\n",
      "5 Train Loss 41.718876 Test MSE 7.97069733932315 Test RE 1.3494482037283286\n",
      "6 Train Loss 40.81039 Test MSE 8.04321822469534 Test RE 1.3555732377619554\n",
      "7 Train Loss 40.17461 Test MSE 7.938533838207083 Test RE 1.346722792723384\n",
      "8 Train Loss 40.038887 Test MSE 8.018801334258757 Test RE 1.353514109178976\n",
      "9 Train Loss 39.662033 Test MSE 8.022420952019505 Test RE 1.3538195570112008\n",
      "10 Train Loss 39.563545 Test MSE 7.969590865452531 Test RE 1.349354536829725\n",
      "11 Train Loss 39.070015 Test MSE 7.888248674570186 Test RE 1.3424507345200154\n",
      "12 Train Loss 38.717827 Test MSE 7.796531904465392 Test RE 1.3346235702745386\n",
      "13 Train Loss 38.53064 Test MSE 7.641605532661848 Test RE 1.3212967534447801\n",
      "14 Train Loss 38.438564 Test MSE 7.530947037671783 Test RE 1.3116949815588146\n",
      "15 Train Loss 37.951324 Test MSE 7.000716687836497 Test RE 1.26467610075716\n",
      "16 Train Loss 37.74378 Test MSE 6.536320817144666 Test RE 1.2220099451755895\n",
      "17 Train Loss 35.611053 Test MSE 5.88131325315985 Test RE 1.1591648840927926\n",
      "18 Train Loss 30.154158 Test MSE 2.9473176703862056 Test RE 0.8205811459980021\n",
      "19 Train Loss 24.600645 Test MSE 3.1051557854790683 Test RE 0.8422669451063547\n",
      "20 Train Loss 23.584526 Test MSE 3.0621532851063544 Test RE 0.8364144433403347\n",
      "21 Train Loss 21.003288 Test MSE 2.7896523840924914 Test RE 0.7983312047792159\n",
      "22 Train Loss 18.952913 Test MSE 2.711333329183546 Test RE 0.7870449136983931\n",
      "23 Train Loss 18.341572 Test MSE 2.5655612953850384 Test RE 0.765595298584396\n",
      "24 Train Loss 17.402407 Test MSE 2.750988917708194 Test RE 0.7927796263878417\n",
      "25 Train Loss 16.28145 Test MSE 3.0047407485443745 Test RE 0.8285363439710314\n",
      "26 Train Loss 15.722212 Test MSE 2.9133781644238512 Test RE 0.8158428104960721\n",
      "27 Train Loss 15.4359255 Test MSE 3.0049340037341694 Test RE 0.8285629879292469\n",
      "28 Train Loss 15.000948 Test MSE 3.0322941734280744 Test RE 0.8323265074144865\n",
      "29 Train Loss 14.940994 Test MSE 2.94179944710643 Test RE 0.8198126045690641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 14.582723 Test MSE 2.847572282708616 Test RE 0.8065762665700653\n",
      "31 Train Loss 14.419056 Test MSE 2.921877391874024 Test RE 0.8170319770581669\n",
      "32 Train Loss 14.388437 Test MSE 2.9074403345033177 Test RE 0.8150109914810636\n",
      "33 Train Loss 14.086243 Test MSE 2.7398664065312204 Test RE 0.7911753612883106\n",
      "34 Train Loss 13.290387 Test MSE 2.59427818790165 Test RE 0.7698681135976232\n",
      "35 Train Loss 12.740765 Test MSE 2.3579055276572722 Test RE 0.7339580878784252\n",
      "36 Train Loss 11.914818 Test MSE 2.025345371142091 Test RE 0.6802328577921924\n",
      "37 Train Loss 11.188275 Test MSE 1.7031599681412366 Test RE 0.6237862258247758\n",
      "38 Train Loss 9.919487 Test MSE 2.0112457862357536 Test RE 0.6778609780291734\n",
      "39 Train Loss 9.618401 Test MSE 2.0459967478858485 Test RE 0.6836920498070806\n",
      "40 Train Loss 8.861776 Test MSE 2.090081818898875 Test RE 0.6910185469549561\n",
      "41 Train Loss 8.493296 Test MSE 2.160902058060808 Test RE 0.7026282414421005\n",
      "42 Train Loss 8.2409 Test MSE 2.1393111445812103 Test RE 0.699109231823077\n",
      "43 Train Loss 8.097822 Test MSE 2.1382360227672743 Test RE 0.6989335392772137\n",
      "44 Train Loss 7.8190184 Test MSE 2.1625833614275036 Test RE 0.7029015304436259\n",
      "45 Train Loss 7.540915 Test MSE 2.1443563033060844 Test RE 0.6999331044956346\n",
      "46 Train Loss 7.4654503 Test MSE 2.156017194212469 Test RE 0.7018336230136255\n",
      "47 Train Loss 7.391145 Test MSE 2.16486997528399 Test RE 0.7032730397622858\n",
      "48 Train Loss 7.3073063 Test MSE 2.173171321292916 Test RE 0.7046201245640749\n",
      "49 Train Loss 7.2709084 Test MSE 2.1652589833512788 Test RE 0.7033362229096048\n",
      "50 Train Loss 7.225889 Test MSE 2.1371307001504274 Test RE 0.6987528653701253\n",
      "51 Train Loss 7.156064 Test MSE 2.1177429031927235 Test RE 0.6955761425648262\n",
      "52 Train Loss 7.0494146 Test MSE 2.0907279517270423 Test RE 0.6911253502537867\n",
      "53 Train Loss 6.9291964 Test MSE 2.0764714267330833 Test RE 0.6887649522547356\n",
      "54 Train Loss 6.882677 Test MSE 2.1264302504247747 Test RE 0.6970013691785745\n",
      "55 Train Loss 6.8262796 Test MSE 2.108066854726549 Test RE 0.6939852662674574\n",
      "56 Train Loss 6.783914 Test MSE 2.130740032030231 Test RE 0.6977073418187212\n",
      "57 Train Loss 6.7583904 Test MSE 2.143133378314866 Test RE 0.6997334903367546\n",
      "58 Train Loss 6.732296 Test MSE 2.123064180878412 Test RE 0.6964494855018379\n",
      "59 Train Loss 6.679335 Test MSE 2.101322210190522 Test RE 0.6928741929106197\n",
      "60 Train Loss 6.6336575 Test MSE 2.093238878920617 Test RE 0.691540240366953\n",
      "61 Train Loss 6.5733232 Test MSE 2.0735711541519386 Test RE 0.6882837744023853\n",
      "62 Train Loss 6.5117908 Test MSE 2.0868254691987205 Test RE 0.6904800333058777\n",
      "63 Train Loss 6.4685974 Test MSE 2.104496820729123 Test RE 0.6933973814910065\n",
      "64 Train Loss 6.436082 Test MSE 2.091837219293677 Test RE 0.691308669483179\n",
      "65 Train Loss 6.4012656 Test MSE 2.123160631845301 Test RE 0.6964653051986627\n",
      "66 Train Loss 6.3541327 Test MSE 2.0719323290034404 Test RE 0.6880117317199359\n",
      "67 Train Loss 6.321087 Test MSE 2.0839252294052337 Test RE 0.6900000569101298\n",
      "68 Train Loss 6.294199 Test MSE 2.096876275382086 Test RE 0.6921408202265101\n",
      "69 Train Loss 6.2765474 Test MSE 2.0930936178743393 Test RE 0.6915162451118753\n",
      "70 Train Loss 6.246167 Test MSE 2.095729258239925 Test RE 0.6919514895558054\n",
      "71 Train Loss 6.1991696 Test MSE 2.096303754285931 Test RE 0.6920463243618691\n",
      "72 Train Loss 6.115528 Test MSE 2.1184563752637393 Test RE 0.6956933032358222\n",
      "73 Train Loss 6.0391235 Test MSE 2.108938077110665 Test RE 0.6941286566539764\n",
      "74 Train Loss 6.009109 Test MSE 2.098350923143572 Test RE 0.6923841546898695\n",
      "75 Train Loss 5.983389 Test MSE 2.106476260051227 Test RE 0.6937234013349995\n",
      "76 Train Loss 5.936939 Test MSE 2.1025333618575672 Test RE 0.6930738421705894\n",
      "77 Train Loss 5.881519 Test MSE 2.1010523120481315 Test RE 0.6928296943891895\n",
      "78 Train Loss 5.787584 Test MSE 2.0933022951471965 Test RE 0.6915507156502246\n",
      "79 Train Loss 5.691585 Test MSE 2.1052535996032975 Test RE 0.693522043433479\n",
      "80 Train Loss 5.6445208 Test MSE 2.127170771150932 Test RE 0.6971227225668397\n",
      "81 Train Loss 5.57475 Test MSE 2.0810524008374056 Test RE 0.6895242875579238\n",
      "82 Train Loss 5.5439763 Test MSE 2.081606715865349 Test RE 0.6896161132673775\n",
      "83 Train Loss 5.507595 Test MSE 2.0707173041601226 Test RE 0.6878099698366793\n",
      "84 Train Loss 5.4738717 Test MSE 2.0780612612475617 Test RE 0.6890285756209655\n",
      "85 Train Loss 5.4425883 Test MSE 2.057521690991412 Test RE 0.6856149382364596\n",
      "86 Train Loss 5.3878155 Test MSE 2.0742863862792555 Test RE 0.6884024682374184\n",
      "87 Train Loss 5.3419375 Test MSE 2.087094051179986 Test RE 0.6905244655143814\n",
      "88 Train Loss 5.31125 Test MSE 2.082013157881502 Test RE 0.6896834351300433\n",
      "89 Train Loss 5.29638 Test MSE 2.0790058017856876 Test RE 0.6891851498030663\n",
      "90 Train Loss 5.289548 Test MSE 2.084962430949446 Test RE 0.6901717473543729\n",
      "91 Train Loss 5.275102 Test MSE 2.089889240342341 Test RE 0.6909867112587135\n",
      "92 Train Loss 5.2615166 Test MSE 2.0872430842420013 Test RE 0.6905491192041273\n",
      "93 Train Loss 5.2346277 Test MSE 2.06684396906529 Test RE 0.687166384765188\n",
      "94 Train Loss 5.218699 Test MSE 2.0691725877006157 Test RE 0.6875533752742105\n",
      "95 Train Loss 5.2011995 Test MSE 2.0727398823963736 Test RE 0.6881457978940642\n",
      "96 Train Loss 5.175997 Test MSE 2.070727980598612 Test RE 0.6878117429786132\n",
      "97 Train Loss 5.160043 Test MSE 2.0674706087812007 Test RE 0.6872705467437974\n",
      "98 Train Loss 5.1523333 Test MSE 2.0636825280017135 Test RE 0.6866406393694506\n",
      "99 Train Loss 5.1417165 Test MSE 2.0730830635033364 Test RE 0.6882027632818489\n",
      "Training time: 75.13\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.78283 Test MSE 8.428386837477161 Test RE 1.3876511194855838\n",
      "1 Train Loss 56.075085 Test MSE 8.687662240292553 Test RE 1.4088330274424012\n",
      "2 Train Loss 55.02846 Test MSE 8.219757567333705 Test RE 1.370369123101228\n",
      "3 Train Loss 47.633156 Test MSE 8.90719943740179 Test RE 1.4265225740234602\n",
      "4 Train Loss 45.563087 Test MSE 8.412936869071777 Test RE 1.3863786933174391\n",
      "5 Train Loss 43.886612 Test MSE 8.42383338610335 Test RE 1.3872762283196995\n",
      "6 Train Loss 43.59368 Test MSE 8.526398944654689 Test RE 1.395696163961335\n",
      "7 Train Loss 43.54266 Test MSE 8.471702285100285 Test RE 1.3912122814682553\n",
      "8 Train Loss 43.43118 Test MSE 8.451112073213585 Test RE 1.3895206036160317\n",
      "9 Train Loss 43.307198 Test MSE 8.478915443438135 Test RE 1.3918044233411635\n",
      "10 Train Loss 43.19187 Test MSE 8.507883720229167 Test RE 1.3941799510786903\n",
      "11 Train Loss 43.0282 Test MSE 8.399132188040364 Test RE 1.3852407807529807\n",
      "12 Train Loss 42.9466 Test MSE 8.397748528521614 Test RE 1.385126674885004\n",
      "13 Train Loss 42.87742 Test MSE 8.51071403116023 Test RE 1.3944118321647896\n",
      "14 Train Loss 42.674713 Test MSE 8.329966285494491 Test RE 1.3795253394354854\n",
      "15 Train Loss 41.86246 Test MSE 8.109825308171322 Test RE 1.361174516967492\n",
      "16 Train Loss 40.13943 Test MSE 7.9634076521803445 Test RE 1.3488309863772598\n",
      "17 Train Loss 39.76631 Test MSE 7.936781361296529 Test RE 1.3465741361255106\n",
      "18 Train Loss 39.547707 Test MSE 7.899218893301913 Test RE 1.343383885979998\n",
      "19 Train Loss 39.44509 Test MSE 7.914390464813493 Test RE 1.344673346880304\n",
      "20 Train Loss 39.3171 Test MSE 7.927027754666146 Test RE 1.3457464711424063\n",
      "21 Train Loss 39.23826 Test MSE 7.911922678128468 Test RE 1.3444636891870618\n",
      "22 Train Loss 39.115456 Test MSE 7.875320046297027 Test RE 1.341350162986614\n",
      "23 Train Loss 39.025467 Test MSE 7.901171636114269 Test RE 1.3435499227210672\n",
      "24 Train Loss 38.93862 Test MSE 7.951678760298252 Test RE 1.3478373086067292\n",
      "25 Train Loss 38.738415 Test MSE 7.911561751510475 Test RE 1.3444330229200687\n",
      "26 Train Loss 38.590202 Test MSE 7.933451916286575 Test RE 1.3462916655232324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 38.41774 Test MSE 7.920863359993152 Test RE 1.345223114467183\n",
      "28 Train Loss 38.239563 Test MSE 7.886098215521058 Test RE 1.3422677355915826\n",
      "29 Train Loss 38.132343 Test MSE 7.895198145614364 Test RE 1.3430419474138011\n",
      "30 Train Loss 37.961365 Test MSE 7.840921562405533 Test RE 1.3384175262156097\n",
      "31 Train Loss 37.517883 Test MSE 8.06562990068292 Test RE 1.3574605130754063\n",
      "32 Train Loss 37.28452 Test MSE 7.943614810013767 Test RE 1.3471537013860166\n",
      "33 Train Loss 37.143364 Test MSE 7.86580372030591 Test RE 1.3405394921939418\n",
      "34 Train Loss 36.927498 Test MSE 7.935243164087782 Test RE 1.3464436426136888\n",
      "35 Train Loss 36.757584 Test MSE 7.833080511428809 Test RE 1.3377481390157986\n",
      "36 Train Loss 36.426067 Test MSE 7.8938311262665755 Test RE 1.342925671433621\n",
      "37 Train Loss 36.264217 Test MSE 7.958994369184035 Test RE 1.3484571766907922\n",
      "38 Train Loss 36.120205 Test MSE 7.92530954995829 Test RE 1.3456006161444791\n",
      "39 Train Loss 35.921986 Test MSE 7.935591777363016 Test RE 1.3464732184542303\n",
      "40 Train Loss 35.690704 Test MSE 8.083874830737475 Test RE 1.3589949736359608\n",
      "41 Train Loss 35.35519 Test MSE 7.921520370238782 Test RE 1.3452789042846454\n",
      "42 Train Loss 35.18683 Test MSE 8.022158865637863 Test RE 1.353797442703738\n",
      "43 Train Loss 34.934544 Test MSE 8.050152735155024 Test RE 1.3561574697999537\n",
      "44 Train Loss 34.776386 Test MSE 8.087455160159491 Test RE 1.3592958881827208\n",
      "45 Train Loss 34.451416 Test MSE 8.106880580812474 Test RE 1.3609273691182775\n",
      "46 Train Loss 34.291508 Test MSE 8.13842379699732 Test RE 1.363572427810079\n",
      "47 Train Loss 34.112644 Test MSE 8.1799926933768 Test RE 1.3670503743535882\n",
      "48 Train Loss 33.847515 Test MSE 8.217018107853633 Test RE 1.370140747538227\n",
      "49 Train Loss 33.50747 Test MSE 8.41772303950791 Test RE 1.3867729968377633\n",
      "50 Train Loss 33.378586 Test MSE 8.421349737165695 Test RE 1.387071703789414\n",
      "51 Train Loss 33.22734 Test MSE 8.513742684041238 Test RE 1.3946599202655285\n",
      "52 Train Loss 33.02536 Test MSE 8.534607659130288 Test RE 1.3963678493472422\n",
      "53 Train Loss 32.74232 Test MSE 8.591458088200817 Test RE 1.4010108484953798\n",
      "54 Train Loss 32.489285 Test MSE 8.62099811703265 Test RE 1.403417331024437\n",
      "55 Train Loss 32.18322 Test MSE 8.74153790943887 Test RE 1.4131946444716241\n",
      "56 Train Loss 32.03608 Test MSE 8.724713420177842 Test RE 1.4118340298004874\n",
      "57 Train Loss 31.681225 Test MSE 8.926514024037417 Test RE 1.4280683895027082\n",
      "58 Train Loss 31.457859 Test MSE 8.956025168038636 Test RE 1.4304270458139718\n",
      "59 Train Loss 31.131157 Test MSE 8.98314805031719 Test RE 1.432591397415626\n",
      "60 Train Loss 30.86026 Test MSE 9.12333213299018 Test RE 1.4437260841705182\n",
      "61 Train Loss 30.676449 Test MSE 9.005788415923291 Test RE 1.4343955523904806\n",
      "62 Train Loss 30.492031 Test MSE 9.053095759680172 Test RE 1.438158052683192\n",
      "63 Train Loss 30.296898 Test MSE 9.036277791291832 Test RE 1.4368215960291988\n",
      "64 Train Loss 30.062784 Test MSE 8.987604524806173 Test RE 1.4329467024475717\n",
      "65 Train Loss 29.783195 Test MSE 8.978880190198653 Test RE 1.432251047572454\n",
      "66 Train Loss 29.626755 Test MSE 8.989874168737481 Test RE 1.4331276223734082\n",
      "67 Train Loss 29.37363 Test MSE 8.950287053007436 Test RE 1.4299687359104851\n",
      "68 Train Loss 29.104977 Test MSE 8.932942449335613 Test RE 1.4285825083820325\n",
      "69 Train Loss 29.019098 Test MSE 8.895476893037165 Test RE 1.4255835594706474\n",
      "70 Train Loss 28.869608 Test MSE 8.954250466022721 Test RE 1.430285313991746\n",
      "71 Train Loss 28.573658 Test MSE 8.842475359708628 Test RE 1.4213302181007597\n",
      "72 Train Loss 28.300993 Test MSE 8.824196851133353 Test RE 1.4198604239937047\n",
      "73 Train Loss 28.08496 Test MSE 8.891717497742665 Test RE 1.4252822884680874\n",
      "74 Train Loss 27.563374 Test MSE 9.187048664902616 Test RE 1.4487587391849674\n",
      "75 Train Loss 27.250992 Test MSE 9.215910399128678 Test RE 1.4510326414229286\n",
      "76 Train Loss 26.924416 Test MSE 9.211324033001551 Test RE 1.4506715379156663\n",
      "77 Train Loss 26.4701 Test MSE 9.392741644067321 Test RE 1.4648874175172941\n",
      "78 Train Loss 26.110676 Test MSE 9.451521161597402 Test RE 1.469463881317672\n",
      "79 Train Loss 25.690754 Test MSE 9.504935946415763 Test RE 1.4736103309125779\n",
      "80 Train Loss 25.229794 Test MSE 9.813025011170062 Test RE 1.4973023739780416\n",
      "81 Train Loss 24.920593 Test MSE 9.772848289199835 Test RE 1.4942340845749487\n",
      "82 Train Loss 24.50398 Test MSE 9.829854375052204 Test RE 1.4985857627283357\n",
      "83 Train Loss 23.700499 Test MSE 9.891484922257488 Test RE 1.503276287283638\n",
      "84 Train Loss 23.226917 Test MSE 9.87794001687142 Test RE 1.5022466789587565\n",
      "85 Train Loss 22.725468 Test MSE 9.787036510927274 Test RE 1.4953183557478638\n",
      "86 Train Loss 22.317009 Test MSE 9.63601238941353 Test RE 1.4837363450691796\n",
      "87 Train Loss 21.95927 Test MSE 9.677281156617596 Test RE 1.4869101968058247\n",
      "88 Train Loss 21.717354 Test MSE 9.532312725054316 Test RE 1.475731002548329\n",
      "89 Train Loss 21.533905 Test MSE 9.663569572654291 Test RE 1.4858564338418354\n",
      "90 Train Loss 21.290424 Test MSE 9.549263615594212 Test RE 1.477042533366786\n",
      "91 Train Loss 21.0452 Test MSE 9.596570847838635 Test RE 1.4806966616015613\n",
      "92 Train Loss 20.839546 Test MSE 9.543419145730063 Test RE 1.476590464381372\n",
      "93 Train Loss 20.512054 Test MSE 9.594054731946807 Test RE 1.4805025376433525\n",
      "94 Train Loss 20.245537 Test MSE 9.5307214981805 Test RE 1.475607825681247\n",
      "95 Train Loss 20.024178 Test MSE 9.752042299582417 Test RE 1.4926426558340606\n",
      "96 Train Loss 19.933193 Test MSE 9.680260464451889 Test RE 1.4871390638925626\n",
      "97 Train Loss 19.843693 Test MSE 9.687944852980886 Test RE 1.4877292074847235\n",
      "98 Train Loss 19.682392 Test MSE 9.778152640279801 Test RE 1.4946395378654482\n",
      "99 Train Loss 19.419033 Test MSE 9.709001645693572 Test RE 1.4893451230501316\n",
      "Training time: 74.59\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.900368 Test MSE 8.671179194694819 Test RE 1.4074959080010232\n",
      "1 Train Loss 57.987583 Test MSE 8.624278821456087 Test RE 1.4036843395214238\n",
      "2 Train Loss 52.156372 Test MSE 8.05041086696919 Test RE 1.3561792125291463\n",
      "3 Train Loss 44.043343 Test MSE 8.728193194719845 Test RE 1.41211555047128\n",
      "4 Train Loss 37.779312 Test MSE 7.3059945482106 Test RE 1.2919560267382726\n",
      "5 Train Loss 35.181236 Test MSE 7.094806106609756 Test RE 1.2731463399178231\n",
      "6 Train Loss 33.697533 Test MSE 6.570927653466347 Test RE 1.2252406670606746\n",
      "7 Train Loss 31.947456 Test MSE 5.934683804239915 Test RE 1.1644124834484895\n",
      "8 Train Loss 30.324097 Test MSE 6.402299048190594 Test RE 1.209416914639918\n",
      "9 Train Loss 28.010353 Test MSE 6.114571194662236 Test RE 1.1819281144368636\n",
      "10 Train Loss 26.973732 Test MSE 6.1577022693482775 Test RE 1.1860893423248873\n",
      "11 Train Loss 25.76857 Test MSE 5.918744218129091 Test RE 1.1628477217128002\n",
      "12 Train Loss 24.770784 Test MSE 6.058949059248058 Test RE 1.176540037821601\n",
      "13 Train Loss 23.954782 Test MSE 5.8425622841355525 Test RE 1.1553398032087085\n",
      "14 Train Loss 23.107634 Test MSE 5.163008677165354 Test RE 1.086074176794043\n",
      "15 Train Loss 21.284233 Test MSE 4.47196557479771 Test RE 1.0107815036149568\n",
      "16 Train Loss 19.386003 Test MSE 3.8685405182710175 Test RE 0.9401164138084539\n",
      "17 Train Loss 16.61819 Test MSE 3.977412494601491 Test RE 0.9532534310907026\n",
      "18 Train Loss 13.459682 Test MSE 4.13577263679466 Test RE 0.9720450388137157\n",
      "19 Train Loss 12.3104515 Test MSE 4.027074567518996 Test RE 0.9591861427575611\n",
      "20 Train Loss 10.860453 Test MSE 4.198427297265896 Test RE 0.9793803333030389\n",
      "21 Train Loss 10.277845 Test MSE 4.195562955646394 Test RE 0.9790461893147951\n",
      "22 Train Loss 9.9762535 Test MSE 4.249228835909391 Test RE 0.9852878339540504\n",
      "23 Train Loss 9.700121 Test MSE 4.216754266194829 Test RE 0.9815156004504325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 9.43841 Test MSE 4.221780027712439 Test RE 0.9821003386261261\n",
      "25 Train Loss 9.21104 Test MSE 4.1986031776912585 Test RE 0.97940084717805\n",
      "26 Train Loss 9.037547 Test MSE 4.215121752464075 Test RE 0.9813255854875538\n",
      "27 Train Loss 8.939415 Test MSE 4.230394870868471 Test RE 0.9831018508541841\n",
      "28 Train Loss 8.863393 Test MSE 4.228216525091111 Test RE 0.9828487052749051\n",
      "29 Train Loss 8.762836 Test MSE 4.237899670022151 Test RE 0.9839734849324825\n",
      "30 Train Loss 8.716416 Test MSE 4.224715472289204 Test RE 0.9824417112391958\n",
      "31 Train Loss 8.640356 Test MSE 4.229336149817765 Test RE 0.9829788250155379\n",
      "32 Train Loss 8.577617 Test MSE 4.222938008121537 Test RE 0.9822350181892051\n",
      "33 Train Loss 8.486031 Test MSE 4.258398996038316 Test RE 0.9863504241467411\n",
      "34 Train Loss 8.400556 Test MSE 4.324411994988782 Test RE 0.9939661440462212\n",
      "35 Train Loss 8.258619 Test MSE 4.293344597814183 Test RE 0.9903892874730422\n",
      "36 Train Loss 7.8227825 Test MSE 4.121474367851963 Test RE 0.9703632980591657\n",
      "37 Train Loss 6.7380104 Test MSE 3.760486315265645 Test RE 0.9268939908051048\n",
      "38 Train Loss 5.7239504 Test MSE 3.3492748182570407 Test RE 0.8747489953686796\n",
      "39 Train Loss 5.201025 Test MSE 3.0766975435404653 Test RE 0.8383984421617992\n",
      "40 Train Loss 4.986377 Test MSE 2.8371387224239024 Test RE 0.8050972549727945\n",
      "41 Train Loss 4.7894864 Test MSE 2.534656814748637 Test RE 0.7609701878969122\n",
      "42 Train Loss 4.629056 Test MSE 2.415087487185968 Test RE 0.7428044454357352\n",
      "43 Train Loss 4.396275 Test MSE 2.2662129733084466 Test RE 0.7195457642767153\n",
      "44 Train Loss 4.289674 Test MSE 2.188636300434182 Test RE 0.7071228305361128\n",
      "45 Train Loss 4.2244434 Test MSE 2.153728783993033 Test RE 0.7014610588145557\n",
      "46 Train Loss 4.151043 Test MSE 2.1570371485017454 Test RE 0.7019996127782469\n",
      "47 Train Loss 4.0873795 Test MSE 2.145837947770485 Test RE 0.7001748723706935\n",
      "48 Train Loss 4.055109 Test MSE 2.1481605085732856 Test RE 0.7005536891685349\n",
      "49 Train Loss 4.0257783 Test MSE 2.144109572658904 Test RE 0.6998928360207864\n",
      "50 Train Loss 3.9961765 Test MSE 2.1398448385275026 Test RE 0.6991964297743212\n",
      "51 Train Loss 3.9786167 Test MSE 2.150264745716242 Test RE 0.7008967199306232\n",
      "52 Train Loss 3.9621553 Test MSE 2.1642603305431103 Test RE 0.7031740091267588\n",
      "53 Train Loss 3.9507346 Test MSE 2.1581508613360567 Test RE 0.7021808162145672\n",
      "54 Train Loss 3.9366603 Test MSE 2.1472014807219866 Test RE 0.7003972936155074\n",
      "55 Train Loss 3.924147 Test MSE 2.1499759969875973 Test RE 0.7008496583229974\n",
      "56 Train Loss 3.9171755 Test MSE 2.1392209200695342 Test RE 0.6990944893546236\n",
      "57 Train Loss 3.908925 Test MSE 2.140539364638606 Test RE 0.6993098891176073\n",
      "58 Train Loss 3.8989677 Test MSE 2.1513625587474055 Test RE 0.7010756177543729\n",
      "59 Train Loss 3.8918147 Test MSE 2.1467578422612923 Test RE 0.7003249344933018\n",
      "60 Train Loss 3.8865912 Test MSE 2.1413474706786157 Test RE 0.6994418799672735\n",
      "61 Train Loss 3.878804 Test MSE 2.1378013059920606 Test RE 0.6988624868827008\n",
      "62 Train Loss 3.8714201 Test MSE 2.130444100815772 Test RE 0.6976588890399938\n",
      "63 Train Loss 3.8564177 Test MSE 2.1273898401211255 Test RE 0.6971586186094255\n",
      "64 Train Loss 3.84828 Test MSE 2.1333800180196696 Test RE 0.6981394375677683\n",
      "65 Train Loss 3.8395147 Test MSE 2.1258789582276254 Test RE 0.6969110120355733\n",
      "66 Train Loss 3.8313894 Test MSE 2.1281034244805377 Test RE 0.6972755317784842\n",
      "67 Train Loss 3.8188457 Test MSE 2.135047201880313 Test RE 0.6984121736688729\n",
      "68 Train Loss 3.8066921 Test MSE 2.1329902830629854 Test RE 0.6980756651107031\n",
      "69 Train Loss 3.7987728 Test MSE 2.140007120500485 Test RE 0.6992229421697254\n",
      "70 Train Loss 3.7896218 Test MSE 2.1428577761425527 Test RE 0.6996884968071205\n",
      "71 Train Loss 3.78085 Test MSE 2.1344200177357355 Test RE 0.6983095845516825\n",
      "72 Train Loss 3.756399 Test MSE 2.1271329091132745 Test RE 0.6971165184095188\n",
      "73 Train Loss 3.7354846 Test MSE 2.132714304590479 Test RE 0.6980305031403587\n",
      "74 Train Loss 3.704795 Test MSE 2.1446660335890484 Test RE 0.6999836517508768\n",
      "75 Train Loss 3.6709244 Test MSE 2.1370714136495312 Test RE 0.6987431731927386\n",
      "76 Train Loss 3.6530125 Test MSE 2.1217436225642308 Test RE 0.6962328539872812\n",
      "77 Train Loss 3.626133 Test MSE 2.1120582759425184 Test RE 0.694641952646482\n",
      "78 Train Loss 3.596559 Test MSE 2.123012573994392 Test RE 0.6964410208952176\n",
      "79 Train Loss 3.526371 Test MSE 2.105515879676148 Test RE 0.6935652428245439\n",
      "80 Train Loss 3.411135 Test MSE 2.0871027906508055 Test RE 0.6905259112595062\n",
      "81 Train Loss 3.2793303 Test MSE 2.062156376281225 Test RE 0.6863866973042811\n",
      "82 Train Loss 2.9832802 Test MSE 1.9434193209361215 Test RE 0.6663329941121945\n",
      "83 Train Loss 2.2826452 Test MSE 1.5193595667168418 Test RE 0.5891669039463491\n",
      "84 Train Loss 1.9612699 Test MSE 1.324060338064263 Test RE 0.5499990616666728\n",
      "85 Train Loss 1.4332854 Test MSE 1.0820307419322968 Test RE 0.49719626807581296\n",
      "86 Train Loss 0.82731146 Test MSE 0.6059641927519298 Test RE 0.37207590024758314\n",
      "87 Train Loss 0.5521088 Test MSE 0.4458915028785712 Test RE 0.31917043714493715\n",
      "88 Train Loss 0.4162071 Test MSE 0.2927057800255107 Test RE 0.25859713529810735\n",
      "89 Train Loss 0.3315275 Test MSE 0.21837559131775927 Test RE 0.22336242050129554\n",
      "90 Train Loss 0.27757993 Test MSE 0.1971486103392675 Test RE 0.2122290941374042\n",
      "91 Train Loss 0.24574694 Test MSE 0.17294861284260366 Test RE 0.19877721511336316\n",
      "92 Train Loss 0.21287528 Test MSE 0.13497329964344154 Test RE 0.17560302494419336\n",
      "93 Train Loss 0.16843277 Test MSE 0.0666079227655048 Test RE 0.12335904689954967\n",
      "94 Train Loss 0.14567812 Test MSE 0.05703548972200732 Test RE 0.11415124373652061\n",
      "95 Train Loss 0.11220042 Test MSE 0.05648368183964705 Test RE 0.11359770548376973\n",
      "96 Train Loss 0.09785791 Test MSE 0.05846814936587624 Test RE 0.11557601979494436\n",
      "97 Train Loss 0.08337024 Test MSE 0.06125994037516908 Test RE 0.11830315997964999\n",
      "98 Train Loss 0.0754919 Test MSE 0.052297091686794056 Test RE 0.10930671161903847\n",
      "99 Train Loss 0.06558391 Test MSE 0.04769872111916665 Test RE 0.10439060818259938\n",
      "Training time: 70.91\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.618046 Test MSE 8.616196728122008 Test RE 1.4030264661386922\n",
      "1 Train Loss 56.1997 Test MSE 8.752282267896796 Test RE 1.4140628673845441\n",
      "2 Train Loss 52.467617 Test MSE 9.424806142617681 Test RE 1.4673856690282512\n",
      "3 Train Loss 45.64791 Test MSE 8.472447414070512 Test RE 1.3912734621935985\n",
      "4 Train Loss 44.57878 Test MSE 8.270974241781367 Test RE 1.37463182534492\n",
      "5 Train Loss 44.28395 Test MSE 8.304448761938271 Test RE 1.37741074079895\n",
      "6 Train Loss 44.016365 Test MSE 8.254306482063544 Test RE 1.3732460401225848\n",
      "7 Train Loss 43.76191 Test MSE 8.457245884195205 Test RE 1.3900247686725182\n",
      "8 Train Loss 43.526016 Test MSE 8.514220235795522 Test RE 1.3946990342590406\n",
      "9 Train Loss 42.716267 Test MSE 8.508318240013919 Test RE 1.3942155528251081\n",
      "10 Train Loss 42.045063 Test MSE 8.536020192566445 Test RE 1.396483398576331\n",
      "11 Train Loss 41.79588 Test MSE 8.637924427553356 Test RE 1.4047943774388962\n",
      "12 Train Loss 41.28288 Test MSE 8.731006568098397 Test RE 1.412343116940054\n",
      "13 Train Loss 40.431313 Test MSE 8.751909945235328 Test RE 1.4140327899011245\n",
      "14 Train Loss 39.63971 Test MSE 8.634711621735981 Test RE 1.404533102213683\n",
      "15 Train Loss 37.75084 Test MSE 8.45126715461852 Test RE 1.3895333526966829\n",
      "16 Train Loss 37.076633 Test MSE 8.177232070479644 Test RE 1.3668196755516728\n",
      "17 Train Loss 36.556564 Test MSE 8.350980012281399 Test RE 1.3812642846025238\n",
      "18 Train Loss 36.07372 Test MSE 8.372406430151733 Test RE 1.3830351298461971\n",
      "19 Train Loss 33.530922 Test MSE 8.543495347547678 Test RE 1.3970947282830037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 31.592464 Test MSE 8.201342317660671 Test RE 1.3688331994758889\n",
      "21 Train Loss 30.49308 Test MSE 8.307853415491001 Test RE 1.3776930669318799\n",
      "22 Train Loss 30.199736 Test MSE 8.350066620583112 Test RE 1.381188744376784\n",
      "23 Train Loss 29.914814 Test MSE 8.428169457157589 Test RE 1.3876332246028125\n",
      "24 Train Loss 29.427477 Test MSE 8.3665834881965 Test RE 1.3825541012378295\n",
      "25 Train Loss 29.131863 Test MSE 8.17362978958451 Test RE 1.366518582789967\n",
      "26 Train Loss 28.884007 Test MSE 8.131988493068897 Test RE 1.363033211705513\n",
      "27 Train Loss 28.112915 Test MSE 8.009918470715403 Test RE 1.352764220752035\n",
      "28 Train Loss 26.640137 Test MSE 7.379663115895895 Test RE 1.2984532823742738\n",
      "29 Train Loss 24.598505 Test MSE 6.664613892507113 Test RE 1.2339443032551598\n",
      "30 Train Loss 22.91814 Test MSE 6.147043247944096 Test RE 1.1850623336324897\n",
      "31 Train Loss 21.506443 Test MSE 5.830701622639093 Test RE 1.1541665118347137\n",
      "32 Train Loss 20.308317 Test MSE 5.675774603753335 Test RE 1.1387296542804362\n",
      "33 Train Loss 18.931606 Test MSE 5.300438978236234 Test RE 1.1004339480870746\n",
      "34 Train Loss 18.175156 Test MSE 5.233296860227587 Test RE 1.0934419855364024\n",
      "35 Train Loss 17.80059 Test MSE 5.145207713564749 Test RE 1.0842002829990605\n",
      "36 Train Loss 17.559252 Test MSE 5.029800192236172 Test RE 1.0719719633558762\n",
      "37 Train Loss 17.235273 Test MSE 5.002718104010529 Test RE 1.0690821444607779\n",
      "38 Train Loss 16.750778 Test MSE 4.890029620219764 Test RE 1.0569727848882637\n",
      "39 Train Loss 16.186844 Test MSE 4.719039584736248 Test RE 1.0383287289958303\n",
      "40 Train Loss 15.518383 Test MSE 4.693879533244483 Test RE 1.0355570507549048\n",
      "41 Train Loss 14.987279 Test MSE 4.76716416320791 Test RE 1.0436097169143708\n",
      "42 Train Loss 14.660318 Test MSE 4.609008099146423 Test RE 1.0261522362546691\n",
      "43 Train Loss 14.389665 Test MSE 4.506044819161979 Test RE 1.0146255954054788\n",
      "44 Train Loss 14.222797 Test MSE 4.426983554854914 Test RE 1.0056850973464422\n",
      "45 Train Loss 14.05839 Test MSE 4.468135024158491 Test RE 1.010348508419367\n",
      "46 Train Loss 13.8368435 Test MSE 4.419495217810381 Test RE 1.0048341684638498\n",
      "47 Train Loss 13.5723915 Test MSE 4.474579447538487 Test RE 1.0110768623578075\n",
      "48 Train Loss 13.292818 Test MSE 4.561661704775082 Test RE 1.0208680162317598\n",
      "49 Train Loss 13.017662 Test MSE 4.527499491295666 Test RE 1.0170382000591232\n",
      "50 Train Loss 12.7860985 Test MSE 4.540392828973812 Test RE 1.0184853227459159\n",
      "51 Train Loss 12.409025 Test MSE 4.599779689062043 Test RE 1.0251244122187215\n",
      "52 Train Loss 11.946314 Test MSE 4.788628153732043 Test RE 1.0459564865109399\n",
      "53 Train Loss 11.618912 Test MSE 4.798406036073929 Test RE 1.047023809313448\n",
      "54 Train Loss 11.161583 Test MSE 4.760742883566997 Test RE 1.042906618829832\n",
      "55 Train Loss 10.764298 Test MSE 4.735874024721246 Test RE 1.0401791183696327\n",
      "56 Train Loss 10.281515 Test MSE 4.6188325619736865 Test RE 1.0272453161191986\n",
      "57 Train Loss 9.864616 Test MSE 4.709472955880266 Test RE 1.0372757239497927\n",
      "58 Train Loss 9.573485 Test MSE 4.781770646936211 Test RE 1.0452072924614122\n",
      "59 Train Loss 9.307528 Test MSE 4.843552518395226 Test RE 1.0519378136963378\n",
      "60 Train Loss 9.18651 Test MSE 4.933793392974348 Test RE 1.061691987562925\n",
      "61 Train Loss 9.013475 Test MSE 5.012995428030406 Test RE 1.0701797144444019\n",
      "62 Train Loss 8.901599 Test MSE 4.9459173538016685 Test RE 1.062995651205562\n",
      "63 Train Loss 8.779831 Test MSE 4.810377522539828 Test RE 1.0483290993415009\n",
      "64 Train Loss 8.627459 Test MSE 4.767973313652555 Test RE 1.043698281248234\n",
      "65 Train Loss 8.476051 Test MSE 4.7963104979415165 Test RE 1.0467951586010273\n",
      "66 Train Loss 8.364453 Test MSE 4.765608038362981 Test RE 1.04343937250177\n",
      "67 Train Loss 8.273622 Test MSE 4.670915664124709 Test RE 1.0330208168158481\n",
      "68 Train Loss 8.13295 Test MSE 4.6292418364065435 Test RE 1.028402195104864\n",
      "69 Train Loss 8.025711 Test MSE 4.581439462925683 Test RE 1.023078684694822\n",
      "70 Train Loss 7.811679 Test MSE 4.39811831158166 Test RE 1.0024010530854586\n",
      "71 Train Loss 7.504427 Test MSE 4.194496484671778 Test RE 0.9789217494345303\n",
      "72 Train Loss 6.062954 Test MSE 3.2028299204581456 Test RE 0.8554113310680455\n",
      "73 Train Loss 4.8540134 Test MSE 2.7839878781692042 Test RE 0.7975202704487805\n",
      "74 Train Loss 4.0032344 Test MSE 2.5397673015816213 Test RE 0.7617369524189421\n",
      "75 Train Loss 3.5694234 Test MSE 2.4510657419825477 Test RE 0.7483168772828064\n",
      "76 Train Loss 3.2333713 Test MSE 2.433708752936473 Test RE 0.745662602521144\n",
      "77 Train Loss 3.0887685 Test MSE 2.4412735601254645 Test RE 0.746820591788531\n",
      "78 Train Loss 2.9242218 Test MSE 2.452016916591017 Test RE 0.748462061265351\n",
      "79 Train Loss 2.678821 Test MSE 2.4541308811312192 Test RE 0.7487846286530274\n",
      "80 Train Loss 2.5087135 Test MSE 2.5039528964176814 Test RE 0.7563470854132097\n",
      "81 Train Loss 2.3337789 Test MSE 2.563654247800431 Test RE 0.7653107023661547\n",
      "82 Train Loss 2.2035844 Test MSE 2.5621073208129377 Test RE 0.7650797705966759\n",
      "83 Train Loss 2.05519 Test MSE 2.5368283550046833 Test RE 0.7612960946632611\n",
      "84 Train Loss 1.9312992 Test MSE 2.4816185953581926 Test RE 0.7529663666517391\n",
      "85 Train Loss 1.760146 Test MSE 2.4100319459187682 Test RE 0.7420265759272636\n",
      "86 Train Loss 1.7055912 Test MSE 2.4438659191425414 Test RE 0.7472170064793323\n",
      "87 Train Loss 1.6195836 Test MSE 2.483214216672661 Test RE 0.7532083974219498\n",
      "88 Train Loss 1.5893743 Test MSE 2.4974749696029677 Test RE 0.7553680865534763\n",
      "89 Train Loss 1.5321783 Test MSE 2.4943915200622633 Test RE 0.7549016436948868\n",
      "90 Train Loss 1.5052997 Test MSE 2.4945607880522482 Test RE 0.7549272568584837\n",
      "91 Train Loss 1.4855585 Test MSE 2.503820470878914 Test RE 0.7563270848383717\n",
      "92 Train Loss 1.4623919 Test MSE 2.5090667295397964 Test RE 0.7571190368293339\n",
      "93 Train Loss 1.4318665 Test MSE 2.478073250578119 Test RE 0.7524283146897388\n",
      "94 Train Loss 1.3978572 Test MSE 2.4963799924478005 Test RE 0.7552024789924848\n",
      "95 Train Loss 1.3780111 Test MSE 2.51008153693611 Test RE 0.7572721320651411\n",
      "96 Train Loss 1.356796 Test MSE 2.509824082227327 Test RE 0.7572332950248142\n",
      "97 Train Loss 1.3280923 Test MSE 2.5178126331619333 Test RE 0.7584374413469612\n",
      "98 Train Loss 1.2972403 Test MSE 2.488962716607194 Test RE 0.7540797107926376\n",
      "99 Train Loss 1.2767693 Test MSE 2.483685873183222 Test RE 0.7532799254388528\n",
      "Training time: 70.85\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.853523 Test MSE 8.620391329718224 Test RE 1.4033679405242434\n",
      "1 Train Loss 54.566193 Test MSE 9.08169411226255 Test RE 1.4404278022910613\n",
      "2 Train Loss 46.945705 Test MSE 9.186417361548653 Test RE 1.4487089613946664\n",
      "3 Train Loss 45.024094 Test MSE 7.782724062721581 Test RE 1.3334412216527092\n",
      "4 Train Loss 43.543415 Test MSE 8.000811534104004 Test RE 1.3519949843519798\n",
      "5 Train Loss 43.28326 Test MSE 8.296604629881639 Test RE 1.376760056768889\n",
      "6 Train Loss 38.785984 Test MSE 7.647783612796557 Test RE 1.321830766090189\n",
      "7 Train Loss 36.520092 Test MSE 7.587378585284931 Test RE 1.316600263021864\n",
      "8 Train Loss 34.872562 Test MSE 7.486054556965989 Test RE 1.3077795869470685\n",
      "9 Train Loss 33.614555 Test MSE 7.205225408718833 Test RE 1.2830153319852642\n",
      "10 Train Loss 31.881813 Test MSE 7.156216057226081 Test RE 1.278644404170447\n",
      "11 Train Loss 30.23885 Test MSE 6.7640549081728425 Test RE 1.2431159033360237\n",
      "12 Train Loss 27.629026 Test MSE 6.172239354669515 Test RE 1.1874885750927797\n",
      "13 Train Loss 25.749199 Test MSE 6.199089349999933 Test RE 1.1900686324422693\n",
      "14 Train Loss 25.03343 Test MSE 6.243329449468418 Test RE 1.1943075740676534\n",
      "15 Train Loss 24.162539 Test MSE 6.0592109256043605 Test RE 1.1765654624390427\n",
      "16 Train Loss 23.904667 Test MSE 5.986025550156161 Test RE 1.1694383812461515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 23.593422 Test MSE 6.110005181020192 Test RE 1.1814867337099089\n",
      "18 Train Loss 23.392088 Test MSE 5.975479810380273 Test RE 1.1684078118639392\n",
      "19 Train Loss 23.121145 Test MSE 5.820690581583359 Test RE 1.153175261300924\n",
      "20 Train Loss 22.931515 Test MSE 5.939682697353225 Test RE 1.1649027832282575\n",
      "21 Train Loss 22.66251 Test MSE 5.958479608192082 Test RE 1.1667445716346558\n",
      "22 Train Loss 22.251064 Test MSE 5.843900387137521 Test RE 1.1554720974896393\n",
      "23 Train Loss 22.078865 Test MSE 5.9581672023186085 Test RE 1.1667139847518586\n",
      "24 Train Loss 21.74355 Test MSE 5.913115822408106 Test RE 1.1622946885342464\n",
      "25 Train Loss 21.404076 Test MSE 5.825029764973857 Test RE 1.1536050132914655\n",
      "26 Train Loss 20.726778 Test MSE 6.2406684916823405 Test RE 1.1940530351426561\n",
      "27 Train Loss 19.681524 Test MSE 6.091141970630474 Test RE 1.17966154208047\n",
      "28 Train Loss 19.032022 Test MSE 6.033003421713472 Test RE 1.1740182447738639\n",
      "29 Train Loss 17.670588 Test MSE 5.690483839630143 Test RE 1.1402042552066827\n",
      "30 Train Loss 16.84547 Test MSE 5.337697644502374 Test RE 1.1042948454015642\n",
      "31 Train Loss 15.907154 Test MSE 5.04937715091854 Test RE 1.0740560988412826\n",
      "32 Train Loss 14.899307 Test MSE 4.820326000425287 Test RE 1.049412578975865\n",
      "33 Train Loss 13.939118 Test MSE 4.591881026635114 Test RE 1.024243871054993\n",
      "34 Train Loss 13.219744 Test MSE 4.340724370074254 Test RE 0.995839079251136\n",
      "35 Train Loss 12.494917 Test MSE 4.099317814840845 Test RE 0.9677515046700943\n",
      "36 Train Loss 11.782717 Test MSE 4.065567943148445 Test RE 0.9637594998238141\n",
      "37 Train Loss 11.250445 Test MSE 3.910676977434592 Test RE 0.9452224599627562\n",
      "38 Train Loss 10.679096 Test MSE 3.717900274083161 Test RE 0.9216306906618561\n",
      "39 Train Loss 10.237864 Test MSE 3.830522172526331 Test RE 0.9354854789270621\n",
      "40 Train Loss 9.759466 Test MSE 3.8152603362262894 Test RE 0.9336200053596887\n",
      "41 Train Loss 9.430149 Test MSE 3.9831339706436526 Test RE 0.9539388084176853\n",
      "42 Train Loss 9.094141 Test MSE 4.045503613097139 Test RE 0.9613783926610826\n",
      "43 Train Loss 8.793157 Test MSE 4.007403953952346 Test RE 0.9568406589046657\n",
      "44 Train Loss 8.388384 Test MSE 4.0279577968899005 Test RE 0.9592913226980843\n",
      "45 Train Loss 8.026852 Test MSE 4.004024719800692 Test RE 0.9564371469810056\n",
      "46 Train Loss 7.9040236 Test MSE 3.963159691242104 Test RE 0.9515439368907384\n",
      "47 Train Loss 7.812711 Test MSE 3.9463084946369156 Test RE 0.9495188185231062\n",
      "48 Train Loss 7.6902857 Test MSE 3.95384514072637 Test RE 0.9504250798865551\n",
      "49 Train Loss 7.607724 Test MSE 3.953752076013952 Test RE 0.9504138943754793\n",
      "50 Train Loss 7.5238066 Test MSE 3.9292291067905136 Test RE 0.9474618600980858\n",
      "51 Train Loss 7.4247694 Test MSE 3.911502719626063 Test RE 0.9453222468887867\n",
      "52 Train Loss 7.3107786 Test MSE 3.890933397862149 Test RE 0.9428333993081894\n",
      "53 Train Loss 7.1940303 Test MSE 3.8666104914769583 Test RE 0.939881871062327\n",
      "54 Train Loss 6.904307 Test MSE 3.8705738128673484 Test RE 0.9403634426952953\n",
      "55 Train Loss 6.6285396 Test MSE 3.7925450068551068 Test RE 0.9308365587916912\n",
      "56 Train Loss 5.9137564 Test MSE 3.5170763017808615 Test RE 0.8963940299205153\n",
      "57 Train Loss 5.3757544 Test MSE 3.0804690885501333 Test RE 0.8389121567801052\n",
      "58 Train Loss 4.792589 Test MSE 2.666160451884626 Test RE 0.7804609915199776\n",
      "59 Train Loss 4.4110055 Test MSE 2.3321070730763065 Test RE 0.7299318318205648\n",
      "60 Train Loss 4.068918 Test MSE 2.064916306468429 Test RE 0.6868458637297751\n",
      "61 Train Loss 3.921813 Test MSE 2.037937666388162 Test RE 0.682344206389625\n",
      "62 Train Loss 3.7792647 Test MSE 2.028911228891209 Test RE 0.6808314092630466\n",
      "63 Train Loss 3.67947 Test MSE 1.952655685656985 Test RE 0.6679145363198363\n",
      "64 Train Loss 3.6019778 Test MSE 1.9092218620354742 Test RE 0.6604443962801388\n",
      "65 Train Loss 3.5435877 Test MSE 1.8490421888092161 Test RE 0.6499522783479375\n",
      "66 Train Loss 3.4957523 Test MSE 1.8072042830253416 Test RE 0.6425570365835251\n",
      "67 Train Loss 3.432446 Test MSE 1.7882456041490873 Test RE 0.6391777422321645\n",
      "68 Train Loss 3.387771 Test MSE 1.7902507931124616 Test RE 0.6395360020435434\n",
      "69 Train Loss 3.3456416 Test MSE 1.7832789331175918 Test RE 0.6382894993342608\n",
      "70 Train Loss 3.3140578 Test MSE 1.7739794481694773 Test RE 0.6366230403707827\n",
      "71 Train Loss 3.2773077 Test MSE 1.7944647067586275 Test RE 0.6402882333815193\n",
      "72 Train Loss 3.244226 Test MSE 1.8026092696744236 Test RE 0.6417396311082874\n",
      "73 Train Loss 3.1937964 Test MSE 1.7875593321099081 Test RE 0.6390550823736428\n",
      "74 Train Loss 3.1548438 Test MSE 1.7682185281882927 Test RE 0.6355884971631037\n",
      "75 Train Loss 3.0599217 Test MSE 1.765729380060156 Test RE 0.6351409758125557\n",
      "76 Train Loss 2.951026 Test MSE 1.804356834990446 Test RE 0.6420506275795168\n",
      "77 Train Loss 2.7169528 Test MSE 1.7151101168462484 Test RE 0.625970785176128\n",
      "78 Train Loss 2.3995678 Test MSE 1.6750990055734478 Test RE 0.6186261877882362\n",
      "79 Train Loss 1.7574221 Test MSE 1.39452306143744 Test RE 0.5644440646288438\n",
      "80 Train Loss 1.271446 Test MSE 1.0310846741990758 Test RE 0.48535021473504153\n",
      "81 Train Loss 1.0465978 Test MSE 0.8211472758628586 Test RE 0.433130322215981\n",
      "82 Train Loss 0.9070623 Test MSE 0.7475858986489017 Test RE 0.41327450152437645\n",
      "83 Train Loss 0.62371516 Test MSE 0.4863695618035244 Test RE 0.3333429344467917\n",
      "84 Train Loss 0.50763655 Test MSE 0.3441366863331419 Test RE 0.2803971186858518\n",
      "85 Train Loss 0.44445857 Test MSE 0.2641766180696315 Test RE 0.24567176633848445\n",
      "86 Train Loss 0.33670494 Test MSE 0.19811248478664778 Test RE 0.2127472636030976\n",
      "87 Train Loss 0.27577493 Test MSE 0.11226329579598025 Test RE 0.1601500041545306\n",
      "88 Train Loss 0.22543228 Test MSE 0.06517190137290119 Test RE 0.1220220328927673\n",
      "89 Train Loss 0.19280785 Test MSE 0.06096788604738017 Test RE 0.11802082026321731\n",
      "90 Train Loss 0.1684291 Test MSE 0.05115989228079404 Test RE 0.10811174344335972\n",
      "91 Train Loss 0.14656617 Test MSE 0.046529572933336184 Test RE 0.10310330656152597\n",
      "92 Train Loss 0.12292136 Test MSE 0.03412526186280053 Test RE 0.08829702205348214\n",
      "93 Train Loss 0.09865996 Test MSE 0.029718099767267726 Test RE 0.08239836200499798\n",
      "94 Train Loss 0.08577631 Test MSE 0.03249101722632421 Test RE 0.08615683060729096\n",
      "95 Train Loss 0.075155854 Test MSE 0.03150939452609364 Test RE 0.08484535854535598\n",
      "96 Train Loss 0.069365785 Test MSE 0.0345734898082816 Test RE 0.08887501146243594\n",
      "97 Train Loss 0.062954694 Test MSE 0.03471487717687708 Test RE 0.08905655205025712\n",
      "98 Train Loss 0.05565354 Test MSE 0.033710477033893405 Test RE 0.08775876630647496\n",
      "99 Train Loss 0.04924621 Test MSE 0.03034138352401587 Test RE 0.0832579570878089\n",
      "Training time: 71.75\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.384617 Test MSE 8.65930009174186 Test RE 1.4065314763662922\n",
      "1 Train Loss 55.570526 Test MSE 8.524084826108068 Test RE 1.3955067507297558\n",
      "2 Train Loss 49.055855 Test MSE 8.842189772236532 Test RE 1.4213072654000163\n",
      "3 Train Loss 44.450203 Test MSE 8.700025489271733 Test RE 1.4098351129685538\n",
      "4 Train Loss 44.249763 Test MSE 8.555487340301335 Test RE 1.3980748935531824\n",
      "5 Train Loss 43.824196 Test MSE 8.584438711313986 Test RE 1.4004384059266821\n",
      "6 Train Loss 43.6741 Test MSE 8.542705011006495 Test RE 1.3970301059880519\n",
      "7 Train Loss 43.25573 Test MSE 8.587403280975327 Test RE 1.4006802003510541\n",
      "8 Train Loss 42.96119 Test MSE 8.549779005984528 Test RE 1.3976084086983311\n",
      "9 Train Loss 42.618446 Test MSE 8.397949074815953 Test RE 1.3851432138634268\n",
      "10 Train Loss 42.438725 Test MSE 8.334926803530182 Test RE 1.379936033885826\n",
      "11 Train Loss 42.107155 Test MSE 8.497716429424997 Test RE 1.3933466492295046\n",
      "12 Train Loss 41.82933 Test MSE 8.445187519937866 Test RE 1.3890334646415456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train Loss 41.78535 Test MSE 8.414024729389494 Test RE 1.3864683253708627\n",
      "14 Train Loss 41.451836 Test MSE 8.442408722622895 Test RE 1.3888049226455923\n",
      "15 Train Loss 41.01358 Test MSE 8.619307640769561 Test RE 1.4032797274681796\n",
      "16 Train Loss 40.81952 Test MSE 8.739008535695033 Test RE 1.4129901749564016\n",
      "17 Train Loss 40.46633 Test MSE 8.69533514520305 Test RE 1.40945502768871\n",
      "18 Train Loss 40.21249 Test MSE 8.670650851919476 Test RE 1.4074530273497508\n",
      "19 Train Loss 39.91938 Test MSE 8.67556534503533 Test RE 1.4078518404543616\n",
      "20 Train Loss 37.503384 Test MSE 8.998486246479713 Test RE 1.4338139085104245\n",
      "21 Train Loss 35.40872 Test MSE 8.933291819107612 Test RE 1.4286104442311744\n",
      "22 Train Loss 34.757446 Test MSE 8.721219697048832 Test RE 1.4115513241766062\n",
      "23 Train Loss 34.406616 Test MSE 8.690126173519024 Test RE 1.4090327949012105\n",
      "24 Train Loss 33.657566 Test MSE 8.902291960168917 Test RE 1.4261295441138377\n",
      "25 Train Loss 32.966908 Test MSE 8.82263657530055 Test RE 1.4197348900850109\n",
      "26 Train Loss 32.392246 Test MSE 8.739949129719871 Test RE 1.4130662141518233\n",
      "27 Train Loss 31.598671 Test MSE 8.546714910736423 Test RE 1.3973579467252868\n",
      "28 Train Loss 31.397324 Test MSE 8.447678394321034 Test RE 1.389238294479982\n",
      "29 Train Loss 31.133846 Test MSE 8.439044614767738 Test RE 1.3885281914882779\n",
      "30 Train Loss 30.928123 Test MSE 8.41815040267346 Test RE 1.3868081992418482\n",
      "31 Train Loss 30.602608 Test MSE 8.237392483663799 Test RE 1.3718383511601717\n",
      "32 Train Loss 30.375717 Test MSE 8.413636374843604 Test RE 1.3864363283475962\n",
      "33 Train Loss 30.08596 Test MSE 8.47782421411487 Test RE 1.3917148584269572\n",
      "34 Train Loss 29.844372 Test MSE 8.432375579508795 Test RE 1.3879794342478422\n",
      "35 Train Loss 29.629723 Test MSE 8.509251556562075 Test RE 1.394292019685392\n",
      "36 Train Loss 29.052338 Test MSE 8.457803490282627 Test RE 1.3900705917163256\n",
      "37 Train Loss 28.260342 Test MSE 8.605190866870261 Test RE 1.402130104942686\n",
      "38 Train Loss 27.501312 Test MSE 8.616473494161024 Test RE 1.4030489996863635\n",
      "39 Train Loss 26.779293 Test MSE 8.366393734769343 Test RE 1.3825384230421347\n",
      "40 Train Loss 26.17182 Test MSE 8.359300183629944 Test RE 1.381952197544735\n",
      "41 Train Loss 25.647638 Test MSE 7.932725669049005 Test RE 1.3462300427270921\n",
      "42 Train Loss 25.069149 Test MSE 7.317102805612087 Test RE 1.2929378184078126\n",
      "43 Train Loss 23.849823 Test MSE 6.656240097537657 Test RE 1.2331688611603198\n",
      "44 Train Loss 22.822063 Test MSE 6.224198124681167 Test RE 1.1924763222606698\n",
      "45 Train Loss 21.934208 Test MSE 6.292373494824295 Test RE 1.1989892983412114\n",
      "46 Train Loss 21.383842 Test MSE 6.3558016636852495 Test RE 1.2050171515220005\n",
      "47 Train Loss 20.774094 Test MSE 6.028816924517661 Test RE 1.1736108293693235\n",
      "48 Train Loss 19.797054 Test MSE 5.852333413625558 Test RE 1.156305497563512\n",
      "49 Train Loss 19.48924 Test MSE 5.897090445493083 Test RE 1.1607186287991267\n",
      "50 Train Loss 18.933071 Test MSE 5.883812694930536 Test RE 1.1594111689998376\n",
      "51 Train Loss 18.216618 Test MSE 5.854953943036547 Test RE 1.1565643510174877\n",
      "52 Train Loss 17.984823 Test MSE 5.927636879134235 Test RE 1.1637209584136243\n",
      "53 Train Loss 17.749372 Test MSE 5.860880865894129 Test RE 1.1571495933482219\n",
      "54 Train Loss 17.466412 Test MSE 5.77926190902082 Test RE 1.1490640796369989\n",
      "55 Train Loss 17.124565 Test MSE 5.846698567230323 Test RE 1.1557486963248744\n",
      "56 Train Loss 16.601322 Test MSE 5.909947331685129 Test RE 1.1619832441520423\n",
      "57 Train Loss 16.340225 Test MSE 5.933690649868703 Test RE 1.1643150486253453\n",
      "58 Train Loss 16.208961 Test MSE 5.9689493044496 Test RE 1.1677691702582873\n",
      "59 Train Loss 16.02808 Test MSE 5.95745331932262 Test RE 1.1666440872316408\n",
      "60 Train Loss 15.906778 Test MSE 5.90215881227222 Test RE 1.1612173225433147\n",
      "61 Train Loss 15.689893 Test MSE 5.890897709917667 Test RE 1.1601090136252816\n",
      "62 Train Loss 15.48835 Test MSE 5.894731293083741 Test RE 1.160486430726388\n",
      "63 Train Loss 15.354535 Test MSE 5.914824013336899 Test RE 1.1624625592420001\n",
      "64 Train Loss 15.246384 Test MSE 5.905478917811402 Test RE 1.1615438828881128\n",
      "65 Train Loss 15.114346 Test MSE 5.857252522474597 Test RE 1.156791354867074\n",
      "66 Train Loss 15.031802 Test MSE 5.872368993278293 Test RE 1.1582831238149955\n",
      "67 Train Loss 14.830828 Test MSE 5.947318448872011 Test RE 1.1656513123817414\n",
      "68 Train Loss 14.5966 Test MSE 5.855159464672154 Test RE 1.1565846498032266\n",
      "69 Train Loss 14.410376 Test MSE 5.721164168952654 Test RE 1.1432738375505453\n",
      "70 Train Loss 14.274988 Test MSE 5.68985892551345 Test RE 1.1401416463566987\n",
      "71 Train Loss 14.091858 Test MSE 5.67126203282403 Test RE 1.1382768861148183\n",
      "72 Train Loss 13.852525 Test MSE 5.574352698372742 Test RE 1.1285096630884828\n",
      "73 Train Loss 13.5747385 Test MSE 5.415833047080194 Test RE 1.1123480409206326\n",
      "74 Train Loss 13.01729 Test MSE 5.161148914366703 Test RE 1.0858785522657028\n",
      "75 Train Loss 12.604909 Test MSE 5.00098660877888 Test RE 1.0688971179614826\n",
      "76 Train Loss 12.098092 Test MSE 4.771748469377076 Test RE 1.0441113859018334\n",
      "77 Train Loss 11.957946 Test MSE 4.811761973712811 Test RE 1.048479945718136\n",
      "78 Train Loss 11.779067 Test MSE 4.889850462861938 Test RE 1.0569534224098514\n",
      "79 Train Loss 11.11101 Test MSE 4.801714135998474 Test RE 1.0473846648338365\n",
      "80 Train Loss 10.600468 Test MSE 4.538999351365026 Test RE 1.0183290206972113\n",
      "81 Train Loss 10.305454 Test MSE 4.618783565005126 Test RE 1.0272398675519183\n",
      "82 Train Loss 10.037033 Test MSE 4.657643722261517 Test RE 1.0315521599069808\n",
      "83 Train Loss 9.848575 Test MSE 4.574465041779893 Test RE 1.022299661057792\n",
      "84 Train Loss 9.703779 Test MSE 4.492198669031287 Test RE 1.013065528022892\n",
      "85 Train Loss 9.401672 Test MSE 4.329465675329608 Test RE 0.9945467687011014\n",
      "86 Train Loss 9.15724 Test MSE 3.983095358690338 Test RE 0.9539341847306246\n",
      "87 Train Loss 8.966324 Test MSE 3.92534549808843 Test RE 0.9469935136760919\n",
      "88 Train Loss 8.864138 Test MSE 4.0140892841698275 Test RE 0.9576384484726352\n",
      "89 Train Loss 8.794535 Test MSE 3.937081622353576 Test RE 0.948408132934695\n",
      "90 Train Loss 8.696929 Test MSE 3.8331058901741177 Test RE 0.9358009219388975\n",
      "91 Train Loss 8.60733 Test MSE 3.785555225311609 Test RE 0.9299783824480131\n",
      "92 Train Loss 8.445207 Test MSE 3.7136569394451406 Test RE 0.9211046001736203\n",
      "93 Train Loss 8.337633 Test MSE 3.6592476452201987 Test RE 0.9143320878406631\n",
      "94 Train Loss 8.285176 Test MSE 3.656661426899073 Test RE 0.9140089230008174\n",
      "95 Train Loss 8.227262 Test MSE 3.6980743360026636 Test RE 0.9191700789953896\n",
      "96 Train Loss 8.186979 Test MSE 3.6840368655845603 Test RE 0.9174238876905616\n",
      "97 Train Loss 8.107036 Test MSE 3.682852180340624 Test RE 0.917276366646138\n",
      "98 Train Loss 8.019597 Test MSE 3.615994470775997 Test RE 0.9089122131877545\n",
      "99 Train Loss 7.981702 Test MSE 3.5993483169398655 Test RE 0.9068177208736339\n",
      "Training time: 71.12\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.214165 Test MSE 8.554753849390798 Test RE 1.3980149614203778\n",
      "1 Train Loss 56.556713 Test MSE 8.596254890627433 Test RE 1.4014019017017845\n",
      "2 Train Loss 53.207256 Test MSE 7.753442363299844 Test RE 1.3309303899641052\n",
      "3 Train Loss 47.486336 Test MSE 8.154815248017353 Test RE 1.364944910270356\n",
      "4 Train Loss 45.46965 Test MSE 8.314899418401376 Test RE 1.3782771631802138\n",
      "5 Train Loss 44.479923 Test MSE 8.23575790746881 Test RE 1.3717022349335677\n",
      "6 Train Loss 44.147316 Test MSE 7.9933101021907875 Test RE 1.3513610313702067\n",
      "7 Train Loss 43.503742 Test MSE 7.951334484107393 Test RE 1.3478081302828029\n",
      "8 Train Loss 42.338417 Test MSE 8.039898024458976 Test RE 1.3552934219575794\n",
      "9 Train Loss 42.130203 Test MSE 8.075737660642428 Test RE 1.3583108241586648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 41.80338 Test MSE 8.062618549303584 Test RE 1.3572070813992498\n",
      "11 Train Loss 41.73845 Test MSE 8.125308810175007 Test RE 1.3624732933006438\n",
      "12 Train Loss 41.28926 Test MSE 8.18780502628921 Test RE 1.367703021873657\n",
      "13 Train Loss 41.063988 Test MSE 8.067354469777493 Test RE 1.3576056294117553\n",
      "14 Train Loss 40.011147 Test MSE 7.682312126697776 Test RE 1.3248113324200417\n",
      "15 Train Loss 37.494072 Test MSE 7.7667397835145575 Test RE 1.33207119673088\n",
      "16 Train Loss 36.3321 Test MSE 6.947117587084057 Test RE 1.2598254726573153\n",
      "17 Train Loss 34.76512 Test MSE 6.520769882138498 Test RE 1.2205554026087806\n",
      "18 Train Loss 33.161907 Test MSE 6.504087348518659 Test RE 1.2189930873499053\n",
      "19 Train Loss 31.461891 Test MSE 6.1077275506233395 Test RE 1.1812665014150332\n",
      "20 Train Loss 29.7285 Test MSE 5.897084822560277 Test RE 1.1607180754207724\n",
      "21 Train Loss 28.528484 Test MSE 6.115587764706244 Test RE 1.182026360310714\n",
      "22 Train Loss 28.175642 Test MSE 6.178913669924582 Test RE 1.1881304435637794\n",
      "23 Train Loss 27.894583 Test MSE 6.001871078337268 Test RE 1.1709851606577752\n",
      "24 Train Loss 27.616806 Test MSE 5.919575466436098 Test RE 1.16292937596479\n",
      "25 Train Loss 27.268087 Test MSE 5.8054028956290145 Test RE 1.1516598936786762\n",
      "26 Train Loss 26.913717 Test MSE 5.475299303287233 Test RE 1.1184382017365244\n",
      "27 Train Loss 26.857056 Test MSE 5.444355913434282 Test RE 1.1152733240939645\n",
      "28 Train Loss 26.597843 Test MSE 5.567598801156727 Test RE 1.1278258035676823\n",
      "29 Train Loss 26.286194 Test MSE 5.437190334641141 Test RE 1.1145391500002781\n",
      "30 Train Loss 25.89935 Test MSE 5.169886922979632 Test RE 1.086797379026881\n",
      "31 Train Loss 25.806362 Test MSE 5.0241646727304685 Test RE 1.0713712623554787\n",
      "32 Train Loss 25.677048 Test MSE 5.117806045379482 Test RE 1.0813093834798169\n",
      "33 Train Loss 25.438457 Test MSE 5.2369040177893496 Test RE 1.093818759318557\n",
      "34 Train Loss 25.110674 Test MSE 5.221343693271014 Test RE 1.092192527812425\n",
      "35 Train Loss 24.992897 Test MSE 5.371171471419461 Test RE 1.1077520664922875\n",
      "36 Train Loss 24.941025 Test MSE 5.371097041640378 Test RE 1.1077443912553622\n",
      "37 Train Loss 24.875813 Test MSE 5.336087278838275 Test RE 1.104128251790521\n",
      "38 Train Loss 24.65632 Test MSE 5.460758355280457 Test RE 1.1169520762428478\n",
      "39 Train Loss 24.450191 Test MSE 5.488474431502614 Test RE 1.1197830335028502\n",
      "40 Train Loss 24.341187 Test MSE 5.491435661731156 Test RE 1.1200850744673727\n",
      "41 Train Loss 24.282267 Test MSE 5.495389026009524 Test RE 1.120488184684577\n",
      "42 Train Loss 24.084435 Test MSE 5.426877199005412 Test RE 1.1134816323793058\n",
      "43 Train Loss 24.034887 Test MSE 5.324517054231865 Test RE 1.1029305629481148\n",
      "44 Train Loss 24.00488 Test MSE 5.32948736600956 Test RE 1.1034452227754403\n",
      "45 Train Loss 23.966923 Test MSE 5.380298584500808 Test RE 1.1086928563093295\n",
      "46 Train Loss 23.902248 Test MSE 5.464996572693466 Test RE 1.1173854379912131\n",
      "47 Train Loss 23.85042 Test MSE 5.510648987841759 Test RE 1.1220428292389413\n",
      "48 Train Loss 23.803099 Test MSE 5.392013906442501 Test RE 1.1098992606266194\n",
      "49 Train Loss 23.588634 Test MSE 5.1893702022792185 Test RE 1.088843310128637\n",
      "50 Train Loss 22.780409 Test MSE 4.547548325488059 Test RE 1.0192875549971798\n",
      "51 Train Loss 21.750404 Test MSE 4.494749780058915 Test RE 1.013353146181591\n",
      "52 Train Loss 21.470154 Test MSE 4.5181609856414235 Test RE 1.015988777574556\n",
      "53 Train Loss 20.886616 Test MSE 4.6343824948388805 Test RE 1.0289730442568132\n",
      "54 Train Loss 20.703106 Test MSE 4.793408738982533 Test RE 1.0464784561275706\n",
      "55 Train Loss 20.131798 Test MSE 4.83459897496434 Test RE 1.0509650847370098\n",
      "56 Train Loss 19.908447 Test MSE 4.83290779108247 Test RE 1.0507812503917666\n",
      "57 Train Loss 19.307158 Test MSE 4.8098626287772355 Test RE 1.0482729922525202\n",
      "58 Train Loss 19.15157 Test MSE 4.760172591973539 Test RE 1.0428441518257567\n",
      "59 Train Loss 19.012928 Test MSE 4.713975339059824 Test RE 1.0377714372850977\n",
      "60 Train Loss 18.859383 Test MSE 4.603366744471797 Test RE 1.025524046733976\n",
      "61 Train Loss 18.695179 Test MSE 4.437170989024504 Test RE 1.0068415804443651\n",
      "62 Train Loss 18.567888 Test MSE 4.36116308315589 Test RE 0.9981808273591259\n",
      "63 Train Loss 18.48387 Test MSE 4.23429052316011 Test RE 0.9835544021888217\n",
      "64 Train Loss 18.381248 Test MSE 4.1703048795752435 Test RE 0.9760947196454842\n",
      "65 Train Loss 18.146538 Test MSE 4.136999736435329 Test RE 0.9721892328687222\n",
      "66 Train Loss 18.001066 Test MSE 3.9139439099147744 Test RE 0.9456171912749557\n",
      "67 Train Loss 17.717821 Test MSE 3.66699043947054 Test RE 0.9152989183085442\n",
      "68 Train Loss 17.061651 Test MSE 3.790892203328171 Test RE 0.9306337058788234\n",
      "69 Train Loss 16.587383 Test MSE 3.643302370073556 Test RE 0.9123377989550329\n",
      "70 Train Loss 16.365524 Test MSE 3.5034097146770167 Test RE 0.8946507394645629\n",
      "71 Train Loss 16.072124 Test MSE 3.5912601090565603 Test RE 0.9057982786522265\n",
      "72 Train Loss 15.802616 Test MSE 3.4254165603129048 Test RE 0.8846363012769628\n",
      "73 Train Loss 15.419146 Test MSE 3.2205023748211703 Test RE 0.8577680627889428\n",
      "74 Train Loss 15.176556 Test MSE 3.4749399412603164 Test RE 0.8910082222445878\n",
      "75 Train Loss 14.843229 Test MSE 3.5015888053358766 Test RE 0.8944182103349452\n",
      "76 Train Loss 14.545464 Test MSE 3.5330810913272384 Test RE 0.898431277937316\n",
      "77 Train Loss 14.320368 Test MSE 3.613567576892042 Test RE 0.908607151364854\n",
      "78 Train Loss 13.941505 Test MSE 3.5594472473225847 Test RE 0.901777386983496\n",
      "79 Train Loss 13.684967 Test MSE 3.591488945467446 Test RE 0.9058271370917297\n",
      "80 Train Loss 13.564172 Test MSE 3.6434083032603155 Test RE 0.9123510624915316\n",
      "81 Train Loss 13.461689 Test MSE 3.583074560051086 Test RE 0.9047653980291624\n",
      "82 Train Loss 13.333826 Test MSE 3.59161592450364 Test RE 0.9058431499546304\n",
      "83 Train Loss 13.202189 Test MSE 3.6676306234336216 Test RE 0.9153788113607065\n",
      "84 Train Loss 13.164058 Test MSE 3.636671641564313 Test RE 0.9115072037122177\n",
      "85 Train Loss 13.11965 Test MSE 3.6015104834516767 Test RE 0.9070900474689294\n",
      "86 Train Loss 13.047117 Test MSE 3.6298202000548025 Test RE 0.9106481651295214\n",
      "87 Train Loss 12.95396 Test MSE 3.5882577817150287 Test RE 0.9054195715305549\n",
      "88 Train Loss 12.906082 Test MSE 3.5360464752570366 Test RE 0.8988082343121926\n",
      "89 Train Loss 12.86652 Test MSE 3.5279112692795636 Test RE 0.8977737172888465\n",
      "90 Train Loss 12.825464 Test MSE 3.500826932143997 Test RE 0.8943209016038031\n",
      "91 Train Loss 12.737575 Test MSE 3.533780951807209 Test RE 0.8985202576966221\n",
      "92 Train Loss 12.689716 Test MSE 3.578931693612451 Test RE 0.9042421872713199\n",
      "93 Train Loss 12.645451 Test MSE 3.5751436615917833 Test RE 0.9037635241549548\n",
      "94 Train Loss 12.560442 Test MSE 3.639538138863914 Test RE 0.9118663670525615\n",
      "95 Train Loss 12.524321 Test MSE 3.6625022436087984 Test RE 0.9147386088859488\n",
      "96 Train Loss 12.487738 Test MSE 3.6448152331781247 Test RE 0.9125272011511492\n",
      "97 Train Loss 12.424759 Test MSE 3.6388446053590804 Test RE 0.9117794824007875\n",
      "98 Train Loss 12.368035 Test MSE 3.633380700678849 Test RE 0.9110946843040966\n",
      "99 Train Loss 12.331671 Test MSE 3.643110652179591 Test RE 0.9123137941148162\n",
      "Training time: 70.94\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.855446 Test MSE 8.659793188090754 Test RE 1.4065715226549678\n",
      "1 Train Loss 57.38731 Test MSE 8.442474578756407 Test RE 1.388810339413901\n",
      "2 Train Loss 49.533928 Test MSE 9.08298232325107 Test RE 1.4405299588437308\n",
      "3 Train Loss 47.31863 Test MSE 8.77652716934246 Test RE 1.4160200771749853\n",
      "4 Train Loss 45.99121 Test MSE 8.71834985079861 Test RE 1.4113190591537483\n",
      "5 Train Loss 45.835915 Test MSE 8.679205327823002 Test RE 1.4081471537193662\n",
      "6 Train Loss 45.722054 Test MSE 8.54424066674609 Test RE 1.3971556669721306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 45.37746 Test MSE 8.617846886676213 Test RE 1.4031608122636146\n",
      "8 Train Loss 45.200092 Test MSE 8.544209948517466 Test RE 1.3971531554449255\n",
      "9 Train Loss 45.092064 Test MSE 8.540030359556967 Test RE 1.3968113894860015\n",
      "10 Train Loss 45.028908 Test MSE 8.56320108377421 Test RE 1.3987050132011212\n",
      "11 Train Loss 44.955456 Test MSE 8.57706552806633 Test RE 1.3998368577369757\n",
      "12 Train Loss 44.49283 Test MSE 8.540992136076298 Test RE 1.396890041581953\n",
      "13 Train Loss 44.28609 Test MSE 8.436128605650957 Test RE 1.3882882762562898\n",
      "14 Train Loss 43.95668 Test MSE 8.542045610617443 Test RE 1.3969761874709368\n",
      "15 Train Loss 43.872093 Test MSE 8.489649547647392 Test RE 1.3926851402477198\n",
      "16 Train Loss 43.281487 Test MSE 8.59400557834915 Test RE 1.4012185429732786\n",
      "17 Train Loss 43.032505 Test MSE 9.009820600631071 Test RE 1.4347166292521611\n",
      "18 Train Loss 42.72401 Test MSE 9.074625640813048 Test RE 1.4398671357136996\n",
      "19 Train Loss 42.50263 Test MSE 8.962391163194061 Test RE 1.4309353334684858\n",
      "20 Train Loss 42.347755 Test MSE 9.070079638481804 Test RE 1.4395064343695323\n",
      "21 Train Loss 42.242386 Test MSE 9.162237556252718 Test RE 1.4468011130934388\n",
      "22 Train Loss 42.127113 Test MSE 9.113572303075685 Test RE 1.4429536530441487\n",
      "23 Train Loss 41.997803 Test MSE 9.003219610064384 Test RE 1.434190964723053\n",
      "24 Train Loss 41.916405 Test MSE 9.042773892379545 Test RE 1.437337962483691\n",
      "25 Train Loss 41.778366 Test MSE 9.016635319309275 Test RE 1.4352591118697833\n",
      "26 Train Loss 38.90187 Test MSE 8.593133573385295 Test RE 1.4011474526935417\n",
      "27 Train Loss 36.391014 Test MSE 8.480665026146323 Test RE 1.3919480119501608\n",
      "28 Train Loss 34.60557 Test MSE 8.789579393299944 Test RE 1.4170726201887245\n",
      "29 Train Loss 33.665054 Test MSE 8.566010771017076 Test RE 1.3989344601849643\n",
      "30 Train Loss 33.320717 Test MSE 8.404978911132721 Test RE 1.3857228371190509\n",
      "31 Train Loss 33.065536 Test MSE 8.307362154566205 Test RE 1.3776523333788275\n",
      "32 Train Loss 32.90243 Test MSE 8.174050074068488 Test RE 1.3665537152335374\n",
      "33 Train Loss 32.76086 Test MSE 8.178278921387946 Test RE 1.3669071630177738\n",
      "34 Train Loss 32.592945 Test MSE 8.23526212531069 Test RE 1.371660946946654\n",
      "35 Train Loss 32.2929 Test MSE 8.069752563934225 Test RE 1.357807394701177\n",
      "36 Train Loss 32.084427 Test MSE 8.007405021985907 Test RE 1.3525519607710117\n",
      "37 Train Loss 31.816715 Test MSE 7.779337356158448 Test RE 1.3331510619671774\n",
      "38 Train Loss 30.549538 Test MSE 7.075590556162212 Test RE 1.2714210781897648\n",
      "39 Train Loss 29.800611 Test MSE 7.164639591440751 Test RE 1.2793967247497613\n",
      "40 Train Loss 28.340284 Test MSE 7.4137279332758705 Test RE 1.301446687834873\n",
      "41 Train Loss 26.47419 Test MSE 7.189903254390048 Test RE 1.281650418323228\n",
      "42 Train Loss 24.284683 Test MSE 7.470197642130882 Test RE 1.3063937873611258\n",
      "43 Train Loss 21.99082 Test MSE 7.657427429508888 Test RE 1.322663914501446\n",
      "44 Train Loss 20.895765 Test MSE 7.632232893045986 Test RE 1.3204862014008245\n",
      "45 Train Loss 18.964912 Test MSE 7.082570500533309 Test RE 1.2720480407581194\n",
      "46 Train Loss 17.78705 Test MSE 6.751344623728184 Test RE 1.2419473892931556\n",
      "47 Train Loss 16.532242 Test MSE 5.396965991792683 Test RE 1.1104088155511693\n",
      "48 Train Loss 14.425682 Test MSE 4.22740691230728 Test RE 0.9827546035459084\n",
      "49 Train Loss 13.454918 Test MSE 3.94274747928275 Test RE 0.9490903149960199\n",
      "50 Train Loss 11.873713 Test MSE 4.24739461365578 Test RE 0.9850751563116907\n",
      "51 Train Loss 11.173487 Test MSE 4.187573107233767 Test RE 0.9781135184850198\n",
      "52 Train Loss 10.564571 Test MSE 4.039819292087534 Test RE 0.9607027407639923\n",
      "53 Train Loss 10.151059 Test MSE 3.9966982174135777 Test RE 0.9555617093966747\n",
      "54 Train Loss 9.777779 Test MSE 3.9464291333225283 Test RE 0.9495333318115325\n",
      "55 Train Loss 9.233394 Test MSE 3.8394857890133 Test RE 0.9365793811275512\n",
      "56 Train Loss 8.915721 Test MSE 3.707421054588017 Test RE 0.9203309267292882\n",
      "57 Train Loss 8.6217 Test MSE 3.7281047421354256 Test RE 0.9228946173160661\n",
      "58 Train Loss 8.4642105 Test MSE 3.696955409947929 Test RE 0.9190310118667341\n",
      "59 Train Loss 8.27902 Test MSE 3.7825692236104733 Test RE 0.9296115320545179\n",
      "60 Train Loss 8.072731 Test MSE 3.7275270353097683 Test RE 0.9228231087060659\n",
      "61 Train Loss 7.896644 Test MSE 3.679020003943019 Test RE 0.9167990083965077\n",
      "62 Train Loss 7.7379475 Test MSE 3.6355368551531737 Test RE 0.9113649793386938\n",
      "63 Train Loss 7.6108074 Test MSE 3.6161702855118896 Test RE 0.9089343092141206\n",
      "64 Train Loss 7.5117655 Test MSE 3.543109561380326 Test RE 0.8997054500355134\n",
      "65 Train Loss 7.4357243 Test MSE 3.544081280467855 Test RE 0.8998288163905747\n",
      "66 Train Loss 7.383298 Test MSE 3.5640538667349344 Test RE 0.9023607362689782\n",
      "67 Train Loss 7.2762184 Test MSE 3.4941563988247277 Test RE 0.8934684684593761\n",
      "68 Train Loss 7.1752043 Test MSE 3.4638884674189687 Test RE 0.8895902415232968\n",
      "69 Train Loss 7.1038017 Test MSE 3.4049626294531636 Test RE 0.8819911657676528\n",
      "70 Train Loss 7.0171785 Test MSE 3.358248913516312 Test RE 0.8759201189500642\n",
      "71 Train Loss 6.941472 Test MSE 3.3600115403094413 Test RE 0.8761499586337561\n",
      "72 Train Loss 6.8383923 Test MSE 3.3672329520349336 Test RE 0.8770909738063773\n",
      "73 Train Loss 6.7670107 Test MSE 3.3985668685402333 Test RE 0.8811624259701533\n",
      "74 Train Loss 6.7096696 Test MSE 3.367501802190626 Test RE 0.8771259879175988\n",
      "75 Train Loss 6.6167374 Test MSE 3.3482341871477748 Test RE 0.8746130910632112\n",
      "76 Train Loss 6.358081 Test MSE 3.2551329289465345 Test RE 0.8623675865288417\n",
      "77 Train Loss 6.092065 Test MSE 3.2108678894540383 Test RE 0.856484048226997\n",
      "78 Train Loss 5.881342 Test MSE 3.300071080150418 Test RE 0.8682998128132996\n",
      "79 Train Loss 5.4643517 Test MSE 3.147018374079816 Test RE 0.8479255066331242\n",
      "80 Train Loss 4.447171 Test MSE 2.4132519593055837 Test RE 0.7425221166511808\n",
      "81 Train Loss 3.728341 Test MSE 2.14474452571669 Test RE 0.6999964609021795\n",
      "82 Train Loss 3.3399684 Test MSE 2.0487345400119854 Test RE 0.6841493283816976\n",
      "83 Train Loss 2.984995 Test MSE 2.1682337439845134 Test RE 0.7038191994959202\n",
      "84 Train Loss 2.891877 Test MSE 2.2472540502278937 Test RE 0.7165296169725924\n",
      "85 Train Loss 2.6292138 Test MSE 2.4975339540837997 Test RE 0.7553770065090109\n",
      "86 Train Loss 2.3760922 Test MSE 2.5941448017355495 Test RE 0.769848321757922\n",
      "87 Train Loss 2.127 Test MSE 2.8019698707715124 Test RE 0.8000917472843233\n",
      "88 Train Loss 1.9693015 Test MSE 2.7559423661810016 Test RE 0.7934930474510417\n",
      "89 Train Loss 1.8718901 Test MSE 2.7156174054524325 Test RE 0.7876664583742441\n",
      "90 Train Loss 1.6684576 Test MSE 2.727842522060137 Test RE 0.789437418697994\n",
      "91 Train Loss 1.5176554 Test MSE 2.6553646581333767 Test RE 0.7788792707883376\n",
      "92 Train Loss 1.4102137 Test MSE 2.6626505044256676 Test RE 0.7799470916063515\n",
      "93 Train Loss 1.3590057 Test MSE 2.6400998902870554 Test RE 0.7766372910425868\n",
      "94 Train Loss 1.309315 Test MSE 2.640132337698245 Test RE 0.7766420635499063\n",
      "95 Train Loss 1.2715952 Test MSE 2.603956888143775 Test RE 0.7713028837470034\n",
      "96 Train Loss 1.256217 Test MSE 2.603050536633294 Test RE 0.7711686395169183\n",
      "97 Train Loss 1.2328697 Test MSE 2.616669289786826 Test RE 0.7731833246605014\n",
      "98 Train Loss 1.2148623 Test MSE 2.5884513071089126 Test RE 0.7690030461032501\n",
      "99 Train Loss 1.1896027 Test MSE 2.587886309225195 Test RE 0.7689191139070987\n",
      "Training time: 71.51\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.96525 Test MSE 8.54175502849143 Test RE 1.3969524261975026\n",
      "1 Train Loss 58.81157 Test MSE 8.42455016629162 Test RE 1.3873352484189092\n",
      "2 Train Loss 58.49318 Test MSE 8.267257149078706 Test RE 1.3743229011485734\n",
      "3 Train Loss 56.377014 Test MSE 8.673982335520353 Test RE 1.4077233909272395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 54.97982 Test MSE 8.835805941075805 Test RE 1.420794099310949\n",
      "5 Train Loss 51.528175 Test MSE 9.326642818020387 Test RE 1.4597239469768988\n",
      "6 Train Loss 47.073307 Test MSE 8.523255189803711 Test RE 1.3954388377948657\n",
      "7 Train Loss 45.93466 Test MSE 8.666899603097324 Test RE 1.4071485359237552\n",
      "8 Train Loss 45.496315 Test MSE 8.401056483294754 Test RE 1.3853994554553888\n",
      "9 Train Loss 44.846313 Test MSE 8.402629660622052 Test RE 1.3855291639625533\n",
      "10 Train Loss 44.47603 Test MSE 8.572379652071303 Test RE 1.3994544216897342\n",
      "11 Train Loss 44.25714 Test MSE 8.64477066118508 Test RE 1.4053509721209798\n",
      "12 Train Loss 43.83165 Test MSE 8.626501111992761 Test RE 1.4038651774537594\n",
      "13 Train Loss 43.70097 Test MSE 8.595424016247602 Test RE 1.4013341735406106\n",
      "14 Train Loss 43.630047 Test MSE 8.581704498043491 Test RE 1.4002153626765077\n",
      "15 Train Loss 43.521713 Test MSE 8.666747352236683 Test RE 1.4071361762261507\n",
      "16 Train Loss 43.131645 Test MSE 8.535212058394517 Test RE 1.3964172920863311\n",
      "17 Train Loss 42.66359 Test MSE 8.379271673862595 Test RE 1.3836020473562107\n",
      "18 Train Loss 42.07508 Test MSE 8.56652417675081 Test RE 1.3989763822786214\n",
      "19 Train Loss 40.56366 Test MSE 8.220293640549219 Test RE 1.3704138084948736\n",
      "20 Train Loss 39.69094 Test MSE 8.282189404953382 Test RE 1.3755634869106403\n",
      "21 Train Loss 39.10041 Test MSE 8.103900981073453 Test RE 1.36067724877563\n",
      "22 Train Loss 38.755615 Test MSE 8.101706615072391 Test RE 1.360493014907764\n",
      "23 Train Loss 38.471893 Test MSE 7.839993841862505 Test RE 1.3383383445687433\n",
      "24 Train Loss 38.220947 Test MSE 7.716117661597267 Test RE 1.3277230075545172\n",
      "25 Train Loss 38.10133 Test MSE 7.710496706401504 Test RE 1.3272393166936982\n",
      "26 Train Loss 37.795593 Test MSE 7.632327581919152 Test RE 1.320494392644749\n",
      "27 Train Loss 37.40838 Test MSE 7.729167856797411 Test RE 1.3288453157607354\n",
      "28 Train Loss 33.688675 Test MSE 8.195123633538392 Test RE 1.368314140815072\n",
      "29 Train Loss 30.457779 Test MSE 8.299711256558128 Test RE 1.3770177934817893\n",
      "30 Train Loss 27.052767 Test MSE 7.850133571358611 Test RE 1.3392035240660827\n",
      "31 Train Loss 25.78565 Test MSE 7.472379841685942 Test RE 1.3065845857785952\n",
      "32 Train Loss 24.868505 Test MSE 7.476445859813186 Test RE 1.3069400196712129\n",
      "33 Train Loss 23.813013 Test MSE 7.566918380696859 Test RE 1.3148238856321537\n",
      "34 Train Loss 22.208431 Test MSE 7.391878455660692 Test RE 1.29952748383908\n",
      "35 Train Loss 21.235601 Test MSE 7.2142614089503505 Test RE 1.2838195881804804\n",
      "36 Train Loss 19.88283 Test MSE 6.73475864686881 Test RE 1.2404209098532166\n",
      "37 Train Loss 18.999376 Test MSE 6.565728703389159 Test RE 1.2247558629445616\n",
      "38 Train Loss 18.236923 Test MSE 6.137779225381479 Test RE 1.184169011168842\n",
      "39 Train Loss 17.318054 Test MSE 5.990066041516773 Test RE 1.169832992709048\n",
      "40 Train Loss 16.365791 Test MSE 5.912720507265666 Test RE 1.1622558358900732\n",
      "41 Train Loss 15.375014 Test MSE 5.38989734199198 Test RE 1.1096814010347271\n",
      "42 Train Loss 14.673959 Test MSE 5.0100850802269035 Test RE 1.0698690172365035\n",
      "43 Train Loss 13.956766 Test MSE 4.913061867564186 Test RE 1.0594590540888904\n",
      "44 Train Loss 12.455289 Test MSE 4.501688720986973 Test RE 1.0141350457570129\n",
      "45 Train Loss 11.482916 Test MSE 3.9996353518604986 Test RE 0.9559127613915226\n",
      "46 Train Loss 9.924924 Test MSE 4.102788112950659 Test RE 0.9681610454650623\n",
      "47 Train Loss 9.085517 Test MSE 4.103011492313972 Test RE 0.9681874012319629\n",
      "48 Train Loss 8.037398 Test MSE 3.8858644654627983 Test RE 0.942219058761991\n",
      "49 Train Loss 7.522889 Test MSE 3.871997553299716 Test RE 0.9405363770486641\n",
      "50 Train Loss 7.0167418 Test MSE 3.421143353829539 Test RE 0.8840843372738166\n",
      "51 Train Loss 6.1248546 Test MSE 2.6660110511244883 Test RE 0.7804391242878644\n",
      "52 Train Loss 5.267513 Test MSE 2.4361616920996885 Test RE 0.7460382851805322\n",
      "53 Train Loss 4.305426 Test MSE 2.3027736502214498 Test RE 0.7253267357094221\n",
      "54 Train Loss 3.3372083 Test MSE 2.201477274783121 Test RE 0.7091941811977304\n",
      "55 Train Loss 2.827473 Test MSE 2.245630172737177 Test RE 0.716270686169851\n",
      "56 Train Loss 2.4207866 Test MSE 2.054802251916969 Test RE 0.685161697683752\n",
      "57 Train Loss 2.086237 Test MSE 1.9491393441022797 Test RE 0.6673128752190239\n",
      "58 Train Loss 1.9105368 Test MSE 1.8659990111342815 Test RE 0.6529257023706078\n",
      "59 Train Loss 1.6890864 Test MSE 1.701419611954991 Test RE 0.6234674396540801\n",
      "60 Train Loss 1.5911711 Test MSE 1.578468577953661 Test RE 0.6005180016999219\n",
      "61 Train Loss 1.4937348 Test MSE 1.501116989614802 Test RE 0.5856192316341398\n",
      "62 Train Loss 1.4310752 Test MSE 1.509823514829727 Test RE 0.5873150810707825\n",
      "63 Train Loss 1.3710041 Test MSE 1.4563648879561855 Test RE 0.5768237852975471\n",
      "64 Train Loss 1.2904103 Test MSE 1.186382340567227 Test RE 0.5206194596151845\n",
      "65 Train Loss 1.206636 Test MSE 0.9644946655256106 Test RE 0.46941609388782823\n",
      "66 Train Loss 1.102653 Test MSE 0.8192387021630086 Test RE 0.4326266719742354\n",
      "67 Train Loss 0.93477535 Test MSE 0.6643568735292043 Test RE 0.3895908752868794\n",
      "68 Train Loss 0.78659856 Test MSE 0.5397153823396257 Test RE 0.35114820948562886\n",
      "69 Train Loss 0.70852876 Test MSE 0.4201163365096081 Test RE 0.3098081548117227\n",
      "70 Train Loss 0.63101125 Test MSE 0.40393875419260666 Test RE 0.30378464693242924\n",
      "71 Train Loss 0.55981123 Test MSE 0.3906336635462367 Test RE 0.29873966772259924\n",
      "72 Train Loss 0.46980023 Test MSE 0.30392943064846095 Test RE 0.26350838454333675\n",
      "73 Train Loss 0.41333476 Test MSE 0.3168250185278084 Test RE 0.26904058259303165\n",
      "74 Train Loss 0.38167933 Test MSE 0.2759994577023845 Test RE 0.25110893992881084\n",
      "75 Train Loss 0.34348965 Test MSE 0.1884614511150816 Test RE 0.20750058510713734\n",
      "76 Train Loss 0.31589648 Test MSE 0.15756391340911172 Test RE 0.18973018915488077\n",
      "77 Train Loss 0.2809856 Test MSE 0.1297616702140832 Test RE 0.17217943315875797\n",
      "78 Train Loss 0.27206445 Test MSE 0.12125873005507537 Test RE 0.1664426294203096\n",
      "79 Train Loss 0.26360187 Test MSE 0.11812925966068487 Test RE 0.16428079708199347\n",
      "80 Train Loss 0.23710097 Test MSE 0.09454354957037925 Test RE 0.14696841552764045\n",
      "81 Train Loss 0.22694463 Test MSE 0.08120654877192579 Test RE 0.13620830455101218\n",
      "82 Train Loss 0.2197583 Test MSE 0.06615997624990315 Test RE 0.12294354472432104\n",
      "83 Train Loss 0.20558333 Test MSE 0.046319440791346325 Test RE 0.10287023076310806\n",
      "84 Train Loss 0.19685566 Test MSE 0.04154795335851613 Test RE 0.09742779597379561\n",
      "85 Train Loss 0.1912291 Test MSE 0.039257654073943805 Test RE 0.09470441640908459\n",
      "86 Train Loss 0.18225893 Test MSE 0.03456250484193845 Test RE 0.08886089130019618\n",
      "87 Train Loss 0.17707293 Test MSE 0.03174035438022055 Test RE 0.08515574365619673\n",
      "88 Train Loss 0.17450413 Test MSE 0.03135316545668061 Test RE 0.08463475813546908\n",
      "89 Train Loss 0.17213827 Test MSE 0.028916625615804888 Test RE 0.08127965777881717\n",
      "90 Train Loss 0.16501294 Test MSE 0.026190710539999523 Test RE 0.07735380844537293\n",
      "91 Train Loss 0.160593 Test MSE 0.026783872168928382 Test RE 0.07822485054481158\n",
      "92 Train Loss 0.15638636 Test MSE 0.02340430060246248 Test RE 0.07312331877017703\n",
      "93 Train Loss 0.15165192 Test MSE 0.01994815118404635 Test RE 0.06750864416874487\n",
      "94 Train Loss 0.14820828 Test MSE 0.019129573102500925 Test RE 0.0661090169920268\n",
      "95 Train Loss 0.14465715 Test MSE 0.019297347329434708 Test RE 0.06639828576480623\n",
      "96 Train Loss 0.13961074 Test MSE 0.01905967661523721 Test RE 0.06598813042862262\n",
      "97 Train Loss 0.13569586 Test MSE 0.01784059011860224 Test RE 0.06384290909653148\n",
      "98 Train Loss 0.13211352 Test MSE 0.01688121700732122 Test RE 0.06210262199790921\n",
      "99 Train Loss 0.12853146 Test MSE 0.01511180720245715 Test RE 0.05875789954118747\n",
      "Training time: 71.25\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.694237 Test MSE 8.509037598530416 Test RE 1.3942744904203694\n",
      "1 Train Loss 55.511555 Test MSE 8.531525314111212 Test RE 1.3961156716056489\n",
      "2 Train Loss 54.10572 Test MSE 8.162700334454053 Test RE 1.3656046498137022\n",
      "3 Train Loss 49.702293 Test MSE 7.689398122676173 Test RE 1.3254221800324428\n",
      "4 Train Loss 47.96547 Test MSE 7.443438773348666 Test RE 1.3040518826967555\n",
      "5 Train Loss 45.977036 Test MSE 7.948202938180004 Test RE 1.3475426944164735\n",
      "6 Train Loss 44.789 Test MSE 8.182322963980877 Test RE 1.3672450793233581\n",
      "7 Train Loss 43.0916 Test MSE 7.934764387117735 Test RE 1.3464030228167727\n",
      "8 Train Loss 42.29877 Test MSE 7.963478348281541 Test RE 1.3488369735679475\n",
      "9 Train Loss 41.397064 Test MSE 7.899451672632187 Test RE 1.3434036796900934\n",
      "10 Train Loss 40.89885 Test MSE 8.076985747738052 Test RE 1.3584157820452971\n",
      "11 Train Loss 40.23259 Test MSE 7.815140134303254 Test RE 1.3362153152641532\n",
      "12 Train Loss 40.07337 Test MSE 7.856530307177573 Test RE 1.3397490426015146\n",
      "13 Train Loss 39.95424 Test MSE 7.881176653849563 Test RE 1.341848828531389\n",
      "14 Train Loss 39.894806 Test MSE 7.865676057333299 Test RE 1.3405286135884644\n",
      "15 Train Loss 39.614655 Test MSE 7.864044101279008 Test RE 1.3403895411643727\n",
      "16 Train Loss 39.25486 Test MSE 7.703714141981344 Test RE 1.32665543299208\n",
      "17 Train Loss 38.757984 Test MSE 7.383225087873279 Test RE 1.298766609430628\n",
      "18 Train Loss 37.110184 Test MSE 6.69849469984464 Test RE 1.2370768200858144\n",
      "19 Train Loss 36.47811 Test MSE 6.82563066011038 Test RE 1.2487613615442408\n",
      "20 Train Loss 35.823494 Test MSE 5.835471884573098 Test RE 1.1546385434448123\n",
      "21 Train Loss 33.563534 Test MSE 5.824189499441433 Test RE 1.1535218060350936\n",
      "22 Train Loss 32.85646 Test MSE 5.719066220226867 Test RE 1.143064199289415\n",
      "23 Train Loss 30.805286 Test MSE 5.507472145068503 Test RE 1.1217193584877514\n",
      "24 Train Loss 27.605991 Test MSE 5.0666865489130615 Test RE 1.075895470148141\n",
      "25 Train Loss 21.195145 Test MSE 4.334808476437698 Test RE 0.9951602424698462\n",
      "26 Train Loss 17.378532 Test MSE 3.968740552769063 Test RE 0.9522136760835531\n",
      "27 Train Loss 15.117214 Test MSE 3.405440032073463 Test RE 0.8820529946599668\n",
      "28 Train Loss 14.343627 Test MSE 3.4816181249783362 Test RE 0.8918639867467424\n",
      "29 Train Loss 13.8052225 Test MSE 3.3342589110428427 Test RE 0.8727858980021455\n",
      "30 Train Loss 13.439332 Test MSE 3.4144054930059853 Test RE 0.8832133166151254\n",
      "31 Train Loss 13.127087 Test MSE 3.5317999407848557 Test RE 0.8982683705410266\n",
      "32 Train Loss 12.78829 Test MSE 3.6498601787248424 Test RE 0.9131585168447184\n",
      "33 Train Loss 12.595859 Test MSE 3.670334242743777 Test RE 0.9157161381210848\n",
      "34 Train Loss 12.356814 Test MSE 3.7397478314107837 Test RE 0.9243346208371606\n",
      "35 Train Loss 12.092237 Test MSE 3.831765519001187 Test RE 0.9356372908929431\n",
      "36 Train Loss 12.00212 Test MSE 3.7994016918742326 Test RE 0.9316776260581088\n",
      "37 Train Loss 11.836531 Test MSE 3.8392332229778843 Test RE 0.936548575956706\n",
      "38 Train Loss 11.735434 Test MSE 3.851524078380384 Test RE 0.9380465033302011\n",
      "39 Train Loss 11.63542 Test MSE 3.8542710021934035 Test RE 0.9383809531418973\n",
      "40 Train Loss 11.5596285 Test MSE 3.9458184750032075 Test RE 0.949459865034179\n",
      "41 Train Loss 11.4631195 Test MSE 3.9934134782503574 Test RE 0.9551689581837755\n",
      "42 Train Loss 11.409825 Test MSE 3.9977730633579824 Test RE 0.9556901920249881\n",
      "43 Train Loss 11.361717 Test MSE 4.0128392370223045 Test RE 0.9574893254289267\n",
      "44 Train Loss 11.287653 Test MSE 4.053400333259897 Test RE 0.9623162283121486\n",
      "45 Train Loss 11.221396 Test MSE 4.056579494727237 Test RE 0.9626935361003418\n",
      "46 Train Loss 11.110865 Test MSE 3.996766935295774 Test RE 0.9555699241643595\n",
      "47 Train Loss 11.004105 Test MSE 3.984029034648295 Test RE 0.9540459838647817\n",
      "48 Train Loss 10.820924 Test MSE 4.019887220638908 Test RE 0.9583298037213557\n",
      "49 Train Loss 10.723339 Test MSE 4.0473582729813575 Test RE 0.961598739223387\n",
      "50 Train Loss 10.621406 Test MSE 4.042336054212504 Test RE 0.9610019476887106\n",
      "51 Train Loss 10.475059 Test MSE 4.011954944082031 Test RE 0.9573838206164981\n",
      "52 Train Loss 10.415184 Test MSE 4.0138395423606505 Test RE 0.9576086576456514\n",
      "53 Train Loss 10.361853 Test MSE 4.0333981274128465 Test RE 0.9599389338588001\n",
      "54 Train Loss 10.213522 Test MSE 4.017755559403157 Test RE 0.9580756790069871\n",
      "55 Train Loss 10.101807 Test MSE 3.995256292666589 Test RE 0.9553893205524119\n",
      "56 Train Loss 9.937607 Test MSE 3.968572119737946 Test RE 0.9521934699330997\n",
      "57 Train Loss 9.747585 Test MSE 4.040105019879219 Test RE 0.9607367143899418\n",
      "58 Train Loss 9.527955 Test MSE 4.0324850192673605 Test RE 0.9598302689506752\n",
      "59 Train Loss 9.448486 Test MSE 4.041094954966304 Test RE 0.9608544104307866\n",
      "60 Train Loss 9.342941 Test MSE 4.05675055642313 Test RE 0.9627138337739196\n",
      "61 Train Loss 9.188329 Test MSE 4.0001866367001275 Test RE 0.9559786376538989\n",
      "62 Train Loss 9.012777 Test MSE 3.981794121098793 Test RE 0.9537783516026823\n",
      "63 Train Loss 8.880513 Test MSE 3.90580785349792 Test RE 0.9446338356886901\n",
      "64 Train Loss 8.793741 Test MSE 3.89133914196207 Test RE 0.9428825570651318\n",
      "65 Train Loss 8.688652 Test MSE 3.910506233115104 Test RE 0.9452018250281542\n",
      "66 Train Loss 8.606644 Test MSE 3.8952500021636376 Test RE 0.9433562443618311\n",
      "67 Train Loss 8.479313 Test MSE 3.9020505348684162 Test RE 0.944179365775983\n",
      "68 Train Loss 8.359682 Test MSE 3.8825530149399805 Test RE 0.941817503737493\n",
      "69 Train Loss 8.209561 Test MSE 3.8880045011212125 Test RE 0.9424784739913425\n",
      "70 Train Loss 8.098342 Test MSE 3.8101274445828825 Test RE 0.9329917673388634\n",
      "71 Train Loss 7.962261 Test MSE 3.7378153455179355 Test RE 0.9240957685783041\n",
      "72 Train Loss 7.8541307 Test MSE 3.7339359580925544 Test RE 0.9236160958506927\n",
      "73 Train Loss 7.7773895 Test MSE 3.689780296879923 Test RE 0.9181387433227425\n",
      "74 Train Loss 7.6798687 Test MSE 3.6028793423815673 Test RE 0.9072624140850776\n",
      "75 Train Loss 7.5536966 Test MSE 3.5434448558987044 Test RE 0.8997480198691267\n",
      "76 Train Loss 7.0708904 Test MSE 2.5444461708936053 Test RE 0.7624382819636941\n",
      "77 Train Loss 6.105978 Test MSE 2.3353850755148495 Test RE 0.7304446466358296\n",
      "78 Train Loss 5.67424 Test MSE 2.2547766832723233 Test RE 0.7177278984981884\n",
      "79 Train Loss 5.3330555 Test MSE 2.2333820004027563 Test RE 0.7143146646191963\n",
      "80 Train Loss 5.1981354 Test MSE 2.195903552125563 Test RE 0.7082958396928019\n",
      "81 Train Loss 5.084865 Test MSE 2.202387990650436 Test RE 0.7093408571634702\n",
      "82 Train Loss 4.9120793 Test MSE 2.1812941928371723 Test RE 0.7059357595349958\n",
      "83 Train Loss 4.81187 Test MSE 2.158074738662607 Test RE 0.7021684323832785\n",
      "84 Train Loss 4.670169 Test MSE 2.1132937396149223 Test RE 0.6948450908460782\n",
      "85 Train Loss 4.3806114 Test MSE 2.020220979081492 Test RE 0.6793717731667152\n",
      "86 Train Loss 3.153579 Test MSE 1.6754606075524285 Test RE 0.618692955299299\n",
      "87 Train Loss 2.3642886 Test MSE 1.3587241095357774 Test RE 0.5571520093546675\n",
      "88 Train Loss 1.8262521 Test MSE 1.0851845623513328 Test RE 0.4979203356660472\n",
      "89 Train Loss 1.5641177 Test MSE 0.9390736512704164 Test RE 0.4631886276038284\n",
      "90 Train Loss 1.3889058 Test MSE 0.7484303824366582 Test RE 0.4135078560544794\n",
      "91 Train Loss 1.1830661 Test MSE 0.5933899249237521 Test RE 0.3681952185621032\n",
      "92 Train Loss 0.9728881 Test MSE 0.43352866467761436 Test RE 0.3147146568694196\n",
      "93 Train Loss 0.75932133 Test MSE 0.2965904378575084 Test RE 0.2603074710180731\n",
      "94 Train Loss 0.62029886 Test MSE 0.198998613592444 Test RE 0.213222526788999\n",
      "95 Train Loss 0.5400586 Test MSE 0.13252572141546512 Test RE 0.17400356602405304\n",
      "96 Train Loss 0.42564523 Test MSE 0.07821779718564936 Test RE 0.1336782805448304\n",
      "97 Train Loss 0.35508245 Test MSE 0.059862765993694 Test RE 0.11694629036529595\n",
      "98 Train Loss 0.29768854 Test MSE 0.04357465796782368 Test RE 0.09977576211152701\n",
      "99 Train Loss 0.25124335 Test MSE 0.050657229973901506 Test RE 0.10757931616669632\n",
      "Training time: 70.62\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.158264 Test MSE 8.564072584686123 Test RE 1.3987761864498627\n",
      "1 Train Loss 55.436535 Test MSE 8.465259203565449 Test RE 1.3906831434730855\n",
      "2 Train Loss 49.151024 Test MSE 8.216538907335297 Test RE 1.3701007949836277\n",
      "3 Train Loss 46.08056 Test MSE 8.944111942691821 Test RE 1.429475358534289\n",
      "4 Train Loss 43.21589 Test MSE 8.326063992258888 Test RE 1.3792021722799253\n",
      "5 Train Loss 42.583176 Test MSE 8.13695627354028 Test RE 1.363449482336247\n",
      "6 Train Loss 42.22767 Test MSE 8.176356634194835 Test RE 1.366746509255576\n",
      "7 Train Loss 41.557644 Test MSE 8.442919115755071 Test RE 1.3888469027134098\n",
      "8 Train Loss 40.803574 Test MSE 8.322765594092925 Test RE 1.3789289574361483\n",
      "9 Train Loss 40.2667 Test MSE 8.327818106215602 Test RE 1.3793474480292693\n",
      "10 Train Loss 39.6412 Test MSE 8.118336002446439 Test RE 1.3618885583944957\n",
      "11 Train Loss 39.478992 Test MSE 7.980696131382803 Test RE 1.3502943419365632\n",
      "12 Train Loss 38.9657 Test MSE 7.864286044052109 Test RE 1.3404101600129055\n",
      "13 Train Loss 38.670113 Test MSE 7.797032231304262 Test RE 1.3346663929864624\n",
      "14 Train Loss 38.21325 Test MSE 7.5597402921885335 Test RE 1.3142001071632512\n",
      "15 Train Loss 37.761955 Test MSE 7.050632940845789 Test RE 1.2691767659303286\n",
      "16 Train Loss 34.154167 Test MSE 6.195178216102489 Test RE 1.189693153731171\n",
      "17 Train Loss 28.316433 Test MSE 5.624828466830417 Test RE 1.1336074769007052\n",
      "18 Train Loss 26.402172 Test MSE 5.603988270872236 Test RE 1.1315054994596199\n",
      "19 Train Loss 25.118576 Test MSE 5.415716025708428 Test RE 1.1123360234529918\n",
      "20 Train Loss 24.20683 Test MSE 5.2574150743796695 Test RE 1.0959587119983785\n",
      "21 Train Loss 23.593712 Test MSE 5.245860392649671 Test RE 1.09475370730698\n",
      "22 Train Loss 23.0154 Test MSE 5.626669797836123 Test RE 1.1337930092959172\n",
      "23 Train Loss 21.586647 Test MSE 5.782661450530378 Test RE 1.1494019875580959\n",
      "24 Train Loss 20.829288 Test MSE 5.395252564047032 Test RE 1.110232535367994\n",
      "25 Train Loss 20.38939 Test MSE 5.372702194782172 Test RE 1.1079099036776543\n",
      "26 Train Loss 19.890656 Test MSE 5.506375607660155 Test RE 1.1216076857969473\n",
      "27 Train Loss 19.641996 Test MSE 5.359189935613927 Test RE 1.106515838864242\n",
      "28 Train Loss 19.447498 Test MSE 5.308128883795362 Test RE 1.1012319165318212\n",
      "29 Train Loss 19.264875 Test MSE 5.228538165061093 Test RE 1.092944732978773\n",
      "30 Train Loss 18.883162 Test MSE 5.209965860834121 Test RE 1.0910018802043342\n",
      "31 Train Loss 18.709238 Test MSE 5.317990867459179 Test RE 1.1022544323496477\n",
      "32 Train Loss 18.53715 Test MSE 5.30755441903738 Test RE 1.1011723252843912\n",
      "33 Train Loss 18.392136 Test MSE 5.21439167773149 Test RE 1.0914651797406079\n",
      "34 Train Loss 18.14352 Test MSE 5.289579768407885 Test RE 1.0993061198076397\n",
      "35 Train Loss 18.00793 Test MSE 5.302438205415915 Test RE 1.1006414601492995\n",
      "36 Train Loss 17.721127 Test MSE 5.400868786460746 Test RE 1.1108102368701445\n",
      "37 Train Loss 17.55069 Test MSE 5.551000160295661 Test RE 1.1261433593306984\n",
      "38 Train Loss 17.241163 Test MSE 5.648162565485237 Test RE 1.1359563780693902\n",
      "39 Train Loss 17.063026 Test MSE 5.731913718389012 Test RE 1.1443473875214845\n",
      "40 Train Loss 16.843594 Test MSE 5.878780172190256 Test RE 1.1589152311146425\n",
      "41 Train Loss 16.661827 Test MSE 5.857364808132744 Test RE 1.156802442869138\n",
      "42 Train Loss 16.551352 Test MSE 5.872533433138159 Test RE 1.1582993409993572\n",
      "43 Train Loss 16.370316 Test MSE 5.93874303791295 Test RE 1.1648106356129346\n",
      "44 Train Loss 16.309387 Test MSE 5.92891057266794 Test RE 1.163845978238202\n",
      "45 Train Loss 16.201733 Test MSE 5.896367282322629 Test RE 1.1606474568621672\n",
      "46 Train Loss 16.027733 Test MSE 5.8561713384631995 Test RE 1.1566845844969662\n",
      "47 Train Loss 15.854515 Test MSE 5.805394757335988 Test RE 1.1516590864522758\n",
      "48 Train Loss 15.766951 Test MSE 5.7493094470448325 Test RE 1.1460825563315191\n",
      "49 Train Loss 15.739595 Test MSE 5.756789022683725 Test RE 1.1468278132228613\n",
      "50 Train Loss 15.691463 Test MSE 5.7128469423203185 Test RE 1.142442509716104\n",
      "51 Train Loss 15.616395 Test MSE 5.73010339197528 Test RE 1.1441666620253503\n",
      "52 Train Loss 15.595465 Test MSE 5.728610855017096 Test RE 1.144017640085414\n",
      "53 Train Loss 15.546114 Test MSE 5.704965998493336 Test RE 1.1416542308948683\n",
      "54 Train Loss 15.405697 Test MSE 5.75472722384665 Test RE 1.1466224261577211\n",
      "55 Train Loss 15.309067 Test MSE 5.739245339977232 Test RE 1.1450790141016551\n",
      "56 Train Loss 15.26722 Test MSE 5.660619492590271 Test RE 1.1372083544455742\n",
      "57 Train Loss 15.162323 Test MSE 5.774412625947085 Test RE 1.1485818981368001\n",
      "58 Train Loss 15.115389 Test MSE 5.770461660440331 Test RE 1.148188889854472\n",
      "59 Train Loss 15.065434 Test MSE 5.74469352065634 Test RE 1.1456223884602588\n",
      "60 Train Loss 14.986925 Test MSE 5.755646634821629 Test RE 1.1467140182608786\n",
      "61 Train Loss 14.925215 Test MSE 5.755608411184869 Test RE 1.1467102105520617\n",
      "62 Train Loss 14.870037 Test MSE 5.712835155477044 Test RE 1.1424413311620576\n",
      "63 Train Loss 14.808958 Test MSE 5.725768541709663 Test RE 1.1437337964031458\n",
      "64 Train Loss 14.748012 Test MSE 5.6818641761226205 Test RE 1.1393403654288172\n",
      "65 Train Loss 14.674721 Test MSE 5.7475816163080795 Test RE 1.1459103282154623\n",
      "66 Train Loss 14.626796 Test MSE 5.778796933235607 Test RE 1.1490178542082012\n",
      "67 Train Loss 14.484858 Test MSE 5.835965522192692 Test RE 1.1546873793384633\n",
      "68 Train Loss 14.412535 Test MSE 5.817609866753232 Test RE 1.152870050581058\n",
      "69 Train Loss 14.352173 Test MSE 5.838832212331839 Test RE 1.1549709420598526\n",
      "70 Train Loss 14.312118 Test MSE 5.865379957116087 Test RE 1.1575936497079757\n",
      "71 Train Loss 14.231187 Test MSE 5.861781558963792 Test RE 1.1572385046060858\n",
      "72 Train Loss 14.056707 Test MSE 5.883981195714239 Test RE 1.1594277705048543\n",
      "73 Train Loss 13.986994 Test MSE 5.887345827189654 Test RE 1.1597592203783937\n",
      "74 Train Loss 13.899536 Test MSE 5.851239818002456 Test RE 1.1561974560678094\n",
      "75 Train Loss 13.81293 Test MSE 5.876589276173855 Test RE 1.1586992594932728\n",
      "76 Train Loss 13.739607 Test MSE 5.850518840983461 Test RE 1.1561262218079689\n",
      "77 Train Loss 13.645111 Test MSE 5.857554422922124 Test RE 1.1568211667393076\n",
      "78 Train Loss 13.5532255 Test MSE 5.9081219402516565 Test RE 1.161803780787247\n",
      "79 Train Loss 13.482353 Test MSE 5.874001842816503 Test RE 1.158444146616197\n",
      "80 Train Loss 13.394342 Test MSE 5.869744862588502 Test RE 1.1580242993159944\n",
      "81 Train Loss 13.317775 Test MSE 5.896131309095761 Test RE 1.1606242320143259\n",
      "82 Train Loss 13.211972 Test MSE 5.886661830584524 Test RE 1.1596918475388445\n",
      "83 Train Loss 13.079731 Test MSE 5.877537135094766 Test RE 1.1587927013772528\n",
      "84 Train Loss 12.929878 Test MSE 5.913006726783183 Test RE 1.162283966450148\n",
      "85 Train Loss 12.767074 Test MSE 5.859665066078073 Test RE 1.1570295657223837\n",
      "86 Train Loss 12.655528 Test MSE 5.790545694177162 Test RE 1.1501852841937836\n",
      "87 Train Loss 12.560054 Test MSE 5.785641656455864 Test RE 1.1496981326301858\n",
      "88 Train Loss 12.426445 Test MSE 5.791674005852835 Test RE 1.1502973379052297\n",
      "89 Train Loss 12.270548 Test MSE 5.755061689265964 Test RE 1.1466557465883387\n",
      "90 Train Loss 12.140821 Test MSE 5.732190203856296 Test RE 1.1443749866465223\n",
      "91 Train Loss 12.077349 Test MSE 5.725311804860384 Test RE 1.1436881784407111\n",
      "92 Train Loss 11.959923 Test MSE 5.705789564045465 Test RE 1.141736632189376\n",
      "93 Train Loss 11.913961 Test MSE 5.700224788694895 Test RE 1.1411797366297305\n",
      "94 Train Loss 11.879059 Test MSE 5.703792097641684 Test RE 1.1415367667571799\n",
      "95 Train Loss 11.856131 Test MSE 5.68298457349379 Test RE 1.1394526922100032\n",
      "96 Train Loss 11.806471 Test MSE 5.665451540051717 Test RE 1.1376936257637138\n",
      "97 Train Loss 11.763786 Test MSE 5.708547165361138 Test RE 1.1420124988406577\n",
      "98 Train Loss 11.729295 Test MSE 5.705108196683287 Test RE 1.1416684588634167\n",
      "99 Train Loss 11.710037 Test MSE 5.720626299079641 Test RE 1.1432200943796262\n",
      "Training time: 70.02\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.650993 Test MSE 8.624315994600822 Test RE 1.4036873646616106\n",
      "1 Train Loss 56.23677 Test MSE 8.630834741116182 Test RE 1.4042177576632437\n",
      "2 Train Loss 51.416702 Test MSE 8.362399901685656 Test RE 1.3822083951361255\n",
      "3 Train Loss 45.173073 Test MSE 8.762947545507947 Test RE 1.4149241730957245\n",
      "4 Train Loss 45.025585 Test MSE 8.643261036646102 Test RE 1.405228259499351\n",
      "5 Train Loss 44.78691 Test MSE 8.528399257800295 Test RE 1.3958598711534886\n",
      "6 Train Loss 44.49432 Test MSE 8.572103070183935 Test RE 1.3994318452942007\n",
      "7 Train Loss 43.652206 Test MSE 8.55429976238298 Test RE 1.397977857555895\n",
      "8 Train Loss 43.598274 Test MSE 8.551598243238853 Test RE 1.3977570935966732\n",
      "9 Train Loss 43.481396 Test MSE 8.459956307578631 Test RE 1.3902474921143402\n",
      "10 Train Loss 43.31405 Test MSE 8.54929399081484 Test RE 1.397568766100973\n",
      "11 Train Loss 42.82413 Test MSE 8.244119622014844 Test RE 1.3723983987133004\n",
      "12 Train Loss 41.295513 Test MSE 7.863105981478056 Test RE 1.340309589713408\n",
      "13 Train Loss 39.195866 Test MSE 7.7418287447848435 Test RE 1.3299332386646034\n",
      "14 Train Loss 38.117023 Test MSE 7.699518641020186 Test RE 1.3262941305042575\n",
      "15 Train Loss 37.86406 Test MSE 7.8779535809437045 Test RE 1.341574420339757\n",
      "16 Train Loss 37.671257 Test MSE 8.027465202518119 Test RE 1.354245110088434\n",
      "17 Train Loss 37.318443 Test MSE 8.131284942433938 Test RE 1.362974248044608\n",
      "18 Train Loss 37.103424 Test MSE 8.277688115797988 Test RE 1.3751896334385063\n",
      "19 Train Loss 36.91455 Test MSE 8.201323854921077 Test RE 1.3688316587265732\n",
      "20 Train Loss 36.757805 Test MSE 8.180582188577928 Test RE 1.3670996320453286\n",
      "21 Train Loss 36.64017 Test MSE 8.200853849662698 Test RE 1.3687924353459\n",
      "22 Train Loss 36.58278 Test MSE 8.212284619159407 Test RE 1.3697460496115286\n",
      "23 Train Loss 36.46264 Test MSE 8.202597658664383 Test RE 1.36893795590636\n",
      "24 Train Loss 36.330223 Test MSE 8.160826110174963 Test RE 1.3654478636877843\n",
      "25 Train Loss 36.17702 Test MSE 8.12214428994145 Test RE 1.3622079498971968\n",
      "26 Train Loss 36.002144 Test MSE 8.087158729935547 Test RE 1.35927097675701\n",
      "27 Train Loss 35.837944 Test MSE 8.161046877683628 Test RE 1.365466332681018\n",
      "28 Train Loss 35.428345 Test MSE 8.186371832149764 Test RE 1.3675833152041432\n",
      "29 Train Loss 34.915695 Test MSE 8.174666033926385 Test RE 1.3666052029518492\n",
      "30 Train Loss 34.469116 Test MSE 8.066925215137223 Test RE 1.3575695106152865\n",
      "31 Train Loss 34.304832 Test MSE 7.982072241989749 Test RE 1.3504107524753446\n",
      "32 Train Loss 33.848602 Test MSE 7.588618505015948 Test RE 1.3167078371949925\n",
      "33 Train Loss 33.242195 Test MSE 7.556916314021042 Test RE 1.3139546212786406\n",
      "34 Train Loss 32.135006 Test MSE 7.299261328248763 Test RE 1.2913605548120715\n",
      "35 Train Loss 30.891289 Test MSE 7.1659235019203305 Test RE 1.279511354191885\n",
      "36 Train Loss 30.034676 Test MSE 7.256836426353201 Test RE 1.2876022509647436\n",
      "37 Train Loss 29.301594 Test MSE 7.112108323419878 Test RE 1.2746978157341542\n",
      "38 Train Loss 28.451418 Test MSE 6.642758469569475 Test RE 1.2319193907174522\n",
      "39 Train Loss 28.044952 Test MSE 6.58691679730677 Test RE 1.2267304602280344\n",
      "40 Train Loss 27.180283 Test MSE 6.295003875706499 Test RE 1.199239876998589\n",
      "41 Train Loss 26.353302 Test MSE 6.009921694524336 Test RE 1.1717702485749002\n",
      "42 Train Loss 25.214867 Test MSE 5.472285994619276 Test RE 1.1181303954265223\n",
      "43 Train Loss 25.005043 Test MSE 5.25238958445149 Test RE 1.0954347809209535\n",
      "44 Train Loss 24.496584 Test MSE 5.054048317562212 Test RE 1.0745527873518839\n",
      "45 Train Loss 24.115374 Test MSE 5.163538580417616 Test RE 1.086129909750184\n",
      "46 Train Loss 23.890202 Test MSE 5.02035884038037 Test RE 1.0709654006708045\n",
      "47 Train Loss 23.687363 Test MSE 4.909736244069661 Test RE 1.0591004225008378\n",
      "48 Train Loss 23.485703 Test MSE 4.805843471924009 Test RE 1.0478349283810762\n",
      "49 Train Loss 23.145947 Test MSE 4.169769183902868 Test RE 0.9760320256068892\n",
      "50 Train Loss 22.941008 Test MSE 3.9496086545456466 Test RE 0.9499157602590359\n",
      "51 Train Loss 22.841125 Test MSE 3.8559177740971964 Test RE 0.9385813975790297\n",
      "52 Train Loss 22.679813 Test MSE 3.8906882566618104 Test RE 0.9428036980863818\n",
      "53 Train Loss 22.456589 Test MSE 3.988158109670785 Test RE 0.9545402457351293\n",
      "54 Train Loss 22.354988 Test MSE 4.02960539906684 Test RE 0.95948749765307\n",
      "55 Train Loss 22.200935 Test MSE 4.093426782999752 Test RE 0.967055888366184\n",
      "56 Train Loss 22.040928 Test MSE 4.096860049805854 Test RE 0.9674613512182089\n",
      "57 Train Loss 21.906673 Test MSE 4.080196723238751 Test RE 0.9654918489421344\n",
      "58 Train Loss 21.725445 Test MSE 4.203267685282023 Test RE 0.9799447369380407\n",
      "59 Train Loss 21.09552 Test MSE 4.810733892368413 Test RE 1.0483679305913003\n",
      "60 Train Loss 20.574556 Test MSE 4.835625677130043 Test RE 1.0510766731906909\n",
      "61 Train Loss 20.261583 Test MSE 4.825454468714394 Test RE 1.0499706790311536\n",
      "62 Train Loss 19.956993 Test MSE 4.790728483734157 Test RE 1.0461858437383624\n",
      "63 Train Loss 19.755306 Test MSE 4.8139180046049495 Test RE 1.0487148183071355\n",
      "64 Train Loss 19.653465 Test MSE 4.8318900592027205 Test RE 1.0506706058347413\n",
      "65 Train Loss 19.396923 Test MSE 4.8586541272059325 Test RE 1.0535764446333418\n",
      "66 Train Loss 19.312986 Test MSE 4.907490694830781 Test RE 1.0588581962359211\n",
      "67 Train Loss 19.177042 Test MSE 4.9860139653701925 Test RE 1.0672958127078178\n",
      "68 Train Loss 19.02209 Test MSE 4.9344360541729255 Test RE 1.0617611317257925\n",
      "69 Train Loss 18.792364 Test MSE 4.818043603513243 Test RE 1.0491641041193722\n",
      "70 Train Loss 18.512482 Test MSE 4.772045740191417 Test RE 1.0441439084677242\n",
      "71 Train Loss 18.15765 Test MSE 4.589781410138185 Test RE 1.0240096788796016\n",
      "72 Train Loss 17.8037 Test MSE 4.402046706115083 Test RE 1.0028486249349566\n",
      "73 Train Loss 17.439816 Test MSE 4.462856906858458 Test RE 1.0097515799797416\n",
      "74 Train Loss 16.711292 Test MSE 4.629419286636353 Test RE 1.028421905509236\n",
      "75 Train Loss 14.902509 Test MSE 3.9555225164058045 Test RE 0.9506266622463396\n",
      "76 Train Loss 13.753888 Test MSE 3.4994818158126098 Test RE 0.8941490734544694\n",
      "77 Train Loss 13.147087 Test MSE 3.7499695046986856 Test RE 0.9255969785718106\n",
      "78 Train Loss 12.688791 Test MSE 3.7506926632193296 Test RE 0.9256862221075034\n",
      "79 Train Loss 12.258003 Test MSE 3.6948631372373577 Test RE 0.9187709146477105\n",
      "80 Train Loss 11.965569 Test MSE 3.7519082546244413 Test RE 0.9258362164096161\n",
      "81 Train Loss 11.732508 Test MSE 3.7385118930671046 Test RE 0.9241818678901434\n",
      "82 Train Loss 10.994763 Test MSE 3.636041828661911 Test RE 0.9114282711178602\n",
      "83 Train Loss 8.885464 Test MSE 3.1787675311258634 Test RE 0.8521919833941519\n",
      "84 Train Loss 5.737033 Test MSE 3.0353557730651692 Test RE 0.8327465866502654\n",
      "85 Train Loss 4.736584 Test MSE 2.7625214008788728 Test RE 0.7944396032462708\n",
      "86 Train Loss 4.2269526 Test MSE 2.766050016744241 Test RE 0.7949468169807171\n",
      "87 Train Loss 3.5705032 Test MSE 2.639172754177678 Test RE 0.7765009114105401\n",
      "88 Train Loss 3.1845376 Test MSE 2.5548548107823144 Test RE 0.7639961545986194\n",
      "89 Train Loss 2.7432368 Test MSE 2.5490775372969288 Test RE 0.7631318564074309\n",
      "90 Train Loss 2.4880517 Test MSE 2.5242001203244198 Test RE 0.7593988792068287\n",
      "91 Train Loss 2.2817652 Test MSE 2.5211195493528873 Test RE 0.7589353469547254\n",
      "92 Train Loss 2.176289 Test MSE 2.539324470701345 Test RE 0.7616705417383336\n",
      "93 Train Loss 2.0672023 Test MSE 2.490520798933839 Test RE 0.7543156995533838\n",
      "94 Train Loss 2.0025153 Test MSE 2.538226527455269 Test RE 0.7615058598609015\n",
      "95 Train Loss 1.9140271 Test MSE 2.5739629245372986 Test RE 0.7668478491196608\n",
      "96 Train Loss 1.8476185 Test MSE 2.576465056353782 Test RE 0.7672204823669942\n",
      "97 Train Loss 1.802049 Test MSE 2.560970151889067 Test RE 0.7649099647708218\n",
      "98 Train Loss 1.7708939 Test MSE 2.5382162156915795 Test RE 0.7615043130177881\n",
      "99 Train Loss 1.7384903 Test MSE 2.50673053426229 Test RE 0.7567664774858209\n",
      "Training time: 71.43\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.58457 Test MSE 8.677375181426527 Test RE 1.4079986809495468\n",
      "1 Train Loss 54.65739 Test MSE 8.869936384816576 Test RE 1.4235355354217116\n",
      "2 Train Loss 47.683426 Test MSE 7.87205198590107 Test RE 1.3410718207614223\n",
      "3 Train Loss 38.442574 Test MSE 7.614972225484744 Test RE 1.31899218419599\n",
      "4 Train Loss 36.44889 Test MSE 7.449847725686527 Test RE 1.3046131695141459\n",
      "5 Train Loss 34.48618 Test MSE 7.254704987832683 Test RE 1.2874131433132798\n",
      "6 Train Loss 32.658363 Test MSE 6.288082682254586 Test RE 1.1985804291206632\n",
      "7 Train Loss 30.73367 Test MSE 6.429312636316726 Test RE 1.2119657100290682\n",
      "8 Train Loss 27.980381 Test MSE 6.114282514590567 Test RE 1.1819002136152708\n",
      "9 Train Loss 26.659271 Test MSE 6.438560497350472 Test RE 1.2128370366849364\n",
      "10 Train Loss 25.467632 Test MSE 6.202763638522772 Test RE 1.1904212655089088\n",
      "11 Train Loss 24.232891 Test MSE 6.05399282647231 Test RE 1.1760587332906456\n",
      "12 Train Loss 23.509901 Test MSE 5.754466551728219 Test RE 1.1465964565617652\n",
      "13 Train Loss 23.248081 Test MSE 5.771895694480502 Test RE 1.148331550855053\n",
      "14 Train Loss 23.059278 Test MSE 5.830700261477394 Test RE 1.1541663771161632\n",
      "15 Train Loss 22.915058 Test MSE 5.8649984504159836 Test RE 1.1575560019410673\n",
      "16 Train Loss 22.56345 Test MSE 5.977215164048126 Test RE 1.168577459629261\n",
      "17 Train Loss 22.220184 Test MSE 6.006323334552898 Test RE 1.171419405194783\n",
      "18 Train Loss 21.030502 Test MSE 5.988543054521949 Test RE 1.1696842669952978\n",
      "19 Train Loss 18.751886 Test MSE 5.7025025361710755 Test RE 1.1414077153277908\n",
      "20 Train Loss 17.582687 Test MSE 5.6780088587091875 Test RE 1.1389537613160006\n",
      "21 Train Loss 16.067724 Test MSE 5.655209173718986 Test RE 1.1366647628225865\n",
      "22 Train Loss 14.882849 Test MSE 5.968603439798362 Test RE 1.167735337174178\n",
      "23 Train Loss 14.015202 Test MSE 6.016943656551969 Test RE 1.172454593944651\n",
      "24 Train Loss 13.507875 Test MSE 6.066245704851009 Test RE 1.1772482639965935\n",
      "25 Train Loss 13.005604 Test MSE 5.991459941209497 Test RE 1.1699690959661868\n",
      "26 Train Loss 12.726265 Test MSE 5.938308088109555 Test RE 1.1647679798328776\n",
      "27 Train Loss 12.577124 Test MSE 5.981352593610515 Test RE 1.1689818344428904\n",
      "28 Train Loss 12.430517 Test MSE 6.005527000430106 Test RE 1.1713417476900014\n",
      "29 Train Loss 12.314 Test MSE 5.9829219913202065 Test RE 1.1691351841292286\n",
      "30 Train Loss 12.192345 Test MSE 5.988593898161215 Test RE 1.1696892323832193\n",
      "31 Train Loss 12.112055 Test MSE 5.995898592759093 Test RE 1.1704023896667117\n",
      "32 Train Loss 12.019845 Test MSE 5.993203215593175 Test RE 1.1701392906130264\n",
      "33 Train Loss 11.951381 Test MSE 5.984448282720468 Test RE 1.1692843025021642\n",
      "34 Train Loss 11.876561 Test MSE 5.915776162274837 Test RE 1.162556120178767\n",
      "35 Train Loss 11.775749 Test MSE 5.898526926431311 Test RE 1.1608599907703072\n",
      "36 Train Loss 11.611552 Test MSE 5.888842912176038 Test RE 1.1599066677854242\n",
      "37 Train Loss 11.42558 Test MSE 5.920279168108973 Test RE 1.1629984967178293\n",
      "38 Train Loss 11.118683 Test MSE 5.775528251065792 Test RE 1.1486928466448105\n",
      "39 Train Loss 10.397512 Test MSE 5.155325520216058 Test RE 1.08526577363406\n",
      "40 Train Loss 8.941691 Test MSE 4.423651805029654 Test RE 1.0053065865866793\n",
      "41 Train Loss 7.3348827 Test MSE 3.767313628877577 Test RE 0.9277350158429609\n",
      "42 Train Loss 6.4064283 Test MSE 3.4044261875844732 Test RE 0.8819216854711815\n",
      "43 Train Loss 5.579816 Test MSE 2.5917363947991157 Test RE 0.7694908747534684\n",
      "44 Train Loss 4.9530396 Test MSE 2.065784991730596 Test RE 0.6869903224033229\n",
      "45 Train Loss 4.616278 Test MSE 1.796969385858247 Test RE 0.6407349285243434\n",
      "46 Train Loss 4.334685 Test MSE 1.7328632469628167 Test RE 0.6292021611137381\n",
      "47 Train Loss 4.1781607 Test MSE 1.7347230658314614 Test RE 0.6295397204214549\n",
      "48 Train Loss 4.0857034 Test MSE 1.7181308819264383 Test RE 0.6265217931853986\n",
      "49 Train Loss 3.973394 Test MSE 1.7554070975530724 Test RE 0.6332817684064626\n",
      "50 Train Loss 3.9045646 Test MSE 1.7399574255556016 Test RE 0.6304887927546946\n",
      "51 Train Loss 3.8189487 Test MSE 1.711523916472011 Test RE 0.6253160075795737\n",
      "52 Train Loss 3.7457342 Test MSE 1.6845935988252725 Test RE 0.6203769214762985\n",
      "53 Train Loss 3.7006035 Test MSE 1.6768713464541822 Test RE 0.6189533704251824\n",
      "54 Train Loss 3.6612337 Test MSE 1.6718867594586344 Test RE 0.6180327502801614\n",
      "55 Train Loss 3.6108117 Test MSE 1.679826300879202 Test RE 0.6194984849817792\n",
      "56 Train Loss 3.509066 Test MSE 1.6095530331030248 Test RE 0.6064021126717072\n",
      "57 Train Loss 2.9751668 Test MSE 1.3256383636103737 Test RE 0.5503267106802514\n",
      "58 Train Loss 1.3838115 Test MSE 0.8289386945050515 Test RE 0.4351803395207022\n",
      "59 Train Loss 0.58968925 Test MSE 0.1495052689343523 Test RE 0.18481461399048463\n",
      "60 Train Loss 0.36960185 Test MSE 0.08259060223544876 Test RE 0.13736414165879307\n",
      "61 Train Loss 0.26677233 Test MSE 0.052378934134914526 Test RE 0.10939220807146735\n",
      "62 Train Loss 0.20986539 Test MSE 0.04776667356517643 Test RE 0.10446494007643116\n",
      "63 Train Loss 0.1513619 Test MSE 0.04236249653107995 Test RE 0.09837819123276485\n",
      "64 Train Loss 0.12821415 Test MSE 0.03539883901054173 Test RE 0.08992958091597918\n",
      "65 Train Loss 0.09958421 Test MSE 0.021470142123387593 Test RE 0.07003667503409411\n",
      "66 Train Loss 0.08286185 Test MSE 0.015635301425114323 Test RE 0.059766963170467285\n",
      "67 Train Loss 0.0741649 Test MSE 0.013787829842191623 Test RE 0.056124956552549725\n",
      "68 Train Loss 0.066118345 Test MSE 0.012088892636651104 Test RE 0.05255346076191092\n",
      "69 Train Loss 0.058098022 Test MSE 0.012895664360211539 Test RE 0.05427876039867113\n",
      "70 Train Loss 0.051699437 Test MSE 0.01346331838122742 Test RE 0.055460543129810885\n",
      "71 Train Loss 0.047837872 Test MSE 0.01220396682972077 Test RE 0.05280299658419854\n",
      "72 Train Loss 0.03842515 Test MSE 0.007102906647988228 Test RE 0.04028339953226591\n",
      "73 Train Loss 0.03479629 Test MSE 0.0075117654785268 Test RE 0.04142657897564071\n",
      "74 Train Loss 0.029047877 Test MSE 0.00417691748359739 Test RE 0.03089128741126873\n",
      "75 Train Loss 0.027037289 Test MSE 0.0040421462789697535 Test RE 0.030388836549228523\n",
      "76 Train Loss 0.022219429 Test MSE 0.0035344495417949343 Test RE 0.028416393185128643\n",
      "77 Train Loss 0.021023318 Test MSE 0.0032322153124359028 Test RE 0.02717428975922046\n",
      "78 Train Loss 0.01929066 Test MSE 0.003115134727205717 Test RE 0.026677582856583636\n",
      "79 Train Loss 0.017400457 Test MSE 0.002418150209204706 Test RE 0.023504428587285076\n",
      "80 Train Loss 0.01599178 Test MSE 0.002065424511365201 Test RE 0.02172264593928641\n",
      "81 Train Loss 0.014085932 Test MSE 0.001505283438395819 Test RE 0.0185445885472053\n",
      "82 Train Loss 0.013733845 Test MSE 0.0015463275669895084 Test RE 0.018795713192938525\n",
      "83 Train Loss 0.01294416 Test MSE 0.0015870283340290758 Test RE 0.019041466829586212\n",
      "84 Train Loss 0.012342433 Test MSE 0.0015632194552755035 Test RE 0.018898095355985873\n",
      "85 Train Loss 0.011573166 Test MSE 0.001473124877868262 Test RE 0.018345427741606506\n",
      "86 Train Loss 0.010471272 Test MSE 0.0016497577444895316 Test RE 0.019414139600226327\n",
      "87 Train Loss 0.00980229 Test MSE 0.0013901937934458696 Test RE 0.017821560649478665\n",
      "88 Train Loss 0.009217072 Test MSE 0.0011796670065008473 Test RE 0.016416772383658247\n",
      "89 Train Loss 0.008593842 Test MSE 0.001053039982115851 Test RE 0.01551066759647788\n",
      "90 Train Loss 0.008091112 Test MSE 0.0012304273236238114 Test RE 0.016766254094948384\n",
      "91 Train Loss 0.007819105 Test MSE 0.0012772018596305208 Test RE 0.017081965145454688\n",
      "92 Train Loss 0.0076600607 Test MSE 0.0012709405566818921 Test RE 0.017040042733725645\n",
      "93 Train Loss 0.007346749 Test MSE 0.0012900698796648319 Test RE 0.01716780129637312\n",
      "94 Train Loss 0.00708242 Test MSE 0.0010792768177571267 Test RE 0.01570270546289384\n",
      "95 Train Loss 0.0066028554 Test MSE 0.0007979964006004923 Test RE 0.013502324045182881\n",
      "96 Train Loss 0.0060980446 Test MSE 0.0010025078502456305 Test RE 0.01513393803098636\n",
      "97 Train Loss 0.0058638016 Test MSE 0.00101205548379706 Test RE 0.015205833175513609\n",
      "98 Train Loss 0.005370962 Test MSE 0.0009403149343028342 Test RE 0.014656987826531522\n",
      "99 Train Loss 0.0047881687 Test MSE 0.0008225144119576393 Test RE 0.01370818063102897\n",
      "Training time: 70.76\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.555264 Test MSE 8.66658204605013 Test RE 1.4071227565765996\n",
      "1 Train Loss 57.12248 Test MSE 8.586567101168045 Test RE 1.400612004589523\n",
      "2 Train Loss 53.009857 Test MSE 9.166060915592311 Test RE 1.4471029533127466\n",
      "3 Train Loss 45.478043 Test MSE 8.624362042883902 Test RE 1.403691112049049\n",
      "4 Train Loss 44.53386 Test MSE 8.485972781717262 Test RE 1.3923835299290814\n",
      "5 Train Loss 44.169167 Test MSE 8.475809419930343 Test RE 1.3915494748598254\n",
      "6 Train Loss 44.056953 Test MSE 8.473112007561904 Test RE 1.3913280280770342\n",
      "7 Train Loss 43.762405 Test MSE 8.527060562695887 Test RE 1.3957503134243918\n",
      "8 Train Loss 43.49726 Test MSE 8.5290051031858 Test RE 1.395909450225588\n",
      "9 Train Loss 43.063213 Test MSE 8.461369659120358 Test RE 1.3903636172044453\n",
      "10 Train Loss 42.76068 Test MSE 8.444548840218008 Test RE 1.3889809397997013\n",
      "11 Train Loss 42.533195 Test MSE 8.434069507672065 Test RE 1.388118838580999\n",
      "12 Train Loss 42.020607 Test MSE 8.45430668141218 Test RE 1.3897832054167587\n",
      "13 Train Loss 41.6455 Test MSE 8.674329312365916 Test RE 1.4077515465377821\n",
      "14 Train Loss 40.83468 Test MSE 8.389729023081019 Test RE 1.3844651473301541\n",
      "15 Train Loss 38.39516 Test MSE 7.998317197760062 Test RE 1.3517842186632325\n",
      "16 Train Loss 37.463127 Test MSE 8.09869834101688 Test RE 1.360240406659489\n",
      "17 Train Loss 36.594864 Test MSE 8.249353119333525 Test RE 1.3728339396896962\n",
      "18 Train Loss 33.56435 Test MSE 8.149431386412928 Test RE 1.364494263162963\n",
      "19 Train Loss 31.806793 Test MSE 8.066427068241564 Test RE 1.3575275938093265\n",
      "20 Train Loss 30.92102 Test MSE 8.138000787981639 Test RE 1.3635369903015284\n",
      "21 Train Loss 29.897331 Test MSE 8.189383216839573 Test RE 1.3678348271606646\n",
      "22 Train Loss 29.294285 Test MSE 8.261089212538321 Test RE 1.3738101362778885\n",
      "23 Train Loss 28.663246 Test MSE 8.134516952838457 Test RE 1.363245097567851\n",
      "24 Train Loss 27.914278 Test MSE 7.738828355572991 Test RE 1.3296755021422817\n",
      "25 Train Loss 24.805817 Test MSE 7.532618154967171 Test RE 1.3118405060573595\n",
      "26 Train Loss 22.604088 Test MSE 7.31086076601347 Test RE 1.2923862140904476\n",
      "27 Train Loss 21.698952 Test MSE 7.097752688946331 Test RE 1.2734106911231162\n",
      "28 Train Loss 21.01414 Test MSE 7.284830769841334 Test RE 1.290083420557522\n",
      "29 Train Loss 20.139122 Test MSE 7.490181894597593 Test RE 1.3081400507993195\n",
      "30 Train Loss 19.581924 Test MSE 7.60020031141761 Test RE 1.317712238791476\n",
      "31 Train Loss 19.069443 Test MSE 7.494162659404601 Test RE 1.3084876195397934\n",
      "32 Train Loss 18.446398 Test MSE 7.581472036611705 Test RE 1.3160876961653043\n",
      "33 Train Loss 17.052872 Test MSE 6.896377457128904 Test RE 1.2552163051443452\n",
      "34 Train Loss 15.845374 Test MSE 6.886881375787493 Test RE 1.2543518119904058\n",
      "35 Train Loss 14.890063 Test MSE 6.821715503881488 Test RE 1.2484031677479854\n",
      "36 Train Loss 13.31155 Test MSE 6.61144089814205 Test RE 1.2290119913427644\n",
      "37 Train Loss 11.46305 Test MSE 6.4184237173920815 Test RE 1.2109389603927967\n",
      "38 Train Loss 10.491489 Test MSE 6.161574331161167 Test RE 1.1864621997072566\n",
      "39 Train Loss 8.748575 Test MSE 6.2627356579496825 Test RE 1.1961622735177884\n",
      "40 Train Loss 7.1085463 Test MSE 5.903723031856854 Test RE 1.1613711881545157\n",
      "41 Train Loss 5.4617863 Test MSE 4.614670843231559 Test RE 1.0267824210624863\n",
      "42 Train Loss 4.349717 Test MSE 4.353066350856613 Test RE 0.9972538088728907\n",
      "43 Train Loss 3.5352197 Test MSE 4.480488961029064 Test RE 1.0117442994839667\n",
      "44 Train Loss 3.0130112 Test MSE 4.551740852481116 Test RE 1.019757303287124\n",
      "45 Train Loss 2.61542 Test MSE 4.284971466667077 Test RE 0.9894230586558356\n",
      "46 Train Loss 2.471763 Test MSE 4.320292345249349 Test RE 0.9934925804656074\n",
      "47 Train Loss 2.360605 Test MSE 4.298071683422207 Test RE 0.9909343598394776\n",
      "48 Train Loss 2.2481987 Test MSE 4.418168771697121 Test RE 1.0046833640918593\n",
      "49 Train Loss 2.1230032 Test MSE 4.371168049975298 Test RE 0.9993251373464833\n",
      "50 Train Loss 2.0683973 Test MSE 4.386889016023285 Test RE 1.0011205677774153\n",
      "51 Train Loss 2.0344923 Test MSE 4.427310547452313 Test RE 1.0057222383822926\n",
      "52 Train Loss 1.9863993 Test MSE 4.426773232973474 Test RE 1.0056612074797306\n",
      "53 Train Loss 1.9245607 Test MSE 4.41001460150339 Test RE 1.0037558143522671\n",
      "54 Train Loss 1.8818779 Test MSE 4.368410454949076 Test RE 0.9990098704939457\n",
      "55 Train Loss 1.846985 Test MSE 4.349711326007555 Test RE 0.9968694296830259\n",
      "56 Train Loss 1.7963542 Test MSE 4.298679866039934 Test RE 0.9910044665965594\n",
      "57 Train Loss 1.7699519 Test MSE 4.354511529172046 Test RE 0.9974193347190595\n",
      "58 Train Loss 1.7278727 Test MSE 4.38270371597694 Test RE 1.0006428955839015\n",
      "59 Train Loss 1.6994952 Test MSE 4.358040976824102 Test RE 0.9978234703221218\n",
      "60 Train Loss 1.6647438 Test MSE 4.269839082964381 Test RE 0.9876744389067424\n",
      "61 Train Loss 1.6438324 Test MSE 4.247796387538588 Test RE 0.985121745826841\n",
      "62 Train Loss 1.6153164 Test MSE 4.217685385752644 Test RE 0.9816239607992638\n",
      "63 Train Loss 1.5681838 Test MSE 4.2046169031066984 Test RE 0.9801020018235395\n",
      "64 Train Loss 1.5532486 Test MSE 4.2463416349153364 Test RE 0.9849530429237108\n",
      "65 Train Loss 1.524653 Test MSE 4.242749399301512 Test RE 0.9845363392867716\n",
      "66 Train Loss 1.5099347 Test MSE 4.213972339082142 Test RE 0.981191778478971\n",
      "67 Train Loss 1.4784126 Test MSE 4.179055782874178 Test RE 0.9771182939998351\n",
      "68 Train Loss 1.4327958 Test MSE 4.1348283372353976 Test RE 0.9719340614724462\n",
      "69 Train Loss 1.3976457 Test MSE 4.001580437266083 Test RE 0.9561451708235108\n",
      "70 Train Loss 1.3448247 Test MSE 3.8421353185499876 Test RE 0.9369024799634311\n",
      "71 Train Loss 1.3183156 Test MSE 3.78140114003701 Test RE 0.9294679857319497\n",
      "72 Train Loss 1.2957404 Test MSE 3.6352174940206354 Test RE 0.9113249493574689\n",
      "73 Train Loss 1.2484052 Test MSE 3.5508166419715375 Test RE 0.9006834519247134\n",
      "74 Train Loss 1.209223 Test MSE 3.365867526272456 Test RE 0.8769131239127912\n",
      "75 Train Loss 1.1751999 Test MSE 3.1022867284032327 Test RE 0.8418777423485744\n",
      "76 Train Loss 1.1400089 Test MSE 3.0766872903499567 Test RE 0.8383970451661582\n",
      "77 Train Loss 1.11432 Test MSE 3.1211905256617976 Test RE 0.8444388395460175\n",
      "78 Train Loss 1.0769879 Test MSE 2.9221841884693442 Test RE 0.8170748700368369\n",
      "79 Train Loss 1.0576142 Test MSE 2.971557786595359 Test RE 0.823948657359268\n",
      "80 Train Loss 1.0407652 Test MSE 2.9208822505211476 Test RE 0.8168928316666083\n",
      "81 Train Loss 1.0243016 Test MSE 2.912127356708727 Test RE 0.815667657807848\n",
      "82 Train Loss 1.009277 Test MSE 2.929954209665615 Test RE 0.8181604406231702\n",
      "83 Train Loss 0.98998255 Test MSE 2.9564695545966186 Test RE 0.8218541751858758\n",
      "84 Train Loss 0.9764467 Test MSE 2.961808716756243 Test RE 0.8225959439261443\n",
      "85 Train Loss 0.9663833 Test MSE 2.9592161639222776 Test RE 0.8222358446523532\n",
      "86 Train Loss 0.9581801 Test MSE 2.969241543112508 Test RE 0.8236274726661904\n",
      "87 Train Loss 0.9433156 Test MSE 2.982596465221244 Test RE 0.82547763205502\n",
      "88 Train Loss 0.9327807 Test MSE 3.0006609874051375 Test RE 0.8279736700435548\n",
      "89 Train Loss 0.9209158 Test MSE 2.9890011042544176 Test RE 0.8263634460071858\n",
      "90 Train Loss 0.9086358 Test MSE 3.002706872981747 Test RE 0.8282558829889624\n",
      "91 Train Loss 0.8995653 Test MSE 3.024525765516381 Test RE 0.8312596586902639\n",
      "92 Train Loss 0.89051276 Test MSE 3.0243967502577003 Test RE 0.8312419292457314\n",
      "93 Train Loss 0.8790035 Test MSE 3.0125310167610215 Test RE 0.8296097048211872\n",
      "94 Train Loss 0.87209076 Test MSE 3.0166576000494243 Test RE 0.830177712579477\n",
      "95 Train Loss 0.85983133 Test MSE 3.053008679569716 Test RE 0.8351646040355428\n",
      "96 Train Loss 0.85284793 Test MSE 3.0822352761073333 Test RE 0.8391526175429511\n",
      "97 Train Loss 0.8382662 Test MSE 3.126249497166333 Test RE 0.8451229154349862\n",
      "98 Train Loss 0.8273177 Test MSE 3.0939465234505548 Test RE 0.8407453263276858\n",
      "99 Train Loss 0.8164985 Test MSE 3.106312727327507 Test RE 0.8424238395092873\n",
      "Training time: 70.94\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.196274 Test MSE 8.506378441211972 Test RE 1.3940566112018105\n",
      "1 Train Loss 52.237354 Test MSE 8.999236477265748 Test RE 1.433873677947537\n",
      "2 Train Loss 45.886005 Test MSE 7.83984832954855 Test RE 1.3383259245581576\n",
      "3 Train Loss 42.77487 Test MSE 7.133864059666247 Test RE 1.2766459591500767\n",
      "4 Train Loss 38.177612 Test MSE 7.661997140797243 Test RE 1.323058517702035\n",
      "5 Train Loss 36.254787 Test MSE 7.392771892831408 Test RE 1.2996060167238095\n",
      "6 Train Loss 34.27214 Test MSE 7.24281961953347 Test RE 1.2863581278729062\n",
      "7 Train Loss 32.698174 Test MSE 6.891494310404153 Test RE 1.2547718333306905\n",
      "8 Train Loss 31.696651 Test MSE 6.465654485306967 Test RE 1.2153862163199969\n",
      "9 Train Loss 30.871038 Test MSE 6.601864885633371 Test RE 1.228121618197124\n",
      "10 Train Loss 30.12934 Test MSE 6.259903805352193 Test RE 1.1958918055919279\n",
      "11 Train Loss 28.68409 Test MSE 6.260008277865087 Test RE 1.1959017847629103\n",
      "12 Train Loss 28.161932 Test MSE 5.928109549781046 Test RE 1.163767355129919\n",
      "13 Train Loss 27.609982 Test MSE 6.107102279887977 Test RE 1.181206034549702\n",
      "14 Train Loss 27.243885 Test MSE 6.062104750333122 Test RE 1.1768463874511155\n",
      "15 Train Loss 26.714924 Test MSE 6.222126874916144 Test RE 1.1922778933411673\n",
      "16 Train Loss 26.084263 Test MSE 5.672767417523686 Test RE 1.13842794869157\n",
      "17 Train Loss 25.797066 Test MSE 5.646455305767429 Test RE 1.1357846833706469\n",
      "18 Train Loss 25.269722 Test MSE 5.585436154423083 Test RE 1.1296310108763847\n",
      "19 Train Loss 24.59589 Test MSE 5.46849568147893 Test RE 1.1177430985591876\n",
      "20 Train Loss 24.410242 Test MSE 5.566679030588909 Test RE 1.127732640979763\n",
      "21 Train Loss 24.358667 Test MSE 5.5046612390392475 Test RE 1.12143307014702\n",
      "22 Train Loss 23.967733 Test MSE 5.445208066786799 Test RE 1.1153606022524354\n",
      "23 Train Loss 23.76165 Test MSE 5.469404615913962 Test RE 1.1178359863512128\n",
      "24 Train Loss 23.588308 Test MSE 5.466362025462153 Test RE 1.1175250210383958\n",
      "25 Train Loss 23.468655 Test MSE 5.423035664711817 Test RE 1.1130874613888904\n",
      "26 Train Loss 23.35767 Test MSE 5.352983431253625 Test RE 1.1058749225165831\n",
      "27 Train Loss 23.283825 Test MSE 5.475364719353751 Test RE 1.118444882979432\n",
      "28 Train Loss 23.204832 Test MSE 5.499065161376298 Test RE 1.1208628967926015\n",
      "29 Train Loss 22.942753 Test MSE 5.558200247671835 Test RE 1.1268734712716184\n",
      "30 Train Loss 22.837925 Test MSE 5.612859988599356 Test RE 1.1324007928728275\n",
      "31 Train Loss 22.76956 Test MSE 5.62042112119838 Test RE 1.1331632696621665\n",
      "32 Train Loss 22.669783 Test MSE 5.451227222132524 Test RE 1.1159768940803416\n",
      "33 Train Loss 22.499397 Test MSE 5.276210721050181 Test RE 1.0979160307852716\n",
      "34 Train Loss 22.297382 Test MSE 5.249361358633881 Test RE 1.0951189530392087\n",
      "35 Train Loss 22.083893 Test MSE 5.2810978715321735 Test RE 1.0984243917295131\n",
      "36 Train Loss 21.782333 Test MSE 5.082192852463966 Test RE 1.077540570611581\n",
      "37 Train Loss 20.653683 Test MSE 5.691170004832254 Test RE 1.140272996716365\n",
      "38 Train Loss 18.776339 Test MSE 5.840232571866762 Test RE 1.1551094353020037\n",
      "39 Train Loss 18.09336 Test MSE 5.44066000461716 Test RE 1.114894707379446\n",
      "40 Train Loss 17.53809 Test MSE 5.519218473203428 Test RE 1.1229149220160328\n",
      "41 Train Loss 17.0037 Test MSE 5.635611892408145 Test RE 1.13469358279411\n",
      "42 Train Loss 16.599775 Test MSE 5.602601410685808 Test RE 1.1313654798029107\n",
      "43 Train Loss 16.257225 Test MSE 5.537671919521584 Test RE 1.1247905823632975\n",
      "44 Train Loss 16.049244 Test MSE 5.570951052626505 Test RE 1.1281652844566288\n",
      "45 Train Loss 15.813646 Test MSE 5.704626809964936 Test RE 1.1416202918867684\n",
      "46 Train Loss 15.633635 Test MSE 5.702707412472117 Test RE 1.141428219070566\n",
      "47 Train Loss 15.473751 Test MSE 5.652021908774597 Test RE 1.136344406648065\n",
      "48 Train Loss 15.3288555 Test MSE 5.7077794501935 Test RE 1.1419357043629448\n",
      "49 Train Loss 15.255975 Test MSE 5.770404079416858 Test RE 1.1481831611918238\n",
      "50 Train Loss 15.152901 Test MSE 5.829630965126405 Test RE 1.15406054055897\n",
      "51 Train Loss 15.045351 Test MSE 5.8777310961684215 Test RE 1.1588118215305647\n",
      "52 Train Loss 14.928114 Test MSE 5.850998994372452 Test RE 1.1561736626033403\n",
      "53 Train Loss 14.791119 Test MSE 5.9125714583837805 Test RE 1.1622411866246185\n",
      "54 Train Loss 14.688506 Test MSE 5.860186920531196 Test RE 1.157081086379419\n",
      "55 Train Loss 14.607704 Test MSE 5.8046125229702055 Test RE 1.1515814950307521\n",
      "56 Train Loss 14.396123 Test MSE 5.748493077055616 Test RE 1.146001184766064\n",
      "57 Train Loss 14.210412 Test MSE 5.6560500841226276 Test RE 1.1367492687767877\n",
      "58 Train Loss 14.148587 Test MSE 5.759270583348534 Test RE 1.147074966292894\n",
      "59 Train Loss 13.971654 Test MSE 5.737424145235738 Test RE 1.144897319713361\n",
      "60 Train Loss 13.8678255 Test MSE 5.77729295870269 Test RE 1.1488683242919857\n",
      "61 Train Loss 13.742458 Test MSE 5.890866891665062 Test RE 1.1601059790640695\n",
      "62 Train Loss 13.552027 Test MSE 5.747516791577096 Test RE 1.145903866059449\n",
      "63 Train Loss 13.424953 Test MSE 5.756862858094097 Test RE 1.1468351676899413\n",
      "64 Train Loss 13.296412 Test MSE 5.796846266062918 Test RE 1.1508108603691205\n",
      "65 Train Loss 13.18684 Test MSE 5.829280751577249 Test RE 1.154025875096394\n",
      "66 Train Loss 13.067559 Test MSE 5.86579919796952 Test RE 1.1576350197369707\n",
      "67 Train Loss 12.919961 Test MSE 5.769503433532141 Test RE 1.1480935533603076\n",
      "68 Train Loss 12.74471 Test MSE 5.820293923380126 Test RE 1.1531359683498714\n",
      "69 Train Loss 12.636341 Test MSE 5.814861503580254 Test RE 1.1525976981916164\n",
      "70 Train Loss 12.465704 Test MSE 5.877386655616509 Test RE 1.1587778673036249\n",
      "71 Train Loss 12.293726 Test MSE 5.8332538411764645 Test RE 1.1544190854597298\n",
      "72 Train Loss 12.096738 Test MSE 5.735112356336037 Test RE 1.1446666388784106\n",
      "73 Train Loss 12.019231 Test MSE 5.735679712923923 Test RE 1.1447232566094445\n",
      "74 Train Loss 11.950403 Test MSE 5.759338443794468 Test RE 1.1470817241616476\n",
      "75 Train Loss 11.864456 Test MSE 5.766381944689304 Test RE 1.147782933380388\n",
      "76 Train Loss 11.769934 Test MSE 5.799857390508089 Test RE 1.1511097112161388\n",
      "77 Train Loss 11.635883 Test MSE 5.695988373434414 Test RE 1.1407555945986416\n",
      "78 Train Loss 11.534824 Test MSE 5.564024680882764 Test RE 1.1274637415419773\n",
      "79 Train Loss 11.435647 Test MSE 5.553533562309082 Test RE 1.1264003083787133\n",
      "80 Train Loss 11.1877 Test MSE 4.819640346015416 Test RE 1.0493379408755203\n",
      "81 Train Loss 10.911615 Test MSE 4.632387090918367 Test RE 1.0287515004041605\n",
      "82 Train Loss 10.419595 Test MSE 4.459015336582239 Test RE 1.0093168957794982\n",
      "83 Train Loss 9.5414915 Test MSE 4.251546198460369 Test RE 0.9855564659811813\n",
      "84 Train Loss 9.244019 Test MSE 4.237702518151342 Test RE 0.983950596888319\n",
      "85 Train Loss 9.047512 Test MSE 4.2326981689179215 Test RE 0.9833694462572782\n",
      "86 Train Loss 8.831176 Test MSE 4.227027474957097 Test RE 0.9827104982375984\n",
      "87 Train Loss 8.678432 Test MSE 4.242662489206359 Test RE 0.9845262554263929\n",
      "88 Train Loss 8.539865 Test MSE 4.182592642054639 Test RE 0.9775316886855328\n",
      "89 Train Loss 8.49285 Test MSE 4.195857214123112 Test RE 0.979080521726457\n",
      "90 Train Loss 8.4168 Test MSE 4.177341723032271 Test RE 0.9769178885629808\n",
      "91 Train Loss 8.341815 Test MSE 4.188495189262055 Test RE 0.9782212003368839\n",
      "92 Train Loss 8.304842 Test MSE 4.209013740379228 Test RE 0.980614322340616\n",
      "93 Train Loss 8.252498 Test MSE 4.218136714391725 Test RE 0.9816764805007462\n",
      "94 Train Loss 8.203913 Test MSE 4.184237083148736 Test RE 0.9777238344963373\n",
      "95 Train Loss 8.157465 Test MSE 4.220089233625341 Test RE 0.9819036566903593\n",
      "96 Train Loss 8.099735 Test MSE 4.23545634337184 Test RE 0.9836897930742435\n",
      "97 Train Loss 8.06847 Test MSE 4.258666105013705 Test RE 0.9863813581808812\n",
      "98 Train Loss 8.018695 Test MSE 4.2514470690814194 Test RE 0.9855449762589343\n",
      "99 Train Loss 7.962854 Test MSE 4.2603066688249305 Test RE 0.986571331485167\n",
      "Training time: 71.70\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.32094 Test MSE 8.610724434807594 Test RE 1.402580852368999\n",
      "1 Train Loss 55.005585 Test MSE 8.881048507572052 Test RE 1.4244269482648295\n",
      "2 Train Loss 46.7312 Test MSE 9.817340478602098 Test RE 1.4976315716199862\n",
      "3 Train Loss 43.03425 Test MSE 8.536629692602075 Test RE 1.3965332544499518\n",
      "4 Train Loss 42.653255 Test MSE 8.375295359225507 Test RE 1.3832737198994178\n",
      "5 Train Loss 42.175167 Test MSE 8.45423260941249 Test RE 1.3897771171442055\n",
      "6 Train Loss 41.65255 Test MSE 8.345842933672932 Test RE 1.3808393790972406\n",
      "7 Train Loss 41.39948 Test MSE 8.445607070792168 Test RE 1.3890679673057937\n",
      "8 Train Loss 40.484745 Test MSE 8.434500963743035 Test RE 1.3881543436619241\n",
      "9 Train Loss 39.865715 Test MSE 8.74035704643418 Test RE 1.413099189549797\n",
      "10 Train Loss 38.883575 Test MSE 8.796938813847683 Test RE 1.4176657459128315\n",
      "11 Train Loss 37.09095 Test MSE 9.844280838582817 Test RE 1.4996850346825636\n",
      "12 Train Loss 36.332382 Test MSE 10.040754640065543 Test RE 1.5145765819879742\n",
      "13 Train Loss 35.65712 Test MSE 10.120723551160765 Test RE 1.5205959918265053\n",
      "14 Train Loss 35.100464 Test MSE 10.271262171755863 Test RE 1.5318631448850346\n",
      "15 Train Loss 34.519127 Test MSE 9.874383112969417 Test RE 1.5019761859122687\n",
      "16 Train Loss 33.77939 Test MSE 9.514482123520905 Test RE 1.4743501473068796\n",
      "17 Train Loss 31.539307 Test MSE 9.632517030076112 Test RE 1.4834672160004077\n",
      "18 Train Loss 27.563324 Test MSE 8.5939742566673 Test RE 1.4012159895329181\n",
      "19 Train Loss 26.295803 Test MSE 8.775316396467735 Test RE 1.415922399710934\n",
      "20 Train Loss 25.201488 Test MSE 8.804693122455912 Test RE 1.418290428911703\n",
      "21 Train Loss 23.968964 Test MSE 8.353390484337513 Test RE 1.38146361801781\n",
      "22 Train Loss 22.475897 Test MSE 8.04465840622222 Test RE 1.3556945936730753\n",
      "23 Train Loss 21.69121 Test MSE 8.056187737192674 Test RE 1.3566657135578113\n",
      "24 Train Loss 21.05392 Test MSE 7.791280050119091 Test RE 1.3341739838773983\n",
      "25 Train Loss 20.451675 Test MSE 7.93571324509804 Test RE 1.346483523446652\n",
      "26 Train Loss 20.10778 Test MSE 8.026869421429163 Test RE 1.354194854585796\n",
      "27 Train Loss 19.779076 Test MSE 7.9287365845934845 Test RE 1.3458915146565074\n",
      "28 Train Loss 19.369495 Test MSE 8.077588736892267 Test RE 1.3584664875140164\n",
      "29 Train Loss 19.216438 Test MSE 8.021500516247768 Test RE 1.3537418909487648\n",
      "30 Train Loss 18.986542 Test MSE 8.003378851803948 Test RE 1.3522118824902427\n",
      "31 Train Loss 18.790743 Test MSE 8.388918173587072 Test RE 1.384398242905328\n",
      "32 Train Loss 18.495548 Test MSE 8.483778611841323 Test RE 1.3922035079334956\n",
      "33 Train Loss 18.12173 Test MSE 8.801752509638396 Test RE 1.4180535670901293\n",
      "34 Train Loss 17.353466 Test MSE 8.804455011889981 Test RE 1.4182712509451774\n",
      "35 Train Loss 16.762447 Test MSE 8.832809023253931 Test RE 1.4205531272760747\n",
      "36 Train Loss 16.011887 Test MSE 8.877391379974448 Test RE 1.4241336356286627\n",
      "37 Train Loss 15.52383 Test MSE 9.010890113634861 Test RE 1.4348017809230817\n",
      "38 Train Loss 14.993836 Test MSE 8.88153693531291 Test RE 1.4244661170673831\n",
      "39 Train Loss 14.643761 Test MSE 8.729495568145568 Test RE 1.4122209006351616\n",
      "40 Train Loss 14.349514 Test MSE 8.776768853095515 Test RE 1.4160395738781828\n",
      "41 Train Loss 14.059237 Test MSE 8.665607844463398 Test RE 1.4070436677420266\n",
      "42 Train Loss 13.866694 Test MSE 8.707834451855119 Test RE 1.4104676904435596\n",
      "43 Train Loss 13.637445 Test MSE 8.718303632709185 Test RE 1.4113153182762868\n",
      "44 Train Loss 13.539152 Test MSE 8.74738427753199 Test RE 1.4136671399983753\n",
      "45 Train Loss 13.380604 Test MSE 8.759904528694499 Test RE 1.4146784788310685\n",
      "46 Train Loss 13.312614 Test MSE 8.784443239575387 Test RE 1.4166585294761547\n",
      "47 Train Loss 13.234406 Test MSE 8.779396738249087 Test RE 1.4162515488619853\n",
      "48 Train Loss 13.0984335 Test MSE 8.96574075362395 Test RE 1.4312027062855515\n",
      "49 Train Loss 12.993341 Test MSE 9.021912134597969 Test RE 1.4356790295666049\n",
      "50 Train Loss 12.91905 Test MSE 9.002341589125729 Test RE 1.434121029718991\n",
      "51 Train Loss 12.782677 Test MSE 9.067070890077959 Test RE 1.4392676563157163\n",
      "52 Train Loss 12.689163 Test MSE 9.12939694995799 Test RE 1.4442058693883244\n",
      "53 Train Loss 12.574313 Test MSE 9.24753013908173 Test RE 1.453519752601596\n",
      "54 Train Loss 12.46143 Test MSE 9.148550140516516 Test RE 1.4457200251159423\n",
      "55 Train Loss 12.243845 Test MSE 9.240298140715776 Test RE 1.452951281436275\n",
      "56 Train Loss 12.035662 Test MSE 9.136062050478445 Test RE 1.4447329590259113\n",
      "57 Train Loss 11.371107 Test MSE 8.7281028836313 Test RE 1.4121082448342726\n",
      "58 Train Loss 8.877113 Test MSE 8.130176182089796 Test RE 1.3628813191086075\n",
      "59 Train Loss 8.293097 Test MSE 7.935018492424861 Test RE 1.3464245814540476\n",
      "60 Train Loss 7.8208857 Test MSE 8.240408135915207 Test RE 1.3720894384343991\n",
      "61 Train Loss 7.5360775 Test MSE 8.301623973998318 Test RE 1.377176455279699\n",
      "62 Train Loss 7.3015428 Test MSE 8.416114625131803 Test RE 1.3866405018523293\n",
      "63 Train Loss 7.067127 Test MSE 8.38089386638776 Test RE 1.3837359707070038\n",
      "64 Train Loss 6.9765425 Test MSE 8.325923349215863 Test RE 1.3791905235579245\n",
      "65 Train Loss 6.8612823 Test MSE 8.336004199014175 Test RE 1.3800252181608856\n",
      "66 Train Loss 6.786324 Test MSE 8.346010253898218 Test RE 1.3808532207906343\n",
      "67 Train Loss 6.697812 Test MSE 8.323274096471879 Test RE 1.378971081531643\n",
      "68 Train Loss 6.5736594 Test MSE 8.350617286869443 Test RE 1.3812342866204612\n",
      "69 Train Loss 6.454659 Test MSE 8.227664591592909 Test RE 1.3710280803297417\n",
      "70 Train Loss 6.2977204 Test MSE 8.207436346265649 Test RE 1.3693416625629915\n",
      "71 Train Loss 6.104196 Test MSE 8.159597779992023 Test RE 1.3653450993402658\n",
      "72 Train Loss 5.5405183 Test MSE 7.7786462611688165 Test RE 1.3330918439104025\n",
      "73 Train Loss 5.1803045 Test MSE 7.700356398671294 Test RE 1.326366283250736\n",
      "74 Train Loss 4.364069 Test MSE 7.268649423509605 Test RE 1.2886498325700546\n",
      "75 Train Loss 3.4480853 Test MSE 7.001374242858221 Test RE 1.2647354928616867\n",
      "76 Train Loss 2.9886465 Test MSE 6.836606964149174 Test RE 1.2497650254553898\n",
      "77 Train Loss 2.7284038 Test MSE 6.715919085072208 Test RE 1.2386847413138757\n",
      "78 Train Loss 2.42671 Test MSE 6.769620343179142 Test RE 1.2436272133653186\n",
      "79 Train Loss 2.303847 Test MSE 6.715796739846702 Test RE 1.238673458580099\n",
      "80 Train Loss 2.2065284 Test MSE 6.737699641213617 Test RE 1.24069171931286\n",
      "81 Train Loss 2.121326 Test MSE 6.632304206789729 Test RE 1.230949621893394\n",
      "82 Train Loss 1.9835407 Test MSE 6.448294183708912 Test RE 1.213753461785779\n",
      "83 Train Loss 1.8532512 Test MSE 6.283395936888085 Test RE 1.1981336722418585\n",
      "84 Train Loss 1.7386904 Test MSE 6.125510136592565 Test RE 1.182984874204974\n",
      "85 Train Loss 1.6839465 Test MSE 5.9559961184252685 Test RE 1.1665013971684481\n",
      "86 Train Loss 1.6530808 Test MSE 5.982469718088952 Test RE 1.1690909934694151\n",
      "87 Train Loss 1.6184633 Test MSE 5.948513192978744 Test RE 1.1657683891040571\n",
      "88 Train Loss 1.5877522 Test MSE 5.853695274626043 Test RE 1.1564400281558271\n",
      "89 Train Loss 1.5622015 Test MSE 5.783021232077069 Test RE 1.1494377433425518\n",
      "90 Train Loss 1.5355943 Test MSE 5.7718830491484026 Test RE 1.14833029294582\n",
      "91 Train Loss 1.5083559 Test MSE 5.762766409038832 Test RE 1.1474230455989314\n",
      "92 Train Loss 1.4817051 Test MSE 5.756990776461714 Test RE 1.1468479090450219\n",
      "93 Train Loss 1.456091 Test MSE 5.768742982788038 Test RE 1.1480178884978405\n",
      "94 Train Loss 1.4391497 Test MSE 5.804060637984603 Test RE 1.1515267492883512\n",
      "95 Train Loss 1.4225795 Test MSE 5.799652907768857 Test RE 1.1510894189808494\n",
      "96 Train Loss 1.4017524 Test MSE 5.872308989964749 Test RE 1.1582772061859203\n",
      "97 Train Loss 1.3782746 Test MSE 5.910467948095691 Test RE 1.162034423476463\n",
      "98 Train Loss 1.3504578 Test MSE 5.932860771479679 Test RE 1.1642336259711727\n",
      "99 Train Loss 1.3306996 Test MSE 5.964464602112702 Test RE 1.1673303927668275\n",
      "Training time: 70.66\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.025032 Test MSE 8.552294929849928 Test RE 1.3978140290835992\n",
      "1 Train Loss 53.526413 Test MSE 9.325994721115624 Test RE 1.459673228887565\n",
      "2 Train Loss 49.32892 Test MSE 8.169151863324815 Test RE 1.3661442076389765\n",
      "3 Train Loss 45.189644 Test MSE 8.426907295189878 Test RE 1.387529318086337\n",
      "4 Train Loss 44.106926 Test MSE 8.302127644714279 Test RE 1.3772182322219368\n",
      "5 Train Loss 43.822205 Test MSE 8.288069368696874 Test RE 1.3760516928651598\n",
      "6 Train Loss 43.548347 Test MSE 8.299433171875918 Test RE 1.3769947245610012\n",
      "7 Train Loss 43.35661 Test MSE 8.318696179119208 Test RE 1.3785918026659674\n",
      "8 Train Loss 42.85723 Test MSE 8.324453904097174 Test RE 1.3790688112789207\n",
      "9 Train Loss 41.916046 Test MSE 7.99467117930112 Test RE 1.351476079344878\n",
      "10 Train Loss 41.32119 Test MSE 8.082885070909416 Test RE 1.35891177592238\n",
      "11 Train Loss 39.35858 Test MSE 7.820467119133702 Test RE 1.336670635709875\n",
      "12 Train Loss 37.773743 Test MSE 7.900626858117627 Test RE 1.3435036037011796\n",
      "13 Train Loss 34.532806 Test MSE 7.3730499058041 Test RE 1.2978713541172497\n",
      "14 Train Loss 32.932453 Test MSE 7.344925354100505 Test RE 1.2953936192346682\n",
      "15 Train Loss 31.124142 Test MSE 6.952581215197242 Test RE 1.2603207762830548\n",
      "16 Train Loss 27.991322 Test MSE 6.649519956169316 Test RE 1.232546200193335\n",
      "17 Train Loss 25.346302 Test MSE 5.866997494696498 Test RE 1.1577532576249336\n",
      "18 Train Loss 21.74419 Test MSE 6.01775182647344 Test RE 1.17253333082303\n",
      "19 Train Loss 18.841558 Test MSE 5.862225030518622 Test RE 1.1572822790667685\n",
      "20 Train Loss 15.164541 Test MSE 4.488663834172046 Test RE 1.0126668675511308\n",
      "21 Train Loss 11.752484 Test MSE 3.692467462639864 Test RE 0.9184730101031573\n",
      "22 Train Loss 8.718601 Test MSE 2.744059727561209 Test RE 0.7917805703306625\n",
      "23 Train Loss 7.468948 Test MSE 2.261320777096654 Test RE 0.7187686835375325\n",
      "24 Train Loss 6.57992 Test MSE 2.0863414570399303 Test RE 0.6903999547087246\n",
      "25 Train Loss 6.1001577 Test MSE 2.0560753386840904 Test RE 0.6853739164567036\n",
      "26 Train Loss 5.6879587 Test MSE 2.0923991958387744 Test RE 0.6914015240238682\n",
      "27 Train Loss 5.5086665 Test MSE 2.0929406190809234 Test RE 0.6914909707802036\n",
      "28 Train Loss 5.310937 Test MSE 2.0692055402291474 Test RE 0.6875588500548417\n",
      "29 Train Loss 5.214494 Test MSE 2.075084591297535 Test RE 0.6885349073877366\n",
      "30 Train Loss 5.09702 Test MSE 2.0667162970039317 Test RE 0.6871451607867385\n",
      "31 Train Loss 5.0483627 Test MSE 2.0796160796093877 Test RE 0.6892862951562607\n",
      "32 Train Loss 4.9889975 Test MSE 2.094266489748249 Test RE 0.6917099646758533\n",
      "33 Train Loss 4.943336 Test MSE 2.080459463665099 Test RE 0.6894260503132806\n",
      "34 Train Loss 4.910624 Test MSE 2.1025370450879435 Test RE 0.693074449235751\n",
      "35 Train Loss 4.876773 Test MSE 2.107698158239125 Test RE 0.6939245753272767\n",
      "36 Train Loss 4.8336053 Test MSE 2.0962664988989066 Test RE 0.6920401748312601\n",
      "37 Train Loss 4.7811174 Test MSE 2.110712558413522 Test RE 0.6944206186016347\n",
      "38 Train Loss 4.741454 Test MSE 2.1097445708979516 Test RE 0.6942613672691472\n",
      "39 Train Loss 4.671225 Test MSE 2.102399621193355 Test RE 0.6930517988509093\n",
      "40 Train Loss 4.5810747 Test MSE 2.079069734355226 Test RE 0.6891957464639181\n",
      "41 Train Loss 3.2989738 Test MSE 1.5618387142373742 Test RE 0.5973462644614173\n",
      "42 Train Loss 1.8799397 Test MSE 1.1496365343436026 Test RE 0.5124934729946388\n",
      "43 Train Loss 1.5719402 Test MSE 0.8740335381747274 Test RE 0.4468606460546883\n",
      "44 Train Loss 1.1798397 Test MSE 0.5215817029585122 Test RE 0.3451987657756935\n",
      "45 Train Loss 0.7811564 Test MSE 0.3277230304260628 Test RE 0.2736286333340827\n",
      "46 Train Loss 0.61994565 Test MSE 0.21089492898849635 Test RE 0.21950333794586244\n",
      "47 Train Loss 0.33752993 Test MSE 0.04260363692951585 Test RE 0.09865779340826655\n",
      "48 Train Loss 0.21949287 Test MSE 0.03878473526398509 Test RE 0.09413225789437815\n",
      "49 Train Loss 0.1784853 Test MSE 0.02690130161187296 Test RE 0.07839614493539405\n",
      "50 Train Loss 0.14150724 Test MSE 0.02039131667008389 Test RE 0.06825440653256212\n",
      "51 Train Loss 0.128594 Test MSE 0.0191811782863541 Test RE 0.06619812693293069\n",
      "52 Train Loss 0.11955879 Test MSE 0.015346674768527208 Test RE 0.059212746411055485\n",
      "53 Train Loss 0.112288676 Test MSE 0.012693532698943891 Test RE 0.05385168705445396\n",
      "54 Train Loss 0.0979318 Test MSE 0.011957908005013772 Test RE 0.05226797374355949\n",
      "55 Train Loss 0.09001142 Test MSE 0.01172952693535081 Test RE 0.05176644111270567\n",
      "56 Train Loss 0.08023859 Test MSE 0.012128332438541806 Test RE 0.0526391183303943\n",
      "57 Train Loss 0.07517093 Test MSE 0.012820702537576136 Test RE 0.05412077066950043\n",
      "58 Train Loss 0.06865503 Test MSE 0.011451700841559111 Test RE 0.051149696057420736\n",
      "59 Train Loss 0.06391979 Test MSE 0.008394731336628034 Test RE 0.04379368206005465\n",
      "60 Train Loss 0.06041346 Test MSE 0.008056965182136779 Test RE 0.04290360679299457\n",
      "61 Train Loss 0.05787486 Test MSE 0.007853757965670904 Test RE 0.04235910904795298\n",
      "62 Train Loss 0.055518277 Test MSE 0.007446529902811351 Test RE 0.04124630312978579\n",
      "63 Train Loss 0.05307415 Test MSE 0.007452726365212417 Test RE 0.04126346065301754\n",
      "64 Train Loss 0.050568946 Test MSE 0.006919864168811137 Test RE 0.0397609584937453\n",
      "65 Train Loss 0.048235726 Test MSE 0.00507466903011998 Test RE 0.03404959273352763\n",
      "66 Train Loss 0.04632518 Test MSE 0.004465125586454989 Test RE 0.0319392636563671\n",
      "67 Train Loss 0.043561928 Test MSE 0.0035877012086787626 Test RE 0.028629660216167162\n",
      "68 Train Loss 0.03908311 Test MSE 0.003009792672149886 Test RE 0.026222636243431473\n",
      "69 Train Loss 0.035984837 Test MSE 0.002766365630126054 Test RE 0.02513985974202205\n",
      "70 Train Loss 0.03256395 Test MSE 0.0025222723141761667 Test RE 0.0240051291418278\n",
      "71 Train Loss 0.030373184 Test MSE 0.002740741180443777 Test RE 0.025023155394452736\n",
      "72 Train Loss 0.028193353 Test MSE 0.0028953362947640145 Test RE 0.025719206625446776\n",
      "73 Train Loss 0.026153177 Test MSE 0.0027489052747372697 Test RE 0.0250603970523766\n",
      "74 Train Loss 0.024548084 Test MSE 0.002861584435543878 Test RE 0.02556885867759913\n",
      "75 Train Loss 0.023879452 Test MSE 0.0025986497210558133 Test RE 0.024365870525744432\n",
      "76 Train Loss 0.022488963 Test MSE 0.002498161277612479 Test RE 0.023890118088004057\n",
      "77 Train Loss 0.020849464 Test MSE 0.002440317098435882 Test RE 0.023611913943790974\n",
      "78 Train Loss 0.019924073 Test MSE 0.002802955037423652 Test RE 0.025305570104789715\n",
      "79 Train Loss 0.018359331 Test MSE 0.003230423097912007 Test RE 0.02716675484816111\n",
      "80 Train Loss 0.01790689 Test MSE 0.003190267335649398 Test RE 0.026997378722493165\n",
      "81 Train Loss 0.017108247 Test MSE 0.0033433897440222193 Test RE 0.027637678672861838\n",
      "82 Train Loss 0.015351134 Test MSE 0.003045414594636354 Test RE 0.02637735671798806\n",
      "83 Train Loss 0.0141517045 Test MSE 0.0028333797777086727 Test RE 0.025442539371951574\n",
      "84 Train Loss 0.013817938 Test MSE 0.0029410176753156374 Test RE 0.02592130591966414\n",
      "85 Train Loss 0.013429919 Test MSE 0.002747793613659664 Test RE 0.02505532931043964\n",
      "86 Train Loss 0.012745068 Test MSE 0.0024507098737775986 Test RE 0.023662139507294618\n",
      "87 Train Loss 0.011322332 Test MSE 0.0016362367911680444 Test RE 0.019334419492553448\n",
      "88 Train Loss 0.010835953 Test MSE 0.0016634330404023824 Test RE 0.019494438112227928\n",
      "89 Train Loss 0.0105822245 Test MSE 0.0015300021943381642 Test RE 0.018696231938896087\n",
      "90 Train Loss 0.010261416 Test MSE 0.0015132242761561683 Test RE 0.018593438440128278\n",
      "91 Train Loss 0.009295879 Test MSE 0.0014918413665091675 Test RE 0.0184616019505761\n",
      "92 Train Loss 0.008454116 Test MSE 0.0013918271143199548 Test RE 0.017832026737884282\n",
      "93 Train Loss 0.008168183 Test MSE 0.0014158178823139042 Test RE 0.01798505444817744\n",
      "94 Train Loss 0.007984462 Test MSE 0.0013828366122015507 Test RE 0.017774340475394987\n",
      "95 Train Loss 0.007841938 Test MSE 0.001421646944731245 Test RE 0.018022039544484867\n",
      "96 Train Loss 0.0073791067 Test MSE 0.0012611194138147889 Test RE 0.016974076921509117\n",
      "97 Train Loss 0.0071326178 Test MSE 0.0013840169960483491 Test RE 0.017781924910490958\n",
      "98 Train Loss 0.0069152056 Test MSE 0.001257893199802007 Test RE 0.016952351352809064\n",
      "99 Train Loss 0.006468318 Test MSE 0.0014151141191636918 Test RE 0.017980583960831936\n",
      "Training time: 71.68\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.85968 Test MSE 8.68074157425693 Test RE 1.408271771425949\n",
      "1 Train Loss 57.564396 Test MSE 8.441197717513278 Test RE 1.3887053118455466\n",
      "2 Train Loss 53.008583 Test MSE 8.733342227390565 Test RE 1.4125320145037916\n",
      "3 Train Loss 46.87855 Test MSE 8.59402736435662 Test RE 1.401220319033232\n",
      "4 Train Loss 45.86425 Test MSE 8.671418090358669 Test RE 1.4075152965032012\n",
      "5 Train Loss 45.75374 Test MSE 8.715963696990812 Test RE 1.411125911662524\n",
      "6 Train Loss 45.401672 Test MSE 8.605233637464409 Test RE 1.4021335894594196\n",
      "7 Train Loss 44.81115 Test MSE 8.52310192383757 Test RE 1.3954262912830941\n",
      "8 Train Loss 44.298496 Test MSE 8.470434715823798 Test RE 1.3911081982595606\n",
      "9 Train Loss 43.928574 Test MSE 8.424009522518434 Test RE 1.3872907317276553\n",
      "10 Train Loss 43.850597 Test MSE 8.436668609866864 Test RE 1.3883327083388568\n",
      "11 Train Loss 43.69017 Test MSE 8.390935867718087 Test RE 1.3845647199296678\n",
      "12 Train Loss 43.39051 Test MSE 8.585714103960175 Test RE 1.4005424338409505\n",
      "13 Train Loss 43.08504 Test MSE 8.647030903308883 Test RE 1.405534680052154\n",
      "14 Train Loss 42.75627 Test MSE 8.701373059396577 Test RE 1.4099442952990513\n",
      "15 Train Loss 42.415764 Test MSE 8.73906849231697 Test RE 1.4129950220721856\n",
      "16 Train Loss 40.988075 Test MSE 8.864982013318794 Test RE 1.4231379165048312\n",
      "17 Train Loss 36.683544 Test MSE 9.012380380966361 Test RE 1.4349204234652404\n",
      "18 Train Loss 33.998436 Test MSE 8.554133729970403 Test RE 1.3979642906498275\n",
      "19 Train Loss 33.06302 Test MSE 8.350518792272151 Test RE 1.3812261408444475\n",
      "20 Train Loss 32.482536 Test MSE 8.227768768547827 Test RE 1.3710367601365572\n",
      "21 Train Loss 31.993246 Test MSE 8.172537995312323 Test RE 1.3664273132423248\n",
      "22 Train Loss 31.6994 Test MSE 7.902002177507194 Test RE 1.3436205353183561\n",
      "23 Train Loss 31.191643 Test MSE 7.894890940411393 Test RE 1.3430158180197054\n",
      "24 Train Loss 30.923248 Test MSE 7.905009610448675 Test RE 1.343876196109333\n",
      "25 Train Loss 30.390457 Test MSE 8.018450645121845 Test RE 1.353484511994514\n",
      "26 Train Loss 29.11729 Test MSE 7.806839231244747 Test RE 1.3355054917371594\n",
      "27 Train Loss 27.394278 Test MSE 7.611604242251724 Test RE 1.3187004671198976\n",
      "28 Train Loss 24.138474 Test MSE 7.068594723686238 Test RE 1.2707923781199357\n",
      "29 Train Loss 20.473253 Test MSE 6.122190326602937 Test RE 1.1826642627642914\n",
      "30 Train Loss 19.558277 Test MSE 6.000036129309697 Test RE 1.170806144621858\n",
      "31 Train Loss 18.740374 Test MSE 5.877037969788035 Test RE 1.1587434935728105\n",
      "32 Train Loss 17.591211 Test MSE 5.722720879398841 Test RE 1.1434293675461777\n",
      "33 Train Loss 16.025604 Test MSE 5.274806488130849 Test RE 1.0977699190671395\n",
      "34 Train Loss 13.689781 Test MSE 4.830136152493429 Test RE 1.0504798993556914\n",
      "35 Train Loss 12.144848 Test MSE 4.257842386606311 Test RE 0.9862859597915716\n",
      "36 Train Loss 11.089406 Test MSE 4.0047079820930875 Test RE 0.9565187485702629\n",
      "37 Train Loss 10.423158 Test MSE 4.0676803925637115 Test RE 0.9640098496923871\n",
      "38 Train Loss 9.32589 Test MSE 3.8157769991305424 Test RE 0.9336832186730013\n",
      "39 Train Loss 6.8490396 Test MSE 3.725993948367645 Test RE 0.9226333161782545\n",
      "40 Train Loss 5.5185885 Test MSE 3.560511572369672 Test RE 0.9019121990001712\n",
      "41 Train Loss 4.9228597 Test MSE 3.416015065507193 Test RE 0.8834214682790356\n",
      "42 Train Loss 4.5393267 Test MSE 3.1101488582364443 Test RE 0.8429438533166508\n",
      "43 Train Loss 4.0764623 Test MSE 2.5811673921180507 Test RE 0.7679202946307715\n",
      "44 Train Loss 3.4455352 Test MSE 2.2190638093295614 Test RE 0.7120212506348866\n",
      "45 Train Loss 2.3720727 Test MSE 1.8813146218874952 Test RE 0.6555997446396341\n",
      "46 Train Loss 1.553982 Test MSE 1.739382038931143 Test RE 0.6303845359466372\n",
      "47 Train Loss 1.1172566 Test MSE 1.6750483416601756 Test RE 0.618616832442548\n",
      "48 Train Loss 0.943888 Test MSE 1.7442429870465623 Test RE 0.6312647705813058\n",
      "49 Train Loss 0.8425285 Test MSE 1.7577768171820856 Test RE 0.6337090750157685\n",
      "50 Train Loss 0.72190875 Test MSE 1.8395074083139475 Test RE 0.6482743387974628\n",
      "51 Train Loss 0.67925763 Test MSE 1.860840418435979 Test RE 0.6520225644768756\n",
      "52 Train Loss 0.6339578 Test MSE 1.8830232116750338 Test RE 0.6558973814100888\n",
      "53 Train Loss 0.58730835 Test MSE 1.9491112933281123 Test RE 0.6673080734304382\n",
      "54 Train Loss 0.5487611 Test MSE 1.935793839565542 Test RE 0.6650244489553598\n",
      "55 Train Loss 0.50176543 Test MSE 2.0257319332967603 Test RE 0.680297770112137\n",
      "56 Train Loss 0.47040167 Test MSE 2.0037878613094295 Test RE 0.6766030185197716\n",
      "57 Train Loss 0.44813395 Test MSE 2.034490892078097 Test RE 0.6817669360929828\n",
      "58 Train Loss 0.41579643 Test MSE 2.0363900166475037 Test RE 0.6820850644099478\n",
      "59 Train Loss 0.39864305 Test MSE 2.0105993561167197 Test RE 0.6777520343658039\n",
      "60 Train Loss 0.37462458 Test MSE 2.0046079018362755 Test RE 0.6767414526203828\n",
      "61 Train Loss 0.36714152 Test MSE 1.9816261489470877 Test RE 0.6728510314471638\n",
      "62 Train Loss 0.34874013 Test MSE 1.9841596525912308 Test RE 0.6732810131656879\n",
      "63 Train Loss 0.3387769 Test MSE 1.9857605796014182 Test RE 0.6735525781136035\n",
      "64 Train Loss 0.32645088 Test MSE 1.9919563434125491 Test RE 0.6746025341416895\n",
      "65 Train Loss 0.31476682 Test MSE 2.012218966955177 Test RE 0.6780249563599561\n",
      "66 Train Loss 0.29881394 Test MSE 1.970016080523545 Test RE 0.6708770662047049\n",
      "67 Train Loss 0.28647316 Test MSE 2.0027031771952517 Test RE 0.6764198654263137\n",
      "68 Train Loss 0.26738623 Test MSE 1.9939644759769013 Test RE 0.674942488897766\n",
      "69 Train Loss 0.25696388 Test MSE 2.0144478515694026 Test RE 0.678400368071902\n",
      "70 Train Loss 0.24588364 Test MSE 2.0270085060993663 Test RE 0.680512090881889\n",
      "71 Train Loss 0.23804544 Test MSE 2.040730647592895 Test RE 0.6828116205944292\n",
      "72 Train Loss 0.23080233 Test MSE 2.0364613331846435 Test RE 0.6820970079763933\n",
      "73 Train Loss 0.22563784 Test MSE 2.0208068375738746 Test RE 0.6794702739929205\n",
      "74 Train Loss 0.22098066 Test MSE 2.010528661703088 Test RE 0.6777401190869873\n",
      "75 Train Loss 0.21017285 Test MSE 1.9864886173630378 Test RE 0.6736760388113414\n",
      "76 Train Loss 0.20626435 Test MSE 1.9944176303154704 Test RE 0.6750191792665047\n",
      "77 Train Loss 0.19915962 Test MSE 1.9399187484511708 Test RE 0.6657326094606439\n",
      "78 Train Loss 0.19021533 Test MSE 1.8881681839430402 Test RE 0.6567928222838905\n",
      "79 Train Loss 0.1824693 Test MSE 1.846989040568679 Test RE 0.6495913295744619\n",
      "80 Train Loss 0.17538513 Test MSE 1.7771560878792516 Test RE 0.6371927813297767\n",
      "81 Train Loss 0.16676915 Test MSE 1.7289609884407466 Test RE 0.6284933073295483\n",
      "82 Train Loss 0.15890032 Test MSE 1.7161931339042729 Test RE 0.6261683905786586\n",
      "83 Train Loss 0.1498124 Test MSE 1.6719136563177501 Test RE 0.6180377216314992\n",
      "84 Train Loss 0.14189318 Test MSE 1.6169740181537977 Test RE 0.6077984400422208\n",
      "85 Train Loss 0.13081335 Test MSE 1.6059324637886114 Test RE 0.6057197005697731\n",
      "86 Train Loss 0.12086413 Test MSE 1.556099644998071 Test RE 0.5962477622180097\n",
      "87 Train Loss 0.10945243 Test MSE 1.5242105921213607 Test RE 0.5901067031889717\n",
      "88 Train Loss 0.09996212 Test MSE 1.496789928969335 Test RE 0.5847745810526259\n",
      "89 Train Loss 0.09283189 Test MSE 1.4580663939180503 Test RE 0.5771606454541667\n",
      "90 Train Loss 0.08321957 Test MSE 1.402775586733303 Test RE 0.5661117379511486\n",
      "91 Train Loss 0.08028942 Test MSE 1.392584895472241 Test RE 0.5640516843639218\n",
      "92 Train Loss 0.07278084 Test MSE 1.319226378311538 Test RE 0.5489941586789401\n",
      "93 Train Loss 0.06705124 Test MSE 1.2552656413612704 Test RE 0.5355202294648226\n",
      "94 Train Loss 0.06166091 Test MSE 1.1504003703376118 Test RE 0.5126636989521974\n",
      "95 Train Loss 0.058915842 Test MSE 1.0962871880731953 Test RE 0.5004609887718019\n",
      "96 Train Loss 0.05589898 Test MSE 0.9932857284991728 Test RE 0.47637082775440215\n",
      "97 Train Loss 0.051931657 Test MSE 0.9836425257576209 Test RE 0.4740527916418031\n",
      "98 Train Loss 0.044828996 Test MSE 0.7347464180199202 Test RE 0.409710221608934\n",
      "99 Train Loss 0.042138338 Test MSE 0.7202939576597015 Test RE 0.40566070967624057\n",
      "Training time: 71.75\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.679 Test MSE 8.660006847709589 Test RE 1.406588874436655\n",
      "1 Train Loss 53.657677 Test MSE 8.498450185584078 Test RE 1.3934068038972407\n",
      "2 Train Loss 48.06275 Test MSE 8.87701180895825 Test RE 1.4241031894307623\n",
      "3 Train Loss 46.78606 Test MSE 8.443226128302856 Test RE 1.3888721540242444\n",
      "4 Train Loss 45.958252 Test MSE 8.51400084974517 Test RE 1.3946810655270168\n",
      "5 Train Loss 45.770706 Test MSE 8.417724247061402 Test RE 1.386773096306617\n",
      "6 Train Loss 45.593025 Test MSE 8.275112928456846 Test RE 1.3749757061704706\n",
      "7 Train Loss 44.77477 Test MSE 8.365432043353472 Test RE 1.3824589614732943\n",
      "8 Train Loss 41.359436 Test MSE 7.744164811235624 Test RE 1.3301338745990365\n",
      "9 Train Loss 40.67606 Test MSE 7.901906974954363 Test RE 1.3436124413892858\n",
      "10 Train Loss 40.52237 Test MSE 7.878110865390977 Test RE 1.3415878126335694\n",
      "11 Train Loss 40.304813 Test MSE 7.858128792143209 Test RE 1.339885327939896\n",
      "12 Train Loss 40.128487 Test MSE 7.757046161652159 Test RE 1.3312396621111846\n",
      "13 Train Loss 39.94284 Test MSE 7.8470310922755555 Test RE 1.3389388622308367\n",
      "14 Train Loss 39.27404 Test MSE 7.953617414173175 Test RE 1.3480016028931745\n",
      "15 Train Loss 38.75428 Test MSE 7.919852483879496 Test RE 1.345137271722413\n",
      "16 Train Loss 37.854027 Test MSE 7.8167717850505545 Test RE 1.3363547959960569\n",
      "17 Train Loss 37.01839 Test MSE 7.895719737107301 Test RE 1.3430863103083135\n",
      "18 Train Loss 35.945038 Test MSE 7.638908387526345 Test RE 1.3210635535229414\n",
      "19 Train Loss 33.180244 Test MSE 7.660089366312642 Test RE 1.3228937920844988\n",
      "20 Train Loss 30.967913 Test MSE 7.77743296974364 Test RE 1.3329878738927214\n",
      "21 Train Loss 29.2233 Test MSE 7.73222662905389 Test RE 1.3291082310707045\n",
      "22 Train Loss 27.416767 Test MSE 7.221243888002973 Test RE 1.2844407242097702\n",
      "23 Train Loss 24.717108 Test MSE 7.112779314974424 Test RE 1.2747579449713256\n",
      "24 Train Loss 23.456726 Test MSE 6.922532211467372 Test RE 1.2575942786586285\n",
      "25 Train Loss 22.492702 Test MSE 6.218387079756286 Test RE 1.1919195315313733\n",
      "26 Train Loss 21.712614 Test MSE 5.921246247258712 Test RE 1.1630934808932953\n",
      "27 Train Loss 21.191412 Test MSE 5.8289246844424465 Test RE 1.1539906291561663\n",
      "28 Train Loss 20.279316 Test MSE 5.691936269120847 Test RE 1.1403497578276325\n",
      "29 Train Loss 19.645218 Test MSE 5.613311828419012 Test RE 1.1324463715505557\n",
      "30 Train Loss 19.294704 Test MSE 5.553651402878958 Test RE 1.1264122588737122\n",
      "31 Train Loss 18.93612 Test MSE 5.447186827855097 Test RE 1.115563242045087\n",
      "32 Train Loss 18.749609 Test MSE 5.379699656236192 Test RE 1.1086311454248217\n",
      "33 Train Loss 18.53982 Test MSE 5.429986158924435 Test RE 1.1138005334695953\n",
      "34 Train Loss 18.435617 Test MSE 5.383650722034473 Test RE 1.1090381821475572\n",
      "35 Train Loss 18.12736 Test MSE 5.473600603803483 Test RE 1.1182646917900623\n",
      "36 Train Loss 17.895668 Test MSE 5.424979806093753 Test RE 1.1132869627030226\n",
      "37 Train Loss 17.248976 Test MSE 5.150458587411759 Test RE 1.0847533750693634\n",
      "38 Train Loss 15.6283245 Test MSE 4.918842579425094 Test RE 1.0600821509725478\n",
      "39 Train Loss 13.587044 Test MSE 4.418624121386552 Test RE 1.0047351355943404\n",
      "40 Train Loss 11.251012 Test MSE 3.967322294459705 Test RE 0.9520435206383433\n",
      "41 Train Loss 8.870249 Test MSE 3.3352168400522944 Test RE 0.872911264224653\n",
      "42 Train Loss 7.366261 Test MSE 2.879892603928206 Test RE 0.8111407248502505\n",
      "43 Train Loss 5.7300267 Test MSE 2.717746880237737 Test RE 0.7879752255752888\n",
      "44 Train Loss 4.8551383 Test MSE 2.2344350415196863 Test RE 0.7144830446963641\n",
      "45 Train Loss 4.417681 Test MSE 2.019503551912778 Test RE 0.6792511321447204\n",
      "46 Train Loss 3.9580543 Test MSE 1.6765146339836272 Test RE 0.6188875334933746\n",
      "47 Train Loss 3.5459857 Test MSE 1.5280723280885502 Test RE 0.5908537766918628\n",
      "48 Train Loss 3.1936026 Test MSE 1.147572910770474 Test RE 0.5120332977097167\n",
      "49 Train Loss 2.8076744 Test MSE 0.840298041690052 Test RE 0.4381519370113149\n",
      "50 Train Loss 2.563287 Test MSE 0.808740969661766 Test RE 0.42984589388377636\n",
      "51 Train Loss 2.1013682 Test MSE 0.4072157508310552 Test RE 0.3050144006725598\n",
      "52 Train Loss 1.5558966 Test MSE 0.22946187606298457 Test RE 0.22896195796289925\n",
      "53 Train Loss 1.1698631 Test MSE 0.18511677539677815 Test RE 0.2056510582021688\n",
      "54 Train Loss 0.7160544 Test MSE 0.14979319650854817 Test RE 0.18499249276384527\n",
      "55 Train Loss 0.57364345 Test MSE 0.17091243150496596 Test RE 0.19760361557570919\n",
      "56 Train Loss 0.4745471 Test MSE 0.14843568355158 Test RE 0.18415233020833238\n",
      "57 Train Loss 0.36635643 Test MSE 0.12258768014535773 Test RE 0.16735221834284894\n",
      "58 Train Loss 0.3211513 Test MSE 0.10324442405582426 Test RE 0.1535823693422734\n",
      "59 Train Loss 0.26871443 Test MSE 0.09545576501039037 Test RE 0.14767573516479526\n",
      "60 Train Loss 0.23047985 Test MSE 0.08262079863532949 Test RE 0.13738925058991558\n",
      "61 Train Loss 0.20911549 Test MSE 0.07042466325120406 Test RE 0.12684415211570893\n",
      "62 Train Loss 0.19434099 Test MSE 0.058910211783447505 Test RE 0.1160121171032496\n",
      "63 Train Loss 0.17674516 Test MSE 0.05190558921964135 Test RE 0.10889680126755885\n",
      "64 Train Loss 0.16075628 Test MSE 0.04691694076335789 Test RE 0.10353159464842204\n",
      "65 Train Loss 0.15056388 Test MSE 0.04475474982924476 Test RE 0.10111780349729382\n",
      "66 Train Loss 0.14197925 Test MSE 0.04349383762082261 Test RE 0.09968318933286778\n",
      "67 Train Loss 0.13503738 Test MSE 0.04591090727075528 Test RE 0.10241557269690377\n",
      "68 Train Loss 0.122904524 Test MSE 0.04795250574828287 Test RE 0.1046679488057156\n",
      "69 Train Loss 0.11582011 Test MSE 0.04384591474270883 Test RE 0.10008583754204117\n",
      "70 Train Loss 0.11104293 Test MSE 0.041048092415389564 Test RE 0.09683994853971262\n",
      "71 Train Loss 0.10654834 Test MSE 0.04036298047408942 Test RE 0.09602839588028945\n",
      "72 Train Loss 0.10090645 Test MSE 0.03444239388462268 Test RE 0.0887063530843668\n",
      "73 Train Loss 0.09738769 Test MSE 0.03537260661456351 Test RE 0.08989625347286168\n",
      "74 Train Loss 0.09148829 Test MSE 0.03491377070069692 Test RE 0.08931130555462821\n",
      "75 Train Loss 0.08385355 Test MSE 0.0277032502288822 Test RE 0.07955608858585059\n",
      "76 Train Loss 0.07878894 Test MSE 0.022157939197631017 Test RE 0.07114964596916788\n",
      "77 Train Loss 0.076218635 Test MSE 0.02125592664424378 Test RE 0.06968640836765376\n",
      "78 Train Loss 0.0705865 Test MSE 0.02147743642812292 Test RE 0.07004857121679998\n",
      "79 Train Loss 0.06782764 Test MSE 0.019383339732317914 Test RE 0.06654606258779545\n",
      "80 Train Loss 0.06520916 Test MSE 0.017434690022709604 Test RE 0.06311246973407293\n",
      "81 Train Loss 0.06158109 Test MSE 0.016469839418626626 Test RE 0.06134126708747394\n",
      "82 Train Loss 0.056703694 Test MSE 0.01485269005431534 Test RE 0.05825197030184694\n",
      "83 Train Loss 0.05540508 Test MSE 0.013940658941395541 Test RE 0.056435153603350226\n",
      "84 Train Loss 0.053818647 Test MSE 0.013198933062170346 Test RE 0.05491329116887024\n",
      "85 Train Loss 0.051695496 Test MSE 0.013192921580233294 Test RE 0.05490078455745224\n",
      "86 Train Loss 0.04963403 Test MSE 0.013435198513698106 Test RE 0.05540259462633925\n",
      "87 Train Loss 0.04779322 Test MSE 0.012318716230345084 Test RE 0.0530506593303958\n",
      "88 Train Loss 0.04676155 Test MSE 0.01290304967210095 Test RE 0.054294300823192566\n",
      "89 Train Loss 0.044110343 Test MSE 0.012533696649772804 Test RE 0.05351156468174312\n",
      "90 Train Loss 0.040324237 Test MSE 0.011058713996369084 Test RE 0.05026438503009901\n",
      "91 Train Loss 0.039058805 Test MSE 0.01095473935551884 Test RE 0.050027532726165336\n",
      "92 Train Loss 0.037837382 Test MSE 0.009997635839540438 Test RE 0.04779216637294428\n",
      "93 Train Loss 0.037110645 Test MSE 0.010364828942890456 Test RE 0.04866190760710047\n",
      "94 Train Loss 0.034274288 Test MSE 0.009942349196466948 Test RE 0.047659838513680185\n",
      "95 Train Loss 0.031944294 Test MSE 0.00902510060275643 Test RE 0.045408179035825086\n",
      "96 Train Loss 0.031025076 Test MSE 0.008810972651669196 Test RE 0.04486627220569287\n",
      "97 Train Loss 0.028855732 Test MSE 0.008265693665100132 Test RE 0.04345579637032932\n",
      "98 Train Loss 0.025540255 Test MSE 0.007750462029373903 Test RE 0.04207962460046174\n",
      "99 Train Loss 0.022816919 Test MSE 0.006511451847120906 Test RE 0.03856976359016379\n",
      "Training time: 72.14\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.56541 Test MSE 8.557560545816855 Test RE 1.3982442773002515\n",
      "1 Train Loss 55.271004 Test MSE 8.599720290521542 Test RE 1.401684346133773\n",
      "2 Train Loss 52.515957 Test MSE 7.80897506869826 Test RE 1.335688166664586\n",
      "3 Train Loss 43.531143 Test MSE 6.914468035222421 Test RE 1.2568615686610416\n",
      "4 Train Loss 40.427505 Test MSE 7.362438133054478 Test RE 1.2969370273962437\n",
      "5 Train Loss 39.64109 Test MSE 7.477951312281179 Test RE 1.3070715953610215\n",
      "6 Train Loss 38.516792 Test MSE 7.298280898925295 Test RE 1.2912738247844748\n",
      "7 Train Loss 37.135296 Test MSE 7.012433579992183 Test RE 1.2657339837700938\n",
      "8 Train Loss 36.00792 Test MSE 6.835024543278327 Test RE 1.2496203799666301\n",
      "9 Train Loss 34.64011 Test MSE 6.776463189327467 Test RE 1.2442555942671822\n",
      "10 Train Loss 32.904175 Test MSE 6.497892053881638 Test RE 1.218412389385848\n",
      "11 Train Loss 30.207932 Test MSE 6.061793419333236 Test RE 1.1768161674630198\n",
      "12 Train Loss 28.21544 Test MSE 6.163504106552502 Test RE 1.1866479822838685\n",
      "13 Train Loss 27.235912 Test MSE 5.93165730074451 Test RE 1.164115538575168\n",
      "14 Train Loss 25.342487 Test MSE 5.8984917231080365 Test RE 1.1608565266689292\n",
      "15 Train Loss 24.468575 Test MSE 5.803813312310908 Test RE 1.1515022142963078\n",
      "16 Train Loss 23.91894 Test MSE 5.6302611648669645 Test RE 1.1341547878828475\n",
      "17 Train Loss 23.496634 Test MSE 5.559356660206771 Test RE 1.1269906911247791\n",
      "18 Train Loss 23.259354 Test MSE 5.456017360443119 Test RE 1.116467105699063\n",
      "19 Train Loss 22.939178 Test MSE 5.596262701266524 Test RE 1.130725292678043\n",
      "20 Train Loss 22.657692 Test MSE 5.57109287468579 Test RE 1.1281796444558525\n",
      "21 Train Loss 22.262657 Test MSE 5.474125796907126 Test RE 1.1183183393667993\n",
      "22 Train Loss 21.787937 Test MSE 5.083574340767738 Test RE 1.0776870141439505\n",
      "23 Train Loss 20.134953 Test MSE 4.86491922262481 Test RE 1.0542555041303725\n",
      "24 Train Loss 18.321413 Test MSE 4.627468449680169 Test RE 1.0282051942175976\n",
      "25 Train Loss 15.917955 Test MSE 3.9898776918443986 Test RE 0.9547460090788846\n",
      "26 Train Loss 12.822856 Test MSE 3.7574799966843417 Test RE 0.9265234142970827\n",
      "27 Train Loss 8.64798 Test MSE 2.580905040256189 Test RE 0.7678812676309718\n",
      "28 Train Loss 7.796274 Test MSE 2.520148520384877 Test RE 0.7587891779281628\n",
      "29 Train Loss 7.008604 Test MSE 2.2983718652752825 Test RE 0.7246331678669207\n",
      "30 Train Loss 6.593747 Test MSE 2.289111799860229 Test RE 0.7231719328439636\n",
      "31 Train Loss 6.2040243 Test MSE 2.2109448640861404 Test RE 0.7107175118998285\n",
      "32 Train Loss 5.891592 Test MSE 2.2101691199991653 Test RE 0.7105928178638319\n",
      "33 Train Loss 5.6767497 Test MSE 2.1764657714947333 Test RE 0.7051540117890361\n",
      "34 Train Loss 5.596464 Test MSE 2.193766572396932 Test RE 0.7079511109184686\n",
      "35 Train Loss 5.490362 Test MSE 2.140446863234563 Test RE 0.6992947789433824\n",
      "36 Train Loss 5.3997984 Test MSE 2.131490711589443 Test RE 0.6978302353930564\n",
      "37 Train Loss 5.3049607 Test MSE 2.143169736246214 Test RE 0.6997394257476259\n",
      "38 Train Loss 5.234566 Test MSE 2.121977639015563 Test RE 0.6962712482229798\n",
      "39 Train Loss 5.182985 Test MSE 2.1164333410224456 Test RE 0.6953610453816824\n",
      "40 Train Loss 5.131725 Test MSE 2.1204054712750784 Test RE 0.6960132676470071\n",
      "41 Train Loss 5.0802746 Test MSE 2.1110202234379964 Test RE 0.6944712273760921\n",
      "42 Train Loss 5.013524 Test MSE 2.123514599723369 Test RE 0.6965233592310163\n",
      "43 Train Loss 4.958927 Test MSE 2.122189371630792 Test RE 0.6963059846057444\n",
      "44 Train Loss 4.916692 Test MSE 2.119548938221969 Test RE 0.6958726769454662\n",
      "45 Train Loss 4.8896627 Test MSE 2.1282973257248265 Test RE 0.6973072970376527\n",
      "46 Train Loss 4.8417234 Test MSE 2.1232313046478395 Test RE 0.6964768965838496\n",
      "47 Train Loss 4.802991 Test MSE 2.1154850285753377 Test RE 0.6952052423603835\n",
      "48 Train Loss 4.7778277 Test MSE 2.112361472417612 Test RE 0.6946918105116269\n",
      "49 Train Loss 4.760616 Test MSE 2.108337487482503 Test RE 0.6940298116093804\n",
      "50 Train Loss 4.732813 Test MSE 2.116164151676937 Test RE 0.6953168224587514\n",
      "51 Train Loss 4.711467 Test MSE 2.1291697779060685 Test RE 0.6974502058621795\n",
      "52 Train Loss 4.6948357 Test MSE 2.141357484770968 Test RE 0.6994435154485509\n",
      "53 Train Loss 4.676215 Test MSE 2.1308375015535597 Test RE 0.6977232997543001\n",
      "54 Train Loss 4.6685624 Test MSE 2.1357796340967954 Test RE 0.6985319592437031\n",
      "55 Train Loss 4.6404033 Test MSE 2.1506522923166917 Test RE 0.7009598791075584\n",
      "56 Train Loss 4.621851 Test MSE 2.143432947469026 Test RE 0.6997823933232188\n",
      "57 Train Loss 4.6023326 Test MSE 2.1363429565561667 Test RE 0.6986240738026115\n",
      "58 Train Loss 4.595491 Test MSE 2.1418324263941715 Test RE 0.6995210775611853\n",
      "59 Train Loss 4.5733247 Test MSE 2.1500644350452576 Test RE 0.7008640727037153\n",
      "60 Train Loss 4.5575666 Test MSE 2.1503051210464226 Test RE 0.700903300237468\n",
      "61 Train Loss 4.5405483 Test MSE 2.148530535871449 Test RE 0.7006140228413946\n",
      "62 Train Loss 4.529967 Test MSE 2.1508083333704784 Test RE 0.700985307796023\n",
      "63 Train Loss 4.490284 Test MSE 2.145298701030482 Test RE 0.7000868902513362\n",
      "64 Train Loss 4.440267 Test MSE 2.1714118842342276 Test RE 0.7043348304925473\n",
      "65 Train Loss 4.1924353 Test MSE 2.0930975664894853 Test RE 0.6915168973832808\n",
      "66 Train Loss 3.9306521 Test MSE 2.010417786313566 Test RE 0.6777214310331519\n",
      "67 Train Loss 3.0638578 Test MSE 1.3821748114596173 Test RE 0.5619394827443436\n",
      "68 Train Loss 2.47277 Test MSE 1.1674315142309089 Test RE 0.516444630766801\n",
      "69 Train Loss 1.9353801 Test MSE 0.8850051215383586 Test RE 0.44965657924451574\n",
      "70 Train Loss 1.5012856 Test MSE 0.787380400252952 Test RE 0.4241313357488895\n",
      "71 Train Loss 1.320471 Test MSE 0.6651187819649184 Test RE 0.3898142097102673\n",
      "72 Train Loss 0.9191182 Test MSE 0.18428492828759663 Test RE 0.20518847761570103\n",
      "73 Train Loss 0.71876615 Test MSE 0.14470367776882787 Test RE 0.18182259211259205\n",
      "74 Train Loss 0.5108739 Test MSE 0.08802582729922456 Test RE 0.1418120444059991\n",
      "75 Train Loss 0.4126584 Test MSE 0.08570257796336825 Test RE 0.13992812128326954\n",
      "76 Train Loss 0.3223071 Test MSE 0.08117794828768372 Test RE 0.13618431654394014\n",
      "77 Train Loss 0.26295382 Test MSE 0.07890467163674834 Test RE 0.13426394965052435\n",
      "78 Train Loss 0.22506973 Test MSE 0.06402195673586501 Test RE 0.12094071506864956\n",
      "79 Train Loss 0.19216606 Test MSE 0.0505068086013643 Test RE 0.10741947462845809\n",
      "80 Train Loss 0.16305605 Test MSE 0.040378133548656964 Test RE 0.09604641968429355\n",
      "81 Train Loss 0.1414228 Test MSE 0.03926344910884333 Test RE 0.09471140606701588\n",
      "82 Train Loss 0.12299202 Test MSE 0.03289579894094183 Test RE 0.08669185173579823\n",
      "83 Train Loss 0.11133327 Test MSE 0.023631962404972964 Test RE 0.0734781060978226\n",
      "84 Train Loss 0.09830896 Test MSE 0.016303585611251427 Test RE 0.06103087892906178\n",
      "85 Train Loss 0.08827013 Test MSE 0.014069894990152144 Test RE 0.05669613950097268\n",
      "86 Train Loss 0.0811075 Test MSE 0.015074316791101536 Test RE 0.05868496895974341\n",
      "87 Train Loss 0.07419194 Test MSE 0.014586856152010448 Test RE 0.05772831886456889\n",
      "88 Train Loss 0.06812643 Test MSE 0.01465722285725751 Test RE 0.05786739147903865\n",
      "89 Train Loss 0.063442454 Test MSE 0.012690706420716109 Test RE 0.05384569154763887\n",
      "90 Train Loss 0.05730955 Test MSE 0.010487697266057326 Test RE 0.04894948552874773\n",
      "91 Train Loss 0.051046494 Test MSE 0.009839343075270431 Test RE 0.0474123096504924\n",
      "92 Train Loss 0.045630675 Test MSE 0.008960516774590133 Test RE 0.04524541634114036\n",
      "93 Train Loss 0.041367978 Test MSE 0.008277190210244539 Test RE 0.04348600665565923\n",
      "94 Train Loss 0.038039155 Test MSE 0.008462142804229958 Test RE 0.04396916673302722\n",
      "95 Train Loss 0.033857465 Test MSE 0.010211764501384748 Test RE 0.048301259514790994\n",
      "96 Train Loss 0.03198313 Test MSE 0.009445744837074901 Test RE 0.04645432618521767\n",
      "97 Train Loss 0.028514085 Test MSE 0.009127667995619912 Test RE 0.045665474823521665\n",
      "98 Train Loss 0.0263039 Test MSE 0.009295159476500435 Test RE 0.04608254787511678\n",
      "99 Train Loss 0.024640093 Test MSE 0.00813473270569123 Test RE 0.0431101668706422\n",
      "Training time: 70.90\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.094566 Test MSE 8.495721041712947 Test RE 1.3931830505711738\n",
      "1 Train Loss 55.90783 Test MSE 8.700194600911455 Test RE 1.4098488151335296\n",
      "2 Train Loss 50.28839 Test MSE 7.196385010783091 Test RE 1.2822279973293165\n",
      "3 Train Loss 42.814255 Test MSE 6.8002432108745525 Test RE 1.2464368584071108\n",
      "4 Train Loss 38.601833 Test MSE 7.771832893227524 Test RE 1.332507884007244\n",
      "5 Train Loss 36.413612 Test MSE 7.610282159632262 Test RE 1.3185859376051987\n",
      "6 Train Loss 34.614395 Test MSE 6.950541157809833 Test RE 1.2601358582457014\n",
      "7 Train Loss 33.176407 Test MSE 6.775056463368747 Test RE 1.2441264400578373\n",
      "8 Train Loss 30.262455 Test MSE 6.302480273333778 Test RE 1.1999518172740327\n",
      "9 Train Loss 28.496178 Test MSE 6.449996297401239 Test RE 1.213913644464484\n",
      "10 Train Loss 26.79168 Test MSE 6.115329029533425 Test RE 1.1820013557615854\n",
      "11 Train Loss 25.739967 Test MSE 6.109426354217128 Test RE 1.1814307687503\n",
      "12 Train Loss 24.684841 Test MSE 5.904909254659314 Test RE 1.1614878582441515\n",
      "13 Train Loss 23.802292 Test MSE 5.961407897675952 Test RE 1.1670312342080105\n",
      "14 Train Loss 23.257723 Test MSE 5.755456766437495 Test RE 1.1466951040930067\n",
      "15 Train Loss 22.873775 Test MSE 5.597095028379491 Test RE 1.1308093754291373\n",
      "16 Train Loss 22.576408 Test MSE 5.675757134902841 Test RE 1.1387279018928962\n",
      "17 Train Loss 22.428347 Test MSE 5.576371860384091 Test RE 1.1287140309906551\n",
      "18 Train Loss 22.234745 Test MSE 5.653737348229726 Test RE 1.136516838936358\n",
      "19 Train Loss 21.993805 Test MSE 5.696333513607325 Test RE 1.1407901552923532\n",
      "20 Train Loss 21.545864 Test MSE 5.870970644767312 Test RE 1.1581452084425152\n",
      "21 Train Loss 20.618225 Test MSE 5.754405422413735 Test RE 1.146590366436739\n",
      "22 Train Loss 18.556328 Test MSE 5.120790337526807 Test RE 1.081624603789764\n",
      "23 Train Loss 16.805714 Test MSE 5.4321828890784944 Test RE 1.1140258076910718\n",
      "24 Train Loss 15.262706 Test MSE 5.6958838716868785 Test RE 1.1407451300846614\n",
      "25 Train Loss 14.716602 Test MSE 5.554018084807107 Test RE 1.1264494441570092\n",
      "26 Train Loss 14.333622 Test MSE 5.5573340949054995 Test RE 1.1267856656367918\n",
      "27 Train Loss 13.983545 Test MSE 5.62984623715006 Test RE 1.1341129957782288\n",
      "28 Train Loss 13.335709 Test MSE 5.907188507518788 Test RE 1.1617119996318666\n",
      "29 Train Loss 12.650861 Test MSE 5.970000870621091 Test RE 1.167872030277132\n",
      "30 Train Loss 12.170805 Test MSE 6.01982981537228 Test RE 1.172735756995935\n",
      "31 Train Loss 11.966149 Test MSE 5.982503675764799 Test RE 1.1690943114600216\n",
      "32 Train Loss 11.684101 Test MSE 5.902001111677941 Test RE 1.1612018090768927\n",
      "33 Train Loss 11.57099 Test MSE 5.909672098394829 Test RE 1.1619561863647851\n",
      "34 Train Loss 11.467684 Test MSE 5.861606256232067 Test RE 1.1572212002604843\n",
      "35 Train Loss 11.383419 Test MSE 5.875830751566082 Test RE 1.1586244771473349\n",
      "36 Train Loss 11.3242445 Test MSE 5.889618618180025 Test RE 1.1599830594426581\n",
      "37 Train Loss 11.280716 Test MSE 5.891985743268788 Test RE 1.1602161432243951\n",
      "38 Train Loss 11.23378 Test MSE 5.892330538877217 Test RE 1.160250090317627\n",
      "39 Train Loss 11.19118 Test MSE 5.877569714234059 Test RE 1.1587959129619394\n",
      "40 Train Loss 11.123478 Test MSE 5.851281776256102 Test RE 1.156201601508833\n",
      "41 Train Loss 11.095931 Test MSE 5.8437083459201915 Test RE 1.1554531118741673\n",
      "42 Train Loss 11.055244 Test MSE 5.838855074827961 Test RE 1.1549732032562592\n",
      "43 Train Loss 11.006687 Test MSE 5.873749491104802 Test RE 1.1584192625158056\n",
      "44 Train Loss 10.975861 Test MSE 5.847798990146179 Test RE 1.155857454498278\n",
      "45 Train Loss 10.920852 Test MSE 5.82462684410315 Test RE 1.1535651148194175\n",
      "46 Train Loss 10.8843 Test MSE 5.8119190302925725 Test RE 1.1523060388726056\n",
      "47 Train Loss 10.83102 Test MSE 5.76497594828114 Test RE 1.1476429949337466\n",
      "48 Train Loss 10.78426 Test MSE 5.757808894534507 Test RE 1.1469293946428218\n",
      "49 Train Loss 10.725499 Test MSE 5.694126583076 Test RE 1.1405691457150913\n",
      "50 Train Loss 10.650611 Test MSE 5.627885507612191 Test RE 1.1339154874979454\n",
      "51 Train Loss 10.497299 Test MSE 5.612510691287014 Test RE 1.1323655567625124\n",
      "52 Train Loss 10.355932 Test MSE 5.5226851948433815 Test RE 1.1232675283117328\n",
      "53 Train Loss 10.163794 Test MSE 5.381988085793405 Test RE 1.10886691644359\n",
      "54 Train Loss 9.9572525 Test MSE 5.21536582522809 Test RE 1.0915671282021044\n",
      "55 Train Loss 9.740525 Test MSE 5.144194167443095 Test RE 1.0840934903120176\n",
      "56 Train Loss 8.796789 Test MSE 4.567872121990718 Test RE 1.0215627038584165\n",
      "57 Train Loss 7.873559 Test MSE 4.429473236336144 Test RE 1.005967850105642\n",
      "58 Train Loss 7.3871346 Test MSE 4.454508460942594 Test RE 1.008806691688384\n",
      "59 Train Loss 7.041318 Test MSE 4.301123083486149 Test RE 0.9912860525181164\n",
      "60 Train Loss 6.747034 Test MSE 4.346126116737506 Test RE 0.9964585147955554\n",
      "61 Train Loss 6.5915184 Test MSE 4.298795415934622 Test RE 0.9910177857661431\n",
      "62 Train Loss 6.457862 Test MSE 4.277272535678684 Test RE 0.9885337966585753\n",
      "63 Train Loss 6.298673 Test MSE 4.082387313663963 Test RE 0.9657509925009801\n",
      "64 Train Loss 4.763006 Test MSE 3.2588445973251687 Test RE 0.8628591041805231\n",
      "65 Train Loss 3.9762588 Test MSE 2.8519182511932324 Test RE 0.8071915307736357\n",
      "66 Train Loss 3.5061846 Test MSE 2.788738276760749 Test RE 0.7982003963310043\n",
      "67 Train Loss 3.2470915 Test MSE 2.616576336301025 Test RE 0.7731695914150059\n",
      "68 Train Loss 3.0701904 Test MSE 2.453543801835085 Test RE 0.7486950608452547\n",
      "69 Train Loss 2.9653563 Test MSE 2.307555787897512 Test RE 0.7260794830262892\n",
      "70 Train Loss 2.8990607 Test MSE 2.2649633867359036 Test RE 0.7193473586732824\n",
      "71 Train Loss 2.8006573 Test MSE 2.1612437855033306 Test RE 0.7026837964495884\n",
      "72 Train Loss 2.7056575 Test MSE 2.1910189872032504 Test RE 0.7075076349694889\n",
      "73 Train Loss 2.6571991 Test MSE 2.176258340660324 Test RE 0.7051204081890481\n",
      "74 Train Loss 2.628336 Test MSE 2.154025899357065 Test RE 0.7015094418031605\n",
      "75 Train Loss 2.602143 Test MSE 2.163248920337746 Test RE 0.7030096849767908\n",
      "76 Train Loss 2.579489 Test MSE 2.1519664787740136 Test RE 0.7011740121172683\n",
      "77 Train Loss 2.5642889 Test MSE 2.151754766638515 Test RE 0.7011395202466492\n",
      "78 Train Loss 2.5502393 Test MSE 2.1509375918862306 Test RE 0.7010063712626621\n",
      "79 Train Loss 2.5399299 Test MSE 2.1401210450306185 Test RE 0.6992415536930798\n",
      "80 Train Loss 2.5279856 Test MSE 2.138777157525036 Test RE 0.6990219750955955\n",
      "81 Train Loss 2.5142848 Test MSE 2.1442692730876103 Test RE 0.6999189007112655\n",
      "82 Train Loss 2.502459 Test MSE 2.1357821593003434 Test RE 0.6985323721924062\n",
      "83 Train Loss 2.4929 Test MSE 2.1314653266513233 Test RE 0.6978260799843581\n",
      "84 Train Loss 2.4783647 Test MSE 2.1292734373449296 Test RE 0.6974671834695523\n",
      "85 Train Loss 2.4640622 Test MSE 2.1235304848294256 Test RE 0.6965259644230747\n",
      "86 Train Loss 2.450297 Test MSE 2.1211163530325514 Test RE 0.6961299296908113\n",
      "87 Train Loss 2.427929 Test MSE 2.1254499442891652 Test RE 0.6968406882707672\n",
      "88 Train Loss 2.4115686 Test MSE 2.1202898464911972 Test RE 0.6959942907386146\n",
      "89 Train Loss 2.3689048 Test MSE 2.1208224473151107 Test RE 0.6960816995091116\n",
      "90 Train Loss 2.335715 Test MSE 2.1195106729764355 Test RE 0.6958663954535544\n",
      "91 Train Loss 2.299673 Test MSE 2.144036518138203 Test RE 0.6998809124764237\n",
      "92 Train Loss 2.2505002 Test MSE 2.151905286600967 Test RE 0.7011640429409527\n",
      "93 Train Loss 2.0466075 Test MSE 1.9823845535258915 Test RE 0.6729797753295729\n",
      "94 Train Loss 1.7838552 Test MSE 1.8681750573628952 Test RE 0.6533062981071087\n",
      "95 Train Loss 1.6345696 Test MSE 1.8874727611833637 Test RE 0.6566718609351071\n",
      "96 Train Loss 1.4752219 Test MSE 1.8614256619901317 Test RE 0.6521250885839442\n",
      "97 Train Loss 1.3236893 Test MSE 1.7159926185420826 Test RE 0.6261318095998687\n",
      "98 Train Loss 1.2228024 Test MSE 1.5287923939074586 Test RE 0.5909929728187295\n",
      "99 Train Loss 1.1721392 Test MSE 1.3647468057488017 Test RE 0.5583854632329327\n",
      "Training time: 70.68\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.579967 Test MSE 8.641647390756448 Test RE 1.4050970794598179\n",
      "1 Train Loss 53.251488 Test MSE 8.100591137736883 Test RE 1.3603993524588314\n",
      "2 Train Loss 44.530838 Test MSE 8.463366672966432 Test RE 1.3905276811620044\n",
      "3 Train Loss 43.695007 Test MSE 8.472978072581352 Test RE 1.391317031631535\n",
      "4 Train Loss 43.643875 Test MSE 8.47841069184232 Test RE 1.3917629955215347\n",
      "5 Train Loss 43.494247 Test MSE 8.480633127288407 Test RE 1.3919453941369662\n",
      "6 Train Loss 43.3192 Test MSE 8.471279687454002 Test RE 1.391177581808852\n",
      "7 Train Loss 43.21455 Test MSE 8.436204523731352 Test RE 1.3882945229571628\n",
      "8 Train Loss 43.141 Test MSE 8.522989312782453 Test RE 1.39541707275283\n",
      "9 Train Loss 42.91125 Test MSE 8.382027967004728 Test RE 1.383829590955484\n",
      "10 Train Loss 42.658485 Test MSE 8.395027433062815 Test RE 1.3849022476316264\n",
      "11 Train Loss 41.589787 Test MSE 8.29435895236793 Test RE 1.3765737173877546\n",
      "12 Train Loss 40.94603 Test MSE 8.212058297999974 Test RE 1.369727175165238\n",
      "13 Train Loss 39.80441 Test MSE 7.902090792438731 Test RE 1.343628069137335\n",
      "14 Train Loss 39.571785 Test MSE 7.904904554545232 Test RE 1.3438672661646565\n",
      "15 Train Loss 39.52721 Test MSE 7.899713541101392 Test RE 1.3434259465615312\n",
      "16 Train Loss 39.491646 Test MSE 7.896277206136367 Test RE 1.3431337230731368\n",
      "17 Train Loss 39.387146 Test MSE 7.883725369388419 Test RE 1.3420657830963534\n",
      "18 Train Loss 39.334114 Test MSE 7.889335556517477 Test RE 1.3425432160879864\n",
      "19 Train Loss 39.28402 Test MSE 7.903257661448798 Test RE 1.3437272694705977\n",
      "20 Train Loss 39.245575 Test MSE 7.916900325825567 Test RE 1.3448865455905492\n",
      "21 Train Loss 39.18091 Test MSE 7.876086646624861 Test RE 1.3414154463304104\n",
      "22 Train Loss 39.11212 Test MSE 7.907209888180239 Test RE 1.3440632101224024\n",
      "23 Train Loss 39.02072 Test MSE 7.874983362156055 Test RE 1.3413214901103618\n",
      "24 Train Loss 38.984737 Test MSE 7.815967401622467 Test RE 1.3362860355577906\n",
      "25 Train Loss 38.900593 Test MSE 7.815066880847445 Test RE 1.3362090528928305\n",
      "26 Train Loss 38.851868 Test MSE 7.760044880338577 Test RE 1.331496952543274\n",
      "27 Train Loss 38.736217 Test MSE 7.769969065504378 Test RE 1.332348094541323\n",
      "28 Train Loss 38.62401 Test MSE 7.860696610417499 Test RE 1.3401042287174083\n",
      "29 Train Loss 38.514145 Test MSE 7.787970687372303 Test RE 1.3338906071665406\n",
      "30 Train Loss 38.426277 Test MSE 7.703571665244025 Test RE 1.326643164986796\n",
      "31 Train Loss 38.32656 Test MSE 7.690625144676568 Test RE 1.3255279267550455\n",
      "32 Train Loss 38.210392 Test MSE 7.78214834957656 Test RE 1.333391901271395\n",
      "33 Train Loss 37.758526 Test MSE 7.739495872201995 Test RE 1.3297328468286624\n",
      "34 Train Loss 36.912003 Test MSE 7.361994906786434 Test RE 1.2968979883442444\n",
      "35 Train Loss 34.401123 Test MSE 6.989186977887149 Test RE 1.2636342533402263\n",
      "36 Train Loss 32.62232 Test MSE 7.115187592605002 Test RE 1.2749737334198405\n",
      "37 Train Loss 32.53946 Test MSE 7.143215904557314 Test RE 1.2774824682789436\n",
      "38 Train Loss 32.42807 Test MSE 7.085799804285801 Test RE 1.2723380033766158\n",
      "39 Train Loss 32.360397 Test MSE 7.078725633611929 Test RE 1.2717027198481095\n",
      "40 Train Loss 32.301006 Test MSE 7.172470228606457 Test RE 1.2800956960983223\n",
      "41 Train Loss 32.224472 Test MSE 7.109546911575908 Test RE 1.2744682551059736\n",
      "42 Train Loss 32.093586 Test MSE 7.134808520849461 Test RE 1.2767304647306599\n",
      "43 Train Loss 32.011375 Test MSE 7.1063067441519285 Test RE 1.2741778033244264\n",
      "44 Train Loss 31.944977 Test MSE 7.097585824594222 Test RE 1.2733957224345653\n",
      "45 Train Loss 31.830769 Test MSE 7.193174048003871 Test RE 1.281941906067303\n",
      "46 Train Loss 31.75084 Test MSE 7.224052139717324 Test RE 1.2846904514248683\n",
      "47 Train Loss 31.649893 Test MSE 7.215625819435138 Test RE 1.2839409848137526\n",
      "48 Train Loss 31.579313 Test MSE 7.149392702963102 Test RE 1.2780346738062793\n",
      "49 Train Loss 31.44641 Test MSE 7.229919620659188 Test RE 1.2852120677295338\n",
      "50 Train Loss 31.356888 Test MSE 7.266285858031977 Test RE 1.2884402987403751\n",
      "51 Train Loss 31.146072 Test MSE 7.263471209240986 Test RE 1.2881907311995102\n",
      "52 Train Loss 30.973171 Test MSE 7.397510710390477 Test RE 1.3000224781872374\n",
      "53 Train Loss 30.726141 Test MSE 7.293616469597689 Test RE 1.2908611236125633\n",
      "54 Train Loss 30.565952 Test MSE 7.313354734393472 Test RE 1.2926066324256547\n",
      "55 Train Loss 29.752075 Test MSE 7.016581973112168 Test RE 1.266108317855575\n",
      "56 Train Loss 28.912066 Test MSE 6.996881231572978 Test RE 1.2643296166297706\n",
      "57 Train Loss 28.507969 Test MSE 6.9820830860001735 Test RE 1.26299190371358\n",
      "58 Train Loss 27.980307 Test MSE 7.136891741337306 Test RE 1.276916840926785\n",
      "59 Train Loss 27.534107 Test MSE 7.177042827494892 Test RE 1.2805036748948493\n",
      "60 Train Loss 27.096409 Test MSE 7.107672493734672 Test RE 1.274300238526141\n",
      "61 Train Loss 26.448103 Test MSE 6.996958440073367 Test RE 1.264336592360898\n",
      "62 Train Loss 25.438519 Test MSE 6.796371606243457 Test RE 1.2460819889106307\n",
      "63 Train Loss 24.940737 Test MSE 6.80116382927451 Test RE 1.2465212269977868\n",
      "64 Train Loss 24.293419 Test MSE 6.931403622821535 Test RE 1.2583998411123691\n",
      "65 Train Loss 23.427097 Test MSE 6.665910052944079 Test RE 1.2340642886029043\n",
      "66 Train Loss 22.087036 Test MSE 6.4426183915885895 Test RE 1.2132191709536804\n",
      "67 Train Loss 21.59087 Test MSE 6.2520223328609745 Test RE 1.1951387303637013\n",
      "68 Train Loss 20.901543 Test MSE 5.929543989512174 Test RE 1.1639081464855545\n",
      "69 Train Loss 20.50944 Test MSE 5.697015979596175 Test RE 1.1408584911053634\n",
      "70 Train Loss 20.061771 Test MSE 5.849114112154918 Test RE 1.1559874186202843\n",
      "71 Train Loss 19.756918 Test MSE 6.0171011756285635 Test RE 1.1724699408355996\n",
      "72 Train Loss 18.99953 Test MSE 6.036674179158257 Test RE 1.1743753538769375\n",
      "73 Train Loss 18.486757 Test MSE 5.790002637994679 Test RE 1.1501313488733602\n",
      "74 Train Loss 17.913435 Test MSE 4.836831279132181 Test RE 1.05120769048336\n",
      "75 Train Loss 16.74194 Test MSE 4.730158683956321 Test RE 1.039551275146014\n",
      "76 Train Loss 16.067677 Test MSE 4.349087293618945 Test RE 0.9967979190610576\n",
      "77 Train Loss 15.430655 Test MSE 4.012055077510469 Test RE 0.957395768099391\n",
      "78 Train Loss 14.121879 Test MSE 3.371455090361329 Test RE 0.8776406891580331\n",
      "79 Train Loss 12.958351 Test MSE 3.339994497284678 Test RE 0.8735362578227289\n",
      "80 Train Loss 12.3549 Test MSE 3.132517474422014 Test RE 0.8459697062482421\n",
      "81 Train Loss 10.84457 Test MSE 2.480151218490008 Test RE 0.7527437198661818\n",
      "82 Train Loss 9.036889 Test MSE 2.6121549383471265 Test RE 0.7725160779412263\n",
      "83 Train Loss 6.667354 Test MSE 2.7386938599764927 Test RE 0.7910060484312897\n",
      "84 Train Loss 5.761978 Test MSE 2.5358865616082413 Test RE 0.7611547665772705\n",
      "85 Train Loss 5.1219435 Test MSE 2.3627470808589988 Test RE 0.7347112297739136\n",
      "86 Train Loss 4.5896273 Test MSE 2.540679996854313 Test RE 0.7618738096944472\n",
      "87 Train Loss 3.7500036 Test MSE 2.4208606223664138 Test RE 0.7436917322968043\n",
      "88 Train Loss 3.549058 Test MSE 2.2866768019553496 Test RE 0.7227872005042626\n",
      "89 Train Loss 3.3491824 Test MSE 2.3207347608502205 Test RE 0.7281499330973376\n",
      "90 Train Loss 3.2221482 Test MSE 2.2627746765095655 Test RE 0.7189997099049619\n",
      "91 Train Loss 3.1036687 Test MSE 2.0903888960278083 Test RE 0.6910693076945779\n",
      "92 Train Loss 3.0185068 Test MSE 2.084332833867489 Test RE 0.6900675337434939\n",
      "93 Train Loss 2.892605 Test MSE 2.199449611588567 Test RE 0.7088675055091112\n",
      "94 Train Loss 2.7589035 Test MSE 2.1502356613960782 Test RE 0.7008919797762821\n",
      "95 Train Loss 2.633193 Test MSE 2.1150278083614924 Test RE 0.6951301108746889\n",
      "96 Train Loss 2.527158 Test MSE 2.165834802570558 Test RE 0.7034297377260438\n",
      "97 Train Loss 2.4709475 Test MSE 2.144832373599442 Test RE 0.7000107965437015\n",
      "98 Train Loss 2.2434244 Test MSE 1.9703305683376076 Test RE 0.6709306125296927\n",
      "99 Train Loss 2.1707196 Test MSE 1.9835213218416583 Test RE 0.6731727026915334\n",
      "Training time: 71.95\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.46782 Test MSE 8.73240995485793 Test RE 1.412456619545621\n",
      "1 Train Loss 55.862816 Test MSE 7.875427378807348 Test RE 1.341359303566859\n",
      "2 Train Loss 48.623646 Test MSE 7.505296107380828 Test RE 1.3094592138933734\n",
      "3 Train Loss 41.415504 Test MSE 7.580157749736677 Test RE 1.3159736159611295\n",
      "4 Train Loss 37.69026 Test MSE 7.6900463972238535 Test RE 1.3254780504231578\n",
      "5 Train Loss 34.92955 Test MSE 7.455095048578208 Test RE 1.3050725427640082\n",
      "6 Train Loss 31.797497 Test MSE 6.3918660128858935 Test RE 1.208431094240106\n",
      "7 Train Loss 29.443087 Test MSE 6.717763774376838 Test RE 1.2388548469673162\n",
      "8 Train Loss 28.246986 Test MSE 6.70005456061088 Test RE 1.237220849107025\n",
      "9 Train Loss 27.496063 Test MSE 6.703091298206302 Test RE 1.2375011967825102\n",
      "10 Train Loss 26.293053 Test MSE 6.363233483012094 Test RE 1.2057214571201158\n",
      "11 Train Loss 25.216595 Test MSE 6.027877098566369 Test RE 1.173519349322964\n",
      "12 Train Loss 24.292786 Test MSE 5.9956191684273 Test RE 1.1703751174646464\n",
      "13 Train Loss 23.454311 Test MSE 5.580514736729156 Test RE 1.1291332331696187\n",
      "14 Train Loss 22.813702 Test MSE 5.363854068031333 Test RE 1.1069972375501402\n",
      "15 Train Loss 22.235006 Test MSE 5.512830348272059 Test RE 1.1222648845419412\n",
      "16 Train Loss 21.82454 Test MSE 5.301701992348893 Test RE 1.1005650486266911\n",
      "17 Train Loss 21.28778 Test MSE 5.2011592814234255 Test RE 1.0900794117500507\n",
      "18 Train Loss 20.841541 Test MSE 4.848659543916053 Test RE 1.0524922474368448\n",
      "19 Train Loss 18.975597 Test MSE 4.419151337547856 Test RE 1.0047950747051133\n",
      "20 Train Loss 17.94246 Test MSE 3.969052039502725 Test RE 0.9522510426113339\n",
      "21 Train Loss 15.920866 Test MSE 3.795128010397741 Test RE 0.9311534890955172\n",
      "22 Train Loss 14.324405 Test MSE 3.6525036758829073 Test RE 0.9134891452657282\n",
      "23 Train Loss 13.192381 Test MSE 3.4125841059815243 Test RE 0.8829777136867842\n",
      "24 Train Loss 12.209274 Test MSE 3.297976843023911 Test RE 0.868024255977215\n",
      "25 Train Loss 11.822827 Test MSE 3.1952296190251324 Test RE 0.8543957845593506\n",
      "26 Train Loss 11.284494 Test MSE 3.5560807977352757 Test RE 0.9013508451587565\n",
      "27 Train Loss 11.050991 Test MSE 3.5989221578067347 Test RE 0.9067640361425019\n",
      "28 Train Loss 10.7316475 Test MSE 3.7750938890567727 Test RE 0.9286925014267111\n",
      "29 Train Loss 10.573643 Test MSE 3.7124547558588374 Test RE 0.9209554982936099\n",
      "30 Train Loss 10.316641 Test MSE 3.7123367773139906 Test RE 0.9209408645997416\n",
      "31 Train Loss 10.151468 Test MSE 3.8052429999331987 Test RE 0.9323935448156778\n",
      "32 Train Loss 9.861463 Test MSE 3.8947601907488085 Test RE 0.9432969309438047\n",
      "33 Train Loss 9.57012 Test MSE 3.8859179297115207 Test RE 0.9422255405707729\n",
      "34 Train Loss 9.114212 Test MSE 4.039450215902153 Test RE 0.9606588550631752\n",
      "35 Train Loss 8.509748 Test MSE 3.7131538966231696 Test RE 0.9210422127806467\n",
      "36 Train Loss 7.346179 Test MSE 3.128051129437699 Test RE 0.8453663991071418\n",
      "37 Train Loss 6.4320946 Test MSE 2.921661653978211 Test RE 0.8170018135725606\n",
      "38 Train Loss 5.830676 Test MSE 2.332733114203043 Test RE 0.7300297983093765\n",
      "39 Train Loss 5.3932514 Test MSE 2.253221257486205 Test RE 0.7174802985731273\n",
      "40 Train Loss 4.994571 Test MSE 2.104698735124535 Test RE 0.6934306444433734\n",
      "41 Train Loss 4.7734756 Test MSE 2.024014548084608 Test RE 0.6800093358331629\n",
      "42 Train Loss 4.5933504 Test MSE 1.9094957307938416 Test RE 0.6604917633788567\n",
      "43 Train Loss 4.4137554 Test MSE 1.8518174851007643 Test RE 0.650439864249091\n",
      "44 Train Loss 4.3033323 Test MSE 1.8419779649130883 Test RE 0.6487095262398476\n",
      "45 Train Loss 4.1913652 Test MSE 1.8331191074248439 Test RE 0.6471476857202657\n",
      "46 Train Loss 4.1502914 Test MSE 1.813980452544113 Test RE 0.6437605534311437\n",
      "47 Train Loss 4.1123514 Test MSE 1.7892122412599625 Test RE 0.6393504728268968\n",
      "48 Train Loss 4.0367184 Test MSE 1.783086736391449 Test RE 0.6382551018949562\n",
      "49 Train Loss 3.9724133 Test MSE 1.7546720898753465 Test RE 0.633149173609281\n",
      "50 Train Loss 3.9315546 Test MSE 1.750719070645272 Test RE 0.6324355752958322\n",
      "51 Train Loss 3.8400683 Test MSE 1.7593970298937713 Test RE 0.634001065159292\n",
      "52 Train Loss 3.129787 Test MSE 1.3404040549149618 Test RE 0.5533831444176898\n",
      "53 Train Loss 2.1104872 Test MSE 0.6776536444082903 Test RE 0.39347029365325925\n",
      "54 Train Loss 1.5855024 Test MSE 0.4425189267447994 Test RE 0.31796109612803136\n",
      "55 Train Loss 1.101294 Test MSE 0.21324036605904814 Test RE 0.2207205501565574\n",
      "56 Train Loss 0.80530244 Test MSE 0.06905973222649878 Test RE 0.12560892688485178\n",
      "57 Train Loss 0.6462458 Test MSE 0.054065925801176924 Test RE 0.11113986945035464\n",
      "58 Train Loss 0.44547224 Test MSE 0.04842579307601632 Test RE 0.10518321259122765\n",
      "59 Train Loss 0.37758029 Test MSE 0.054308523271027254 Test RE 0.11138893642769991\n",
      "60 Train Loss 0.34541142 Test MSE 0.04127006415116218 Test RE 0.097101431454335\n",
      "61 Train Loss 0.32682455 Test MSE 0.03814410201309628 Test RE 0.09335159826830405\n",
      "62 Train Loss 0.29321447 Test MSE 0.028781721216595727 Test RE 0.08108983960695007\n",
      "63 Train Loss 0.2724392 Test MSE 0.027026837530091958 Test RE 0.07857885128589599\n",
      "64 Train Loss 0.25773728 Test MSE 0.025745890141896755 Test RE 0.07669411073221162\n",
      "65 Train Loss 0.23156978 Test MSE 0.028183612620794187 Test RE 0.08024285841241811\n",
      "66 Train Loss 0.21833305 Test MSE 0.027726813181719344 Test RE 0.07958991454332409\n",
      "67 Train Loss 0.19760928 Test MSE 0.02643707424081201 Test RE 0.07771677234011928\n",
      "68 Train Loss 0.1876725 Test MSE 0.02650825230722053 Test RE 0.07782132269972422\n",
      "69 Train Loss 0.17060342 Test MSE 0.02317299128156538 Test RE 0.07276107542321818\n",
      "70 Train Loss 0.16067155 Test MSE 0.022864485422447876 Test RE 0.07227511247207345\n",
      "71 Train Loss 0.15024781 Test MSE 0.021811017893850572 Test RE 0.07059046249285726\n",
      "72 Train Loss 0.13520621 Test MSE 0.024810861503779598 Test RE 0.07528855857715107\n",
      "73 Train Loss 0.114377484 Test MSE 0.021456848232431443 Test RE 0.07001498900883098\n",
      "74 Train Loss 0.10380778 Test MSE 0.019231729397441277 Test RE 0.06628530059102387\n",
      "75 Train Loss 0.09841964 Test MSE 0.0172654156093889 Test RE 0.0628053411248234\n",
      "76 Train Loss 0.07847807 Test MSE 0.015514485544444354 Test RE 0.05953560205866611\n",
      "77 Train Loss 0.070280515 Test MSE 0.014801220534971378 Test RE 0.05815095146778955\n",
      "78 Train Loss 0.06634482 Test MSE 0.013901933065344945 Test RE 0.0563567132417914\n",
      "79 Train Loss 0.05622976 Test MSE 0.015845362894459977 Test RE 0.060167110510572636\n",
      "80 Train Loss 0.049344026 Test MSE 0.014562151861176072 Test RE 0.05767941382629772\n",
      "81 Train Loss 0.04655209 Test MSE 0.01587613635698206 Test RE 0.060225507791381666\n",
      "82 Train Loss 0.042724516 Test MSE 0.015335772890616104 Test RE 0.059191711078497224\n",
      "83 Train Loss 0.038690668 Test MSE 0.01501358532315731 Test RE 0.05856663453375177\n",
      "84 Train Loss 0.03634425 Test MSE 0.014772426722181861 Test RE 0.05809436144793357\n",
      "85 Train Loss 0.033895094 Test MSE 0.015823448518446324 Test RE 0.06012549010425649\n",
      "86 Train Loss 0.03175602 Test MSE 0.01486144228964475 Test RE 0.05826913082513298\n",
      "87 Train Loss 0.029025637 Test MSE 0.01283528752608909 Test RE 0.05415154614572814\n",
      "88 Train Loss 0.027330866 Test MSE 0.011762466071059234 Test RE 0.051839076028475914\n",
      "89 Train Loss 0.023615908 Test MSE 0.010729796571292046 Test RE 0.04951124012115356\n",
      "90 Train Loss 0.022756696 Test MSE 0.010878008759819948 Test RE 0.04985202020664015\n",
      "91 Train Loss 0.021823045 Test MSE 0.00905692692557859 Test RE 0.04548817279960173\n",
      "92 Train Loss 0.019843874 Test MSE 0.007754473368040945 Test RE 0.042090512582994094\n",
      "93 Train Loss 0.019454442 Test MSE 0.0077119097981400335 Test RE 0.04197483821455086\n",
      "94 Train Loss 0.01906644 Test MSE 0.00748368991587767 Test RE 0.041349089648182305\n",
      "95 Train Loss 0.018333528 Test MSE 0.006866097554585676 Test RE 0.03960618804453455\n",
      "96 Train Loss 0.017535767 Test MSE 0.006374702161094685 Test RE 0.03816260476225685\n",
      "97 Train Loss 0.016904166 Test MSE 0.006123460664334244 Test RE 0.03740300768324388\n",
      "98 Train Loss 0.016169332 Test MSE 0.00603402988348697 Test RE 0.03712887485139413\n",
      "99 Train Loss 0.01505864 Test MSE 0.004667190513680069 Test RE 0.03265395762305483\n",
      "Training time: 72.85\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.471302 Test MSE 8.685143905016245 Test RE 1.4086288199718895\n",
      "1 Train Loss 54.898895 Test MSE 8.83601294928685 Test RE 1.4208107426326833\n",
      "2 Train Loss 49.689117 Test MSE 8.714839981577482 Test RE 1.4110349432334912\n",
      "3 Train Loss 45.202858 Test MSE 8.626498802433009 Test RE 1.4038649895264246\n",
      "4 Train Loss 44.345253 Test MSE 8.622636343414722 Test RE 1.4035506686062433\n",
      "5 Train Loss 43.99311 Test MSE 8.437277532797909 Test RE 1.3883828094159263\n",
      "6 Train Loss 43.261795 Test MSE 8.435373059068203 Test RE 1.3882261067471144\n",
      "7 Train Loss 41.22202 Test MSE 7.786195005348806 Test RE 1.3337385328526372\n",
      "8 Train Loss 40.154358 Test MSE 7.681943308489031 Test RE 1.3247795307697654\n",
      "9 Train Loss 39.707447 Test MSE 7.66694973070655 Test RE 1.3234860503425405\n",
      "10 Train Loss 39.502575 Test MSE 7.93872338649046 Test RE 1.3467388704699184\n",
      "11 Train Loss 39.359173 Test MSE 7.972778653747521 Test RE 1.3496243766883664\n",
      "12 Train Loss 39.23459 Test MSE 7.907204886603568 Test RE 1.3440627850397022\n",
      "13 Train Loss 39.03311 Test MSE 7.819454381522057 Test RE 1.336584084584811\n",
      "14 Train Loss 38.44874 Test MSE 7.823483975569979 Test RE 1.3369284307060911\n",
      "15 Train Loss 36.720337 Test MSE 7.578655141244877 Test RE 1.3158431773080312\n",
      "16 Train Loss 35.295017 Test MSE 7.307987257624119 Test RE 1.292132205176068\n",
      "17 Train Loss 34.222107 Test MSE 7.167129985376548 Test RE 1.2796190614755079\n",
      "18 Train Loss 33.674984 Test MSE 7.099245269675217 Test RE 1.2735445763420596\n",
      "19 Train Loss 33.30379 Test MSE 7.138746405859482 Test RE 1.277082746380376\n",
      "20 Train Loss 32.674828 Test MSE 7.0213658207510194 Test RE 1.2665398554105438\n",
      "21 Train Loss 32.072075 Test MSE 7.026101844311876 Test RE 1.2669669341009442\n",
      "22 Train Loss 31.314651 Test MSE 6.803125659948666 Test RE 1.246700996763248\n",
      "23 Train Loss 30.396774 Test MSE 6.966741737197247 Test RE 1.261603589205135\n",
      "24 Train Loss 29.364395 Test MSE 7.01783553268775 Test RE 1.2662214121890825\n",
      "25 Train Loss 28.032116 Test MSE 6.885031209125785 Test RE 1.2541833093208061\n",
      "26 Train Loss 26.540922 Test MSE 6.856746554363692 Test RE 1.251604479318019\n",
      "27 Train Loss 25.419434 Test MSE 6.80997512077144 Test RE 1.247328434928864\n",
      "28 Train Loss 23.876835 Test MSE 6.790980180314358 Test RE 1.2455876448688294\n",
      "29 Train Loss 22.723495 Test MSE 6.494692989940656 Test RE 1.218112426030975\n",
      "30 Train Loss 21.491396 Test MSE 6.593766050431495 Test RE 1.2273680881673406\n",
      "31 Train Loss 20.428013 Test MSE 6.533524002119426 Test RE 1.221748475340204\n",
      "32 Train Loss 18.470871 Test MSE 6.331784594719881 Test RE 1.2027382594466192\n",
      "33 Train Loss 16.753885 Test MSE 5.2803227684649725 Test RE 1.0983437812790273\n",
      "34 Train Loss 12.374982 Test MSE 3.8883081073548413 Test RE 0.9425152713707996\n",
      "35 Train Loss 10.506606 Test MSE 3.999456621869269 Test RE 0.9558914029209185\n",
      "36 Train Loss 9.736569 Test MSE 3.9359962320217936 Test RE 0.9482773934589372\n",
      "37 Train Loss 8.831917 Test MSE 3.7939555214890763 Test RE 0.9310096399984003\n",
      "38 Train Loss 8.153591 Test MSE 3.9014232685439385 Test RE 0.9441034728936888\n",
      "39 Train Loss 7.310911 Test MSE 3.8569841199361545 Test RE 0.9387111699497251\n",
      "40 Train Loss 6.9483824 Test MSE 3.8108173923448327 Test RE 0.9330762377998087\n",
      "41 Train Loss 6.592113 Test MSE 3.764333839867958 Test RE 0.9273680432817419\n",
      "42 Train Loss 6.232708 Test MSE 3.654657253732907 Test RE 0.9137584098942626\n",
      "43 Train Loss 6.0772 Test MSE 3.6365514190116888 Test RE 0.9114921371019695\n",
      "44 Train Loss 5.9306693 Test MSE 3.7457416643267254 Test RE 0.9250750570093894\n",
      "45 Train Loss 5.8462462 Test MSE 3.674376440195555 Test RE 0.916220245734239\n",
      "46 Train Loss 5.686871 Test MSE 3.5660071419334654 Test RE 0.9026079712275809\n",
      "47 Train Loss 5.58468 Test MSE 3.532645000406958 Test RE 0.8983758291939392\n",
      "48 Train Loss 5.475218 Test MSE 3.4956026939622284 Test RE 0.8936533607857866\n",
      "49 Train Loss 5.376254 Test MSE 3.4835900915632227 Test RE 0.8921165240662696\n",
      "50 Train Loss 5.2559767 Test MSE 3.2983819359003714 Test RE 0.8680775643632854\n",
      "51 Train Loss 5.13515 Test MSE 3.2250712812407087 Test RE 0.8583763022110197\n",
      "52 Train Loss 4.875267 Test MSE 3.018279763714998 Test RE 0.8304008905646106\n",
      "53 Train Loss 4.5136533 Test MSE 2.5517903286555876 Test RE 0.7635378203245772\n",
      "54 Train Loss 4.3110557 Test MSE 2.3082021214586415 Test RE 0.7261811613223548\n",
      "55 Train Loss 3.9972243 Test MSE 1.6486793479896886 Test RE 0.6137283133263505\n",
      "56 Train Loss 3.085206 Test MSE 1.2208663896037728 Test RE 0.5281315702302628\n",
      "57 Train Loss 2.6009803 Test MSE 0.9364175620094619 Test RE 0.4625331191147574\n",
      "58 Train Loss 2.1766498 Test MSE 0.8542884996705002 Test RE 0.44178436336439597\n",
      "59 Train Loss 1.8560243 Test MSE 0.7362891586377669 Test RE 0.41014012854102455\n",
      "60 Train Loss 1.5383798 Test MSE 0.5968598103414416 Test RE 0.36927017189563516\n",
      "61 Train Loss 1.2513764 Test MSE 0.6774451638379224 Test RE 0.3934097633055612\n",
      "62 Train Loss 1.0938051 Test MSE 0.598204071796387 Test RE 0.36968577742460984\n",
      "63 Train Loss 0.9985711 Test MSE 0.5387972761263423 Test RE 0.3508494144311936\n",
      "64 Train Loss 0.9042668 Test MSE 0.5263546423540106 Test RE 0.3467746077237202\n",
      "65 Train Loss 0.8425611 Test MSE 0.47149807395575216 Test RE 0.3282071377938619\n",
      "66 Train Loss 0.80069965 Test MSE 0.45327787095893607 Test RE 0.3218031707596451\n",
      "67 Train Loss 0.75718606 Test MSE 0.41778804879228615 Test RE 0.3089484825835949\n",
      "68 Train Loss 0.69247454 Test MSE 0.3789299644243523 Test RE 0.29423039501148385\n",
      "69 Train Loss 0.6296801 Test MSE 0.3656594677665786 Test RE 0.28903236178435426\n",
      "70 Train Loss 0.5966398 Test MSE 0.3256160546496225 Test RE 0.2727476172244972\n",
      "71 Train Loss 0.56288755 Test MSE 0.25807749012545506 Test RE 0.2428192556645842\n",
      "72 Train Loss 0.53961325 Test MSE 0.2724938879810232 Test RE 0.2495091306639115\n",
      "73 Train Loss 0.49868122 Test MSE 0.2504338528538364 Test RE 0.23919636626295054\n",
      "74 Train Loss 0.46690285 Test MSE 0.22516120727041514 Test RE 0.22680615940712862\n",
      "75 Train Loss 0.42697152 Test MSE 0.19920725851598908 Test RE 0.21333427667013768\n",
      "76 Train Loss 0.40807647 Test MSE 0.17492660251036177 Test RE 0.19991067744588512\n",
      "77 Train Loss 0.39143938 Test MSE 0.1508194327601555 Test RE 0.18562510477876795\n",
      "78 Train Loss 0.36899927 Test MSE 0.1424136686552953 Test RE 0.18037813713141482\n",
      "79 Train Loss 0.35417345 Test MSE 0.1609526802506385 Test RE 0.19175962284290332\n",
      "80 Train Loss 0.33870697 Test MSE 0.14978970022064061 Test RE 0.18499033381802968\n",
      "81 Train Loss 0.32649896 Test MSE 0.15618902771120538 Test RE 0.18890059287405628\n",
      "82 Train Loss 0.3055417 Test MSE 0.14621907701417827 Test RE 0.18277217473082846\n",
      "83 Train Loss 0.29767585 Test MSE 0.13347321953555077 Test RE 0.17462448102810296\n",
      "84 Train Loss 0.2864648 Test MSE 0.1314479706113697 Test RE 0.1732945892637409\n",
      "85 Train Loss 0.27765572 Test MSE 0.12420298320530854 Test RE 0.16845118632900993\n",
      "86 Train Loss 0.2669508 Test MSE 0.11603777451521805 Test RE 0.1628200019938602\n",
      "87 Train Loss 0.25988692 Test MSE 0.11367532179268548 Test RE 0.16115402479661828\n",
      "88 Train Loss 0.25518638 Test MSE 0.11076195437614664 Test RE 0.159075525057145\n",
      "89 Train Loss 0.2484665 Test MSE 0.10235575367780225 Test RE 0.15291996520259782\n",
      "90 Train Loss 0.24373077 Test MSE 0.09623204898344437 Test RE 0.14827499796644128\n",
      "91 Train Loss 0.23583841 Test MSE 0.09750244327235343 Test RE 0.14925050511227994\n",
      "92 Train Loss 0.22992171 Test MSE 0.09378585727644984 Test RE 0.14637831263683204\n",
      "93 Train Loss 0.22312762 Test MSE 0.0881337979281378 Test RE 0.14189898958883368\n",
      "94 Train Loss 0.21668853 Test MSE 0.08254900083580359 Test RE 0.137329541715258\n",
      "95 Train Loss 0.21202326 Test MSE 0.08218739140059213 Test RE 0.13702842261616485\n",
      "96 Train Loss 0.20771825 Test MSE 0.08418310762638134 Test RE 0.13868214080492544\n",
      "97 Train Loss 0.202898 Test MSE 0.0819043305506205 Test RE 0.13679224991639366\n",
      "98 Train Loss 0.19544627 Test MSE 0.08358294941530636 Test RE 0.13818691021740445\n",
      "99 Train Loss 0.18994297 Test MSE 0.08509152156426893 Test RE 0.13942838760067702\n",
      "Training time: 72.38\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.130714 Test MSE 8.18145977137374 Test RE 1.3671729587912316\n",
      "1 Train Loss 52.576897 Test MSE 8.482389116046685 Test RE 1.3920894938707562\n",
      "2 Train Loss 47.93762 Test MSE 8.13809388194558 Test RE 1.3635447893116102\n",
      "3 Train Loss 43.145256 Test MSE 8.161945302360142 Test RE 1.3655414906175958\n",
      "4 Train Loss 42.54618 Test MSE 8.235604850184417 Test RE 1.3716894886874489\n",
      "5 Train Loss 42.25666 Test MSE 8.34987093908705 Test RE 1.381172560394333\n",
      "6 Train Loss 41.89489 Test MSE 8.367546022331739 Test RE 1.382633626963361\n",
      "7 Train Loss 40.85841 Test MSE 8.275490238768144 Test RE 1.3750070523649367\n",
      "8 Train Loss 36.3014 Test MSE 6.422938742300212 Test RE 1.21136480158343\n",
      "9 Train Loss 31.852818 Test MSE 6.71595644030266 Test RE 1.2386881862101762\n",
      "10 Train Loss 29.809135 Test MSE 6.706284040171586 Test RE 1.237795878106588\n",
      "11 Train Loss 29.284105 Test MSE 6.776038613917994 Test RE 1.244216614596763\n",
      "12 Train Loss 27.353043 Test MSE 6.396961454612603 Test RE 1.2089126643752721\n",
      "13 Train Loss 26.532654 Test MSE 6.398570714224134 Test RE 1.2090647156265713\n",
      "14 Train Loss 25.35841 Test MSE 6.246656055575692 Test RE 1.1946257105535696\n",
      "15 Train Loss 24.401361 Test MSE 6.383125121887488 Test RE 1.2076045454611766\n",
      "16 Train Loss 24.082962 Test MSE 6.227048087234833 Test RE 1.1927492991047652\n",
      "17 Train Loss 23.590849 Test MSE 6.128742061961012 Test RE 1.1832969147175891\n",
      "18 Train Loss 23.159088 Test MSE 5.9308778038680225 Test RE 1.1640390461048535\n",
      "19 Train Loss 22.937752 Test MSE 6.037371849543209 Test RE 1.1744432143585088\n",
      "20 Train Loss 22.512894 Test MSE 6.022237471344281 Test RE 1.172970253823078\n",
      "21 Train Loss 22.415562 Test MSE 5.936513789289632 Test RE 1.1645919953877328\n",
      "22 Train Loss 22.232822 Test MSE 5.848855169141698 Test RE 1.1559618302856507\n",
      "23 Train Loss 22.139683 Test MSE 5.818881893852784 Test RE 1.1529960818745755\n",
      "24 Train Loss 22.051773 Test MSE 5.776125322917673 Test RE 1.1487522208189562\n",
      "25 Train Loss 21.850925 Test MSE 5.698310243058822 Test RE 1.140988075401162\n",
      "26 Train Loss 21.585152 Test MSE 5.741842107354498 Test RE 1.1453380348771902\n",
      "27 Train Loss 21.374477 Test MSE 5.752784089940699 Test RE 1.1464288262755684\n",
      "28 Train Loss 21.116268 Test MSE 5.5500262789032195 Test RE 1.1260445682895621\n",
      "29 Train Loss 20.558853 Test MSE 5.4273844133104046 Test RE 1.113533666043951\n",
      "30 Train Loss 19.356424 Test MSE 6.252780490773619 Test RE 1.1952111930300717\n",
      "31 Train Loss 18.284082 Test MSE 6.221562425872845 Test RE 1.192223812526596\n",
      "32 Train Loss 16.242023 Test MSE 5.856289368588211 Test RE 1.1566962408275556\n",
      "33 Train Loss 15.49515 Test MSE 6.230246211203812 Test RE 1.1930555493872979\n",
      "34 Train Loss 14.163589 Test MSE 6.252144642737 Test RE 1.1951504207054213\n",
      "35 Train Loss 13.828989 Test MSE 6.191973912821488 Test RE 1.1893854442025682\n",
      "36 Train Loss 13.395088 Test MSE 6.262064211943471 Test RE 1.196098149790268\n",
      "37 Train Loss 13.014433 Test MSE 6.144683789635946 Test RE 1.184834876835853\n",
      "38 Train Loss 12.691998 Test MSE 6.135120445065062 Test RE 1.1839125025702497\n",
      "39 Train Loss 12.483373 Test MSE 6.092675597256857 Test RE 1.1798100402189629\n",
      "40 Train Loss 12.336695 Test MSE 6.050195532777375 Test RE 1.1756898411357803\n",
      "41 Train Loss 12.100863 Test MSE 6.069481953351541 Test RE 1.1775622440201126\n",
      "42 Train Loss 11.953718 Test MSE 6.028154120251639 Test RE 1.1735463145851608\n",
      "43 Train Loss 11.866324 Test MSE 6.044573717843777 Test RE 1.175143491289223\n",
      "44 Train Loss 11.60677 Test MSE 5.986590661853033 Test RE 1.1694935804518667\n",
      "45 Train Loss 11.455933 Test MSE 5.8534005385248955 Test RE 1.1564109141603387\n",
      "46 Train Loss 11.269385 Test MSE 5.931953962827594 Test RE 1.1641446488731175\n",
      "47 Train Loss 11.1141615 Test MSE 5.806621508244039 Test RE 1.151780759849313\n",
      "48 Train Loss 10.543558 Test MSE 6.012565441006521 Test RE 1.172027949342044\n",
      "49 Train Loss 9.954668 Test MSE 5.748579722509957 Test RE 1.146009821413776\n",
      "50 Train Loss 9.709301 Test MSE 5.710658678506517 Test RE 1.1422236866780633\n",
      "51 Train Loss 9.197604 Test MSE 5.520288284150447 Test RE 1.1230237461615316\n",
      "52 Train Loss 8.9994955 Test MSE 5.497730637955189 Test RE 1.1207268819876575\n",
      "53 Train Loss 8.621823 Test MSE 5.457369737456993 Test RE 1.116605465861705\n",
      "54 Train Loss 8.267095 Test MSE 5.468259004720175 Test RE 1.117718910309665\n",
      "55 Train Loss 7.9831495 Test MSE 5.5781415395257445 Test RE 1.128893117256556\n",
      "56 Train Loss 7.6539326 Test MSE 5.479499746415272 Test RE 1.118867131291244\n",
      "57 Train Loss 7.3559484 Test MSE 5.1417947822245 Test RE 1.0838406362017194\n",
      "58 Train Loss 7.0941772 Test MSE 5.088227840319429 Test RE 1.07818015819386\n",
      "59 Train Loss 6.8179216 Test MSE 5.004160176825081 Test RE 1.0692362190238087\n",
      "60 Train Loss 6.5762157 Test MSE 4.8191427871528685 Test RE 1.049283774918049\n",
      "61 Train Loss 6.4140067 Test MSE 4.91628582650963 Test RE 1.0598066064331773\n",
      "62 Train Loss 6.2858863 Test MSE 4.782715223365226 Test RE 1.0453105208984936\n",
      "63 Train Loss 6.150888 Test MSE 4.761356477324602 Test RE 1.0429738247668903\n",
      "64 Train Loss 6.038149 Test MSE 4.524027721644958 Test RE 1.0166481835039558\n",
      "65 Train Loss 5.9688134 Test MSE 4.2022022214820876 Test RE 0.9798205285964285\n",
      "66 Train Loss 5.8476963 Test MSE 3.8473474525914466 Test RE 0.9375377525271004\n",
      "67 Train Loss 5.732766 Test MSE 3.8262683918924 Test RE 0.9349659080681167\n",
      "68 Train Loss 5.5727506 Test MSE 3.508172729973239 Test RE 0.8952586883144972\n",
      "69 Train Loss 5.424111 Test MSE 3.1607362622736246 Test RE 0.8497715554543046\n",
      "70 Train Loss 5.2997465 Test MSE 2.939597046022204 Test RE 0.8195056675626299\n",
      "71 Train Loss 5.181525 Test MSE 2.7831079869361544 Test RE 0.7973942306490582\n",
      "72 Train Loss 5.0720825 Test MSE 2.814831932394118 Test RE 0.8019260008980384\n",
      "73 Train Loss 4.9668145 Test MSE 2.734612702568975 Test RE 0.7904164564731517\n",
      "74 Train Loss 4.8664646 Test MSE 2.613644147630595 Test RE 0.772736255193419\n",
      "75 Train Loss 4.741411 Test MSE 2.497332822506974 Test RE 0.755346589859999\n",
      "76 Train Loss 4.619502 Test MSE 2.3805683259223223 Test RE 0.7374768393420532\n",
      "77 Train Loss 4.5569315 Test MSE 2.3737329926066297 Test RE 0.7364173184606708\n",
      "78 Train Loss 4.46634 Test MSE 2.35829190269603 Test RE 0.7340182199458543\n",
      "79 Train Loss 4.389477 Test MSE 2.279922706857084 Test RE 0.7217189726708022\n",
      "80 Train Loss 4.360243 Test MSE 2.2550889096908135 Test RE 0.7177775898613402\n",
      "81 Train Loss 4.298094 Test MSE 2.2479014769307137 Test RE 0.7166328244849114\n",
      "82 Train Loss 4.207609 Test MSE 2.189391791591341 Test RE 0.7072448651910518\n",
      "83 Train Loss 4.1707788 Test MSE 2.1684218147837124 Test RE 0.7038497231812619\n",
      "84 Train Loss 4.1440926 Test MSE 2.1670229114175785 Test RE 0.7036226509871091\n",
      "85 Train Loss 4.1133885 Test MSE 2.1635090015359935 Test RE 0.7030519441232745\n",
      "86 Train Loss 4.061425 Test MSE 2.1612730019810695 Test RE 0.7026885460008079\n",
      "87 Train Loss 4.023678 Test MSE 2.1539500166098247 Test RE 0.7014970851893181\n",
      "88 Train Loss 3.96988 Test MSE 2.159931664838598 Test RE 0.7024704595925022\n",
      "89 Train Loss 3.8895845 Test MSE 2.154675616642964 Test RE 0.7016152317211274\n",
      "90 Train Loss 3.6600986 Test MSE 2.1348224019250535 Test RE 0.6983754046554759\n",
      "91 Train Loss 3.093166 Test MSE 1.9835404565714383 Test RE 0.6731759496812567\n",
      "92 Train Loss 2.4540677 Test MSE 1.6403497267499987 Test RE 0.6121759806187325\n",
      "93 Train Loss 2.104317 Test MSE 1.3525728947961735 Test RE 0.5558894096502572\n",
      "94 Train Loss 1.9550959 Test MSE 1.23596229161197 Test RE 0.5313866882806974\n",
      "95 Train Loss 1.6962519 Test MSE 0.9331783580349589 Test RE 0.4617324415746689\n",
      "96 Train Loss 1.4190772 Test MSE 0.7064654183704455 Test RE 0.4017478064897789\n",
      "97 Train Loss 1.1029556 Test MSE 0.3041563647478873 Test RE 0.26360674270411477\n",
      "98 Train Loss 0.706256 Test MSE 0.17973337816169677 Test RE 0.20263871782715448\n",
      "99 Train Loss 0.47179615 Test MSE 0.13546526772793935 Test RE 0.17592276412536592\n",
      "Training time: 70.91\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.36748 Test MSE 8.647822180175186 Test RE 1.4055989877693078\n",
      "1 Train Loss 55.66156 Test MSE 8.89607487075609 Test RE 1.4256314744329073\n",
      "2 Train Loss 51.569374 Test MSE 9.492548369693434 Test RE 1.4726497556559142\n",
      "3 Train Loss 45.59787 Test MSE 8.84525953304672 Test RE 1.4215539630414613\n",
      "4 Train Loss 44.57077 Test MSE 8.684411789681183 Test RE 1.408569448445887\n",
      "5 Train Loss 44.058323 Test MSE 8.636228756089823 Test RE 1.4046564862896558\n",
      "6 Train Loss 43.40443 Test MSE 8.63732305410218 Test RE 1.4047454756017466\n",
      "7 Train Loss 42.8515 Test MSE 8.495677408286648 Test RE 1.3931794729214542\n",
      "8 Train Loss 42.695827 Test MSE 8.423605456410755 Test RE 1.3872574599295424\n",
      "9 Train Loss 42.279705 Test MSE 8.090013629526828 Test RE 1.35951087805416\n",
      "10 Train Loss 41.70759 Test MSE 8.392284847068163 Test RE 1.3846760111005063\n",
      "11 Train Loss 41.293488 Test MSE 8.464710555587091 Test RE 1.39063807646214\n",
      "12 Train Loss 40.92207 Test MSE 8.549870972120354 Test RE 1.397615925401337\n",
      "13 Train Loss 40.520332 Test MSE 8.756649663763373 Test RE 1.4144156326345902\n",
      "14 Train Loss 40.310074 Test MSE 8.692064362352077 Test RE 1.4091899168644844\n",
      "15 Train Loss 40.094494 Test MSE 8.740325353849057 Test RE 1.4130966275945642\n",
      "16 Train Loss 36.542545 Test MSE 9.210634398480236 Test RE 1.4506172323731688\n",
      "17 Train Loss 34.40505 Test MSE 9.036357207560194 Test RE 1.4368279098434364\n",
      "18 Train Loss 32.91597 Test MSE 8.940451473441264 Test RE 1.4291828148974157\n",
      "19 Train Loss 32.460808 Test MSE 8.682628215969533 Test RE 1.4084247975181936\n",
      "20 Train Loss 31.71569 Test MSE 8.609927353223513 Test RE 1.4025159334850255\n",
      "21 Train Loss 31.535812 Test MSE 8.688446145941743 Test RE 1.4088965869608692\n",
      "22 Train Loss 31.304836 Test MSE 8.584984794578206 Test RE 1.4004829483737784\n",
      "23 Train Loss 30.623034 Test MSE 8.184523726920274 Test RE 1.3674289378689055\n",
      "24 Train Loss 30.097672 Test MSE 7.984682194614982 Test RE 1.3506315109401077\n",
      "25 Train Loss 29.201477 Test MSE 7.767007320798592 Test RE 1.3320941391527392\n",
      "26 Train Loss 28.495268 Test MSE 7.994813288922312 Test RE 1.3514880909020701\n",
      "27 Train Loss 27.142704 Test MSE 7.868641486001964 Test RE 1.340781285281799\n",
      "28 Train Loss 25.445465 Test MSE 7.753892978768905 Test RE 1.3309690649861279\n",
      "29 Train Loss 24.352962 Test MSE 7.2378547647266025 Test RE 1.28591716174893\n",
      "30 Train Loss 22.759823 Test MSE 7.461187921834438 Test RE 1.3056057363405318\n",
      "31 Train Loss 22.08583 Test MSE 7.324016827438011 Test RE 1.2935485307206525\n",
      "32 Train Loss 21.432758 Test MSE 7.429992613404486 Test RE 1.3028735015307185\n",
      "33 Train Loss 20.925365 Test MSE 7.409027848775296 Test RE 1.301034083052685\n",
      "34 Train Loss 20.420444 Test MSE 7.5476573220741505 Test RE 1.3131494235264383\n",
      "35 Train Loss 19.952787 Test MSE 7.46083412405349 Test RE 1.3055747810896274\n",
      "36 Train Loss 19.36285 Test MSE 6.925702282483053 Test RE 1.2578821940302465\n",
      "37 Train Loss 15.859898 Test MSE 6.387530729062874 Test RE 1.208021215467253\n",
      "38 Train Loss 14.759089 Test MSE 6.331038728169648 Test RE 1.2026674177555454\n",
      "39 Train Loss 14.229385 Test MSE 6.491473821932257 Test RE 1.2178105030155777\n",
      "40 Train Loss 13.540979 Test MSE 6.3517268541512575 Test RE 1.2046308113799573\n",
      "41 Train Loss 13.210241 Test MSE 6.3102010492753005 Test RE 1.2006865854207132\n",
      "42 Train Loss 12.787655 Test MSE 6.2711268975136205 Test RE 1.196963355092505\n",
      "43 Train Loss 12.473822 Test MSE 6.145153993303496 Test RE 1.1848802089526993\n",
      "44 Train Loss 12.132459 Test MSE 6.163846381608855 Test RE 1.1866809306164539\n",
      "45 Train Loss 11.734989 Test MSE 6.250987186544542 Test RE 1.19503978680583\n",
      "46 Train Loss 10.94309 Test MSE 6.330329411367889 Test RE 1.2026000436532507\n",
      "47 Train Loss 10.673304 Test MSE 6.385797087802762 Test RE 1.2078572696772212\n",
      "48 Train Loss 9.844152 Test MSE 6.483903646657466 Test RE 1.2171002075936928\n",
      "49 Train Loss 9.517823 Test MSE 6.645079037052486 Test RE 1.2321345500122582\n",
      "50 Train Loss 8.980133 Test MSE 6.877788477812531 Test RE 1.2535234646070543\n",
      "51 Train Loss 8.597184 Test MSE 6.636185397386858 Test RE 1.231309741936447\n",
      "52 Train Loss 8.410003 Test MSE 6.519093465849598 Test RE 1.2203984970191473\n",
      "53 Train Loss 8.227976 Test MSE 6.543394131253714 Test RE 1.2226709686509614\n",
      "54 Train Loss 8.079965 Test MSE 6.58083040953462 Test RE 1.226163572634778\n",
      "55 Train Loss 7.853292 Test MSE 6.612908654089023 Test RE 1.2291484055965651\n",
      "56 Train Loss 7.727721 Test MSE 6.648743875985513 Test RE 1.232474271497735\n",
      "57 Train Loss 7.646295 Test MSE 6.664187394752052 Test RE 1.2339048198804574\n",
      "58 Train Loss 7.536095 Test MSE 6.616070524321976 Test RE 1.2294422205811575\n",
      "59 Train Loss 7.426362 Test MSE 6.532555964583958 Test RE 1.2216579619974484\n",
      "60 Train Loss 7.248454 Test MSE 6.393987600988643 Test RE 1.2086316288194543\n",
      "61 Train Loss 7.1142044 Test MSE 6.409425001352342 Test RE 1.2100897863273048\n",
      "62 Train Loss 6.983329 Test MSE 6.455835756551598 Test RE 1.2144630242729793\n",
      "63 Train Loss 6.890242 Test MSE 6.479085739032517 Test RE 1.2166479363699776\n",
      "64 Train Loss 6.761365 Test MSE 6.51761938856201 Test RE 1.2202605128484107\n",
      "65 Train Loss 6.6690598 Test MSE 6.413188846447428 Test RE 1.2104450383231777\n",
      "66 Train Loss 6.541834 Test MSE 6.545906039569287 Test RE 1.2229056284176008\n",
      "67 Train Loss 6.4690285 Test MSE 6.471894859203233 Test RE 1.2159725943322826\n",
      "68 Train Loss 6.3680105 Test MSE 6.496915708177537 Test RE 1.218320849207784\n",
      "69 Train Loss 6.231395 Test MSE 6.592976833909947 Test RE 1.2272946333197956\n",
      "70 Train Loss 6.142185 Test MSE 6.642171027194478 Test RE 1.2318649180419714\n",
      "71 Train Loss 6.040113 Test MSE 6.6468575216627315 Test RE 1.232299422824204\n",
      "72 Train Loss 5.871201 Test MSE 6.644383277492892 Test RE 1.2320700442458152\n",
      "73 Train Loss 5.3662243 Test MSE 6.333025282867566 Test RE 1.2028560895772316\n",
      "74 Train Loss 5.008452 Test MSE 6.443230369145947 Test RE 1.2132767907930877\n",
      "75 Train Loss 4.6442156 Test MSE 6.315003018626695 Test RE 1.2011433508756097\n",
      "76 Train Loss 3.7854762 Test MSE 6.044864526722593 Test RE 1.1751717594572388\n",
      "77 Train Loss 3.2726433 Test MSE 5.945771820659131 Test RE 1.1654997359657977\n",
      "78 Train Loss 3.0276084 Test MSE 5.945091056783824 Test RE 1.165433011842068\n",
      "79 Train Loss 2.6674893 Test MSE 5.755308158001618 Test RE 1.1466802999104035\n",
      "80 Train Loss 2.3439548 Test MSE 5.798432972274277 Test RE 1.1509683489172868\n",
      "81 Train Loss 2.1394558 Test MSE 5.860371031933149 Test RE 1.157099262433415\n",
      "82 Train Loss 2.0081446 Test MSE 5.911456048174688 Test RE 1.16213155269965\n",
      "83 Train Loss 1.9289819 Test MSE 5.900208254642225 Test RE 1.1610254259382944\n",
      "84 Train Loss 1.8344973 Test MSE 5.892704335689966 Test RE 1.1602868916227211\n",
      "85 Train Loss 1.7644765 Test MSE 5.866343614358089 Test RE 1.1576887396848232\n",
      "86 Train Loss 1.7301837 Test MSE 5.849244084706252 Test RE 1.1560002620865408\n",
      "87 Train Loss 1.67877 Test MSE 5.869499260978806 Test RE 1.1580000720613355\n",
      "88 Train Loss 1.62785 Test MSE 5.897023381517226 Test RE 1.1607120287114958\n",
      "89 Train Loss 1.5874882 Test MSE 5.887225265793084 Test RE 1.159747345510565\n",
      "90 Train Loss 1.5435665 Test MSE 5.8625438522133 Test RE 1.1573137484899834\n",
      "91 Train Loss 1.5023707 Test MSE 5.8831160870089905 Test RE 1.1593425333248668\n",
      "92 Train Loss 1.4746339 Test MSE 5.919363787707698 Test RE 1.162908583121313\n",
      "93 Train Loss 1.4441108 Test MSE 5.96778518776705 Test RE 1.1676552904286002\n",
      "94 Train Loss 1.4040982 Test MSE 5.961192071199736 Test RE 1.1670101084502191\n",
      "95 Train Loss 1.3732951 Test MSE 5.963973896443734 Test RE 1.1672823727464574\n",
      "96 Train Loss 1.3456007 Test MSE 5.946962940550578 Test RE 1.1656164727361105\n",
      "97 Train Loss 1.3069838 Test MSE 5.9800275163059835 Test RE 1.1688523422358743\n",
      "98 Train Loss 1.2661167 Test MSE 5.956208805095537 Test RE 1.1665222246738935\n",
      "99 Train Loss 1.2403512 Test MSE 5.977328904414356 Test RE 1.168588578000633\n",
      "Training time: 70.26\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.00114 Test MSE 8.692544877880147 Test RE 1.4092288678116172\n",
      "1 Train Loss 56.271263 Test MSE 8.447080159910403 Test RE 1.3891891031620975\n",
      "2 Train Loss 54.136818 Test MSE 8.564250716699267 Test RE 1.3987907335896679\n",
      "3 Train Loss 48.217056 Test MSE 8.570014700848231 Test RE 1.3992613673758616\n",
      "4 Train Loss 45.837 Test MSE 8.060304675106671 Test RE 1.3570123163999297\n",
      "5 Train Loss 44.66456 Test MSE 7.912872828311245 Test RE 1.3445444157134683\n",
      "6 Train Loss 43.697903 Test MSE 7.596553709562132 Test RE 1.317396079465352\n",
      "7 Train Loss 42.536926 Test MSE 7.236898749354231 Test RE 1.2858322334647965\n",
      "8 Train Loss 37.354843 Test MSE 6.930629189134921 Test RE 1.258329539734477\n",
      "9 Train Loss 36.005165 Test MSE 6.899024933752687 Test RE 1.2554572169109053\n",
      "10 Train Loss 35.33667 Test MSE 6.658602780541653 Test RE 1.2333877030712588\n",
      "11 Train Loss 33.298637 Test MSE 6.492543828895933 Test RE 1.2179108663584708\n",
      "12 Train Loss 32.2021 Test MSE 5.897360197433731 Test RE 1.1607451760027874\n",
      "13 Train Loss 28.04092 Test MSE 5.637574797294947 Test RE 1.1348911746183092\n",
      "14 Train Loss 26.589848 Test MSE 5.751052668398098 Test RE 1.146256292341428\n",
      "15 Train Loss 25.675253 Test MSE 5.611595546308183 Test RE 1.1322732343638227\n",
      "16 Train Loss 25.41046 Test MSE 5.692930198180605 Test RE 1.1404493177342643\n",
      "17 Train Loss 23.731289 Test MSE 4.399760675138708 Test RE 1.0025881959927783\n",
      "18 Train Loss 23.357687 Test MSE 3.8453527260289615 Test RE 0.9372946793520055\n",
      "19 Train Loss 22.517008 Test MSE 4.008604818813982 Test RE 0.9569840123413369\n",
      "20 Train Loss 22.295578 Test MSE 4.239870002924068 Test RE 0.9842021984684556\n",
      "21 Train Loss 21.910347 Test MSE 3.8964855972582706 Test RE 0.9435058514381188\n",
      "22 Train Loss 21.759552 Test MSE 3.69105733197533 Test RE 0.918297613752763\n",
      "23 Train Loss 21.154884 Test MSE 3.9982878147257654 Test RE 0.9557517171529986\n",
      "24 Train Loss 20.787785 Test MSE 3.903487060942638 Test RE 0.9443531479266432\n",
      "25 Train Loss 19.999336 Test MSE 3.767838632690634 Test RE 0.9277996570569605\n",
      "26 Train Loss 19.533152 Test MSE 3.666246145994267 Test RE 0.9152060239313867\n",
      "27 Train Loss 18.944527 Test MSE 3.156508020150032 Test RE 0.8492029787002953\n",
      "28 Train Loss 18.838444 Test MSE 2.9280459293290426 Test RE 0.8178939631174538\n",
      "29 Train Loss 17.670248 Test MSE 1.5598693444668248 Test RE 0.5969695396634982\n",
      "30 Train Loss 14.87989 Test MSE 1.1342352812876328 Test RE 0.5090490559840388\n",
      "31 Train Loss 12.1315975 Test MSE 0.8480011519072672 Test RE 0.44015565038985105\n",
      "32 Train Loss 10.062154 Test MSE 0.732262164090388 Test RE 0.4090169987480247\n",
      "33 Train Loss 8.205474 Test MSE 0.6875432094317415 Test RE 0.39633101437737955\n",
      "34 Train Loss 7.485365 Test MSE 0.6041190083912814 Test RE 0.37150897560141477\n",
      "35 Train Loss 6.937741 Test MSE 0.5470642305378597 Test RE 0.35353077076679246\n",
      "36 Train Loss 6.337096 Test MSE 0.4291238654165446 Test RE 0.31311177082087616\n",
      "37 Train Loss 5.8470006 Test MSE 0.4424989272750442 Test RE 0.31795391098318054\n",
      "38 Train Loss 5.4356833 Test MSE 0.4119142109870807 Test RE 0.3067689839707112\n",
      "39 Train Loss 5.264935 Test MSE 0.35937971005059627 Test RE 0.2865397233568398\n",
      "40 Train Loss 4.6044793 Test MSE 0.309670838980785 Test RE 0.2659856553221896\n",
      "41 Train Loss 4.3294916 Test MSE 0.3431425692259299 Test RE 0.27999183034940534\n",
      "42 Train Loss 4.1832056 Test MSE 0.36989616340699705 Test RE 0.29070196920784924\n",
      "43 Train Loss 4.0254354 Test MSE 0.40598912360837625 Test RE 0.30455466754626653\n",
      "44 Train Loss 3.7239945 Test MSE 0.359054148912058 Test RE 0.28640990615727524\n",
      "45 Train Loss 3.616325 Test MSE 0.35515142869072736 Test RE 0.28484909455990454\n",
      "46 Train Loss 3.4999 Test MSE 0.3332492171554881 Test RE 0.275926002565877\n",
      "47 Train Loss 3.2802966 Test MSE 0.25148592898122435 Test RE 0.23969827333007837\n",
      "48 Train Loss 3.1415877 Test MSE 0.2404745492702656 Test RE 0.2343919110675991\n",
      "49 Train Loss 2.8333108 Test MSE 0.21260813425365443 Test RE 0.2203931024440024\n",
      "50 Train Loss 2.6421566 Test MSE 0.1845093703965267 Test RE 0.20531338994994247\n",
      "51 Train Loss 2.5723689 Test MSE 0.18160522561516054 Test RE 0.20369118313978077\n",
      "52 Train Loss 2.3705554 Test MSE 0.1708343141237718 Test RE 0.19755845197625663\n",
      "53 Train Loss 2.2086637 Test MSE 0.13530730820684247 Test RE 0.17582016667908776\n",
      "54 Train Loss 1.9778249 Test MSE 0.11098619994777191 Test RE 0.15923647357677465\n",
      "55 Train Loss 1.7589132 Test MSE 0.13096599326166636 Test RE 0.17297658978793273\n",
      "56 Train Loss 1.6961555 Test MSE 0.121128383514318 Test RE 0.16635314697891726\n",
      "57 Train Loss 1.445191 Test MSE 0.10530446455772392 Test RE 0.15510701941479296\n",
      "58 Train Loss 1.2281967 Test MSE 0.09619839642195654 Test RE 0.148249069651217\n",
      "59 Train Loss 1.0618017 Test MSE 0.07351614834574234 Test RE 0.1295983382761671\n",
      "60 Train Loss 0.95737314 Test MSE 0.07579950239729842 Test RE 0.1315955603172215\n",
      "61 Train Loss 0.87037235 Test MSE 0.07010515670425528 Test RE 0.12655608820004488\n",
      "62 Train Loss 0.84586406 Test MSE 0.07422746699772693 Test RE 0.1302238049240633\n",
      "63 Train Loss 0.74839216 Test MSE 0.06934789142316697 Test RE 0.12587071249853282\n",
      "64 Train Loss 0.6828685 Test MSE 0.05323425745763311 Test RE 0.11028175293028322\n",
      "65 Train Loss 0.6348159 Test MSE 0.04178774649733297 Test RE 0.09770854271311767\n",
      "66 Train Loss 0.58999026 Test MSE 0.03802239477370621 Test RE 0.09320254976400819\n",
      "67 Train Loss 0.5387702 Test MSE 0.039191407284219375 Test RE 0.09462447642400923\n",
      "68 Train Loss 0.49416956 Test MSE 0.03978511175878759 Test RE 0.09533850806723314\n",
      "69 Train Loss 0.45526913 Test MSE 0.04461343929748384 Test RE 0.10095804048152354\n",
      "70 Train Loss 0.42950073 Test MSE 0.03896061550247455 Test RE 0.09434545100803912\n",
      "71 Train Loss 0.41403025 Test MSE 0.04239342002435887 Test RE 0.09841409141106224\n",
      "72 Train Loss 0.37886676 Test MSE 0.03427502120393706 Test RE 0.08849055650852165\n",
      "73 Train Loss 0.37064707 Test MSE 0.034252011694484004 Test RE 0.08846084877877447\n",
      "74 Train Loss 0.3544774 Test MSE 0.03126539641920356 Test RE 0.0845162132121229\n",
      "75 Train Loss 0.3377571 Test MSE 0.031926331178567344 Test RE 0.08540485653002258\n",
      "76 Train Loss 0.31421685 Test MSE 0.027691631444420165 Test RE 0.07953940386516735\n",
      "77 Train Loss 0.2838956 Test MSE 0.02028136158202892 Test RE 0.06807013535791216\n",
      "78 Train Loss 0.26623693 Test MSE 0.01880252466133531 Test RE 0.06554146487106505\n",
      "79 Train Loss 0.25585327 Test MSE 0.020418175459782705 Test RE 0.068299343000122\n",
      "80 Train Loss 0.24078862 Test MSE 0.01791757269761887 Test RE 0.0639805026769054\n",
      "81 Train Loss 0.2197884 Test MSE 0.016889719303208508 Test RE 0.06211825915250194\n",
      "82 Train Loss 0.20182005 Test MSE 0.017651150827907053 Test RE 0.06350304834256412\n",
      "83 Train Loss 0.18475036 Test MSE 0.017734715549712142 Test RE 0.06365319007415579\n",
      "84 Train Loss 0.1798469 Test MSE 0.01733002817263128 Test RE 0.0629227499572074\n",
      "85 Train Loss 0.1688788 Test MSE 0.016592627745678802 Test RE 0.0615695026234681\n",
      "86 Train Loss 0.16314763 Test MSE 0.015832071780617813 Test RE 0.06014187108608304\n",
      "87 Train Loss 0.14683989 Test MSE 0.012984066248216472 Test RE 0.05446448753417664\n",
      "88 Train Loss 0.13687201 Test MSE 0.013389462634110283 Test RE 0.055308213939447945\n",
      "89 Train Loss 0.13367498 Test MSE 0.013936804938378143 Test RE 0.056427352096701834\n",
      "90 Train Loss 0.12965809 Test MSE 0.013455179130813441 Test RE 0.05544377625699953\n",
      "91 Train Loss 0.12139581 Test MSE 0.013782271301584433 Test RE 0.05611364207076333\n",
      "92 Train Loss 0.11731942 Test MSE 0.014972750357194283 Test RE 0.05848693355368406\n",
      "93 Train Loss 0.11213417 Test MSE 0.015045619028769226 Test RE 0.05862908153150598\n",
      "94 Train Loss 0.1083896 Test MSE 0.014394255747247118 Test RE 0.0573459388955157\n",
      "95 Train Loss 0.10691254 Test MSE 0.013372996314046502 Test RE 0.05527419454109368\n",
      "96 Train Loss 0.104169 Test MSE 0.011798676794883407 Test RE 0.05191880794812945\n",
      "97 Train Loss 0.09955714 Test MSE 0.012818679302891076 Test RE 0.054116500102406706\n",
      "98 Train Loss 0.09559342 Test MSE 0.013384205595384734 Test RE 0.055297355177758495\n",
      "99 Train Loss 0.09379589 Test MSE 0.013108764653997098 Test RE 0.0547253998644859\n",
      "Training time: 71.35\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.84659 Test MSE 8.624517827165134 Test RE 1.4037037896258013\n",
      "1 Train Loss 56.25527 Test MSE 8.884038324354085 Test RE 1.4246666957012264\n",
      "2 Train Loss 51.232338 Test MSE 9.051817073813327 Test RE 1.4380564842603885\n",
      "3 Train Loss 47.036163 Test MSE 8.518165990108814 Test RE 1.3950221702682097\n",
      "4 Train Loss 46.095253 Test MSE 8.589276113679123 Test RE 1.400832929679729\n",
      "5 Train Loss 45.461067 Test MSE 8.565185593454437 Test RE 1.3988670777615169\n",
      "6 Train Loss 44.969505 Test MSE 8.546325498161568 Test RE 1.397326112566777\n",
      "7 Train Loss 44.63409 Test MSE 8.577711585743788 Test RE 1.399889577301526\n",
      "8 Train Loss 44.324615 Test MSE 8.445491427625361 Test RE 1.3890584572275244\n",
      "9 Train Loss 44.27434 Test MSE 8.433905009901492 Test RE 1.3881053016065037\n",
      "10 Train Loss 43.912197 Test MSE 8.283436416300129 Test RE 1.3756670391617112\n",
      "11 Train Loss 43.4767 Test MSE 7.980296728674815 Test RE 1.3502605530317082\n",
      "12 Train Loss 41.524086 Test MSE 7.656169391474393 Test RE 1.3225552598732924\n",
      "13 Train Loss 41.216145 Test MSE 7.6961663334651105 Test RE 1.3260053702517967\n",
      "14 Train Loss 40.550613 Test MSE 7.760851600941227 Test RE 1.331566160784039\n",
      "15 Train Loss 40.037933 Test MSE 7.95996576562551 Test RE 1.348539463879138\n",
      "16 Train Loss 39.79922 Test MSE 7.8968016457044286 Test RE 1.3431783251530687\n",
      "17 Train Loss 39.413086 Test MSE 7.968868878123615 Test RE 1.3492934145613735\n",
      "18 Train Loss 39.094723 Test MSE 7.913682625668359 Test RE 1.3446132137772344\n",
      "19 Train Loss 38.630585 Test MSE 7.714177903244648 Test RE 1.3275561086172012\n",
      "20 Train Loss 37.535072 Test MSE 7.553379042042556 Test RE 1.3136470646848515\n",
      "21 Train Loss 36.354446 Test MSE 7.821114140284864 Test RE 1.3367259288447175\n",
      "22 Train Loss 35.359516 Test MSE 7.161831168723631 Test RE 1.2791459487716312\n",
      "23 Train Loss 34.06672 Test MSE 7.602286026986328 Test RE 1.317893035631458\n",
      "24 Train Loss 33.178715 Test MSE 7.607887140817852 Test RE 1.3183784363216051\n",
      "25 Train Loss 32.96993 Test MSE 7.681049665921849 Test RE 1.3247024725459837\n",
      "26 Train Loss 32.57386 Test MSE 7.47384355865513 Test RE 1.306712548785306\n",
      "27 Train Loss 31.841808 Test MSE 7.287696082573017 Test RE 1.2903371072358079\n",
      "28 Train Loss 30.483553 Test MSE 7.702185987135902 Test RE 1.3265238448101107\n",
      "29 Train Loss 29.985481 Test MSE 7.841222081739948 Test RE 1.3384431747625976\n",
      "30 Train Loss 28.726162 Test MSE 7.711532174335068 Test RE 1.3273284333659277\n",
      "31 Train Loss 28.473585 Test MSE 7.696908134507791 Test RE 1.3260692727470609\n",
      "32 Train Loss 27.336605 Test MSE 7.1912734269330905 Test RE 1.2817725339133208\n",
      "33 Train Loss 26.94465 Test MSE 6.85156933719748 Test RE 1.2511318753095395\n",
      "34 Train Loss 26.538368 Test MSE 6.872581465463192 Test RE 1.2530488681557241\n",
      "35 Train Loss 26.341717 Test MSE 6.801381829360465 Test RE 1.2465412044284097\n",
      "36 Train Loss 26.03033 Test MSE 6.866521417624644 Test RE 1.252496294802977\n",
      "37 Train Loss 25.73015 Test MSE 6.861654822434266 Test RE 1.2520523674872235\n",
      "38 Train Loss 25.38329 Test MSE 7.237986967918517 Test RE 1.285928905669094\n",
      "39 Train Loss 25.077667 Test MSE 7.39632422609226 Test RE 1.2999182189187106\n",
      "40 Train Loss 24.672546 Test MSE 7.454832872693366 Test RE 1.305049594595359\n",
      "41 Train Loss 24.20629 Test MSE 7.44294942565663 Test RE 1.3040090164028988\n",
      "42 Train Loss 23.955227 Test MSE 7.4527857175754875 Test RE 1.3048703939049688\n",
      "43 Train Loss 23.60543 Test MSE 7.438584151409004 Test RE 1.3036265610390305\n",
      "44 Train Loss 23.40783 Test MSE 7.526170981680185 Test RE 1.3112789832642044\n",
      "45 Train Loss 23.298641 Test MSE 7.613118858141803 Test RE 1.3188316632033574\n",
      "46 Train Loss 23.155497 Test MSE 7.589168182141168 Test RE 1.3167555238109643\n",
      "47 Train Loss 23.066788 Test MSE 7.58298976721625 Test RE 1.3162194229992996\n",
      "48 Train Loss 22.871914 Test MSE 7.679812006385472 Test RE 1.3245957425566153\n",
      "49 Train Loss 22.749424 Test MSE 7.756624802560999 Test RE 1.3312035054646971\n",
      "50 Train Loss 22.685444 Test MSE 7.752489771917756 Test RE 1.3308486281024539\n",
      "51 Train Loss 22.613544 Test MSE 7.696885859306873 Test RE 1.3260673538933903\n",
      "52 Train Loss 22.533588 Test MSE 7.738767077356241 Test RE 1.3296702377597953\n",
      "53 Train Loss 22.318321 Test MSE 7.715204258922049 Test RE 1.3276444199997166\n",
      "54 Train Loss 22.218159 Test MSE 7.8028087821629 Test RE 1.3351607054776413\n",
      "55 Train Loss 22.137993 Test MSE 7.765114940582149 Test RE 1.33193185128202\n",
      "56 Train Loss 22.061895 Test MSE 7.727550285312979 Test RE 1.3287062571450903\n",
      "57 Train Loss 22.00304 Test MSE 7.654806859747482 Test RE 1.3224375702303697\n",
      "58 Train Loss 21.8456 Test MSE 7.567789834563043 Test RE 1.314899595142493\n",
      "59 Train Loss 21.560606 Test MSE 7.495095077391593 Test RE 1.308569017522488\n",
      "60 Train Loss 21.348946 Test MSE 7.487029020243076 Test RE 1.3078647013222868\n",
      "61 Train Loss 21.212822 Test MSE 7.5272847654808 Test RE 1.3113760065223607\n",
      "62 Train Loss 20.932877 Test MSE 7.50908051356748 Test RE 1.3097893075335072\n",
      "63 Train Loss 20.856861 Test MSE 7.48558703890279 Test RE 1.3077387496728299\n",
      "64 Train Loss 20.783344 Test MSE 7.514866710805104 Test RE 1.3102938459960383\n",
      "65 Train Loss 20.70019 Test MSE 7.698139187688632 Test RE 1.3261753151018882\n",
      "66 Train Loss 20.652794 Test MSE 7.724622784747604 Test RE 1.3284545501586296\n",
      "67 Train Loss 20.577589 Test MSE 7.610559680279002 Test RE 1.3186099795183948\n",
      "68 Train Loss 20.474112 Test MSE 7.621556110330027 Test RE 1.3195622595781205\n",
      "69 Train Loss 20.431091 Test MSE 7.735516715739517 Test RE 1.3293909708580147\n",
      "70 Train Loss 20.401056 Test MSE 7.648273022753968 Test RE 1.3218730598332107\n",
      "71 Train Loss 20.387688 Test MSE 7.637852998847975 Test RE 1.3209722915515212\n",
      "72 Train Loss 20.36341 Test MSE 7.658656153409502 Test RE 1.322770028701631\n",
      "73 Train Loss 20.312908 Test MSE 7.661671498311228 Test RE 1.3230304017529646\n",
      "74 Train Loss 20.275833 Test MSE 7.631807723850404 Test RE 1.3204494206917574\n",
      "75 Train Loss 20.244358 Test MSE 7.6789196281033965 Test RE 1.3245187826771376\n",
      "76 Train Loss 20.22727 Test MSE 7.671759736098845 Test RE 1.3239011422057851\n",
      "77 Train Loss 20.210754 Test MSE 7.678700207267223 Test RE 1.3244998588500203\n",
      "78 Train Loss 20.16693 Test MSE 7.6298770623603795 Test RE 1.3202823893546878\n",
      "79 Train Loss 20.149675 Test MSE 7.667862336873934 Test RE 1.3235648160599662\n",
      "80 Train Loss 20.128452 Test MSE 7.659051974342161 Test RE 1.3228042105013569\n",
      "81 Train Loss 20.107954 Test MSE 7.681470330612774 Test RE 1.324738746750089\n",
      "82 Train Loss 20.069525 Test MSE 7.655422166334615 Test RE 1.3224907190695148\n",
      "83 Train Loss 20.048302 Test MSE 7.665481440758006 Test RE 1.3233593145232156\n",
      "84 Train Loss 20.012466 Test MSE 7.688002038659464 Test RE 1.3253018530127894\n",
      "85 Train Loss 19.997356 Test MSE 7.704259950913915 Test RE 1.3267024289960354\n",
      "86 Train Loss 19.991848 Test MSE 7.697422116852237 Test RE 1.3261135479809365\n",
      "87 Train Loss 19.98257 Test MSE 7.706877480091675 Test RE 1.3269277840222542\n",
      "88 Train Loss 19.957207 Test MSE 7.714078093546833 Test RE 1.3275475203136715\n",
      "89 Train Loss 19.941265 Test MSE 7.70619292236373 Test RE 1.3268688510209647\n",
      "90 Train Loss 19.911835 Test MSE 7.799595487662211 Test RE 1.3348857592076895\n",
      "91 Train Loss 19.86259 Test MSE 7.817395876369014 Test RE 1.336408142236894\n",
      "92 Train Loss 19.830925 Test MSE 7.826718490831043 Test RE 1.3372047697744835\n",
      "93 Train Loss 19.809673 Test MSE 7.818196928211107 Test RE 1.3364766116350155\n",
      "94 Train Loss 19.79198 Test MSE 7.853218349931506 Test RE 1.3394666240844102\n",
      "95 Train Loss 19.772673 Test MSE 7.78705541837167 Test RE 1.3338122231661214\n",
      "96 Train Loss 19.728153 Test MSE 7.7874639646255694 Test RE 1.3338472117985862\n",
      "97 Train Loss 19.69757 Test MSE 7.804049862988789 Test RE 1.335266883682955\n",
      "98 Train Loss 19.626984 Test MSE 7.82278647408673 Test RE 1.3368688325557216\n",
      "99 Train Loss 19.584137 Test MSE 7.882330580981912 Test RE 1.3419470587301008\n",
      "Training time: 72.89\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.922356 Test MSE 8.592539603191742 Test RE 1.401099027157125\n",
      "1 Train Loss 58.36521 Test MSE 8.771734757476878 Test RE 1.4156334163731543\n",
      "2 Train Loss 56.24039 Test MSE 9.024334023473816 Test RE 1.4358717171976065\n",
      "3 Train Loss 50.224056 Test MSE 8.502837397017686 Test RE 1.3937664213199001\n",
      "4 Train Loss 47.0163 Test MSE 8.60660822566189 Test RE 1.4022455724341065\n",
      "5 Train Loss 46.107265 Test MSE 8.539004943876112 Test RE 1.3967275282326284\n",
      "6 Train Loss 45.910934 Test MSE 8.38365717197409 Test RE 1.3839640710904033\n",
      "7 Train Loss 45.69084 Test MSE 8.43454868356527 Test RE 1.3881582705323519\n",
      "8 Train Loss 44.566643 Test MSE 8.864547246613323 Test RE 1.423103018488749\n",
      "9 Train Loss 41.309044 Test MSE 7.953788658037985 Test RE 1.34801611426264\n",
      "10 Train Loss 40.456245 Test MSE 7.679960455242915 Test RE 1.3246085445480036\n",
      "11 Train Loss 39.845108 Test MSE 7.818849341140234 Test RE 1.3365323736246006\n",
      "12 Train Loss 39.70217 Test MSE 7.807160360600896 Test RE 1.3355329590383147\n",
      "13 Train Loss 39.539223 Test MSE 7.741524548102515 Test RE 1.3299071101317723\n",
      "14 Train Loss 39.40084 Test MSE 7.824020199049989 Test RE 1.336974246619711\n",
      "15 Train Loss 39.231804 Test MSE 7.875461590483437 Test RE 1.3413622170658963\n",
      "16 Train Loss 39.1251 Test MSE 7.818276390208962 Test RE 1.336483403407644\n",
      "17 Train Loss 38.78499 Test MSE 7.8531175707411816 Test RE 1.3394580294682343\n",
      "18 Train Loss 38.39771 Test MSE 7.748881283478847 Test RE 1.3305388624021581\n",
      "19 Train Loss 38.233124 Test MSE 7.773450424739699 Test RE 1.3326465425055547\n",
      "20 Train Loss 37.89417 Test MSE 7.754503507915931 Test RE 1.3310214631437505\n",
      "21 Train Loss 37.68342 Test MSE 7.755419013505183 Test RE 1.3311000317860704\n",
      "22 Train Loss 37.53871 Test MSE 7.702845249378385 Test RE 1.3265806149512949\n",
      "23 Train Loss 37.297028 Test MSE 7.616550702075821 Test RE 1.3191288813725437\n",
      "24 Train Loss 37.040325 Test MSE 7.740881452809534 Test RE 1.329851870704461\n",
      "25 Train Loss 36.870346 Test MSE 7.7272435710063725 Test RE 1.3286798880341022\n",
      "26 Train Loss 36.27436 Test MSE 7.534872740318364 Test RE 1.312036814634706\n",
      "27 Train Loss 35.937363 Test MSE 7.553074329830142 Test RE 1.3136205673822372\n",
      "28 Train Loss 35.05378 Test MSE 7.35185517632649 Test RE 1.2960045669761873\n",
      "29 Train Loss 34.204082 Test MSE 6.781095244932519 Test RE 1.2446807774616206\n",
      "30 Train Loss 33.49864 Test MSE 6.679847036489808 Test RE 1.235353696426587\n",
      "31 Train Loss 32.87511 Test MSE 6.480094159737103 Test RE 1.2167426137120598\n",
      "32 Train Loss 32.265938 Test MSE 6.0409622093516075 Test RE 1.1747923768006205\n",
      "33 Train Loss 31.59263 Test MSE 5.8075580899652754 Test RE 1.1518736446111046\n",
      "34 Train Loss 30.750233 Test MSE 5.45724755422346 Test RE 1.116592966137791\n",
      "35 Train Loss 29.95403 Test MSE 5.369814902496985 Test RE 1.1076121680611783\n",
      "36 Train Loss 28.611311 Test MSE 5.052876680865893 Test RE 1.0744282279519635\n",
      "37 Train Loss 26.083092 Test MSE 4.658590733831086 Test RE 1.0316570243230796\n",
      "38 Train Loss 24.630638 Test MSE 4.603592832263408 Test RE 1.0255492300001654\n",
      "39 Train Loss 21.6624 Test MSE 4.422039690410478 Test RE 1.0051233875919605\n",
      "40 Train Loss 19.762482 Test MSE 4.194050101969245 Test RE 0.978869659110448\n",
      "41 Train Loss 18.316208 Test MSE 3.5557053728322634 Test RE 0.9013032649005297\n",
      "42 Train Loss 15.693155 Test MSE 3.2003093505190874 Test RE 0.8550746680988952\n",
      "43 Train Loss 14.545023 Test MSE 3.0152886242706622 Test RE 0.8299893216022334\n",
      "44 Train Loss 13.47703 Test MSE 2.770350143698347 Test RE 0.7955644928519974\n",
      "45 Train Loss 12.3506155 Test MSE 2.6170060532286468 Test RE 0.7732330771266326\n",
      "46 Train Loss 9.657691 Test MSE 2.631701302516571 Test RE 0.7754010021896057\n",
      "47 Train Loss 8.752829 Test MSE 2.227179537075284 Test RE 0.713322091281815\n",
      "48 Train Loss 8.089564 Test MSE 2.3541964618295848 Test RE 0.7333805901286526\n",
      "49 Train Loss 7.5361185 Test MSE 2.321453567353827 Test RE 0.7282626901418368\n",
      "50 Train Loss 7.0837946 Test MSE 2.2289306237918765 Test RE 0.7136024556159437\n",
      "51 Train Loss 6.756193 Test MSE 1.9866727502284118 Test RE 0.6737072604916154\n",
      "52 Train Loss 6.370826 Test MSE 1.8317359172106669 Test RE 0.6469034852037414\n",
      "53 Train Loss 6.125296 Test MSE 1.7379944168114443 Test RE 0.6301330356911193\n",
      "54 Train Loss 5.6842837 Test MSE 1.3292864350329971 Test RE 0.5510834222694558\n",
      "55 Train Loss 5.041476 Test MSE 0.6670740193377571 Test RE 0.3903867540532073\n",
      "56 Train Loss 4.0444756 Test MSE 0.46657168957799655 Test RE 0.32648802138697763\n",
      "57 Train Loss 3.0172496 Test MSE 0.46801788124537674 Test RE 0.32699362315290437\n",
      "58 Train Loss 1.726955 Test MSE 0.26677946674781294 Test RE 0.24687906296247916\n",
      "59 Train Loss 1.338351 Test MSE 0.18114722083921267 Test RE 0.20343416842966297\n",
      "60 Train Loss 1.1617445 Test MSE 0.16105557410164797 Test RE 0.19182090710871486\n",
      "61 Train Loss 0.99528104 Test MSE 0.15392136101867768 Test RE 0.187524280454665\n",
      "62 Train Loss 0.89497787 Test MSE 0.14531415386512975 Test RE 0.1822057251616697\n",
      "63 Train Loss 0.8313454 Test MSE 0.1364271652870705 Test RE 0.17654624624629323\n",
      "64 Train Loss 0.7683144 Test MSE 0.14528398373021198 Test RE 0.182186809397014\n",
      "65 Train Loss 0.68967783 Test MSE 0.15462792407102433 Test RE 0.18795419486093656\n",
      "66 Train Loss 0.6321475 Test MSE 0.13566674320971006 Test RE 0.17605353917627894\n",
      "67 Train Loss 0.5916755 Test MSE 0.11726527017767865 Test RE 0.16367892518334326\n",
      "68 Train Loss 0.5390995 Test MSE 0.12356210897963936 Test RE 0.16801602913041241\n",
      "69 Train Loss 0.5201919 Test MSE 0.1334127621506141 Test RE 0.17458492801785552\n",
      "70 Train Loss 0.4751672 Test MSE 0.13944996643715613 Test RE 0.17849138823143543\n",
      "71 Train Loss 0.43735847 Test MSE 0.15071332051109815 Test RE 0.18555979302554335\n",
      "72 Train Loss 0.42016178 Test MSE 0.13287177030619426 Test RE 0.17423059548039757\n",
      "73 Train Loss 0.4030489 Test MSE 0.13570497117281194 Test RE 0.17607834147492293\n",
      "74 Train Loss 0.3985384 Test MSE 0.13803415948674402 Test RE 0.177582983381904\n",
      "75 Train Loss 0.3592336 Test MSE 0.11077289632056785 Test RE 0.15908338223418023\n",
      "76 Train Loss 0.3272895 Test MSE 0.10968984879932835 Test RE 0.15830377783709323\n",
      "77 Train Loss 0.3177108 Test MSE 0.1060510295978943 Test RE 0.15565587061472785\n",
      "78 Train Loss 0.30212218 Test MSE 0.10311485588275718 Test RE 0.15348596881326734\n",
      "79 Train Loss 0.29303047 Test MSE 0.09212865558885097 Test RE 0.14507929186294688\n",
      "80 Train Loss 0.282146 Test MSE 0.08418473518882011 Test RE 0.13868348141088965\n",
      "81 Train Loss 0.2749732 Test MSE 0.08095409352660637 Test RE 0.13599641728141307\n",
      "82 Train Loss 0.25483707 Test MSE 0.06617359971326141 Test RE 0.12295620215527124\n",
      "83 Train Loss 0.23682395 Test MSE 0.06110405849067092 Test RE 0.1181525471502074\n",
      "84 Train Loss 0.23100528 Test MSE 0.0586434335418431 Test RE 0.11574913530108537\n",
      "85 Train Loss 0.22527553 Test MSE 0.06168865562681344 Test RE 0.11871639856825293\n",
      "86 Train Loss 0.21092571 Test MSE 0.056815713351202085 Test RE 0.11393110044775996\n",
      "87 Train Loss 0.19995277 Test MSE 0.050950796473463046 Test RE 0.10789058526098007\n",
      "88 Train Loss 0.19361284 Test MSE 0.04468201630672619 Test RE 0.10103560390267731\n",
      "89 Train Loss 0.1863114 Test MSE 0.0443401844060942 Test RE 0.10064838434055638\n",
      "90 Train Loss 0.17759356 Test MSE 0.04075009622638497 Test RE 0.09648779452034695\n",
      "91 Train Loss 0.16799322 Test MSE 0.042787646642103244 Test RE 0.09887062068630108\n",
      "92 Train Loss 0.15546377 Test MSE 0.03529317334898232 Test RE 0.08979526054338673\n",
      "93 Train Loss 0.15097891 Test MSE 0.030607707936961274 Test RE 0.08362256111330901\n",
      "94 Train Loss 0.14759172 Test MSE 0.03143205394502838 Test RE 0.08474116706501197\n",
      "95 Train Loss 0.14296886 Test MSE 0.031049491465210226 Test RE 0.0842238919449737\n",
      "96 Train Loss 0.13830017 Test MSE 0.03218595143819592 Test RE 0.0857514033458536\n",
      "97 Train Loss 0.13523 Test MSE 0.033246841311314855 Test RE 0.08715318350888086\n",
      "98 Train Loss 0.13243724 Test MSE 0.03391443875514836 Test RE 0.08802385356635418\n",
      "99 Train Loss 0.12846434 Test MSE 0.03251087420427507 Test RE 0.08618315408250497\n",
      "Training time: 71.19\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.650574 Test MSE 8.60197556745681 Test RE 1.4018681299686788\n",
      "1 Train Loss 54.86461 Test MSE 8.402744866795178 Test RE 1.3855386622370254\n",
      "2 Train Loss 51.887787 Test MSE 8.849310193759786 Test RE 1.4218794240229917\n",
      "3 Train Loss 46.955612 Test MSE 8.191739447009226 Test RE 1.3680315881261211\n",
      "4 Train Loss 45.37139 Test MSE 7.967339220356944 Test RE 1.34916390708431\n",
      "5 Train Loss 43.1849 Test MSE 8.333304249215594 Test RE 1.379801711761817\n",
      "6 Train Loss 42.437057 Test MSE 7.96627696513363 Test RE 1.3490739646242063\n",
      "7 Train Loss 41.601345 Test MSE 7.900671542821379 Test RE 1.3435074030184182\n",
      "8 Train Loss 41.048977 Test MSE 8.06482256891995 Test RE 1.3573925736566514\n",
      "9 Train Loss 40.131573 Test MSE 8.100228055267076 Test RE 1.3603688643942367\n",
      "10 Train Loss 39.670906 Test MSE 7.971599832043073 Test RE 1.3495245980923494\n",
      "11 Train Loss 39.45143 Test MSE 8.012158416743068 Test RE 1.3529533554506439\n",
      "12 Train Loss 39.237537 Test MSE 7.934604585097747 Test RE 1.3463894648208719\n",
      "13 Train Loss 38.820644 Test MSE 7.825163844521886 Test RE 1.3370719565331306\n",
      "14 Train Loss 38.683846 Test MSE 7.651854599519989 Test RE 1.3221825307224324\n",
      "15 Train Loss 37.92987 Test MSE 7.246172894416553 Test RE 1.2866558719474732\n",
      "16 Train Loss 37.647957 Test MSE 7.246929522640311 Test RE 1.2867230449744855\n",
      "17 Train Loss 35.68973 Test MSE 5.788422751043235 Test RE 1.1499744230828979\n",
      "18 Train Loss 33.37219 Test MSE 5.501754627924143 Test RE 1.1211369574450727\n",
      "19 Train Loss 32.477722 Test MSE 5.21019889863256 Test RE 1.0910262797723993\n",
      "20 Train Loss 31.15256 Test MSE 5.051268874257316 Test RE 1.0742572748142576\n",
      "21 Train Loss 30.188717 Test MSE 4.7500876659199065 Test RE 1.0417388786231983\n",
      "22 Train Loss 29.226158 Test MSE 4.299593395255113 Test RE 0.9911097621138008\n",
      "23 Train Loss 27.401144 Test MSE 3.695190263076362 Test RE 0.918811585579628\n",
      "24 Train Loss 24.11618 Test MSE 3.0631945030874377 Test RE 0.8365566334362922\n",
      "25 Train Loss 21.449139 Test MSE 2.789805576213018 Test RE 0.7983531244226642\n",
      "26 Train Loss 19.374939 Test MSE 2.6379982775831867 Test RE 0.7763281141525609\n",
      "27 Train Loss 18.670212 Test MSE 2.591280302603901 Test RE 0.7694231645062565\n",
      "28 Train Loss 18.197983 Test MSE 2.6709049183055966 Test RE 0.7811551029906745\n",
      "29 Train Loss 17.564814 Test MSE 2.5594041876994553 Test RE 0.7646760681014028\n",
      "30 Train Loss 16.835676 Test MSE 2.3640255040903577 Test RE 0.7349099698109514\n",
      "31 Train Loss 16.426306 Test MSE 2.309040913831334 Test RE 0.7263130951521805\n",
      "32 Train Loss 15.85857 Test MSE 2.291482551607375 Test RE 0.7235463176711888\n",
      "33 Train Loss 14.645437 Test MSE 2.453858284262229 Test RE 0.7487430412186842\n",
      "34 Train Loss 13.441696 Test MSE 2.0734882809776756 Test RE 0.6882700201526218\n",
      "35 Train Loss 13.234048 Test MSE 2.121736264583913 Test RE 0.6962316467556383\n",
      "36 Train Loss 13.029772 Test MSE 2.1314373267226356 Test RE 0.6978214964838902\n",
      "37 Train Loss 12.557575 Test MSE 2.141078119373027 Test RE 0.6993978886228324\n",
      "38 Train Loss 12.126217 Test MSE 2.040781934158134 Test RE 0.6828202005711033\n",
      "39 Train Loss 11.92741 Test MSE 2.056982062657601 Test RE 0.6855250238724613\n",
      "40 Train Loss 11.624181 Test MSE 1.934486288150875 Test RE 0.664799812290017\n",
      "41 Train Loss 11.436466 Test MSE 1.9347816735540255 Test RE 0.6648505659878089\n",
      "42 Train Loss 11.228667 Test MSE 1.9384696648686208 Test RE 0.6654839180099017\n",
      "43 Train Loss 10.808378 Test MSE 2.019982725808814 Test RE 0.6793317113807609\n",
      "44 Train Loss 10.614893 Test MSE 2.0424369917201157 Test RE 0.6830970252733253\n",
      "45 Train Loss 10.393732 Test MSE 2.0024487160451354 Test RE 0.6763768914982127\n",
      "46 Train Loss 10.233224 Test MSE 1.8478657734040798 Test RE 0.6497454860060207\n",
      "47 Train Loss 10.022342 Test MSE 1.8411148773224006 Test RE 0.6485575269340011\n",
      "48 Train Loss 9.945201 Test MSE 1.8488786589035313 Test RE 0.649923536714693\n",
      "49 Train Loss 9.822672 Test MSE 1.767974015270055 Test RE 0.6355445503972705\n",
      "50 Train Loss 9.627498 Test MSE 1.9364183620188269 Test RE 0.6651317148221061\n",
      "51 Train Loss 9.4964695 Test MSE 1.8812794098285026 Test RE 0.6555936092690174\n",
      "52 Train Loss 9.405756 Test MSE 1.9427092416678784 Test RE 0.6662112518646414\n",
      "53 Train Loss 9.205459 Test MSE 1.9000261183041602 Test RE 0.6588519653088944\n",
      "54 Train Loss 9.10654 Test MSE 1.825763416304379 Test RE 0.6458479874735791\n",
      "55 Train Loss 9.061324 Test MSE 1.8761589041895352 Test RE 0.6547007971386452\n",
      "56 Train Loss 9.036887 Test MSE 1.8949903398436547 Test RE 0.657978284206475\n",
      "57 Train Loss 8.938585 Test MSE 1.90797044300119 Test RE 0.6602279132765894\n",
      "58 Train Loss 8.704094 Test MSE 1.9182097562273166 Test RE 0.6619971321751549\n",
      "59 Train Loss 8.659464 Test MSE 1.9495101344970271 Test RE 0.6673763446263826\n",
      "60 Train Loss 8.622851 Test MSE 1.9493221608866838 Test RE 0.6673441693217087\n",
      "61 Train Loss 8.6085415 Test MSE 1.9140640576902463 Test RE 0.661281380161586\n",
      "62 Train Loss 8.599775 Test MSE 1.9133970098091273 Test RE 0.6611661424349337\n",
      "63 Train Loss 8.580156 Test MSE 1.892210342802331 Test RE 0.6574954719726921\n",
      "64 Train Loss 8.550689 Test MSE 1.88952123130551 Test RE 0.6570281065812699\n",
      "65 Train Loss 8.514499 Test MSE 1.8924613897596512 Test RE 0.6575390867758291\n",
      "66 Train Loss 8.485586 Test MSE 1.9171348870954348 Test RE 0.6618116310877152\n",
      "67 Train Loss 8.475916 Test MSE 1.9251755674962898 Test RE 0.6631980353158045\n",
      "68 Train Loss 8.461442 Test MSE 1.9157956998525683 Test RE 0.661580441167319\n",
      "69 Train Loss 8.444955 Test MSE 1.9028160416399602 Test RE 0.6593355039783554\n",
      "70 Train Loss 8.440048 Test MSE 1.9011923279111083 Test RE 0.6590541313786594\n",
      "71 Train Loss 8.410592 Test MSE 1.9052961222888343 Test RE 0.6597650443844646\n",
      "72 Train Loss 8.302378 Test MSE 1.9220589381271567 Test RE 0.6626609986630432\n",
      "73 Train Loss 8.256521 Test MSE 1.8492406618291204 Test RE 0.6499871597938118\n",
      "74 Train Loss 8.246323 Test MSE 1.8431568540539662 Test RE 0.6489170841765609\n",
      "75 Train Loss 8.232264 Test MSE 1.8481807216499717 Test RE 0.6498008546061885\n",
      "76 Train Loss 8.21657 Test MSE 1.8578572258502752 Test RE 0.6514997122596659\n",
      "77 Train Loss 8.176107 Test MSE 1.8755573825140797 Test RE 0.6545958358023938\n",
      "78 Train Loss 8.105396 Test MSE 1.8583953913784286 Test RE 0.6515940653926457\n",
      "79 Train Loss 8.072981 Test MSE 1.852686298125378 Test RE 0.6505924290571671\n",
      "80 Train Loss 8.058135 Test MSE 1.85542906625053 Test RE 0.651073828482247\n",
      "81 Train Loss 8.048029 Test MSE 1.8786738451340252 Test RE 0.6551394546594144\n",
      "82 Train Loss 8.018156 Test MSE 1.8873737403480533 Test RE 0.6566546355079693\n",
      "83 Train Loss 7.9900646 Test MSE 1.931597694282238 Test RE 0.6643032840707394\n",
      "84 Train Loss 7.977383 Test MSE 1.9551189306140906 Test RE 0.6683356854738224\n",
      "85 Train Loss 7.952034 Test MSE 1.978120037160233 Test RE 0.6722555267530518\n",
      "86 Train Loss 7.925277 Test MSE 1.978714708924884 Test RE 0.6723565674715392\n",
      "87 Train Loss 7.921141 Test MSE 1.9882311967163353 Test RE 0.6739714536982597\n",
      "88 Train Loss 7.9005203 Test MSE 1.9608593699464145 Test RE 0.669316119042062\n",
      "89 Train Loss 7.8888683 Test MSE 1.9467410461310837 Test RE 0.6669022048053816\n",
      "90 Train Loss 7.8798885 Test MSE 1.9813871581737508 Test RE 0.6728104561759062\n",
      "91 Train Loss 7.8458004 Test MSE 2.001357935543772 Test RE 0.6761926472732298\n",
      "92 Train Loss 7.828641 Test MSE 2.0209126267120046 Test RE 0.6794880588778045\n",
      "93 Train Loss 7.820206 Test MSE 2.0375732963686346 Test RE 0.6822832043064729\n",
      "94 Train Loss 7.8081264 Test MSE 2.0505673130508493 Test RE 0.6844552758130765\n",
      "95 Train Loss 7.794364 Test MSE 2.0280276538671393 Test RE 0.6806831447335764\n",
      "96 Train Loss 7.760401 Test MSE 2.007444698887585 Test RE 0.6772201246459373\n",
      "97 Train Loss 7.742999 Test MSE 2.0058287054622714 Test RE 0.6769474885920249\n",
      "98 Train Loss 7.7220354 Test MSE 1.9998062713268288 Test RE 0.6759304684390255\n",
      "99 Train Loss 7.7002277 Test MSE 1.9963377478849023 Test RE 0.6753440370993203\n",
      "Training time: 73.06\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.000656 Test MSE 8.445810603014412 Test RE 1.3890847049058592\n",
      "1 Train Loss 55.939545 Test MSE 8.394108009694097 Test RE 1.3848264083109578\n",
      "2 Train Loss 50.878437 Test MSE 7.677197914425317 Test RE 1.3243702871819383\n",
      "3 Train Loss 44.552315 Test MSE 7.572762073292156 Test RE 1.3153314861753056\n",
      "4 Train Loss 39.80375 Test MSE 7.993292684717419 Test RE 1.3513595590572796\n",
      "5 Train Loss 37.758316 Test MSE 7.521643582843143 Test RE 1.3108845213236027\n",
      "6 Train Loss 36.01625 Test MSE 7.100889158504302 Test RE 1.2736920176855613\n",
      "7 Train Loss 34.45152 Test MSE 6.860776124247468 Test RE 1.2519721964936554\n",
      "8 Train Loss 34.09686 Test MSE 6.935014664394547 Test RE 1.2587275916449907\n",
      "9 Train Loss 32.0185 Test MSE 6.393913118580349 Test RE 1.2086245892330305\n",
      "10 Train Loss 30.738543 Test MSE 6.466002465950784 Test RE 1.2154189218402685\n",
      "11 Train Loss 29.378317 Test MSE 6.466589817696103 Test RE 1.2154741230420851\n",
      "12 Train Loss 27.335304 Test MSE 5.891758448514112 Test RE 1.1601937642168352\n",
      "13 Train Loss 25.83775 Test MSE 5.610489374624695 Test RE 1.1321616306043403\n",
      "14 Train Loss 24.859875 Test MSE 4.831934845750806 Test RE 1.0506754751301925\n",
      "15 Train Loss 24.465086 Test MSE 4.901936058271999 Test RE 1.0582587821923557\n",
      "16 Train Loss 23.913582 Test MSE 4.910607789278449 Test RE 1.0591944207212045\n",
      "17 Train Loss 23.117678 Test MSE 4.00120993572167 Test RE 0.9561009056302482\n",
      "18 Train Loss 21.773756 Test MSE 4.07664856376212 Test RE 0.9650719593675062\n",
      "19 Train Loss 20.685404 Test MSE 3.9410029434192846 Test RE 0.9488803211665868\n",
      "20 Train Loss 19.268652 Test MSE 4.00723632776398 Test RE 0.9568206467931263\n",
      "21 Train Loss 18.598568 Test MSE 3.647082115484032 Test RE 0.9128109288705183\n",
      "22 Train Loss 17.828665 Test MSE 2.983455050242752 Test RE 0.8255964365497828\n",
      "23 Train Loss 16.465687 Test MSE 2.656888828048224 Test RE 0.7791027756924395\n",
      "24 Train Loss 15.320896 Test MSE 2.606496785597823 Test RE 0.7716789561703516\n",
      "25 Train Loss 14.073161 Test MSE 2.260224779314798 Test RE 0.7185944790712248\n",
      "26 Train Loss 13.289976 Test MSE 1.9208440197052903 Test RE 0.6624515341403842\n",
      "27 Train Loss 12.507334 Test MSE 2.18668313346865 Test RE 0.7068072373914804\n",
      "28 Train Loss 12.200749 Test MSE 2.27270755759493 Test RE 0.7205760750512614\n",
      "29 Train Loss 10.7869425 Test MSE 2.41746185963308 Test RE 0.7431694966276513\n",
      "30 Train Loss 10.103922 Test MSE 2.463709939698861 Test RE 0.7502445479977848\n",
      "31 Train Loss 9.070587 Test MSE 2.2375441345770395 Test RE 0.7149799537657386\n",
      "32 Train Loss 7.4998198 Test MSE 2.119042563013227 Test RE 0.6957895475318714\n",
      "33 Train Loss 6.093032 Test MSE 2.2197097217944566 Test RE 0.7121248686420563\n",
      "34 Train Loss 5.456064 Test MSE 2.1859588692845193 Test RE 0.7066901748059322\n",
      "35 Train Loss 4.9002757 Test MSE 2.2566608526682774 Test RE 0.718027715007167\n",
      "36 Train Loss 4.7390203 Test MSE 2.231846637121936 Test RE 0.7140690906283019\n",
      "37 Train Loss 4.4201508 Test MSE 2.140467673349459 Test RE 0.6992981783198345\n",
      "38 Train Loss 4.1418357 Test MSE 2.1168075418018355 Test RE 0.6954225151052015\n",
      "39 Train Loss 3.7933462 Test MSE 2.10598084437937 Test RE 0.693641819201558\n",
      "40 Train Loss 3.7023985 Test MSE 2.11361490976748 Test RE 0.6948978887656037\n",
      "41 Train Loss 3.5485706 Test MSE 2.072952152550849 Test RE 0.6881810336408186\n",
      "42 Train Loss 3.419694 Test MSE 2.061489131845387 Test RE 0.6862756424969866\n",
      "43 Train Loss 3.3245797 Test MSE 2.0646703486380678 Test RE 0.6868049564666606\n",
      "44 Train Loss 3.2800725 Test MSE 2.0856910717876267 Test RE 0.6902923354724464\n",
      "45 Train Loss 3.1544967 Test MSE 2.084763935318286 Test RE 0.690138893204258\n",
      "46 Train Loss 3.1080992 Test MSE 2.047633548634875 Test RE 0.6839654725131222\n",
      "47 Train Loss 3.0812857 Test MSE 2.0368693140675536 Test RE 0.6821653295788599\n",
      "48 Train Loss 3.037621 Test MSE 2.071548289916544 Test RE 0.6879479662102432\n",
      "49 Train Loss 2.9499378 Test MSE 2.1099698223522383 Test RE 0.6942984284401676\n",
      "50 Train Loss 2.9309072 Test MSE 2.128662389871809 Test RE 0.6973670985924604\n",
      "51 Train Loss 2.8880606 Test MSE 2.1679580811650263 Test RE 0.703774457329041\n",
      "52 Train Loss 2.8431299 Test MSE 2.157381758514923 Test RE 0.7020556865539284\n",
      "53 Train Loss 2.8310528 Test MSE 2.1535145222375354 Test RE 0.7014261658379655\n",
      "54 Train Loss 2.8069801 Test MSE 2.1473698165628132 Test RE 0.7004247478757781\n",
      "55 Train Loss 2.763115 Test MSE 2.1381309245950373 Test RE 0.6989163621416301\n",
      "56 Train Loss 2.7531939 Test MSE 2.137560024601945 Test RE 0.6988230474666067\n",
      "57 Train Loss 2.7458425 Test MSE 2.149968235310318 Test RE 0.7008483932452044\n",
      "58 Train Loss 2.7259278 Test MSE 2.148221600675877 Test RE 0.7005636507131673\n",
      "59 Train Loss 2.7210603 Test MSE 2.152234306766153 Test RE 0.7012176438808055\n",
      "60 Train Loss 2.715861 Test MSE 2.1499891659534693 Test RE 0.7008518047309368\n",
      "61 Train Loss 2.7060966 Test MSE 2.142497959087428 Test RE 0.6996297503922505\n",
      "62 Train Loss 2.6865532 Test MSE 2.1526869426035353 Test RE 0.7012913764545089\n",
      "63 Train Loss 2.6841614 Test MSE 2.150388902483722 Test RE 0.7009169546052461\n",
      "64 Train Loss 2.6814072 Test MSE 2.155261541280161 Test RE 0.7017106209535878\n",
      "65 Train Loss 2.6648848 Test MSE 2.162313327045045 Test RE 0.7028576446194741\n",
      "66 Train Loss 2.656494 Test MSE 2.1645966714217524 Test RE 0.7032286460326739\n",
      "67 Train Loss 2.6538553 Test MSE 2.170604693136378 Test RE 0.7042039051588967\n",
      "68 Train Loss 2.6490865 Test MSE 2.168368081755914 Test RE 0.7038410025045978\n",
      "69 Train Loss 2.6480932 Test MSE 2.1695340658598723 Test RE 0.704030213260372\n",
      "70 Train Loss 2.6464233 Test MSE 2.1649854736103786 Test RE 0.7032917997286248\n",
      "71 Train Loss 2.6421814 Test MSE 2.1675156292302953 Test RE 0.7037026380761554\n",
      "72 Train Loss 2.6408143 Test MSE 2.1682695836651695 Test RE 0.7038250163390494\n",
      "73 Train Loss 2.640101 Test MSE 2.167560309926425 Test RE 0.703709891025403\n",
      "74 Train Loss 2.637052 Test MSE 2.1650337822007844 Test RE 0.7032996461660213\n",
      "75 Train Loss 2.6364408 Test MSE 2.1617974011057735 Test RE 0.7027737890285968\n",
      "76 Train Loss 2.6278079 Test MSE 2.155282270877081 Test RE 0.7017139955192896\n",
      "77 Train Loss 2.6213205 Test MSE 2.1642525882788557 Test RE 0.7031727513843817\n",
      "78 Train Loss 2.6179152 Test MSE 2.1648937499659744 Test RE 0.7032769014369256\n",
      "79 Train Loss 2.6166074 Test MSE 2.167980363096619 Test RE 0.7037780739612437\n",
      "80 Train Loss 2.615843 Test MSE 2.1660295367205418 Test RE 0.7034613603394015\n",
      "81 Train Loss 2.6134348 Test MSE 2.1661899282154664 Test RE 0.7034874050282343\n",
      "82 Train Loss 2.6095114 Test MSE 2.1608152247786396 Test RE 0.7026141241596786\n",
      "83 Train Loss 2.6027238 Test MSE 2.1611994123599674 Test RE 0.7026765829068377\n",
      "84 Train Loss 2.6002092 Test MSE 2.164893335937109 Test RE 0.703276834187216\n",
      "85 Train Loss 2.5997221 Test MSE 2.164090377820741 Test RE 0.7031463995361581\n",
      "86 Train Loss 2.5961368 Test MSE 2.166338677495062 Test RE 0.7035115583693086\n",
      "87 Train Loss 2.592596 Test MSE 2.1664953863309235 Test RE 0.703537003255833\n",
      "88 Train Loss 2.5906549 Test MSE 2.1661055991460936 Test RE 0.7034737116270257\n",
      "89 Train Loss 2.5898104 Test MSE 2.1671395109269063 Test RE 0.7036415804021744\n",
      "90 Train Loss 2.5887623 Test MSE 2.166667625884225 Test RE 0.7035649688106174\n",
      "91 Train Loss 2.5865781 Test MSE 2.162219268771214 Test RE 0.7028423576823508\n",
      "92 Train Loss 2.5855608 Test MSE 2.159745439811112 Test RE 0.7024401761343247\n",
      "93 Train Loss 2.5842512 Test MSE 2.156900809065043 Test RE 0.7019774268496757\n",
      "94 Train Loss 2.580988 Test MSE 2.1576268304561674 Test RE 0.7020955611063479\n",
      "95 Train Loss 2.5788558 Test MSE 2.158990087658747 Test RE 0.7023173292261743\n",
      "96 Train Loss 2.5778093 Test MSE 2.161321968330432 Test RE 0.7026965061006929\n",
      "97 Train Loss 2.5773945 Test MSE 2.158502747881121 Test RE 0.7022380591800035\n",
      "98 Train Loss 2.5761495 Test MSE 2.158091033785446 Test RE 0.702171083333928\n",
      "99 Train Loss 2.5746982 Test MSE 2.161954702795964 Test RE 0.7027993569874335\n",
      "Training time: 71.21\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.398453 Test MSE 8.600345953614404 Test RE 1.40173533419985\n",
      "1 Train Loss 52.33442 Test MSE 7.297710573894817 Test RE 1.291223370425315\n",
      "2 Train Loss 44.100212 Test MSE 8.261962858855142 Test RE 1.3738827775727669\n",
      "3 Train Loss 43.60495 Test MSE 8.501815653881025 Test RE 1.3936826778592155\n",
      "4 Train Loss 43.391846 Test MSE 8.495136232603443 Test RE 1.3931350993639384\n",
      "5 Train Loss 43.344067 Test MSE 8.481502565166648 Test RE 1.3920167437057855\n",
      "6 Train Loss 43.304886 Test MSE 8.469997517869153 Test RE 1.3910722970616036\n",
      "7 Train Loss 43.285362 Test MSE 8.485414450302839 Test RE 1.3923377234980765\n",
      "8 Train Loss 43.062073 Test MSE 8.454727895497413 Test RE 1.3898178261723282\n",
      "9 Train Loss 42.709045 Test MSE 8.444305325157849 Test RE 1.3889609126661038\n",
      "10 Train Loss 42.164543 Test MSE 8.363600943004489 Test RE 1.38230765072127\n",
      "11 Train Loss 41.238625 Test MSE 8.369976233195997 Test RE 1.382834393551182\n",
      "12 Train Loss 40.17991 Test MSE 7.986774073090145 Test RE 1.350808422925437\n",
      "13 Train Loss 39.358986 Test MSE 7.920192670909821 Test RE 1.345166160728932\n",
      "14 Train Loss 39.06611 Test MSE 7.915800264880823 Test RE 1.3447931057024871\n",
      "15 Train Loss 38.66973 Test MSE 7.87662801990196 Test RE 1.3414615475244391\n",
      "16 Train Loss 38.153328 Test MSE 7.907478630870968 Test RE 1.3440860502960965\n",
      "17 Train Loss 35.4578 Test MSE 7.471078907556291 Test RE 1.3064708432691194\n",
      "18 Train Loss 34.16602 Test MSE 7.273734314184593 Test RE 1.289100500743491\n",
      "19 Train Loss 33.600975 Test MSE 7.23809738502021 Test RE 1.2859387141974779\n",
      "20 Train Loss 33.32437 Test MSE 7.196790896544298 Test RE 1.2822641565083912\n",
      "21 Train Loss 33.068703 Test MSE 7.265478310925407 Test RE 1.2883687005975413\n",
      "22 Train Loss 32.831093 Test MSE 7.144079537376569 Test RE 1.2775596913711182\n",
      "23 Train Loss 32.712173 Test MSE 7.10874516111071 Test RE 1.274396391572457\n",
      "24 Train Loss 32.607277 Test MSE 7.168251406649176 Test RE 1.2797191668113537\n",
      "25 Train Loss 32.35968 Test MSE 7.040320056799252 Test RE 1.2682482207434642\n",
      "26 Train Loss 32.11302 Test MSE 7.123006053723985 Test RE 1.2756740379116545\n",
      "27 Train Loss 31.773666 Test MSE 7.070107858343984 Test RE 1.2709283865608818\n",
      "28 Train Loss 31.577213 Test MSE 6.986736591987593 Test RE 1.2634127209209238\n",
      "29 Train Loss 31.064625 Test MSE 6.95352918712054 Test RE 1.2604066945881134\n",
      "30 Train Loss 30.399246 Test MSE 6.857397572792465 Test RE 1.2516638951236916\n",
      "31 Train Loss 30.034134 Test MSE 6.778159091249829 Test RE 1.2444112804554848\n",
      "32 Train Loss 29.51633 Test MSE 6.81188533212935 Test RE 1.2475033616972702\n",
      "33 Train Loss 29.052141 Test MSE 6.57283978846258 Test RE 1.225418926148776\n",
      "34 Train Loss 27.795063 Test MSE 6.597524738253126 Test RE 1.2277178606798305\n",
      "35 Train Loss 26.996403 Test MSE 6.646261403953921 Test RE 1.232244162727441\n",
      "36 Train Loss 24.051003 Test MSE 6.154840297945966 Test RE 1.1858136755135564\n",
      "37 Train Loss 22.187305 Test MSE 5.887283865291022 Test RE 1.1597531173674247\n",
      "38 Train Loss 20.717585 Test MSE 5.535767684081276 Test RE 1.1245971752525872\n",
      "39 Train Loss 17.995316 Test MSE 4.855103914703393 Test RE 1.0531914507957454\n",
      "40 Train Loss 15.147382 Test MSE 4.442089661912898 Test RE 1.0073994756353475\n",
      "41 Train Loss 13.796494 Test MSE 4.107948993470139 Test RE 0.9687697770202874\n",
      "42 Train Loss 12.846463 Test MSE 3.935235924771191 Test RE 0.9481858007646988\n",
      "43 Train Loss 12.591455 Test MSE 3.898906191485466 Test RE 0.943798870644155\n",
      "44 Train Loss 12.1640005 Test MSE 3.819217622528761 Test RE 0.934104067231742\n",
      "45 Train Loss 11.849338 Test MSE 3.8473984217200523 Test RE 0.9375439626919744\n",
      "46 Train Loss 11.552294 Test MSE 3.8015200550929378 Test RE 0.9319373191296728\n",
      "47 Train Loss 11.273024 Test MSE 3.799969831784301 Test RE 0.9317472822170421\n",
      "48 Train Loss 10.890086 Test MSE 3.874051235762365 Test RE 0.9407857711898281\n",
      "49 Train Loss 10.596775 Test MSE 3.927156628441639 Test RE 0.9472119569832995\n",
      "50 Train Loss 10.466869 Test MSE 3.911997347805331 Test RE 0.9453820152533037\n",
      "51 Train Loss 10.255333 Test MSE 3.9749189625761363 Test RE 0.9529545759150295\n",
      "52 Train Loss 10.085551 Test MSE 3.8790462375024193 Test RE 0.9413920761299143\n",
      "53 Train Loss 9.794668 Test MSE 3.899934551639799 Test RE 0.9439233287761206\n",
      "54 Train Loss 9.506217 Test MSE 3.8623213525261506 Test RE 0.9393604321271757\n",
      "55 Train Loss 9.286849 Test MSE 3.916887482461544 Test RE 0.9459727111440601\n",
      "56 Train Loss 9.07975 Test MSE 3.9341775724846775 Test RE 0.9480582884489857\n",
      "57 Train Loss 8.876823 Test MSE 3.9128818244009143 Test RE 0.9454888815078483\n",
      "58 Train Loss 8.652337 Test MSE 3.890307457348134 Test RE 0.9427575587194351\n",
      "59 Train Loss 8.344218 Test MSE 3.914074341280626 Test RE 0.9456329473916925\n",
      "60 Train Loss 7.917697 Test MSE 3.828886171069034 Test RE 0.9352856864463357\n",
      "61 Train Loss 7.658718 Test MSE 3.8524467392097894 Test RE 0.9381588545604198\n",
      "62 Train Loss 7.418129 Test MSE 3.8187015087863134 Test RE 0.9340409495618258\n",
      "63 Train Loss 7.150436 Test MSE 3.7965734815082137 Test RE 0.931330798968632\n",
      "64 Train Loss 6.7590656 Test MSE 3.901214874553501 Test RE 0.9440782579780138\n",
      "65 Train Loss 6.2693057 Test MSE 3.890446750240758 Test RE 0.9427744363381555\n",
      "66 Train Loss 5.8712177 Test MSE 3.766113510987534 Test RE 0.9275872341363891\n",
      "67 Train Loss 5.6339717 Test MSE 3.8461610377552438 Test RE 0.9373931861112398\n",
      "68 Train Loss 5.4398155 Test MSE 3.78134941270193 Test RE 0.9294616284235622\n",
      "69 Train Loss 5.2726135 Test MSE 3.7637029759321603 Test RE 0.9272903313156318\n",
      "70 Train Loss 5.0486355 Test MSE 3.6896011484833493 Test RE 0.9181164540443802\n",
      "71 Train Loss 4.7658243 Test MSE 3.5890406565413624 Test RE 0.9055183369446596\n",
      "72 Train Loss 4.565626 Test MSE 3.494370285221154 Test RE 0.8934958138047004\n",
      "73 Train Loss 4.309805 Test MSE 3.3206919562999344 Test RE 0.871008424080783\n",
      "74 Train Loss 4.07676 Test MSE 3.226442281936963 Test RE 0.8585587337546614\n",
      "75 Train Loss 3.6503096 Test MSE 2.6744484172928766 Test RE 0.7816731118534491\n",
      "76 Train Loss 3.147356 Test MSE 2.53689183640532 Test RE 0.7613056199115809\n",
      "77 Train Loss 2.8400831 Test MSE 2.5101947699500657 Test RE 0.7572892126335619\n",
      "78 Train Loss 2.5564399 Test MSE 2.246575775892262 Test RE 0.7164214760333774\n",
      "79 Train Loss 2.3764653 Test MSE 2.1103893442398425 Test RE 0.6943674481264351\n",
      "80 Train Loss 2.2392507 Test MSE 2.0820322626915746 Test RE 0.6896865994330068\n",
      "81 Train Loss 2.0182567 Test MSE 1.8891766323017565 Test RE 0.6569681915215658\n",
      "82 Train Loss 1.783559 Test MSE 1.8576750354082598 Test RE 0.6514677668741321\n",
      "83 Train Loss 1.5848811 Test MSE 1.724910569402612 Test RE 0.6277566932743719\n",
      "84 Train Loss 1.3428609 Test MSE 1.738578843008148 Test RE 0.6302389725388936\n",
      "85 Train Loss 1.1408852 Test MSE 1.5535000915206776 Test RE 0.5957495210476513\n",
      "86 Train Loss 0.9293722 Test MSE 1.2267218511672542 Test RE 0.5293965550931387\n",
      "87 Train Loss 0.7606033 Test MSE 1.0326286452549875 Test RE 0.485713466358395\n",
      "88 Train Loss 0.5480601 Test MSE 0.4511176469047847 Test RE 0.32103543287958725\n",
      "89 Train Loss 0.48958686 Test MSE 0.5150331986973863 Test RE 0.34302492055129163\n",
      "90 Train Loss 0.4204059 Test MSE 0.34176197150543014 Test RE 0.27942800394248\n",
      "91 Train Loss 0.361996 Test MSE 0.24112884608966592 Test RE 0.23471056787580696\n",
      "92 Train Loss 0.33283356 Test MSE 0.21496774124444587 Test RE 0.2216127315865363\n",
      "93 Train Loss 0.30300757 Test MSE 0.20538652206475372 Test RE 0.21661774508961287\n",
      "94 Train Loss 0.26360458 Test MSE 0.18709391511672624 Test RE 0.20674636941572672\n",
      "95 Train Loss 0.23434614 Test MSE 0.1864868785529115 Test RE 0.20641069689769143\n",
      "96 Train Loss 0.21988326 Test MSE 0.1555517380483806 Test RE 0.18851481850961824\n",
      "97 Train Loss 0.20679659 Test MSE 0.1549544677418826 Test RE 0.18815255128386138\n",
      "98 Train Loss 0.18280008 Test MSE 0.13418484233513225 Test RE 0.17508937416588882\n",
      "99 Train Loss 0.17184299 Test MSE 0.127322070158258 Test RE 0.17055321322267925\n",
      "Training time: 69.93\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "#for tune_reps in range(1,5):\n",
    "  max_reps = 10 #10\n",
    "  max_iter = 100 #100\n",
    "  label = \"KG_tanh_tune\"+str(tune_reps)\n",
    "\n",
    "  train_loss_full = []\n",
    "  test_mse_full = []\n",
    "  test_re_full = []\n",
    "\n",
    "  elapsed_time= np.zeros((max_reps,1))\n",
    "  time_threshold = np.empty((max_reps,1))\n",
    "  time_threshold[:] = np.nan\n",
    "  epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "  N_I = 200  #Total number of data points for 'y'\n",
    "  N_B = 400\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  for reps in range(max_reps):\n",
    "      print(reps)\n",
    "      print(label)\n",
    "\n",
    "      train_loss = []\n",
    "      test_mse_loss = []\n",
    "      test_re_loss = []\n",
    "\n",
    "      \n",
    "      torch.manual_seed(reps*36)\n",
    "\n",
    "      layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "      PINN = Sequentialmodel(layers)\n",
    "    \n",
    "      PINN.to(device)\n",
    "\n",
    "      'Neural Network Summary'\n",
    "      print(PINN)\n",
    "\n",
    "      params = list(PINN.parameters())\n",
    "      \n",
    "\n",
    "      optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "      train_model(max_iter,reps)\n",
    "      \n",
    "      torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "      train_loss_full.append(train_loss)\n",
    "      test_mse_full.append(test_mse_loss)\n",
    "      test_re_full.append(test_re_loss)\n",
    "      #elapsed_time[reps] = time.time() - start_time\n",
    "    \n",
    "\n",
    "\n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "      \n",
    "  mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label}\n",
    "  savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737439545138477\n",
      "0.6045129454552253\n",
      "0.5595302907178141\n",
      "0.47469131344146553\n",
      "0.45481459073362557\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"KG_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KG_tanh_tune4.mat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
