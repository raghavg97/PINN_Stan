{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1]).reshape(-1,1)\n",
    "n_value = np.array([1.0,3.0,5.0,8.0,10.0]).reshape(-1,1)\n",
    "\n",
    "LR_tune,N_value = np.meshgrid(lr_tune,n_value)\n",
    "\n",
    "LR_tune = LR_tune.flatten('F').reshape(-1,1)\n",
    "N_value = N_value.flatten('F').reshape(-1,1)\n",
    "\n",
    "lrn_tune = np.hstack((LR_tune,N_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "\n",
    "  xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "  xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "  xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "  y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "  f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "  nan_flag = 0\n",
    "    \n",
    "  for i in range(max_iter):\n",
    "    train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    \n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "  return nan_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_stan_tune0\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.821976 Test MSE 8.332439300210298 Test RE 1.3797301021666\n",
      "1 Train Loss 58.48656 Test MSE 8.725455882445857 Test RE 1.4118941011830908\n",
      "2 Train Loss 57.342484 Test MSE 8.666457715887905 Test RE 1.4071126632995081\n",
      "3 Train Loss 54.188377 Test MSE 7.4821596887800785 Test RE 1.307439334830723\n",
      "4 Train Loss 48.436172 Test MSE 7.631460673797282 Test RE 1.320419397185658\n",
      "5 Train Loss 41.784683 Test MSE 7.762630048532921 Test RE 1.331718720393585\n",
      "6 Train Loss 38.24668 Test MSE 7.502870671472267 Test RE 1.3092476122465777\n",
      "7 Train Loss 35.896614 Test MSE 7.356264912280947 Test RE 1.2963931886960087\n",
      "8 Train Loss 33.65513 Test MSE 6.992414988328687 Test RE 1.263926029315271\n",
      "9 Train Loss 30.470966 Test MSE 6.575242591642694 Test RE 1.225642891096973\n",
      "10 Train Loss 29.357655 Test MSE 6.13989496699348 Test RE 1.1843730898502598\n",
      "11 Train Loss 28.245447 Test MSE 6.23371987183507 Test RE 1.1933880958434147\n",
      "12 Train Loss 27.444448 Test MSE 6.48987014007759 Test RE 1.2176600671289988\n",
      "13 Train Loss 26.776405 Test MSE 6.363020182428846 Test RE 1.2057012485857292\n",
      "14 Train Loss 25.520035 Test MSE 6.322055842321204 Test RE 1.2018139038646134\n",
      "15 Train Loss 25.0411 Test MSE 6.27579963641174 Test RE 1.1974092124182207\n",
      "16 Train Loss 24.430578 Test MSE 6.194042554035818 Test RE 1.1895841051079865\n",
      "17 Train Loss 24.017706 Test MSE 6.146501857666556 Test RE 1.185010146318444\n",
      "18 Train Loss 23.512798 Test MSE 6.1128957111649 Test RE 1.1817661703966107\n",
      "19 Train Loss 23.150177 Test MSE 6.029259083640934 Test RE 1.173653865443204\n",
      "20 Train Loss 22.984612 Test MSE 6.0518215787176075 Test RE 1.1758478192747988\n",
      "21 Train Loss 22.85426 Test MSE 6.027982163246382 Test RE 1.1735295763809859\n",
      "22 Train Loss 22.699287 Test MSE 6.083230777688626 Test RE 1.1788952192497701\n",
      "23 Train Loss 22.248196 Test MSE 6.025967756669597 Test RE 1.1733334773248838\n",
      "24 Train Loss 21.76706 Test MSE 6.262700282364604 Test RE 1.196158895201798\n",
      "25 Train Loss 21.054956 Test MSE 6.1584115898907 Test RE 1.1861576546004655\n",
      "26 Train Loss 20.64785 Test MSE 6.233513947676329 Test RE 1.1933683845414733\n",
      "27 Train Loss 20.22202 Test MSE 6.216268479397813 Test RE 1.1917164711368835\n",
      "28 Train Loss 19.950323 Test MSE 6.2606857569660885 Test RE 1.1959664952641305\n",
      "29 Train Loss 19.49663 Test MSE 6.275822856669856 Test RE 1.1974114276040835\n",
      "30 Train Loss 19.178074 Test MSE 6.153199023785604 Test RE 1.1856555580794648\n",
      "31 Train Loss 18.590513 Test MSE 5.827240966999894 Test RE 1.1538239488002264\n",
      "32 Train Loss 17.386272 Test MSE 5.7751878248135755 Test RE 1.1486589925152633\n",
      "33 Train Loss 16.17574 Test MSE 5.792795415902392 Test RE 1.150408695395113\n",
      "34 Train Loss 15.588773 Test MSE 5.6781350179480095 Test RE 1.1389664144083969\n",
      "35 Train Loss 15.298172 Test MSE 5.703427290387164 Test RE 1.1415002605569486\n",
      "36 Train Loss 14.898594 Test MSE 5.6598224433691895 Test RE 1.1371282887439687\n",
      "37 Train Loss 14.6207905 Test MSE 5.644776621769241 Test RE 1.1356158371476304\n",
      "38 Train Loss 14.418372 Test MSE 5.685541711711067 Test RE 1.1397090196989137\n",
      "39 Train Loss 14.239538 Test MSE 5.6440049006973085 Test RE 1.1355382070937532\n",
      "40 Train Loss 14.038075 Test MSE 5.594663930615206 Test RE 1.130563765276543\n",
      "41 Train Loss 13.85693 Test MSE 5.6226317342466485 Test RE 1.1333860945350855\n",
      "42 Train Loss 13.70763 Test MSE 5.5582511401117625 Test RE 1.1268786302445424\n",
      "43 Train Loss 13.522919 Test MSE 5.676266456999412 Test RE 1.1387789934264048\n",
      "44 Train Loss 13.283493 Test MSE 5.771981270893936 Test RE 1.1483400636328747\n",
      "45 Train Loss 13.107269 Test MSE 5.838865526303602 Test RE 1.1549742369494016\n",
      "46 Train Loss 12.873196 Test MSE 5.943972015041359 Test RE 1.1653233222214745\n",
      "47 Train Loss 12.622318 Test MSE 6.007779197212389 Test RE 1.1715613657873398\n",
      "48 Train Loss 11.995719 Test MSE 5.958532893205007 Test RE 1.16674978855782\n",
      "49 Train Loss 11.517746 Test MSE 6.145101742413124 Test RE 1.184875171554322\n",
      "50 Train Loss 10.541064 Test MSE 6.0237903105131885 Test RE 1.1731214697758947\n",
      "51 Train Loss 9.695257 Test MSE 6.001343115156714 Test RE 1.1709336558321666\n",
      "52 Train Loss 8.6372795 Test MSE 5.8045777997058305 Test RE 1.1515780506381814\n",
      "53 Train Loss 7.584852 Test MSE 5.28177901075463 Test RE 1.0984952250894884\n",
      "54 Train Loss 6.335776 Test MSE 4.321574964672571 Test RE 0.9936400448285945\n",
      "55 Train Loss 5.001476 Test MSE 3.5745336280338935 Test RE 0.9036864154216032\n",
      "56 Train Loss 3.9741137 Test MSE 2.864663704514207 Test RE 0.8089932221589162\n",
      "57 Train Loss 3.2330754 Test MSE 2.460479376719634 Test RE 0.7497525040129561\n",
      "58 Train Loss 2.8663993 Test MSE 2.201960593309373 Test RE 0.7092720261701684\n",
      "59 Train Loss 2.5518835 Test MSE 2.026181684986336 Test RE 0.6803732855556754\n",
      "60 Train Loss 2.3168283 Test MSE 1.7941640147357807 Test RE 0.6402345857312135\n",
      "61 Train Loss 2.079526 Test MSE 1.5963948645075174 Test RE 0.6039183437214992\n",
      "62 Train Loss 1.8633485 Test MSE 1.2490902741069616 Test RE 0.5342013407324447\n",
      "63 Train Loss 1.599112 Test MSE 0.8972261383174338 Test RE 0.4527505836450455\n",
      "64 Train Loss 1.1632426 Test MSE 0.5938951822985196 Test RE 0.36835193993352416\n",
      "65 Train Loss 0.9967454 Test MSE 0.5401097128221374 Test RE 0.35127646519637823\n",
      "66 Train Loss 0.86559695 Test MSE 0.4425290582352008 Test RE 0.31796473597387787\n",
      "67 Train Loss 0.7060753 Test MSE 0.29673547798637134 Test RE 0.26037111166467225\n",
      "68 Train Loss 0.57505655 Test MSE 0.2294663145952938 Test RE 0.22896417238333172\n",
      "69 Train Loss 0.4950094 Test MSE 0.17927853890487885 Test RE 0.2023821532715354\n",
      "70 Train Loss 0.4364274 Test MSE 0.1915500707578688 Test RE 0.20919399735107588\n",
      "71 Train Loss 0.38620943 Test MSE 0.1422864179350392 Test RE 0.18029753258788872\n",
      "72 Train Loss 0.35367662 Test MSE 0.14996388720197673 Test RE 0.1850978630586943\n",
      "73 Train Loss 0.30291632 Test MSE 0.11040379495339443 Test RE 0.15881812380770474\n",
      "74 Train Loss 0.27142292 Test MSE 0.08740149188402004 Test RE 0.14130823867028675\n",
      "75 Train Loss 0.2345975 Test MSE 0.04772020930349551 Test RE 0.10441411942147255\n",
      "76 Train Loss 0.20743203 Test MSE 0.03532417362423271 Test RE 0.08983468837781217\n",
      "77 Train Loss 0.18431649 Test MSE 0.033498737418531065 Test RE 0.08748272039993442\n",
      "78 Train Loss 0.16021235 Test MSE 0.03601111904541689 Test RE 0.09070398522844796\n",
      "79 Train Loss 0.14269836 Test MSE 0.03731013203023445 Test RE 0.09232545427703306\n",
      "80 Train Loss 0.1246043 Test MSE 0.035983375644135514 Test RE 0.09066903877320165\n",
      "81 Train Loss 0.11080207 Test MSE 0.030115267906494887 Test RE 0.08294714182500934\n",
      "82 Train Loss 0.09699778 Test MSE 0.024186067002315022 Test RE 0.07433454476776805\n",
      "83 Train Loss 0.08024295 Test MSE 0.024866103702329348 Test RE 0.07537232819914254\n",
      "84 Train Loss 0.07112556 Test MSE 0.02441699818215705 Test RE 0.07468857881740917\n",
      "85 Train Loss 0.066193 Test MSE 0.020437786145105916 Test RE 0.0683321342618487\n",
      "86 Train Loss 0.0597554 Test MSE 0.021090118130016617 Test RE 0.06941407911372385\n",
      "87 Train Loss 0.05649124 Test MSE 0.01967652572222092 Test RE 0.06704745061950061\n",
      "88 Train Loss 0.05150755 Test MSE 0.015566370525714359 Test RE 0.05963507120526895\n",
      "89 Train Loss 0.049377948 Test MSE 0.014648842306570892 Test RE 0.057850845713399976\n",
      "90 Train Loss 0.044937585 Test MSE 0.013921671888991684 Test RE 0.056396708421953504\n",
      "91 Train Loss 0.04081434 Test MSE 0.013288283360482775 Test RE 0.055098845684167404\n",
      "92 Train Loss 0.033585634 Test MSE 0.01185629373974126 Test RE 0.05204542214509416\n",
      "93 Train Loss 0.03228061 Test MSE 0.011773201952669322 Test RE 0.051862728009539213\n",
      "94 Train Loss 0.031182887 Test MSE 0.011085719896260898 Test RE 0.050325721602825495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.030125553 Test MSE 0.011600532852510375 Test RE 0.05148100653333736\n",
      "96 Train Loss 0.028898705 Test MSE 0.01144841814601544 Test RE 0.051142364355503\n",
      "97 Train Loss 0.027251286 Test MSE 0.010759720715164086 Test RE 0.049580232571827705\n",
      "98 Train Loss 0.026501235 Test MSE 0.010465421848395143 Test RE 0.04889747459644461\n",
      "99 Train Loss 0.025563614 Test MSE 0.010000469452563976 Test RE 0.047798938719567294\n",
      "Training time: 70.69\n",
      "KG_stan_tune0\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.748535 Test MSE 8.589899942449588 Test RE 1.4008837991596452\n",
      "1 Train Loss 57.002678 Test MSE 8.8774309483688 Test RE 1.4241368094562037\n",
      "2 Train Loss 54.653454 Test MSE 8.44719630715281 Test RE 1.3891986537953238\n",
      "3 Train Loss 49.170334 Test MSE 9.400627069902637 Test RE 1.4655021921035845\n",
      "4 Train Loss 45.461807 Test MSE 8.282700761949275 Test RE 1.3756059511143022\n",
      "5 Train Loss 44.540993 Test MSE 8.443063218734208 Test RE 1.3888587550194385\n",
      "6 Train Loss 44.437103 Test MSE 8.503668118389054 Test RE 1.393834504667868\n",
      "7 Train Loss 44.299744 Test MSE 8.513647025164346 Test RE 1.3946520851698885\n",
      "8 Train Loss 44.165466 Test MSE 8.474330863898597 Test RE 1.3914280956791203\n",
      "9 Train Loss 44.05217 Test MSE 8.435398994333996 Test RE 1.3882282408545887\n",
      "10 Train Loss 43.962616 Test MSE 8.509861651567306 Test RE 1.3943420026565434\n",
      "11 Train Loss 43.790756 Test MSE 8.496089148901765 Test RE 1.3932132325379958\n",
      "12 Train Loss 43.480217 Test MSE 8.331608457347926 Test RE 1.3796613127375144\n",
      "13 Train Loss 41.654655 Test MSE 8.068964258743387 Test RE 1.357741073413736\n",
      "14 Train Loss 39.779663 Test MSE 7.548885370381927 Test RE 1.3132562477547134\n",
      "15 Train Loss 39.636814 Test MSE 7.707438522940267 Test RE 1.326976081779513\n",
      "16 Train Loss 39.407673 Test MSE 7.731301897057448 Test RE 1.3290287516583277\n",
      "17 Train Loss 39.070942 Test MSE 7.884703377970207 Test RE 1.342149024907005\n",
      "18 Train Loss 38.8424 Test MSE 7.768887915560916 Test RE 1.3322553967347552\n",
      "19 Train Loss 38.72049 Test MSE 7.745471312494326 Test RE 1.3302460718684592\n",
      "20 Train Loss 38.515358 Test MSE 7.76446366787031 Test RE 1.3318759944746967\n",
      "21 Train Loss 38.365482 Test MSE 7.88375133699629 Test RE 1.3420679933591202\n",
      "22 Train Loss 38.206417 Test MSE 7.932466338847776 Test RE 1.346208037619657\n",
      "23 Train Loss 38.043354 Test MSE 7.8894436901296965 Test RE 1.3425524167075455\n",
      "24 Train Loss 37.85548 Test MSE 7.897247483710902 Test RE 1.3432162412310962\n",
      "25 Train Loss 37.31997 Test MSE 7.993827081272689 Test RE 1.3514047312943058\n",
      "26 Train Loss 36.90343 Test MSE 8.062784917236925 Test RE 1.3572210839575423\n",
      "27 Train Loss 35.229553 Test MSE 8.261934261714078 Test RE 1.37388039985973\n",
      "28 Train Loss 33.32906 Test MSE 8.204954585753148 Test RE 1.3691346164854046\n",
      "29 Train Loss 31.345695 Test MSE 8.09788340972934 Test RE 1.3601719678618922\n",
      "30 Train Loss 30.70203 Test MSE 8.108517550881475 Test RE 1.3610647638225226\n",
      "31 Train Loss 29.716934 Test MSE 8.149050060110113 Test RE 1.3644623392400104\n",
      "32 Train Loss 28.709724 Test MSE 8.283050707673207 Test RE 1.3756350106173352\n",
      "33 Train Loss 27.749386 Test MSE 7.751005301901904 Test RE 1.3307212045569268\n",
      "34 Train Loss 26.173157 Test MSE 7.49208971536621 Test RE 1.3083066380660304\n",
      "35 Train Loss 23.695736 Test MSE 6.994066395192704 Test RE 1.2640752719518287\n",
      "36 Train Loss 22.44799 Test MSE 6.73742793560861 Test RE 1.2406667028895435\n",
      "37 Train Loss 21.642715 Test MSE 6.59552707534139 Test RE 1.2275319764115042\n",
      "38 Train Loss 20.733725 Test MSE 6.48541992942315 Test RE 1.2172425107716722\n",
      "39 Train Loss 19.638355 Test MSE 6.108252607831661 Test RE 1.1813172747310674\n",
      "40 Train Loss 19.01368 Test MSE 5.78592003088537 Test RE 1.1497257909895462\n",
      "41 Train Loss 18.732979 Test MSE 5.673130289031998 Test RE 1.1384643591796426\n",
      "42 Train Loss 18.407066 Test MSE 5.412050566850165 Test RE 1.1119595347274076\n",
      "43 Train Loss 17.884201 Test MSE 5.325662835526649 Test RE 1.1030492262201246\n",
      "44 Train Loss 17.675312 Test MSE 5.2706161961419635 Test RE 1.0973337997115653\n",
      "45 Train Loss 17.57182 Test MSE 5.229817238464345 Test RE 1.0930784100228048\n",
      "46 Train Loss 17.42794 Test MSE 5.149324912277871 Test RE 1.0846339851562852\n",
      "47 Train Loss 17.240072 Test MSE 5.068117830820928 Test RE 1.0760474235964037\n",
      "48 Train Loss 17.096994 Test MSE 5.068436741045767 Test RE 1.076081278090228\n",
      "49 Train Loss 16.909977 Test MSE 5.028310931273476 Test RE 1.071813252857791\n",
      "50 Train Loss 16.310745 Test MSE 4.470478581025068 Test RE 1.010613439847301\n",
      "51 Train Loss 14.697191 Test MSE 4.266839260124352 Test RE 0.9873274271270069\n",
      "52 Train Loss 13.453916 Test MSE 3.824076900879204 Test RE 0.9346981193709352\n",
      "53 Train Loss 10.968668 Test MSE 3.766340401808744 Test RE 0.9276151751236902\n",
      "54 Train Loss 9.952326 Test MSE 3.763917169869118 Test RE 0.9273167171837822\n",
      "55 Train Loss 8.144808 Test MSE 3.2882258577945866 Test RE 0.8667400812056408\n",
      "56 Train Loss 6.297913 Test MSE 3.1292114944424774 Test RE 0.8455231808526378\n",
      "57 Train Loss 5.166771 Test MSE 2.4612926834103086 Test RE 0.7498764083934731\n",
      "58 Train Loss 3.188501 Test MSE 1.9222601226589522 Test RE 0.66269567857105\n",
      "59 Train Loss 2.0794175 Test MSE 1.5219896571309248 Test RE 0.5896766227275005\n",
      "60 Train Loss 1.4370098 Test MSE 1.3690659096708333 Test RE 0.5592683448456655\n",
      "61 Train Loss 1.0635461 Test MSE 1.2444005935601434 Test RE 0.533197574402351\n",
      "62 Train Loss 0.8923283 Test MSE 1.1829508061322906 Test RE 0.5198659852651357\n",
      "63 Train Loss 0.7534298 Test MSE 1.080964025378194 Test RE 0.4969511279661179\n",
      "64 Train Loss 0.64216226 Test MSE 0.9097939499469425 Test RE 0.455910487443132\n",
      "65 Train Loss 0.5317796 Test MSE 0.7156501545525358 Test RE 0.40435092875700757\n",
      "66 Train Loss 0.48968855 Test MSE 0.6049347970668046 Test RE 0.3717597296451497\n",
      "67 Train Loss 0.4382483 Test MSE 0.47835163539728126 Test RE 0.3305838946328808\n",
      "68 Train Loss 0.38691816 Test MSE 0.3573922703065545 Test RE 0.2857463146897412\n",
      "69 Train Loss 0.3612092 Test MSE 0.3208809940358728 Test RE 0.27075722693543086\n",
      "70 Train Loss 0.31995207 Test MSE 0.2886410674905 Test RE 0.25679532986428455\n",
      "71 Train Loss 0.29359803 Test MSE 0.22537401786133462 Test RE 0.22691331675003137\n",
      "72 Train Loss 0.25922608 Test MSE 0.16968956629160684 Test RE 0.1968954272592162\n",
      "73 Train Loss 0.22242565 Test MSE 0.13617426109351552 Test RE 0.17638253252591962\n",
      "74 Train Loss 0.20044899 Test MSE 0.11871539216883936 Test RE 0.16468785613008466\n",
      "75 Train Loss 0.1853733 Test MSE 0.10722185941994282 Test RE 0.15651275188148123\n",
      "76 Train Loss 0.17150882 Test MSE 0.09549803847819119 Test RE 0.1477084313273643\n",
      "77 Train Loss 0.1577008 Test MSE 0.08078386069788868 Test RE 0.13585335324779765\n",
      "78 Train Loss 0.14548422 Test MSE 0.0764472395019862 Test RE 0.13215663260282212\n",
      "79 Train Loss 0.13499466 Test MSE 0.06744834846300563 Test RE 0.12413484900106825\n",
      "80 Train Loss 0.12491691 Test MSE 0.05672226548942441 Test RE 0.11383736758348033\n",
      "81 Train Loss 0.11891073 Test MSE 0.0553859916283712 Test RE 0.11248847474663294\n",
      "82 Train Loss 0.10740721 Test MSE 0.04592493535451331 Test RE 0.1024312180477425\n",
      "83 Train Loss 0.09753023 Test MSE 0.04029754282872918 Test RE 0.09595052228168147\n",
      "84 Train Loss 0.0908412 Test MSE 0.03410245689031863 Test RE 0.08826751388898903\n",
      "85 Train Loss 0.083223306 Test MSE 0.030127057579237126 Test RE 0.08296337651315147\n",
      "86 Train Loss 0.0781181 Test MSE 0.02741565993705328 Test RE 0.07914207132199115\n",
      "87 Train Loss 0.07234424 Test MSE 0.023339157171547154 Test RE 0.07302148229051136\n",
      "88 Train Loss 0.068312734 Test MSE 0.020161731280844808 Test RE 0.06786908143412118\n",
      "89 Train Loss 0.06561738 Test MSE 0.020134988103680074 Test RE 0.06782405461763992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 0.06316068 Test MSE 0.01979005885476237 Test RE 0.0672406035761226\n",
      "91 Train Loss 0.060739327 Test MSE 0.01808839913559294 Test RE 0.06428477475520117\n",
      "92 Train Loss 0.05781932 Test MSE 0.01772208195285973 Test RE 0.06363051387148334\n",
      "93 Train Loss 0.053257577 Test MSE 0.017679718464458986 Test RE 0.06355441605768364\n",
      "94 Train Loss 0.052204777 Test MSE 0.017225825842114444 Test RE 0.06273329316795886\n",
      "95 Train Loss 0.050146762 Test MSE 0.017473680884625756 Test RE 0.06318300254222248\n",
      "96 Train Loss 0.047353294 Test MSE 0.01710771500414247 Test RE 0.06251785425047651\n",
      "97 Train Loss 0.044706292 Test MSE 0.01567069882125498 Test RE 0.05983457935425925\n",
      "98 Train Loss 0.04392284 Test MSE 0.016021412232427548 Test RE 0.06050042950098734\n",
      "99 Train Loss 0.04188729 Test MSE 0.015234786806583361 Test RE 0.05899650043566611\n",
      "Training time: 71.51\n",
      "KG_stan_tune0\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.6366 Test MSE 8.406696838293177 Test RE 1.3858644465920047\n",
      "1 Train Loss 55.468174 Test MSE 8.502810380636355 Test RE 1.3937642070852114\n",
      "2 Train Loss 51.349926 Test MSE 8.311712115260972 Test RE 1.3780129742841802\n",
      "3 Train Loss 47.914345 Test MSE 8.30566221543404 Test RE 1.3775113713689866\n",
      "4 Train Loss 44.302128 Test MSE 7.467892917098533 Test RE 1.3061922457905442\n",
      "5 Train Loss 38.957188 Test MSE 7.3918729088742126 Test RE 1.2995269962632308\n",
      "6 Train Loss 38.534473 Test MSE 7.674073921738962 Test RE 1.3241008044806248\n",
      "7 Train Loss 37.543587 Test MSE 7.553623528591069 Test RE 1.3136683244704508\n",
      "8 Train Loss 36.246197 Test MSE 7.512451778328485 Test RE 1.310083294995066\n",
      "9 Train Loss 35.7725 Test MSE 7.496832432944802 Test RE 1.308720671230367\n",
      "10 Train Loss 35.30813 Test MSE 7.3644122442094195 Test RE 1.2971108914209608\n",
      "11 Train Loss 33.17278 Test MSE 7.060596636335785 Test RE 1.270073226324187\n",
      "12 Train Loss 30.298374 Test MSE 7.034001211220676 Test RE 1.2676789523323089\n",
      "13 Train Loss 28.816006 Test MSE 6.9382805532474885 Test RE 1.2590239414541502\n",
      "14 Train Loss 26.987179 Test MSE 6.729145767838042 Test RE 1.2399039066375057\n",
      "15 Train Loss 26.307167 Test MSE 6.429760228001227 Test RE 1.2120078962131489\n",
      "16 Train Loss 25.23553 Test MSE 6.282507951061328 Test RE 1.1980490075699168\n",
      "17 Train Loss 24.35144 Test MSE 6.286337849865539 Test RE 1.1984141250852605\n",
      "18 Train Loss 23.455463 Test MSE 6.159989391489249 Test RE 1.1863095932586238\n",
      "19 Train Loss 23.145445 Test MSE 6.210068127711498 Test RE 1.1911219903232915\n",
      "20 Train Loss 22.716276 Test MSE 6.120001703236932 Test RE 1.1824528483949701\n",
      "21 Train Loss 22.136013 Test MSE 6.217602602899996 Test RE 1.1918443462167128\n",
      "22 Train Loss 21.82426 Test MSE 6.019065527880712 Test RE 1.172661308402832\n",
      "23 Train Loss 21.45119 Test MSE 6.007370684848743 Test RE 1.1715215336444564\n",
      "24 Train Loss 21.136242 Test MSE 6.100719179517618 Test RE 1.1805885790457344\n",
      "25 Train Loss 20.565601 Test MSE 5.817596466863121 Test RE 1.1528687228587426\n",
      "26 Train Loss 19.867815 Test MSE 5.741099985786352 Test RE 1.1452640161642982\n",
      "27 Train Loss 19.537062 Test MSE 5.706074823404491 Test RE 1.1417651722350273\n",
      "28 Train Loss 19.045513 Test MSE 5.6095291678364685 Test RE 1.1320647445995928\n",
      "29 Train Loss 18.615124 Test MSE 5.676537727801785 Test RE 1.13880620442882\n",
      "30 Train Loss 18.072487 Test MSE 5.617736892880989 Test RE 1.1328926465076379\n",
      "31 Train Loss 17.754333 Test MSE 5.55062106952007 Test RE 1.1261049051930547\n",
      "32 Train Loss 16.517418 Test MSE 5.59472955205045 Test RE 1.1305703956121884\n",
      "33 Train Loss 15.278711 Test MSE 5.325715685862873 Test RE 1.1030546993771426\n",
      "34 Train Loss 14.448059 Test MSE 5.477519923787355 Test RE 1.1186649815791299\n",
      "35 Train Loss 13.804804 Test MSE 5.513711052225641 Test RE 1.1223545248525109\n",
      "36 Train Loss 12.836488 Test MSE 5.789774713791007 Test RE 1.1501087111158261\n",
      "37 Train Loss 12.215961 Test MSE 5.756342404846872 Test RE 1.1467833262971037\n",
      "38 Train Loss 11.784123 Test MSE 5.782281771162909 Test RE 1.1493642530834982\n",
      "39 Train Loss 11.286502 Test MSE 5.822375115630087 Test RE 1.1533421162845379\n",
      "40 Train Loss 10.715623 Test MSE 5.740552230339656 Test RE 1.1452093803307293\n",
      "41 Train Loss 10.30777 Test MSE 5.737263650139783 Test RE 1.1448813062824572\n",
      "42 Train Loss 9.861994 Test MSE 5.6591945522766425 Test RE 1.1370652114536368\n",
      "43 Train Loss 9.538816 Test MSE 5.6165033216480005 Test RE 1.1327682565146908\n",
      "44 Train Loss 9.352518 Test MSE 5.533073364800901 Test RE 1.1243234650102911\n",
      "45 Train Loss 8.999315 Test MSE 5.461340955983592 Test RE 1.1170116576843823\n",
      "46 Train Loss 8.870658 Test MSE 5.375476857580658 Test RE 1.1081959496460556\n",
      "47 Train Loss 8.714661 Test MSE 5.36745046311737 Test RE 1.1073682890611236\n",
      "48 Train Loss 8.5047455 Test MSE 5.30467508819603 Test RE 1.1008735935786444\n",
      "49 Train Loss 8.278226 Test MSE 5.2891144017513065 Test RE 1.0992577613662913\n",
      "50 Train Loss 8.095246 Test MSE 5.234560895021286 Test RE 1.0935740309087163\n",
      "51 Train Loss 7.905635 Test MSE 5.260007465064556 Test RE 1.0962288830771765\n",
      "52 Train Loss 7.6824656 Test MSE 5.2679506361019 Test RE 1.0970562819664722\n",
      "53 Train Loss 7.5874033 Test MSE 5.131858508572283 Test RE 1.082792894561489\n",
      "54 Train Loss 7.3146887 Test MSE 4.9878184427068994 Test RE 1.0674889265759226\n",
      "55 Train Loss 7.1131334 Test MSE 4.819639434485931 Test RE 1.049337841645863\n",
      "56 Train Loss 6.3046765 Test MSE 4.172606213098554 Test RE 0.9763640056748459\n",
      "57 Train Loss 6.1056137 Test MSE 3.771535406578644 Test RE 0.9282546957407303\n",
      "58 Train Loss 5.6810246 Test MSE 3.4737825226184977 Test RE 0.8908598232174209\n",
      "59 Train Loss 5.4520097 Test MSE 3.276341208831215 Test RE 0.8651723321275281\n",
      "60 Train Loss 5.1959796 Test MSE 3.053237956676857 Test RE 0.8351959633518072\n",
      "61 Train Loss 5.0937233 Test MSE 3.0437720757400917 Test RE 0.8339002892561493\n",
      "62 Train Loss 5.0103645 Test MSE 3.0380395149106025 Test RE 0.8331146461544985\n",
      "63 Train Loss 4.900965 Test MSE 2.9597868456145857 Test RE 0.8223151244846854\n",
      "64 Train Loss 4.7853427 Test MSE 2.9511120133315307 Test RE 0.8211091794817705\n",
      "65 Train Loss 4.6786575 Test MSE 2.78378656539002 Test RE 0.7974914352074595\n",
      "66 Train Loss 4.5656886 Test MSE 2.653723965761085 Test RE 0.7786386072823858\n",
      "67 Train Loss 4.3820906 Test MSE 2.4991246602951525 Test RE 0.7556175220843532\n",
      "68 Train Loss 4.0894957 Test MSE 2.4550291023108994 Test RE 0.748921645119372\n",
      "69 Train Loss 3.6984541 Test MSE 2.520198426628463 Test RE 0.7587966910032381\n",
      "70 Train Loss 3.4272647 Test MSE 2.3187701419175886 Test RE 0.7278416600339617\n",
      "71 Train Loss 3.100819 Test MSE 2.1436853672245015 Test RE 0.6998235967815974\n",
      "72 Train Loss 2.6434276 Test MSE 2.0871302609034967 Test RE 0.6905304555634428\n",
      "73 Train Loss 2.4268627 Test MSE 1.9505122394073373 Test RE 0.6675478480156155\n",
      "74 Train Loss 2.165742 Test MSE 1.9770447249521428 Test RE 0.672072781816299\n",
      "75 Train Loss 1.977371 Test MSE 1.842644990981133 Test RE 0.6488269725411892\n",
      "76 Train Loss 1.8492969 Test MSE 1.717162017667052 Test RE 0.626345118585561\n",
      "77 Train Loss 1.7545314 Test MSE 1.589560549995118 Test RE 0.6026242419660588\n",
      "78 Train Loss 1.6140784 Test MSE 1.3690651548564308 Test RE 0.5592681906734458\n",
      "79 Train Loss 1.4188708 Test MSE 1.0714836211466503 Test RE 0.49476711771475307\n",
      "80 Train Loss 1.3300273 Test MSE 0.9921025665819111 Test RE 0.4760870263530287\n",
      "81 Train Loss 1.2151785 Test MSE 0.8683105370295496 Test RE 0.445395265178526\n",
      "82 Train Loss 1.1477259 Test MSE 0.6936568753391654 Test RE 0.39808921135889114\n",
      "83 Train Loss 1.0592612 Test MSE 0.5382809484403098 Test RE 0.35068126520811627\n",
      "84 Train Loss 0.8923071 Test MSE 0.4253757642729894 Test RE 0.3117413641329564\n",
      "85 Train Loss 0.8034207 Test MSE 0.2933786841138612 Test RE 0.2588942103600172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.71386814 Test MSE 0.2157670798729949 Test RE 0.22202437299869646\n",
      "87 Train Loss 0.5979019 Test MSE 0.1615653530357754 Test RE 0.1921242465031551\n",
      "88 Train Loss 0.4917791 Test MSE 0.1268270232014912 Test RE 0.1702213222949173\n",
      "89 Train Loss 0.4279695 Test MSE 0.12460939073001488 Test RE 0.16872655780996382\n",
      "90 Train Loss 0.3950012 Test MSE 0.11615372229976395 Test RE 0.16290132854872597\n",
      "91 Train Loss 0.36246318 Test MSE 0.09319736630505554 Test RE 0.14591833990861594\n",
      "92 Train Loss 0.32803148 Test MSE 0.08116661492361504 Test RE 0.13617480977303667\n",
      "93 Train Loss 0.29827434 Test MSE 0.07301414339292364 Test RE 0.12915509924754648\n",
      "94 Train Loss 0.27424082 Test MSE 0.07525917899689447 Test RE 0.13112569359385312\n",
      "95 Train Loss 0.25114945 Test MSE 0.07297415441115665 Test RE 0.12911972604425362\n",
      "96 Train Loss 0.23031007 Test MSE 0.06595819034004355 Test RE 0.12275591451748535\n",
      "97 Train Loss 0.20965245 Test MSE 0.06820928883769554 Test RE 0.12483311882473694\n",
      "98 Train Loss 0.19672607 Test MSE 0.06806998677346249 Test RE 0.12470558195220627\n",
      "99 Train Loss 0.18541427 Test MSE 0.06842203265811977 Test RE 0.12502764364092794\n",
      "Training time: 71.08\n",
      "KG_stan_tune0\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.577522 Test MSE 8.53014352238063 Test RE 1.3960026074619203\n",
      "1 Train Loss 56.356663 Test MSE 8.638892461534716 Test RE 1.4048730914058778\n",
      "2 Train Loss 55.765892 Test MSE 8.373151415572039 Test RE 1.3830966604286477\n",
      "3 Train Loss 54.68233 Test MSE 8.715641600522297 Test RE 1.4110998375020634\n",
      "4 Train Loss 52.879723 Test MSE 8.255869969736395 Test RE 1.3733760905150019\n",
      "5 Train Loss 44.5859 Test MSE 8.948110193698655 Test RE 1.4297948291948495\n",
      "6 Train Loss 43.061245 Test MSE 8.523642865864746 Test RE 1.3954705728578556\n",
      "7 Train Loss 42.503525 Test MSE 8.561541284090588 Test RE 1.3985694515914093\n",
      "8 Train Loss 42.186905 Test MSE 8.539331758300738 Test RE 1.3967542565422464\n",
      "9 Train Loss 41.752975 Test MSE 8.425662062034059 Test RE 1.3874267975954657\n",
      "10 Train Loss 41.373383 Test MSE 8.256958983182862 Test RE 1.3734666670210043\n",
      "11 Train Loss 41.106064 Test MSE 8.313544651187815 Test RE 1.3781648755455222\n",
      "12 Train Loss 40.906044 Test MSE 8.313753886986655 Test RE 1.3781822183052244\n",
      "13 Train Loss 40.68992 Test MSE 8.261063422845117 Test RE 1.3738079918772725\n",
      "14 Train Loss 40.476723 Test MSE 8.433497198079811 Test RE 1.3880717410794203\n",
      "15 Train Loss 40.24696 Test MSE 8.57620615693067 Test RE 1.3997667283016468\n",
      "16 Train Loss 40.105705 Test MSE 8.5244486029453 Test RE 1.3955365279801224\n",
      "17 Train Loss 39.69613 Test MSE 8.735976436649805 Test RE 1.412745027132631\n",
      "18 Train Loss 39.222 Test MSE 8.823779136233911 Test RE 1.4198268173163306\n",
      "19 Train Loss 38.55794 Test MSE 8.994754506252786 Test RE 1.4335165709502753\n",
      "20 Train Loss 37.48269 Test MSE 9.347921109615609 Test RE 1.461388143668779\n",
      "21 Train Loss 34.020844 Test MSE 8.94773356277423 Test RE 1.4297647384492498\n",
      "22 Train Loss 32.569603 Test MSE 8.941858589115045 Test RE 1.4292952782570203\n",
      "23 Train Loss 32.200855 Test MSE 8.830867756681746 Test RE 1.4203970147738654\n",
      "24 Train Loss 31.6351 Test MSE 8.424725018044484 Test RE 1.3873496454333814\n",
      "25 Train Loss 31.47237 Test MSE 8.436977001194903 Test RE 1.3883580824453285\n",
      "26 Train Loss 31.182957 Test MSE 8.518786554467281 Test RE 1.3950729843326883\n",
      "27 Train Loss 30.962177 Test MSE 8.44703113586614 Test RE 1.3891850719604515\n",
      "28 Train Loss 30.632282 Test MSE 8.514620324645685 Test RE 1.394731802789945\n",
      "29 Train Loss 30.470913 Test MSE 8.694156516116022 Test RE 1.4093595005490318\n",
      "30 Train Loss 30.349682 Test MSE 8.567286383144612 Test RE 1.3990386178483631\n",
      "31 Train Loss 29.840515 Test MSE 8.520365630671188 Test RE 1.3952022764837382\n",
      "32 Train Loss 28.890442 Test MSE 8.041729633614233 Test RE 1.355447791233665\n",
      "33 Train Loss 27.25172 Test MSE 7.408769105239177 Test RE 1.301011365018334\n",
      "34 Train Loss 26.317394 Test MSE 7.122255059757635 Test RE 1.2756067875996915\n",
      "35 Train Loss 25.845295 Test MSE 7.037138073970593 Test RE 1.2679615860370008\n",
      "36 Train Loss 25.367031 Test MSE 7.1114803384409955 Test RE 1.2746415378545364\n",
      "37 Train Loss 24.932194 Test MSE 7.198899482922007 Test RE 1.2824519879152663\n",
      "38 Train Loss 24.712254 Test MSE 7.23068723588494 Test RE 1.2852802927042708\n",
      "39 Train Loss 24.299957 Test MSE 7.453585477948425 Test RE 1.3049404050173974\n",
      "40 Train Loss 23.948042 Test MSE 7.452584517717209 Test RE 1.3048527802555083\n",
      "41 Train Loss 23.346592 Test MSE 7.817800775232529 Test RE 1.3364427511488692\n",
      "42 Train Loss 22.449982 Test MSE 8.25188901127995 Test RE 1.3730449314472002\n",
      "43 Train Loss 21.945995 Test MSE 7.943623559611353 Test RE 1.347154443305773\n",
      "44 Train Loss 21.461124 Test MSE 7.661614693681281 Test RE 1.3230254971840532\n",
      "45 Train Loss 21.17334 Test MSE 7.527389635472503 Test RE 1.3113851415236413\n",
      "46 Train Loss 20.66351 Test MSE 7.459701968768351 Test RE 1.3054757191454232\n",
      "47 Train Loss 20.159893 Test MSE 7.376844626184408 Test RE 1.2982053017646906\n",
      "48 Train Loss 19.908037 Test MSE 7.40643798762399 Test RE 1.3008066718319091\n",
      "49 Train Loss 19.207043 Test MSE 7.513442543458662 Test RE 1.310169681043981\n",
      "50 Train Loss 18.822212 Test MSE 7.204158647160771 Test RE 1.2829203507723281\n",
      "51 Train Loss 18.382378 Test MSE 6.87948028495939 Test RE 1.2536776267744942\n",
      "52 Train Loss 17.681032 Test MSE 6.789531303999207 Test RE 1.245454762820941\n",
      "53 Train Loss 17.002995 Test MSE 6.339414893174408 Test RE 1.203462738350006\n",
      "54 Train Loss 16.261593 Test MSE 6.242821306052749 Test RE 1.1942589708436915\n",
      "55 Train Loss 15.7698145 Test MSE 6.280293877598553 Test RE 1.1978378815132271\n",
      "56 Train Loss 14.809411 Test MSE 5.887743732018413 Test RE 1.1597984117228852\n",
      "57 Train Loss 14.021477 Test MSE 5.899618735848902 Test RE 1.1609674226123077\n",
      "58 Train Loss 13.040283 Test MSE 6.015622137615452 Test RE 1.1723258320580636\n",
      "59 Train Loss 12.715379 Test MSE 6.1203442940500485 Test RE 1.1824859441221764\n",
      "60 Train Loss 12.4127655 Test MSE 5.911661085840049 Test RE 1.1621517066746034\n",
      "61 Train Loss 11.9835825 Test MSE 6.229510895814598 Test RE 1.192985143021152\n",
      "62 Train Loss 11.531305 Test MSE 6.165541389701444 Test RE 1.1868440832482023\n",
      "63 Train Loss 11.069523 Test MSE 6.116553913553523 Test RE 1.1821197256869262\n",
      "64 Train Loss 10.49699 Test MSE 5.968270362219229 Test RE 1.1677027540172022\n",
      "65 Train Loss 10.288203 Test MSE 5.8883091981445155 Test RE 1.1598541046163726\n",
      "66 Train Loss 9.855243 Test MSE 5.784386446063697 Test RE 1.149573410826631\n",
      "67 Train Loss 9.428137 Test MSE 5.906174941605629 Test RE 1.1616123310505488\n",
      "68 Train Loss 9.098283 Test MSE 5.851688976208692 Test RE 1.1562418317579124\n",
      "69 Train Loss 8.926725 Test MSE 5.8455149541892055 Test RE 1.1556317047908187\n",
      "70 Train Loss 8.667468 Test MSE 5.835057634631112 Test RE 1.1545975598321776\n",
      "71 Train Loss 8.328373 Test MSE 5.936233006610414 Test RE 1.1645644538760898\n",
      "72 Train Loss 8.071234 Test MSE 5.871288377777342 Test RE 1.1581765470410887\n",
      "73 Train Loss 7.937359 Test MSE 5.848553477788971 Test RE 1.1559320169140193\n",
      "74 Train Loss 7.872093 Test MSE 5.814983091634915 Test RE 1.1526097484682447\n",
      "75 Train Loss 7.691848 Test MSE 5.844329934809711 Test RE 1.1555145623843757\n",
      "76 Train Loss 7.574937 Test MSE 5.849300957301883 Test RE 1.1560058820072256\n",
      "77 Train Loss 7.4985085 Test MSE 5.806280714392038 Test RE 1.151746960026066\n",
      "78 Train Loss 7.4236016 Test MSE 5.842857230962675 Test RE 1.155368965029507\n",
      "79 Train Loss 7.3566017 Test MSE 5.854615960983933 Test RE 1.1565309687194771\n",
      "80 Train Loss 7.312993 Test MSE 5.854561469641581 Test RE 1.1565255865499195\n",
      "81 Train Loss 7.2795773 Test MSE 5.868341674887189 Test RE 1.1578858757034163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 7.2586555 Test MSE 5.8771574143981375 Test RE 1.158755268633843\n",
      "83 Train Loss 7.2305098 Test MSE 5.855562600615305 Test RE 1.1566244653557358\n",
      "84 Train Loss 7.205329 Test MSE 5.8367242816481975 Test RE 1.1547624398822902\n",
      "85 Train Loss 7.1610785 Test MSE 5.8572648541926835 Test RE 1.156792572606732\n",
      "86 Train Loss 7.134964 Test MSE 5.890726053546409 Test RE 1.160092111145892\n",
      "87 Train Loss 7.0911093 Test MSE 5.946389806486192 Test RE 1.1655603036789124\n",
      "88 Train Loss 7.0727015 Test MSE 5.953800830522081 Test RE 1.1662864001832907\n",
      "89 Train Loss 7.048956 Test MSE 5.997656202409717 Test RE 1.1705739202365273\n",
      "90 Train Loss 7.0156775 Test MSE 6.025873057384727 Test RE 1.1733242577038825\n",
      "91 Train Loss 7.002407 Test MSE 6.012343961540649 Test RE 1.1720063626734847\n",
      "92 Train Loss 6.9798403 Test MSE 6.009837351504808 Test RE 1.1717620262558144\n",
      "93 Train Loss 6.9442215 Test MSE 6.045540352049675 Test RE 1.1752374506433634\n",
      "94 Train Loss 6.910099 Test MSE 5.998943847859607 Test RE 1.1706995695935192\n",
      "95 Train Loss 6.8793125 Test MSE 6.004313888139661 Test RE 1.1712234366045404\n",
      "96 Train Loss 6.847876 Test MSE 6.005266527298928 Test RE 1.171316345559514\n",
      "97 Train Loss 6.8211308 Test MSE 6.015696834403542 Test RE 1.1723331104991306\n",
      "98 Train Loss 6.7495985 Test MSE 6.077361267552809 Test RE 1.1783263433016211\n",
      "99 Train Loss 6.693088 Test MSE 6.143570184904437 Test RE 1.1847275078030344\n",
      "Training time: 72.01\n",
      "KG_stan_tune0\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.50105 Test MSE 8.438843854245373 Test RE 1.3885116752049964\n",
      "1 Train Loss 57.09606 Test MSE 8.590624476520972 Test RE 1.4009428782320088\n",
      "2 Train Loss 56.31574 Test MSE 8.586667822898422 Test RE 1.4006202192607256\n",
      "3 Train Loss 52.726543 Test MSE 8.08446379811067 Test RE 1.3590444789250904\n",
      "4 Train Loss 48.174156 Test MSE 8.541847784704846 Test RE 1.3969600110360505\n",
      "5 Train Loss 47.023773 Test MSE 8.053237879024874 Test RE 1.3564173120821514\n",
      "6 Train Loss 45.305637 Test MSE 8.026712389454316 Test RE 1.3541816082676346\n",
      "7 Train Loss 44.68048 Test MSE 8.127119061612236 Test RE 1.3626250587249413\n",
      "8 Train Loss 44.560482 Test MSE 8.126258048814655 Test RE 1.362552876400507\n",
      "9 Train Loss 44.14849 Test MSE 8.236093300483994 Test RE 1.3717301652509655\n",
      "10 Train Loss 44.0633 Test MSE 8.05054959860384 Test RE 1.356190897904687\n",
      "11 Train Loss 42.97763 Test MSE 7.415829181975299 Test RE 1.3016311071609585\n",
      "12 Train Loss 40.4833 Test MSE 7.075929773099112 Test RE 1.2714515549670156\n",
      "13 Train Loss 39.101433 Test MSE 7.070057159942848 Test RE 1.2709238297596308\n",
      "14 Train Loss 36.535126 Test MSE 6.814388232222068 Test RE 1.2477325265587875\n",
      "15 Train Loss 36.33003 Test MSE 6.738674525505813 Test RE 1.240781474510044\n",
      "16 Train Loss 35.36306 Test MSE 6.769380795997521 Test RE 1.2436052099135517\n",
      "17 Train Loss 33.928562 Test MSE 7.074979621218998 Test RE 1.271366187200397\n",
      "18 Train Loss 32.326164 Test MSE 6.742014382640053 Test RE 1.2410889177245354\n",
      "19 Train Loss 29.742172 Test MSE 6.590278246697633 Test RE 1.2270434341526528\n",
      "20 Train Loss 28.95337 Test MSE 6.588118687866078 Test RE 1.2268423736280034\n",
      "21 Train Loss 27.884438 Test MSE 6.4326315061365875 Test RE 1.2122784835466194\n",
      "22 Train Loss 27.546452 Test MSE 6.477852118557011 Test RE 1.2165321057331275\n",
      "23 Train Loss 27.403605 Test MSE 6.377061578269587 Test RE 1.2070308372492609\n",
      "24 Train Loss 27.306993 Test MSE 6.329038282975936 Test RE 1.2024773967781763\n",
      "25 Train Loss 27.086712 Test MSE 6.331640118217071 Test RE 1.2027245375325064\n",
      "26 Train Loss 26.89225 Test MSE 6.288704692288293 Test RE 1.1986397087655865\n",
      "27 Train Loss 26.753477 Test MSE 6.248538693441651 Test RE 1.1948057171160817\n",
      "28 Train Loss 26.133568 Test MSE 6.039334533451328 Test RE 1.1746340982023533\n",
      "29 Train Loss 25.90139 Test MSE 5.982545331198076 Test RE 1.1690983815824951\n",
      "30 Train Loss 25.643375 Test MSE 5.850034188737952 Test RE 1.156078334535977\n",
      "31 Train Loss 25.429611 Test MSE 5.713160314875522 Test RE 1.1424738430620365\n",
      "32 Train Loss 24.854065 Test MSE 5.682570105155646 Test RE 1.1394111404805622\n",
      "33 Train Loss 24.703903 Test MSE 5.555258522303161 Test RE 1.1265752280577306\n",
      "34 Train Loss 24.608364 Test MSE 5.523525681953427 Test RE 1.1233529990499884\n",
      "35 Train Loss 24.410736 Test MSE 5.540117501041164 Test RE 1.1250389234952636\n",
      "36 Train Loss 24.13745 Test MSE 5.521159451802532 Test RE 1.123112355969059\n",
      "37 Train Loss 24.003992 Test MSE 5.524319001098887 Test RE 1.123433667222449\n",
      "38 Train Loss 23.859793 Test MSE 5.476740852435705 Test RE 1.1185854245129043\n",
      "39 Train Loss 23.6143 Test MSE 5.307980093890095 Test RE 1.1012164823416992\n",
      "40 Train Loss 23.414833 Test MSE 5.176055895578757 Test RE 1.0874455967277075\n",
      "41 Train Loss 23.141415 Test MSE 5.198706985856943 Test RE 1.0898224005786248\n",
      "42 Train Loss 22.77259 Test MSE 5.141248154644136 Test RE 1.0837830227655048\n",
      "43 Train Loss 22.68624 Test MSE 5.1263300247417956 Test RE 1.082209498109421\n",
      "44 Train Loss 22.120256 Test MSE 4.8228875456688405 Test RE 1.0496913734780446\n",
      "45 Train Loss 21.922758 Test MSE 4.724516030714718 Test RE 1.0389310446041162\n",
      "46 Train Loss 21.595982 Test MSE 4.477183017494478 Test RE 1.0113709711743042\n",
      "47 Train Loss 21.431435 Test MSE 4.4878965475558905 Test RE 1.0125803118442727\n",
      "48 Train Loss 21.17315 Test MSE 4.570091086868212 Test RE 1.0218107993036667\n",
      "49 Train Loss 20.834442 Test MSE 4.523710878041287 Test RE 1.0166125820295513\n",
      "50 Train Loss 20.547485 Test MSE 4.351844220273781 Test RE 0.9971138087171763\n",
      "51 Train Loss 20.146461 Test MSE 3.7706047440826485 Test RE 0.9281401608048361\n",
      "52 Train Loss 19.70572 Test MSE 3.6148438133447027 Test RE 0.908767587716842\n",
      "53 Train Loss 19.420002 Test MSE 3.460972506171925 Test RE 0.889215726459503\n",
      "54 Train Loss 18.999207 Test MSE 3.469089165181212 Test RE 0.890257808444994\n",
      "55 Train Loss 18.629267 Test MSE 3.3713787383222287 Test RE 0.8776307513071927\n",
      "56 Train Loss 18.302296 Test MSE 3.298562505954809 Test RE 0.8681013255090311\n",
      "57 Train Loss 18.169044 Test MSE 3.3509999007273876 Test RE 0.8749742411279847\n",
      "58 Train Loss 17.90567 Test MSE 3.2134736579922496 Test RE 0.856831516052616\n",
      "59 Train Loss 17.80275 Test MSE 3.0449448387617712 Test RE 0.8340609243520593\n",
      "60 Train Loss 17.51716 Test MSE 2.870230276260536 Test RE 0.8097788524641153\n",
      "61 Train Loss 17.373356 Test MSE 2.9823721519996735 Test RE 0.8254465904725055\n",
      "62 Train Loss 17.261353 Test MSE 2.973886941002846 Test RE 0.8242715061604556\n",
      "63 Train Loss 17.2007 Test MSE 3.0158485251891833 Test RE 0.8300663772792617\n",
      "64 Train Loss 17.082317 Test MSE 2.957799004415766 Test RE 0.8220389379682713\n",
      "65 Train Loss 16.84283 Test MSE 2.846108995750834 Test RE 0.8063690015601345\n",
      "66 Train Loss 16.750546 Test MSE 2.906085930621237 Test RE 0.8148211367448077\n",
      "67 Train Loss 16.58444 Test MSE 2.941967497271579 Test RE 0.8198360201143114\n",
      "68 Train Loss 16.433226 Test MSE 2.976639189219881 Test RE 0.8246528379309116\n",
      "69 Train Loss 16.058966 Test MSE 2.921823427282277 Test RE 0.8170244320802716\n",
      "70 Train Loss 15.999697 Test MSE 2.9224419863319504 Test RE 0.8171109108022347\n",
      "71 Train Loss 15.898382 Test MSE 2.938931136426731 Test RE 0.8194128406227543\n",
      "72 Train Loss 15.769243 Test MSE 2.905681061595343 Test RE 0.8147643752899392\n",
      "73 Train Loss 15.710283 Test MSE 2.870740245088211 Test RE 0.8098507880913425\n",
      "74 Train Loss 15.641796 Test MSE 2.8913899931612277 Test RE 0.8127582697396742\n",
      "75 Train Loss 15.140808 Test MSE 2.701388364231869 Test RE 0.7856001771688583\n",
      "76 Train Loss 14.944981 Test MSE 2.7093492685299223 Test RE 0.7867568947733703\n",
      "77 Train Loss 14.792078 Test MSE 2.731309467036976 Test RE 0.789938926207635\n",
      "78 Train Loss 14.663067 Test MSE 2.6752589020111315 Test RE 0.7817915448950588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Train Loss 14.469309 Test MSE 2.553428651334623 Test RE 0.7637828876006514\n",
      "80 Train Loss 14.311604 Test MSE 2.4648089401305393 Test RE 0.7504118621649086\n",
      "81 Train Loss 14.152171 Test MSE 2.4963631758980793 Test RE 0.7551999353249613\n",
      "82 Train Loss 13.854346 Test MSE 2.428337019808385 Test RE 0.7448392268402277\n",
      "83 Train Loss 13.475353 Test MSE 2.2358345329795832 Test RE 0.7147067603965558\n",
      "84 Train Loss 13.06147 Test MSE 2.2501996824263193 Test RE 0.7169990657928778\n",
      "85 Train Loss 12.683003 Test MSE 2.095069337576675 Test RE 0.6918425372574835\n",
      "86 Train Loss 12.10176 Test MSE 2.0097355488711615 Test RE 0.6776064285267682\n",
      "87 Train Loss 11.425713 Test MSE 1.9965834092993775 Test RE 0.6753855884019414\n",
      "88 Train Loss 10.949495 Test MSE 2.003454272485591 Test RE 0.6765466960406863\n",
      "89 Train Loss 10.870499 Test MSE 2.003636379763035 Test RE 0.6765774432553818\n",
      "90 Train Loss 10.538029 Test MSE 2.0119144690160318 Test RE 0.677973653540435\n",
      "91 Train Loss 10.383158 Test MSE 1.9681067026491768 Test RE 0.6705518738440659\n",
      "92 Train Loss 10.136199 Test MSE 1.930207168735395 Test RE 0.664064130494764\n",
      "93 Train Loss 10.037766 Test MSE 1.9327119745204036 Test RE 0.6644948646731411\n",
      "94 Train Loss 9.891515 Test MSE 1.8738811632491572 Test RE 0.6543032583990859\n",
      "95 Train Loss 9.584807 Test MSE 1.7405139482913792 Test RE 0.6305896151340062\n",
      "96 Train Loss 9.120977 Test MSE 1.6889498223154313 Test RE 0.6211785259888212\n",
      "97 Train Loss 8.649981 Test MSE 1.6295544682400602 Test RE 0.6101582685736857\n",
      "98 Train Loss 8.09022 Test MSE 1.5028237564287765 Test RE 0.5859520609628183\n",
      "99 Train Loss 7.804082 Test MSE 1.4447296015408302 Test RE 0.5745149652912388\n",
      "Training time: 72.76\n",
      "KG_stan_tune0\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.867065 Test MSE 8.638192617764531 Test RE 1.4048161852921366\n",
      "1 Train Loss 57.24247 Test MSE 8.36997471008571 Test RE 1.382834267731865\n",
      "2 Train Loss 53.44906 Test MSE 9.50638591218525 Test RE 1.4737227253078968\n",
      "3 Train Loss 47.998825 Test MSE 8.837499470048291 Test RE 1.4209302521816252\n",
      "4 Train Loss 46.2799 Test MSE 8.956542046174585 Test RE 1.43046832226105\n",
      "5 Train Loss 45.872482 Test MSE 8.65615435391157 Test RE 1.4062759718139901\n",
      "6 Train Loss 45.50788 Test MSE 8.70969359845153 Test RE 1.4106182517725678\n",
      "7 Train Loss 45.354702 Test MSE 8.662331973449286 Test RE 1.4067776893279238\n",
      "8 Train Loss 45.13423 Test MSE 8.580652971592059 Test RE 1.4001295750222449\n",
      "9 Train Loss 44.900455 Test MSE 8.536203183324776 Test RE 1.3964983670382607\n",
      "10 Train Loss 44.78368 Test MSE 8.556501575024031 Test RE 1.398157760491298\n",
      "11 Train Loss 44.593315 Test MSE 8.489136049966374 Test RE 1.3926430212297278\n",
      "12 Train Loss 44.439644 Test MSE 8.366244327917395 Test RE 1.3825260783185758\n",
      "13 Train Loss 44.361977 Test MSE 8.259765362664542 Test RE 1.3737000544716322\n",
      "14 Train Loss 44.262398 Test MSE 8.435941516924201 Test RE 1.3882728820785715\n",
      "15 Train Loss 44.243156 Test MSE 8.467822077033032 Test RE 1.3908936435370776\n",
      "16 Train Loss 44.199226 Test MSE 8.484428666300424 Test RE 1.3922568444716241\n",
      "17 Train Loss 44.095757 Test MSE 8.445464989130652 Test RE 1.3890562830116295\n",
      "18 Train Loss 43.975883 Test MSE 8.45572845522102 Test RE 1.3899000614978019\n",
      "19 Train Loss 43.650345 Test MSE 8.431981230001622 Test RE 1.3879469786604344\n",
      "20 Train Loss 43.35901 Test MSE 8.219649420802043 Test RE 1.3703601081665409\n",
      "21 Train Loss 43.09384 Test MSE 8.44670260240293 Test RE 1.3891580566568995\n",
      "22 Train Loss 42.796925 Test MSE 8.466242879443937 Test RE 1.3907639408646297\n",
      "23 Train Loss 42.44359 Test MSE 8.628607372290237 Test RE 1.404036551976248\n",
      "24 Train Loss 42.34842 Test MSE 8.686294460449995 Test RE 1.4087221202032334\n",
      "25 Train Loss 42.135612 Test MSE 8.733697356732318 Test RE 1.4125607335469723\n",
      "26 Train Loss 41.846725 Test MSE 8.71933604883015 Test RE 1.4113988793458543\n",
      "27 Train Loss 41.662766 Test MSE 8.781807115249995 Test RE 1.4164459509369558\n",
      "28 Train Loss 40.996544 Test MSE 8.625112995801087 Test RE 1.4037522228294763\n",
      "29 Train Loss 39.232346 Test MSE 8.74510731092134 Test RE 1.413483137428481\n",
      "30 Train Loss 37.830772 Test MSE 8.250418864974636 Test RE 1.3729226160085752\n",
      "31 Train Loss 36.599857 Test MSE 8.503488930539074 Test RE 1.3938198192685571\n",
      "32 Train Loss 35.082954 Test MSE 8.296135329332543 Test RE 1.3767211177440337\n",
      "33 Train Loss 33.557026 Test MSE 8.187303462765916 Test RE 1.3676611302769428\n",
      "34 Train Loss 32.33459 Test MSE 7.965355384816331 Test RE 1.3489959284237845\n",
      "35 Train Loss 31.739866 Test MSE 8.064897720207938 Test RE 1.3573988980092144\n",
      "36 Train Loss 31.090088 Test MSE 7.987944824574801 Test RE 1.3509074242870178\n",
      "37 Train Loss 29.917074 Test MSE 7.610289773289772 Test RE 1.3185865971904156\n",
      "38 Train Loss 27.852982 Test MSE 6.859240640050542 Test RE 1.2518320890874186\n",
      "39 Train Loss 25.689308 Test MSE 6.5203538001093015 Test RE 1.220516460943959\n",
      "40 Train Loss 24.928864 Test MSE 6.337194855320776 Test RE 1.2032519959685628\n",
      "41 Train Loss 24.0606 Test MSE 6.258846379898019 Test RE 1.1957907960650829\n",
      "42 Train Loss 23.472443 Test MSE 6.17284706675771 Test RE 1.1875470330816749\n",
      "43 Train Loss 23.180996 Test MSE 6.014908020015665 Test RE 1.1722562462914423\n",
      "44 Train Loss 22.66905 Test MSE 5.94314357339955 Test RE 1.1652421108694988\n",
      "45 Train Loss 21.479507 Test MSE 6.144266498607387 Test RE 1.1847946445492306\n",
      "46 Train Loss 20.687817 Test MSE 5.790900376392906 Test RE 1.1502205092001916\n",
      "47 Train Loss 20.412218 Test MSE 5.584903776899775 Test RE 1.1295771740340776\n",
      "48 Train Loss 19.971542 Test MSE 5.690589005655922 Test RE 1.1402147912348537\n",
      "49 Train Loss 19.682968 Test MSE 5.609442626030628 Test RE 1.1320560120213088\n",
      "50 Train Loss 19.424915 Test MSE 5.72084499728614 Test RE 1.1432419466892945\n",
      "51 Train Loss 19.218184 Test MSE 5.723579040846012 Test RE 1.143515096890491\n",
      "52 Train Loss 18.91685 Test MSE 5.606614698803172 Test RE 1.1317706204220837\n",
      "53 Train Loss 18.706516 Test MSE 5.476802975857382 Test RE 1.118591768628759\n",
      "54 Train Loss 18.608604 Test MSE 5.461177007066745 Test RE 1.1169948912686531\n",
      "55 Train Loss 18.486439 Test MSE 5.456710235263869 Test RE 1.1165379950801517\n",
      "56 Train Loss 18.45168 Test MSE 5.427449049428993 Test RE 1.1135402967037975\n",
      "57 Train Loss 18.355791 Test MSE 5.478646531806129 Test RE 1.118780018325575\n",
      "58 Train Loss 18.228722 Test MSE 5.451427773287582 Test RE 1.11599742233825\n",
      "59 Train Loss 18.095146 Test MSE 5.38569251664102 Test RE 1.1092484682188064\n",
      "60 Train Loss 17.909534 Test MSE 5.382833989740885 Test RE 1.1089540550653125\n",
      "61 Train Loss 17.706356 Test MSE 5.422754264210081 Test RE 1.1130585820441043\n",
      "62 Train Loss 17.544296 Test MSE 5.406146008729502 Test RE 1.111352794142128\n",
      "63 Train Loss 17.308609 Test MSE 5.528491532544409 Test RE 1.123857853217578\n",
      "64 Train Loss 17.173502 Test MSE 5.505000405902353 Test RE 1.1214676178749763\n",
      "65 Train Loss 16.983467 Test MSE 5.532538613867283 Test RE 1.1242691328597485\n",
      "66 Train Loss 16.749218 Test MSE 5.651132354301039 Test RE 1.1362549802407413\n",
      "67 Train Loss 16.612122 Test MSE 5.668160815873804 Test RE 1.1379656215084244\n",
      "68 Train Loss 16.513264 Test MSE 5.606387568862585 Test RE 1.1317476955725023\n",
      "69 Train Loss 15.9657955 Test MSE 5.693701307156592 Test RE 1.1405265522073618\n",
      "70 Train Loss 15.7103615 Test MSE 5.653534524888104 Test RE 1.1364964529335886\n",
      "71 Train Loss 15.575808 Test MSE 5.744877069289474 Test RE 1.1456406901976026\n",
      "72 Train Loss 15.405292 Test MSE 5.75256315546458 Test RE 1.1464068118839212\n",
      "73 Train Loss 15.216088 Test MSE 5.7276697885890036 Test RE 1.1439236695889416\n",
      "74 Train Loss 15.0249 Test MSE 5.826837411935158 Test RE 1.1537839951100595\n",
      "75 Train Loss 14.883558 Test MSE 5.7913096075618755 Test RE 1.1502611503559093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 14.679561 Test MSE 5.929796713707819 Test RE 1.1639329497939104\n",
      "77 Train Loss 14.428116 Test MSE 5.857896806305016 Test RE 1.1568549752648642\n",
      "78 Train Loss 14.001625 Test MSE 5.896006690780691 Test RE 1.1606119667006067\n",
      "79 Train Loss 13.765 Test MSE 5.775531079269648 Test RE 1.1486931278950268\n",
      "80 Train Loss 13.19087 Test MSE 5.199795087838151 Test RE 1.0899364458473104\n",
      "81 Train Loss 11.956377 Test MSE 4.7485335513654565 Test RE 1.041568448716246\n",
      "82 Train Loss 11.328294 Test MSE 4.539116163268017 Test RE 1.0183421240462383\n",
      "83 Train Loss 11.016161 Test MSE 4.503516243847444 Test RE 1.0143408759503003\n",
      "84 Train Loss 10.444697 Test MSE 4.526159308882305 Test RE 1.0168876624838643\n",
      "85 Train Loss 10.193079 Test MSE 4.594859573653905 Test RE 1.0245760077054011\n",
      "86 Train Loss 10.031834 Test MSE 4.569359583380688 Test RE 1.0217290188684844\n",
      "87 Train Loss 9.921604 Test MSE 4.534112086995564 Test RE 1.0177806417317967\n",
      "88 Train Loss 9.835505 Test MSE 4.476265639114263 Test RE 1.0112673505057026\n",
      "89 Train Loss 9.687365 Test MSE 4.432539602850609 Test RE 1.0063159877169583\n",
      "90 Train Loss 9.582431 Test MSE 4.428989602401003 Test RE 1.0059129300908942\n",
      "91 Train Loss 9.447033 Test MSE 4.458751747734145 Test RE 1.0092870631158184\n",
      "92 Train Loss 9.407349 Test MSE 4.403349779649335 Test RE 1.0029970432612958\n",
      "93 Train Loss 9.346561 Test MSE 4.32743470429178 Test RE 0.9943134682460901\n",
      "94 Train Loss 9.2774 Test MSE 4.209826525773629 Test RE 0.9807089989767432\n",
      "95 Train Loss 9.220149 Test MSE 4.154299468725676 Test RE 0.9742198188684054\n",
      "96 Train Loss 9.112941 Test MSE 3.9777484731171935 Test RE 0.9532936916759569\n",
      "97 Train Loss 9.000631 Test MSE 3.8728713467180738 Test RE 0.9406424964513852\n",
      "98 Train Loss 8.822694 Test MSE 3.7503634534897636 Test RE 0.9256455960651163\n",
      "99 Train Loss 8.759599 Test MSE 3.690690194040591 Test RE 0.9182519425204991\n",
      "Training time: 71.77\n",
      "KG_stan_tune0\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.12932 Test MSE 8.403846806470902 Test RE 1.385629509334968\n",
      "1 Train Loss 58.70488 Test MSE 8.579413662824734 Test RE 1.400028460601133\n",
      "2 Train Loss 58.10164 Test MSE 8.646298174363725 Test RE 1.405475127948475\n",
      "3 Train Loss 55.760357 Test MSE 8.417743438282693 Test RE 1.3867746771290235\n",
      "4 Train Loss 48.640198 Test MSE 8.585200049349137 Test RE 1.4005005056993776\n",
      "5 Train Loss 48.372116 Test MSE 8.936683059114625 Test RE 1.4288815817518346\n",
      "6 Train Loss 47.68354 Test MSE 8.671653861010212 Test RE 1.4075344311210563\n",
      "7 Train Loss 47.226562 Test MSE 8.59462641195511 Test RE 1.4012691542884865\n",
      "8 Train Loss 47.052757 Test MSE 8.601292066671517 Test RE 1.4018124336350393\n",
      "9 Train Loss 46.850777 Test MSE 8.576634278559984 Test RE 1.399801665832459\n",
      "10 Train Loss 46.706123 Test MSE 8.62319552050126 Test RE 1.4035961779272177\n",
      "11 Train Loss 46.582268 Test MSE 8.574967589830464 Test RE 1.399665648197845\n",
      "12 Train Loss 46.218338 Test MSE 8.447371763919861 Test RE 1.3892130812473467\n",
      "13 Train Loss 46.00112 Test MSE 8.458752435403632 Test RE 1.390148570810394\n",
      "14 Train Loss 45.768852 Test MSE 8.347423013217782 Test RE 1.3809700868529182\n",
      "15 Train Loss 45.47177 Test MSE 8.236542215209038 Test RE 1.3717675483558371\n",
      "16 Train Loss 45.1313 Test MSE 8.327130675988364 Test RE 1.3792905168687877\n",
      "17 Train Loss 44.987274 Test MSE 8.197062030654127 Test RE 1.3684759552965542\n",
      "18 Train Loss 44.810596 Test MSE 8.285043399688316 Test RE 1.3758004721212613\n",
      "19 Train Loss 44.188522 Test MSE 8.18538604780703 Test RE 1.367500972083488\n",
      "20 Train Loss 42.340942 Test MSE 7.865832389231954 Test RE 1.3405419351606054\n",
      "21 Train Loss 36.706608 Test MSE 7.393346211071356 Test RE 1.2996564966355049\n",
      "22 Train Loss 35.055206 Test MSE 7.458086374384114 Test RE 1.3053343439632712\n",
      "23 Train Loss 32.162502 Test MSE 6.984189148932394 Test RE 1.2631823726499047\n",
      "24 Train Loss 31.069817 Test MSE 6.994308555257642 Test RE 1.2640971552085098\n",
      "25 Train Loss 29.0443 Test MSE 5.9894339060315405 Test RE 1.1697712644699787\n",
      "26 Train Loss 26.310537 Test MSE 5.820396717402564 Test RE 1.153146151251525\n",
      "27 Train Loss 25.64569 Test MSE 5.672937052445471 Test RE 1.1384449699863042\n",
      "28 Train Loss 23.975342 Test MSE 5.853927570082245 Test RE 1.1564629737556795\n",
      "29 Train Loss 22.402824 Test MSE 5.934812032151615 Test RE 1.1644250628359956\n",
      "30 Train Loss 21.838217 Test MSE 5.744395287502461 Test RE 1.1455926508414225\n",
      "31 Train Loss 21.709385 Test MSE 5.761096294030613 Test RE 1.1472567654500632\n",
      "32 Train Loss 21.29784 Test MSE 5.956339392304695 Test RE 1.1665350123423401\n",
      "33 Train Loss 20.962807 Test MSE 5.911605198507775 Test RE 1.1621462133190863\n",
      "34 Train Loss 20.842659 Test MSE 5.9696486513934826 Test RE 1.1678375786027748\n",
      "35 Train Loss 20.653816 Test MSE 5.914618786720433 Test RE 1.162442392088531\n",
      "36 Train Loss 20.338638 Test MSE 5.84302898367165 Test RE 1.1553859461299774\n",
      "37 Train Loss 20.20861 Test MSE 5.930119082491657 Test RE 1.1639645875184539\n",
      "38 Train Loss 20.014126 Test MSE 6.093862590407699 Test RE 1.1799249616695242\n",
      "39 Train Loss 19.863686 Test MSE 6.053043737868347 Test RE 1.175966543910594\n",
      "40 Train Loss 19.751 Test MSE 6.050810232077007 Test RE 1.1757495646077318\n",
      "41 Train Loss 19.61095 Test MSE 5.965092384139957 Test RE 1.1673918240776913\n",
      "42 Train Loss 19.449703 Test MSE 6.045921948413605 Test RE 1.1752745407325196\n",
      "43 Train Loss 19.240318 Test MSE 6.1549657458693785 Test RE 1.1858257600761082\n",
      "44 Train Loss 19.17438 Test MSE 6.122396057984421 Test RE 1.182684133847645\n",
      "45 Train Loss 18.95805 Test MSE 6.121475828169881 Test RE 1.1825952485411544\n",
      "46 Train Loss 18.786554 Test MSE 6.138241171800832 Test RE 1.1842135722651528\n",
      "47 Train Loss 18.657251 Test MSE 6.169863909921356 Test RE 1.1872600449926387\n",
      "48 Train Loss 18.538763 Test MSE 6.103834017877607 Test RE 1.180889926577119\n",
      "49 Train Loss 18.484915 Test MSE 6.08419557435729 Test RE 1.1789887015725578\n",
      "50 Train Loss 18.450241 Test MSE 6.100570462103324 Test RE 1.1805741893364505\n",
      "51 Train Loss 18.407993 Test MSE 6.102042357105624 Test RE 1.1807166003174596\n",
      "52 Train Loss 18.369389 Test MSE 6.078837179840872 Test RE 1.1784694153256785\n",
      "53 Train Loss 18.307552 Test MSE 6.100576827601882 Test RE 1.180574805257649\n",
      "54 Train Loss 18.17141 Test MSE 6.086344197803618 Test RE 1.1791968621359887\n",
      "55 Train Loss 18.131577 Test MSE 6.041243890429212 Test RE 1.1748197658914423\n",
      "56 Train Loss 18.074957 Test MSE 6.019634356883794 Test RE 1.1727167180009663\n",
      "57 Train Loss 18.022339 Test MSE 6.051127290255296 Test RE 1.175780368427183\n",
      "58 Train Loss 17.997597 Test MSE 6.063209822742824 Test RE 1.1769536473273903\n",
      "59 Train Loss 17.951302 Test MSE 6.0607745184230835 Test RE 1.176717260310336\n",
      "60 Train Loss 17.899086 Test MSE 6.049565589057629 Test RE 1.1756286333857993\n",
      "61 Train Loss 17.840342 Test MSE 6.068861510382442 Test RE 1.177502055284656\n",
      "62 Train Loss 17.787363 Test MSE 6.107616996146993 Test RE 1.181255810459242\n",
      "63 Train Loss 17.719519 Test MSE 6.126616039217419 Test RE 1.1830916577221795\n",
      "64 Train Loss 17.615711 Test MSE 6.095093020612797 Test RE 1.1800440767638782\n",
      "65 Train Loss 17.574083 Test MSE 6.072170338802564 Test RE 1.1778230068621567\n",
      "66 Train Loss 17.547112 Test MSE 6.073884653859404 Test RE 1.1779892585570593\n",
      "67 Train Loss 17.512426 Test MSE 6.09656928635945 Test RE 1.1801869747617313\n",
      "68 Train Loss 17.495651 Test MSE 6.071708215171761 Test RE 1.1777781867920332\n",
      "69 Train Loss 17.472298 Test MSE 6.025591493365401 Test RE 1.1732968450990973\n",
      "70 Train Loss 17.442852 Test MSE 6.037373682784029 Test RE 1.1744433926676419\n",
      "71 Train Loss 17.40842 Test MSE 6.043445645060136 Test RE 1.175033830185974\n",
      "72 Train Loss 17.355291 Test MSE 6.033282990155126 Test RE 1.1740454463703085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 17.29851 Test MSE 6.043701573837493 Test RE 1.1750587101803889\n",
      "74 Train Loss 17.262245 Test MSE 6.071035613676837 Test RE 1.1777129500183912\n",
      "75 Train Loss 17.197845 Test MSE 6.088777869954873 Test RE 1.179432594100242\n",
      "76 Train Loss 17.154507 Test MSE 6.162825650689917 Test RE 1.1865826695637827\n",
      "77 Train Loss 17.112255 Test MSE 6.162138299746829 Test RE 1.1865164968772774\n",
      "78 Train Loss 17.07556 Test MSE 6.135093058185532 Test RE 1.1839098601033613\n",
      "79 Train Loss 17.032095 Test MSE 6.156623267372874 Test RE 1.1859854197287472\n",
      "80 Train Loss 16.968039 Test MSE 6.172255370818964 Test RE 1.1874901157801265\n",
      "81 Train Loss 16.951885 Test MSE 6.157782954122286 Test RE 1.1860971130023954\n",
      "82 Train Loss 16.907085 Test MSE 6.119309225141467 Test RE 1.1823859492420052\n",
      "83 Train Loss 16.870878 Test MSE 6.121909519225639 Test RE 1.1826371397380255\n",
      "84 Train Loss 16.802525 Test MSE 6.203044153694809 Test RE 1.1904481831435463\n",
      "85 Train Loss 16.751627 Test MSE 6.199068307311108 Test RE 1.1900666126080846\n",
      "86 Train Loss 16.703337 Test MSE 6.189153039667416 Test RE 1.1891144895987165\n",
      "87 Train Loss 16.628222 Test MSE 6.180997374055816 Test RE 1.1883307622412278\n",
      "88 Train Loss 16.468557 Test MSE 6.147621034072905 Test RE 1.1851180267894712\n",
      "89 Train Loss 16.419361 Test MSE 6.152208556985374 Test RE 1.1855601280662085\n",
      "90 Train Loss 16.366755 Test MSE 6.103177122473728 Test RE 1.180826381104314\n",
      "91 Train Loss 16.25284 Test MSE 6.08929694669548 Test RE 1.1794828671593247\n",
      "92 Train Loss 16.162355 Test MSE 6.139924812369185 Test RE 1.1843759684025053\n",
      "93 Train Loss 16.090076 Test MSE 6.112485932690043 Test RE 1.1817265598357787\n",
      "94 Train Loss 15.9639 Test MSE 6.055408880347562 Test RE 1.1761962677412245\n",
      "95 Train Loss 15.92167 Test MSE 6.084015841708053 Test RE 1.1789712872467741\n",
      "96 Train Loss 15.886198 Test MSE 6.116804473830521 Test RE 1.1821439377855063\n",
      "97 Train Loss 15.775068 Test MSE 6.069321623373252 Test RE 1.1775466908166183\n",
      "98 Train Loss 15.658033 Test MSE 6.01773126938813 Test RE 1.1725313280910303\n",
      "99 Train Loss 15.562466 Test MSE 6.004816285392476 Test RE 1.1712724353027928\n",
      "Training time: 73.33\n",
      "KG_stan_tune0\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.63945 Test MSE 8.539814409186409 Test RE 1.3967937289021757\n",
      "1 Train Loss 55.26995 Test MSE 8.293774229030804 Test RE 1.3765251947129538\n",
      "2 Train Loss 52.459435 Test MSE 8.554937978032264 Test RE 1.3980300064593711\n",
      "3 Train Loss 49.14279 Test MSE 8.185355869582855 Test RE 1.3674984512012294\n",
      "4 Train Loss 46.285275 Test MSE 7.913706310387611 Test RE 1.344615225910154\n",
      "5 Train Loss 45.26966 Test MSE 7.961264103469021 Test RE 1.348649438499744\n",
      "6 Train Loss 41.955093 Test MSE 7.316207419175318 Test RE 1.2928587082439191\n",
      "7 Train Loss 39.67853 Test MSE 7.568980487968257 Test RE 1.3150030287829821\n",
      "8 Train Loss 39.2771 Test MSE 7.523420019236118 Test RE 1.3110393123253936\n",
      "9 Train Loss 38.439987 Test MSE 7.541139076029926 Test RE 1.3125822753720569\n",
      "10 Train Loss 37.86808 Test MSE 7.505233479326777 Test RE 1.309453750481115\n",
      "11 Train Loss 37.149902 Test MSE 7.6739158071603395 Test RE 1.3240871636999065\n",
      "12 Train Loss 36.16015 Test MSE 7.364672461640624 Test RE 1.2971338075662957\n",
      "13 Train Loss 35.38547 Test MSE 7.033404414208784 Test RE 1.267625173335406\n",
      "14 Train Loss 33.909847 Test MSE 7.3988069631802915 Test RE 1.3001363735241152\n",
      "15 Train Loss 33.44128 Test MSE 7.133434734539861 Test RE 1.2766075434731234\n",
      "16 Train Loss 31.766558 Test MSE 6.845891533997223 Test RE 1.250613369803203\n",
      "17 Train Loss 28.959621 Test MSE 6.584108772149579 Test RE 1.2264689526594346\n",
      "18 Train Loss 26.725536 Test MSE 6.576773370058973 Test RE 1.2257855533996773\n",
      "19 Train Loss 25.699131 Test MSE 6.370538631538077 Test RE 1.2064133575396097\n",
      "20 Train Loss 25.156351 Test MSE 6.36719843043908 Test RE 1.2060970427189475\n",
      "21 Train Loss 24.239733 Test MSE 6.258230807967741 Test RE 1.195731990232193\n",
      "22 Train Loss 22.149231 Test MSE 5.353387564686696 Test RE 1.1059166667700224\n",
      "23 Train Loss 19.740318 Test MSE 4.831882520276718 Test RE 1.0506697861833267\n",
      "24 Train Loss 17.940216 Test MSE 4.6084114623096895 Test RE 1.0260858163194027\n",
      "25 Train Loss 16.85622 Test MSE 4.552986202458238 Test RE 1.0198967958376552\n",
      "26 Train Loss 16.16376 Test MSE 4.491563080727496 Test RE 1.0129938576199038\n",
      "27 Train Loss 15.275366 Test MSE 4.425805086952194 Test RE 1.0055512311962178\n",
      "28 Train Loss 14.721939 Test MSE 4.462084331564992 Test RE 1.0096641760024183\n",
      "29 Train Loss 14.200527 Test MSE 4.413830508181297 Test RE 1.0041899864197184\n",
      "30 Train Loss 13.413374 Test MSE 4.497523630139249 Test RE 1.0136657838483503\n",
      "31 Train Loss 12.864086 Test MSE 4.526300463224141 Test RE 1.01690351886229\n",
      "32 Train Loss 12.162343 Test MSE 4.630185361025433 Test RE 1.0285069934051174\n",
      "33 Train Loss 10.816328 Test MSE 4.291565892117133 Test RE 0.9901841101897276\n",
      "34 Train Loss 10.074231 Test MSE 4.226353703923766 Test RE 0.9826321750827607\n",
      "35 Train Loss 9.36385 Test MSE 4.197090226366541 Test RE 0.9792243695187506\n",
      "36 Train Loss 8.056337 Test MSE 3.358370292137664 Test RE 0.8759359481840692\n",
      "37 Train Loss 6.3265395 Test MSE 2.2564553219028687 Test RE 0.7179950162199177\n",
      "38 Train Loss 3.7949445 Test MSE 1.122182055033058 Test RE 0.5063370652178615\n",
      "39 Train Loss 3.3822007 Test MSE 0.99271112311228 Test RE 0.47623302005507556\n",
      "40 Train Loss 2.6986659 Test MSE 0.8226461198095004 Test RE 0.43352543939297195\n",
      "41 Train Loss 2.297916 Test MSE 0.787745009094882 Test RE 0.42422952471631425\n",
      "42 Train Loss 1.9773533 Test MSE 0.7292211736043774 Test RE 0.4081668176899165\n",
      "43 Train Loss 1.7495798 Test MSE 0.6372077757506328 Test RE 0.38154748364845026\n",
      "44 Train Loss 1.567167 Test MSE 0.5485499890302261 Test RE 0.35401051808256184\n",
      "45 Train Loss 1.4539454 Test MSE 0.46466212349882724 Test RE 0.32581921776912154\n",
      "46 Train Loss 1.310486 Test MSE 0.37493445675468356 Test RE 0.29267507438183343\n",
      "47 Train Loss 1.1570221 Test MSE 0.2678018664312093 Test RE 0.24735167749582954\n",
      "48 Train Loss 1.076354 Test MSE 0.24192639137692398 Test RE 0.2350984057037375\n",
      "49 Train Loss 0.9599209 Test MSE 0.20168046688172134 Test RE 0.21465449104154224\n",
      "50 Train Loss 0.91035634 Test MSE 0.18646760678286528 Test RE 0.20640003126187825\n",
      "51 Train Loss 0.80728537 Test MSE 0.18540857849412076 Test RE 0.2058130802168463\n",
      "52 Train Loss 0.73318034 Test MSE 0.16134466784849585 Test RE 0.19199298858550212\n",
      "53 Train Loss 0.71080583 Test MSE 0.14683102301125306 Test RE 0.18315423815220405\n",
      "54 Train Loss 0.66784304 Test MSE 0.1611461738322497 Test RE 0.19187485270861082\n",
      "55 Train Loss 0.62189627 Test MSE 0.18041942027470825 Test RE 0.2030250853722402\n",
      "56 Train Loss 0.570101 Test MSE 0.19412989144112064 Test RE 0.21059801146569818\n",
      "57 Train Loss 0.5183757 Test MSE 0.22128816821551658 Test RE 0.22484703094269637\n",
      "58 Train Loss 0.4717013 Test MSE 0.20252740071129813 Test RE 0.21510472723088714\n",
      "59 Train Loss 0.442318 Test MSE 0.1787390802441632 Test RE 0.20207743453741642\n",
      "60 Train Loss 0.40381488 Test MSE 0.15051990136043084 Test RE 0.18544068497314792\n",
      "61 Train Loss 0.3743945 Test MSE 0.1420208061693291 Test RE 0.1801291696593985\n",
      "62 Train Loss 0.32477456 Test MSE 0.11632210435901788 Test RE 0.16301936061421204\n",
      "63 Train Loss 0.29395398 Test MSE 0.10360184582025492 Test RE 0.15384798298146496\n",
      "64 Train Loss 0.26027453 Test MSE 0.08432724251779687 Test RE 0.13880081298944064\n",
      "65 Train Loss 0.23847915 Test MSE 0.06768010113303351 Test RE 0.12434792992514739\n",
      "66 Train Loss 0.21146011 Test MSE 0.061111294401167464 Test RE 0.11815954272438295\n",
      "67 Train Loss 0.19635351 Test MSE 0.05443893832902301 Test RE 0.11152259946178666\n",
      "68 Train Loss 0.17948467 Test MSE 0.050458884972152174 Test RE 0.10736849979007142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 0.16748297 Test MSE 0.05521678916885102 Test RE 0.1123165189430542\n",
      "70 Train Loss 0.15732424 Test MSE 0.05569349439558897 Test RE 0.1128003102619942\n",
      "71 Train Loss 0.13505086 Test MSE 0.05356157626248391 Test RE 0.1106202753012148\n",
      "72 Train Loss 0.12929454 Test MSE 0.05097200363774492 Test RE 0.10791303648339295\n",
      "73 Train Loss 0.12214388 Test MSE 0.04899763616083275 Test RE 0.10580242564077705\n",
      "74 Train Loss 0.11431421 Test MSE 0.045963811809576136 Test RE 0.1024745640015741\n",
      "75 Train Loss 0.10905844 Test MSE 0.04453681022928655 Test RE 0.10087129929358181\n",
      "76 Train Loss 0.10334112 Test MSE 0.04452530919880825 Test RE 0.10085827412644648\n",
      "77 Train Loss 0.100851975 Test MSE 0.04459126475090624 Test RE 0.10093294740357783\n",
      "78 Train Loss 0.09609026 Test MSE 0.04044502748096537 Test RE 0.09612594619174636\n",
      "79 Train Loss 0.08606773 Test MSE 0.03514099813210731 Test RE 0.0896014642171066\n",
      "80 Train Loss 0.082056716 Test MSE 0.035134730686251975 Test RE 0.08959347358797075\n",
      "81 Train Loss 0.079856515 Test MSE 0.034044274585383644 Test RE 0.08819218500924174\n",
      "82 Train Loss 0.074063726 Test MSE 0.030197340089061834 Test RE 0.08306009152759382\n",
      "83 Train Loss 0.06904579 Test MSE 0.0308162208283216 Test RE 0.08390691410574294\n",
      "84 Train Loss 0.0656116 Test MSE 0.03049006564469268 Test RE 0.08346170260037428\n",
      "85 Train Loss 0.060909323 Test MSE 0.028203651040171678 Test RE 0.0802713794959748\n",
      "86 Train Loss 0.058250517 Test MSE 0.027570326621441703 Test RE 0.07936499913566654\n",
      "87 Train Loss 0.054784067 Test MSE 0.024240846411404147 Test RE 0.07441867790438915\n",
      "88 Train Loss 0.05330663 Test MSE 0.022438662292760186 Test RE 0.07159893154396184\n",
      "89 Train Loss 0.051508065 Test MSE 0.020951705574904448 Test RE 0.06918592496867342\n",
      "90 Train Loss 0.050048366 Test MSE 0.019470875384667994 Test RE 0.06669615517385356\n",
      "91 Train Loss 0.048971746 Test MSE 0.018115988621330164 Test RE 0.06433378152701966\n",
      "92 Train Loss 0.04706265 Test MSE 0.018761419975929918 Test RE 0.06546978472853185\n",
      "93 Train Loss 0.045388274 Test MSE 0.020104746747997997 Test RE 0.06777310196554329\n",
      "94 Train Loss 0.043703474 Test MSE 0.01907067065614945 Test RE 0.06600715938784367\n",
      "95 Train Loss 0.040924467 Test MSE 0.0180111885679932 Test RE 0.06414742783198993\n",
      "96 Train Loss 0.039371613 Test MSE 0.01918365961626718 Test RE 0.06620240858023559\n",
      "97 Train Loss 0.037345193 Test MSE 0.01777605725990912 Test RE 0.06372733842776498\n",
      "98 Train Loss 0.03644485 Test MSE 0.016843475853805287 Test RE 0.06203316207473583\n",
      "99 Train Loss 0.035998676 Test MSE 0.017589751393984224 Test RE 0.0633925046200613\n",
      "Training time: 71.48\n",
      "KG_stan_tune0\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.071102 Test MSE 8.579313455188169 Test RE 1.4000202844041143\n",
      "1 Train Loss 56.214275 Test MSE 8.5822777112631 Test RE 1.4002621254468919\n",
      "2 Train Loss 50.15242 Test MSE 8.215069634064037 Test RE 1.369978289479743\n",
      "3 Train Loss 48.903183 Test MSE 8.124689289897171 Test RE 1.3624213509103351\n",
      "4 Train Loss 44.64051 Test MSE 8.582488358017219 Test RE 1.4002793096299069\n",
      "5 Train Loss 43.797928 Test MSE 8.225731804773481 Test RE 1.3708670345909477\n",
      "6 Train Loss 42.584854 Test MSE 8.213933670446657 Test RE 1.3698835672579526\n",
      "7 Train Loss 42.41366 Test MSE 8.174384207669597 Test RE 1.3665816455033346\n",
      "8 Train Loss 41.592163 Test MSE 8.163739765988831 Test RE 1.365691594531369\n",
      "9 Train Loss 41.04081 Test MSE 8.349479209626649 Test RE 1.3811401615505896\n",
      "10 Train Loss 40.41278 Test MSE 8.327158733733748 Test RE 1.3792928405833442\n",
      "11 Train Loss 39.508377 Test MSE 7.994937171884302 Test RE 1.3514985617969597\n",
      "12 Train Loss 39.339943 Test MSE 8.109905240874422 Test RE 1.3611812250090523\n",
      "13 Train Loss 39.075886 Test MSE 8.021034245197747 Test RE 1.3537025454532037\n",
      "14 Train Loss 38.79825 Test MSE 7.952941510636504 Test RE 1.3479443246535332\n",
      "15 Train Loss 38.63205 Test MSE 7.8744502532907825 Test RE 1.341276087952222\n",
      "16 Train Loss 38.33841 Test MSE 7.76600635801028 Test RE 1.3320083004525292\n",
      "17 Train Loss 38.07805 Test MSE 7.541248931056833 Test RE 1.3125918358134303\n",
      "18 Train Loss 37.88924 Test MSE 7.67592947047839 Test RE 1.324260874940161\n",
      "19 Train Loss 36.975296 Test MSE 7.774813037790459 Test RE 1.3327633376159538\n",
      "20 Train Loss 32.300232 Test MSE 6.511321740014367 Test RE 1.219670832120067\n",
      "21 Train Loss 29.2235 Test MSE 6.008282060514477 Test RE 1.1716103957924568\n",
      "22 Train Loss 27.512474 Test MSE 5.593607875833418 Test RE 1.130457057024467\n",
      "23 Train Loss 24.429462 Test MSE 5.087050067606353 Test RE 1.0780553677263724\n",
      "24 Train Loss 23.471062 Test MSE 4.954391977723651 Test RE 1.0639059608726467\n",
      "25 Train Loss 23.176632 Test MSE 5.136343822725374 Test RE 1.0832659790738666\n",
      "26 Train Loss 22.733221 Test MSE 5.529398371555842 Test RE 1.123950022695353\n",
      "27 Train Loss 22.329226 Test MSE 5.280416633050308 Test RE 1.0983535434782288\n",
      "28 Train Loss 20.912045 Test MSE 5.326855659970364 Test RE 1.103172747972677\n",
      "29 Train Loss 20.189255 Test MSE 5.080476857387305 Test RE 1.0773586402444402\n",
      "30 Train Loss 19.775627 Test MSE 4.683521987175793 Test RE 1.0344138862101877\n",
      "31 Train Loss 17.857233 Test MSE 3.88342105110381 Test RE 0.941922780595313\n",
      "32 Train Loss 15.127143 Test MSE 3.9437885218962108 Test RE 0.9492156055776528\n",
      "33 Train Loss 13.937115 Test MSE 4.155378169750592 Test RE 0.9743462931049764\n",
      "34 Train Loss 12.997129 Test MSE 3.6932572927592315 Test RE 0.9185712369481274\n",
      "35 Train Loss 12.481162 Test MSE 4.025067881342827 Test RE 0.9589471323568243\n",
      "36 Train Loss 12.111863 Test MSE 4.134010519149198 Test RE 0.9718379384297511\n",
      "37 Train Loss 11.772541 Test MSE 4.234634174155204 Test RE 0.9835943135493606\n",
      "38 Train Loss 11.499046 Test MSE 4.178920167479803 Test RE 0.9771024395383564\n",
      "39 Train Loss 11.19501 Test MSE 4.1568529233670715 Test RE 0.9745191766779919\n",
      "40 Train Loss 11.056559 Test MSE 4.092601221671199 Test RE 0.9669583656494197\n",
      "41 Train Loss 10.954356 Test MSE 4.090729207709884 Test RE 0.9667371901050674\n",
      "42 Train Loss 10.816593 Test MSE 4.0620457190912145 Test RE 0.963341930558124\n",
      "43 Train Loss 10.729406 Test MSE 4.052513050459123 Test RE 0.9622108978118759\n",
      "44 Train Loss 10.688645 Test MSE 4.091268455612172 Test RE 0.96680090659624\n",
      "45 Train Loss 10.605939 Test MSE 4.115738083001488 Test RE 0.9696877851321116\n",
      "46 Train Loss 10.572695 Test MSE 4.07238323618929 Test RE 0.9645669581080881\n",
      "47 Train Loss 10.513676 Test MSE 4.132914638088802 Test RE 0.9717091180776822\n",
      "48 Train Loss 10.474741 Test MSE 4.11595633797843 Test RE 0.9697134957549961\n",
      "49 Train Loss 10.429434 Test MSE 4.087608959157985 Test RE 0.9663684250764721\n",
      "50 Train Loss 10.401478 Test MSE 4.095294379247967 Test RE 0.9672764693231745\n",
      "51 Train Loss 10.359632 Test MSE 4.1261646303204484 Test RE 0.9709152806809134\n",
      "52 Train Loss 10.339152 Test MSE 4.132971273769175 Test RE 0.9717157759962831\n",
      "53 Train Loss 10.263659 Test MSE 4.152032817452961 Test RE 0.9739540077610677\n",
      "54 Train Loss 10.2166195 Test MSE 4.183430960161884 Test RE 0.9776296472398314\n",
      "55 Train Loss 10.155508 Test MSE 4.157961165294903 Test RE 0.9746490743501915\n",
      "56 Train Loss 10.1173 Test MSE 4.207796371513471 Test RE 0.980472501031678\n",
      "57 Train Loss 10.104171 Test MSE 4.212122391765906 Test RE 0.9809763816740711\n",
      "58 Train Loss 10.05303 Test MSE 4.206506252054898 Test RE 0.9803221820151833\n",
      "59 Train Loss 9.928224 Test MSE 4.259293584595987 Test RE 0.9864540231128457\n",
      "60 Train Loss 9.871428 Test MSE 4.255692122155472 Test RE 0.9860368848766973\n",
      "61 Train Loss 9.843536 Test MSE 4.24733364189163 Test RE 0.985068085861319\n",
      "62 Train Loss 9.81853 Test MSE 4.2496470725226585 Test RE 0.98533632196484\n",
      "63 Train Loss 9.783596 Test MSE 4.255779728270451 Test RE 0.9860470339210446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Train Loss 9.752502 Test MSE 4.264066453729692 Test RE 0.9870065675223075\n",
      "65 Train Loss 9.721432 Test MSE 4.279391978295664 Test RE 0.9887786818233154\n",
      "66 Train Loss 9.689497 Test MSE 4.272115789591802 Test RE 0.9879377211088206\n",
      "67 Train Loss 9.655297 Test MSE 4.264397788730924 Test RE 0.9870449139544258\n",
      "68 Train Loss 9.645584 Test MSE 4.256624499011956 Test RE 0.9861448940553266\n",
      "69 Train Loss 9.62042 Test MSE 4.249721210905205 Test RE 0.9853449169047634\n",
      "70 Train Loss 9.59631 Test MSE 4.269900763707829 Test RE 0.9876815726970894\n",
      "71 Train Loss 9.555828 Test MSE 4.267134497003988 Test RE 0.9873615847796368\n",
      "72 Train Loss 9.517559 Test MSE 4.292108394510713 Test RE 0.9902466934388398\n",
      "73 Train Loss 9.4928665 Test MSE 4.306889614535644 Test RE 0.991950340311479\n",
      "74 Train Loss 9.483831 Test MSE 4.2996143138851535 Test RE 0.9911121731130882\n",
      "75 Train Loss 9.466999 Test MSE 4.288523739176696 Test RE 0.9898330931487989\n",
      "76 Train Loss 9.427235 Test MSE 4.243001232414817 Test RE 0.9845655579783656\n",
      "77 Train Loss 9.414358 Test MSE 4.241941784782303 Test RE 0.9844426307490457\n",
      "78 Train Loss 9.400833 Test MSE 4.258040843314737 Test RE 0.9863089447645512\n",
      "79 Train Loss 9.375299 Test MSE 4.269621716588354 Test RE 0.9876492986213977\n",
      "80 Train Loss 9.32531 Test MSE 4.221423891706969 Test RE 0.9820589143138964\n",
      "81 Train Loss 9.271793 Test MSE 4.241957829308677 Test RE 0.9844444925026511\n",
      "82 Train Loss 9.2255745 Test MSE 4.258294916937529 Test RE 0.9863383704274231\n",
      "83 Train Loss 9.199578 Test MSE 4.276421767119603 Test RE 0.98843547988179\n",
      "84 Train Loss 9.173283 Test MSE 4.231161677695545 Test RE 0.9831909459713218\n",
      "85 Train Loss 9.110252 Test MSE 4.25655127934771 Test RE 0.9861364125098478\n",
      "86 Train Loss 9.057951 Test MSE 4.278678144338042 Test RE 0.9886962106171435\n",
      "87 Train Loss 9.033746 Test MSE 4.264463145425126 Test RE 0.9870524777123856\n",
      "88 Train Loss 9.01487 Test MSE 4.272042003770836 Test RE 0.9879291894919167\n",
      "89 Train Loss 9.005262 Test MSE 4.29215328784403 Test RE 0.9902518721708921\n",
      "90 Train Loss 8.992051 Test MSE 4.279286349014252 Test RE 0.9887664786146958\n",
      "91 Train Loss 8.955308 Test MSE 4.2477656020981565 Test RE 0.9851181760392376\n",
      "92 Train Loss 8.916528 Test MSE 4.2625179078404205 Test RE 0.9868273297253614\n",
      "93 Train Loss 8.8661175 Test MSE 4.184245087517321 Test RE 0.977724769679747\n",
      "94 Train Loss 8.817365 Test MSE 4.1826594584283985 Test RE 0.9775394966251788\n",
      "95 Train Loss 8.789262 Test MSE 4.2269020076078085 Test RE 0.9826959136392002\n",
      "96 Train Loss 8.760559 Test MSE 4.203904199553359 Test RE 0.9800189322123607\n",
      "97 Train Loss 8.686613 Test MSE 4.171221320541286 Test RE 0.9762019640886063\n",
      "98 Train Loss 8.644032 Test MSE 4.2182557872592215 Test RE 0.9816903361693136\n",
      "99 Train Loss 8.59814 Test MSE 4.2333566505043025 Test RE 0.9834459347599983\n",
      "Training time: 72.21\n",
      "KG_stan_tune0\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.67858 Test MSE 8.530702858106308 Test RE 1.3960483758203137\n",
      "1 Train Loss 56.255383 Test MSE 8.648999338158335 Test RE 1.4056946509161488\n",
      "2 Train Loss 54.481575 Test MSE 7.363849064312905 Test RE 1.297061293386525\n",
      "3 Train Loss 46.355354 Test MSE 8.364384613935286 Test RE 1.3823724104435537\n",
      "4 Train Loss 43.89998 Test MSE 8.582321818812362 Test RE 1.4002657236788185\n",
      "5 Train Loss 43.80902 Test MSE 8.572416871798277 Test RE 1.3994574597758354\n",
      "6 Train Loss 43.517067 Test MSE 8.51983079395211 Test RE 1.3951584862785498\n",
      "7 Train Loss 43.478622 Test MSE 8.469873814690882 Test RE 1.391062138812307\n",
      "8 Train Loss 43.442856 Test MSE 8.51654152168763 Test RE 1.3948891441262783\n",
      "9 Train Loss 43.30213 Test MSE 8.51548913294898 Test RE 1.3948029582622674\n",
      "10 Train Loss 43.23625 Test MSE 8.426694470100447 Test RE 1.3875117966573371\n",
      "11 Train Loss 43.188732 Test MSE 8.461737939787328 Test RE 1.3903938746266686\n",
      "12 Train Loss 43.101646 Test MSE 8.408299958339791 Test RE 1.3859965794148967\n",
      "13 Train Loss 42.49039 Test MSE 8.621797498688137 Test RE 1.4034823954200644\n",
      "14 Train Loss 41.251976 Test MSE 8.37506194688737 Test RE 1.3832544444357493\n",
      "15 Train Loss 40.496758 Test MSE 8.107195812394028 Test RE 1.360953828316259\n",
      "16 Train Loss 40.172962 Test MSE 8.011247320072531 Test RE 1.3528764282183992\n",
      "17 Train Loss 39.57689 Test MSE 7.751064386113944 Test RE 1.330726276445083\n",
      "18 Train Loss 39.312386 Test MSE 7.941431102925528 Test RE 1.3469685217568454\n",
      "19 Train Loss 39.14621 Test MSE 7.834446456616346 Test RE 1.3378647732681488\n",
      "20 Train Loss 38.91641 Test MSE 7.788879697313395 Test RE 1.3339684505799105\n",
      "21 Train Loss 38.73236 Test MSE 7.895076948563567 Test RE 1.3430316390374442\n",
      "22 Train Loss 38.444576 Test MSE 8.053482120198876 Test RE 1.3564378808552255\n",
      "23 Train Loss 38.313923 Test MSE 7.911637964019032 Test RE 1.3444394984030217\n",
      "24 Train Loss 37.87641 Test MSE 7.798279371085663 Test RE 1.3347731290463807\n",
      "25 Train Loss 37.736996 Test MSE 7.8799242647027 Test RE 1.3417422084319433\n",
      "26 Train Loss 37.493073 Test MSE 7.838498096886498 Test RE 1.3382106717425255\n",
      "27 Train Loss 37.067318 Test MSE 8.0201124283757 Test RE 1.353624756131086\n",
      "28 Train Loss 36.695644 Test MSE 7.8189322975368105 Test RE 1.3365394637737193\n",
      "29 Train Loss 35.83125 Test MSE 7.925696366408641 Test RE 1.3456334536065164\n",
      "30 Train Loss 34.881718 Test MSE 7.6485003222070205 Test RE 1.3218927020969147\n",
      "31 Train Loss 33.61251 Test MSE 7.580759553436647 Test RE 1.3160258537970129\n",
      "32 Train Loss 32.307205 Test MSE 7.653333463479532 Test RE 1.3223102927963446\n",
      "33 Train Loss 31.12904 Test MSE 7.428713142536126 Test RE 1.3027613170004897\n",
      "34 Train Loss 30.409101 Test MSE 7.570798587811571 Test RE 1.3151609538332085\n",
      "35 Train Loss 29.259045 Test MSE 7.44163561142686 Test RE 1.3038939208195515\n",
      "36 Train Loss 28.717293 Test MSE 7.395541408806801 Test RE 1.2998494262761024\n",
      "37 Train Loss 27.896439 Test MSE 7.173962499217313 Test RE 1.280228854534429\n",
      "38 Train Loss 27.28606 Test MSE 7.153410990866733 Test RE 1.2783937805225962\n",
      "39 Train Loss 26.482817 Test MSE 7.184328908303106 Test RE 1.2811534889461487\n",
      "40 Train Loss 24.78035 Test MSE 6.65479695987127 Test RE 1.2330351724053057\n",
      "41 Train Loss 22.444098 Test MSE 6.313072355668782 Test RE 1.2009597262407496\n",
      "42 Train Loss 21.407085 Test MSE 6.126699118148725 Test RE 1.1830996792512523\n",
      "43 Train Loss 20.193783 Test MSE 5.7303763128046885 Test RE 1.1441939096310951\n",
      "44 Train Loss 19.830502 Test MSE 5.640433155603356 Test RE 1.1351788439314305\n",
      "45 Train Loss 19.109158 Test MSE 5.421847597501963 Test RE 1.112965528284198\n",
      "46 Train Loss 18.800901 Test MSE 5.429523682081795 Test RE 1.113753100759136\n",
      "47 Train Loss 18.56489 Test MSE 5.381452730695636 Test RE 1.1088117646752973\n",
      "48 Train Loss 18.293144 Test MSE 5.21807847377424 Test RE 1.0918509676444637\n",
      "49 Train Loss 18.140335 Test MSE 5.284173253782412 Test RE 1.0987441721338715\n",
      "50 Train Loss 17.891726 Test MSE 5.256429980252149 Test RE 1.095856031017944\n",
      "51 Train Loss 17.381836 Test MSE 5.262101565890652 Test RE 1.0964470752935729\n",
      "52 Train Loss 16.8434 Test MSE 4.904863188519479 Test RE 1.058574698083518\n",
      "53 Train Loss 15.715701 Test MSE 4.2592658604815306 Test RE 0.9864508126498661\n",
      "54 Train Loss 13.541236 Test MSE 3.769293484672131 Test RE 0.9279787625107342\n",
      "55 Train Loss 12.120322 Test MSE 3.410532292555057 Test RE 0.8827122289579896\n",
      "56 Train Loss 11.196178 Test MSE 3.6182135876034756 Test RE 0.9091910677387397\n",
      "57 Train Loss 10.494452 Test MSE 3.511010573544716 Test RE 0.8956207130390516\n",
      "58 Train Loss 10.201387 Test MSE 3.5366860264170645 Test RE 0.8988895126357765\n",
      "59 Train Loss 9.948757 Test MSE 3.5444894536213214 Test RE 0.8998806317077181\n",
      "60 Train Loss 9.727597 Test MSE 3.5154839567738674 Test RE 0.8961910871875365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 9.255875 Test MSE 3.623003189733626 Test RE 0.9097926385420383\n",
      "62 Train Loss 8.906563 Test MSE 3.5859978683674942 Test RE 0.9051344063927195\n",
      "63 Train Loss 8.59926 Test MSE 3.6751701619962756 Test RE 0.9163191992201553\n",
      "64 Train Loss 8.407885 Test MSE 3.678848525526681 Test RE 0.916777642234618\n",
      "65 Train Loss 8.241627 Test MSE 3.7332365674193357 Test RE 0.9235295921262462\n",
      "66 Train Loss 8.095339 Test MSE 3.8052686916618286 Test RE 0.9323966924151208\n",
      "67 Train Loss 7.935028 Test MSE 3.8552759496863915 Test RE 0.9385032800519325\n",
      "68 Train Loss 7.6568227 Test MSE 3.874561081621429 Test RE 0.9408476753723287\n",
      "69 Train Loss 7.6022406 Test MSE 3.8905676532299514 Test RE 0.942789085473493\n",
      "70 Train Loss 7.507359 Test MSE 3.8414462018021913 Test RE 0.9368184558350519\n",
      "71 Train Loss 7.402259 Test MSE 3.819119868982127 Test RE 0.9340921128763195\n",
      "72 Train Loss 7.3402433 Test MSE 3.8324512977144405 Test RE 0.935721013582641\n",
      "73 Train Loss 7.214544 Test MSE 3.7507161463115755 Test RE 0.9256891199643624\n",
      "74 Train Loss 7.1800323 Test MSE 3.6830516342406265 Test RE 0.9173012049864695\n",
      "75 Train Loss 7.1604953 Test MSE 3.6930424877063297 Test RE 0.9185445238603831\n",
      "76 Train Loss 7.138842 Test MSE 3.712675682580498 Test RE 0.9209829007355915\n",
      "77 Train Loss 7.0889354 Test MSE 3.6860909916218625 Test RE 0.917679618258535\n",
      "78 Train Loss 7.0433784 Test MSE 3.661891901791375 Test RE 0.914662386886673\n",
      "79 Train Loss 7.0164685 Test MSE 3.633142368341966 Test RE 0.9110648020946439\n",
      "80 Train Loss 7.0044174 Test MSE 3.615015385992575 Test RE 0.9087891540443658\n",
      "81 Train Loss 6.9808693 Test MSE 3.591028371120718 Test RE 0.9057690533659245\n",
      "82 Train Loss 6.942661 Test MSE 3.5786238804586956 Test RE 0.9042033008593607\n",
      "83 Train Loss 6.9264708 Test MSE 3.592500818811516 Test RE 0.9059547328879896\n",
      "84 Train Loss 6.9088926 Test MSE 3.6048187775056064 Test RE 0.9075065715621211\n",
      "85 Train Loss 6.8971853 Test MSE 3.5898415635190166 Test RE 0.9056193661010039\n",
      "86 Train Loss 6.886571 Test MSE 3.58168248219403 Test RE 0.9045896235353454\n",
      "87 Train Loss 6.875426 Test MSE 3.5865552304144184 Test RE 0.9052047449683047\n",
      "88 Train Loss 6.863838 Test MSE 3.587925643471211 Test RE 0.9053776665945138\n",
      "89 Train Loss 6.8556128 Test MSE 3.58474668050105 Test RE 0.9049764877282456\n",
      "90 Train Loss 6.83978 Test MSE 3.581165552146169 Test RE 0.9045243432609227\n",
      "91 Train Loss 6.8296123 Test MSE 3.582649364679494 Test RE 0.9047117132025172\n",
      "92 Train Loss 6.8036065 Test MSE 3.5862067424495634 Test RE 0.9051607667493436\n",
      "93 Train Loss 6.788911 Test MSE 3.5847926041187352 Test RE 0.9049822844643665\n",
      "94 Train Loss 6.773324 Test MSE 3.59328351445246 Test RE 0.9060534173752356\n",
      "95 Train Loss 6.75805 Test MSE 3.617487320143634 Test RE 0.9090998142775829\n",
      "96 Train Loss 6.7409906 Test MSE 3.631581407739005 Test RE 0.9108690639560313\n",
      "97 Train Loss 6.725267 Test MSE 3.654965653587803 Test RE 0.9137969630329965\n",
      "98 Train Loss 6.7125845 Test MSE 3.6854187963628786 Test RE 0.9175959404525263\n",
      "99 Train Loss 6.704349 Test MSE 3.6827363977164933 Test RE 0.9172619477264641\n",
      "Training time: 73.00\n",
      "KG_stan_tune1\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 363.02994 Test MSE 4.4435867250067895 Test RE 1.0075692170908812\n",
      "1 Train Loss 211.19183 Test MSE 4.438130951381297 Test RE 1.0069504874200483\n",
      "2 Train Loss 176.85526 Test MSE 4.435517151063073 Test RE 1.006653926191201\n",
      "3 Train Loss 156.02184 Test MSE 4.441726403257339 Test RE 1.0073582839790836\n",
      "4 Train Loss 151.07602 Test MSE 4.444720005835446 Test RE 1.0076976928192778\n",
      "5 Train Loss 146.22456 Test MSE 4.451780393800724 Test RE 1.008497733482767\n",
      "6 Train Loss 140.78378 Test MSE 4.462619088604785 Test RE 1.009724675626586\n",
      "7 Train Loss 133.38046 Test MSE 4.4734894952896145 Test RE 1.0109537119443495\n",
      "8 Train Loss 127.42354 Test MSE 4.486206474152453 Test RE 1.0123896327386193\n",
      "9 Train Loss 121.16508 Test MSE 4.519102685771517 Test RE 1.0160946510614806\n",
      "10 Train Loss 116.33483 Test MSE 4.5372185181179745 Test RE 1.0181292352438724\n",
      "11 Train Loss 114.66581 Test MSE 4.530338097399083 Test RE 1.0173569762929424\n",
      "12 Train Loss 111.82516 Test MSE 4.53777559886258 Test RE 1.0181917363975694\n",
      "13 Train Loss 108.98387 Test MSE 4.560789469354442 Test RE 1.0207704114694616\n",
      "14 Train Loss 106.229225 Test MSE 4.5822313683046945 Test RE 1.0231671008479784\n",
      "15 Train Loss 104.392685 Test MSE 4.595032797097855 Test RE 1.0245953204731912\n",
      "16 Train Loss 102.78048 Test MSE 4.609658193771337 Test RE 1.0262246024251314\n",
      "17 Train Loss 101.00255 Test MSE 4.632396692305672 Test RE 1.0287525665323014\n",
      "18 Train Loss 99.78233 Test MSE 4.647412355155965 Test RE 1.0304185404318764\n",
      "19 Train Loss 96.194916 Test MSE 4.698830409033751 Test RE 1.036103034423874\n",
      "20 Train Loss 94.71219 Test MSE 4.721458994373222 Test RE 1.0385948658423647\n",
      "21 Train Loss 93.3409 Test MSE 4.751201863525406 Test RE 1.0418610484639539\n",
      "22 Train Loss 92.58843 Test MSE 4.7674456883284355 Test RE 1.0436405316717166\n",
      "23 Train Loss 90.24236 Test MSE 4.867368216101111 Test RE 1.054520826110945\n",
      "24 Train Loss 89.13621 Test MSE 4.918997405860255 Test RE 1.0600988345161095\n",
      "25 Train Loss 87.91495 Test MSE 4.950285701418319 Test RE 1.063464978665046\n",
      "26 Train Loss 86.78122 Test MSE 4.997916513100195 Test RE 1.068568970689888\n",
      "27 Train Loss 84.836624 Test MSE 5.0815457948782585 Test RE 1.0774719729595057\n",
      "28 Train Loss 84.27695 Test MSE 5.0976918617670135 Test RE 1.079182391199877\n",
      "29 Train Loss 82.89641 Test MSE 5.151189192559818 Test RE 1.0848303098008338\n",
      "30 Train Loss 81.887634 Test MSE 5.174156640758407 Test RE 1.0872460697300466\n",
      "31 Train Loss 80.819984 Test MSE 5.179984011968089 Test RE 1.087858150497531\n",
      "32 Train Loss 80.376434 Test MSE 5.188857120520043 Test RE 1.0887894809134349\n",
      "33 Train Loss 79.88443 Test MSE 5.216952400903209 Test RE 1.0917331493613909\n",
      "34 Train Loss 79.53504 Test MSE 5.215100433239413 Test RE 1.0915393548046\n",
      "35 Train Loss 78.75614 Test MSE 5.217819621822775 Test RE 1.0918238857157183\n",
      "36 Train Loss 78.018684 Test MSE 5.31284145214391 Test RE 1.101720646125386\n",
      "37 Train Loss 76.89617 Test MSE 5.3979465518248055 Test RE 1.110509684544387\n",
      "38 Train Loss 76.35131 Test MSE 5.402107957304918 Test RE 1.1109376612501467\n",
      "39 Train Loss 75.26061 Test MSE 5.510960402246095 Test RE 1.1220745328879727\n",
      "40 Train Loss 74.38351 Test MSE 5.535354750648751 Test RE 1.1245552305342899\n",
      "41 Train Loss 73.03357 Test MSE 5.534286803054334 Test RE 1.1244467439025245\n",
      "42 Train Loss 71.90045 Test MSE 5.638954016493305 Test RE 1.1350299903351335\n",
      "43 Train Loss 70.92313 Test MSE 5.657076275362797 Test RE 1.1368523857239579\n",
      "44 Train Loss 68.57885 Test MSE 5.73402429308463 Test RE 1.1445580508765025\n",
      "45 Train Loss 67.1252 Test MSE 5.779276821963252 Test RE 1.1490655621719386\n",
      "46 Train Loss 65.006294 Test MSE 5.844744237280529 Test RE 1.155555518666756\n",
      "47 Train Loss 63.63447 Test MSE 5.843056201746043 Test RE 1.1553886371438415\n",
      "48 Train Loss 62.657578 Test MSE 5.83539940213464 Test RE 1.1546313725356976\n",
      "49 Train Loss 62.017677 Test MSE 5.882559645882934 Test RE 1.1592877051428392\n",
      "50 Train Loss 60.302616 Test MSE 6.063372297169509 Test RE 1.1769694164986408\n",
      "51 Train Loss 59.261242 Test MSE 6.148876988593704 Test RE 1.1852390799839025\n",
      "52 Train Loss 58.82001 Test MSE 6.193367230948303 Test RE 1.1895192544468969\n",
      "53 Train Loss 58.35287 Test MSE 6.2492634894517645 Test RE 1.1948750105419559\n",
      "54 Train Loss 57.830482 Test MSE 6.347067163380081 Test RE 1.2041888656652346\n",
      "55 Train Loss 56.896126 Test MSE 6.489348901951614 Test RE 1.217611167568439\n",
      "56 Train Loss 56.356228 Test MSE 6.5110807235578365 Test RE 1.219648258864274\n",
      "57 Train Loss 55.80757 Test MSE 6.567914031832966 Test RE 1.2249596690468092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 55.10777 Test MSE 6.54888710392544 Test RE 1.223184057820424\n",
      "59 Train Loss 54.253067 Test MSE 6.617931850643803 Test RE 1.22961515043656\n",
      "60 Train Loss 53.728374 Test MSE 6.625753412330011 Test RE 1.2303415609657797\n",
      "61 Train Loss 53.26319 Test MSE 6.7006727694372135 Test RE 1.2372779264934592\n",
      "62 Train Loss 53.048374 Test MSE 6.704397266496608 Test RE 1.2376217425530867\n",
      "63 Train Loss 52.808853 Test MSE 6.687835118705877 Test RE 1.2360921234004836\n",
      "64 Train Loss 52.542145 Test MSE 6.766358304666005 Test RE 1.243327547469741\n",
      "65 Train Loss 52.27536 Test MSE 6.830076700396514 Test RE 1.2491680008554924\n",
      "66 Train Loss 51.99092 Test MSE 6.8116207428890485 Test RE 1.2474791335169695\n",
      "67 Train Loss 51.66836 Test MSE 6.900139356668228 Test RE 1.2555586119492799\n",
      "68 Train Loss 51.53587 Test MSE 6.9423610558889575 Test RE 1.2593941120857097\n",
      "69 Train Loss 51.22774 Test MSE 6.986259464847006 Test RE 1.2633695806949516\n",
      "70 Train Loss 50.744488 Test MSE 7.021170735335674 Test RE 1.2665222601750616\n",
      "71 Train Loss 50.31062 Test MSE 7.073725929182781 Test RE 1.2712535386582267\n",
      "72 Train Loss 49.83436 Test MSE 7.171365139205381 Test RE 1.2799970777259773\n",
      "73 Train Loss 49.597473 Test MSE 7.248789868713269 Test RE 1.2868881905407645\n",
      "74 Train Loss 49.10553 Test MSE 7.365982838019931 Test RE 1.2972492001998825\n",
      "75 Train Loss 48.811134 Test MSE 7.415994800824503 Test RE 1.3016456418432691\n",
      "76 Train Loss 47.799664 Test MSE 7.679842747232981 Test RE 1.3245983936081618\n",
      "77 Train Loss 47.41079 Test MSE 7.6336026553501135 Test RE 1.3206046903869386\n",
      "78 Train Loss 47.18643 Test MSE 7.631775090243308 Test RE 1.320446597568114\n",
      "79 Train Loss 46.95686 Test MSE 7.6554733860832345 Test RE 1.322495143223233\n",
      "80 Train Loss 46.680447 Test MSE 7.679051610956633 Test RE 1.3245301653341657\n",
      "81 Train Loss 46.128746 Test MSE 7.632514150441481 Test RE 1.3205105319665618\n",
      "82 Train Loss 45.768986 Test MSE 7.6289885318148585 Test RE 1.3202055109608775\n",
      "83 Train Loss 45.532738 Test MSE 7.604275501388741 Test RE 1.3180654668539662\n",
      "84 Train Loss 45.231766 Test MSE 7.6989925451404435 Test RE 1.3262488179445062\n",
      "85 Train Loss 44.953495 Test MSE 7.8312007192198525 Test RE 1.3375876121698653\n",
      "86 Train Loss 44.394913 Test MSE 7.84767785649578 Test RE 1.3389940397811682\n",
      "87 Train Loss 44.11541 Test MSE 7.820623313931788 Test RE 1.3366839840146763\n",
      "88 Train Loss 43.678463 Test MSE 7.80341218460417 Test RE 1.335212329429794\n",
      "89 Train Loss 43.43703 Test MSE 7.8126228282792445 Test RE 1.3360000962333631\n",
      "90 Train Loss 43.022648 Test MSE 7.845675382008078 Test RE 1.3388231948178468\n",
      "91 Train Loss 42.767323 Test MSE 7.906622282736731 Test RE 1.3440132687686863\n",
      "92 Train Loss 42.445953 Test MSE 7.940187136089158 Test RE 1.3468630212638544\n",
      "93 Train Loss 42.12975 Test MSE 8.000170752693442 Test RE 1.3519408429316868\n",
      "94 Train Loss 41.74419 Test MSE 8.092621248999057 Test RE 1.359729963063067\n",
      "95 Train Loss 41.42679 Test MSE 8.139416246173477 Test RE 1.36365556645659\n",
      "96 Train Loss 41.3087 Test MSE 8.159254840457647 Test RE 1.3653164070109884\n",
      "97 Train Loss 41.06445 Test MSE 8.18117974789484 Test RE 1.367149561756059\n",
      "98 Train Loss 40.83753 Test MSE 8.152050382272549 Test RE 1.3647135004071715\n",
      "99 Train Loss 40.50743 Test MSE 8.148813444556907 Test RE 1.3644425298541025\n",
      "Training time: 74.17\n",
      "KG_stan_tune1\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 713.86926 Test MSE 5.550583563378966 Test RE 1.1261011005808965\n",
      "1 Train Loss 479.18576 Test MSE 5.545047568135089 Test RE 1.1255393897744743\n",
      "2 Train Loss 389.65015 Test MSE 5.534247005058495 Test RE 1.1244427008515514\n",
      "3 Train Loss 334.42255 Test MSE 5.537957006579609 Test RE 1.1248195348830325\n",
      "4 Train Loss 255.12714 Test MSE 5.528240257094452 Test RE 1.1238323126976206\n",
      "5 Train Loss 231.50356 Test MSE 5.517498771641051 Test RE 1.1227399670833702\n",
      "6 Train Loss 219.99915 Test MSE 5.511375969948592 Test RE 1.1221168385036338\n",
      "7 Train Loss 205.10327 Test MSE 5.505735695269339 Test RE 1.1215425112102007\n",
      "8 Train Loss 195.89284 Test MSE 5.506553617333387 Test RE 1.1216258152725107\n",
      "9 Train Loss 190.83717 Test MSE 5.499632687935683 Test RE 1.1209207341734102\n",
      "10 Train Loss 181.77428 Test MSE 5.468996108792809 Test RE 1.117794240263684\n",
      "11 Train Loss 175.53557 Test MSE 5.433629529795162 Test RE 1.1141741355221053\n",
      "12 Train Loss 159.79433 Test MSE 5.372686378708849 Test RE 1.1079082729528782\n",
      "13 Train Loss 151.31116 Test MSE 5.341228842396997 Test RE 1.1046600626892555\n",
      "14 Train Loss 143.44424 Test MSE 5.319909372409272 Test RE 1.102453237683289\n",
      "15 Train Loss 136.7652 Test MSE 5.313880835670486 Test RE 1.1018284090146084\n",
      "16 Train Loss 129.38506 Test MSE 5.296010965234377 Test RE 1.099974198059572\n",
      "17 Train Loss 127.23296 Test MSE 5.279741482078198 Test RE 1.0982833238138225\n",
      "18 Train Loss 122.32159 Test MSE 5.257682059296406 Test RE 1.0959865394313113\n",
      "19 Train Loss 120.714424 Test MSE 5.250909478739745 Test RE 1.0952804251282704\n",
      "20 Train Loss 119.14917 Test MSE 5.228359566634891 Test RE 1.0929260662051916\n",
      "21 Train Loss 117.604774 Test MSE 5.212719853697808 Test RE 1.0912901944195716\n",
      "22 Train Loss 116.888115 Test MSE 5.207237237644438 Test RE 1.0907161467666942\n",
      "23 Train Loss 115.41496 Test MSE 5.170829148383019 Test RE 1.086896410346262\n",
      "24 Train Loss 113.18359 Test MSE 5.108198750220276 Test RE 1.0802939739201047\n",
      "25 Train Loss 111.62211 Test MSE 5.066071167898008 Test RE 1.0758301310211829\n",
      "26 Train Loss 108.849 Test MSE 4.962379466376991 Test RE 1.0647632320056113\n",
      "27 Train Loss 105.5932 Test MSE 4.875088439247243 Test RE 1.055356792292703\n",
      "28 Train Loss 103.70572 Test MSE 4.849044801233747 Test RE 1.052534060259779\n",
      "29 Train Loss 101.70687 Test MSE 4.837142327698768 Test RE 1.0512414906481564\n",
      "30 Train Loss 100.75229 Test MSE 4.834463120560542 Test RE 1.0509503183376887\n",
      "31 Train Loss 99.14509 Test MSE 4.83321627370236 Test RE 1.050814785335394\n",
      "32 Train Loss 96.36034 Test MSE 4.83806167027062 Test RE 1.0513413848701838\n",
      "33 Train Loss 93.83474 Test MSE 4.856568524829956 Test RE 1.0533502937966757\n",
      "34 Train Loss 92.800735 Test MSE 4.862719383711339 Test RE 1.0540171184130231\n",
      "35 Train Loss 91.59233 Test MSE 4.849299031044761 Test RE 1.052561651469902\n",
      "36 Train Loss 90.915634 Test MSE 4.848112539344552 Test RE 1.0524328769753786\n",
      "37 Train Loss 90.10277 Test MSE 4.853688901551806 Test RE 1.0530379640340812\n",
      "38 Train Loss 89.40672 Test MSE 4.847041578865716 Test RE 1.052316627995885\n",
      "39 Train Loss 88.665985 Test MSE 4.852674772704614 Test RE 1.0529279475098914\n",
      "40 Train Loss 87.489784 Test MSE 4.848843354219703 Test RE 1.0525121969800526\n",
      "41 Train Loss 85.953766 Test MSE 4.844632329860283 Test RE 1.0520550655694223\n",
      "42 Train Loss 85.09219 Test MSE 4.849619598057346 Test RE 1.0525964411339237\n",
      "43 Train Loss 83.558495 Test MSE 4.869731505799464 Test RE 1.0547767997358288\n",
      "44 Train Loss 82.73938 Test MSE 4.875818441022789 Test RE 1.055435804550977\n",
      "45 Train Loss 82.379295 Test MSE 4.876914935784444 Test RE 1.0555544733230777\n",
      "46 Train Loss 81.96357 Test MSE 4.88610195359102 Test RE 1.0565482199060943\n",
      "47 Train Loss 81.76817 Test MSE 4.885188780067882 Test RE 1.0564494850707762\n",
      "48 Train Loss 81.21349 Test MSE 4.889217201791646 Test RE 1.0568849797107998\n",
      "49 Train Loss 80.98841 Test MSE 4.891087818905708 Test RE 1.05708714275473\n",
      "50 Train Loss 80.627556 Test MSE 4.886751654783938 Test RE 1.056618461770469\n",
      "51 Train Loss 80.220406 Test MSE 4.88499242396547 Test RE 1.0564282533029639\n",
      "52 Train Loss 80.00437 Test MSE 4.888756975597284 Test RE 1.0568352357968962\n",
      "53 Train Loss 79.53082 Test MSE 4.896888647210986 Test RE 1.0577138094791245\n",
      "54 Train Loss 79.21757 Test MSE 4.89970620878286 Test RE 1.0580180583032286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 78.51139 Test MSE 4.8996992904807 Test RE 1.058017311351178\n",
      "56 Train Loss 77.92006 Test MSE 4.885066208594813 Test RE 1.0564362316032352\n",
      "57 Train Loss 77.22303 Test MSE 4.870774861048903 Test RE 1.0548897883029842\n",
      "58 Train Loss 76.83271 Test MSE 4.874976884734077 Test RE 1.055344717590044\n",
      "59 Train Loss 76.56127 Test MSE 4.879034236197458 Test RE 1.0557837980173934\n",
      "60 Train Loss 76.27766 Test MSE 4.882352646004064 Test RE 1.0561427755960802\n",
      "61 Train Loss 75.7416 Test MSE 4.880153223889379 Test RE 1.0559048610483115\n",
      "62 Train Loss 74.536255 Test MSE 4.869980895296192 Test RE 1.0548038080921596\n",
      "63 Train Loss 74.11035 Test MSE 4.866474497989799 Test RE 1.0544240091469588\n",
      "64 Train Loss 73.75407 Test MSE 4.871331982304367 Test RE 1.0549501159444346\n",
      "65 Train Loss 73.601616 Test MSE 4.873748200112391 Test RE 1.0552117151605032\n",
      "66 Train Loss 73.316025 Test MSE 4.881819677639679 Test RE 1.0560851285874646\n",
      "67 Train Loss 72.78698 Test MSE 4.889920892377687 Test RE 1.0569610341405404\n",
      "68 Train Loss 72.41382 Test MSE 4.900268549648036 Test RE 1.0580787710985244\n",
      "69 Train Loss 72.29138 Test MSE 4.904439548624301 Test RE 1.0585289818075765\n",
      "70 Train Loss 72.119644 Test MSE 4.909360373406271 Test RE 1.059059881382347\n",
      "71 Train Loss 71.917435 Test MSE 4.918791857395372 Test RE 1.0600766852907213\n",
      "72 Train Loss 71.59475 Test MSE 4.919098966179713 Test RE 1.0601097781507258\n",
      "73 Train Loss 71.21732 Test MSE 4.916814979984937 Test RE 1.0598636398603845\n",
      "74 Train Loss 70.85449 Test MSE 4.934109440523457 Test RE 1.0617259918016981\n",
      "75 Train Loss 70.435104 Test MSE 4.952455959540855 Test RE 1.063698070322817\n",
      "76 Train Loss 70.26956 Test MSE 4.970394603544545 Test RE 1.0656227773221587\n",
      "77 Train Loss 70.084175 Test MSE 4.9996833359282915 Test RE 1.0687578299095462\n",
      "78 Train Loss 69.847336 Test MSE 5.010010574122665 Test RE 1.0698610620753035\n",
      "79 Train Loss 69.55669 Test MSE 5.0135933830700985 Test RE 1.0702435385872124\n",
      "80 Train Loss 69.276886 Test MSE 5.037526489917687 Test RE 1.0727949777870163\n",
      "81 Train Loss 69.099976 Test MSE 5.059672485873479 Test RE 1.0751505047648826\n",
      "82 Train Loss 68.828445 Test MSE 5.082302929710729 Test RE 1.077552239989394\n",
      "83 Train Loss 68.48753 Test MSE 5.09575552991283 Test RE 1.0789774108115853\n",
      "84 Train Loss 68.24179 Test MSE 5.102995373162231 Test RE 1.0797436224789585\n",
      "85 Train Loss 68.111336 Test MSE 5.109378223070213 Test RE 1.0804186855779447\n",
      "86 Train Loss 67.75637 Test MSE 5.133868638484248 Test RE 1.0830049367764925\n",
      "87 Train Loss 67.40929 Test MSE 5.14437564837094 Test RE 1.0841126128947693\n",
      "88 Train Loss 67.08593 Test MSE 5.169918502913786 Test RE 1.08680069833906\n",
      "89 Train Loss 66.8345 Test MSE 5.218088542533854 Test RE 1.0918520210571023\n",
      "90 Train Loss 66.57607 Test MSE 5.241580196193207 Test RE 1.094307001068324\n",
      "91 Train Loss 66.42512 Test MSE 5.2509161820055565 Test RE 1.095281124240825\n",
      "92 Train Loss 66.1808 Test MSE 5.285581517872662 Test RE 1.098890573359641\n",
      "93 Train Loss 65.91994 Test MSE 5.318306427443628 Test RE 1.1022871347593068\n",
      "94 Train Loss 65.673355 Test MSE 5.335090274560998 Test RE 1.104025098304005\n",
      "95 Train Loss 65.471985 Test MSE 5.33992362456757 Test RE 1.1045250834414204\n",
      "96 Train Loss 65.23319 Test MSE 5.378496240740285 Test RE 1.1085071404985425\n",
      "97 Train Loss 65.04137 Test MSE 5.409687150544199 Test RE 1.1117167145396238\n",
      "98 Train Loss 64.69743 Test MSE 5.4270267704379 Test RE 1.1134969767375036\n",
      "99 Train Loss 64.13584 Test MSE 5.567057460910043 Test RE 1.1277709727185175\n",
      "Training time: 72.97\n",
      "KG_stan_tune1\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 986.8299 Test MSE 6.876245983397354 Test RE 1.253382891705443\n",
      "1 Train Loss 845.8387 Test MSE 6.8873013495028035 Test RE 1.2543900576585891\n",
      "2 Train Loss 793.7738 Test MSE 6.8979273875051055 Test RE 1.2553573493805334\n",
      "3 Train Loss 654.2745 Test MSE 6.947099227215377 Test RE 1.2598238079204491\n",
      "4 Train Loss 570.4296 Test MSE 6.981360473624844 Test RE 1.2629265451964031\n",
      "5 Train Loss 470.6135 Test MSE 6.975193282001869 Test RE 1.2623686001585765\n",
      "6 Train Loss 343.70706 Test MSE 6.887734797549964 Test RE 1.2544295291684724\n",
      "7 Train Loss 282.32455 Test MSE 6.762771867499873 Test RE 1.2429979974401177\n",
      "8 Train Loss 213.8102 Test MSE 6.536835937171578 Test RE 1.2220580968355028\n",
      "9 Train Loss 184.58618 Test MSE 6.583666139474322 Test RE 1.2264277257920821\n",
      "10 Train Loss 164.83195 Test MSE 6.639427058993057 Test RE 1.2316104419585554\n",
      "11 Train Loss 154.70667 Test MSE 6.602903753238112 Test RE 1.2282182428325712\n",
      "12 Train Loss 145.49239 Test MSE 6.602052762414464 Test RE 1.2281390930999627\n",
      "13 Train Loss 136.31764 Test MSE 6.589435682815507 Test RE 1.2269649931910178\n",
      "14 Train Loss 131.69786 Test MSE 6.584770159533109 Test RE 1.226530551787709\n",
      "15 Train Loss 124.12786 Test MSE 6.572060226372534 Test RE 1.2253462544804503\n",
      "16 Train Loss 114.00554 Test MSE 6.593450521302068 Test RE 1.2273387214128577\n",
      "17 Train Loss 112.17047 Test MSE 6.571160313121529 Test RE 1.2252623581797102\n",
      "18 Train Loss 108.4801 Test MSE 6.5325673518032 Test RE 1.2216590267629912\n",
      "19 Train Loss 104.25206 Test MSE 6.500190592745275 Test RE 1.2186278685430891\n",
      "20 Train Loss 100.630646 Test MSE 6.4572067767584 Test RE 1.2145919746534863\n",
      "21 Train Loss 98.00967 Test MSE 6.415935068025207 Test RE 1.2107041757488974\n",
      "22 Train Loss 95.51997 Test MSE 6.38842769329877 Test RE 1.2081060302286895\n",
      "23 Train Loss 92.48881 Test MSE 6.390399691642692 Test RE 1.2082924766739973\n",
      "24 Train Loss 90.22263 Test MSE 6.3561621429511606 Test RE 1.2050513232569102\n",
      "25 Train Loss 87.57223 Test MSE 6.344904376569916 Test RE 1.203983682260723\n",
      "26 Train Loss 85.07045 Test MSE 6.3168139608945815 Test RE 1.2013155634094104\n",
      "27 Train Loss 83.50859 Test MSE 6.295609503324411 Test RE 1.1992975636447343\n",
      "28 Train Loss 80.76784 Test MSE 6.290056928804837 Test RE 1.1987685713328426\n",
      "29 Train Loss 77.73062 Test MSE 6.27312592594718 Test RE 1.1971541161125498\n",
      "30 Train Loss 75.077965 Test MSE 6.294893986376507 Test RE 1.1992294096307914\n",
      "31 Train Loss 73.541916 Test MSE 6.274546515837899 Test RE 1.1972896600809246\n",
      "32 Train Loss 72.26618 Test MSE 6.263823013944267 Test RE 1.1962661097515535\n",
      "33 Train Loss 70.806145 Test MSE 6.257996453995267 Test RE 1.1957096015432824\n",
      "34 Train Loss 68.85674 Test MSE 6.232358356054286 Test RE 1.1932577639157826\n",
      "35 Train Loss 68.30793 Test MSE 6.235902792422079 Test RE 1.1935970275467607\n",
      "36 Train Loss 66.581795 Test MSE 6.247940595053564 Test RE 1.1947485334680576\n",
      "37 Train Loss 64.51639 Test MSE 6.208371441716897 Test RE 1.190959262796357\n",
      "38 Train Loss 63.837067 Test MSE 6.187408357516508 Test RE 1.1889468759495896\n",
      "39 Train Loss 63.110188 Test MSE 6.1891956772990735 Test RE 1.1891185855499689\n",
      "40 Train Loss 61.789345 Test MSE 6.194345337050059 Test RE 1.1896131799372491\n",
      "41 Train Loss 60.606903 Test MSE 6.231498685589852 Test RE 1.193175464104534\n",
      "42 Train Loss 59.70392 Test MSE 6.2575164516318384 Test RE 1.195663743859833\n",
      "43 Train Loss 59.220974 Test MSE 6.262459650782585 Test RE 1.1961359149888524\n",
      "44 Train Loss 58.223522 Test MSE 6.279862641966661 Test RE 1.197796756109438\n",
      "45 Train Loss 57.550793 Test MSE 6.299011837706903 Test RE 1.199621587886431\n",
      "46 Train Loss 57.076992 Test MSE 6.308428458850518 Test RE 1.2005179319170327\n",
      "47 Train Loss 56.62578 Test MSE 6.322815566176059 Test RE 1.2018861129122707\n",
      "48 Train Loss 55.829697 Test MSE 6.336905067064036 Test RE 1.2032244844044877\n",
      "49 Train Loss 55.19165 Test MSE 6.3291758895431265 Test RE 1.2024904688975013\n",
      "50 Train Loss 54.65889 Test MSE 6.304061727948049 Test RE 1.2001023572382565\n",
      "51 Train Loss 54.256706 Test MSE 6.3024514323872625 Test RE 1.1999490717052828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 53.72062 Test MSE 6.320372311124447 Test RE 1.2016538747564969\n",
      "53 Train Loss 53.069935 Test MSE 6.313399383727306 Test RE 1.2009908317326083\n",
      "54 Train Loss 52.704735 Test MSE 6.317659938595369 Test RE 1.2013960036566893\n",
      "55 Train Loss 51.974564 Test MSE 6.297567573687022 Test RE 1.1994840528519177\n",
      "56 Train Loss 51.741493 Test MSE 6.28888909064065 Test RE 1.1986572819843937\n",
      "57 Train Loss 51.435867 Test MSE 6.27216263698783 Test RE 1.1970621962602555\n",
      "58 Train Loss 51.082237 Test MSE 6.2426574285999505 Test RE 1.1942432957672373\n",
      "59 Train Loss 50.227474 Test MSE 6.201842423718777 Test RE 1.1903328634290575\n",
      "60 Train Loss 49.64395 Test MSE 6.150160076548477 Test RE 1.1853627356256957\n",
      "61 Train Loss 48.678734 Test MSE 6.090902077609583 Test RE 1.1796383120064777\n",
      "62 Train Loss 47.734764 Test MSE 6.049380591109029 Test RE 1.1756106576696068\n",
      "63 Train Loss 47.078976 Test MSE 5.997243808481452 Test RE 1.1705336756927054\n",
      "64 Train Loss 46.66524 Test MSE 5.971114277345247 Test RE 1.167980929419523\n",
      "65 Train Loss 46.37095 Test MSE 5.948829142427019 Test RE 1.1657993480157\n",
      "66 Train Loss 45.959972 Test MSE 5.960241354376848 Test RE 1.1669170448171673\n",
      "67 Train Loss 45.3374 Test MSE 5.954562461890874 Test RE 1.1663609955490477\n",
      "68 Train Loss 44.821026 Test MSE 5.9458697127236855 Test RE 1.165509330406118\n",
      "69 Train Loss 44.46057 Test MSE 5.962102770471649 Test RE 1.1670992478920728\n",
      "70 Train Loss 43.883087 Test MSE 6.007846086772437 Test RE 1.1715678877485862\n",
      "71 Train Loss 43.49132 Test MSE 6.002804143952337 Test RE 1.1710761792345992\n",
      "72 Train Loss 43.223328 Test MSE 6.003044400745017 Test RE 1.1710996146311927\n",
      "73 Train Loss 43.07361 Test MSE 6.013004965025725 Test RE 1.172070786715384\n",
      "74 Train Loss 42.816444 Test MSE 6.033596871631067 Test RE 1.174075985823315\n",
      "75 Train Loss 42.535835 Test MSE 6.052806981229491 Test RE 1.1759435455133462\n",
      "76 Train Loss 42.072506 Test MSE 6.061780354811958 Test RE 1.1768148993112466\n",
      "77 Train Loss 41.61547 Test MSE 6.062546269216193 Test RE 1.1768892430650755\n",
      "78 Train Loss 41.353374 Test MSE 6.053914551423334 Test RE 1.1760511303453545\n",
      "79 Train Loss 41.052223 Test MSE 6.078165121706115 Test RE 1.1784042694906118\n",
      "80 Train Loss 40.888092 Test MSE 6.1021043764533704 Test RE 1.1807226005287883\n",
      "81 Train Loss 40.470654 Test MSE 6.083450872656998 Test RE 1.1789165456278556\n",
      "82 Train Loss 40.181564 Test MSE 6.106281951729576 Test RE 1.1811266999432144\n",
      "83 Train Loss 39.893173 Test MSE 6.157287846013402 Test RE 1.1860494287865333\n",
      "84 Train Loss 39.63205 Test MSE 6.167327762253678 Test RE 1.1870160058752912\n",
      "85 Train Loss 39.37674 Test MSE 6.1554314008741935 Test RE 1.1858706161548653\n",
      "86 Train Loss 39.20599 Test MSE 6.1600105808310985 Test RE 1.1863116336109922\n",
      "87 Train Loss 38.982582 Test MSE 6.146824546177642 Test RE 1.1850412521531049\n",
      "88 Train Loss 38.68107 Test MSE 6.125059965272761 Test RE 1.1829414038951567\n",
      "89 Train Loss 38.22808 Test MSE 6.149521684121594 Test RE 1.1853012131431608\n",
      "90 Train Loss 37.92324 Test MSE 6.191862318384004 Test RE 1.1893747263442978\n",
      "91 Train Loss 37.707188 Test MSE 6.206370533186217 Test RE 1.1907673290012022\n",
      "92 Train Loss 37.51756 Test MSE 6.18257477662339 Test RE 1.1884823847306771\n",
      "93 Train Loss 37.385414 Test MSE 6.153033056686874 Test RE 1.1856395679303378\n",
      "94 Train Loss 37.256107 Test MSE 6.164614053455381 Test RE 1.1867548254803282\n",
      "95 Train Loss 37.202705 Test MSE 6.181476209001554 Test RE 1.1883767906765943\n",
      "96 Train Loss 37.08924 Test MSE 6.18016930893834 Test RE 1.1882511595370124\n",
      "97 Train Loss 36.987946 Test MSE 6.180024996288479 Test RE 1.188237286076107\n",
      "98 Train Loss 36.907562 Test MSE 6.195531532641827 Test RE 1.1897270778783378\n",
      "99 Train Loss 36.700134 Test MSE 6.213881844892865 Test RE 1.1914876791608626\n",
      "Training time: 72.23\n",
      "KG_stan_tune1\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 670.6061 Test MSE 5.455434689791354 Test RE 1.1164074880381971\n",
      "1 Train Loss 383.8525 Test MSE 5.439713191266763 Test RE 1.114797693127358\n",
      "2 Train Loss 285.6906 Test MSE 5.435152680639027 Test RE 1.11433028679749\n",
      "3 Train Loss 230.6354 Test MSE 5.423548818059674 Test RE 1.1131401229497917\n",
      "4 Train Loss 183.61624 Test MSE 5.358928454266701 Test RE 1.1064888444131153\n",
      "5 Train Loss 162.78424 Test MSE 5.30172080896101 Test RE 1.1005670016681186\n",
      "6 Train Loss 147.29825 Test MSE 5.285653497140524 Test RE 1.098898055702821\n",
      "7 Train Loss 136.02461 Test MSE 5.302942909890071 Test RE 1.1006938403402524\n",
      "8 Train Loss 123.87651 Test MSE 5.295189734294982 Test RE 1.0998889104844831\n",
      "9 Train Loss 116.94937 Test MSE 5.3171585397115475 Test RE 1.1021681711212938\n",
      "10 Train Loss 108.0557 Test MSE 5.378764760886072 Test RE 1.1085348111308757\n",
      "11 Train Loss 104.58434 Test MSE 5.384415284388369 Test RE 1.109116929709782\n",
      "12 Train Loss 99.35246 Test MSE 5.276362664879758 Test RE 1.0979318395137396\n",
      "13 Train Loss 93.081825 Test MSE 5.251899319006564 Test RE 1.0953836550148734\n",
      "14 Train Loss 89.847595 Test MSE 5.280561916491383 Test RE 1.0983686532220056\n",
      "15 Train Loss 86.999725 Test MSE 5.2687452574172955 Test RE 1.0971390192105073\n",
      "16 Train Loss 84.43026 Test MSE 5.305596312008425 Test RE 1.100969179729141\n",
      "17 Train Loss 82.44438 Test MSE 5.303633200180583 Test RE 1.1007654773123425\n",
      "18 Train Loss 80.67082 Test MSE 5.262033863048652 Test RE 1.0964400217598327\n",
      "19 Train Loss 78.612915 Test MSE 5.2513926070709935 Test RE 1.095330811526561\n",
      "20 Train Loss 77.11649 Test MSE 5.260349277724023 Test RE 1.096264500785441\n",
      "21 Train Loss 76.09465 Test MSE 5.244443902944916 Test RE 1.0946058943712187\n",
      "22 Train Loss 75.24798 Test MSE 5.236451723088239 Test RE 1.093771523479441\n",
      "23 Train Loss 74.02831 Test MSE 5.259211823668335 Test RE 1.0961459708312948\n",
      "24 Train Loss 73.11082 Test MSE 5.252925129711099 Test RE 1.0954906259740769\n",
      "25 Train Loss 71.48013 Test MSE 5.259651872618975 Test RE 1.096191828253552\n",
      "26 Train Loss 70.087654 Test MSE 5.298533385975719 Test RE 1.1002361185364027\n",
      "27 Train Loss 68.60097 Test MSE 5.3421270088110795 Test RE 1.1047529370904448\n",
      "28 Train Loss 67.12226 Test MSE 5.381532199758419 Test RE 1.108819951675244\n",
      "29 Train Loss 65.813705 Test MSE 5.383938157273744 Test RE 1.1090677877457764\n",
      "30 Train Loss 64.80878 Test MSE 5.39543727912267 Test RE 1.1102515404960267\n",
      "31 Train Loss 63.52238 Test MSE 5.319908629724972 Test RE 1.102453160729465\n",
      "32 Train Loss 62.018036 Test MSE 5.23327304075807 Test RE 1.0934394971205554\n",
      "33 Train Loss 60.724236 Test MSE 5.196937114283648 Test RE 1.0896368727265855\n",
      "34 Train Loss 58.982807 Test MSE 5.1978433647371025 Test RE 1.0897318749213671\n",
      "35 Train Loss 58.27552 Test MSE 5.310517641393199 Test RE 1.1014796761736458\n",
      "36 Train Loss 56.74246 Test MSE 5.4062201112271655 Test RE 1.1113604108191004\n",
      "37 Train Loss 55.764988 Test MSE 5.542103058267611 Test RE 1.125240510289319\n",
      "38 Train Loss 54.99393 Test MSE 5.609271222046897 Test RE 1.1320387161502654\n",
      "39 Train Loss 54.05915 Test MSE 5.690117962492846 Test RE 1.140167599151899\n",
      "40 Train Loss 53.32059 Test MSE 5.581763899778076 Test RE 1.129259600776933\n",
      "41 Train Loss 52.148464 Test MSE 5.527953652635464 Test RE 1.1238031805043946\n",
      "42 Train Loss 51.600056 Test MSE 5.55200025827874 Test RE 1.1262448007778605\n",
      "43 Train Loss 51.072796 Test MSE 5.528197440919435 Test RE 1.1238279606532156\n",
      "44 Train Loss 49.99868 Test MSE 5.56989076686885 Test RE 1.1280579208760808\n",
      "45 Train Loss 49.575584 Test MSE 5.573948573627196 Test RE 1.1284687554736292\n",
      "46 Train Loss 48.74902 Test MSE 5.547331758203791 Test RE 1.125771189515991\n",
      "47 Train Loss 47.456585 Test MSE 5.619125519267341 Test RE 1.1330326555048327\n",
      "48 Train Loss 45.480103 Test MSE 5.773905284693213 Test RE 1.1485314396903548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 44.61872 Test MSE 5.867402813916659 Test RE 1.157793248399054\n",
      "50 Train Loss 44.125595 Test MSE 5.890451899902734 Test RE 1.16006511556191\n",
      "51 Train Loss 43.441746 Test MSE 5.898981587930564 Test RE 1.1609047297517563\n",
      "52 Train Loss 42.737732 Test MSE 5.925676157841714 Test RE 1.163528476888089\n",
      "53 Train Loss 42.261963 Test MSE 5.995630806501509 Test RE 1.170376253369503\n",
      "54 Train Loss 41.79527 Test MSE 6.003364039692449 Test RE 1.171130792483663\n",
      "55 Train Loss 41.13082 Test MSE 5.972376582196524 Test RE 1.1681043795841972\n",
      "56 Train Loss 40.363285 Test MSE 5.864770147045209 Test RE 1.157533471968451\n",
      "57 Train Loss 39.970486 Test MSE 5.88584822725935 Test RE 1.1596117034967417\n",
      "58 Train Loss 39.633892 Test MSE 5.873826879515053 Test RE 1.1584268937511844\n",
      "59 Train Loss 38.887577 Test MSE 5.884206635423422 Test RE 1.1594499815340118\n",
      "60 Train Loss 37.8053 Test MSE 5.862573431345436 Test RE 1.1573166680667042\n",
      "61 Train Loss 37.029648 Test MSE 5.801222281124417 Test RE 1.1512451495824279\n",
      "62 Train Loss 36.290146 Test MSE 5.84124271018404 Test RE 1.1552093260030465\n",
      "63 Train Loss 35.510437 Test MSE 5.784563162259162 Test RE 1.149590970743306\n",
      "64 Train Loss 35.078796 Test MSE 5.801912408757028 Test RE 1.1513136250194524\n",
      "65 Train Loss 34.56879 Test MSE 5.7986492729835435 Test RE 1.1509898161783327\n",
      "66 Train Loss 33.94193 Test MSE 5.83271562926138 Test RE 1.1543658273248947\n",
      "67 Train Loss 33.339836 Test MSE 5.920534198342916 Test RE 1.1630235459238005\n",
      "68 Train Loss 32.599846 Test MSE 5.985775083350082 Test RE 1.169413915216246\n",
      "69 Train Loss 32.270958 Test MSE 5.969000323549047 Test RE 1.1677741609527195\n",
      "70 Train Loss 31.779827 Test MSE 6.052821721812139 Test RE 1.1759449774177935\n",
      "71 Train Loss 31.30058 Test MSE 6.0517548590193515 Test RE 1.1758413375546333\n",
      "72 Train Loss 31.070637 Test MSE 6.037671076640097 Test RE 1.1744723181546624\n",
      "73 Train Loss 30.71067 Test MSE 6.012678556232052 Test RE 1.1720389740521773\n",
      "74 Train Loss 30.170208 Test MSE 6.020111455300549 Test RE 1.1727631901096212\n",
      "75 Train Loss 29.792809 Test MSE 6.018807749446572 Test RE 1.172636197359345\n",
      "76 Train Loss 29.132664 Test MSE 6.094229658521515 Test RE 1.1799604979407872\n",
      "77 Train Loss 28.726303 Test MSE 6.1050624108375935 Test RE 1.1810087472963982\n",
      "78 Train Loss 28.364422 Test MSE 6.087038676848728 Test RE 1.1792641360301945\n",
      "79 Train Loss 28.044682 Test MSE 6.094133713586959 Test RE 1.179951209508558\n",
      "80 Train Loss 27.694214 Test MSE 6.0746815238657685 Test RE 1.1780665298237107\n",
      "81 Train Loss 27.377373 Test MSE 6.120711932754954 Test RE 1.1825214585517603\n",
      "82 Train Loss 27.127111 Test MSE 6.0929151198781915 Test RE 1.1798332310496302\n",
      "83 Train Loss 26.818851 Test MSE 6.093327453578451 Test RE 1.1798731525619048\n",
      "84 Train Loss 26.553951 Test MSE 6.101393921669681 Test RE 1.1806538640416855\n",
      "85 Train Loss 26.246975 Test MSE 6.0434040332054995 Test RE 1.175029784859518\n",
      "86 Train Loss 26.005611 Test MSE 5.98507758296375 Test RE 1.1693457794769864\n",
      "87 Train Loss 25.669617 Test MSE 6.014715734832809 Test RE 1.1722375087390629\n",
      "88 Train Loss 25.333008 Test MSE 6.035061345824422 Test RE 1.1742184629972225\n",
      "89 Train Loss 25.044344 Test MSE 6.025625800162226 Test RE 1.1733001851860603\n",
      "90 Train Loss 24.765686 Test MSE 6.000572600579622 Test RE 1.1708584851250177\n",
      "91 Train Loss 24.364761 Test MSE 5.912647243878969 Test RE 1.1622486352231032\n",
      "92 Train Loss 23.765604 Test MSE 5.904954633150712 Test RE 1.1614923211802652\n",
      "93 Train Loss 23.453815 Test MSE 5.889803576904639 Test RE 1.1600012734660738\n",
      "94 Train Loss 22.949635 Test MSE 5.8465365346567895 Test RE 1.1557326812839963\n",
      "95 Train Loss 22.609142 Test MSE 5.817148729938723 Test RE 1.1528243581600912\n",
      "96 Train Loss 22.213165 Test MSE 5.8360297374299615 Test RE 1.1546937320422088\n",
      "97 Train Loss 21.937746 Test MSE 5.823739497200276 Test RE 1.153477242115503\n",
      "98 Train Loss 21.55243 Test MSE 5.804997822018099 Test RE 1.1516197142821711\n",
      "99 Train Loss 21.320312 Test MSE 5.779445443788385 Test RE 1.149082325179229\n",
      "Training time: 70.34\n",
      "KG_stan_tune1\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 575.2061 Test MSE 6.466606649367913 Test RE 1.2154757048996634\n",
      "1 Train Loss 307.33826 Test MSE 6.460431927420836 Test RE 1.2148952600551741\n",
      "2 Train Loss 193.53857 Test MSE 6.451153068936301 Test RE 1.2140224939684998\n",
      "3 Train Loss 176.09456 Test MSE 6.451261271687483 Test RE 1.2140326750959376\n",
      "4 Train Loss 155.86967 Test MSE 6.4468842001641455 Test RE 1.213620754908415\n",
      "5 Train Loss 143.31424 Test MSE 6.448429991146818 Test RE 1.2137662431412277\n",
      "6 Train Loss 132.89926 Test MSE 6.435541912428708 Test RE 1.2125526966685958\n",
      "7 Train Loss 127.22316 Test MSE 6.457758993038021 Test RE 1.2146439091156669\n",
      "8 Train Loss 123.545616 Test MSE 6.477853825684618 Test RE 1.216532266031277\n",
      "9 Train Loss 121.01558 Test MSE 6.4949524578912055 Test RE 1.2181367580493283\n",
      "10 Train Loss 116.6484 Test MSE 6.534120666440092 Test RE 1.2218042612439122\n",
      "11 Train Loss 114.68166 Test MSE 6.574412766470689 Test RE 1.2255655478354546\n",
      "12 Train Loss 112.98941 Test MSE 6.608869966395211 Test RE 1.2287730106707868\n",
      "13 Train Loss 110.99774 Test MSE 6.632474020586162 Test RE 1.230965380435523\n",
      "14 Train Loss 107.75336 Test MSE 6.684795894048116 Test RE 1.2358112261820713\n",
      "15 Train Loss 106.031525 Test MSE 6.694634945901664 Test RE 1.2367203593903529\n",
      "16 Train Loss 104.12066 Test MSE 6.6743268302735 Test RE 1.2348431445693278\n",
      "17 Train Loss 101.37389 Test MSE 6.652826030825095 Test RE 1.2328525669242179\n",
      "18 Train Loss 98.15984 Test MSE 6.65499277829855 Test RE 1.23305331339695\n",
      "19 Train Loss 96.757645 Test MSE 6.643908524303556 Test RE 1.2320260266442193\n",
      "20 Train Loss 94.62503 Test MSE 6.625686816397368 Test RE 1.230335377823689\n",
      "21 Train Loss 93.084045 Test MSE 6.635760113362337 Test RE 1.231270286683082\n",
      "22 Train Loss 90.40896 Test MSE 6.616103836257147 Test RE 1.2294453156999174\n",
      "23 Train Loss 89.00661 Test MSE 6.613015037074547 Test RE 1.2291582923164635\n",
      "24 Train Loss 86.98597 Test MSE 6.623750677155192 Test RE 1.2301556021475866\n",
      "25 Train Loss 85.95466 Test MSE 6.609082304783523 Test RE 1.2287927503226703\n",
      "26 Train Loss 85.21218 Test MSE 6.595095765637847 Test RE 1.2274918389742107\n",
      "27 Train Loss 84.41686 Test MSE 6.578830499392361 Test RE 1.2259772433155685\n",
      "28 Train Loss 82.705574 Test MSE 6.514877721796161 Test RE 1.22000383173539\n",
      "29 Train Loss 81.877625 Test MSE 6.4556607866151525 Test RE 1.2144465666084734\n",
      "30 Train Loss 81.01639 Test MSE 6.405752686982422 Test RE 1.2097430729464815\n",
      "31 Train Loss 80.574036 Test MSE 6.409300287445421 Test RE 1.2100780133711446\n",
      "32 Train Loss 80.009735 Test MSE 6.388753975587402 Test RE 1.2081368812131867\n",
      "33 Train Loss 79.05288 Test MSE 6.367982590106745 Test RE 1.2061713095687152\n",
      "34 Train Loss 78.51734 Test MSE 6.372233152799581 Test RE 1.2065737958697655\n",
      "35 Train Loss 78.054375 Test MSE 6.376443805526577 Test RE 1.2069723707594822\n",
      "36 Train Loss 77.47559 Test MSE 6.393390830239693 Test RE 1.2085752248288724\n",
      "37 Train Loss 77.100075 Test MSE 6.390634414644402 Test RE 1.2083146671038978\n",
      "38 Train Loss 76.91169 Test MSE 6.38645406016586 Test RE 1.2079194004046203\n",
      "39 Train Loss 76.512726 Test MSE 6.365232072077559 Test RE 1.205910791091679\n",
      "40 Train Loss 76.15956 Test MSE 6.348237710172198 Test RE 1.2042999007618105\n",
      "41 Train Loss 75.63122 Test MSE 6.340664061346867 Test RE 1.2035813023914241\n",
      "42 Train Loss 75.223724 Test MSE 6.335564710127541 Test RE 1.2030972270480644\n",
      "43 Train Loss 74.979 Test MSE 6.331839908782172 Test RE 1.2027435129571191\n",
      "44 Train Loss 74.671 Test MSE 6.31882597801817 Test RE 1.201506868318841\n",
      "45 Train Loss 74.060356 Test MSE 6.289065031954262 Test RE 1.1986740490046677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 73.81987 Test MSE 6.271188345964996 Test RE 1.1969692193785855\n",
      "47 Train Loss 73.497696 Test MSE 6.23942096466804 Test RE 1.1939336819137718\n",
      "48 Train Loss 73.133545 Test MSE 6.22854745201828 Test RE 1.1928928870962663\n",
      "49 Train Loss 72.93748 Test MSE 6.209255377409284 Test RE 1.1910440429952918\n",
      "50 Train Loss 72.74552 Test MSE 6.200255145531133 Test RE 1.190180528834957\n",
      "51 Train Loss 72.48811 Test MSE 6.201564546593103 Test RE 1.1903061963552097\n",
      "52 Train Loss 72.315315 Test MSE 6.196592912264437 Test RE 1.189828981806452\n",
      "53 Train Loss 71.73872 Test MSE 6.157567015832707 Test RE 1.1860763160671013\n",
      "54 Train Loss 71.36559 Test MSE 6.1569715786359565 Test RE 1.18601896784588\n",
      "55 Train Loss 70.82087 Test MSE 6.145177811559399 Test RE 1.1848825052135183\n",
      "56 Train Loss 70.02383 Test MSE 6.096835306636214 Test RE 1.180212722869084\n",
      "57 Train Loss 69.7 Test MSE 6.085123870276169 Test RE 1.179078640221263\n",
      "58 Train Loss 69.528915 Test MSE 6.071287716977501 Test RE 1.1777374023736893\n",
      "59 Train Loss 69.23089 Test MSE 6.049194534584453 Test RE 1.175592578817418\n",
      "60 Train Loss 68.56656 Test MSE 6.022219087525357 Test RE 1.1729684634844115\n",
      "61 Train Loss 68.17402 Test MSE 6.00628206478483 Test RE 1.1714153807452554\n",
      "62 Train Loss 67.720825 Test MSE 6.004744258298065 Test RE 1.1712654106413165\n",
      "63 Train Loss 67.41219 Test MSE 6.028947125055856 Test RE 1.1736235021655395\n",
      "64 Train Loss 67.060234 Test MSE 6.025272961025614 Test RE 1.173265832547959\n",
      "65 Train Loss 66.49959 Test MSE 6.019891694554883 Test RE 1.1727417843875552\n",
      "66 Train Loss 65.71163 Test MSE 6.002298950198648 Test RE 1.1710268995309125\n",
      "67 Train Loss 65.41127 Test MSE 5.990556481118291 Test RE 1.1698808820544775\n",
      "68 Train Loss 65.01796 Test MSE 5.9741833556610535 Test RE 1.1682810546794395\n",
      "69 Train Loss 64.797806 Test MSE 5.986953620473638 Test RE 1.1695290322947491\n",
      "70 Train Loss 64.62756 Test MSE 5.971373658099217 Test RE 1.1680062972545784\n",
      "71 Train Loss 64.50439 Test MSE 5.941004945995125 Test RE 1.1650324370741785\n",
      "72 Train Loss 64.2143 Test MSE 5.916539354951728 Test RE 1.1626311082850433\n",
      "73 Train Loss 64.0867 Test MSE 5.909803557714926 Test RE 1.161969110019282\n",
      "74 Train Loss 63.73107 Test MSE 5.87732583657051 Test RE 1.1587718717863256\n",
      "75 Train Loss 63.29354 Test MSE 5.879761566097513 Test RE 1.159011960780539\n",
      "76 Train Loss 63.017406 Test MSE 5.892082708399472 Test RE 1.1602256900946692\n",
      "77 Train Loss 62.408707 Test MSE 5.8579900452450735 Test RE 1.1568641819397223\n",
      "78 Train Loss 61.94777 Test MSE 5.8561879050030825 Test RE 1.1566862205699777\n",
      "79 Train Loss 61.651947 Test MSE 5.840264743337431 Test RE 1.1551126168121302\n",
      "80 Train Loss 61.441635 Test MSE 5.850647766688466 Test RE 1.156138960299299\n",
      "81 Train Loss 61.363884 Test MSE 5.848850738265057 Test RE 1.1559613924285748\n",
      "82 Train Loss 61.2721 Test MSE 5.837966436798194 Test RE 1.1548853099832836\n",
      "83 Train Loss 61.204575 Test MSE 5.832795014902488 Test RE 1.154373682993273\n",
      "84 Train Loss 61.147682 Test MSE 5.830856143154209 Test RE 1.1541818051247774\n",
      "85 Train Loss 61.06979 Test MSE 5.838821623166685 Test RE 1.1549698947456677\n",
      "86 Train Loss 60.916473 Test MSE 5.863974206424707 Test RE 1.1574549216460526\n",
      "87 Train Loss 60.770668 Test MSE 5.8756360372384275 Test RE 1.1586052796359834\n",
      "88 Train Loss 60.586258 Test MSE 5.867958887570992 Test RE 1.1578481110946561\n",
      "89 Train Loss 60.365715 Test MSE 5.875996826590577 Test RE 1.1586408507663972\n",
      "90 Train Loss 60.11492 Test MSE 5.881069410906902 Test RE 1.15914085405949\n",
      "91 Train Loss 59.931458 Test MSE 5.87784907605348 Test RE 1.1588234515113534\n",
      "92 Train Loss 59.763893 Test MSE 5.883312241618288 Test RE 1.1593618605387752\n",
      "93 Train Loss 59.6926 Test MSE 5.879931810004137 Test RE 1.1590287398024055\n",
      "94 Train Loss 59.602844 Test MSE 5.874556545701918 Test RE 1.1584988433253625\n",
      "95 Train Loss 59.483887 Test MSE 5.879910463484894 Test RE 1.1590266359300687\n",
      "96 Train Loss 59.422535 Test MSE 5.882266212871921 Test RE 1.159258791069319\n",
      "97 Train Loss 59.35283 Test MSE 5.880736493407492 Test RE 1.1591080450830051\n",
      "98 Train Loss 59.27291 Test MSE 5.877339292881615 Test RE 1.1587731983067802\n",
      "99 Train Loss 59.17382 Test MSE 5.882216835888079 Test RE 1.1592539255276513\n",
      "Training time: 73.93\n",
      "KG_stan_tune1\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 863.18225 Test MSE 6.544269693282631 Test RE 1.2227527678245718\n",
      "1 Train Loss 609.0217 Test MSE 6.4811525563850925 Test RE 1.2168419752099242\n",
      "2 Train Loss 465.76828 Test MSE 6.460708403395049 Test RE 1.2149212556666769\n",
      "3 Train Loss 403.20773 Test MSE 6.45077418468437 Test RE 1.2139868429187228\n",
      "4 Train Loss 349.30872 Test MSE 6.455902518908719 Test RE 1.2144693038785623\n",
      "5 Train Loss 305.9741 Test MSE 6.460731056437223 Test RE 1.2149233855908734\n",
      "6 Train Loss 265.4049 Test MSE 6.477198623828055 Test RE 1.2164707414602738\n",
      "7 Train Loss 247.8691 Test MSE 6.481827191278876 Test RE 1.2169053052031469\n",
      "8 Train Loss 234.88788 Test MSE 6.455614542343438 Test RE 1.2144422168370521\n",
      "9 Train Loss 219.336 Test MSE 6.426670400807398 Test RE 1.2117166454638713\n",
      "10 Train Loss 212.96243 Test MSE 6.427503641495989 Test RE 1.2117951946055705\n",
      "11 Train Loss 205.7093 Test MSE 6.442226068831456 Test RE 1.2131822309467186\n",
      "12 Train Loss 194.11435 Test MSE 6.475145760201935 Test RE 1.216277953915737\n",
      "13 Train Loss 188.41055 Test MSE 6.481006115851068 Test RE 1.2168282279640676\n",
      "14 Train Loss 180.62685 Test MSE 6.499810039041946 Test RE 1.218592195732458\n",
      "15 Train Loss 175.37842 Test MSE 6.524430323324975 Test RE 1.220897934589336\n",
      "16 Train Loss 170.56487 Test MSE 6.514944786096616 Test RE 1.220010111092921\n",
      "17 Train Loss 164.29608 Test MSE 6.501965631231054 Test RE 1.218794245488733\n",
      "18 Train Loss 156.0666 Test MSE 6.485563093051562 Test RE 1.217255945822501\n",
      "19 Train Loss 150.9495 Test MSE 6.447989064405474 Test RE 1.2137247453546365\n",
      "20 Train Loss 144.14658 Test MSE 6.432198156676736 Test RE 1.2122376488529538\n",
      "21 Train Loss 140.53888 Test MSE 6.391246744458114 Test RE 1.2083725541088854\n",
      "22 Train Loss 136.97472 Test MSE 6.3335577675776955 Test RE 1.2029066569589082\n",
      "23 Train Loss 130.45361 Test MSE 6.211392731741828 Test RE 1.19124901637449\n",
      "24 Train Loss 128.4306 Test MSE 6.147713169587794 Test RE 1.1851269075459365\n",
      "25 Train Loss 126.55947 Test MSE 6.107419317474242 Test RE 1.181236694086162\n",
      "26 Train Loss 122.58443 Test MSE 5.994464502433167 Test RE 1.170262413723692\n",
      "27 Train Loss 120.39092 Test MSE 5.932864748028469 Test RE 1.1642340161396951\n",
      "28 Train Loss 118.84349 Test MSE 5.916602651280106 Test RE 1.1626373272991646\n",
      "29 Train Loss 114.31552 Test MSE 5.815959118621922 Test RE 1.1527064754062422\n",
      "30 Train Loss 112.65214 Test MSE 5.7776599496126 Test RE 1.1489048134867703\n",
      "31 Train Loss 110.07635 Test MSE 5.749244578975876 Test RE 1.1460760908270373\n",
      "32 Train Loss 107.81905 Test MSE 5.739233406830398 Test RE 1.1450778236661272\n",
      "33 Train Loss 106.42515 Test MSE 5.717237391766887 Test RE 1.1428814215940164\n",
      "34 Train Loss 104.72403 Test MSE 5.706764660526776 Test RE 1.141834187120156\n",
      "35 Train Loss 102.64306 Test MSE 5.687887266645842 Test RE 1.1399440874019768\n",
      "36 Train Loss 102.24153 Test MSE 5.666013220444734 Test RE 1.1377500205948043\n",
      "37 Train Loss 101.86607 Test MSE 5.648214534462425 Test RE 1.135961604048159\n",
      "38 Train Loss 100.682 Test MSE 5.6620557912661384 Test RE 1.13735262021525\n",
      "39 Train Loss 99.025406 Test MSE 5.689532591938173 Test RE 1.1401089503057389\n",
      "40 Train Loss 98.44717 Test MSE 5.6856151025516155 Test RE 1.1397163755444297\n",
      "41 Train Loss 97.797005 Test MSE 5.655906876728227 Test RE 1.1367348778211825\n",
      "42 Train Loss 96.53421 Test MSE 5.6547143704224405 Test RE 1.136615035415753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 95.35437 Test MSE 5.651309709987829 Test RE 1.1362728102691886\n",
      "44 Train Loss 94.33025 Test MSE 5.592838207530673 Test RE 1.1303792801302015\n",
      "45 Train Loss 93.38179 Test MSE 5.532573406666438 Test RE 1.1242726679827153\n",
      "46 Train Loss 92.74123 Test MSE 5.514773205754315 Test RE 1.122462624043917\n",
      "47 Train Loss 92.173164 Test MSE 5.51536477244231 Test RE 1.1225228254036148\n",
      "48 Train Loss 91.53896 Test MSE 5.522093097049294 Test RE 1.1232073128522764\n",
      "49 Train Loss 90.90033 Test MSE 5.522645860098018 Test RE 1.123263528127102\n",
      "50 Train Loss 90.17067 Test MSE 5.524062631454483 Test RE 1.1234075990653334\n",
      "51 Train Loss 88.413445 Test MSE 5.534067602995578 Test RE 1.124424475339134\n",
      "52 Train Loss 86.40593 Test MSE 5.537781406657842 Test RE 1.1248017016109557\n",
      "53 Train Loss 85.68075 Test MSE 5.536062434749154 Test RE 1.1246271143120992\n",
      "54 Train Loss 84.87457 Test MSE 5.5070519358016465 Test RE 1.121676565183666\n",
      "55 Train Loss 84.30633 Test MSE 5.481783650899 Test RE 1.119100283910523\n",
      "56 Train Loss 83.8277 Test MSE 5.4682543981297185 Test RE 1.1177184395131698\n",
      "57 Train Loss 83.47436 Test MSE 5.469236998175957 Test RE 1.1178188573775654\n",
      "58 Train Loss 82.97531 Test MSE 5.476563644202762 Test RE 1.1185673276049724\n",
      "59 Train Loss 82.598465 Test MSE 5.478439256247458 Test RE 1.1187588545266902\n",
      "60 Train Loss 82.351395 Test MSE 5.478633166979806 Test RE 1.118778653726703\n",
      "61 Train Loss 81.96267 Test MSE 5.478603160534622 Test RE 1.118775589950092\n",
      "62 Train Loss 81.378365 Test MSE 5.475695735844114 Test RE 1.1184786905998778\n",
      "63 Train Loss 81.07655 Test MSE 5.481774932815411 Test RE 1.1190993940164375\n",
      "64 Train Loss 80.603195 Test MSE 5.48904290660416 Test RE 1.119841023414176\n",
      "65 Train Loss 80.15608 Test MSE 5.473899053202505 Test RE 1.1182951782011201\n",
      "66 Train Loss 79.825714 Test MSE 5.463282999522533 Test RE 1.117210243752891\n",
      "67 Train Loss 79.63965 Test MSE 5.452954814723057 Test RE 1.1161537167120381\n",
      "68 Train Loss 79.34775 Test MSE 5.435610327673916 Test RE 1.1143771998509977\n",
      "69 Train Loss 78.96522 Test MSE 5.434106768943893 Test RE 1.1142230637604107\n",
      "70 Train Loss 78.46058 Test MSE 5.43745325763999 Test RE 1.1145660972299258\n",
      "71 Train Loss 77.99387 Test MSE 5.425283757094426 Test RE 1.1133181499109774\n",
      "72 Train Loss 77.49364 Test MSE 5.424648906433419 Test RE 1.113253009406547\n",
      "73 Train Loss 77.12735 Test MSE 5.436870344485588 Test RE 1.1145063530241326\n",
      "74 Train Loss 76.70843 Test MSE 5.437736772549594 Test RE 1.1145951542141737\n",
      "75 Train Loss 76.43397 Test MSE 5.41875927084568 Test RE 1.1126485062128202\n",
      "76 Train Loss 75.89104 Test MSE 5.403004789294115 Test RE 1.1110298736876498\n",
      "77 Train Loss 75.648346 Test MSE 5.399314272435067 Test RE 1.110650364965099\n",
      "78 Train Loss 75.43462 Test MSE 5.394618955252575 Test RE 1.110167341594002\n",
      "79 Train Loss 75.06371 Test MSE 5.394382143450785 Test RE 1.1101429743851325\n",
      "80 Train Loss 74.33939 Test MSE 5.396106193824851 Test RE 1.11032036166131\n",
      "81 Train Loss 74.02774 Test MSE 5.381165078744323 Test RE 1.1087821299143867\n",
      "82 Train Loss 73.59354 Test MSE 5.368773751389756 Test RE 1.1075047856318516\n",
      "83 Train Loss 73.303894 Test MSE 5.371988170513876 Test RE 1.1078362814281286\n",
      "84 Train Loss 72.95772 Test MSE 5.367926013894428 Test RE 1.1074173438395707\n",
      "85 Train Loss 72.79085 Test MSE 5.374914675440073 Test RE 1.1081379990420919\n",
      "86 Train Loss 72.52087 Test MSE 5.400475497119287 Test RE 1.110769791730919\n",
      "87 Train Loss 71.80458 Test MSE 5.4386881777517 Test RE 1.1146926566579458\n",
      "88 Train Loss 71.33387 Test MSE 5.452793706945814 Test RE 1.1161372281862116\n",
      "89 Train Loss 70.68232 Test MSE 5.478768147433919 Test RE 1.1187924356606258\n",
      "90 Train Loss 70.22932 Test MSE 5.492751889723608 Test RE 1.1202193015701116\n",
      "91 Train Loss 69.87558 Test MSE 5.470883871851638 Test RE 1.1179871411702007\n",
      "92 Train Loss 69.58913 Test MSE 5.4699301967270415 Test RE 1.1178896941196355\n",
      "93 Train Loss 69.35608 Test MSE 5.4882845885539835 Test RE 1.1197636670328162\n",
      "94 Train Loss 68.636 Test MSE 5.519094524416761 Test RE 1.122902312918908\n",
      "95 Train Loss 67.89803 Test MSE 5.531633859807518 Test RE 1.1241772014045346\n",
      "96 Train Loss 67.54045 Test MSE 5.532835244648089 Test RE 1.1242992716788331\n",
      "97 Train Loss 67.2598 Test MSE 5.537552145422168 Test RE 1.124778418270745\n",
      "98 Train Loss 66.82433 Test MSE 5.537135362403573 Test RE 1.1247360893361122\n",
      "99 Train Loss 66.13651 Test MSE 5.576947831318395 Test RE 1.128772320655076\n",
      "Training time: 72.29\n",
      "KG_stan_tune1\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 3076.9053 Test MSE 5.392796280392636 Test RE 1.1099797801492697\n",
      "1 Train Loss 1654.8915 Test MSE 5.3961968698798 Test RE 1.1103296905221183\n",
      "2 Train Loss 1236.2888 Test MSE 5.401436748255761 Test RE 1.1108686423985306\n",
      "3 Train Loss 969.228 Test MSE 5.410917812194579 Test RE 1.111843160791204\n",
      "4 Train Loss 846.08966 Test MSE 5.414225342548117 Test RE 1.1121829269198684\n",
      "5 Train Loss 745.513 Test MSE 5.417090722230149 Test RE 1.1124771892223266\n",
      "6 Train Loss 713.1394 Test MSE 5.41831089212951 Test RE 1.1126024718528815\n",
      "7 Train Loss 647.99384 Test MSE 5.423001272511672 Test RE 1.1130839318539751\n",
      "8 Train Loss 604.71704 Test MSE 5.422987091715364 Test RE 1.1130824765319096\n",
      "9 Train Loss 561.3519 Test MSE 5.427764442998581 Test RE 1.113572650609272\n",
      "10 Train Loss 526.19385 Test MSE 5.437063879665714 Test RE 1.11452618927685\n",
      "11 Train Loss 514.1538 Test MSE 5.438143210453287 Test RE 1.1146368080558546\n",
      "12 Train Loss 507.35782 Test MSE 5.439397814414915 Test RE 1.1147653764894607\n",
      "13 Train Loss 497.34665 Test MSE 5.441892481177018 Test RE 1.1150209791721404\n",
      "14 Train Loss 485.53668 Test MSE 5.443822038989633 Test RE 1.1152186408097193\n",
      "15 Train Loss 467.47894 Test MSE 5.447850597982378 Test RE 1.115631208779303\n",
      "16 Train Loss 457.87918 Test MSE 5.4533196308287755 Test RE 1.1161910528037404\n",
      "17 Train Loss 418.73233 Test MSE 5.461723183374504 Test RE 1.1170507456103025\n",
      "18 Train Loss 393.59103 Test MSE 5.461522345870719 Test RE 1.1170302074268157\n",
      "19 Train Loss 372.4396 Test MSE 5.457630824702651 Test RE 1.1166321754281148\n",
      "20 Train Loss 354.8797 Test MSE 5.457605398054253 Test RE 1.1166295742768368\n",
      "21 Train Loss 346.39157 Test MSE 5.456416846114208 Test RE 1.1165079784105687\n",
      "22 Train Loss 338.12277 Test MSE 5.457866970393874 Test RE 1.1166563328906718\n",
      "23 Train Loss 315.35632 Test MSE 5.455627001925284 Test RE 1.1164271653715803\n",
      "24 Train Loss 308.49396 Test MSE 5.451901155798413 Test RE 1.1160458759008347\n",
      "25 Train Loss 301.18887 Test MSE 5.451507938108563 Test RE 1.1160056278404045\n",
      "26 Train Loss 296.34198 Test MSE 5.451938780821759 Test RE 1.1160497269592533\n",
      "27 Train Loss 288.79846 Test MSE 5.447918283630693 Test RE 1.115638139217807\n",
      "28 Train Loss 278.4326 Test MSE 5.442862805100575 Test RE 1.11512038239543\n",
      "29 Train Loss 266.09265 Test MSE 5.445409842984054 Test RE 1.1153812673154864\n",
      "30 Train Loss 249.8675 Test MSE 5.447651577751812 Test RE 1.1156108305398242\n",
      "31 Train Loss 232.60866 Test MSE 5.444007799698465 Test RE 1.115237668070024\n",
      "32 Train Loss 219.18054 Test MSE 5.440097226970658 Test RE 1.1148370439668045\n",
      "33 Train Loss 214.79779 Test MSE 5.437437311739873 Test RE 1.1145644629379283\n",
      "34 Train Loss 211.92242 Test MSE 5.433123030951448 Test RE 1.1141222051264192\n",
      "35 Train Loss 205.89523 Test MSE 5.426684610669319 Test RE 1.1134618746558897\n",
      "36 Train Loss 202.12502 Test MSE 5.431893710596502 Test RE 1.1139961551014914\n",
      "37 Train Loss 198.73894 Test MSE 5.437187696871301 Test RE 1.114538879649423\n",
      "38 Train Loss 190.84555 Test MSE 5.436236078724171 Test RE 1.1144413419245864\n",
      "39 Train Loss 188.52284 Test MSE 5.432621176160475 Test RE 1.1140707484894752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 183.61603 Test MSE 5.429371461313189 Test RE 1.1137374881979565\n",
      "41 Train Loss 181.7291 Test MSE 5.425484993133477 Test RE 1.1133387974629974\n",
      "42 Train Loss 180.48471 Test MSE 5.422936522299673 Test RE 1.113077286766497\n",
      "43 Train Loss 178.44292 Test MSE 5.423154983727636 Test RE 1.1130997065388475\n",
      "44 Train Loss 177.43855 Test MSE 5.423620974053626 Test RE 1.1131475276461933\n",
      "45 Train Loss 176.22043 Test MSE 5.421301423474471 Test RE 1.1129094691490493\n",
      "46 Train Loss 175.01349 Test MSE 5.419648371683209 Test RE 1.1127397832094297\n",
      "47 Train Loss 174.4516 Test MSE 5.422537429243644 Test RE 1.1130363283680906\n",
      "48 Train Loss 173.43915 Test MSE 5.422969294260836 Test RE 1.1130806500430501\n",
      "49 Train Loss 172.31386 Test MSE 5.427466931982262 Test RE 1.1135421311684868\n",
      "50 Train Loss 171.72675 Test MSE 5.4307208552814865 Test RE 1.1138758814992626\n",
      "51 Train Loss 171.47095 Test MSE 5.431301706837165 Test RE 1.1139354481071433\n",
      "52 Train Loss 171.24184 Test MSE 5.431285501315103 Test RE 1.1139337862662142\n",
      "53 Train Loss 170.26178 Test MSE 5.427984034071292 Test RE 1.113595176286488\n",
      "54 Train Loss 168.17877 Test MSE 5.423390919958097 Test RE 1.1131239191690772\n",
      "55 Train Loss 165.20064 Test MSE 5.415706582537609 Test RE 1.112335053684303\n",
      "56 Train Loss 163.15125 Test MSE 5.405136565722938 Test RE 1.111249032638354\n",
      "57 Train Loss 161.80864 Test MSE 5.397591005293139 Test RE 1.110473110972859\n",
      "58 Train Loss 160.21428 Test MSE 5.390729884736765 Test RE 1.1097671003967027\n",
      "59 Train Loss 158.32486 Test MSE 5.382540747938666 Test RE 1.1089238482899126\n",
      "60 Train Loss 157.39674 Test MSE 5.380461027741604 Test RE 1.1087095931407915\n",
      "61 Train Loss 154.90483 Test MSE 5.362966610223722 Test RE 1.1069056565742401\n",
      "62 Train Loss 153.24219 Test MSE 5.350508884291557 Test RE 1.1056192841612427\n",
      "63 Train Loss 151.90085 Test MSE 5.331521977816332 Test RE 1.1036558310658449\n",
      "64 Train Loss 150.45569 Test MSE 5.325067915995621 Test RE 1.102987614747893\n",
      "65 Train Loss 149.30342 Test MSE 5.311171557515953 Test RE 1.101547490009902\n",
      "66 Train Loss 148.62662 Test MSE 5.297494477329817 Test RE 1.1001282489837487\n",
      "67 Train Loss 146.64249 Test MSE 5.289141406052913 Test RE 1.0992605675686138\n",
      "68 Train Loss 145.21072 Test MSE 5.293566596690551 Test RE 1.099720322768848\n",
      "69 Train Loss 143.37782 Test MSE 5.292787137558012 Test RE 1.0996393548061394\n",
      "70 Train Loss 140.71283 Test MSE 5.267229132920358 Test RE 1.096981152494268\n",
      "71 Train Loss 137.97859 Test MSE 5.222438018616314 Test RE 1.092306976450228\n",
      "72 Train Loss 137.06184 Test MSE 5.200301356378924 Test RE 1.0899895043903922\n",
      "73 Train Loss 135.5696 Test MSE 5.189597867789768 Test RE 1.088867194467165\n",
      "74 Train Loss 133.44109 Test MSE 5.192773049492864 Test RE 1.0892002474907285\n",
      "75 Train Loss 128.5772 Test MSE 5.15619565301763 Test RE 1.085357357133602\n",
      "76 Train Loss 126.53784 Test MSE 5.126026381644784 Test RE 1.0821774468848437\n",
      "77 Train Loss 126.223335 Test MSE 5.12305251360749 Test RE 1.0818634883150147\n",
      "78 Train Loss 125.79092 Test MSE 5.122000098175078 Test RE 1.0817523603978976\n",
      "79 Train Loss 124.56503 Test MSE 5.123410031699258 Test RE 1.081901237198227\n",
      "80 Train Loss 122.93604 Test MSE 5.109190598767047 Test RE 1.0803988480698197\n",
      "81 Train Loss 121.70901 Test MSE 5.109407390099638 Test RE 1.0804217693737843\n",
      "82 Train Loss 120.25717 Test MSE 5.121696753127734 Test RE 1.0817203271029605\n",
      "83 Train Loss 119.49193 Test MSE 5.133897679258229 Test RE 1.0830079998912043\n",
      "84 Train Loss 118.9098 Test MSE 5.146301791268574 Test RE 1.0843155491234273\n",
      "85 Train Loss 117.68107 Test MSE 5.16702714992019 Test RE 1.0864967511954535\n",
      "86 Train Loss 115.99406 Test MSE 5.187402692649876 Test RE 1.08863687729454\n",
      "87 Train Loss 113.31575 Test MSE 5.205090959238563 Test RE 1.090491342165195\n",
      "88 Train Loss 111.61375 Test MSE 5.191329945270638 Test RE 1.0890488891816403\n",
      "89 Train Loss 109.75235 Test MSE 5.174797945697584 Test RE 1.0873134463789582\n",
      "90 Train Loss 108.41206 Test MSE 5.177171997208869 Test RE 1.0875628321679578\n",
      "91 Train Loss 107.261 Test MSE 5.222355708953719 Test RE 1.092298368614901\n",
      "92 Train Loss 106.405846 Test MSE 5.269118280844843 Test RE 1.0971778568553259\n",
      "93 Train Loss 104.72367 Test MSE 5.330155021229084 Test RE 1.103514338043006\n",
      "94 Train Loss 103.14006 Test MSE 5.352835944727829 Test RE 1.1058596877623712\n",
      "95 Train Loss 101.522934 Test MSE 5.356713004559451 Test RE 1.1062601024344978\n",
      "96 Train Loss 98.73067 Test MSE 5.303602164543236 Test RE 1.1007622565948791\n",
      "97 Train Loss 97.85114 Test MSE 5.291594303709881 Test RE 1.0995154351281875\n",
      "98 Train Loss 97.389465 Test MSE 5.323714085027335 Test RE 1.1028473955303513\n",
      "99 Train Loss 96.872826 Test MSE 5.3414136972306725 Test RE 1.1046791781392211\n",
      "Training time: 72.56\n",
      "KG_stan_tune1\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 781.6417 Test MSE 6.299508477460192 Test RE 1.199668878480721\n",
      "1 Train Loss 523.1381 Test MSE 6.300674987111232 Test RE 1.1997799475070792\n",
      "2 Train Loss 479.61395 Test MSE 6.295844052950613 Test RE 1.1993199039896347\n",
      "3 Train Loss 434.07675 Test MSE 6.281475995929131 Test RE 1.1979506086816607\n",
      "4 Train Loss 365.0093 Test MSE 6.263007970102888 Test RE 1.1961882786057692\n",
      "5 Train Loss 336.07513 Test MSE 6.259650276165951 Test RE 1.1958675882432541\n",
      "6 Train Loss 312.3436 Test MSE 6.248781538806828 Test RE 1.1948289345614576\n",
      "7 Train Loss 285.24686 Test MSE 6.238513971224503 Test RE 1.193846900673647\n",
      "8 Train Loss 261.42947 Test MSE 6.225157904789583 Test RE 1.1925682594799611\n",
      "9 Train Loss 250.54079 Test MSE 6.208247381982754 Test RE 1.190947363473884\n",
      "10 Train Loss 243.63309 Test MSE 6.195451163230798 Test RE 1.1897193611897754\n",
      "11 Train Loss 230.61972 Test MSE 6.1799807555986375 Test RE 1.1882330329758892\n",
      "12 Train Loss 220.39415 Test MSE 6.164763760032441 Test RE 1.1867692354598147\n",
      "13 Train Loss 211.86513 Test MSE 6.152265167205364 Test RE 1.1855655825842606\n",
      "14 Train Loss 201.98868 Test MSE 6.131410997038033 Test RE 1.1835545368249794\n",
      "15 Train Loss 193.43636 Test MSE 6.131845275176064 Test RE 1.1835964507302592\n",
      "16 Train Loss 187.02783 Test MSE 6.129313856953082 Test RE 1.1833521126246438\n",
      "17 Train Loss 176.49544 Test MSE 6.129891967044115 Test RE 1.183407917538799\n",
      "18 Train Loss 168.55376 Test MSE 6.139994961350065 Test RE 1.1843827341636828\n",
      "19 Train Loss 164.55292 Test MSE 6.152189749127745 Test RE 1.1855583158825889\n",
      "20 Train Loss 158.68 Test MSE 6.17556006947885 Test RE 1.187807971379118\n",
      "21 Train Loss 156.15396 Test MSE 6.185858893316759 Test RE 1.1887979973027054\n",
      "22 Train Loss 152.99272 Test MSE 6.199653417396553 Test RE 1.1901227745595906\n",
      "23 Train Loss 145.63127 Test MSE 6.270745983613599 Test RE 1.196927002223955\n",
      "24 Train Loss 138.4877 Test MSE 6.262368676395916 Test RE 1.1961272268589076\n",
      "25 Train Loss 135.42088 Test MSE 6.264300238098681 Test RE 1.1963116790634765\n",
      "26 Train Loss 130.89594 Test MSE 6.278366648882383 Test RE 1.1976540776389812\n",
      "27 Train Loss 126.470314 Test MSE 6.284232144832099 Test RE 1.1982133947019435\n",
      "28 Train Loss 120.438354 Test MSE 6.297206813113495 Test RE 1.1994496957174194\n",
      "29 Train Loss 115.8802 Test MSE 6.333951310516817 Test RE 1.2029440283767692\n",
      "30 Train Loss 114.199875 Test MSE 6.3539718693010725 Test RE 1.204843680695441\n",
      "31 Train Loss 112.73127 Test MSE 6.364688854240438 Test RE 1.2058593329342175\n",
      "32 Train Loss 111.64453 Test MSE 6.379051942465461 Test RE 1.2072191875971459\n",
      "33 Train Loss 110.24649 Test MSE 6.390314195682194 Test RE 1.2082843938876011\n",
      "34 Train Loss 108.66473 Test MSE 6.416268982022524 Test RE 1.2107356805729588\n",
      "35 Train Loss 106.26346 Test MSE 6.444461326972098 Test RE 1.2133926815148581\n",
      "36 Train Loss 103.516914 Test MSE 6.4935150809042845 Test RE 1.2180019596318088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 102.1463 Test MSE 6.50314484997652 Test RE 1.2189047628263774\n",
      "38 Train Loss 101.35962 Test MSE 6.506880199234241 Test RE 1.2192547766649096\n",
      "39 Train Loss 100.10594 Test MSE 6.493057444599306 Test RE 1.2179590389847854\n",
      "40 Train Loss 98.454506 Test MSE 6.552008542094838 Test RE 1.2234755301342297\n",
      "41 Train Loss 97.88763 Test MSE 6.575741946854087 Test RE 1.225689430790129\n",
      "42 Train Loss 97.01593 Test MSE 6.5839731933843 Test RE 1.2264563249820954\n",
      "43 Train Loss 96.06779 Test MSE 6.598261239807278 Test RE 1.2277863856884235\n",
      "44 Train Loss 94.24882 Test MSE 6.633711934562499 Test RE 1.2310802514585528\n",
      "45 Train Loss 92.90533 Test MSE 6.62547286088131 Test RE 1.2303155127762526\n",
      "46 Train Loss 92.04851 Test MSE 6.61174941282682 Test RE 1.2290406661679416\n",
      "47 Train Loss 90.9324 Test MSE 6.636957852407595 Test RE 1.2313814023602347\n",
      "48 Train Loss 89.3705 Test MSE 6.633970223412161 Test RE 1.2311042177695743\n",
      "49 Train Loss 88.00767 Test MSE 6.595524449762194 Test RE 1.227531732080558\n",
      "50 Train Loss 87.269775 Test MSE 6.592945532216374 Test RE 1.227291719882732\n",
      "51 Train Loss 86.79596 Test MSE 6.596769658356646 Test RE 1.2276476031485812\n",
      "52 Train Loss 86.25354 Test MSE 6.610940982610114 Test RE 1.2289655253902123\n",
      "53 Train Loss 85.43223 Test MSE 6.6205271582398275 Test RE 1.2298562315479231\n",
      "54 Train Loss 84.64824 Test MSE 6.6036689863910185 Test RE 1.2282894119820724\n",
      "55 Train Loss 84.098434 Test MSE 6.602811911164924 Test RE 1.2282097009465909\n",
      "56 Train Loss 83.48555 Test MSE 6.622367538629789 Test RE 1.2300271579683597\n",
      "57 Train Loss 83.10561 Test MSE 6.642800876185487 Test RE 1.2319233229279507\n",
      "58 Train Loss 82.60933 Test MSE 6.660656049720731 Test RE 1.2335778542065148\n",
      "59 Train Loss 81.335976 Test MSE 6.643935315328058 Test RE 1.2320285106644362\n",
      "60 Train Loss 80.908554 Test MSE 6.631742213606091 Test RE 1.2308974680769609\n",
      "61 Train Loss 80.32026 Test MSE 6.610803629036355 Test RE 1.2289527583965132\n",
      "62 Train Loss 79.788216 Test MSE 6.586637003300429 Test RE 1.2267044058929266\n",
      "63 Train Loss 79.58838 Test MSE 6.592764927489164 Test RE 1.2272749097784172\n",
      "64 Train Loss 79.26186 Test MSE 6.610616313292442 Test RE 1.2289353472129565\n",
      "65 Train Loss 78.212585 Test MSE 6.597926977350316 Test RE 1.2277552859731513\n",
      "66 Train Loss 77.68019 Test MSE 6.574978096347187 Test RE 1.225618239532084\n",
      "67 Train Loss 77.42952 Test MSE 6.56552282439057 Test RE 1.224736660697663\n",
      "68 Train Loss 77.18532 Test MSE 6.5582128910933655 Test RE 1.2240546710923157\n",
      "69 Train Loss 76.775375 Test MSE 6.5412223614560645 Test RE 1.2224680479498913\n",
      "70 Train Loss 76.360466 Test MSE 6.526331035876542 Test RE 1.2210757590835177\n",
      "71 Train Loss 75.984245 Test MSE 6.531949975174704 Test RE 1.2216012974269361\n",
      "72 Train Loss 75.30785 Test MSE 6.523995882631064 Test RE 1.2208572860921159\n",
      "73 Train Loss 74.662125 Test MSE 6.50147358451032 Test RE 1.2187481275074887\n",
      "74 Train Loss 74.31909 Test MSE 6.504595334024529 Test RE 1.2190406896264852\n",
      "75 Train Loss 73.83315 Test MSE 6.517912855713326 Test RE 1.220287984715378\n",
      "76 Train Loss 73.61664 Test MSE 6.519762882210184 Test RE 1.2204611540245531\n",
      "77 Train Loss 73.363625 Test MSE 6.527164904876793 Test RE 1.2211537649871833\n",
      "78 Train Loss 73.19145 Test MSE 6.531556915714497 Test RE 1.2215645420038217\n",
      "79 Train Loss 72.975334 Test MSE 6.530510520978058 Test RE 1.2214666870878383\n",
      "80 Train Loss 72.56099 Test MSE 6.522994787092463 Test RE 1.2207636133113644\n",
      "81 Train Loss 72.323875 Test MSE 6.520039072968496 Test RE 1.2204870043911948\n",
      "82 Train Loss 72.12019 Test MSE 6.513154394055025 Test RE 1.2198424622060762\n",
      "83 Train Loss 71.95383 Test MSE 6.508851715981732 Test RE 1.2194394734078553\n",
      "84 Train Loss 71.79358 Test MSE 6.5169944327210905 Test RE 1.220202007804509\n",
      "85 Train Loss 71.45459 Test MSE 6.536108587344639 Test RE 1.22199010610719\n",
      "86 Train Loss 71.07723 Test MSE 6.5507196106107735 Test RE 1.2233551812606605\n",
      "87 Train Loss 70.823006 Test MSE 6.566201420737237 Test RE 1.2247999519519739\n",
      "88 Train Loss 70.62976 Test MSE 6.578613602744741 Test RE 1.2259570336030758\n",
      "89 Train Loss 70.113686 Test MSE 6.603738061016715 Test RE 1.2282958359419722\n",
      "90 Train Loss 69.775925 Test MSE 6.608314509139248 Test RE 1.2287213720979304\n",
      "91 Train Loss 69.64667 Test MSE 6.605299826525601 Test RE 1.2284410716136653\n",
      "92 Train Loss 69.52366 Test MSE 6.610731177834465 Test RE 1.2289460240149337\n",
      "93 Train Loss 69.32242 Test MSE 6.607472446157916 Test RE 1.2286430848324827\n",
      "94 Train Loss 69.09258 Test MSE 6.592325305308854 Test RE 1.2272339902042828\n",
      "95 Train Loss 68.97966 Test MSE 6.589184731692974 Test RE 1.2269416291892417\n",
      "96 Train Loss 68.90488 Test MSE 6.589884066210001 Test RE 1.2270067373855515\n",
      "97 Train Loss 68.74985 Test MSE 6.592017658202909 Test RE 1.2272053539209602\n",
      "98 Train Loss 68.5961 Test MSE 6.5906392917151 Test RE 1.2270770451652744\n",
      "99 Train Loss 68.40746 Test MSE 6.587436577655463 Test RE 1.2267788605515448\n",
      "Training time: 72.66\n",
      "KG_stan_tune1\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4549.8745 Test MSE 5.386680568493157 Test RE 1.1093502141630178\n",
      "1 Train Loss 1707.4521 Test MSE 5.385847888568744 Test RE 1.109264468466622\n",
      "2 Train Loss 811.3522 Test MSE 5.384233607315683 Test RE 1.1090982180385818\n",
      "3 Train Loss 778.66534 Test MSE 5.383920310089574 Test RE 1.109065949523188\n",
      "4 Train Loss 758.95825 Test MSE 5.383761551767117 Test RE 1.1090495976144013\n",
      "5 Train Loss 728.1948 Test MSE 5.384104573514606 Test RE 1.1090849281233677\n",
      "6 Train Loss 711.9424 Test MSE 5.384411063250156 Test RE 1.1091164949609256\n",
      "7 Train Loss 689.1026 Test MSE 5.384242830829509 Test RE 1.109099168013928\n",
      "8 Train Loss 671.3555 Test MSE 5.384361021008503 Test RE 1.1091113409334965\n",
      "9 Train Loss 659.1898 Test MSE 5.384753381660676 Test RE 1.1091517509022808\n",
      "10 Train Loss 657.0182 Test MSE 5.385096438219801 Test RE 1.1091870817425344\n",
      "11 Train Loss 653.64825 Test MSE 5.385665553661942 Test RE 1.109245691539616\n",
      "12 Train Loss 644.4462 Test MSE 5.387377036251699 Test RE 1.1094219282432207\n",
      "13 Train Loss 637.08704 Test MSE 5.389206108499258 Test RE 1.1096102425787941\n",
      "14 Train Loss 631.39014 Test MSE 5.3906592114849765 Test RE 1.10975982576892\n",
      "15 Train Loss 628.07495 Test MSE 5.391008580193257 Test RE 1.1097957869621495\n",
      "16 Train Loss 624.0078 Test MSE 5.391279048959235 Test RE 1.1098236260323133\n",
      "17 Train Loss 610.1041 Test MSE 5.393852883305962 Test RE 1.1100885132042049\n",
      "18 Train Loss 590.86487 Test MSE 5.39761536743576 Test RE 1.1104756170421177\n",
      "19 Train Loss 559.88654 Test MSE 5.40236480504656 Test RE 1.1109640711664264\n",
      "20 Train Loss 551.7483 Test MSE 5.403568985034799 Test RE 1.1110878804805167\n",
      "21 Train Loss 548.6198 Test MSE 5.404319652103802 Test RE 1.111165054300268\n",
      "22 Train Loss 543.26514 Test MSE 5.405163707530919 Test RE 1.111251822694593\n",
      "23 Train Loss 536.7395 Test MSE 5.404967960788946 Test RE 1.1112317006497299\n",
      "24 Train Loss 526.1091 Test MSE 5.4036677913925395 Test RE 1.1110980387708111\n",
      "25 Train Loss 511.94907 Test MSE 5.402904674025526 Test RE 1.1110195801959892\n",
      "26 Train Loss 509.1003 Test MSE 5.402965774436012 Test RE 1.111025862331672\n",
      "27 Train Loss 501.06027 Test MSE 5.403343136061341 Test RE 1.111064660578999\n",
      "28 Train Loss 493.67108 Test MSE 5.403458218466184 Test RE 1.1110764924494763\n",
      "29 Train Loss 490.38748 Test MSE 5.40372195679941 Test RE 1.1111036074816243\n",
      "30 Train Loss 480.95035 Test MSE 5.4054026737518805 Test RE 1.1112763870489757\n",
      "31 Train Loss 475.09888 Test MSE 5.408019330453025 Test RE 1.1115453288058557\n",
      "32 Train Loss 472.97485 Test MSE 5.408814640966208 Test RE 1.1116270584681243\n",
      "33 Train Loss 464.7341 Test MSE 5.411665470693268 Test RE 1.111919973108774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 451.37054 Test MSE 5.415340054218624 Test RE 1.1122974123175127\n",
      "35 Train Loss 446.9402 Test MSE 5.41817035843331 Test RE 1.1125880430802662\n",
      "36 Train Loss 443.23883 Test MSE 5.419517324971591 Test RE 1.1127263301437536\n",
      "37 Train Loss 432.8911 Test MSE 5.421532748751303 Test RE 1.112933212649431\n",
      "38 Train Loss 423.89178 Test MSE 5.423744278436338 Test RE 1.113160181110485\n",
      "39 Train Loss 391.2686 Test MSE 5.434421401846195 Test RE 1.1142553198585081\n",
      "40 Train Loss 373.14368 Test MSE 5.445453926235667 Test RE 1.1153857820843425\n",
      "41 Train Loss 364.27356 Test MSE 5.449499742227135 Test RE 1.1158000549635745\n",
      "42 Train Loss 354.71997 Test MSE 5.451543280312036 Test RE 1.116009245374718\n",
      "43 Train Loss 348.29755 Test MSE 5.455429757875014 Test RE 1.1164069834010886\n",
      "44 Train Loss 343.4926 Test MSE 5.4602616168696825 Test RE 1.116901273260794\n",
      "45 Train Loss 339.79233 Test MSE 5.467042551253102 Test RE 1.1175945810974752\n",
      "46 Train Loss 336.86398 Test MSE 5.470790075093372 Test RE 1.11797755734229\n",
      "47 Train Loss 328.69458 Test MSE 5.479019369652604 Test RE 1.1188180857966112\n",
      "48 Train Loss 315.0293 Test MSE 5.484866796142738 Test RE 1.1194149500780282\n",
      "49 Train Loss 310.22052 Test MSE 5.483935259624601 Test RE 1.1193198866769376\n",
      "50 Train Loss 308.9398 Test MSE 5.482647578267798 Test RE 1.119188465361633\n",
      "51 Train Loss 307.71228 Test MSE 5.4832198532197065 Test RE 1.1192468738954315\n",
      "52 Train Loss 306.279 Test MSE 5.485890258684672 Test RE 1.1195193852332128\n",
      "53 Train Loss 305.44376 Test MSE 5.487816831322267 Test RE 1.1197159482324095\n",
      "54 Train Loss 303.0522 Test MSE 5.489977509420444 Test RE 1.1199363553368111\n",
      "55 Train Loss 298.84454 Test MSE 5.491711641671084 Test RE 1.1201132198511012\n",
      "56 Train Loss 296.23233 Test MSE 5.491898543063735 Test RE 1.1201322802964757\n",
      "57 Train Loss 289.23114 Test MSE 5.49873088280872 Test RE 1.1208288286258485\n",
      "58 Train Loss 284.3592 Test MSE 5.506169337672952 Test RE 1.121586677770419\n",
      "59 Train Loss 282.10608 Test MSE 5.504962469266817 Test RE 1.1214637536807486\n",
      "60 Train Loss 278.44357 Test MSE 5.503600160026364 Test RE 1.1213249811664587\n",
      "61 Train Loss 273.3962 Test MSE 5.5022422678711225 Test RE 1.1211866415085907\n",
      "62 Train Loss 267.72845 Test MSE 5.495606053469993 Test RE 1.1205103099884621\n",
      "63 Train Loss 264.51416 Test MSE 5.496217668584409 Test RE 1.120572659979365\n",
      "64 Train Loss 263.19794 Test MSE 5.499268458993354 Test RE 1.120883615464164\n",
      "65 Train Loss 257.4806 Test MSE 5.503072673798368 Test RE 1.1212712438272021\n",
      "66 Train Loss 251.90273 Test MSE 5.509876795023951 Test RE 1.1219642120224562\n",
      "67 Train Loss 250.62166 Test MSE 5.511056614789763 Test RE 1.12208432765748\n",
      "68 Train Loss 247.06888 Test MSE 5.514405936230443 Test RE 1.1224252468788032\n",
      "69 Train Loss 243.8197 Test MSE 5.5165682265897 Test RE 1.1226452861221345\n",
      "70 Train Loss 242.34941 Test MSE 5.517805958967747 Test RE 1.1227712209814678\n",
      "71 Train Loss 241.02911 Test MSE 5.518312452018763 Test RE 1.122822750772122\n",
      "72 Train Loss 240.26875 Test MSE 5.517186708812126 Test RE 1.1227082162503408\n",
      "73 Train Loss 238.31305 Test MSE 5.516384069143219 Test RE 1.122626547550785\n",
      "74 Train Loss 236.40192 Test MSE 5.52141187939929 Test RE 1.1231380300430456\n",
      "75 Train Loss 235.29483 Test MSE 5.524560510256417 Test RE 1.1234582237834636\n",
      "76 Train Loss 234.8092 Test MSE 5.5260165643965395 Test RE 1.1236062634533313\n",
      "77 Train Loss 234.46826 Test MSE 5.52591825095495 Test RE 1.123596268361135\n",
      "78 Train Loss 233.31094 Test MSE 5.525931538716764 Test RE 1.123597619274226\n",
      "79 Train Loss 230.81235 Test MSE 5.527561566528422 Test RE 1.1237633253016117\n",
      "80 Train Loss 228.52 Test MSE 5.529520937866068 Test RE 1.123962479533739\n",
      "81 Train Loss 225.19792 Test MSE 5.532033661865972 Test RE 1.1242178259514441\n",
      "82 Train Loss 222.7328 Test MSE 5.532481953503036 Test RE 1.1242633758586575\n",
      "83 Train Loss 221.1262 Test MSE 5.53264966190032 Test RE 1.1242804158582098\n",
      "84 Train Loss 219.33136 Test MSE 5.535947550828685 Test RE 1.1246154451660426\n",
      "85 Train Loss 218.8783 Test MSE 5.5385440769494085 Test RE 1.1248791535041074\n",
      "86 Train Loss 218.45908 Test MSE 5.540359220777953 Test RE 1.1250634663994705\n",
      "87 Train Loss 218.12468 Test MSE 5.541482844385919 Test RE 1.1251775459864541\n",
      "88 Train Loss 217.7703 Test MSE 5.542893328446649 Test RE 1.1253207336550919\n",
      "89 Train Loss 216.89091 Test MSE 5.542857103780003 Test RE 1.125317056474905\n",
      "90 Train Loss 216.38042 Test MSE 5.542031856908234 Test RE 1.1252332820845705\n",
      "91 Train Loss 216.04521 Test MSE 5.542394831852784 Test RE 1.1252701300142995\n",
      "92 Train Loss 215.7508 Test MSE 5.543586690388882 Test RE 1.125391114783165\n",
      "93 Train Loss 215.38484 Test MSE 5.544761690878524 Test RE 1.1255103755724991\n",
      "94 Train Loss 214.59909 Test MSE 5.5424497840326605 Test RE 1.1252757084596463\n",
      "95 Train Loss 213.95319 Test MSE 5.5388156229851075 Test RE 1.1249067286869177\n",
      "96 Train Loss 213.55658 Test MSE 5.537564185871461 Test RE 1.1247796410881372\n",
      "97 Train Loss 212.7713 Test MSE 5.540762831893965 Test RE 1.1251044456783825\n",
      "98 Train Loss 212.46243 Test MSE 5.5414875885760795 Test RE 1.1251780276314627\n",
      "99 Train Loss 212.17625 Test MSE 5.541074146084011 Test RE 1.1251360528839274\n",
      "Training time: 74.78\n",
      "KG_stan_tune1\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 2173.6807 Test MSE 6.120908143828715 Test RE 1.1825404123881946\n",
      "1 Train Loss 1282.9099 Test MSE 6.12357258748979 Test RE 1.1827977654980268\n",
      "2 Train Loss 1030.7886 Test MSE 6.121640944329573 Test RE 1.1826111976582196\n",
      "3 Train Loss 900.9186 Test MSE 6.116632572423779 Test RE 1.1821273266910617\n",
      "4 Train Loss 760.52136 Test MSE 6.112044343535094 Test RE 1.1816838728616157\n",
      "5 Train Loss 686.40875 Test MSE 6.108595842682476 Test RE 1.181350464547265\n",
      "6 Train Loss 623.47925 Test MSE 6.0997922771155535 Test RE 1.1804988902790898\n",
      "7 Train Loss 593.89844 Test MSE 6.101264682903827 Test RE 1.1806413597632968\n",
      "8 Train Loss 529.735 Test MSE 6.105580397302781 Test RE 1.1810588478137873\n",
      "9 Train Loss 483.0395 Test MSE 6.102463669634967 Test RE 1.180757360613926\n",
      "10 Train Loss 383.2569 Test MSE 6.09204372375444 Test RE 1.1797488593781176\n",
      "11 Train Loss 338.68027 Test MSE 6.084903041042629 Test RE 1.1790572456366781\n",
      "12 Train Loss 322.8836 Test MSE 6.083325308147638 Test RE 1.178904378944457\n",
      "13 Train Loss 297.92545 Test MSE 6.074288941311168 Test RE 1.1780284623268062\n",
      "14 Train Loss 286.0786 Test MSE 6.070723366547289 Test RE 1.1776826634050361\n",
      "15 Train Loss 267.83554 Test MSE 6.0639369657011475 Test RE 1.1770242195098386\n",
      "16 Train Loss 260.4248 Test MSE 6.062447684960857 Test RE 1.1768796742126362\n",
      "17 Train Loss 254.22696 Test MSE 6.063215780506344 Test RE 1.1769542255697722\n",
      "18 Train Loss 243.62418 Test MSE 6.063297116479783 Test RE 1.1769621197632214\n",
      "19 Train Loss 233.25197 Test MSE 6.0545019873439445 Test RE 1.176108187470482\n",
      "20 Train Loss 227.80661 Test MSE 6.045682480906433 Test RE 1.1752512653037435\n",
      "21 Train Loss 218.07896 Test MSE 6.032866622559132 Test RE 1.1740049341885481\n",
      "22 Train Loss 212.87239 Test MSE 6.0248867648444735 Test RE 1.1732282310942317\n",
      "23 Train Loss 201.29987 Test MSE 6.016063863874794 Test RE 1.1723688731256927\n",
      "24 Train Loss 196.94456 Test MSE 6.014391206697914 Test RE 1.1722058838709235\n",
      "25 Train Loss 191.16719 Test MSE 6.004851993499715 Test RE 1.1712759178289487\n",
      "26 Train Loss 187.4851 Test MSE 6.003719932526247 Test RE 1.1711655055942416\n",
      "27 Train Loss 183.80489 Test MSE 6.003429314120991 Test RE 1.1711371593044095\n",
      "28 Train Loss 176.51183 Test MSE 5.9918701455973515 Test RE 1.170009146158234\n",
      "29 Train Loss 174.45006 Test MSE 5.985750829452864 Test RE 1.1694115460265218\n",
      "30 Train Loss 172.78882 Test MSE 5.980124759010749 Test RE 1.1688618456955873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 170.65588 Test MSE 5.979247202886061 Test RE 1.1687760799677436\n",
      "32 Train Loss 168.49103 Test MSE 5.9743883467708345 Test RE 1.168301098019369\n",
      "33 Train Loss 167.32166 Test MSE 5.966304862715323 Test RE 1.1675104614403369\n",
      "34 Train Loss 165.63889 Test MSE 5.956439257207547 Test RE 1.1665447914541156\n",
      "35 Train Loss 163.05246 Test MSE 5.935768904102349 Test RE 1.1645189293955422\n",
      "36 Train Loss 159.7534 Test MSE 5.916966017095444 Test RE 1.1626730282071966\n",
      "37 Train Loss 156.72424 Test MSE 5.895991601832876 Test RE 1.1606104815916576\n",
      "38 Train Loss 154.11536 Test MSE 5.873696557813109 Test RE 1.1584140427594163\n",
      "39 Train Loss 148.22238 Test MSE 5.857152478564821 Test RE 1.1567814756255976\n",
      "40 Train Loss 143.6052 Test MSE 5.858341773018966 Test RE 1.1568989118686408\n",
      "41 Train Loss 141.48189 Test MSE 5.856152879437433 Test RE 1.1566827615237183\n",
      "42 Train Loss 140.49649 Test MSE 5.858187682412219 Test RE 1.1568836969465328\n",
      "43 Train Loss 140.01477 Test MSE 5.860648171120951 Test RE 1.1571266219433252\n",
      "44 Train Loss 139.60387 Test MSE 5.861664602862412 Test RE 1.1572269597559723\n",
      "45 Train Loss 138.549 Test MSE 5.862983143375715 Test RE 1.1573571074985665\n",
      "46 Train Loss 138.18387 Test MSE 5.863063938465571 Test RE 1.157365081975643\n",
      "47 Train Loss 137.35684 Test MSE 5.860751596549769 Test RE 1.1571368320587925\n",
      "48 Train Loss 132.02286 Test MSE 5.847400474000688 Test RE 1.1558180691067599\n",
      "49 Train Loss 129.53374 Test MSE 5.845080471735142 Test RE 1.1555887563907754\n",
      "50 Train Loss 128.62717 Test MSE 5.84678589820162 Test RE 1.1557573278866147\n",
      "51 Train Loss 127.802315 Test MSE 5.848527369081301 Test RE 1.1559294367952841\n",
      "52 Train Loss 126.55493 Test MSE 5.850846254221978 Test RE 1.156158571565735\n",
      "53 Train Loss 125.56447 Test MSE 5.8529303321261645 Test RE 1.156364465713131\n",
      "54 Train Loss 124.022835 Test MSE 5.856181206993813 Test RE 1.1566855590904137\n",
      "55 Train Loss 123.43729 Test MSE 5.859287376441305 Test RE 1.1569922764649365\n",
      "56 Train Loss 122.66871 Test MSE 5.866139554390405 Test RE 1.1576686044867555\n",
      "57 Train Loss 122.058655 Test MSE 5.869468323878556 Test RE 1.1579970202497645\n",
      "58 Train Loss 120.28797 Test MSE 5.867884569072343 Test RE 1.1578407789194156\n",
      "59 Train Loss 118.76894 Test MSE 5.864864858808753 Test RE 1.1575428185916883\n",
      "60 Train Loss 117.94159 Test MSE 5.858883817805407 Test RE 1.1569524318358209\n",
      "61 Train Loss 117.479034 Test MSE 5.853040889982375 Test RE 1.156375387129016\n",
      "62 Train Loss 117.08284 Test MSE 5.851795487192043 Test RE 1.156252354522758\n",
      "63 Train Loss 116.50996 Test MSE 5.850557303992475 Test RE 1.1561300221564006\n",
      "64 Train Loss 116.107895 Test MSE 5.847210988601319 Test RE 1.1557993417745303\n",
      "65 Train Loss 115.52573 Test MSE 5.8411363581643 Test RE 1.15519880945628\n",
      "66 Train Loss 114.68496 Test MSE 5.834774989119491 Test RE 1.1545695956036746\n",
      "67 Train Loss 113.559044 Test MSE 5.834406963396653 Test RE 1.1545331830589523\n",
      "68 Train Loss 112.67085 Test MSE 5.832972639734985 Test RE 1.1543912598042643\n",
      "69 Train Loss 111.83645 Test MSE 5.824620594723469 Test RE 1.153564495975626\n",
      "70 Train Loss 110.69732 Test MSE 5.811053248785152 Test RE 1.1522202081503563\n",
      "71 Train Loss 110.10167 Test MSE 5.8075283104703646 Test RE 1.1518706913682117\n",
      "72 Train Loss 109.548676 Test MSE 5.806082537667663 Test RE 1.1517273044669634\n",
      "73 Train Loss 109.258835 Test MSE 5.808866029960638 Test RE 1.1520033460079746\n",
      "74 Train Loss 108.94441 Test MSE 5.811684224448403 Test RE 1.152282761627721\n",
      "75 Train Loss 108.679825 Test MSE 5.8089288007109054 Test RE 1.152009570279512\n",
      "76 Train Loss 108.50652 Test MSE 5.807161407121253 Test RE 1.1518343048138038\n",
      "77 Train Loss 108.07837 Test MSE 5.805959407976262 Test RE 1.1517150920519206\n",
      "78 Train Loss 107.64849 Test MSE 5.80510514460114 Test RE 1.1516303597841124\n",
      "79 Train Loss 107.024796 Test MSE 5.801782392500836 Test RE 1.1513007249345062\n",
      "80 Train Loss 106.674355 Test MSE 5.800405434543972 Test RE 1.1511640956489986\n",
      "81 Train Loss 105.80323 Test MSE 5.796617261801873 Test RE 1.1507881287680546\n",
      "82 Train Loss 105.03408 Test MSE 5.791603917474958 Test RE 1.1502903776793671\n",
      "83 Train Loss 104.694595 Test MSE 5.7858010818831795 Test RE 1.1497139726929064\n",
      "84 Train Loss 104.451836 Test MSE 5.779486821744498 Test RE 1.1490864386009558\n",
      "85 Train Loss 104.22241 Test MSE 5.77175536365951 Test RE 1.1483175912049381\n",
      "86 Train Loss 104.11178 Test MSE 5.769155665396606 Test RE 1.1480589510434913\n",
      "87 Train Loss 103.87894 Test MSE 5.7706575633038035 Test RE 1.1482083797666764\n",
      "88 Train Loss 103.66964 Test MSE 5.771367738325603 Test RE 1.1482790306254147\n",
      "89 Train Loss 103.324844 Test MSE 5.765224559351456 Test RE 1.147667740368932\n",
      "90 Train Loss 103.06029 Test MSE 5.755383919958851 Test RE 1.1466878472437136\n",
      "91 Train Loss 102.680695 Test MSE 5.747605394376173 Test RE 1.1459126985607182\n",
      "92 Train Loss 102.24401 Test MSE 5.73817720641767 Test RE 1.1449724535554553\n",
      "93 Train Loss 101.57177 Test MSE 5.721528541708277 Test RE 1.1433102437079044\n",
      "94 Train Loss 101.21293 Test MSE 5.710489704801485 Test RE 1.1422067878221758\n",
      "95 Train Loss 101.052345 Test MSE 5.709118335124131 Test RE 1.1420696295495882\n",
      "96 Train Loss 100.83465 Test MSE 5.711226865516794 Test RE 1.1422805085401122\n",
      "97 Train Loss 100.687485 Test MSE 5.708111487064451 Test RE 1.1419689186144166\n",
      "98 Train Loss 100.51503 Test MSE 5.702792399803912 Test RE 1.141436724379566\n",
      "99 Train Loss 100.20374 Test MSE 5.701054802847835 Test RE 1.1412628176387793\n",
      "Training time: 73.29\n",
      "KG_stan_tune2\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 2746960.8 Test MSE 5.492242947396111 Test RE 1.120167402245576\n",
      "1 Train Loss 2634852.5 Test MSE 5.4922170163539 Test RE 1.120164757866699\n",
      "2 Train Loss 2324417.5 Test MSE 5.487229163695451 Test RE 1.1196559937503854\n",
      "3 Train Loss 2190368.0 Test MSE 5.486245052323578 Test RE 1.1195555864618107\n",
      "4 Train Loss 2027921.8 Test MSE 5.486090181539409 Test RE 1.1195397844265762\n",
      "5 Train Loss 1823120.6 Test MSE 5.487608925998968 Test RE 1.119694737875152\n",
      "6 Train Loss 1768291.0 Test MSE 5.488289653135865 Test RE 1.119764183690925\n",
      "7 Train Loss 1696380.2 Test MSE 5.488879905745403 Test RE 1.1198243960706902\n",
      "8 Train Loss 1599807.9 Test MSE 5.490326659906045 Test RE 1.119971967514159\n",
      "9 Train Loss 1563365.8 Test MSE 5.491609394400273 Test RE 1.1201027924051339\n",
      "10 Train Loss 1507758.0 Test MSE 5.492864414672662 Test RE 1.1202307759618917\n",
      "11 Train Loss 1449174.4 Test MSE 5.493212690869681 Test RE 1.1202662896302433\n",
      "12 Train Loss 1392427.2 Test MSE 5.4929611978338455 Test RE 1.1202406450383868\n",
      "13 Train Loss 1360160.6 Test MSE 5.492139362574461 Test RE 1.1201568389029861\n",
      "14 Train Loss 1327619.1 Test MSE 5.489693752973989 Test RE 1.1199074122977604\n",
      "15 Train Loss 1261718.5 Test MSE 5.4899776583246584 Test RE 1.1199363705247827\n",
      "16 Train Loss 1231798.9 Test MSE 5.4939896457203785 Test RE 1.1203455115357064\n",
      "17 Train Loss 1170603.0 Test MSE 5.495506617233218 Test RE 1.1205001728141983\n",
      "18 Train Loss 1148836.2 Test MSE 5.497001848029325 Test RE 1.1206525966520229\n",
      "19 Train Loss 1122694.1 Test MSE 5.497819422294494 Test RE 1.1207359314119187\n",
      "20 Train Loss 1082260.6 Test MSE 5.4999299148334115 Test RE 1.120951023768183\n",
      "21 Train Loss 1059465.9 Test MSE 5.501444664965057 Test RE 1.1211053751729514\n",
      "22 Train Loss 1053822.1 Test MSE 5.501961747563478 Test RE 1.1211580604669782\n",
      "23 Train Loss 1040417.2 Test MSE 5.50256872245073 Test RE 1.121219901683898\n",
      "24 Train Loss 1022855.25 Test MSE 5.503341238292476 Test RE 1.1212986039938098\n",
      "25 Train Loss 1009381.4 Test MSE 5.504989018557342 Test RE 1.1214664579708575\n",
      "26 Train Loss 971745.06 Test MSE 5.5043794026246955 Test RE 1.1214043613212112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 948360.06 Test MSE 5.50051414638985 Test RE 1.121010558851427\n",
      "28 Train Loss 899805.94 Test MSE 5.493168807101956 Test RE 1.120261814871428\n",
      "29 Train Loss 848186.5 Test MSE 5.48983417291957 Test RE 1.1199217351670643\n",
      "30 Train Loss 811951.3 Test MSE 5.489775440659386 Test RE 1.1199157444842327\n",
      "31 Train Loss 784536.25 Test MSE 5.489831106637333 Test RE 1.1199214224074716\n",
      "32 Train Loss 747501.2 Test MSE 5.489843001754152 Test RE 1.1199226357042629\n",
      "33 Train Loss 733299.4 Test MSE 5.489432569779523 Test RE 1.119880771059854\n",
      "34 Train Loss 717486.8 Test MSE 5.486011795581001 Test RE 1.1195317863341696\n",
      "35 Train Loss 703513.44 Test MSE 5.4840689645538205 Test RE 1.1193335317754787\n",
      "36 Train Loss 692637.7 Test MSE 5.4813765077504355 Test RE 1.1190587242191257\n",
      "37 Train Loss 675177.0 Test MSE 5.477153908199135 Test RE 1.118627605570721\n",
      "38 Train Loss 663007.06 Test MSE 5.473389434671885 Test RE 1.1182431204991907\n",
      "39 Train Loss 659491.25 Test MSE 5.470353736435143 Test RE 1.1179329726892693\n",
      "40 Train Loss 651978.44 Test MSE 5.465620611762372 Test RE 1.1174492323828962\n",
      "41 Train Loss 643839.44 Test MSE 5.465409249441058 Test RE 1.1174276256007996\n",
      "42 Train Loss 627162.0 Test MSE 5.469453805037648 Test RE 1.1178410129722824\n",
      "43 Train Loss 607303.7 Test MSE 5.467251899245824 Test RE 1.1176159787672644\n",
      "44 Train Loss 594801.2 Test MSE 5.459964206685032 Test RE 1.1168708550903268\n",
      "45 Train Loss 591647.5 Test MSE 5.458317415792492 Test RE 1.1167024115448396\n",
      "46 Train Loss 582346.9 Test MSE 5.455006885310434 Test RE 1.1163637139379985\n",
      "47 Train Loss 577989.8 Test MSE 5.453590729781295 Test RE 1.1162187968647037\n",
      "48 Train Loss 568832.6 Test MSE 5.451739067523398 Test RE 1.116029285422554\n",
      "49 Train Loss 558007.1 Test MSE 5.45145141712713 Test RE 1.1159998424781172\n",
      "50 Train Loss 552607.94 Test MSE 5.451135448464226 Test RE 1.1159675000741671\n",
      "51 Train Loss 546581.56 Test MSE 5.452376164735307 Test RE 1.116094493823571\n",
      "52 Train Loss 537719.3 Test MSE 5.449745908761045 Test RE 1.115825256316289\n",
      "53 Train Loss 530141.2 Test MSE 5.445195517092332 Test RE 1.1153593169532632\n",
      "54 Train Loss 525670.3 Test MSE 5.442349977531441 Test RE 1.1150678477306402\n",
      "55 Train Loss 522215.88 Test MSE 5.442813332692893 Test RE 1.1151153144911388\n",
      "56 Train Loss 519567.78 Test MSE 5.444027974192866 Test RE 1.1152397345012337\n",
      "57 Train Loss 507071.9 Test MSE 5.444281121996227 Test RE 1.1152656635751144\n",
      "58 Train Loss 496652.88 Test MSE 5.4415167878701505 Test RE 1.1149824895152227\n",
      "59 Train Loss 492687.5 Test MSE 5.439541028758009 Test RE 1.1147800517665496\n",
      "60 Train Loss 484967.6 Test MSE 5.439155644141298 Test RE 1.1147405606872047\n",
      "61 Train Loss 482444.7 Test MSE 5.439875465830178 Test RE 1.1148143210223829\n",
      "62 Train Loss 479573.7 Test MSE 5.440200977321818 Test RE 1.1148476746760096\n",
      "63 Train Loss 475232.6 Test MSE 5.440425163852209 Test RE 1.1148706454502788\n",
      "64 Train Loss 469375.5 Test MSE 5.441953389437961 Test RE 1.1150272190784747\n",
      "65 Train Loss 462444.22 Test MSE 5.444072856271587 Test RE 1.1152443316648257\n",
      "66 Train Loss 458829.84 Test MSE 5.443014093298366 Test RE 1.1151358800651963\n",
      "67 Train Loss 455174.8 Test MSE 5.4410534236280705 Test RE 1.1149350161695282\n",
      "68 Train Loss 447791.9 Test MSE 5.440206624679953 Test RE 1.114848253325813\n",
      "69 Train Loss 436876.3 Test MSE 5.439224273075887 Test RE 1.114747593324319\n",
      "70 Train Loss 432201.16 Test MSE 5.437050868155608 Test RE 1.1145248556823062\n",
      "71 Train Loss 427393.34 Test MSE 5.435209161446674 Test RE 1.1143360767094552\n",
      "72 Train Loss 421944.34 Test MSE 5.4361201932386685 Test RE 1.1144294634610343\n",
      "73 Train Loss 419534.8 Test MSE 5.435774879974808 Test RE 1.1143940675009434\n",
      "74 Train Loss 416716.84 Test MSE 5.433859410620003 Test RE 1.1141977039820954\n",
      "75 Train Loss 409519.47 Test MSE 5.4304685268177515 Test RE 1.1138500041008197\n",
      "76 Train Loss 403866.12 Test MSE 5.430693705203654 Test RE 1.1138730971677275\n",
      "77 Train Loss 402553.44 Test MSE 5.431151928178458 Test RE 1.1139200885380576\n",
      "78 Train Loss 402107.97 Test MSE 5.431302985439494 Test RE 1.1139355792249162\n",
      "79 Train Loss 400823.22 Test MSE 5.430791553570945 Test RE 1.1138831318132907\n",
      "80 Train Loss 396980.88 Test MSE 5.427908655619549 Test RE 1.113587444007694\n",
      "81 Train Loss 394267.44 Test MSE 5.4266112912610405 Test RE 1.113454352692905\n",
      "82 Train Loss 391952.94 Test MSE 5.42586208016207 Test RE 1.1133774869372992\n",
      "83 Train Loss 387348.75 Test MSE 5.424468838285202 Test RE 1.1132345323516313\n",
      "84 Train Loss 380871.22 Test MSE 5.421794398892654 Test RE 1.1129600681193292\n",
      "85 Train Loss 376586.0 Test MSE 5.420451967412658 Test RE 1.1128222756270563\n",
      "86 Train Loss 373889.4 Test MSE 5.4204151045054525 Test RE 1.1128184916313417\n",
      "87 Train Loss 371810.25 Test MSE 5.419772865498859 Test RE 1.1127525634136437\n",
      "88 Train Loss 367169.2 Test MSE 5.417708809168371 Test RE 1.1125406539160336\n",
      "89 Train Loss 362899.8 Test MSE 5.417807628855653 Test RE 1.112550800310206\n",
      "90 Train Loss 360309.84 Test MSE 5.418452369340034 Test RE 1.1126169973083022\n",
      "91 Train Loss 356937.5 Test MSE 5.4167267468096085 Test RE 1.1124398148109174\n",
      "92 Train Loss 349547.84 Test MSE 5.412425160241477 Test RE 1.111998016027672\n",
      "93 Train Loss 344743.06 Test MSE 5.411293289724537 Test RE 1.1118817369529654\n",
      "94 Train Loss 341872.28 Test MSE 5.410996395572952 Test RE 1.111851234474597\n",
      "95 Train Loss 335530.47 Test MSE 5.410241883666277 Test RE 1.1117737132400691\n",
      "96 Train Loss 332397.53 Test MSE 5.410720818089367 Test RE 1.1118229212912014\n",
      "97 Train Loss 328383.78 Test MSE 5.411506709126189 Test RE 1.1119036628385737\n",
      "98 Train Loss 323252.66 Test MSE 5.412931073368004 Test RE 1.1120499854527102\n",
      "99 Train Loss 320380.75 Test MSE 5.4115559528984996 Test RE 1.1119087218922885\n",
      "Training time: 73.98\n",
      "KG_stan_tune2\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.03\n",
      "KG_stan_tune3\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 13306818000.0 Test MSE 6.241409110593881 Test RE 1.1941238858876093\n",
      "1 Train Loss 6873797000.0 Test MSE 6.2416666746951925 Test RE 1.1941485245763324\n",
      "2 Train Loss 5669400600.0 Test MSE 6.241645550516403 Test RE 1.1941465038477679\n",
      "3 Train Loss 5141303000.0 Test MSE 6.241546062356398 Test RE 1.1941369868132856\n",
      "4 Train Loss 4591281700.0 Test MSE 6.241573461858596 Test RE 1.1941396078564344\n",
      "5 Train Loss 4088397800.0 Test MSE 6.2416876788130695 Test RE 1.1941505338165384\n",
      "6 Train Loss 3823276500.0 Test MSE 6.241668466185102 Test RE 1.1941486959492196\n",
      "7 Train Loss 3103209000.0 Test MSE 6.241770406376588 Test RE 1.1941584474483866\n",
      "8 Train Loss 2747183900.0 Test MSE 6.2421013016902105 Test RE 1.1941901000222142\n",
      "9 Train Loss 2509397800.0 Test MSE 6.2425166473602625 Test RE 1.1942298297071914\n",
      "10 Train Loss 2374103600.0 Test MSE 6.242672920298559 Test RE 1.194244777575741\n",
      "11 Train Loss 2251199000.0 Test MSE 6.242871056281555 Test RE 1.1942637294725047\n",
      "12 Train Loss 2136039200.0 Test MSE 6.243209076029128 Test RE 1.1942960606913067\n",
      "13 Train Loss 2047088800.0 Test MSE 6.243356459417292 Test RE 1.1943101574770258\n",
      "14 Train Loss 1961694300.0 Test MSE 6.243596164311618 Test RE 1.1943330841867332\n",
      "15 Train Loss 1899778200.0 Test MSE 6.243844015044189 Test RE 1.1943567895469454\n",
      "16 Train Loss 1852527900.0 Test MSE 6.24407846931944 Test RE 1.1943792131874285\n",
      "17 Train Loss 1824407300.0 Test MSE 6.2441430145895085 Test RE 1.1943853863425251\n",
      "18 Train Loss 1768311300.0 Test MSE 6.243993559790706 Test RE 1.1943710923316935\n",
      "19 Train Loss 1685342700.0 Test MSE 6.243920469342322 Test RE 1.1943641018236708\n",
      "20 Train Loss 1648674200.0 Test MSE 6.243986587629774 Test RE 1.194370425502867\n",
      "21 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "22 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "23 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "24 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "25 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "26 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "27 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "28 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "29 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "30 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "31 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "32 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "33 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "34 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "35 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "36 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "37 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "38 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "39 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "40 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "41 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "42 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "43 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "44 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "45 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "46 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "47 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "48 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "49 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "50 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "51 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "52 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "53 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "54 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "55 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "56 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "57 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "58 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "59 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "60 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "61 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "62 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "63 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "64 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "65 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "66 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "67 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "68 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "69 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "70 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "71 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "72 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "73 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "74 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "75 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "76 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "77 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "78 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "79 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "80 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "81 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "82 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "83 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "84 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "85 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "86 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "87 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "88 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "89 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "90 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "91 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "92 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "93 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "94 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "95 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "96 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "97 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "98 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "99 Train Loss 1638852200.0 Test MSE 6.243994527721045 Test RE 1.1943711849060983\n",
      "Training time: 28.32\n",
      "KG_stan_tune3\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 1.02\n",
      "KG_stan_tune4\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 327800700000.0 Test MSE 6.429705314536661 Test RE 1.212002720616206\n",
      "1 Train Loss 207436840000.0 Test MSE 6.4299156332465115 Test RE 1.2120225430459723\n",
      "2 Train Loss 180972470000.0 Test MSE 6.4299332590238 Test RE 1.212024204251655\n",
      "3 Train Loss 154751000000.0 Test MSE 6.429927809678362 Test RE 1.2120236906584574\n",
      "4 Train Loss 139813850000.0 Test MSE 6.429866667586107 Test RE 1.2120179280867245\n",
      "5 Train Loss 131999640000.0 Test MSE 6.429809311266695 Test RE 1.2120125222948135\n",
      "6 Train Loss 127490966000.0 Test MSE 6.429783542573192 Test RE 1.212010093606108\n",
      "7 Train Loss 126156030000.0 Test MSE 6.429776199635559 Test RE 1.212009401536382\n",
      "8 Train Loss 112372240000.0 Test MSE 6.4298651244266285 Test RE 1.2120177826453677\n",
      "9 Train Loss 96442065000.0 Test MSE 6.42982603185416 Test RE 1.2120140982006629\n",
      "10 Train Loss 83558010000.0 Test MSE 6.429783172946556 Test RE 1.2120100587689149\n",
      "11 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "12 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "13 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "14 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "15 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "16 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "17 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "18 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "19 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "20 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "21 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "22 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "23 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "24 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "25 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "26 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "27 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "28 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "29 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "30 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "31 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "32 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "33 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "34 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "35 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "36 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "37 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "38 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "39 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "40 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "41 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "42 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "43 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "44 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "45 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "46 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "47 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "48 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "49 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "50 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "51 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "52 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "53 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "54 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "55 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "56 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "57 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "58 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "59 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "60 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "61 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "62 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "63 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "64 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "65 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "66 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "67 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "68 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "69 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "70 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "71 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "72 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "73 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "74 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "75 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "76 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "77 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "78 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "79 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "80 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "81 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "82 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "83 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "84 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "85 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "86 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "87 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "88 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "89 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "90 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "91 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "93 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "94 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "95 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "96 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "97 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "98 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "99 Train Loss 81921580000.0 Test MSE 6.429755192882515 Test RE 1.2120074216538643\n",
      "Training time: 21.91\n",
      "KG_stan_tune4\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.92\n",
      "KG_stan_tune5\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 59.959656 Test MSE 8.598738724760752 Test RE 1.4016043502399036\n",
      "1 Train Loss 58.348354 Test MSE 8.543017508480352 Test RE 1.3970556578703919\n",
      "2 Train Loss 56.87272 Test MSE 8.43767748078735 Test RE 1.3884157154291974\n",
      "3 Train Loss 51.728386 Test MSE 8.0102120546562 Test RE 1.352789011654294\n",
      "4 Train Loss 49.472416 Test MSE 8.155934726256195 Test RE 1.3650385956353965\n",
      "5 Train Loss 41.15147 Test MSE 7.291389163844366 Test RE 1.2906640086454024\n",
      "6 Train Loss 36.5358 Test MSE 7.4686333902610755 Test RE 1.3062570014277468\n",
      "7 Train Loss 34.01408 Test MSE 7.0149019710503575 Test RE 1.26595673465379\n",
      "8 Train Loss 32.697815 Test MSE 6.537487678767471 Test RE 1.2221190166941664\n",
      "9 Train Loss 29.91859 Test MSE 6.273030274682707 Test RE 1.1971449891045134\n",
      "10 Train Loss 28.74527 Test MSE 6.075170232951407 Test RE 1.178113916689622\n",
      "11 Train Loss 27.15493 Test MSE 6.476290606098658 Test RE 1.2163854719032334\n",
      "12 Train Loss 26.160591 Test MSE 6.343963882912227 Test RE 1.2038944467959964\n",
      "13 Train Loss 24.834534 Test MSE 6.21426400769822 Test RE 1.1915243177134247\n",
      "14 Train Loss 24.196896 Test MSE 6.0903197366612565 Test RE 1.1795819190366916\n",
      "15 Train Loss 23.633554 Test MSE 5.888981071751419 Test RE 1.1599202741317964\n",
      "16 Train Loss 23.255348 Test MSE 5.805519749742779 Test RE 1.1516714842195441\n",
      "17 Train Loss 23.06578 Test MSE 5.85170815027007 Test RE 1.156243726068578\n",
      "18 Train Loss 22.773907 Test MSE 5.898651421727883 Test RE 1.1608722413582981\n",
      "19 Train Loss 22.587854 Test MSE 5.874483244871112 Test RE 1.1584916156144756\n",
      "20 Train Loss 22.116325 Test MSE 5.9061270700484405 Test RE 1.1616076234094472\n",
      "21 Train Loss 21.397972 Test MSE 5.4413200884514135 Test RE 1.1149623371939006\n",
      "22 Train Loss 20.430094 Test MSE 5.160357915144162 Test RE 1.0857953380417649\n",
      "23 Train Loss 19.184578 Test MSE 4.947551988091273 Test RE 1.06317129764988\n",
      "24 Train Loss 17.690395 Test MSE 4.93819371390057 Test RE 1.0621653296651956\n",
      "25 Train Loss 16.559341 Test MSE 5.102043018208411 Test RE 1.0796428633077255\n",
      "26 Train Loss 15.5019245 Test MSE 4.814926719702937 Test RE 1.0488246871353364\n",
      "27 Train Loss 13.182568 Test MSE 4.562824217157713 Test RE 1.0209980890194745\n",
      "28 Train Loss 11.652428 Test MSE 4.560245508248514 Test RE 1.0207095364868564\n",
      "29 Train Loss 9.97169 Test MSE 4.289531550929129 Test RE 0.9899493927059774\n",
      "30 Train Loss 8.864094 Test MSE 4.196518444338059 Test RE 0.9791576659292696\n",
      "31 Train Loss 7.911488 Test MSE 4.214075428635368 Test RE 0.9812037802192899\n",
      "32 Train Loss 7.2070875 Test MSE 4.013248315485158 Test RE 0.9575381285651113\n",
      "33 Train Loss 6.685709 Test MSE 3.5820625441258365 Test RE 0.9046376164774361\n",
      "34 Train Loss 6.2078967 Test MSE 3.3126742957903432 Test RE 0.8699562833914793\n",
      "35 Train Loss 5.8135004 Test MSE 3.0690521522470915 Test RE 0.83735611170035\n",
      "36 Train Loss 5.5397663 Test MSE 2.9568049447550044 Test RE 0.8219007905796667\n",
      "37 Train Loss 5.1686754 Test MSE 2.5186626469047426 Test RE 0.758565454813433\n",
      "38 Train Loss 4.880709 Test MSE 2.2989066659933064 Test RE 0.7247174692376929\n",
      "39 Train Loss 4.4865503 Test MSE 2.2145832620656214 Test RE 0.7113020606662579\n",
      "40 Train Loss 4.382655 Test MSE 2.2370525337174008 Test RE 0.7149014069200315\n",
      "41 Train Loss 4.2507896 Test MSE 2.2490211376153555 Test RE 0.7168112766360938\n",
      "42 Train Loss 4.1677036 Test MSE 2.2328623851359044 Test RE 0.7142315641024891\n",
      "43 Train Loss 3.9559407 Test MSE 2.1725761955780687 Test RE 0.7045236374017007\n",
      "44 Train Loss 3.9114952 Test MSE 2.155749961529761 Test RE 0.7017901264463374\n",
      "45 Train Loss 3.7995348 Test MSE 2.129836222904371 Test RE 0.6975593507127711\n",
      "46 Train Loss 3.7053776 Test MSE 2.1479086604020337 Test RE 0.70051262186088\n",
      "47 Train Loss 3.4745207 Test MSE 2.1592844695766447 Test RE 0.7023652086667405\n",
      "48 Train Loss 2.580026 Test MSE 1.5225919580549336 Test RE 0.5897932883180484\n",
      "49 Train Loss 1.9052099 Test MSE 0.8458124572578278 Test RE 0.4395872615784619\n",
      "50 Train Loss 1.1280128 Test MSE 0.30268734053128565 Test RE 0.2629693840163811\n",
      "51 Train Loss 0.8408939 Test MSE 0.21879291073663693 Test RE 0.22357574330063534\n",
      "52 Train Loss 0.6323788 Test MSE 0.12762156829565804 Test RE 0.17075369050824118\n",
      "53 Train Loss 0.5310788 Test MSE 0.10448080936895802 Test RE 0.15449923181067576\n",
      "54 Train Loss 0.43611503 Test MSE 0.07723095930902192 Test RE 0.1328323252085162\n",
      "55 Train Loss 0.36203808 Test MSE 0.05727518078061149 Test RE 0.11439085197619316\n",
      "56 Train Loss 0.32658815 Test MSE 0.06747957785211994 Test RE 0.12416358363252969\n",
      "57 Train Loss 0.29752138 Test MSE 0.06105891526297754 Test RE 0.11810889397090076\n",
      "58 Train Loss 0.26954213 Test MSE 0.06627980900719516 Test RE 0.12305483556557276\n",
      "59 Train Loss 0.24411267 Test MSE 0.060744277713498954 Test RE 0.11780419243800742\n",
      "60 Train Loss 0.21689126 Test MSE 0.055783080923248955 Test RE 0.11289099704417813\n",
      "61 Train Loss 0.20019016 Test MSE 0.0496468954286323 Test RE 0.10650110363434444\n",
      "62 Train Loss 0.1891627 Test MSE 0.04338459850691429 Test RE 0.0995579284929052\n",
      "63 Train Loss 0.17235525 Test MSE 0.03739208954274915 Test RE 0.09242680226652676\n",
      "64 Train Loss 0.15741345 Test MSE 0.03314503267179918 Test RE 0.08701964074499793\n",
      "65 Train Loss 0.14383838 Test MSE 0.026955959236870802 Test RE 0.07847574652567924\n",
      "66 Train Loss 0.13719538 Test MSE 0.02615663719940367 Test RE 0.07730347455965382\n",
      "67 Train Loss 0.12668815 Test MSE 0.029192697159385637 Test RE 0.0816667309087313\n",
      "68 Train Loss 0.12020117 Test MSE 0.02953903428829162 Test RE 0.08214974255274247\n",
      "69 Train Loss 0.11395098 Test MSE 0.028922486275239963 Test RE 0.08128789401401812\n",
      "70 Train Loss 0.10708454 Test MSE 0.028107580045095025 Test RE 0.08013454739401941\n",
      "71 Train Loss 0.10461554 Test MSE 0.02939945368291981 Test RE 0.08195542190501676\n",
      "72 Train Loss 0.100552976 Test MSE 0.027245015090488697 Test RE 0.07889538261228789\n",
      "73 Train Loss 0.091359235 Test MSE 0.024437902852525516 Test RE 0.07472054437815401\n",
      "74 Train Loss 0.087114334 Test MSE 0.024205143242110212 Test RE 0.0743638538758226\n",
      "75 Train Loss 0.07778594 Test MSE 0.022646667703095376 Test RE 0.07193002547708044\n",
      "76 Train Loss 0.07507386 Test MSE 0.02141713745235995 Test RE 0.06995016966981639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 0.07195319 Test MSE 0.020515442172803763 Test RE 0.06846182959762158\n",
      "78 Train Loss 0.063310705 Test MSE 0.02203936092562235 Test RE 0.07095901182007856\n",
      "79 Train Loss 0.058435198 Test MSE 0.020251396572962477 Test RE 0.0680198311370464\n",
      "80 Train Loss 0.055798747 Test MSE 0.01781022464456266 Test RE 0.06378855422954013\n",
      "81 Train Loss 0.05271364 Test MSE 0.01781485964747654 Test RE 0.06379685398171028\n",
      "82 Train Loss 0.048200563 Test MSE 0.01655610881240668 Test RE 0.06150171073667572\n",
      "83 Train Loss 0.046160962 Test MSE 0.017418841244810402 Test RE 0.06308377742767478\n",
      "84 Train Loss 0.043786492 Test MSE 0.01617994518850529 Test RE 0.06079902059244792\n",
      "85 Train Loss 0.040365648 Test MSE 0.014865208126983437 Test RE 0.058276512954175665\n",
      "86 Train Loss 0.036677323 Test MSE 0.014436324910444262 Test RE 0.057429678394251324\n",
      "87 Train Loss 0.035522006 Test MSE 0.015090593006073518 Test RE 0.058716642417691166\n",
      "88 Train Loss 0.034518868 Test MSE 0.014401360882844789 Test RE 0.05736009038799464\n",
      "89 Train Loss 0.03138676 Test MSE 0.013200990204219767 Test RE 0.0549175703041072\n",
      "90 Train Loss 0.02994953 Test MSE 0.012412197746743512 Test RE 0.05325156838188747\n",
      "91 Train Loss 0.029376637 Test MSE 0.01269084877995905 Test RE 0.05384599355645278\n",
      "92 Train Loss 0.028867407 Test MSE 0.012409701895733292 Test RE 0.05324621418654565\n",
      "93 Train Loss 0.02792693 Test MSE 0.013244184854863365 Test RE 0.0550073441746568\n",
      "94 Train Loss 0.026688077 Test MSE 0.012478876054823491 Test RE 0.05339441047555431\n",
      "95 Train Loss 0.025031935 Test MSE 0.0105637403109314 Test RE 0.04912662379505211\n",
      "96 Train Loss 0.024299024 Test MSE 0.009718417596201758 Test RE 0.047120060410285214\n",
      "97 Train Loss 0.023127075 Test MSE 0.009160150965420931 Test RE 0.0457466583673389\n",
      "98 Train Loss 0.022429202 Test MSE 0.00887103318451325 Test RE 0.04501892933976753\n",
      "99 Train Loss 0.02106227 Test MSE 0.007580861607824319 Test RE 0.041616671701697784\n",
      "Training time: 77.35\n",
      "KG_stan_tune5\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.638416 Test MSE 8.510158526810272 Test RE 1.3943663239691337\n",
      "1 Train Loss 57.34266 Test MSE 8.699512705626235 Test RE 1.4097935641798403\n",
      "2 Train Loss 52.537148 Test MSE 9.079161493601669 Test RE 1.4402269417106452\n",
      "3 Train Loss 45.12857 Test MSE 8.307621841439417 Test RE 1.377673865811407\n",
      "4 Train Loss 44.410587 Test MSE 8.52075146242194 Test RE 1.3952338659287389\n",
      "5 Train Loss 44.390472 Test MSE 8.400259623449687 Test RE 1.3853337497088924\n",
      "6 Train Loss 44.18961 Test MSE 8.524471968425015 Test RE 1.3955384405588482\n",
      "7 Train Loss 43.95896 Test MSE 8.51397752384857 Test RE 1.394679155014604\n",
      "8 Train Loss 43.670204 Test MSE 8.3542283145498 Test RE 1.3815328954529948\n",
      "9 Train Loss 43.36183 Test MSE 8.312444926784396 Test RE 1.3780737199834958\n",
      "10 Train Loss 41.000793 Test MSE 7.672422845351973 Test RE 1.3239583567275177\n",
      "11 Train Loss 39.950333 Test MSE 7.950165584831731 Test RE 1.3477090582430642\n",
      "12 Train Loss 39.551575 Test MSE 7.678608222297874 Test RE 1.3244919255774288\n",
      "13 Train Loss 39.23538 Test MSE 7.729540093785778 Test RE 1.3288773139934118\n",
      "14 Train Loss 38.772892 Test MSE 7.703406229942394 Test RE 1.3266289199846064\n",
      "15 Train Loss 38.095608 Test MSE 7.800650293592645 Test RE 1.3349760201587353\n",
      "16 Train Loss 37.774704 Test MSE 8.051519367322289 Test RE 1.3562725787817704\n",
      "17 Train Loss 37.601204 Test MSE 8.023461042739578 Test RE 1.3539073141564626\n",
      "18 Train Loss 37.20656 Test MSE 8.133270055763704 Test RE 1.363140611248717\n",
      "19 Train Loss 36.283604 Test MSE 8.274433834804721 Test RE 1.3749192866122468\n",
      "20 Train Loss 33.606804 Test MSE 7.911397225250521 Test RE 1.344419043651882\n",
      "21 Train Loss 32.498837 Test MSE 7.725814180501901 Test RE 1.3285569923187657\n",
      "22 Train Loss 32.03371 Test MSE 7.751317941811042 Test RE 1.3307480418731912\n",
      "23 Train Loss 31.667347 Test MSE 7.816670843150486 Test RE 1.3363461674578652\n",
      "24 Train Loss 31.118061 Test MSE 8.067456630020814 Test RE 1.3576142253450856\n",
      "25 Train Loss 30.654396 Test MSE 8.05862800053276 Test RE 1.3568711687340156\n",
      "26 Train Loss 30.004147 Test MSE 7.986456600623763 Test RE 1.3507815754937074\n",
      "27 Train Loss 29.45091 Test MSE 7.871020548262602 Test RE 1.34098396074304\n",
      "28 Train Loss 28.692585 Test MSE 7.66599109234605 Test RE 1.3234033066045534\n",
      "29 Train Loss 27.555717 Test MSE 7.209852094465004 Test RE 1.2834271966932056\n",
      "30 Train Loss 26.892017 Test MSE 7.197685663489902 Test RE 1.2823438650854562\n",
      "31 Train Loss 23.507492 Test MSE 6.104562960587782 Test RE 1.1809604376200546\n",
      "32 Train Loss 21.184095 Test MSE 5.684657088830351 Test RE 1.13962035163985\n",
      "33 Train Loss 19.570099 Test MSE 5.391758486445908 Test RE 1.109872972320654\n",
      "34 Train Loss 18.70555 Test MSE 5.465742252739151 Test RE 1.1174616670970394\n",
      "35 Train Loss 18.325924 Test MSE 5.384913005441439 Test RE 1.1091681904373267\n",
      "36 Train Loss 18.058811 Test MSE 5.334975581474174 Test RE 1.104013231145205\n",
      "37 Train Loss 17.814342 Test MSE 5.298566116808366 Test RE 1.1002395167964525\n",
      "38 Train Loss 17.64466 Test MSE 5.219929019969802 Test RE 1.0920445582119673\n",
      "39 Train Loss 17.505415 Test MSE 5.173268894581883 Test RE 1.087152794631084\n",
      "40 Train Loss 17.406113 Test MSE 5.238540636353345 Test RE 1.0939896641355056\n",
      "41 Train Loss 17.269829 Test MSE 5.299849405208647 Test RE 1.1003727452112961\n",
      "42 Train Loss 17.120909 Test MSE 5.300248954345567 Test RE 1.1004142223044275\n",
      "43 Train Loss 16.891102 Test MSE 5.313864540167009 Test RE 1.1018267195843228\n",
      "44 Train Loss 16.68268 Test MSE 5.320237552777486 Test RE 1.1024872418273912\n",
      "45 Train Loss 16.438152 Test MSE 5.322964549283543 Test RE 1.1027697568154227\n",
      "46 Train Loss 16.186247 Test MSE 5.361574879480392 Test RE 1.1067620220244672\n",
      "47 Train Loss 15.830254 Test MSE 5.436378863996942 Test RE 1.1144559774889575\n",
      "48 Train Loss 15.423727 Test MSE 5.498485935252465 Test RE 1.1208038640162006\n",
      "49 Train Loss 14.7409525 Test MSE 5.344936237900149 Test RE 1.105043373482581\n",
      "50 Train Loss 13.619432 Test MSE 4.974951764130724 Test RE 1.066111179340465\n",
      "51 Train Loss 12.374245 Test MSE 4.7275880710100635 Test RE 1.0392687637856357\n",
      "52 Train Loss 11.06942 Test MSE 4.502565828892937 Test RE 1.0142338378545928\n",
      "53 Train Loss 10.454065 Test MSE 4.364720245317188 Test RE 0.9985878251336341\n",
      "54 Train Loss 9.685896 Test MSE 4.378816562330088 Test RE 1.000199046788901\n",
      "55 Train Loss 9.37221 Test MSE 4.500369736283053 Test RE 1.0139864652252528\n",
      "56 Train Loss 9.078411 Test MSE 4.591745487345968 Test RE 1.0242287545580895\n",
      "57 Train Loss 8.83651 Test MSE 4.582123880146094 Test RE 1.0231551002544101\n",
      "58 Train Loss 8.622664 Test MSE 4.462093203032735 Test RE 1.0096651797036094\n",
      "59 Train Loss 8.460501 Test MSE 4.256037276181535 Test RE 0.9860768698768505\n",
      "60 Train Loss 8.310432 Test MSE 4.173073184693689 Test RE 0.9764186383766005\n",
      "61 Train Loss 8.178178 Test MSE 4.0352464674545745 Test RE 0.9601588588808518\n",
      "62 Train Loss 7.982396 Test MSE 3.9884512005580866 Test RE 0.9545753198094313\n",
      "63 Train Loss 7.692669 Test MSE 3.8041535899645567 Test RE 0.9322600669361167\n",
      "64 Train Loss 7.3045864 Test MSE 3.4976004669752214 Test RE 0.8939086903690636\n",
      "65 Train Loss 7.1302013 Test MSE 3.3372696518581084 Test RE 0.8731798594898476\n",
      "66 Train Loss 6.7036915 Test MSE 3.1475327088921086 Test RE 0.8479947944059658\n",
      "67 Train Loss 6.1514587 Test MSE 3.189072669658842 Test RE 0.8535722117989782\n",
      "68 Train Loss 5.24537 Test MSE 3.158616753426657 Test RE 0.849486590144943\n",
      "69 Train Loss 4.7504773 Test MSE 3.037355464140393 Test RE 0.8330208480330913\n",
      "70 Train Loss 3.9475589 Test MSE 2.840173820466246 Test RE 0.8055277760327941\n",
      "71 Train Loss 3.3217049 Test MSE 2.5601584049871584 Test RE 0.7647887289758682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Train Loss 2.4102795 Test MSE 2.2600000414805503 Test RE 0.718558752672894\n",
      "73 Train Loss 1.9896494 Test MSE 2.164203753420434 Test RE 0.7031648180369391\n",
      "74 Train Loss 1.8404112 Test MSE 2.215938124317644 Test RE 0.7115196115199788\n",
      "75 Train Loss 1.7247014 Test MSE 2.3079625956714795 Test RE 0.7261434818606238\n",
      "76 Train Loss 1.6517016 Test MSE 2.3053970969651294 Test RE 0.7257397842110781\n",
      "77 Train Loss 1.5757688 Test MSE 2.2984046121641963 Test RE 0.724638330085813\n",
      "78 Train Loss 1.5077204 Test MSE 2.356704016326297 Test RE 0.7337710635640634\n",
      "79 Train Loss 1.4719355 Test MSE 2.3592694172304287 Test RE 0.7341703298565421\n",
      "80 Train Loss 1.4182801 Test MSE 2.4223875791025056 Test RE 0.7439262369350973\n",
      "81 Train Loss 1.3732691 Test MSE 2.4581010969812676 Test RE 0.7493900640140656\n",
      "82 Train Loss 1.337449 Test MSE 2.467817659100274 Test RE 0.7508697252040117\n",
      "83 Train Loss 1.2891235 Test MSE 2.4332774654486715 Test RE 0.7455965286330395\n",
      "84 Train Loss 1.2517158 Test MSE 2.5010719781751116 Test RE 0.7559118533380289\n",
      "85 Train Loss 1.2221905 Test MSE 2.484316431293178 Test RE 0.7533755407152448\n",
      "86 Train Loss 1.1943375 Test MSE 2.497838872691884 Test RE 0.755423116287694\n",
      "87 Train Loss 1.1702602 Test MSE 2.4919628810043646 Test RE 0.7545340530253322\n",
      "88 Train Loss 1.144728 Test MSE 2.5015443450027153 Test RE 0.7559832328963448\n",
      "89 Train Loss 1.1144048 Test MSE 2.471788402255549 Test RE 0.7514735608347796\n",
      "90 Train Loss 1.0865469 Test MSE 2.4461126561314424 Test RE 0.7475603997902006\n",
      "91 Train Loss 1.0672939 Test MSE 2.4548422352542807 Test RE 0.7488931421076322\n",
      "92 Train Loss 1.0535971 Test MSE 2.4759125987986295 Test RE 0.7521002190403844\n",
      "93 Train Loss 1.0417163 Test MSE 2.484362228605587 Test RE 0.7533824847614131\n",
      "94 Train Loss 1.0304583 Test MSE 2.491780869805915 Test RE 0.7545064972065659\n",
      "95 Train Loss 1.0246952 Test MSE 2.500825225865925 Test RE 0.7558745638082324\n",
      "96 Train Loss 1.0177042 Test MSE 2.4956042155161335 Test RE 0.7550851262282757\n",
      "97 Train Loss 1.0092645 Test MSE 2.4809861040290153 Test RE 0.7528704060863228\n",
      "98 Train Loss 0.98881924 Test MSE 2.504974264068768 Test RE 0.7565013274690904\n",
      "99 Train Loss 0.9864128 Test MSE 2.4978169413252753 Test RE 0.7554197999213231\n",
      "Training time: 77.22\n",
      "KG_stan_tune5\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.51223 Test MSE 8.592505337758096 Test RE 1.4010962334944927\n",
      "1 Train Loss 53.967445 Test MSE 7.869967085512108 Test RE 1.3408942186368829\n",
      "2 Train Loss 48.53524 Test MSE 7.847868472524548 Test RE 1.3390103014181272\n",
      "3 Train Loss 43.357323 Test MSE 8.32982412590492 Test RE 1.3795135678636659\n",
      "4 Train Loss 37.019016 Test MSE 7.180707028602818 Test RE 1.2808305103602342\n",
      "5 Train Loss 35.043358 Test MSE 7.057842909177474 Test RE 1.2698255293946874\n",
      "6 Train Loss 33.117374 Test MSE 6.684023516783605 Test RE 1.2357398298311044\n",
      "7 Train Loss 31.976757 Test MSE 6.818704919970716 Test RE 1.2481276624699886\n",
      "8 Train Loss 30.864397 Test MSE 6.906337359907407 Test RE 1.2561223838677693\n",
      "9 Train Loss 29.839508 Test MSE 6.632171186253501 Test RE 1.2309372775862955\n",
      "10 Train Loss 28.632938 Test MSE 6.2709842974531265 Test RE 1.1969497460538137\n",
      "11 Train Loss 26.98518 Test MSE 5.783406893016829 Test RE 1.149476069835929\n",
      "12 Train Loss 25.71759 Test MSE 6.0662467503343676 Test RE 1.1772483654426498\n",
      "13 Train Loss 24.833645 Test MSE 6.141655899945631 Test RE 1.1845429178437048\n",
      "14 Train Loss 23.764061 Test MSE 5.967343146951082 Test RE 1.1676120448325003\n",
      "15 Train Loss 23.359413 Test MSE 5.6286901964442055 Test RE 1.133996549605044\n",
      "16 Train Loss 22.618221 Test MSE 5.518467620240194 Test RE 1.12283853686488\n",
      "17 Train Loss 22.006527 Test MSE 5.826149636385427 Test RE 1.1537158991788143\n",
      "18 Train Loss 21.074917 Test MSE 5.454611271470801 Test RE 1.1163232321428047\n",
      "19 Train Loss 20.375797 Test MSE 5.291394398537457 Test RE 1.0994946662553349\n",
      "20 Train Loss 19.079426 Test MSE 5.807746411586604 Test RE 1.1518923203566116\n",
      "21 Train Loss 18.224306 Test MSE 5.5942889646042255 Test RE 1.130525878274413\n",
      "22 Train Loss 17.853365 Test MSE 5.521955253260316 Test RE 1.1231932938819953\n",
      "23 Train Loss 17.397722 Test MSE 5.305959101784343 Test RE 1.1010068205060484\n",
      "24 Train Loss 17.021223 Test MSE 5.377486314947103 Test RE 1.1084030628473902\n",
      "25 Train Loss 16.736713 Test MSE 5.45884990412691 Test RE 1.116756880391208\n",
      "26 Train Loss 16.250202 Test MSE 5.574160345805982 Test RE 1.1284901923432058\n",
      "27 Train Loss 16.10928 Test MSE 5.669163943308942 Test RE 1.1380663132558153\n",
      "28 Train Loss 15.668507 Test MSE 5.608339968272341 Test RE 1.1319447414568884\n",
      "29 Train Loss 15.53845 Test MSE 5.700856031209522 Test RE 1.1412429219646265\n",
      "30 Train Loss 15.31821 Test MSE 5.652880066725897 Test RE 1.1364306701119449\n",
      "31 Train Loss 15.089909 Test MSE 5.642243904871526 Test RE 1.1353610426437757\n",
      "32 Train Loss 15.009388 Test MSE 5.610506359297491 Test RE 1.1321633443033612\n",
      "33 Train Loss 14.74945 Test MSE 5.743784805714892 Test RE 1.1455317756755965\n",
      "34 Train Loss 14.438843 Test MSE 5.473626342488381 Test RE 1.1182673210126512\n",
      "35 Train Loss 14.27673 Test MSE 5.584971350406695 Test RE 1.1295840075681147\n",
      "36 Train Loss 14.023571 Test MSE 5.542118914882853 Test RE 1.1252421200115563\n",
      "37 Train Loss 13.9499 Test MSE 5.500127642020505 Test RE 1.120971173161376\n",
      "38 Train Loss 13.85008 Test MSE 5.547456622892573 Test RE 1.1257838594160743\n",
      "39 Train Loss 13.711116 Test MSE 5.429355008773885 Test RE 1.1137358007260447\n",
      "40 Train Loss 13.603525 Test MSE 5.406896615740652 Test RE 1.111429943394518\n",
      "41 Train Loss 13.51878 Test MSE 5.3186838462674855 Test RE 1.1023262465084136\n",
      "42 Train Loss 13.372 Test MSE 5.413563680077383 Test RE 1.1121149659336624\n",
      "43 Train Loss 13.219658 Test MSE 5.489116231399756 Test RE 1.119848503027773\n",
      "44 Train Loss 13.111584 Test MSE 5.486887014550709 Test RE 1.1196210858486753\n",
      "45 Train Loss 12.940075 Test MSE 5.582655973456256 Test RE 1.1293498359191911\n",
      "46 Train Loss 12.55932 Test MSE 5.567679403458082 Test RE 1.1278339673227886\n",
      "47 Train Loss 12.3518915 Test MSE 5.55885123592914 Test RE 1.1269394602506213\n",
      "48 Train Loss 12.166429 Test MSE 5.5705866405620235 Test RE 1.128128385571698\n",
      "49 Train Loss 11.918637 Test MSE 5.515579861238641 Test RE 1.122544713323946\n",
      "50 Train Loss 11.800624 Test MSE 5.593505755730418 Test RE 1.1304467378422358\n",
      "51 Train Loss 11.647249 Test MSE 5.628039821844979 Test RE 1.133931033132164\n",
      "52 Train Loss 11.57416 Test MSE 5.671168028065341 Test RE 1.1382674522457077\n",
      "53 Train Loss 11.452417 Test MSE 5.6527142924682625 Test RE 1.136414006718271\n",
      "54 Train Loss 11.414075 Test MSE 5.724678871475181 Test RE 1.1436249593128827\n",
      "55 Train Loss 11.362822 Test MSE 5.707265685852239 Test RE 1.1418843096784879\n",
      "56 Train Loss 11.30643 Test MSE 5.773845811189865 Test RE 1.1485255245115493\n",
      "57 Train Loss 11.251928 Test MSE 5.751326006435008 Test RE 1.1462835318521793\n",
      "58 Train Loss 11.213136 Test MSE 5.724357544527635 Test RE 1.143592862955834\n",
      "59 Train Loss 11.175175 Test MSE 5.736285438801721 Test RE 1.144783700203622\n",
      "60 Train Loss 11.14849 Test MSE 5.719361090601285 Test RE 1.1430936666369667\n",
      "61 Train Loss 11.09895 Test MSE 5.66989414478503 Test RE 1.1381396036874036\n",
      "62 Train Loss 11.070009 Test MSE 5.658817016157987 Test RE 1.1370272828807237\n",
      "63 Train Loss 11.031037 Test MSE 5.676064775245723 Test RE 1.1387587624359883\n",
      "64 Train Loss 11.010207 Test MSE 5.647462539491417 Test RE 1.135885981402882\n",
      "65 Train Loss 10.982214 Test MSE 5.6425438194417845 Test RE 1.1353912174111256\n",
      "66 Train Loss 10.954038 Test MSE 5.650275561138079 Test RE 1.1361688406548396\n",
      "67 Train Loss 10.906777 Test MSE 5.615193378347802 Test RE 1.1326361504128946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Train Loss 10.869518 Test MSE 5.5847759426674415 Test RE 1.1295642463756097\n",
      "69 Train Loss 10.824078 Test MSE 5.5590864323178035 Test RE 1.1269633005439208\n",
      "70 Train Loss 10.781117 Test MSE 5.543667204735455 Test RE 1.125399287272052\n",
      "71 Train Loss 10.7328415 Test MSE 5.498545767657239 Test RE 1.1208099620774505\n",
      "72 Train Loss 10.670081 Test MSE 5.4345081572466665 Test RE 1.1142642138394447\n",
      "73 Train Loss 10.577595 Test MSE 5.403403795507898 Test RE 1.1110708971233523\n",
      "74 Train Loss 10.251216 Test MSE 5.03857551389878 Test RE 1.0729066723933511\n",
      "75 Train Loss 10.038567 Test MSE 4.978835415462592 Test RE 1.0665272232109153\n",
      "76 Train Loss 9.821892 Test MSE 4.897530931380865 Test RE 1.0577831729678853\n",
      "77 Train Loss 9.772571 Test MSE 4.897328543134201 Test RE 1.0577613165369109\n",
      "78 Train Loss 9.670827 Test MSE 4.950927063403972 Test RE 1.0635338680141397\n",
      "79 Train Loss 9.608713 Test MSE 4.905614239540661 Test RE 1.0586557414423998\n",
      "80 Train Loss 9.572293 Test MSE 4.907958759067294 Test RE 1.0589086906603615\n",
      "81 Train Loss 9.514263 Test MSE 4.910870630867685 Test RE 1.0592227671735719\n",
      "82 Train Loss 9.46505 Test MSE 4.998879303031255 Test RE 1.0686718893661786\n",
      "83 Train Loss 9.393332 Test MSE 5.1061776582646505 Test RE 1.0800802401191725\n",
      "84 Train Loss 9.344021 Test MSE 5.10130491245871 Test RE 1.079564765237448\n",
      "85 Train Loss 9.324521 Test MSE 5.135855578664858 Test RE 1.083214491988118\n",
      "86 Train Loss 9.30771 Test MSE 5.151430860332185 Test RE 1.0848557568810837\n",
      "87 Train Loss 9.272477 Test MSE 5.207912377201486 Test RE 1.0907868523746092\n",
      "88 Train Loss 9.240833 Test MSE 5.224594928492997 Test RE 1.0925325190497812\n",
      "89 Train Loss 9.210014 Test MSE 5.232372639561664 Test RE 1.0933454282103878\n",
      "90 Train Loss 9.198336 Test MSE 5.236430106971819 Test RE 1.0937692659281217\n",
      "91 Train Loss 9.189661 Test MSE 5.23150453774327 Test RE 1.09325472609581\n",
      "92 Train Loss 9.1688 Test MSE 5.251436112665184 Test RE 1.0953353486962853\n",
      "93 Train Loss 9.147968 Test MSE 5.219274054486209 Test RE 1.0919760444517974\n",
      "94 Train Loss 9.134498 Test MSE 5.212676064861454 Test RE 1.0912856107828677\n",
      "95 Train Loss 9.084376 Test MSE 5.244876709606464 Test RE 1.094651060546862\n",
      "96 Train Loss 9.065277 Test MSE 5.2369001427818 Test RE 1.0938183546370202\n",
      "97 Train Loss 9.051151 Test MSE 5.220078627453981 Test RE 1.0920602075500825\n",
      "98 Train Loss 9.040592 Test MSE 5.2052550356294445 Test RE 1.0905085294223542\n",
      "99 Train Loss 9.035292 Test MSE 5.203065943835797 Test RE 1.0902791963446956\n",
      "Training time: 78.37\n",
      "KG_stan_tune5\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.575172 Test MSE 8.728424393786552 Test RE 1.4121342529465852\n",
      "1 Train Loss 56.262405 Test MSE 8.512876477831199 Test RE 1.3945889706339771\n",
      "2 Train Loss 53.90049 Test MSE 8.652610542400838 Test RE 1.4059880791226553\n",
      "3 Train Loss 47.696957 Test MSE 9.460675185963414 Test RE 1.470175314561806\n",
      "4 Train Loss 45.065727 Test MSE 9.064800489740707 Test RE 1.439087448264134\n",
      "5 Train Loss 44.394836 Test MSE 8.670840204285632 Test RE 1.4074683954640106\n",
      "6 Train Loss 43.803055 Test MSE 8.589930555713295 Test RE 1.4008862954394177\n",
      "7 Train Loss 43.249397 Test MSE 8.69655833694034 Test RE 1.4095541597571424\n",
      "8 Train Loss 42.993484 Test MSE 8.526254886849664 Test RE 1.3956843734166728\n",
      "9 Train Loss 42.642227 Test MSE 8.411939993599358 Test RE 1.386296552688099\n",
      "10 Train Loss 42.504303 Test MSE 8.30412487138726 Test RE 1.3773838796136575\n",
      "11 Train Loss 42.149155 Test MSE 8.337692210057021 Test RE 1.3801649361741712\n",
      "12 Train Loss 42.070267 Test MSE 8.387958163970167 Test RE 1.3843190268714798\n",
      "13 Train Loss 42.01892 Test MSE 8.330030369397761 Test RE 1.3795306458914394\n",
      "14 Train Loss 41.998817 Test MSE 8.233761065172734 Test RE 1.3715359333545143\n",
      "15 Train Loss 41.870937 Test MSE 8.159461295786203 Test RE 1.3653336803447564\n",
      "16 Train Loss 41.71962 Test MSE 8.355177910886674 Test RE 1.3816114102630868\n",
      "17 Train Loss 41.522293 Test MSE 8.381524889805988 Test RE 1.3837880626067938\n",
      "18 Train Loss 41.04045 Test MSE 8.13381192237973 Test RE 1.3631860190664116\n",
      "19 Train Loss 39.25911 Test MSE 7.868726306212886 Test RE 1.3407885117544467\n",
      "20 Train Loss 38.056805 Test MSE 7.922218328664924 Test RE 1.345338168669592\n",
      "21 Train Loss 37.61418 Test MSE 7.894248532804006 Test RE 1.3429611762813745\n",
      "22 Train Loss 37.205193 Test MSE 7.9035332171744015 Test RE 1.3437506945271498\n",
      "23 Train Loss 36.413956 Test MSE 7.915146500510676 Test RE 1.3447375714582015\n",
      "24 Train Loss 35.832275 Test MSE 7.941273268581206 Test RE 1.3469551363262444\n",
      "25 Train Loss 35.647682 Test MSE 7.892016163352726 Test RE 1.3427712786953347\n",
      "26 Train Loss 35.42304 Test MSE 7.809257692478248 Test RE 1.3357123371747794\n",
      "27 Train Loss 35.17695 Test MSE 7.8856498576915 Test RE 1.3422295782680014\n",
      "28 Train Loss 34.75983 Test MSE 7.618135179396075 Test RE 1.3192660839715435\n",
      "29 Train Loss 34.370247 Test MSE 7.5914585904016985 Test RE 1.316954206996053\n",
      "30 Train Loss 33.6689 Test MSE 7.704109028885451 Test RE 1.3266894342630158\n",
      "31 Train Loss 33.155922 Test MSE 7.756401346234512 Test RE 1.3311843303727515\n",
      "32 Train Loss 32.53083 Test MSE 7.796405338722401 Test RE 1.334612737361175\n",
      "33 Train Loss 31.889692 Test MSE 7.487351802852124 Test RE 1.3078928935083665\n",
      "34 Train Loss 31.247963 Test MSE 7.343583803483212 Test RE 1.295275312009821\n",
      "35 Train Loss 30.31371 Test MSE 7.168760569022912 Test RE 1.279764615362303\n",
      "36 Train Loss 29.622623 Test MSE 7.210806108217002 Test RE 1.2835121059727803\n",
      "37 Train Loss 27.29131 Test MSE 6.602053808240928 Test RE 1.228139190374277\n",
      "38 Train Loss 24.043293 Test MSE 5.849420998136047 Test RE 1.1560177438689625\n",
      "39 Train Loss 21.038532 Test MSE 5.185019958171571 Test RE 1.088386826285163\n",
      "40 Train Loss 19.618727 Test MSE 5.1435963031027 Test RE 1.084030491166628\n",
      "41 Train Loss 15.927008 Test MSE 4.749407192855166 Test RE 1.0416642588807294\n",
      "42 Train Loss 15.323966 Test MSE 4.867075150940044 Test RE 1.0544890791838522\n",
      "43 Train Loss 14.669195 Test MSE 5.244036566938012 Test RE 1.0945633845207503\n",
      "44 Train Loss 14.290362 Test MSE 5.118846215250018 Test RE 1.081419263405654\n",
      "45 Train Loss 13.926914 Test MSE 5.206074102271101 Test RE 1.090594323876082\n",
      "46 Train Loss 13.459149 Test MSE 5.3360975740946195 Test RE 1.1041293169228281\n",
      "47 Train Loss 13.227263 Test MSE 5.293424416414981 Test RE 1.0997055539371337\n",
      "48 Train Loss 12.81345 Test MSE 5.2159640201556545 Test RE 1.0916297269936819\n",
      "49 Train Loss 12.653044 Test MSE 5.195171096694738 Test RE 1.0894517173794906\n",
      "50 Train Loss 12.456503 Test MSE 4.987159185619297 Test RE 1.0674183774065156\n",
      "51 Train Loss 12.062279 Test MSE 4.954094589870284 Test RE 1.0638740298648321\n",
      "52 Train Loss 11.570217 Test MSE 4.960279630823216 Test RE 1.064537930385766\n",
      "53 Train Loss 11.118208 Test MSE 4.887139710837676 Test RE 1.0566604138768803\n",
      "54 Train Loss 10.929595 Test MSE 4.8754420860180065 Test RE 1.0553950702396502\n",
      "55 Train Loss 10.789403 Test MSE 4.9067988216463165 Test RE 1.0587835530567082\n",
      "56 Train Loss 10.544364 Test MSE 4.889710107165213 Test RE 1.0569382531833396\n",
      "57 Train Loss 10.283287 Test MSE 4.871510457182085 Test RE 1.0549694412921111\n",
      "58 Train Loss 9.998663 Test MSE 4.7397639460238805 Test RE 1.0406062184537597\n",
      "59 Train Loss 9.470094 Test MSE 4.279241967855252 Test RE 0.9887613512742355\n",
      "60 Train Loss 8.020672 Test MSE 3.5491840877656577 Test RE 0.9004763751086761\n",
      "61 Train Loss 6.503042 Test MSE 3.11401120086708 Test RE 0.8434670964104249\n",
      "62 Train Loss 5.7922173 Test MSE 3.306306672611094 Test RE 0.8691197661406732\n",
      "63 Train Loss 5.53125 Test MSE 3.599611287330227 Test RE 0.9068508465721755\n",
      "64 Train Loss 4.984247 Test MSE 3.938578829074532 Test RE 0.9485884477205699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 4.676627 Test MSE 4.007497086469079 Test RE 0.9568517773821086\n",
      "66 Train Loss 4.289694 Test MSE 4.183561560605482 Test RE 0.9776449071867925\n",
      "67 Train Loss 3.9952354 Test MSE 4.0713976605450455 Test RE 0.9644502314678183\n",
      "68 Train Loss 3.7324588 Test MSE 4.104027043311521 Test RE 0.9683072135757702\n",
      "69 Train Loss 3.5789442 Test MSE 4.0227466779102246 Test RE 0.9586705864143803\n",
      "70 Train Loss 3.4368565 Test MSE 3.9753534001183697 Test RE 0.9530066509304392\n",
      "71 Train Loss 3.2840106 Test MSE 4.065135982514095 Test RE 0.9637082994467333\n",
      "72 Train Loss 3.120317 Test MSE 3.915532242486342 Test RE 0.9458090440802243\n",
      "73 Train Loss 3.0487099 Test MSE 3.935801523514963 Test RE 0.9482539381571586\n",
      "74 Train Loss 2.9441712 Test MSE 3.963009045625616 Test RE 0.9515258519160741\n",
      "75 Train Loss 2.818973 Test MSE 4.03573979922098 Test RE 0.9602175495200937\n",
      "76 Train Loss 2.7403357 Test MSE 3.900345950112091 Test RE 0.943973114018637\n",
      "77 Train Loss 2.6902547 Test MSE 3.9401664618014935 Test RE 0.9487796154478885\n",
      "78 Train Loss 2.5353594 Test MSE 3.9138730636638877 Test RE 0.945608632933615\n",
      "79 Train Loss 2.4845932 Test MSE 3.9808679191965637 Test RE 0.9536674163466268\n",
      "80 Train Loss 2.361744 Test MSE 3.9354718325359053 Test RE 0.9482142210481123\n",
      "81 Train Loss 2.279934 Test MSE 4.006202776531508 Test RE 0.9566972466674357\n",
      "82 Train Loss 2.256834 Test MSE 3.9768886496196436 Test RE 0.9531906549177488\n",
      "83 Train Loss 2.1854136 Test MSE 3.937655542093155 Test RE 0.9484772565097064\n",
      "84 Train Loss 2.1231265 Test MSE 3.8754802610725245 Test RE 0.9409592695048151\n",
      "85 Train Loss 2.0721257 Test MSE 3.706383587577643 Test RE 0.9202021472127496\n",
      "86 Train Loss 2.0160728 Test MSE 3.8024938968084965 Test RE 0.9320566794525431\n",
      "87 Train Loss 1.9766948 Test MSE 3.7496299277855787 Test RE 0.9255550691002433\n",
      "88 Train Loss 1.8572013 Test MSE 3.652504951592677 Test RE 0.9134893047928674\n",
      "89 Train Loss 1.834868 Test MSE 3.611970952560735 Test RE 0.9084063989871318\n",
      "90 Train Loss 1.8060822 Test MSE 3.520251106809629 Test RE 0.8967985184912031\n",
      "91 Train Loss 1.7836534 Test MSE 3.50621492844032 Test RE 0.8950088455084675\n",
      "92 Train Loss 1.7338861 Test MSE 3.360494060204671 Test RE 0.8762128668417319\n",
      "93 Train Loss 1.7027615 Test MSE 3.3238771193602097 Test RE 0.8714260537411372\n",
      "94 Train Loss 1.6699914 Test MSE 3.246588144735374 Test RE 0.8612349773191806\n",
      "95 Train Loss 1.6533306 Test MSE 3.220736620260299 Test RE 0.85779925739457\n",
      "96 Train Loss 1.638088 Test MSE 3.2117471228062806 Test RE 0.8566013059002942\n",
      "97 Train Loss 1.6242428 Test MSE 3.232493866616143 Test RE 0.8593635221940078\n",
      "98 Train Loss 1.6022537 Test MSE 3.1799779693302197 Test RE 0.8523542204159611\n",
      "99 Train Loss 1.582422 Test MSE 3.0969273843537635 Test RE 0.8411502366111197\n",
      "Training time: 78.64\n",
      "KG_stan_tune5\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.394638 Test MSE 8.466915737952595 Test RE 1.3908192055654054\n",
      "1 Train Loss 56.672066 Test MSE 8.750775113014905 Test RE 1.413941110370434\n",
      "2 Train Loss 55.117798 Test MSE 8.224869903458469 Test RE 1.3707952122242224\n",
      "3 Train Loss 49.853897 Test MSE 8.18023979710473 Test RE 1.3670710223361324\n",
      "4 Train Loss 46.87155 Test MSE 7.721413268719732 Test RE 1.3281785406197566\n",
      "5 Train Loss 44.631874 Test MSE 8.343618450131311 Test RE 1.3806553438115174\n",
      "6 Train Loss 43.957245 Test MSE 8.241622515321994 Test RE 1.3721905363258808\n",
      "7 Train Loss 43.766037 Test MSE 8.372656190841969 Test RE 1.3830557586364627\n",
      "8 Train Loss 42.9989 Test MSE 8.23386842450141 Test RE 1.371544874997095\n",
      "9 Train Loss 41.564224 Test MSE 8.480935001865832 Test RE 1.3919701675932719\n",
      "10 Train Loss 40.939957 Test MSE 8.667383338766465 Test RE 1.4071878047783655\n",
      "11 Train Loss 40.601143 Test MSE 8.523812973785615 Test RE 1.3954844976208451\n",
      "12 Train Loss 40.36609 Test MSE 8.794758540375199 Test RE 1.4174900546511644\n",
      "13 Train Loss 40.060165 Test MSE 8.601641604533732 Test RE 1.4018409166547758\n",
      "14 Train Loss 39.720215 Test MSE 8.570422182616428 Test RE 1.3992946325882702\n",
      "15 Train Loss 39.41946 Test MSE 8.423057115378421 Test RE 1.387212306902643\n",
      "16 Train Loss 39.22568 Test MSE 8.493652615150022 Test RE 1.3930134432926724\n",
      "17 Train Loss 38.773464 Test MSE 8.270505970639736 Test RE 1.3745929115781383\n",
      "18 Train Loss 38.44131 Test MSE 8.123850659806196 Test RE 1.362351034558155\n",
      "19 Train Loss 37.41549 Test MSE 8.164095903041288 Test RE 1.36572138284461\n",
      "20 Train Loss 36.209137 Test MSE 8.247498875269192 Test RE 1.3726796420006535\n",
      "21 Train Loss 35.675995 Test MSE 7.9491172541893516 Test RE 1.3476201990069796\n",
      "22 Train Loss 35.170464 Test MSE 8.003264413190706 Test RE 1.3522022149605233\n",
      "23 Train Loss 34.424206 Test MSE 7.5734606139757785 Test RE 1.3153921503925972\n",
      "24 Train Loss 33.17031 Test MSE 7.4103337872824975 Test RE 1.3011487401763075\n",
      "25 Train Loss 30.297253 Test MSE 5.650547237561136 Test RE 1.1361961549488948\n",
      "26 Train Loss 24.698792 Test MSE 3.8954738908421183 Test RE 0.9433833547845197\n",
      "27 Train Loss 21.419273 Test MSE 2.7041188066982325 Test RE 0.7859971016468144\n",
      "28 Train Loss 19.08102 Test MSE 2.537373283407798 Test RE 0.7613778561250618\n",
      "29 Train Loss 17.811907 Test MSE 2.390049281374011 Test RE 0.7389439338099043\n",
      "30 Train Loss 16.566536 Test MSE 1.8118659797169983 Test RE 0.643385243128625\n",
      "31 Train Loss 14.660656 Test MSE 1.8513718054588146 Test RE 0.6503615883789873\n",
      "32 Train Loss 11.196877 Test MSE 0.7651692323761147 Test RE 0.4181063944165346\n",
      "33 Train Loss 8.353515 Test MSE 0.7539607685959139 Test RE 0.41503281357665905\n",
      "34 Train Loss 6.990398 Test MSE 0.6926691949708831 Test RE 0.3978056958528156\n",
      "35 Train Loss 5.9264526 Test MSE 0.61755261460751 Test RE 0.37561682957833614\n",
      "36 Train Loss 5.073154 Test MSE 0.4057670463333093 Test RE 0.30447135999149866\n",
      "37 Train Loss 4.243566 Test MSE 0.2982475912143819 Test RE 0.26103367198311456\n",
      "38 Train Loss 3.5886598 Test MSE 0.2659115952226737 Test RE 0.24647716950058168\n",
      "39 Train Loss 2.8157132 Test MSE 0.1869074527529274 Test RE 0.2066433194940204\n",
      "40 Train Loss 2.4355772 Test MSE 0.18849901396419086 Test RE 0.2075212628764735\n",
      "41 Train Loss 2.2516072 Test MSE 0.15158778969401177 Test RE 0.18609734214500512\n",
      "42 Train Loss 2.042189 Test MSE 0.15581322553230695 Test RE 0.18867320171791607\n",
      "43 Train Loss 1.7860079 Test MSE 0.14187670407501182 Test RE 0.18003776200236318\n",
      "44 Train Loss 1.4912548 Test MSE 0.09552506708040176 Test RE 0.1477293326466498\n",
      "45 Train Loss 1.116126 Test MSE 0.07796774711990836 Test RE 0.1334644352214989\n",
      "46 Train Loss 0.9498606 Test MSE 0.07538054500658894 Test RE 0.13123138031278755\n",
      "47 Train Loss 0.8099174 Test MSE 0.051506343306841264 Test RE 0.10847718818176859\n",
      "48 Train Loss 0.7555297 Test MSE 0.049992318591853595 Test RE 0.10687095738336007\n",
      "49 Train Loss 0.6362176 Test MSE 0.04087034990817039 Test RE 0.0966300575587977\n",
      "50 Train Loss 0.5224144 Test MSE 0.0359922519335969 Test RE 0.09068022108994168\n",
      "51 Train Loss 0.4600522 Test MSE 0.030105358224804705 Test RE 0.08293349347550584\n",
      "52 Train Loss 0.43943644 Test MSE 0.0274812544377551 Test RE 0.07923669211931691\n",
      "53 Train Loss 0.42632288 Test MSE 0.02492113953890423 Test RE 0.07545569241343507\n",
      "54 Train Loss 0.39969313 Test MSE 0.025677748287237928 Test RE 0.07659255002722348\n",
      "55 Train Loss 0.3657217 Test MSE 0.024824409850201547 Test RE 0.07530911200008666\n",
      "56 Train Loss 0.35181177 Test MSE 0.024335445363689822 Test RE 0.07456374449876838\n",
      "57 Train Loss 0.28808314 Test MSE 0.017467300573339208 Test RE 0.06317146621988365\n",
      "58 Train Loss 0.2800275 Test MSE 0.01783482801554954 Test RE 0.0638325983633353\n",
      "59 Train Loss 0.2673015 Test MSE 0.015450990360464599 Test RE 0.059413648298001956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Train Loss 0.26427966 Test MSE 0.01548799264799635 Test RE 0.05948474814999858\n",
      "61 Train Loss 0.26043022 Test MSE 0.014087378607999555 Test RE 0.056731354614125123\n",
      "62 Train Loss 0.24468645 Test MSE 0.010932633829200808 Test RE 0.0499770320542995\n",
      "63 Train Loss 0.21521913 Test MSE 0.009580220368200106 Test RE 0.046783833980756126\n",
      "64 Train Loss 0.20916517 Test MSE 0.008915448593267468 Test RE 0.04513148880946979\n",
      "65 Train Loss 0.2076298 Test MSE 0.009286807630468432 Test RE 0.046061840277880094\n",
      "66 Train Loss 0.20386042 Test MSE 0.00923713466057991 Test RE 0.045938488086319375\n",
      "67 Train Loss 0.19874433 Test MSE 0.009227839227169252 Test RE 0.04591536805748584\n",
      "68 Train Loss 0.1881475 Test MSE 0.008039554411854711 Test RE 0.0428572252577176\n",
      "69 Train Loss 0.18517345 Test MSE 0.007233337929833079 Test RE 0.040651580739836185\n",
      "70 Train Loss 0.18062983 Test MSE 0.00714294303954837 Test RE 0.04039677112302816\n",
      "71 Train Loss 0.17277174 Test MSE 0.007345546111210684 Test RE 0.040965674031628485\n",
      "72 Train Loss 0.1702958 Test MSE 0.007015884879486652 Test RE 0.04003587156978319\n",
      "73 Train Loss 0.16882855 Test MSE 0.0070702126558197225 Test RE 0.04019058230637454\n",
      "74 Train Loss 0.16623919 Test MSE 0.007535077777439017 Test RE 0.04149081158978376\n",
      "75 Train Loss 0.16417374 Test MSE 0.007536170255188315 Test RE 0.04149381926581252\n",
      "76 Train Loss 0.16258532 Test MSE 0.007399819039972913 Test RE 0.04111673396551919\n",
      "77 Train Loss 0.16188362 Test MSE 0.007171370448377046 Test RE 0.04047707662291103\n",
      "78 Train Loss 0.15969682 Test MSE 0.007167127888980327 Test RE 0.04046510179824363\n",
      "79 Train Loss 0.15871443 Test MSE 0.007047365005069236 Test RE 0.040125591090281125\n",
      "80 Train Loss 0.15591307 Test MSE 0.006204828748981501 Test RE 0.03765069177283449\n",
      "81 Train Loss 0.15081726 Test MSE 0.005970611956942821 Test RE 0.036933246402080455\n",
      "82 Train Loss 0.14877747 Test MSE 0.006169432406700526 Test RE 0.037543146270123826\n",
      "83 Train Loss 0.14263245 Test MSE 0.006851173251481501 Test RE 0.03956312018071294\n",
      "84 Train Loss 0.1354143 Test MSE 0.006222053362387233 Test RE 0.037702914742068355\n",
      "85 Train Loss 0.13287488 Test MSE 0.005803635347148508 Test RE 0.03641313898926379\n",
      "86 Train Loss 0.13023028 Test MSE 0.00570562654418973 Test RE 0.03610436667851698\n",
      "87 Train Loss 0.12736279 Test MSE 0.005625953253221574 Test RE 0.03585140002710601\n",
      "88 Train Loss 0.1255818 Test MSE 0.005310252246889044 Test RE 0.034830975354772344\n",
      "89 Train Loss 0.1224294 Test MSE 0.005528158371808553 Test RE 0.035538434958431224\n",
      "90 Train Loss 0.12076227 Test MSE 0.005814691603221167 Test RE 0.03644780703840706\n",
      "91 Train Loss 0.11940993 Test MSE 0.006348798490619889 Test RE 0.03808498875712942\n",
      "92 Train Loss 0.11862399 Test MSE 0.006179387143369893 Test RE 0.03757342308265089\n",
      "93 Train Loss 0.1181623 Test MSE 0.006310085925352253 Test RE 0.037968697302351154\n",
      "94 Train Loss 0.11790878 Test MSE 0.006215208576569001 Test RE 0.037682170835319814\n",
      "95 Train Loss 0.115107566 Test MSE 0.0054617137377897815 Test RE 0.03532421563602923\n",
      "96 Train Loss 0.113513425 Test MSE 0.005452598636687753 Test RE 0.03529472688351144\n",
      "97 Train Loss 0.11038109 Test MSE 0.004672841649642554 Test RE 0.032673720704148757\n",
      "98 Train Loss 0.10866231 Test MSE 0.004385756367902571 Test RE 0.03165412489539471\n",
      "99 Train Loss 0.10751216 Test MSE 0.004242867412151728 Test RE 0.03113420570628422\n",
      "Training time: 79.23\n",
      "KG_stan_tune5\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.839127 Test MSE 8.649304838945863 Test RE 1.4057194767378403\n",
      "1 Train Loss 57.210594 Test MSE 8.612459245414238 Test RE 1.4027221348833077\n",
      "2 Train Loss 52.352295 Test MSE 8.30035530927403 Test RE 1.3770712203310977\n",
      "3 Train Loss 46.050117 Test MSE 8.598384946202716 Test RE 1.4015755167864044\n",
      "4 Train Loss 45.69748 Test MSE 8.738698503004317 Test RE 1.4129651104980276\n",
      "5 Train Loss 45.544933 Test MSE 8.658094556072443 Test RE 1.4064335652841802\n",
      "6 Train Loss 45.44251 Test MSE 8.571107918072052 Test RE 1.3993506115545913\n",
      "7 Train Loss 45.038918 Test MSE 8.598849887679522 Test RE 1.401613410052742\n",
      "8 Train Loss 42.44061 Test MSE 7.498565228673171 Test RE 1.3088719094089014\n",
      "9 Train Loss 40.462303 Test MSE 7.718870386111382 Test RE 1.3279598189875377\n",
      "10 Train Loss 39.58441 Test MSE 7.688478756288286 Test RE 1.3253429420343508\n",
      "11 Train Loss 38.601547 Test MSE 7.806993740986808 Test RE 1.3355187075586947\n",
      "12 Train Loss 37.332573 Test MSE 7.520273586552232 Test RE 1.310765133273866\n",
      "13 Train Loss 37.151573 Test MSE 7.668527614467088 Test RE 1.3236222322522562\n",
      "14 Train Loss 36.60919 Test MSE 7.701927227991734 Test RE 1.326501561976488\n",
      "15 Train Loss 36.233074 Test MSE 7.528481687972806 Test RE 1.311480264106267\n",
      "16 Train Loss 36.018387 Test MSE 7.501606043510488 Test RE 1.3091372690868521\n",
      "17 Train Loss 35.79135 Test MSE 7.511513574178147 Test RE 1.3100014865523215\n",
      "18 Train Loss 35.691483 Test MSE 7.439727100768623 Test RE 1.3037267092582903\n",
      "19 Train Loss 35.452877 Test MSE 7.58392272068096 Test RE 1.3163003893292664\n",
      "20 Train Loss 35.176796 Test MSE 7.454238863479982 Test RE 1.3049975996721066\n",
      "21 Train Loss 34.867203 Test MSE 7.2840803834940475 Test RE 1.290016975231151\n",
      "22 Train Loss 34.17473 Test MSE 7.429553736961198 Test RE 1.3028350217527285\n",
      "23 Train Loss 33.886665 Test MSE 7.5734214542744756 Test RE 1.3153887496731034\n",
      "24 Train Loss 33.43316 Test MSE 7.6100047028852496 Test RE 1.3185619007894904\n",
      "25 Train Loss 33.028065 Test MSE 7.5311292465811075 Test RE 1.3117108494878502\n",
      "26 Train Loss 32.6688 Test MSE 7.8106202308140125 Test RE 1.3358288578453823\n",
      "27 Train Loss 31.75491 Test MSE 7.865372615999748 Test RE 1.3405027559437823\n",
      "28 Train Loss 30.999008 Test MSE 7.787823784388737 Test RE 1.3338780266470531\n",
      "29 Train Loss 30.135147 Test MSE 8.425609860895056 Test RE 1.3874224996915876\n",
      "30 Train Loss 29.200226 Test MSE 8.87244622319552 Test RE 1.4237369230787495\n",
      "31 Train Loss 28.001904 Test MSE 8.81541311434391 Test RE 1.4191535729554614\n",
      "32 Train Loss 27.39264 Test MSE 8.945096899402138 Test RE 1.4295540657662145\n",
      "33 Train Loss 26.425291 Test MSE 9.016802591531931 Test RE 1.4352724249217022\n",
      "34 Train Loss 25.844364 Test MSE 8.984398677576419 Test RE 1.4326911161049776\n",
      "35 Train Loss 25.09177 Test MSE 8.999708146816012 Test RE 1.4339112536737098\n",
      "36 Train Loss 24.600574 Test MSE 9.12066515752692 Test RE 1.4435150503389305\n",
      "37 Train Loss 23.958908 Test MSE 9.017567870000596 Test RE 1.4353333312001564\n",
      "38 Train Loss 23.549706 Test MSE 9.016479732593952 Test RE 1.435246728746463\n",
      "39 Train Loss 23.21014 Test MSE 9.01163973235161 Test RE 1.4348614604823844\n",
      "40 Train Loss 22.564611 Test MSE 9.076989519540176 Test RE 1.440054661337193\n",
      "41 Train Loss 22.241701 Test MSE 8.802904733059007 Test RE 1.418146381621105\n",
      "42 Train Loss 21.865988 Test MSE 8.650028649539651 Test RE 1.4057782937978434\n",
      "43 Train Loss 21.377214 Test MSE 8.711146358810982 Test RE 1.410735891090646\n",
      "44 Train Loss 20.59302 Test MSE 8.599073469476439 Test RE 1.4016316318621622\n",
      "45 Train Loss 20.274452 Test MSE 8.316183074424053 Test RE 1.3783835484420193\n",
      "46 Train Loss 19.06564 Test MSE 8.200336807422753 Test RE 1.3687492852864585\n",
      "47 Train Loss 18.50211 Test MSE 8.158096474894947 Test RE 1.3652194869076553\n",
      "48 Train Loss 18.189198 Test MSE 8.02314128049052 Test RE 1.3538803349788364\n",
      "49 Train Loss 17.848993 Test MSE 7.982934559824757 Test RE 1.350483694174726\n",
      "50 Train Loss 17.571642 Test MSE 7.9731916708104436 Test RE 1.3496593338031608\n",
      "51 Train Loss 17.41701 Test MSE 8.018744897009483 Test RE 1.3535093460763374\n",
      "52 Train Loss 17.253075 Test MSE 7.989658302588706 Test RE 1.3510523067380977\n",
      "53 Train Loss 16.878405 Test MSE 7.828302716795807 Test RE 1.3373400964334394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 16.698837 Test MSE 7.721419884738849 Test RE 1.328179109638175\n",
      "55 Train Loss 16.441166 Test MSE 7.617787397630581 Test RE 1.319235970176395\n",
      "56 Train Loss 16.183832 Test MSE 7.724361654678371 Test RE 1.3284320958349622\n",
      "57 Train Loss 15.963238 Test MSE 7.810637063262599 Test RE 1.3358302972482585\n",
      "58 Train Loss 15.800678 Test MSE 7.892892747913214 Test RE 1.3428458489866348\n",
      "59 Train Loss 15.628191 Test MSE 7.950092636663657 Test RE 1.3477028751559719\n",
      "60 Train Loss 15.468547 Test MSE 7.9487504549372625 Test RE 1.34758910676317\n",
      "61 Train Loss 15.247798 Test MSE 8.014193119145903 Test RE 1.3531251370448767\n",
      "62 Train Loss 15.136528 Test MSE 8.116072512604907 Test RE 1.3616986896939265\n",
      "63 Train Loss 14.928317 Test MSE 8.19445003523676 Test RE 1.368257905359513\n",
      "64 Train Loss 14.813786 Test MSE 8.218432082556976 Test RE 1.3702586285623897\n",
      "65 Train Loss 14.621865 Test MSE 8.239720236488921 Test RE 1.3720321670456022\n",
      "66 Train Loss 14.457804 Test MSE 8.18921807056939 Test RE 1.3678210352820346\n",
      "67 Train Loss 14.317116 Test MSE 8.158389830160774 Test RE 1.365244032506403\n",
      "68 Train Loss 14.090253 Test MSE 8.106638368407733 Test RE 1.3609070384898907\n",
      "69 Train Loss 13.851777 Test MSE 8.199876645797806 Test RE 1.3687108810875674\n",
      "70 Train Loss 13.662144 Test MSE 8.099905749352661 Test RE 1.3603417997678233\n",
      "71 Train Loss 13.332659 Test MSE 7.978127589167613 Test RE 1.3500770321260993\n",
      "72 Train Loss 12.038366 Test MSE 7.39792061365128 Test RE 1.3000584954430476\n",
      "73 Train Loss 10.810616 Test MSE 7.248726525639062 Test RE 1.2868825678345126\n",
      "74 Train Loss 10.069247 Test MSE 7.19897090672092 Test RE 1.2824583498158546\n",
      "75 Train Loss 9.756775 Test MSE 7.350268625140893 Test RE 1.2958647187013528\n",
      "76 Train Loss 9.5084 Test MSE 7.25521472994831 Test RE 1.287458371697705\n",
      "77 Train Loss 9.319588 Test MSE 7.243388855480234 Test RE 1.2864086763428764\n",
      "78 Train Loss 9.16202 Test MSE 7.218897481165164 Test RE 1.284232029876384\n",
      "79 Train Loss 9.027005 Test MSE 7.329386874091062 Test RE 1.2940226655630314\n",
      "80 Train Loss 8.896389 Test MSE 7.390727050301325 Test RE 1.299426268620874\n",
      "81 Train Loss 8.785179 Test MSE 7.384558215941409 Test RE 1.298883857926392\n",
      "82 Train Loss 8.704533 Test MSE 7.345803981192889 Test RE 1.2954710968017205\n",
      "83 Train Loss 8.654125 Test MSE 7.3219575543233555 Test RE 1.2933666662436816\n",
      "84 Train Loss 8.606136 Test MSE 7.37266576691192 Test RE 1.2978375438647398\n",
      "85 Train Loss 8.52981 Test MSE 7.400470621699022 Test RE 1.3002825363709352\n",
      "86 Train Loss 8.4738 Test MSE 7.329513395580673 Test RE 1.2940338343668822\n",
      "87 Train Loss 8.41269 Test MSE 7.3520218216769715 Test RE 1.2960192552355625\n",
      "88 Train Loss 8.309692 Test MSE 7.3193912177040525 Test RE 1.2931399847101444\n",
      "89 Train Loss 8.246266 Test MSE 7.387163827683899 Test RE 1.2991129906953538\n",
      "90 Train Loss 8.173205 Test MSE 7.495979681647521 Test RE 1.308646236794351\n",
      "91 Train Loss 8.023496 Test MSE 7.611696675351728 Test RE 1.3187084740523534\n",
      "92 Train Loss 7.2382393 Test MSE 6.901599810533228 Test RE 1.255691477991221\n",
      "93 Train Loss 6.1136465 Test MSE 6.7495659637098635 Test RE 1.2417837813157542\n",
      "94 Train Loss 5.632611 Test MSE 6.634138930653495 Test RE 1.2311198716592457\n",
      "95 Train Loss 5.0235868 Test MSE 6.658179435943456 Test RE 1.233348493920449\n",
      "96 Train Loss 4.8128376 Test MSE 6.746234273842921 Test RE 1.2414772616713343\n",
      "97 Train Loss 4.695876 Test MSE 6.851192312603099 Test RE 1.2510974515188729\n",
      "98 Train Loss 4.497131 Test MSE 6.7838458725106925 Test RE 1.2449331928925822\n",
      "99 Train Loss 4.403736 Test MSE 6.719400751562804 Test RE 1.2390057791569977\n",
      "Training time: 76.95\n",
      "KG_stan_tune5\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.019417 Test MSE 8.441796334336145 Test RE 1.3887545517550854\n",
      "1 Train Loss 58.818794 Test MSE 8.463798542582024 Test RE 1.3905631587099825\n",
      "2 Train Loss 57.989647 Test MSE 8.766527139860349 Test RE 1.4152131362225835\n",
      "3 Train Loss 55.608887 Test MSE 8.875067396005912 Test RE 1.4239472137265792\n",
      "4 Train Loss 53.17903 Test MSE 8.914100846195216 Test RE 1.4270751107233473\n",
      "5 Train Loss 48.312973 Test MSE 8.697706338910919 Test RE 1.4096471918217601\n",
      "6 Train Loss 46.1494 Test MSE 8.588346527240533 Test RE 1.400757124075636\n",
      "7 Train Loss 45.986694 Test MSE 8.505242831968518 Test RE 1.3939635541843916\n",
      "8 Train Loss 45.74749 Test MSE 8.503263645150636 Test RE 1.3938013557107303\n",
      "9 Train Loss 45.55104 Test MSE 8.395203579080812 Test RE 1.3849167766929409\n",
      "10 Train Loss 45.17964 Test MSE 8.445127460126194 Test RE 1.3890285254240073\n",
      "11 Train Loss 44.5224 Test MSE 8.28530690331433 Test RE 1.3758223504333655\n",
      "12 Train Loss 44.276207 Test MSE 8.351328239006358 Test RE 1.3812930829066334\n",
      "13 Train Loss 44.03103 Test MSE 8.142681500951008 Test RE 1.3639290649632545\n",
      "14 Train Loss 43.37079 Test MSE 8.09346611852439 Test RE 1.359800939103534\n",
      "15 Train Loss 42.322853 Test MSE 7.66482729910251 Test RE 1.3233028482119746\n",
      "16 Train Loss 40.38761 Test MSE 7.666355438860816 Test RE 1.3234347553531582\n",
      "17 Train Loss 39.80442 Test MSE 7.735327680402474 Test RE 1.3293747273790864\n",
      "18 Train Loss 39.609497 Test MSE 7.745202685966654 Test RE 1.3302230040351954\n",
      "19 Train Loss 39.35253 Test MSE 7.83805381267459 Test RE 1.3381727464734736\n",
      "20 Train Loss 39.222694 Test MSE 7.802698653224159 Test RE 1.3351512832071173\n",
      "21 Train Loss 39.03804 Test MSE 7.802286065386666 Test RE 1.3351159829547645\n",
      "22 Train Loss 38.72972 Test MSE 7.836423862536556 Test RE 1.3380336004359872\n",
      "23 Train Loss 38.312183 Test MSE 7.883539500665081 Test RE 1.342049962560228\n",
      "24 Train Loss 38.028866 Test MSE 7.811989207554588 Test RE 1.3359459188762823\n",
      "25 Train Loss 37.68597 Test MSE 7.897402877759176 Test RE 1.3432294563913838\n",
      "26 Train Loss 37.248016 Test MSE 7.75017410626618 Test RE 1.3306498512763154\n",
      "27 Train Loss 36.904438 Test MSE 7.729713974626989 Test RE 1.3288922608727176\n",
      "28 Train Loss 36.430458 Test MSE 7.598683408179218 Test RE 1.3175807329346434\n",
      "29 Train Loss 35.724007 Test MSE 7.400844128885883 Test RE 1.300315349064161\n",
      "30 Train Loss 34.909966 Test MSE 7.333899093312748 Test RE 1.2944209264041684\n",
      "31 Train Loss 34.302517 Test MSE 7.380117135517198 Test RE 1.2984932241840315\n",
      "32 Train Loss 33.80184 Test MSE 7.333774699750089 Test RE 1.2944099487297183\n",
      "33 Train Loss 33.32261 Test MSE 7.20874596743634 Test RE 1.2833287419713344\n",
      "34 Train Loss 32.55794 Test MSE 7.004206552611535 Test RE 1.2649912826785272\n",
      "35 Train Loss 31.340805 Test MSE 6.7434088737540865 Test RE 1.2412172620061122\n",
      "36 Train Loss 30.634544 Test MSE 6.893747049290498 Test RE 1.2549769007813985\n",
      "37 Train Loss 30.232677 Test MSE 6.920111407555114 Test RE 1.257374369580674\n",
      "38 Train Loss 30.057413 Test MSE 6.9599058771827025 Test RE 1.2609844861563015\n",
      "39 Train Loss 29.693314 Test MSE 7.085457955601501 Test RE 1.2723073115471475\n",
      "40 Train Loss 29.490343 Test MSE 7.009981196208259 Test RE 1.2655126385768338\n",
      "41 Train Loss 29.198544 Test MSE 6.7199834156749505 Test RE 1.2390594973812448\n",
      "42 Train Loss 28.733736 Test MSE 6.078864893025724 Test RE 1.1784721016209814\n",
      "43 Train Loss 28.10257 Test MSE 5.756602050958046 Test RE 1.1468091894626782\n",
      "44 Train Loss 27.637224 Test MSE 5.637503451257667 Test RE 1.1348839933172044\n",
      "45 Train Loss 27.387703 Test MSE 5.625577022546357 Test RE 1.1336829049898767\n",
      "46 Train Loss 27.07446 Test MSE 5.575014761810279 Test RE 1.1285766773988484\n",
      "47 Train Loss 26.682861 Test MSE 5.116803107438501 Test RE 1.0812034260310592\n",
      "48 Train Loss 26.363308 Test MSE 4.91306323825456 Test RE 1.0594592018776081\n",
      "49 Train Loss 26.180222 Test MSE 4.930728393471005 Test RE 1.0613621611299142\n",
      "50 Train Loss 25.9929 Test MSE 4.820806198710114 Test RE 1.0494648486326132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 Train Loss 25.769201 Test MSE 4.665240946691115 Test RE 1.0323931151812984\n",
      "52 Train Loss 25.48106 Test MSE 4.482763298313902 Test RE 1.0120010522478833\n",
      "53 Train Loss 25.215712 Test MSE 4.203298248824187 Test RE 0.9799482997051643\n",
      "54 Train Loss 22.91946 Test MSE 4.364052788975785 Test RE 0.9985114698093783\n",
      "55 Train Loss 19.566957 Test MSE 4.204421513446443 Test RE 0.9800792287592627\n",
      "56 Train Loss 17.599787 Test MSE 3.796294280348479 Test RE 0.9312965531649807\n",
      "57 Train Loss 16.232613 Test MSE 3.342409718852272 Test RE 0.8738520371364512\n",
      "58 Train Loss 15.413118 Test MSE 3.243891731517641 Test RE 0.8608772590544704\n",
      "59 Train Loss 14.92799 Test MSE 3.094276281737157 Test RE 0.8407901291950458\n",
      "60 Train Loss 14.523161 Test MSE 2.9952620176439897 Test RE 0.8272284646700228\n",
      "61 Train Loss 13.833624 Test MSE 3.0034008747152248 Test RE 0.8283515929322491\n",
      "62 Train Loss 13.063617 Test MSE 2.8582605623558623 Test RE 0.8080885790592915\n",
      "63 Train Loss 12.829388 Test MSE 2.8302419850150864 Test RE 0.8041181130632113\n",
      "64 Train Loss 12.522166 Test MSE 2.806297062153336 Test RE 0.8007093153919246\n",
      "65 Train Loss 12.346312 Test MSE 2.7812860168788935 Test RE 0.7971331796457577\n",
      "66 Train Loss 11.915348 Test MSE 2.6127083265749054 Test RE 0.772597902847122\n",
      "67 Train Loss 11.491362 Test MSE 2.481949878149101 Test RE 0.753016623463068\n",
      "68 Train Loss 11.190765 Test MSE 2.3830040570462017 Test RE 0.7378540257530186\n",
      "69 Train Loss 11.04755 Test MSE 2.3140252873974627 Test RE 0.7270965945255283\n",
      "70 Train Loss 10.9224825 Test MSE 2.203356286904662 Test RE 0.7094967735187084\n",
      "71 Train Loss 10.7623005 Test MSE 2.1289144813677403 Test RE 0.6974083909813706\n",
      "72 Train Loss 10.49863 Test MSE 2.0343622878358025 Test RE 0.6817453878259938\n",
      "73 Train Loss 10.258948 Test MSE 2.037196792675818 Test RE 0.6822201650984548\n",
      "74 Train Loss 9.868525 Test MSE 1.930358485842525 Test RE 0.6640901593831482\n",
      "75 Train Loss 9.645619 Test MSE 1.7562373191889333 Test RE 0.6334315063435968\n",
      "76 Train Loss 9.384786 Test MSE 1.698705389764038 Test RE 0.6229699419829469\n",
      "77 Train Loss 8.983819 Test MSE 1.6407107957208706 Test RE 0.6122433521022347\n",
      "78 Train Loss 7.9599767 Test MSE 0.9953615870209153 Test RE 0.47686834940964246\n",
      "79 Train Loss 5.931158 Test MSE 0.7256256659314448 Test RE 0.40715931787172727\n",
      "80 Train Loss 4.474066 Test MSE 0.5375289710267298 Test RE 0.350436229084712\n",
      "81 Train Loss 3.5830326 Test MSE 0.36260049553260815 Test RE 0.2878208536407839\n",
      "82 Train Loss 2.6741617 Test MSE 0.26411744959697586 Test RE 0.24564425285658356\n",
      "83 Train Loss 2.0284038 Test MSE 0.15081674060825195 Test RE 0.1856234480519122\n",
      "84 Train Loss 1.531003 Test MSE 0.12473178172508625 Test RE 0.16880939884999266\n",
      "85 Train Loss 1.1370928 Test MSE 0.13521015345498036 Test RE 0.17575703323751637\n",
      "86 Train Loss 1.0292548 Test MSE 0.12631604783723402 Test RE 0.16987807254988535\n",
      "87 Train Loss 0.9247912 Test MSE 0.09842520309316377 Test RE 0.149955092852024\n",
      "88 Train Loss 0.83724654 Test MSE 0.08336798113695053 Test RE 0.13800909328707872\n",
      "89 Train Loss 0.7451363 Test MSE 0.08222484787504225 Test RE 0.1370596440533423\n",
      "90 Train Loss 0.640685 Test MSE 0.09367651368051412 Test RE 0.14629295755552044\n",
      "91 Train Loss 0.5416896 Test MSE 0.07315352418350388 Test RE 0.12927831617554292\n",
      "92 Train Loss 0.4874898 Test MSE 0.05717613351627422 Test RE 0.11429189983506621\n",
      "93 Train Loss 0.44902176 Test MSE 0.05634321133822849 Test RE 0.11345636324547591\n",
      "94 Train Loss 0.42199734 Test MSE 0.05531759823998684 Test RE 0.1124190000992265\n",
      "95 Train Loss 0.39064345 Test MSE 0.042332570226083326 Test RE 0.09834343624742409\n",
      "96 Train Loss 0.36712766 Test MSE 0.04255846258357505 Test RE 0.09860547412676193\n",
      "97 Train Loss 0.3352764 Test MSE 0.03706864799943272 Test RE 0.09202618817585162\n",
      "98 Train Loss 0.3192993 Test MSE 0.03350484164100345 Test RE 0.08749069069529242\n",
      "99 Train Loss 0.29922447 Test MSE 0.033018044836126845 Test RE 0.08685278255245715\n",
      "Training time: 78.53\n",
      "KG_stan_tune5\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.673553 Test MSE 8.572447214376966 Test RE 1.3994599365050444\n",
      "1 Train Loss 55.463703 Test MSE 8.494159046956396 Test RE 1.3930549717039962\n",
      "2 Train Loss 54.498272 Test MSE 8.207403072901757 Test RE 1.3693388868698466\n",
      "3 Train Loss 48.334076 Test MSE 8.079818641353596 Test RE 1.3586539841509686\n",
      "4 Train Loss 46.867645 Test MSE 8.107177246123502 Test RE 1.3609522699567473\n",
      "5 Train Loss 44.63146 Test MSE 8.193822676049582 Test RE 1.3682055281045624\n",
      "6 Train Loss 43.969086 Test MSE 8.124776939987603 Test RE 1.3624286998702944\n",
      "7 Train Loss 43.63414 Test MSE 8.035270505827942 Test RE 1.3549033331627314\n",
      "8 Train Loss 43.42265 Test MSE 7.983556759268837 Test RE 1.3505363223044682\n",
      "9 Train Loss 43.346085 Test MSE 8.035602209072351 Test RE 1.3549312986925206\n",
      "10 Train Loss 43.294945 Test MSE 8.031331686896955 Test RE 1.35457121160827\n",
      "11 Train Loss 43.141335 Test MSE 8.059265719881624 Test RE 1.3569248556568958\n",
      "12 Train Loss 43.071327 Test MSE 8.058350842390563 Test RE 1.3568478352878097\n",
      "13 Train Loss 42.9926 Test MSE 8.030056032108837 Test RE 1.3544636308271498\n",
      "14 Train Loss 42.927116 Test MSE 8.059655998455304 Test RE 1.3569577105288195\n",
      "15 Train Loss 42.907265 Test MSE 8.005192337440226 Test RE 1.3523650726599998\n",
      "16 Train Loss 42.756653 Test MSE 8.047205421120875 Test RE 1.3559091895506095\n",
      "17 Train Loss 42.497086 Test MSE 8.036622494276518 Test RE 1.3550173141797228\n",
      "18 Train Loss 42.010513 Test MSE 7.994569422716137 Test RE 1.351467478489068\n",
      "19 Train Loss 41.52285 Test MSE 8.161395246334573 Test RE 1.3654954760369553\n",
      "20 Train Loss 41.090454 Test MSE 8.142774872457553 Test RE 1.363936884976018\n",
      "21 Train Loss 40.310352 Test MSE 7.925281123971997 Test RE 1.3455982029858051\n",
      "22 Train Loss 39.563957 Test MSE 7.76759632729162 Test RE 1.3321446474882084\n",
      "23 Train Loss 39.349464 Test MSE 7.632216658158501 Test RE 1.3204847969654119\n",
      "24 Train Loss 39.07 Test MSE 7.706402084182859 Test RE 1.3268868578644388\n",
      "25 Train Loss 38.979504 Test MSE 7.768000772472511 Test RE 1.332179328259909\n",
      "26 Train Loss 38.819237 Test MSE 7.718398372723665 Test RE 1.327919215611372\n",
      "27 Train Loss 38.26037 Test MSE 7.552717654162538 Test RE 1.3135895507389543\n",
      "28 Train Loss 37.627518 Test MSE 7.453962715337812 Test RE 1.3049734271169393\n",
      "29 Train Loss 37.353878 Test MSE 7.2797453945695345 Test RE 1.2896330529459155\n",
      "30 Train Loss 36.869858 Test MSE 7.11688305743704 Test RE 1.2751256299326683\n",
      "31 Train Loss 35.698174 Test MSE 6.249161084052387 Test RE 1.194865220415955\n",
      "32 Train Loss 31.660948 Test MSE 4.5384661721507324 Test RE 1.0182692092970895\n",
      "33 Train Loss 30.560919 Test MSE 4.786855713348877 Test RE 1.0457628958795517\n",
      "34 Train Loss 29.736721 Test MSE 4.488611152750218 Test RE 1.012660924926675\n",
      "35 Train Loss 28.502823 Test MSE 4.658920151775892 Test RE 1.0316934989082633\n",
      "36 Train Loss 26.59197 Test MSE 3.8975667385637407 Test RE 0.9436367376398193\n",
      "37 Train Loss 25.326551 Test MSE 2.9494266616511795 Test RE 0.8208746822206473\n",
      "38 Train Loss 23.450428 Test MSE 3.115255759330324 Test RE 0.8436356313289429\n",
      "39 Train Loss 21.346807 Test MSE 2.9433458462825035 Test RE 0.8200280494012258\n",
      "40 Train Loss 20.06529 Test MSE 3.1571095472193615 Test RE 0.8492838899860857\n",
      "41 Train Loss 19.682476 Test MSE 3.2676030523032753 Test RE 0.8640178341312288\n",
      "42 Train Loss 19.605549 Test MSE 3.3098284826975597 Test RE 0.8695825272212849\n",
      "43 Train Loss 19.376387 Test MSE 3.3154405469529884 Test RE 0.8703194364189311\n",
      "44 Train Loss 18.888655 Test MSE 3.331319240901502 Test RE 0.8724010645985358\n",
      "45 Train Loss 18.738136 Test MSE 3.3048629515416437 Test RE 0.8689299919230962\n",
      "46 Train Loss 18.006626 Test MSE 3.1977739387555433 Test RE 0.854735888985366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Train Loss 17.596333 Test MSE 3.317385604029985 Test RE 0.8705746925074735\n",
      "48 Train Loss 17.463179 Test MSE 3.4155756756565063 Test RE 0.8833646507734747\n",
      "49 Train Loss 17.26683 Test MSE 3.3956691268290142 Test RE 0.8807866902963474\n",
      "50 Train Loss 16.792461 Test MSE 3.3659750764023584 Test RE 0.8769271338769794\n",
      "51 Train Loss 16.22257 Test MSE 3.426202973621529 Test RE 0.8847378436475801\n",
      "52 Train Loss 16.01801 Test MSE 3.425442423066014 Test RE 0.8846396408834986\n",
      "53 Train Loss 15.688642 Test MSE 3.2834330941272967 Test RE 0.8661081910386942\n",
      "54 Train Loss 15.511537 Test MSE 3.266298863050134 Test RE 0.8638453904138308\n",
      "55 Train Loss 15.474048 Test MSE 3.245083702160618 Test RE 0.8610354095505726\n",
      "56 Train Loss 15.309767 Test MSE 3.2428833515238074 Test RE 0.8607434446503289\n",
      "57 Train Loss 14.920153 Test MSE 3.293519442517479 Test RE 0.8674374659292974\n",
      "58 Train Loss 14.809803 Test MSE 3.251600140529611 Test RE 0.8618994966930384\n",
      "59 Train Loss 14.589565 Test MSE 3.140680748880963 Test RE 0.8470712786510993\n",
      "60 Train Loss 14.524969 Test MSE 3.169590973812635 Test RE 0.8509610282286288\n",
      "61 Train Loss 14.475334 Test MSE 3.1327673411376415 Test RE 0.8460034451593116\n",
      "62 Train Loss 14.448611 Test MSE 3.1511633583498235 Test RE 0.8484837304716394\n",
      "63 Train Loss 14.401485 Test MSE 3.2032720520213522 Test RE 0.8554703712461176\n",
      "64 Train Loss 14.297104 Test MSE 3.279385476940715 Test RE 0.865574183589617\n",
      "65 Train Loss 13.885103 Test MSE 3.2093354634996274 Test RE 0.8562796400935746\n",
      "66 Train Loss 13.414631 Test MSE 3.034485581730751 Test RE 0.8326272100661667\n",
      "67 Train Loss 13.161545 Test MSE 2.8554032670781413 Test RE 0.8076845702292491\n",
      "68 Train Loss 13.026283 Test MSE 2.6602817721677576 Test RE 0.77960008832848\n",
      "69 Train Loss 12.492369 Test MSE 2.5282065744022297 Test RE 0.7600013057721976\n",
      "70 Train Loss 11.744277 Test MSE 2.5798477357413705 Test RE 0.7677239647690922\n",
      "71 Train Loss 11.137763 Test MSE 2.3319905196121944 Test RE 0.7299135914173792\n",
      "72 Train Loss 10.855109 Test MSE 2.386174765880217 Test RE 0.7383447388458457\n",
      "73 Train Loss 10.603977 Test MSE 2.444098974196716 Test RE 0.7472526341598559\n",
      "74 Train Loss 10.462776 Test MSE 2.4343558110422383 Test RE 0.7457617218107279\n",
      "75 Train Loss 10.253844 Test MSE 2.463034342070628 Test RE 0.7501416750536536\n",
      "76 Train Loss 9.720859 Test MSE 2.3327245717830483 Test RE 0.7300284616312077\n",
      "77 Train Loss 9.434519 Test MSE 2.314398853941409 Test RE 0.727155281870485\n",
      "78 Train Loss 9.314999 Test MSE 2.3085830899115227 Test RE 0.7262410869017834\n",
      "79 Train Loss 9.167803 Test MSE 2.253178392246775 Test RE 0.7174734738747197\n",
      "80 Train Loss 8.871916 Test MSE 2.237222308673133 Test RE 0.7149285341443956\n",
      "81 Train Loss 8.774844 Test MSE 2.2662543917953157 Test RE 0.7195523396429693\n",
      "82 Train Loss 8.519532 Test MSE 2.0973344358799446 Test RE 0.6922164313310949\n",
      "83 Train Loss 8.25243 Test MSE 2.1687106172247392 Test RE 0.703896592925184\n",
      "84 Train Loss 8.118446 Test MSE 2.1614066886121175 Test RE 0.7027102782418695\n",
      "85 Train Loss 7.9895654 Test MSE 2.174672851235825 Test RE 0.7048635074748542\n",
      "86 Train Loss 7.892384 Test MSE 2.1643642439952915 Test RE 0.703190889804348\n",
      "87 Train Loss 7.787327 Test MSE 2.182620412311078 Test RE 0.7061503301996086\n",
      "88 Train Loss 7.629878 Test MSE 2.088635133651764 Test RE 0.6907793555090431\n",
      "89 Train Loss 7.550727 Test MSE 2.0736141363317886 Test RE 0.6882909079371119\n",
      "90 Train Loss 7.4649916 Test MSE 2.0834904660778757 Test RE 0.6899280767919468\n",
      "91 Train Loss 7.347913 Test MSE 2.1035989157523933 Test RE 0.6932494431862499\n",
      "92 Train Loss 7.2715235 Test MSE 2.142666606185832 Test RE 0.6996572855889679\n",
      "93 Train Loss 7.1896443 Test MSE 2.2163010203315703 Test RE 0.7115778706061541\n",
      "94 Train Loss 7.153635 Test MSE 2.184250019160245 Test RE 0.706413897032636\n",
      "95 Train Loss 7.056694 Test MSE 2.201549775584976 Test RE 0.7092058589752109\n",
      "96 Train Loss 6.9846296 Test MSE 2.190460991864165 Test RE 0.7074175373702425\n",
      "97 Train Loss 6.9561777 Test MSE 2.208487585235983 Test RE 0.7103224507969053\n",
      "98 Train Loss 6.909189 Test MSE 2.2291790447426463 Test RE 0.7136422210665718\n",
      "99 Train Loss 6.8610077 Test MSE 2.211679515788572 Test RE 0.7108355805302335\n",
      "Training time: 78.09\n",
      "KG_stan_tune5\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.96389 Test MSE 8.526827932817891 Test RE 1.3957312743055013\n",
      "1 Train Loss 56.345448 Test MSE 8.443857994500243 Test RE 1.388924122604441\n",
      "2 Train Loss 48.75355 Test MSE 8.325547595019584 Test RE 1.3791594013356685\n",
      "3 Train Loss 44.004234 Test MSE 8.148190178077277 Test RE 1.3643903487875157\n",
      "4 Train Loss 42.84635 Test MSE 8.069220806653409 Test RE 1.3577626575263253\n",
      "5 Train Loss 42.383087 Test MSE 8.182227388944696 Test RE 1.367237094128928\n",
      "6 Train Loss 41.398945 Test MSE 8.310908960314217 Test RE 1.3779463944592754\n",
      "7 Train Loss 41.330154 Test MSE 8.292775292088072 Test RE 1.37644229498367\n",
      "8 Train Loss 41.01561 Test MSE 8.293158911769373 Test RE 1.376474131385205\n",
      "9 Train Loss 39.741436 Test MSE 8.310660894284343 Test RE 1.3779258296664338\n",
      "10 Train Loss 39.081566 Test MSE 8.116626730863485 Test RE 1.3617451817251518\n",
      "11 Train Loss 38.774193 Test MSE 7.87545405585471 Test RE 1.341361575410255\n",
      "12 Train Loss 38.31182 Test MSE 7.73694712551386 Test RE 1.32951387705869\n",
      "13 Train Loss 37.12784 Test MSE 6.89657838169915 Test RE 1.2552345902484665\n",
      "14 Train Loss 29.23315 Test MSE 6.718395061659547 Test RE 1.238913054948702\n",
      "15 Train Loss 25.358818 Test MSE 5.982832428556636 Test RE 1.1691264332738682\n",
      "16 Train Loss 21.859919 Test MSE 5.5922072619296666 Test RE 1.130315517517755\n",
      "17 Train Loss 19.921225 Test MSE 4.083334248105633 Test RE 0.9658629919000626\n",
      "18 Train Loss 16.892525 Test MSE 4.0614067124929045 Test RE 0.9632661551848195\n",
      "19 Train Loss 16.110756 Test MSE 4.143483866126867 Test RE 0.9729508153365821\n",
      "20 Train Loss 14.3560505 Test MSE 4.336557473423281 Test RE 0.9953609845260162\n",
      "21 Train Loss 13.244446 Test MSE 4.127263026763956 Test RE 0.9710445022490349\n",
      "22 Train Loss 12.40556 Test MSE 4.280244113120581 Test RE 0.9888771223042285\n",
      "23 Train Loss 12.105326 Test MSE 4.160387815080003 Test RE 0.974933442925518\n",
      "24 Train Loss 11.841089 Test MSE 4.212158838782246 Test RE 0.9809806258034603\n",
      "25 Train Loss 11.682163 Test MSE 4.205721773068505 Test RE 0.9802307667213545\n",
      "26 Train Loss 11.556625 Test MSE 4.195003959313389 Test RE 0.9789809654740372\n",
      "27 Train Loss 11.39742 Test MSE 4.2601415830750815 Test RE 0.9865522166116953\n",
      "28 Train Loss 11.242357 Test MSE 4.295754745042638 Test RE 0.9906672350080789\n",
      "29 Train Loss 11.208372 Test MSE 4.324775668972386 Test RE 0.994007938402077\n",
      "30 Train Loss 11.17089 Test MSE 4.34383204921954 Test RE 0.9961954937989058\n",
      "31 Train Loss 11.081778 Test MSE 4.36060525488474 Test RE 0.9981169875896669\n",
      "32 Train Loss 11.020348 Test MSE 4.315135130695194 Test RE 0.9928994279715269\n",
      "33 Train Loss 10.9981365 Test MSE 4.296083575633511 Test RE 0.9907051509830044\n",
      "34 Train Loss 10.909683 Test MSE 4.25025023847294 Test RE 0.9854062454457617\n",
      "35 Train Loss 10.893022 Test MSE 4.272326469381368 Test RE 0.9879620809290373\n",
      "36 Train Loss 10.819039 Test MSE 4.304154180192146 Test RE 0.9916352816205857\n",
      "37 Train Loss 10.695116 Test MSE 4.273845972227873 Test RE 0.9881377554412583\n",
      "38 Train Loss 10.596428 Test MSE 4.260613569034204 Test RE 0.9866068657223707\n",
      "39 Train Loss 10.530956 Test MSE 4.204280391791031 Test RE 0.9800627804127572\n",
      "40 Train Loss 10.4764185 Test MSE 4.264107971032419 Test RE 0.9870113725307608\n",
      "41 Train Loss 10.404968 Test MSE 4.259215636632853 Test RE 0.986444996682512\n",
      "42 Train Loss 10.2044735 Test MSE 4.293023295907839 Test RE 0.9903522277969995\n",
      "43 Train Loss 10.17316 Test MSE 4.320263839491046 Test RE 0.9934893028742056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 10.071694 Test MSE 4.284536960461245 Test RE 0.9893728924690173\n",
      "45 Train Loss 10.00518 Test MSE 4.329679962233716 Test RE 0.9945713809427766\n",
      "46 Train Loss 9.916136 Test MSE 4.353509046841981 Test RE 0.9973045166956308\n",
      "47 Train Loss 9.7827635 Test MSE 4.317104274126024 Test RE 0.9931259490799064\n",
      "48 Train Loss 9.672048 Test MSE 4.232036415922383 Test RE 0.9832925717569274\n",
      "49 Train Loss 9.569072 Test MSE 4.222658641517864 Test RE 0.9822025279893816\n",
      "50 Train Loss 9.500463 Test MSE 4.264318287743639 Test RE 0.9870357131932894\n",
      "51 Train Loss 9.418791 Test MSE 4.257904330049625 Test RE 0.9862931340503509\n",
      "52 Train Loss 9.268121 Test MSE 4.283582576567304 Test RE 0.9892626945467123\n",
      "53 Train Loss 9.149687 Test MSE 4.28355358195969 Test RE 0.9892593464926385\n",
      "54 Train Loss 9.077272 Test MSE 4.269138086535718 Test RE 0.9875933603625685\n",
      "55 Train Loss 8.922593 Test MSE 4.251596345314598 Test RE 0.9855622782678641\n",
      "56 Train Loss 8.721828 Test MSE 4.236006243643316 Test RE 0.9837536484990097\n",
      "57 Train Loss 8.445947 Test MSE 4.286597025178578 Test RE 0.9896107159806818\n",
      "58 Train Loss 8.247912 Test MSE 4.2922825511534555 Test RE 0.9902667833660255\n",
      "59 Train Loss 8.150725 Test MSE 4.287866801794129 Test RE 0.9897572764685959\n",
      "60 Train Loss 8.102588 Test MSE 4.279866063988525 Test RE 0.9888334504501067\n",
      "61 Train Loss 8.008513 Test MSE 4.308856245390505 Test RE 0.9921767888248397\n",
      "62 Train Loss 7.9282665 Test MSE 4.28810324764554 Test RE 0.9897845651865801\n",
      "63 Train Loss 7.863993 Test MSE 4.261132853805127 Test RE 0.9866669878505784\n",
      "64 Train Loss 7.7966976 Test MSE 4.210860401668944 Test RE 0.9808294159516314\n",
      "65 Train Loss 7.729153 Test MSE 4.238033761269282 Test RE 0.9839890517460381\n",
      "66 Train Loss 7.674761 Test MSE 4.277161698208704 Test RE 0.9885209885789039\n",
      "67 Train Loss 7.630535 Test MSE 4.247852865095831 Test RE 0.9851282947618398\n",
      "68 Train Loss 7.583716 Test MSE 4.292052875190568 Test RE 0.9902402888940415\n",
      "69 Train Loss 7.53028 Test MSE 4.285240200530871 Test RE 0.9894540842198101\n",
      "70 Train Loss 7.4928236 Test MSE 4.281391973170247 Test RE 0.9890097101218505\n",
      "71 Train Loss 7.42357 Test MSE 4.316320959632013 Test RE 0.9930358464101702\n",
      "72 Train Loss 7.3729506 Test MSE 4.3510496768237985 Test RE 0.9970227799061334\n",
      "73 Train Loss 7.3188343 Test MSE 4.34185072799885 Test RE 0.9959682741029405\n",
      "74 Train Loss 7.272663 Test MSE 4.3496340159336375 Test RE 0.996860570659292\n",
      "75 Train Loss 7.2463074 Test MSE 4.340943725586947 Test RE 0.9958642409538291\n",
      "76 Train Loss 7.199504 Test MSE 4.331310225717641 Test RE 0.9947586073450545\n",
      "77 Train Loss 7.1726003 Test MSE 4.348299211334581 Test RE 0.9967076019073247\n",
      "78 Train Loss 7.1385093 Test MSE 4.357253536554691 Test RE 0.9977333195086869\n",
      "79 Train Loss 7.1001654 Test MSE 4.3165431823474245 Test RE 0.9930614089533755\n",
      "80 Train Loss 7.0726757 Test MSE 4.3093363004511005 Test RE 0.9922320571136638\n",
      "81 Train Loss 7.0621805 Test MSE 4.31618323842624 Test RE 0.9930200038458245\n",
      "82 Train Loss 7.046998 Test MSE 4.306353143053882 Test RE 0.9918885591086882\n",
      "83 Train Loss 7.0340242 Test MSE 4.306529848789724 Test RE 0.9919089093440155\n",
      "84 Train Loss 7.016405 Test MSE 4.318147930727778 Test RE 0.9932459855386856\n",
      "85 Train Loss 6.9949613 Test MSE 4.315515395743063 Test RE 0.9929431759213992\n",
      "86 Train Loss 6.984178 Test MSE 4.309711310205223 Test RE 0.9922752294932334\n",
      "87 Train Loss 6.9687185 Test MSE 4.300215871430351 Test RE 0.9911815037681064\n",
      "88 Train Loss 6.9606705 Test MSE 4.305477762868716 Test RE 0.9917877401916866\n",
      "89 Train Loss 6.950128 Test MSE 4.2961781233708 Test RE 0.9907160525883083\n",
      "90 Train Loss 6.936461 Test MSE 4.296004844161102 Test RE 0.9906960729435234\n",
      "91 Train Loss 6.931392 Test MSE 4.290265461643935 Test RE 0.9900340760081204\n",
      "92 Train Loss 6.927091 Test MSE 4.295698350253373 Test RE 0.990660732233057\n",
      "93 Train Loss 6.918089 Test MSE 4.290703972814245 Test RE 0.9900846707687826\n",
      "94 Train Loss 6.911014 Test MSE 4.298632983793693 Test RE 0.9909990625372261\n",
      "95 Train Loss 6.902649 Test MSE 4.304712840163372 Test RE 0.991699634445742\n",
      "96 Train Loss 6.897664 Test MSE 4.312770032206182 Test RE 0.9926272897039278\n",
      "97 Train Loss 6.891804 Test MSE 4.312538491586599 Test RE 0.9926006436480493\n",
      "98 Train Loss 6.888912 Test MSE 4.3123036013048255 Test RE 0.9925736113768958\n",
      "99 Train Loss 6.883375 Test MSE 4.326447815365098 Test RE 0.9942000831841606\n",
      "Training time: 77.09\n",
      "KG_stan_tune5\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.709526 Test MSE 8.449440285926578 Test RE 1.3893831602977018\n",
      "1 Train Loss 56.053864 Test MSE 8.72096122375963 Test RE 1.4115304067459244\n",
      "2 Train Loss 47.895687 Test MSE 7.634493856248572 Test RE 1.3206817765146233\n",
      "3 Train Loss 45.228302 Test MSE 8.024251128472692 Test RE 1.3539739734519052\n",
      "4 Train Loss 42.610023 Test MSE 8.35518519677035 Test RE 1.3816120126594655\n",
      "5 Train Loss 40.546722 Test MSE 8.149325743428477 Test RE 1.3644854190052205\n",
      "6 Train Loss 39.113434 Test MSE 8.071677917656354 Test RE 1.3579693639552441\n",
      "7 Train Loss 36.998123 Test MSE 7.943586127649022 Test RE 1.3471512692698058\n",
      "8 Train Loss 35.63717 Test MSE 7.681402132121664 Test RE 1.324732866015003\n",
      "9 Train Loss 35.01745 Test MSE 7.536226676160626 Test RE 1.3121546888137046\n",
      "10 Train Loss 34.44181 Test MSE 7.557968910402211 Test RE 1.3140461278974664\n",
      "11 Train Loss 33.989243 Test MSE 7.547702704894641 Test RE 1.3131533713961172\n",
      "12 Train Loss 33.728584 Test MSE 7.389694297544865 Test RE 1.2993354769480174\n",
      "13 Train Loss 33.553303 Test MSE 7.465904318959709 Test RE 1.3060183236119633\n",
      "14 Train Loss 33.28433 Test MSE 7.4453431156501395 Test RE 1.304218687477624\n",
      "15 Train Loss 33.070705 Test MSE 7.51830939629523 Test RE 1.3105939453371385\n",
      "16 Train Loss 32.589954 Test MSE 7.635276238685143 Test RE 1.3207494464724807\n",
      "17 Train Loss 32.03162 Test MSE 7.568087823956196 Test RE 1.3149254826396304\n",
      "18 Train Loss 31.388294 Test MSE 7.786699398458642 Test RE 1.3337817322350873\n",
      "19 Train Loss 30.990093 Test MSE 8.04412451879087 Test RE 1.3556496072810624\n",
      "20 Train Loss 30.357422 Test MSE 8.352524092528075 Test RE 1.3813919752637636\n",
      "21 Train Loss 29.212788 Test MSE 8.62475882078615 Test RE 1.403723401232082\n",
      "22 Train Loss 28.219904 Test MSE 8.952283095941898 Test RE 1.4301281788342886\n",
      "23 Train Loss 27.457253 Test MSE 9.063634015528516 Test RE 1.438994853153738\n",
      "24 Train Loss 26.487375 Test MSE 8.884018938808786 Test RE 1.424665141343015\n",
      "25 Train Loss 25.527874 Test MSE 9.057492934543962 Test RE 1.4385072738174474\n",
      "26 Train Loss 23.721447 Test MSE 8.865461712360974 Test RE 1.4231764201735042\n",
      "27 Train Loss 21.996765 Test MSE 8.83307180517102 Test RE 1.4205742583169885\n",
      "28 Train Loss 19.611578 Test MSE 8.395335082571995 Test RE 1.3849276234029837\n",
      "29 Train Loss 18.52172 Test MSE 7.806215887086502 Test RE 1.3354521733492626\n",
      "30 Train Loss 17.577091 Test MSE 7.889189989925105 Test RE 1.3425308303591021\n",
      "31 Train Loss 17.168264 Test MSE 7.631785464649179 Test RE 1.3204474950555343\n",
      "32 Train Loss 16.660093 Test MSE 7.734762528197296 Test RE 1.3293261636457234\n",
      "33 Train Loss 16.229973 Test MSE 7.7140609216550615 Test RE 1.3275460427220043\n",
      "34 Train Loss 15.950607 Test MSE 7.85270682077794 Test RE 1.3394229994609927\n",
      "35 Train Loss 15.534189 Test MSE 7.694303144079559 Test RE 1.32584485210738\n",
      "36 Train Loss 15.207397 Test MSE 7.7595451283575905 Test RE 1.3314540772143513\n",
      "37 Train Loss 14.317161 Test MSE 6.725259402498872 Test RE 1.2395458065392662\n",
      "38 Train Loss 11.625696 Test MSE 5.94339310719277 Test RE 1.165266573027304\n",
      "39 Train Loss 9.369074 Test MSE 5.793755592655967 Test RE 1.1505040336418695\n",
      "40 Train Loss 8.885279 Test MSE 5.706262545215104 Test RE 1.1417839533121483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 8.599785 Test MSE 5.760113796535339 Test RE 1.1471589346812083\n",
      "42 Train Loss 8.377424 Test MSE 5.766259717838244 Test RE 1.14777076885171\n",
      "43 Train Loss 8.248116 Test MSE 5.7587104134754625 Test RE 1.1470191803687786\n",
      "44 Train Loss 8.104484 Test MSE 5.800092988446499 Test RE 1.1511330907841635\n",
      "45 Train Loss 7.8411627 Test MSE 5.764466679268808 Test RE 1.1475923033152642\n",
      "46 Train Loss 7.574289 Test MSE 5.821131203556231 Test RE 1.1532189077322168\n",
      "47 Train Loss 7.262633 Test MSE 5.762997209078208 Test RE 1.1474460226392786\n",
      "48 Train Loss 6.462046 Test MSE 5.601526116032798 Test RE 1.1312569043805365\n",
      "49 Train Loss 5.707096 Test MSE 5.388036058748941 Test RE 1.1094897823813945\n",
      "50 Train Loss 4.8102946 Test MSE 5.08193491278621 Test RE 1.0775132257230324\n",
      "51 Train Loss 4.124008 Test MSE 4.830484196870538 Test RE 1.050517745808119\n",
      "52 Train Loss 3.5078154 Test MSE 4.800137097705967 Test RE 1.0472126532019232\n",
      "53 Train Loss 2.921606 Test MSE 4.859915646106904 Test RE 1.0537132129956692\n",
      "54 Train Loss 2.7243874 Test MSE 4.918330167692228 Test RE 1.060026933442142\n",
      "55 Train Loss 2.607448 Test MSE 4.968670155617575 Test RE 1.0654379056418903\n",
      "56 Train Loss 2.484812 Test MSE 4.97932625291294 Test RE 1.066579793597145\n",
      "57 Train Loss 2.4208095 Test MSE 5.002560477548152 Test RE 1.0690653019203484\n",
      "58 Train Loss 2.3359244 Test MSE 4.99983217011351 Test RE 1.0687737375687252\n",
      "59 Train Loss 2.268342 Test MSE 4.992736371986404 Test RE 1.068015062568721\n",
      "60 Train Loss 2.240634 Test MSE 4.988973336604135 Test RE 1.0676125041585336\n",
      "61 Train Loss 2.1881623 Test MSE 4.9967951165492455 Test RE 1.0684490850556962\n",
      "62 Train Loss 2.1381671 Test MSE 5.049134740619289 Test RE 1.074030316910414\n",
      "63 Train Loss 2.1013508 Test MSE 5.019311513891758 Test RE 1.0708536846587826\n",
      "64 Train Loss 2.051402 Test MSE 5.05760360924293 Test RE 1.0749306702609371\n",
      "65 Train Loss 1.9911996 Test MSE 5.12115111135422 Test RE 1.081662704839563\n",
      "66 Train Loss 1.9540622 Test MSE 5.1037129472842855 Test RE 1.0798195356230624\n",
      "67 Train Loss 1.9099728 Test MSE 5.0842576166535265 Test RE 1.0777594368880978\n",
      "68 Train Loss 1.880773 Test MSE 5.102832590062623 Test RE 1.0797264006903309\n",
      "69 Train Loss 1.8386025 Test MSE 5.115743434743769 Test RE 1.0810914634394881\n",
      "70 Train Loss 1.8095574 Test MSE 5.157841300871994 Test RE 1.0855305442695276\n",
      "71 Train Loss 1.7851155 Test MSE 5.125551295883594 Test RE 1.0821272970250075\n",
      "72 Train Loss 1.7496504 Test MSE 5.1302619042823485 Test RE 1.0826244442561679\n",
      "73 Train Loss 1.7275851 Test MSE 5.127466234511373 Test RE 1.0823294229750091\n",
      "74 Train Loss 1.6871057 Test MSE 5.131446929049755 Test RE 1.0827494732242053\n",
      "75 Train Loss 1.6509159 Test MSE 5.151872033781155 Test RE 1.0849022099270595\n",
      "76 Train Loss 1.5985875 Test MSE 5.161327249653182 Test RE 1.085897312506215\n",
      "77 Train Loss 1.5578973 Test MSE 5.207898018788718 Test RE 1.0907853487031254\n",
      "78 Train Loss 1.5307596 Test MSE 5.259733243211763 Test RE 1.0962003076582771\n",
      "79 Train Loss 1.5186675 Test MSE 5.269415715237386 Test RE 1.097208823499721\n",
      "80 Train Loss 1.4795636 Test MSE 5.304487099543552 Test RE 1.1008540868630117\n",
      "81 Train Loss 1.4475787 Test MSE 5.349565565898395 Test RE 1.1055218170789136\n",
      "82 Train Loss 1.4293878 Test MSE 5.386931955643611 Test RE 1.1093760995976607\n",
      "83 Train Loss 1.3962662 Test MSE 5.397363317018805 Test RE 1.1104496890080824\n",
      "84 Train Loss 1.3705814 Test MSE 5.4073375556939505 Test RE 1.1114752618008994\n",
      "85 Train Loss 1.3458354 Test MSE 5.42675771747325 Test RE 1.1134693747568394\n",
      "86 Train Loss 1.3317487 Test MSE 5.416387376406768 Test RE 1.1124049658071566\n",
      "87 Train Loss 1.3142166 Test MSE 5.429447057945764 Test RE 1.1137452418128284\n",
      "88 Train Loss 1.298873 Test MSE 5.454146128240789 Test RE 1.1162756337679292\n",
      "89 Train Loss 1.2723935 Test MSE 5.545552254786229 Test RE 1.1255906095136838\n",
      "90 Train Loss 1.2505693 Test MSE 5.5304692760177545 Test RE 1.1240588577566242\n",
      "91 Train Loss 1.2339509 Test MSE 5.580596019141448 Test RE 1.1291414562765474\n",
      "92 Train Loss 1.2154068 Test MSE 5.5636681751956365 Test RE 1.1274276207752953\n",
      "93 Train Loss 1.2012546 Test MSE 5.587183717063435 Test RE 1.1298077156589796\n",
      "94 Train Loss 1.1810979 Test MSE 5.616277121508622 Test RE 1.13274544562126\n",
      "95 Train Loss 1.1664947 Test MSE 5.63412557887541 Test RE 1.134543943174416\n",
      "96 Train Loss 1.1526872 Test MSE 5.661127998012575 Test RE 1.13725943221444\n",
      "97 Train Loss 1.1351438 Test MSE 5.699058451754243 Test RE 1.1410629808679968\n",
      "98 Train Loss 1.1186056 Test MSE 5.762161172262151 Test RE 1.147362789741647\n",
      "99 Train Loss 1.1099527 Test MSE 5.76984920469531 Test RE 1.14812795594801\n",
      "Training time: 76.59\n",
      "KG_stan_tune6\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 199.59178 Test MSE 4.399736830911105 Test RE 1.0025854792571092\n",
      "1 Train Loss 160.66075 Test MSE 4.4138120465737085 Test RE 1.00418788631859\n",
      "2 Train Loss 150.36328 Test MSE 4.412652815647227 Test RE 1.0040560091470427\n",
      "3 Train Loss 140.1761 Test MSE 4.423078713237025 Test RE 1.0052414648682204\n",
      "4 Train Loss 130.641 Test MSE 4.4380785674776755 Test RE 1.0069445448111538\n",
      "5 Train Loss 121.33107 Test MSE 4.468287966193186 Test RE 1.01036580013431\n",
      "6 Train Loss 114.106476 Test MSE 4.464598269850172 Test RE 1.0099485583481056\n",
      "7 Train Loss 108.51518 Test MSE 4.433203210128152 Test RE 1.006391314017475\n",
      "8 Train Loss 104.81069 Test MSE 4.4085246541295104 Test RE 1.003586237852475\n",
      "9 Train Loss 101.73589 Test MSE 4.385034360234976 Test RE 1.0009089223112853\n",
      "10 Train Loss 98.040764 Test MSE 4.352628664485619 Test RE 0.9972036723326106\n",
      "11 Train Loss 95.22819 Test MSE 4.323694542320374 Test RE 0.9938836873742174\n",
      "12 Train Loss 92.83805 Test MSE 4.279013882386215 Test RE 0.988735000216799\n",
      "13 Train Loss 89.79627 Test MSE 4.24528929149838 Test RE 0.9848309880862022\n",
      "14 Train Loss 87.001915 Test MSE 4.166042437385292 Test RE 0.9755957620038376\n",
      "15 Train Loss 85.08064 Test MSE 4.120555440769247 Test RE 0.9702551155565273\n",
      "16 Train Loss 83.22041 Test MSE 4.114408642719385 Test RE 0.9695311612051144\n",
      "17 Train Loss 81.661896 Test MSE 4.10307596038074 Test RE 0.9681950074652091\n",
      "18 Train Loss 80.24034 Test MSE 4.080287959270104 Test RE 0.9655026434158025\n",
      "19 Train Loss 78.996254 Test MSE 4.06220133527099 Test RE 0.9633603831021962\n",
      "20 Train Loss 76.93707 Test MSE 4.051700477620145 Test RE 0.9621144261129199\n",
      "21 Train Loss 75.50749 Test MSE 4.020343123379158 Test RE 0.9583841451459718\n",
      "22 Train Loss 73.88441 Test MSE 4.030404241442029 Test RE 0.9595825989362107\n",
      "23 Train Loss 73.5949 Test MSE 4.02151520017572 Test RE 0.9585238369490655\n",
      "24 Train Loss 72.69907 Test MSE 4.005886092257776 Test RE 0.9566594331845409\n",
      "25 Train Loss 71.857796 Test MSE 4.00012980327952 Test RE 0.9559718465046445\n",
      "26 Train Loss 69.09776 Test MSE 3.9006398764739387 Test RE 0.9440086818066711\n",
      "27 Train Loss 68.29713 Test MSE 3.8688372666647806 Test RE 0.9401524703890514\n",
      "28 Train Loss 67.430954 Test MSE 3.8100179868909474 Test RE 0.9329783657059264\n",
      "29 Train Loss 65.91196 Test MSE 3.77484322348175 Test RE 0.9286616684049126\n",
      "30 Train Loss 64.88322 Test MSE 3.7763046762651586 Test RE 0.9288414194255099\n",
      "31 Train Loss 63.645744 Test MSE 3.717655393460618 Test RE 0.9216003384203966\n",
      "32 Train Loss 62.775635 Test MSE 3.66151298893911 Test RE 0.9146150634935849\n",
      "33 Train Loss 62.0414 Test MSE 3.6563785666366875 Test RE 0.9139735708347898\n",
      "34 Train Loss 61.54448 Test MSE 3.6253638051816326 Test RE 0.9100889839663642\n",
      "35 Train Loss 61.178905 Test MSE 3.6133276005995745 Test RE 0.908576980655293\n",
      "36 Train Loss 60.674797 Test MSE 3.593583852526322 Test RE 0.906091281998375\n",
      "37 Train Loss 60.29238 Test MSE 3.580211117649571 Test RE 0.9044038005559656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 59.948135 Test MSE 3.581756520382067 Test RE 0.9045989730283377\n",
      "39 Train Loss 59.36984 Test MSE 3.5834654619625375 Test RE 0.9048147501807736\n",
      "40 Train Loss 58.9941 Test MSE 3.5871296787417633 Test RE 0.9052772340976294\n",
      "41 Train Loss 58.26255 Test MSE 3.5814482057320296 Test RE 0.9045600386233384\n",
      "42 Train Loss 57.68522 Test MSE 3.573208383406771 Test RE 0.9035188807564164\n",
      "43 Train Loss 57.035233 Test MSE 3.5731285192591162 Test RE 0.9035087835047643\n",
      "44 Train Loss 56.520958 Test MSE 3.5702012961370815 Test RE 0.9031386157819208\n",
      "45 Train Loss 56.12835 Test MSE 3.5653444354563337 Test RE 0.9025240970346373\n",
      "46 Train Loss 55.638157 Test MSE 3.5627227702342217 Test RE 0.9021922144910822\n",
      "47 Train Loss 55.298218 Test MSE 3.5773284189115095 Test RE 0.9040396252855178\n",
      "48 Train Loss 54.980366 Test MSE 3.578099484999093 Test RE 0.9041370494883076\n",
      "49 Train Loss 54.703285 Test MSE 3.583817712289702 Test RE 0.904859220186563\n",
      "50 Train Loss 54.02982 Test MSE 3.581859147080484 Test RE 0.9046119324995464\n",
      "51 Train Loss 53.283558 Test MSE 3.6422064900066164 Test RE 0.9122005761963757\n",
      "52 Train Loss 52.527325 Test MSE 3.694533504745933 Test RE 0.9187299302472823\n",
      "53 Train Loss 51.84263 Test MSE 3.749790216695715 Test RE 0.9255748516695512\n",
      "54 Train Loss 50.74731 Test MSE 3.769963061296909 Test RE 0.9280611818418888\n",
      "55 Train Loss 50.215393 Test MSE 3.767524409665464 Test RE 0.9277609688165775\n",
      "56 Train Loss 49.40462 Test MSE 3.795338141110814 Test RE 0.9311792670452698\n",
      "57 Train Loss 48.765472 Test MSE 3.793675349905892 Test RE 0.9309752633090724\n",
      "58 Train Loss 48.29533 Test MSE 3.8089468919740073 Test RE 0.932847214274186\n",
      "59 Train Loss 47.41188 Test MSE 3.8362844347460814 Test RE 0.9361888408543992\n",
      "60 Train Loss 46.687927 Test MSE 3.9454742740141473 Test RE 0.9494184525675449\n",
      "61 Train Loss 46.303795 Test MSE 4.081245955881648 Test RE 0.965615980266668\n",
      "62 Train Loss 46.035892 Test MSE 4.096329851387383 Test RE 0.9673987468005533\n",
      "63 Train Loss 45.600243 Test MSE 4.087392894649506 Test RE 0.9663428843899589\n",
      "64 Train Loss 44.600338 Test MSE 4.172441734565698 Test RE 0.9763447620063104\n",
      "65 Train Loss 44.063206 Test MSE 4.1871135948780145 Test RE 0.9780598516514881\n",
      "66 Train Loss 43.512405 Test MSE 4.3638332997227325 Test RE 0.9984863595159169\n",
      "67 Train Loss 42.497017 Test MSE 4.453081839544348 Test RE 1.0086451362132791\n",
      "68 Train Loss 42.02654 Test MSE 4.4897980537828355 Test RE 1.012794802512872\n",
      "69 Train Loss 41.851753 Test MSE 4.537267394787652 Test RE 1.0181347190697128\n",
      "70 Train Loss 41.37972 Test MSE 4.586265485680483 Test RE 1.0236173910871826\n",
      "71 Train Loss 40.609463 Test MSE 4.71350021592327 Test RE 1.0377191373036996\n",
      "72 Train Loss 40.1453 Test MSE 4.780941534007627 Test RE 1.0451166740993794\n",
      "73 Train Loss 39.662006 Test MSE 4.889170481648271 Test RE 1.0568799300337548\n",
      "74 Train Loss 39.269897 Test MSE 4.913703863482371 Test RE 1.0595282722453458\n",
      "75 Train Loss 38.80692 Test MSE 4.933055649341469 Test RE 1.0616126078926051\n",
      "76 Train Loss 38.526176 Test MSE 4.9735161267833226 Test RE 1.0659573427272802\n",
      "77 Train Loss 38.08526 Test MSE 4.965572953333339 Test RE 1.065105785475574\n",
      "78 Train Loss 37.613655 Test MSE 5.048991230071663 Test RE 1.0740150533274317\n",
      "79 Train Loss 37.132286 Test MSE 5.083018791816857 Test RE 1.077628126026259\n",
      "80 Train Loss 36.754456 Test MSE 5.161026497808037 Test RE 1.0858656742896993\n",
      "81 Train Loss 36.1633 Test MSE 5.1656236425009885 Test RE 1.0863491798964515\n",
      "82 Train Loss 35.636433 Test MSE 5.331922687155634 Test RE 1.1036973048599514\n",
      "83 Train Loss 35.3079 Test MSE 5.314932684441924 Test RE 1.1019374535667767\n",
      "84 Train Loss 34.920982 Test MSE 5.304629549738533 Test RE 1.1008688682946157\n",
      "85 Train Loss 33.752296 Test MSE 5.381067754152699 Test RE 1.1087721030657078\n",
      "86 Train Loss 33.254635 Test MSE 5.457407613055879 Test RE 1.116609340624585\n",
      "87 Train Loss 32.96882 Test MSE 5.479494256560109 Test RE 1.1188665708002936\n",
      "88 Train Loss 32.4808 Test MSE 5.501363281310505 Test RE 1.1210970828065314\n",
      "89 Train Loss 32.101204 Test MSE 5.5298124297358235 Test RE 1.1239921043069108\n",
      "90 Train Loss 31.884254 Test MSE 5.521243871231117 Test RE 1.123120942221795\n",
      "91 Train Loss 31.5843 Test MSE 5.530236775187326 Test RE 1.124035229801054\n",
      "92 Train Loss 30.907038 Test MSE 5.605645272584638 Test RE 1.1316727703286655\n",
      "93 Train Loss 30.297642 Test MSE 5.543019427870656 Test RE 1.1253335339636021\n",
      "94 Train Loss 29.952621 Test MSE 5.548461408866661 Test RE 1.1258858088942139\n",
      "95 Train Loss 29.81391 Test MSE 5.558517304136647 Test RE 1.1269056109398747\n",
      "96 Train Loss 29.439045 Test MSE 5.575935134722478 Test RE 1.128669831281054\n",
      "97 Train Loss 29.082066 Test MSE 5.604426583810233 Test RE 1.1315497486423938\n",
      "98 Train Loss 28.935455 Test MSE 5.6114913852494155 Test RE 1.132262725826168\n",
      "99 Train Loss 28.67466 Test MSE 5.621643233640068 Test RE 1.1332864612902969\n",
      "Training time: 79.22\n",
      "KG_stan_tune6\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 464.56952 Test MSE 5.62891769039227 Test RE 1.1340194656598055\n",
      "1 Train Loss 353.20822 Test MSE 5.615003938015868 Test RE 1.132617044323079\n",
      "2 Train Loss 268.2774 Test MSE 5.558583505858428 Test RE 1.1269123216205756\n",
      "3 Train Loss 201.46924 Test MSE 5.470127978458792 Test RE 1.1179099042642875\n",
      "4 Train Loss 167.21117 Test MSE 5.458024535313426 Test RE 1.1166724513300157\n",
      "5 Train Loss 153.3527 Test MSE 5.447513774043739 Test RE 1.1155967202136357\n",
      "6 Train Loss 140.71944 Test MSE 5.415057531809536 Test RE 1.1122683972381116\n",
      "7 Train Loss 133.38664 Test MSE 5.351680195379259 Test RE 1.1057402963197824\n",
      "8 Train Loss 124.99816 Test MSE 5.255987468568062 Test RE 1.0958099028181987\n",
      "9 Train Loss 112.47029 Test MSE 5.0581212109042415 Test RE 1.0749856737476797\n",
      "10 Train Loss 106.24749 Test MSE 4.968540627092704 Test RE 1.0654240180728467\n",
      "11 Train Loss 100.20494 Test MSE 4.91097109266653 Test RE 1.0592336013910006\n",
      "12 Train Loss 96.28665 Test MSE 4.863144058284981 Test RE 1.0540631425059879\n",
      "13 Train Loss 93.822296 Test MSE 4.8428662556175 Test RE 1.0518632887132757\n",
      "14 Train Loss 91.84307 Test MSE 4.816162756722853 Test RE 1.0489593000825537\n",
      "15 Train Loss 90.48633 Test MSE 4.811260193926051 Test RE 1.0484252755408692\n",
      "16 Train Loss 86.038315 Test MSE 4.823003536522167 Test RE 1.0497039959853018\n",
      "17 Train Loss 83.8494 Test MSE 4.832527603686172 Test RE 1.0507399189964732\n",
      "18 Train Loss 82.10907 Test MSE 4.849040006382066 Test RE 1.0525335398742017\n",
      "19 Train Loss 81.221504 Test MSE 4.8616886671084805 Test RE 1.053905406176228\n",
      "20 Train Loss 80.574486 Test MSE 4.86009665197662 Test RE 1.053732835404222\n",
      "21 Train Loss 78.62809 Test MSE 4.87033103082962 Test RE 1.0548417258647225\n",
      "22 Train Loss 77.7235 Test MSE 4.872908802157184 Test RE 1.0551208425240393\n",
      "23 Train Loss 76.87234 Test MSE 4.873726317706415 Test RE 1.0552093462858598\n",
      "24 Train Loss 76.361664 Test MSE 4.882095052332004 Test RE 1.056114914101425\n",
      "25 Train Loss 75.548096 Test MSE 4.895951641107612 Test RE 1.0576126093313003\n",
      "26 Train Loss 74.61987 Test MSE 4.904355592480638 Test RE 1.0585199216090853\n",
      "27 Train Loss 73.18824 Test MSE 4.915019692088767 Test RE 1.0596701269771964\n",
      "28 Train Loss 72.18614 Test MSE 4.912808943897931 Test RE 1.0594317833436626\n",
      "29 Train Loss 71.37147 Test MSE 4.911294621851125 Test RE 1.0592684913682595\n",
      "30 Train Loss 71.116295 Test MSE 4.908342100548064 Test RE 1.0589500434629664\n",
      "31 Train Loss 70.28547 Test MSE 4.905313921989178 Test RE 1.058623335942227\n",
      "32 Train Loss 69.31674 Test MSE 4.892486213527546 Test RE 1.0572382460865934\n",
      "33 Train Loss 68.91184 Test MSE 4.887600023291579 Test RE 1.0567101753451618\n",
      "34 Train Loss 68.43507 Test MSE 4.883656415197911 Test RE 1.056283780824702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 68.18908 Test MSE 4.878135970002466 Test RE 1.0556866047508795\n",
      "36 Train Loss 67.601685 Test MSE 4.870549727683939 Test RE 1.0548654088521954\n",
      "37 Train Loss 67.01901 Test MSE 4.86787516201779 Test RE 1.0545757398840891\n",
      "38 Train Loss 66.50615 Test MSE 4.854925052817372 Test RE 1.0531720508459699\n",
      "39 Train Loss 66.23616 Test MSE 4.8562773933039995 Test RE 1.0533187212910295\n",
      "40 Train Loss 65.45607 Test MSE 4.8429694665669425 Test RE 1.0518744972852825\n",
      "41 Train Loss 65.11667 Test MSE 4.831249825493555 Test RE 1.0506009957013402\n",
      "42 Train Loss 64.814255 Test MSE 4.8516313708266114 Test RE 1.0528147433378423\n",
      "43 Train Loss 64.48665 Test MSE 4.863341726607967 Test RE 1.054084564118636\n",
      "44 Train Loss 64.18233 Test MSE 4.887961355994195 Test RE 1.056749235096887\n",
      "45 Train Loss 63.744095 Test MSE 4.910006810511415 Test RE 1.0591296046269982\n",
      "46 Train Loss 63.339016 Test MSE 4.941418746297373 Test RE 1.0625121121828733\n",
      "47 Train Loss 63.197517 Test MSE 4.958347383210995 Test RE 1.0643305679602073\n",
      "48 Train Loss 62.784218 Test MSE 4.994165333733411 Test RE 1.0681678889320856\n",
      "49 Train Loss 62.250298 Test MSE 5.0250106735817335 Test RE 1.0714614607174633\n",
      "50 Train Loss 62.075928 Test MSE 5.039287654664168 Test RE 1.0729824908048273\n",
      "51 Train Loss 61.895546 Test MSE 5.071597677071365 Test RE 1.0764167754133673\n",
      "52 Train Loss 61.591675 Test MSE 5.058996445347533 Test RE 1.0750786750569863\n",
      "53 Train Loss 61.382763 Test MSE 5.067799834541308 Test RE 1.0760136650635073\n",
      "54 Train Loss 60.984615 Test MSE 5.086352611312866 Test RE 1.0779814621951922\n",
      "55 Train Loss 60.765175 Test MSE 5.0951452298359 Test RE 1.078912796279876\n",
      "56 Train Loss 60.324993 Test MSE 5.117724508757488 Test RE 1.0813007697628403\n",
      "57 Train Loss 59.911655 Test MSE 5.147518691980285 Test RE 1.0844437408252834\n",
      "58 Train Loss 59.791065 Test MSE 5.143120842572718 Test RE 1.0839803875433172\n",
      "59 Train Loss 59.35265 Test MSE 5.168389980613408 Test RE 1.0866400263761502\n",
      "60 Train Loss 59.18622 Test MSE 5.174917073479495 Test RE 1.087325961697915\n",
      "61 Train Loss 58.72912 Test MSE 5.211733036805491 Test RE 1.09118689378187\n",
      "62 Train Loss 58.493935 Test MSE 5.219673664560265 Test RE 1.092017846843401\n",
      "63 Train Loss 57.9393 Test MSE 5.271251637787548 Test RE 1.0973999466812798\n",
      "64 Train Loss 57.345535 Test MSE 5.394081432915304 Test RE 1.110112031421517\n",
      "65 Train Loss 57.060043 Test MSE 5.433489722841603 Test RE 1.1141598016139171\n",
      "66 Train Loss 56.635147 Test MSE 5.431671939701249 Test RE 1.1139734140042359\n",
      "67 Train Loss 56.12385 Test MSE 5.397514945939906 Test RE 1.110465286911711\n",
      "68 Train Loss 55.76213 Test MSE 5.4544230097535 Test RE 1.116303967457229\n",
      "69 Train Loss 55.356056 Test MSE 5.450671413938657 Test RE 1.1159200000188656\n",
      "70 Train Loss 55.106842 Test MSE 5.446741802758978 Test RE 1.1155176713867858\n",
      "71 Train Loss 54.87571 Test MSE 5.475342180201254 Test RE 1.1184425809569172\n",
      "72 Train Loss 54.583168 Test MSE 5.572791364039639 Test RE 1.128351608478894\n",
      "73 Train Loss 54.183807 Test MSE 5.671123274184597 Test RE 1.1382629609322727\n",
      "74 Train Loss 53.68853 Test MSE 5.6831086649787395 Test RE 1.1394651324694232\n",
      "75 Train Loss 52.98567 Test MSE 5.754535322427098 Test RE 1.1466033079356812\n",
      "76 Train Loss 52.71378 Test MSE 5.8075357001064765 Test RE 1.1518714242017074\n",
      "77 Train Loss 52.54768 Test MSE 5.854905412309139 Test RE 1.1565595577239705\n",
      "78 Train Loss 52.382626 Test MSE 5.888063373253122 Test RE 1.1598298935928362\n",
      "79 Train Loss 52.285408 Test MSE 5.881945340926505 Test RE 1.159227172413948\n",
      "80 Train Loss 52.130062 Test MSE 5.899752545335182 Test RE 1.1609805885117082\n",
      "81 Train Loss 51.992332 Test MSE 5.936735098682965 Test RE 1.1646137028034929\n",
      "82 Train Loss 51.80708 Test MSE 6.019387048903252 Test RE 1.1726926280675145\n",
      "83 Train Loss 51.63731 Test MSE 6.086407417935649 Test RE 1.1792029864024862\n",
      "84 Train Loss 51.425087 Test MSE 6.107966960893696 Test RE 1.1812896527883392\n",
      "85 Train Loss 51.231815 Test MSE 6.061547819437172 Test RE 1.176792327253033\n",
      "86 Train Loss 50.908684 Test MSE 6.031302917450116 Test RE 1.1738527746429703\n",
      "87 Train Loss 50.611378 Test MSE 6.082193654403676 Test RE 1.1787947206953011\n",
      "88 Train Loss 50.38057 Test MSE 6.067229334474165 Test RE 1.1773437043550565\n",
      "89 Train Loss 50.15021 Test MSE 6.11523982979661 Test RE 1.1819927352446995\n",
      "90 Train Loss 49.894802 Test MSE 6.136323039124659 Test RE 1.1840285309670275\n",
      "91 Train Loss 49.729 Test MSE 6.2084775222906 Test RE 1.1909694375340785\n",
      "92 Train Loss 49.42691 Test MSE 6.223338030357026 Test RE 1.192393927907969\n",
      "93 Train Loss 49.242714 Test MSE 6.2715338202515465 Test RE 1.1970021889187505\n",
      "94 Train Loss 49.086403 Test MSE 6.312577902209405 Test RE 1.2009126944402648\n",
      "95 Train Loss 48.918015 Test MSE 6.275121273582129 Test RE 1.1973444955773447\n",
      "96 Train Loss 48.63817 Test MSE 6.396310207478786 Test RE 1.2088511257094348\n",
      "97 Train Loss 48.45407 Test MSE 6.408006319274641 Test RE 1.2099558563960577\n",
      "98 Train Loss 48.382053 Test MSE 6.4493316681899895 Test RE 1.2138510999903618\n",
      "99 Train Loss 48.285126 Test MSE 6.519256492503342 Test RE 1.220413756521132\n",
      "Training time: 76.09\n",
      "KG_stan_tune6\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1111.6664 Test MSE 6.856612871954489 Test RE 1.251592278318874\n",
      "1 Train Loss 791.57935 Test MSE 6.849957813960764 Test RE 1.2509847304321624\n",
      "2 Train Loss 735.0938 Test MSE 6.851759237331356 Test RE 1.2511492135610165\n",
      "3 Train Loss 650.0472 Test MSE 6.8596875922510705 Test RE 1.2518728734848525\n",
      "4 Train Loss 576.2466 Test MSE 6.887279748704961 Test RE 1.2543880905711968\n",
      "5 Train Loss 513.2011 Test MSE 6.915368346533567 Test RE 1.2569433920094903\n",
      "6 Train Loss 422.61658 Test MSE 6.925936643293564 Test RE 1.2579034767669715\n",
      "7 Train Loss 398.31723 Test MSE 6.890965045566387 Test RE 1.2547236493424163\n",
      "8 Train Loss 340.1641 Test MSE 6.665516281427265 Test RE 1.2340278384753507\n",
      "9 Train Loss 307.96277 Test MSE 6.609342799531547 Test RE 1.2288169663097825\n",
      "10 Train Loss 242.11455 Test MSE 6.604747086319703 Test RE 1.2283896717533733\n",
      "11 Train Loss 207.17519 Test MSE 6.623718272716457 Test RE 1.2301525930857617\n",
      "12 Train Loss 189.77965 Test MSE 6.641179947979481 Test RE 1.2317730112500425\n",
      "13 Train Loss 176.09798 Test MSE 6.665952345993366 Test RE 1.2340682034666353\n",
      "14 Train Loss 157.96262 Test MSE 6.697253002417413 Test RE 1.2369621565408218\n",
      "15 Train Loss 145.99208 Test MSE 6.666153073660745 Test RE 1.2340867836900031\n",
      "16 Train Loss 135.24254 Test MSE 6.64539582468104 Test RE 1.2321639191385059\n",
      "17 Train Loss 125.109 Test MSE 6.6174094744673955 Test RE 1.2295666205974118\n",
      "18 Train Loss 122.68162 Test MSE 6.592784431571541 Test RE 1.2272767251664596\n",
      "19 Train Loss 114.25876 Test MSE 6.592407506359686 Test RE 1.227241641496086\n",
      "20 Train Loss 104.277145 Test MSE 6.581299581186012 Test RE 1.226207280715623\n",
      "21 Train Loss 99.46845 Test MSE 6.542172159683222 Test RE 1.2225567970991464\n",
      "22 Train Loss 95.15602 Test MSE 6.528263358185053 Test RE 1.2212565143417868\n",
      "23 Train Loss 90.76807 Test MSE 6.530206179754925 Test RE 1.2214382247650575\n",
      "24 Train Loss 87.65016 Test MSE 6.5181710183557975 Test RE 1.2203121511669923\n",
      "25 Train Loss 84.236305 Test MSE 6.496377998653919 Test RE 1.218270431724464\n",
      "26 Train Loss 79.301445 Test MSE 6.458641913257546 Test RE 1.2147269407845571\n",
      "27 Train Loss 76.48354 Test MSE 6.412698284385045 Test RE 1.2103987423396692\n",
      "28 Train Loss 73.629555 Test MSE 6.330747739030904 Test RE 1.2026397787540724\n",
      "29 Train Loss 68.49306 Test MSE 6.125262169783195 Test RE 1.1829609297540635\n",
      "30 Train Loss 65.307594 Test MSE 6.042410233228876 Test RE 1.1749331677396524\n",
      "31 Train Loss 63.130295 Test MSE 6.03608700504276 Test RE 1.1743182380248893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 59.51068 Test MSE 6.007868722830534 Test RE 1.1715700948335723\n",
      "33 Train Loss 56.6414 Test MSE 6.0830168150149975 Test RE 1.1788744866982466\n",
      "34 Train Loss 53.485943 Test MSE 6.192078956140817 Test RE 1.1893955327839245\n",
      "35 Train Loss 52.16539 Test MSE 6.16569020834365 Test RE 1.1868584066829198\n",
      "36 Train Loss 51.257225 Test MSE 6.234290343579942 Test RE 1.193442700367561\n",
      "37 Train Loss 49.485718 Test MSE 6.163162938210965 Test RE 1.1866151395762439\n",
      "38 Train Loss 48.285736 Test MSE 6.181431626474903 Test RE 1.1883725052168044\n",
      "39 Train Loss 47.34746 Test MSE 6.238448790305419 Test RE 1.1938406639126287\n",
      "40 Train Loss 45.960304 Test MSE 6.174995556737473 Test RE 1.187753680913898\n",
      "41 Train Loss 45.04862 Test MSE 6.155471172728063 Test RE 1.1858744472589424\n",
      "42 Train Loss 43.3076 Test MSE 6.311589811511024 Test RE 1.2008187029585595\n",
      "43 Train Loss 42.34257 Test MSE 6.314124571778896 Test RE 1.201059805603855\n",
      "44 Train Loss 41.10055 Test MSE 6.344078398550842 Test RE 1.2039053125671293\n",
      "45 Train Loss 39.971527 Test MSE 6.414739963039507 Test RE 1.2105914107374491\n",
      "46 Train Loss 38.818863 Test MSE 6.511187280520054 Test RE 1.2196582388881163\n",
      "47 Train Loss 38.105965 Test MSE 6.585465886336278 Test RE 1.2265953458215344\n",
      "48 Train Loss 37.494106 Test MSE 6.594852945103088 Test RE 1.2274692416550121\n",
      "49 Train Loss 36.74208 Test MSE 6.612467648484867 Test RE 1.229107419821531\n",
      "50 Train Loss 36.135212 Test MSE 6.596145041882084 Test RE 1.2275894817414519\n",
      "51 Train Loss 35.12306 Test MSE 6.44936472823019 Test RE 1.2138542111588362\n",
      "52 Train Loss 34.320282 Test MSE 6.310917567966016 Test RE 1.2007547520252948\n",
      "53 Train Loss 33.81168 Test MSE 6.219056069909943 Test RE 1.1919836446989318\n",
      "54 Train Loss 33.419888 Test MSE 6.0716279472613595 Test RE 1.1777704016594912\n",
      "55 Train Loss 32.881824 Test MSE 5.990195091148027 Test RE 1.1698455940478478\n",
      "56 Train Loss 32.564144 Test MSE 5.964400650015577 Test RE 1.1673241345834238\n",
      "57 Train Loss 32.093185 Test MSE 5.825575879135926 Test RE 1.1536590890039684\n",
      "58 Train Loss 31.712988 Test MSE 5.859910696151392 Test RE 1.1570538161083332\n",
      "59 Train Loss 31.132256 Test MSE 5.6854522324033985 Test RE 1.1397000512680722\n",
      "60 Train Loss 30.34465 Test MSE 5.51947961196314 Test RE 1.122941486750055\n",
      "61 Train Loss 29.892063 Test MSE 5.411790882341152 Test RE 1.111932857026767\n",
      "62 Train Loss 28.907879 Test MSE 5.275943411127694 Test RE 1.0978882184421048\n",
      "63 Train Loss 27.875206 Test MSE 5.157043470748371 Test RE 1.085446584487525\n",
      "64 Train Loss 26.758049 Test MSE 5.091443268194924 Test RE 1.0785207741330174\n",
      "65 Train Loss 26.225739 Test MSE 5.041363894664176 Test RE 1.0732035081291487\n",
      "66 Train Loss 25.389141 Test MSE 5.049154888915907 Test RE 1.0740324598379571\n",
      "67 Train Loss 25.02959 Test MSE 5.057543304402229 Test RE 1.074924261720344\n",
      "68 Train Loss 24.409275 Test MSE 5.019803462287541 Test RE 1.0709061611631077\n",
      "69 Train Loss 23.668571 Test MSE 5.132762319509318 Test RE 1.0828882398417474\n",
      "70 Train Loss 23.056053 Test MSE 5.1660659589670805 Test RE 1.0863956892705111\n",
      "71 Train Loss 22.460316 Test MSE 5.0755180237218545 Test RE 1.0768327303039653\n",
      "72 Train Loss 21.83934 Test MSE 5.104251881581343 Test RE 1.0798765467075595\n",
      "73 Train Loss 21.234554 Test MSE 5.105243493320495 Test RE 1.0799814363449656\n",
      "74 Train Loss 20.74094 Test MSE 5.115139068290648 Test RE 1.0810276022705356\n",
      "75 Train Loss 20.43688 Test MSE 5.130963287418736 Test RE 1.0826984471619745\n",
      "76 Train Loss 20.138811 Test MSE 5.153464849138645 Test RE 1.08506990774103\n",
      "77 Train Loss 19.794231 Test MSE 5.103845975510716 Test RE 1.0798336082740079\n",
      "78 Train Loss 19.442001 Test MSE 5.06948064738019 Test RE 1.0761920884135208\n",
      "79 Train Loss 18.818417 Test MSE 4.9339062657488135 Test RE 1.0617041319136649\n",
      "80 Train Loss 18.467728 Test MSE 4.86990408349116 Test RE 1.0547954896094311\n",
      "81 Train Loss 18.064644 Test MSE 4.86562970793502 Test RE 1.0543324844119493\n",
      "82 Train Loss 17.510723 Test MSE 4.759144645041935 Test RE 1.0427315460005655\n",
      "83 Train Loss 17.111809 Test MSE 4.673201522905445 Test RE 1.0332735564333422\n",
      "84 Train Loss 16.497656 Test MSE 4.572293609393453 Test RE 1.0220569968262208\n",
      "85 Train Loss 16.150368 Test MSE 4.577622385576929 Test RE 1.0226524011814144\n",
      "86 Train Loss 15.801193 Test MSE 4.506576677630622 Test RE 1.014685472893872\n",
      "87 Train Loss 15.299181 Test MSE 4.466479670758338 Test RE 1.010161334266869\n",
      "88 Train Loss 15.043129 Test MSE 4.489092150017051 Test RE 1.0127151815856101\n",
      "89 Train Loss 14.772553 Test MSE 4.495546051963579 Test RE 1.0134429030029328\n",
      "90 Train Loss 14.510648 Test MSE 4.4635382397084555 Test RE 1.009828655122439\n",
      "91 Train Loss 14.248418 Test MSE 4.4731343395906045 Test RE 1.010913580733673\n",
      "92 Train Loss 13.877428 Test MSE 4.508289993741875 Test RE 1.0148783367781686\n",
      "93 Train Loss 13.549218 Test MSE 4.531604506580997 Test RE 1.0174991621697917\n",
      "94 Train Loss 13.265158 Test MSE 4.5390331975362495 Test RE 1.0183328174012287\n",
      "95 Train Loss 13.100512 Test MSE 4.453509775644065 Test RE 1.0086935998741453\n",
      "96 Train Loss 12.861336 Test MSE 4.482401935177137 Test RE 1.0119602618669812\n",
      "97 Train Loss 12.537585 Test MSE 4.445318137275703 Test RE 1.0077654940975584\n",
      "98 Train Loss 12.212145 Test MSE 4.4818820547397715 Test RE 1.0119015752959655\n",
      "99 Train Loss 11.984716 Test MSE 4.449727910656618 Test RE 1.0082652238962386\n",
      "Training time: 74.05\n",
      "KG_stan_tune6\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 207.07736 Test MSE 5.54192071846899 Test RE 1.1252219994628754\n",
      "1 Train Loss 142.55334 Test MSE 5.487925546773996 Test RE 1.1197270391476117\n",
      "2 Train Loss 121.203094 Test MSE 5.390479030657238 Test RE 1.1097412789542302\n",
      "3 Train Loss 110.83688 Test MSE 5.328556630085827 Test RE 1.1033488663267488\n",
      "4 Train Loss 96.77226 Test MSE 5.406785082473404 Test RE 1.1114184800671238\n",
      "5 Train Loss 87.735115 Test MSE 5.4558198166783205 Test RE 1.116446893784662\n",
      "6 Train Loss 81.9241 Test MSE 5.6500028906634325 Test RE 1.1361414257587548\n",
      "7 Train Loss 76.11812 Test MSE 5.739250388677342 Test RE 1.145079517753175\n",
      "8 Train Loss 72.44795 Test MSE 5.565951186097808 Test RE 1.1276589129259436\n",
      "9 Train Loss 70.3732 Test MSE 5.480509576454654 Test RE 1.1189702258838097\n",
      "10 Train Loss 67.50779 Test MSE 5.670427279896489 Test RE 1.1381931115577306\n",
      "11 Train Loss 65.99939 Test MSE 5.7368520415226385 Test RE 1.144840236924971\n",
      "12 Train Loss 64.98825 Test MSE 5.7103022542850095 Test RE 1.1421880408301976\n",
      "13 Train Loss 63.822388 Test MSE 5.565790444767192 Test RE 1.1276426297519824\n",
      "14 Train Loss 62.210823 Test MSE 5.440924409449036 Test RE 1.114921797839614\n",
      "15 Train Loss 61.251976 Test MSE 5.251789929806457 Test RE 1.0953722473546637\n",
      "16 Train Loss 59.241577 Test MSE 5.254163652361247 Test RE 1.0956197644972816\n",
      "17 Train Loss 57.852264 Test MSE 5.177239713962494 Test RE 1.08756994473671\n",
      "18 Train Loss 57.056633 Test MSE 5.143173705939326 Test RE 1.08398595835403\n",
      "19 Train Loss 55.240417 Test MSE 5.058559543935266 Test RE 1.0750322514690291\n",
      "20 Train Loss 53.969997 Test MSE 5.065755733743684 Test RE 1.075796637724418\n",
      "21 Train Loss 53.170914 Test MSE 5.076194945902849 Test RE 1.0769045365367627\n",
      "22 Train Loss 51.93512 Test MSE 5.259097900453377 Test RE 1.0961340986008632\n",
      "23 Train Loss 50.233063 Test MSE 5.321513857898401 Test RE 1.1026194751833778\n",
      "24 Train Loss 46.815956 Test MSE 5.534564936346626 Test RE 1.124474998866239\n",
      "25 Train Loss 43.807392 Test MSE 6.10926689610135 Test RE 1.1814153507762835\n",
      "26 Train Loss 41.6324 Test MSE 6.239977475650508 Test RE 1.1939869258281512\n",
      "27 Train Loss 40.34338 Test MSE 6.338039381658142 Test RE 1.2033321689923768\n",
      "28 Train Loss 39.32676 Test MSE 6.322015296923386 Test RE 1.2018100500469489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Train Loss 38.115807 Test MSE 6.447233126187548 Test RE 1.2136535969853879\n",
      "30 Train Loss 37.39325 Test MSE 6.4376980630604645 Test RE 1.2127558052296576\n",
      "31 Train Loss 36.38344 Test MSE 6.41915791560763 Test RE 1.211008217568661\n",
      "32 Train Loss 35.404423 Test MSE 6.378735769525163 Test RE 1.2071892697681932\n",
      "33 Train Loss 34.0163 Test MSE 6.115317959200262 Test RE 1.182000285896443\n",
      "34 Train Loss 32.71905 Test MSE 6.0163969280678025 Test RE 1.1724013252985106\n",
      "35 Train Loss 32.01177 Test MSE 6.05424066839455 Test RE 1.1760828061366482\n",
      "36 Train Loss 30.948643 Test MSE 5.945875278436324 Test RE 1.1655098759014624\n",
      "37 Train Loss 29.754833 Test MSE 6.0264406473845575 Test RE 1.173379515375875\n",
      "38 Train Loss 28.667171 Test MSE 5.857916235888364 Test RE 1.1568568938025472\n",
      "39 Train Loss 27.687918 Test MSE 5.808082569495083 Test RE 1.151925656187999\n",
      "40 Train Loss 26.69214 Test MSE 5.780428994253097 Test RE 1.1491800968760344\n",
      "41 Train Loss 26.120106 Test MSE 5.776453602892362 Test RE 1.1487848644140004\n",
      "42 Train Loss 25.444698 Test MSE 5.765409385157094 Test RE 1.1476861366093996\n",
      "43 Train Loss 24.934643 Test MSE 5.756121548142832 Test RE 1.1467613264578558\n",
      "44 Train Loss 24.450516 Test MSE 5.696741900899059 Test RE 1.1408310478990606\n",
      "45 Train Loss 23.854816 Test MSE 5.796501767548206 Test RE 1.1507766643162802\n",
      "46 Train Loss 23.049637 Test MSE 5.792608263805084 Test RE 1.1503901116955646\n",
      "47 Train Loss 22.65719 Test MSE 5.792357890836274 Test RE 1.1503652498641723\n",
      "48 Train Loss 21.894344 Test MSE 5.772759960586089 Test RE 1.1484175214737677\n",
      "49 Train Loss 21.251251 Test MSE 5.765569019955212 Test RE 1.147702025279596\n",
      "50 Train Loss 20.8044 Test MSE 5.824888233897563 Test RE 1.153590998603344\n",
      "51 Train Loss 20.247416 Test MSE 5.80446415017589 Test RE 1.1515667770409204\n",
      "52 Train Loss 19.718086 Test MSE 5.785370513703156 Test RE 1.1496711921465386\n",
      "53 Train Loss 19.367224 Test MSE 5.819281430182592 Test RE 1.153035664729493\n",
      "54 Train Loss 19.12032 Test MSE 5.7446200920711235 Test RE 1.1456150667728888\n",
      "55 Train Loss 18.859299 Test MSE 5.718348814775971 Test RE 1.1429925034763222\n",
      "56 Train Loss 18.583681 Test MSE 5.638485896311745 Test RE 1.1349828768570658\n",
      "57 Train Loss 18.429272 Test MSE 5.6636752538037145 Test RE 1.1375152615192232\n",
      "58 Train Loss 18.17509 Test MSE 5.668395512913575 Test RE 1.1379891806845661\n",
      "59 Train Loss 17.971434 Test MSE 5.628394144176009 Test RE 1.1339667267996014\n",
      "60 Train Loss 17.722229 Test MSE 5.63823331862119 Test RE 1.1349574556207993\n",
      "61 Train Loss 17.507061 Test MSE 5.598373385092156 Test RE 1.130938504487757\n",
      "62 Train Loss 17.266125 Test MSE 5.613514787950893 Test RE 1.1324668441979815\n",
      "63 Train Loss 17.152676 Test MSE 5.562079831350226 Test RE 1.1272666774469005\n",
      "64 Train Loss 17.01043 Test MSE 5.5714948418252455 Test RE 1.1282203440972753\n",
      "65 Train Loss 16.884762 Test MSE 5.554651351458407 Test RE 1.1265136609567992\n",
      "66 Train Loss 16.740242 Test MSE 5.567808121535597 Test RE 1.127847004332507\n",
      "67 Train Loss 16.512682 Test MSE 5.541405582720881 Test RE 1.125169702111798\n",
      "68 Train Loss 16.381418 Test MSE 5.54037697229198 Test RE 1.1250652687703195\n",
      "69 Train Loss 16.234297 Test MSE 5.508790250403639 Test RE 1.1218535812107586\n",
      "70 Train Loss 16.12661 Test MSE 5.468226573498058 Test RE 1.1177155958137752\n",
      "71 Train Loss 15.938677 Test MSE 5.462207913389337 Test RE 1.117100313850304\n",
      "72 Train Loss 15.852007 Test MSE 5.433375414167057 Test RE 1.1141480818162828\n",
      "73 Train Loss 15.722102 Test MSE 5.4278776475946575 Test RE 1.1135842632065156\n",
      "74 Train Loss 15.542739 Test MSE 5.373126866780612 Test RE 1.107953688815826\n",
      "75 Train Loss 15.325929 Test MSE 5.34270355050195 Test RE 1.1048125499507448\n",
      "76 Train Loss 15.208802 Test MSE 5.358012810932711 Test RE 1.1063943112966237\n",
      "77 Train Loss 15.096386 Test MSE 5.288720607524243 Test RE 1.0992168386914059\n",
      "78 Train Loss 14.992672 Test MSE 5.258828504797932 Test RE 1.0961060236770628\n",
      "79 Train Loss 14.842606 Test MSE 5.286728275918622 Test RE 1.0990097743651235\n",
      "80 Train Loss 14.7384205 Test MSE 5.268100896010513 Test RE 1.0970719277472134\n",
      "81 Train Loss 14.497955 Test MSE 5.248179871057146 Test RE 1.0949957054514068\n",
      "82 Train Loss 14.334712 Test MSE 5.276286145885881 Test RE 1.097923878258076\n",
      "83 Train Loss 14.16087 Test MSE 5.298749829120875 Test RE 1.1002585904278344\n",
      "84 Train Loss 13.840029 Test MSE 5.271711069254531 Test RE 1.0974477692020648\n",
      "85 Train Loss 13.711725 Test MSE 5.2985157232505875 Test RE 1.1002342847096698\n",
      "86 Train Loss 13.612228 Test MSE 5.278543409160161 Test RE 1.0981587061440157\n",
      "87 Train Loss 13.448378 Test MSE 5.220155125836372 Test RE 1.0920682093963427\n",
      "88 Train Loss 13.184429 Test MSE 5.211347470960529 Test RE 1.0911465298400331\n",
      "89 Train Loss 12.983951 Test MSE 5.133558530125998 Test RE 1.0829722271399191\n",
      "90 Train Loss 12.862898 Test MSE 5.123698596725675 Test RE 1.081931704646792\n",
      "91 Train Loss 12.732795 Test MSE 5.148256549320664 Test RE 1.0845214613883312\n",
      "92 Train Loss 12.480257 Test MSE 5.100889077609349 Test RE 1.0795207637703637\n",
      "93 Train Loss 12.321722 Test MSE 5.184234310296183 Test RE 1.088304365542644\n",
      "94 Train Loss 12.058368 Test MSE 5.16881268925717 Test RE 1.0866844621426104\n",
      "95 Train Loss 11.898679 Test MSE 5.177630664734908 Test RE 1.0876110069925575\n",
      "96 Train Loss 11.727117 Test MSE 5.213123684710397 Test RE 1.0913324648946507\n",
      "97 Train Loss 11.5463085 Test MSE 5.140770927277285 Test RE 1.0837327214665309\n",
      "98 Train Loss 11.301448 Test MSE 5.120980429893134 Test RE 1.0816446794674193\n",
      "99 Train Loss 11.086048 Test MSE 5.083830435394888 Test RE 1.0777141590581176\n",
      "Training time: 75.95\n",
      "KG_stan_tune6\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 365.82635 Test MSE 6.405884085460416 Test RE 1.2097554803551935\n",
      "1 Train Loss 163.19846 Test MSE 6.414055898959976 Test RE 1.2105268606401238\n",
      "2 Train Loss 123.129234 Test MSE 6.416227061250069 Test RE 1.2107317253882546\n",
      "3 Train Loss 114.20433 Test MSE 6.39774489057963 Test RE 1.2089866898850983\n",
      "4 Train Loss 105.478264 Test MSE 6.335413110557688 Test RE 1.2030828328999863\n",
      "5 Train Loss 99.67194 Test MSE 6.271215471473934 Test RE 1.1969718080716973\n",
      "6 Train Loss 94.84516 Test MSE 6.269764643297553 Test RE 1.1968333420211832\n",
      "7 Train Loss 89.22932 Test MSE 6.217309576801075 Test RE 1.1918162609854341\n",
      "8 Train Loss 84.977486 Test MSE 6.078536844894039 Test RE 1.1784403028564243\n",
      "9 Train Loss 82.68846 Test MSE 5.982318053647937 Test RE 1.1690761742840161\n",
      "10 Train Loss 79.62959 Test MSE 5.990684484616845 Test RE 1.1698933807302128\n",
      "11 Train Loss 78.60611 Test MSE 5.987208265888178 Test RE 1.1695539040456777\n",
      "12 Train Loss 75.72012 Test MSE 5.9731569593427905 Test RE 1.1681806919344402\n",
      "13 Train Loss 74.14942 Test MSE 5.972116622401349 Test RE 1.1680789572522738\n",
      "14 Train Loss 72.07942 Test MSE 6.028386364664178 Test RE 1.1735689207548048\n",
      "15 Train Loss 68.99603 Test MSE 6.17087771209719 Test RE 1.1873575833981995\n",
      "16 Train Loss 66.30733 Test MSE 6.287914027488331 Test RE 1.1985643552498346\n",
      "17 Train Loss 63.44674 Test MSE 6.423517459926543 Test RE 1.2114193733612604\n",
      "18 Train Loss 58.702892 Test MSE 6.348320915638611 Test RE 1.2043077930313806\n",
      "19 Train Loss 54.557003 Test MSE 6.146966472710869 Test RE 1.18505493302398\n",
      "20 Train Loss 51.58788 Test MSE 6.066475595043655 Test RE 1.1772705706487923\n",
      "21 Train Loss 49.895714 Test MSE 6.061741968592774 Test RE 1.1768111732156497\n",
      "22 Train Loss 47.780346 Test MSE 5.995790404372285 Test RE 1.170391830405602\n",
      "23 Train Loss 45.75075 Test MSE 5.926179699307302 Test RE 1.1635779119544731\n",
      "24 Train Loss 43.576992 Test MSE 5.899158610325056 Test RE 1.1609221484019285\n",
      "25 Train Loss 42.159554 Test MSE 5.946494878622079 Test RE 1.1655706013026474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 41.18251 Test MSE 5.9436701031745205 Test RE 1.1652937267416794\n",
      "27 Train Loss 40.25124 Test MSE 5.977540343996703 Test RE 1.1686092464045124\n",
      "28 Train Loss 38.930946 Test MSE 6.093438099125705 Test RE 1.179883864863108\n",
      "29 Train Loss 37.786064 Test MSE 6.117647559594283 Test RE 1.18222540306603\n",
      "30 Train Loss 36.674637 Test MSE 6.241311553992779 Test RE 1.1941145534499533\n",
      "31 Train Loss 35.18096 Test MSE 6.381362920510472 Test RE 1.207437841123904\n",
      "32 Train Loss 34.327095 Test MSE 6.331454078537754 Test RE 1.202706867850818\n",
      "33 Train Loss 33.298355 Test MSE 6.1748231768641775 Test RE 1.1877371022576013\n",
      "34 Train Loss 32.00111 Test MSE 6.201533610775359 Test RE 1.190303227496207\n",
      "35 Train Loss 31.087254 Test MSE 6.2054999285666455 Test RE 1.1906838080536488\n",
      "36 Train Loss 30.230854 Test MSE 6.27427804844224 Test RE 1.197264045745735\n",
      "37 Train Loss 29.263103 Test MSE 6.319227202330415 Test RE 1.2015450135467913\n",
      "38 Train Loss 28.612785 Test MSE 6.304120254037412 Test RE 1.2001079280224445\n",
      "39 Train Loss 27.979853 Test MSE 6.249176206945187 Test RE 1.1948666661946334\n",
      "40 Train Loss 27.627518 Test MSE 6.253497295246107 Test RE 1.1952796992072783\n",
      "41 Train Loss 27.00766 Test MSE 6.35010256164662 Test RE 1.204476774694263\n",
      "42 Train Loss 26.581068 Test MSE 6.295420534105596 Test RE 1.1992795644324046\n",
      "43 Train Loss 25.79945 Test MSE 6.100095136864442 Test RE 1.180528196290137\n",
      "44 Train Loss 25.31459 Test MSE 6.017778077021023 Test RE 1.1725358882239758\n",
      "45 Train Loss 24.662548 Test MSE 5.962678327746388 Test RE 1.1671555800518432\n",
      "46 Train Loss 24.328014 Test MSE 5.954080425168624 Test RE 1.1663137846738767\n",
      "47 Train Loss 23.645473 Test MSE 5.809812653970546 Test RE 1.1520972085275054\n",
      "48 Train Loss 23.272413 Test MSE 5.815193712313751 Test RE 1.152630622239125\n",
      "49 Train Loss 22.968317 Test MSE 5.7196174317895165 Test RE 1.1431192830214627\n",
      "50 Train Loss 22.745644 Test MSE 5.684942306735692 Test RE 1.1396489405281087\n",
      "51 Train Loss 22.408636 Test MSE 5.662793091198596 Test RE 1.1374266695308686\n",
      "52 Train Loss 22.305809 Test MSE 5.626154300120368 Test RE 1.1337410708389954\n",
      "53 Train Loss 21.879925 Test MSE 5.653948172418329 Test RE 1.1365380287256963\n",
      "54 Train Loss 21.677734 Test MSE 5.696427971391134 Test RE 1.1407996136626268\n",
      "55 Train Loss 21.387619 Test MSE 5.6911793412364124 Test RE 1.1402739320288904\n",
      "56 Train Loss 21.014202 Test MSE 5.759333981281245 Test RE 1.147081279764396\n",
      "57 Train Loss 20.779842 Test MSE 5.74492768303874 Test RE 1.1456457368715547\n",
      "58 Train Loss 20.491573 Test MSE 5.72899041604949 Test RE 1.1440555390922733\n",
      "59 Train Loss 20.008345 Test MSE 5.721144055078224 Test RE 1.1432718278471057\n",
      "60 Train Loss 19.590961 Test MSE 5.778578377499215 Test RE 1.14899612591245\n",
      "61 Train Loss 19.248302 Test MSE 5.788514030421424 Test RE 1.1499834901933155\n",
      "62 Train Loss 18.877771 Test MSE 5.730594200437071 Test RE 1.1442156624199646\n",
      "63 Train Loss 18.669561 Test MSE 5.741140706528093 Test RE 1.145268077748111\n",
      "64 Train Loss 18.376461 Test MSE 5.724314004920511 Test RE 1.143588513849558\n",
      "65 Train Loss 18.12502 Test MSE 5.658462863929874 Test RE 1.1369917023835048\n",
      "66 Train Loss 17.92274 Test MSE 5.610600688780772 Test RE 1.1321728617985327\n",
      "67 Train Loss 17.69732 Test MSE 5.627008177539955 Test RE 1.1338271011111984\n",
      "68 Train Loss 17.575684 Test MSE 5.6495661324678 Test RE 1.1360975117397012\n",
      "69 Train Loss 17.430904 Test MSE 5.647826131408506 Test RE 1.1359225458166813\n",
      "70 Train Loss 17.09808 Test MSE 5.756885970711513 Test RE 1.1468374698410013\n",
      "71 Train Loss 16.89197 Test MSE 5.74035463701533 Test RE 1.1451896707569211\n",
      "72 Train Loss 16.662224 Test MSE 5.7346769652466865 Test RE 1.1446231883683733\n",
      "73 Train Loss 16.438473 Test MSE 5.692538968451512 Test RE 1.1404101300639513\n",
      "74 Train Loss 16.261997 Test MSE 5.730315646745222 Test RE 1.1441878529678249\n",
      "75 Train Loss 16.049305 Test MSE 5.692613017309908 Test RE 1.1404175472985176\n",
      "76 Train Loss 15.902998 Test MSE 5.692524059494033 Test RE 1.1404086366760826\n",
      "77 Train Loss 15.71666 Test MSE 5.689968186192976 Test RE 1.1401525932057015\n",
      "78 Train Loss 15.573704 Test MSE 5.742321120033567 Test RE 1.1453858087438664\n",
      "79 Train Loss 15.415195 Test MSE 5.728651632848971 Test RE 1.1440217117946951\n",
      "80 Train Loss 15.245192 Test MSE 5.6999424587615755 Test RE 1.1411514751838694\n",
      "81 Train Loss 15.084323 Test MSE 5.743135496430035 Test RE 1.1454670252135457\n",
      "82 Train Loss 14.8816805 Test MSE 5.7344315434534385 Test RE 1.1445986954036633\n",
      "83 Train Loss 14.7002125 Test MSE 5.7419824291897745 Test RE 1.1453520299462083\n",
      "84 Train Loss 14.523053 Test MSE 5.730517229614196 Test RE 1.1442079780931969\n",
      "85 Train Loss 14.323788 Test MSE 5.682852473289038 Test RE 1.1394394489214879\n",
      "86 Train Loss 14.060124 Test MSE 5.606443036663774 Test RE 1.131753294133085\n",
      "87 Train Loss 13.792214 Test MSE 5.551870068386691 Test RE 1.126231595938002\n",
      "88 Train Loss 13.451521 Test MSE 5.59508884810078 Test RE 1.1306066978992297\n",
      "89 Train Loss 13.166306 Test MSE 5.488341753274828 Test RE 1.1197694986191455\n",
      "90 Train Loss 12.789879 Test MSE 5.398400452977738 Test RE 1.1105563736904736\n",
      "91 Train Loss 12.547373 Test MSE 5.340410518374837 Test RE 1.1045754375478307\n",
      "92 Train Loss 12.262778 Test MSE 5.245702345794722 Test RE 1.0947372158574702\n",
      "93 Train Loss 12.023087 Test MSE 5.245659959609674 Test RE 1.094732793015219\n",
      "94 Train Loss 11.717615 Test MSE 5.276072283626222 Test RE 1.0979016271088387\n",
      "95 Train Loss 11.453716 Test MSE 5.254783330159252 Test RE 1.0956843714709958\n",
      "96 Train Loss 11.129113 Test MSE 5.2616940397591945 Test RE 1.0964046170208712\n",
      "97 Train Loss 10.831717 Test MSE 5.254770946683081 Test RE 1.0956830804197333\n",
      "98 Train Loss 10.480855 Test MSE 5.179212725402304 Test RE 1.0877771578139177\n",
      "99 Train Loss 10.121404 Test MSE 5.091119697532578 Test RE 1.078486502590787\n",
      "Training time: 75.64\n",
      "KG_stan_tune6\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 653.47485 Test MSE 6.553980356197833 Test RE 1.2236596175640648\n",
      "1 Train Loss 436.9872 Test MSE 6.699925596190409 Test RE 1.2372089418728252\n",
      "2 Train Loss 332.80353 Test MSE 6.827301082071294 Test RE 1.2489141555422396\n",
      "3 Train Loss 301.3018 Test MSE 6.817238382237469 Test RE 1.247993434286995\n",
      "4 Train Loss 266.9947 Test MSE 6.76334803163853 Test RE 1.2430509458192314\n",
      "5 Train Loss 243.36557 Test MSE 6.774400273614002 Test RE 1.2440661894314116\n",
      "6 Train Loss 226.22469 Test MSE 6.79452316686577 Test RE 1.2459125261604271\n",
      "7 Train Loss 209.01143 Test MSE 6.7908061768354795 Test RE 1.245571687086148\n",
      "8 Train Loss 194.70876 Test MSE 6.822521213804717 Test RE 1.2484768897554097\n",
      "9 Train Loss 181.57248 Test MSE 6.856514002794995 Test RE 1.2515832545979069\n",
      "10 Train Loss 175.36024 Test MSE 6.869976392821659 Test RE 1.2528113596784451\n",
      "11 Train Loss 168.37767 Test MSE 6.883581535754553 Test RE 1.2540512654849687\n",
      "12 Train Loss 160.54086 Test MSE 6.94939387981395 Test RE 1.26003185297668\n",
      "13 Train Loss 155.4362 Test MSE 6.974757438944399 Test RE 1.2623291601629334\n",
      "14 Train Loss 144.64755 Test MSE 7.13665669211958 Test RE 1.276895813511301\n",
      "15 Train Loss 138.74602 Test MSE 7.11307190582544 Test RE 1.2747841638837771\n",
      "16 Train Loss 128.77246 Test MSE 7.0921229025403845 Test RE 1.2729055698081782\n",
      "17 Train Loss 119.7609 Test MSE 7.165705289266082 Test RE 1.2794918725651103\n",
      "18 Train Loss 114.391365 Test MSE 7.097966246339787 Test RE 1.2734298481883426\n",
      "19 Train Loss 109.15277 Test MSE 7.047224685466148 Test RE 1.2688699706781876\n",
      "20 Train Loss 104.153534 Test MSE 6.888772685970756 Test RE 1.254524038385082\n",
      "21 Train Loss 100.17173 Test MSE 6.7758458392806356 Test RE 1.244198915825675\n",
      "22 Train Loss 97.39824 Test MSE 6.672274232774699 Test RE 1.2346532504483547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Train Loss 94.312 Test MSE 6.564653126155406 Test RE 1.2246555409896942\n",
      "24 Train Loss 91.17018 Test MSE 6.546597405703905 Test RE 1.2229702071947028\n",
      "25 Train Loss 88.7025 Test MSE 6.4863345127540235 Test RE 1.2173283363987042\n",
      "26 Train Loss 85.92386 Test MSE 6.412710829479725 Test RE 1.2103999262842995\n",
      "27 Train Loss 84.658325 Test MSE 6.3879123723341955 Test RE 1.208057303456633\n",
      "28 Train Loss 81.644684 Test MSE 6.33060594660518 Test RE 1.2026263106636217\n",
      "29 Train Loss 78.624344 Test MSE 6.111274963363429 Test RE 1.1816094957217504\n",
      "30 Train Loss 76.92198 Test MSE 6.107496185863477 Test RE 1.1812441276249088\n",
      "31 Train Loss 75.21848 Test MSE 6.010177416307524 Test RE 1.1717951776842348\n",
      "32 Train Loss 73.90403 Test MSE 6.082384085954814 Test RE 1.1788131743949708\n",
      "33 Train Loss 71.445175 Test MSE 6.172185137440619 Test RE 1.1874833596047234\n",
      "34 Train Loss 70.53663 Test MSE 6.130124781660469 Test RE 1.1834303903691372\n",
      "35 Train Loss 68.70738 Test MSE 6.2457135078649335 Test RE 1.1945355795941694\n",
      "36 Train Loss 67.48568 Test MSE 6.323285263964892 Test RE 1.2019307538447854\n",
      "37 Train Loss 66.510765 Test MSE 6.401423236005641 Test RE 1.2093341898023635\n",
      "38 Train Loss 65.0607 Test MSE 6.530066711869735 Test RE 1.2214251813548664\n",
      "39 Train Loss 64.49569 Test MSE 6.533803844494042 Test RE 1.2217746398827607\n",
      "40 Train Loss 63.769394 Test MSE 6.5979192633040835 Test RE 1.2277545682504607\n",
      "41 Train Loss 62.22532 Test MSE 6.685714314502162 Test RE 1.2358961169808385\n",
      "42 Train Loss 60.95104 Test MSE 6.824709874589427 Test RE 1.2486771290227754\n",
      "43 Train Loss 60.081966 Test MSE 6.882970368786309 Test RE 1.2539955930331408\n",
      "44 Train Loss 58.830242 Test MSE 6.873731103947282 Test RE 1.253153668147545\n",
      "45 Train Loss 57.950462 Test MSE 6.939835015123987 Test RE 1.2591649702795016\n",
      "46 Train Loss 57.012177 Test MSE 7.084678822244739 Test RE 1.2722373566955687\n",
      "47 Train Loss 55.430542 Test MSE 7.164392165802129 Test RE 1.279374633039447\n",
      "48 Train Loss 54.844963 Test MSE 7.1466371620244695 Test RE 1.2777883580414104\n",
      "49 Train Loss 53.695602 Test MSE 7.198894961011713 Test RE 1.2824515851360805\n",
      "50 Train Loss 53.00764 Test MSE 7.442437473812715 Test RE 1.3039641685030654\n",
      "51 Train Loss 52.164238 Test MSE 7.445605713562793 Test RE 1.3042416872292697\n",
      "52 Train Loss 51.817127 Test MSE 7.470962863713494 Test RE 1.3064606969108934\n",
      "53 Train Loss 50.88341 Test MSE 7.596143763891917 Test RE 1.3173605325498936\n",
      "54 Train Loss 50.49681 Test MSE 7.649831953148258 Test RE 1.3220077701846558\n",
      "55 Train Loss 49.96559 Test MSE 7.774990383704109 Test RE 1.332778537903266\n",
      "56 Train Loss 49.407043 Test MSE 7.898510567786193 Test RE 1.3433236537957038\n",
      "57 Train Loss 48.435074 Test MSE 8.017491642877909 Test RE 1.3534035715763606\n",
      "58 Train Loss 47.97785 Test MSE 8.102593380235605 Test RE 1.3605674686529534\n",
      "59 Train Loss 47.36209 Test MSE 8.136596844407238 Test RE 1.3634193685651483\n",
      "60 Train Loss 46.80784 Test MSE 8.154201066428023 Test RE 1.3648935087490415\n",
      "61 Train Loss 46.10845 Test MSE 8.219140956750609 Test RE 1.3703177225614624\n",
      "62 Train Loss 45.789047 Test MSE 8.212796127863726 Test RE 1.369788706810468\n",
      "63 Train Loss 45.440086 Test MSE 8.232221848815598 Test RE 1.3714077301435421\n",
      "64 Train Loss 45.00988 Test MSE 8.26992981386781 Test RE 1.3745450309036615\n",
      "65 Train Loss 44.66236 Test MSE 8.242733914350834 Test RE 1.372283054505162\n",
      "66 Train Loss 44.382996 Test MSE 8.280979147417305 Test RE 1.3754629792539523\n",
      "67 Train Loss 43.96605 Test MSE 8.274799075247557 Test RE 1.3749496313220861\n",
      "68 Train Loss 43.625595 Test MSE 8.268919368684514 Test RE 1.3744610552917378\n",
      "69 Train Loss 42.925026 Test MSE 8.273096445359753 Test RE 1.37480816862609\n",
      "70 Train Loss 42.802998 Test MSE 8.215001233914768 Test RE 1.3699725861248888\n",
      "71 Train Loss 42.652885 Test MSE 8.219959001900113 Test RE 1.3703859142302077\n",
      "72 Train Loss 42.44112 Test MSE 8.215001113785094 Test RE 1.369972576108192\n",
      "73 Train Loss 42.104008 Test MSE 8.21137142865263 Test RE 1.3696698909101508\n",
      "74 Train Loss 41.941757 Test MSE 8.222286399724517 Test RE 1.3705799059193813\n",
      "75 Train Loss 41.689503 Test MSE 8.262929365924132 Test RE 1.373963135509921\n",
      "76 Train Loss 41.45269 Test MSE 8.30195104080663 Test RE 1.377203583963961\n",
      "77 Train Loss 41.149746 Test MSE 8.278676548139826 Test RE 1.375271736153392\n",
      "78 Train Loss 40.94337 Test MSE 8.334623060297686 Test RE 1.379910889690791\n",
      "79 Train Loss 40.846783 Test MSE 8.329387862903406 Test RE 1.3794774423344303\n",
      "80 Train Loss 40.643486 Test MSE 8.266337990699537 Test RE 1.374246500021764\n",
      "81 Train Loss 40.349262 Test MSE 8.230896802721153 Test RE 1.3712973558352108\n",
      "82 Train Loss 40.255 Test MSE 8.21018966577042 Test RE 1.369571327394089\n",
      "83 Train Loss 40.089622 Test MSE 8.21830272863198 Test RE 1.3702478449343483\n",
      "84 Train Loss 39.88063 Test MSE 8.16607673209422 Test RE 1.3658870531498803\n",
      "85 Train Loss 39.652782 Test MSE 8.220587236062707 Test RE 1.3704382810849602\n",
      "86 Train Loss 39.481655 Test MSE 8.204007688199916 Test RE 1.3690556113178056\n",
      "87 Train Loss 39.31685 Test MSE 8.241695984374706 Test RE 1.3721966524343276\n",
      "88 Train Loss 39.160263 Test MSE 8.26907428449526 Test RE 1.3744739302964368\n",
      "89 Train Loss 39.04917 Test MSE 8.242540186959989 Test RE 1.3722669281579767\n",
      "90 Train Loss 38.972065 Test MSE 8.274544919832513 Test RE 1.3749285157895896\n",
      "91 Train Loss 38.818592 Test MSE 8.294162779895112 Test RE 1.3765574384041428\n",
      "92 Train Loss 38.70168 Test MSE 8.301018149894642 Test RE 1.377126203550858\n",
      "93 Train Loss 38.56307 Test MSE 8.294354305849303 Test RE 1.376573331807847\n",
      "94 Train Loss 38.382893 Test MSE 8.265447730576174 Test RE 1.3741724968899103\n",
      "95 Train Loss 38.289402 Test MSE 8.283807485293691 Test RE 1.3756978513537408\n",
      "96 Train Loss 38.16507 Test MSE 8.305525866304395 Test RE 1.3775000644290616\n",
      "97 Train Loss 38.02152 Test MSE 8.32209178454393 Test RE 1.3788731373908274\n",
      "98 Train Loss 37.914406 Test MSE 8.35596052528825 Test RE 1.3816761152687518\n",
      "99 Train Loss 37.802765 Test MSE 8.369120057680819 Test RE 1.382763665797914\n",
      "Training time: 75.57\n",
      "KG_stan_tune6\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 1754.2367 Test MSE 5.327020983666618 Test RE 1.1031898668128413\n",
      "1 Train Loss 1176.9825 Test MSE 5.327883097503738 Test RE 1.103279132161633\n",
      "2 Train Loss 1048.9222 Test MSE 5.333241787890473 Test RE 1.1038338220205448\n",
      "3 Train Loss 776.64716 Test MSE 5.337244640363545 Test RE 1.1042479843030972\n",
      "4 Train Loss 612.0766 Test MSE 5.332435639182406 Test RE 1.10375039360364\n",
      "5 Train Loss 448.774 Test MSE 5.329446140834795 Test RE 1.1034409550281885\n",
      "6 Train Loss 405.45294 Test MSE 5.330866844357083 Test RE 1.1035880207784152\n",
      "7 Train Loss 387.80704 Test MSE 5.326314402901035 Test RE 1.103116700347669\n",
      "8 Train Loss 358.14474 Test MSE 5.322418511219481 Test RE 1.1027131934379275\n",
      "9 Train Loss 335.90897 Test MSE 5.316457130174061 Test RE 1.1020954728222074\n",
      "10 Train Loss 303.6946 Test MSE 5.332696929987076 Test RE 1.1037774353079552\n",
      "11 Train Loss 286.88437 Test MSE 5.336915418846447 Test RE 1.1042139266734134\n",
      "12 Train Loss 263.0883 Test MSE 5.365201711124804 Test RE 1.1071362927397723\n",
      "13 Train Loss 251.20761 Test MSE 5.373482159280927 Test RE 1.107990319360658\n",
      "14 Train Loss 241.76921 Test MSE 5.380372931881033 Test RE 1.1087005164905717\n",
      "15 Train Loss 228.22212 Test MSE 5.398689207686267 Test RE 1.110586074533965\n",
      "16 Train Loss 220.14735 Test MSE 5.403025238797621 Test RE 1.1110319762202854\n",
      "17 Train Loss 211.93939 Test MSE 5.423469133725716 Test RE 1.1131319456328657\n",
      "18 Train Loss 204.32535 Test MSE 5.4344449326987485 Test RE 1.1142577321989688\n",
      "19 Train Loss 193.11626 Test MSE 5.440121974896961 Test RE 1.1148395797554567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 187.21498 Test MSE 5.431710990770062 Test RE 1.1139774184594702\n",
      "21 Train Loss 183.17537 Test MSE 5.436261830431629 Test RE 1.1144439815021374\n",
      "22 Train Loss 176.03725 Test MSE 5.448270175262884 Test RE 1.1156741692540588\n",
      "23 Train Loss 173.91687 Test MSE 5.452722435610373 Test RE 1.1161299338656303\n",
      "24 Train Loss 167.80618 Test MSE 5.501292051345582 Test RE 1.121089824972401\n",
      "25 Train Loss 161.6505 Test MSE 5.510802713073218 Test RE 1.1220584794002115\n",
      "26 Train Loss 156.27573 Test MSE 5.510139377127163 Test RE 1.1219909462148496\n",
      "27 Train Loss 148.75037 Test MSE 5.515843820577491 Test RE 1.1225715738375104\n",
      "28 Train Loss 144.31541 Test MSE 5.53366520058716 Test RE 1.1243835940764775\n",
      "29 Train Loss 138.2743 Test MSE 5.547025843686356 Test RE 1.1257401480609928\n",
      "30 Train Loss 135.5914 Test MSE 5.560608967450744 Test RE 1.127117617604014\n",
      "31 Train Loss 130.00703 Test MSE 5.5511493192466785 Test RE 1.126158489327901\n",
      "32 Train Loss 126.824844 Test MSE 5.556639609137605 Test RE 1.1267152576817983\n",
      "33 Train Loss 124.37252 Test MSE 5.567488981710841 Test RE 1.1278146804767417\n",
      "34 Train Loss 120.14852 Test MSE 5.595147403910379 Test RE 1.1306126141070965\n",
      "35 Train Loss 118.18183 Test MSE 5.6029081688373825 Test RE 1.1313964520966242\n",
      "36 Train Loss 116.01414 Test MSE 5.593111729602487 Test RE 1.1304069208280945\n",
      "37 Train Loss 115.482155 Test MSE 5.60658377423833 Test RE 1.13176749914801\n",
      "38 Train Loss 113.99849 Test MSE 5.616163913621763 Test RE 1.1327340291293657\n",
      "39 Train Loss 112.22735 Test MSE 5.641609903872419 Test RE 1.1352972523974099\n",
      "40 Train Loss 110.331024 Test MSE 5.65211524069507 Test RE 1.1363537888452397\n",
      "41 Train Loss 108.43725 Test MSE 5.687081056413394 Test RE 1.1398632957904997\n",
      "42 Train Loss 106.24871 Test MSE 5.626487437073363 Test RE 1.1337746359915726\n",
      "43 Train Loss 105.235115 Test MSE 5.626121334159188 Test RE 1.1337377493055925\n",
      "44 Train Loss 104.57084 Test MSE 5.629314378979161 Test RE 1.1340594240211384\n",
      "45 Train Loss 102.22647 Test MSE 5.663405064527122 Test RE 1.1374881282464404\n",
      "46 Train Loss 99.13882 Test MSE 5.723498417439491 Test RE 1.143507042978199\n",
      "47 Train Loss 98.0693 Test MSE 5.7175249888219435 Test RE 1.1429101667007133\n",
      "48 Train Loss 95.455475 Test MSE 5.791500947002966 Test RE 1.1502801519740808\n",
      "49 Train Loss 92.183426 Test MSE 5.835855723819576 Test RE 1.1546765170919715\n",
      "50 Train Loss 90.1495 Test MSE 5.894653214313418 Test RE 1.160478745078898\n",
      "51 Train Loss 89.257706 Test MSE 5.90626901504518 Test RE 1.161621582083015\n",
      "52 Train Loss 87.294876 Test MSE 5.9982901349506355 Test RE 1.1706357815092578\n",
      "53 Train Loss 86.38827 Test MSE 6.034860827292081 Test RE 1.17419895577889\n",
      "54 Train Loss 85.654976 Test MSE 6.037653550680811 Test RE 1.1744706135430076\n",
      "55 Train Loss 85.24156 Test MSE 6.050258744954722 Test RE 1.175695982897664\n",
      "56 Train Loss 84.11311 Test MSE 6.054890309949656 Test RE 1.1761459033779218\n",
      "57 Train Loss 80.929504 Test MSE 6.07576813282318 Test RE 1.1781718884667471\n",
      "58 Train Loss 80.25857 Test MSE 6.112686078141285 Test RE 1.1817459067317946\n",
      "59 Train Loss 79.3461 Test MSE 6.106830093758447 Test RE 1.1811797117974077\n",
      "60 Train Loss 78.07922 Test MSE 6.1468947249516335 Test RE 1.1850480169878748\n",
      "61 Train Loss 76.936554 Test MSE 6.202375466658774 Test RE 1.1903840163649662\n",
      "62 Train Loss 75.87883 Test MSE 6.200045221113349 Test RE 1.1901603804649672\n",
      "63 Train Loss 74.76563 Test MSE 6.218584278866639 Test RE 1.191938430612822\n",
      "64 Train Loss 73.62528 Test MSE 6.245029006401124 Test RE 1.1944701199988819\n",
      "65 Train Loss 72.037415 Test MSE 6.196928512149119 Test RE 1.1898612012105987\n",
      "66 Train Loss 70.495995 Test MSE 6.185221259089189 Test RE 1.1887367254695749\n",
      "67 Train Loss 69.88355 Test MSE 6.157985953782644 Test RE 1.1861166634906577\n",
      "68 Train Loss 69.047554 Test MSE 6.134206129067664 Test RE 1.183824280139785\n",
      "69 Train Loss 67.92137 Test MSE 6.1185798906309286 Test RE 1.1823154853593618\n",
      "70 Train Loss 66.83598 Test MSE 6.099586283275091 Test RE 1.1804789570139793\n",
      "71 Train Loss 66.27797 Test MSE 6.079304650184784 Test RE 1.1785147273562335\n",
      "72 Train Loss 65.68192 Test MSE 6.049771599006248 Test RE 1.1756486504538812\n",
      "73 Train Loss 64.99746 Test MSE 6.035059000458111 Test RE 1.1742182348327903\n",
      "74 Train Loss 64.17712 Test MSE 6.0372872747658635 Test RE 1.1744349882111307\n",
      "75 Train Loss 63.80079 Test MSE 6.025640755638669 Test RE 1.1733016412383424\n",
      "76 Train Loss 63.030445 Test MSE 6.020461165765849 Test RE 1.172797252735206\n",
      "77 Train Loss 62.013367 Test MSE 5.99612608131297 Test RE 1.1704245923955898\n",
      "78 Train Loss 61.558933 Test MSE 5.984425088135558 Test RE 1.1692820365380325\n",
      "79 Train Loss 61.186768 Test MSE 5.99861305568513 Test RE 1.1706672919455885\n",
      "80 Train Loss 60.84987 Test MSE 5.998269842772988 Test RE 1.1706338013808555\n",
      "81 Train Loss 60.536514 Test MSE 5.998968826229118 Test RE 1.1707020068672076\n",
      "82 Train Loss 59.333786 Test MSE 5.968628629137266 Test RE 1.16773780127239\n",
      "83 Train Loss 59.118237 Test MSE 5.960426320607994 Test RE 1.1669351513467925\n",
      "84 Train Loss 59.03039 Test MSE 5.956424839041489 Test RE 1.1665433795832003\n",
      "85 Train Loss 58.764214 Test MSE 5.965713706637998 Test RE 1.1674526201116115\n",
      "86 Train Loss 58.227448 Test MSE 5.968083590509825 Test RE 1.1676844827650226\n",
      "87 Train Loss 57.157425 Test MSE 6.0197782832651905 Test RE 1.1727307374458975\n",
      "88 Train Loss 56.00445 Test MSE 6.042891934732951 Test RE 1.1749799996968475\n",
      "89 Train Loss 55.690407 Test MSE 6.041868423054674 Test RE 1.1748804896699094\n",
      "90 Train Loss 55.467354 Test MSE 6.054730036609815 Test RE 1.1761303369456764\n",
      "91 Train Loss 55.33333 Test MSE 6.046696047374619 Test RE 1.1753497773704784\n",
      "92 Train Loss 55.058487 Test MSE 6.038749898750289 Test RE 1.1745772418987726\n",
      "93 Train Loss 54.665035 Test MSE 6.022515892864962 Test RE 1.172997368030114\n",
      "94 Train Loss 54.26295 Test MSE 6.01292306791327 Test RE 1.172062804887627\n",
      "95 Train Loss 53.886982 Test MSE 6.008713726366914 Test RE 1.1716524822916958\n",
      "96 Train Loss 53.68804 Test MSE 6.019975651753271 Test RE 1.1727499622565563\n",
      "97 Train Loss 53.06924 Test MSE 5.960518026816598 Test RE 1.1669441284552264\n",
      "98 Train Loss 52.347145 Test MSE 5.976791477204547 Test RE 1.1685360423759177\n",
      "99 Train Loss 51.914383 Test MSE 5.9990683950667885 Test RE 1.1707117222831218\n",
      "Training time: 74.94\n",
      "KG_stan_tune6\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 651.6313 Test MSE 6.2916263933893815 Test RE 1.1989181174731\n",
      "1 Train Loss 331.7993 Test MSE 6.317233007275793 Test RE 1.2013554093344405\n",
      "2 Train Loss 276.5485 Test MSE 6.3071114269310575 Test RE 1.2003926072835593\n",
      "3 Train Loss 230.61267 Test MSE 6.314231647436226 Test RE 1.2010699894164718\n",
      "4 Train Loss 187.23787 Test MSE 6.291763977262944 Test RE 1.198931226237559\n",
      "5 Train Loss 168.91362 Test MSE 6.291768934241293 Test RE 1.1989316985276022\n",
      "6 Train Loss 157.45328 Test MSE 6.281048016848822 Test RE 1.197909797689677\n",
      "7 Train Loss 141.89268 Test MSE 6.262899592499122 Test RE 1.1961779288999448\n",
      "8 Train Loss 131.82455 Test MSE 6.241199167589508 Test RE 1.1941038022766828\n",
      "9 Train Loss 120.41962 Test MSE 6.231587846018657 Test RE 1.1931840000652116\n",
      "10 Train Loss 111.30664 Test MSE 6.227697493169461 Test RE 1.1928114921590638\n",
      "11 Train Loss 105.85052 Test MSE 6.208628686859277 Test RE 1.1909839363612733\n",
      "12 Train Loss 100.32556 Test MSE 6.159647801443721 Test RE 1.1862767005748702\n",
      "13 Train Loss 97.64003 Test MSE 6.124138979900663 Test RE 1.182852464954764\n",
      "14 Train Loss 94.46241 Test MSE 6.0778300098161395 Test RE 1.178371784133832\n",
      "15 Train Loss 92.34796 Test MSE 6.048479884819399 Test RE 1.175523134714547\n",
      "16 Train Loss 89.96204 Test MSE 5.979805618560898 Test RE 1.1688306560392432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 86.07946 Test MSE 5.869675155765007 Test RE 1.1580174231708653\n",
      "18 Train Loss 81.79396 Test MSE 5.900193073836358 Test RE 1.1610239323204279\n",
      "19 Train Loss 76.41864 Test MSE 5.817096545339665 Test RE 1.1528191872581057\n",
      "20 Train Loss 74.056076 Test MSE 5.794252492642204 Test RE 1.1505533689281315\n",
      "21 Train Loss 70.79819 Test MSE 5.812404587356775 Test RE 1.1523541725999336\n",
      "22 Train Loss 68.94692 Test MSE 5.821065424108734 Test RE 1.1532123919611197\n",
      "23 Train Loss 67.03873 Test MSE 5.879934000972873 Test RE 1.1590289557399003\n",
      "24 Train Loss 65.83628 Test MSE 5.915309431730213 Test RE 1.1625102588125737\n",
      "25 Train Loss 63.347755 Test MSE 5.930523060284194 Test RE 1.1640042332515543\n",
      "26 Train Loss 61.414738 Test MSE 5.9543917107998805 Test RE 1.1663442723354176\n",
      "27 Train Loss 60.317482 Test MSE 5.9712249104384165 Test RE 1.167991749572886\n",
      "28 Train Loss 58.8413 Test MSE 6.010942772769156 Test RE 1.1718697855035178\n",
      "29 Train Loss 57.050957 Test MSE 6.024567656841575 Test RE 1.173197160678317\n",
      "30 Train Loss 56.15889 Test MSE 6.037612342651101 Test RE 1.1744666055536361\n",
      "31 Train Loss 55.316742 Test MSE 6.044987892898673 Test RE 1.175183751099556\n",
      "32 Train Loss 54.266483 Test MSE 6.063595669874135 Test RE 1.176991095888234\n",
      "33 Train Loss 53.53909 Test MSE 6.080143820088238 Test RE 1.178596063958069\n",
      "34 Train Loss 52.601982 Test MSE 6.092556470355633 Test RE 1.1797985060580756\n",
      "35 Train Loss 51.214172 Test MSE 6.058615872310647 Test RE 1.1765076878911533\n",
      "36 Train Loss 50.49383 Test MSE 6.056353692258353 Test RE 1.1762880237993807\n",
      "37 Train Loss 49.77435 Test MSE 6.046522373775918 Test RE 1.1753328980127487\n",
      "38 Train Loss 48.596626 Test MSE 6.068248481871607 Test RE 1.1774425827987671\n",
      "39 Train Loss 48.15712 Test MSE 6.096216057869856 Test RE 1.1801527849017088\n",
      "40 Train Loss 47.326633 Test MSE 6.153179771843467 Test RE 1.1856537032564722\n",
      "41 Train Loss 46.686863 Test MSE 6.18752603552705 Test RE 1.1889581821564597\n",
      "42 Train Loss 46.333572 Test MSE 6.180521151646096 Test RE 1.1882849831698576\n",
      "43 Train Loss 45.882793 Test MSE 6.213220590999382 Test RE 1.1914242810428881\n",
      "44 Train Loss 45.223816 Test MSE 6.235719587368426 Test RE 1.1935794940298918\n",
      "45 Train Loss 44.78804 Test MSE 6.248064674265103 Test RE 1.1947603967946827\n",
      "46 Train Loss 44.280735 Test MSE 6.303312088890121 Test RE 1.2000310008345685\n",
      "47 Train Loss 43.39792 Test MSE 6.355437262489976 Test RE 1.2049826070217398\n",
      "48 Train Loss 43.141567 Test MSE 6.403794353180149 Test RE 1.2095581405926212\n",
      "49 Train Loss 42.437447 Test MSE 6.472427887338352 Test RE 1.2160226673227692\n",
      "50 Train Loss 41.28267 Test MSE 6.517229009843618 Test RE 1.22022396799668\n",
      "51 Train Loss 40.98311 Test MSE 6.573095591785078 Test RE 1.22544277148755\n",
      "52 Train Loss 40.47094 Test MSE 6.601080443572936 Test RE 1.2280486525359924\n",
      "53 Train Loss 39.994263 Test MSE 6.661732240140076 Test RE 1.2336775073816355\n",
      "54 Train Loss 39.683453 Test MSE 6.687823404890314 Test RE 1.236091040885646\n",
      "55 Train Loss 39.18768 Test MSE 6.74162248105606 Test RE 1.2410528460289334\n",
      "56 Train Loss 38.592873 Test MSE 6.790416509546382 Test RE 1.245535950128495\n",
      "57 Train Loss 38.269787 Test MSE 6.795732846413994 Test RE 1.2460234307661098\n",
      "58 Train Loss 37.59137 Test MSE 6.838255716416147 Test RE 1.249915716339861\n",
      "59 Train Loss 36.743942 Test MSE 6.923564364174892 Test RE 1.2576880291042345\n",
      "60 Train Loss 36.29869 Test MSE 6.927438712618516 Test RE 1.2580398738992358\n",
      "61 Train Loss 35.92933 Test MSE 6.9912081784212585 Test RE 1.2638169551058775\n",
      "62 Train Loss 35.476818 Test MSE 7.03052028023222 Test RE 1.2673652440401086\n",
      "63 Train Loss 34.94127 Test MSE 7.087554269807111 Test RE 1.2724955110015652\n",
      "64 Train Loss 34.56648 Test MSE 7.073495171992152 Test RE 1.2712328032430769\n",
      "65 Train Loss 34.278854 Test MSE 7.0655600309271 Test RE 1.2705195602132149\n",
      "66 Train Loss 33.9914 Test MSE 7.169462008267422 Test RE 1.279827224174433\n",
      "67 Train Loss 33.788593 Test MSE 7.1519631743709065 Test RE 1.2782644035534996\n",
      "68 Train Loss 33.440872 Test MSE 7.296092736534675 Test RE 1.2910802361383202\n",
      "69 Train Loss 33.138744 Test MSE 7.324640282261822 Test RE 1.2936035860221649\n",
      "70 Train Loss 32.780895 Test MSE 7.286871349425732 Test RE 1.29026409280978\n",
      "71 Train Loss 32.34949 Test MSE 7.3052142007681 Test RE 1.2918870285001378\n",
      "72 Train Loss 32.070595 Test MSE 7.300512880007894 Test RE 1.2914712602127667\n",
      "73 Train Loss 31.90025 Test MSE 7.309339288427113 Test RE 1.292251726576885\n",
      "74 Train Loss 31.711231 Test MSE 7.332817080147051 Test RE 1.2943254361247634\n",
      "75 Train Loss 31.32899 Test MSE 7.368003930016893 Test RE 1.2974271588111914\n",
      "76 Train Loss 30.981058 Test MSE 7.412758168639592 Test RE 1.3013615661349276\n",
      "77 Train Loss 30.640343 Test MSE 7.4694581426134645 Test RE 1.3063291236446102\n",
      "78 Train Loss 30.279953 Test MSE 7.536334451332825 Test RE 1.3121640713069613\n",
      "79 Train Loss 29.849123 Test MSE 7.634547933548188 Test RE 1.3206864538893783\n",
      "80 Train Loss 29.50396 Test MSE 7.674748805342459 Test RE 1.3241590261165803\n",
      "81 Train Loss 29.025417 Test MSE 7.582479124916102 Test RE 1.31617510481809\n",
      "82 Train Loss 28.67495 Test MSE 7.507315743690119 Test RE 1.3096353863884926\n",
      "83 Train Loss 28.453321 Test MSE 7.498254460223008 Test RE 1.3088447868663347\n",
      "84 Train Loss 28.225471 Test MSE 7.467499300442837 Test RE 1.306157822037809\n",
      "85 Train Loss 27.928965 Test MSE 7.5115413805178095 Test RE 1.310003911250901\n",
      "86 Train Loss 27.771725 Test MSE 7.499313261429535 Test RE 1.3089371922074127\n",
      "87 Train Loss 27.586945 Test MSE 7.53015487538521 Test RE 1.3116259927173999\n",
      "88 Train Loss 27.277235 Test MSE 7.50501042660171 Test RE 1.3094342920992852\n",
      "89 Train Loss 27.081316 Test MSE 7.480103875899418 Test RE 1.3072597051922106\n",
      "90 Train Loss 26.67178 Test MSE 7.451813668125558 Test RE 1.3047852955298136\n",
      "91 Train Loss 26.225985 Test MSE 7.479637963658942 Test RE 1.3072189920020756\n",
      "92 Train Loss 26.001892 Test MSE 7.508637907665855 Test RE 1.3097507056687925\n",
      "93 Train Loss 25.737461 Test MSE 7.53287865333378 Test RE 1.311863189362659\n",
      "94 Train Loss 25.51116 Test MSE 7.585738103381407 Test RE 1.316457922973794\n",
      "95 Train Loss 25.31961 Test MSE 7.588947192530797 Test RE 1.3167363523153839\n",
      "96 Train Loss 25.151222 Test MSE 7.603250730804607 Test RE 1.3179766510142712\n",
      "97 Train Loss 24.990932 Test MSE 7.670588725490017 Test RE 1.323800098801169\n",
      "98 Train Loss 24.823696 Test MSE 7.652695340747649 Test RE 1.322255165586104\n",
      "99 Train Loss 24.703665 Test MSE 7.676865258873766 Test RE 1.3243415941675247\n",
      "Training time: 73.84\n",
      "KG_stan_tune6\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 6520.2603 Test MSE 5.3851289417625505 Test RE 1.1091904291714751\n",
      "1 Train Loss 5711.5527 Test MSE 5.384437804324147 Test RE 1.1091192491088802\n",
      "2 Train Loss 3902.3237 Test MSE 5.379787293053141 Test RE 1.108640175344268\n",
      "3 Train Loss 2388.7507 Test MSE 5.376592673804929 Test RE 1.108310960731654\n",
      "4 Train Loss 1480.1338 Test MSE 5.375745325725935 Test RE 1.108223622688324\n",
      "5 Train Loss 902.2073 Test MSE 5.369313375201721 Test RE 1.1075604427488481\n",
      "6 Train Loss 759.66504 Test MSE 5.37058007522908 Test RE 1.1076910799468387\n",
      "7 Train Loss 697.608 Test MSE 5.367722586882453 Test RE 1.1073963598752747\n",
      "8 Train Loss 641.27875 Test MSE 5.364185449436617 Test RE 1.1070314324247479\n",
      "9 Train Loss 580.9296 Test MSE 5.365715268742911 Test RE 1.1071892790674627\n",
      "10 Train Loss 500.89337 Test MSE 5.371098718011493 Test RE 1.1077445641241952\n",
      "11 Train Loss 424.36902 Test MSE 5.3878250556091825 Test RE 1.1094680575713631\n",
      "12 Train Loss 407.3298 Test MSE 5.387661459980238 Test RE 1.109451213529416\n",
      "13 Train Loss 391.14734 Test MSE 5.391546319965648 Test RE 1.1098511352744258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 362.15787 Test MSE 5.397761149092954 Test RE 1.1104906130979353\n",
      "15 Train Loss 345.89142 Test MSE 5.4003079846245985 Test RE 1.110752564612508\n",
      "16 Train Loss 335.3191 Test MSE 5.404165169876691 Test RE 1.1111491728859517\n",
      "17 Train Loss 314.42548 Test MSE 5.420168495116375 Test RE 1.1127931767242203\n",
      "18 Train Loss 297.30252 Test MSE 5.434306522414299 Test RE 1.1142435425518589\n",
      "19 Train Loss 288.63464 Test MSE 5.450396224500809 Test RE 1.115891829794476\n",
      "20 Train Loss 278.02322 Test MSE 5.453137482152016 Test RE 1.116172411459128\n",
      "21 Train Loss 261.13025 Test MSE 5.471939231022569 Test RE 1.1180949684531902\n",
      "22 Train Loss 246.03458 Test MSE 5.4850954457411545 Test RE 1.1194382825600058\n",
      "23 Train Loss 232.99686 Test MSE 5.50249374876986 Test RE 1.1212122632268726\n",
      "24 Train Loss 225.40324 Test MSE 5.516689188146399 Test RE 1.1226575941523678\n",
      "25 Train Loss 215.64828 Test MSE 5.5352575409046745 Test RE 1.1245453559904677\n",
      "26 Train Loss 211.58223 Test MSE 5.539526771874007 Test RE 1.1249789418231146\n",
      "27 Train Loss 205.12851 Test MSE 5.563177189965453 Test RE 1.1273778727937929\n",
      "28 Train Loss 202.09262 Test MSE 5.581419567452396 Test RE 1.1292247689040182\n",
      "29 Train Loss 199.17596 Test MSE 5.591762465189869 Test RE 1.1302705647261997\n",
      "30 Train Loss 195.42462 Test MSE 5.617664914907373 Test RE 1.1328853888183075\n",
      "31 Train Loss 190.91193 Test MSE 5.617344164415654 Test RE 1.1328530463114082\n",
      "32 Train Loss 187.60493 Test MSE 5.6377170007474415 Test RE 1.1349054879029519\n",
      "33 Train Loss 174.07382 Test MSE 5.661945898675018 Test RE 1.1373415829491473\n",
      "34 Train Loss 169.57303 Test MSE 5.679766485602724 Test RE 1.1391300291694526\n",
      "35 Train Loss 167.2289 Test MSE 5.6941370395998945 Test RE 1.1405701929681575\n",
      "36 Train Loss 165.65295 Test MSE 5.703777385571703 Test RE 1.1415352945454178\n",
      "37 Train Loss 163.57445 Test MSE 5.709460207912179 Test RE 1.1421038236808492\n",
      "38 Train Loss 161.3734 Test MSE 5.718908922385814 Test RE 1.1430484796981266\n",
      "39 Train Loss 155.41754 Test MSE 5.734677438909913 Test RE 1.1446232356392056\n",
      "40 Train Loss 152.38213 Test MSE 5.736646928123918 Test RE 1.1448197706335919\n",
      "41 Train Loss 150.6207 Test MSE 5.757807782761132 Test RE 1.1469292839127119\n",
      "42 Train Loss 149.1388 Test MSE 5.762669090235489 Test RE 1.1474133569961629\n",
      "43 Train Loss 148.01898 Test MSE 5.757201144840312 Test RE 1.146868862555331\n",
      "44 Train Loss 146.7913 Test MSE 5.747847741684378 Test RE 1.1459368569633523\n",
      "45 Train Loss 144.53197 Test MSE 5.766242044167779 Test RE 1.1477690098832556\n",
      "46 Train Loss 140.6724 Test MSE 5.774208677891326 Test RE 1.1485616144189048\n",
      "47 Train Loss 139.62294 Test MSE 5.781295343604939 Test RE 1.1492662110841645\n",
      "48 Train Loss 137.3066 Test MSE 5.765497721210173 Test RE 1.1476949288449871\n",
      "49 Train Loss 133.47513 Test MSE 5.765825696231216 Test RE 1.147727572159894\n",
      "50 Train Loss 130.17903 Test MSE 5.76956367848385 Test RE 1.1480995475208895\n",
      "51 Train Loss 128.9626 Test MSE 5.78054821659751 Test RE 1.1491919478337225\n",
      "52 Train Loss 128.6203 Test MSE 5.789326559855027 Test RE 1.150064198527201\n",
      "53 Train Loss 127.84014 Test MSE 5.800668318344764 Test RE 1.1511901816672485\n",
      "54 Train Loss 125.89572 Test MSE 5.794056506289703 Test RE 1.1505339104505077\n",
      "55 Train Loss 123.71947 Test MSE 5.811926318666233 Test RE 1.1523067613907887\n",
      "56 Train Loss 122.12272 Test MSE 5.827927860486553 Test RE 1.1538919510336343\n",
      "57 Train Loss 120.02071 Test MSE 5.823245080907626 Test RE 1.1534282778678238\n",
      "58 Train Loss 119.51106 Test MSE 5.834729429779544 Test RE 1.1545650880149947\n",
      "59 Train Loss 118.52155 Test MSE 5.847458045600367 Test RE 1.155823758996796\n",
      "60 Train Loss 116.830795 Test MSE 5.852879203496216 Test RE 1.1563594149559357\n",
      "61 Train Loss 113.99847 Test MSE 5.870540983152297 Test RE 1.158102828768402\n",
      "62 Train Loss 112.18163 Test MSE 5.876211481162573 Test RE 1.1586620135828465\n",
      "63 Train Loss 111.04283 Test MSE 5.886127244906564 Test RE 1.1596391887700879\n",
      "64 Train Loss 109.22869 Test MSE 5.8787240400372465 Test RE 1.1589096982863634\n",
      "65 Train Loss 108.015434 Test MSE 5.882929743340963 Test RE 1.1593241724895804\n",
      "66 Train Loss 107.14829 Test MSE 5.87988295628756 Test RE 1.1590239248673855\n",
      "67 Train Loss 106.40441 Test MSE 5.871584313320809 Test RE 1.1582057349522425\n",
      "68 Train Loss 105.47897 Test MSE 5.878230509637079 Test RE 1.1588610508955357\n",
      "69 Train Loss 104.171196 Test MSE 5.874281825442933 Test RE 1.158471754742528\n",
      "70 Train Loss 102.76571 Test MSE 5.8759310926581385 Test RE 1.1586343699738906\n",
      "71 Train Loss 101.39783 Test MSE 5.882401148916643 Test RE 1.159272087381773\n",
      "72 Train Loss 99.72719 Test MSE 5.9008835772828085 Test RE 1.161091868027142\n",
      "73 Train Loss 98.83163 Test MSE 5.89773309375765 Test RE 1.1607818729953963\n",
      "74 Train Loss 97.40375 Test MSE 5.892689947088347 Test RE 1.160285475047658\n",
      "75 Train Loss 96.64557 Test MSE 5.900231785062096 Test RE 1.1610277410589935\n",
      "76 Train Loss 95.56011 Test MSE 5.896374664291282 Test RE 1.160648183399377\n",
      "77 Train Loss 94.42346 Test MSE 5.907034841258591 Test RE 1.1616968894742044\n",
      "78 Train Loss 93.62 Test MSE 5.914741298055591 Test RE 1.1624544310412672\n",
      "79 Train Loss 93.031296 Test MSE 5.913250378176406 Test RE 1.1623079127437672\n",
      "80 Train Loss 92.16927 Test MSE 5.89982760604945 Test RE 1.1609879738854485\n",
      "81 Train Loss 91.649956 Test MSE 5.903222051329327 Test RE 1.1613219110550435\n",
      "82 Train Loss 90.46921 Test MSE 5.914381373354156 Test RE 1.1624190615797636\n",
      "83 Train Loss 89.97397 Test MSE 5.909446335795075 Test RE 1.1619339914992768\n",
      "84 Train Loss 89.11395 Test MSE 5.905706126807401 Test RE 1.1615662274502303\n",
      "85 Train Loss 88.47458 Test MSE 5.906132927278609 Test RE 1.1616081994046341\n",
      "86 Train Loss 87.88438 Test MSE 5.904183881832162 Test RE 1.1614165161141783\n",
      "87 Train Loss 87.13239 Test MSE 5.912816598992155 Test RE 1.1622652801650053\n",
      "88 Train Loss 86.5309 Test MSE 5.914891216078526 Test RE 1.162469163026741\n",
      "89 Train Loss 86.29279 Test MSE 5.9159734914067235 Test RE 1.1625755093739176\n",
      "90 Train Loss 85.99671 Test MSE 5.91800192503297 Test RE 1.1627748007629282\n",
      "91 Train Loss 85.44184 Test MSE 5.91694761198618 Test RE 1.1626712199205933\n",
      "92 Train Loss 84.44613 Test MSE 5.938251471595803 Test RE 1.1647624273035582\n",
      "93 Train Loss 83.22439 Test MSE 5.9374604146604035 Test RE 1.1646848435157855\n",
      "94 Train Loss 82.23078 Test MSE 5.951642579622243 Test RE 1.1660749917988673\n",
      "95 Train Loss 81.571304 Test MSE 5.951000381017711 Test RE 1.1660120787522275\n",
      "96 Train Loss 80.7044 Test MSE 5.973698912950978 Test RE 1.168233686137124\n",
      "97 Train Loss 80.32716 Test MSE 5.976983199769819 Test RE 1.1685547842821646\n",
      "98 Train Loss 80.11942 Test MSE 5.98365327397908 Test RE 1.1692066326759027\n",
      "99 Train Loss 79.751305 Test MSE 5.981519677501422 Test RE 1.1689981615751106\n",
      "Training time: 77.24\n",
      "KG_stan_tune6\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.91\n",
      "KG_stan_tune7\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 1427812.8 Test MSE 5.198143276118852 Test RE 1.0897633127942685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 1061560.5 Test MSE 5.190393160559096 Test RE 1.0889506243449958\n",
      "2 Train Loss 910253.25 Test MSE 5.191821612210956 Test RE 1.0891004594597238\n",
      "3 Train Loss 828060.44 Test MSE 5.188378062997769 Test RE 1.0887392188982774\n",
      "4 Train Loss 795860.06 Test MSE 5.189686845083376 Test RE 1.0888765289130369\n",
      "5 Train Loss 736086.2 Test MSE 5.196633235959661 Test RE 1.089605015320982\n",
      "6 Train Loss 693721.94 Test MSE 5.201604220081042 Test RE 1.090126036749547\n",
      "7 Train Loss 666319.44 Test MSE 5.202240551946118 Test RE 1.0901927143254346\n",
      "8 Train Loss 650152.5 Test MSE 5.196978706541873 Test RE 1.0896412330225167\n",
      "9 Train Loss 624249.2 Test MSE 5.193951437692237 Test RE 1.0893238257694922\n",
      "10 Train Loss 596703.25 Test MSE 5.195031631358489 Test RE 1.0894370940141584\n",
      "11 Train Loss 585166.44 Test MSE 5.1952909347343965 Test RE 1.0894642826061975\n",
      "12 Train Loss 573490.8 Test MSE 5.197013333068309 Test RE 1.0896448630574123\n",
      "13 Train Loss 565258.6 Test MSE 5.197016966622969 Test RE 1.0896452439765312\n",
      "14 Train Loss 555333.2 Test MSE 5.199347108064511 Test RE 1.0898894939971886\n",
      "15 Train Loss 550934.56 Test MSE 5.199801005638336 Test RE 1.089937066066392\n",
      "16 Train Loss 540324.3 Test MSE 5.1975960555254845 Test RE 1.089705950329408\n",
      "17 Train Loss 536609.6 Test MSE 5.196252891021187 Test RE 1.0895651401444018\n",
      "18 Train Loss 531698.9 Test MSE 5.197719893394567 Test RE 1.0897189319133533\n",
      "19 Train Loss 526060.1 Test MSE 5.199431604701095 Test RE 1.0898983500728097\n",
      "20 Train Loss 521542.5 Test MSE 5.199278433361477 Test RE 1.0898822961622547\n",
      "21 Train Loss 518276.8 Test MSE 5.200682542031335 Test RE 1.090029452147095\n",
      "22 Train Loss 511977.28 Test MSE 5.202501711085871 Test RE 1.090220078517405\n",
      "23 Train Loss 507408.3 Test MSE 5.202417087981258 Test RE 1.0902112118040386\n",
      "24 Train Loss 500534.9 Test MSE 5.204161766314002 Test RE 1.0903940026496146\n",
      "25 Train Loss 495000.44 Test MSE 5.203603888689177 Test RE 1.090335556856913\n",
      "26 Train Loss 490171.44 Test MSE 5.203314043026832 Test RE 1.090305190072727\n",
      "27 Train Loss 478153.34 Test MSE 5.203313925390031 Test RE 1.0903051777478876\n",
      "28 Train Loss 470822.6 Test MSE 5.205241335754981 Test RE 1.09050709434956\n",
      "29 Train Loss 461489.3 Test MSE 5.206497882537039 Test RE 1.0906387107728652\n",
      "30 Train Loss 455796.94 Test MSE 5.201413900209457 Test RE 1.0901060934266438\n",
      "31 Train Loss 450611.47 Test MSE 5.20231903898323 Test RE 1.090200938250534\n",
      "32 Train Loss 443530.72 Test MSE 5.202911614835352 Test RE 1.0902630267489113\n",
      "33 Train Loss 435143.97 Test MSE 5.204885309345615 Test RE 1.09046979963648\n",
      "34 Train Loss 431746.66 Test MSE 5.204647130963792 Test RE 1.0904448491055616\n",
      "35 Train Loss 426848.5 Test MSE 5.20619339404607 Test RE 1.0906068187219913\n",
      "36 Train Loss 424004.47 Test MSE 5.2070043053401385 Test RE 1.0906917513094598\n",
      "37 Train Loss 419988.47 Test MSE 5.206533061429826 Test RE 1.0906423953414877\n",
      "38 Train Loss 414070.75 Test MSE 5.205975354705304 Test RE 1.0905839807611628\n",
      "39 Train Loss 410466.75 Test MSE 5.20494057914625 Test RE 1.0904755893786975\n",
      "40 Train Loss 406546.72 Test MSE 5.204065731575412 Test RE 1.0903839418376333\n",
      "41 Train Loss 402174.5 Test MSE 5.2036438845128545 Test RE 1.0903397471052312\n",
      "42 Train Loss 397656.66 Test MSE 5.2026186825486205 Test RE 1.0902323345364886\n",
      "43 Train Loss 393638.6 Test MSE 5.203484167327497 Test RE 1.0903230138952291\n",
      "44 Train Loss 387953.75 Test MSE 5.204824250270052 Test RE 1.0904634034078204\n",
      "45 Train Loss 384856.47 Test MSE 5.20484064952006 Test RE 1.0904651213109646\n",
      "46 Train Loss 382183.12 Test MSE 5.2044319826121095 Test RE 1.0904223106096207\n",
      "47 Train Loss 377861.88 Test MSE 5.204280743274601 Test RE 1.0904064668108617\n",
      "48 Train Loss 371222.06 Test MSE 5.202744558574339 Test RE 1.0902455234026809\n",
      "49 Train Loss 369835.3 Test MSE 5.203705743142906 Test RE 1.0903462278256744\n",
      "50 Train Loss 366833.75 Test MSE 5.2050461458374135 Test RE 1.090486647844622\n",
      "51 Train Loss 364681.5 Test MSE 5.203679794708687 Test RE 1.0903435093002585\n",
      "52 Train Loss 362259.06 Test MSE 5.203726494033878 Test RE 1.090348401818042\n",
      "53 Train Loss 359233.62 Test MSE 5.204548262956861 Test RE 1.0904344919556734\n",
      "54 Train Loss 356205.44 Test MSE 5.20358600213851 Test RE 1.0903336829288282\n",
      "55 Train Loss 353982.6 Test MSE 5.203569639817453 Test RE 1.0903319686875534\n",
      "56 Train Loss 353062.38 Test MSE 5.203722038938266 Test RE 1.0903479350748895\n",
      "57 Train Loss 351770.22 Test MSE 5.202794141744905 Test RE 1.0902507185165615\n",
      "58 Train Loss 345024.47 Test MSE 5.2052452035851955 Test RE 1.0905074995080557\n",
      "59 Train Loss 342285.94 Test MSE 5.206124112088716 Test RE 1.090599562016298\n",
      "60 Train Loss 340295.38 Test MSE 5.206013587985528 Test RE 1.0905879854407423\n",
      "61 Train Loss 338220.06 Test MSE 5.206471949739794 Test RE 1.090635994614287\n",
      "62 Train Loss 336685.7 Test MSE 5.207387517642118 Test RE 1.090731885596127\n",
      "63 Train Loss 335273.3 Test MSE 5.2073372969435505 Test RE 1.0907266260058686\n",
      "64 Train Loss 333203.56 Test MSE 5.207209453169034 Test RE 1.0907132368727335\n",
      "65 Train Loss 328875.9 Test MSE 5.205992505016496 Test RE 1.0905857771430096\n",
      "66 Train Loss 326915.16 Test MSE 5.205925808480166 Test RE 1.0905787911046312\n",
      "67 Train Loss 325205.56 Test MSE 5.206606246966546 Test RE 1.0906500606119893\n",
      "68 Train Loss 323458.56 Test MSE 5.207316362785316 Test RE 1.0907244335737842\n",
      "69 Train Loss 321826.44 Test MSE 5.207479317073775 Test RE 1.090741499642092\n",
      "70 Train Loss 319676.03 Test MSE 5.207483686292932 Test RE 1.0907419572231374\n",
      "71 Train Loss 317283.5 Test MSE 5.209088331926806 Test RE 1.0909099961084918\n",
      "72 Train Loss 313929.8 Test MSE 5.210260132183352 Test RE 1.091032690968798\n",
      "73 Train Loss 311787.25 Test MSE 5.209145037865254 Test RE 1.0909159338947987\n",
      "74 Train Loss 310600.75 Test MSE 5.208525411245212 Test RE 1.0908510498638793\n",
      "75 Train Loss 309588.47 Test MSE 5.2080556679823005 Test RE 1.0908018582554075\n",
      "76 Train Loss 308078.47 Test MSE 5.206660835422383 Test RE 1.0906557780355652\n",
      "77 Train Loss 305415.56 Test MSE 5.205331221954641 Test RE 1.0905165099663319\n",
      "78 Train Loss 303171.16 Test MSE 5.2047783080398995 Test RE 1.090458590715903\n",
      "79 Train Loss 300640.0 Test MSE 5.204410690335998 Test RE 1.0904200800495187\n",
      "80 Train Loss 299514.4 Test MSE 5.204581272790952 Test RE 1.0904379499891832\n",
      "81 Train Loss 297778.6 Test MSE 5.204675924702357 Test RE 1.0904478654426626\n",
      "82 Train Loss 295165.6 Test MSE 5.203434528528096 Test RE 1.0903178132976388\n",
      "83 Train Loss 293455.53 Test MSE 5.20330014837906 Test RE 1.0903037343258155\n",
      "84 Train Loss 292119.38 Test MSE 5.2024909078179205 Test RE 1.090218946567201\n",
      "85 Train Loss 289763.62 Test MSE 5.202661687814643 Test RE 1.0902368405014211\n",
      "86 Train Loss 288473.7 Test MSE 5.203387498126738 Test RE 1.090312885955904\n",
      "87 Train Loss 287703.06 Test MSE 5.202682475319569 Test RE 1.0902390185481996\n",
      "88 Train Loss 286793.53 Test MSE 5.202316522898025 Test RE 1.0902006746143786\n",
      "89 Train Loss 285953.3 Test MSE 5.203520573829391 Test RE 1.0903268281450818\n",
      "90 Train Loss 283895.22 Test MSE 5.20382270181366 Test RE 1.0903584810866391\n",
      "91 Train Loss 282358.25 Test MSE 5.202781687969976 Test RE 1.0902494136652818\n",
      "92 Train Loss 280934.03 Test MSE 5.202336675112958 Test RE 1.0902027861676589\n",
      "93 Train Loss 279411.8 Test MSE 5.2022933768907675 Test RE 1.0901982493658682\n",
      "94 Train Loss 278426.9 Test MSE 5.202582811703793 Test RE 1.0902285760809212\n",
      "95 Train Loss 276936.88 Test MSE 5.202895280604719 Test RE 1.0902613153397016\n",
      "96 Train Loss 274827.44 Test MSE 5.2022295735590145 Test RE 1.0901915639976263\n",
      "97 Train Loss 273013.12 Test MSE 5.2007200771409865 Test RE 1.090033385698207\n",
      "98 Train Loss 271840.66 Test MSE 5.200175394639703 Test RE 1.0899763034433978\n",
      "99 Train Loss 270076.3 Test MSE 5.199166608971987 Test RE 1.0898705756822626\n",
      "Training time: 77.06\n",
      "KG_stan_tune7\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.90\n",
      "KG_stan_tune8\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 14359382000.0 Test MSE 6.211652074625888 Test RE 1.191273885091069\n",
      "1 Train Loss 9699587000.0 Test MSE 6.2116065178959845 Test RE 1.1912695166363096\n",
      "2 Train Loss 6986275000.0 Test MSE 6.21151577770646 Test RE 1.191260815472112\n",
      "3 Train Loss 5690523600.0 Test MSE 6.210926036386903 Test RE 1.1912042630599118\n",
      "4 Train Loss 4799497700.0 Test MSE 6.21071064470187 Test RE 1.1911836077086446\n",
      "5 Train Loss 4630019000.0 Test MSE 6.210680127533372 Test RE 1.1911806811840002\n",
      "6 Train Loss 4143159300.0 Test MSE 6.210532851287805 Test RE 1.1911665576375483\n",
      "7 Train Loss 4043626500.0 Test MSE 6.21053464715856 Test RE 1.1911667298595685\n",
      "8 Train Loss 3896525000.0 Test MSE 6.2106082723341025 Test RE 1.1911737904110877\n",
      "9 Train Loss 3724402200.0 Test MSE 6.210484768177376 Test RE 1.1911619465111476\n",
      "10 Train Loss 3627946200.0 Test MSE 6.210309342480064 Test RE 1.1911451231955363\n",
      "11 Train Loss 3558376200.0 Test MSE 6.2102091203696075 Test RE 1.1911355117934979\n",
      "12 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "13 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "14 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "15 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "16 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "17 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "18 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "19 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "20 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "21 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "22 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "23 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "24 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "25 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "26 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "27 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "28 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "29 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "30 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "31 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "32 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "33 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "34 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "35 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "36 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "37 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "38 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "39 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "40 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "41 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "42 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "43 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "44 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "45 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "46 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "47 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "48 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "49 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "50 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "51 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "52 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "53 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "54 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "55 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "56 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "57 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "58 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "59 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "60 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "61 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "62 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "63 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "64 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "65 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "66 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "67 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "68 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "69 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "70 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "71 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "72 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "73 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "74 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "75 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "76 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "77 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "78 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "79 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "80 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "81 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "82 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "83 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "84 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "85 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "86 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "87 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "88 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "89 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "90 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "91 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "93 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "94 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "95 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "96 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "97 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "98 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "99 Train Loss 3523756300.0 Test MSE 6.210170014667735 Test RE 1.1911317614959924\n",
      "Training time: 22.70\n",
      "KG_stan_tune8\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 946971600.0 Test MSE 5.758493188374613 Test RE 1.1469975467313016\n",
      "1 Train Loss 698788000.0 Test MSE 5.758545841357523 Test RE 1.1470027905253115\n",
      "2 Train Loss 576756900.0 Test MSE 5.758249278899097 Test RE 1.1469732550873415\n",
      "3 Train Loss 514127200.0 Test MSE 5.757277102364696 Test RE 1.1468764281266972\n",
      "4 Train Loss 441803040.0 Test MSE 5.756816606152397 Test RE 1.1468305607137836\n",
      "5 Train Loss 406676830.0 Test MSE 5.756152387872575 Test RE 1.1467643984709919\n",
      "6 Train Loss 391072800.0 Test MSE 5.756062195003887 Test RE 1.146755414138316\n",
      "7 Train Loss 379992930.0 Test MSE 5.755834917477263 Test RE 1.1467327741547528\n",
      "8 Train Loss 360591200.0 Test MSE 5.755314247079866 Test RE 1.1466809065003578\n",
      "9 Train Loss 345974270.0 Test MSE 5.7551042143183855 Test RE 1.146659982989988\n",
      "10 Train Loss 336764740.0 Test MSE 5.754587161451029 Test RE 1.1466084724415124\n",
      "11 Train Loss 328730370.0 Test MSE 5.754257629151529 Test RE 1.1465756421162994\n",
      "12 Train Loss 316643230.0 Test MSE 5.753736716194651 Test RE 1.1465237431864783\n",
      "13 Train Loss 307110340.0 Test MSE 5.753689036539213 Test RE 1.1465189927110064\n",
      "14 Train Loss 298137500.0 Test MSE 5.753609575464729 Test RE 1.1465110757081027\n",
      "15 Train Loss 291140670.0 Test MSE 5.753527267234194 Test RE 1.1465028749747905\n",
      "16 Train Loss 285798300.0 Test MSE 5.753544935697428 Test RE 1.146504635366929\n",
      "17 Train Loss 282667200.0 Test MSE 5.75350641672371 Test RE 1.1465007975368324\n",
      "18 Train Loss 279941120.0 Test MSE 5.7534508156902735 Test RE 1.1464952577165408\n",
      "19 Train Loss 275085570.0 Test MSE 5.753487090446199 Test RE 1.146498871962271\n",
      "20 Train Loss 267065010.0 Test MSE 5.753555366728676 Test RE 1.146505674658391\n",
      "21 Train Loss 264229330.0 Test MSE 5.753524573263813 Test RE 1.146502606561606\n",
      "22 Train Loss 261791330.0 Test MSE 5.753524132331984 Test RE 1.1465025626294478\n",
      "23 Train Loss 260240240.0 Test MSE 5.753489558644776 Test RE 1.1464991178815318\n",
      "24 Train Loss 258197950.0 Test MSE 5.753505272322911 Test RE 1.1465006835144953\n",
      "25 Train Loss 254915970.0 Test MSE 5.753744201433799 Test RE 1.1465244889628352\n",
      "26 Train Loss 252965520.0 Test MSE 5.753735651716132 Test RE 1.1465236371293186\n",
      "27 Train Loss 250982460.0 Test MSE 5.753714553071447 Test RE 1.1465215350065856\n",
      "28 Train Loss 249214350.0 Test MSE 5.7537165267137445 Test RE 1.1465217316467895\n",
      "29 Train Loss 248237620.0 Test MSE 5.753742712154553 Test RE 1.146524340581609\n",
      "30 Train Loss 247070050.0 Test MSE 5.753738528363955 Test RE 1.1465239237382718\n",
      "31 Train Loss 245578940.0 Test MSE 5.753706270024178 Test RE 1.1465207097401082\n",
      "32 Train Loss 244426500.0 Test MSE 5.753676812570071 Test RE 1.1465177747949757\n",
      "33 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "34 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "35 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "36 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "37 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "38 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "39 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "40 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "41 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "42 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "43 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "44 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "45 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "46 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "47 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "48 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "49 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "50 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "51 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "52 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "53 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "54 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "55 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "56 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "57 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "58 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "59 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "60 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "61 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "62 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "63 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "64 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "65 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "66 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "67 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "68 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "69 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "70 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "71 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "72 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "73 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "74 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "75 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "76 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "77 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "78 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "79 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "80 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "81 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "82 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "83 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "84 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "85 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "87 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "88 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "89 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "90 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "91 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "92 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "93 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "94 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "95 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "96 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "97 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "98 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "99 Train Loss 244423180.0 Test MSE 5.753676846655231 Test RE 1.1465177781909992\n",
      "Training time: 35.95\n",
      "KG_stan_tune8\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4587888600.0 Test MSE 6.170635632370377 Test RE 1.1873342935169324\n",
      "1 Train Loss 3656370200.0 Test MSE 6.17014071472334 Test RE 1.1872866773139121\n",
      "2 Train Loss 3343882800.0 Test MSE 6.170050392029146 Test RE 1.1872779871292876\n",
      "3 Train Loss 2966792200.0 Test MSE 6.169985405549331 Test RE 1.1872717345693231\n",
      "4 Train Loss 2767441000.0 Test MSE 6.169912759674395 Test RE 1.1872647450351388\n",
      "5 Train Loss 2642987500.0 Test MSE 6.169952418034435 Test RE 1.187268560720943\n",
      "6 Train Loss 2555528200.0 Test MSE 6.170051045208697 Test RE 1.1872780499736428\n",
      "7 Train Loss 2450827500.0 Test MSE 6.17027013874172 Test RE 1.1872991294291921\n",
      "8 Train Loss 2399977500.0 Test MSE 6.170365995253061 Test RE 1.1873083518706649\n",
      "9 Train Loss 2362639000.0 Test MSE 6.170386690861807 Test RE 1.187310343004459\n",
      "10 Train Loss 2299022600.0 Test MSE 6.170237173435773 Test RE 1.1872959577907995\n",
      "11 Train Loss 2258828500.0 Test MSE 6.1703081332823935 Test RE 1.1873027849268127\n",
      "12 Train Loss 2229332200.0 Test MSE 6.170338421391392 Test RE 1.187305698971886\n",
      "13 Train Loss 2176618800.0 Test MSE 6.170199272144081 Test RE 1.187292311243814\n",
      "14 Train Loss 2121361000.0 Test MSE 6.170172934729188 Test RE 1.1872897772702589\n",
      "15 Train Loss 2089367200.0 Test MSE 6.1701897484591175 Test RE 1.1872913949523136\n",
      "16 Train Loss 2081901200.0 Test MSE 6.170170618195437 Test RE 1.1872895543918138\n",
      "17 Train Loss 2064251400.0 Test MSE 6.170178501718227 Test RE 1.1872903128814773\n",
      "18 Train Loss 2044784100.0 Test MSE 6.1701589873650615 Test RE 1.1872884353652284\n",
      "19 Train Loss 2008025000.0 Test MSE 6.169948660263333 Test RE 1.1872681991716258\n",
      "20 Train Loss 1980936200.0 Test MSE 6.169876462993344 Test RE 1.1872612527788595\n",
      "21 Train Loss 1964246900.0 Test MSE 6.169773392946347 Test RE 1.1872513359203194\n",
      "22 Train Loss 1938228200.0 Test MSE 6.169458929526036 Test RE 1.1872210793898577\n",
      "23 Train Loss 1911933000.0 Test MSE 6.1691396922148485 Test RE 1.1871903627441587\n",
      "24 Train Loss 1885087200.0 Test MSE 6.169042887515159 Test RE 1.1871810481506238\n",
      "25 Train Loss 1850625800.0 Test MSE 6.1690718664210324 Test RE 1.1871838365221812\n",
      "26 Train Loss 1838548000.0 Test MSE 6.169025172555493 Test RE 1.1871793436009987\n",
      "27 Train Loss 1828537700.0 Test MSE 6.169037941948907 Test RE 1.1871805722839606\n",
      "28 Train Loss 1802832000.0 Test MSE 6.1686535510778535 Test RE 1.1871435852782544\n",
      "29 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "30 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "31 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "32 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "33 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "34 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "35 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "36 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "37 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "38 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "39 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "40 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "41 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "42 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "43 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "44 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "45 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "46 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "47 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "48 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "49 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "50 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "51 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "52 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "53 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "54 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "55 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "56 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "57 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "58 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "59 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "60 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "61 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "62 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "63 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "64 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "65 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "66 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "67 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "68 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "69 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "70 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "71 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "72 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "73 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "74 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "75 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "76 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "77 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "78 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "79 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "80 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "82 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "83 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "84 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "85 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "86 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "87 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "88 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "89 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "90 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "91 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "92 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "93 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "94 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "95 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "96 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "97 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "98 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "99 Train Loss 1787686000.0 Test MSE 6.1684686353479 Test RE 1.1871257918354903\n",
      "Training time: 32.89\n",
      "KG_stan_tune8\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.89\n",
      "KG_stan_tune9\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 361013500000.0 Test MSE 6.661183498763052 Test RE 1.2336266959851963\n",
      "1 Train Loss 269429570000.0 Test MSE 6.661200017688596 Test RE 1.23362822560639\n",
      "2 Train Loss 204020120000.0 Test MSE 6.661631394904915 Test RE 1.233668169647493\n",
      "3 Train Loss 174849160000.0 Test MSE 6.661770983231086 Test RE 1.2336810947676735\n",
      "4 Train Loss 158050550000.0 Test MSE 6.661812280356623 Test RE 1.2336849186310437\n",
      "5 Train Loss 149394900000.0 Test MSE 6.661975443264772 Test RE 1.2337000264108853\n",
      "6 Train Loss 147860700000.0 Test MSE 6.66204743607679 Test RE 1.233706692398691\n",
      "7 Train Loss 142322550000.0 Test MSE 6.662034305942923 Test RE 1.2337054766506677\n",
      "8 Train Loss 137751350000.0 Test MSE 6.6620139716041455 Test RE 1.2337035938470744\n",
      "9 Train Loss 135916470000.0 Test MSE 6.661990430473167 Test RE 1.2337014141155649\n",
      "10 Train Loss 128478780000.0 Test MSE 6.661898335972322 Test RE 1.2336928868210744\n",
      "11 Train Loss 118729510000.0 Test MSE 6.662090437306052 Test RE 1.2337106739688635\n",
      "12 Train Loss 118579570000.0 Test MSE 6.662097741380246 Test RE 1.2337113502664847\n",
      "13 Train Loss 113451205000.0 Test MSE 6.662273044779106 Test RE 1.2337275818183615\n",
      "14 Train Loss 112147980000.0 Test MSE 6.662312153541469 Test RE 1.233731202916423\n",
      "15 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "16 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "17 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "18 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "19 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "20 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "21 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "22 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "23 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "24 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "25 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "26 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "27 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "28 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "29 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "30 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "31 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "32 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "33 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "34 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "35 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "36 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "37 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "38 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "39 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "40 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "41 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "42 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "43 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "44 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "45 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "46 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "47 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "48 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "49 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "50 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "51 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "52 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "53 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "54 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "55 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "56 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "57 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "58 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "59 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "60 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "61 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "62 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "64 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "65 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "66 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "67 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "68 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "69 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "70 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "71 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "72 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "73 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "74 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "75 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "76 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "77 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "78 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "79 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "80 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "81 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "82 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "83 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "84 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "85 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "86 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "87 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "88 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "89 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "90 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "91 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "92 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "93 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "94 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "95 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "96 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "97 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "98 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "99 Train Loss 111853380000.0 Test MSE 6.662335783952884 Test RE 1.233733390861792\n",
      "Training time: 21.54\n",
      "KG_stan_tune9\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.98\n",
      "KG_stan_tune10\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.488976 Test MSE 8.71327786994542 Test RE 1.4109084754563699\n",
      "1 Train Loss 57.14413 Test MSE 8.30391196082494 Test RE 1.3773662220362104\n",
      "2 Train Loss 52.53379 Test MSE 8.010639952649099 Test RE 1.352825143529997\n",
      "3 Train Loss 47.85677 Test MSE 7.49971388753911 Test RE 1.3089721545695243\n",
      "4 Train Loss 40.494392 Test MSE 7.8317155845747255 Test RE 1.3376315815575957\n",
      "5 Train Loss 38.409065 Test MSE 7.5466686722592495 Test RE 1.3130634175383944\n",
      "6 Train Loss 36.473312 Test MSE 7.421097400677376 Test RE 1.3020933656455118\n",
      "7 Train Loss 34.331932 Test MSE 7.03032542801342 Test RE 1.2673476812829394\n",
      "8 Train Loss 32.894463 Test MSE 6.6732770741400955 Test RE 1.234746031019711\n",
      "9 Train Loss 31.864346 Test MSE 6.717111417571583 Test RE 1.2387946933925138\n",
      "10 Train Loss 30.660696 Test MSE 6.490774505220343 Test RE 1.2177449048018554\n",
      "11 Train Loss 29.034504 Test MSE 6.365121205250516 Test RE 1.2059002890327002\n",
      "12 Train Loss 27.472181 Test MSE 6.189231505731092 Test RE 1.1891220273697922\n",
      "13 Train Loss 26.071274 Test MSE 6.143915858780349 Test RE 1.184760837249652\n",
      "14 Train Loss 25.405602 Test MSE 6.043250381332307 Test RE 1.1750148473612054\n",
      "15 Train Loss 24.732933 Test MSE 5.916072609505375 Test RE 1.1625852484127706\n",
      "16 Train Loss 23.969654 Test MSE 5.556461084832368 Test RE 1.1266971579229181\n",
      "17 Train Loss 23.502895 Test MSE 5.353105131724257 Test RE 1.1058874935188399\n",
      "18 Train Loss 22.817942 Test MSE 4.509094583417142 Test RE 1.0149688948615148\n",
      "19 Train Loss 19.233534 Test MSE 2.301962851478637 Test RE 0.7251990319333752\n",
      "20 Train Loss 15.366236 Test MSE 2.0544094367324846 Test RE 0.6850962035996918\n",
      "21 Train Loss 11.4552765 Test MSE 1.196228605926288 Test RE 0.5227754109778077\n",
      "22 Train Loss 8.441932 Test MSE 0.9145844935217881 Test RE 0.4571092157629395\n",
      "23 Train Loss 5.297946 Test MSE 0.4385917033730877 Test RE 0.31654704691579544\n",
      "24 Train Loss 4.1650357 Test MSE 0.317718113938334 Test RE 0.269419513870084\n",
      "25 Train Loss 3.1681612 Test MSE 0.2675136106537017 Test RE 0.24721851982227344\n",
      "26 Train Loss 2.5145602 Test MSE 0.2558687066075056 Test RE 0.24177792564186437\n",
      "27 Train Loss 2.3383992 Test MSE 0.18666948159879693 Test RE 0.2065117281343136\n",
      "28 Train Loss 1.7968433 Test MSE 0.13938086941567845 Test RE 0.17844716179041017\n",
      "29 Train Loss 1.5081192 Test MSE 0.15081168456127098 Test RE 0.18562033656463192\n",
      "30 Train Loss 1.3615322 Test MSE 0.12973134117167318 Test RE 0.17215931033476609\n",
      "31 Train Loss 1.1629642 Test MSE 0.11484572193438759 Test RE 0.16198152050995768\n",
      "32 Train Loss 1.0548316 Test MSE 0.11124295732800363 Test RE 0.15942055736840027\n",
      "33 Train Loss 0.953892 Test MSE 0.08275790961342737 Test RE 0.13750320352899667\n",
      "34 Train Loss 0.85921645 Test MSE 0.0695506445011711 Test RE 0.1260545828897381\n",
      "35 Train Loss 0.79825604 Test MSE 0.07782771020836474 Test RE 0.13334452443953332\n",
      "36 Train Loss 0.74493647 Test MSE 0.07526774685714747 Test RE 0.13113315736544806\n",
      "37 Train Loss 0.61035985 Test MSE 0.05199899410823463 Test RE 0.10899473794371542\n",
      "38 Train Loss 0.5872909 Test MSE 0.054966528483452286 Test RE 0.1120617021476592\n",
      "39 Train Loss 0.5576557 Test MSE 0.06036357884836941 Test RE 0.11743445875054076\n",
      "40 Train Loss 0.5173739 Test MSE 0.0523392079469733 Test RE 0.10935071658453116\n",
      "41 Train Loss 0.4678378 Test MSE 0.04746553860058279 Test RE 0.10413513081043556\n",
      "42 Train Loss 0.44991803 Test MSE 0.042030251060611486 Test RE 0.09799164592171783\n",
      "43 Train Loss 0.42547408 Test MSE 0.03498269888785504 Test RE 0.08939942309202785\n",
      "44 Train Loss 0.34503013 Test MSE 0.029706971755362015 Test RE 0.0823829334309421\n",
      "45 Train Loss 0.30721182 Test MSE 0.030423301743562316 Test RE 0.08337027474583532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 0.28833416 Test MSE 0.026280244003193485 Test RE 0.07748591340466977\n",
      "47 Train Loss 0.2686499 Test MSE 0.027326157533195 Test RE 0.07901278031999392\n",
      "48 Train Loss 0.2607997 Test MSE 0.027886188451457173 Test RE 0.07981833041241211\n",
      "49 Train Loss 0.24354401 Test MSE 0.02339153588416751 Test RE 0.07310337530157077\n",
      "50 Train Loss 0.22800598 Test MSE 0.02241295013865389 Test RE 0.07155789767074063\n",
      "51 Train Loss 0.19955784 Test MSE 0.018737357999240232 Test RE 0.06542778796440829\n",
      "52 Train Loss 0.17772956 Test MSE 0.01892691884140379 Test RE 0.06575791283985769\n",
      "53 Train Loss 0.16190635 Test MSE 0.0189915123537113 Test RE 0.06587002608918519\n",
      "54 Train Loss 0.15201643 Test MSE 0.016681281306635088 Test RE 0.06173376485550944\n",
      "55 Train Loss 0.14481884 Test MSE 0.017417330434854772 Test RE 0.063081041606608\n",
      "56 Train Loss 0.1373139 Test MSE 0.015003441154182763 Test RE 0.05854684544896418\n",
      "57 Train Loss 0.1314567 Test MSE 0.013519724714527878 Test RE 0.05557660129636844\n",
      "58 Train Loss 0.12295106 Test MSE 0.01513337310134915 Test RE 0.05879981097956939\n",
      "59 Train Loss 0.11579499 Test MSE 0.016655821122567027 Test RE 0.06168663558598355\n",
      "60 Train Loss 0.11316325 Test MSE 0.014864498735568572 Test RE 0.05827512241356401\n",
      "61 Train Loss 0.105398074 Test MSE 0.013560366894651992 Test RE 0.05566007412226925\n",
      "62 Train Loss 0.10313931 Test MSE 0.013004693195926315 Test RE 0.05450773247325769\n",
      "63 Train Loss 0.10205109 Test MSE 0.012748587572240068 Test RE 0.05396834449222453\n",
      "64 Train Loss 0.10022759 Test MSE 0.013661048546221669 Test RE 0.05586632166563469\n",
      "65 Train Loss 0.099033475 Test MSE 0.012755389479869313 Test RE 0.05398273976310991\n",
      "66 Train Loss 0.09449819 Test MSE 0.01186956211236312 Test RE 0.05207453600549062\n",
      "67 Train Loss 0.090124525 Test MSE 0.013647589207395401 Test RE 0.05583879416485898\n",
      "68 Train Loss 0.08805214 Test MSE 0.01323792550871293 Test RE 0.05499434410320807\n",
      "69 Train Loss 0.083946444 Test MSE 0.013215342378944415 Test RE 0.054947415506575614\n",
      "70 Train Loss 0.07833192 Test MSE 0.01325747257021243 Test RE 0.0550349313270691\n",
      "71 Train Loss 0.076498434 Test MSE 0.01246335095457295 Test RE 0.05336118586623173\n",
      "72 Train Loss 0.075474 Test MSE 0.01263920522094867 Test RE 0.05373632265978712\n",
      "73 Train Loss 0.07413758 Test MSE 0.012924634074650467 Test RE 0.05433969398168927\n",
      "74 Train Loss 0.07276578 Test MSE 0.01248899663896127 Test RE 0.05341605798214171\n",
      "75 Train Loss 0.07118349 Test MSE 0.012413089698980135 Test RE 0.05325348170147887\n",
      "76 Train Loss 0.06999728 Test MSE 0.01232658774964649 Test RE 0.053067606007049004\n",
      "77 Train Loss 0.06957736 Test MSE 0.012322986974727461 Test RE 0.053059854532542\n",
      "78 Train Loss 0.06886607 Test MSE 0.011810748845010825 Test RE 0.05194536203647482\n",
      "79 Train Loss 0.06543696 Test MSE 0.009971519919157304 Test RE 0.04772970397699361\n",
      "80 Train Loss 0.062082358 Test MSE 0.00990481701051964 Test RE 0.047569795947743014\n",
      "81 Train Loss 0.057925276 Test MSE 0.008266983019602379 Test RE 0.043459185543950486\n",
      "82 Train Loss 0.05587435 Test MSE 0.007102716028518545 Test RE 0.04028285898934766\n",
      "83 Train Loss 0.055218004 Test MSE 0.007013662080321257 Test RE 0.04002952890928999\n",
      "84 Train Loss 0.05485869 Test MSE 0.007164191600957452 Test RE 0.040456811910886334\n",
      "85 Train Loss 0.05468285 Test MSE 0.007104034818226312 Test RE 0.04028659855558436\n",
      "86 Train Loss 0.054216497 Test MSE 0.0072474586463481434 Test RE 0.04069124082313461\n",
      "87 Train Loss 0.05309536 Test MSE 0.00692142302664964 Test RE 0.03976543677467663\n",
      "88 Train Loss 0.05160355 Test MSE 0.0055653619095347205 Test RE 0.0356578181600314\n",
      "89 Train Loss 0.047385007 Test MSE 0.005179592753432442 Test RE 0.03439979603797968\n",
      "90 Train Loss 0.040709894 Test MSE 0.005033792808429619 Test RE 0.03391218152536857\n",
      "91 Train Loss 0.038059525 Test MSE 0.004545331086960999 Test RE 0.032224843871157406\n",
      "92 Train Loss 0.03634294 Test MSE 0.004557680144759941 Test RE 0.03226858947809094\n",
      "93 Train Loss 0.034622137 Test MSE 0.004359835387188577 Test RE 0.03156044414345719\n",
      "94 Train Loss 0.032301024 Test MSE 0.004844014541765467 Test RE 0.0332667810163393\n",
      "95 Train Loss 0.030707253 Test MSE 0.0049893071090780835 Test RE 0.03376200103280951\n",
      "96 Train Loss 0.029291373 Test MSE 0.0046324058981090125 Test RE 0.03253204491472114\n",
      "97 Train Loss 0.028860204 Test MSE 0.004635234269304323 Test RE 0.03254197481510182\n",
      "98 Train Loss 0.028584905 Test MSE 0.004765101036153725 Test RE 0.03299469491866451\n",
      "99 Train Loss 0.02822907 Test MSE 0.0046118832392032525 Test RE 0.03245990257940076\n",
      "Training time: 71.12\n",
      "KG_stan_tune10\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.631336 Test MSE 8.600256018308334 Test RE 1.4017280050861975\n",
      "1 Train Loss 56.929985 Test MSE 8.675668164030919 Test RE 1.4078601830509259\n",
      "2 Train Loss 54.325493 Test MSE 9.016889471453082 Test RE 1.4352793395709627\n",
      "3 Train Loss 52.174904 Test MSE 8.690957844679776 Test RE 1.4091002176221572\n",
      "4 Train Loss 46.910995 Test MSE 8.567168838388191 Test RE 1.3990290202809266\n",
      "5 Train Loss 46.23195 Test MSE 8.727003489449286 Test RE 1.412019307266757\n",
      "6 Train Loss 45.511414 Test MSE 8.735307511298213 Test RE 1.4126909382129826\n",
      "7 Train Loss 45.29029 Test MSE 8.630789532345553 Test RE 1.4042140799748417\n",
      "8 Train Loss 44.712463 Test MSE 8.469465482835309 Test RE 1.3910286069177986\n",
      "9 Train Loss 44.37202 Test MSE 8.495210947886898 Test RE 1.3931412257080091\n",
      "10 Train Loss 43.559555 Test MSE 8.551083156644452 Test RE 1.3977149975602141\n",
      "11 Train Loss 43.030064 Test MSE 8.45002367242391 Test RE 1.3894311240300594\n",
      "12 Train Loss 42.55697 Test MSE 8.840610697642719 Test RE 1.4211803482866718\n",
      "13 Train Loss 42.07116 Test MSE 8.833147061455184 Test RE 1.4205803098308165\n",
      "14 Train Loss 41.5214 Test MSE 9.210220923347809 Test RE 1.4505846721358484\n",
      "15 Train Loss 41.14044 Test MSE 9.383377300224945 Test RE 1.4641570061660452\n",
      "16 Train Loss 40.819504 Test MSE 9.6701444642823 Test RE 1.4863618207904232\n",
      "17 Train Loss 40.199577 Test MSE 9.332053166828823 Test RE 1.4601472756525744\n",
      "18 Train Loss 39.747147 Test MSE 9.227604672667805 Test RE 1.4519529733428238\n",
      "19 Train Loss 39.067436 Test MSE 9.389607203937212 Test RE 1.4646429742434377\n",
      "20 Train Loss 38.120396 Test MSE 9.52023213785417 Test RE 1.4747955868967926\n",
      "21 Train Loss 36.778595 Test MSE 8.750899797104585 Test RE 1.4139511834970975\n",
      "22 Train Loss 34.391083 Test MSE 8.357935943915365 Test RE 1.3818394254850332\n",
      "23 Train Loss 32.33557 Test MSE 8.323873204317682 Test RE 1.379020709689893\n",
      "24 Train Loss 31.37117 Test MSE 8.714418600916469 Test RE 1.4110008295821879\n",
      "25 Train Loss 30.48898 Test MSE 9.294511075643241 Test RE 1.4572072889516237\n",
      "26 Train Loss 29.88319 Test MSE 9.039456070054541 Test RE 1.4370742563719152\n",
      "27 Train Loss 29.585289 Test MSE 8.930757553549071 Test RE 1.4284077902080843\n",
      "28 Train Loss 28.754742 Test MSE 8.881104872026064 Test RE 1.4244314683910153\n",
      "29 Train Loss 28.372528 Test MSE 8.871560854267312 Test RE 1.4236658849540782\n",
      "30 Train Loss 27.938179 Test MSE 9.11161401788524 Test RE 1.4427986168801752\n",
      "31 Train Loss 27.555212 Test MSE 8.9003068457728 Test RE 1.4259705295510006\n",
      "32 Train Loss 27.092682 Test MSE 8.743586105730817 Test RE 1.4133601948891044\n",
      "33 Train Loss 26.302925 Test MSE 9.03232962204185 Test RE 1.4365076706078448\n",
      "34 Train Loss 25.528402 Test MSE 8.854309612936294 Test RE 1.4222810128129604\n",
      "35 Train Loss 24.97213 Test MSE 8.806626717697394 Test RE 1.4184461554678955\n",
      "36 Train Loss 24.164814 Test MSE 8.607544446915826 Test RE 1.4023218380415305\n",
      "37 Train Loss 23.142078 Test MSE 8.077987389537276 Test RE 1.3585000092489274\n",
      "38 Train Loss 21.31794 Test MSE 7.727996931895851 Test RE 1.3287446557004094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 20.60691 Test MSE 7.530054155474696 Test RE 1.3116172208331185\n",
      "40 Train Loss 20.182678 Test MSE 7.689794069321122 Test RE 1.3254563042708651\n",
      "41 Train Loss 19.50299 Test MSE 7.745285743834777 Test RE 1.3302301365270819\n",
      "42 Train Loss 19.182888 Test MSE 7.7198158328666056 Test RE 1.3280411441553404\n",
      "43 Train Loss 18.90415 Test MSE 7.658626741702648 Test RE 1.3227674887676732\n",
      "44 Train Loss 18.614075 Test MSE 7.612759053924455 Test RE 1.3188004981309367\n",
      "45 Train Loss 17.994831 Test MSE 7.518953549235077 Test RE 1.3106500886012886\n",
      "46 Train Loss 17.591707 Test MSE 7.327376834593012 Test RE 1.2938452144973493\n",
      "47 Train Loss 16.886517 Test MSE 7.099821268648043 Test RE 1.2735962399669354\n",
      "48 Train Loss 16.22007 Test MSE 6.337853130391071 Test RE 1.2033144881470679\n",
      "49 Train Loss 15.559012 Test MSE 5.720732557432276 Test RE 1.143230711759043\n",
      "50 Train Loss 14.374138 Test MSE 5.022154336959576 Test RE 1.0711568952308488\n",
      "51 Train Loss 12.855705 Test MSE 5.235734667501951 Test RE 1.0936966328976325\n",
      "52 Train Loss 12.345498 Test MSE 5.316704747587027 Test RE 1.1021211379263935\n",
      "53 Train Loss 11.917182 Test MSE 5.282656503869932 Test RE 1.0985864710468696\n",
      "54 Train Loss 11.561779 Test MSE 5.189171180239795 Test RE 1.0888224303411542\n",
      "55 Train Loss 11.385185 Test MSE 5.284305061892031 Test RE 1.098757875553709\n",
      "56 Train Loss 11.341454 Test MSE 5.309468434014969 Test RE 1.1013708602568832\n",
      "57 Train Loss 11.261436 Test MSE 5.293405067497781 Test RE 1.0997035440726797\n",
      "58 Train Loss 11.0864525 Test MSE 5.315852139690316 Test RE 1.1020327641210428\n",
      "59 Train Loss 11.02985 Test MSE 5.355451082903344 Test RE 1.1061297897029372\n",
      "60 Train Loss 10.911211 Test MSE 5.365151220104817 Test RE 1.1071310831898602\n",
      "61 Train Loss 10.765776 Test MSE 5.435708486156057 Test RE 1.1143872617459871\n",
      "62 Train Loss 10.705833 Test MSE 5.470934772400199 Test RE 1.1179923419775784\n",
      "63 Train Loss 10.646502 Test MSE 5.46545914699007 Test RE 1.117432726478878\n",
      "64 Train Loss 10.592367 Test MSE 5.468426553916718 Test RE 1.117736033810099\n",
      "65 Train Loss 10.552799 Test MSE 5.4575562615359585 Test RE 1.1166245475839014\n",
      "66 Train Loss 10.488156 Test MSE 5.458033045789658 Test RE 1.116673321920702\n",
      "67 Train Loss 10.434563 Test MSE 5.433590096094813 Test RE 1.114170092544159\n",
      "68 Train Loss 10.34255 Test MSE 5.373743745017847 Test RE 1.108017287993691\n",
      "69 Train Loss 10.28849 Test MSE 5.40772415658928 Test RE 1.1115149938914919\n",
      "70 Train Loss 10.186588 Test MSE 5.5236586869208395 Test RE 1.1233665239829937\n",
      "71 Train Loss 10.1213875 Test MSE 5.480630479466016 Test RE 1.1189825683605388\n",
      "72 Train Loss 10.069056 Test MSE 5.4696582164842384 Test RE 1.1178619014715514\n",
      "73 Train Loss 9.9970875 Test MSE 5.441552173601225 Test RE 1.1149861148285243\n",
      "74 Train Loss 9.950634 Test MSE 5.41929496540358 Test RE 1.1127035026603058\n",
      "75 Train Loss 9.893534 Test MSE 5.4073078193543305 Test RE 1.111472205652567\n",
      "76 Train Loss 9.799845 Test MSE 5.372072310821937 Test RE 1.1078449572961735\n",
      "77 Train Loss 9.718557 Test MSE 5.319137056330708 Test RE 1.1023732106371562\n",
      "78 Train Loss 9.667591 Test MSE 5.347829978761528 Test RE 1.1053424674595211\n",
      "79 Train Loss 9.594765 Test MSE 5.2994762160302455 Test RE 1.1003340031265199\n",
      "80 Train Loss 9.464823 Test MSE 5.172305784697635 Test RE 1.0870515920490798\n",
      "81 Train Loss 9.346527 Test MSE 5.149666558936006 Test RE 1.0846699661281944\n",
      "82 Train Loss 9.112485 Test MSE 5.044468245199746 Test RE 1.0735338837212443\n",
      "83 Train Loss 8.36478 Test MSE 4.266969986495109 Test RE 0.9873425517584778\n",
      "84 Train Loss 6.361575 Test MSE 3.5841509333294757 Test RE 0.9049012858196378\n",
      "85 Train Loss 5.397453 Test MSE 3.3365376523574484 Test RE 0.8730840922398908\n",
      "86 Train Loss 4.747994 Test MSE 3.0369625929675195 Test RE 0.8329669721425439\n",
      "87 Train Loss 4.383724 Test MSE 2.7979356914315576 Test RE 0.7995155676017083\n",
      "88 Train Loss 4.166301 Test MSE 2.5567659219203915 Test RE 0.7642818476661423\n",
      "89 Train Loss 3.7102873 Test MSE 2.3422908599025103 Test RE 0.7315238197819848\n",
      "90 Train Loss 3.3653154 Test MSE 2.227294188095097 Test RE 0.7133404512863354\n",
      "91 Train Loss 3.0241148 Test MSE 2.150546750498171 Test RE 0.7009426793286181\n",
      "92 Train Loss 2.7169054 Test MSE 2.2342547715413477 Test RE 0.7144542225470215\n",
      "93 Train Loss 2.5553339 Test MSE 2.200517933951916 Test RE 0.7090396410897162\n",
      "94 Train Loss 2.425128 Test MSE 2.2333005463277344 Test RE 0.7143016385513791\n",
      "95 Train Loss 2.3098788 Test MSE 2.2044819034203513 Test RE 0.7096779787373274\n",
      "96 Train Loss 2.2211094 Test MSE 2.140916253882871 Test RE 0.6993714508855188\n",
      "97 Train Loss 2.1178837 Test MSE 2.1403783725608605 Test RE 0.6992835907297212\n",
      "98 Train Loss 2.0377197 Test MSE 2.114603243022669 Test RE 0.695060338041871\n",
      "99 Train Loss 1.9536095 Test MSE 2.1236674761389804 Test RE 0.6965484308924413\n",
      "Training time: 70.99\n",
      "KG_stan_tune10\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.55521 Test MSE 8.57907296468749 Test RE 1.4000006619750915\n",
      "1 Train Loss 52.219578 Test MSE 8.485646595378034 Test RE 1.3923567692463272\n",
      "2 Train Loss 47.62532 Test MSE 8.909936639778573 Test RE 1.4267417439811088\n",
      "3 Train Loss 46.80667 Test MSE 7.874910329301762 Test RE 1.3413152703661688\n",
      "4 Train Loss 41.937416 Test MSE 6.953981045876053 Test RE 1.2604476462065723\n",
      "5 Train Loss 38.670868 Test MSE 8.01325105385367 Test RE 1.353045605040096\n",
      "6 Train Loss 37.008705 Test MSE 7.578872635803118 Test RE 1.3158620584071166\n",
      "7 Train Loss 36.145863 Test MSE 7.627917614343852 Test RE 1.3201128459397449\n",
      "8 Train Loss 34.42117 Test MSE 7.255969877055096 Test RE 1.2875253714491945\n",
      "9 Train Loss 33.595837 Test MSE 7.364860013843547 Test RE 1.29715032417009\n",
      "10 Train Loss 31.884579 Test MSE 7.050188929365112 Test RE 1.2691368022893257\n",
      "11 Train Loss 29.400536 Test MSE 6.728567253801012 Test RE 1.239850607358754\n",
      "12 Train Loss 28.215725 Test MSE 6.489723151408495 Test RE 1.2176462776969867\n",
      "13 Train Loss 26.704315 Test MSE 6.03750905442722 Test RE 1.1744565594392427\n",
      "14 Train Loss 25.66061 Test MSE 6.193823054810666 Test RE 1.189563027185098\n",
      "15 Train Loss 24.718918 Test MSE 6.341190606129983 Test RE 1.2036312755719467\n",
      "16 Train Loss 24.192266 Test MSE 6.284284806047138 Test RE 1.19821841514355\n",
      "17 Train Loss 23.568409 Test MSE 6.248609975816782 Test RE 1.1948125321772192\n",
      "18 Train Loss 23.287167 Test MSE 6.190401520144606 Test RE 1.1892344180732184\n",
      "19 Train Loss 22.995544 Test MSE 6.242839789783116 Test RE 1.1942607388219324\n",
      "20 Train Loss 22.368357 Test MSE 6.168784555901585 Test RE 1.1871561910040545\n",
      "21 Train Loss 21.325016 Test MSE 6.140710704583954 Test RE 1.1844517642875216\n",
      "22 Train Loss 19.840727 Test MSE 6.0583153882250205 Test RE 1.1764785123973012\n",
      "23 Train Loss 19.350552 Test MSE 6.0327060362775065 Test RE 1.1739893089183906\n",
      "24 Train Loss 18.937513 Test MSE 6.011279195609934 Test RE 1.1719025788822792\n",
      "25 Train Loss 18.416763 Test MSE 6.0618573402376175 Test RE 1.1768223721412567\n",
      "26 Train Loss 17.777412 Test MSE 5.9150441790539885 Test RE 1.1624841940379613\n",
      "27 Train Loss 16.213177 Test MSE 5.372862541628774 Test RE 1.1079264361902965\n",
      "28 Train Loss 13.554155 Test MSE 4.810284923367229 Test RE 1.0483190091901635\n",
      "29 Train Loss 11.381025 Test MSE 3.9231931310882304 Test RE 0.9467338477338514\n",
      "30 Train Loss 9.057709 Test MSE 3.2493246124210753 Test RE 0.8615978575460153\n",
      "31 Train Loss 7.61528 Test MSE 2.703444375036052 Test RE 0.785899078145118\n",
      "32 Train Loss 6.753209 Test MSE 2.585958878831742 Test RE 0.7686327191533274\n",
      "33 Train Loss 6.137496 Test MSE 2.4340655424885385 Test RE 0.745717258789194\n",
      "34 Train Loss 5.6368575 Test MSE 2.3717610430470772 Test RE 0.7361113700807618\n",
      "35 Train Loss 5.406356 Test MSE 2.353273124409055 Test RE 0.7332367567308825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Train Loss 5.245793 Test MSE 2.29757055000683 Test RE 0.7245068370825037\n",
      "37 Train Loss 5.053418 Test MSE 2.3310004181375583 Test RE 0.7297586239674613\n",
      "38 Train Loss 4.8877993 Test MSE 2.291203717948312 Test RE 0.7235022948168951\n",
      "39 Train Loss 4.7697077 Test MSE 2.2577532152504225 Test RE 0.7182014787592307\n",
      "40 Train Loss 4.6301594 Test MSE 2.238016683849503 Test RE 0.7150554484599477\n",
      "41 Train Loss 4.5502367 Test MSE 2.2029288597846985 Test RE 0.7094279528579388\n",
      "42 Train Loss 4.487518 Test MSE 2.1821134952875627 Test RE 0.7060683231753673\n",
      "43 Train Loss 4.4257708 Test MSE 2.1806981157823273 Test RE 0.7058392982550418\n",
      "44 Train Loss 4.3857703 Test MSE 2.1679941734582653 Test RE 0.7037803155438724\n",
      "45 Train Loss 4.335208 Test MSE 2.1651345300894445 Test RE 0.7033160096820879\n",
      "46 Train Loss 4.293646 Test MSE 2.1597659877299398 Test RE 0.702443517650673\n",
      "47 Train Loss 4.18094 Test MSE 2.1253226666849314 Test RE 0.6968198236201092\n",
      "48 Train Loss 4.101297 Test MSE 2.1473545561434193 Test RE 0.7004222590649746\n",
      "49 Train Loss 4.006891 Test MSE 2.1573458047695087 Test RE 0.7020498364913501\n",
      "50 Train Loss 3.8082004 Test MSE 2.0936795372934762 Test RE 0.6916130263647959\n",
      "51 Train Loss 3.475121 Test MSE 2.141549412356663 Test RE 0.6994748599340785\n",
      "52 Train Loss 3.076356 Test MSE 2.006687492732528 Test RE 0.677092389218759\n",
      "53 Train Loss 2.4768667 Test MSE 1.964771152093269 Test RE 0.6699834066593063\n",
      "54 Train Loss 1.8153507 Test MSE 1.601222623660577 Test RE 0.6048308282863407\n",
      "55 Train Loss 1.4610875 Test MSE 1.4158000065878042 Test RE 0.5687337686119835\n",
      "56 Train Loss 1.2254679 Test MSE 1.1405684655446129 Test RE 0.5104682561043313\n",
      "57 Train Loss 0.89571255 Test MSE 0.5070565871805502 Test RE 0.34035824434435874\n",
      "58 Train Loss 0.6942278 Test MSE 0.3324423449511969 Test RE 0.2755917602967832\n",
      "59 Train Loss 0.587244 Test MSE 0.3144897477016931 Test RE 0.26804721935131925\n",
      "60 Train Loss 0.48726866 Test MSE 0.25058448811806894 Test RE 0.2392682934222703\n",
      "61 Train Loss 0.3989954 Test MSE 0.2117928242841911 Test RE 0.21997011464777355\n",
      "62 Train Loss 0.34577715 Test MSE 0.18883329981159014 Test RE 0.2077051914048551\n",
      "63 Train Loss 0.28842947 Test MSE 0.17931304017938626 Test RE 0.20240162606054354\n",
      "64 Train Loss 0.2548815 Test MSE 0.1387357275143322 Test RE 0.1780337002188485\n",
      "65 Train Loss 0.20490682 Test MSE 0.08165295456645517 Test RE 0.13658217121311378\n",
      "66 Train Loss 0.16429201 Test MSE 0.058233093032261964 Test RE 0.11534346382075522\n",
      "67 Train Loss 0.14790002 Test MSE 0.048972660526813774 Test RE 0.10577545679398002\n",
      "68 Train Loss 0.13249667 Test MSE 0.05055602334503032 Test RE 0.10747179762051709\n",
      "69 Train Loss 0.111960344 Test MSE 0.04416318253544901 Test RE 0.10044729398622873\n",
      "70 Train Loss 0.09833978 Test MSE 0.034302569596925334 Test RE 0.0885261113076205\n",
      "71 Train Loss 0.09040015 Test MSE 0.03318863504013846 Test RE 0.0870768592043352\n",
      "72 Train Loss 0.08163367 Test MSE 0.027853860373460104 Test RE 0.07977205084470909\n",
      "73 Train Loss 0.07311672 Test MSE 0.022821619605677343 Test RE 0.07220733082051875\n",
      "74 Train Loss 0.06753168 Test MSE 0.023949743746783964 Test RE 0.07397049003092043\n",
      "75 Train Loss 0.0615634 Test MSE 0.02197479414161687 Test RE 0.07085499438273878\n",
      "76 Train Loss 0.058503196 Test MSE 0.019973362240465625 Test RE 0.06755129039727845\n",
      "77 Train Loss 0.053860635 Test MSE 0.022786575011315775 Test RE 0.07215186918258636\n",
      "78 Train Loss 0.049736746 Test MSE 0.02070991751422311 Test RE 0.06878555485616165\n",
      "79 Train Loss 0.04781158 Test MSE 0.01956359664541499 Test RE 0.06685477173942715\n",
      "80 Train Loss 0.045187518 Test MSE 0.021360487702389144 Test RE 0.06985759699345555\n",
      "81 Train Loss 0.039313823 Test MSE 0.018511838096745333 Test RE 0.06503285673670821\n",
      "82 Train Loss 0.036275033 Test MSE 0.016704904355628533 Test RE 0.061777461253479556\n",
      "83 Train Loss 0.034490615 Test MSE 0.017105292432985367 Test RE 0.06251342761276987\n",
      "84 Train Loss 0.031131402 Test MSE 0.01714442844225724 Test RE 0.06258490047153784\n",
      "85 Train Loss 0.028949624 Test MSE 0.01712194142493102 Test RE 0.06254384312377846\n",
      "86 Train Loss 0.027620733 Test MSE 0.017001334214367062 Test RE 0.062323173956282236\n",
      "87 Train Loss 0.025902528 Test MSE 0.01713426831043177 Test RE 0.06256635319022741\n",
      "88 Train Loss 0.02376702 Test MSE 0.017828705515452712 Test RE 0.06382164090874962\n",
      "89 Train Loss 0.022525124 Test MSE 0.016678535785281872 Test RE 0.06172868436015957\n",
      "90 Train Loss 0.020518314 Test MSE 0.016076823699293172 Test RE 0.060604962230061475\n",
      "91 Train Loss 0.019170074 Test MSE 0.01535524294745182 Test RE 0.059229273594287916\n",
      "92 Train Loss 0.018427508 Test MSE 0.012975871645586322 Test RE 0.054447297800741146\n",
      "93 Train Loss 0.017633151 Test MSE 0.011909135050802894 Test RE 0.05216127162490646\n",
      "94 Train Loss 0.016195351 Test MSE 0.01163358850573718 Test RE 0.05155430177641087\n",
      "95 Train Loss 0.015099675 Test MSE 0.010696257811420324 Test RE 0.04943379945251092\n",
      "96 Train Loss 0.014042704 Test MSE 0.00996889312490284 Test RE 0.04772341685270233\n",
      "97 Train Loss 0.013002456 Test MSE 0.009065159217352679 Test RE 0.045508841336426825\n",
      "98 Train Loss 0.012272868 Test MSE 0.007943028491587718 Test RE 0.042599168337138144\n",
      "99 Train Loss 0.010724389 Test MSE 0.007048141741386802 Test RE 0.04012780228163481\n",
      "Training time: 72.00\n",
      "KG_stan_tune10\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.385384 Test MSE 8.659355091746443 Test RE 1.4065359431888989\n",
      "1 Train Loss 55.81421 Test MSE 8.56393569975543 Test RE 1.3987650076476892\n",
      "2 Train Loss 50.634193 Test MSE 8.89355466596308 Test RE 1.42542952369487\n",
      "3 Train Loss 43.977753 Test MSE 8.59780418345373 Test RE 1.4015281825137265\n",
      "4 Train Loss 43.92463 Test MSE 8.636478743278 Test RE 1.4046768159725658\n",
      "5 Train Loss 43.747185 Test MSE 8.619494795988427 Test RE 1.403294962433088\n",
      "6 Train Loss 43.275238 Test MSE 8.512907622650424 Test RE 1.394591521721249\n",
      "7 Train Loss 42.917503 Test MSE 8.456970421263637 Test RE 1.3900021310774366\n",
      "8 Train Loss 42.617435 Test MSE 8.396066607049157 Test RE 1.3849879596717216\n",
      "9 Train Loss 42.387413 Test MSE 8.326742350038778 Test RE 1.3792583556979625\n",
      "10 Train Loss 42.035942 Test MSE 8.375541893644833 Test RE 1.3832940787082193\n",
      "11 Train Loss 41.890358 Test MSE 8.332591010405737 Test RE 1.379742662604375\n",
      "12 Train Loss 41.60791 Test MSE 8.436455725657972 Test RE 1.3883151921847667\n",
      "13 Train Loss 41.454037 Test MSE 8.569747288076757 Test RE 1.399239536416856\n",
      "14 Train Loss 41.09047 Test MSE 8.690835741295535 Test RE 1.4090903190291195\n",
      "15 Train Loss 40.676952 Test MSE 8.613256102906226 Test RE 1.4027870259763524\n",
      "16 Train Loss 40.203247 Test MSE 8.73215899675193 Test RE 1.4124363233165929\n",
      "17 Train Loss 39.850777 Test MSE 8.718834146204658 Test RE 1.4113582572736287\n",
      "18 Train Loss 39.3039 Test MSE 8.736299145180443 Test RE 1.4127711204185363\n",
      "19 Train Loss 38.14814 Test MSE 9.188466708071116 Test RE 1.4488705445774528\n",
      "20 Train Loss 35.859585 Test MSE 9.381060187518976 Test RE 1.4639762169810138\n",
      "21 Train Loss 34.811184 Test MSE 9.278176205299314 Test RE 1.4559262231936652\n",
      "22 Train Loss 34.000847 Test MSE 9.088893065209326 Test RE 1.440998594353542\n",
      "23 Train Loss 32.503597 Test MSE 8.871027944437683 Test RE 1.4236231248946893\n",
      "24 Train Loss 29.872353 Test MSE 8.105437695210847 Test RE 1.3608062528721139\n",
      "25 Train Loss 27.648018 Test MSE 7.741337392200982 Test RE 1.3298910343919774\n",
      "26 Train Loss 27.315487 Test MSE 7.775735603717029 Test RE 1.3328424086858583\n",
      "27 Train Loss 26.889015 Test MSE 7.7481823494906354 Test RE 1.3304788550429911\n",
      "28 Train Loss 26.414541 Test MSE 7.769057450949619 Test RE 1.3322699331270154\n",
      "29 Train Loss 25.895971 Test MSE 7.467272480905067 Test RE 1.3061379851184307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 25.091307 Test MSE 6.893023036755109 Test RE 1.2549109973721657\n",
      "31 Train Loss 23.735203 Test MSE 6.425436676047797 Test RE 1.2116003335569443\n",
      "32 Train Loss 21.362972 Test MSE 5.37079910752067 Test RE 1.1077136676039006\n",
      "33 Train Loss 19.555027 Test MSE 5.714089977075293 Test RE 1.1425667926279062\n",
      "34 Train Loss 17.943604 Test MSE 5.575944359376869 Test RE 1.128670764898874\n",
      "35 Train Loss 16.835209 Test MSE 5.511831610830302 Test RE 1.1221632218153168\n",
      "36 Train Loss 16.371307 Test MSE 5.379141955447956 Test RE 1.108573679346041\n",
      "37 Train Loss 15.960172 Test MSE 5.1006338798028965 Test RE 1.0794937591862077\n",
      "38 Train Loss 15.659149 Test MSE 4.95009679564696 Test RE 1.0634446872514967\n",
      "39 Train Loss 15.267307 Test MSE 4.874390557141502 Test RE 1.055281250998417\n",
      "40 Train Loss 14.899177 Test MSE 4.998328196072389 Test RE 1.0686129792872792\n",
      "41 Train Loss 14.424408 Test MSE 5.041481609459258 Test RE 1.0732160375950075\n",
      "42 Train Loss 13.877534 Test MSE 4.505788228182625 Test RE 1.014596706713511\n",
      "43 Train Loss 13.448113 Test MSE 4.270200420576832 Test RE 0.9877162292841593\n",
      "44 Train Loss 12.940647 Test MSE 4.251235302675349 Test RE 0.9855204307438139\n",
      "45 Train Loss 12.393852 Test MSE 4.239652816145768 Test RE 0.9841769903321206\n",
      "46 Train Loss 12.079089 Test MSE 4.226571021291275 Test RE 0.9826574380289635\n",
      "47 Train Loss 11.718443 Test MSE 4.190204735053515 Test RE 0.978420811802999\n",
      "48 Train Loss 11.207205 Test MSE 4.054735882331837 Test RE 0.9624747513534281\n",
      "49 Train Loss 10.078409 Test MSE 3.52291912576782 Test RE 0.8971382985512694\n",
      "50 Train Loss 8.085669 Test MSE 3.2430005492159992 Test RE 0.8607589981289682\n",
      "51 Train Loss 7.4989963 Test MSE 3.3203450354133355 Test RE 0.8709629246922153\n",
      "52 Train Loss 6.829495 Test MSE 3.385757986398196 Test RE 0.8795003488619525\n",
      "53 Train Loss 6.4723105 Test MSE 3.2492921236850143 Test RE 0.8615935501439091\n",
      "54 Train Loss 6.156363 Test MSE 3.055540071309004 Test RE 0.8355107692372112\n",
      "55 Train Loss 5.7993875 Test MSE 2.843313550540125 Test RE 0.8059728968875248\n",
      "56 Train Loss 5.6218505 Test MSE 2.7383979279200736 Test RE 0.7909633108376772\n",
      "57 Train Loss 5.4612184 Test MSE 2.7423420475912876 Test RE 0.7915327188515845\n",
      "58 Train Loss 5.3105245 Test MSE 2.7323379625575406 Test RE 0.7900876409885642\n",
      "59 Train Loss 5.1248455 Test MSE 2.7277871826308977 Test RE 0.7894294110440719\n",
      "60 Train Loss 4.990966 Test MSE 2.793542167634347 Test RE 0.798887591994884\n",
      "61 Train Loss 4.962297 Test MSE 2.8023373047328524 Test RE 0.8001442052436514\n",
      "62 Train Loss 4.9114623 Test MSE 2.7776127893366724 Test RE 0.7966066212593826\n",
      "63 Train Loss 4.848226 Test MSE 2.7312772610830005 Test RE 0.7899342689522042\n",
      "64 Train Loss 4.7360797 Test MSE 2.7106452627579665 Test RE 0.7869450415181198\n",
      "65 Train Loss 4.6130548 Test MSE 2.7254598962841987 Test RE 0.7890925775221295\n",
      "66 Train Loss 4.5194836 Test MSE 2.652823914080681 Test RE 0.7785065523985503\n",
      "67 Train Loss 4.405243 Test MSE 2.5724331223492163 Test RE 0.7666199321076853\n",
      "68 Train Loss 4.317339 Test MSE 2.511085526323757 Test RE 0.7574235648297989\n",
      "69 Train Loss 4.2642875 Test MSE 2.481613094315029 Test RE 0.7529655320950537\n",
      "70 Train Loss 4.1825113 Test MSE 2.517871903062718 Test RE 0.7584463681921846\n",
      "71 Train Loss 4.0484953 Test MSE 2.6503566243125776 Test RE 0.778144438640332\n",
      "72 Train Loss 3.940207 Test MSE 2.688031727035747 Test RE 0.7836556254126192\n",
      "73 Train Loss 3.8476298 Test MSE 2.7201991999131585 Test RE 0.7883306544507894\n",
      "74 Train Loss 3.7193298 Test MSE 2.8239577852061557 Test RE 0.8032248949109194\n",
      "75 Train Loss 3.6111243 Test MSE 2.76289181042267 Test RE 0.7944928622268949\n",
      "76 Train Loss 3.5284867 Test MSE 2.7706100659130577 Test RE 0.7956018130505534\n",
      "77 Train Loss 3.4396586 Test MSE 2.8226673117536434 Test RE 0.8030413477535208\n",
      "78 Train Loss 3.3550875 Test MSE 2.7588454499480557 Test RE 0.7939108665047634\n",
      "79 Train Loss 3.2806134 Test MSE 2.7204193357305213 Test RE 0.7883625521702896\n",
      "80 Train Loss 3.2429497 Test MSE 2.688584227841671 Test RE 0.7837361579662803\n",
      "81 Train Loss 3.1936727 Test MSE 2.647527278789894 Test RE 0.7777289799510562\n",
      "82 Train Loss 3.1393251 Test MSE 2.700135806418138 Test RE 0.7854180256973661\n",
      "83 Train Loss 3.0686436 Test MSE 2.648624920223446 Test RE 0.7778901830285253\n",
      "84 Train Loss 2.9693313 Test MSE 2.55363491151683 Test RE 0.7638137353034488\n",
      "85 Train Loss 2.8910296 Test MSE 2.5569837047876307 Test RE 0.7643143973701312\n",
      "86 Train Loss 2.8216271 Test MSE 2.473037027974567 Test RE 0.7516633405803657\n",
      "87 Train Loss 2.752922 Test MSE 2.477126073167995 Test RE 0.7522845031183315\n",
      "88 Train Loss 2.6769462 Test MSE 2.5225427573358723 Test RE 0.7591495316512525\n",
      "89 Train Loss 2.6001055 Test MSE 2.4760729272713182 Test RE 0.7521245698852913\n",
      "90 Train Loss 2.4765785 Test MSE 2.397066841779714 Test RE 0.740027966446384\n",
      "91 Train Loss 2.3586023 Test MSE 2.339891620487161 Test RE 0.7311490690443004\n",
      "92 Train Loss 2.264791 Test MSE 2.3277435274114455 Test RE 0.7292486337380042\n",
      "93 Train Loss 2.1917758 Test MSE 2.361866526263922 Test RE 0.7345743099903778\n",
      "94 Train Loss 2.1007833 Test MSE 2.3697347647392055 Test RE 0.7357968600637762\n",
      "95 Train Loss 1.9565305 Test MSE 2.4314174158025916 Test RE 0.7453114991380312\n",
      "96 Train Loss 1.8577108 Test MSE 2.449457720688326 Test RE 0.7480713704252395\n",
      "97 Train Loss 1.7725978 Test MSE 2.515636024339915 Test RE 0.7581095419362649\n",
      "98 Train Loss 1.7257794 Test MSE 2.5586474784643576 Test RE 0.7645630183100794\n",
      "99 Train Loss 1.6650411 Test MSE 2.556104682884836 Test RE 0.7641830107591272\n",
      "Training time: 71.83\n",
      "KG_stan_tune10\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.21826 Test MSE 8.55173618995595 Test RE 1.3977683672334424\n",
      "1 Train Loss 56.463165 Test MSE 8.395570728325753 Test RE 1.384947059793579\n",
      "2 Train Loss 47.9403 Test MSE 8.245494402641222 Test RE 1.3725128237923456\n",
      "3 Train Loss 46.23879 Test MSE 8.234411963679872 Test RE 1.371590143881272\n",
      "4 Train Loss 45.281044 Test MSE 8.291409265974021 Test RE 1.3763289231937208\n",
      "5 Train Loss 44.601997 Test MSE 8.069857613015907 Test RE 1.3578162323919611\n",
      "6 Train Loss 44.252388 Test MSE 8.117624425002411 Test RE 1.361828871876508\n",
      "7 Train Loss 42.936478 Test MSE 8.257692742786535 Test RE 1.3735276926341107\n",
      "8 Train Loss 42.24899 Test MSE 8.116498202886236 Test RE 1.3617343999649192\n",
      "9 Train Loss 42.093266 Test MSE 8.098834696139635 Test RE 1.360251857571668\n",
      "10 Train Loss 41.779472 Test MSE 8.076479658019522 Test RE 1.3583732234069845\n",
      "11 Train Loss 41.48929 Test MSE 8.245802416773705 Test RE 1.372538458968245\n",
      "12 Train Loss 40.87879 Test MSE 8.170284384048982 Test RE 1.3662389012518412\n",
      "13 Train Loss 40.376244 Test MSE 8.120844264532973 Test RE 1.3620989284521554\n",
      "14 Train Loss 39.921585 Test MSE 8.123081781781089 Test RE 1.36228656349618\n",
      "15 Train Loss 39.477337 Test MSE 8.07265026915156 Test RE 1.3580511551138652\n",
      "16 Train Loss 38.933266 Test MSE 7.7077414913292515 Test RE 1.327002162289515\n",
      "17 Train Loss 37.46245 Test MSE 7.2838123430264385 Test RE 1.289993239912751\n",
      "18 Train Loss 33.11134 Test MSE 6.149695447262842 Test RE 1.1853179591778766\n",
      "19 Train Loss 30.625122 Test MSE 6.401271589564231 Test RE 1.2093198654634059\n",
      "20 Train Loss 28.889044 Test MSE 6.186188293282117 Test RE 1.1888296489143033\n",
      "21 Train Loss 28.14714 Test MSE 6.055997102686469 Test RE 1.1762533941989233\n",
      "22 Train Loss 27.787724 Test MSE 6.071615960030586 Test RE 1.177769239021341\n",
      "23 Train Loss 27.445683 Test MSE 6.282142910445208 Test RE 1.1980142011753818\n",
      "24 Train Loss 27.316471 Test MSE 6.2089812568787135 Test RE 1.191017752143279\n",
      "25 Train Loss 27.139776 Test MSE 6.209647101659247 Test RE 1.1910816121922236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 26.867098 Test MSE 6.169139922877571 Test RE 1.1871903849385472\n",
      "27 Train Loss 26.625889 Test MSE 6.097257448822919 Test RE 1.1802535808659593\n",
      "28 Train Loss 26.342175 Test MSE 6.007276222094289 Test RE 1.1715123228272935\n",
      "29 Train Loss 25.907784 Test MSE 5.859812567463515 Test RE 1.1570441281920838\n",
      "30 Train Loss 25.291037 Test MSE 5.4769226623250225 Test RE 1.1186039910481784\n",
      "31 Train Loss 24.996157 Test MSE 5.251502157537861 Test RE 1.0953422364365761\n",
      "32 Train Loss 24.846752 Test MSE 5.268650977917243 Test RE 1.0971292030041908\n",
      "33 Train Loss 24.666681 Test MSE 5.40802075322034 Test RE 1.1115454750211482\n",
      "34 Train Loss 24.507542 Test MSE 5.4321260685750845 Test RE 1.1140199813341518\n",
      "35 Train Loss 24.283775 Test MSE 5.428064870529984 Test RE 1.113603468384876\n",
      "36 Train Loss 24.144138 Test MSE 5.434638105620215 Test RE 1.1142775357402066\n",
      "37 Train Loss 24.046352 Test MSE 5.303645357480479 Test RE 1.1007667389312983\n",
      "38 Train Loss 23.960361 Test MSE 5.076276081620768 Test RE 1.0769131428919652\n",
      "39 Train Loss 23.612585 Test MSE 4.618627757102606 Test RE 1.0272225411891762\n",
      "40 Train Loss 23.087337 Test MSE 4.437681467146438 Test RE 1.0068994952529948\n",
      "41 Train Loss 21.361298 Test MSE 4.138303714682021 Test RE 0.9723424373420491\n",
      "42 Train Loss 19.333694 Test MSE 4.1330888890470865 Test RE 0.9717296023454619\n",
      "43 Train Loss 18.67202 Test MSE 3.69902772185186 Test RE 0.9192885551526536\n",
      "44 Train Loss 18.216139 Test MSE 3.5850941401575165 Test RE 0.9050203451090331\n",
      "45 Train Loss 17.85257 Test MSE 3.543087885896901 Test RE 0.8997026979924195\n",
      "46 Train Loss 17.62357 Test MSE 3.6837032877183424 Test RE 0.9173823518371056\n",
      "47 Train Loss 17.26992 Test MSE 3.923517849353143 Test RE 0.9467730269688678\n",
      "48 Train Loss 16.999195 Test MSE 4.020560364958252 Test RE 0.9584100382185519\n",
      "49 Train Loss 16.754503 Test MSE 3.8361060538990928 Test RE 0.9361670749892058\n",
      "50 Train Loss 16.53983 Test MSE 3.7529700443487624 Test RE 0.9259672129284301\n",
      "51 Train Loss 16.402002 Test MSE 3.693027388618247 Test RE 0.9185426461133908\n",
      "52 Train Loss 16.25887 Test MSE 3.5593411920118947 Test RE 0.9017639524546615\n",
      "53 Train Loss 16.187737 Test MSE 3.5885337271733118 Test RE 0.9054543853079563\n",
      "54 Train Loss 16.118177 Test MSE 3.5669166170139985 Test RE 0.9027230645365307\n",
      "55 Train Loss 15.900342 Test MSE 3.379507934982057 Test RE 0.8786882025754538\n",
      "56 Train Loss 15.712009 Test MSE 3.364672497556684 Test RE 0.8767574390279372\n",
      "57 Train Loss 15.658869 Test MSE 3.326528317108846 Test RE 0.8717735187949524\n",
      "58 Train Loss 15.505706 Test MSE 3.3075911733661982 Test RE 0.8692885763416813\n",
      "59 Train Loss 14.807257 Test MSE 2.6830414224079204 Test RE 0.7829278629802685\n",
      "60 Train Loss 13.511631 Test MSE 2.3986392059022563 Test RE 0.7402706385843975\n",
      "61 Train Loss 12.119707 Test MSE 2.365438688390505 Test RE 0.7351295968974555\n",
      "62 Train Loss 10.634425 Test MSE 2.152933941498951 Test RE 0.7013316083208915\n",
      "63 Train Loss 9.045395 Test MSE 1.9682981554131367 Test RE 0.6705844879008913\n",
      "64 Train Loss 8.561085 Test MSE 2.031351199376078 Test RE 0.6812406704908153\n",
      "65 Train Loss 8.08042 Test MSE 2.104173761386486 Test RE 0.6933441580559461\n",
      "66 Train Loss 7.315799 Test MSE 2.1029509499757704 Test RE 0.6931426651052625\n",
      "67 Train Loss 6.955105 Test MSE 2.205668491959453 Test RE 0.7098689493386725\n",
      "68 Train Loss 6.5707617 Test MSE 2.2053928968125467 Test RE 0.7098245993945183\n",
      "69 Train Loss 6.334076 Test MSE 2.2792150091730887 Test RE 0.7216069516611648\n",
      "70 Train Loss 6.1919703 Test MSE 2.2807502327778875 Test RE 0.7218499391661695\n",
      "71 Train Loss 6.074622 Test MSE 2.296337231748672 Test RE 0.7243123561219755\n",
      "72 Train Loss 5.82828 Test MSE 2.3073810479962447 Test RE 0.7260519912837624\n",
      "73 Train Loss 5.753186 Test MSE 2.3054927334690634 Test RE 0.7257548372568235\n",
      "74 Train Loss 5.6870937 Test MSE 2.302663016841522 Test RE 0.7253093118709661\n",
      "75 Train Loss 5.628114 Test MSE 2.306313586001252 Test RE 0.7258840254060143\n",
      "76 Train Loss 5.5897765 Test MSE 2.2859335590676215 Test RE 0.7226697265120793\n",
      "77 Train Loss 5.5072875 Test MSE 2.254347826494988 Test RE 0.7176596396073684\n",
      "78 Train Loss 5.4497757 Test MSE 2.258646358399744 Test RE 0.71834352114465\n",
      "79 Train Loss 5.4141855 Test MSE 2.2909072611314856 Test RE 0.7234554866426299\n",
      "80 Train Loss 5.3801184 Test MSE 2.296987214629168 Test RE 0.7244148579050885\n",
      "81 Train Loss 5.3528476 Test MSE 2.279555672474081 Test RE 0.7216608772057708\n",
      "82 Train Loss 5.318796 Test MSE 2.2893098444397237 Test RE 0.7232032151045719\n",
      "83 Train Loss 5.2771893 Test MSE 2.3112418805334394 Test RE 0.7266591717780444\n",
      "84 Train Loss 5.2541876 Test MSE 2.290429220891168 Test RE 0.7233800015097378\n",
      "85 Train Loss 5.227931 Test MSE 2.271596752103892 Test RE 0.7203999596321998\n",
      "86 Train Loss 5.2037106 Test MSE 2.2633946965517064 Test RE 0.7190982092609441\n",
      "87 Train Loss 5.1810226 Test MSE 2.245803547386085 Test RE 0.7162983355983805\n",
      "88 Train Loss 5.1281824 Test MSE 2.239072339777478 Test RE 0.7152240717626344\n",
      "89 Train Loss 5.0948663 Test MSE 2.246722664634613 Test RE 0.716444896683295\n",
      "90 Train Loss 5.057597 Test MSE 2.2546197520687032 Test RE 0.717702921332223\n",
      "91 Train Loss 5.0253024 Test MSE 2.274657224909361 Test RE 0.7208850858711585\n",
      "92 Train Loss 4.9756355 Test MSE 2.244636204638422 Test RE 0.7161121495996631\n",
      "93 Train Loss 4.948372 Test MSE 2.2515574423381284 Test RE 0.7172153501046654\n",
      "94 Train Loss 4.9328513 Test MSE 2.262067662259424 Test RE 0.7188873737628001\n",
      "95 Train Loss 4.9046364 Test MSE 2.2379399584612223 Test RE 0.7150431913178225\n",
      "96 Train Loss 4.8410726 Test MSE 2.237365415429148 Test RE 0.7149513994329382\n",
      "97 Train Loss 4.8131523 Test MSE 2.2570717770588757 Test RE 0.7180930862990375\n",
      "98 Train Loss 4.7785044 Test MSE 2.23732235356556 Test RE 0.7149445191782504\n",
      "99 Train Loss 4.694615 Test MSE 2.207568480960803 Test RE 0.7101746282904838\n",
      "Training time: 71.71\n",
      "KG_stan_tune10\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.919655 Test MSE 8.567905096123335 Test RE 1.3990891348781669\n",
      "1 Train Loss 56.872913 Test MSE 8.312547902332815 Test RE 1.378082255826971\n",
      "2 Train Loss 54.46581 Test MSE 8.802427851853189 Test RE 1.4181079683622773\n",
      "3 Train Loss 48.535973 Test MSE 9.058761612618149 Test RE 1.4386080157528112\n",
      "4 Train Loss 46.169113 Test MSE 8.71954097283715 Test RE 1.411415464772362\n",
      "5 Train Loss 45.7082 Test MSE 8.61842240241455 Test RE 1.4032076643172469\n",
      "6 Train Loss 45.458344 Test MSE 8.601149532605122 Test RE 1.4018008187024975\n",
      "7 Train Loss 44.694366 Test MSE 8.657785147296826 Test RE 1.4064084346522352\n",
      "8 Train Loss 44.60077 Test MSE 8.499554030245339 Test RE 1.3934972942034647\n",
      "9 Train Loss 44.335663 Test MSE 8.348542864568717 Test RE 1.3810627160003344\n",
      "10 Train Loss 44.243706 Test MSE 8.368614335812968 Test RE 1.382721886949992\n",
      "11 Train Loss 44.194725 Test MSE 8.432356507923531 Test RE 1.387977864643711\n",
      "12 Train Loss 43.132755 Test MSE 8.346547234247844 Test RE 1.3808976419629235\n",
      "13 Train Loss 40.507614 Test MSE 7.573438906587012 Test RE 1.3153902652735803\n",
      "14 Train Loss 40.086216 Test MSE 7.835936988380456 Test RE 1.3379920340205897\n",
      "15 Train Loss 39.916924 Test MSE 7.865887986060932 Test RE 1.3405466727233528\n",
      "16 Train Loss 39.757717 Test MSE 7.86322920066512 Test RE 1.3403200913657736\n",
      "17 Train Loss 39.664 Test MSE 7.879875937726851 Test RE 1.3417380940242067\n",
      "18 Train Loss 39.43177 Test MSE 7.884782935168274 Test RE 1.3421557960777983\n",
      "19 Train Loss 39.133736 Test MSE 7.891977663513836 Test RE 1.3427680034523628\n",
      "20 Train Loss 37.50486 Test MSE 7.66638763443749 Test RE 1.3234375342942566\n",
      "21 Train Loss 36.880684 Test MSE 7.938849329267105 Test RE 1.3467495530036082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 36.055286 Test MSE 8.030207660694087 Test RE 1.3544764186852791\n",
      "23 Train Loss 35.71902 Test MSE 8.202002053305073 Test RE 1.3688882544813656\n",
      "24 Train Loss 34.86923 Test MSE 8.093655992858682 Test RE 1.3598168896110188\n",
      "25 Train Loss 34.43611 Test MSE 8.25907532795463 Test RE 1.3736426726650608\n",
      "26 Train Loss 34.27055 Test MSE 8.291897669885202 Test RE 1.3763694587956232\n",
      "27 Train Loss 33.986683 Test MSE 8.229865528722339 Test RE 1.3712114461438847\n",
      "28 Train Loss 32.713837 Test MSE 8.441720388855472 Test RE 1.3887483048696474\n",
      "29 Train Loss 31.980555 Test MSE 8.695915802199554 Test RE 1.4095020871894037\n",
      "30 Train Loss 31.357506 Test MSE 8.66111360895382 Test RE 1.4066787535986673\n",
      "31 Train Loss 30.910461 Test MSE 8.845525641735312 Test RE 1.4215753465302277\n",
      "32 Train Loss 30.523605 Test MSE 8.956249432385883 Test RE 1.4304449550858591\n",
      "33 Train Loss 29.759647 Test MSE 8.531447308355068 Test RE 1.396109289082972\n",
      "34 Train Loss 29.489147 Test MSE 8.64034466998561 Test RE 1.4049911668914419\n",
      "35 Train Loss 29.223103 Test MSE 8.63774644881821 Test RE 1.404779904933583\n",
      "36 Train Loss 29.009022 Test MSE 8.515594278422714 Test RE 1.3948115694390777\n",
      "37 Train Loss 28.543308 Test MSE 8.511935701817043 Test RE 1.3945119090140616\n",
      "38 Train Loss 28.25189 Test MSE 8.53756126354692 Test RE 1.3966094516354703\n",
      "39 Train Loss 28.179684 Test MSE 8.450602142224335 Test RE 1.3894786818962277\n",
      "40 Train Loss 28.073887 Test MSE 8.552532713467526 Test RE 1.397833461000354\n",
      "41 Train Loss 27.947512 Test MSE 8.676814615564682 Test RE 1.40795320125523\n",
      "42 Train Loss 27.830502 Test MSE 8.61257810915948 Test RE 1.4027318145942043\n",
      "43 Train Loss 27.74915 Test MSE 8.648090779707067 Test RE 1.4056208164037718\n",
      "44 Train Loss 27.518394 Test MSE 8.807905073183502 Test RE 1.4185491013905718\n",
      "45 Train Loss 27.466988 Test MSE 8.77038898957914 Test RE 1.4155248182944324\n",
      "46 Train Loss 27.392876 Test MSE 8.704352816674874 Test RE 1.4101856900840517\n",
      "47 Train Loss 27.315506 Test MSE 8.773786348502396 Test RE 1.4157989555221002\n",
      "48 Train Loss 27.224003 Test MSE 8.822698760573111 Test RE 1.4197398934898764\n",
      "49 Train Loss 27.140846 Test MSE 8.798001765551865 Test RE 1.4177513930188574\n",
      "50 Train Loss 27.037838 Test MSE 8.70926191986645 Test RE 1.4105832940998633\n",
      "51 Train Loss 27.009743 Test MSE 8.683801321733952 Test RE 1.408519940106552\n",
      "52 Train Loss 26.89309 Test MSE 8.604004874427325 Test RE 1.4020334787878963\n",
      "53 Train Loss 26.785753 Test MSE 8.552991177747153 Test RE 1.3978709264006075\n",
      "54 Train Loss 26.668695 Test MSE 8.587095739692025 Test RE 1.400655118796767\n",
      "55 Train Loss 26.599371 Test MSE 8.488787733310893 Test RE 1.392614450257812\n",
      "56 Train Loss 26.547958 Test MSE 8.571225854581332 Test RE 1.3993602388956687\n",
      "57 Train Loss 26.481503 Test MSE 8.519114517166232 Test RE 1.395099838362586\n",
      "58 Train Loss 26.42094 Test MSE 8.497792684588442 Test RE 1.3933529008877588\n",
      "59 Train Loss 26.35817 Test MSE 8.585967415479397 Test RE 1.4005630943771972\n",
      "60 Train Loss 26.28069 Test MSE 8.512320321062097 Test RE 1.3945434147771258\n",
      "61 Train Loss 26.138672 Test MSE 8.440022823420973 Test RE 1.3886086645154754\n",
      "62 Train Loss 26.021868 Test MSE 8.546149472725153 Test RE 1.3973117223937517\n",
      "63 Train Loss 25.910408 Test MSE 8.610563482072871 Test RE 1.4025677436996582\n",
      "64 Train Loss 25.54528 Test MSE 8.110937808643994 Test RE 1.3612678762758998\n",
      "65 Train Loss 24.47694 Test MSE 7.84448325160817 Test RE 1.3387214755657404\n",
      "66 Train Loss 23.941374 Test MSE 7.733268315394939 Test RE 1.3291977568521633\n",
      "67 Train Loss 23.62478 Test MSE 7.698522464669759 Test RE 1.3262083286738857\n",
      "68 Train Loss 23.34956 Test MSE 7.70467049099673 Test RE 1.3267377767953563\n",
      "69 Train Loss 22.923351 Test MSE 7.6643112967480675 Test RE 1.323258304554878\n",
      "70 Train Loss 22.66927 Test MSE 7.724155054671529 Test RE 1.3284143302300129\n",
      "71 Train Loss 22.515106 Test MSE 7.851420040451793 Test RE 1.3393132529865521\n",
      "72 Train Loss 22.455475 Test MSE 7.9840828993178405 Test RE 1.3505808237442036\n",
      "73 Train Loss 22.36439 Test MSE 8.014147296357786 Test RE 1.3531212686544996\n",
      "74 Train Loss 22.257977 Test MSE 7.855423263274516 Test RE 1.3396546489441332\n",
      "75 Train Loss 22.123783 Test MSE 7.770918165985503 Test RE 1.3324294651100892\n",
      "76 Train Loss 22.050377 Test MSE 7.894619546325366 Test RE 1.3429927341236991\n",
      "77 Train Loss 21.96273 Test MSE 7.859152418133914 Test RE 1.3399725940575709\n",
      "78 Train Loss 21.877842 Test MSE 7.875803432634234 Test RE 1.3413913283226993\n",
      "79 Train Loss 21.83257 Test MSE 7.938765570630968 Test RE 1.3467424485607205\n",
      "80 Train Loss 21.767376 Test MSE 7.802503336895429 Test RE 1.335134572419576\n",
      "81 Train Loss 21.713531 Test MSE 7.815811962430707 Test RE 1.3362727478709713\n",
      "82 Train Loss 21.632866 Test MSE 7.863131719387286 Test RE 1.3403117832955889\n",
      "83 Train Loss 21.535614 Test MSE 7.911123782849511 Test RE 1.3443958098072537\n",
      "84 Train Loss 21.444893 Test MSE 7.995447027509733 Test RE 1.3515416552037083\n",
      "85 Train Loss 21.379707 Test MSE 8.037190206006308 Test RE 1.3550651729437202\n",
      "86 Train Loss 21.228935 Test MSE 7.993569021868828 Test RE 1.3513829178681211\n",
      "87 Train Loss 21.17123 Test MSE 7.867448677267395 Test RE 1.3406796567957995\n",
      "88 Train Loss 21.10684 Test MSE 7.838134611537784 Test RE 1.3381796437569453\n",
      "89 Train Loss 21.071987 Test MSE 7.850196855642475 Test RE 1.3392089220866636\n",
      "90 Train Loss 21.018757 Test MSE 7.832096061231368 Test RE 1.3376640732514902\n",
      "91 Train Loss 20.965708 Test MSE 7.8655710718340845 Test RE 1.3405196673431383\n",
      "92 Train Loss 20.893082 Test MSE 7.818418135439747 Test RE 1.336495518564513\n",
      "93 Train Loss 20.8552 Test MSE 7.865659974689849 Test RE 1.3405272431242732\n",
      "94 Train Loss 20.823235 Test MSE 7.959677858101602 Test RE 1.3485150756983233\n",
      "95 Train Loss 20.721851 Test MSE 7.972702266296505 Test RE 1.3496179112754045\n",
      "96 Train Loss 20.672256 Test MSE 7.887099806698451 Test RE 1.342352971712184\n",
      "97 Train Loss 20.595753 Test MSE 7.927361277963517 Test RE 1.3457747814431489\n",
      "98 Train Loss 20.535133 Test MSE 7.993142320861173 Test RE 1.3513468486137805\n",
      "99 Train Loss 20.371185 Test MSE 8.05386208698824 Test RE 1.3564698791424135\n",
      "Training time: 71.29\n",
      "KG_stan_tune10\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.966164 Test MSE 8.539695601759053 Test RE 1.3967840126461362\n",
      "1 Train Loss 58.85904 Test MSE 8.494476697826432 Test RE 1.3930810190728042\n",
      "2 Train Loss 58.12417 Test MSE 8.806920630096528 Test RE 1.4184698248845526\n",
      "3 Train Loss 56.595013 Test MSE 8.696105575712567 Test RE 1.4095174670935695\n",
      "4 Train Loss 52.58233 Test MSE 8.875838209786048 Test RE 1.4240090484290413\n",
      "5 Train Loss 48.596214 Test MSE 8.79467362065571 Test RE 1.4174832111916285\n",
      "6 Train Loss 46.871452 Test MSE 8.74564268996529 Test RE 1.4135264037739979\n",
      "7 Train Loss 46.08776 Test MSE 8.452513312512627 Test RE 1.3896357937921058\n",
      "8 Train Loss 45.19975 Test MSE 8.460891712096185 Test RE 1.3903243487665689\n",
      "9 Train Loss 44.60497 Test MSE 8.56175421036766 Test RE 1.3985868427552874\n",
      "10 Train Loss 44.154335 Test MSE 8.677968261918389 Test RE 1.408046797013718\n",
      "11 Train Loss 43.90694 Test MSE 8.694101211905489 Test RE 1.4093550180188208\n",
      "12 Train Loss 43.805283 Test MSE 8.61275284611074 Test RE 1.4027460442380109\n",
      "13 Train Loss 43.59869 Test MSE 8.598164453089733 Test RE 1.401557545985379\n",
      "14 Train Loss 43.4441 Test MSE 8.686380746096678 Test RE 1.4087291169840719\n",
      "15 Train Loss 43.26527 Test MSE 8.697388207409286 Test RE 1.4096214116182662\n",
      "16 Train Loss 43.098907 Test MSE 8.709758926687895 Test RE 1.410623542029265\n",
      "17 Train Loss 43.005188 Test MSE 8.779648525909767 Test RE 1.4162718573249908\n",
      "18 Train Loss 42.724087 Test MSE 9.031695701960823 Test RE 1.4364572601890815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Train Loss 42.497078 Test MSE 9.23241382505966 Test RE 1.4523312813550504\n",
      "20 Train Loss 42.171196 Test MSE 9.312480239682667 Test RE 1.4586152249362776\n",
      "21 Train Loss 39.87926 Test MSE 8.33350333458683 Test RE 1.3798181936210634\n",
      "22 Train Loss 38.086544 Test MSE 8.064460963184553 Test RE 1.3573621423335955\n",
      "23 Train Loss 36.721752 Test MSE 7.8967459365851385 Test RE 1.3431735873226869\n",
      "24 Train Loss 34.89859 Test MSE 7.436924405508746 Test RE 1.3034811160522088\n",
      "25 Train Loss 32.606976 Test MSE 7.4435154215084 Test RE 1.304058596859573\n",
      "26 Train Loss 31.181767 Test MSE 7.269393860216056 Test RE 1.2887158210102554\n",
      "27 Train Loss 28.930185 Test MSE 6.362878682617672 Test RE 1.2056878424167552\n",
      "28 Train Loss 27.888733 Test MSE 6.333092728968103 Test RE 1.202862494710097\n",
      "29 Train Loss 24.857063 Test MSE 5.36447956360362 Test RE 1.107061780850224\n",
      "30 Train Loss 22.530113 Test MSE 5.3723677071804605 Test RE 1.1078754156415451\n",
      "31 Train Loss 21.734676 Test MSE 5.447038323363006 Test RE 1.1155480353625338\n",
      "32 Train Loss 19.190971 Test MSE 3.9634816418792465 Test RE 0.951582585845009\n",
      "33 Train Loss 18.198326 Test MSE 3.3238464119317546 Test RE 0.8714220284246107\n",
      "34 Train Loss 17.671808 Test MSE 2.9302023805533346 Test RE 0.8181950895099761\n",
      "35 Train Loss 16.040945 Test MSE 2.248793225751685 Test RE 0.7167749555161322\n",
      "36 Train Loss 14.236548 Test MSE 2.1674009927707885 Test RE 0.7036840289725936\n",
      "37 Train Loss 13.153028 Test MSE 2.284516347302227 Test RE 0.7224456747622268\n",
      "38 Train Loss 12.181248 Test MSE 2.2544105240372665 Test RE 0.7176696192525278\n",
      "39 Train Loss 11.369381 Test MSE 1.998621476573813 Test RE 0.6757302096604014\n",
      "40 Train Loss 10.233202 Test MSE 1.4756924624333252 Test RE 0.5806387150597535\n",
      "41 Train Loss 9.578896 Test MSE 1.2240008365394304 Test RE 0.5288090969608257\n",
      "42 Train Loss 7.0524697 Test MSE 0.7431633690153853 Test RE 0.4120502744229184\n",
      "43 Train Loss 5.7479687 Test MSE 0.4549044975574768 Test RE 0.32238006283484294\n",
      "44 Train Loss 4.5720277 Test MSE 0.4853450086742151 Test RE 0.33299165054372987\n",
      "45 Train Loss 4.159921 Test MSE 0.46696049701228914 Test RE 0.32662402892653963\n",
      "46 Train Loss 3.0492084 Test MSE 0.30992435920670086 Test RE 0.26609451114454624\n",
      "47 Train Loss 2.7194245 Test MSE 0.2367933649804313 Test RE 0.2325909566010633\n",
      "48 Train Loss 2.2620363 Test MSE 0.20687820763976766 Test RE 0.21740294993784595\n",
      "49 Train Loss 1.8873847 Test MSE 0.16466460827848134 Test RE 0.19395822138996607\n",
      "50 Train Loss 1.5506988 Test MSE 0.11171559230350961 Test RE 0.15975886134119693\n",
      "51 Train Loss 1.272178 Test MSE 0.07337324404198847 Test RE 0.12947231719390445\n",
      "52 Train Loss 1.13897 Test MSE 0.06488662809996584 Test RE 0.12175467993767392\n",
      "53 Train Loss 0.9955683 Test MSE 0.0722526210050089 Test RE 0.12847980337036735\n",
      "54 Train Loss 0.86544794 Test MSE 0.06554961897557014 Test RE 0.12237512433771852\n",
      "55 Train Loss 0.74029285 Test MSE 0.04590342621909516 Test RE 0.10240722819393273\n",
      "56 Train Loss 0.6634952 Test MSE 0.044151023826634245 Test RE 0.10043346579947991\n",
      "57 Train Loss 0.5887951 Test MSE 0.051183389252426985 Test RE 0.10813656764492016\n",
      "58 Train Loss 0.5177349 Test MSE 0.058871285810073205 Test RE 0.11597378223159399\n",
      "59 Train Loss 0.4780793 Test MSE 0.06431409376685367 Test RE 0.12121633182668116\n",
      "60 Train Loss 0.45794266 Test MSE 0.057092842805377214 Test RE 0.11420862275449997\n",
      "61 Train Loss 0.3926646 Test MSE 0.044291229018984864 Test RE 0.1005928067480145\n",
      "62 Train Loss 0.36574954 Test MSE 0.042498465237584215 Test RE 0.09853594443839293\n",
      "63 Train Loss 0.33545798 Test MSE 0.03318903884270207 Test RE 0.0870773889301281\n",
      "64 Train Loss 0.31885055 Test MSE 0.0334922067209602 Test RE 0.08747419245109628\n",
      "65 Train Loss 0.2988847 Test MSE 0.036958999914735974 Test RE 0.09188998185687769\n",
      "66 Train Loss 0.28126204 Test MSE 0.035636185122416994 Test RE 0.09023056222312585\n",
      "67 Train Loss 0.27373898 Test MSE 0.03381721314240229 Test RE 0.08789759000656922\n",
      "68 Train Loss 0.26357237 Test MSE 0.03091485676985383 Test RE 0.08404109060801133\n",
      "69 Train Loss 0.24492721 Test MSE 0.026784188006596658 Test RE 0.078225311760453\n",
      "70 Train Loss 0.2397168 Test MSE 0.025459155311906734 Test RE 0.07626583956496272\n",
      "71 Train Loss 0.23172426 Test MSE 0.024830905210081283 Test RE 0.07531896375072998\n",
      "72 Train Loss 0.2267571 Test MSE 0.026897558132906976 Test RE 0.07839069009655006\n",
      "73 Train Loss 0.21695895 Test MSE 0.02467123509663821 Test RE 0.07507641152024348\n",
      "74 Train Loss 0.20078972 Test MSE 0.018009490181923805 Test RE 0.06414440333236152\n",
      "75 Train Loss 0.19201726 Test MSE 0.015084137205466926 Test RE 0.05870408149694664\n",
      "76 Train Loss 0.18864632 Test MSE 0.015434040849049523 Test RE 0.05938105140249344\n",
      "77 Train Loss 0.17177117 Test MSE 0.014071807358408267 Test RE 0.05669999241577878\n",
      "78 Train Loss 0.14808902 Test MSE 0.01307233857907915 Test RE 0.05464931266973549\n",
      "79 Train Loss 0.14063627 Test MSE 0.013059570174372424 Test RE 0.0546226167954514\n",
      "80 Train Loss 0.12976378 Test MSE 0.013816986945399621 Test RE 0.05618426889314665\n",
      "81 Train Loss 0.12273125 Test MSE 0.01297257443757722 Test RE 0.0544403797501802\n",
      "82 Train Loss 0.120593965 Test MSE 0.01244382566758818 Test RE 0.053319371234956815\n",
      "83 Train Loss 0.11690348 Test MSE 0.013434597905742552 Test RE 0.05540135625196949\n",
      "84 Train Loss 0.113441885 Test MSE 0.013749956457911907 Test RE 0.05604781954854973\n",
      "85 Train Loss 0.1086951 Test MSE 0.013215569212988056 Test RE 0.05494788707555227\n",
      "86 Train Loss 0.103184916 Test MSE 0.013838177924785767 Test RE 0.05622733702137053\n",
      "87 Train Loss 0.09893911 Test MSE 0.013334429770694808 Test RE 0.055194434040013333\n",
      "88 Train Loss 0.09717593 Test MSE 0.013115164725094419 Test RE 0.0547387574813008\n",
      "89 Train Loss 0.09473854 Test MSE 0.013076345663394492 Test RE 0.05465768789745323\n",
      "90 Train Loss 0.0888205 Test MSE 0.012613889048749502 Test RE 0.053682479088446866\n",
      "91 Train Loss 0.08478434 Test MSE 0.012001587445775161 Test RE 0.0523633480687326\n",
      "92 Train Loss 0.082262784 Test MSE 0.012929469842616807 Test RE 0.05434985866315017\n",
      "93 Train Loss 0.081123754 Test MSE 0.013097661464245564 Test RE 0.054702218609990846\n",
      "94 Train Loss 0.08010554 Test MSE 0.012295131162313663 Test RE 0.052999850348367045\n",
      "95 Train Loss 0.07741652 Test MSE 0.013321338251779846 Test RE 0.05516733290292867\n",
      "96 Train Loss 0.0749092 Test MSE 0.014921768043358027 Test RE 0.05838727444888803\n",
      "97 Train Loss 0.07303911 Test MSE 0.013653247612784835 Test RE 0.05585036858236454\n",
      "98 Train Loss 0.07131311 Test MSE 0.013562792511643123 Test RE 0.055665052010611504\n",
      "99 Train Loss 0.06915967 Test MSE 0.013725816515497452 Test RE 0.055998598101815296\n",
      "Training time: 72.38\n",
      "KG_stan_tune10\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.71428 Test MSE 8.500606860415997 Test RE 1.3935835970000097\n",
      "1 Train Loss 55.527798 Test MSE 8.532969475482258 Test RE 1.396233829316751\n",
      "2 Train Loss 54.858074 Test MSE 8.204316853094053 Test RE 1.369081407243508\n",
      "3 Train Loss 51.56897 Test MSE 7.245665812969865 Test RE 1.286610851579816\n",
      "4 Train Loss 48.167484 Test MSE 7.582929434243371 Test RE 1.3162141868331472\n",
      "5 Train Loss 45.225185 Test MSE 7.860548666278164 Test RE 1.3400916177803994\n",
      "6 Train Loss 43.641815 Test MSE 7.93483838408958 Test RE 1.3464093008553777\n",
      "7 Train Loss 43.254227 Test MSE 7.836613785238103 Test RE 1.3380498145548831\n",
      "8 Train Loss 42.922813 Test MSE 7.79585390944612 Test RE 1.3345655388435598\n",
      "9 Train Loss 41.519176 Test MSE 7.996288620832499 Test RE 1.3516127843412307\n",
      "10 Train Loss 40.422108 Test MSE 7.440569365314532 Test RE 1.3038005057626962\n",
      "11 Train Loss 39.65293 Test MSE 7.351463391428152 Test RE 1.295970034074616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 38.43503 Test MSE 7.538966879596865 Test RE 1.3123932195904402\n",
      "13 Train Loss 37.34372 Test MSE 7.32381771344232 Test RE 1.2935309471068224\n",
      "14 Train Loss 36.94189 Test MSE 7.179547941837103 Test RE 1.2807271324057936\n",
      "15 Train Loss 35.229168 Test MSE 6.740273603648166 Test RE 1.2409286836411086\n",
      "16 Train Loss 34.173584 Test MSE 6.5750382630317805 Test RE 1.2256238472479029\n",
      "17 Train Loss 32.334667 Test MSE 6.721919788042192 Test RE 1.2392380028632979\n",
      "18 Train Loss 30.881516 Test MSE 6.504767920325355 Test RE 1.2190568619106033\n",
      "19 Train Loss 28.932617 Test MSE 6.182511997385224 Test RE 1.1884763506582408\n",
      "20 Train Loss 27.34581 Test MSE 5.9444926904426065 Test RE 1.1653743606432503\n",
      "21 Train Loss 26.67228 Test MSE 5.987183543735251 Test RE 1.1695514894044097\n",
      "22 Train Loss 24.877188 Test MSE 4.764199631254526 Test RE 1.0432851743372797\n",
      "23 Train Loss 19.865662 Test MSE 2.990077049090508 Test RE 0.8265121648353208\n",
      "24 Train Loss 17.538647 Test MSE 2.823616480980415 Test RE 0.8031763544660039\n",
      "25 Train Loss 15.948959 Test MSE 2.944657526123019 Test RE 0.820210748701457\n",
      "26 Train Loss 15.41956 Test MSE 2.701303128748719 Test RE 0.7855877832569431\n",
      "27 Train Loss 12.247131 Test MSE 2.630292568253348 Test RE 0.775193440606229\n",
      "28 Train Loss 9.093092 Test MSE 2.204290246754409 Test RE 0.7096471285245234\n",
      "29 Train Loss 8.704918 Test MSE 2.1236944418429737 Test RE 0.6965528531617914\n",
      "30 Train Loss 7.892419 Test MSE 2.0095027762569053 Test RE 0.6775671863520262\n",
      "31 Train Loss 7.6309285 Test MSE 2.03147318272356 Test RE 0.6812611245535947\n",
      "32 Train Loss 7.385808 Test MSE 2.0376343592161805 Test RE 0.6822934277038911\n",
      "33 Train Loss 7.162278 Test MSE 2.0728806879043633 Test RE 0.6881691710809166\n",
      "34 Train Loss 7.0088005 Test MSE 2.10533017413515 Test RE 0.6935346560809328\n",
      "35 Train Loss 6.7196226 Test MSE 2.0194377467674873 Test RE 0.679240065419058\n",
      "36 Train Loss 6.490549 Test MSE 2.045853557499448 Test RE 0.6836681250765506\n",
      "37 Train Loss 6.290036 Test MSE 2.1065104205942777 Test RE 0.6937290263383495\n",
      "38 Train Loss 6.0938687 Test MSE 2.0923554631397843 Test RE 0.6913942985831428\n",
      "39 Train Loss 5.981333 Test MSE 2.07134393523727 Test RE 0.6879140329309723\n",
      "40 Train Loss 5.867559 Test MSE 2.073248743751921 Test RE 0.6882302632235665\n",
      "41 Train Loss 5.78164 Test MSE 2.059500363387305 Test RE 0.6859445292586265\n",
      "42 Train Loss 5.6988554 Test MSE 2.0586243345666357 Test RE 0.6857986271015455\n",
      "43 Train Loss 5.6168633 Test MSE 2.090823264821579 Test RE 0.6911411037488893\n",
      "44 Train Loss 5.497428 Test MSE 2.1393154904343743 Test RE 0.6991099419171957\n",
      "45 Train Loss 5.390366 Test MSE 2.135308090049349 Test RE 0.6984548429614476\n",
      "46 Train Loss 5.300763 Test MSE 2.1770471775743108 Test RE 0.7052481904934877\n",
      "47 Train Loss 5.2331524 Test MSE 2.152793360257752 Test RE 0.7013087103406915\n",
      "48 Train Loss 5.2035685 Test MSE 2.1501628476061607 Test RE 0.700880112464633\n",
      "49 Train Loss 5.1621914 Test MSE 2.1717082900995957 Test RE 0.7043829010250211\n",
      "50 Train Loss 5.114049 Test MSE 2.1714735811887977 Test RE 0.7043448366562058\n",
      "51 Train Loss 5.0752087 Test MSE 2.1444453279786035 Test RE 0.6999476334870632\n",
      "52 Train Loss 5.0475287 Test MSE 2.15074465136609 Test RE 0.7009749301907315\n",
      "53 Train Loss 4.978911 Test MSE 2.1659963821927977 Test RE 0.7034559765212121\n",
      "54 Train Loss 4.9399905 Test MSE 2.130453442166251 Test RE 0.6976604185495107\n",
      "55 Train Loss 4.9080915 Test MSE 2.1469749354471177 Test RE 0.700360344152614\n",
      "56 Train Loss 4.883127 Test MSE 2.153345606970621 Test RE 0.7013986564085593\n",
      "57 Train Loss 4.8607755 Test MSE 2.1510209506515268 Test RE 0.7010199547482193\n",
      "58 Train Loss 4.848914 Test MSE 2.1535183671363067 Test RE 0.701426792003095\n",
      "59 Train Loss 4.822816 Test MSE 2.1536048449488865 Test RE 0.7014408752927115\n",
      "60 Train Loss 4.8060265 Test MSE 2.1524640876472634 Test RE 0.7012550752392697\n",
      "61 Train Loss 4.781121 Test MSE 2.1567451588369155 Test RE 0.7019520977020746\n",
      "62 Train Loss 4.756587 Test MSE 2.1592673042980604 Test RE 0.7023624169274849\n",
      "63 Train Loss 4.7249446 Test MSE 2.154933658631349 Test RE 0.7016572428637604\n",
      "64 Train Loss 4.703768 Test MSE 2.15383256791037 Test RE 0.7014779596193551\n",
      "65 Train Loss 4.6912236 Test MSE 2.1589921951126256 Test RE 0.7023176720024163\n",
      "66 Train Loss 4.6741366 Test MSE 2.15760397651973 Test RE 0.7020918427409685\n",
      "67 Train Loss 4.6665626 Test MSE 2.1568360238908615 Test RE 0.7019668843919101\n",
      "68 Train Loss 4.656391 Test MSE 2.1468431275142135 Test RE 0.7003388454232622\n",
      "69 Train Loss 4.6456165 Test MSE 2.1513863471089625 Test RE 0.7010794937617209\n",
      "70 Train Loss 4.6272545 Test MSE 2.155966359809954 Test RE 0.7018253490760876\n",
      "71 Train Loss 4.6095934 Test MSE 2.1427016286300034 Test RE 0.699663003605953\n",
      "72 Train Loss 4.5978346 Test MSE 2.145816174153189 Test RE 0.7001713200571555\n",
      "73 Train Loss 4.584748 Test MSE 2.1488576725035546 Test RE 0.7006673587806038\n",
      "74 Train Loss 4.5674186 Test MSE 2.138567083326729 Test RE 0.698987644710461\n",
      "75 Train Loss 4.561878 Test MSE 2.142867708791433 Test RE 0.6996901184154672\n",
      "76 Train Loss 4.556136 Test MSE 2.141402047993907 Test RE 0.6994507933774743\n",
      "77 Train Loss 4.5499754 Test MSE 2.138033075066191 Test RE 0.6989003693372592\n",
      "78 Train Loss 4.536311 Test MSE 2.1356881417374507 Test RE 0.6985169972550057\n",
      "79 Train Loss 4.528714 Test MSE 2.1302933607220482 Test RE 0.697634207090678\n",
      "80 Train Loss 4.52326 Test MSE 2.13078399063583 Test RE 0.6977145388683885\n",
      "81 Train Loss 4.51534 Test MSE 2.1300695526085183 Test RE 0.6975975594862154\n",
      "82 Train Loss 4.509939 Test MSE 2.12987739838974 Test RE 0.6975660935331138\n",
      "83 Train Loss 4.5033593 Test MSE 2.129496271751781 Test RE 0.697503678458251\n",
      "84 Train Loss 4.497661 Test MSE 2.132088059011597 Test RE 0.6979280115383685\n",
      "85 Train Loss 4.489972 Test MSE 2.127242156070219 Test RE 0.6971344197075822\n",
      "86 Train Loss 4.4825716 Test MSE 2.1252241947502424 Test RE 0.6968036806616634\n",
      "87 Train Loss 4.4775205 Test MSE 2.1194609304763317 Test RE 0.6958582298099977\n",
      "88 Train Loss 4.4612274 Test MSE 2.1204627241421345 Test RE 0.6960226640776986\n",
      "89 Train Loss 4.4351683 Test MSE 2.109347668452166 Test RE 0.6941960591272104\n",
      "90 Train Loss 4.3669405 Test MSE 2.0872591042505793 Test RE 0.6905517692504181\n",
      "91 Train Loss 4.267691 Test MSE 2.0720861086792786 Test RE 0.6880372635040819\n",
      "92 Train Loss 3.9165092 Test MSE 2.029656033562223 Test RE 0.6809563629519505\n",
      "93 Train Loss 2.9097624 Test MSE 1.6875629276100714 Test RE 0.620923430742993\n",
      "94 Train Loss 2.345503 Test MSE 1.4512823086546645 Test RE 0.5758163746493462\n",
      "95 Train Loss 1.8533385 Test MSE 1.3449079573188607 Test RE 0.5543120783110964\n",
      "96 Train Loss 1.5443416 Test MSE 1.246578536815587 Test RE 0.5336639701905115\n",
      "97 Train Loss 1.2220492 Test MSE 1.0652246828014527 Test RE 0.49331994094414067\n",
      "98 Train Loss 1.0767596 Test MSE 0.8891182251301827 Test RE 0.4507002682209275\n",
      "99 Train Loss 0.97014076 Test MSE 0.7070703137443081 Test RE 0.40191976352150954\n",
      "Training time: 71.44\n",
      "KG_stan_tune10\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.27639 Test MSE 8.530369295020552 Test RE 1.3960210817764327\n",
      "1 Train Loss 56.192493 Test MSE 8.55216215962221 Test RE 1.397803178849319\n",
      "2 Train Loss 49.979362 Test MSE 8.093971511704035 Test RE 1.3598433945473487\n",
      "3 Train Loss 48.013386 Test MSE 8.41484773185206 Test RE 1.3865361311464142\n",
      "4 Train Loss 43.700264 Test MSE 8.392654045540404 Test RE 1.3847064685179329\n",
      "5 Train Loss 42.839333 Test MSE 8.141438435868993 Test RE 1.3638249520056949\n",
      "6 Train Loss 42.46389 Test MSE 8.200344203660647 Test RE 1.368749902553364\n",
      "7 Train Loss 41.650658 Test MSE 8.341654763788618 Test RE 1.3804928643310879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 41.40397 Test MSE 8.412779642096954 Test RE 1.386365738439153\n",
      "9 Train Loss 40.207153 Test MSE 8.12652973453406 Test RE 1.3625756533700646\n",
      "10 Train Loss 39.284615 Test MSE 8.111636250782391 Test RE 1.3613264851816669\n",
      "11 Train Loss 39.089912 Test MSE 7.977466914700586 Test RE 1.350021130545156\n",
      "12 Train Loss 38.451904 Test MSE 7.860961888756263 Test RE 1.3401268410660285\n",
      "13 Train Loss 38.20144 Test MSE 7.852819383176702 Test RE 1.3394325992161429\n",
      "14 Train Loss 35.91924 Test MSE 6.853479646375879 Test RE 1.2513062793048877\n",
      "15 Train Loss 32.285515 Test MSE 6.628356367639586 Test RE 1.2305832096832845\n",
      "16 Train Loss 27.64232 Test MSE 6.194428522618244 Test RE 1.189621167731816\n",
      "17 Train Loss 26.569988 Test MSE 5.959549208112348 Test RE 1.1668492874332614\n",
      "18 Train Loss 24.78376 Test MSE 6.040329600556651 Test RE 1.1747308631359414\n",
      "19 Train Loss 24.342106 Test MSE 5.776991042575325 Test RE 1.1488383044877626\n",
      "20 Train Loss 24.02759 Test MSE 5.816074365663691 Test RE 1.1527178961668176\n",
      "21 Train Loss 23.506258 Test MSE 5.763693534573352 Test RE 1.1475153417589377\n",
      "22 Train Loss 23.088005 Test MSE 5.6348100054615475 Test RE 1.1346128525771246\n",
      "23 Train Loss 22.795506 Test MSE 5.460717109058191 Test RE 1.116947857951395\n",
      "24 Train Loss 22.530624 Test MSE 5.316436817490669 Test RE 1.1020933674221975\n",
      "25 Train Loss 22.123055 Test MSE 5.4805274297152105 Test RE 1.1189720484561863\n",
      "26 Train Loss 20.502876 Test MSE 5.2958065276450625 Test RE 1.0999529671515307\n",
      "27 Train Loss 19.411327 Test MSE 5.326030065937275 Test RE 1.1030872558748446\n",
      "28 Train Loss 18.501331 Test MSE 5.471707290005194 Test RE 1.1180712716592647\n",
      "29 Train Loss 17.453785 Test MSE 5.351527374019977 Test RE 1.105724508573198\n",
      "30 Train Loss 16.843046 Test MSE 5.762046128268404 Test RE 1.1473513358919094\n",
      "31 Train Loss 16.269045 Test MSE 5.785862174728187 Test RE 1.1497200426485723\n",
      "32 Train Loss 15.757624 Test MSE 5.724369271272906 Test RE 1.1435940343200632\n",
      "33 Train Loss 15.513351 Test MSE 5.579650305414408 Test RE 1.1290457774444285\n",
      "34 Train Loss 15.181608 Test MSE 5.727161080991106 Test RE 1.1438728692106752\n",
      "35 Train Loss 14.7231655 Test MSE 5.660687931122438 Test RE 1.1372152290142858\n",
      "36 Train Loss 14.357067 Test MSE 5.608045788483741 Test RE 1.1319150535605162\n",
      "37 Train Loss 13.898544 Test MSE 5.617098441491256 Test RE 1.1328282684983015\n",
      "38 Train Loss 13.546719 Test MSE 5.603077345114485 Test RE 1.1314135328687076\n",
      "39 Train Loss 13.232728 Test MSE 5.790579127016061 Test RE 1.1501886045979246\n",
      "40 Train Loss 12.8502865 Test MSE 5.841174546176852 Test RE 1.1552025856628112\n",
      "41 Train Loss 12.532991 Test MSE 5.8911398747157975 Test RE 1.1601328584356798\n",
      "42 Train Loss 12.233709 Test MSE 5.949332537741228 Test RE 1.1658486724710222\n",
      "43 Train Loss 12.051078 Test MSE 5.952748681560936 Test RE 1.166183343222089\n",
      "44 Train Loss 11.839912 Test MSE 5.98956454071715 Test RE 1.1697840212572257\n",
      "45 Train Loss 11.702633 Test MSE 6.035356383259277 Test RE 1.1742471647907444\n",
      "46 Train Loss 11.514644 Test MSE 5.9561027922222065 Test RE 1.1665118433283792\n",
      "47 Train Loss 11.397233 Test MSE 5.933399053303599 Test RE 1.1642864395808137\n",
      "48 Train Loss 11.278078 Test MSE 5.864536183030196 Test RE 1.1575103829237947\n",
      "49 Train Loss 11.187486 Test MSE 5.868309064712813 Test RE 1.1578826585328035\n",
      "50 Train Loss 11.044011 Test MSE 5.90699530555418 Test RE 1.1616930018569036\n",
      "51 Train Loss 10.944527 Test MSE 5.84555773841734 Test RE 1.15563593390668\n",
      "52 Train Loss 10.794434 Test MSE 5.771426268801602 Test RE 1.1482848532614771\n",
      "53 Train Loss 10.688749 Test MSE 5.806679246258055 Test RE 1.1517864861884797\n",
      "54 Train Loss 10.515978 Test MSE 5.807581026090868 Test RE 1.1518759191895147\n",
      "55 Train Loss 10.349735 Test MSE 5.7990664515027355 Test RE 1.1510312188885594\n",
      "56 Train Loss 10.134105 Test MSE 5.746595986299441 Test RE 1.1458120701908532\n",
      "57 Train Loss 9.668574 Test MSE 5.646622443344822 Test RE 1.1358014931110396\n",
      "58 Train Loss 8.845205 Test MSE 5.141251605856352 Test RE 1.0837833865258668\n",
      "59 Train Loss 8.38946 Test MSE 4.815849444286619 Test RE 1.0489251798341674\n",
      "60 Train Loss 7.914188 Test MSE 4.483574219115565 Test RE 1.0120925823532905\n",
      "61 Train Loss 7.6745434 Test MSE 4.257113029681298 Test RE 0.9862014821103885\n",
      "62 Train Loss 7.516081 Test MSE 4.136711007452453 Test RE 0.9721553068203717\n",
      "63 Train Loss 7.35799 Test MSE 3.9723659076085953 Test RE 0.9526484896492361\n",
      "64 Train Loss 7.1059146 Test MSE 3.8801083359475994 Test RE 0.9415209457756606\n",
      "65 Train Loss 7.007214 Test MSE 3.8406503663164973 Test RE 0.9367214100937011\n",
      "66 Train Loss 6.877511 Test MSE 3.738189768398141 Test RE 0.9241420514872761\n",
      "67 Train Loss 6.7852087 Test MSE 3.7182500155703453 Test RE 0.9216740383695079\n",
      "68 Train Loss 6.7107496 Test MSE 3.7351601161164933 Test RE 0.9237674856190977\n",
      "69 Train Loss 6.634412 Test MSE 3.7467933427908697 Test RE 0.9252049128996007\n",
      "70 Train Loss 6.576435 Test MSE 3.7202449617365314 Test RE 0.9219212572924511\n",
      "71 Train Loss 6.515588 Test MSE 3.7513532282774187 Test RE 0.9257677335918275\n",
      "72 Train Loss 6.4591007 Test MSE 3.7484640885683853 Test RE 0.9254111705948183\n",
      "73 Train Loss 6.376384 Test MSE 3.682593896042067 Test RE 0.9172442010547228\n",
      "74 Train Loss 6.3112397 Test MSE 3.6945653915723127 Test RE 0.9187338949316635\n",
      "75 Train Loss 6.2292976 Test MSE 3.6719584869549893 Test RE 0.9159187330381263\n",
      "76 Train Loss 6.1559267 Test MSE 3.608737230291118 Test RE 0.9079996692800598\n",
      "77 Train Loss 5.898137 Test MSE 3.4694565241302904 Test RE 0.8903049440906524\n",
      "78 Train Loss 4.4351654 Test MSE 2.709906176648374 Test RE 0.786837749758328\n",
      "79 Train Loss 3.428665 Test MSE 2.5562945648202575 Test RE 0.7642113941534724\n",
      "80 Train Loss 3.1690507 Test MSE 2.4791759822226918 Test RE 0.7525957097066259\n",
      "81 Train Loss 2.9492416 Test MSE 2.342257479372014 Test RE 0.7315186072055727\n",
      "82 Train Loss 2.8245683 Test MSE 2.3420869782735116 Test RE 0.7314919818244878\n",
      "83 Train Loss 2.6369202 Test MSE 2.4161614359323598 Test RE 0.742969583394966\n",
      "84 Train Loss 2.3428895 Test MSE 2.3999237511362366 Test RE 0.7404688309265044\n",
      "85 Train Loss 2.099575 Test MSE 2.45248173320553 Test RE 0.748532999013234\n",
      "86 Train Loss 1.998017 Test MSE 2.397630639301193 Test RE 0.7401149897608182\n",
      "87 Train Loss 1.9055848 Test MSE 2.354536684704261 Test RE 0.7334335814236763\n",
      "88 Train Loss 1.8229011 Test MSE 2.316988923587297 Test RE 0.7275620519019677\n",
      "89 Train Loss 1.7859235 Test MSE 2.3149758726092435 Test RE 0.7272459222591049\n",
      "90 Train Loss 1.714605 Test MSE 2.296032904708846 Test RE 0.7242643590038147\n",
      "91 Train Loss 1.6647048 Test MSE 2.1819594901942643 Test RE 0.7060434069560994\n",
      "92 Train Loss 1.5847495 Test MSE 2.1032360252151814 Test RE 0.6931896445926076\n",
      "93 Train Loss 1.522548 Test MSE 2.0611850647042878 Test RE 0.6862250282189993\n",
      "94 Train Loss 1.4094242 Test MSE 1.7311983400755238 Test RE 0.6288998248633992\n",
      "95 Train Loss 1.3158025 Test MSE 1.6477366941156992 Test RE 0.6135528346644489\n",
      "96 Train Loss 1.2383456 Test MSE 1.6228225579435283 Test RE 0.6088966409976879\n",
      "97 Train Loss 1.0165128 Test MSE 1.0234667740254106 Test RE 0.4835539490410329\n",
      "98 Train Loss 0.80676305 Test MSE 0.7061239489236855 Test RE 0.4016507025278061\n",
      "99 Train Loss 0.65211016 Test MSE 0.5738671098711431 Test RE 0.3620876628082799\n",
      "Training time: 71.53\n",
      "KG_stan_tune10\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.6455 Test MSE 8.631549878782279 Test RE 1.4042759321179221\n",
      "1 Train Loss 55.893013 Test MSE 8.576827348853701 Test RE 1.3998174213484949\n",
      "2 Train Loss 50.412575 Test MSE 8.26301580099762 Test RE 1.3739703217200863\n",
      "3 Train Loss 45.217278 Test MSE 8.65577296294953 Test RE 1.406244991147993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 44.79532 Test MSE 8.625129186457755 Test RE 1.4037535403577004\n",
      "5 Train Loss 44.23257 Test MSE 8.64049774738818 Test RE 1.40500361265918\n",
      "6 Train Loss 43.699684 Test MSE 8.589376433088175 Test RE 1.40084111024812\n",
      "7 Train Loss 43.597923 Test MSE 8.47945550681501 Test RE 1.3918487480329798\n",
      "8 Train Loss 43.44258 Test MSE 8.434509987876803 Test RE 1.3881550862599266\n",
      "9 Train Loss 43.19519 Test MSE 8.487459068802684 Test RE 1.3925054600309168\n",
      "10 Train Loss 43.085754 Test MSE 8.45925880324308 Test RE 1.3901901795463858\n",
      "11 Train Loss 43.04419 Test MSE 8.375593594255115 Test RE 1.3832983481058667\n",
      "12 Train Loss 42.662277 Test MSE 8.240247282883207 Test RE 1.3720760467540507\n",
      "13 Train Loss 42.3467 Test MSE 8.15924391551986 Test RE 1.36531549295682\n",
      "14 Train Loss 42.24421 Test MSE 8.07737529420297 Test RE 1.3584485392954744\n",
      "15 Train Loss 42.0886 Test MSE 8.09033241423943 Test RE 1.3595376633622605\n",
      "16 Train Loss 41.89335 Test MSE 8.154392507009273 Test RE 1.364909530825938\n",
      "17 Train Loss 41.702194 Test MSE 8.265997622221482 Test RE 1.3742182072635167\n",
      "18 Train Loss 40.92183 Test MSE 8.123314229086992 Test RE 1.3623060547179064\n",
      "19 Train Loss 39.653675 Test MSE 7.5932111925473045 Test RE 1.3171062175446213\n",
      "20 Train Loss 39.20221 Test MSE 7.759761877495109 Test RE 1.3314726729891557\n",
      "21 Train Loss 38.81763 Test MSE 7.885859251585365 Test RE 1.3422473987911785\n",
      "22 Train Loss 38.536076 Test MSE 7.818184666662056 Test RE 1.3364755636133228\n",
      "23 Train Loss 38.515728 Test MSE 7.788467871613635 Test RE 1.3339331842916993\n",
      "24 Train Loss 38.41227 Test MSE 7.833714673330791 Test RE 1.3378022895976287\n",
      "25 Train Loss 37.706562 Test MSE 7.761021339979099 Test RE 1.3315807221707785\n",
      "26 Train Loss 36.11376 Test MSE 7.1332805190052015 Test RE 1.2765937441053408\n",
      "27 Train Loss 34.408455 Test MSE 7.063436511640196 Test RE 1.2703286216658969\n",
      "28 Train Loss 34.09906 Test MSE 7.2351271375514985 Test RE 1.2856748362790733\n",
      "29 Train Loss 33.688034 Test MSE 7.199514777056903 Test RE 1.2825067927037037\n",
      "30 Train Loss 33.4991 Test MSE 7.2693322774429205 Test RE 1.288710362311522\n",
      "31 Train Loss 33.40006 Test MSE 7.3558467268118735 Test RE 1.2963563397988351\n",
      "32 Train Loss 33.232536 Test MSE 7.276801248412613 Test RE 1.289372243538431\n",
      "33 Train Loss 33.111275 Test MSE 7.198029364362973 Test RE 1.2823744816937102\n",
      "34 Train Loss 33.02021 Test MSE 7.24021055262957 Test RE 1.2861264158534427\n",
      "35 Train Loss 32.869373 Test MSE 7.282659767056383 Test RE 1.2898911728933\n",
      "36 Train Loss 32.713696 Test MSE 7.278506512999738 Test RE 1.289523312116029\n",
      "37 Train Loss 32.543148 Test MSE 7.250330574478094 Test RE 1.2870249451402263\n",
      "38 Train Loss 32.46048 Test MSE 7.291719356615463 Test RE 1.290693232370218\n",
      "39 Train Loss 32.333748 Test MSE 7.256216477806362 Test RE 1.2875472501250727\n",
      "40 Train Loss 32.228897 Test MSE 7.254319257656913 Test RE 1.287378917200709\n",
      "41 Train Loss 32.161316 Test MSE 7.171052562457407 Test RE 1.2799691819435113\n",
      "42 Train Loss 31.965778 Test MSE 7.184750282134716 Test RE 1.281191059375198\n",
      "43 Train Loss 31.903423 Test MSE 7.163918705608474 Test RE 1.279332358485282\n",
      "44 Train Loss 31.720135 Test MSE 7.177512459080721 Test RE 1.2805455692480432\n",
      "45 Train Loss 31.508972 Test MSE 7.298895224693697 Test RE 1.2913281695064223\n",
      "46 Train Loss 31.12157 Test MSE 7.346122540039234 Test RE 1.2954991862596688\n",
      "47 Train Loss 30.832901 Test MSE 7.25278752175518 Test RE 1.2872429962038796\n",
      "48 Train Loss 30.653976 Test MSE 7.286389229107576 Test RE 1.2902214083163395\n",
      "49 Train Loss 30.48789 Test MSE 7.30428758969125 Test RE 1.291805092860731\n",
      "50 Train Loss 30.177067 Test MSE 7.193649266501779 Test RE 1.2819842512435429\n",
      "51 Train Loss 29.980614 Test MSE 7.143659903838944 Test RE 1.2775221697587966\n",
      "52 Train Loss 29.705105 Test MSE 7.10646827868492 Test RE 1.2741922850062746\n",
      "53 Train Loss 29.392906 Test MSE 7.098780533773504 Test RE 1.273502890814154\n",
      "54 Train Loss 29.243996 Test MSE 7.002809224985643 Test RE 1.264865094550008\n",
      "55 Train Loss 29.079472 Test MSE 6.997055135890244 Test RE 1.2643453287024295\n",
      "56 Train Loss 28.878452 Test MSE 6.847001473208607 Test RE 1.2507147480204142\n",
      "57 Train Loss 28.689629 Test MSE 6.8579981445738545 Test RE 1.2517187043679516\n",
      "58 Train Loss 28.409262 Test MSE 6.8813441606374495 Test RE 1.2538474463603722\n",
      "59 Train Loss 28.03503 Test MSE 6.7658892095436425 Test RE 1.2432844482891523\n",
      "60 Train Loss 27.237797 Test MSE 6.463753256506716 Test RE 1.2152075107322067\n",
      "61 Train Loss 26.239714 Test MSE 5.751616842555401 Test RE 1.1463125144242303\n",
      "62 Train Loss 23.291672 Test MSE 5.195330739080169 Test RE 1.0894684561289603\n",
      "63 Train Loss 21.288177 Test MSE 4.953620831252272 Test RE 1.0638231596673253\n",
      "64 Train Loss 19.861668 Test MSE 4.894551794288996 Test RE 1.057461402620561\n",
      "65 Train Loss 17.460867 Test MSE 4.279529732612786 Test RE 0.9887945961677672\n",
      "66 Train Loss 15.793318 Test MSE 3.908714366239205 Test RE 0.9449852456643508\n",
      "67 Train Loss 13.945917 Test MSE 4.0419991270518585 Test RE 0.9609618972821582\n",
      "68 Train Loss 12.726418 Test MSE 3.615199267903167 Test RE 0.9088122670526273\n",
      "69 Train Loss 11.042068 Test MSE 2.477861541442562 Test RE 0.7523961729137723\n",
      "70 Train Loss 8.767601 Test MSE 2.0039304933619224 Test RE 0.676627098803378\n",
      "71 Train Loss 7.316675 Test MSE 1.932680350690713 Test RE 0.6644894282815145\n",
      "72 Train Loss 6.4574165 Test MSE 1.845708675056806 Test RE 0.6493661364339812\n",
      "73 Train Loss 6.002753 Test MSE 1.6490813943217337 Test RE 0.6138031405438015\n",
      "74 Train Loss 5.0936337 Test MSE 1.3059650973061634 Test RE 0.5462278576843259\n",
      "75 Train Loss 4.296183 Test MSE 0.805461508948554 Test RE 0.4289734917599595\n",
      "76 Train Loss 3.606558 Test MSE 0.4703698503538191 Test RE 0.3278142275809835\n",
      "77 Train Loss 3.184662 Test MSE 0.3827146233598325 Test RE 0.2956960946161702\n",
      "78 Train Loss 2.895228 Test MSE 0.3855213311398882 Test RE 0.29677838467938933\n",
      "79 Train Loss 2.6171393 Test MSE 0.30615803000955283 Test RE 0.26447272356140467\n",
      "80 Train Loss 2.1964402 Test MSE 0.24309789072444052 Test RE 0.23566693610052247\n",
      "81 Train Loss 1.9630616 Test MSE 0.1843676571018764 Test RE 0.2052345288444876\n",
      "82 Train Loss 1.738023 Test MSE 0.15310505920971854 Test RE 0.18702636416972676\n",
      "83 Train Loss 1.5658926 Test MSE 0.13250906381971578 Test RE 0.17399263013886618\n",
      "84 Train Loss 1.469046 Test MSE 0.14774876267936293 Test RE 0.18372573208265808\n",
      "85 Train Loss 1.2698053 Test MSE 0.1135467564878809 Test RE 0.1610628674658783\n",
      "86 Train Loss 1.1310673 Test MSE 0.10476181097567569 Test RE 0.1547068554926281\n",
      "87 Train Loss 1.0342622 Test MSE 0.09446753310050938 Test RE 0.14690931965720316\n",
      "88 Train Loss 0.95531464 Test MSE 0.06927383076242385 Test RE 0.1258034822037859\n",
      "89 Train Loss 0.854753 Test MSE 0.06946308340079156 Test RE 0.1259752094046025\n",
      "90 Train Loss 0.75956947 Test MSE 0.07353495676276597 Test RE 0.12961491547560722\n",
      "91 Train Loss 0.70942897 Test MSE 0.059385003523260954 Test RE 0.11647868354889963\n",
      "92 Train Loss 0.6244636 Test MSE 0.03785632378892119 Test RE 0.09299878593664763\n",
      "93 Train Loss 0.55611885 Test MSE 0.04518051814595623 Test RE 0.10159765029756937\n",
      "94 Train Loss 0.49522233 Test MSE 0.04716005028883468 Test RE 0.10379948291455067\n",
      "95 Train Loss 0.4651876 Test MSE 0.044338414752338046 Test RE 0.10064637584001701\n",
      "96 Train Loss 0.42888224 Test MSE 0.04093115491085776 Test RE 0.09670191169253102\n",
      "97 Train Loss 0.3502426 Test MSE 0.03699344477178141 Test RE 0.09193279145917559\n",
      "98 Train Loss 0.3284244 Test MSE 0.032224623450729684 Test RE 0.08580290382482349\n",
      "99 Train Loss 0.31801954 Test MSE 0.02918313036087305 Test RE 0.08165334822648934\n",
      "Training time: 71.95\n",
      "KG_stan_tune11\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 169.77489 Test MSE 4.673031937136987 Test RE 1.0332548080358055\n",
      "1 Train Loss 134.58615 Test MSE 4.635592769363178 Test RE 1.029107394255778\n",
      "2 Train Loss 115.12036 Test MSE 4.5268311801266785 Test RE 1.0169631340017593\n",
      "3 Train Loss 106.314156 Test MSE 4.497807395930433 Test RE 1.0136977613497287\n",
      "4 Train Loss 95.11896 Test MSE 4.640028059443003 Test RE 1.029599596523633\n",
      "5 Train Loss 86.15051 Test MSE 4.790552409131798 Test RE 1.046166618222908\n",
      "6 Train Loss 76.77091 Test MSE 4.957834781796195 Test RE 1.0642755504902557\n",
      "7 Train Loss 71.49549 Test MSE 5.026300121397403 Test RE 1.071598923611565\n",
      "8 Train Loss 68.47634 Test MSE 5.14327340268303 Test RE 1.0839964644493651\n",
      "9 Train Loss 64.946175 Test MSE 5.24221091260589 Test RE 1.0943728377624828\n",
      "10 Train Loss 62.435265 Test MSE 5.27748879562861 Test RE 1.0980489987120712\n",
      "11 Train Loss 60.11261 Test MSE 5.266616230108209 Test RE 1.0969173274378563\n",
      "12 Train Loss 58.256443 Test MSE 5.264977608447767 Test RE 1.0967466702031052\n",
      "13 Train Loss 56.291462 Test MSE 5.345252270506459 Test RE 1.105076042214232\n",
      "14 Train Loss 53.796814 Test MSE 5.390790846519498 Test RE 1.1097733753530665\n",
      "15 Train Loss 51.542397 Test MSE 5.344074889650223 Test RE 1.1049543298079862\n",
      "16 Train Loss 48.14343 Test MSE 5.543265080849464 Test RE 1.1253584696936345\n",
      "17 Train Loss 45.87945 Test MSE 5.686488927686904 Test RE 1.1398039539801348\n",
      "18 Train Loss 44.538757 Test MSE 5.609433379602663 Test RE 1.1320550789982458\n",
      "19 Train Loss 42.699726 Test MSE 5.46946597305646 Test RE 1.1178422564148083\n",
      "20 Train Loss 40.76515 Test MSE 5.646681200635602 Test RE 1.1358074025237603\n",
      "21 Train Loss 39.657265 Test MSE 5.726536218728492 Test RE 1.143810466348575\n",
      "22 Train Loss 38.277348 Test MSE 5.804999251099024 Test RE 1.1516198560356843\n",
      "23 Train Loss 37.290188 Test MSE 5.703663858966817 Test RE 1.1415239340677508\n",
      "24 Train Loss 36.20321 Test MSE 5.707925762555743 Test RE 1.1419503403734275\n",
      "25 Train Loss 35.46046 Test MSE 5.81825188879022 Test RE 1.1529336632652532\n",
      "26 Train Loss 34.619003 Test MSE 5.813970521038105 Test RE 1.1525093913791502\n",
      "27 Train Loss 33.386963 Test MSE 5.760375170304799 Test RE 1.1471849614112526\n",
      "28 Train Loss 32.534958 Test MSE 5.823111593197162 Test RE 1.1534150576289166\n",
      "29 Train Loss 31.923355 Test MSE 5.866330811931477 Test RE 1.1576874764419767\n",
      "30 Train Loss 31.233131 Test MSE 5.903420779992469 Test RE 1.1613414585162902\n",
      "31 Train Loss 30.862625 Test MSE 5.934494948743223 Test RE 1.164393956138975\n",
      "32 Train Loss 30.36565 Test MSE 5.974106528603719 Test RE 1.1682735427000788\n",
      "33 Train Loss 29.667547 Test MSE 5.9751814154557525 Test RE 1.1683786383645252\n",
      "34 Train Loss 28.98404 Test MSE 6.033600870980242 Test RE 1.1740763749393883\n",
      "35 Train Loss 28.426186 Test MSE 6.060028732784951 Test RE 1.176644859841662\n",
      "36 Train Loss 28.07814 Test MSE 6.026507478471461 Test RE 1.173386021538928\n",
      "37 Train Loss 27.415243 Test MSE 6.059591738630786 Test RE 1.1766024346141664\n",
      "38 Train Loss 26.84439 Test MSE 6.0684180472323295 Test RE 1.177459033351358\n",
      "39 Train Loss 26.279419 Test MSE 5.969631135553129 Test RE 1.1678358652966168\n",
      "40 Train Loss 25.586823 Test MSE 5.937116318053199 Test RE 1.1646510942457509\n",
      "41 Train Loss 25.007069 Test MSE 6.042260915670975 Test RE 1.174918650417228\n",
      "42 Train Loss 24.617702 Test MSE 6.098266636987444 Test RE 1.1803512517182115\n",
      "43 Train Loss 24.301937 Test MSE 6.166891461329584 Test RE 1.1869740180517094\n",
      "44 Train Loss 23.944012 Test MSE 6.2189946463529076 Test RE 1.1919777582705622\n",
      "45 Train Loss 23.489548 Test MSE 6.202503380368951 Test RE 1.190396291149993\n",
      "46 Train Loss 22.975927 Test MSE 6.075566686813538 Test RE 1.1781523567805703\n",
      "47 Train Loss 22.406488 Test MSE 6.035161152990891 Test RE 1.174228172503585\n",
      "48 Train Loss 22.023806 Test MSE 6.007956748944787 Test RE 1.1715786776097639\n",
      "49 Train Loss 21.561214 Test MSE 6.016017566262684 Test RE 1.1723643620379625\n",
      "50 Train Loss 21.258081 Test MSE 5.985735648467037 Test RE 1.1694100631021678\n",
      "51 Train Loss 20.896555 Test MSE 5.918601513071407 Test RE 1.162833703092857\n",
      "52 Train Loss 20.46695 Test MSE 5.836979437329062 Test RE 1.1547876801508299\n",
      "53 Train Loss 20.173883 Test MSE 5.909318858312866 Test RE 1.1619214589192233\n",
      "54 Train Loss 19.860003 Test MSE 5.9250055035293965 Test RE 1.1634626322950126\n",
      "55 Train Loss 19.582775 Test MSE 5.823895523313386 Test RE 1.153492693644999\n",
      "56 Train Loss 19.205452 Test MSE 5.874301392792265 Test RE 1.1584736841871235\n",
      "57 Train Loss 18.850464 Test MSE 5.941556762881281 Test RE 1.1650865415270457\n",
      "58 Train Loss 18.62978 Test MSE 5.867530517961235 Test RE 1.1578058480177256\n",
      "59 Train Loss 18.41315 Test MSE 5.865936934095402 Test RE 1.1576486109989135\n",
      "60 Train Loss 18.058558 Test MSE 5.831982722697418 Test RE 1.1542932994558237\n",
      "61 Train Loss 17.708076 Test MSE 5.789672778489716 Test RE 1.1500985866118683\n",
      "62 Train Loss 17.396622 Test MSE 5.795507765721343 Test RE 1.1506779907373288\n",
      "63 Train Loss 17.092216 Test MSE 5.72090101135924 Test RE 1.1432475435444138\n",
      "64 Train Loss 16.765987 Test MSE 5.731256358463487 Test RE 1.1442817663590437\n",
      "65 Train Loss 16.39102 Test MSE 5.7523113504513885 Test RE 1.146381720969347\n",
      "66 Train Loss 16.046654 Test MSE 5.7504277971732645 Test RE 1.1461940183481425\n",
      "67 Train Loss 15.759833 Test MSE 5.690408850552253 Test RE 1.140196742387931\n",
      "68 Train Loss 15.401844 Test MSE 5.654487163975058 Test RE 1.1365922005879032\n",
      "69 Train Loss 15.148636 Test MSE 5.594947321503027 Test RE 1.1305923985792754\n",
      "70 Train Loss 14.82562 Test MSE 5.554036056509515 Test RE 1.126451266639175\n",
      "71 Train Loss 14.463405 Test MSE 5.523804814270828 Test RE 1.1233813831096031\n",
      "72 Train Loss 14.1569195 Test MSE 5.446202584280162 Test RE 1.115462452812871\n",
      "73 Train Loss 13.822588 Test MSE 5.428943758893143 Test RE 1.1136936196209102\n",
      "74 Train Loss 13.446775 Test MSE 5.4546942036345785 Test RE 1.116331718425751\n",
      "75 Train Loss 12.975761 Test MSE 5.374248852345957 Test RE 1.1080693610481076\n",
      "76 Train Loss 12.590973 Test MSE 5.340531068417545 Test RE 1.1045879043670277\n",
      "77 Train Loss 12.1815815 Test MSE 5.317197300880562 Test RE 1.1021721884219426\n",
      "78 Train Loss 11.844697 Test MSE 5.246167851969937 Test RE 1.094785788536154\n",
      "79 Train Loss 11.431647 Test MSE 5.170915401002049 Test RE 1.086905475359665\n",
      "80 Train Loss 10.968399 Test MSE 5.135915796470232 Test RE 1.0832208423037812\n",
      "81 Train Loss 10.534818 Test MSE 5.154459078199446 Test RE 1.0851745709181138\n",
      "82 Train Loss 10.083817 Test MSE 5.170042598153922 Test RE 1.0868137416766157\n",
      "83 Train Loss 9.670389 Test MSE 5.15783189516358 Test RE 1.0855295544961092\n",
      "84 Train Loss 9.257511 Test MSE 5.203590218105447 Test RE 1.090334124625172\n",
      "85 Train Loss 8.803238 Test MSE 5.133130911340381 Test RE 1.0829271211076996\n",
      "86 Train Loss 8.343971 Test MSE 5.091626829663162 Test RE 1.078540215876943\n",
      "87 Train Loss 7.933832 Test MSE 5.109773980088151 Test RE 1.0804605277531514\n",
      "88 Train Loss 7.5337734 Test MSE 5.0463236315269855 Test RE 1.0737312917408448\n",
      "89 Train Loss 7.1512547 Test MSE 5.031938687061734 Test RE 1.0721998216005608\n",
      "90 Train Loss 6.7676325 Test MSE 5.01807838597868 Test RE 1.0707221346763118\n",
      "91 Train Loss 6.393482 Test MSE 4.965991890516566 Test RE 1.065150715135318\n",
      "92 Train Loss 6.0840397 Test MSE 4.958699777991795 Test RE 1.0643683888150595\n",
      "93 Train Loss 5.795498 Test MSE 4.974041597054258 Test RE 1.0660136523968653\n",
      "94 Train Loss 5.521631 Test MSE 4.9667352796437765 Test RE 1.065230436553216\n",
      "95 Train Loss 5.2489147 Test MSE 4.954780946706954 Test RE 1.0639477236459334\n",
      "96 Train Loss 5.0355806 Test MSE 5.010977217996103 Test RE 1.0699642679215327\n",
      "97 Train Loss 4.8578386 Test MSE 5.016885391508568 Test RE 1.0705948507424565\n",
      "98 Train Loss 4.68012 Test MSE 5.057092062421458 Test RE 1.0748763074327015\n",
      "99 Train Loss 4.515556 Test MSE 5.07556130548051 Test RE 1.0768373216692966\n",
      "Training time: 72.01\n",
      "KG_stan_tune11\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 288.90375 Test MSE 5.812748034134008 Test RE 1.152388217587221\n",
      "1 Train Loss 213.48254 Test MSE 5.748166786168632 Test RE 1.1459686601509718\n",
      "2 Train Loss 184.91223 Test MSE 5.693453293202834 Test RE 1.1405017116366367\n",
      "3 Train Loss 150.91199 Test MSE 5.539886947389429 Test RE 1.1250155138355655\n",
      "4 Train Loss 128.48558 Test MSE 5.402439277709684 Test RE 1.1109717285693292\n",
      "5 Train Loss 107.67978 Test MSE 5.234507261385485 Test RE 1.0935684284806702\n",
      "6 Train Loss 98.946434 Test MSE 5.197996161967851 Test RE 1.0897478918323629\n",
      "7 Train Loss 93.25924 Test MSE 5.116557669397257 Test RE 1.0811774946411064\n",
      "8 Train Loss 89.00393 Test MSE 5.03339925971901 Test RE 1.0723554188979065\n",
      "9 Train Loss 83.47949 Test MSE 4.962883443326796 Test RE 1.0648172990621145\n",
      "10 Train Loss 80.12782 Test MSE 4.871455272228634 Test RE 1.0549634658759752\n",
      "11 Train Loss 78.493195 Test MSE 4.847992059570368 Test RE 1.0524197999622011\n",
      "12 Train Loss 75.68085 Test MSE 4.865217957844677 Test RE 1.0542878724391467\n",
      "13 Train Loss 73.46832 Test MSE 4.854464046769246 Test RE 1.0531220469626765\n",
      "14 Train Loss 71.944016 Test MSE 4.848943658450268 Test RE 1.05252308317212\n",
      "15 Train Loss 70.88569 Test MSE 4.882916334124558 Test RE 1.056203741896225\n",
      "16 Train Loss 69.95455 Test MSE 4.922903224370909 Test RE 1.0605196247409612\n",
      "17 Train Loss 68.8237 Test MSE 4.954508178723698 Test RE 1.063918437298844\n",
      "18 Train Loss 67.88252 Test MSE 5.028315332815691 Test RE 1.0718137219646455\n",
      "19 Train Loss 67.353386 Test MSE 5.028241138568889 Test RE 1.0718058144747709\n",
      "20 Train Loss 66.3683 Test MSE 5.000515325667907 Test RE 1.0688467513971218\n",
      "21 Train Loss 65.44802 Test MSE 5.047062420668022 Test RE 1.073809886778057\n",
      "22 Train Loss 64.643585 Test MSE 5.111966986016286 Test RE 1.0806923581801167\n",
      "23 Train Loss 63.677643 Test MSE 5.173444880452622 Test RE 1.087171286024823\n",
      "24 Train Loss 62.87582 Test MSE 5.280290496570587 Test RE 1.0983404248848996\n",
      "25 Train Loss 61.553627 Test MSE 5.430298001513968 Test RE 1.1138325156373012\n",
      "26 Train Loss 60.60724 Test MSE 5.589304842436653 Test RE 1.1300221561112656\n",
      "27 Train Loss 59.36041 Test MSE 5.762453542909667 Test RE 1.1473918978259772\n",
      "28 Train Loss 58.456482 Test MSE 5.736687330094589 Test RE 1.1448238019862218\n",
      "29 Train Loss 57.425873 Test MSE 5.807526761604393 Test RE 1.1518705377664258\n",
      "30 Train Loss 56.525307 Test MSE 5.820267500232085 Test RE 1.1531333508259642\n",
      "31 Train Loss 55.654438 Test MSE 5.8589174675287055 Test RE 1.1569557542325875\n",
      "32 Train Loss 54.624622 Test MSE 5.998618370805742 Test RE 1.170667810585182\n",
      "33 Train Loss 54.07419 Test MSE 6.033903094937997 Test RE 1.17410577940059\n",
      "34 Train Loss 53.551353 Test MSE 6.092758902731243 Test RE 1.1798181059938067\n",
      "35 Train Loss 52.954247 Test MSE 6.133623859042519 Test RE 1.1837680934273427\n",
      "36 Train Loss 52.248657 Test MSE 6.214038174007294 Test RE 1.1915026668164772\n",
      "37 Train Loss 51.4505 Test MSE 6.2901923556635335 Test RE 1.1987814761912505\n",
      "38 Train Loss 50.868385 Test MSE 6.33961599341025 Test RE 1.2034818264460918\n",
      "39 Train Loss 50.06424 Test MSE 6.390905467277234 Test RE 1.208340291586367\n",
      "40 Train Loss 49.29568 Test MSE 6.389506130975369 Test RE 1.2082079967956527\n",
      "41 Train Loss 48.52013 Test MSE 6.539972906918241 Test RE 1.222351289100293\n",
      "42 Train Loss 47.928467 Test MSE 6.684318323951624 Test RE 1.2357670814514636\n",
      "43 Train Loss 46.843174 Test MSE 6.7885243700727536 Test RE 1.2453624046669391\n",
      "44 Train Loss 45.92596 Test MSE 6.776048680070532 Test RE 1.2442175387701844\n",
      "45 Train Loss 45.372612 Test MSE 6.79427168446927 Test RE 1.2458894687685027\n",
      "46 Train Loss 44.812454 Test MSE 6.874383054757661 Test RE 1.253213095492442\n",
      "47 Train Loss 44.20566 Test MSE 7.035668823355192 Test RE 1.2678292132904057\n",
      "48 Train Loss 43.83596 Test MSE 7.12771145455247 Test RE 1.2760953183827428\n",
      "49 Train Loss 43.314583 Test MSE 7.168068214069032 Test RE 1.2797028143886664\n",
      "50 Train Loss 43.13058 Test MSE 7.226305233221106 Test RE 1.284890775425701\n",
      "51 Train Loss 42.92833 Test MSE 7.322979313632268 Test RE 1.2934569060000054\n",
      "52 Train Loss 42.57793 Test MSE 7.314985226197088 Test RE 1.2927507158961753\n",
      "53 Train Loss 42.227528 Test MSE 7.394201740483583 Test RE 1.2997316900704363\n",
      "54 Train Loss 41.880856 Test MSE 7.496596187930243 Test RE 1.3087000504433481\n",
      "55 Train Loss 41.575497 Test MSE 7.619365997615795 Test RE 1.3193726527783318\n",
      "56 Train Loss 41.33491 Test MSE 7.671524545924506 Test RE 1.3238808488873308\n",
      "57 Train Loss 40.967518 Test MSE 7.611500148489868 Test RE 1.3186914500351066\n",
      "58 Train Loss 40.589825 Test MSE 7.600279666246808 Test RE 1.3177191179888923\n",
      "59 Train Loss 40.218987 Test MSE 7.633674287097933 Test RE 1.3206108864783845\n",
      "60 Train Loss 39.977604 Test MSE 7.70240663334014 Test RE 1.3265428452831909\n",
      "61 Train Loss 39.65843 Test MSE 7.838263973133683 Test RE 1.3381906864570678\n",
      "62 Train Loss 39.35096 Test MSE 7.910815253002029 Test RE 1.3443695941715403\n",
      "63 Train Loss 39.102253 Test MSE 7.88653408527105 Test RE 1.3423048290820823\n",
      "64 Train Loss 38.757835 Test MSE 7.898016163373616 Test RE 1.34328161070862\n",
      "65 Train Loss 38.51671 Test MSE 7.982414990269246 Test RE 1.350439745322028\n",
      "66 Train Loss 38.08873 Test MSE 8.038773547437286 Test RE 1.3551986415513444\n",
      "67 Train Loss 37.553066 Test MSE 8.168340713623353 Test RE 1.3660763808318452\n",
      "68 Train Loss 37.323833 Test MSE 8.147815195176502 Test RE 1.3643589535374048\n",
      "69 Train Loss 37.062286 Test MSE 8.127117580730001 Test RE 1.3626249345796375\n",
      "70 Train Loss 36.622147 Test MSE 8.186788804808295 Test RE 1.3676181436727999\n",
      "71 Train Loss 36.41555 Test MSE 8.194366360455543 Test RE 1.3682509195964256\n",
      "72 Train Loss 36.150482 Test MSE 8.194676271547577 Test RE 1.3682767929897321\n",
      "73 Train Loss 35.850105 Test MSE 8.176755558192738 Test RE 1.366779850593028\n",
      "74 Train Loss 35.639954 Test MSE 8.20250041748015 Test RE 1.3689298415535636\n",
      "75 Train Loss 35.426506 Test MSE 8.282807957602566 Test RE 1.3756148527096712\n",
      "76 Train Loss 35.27482 Test MSE 8.287558301269202 Test RE 1.3760092664562293\n",
      "77 Train Loss 35.084354 Test MSE 8.312086963830382 Test RE 1.3780440473267195\n",
      "78 Train Loss 34.843914 Test MSE 8.355644420628156 Test RE 1.3816499807275386\n",
      "79 Train Loss 34.578606 Test MSE 8.342755240625007 Test RE 1.3805839224221386\n",
      "80 Train Loss 34.40973 Test MSE 8.353251665378721 Test RE 1.3814521391974333\n",
      "81 Train Loss 34.15803 Test MSE 8.445235452168726 Test RE 1.389037406494706\n",
      "82 Train Loss 33.951004 Test MSE 8.45642553411693 Test RE 1.3899573510641692\n",
      "83 Train Loss 33.812256 Test MSE 8.444189116842828 Test RE 1.388951355375338\n",
      "84 Train Loss 33.636127 Test MSE 8.535260927737179 Test RE 1.396421289754871\n",
      "85 Train Loss 33.50137 Test MSE 8.563683547779913 Test RE 1.3987444152490212\n",
      "86 Train Loss 33.336655 Test MSE 8.546334117648989 Test RE 1.397326817210651\n",
      "87 Train Loss 33.22974 Test MSE 8.52720248875512 Test RE 1.3957619289462901\n",
      "88 Train Loss 33.071907 Test MSE 8.485241319223178 Test RE 1.3923235192323722\n",
      "89 Train Loss 32.962997 Test MSE 8.471518774781792 Test RE 1.3911972134699446\n",
      "90 Train Loss 32.863605 Test MSE 8.46858282379338 Test RE 1.3909561208812817\n",
      "91 Train Loss 32.71927 Test MSE 8.491947133551829 Test RE 1.392873581317311\n",
      "92 Train Loss 32.565964 Test MSE 8.542828806720303 Test RE 1.3970402284090186\n",
      "93 Train Loss 32.443996 Test MSE 8.565850393539225 Test RE 1.3989213643205913\n",
      "94 Train Loss 32.263054 Test MSE 8.540625273645425 Test RE 1.39686004085304\n",
      "95 Train Loss 32.160038 Test MSE 8.540418606149007 Test RE 1.3968431400229087\n",
      "96 Train Loss 32.000248 Test MSE 8.598988379230699 Test RE 1.401624697075789\n",
      "97 Train Loss 31.78775 Test MSE 8.633562243183762 Test RE 1.4044396194189104\n",
      "98 Train Loss 31.679241 Test MSE 8.623632417032121 Test RE 1.403631734266645\n",
      "99 Train Loss 31.522903 Test MSE 8.602267775914271 Test RE 1.4018919404434838\n",
      "Training time: 71.78\n",
      "KG_stan_tune11\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 445.00574 Test MSE 6.938038113393909 Test RE 1.2590019446320166\n",
      "1 Train Loss 333.7349 Test MSE 6.991439311445027 Test RE 1.2638378461602269\n",
      "2 Train Loss 256.98694 Test MSE 6.862014747459629 Test RE 1.2520852049792237\n",
      "3 Train Loss 226.50012 Test MSE 6.682330404945526 Test RE 1.2355833089689714\n",
      "4 Train Loss 193.54672 Test MSE 6.45120399759367 Test RE 1.2140272860121049\n",
      "5 Train Loss 171.31819 Test MSE 6.393130772916731 Test RE 1.208550644598907\n",
      "6 Train Loss 135.82631 Test MSE 6.274100174990913 Test RE 1.1972470746300399\n",
      "7 Train Loss 116.97033 Test MSE 6.288645013256349 Test RE 1.1986340212805893\n",
      "8 Train Loss 107.02326 Test MSE 6.348048800314237 Test RE 1.2042819819451154\n",
      "9 Train Loss 100.06582 Test MSE 6.307767180811179 Test RE 1.2004550084048697\n",
      "10 Train Loss 92.57402 Test MSE 6.174229946323656 Test RE 1.1876800464661221\n",
      "11 Train Loss 87.69766 Test MSE 6.085830251993843 Test RE 1.1791470739494367\n",
      "12 Train Loss 83.925995 Test MSE 6.02536759614563 Test RE 1.173275046380894\n",
      "13 Train Loss 78.74697 Test MSE 5.926963326482709 Test RE 1.1636548401930886\n",
      "14 Train Loss 76.30194 Test MSE 5.941709868190564 Test RE 1.1651015527264046\n",
      "15 Train Loss 71.79468 Test MSE 5.985533893426592 Test RE 1.169390354884451\n",
      "16 Train Loss 67.93562 Test MSE 6.072900759379084 Test RE 1.1778938448197354\n",
      "17 Train Loss 64.414795 Test MSE 6.0928848750949 Test RE 1.1798303027432304\n",
      "18 Train Loss 61.25907 Test MSE 5.950631318708598 Test RE 1.165975921992453\n",
      "19 Train Loss 57.88646 Test MSE 5.81750240930214 Test RE 1.1528594031629609\n",
      "20 Train Loss 55.773197 Test MSE 5.669179643179669 Test RE 1.1380678891038423\n",
      "21 Train Loss 53.0545 Test MSE 5.550407240695718 Test RE 1.1260832142863935\n",
      "22 Train Loss 51.390556 Test MSE 5.501717769604674 Test RE 1.121133201980121\n",
      "23 Train Loss 48.90982 Test MSE 5.507569777699235 Test RE 1.1217293009734937\n",
      "24 Train Loss 47.7285 Test MSE 5.510531982766015 Test RE 1.122030917266014\n",
      "25 Train Loss 46.755604 Test MSE 5.475915903226368 Test RE 1.1185011763315555\n",
      "26 Train Loss 45.2972 Test MSE 5.388349813246884 Test RE 1.1095220856490675\n",
      "27 Train Loss 44.113495 Test MSE 5.348690854079038 Test RE 1.1054314309979743\n",
      "28 Train Loss 42.926094 Test MSE 5.2320818117338455 Test RE 1.093315042406812\n",
      "29 Train Loss 41.94696 Test MSE 5.160327666776719 Test RE 1.085792155744624\n",
      "30 Train Loss 40.57089 Test MSE 5.171377936943902 Test RE 1.0869540858635083\n",
      "31 Train Loss 39.6864 Test MSE 5.150236772965288 Test RE 1.0847300163182885\n",
      "32 Train Loss 38.71144 Test MSE 5.132945231590823 Test RE 1.0829075346741437\n",
      "33 Train Loss 37.666153 Test MSE 5.0368429975569855 Test RE 1.0727221968252842\n",
      "34 Train Loss 36.83992 Test MSE 4.935916402514227 Test RE 1.0619203858377122\n",
      "35 Train Loss 36.093475 Test MSE 4.907219191889209 Test RE 1.058828905595433\n",
      "36 Train Loss 35.268356 Test MSE 4.886750339203248 Test RE 1.0566183195423557\n",
      "37 Train Loss 34.43168 Test MSE 4.788414690655917 Test RE 1.0459331734064132\n",
      "38 Train Loss 32.685844 Test MSE 4.642412678595909 Test RE 1.0298641302204878\n",
      "39 Train Loss 31.394985 Test MSE 4.635838953098929 Test RE 1.0291347204416434\n",
      "40 Train Loss 30.089231 Test MSE 4.567671308580773 Test RE 1.021540248572975\n",
      "41 Train Loss 28.829803 Test MSE 4.43094004915397 Test RE 1.0061343986228686\n",
      "42 Train Loss 28.192863 Test MSE 4.383818902128053 Test RE 1.0007701950997785\n",
      "43 Train Loss 27.609926 Test MSE 4.418046216597018 Test RE 1.0046694295942769\n",
      "44 Train Loss 27.011202 Test MSE 4.3609195241542515 Test RE 0.9981529541386611\n",
      "45 Train Loss 25.575384 Test MSE 4.1968893844784185 Test RE 0.9792009399981179\n",
      "46 Train Loss 24.658848 Test MSE 4.225480466533138 Test RE 0.9825306554816718\n",
      "47 Train Loss 23.817677 Test MSE 4.238436299779503 Test RE 0.984035781444791\n",
      "48 Train Loss 23.090858 Test MSE 4.267319712034805 Test RE 0.9873830127686201\n",
      "49 Train Loss 22.641817 Test MSE 4.275985850866656 Test RE 0.988385100605027\n",
      "50 Train Loss 21.957157 Test MSE 4.260616990605034 Test RE 0.9866072618794668\n",
      "51 Train Loss 21.17147 Test MSE 4.231914790932921 Test RE 0.9832784421753046\n",
      "52 Train Loss 20.29773 Test MSE 4.215275274500376 Test RE 0.9813434561137482\n",
      "53 Train Loss 19.440731 Test MSE 4.32802314065959 Test RE 0.9943810683784072\n",
      "54 Train Loss 18.456161 Test MSE 4.295204160182794 Test RE 0.9906037462975221\n",
      "55 Train Loss 17.720682 Test MSE 4.222500022558013 Test RE 0.9821840802033213\n",
      "56 Train Loss 17.076794 Test MSE 4.124030639033978 Test RE 0.9706641767022754\n",
      "57 Train Loss 16.52848 Test MSE 4.0094037845219335 Test RE 0.9570793771064843\n",
      "58 Train Loss 15.865008 Test MSE 3.9124569868348673 Test RE 0.9454375523191901\n",
      "59 Train Loss 15.12879 Test MSE 3.850293904033918 Test RE 0.9378966856373859\n",
      "60 Train Loss 14.387911 Test MSE 3.782785657077794 Test RE 0.9296381272279634\n",
      "61 Train Loss 13.31955 Test MSE 3.7626291741366242 Test RE 0.9271580417778343\n",
      "62 Train Loss 12.639847 Test MSE 3.6957534667290206 Test RE 0.9188816033984504\n",
      "63 Train Loss 11.847935 Test MSE 3.6177828699204237 Test RE 0.9091369503800405\n",
      "64 Train Loss 10.899959 Test MSE 3.325637505378133 Test RE 0.8716567847706885\n",
      "65 Train Loss 10.033761 Test MSE 3.0856581249935413 Test RE 0.8396184313697882\n",
      "66 Train Loss 9.603484 Test MSE 3.103030620958481 Test RE 0.8419786725818851\n",
      "67 Train Loss 8.727405 Test MSE 2.896053016512857 Test RE 0.8134133844090566\n",
      "68 Train Loss 8.036671 Test MSE 2.7165968259783497 Test RE 0.7878084863250674\n",
      "69 Train Loss 7.4171877 Test MSE 2.699034672783464 Test RE 0.7852578599763972\n",
      "70 Train Loss 6.783144 Test MSE 2.6084625288713816 Test RE 0.7719698901221952\n",
      "71 Train Loss 6.288149 Test MSE 2.6214870809414346 Test RE 0.7738947868897764\n",
      "72 Train Loss 5.693594 Test MSE 2.645063130406066 Test RE 0.7773669655996405\n",
      "73 Train Loss 5.216386 Test MSE 2.6456105244118686 Test RE 0.7774473992193685\n",
      "74 Train Loss 4.7140675 Test MSE 2.5090638255662987 Test RE 0.7571185986874888\n",
      "75 Train Loss 4.2927413 Test MSE 2.4344063077313627 Test RE 0.7457694565679821\n",
      "76 Train Loss 3.9095862 Test MSE 2.3834745489319262 Test RE 0.7379268618015766\n",
      "77 Train Loss 3.6956825 Test MSE 2.334968950639506 Test RE 0.7303795674906721\n",
      "78 Train Loss 3.5051336 Test MSE 2.3912367093011557 Test RE 0.7391274726420116\n",
      "79 Train Loss 3.2826695 Test MSE 2.37471078096949 Test RE 0.7365689753972093\n",
      "80 Train Loss 3.1176667 Test MSE 2.3368585692778305 Test RE 0.7306750445954832\n",
      "81 Train Loss 2.9107819 Test MSE 2.3121204135714684 Test RE 0.7267972649480466\n",
      "82 Train Loss 2.7457952 Test MSE 2.2441053492605825 Test RE 0.7160274645036855\n",
      "83 Train Loss 2.5566807 Test MSE 2.190031478157791 Test RE 0.707348177444225\n",
      "84 Train Loss 2.427055 Test MSE 2.141348530818258 Test RE 0.6994420531073133\n",
      "85 Train Loss 2.3084786 Test MSE 2.1000304278291293 Test RE 0.6926611888659973\n",
      "86 Train Loss 2.168653 Test MSE 2.083353288808744 Test RE 0.6899053639432725\n",
      "87 Train Loss 2.0864809 Test MSE 2.057315998450247 Test RE 0.6855806665677027\n",
      "88 Train Loss 1.9486084 Test MSE 2.027438222276747 Test RE 0.6805842197251649\n",
      "89 Train Loss 1.8629311 Test MSE 1.9977520519208112 Test RE 0.6755832182425977\n",
      "90 Train Loss 1.7766457 Test MSE 1.9833198584437581 Test RE 0.6731385152334981\n",
      "91 Train Loss 1.6939647 Test MSE 1.9675598392384845 Test RE 0.6704587067000021\n",
      "92 Train Loss 1.6191906 Test MSE 1.9516151459449171 Test RE 0.6677365519940195\n",
      "93 Train Loss 1.5655373 Test MSE 1.9360311237896508 Test RE 0.6650652061299592\n",
      "94 Train Loss 1.4980123 Test MSE 1.9172319317914126 Test RE 0.6618283812121382\n",
      "95 Train Loss 1.4466676 Test MSE 1.9090640053417085 Test RE 0.6604170925586673\n",
      "96 Train Loss 1.3940775 Test MSE 1.8970753934498146 Test RE 0.6583401707007682\n",
      "97 Train Loss 1.3655444 Test MSE 1.8996389339136899 Test RE 0.6587848319702277\n",
      "98 Train Loss 1.3319796 Test MSE 1.8978566617023438 Test RE 0.6584757181156241\n",
      "99 Train Loss 1.2965503 Test MSE 1.8787366933414877 Test RE 0.6551504129202427\n",
      "Training time: 71.48\n",
      "KG_stan_tune11\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 132.29793 Test MSE 6.104458266587268 Test RE 1.1809503107687487\n",
      "1 Train Loss 103.98758 Test MSE 6.23104130178055 Test RE 1.1931316745459561\n",
      "2 Train Loss 79.647575 Test MSE 6.615136402517225 Test RE 1.229355425154636\n",
      "3 Train Loss 64.31011 Test MSE 7.045828349919885 Test RE 1.2687442576424992\n",
      "4 Train Loss 57.921352 Test MSE 7.54419840266838 Test RE 1.3128484958125883\n",
      "5 Train Loss 52.552513 Test MSE 7.897746954503571 Test RE 1.343258717212413\n",
      "6 Train Loss 47.597523 Test MSE 8.373749811964148 Test RE 1.383146081800837\n",
      "7 Train Loss 44.56508 Test MSE 8.621087988064266 Test RE 1.403424646084301\n",
      "8 Train Loss 41.51561 Test MSE 8.924648107461714 Test RE 1.4279191265465625\n",
      "9 Train Loss 38.760193 Test MSE 9.166031367663903 Test RE 1.4471006208533992\n",
      "10 Train Loss 37.195786 Test MSE 9.192292838716057 Test RE 1.449172172215336\n",
      "11 Train Loss 35.2505 Test MSE 9.208668752553596 Test RE 1.450462435652527\n",
      "12 Train Loss 33.9526 Test MSE 9.31403343603761 Test RE 1.4587368585578169\n",
      "13 Train Loss 32.866493 Test MSE 9.272090125145228 Test RE 1.4554486327134846\n",
      "14 Train Loss 31.61578 Test MSE 9.461178145411301 Test RE 1.4702143936297636\n",
      "15 Train Loss 30.598515 Test MSE 9.457889750383773 Test RE 1.469958872288173\n",
      "16 Train Loss 29.851921 Test MSE 9.357950365154744 Test RE 1.462171885093475\n",
      "17 Train Loss 29.05672 Test MSE 9.298297804878118 Test RE 1.457504103247555\n",
      "18 Train Loss 28.158936 Test MSE 9.167919208208806 Test RE 1.4472496359758595\n",
      "19 Train Loss 27.166462 Test MSE 9.215928973154405 Test RE 1.4510341036498204\n",
      "20 Train Loss 26.442085 Test MSE 9.226052978127784 Test RE 1.451830889535411\n",
      "21 Train Loss 25.564798 Test MSE 9.192432655894601 Test RE 1.4491831933173303\n",
      "22 Train Loss 24.752312 Test MSE 9.150653325702917 Test RE 1.4458861958293319\n",
      "23 Train Loss 24.022427 Test MSE 9.169742199575888 Test RE 1.4473935177221648\n",
      "24 Train Loss 23.307566 Test MSE 9.038814372140022 Test RE 1.4370232475549807\n",
      "25 Train Loss 22.373161 Test MSE 8.966734223495255 Test RE 1.4312819979705134\n",
      "26 Train Loss 21.60979 Test MSE 8.981581799752446 Test RE 1.432466502730315\n",
      "27 Train Loss 21.006336 Test MSE 8.973426184913047 Test RE 1.4318159882328443\n",
      "28 Train Loss 20.111248 Test MSE 8.841440281432275 Test RE 1.4212470269677138\n",
      "29 Train Loss 19.20722 Test MSE 8.684797478398227 Test RE 1.4086007265177287\n",
      "30 Train Loss 18.563593 Test MSE 8.706956327722223 Test RE 1.4103965707552353\n",
      "31 Train Loss 17.974632 Test MSE 8.708705267454734 Test RE 1.4105382146690915\n",
      "32 Train Loss 17.194124 Test MSE 8.629233661585337 Test RE 1.4040875055698545\n",
      "33 Train Loss 16.2664 Test MSE 8.627262846503116 Test RE 1.4039271579099069\n",
      "34 Train Loss 15.65706 Test MSE 8.471060983047538 Test RE 1.3911596235639152\n",
      "35 Train Loss 14.990341 Test MSE 8.3296078169167 Test RE 1.3794956561336675\n",
      "36 Train Loss 14.523756 Test MSE 8.432075017686078 Test RE 1.3879546976038095\n",
      "37 Train Loss 13.899957 Test MSE 8.296825578017504 Test RE 1.3767783889997487\n",
      "38 Train Loss 13.178462 Test MSE 8.257519425819611 Test RE 1.3735132783836528\n",
      "39 Train Loss 12.6174555 Test MSE 8.177169585948286 Test RE 1.3668144534148117\n",
      "40 Train Loss 12.245766 Test MSE 8.02701106463259 Test RE 1.3542068026841778\n",
      "41 Train Loss 11.68288 Test MSE 8.014902963394517 Test RE 1.3531850611578837\n",
      "42 Train Loss 11.315968 Test MSE 8.045866379819616 Test RE 1.3557963743653505\n",
      "43 Train Loss 10.869463 Test MSE 7.9858364933950154 Test RE 1.3507291338589906\n",
      "44 Train Loss 10.497162 Test MSE 7.88813016507455 Test RE 1.3424406502945068\n",
      "45 Train Loss 10.031796 Test MSE 7.92564700240316 Test RE 1.3456292630623967\n",
      "46 Train Loss 9.671896 Test MSE 7.974183202704121 Test RE 1.3497432518078896\n",
      "47 Train Loss 9.409636 Test MSE 7.925763782256733 Test RE 1.3456391765627969\n",
      "48 Train Loss 8.893972 Test MSE 7.912658816112135 Test RE 1.344526233261968\n",
      "49 Train Loss 8.513903 Test MSE 7.89096670293067 Test RE 1.3426819965566337\n",
      "50 Train Loss 8.190727 Test MSE 7.888405757870103 Test RE 1.3424641009559783\n",
      "51 Train Loss 7.9301147 Test MSE 7.944199379137273 Test RE 1.3472032688681856\n",
      "52 Train Loss 7.6471334 Test MSE 7.99484164791049 Test RE 1.351490487881175\n",
      "53 Train Loss 7.395676 Test MSE 7.87914899326702 Test RE 1.3416762027217297\n",
      "54 Train Loss 7.131254 Test MSE 7.846383115411403 Test RE 1.338883578945569\n",
      "55 Train Loss 6.890398 Test MSE 7.8380061895251565 Test RE 1.3381686811723794\n",
      "56 Train Loss 6.5250783 Test MSE 7.726635208095371 Test RE 1.3286275837766177\n",
      "57 Train Loss 6.342638 Test MSE 7.72529756935341 Test RE 1.3285125724808244\n",
      "58 Train Loss 6.1228533 Test MSE 7.741280632078135 Test RE 1.3298861589477857\n",
      "59 Train Loss 5.9429913 Test MSE 7.721793596346942 Test RE 1.3282112507438673\n",
      "60 Train Loss 5.748852 Test MSE 7.686763993781551 Test RE 1.325195138080603\n",
      "61 Train Loss 5.625003 Test MSE 7.676997405642793 Test RE 1.3243529924859616\n",
      "62 Train Loss 5.39334 Test MSE 7.7196531509346284 Test RE 1.3280271509823178\n",
      "63 Train Loss 5.254923 Test MSE 7.688187280878809 Test RE 1.3253178194743291\n",
      "64 Train Loss 5.1065044 Test MSE 7.63685753979666 Test RE 1.320886206059103\n",
      "65 Train Loss 4.9816394 Test MSE 7.635727516993395 Test RE 1.3207884769378186\n",
      "66 Train Loss 4.8847537 Test MSE 7.603543040247041 Test RE 1.3180019857908605\n",
      "67 Train Loss 4.780513 Test MSE 7.570966210043423 Test RE 1.315175512997051\n",
      "68 Train Loss 4.700058 Test MSE 7.576438566555141 Test RE 1.3156507369658523\n",
      "69 Train Loss 4.585265 Test MSE 7.570106091119813 Test RE 1.315100803941069\n",
      "70 Train Loss 4.4768076 Test MSE 7.548386664049407 Test RE 1.3132128678388755\n",
      "71 Train Loss 4.3949847 Test MSE 7.4973011309365525 Test RE 1.3087615808524558\n",
      "72 Train Loss 4.3272123 Test MSE 7.495114680412724 Test RE 1.3085707287675798\n",
      "73 Train Loss 4.1927567 Test MSE 7.523858575206025 Test RE 1.3110775233874508\n",
      "74 Train Loss 4.1135488 Test MSE 7.468132152006747 Test RE 1.3062131676411182\n",
      "75 Train Loss 4.044425 Test MSE 7.447320870408172 Test RE 1.3043919000079283\n",
      "76 Train Loss 3.974309 Test MSE 7.502513460149599 Test RE 1.3092164452667365\n",
      "77 Train Loss 3.8857949 Test MSE 7.515147699572957 Test RE 1.3103183423993614\n",
      "78 Train Loss 3.8070922 Test MSE 7.528275050345889 Test RE 1.3114622655880825\n",
      "79 Train Loss 3.7204795 Test MSE 7.549631276168526 Test RE 1.3133211276137848\n",
      "80 Train Loss 3.6391914 Test MSE 7.560927118852478 Test RE 1.314303263254391\n",
      "81 Train Loss 3.5743003 Test MSE 7.59090625232086 Test RE 1.3169062967570557\n",
      "82 Train Loss 3.5080037 Test MSE 7.574937006926533 Test RE 1.3155203573748455\n",
      "83 Train Loss 3.458611 Test MSE 7.57395756521844 Test RE 1.315435306030033\n",
      "84 Train Loss 3.385058 Test MSE 7.580194371883565 Test RE 1.3159767949003052\n",
      "85 Train Loss 3.3198204 Test MSE 7.560190216075567 Test RE 1.3142392144076933\n",
      "86 Train Loss 3.247536 Test MSE 7.54216038938592 Test RE 1.3126711553416177\n",
      "87 Train Loss 3.1834621 Test MSE 7.5433682383336675 Test RE 1.3127762608365043\n",
      "88 Train Loss 3.1259751 Test MSE 7.531572369023913 Test RE 1.3117494386520456\n",
      "89 Train Loss 3.0383437 Test MSE 7.561693469067269 Test RE 1.3143698682521334\n",
      "90 Train Loss 2.995662 Test MSE 7.527569326639901 Test RE 1.3114007938900063\n",
      "91 Train Loss 2.9548283 Test MSE 7.485360817676009 Test RE 1.3077189889982241\n",
      "92 Train Loss 2.9076777 Test MSE 7.472083939655746 Test RE 1.3065587155158866\n",
      "93 Train Loss 2.8585138 Test MSE 7.466079695035063 Test RE 1.3060336628805291\n",
      "94 Train Loss 2.806446 Test MSE 7.470311236155034 Test RE 1.3064037200275957\n",
      "95 Train Loss 2.7393663 Test MSE 7.475627049721497 Test RE 1.3068684505728103\n",
      "96 Train Loss 2.7071548 Test MSE 7.458302562363736 Test RE 1.3053532627271065\n",
      "97 Train Loss 2.6555476 Test MSE 7.444387124511121 Test RE 1.3041349531543618\n",
      "98 Train Loss 2.5919113 Test MSE 7.441501306697744 Test RE 1.3038821545950872\n",
      "99 Train Loss 2.525986 Test MSE 7.3875010132358385 Test RE 1.2991426392277639\n",
      "Training time: 71.58\n",
      "KG_stan_tune11\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 135.42746 Test MSE 6.2986995080975445 Test RE 1.1995918465558717\n",
      "1 Train Loss 119.37405 Test MSE 6.307712652296127 Test RE 1.2004498196297781\n",
      "2 Train Loss 104.43335 Test MSE 6.3115372056510015 Test RE 1.2008136986542466\n",
      "3 Train Loss 94.650215 Test MSE 6.287194643055071 Test RE 1.198495790921631\n",
      "4 Train Loss 81.479774 Test MSE 5.917702944314086 Test RE 1.1627454283800545\n",
      "5 Train Loss 76.89288 Test MSE 5.827815341441674 Test RE 1.1538808119589912\n",
      "6 Train Loss 67.61583 Test MSE 5.413170499523619 Test RE 1.1120745794208464\n",
      "7 Train Loss 64.70617 Test MSE 5.501026802903987 Test RE 1.1210627976022203\n",
      "8 Train Loss 59.83821 Test MSE 5.420433525345213 Test RE 1.1128203825412912\n",
      "9 Train Loss 54.636417 Test MSE 5.292079667482495 Test RE 1.0995658596970572\n",
      "10 Train Loss 49.714985 Test MSE 5.593019760368101 Test RE 1.1303976269777785\n",
      "11 Train Loss 44.716812 Test MSE 6.09021346254799 Test RE 1.1795716273299532\n",
      "12 Train Loss 41.184853 Test MSE 6.225444829733201 Test RE 1.1925957426091518\n",
      "13 Train Loss 38.373417 Test MSE 6.411464012703042 Test RE 1.2102822521572938\n",
      "14 Train Loss 35.544952 Test MSE 6.338756506943786 Test RE 1.2034002433183022\n",
      "15 Train Loss 33.363144 Test MSE 6.422241498585792 Test RE 1.2112990497951293\n",
      "16 Train Loss 30.941826 Test MSE 6.414311899149915 Test RE 1.2105510178987313\n",
      "17 Train Loss 29.115818 Test MSE 6.1999499539859295 Test RE 1.190151236693259\n",
      "18 Train Loss 27.22716 Test MSE 6.029767922101374 Test RE 1.1737033895736217\n",
      "19 Train Loss 25.768478 Test MSE 5.994536179997812 Test RE 1.1702694102876918\n",
      "20 Train Loss 23.795185 Test MSE 5.670296881505778 Test RE 1.1381800244131453\n",
      "21 Train Loss 22.049812 Test MSE 5.719017280043249 Test RE 1.1430593084655183\n",
      "22 Train Loss 20.649784 Test MSE 5.832998642257773 Test RE 1.1543938328535002\n",
      "23 Train Loss 19.72874 Test MSE 5.892796611250482 Test RE 1.1602959762210692\n",
      "24 Train Loss 18.747475 Test MSE 5.79776057342025 Test RE 1.1509016125904297\n",
      "25 Train Loss 17.94423 Test MSE 5.775959163576015 Test RE 1.1487356978667351\n",
      "26 Train Loss 17.27684 Test MSE 5.829206233291892 Test RE 1.154018498860117\n",
      "27 Train Loss 16.625084 Test MSE 5.762804817648492 Test RE 1.1474268693571161\n",
      "28 Train Loss 15.944017 Test MSE 5.721506407853236 Test RE 1.1433080322457494\n",
      "29 Train Loss 15.097731 Test MSE 5.73246870832298 Test RE 1.1444027866376987\n",
      "30 Train Loss 14.093141 Test MSE 5.6437968701569075 Test RE 1.1355172796842437\n",
      "31 Train Loss 13.395771 Test MSE 5.58026402180447 Test RE 1.1291078686874396\n",
      "32 Train Loss 12.66721 Test MSE 5.5600218906070165 Test RE 1.1270581167360716\n",
      "33 Train Loss 12.0953455 Test MSE 5.528702854947479 Test RE 1.1238793323200935\n",
      "34 Train Loss 11.687056 Test MSE 5.516423420097137 Test RE 1.122630551654397\n",
      "35 Train Loss 11.000216 Test MSE 5.512780505381545 Test RE 1.1222598111904438\n",
      "36 Train Loss 10.440422 Test MSE 5.406811760424115 Test RE 1.1114212220228707\n",
      "37 Train Loss 9.855076 Test MSE 5.3413218962582905 Test RE 1.1046696852348885\n",
      "38 Train Loss 9.428323 Test MSE 5.34058632120043 Test RE 1.104593618349122\n",
      "39 Train Loss 9.076721 Test MSE 5.284201271794372 Test RE 1.0987470850386034\n",
      "40 Train Loss 8.639583 Test MSE 5.257781605543651 Test RE 1.0959969148048498\n",
      "41 Train Loss 8.112711 Test MSE 5.172976023126011 Test RE 1.0871220210008483\n",
      "42 Train Loss 7.758067 Test MSE 5.096782856300547 Test RE 1.0790861685902227\n",
      "43 Train Loss 7.432923 Test MSE 5.065916835118731 Test RE 1.075813743853179\n",
      "44 Train Loss 7.062325 Test MSE 4.96735471874626 Test RE 1.0652968609523545\n",
      "45 Train Loss 6.6356034 Test MSE 4.9505531589601395 Test RE 1.0634937070965345\n",
      "46 Train Loss 6.2009125 Test MSE 4.847738555143378 Test RE 1.0523922837696362\n",
      "47 Train Loss 5.4927015 Test MSE 4.463513637830258 Test RE 1.0098258721603053\n",
      "48 Train Loss 4.930006 Test MSE 4.181771604619176 Test RE 0.977435739884136\n",
      "49 Train Loss 4.3627634 Test MSE 4.205321080946297 Test RE 0.9801840708005434\n",
      "50 Train Loss 4.0512137 Test MSE 4.134396520948182 Test RE 0.971883308710562\n",
      "51 Train Loss 3.7765894 Test MSE 4.07911240162834 Test RE 0.9653635495841615\n",
      "52 Train Loss 3.5124178 Test MSE 4.027538946559935 Test RE 0.9592414450735895\n",
      "53 Train Loss 3.2382588 Test MSE 4.027577306161601 Test RE 0.9592460131277548\n",
      "54 Train Loss 3.0220375 Test MSE 3.978461765420351 Test RE 0.953379160450161\n",
      "55 Train Loss 2.8152256 Test MSE 3.9973348274538147 Test RE 0.9556378092074673\n",
      "56 Train Loss 2.6506903 Test MSE 4.022628800128673 Test RE 0.9586565404404627\n",
      "57 Train Loss 2.5350597 Test MSE 4.050684372961003 Test RE 0.9619937767391027\n",
      "58 Train Loss 2.4295754 Test MSE 4.054567127641938 Test RE 0.9624547224510632\n",
      "59 Train Loss 2.3553905 Test MSE 4.06490768989485 Test RE 0.9636812387799152\n",
      "60 Train Loss 2.266353 Test MSE 4.048482272730778 Test RE 0.9617322536838244\n",
      "61 Train Loss 2.2000878 Test MSE 4.03493872101352 Test RE 0.9601222451190861\n",
      "62 Train Loss 2.120781 Test MSE 4.06797634374896 Test RE 0.9640449181639594\n",
      "63 Train Loss 2.0618122 Test MSE 4.0584848800013065 Test RE 0.9629195993077858\n",
      "64 Train Loss 2.0050886 Test MSE 4.073565748507749 Test RE 0.9647069903023713\n",
      "65 Train Loss 1.9401163 Test MSE 4.051637675990358 Test RE 0.9621069696648837\n",
      "66 Train Loss 1.8851936 Test MSE 4.0213547437396056 Test RE 0.9585047144485486\n",
      "67 Train Loss 1.8233321 Test MSE 4.011907992682297 Test RE 0.9573782185294107\n",
      "68 Train Loss 1.753791 Test MSE 3.9712040314650903 Test RE 0.9525091595211576\n",
      "69 Train Loss 1.7099901 Test MSE 3.9982889099307783 Test RE 0.9557518480520294\n",
      "70 Train Loss 1.6659312 Test MSE 3.9998869102375285 Test RE 0.9559428221421566\n",
      "71 Train Loss 1.6193572 Test MSE 3.951932750343908 Test RE 0.9501952019383677\n",
      "72 Train Loss 1.5648664 Test MSE 3.945985290693535 Test RE 0.9494799347776138\n",
      "73 Train Loss 1.5190159 Test MSE 3.929950879032003 Test RE 0.947548877201197\n",
      "74 Train Loss 1.4771774 Test MSE 3.9308006401510185 Test RE 0.9476513144450397\n",
      "75 Train Loss 1.4337162 Test MSE 3.9482733663889213 Test RE 0.9497551723881712\n",
      "76 Train Loss 1.4047489 Test MSE 3.940567905251674 Test RE 0.9488279473730699\n",
      "77 Train Loss 1.3644121 Test MSE 3.9345362741553007 Test RE 0.9481015074362407\n",
      "78 Train Loss 1.3261276 Test MSE 3.9292028696012493 Test RE 0.947458696783226\n",
      "79 Train Loss 1.2776167 Test MSE 3.9044736878389834 Test RE 0.9444724855001689\n",
      "80 Train Loss 1.2407523 Test MSE 3.9297327951089382 Test RE 0.9475225857729189\n",
      "81 Train Loss 1.2095048 Test MSE 3.949786085240098 Test RE 0.9499370968438589\n",
      "82 Train Loss 1.1871598 Test MSE 3.9313544175603963 Test RE 0.9477180654019073\n",
      "83 Train Loss 1.1600112 Test MSE 3.9444852183506023 Test RE 0.9492994444979369\n",
      "84 Train Loss 1.1363945 Test MSE 3.934876255002203 Test RE 0.948142468983939\n",
      "85 Train Loss 1.1165111 Test MSE 3.9239774502461735 Test RE 0.9468284778426931\n",
      "86 Train Loss 1.0932314 Test MSE 3.9605960766622714 Test RE 0.9512361286373835\n",
      "87 Train Loss 1.0777967 Test MSE 3.94149279884693 Test RE 0.9489392908932412\n",
      "88 Train Loss 1.0570091 Test MSE 3.918854273338945 Test RE 0.946210182479139\n",
      "89 Train Loss 1.0372748 Test MSE 3.896781386509548 Test RE 0.9435416623741875\n",
      "90 Train Loss 1.0196159 Test MSE 3.8692052501524885 Test RE 0.9401971805093131\n",
      "91 Train Loss 1.0040015 Test MSE 3.8433251743045873 Test RE 0.9370475415529322\n",
      "92 Train Loss 0.99057287 Test MSE 3.810912081328104 Test RE 0.9330878299967515\n",
      "93 Train Loss 0.9756812 Test MSE 3.8391724027304894 Test RE 0.9365411576340393\n",
      "94 Train Loss 0.96285117 Test MSE 3.8315325213194966 Test RE 0.9356088438712379\n",
      "95 Train Loss 0.9439146 Test MSE 3.8145031424637716 Test RE 0.9335273555453918\n",
      "96 Train Loss 0.9326406 Test MSE 3.8127739596156704 Test RE 0.9333157391941179\n",
      "97 Train Loss 0.91729426 Test MSE 3.7776364779542306 Test RE 0.9290051937537833\n",
      "98 Train Loss 0.90164304 Test MSE 3.773460816216788 Test RE 0.9284916075416483\n",
      "99 Train Loss 0.8851812 Test MSE 3.7752663420795733 Test RE 0.9287137133494896\n",
      "Training time: 72.03\n",
      "KG_stan_tune11\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 276.39304 Test MSE 6.795535302484557 Test RE 1.2460053204195838\n",
      "1 Train Loss 224.36385 Test MSE 6.843715820515066 Test RE 1.2504146234031959\n",
      "2 Train Loss 165.19441 Test MSE 6.54849135307309 Test RE 1.2231470986058874\n",
      "3 Train Loss 148.17754 Test MSE 6.278964995515145 Test RE 1.197711146240709\n",
      "4 Train Loss 135.11409 Test MSE 6.181972506621355 Test RE 1.1884244958456307\n",
      "5 Train Loss 118.84773 Test MSE 5.8782759177174455 Test RE 1.1588655268644539\n",
      "6 Train Loss 101.07766 Test MSE 5.702315669676374 Test RE 1.1413890136608646\n",
      "7 Train Loss 87.58232 Test MSE 5.605084661622768 Test RE 1.131616180588122\n",
      "8 Train Loss 80.36885 Test MSE 5.57489727173651 Test RE 1.1285647852997827\n",
      "9 Train Loss 73.67697 Test MSE 5.73482280587289 Test RE 1.1446377429372057\n",
      "10 Train Loss 68.13071 Test MSE 5.7743361115978455 Test RE 1.1485742884201673\n",
      "11 Train Loss 62.803978 Test MSE 5.71952565095531 Test RE 1.1431101113536422\n",
      "12 Train Loss 58.801643 Test MSE 5.673340524362687 Test RE 1.138485453637328\n",
      "13 Train Loss 56.159748 Test MSE 5.6813385546195745 Test RE 1.1392876647985835\n",
      "14 Train Loss 53.14888 Test MSE 5.794912512603282 Test RE 1.1506188964976158\n",
      "15 Train Loss 50.658527 Test MSE 5.853242446292032 Test RE 1.1563952975271727\n",
      "16 Train Loss 48.141563 Test MSE 6.02006409148853 Test RE 1.1727585766863529\n",
      "17 Train Loss 46.2259 Test MSE 6.123469915179034 Test RE 1.1827878496288953\n",
      "18 Train Loss 44.48014 Test MSE 6.0579029058956015 Test RE 1.1764384612587802\n",
      "19 Train Loss 42.89537 Test MSE 6.132664963523379 Test RE 1.1836755580588407\n",
      "20 Train Loss 41.293774 Test MSE 6.233775585207209 Test RE 1.1933934287367671\n",
      "21 Train Loss 39.90099 Test MSE 6.094037551956682 Test RE 1.1799419000246432\n",
      "22 Train Loss 38.50537 Test MSE 6.001259466897864 Test RE 1.1709254954169928\n",
      "23 Train Loss 37.24363 Test MSE 5.990166094477611 Test RE 1.1698427626151764\n",
      "24 Train Loss 35.890762 Test MSE 5.811124153121507 Test RE 1.1522272376127007\n",
      "25 Train Loss 34.251083 Test MSE 5.719386287365829 Test RE 1.1430961845956855\n",
      "26 Train Loss 33.125114 Test MSE 5.737892669755807 Test RE 1.144944065561594\n",
      "27 Train Loss 31.754961 Test MSE 5.64291049051429 Test RE 1.1354281075413188\n",
      "28 Train Loss 30.436573 Test MSE 5.717591978540469 Test RE 1.1429168621682675\n",
      "29 Train Loss 29.475147 Test MSE 5.842078659650689 Test RE 1.155291984961057\n",
      "30 Train Loss 28.814144 Test MSE 5.841166357681641 Test RE 1.1552017759477378\n",
      "31 Train Loss 28.183388 Test MSE 5.869038857700032 Test RE 1.157954654431849\n",
      "32 Train Loss 27.433659 Test MSE 5.887739630094808 Test RE 1.159798007713682\n",
      "33 Train Loss 26.531555 Test MSE 5.886360246239074 Test RE 1.1596621406016656\n",
      "34 Train Loss 25.85012 Test MSE 5.895131190385222 Test RE 1.1605257936335802\n",
      "35 Train Loss 25.319294 Test MSE 5.857811620136528 Test RE 1.1568465636792413\n",
      "36 Train Loss 24.829311 Test MSE 5.805601813830601 Test RE 1.1516796239331195\n",
      "37 Train Loss 24.466843 Test MSE 5.84715110938896 Test RE 1.1557934236939653\n",
      "38 Train Loss 23.88609 Test MSE 5.867051528281231 Test RE 1.1577585889221411\n",
      "39 Train Loss 23.464088 Test MSE 5.9094132365814085 Test RE 1.1619307374587864\n",
      "40 Train Loss 22.980167 Test MSE 5.858943440524721 Test RE 1.1569583186631376\n",
      "41 Train Loss 22.30735 Test MSE 5.836445270765963 Test RE 1.1547348392006347\n",
      "42 Train Loss 21.871407 Test MSE 5.863447599741051 Test RE 1.1574029486017232\n",
      "43 Train Loss 21.525486 Test MSE 5.819057294952064 Test RE 1.15301345937595\n",
      "44 Train Loss 21.150059 Test MSE 5.8073990810570075 Test RE 1.1518578755545086\n",
      "45 Train Loss 20.686628 Test MSE 5.772510018580841 Test RE 1.148392659805592\n",
      "46 Train Loss 20.261377 Test MSE 5.736198902695538 Test RE 1.1447750652168773\n",
      "47 Train Loss 19.84201 Test MSE 5.734082061002922 Test RE 1.1445638163359824\n",
      "48 Train Loss 19.5266 Test MSE 5.75825873086968 Test RE 1.146974196445773\n",
      "49 Train Loss 19.245056 Test MSE 5.7495474658667165 Test RE 1.146106279736832\n",
      "50 Train Loss 18.989374 Test MSE 5.719009996472225 Test RE 1.1430585805820463\n",
      "51 Train Loss 18.626377 Test MSE 5.755281952873538 Test RE 1.1466776893691863\n",
      "52 Train Loss 18.318901 Test MSE 5.793817057878867 Test RE 1.1505101364018313\n",
      "53 Train Loss 17.9409 Test MSE 5.724159306357474 Test RE 1.1435730611075428\n",
      "54 Train Loss 17.579697 Test MSE 5.756549203360502 Test RE 1.146803925398125\n",
      "55 Train Loss 17.199306 Test MSE 5.806709806165335 Test RE 1.151789517046602\n",
      "56 Train Loss 16.895596 Test MSE 5.676541941045587 Test RE 1.13880662705151\n",
      "57 Train Loss 16.600794 Test MSE 5.702346622044076 Test RE 1.1413921114062842\n",
      "58 Train Loss 16.322115 Test MSE 5.721964287727074 Test RE 1.1433537795740807\n",
      "59 Train Loss 15.959614 Test MSE 5.643071787469474 Test RE 1.135444334964045\n",
      "60 Train Loss 15.683345 Test MSE 5.58524968567909 Test RE 1.1296121544587274\n",
      "61 Train Loss 15.454121 Test MSE 5.574413286498044 Test RE 1.1285157960067587\n",
      "62 Train Loss 15.117043 Test MSE 5.629025286689074 Test RE 1.1340303039522308\n",
      "63 Train Loss 14.786133 Test MSE 5.621324425001934 Test RE 1.1332543259678562\n",
      "64 Train Loss 14.41391 Test MSE 5.598453556723229 Test RE 1.1309466022738195\n",
      "65 Train Loss 14.032197 Test MSE 5.6158441177251115 Test RE 1.1327017785703581\n",
      "66 Train Loss 13.6856785 Test MSE 5.643415038028099 Test RE 1.1354788672179683\n",
      "67 Train Loss 13.376549 Test MSE 5.62846075183958 Test RE 1.1339734365865177\n",
      "68 Train Loss 13.023533 Test MSE 5.651800657034664 Test RE 1.1363221649935105\n",
      "69 Train Loss 12.641684 Test MSE 5.660173118148056 Test RE 1.1371635156471702\n",
      "70 Train Loss 12.316479 Test MSE 5.606356780680797 Test RE 1.1317445880008976\n",
      "71 Train Loss 11.94202 Test MSE 5.6158448445631866 Test RE 1.1327018518710708\n",
      "72 Train Loss 11.549897 Test MSE 5.633863733490371 Test RE 1.13451757896375\n",
      "73 Train Loss 11.275241 Test MSE 5.600872007595086 Test RE 1.131190852176697\n",
      "74 Train Loss 11.048166 Test MSE 5.620341031659283 Test RE 1.1331551959924768\n",
      "75 Train Loss 10.805393 Test MSE 5.5627621377402505 Test RE 1.127335816842073\n",
      "76 Train Loss 10.564119 Test MSE 5.50904081391415 Test RE 1.121879094287362\n",
      "77 Train Loss 10.345028 Test MSE 5.499697920830757 Test RE 1.120927381952631\n",
      "78 Train Loss 10.181114 Test MSE 5.47244193689104 Test RE 1.118146326844579\n",
      "79 Train Loss 10.0050125 Test MSE 5.475126834163652 Test RE 1.1184205864825625\n",
      "80 Train Loss 9.771562 Test MSE 5.4563834422469055 Test RE 1.1165045608068112\n",
      "81 Train Loss 9.545769 Test MSE 5.449767925965129 Test RE 1.1158275103046387\n",
      "82 Train Loss 9.322974 Test MSE 5.435692023960035 Test RE 1.1143855742681281\n",
      "83 Train Loss 9.074557 Test MSE 5.38769580928898 Test RE 1.1094547502050036\n",
      "84 Train Loss 8.829637 Test MSE 5.348696324065611 Test RE 1.105431996247837\n",
      "85 Train Loss 8.605632 Test MSE 5.312565577359422 Test RE 1.1016920417623337\n",
      "86 Train Loss 8.354746 Test MSE 5.263115392912793 Test RE 1.0965526941344794\n",
      "87 Train Loss 8.113007 Test MSE 5.269377685504639 Test RE 1.097204864177107\n",
      "88 Train Loss 7.8940115 Test MSE 5.280857588125495 Test RE 1.0983994029711655\n",
      "89 Train Loss 7.727582 Test MSE 5.2520677729665035 Test RE 1.0954012220152602\n",
      "90 Train Loss 7.570961 Test MSE 5.259246540195111 Test RE 1.0961495887040318\n",
      "91 Train Loss 7.355488 Test MSE 5.250218089703015 Test RE 1.0952083147814706\n",
      "92 Train Loss 7.145378 Test MSE 5.210834765071335 Test RE 1.0910928536060707\n",
      "93 Train Loss 6.953029 Test MSE 5.216362764452279 Test RE 1.0916714520523025\n",
      "94 Train Loss 6.744011 Test MSE 5.168816904958059 Test RE 1.0866849052942582\n",
      "95 Train Loss 6.566232 Test MSE 5.1205859386715655 Test RE 1.0816030167863482\n",
      "96 Train Loss 6.402787 Test MSE 5.15149103345132 Test RE 1.0848620928842105\n",
      "97 Train Loss 6.2120624 Test MSE 5.140544049747032 Test RE 1.083708807026495\n",
      "98 Train Loss 6.0742893 Test MSE 5.1338222983066695 Test RE 1.0830000489659664\n",
      "99 Train Loss 5.94675 Test MSE 5.145098143793269 Test RE 1.0841887386439713\n",
      "Training time: 70.89\n",
      "KG_stan_tune11\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 518.77576 Test MSE 5.342266551499098 Test RE 1.1047673657241603\n",
      "1 Train Loss 425.78418 Test MSE 5.341478271452972 Test RE 1.1046858555459214\n",
      "2 Train Loss 327.767 Test MSE 5.345955510844552 Test RE 1.1051487336842756\n",
      "3 Train Loss 294.2606 Test MSE 5.343172869981387 Test RE 1.104861073947962\n",
      "4 Train Loss 270.82947 Test MSE 5.33701329783299 Test RE 1.1042240522643263\n",
      "5 Train Loss 263.26263 Test MSE 5.338523264932878 Test RE 1.1043802467481\n",
      "6 Train Loss 250.59125 Test MSE 5.3404673117005474 Test RE 1.1045813109114608\n",
      "7 Train Loss 240.85631 Test MSE 5.34120978922155 Test RE 1.1046580924216098\n",
      "8 Train Loss 224.81279 Test MSE 5.357477031173585 Test RE 1.1063389924201799\n",
      "9 Train Loss 207.91594 Test MSE 5.3805836041787485 Test RE 1.1087222222535238\n",
      "10 Train Loss 193.05678 Test MSE 5.4087268436675044 Test RE 1.111618036320441\n",
      "11 Train Loss 183.77187 Test MSE 5.431370254866337 Test RE 1.1139424775305478\n",
      "12 Train Loss 173.51616 Test MSE 5.465545777010291 Test RE 1.1174415823529675\n",
      "13 Train Loss 167.53188 Test MSE 5.470942017932412 Test RE 1.1179930822941042\n",
      "14 Train Loss 156.94272 Test MSE 5.470501785829891 Test RE 1.1179481004294602\n",
      "15 Train Loss 147.13918 Test MSE 5.475806107281247 Test RE 1.11848996290977\n",
      "16 Train Loss 140.42172 Test MSE 5.464242129734828 Test RE 1.1173083077807238\n",
      "17 Train Loss 134.75327 Test MSE 5.434824720666021 Test RE 1.1142966666523566\n",
      "18 Train Loss 132.19633 Test MSE 5.416065719493465 Test RE 1.1123719347446428\n",
      "19 Train Loss 126.70248 Test MSE 5.35887993299828 Test RE 1.106483835168804\n",
      "20 Train Loss 120.04599 Test MSE 5.29827801702002 Test RE 1.1002096046396694\n",
      "21 Train Loss 116.485535 Test MSE 5.309378509522758 Test RE 1.1013615334630686\n",
      "22 Train Loss 113.47737 Test MSE 5.308931541272091 Test RE 1.1013151736115352\n",
      "23 Train Loss 110.08154 Test MSE 5.2951539724693975 Test RE 1.0998851963492242\n",
      "24 Train Loss 107.40892 Test MSE 5.316487897281506 Test RE 1.1020986618106576\n",
      "25 Train Loss 105.77475 Test MSE 5.323262047660142 Test RE 1.1028005730669261\n",
      "26 Train Loss 103.51633 Test MSE 5.324021952667343 Test RE 1.1028792836174035\n",
      "27 Train Loss 101.96463 Test MSE 5.337218130820028 Test RE 1.1042452419567823\n",
      "28 Train Loss 99.94419 Test MSE 5.3573006794977465 Test RE 1.106320783630874\n",
      "29 Train Loss 98.95106 Test MSE 5.381981168896806 Test RE 1.1088662038890333\n",
      "30 Train Loss 96.97292 Test MSE 5.427931568116691 Test RE 1.113589794364325\n",
      "31 Train Loss 94.940834 Test MSE 5.452896815980967 Test RE 1.116147780876708\n",
      "32 Train Loss 93.550064 Test MSE 5.505702576096174 Test RE 1.1215391379447053\n",
      "33 Train Loss 91.67908 Test MSE 5.5406471936646 Test RE 1.125092704897488\n",
      "34 Train Loss 89.08642 Test MSE 5.550938204463328 Test RE 1.1261370747565835\n",
      "35 Train Loss 86.90238 Test MSE 5.627659426552149 Test RE 1.1338927116801283\n",
      "36 Train Loss 85.92084 Test MSE 5.6675761793672 Test RE 1.1379069328593712\n",
      "37 Train Loss 84.08407 Test MSE 5.669559791747618 Test RE 1.1381060452087046\n",
      "38 Train Loss 82.97648 Test MSE 5.676747687783991 Test RE 1.1388272649353268\n",
      "39 Train Loss 81.51716 Test MSE 5.682102754692614 Test RE 1.1393642853372605\n",
      "40 Train Loss 80.36725 Test MSE 5.677325279812613 Test RE 1.1388851995887153\n",
      "41 Train Loss 78.92012 Test MSE 5.679397016331349 Test RE 1.139092978316426\n",
      "42 Train Loss 76.096375 Test MSE 5.618682461982153 Test RE 1.132987985896862\n",
      "43 Train Loss 74.438545 Test MSE 5.552460670292594 Test RE 1.126291497991742\n",
      "44 Train Loss 72.933304 Test MSE 5.512041954049835 Test RE 1.1221846336788932\n",
      "45 Train Loss 72.38995 Test MSE 5.4946013320056695 Test RE 1.1204078779537898\n",
      "46 Train Loss 70.50466 Test MSE 5.457404435640864 Test RE 1.1166090155680697\n",
      "47 Train Loss 66.79773 Test MSE 5.496208444604689 Test RE 1.1205717196832878\n",
      "48 Train Loss 65.62047 Test MSE 5.487910459963289 Test RE 1.1197255000303854\n",
      "49 Train Loss 64.929794 Test MSE 5.499365800237672 Test RE 1.120893535667538\n",
      "50 Train Loss 63.3767 Test MSE 5.5561645903533945 Test RE 1.126667097067799\n",
      "51 Train Loss 62.528015 Test MSE 5.60091074319205 Test RE 1.1311947638244835\n",
      "52 Train Loss 62.041294 Test MSE 5.620660799170139 Test RE 1.1331874307857617\n",
      "53 Train Loss 61.617878 Test MSE 5.652945040609569 Test RE 1.1364372011280919\n",
      "54 Train Loss 60.702984 Test MSE 5.7013529019460645 Test RE 1.1412926546585425\n",
      "55 Train Loss 60.48529 Test MSE 5.710236062287424 Test RE 1.1421814208717636\n",
      "56 Train Loss 59.983723 Test MSE 5.734247370288114 Test RE 1.1445803146752693\n",
      "57 Train Loss 59.349815 Test MSE 5.757805257219016 Test RE 1.1469290323743975\n",
      "58 Train Loss 58.86039 Test MSE 5.788856178499 Test RE 1.1500174763618103\n",
      "59 Train Loss 58.447655 Test MSE 5.796425801215272 Test RE 1.1507691235120898\n",
      "60 Train Loss 57.637897 Test MSE 5.757477132429921 Test RE 1.1468963514142194\n",
      "61 Train Loss 56.85133 Test MSE 5.752457336276453 Test RE 1.1463962676801716\n",
      "62 Train Loss 55.574947 Test MSE 5.71803173321836 Test RE 1.142960813658223\n",
      "63 Train Loss 54.968227 Test MSE 5.694310331122716 Test RE 1.140587548507766\n",
      "64 Train Loss 54.357033 Test MSE 5.672045764580816 Test RE 1.1383555346519416\n",
      "65 Train Loss 53.46046 Test MSE 5.69791958657454 Test RE 1.1409489636284706\n",
      "66 Train Loss 52.905045 Test MSE 5.695981173333566 Test RE 1.1407548736036723\n",
      "67 Train Loss 52.451897 Test MSE 5.715073809413248 Test RE 1.1426651500025597\n",
      "68 Train Loss 52.022903 Test MSE 5.72271969004001 Test RE 1.1434292487261344\n",
      "69 Train Loss 51.484493 Test MSE 5.70354213806718 Test RE 1.1415117534707724\n",
      "70 Train Loss 51.09615 Test MSE 5.688612410725038 Test RE 1.1400167503541532\n",
      "71 Train Loss 50.74075 Test MSE 5.688025231770697 Test RE 1.1399579125331096\n",
      "72 Train Loss 50.566307 Test MSE 5.6900217213246735 Test RE 1.1401579568627258\n",
      "73 Train Loss 50.422 Test MSE 5.678962149005129 Test RE 1.1390493677184201\n",
      "74 Train Loss 49.996914 Test MSE 5.671939014558936 Test RE 1.1383448224631618\n",
      "75 Train Loss 49.638454 Test MSE 5.682762642661053 Test RE 1.139430443147871\n",
      "76 Train Loss 49.33938 Test MSE 5.680156198650867 Test RE 1.1391691087885032\n",
      "77 Train Loss 48.812088 Test MSE 5.675593497303138 Test RE 1.1387114864579817\n",
      "78 Train Loss 48.504944 Test MSE 5.675005470279167 Test RE 1.1386524961099884\n",
      "79 Train Loss 48.266983 Test MSE 5.6739758468882835 Test RE 1.1385491978460665\n",
      "80 Train Loss 47.98952 Test MSE 5.658194464993303 Test RE 1.1369647364927675\n",
      "81 Train Loss 47.68318 Test MSE 5.6530916735181655 Test RE 1.136451940172115\n",
      "82 Train Loss 47.085262 Test MSE 5.679365108578877 Test RE 1.1390897785094978\n",
      "83 Train Loss 46.702393 Test MSE 5.698894803438192 Test RE 1.1410465979533944\n",
      "84 Train Loss 46.457813 Test MSE 5.689297953990893 Test RE 1.140085440854164\n",
      "85 Train Loss 46.271248 Test MSE 5.683099694927657 Test RE 1.139464233219991\n",
      "86 Train Loss 45.7865 Test MSE 5.736737069741207 Test RE 1.1448287650428295\n",
      "87 Train Loss 45.47855 Test MSE 5.77442665239606 Test RE 1.1485832931285203\n",
      "88 Train Loss 45.386772 Test MSE 5.770417337113728 Test RE 1.1481844801857237\n",
      "89 Train Loss 45.12203 Test MSE 5.790654088967807 Test RE 1.15019604945808\n",
      "90 Train Loss 44.714348 Test MSE 5.814039164676359 Test RE 1.1525161950087819\n",
      "91 Train Loss 44.39842 Test MSE 5.821244691868251 Test RE 1.1532301492095836\n",
      "92 Train Loss 44.119415 Test MSE 5.850539743459098 Test RE 1.1561282870845075\n",
      "93 Train Loss 44.009827 Test MSE 5.865422986755799 Test RE 1.1575978958733304\n",
      "94 Train Loss 43.56551 Test MSE 5.906010693645947 Test RE 1.1615961789907396\n",
      "95 Train Loss 43.38366 Test MSE 5.899400618699203 Test RE 1.1609459611198765\n",
      "96 Train Loss 43.126873 Test MSE 5.917344419657577 Test RE 1.1627102053193923\n",
      "97 Train Loss 42.71589 Test MSE 5.906930015632121 Test RE 1.161686581752332\n",
      "98 Train Loss 42.502934 Test MSE 5.885202113131409 Test RE 1.1595480540414214\n",
      "99 Train Loss 42.296852 Test MSE 5.877981069980007 Test RE 1.1588364628014391\n",
      "Training time: 70.35\n",
      "KG_stan_tune11\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 365.05414 Test MSE 6.389302601281832 Test RE 1.2081887536682054\n",
      "1 Train Loss 245.13278 Test MSE 6.377239987933157 Test RE 1.2070477215506585\n",
      "2 Train Loss 201.48976 Test MSE 6.298921509066237 Test RE 1.199612986491592\n",
      "3 Train Loss 164.20322 Test MSE 6.371701354254719 Test RE 1.2065234471488782\n",
      "4 Train Loss 133.79004 Test MSE 6.395030778277053 Test RE 1.2087302187544542\n",
      "5 Train Loss 117.1428 Test MSE 6.393693294268373 Test RE 1.2086038126485308\n",
      "6 Train Loss 105.27078 Test MSE 6.512815664275526 Test RE 1.2198107416052983\n",
      "7 Train Loss 88.42902 Test MSE 6.560356703664537 Test RE 1.224254720207744\n",
      "8 Train Loss 82.873985 Test MSE 6.469284065784208 Test RE 1.215727305004485\n",
      "9 Train Loss 76.14846 Test MSE 6.3554480603179355 Test RE 1.204983630648346\n",
      "10 Train Loss 72.67628 Test MSE 6.29568691034002 Test RE 1.1993049365416575\n",
      "11 Train Loss 68.22494 Test MSE 6.2935560343020915 Test RE 1.1991019573856212\n",
      "12 Train Loss 64.00857 Test MSE 6.2740586722633696 Test RE 1.1972431147712608\n",
      "13 Train Loss 59.33644 Test MSE 6.221352212934497 Test RE 1.1922036710435837\n",
      "14 Train Loss 55.69761 Test MSE 6.337501932735315 Test RE 1.2032811482231842\n",
      "15 Train Loss 53.24203 Test MSE 6.45601481061081 Test RE 1.2144798658590028\n",
      "16 Train Loss 50.16729 Test MSE 6.514436935442303 Test RE 1.2199625592695074\n",
      "17 Train Loss 47.78941 Test MSE 6.492286268437073 Test RE 1.217886708740061\n",
      "18 Train Loss 46.03221 Test MSE 6.564390236268513 Test RE 1.2246310192995342\n",
      "19 Train Loss 43.51435 Test MSE 6.8812589832782525 Test RE 1.2538396862671175\n",
      "20 Train Loss 41.77235 Test MSE 7.062899149611088 Test RE 1.2702802996240619\n",
      "21 Train Loss 39.985073 Test MSE 7.190699182831696 Test RE 1.2817213562589778\n",
      "22 Train Loss 38.853096 Test MSE 7.344985851247712 Test RE 1.2953989540374966\n",
      "23 Train Loss 37.649418 Test MSE 7.553180695731518 Test RE 1.3136298168571992\n",
      "24 Train Loss 36.264187 Test MSE 7.69633831443458 Test RE 1.3260201858369354\n",
      "25 Train Loss 35.019825 Test MSE 7.670109779751324 Test RE 1.3237587696192594\n",
      "26 Train Loss 34.022354 Test MSE 7.683054703121462 Test RE 1.3248753593609675\n",
      "27 Train Loss 33.290234 Test MSE 7.749917168356564 Test RE 1.330627793886362\n",
      "28 Train Loss 32.44387 Test MSE 7.6331055039976885 Test RE 1.3205616863738\n",
      "29 Train Loss 31.366177 Test MSE 7.593461433233968 Test RE 1.3171279205396034\n",
      "30 Train Loss 30.704948 Test MSE 7.713226679696928 Test RE 1.327474256631271\n",
      "31 Train Loss 29.926916 Test MSE 7.697293111378224 Test RE 1.3261024353888862\n",
      "32 Train Loss 29.422916 Test MSE 7.617779257694039 Test RE 1.3192352653457542\n",
      "33 Train Loss 28.763065 Test MSE 7.625271221047893 Test RE 1.319883829252462\n",
      "34 Train Loss 27.965843 Test MSE 7.729925894815639 Test RE 1.3289104774050067\n",
      "35 Train Loss 27.371603 Test MSE 7.7049626035992524 Test RE 1.3267629273291746\n",
      "36 Train Loss 26.783642 Test MSE 7.665211632552494 Test RE 1.3233360246394303\n",
      "37 Train Loss 26.189772 Test MSE 7.751487382784525 Test RE 1.330762586626299\n",
      "38 Train Loss 25.54818 Test MSE 7.694635250062605 Test RE 1.3258734652415707\n",
      "39 Train Loss 25.170368 Test MSE 7.6131645902650975 Test RE 1.318835624318557\n",
      "40 Train Loss 24.775051 Test MSE 7.606533130353381 Test RE 1.318261112181639\n",
      "41 Train Loss 24.333303 Test MSE 7.500249808033485 Test RE 1.309018922518475\n",
      "42 Train Loss 24.050798 Test MSE 7.483536430207343 Test RE 1.3075596158175413\n",
      "43 Train Loss 23.81425 Test MSE 7.5241618187357195 Test RE 1.3111039441239656\n",
      "44 Train Loss 23.325983 Test MSE 7.448532415344579 Test RE 1.3044979962243723\n",
      "45 Train Loss 23.008064 Test MSE 7.473419837845839 Test RE 1.3066755069913387\n",
      "46 Train Loss 22.593922 Test MSE 7.436848943765985 Test RE 1.3034745028878933\n",
      "47 Train Loss 22.159517 Test MSE 7.300161441171661 Test RE 1.2914401748200999\n",
      "48 Train Loss 21.663296 Test MSE 7.2313165318675106 Test RE 1.2853362212834543\n",
      "49 Train Loss 21.166996 Test MSE 7.047545366216569 Test RE 1.2688988400248933\n",
      "50 Train Loss 20.71099 Test MSE 6.816470895892298 Test RE 1.2479231826084312\n",
      "51 Train Loss 20.25101 Test MSE 6.8550550137289585 Test RE 1.2514500860931963\n",
      "52 Train Loss 19.767368 Test MSE 6.790997158734684 Test RE 1.2455892019413581\n",
      "53 Train Loss 19.447193 Test MSE 6.739185591386145 Test RE 1.240828524493804\n",
      "54 Train Loss 19.039825 Test MSE 6.808978798785415 Test RE 1.2472371874441763\n",
      "55 Train Loss 18.563473 Test MSE 6.779080858123815 Test RE 1.2444958917847453\n",
      "56 Train Loss 18.179436 Test MSE 6.669394684395139 Test RE 1.2343868025095515\n",
      "57 Train Loss 17.83709 Test MSE 6.623274366277016 Test RE 1.2301113713893879\n",
      "58 Train Loss 17.390461 Test MSE 6.611201424359426 Test RE 1.2289897330468684\n",
      "59 Train Loss 16.981297 Test MSE 6.562074748102753 Test RE 1.2244150153273512\n",
      "60 Train Loss 16.803507 Test MSE 6.475684403319638 Test RE 1.216328541666906\n",
      "61 Train Loss 16.466507 Test MSE 6.359076909127336 Test RE 1.2053275937620345\n",
      "62 Train Loss 16.221245 Test MSE 6.370701057506852 Test RE 1.2064287370562152\n",
      "63 Train Loss 15.897877 Test MSE 6.293234321412877 Test RE 1.1990713092525873\n",
      "64 Train Loss 15.621117 Test MSE 6.375408531166414 Test RE 1.2068743852435746\n",
      "65 Train Loss 15.337531 Test MSE 6.388431627821413 Test RE 1.2081064022544858\n",
      "66 Train Loss 15.152174 Test MSE 6.3366991045746826 Test RE 1.2032049306064483\n",
      "67 Train Loss 14.958781 Test MSE 6.331261206775318 Test RE 1.2026885489972787\n",
      "68 Train Loss 14.7963505 Test MSE 6.309254703560904 Test RE 1.2005965480985747\n",
      "69 Train Loss 14.565186 Test MSE 6.299157211506546 Test RE 1.1996354307356487\n",
      "70 Train Loss 14.426399 Test MSE 6.308892252060168 Test RE 1.2005620619119366\n",
      "71 Train Loss 14.184248 Test MSE 6.309687262825503 Test RE 1.2006377035347866\n",
      "72 Train Loss 13.987625 Test MSE 6.3514624625343075 Test RE 1.2046057396467282\n",
      "73 Train Loss 13.833421 Test MSE 6.317941923173626 Test RE 1.201422815116038\n",
      "74 Train Loss 13.618275 Test MSE 6.260156708842388 Test RE 1.1959159626849327\n",
      "75 Train Loss 13.473412 Test MSE 6.298868343022684 Test RE 1.1996079238145312\n",
      "76 Train Loss 13.322742 Test MSE 6.260794025543491 Test RE 1.1959768363861965\n",
      "77 Train Loss 13.160735 Test MSE 6.304525275318132 Test RE 1.2001464791147098\n",
      "78 Train Loss 12.936346 Test MSE 6.315434374258228 Test RE 1.2011843731126315\n",
      "79 Train Loss 12.631549 Test MSE 6.330611274908947 Test RE 1.202626816772911\n",
      "80 Train Loss 12.4130945 Test MSE 6.295328783736274 Test RE 1.1992708251636552\n",
      "81 Train Loss 12.1587 Test MSE 6.312915668226416 Test RE 1.2009448225247057\n",
      "82 Train Loss 11.979005 Test MSE 6.367137495240419 Test RE 1.20609127142569\n",
      "83 Train Loss 11.810851 Test MSE 6.326507417279127 Test RE 1.202236948469901\n",
      "84 Train Loss 11.624292 Test MSE 6.303087952741607 Test RE 1.2000096650103291\n",
      "85 Train Loss 11.505526 Test MSE 6.318439499164714 Test RE 1.2014701238271346\n",
      "86 Train Loss 11.34285 Test MSE 6.282733294980252 Test RE 1.1980704934669262\n",
      "87 Train Loss 11.181975 Test MSE 6.287587224100478 Test RE 1.1985332081969575\n",
      "88 Train Loss 11.0699625 Test MSE 6.306591013542861 Test RE 1.2003430827684118\n",
      "89 Train Loss 10.938211 Test MSE 6.285479366578482 Test RE 1.1983322925741031\n",
      "90 Train Loss 10.795206 Test MSE 6.258674878787079 Test RE 1.1957744127859278\n",
      "91 Train Loss 10.6412945 Test MSE 6.2378184296977475 Test RE 1.1937803469041162\n",
      "92 Train Loss 10.489769 Test MSE 6.242582442903737 Test RE 1.1942361232261423\n",
      "93 Train Loss 10.355439 Test MSE 6.240068085330932 Test RE 1.1939955946399747\n",
      "94 Train Loss 10.170608 Test MSE 6.208741676818263 Test RE 1.190994773586421\n",
      "95 Train Loss 10.049827 Test MSE 6.191900568275673 Test RE 1.1893783999873664\n",
      "96 Train Loss 9.929689 Test MSE 6.12977204164266 Test RE 1.1833963413671067\n",
      "97 Train Loss 9.784527 Test MSE 6.148556470025166 Test RE 1.185208188482519\n",
      "98 Train Loss 9.622822 Test MSE 6.14360629348619 Test RE 1.1847309893915827\n",
      "99 Train Loss 9.479946 Test MSE 6.127451952202609 Test RE 1.183172365240159\n",
      "Training time: 71.28\n",
      "KG_stan_tune11\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 466.5074 Test MSE 5.452159211151056 Test RE 1.116072288540749\n",
      "1 Train Loss 323.58624 Test MSE 5.44566360003864 Test RE 1.1154072554941539\n",
      "2 Train Loss 276.35883 Test MSE 5.444865120498065 Test RE 1.1153254782684325\n",
      "3 Train Loss 211.28409 Test MSE 5.426656467583503 Test RE 1.113458987414787\n",
      "4 Train Loss 184.6065 Test MSE 5.407157403789075 Test RE 1.1114567465841811\n",
      "5 Train Loss 168.38159 Test MSE 5.3836549252686465 Test RE 1.109038615082987\n",
      "6 Train Loss 156.24838 Test MSE 5.370561170103363 Test RE 1.1076891303382992\n",
      "7 Train Loss 141.23785 Test MSE 5.350788364746602 Test RE 1.1056481594469718\n",
      "8 Train Loss 126.52702 Test MSE 5.377076701950418 Test RE 1.1083608474962339\n",
      "9 Train Loss 114.5576 Test MSE 5.412594048201664 Test RE 1.1120153651462354\n",
      "10 Train Loss 106.98074 Test MSE 5.431353041308599 Test RE 1.1139407123288165\n",
      "11 Train Loss 100.79668 Test MSE 5.463438479818166 Test RE 1.1172261410570528\n",
      "12 Train Loss 97.5981 Test MSE 5.497553043955236 Test RE 1.1207087803389666\n",
      "13 Train Loss 92.54479 Test MSE 5.553027062972618 Test RE 1.126348941621738\n",
      "14 Train Loss 87.98364 Test MSE 5.627064809583384 Test RE 1.1338328066995012\n",
      "15 Train Loss 84.53425 Test MSE 5.735055090196858 Test RE 1.144660924011934\n",
      "16 Train Loss 81.0274 Test MSE 5.853044960947812 Test RE 1.1563757892758233\n",
      "17 Train Loss 78.211266 Test MSE 5.889592631759616 Test RE 1.1599805003770671\n",
      "18 Train Loss 76.02506 Test MSE 5.9300748202525115 Test RE 1.163960243611161\n",
      "19 Train Loss 73.38785 Test MSE 6.000486825171404 Test RE 1.1708501166550298\n",
      "20 Train Loss 71.693924 Test MSE 5.997947185673973 Test RE 1.1706023157695158\n",
      "21 Train Loss 70.61559 Test MSE 6.01087683333079 Test RE 1.1718633578389788\n",
      "22 Train Loss 69.1951 Test MSE 6.046656510264011 Test RE 1.1753459347753032\n",
      "23 Train Loss 67.87003 Test MSE 6.073271633558755 Test RE 1.1779298114657666\n",
      "24 Train Loss 66.521164 Test MSE 6.097649483148674 Test RE 1.1802915235380036\n",
      "25 Train Loss 65.491516 Test MSE 6.14010613859021 Test RE 1.184393456958117\n",
      "26 Train Loss 64.32807 Test MSE 6.214361155937308 Test RE 1.191533631289156\n",
      "27 Train Loss 63.052002 Test MSE 6.275194533280352 Test RE 1.1973514848319404\n",
      "28 Train Loss 62.22715 Test MSE 6.310891313469758 Test RE 1.2007522543501477\n",
      "29 Train Loss 61.24857 Test MSE 6.38306932706704 Test RE 1.2075992676211889\n",
      "30 Train Loss 60.430656 Test MSE 6.4559843347700365 Test RE 1.2144769993585547\n",
      "31 Train Loss 59.735085 Test MSE 6.533627130002675 Test RE 1.221758117597345\n",
      "32 Train Loss 58.9637 Test MSE 6.596199829013025 Test RE 1.2275945798681294\n",
      "33 Train Loss 58.419228 Test MSE 6.642993638076579 Test RE 1.2319411968753367\n",
      "34 Train Loss 57.77317 Test MSE 6.697820526143811 Test RE 1.2370145653792608\n",
      "35 Train Loss 57.287724 Test MSE 6.721012233789586 Test RE 1.239154342709703\n",
      "36 Train Loss 56.78263 Test MSE 6.779337905117071 Test RE 1.2445194857572501\n",
      "37 Train Loss 56.289967 Test MSE 6.8265658505743305 Test RE 1.2488469059998675\n",
      "38 Train Loss 55.242256 Test MSE 6.957421303876777 Test RE 1.260759390579797\n",
      "39 Train Loss 54.6371 Test MSE 7.115252371494353 Test RE 1.274979537286102\n",
      "40 Train Loss 54.015236 Test MSE 7.2236956805163395 Test RE 1.2846587555447593\n",
      "41 Train Loss 52.849815 Test MSE 7.428075906690609 Test RE 1.302705440296334\n",
      "42 Train Loss 51.814266 Test MSE 7.653755872028235 Test RE 1.322346783265991\n",
      "43 Train Loss 50.98565 Test MSE 7.807266568760646 Test RE 1.3355420432641345\n",
      "44 Train Loss 50.169987 Test MSE 7.917355131492344 Test RE 1.3449251751812081\n",
      "45 Train Loss 49.485016 Test MSE 7.992080497353494 Test RE 1.3512570879508363\n",
      "46 Train Loss 48.59785 Test MSE 8.021921776624243 Test RE 1.353777437311346\n",
      "47 Train Loss 48.11794 Test MSE 8.043629004816465 Test RE 1.3556078529752764\n",
      "48 Train Loss 47.464893 Test MSE 8.131730609902585 Test RE 1.3630115991498937\n",
      "49 Train Loss 46.807167 Test MSE 8.22456159827808 Test RE 1.370769520193183\n",
      "50 Train Loss 46.378178 Test MSE 8.276513276711421 Test RE 1.375092040738703\n",
      "51 Train Loss 46.033264 Test MSE 8.315964539731448 Test RE 1.3783654375730487\n",
      "52 Train Loss 45.678486 Test MSE 8.337667327067297 Test RE 1.3801628766920817\n",
      "53 Train Loss 45.333576 Test MSE 8.35986435574985 Test RE 1.3819988309787161\n",
      "54 Train Loss 44.92685 Test MSE 8.372588306397256 Test RE 1.3830501518039149\n",
      "55 Train Loss 44.27111 Test MSE 8.418908967802269 Test RE 1.3868706809386753\n",
      "56 Train Loss 43.823402 Test MSE 8.442946846780417 Test RE 1.3888491835665426\n",
      "57 Train Loss 43.4232 Test MSE 8.53223168386912 Test RE 1.3961734662813292\n",
      "58 Train Loss 43.1554 Test MSE 8.588219930708886 Test RE 1.4007468001066092\n",
      "59 Train Loss 42.755806 Test MSE 8.626962221757102 Test RE 1.403902697143522\n",
      "60 Train Loss 42.37166 Test MSE 8.681885542753061 Test RE 1.4083645610484863\n",
      "61 Train Loss 42.103573 Test MSE 8.682056033902546 Test RE 1.408378389410594\n",
      "62 Train Loss 41.76819 Test MSE 8.680197901931175 Test RE 1.408227670909246\n",
      "63 Train Loss 41.38443 Test MSE 8.746942180404783 Test RE 1.4136314158288146\n",
      "64 Train Loss 40.95331 Test MSE 8.723881245625625 Test RE 1.4117666969087348\n",
      "65 Train Loss 40.516228 Test MSE 8.666317956298219 Test RE 1.4071013173558848\n",
      "66 Train Loss 40.320145 Test MSE 8.720214254147654 Test RE 1.4114699551012362\n",
      "67 Train Loss 39.916878 Test MSE 8.724185093805 Test RE 1.4117912822391292\n",
      "68 Train Loss 39.586178 Test MSE 8.686757733129197 Test RE 1.4087596859208342\n",
      "69 Train Loss 39.052975 Test MSE 8.678761148656543 Test RE 1.4081111206029657\n",
      "70 Train Loss 38.82627 Test MSE 8.673087312330836 Test RE 1.4076507612207194\n",
      "71 Train Loss 38.586853 Test MSE 8.64667083357399 Test RE 1.405505415916643\n",
      "72 Train Loss 38.191925 Test MSE 8.599259509961923 Test RE 1.401646793892108\n",
      "73 Train Loss 37.950195 Test MSE 8.549489382977296 Test RE 1.3975847365672733\n",
      "74 Train Loss 37.7497 Test MSE 8.542370326547113 Test RE 1.3970027394311604\n",
      "75 Train Loss 37.481964 Test MSE 8.551057583276307 Test RE 1.3977129075146457\n",
      "76 Train Loss 37.213818 Test MSE 8.533681432235252 Test RE 1.396292076177484\n",
      "77 Train Loss 36.9824 Test MSE 8.531197241230952 Test RE 1.396088828100176\n",
      "78 Train Loss 36.65494 Test MSE 8.595348650168875 Test RE 1.4013280299639266\n",
      "79 Train Loss 36.0141 Test MSE 8.701309709050772 Test RE 1.4099391627400497\n",
      "80 Train Loss 35.75418 Test MSE 8.727525790108166 Test RE 1.4120615604628943\n",
      "81 Train Loss 35.529713 Test MSE 8.793921604899225 Test RE 1.4174226067540128\n",
      "82 Train Loss 35.23986 Test MSE 8.808419922975212 Test RE 1.4185905601160556\n",
      "83 Train Loss 35.03364 Test MSE 8.801142290414104 Test RE 1.4180044099168647\n",
      "84 Train Loss 34.680237 Test MSE 8.78637260625647 Test RE 1.4168140944691758\n",
      "85 Train Loss 34.358917 Test MSE 8.75198625392385 Test RE 1.4140389544271077\n",
      "86 Train Loss 34.11109 Test MSE 8.688694599348858 Test RE 1.4089167311068418\n",
      "87 Train Loss 33.978363 Test MSE 8.658356110335246 Test RE 1.4064548087525803\n",
      "88 Train Loss 33.689667 Test MSE 8.619439473055706 Test RE 1.4032904590068893\n",
      "89 Train Loss 33.52247 Test MSE 8.621880228878412 Test RE 1.403489128939792\n",
      "90 Train Loss 33.31472 Test MSE 8.65171335661795 Test RE 1.4059151840576127\n",
      "91 Train Loss 33.176624 Test MSE 8.669084746576763 Test RE 1.407325913521463\n",
      "92 Train Loss 32.975365 Test MSE 8.678527288081034 Test RE 1.4080921487768145\n",
      "93 Train Loss 32.77529 Test MSE 8.683342542696096 Test RE 1.4084827324405689\n",
      "94 Train Loss 32.656242 Test MSE 8.675318684100036 Test RE 1.4078318265125456\n",
      "95 Train Loss 32.508087 Test MSE 8.683243244170994 Test RE 1.4084746790523077\n",
      "96 Train Loss 32.30713 Test MSE 8.656894881247378 Test RE 1.4063361234404959\n",
      "97 Train Loss 32.09495 Test MSE 8.619531772787015 Test RE 1.4032979724296577\n",
      "98 Train Loss 31.942287 Test MSE 8.647788186280122 Test RE 1.4055962251181768\n",
      "99 Train Loss 31.751358 Test MSE 8.63654806289873 Test RE 1.4046824531929907\n",
      "Training time: 71.99\n",
      "KG_stan_tune11\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.90\n",
      "KG_stan_tune12\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 1241028.8 Test MSE 5.0867328639125855 Test RE 1.0780217560583976\n",
      "1 Train Loss 966807.94 Test MSE 5.091188247866139 Test RE 1.0784937633079794\n",
      "2 Train Loss 777451.0 Test MSE 5.085902619343223 Test RE 1.0779337763810306\n",
      "3 Train Loss 644794.75 Test MSE 5.076732841218818 Test RE 1.0769615917294482\n",
      "4 Train Loss 565700.2 Test MSE 5.088141315630798 Test RE 1.0781709909943948\n",
      "5 Train Loss 512811.28 Test MSE 5.098589768801869 Test RE 1.0792774305648334\n",
      "6 Train Loss 476634.4 Test MSE 5.1031550869175994 Test RE 1.0797605192765116\n",
      "7 Train Loss 443899.8 Test MSE 5.099200067109654 Test RE 1.0793420230805693\n",
      "8 Train Loss 414246.22 Test MSE 5.082124605916933 Test RE 1.077533335676559\n",
      "9 Train Loss 396627.8 Test MSE 5.076868918217936 Test RE 1.0769760250987168\n",
      "10 Train Loss 385672.3 Test MSE 5.078561144987697 Test RE 1.0771554994801111\n",
      "11 Train Loss 374626.44 Test MSE 5.07943078203268 Test RE 1.0772477199143422\n",
      "12 Train Loss 360548.94 Test MSE 5.077360503085472 Test RE 1.077028164745214\n",
      "13 Train Loss 350148.7 Test MSE 5.07477161493907 Test RE 1.0767535475529464\n",
      "14 Train Loss 341623.06 Test MSE 5.0716735802002715 Test RE 1.0764248303795503\n",
      "15 Train Loss 333711.56 Test MSE 5.072770199766549 Test RE 1.0765411987448927\n",
      "16 Train Loss 327537.56 Test MSE 5.077219401018885 Test RE 1.0770131990996217\n",
      "17 Train Loss 316756.0 Test MSE 5.079835893097593 Test RE 1.0772906771165047\n",
      "18 Train Loss 305797.16 Test MSE 5.078358625540721 Test RE 1.077134022224582\n",
      "19 Train Loss 293065.0 Test MSE 5.076862330314263 Test RE 1.0769753263396262\n",
      "20 Train Loss 285080.9 Test MSE 5.071438476335309 Test RE 1.0763998805708825\n",
      "21 Train Loss 279081.47 Test MSE 5.0640575514127715 Test RE 1.0756163041206697\n",
      "22 Train Loss 272227.84 Test MSE 5.059409816930095 Test RE 1.0751225966035136\n",
      "23 Train Loss 267267.75 Test MSE 5.058258091404778 Test RE 1.0750002190279806\n",
      "24 Train Loss 262652.84 Test MSE 5.055107401538212 Test RE 1.0746653685891\n",
      "25 Train Loss 259089.3 Test MSE 5.0540064299876235 Test RE 1.0745483344360762\n",
      "26 Train Loss 254463.25 Test MSE 5.052819395816859 Test RE 1.0744221374759777\n",
      "27 Train Loss 248807.48 Test MSE 5.05295963079161 Test RE 1.0744370470248956\n",
      "28 Train Loss 244695.55 Test MSE 5.053271454181618 Test RE 1.0744701988268253\n",
      "29 Train Loss 241099.28 Test MSE 5.053345096896495 Test RE 1.074478028073179\n",
      "30 Train Loss 235189.36 Test MSE 5.053207734060697 Test RE 1.0744634244443834\n",
      "31 Train Loss 231215.12 Test MSE 5.0543252463735895 Test RE 1.0745822261830238\n",
      "32 Train Loss 225698.25 Test MSE 5.059360041047245 Test RE 1.0751173079127394\n",
      "33 Train Loss 222012.48 Test MSE 5.061226587048996 Test RE 1.0753156107457662\n",
      "34 Train Loss 219083.75 Test MSE 5.062913464172582 Test RE 1.0754947940085318\n",
      "35 Train Loss 216507.34 Test MSE 5.064980529419785 Test RE 1.0757143208741342\n",
      "36 Train Loss 212932.23 Test MSE 5.067990105011145 Test RE 1.0760338643324845\n",
      "37 Train Loss 209147.38 Test MSE 5.063887851720323 Test RE 1.075598281686746\n",
      "38 Train Loss 206467.8 Test MSE 5.061876260847969 Test RE 1.0753846238544102\n",
      "39 Train Loss 204119.02 Test MSE 5.061257046969826 Test RE 1.0753188465205856\n",
      "40 Train Loss 201936.98 Test MSE 5.06057972272267 Test RE 1.0752468916790707\n",
      "41 Train Loss 199098.2 Test MSE 5.06183386184777 Test RE 1.0753801200572006\n",
      "42 Train Loss 196038.64 Test MSE 5.060921179216367 Test RE 1.0752831665586855\n",
      "43 Train Loss 192147.56 Test MSE 5.057481547951652 Test RE 1.0749176988788915\n",
      "44 Train Loss 189758.1 Test MSE 5.055839114047228 Test RE 1.0747431431621661\n",
      "45 Train Loss 187005.81 Test MSE 5.0520733888777425 Test RE 1.0743428197828075\n",
      "46 Train Loss 184400.05 Test MSE 5.047340667876755 Test RE 1.0738394862223355\n",
      "47 Train Loss 181564.84 Test MSE 5.045157291392862 Test RE 1.0736072005845199\n",
      "48 Train Loss 178452.98 Test MSE 5.044982847906397 Test RE 1.073588639676378\n",
      "49 Train Loss 175529.55 Test MSE 5.044181444800243 Test RE 1.073503365705457\n",
      "50 Train Loss 173147.67 Test MSE 5.04383328169652 Test RE 1.0734663170071346\n",
      "51 Train Loss 170558.19 Test MSE 5.041666924959065 Test RE 1.0732357621278132\n",
      "52 Train Loss 168596.53 Test MSE 5.042658020086249 Test RE 1.0733412457387315\n",
      "53 Train Loss 166212.3 Test MSE 5.041908895680506 Test RE 1.0732615163594643\n",
      "54 Train Loss 164126.1 Test MSE 5.039764776572424 Test RE 1.0730332848228947\n",
      "55 Train Loss 161768.2 Test MSE 5.041435278847888 Test RE 1.0732111062203393\n",
      "56 Train Loss 159604.92 Test MSE 5.039998572114344 Test RE 1.0730581736321978\n",
      "57 Train Loss 158213.08 Test MSE 5.03566784146787 Test RE 1.0725970500259954\n",
      "58 Train Loss 156098.14 Test MSE 5.032621733204479 Test RE 1.0722725904821526\n",
      "59 Train Loss 154589.58 Test MSE 5.03357449391953 Test RE 1.0723740853794748\n",
      "60 Train Loss 153056.69 Test MSE 5.033278269508803 Test RE 1.0723425304620258\n",
      "61 Train Loss 151774.03 Test MSE 5.03249414570587 Test RE 1.072258998218318\n",
      "62 Train Loss 150409.67 Test MSE 5.031906499143522 Test RE 1.0721963923124178\n",
      "63 Train Loss 149230.83 Test MSE 5.032072680574449 Test RE 1.0722140970988288\n",
      "64 Train Loss 147537.75 Test MSE 5.032629444728117 Test RE 1.0722734120074624\n",
      "65 Train Loss 145740.95 Test MSE 5.032181046597896 Test RE 1.0722256421380028\n",
      "66 Train Loss 144568.83 Test MSE 5.032854517707595 Test RE 1.0722973892420296\n",
      "67 Train Loss 143019.42 Test MSE 5.0341661914180875 Test RE 1.0724371124011947\n",
      "68 Train Loss 141107.34 Test MSE 5.035255553243846 Test RE 1.0725531404395552\n",
      "69 Train Loss 139814.55 Test MSE 5.0345268369893015 Test RE 1.0724755261874641\n",
      "70 Train Loss 138453.14 Test MSE 5.034045173673479 Test RE 1.0724242220142248\n",
      "71 Train Loss 137171.17 Test MSE 5.035206140993083 Test RE 1.0725478778074813\n",
      "72 Train Loss 136328.67 Test MSE 5.034960925126034 Test RE 1.0725217608072402\n",
      "73 Train Loss 135439.44 Test MSE 5.035083510797096 Test RE 1.0725348170157674\n",
      "74 Train Loss 134558.23 Test MSE 5.037057820964334 Test RE 1.0727450726008914\n",
      "75 Train Loss 133552.23 Test MSE 5.038328505068608 Test RE 1.0728803732271084\n",
      "76 Train Loss 132500.88 Test MSE 5.040003849988886 Test RE 1.0730587354840366\n",
      "77 Train Loss 131290.6 Test MSE 5.042783563319097 Test RE 1.0733546067371094\n",
      "78 Train Loss 130504.266 Test MSE 5.044775406694845 Test RE 1.0735665673696713\n",
      "79 Train Loss 129438.54 Test MSE 5.0465194727038725 Test RE 1.0737521265876606\n",
      "80 Train Loss 128728.46 Test MSE 5.046856955800099 Test RE 1.0737880292663333\n",
      "81 Train Loss 127942.95 Test MSE 5.04901527271301 Test RE 1.0740176104845762\n",
      "82 Train Loss 126705.12 Test MSE 5.052698622214723 Test RE 1.074409296861956\n",
      "83 Train Loss 125791.55 Test MSE 5.054928246104648 Test RE 1.0746463250920342\n",
      "84 Train Loss 124923.47 Test MSE 5.057529795816214 Test RE 1.0749228261699524\n",
      "85 Train Loss 123859.64 Test MSE 5.060571927794555 Test RE 1.0752460635649104\n",
      "86 Train Loss 122475.055 Test MSE 5.064389180054259 Test RE 1.0756515228489723\n",
      "87 Train Loss 121496.14 Test MSE 5.066164246708646 Test RE 1.0758400140770834\n",
      "88 Train Loss 120245.14 Test MSE 5.068990572210554 Test RE 1.076140068512064\n",
      "89 Train Loss 119108.4 Test MSE 5.070739916395872 Test RE 1.0763257442351943\n",
      "90 Train Loss 118459.016 Test MSE 5.072575510517709 Test RE 1.0765205401106452\n",
      "91 Train Loss 117845.76 Test MSE 5.074703406288614 Test RE 1.0767463113501468\n",
      "92 Train Loss 116858.8 Test MSE 5.074912760715067 Test RE 1.0767685214443665\n",
      "93 Train Loss 115508.28 Test MSE 5.078416007537253 Test RE 1.0771401076481104\n",
      "94 Train Loss 114836.51 Test MSE 5.080127175566404 Test RE 1.077321563093577\n",
      "95 Train Loss 114269.22 Test MSE 5.081630242738861 Test RE 1.0774809259266365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 113746.766 Test MSE 5.084234178381703 Test RE 1.0777569526662447\n",
      "97 Train Loss 113183.83 Test MSE 5.084069475957269 Test RE 1.077739495698839\n",
      "98 Train Loss 112379.19 Test MSE 5.086229830612023 Test RE 1.0779684512885281\n",
      "99 Train Loss 111558.55 Test MSE 5.090067402601114 Test RE 1.0783750394356417\n",
      "Training time: 72.12\n",
      "KG_stan_tune12\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.93\n",
      "KG_stan_tune13\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 5606668000.0 Test MSE 6.195865331590752 Test RE 1.1897591271300512\n",
      "1 Train Loss 4420389000.0 Test MSE 6.195448082923926 Test RE 1.1897190654323657\n",
      "2 Train Loss 2831641600.0 Test MSE 6.19457813687 Test RE 1.1896355341261922\n",
      "3 Train Loss 2195588900.0 Test MSE 6.194983379819858 Test RE 1.1896744458582127\n",
      "4 Train Loss 1913471000.0 Test MSE 6.194913838288206 Test RE 1.1896677685186423\n",
      "5 Train Loss 1774914700.0 Test MSE 6.1945591107709115 Test RE 1.1896337071946055\n",
      "6 Train Loss 1687027500.0 Test MSE 6.194474032806507 Test RE 1.1896255377704457\n",
      "7 Train Loss 1588887600.0 Test MSE 6.194374184005808 Test RE 1.189615949937704\n",
      "8 Train Loss 1563489300.0 Test MSE 6.194392907532478 Test RE 1.1896177478424215\n",
      "9 Train Loss 1516625000.0 Test MSE 6.194506561858139 Test RE 1.1896286613076121\n",
      "10 Train Loss 1458279200.0 Test MSE 6.194558812122888 Test RE 1.1896336785176844\n",
      "11 Train Loss 1421519400.0 Test MSE 6.194680900442975 Test RE 1.1896454016820057\n",
      "12 Train Loss 1403849000.0 Test MSE 6.19474300333402 Test RE 1.1896513648813039\n",
      "13 Train Loss 1387159400.0 Test MSE 6.19478112732025 Test RE 1.189655025580582\n",
      "14 Train Loss 1365037600.0 Test MSE 6.1948243235095415 Test RE 1.1896591733037243\n",
      "15 Train Loss 1345641300.0 Test MSE 6.19483081503113 Test RE 1.1896597966221416\n",
      "16 Train Loss 1337069200.0 Test MSE 6.194851953208427 Test RE 1.1896618263158494\n",
      "17 Train Loss 1323027700.0 Test MSE 6.194905714602798 Test RE 1.1896669884843993\n",
      "18 Train Loss 1300697200.0 Test MSE 6.194962891914839 Test RE 1.1896724786247503\n",
      "19 Train Loss 1279945700.0 Test MSE 6.195076592354598 Test RE 1.189683396015677\n",
      "20 Train Loss 1270842500.0 Test MSE 6.195117185230946 Test RE 1.1896872936746619\n",
      "21 Train Loss 1263203600.0 Test MSE 6.195190212429847 Test RE 1.1896943055900135\n",
      "22 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "23 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "24 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "25 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "26 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "27 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "28 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "29 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "30 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "31 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "32 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "33 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "34 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "35 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "36 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "37 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "38 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "39 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "40 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "41 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "42 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "43 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "44 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "45 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "46 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "47 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "48 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "49 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "50 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "51 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "52 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "53 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "54 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "55 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "56 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "57 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "58 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "59 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "60 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "61 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "62 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "63 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "64 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "65 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "66 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "67 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "68 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "69 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "70 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "71 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "72 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "73 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "74 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "75 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "76 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "77 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "78 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "80 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "81 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "82 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "83 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "84 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "85 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "86 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "87 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "88 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "89 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "90 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "91 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "92 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "93 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "94 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "95 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "96 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "97 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "98 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "99 Train Loss 1261389400.0 Test MSE 6.195214138811786 Test RE 1.1896966029410139\n",
      "Training time: 32.82\n",
      "KG_stan_tune13\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.93\n",
      "KG_stan_tune14\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 279504400000.0 Test MSE 6.586173898209397 Test RE 1.2266612804678232\n",
      "1 Train Loss 152382100000.0 Test MSE 6.5850185432587365 Test RE 1.2265536845127543\n",
      "2 Train Loss 132235970000.0 Test MSE 6.585005280785893 Test RE 1.2265524493497084\n",
      "3 Train Loss 113202370000.0 Test MSE 6.584280728732915 Test RE 1.226484968345154\n",
      "4 Train Loss 108346474000.0 Test MSE 6.584024861415422 Test RE 1.22646113730874\n",
      "5 Train Loss 104648740000.0 Test MSE 6.583949893290297 Test RE 1.2264541548203935\n",
      "6 Train Loss 101312940000.0 Test MSE 6.583635361300916 Test RE 1.226424859057308\n",
      "7 Train Loss 98623900000.0 Test MSE 6.583469755489988 Test RE 1.2264094341173302\n",
      "8 Train Loss 92272615000.0 Test MSE 6.5830962769661525 Test RE 1.2263746466801313\n",
      "9 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "10 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "11 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "12 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "13 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "14 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "15 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "16 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "17 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "18 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "19 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "20 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "21 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "22 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "23 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "24 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "25 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "26 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "27 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "28 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "29 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "30 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "31 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "32 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "33 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "34 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "35 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "36 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "37 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "38 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "39 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "40 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "41 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "42 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "43 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "44 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "45 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "46 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "47 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "48 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "49 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "50 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "51 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "52 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "53 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "54 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "55 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "56 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "57 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "58 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "59 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "60 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "62 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "63 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "64 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "65 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "66 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "67 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "68 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "69 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "70 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "71 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "72 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "73 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "74 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "75 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "76 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "77 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "78 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "79 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "80 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "81 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "82 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "83 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "84 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "85 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "86 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "87 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "88 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "89 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "90 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "91 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "92 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "93 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "94 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "95 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "96 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "97 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "98 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "99 Train Loss 90073530000.0 Test MSE 6.582819369288891 Test RE 1.2263488536405212\n",
      "Training time: 21.73\n",
      "KG_stan_tune14\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.93\n",
      "KG_stan_tune15\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.619946 Test MSE 8.657548545222333 Test RE 1.406389217183735\n",
      "1 Train Loss 56.89107 Test MSE 8.152874852409827 Test RE 1.36478250986043\n",
      "2 Train Loss 49.710155 Test MSE 7.2615887123404645 Test RE 1.288023788140608\n",
      "3 Train Loss 44.029606 Test MSE 8.438868953618467 Test RE 1.3885137401055485\n",
      "4 Train Loss 38.426155 Test MSE 7.84861353560282 Test RE 1.3390738615722573\n",
      "5 Train Loss 36.176777 Test MSE 7.447748689736739 Test RE 1.3044293655651689\n",
      "6 Train Loss 32.891193 Test MSE 6.764069069669145 Test RE 1.2431172046539682\n",
      "7 Train Loss 29.778217 Test MSE 6.425459601469865 Test RE 1.211602494999478\n",
      "8 Train Loss 27.787613 Test MSE 6.663684582403406 Test RE 1.2338582699977123\n",
      "9 Train Loss 25.550426 Test MSE 6.1132987987430925 Test RE 1.1818051328976582\n",
      "10 Train Loss 23.730152 Test MSE 5.712311936991563 Test RE 1.1423890138718003\n",
      "11 Train Loss 21.749195 Test MSE 5.2022443096650495 Test RE 1.0901931080631928\n",
      "12 Train Loss 20.294895 Test MSE 4.67218505654204 Test RE 1.0331611768443918\n",
      "13 Train Loss 18.58051 Test MSE 3.975045762352785 Test RE 0.9529697754027274\n",
      "14 Train Loss 17.263279 Test MSE 3.558448694717026 Test RE 0.9016508876621999\n",
      "15 Train Loss 15.231667 Test MSE 3.7634403479012186 Test RE 0.9272579779811759\n",
      "16 Train Loss 13.832129 Test MSE 3.638672470498826 Test RE 0.9117579163672024\n",
      "17 Train Loss 13.110428 Test MSE 3.724212770724952 Test RE 0.9224127615685442\n",
      "18 Train Loss 12.442211 Test MSE 3.719575389690786 Test RE 0.9218382895730813\n",
      "19 Train Loss 11.741823 Test MSE 3.8195027715236156 Test RE 0.9341389374447902\n",
      "20 Train Loss 11.347406 Test MSE 3.7705032213635934 Test RE 0.9281276657339581\n",
      "21 Train Loss 10.987028 Test MSE 3.779305434286727 Test RE 0.9292103879140668\n",
      "22 Train Loss 10.55604 Test MSE 3.752689319080343 Test RE 0.9259325807234716\n",
      "23 Train Loss 9.927457 Test MSE 3.913892000340267 Test RE 0.9456109205222405\n",
      "24 Train Loss 9.609166 Test MSE 3.9995403157215277 Test RE 0.955901404506494\n",
      "25 Train Loss 9.092907 Test MSE 3.9510793960854107 Test RE 0.9500926069613654\n",
      "26 Train Loss 8.880024 Test MSE 3.9616312266094704 Test RE 0.9513604290808874\n",
      "27 Train Loss 8.636814 Test MSE 3.947692458508396 Test RE 0.9496853012688111\n",
      "28 Train Loss 8.555169 Test MSE 3.924813899931701 Test RE 0.9469293872123344\n",
      "29 Train Loss 8.445242 Test MSE 3.9254652635696248 Test RE 0.94700796033675\n",
      "30 Train Loss 8.365309 Test MSE 3.8872293902769095 Test RE 0.9423845232643785\n",
      "31 Train Loss 8.314552 Test MSE 3.854251451341117 Test RE 0.9383785731625628\n",
      "32 Train Loss 8.195628 Test MSE 3.8328374468787536 Test RE 0.9357681529665719\n",
      "33 Train Loss 8.0706005 Test MSE 3.8507983586634067 Test RE 0.9379581239120919\n",
      "34 Train Loss 7.9063315 Test MSE 3.846853636600533 Test RE 0.9374775830211228\n",
      "35 Train Loss 7.492069 Test MSE 3.7341869204132125 Test RE 0.9236471340027628\n",
      "36 Train Loss 6.5539246 Test MSE 3.4416271390113176 Test RE 0.8867270747358019\n",
      "37 Train Loss 5.9696074 Test MSE 3.400642199208052 Test RE 0.8814314252848656\n",
      "38 Train Loss 5.5834603 Test MSE 3.25551134268395 Test RE 0.8624177107887397\n",
      "39 Train Loss 5.2836657 Test MSE 3.2944236054254827 Test RE 0.8675565256425308\n",
      "40 Train Loss 5.043393 Test MSE 3.0730117657047695 Test RE 0.8378961054224722\n",
      "41 Train Loss 4.90557 Test MSE 2.8904717614540654 Test RE 0.8126292038446891\n",
      "42 Train Loss 4.7381577 Test MSE 2.6043538941691353 Test RE 0.7713616789258032\n",
      "43 Train Loss 4.63859 Test MSE 2.3997078405891163 Test RE 0.7404355218210984\n",
      "44 Train Loss 4.447911 Test MSE 1.972396610214503 Test RE 0.671282281325325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 4.3014636 Test MSE 1.8372194682740803 Test RE 0.6478710584698074\n",
      "46 Train Loss 4.197842 Test MSE 1.7290286653527867 Test RE 0.6285056078008537\n",
      "47 Train Loss 4.0532036 Test MSE 1.649067802808965 Test RE 0.6138006110960614\n",
      "48 Train Loss 3.9324844 Test MSE 1.6899299234352574 Test RE 0.6213587354485552\n",
      "49 Train Loss 3.873937 Test MSE 1.6559371866323955 Test RE 0.6150777114353767\n",
      "50 Train Loss 3.7877603 Test MSE 1.6495208151139782 Test RE 0.6138849133107791\n",
      "51 Train Loss 3.745811 Test MSE 1.6098949569063234 Test RE 0.6064665194672288\n",
      "52 Train Loss 3.6981592 Test MSE 1.610680782781076 Test RE 0.6066145163717228\n",
      "53 Train Loss 3.671413 Test MSE 1.5954094182875471 Test RE 0.6037319171258315\n",
      "54 Train Loss 3.6183496 Test MSE 1.5703199393719174 Test RE 0.5989659480288494\n",
      "55 Train Loss 3.5423748 Test MSE 1.5097894228610953 Test RE 0.5873084502161978\n",
      "56 Train Loss 3.440207 Test MSE 1.2533296089518617 Test RE 0.5351070959573745\n",
      "57 Train Loss 1.9395273 Test MSE 0.37496225830510327 Test RE 0.2926859251716966\n",
      "58 Train Loss 0.8090448 Test MSE 0.07040446304164047 Test RE 0.12682595918371578\n",
      "59 Train Loss 0.52814513 Test MSE 0.043880412715770714 Test RE 0.10012520357713206\n",
      "60 Train Loss 0.34864601 Test MSE 0.02088313059053424 Test RE 0.06907260931997411\n",
      "61 Train Loss 0.26190442 Test MSE 0.023763910023558037 Test RE 0.07368295081991791\n",
      "62 Train Loss 0.1843574 Test MSE 0.01608544176850481 Test RE 0.06062120386436833\n",
      "63 Train Loss 0.13675886 Test MSE 0.01573976696181557 Test RE 0.05996629394925644\n",
      "64 Train Loss 0.10322747 Test MSE 0.012026927885274985 Test RE 0.052418599533618805\n",
      "65 Train Loss 0.08888793 Test MSE 0.010830868256902286 Test RE 0.049743884567688405\n",
      "66 Train Loss 0.07629894 Test MSE 0.007577654688738897 Test RE 0.041607868255393136\n",
      "67 Train Loss 0.069814496 Test MSE 0.006827286497643905 Test RE 0.0394940911518403\n",
      "68 Train Loss 0.059501752 Test MSE 0.005828398748314053 Test RE 0.036490741499271985\n",
      "69 Train Loss 0.052398022 Test MSE 0.005247378694570493 Test RE 0.034624161443564117\n",
      "70 Train Loss 0.048335224 Test MSE 0.0044972046429639844 Test RE 0.03205378986230357\n",
      "71 Train Loss 0.042974897 Test MSE 0.003986363707244837 Test RE 0.030178421528223483\n",
      "72 Train Loss 0.038596906 Test MSE 0.00411697895934076 Test RE 0.030668842415807075\n",
      "73 Train Loss 0.035924383 Test MSE 0.004325006546884148 Test RE 0.03143412999744845\n",
      "74 Train Loss 0.03321048 Test MSE 0.004241587191112992 Test RE 0.03112950821418297\n",
      "75 Train Loss 0.03015573 Test MSE 0.0036157122454652294 Test RE 0.02874120618909857\n",
      "76 Train Loss 0.027766824 Test MSE 0.003749510639869449 Test RE 0.0292681556140216\n",
      "77 Train Loss 0.024572756 Test MSE 0.003730772059989259 Test RE 0.02919492864272704\n",
      "78 Train Loss 0.02256696 Test MSE 0.0030857172277244387 Test RE 0.02655132036435659\n",
      "79 Train Loss 0.020409243 Test MSE 0.003383211631174309 Test RE 0.02780178259332074\n",
      "80 Train Loss 0.01925949 Test MSE 0.003112960808049529 Test RE 0.026668272660546354\n",
      "81 Train Loss 0.017830689 Test MSE 0.0032280521864084134 Test RE 0.02715678374033576\n",
      "82 Train Loss 0.015675394 Test MSE 0.002950202787991738 Test RE 0.02596175187007073\n",
      "83 Train Loss 0.014849592 Test MSE 0.0030372607795107025 Test RE 0.026342021587399136\n",
      "84 Train Loss 0.0142176505 Test MSE 0.002982268511200817 Test RE 0.026102459570344797\n",
      "85 Train Loss 0.013715617 Test MSE 0.0029343662092571497 Test RE 0.02589197724841768\n",
      "86 Train Loss 0.01310354 Test MSE 0.0023896818256226304 Test RE 0.023365662567616664\n",
      "87 Train Loss 0.012317197 Test MSE 0.002300722321144857 Test RE 0.02292662688830207\n",
      "88 Train Loss 0.011926458 Test MSE 0.0024023338505985772 Test RE 0.023427434952167918\n",
      "89 Train Loss 0.011219011 Test MSE 0.0020765789630395612 Test RE 0.021781224197356962\n",
      "90 Train Loss 0.010618355 Test MSE 0.0016575843765393795 Test RE 0.01946013651711638\n",
      "91 Train Loss 0.010308363 Test MSE 0.0016009234213523315 Test RE 0.019124643111702547\n",
      "92 Train Loss 0.009748354 Test MSE 0.0014996355680271655 Test RE 0.018509765915550192\n",
      "93 Train Loss 0.008402466 Test MSE 0.0013913756408192302 Test RE 0.017829134374163506\n",
      "94 Train Loss 0.008095328 Test MSE 0.0013058504377058632 Test RE 0.017272483232568286\n",
      "95 Train Loss 0.007619776 Test MSE 0.001315495703236937 Test RE 0.01733615483787361\n",
      "96 Train Loss 0.007389005 Test MSE 0.001327579337247861 Test RE 0.01741559443139092\n",
      "97 Train Loss 0.007199103 Test MSE 0.001219315364834854 Test RE 0.016690374576443796\n",
      "98 Train Loss 0.006842687 Test MSE 0.0013279040231067524 Test RE 0.01741772396571845\n",
      "99 Train Loss 0.0065376973 Test MSE 0.001355234387714887 Test RE 0.017596053215461788\n",
      "Training time: 71.80\n",
      "KG_stan_tune15\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.557762 Test MSE 8.671716021990884 Test RE 1.4075394759236495\n",
      "1 Train Loss 56.249702 Test MSE 8.396162647774926 Test RE 1.384995880932633\n",
      "2 Train Loss 47.54108 Test MSE 8.684740861542451 Test RE 1.4085961351225715\n",
      "3 Train Loss 44.960747 Test MSE 8.154110583441232 Test RE 1.3648859359664405\n",
      "4 Train Loss 44.333546 Test MSE 8.390312118348863 Test RE 1.3845132574090104\n",
      "5 Train Loss 43.95952 Test MSE 8.518079596352965 Test RE 1.3950150958867922\n",
      "6 Train Loss 43.71756 Test MSE 8.429790600994847 Test RE 1.3877666726129565\n",
      "7 Train Loss 42.914948 Test MSE 8.427705060503175 Test RE 1.3875949944089698\n",
      "8 Train Loss 42.05959 Test MSE 8.616025792130669 Test RE 1.4030125488085226\n",
      "9 Train Loss 41.681202 Test MSE 8.66414514883718 Test RE 1.4069249130331645\n",
      "10 Train Loss 41.16697 Test MSE 8.846188040668626 Test RE 1.4216285730089613\n",
      "11 Train Loss 40.596764 Test MSE 8.998990330841126 Test RE 1.4338540682121153\n",
      "12 Train Loss 39.879944 Test MSE 8.587154568764166 Test RE 1.400659916641254\n",
      "13 Train Loss 37.26283 Test MSE 7.734448931103617 Test RE 1.3292992153686793\n",
      "14 Train Loss 33.479477 Test MSE 7.921056431305203 Test RE 1.3452395092967124\n",
      "15 Train Loss 31.917727 Test MSE 8.027761326942283 Test RE 1.3542700881696215\n",
      "16 Train Loss 30.511906 Test MSE 7.687276411358783 Test RE 1.3252393076405193\n",
      "17 Train Loss 28.71479 Test MSE 7.954835116012608 Test RE 1.348104788721933\n",
      "18 Train Loss 27.11079 Test MSE 7.7456328491718445 Test RE 1.3302599433555315\n",
      "19 Train Loss 24.673077 Test MSE 6.792475718113008 Test RE 1.2457247915550653\n",
      "20 Train Loss 22.944622 Test MSE 6.248192065064467 Test RE 1.1947725766226884\n",
      "21 Train Loss 21.078514 Test MSE 5.72376324573146 Test RE 1.1435334979094307\n",
      "22 Train Loss 19.662457 Test MSE 5.610149464669211 Test RE 1.13212733423439\n",
      "23 Train Loss 19.008556 Test MSE 5.7146029197443875 Test RE 1.1426180744689827\n",
      "24 Train Loss 18.278805 Test MSE 5.546213800597893 Test RE 1.1256577450768523\n",
      "25 Train Loss 17.808544 Test MSE 5.529610873361515 Test RE 1.1239716199016456\n",
      "26 Train Loss 17.53629 Test MSE 5.5441304338264095 Test RE 1.1254463054984059\n",
      "27 Train Loss 17.113647 Test MSE 5.587600313819182 Test RE 1.129849835757352\n",
      "28 Train Loss 16.380737 Test MSE 5.613854595832561 Test RE 1.1325011199904589\n",
      "29 Train Loss 15.869791 Test MSE 5.596746788049233 Test RE 1.1307741965056228\n",
      "30 Train Loss 15.1651325 Test MSE 5.71298393198788 Test RE 1.1424562070795201\n",
      "31 Train Loss 14.06317 Test MSE 5.953049034585173 Test RE 1.1662127634357178\n",
      "32 Train Loss 13.681845 Test MSE 6.034278557457951 Test RE 1.1741423084805358\n",
      "33 Train Loss 13.212172 Test MSE 5.869463059531685 Test RE 1.1579965009438389\n",
      "34 Train Loss 13.000425 Test MSE 5.858370335580207 Test RE 1.1569017321168462\n",
      "35 Train Loss 12.766846 Test MSE 5.787825603257821 Test RE 1.1499151044721982\n",
      "36 Train Loss 12.533422 Test MSE 5.654041395926672 Test RE 1.1365473984282857\n",
      "37 Train Loss 12.412471 Test MSE 5.683529130878523 Test RE 1.13950728346451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 12.0757885 Test MSE 5.574545074347054 Test RE 1.1285291358671778\n",
      "39 Train Loss 11.437094 Test MSE 5.198642556876983 Test RE 1.089815647326004\n",
      "40 Train Loss 9.288274 Test MSE 4.471808474383109 Test RE 1.010763749052084\n",
      "41 Train Loss 8.594072 Test MSE 4.074029874047521 Test RE 0.9647619461355897\n",
      "42 Train Loss 8.245708 Test MSE 4.018155737901664 Test RE 0.9581233911854112\n",
      "43 Train Loss 8.012822 Test MSE 3.857541695695908 Test RE 0.9387790187744481\n",
      "44 Train Loss 7.7931485 Test MSE 3.6665904598741617 Test RE 0.9152489985062328\n",
      "45 Train Loss 7.697754 Test MSE 3.6237479954262346 Test RE 0.9098861499024606\n",
      "46 Train Loss 7.608903 Test MSE 3.610277989120484 Test RE 0.9081934848895947\n",
      "47 Train Loss 7.5170727 Test MSE 3.642282498503837 Test RE 0.9122100944147166\n",
      "48 Train Loss 7.447369 Test MSE 3.6961520071606286 Test RE 0.9189311469626817\n",
      "49 Train Loss 7.3599424 Test MSE 3.6973235439618546 Test RE 0.9190767681872448\n",
      "50 Train Loss 7.2215686 Test MSE 3.6628387466829753 Test RE 0.9147806300593871\n",
      "51 Train Loss 7.1005707 Test MSE 3.695618635727012 Test RE 0.9188648416124652\n",
      "52 Train Loss 7.021716 Test MSE 3.713269102150233 Test RE 0.9210565009482657\n",
      "53 Train Loss 6.9064627 Test MSE 3.586493980138026 Test RE 0.9051970155073069\n",
      "54 Train Loss 6.853223 Test MSE 3.503757298743769 Test RE 0.8946951188913317\n",
      "55 Train Loss 6.7929535 Test MSE 3.458527136166327 Test RE 0.8889015307107034\n",
      "56 Train Loss 6.7008886 Test MSE 3.474723861013609 Test RE 0.8909805192809664\n",
      "57 Train Loss 6.630125 Test MSE 3.4808242371300158 Test RE 0.8917622983474252\n",
      "58 Train Loss 6.5360394 Test MSE 3.4463742954822107 Test RE 0.8873384108054603\n",
      "59 Train Loss 6.418242 Test MSE 3.5568028687109603 Test RE 0.9014423512698295\n",
      "60 Train Loss 6.309312 Test MSE 3.442524265971265 Test RE 0.886842638522699\n",
      "61 Train Loss 5.9929056 Test MSE 3.229765107717749 Test RE 0.8590007232135757\n",
      "62 Train Loss 5.616353 Test MSE 3.0548418899149 Test RE 0.8354153079788772\n",
      "63 Train Loss 3.386938 Test MSE 2.4559551073526458 Test RE 0.7490628735544329\n",
      "64 Train Loss 2.684586 Test MSE 2.232124723865234 Test RE 0.7141135755313998\n",
      "65 Train Loss 2.2723541 Test MSE 2.257083600765805 Test RE 0.7180949671676845\n",
      "66 Train Loss 1.7296915 Test MSE 2.4170779113298817 Test RE 0.7431104781168607\n",
      "67 Train Loss 1.5419486 Test MSE 2.4475685406660537 Test RE 0.7477828342979941\n",
      "68 Train Loss 1.407475 Test MSE 2.436305138090245 Test RE 0.7460602489577874\n",
      "69 Train Loss 1.3010557 Test MSE 2.467537549848077 Test RE 0.7508271103201632\n",
      "70 Train Loss 1.2406234 Test MSE 2.4825462100980693 Test RE 0.7531070807492851\n",
      "71 Train Loss 1.1923774 Test MSE 2.4756787800024274 Test RE 0.7520647050000367\n",
      "72 Train Loss 1.1691239 Test MSE 2.4710469693877415 Test RE 0.7513608471039547\n",
      "73 Train Loss 1.1510386 Test MSE 2.467562284977393 Test RE 0.7508308735372877\n",
      "74 Train Loss 1.1323298 Test MSE 2.4415944996952494 Test RE 0.746869680183704\n",
      "75 Train Loss 1.1129966 Test MSE 2.473090654180962 Test RE 0.7516714902025651\n",
      "76 Train Loss 1.0970341 Test MSE 2.4870538748191025 Test RE 0.7537904949396833\n",
      "77 Train Loss 1.0706136 Test MSE 2.48706475904136 Test RE 0.7537921443640061\n",
      "78 Train Loss 1.0619798 Test MSE 2.5080576275445035 Test RE 0.7569667716155326\n",
      "79 Train Loss 1.042266 Test MSE 2.513769415466512 Test RE 0.7578282300567554\n",
      "80 Train Loss 1.0299008 Test MSE 2.5112922315540414 Test RE 0.7574547386366887\n",
      "81 Train Loss 1.0192182 Test MSE 2.522137094109978 Test RE 0.7590884878038948\n",
      "82 Train Loss 1.0040522 Test MSE 2.5021349965457667 Test RE 0.7560724770285517\n",
      "83 Train Loss 0.9932193 Test MSE 2.518029497429459 Test RE 0.7584701035150002\n",
      "84 Train Loss 0.9800762 Test MSE 2.5165079505252432 Test RE 0.7582409119530417\n",
      "85 Train Loss 0.9725784 Test MSE 2.5443547494610095 Test RE 0.7624245847145802\n",
      "86 Train Loss 0.9605113 Test MSE 2.54219925557424 Test RE 0.7621015657373127\n",
      "87 Train Loss 0.94907045 Test MSE 2.5463113431711895 Test RE 0.7627176783702025\n",
      "88 Train Loss 0.94158375 Test MSE 2.5496408790210414 Test RE 0.7632161771587688\n",
      "89 Train Loss 0.9305917 Test MSE 2.5287492252684873 Test RE 0.7600828642262049\n",
      "90 Train Loss 0.91884273 Test MSE 2.550144531094338 Test RE 0.7632915557016491\n",
      "91 Train Loss 0.90987825 Test MSE 2.5704196414261564 Test RE 0.7663198510758448\n",
      "92 Train Loss 0.90095246 Test MSE 2.5800126638139096 Test RE 0.7677485044363737\n",
      "93 Train Loss 0.89438605 Test MSE 2.5956643876961496 Test RE 0.7700737678150382\n",
      "94 Train Loss 0.88379174 Test MSE 2.6299174334520137 Test RE 0.7751381592260885\n",
      "95 Train Loss 0.8719385 Test MSE 2.6552088893159635 Test RE 0.7788564251724089\n",
      "96 Train Loss 0.86671215 Test MSE 2.6755434558535574 Test RE 0.7818331214080253\n",
      "97 Train Loss 0.8477452 Test MSE 2.6623768584126726 Test RE 0.7799070122013498\n",
      "98 Train Loss 0.84146327 Test MSE 2.6835833849964943 Test RE 0.7830069329831266\n",
      "99 Train Loss 0.8302042 Test MSE 2.6919034018078967 Test RE 0.7842197869053061\n",
      "Training time: 72.40\n",
      "KG_stan_tune15\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.849575 Test MSE 8.76358330694997 Test RE 1.4149754993140227\n",
      "1 Train Loss 52.698345 Test MSE 8.513345490323951 Test RE 1.3946273871810977\n",
      "2 Train Loss 44.652832 Test MSE 8.166622563110526 Test RE 1.365932701206161\n",
      "3 Train Loss 39.57036 Test MSE 7.228296008071812 Test RE 1.285067750519641\n",
      "4 Train Loss 37.94986 Test MSE 7.1237704496528975 Test RE 1.2757424847074537\n",
      "5 Train Loss 36.882187 Test MSE 7.432176555492225 Test RE 1.3030649681554105\n",
      "6 Train Loss 35.935467 Test MSE 7.4141962021056855 Test RE 1.3014877884323153\n",
      "7 Train Loss 34.38436 Test MSE 7.139774993487324 Test RE 1.2771747474211834\n",
      "8 Train Loss 33.01893 Test MSE 7.009901853709094 Test RE 1.265505476701732\n",
      "9 Train Loss 31.067226 Test MSE 6.9358469982083255 Test RE 1.258803125018315\n",
      "10 Train Loss 29.296104 Test MSE 6.289474371212689 Test RE 1.1987130576935632\n",
      "11 Train Loss 28.491028 Test MSE 6.212177797791823 Test RE 1.191324295756387\n",
      "12 Train Loss 27.378502 Test MSE 6.5716286993603665 Test RE 1.2253060251862857\n",
      "13 Train Loss 26.686129 Test MSE 6.37270531182793 Test RE 1.2066184963809325\n",
      "14 Train Loss 26.222511 Test MSE 6.411444186268483 Test RE 1.2102803808529887\n",
      "15 Train Loss 25.650599 Test MSE 6.369386126322274 Test RE 1.20630422543494\n",
      "16 Train Loss 25.467731 Test MSE 6.377549808236747 Test RE 1.2070770417072079\n",
      "17 Train Loss 25.174168 Test MSE 6.363899235968653 Test RE 1.2057845297413043\n",
      "18 Train Loss 24.923058 Test MSE 6.199470093760766 Test RE 1.1901051784754002\n",
      "19 Train Loss 24.768776 Test MSE 6.288775807417409 Test RE 1.1986464860894424\n",
      "20 Train Loss 24.386864 Test MSE 6.234327541457106 Test RE 1.1934462607943546\n",
      "21 Train Loss 24.046421 Test MSE 6.187145811130099 Test RE 1.1889216507665\n",
      "22 Train Loss 23.643703 Test MSE 6.101102364235255 Test RE 1.1806256547072007\n",
      "23 Train Loss 23.103542 Test MSE 6.111519558214249 Test RE 1.1816331415819241\n",
      "24 Train Loss 22.612167 Test MSE 6.270378092456632 Test RE 1.1968918911447128\n",
      "25 Train Loss 22.059246 Test MSE 6.045928785227892 Test RE 1.1752752052408915\n",
      "26 Train Loss 21.5984 Test MSE 6.244984493089276 Test RE 1.1944658630198\n",
      "27 Train Loss 21.156704 Test MSE 6.189106842936201 Test RE 1.1891100517293818\n",
      "28 Train Loss 20.66948 Test MSE 6.117932802194008 Test RE 1.1822529640781185\n",
      "29 Train Loss 20.395191 Test MSE 6.213982891389071 Test RE 1.191497366757828\n",
      "30 Train Loss 20.019814 Test MSE 6.187863484297277 Test RE 1.1889906027882309\n",
      "31 Train Loss 19.627594 Test MSE 6.092338676798777 Test RE 1.1797774184562908\n",
      "32 Train Loss 19.405897 Test MSE 6.046291582517658 Test RE 1.175310467007776\n",
      "33 Train Loss 19.017706 Test MSE 5.85461714051378 Test RE 1.1565310852226551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 18.614666 Test MSE 5.652062864748808 Test RE 1.136348523759486\n",
      "35 Train Loss 18.381563 Test MSE 5.705996835563977 Test RE 1.141757369664332\n",
      "36 Train Loss 17.886671 Test MSE 5.591122487124622 Test RE 1.1302058830563562\n",
      "37 Train Loss 17.588394 Test MSE 5.688502791260561 Test RE 1.1400057662495346\n",
      "38 Train Loss 17.303288 Test MSE 5.501373339432951 Test RE 1.1210981076549194\n",
      "39 Train Loss 16.971527 Test MSE 5.5300957157832915 Test RE 1.1240208943614378\n",
      "40 Train Loss 16.093641 Test MSE 5.0933044077781355 Test RE 1.0787178787844354\n",
      "41 Train Loss 15.644268 Test MSE 5.189364534320862 Test RE 1.0888427154976912\n",
      "42 Train Loss 14.988018 Test MSE 5.411239419552402 Test RE 1.111876202471056\n",
      "43 Train Loss 14.34842 Test MSE 5.654852983891001 Test RE 1.1366289661978106\n",
      "44 Train Loss 13.697935 Test MSE 5.4329655508989205 Test RE 1.1141060584927258\n",
      "45 Train Loss 13.325543 Test MSE 5.613990849867732 Test RE 1.1325148633915842\n",
      "46 Train Loss 12.70041 Test MSE 5.765917498130366 Test RE 1.1477367090257127\n",
      "47 Train Loss 12.354359 Test MSE 5.85855969120214 Test RE 1.1569204287905206\n",
      "48 Train Loss 11.902851 Test MSE 5.758624094705921 Test RE 1.147010583856\n",
      "49 Train Loss 11.186289 Test MSE 5.863036827044782 Test RE 1.1573624060839633\n",
      "50 Train Loss 10.432374 Test MSE 5.9688558560662965 Test RE 1.1677600290709038\n",
      "51 Train Loss 10.041815 Test MSE 5.929746031336259 Test RE 1.163927975676657\n",
      "52 Train Loss 9.577593 Test MSE 6.135648894406989 Test RE 1.1839634896956626\n",
      "53 Train Loss 9.103516 Test MSE 6.040369727294501 Test RE 1.174734765078569\n",
      "54 Train Loss 8.711348 Test MSE 5.9877114094786785 Test RE 1.1696030455789321\n",
      "55 Train Loss 8.3662 Test MSE 5.7741732464817845 Test RE 1.1485580905404265\n",
      "56 Train Loss 8.070738 Test MSE 5.74919171212162 Test RE 1.1460708214758977\n",
      "57 Train Loss 7.5732436 Test MSE 5.3130905379705125 Test RE 1.10174647220959\n",
      "58 Train Loss 7.291265 Test MSE 5.276789686984093 Test RE 1.0979762670586908\n",
      "59 Train Loss 6.968801 Test MSE 5.129915094494368 Test RE 1.0825878505006608\n",
      "60 Train Loss 6.8110046 Test MSE 4.9612136672209886 Test RE 1.0646381536033993\n",
      "61 Train Loss 6.666643 Test MSE 4.954408809327881 Test RE 1.0639077680801647\n",
      "62 Train Loss 6.5439663 Test MSE 4.842680901951842 Test RE 1.051843159251548\n",
      "63 Train Loss 6.336459 Test MSE 4.498002323277539 Test RE 1.0137197270829352\n",
      "64 Train Loss 6.1783037 Test MSE 4.374533583081629 Test RE 0.9997097730625781\n",
      "65 Train Loss 5.8618145 Test MSE 4.188497242802428 Test RE 0.978221440138578\n",
      "66 Train Loss 5.6388154 Test MSE 4.127889893549321 Test RE 0.9711182426951591\n",
      "67 Train Loss 5.4887223 Test MSE 3.98524649622379 Test RE 0.9541917440480755\n",
      "68 Train Loss 5.2800264 Test MSE 3.8304746890959116 Test RE 0.9354796807362014\n",
      "69 Train Loss 5.152501 Test MSE 3.6710906984351808 Test RE 0.9158104977830349\n",
      "70 Train Loss 4.943839 Test MSE 3.399995680338549 Test RE 0.881347633885641\n",
      "71 Train Loss 4.794503 Test MSE 3.2286852147244676 Test RE 0.8588571049651992\n",
      "72 Train Loss 4.543102 Test MSE 2.6984698329892174 Test RE 0.7851756883576613\n",
      "73 Train Loss 4.340285 Test MSE 2.4676854335174303 Test RE 0.7508496091479014\n",
      "74 Train Loss 4.189411 Test MSE 2.3134837918579043 Test RE 0.727011517106371\n",
      "75 Train Loss 4.0529466 Test MSE 2.23268044500327 Test RE 0.7142024646753145\n",
      "76 Train Loss 3.8951907 Test MSE 2.195977004307521 Test RE 0.7083076857139518\n",
      "77 Train Loss 3.7796528 Test MSE 2.0615135400892046 Test RE 0.6862797052721349\n",
      "78 Train Loss 3.7047505 Test MSE 2.052061447969481 Test RE 0.6847045927456824\n",
      "79 Train Loss 3.5932426 Test MSE 1.9914289979650919 Test RE 0.6745132319527859\n",
      "80 Train Loss 3.514186 Test MSE 1.9116420551030913 Test RE 0.6608628643363742\n",
      "81 Train Loss 3.425138 Test MSE 1.8774052309088112 Test RE 0.6549182189220526\n",
      "82 Train Loss 3.3574934 Test MSE 1.849465500050656 Test RE 0.6500266726377001\n",
      "83 Train Loss 3.259559 Test MSE 1.859528530668852 Test RE 0.6517926868282672\n",
      "84 Train Loss 3.1649954 Test MSE 1.8922810877155547 Test RE 0.657507762896249\n",
      "85 Train Loss 3.0436454 Test MSE 1.8830536204305466 Test RE 0.6559026773996622\n",
      "86 Train Loss 2.626774 Test MSE 1.4334977650288567 Test RE 0.5722773670428719\n",
      "87 Train Loss 1.974364 Test MSE 0.8628820478923075 Test RE 0.44400082503228544\n",
      "88 Train Loss 1.4720917 Test MSE 0.4214312703227284 Test RE 0.3102926146095535\n",
      "89 Train Loss 1.1454746 Test MSE 0.31902561364605064 Test RE 0.2699733133633748\n",
      "90 Train Loss 0.9391394 Test MSE 0.20751426284924906 Test RE 0.2177369004212647\n",
      "91 Train Loss 0.7868056 Test MSE 0.15704709770365152 Test RE 0.18941877241592261\n",
      "92 Train Loss 0.5989879 Test MSE 0.1058663279045303 Test RE 0.15552026404950978\n",
      "93 Train Loss 0.54785025 Test MSE 0.12106088052505348 Test RE 0.16630678749120328\n",
      "94 Train Loss 0.49405292 Test MSE 0.11215832959221528 Test RE 0.16007511650267062\n",
      "95 Train Loss 0.43592748 Test MSE 0.10318234285180987 Test RE 0.15353618761277277\n",
      "96 Train Loss 0.38691074 Test MSE 0.09022774132579055 Test RE 0.14357476138560246\n",
      "97 Train Loss 0.34282115 Test MSE 0.05744966731026757 Test RE 0.11456496303135145\n",
      "98 Train Loss 0.31226042 Test MSE 0.05024829518680929 Test RE 0.1071442147102365\n",
      "99 Train Loss 0.2866736 Test MSE 0.049086995729070305 Test RE 0.10589886041898103\n",
      "Training time: 72.44\n",
      "KG_stan_tune15\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.327934 Test MSE 8.642527608696554 Test RE 1.4051686375845844\n",
      "1 Train Loss 55.01937 Test MSE 8.697338816961217 Test RE 1.4096174091562454\n",
      "2 Train Loss 45.66247 Test MSE 8.956130350142567 Test RE 1.4304354454601107\n",
      "3 Train Loss 44.34514 Test MSE 8.61532586969596 Test RE 1.4029555608231816\n",
      "4 Train Loss 43.3235 Test MSE 8.835951389583576 Test RE 1.4208057932940752\n",
      "5 Train Loss 42.596344 Test MSE 8.474246051666254 Test RE 1.3914211328628163\n",
      "6 Train Loss 42.17872 Test MSE 8.275318955912418 Test RE 1.3749928226125934\n",
      "7 Train Loss 42.086548 Test MSE 8.29856833862981 Test RE 1.3769229785864383\n",
      "8 Train Loss 41.93532 Test MSE 8.385219216855653 Test RE 1.3840929953331969\n",
      "9 Train Loss 41.872715 Test MSE 8.333845216411301 Test RE 1.3798464968390747\n",
      "10 Train Loss 41.702095 Test MSE 8.321978149677005 Test RE 1.378863723375432\n",
      "11 Train Loss 41.58899 Test MSE 8.329794713915122 Test RE 1.3795111323815838\n",
      "12 Train Loss 41.415764 Test MSE 8.274121360508273 Test RE 1.3748933252593911\n",
      "13 Train Loss 41.095238 Test MSE 8.291139270766088 Test RE 1.3763065141419493\n",
      "14 Train Loss 40.94809 Test MSE 8.181276222056434 Test RE 1.3671576225873192\n",
      "15 Train Loss 40.74537 Test MSE 8.363042413492007 Test RE 1.3822614940171378\n",
      "16 Train Loss 40.48672 Test MSE 8.365487659859534 Test RE 1.382463557016538\n",
      "17 Train Loss 40.244488 Test MSE 8.49159658608128 Test RE 1.3928448321186828\n",
      "18 Train Loss 39.90692 Test MSE 8.53586291012755 Test RE 1.3964705329011318\n",
      "19 Train Loss 39.62943 Test MSE 8.531621393728111 Test RE 1.396123532912758\n",
      "20 Train Loss 39.178936 Test MSE 8.552494299107805 Test RE 1.3978303217584773\n",
      "21 Train Loss 39.050808 Test MSE 8.61606904585339 Test RE 1.403016070469266\n",
      "22 Train Loss 38.903625 Test MSE 8.516494692705097 Test RE 1.3948853091582338\n",
      "23 Train Loss 38.30945 Test MSE 8.560486164790706 Test RE 1.398483269498768\n",
      "24 Train Loss 37.793945 Test MSE 8.413991315689142 Test RE 1.386465572402773\n",
      "25 Train Loss 36.57961 Test MSE 8.05680816711036 Test RE 1.3567179528935451\n",
      "26 Train Loss 35.446342 Test MSE 7.59606422317695 Test RE 1.3173536353612547\n",
      "27 Train Loss 33.652054 Test MSE 6.965578246144947 Test RE 1.2614982368156105\n",
      "28 Train Loss 32.449036 Test MSE 7.009465952519671 Test RE 1.265466129223695\n",
      "29 Train Loss 32.11555 Test MSE 7.205768637722667 Test RE 1.2830636967458953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 31.840916 Test MSE 7.190654166062572 Test RE 1.281717344198174\n",
      "31 Train Loss 31.38844 Test MSE 7.448786968701192 Test RE 1.3045202866225405\n",
      "32 Train Loss 31.1964 Test MSE 7.447660074832858 Test RE 1.3044216053525535\n",
      "33 Train Loss 31.071625 Test MSE 7.362001011684258 Test RE 1.2968985260672503\n",
      "34 Train Loss 30.682037 Test MSE 7.183848591679484 Test RE 1.2811106617307269\n",
      "35 Train Loss 30.505188 Test MSE 7.234305009367957 Test RE 1.2856017885270545\n",
      "36 Train Loss 30.337233 Test MSE 7.192990469292276 Test RE 1.2819255475902642\n",
      "37 Train Loss 30.14962 Test MSE 7.119647088886786 Test RE 1.2753732204279966\n",
      "38 Train Loss 30.001072 Test MSE 7.157752639555617 Test RE 1.2787816720313856\n",
      "39 Train Loss 29.915367 Test MSE 7.185885692763214 Test RE 1.2812922890924783\n",
      "40 Train Loss 29.78341 Test MSE 7.315289578265518 Test RE 1.2927776091331207\n",
      "41 Train Loss 29.474396 Test MSE 7.303444276838363 Test RE 1.2917305183542798\n",
      "42 Train Loss 29.106308 Test MSE 7.125339970172004 Test RE 1.2758830137815889\n",
      "43 Train Loss 28.481163 Test MSE 6.905833857919784 Test RE 1.256076594644647\n",
      "44 Train Loss 28.04623 Test MSE 6.989395944177654 Test RE 1.2636531435909526\n",
      "45 Train Loss 27.315266 Test MSE 6.686324373903958 Test RE 1.2359525023430844\n",
      "46 Train Loss 25.992237 Test MSE 5.811193059139181 Test RE 1.1522340689204602\n",
      "47 Train Loss 23.869595 Test MSE 4.620724354804173 Test RE 1.0274556654174072\n",
      "48 Train Loss 22.258987 Test MSE 3.4720067603425773 Test RE 0.8906320948725334\n",
      "49 Train Loss 18.265902 Test MSE 2.889638477801033 Test RE 0.8125120604338916\n",
      "50 Train Loss 16.5841 Test MSE 3.2427989312938905 Test RE 0.8607322409429286\n",
      "51 Train Loss 14.944842 Test MSE 3.021457214065016 Test RE 0.830837871849702\n",
      "52 Train Loss 13.986221 Test MSE 2.963792747998298 Test RE 0.8228714145900082\n",
      "53 Train Loss 12.872161 Test MSE 2.912893376100319 Test RE 0.815774929242636\n",
      "54 Train Loss 12.103321 Test MSE 2.9032550185545074 Test RE 0.8144241682669907\n",
      "55 Train Loss 10.884041 Test MSE 2.5727143435416293 Test RE 0.76666183482573\n",
      "56 Train Loss 10.073106 Test MSE 2.077360670994847 Test RE 0.6889124174965686\n",
      "57 Train Loss 9.585873 Test MSE 2.102935505118891 Test RE 0.6931401197513358\n",
      "58 Train Loss 8.837003 Test MSE 1.9122550605956747 Test RE 0.6609688151583352\n",
      "59 Train Loss 7.408677 Test MSE 1.2654154182581012 Test RE 0.5376809146275093\n",
      "60 Train Loss 5.1795106 Test MSE 0.3624388957903686 Test RE 0.28775671010030357\n",
      "61 Train Loss 3.533482 Test MSE 0.25276228745975915 Test RE 0.24030576998725484\n",
      "62 Train Loss 2.5081081 Test MSE 0.17157095789639523 Test RE 0.19798393341005044\n",
      "63 Train Loss 1.9362963 Test MSE 0.1406506834875805 Test RE 0.17925818041914418\n",
      "64 Train Loss 1.4885241 Test MSE 0.12159816125412297 Test RE 0.1666754223098447\n",
      "65 Train Loss 1.2233074 Test MSE 0.09853200395936267 Test RE 0.15003642868427675\n",
      "66 Train Loss 1.0206039 Test MSE 0.08855983703432299 Test RE 0.14224154622898424\n",
      "67 Train Loss 0.8259928 Test MSE 0.06562384596258328 Test RE 0.12244439222104939\n",
      "68 Train Loss 0.56017196 Test MSE 0.04408541592354768 Test RE 0.10035881658164501\n",
      "69 Train Loss 0.48268646 Test MSE 0.03220947845572963 Test RE 0.08578273854235087\n",
      "70 Train Loss 0.41217822 Test MSE 0.02781409697072158 Test RE 0.07971509031896697\n",
      "71 Train Loss 0.32086 Test MSE 0.02925895262499916 Test RE 0.08175935339951826\n",
      "72 Train Loss 0.27140516 Test MSE 0.029477839381699702 Test RE 0.0820646051695998\n",
      "73 Train Loss 0.23663025 Test MSE 0.03173254180396593 Test RE 0.08514526288657003\n",
      "74 Train Loss 0.21804513 Test MSE 0.02629799482765239 Test RE 0.07751207767215633\n",
      "75 Train Loss 0.1962382 Test MSE 0.0206695583116233 Test RE 0.06871849799842586\n",
      "76 Train Loss 0.19047102 Test MSE 0.019715781652754453 Test RE 0.0671142992759093\n",
      "77 Train Loss 0.18002415 Test MSE 0.017947224677854208 Test RE 0.06403342179655441\n",
      "78 Train Loss 0.16783017 Test MSE 0.016261578236223304 Test RE 0.06095220296686011\n",
      "79 Train Loss 0.15081678 Test MSE 0.013827520025485363 Test RE 0.05620568024223106\n",
      "80 Train Loss 0.14495325 Test MSE 0.013382594194474436 Test RE 0.05529402629544275\n",
      "81 Train Loss 0.13897689 Test MSE 0.012447828935044624 Test RE 0.0533279471562567\n",
      "82 Train Loss 0.12678376 Test MSE 0.01227389527951353 Test RE 0.05295406047431551\n",
      "83 Train Loss 0.11923802 Test MSE 0.012622133793935796 Test RE 0.05370002031065443\n",
      "84 Train Loss 0.11617894 Test MSE 0.01199470255352778 Test RE 0.05234832640057847\n",
      "85 Train Loss 0.109929435 Test MSE 0.009454791496317533 Test RE 0.04647656666966993\n",
      "86 Train Loss 0.10238746 Test MSE 0.0074648473711251325 Test RE 0.041297002167236224\n",
      "87 Train Loss 0.09644903 Test MSE 0.006813586318607641 Test RE 0.03945444525195136\n",
      "88 Train Loss 0.09276118 Test MSE 0.006688844322353042 Test RE 0.03909161423317996\n",
      "89 Train Loss 0.09083072 Test MSE 0.006605773775795245 Test RE 0.03884811123285745\n",
      "90 Train Loss 0.08477953 Test MSE 0.00717463370966505 Test RE 0.040486284922448136\n",
      "91 Train Loss 0.08129564 Test MSE 0.00737977972838027 Test RE 0.041061022492889614\n",
      "92 Train Loss 0.08021587 Test MSE 0.007090038124412683 Test RE 0.04024689173978947\n",
      "93 Train Loss 0.07858263 Test MSE 0.007071073826439384 Test RE 0.04019302989151038\n",
      "94 Train Loss 0.077001795 Test MSE 0.006767651033240627 Test RE 0.0393212249441983\n",
      "95 Train Loss 0.0756282 Test MSE 0.006448986505717638 Test RE 0.03838431497434023\n",
      "96 Train Loss 0.074142516 Test MSE 0.006350016212195228 Test RE 0.03808864099849247\n",
      "97 Train Loss 0.07024318 Test MSE 0.007099065801766961 Test RE 0.04027250657868714\n",
      "98 Train Loss 0.06904398 Test MSE 0.006550243867459571 Test RE 0.03868448280316507\n",
      "99 Train Loss 0.06839967 Test MSE 0.00678676840170208 Test RE 0.03937672338995985\n",
      "Training time: 72.98\n",
      "KG_stan_tune15\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.018917 Test MSE 8.5528046345465 Test RE 1.3978556823337578\n",
      "1 Train Loss 55.835033 Test MSE 8.873416341691826 Test RE 1.4238147570681106\n",
      "2 Train Loss 50.049118 Test MSE 8.408096852845935 Test RE 1.3859798396921754\n",
      "3 Train Loss 47.11509 Test MSE 8.198094325297575 Test RE 1.368562121896233\n",
      "4 Train Loss 44.019424 Test MSE 8.359313931267165 Test RE 1.3819533339179504\n",
      "5 Train Loss 43.761627 Test MSE 8.280105313331273 Test RE 1.3753904058225161\n",
      "6 Train Loss 43.3497 Test MSE 8.324435137577177 Test RE 1.379067256802356\n",
      "7 Train Loss 42.528316 Test MSE 8.285270621544525 Test RE 1.3758193380329173\n",
      "8 Train Loss 41.840668 Test MSE 8.063858513882467 Test RE 1.357311441043589\n",
      "9 Train Loss 40.97944 Test MSE 7.715665267595259 Test RE 1.3276840849540859\n",
      "10 Train Loss 39.964252 Test MSE 7.6735140044036445 Test RE 1.324052498943989\n",
      "11 Train Loss 39.564274 Test MSE 7.537004805749406 Test RE 1.3122224282858528\n",
      "12 Train Loss 36.615925 Test MSE 6.024132192557277 Test RE 1.1731547597357739\n",
      "13 Train Loss 31.657427 Test MSE 5.861614678336262 Test RE 1.1572220316225375\n",
      "14 Train Loss 28.056334 Test MSE 5.459860127346707 Test RE 1.1168602099899965\n",
      "15 Train Loss 25.816154 Test MSE 4.915092551817462 Test RE 1.059677981166668\n",
      "16 Train Loss 24.741505 Test MSE 5.179949832159955 Test RE 1.087854561408828\n",
      "17 Train Loss 22.702126 Test MSE 2.714626082878892 Test RE 0.7875226783977807\n",
      "18 Train Loss 16.11679 Test MSE 1.7843466396559837 Test RE 0.6384805529826325\n",
      "19 Train Loss 12.588957 Test MSE 1.7425770657216433 Test RE 0.6309632390072265\n",
      "20 Train Loss 9.641077 Test MSE 0.7362621925656669 Test RE 0.4101326179255182\n",
      "21 Train Loss 6.4661703 Test MSE 0.4868759486437212 Test RE 0.3335164203867625\n",
      "22 Train Loss 3.512362 Test MSE 0.22199580246259365 Test RE 0.22520625137422098\n",
      "23 Train Loss 2.5798373 Test MSE 0.16904981599446078 Test RE 0.19652391691831622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 1.4822468 Test MSE 0.06201366902330597 Test RE 0.11902872286364176\n",
      "25 Train Loss 1.2744364 Test MSE 0.057786484252460454 Test RE 0.11490030899389436\n",
      "26 Train Loss 0.96687645 Test MSE 0.05385402519887628 Test RE 0.1109218603648571\n",
      "27 Train Loss 0.76997244 Test MSE 0.040057712283265656 Test RE 0.09566457175610164\n",
      "28 Train Loss 0.62435436 Test MSE 0.0316998938415509 Test RE 0.08510145084764376\n",
      "29 Train Loss 0.5511766 Test MSE 0.02964714526593955 Test RE 0.08229993665681525\n",
      "30 Train Loss 0.47560376 Test MSE 0.02238556044793584 Test RE 0.07151416072787321\n",
      "31 Train Loss 0.40778998 Test MSE 0.02298656612129778 Test RE 0.07246780541248668\n",
      "32 Train Loss 0.36757174 Test MSE 0.02007031481326122 Test RE 0.06771504206957302\n",
      "33 Train Loss 0.30817407 Test MSE 0.017476341751634893 Test RE 0.06318781306749968\n",
      "34 Train Loss 0.2553225 Test MSE 0.01382214518293712 Test RE 0.056194755432739524\n",
      "35 Train Loss 0.2123543 Test MSE 0.012376175178078893 Test RE 0.053174239123646\n",
      "36 Train Loss 0.20085743 Test MSE 0.013076101254536576 Test RE 0.054657177093982524\n",
      "37 Train Loss 0.13677298 Test MSE 0.011495692377290881 Test RE 0.05124784727839626\n",
      "38 Train Loss 0.12872247 Test MSE 0.01244621983883592 Test RE 0.05332450026719226\n",
      "39 Train Loss 0.104179874 Test MSE 0.008295066625715419 Test RE 0.04353294013353596\n",
      "40 Train Loss 0.098708645 Test MSE 0.007196487324978261 Test RE 0.040547897752612555\n",
      "41 Train Loss 0.090579316 Test MSE 0.006164228706802741 Test RE 0.03752730976633987\n",
      "42 Train Loss 0.07814424 Test MSE 0.0054769311886747225 Test RE 0.03537339164888553\n",
      "43 Train Loss 0.06798756 Test MSE 0.005184944352876192 Test RE 0.034417562531485826\n",
      "44 Train Loss 0.06437105 Test MSE 0.0049620750286828805 Test RE 0.03366973696723587\n",
      "45 Train Loss 0.060883805 Test MSE 0.004895335317925091 Test RE 0.03344254213264596\n",
      "46 Train Loss 0.056004874 Test MSE 0.004212034187935128 Test RE 0.03102087216825443\n",
      "47 Train Loss 0.05428905 Test MSE 0.004685102232707613 Test RE 0.03271655721226286\n",
      "48 Train Loss 0.052741807 Test MSE 0.004446770583661895 Test RE 0.031873548932301335\n",
      "49 Train Loss 0.047118705 Test MSE 0.0036308926263951898 Test RE 0.02880147722827986\n",
      "50 Train Loss 0.04461784 Test MSE 0.0032534669903084516 Test RE 0.027263478294993496\n",
      "51 Train Loss 0.042536248 Test MSE 0.0029207970799529706 Test RE 0.025832042894316055\n",
      "52 Train Loss 0.035550326 Test MSE 0.002718508812023886 Test RE 0.024921457209408596\n",
      "53 Train Loss 0.032113668 Test MSE 0.0027773383875669736 Test RE 0.025189668881257208\n",
      "54 Train Loss 0.028576741 Test MSE 0.002181706457344569 Test RE 0.022325758303573747\n",
      "55 Train Loss 0.024595559 Test MSE 0.0018030872992617093 Test RE 0.020296279616478292\n",
      "56 Train Loss 0.02299943 Test MSE 0.00196227506532822 Test RE 0.02117327328039248\n",
      "57 Train Loss 0.021738758 Test MSE 0.0019182038608608059 Test RE 0.02093415525246361\n",
      "58 Train Loss 0.021222085 Test MSE 0.0019527227831294314 Test RE 0.021121675054925113\n",
      "59 Train Loss 0.018967904 Test MSE 0.0017160783839385203 Test RE 0.019800521135152918\n",
      "60 Train Loss 0.018750217 Test MSE 0.0015412036187005232 Test RE 0.018764546388660947\n",
      "61 Train Loss 0.017606102 Test MSE 0.0015142633302978646 Test RE 0.01859982092890317\n",
      "62 Train Loss 0.017197564 Test MSE 0.0013173884477736982 Test RE 0.01734862204620346\n",
      "63 Train Loss 0.016978832 Test MSE 0.0012929202330421246 Test RE 0.01718675658764956\n",
      "64 Train Loss 0.016094686 Test MSE 0.0012477070319368531 Test RE 0.016883573454869613\n",
      "65 Train Loss 0.015576196 Test MSE 0.0011195463261687293 Test RE 0.01599296897858139\n",
      "66 Train Loss 0.015318813 Test MSE 0.001093522660022265 Test RE 0.015805999131775696\n",
      "67 Train Loss 0.015059719 Test MSE 0.0011123260440640249 Test RE 0.01594131388900802\n",
      "68 Train Loss 0.014838288 Test MSE 0.0010421120260468387 Test RE 0.015429976482522643\n",
      "69 Train Loss 0.014638891 Test MSE 0.0010122845382008715 Test RE 0.015207553815369482\n",
      "70 Train Loss 0.014277659 Test MSE 0.0010071641004876385 Test RE 0.015169042877699471\n",
      "71 Train Loss 0.013798133 Test MSE 0.0009454828832198271 Test RE 0.014697209868789422\n",
      "72 Train Loss 0.0135299815 Test MSE 0.0008861287126932398 Test RE 0.01422841306712921\n",
      "73 Train Loss 0.013449147 Test MSE 0.0009204340637566462 Test RE 0.014501215337158396\n",
      "74 Train Loss 0.013342607 Test MSE 0.0008908713876969718 Test RE 0.014266438405575886\n",
      "75 Train Loss 0.012812482 Test MSE 0.0010190360351427397 Test RE 0.015258183416259279\n",
      "76 Train Loss 0.012004134 Test MSE 0.0009033166372907996 Test RE 0.014365742077721774\n",
      "77 Train Loss 0.01177982 Test MSE 0.0009039275595302222 Test RE 0.014370599105466243\n",
      "78 Train Loss 0.01147575 Test MSE 0.0009109659788450781 Test RE 0.014426438851982644\n",
      "79 Train Loss 0.011208013 Test MSE 0.0008486393229176442 Test RE 0.013924180231381235\n",
      "80 Train Loss 0.01113627 Test MSE 0.0008609972756676034 Test RE 0.014025196314826406\n",
      "81 Train Loss 0.010590927 Test MSE 0.000803148059331649 Test RE 0.013545837688915494\n",
      "82 Train Loss 0.010079692 Test MSE 0.0007605773114087061 Test RE 0.013181952526830267\n",
      "83 Train Loss 0.010030614 Test MSE 0.0007397532787782859 Test RE 0.013000244181023024\n",
      "84 Train Loss 0.009948479 Test MSE 0.00074651160411469 Test RE 0.013059493746675473\n",
      "85 Train Loss 0.009508402 Test MSE 0.0007146095022816033 Test RE 0.012777398910287823\n",
      "86 Train Loss 0.009222761 Test MSE 0.0007186046382052427 Test RE 0.01281306615008935\n",
      "87 Train Loss 0.008753053 Test MSE 0.0007291039825604149 Test RE 0.012906330897296783\n",
      "88 Train Loss 0.008385849 Test MSE 0.0006856183395631087 Test RE 0.012515530798343107\n",
      "89 Train Loss 0.00819575 Test MSE 0.0006612505056712198 Test RE 0.012291108964861585\n",
      "90 Train Loss 0.007871589 Test MSE 0.0006412297382570757 Test RE 0.012103609065789157\n",
      "91 Train Loss 0.007513517 Test MSE 0.0006561038329305805 Test RE 0.012243183190158349\n",
      "92 Train Loss 0.0073334435 Test MSE 0.0006465848082395662 Test RE 0.012154044119622447\n",
      "93 Train Loss 0.0072239963 Test MSE 0.0006349536875431903 Test RE 0.012044231242944656\n",
      "94 Train Loss 0.0071681673 Test MSE 0.0006203412031262852 Test RE 0.011904834829639839\n",
      "95 Train Loss 0.007070246 Test MSE 0.0006310118987948045 Test RE 0.012006787782007543\n",
      "96 Train Loss 0.006969502 Test MSE 0.0006411623967248161 Test RE 0.012102973492505094\n",
      "97 Train Loss 0.0067309644 Test MSE 0.0006022376584535985 Test RE 0.011729838015031748\n",
      "98 Train Loss 0.0065861493 Test MSE 0.0006029989639550671 Test RE 0.01173724968192648\n",
      "99 Train Loss 0.006440226 Test MSE 0.0005655095490359718 Test RE 0.011366533379120265\n",
      "Training time: 72.69\n",
      "KG_stan_tune15\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.109413 Test MSE 8.415385384433604 Test RE 1.3865804256391205\n",
      "1 Train Loss 57.747272 Test MSE 8.689072127332137 Test RE 1.408947339831102\n",
      "2 Train Loss 56.198055 Test MSE 8.610023449287059 Test RE 1.4025237602574634\n",
      "3 Train Loss 50.63927 Test MSE 8.363947090302167 Test RE 1.3823362554520822\n",
      "4 Train Loss 46.480843 Test MSE 8.65840122999429 Test RE 1.406458473344216\n",
      "5 Train Loss 45.81814 Test MSE 8.72427038396679 Test RE 1.4117981832626225\n",
      "6 Train Loss 45.602554 Test MSE 8.611148322617632 Test RE 1.4026153749932944\n",
      "7 Train Loss 45.28705 Test MSE 8.644540553831174 Test RE 1.4053322681114602\n",
      "8 Train Loss 44.811737 Test MSE 8.518429291800086 Test RE 1.3950437305934484\n",
      "9 Train Loss 44.61344 Test MSE 8.538659449205412 Test RE 1.3966992716147963\n",
      "10 Train Loss 44.22654 Test MSE 8.370684016578423 Test RE 1.3828928600561492\n",
      "11 Train Loss 44.015778 Test MSE 8.442428972290312 Test RE 1.388806588214143\n",
      "12 Train Loss 43.012608 Test MSE 8.048613202364121 Test RE 1.3560277860042493\n",
      "13 Train Loss 40.982147 Test MSE 7.648261703069034 Test RE 1.32187208162597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 40.209557 Test MSE 7.992616883313053 Test RE 1.3513024317864788\n",
      "15 Train Loss 39.92226 Test MSE 8.067266425138301 Test RE 1.357598221145242\n",
      "16 Train Loss 39.480778 Test MSE 8.09016424736176 Test RE 1.3595235335107099\n",
      "17 Train Loss 39.22868 Test MSE 8.024049293746199 Test RE 1.353956945028897\n",
      "18 Train Loss 36.984604 Test MSE 7.255347117943995 Test RE 1.287470117956236\n",
      "19 Train Loss 35.966686 Test MSE 7.577457618961328 Test RE 1.315739213362638\n",
      "20 Train Loss 35.726013 Test MSE 7.439441689632756 Test RE 1.3037017015070183\n",
      "21 Train Loss 35.310295 Test MSE 7.463997731123359 Test RE 1.305851552278196\n",
      "22 Train Loss 34.916656 Test MSE 7.452053375094397 Test RE 1.304806281267442\n",
      "23 Train Loss 34.541885 Test MSE 7.366583343094364 Test RE 1.2973020776548259\n",
      "24 Train Loss 33.763287 Test MSE 7.510246075768193 Test RE 1.3098909565748356\n",
      "25 Train Loss 33.044933 Test MSE 7.876116811119023 Test RE 1.3414180150603823\n",
      "26 Train Loss 32.57709 Test MSE 7.863486790635507 Test RE 1.3403420448263912\n",
      "27 Train Loss 32.063927 Test MSE 7.941737393351279 Test RE 1.3469944968977694\n",
      "28 Train Loss 31.689596 Test MSE 7.900399521452975 Test RE 1.3434842742333502\n",
      "29 Train Loss 31.228191 Test MSE 8.123741940234996 Test RE 1.36234191851688\n",
      "30 Train Loss 30.848839 Test MSE 8.205909055189599 Test RE 1.3692142488057277\n",
      "31 Train Loss 30.315641 Test MSE 8.33695335825896 Test RE 1.3801037825652798\n",
      "32 Train Loss 29.203821 Test MSE 8.155645924796387 Test RE 1.3650144274289135\n",
      "33 Train Loss 28.085758 Test MSE 8.16625870406489 Test RE 1.3659022717047788\n",
      "34 Train Loss 27.169977 Test MSE 7.700635624686312 Test RE 1.3263903310087355\n",
      "35 Train Loss 25.883514 Test MSE 7.267562379077182 Test RE 1.2885534685881002\n",
      "36 Train Loss 24.65563 Test MSE 6.878942375696489 Test RE 1.2536286130435923\n",
      "37 Train Loss 23.51493 Test MSE 6.875378539757119 Test RE 1.2533038316113172\n",
      "38 Train Loss 22.433416 Test MSE 5.998492716971423 Test RE 1.1706555494560058\n",
      "39 Train Loss 20.890663 Test MSE 6.007452879995314 Test RE 1.1715295482202033\n",
      "40 Train Loss 20.25536 Test MSE 5.695416659305428 Test RE 1.1406983435638414\n",
      "41 Train Loss 19.817242 Test MSE 5.869339841640868 Test RE 1.1579843459448351\n",
      "42 Train Loss 19.00224 Test MSE 6.002570528714347 Test RE 1.1710533912262289\n",
      "43 Train Loss 18.524979 Test MSE 6.042582096193272 Test RE 1.174949876805535\n",
      "44 Train Loss 17.541737 Test MSE 5.847730887755772 Test RE 1.155850724027127\n",
      "45 Train Loss 16.661407 Test MSE 5.794162952339092 Test RE 1.1505444789724781\n",
      "46 Train Loss 16.135605 Test MSE 5.7805875446195785 Test RE 1.149195857096972\n",
      "47 Train Loss 15.384083 Test MSE 5.757543616909669 Test RE 1.1469029732891631\n",
      "48 Train Loss 14.876539 Test MSE 5.620766199782505 Test RE 1.1331980557010044\n",
      "49 Train Loss 14.494144 Test MSE 5.49541725831474 Test RE 1.1204910629088158\n",
      "50 Train Loss 14.075258 Test MSE 5.387917207428365 Test RE 1.109477545543004\n",
      "51 Train Loss 13.830471 Test MSE 5.533492050618862 Test RE 1.1243660027965945\n",
      "52 Train Loss 13.522938 Test MSE 5.485406522340608 Test RE 1.1194700255005354\n",
      "53 Train Loss 13.171323 Test MSE 5.570735505394682 Test RE 1.128143459165577\n",
      "54 Train Loss 12.982424 Test MSE 5.502002838237326 Test RE 1.1211622470695297\n",
      "55 Train Loss 12.569003 Test MSE 5.389522980718354 Test RE 1.109642863291808\n",
      "56 Train Loss 11.408147 Test MSE 4.4400258740268495 Test RE 1.0071654303401756\n",
      "57 Train Loss 10.210531 Test MSE 4.067222689122065 Test RE 0.9639556120192987\n",
      "58 Train Loss 9.665812 Test MSE 4.089100125458954 Test RE 0.9665446753791453\n",
      "59 Train Loss 9.328672 Test MSE 4.486234247522327 Test RE 1.012392766503011\n",
      "60 Train Loss 9.050428 Test MSE 4.535289114567127 Test RE 1.0179127379524828\n",
      "61 Train Loss 8.827084 Test MSE 4.686019419204658 Test RE 1.0346896438644153\n",
      "62 Train Loss 8.697943 Test MSE 4.725384384910155 Test RE 1.0390265166774042\n",
      "63 Train Loss 8.426724 Test MSE 4.682418723520853 Test RE 1.0342920443074723\n",
      "64 Train Loss 8.263174 Test MSE 4.550772077457293 Test RE 1.0196487769002502\n",
      "65 Train Loss 7.9690933 Test MSE 4.431195295052628 Test RE 1.006163377572885\n",
      "66 Train Loss 7.635474 Test MSE 4.249550625173147 Test RE 0.9853251406109275\n",
      "67 Train Loss 7.483511 Test MSE 4.031635511086784 Test RE 0.9597291617414102\n",
      "68 Train Loss 7.0237074 Test MSE 3.4393088905861324 Test RE 0.8864283788217006\n",
      "69 Train Loss 6.0001874 Test MSE 2.705245837064327 Test RE 0.7861608796430419\n",
      "70 Train Loss 4.957038 Test MSE 2.783650793587349 Test RE 0.797471987206061\n",
      "71 Train Loss 4.389678 Test MSE 2.5396957219896112 Test RE 0.7617262181275722\n",
      "72 Train Loss 3.9182076 Test MSE 2.494846252384553 Test RE 0.7549704505624407\n",
      "73 Train Loss 3.4998083 Test MSE 2.360740269502129 Test RE 0.7343991481163153\n",
      "74 Train Loss 3.3853028 Test MSE 2.2893578392975575 Test RE 0.7232107959599238\n",
      "75 Train Loss 3.1846619 Test MSE 1.9457334963185462 Test RE 0.6667296024562519\n",
      "76 Train Loss 2.7863731 Test MSE 1.9200927624099038 Test RE 0.6623219764529572\n",
      "77 Train Loss 2.648104 Test MSE 1.985946858374382 Test RE 0.6735841694360265\n",
      "78 Train Loss 2.576902 Test MSE 1.9634803857574312 Test RE 0.6697632960105392\n",
      "79 Train Loss 2.472939 Test MSE 1.9522375578699425 Test RE 0.6678430212593283\n",
      "80 Train Loss 2.3808653 Test MSE 1.884172365990444 Test RE 0.6560974884353903\n",
      "81 Train Loss 2.310225 Test MSE 1.835820888192635 Test RE 0.6476244161712933\n",
      "82 Train Loss 2.2670736 Test MSE 1.8365799553039337 Test RE 0.6477582907756454\n",
      "83 Train Loss 2.2308798 Test MSE 1.7741530346254077 Test RE 0.6366541868517124\n",
      "84 Train Loss 2.1659334 Test MSE 1.800490688331693 Test RE 0.6413624064539292\n",
      "85 Train Loss 2.1003788 Test MSE 1.816550262585825 Test RE 0.6442163898854694\n",
      "86 Train Loss 2.0607953 Test MSE 1.8323904557270103 Test RE 0.6470190546546903\n",
      "87 Train Loss 1.9993854 Test MSE 1.8283649438860456 Test RE 0.646307957598535\n",
      "88 Train Loss 1.9266577 Test MSE 1.789239366724033 Test RE 0.6393553192649405\n",
      "89 Train Loss 1.8284423 Test MSE 1.785902479878894 Test RE 0.6387588501637972\n",
      "90 Train Loss 1.773185 Test MSE 1.8039111138192676 Test RE 0.6419713214169439\n",
      "91 Train Loss 1.7385758 Test MSE 1.7960017439715885 Test RE 0.640562392072706\n",
      "92 Train Loss 1.6734058 Test MSE 1.7327996289070866 Test RE 0.6291906111585934\n",
      "93 Train Loss 1.5992819 Test MSE 1.7186107948346387 Test RE 0.6266092879465703\n",
      "94 Train Loss 1.566259 Test MSE 1.742570234417712 Test RE 0.6309620022453166\n",
      "95 Train Loss 1.531276 Test MSE 1.7603369717974324 Test RE 0.6341703972052906\n",
      "96 Train Loss 1.5078176 Test MSE 1.7458127528385057 Test RE 0.6315487662736039\n",
      "97 Train Loss 1.4651296 Test MSE 1.7269273918894656 Test RE 0.6281235830047949\n",
      "98 Train Loss 1.3465428 Test MSE 1.7965112249726682 Test RE 0.6406532414353225\n",
      "99 Train Loss 1.2860748 Test MSE 1.8251700412794323 Test RE 0.6457430283083166\n",
      "Training time: 72.82\n",
      "KG_stan_tune15\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.55084 Test MSE 8.54597337440338 Test RE 1.3972973261140194\n",
      "1 Train Loss 57.201523 Test MSE 8.414477785286417 Test RE 1.3865056522872572\n",
      "2 Train Loss 49.43892 Test MSE 8.672319918240229 Test RE 1.4075884854282328\n",
      "3 Train Loss 48.82344 Test MSE 8.565772109547797 Test RE 1.398914971878903\n",
      "4 Train Loss 47.826138 Test MSE 8.697467119263449 Test RE 1.4096278063878396\n",
      "5 Train Loss 47.027737 Test MSE 8.600810760804961 Test RE 1.4017732122028534\n",
      "6 Train Loss 46.76863 Test MSE 8.60503579680453 Test RE 1.402117471324766\n",
      "7 Train Loss 46.561737 Test MSE 8.573499043004324 Test RE 1.3995457898697323\n",
      "8 Train Loss 46.200226 Test MSE 8.580871237594966 Test RE 1.4001473824515591\n",
      "9 Train Loss 45.710728 Test MSE 8.28883563366313 Test RE 1.3761153021200347\n",
      "10 Train Loss 45.41728 Test MSE 8.324163275536696 Test RE 1.3790447376107666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 45.29973 Test MSE 8.248159110393898 Test RE 1.3727345843044523\n",
      "12 Train Loss 42.642517 Test MSE 7.482769595482406 Test RE 1.3074926215685592\n",
      "13 Train Loss 41.436966 Test MSE 7.383038293514589 Test RE 1.2987501800378172\n",
      "14 Train Loss 40.748474 Test MSE 7.509416924643475 Test RE 1.3098186468577093\n",
      "15 Train Loss 40.51958 Test MSE 7.535309556775983 Test RE 1.312074845201865\n",
      "16 Train Loss 40.331577 Test MSE 7.475495710319352 Test RE 1.306856970326822\n",
      "17 Train Loss 39.95727 Test MSE 7.656643871867413 Test RE 1.3225962409948682\n",
      "18 Train Loss 39.58934 Test MSE 7.4788239717552045 Test RE 1.3071478592391923\n",
      "19 Train Loss 39.36813 Test MSE 7.491178072517417 Test RE 1.3082270377995795\n",
      "20 Train Loss 38.39545 Test MSE 7.656314534528389 Test RE 1.3225677960901596\n",
      "21 Train Loss 37.396416 Test MSE 7.66313416652064 Test RE 1.3231566837372055\n",
      "22 Train Loss 36.646828 Test MSE 7.641157057675649 Test RE 1.321257980360038\n",
      "23 Train Loss 36.045864 Test MSE 7.45809083947648 Test RE 1.3053347347094526\n",
      "24 Train Loss 35.611095 Test MSE 7.353025931098586 Test RE 1.2961077547494553\n",
      "25 Train Loss 35.42617 Test MSE 7.3162277334150465 Test RE 1.2928605031235605\n",
      "26 Train Loss 35.243507 Test MSE 7.212096976786501 Test RE 1.2836269871154986\n",
      "27 Train Loss 35.129242 Test MSE 7.16859892563612 Test RE 1.2797501870206907\n",
      "28 Train Loss 35.012173 Test MSE 7.31713329607981 Test RE 1.2929405122498157\n",
      "29 Train Loss 34.809692 Test MSE 7.308698283646208 Test RE 1.2921950622421459\n",
      "30 Train Loss 34.754025 Test MSE 7.324132503955819 Test RE 1.2935587459210232\n",
      "31 Train Loss 34.640095 Test MSE 7.206152335309816 Test RE 1.2830978570080291\n",
      "32 Train Loss 34.38835 Test MSE 7.307473335843228 Test RE 1.2920867708768782\n",
      "33 Train Loss 34.329697 Test MSE 7.28759098141835 Test RE 1.2903278027582818\n",
      "34 Train Loss 34.098175 Test MSE 7.327074174025117 Test RE 1.2938184927946121\n",
      "35 Train Loss 33.987247 Test MSE 7.373249598954369 Test RE 1.2978889299012053\n",
      "36 Train Loss 33.713318 Test MSE 7.240315038881202 Test RE 1.2861356961114212\n",
      "37 Train Loss 33.649776 Test MSE 7.3080520427122835 Test RE 1.2921379325200246\n",
      "38 Train Loss 33.495853 Test MSE 7.176715834702649 Test RE 1.2804745040892982\n",
      "39 Train Loss 33.297012 Test MSE 7.194446453745395 Test RE 1.2820552828675333\n",
      "40 Train Loss 33.110935 Test MSE 7.121923152069836 Test RE 1.2755770646658346\n",
      "41 Train Loss 32.993713 Test MSE 7.186260193968684 Test RE 1.281325676713404\n",
      "42 Train Loss 32.854527 Test MSE 7.153731695702882 Test RE 1.278422436954707\n",
      "43 Train Loss 32.718517 Test MSE 7.173781439746895 Test RE 1.2802126989564615\n",
      "44 Train Loss 32.623917 Test MSE 7.199495695206992 Test RE 1.282505093101779\n",
      "45 Train Loss 32.50019 Test MSE 7.162688936010056 Test RE 1.279222547666002\n",
      "46 Train Loss 32.39846 Test MSE 7.10539309621423 Test RE 1.2740958910607945\n",
      "47 Train Loss 32.339092 Test MSE 7.103198069298526 Test RE 1.2738990764187612\n",
      "48 Train Loss 32.29104 Test MSE 7.126499749738227 Test RE 1.2759868462194481\n",
      "49 Train Loss 32.25612 Test MSE 7.107848865231568 Test RE 1.2743160488245566\n",
      "50 Train Loss 32.17579 Test MSE 7.133529926428277 Test RE 1.2766160612686834\n",
      "51 Train Loss 32.14125 Test MSE 7.108483848684658 Test RE 1.2743729684038316\n",
      "52 Train Loss 32.045982 Test MSE 7.0677071429239495 Test RE 1.2707125909541932\n",
      "53 Train Loss 31.959826 Test MSE 7.07881919153776 Test RE 1.2717111237248646\n",
      "54 Train Loss 31.858612 Test MSE 7.06410474889409 Test RE 1.2703887100401694\n",
      "55 Train Loss 31.782822 Test MSE 7.053363934775566 Test RE 1.2694225437559694\n",
      "56 Train Loss 31.728695 Test MSE 7.102149759534634 Test RE 1.2738050701625194\n",
      "57 Train Loss 31.584084 Test MSE 7.0663653854991235 Test RE 1.2705919670412955\n",
      "58 Train Loss 31.514156 Test MSE 7.048427746645176 Test RE 1.2689782731040815\n",
      "59 Train Loss 31.39772 Test MSE 7.041156179569602 Test RE 1.268323528380403\n",
      "60 Train Loss 31.34002 Test MSE 6.996756485499225 Test RE 1.2643183458325846\n",
      "61 Train Loss 31.262968 Test MSE 6.9984327404799505 Test RE 1.2644697869331476\n",
      "62 Train Loss 31.124195 Test MSE 6.9814811583651055 Test RE 1.2629374610704625\n",
      "63 Train Loss 31.055813 Test MSE 6.987107982378635 Test RE 1.263446299767281\n",
      "64 Train Loss 30.920712 Test MSE 6.983566693413317 Test RE 1.263126081766141\n",
      "65 Train Loss 30.836914 Test MSE 6.988215993130565 Test RE 1.26354647401629\n",
      "66 Train Loss 30.69506 Test MSE 7.025059174439044 Test RE 1.2668729219947332\n",
      "67 Train Loss 30.62913 Test MSE 7.033061120181617 Test RE 1.2675942371460995\n",
      "68 Train Loss 30.438875 Test MSE 7.047443301947725 Test RE 1.2688896517405674\n",
      "69 Train Loss 30.264677 Test MSE 7.026197107564541 Test RE 1.2669755231439674\n",
      "70 Train Loss 30.041565 Test MSE 6.968993034994539 Test RE 1.261807415905607\n",
      "71 Train Loss 29.971632 Test MSE 6.942151762091723 Test RE 1.2593751282443033\n",
      "72 Train Loss 29.749903 Test MSE 6.931123866670332 Test RE 1.2583744459205979\n",
      "73 Train Loss 29.644772 Test MSE 6.979071342755353 Test RE 1.2627194765903316\n",
      "74 Train Loss 29.563213 Test MSE 6.962509985865546 Test RE 1.2612203681929814\n",
      "75 Train Loss 29.489998 Test MSE 6.918510771835848 Test RE 1.2572289445576597\n",
      "76 Train Loss 29.38023 Test MSE 6.877308951019444 Test RE 1.2534797653448095\n",
      "77 Train Loss 29.305546 Test MSE 6.876940811690771 Test RE 1.2534462157850803\n",
      "78 Train Loss 29.152798 Test MSE 6.89463652705434 Test RE 1.2550578609641854\n",
      "79 Train Loss 29.011774 Test MSE 6.893201426311856 Test RE 1.2549272356443308\n",
      "80 Train Loss 28.893375 Test MSE 6.909150929943265 Test RE 1.2563782234135286\n",
      "81 Train Loss 28.844355 Test MSE 6.970944767989288 Test RE 1.261984094139605\n",
      "82 Train Loss 28.706211 Test MSE 6.9790902437390185 Test RE 1.262721186461378\n",
      "83 Train Loss 28.60564 Test MSE 6.959998591782635 Test RE 1.2609928850689354\n",
      "84 Train Loss 28.472763 Test MSE 6.981145236362449 Test RE 1.2629070768600816\n",
      "85 Train Loss 28.327858 Test MSE 6.98420428983324 Test RE 1.2631837418645897\n",
      "86 Train Loss 28.16849 Test MSE 6.95970708983935 Test RE 1.260966478043092\n",
      "87 Train Loss 27.942795 Test MSE 6.995415856617302 Test RE 1.2641972137841604\n",
      "88 Train Loss 27.552774 Test MSE 6.9433218119962845 Test RE 1.259481253096945\n",
      "89 Train Loss 27.363955 Test MSE 6.868330110591564 Test RE 1.2526612423755394\n",
      "90 Train Loss 27.137419 Test MSE 6.859286701488447 Test RE 1.2518362922559807\n",
      "91 Train Loss 27.034237 Test MSE 6.83508389876155 Test RE 1.2496258058184322\n",
      "92 Train Loss 26.995722 Test MSE 6.837244165441762 Test RE 1.2498232658470658\n",
      "93 Train Loss 26.95105 Test MSE 6.804046588263619 Test RE 1.2467853758746557\n",
      "94 Train Loss 26.86005 Test MSE 6.7849933024707 Test RE 1.2450384733833346\n",
      "95 Train Loss 26.772625 Test MSE 6.775536430737988 Test RE 1.2441705082897558\n",
      "96 Train Loss 26.585724 Test MSE 6.769028768939154 Test RE 1.2435728739888459\n",
      "97 Train Loss 26.417057 Test MSE 6.70217144030321 Test RE 1.2374162833999556\n",
      "98 Train Loss 26.242367 Test MSE 6.74766418878058 Test RE 1.2416088249073591\n",
      "99 Train Loss 26.095633 Test MSE 6.811923187329537 Test RE 1.2475068280227863\n",
      "Training time: 72.83\n",
      "KG_stan_tune15\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.563286 Test MSE 8.562878880793352 Test RE 1.3986786987913864\n",
      "1 Train Loss 54.934628 Test MSE 8.438735349324634 Test RE 1.388502748577359\n",
      "2 Train Loss 52.093124 Test MSE 7.93584982367751 Test RE 1.346495110307844\n",
      "3 Train Loss 43.345444 Test MSE 8.861989786232332 Test RE 1.422897717979344\n",
      "4 Train Loss 40.910156 Test MSE 9.27278554833861 Test RE 1.4555032123036693\n",
      "5 Train Loss 40.721375 Test MSE 9.263570774242115 Test RE 1.45477983382472\n",
      "6 Train Loss 40.49034 Test MSE 9.509378131260464 Test RE 1.4739546406933783\n",
      "7 Train Loss 39.325443 Test MSE 9.427627769923754 Test RE 1.467605307796595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 36.606094 Test MSE 9.033940833004372 Test RE 1.436635788922569\n",
      "9 Train Loss 33.043785 Test MSE 8.352335712410094 Test RE 1.3813763974427553\n",
      "10 Train Loss 31.589119 Test MSE 8.241724804526541 Test RE 1.3721990516299167\n",
      "11 Train Loss 30.777477 Test MSE 8.584652120099063 Test RE 1.400455813238413\n",
      "12 Train Loss 29.860096 Test MSE 8.931569647424194 Test RE 1.4284727328986384\n",
      "13 Train Loss 28.883259 Test MSE 9.275506101285385 Test RE 1.4557167125045862\n",
      "14 Train Loss 28.044418 Test MSE 9.20001358043992 Test RE 1.4497806349706284\n",
      "15 Train Loss 26.998917 Test MSE 9.354040678777512 Test RE 1.4618664105774546\n",
      "16 Train Loss 26.082333 Test MSE 9.46828522796438 Test RE 1.4707664904920679\n",
      "17 Train Loss 25.163986 Test MSE 9.223526823214115 Test RE 1.4516321154318814\n",
      "18 Train Loss 24.583128 Test MSE 9.428129499263228 Test RE 1.4676443595529367\n",
      "19 Train Loss 23.998293 Test MSE 9.337441472093658 Test RE 1.4605687575997606\n",
      "20 Train Loss 23.512657 Test MSE 9.419157959818788 Test RE 1.4669459090757313\n",
      "21 Train Loss 23.079603 Test MSE 9.308216054540882 Test RE 1.4582812367083837\n",
      "22 Train Loss 22.891638 Test MSE 9.358061925804368 Test RE 1.4621806006964029\n",
      "23 Train Loss 22.653448 Test MSE 9.345396073774463 Test RE 1.4611907571794127\n",
      "24 Train Loss 22.43919 Test MSE 9.450702162230309 Test RE 1.4694002134677713\n",
      "25 Train Loss 22.217842 Test MSE 9.4411007746555 Test RE 1.4686536093616287\n",
      "26 Train Loss 22.05184 Test MSE 9.359292194853298 Test RE 1.4622767112175927\n",
      "27 Train Loss 21.871819 Test MSE 9.278178772617855 Test RE 1.4559264246247459\n",
      "28 Train Loss 21.774868 Test MSE 9.258398587167386 Test RE 1.454373648984385\n",
      "29 Train Loss 21.621563 Test MSE 9.218234288687599 Test RE 1.4512155765271086\n",
      "30 Train Loss 21.543364 Test MSE 9.285903841949834 Test RE 1.4565324052117796\n",
      "31 Train Loss 21.43415 Test MSE 9.352707704847127 Test RE 1.4617622470769946\n",
      "32 Train Loss 21.34959 Test MSE 9.312850401742054 Test RE 1.4586442139186095\n",
      "33 Train Loss 21.20359 Test MSE 9.206061528289064 Test RE 1.4502570884589916\n",
      "34 Train Loss 21.130846 Test MSE 9.229291189017664 Test RE 1.4520856529838322\n",
      "35 Train Loss 20.992195 Test MSE 9.274048907340116 Test RE 1.4556023605287431\n",
      "36 Train Loss 20.899044 Test MSE 9.250043709497314 Test RE 1.4537172797229667\n",
      "37 Train Loss 20.800982 Test MSE 9.18990156030424 Test RE 1.4489836664969742\n",
      "38 Train Loss 20.669857 Test MSE 9.198073694046794 Test RE 1.4496277787834149\n",
      "39 Train Loss 20.332737 Test MSE 9.035749405570508 Test RE 1.4367795871881932\n",
      "40 Train Loss 20.14347 Test MSE 9.011109240913445 Test RE 1.434819226607925\n",
      "41 Train Loss 19.598257 Test MSE 8.641033163688745 Test RE 1.4050471431481215\n",
      "42 Train Loss 17.485415 Test MSE 7.676501811760226 Test RE 1.3243102445338824\n",
      "43 Train Loss 16.563095 Test MSE 7.021606787838613 Test RE 1.2665615884899486\n",
      "44 Train Loss 16.126886 Test MSE 6.9330487327964905 Test RE 1.2585491675274683\n",
      "45 Train Loss 15.743301 Test MSE 7.017164196267069 Test RE 1.2661608464436205\n",
      "46 Train Loss 15.289253 Test MSE 6.993418676411331 Test RE 1.264016737745422\n",
      "47 Train Loss 14.919946 Test MSE 7.032900892757369 Test RE 1.2675797978775554\n",
      "48 Train Loss 14.4535885 Test MSE 6.8651772745529 Test RE 1.252373698766936\n",
      "49 Train Loss 13.828352 Test MSE 6.706536194971779 Test RE 1.2378191483138021\n",
      "50 Train Loss 12.186379 Test MSE 6.29147925543946 Test RE 1.1989040982534034\n",
      "51 Train Loss 11.759848 Test MSE 6.298864060174869 Test RE 1.1996075159842057\n",
      "52 Train Loss 11.345106 Test MSE 6.3417862361458965 Test RE 1.2036878029755558\n",
      "53 Train Loss 11.074033 Test MSE 6.046232744033021 Test RE 1.1753047483243357\n",
      "54 Train Loss 10.845418 Test MSE 5.979232615988724 Test RE 1.1687746543010578\n",
      "55 Train Loss 10.579955 Test MSE 6.0285819022907345 Test RE 1.1735879536275073\n",
      "56 Train Loss 10.279407 Test MSE 6.028942640995208 Test RE 1.1736230657211792\n",
      "57 Train Loss 10.177685 Test MSE 6.049003635044704 Test RE 1.1755740290872407\n",
      "58 Train Loss 10.090509 Test MSE 5.991083368949412 Test RE 1.1699323282306116\n",
      "59 Train Loss 9.957714 Test MSE 6.063898040718887 Test RE 1.177020441789139\n",
      "60 Train Loss 9.868301 Test MSE 6.079495797031753 Test RE 1.1785332547714964\n",
      "61 Train Loss 9.827068 Test MSE 6.075962922744052 Test RE 1.1781907744877838\n",
      "62 Train Loss 9.787223 Test MSE 6.097346719693828 Test RE 1.1802622209701612\n",
      "63 Train Loss 9.710857 Test MSE 6.0920068185278025 Test RE 1.1797452859496476\n",
      "64 Train Loss 9.666852 Test MSE 6.103098566627395 Test RE 1.1808187816923708\n",
      "65 Train Loss 9.587744 Test MSE 6.014838516806504 Test RE 1.172249473469134\n",
      "66 Train Loss 9.550041 Test MSE 6.022672876281092 Test RE 1.1730126556555247\n",
      "67 Train Loss 9.509372 Test MSE 6.057742642945941 Test RE 1.1764228997065562\n",
      "68 Train Loss 9.468373 Test MSE 6.024442886204585 Test RE 1.173185011979581\n",
      "69 Train Loss 9.427545 Test MSE 6.0210268742073305 Test RE 1.1728523519795215\n",
      "70 Train Loss 9.38259 Test MSE 6.023632439167995 Test RE 1.1731060971061618\n",
      "71 Train Loss 9.31061 Test MSE 5.972058070482044 Test RE 1.1680732311892372\n",
      "72 Train Loss 9.24599 Test MSE 6.024952567594502 Test RE 1.1732346379725873\n",
      "73 Train Loss 8.959753 Test MSE 5.754536009482403 Test RE 1.146603376384289\n",
      "74 Train Loss 8.615925 Test MSE 5.310404566933236 Test RE 1.1014679494559363\n",
      "75 Train Loss 8.226095 Test MSE 5.260554465361333 Test RE 1.0962858812791518\n",
      "76 Train Loss 8.009725 Test MSE 5.091696835184346 Test RE 1.0785476303549606\n",
      "77 Train Loss 7.825738 Test MSE 4.989267028117243 Test RE 1.0676439278700098\n",
      "78 Train Loss 7.6858106 Test MSE 5.049513474789796 Test RE 1.074070597510397\n",
      "79 Train Loss 7.6044292 Test MSE 5.214642747657991 Test RE 1.0914914561311084\n",
      "80 Train Loss 7.5775137 Test MSE 5.205862022982095 Test RE 1.0905721099371481\n",
      "81 Train Loss 7.5166388 Test MSE 5.240365850527204 Test RE 1.0941802316696245\n",
      "82 Train Loss 7.4696407 Test MSE 5.320322252623959 Test RE 1.1024960177633847\n",
      "83 Train Loss 7.4270334 Test MSE 5.320552077440688 Test RE 1.1025198300624237\n",
      "84 Train Loss 7.4048824 Test MSE 5.302593628624673 Test RE 1.1006575908393013\n",
      "85 Train Loss 7.381237 Test MSE 5.267018823749047 Test RE 1.0969592522223948\n",
      "86 Train Loss 7.340794 Test MSE 5.2412217544557125 Test RE 1.0942695837252507\n",
      "87 Train Loss 7.2985687 Test MSE 5.266311907741916 Test RE 1.0968856352388692\n",
      "88 Train Loss 7.278056 Test MSE 5.273559929908523 Test RE 1.0976401972489465\n",
      "89 Train Loss 7.2592936 Test MSE 5.2890732678417915 Test RE 1.0992534868456654\n",
      "90 Train Loss 7.2371826 Test MSE 5.27362836490749 Test RE 1.097647319265484\n",
      "91 Train Loss 7.202257 Test MSE 5.23288534014968 Test RE 1.093398993309003\n",
      "92 Train Loss 7.1656656 Test MSE 5.189375946788735 Test RE 1.088843912790307\n",
      "93 Train Loss 7.1281915 Test MSE 5.209267255174248 Test RE 1.0909287313910072\n",
      "94 Train Loss 7.0959845 Test MSE 5.171214775985862 Test RE 1.0869369386088452\n",
      "95 Train Loss 7.0624046 Test MSE 5.1753419418941125 Test RE 1.0873705963238645\n",
      "96 Train Loss 7.022671 Test MSE 5.090956933828097 Test RE 1.0784692627818804\n",
      "97 Train Loss 6.9811974 Test MSE 5.027987337992499 Test RE 1.0717787644230037\n",
      "98 Train Loss 6.930767 Test MSE 4.9276880410124395 Test RE 1.0610348856858476\n",
      "99 Train Loss 6.9031096 Test MSE 4.936230107328926 Test RE 1.0619541307614322\n",
      "Training time: 72.45\n",
      "KG_stan_tune15\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.634346 Test MSE 8.579499812353856 Test RE 1.4000354897230867\n",
      "1 Train Loss 50.207726 Test MSE 7.632464355494594 Test RE 1.3205062244174528\n",
      "2 Train Loss 46.077053 Test MSE 8.70904023713476 Test RE 1.4105653417205073\n",
      "3 Train Loss 43.18508 Test MSE 8.177638031396567 Test RE 1.366853603198425\n",
      "4 Train Loss 41.59369 Test MSE 7.1013470382963275 Test RE 1.2737330821510104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 36.854492 Test MSE 7.530725623067849 Test RE 1.3116756990862322\n",
      "6 Train Loss 35.934303 Test MSE 7.452909591893121 Test RE 1.3048812381224275\n",
      "7 Train Loss 34.166916 Test MSE 7.028537092799497 Test RE 1.2671864805917672\n",
      "8 Train Loss 33.044518 Test MSE 6.611019774127547 Test RE 1.2289728489898597\n",
      "9 Train Loss 31.245667 Test MSE 6.376698584905056 Test RE 1.2069964836198905\n",
      "10 Train Loss 29.963879 Test MSE 6.557133309127382 Test RE 1.2239539179025265\n",
      "11 Train Loss 28.723022 Test MSE 6.118019959708717 Test RE 1.1822613853755115\n",
      "12 Train Loss 28.048231 Test MSE 6.269141550071659 Test RE 1.196773869511505\n",
      "13 Train Loss 27.192533 Test MSE 5.501286414524627 Test RE 1.1210892506178511\n",
      "14 Train Loss 26.870192 Test MSE 5.183785287045053 Test RE 1.0882572337467944\n",
      "15 Train Loss 26.443064 Test MSE 5.38166604141932 Test RE 1.1088337400700485\n",
      "16 Train Loss 26.07956 Test MSE 5.622841058684856 Test RE 1.1334071917019164\n",
      "17 Train Loss 25.497318 Test MSE 5.500153875200359 Test RE 1.1209738464269114\n",
      "18 Train Loss 24.894054 Test MSE 5.596671622434911 Test RE 1.1307666031995707\n",
      "19 Train Loss 24.123236 Test MSE 5.700711912853945 Test RE 1.1412284964913444\n",
      "20 Train Loss 23.501091 Test MSE 5.400790625738216 Test RE 1.1108021990850896\n",
      "21 Train Loss 23.335487 Test MSE 5.469031845341656 Test RE 1.1177978923089973\n",
      "22 Train Loss 23.022692 Test MSE 5.531664224360632 Test RE 1.1241802868483985\n",
      "23 Train Loss 22.894075 Test MSE 5.512152651822265 Test RE 1.1221959019816887\n",
      "24 Train Loss 22.700401 Test MSE 5.424994529710572 Test RE 1.1132884734551465\n",
      "25 Train Loss 22.435265 Test MSE 5.577440910200446 Test RE 1.1288222190501427\n",
      "26 Train Loss 22.283014 Test MSE 5.566103660995721 Test RE 1.127674358489007\n",
      "27 Train Loss 22.200525 Test MSE 5.463882614694155 Test RE 1.1172715510137656\n",
      "28 Train Loss 21.662165 Test MSE 5.189962258494944 Test RE 1.0889054215254337\n",
      "29 Train Loss 20.536158 Test MSE 4.6951346638828175 Test RE 1.0356954940720504\n",
      "30 Train Loss 18.557137 Test MSE 4.434967329334122 Test RE 1.0065915324120132\n",
      "31 Train Loss 16.796381 Test MSE 3.940079447942851 Test RE 0.9487691390591446\n",
      "32 Train Loss 14.672928 Test MSE 4.2581193858694 Test RE 0.9863180413032914\n",
      "33 Train Loss 13.563124 Test MSE 3.677260927963267 Test RE 0.916579804378384\n",
      "34 Train Loss 12.74445 Test MSE 3.7193548137475134 Test RE 0.9218109560277744\n",
      "35 Train Loss 12.20326 Test MSE 3.50828119464069 Test RE 0.8952725278818218\n",
      "36 Train Loss 11.652311 Test MSE 3.7051933473013863 Test RE 0.920054381934658\n",
      "37 Train Loss 11.229974 Test MSE 3.8870532368388635 Test RE 0.9423631705041257\n",
      "38 Train Loss 10.938545 Test MSE 3.9456170758525784 Test RE 0.9494356339587159\n",
      "39 Train Loss 10.73031 Test MSE 4.062614201541358 Test RE 0.9634093379508015\n",
      "40 Train Loss 10.577639 Test MSE 4.086271237095005 Test RE 0.9662102839529937\n",
      "41 Train Loss 10.332293 Test MSE 4.133402479570312 Test RE 0.9717664657450545\n",
      "42 Train Loss 10.081391 Test MSE 4.169661845345942 Test RE 0.9760194629758716\n",
      "43 Train Loss 10.002306 Test MSE 4.236701806923951 Test RE 0.9838344126420017\n",
      "44 Train Loss 9.818128 Test MSE 4.10925365213704 Test RE 0.9689236023904412\n",
      "45 Train Loss 9.750716 Test MSE 4.184325604670342 Test RE 0.9777341767812111\n",
      "46 Train Loss 9.664089 Test MSE 4.201542948372457 Test RE 0.9797436647723141\n",
      "47 Train Loss 9.559951 Test MSE 4.233822670272554 Test RE 0.9835000635131667\n",
      "48 Train Loss 9.393114 Test MSE 4.296126143379945 Test RE 0.9907100591721084\n",
      "49 Train Loss 9.297556 Test MSE 4.335114418274529 Test RE 0.9951953600283621\n",
      "50 Train Loss 9.161272 Test MSE 4.328374711400556 Test RE 0.9944214549681302\n",
      "51 Train Loss 9.058734 Test MSE 4.309985121818221 Test RE 0.9923067504172863\n",
      "52 Train Loss 8.784734 Test MSE 4.426298342994243 Test RE 1.0056072639848017\n",
      "53 Train Loss 8.585456 Test MSE 4.415561561335281 Test RE 1.0043868829518225\n",
      "54 Train Loss 8.376638 Test MSE 4.445805306127247 Test RE 1.0078207138245754\n",
      "55 Train Loss 8.169225 Test MSE 4.413308999489927 Test RE 1.0041306604810933\n",
      "56 Train Loss 8.002651 Test MSE 4.365948583983294 Test RE 0.9987283287262182\n",
      "57 Train Loss 7.7878227 Test MSE 4.379953706685504 Test RE 1.000328910286513\n",
      "58 Train Loss 7.665845 Test MSE 4.321263753541848 Test RE 0.9936042665056664\n",
      "59 Train Loss 7.467621 Test MSE 4.3313771718716865 Test RE 0.9947662949732967\n",
      "60 Train Loss 7.378832 Test MSE 4.311097526982677 Test RE 0.9924347991119189\n",
      "61 Train Loss 7.1798544 Test MSE 4.294443998174983 Test RE 0.9905160842650791\n",
      "62 Train Loss 7.0574665 Test MSE 4.330264377201167 Test RE 0.9946385016992485\n",
      "63 Train Loss 6.9776087 Test MSE 4.312253056588096 Test RE 0.9925677943584683\n",
      "64 Train Loss 6.6831293 Test MSE 4.198622204449369 Test RE 0.9794030663448907\n",
      "65 Train Loss 6.000083 Test MSE 3.723963688127408 Test RE 0.9223819146724911\n",
      "66 Train Loss 5.042551 Test MSE 2.62638931193373 Test RE 0.7746180479480252\n",
      "67 Train Loss 4.2174015 Test MSE 2.3676969596551443 Test RE 0.7354804252690152\n",
      "68 Train Loss 3.4954047 Test MSE 2.1956944704862105 Test RE 0.7082621189083783\n",
      "69 Train Loss 3.2297513 Test MSE 2.207505886770627 Test RE 0.7101645599457785\n",
      "70 Train Loss 3.1154397 Test MSE 2.241054152689336 Test RE 0.7155405257619448\n",
      "71 Train Loss 3.0660536 Test MSE 2.2322703684716174 Test RE 0.7141368728617353\n",
      "72 Train Loss 2.9943633 Test MSE 2.187606307127639 Test RE 0.7069564215506713\n",
      "73 Train Loss 2.9301174 Test MSE 2.225921592904623 Test RE 0.7131206153585177\n",
      "74 Train Loss 2.901043 Test MSE 2.2315735385688424 Test RE 0.7140254009772772\n",
      "75 Train Loss 2.8662658 Test MSE 2.207647120112838 Test RE 0.7101872772827345\n",
      "76 Train Loss 2.8323646 Test MSE 2.195479241653854 Test RE 0.7082274050247507\n",
      "77 Train Loss 2.8110995 Test MSE 2.215074303325898 Test RE 0.7113809150735356\n",
      "78 Train Loss 2.783782 Test MSE 2.2155051345452095 Test RE 0.7114500933862477\n",
      "79 Train Loss 2.7689633 Test MSE 2.2119614295784507 Test RE 0.7108808827464005\n",
      "80 Train Loss 2.7499104 Test MSE 2.2069697986778922 Test RE 0.710078323736114\n",
      "81 Train Loss 2.7260752 Test MSE 2.2184661726038417 Test RE 0.7119253636437588\n",
      "82 Train Loss 2.709187 Test MSE 2.218115455252294 Test RE 0.7118690872736116\n",
      "83 Train Loss 2.6935067 Test MSE 2.2105677501329755 Test RE 0.710656896882982\n",
      "84 Train Loss 2.6863787 Test MSE 2.2133502125239377 Test RE 0.7111040114860451\n",
      "85 Train Loss 2.6705134 Test MSE 2.1948126713249696 Test RE 0.7081198842604614\n",
      "86 Train Loss 2.6541595 Test MSE 2.201620774478116 Test RE 0.7092172946523865\n",
      "87 Train Loss 2.648262 Test MSE 2.2003392347604565 Test RE 0.7090108507351641\n",
      "88 Train Loss 2.6387656 Test MSE 2.191452984438586 Test RE 0.7075777030874326\n",
      "89 Train Loss 2.635145 Test MSE 2.1910021511985605 Test RE 0.7075049166852538\n",
      "90 Train Loss 2.6248796 Test MSE 2.177307733045099 Test RE 0.7052903923296249\n",
      "91 Train Loss 2.611833 Test MSE 2.180737655459025 Test RE 0.7058456972451048\n",
      "92 Train Loss 2.6003013 Test MSE 2.1702140740544182 Test RE 0.7041405385172225\n",
      "93 Train Loss 2.5976295 Test MSE 2.166814224918329 Test RE 0.7035887703847512\n",
      "94 Train Loss 2.593249 Test MSE 2.1650436654187257 Test RE 0.7033012514194367\n",
      "95 Train Loss 2.5889804 Test MSE 2.1682414527821754 Test RE 0.7038204506513811\n",
      "96 Train Loss 2.5817082 Test MSE 2.1609244538138026 Test RE 0.7026318824788869\n",
      "97 Train Loss 2.5766132 Test MSE 2.164285168811029 Test RE 0.7031780441252463\n",
      "98 Train Loss 2.5729828 Test MSE 2.156250625556367 Test RE 0.7018716156446764\n",
      "99 Train Loss 2.5633056 Test MSE 2.1439939741228615 Test RE 0.6998739685900361\n",
      "Training time: 72.62\n",
      "KG_stan_tune15\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.579502 Test MSE 8.630982895912314 Test RE 1.4042298098406438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 54.48649 Test MSE 8.208127974043597 Test RE 1.3693993574837986\n",
      "2 Train Loss 45.510567 Test MSE 8.14756511876946 Test RE 1.3643380156175515\n",
      "3 Train Loss 43.691513 Test MSE 8.534674430176613 Test RE 1.3963733116229389\n",
      "4 Train Loss 43.50827 Test MSE 8.499074426529772 Test RE 1.3934579782637273\n",
      "5 Train Loss 43.41755 Test MSE 8.463815206610361 Test RE 1.3905645276209013\n",
      "6 Train Loss 43.346436 Test MSE 8.525577827227641 Test RE 1.3956289575097374\n",
      "7 Train Loss 43.236923 Test MSE 8.42539119190978 Test RE 1.3874044957581266\n",
      "8 Train Loss 43.205177 Test MSE 8.440122786905608 Test RE 1.3886168878196523\n",
      "9 Train Loss 42.871933 Test MSE 8.336628686342426 Test RE 1.380076909121024\n",
      "10 Train Loss 42.71291 Test MSE 8.312719041831 Test RE 1.3780964417958583\n",
      "11 Train Loss 42.690514 Test MSE 8.335433590795885 Test RE 1.3799779852667975\n",
      "12 Train Loss 42.60838 Test MSE 8.281332513942926 Test RE 1.3754923258674656\n",
      "13 Train Loss 42.44025 Test MSE 8.27833055807291 Test RE 1.375242997542278\n",
      "14 Train Loss 42.169807 Test MSE 8.496468269458536 Test RE 1.3932443168330684\n",
      "15 Train Loss 41.032196 Test MSE 8.295449617671515 Test RE 1.376664220574757\n",
      "16 Train Loss 39.74095 Test MSE 7.436042156292624 Test RE 1.3034037971742403\n",
      "17 Train Loss 39.237953 Test MSE 7.885670132253906 Test RE 1.3422313037503866\n",
      "18 Train Loss 38.999104 Test MSE 7.847891714497276 Test RE 1.339012284199692\n",
      "19 Train Loss 38.763134 Test MSE 7.749603372855387 Test RE 1.330600854937655\n",
      "20 Train Loss 38.52591 Test MSE 7.829236602624337 Test RE 1.3374198637702102\n",
      "21 Train Loss 38.435314 Test MSE 7.8536894642211905 Test RE 1.339506800759455\n",
      "22 Train Loss 38.296383 Test MSE 7.87207438318165 Test RE 1.34107372854484\n",
      "23 Train Loss 38.170418 Test MSE 7.889919690044047 Test RE 1.3425929167238717\n",
      "24 Train Loss 38.105312 Test MSE 7.836219107072355 Test RE 1.3380161197914087\n",
      "25 Train Loss 37.986755 Test MSE 7.8032251209232575 Test RE 1.3351963254546024\n",
      "26 Train Loss 37.461296 Test MSE 7.718927228906679 Test RE 1.3279647086155146\n",
      "27 Train Loss 37.185627 Test MSE 7.776072130946026 Test RE 1.3328712505171891\n",
      "28 Train Loss 35.60634 Test MSE 7.144306996787877 Test RE 1.2775800292369546\n",
      "29 Train Loss 32.99962 Test MSE 7.370917948906158 Test RE 1.2976836973216241\n",
      "30 Train Loss 32.560307 Test MSE 7.2118471774540716 Test RE 1.2836047569692548\n",
      "31 Train Loss 32.382442 Test MSE 7.1701462314616125 Test RE 1.2798882933717\n",
      "32 Train Loss 31.984547 Test MSE 7.278408847903548 Test RE 1.2895146604894503\n",
      "33 Train Loss 31.781136 Test MSE 7.135758473925165 Test RE 1.2768154560559863\n",
      "34 Train Loss 31.548271 Test MSE 7.089210525624806 Test RE 1.2726441839358278\n",
      "35 Train Loss 31.416405 Test MSE 7.123286641752138 Test RE 1.275699163212354\n",
      "36 Train Loss 31.215946 Test MSE 7.136414100446611 Test RE 1.276874110987457\n",
      "37 Train Loss 31.10906 Test MSE 7.1809515664256445 Test RE 1.280852319413063\n",
      "38 Train Loss 30.913723 Test MSE 7.155977603726138 Test RE 1.2786231010284757\n",
      "39 Train Loss 30.78471 Test MSE 7.180138379080978 Test RE 1.2807797940397825\n",
      "40 Train Loss 30.40932 Test MSE 7.22716634834592 Test RE 1.284967329479592\n",
      "41 Train Loss 29.77018 Test MSE 7.16359908304607 Test RE 1.279303819073798\n",
      "42 Train Loss 28.91309 Test MSE 7.1881454613256714 Test RE 1.2814937393075565\n",
      "43 Train Loss 28.477573 Test MSE 7.113526328129596 Test RE 1.274824883358636\n",
      "44 Train Loss 27.709942 Test MSE 7.150344490662217 Test RE 1.2781197423743276\n",
      "45 Train Loss 25.96666 Test MSE 6.921667984738146 Test RE 1.2575157755559894\n",
      "46 Train Loss 24.27867 Test MSE 6.256095187732382 Test RE 1.195527951150993\n",
      "47 Train Loss 23.12098 Test MSE 5.58849688488235 Test RE 1.1299404784285711\n",
      "48 Train Loss 20.777487 Test MSE 4.885653895832 Test RE 1.0564997758206727\n",
      "49 Train Loss 18.83889 Test MSE 5.0359064124837944 Test RE 1.0726224575335244\n",
      "50 Train Loss 18.034618 Test MSE 5.040953194352593 Test RE 1.073159792380632\n",
      "51 Train Loss 17.208036 Test MSE 4.617066815626755 Test RE 1.02704894311487\n",
      "52 Train Loss 16.23302 Test MSE 4.477390595455707 Test RE 1.0113944162613275\n",
      "53 Train Loss 15.620842 Test MSE 4.246691045131806 Test RE 0.9849935655201209\n",
      "54 Train Loss 14.715269 Test MSE 4.178653882284047 Test RE 0.9770713080439806\n",
      "55 Train Loss 13.937866 Test MSE 4.082228204987358 Test RE 0.9657321725253427\n",
      "56 Train Loss 13.6760845 Test MSE 4.045264332894723 Test RE 0.9613499608216836\n",
      "57 Train Loss 13.105057 Test MSE 3.924646167640446 Test RE 0.9469091528347537\n",
      "58 Train Loss 12.763651 Test MSE 3.9527815669361397 Test RE 0.9502972403839308\n",
      "59 Train Loss 12.580814 Test MSE 3.9980297452878317 Test RE 0.9557208721638412\n",
      "60 Train Loss 12.299091 Test MSE 4.0467031579362684 Test RE 0.9615209127434222\n",
      "61 Train Loss 11.797415 Test MSE 3.9197907378036674 Test RE 0.9463232307351568\n",
      "62 Train Loss 11.579773 Test MSE 3.8340110846631403 Test RE 0.9359114109075796\n",
      "63 Train Loss 11.343127 Test MSE 3.8537135442657457 Test RE 0.938313089878347\n",
      "64 Train Loss 10.768295 Test MSE 3.891059614896809 Test RE 0.9428486913549324\n",
      "65 Train Loss 10.580006 Test MSE 3.83087248075029 Test RE 0.935528253873906\n",
      "66 Train Loss 10.255213 Test MSE 3.784561075309192 Test RE 0.9298562605050117\n",
      "67 Train Loss 9.855152 Test MSE 3.8296787820627505 Test RE 0.93538248735964\n",
      "68 Train Loss 9.643151 Test MSE 3.884195021938837 Test RE 0.9420166391328447\n",
      "69 Train Loss 9.239679 Test MSE 3.758712944146031 Test RE 0.926675412577526\n",
      "70 Train Loss 8.571466 Test MSE 3.834941717365214 Test RE 0.9360249912935511\n",
      "71 Train Loss 8.384202 Test MSE 3.8448692048921447 Test RE 0.9372357489925989\n",
      "72 Train Loss 8.076887 Test MSE 3.851677342506331 Test RE 0.9380651670389409\n",
      "73 Train Loss 7.807569 Test MSE 3.77279101974863 Test RE 0.9284091993718926\n",
      "74 Train Loss 7.5225554 Test MSE 3.6408125428840643 Test RE 0.9120260005568397\n",
      "75 Train Loss 7.269764 Test MSE 3.6274011955628147 Test RE 0.9103446750096533\n",
      "76 Train Loss 7.0756764 Test MSE 3.5905248063790642 Test RE 0.9057055437938234\n",
      "77 Train Loss 7.0019846 Test MSE 3.53640267411504 Test RE 0.8988535032879665\n",
      "78 Train Loss 6.87691 Test MSE 3.5252721829140015 Test RE 0.8974378605373334\n",
      "79 Train Loss 6.7699966 Test MSE 3.48160105054975 Test RE 0.891861799820136\n",
      "80 Train Loss 6.663163 Test MSE 3.4656411359980823 Test RE 0.88981527181836\n",
      "81 Train Loss 6.5543785 Test MSE 3.440778253539849 Test RE 0.8866177113268873\n",
      "82 Train Loss 6.3570957 Test MSE 3.3730290901904625 Test RE 0.8778455332185806\n",
      "83 Train Loss 6.229246 Test MSE 3.405239405672727 Test RE 0.882027011861508\n",
      "84 Train Loss 6.131746 Test MSE 3.4073792913049696 Test RE 0.8823041055217923\n",
      "85 Train Loss 6.046327 Test MSE 3.362365137947727 Test RE 0.8764567646466136\n",
      "86 Train Loss 5.96373 Test MSE 3.4268135722354938 Test RE 0.8848166766353845\n",
      "87 Train Loss 5.890237 Test MSE 3.390534265450874 Test RE 0.880120484539306\n",
      "88 Train Loss 5.792334 Test MSE 3.319464946311653 Test RE 0.8708474885296725\n",
      "89 Train Loss 5.650721 Test MSE 3.205355191448243 Test RE 0.8557484891202582\n",
      "90 Train Loss 5.5729313 Test MSE 3.216563448308217 Test RE 0.8572433435522261\n",
      "91 Train Loss 5.5030165 Test MSE 3.146044983214038 Test RE 0.8477943623757437\n",
      "92 Train Loss 5.413083 Test MSE 3.162392500163378 Test RE 0.8499941680681747\n",
      "93 Train Loss 5.2658005 Test MSE 3.177188291491637 Test RE 0.8519802688636425\n",
      "94 Train Loss 5.1815667 Test MSE 3.18540022847571 Test RE 0.8530805960468162\n",
      "95 Train Loss 5.1244993 Test MSE 3.2288888459621825 Test RE 0.8588841883391124\n",
      "96 Train Loss 5.0767775 Test MSE 3.2296297289208016 Test RE 0.858982720092723\n",
      "97 Train Loss 5.0065784 Test MSE 3.3007798119531806 Test RE 0.8683930469648524\n",
      "98 Train Loss 4.9516344 Test MSE 3.240014664146112 Test RE 0.8603626492439395\n",
      "99 Train Loss 4.792411 Test MSE 3.3132523820113433 Test RE 0.8700321869903456\n",
      "Training time: 73.42\n",
      "KG_stan_tune16\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 131.07707 Test MSE 4.798998720810565 Test RE 1.0470884699387601\n",
      "1 Train Loss 97.53414 Test MSE 4.784230374903629 Test RE 1.0454760835918102\n",
      "2 Train Loss 83.25235 Test MSE 4.5987819537112795 Test RE 1.0250132266398413\n",
      "3 Train Loss 73.292755 Test MSE 4.64014375485674 Test RE 1.0296124325676448\n",
      "4 Train Loss 59.17744 Test MSE 5.36655006096628 Test RE 1.1072754033777474\n",
      "5 Train Loss 51.778458 Test MSE 5.742237087860241 Test RE 1.1453774280203817\n",
      "6 Train Loss 44.676456 Test MSE 6.279235444573768 Test RE 1.1977369400112048\n",
      "7 Train Loss 39.13202 Test MSE 5.673191549851055 Test RE 1.1384705059687412\n",
      "8 Train Loss 33.67346 Test MSE 5.8634040911824306 Test RE 1.1573986544533919\n",
      "9 Train Loss 28.275003 Test MSE 5.835588396475674 Test RE 1.1546500702300186\n",
      "10 Train Loss 24.923477 Test MSE 5.5871665735901885 Test RE 1.129805982331047\n",
      "11 Train Loss 22.80104 Test MSE 5.666259936474846 Test RE 1.1377747909317097\n",
      "12 Train Loss 20.581085 Test MSE 5.5409431052689815 Test RE 1.125122748638829\n",
      "13 Train Loss 18.624138 Test MSE 5.529068532569276 Test RE 1.1239164993316648\n",
      "14 Train Loss 17.325224 Test MSE 5.50707826903063 Test RE 1.1216792469570422\n",
      "15 Train Loss 16.57412 Test MSE 5.471118074925557 Test RE 1.118011070870503\n",
      "16 Train Loss 15.737923 Test MSE 5.456213656550932 Test RE 1.1164871895955846\n",
      "17 Train Loss 14.99778 Test MSE 5.379553473430313 Test RE 1.1086160828820377\n",
      "18 Train Loss 14.180316 Test MSE 5.286564561509926 Test RE 1.0989927576849652\n",
      "19 Train Loss 13.1903925 Test MSE 5.190684540537722 Test RE 1.0889811898481094\n",
      "20 Train Loss 12.099418 Test MSE 4.874975045389201 Test RE 1.0553445184975014\n",
      "21 Train Loss 11.030337 Test MSE 4.833699781641304 Test RE 1.0508673450136812\n",
      "22 Train Loss 9.97686 Test MSE 4.865751692260243 Test RE 1.0543457007105894\n",
      "23 Train Loss 9.3250065 Test MSE 4.6974840403864535 Test RE 1.0359545850800582\n",
      "24 Train Loss 8.663757 Test MSE 4.5807260224399435 Test RE 1.0229990225954042\n",
      "25 Train Loss 8.037802 Test MSE 4.683246014735666 Test RE 1.0343834097941003\n",
      "26 Train Loss 7.5363226 Test MSE 4.675013730233133 Test RE 1.0334738820990634\n",
      "27 Train Loss 7.104926 Test MSE 4.638095056564704 Test RE 1.02938511222752\n",
      "28 Train Loss 6.7693596 Test MSE 4.6263485354331015 Test RE 1.028080766429826\n",
      "29 Train Loss 6.40462 Test MSE 4.577359999697362 Test RE 1.0226230919273522\n",
      "30 Train Loss 5.980563 Test MSE 4.454362721620304 Test RE 1.0087901888567676\n",
      "31 Train Loss 5.7985296 Test MSE 4.478463562072673 Test RE 1.0115155948156354\n",
      "32 Train Loss 5.5914416 Test MSE 4.421862245632747 Test RE 1.0051032209157382\n",
      "33 Train Loss 5.38487 Test MSE 4.406235425053959 Test RE 1.003325636256375\n",
      "34 Train Loss 5.208063 Test MSE 4.447424051682104 Test RE 1.00800417404315\n",
      "35 Train Loss 5.0093455 Test MSE 4.485518891826578 Test RE 1.012312047378185\n",
      "36 Train Loss 4.8253064 Test MSE 4.464603569566342 Test RE 1.0099491577793187\n",
      "37 Train Loss 4.64333 Test MSE 4.45298988579261 Test RE 1.0086347221689613\n",
      "38 Train Loss 4.4967666 Test MSE 4.45336144541644 Test RE 1.008676801775045\n",
      "39 Train Loss 4.365551 Test MSE 4.497792980005114 Test RE 1.01369613684676\n",
      "40 Train Loss 4.1642337 Test MSE 4.469962862851225 Test RE 1.0105551455572874\n",
      "41 Train Loss 4.028797 Test MSE 4.513826582019341 Test RE 1.0155013268054065\n",
      "42 Train Loss 3.9200497 Test MSE 4.494687751777266 Test RE 1.0133461539379405\n",
      "43 Train Loss 3.8046947 Test MSE 4.483633082179673 Test RE 1.0120992260121344\n",
      "44 Train Loss 3.699415 Test MSE 4.487938217993769 Test RE 1.0125850127733815\n",
      "45 Train Loss 3.6088233 Test MSE 4.51736521293521 Test RE 1.015899301818343\n",
      "46 Train Loss 3.481196 Test MSE 4.491948804129959 Test RE 1.013037353285215\n",
      "47 Train Loss 3.389932 Test MSE 4.552915301774634 Test RE 1.0198888547130465\n",
      "48 Train Loss 3.2691236 Test MSE 4.571108122149539 Test RE 1.0219244906725178\n",
      "49 Train Loss 3.1710138 Test MSE 4.603690285230336 Test RE 1.0255600848139945\n",
      "50 Train Loss 3.1034756 Test MSE 4.6176099683289555 Test RE 1.027109352464112\n",
      "51 Train Loss 3.0373375 Test MSE 4.635309224710193 Test RE 1.0290759201406288\n",
      "52 Train Loss 2.9454765 Test MSE 4.647034693335487 Test RE 1.0303766722245524\n",
      "53 Train Loss 2.877752 Test MSE 4.6329796180157565 Test RE 1.0288172919321024\n",
      "54 Train Loss 2.7853196 Test MSE 4.640710282568764 Test RE 1.0296752847337955\n",
      "55 Train Loss 2.7213917 Test MSE 4.617490011775192 Test RE 1.0270960112227232\n",
      "56 Train Loss 2.635409 Test MSE 4.570943245284798 Test RE 1.0219060604340624\n",
      "57 Train Loss 2.58545 Test MSE 4.546303374941741 Test RE 1.019148023829145\n",
      "58 Train Loss 2.5474584 Test MSE 4.547912151634636 Test RE 1.019328328180862\n",
      "59 Train Loss 2.5019684 Test MSE 4.564456252753995 Test RE 1.021180668510917\n",
      "60 Train Loss 2.4401808 Test MSE 4.563689745053531 Test RE 1.0210949216369374\n",
      "61 Train Loss 2.3763146 Test MSE 4.560139127150329 Test RE 1.0206976308959737\n",
      "62 Train Loss 2.3297625 Test MSE 4.572226423904548 Test RE 1.0220494877227881\n",
      "63 Train Loss 2.290683 Test MSE 4.606690168858208 Test RE 1.025894171132667\n",
      "64 Train Loss 2.2090414 Test MSE 4.582318380431165 Test RE 1.023176815276975\n",
      "65 Train Loss 2.1547651 Test MSE 4.603443543845477 Test RE 1.0255326012637758\n",
      "66 Train Loss 2.084752 Test MSE 4.606138122974251 Test RE 1.0258326999242982\n",
      "67 Train Loss 2.0469046 Test MSE 4.6356096336484285 Test RE 1.0291092662002879\n",
      "68 Train Loss 2.0149562 Test MSE 4.6356306917672185 Test RE 1.0291116036577395\n",
      "69 Train Loss 1.9753225 Test MSE 4.637401531620822 Test RE 1.029308148416662\n",
      "70 Train Loss 1.9325631 Test MSE 4.669495186091086 Test RE 1.0328637282423212\n",
      "71 Train Loss 1.8736924 Test MSE 4.690509540794371 Test RE 1.0351852425282633\n",
      "72 Train Loss 1.8336256 Test MSE 4.714007640332684 Test RE 1.0377749928065552\n",
      "73 Train Loss 1.7980081 Test MSE 4.702299467473259 Test RE 1.0364854315851109\n",
      "74 Train Loss 1.7667248 Test MSE 4.709746192979191 Test RE 1.03730581416386\n",
      "75 Train Loss 1.7221317 Test MSE 4.710920267955255 Test RE 1.0374350991463872\n",
      "76 Train Loss 1.6940887 Test MSE 4.7017081418049775 Test RE 1.0364202592460905\n",
      "77 Train Loss 1.6673169 Test MSE 4.7205489768329 Test RE 1.0384947712431696\n",
      "78 Train Loss 1.6399003 Test MSE 4.715747224814005 Test RE 1.0379664573619074\n",
      "79 Train Loss 1.6121352 Test MSE 4.769620168276657 Test RE 1.0438785120122778\n",
      "80 Train Loss 1.5759258 Test MSE 4.768592368195161 Test RE 1.043766033849708\n",
      "81 Train Loss 1.5465224 Test MSE 4.762867723844859 Test RE 1.0431393307020886\n",
      "82 Train Loss 1.5212827 Test MSE 4.784055397632886 Test RE 1.045456964923803\n",
      "83 Train Loss 1.4960845 Test MSE 4.774707386678342 Test RE 1.0444350576627446\n",
      "84 Train Loss 1.4698384 Test MSE 4.809664518620689 Test RE 1.04825140372899\n",
      "85 Train Loss 1.4427722 Test MSE 4.814391163236331 Test RE 1.0487663559813567\n",
      "86 Train Loss 1.4138405 Test MSE 4.811162751450171 Test RE 1.0484146586060354\n",
      "87 Train Loss 1.3843199 Test MSE 4.8238284765648025 Test RE 1.0497937643036839\n",
      "88 Train Loss 1.3646297 Test MSE 4.818548210833296 Test RE 1.0492190436414437\n",
      "89 Train Loss 1.3427838 Test MSE 4.79614283774143 Test RE 1.0467768625149425\n",
      "90 Train Loss 1.3167571 Test MSE 4.7648065075593165 Test RE 1.0433516204288384\n",
      "91 Train Loss 1.2968261 Test MSE 4.7673691369878055 Test RE 1.0436321527191528\n",
      "92 Train Loss 1.2753184 Test MSE 4.7743446825452285 Test RE 1.0443953873671714\n",
      "93 Train Loss 1.2577925 Test MSE 4.7893723892672 Test RE 1.0460377632061828\n",
      "94 Train Loss 1.241978 Test MSE 4.765900399982877 Test RE 1.0434713785904106\n",
      "95 Train Loss 1.225619 Test MSE 4.7667859718063035 Test RE 1.04356831997101\n",
      "96 Train Loss 1.2025895 Test MSE 4.768096913594904 Test RE 1.0437118090306787\n",
      "97 Train Loss 1.1857104 Test MSE 4.736938362529313 Test RE 1.040295996453981\n",
      "98 Train Loss 1.1773127 Test MSE 4.750867294402677 Test RE 1.0418243650432442\n",
      "99 Train Loss 1.1654193 Test MSE 4.77144550676125 Test RE 1.0440782395887114\n",
      "Training time: 72.48\n",
      "KG_stan_tune16\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 168.06645 Test MSE 6.036586578216319 Test RE 1.1743668328968941\n",
      "1 Train Loss 143.63174 Test MSE 6.00655866378447 Test RE 1.1714423532208027\n",
      "2 Train Loss 115.76786 Test MSE 5.937059544089573 Test RE 1.164645525716065\n",
      "3 Train Loss 93.696785 Test MSE 5.797836572422299 Test RE 1.1509091557690643\n",
      "4 Train Loss 88.1971 Test MSE 5.762514671867745 Test RE 1.1473979836611763\n",
      "5 Train Loss 83.42007 Test MSE 5.663515457403939 Test RE 1.1374992143310028\n",
      "6 Train Loss 75.71354 Test MSE 5.578463124430484 Test RE 1.1289256576421687\n",
      "7 Train Loss 67.94756 Test MSE 5.7277357234239 Test RE 1.1439302537849596\n",
      "8 Train Loss 60.269726 Test MSE 5.816884610009735 Test RE 1.1527981866319081\n",
      "9 Train Loss 55.64966 Test MSE 6.007743969218899 Test RE 1.171557930922699\n",
      "10 Train Loss 52.02453 Test MSE 6.275782259646503 Test RE 1.1974075546921632\n",
      "11 Train Loss 49.611515 Test MSE 6.4129044832720545 Test RE 1.210418202234409\n",
      "12 Train Loss 47.354225 Test MSE 6.574395747179373 Test RE 1.2255639615135028\n",
      "13 Train Loss 45.9634 Test MSE 6.829366980293908 Test RE 1.2491030980211137\n",
      "14 Train Loss 45.01403 Test MSE 6.9199608192946425 Test RE 1.2573606886702076\n",
      "15 Train Loss 44.050186 Test MSE 6.958344061236863 Test RE 1.260842994575036\n",
      "16 Train Loss 42.255486 Test MSE 7.43190440908527 Test RE 1.3030411105618187\n",
      "17 Train Loss 41.480152 Test MSE 7.5878326019545215 Test RE 1.3166396540656828\n",
      "18 Train Loss 40.180614 Test MSE 8.044881164651557 Test RE 1.355713363289669\n",
      "19 Train Loss 39.113777 Test MSE 8.174865549839538 Test RE 1.3666218799524879\n",
      "20 Train Loss 37.993603 Test MSE 8.381828666437222 Test RE 1.3838131391097412\n",
      "21 Train Loss 37.114185 Test MSE 8.376338625072952 Test RE 1.3833598707293309\n",
      "22 Train Loss 36.422768 Test MSE 8.490370445051246 Test RE 1.3927442688244644\n",
      "23 Train Loss 35.584244 Test MSE 8.573931646180348 Test RE 1.3995810986925006\n",
      "24 Train Loss 34.823277 Test MSE 8.591945332529685 Test RE 1.4010505754489058\n",
      "25 Train Loss 33.901466 Test MSE 8.652475200992289 Test RE 1.4059770830683307\n",
      "26 Train Loss 33.169514 Test MSE 8.605832510539468 Test RE 1.4021823786893646\n",
      "27 Train Loss 32.700485 Test MSE 8.56789682487363 Test RE 1.3990884595544877\n",
      "28 Train Loss 32.367363 Test MSE 8.531123109266096 Test RE 1.3960827624197185\n",
      "29 Train Loss 31.841475 Test MSE 8.450346470097578 Test RE 1.3894576624676254\n",
      "30 Train Loss 31.389265 Test MSE 8.477807428785553 Test RE 1.391713480691162\n",
      "31 Train Loss 30.920658 Test MSE 8.515023750991189 Test RE 1.394764843892657\n",
      "32 Train Loss 30.566664 Test MSE 8.506042700438986 Test RE 1.3940290997134683\n",
      "33 Train Loss 30.309673 Test MSE 8.543021084961056 Test RE 1.3970559503046565\n",
      "34 Train Loss 29.953888 Test MSE 8.5311051381183 Test RE 1.3960812919672025\n",
      "35 Train Loss 29.701408 Test MSE 8.599590226070262 Test RE 1.4016737463707267\n",
      "36 Train Loss 29.417923 Test MSE 8.630902806932122 Test RE 1.4042232947313176\n",
      "37 Train Loss 29.228474 Test MSE 8.609480323049752 Test RE 1.4024795234751595\n",
      "38 Train Loss 28.946644 Test MSE 8.698883835300972 Test RE 1.4097426076843405\n",
      "39 Train Loss 28.688229 Test MSE 8.785175246840451 Test RE 1.4167175532927427\n",
      "40 Train Loss 28.40922 Test MSE 8.739671369979762 Test RE 1.4130437600152477\n",
      "41 Train Loss 28.146465 Test MSE 8.685738720998687 Test RE 1.4086770552457835\n",
      "42 Train Loss 27.957912 Test MSE 8.770818986374692 Test RE 1.4155595182191614\n",
      "43 Train Loss 27.75909 Test MSE 8.736610484279861 Test RE 1.412796293948099\n",
      "44 Train Loss 27.466606 Test MSE 8.665284335119354 Test RE 1.4070174032242564\n",
      "45 Train Loss 27.287603 Test MSE 8.706692642077792 Test RE 1.4103752140301975\n",
      "46 Train Loss 27.084116 Test MSE 8.750587259829102 Test RE 1.4139259337281265\n",
      "47 Train Loss 26.792347 Test MSE 8.7135529661685 Test RE 1.4109307479314925\n",
      "48 Train Loss 26.567562 Test MSE 8.755449849064002 Test RE 1.4143187294314734\n",
      "49 Train Loss 26.29879 Test MSE 8.793163924264181 Test RE 1.417361543166974\n",
      "50 Train Loss 26.020445 Test MSE 8.838680327471485 Test RE 1.4210251806167113\n",
      "51 Train Loss 25.56416 Test MSE 8.779200793829041 Test RE 1.416235744351433\n",
      "52 Train Loss 25.206074 Test MSE 8.779306170384764 Test RE 1.416244243849309\n",
      "53 Train Loss 24.87717 Test MSE 8.75585956832129 Test RE 1.4143518212114667\n",
      "54 Train Loss 24.597519 Test MSE 8.780973662497013 Test RE 1.4163787342027796\n",
      "55 Train Loss 24.32679 Test MSE 8.748716728926182 Test RE 1.4137748048136798\n",
      "56 Train Loss 24.088062 Test MSE 8.701278468565382 Test RE 1.409936631671462\n",
      "57 Train Loss 23.845888 Test MSE 8.661203094662412 Test RE 1.4066860204078553\n",
      "58 Train Loss 23.543041 Test MSE 8.687649226261854 Test RE 1.4088319722331506\n",
      "59 Train Loss 23.331078 Test MSE 8.682481836326396 Test RE 1.4084129252150699\n",
      "60 Train Loss 23.087626 Test MSE 8.666245562330376 Test RE 1.4070954402428608\n",
      "61 Train Loss 22.966743 Test MSE 8.621708788469258 Test RE 1.4034751751419978\n",
      "62 Train Loss 22.731636 Test MSE 8.575837247716377 Test RE 1.3997366221925032\n",
      "63 Train Loss 22.516079 Test MSE 8.629896541130488 Test RE 1.4041414340558498\n",
      "64 Train Loss 22.298548 Test MSE 8.677160375586427 Test RE 1.4079812535475404\n",
      "65 Train Loss 22.059177 Test MSE 8.631682764371865 Test RE 1.4042867417245153\n",
      "66 Train Loss 21.901579 Test MSE 8.566605176368814 Test RE 1.3989829961795663\n",
      "67 Train Loss 21.634 Test MSE 8.619672453107297 Test RE 1.4033094240727348\n",
      "68 Train Loss 21.453026 Test MSE 8.586805227883547 Test RE 1.4006314256701535\n",
      "69 Train Loss 21.192513 Test MSE 8.63067885584188 Test RE 1.4042050765109964\n",
      "70 Train Loss 21.024868 Test MSE 8.56362930441238 Test RE 1.3987399853371074\n",
      "71 Train Loss 20.879517 Test MSE 8.516446669918098 Test RE 1.3948813764149555\n",
      "72 Train Loss 20.723623 Test MSE 8.478470865104347 Test RE 1.391767934346384\n",
      "73 Train Loss 20.575447 Test MSE 8.474653836921197 Test RE 1.3914546104248435\n",
      "74 Train Loss 20.367111 Test MSE 8.407957524258265 Test RE 1.3859683562722669\n",
      "75 Train Loss 20.160206 Test MSE 8.421219427923582 Test RE 1.3870609721984384\n",
      "76 Train Loss 19.967327 Test MSE 8.45651830700992 Test RE 1.3899649754446115\n",
      "77 Train Loss 19.685436 Test MSE 8.405820242765937 Test RE 1.3857921902546328\n",
      "78 Train Loss 19.52735 Test MSE 8.44444432761051 Test RE 1.388972344522932\n",
      "79 Train Loss 19.382238 Test MSE 8.430732239776093 Test RE 1.3878441797830183\n",
      "80 Train Loss 19.224766 Test MSE 8.468109042552557 Test RE 1.3909172112934531\n",
      "81 Train Loss 19.007448 Test MSE 8.547394995457582 Test RE 1.3974135413540612\n",
      "82 Train Loss 18.910847 Test MSE 8.52617420172269 Test RE 1.395677769624105\n",
      "83 Train Loss 18.763868 Test MSE 8.531871118641778 Test RE 1.3961439653875136\n",
      "84 Train Loss 18.609543 Test MSE 8.505365595954183 Test RE 1.3939736143265684\n",
      "85 Train Loss 18.448864 Test MSE 8.464615291695864 Test RE 1.390630251152207\n",
      "86 Train Loss 18.286388 Test MSE 8.5314183591226 Test RE 1.3961069204153134\n",
      "87 Train Loss 18.112373 Test MSE 8.542375189134273 Test RE 1.3970031370401588\n",
      "88 Train Loss 17.995184 Test MSE 8.586730310784246 Test RE 1.4006253156286597\n",
      "89 Train Loss 17.79369 Test MSE 8.527133873351774 Test RE 1.3957563133319948\n",
      "90 Train Loss 17.55505 Test MSE 8.465466098679334 Test RE 1.3907001378605233\n",
      "91 Train Loss 17.445217 Test MSE 8.513767191439143 Test RE 1.394661927576665\n",
      "92 Train Loss 17.346024 Test MSE 8.49253651524508 Test RE 1.392921916518487\n",
      "93 Train Loss 17.204613 Test MSE 8.49111128967414 Test RE 1.3928050308726092\n",
      "94 Train Loss 17.080921 Test MSE 8.498220683883432 Test RE 1.3933879892084908\n",
      "95 Train Loss 16.87212 Test MSE 8.458332149155524 Test RE 1.3901140345363245\n",
      "96 Train Loss 16.740643 Test MSE 8.442708097814533 Test RE 1.3888295465454565\n",
      "97 Train Loss 16.615648 Test MSE 8.433259318175661 Test RE 1.3880521645802877\n",
      "98 Train Loss 16.50934 Test MSE 8.402709999159592 Test RE 1.3855357875509526\n",
      "99 Train Loss 16.385979 Test MSE 8.375413350817134 Test RE 1.383283463680743\n",
      "Training time: 71.76\n",
      "KG_stan_tune16\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 270.93085 Test MSE 6.533816114640765 Test RE 1.2217757870971098\n",
      "1 Train Loss 140.02415 Test MSE 6.262577980967423 Test RE 1.1961472155259583\n",
      "2 Train Loss 101.58006 Test MSE 6.008277381068711 Test RE 1.1716099395481994\n",
      "3 Train Loss 84.03111 Test MSE 5.831611110317971 Test RE 1.154256523239797\n",
      "4 Train Loss 68.65828 Test MSE 5.658333071726538 Test RE 1.1369786623134337\n",
      "5 Train Loss 54.85502 Test MSE 4.956305355689825 Test RE 1.0641113804003235\n",
      "6 Train Loss 49.234406 Test MSE 5.658045624594436 Test RE 1.13694978230563\n",
      "7 Train Loss 42.462196 Test MSE 5.393299460462909 Test RE 1.110031562809604\n",
      "8 Train Loss 38.707775 Test MSE 5.140656742050274 Test RE 1.0837206856302986\n",
      "9 Train Loss 34.2753 Test MSE 4.856223580041891 Test RE 1.053312885270054\n",
      "10 Train Loss 29.488153 Test MSE 4.718968562734554 Test RE 1.0383209154925854\n",
      "11 Train Loss 25.765446 Test MSE 4.559981316501939 Test RE 1.020679969335213\n",
      "12 Train Loss 21.7991 Test MSE 4.410840841159859 Test RE 1.0038498394397508\n",
      "13 Train Loss 17.151947 Test MSE 4.106353364336872 Test RE 0.9685816116587231\n",
      "14 Train Loss 14.249416 Test MSE 3.9789372376911953 Test RE 0.9534361286753343\n",
      "15 Train Loss 12.118065 Test MSE 3.7792586829831523 Test RE 0.9292046405708003\n",
      "16 Train Loss 10.560635 Test MSE 3.6810509181599027 Test RE 0.9170520218687503\n",
      "17 Train Loss 9.560141 Test MSE 3.5738577164982774 Test RE 0.9036009719744573\n",
      "18 Train Loss 8.750941 Test MSE 3.3627323616954805 Test RE 0.8765046248487616\n",
      "19 Train Loss 8.048981 Test MSE 3.267825994916891 Test RE 0.8640473088112229\n",
      "20 Train Loss 7.483035 Test MSE 3.2183206496673322 Test RE 0.8574774666342004\n",
      "21 Train Loss 6.8081923 Test MSE 3.0706064558522668 Test RE 0.837568121926212\n",
      "22 Train Loss 6.1188593 Test MSE 2.8338671568245686 Test RE 0.8046329336108099\n",
      "23 Train Loss 5.355956 Test MSE 2.7453687488298884 Test RE 0.7919694025959179\n",
      "24 Train Loss 4.479788 Test MSE 2.5328908140383772 Test RE 0.7607050419313383\n",
      "25 Train Loss 3.8757591 Test MSE 2.430200001180318 Test RE 0.745124886440837\n",
      "26 Train Loss 3.3575516 Test MSE 2.354556331577417 Test RE 0.7334366413986126\n",
      "27 Train Loss 2.9510295 Test MSE 2.2493746479880308 Test RE 0.7168676100916723\n",
      "28 Train Loss 2.627772 Test MSE 2.2087821643679946 Test RE 0.7103698223998278\n",
      "29 Train Loss 2.3167253 Test MSE 2.088046686123631 Test RE 0.690682039316177\n",
      "30 Train Loss 2.1332192 Test MSE 2.038769821561795 Test RE 0.6824835036601826\n",
      "31 Train Loss 1.9190748 Test MSE 1.8926981299119698 Test RE 0.6575802133838522\n",
      "32 Train Loss 1.7429929 Test MSE 1.8294712974225373 Test RE 0.6465034702504923\n",
      "33 Train Loss 1.5981115 Test MSE 1.7692484635297212 Test RE 0.6357735760291041\n",
      "34 Train Loss 1.4896777 Test MSE 1.7315287489638393 Test RE 0.6289598365251093\n",
      "35 Train Loss 1.4203825 Test MSE 1.7118702563778632 Test RE 0.6253792731086075\n",
      "36 Train Loss 1.353049 Test MSE 1.6774451497000356 Test RE 0.6190592602050938\n",
      "37 Train Loss 1.27672 Test MSE 1.5718195472118957 Test RE 0.5992518769244781\n",
      "38 Train Loss 1.2131445 Test MSE 1.5033844770151685 Test RE 0.5860613634477556\n",
      "39 Train Loss 1.1358815 Test MSE 1.4013575041383135 Test RE 0.5658255210391466\n",
      "40 Train Loss 1.0493686 Test MSE 1.3101930465040161 Test RE 0.5471113259780421\n",
      "41 Train Loss 0.9816971 Test MSE 1.2855145208970304 Test RE 0.5419341932687847\n",
      "42 Train Loss 0.90129864 Test MSE 1.1969332091173435 Test RE 0.522929351033919\n",
      "43 Train Loss 0.84798825 Test MSE 1.1594625019098088 Test RE 0.5146789593113822\n",
      "44 Train Loss 0.78870285 Test MSE 1.110184001035076 Test RE 0.5036229846373266\n",
      "45 Train Loss 0.7519342 Test MSE 1.0761296081049896 Test RE 0.4958386204095174\n",
      "46 Train Loss 0.6854009 Test MSE 1.0158802772665028 Test RE 0.48175843204390517\n",
      "47 Train Loss 0.63823235 Test MSE 0.9844180006710616 Test RE 0.47423961948426596\n",
      "48 Train Loss 0.60004777 Test MSE 0.9433757438029821 Test RE 0.4642483971569586\n",
      "49 Train Loss 0.561296 Test MSE 0.9083092047265385 Test RE 0.45553832223183577\n",
      "50 Train Loss 0.507512 Test MSE 0.8486926891624478 Test RE 0.44033508528762444\n",
      "51 Train Loss 0.46424258 Test MSE 0.7910125101868877 Test RE 0.4251084487099241\n",
      "52 Train Loss 0.403731 Test MSE 0.7598098533736355 Test RE 0.41663957631930476\n",
      "53 Train Loss 0.3765477 Test MSE 0.7251251659565315 Test RE 0.40701887467220904\n",
      "54 Train Loss 0.33784845 Test MSE 0.6875152640698516 Test RE 0.3963229598100316\n",
      "55 Train Loss 0.3124805 Test MSE 0.6724193509436992 Test RE 0.3919477374912336\n",
      "56 Train Loss 0.28575233 Test MSE 0.6347059794708035 Test RE 0.38079773380657783\n",
      "57 Train Loss 0.25786704 Test MSE 0.6032565153851533 Test RE 0.3712436815643897\n",
      "58 Train Loss 0.24057366 Test MSE 0.5843775911595205 Test RE 0.3653884686200734\n",
      "59 Train Loss 0.22849305 Test MSE 0.5654958023711478 Test RE 0.35943697702461835\n",
      "60 Train Loss 0.21395785 Test MSE 0.5537097040643971 Test RE 0.3556715501057096\n",
      "61 Train Loss 0.2026756 Test MSE 0.5456333432787369 Test RE 0.3530681250105713\n",
      "62 Train Loss 0.19010335 Test MSE 0.5286025430908815 Test RE 0.3475143032998683\n",
      "63 Train Loss 0.18070297 Test MSE 0.5236621265685522 Test RE 0.3458865247168229\n",
      "64 Train Loss 0.17039333 Test MSE 0.5263753229822371 Test RE 0.3467814200948122\n",
      "65 Train Loss 0.16095713 Test MSE 0.5270191742919494 Test RE 0.34699344317697084\n",
      "66 Train Loss 0.15395033 Test MSE 0.518933090389925 Test RE 0.3443211837486962\n",
      "67 Train Loss 0.14596893 Test MSE 0.5140468060113401 Test RE 0.34269628209207614\n",
      "68 Train Loss 0.13881822 Test MSE 0.5088103024096143 Test RE 0.34094632093894395\n",
      "69 Train Loss 0.13542934 Test MSE 0.5118348972180709 Test RE 0.3419581877302156\n",
      "70 Train Loss 0.13158846 Test MSE 0.501517082338778 Test RE 0.3384939613698425\n",
      "71 Train Loss 0.12758228 Test MSE 0.5048722261739347 Test RE 0.33962433443837925\n",
      "72 Train Loss 0.12393647 Test MSE 0.5060923985716527 Test RE 0.3400344878782566\n",
      "73 Train Loss 0.12169316 Test MSE 0.5039068636413536 Test RE 0.33929948246038943\n",
      "74 Train Loss 0.11893825 Test MSE 0.5012802647743342 Test RE 0.3384140331045252\n",
      "75 Train Loss 0.11644039 Test MSE 0.5017207459404082 Test RE 0.3385626847535662\n",
      "76 Train Loss 0.113516964 Test MSE 0.4964297044096162 Test RE 0.33677274771526267\n",
      "77 Train Loss 0.11135173 Test MSE 0.49315018022480916 Test RE 0.33565850688870963\n",
      "78 Train Loss 0.109624706 Test MSE 0.49408722801269445 Test RE 0.3359772523794007\n",
      "79 Train Loss 0.10849802 Test MSE 0.49386240706678464 Test RE 0.3359008050297612\n",
      "80 Train Loss 0.107067935 Test MSE 0.49380759248571615 Test RE 0.33588216342779403\n",
      "81 Train Loss 0.105917186 Test MSE 0.4948515922041946 Test RE 0.3362370341757523\n",
      "82 Train Loss 0.1045759 Test MSE 0.4958416106273621 Test RE 0.33657321025007614\n",
      "83 Train Loss 0.103309005 Test MSE 0.49441691978461194 Test RE 0.336089328200455\n",
      "84 Train Loss 0.10183695 Test MSE 0.4934082363790192 Test RE 0.3357463172742322\n",
      "85 Train Loss 0.100306064 Test MSE 0.4910694606975119 Test RE 0.3349496462947174\n",
      "86 Train Loss 0.09887451 Test MSE 0.49249974159283727 Test RE 0.33543707606892187\n",
      "87 Train Loss 0.09745408 Test MSE 0.4954046649397278 Test RE 0.3364248799940886\n",
      "88 Train Loss 0.09643356 Test MSE 0.49276441124618103 Test RE 0.33552719600477243\n",
      "89 Train Loss 0.09557126 Test MSE 0.4943571208466605 Test RE 0.33606900285173164\n",
      "90 Train Loss 0.094391055 Test MSE 0.49764721663033396 Test RE 0.33718546863001514\n",
      "91 Train Loss 0.093635276 Test MSE 0.49931529818360393 Test RE 0.33775010789983384\n",
      "92 Train Loss 0.09231633 Test MSE 0.5020300379338353 Test RE 0.33866702426445244\n",
      "93 Train Loss 0.09145498 Test MSE 0.5021118197413512 Test RE 0.33869460794612677\n",
      "94 Train Loss 0.09076361 Test MSE 0.5010127986011332 Test RE 0.3383237379245454\n",
      "95 Train Loss 0.08963562 Test MSE 0.4998721464699122 Test RE 0.3379383888939286\n",
      "96 Train Loss 0.08894841 Test MSE 0.4970063005160661 Test RE 0.336968269358323\n",
      "97 Train Loss 0.08795133 Test MSE 0.49882134014301555 Test RE 0.3375830034033055\n",
      "98 Train Loss 0.0871658 Test MSE 0.4975974531973227 Test RE 0.3371686093716714\n",
      "99 Train Loss 0.0862292 Test MSE 0.49755653857208115 Test RE 0.33715474735249057\n",
      "Training time: 71.95\n",
      "KG_stan_tune16\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 125.61084 Test MSE 6.811560992171059 Test RE 1.2474736621365023\n",
      "1 Train Loss 70.88951 Test MSE 7.756132460206912 Test RE 1.3311612565300783\n",
      "2 Train Loss 52.931313 Test MSE 7.949931536995147 Test RE 1.3476892202467612\n",
      "3 Train Loss 47.299686 Test MSE 8.368340833318898 Test RE 1.3826992917532568\n",
      "4 Train Loss 42.594788 Test MSE 8.860351789952432 Test RE 1.4227662120233986\n",
      "5 Train Loss 39.77244 Test MSE 9.270338538406637 Test RE 1.4553111521185145\n",
      "6 Train Loss 37.4111 Test MSE 9.490909048847156 Test RE 1.4725225901368815\n",
      "7 Train Loss 35.382977 Test MSE 9.497917237398685 Test RE 1.4730661530116747\n",
      "8 Train Loss 33.641563 Test MSE 9.495370381757976 Test RE 1.472868639268213\n",
      "9 Train Loss 31.966484 Test MSE 9.435306244007982 Test RE 1.468202842827943\n",
      "10 Train Loss 30.978897 Test MSE 9.575508927465775 Test RE 1.479070901426512\n",
      "11 Train Loss 30.100002 Test MSE 9.327416672236152 Test RE 1.4597845041420834\n",
      "12 Train Loss 29.434204 Test MSE 9.216554594268048 Test RE 1.4510833543639163\n",
      "13 Train Loss 28.5482 Test MSE 9.260039005463732 Test RE 1.4545024874358332\n",
      "14 Train Loss 27.754168 Test MSE 9.238364400667725 Test RE 1.4527992421271567\n",
      "15 Train Loss 26.701115 Test MSE 9.332442816695908 Test RE 1.4601777587757896\n",
      "16 Train Loss 25.95652 Test MSE 9.284965396202862 Test RE 1.4564588038047115\n",
      "17 Train Loss 25.060394 Test MSE 9.183494449172423 Test RE 1.4484784696770314\n",
      "18 Train Loss 23.966377 Test MSE 9.26501590616324 Test RE 1.4548933033949998\n",
      "19 Train Loss 23.110546 Test MSE 9.233194852178961 Test RE 1.4523927109091126\n",
      "20 Train Loss 22.132307 Test MSE 9.23060409086261 Test RE 1.452188931670072\n",
      "21 Train Loss 21.557083 Test MSE 9.181355694675528 Test RE 1.4483097909540505\n",
      "22 Train Loss 20.748878 Test MSE 9.078373660399642 Test RE 1.4401644533839617\n",
      "23 Train Loss 20.083593 Test MSE 9.160726091882525 Test RE 1.4466817711469968\n",
      "24 Train Loss 19.477049 Test MSE 9.169237693054892 Test RE 1.4473537003807146\n",
      "25 Train Loss 18.844606 Test MSE 8.924784572214781 Test RE 1.4279300434972242\n",
      "26 Train Loss 18.47628 Test MSE 8.945088060437739 Test RE 1.4295533594697505\n",
      "27 Train Loss 17.945812 Test MSE 9.06735726810188 Test RE 1.4392903853413184\n",
      "28 Train Loss 17.477652 Test MSE 8.911938289814238 Test RE 1.4269019963713658\n",
      "29 Train Loss 16.858305 Test MSE 8.780853435695159 Test RE 1.4163690378254268\n",
      "30 Train Loss 16.430105 Test MSE 8.805573292762276 Test RE 1.4183613175791268\n",
      "31 Train Loss 15.930946 Test MSE 8.7153103330309 Test RE 1.4110730204318718\n",
      "32 Train Loss 15.4614315 Test MSE 8.71092041380768 Test RE 1.410717595519699\n",
      "33 Train Loss 14.967369 Test MSE 8.701822072306882 Test RE 1.4099806731798823\n",
      "34 Train Loss 14.507395 Test MSE 8.55674111980292 Test RE 1.3981773315183468\n",
      "35 Train Loss 14.181886 Test MSE 8.496946559819401 Test RE 1.393283531123534\n",
      "36 Train Loss 13.681895 Test MSE 8.493690611328999 Test RE 1.3930165590975745\n",
      "37 Train Loss 13.029637 Test MSE 8.435904989269146 Test RE 1.3882698764622008\n",
      "38 Train Loss 12.5515175 Test MSE 8.306574291875641 Test RE 1.3775870041810832\n",
      "39 Train Loss 12.156122 Test MSE 8.228210832540432 Test RE 1.3710735913760146\n",
      "40 Train Loss 11.601452 Test MSE 8.167342234079884 Test RE 1.3659928852325254\n",
      "41 Train Loss 11.309126 Test MSE 8.078743078994691 Test RE 1.3585635510741991\n",
      "42 Train Loss 11.032164 Test MSE 8.00917895232632 Test RE 1.3527017721071142\n",
      "43 Train Loss 10.727495 Test MSE 8.018483553422291 Test RE 1.3534872893907495\n",
      "44 Train Loss 10.450596 Test MSE 7.942203191131329 Test RE 1.3470339981942518\n",
      "45 Train Loss 10.110439 Test MSE 7.857072279490933 Test RE 1.339795252209166\n",
      "46 Train Loss 9.766354 Test MSE 7.711768290625148 Test RE 1.3273487536770774\n",
      "47 Train Loss 9.398429 Test MSE 7.656508780286662 Test RE 1.322584573193153\n",
      "48 Train Loss 9.115261 Test MSE 7.754554210541189 Test RE 1.3310258145617402\n",
      "49 Train Loss 8.909612 Test MSE 7.734547450341786 Test RE 1.3293076814617475\n",
      "50 Train Loss 8.659003 Test MSE 7.658863949295835 Test RE 1.3227879733841326\n",
      "51 Train Loss 8.505321 Test MSE 7.701232569054196 Test RE 1.3264417401347095\n",
      "52 Train Loss 8.302218 Test MSE 7.783434402346795 Test RE 1.3335020727453357\n",
      "53 Train Loss 8.061423 Test MSE 7.685572520563842 Test RE 1.3250924293395603\n",
      "54 Train Loss 7.853431 Test MSE 7.685363201088537 Test RE 1.3250743845198754\n",
      "55 Train Loss 7.669055 Test MSE 7.72279544013871 Test RE 1.328297410586212\n",
      "56 Train Loss 7.508588 Test MSE 7.699411203238652 Test RE 1.326284877029932\n",
      "57 Train Loss 7.41383 Test MSE 7.6812588602138385 Test RE 1.324720511637063\n",
      "58 Train Loss 7.2660837 Test MSE 7.692944648056785 Test RE 1.3257278022307317\n",
      "59 Train Loss 7.1081123 Test MSE 7.6705950415186 Test RE 1.3238006438152372\n",
      "60 Train Loss 6.933037 Test MSE 7.638662944853253 Test RE 1.32104233007333\n",
      "61 Train Loss 6.823841 Test MSE 7.64173360509196 Test RE 1.3213078257892217\n",
      "62 Train Loss 6.6228075 Test MSE 7.637592176639592 Test RE 1.3209497366626157\n",
      "63 Train Loss 6.464502 Test MSE 7.598965350020055 Test RE 1.3176051764909509\n",
      "64 Train Loss 6.333827 Test MSE 7.595545976282693 Test RE 1.317308695899504\n",
      "65 Train Loss 6.1655273 Test MSE 7.615449697254343 Test RE 1.3190335350796076\n",
      "66 Train Loss 5.9808936 Test MSE 7.6413031714385244 Test RE 1.3212706128089522\n",
      "67 Train Loss 5.87288 Test MSE 7.64720421707728 Test RE 1.3217806942241266\n",
      "68 Train Loss 5.6823163 Test MSE 7.625216514266297 Test RE 1.319879094553604\n",
      "69 Train Loss 5.523904 Test MSE 7.576046281074243 Test RE 1.315616676281643\n",
      "70 Train Loss 5.338168 Test MSE 7.554202898573654 Test RE 1.3137187032984183\n",
      "71 Train Loss 5.208714 Test MSE 7.541947901192654 Test RE 1.3126526640160325\n",
      "72 Train Loss 5.0633726 Test MSE 7.543775018605003 Test RE 1.312811656449425\n",
      "73 Train Loss 4.939665 Test MSE 7.546583203264712 Test RE 1.3130559820372025\n",
      "74 Train Loss 4.803044 Test MSE 7.5538963358196085 Test RE 1.313692046527667\n",
      "75 Train Loss 4.697324 Test MSE 7.528526317421788 Test RE 1.3114841513811\n",
      "76 Train Loss 4.5661125 Test MSE 7.5087780490738725 Test RE 1.309762928221928\n",
      "77 Train Loss 4.466713 Test MSE 7.537865578997563 Test RE 1.3122973581647044\n",
      "78 Train Loss 4.2895494 Test MSE 7.5627991755987765 Test RE 1.3144659614242915\n",
      "79 Train Loss 4.179398 Test MSE 7.488891129138939 Test RE 1.3080273315912565\n",
      "80 Train Loss 4.059639 Test MSE 7.452823680198242 Test RE 1.3048737172421276\n",
      "81 Train Loss 3.963009 Test MSE 7.512081517341929 Test RE 1.3100510100151028\n",
      "82 Train Loss 3.8692508 Test MSE 7.4860913202199715 Test RE 1.3077827981295218\n",
      "83 Train Loss 3.758105 Test MSE 7.510702629015675 Test RE 1.3099307705753072\n",
      "84 Train Loss 3.6415882 Test MSE 7.496327813799707 Test RE 1.308676624853067\n",
      "85 Train Loss 3.5251198 Test MSE 7.475126037170362 Test RE 1.3068246570246027\n",
      "86 Train Loss 3.427795 Test MSE 7.457702760279707 Test RE 1.3053007729452235\n",
      "87 Train Loss 3.3232422 Test MSE 7.406548576822836 Test RE 1.300816383290436\n",
      "88 Train Loss 3.2255704 Test MSE 7.459774415141249 Test RE 1.3054820583230156\n",
      "89 Train Loss 3.1494136 Test MSE 7.4702139816582855 Test RE 1.3063952160947714\n",
      "90 Train Loss 3.0760965 Test MSE 7.453426245444775 Test RE 1.304926466085712\n",
      "91 Train Loss 3.0136538 Test MSE 7.493899086847205 Test RE 1.3084646093332948\n",
      "92 Train Loss 2.9372 Test MSE 7.525770782625658 Test RE 1.3112441196139566\n",
      "93 Train Loss 2.8515344 Test MSE 7.488874330642683 Test RE 1.3080258645580087\n",
      "94 Train Loss 2.781115 Test MSE 7.474244506994123 Test RE 1.3067475988365502\n",
      "95 Train Loss 2.7174776 Test MSE 7.472429696670284 Test RE 1.3065889444733345\n",
      "96 Train Loss 2.664904 Test MSE 7.521367407002966 Test RE 1.3108604549108982\n",
      "97 Train Loss 2.616597 Test MSE 7.463118463399963 Test RE 1.3057746345874732\n",
      "98 Train Loss 2.5813608 Test MSE 7.466240681692882 Test RE 1.3060477434200886\n",
      "99 Train Loss 2.5615633 Test MSE 7.478766764707089 Test RE 1.3071428599095014\n",
      "Training time: 70.83\n",
      "KG_stan_tune16\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 91.645355 Test MSE 6.161115330852456 Test RE 1.1864180067275765\n",
      "1 Train Loss 71.85803 Test MSE 5.727195991744389 Test RE 1.143876355528076\n",
      "2 Train Loss 61.58755 Test MSE 5.7759952705523085 Test RE 1.14873928837929\n",
      "3 Train Loss 50.869213 Test MSE 6.045317391269527 Test RE 1.175215778943268\n",
      "4 Train Loss 41.963215 Test MSE 6.661475028861818 Test RE 1.2336536908411198\n",
      "5 Train Loss 35.511536 Test MSE 6.865452790426474 Test RE 1.2523988288806989\n",
      "6 Train Loss 30.961731 Test MSE 6.898622469285955 Test RE 1.2554205969324745\n",
      "7 Train Loss 27.640354 Test MSE 6.964543367086547 Test RE 1.261404522657606\n",
      "8 Train Loss 24.237034 Test MSE 6.847697589436129 Test RE 1.2507783248071032\n",
      "9 Train Loss 21.533178 Test MSE 6.76167651491568 Test RE 1.2428973304184814\n",
      "10 Train Loss 19.762903 Test MSE 6.548256149290994 Test RE 1.2231251323703507\n",
      "11 Train Loss 18.198727 Test MSE 6.709044378564458 Test RE 1.2380505932327752\n",
      "12 Train Loss 16.669195 Test MSE 6.764851344345498 Test RE 1.243189086755109\n",
      "13 Train Loss 15.486708 Test MSE 6.658779223370621 Test RE 1.2334040444105054\n",
      "14 Train Loss 14.450604 Test MSE 6.583482026822369 Test RE 1.226410577106616\n",
      "15 Train Loss 13.599685 Test MSE 6.529109618537531 Test RE 1.2213356676648466\n",
      "16 Train Loss 12.623766 Test MSE 6.5197030271476075 Test RE 1.2204555517543692\n",
      "17 Train Loss 11.744932 Test MSE 6.54433004100334 Test RE 1.2227584055943972\n",
      "18 Train Loss 11.219479 Test MSE 6.477179406951389 Test RE 1.2164689369158326\n",
      "19 Train Loss 10.44914 Test MSE 6.5199886480729505 Test RE 1.2204822848605283\n",
      "20 Train Loss 9.86194 Test MSE 6.397050322237053 Test RE 1.2089210615513608\n",
      "21 Train Loss 9.164654 Test MSE 6.32460541671005 Test RE 1.2020562146858296\n",
      "22 Train Loss 8.583893 Test MSE 6.19140516927519 Test RE 1.1893308193899406\n",
      "23 Train Loss 7.8427334 Test MSE 5.9115809721564725 Test RE 1.1621438320207476\n",
      "24 Train Loss 7.099519 Test MSE 5.716516946222796 Test RE 1.1428094104361735\n",
      "25 Train Loss 6.4330487 Test MSE 5.536693179189339 Test RE 1.1246911789884235\n",
      "26 Train Loss 5.6209493 Test MSE 5.216779880066514 Test RE 1.0917150977999575\n",
      "27 Train Loss 4.780308 Test MSE 5.221246124407679 Test RE 1.0921823231134453\n",
      "28 Train Loss 4.3538146 Test MSE 5.20083427206905 Test RE 1.090045352848806\n",
      "29 Train Loss 3.93265 Test MSE 5.177269446748725 Test RE 1.0875730676786668\n",
      "30 Train Loss 3.557296 Test MSE 5.1532659350983785 Test RE 1.0850489667112189\n",
      "31 Train Loss 3.2591221 Test MSE 5.139858286436803 Test RE 1.0836365196850712\n",
      "32 Train Loss 3.0554852 Test MSE 5.148139120421429 Test RE 1.0845090926488936\n",
      "33 Train Loss 2.8749878 Test MSE 5.139175771361711 Test RE 1.0835645699567327\n",
      "34 Train Loss 2.6979258 Test MSE 5.148944911605169 Test RE 1.0845939634781732\n",
      "35 Train Loss 2.5710266 Test MSE 5.1674475981829024 Test RE 1.0865409551802279\n",
      "36 Train Loss 2.4562674 Test MSE 5.172472783808588 Test RE 1.0870691408166588\n",
      "37 Train Loss 2.3399253 Test MSE 5.201708549674777 Test RE 1.0901369691303506\n",
      "38 Train Loss 2.2569752 Test MSE 5.204875908575359 Test RE 1.0904688148635142\n",
      "39 Train Loss 2.1949275 Test MSE 5.17024883260934 Test RE 1.0868354181135795\n",
      "40 Train Loss 2.1050267 Test MSE 5.183815260135726 Test RE 1.0882603799405295\n",
      "41 Train Loss 2.0285432 Test MSE 5.183167189605437 Test RE 1.0881923517132144\n",
      "42 Train Loss 1.9672918 Test MSE 5.1672818044123074 Test RE 1.0865235246051332\n",
      "43 Train Loss 1.9074358 Test MSE 5.127896485359098 Test RE 1.0823748316975716\n",
      "44 Train Loss 1.8657262 Test MSE 5.178428598505774 Test RE 1.0876948105867759\n",
      "45 Train Loss 1.8261261 Test MSE 5.16212431455019 Test RE 1.0859811569491509\n",
      "46 Train Loss 1.7822016 Test MSE 5.14936442344341 Test RE 1.0846381463882386\n",
      "47 Train Loss 1.7515438 Test MSE 5.167834146826939 Test RE 1.0865815935293093\n",
      "48 Train Loss 1.718882 Test MSE 5.159782167302937 Test RE 1.0857347645534352\n",
      "49 Train Loss 1.690175 Test MSE 5.168070415208626 Test RE 1.086606431975469\n",
      "50 Train Loss 1.6629338 Test MSE 5.146159029470927 Test RE 1.084300509205749\n",
      "51 Train Loss 1.631685 Test MSE 5.107176915166376 Test RE 1.080185918466976\n",
      "52 Train Loss 1.600303 Test MSE 5.099104406314293 Test RE 1.079331898825854\n",
      "53 Train Loss 1.5699544 Test MSE 5.089394995269432 Test RE 1.078303809413124\n",
      "54 Train Loss 1.5454358 Test MSE 5.0795445544573665 Test RE 1.077259784297543\n",
      "55 Train Loss 1.5173194 Test MSE 5.08612284865619 Test RE 1.077957114425713\n",
      "56 Train Loss 1.4931992 Test MSE 5.032136784120708 Test RE 1.0722209265418279\n",
      "57 Train Loss 1.4617933 Test MSE 5.005200054213018 Test RE 1.069347308274616\n",
      "58 Train Loss 1.4311198 Test MSE 4.962187424920341 Test RE 1.0647426289197541\n",
      "59 Train Loss 1.4070857 Test MSE 4.909459401965699 Test RE 1.059070562676604\n",
      "60 Train Loss 1.3809779 Test MSE 4.883709932756176 Test RE 1.056289568452773\n",
      "61 Train Loss 1.3604149 Test MSE 4.845782475135247 Test RE 1.0521799403042318\n",
      "62 Train Loss 1.3386624 Test MSE 4.808406886974055 Test RE 1.048114346318504\n",
      "63 Train Loss 1.3154399 Test MSE 4.827665524329187 Test RE 1.050211203286899\n",
      "64 Train Loss 1.2957866 Test MSE 4.773173874088207 Test RE 1.044267321422182\n",
      "65 Train Loss 1.2753152 Test MSE 4.768961679771924 Test RE 1.0438064511664784\n",
      "66 Train Loss 1.2544364 Test MSE 4.7389474482977985 Test RE 1.0405165843268924\n",
      "67 Train Loss 1.2328645 Test MSE 4.728792246829744 Test RE 1.0394011127356795\n",
      "68 Train Loss 1.2082556 Test MSE 4.711935821883905 Test RE 1.0375469153580934\n",
      "69 Train Loss 1.1913975 Test MSE 4.681792811156526 Test RE 1.0342229136025218\n",
      "70 Train Loss 1.1721458 Test MSE 4.6740633570837264 Test RE 1.0333688304557411\n",
      "71 Train Loss 1.1575755 Test MSE 4.668706726479646 Test RE 1.032776523343119\n",
      "72 Train Loss 1.1431932 Test MSE 4.624364098251831 Test RE 1.0278602490490512\n",
      "73 Train Loss 1.1296821 Test MSE 4.622392776794533 Test RE 1.027641142280104\n",
      "74 Train Loss 1.1096519 Test MSE 4.642433241238657 Test RE 1.0298664110070317\n",
      "75 Train Loss 1.0956169 Test MSE 4.6408847760517205 Test RE 1.0296946427551872\n",
      "76 Train Loss 1.0823935 Test MSE 4.629351339604904 Test RE 1.028414358291363\n",
      "77 Train Loss 1.0694947 Test MSE 4.622179165715088 Test RE 1.0276173972112164\n",
      "78 Train Loss 1.0581652 Test MSE 4.596904503175003 Test RE 1.0248039747007893\n",
      "79 Train Loss 1.047358 Test MSE 4.588062771521958 Test RE 1.023817941278234\n",
      "80 Train Loss 1.0370623 Test MSE 4.590158574274089 Test RE 1.024051751884515\n",
      "81 Train Loss 1.0249761 Test MSE 4.574498575765259 Test RE 1.0223034081319011\n",
      "82 Train Loss 1.0143653 Test MSE 4.565071334140388 Test RE 1.021249470579317\n",
      "83 Train Loss 1.0038191 Test MSE 4.570765273230734 Test RE 1.021886166018269\n",
      "84 Train Loss 0.98852885 Test MSE 4.553365846388182 Test RE 1.0199393162340886\n",
      "85 Train Loss 0.97715515 Test MSE 4.536246563178629 Test RE 1.0180201784795677\n",
      "86 Train Loss 0.9650846 Test MSE 4.5390448764289415 Test RE 1.0183341274810993\n",
      "87 Train Loss 0.95495766 Test MSE 4.524012974859998 Test RE 1.0166465265397104\n",
      "88 Train Loss 0.9467812 Test MSE 4.521523276884723 Test RE 1.0163667427339071\n",
      "89 Train Loss 0.9385481 Test MSE 4.498264851623331 Test RE 1.0137493098021992\n",
      "90 Train Loss 0.9302072 Test MSE 4.4869638996501475 Test RE 1.0124750921755226\n",
      "91 Train Loss 0.9215941 Test MSE 4.472405483668376 Test RE 1.0108312178633903\n",
      "92 Train Loss 0.9131124 Test MSE 4.477565740095014 Test RE 1.0114141977137343\n",
      "93 Train Loss 0.9060868 Test MSE 4.466324657962738 Test RE 1.0101438048810185\n",
      "94 Train Loss 0.89865124 Test MSE 4.450899838513686 Test RE 1.0083979889030588\n",
      "95 Train Loss 0.8921498 Test MSE 4.45171645613014 Test RE 1.0084904912985515\n",
      "96 Train Loss 0.88681793 Test MSE 4.43593299319813 Test RE 1.006701113395386\n",
      "97 Train Loss 0.880417 Test MSE 4.4418814521555445 Test RE 1.0073758659297518\n",
      "98 Train Loss 0.87147623 Test MSE 4.426227970990281 Test RE 1.0055992700727154\n",
      "99 Train Loss 0.8632234 Test MSE 4.403957735445612 Test RE 1.0030662810973259\n",
      "Training time: 70.81\n",
      "KG_stan_tune16\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 160.15921 Test MSE 8.18373149769105 Test RE 1.3673627554356889\n",
      "1 Train Loss 131.70757 Test MSE 8.152951211918491 Test RE 1.3647889010954086\n",
      "2 Train Loss 106.43059 Test MSE 7.746285904894229 Test RE 1.330316021120552\n",
      "3 Train Loss 90.843834 Test MSE 7.594785719626967 Test RE 1.3172427679353689\n",
      "4 Train Loss 80.55616 Test MSE 7.4860291265415375 Test RE 1.3077773656556\n",
      "5 Train Loss 70.97625 Test MSE 7.26886388038096 Test RE 1.288668842826076\n",
      "6 Train Loss 60.647266 Test MSE 6.8594734428664665 Test RE 1.2518533325149315\n",
      "7 Train Loss 53.207123 Test MSE 6.693690434499715 Test RE 1.2366331150750922\n",
      "8 Train Loss 46.938675 Test MSE 6.510554436956358 Test RE 1.2195989661634372\n",
      "9 Train Loss 42.959007 Test MSE 6.468459829052105 Test RE 1.2156498560155409\n",
      "10 Train Loss 39.823917 Test MSE 6.575260340535864 Test RE 1.2256445453165516\n",
      "11 Train Loss 37.114166 Test MSE 6.45591693290217 Test RE 1.214470659641197\n",
      "12 Train Loss 33.725082 Test MSE 6.337137755587598 Test RE 1.2032465751534982\n",
      "13 Train Loss 31.227255 Test MSE 6.42448682575748 Test RE 1.2115107768839208\n",
      "14 Train Loss 29.522104 Test MSE 6.265908924620711 Test RE 1.1964652769805295\n",
      "15 Train Loss 27.751064 Test MSE 6.36145128666103 Test RE 1.2055525977762143\n",
      "16 Train Loss 26.169445 Test MSE 6.28861878358416 Test RE 1.198631521552097\n",
      "17 Train Loss 25.152298 Test MSE 6.289649745678236 Test RE 1.198729769916556\n",
      "18 Train Loss 23.879768 Test MSE 6.229096741113662 Test RE 1.1929454859256259\n",
      "19 Train Loss 22.695602 Test MSE 6.266666740051114 Test RE 1.196537626614616\n",
      "20 Train Loss 21.700039 Test MSE 6.231262803444306 Test RE 1.1931528811380463\n",
      "21 Train Loss 20.9334 Test MSE 6.11019519305738 Test RE 1.1815051048036462\n",
      "22 Train Loss 20.1622 Test MSE 6.123715170910033 Test RE 1.1828115357576872\n",
      "23 Train Loss 19.546978 Test MSE 6.049165069678502 Test RE 1.1755897157282287\n",
      "24 Train Loss 18.84842 Test MSE 6.011316773493401 Test RE 1.1719062417923092\n",
      "25 Train Loss 17.989426 Test MSE 5.997436701961618 Test RE 1.1705524998814532\n",
      "26 Train Loss 17.305796 Test MSE 6.034115006348516 Test RE 1.1741263965884539\n",
      "27 Train Loss 16.652615 Test MSE 6.0293759702102605 Test RE 1.173665241941305\n",
      "28 Train Loss 15.810371 Test MSE 5.874412885095006 Test RE 1.1584846778591562\n",
      "29 Train Loss 15.08582 Test MSE 5.87864823090203 Test RE 1.1589022258974009\n",
      "30 Train Loss 14.467591 Test MSE 5.873523706560656 Test RE 1.1583969977189272\n",
      "31 Train Loss 13.849482 Test MSE 5.813082718340935 Test RE 1.1524213929960678\n",
      "32 Train Loss 13.293161 Test MSE 5.871640832087797 Test RE 1.158211309274184\n",
      "33 Train Loss 12.782929 Test MSE 5.8731477091486495 Test RE 1.1583599193596856\n",
      "34 Train Loss 12.375603 Test MSE 5.878133869417263 Test RE 1.1588515248105329\n",
      "35 Train Loss 11.851288 Test MSE 5.779423626678221 Test RE 1.1490801563137572\n",
      "36 Train Loss 11.36182 Test MSE 5.794134214052583 Test RE 1.150541625694261\n",
      "37 Train Loss 10.796078 Test MSE 5.769844966217057 Test RE 1.1481275342458053\n",
      "38 Train Loss 10.266669 Test MSE 5.669446462615151 Test RE 1.1380946703207013\n",
      "39 Train Loss 9.788912 Test MSE 5.6164702855820465 Test RE 1.1327649250591822\n",
      "40 Train Loss 9.28952 Test MSE 5.520877661966617 Test RE 1.1230836948076186\n",
      "41 Train Loss 8.784151 Test MSE 5.403090547968349 Test RE 1.1110386910101067\n",
      "42 Train Loss 8.211853 Test MSE 5.375393421532648 Test RE 1.1081873491207714\n",
      "43 Train Loss 7.517003 Test MSE 5.273838287323391 Test RE 1.0976691655606847\n",
      "44 Train Loss 7.2068386 Test MSE 5.2683900822747205 Test RE 1.097102038576984\n",
      "45 Train Loss 6.7896852 Test MSE 5.151149001784334 Test RE 1.0848260777434549\n",
      "46 Train Loss 6.2765036 Test MSE 5.101805261084581 Test RE 1.0796177071328763\n",
      "47 Train Loss 5.9219112 Test MSE 5.036481880593572 Test RE 1.0726837416733148\n",
      "48 Train Loss 5.678919 Test MSE 5.044604027337033 Test RE 1.0735483317995353\n",
      "49 Train Loss 5.387171 Test MSE 5.000208235811737 Test RE 1.06881393107629\n",
      "50 Train Loss 5.0803 Test MSE 4.952921077261083 Test RE 1.0637480185919062\n",
      "51 Train Loss 4.79041 Test MSE 4.91087857078277 Test RE 1.059223623451008\n",
      "52 Train Loss 4.5586724 Test MSE 4.942293026253254 Test RE 1.0626061025938365\n",
      "53 Train Loss 4.3582635 Test MSE 4.921040866051338 Test RE 1.0603190058900573\n",
      "54 Train Loss 4.2273726 Test MSE 4.9249175949015775 Test RE 1.060736576089999\n",
      "55 Train Loss 4.0800676 Test MSE 4.9167341817935695 Test RE 1.0598549314366024\n",
      "56 Train Loss 3.9345722 Test MSE 4.954149824505081 Test RE 1.0638799605680775\n",
      "57 Train Loss 3.7614508 Test MSE 4.9113239246639315 Test RE 1.059271651380273\n",
      "58 Train Loss 3.651909 Test MSE 4.939739793985206 Test RE 1.0623315912824074\n",
      "59 Train Loss 3.5311906 Test MSE 4.904928676111855 Test RE 1.0585817648735865\n",
      "60 Train Loss 3.404762 Test MSE 4.900237972868912 Test RE 1.0580754699844097\n",
      "61 Train Loss 3.2989144 Test MSE 4.925133347270239 Test RE 1.0607598103795082\n",
      "62 Train Loss 3.1794925 Test MSE 4.9417558950577005 Test RE 1.062548358709399\n",
      "63 Train Loss 3.0599923 Test MSE 4.88533162164308 Test RE 1.056464930103944\n",
      "64 Train Loss 2.9564986 Test MSE 4.9321476361032195 Test RE 1.061514899420137\n",
      "65 Train Loss 2.852979 Test MSE 4.9517007452213635 Test RE 1.0636169640345057\n",
      "66 Train Loss 2.7450094 Test MSE 4.92075979386724 Test RE 1.060288724650518\n",
      "67 Train Loss 2.635189 Test MSE 4.932507665378023 Test RE 1.0615536421234684\n",
      "68 Train Loss 2.5334542 Test MSE 4.930048325464421 Test RE 1.0612889647092525\n",
      "69 Train Loss 2.4410434 Test MSE 4.938663039588506 Test RE 1.0622158025363608\n",
      "70 Train Loss 2.3529577 Test MSE 4.936893475004621 Test RE 1.0620254850502138\n",
      "71 Train Loss 2.273625 Test MSE 5.000004538910952 Test RE 1.0687921603527177\n",
      "72 Train Loss 2.1835017 Test MSE 5.006625769809167 Test RE 1.069499597550342\n",
      "73 Train Loss 2.1030903 Test MSE 5.050584990863472 Test RE 1.0741845513464243\n",
      "74 Train Loss 2.0463808 Test MSE 5.053306877225197 Test RE 1.0744739647968826\n",
      "75 Train Loss 1.9779261 Test MSE 5.022417890265212 Test RE 1.0711850010215125\n",
      "76 Train Loss 1.9278741 Test MSE 5.0301568697239345 Test RE 1.0720099709778608\n",
      "77 Train Loss 1.8589348 Test MSE 5.04185961613009 Test RE 1.0732562713247622\n",
      "78 Train Loss 1.8093524 Test MSE 5.04925896783042 Test RE 1.0740435293692927\n",
      "79 Train Loss 1.7583688 Test MSE 5.015858810246832 Test RE 1.070485309786651\n",
      "80 Train Loss 1.7093818 Test MSE 5.018789834012317 Test RE 1.0707980338652534\n",
      "81 Train Loss 1.6735895 Test MSE 4.997155043506718 Test RE 1.0684875653910408\n",
      "82 Train Loss 1.6344054 Test MSE 5.051159185506914 Test RE 1.0742456109550653\n",
      "83 Train Loss 1.5976372 Test MSE 5.025778609420461 Test RE 1.0715433294213514\n",
      "84 Train Loss 1.5696943 Test MSE 5.043382739108619 Test RE 1.0734183720150667\n",
      "85 Train Loss 1.5362308 Test MSE 5.074765373818876 Test RE 1.076752885439369\n",
      "86 Train Loss 1.5044359 Test MSE 5.078073551219887 Test RE 1.0771037892711954\n",
      "87 Train Loss 1.472704 Test MSE 5.083154231080826 Test RE 1.0776424828675344\n",
      "88 Train Loss 1.4335685 Test MSE 5.079256303450917 Test RE 1.0772292180116145\n",
      "89 Train Loss 1.4049957 Test MSE 5.07103885378396 Test RE 1.0763574703018075\n",
      "90 Train Loss 1.3697463 Test MSE 5.068073333195606 Test RE 1.076042699785535\n",
      "91 Train Loss 1.3352172 Test MSE 5.045676560386279 Test RE 1.0736624492669768\n",
      "92 Train Loss 1.3066021 Test MSE 5.077719695169288 Test RE 1.077066260636656\n",
      "93 Train Loss 1.2783349 Test MSE 5.0574521012314015 Test RE 1.0749145695697138\n",
      "94 Train Loss 1.2559102 Test MSE 5.059026416384575 Test RE 1.0750818595991602\n",
      "95 Train Loss 1.2358251 Test MSE 5.056141713110305 Test RE 1.074775305123298\n",
      "96 Train Loss 1.2091451 Test MSE 5.064833074450677 Test RE 1.0756986623167613\n",
      "97 Train Loss 1.1862812 Test MSE 5.048095358684577 Test RE 1.0739197647839624\n",
      "98 Train Loss 1.1631696 Test MSE 5.052827611415619 Test RE 1.074423010950458\n",
      "99 Train Loss 1.1380825 Test MSE 5.064770611708639 Test RE 1.0756920291963572\n",
      "Training time: 71.95\n",
      "KG_stan_tune16\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.95\n",
      "KG_stan_tune17\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 540028.75 Test MSE 5.390893838311078 Test RE 1.1097839764879947\n",
      "1 Train Loss 444993.12 Test MSE 5.392500698578648 Test RE 1.1099493604638537\n",
      "2 Train Loss 394684.0 Test MSE 5.365804558724808 Test RE 1.1071984913061348\n",
      "3 Train Loss 353225.44 Test MSE 5.362459123490657 Test RE 1.1068532832083402\n",
      "4 Train Loss 321692.88 Test MSE 5.358488101450367 Test RE 1.1064433823871795\n",
      "5 Train Loss 286539.2 Test MSE 5.346898008968839 Test RE 1.1052461488892509\n",
      "6 Train Loss 254087.64 Test MSE 5.351083702697844 Test RE 1.1056786722737002\n",
      "7 Train Loss 228449.12 Test MSE 5.357263149904701 Test RE 1.1063169085598268\n",
      "8 Train Loss 208613.38 Test MSE 5.353678402609286 Test RE 1.1059467073876328\n",
      "9 Train Loss 198329.4 Test MSE 5.352109444505495 Test RE 1.1057846402007339\n",
      "10 Train Loss 188177.31 Test MSE 5.3571640227197594 Test RE 1.106306673241435\n",
      "11 Train Loss 182368.19 Test MSE 5.360390698800685 Test RE 1.106639793145125\n",
      "12 Train Loss 174473.25 Test MSE 5.35953762308994 Test RE 1.1065517319249587\n",
      "13 Train Loss 167270.14 Test MSE 5.3612964022007965 Test RE 1.106733279342874\n",
      "14 Train Loss 159845.39 Test MSE 5.3493102592024 Test RE 1.105495436386256\n",
      "15 Train Loss 151194.81 Test MSE 5.347482202688918 Test RE 1.1053065259735686\n",
      "16 Train Loss 143745.03 Test MSE 5.344484930656541 Test RE 1.104996719548408\n",
      "17 Train Loss 138803.08 Test MSE 5.34701682538895 Test RE 1.1052584289683736\n",
      "18 Train Loss 133074.56 Test MSE 5.347343081105334 Test RE 1.1052921478991244\n",
      "19 Train Loss 128979.47 Test MSE 5.350069678094509 Test RE 1.1055739048508517\n",
      "20 Train Loss 125167.25 Test MSE 5.350146494110922 Test RE 1.105581841708079\n",
      "21 Train Loss 122937.79 Test MSE 5.346736532838311 Test RE 1.1052294595659669\n",
      "22 Train Loss 120740.01 Test MSE 5.342819858672565 Test RE 1.1048245755128974\n",
      "23 Train Loss 117800.88 Test MSE 5.338226726597398 Test RE 1.1043495738811142\n",
      "24 Train Loss 114778.05 Test MSE 5.337865577029607 Test RE 1.1043122167082553\n",
      "25 Train Loss 112512.13 Test MSE 5.340901214974657 Test RE 1.1046261826131827\n",
      "26 Train Loss 110592.82 Test MSE 5.343984137731156 Test RE 1.104944947720936\n",
      "27 Train Loss 107932.44 Test MSE 5.350994070101726 Test RE 1.1056694119751902\n",
      "28 Train Loss 104283.41 Test MSE 5.3539896192361445 Test RE 1.105978852015679\n",
      "29 Train Loss 102164.44 Test MSE 5.3571023431803315 Test RE 1.1063003045095654\n",
      "30 Train Loss 100357.94 Test MSE 5.353532660617276 Test RE 1.1059316538150195\n",
      "31 Train Loss 98683.87 Test MSE 5.35152532383452 Test RE 1.1057242967700653\n",
      "32 Train Loss 96666.77 Test MSE 5.352297951733917 Test RE 1.1058041135097632\n",
      "33 Train Loss 95101.64 Test MSE 5.349111459441581 Test RE 1.1054748940864445\n",
      "34 Train Loss 93218.89 Test MSE 5.346670532176109 Test RE 1.105222638012213\n",
      "35 Train Loss 92112.484 Test MSE 5.346897361753888 Test RE 1.1052460819970218\n",
      "36 Train Loss 90838.195 Test MSE 5.345759943729287 Test RE 1.1051285190822255\n",
      "37 Train Loss 89947.914 Test MSE 5.347074877335886 Test RE 1.105264428783935\n",
      "38 Train Loss 88770.67 Test MSE 5.348327652649857 Test RE 1.1053938983472167\n",
      "39 Train Loss 87343.35 Test MSE 5.346380981660371 Test RE 1.1051927107784614\n",
      "40 Train Loss 85466.11 Test MSE 5.350316739710349 Test RE 1.105599431782132\n",
      "41 Train Loss 84253.54 Test MSE 5.350804657991342 Test RE 1.105649842804742\n",
      "42 Train Loss 83072.09 Test MSE 5.347640374965964 Test RE 1.105322872690643\n",
      "43 Train Loss 81987.516 Test MSE 5.348209577762439 Test RE 1.1053816964040162\n",
      "44 Train Loss 81045.96 Test MSE 5.349285638525036 Test RE 1.1054928923126774\n",
      "45 Train Loss 79937.086 Test MSE 5.347462503236645 Test RE 1.1053044900665394\n",
      "46 Train Loss 78811.375 Test MSE 5.346858924701827 Test RE 1.105242109368162\n",
      "47 Train Loss 77564.8 Test MSE 5.3488350043871336 Test RE 1.1054463269054111\n",
      "48 Train Loss 76673.6 Test MSE 5.3479714583610285 Test RE 1.1053570885652726\n",
      "49 Train Loss 75728.44 Test MSE 5.345859474020084 Test RE 1.1051388069788066\n",
      "50 Train Loss 74543.81 Test MSE 5.3442058684741545 Test RE 1.104967870480118\n",
      "51 Train Loss 73873.086 Test MSE 5.343174356105051 Test RE 1.1048612275982477\n",
      "52 Train Loss 73211.01 Test MSE 5.344160205914327 Test RE 1.104963149875175\n",
      "53 Train Loss 72283.18 Test MSE 5.343106234477468 Test RE 1.1048541844830546\n",
      "54 Train Loss 71473.52 Test MSE 5.343360959005527 Test RE 1.1048805202973002\n",
      "55 Train Loss 70510.72 Test MSE 5.34460009061974 Test RE 1.1050086244090007\n",
      "56 Train Loss 69837.05 Test MSE 5.343063011216591 Test RE 1.104849715594066\n",
      "57 Train Loss 68826.12 Test MSE 5.343124870824683 Test RE 1.104856111304958\n",
      "58 Train Loss 68283.11 Test MSE 5.345832432273861 Test RE 1.1051360118322922\n",
      "59 Train Loss 67886.52 Test MSE 5.345290967916186 Test RE 1.1050800423531235\n",
      "60 Train Loss 67451.87 Test MSE 5.346304362767709 Test RE 1.1051847915013506\n",
      "61 Train Loss 66938.8 Test MSE 5.348025308534758 Test RE 1.1053626536212826\n",
      "62 Train Loss 66393.516 Test MSE 5.34804640411457 Test RE 1.1053648337010074\n",
      "63 Train Loss 65982.42 Test MSE 5.347056994617403 Test RE 1.105262580563216\n",
      "64 Train Loss 65336.746 Test MSE 5.349373139485367 Test RE 1.1055019338278147\n",
      "65 Train Loss 64696.71 Test MSE 5.349399437060221 Test RE 1.1055046511540667\n",
      "66 Train Loss 64257.137 Test MSE 5.348687018754488 Test RE 1.1054310346683698\n",
      "67 Train Loss 63651.723 Test MSE 5.351222105744096 Test RE 1.1056929710882417\n",
      "68 Train Loss 62976.027 Test MSE 5.353047992276528 Test RE 1.1058815913398519\n",
      "69 Train Loss 62514.47 Test MSE 5.355088079236665 Test RE 1.1060923011732484\n",
      "70 Train Loss 62070.6 Test MSE 5.356523044311797 Test RE 1.1062404871120108\n",
      "71 Train Loss 61620.926 Test MSE 5.35480444207547 Test RE 1.1060630081877714\n",
      "72 Train Loss 61033.434 Test MSE 5.353898259105152 Test RE 1.1059694157997886\n",
      "73 Train Loss 60418.11 Test MSE 5.352888318276896 Test RE 1.1058650977595712\n",
      "74 Train Loss 59816.164 Test MSE 5.351483445936272 Test RE 1.1057199703867093\n",
      "75 Train Loss 59312.727 Test MSE 5.35114139763444 Test RE 1.105684632925083\n",
      "76 Train Loss 58871.418 Test MSE 5.35099747033772 Test RE 1.105669763268453\n",
      "77 Train Loss 58354.742 Test MSE 5.351933112496111 Test RE 1.1057664243144925\n",
      "78 Train Loss 57846.562 Test MSE 5.353203753629938 Test RE 1.1058976805249856\n",
      "79 Train Loss 57444.277 Test MSE 5.3542760536965215 Test RE 1.1060084361427782\n",
      "80 Train Loss 56989.617 Test MSE 5.355547523249451 Test RE 1.1061397491870089\n",
      "81 Train Loss 56533.64 Test MSE 5.355492697057334 Test RE 1.1061340872462506\n",
      "82 Train Loss 56175.51 Test MSE 5.354918148773179 Test RE 1.1060747514835196\n",
      "83 Train Loss 55737.08 Test MSE 5.356360118385857 Test RE 1.1062236630803834\n",
      "84 Train Loss 55332.773 Test MSE 5.35733684395048 Test RE 1.1063245177332288\n",
      "85 Train Loss 54913.016 Test MSE 5.3579654348178245 Test RE 1.106389419858163\n",
      "86 Train Loss 54515.414 Test MSE 5.36039109475206 Test RE 1.1066398340167298\n",
      "87 Train Loss 53930.94 Test MSE 5.36389723454643 Test RE 1.1070016919141314\n",
      "88 Train Loss 53574.742 Test MSE 5.366794131504771 Test RE 1.1073005825178075\n",
      "89 Train Loss 53220.508 Test MSE 5.367992011033652 Test RE 1.1074241515108938\n",
      "90 Train Loss 52807.51 Test MSE 5.370409422749016 Test RE 1.1076734811280011\n",
      "91 Train Loss 52475.43 Test MSE 5.371209327466115 Test RE 1.1077559702067978\n",
      "92 Train Loss 52222.812 Test MSE 5.3713511719138705 Test RE 1.1077705970800862\n",
      "93 Train Loss 51827.63 Test MSE 5.37324973906639 Test RE 1.1079663570467622\n",
      "94 Train Loss 51586.934 Test MSE 5.374332795021914 Test RE 1.1080780147173608\n",
      "95 Train Loss 51294.906 Test MSE 5.37631843804967 Test RE 1.10828269539824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 51017.64 Test MSE 5.3762532802809755 Test RE 1.108275979515695\n",
      "97 Train Loss 50737.88 Test MSE 5.375489863049724 Test RE 1.108197290234045\n",
      "98 Train Loss 50475.246 Test MSE 5.374246689780864 Test RE 1.1080691381078953\n",
      "99 Train Loss 50193.21 Test MSE 5.375003476499633 Test RE 1.1081471529941036\n",
      "Training time: 72.14\n",
      "KG_stan_tune17\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 486199.12 Test MSE 5.277162625373821 Test RE 1.098015066242528\n",
      "1 Train Loss 365131.4 Test MSE 5.262396709605024 Test RE 1.0964778239327613\n",
      "2 Train Loss 294733.0 Test MSE 5.257690331999024 Test RE 1.0959874016712727\n",
      "3 Train Loss 253375.52 Test MSE 5.249729464849544 Test RE 1.0951573494267988\n",
      "4 Train Loss 225315.45 Test MSE 5.2398594613925065 Test RE 1.0941273637609026\n",
      "5 Train Loss 207692.36 Test MSE 5.233737065761763 Test RE 1.093487972712794\n",
      "6 Train Loss 186529.7 Test MSE 5.2320057260277375 Test RE 1.0933070928035358\n",
      "7 Train Loss 168387.53 Test MSE 5.23252789886232 Test RE 1.093361649416236\n",
      "8 Train Loss 155102.31 Test MSE 5.232589093816559 Test RE 1.093368042886254\n",
      "9 Train Loss 147613.94 Test MSE 5.234798042714567 Test RE 1.0935988023868637\n",
      "10 Train Loss 134678.84 Test MSE 5.238251815178017 Test RE 1.0939595057614686\n",
      "11 Train Loss 124514.18 Test MSE 5.239721604374134 Test RE 1.0941129708053956\n",
      "12 Train Loss 116725.2 Test MSE 5.235856900291349 Test RE 1.093709399473714\n",
      "13 Train Loss 110364.75 Test MSE 5.234436823739857 Test RE 1.0935610707065075\n",
      "14 Train Loss 105549.45 Test MSE 5.233789819109334 Test RE 1.0934934835939296\n",
      "15 Train Loss 102459.0 Test MSE 5.233419781155426 Test RE 1.0934548269743862\n",
      "16 Train Loss 98438.74 Test MSE 5.228084682000192 Test RE 1.0928973351541276\n",
      "17 Train Loss 94339.47 Test MSE 5.218849545492591 Test RE 1.0919316356822062\n",
      "18 Train Loss 90478.48 Test MSE 5.208318855862733 Test RE 1.0908294196161616\n",
      "19 Train Loss 85720.72 Test MSE 5.1987567975388265 Test RE 1.0898276216611786\n",
      "20 Train Loss 81188.914 Test MSE 5.189595292268638 Test RE 1.088866924272741\n",
      "21 Train Loss 79353.21 Test MSE 5.188573003964962 Test RE 1.0887596720996644\n",
      "22 Train Loss 77831.82 Test MSE 5.189056851461839 Test RE 1.088810435706634\n",
      "23 Train Loss 76851.016 Test MSE 5.189114003460601 Test RE 1.0888164317405098\n",
      "24 Train Loss 75693.4 Test MSE 5.19051959908301 Test RE 1.088963887740157\n",
      "25 Train Loss 74233.75 Test MSE 5.190669406466386 Test RE 1.0889796023184788\n",
      "26 Train Loss 72897.984 Test MSE 5.193117266022276 Test RE 1.0892363471346478\n",
      "27 Train Loss 70549.8 Test MSE 5.196855491065584 Test RE 1.0896283157616518\n",
      "28 Train Loss 69410.46 Test MSE 5.197726229397657 Test RE 1.0897195960950097\n",
      "29 Train Loss 68181.99 Test MSE 5.199413916160965 Test RE 1.089896496146403\n",
      "30 Train Loss 67221.68 Test MSE 5.2005906160073385 Test RE 1.0900198185542394\n",
      "31 Train Loss 65414.754 Test MSE 5.194844815127442 Test RE 1.0894175054556992\n",
      "32 Train Loss 63899.336 Test MSE 5.191805466061162 Test RE 1.0890987659507645\n",
      "33 Train Loss 62385.527 Test MSE 5.189050263717052 Test RE 1.0888097445591138\n",
      "34 Train Loss 61610.582 Test MSE 5.184655463006991 Test RE 1.0883485700478872\n",
      "35 Train Loss 59692.582 Test MSE 5.180238982168681 Test RE 1.087884923552919\n",
      "36 Train Loss 58269.61 Test MSE 5.173379629486385 Test RE 1.087164429935486\n",
      "37 Train Loss 56875.79 Test MSE 5.168509719204919 Test RE 1.0866526136608887\n",
      "38 Train Loss 55188.914 Test MSE 5.158447678850293 Test RE 1.085594352210982\n",
      "39 Train Loss 53953.785 Test MSE 5.15398139108968 Test RE 1.0851242857274583\n",
      "40 Train Loss 52933.117 Test MSE 5.154486022628022 Test RE 1.0851774072361504\n",
      "41 Train Loss 51966.766 Test MSE 5.154118632077485 Test RE 1.0851387330572204\n",
      "42 Train Loss 50839.324 Test MSE 5.154187950574489 Test RE 1.085146030127629\n",
      "43 Train Loss 49981.387 Test MSE 5.157970132019269 Test RE 1.0855441012271758\n",
      "44 Train Loss 49387.1 Test MSE 5.159729193771204 Test RE 1.0857291911250653\n",
      "45 Train Loss 48617.473 Test MSE 5.1597350986667365 Test RE 1.085729812389804\n",
      "46 Train Loss 47855.2 Test MSE 5.159948315849726 Test RE 1.0857522451170816\n",
      "47 Train Loss 47247.594 Test MSE 5.1647900907753375 Test RE 1.0862615269014446\n",
      "48 Train Loss 46779.484 Test MSE 5.166201299707742 Test RE 1.0864099198896537\n",
      "49 Train Loss 46137.438 Test MSE 5.165966550453913 Test RE 1.0863852366842899\n",
      "50 Train Loss 45488.695 Test MSE 5.161659271248165 Test RE 1.0859322391386628\n",
      "51 Train Loss 44930.15 Test MSE 5.156112914020231 Test RE 1.085348648994322\n",
      "52 Train Loss 44356.555 Test MSE 5.153305783657575 Test RE 1.0850531618716217\n",
      "53 Train Loss 43717.85 Test MSE 5.147387586255392 Test RE 1.0844299305123384\n",
      "54 Train Loss 42970.8 Test MSE 5.143446675713902 Test RE 1.0840147238103048\n",
      "55 Train Loss 42260.72 Test MSE 5.142243289204261 Test RE 1.0838879056388293\n",
      "56 Train Loss 41817.46 Test MSE 5.139777857075101 Test RE 1.083628041189196\n",
      "57 Train Loss 41484.98 Test MSE 5.137717894428033 Test RE 1.083410866725795\n",
      "58 Train Loss 41137.297 Test MSE 5.1361925635421555 Test RE 1.083250028512611\n",
      "59 Train Loss 40503.027 Test MSE 5.132169773838041 Test RE 1.0828257316620324\n",
      "60 Train Loss 39958.19 Test MSE 5.126976392527569 Test RE 1.0822777226779987\n",
      "61 Train Loss 39143.555 Test MSE 5.12056691017644 Test RE 1.0816010071240652\n",
      "62 Train Loss 38768.35 Test MSE 5.119782766730309 Test RE 1.0815181878944502\n",
      "63 Train Loss 38324.836 Test MSE 5.1185276990279585 Test RE 1.0813856176462189\n",
      "64 Train Loss 37782.664 Test MSE 5.116453010414757 Test RE 1.0811664368633525\n",
      "65 Train Loss 37302.59 Test MSE 5.114561863148729 Test RE 1.0809666076146753\n",
      "66 Train Loss 36790.48 Test MSE 5.114048435623996 Test RE 1.080912349600632\n",
      "67 Train Loss 36551.04 Test MSE 5.1141269829867495 Test RE 1.080920650508366\n",
      "68 Train Loss 36175.844 Test MSE 5.1117175538119115 Test RE 1.0806659923246469\n",
      "69 Train Loss 35829.133 Test MSE 5.1100482284765 Test RE 1.0804895222432966\n",
      "70 Train Loss 35381.98 Test MSE 5.110045414215379 Test RE 1.0804892247138078\n",
      "71 Train Loss 34938.445 Test MSE 5.109657798227175 Test RE 1.0804482443694956\n",
      "72 Train Loss 34503.973 Test MSE 5.109039773654222 Test RE 1.0803829010741435\n",
      "73 Train Loss 34048.406 Test MSE 5.106120433828829 Test RE 1.080074187925175\n",
      "74 Train Loss 33729.69 Test MSE 5.105495191998533 Test RE 1.0800080586353455\n",
      "75 Train Loss 33368.42 Test MSE 5.106220650618368 Test RE 1.0800847870716184\n",
      "76 Train Loss 33105.05 Test MSE 5.106593634550743 Test RE 1.0801242337526753\n",
      "77 Train Loss 32847.86 Test MSE 5.105222568636982 Test RE 1.079979223101568\n",
      "78 Train Loss 32580.664 Test MSE 5.104266083821718 Test RE 1.0798780490487427\n",
      "79 Train Loss 32259.902 Test MSE 5.102571127836802 Test RE 1.0796987384772978\n",
      "80 Train Loss 31976.13 Test MSE 5.10015206127088 Test RE 1.0794427721526187\n",
      "81 Train Loss 31661.63 Test MSE 5.098705618233222 Test RE 1.0792896920892974\n",
      "82 Train Loss 31314.018 Test MSE 5.095228556702452 Test RE 1.0789216186049497\n",
      "83 Train Loss 30946.568 Test MSE 5.094111145594904 Test RE 1.0788033054524357\n",
      "84 Train Loss 30722.504 Test MSE 5.09158778634345 Test RE 1.078536080669022\n",
      "85 Train Loss 30522.021 Test MSE 5.090334569030908 Test RE 1.0784033398299264\n",
      "86 Train Loss 30195.363 Test MSE 5.0880249937264335 Test RE 1.0781586666885317\n",
      "87 Train Loss 30000.578 Test MSE 5.087920842620495 Test RE 1.0781476317592311\n",
      "88 Train Loss 29778.477 Test MSE 5.089106362289401 Test RE 1.0782732322566033\n",
      "89 Train Loss 29541.914 Test MSE 5.086820906922363 Test RE 1.0780310854130009\n",
      "90 Train Loss 29231.13 Test MSE 5.082983192385649 Test RE 1.0776243523813953\n",
      "91 Train Loss 28971.646 Test MSE 5.080365446492602 Test RE 1.077346827362358\n",
      "92 Train Loss 28821.088 Test MSE 5.0786090243291575 Test RE 1.0771605770378034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 28562.213 Test MSE 5.075994845111029 Test RE 1.0768833108375495\n",
      "94 Train Loss 28398.818 Test MSE 5.075087391843811 Test RE 1.0767870474460504\n",
      "95 Train Loss 28204.213 Test MSE 5.074244401344873 Test RE 1.07669761460703\n",
      "96 Train Loss 27973.844 Test MSE 5.072387240802613 Test RE 1.076500562281278\n",
      "97 Train Loss 27826.896 Test MSE 5.071197382178739 Test RE 1.0763742944569121\n",
      "98 Train Loss 27644.865 Test MSE 5.070792156827664 Test RE 1.0763312885519742\n",
      "99 Train Loss 27311.021 Test MSE 5.067686761911947 Test RE 1.0760016610008984\n",
      "Training time: 71.19\n",
      "KG_stan_tune17\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1356355.9 Test MSE 6.298336255615436 Test RE 1.1995572552090386\n",
      "1 Train Loss 1028240.1 Test MSE 6.305915766525472 Test RE 1.2002788206510715\n",
      "2 Train Loss 870047.3 Test MSE 6.298235084454323 Test RE 1.199547620832374\n",
      "3 Train Loss 761168.9 Test MSE 6.300406012596406 Test RE 1.19975433805459\n",
      "4 Train Loss 638200.0 Test MSE 6.300417293065931 Test RE 1.1997554120953873\n",
      "5 Train Loss 578418.25 Test MSE 6.294830622217458 Test RE 1.1992233739172087\n",
      "6 Train Loss 519545.97 Test MSE 6.291046178652901 Test RE 1.1988628339935496\n",
      "7 Train Loss 481070.84 Test MSE 6.293130912344913 Test RE 1.1990614577716519\n",
      "8 Train Loss 446074.0 Test MSE 6.2889852590200395 Test RE 1.1986664467578465\n",
      "9 Train Loss 423616.56 Test MSE 6.287027726023718 Test RE 1.1984798815456181\n",
      "10 Train Loss 406952.66 Test MSE 6.280416461266301 Test RE 1.1978495716225792\n",
      "11 Train Loss 393311.8 Test MSE 6.275760444893808 Test RE 1.1974054735832833\n",
      "12 Train Loss 375828.56 Test MSE 6.2694809316577755 Test RE 1.1968062629033298\n",
      "13 Train Loss 360686.88 Test MSE 6.264332138407116 Test RE 1.1963147251070494\n",
      "14 Train Loss 349783.3 Test MSE 6.264743787691502 Test RE 1.1963540312932126\n",
      "15 Train Loss 337165.34 Test MSE 6.268372045412078 Test RE 1.1967004183600938\n",
      "16 Train Loss 323453.2 Test MSE 6.2710053140491775 Test RE 1.1969517517826622\n",
      "17 Train Loss 314436.28 Test MSE 6.2684676582141705 Test RE 1.1967095450873466\n",
      "18 Train Loss 304971.0 Test MSE 6.267016668867407 Test RE 1.196571033301759\n",
      "19 Train Loss 292465.53 Test MSE 6.267059220575247 Test RE 1.196575095526042\n",
      "20 Train Loss 285116.34 Test MSE 6.267636792736578 Test RE 1.1966302324345501\n",
      "21 Train Loss 280192.8 Test MSE 6.268347369445209 Test RE 1.1966980629025108\n",
      "22 Train Loss 275051.9 Test MSE 6.270780104375131 Test RE 1.1969302586152493\n",
      "23 Train Loss 270086.94 Test MSE 6.275975961540166 Test RE 1.1974260335296656\n",
      "24 Train Loss 262088.61 Test MSE 6.278899044249117 Test RE 1.1977048561296872\n",
      "25 Train Loss 255746.31 Test MSE 6.280220282744936 Test RE 1.197830863134508\n",
      "26 Train Loss 248623.25 Test MSE 6.283406108528309 Test RE 1.1981346420183814\n",
      "27 Train Loss 243041.52 Test MSE 6.284583875594302 Test RE 1.1982469264528322\n",
      "28 Train Loss 234891.98 Test MSE 6.288024144629986 Test RE 1.198574850137526\n",
      "29 Train Loss 229665.8 Test MSE 6.2923080246262035 Test RE 1.198983060768766\n",
      "30 Train Loss 225084.3 Test MSE 6.29981144355478 Test RE 1.1996977263365738\n",
      "31 Train Loss 220979.45 Test MSE 6.2981143555474945 Test RE 1.199536123899898\n",
      "32 Train Loss 218807.05 Test MSE 6.300492850807649 Test RE 1.1997626061060023\n",
      "33 Train Loss 214702.67 Test MSE 6.298122164542002 Test RE 1.199536867548518\n",
      "34 Train Loss 210913.19 Test MSE 6.297305834492201 Test RE 1.1994591261442087\n",
      "35 Train Loss 206595.22 Test MSE 6.293936065564595 Test RE 1.1991381602373357\n",
      "36 Train Loss 201544.44 Test MSE 6.286554315358429 Test RE 1.198434758169046\n",
      "37 Train Loss 198432.02 Test MSE 6.283334305503119 Test RE 1.1981277962140384\n",
      "38 Train Loss 194073.78 Test MSE 6.274605591325166 Test RE 1.197295296369014\n",
      "39 Train Loss 190215.39 Test MSE 6.271405702079751 Test RE 1.1969899623630382\n",
      "40 Train Loss 185485.42 Test MSE 6.2697428553429955 Test RE 1.1968312624715824\n",
      "41 Train Loss 182671.77 Test MSE 6.265906077364281 Test RE 1.1964650051409702\n",
      "42 Train Loss 180478.27 Test MSE 6.268780969428348 Test RE 1.1967394517452445\n",
      "43 Train Loss 177350.92 Test MSE 6.269626154776864 Test RE 1.1968201239337621\n",
      "44 Train Loss 174321.55 Test MSE 6.265753806031035 Test RE 1.1964504670656992\n",
      "45 Train Loss 171991.55 Test MSE 6.268540990168455 Test RE 1.1967165449474224\n",
      "46 Train Loss 169530.61 Test MSE 6.270666095890322 Test RE 1.1969193779255116\n",
      "47 Train Loss 165827.22 Test MSE 6.270321976088361 Test RE 1.196886535377052\n",
      "48 Train Loss 162793.39 Test MSE 6.269585336645987 Test RE 1.1968162280045025\n",
      "49 Train Loss 160553.48 Test MSE 6.266689411818478 Test RE 1.196539791050615\n",
      "50 Train Loss 157955.67 Test MSE 6.266884611265101 Test RE 1.1965584262558209\n",
      "51 Train Loss 154998.77 Test MSE 6.267861545804704 Test RE 1.1966516874034665\n",
      "52 Train Loss 153425.45 Test MSE 6.269134470770786 Test RE 1.1967731937950115\n",
      "53 Train Loss 151981.44 Test MSE 6.268439725877499 Test RE 1.196706878811235\n",
      "54 Train Loss 150674.75 Test MSE 6.269092672340788 Test RE 1.196769204143475\n",
      "55 Train Loss 149476.73 Test MSE 6.2717431979992 Test RE 1.19702216995829\n",
      "56 Train Loss 147907.17 Test MSE 6.273520310720707 Test RE 1.197191747425873\n",
      "57 Train Loss 146607.4 Test MSE 6.275414162731335 Test RE 1.1973724380746567\n",
      "58 Train Loss 145495.61 Test MSE 6.276253450725578 Test RE 1.1974525050381557\n",
      "59 Train Loss 143477.64 Test MSE 6.279710951129965 Test RE 1.1977822895597927\n",
      "60 Train Loss 141929.25 Test MSE 6.278485467798136 Test RE 1.1976654104659439\n",
      "61 Train Loss 140312.2 Test MSE 6.277200533882416 Test RE 1.1975428490887494\n",
      "62 Train Loss 138191.81 Test MSE 6.2778214466415205 Test RE 1.1976020754304777\n",
      "63 Train Loss 135862.05 Test MSE 6.280465340219937 Test RE 1.1978542328994317\n",
      "64 Train Loss 133730.42 Test MSE 6.2821195804669046 Test RE 1.1980119766421558\n",
      "65 Train Loss 132189.0 Test MSE 6.284583770563571 Test RE 1.1982469164400165\n",
      "66 Train Loss 130575.14 Test MSE 6.288844086465285 Test RE 1.198652993096623\n",
      "67 Train Loss 129681.836 Test MSE 6.290433314598593 Test RE 1.1988044368834898\n",
      "68 Train Loss 128664.39 Test MSE 6.293040475493811 Test RE 1.1990528420497149\n",
      "69 Train Loss 127305.3 Test MSE 6.291269527389678 Test RE 1.1988841152014285\n",
      "70 Train Loss 126127.39 Test MSE 6.288265767959581 Test RE 1.1985978781076303\n",
      "71 Train Loss 125299.83 Test MSE 6.285968683813421 Test RE 1.1983789360517312\n",
      "72 Train Loss 124206.03 Test MSE 6.283888715898972 Test RE 1.1981806534886552\n",
      "73 Train Loss 122877.01 Test MSE 6.281873769493723 Test RE 1.197988538106257\n",
      "74 Train Loss 121624.305 Test MSE 6.280980111850203 Test RE 1.1979033223146442\n",
      "75 Train Loss 120728.36 Test MSE 6.283172671444753 Test RE 1.1981123856458449\n",
      "76 Train Loss 119388.66 Test MSE 6.281741340273961 Test RE 1.1979759105424646\n",
      "77 Train Loss 118110.71 Test MSE 6.28134198098376 Test RE 1.1979378295082797\n",
      "78 Train Loss 116890.055 Test MSE 6.282356260517671 Test RE 1.1980345440942082\n",
      "79 Train Loss 115506.39 Test MSE 6.283744663562907 Test RE 1.198166919818379\n",
      "80 Train Loss 114306.04 Test MSE 6.2847857141096 Test RE 1.1982661680162794\n",
      "81 Train Loss 113230.36 Test MSE 6.285812211432621 Test RE 1.1983640207394235\n",
      "82 Train Loss 112411.54 Test MSE 6.285766883383713 Test RE 1.198359699929396\n",
      "83 Train Loss 111477.06 Test MSE 6.286141164690686 Test RE 1.1983953771161642\n",
      "84 Train Loss 110446.01 Test MSE 6.283068726252809 Test RE 1.1981024751640321\n",
      "85 Train Loss 109043.086 Test MSE 6.285918798468342 Test RE 1.198374180884439\n",
      "86 Train Loss 107606.02 Test MSE 6.283406818630091 Test RE 1.1981347097203174\n",
      "87 Train Loss 106919.51 Test MSE 6.2842002506786265 Test RE 1.1982103540718783\n",
      "88 Train Loss 106230.68 Test MSE 6.284958530479118 Test RE 1.1982826426102247\n",
      "89 Train Loss 105522.54 Test MSE 6.28398979470037 Test RE 1.1981902900515196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 104326.91 Test MSE 6.284590116028603 Test RE 1.1982475213672696\n",
      "91 Train Loss 103068.234 Test MSE 6.28609800600752 Test RE 1.198391263204799\n",
      "92 Train Loss 101909.24 Test MSE 6.28553525588494 Test RE 1.1983376202355234\n",
      "93 Train Loss 101176.51 Test MSE 6.286929604788404 Test RE 1.198470529210108\n",
      "94 Train Loss 100237.625 Test MSE 6.285830173766865 Test RE 1.1983657329604531\n",
      "95 Train Loss 99321.84 Test MSE 6.286024762227623 Test RE 1.1983842815317873\n",
      "96 Train Loss 98539.95 Test MSE 6.288454181854539 Test RE 1.198615834632642\n",
      "97 Train Loss 97689.69 Test MSE 6.290752249872088 Test RE 1.1988348271726492\n",
      "98 Train Loss 96844.87 Test MSE 6.2922103066409445 Test RE 1.198973750777624\n",
      "99 Train Loss 96087.086 Test MSE 6.293220185871183 Test RE 1.1990699626054475\n",
      "Training time: 71.54\n",
      "KG_stan_tune17\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.84\n",
      "KG_stan_tune18\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.92\n",
      "KG_stan_tune19\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.96\n",
      "KG_stan_tune20\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.449306 Test MSE 8.6837674212038 Test RE 1.4085171907564962\n",
      "1 Train Loss 55.047035 Test MSE 7.231925844512456 Test RE 1.2853903715279025\n",
      "2 Train Loss 49.4926 Test MSE 7.735692725308396 Test RE 1.3294060948768278\n",
      "3 Train Loss 40.94881 Test MSE 7.57294133416837 Test RE 1.3153470542122443\n",
      "4 Train Loss 36.82192 Test MSE 7.38593393234316 Test RE 1.299004840966932\n",
      "5 Train Loss 32.945187 Test MSE 6.682723414570932 Test RE 1.235619642775019\n",
      "6 Train Loss 30.997536 Test MSE 6.343905698521728 Test RE 1.203888925955516\n",
      "7 Train Loss 28.156128 Test MSE 6.361742897137353 Test RE 1.2055802288719124\n",
      "8 Train Loss 26.067814 Test MSE 5.822720381042778 Test RE 1.1533763122295424\n",
      "9 Train Loss 23.365746 Test MSE 4.860579626058597 Test RE 1.0537851916681222\n",
      "10 Train Loss 21.593046 Test MSE 4.435052202588343 Test RE 1.0066011640827732\n",
      "11 Train Loss 19.417145 Test MSE 4.315012029926404 Test RE 0.9928852653148615\n",
      "12 Train Loss 18.276722 Test MSE 4.187100969986292 Test RE 0.9780583771382283\n",
      "13 Train Loss 17.68275 Test MSE 4.067330704491907 Test RE 0.9639684120721361\n",
      "14 Train Loss 17.150925 Test MSE 4.090864728901748 Test RE 0.9667532034225601\n",
      "15 Train Loss 16.79501 Test MSE 3.8938431163111358 Test RE 0.9431858683379614\n",
      "16 Train Loss 16.430897 Test MSE 3.901401843894603 Test RE 0.9441008806200211\n",
      "17 Train Loss 16.064095 Test MSE 3.931375512710314 Test RE 0.947720608066054\n",
      "18 Train Loss 14.548956 Test MSE 3.6354567123191504 Test RE 0.9113549340857211\n",
      "19 Train Loss 12.952343 Test MSE 3.6117962857365855 Test RE 0.9083844344723156\n",
      "20 Train Loss 12.048321 Test MSE 3.5629839671550236 Test RE 0.902225285477046\n",
      "21 Train Loss 11.550907 Test MSE 3.7089349298364636 Test RE 0.9205188098950418\n",
      "22 Train Loss 11.159051 Test MSE 3.6487157799047676 Test RE 0.9130153470510636\n",
      "23 Train Loss 10.644867 Test MSE 3.6490094352365547 Test RE 0.9130520868859157\n",
      "24 Train Loss 10.150188 Test MSE 3.772397686583868 Test RE 0.9283608023569251\n",
      "25 Train Loss 9.876158 Test MSE 3.7960856743906777 Test RE 0.931270965491314\n",
      "26 Train Loss 9.599314 Test MSE 3.8320571653762885 Test RE 0.9356728971990722\n",
      "27 Train Loss 9.306408 Test MSE 3.7085930670748084 Test RE 0.9204763855386858\n",
      "28 Train Loss 8.630228 Test MSE 3.8259841515702777 Test RE 0.9349311797219383\n",
      "29 Train Loss 7.580038 Test MSE 3.648809221779799 Test RE 0.9130270379205233\n",
      "30 Train Loss 6.547119 Test MSE 3.34059103286717 Test RE 0.8736142627708638\n",
      "31 Train Loss 5.5547376 Test MSE 3.1253106355976783 Test RE 0.8449960040980358\n",
      "32 Train Loss 3.3935301 Test MSE 1.9681354613251674 Test RE 0.6705567729975527\n",
      "33 Train Loss 2.5655973 Test MSE 1.530139067334223 Test RE 0.5912532106855362\n",
      "34 Train Loss 1.7956035 Test MSE 0.7129543156708289 Test RE 0.40358861951302466\n",
      "35 Train Loss 1.3207922 Test MSE 0.38551641491887684 Test RE 0.2967764923939772\n",
      "36 Train Loss 0.97907275 Test MSE 0.1656404331903481 Test RE 0.19453208387690596\n",
      "37 Train Loss 0.76294625 Test MSE 0.12462172445780154 Test RE 0.16873490780642156\n",
      "38 Train Loss 0.5579153 Test MSE 0.06073050270757397 Test RE 0.1177908344270271\n",
      "39 Train Loss 0.4454605 Test MSE 0.055725541869415106 Test RE 0.11283275969925308\n",
      "40 Train Loss 0.37147826 Test MSE 0.05607651049801673 Test RE 0.11318752162859914\n",
      "41 Train Loss 0.30222952 Test MSE 0.05355341313363703 Test RE 0.11061184535915528\n",
      "42 Train Loss 0.269889 Test MSE 0.05623470156358516 Test RE 0.1133470594159638\n",
      "43 Train Loss 0.21005645 Test MSE 0.043213912807193805 Test RE 0.09936189277969074\n",
      "44 Train Loss 0.17627443 Test MSE 0.047192124381720546 Test RE 0.10383477452640331\n",
      "45 Train Loss 0.13586268 Test MSE 0.050465725777808786 Test RE 0.10737577761784005\n",
      "46 Train Loss 0.12870754 Test MSE 0.04123510515429126 Test RE 0.09706029645879254\n",
      "47 Train Loss 0.119138986 Test MSE 0.03979072912669861 Test RE 0.09534523838103105\n",
      "48 Train Loss 0.103171125 Test MSE 0.029439340259673742 Test RE 0.08201099799270864\n",
      "49 Train Loss 0.09567677 Test MSE 0.02878126091529649 Test RE 0.08108919117617204\n",
      "50 Train Loss 0.08567781 Test MSE 0.027012366653920723 Test RE 0.0785578118824687\n",
      "51 Train Loss 0.07596502 Test MSE 0.023893910631611347 Test RE 0.0738842174433735\n",
      "52 Train Loss 0.06738014 Test MSE 0.02202862288621174 Test RE 0.07094172335374194\n",
      "53 Train Loss 0.06358639 Test MSE 0.024560780129003406 Test RE 0.07490816163300387\n",
      "54 Train Loss 0.059592254 Test MSE 0.025508289604414106 Test RE 0.07633939781499874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 0.05547608 Test MSE 0.0273434284430228 Test RE 0.07903774553968346\n",
      "56 Train Loss 0.04889988 Test MSE 0.025219004315457493 Test RE 0.07590528727608241\n",
      "57 Train Loss 0.046843555 Test MSE 0.02468178241957052 Test RE 0.07509245795122675\n",
      "58 Train Loss 0.043587793 Test MSE 0.023922006911413975 Test RE 0.07392764402587841\n",
      "59 Train Loss 0.04128276 Test MSE 0.02504083910628874 Test RE 0.07563668723111103\n",
      "60 Train Loss 0.038966723 Test MSE 0.023263834046405807 Test RE 0.07290355491364425\n",
      "61 Train Loss 0.03670291 Test MSE 0.023198283613856677 Test RE 0.07280077240056257\n",
      "62 Train Loss 0.034359414 Test MSE 0.021395776922770816 Test RE 0.06991527832604846\n",
      "63 Train Loss 0.031898547 Test MSE 0.019491355070536145 Test RE 0.06673122183872675\n",
      "64 Train Loss 0.030877516 Test MSE 0.019196039766495455 Test RE 0.0662237669547968\n",
      "65 Train Loss 0.02941787 Test MSE 0.020044168458656454 Test RE 0.06767092022795904\n",
      "66 Train Loss 0.027999956 Test MSE 0.02034278836365012 Test RE 0.06817314047613454\n",
      "67 Train Loss 0.027092779 Test MSE 0.02004793463869175 Test RE 0.06767727741106375\n",
      "68 Train Loss 0.025466679 Test MSE 0.021111906015264106 Test RE 0.06944992518098562\n",
      "69 Train Loss 0.025070999 Test MSE 0.021515390732425317 Test RE 0.07011043780091149\n",
      "70 Train Loss 0.0245911 Test MSE 0.020848889370483466 Test RE 0.06901595831397113\n",
      "71 Train Loss 0.024142008 Test MSE 0.020242988016157266 Test RE 0.06800570845682084\n",
      "72 Train Loss 0.023101883 Test MSE 0.020506752708521658 Test RE 0.06844732930987481\n",
      "73 Train Loss 0.022734744 Test MSE 0.020520919635118155 Test RE 0.06847096837370684\n",
      "74 Train Loss 0.021961173 Test MSE 0.019469220699100464 Test RE 0.06669332110738276\n",
      "75 Train Loss 0.021719726 Test MSE 0.01928806903296473 Test RE 0.06638232147086634\n",
      "76 Train Loss 0.02110115 Test MSE 0.019707763982429405 Test RE 0.06710065145172943\n",
      "77 Train Loss 0.020453304 Test MSE 0.0191603089490216 Test RE 0.06616210497951999\n",
      "78 Train Loss 0.01995757 Test MSE 0.01929810243310606 Test RE 0.06639958483192765\n",
      "79 Train Loss 0.019443633 Test MSE 0.01833820078602619 Test RE 0.0647271406136342\n",
      "80 Train Loss 0.018990027 Test MSE 0.017388774755512496 Test RE 0.0630293097718912\n",
      "81 Train Loss 0.018803827 Test MSE 0.016343617133380558 Test RE 0.06110576003666523\n",
      "82 Train Loss 0.01813151 Test MSE 0.015236837964334502 Test RE 0.05900047184195624\n",
      "83 Train Loss 0.017769841 Test MSE 0.015650607522050677 Test RE 0.059796210293119975\n",
      "84 Train Loss 0.01732032 Test MSE 0.015622091417753451 Test RE 0.0597417097763703\n",
      "85 Train Loss 0.016693793 Test MSE 0.015659818299594837 Test RE 0.059813803494489406\n",
      "86 Train Loss 0.01621446 Test MSE 0.015308151104401172 Test RE 0.05913838094412749\n",
      "87 Train Loss 0.015878402 Test MSE 0.01642346705288832 Test RE 0.06125485019262206\n",
      "88 Train Loss 0.015737424 Test MSE 0.01639607757009198 Test RE 0.061203751397924236\n",
      "89 Train Loss 0.015417572 Test MSE 0.016089588338084885 Test RE 0.06062901694919879\n",
      "90 Train Loss 0.014800372 Test MSE 0.014668527945266947 Test RE 0.05788970368181807\n",
      "91 Train Loss 0.014468939 Test MSE 0.014523968883484091 Test RE 0.057603744468452914\n",
      "92 Train Loss 0.01435484 Test MSE 0.013583583523767628 Test RE 0.05570770139782618\n",
      "93 Train Loss 0.014171002 Test MSE 0.013106588716921814 Test RE 0.05472085771381077\n",
      "94 Train Loss 0.01366606 Test MSE 0.011990406868201773 Test RE 0.05233895175899755\n",
      "95 Train Loss 0.013206154 Test MSE 0.011327884899518956 Test RE 0.05087242896920213\n",
      "96 Train Loss 0.013085774 Test MSE 0.011354638041326207 Test RE 0.05093246642088611\n",
      "97 Train Loss 0.012953711 Test MSE 0.010930736578474945 Test RE 0.04997269535575533\n",
      "98 Train Loss 0.01278766 Test MSE 0.010985219394632538 Test RE 0.05009708170917598\n",
      "99 Train Loss 0.012584722 Test MSE 0.011462620522897243 Test RE 0.051174076946563896\n",
      "Training time: 73.95\n",
      "KG_stan_tune20\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.519775 Test MSE 8.67735052184949 Test RE 1.4079966803055797\n",
      "1 Train Loss 56.66414 Test MSE 9.165493227998267 Test RE 1.4470581404361187\n",
      "2 Train Loss 49.8601 Test MSE 8.499567037507992 Test RE 1.3934983604699016\n",
      "3 Train Loss 44.895752 Test MSE 8.418214428027934 Test RE 1.3868134730082617\n",
      "4 Train Loss 44.445866 Test MSE 8.434637495856784 Test RE 1.3881655788778888\n",
      "5 Train Loss 44.228996 Test MSE 8.502016286933475 Test RE 1.3936991224147985\n",
      "6 Train Loss 43.73978 Test MSE 8.4116274119811 Test RE 1.3862707955591966\n",
      "7 Train Loss 43.330986 Test MSE 8.164589426029622 Test RE 1.3657626614332186\n",
      "8 Train Loss 41.32128 Test MSE 7.56460506001433 Test RE 1.3146228895570384\n",
      "9 Train Loss 39.7809 Test MSE 7.771947618542054 Test RE 1.332517718998812\n",
      "10 Train Loss 39.457893 Test MSE 7.886600568835654 Test RE 1.342310486892014\n",
      "11 Train Loss 39.17257 Test MSE 7.650324789027748 Test RE 1.3220503542814561\n",
      "12 Train Loss 38.658142 Test MSE 7.773837809697352 Test RE 1.332679747888279\n",
      "13 Train Loss 38.421497 Test MSE 7.676167781051504 Test RE 1.3242814315984688\n",
      "14 Train Loss 38.18555 Test MSE 7.761513136440923 Test RE 1.3316229109681759\n",
      "15 Train Loss 37.913017 Test MSE 7.724378576569748 Test RE 1.3284335509436382\n",
      "16 Train Loss 36.864857 Test MSE 7.5918963662165515 Test RE 1.316992178775967\n",
      "17 Train Loss 34.878563 Test MSE 8.055857119978311 Test RE 1.3566378752268515\n",
      "18 Train Loss 33.37672 Test MSE 7.914945940163595 Test RE 1.34472053432929\n",
      "19 Train Loss 32.762127 Test MSE 7.925028882199249 Test RE 1.3455767893115422\n",
      "20 Train Loss 32.08938 Test MSE 7.839535698688939 Test RE 1.3382992399758868\n",
      "21 Train Loss 31.332933 Test MSE 7.790798998881596 Test RE 1.3341327957832214\n",
      "22 Train Loss 30.946125 Test MSE 7.706290996566116 Test RE 1.3268772943075207\n",
      "23 Train Loss 30.554688 Test MSE 7.799221817995545 Test RE 1.334853782402487\n",
      "24 Train Loss 29.814497 Test MSE 7.8437203297609255 Test RE 1.3386563747386784\n",
      "25 Train Loss 29.24004 Test MSE 7.8212658146063045 Test RE 1.336738890298266\n",
      "26 Train Loss 28.69667 Test MSE 7.7517884193815405 Test RE 1.33078842710899\n",
      "27 Train Loss 28.27274 Test MSE 7.86034404302788 Test RE 1.3400741752519747\n",
      "28 Train Loss 27.717312 Test MSE 7.888217223572155 Test RE 1.3424480582949594\n",
      "29 Train Loss 27.423367 Test MSE 7.848935692745861 Test RE 1.3391013433549268\n",
      "30 Train Loss 27.097984 Test MSE 7.6757386731489134 Test RE 1.3242444165418938\n",
      "31 Train Loss 26.89201 Test MSE 7.681492522470405 Test RE 1.3247406603415743\n",
      "32 Train Loss 26.46624 Test MSE 7.743741945924019 Test RE 1.3300975585360666\n",
      "33 Train Loss 24.670612 Test MSE 7.728786528486385 Test RE 1.3288125352208753\n",
      "34 Train Loss 23.202728 Test MSE 7.518506736129033 Test RE 1.3106111453937346\n",
      "35 Train Loss 22.197926 Test MSE 7.43875653629606 Test RE 1.3036416663474442\n",
      "36 Train Loss 21.530342 Test MSE 7.419909462292867 Test RE 1.3019891446312677\n",
      "37 Train Loss 20.706932 Test MSE 7.479780380514639 Test RE 1.3072314370651432\n",
      "38 Train Loss 20.261024 Test MSE 7.156527180480729 Test RE 1.2786721990051484\n",
      "39 Train Loss 19.898062 Test MSE 7.243638012607935 Test RE 1.2864308010100045\n",
      "40 Train Loss 19.534115 Test MSE 7.412900284545153 Test RE 1.301374040795965\n",
      "41 Train Loss 19.211779 Test MSE 7.531492735838872 Test RE 1.3117425039074277\n",
      "42 Train Loss 19.033745 Test MSE 7.559208820464109 Test RE 1.31415391030684\n",
      "43 Train Loss 18.840816 Test MSE 7.636605374867905 Test RE 1.3208643984030155\n",
      "44 Train Loss 18.575565 Test MSE 7.702162674647337 Test RE 1.3265218372894267\n",
      "45 Train Loss 18.429798 Test MSE 7.683158228180646 Test RE 1.324884285324875\n",
      "46 Train Loss 18.257778 Test MSE 7.678007470708476 Test RE 1.3244401123991725\n",
      "47 Train Loss 18.072266 Test MSE 7.747351452674175 Test RE 1.3304075144217784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 17.869572 Test MSE 7.6603278148752185 Test RE 1.3229143819009679\n",
      "49 Train Loss 17.485172 Test MSE 7.365011517720806 Test RE 1.297163666059308\n",
      "50 Train Loss 17.156818 Test MSE 7.339842613214142 Test RE 1.2949453308410512\n",
      "51 Train Loss 16.675337 Test MSE 7.003318658920711 Test RE 1.264911101335517\n",
      "52 Train Loss 15.6172695 Test MSE 6.592595320699779 Test RE 1.2272591231169632\n",
      "53 Train Loss 14.873318 Test MSE 6.500216393799283 Test RE 1.2186302870761923\n",
      "54 Train Loss 12.880829 Test MSE 6.216103855843255 Test RE 1.191700691099306\n",
      "55 Train Loss 10.903472 Test MSE 6.278291983836678 Test RE 1.1976469561082304\n",
      "56 Train Loss 9.845564 Test MSE 5.709714939968679 Test RE 1.142129301326738\n",
      "57 Train Loss 8.71516 Test MSE 5.950985047668751 Test RE 1.1660105765777637\n",
      "58 Train Loss 7.8747044 Test MSE 6.023172034480111 Test RE 1.1730612642023628\n",
      "59 Train Loss 7.3785114 Test MSE 5.9502120112729555 Test RE 1.1659348413944004\n",
      "60 Train Loss 6.904236 Test MSE 5.497001642683619 Test RE 1.120652575720503\n",
      "61 Train Loss 6.6473446 Test MSE 5.652897665971642 Test RE 1.1364324391488632\n",
      "62 Train Loss 6.3011026 Test MSE 5.128147739388955 Test RE 1.0824013481949222\n",
      "63 Train Loss 6.045754 Test MSE 4.745007720572553 Test RE 1.0411816897284811\n",
      "64 Train Loss 5.5916348 Test MSE 4.209087136961439 Test RE 0.9806228722563922\n",
      "65 Train Loss 4.8805537 Test MSE 2.9248030958791316 Test RE 0.8174409257109319\n",
      "66 Train Loss 3.3850367 Test MSE 2.537585806320449 Test RE 0.7614097408407686\n",
      "67 Train Loss 2.7798305 Test MSE 2.5134632388490377 Test RE 0.7577820769871085\n",
      "68 Train Loss 2.4387095 Test MSE 2.5839562502408433 Test RE 0.7683350377009451\n",
      "69 Train Loss 2.135542 Test MSE 2.6021364567381022 Test RE 0.7710332269243344\n",
      "70 Train Loss 1.9416925 Test MSE 2.4858453302477064 Test RE 0.753607326388937\n",
      "71 Train Loss 1.7853649 Test MSE 2.5749959659884336 Test RE 0.7670017181087501\n",
      "72 Train Loss 1.6397858 Test MSE 2.55490283028064 Test RE 0.7640033343685874\n",
      "73 Train Loss 1.5385736 Test MSE 2.4998141840511865 Test RE 0.7557217546397147\n",
      "74 Train Loss 1.4757243 Test MSE 2.4704661409015447 Test RE 0.7512725368781934\n",
      "75 Train Loss 1.4135001 Test MSE 2.510967277848372 Test RE 0.7574057308621274\n",
      "76 Train Loss 1.3681054 Test MSE 2.5607401985455214 Test RE 0.7648756227945213\n",
      "77 Train Loss 1.2759191 Test MSE 2.546723181238152 Test RE 0.7627793565060975\n",
      "78 Train Loss 1.2263937 Test MSE 2.586705664442155 Test RE 0.7687436958637734\n",
      "79 Train Loss 1.2036759 Test MSE 2.5789699488108533 Test RE 0.767593345549597\n",
      "80 Train Loss 1.1777742 Test MSE 2.5886670962863905 Test RE 0.7690350998405537\n",
      "81 Train Loss 1.1556627 Test MSE 2.5913947825092603 Test RE 0.7694401604518761\n",
      "82 Train Loss 1.1296328 Test MSE 2.5556896699657017 Test RE 0.7641209713015338\n",
      "83 Train Loss 1.1122944 Test MSE 2.5664810182484126 Test RE 0.7657325146405374\n",
      "84 Train Loss 1.0938286 Test MSE 2.5724945219566138 Test RE 0.7666290810106401\n",
      "85 Train Loss 1.0638326 Test MSE 2.585844171699207 Test RE 0.7686156715827613\n",
      "86 Train Loss 1.0473717 Test MSE 2.6022217023842136 Test RE 0.7710458562941626\n",
      "87 Train Loss 1.0177994 Test MSE 2.6146376917914074 Test RE 0.7728831142534678\n",
      "88 Train Loss 0.99839085 Test MSE 2.6624094320946385 Test RE 0.7799117831948311\n",
      "89 Train Loss 0.9807494 Test MSE 2.6495243239926225 Test RE 0.7780222474013858\n",
      "90 Train Loss 0.9715753 Test MSE 2.6606799935098633 Test RE 0.7796584358651105\n",
      "91 Train Loss 0.953506 Test MSE 2.6908483747816336 Test RE 0.7840660937690088\n",
      "92 Train Loss 0.938538 Test MSE 2.6585398111366136 Test RE 0.7793448042131177\n",
      "93 Train Loss 0.9146073 Test MSE 2.675041667093606 Test RE 0.7817598029448779\n",
      "94 Train Loss 0.89260477 Test MSE 2.7039155337403433 Test RE 0.7859675587587502\n",
      "95 Train Loss 0.87763774 Test MSE 2.713668226884784 Test RE 0.7873837274247276\n",
      "96 Train Loss 0.86315596 Test MSE 2.7585994677037142 Test RE 0.793875472653691\n",
      "97 Train Loss 0.8460437 Test MSE 2.7830781642035256 Test RE 0.797389958350111\n",
      "98 Train Loss 0.83295435 Test MSE 2.779741352125184 Test RE 0.7969117938324481\n",
      "99 Train Loss 0.8235921 Test MSE 2.775672683785546 Test RE 0.7963283659706375\n",
      "Training time: 75.72\n",
      "KG_stan_tune20\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.93708 Test MSE 8.623947407252821 Test RE 1.4036573688375014\n",
      "1 Train Loss 50.792603 Test MSE 8.45343947892881 Test RE 1.3897119249202836\n",
      "2 Train Loss 45.78032 Test MSE 7.3750542729574615 Test RE 1.298047755604426\n",
      "3 Train Loss 43.367634 Test MSE 8.106195668612232 Test RE 1.3608698787286135\n",
      "4 Train Loss 37.99788 Test MSE 7.276537121931232 Test RE 1.2893488431161422\n",
      "5 Train Loss 35.445045 Test MSE 7.590242203553432 Test RE 1.3168486943377964\n",
      "6 Train Loss 33.219063 Test MSE 6.913280574135685 Test RE 1.2567536400192516\n",
      "7 Train Loss 32.395855 Test MSE 6.694113077510365 Test RE 1.2366721552800468\n",
      "8 Train Loss 30.316479 Test MSE 6.7246366341880615 Test RE 1.239488413383579\n",
      "9 Train Loss 29.687262 Test MSE 6.38834616862675 Test RE 1.208098321699547\n",
      "10 Train Loss 29.053186 Test MSE 6.343292057829494 Test RE 1.2038306989629766\n",
      "11 Train Loss 27.352276 Test MSE 6.275702042248317 Test RE 1.1973999020027\n",
      "12 Train Loss 26.99422 Test MSE 6.161535216909867 Test RE 1.1864584338146618\n",
      "13 Train Loss 26.250153 Test MSE 5.870672734217822 Test RE 1.1581158241998317\n",
      "14 Train Loss 25.313898 Test MSE 5.654345288820778 Test RE 1.13657794154012\n",
      "15 Train Loss 24.355587 Test MSE 5.903825198504545 Test RE 1.161381237142844\n",
      "16 Train Loss 23.78862 Test MSE 5.722339932393213 Test RE 1.1433913093172257\n",
      "17 Train Loss 23.382763 Test MSE 5.728476561204534 Test RE 1.1440042306049292\n",
      "18 Train Loss 22.809137 Test MSE 5.496866818936175 Test RE 1.1206388326368992\n",
      "19 Train Loss 22.246609 Test MSE 5.7135160264635525 Test RE 1.1425094087417245\n",
      "20 Train Loss 22.087406 Test MSE 5.729296926916265 Test RE 1.144086143155056\n",
      "21 Train Loss 21.811543 Test MSE 5.709754258004177 Test RE 1.1421332337650103\n",
      "22 Train Loss 21.449356 Test MSE 5.637920690762012 Test RE 1.1349259897148862\n",
      "23 Train Loss 20.596935 Test MSE 5.482720391736491 Test RE 1.119195897147331\n",
      "24 Train Loss 18.55649 Test MSE 4.063977422041102 Test RE 0.9635709616171014\n",
      "25 Train Loss 16.184595 Test MSE 3.6397232212030644 Test RE 0.9118895524415024\n",
      "26 Train Loss 12.09302 Test MSE 3.214651716391543 Test RE 0.8569885587387297\n",
      "27 Train Loss 9.991582 Test MSE 2.6448543774436692 Test RE 0.7773362894208738\n",
      "28 Train Loss 9.279022 Test MSE 2.221757552661772 Test RE 0.712453284353507\n",
      "29 Train Loss 8.922303 Test MSE 2.0959243512150763 Test RE 0.6919836959423605\n",
      "30 Train Loss 8.665976 Test MSE 2.1055351392278956 Test RE 0.6935684149034789\n",
      "31 Train Loss 8.4045 Test MSE 2.1168396711906596 Test RE 0.6954277927261381\n",
      "32 Train Loss 8.280253 Test MSE 2.1240201495401076 Test RE 0.6966062657250958\n",
      "33 Train Loss 8.086686 Test MSE 2.0690569815023516 Test RE 0.6875341679488886\n",
      "34 Train Loss 7.9967856 Test MSE 2.0140403406708005 Test RE 0.6783317464081208\n",
      "35 Train Loss 7.8446393 Test MSE 1.9401413573124726 Test RE 0.6657708053198764\n",
      "36 Train Loss 7.716111 Test MSE 2.0278200231021293 Test RE 0.6806482994543789\n",
      "37 Train Loss 7.540489 Test MSE 2.090608842267227 Test RE 0.6911056631540033\n",
      "38 Train Loss 7.319479 Test MSE 2.128506260135868 Test RE 0.6973415234383094\n",
      "39 Train Loss 7.001333 Test MSE 2.165091230786798 Test RE 0.7033089770370973\n",
      "40 Train Loss 6.7761784 Test MSE 2.141798052781297 Test RE 0.6995154643388586\n",
      "41 Train Loss 6.5154324 Test MSE 2.1162844847261835 Test RE 0.6953365913419839\n",
      "42 Train Loss 6.315075 Test MSE 2.112632051533951 Test RE 0.6947363017314455\n",
      "43 Train Loss 6.1137056 Test MSE 2.115643969001116 Test RE 0.6952313579178944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 5.9255266 Test MSE 2.08564354160364 Test RE 0.6902844699958478\n",
      "45 Train Loss 5.670203 Test MSE 2.195813355252627 Test RE 0.7082812928959181\n",
      "46 Train Loss 5.5162024 Test MSE 2.1556018860342636 Test RE 0.7017660235338663\n",
      "47 Train Loss 5.3625126 Test MSE 2.205365448765348 Test RE 0.7098201821861928\n",
      "48 Train Loss 5.2352014 Test MSE 2.159247443539239 Test RE 0.7023591867848766\n",
      "49 Train Loss 5.106652 Test MSE 2.184445663260142 Test RE 0.7064455332041323\n",
      "50 Train Loss 5.001913 Test MSE 2.152071310013426 Test RE 0.7011910904607971\n",
      "51 Train Loss 4.8893332 Test MSE 2.1525437422138696 Test RE 0.7012680505201706\n",
      "52 Train Loss 4.7572575 Test MSE 2.0985226166022892 Test RE 0.6924124805998333\n",
      "53 Train Loss 4.6816626 Test MSE 2.095889672414215 Test RE 0.6919779711975621\n",
      "54 Train Loss 4.613886 Test MSE 2.104218983671466 Test RE 0.6933516085905022\n",
      "55 Train Loss 4.53922 Test MSE 2.1234187869860293 Test RE 0.6965076455263698\n",
      "56 Train Loss 4.502524 Test MSE 2.115414220516328 Test RE 0.6951936075473071\n",
      "57 Train Loss 4.4574876 Test MSE 2.0828867555978485 Test RE 0.6898281130546584\n",
      "58 Train Loss 4.404887 Test MSE 2.1085982664476868 Test RE 0.6940727323421647\n",
      "59 Train Loss 4.3485947 Test MSE 2.1116553402119975 Test RE 0.6945756880417943\n",
      "60 Train Loss 4.3287 Test MSE 2.1192190658939163 Test RE 0.6958185243689677\n",
      "61 Train Loss 4.29502 Test MSE 2.1142800340219328 Test RE 0.6950072173576668\n",
      "62 Train Loss 4.2730966 Test MSE 2.120710682321048 Test RE 0.6960633579001522\n",
      "63 Train Loss 4.260167 Test MSE 2.1323103577257085 Test RE 0.6979643947578572\n",
      "64 Train Loss 4.249361 Test MSE 2.140232320846867 Test RE 0.6992597320254297\n",
      "65 Train Loss 4.236872 Test MSE 2.1372523279376234 Test RE 0.698772748701463\n",
      "66 Train Loss 4.2164407 Test MSE 2.1394267458446357 Test RE 0.6991281203374764\n",
      "67 Train Loss 4.2033134 Test MSE 2.154487658915023 Test RE 0.7015846292304612\n",
      "68 Train Loss 4.1995277 Test MSE 2.142102831125476 Test RE 0.6995652331722721\n",
      "69 Train Loss 4.179641 Test MSE 2.1364217597417277 Test RE 0.6986369587410232\n",
      "70 Train Loss 4.1649995 Test MSE 2.124630066443148 Test RE 0.6967062745315046\n",
      "71 Train Loss 4.1448236 Test MSE 2.1172021391003235 Test RE 0.6954873294667248\n",
      "72 Train Loss 4.137132 Test MSE 2.1259929669165096 Test RE 0.6969296990932756\n",
      "73 Train Loss 4.1183605 Test MSE 2.1173832684715634 Test RE 0.6955170787490884\n",
      "74 Train Loss 4.0959873 Test MSE 2.120127408044985 Test RE 0.6959676296675397\n",
      "75 Train Loss 4.0912876 Test MSE 2.121128965796982 Test RE 0.6961319993815547\n",
      "76 Train Loss 4.080852 Test MSE 2.1300458461951797 Test RE 0.6975936775514487\n",
      "77 Train Loss 4.0728 Test MSE 2.117526447138628 Test RE 0.6955405939828032\n",
      "78 Train Loss 4.0676527 Test MSE 2.1187027744074505 Test RE 0.6957337603469644\n",
      "79 Train Loss 4.060277 Test MSE 2.1111678697754566 Test RE 0.6944955128706729\n",
      "80 Train Loss 4.05466 Test MSE 2.10324004476258 Test RE 0.6931903069783948\n",
      "81 Train Loss 4.0426197 Test MSE 2.09482951276111 Test RE 0.6918029381486421\n",
      "82 Train Loss 4.025495 Test MSE 2.10591808369191 Test RE 0.6936314834566052\n",
      "83 Train Loss 4.003895 Test MSE 2.1037705852301176 Test RE 0.6932777297909422\n",
      "84 Train Loss 3.9941711 Test MSE 2.1102856656244846 Test RE 0.6943503915723969\n",
      "85 Train Loss 3.986662 Test MSE 2.1087327128713915 Test RE 0.6940948593899556\n",
      "86 Train Loss 3.9810667 Test MSE 2.110029004812606 Test RE 0.6943081655465131\n",
      "87 Train Loss 3.9692001 Test MSE 2.098297625640953 Test RE 0.6923753614560444\n",
      "88 Train Loss 3.9481957 Test MSE 2.1097608101049445 Test RE 0.6942640392116447\n",
      "89 Train Loss 3.8873754 Test MSE 2.1006724504545105 Test RE 0.6927670611822904\n",
      "90 Train Loss 3.7940426 Test MSE 2.097915192444774 Test RE 0.6923122628314127\n",
      "91 Train Loss 3.6085377 Test MSE 2.076498068758386 Test RE 0.6887693708164817\n",
      "92 Train Loss 3.107714 Test MSE 1.9822840040688903 Test RE 0.6729627078516874\n",
      "93 Train Loss 2.3592174 Test MSE 1.5913876416518908 Test RE 0.6029704802741711\n",
      "94 Train Loss 2.0472121 Test MSE 1.2859445918365215 Test RE 0.5420248381637335\n",
      "95 Train Loss 1.7481081 Test MSE 0.890480861181733 Test RE 0.45104550088705814\n",
      "96 Train Loss 1.4655781 Test MSE 0.7507684819853959 Test RE 0.41415325250155555\n",
      "97 Train Loss 1.1493936 Test MSE 0.4684762879709232 Test RE 0.3271537232212739\n",
      "98 Train Loss 0.98009735 Test MSE 0.3739150856330223 Test RE 0.2922769413558536\n",
      "99 Train Loss 0.86723125 Test MSE 0.30236939043160616 Test RE 0.26283123302855876\n",
      "Training time: 75.90\n",
      "KG_stan_tune20\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.36501 Test MSE 8.642727607812215 Test RE 1.4051848961880717\n",
      "1 Train Loss 55.26719 Test MSE 8.450704748460378 Test RE 1.3894871173155297\n",
      "2 Train Loss 51.401924 Test MSE 9.140989111215312 Test RE 1.445122477372953\n",
      "3 Train Loss 45.676933 Test MSE 8.410389842010291 Test RE 1.386168813497269\n",
      "4 Train Loss 44.082726 Test MSE 8.240509098748063 Test RE 1.372097843941143\n",
      "5 Train Loss 42.91182 Test MSE 8.354935878065106 Test RE 1.3815913988561952\n",
      "6 Train Loss 42.61954 Test MSE 8.470264825495164 Test RE 1.391094247557977\n",
      "7 Train Loss 42.530014 Test MSE 8.5131740098086 Test RE 1.394613341432124\n",
      "8 Train Loss 42.05231 Test MSE 8.641525753202556 Test RE 1.4050871905367086\n",
      "9 Train Loss 40.248283 Test MSE 8.351130385390613 Test RE 1.3812767205124294\n",
      "10 Train Loss 37.969475 Test MSE 7.966155606560891 Test RE 1.349063688662479\n",
      "11 Train Loss 36.203693 Test MSE 7.850509841626787 Test RE 1.3392356188340557\n",
      "12 Train Loss 34.61481 Test MSE 7.399959211854301 Test RE 1.3002376075540578\n",
      "13 Train Loss 33.66294 Test MSE 7.295981676250275 Test RE 1.2910704097635024\n",
      "14 Train Loss 32.981445 Test MSE 7.318364703291591 Test RE 1.293049302757442\n",
      "15 Train Loss 32.506516 Test MSE 7.217728988274774 Test RE 1.28412808902323\n",
      "16 Train Loss 31.99995 Test MSE 7.0731357916117705 Test RE 1.2712005093119825\n",
      "17 Train Loss 31.415958 Test MSE 7.059285233939704 Test RE 1.2699552720984815\n",
      "18 Train Loss 30.82495 Test MSE 7.124113453387586 Test RE 1.2757731973176258\n",
      "19 Train Loss 30.195229 Test MSE 6.977188085825419 Test RE 1.2625490967838107\n",
      "20 Train Loss 29.429153 Test MSE 7.192314497350636 Test RE 1.2818653107482427\n",
      "21 Train Loss 28.791315 Test MSE 7.041735502828786 Test RE 1.2683757040592576\n",
      "22 Train Loss 27.013851 Test MSE 6.96657560719068 Test RE 1.261588546917796\n",
      "23 Train Loss 26.123457 Test MSE 7.04876801995684 Test RE 1.269008903639261\n",
      "24 Train Loss 24.475643 Test MSE 6.563462262680481 Test RE 1.2245444563922758\n",
      "25 Train Loss 23.10516 Test MSE 6.68659775677727 Test RE 1.2359777691992635\n",
      "26 Train Loss 21.239967 Test MSE 6.538479840865286 Test RE 1.2222117506483352\n",
      "27 Train Loss 19.076778 Test MSE 6.1990642873247435 Test RE 1.190066226739427\n",
      "28 Train Loss 16.956463 Test MSE 5.301438922215008 Test RE 1.1005377433022159\n",
      "29 Train Loss 13.919344 Test MSE 4.591308923969053 Test RE 1.0241800637722416\n",
      "30 Train Loss 10.853919 Test MSE 4.3960164722718895 Test RE 1.0021615031727404\n",
      "31 Train Loss 8.475084 Test MSE 3.814059607367654 Test RE 0.9334730805629516\n",
      "32 Train Loss 7.197214 Test MSE 3.544560972209982 Test RE 0.8998897102885608\n",
      "33 Train Loss 6.385104 Test MSE 3.368156586803079 Test RE 0.8772112589461067\n",
      "34 Train Loss 5.797161 Test MSE 3.3434556681739434 Test RE 0.8739887548832318\n",
      "35 Train Loss 5.3680897 Test MSE 3.3226843526527112 Test RE 0.8712696849567736\n",
      "36 Train Loss 5.107885 Test MSE 3.280504955234463 Test RE 0.8657219107835274\n",
      "37 Train Loss 4.721838 Test MSE 2.8853928459484757 Test RE 0.8119149450606642\n",
      "38 Train Loss 3.5330162 Test MSE 2.077845419616827 Test RE 0.6889927910856019\n",
      "39 Train Loss 2.3803341 Test MSE 1.9475994824230658 Test RE 0.6670492274304816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 1.9709214 Test MSE 1.858423393396218 Test RE 0.6515989744340598\n",
      "41 Train Loss 1.6722622 Test MSE 1.8303332057292736 Test RE 0.6466557440513518\n",
      "42 Train Loss 1.4485383 Test MSE 1.795479657394321 Test RE 0.6404692815466249\n",
      "43 Train Loss 1.2970362 Test MSE 1.8128777138186734 Test RE 0.64356484911334\n",
      "44 Train Loss 1.2022599 Test MSE 1.8535378058070313 Test RE 0.6507419203154449\n",
      "45 Train Loss 1.1461122 Test MSE 1.8618046624822742 Test RE 0.6521914740311687\n",
      "46 Train Loss 1.1073184 Test MSE 1.8721213626144653 Test RE 0.6539959513576692\n",
      "47 Train Loss 1.0488632 Test MSE 1.8224631738841832 Test RE 0.6452640073751653\n",
      "48 Train Loss 1.017983 Test MSE 1.7977623561880707 Test RE 0.640876285342078\n",
      "49 Train Loss 0.98037666 Test MSE 1.8028896178108205 Test RE 0.6417895319709216\n",
      "50 Train Loss 0.9501217 Test MSE 1.8046389331005437 Test RE 0.6421008155984328\n",
      "51 Train Loss 0.93167895 Test MSE 1.8084516370997497 Test RE 0.6427787486202585\n",
      "52 Train Loss 0.90498996 Test MSE 1.811124959649252 Test RE 0.6432536632716073\n",
      "53 Train Loss 0.87665415 Test MSE 1.8140829177371742 Test RE 0.6437787350267123\n",
      "54 Train Loss 0.8441759 Test MSE 1.8088126053738776 Test RE 0.6428428949745085\n",
      "55 Train Loss 0.81798315 Test MSE 1.794418204661355 Test RE 0.6402799370526756\n",
      "56 Train Loss 0.79452956 Test MSE 1.8207554760323585 Test RE 0.6449616215087712\n",
      "57 Train Loss 0.78360885 Test MSE 1.8164143523738943 Test RE 0.6441922900227732\n",
      "58 Train Loss 0.77172595 Test MSE 1.833958812354391 Test RE 0.6472958896430182\n",
      "59 Train Loss 0.76187605 Test MSE 1.844232284888585 Test RE 0.6491063691181304\n",
      "60 Train Loss 0.74521434 Test MSE 1.8495172529550497 Test RE 0.6500357673012408\n",
      "61 Train Loss 0.71310025 Test MSE 1.8502903158414057 Test RE 0.6501716043759929\n",
      "62 Train Loss 0.70524293 Test MSE 1.8463597146431552 Test RE 0.649480652281655\n",
      "63 Train Loss 0.69608784 Test MSE 1.870357584051378 Test RE 0.653687804707122\n",
      "64 Train Loss 0.68520135 Test MSE 1.8620280768450201 Test RE 0.6522306039609976\n",
      "65 Train Loss 0.67180943 Test MSE 1.877500723379999 Test RE 0.6549348746133454\n",
      "66 Train Loss 0.65834004 Test MSE 1.860830954665714 Test RE 0.6520209064626951\n",
      "67 Train Loss 0.64056957 Test MSE 1.895611795892681 Test RE 0.6580861663040793\n",
      "68 Train Loss 0.62195164 Test MSE 1.8771861599740836 Test RE 0.6548800072111001\n",
      "69 Train Loss 0.6000605 Test MSE 1.9233843876209626 Test RE 0.6628894443931079\n",
      "70 Train Loss 0.59502643 Test MSE 1.909303726044527 Test RE 0.6604585554639282\n",
      "71 Train Loss 0.57864606 Test MSE 1.9183247484242996 Test RE 0.6620169744691328\n",
      "72 Train Loss 0.5741307 Test MSE 1.9342326632876115 Test RE 0.6647562308778951\n",
      "73 Train Loss 0.5649712 Test MSE 1.9378697687502406 Test RE 0.6653809367464046\n",
      "74 Train Loss 0.5562464 Test MSE 1.9453737043275967 Test RE 0.6666679560226563\n",
      "75 Train Loss 0.5377979 Test MSE 1.9624050670639641 Test RE 0.6695798697761957\n",
      "76 Train Loss 0.5306457 Test MSE 1.9631716943451987 Test RE 0.669710645037813\n",
      "77 Train Loss 0.5203501 Test MSE 1.9456650160373168 Test RE 0.6667178695461422\n",
      "78 Train Loss 0.5036009 Test MSE 1.9691156195648285 Test RE 0.6707237254125209\n",
      "79 Train Loss 0.50163954 Test MSE 1.9827544319931791 Test RE 0.6730425555599236\n",
      "80 Train Loss 0.49265322 Test MSE 1.9753791395690177 Test RE 0.6717896242202868\n",
      "81 Train Loss 0.48164773 Test MSE 1.9698947114753858 Test RE 0.6708564001386019\n",
      "82 Train Loss 0.4775486 Test MSE 1.9713822073662233 Test RE 0.671109639010301\n",
      "83 Train Loss 0.47276127 Test MSE 1.9893472669583636 Test RE 0.6741605901414259\n",
      "84 Train Loss 0.46348542 Test MSE 2.0094603591605122 Test RE 0.6775600351839207\n",
      "85 Train Loss 0.46020967 Test MSE 2.005084815095348 Test RE 0.6768219491049182\n",
      "86 Train Loss 0.45747384 Test MSE 1.9997235255353836 Test RE 0.6759164843394295\n",
      "87 Train Loss 0.45201743 Test MSE 1.9948046154120271 Test RE 0.6750846644708097\n",
      "88 Train Loss 0.4480438 Test MSE 2.001982580351948 Test RE 0.676298162450391\n",
      "89 Train Loss 0.44284123 Test MSE 2.0142827846575395 Test RE 0.67837257292502\n",
      "90 Train Loss 0.43811965 Test MSE 2.0251156033543096 Test RE 0.6801942717726975\n",
      "91 Train Loss 0.43223706 Test MSE 2.0056812266321042 Test RE 0.6769226018061789\n",
      "92 Train Loss 0.42629167 Test MSE 1.9992949257516537 Test RE 0.6758440460299179\n",
      "93 Train Loss 0.4180861 Test MSE 1.993846123264904 Test RE 0.674922457833936\n",
      "94 Train Loss 0.41427633 Test MSE 2.013033991094742 Test RE 0.6781622552251528\n",
      "95 Train Loss 0.4107387 Test MSE 2.017128636553844 Test RE 0.6788516184895227\n",
      "96 Train Loss 0.40875682 Test MSE 2.0259742743947475 Test RE 0.6803384613742489\n",
      "97 Train Loss 0.40405804 Test MSE 2.050743598817394 Test RE 0.6844846962395724\n",
      "98 Train Loss 0.39345226 Test MSE 2.064454168329295 Test RE 0.6867689997352812\n",
      "99 Train Loss 0.38884327 Test MSE 2.099052621851772 Test RE 0.6924999133199252\n",
      "Training time: 75.89\n",
      "KG_stan_tune20\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.04028 Test MSE 8.506085375034798 Test RE 1.394032596613017\n",
      "1 Train Loss 56.37198 Test MSE 8.252223237223234 Test RE 1.3730727373586755\n",
      "2 Train Loss 52.88452 Test MSE 9.010587368431542 Test RE 1.434777677699093\n",
      "3 Train Loss 44.95407 Test MSE 8.21139834735824 Test RE 1.369672135949892\n",
      "4 Train Loss 43.93332 Test MSE 8.29085055528723 Test RE 1.3762825509421641\n",
      "5 Train Loss 43.52941 Test MSE 8.396823049880371 Test RE 1.3850503484465013\n",
      "6 Train Loss 42.229233 Test MSE 8.511513782156449 Test RE 1.3944773470000122\n",
      "7 Train Loss 41.328873 Test MSE 8.354231580756288 Test RE 1.38153316551811\n",
      "8 Train Loss 40.754467 Test MSE 8.344072543584483 Test RE 1.3806929137235675\n",
      "9 Train Loss 39.46248 Test MSE 8.388890821003582 Test RE 1.3843959859456936\n",
      "10 Train Loss 38.67943 Test MSE 8.259335920054548 Test RE 1.373664343226887\n",
      "11 Train Loss 37.443726 Test MSE 8.424708145400341 Test RE 1.3873482561732848\n",
      "12 Train Loss 35.66366 Test MSE 7.72839190521843 Test RE 1.328778610940721\n",
      "13 Train Loss 35.205334 Test MSE 7.400552018021687 Test RE 1.300289687127372\n",
      "14 Train Loss 34.338223 Test MSE 7.526613434171764 Test RE 1.3113175267764363\n",
      "15 Train Loss 31.910938 Test MSE 6.861942816304576 Test RE 1.252078642462648\n",
      "16 Train Loss 28.77274 Test MSE 5.525861913200517 Test RE 1.1235905407110762\n",
      "17 Train Loss 24.778532 Test MSE 3.9677157076849436 Test RE 0.9520907234113167\n",
      "18 Train Loss 18.113373 Test MSE 1.8197938484275715 Test RE 0.6447912815537209\n",
      "19 Train Loss 12.549267 Test MSE 2.0529096447878987 Test RE 0.6848460856471212\n",
      "20 Train Loss 10.63952 Test MSE 1.511647605216681 Test RE 0.5876697557732431\n",
      "21 Train Loss 9.731102 Test MSE 0.7648642081200099 Test RE 0.41802304990995476\n",
      "22 Train Loss 5.277783 Test MSE 0.4768395878328306 Test RE 0.3300610008359893\n",
      "23 Train Loss 3.0741978 Test MSE 0.41061246897077813 Test RE 0.3062838707346703\n",
      "24 Train Loss 1.4488269 Test MSE 0.21777280766412704 Test RE 0.22305393305784083\n",
      "25 Train Loss 1.0722991 Test MSE 0.1659633434430977 Test RE 0.19472160831357332\n",
      "26 Train Loss 0.696218 Test MSE 0.06558045813749427 Test RE 0.12240390789554617\n",
      "27 Train Loss 0.543449 Test MSE 0.0590839818873032 Test RE 0.11618309419374931\n",
      "28 Train Loss 0.40592888 Test MSE 0.049878389347061035 Test RE 0.10674911194143366\n",
      "29 Train Loss 0.361142 Test MSE 0.046309652665012586 Test RE 0.102859361028959\n",
      "30 Train Loss 0.2954211 Test MSE 0.036228129421444016 Test RE 0.09097687511591958\n",
      "31 Train Loss 0.21282044 Test MSE 0.023261453060994166 Test RE 0.07289982408531225\n",
      "32 Train Loss 0.18852478 Test MSE 0.023002054177411666 Test RE 0.07249221524456345\n",
      "33 Train Loss 0.1707371 Test MSE 0.021703924229516627 Test RE 0.07041694711718513\n",
      "34 Train Loss 0.14240032 Test MSE 0.020343952768456266 Test RE 0.06817509153601643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 0.13460961 Test MSE 0.020238627366106647 Test RE 0.06799838332606906\n",
      "36 Train Loss 0.12165151 Test MSE 0.016711976313886556 Test RE 0.06179053649740414\n",
      "37 Train Loss 0.11450809 Test MSE 0.016714800711669756 Test RE 0.0617957577135531\n",
      "38 Train Loss 0.105173595 Test MSE 0.016538369607390715 Test RE 0.06146875360094434\n",
      "39 Train Loss 0.093999684 Test MSE 0.012924603001386925 Test RE 0.05433962866020176\n",
      "40 Train Loss 0.088287726 Test MSE 0.012216403648390486 Test RE 0.052829894972251386\n",
      "41 Train Loss 0.07975319 Test MSE 0.010427522033556255 Test RE 0.04880885484850976\n",
      "42 Train Loss 0.07028304 Test MSE 0.006780575355933468 Test RE 0.03935875331250982\n",
      "43 Train Loss 0.065923154 Test MSE 0.006159562483157437 Test RE 0.03751310328730687\n",
      "44 Train Loss 0.05567441 Test MSE 0.005973160443462259 Test RE 0.03694112782524734\n",
      "45 Train Loss 0.05235871 Test MSE 0.005898140479228001 Test RE 0.036708413602796454\n",
      "46 Train Loss 0.0506541 Test MSE 0.005669996983299591 Test RE 0.03599146082462532\n",
      "47 Train Loss 0.04659228 Test MSE 0.005062928604883648 Test RE 0.03401018246104657\n",
      "48 Train Loss 0.043351345 Test MSE 0.004527032709564342 Test RE 0.03215991383639884\n",
      "49 Train Loss 0.041741077 Test MSE 0.004214029143132893 Test RE 0.03102821754123013\n",
      "50 Train Loss 0.040555574 Test MSE 0.004134991095133244 Test RE 0.030735858602435984\n",
      "51 Train Loss 0.036870748 Test MSE 0.0033483318495394904 Test RE 0.02765809775300432\n",
      "52 Train Loss 0.035910882 Test MSE 0.0033319279464707526 Test RE 0.027590264302678524\n",
      "53 Train Loss 0.033719555 Test MSE 0.003214183363458756 Test RE 0.02709838350220505\n",
      "54 Train Loss 0.032443263 Test MSE 0.00313656260445395 Test RE 0.026769178301809925\n",
      "55 Train Loss 0.03190655 Test MSE 0.003204738375883674 Test RE 0.02705853944723736\n",
      "56 Train Loss 0.028058175 Test MSE 0.002775095142904252 Test RE 0.025179494030909234\n",
      "57 Train Loss 0.022752598 Test MSE 0.0028444309598913376 Test RE 0.025492108530955883\n",
      "58 Train Loss 0.021012805 Test MSE 0.002674905483968241 Test RE 0.024720786328057517\n",
      "59 Train Loss 0.020248264 Test MSE 0.002900612783307955 Test RE 0.02574263142193057\n",
      "60 Train Loss 0.019123405 Test MSE 0.002685804228986229 Test RE 0.02477109682808945\n",
      "61 Train Loss 0.01774328 Test MSE 0.0026277567156949176 Test RE 0.024501949341811817\n",
      "62 Train Loss 0.015952602 Test MSE 0.0023041842125274287 Test RE 0.022943869224979815\n",
      "63 Train Loss 0.0150282 Test MSE 0.0021694448916777997 Test RE 0.022262932604910378\n",
      "64 Train Loss 0.014868889 Test MSE 0.002159139145768703 Test RE 0.022209990662168045\n",
      "65 Train Loss 0.0146948155 Test MSE 0.0021967005640251094 Test RE 0.022402345510204084\n",
      "66 Train Loss 0.013053786 Test MSE 0.0018848333080118435 Test RE 0.020751262978757012\n",
      "67 Train Loss 0.012350132 Test MSE 0.001676786166002044 Test RE 0.019572527025605746\n",
      "68 Train Loss 0.011966613 Test MSE 0.0015582856594885215 Test RE 0.01886824892936643\n",
      "69 Train Loss 0.011553618 Test MSE 0.0015008723694978187 Test RE 0.018517397165433783\n",
      "70 Train Loss 0.011325985 Test MSE 0.00148787739205662 Test RE 0.01843705845775743\n",
      "71 Train Loss 0.011179873 Test MSE 0.001525924273951133 Test RE 0.018671299747514015\n",
      "72 Train Loss 0.010718492 Test MSE 0.0015842958378357596 Test RE 0.019025067263794236\n",
      "73 Train Loss 0.0102004 Test MSE 0.0014168467775864087 Test RE 0.017991588260553568\n",
      "74 Train Loss 0.008835111 Test MSE 0.0012124491481661191 Test RE 0.01664331475870691\n",
      "75 Train Loss 0.00847595 Test MSE 0.00122637470552782 Test RE 0.01673862009143749\n",
      "76 Train Loss 0.008227429 Test MSE 0.0011602809761351075 Test RE 0.016281321271333433\n",
      "77 Train Loss 0.008123552 Test MSE 0.001125461978250623 Test RE 0.016035166514091446\n",
      "78 Train Loss 0.008059651 Test MSE 0.0010664507771103893 Test RE 0.015609121739400112\n",
      "79 Train Loss 0.007861939 Test MSE 0.000965377335190073 Test RE 0.014851031165354581\n",
      "80 Train Loss 0.0074656843 Test MSE 0.0008456978817248255 Test RE 0.01390002821066465\n",
      "81 Train Loss 0.006860465 Test MSE 0.0007646041058892282 Test RE 0.013216801673873802\n",
      "82 Train Loss 0.006290528 Test MSE 0.0007124146750332736 Test RE 0.012757761786921373\n",
      "83 Train Loss 0.006114197 Test MSE 0.0006644829533848544 Test RE 0.012321114182780871\n",
      "84 Train Loss 0.0059706005 Test MSE 0.0006718920378219585 Test RE 0.012389614897918951\n",
      "85 Train Loss 0.0058598006 Test MSE 0.0006265429932163422 Test RE 0.011964195446851119\n",
      "86 Train Loss 0.0056583546 Test MSE 0.000616398850766576 Test RE 0.011866946117904165\n",
      "87 Train Loss 0.0055405837 Test MSE 0.0006270066021048168 Test RE 0.011968621066261197\n",
      "88 Train Loss 0.005501932 Test MSE 0.0006156750162087795 Test RE 0.01185997641891753\n",
      "89 Train Loss 0.0054586614 Test MSE 0.0006335573912587697 Test RE 0.012030981008020846\n",
      "90 Train Loss 0.005341723 Test MSE 0.0006130254164202558 Test RE 0.011834428790565496\n",
      "91 Train Loss 0.005261563 Test MSE 0.0005675192069496988 Test RE 0.01138671215908561\n",
      "92 Train Loss 0.005160127 Test MSE 0.0005782933585389025 Test RE 0.0114942903294802\n",
      "93 Train Loss 0.0050853123 Test MSE 0.0005724353923224454 Test RE 0.01143592501229903\n",
      "94 Train Loss 0.0048944554 Test MSE 0.0005100767494815488 Test RE 0.010795078981766786\n",
      "95 Train Loss 0.0047870283 Test MSE 0.00048271355134768003 Test RE 0.010501535523777321\n",
      "96 Train Loss 0.0046421597 Test MSE 0.00042021558472052513 Test RE 0.0097981512207487\n",
      "97 Train Loss 0.0045876545 Test MSE 0.00041815085694344394 Test RE 0.009774049988420883\n",
      "98 Train Loss 0.004556746 Test MSE 0.0004158561888691985 Test RE 0.009747194782493335\n",
      "99 Train Loss 0.004502173 Test MSE 0.00040452943524825404 Test RE 0.009613535278662147\n",
      "Training time: 75.37\n",
      "KG_stan_tune20\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.85772 Test MSE 8.71002894941619 Test RE 1.4106454081606048\n",
      "1 Train Loss 57.02768 Test MSE 9.006315273834442 Test RE 1.434437509382865\n",
      "2 Train Loss 48.981102 Test MSE 8.9616394697453 Test RE 1.4308753245238404\n",
      "3 Train Loss 47.058334 Test MSE 8.890960360492652 Test RE 1.4252216051813127\n",
      "4 Train Loss 46.18699 Test MSE 8.644083615368086 Test RE 1.4052951256601791\n",
      "5 Train Loss 45.41942 Test MSE 8.869414071801785 Test RE 1.4234936218131422\n",
      "6 Train Loss 45.0962 Test MSE 8.641161230730235 Test RE 1.4050575550722895\n",
      "7 Train Loss 44.632175 Test MSE 8.561329536697077 Test RE 1.398552156500648\n",
      "8 Train Loss 44.407055 Test MSE 8.355519050017607 Test RE 1.3816396153420172\n",
      "9 Train Loss 44.308205 Test MSE 8.409238297427136 Test RE 1.3860739136257352\n",
      "10 Train Loss 44.149937 Test MSE 8.464729900548928 Test RE 1.3906396655197324\n",
      "11 Train Loss 43.92444 Test MSE 8.488955623416286 Test RE 1.3926282216606394\n",
      "12 Train Loss 43.607826 Test MSE 8.557512080890525 Test RE 1.3982403178832261\n",
      "13 Train Loss 43.291344 Test MSE 8.757709630905579 Test RE 1.4145012355070834\n",
      "14 Train Loss 42.639973 Test MSE 8.602412986563042 Test RE 1.4019037727175074\n",
      "15 Train Loss 41.85689 Test MSE 8.622903402542992 Test RE 1.403572403728823\n",
      "16 Train Loss 39.140976 Test MSE 9.204245464149762 Test RE 1.4501140365260248\n",
      "17 Train Loss 35.076355 Test MSE 10.038821227184977 Test RE 1.5144307541614472\n",
      "18 Train Loss 33.478535 Test MSE 9.262711326975742 Test RE 1.4547123471296255\n",
      "19 Train Loss 32.326015 Test MSE 9.154684416235277 Test RE 1.4462046351903897\n",
      "20 Train Loss 31.242897 Test MSE 9.251882183413024 Test RE 1.4538617378789944\n",
      "21 Train Loss 30.607723 Test MSE 9.322133964584976 Test RE 1.4593710613184396\n",
      "22 Train Loss 29.887358 Test MSE 9.134421878812677 Test RE 1.444603268771357\n",
      "23 Train Loss 29.31911 Test MSE 9.192022007331596 Test RE 1.4491508236680495\n",
      "24 Train Loss 28.875957 Test MSE 9.11608211977841 Test RE 1.4431523292468476\n",
      "25 Train Loss 28.571228 Test MSE 9.24265992615103 Test RE 1.4531369540129062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 28.178295 Test MSE 9.142370408298166 Test RE 1.445231659652591\n",
      "27 Train Loss 27.63861 Test MSE 9.036034959284052 Test RE 1.436802290037002\n",
      "28 Train Loss 27.365643 Test MSE 9.228821586966356 Test RE 1.452048710218584\n",
      "29 Train Loss 26.959602 Test MSE 9.179939308910287 Test RE 1.4481980730029829\n",
      "30 Train Loss 26.722132 Test MSE 9.202485850144237 Test RE 1.449975417725503\n",
      "31 Train Loss 26.25491 Test MSE 9.30923598607733 Test RE 1.4583611288312395\n",
      "32 Train Loss 26.041386 Test MSE 9.391580845482142 Test RE 1.4647968959291129\n",
      "33 Train Loss 25.808617 Test MSE 9.404037330424902 Test RE 1.465767987728642\n",
      "34 Train Loss 25.626286 Test MSE 9.480381257638916 Test RE 1.4717056656622667\n",
      "35 Train Loss 25.487873 Test MSE 9.487550073770484 Test RE 1.4722619931612513\n",
      "36 Train Loss 25.078352 Test MSE 9.322821446608101 Test RE 1.4594248726494452\n",
      "37 Train Loss 24.586454 Test MSE 9.228509116193676 Test RE 1.4520241281731516\n",
      "38 Train Loss 24.226112 Test MSE 9.519693809478968 Test RE 1.4747538896186108\n",
      "39 Train Loss 23.649939 Test MSE 9.364872238363084 Test RE 1.4627125535694305\n",
      "40 Train Loss 23.211716 Test MSE 9.490405021639681 Test RE 1.4724834894933463\n",
      "41 Train Loss 22.690567 Test MSE 9.54849135880852 Test RE 1.476982807338296\n",
      "42 Train Loss 22.023226 Test MSE 9.7165136176822 Test RE 1.4899211738138298\n",
      "43 Train Loss 19.539696 Test MSE 8.289875488288558 Test RE 1.3762016179217191\n",
      "44 Train Loss 17.982533 Test MSE 8.025855451619446 Test RE 1.3541093196161063\n",
      "45 Train Loss 17.17689 Test MSE 7.589364689224627 Test RE 1.3167725711412155\n",
      "46 Train Loss 16.714014 Test MSE 7.59947555457667 Test RE 1.3176494086232458\n",
      "47 Train Loss 16.200294 Test MSE 7.246459137881713 Test RE 1.28668128489328\n",
      "48 Train Loss 15.851164 Test MSE 6.811114350669233 Test RE 1.247432762360041\n",
      "49 Train Loss 15.442956 Test MSE 6.145330136081116 Test RE 1.1848971903494074\n",
      "50 Train Loss 15.018585 Test MSE 6.060797398428112 Test RE 1.1767194814184916\n",
      "51 Train Loss 14.752058 Test MSE 6.171601216247166 Test RE 1.187427187188826\n",
      "52 Train Loss 14.384839 Test MSE 6.1928609281606075 Test RE 1.1894706323322137\n",
      "53 Train Loss 14.1451435 Test MSE 6.269524276250705 Test RE 1.196810400007436\n",
      "54 Train Loss 14.052416 Test MSE 6.270041949854075 Test RE 1.1968598092079092\n",
      "55 Train Loss 13.980627 Test MSE 6.233634160816773 Test RE 1.1933798915237928\n",
      "56 Train Loss 13.802471 Test MSE 6.110650713063168 Test RE 1.181549145064616\n",
      "57 Train Loss 13.61201 Test MSE 6.060732968427998 Test RE 1.1767132267763356\n",
      "58 Train Loss 13.502977 Test MSE 6.093732267455797 Test RE 1.1799123447025432\n",
      "59 Train Loss 13.405188 Test MSE 6.121724754231198 Test RE 1.182619293052069\n",
      "60 Train Loss 13.3299885 Test MSE 6.134626580641895 Test RE 1.1838648503654152\n",
      "61 Train Loss 13.284674 Test MSE 6.018495260641178 Test RE 1.172605756077943\n",
      "62 Train Loss 13.061462 Test MSE 5.415269912166735 Test RE 1.1122902087924647\n",
      "63 Train Loss 10.736746 Test MSE 4.222610203001415 Test RE 0.9821968945042024\n",
      "64 Train Loss 9.359271 Test MSE 3.8750323793307273 Test RE 0.9409048955143539\n",
      "65 Train Loss 9.1560135 Test MSE 4.010123044972252 Test RE 0.9571652201033998\n",
      "66 Train Loss 8.928132 Test MSE 4.065585981583571 Test RE 0.963761637863834\n",
      "67 Train Loss 8.732037 Test MSE 4.061287209453539 Test RE 0.9632519834841998\n",
      "68 Train Loss 8.473818 Test MSE 3.7326158483822987 Test RE 0.923452812069698\n",
      "69 Train Loss 8.192551 Test MSE 3.7229392111854573 Test RE 0.9222550305133241\n",
      "70 Train Loss 8.038097 Test MSE 3.621621928993728 Test RE 0.9096191939458326\n",
      "71 Train Loss 7.9378004 Test MSE 3.616775149020566 Test RE 0.9090103230856992\n",
      "72 Train Loss 7.893679 Test MSE 3.6278156116139484 Test RE 0.9103966751401206\n",
      "73 Train Loss 7.826828 Test MSE 3.6408809892050185 Test RE 0.9120345734413576\n",
      "74 Train Loss 7.7587047 Test MSE 3.666530466590666 Test RE 0.9152415107573492\n",
      "75 Train Loss 7.7008123 Test MSE 3.577982756689027 Test RE 0.9041223015402623\n",
      "76 Train Loss 7.5998774 Test MSE 3.421338986437487 Test RE 0.884109614386492\n",
      "77 Train Loss 7.5462236 Test MSE 3.3864523051091675 Test RE 0.8795905239789342\n",
      "78 Train Loss 7.522723 Test MSE 3.3539796324139584 Test RE 0.8753631711822363\n",
      "79 Train Loss 7.486865 Test MSE 3.3435431995181424 Test RE 0.8740001952786536\n",
      "80 Train Loss 7.4563613 Test MSE 3.3754266352522215 Test RE 0.8781574635784689\n",
      "81 Train Loss 7.420327 Test MSE 3.4025717773034345 Test RE 0.8816814588778946\n",
      "82 Train Loss 7.3958974 Test MSE 3.3834171144186946 Test RE 0.8791962583583053\n",
      "83 Train Loss 7.374501 Test MSE 3.355196684340686 Test RE 0.875521977424651\n",
      "84 Train Loss 7.3486595 Test MSE 3.3606550581374415 Test RE 0.8762338558344412\n",
      "85 Train Loss 7.3204174 Test MSE 3.340907075106984 Test RE 0.8736555866677027\n",
      "86 Train Loss 7.2930956 Test MSE 3.3279763819914936 Test RE 0.8719632432082415\n",
      "87 Train Loss 7.2782087 Test MSE 3.3340387766153183 Test RE 0.8727570859931739\n",
      "88 Train Loss 7.254737 Test MSE 3.3376313874744157 Test RE 0.8732271813620364\n",
      "89 Train Loss 7.247534 Test MSE 3.338962347289327 Test RE 0.8734012740507023\n",
      "90 Train Loss 7.229454 Test MSE 3.321787348459667 Test RE 0.8711520714203672\n",
      "91 Train Loss 7.190344 Test MSE 3.31539801985009 Test RE 0.8703138546142821\n",
      "92 Train Loss 7.173443 Test MSE 3.32488570931502 Test RE 0.8715582555146945\n",
      "93 Train Loss 7.1488233 Test MSE 3.3335730194317117 Test RE 0.8726961228330112\n",
      "94 Train Loss 7.1302347 Test MSE 3.3364698211620896 Test RE 0.8730752173754665\n",
      "95 Train Loss 7.1151547 Test MSE 3.348649475760507 Test RE 0.8746673294430588\n",
      "96 Train Loss 7.09936 Test MSE 3.365256201770594 Test RE 0.8768334857782029\n",
      "97 Train Loss 7.087229 Test MSE 3.3518217148020173 Test RE 0.8750815258319924\n",
      "98 Train Loss 7.0771513 Test MSE 3.3304575167093953 Test RE 0.872288223758286\n",
      "99 Train Loss 7.0612307 Test MSE 3.326064543478232 Test RE 0.8717127467791959\n",
      "Training time: 75.79\n",
      "KG_stan_tune20\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.924915 Test MSE 8.589122600993415 Test RE 1.4008204113613474\n",
      "1 Train Loss 58.58542 Test MSE 8.532872924176552 Test RE 1.3962259300396576\n",
      "2 Train Loss 56.195477 Test MSE 8.40835041810445 Test RE 1.3860007382196868\n",
      "3 Train Loss 54.340286 Test MSE 8.99965765594802 Test RE 1.4339072313474193\n",
      "4 Train Loss 46.384766 Test MSE 8.588165545854187 Test RE 1.4007423649889472\n",
      "5 Train Loss 45.973045 Test MSE 8.502541682355222 Test RE 1.393742184660348\n",
      "6 Train Loss 45.66949 Test MSE 8.458359128566396 Test RE 1.3901162515471448\n",
      "7 Train Loss 45.34195 Test MSE 8.503373617272223 Test RE 1.3938103686499363\n",
      "8 Train Loss 44.34047 Test MSE 8.249201938906833 Test RE 1.372821360123233\n",
      "9 Train Loss 43.552017 Test MSE 8.36135826273292 Test RE 1.3821223069939728\n",
      "10 Train Loss 40.00706 Test MSE 7.8589684003675835 Test RE 1.339956906602107\n",
      "11 Train Loss 39.559677 Test MSE 7.81548493890108 Test RE 1.3362447919014682\n",
      "12 Train Loss 39.14006 Test MSE 7.81995369458561 Test RE 1.336626757846136\n",
      "13 Train Loss 38.502487 Test MSE 7.626731385626135 Test RE 1.3200101956009884\n",
      "14 Train Loss 37.55519 Test MSE 7.4090069759914705 Test RE 1.301032250408589\n",
      "15 Train Loss 36.099327 Test MSE 7.422886726413456 Test RE 1.3022503322382155\n",
      "16 Train Loss 33.675453 Test MSE 7.1216699723809125 Test RE 1.2755543915010337\n",
      "17 Train Loss 31.288565 Test MSE 7.358471464090752 Test RE 1.2965876042243347\n",
      "18 Train Loss 30.474543 Test MSE 7.091861878949843 Test RE 1.272882145126737\n",
      "19 Train Loss 30.001083 Test MSE 6.935489022232205 Test RE 1.2587706396497573\n",
      "20 Train Loss 29.68539 Test MSE 6.978370839183163 Test RE 1.2626561041402267\n",
      "21 Train Loss 29.386736 Test MSE 7.009044970129333 Test RE 1.2654281272590107\n",
      "22 Train Loss 28.933018 Test MSE 6.982069610848321 Test RE 1.2629906849500894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Train Loss 28.506105 Test MSE 6.8746835159317445 Test RE 1.2532404825147194\n",
      "24 Train Loss 28.193052 Test MSE 6.855252217665913 Test RE 1.251468086613142\n",
      "25 Train Loss 27.808657 Test MSE 6.750855389129792 Test RE 1.2419023897653616\n",
      "26 Train Loss 27.10762 Test MSE 6.630062811123008 Test RE 1.2307416038194687\n",
      "27 Train Loss 26.103546 Test MSE 6.739509773278341 Test RE 1.240858368552564\n",
      "28 Train Loss 25.488832 Test MSE 6.789544860589572 Test RE 1.2454560062139572\n",
      "29 Train Loss 24.679989 Test MSE 7.00319925864731 Test RE 1.2649003184922378\n",
      "30 Train Loss 23.738342 Test MSE 6.879961025980286 Test RE 1.2537214297732997\n",
      "31 Train Loss 22.801762 Test MSE 6.812304688998604 Test RE 1.2475417608354893\n",
      "32 Train Loss 22.344833 Test MSE 6.775548159151912 Test RE 1.244171585115225\n",
      "33 Train Loss 21.73247 Test MSE 6.686236741916024 Test RE 1.2359444030254627\n",
      "34 Train Loss 21.489868 Test MSE 6.56016942526917 Test RE 1.2242372456933095\n",
      "35 Train Loss 21.152983 Test MSE 6.622241100399181 Test RE 1.2300154157025547\n",
      "36 Train Loss 20.779644 Test MSE 7.023597438774888 Test RE 1.2667411131639534\n",
      "37 Train Loss 20.196386 Test MSE 7.1819745361672265 Test RE 1.2809435487225302\n",
      "38 Train Loss 19.953606 Test MSE 7.438936576156455 Test RE 1.303657442239714\n",
      "39 Train Loss 19.734377 Test MSE 7.315208199095433 Test RE 1.2927704183404387\n",
      "40 Train Loss 19.462631 Test MSE 7.519858825525854 Test RE 1.3107289868636371\n",
      "41 Train Loss 19.24571 Test MSE 7.557187533329479 Test RE 1.3139782001202875\n",
      "42 Train Loss 19.057777 Test MSE 7.625718089167701 Test RE 1.3199225036383953\n",
      "43 Train Loss 18.777721 Test MSE 7.78507742337888 Test RE 1.3336428111537693\n",
      "44 Train Loss 18.605381 Test MSE 7.904976541382844 Test RE 1.3438733851844211\n",
      "45 Train Loss 18.267088 Test MSE 7.951781517342255 Test RE 1.3478460174174318\n",
      "46 Train Loss 18.062881 Test MSE 8.199561032518991 Test RE 1.3686845399909613\n",
      "47 Train Loss 17.62981 Test MSE 8.40281468240039 Test RE 1.3855444182144383\n",
      "48 Train Loss 17.311905 Test MSE 8.357659189040612 Test RE 1.3818165469917316\n",
      "49 Train Loss 17.10639 Test MSE 8.292306794626986 Test RE 1.376403413619721\n",
      "50 Train Loss 16.884523 Test MSE 8.390905674228536 Test RE 1.384562228856045\n",
      "51 Train Loss 16.702421 Test MSE 8.319934852332317 Test RE 1.3786944366087401\n",
      "52 Train Loss 16.582253 Test MSE 8.437353375586728 Test RE 1.3883890494967563\n",
      "53 Train Loss 16.432384 Test MSE 8.381189182285315 Test RE 1.3837603497074409\n",
      "54 Train Loss 16.255146 Test MSE 8.405654952171156 Test RE 1.3857785651987302\n",
      "55 Train Loss 16.130852 Test MSE 8.563945368514279 Test RE 1.3987657972564733\n",
      "56 Train Loss 15.975442 Test MSE 8.604698075109898 Test RE 1.4020899566144336\n",
      "57 Train Loss 15.685987 Test MSE 8.634916250309741 Test RE 1.40454974468626\n",
      "58 Train Loss 15.406023 Test MSE 8.670971772138897 Test RE 1.4074790736041052\n",
      "59 Train Loss 15.1459465 Test MSE 8.604836825361717 Test RE 1.4021012608780243\n",
      "60 Train Loss 14.561007 Test MSE 8.352597470175708 Test RE 1.3813980430745152\n",
      "61 Train Loss 14.235714 Test MSE 8.206320356689643 Test RE 1.369248562665048\n",
      "62 Train Loss 14.018327 Test MSE 8.181893233270912 Test RE 1.3672091754048852\n",
      "63 Train Loss 13.697779 Test MSE 8.139048049708462 Test RE 1.363624722792732\n",
      "64 Train Loss 13.510987 Test MSE 7.981738730246998 Test RE 1.3503825403435556\n",
      "65 Train Loss 13.247314 Test MSE 8.091666128895454 Test RE 1.3596497205986693\n",
      "66 Train Loss 12.938093 Test MSE 8.211964766841886 Test RE 1.3697193748958598\n",
      "67 Train Loss 12.792931 Test MSE 8.15602052483936 Test RE 1.3650457755646985\n",
      "68 Train Loss 12.357052 Test MSE 8.028780243774762 Test RE 1.354356030236771\n",
      "69 Train Loss 12.166126 Test MSE 7.946167025236681 Test RE 1.34737009846359\n",
      "70 Train Loss 11.958221 Test MSE 7.904043143651363 Test RE 1.3437940424189603\n",
      "71 Train Loss 11.744628 Test MSE 7.9400520078260275 Test RE 1.3468515605745814\n",
      "72 Train Loss 11.603388 Test MSE 7.817381506391491 Test RE 1.3364069139401509\n",
      "73 Train Loss 11.398935 Test MSE 7.795146717759375 Test RE 1.3345050057018275\n",
      "74 Train Loss 11.14534 Test MSE 7.7999030816328805 Test RE 1.3349120810062711\n",
      "75 Train Loss 10.975819 Test MSE 7.777794738894955 Test RE 1.3330188756568033\n",
      "76 Train Loss 10.592908 Test MSE 7.748349265715559 Test RE 1.3304931859726066\n",
      "77 Train Loss 10.363998 Test MSE 7.761221222988765 Test RE 1.3315978693114063\n",
      "78 Train Loss 10.172919 Test MSE 7.598684563420307 Test RE 1.3175808330916878\n",
      "79 Train Loss 9.974791 Test MSE 7.5817827957240285 Test RE 1.3161146686352478\n",
      "80 Train Loss 9.665163 Test MSE 7.631028043312696 Test RE 1.3203819691096674\n",
      "81 Train Loss 9.44072 Test MSE 7.673789310111024 Test RE 1.3240762505094508\n",
      "82 Train Loss 9.262709 Test MSE 7.499677988676422 Test RE 1.3089690217388203\n",
      "83 Train Loss 9.077522 Test MSE 7.507093659385762 Test RE 1.3096160151761502\n",
      "84 Train Loss 8.949608 Test MSE 7.687011816871233 Test RE 1.3252165002108067\n",
      "85 Train Loss 8.78175 Test MSE 7.519802085923156 Test RE 1.3107240419315598\n",
      "86 Train Loss 8.610216 Test MSE 7.515532839245958 Test RE 1.3103519178613854\n",
      "87 Train Loss 8.519291 Test MSE 7.48776346164808 Test RE 1.3079288473561157\n",
      "88 Train Loss 8.31403 Test MSE 7.340803855231802 Test RE 1.295030122516898\n",
      "89 Train Loss 8.193468 Test MSE 7.261930769071034 Test RE 1.2880541239276586\n",
      "90 Train Loss 8.099015 Test MSE 7.2449126019595305 Test RE 1.286543976107584\n",
      "91 Train Loss 7.912759 Test MSE 7.280660866763903 Test RE 1.289714139990972\n",
      "92 Train Loss 7.813861 Test MSE 7.374857073081365 Test RE 1.2980304013885633\n",
      "93 Train Loss 7.691227 Test MSE 7.412504665414145 Test RE 1.3013393138121399\n",
      "94 Train Loss 7.5384865 Test MSE 7.468176966902391 Test RE 1.3062170868084404\n",
      "95 Train Loss 7.3138466 Test MSE 7.436880686182349 Test RE 1.3034772846699725\n",
      "96 Train Loss 7.015389 Test MSE 7.4400153967339655 Test RE 1.3037519692916184\n",
      "97 Train Loss 6.790628 Test MSE 7.248435612285755 Test RE 1.2868567443275811\n",
      "98 Train Loss 6.5683517 Test MSE 7.172695384486289 Test RE 1.280115788116946\n",
      "99 Train Loss 6.362535 Test MSE 7.221964078041224 Test RE 1.2845047726178909\n",
      "Training time: 75.07\n",
      "KG_stan_tune20\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.65279 Test MSE 8.541686472937197 Test RE 1.3969468202629118\n",
      "1 Train Loss 55.348442 Test MSE 8.449809768938458 Test RE 1.389413537923048\n",
      "2 Train Loss 51.129555 Test MSE 8.217386840403734 Test RE 1.3701714892146806\n",
      "3 Train Loss 44.79473 Test MSE 7.578822304234079 Test RE 1.3158576890559492\n",
      "4 Train Loss 42.699646 Test MSE 7.617026682968055 Test RE 1.319170098870941\n",
      "5 Train Loss 41.108334 Test MSE 7.324108721569539 Test RE 1.2935566457447412\n",
      "6 Train Loss 40.10052 Test MSE 7.678531717332428 Test RE 1.3244853273464425\n",
      "7 Train Loss 38.266045 Test MSE 7.39766632372827 Test RE 1.3000361516904657\n",
      "8 Train Loss 36.63331 Test MSE 7.483997075474044 Test RE 1.3075998582807784\n",
      "9 Train Loss 34.90157 Test MSE 7.00671835151891 Test RE 1.2652180834506326\n",
      "10 Train Loss 33.23378 Test MSE 7.15888314646725 Test RE 1.2788826544565333\n",
      "11 Train Loss 31.690716 Test MSE 6.804338058705043 Test RE 1.2468120803649472\n",
      "12 Train Loss 30.92612 Test MSE 6.942000897990173 Test RE 1.2593614440483951\n",
      "13 Train Loss 27.989021 Test MSE 6.305577177284011 Test RE 1.2002465963900804\n",
      "14 Train Loss 25.903404 Test MSE 6.265780981037449 Test RE 1.1964530616069848\n",
      "15 Train Loss 25.15353 Test MSE 6.138705277961926 Test RE 1.184258340009794\n",
      "16 Train Loss 24.567072 Test MSE 6.211790018118651 Test RE 1.1912871124552435\n",
      "17 Train Loss 24.285976 Test MSE 6.15858062354773 Test RE 1.1861739330829484\n",
      "18 Train Loss 23.848839 Test MSE 6.056754888815729 Test RE 1.1763269841139838\n",
      "19 Train Loss 23.483734 Test MSE 6.005657687270205 Test RE 1.1713544924598518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 22.655275 Test MSE 5.744606500369891 Test RE 1.1456137115164335\n",
      "21 Train Loss 22.158287 Test MSE 5.877409004824494 Test RE 1.158780070471841\n",
      "22 Train Loss 21.685768 Test MSE 5.930561743806898 Test RE 1.1640080295196322\n",
      "23 Train Loss 20.743952 Test MSE 5.986188338781789 Test RE 1.169454282445619\n",
      "24 Train Loss 20.28435 Test MSE 6.055915353813305 Test RE 1.1762454551500425\n",
      "25 Train Loss 19.518953 Test MSE 5.762544914412358 Test RE 1.147400994515912\n",
      "26 Train Loss 18.773293 Test MSE 5.681110727067161 Test RE 1.1392648212626908\n",
      "27 Train Loss 18.011116 Test MSE 5.664833547635382 Test RE 1.137631573762896\n",
      "28 Train Loss 17.529995 Test MSE 5.4841742661109345 Test RE 1.1193442780843585\n",
      "29 Train Loss 16.8573 Test MSE 5.2839657678058005 Test RE 1.09872260052422\n",
      "30 Train Loss 16.13869 Test MSE 5.201443424152904 Test RE 1.090109187218601\n",
      "31 Train Loss 15.655176 Test MSE 5.075140227873872 Test RE 1.0767926525716707\n",
      "32 Train Loss 14.946796 Test MSE 4.64614838292036 Test RE 1.0302784077198879\n",
      "33 Train Loss 14.22097 Test MSE 4.3881647058835265 Test RE 1.0012661181344817\n",
      "34 Train Loss 13.145298 Test MSE 4.19427656896107 Test RE 0.9788960868675359\n",
      "35 Train Loss 12.358606 Test MSE 4.072897365248994 Test RE 0.9646278433715179\n",
      "36 Train Loss 11.852663 Test MSE 3.973593170680574 Test RE 0.952795638735041\n",
      "37 Train Loss 11.519144 Test MSE 3.863940980535124 Test RE 0.9395573674496513\n",
      "38 Train Loss 11.26111 Test MSE 3.8349238939860926 Test RE 0.9360228161434572\n",
      "39 Train Loss 10.85914 Test MSE 3.8730287847426657 Test RE 0.9406616155207024\n",
      "40 Train Loss 10.571018 Test MSE 4.032584186391082 Test RE 0.9598420709811102\n",
      "41 Train Loss 10.128785 Test MSE 4.099969906882967 Test RE 0.9678284733255054\n",
      "42 Train Loss 9.7606735 Test MSE 4.117799795532095 Test RE 0.9699306294422738\n",
      "43 Train Loss 9.409992 Test MSE 4.0883769623317425 Test RE 0.9664592042051999\n",
      "44 Train Loss 9.180344 Test MSE 4.011266067623609 Test RE 0.9573016228478093\n",
      "45 Train Loss 8.758227 Test MSE 4.031714152987528 Test RE 0.9597385220316967\n",
      "46 Train Loss 8.519889 Test MSE 4.087643467926057 Test RE 0.96637250424767\n",
      "47 Train Loss 8.133003 Test MSE 3.9954732180492845 Test RE 0.9554152569837321\n",
      "48 Train Loss 7.8849974 Test MSE 3.919805805802892 Test RE 0.9463250496057237\n",
      "49 Train Loss 7.2809896 Test MSE 3.7539881980173777 Test RE 0.9260928085194222\n",
      "50 Train Loss 5.724214 Test MSE 3.6773896249834994 Test RE 0.9165958434982414\n",
      "51 Train Loss 4.9827366 Test MSE 3.426117379784309 Test RE 0.8847267922620489\n",
      "52 Train Loss 4.0276313 Test MSE 3.038518871821016 Test RE 0.833180370038086\n",
      "53 Train Loss 3.581134 Test MSE 2.6601103879882553 Test RE 0.7795749757116769\n",
      "54 Train Loss 2.9400642 Test MSE 2.3744893157728897 Test RE 0.7365346284363772\n",
      "55 Train Loss 2.5470095 Test MSE 1.8032774351359813 Test RE 0.6418585555299904\n",
      "56 Train Loss 2.2545378 Test MSE 1.514869156516826 Test RE 0.5882956293742846\n",
      "57 Train Loss 2.0810435 Test MSE 1.3762241438741014 Test RE 0.5607285208821521\n",
      "58 Train Loss 1.9390736 Test MSE 1.345543349333387 Test RE 0.5544430032107489\n",
      "59 Train Loss 1.6017176 Test MSE 0.8215860737726898 Test RE 0.4332460330648203\n",
      "60 Train Loss 1.5170572 Test MSE 0.7383150995070654 Test RE 0.4107040026951777\n",
      "61 Train Loss 1.3715223 Test MSE 0.5637413649408273 Test RE 0.35887897150377884\n",
      "62 Train Loss 1.1807225 Test MSE 0.3696156890042786 Test RE 0.2905917356733819\n",
      "63 Train Loss 0.93064636 Test MSE 0.279918168782805 Test RE 0.252885311371175\n",
      "64 Train Loss 0.76580995 Test MSE 0.20480647649058936 Test RE 0.21631164661401298\n",
      "65 Train Loss 0.6336233 Test MSE 0.1387248701069212 Test RE 0.17802673365633812\n",
      "66 Train Loss 0.5446 Test MSE 0.13471332656736326 Test RE 0.17543382828614149\n",
      "67 Train Loss 0.5008524 Test MSE 0.1319524252287473 Test RE 0.17362679501856584\n",
      "68 Train Loss 0.44562727 Test MSE 0.11948361668793812 Test RE 0.16521985635552447\n",
      "69 Train Loss 0.40191 Test MSE 0.11171508772299361 Test RE 0.1597585005531545\n",
      "70 Train Loss 0.36249945 Test MSE 0.10493618125136568 Test RE 0.15483555249104664\n",
      "71 Train Loss 0.31944984 Test MSE 0.10625194054973776 Test RE 0.15580324387361055\n",
      "72 Train Loss 0.29375374 Test MSE 0.1032859098504192 Test RE 0.1536132225663832\n",
      "73 Train Loss 0.27144295 Test MSE 0.09266334895566641 Test RE 0.1454996860721647\n",
      "74 Train Loss 0.2559362 Test MSE 0.08658810739419939 Test RE 0.14064917330174698\n",
      "75 Train Loss 0.23158348 Test MSE 0.06561218002220222 Test RE 0.12243350827751305\n",
      "76 Train Loss 0.21979818 Test MSE 0.05366604362986778 Test RE 0.11072810054068785\n",
      "77 Train Loss 0.20901956 Test MSE 0.054474479711502856 Test RE 0.11155899823037513\n",
      "78 Train Loss 0.19643904 Test MSE 0.05618904750956404 Test RE 0.11330103975786059\n",
      "79 Train Loss 0.17641537 Test MSE 0.05157747347455556 Test RE 0.10855206574039\n",
      "80 Train Loss 0.16811134 Test MSE 0.055559551719061726 Test RE 0.11266458641567259\n",
      "81 Train Loss 0.15206364 Test MSE 0.0472280912058156 Test RE 0.1038743351079677\n",
      "82 Train Loss 0.1445045 Test MSE 0.04603198295810098 Test RE 0.10255052833219822\n",
      "83 Train Loss 0.13375966 Test MSE 0.044057446371066476 Test RE 0.1003269757053972\n",
      "84 Train Loss 0.12562744 Test MSE 0.03694649608307737 Test RE 0.09187443660318113\n",
      "85 Train Loss 0.11036563 Test MSE 0.032396097630398156 Test RE 0.08603088882723259\n",
      "86 Train Loss 0.10039359 Test MSE 0.030981797142366773 Test RE 0.08413202908254072\n",
      "87 Train Loss 0.09466555 Test MSE 0.028819796662706232 Test RE 0.08114345890481746\n",
      "88 Train Loss 0.09078763 Test MSE 0.03067581617982955 Test RE 0.08371554783566945\n",
      "89 Train Loss 0.081311986 Test MSE 0.024982918568388395 Test RE 0.07554916113349092\n",
      "90 Train Loss 0.07785261 Test MSE 0.024941449276041364 Test RE 0.07548643284515884\n",
      "91 Train Loss 0.07446602 Test MSE 0.023811550627788444 Test RE 0.07375677164193752\n",
      "92 Train Loss 0.0711067 Test MSE 0.02327770327770754 Test RE 0.07292528318098546\n",
      "93 Train Loss 0.068033606 Test MSE 0.022900988674479848 Test RE 0.07233278323159693\n",
      "94 Train Loss 0.06420926 Test MSE 0.02456655062545082 Test RE 0.07491696086274831\n",
      "95 Train Loss 0.060581718 Test MSE 0.02248726532915586 Test RE 0.0716764326680071\n",
      "96 Train Loss 0.05721698 Test MSE 0.02080301485889432 Test RE 0.06893998743498775\n",
      "97 Train Loss 0.05180355 Test MSE 0.019888977207018488 Test RE 0.06740844135235861\n",
      "98 Train Loss 0.049720626 Test MSE 0.018955820828720278 Test RE 0.06580810086540483\n",
      "99 Train Loss 0.046660945 Test MSE 0.01611833929805044 Test RE 0.06068316266067591\n",
      "Training time: 74.22\n",
      "KG_stan_tune20\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.96349 Test MSE 8.536644087535349 Test RE 1.3965344319049462\n",
      "1 Train Loss 55.134495 Test MSE 8.365556333785563 Test RE 1.3824692314618943\n",
      "2 Train Loss 51.49691 Test MSE 6.561532155845293 Test RE 1.2243643932400847\n",
      "3 Train Loss 47.32751 Test MSE 7.512578160195055 Test RE 1.3100943147047912\n",
      "4 Train Loss 41.7777 Test MSE 7.460001781073786 Test RE 1.3055019530187135\n",
      "5 Train Loss 37.088783 Test MSE 7.630099465148189 Test RE 1.3203016316270035\n",
      "6 Train Loss 36.09534 Test MSE 8.109235260748612 Test RE 1.3611249985072007\n",
      "7 Train Loss 35.14563 Test MSE 7.935789550134395 Test RE 1.3464899969181632\n",
      "8 Train Loss 34.69362 Test MSE 7.8706259685001125 Test RE 1.340950348090081\n",
      "9 Train Loss 33.896183 Test MSE 7.378950513622686 Test RE 1.2983905896006205\n",
      "10 Train Loss 32.224518 Test MSE 7.002470310205201 Test RE 1.264834486357718\n",
      "11 Train Loss 30.851759 Test MSE 6.520988902177179 Test RE 1.2205759004833887\n",
      "12 Train Loss 29.628414 Test MSE 6.8003050879653895 Test RE 1.2464425292124683\n",
      "13 Train Loss 28.196312 Test MSE 6.426051935107576 Test RE 1.211658339749803\n",
      "14 Train Loss 26.597141 Test MSE 6.339339433470612 Test RE 1.203455575763747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 24.661879 Test MSE 6.090625914840771 Test RE 1.179611569179962\n",
      "16 Train Loss 23.912102 Test MSE 6.3251468171502205 Test RE 1.202107662941816\n",
      "17 Train Loss 23.390327 Test MSE 6.2647883307294165 Test RE 1.1963582843919869\n",
      "18 Train Loss 22.860096 Test MSE 6.474982092742465 Test RE 1.2162625823404847\n",
      "19 Train Loss 22.550098 Test MSE 6.586553491975529 Test RE 1.2266966292358206\n",
      "20 Train Loss 21.520086 Test MSE 6.339112646987764 Test RE 1.2034340490809468\n",
      "21 Train Loss 20.429588 Test MSE 6.563880923225303 Test RE 1.2245835104961675\n",
      "22 Train Loss 19.61161 Test MSE 6.778547410997696 Test RE 1.2444469260155342\n",
      "23 Train Loss 17.791794 Test MSE 6.848667219515907 Test RE 1.2508668764218167\n",
      "24 Train Loss 17.058807 Test MSE 7.055388156081265 Test RE 1.2696046843522546\n",
      "25 Train Loss 16.456022 Test MSE 7.00851693663955 Test RE 1.2653804602075012\n",
      "26 Train Loss 14.261164 Test MSE 6.9105246916534115 Test RE 1.25650312143128\n",
      "27 Train Loss 13.361382 Test MSE 6.710103260206261 Test RE 1.238148289510253\n",
      "28 Train Loss 11.47023 Test MSE 6.381639979798332 Test RE 1.2074640524710367\n",
      "29 Train Loss 10.266268 Test MSE 6.347867542920772 Test RE 1.2042647887430689\n",
      "30 Train Loss 9.378772 Test MSE 6.230011365027729 Test RE 1.193033063343847\n",
      "31 Train Loss 9.051792 Test MSE 6.071190781048139 Test RE 1.1777280002887722\n",
      "32 Train Loss 8.7645855 Test MSE 6.132705386821915 Test RE 1.1836794591354438\n",
      "33 Train Loss 8.497651 Test MSE 6.1122394234320545 Test RE 1.1817027307850712\n",
      "34 Train Loss 8.268597 Test MSE 6.0347077561385145 Test RE 1.1741840642069419\n",
      "35 Train Loss 8.098646 Test MSE 5.764401248116446 Test RE 1.1475857902669542\n",
      "36 Train Loss 7.927206 Test MSE 5.386506614376395 Test RE 1.1093323016849883\n",
      "37 Train Loss 7.0498705 Test MSE 5.211498055470947 Test RE 1.0911622943404784\n",
      "38 Train Loss 6.278253 Test MSE 4.445816778721712 Test RE 1.0078220141863872\n",
      "39 Train Loss 5.4490833 Test MSE 4.646813875895147 Test RE 1.0303521912536426\n",
      "40 Train Loss 4.761424 Test MSE 4.666522918802645 Test RE 1.032534952257623\n",
      "41 Train Loss 4.546702 Test MSE 4.570500579088862 Test RE 1.0218565767501984\n",
      "42 Train Loss 4.4143734 Test MSE 4.504666497411814 Test RE 1.0144704052618267\n",
      "43 Train Loss 4.2935743 Test MSE 4.528186316701184 Test RE 1.0171153399004116\n",
      "44 Train Loss 4.1843805 Test MSE 4.559236415473453 Test RE 1.020596598751122\n",
      "45 Train Loss 4.090234 Test MSE 4.5723415961347955 Test RE 1.0220623601143477\n",
      "46 Train Loss 4.015129 Test MSE 4.5558413716651645 Test RE 1.0202165334137587\n",
      "47 Train Loss 3.9620767 Test MSE 4.534525525077642 Test RE 1.017827043284797\n",
      "48 Train Loss 3.9147165 Test MSE 4.553699277383155 Test RE 1.0199766592861237\n",
      "49 Train Loss 3.8918202 Test MSE 4.536958344297853 Test RE 1.0181000439707486\n",
      "50 Train Loss 3.8753567 Test MSE 4.562845421698617 Test RE 1.0210004614284864\n",
      "51 Train Loss 3.8443472 Test MSE 4.6085530364688365 Test RE 1.0261015772949778\n",
      "52 Train Loss 3.8051722 Test MSE 4.624885021972698 Test RE 1.0279181404364959\n",
      "53 Train Loss 3.784245 Test MSE 4.6190717889293635 Test RE 1.0272719182512828\n",
      "54 Train Loss 3.7618165 Test MSE 4.63228266175837 Test RE 1.028739904626606\n",
      "55 Train Loss 3.7508764 Test MSE 4.6367815843044475 Test RE 1.029239344998633\n",
      "56 Train Loss 3.708222 Test MSE 4.643801959241555 Test RE 1.0300182164011378\n",
      "57 Train Loss 3.690012 Test MSE 4.665039203822546 Test RE 1.032370792625759\n",
      "58 Train Loss 3.6792464 Test MSE 4.67060077826857 Test RE 1.0329859961136487\n",
      "59 Train Loss 3.659715 Test MSE 4.658277748405455 Test RE 1.031622368023046\n",
      "60 Train Loss 3.631119 Test MSE 4.6467353619810945 Test RE 1.0303434866522465\n",
      "61 Train Loss 3.614168 Test MSE 4.655473830356887 Test RE 1.031311843389093\n",
      "62 Train Loss 3.5942204 Test MSE 4.676569806476471 Test RE 1.0336458634505545\n",
      "63 Train Loss 3.5822644 Test MSE 4.6683519072794715 Test RE 1.0327372773672858\n",
      "64 Train Loss 3.5624695 Test MSE 4.659437973111914 Test RE 1.0317508317284125\n",
      "65 Train Loss 3.5398073 Test MSE 4.660460012126408 Test RE 1.031863981832632\n",
      "66 Train Loss 3.5207846 Test MSE 4.713250396223131 Test RE 1.037691636921081\n",
      "67 Train Loss 3.515132 Test MSE 4.7174235310007635 Test RE 1.0381509238858468\n",
      "68 Train Loss 3.5074067 Test MSE 4.722780431555694 Test RE 1.0387401961162472\n",
      "69 Train Loss 3.4966466 Test MSE 4.700596944117998 Test RE 1.0362977786694398\n",
      "70 Train Loss 3.484356 Test MSE 4.723258082391251 Test RE 1.0387927226507152\n",
      "71 Train Loss 3.4768906 Test MSE 4.726123303118755 Test RE 1.0391077508732194\n",
      "72 Train Loss 3.4674497 Test MSE 4.732103051908066 Test RE 1.0397649109505036\n",
      "73 Train Loss 3.4528837 Test MSE 4.700751476556914 Test RE 1.0363148127088333\n",
      "74 Train Loss 3.4369192 Test MSE 4.7144106032977 Test RE 1.0378193474177044\n",
      "75 Train Loss 3.4248683 Test MSE 4.719702642899098 Test RE 1.0384016726684802\n",
      "76 Train Loss 3.4028568 Test MSE 4.7074958108791005 Test RE 1.0370579649962146\n",
      "77 Train Loss 3.3965528 Test MSE 4.710856554360118 Test RE 1.037428083644148\n",
      "78 Train Loss 3.3748553 Test MSE 4.741151355947627 Test RE 1.0407585089236768\n",
      "79 Train Loss 3.3648994 Test MSE 4.738452185024602 Test RE 1.0404622111649344\n",
      "80 Train Loss 3.3605669 Test MSE 4.742467100425984 Test RE 1.0409029123782585\n",
      "81 Train Loss 3.3497357 Test MSE 4.752821037905607 Test RE 1.042038562602999\n",
      "82 Train Loss 3.343086 Test MSE 4.76249875108917 Test RE 1.0430989246410511\n",
      "83 Train Loss 3.3370066 Test MSE 4.774187320641811 Test RE 1.0443781756437573\n",
      "84 Train Loss 3.3222106 Test MSE 4.790050563001499 Test RE 1.0461118199058574\n",
      "85 Train Loss 3.3136983 Test MSE 4.816672159844615 Test RE 1.0490147725655754\n",
      "86 Train Loss 3.3059957 Test MSE 4.826227312463607 Test RE 1.0500547572037964\n",
      "87 Train Loss 3.2952487 Test MSE 4.8617075551521856 Test RE 1.0539074534270292\n",
      "88 Train Loss 3.2870965 Test MSE 4.877828234047485 Test RE 1.0556533053665182\n",
      "89 Train Loss 3.2754412 Test MSE 4.933555465319278 Test RE 1.0616663876937795\n",
      "90 Train Loss 3.2631023 Test MSE 4.938971475482106 Test RE 1.0622489714691732\n",
      "91 Train Loss 3.2523377 Test MSE 4.974534892605476 Test RE 1.0660665114999455\n",
      "92 Train Loss 3.2429798 Test MSE 4.990492501724515 Test RE 1.0677750382231932\n",
      "93 Train Loss 3.2324195 Test MSE 5.023084233805653 Test RE 1.0712560577862345\n",
      "94 Train Loss 3.22862 Test MSE 5.009740375069009 Test RE 1.0698322119022414\n",
      "95 Train Loss 3.216476 Test MSE 5.005461881840094 Test RE 1.0693752772872158\n",
      "96 Train Loss 3.2072344 Test MSE 5.027664092223588 Test RE 1.0717443119178633\n",
      "97 Train Loss 3.2013812 Test MSE 5.0641998679325395 Test RE 1.0756314181761455\n",
      "98 Train Loss 3.185535 Test MSE 5.104710860630821 Test RE 1.0799250973650152\n",
      "99 Train Loss 3.1764815 Test MSE 5.116043940927775 Test RE 1.0811232154129422\n",
      "Training time: 74.52\n",
      "KG_stan_tune20\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.56767 Test MSE 8.598815662647912 Test RE 1.4016106207081414\n",
      "1 Train Loss 55.773052 Test MSE 8.792484960392095 Test RE 1.4173068213474327\n",
      "2 Train Loss 47.017944 Test MSE 8.373532414757724 Test RE 1.3831281272373104\n",
      "3 Train Loss 44.407177 Test MSE 8.375236716250836 Test RE 1.3832688771192987\n",
      "4 Train Loss 43.734055 Test MSE 8.479800869188226 Test RE 1.3918770922640413\n",
      "5 Train Loss 43.49159 Test MSE 8.486226755341916 Test RE 1.3924043658459084\n",
      "6 Train Loss 43.422085 Test MSE 8.52730204077322 Test RE 1.395770076431438\n",
      "7 Train Loss 43.262596 Test MSE 8.451485607321606 Test RE 1.3895513112672642\n",
      "8 Train Loss 43.04361 Test MSE 8.448934025435532 Test RE 1.389341536218849\n",
      "9 Train Loss 42.87157 Test MSE 8.473692061390205 Test RE 1.3913756511544018\n",
      "10 Train Loss 42.43178 Test MSE 8.466689089676649 Test RE 1.3908005902340124\n",
      "11 Train Loss 42.019684 Test MSE 8.438061550888776 Test RE 1.3884473143435803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 41.683113 Test MSE 8.172196019531878 Test RE 1.3663987242081985\n",
      "13 Train Loss 41.312416 Test MSE 8.286154614868796 Test RE 1.3758927322964616\n",
      "14 Train Loss 40.694645 Test MSE 8.032208084428023 Test RE 1.3546451165674729\n",
      "15 Train Loss 39.81128 Test MSE 7.920944174611201 Test RE 1.3452299769397404\n",
      "16 Train Loss 39.41628 Test MSE 7.797954874019034 Test RE 1.3347453578900619\n",
      "17 Train Loss 39.22516 Test MSE 7.807329359135698 Test RE 1.3355474138388703\n",
      "18 Train Loss 39.10833 Test MSE 7.915679827270866 Test RE 1.3447828752596902\n",
      "19 Train Loss 38.972855 Test MSE 7.934610810358137 Test RE 1.34638999298981\n",
      "20 Train Loss 38.835274 Test MSE 7.921405197904621 Test RE 1.3452691246295132\n",
      "21 Train Loss 38.74134 Test MSE 7.969694010801821 Test RE 1.3493632687205488\n",
      "22 Train Loss 38.24405 Test MSE 7.7162128922568245 Test RE 1.3277312007647\n",
      "23 Train Loss 37.87058 Test MSE 7.710222340177787 Test RE 1.3272157025938132\n",
      "24 Train Loss 37.119923 Test MSE 7.758986315340488 Test RE 1.3314061332141671\n",
      "25 Train Loss 36.58705 Test MSE 8.071096947530695 Test RE 1.3579204922189814\n",
      "26 Train Loss 36.10593 Test MSE 7.748784211999951 Test RE 1.3305305284391717\n",
      "27 Train Loss 35.81571 Test MSE 7.10085317368982 Test RE 1.2736887903693752\n",
      "28 Train Loss 33.667152 Test MSE 7.603498863072196 Test RE 1.317998156938414\n",
      "29 Train Loss 33.120186 Test MSE 7.292333782597601 Test RE 1.290747610405964\n",
      "30 Train Loss 32.036163 Test MSE 7.559047180025323 Test RE 1.3141398597920764\n",
      "31 Train Loss 30.151949 Test MSE 6.942373334787325 Test RE 1.2593952258253547\n",
      "32 Train Loss 29.012224 Test MSE 7.3396364871646504 Test RE 1.2949271476283142\n",
      "33 Train Loss 28.195225 Test MSE 7.501593541431905 Test RE 1.3091361781908668\n",
      "34 Train Loss 27.377491 Test MSE 7.544181041261104 Test RE 1.3128469851875144\n",
      "35 Train Loss 26.957882 Test MSE 7.575160171376497 Test RE 1.3155397354379543\n",
      "36 Train Loss 26.783062 Test MSE 7.581107659738252 Test RE 1.316056069214777\n",
      "37 Train Loss 26.4806 Test MSE 7.4590597875505855 Test RE 1.3054195258796522\n",
      "38 Train Loss 26.313698 Test MSE 7.432955857084533 Test RE 1.3031332828663702\n",
      "39 Train Loss 26.10975 Test MSE 7.278447786358977 Test RE 1.289518109845142\n",
      "40 Train Loss 25.979048 Test MSE 7.347051923854149 Test RE 1.2955811327484943\n",
      "41 Train Loss 25.799894 Test MSE 7.117650894987756 Test RE 1.2751944144641605\n",
      "42 Train Loss 25.548996 Test MSE 6.849182693684614 Test RE 1.2509139496267438\n",
      "43 Train Loss 25.44867 Test MSE 6.888735792579368 Test RE 1.2545206790270054\n",
      "44 Train Loss 25.329006 Test MSE 6.87006319665909 Test RE 1.2528192744429119\n",
      "45 Train Loss 24.986475 Test MSE 6.693466614181613 Test RE 1.2366124399382847\n",
      "46 Train Loss 24.685299 Test MSE 6.519727462436536 Test RE 1.2204578388337013\n",
      "47 Train Loss 24.241493 Test MSE 6.432342812793986 Test RE 1.2122512800099305\n",
      "48 Train Loss 23.812185 Test MSE 5.900445955124037 Test RE 1.1610488126995524\n",
      "49 Train Loss 22.913267 Test MSE 5.5379150618904385 Test RE 1.124815275162793\n",
      "50 Train Loss 19.885773 Test MSE 5.148477663687252 Test RE 1.0845447508940982\n",
      "51 Train Loss 16.734941 Test MSE 4.418669665078464 Test RE 1.004740313589605\n",
      "52 Train Loss 13.6555195 Test MSE 4.589285220643106 Test RE 1.0239543258536858\n",
      "53 Train Loss 12.050116 Test MSE 4.529767177900331 Test RE 1.0172928699036574\n",
      "54 Train Loss 11.480096 Test MSE 4.386485022741432 Test RE 1.0010744695864056\n",
      "55 Train Loss 10.750562 Test MSE 4.292943493770602 Test RE 0.9903430230261155\n",
      "56 Train Loss 10.263456 Test MSE 4.247435449932922 Test RE 0.9850798917682541\n",
      "57 Train Loss 9.612489 Test MSE 4.229724200703662 Test RE 0.9830239192148559\n",
      "58 Train Loss 9.089928 Test MSE 4.227497998394981 Test RE 0.9827651909806744\n",
      "59 Train Loss 8.421258 Test MSE 3.9386353853552487 Test RE 0.9485952583550994\n",
      "60 Train Loss 8.065151 Test MSE 4.049476615693 Test RE 0.9618503513958022\n",
      "61 Train Loss 7.427925 Test MSE 3.9481534380248653 Test RE 0.949740747924809\n",
      "62 Train Loss 6.8123946 Test MSE 3.855480680803175 Test RE 0.938528198926267\n",
      "63 Train Loss 6.3870277 Test MSE 3.5676509734107205 Test RE 0.902815986016215\n",
      "64 Train Loss 6.2243423 Test MSE 3.633458611017554 Test RE 0.91110445252284\n",
      "65 Train Loss 5.968296 Test MSE 3.623650077307974 Test RE 0.9098738566991793\n",
      "66 Train Loss 5.7181 Test MSE 3.5087154101789886 Test RE 0.8953279295433892\n",
      "67 Train Loss 5.489529 Test MSE 3.5769156774509847 Test RE 0.9039874710862063\n",
      "68 Train Loss 5.347485 Test MSE 3.5376478033728054 Test RE 0.8990117276761764\n",
      "69 Train Loss 5.198804 Test MSE 3.5885275480246066 Test RE 0.9054536057500469\n",
      "70 Train Loss 4.934456 Test MSE 3.4362819068386257 Test RE 0.8860382139626068\n",
      "71 Train Loss 4.8333306 Test MSE 3.424539236231179 Test RE 0.8845230066720237\n",
      "72 Train Loss 4.6722016 Test MSE 3.420128325312761 Test RE 0.8839531768266372\n",
      "73 Train Loss 4.551028 Test MSE 3.491896687523326 Test RE 0.8931795135450448\n",
      "74 Train Loss 4.392116 Test MSE 3.476981603048685 Test RE 0.8912699347268563\n",
      "75 Train Loss 4.308482 Test MSE 3.564851366161347 Test RE 0.9024616875935703\n",
      "76 Train Loss 4.2120357 Test MSE 3.503607567953094 Test RE 0.8946760015799168\n",
      "77 Train Loss 4.0971885 Test MSE 3.5457447779060067 Test RE 0.9000399694661818\n",
      "78 Train Loss 3.9942892 Test MSE 3.5737497125511717 Test RE 0.9035873182119607\n",
      "79 Train Loss 3.9321039 Test MSE 3.590173523444111 Test RE 0.9056612373621701\n",
      "80 Train Loss 3.870512 Test MSE 3.5953056725885566 Test RE 0.9063083270678205\n",
      "81 Train Loss 3.7727628 Test MSE 3.6820337687669844 Test RE 0.917174441389754\n",
      "82 Train Loss 3.736796 Test MSE 3.659080242689508 Test RE 0.914311173260559\n",
      "83 Train Loss 3.6899858 Test MSE 3.5889830294744285 Test RE 0.9055110672338548\n",
      "84 Train Loss 3.6453414 Test MSE 3.5781602142431175 Test RE 0.904144722182536\n",
      "85 Train Loss 3.5435684 Test MSE 3.5888001056640175 Test RE 0.9054879908297501\n",
      "86 Train Loss 3.496987 Test MSE 3.597502836647779 Test RE 0.9065852164514892\n",
      "87 Train Loss 3.4446075 Test MSE 3.6204223790578225 Test RE 0.9094685398972874\n",
      "88 Train Loss 3.3801215 Test MSE 3.529825444095477 Test RE 0.8980172413837902\n",
      "89 Train Loss 3.3188126 Test MSE 3.5472153180353985 Test RE 0.9002265886075477\n",
      "90 Train Loss 3.2918456 Test MSE 3.526508927243411 Test RE 0.8975952673700491\n",
      "91 Train Loss 3.2248178 Test MSE 3.502069033781705 Test RE 0.8944795411143512\n",
      "92 Train Loss 3.1767786 Test MSE 3.4370292724883114 Test RE 0.8861345620710711\n",
      "93 Train Loss 3.1373322 Test MSE 3.4466597952312537 Test RE 0.887375163871943\n",
      "94 Train Loss 3.088575 Test MSE 3.3546526025041703 Test RE 0.87545098681466\n",
      "95 Train Loss 3.0646 Test MSE 3.3723398398901003 Test RE 0.8777558384377294\n",
      "96 Train Loss 3.044042 Test MSE 3.3757848951149603 Test RE 0.8782040651282655\n",
      "97 Train Loss 3.025688 Test MSE 3.3665749390814557 Test RE 0.8770052705852671\n",
      "98 Train Loss 2.994605 Test MSE 3.2808753617826745 Test RE 0.8657707843590547\n",
      "99 Train Loss 2.9656613 Test MSE 3.221103285715718 Test RE 0.8578480841757011\n",
      "Training time: 76.86\n",
      "KG_stan_tune21\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 121.140465 Test MSE 5.3362476353302695 Test RE 1.1041448419242426\n",
      "1 Train Loss 72.13761 Test MSE 4.782275368048866 Test RE 1.0452624523913563\n",
      "2 Train Loss 59.301765 Test MSE 5.150898935980662 Test RE 1.084799745638006\n",
      "3 Train Loss 46.90457 Test MSE 5.0792203865130645 Test RE 1.077225409300165\n",
      "4 Train Loss 39.947575 Test MSE 5.463447962108539 Test RE 1.1172271105800122\n",
      "5 Train Loss 36.036636 Test MSE 5.45319224029866 Test RE 1.116178015515449\n",
      "6 Train Loss 32.92138 Test MSE 5.608871142097098 Test RE 1.1319983442328685\n",
      "7 Train Loss 29.404633 Test MSE 5.415840437132705 Test RE 1.1123487998350563\n",
      "8 Train Loss 26.11079 Test MSE 5.10958570014143 Test RE 1.080440621694159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 23.33736 Test MSE 4.695375539296818 Test RE 1.0357220609757878\n",
      "10 Train Loss 20.793053 Test MSE 4.4420812372990355 Test RE 1.0073985203467044\n",
      "11 Train Loss 18.688635 Test MSE 4.467209547837882 Test RE 1.010243867216826\n",
      "12 Train Loss 17.261154 Test MSE 4.334772087838136 Test RE 0.9951560655190356\n",
      "13 Train Loss 16.025127 Test MSE 4.473020930807008 Test RE 1.010900765647261\n",
      "14 Train Loss 14.803825 Test MSE 4.564385925548003 Test RE 1.0211728015213035\n",
      "15 Train Loss 13.309599 Test MSE 4.539041457181753 Test RE 1.0183337439271962\n",
      "16 Train Loss 12.5548 Test MSE 4.720302229817764 Test RE 1.0384676293964343\n",
      "17 Train Loss 11.669046 Test MSE 4.676329176005752 Test RE 1.0336192702529141\n",
      "18 Train Loss 10.918413 Test MSE 4.653745597123784 Test RE 1.0311204007013504\n",
      "19 Train Loss 10.238464 Test MSE 4.493010941104095 Test RE 1.013157114315279\n",
      "20 Train Loss 9.392998 Test MSE 4.422889805440574 Test RE 1.005219997922909\n",
      "21 Train Loss 8.638435 Test MSE 4.438913243612426 Test RE 1.0070392291496881\n",
      "22 Train Loss 7.9572115 Test MSE 4.400852259922162 Test RE 1.0027125598192452\n",
      "23 Train Loss 7.2979403 Test MSE 4.415020707097077 Test RE 1.0043253682916105\n",
      "24 Train Loss 6.707758 Test MSE 4.35648683711484 Test RE 0.9976455354006168\n",
      "25 Train Loss 6.200502 Test MSE 4.467140616488233 Test RE 1.0102360728945385\n",
      "26 Train Loss 5.793557 Test MSE 4.51769978615952 Test RE 1.0159369218020906\n",
      "27 Train Loss 5.47511 Test MSE 4.530867237677309 Test RE 1.0174163878450004\n",
      "28 Train Loss 5.13021 Test MSE 4.608031491907045 Test RE 1.0260435142939772\n",
      "29 Train Loss 4.8693466 Test MSE 4.680216529298543 Test RE 1.0340487961092597\n",
      "30 Train Loss 4.58562 Test MSE 4.610460676896406 Test RE 1.0263139248925506\n",
      "31 Train Loss 4.3427525 Test MSE 4.57900194582444 Test RE 1.0228064881945746\n",
      "32 Train Loss 4.0646305 Test MSE 4.622841221134502 Test RE 1.0276909896967341\n",
      "33 Train Loss 3.8482409 Test MSE 4.647693783524037 Test RE 1.0304497389350535\n",
      "34 Train Loss 3.6611795 Test MSE 4.6022488450209496 Test RE 1.0253995180529238\n",
      "35 Train Loss 3.4084997 Test MSE 4.596442165239399 Test RE 1.024752438099616\n",
      "36 Train Loss 3.1852155 Test MSE 4.5915003280449405 Test RE 1.0242014117362837\n",
      "37 Train Loss 3.008109 Test MSE 4.641774337843563 Test RE 1.029793323628166\n",
      "38 Train Loss 2.8319955 Test MSE 4.652576152122268 Test RE 1.030990836854654\n",
      "39 Train Loss 2.670025 Test MSE 4.674412914956135 Test RE 1.0334074708665344\n",
      "40 Train Loss 2.5088062 Test MSE 4.699438172702572 Test RE 1.0361700389085948\n",
      "41 Train Loss 2.401338 Test MSE 4.698592865568467 Test RE 1.0360768446495678\n",
      "42 Train Loss 2.292131 Test MSE 4.744642410722649 Test RE 1.0411416095779127\n",
      "43 Train Loss 2.1337848 Test MSE 4.724577501501722 Test RE 1.0389378033600194\n",
      "44 Train Loss 2.03031 Test MSE 4.693816950321944 Test RE 1.035550147254053\n",
      "45 Train Loss 1.9367172 Test MSE 4.723953009794922 Test RE 1.0388691380155466\n",
      "46 Train Loss 1.8554415 Test MSE 4.730493544683162 Test RE 1.0395880708180245\n",
      "47 Train Loss 1.7580647 Test MSE 4.778089260584703 Test RE 1.0448048732512452\n",
      "48 Train Loss 1.6584966 Test MSE 4.774689170790799 Test RE 1.0444330653595353\n",
      "49 Train Loss 1.5846894 Test MSE 4.796463055119547 Test RE 1.046811806276943\n",
      "50 Train Loss 1.5415201 Test MSE 4.789076011033532 Test RE 1.0460053970007794\n",
      "51 Train Loss 1.4788399 Test MSE 4.753462901019904 Test RE 1.0421089232931529\n",
      "52 Train Loss 1.4418625 Test MSE 4.747684449428379 Test RE 1.0414753212994405\n",
      "53 Train Loss 1.404532 Test MSE 4.737960977216527 Test RE 1.0404082804310029\n",
      "54 Train Loss 1.3741292 Test MSE 4.71265233569672 Test RE 1.0376257989066917\n",
      "55 Train Loss 1.3540822 Test MSE 4.7067382474435835 Test RE 1.0369745162968993\n",
      "56 Train Loss 1.3230888 Test MSE 4.705127866545927 Test RE 1.0367971039650954\n",
      "57 Train Loss 1.2989144 Test MSE 4.694422033446482 Test RE 1.0356168918387894\n",
      "58 Train Loss 1.2735283 Test MSE 4.689374010224172 Test RE 1.0350599303813974\n",
      "59 Train Loss 1.249204 Test MSE 4.678267101897648 Test RE 1.0338334200688333\n",
      "60 Train Loss 1.2266117 Test MSE 4.638004498373508 Test RE 1.0293750628745315\n",
      "61 Train Loss 1.2054535 Test MSE 4.627958550188556 Test RE 1.028259641973623\n",
      "62 Train Loss 1.1884699 Test MSE 4.60656173071259 Test RE 1.025879869664743\n",
      "63 Train Loss 1.1693808 Test MSE 4.565696985307214 Test RE 1.0213194502122136\n",
      "64 Train Loss 1.1481576 Test MSE 4.522010890065792 Test RE 1.0164215451123744\n",
      "65 Train Loss 1.1316388 Test MSE 4.507338256902136 Test RE 1.014771206570831\n",
      "66 Train Loss 1.1129055 Test MSE 4.491181496204138 Test RE 1.0129508268329046\n",
      "67 Train Loss 1.0970466 Test MSE 4.485005992824125 Test RE 1.0122541690484885\n",
      "68 Train Loss 1.0860009 Test MSE 4.438538875791589 Test RE 1.0069967625581766\n",
      "69 Train Loss 1.0648552 Test MSE 4.301850868812148 Test RE 0.9913699158385711\n",
      "70 Train Loss 1.0458609 Test MSE 4.2646551080029 Test RE 0.9870746932878639\n",
      "71 Train Loss 1.0203246 Test MSE 4.240218575414083 Test RE 0.9842426547513055\n",
      "72 Train Loss 0.9890588 Test MSE 4.0842111123115785 Test RE 0.9659666921081433\n",
      "73 Train Loss 0.9510853 Test MSE 4.020985031137851 Test RE 0.9584606522556167\n",
      "74 Train Loss 0.9219024 Test MSE 3.9849712451397896 Test RE 0.9541587916513651\n",
      "75 Train Loss 0.89209616 Test MSE 3.937096933438414 Test RE 0.9484099770853452\n",
      "76 Train Loss 0.8719372 Test MSE 3.913295286122054 Test RE 0.945538833583\n",
      "77 Train Loss 0.85006195 Test MSE 3.8638867595268818 Test RE 0.9395507752259682\n",
      "78 Train Loss 0.8264526 Test MSE 3.8108521641773527 Test RE 0.9330804947207418\n",
      "79 Train Loss 0.80273473 Test MSE 3.7793328773992907 Test RE 0.9292137615999757\n",
      "80 Train Loss 0.7778704 Test MSE 3.7254169174537983 Test RE 0.9225618710059339\n",
      "81 Train Loss 0.75828123 Test MSE 3.715107395289669 Test RE 0.9212844621189152\n",
      "82 Train Loss 0.7403789 Test MSE 3.6661721737271793 Test RE 0.9151967910262254\n",
      "83 Train Loss 0.72196686 Test MSE 3.673783346324515 Test RE 0.9161462976030269\n",
      "84 Train Loss 0.70147586 Test MSE 3.6451293174647126 Test RE 0.9125665178602803\n",
      "85 Train Loss 0.68833804 Test MSE 3.645941652990565 Test RE 0.9126681972303406\n",
      "86 Train Loss 0.6771855 Test MSE 3.6412814034749075 Test RE 0.912084723613634\n",
      "87 Train Loss 0.66385937 Test MSE 3.6381150236243687 Test RE 0.9116880727535408\n",
      "88 Train Loss 0.6541557 Test MSE 3.637241418411 Test RE 0.9115786062762217\n",
      "89 Train Loss 0.6436631 Test MSE 3.6212494986191186 Test RE 0.9095724222874965\n",
      "90 Train Loss 0.6380304 Test MSE 3.6130548936387417 Test RE 0.9085426937085092\n",
      "91 Train Loss 0.63057077 Test MSE 3.601695321062774 Test RE 0.907113324120076\n",
      "92 Train Loss 0.6206291 Test MSE 3.5966419169967323 Test RE 0.9064767323495333\n",
      "93 Train Loss 0.6099623 Test MSE 3.579542834980795 Test RE 0.9043193885516893\n",
      "94 Train Loss 0.59877414 Test MSE 3.5392212421096345 Test RE 0.8992116320624569\n",
      "95 Train Loss 0.5881658 Test MSE 3.534710704783418 Test RE 0.8986384521960749\n",
      "96 Train Loss 0.5735279 Test MSE 3.4934105291360797 Test RE 0.8933731025771037\n",
      "97 Train Loss 0.5597902 Test MSE 3.4793031779153223 Test RE 0.8915674348058487\n",
      "98 Train Loss 0.5466697 Test MSE 3.474623434018077 Test RE 0.8909676435609455\n",
      "99 Train Loss 0.53355104 Test MSE 3.4570759886953524 Test RE 0.8887150260955169\n",
      "Training time: 72.90\n",
      "KG_stan_tune21\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 81.16806 Test MSE 5.900577318609419 Test RE 1.161061737025189\n",
      "1 Train Loss 66.49802 Test MSE 6.281956520142236 Test RE 1.197996428586519\n",
      "2 Train Loss 52.063046 Test MSE 7.26882126356658 Test RE 1.2886650651352105\n",
      "3 Train Loss 41.89956 Test MSE 7.983497323329997 Test RE 1.350531295062471\n",
      "4 Train Loss 37.63125 Test MSE 8.228106547309066 Test RE 1.3710649027812118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 33.489105 Test MSE 8.507626488210972 Test RE 1.394158874719098\n",
      "6 Train Loss 31.220364 Test MSE 8.383797616070991 Test RE 1.3839756632133935\n",
      "7 Train Loss 29.08258 Test MSE 8.437950020789206 Test RE 1.3884381384103417\n",
      "8 Train Loss 27.091022 Test MSE 8.413437936239673 Test RE 1.386419978454434\n",
      "9 Train Loss 25.248997 Test MSE 8.338009965385556 Test RE 1.3801912354529973\n",
      "10 Train Loss 23.47071 Test MSE 8.398650464693079 Test RE 1.3852010556731063\n",
      "11 Train Loss 21.876022 Test MSE 8.397906564492585 Test RE 1.3851397080693384\n",
      "12 Train Loss 20.70028 Test MSE 8.21991153176112 Test RE 1.370381957245524\n",
      "13 Train Loss 19.29555 Test MSE 8.063498227809403 Test RE 1.3572811189669707\n",
      "14 Train Loss 18.561165 Test MSE 8.146274573801538 Test RE 1.3642299582246888\n",
      "15 Train Loss 17.98692 Test MSE 8.067231630843562 Test RE 1.3575952934668263\n",
      "16 Train Loss 16.96563 Test MSE 8.069065785741978 Test RE 1.3577496152127837\n",
      "17 Train Loss 16.189266 Test MSE 8.140348383943945 Test RE 1.3637336481291915\n",
      "18 Train Loss 15.377794 Test MSE 8.094896187134694 Test RE 1.3599210682742822\n",
      "19 Train Loss 14.707974 Test MSE 7.96591150578319 Test RE 1.3490430193437661\n",
      "20 Train Loss 14.095543 Test MSE 7.916774019781018 Test RE 1.34487581740335\n",
      "21 Train Loss 13.274143 Test MSE 7.888397734042248 Test RE 1.3424634182005577\n",
      "22 Train Loss 12.68051 Test MSE 7.853028869537139 Test RE 1.3394504648370926\n",
      "23 Train Loss 12.425185 Test MSE 7.878801987987095 Test RE 1.3416466580429307\n",
      "24 Train Loss 12.020182 Test MSE 7.770264662980102 Test RE 1.332373437949033\n",
      "25 Train Loss 11.712601 Test MSE 7.683082307582175 Test RE 1.3248777394323301\n",
      "26 Train Loss 11.458403 Test MSE 7.614614992372188 Test RE 1.3189612455926931\n",
      "27 Train Loss 11.100011 Test MSE 7.600151133199437 Test RE 1.3177079755587882\n",
      "28 Train Loss 10.843309 Test MSE 7.5972879458853235 Test RE 1.3174597436424809\n",
      "29 Train Loss 10.521807 Test MSE 7.6261514076314585 Test RE 1.3199600042816213\n",
      "30 Train Loss 10.278279 Test MSE 7.562937368419331 Test RE 1.3144779707957368\n",
      "31 Train Loss 10.046405 Test MSE 7.584325552422222 Test RE 1.3163353475267816\n",
      "32 Train Loss 9.662693 Test MSE 7.540476069589107 Test RE 1.3125245739013276\n",
      "33 Train Loss 9.431457 Test MSE 7.528817801146616 Test RE 1.3115095396555962\n",
      "34 Train Loss 9.255776 Test MSE 7.495167275034502 Test RE 1.308575320002321\n",
      "35 Train Loss 9.032387 Test MSE 7.487711125321171 Test RE 1.30792427641102\n",
      "36 Train Loss 8.9010105 Test MSE 7.463044390912023 Test RE 1.3057681545740347\n",
      "37 Train Loss 8.671568 Test MSE 7.479669052870939 Test RE 1.3072217087355817\n",
      "38 Train Loss 8.582157 Test MSE 7.491552624560174 Test RE 1.3082597424676525\n",
      "39 Train Loss 8.339465 Test MSE 7.481520446053632 Test RE 1.3073834827123683\n",
      "40 Train Loss 8.208835 Test MSE 7.477076608129425 Test RE 1.3069951483276965\n",
      "41 Train Loss 8.032578 Test MSE 7.430872627161791 Test RE 1.302950655891267\n",
      "42 Train Loss 7.860697 Test MSE 7.436484149114613 Test RE 1.3034425332753807\n",
      "43 Train Loss 7.6578913 Test MSE 7.473030688600869 Test RE 1.3066414865283114\n",
      "44 Train Loss 7.51193 Test MSE 7.401032555709332 Test RE 1.3003319020902033\n",
      "45 Train Loss 7.369401 Test MSE 7.437664712727939 Test RE 1.3035459918270778\n",
      "46 Train Loss 7.2965665 Test MSE 7.438022345712402 Test RE 1.3035773313306378\n",
      "47 Train Loss 7.0828943 Test MSE 7.450797727878842 Test RE 1.304696348788932\n",
      "48 Train Loss 6.95135 Test MSE 7.38114897210238 Test RE 1.298583994151599\n",
      "49 Train Loss 6.6281238 Test MSE 7.271988909944887 Test RE 1.2889458252785981\n",
      "50 Train Loss 6.53054 Test MSE 7.243615392194858 Test RE 1.2864287923771338\n",
      "51 Train Loss 6.2872286 Test MSE 7.1734614495233195 Test RE 1.2801841463639732\n",
      "52 Train Loss 6.202432 Test MSE 7.192733783320235 Test RE 1.2819026742636328\n",
      "53 Train Loss 6.0226398 Test MSE 7.211620741386838 Test RE 1.2835846056344158\n",
      "54 Train Loss 5.91352 Test MSE 7.275653626768907 Test RE 1.2892705663186772\n",
      "55 Train Loss 5.795386 Test MSE 7.2799895668863295 Test RE 1.2896546807661795\n",
      "56 Train Loss 5.6904607 Test MSE 7.308633914497708 Test RE 1.292189371921123\n",
      "57 Train Loss 5.60426 Test MSE 7.292937707861151 Test RE 1.2908010568728652\n",
      "58 Train Loss 5.511838 Test MSE 7.306265581658823 Test RE 1.291979990624852\n",
      "59 Train Loss 5.4297805 Test MSE 7.280140225744686 Test RE 1.289668025352381\n",
      "60 Train Loss 5.374032 Test MSE 7.266562316081849 Test RE 1.288464808944855\n",
      "61 Train Loss 5.2407846 Test MSE 7.249241104542716 Test RE 1.286928244193436\n",
      "62 Train Loss 5.1879196 Test MSE 7.262057864528596 Test RE 1.2880653953868044\n",
      "63 Train Loss 5.1010623 Test MSE 7.248443268725858 Test RE 1.2868574239734734\n",
      "64 Train Loss 4.955409 Test MSE 7.327664281580149 Test RE 1.2938705924920766\n",
      "65 Train Loss 4.8988047 Test MSE 7.289717450033706 Test RE 1.290516043389087\n",
      "66 Train Loss 4.8199887 Test MSE 7.30227139903718 Test RE 1.2916267931238532\n",
      "67 Train Loss 4.735112 Test MSE 7.29927649570442 Test RE 1.2913618964987779\n",
      "68 Train Loss 4.6534414 Test MSE 7.2526412164807414 Test RE 1.2872300128241074\n",
      "69 Train Loss 4.580628 Test MSE 7.225245385770255 Test RE 1.284796547593884\n",
      "70 Train Loss 4.515217 Test MSE 7.211342968423104 Test RE 1.2835598852181418\n",
      "71 Train Loss 4.4215736 Test MSE 7.226925972600764 Test RE 1.2849459602781113\n",
      "72 Train Loss 4.3463326 Test MSE 7.232863462338966 Test RE 1.2854736941373404\n",
      "73 Train Loss 4.2359476 Test MSE 7.264439047324339 Test RE 1.2882765523229975\n",
      "74 Train Loss 4.184107 Test MSE 7.257973490997829 Test RE 1.2877031234085263\n",
      "75 Train Loss 4.124723 Test MSE 7.252725280217233 Test RE 1.2872374727995715\n",
      "76 Train Loss 4.049097 Test MSE 7.255850913005157 Test RE 1.2875148167016555\n",
      "77 Train Loss 3.9730783 Test MSE 7.246408173553847 Test RE 1.2866767602722955\n",
      "78 Train Loss 3.9167566 Test MSE 7.243262584704383 Test RE 1.2863974635988982\n",
      "79 Train Loss 3.8712382 Test MSE 7.23123241042981 Test RE 1.28532874514513\n",
      "80 Train Loss 3.8079324 Test MSE 7.211436163186242 Test RE 1.2835681791429716\n",
      "81 Train Loss 3.7483866 Test MSE 7.22244862104836 Test RE 1.2845478625141575\n",
      "82 Train Loss 3.702708 Test MSE 7.197569909042779 Test RE 1.2823335536041778\n",
      "83 Train Loss 3.6374645 Test MSE 7.183244996483423 Test RE 1.2810568404067761\n",
      "84 Train Loss 3.5709767 Test MSE 7.193167123664686 Test RE 1.2819412890515984\n",
      "85 Train Loss 3.5318718 Test MSE 7.176288086417173 Test RE 1.2804363439511566\n",
      "86 Train Loss 3.4641693 Test MSE 7.195630252726641 Test RE 1.2821607554234096\n",
      "87 Train Loss 3.3944533 Test MSE 7.198303709774925 Test RE 1.2823989196464787\n",
      "88 Train Loss 3.3460436 Test MSE 7.220558150410144 Test RE 1.2843797367805134\n",
      "89 Train Loss 3.28806 Test MSE 7.261687005306157 Test RE 1.2880325054650539\n",
      "90 Train Loss 3.2549934 Test MSE 7.273933372822266 Test RE 1.2891181398833622\n",
      "91 Train Loss 3.200201 Test MSE 7.25247923066174 Test RE 1.2872156377732857\n",
      "92 Train Loss 3.1373527 Test MSE 7.269971279504659 Test RE 1.2887670023474234\n",
      "93 Train Loss 3.0802202 Test MSE 7.278114295238854 Test RE 1.289488567298597\n",
      "94 Train Loss 3.0329769 Test MSE 7.269367082114826 Test RE 1.2887134474014543\n",
      "95 Train Loss 2.9601977 Test MSE 7.281276834012155 Test RE 1.2897686958123757\n",
      "96 Train Loss 2.9253538 Test MSE 7.2954738748626 Test RE 1.2910254796373901\n",
      "97 Train Loss 2.8657265 Test MSE 7.263534299344284 Test RE 1.2881963257635614\n",
      "98 Train Loss 2.8043044 Test MSE 7.231500987013141 Test RE 1.285352614243641\n",
      "99 Train Loss 2.7609622 Test MSE 7.2354958725670615 Test RE 1.2857075977828916\n",
      "Training time: 73.64\n",
      "KG_stan_tune21\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 155.81497 Test MSE 7.005444669633835 Test RE 1.265103082496309\n",
      "1 Train Loss 79.919495 Test MSE 6.16390033106593 Test RE 1.1866861238552109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 58.791237 Test MSE 6.229658153342823 Test RE 1.192999243245723\n",
      "3 Train Loss 47.710773 Test MSE 6.2169663364908745 Test RE 1.1917833621065657\n",
      "4 Train Loss 36.78733 Test MSE 6.50629260009692 Test RE 1.2191997234590732\n",
      "5 Train Loss 29.268164 Test MSE 6.59183684952506 Test RE 1.2271885236490667\n",
      "6 Train Loss 23.523495 Test MSE 6.506073025406571 Test RE 1.2191791504786622\n",
      "7 Train Loss 18.612507 Test MSE 6.4015182242839455 Test RE 1.2093431621935187\n",
      "8 Train Loss 14.587873 Test MSE 6.337134372153225 Test RE 1.2032462539433146\n",
      "9 Train Loss 12.322919 Test MSE 6.069114014556451 Test RE 1.1775265509079922\n",
      "10 Train Loss 10.783129 Test MSE 5.914157757420842 Test RE 1.1623970865105244\n",
      "11 Train Loss 9.662258 Test MSE 5.828137105698391 Test RE 1.1539126654457152\n",
      "12 Train Loss 8.822491 Test MSE 5.742481558709678 Test RE 1.145401809494729\n",
      "13 Train Loss 8.052134 Test MSE 5.646904597231089 Test RE 1.135829869968644\n",
      "14 Train Loss 7.4119287 Test MSE 5.524276552347777 Test RE 1.1234293509938125\n",
      "15 Train Loss 6.768121 Test MSE 5.48896872330389 Test RE 1.119833456176591\n",
      "16 Train Loss 6.274755 Test MSE 5.444121637237588 Test RE 1.1152493281605922\n",
      "17 Train Loss 5.743305 Test MSE 5.420554710919043 Test RE 1.112832822231054\n",
      "18 Train Loss 5.2754555 Test MSE 5.3763944483234205 Test RE 1.1082905298089336\n",
      "19 Train Loss 4.8200483 Test MSE 5.273619342843071 Test RE 1.0976463803437044\n",
      "20 Train Loss 4.4408817 Test MSE 5.149741912637054 Test RE 1.0846779019427208\n",
      "21 Train Loss 4.100708 Test MSE 5.04883731237673 Test RE 1.073998682613592\n",
      "22 Train Loss 3.7540483 Test MSE 4.917113591015691 Test RE 1.0598958235168903\n",
      "23 Train Loss 3.4517531 Test MSE 4.852008344700664 Test RE 1.052855644625772\n",
      "24 Train Loss 3.2067142 Test MSE 4.790490623988717 Test RE 1.0461598718440888\n",
      "25 Train Loss 2.9795012 Test MSE 4.714887971053324 Test RE 1.037871889399481\n",
      "26 Train Loss 2.7665696 Test MSE 4.615520838540499 Test RE 1.0268769803588282\n",
      "27 Train Loss 2.6029189 Test MSE 4.4967334513115285 Test RE 1.0135767334629533\n",
      "28 Train Loss 2.4463775 Test MSE 4.473739371887979 Test RE 1.010981946072029\n",
      "29 Train Loss 2.3160136 Test MSE 4.379286054871954 Test RE 1.0002526655463555\n",
      "30 Train Loss 2.2077234 Test MSE 4.3586424998133175 Test RE 0.997892330740131\n",
      "31 Train Loss 2.1068237 Test MSE 4.289184353913588 Test RE 0.9899093283742606\n",
      "32 Train Loss 2.023468 Test MSE 4.191996694590984 Test RE 0.9786300024280018\n",
      "33 Train Loss 1.966442 Test MSE 4.171262656266623 Test RE 0.9762068010312173\n",
      "34 Train Loss 1.9073815 Test MSE 4.1364105739678365 Test RE 0.9721200042201861\n",
      "35 Train Loss 1.8644602 Test MSE 4.05480253153497 Test RE 0.962482661598814\n",
      "36 Train Loss 1.8167305 Test MSE 4.033595572495558 Test RE 0.9599624292957374\n",
      "37 Train Loss 1.7641547 Test MSE 3.9028664618772546 Test RE 0.944278075565997\n",
      "38 Train Loss 1.714792 Test MSE 3.802147583733791 Test RE 0.9320142348394878\n",
      "39 Train Loss 1.6681081 Test MSE 3.786745802293607 Test RE 0.930124612491928\n",
      "40 Train Loss 1.6294336 Test MSE 3.711560018811105 Test RE 0.9208445120712094\n",
      "41 Train Loss 1.5967829 Test MSE 3.6535371950726825 Test RE 0.9136183774127463\n",
      "42 Train Loss 1.5606176 Test MSE 3.6151640019656788 Test RE 0.9088078343516359\n",
      "43 Train Loss 1.5298213 Test MSE 3.5539450678078808 Test RE 0.9010801354632497\n",
      "44 Train Loss 1.5006459 Test MSE 3.523449615964499 Test RE 0.8972058427015006\n",
      "45 Train Loss 1.4597263 Test MSE 3.409573875539039 Test RE 0.8825881917415418\n",
      "46 Train Loss 1.4272531 Test MSE 3.328946339242043 Test RE 0.8720903032224947\n",
      "47 Train Loss 1.3944598 Test MSE 3.24670281627511 Test RE 0.861250186866015\n",
      "48 Train Loss 1.3612787 Test MSE 3.1968310935029383 Test RE 0.854609872715627\n",
      "49 Train Loss 1.3263707 Test MSE 3.1812720957991276 Test RE 0.8525276401638386\n",
      "50 Train Loss 1.2942863 Test MSE 3.127379314017763 Test RE 0.8452756140374679\n",
      "51 Train Loss 1.2601961 Test MSE 3.0117263362486804 Test RE 0.8294988984355514\n",
      "52 Train Loss 1.2253596 Test MSE 2.9583534940912877 Test RE 0.8221159869399677\n",
      "53 Train Loss 1.1990222 Test MSE 2.872517347917545 Test RE 0.8101014142964653\n",
      "54 Train Loss 1.1688582 Test MSE 2.817144571416416 Test RE 0.8022553606325289\n",
      "55 Train Loss 1.1308191 Test MSE 2.687060165658367 Test RE 0.7835139904867942\n",
      "56 Train Loss 1.0737413 Test MSE 2.5007365671935338 Test RE 0.7558611651451455\n",
      "57 Train Loss 1.0139484 Test MSE 2.3654542800286156 Test RE 0.7351320196733675\n",
      "58 Train Loss 0.95422953 Test MSE 2.238703016236013 Test RE 0.7151650830520329\n",
      "59 Train Loss 0.8875308 Test MSE 2.1909248245695085 Test RE 0.7074924316557588\n",
      "60 Train Loss 0.8166564 Test MSE 2.1400315588859162 Test RE 0.6992269346403146\n",
      "61 Train Loss 0.72664386 Test MSE 2.039305074954317 Test RE 0.6825730865139267\n",
      "62 Train Loss 0.67589325 Test MSE 1.9957786236625732 Test RE 0.6752494569981294\n",
      "63 Train Loss 0.6131868 Test MSE 1.8663081664894159 Test RE 0.652979787907663\n",
      "64 Train Loss 0.5282578 Test MSE 1.7025184509887874 Test RE 0.6236687361995589\n",
      "65 Train Loss 0.49043754 Test MSE 1.719901536800325 Test RE 0.6268445474670213\n",
      "66 Train Loss 0.43054605 Test MSE 1.650930009628296 Test RE 0.6141470799236203\n",
      "67 Train Loss 0.39578873 Test MSE 1.6254110921157607 Test RE 0.6093820673721936\n",
      "68 Train Loss 0.3585273 Test MSE 1.6247537043884706 Test RE 0.6092588244561241\n",
      "69 Train Loss 0.334274 Test MSE 1.5683772071784106 Test RE 0.5985953259275738\n",
      "70 Train Loss 0.3016704 Test MSE 1.531137039058309 Test RE 0.5914459898322961\n",
      "71 Train Loss 0.2769033 Test MSE 1.522338702694932 Test RE 0.5897442356081422\n",
      "72 Train Loss 0.25522187 Test MSE 1.4877745350186402 Test RE 0.5830108279732265\n",
      "73 Train Loss 0.24125384 Test MSE 1.470415357255208 Test RE 0.5795995975370635\n",
      "74 Train Loss 0.22904179 Test MSE 1.4811721653960035 Test RE 0.5817157617867584\n",
      "75 Train Loss 0.21763425 Test MSE 1.4743227913660437 Test RE 0.580369191195134\n",
      "76 Train Loss 0.20769635 Test MSE 1.4643932734847902 Test RE 0.5784115052138632\n",
      "77 Train Loss 0.20108587 Test MSE 1.4562659230706958 Test RE 0.5768041864078224\n",
      "78 Train Loss 0.19184294 Test MSE 1.438246394063609 Test RE 0.5732244512207383\n",
      "79 Train Loss 0.18550953 Test MSE 1.438059030845914 Test RE 0.573187112460094\n",
      "80 Train Loss 0.17953077 Test MSE 1.4304501667034606 Test RE 0.5716687161111162\n",
      "81 Train Loss 0.17525525 Test MSE 1.4135624565039493 Test RE 0.5682841735136672\n",
      "82 Train Loss 0.16930163 Test MSE 1.4080260751958436 Test RE 0.5671702062600441\n",
      "83 Train Loss 0.16385017 Test MSE 1.417702675510167 Test RE 0.5691157959985516\n",
      "84 Train Loss 0.15936056 Test MSE 1.4177002718268843 Test RE 0.5691153135367747\n",
      "85 Train Loss 0.15609348 Test MSE 1.4192965568235794 Test RE 0.5694356261836805\n",
      "86 Train Loss 0.1529118 Test MSE 1.417132432373392 Test RE 0.5690013266449735\n",
      "87 Train Loss 0.14896853 Test MSE 1.401437615835538 Test RE 0.5658416941408967\n",
      "88 Train Loss 0.14309652 Test MSE 1.3800298577612589 Test RE 0.5615032853274045\n",
      "89 Train Loss 0.13770272 Test MSE 1.362628539889618 Test RE 0.5579519512499166\n",
      "90 Train Loss 0.1337659 Test MSE 1.3501887605081662 Test RE 0.5553992698787872\n",
      "91 Train Loss 0.129271 Test MSE 1.338890435521902 Test RE 0.5530706087860199\n",
      "92 Train Loss 0.12531826 Test MSE 1.3268329962510836 Test RE 0.55057462527732\n",
      "93 Train Loss 0.12226406 Test MSE 1.3228779637449384 Test RE 0.5497534346391706\n",
      "94 Train Loss 0.11916718 Test MSE 1.3255491908827433 Test RE 0.5503082007455171\n",
      "95 Train Loss 0.116265774 Test MSE 1.3147777298973646 Test RE 0.5480677276824673\n",
      "96 Train Loss 0.112710126 Test MSE 1.3164008290884603 Test RE 0.5484059194127257\n",
      "97 Train Loss 0.109137036 Test MSE 1.296929841962279 Test RE 0.5443350528885003\n",
      "98 Train Loss 0.107090116 Test MSE 1.2833407351522248 Test RE 0.5414757981118173\n",
      "99 Train Loss 0.10478092 Test MSE 1.2786493713483378 Test RE 0.5404851860013021\n",
      "Training time: 72.81\n",
      "KG_stan_tune21\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 84.295395 Test MSE 7.002621499385169 Test RE 1.2648481407002665\n",
      "1 Train Loss 53.83637 Test MSE 7.59842761239617 Test RE 1.3175585557748881\n",
      "2 Train Loss 48.175503 Test MSE 8.332937595578475 Test RE 1.3797713567630114\n",
      "3 Train Loss 42.412254 Test MSE 9.248444124946861 Test RE 1.4535915806283501\n",
      "4 Train Loss 38.45185 Test MSE 9.145349041827203 Test RE 1.4454670726095447\n",
      "5 Train Loss 35.09867 Test MSE 9.201776635037632 Test RE 1.4499195434595156\n",
      "6 Train Loss 32.934467 Test MSE 9.323098661948197 Test RE 1.4594465705848425\n",
      "7 Train Loss 31.427368 Test MSE 9.337347618641012 Test RE 1.4605614172718133\n",
      "8 Train Loss 30.084644 Test MSE 9.319043350382318 Test RE 1.4591291249311695\n",
      "9 Train Loss 29.074509 Test MSE 9.095887748080557 Test RE 1.4415529737280173\n",
      "10 Train Loss 27.982212 Test MSE 8.950481235033921 Test RE 1.4299842478554787\n",
      "11 Train Loss 26.88814 Test MSE 9.00195300590572 Test RE 1.4340900776952386\n",
      "12 Train Loss 25.74472 Test MSE 8.95323152419225 Test RE 1.4302039325849991\n",
      "13 Train Loss 24.614283 Test MSE 8.918782212678803 Test RE 1.4274497859052495\n",
      "14 Train Loss 23.783249 Test MSE 8.860705788164351 Test RE 1.4227946336750679\n",
      "15 Train Loss 22.98959 Test MSE 8.767247026512393 Test RE 1.4152712420218323\n",
      "16 Train Loss 22.216286 Test MSE 8.792350721815835 Test RE 1.41729600199563\n",
      "17 Train Loss 21.038616 Test MSE 8.697352595909578 Test RE 1.4096185257643368\n",
      "18 Train Loss 20.274807 Test MSE 8.656557471211084 Test RE 1.406308716584303\n",
      "19 Train Loss 19.03875 Test MSE 8.655504368130464 Test RE 1.406223172585354\n",
      "20 Train Loss 18.271553 Test MSE 8.533425170139463 Test RE 1.3962711110510657\n",
      "21 Train Loss 17.363644 Test MSE 8.484001820209206 Test RE 1.3922218222627023\n",
      "22 Train Loss 16.3706 Test MSE 8.482680206851011 Test RE 1.3921133798873289\n",
      "23 Train Loss 15.567907 Test MSE 8.471043572879957 Test RE 1.391158193971172\n",
      "24 Train Loss 14.715281 Test MSE 8.260180102671436 Test RE 1.3737345422078697\n",
      "25 Train Loss 14.0377 Test MSE 8.260698155256796 Test RE 1.373777619693125\n",
      "26 Train Loss 13.190521 Test MSE 7.941076765432974 Test RE 1.3469384713310204\n",
      "27 Train Loss 12.646054 Test MSE 7.843423049731119 Test RE 1.3386310067015104\n",
      "28 Train Loss 12.039287 Test MSE 7.882884387230905 Test RE 1.3419941999661846\n",
      "29 Train Loss 11.440733 Test MSE 7.9103565392818265 Test RE 1.344330616537879\n",
      "30 Train Loss 10.881739 Test MSE 7.767204917907394 Test RE 1.3321110836633847\n",
      "31 Train Loss 10.331924 Test MSE 7.751801071989881 Test RE 1.3307895131769376\n",
      "32 Train Loss 9.97312 Test MSE 7.755732265931865 Test RE 1.3311269140282784\n",
      "33 Train Loss 9.667608 Test MSE 7.825174478011137 Test RE 1.3370728649956067\n",
      "34 Train Loss 9.28453 Test MSE 7.72874629565106 Test RE 1.3288090765947842\n",
      "35 Train Loss 8.933077 Test MSE 7.756697070368402 Test RE 1.331209706804643\n",
      "36 Train Loss 8.663956 Test MSE 7.641763962570393 Test RE 1.3213104502940825\n",
      "37 Train Loss 8.295116 Test MSE 7.631050022619726 Test RE 1.3203838706267128\n",
      "38 Train Loss 7.8929467 Test MSE 7.620826739691844 Test RE 1.3194991180765168\n",
      "39 Train Loss 7.531087 Test MSE 7.572428145743928 Test RE 1.3153024855110729\n",
      "40 Train Loss 7.1787605 Test MSE 7.562700447395955 Test RE 1.3144573815795433\n",
      "41 Train Loss 6.957402 Test MSE 7.570927255056028 Test RE 1.3151721294981673\n",
      "42 Train Loss 6.597492 Test MSE 7.538664767462595 Test RE 1.3123669232891586\n",
      "43 Train Loss 6.2378545 Test MSE 7.444628604975403 Test RE 1.3041561046981278\n",
      "44 Train Loss 5.8765707 Test MSE 7.434660692542718 Test RE 1.303282718736541\n",
      "45 Train Loss 5.5378294 Test MSE 7.397237436718458 Test RE 1.2999984657044408\n",
      "46 Train Loss 5.3470864 Test MSE 7.4392227188231645 Test RE 1.3036825149383466\n",
      "47 Train Loss 5.1029024 Test MSE 7.418928243954069 Test RE 1.3019030534282243\n",
      "48 Train Loss 4.7991395 Test MSE 7.4074314132623025 Test RE 1.3008939075159731\n",
      "49 Train Loss 4.625306 Test MSE 7.335580846036121 Test RE 1.2945693311686441\n",
      "50 Train Loss 4.4867964 Test MSE 7.316543870173236 Test RE 1.2928884352989929\n",
      "51 Train Loss 4.3084755 Test MSE 7.364630857839856 Test RE 1.2971301437392218\n",
      "52 Train Loss 4.181708 Test MSE 7.350339897968434 Test RE 1.2958710014457961\n",
      "53 Train Loss 4.0474606 Test MSE 7.392412149547408 Test RE 1.2995743959575472\n",
      "54 Train Loss 3.902022 Test MSE 7.318610152305822 Test RE 1.293070986222841\n",
      "55 Train Loss 3.812365 Test MSE 7.288277739412303 Test RE 1.2903885993960063\n",
      "56 Train Loss 3.695581 Test MSE 7.268461078033795 Test RE 1.288633136694106\n",
      "57 Train Loss 3.5612006 Test MSE 7.31497683280252 Test RE 1.2927499742289252\n",
      "58 Train Loss 3.4490175 Test MSE 7.357392562598413 Test RE 1.2964925476906395\n",
      "59 Train Loss 3.360423 Test MSE 7.289489289251627 Test RE 1.2904958473077053\n",
      "60 Train Loss 3.2918184 Test MSE 7.257973896481117 Test RE 1.2877031593787656\n",
      "61 Train Loss 3.1896653 Test MSE 7.2694736918725775 Test RE 1.2887228972561093\n",
      "62 Train Loss 3.111668 Test MSE 7.31322538294348 Test RE 1.2925952011955577\n",
      "63 Train Loss 3.0217078 Test MSE 7.342577295284935 Test RE 1.2951865440506183\n",
      "64 Train Loss 2.9331641 Test MSE 7.331628561328367 Test RE 1.2942205383439689\n",
      "65 Train Loss 2.8579786 Test MSE 7.276678253692878 Test RE 1.2893613468104286\n",
      "66 Train Loss 2.7564883 Test MSE 7.258235474122528 Test RE 1.2877263636038871\n",
      "67 Train Loss 2.6910915 Test MSE 7.226642315968358 Test RE 1.2849207429850424\n",
      "68 Train Loss 2.6193078 Test MSE 7.251721246881324 Test RE 1.2871483701508046\n",
      "69 Train Loss 2.5509744 Test MSE 7.2546940039023955 Test RE 1.2874121687139275\n",
      "70 Train Loss 2.4874444 Test MSE 7.206425595543623 Test RE 1.2831221845742697\n",
      "71 Train Loss 2.4425547 Test MSE 7.208789661702381 Test RE 1.283332631276267\n",
      "72 Train Loss 2.3773816 Test MSE 7.1821401911545735 Test RE 1.2809583213635853\n",
      "73 Train Loss 2.3147116 Test MSE 7.2040111267959315 Test RE 1.282907215453109\n",
      "74 Train Loss 2.2702906 Test MSE 7.122517304899227 Test RE 1.2756302716367387\n",
      "75 Train Loss 2.220907 Test MSE 7.1123825649227514 Test RE 1.274722391546205\n",
      "76 Train Loss 2.1813176 Test MSE 7.164000942221256 Test RE 1.279339701369964\n",
      "77 Train Loss 2.1432016 Test MSE 7.15602287234948 Test RE 1.278627145298821\n",
      "78 Train Loss 2.1092017 Test MSE 7.209238937520809 Test RE 1.2833726214384247\n",
      "79 Train Loss 2.073079 Test MSE 7.205223488572678 Test RE 1.283015161027592\n",
      "80 Train Loss 2.041161 Test MSE 7.211457043234467 Test RE 1.2835700373682595\n",
      "81 Train Loss 2.0062346 Test MSE 7.231742377389845 Test RE 1.2853740668551457\n",
      "82 Train Loss 1.9631858 Test MSE 7.2422877604665 Test RE 1.286310896695684\n",
      "83 Train Loss 1.9228468 Test MSE 7.227696626710749 Test RE 1.2850144695233554\n",
      "84 Train Loss 1.8865871 Test MSE 7.260188471918471 Test RE 1.2878995983802095\n",
      "85 Train Loss 1.8571059 Test MSE 7.238166479633401 Test RE 1.2859448519448222\n",
      "86 Train Loss 1.8268381 Test MSE 7.246498857171801 Test RE 1.2866848111670233\n",
      "87 Train Loss 1.7998227 Test MSE 7.234063380785172 Test RE 1.285580318549518\n",
      "88 Train Loss 1.7700648 Test MSE 7.253593667877873 Test RE 1.2873145326382252\n",
      "89 Train Loss 1.7430515 Test MSE 7.2438594822296825 Test RE 1.2864504667611605\n",
      "90 Train Loss 1.7200955 Test MSE 7.250029826049445 Test RE 1.286998251547432\n",
      "91 Train Loss 1.6897552 Test MSE 7.26645876979419 Test RE 1.2884556287976805\n",
      "92 Train Loss 1.6726797 Test MSE 7.262998527171914 Test RE 1.2881488149758942\n",
      "93 Train Loss 1.6451582 Test MSE 7.2768964181874365 Test RE 1.2893806750497967\n",
      "94 Train Loss 1.6250403 Test MSE 7.293828643637506 Test RE 1.2908798992932378\n",
      "95 Train Loss 1.5961047 Test MSE 7.3051641807836365 Test RE 1.291882605612736\n",
      "96 Train Loss 1.574827 Test MSE 7.310866294603737 Test RE 1.2923867027519558\n",
      "97 Train Loss 1.5584495 Test MSE 7.290791537491241 Test RE 1.2906111140176988\n",
      "98 Train Loss 1.5416105 Test MSE 7.3101736873292245 Test RE 1.2923254830827104\n",
      "99 Train Loss 1.5261841 Test MSE 7.295485581832529 Test RE 1.291026515484455\n",
      "Training time: 73.70\n",
      "KG_stan_tune21\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 78.1384 Test MSE 6.670409496143162 Test RE 1.234480710775614\n",
      "1 Train Loss 57.34408 Test MSE 7.00990476781615 Test RE 1.2655057397452187\n",
      "2 Train Loss 45.027878 Test MSE 7.147412464578383 Test RE 1.277857666562893\n",
      "3 Train Loss 38.391396 Test MSE 6.900208832845908 Test RE 1.2555649329226053\n",
      "4 Train Loss 31.187235 Test MSE 6.901646538048026 Test RE 1.2556957288348238\n",
      "5 Train Loss 27.640244 Test MSE 6.6128140719992 Test RE 1.2291396155280283\n",
      "6 Train Loss 23.590328 Test MSE 6.508023617747202 Test RE 1.2193618984499386\n",
      "7 Train Loss 20.65237 Test MSE 6.364946905822789 Test RE 1.205883778021956\n",
      "8 Train Loss 18.559872 Test MSE 6.47152377837193 Test RE 1.2159377335535506\n",
      "9 Train Loss 16.600227 Test MSE 6.064805483200553 Test RE 1.1771085071216925\n",
      "10 Train Loss 14.996554 Test MSE 6.025428084198603 Test RE 1.1732809355605924\n",
      "11 Train Loss 13.979984 Test MSE 5.73362662432633 Test RE 1.1445183612233527\n",
      "12 Train Loss 12.764761 Test MSE 5.501223007906992 Test RE 1.121082789885132\n",
      "13 Train Loss 11.257185 Test MSE 5.428189238920111 Test RE 1.1136162258113806\n",
      "14 Train Loss 9.891094 Test MSE 5.24413229477814 Test RE 1.0945733748887776\n",
      "15 Train Loss 8.343237 Test MSE 4.909386247403538 Test RE 1.059062672181381\n",
      "16 Train Loss 7.1495476 Test MSE 4.957599091735572 Test RE 1.0642502529398852\n",
      "17 Train Loss 6.158964 Test MSE 4.953356242092185 Test RE 1.0637947481432475\n",
      "18 Train Loss 5.390909 Test MSE 4.557377650815959 Test RE 1.0203885329582123\n",
      "19 Train Loss 4.781792 Test MSE 4.203426840707346 Test RE 0.9799632894139627\n",
      "20 Train Loss 3.9090881 Test MSE 3.9357856287684436 Test RE 0.9482520233920072\n",
      "21 Train Loss 3.2898247 Test MSE 3.8329641036075306 Test RE 0.9357836141432676\n",
      "22 Train Loss 2.8788161 Test MSE 3.8311403952046894 Test RE 0.9355609666777029\n",
      "23 Train Loss 2.6294892 Test MSE 3.736815659054162 Test RE 0.9239721846499396\n",
      "24 Train Loss 2.4187899 Test MSE 3.6139982808742714 Test RE 0.9086612985545343\n",
      "25 Train Loss 2.2433393 Test MSE 3.511280474448436 Test RE 0.8956551367739515\n",
      "26 Train Loss 2.068275 Test MSE 3.5063109763610574 Test RE 0.8950211041907933\n",
      "27 Train Loss 1.9512832 Test MSE 3.4178331137223843 Test RE 0.8836565212797467\n",
      "28 Train Loss 1.8753947 Test MSE 3.3767319600054755 Test RE 0.8783272450607887\n",
      "29 Train Loss 1.8022798 Test MSE 3.3300266801162537 Test RE 0.8722318012037992\n",
      "30 Train Loss 1.7317015 Test MSE 3.2547875081444952 Test RE 0.8623218299326068\n",
      "31 Train Loss 1.6713619 Test MSE 3.2095887745693794 Test RE 0.8563134322655407\n",
      "32 Train Loss 1.6295217 Test MSE 3.1614738624810923 Test RE 0.849870702466314\n",
      "33 Train Loss 1.5837462 Test MSE 3.1134342195264155 Test RE 0.843388951649572\n",
      "34 Train Loss 1.5251403 Test MSE 3.092689778003366 Test RE 0.8405745557323346\n",
      "35 Train Loss 1.4758059 Test MSE 3.0156155024421762 Test RE 0.8300343086786265\n",
      "36 Train Loss 1.4480246 Test MSE 2.952050030161777 Test RE 0.8212396647077695\n",
      "37 Train Loss 1.4037105 Test MSE 2.890527770604351 Test RE 0.8126370770319188\n",
      "38 Train Loss 1.3584018 Test MSE 2.8500890189822705 Test RE 0.806932621250424\n",
      "39 Train Loss 1.319004 Test MSE 2.806121944041053 Test RE 0.8006843321331609\n",
      "40 Train Loss 1.2758974 Test MSE 2.7544538520512956 Test RE 0.7932787314415346\n",
      "41 Train Loss 1.2459483 Test MSE 2.7072001135707864 Test RE 0.7864447906921003\n",
      "42 Train Loss 1.213765 Test MSE 2.683410245654279 Test RE 0.7829816735682671\n",
      "43 Train Loss 1.1873778 Test MSE 2.66043145448019 Test RE 0.779622020347828\n",
      "44 Train Loss 1.1640974 Test MSE 2.6282218605941394 Test RE 0.7748882435602132\n",
      "45 Train Loss 1.141206 Test MSE 2.5989048558282724 Test RE 0.7705543039694066\n",
      "46 Train Loss 1.120404 Test MSE 2.546532747026018 Test RE 0.7627508371125402\n",
      "47 Train Loss 1.0992177 Test MSE 2.508188617304194 Test RE 0.7569865386256281\n",
      "48 Train Loss 1.0731936 Test MSE 2.416970536942447 Test RE 0.7430939722528637\n",
      "49 Train Loss 1.042343 Test MSE 2.360652327409585 Test RE 0.7343854691021163\n",
      "50 Train Loss 1.0064183 Test MSE 2.282484479168851 Test RE 0.72212432865204\n",
      "51 Train Loss 0.97319895 Test MSE 2.2312135066932095 Test RE 0.7139677998564852\n",
      "52 Train Loss 0.9447202 Test MSE 2.2263772959091392 Test RE 0.7131936086250509\n",
      "53 Train Loss 0.91034234 Test MSE 2.1683535303296666 Test RE 0.7038386408419934\n",
      "54 Train Loss 0.87437356 Test MSE 2.10041692209919 Test RE 0.6927249253863613\n",
      "55 Train Loss 0.84467196 Test MSE 2.0484894644955913 Test RE 0.6841084072029876\n",
      "56 Train Loss 0.81881136 Test MSE 1.9489014842540158 Test RE 0.6672721567905257\n",
      "57 Train Loss 0.791195 Test MSE 1.8749816873053824 Test RE 0.6544953652403495\n",
      "58 Train Loss 0.7567631 Test MSE 1.7371420352777485 Test RE 0.6299784955988618\n",
      "59 Train Loss 0.70047903 Test MSE 1.5574780930793362 Test RE 0.5965117924331507\n",
      "60 Train Loss 0.6447136 Test MSE 1.3831357697492277 Test RE 0.5621347932699723\n",
      "61 Train Loss 0.5608717 Test MSE 1.284576058732062 Test RE 0.5417363434653621\n",
      "62 Train Loss 0.48638728 Test MSE 1.1712032526647238 Test RE 0.5172782228281603\n",
      "63 Train Loss 0.40808618 Test MSE 1.0701576468151126 Test RE 0.4944608827066024\n",
      "64 Train Loss 0.35739586 Test MSE 1.033286295850913 Test RE 0.485868109999853\n",
      "65 Train Loss 0.31047127 Test MSE 1.0034283576889163 Test RE 0.4787968069405923\n",
      "66 Train Loss 0.26588672 Test MSE 0.9639723911465138 Test RE 0.46928898214432374\n",
      "67 Train Loss 0.2266528 Test MSE 0.9014873230168561 Test RE 0.45382443144971296\n",
      "68 Train Loss 0.19623071 Test MSE 0.8864049367055254 Test RE 0.45001205029533164\n",
      "69 Train Loss 0.17455871 Test MSE 0.8742447773807946 Test RE 0.44691464214366644\n",
      "70 Train Loss 0.15392952 Test MSE 0.8472841186229056 Test RE 0.4399695226971547\n",
      "71 Train Loss 0.13652527 Test MSE 0.8225204162030711 Test RE 0.43349231591992077\n",
      "72 Train Loss 0.1256167 Test MSE 0.8216647192932983 Test RE 0.4332667685942741\n",
      "73 Train Loss 0.114057496 Test MSE 0.840904123066791 Test RE 0.4383099213507865\n",
      "74 Train Loss 0.10469614 Test MSE 0.8335832167329418 Test RE 0.4363977887046416\n",
      "75 Train Loss 0.09496839 Test MSE 0.8355826136057577 Test RE 0.4369208377406605\n",
      "76 Train Loss 0.08930548 Test MSE 0.8304810027053365 Test RE 0.4355849956813146\n",
      "77 Train Loss 0.082173645 Test MSE 0.8266466520405064 Test RE 0.4345782791535678\n",
      "78 Train Loss 0.07467884 Test MSE 0.8293731017641122 Test RE 0.4352943532220742\n",
      "79 Train Loss 0.06961267 Test MSE 0.8260389315551094 Test RE 0.43441850672872834\n",
      "80 Train Loss 0.06629798 Test MSE 0.8201903262397626 Test RE 0.4328778676690697\n",
      "81 Train Loss 0.062046763 Test MSE 0.8219971911819367 Test RE 0.4333544165416004\n",
      "82 Train Loss 0.057464235 Test MSE 0.8191303930009658 Test RE 0.4325980728730098\n",
      "83 Train Loss 0.0542071 Test MSE 0.8061994923256002 Test RE 0.42916996472750796\n",
      "84 Train Loss 0.051758677 Test MSE 0.803535562246039 Test RE 0.4284603235105511\n",
      "85 Train Loss 0.050014276 Test MSE 0.8009824400282686 Test RE 0.4277790954828736\n",
      "86 Train Loss 0.04765295 Test MSE 0.801226573366332 Test RE 0.4278442824187969\n",
      "87 Train Loss 0.04469869 Test MSE 0.7950521766962658 Test RE 0.42619257151603857\n",
      "88 Train Loss 0.04264071 Test MSE 0.7924762753035997 Test RE 0.4255015975566485\n",
      "89 Train Loss 0.041071177 Test MSE 0.7869632281628968 Test RE 0.4240189636361881\n",
      "90 Train Loss 0.039325517 Test MSE 0.7788486779000781 Test RE 0.42182722290001873\n",
      "91 Train Loss 0.037677836 Test MSE 0.7776240230028834 Test RE 0.421495453700001\n",
      "92 Train Loss 0.03624855 Test MSE 0.771708379773581 Test RE 0.4198891652894695\n",
      "93 Train Loss 0.03458258 Test MSE 0.7678697210689902 Test RE 0.41884354972785404\n",
      "94 Train Loss 0.0331083 Test MSE 0.7595967223561378 Test RE 0.4165811373266711\n",
      "95 Train Loss 0.03160602 Test MSE 0.7598218057000764 Test RE 0.41664285331855533\n",
      "96 Train Loss 0.029975303 Test MSE 0.7610805254365122 Test RE 0.416987815494604\n",
      "97 Train Loss 0.028810665 Test MSE 0.7583044770079616 Test RE 0.41622663725509906\n",
      "98 Train Loss 0.027810432 Test MSE 0.7553980042389609 Test RE 0.41542820281908527\n",
      "99 Train Loss 0.026549296 Test MSE 0.7499516267271045 Test RE 0.41392788653261625\n",
      "Training time: 72.56\n",
      "KG_stan_tune21\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 148.09837 Test MSE 6.921861800602069 Test RE 1.2575333814857186\n",
      "1 Train Loss 110.286514 Test MSE 6.5705695501725225 Test RE 1.2252072799409373\n",
      "2 Train Loss 79.0907 Test MSE 6.381233558464009 Test RE 1.2074256025611032\n",
      "3 Train Loss 66.514885 Test MSE 7.396636048167861 Test RE 1.2999456202948951\n",
      "4 Train Loss 55.587708 Test MSE 7.289152372132501 Test RE 1.290466023876328\n",
      "5 Train Loss 48.21818 Test MSE 7.815173578985855 Test RE 1.3362181744098964\n",
      "6 Train Loss 43.67185 Test MSE 8.099684247131563 Test RE 1.36032319950262\n",
      "7 Train Loss 39.018845 Test MSE 8.743803666627127 Test RE 1.4133777786353119\n",
      "8 Train Loss 35.84458 Test MSE 9.157992581171081 Test RE 1.446465914067348\n",
      "9 Train Loss 32.869087 Test MSE 9.370595359138942 Test RE 1.46315943644217\n",
      "10 Train Loss 30.31865 Test MSE 9.771222340491777 Test RE 1.4941097784888764\n",
      "11 Train Loss 28.524782 Test MSE 9.771905114434167 Test RE 1.4941619787852207\n",
      "12 Train Loss 26.80191 Test MSE 9.792152234769556 Test RE 1.4957091091895716\n",
      "13 Train Loss 25.06661 Test MSE 9.739706249498457 Test RE 1.491698282298915\n",
      "14 Train Loss 23.95795 Test MSE 9.780451048953335 Test RE 1.4948151891748829\n",
      "15 Train Loss 22.975258 Test MSE 9.896400918503051 Test RE 1.5036497995855782\n",
      "16 Train Loss 21.961391 Test MSE 9.91029717161176 Test RE 1.504705121032191\n",
      "17 Train Loss 21.09771 Test MSE 9.9931785668379 Test RE 1.510984064823553\n",
      "18 Train Loss 20.324503 Test MSE 10.036602416620688 Test RE 1.5142633828848298\n",
      "19 Train Loss 19.717066 Test MSE 9.98585611495672 Test RE 1.5104303803492214\n",
      "20 Train Loss 18.79859 Test MSE 10.11510975284414 Test RE 1.5201742085793248\n",
      "21 Train Loss 17.880386 Test MSE 10.01770409272091 Test RE 1.5128370773267659\n",
      "22 Train Loss 17.138878 Test MSE 9.958112734987484 Test RE 1.5083307311345109\n",
      "23 Train Loss 16.54697 Test MSE 9.94725273000999 Test RE 1.5075080377120806\n",
      "24 Train Loss 15.948559 Test MSE 9.89529098731798 Test RE 1.5035654762737205\n",
      "25 Train Loss 15.345079 Test MSE 10.003601839749084 Test RE 1.5117718669477007\n",
      "26 Train Loss 14.823782 Test MSE 9.87209295820521 Test RE 1.5018019999734373\n",
      "27 Train Loss 14.392895 Test MSE 9.897015075111609 Test RE 1.5036964560489738\n",
      "28 Train Loss 13.934664 Test MSE 9.88834036418348 Test RE 1.5030373183432049\n",
      "29 Train Loss 13.196036 Test MSE 9.794116079440906 Test RE 1.4958590860810288\n",
      "30 Train Loss 12.757458 Test MSE 9.67969513827226 Test RE 1.4870956388771164\n",
      "31 Train Loss 12.211689 Test MSE 9.708372377484281 Test RE 1.489296857906149\n",
      "32 Train Loss 11.894447 Test MSE 9.686144910108352 Test RE 1.4875909969552863\n",
      "33 Train Loss 11.49222 Test MSE 9.685682585609657 Test RE 1.4875554948037506\n",
      "34 Train Loss 11.207498 Test MSE 9.697353025351646 Test RE 1.4884514151631645\n",
      "35 Train Loss 10.962261 Test MSE 9.67804681956995 Test RE 1.4869690175383614\n",
      "36 Train Loss 10.5530205 Test MSE 9.701246179605773 Test RE 1.4887501662481348\n",
      "37 Train Loss 10.314121 Test MSE 9.719004144109995 Test RE 1.4901121090841993\n",
      "38 Train Loss 10.082874 Test MSE 9.67901011529662 Test RE 1.487043017762055\n",
      "39 Train Loss 9.897676 Test MSE 9.675254344005525 Test RE 1.4867544791975116\n",
      "40 Train Loss 9.825741 Test MSE 9.628492015694635 Test RE 1.4831572450580188\n",
      "41 Train Loss 9.680525 Test MSE 9.631844656882647 Test RE 1.4834154402810968\n",
      "42 Train Loss 9.506365 Test MSE 9.694065497027498 Test RE 1.4881990916183152\n",
      "43 Train Loss 9.342798 Test MSE 9.698626448401352 Test RE 1.4885491411155083\n",
      "44 Train Loss 9.211944 Test MSE 9.687957702350992 Test RE 1.4877301940911274\n",
      "45 Train Loss 9.049797 Test MSE 9.656660304847861 Test RE 1.4853251593664398\n",
      "46 Train Loss 8.855639 Test MSE 9.539404026880968 Test RE 1.4762798152404504\n",
      "47 Train Loss 8.7408905 Test MSE 9.545745955103138 Test RE 1.476770459364617\n",
      "48 Train Loss 8.638366 Test MSE 9.568835950026537 Test RE 1.4785554443919384\n",
      "49 Train Loss 8.490783 Test MSE 9.547136502735851 Test RE 1.4768780174798435\n",
      "50 Train Loss 8.399059 Test MSE 9.540418441359531 Test RE 1.4763583065070165\n",
      "51 Train Loss 8.276018 Test MSE 9.554415571479819 Test RE 1.4774409217754627\n",
      "52 Train Loss 8.229023 Test MSE 9.549346719083006 Test RE 1.47704896041318\n",
      "53 Train Loss 8.127926 Test MSE 9.511941528650825 Test RE 1.474153290743621\n",
      "54 Train Loss 8.022381 Test MSE 9.551498670933368 Test RE 1.4772153780376343\n",
      "55 Train Loss 7.9224863 Test MSE 9.57461732275819 Test RE 1.4790020394324337\n",
      "56 Train Loss 7.850437 Test MSE 9.525813650555179 Test RE 1.4752278444316813\n",
      "57 Train Loss 7.793479 Test MSE 9.50667431814479 Test RE 1.4737450801332217\n",
      "58 Train Loss 7.691431 Test MSE 9.47893872808982 Test RE 1.4715936944442023\n",
      "59 Train Loss 7.59497 Test MSE 9.406760663180943 Test RE 1.4659802096115955\n",
      "60 Train Loss 7.521055 Test MSE 9.36556785757618 Test RE 1.4627668774318174\n",
      "61 Train Loss 7.39634 Test MSE 9.376988520002232 Test RE 1.463658477236022\n",
      "62 Train Loss 7.3292084 Test MSE 9.372919949136312 Test RE 1.4633409102305028\n",
      "63 Train Loss 7.2123137 Test MSE 9.32282952852796 Test RE 1.4594255052343537\n",
      "64 Train Loss 7.155986 Test MSE 9.352578536744023 Test RE 1.4617521530104145\n",
      "65 Train Loss 7.0454335 Test MSE 9.310584593267548 Test RE 1.4584667596844336\n",
      "66 Train Loss 6.987842 Test MSE 9.357351199115598 Test RE 1.4621250747489787\n",
      "67 Train Loss 6.886736 Test MSE 9.346901612105594 Test RE 1.4613084509659562\n",
      "68 Train Loss 6.8137674 Test MSE 9.31409465485193 Test RE 1.4587416525063654\n",
      "69 Train Loss 6.708982 Test MSE 9.30233166689614 Test RE 1.457820222017138\n",
      "70 Train Loss 6.675707 Test MSE 9.316557928355241 Test RE 1.458934534490558\n",
      "71 Train Loss 6.6095333 Test MSE 9.284246198728873 Test RE 1.4564023953135223\n",
      "72 Train Loss 6.5707154 Test MSE 9.248516376440975 Test RE 1.453597258554118\n",
      "73 Train Loss 6.4871407 Test MSE 9.270926288203636 Test RE 1.4553572855619399\n",
      "74 Train Loss 6.438011 Test MSE 9.256927286462151 Test RE 1.454258083318542\n",
      "75 Train Loss 6.3767815 Test MSE 9.258258693202539 Test RE 1.454362661184347\n",
      "76 Train Loss 6.3386474 Test MSE 9.254663415226844 Test RE 1.4540802459944302\n",
      "77 Train Loss 6.261503 Test MSE 9.299311737621784 Test RE 1.4575835678377707\n",
      "78 Train Loss 6.2079153 Test MSE 9.257238183919752 Test RE 1.4542825040215825\n",
      "79 Train Loss 6.1469297 Test MSE 9.235691568140608 Test RE 1.452589065855438\n",
      "80 Train Loss 6.0956783 Test MSE 9.267878021355274 Test RE 1.4551180062304148\n",
      "81 Train Loss 6.0651035 Test MSE 9.28319665201261 Test RE 1.4563200727683887\n",
      "82 Train Loss 5.986005 Test MSE 9.256971985412077 Test RE 1.4542615944042814\n",
      "83 Train Loss 5.9417286 Test MSE 9.268580739364438 Test RE 1.4551731708670157\n",
      "84 Train Loss 5.853815 Test MSE 9.257372119539488 Test RE 1.454293024412225\n",
      "85 Train Loss 5.8140526 Test MSE 9.267663761436397 Test RE 1.4551011860226388\n",
      "86 Train Loss 5.7579556 Test MSE 9.220797886552209 Test RE 1.4514173545691762\n",
      "87 Train Loss 5.7010493 Test MSE 9.216224457225364 Test RE 1.4510573652238086\n",
      "88 Train Loss 5.6341915 Test MSE 9.193709441287433 Test RE 1.4492838321665427\n",
      "89 Train Loss 5.560482 Test MSE 9.202497669267848 Test RE 1.4499763488561488\n",
      "90 Train Loss 5.5031886 Test MSE 9.20371801003131 Test RE 1.4500724861576717\n",
      "91 Train Loss 5.4351645 Test MSE 9.17672706501671 Test RE 1.4479446741358857\n",
      "92 Train Loss 5.373153 Test MSE 9.194605097764821 Test RE 1.4493544254807658\n",
      "93 Train Loss 5.318577 Test MSE 9.138102991565805 Test RE 1.4448943223235085\n",
      "94 Train Loss 5.2761555 Test MSE 9.156540733130852 Test RE 1.4463512529163065\n",
      "95 Train Loss 5.2346687 Test MSE 9.119531598526018 Test RE 1.4434253441445248\n",
      "96 Train Loss 5.1747017 Test MSE 9.122827521790553 Test RE 1.443686157397353\n",
      "97 Train Loss 5.124489 Test MSE 9.099381913863997 Test RE 1.4418298318845602\n",
      "98 Train Loss 5.057551 Test MSE 9.129566864703264 Test RE 1.4442193089797881\n",
      "99 Train Loss 5.022751 Test MSE 9.153826712469163 Test RE 1.446136886038108\n",
      "Training time: 75.68\n",
      "KG_stan_tune21\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.91\n",
      "KG_stan_tune22\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 317498.7 Test MSE 5.118045467659387 Test RE 1.0813346762056248\n",
      "1 Train Loss 275996.53 Test MSE 5.122903413908318 Test RE 1.0818477450941626\n",
      "2 Train Loss 235766.69 Test MSE 5.122146444019661 Test RE 1.0817678142078335\n",
      "3 Train Loss 205101.06 Test MSE 5.122737242865037 Test RE 1.0818301990649113\n",
      "4 Train Loss 181975.97 Test MSE 5.121499601797793 Test RE 1.081699507376244\n",
      "5 Train Loss 162815.1 Test MSE 5.13120650959564 Test RE 1.0827241083427168\n",
      "6 Train Loss 148361.86 Test MSE 5.127887192615825 Test RE 1.0823738509605365\n",
      "7 Train Loss 137769.16 Test MSE 5.130279660406542 Test RE 1.0826263177665083\n",
      "8 Train Loss 127944.484 Test MSE 5.12294545478223 Test RE 1.081852184152218\n",
      "9 Train Loss 118541.5 Test MSE 5.120725101498575 Test RE 1.0816177141191008\n",
      "10 Train Loss 111053.01 Test MSE 5.113073790691139 Test RE 1.080809343542201\n",
      "11 Train Loss 104845.61 Test MSE 5.108607464234623 Test RE 1.080337190959693\n",
      "12 Train Loss 100524.07 Test MSE 5.11321074995506 Test RE 1.080823818774413\n",
      "13 Train Loss 97467.94 Test MSE 5.1206297125296265 Test RE 1.081607639874049\n",
      "14 Train Loss 95048.09 Test MSE 5.121958056695946 Test RE 1.0817479208662952\n",
      "15 Train Loss 92466.69 Test MSE 5.120200168071495 Test RE 1.0815622735482948\n",
      "16 Train Loss 89119.84 Test MSE 5.127533071353558 Test RE 1.08233647706779\n",
      "17 Train Loss 86911.72 Test MSE 5.127462962309844 Test RE 1.0823290776191947\n",
      "18 Train Loss 83593.914 Test MSE 5.1290155502286705 Test RE 1.0824929290087841\n",
      "19 Train Loss 81093.43 Test MSE 5.127199165344694 Test RE 1.0823012355069794\n",
      "20 Train Loss 78769.42 Test MSE 5.129369550920465 Test RE 1.0825302847771678\n",
      "21 Train Loss 77424.41 Test MSE 5.137030498150465 Test RE 1.0833383873172289\n",
      "22 Train Loss 76161.24 Test MSE 5.138501398129787 Test RE 1.083493473836752\n",
      "23 Train Loss 74469.34 Test MSE 5.141301671193167 Test RE 1.0837886634362714\n",
      "24 Train Loss 72767.62 Test MSE 5.144697564287164 Test RE 1.084146532234007\n",
      "25 Train Loss 71250.945 Test MSE 5.150659760304496 Test RE 1.084774559672618\n",
      "26 Train Loss 69218.93 Test MSE 5.162271323013513 Test RE 1.0859966202811768\n",
      "27 Train Loss 67777.17 Test MSE 5.171624815309716 Test RE 1.0869800308098188\n",
      "28 Train Loss 66136.27 Test MSE 5.178607572630011 Test RE 1.0877136065922115\n",
      "29 Train Loss 64483.63 Test MSE 5.184595327748145 Test RE 1.0883422583157745\n",
      "30 Train Loss 63040.793 Test MSE 5.177188267993549 Test RE 1.0875645411595438\n",
      "31 Train Loss 61947.664 Test MSE 5.1832372677424985 Test RE 1.0881997080488512\n",
      "32 Train Loss 60857.72 Test MSE 5.183386060577147 Test RE 1.088215327163785\n",
      "33 Train Loss 60012.05 Test MSE 5.183941341432572 Test RE 1.0882736142514404\n",
      "34 Train Loss 58863.94 Test MSE 5.1957798875132415 Test RE 1.0895155486529005\n",
      "35 Train Loss 57859.586 Test MSE 5.202809453604109 Test RE 1.09025232282309\n",
      "36 Train Loss 56992.363 Test MSE 5.2112812477912085 Test RE 1.0911395969487454\n",
      "37 Train Loss 55954.773 Test MSE 5.212930910275149 Test RE 1.091312286690828\n",
      "38 Train Loss 54951.934 Test MSE 5.215899461780318 Test RE 1.091622971381542\n",
      "39 Train Loss 54143.723 Test MSE 5.220406930665562 Test RE 1.0920945481474178\n",
      "40 Train Loss 53320.582 Test MSE 5.226472015062182 Test RE 1.092728763349937\n",
      "41 Train Loss 52378.42 Test MSE 5.228122295927286 Test RE 1.092901266621314\n",
      "42 Train Loss 51420.645 Test MSE 5.235527668998007 Test RE 1.093675012645761\n",
      "43 Train Loss 50538.32 Test MSE 5.239196078688588 Test RE 1.0940581015842408\n",
      "44 Train Loss 49658.46 Test MSE 5.239804358094689 Test RE 1.0941216107264058\n",
      "45 Train Loss 49149.26 Test MSE 5.242508288717414 Test RE 1.0944038776928937\n",
      "46 Train Loss 48626.32 Test MSE 5.242591065265447 Test RE 1.0944125176999824\n",
      "47 Train Loss 47692.31 Test MSE 5.2504313365655 Test RE 1.0952305564637626\n",
      "48 Train Loss 47036.906 Test MSE 5.2505743082620775 Test RE 1.0952454681819428\n",
      "49 Train Loss 46307.395 Test MSE 5.248276167063037 Test RE 1.0950057511464684\n",
      "50 Train Loss 45678.875 Test MSE 5.248689535376943 Test RE 1.0950488730930092\n",
      "51 Train Loss 44795.57 Test MSE 5.24960387119056 Test RE 1.0951442491668468\n",
      "52 Train Loss 43947.145 Test MSE 5.2517746439965425 Test RE 1.0953706532634715\n",
      "53 Train Loss 43263.26 Test MSE 5.254355716679838 Test RE 1.0956397893341931\n",
      "54 Train Loss 42460.727 Test MSE 5.250157792855601 Test RE 1.0952020257286044\n",
      "55 Train Loss 41867.37 Test MSE 5.254065507855389 Test RE 1.0956095317019543\n",
      "56 Train Loss 41221.992 Test MSE 5.257095072067179 Test RE 1.0959253577117116\n",
      "57 Train Loss 40654.555 Test MSE 5.258827243088767 Test RE 1.0961058921870264\n",
      "58 Train Loss 40139.34 Test MSE 5.257029228452378 Test RE 1.0959184946141203\n",
      "59 Train Loss 39685.94 Test MSE 5.258799646893628 Test RE 1.0961030162233965\n",
      "60 Train Loss 39181.2 Test MSE 5.264907783050978 Test RE 1.0967393975201964\n",
      "61 Train Loss 38758.543 Test MSE 5.270037695482616 Test RE 1.0972735766064228\n",
      "62 Train Loss 38282.824 Test MSE 5.2714566472810995 Test RE 1.0974212865105404\n",
      "63 Train Loss 37950.906 Test MSE 5.275661405652418 Test RE 1.09785887633188\n",
      "64 Train Loss 37644.125 Test MSE 5.275929986420695 Test RE 1.0978868216457516\n",
      "65 Train Loss 37248.09 Test MSE 5.272626930543443 Test RE 1.0975430955832186\n",
      "66 Train Loss 36794.633 Test MSE 5.278063799280639 Test RE 1.0981088155124332\n",
      "67 Train Loss 36286.13 Test MSE 5.279821642947243 Test RE 1.0982916612496447\n",
      "68 Train Loss 35733.96 Test MSE 5.27944546465919 Test RE 1.0982525348487706\n",
      "69 Train Loss 35264.74 Test MSE 5.27692762645603 Test RE 1.0979906179505863\n",
      "70 Train Loss 34847.586 Test MSE 5.276246869093652 Test RE 1.0979197917655024\n",
      "71 Train Loss 34431.043 Test MSE 5.274298938651263 Test RE 1.0977171032950337\n",
      "72 Train Loss 34089.55 Test MSE 5.27705692695664 Test RE 1.0980040698943072\n",
      "73 Train Loss 33732.098 Test MSE 5.278522469540919 Test RE 1.0981565279817658\n",
      "74 Train Loss 33274.17 Test MSE 5.282509977199742 Test RE 1.098571235025594\n",
      "75 Train Loss 32785.605 Test MSE 5.285069630284447 Test RE 1.098837360476324\n",
      "76 Train Loss 32405.102 Test MSE 5.288062799701615 Test RE 1.099148476607816\n",
      "77 Train Loss 32064.424 Test MSE 5.293286465095717 Test RE 1.0996912241943773\n",
      "78 Train Loss 31665.098 Test MSE 5.293332781513629 Test RE 1.0996960353497185\n",
      "79 Train Loss 31261.479 Test MSE 5.291704882426767 Test RE 1.0995269233833203\n",
      "80 Train Loss 30918.623 Test MSE 5.288543562966363 Test RE 1.0991984399138588\n",
      "81 Train Loss 30459.74 Test MSE 5.297908175583274 Test RE 1.1001712044084324\n",
      "82 Train Loss 30135.395 Test MSE 5.301221239893336 Test RE 1.1005151484865594\n",
      "83 Train Loss 29906.338 Test MSE 5.304593819175537 Test RE 1.1008651607095419\n",
      "84 Train Loss 29699.479 Test MSE 5.3076217778035994 Test RE 1.101179312812736\n",
      "85 Train Loss 29432.018 Test MSE 5.309744737963739 Test RE 1.1013995174720579\n",
      "86 Train Loss 29218.959 Test MSE 5.311092736136178 Test RE 1.1015393161245128\n",
      "87 Train Loss 28986.037 Test MSE 5.315504652046101 Test RE 1.1019967445876486\n",
      "88 Train Loss 28714.918 Test MSE 5.314967146595648 Test RE 1.1019410260557074\n",
      "89 Train Loss 28449.307 Test MSE 5.310295314798268 Test RE 1.1014566190250341\n",
      "90 Train Loss 28212.457 Test MSE 5.308644245976382 Test RE 1.1012853741173534\n",
      "91 Train Loss 27943.473 Test MSE 5.307042136786851 Test RE 1.1011191817266377\n",
      "92 Train Loss 27731.748 Test MSE 5.302853942465854 Test RE 1.1006846071363299\n",
      "93 Train Loss 27504.596 Test MSE 5.302877985990333 Test RE 1.1006871024254312\n",
      "94 Train Loss 27210.85 Test MSE 5.302853960481597 Test RE 1.1006846090060447\n",
      "95 Train Loss 26948.834 Test MSE 5.30469798663859 Test RE 1.1008759696208268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 26556.684 Test MSE 5.309099140711229 Test RE 1.101332557368251\n",
      "97 Train Loss 26247.129 Test MSE 5.306240451211945 Test RE 1.101036010660602\n",
      "98 Train Loss 26040.951 Test MSE 5.3051990024293 Test RE 1.1009279559189262\n",
      "99 Train Loss 25786.473 Test MSE 5.306073556036343 Test RE 1.1010186952896752\n",
      "Training time: 73.70\n",
      "KG_stan_tune22\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 414684.16 Test MSE 5.486707833707322 Test RE 1.1196028044180788\n",
      "1 Train Loss 272272.2 Test MSE 5.481109910765686 Test RE 1.1190315101325856\n",
      "2 Train Loss 211390.36 Test MSE 5.484713665443094 Test RE 1.11939932362826\n",
      "3 Train Loss 176812.58 Test MSE 5.484996851558554 Test RE 1.119428221604868\n",
      "4 Train Loss 149452.67 Test MSE 5.483907462205947 Test RE 1.1193170498233411\n",
      "5 Train Loss 132172.02 Test MSE 5.486056412871512 Test RE 1.1195363388556776\n",
      "6 Train Loss 118912.61 Test MSE 5.487589040118181 Test RE 1.119692709110297\n",
      "7 Train Loss 104548.42 Test MSE 5.488905543359722 Test RE 1.1198270113212458\n",
      "8 Train Loss 94129.07 Test MSE 5.49550859180832 Test RE 1.1205003741160708\n",
      "9 Train Loss 87500.234 Test MSE 5.497735072638105 Test RE 1.120727333998467\n",
      "10 Train Loss 82725.73 Test MSE 5.498454288199012 Test RE 1.1208006385654814\n",
      "11 Train Loss 76762.54 Test MSE 5.49420595839332 Test RE 1.1203675667781126\n",
      "12 Train Loss 72801.88 Test MSE 5.49761557281053 Test RE 1.1207151537597713\n",
      "13 Train Loss 69537.17 Test MSE 5.497435942153495 Test RE 1.1206968443271421\n",
      "14 Train Loss 66610.9 Test MSE 5.498796659256918 Test RE 1.1208355323471693\n",
      "15 Train Loss 64601.195 Test MSE 5.499964850885794 Test RE 1.1209545839536856\n",
      "16 Train Loss 62269.27 Test MSE 5.495183861481958 Test RE 1.1204672683696784\n",
      "17 Train Loss 59635.766 Test MSE 5.48916024890079 Test RE 1.1198529930796997\n",
      "18 Train Loss 57690.348 Test MSE 5.486315299806524 Test RE 1.1195627539971165\n",
      "19 Train Loss 55713.617 Test MSE 5.478137319851248 Test RE 1.118728024699494\n",
      "20 Train Loss 53699.168 Test MSE 5.474977452990893 Test RE 1.1184053291083047\n",
      "21 Train Loss 51383.67 Test MSE 5.460884180254842 Test RE 1.1169649443874972\n",
      "22 Train Loss 49342.83 Test MSE 5.451217379152542 Test RE 1.1159758865509597\n",
      "23 Train Loss 47467.297 Test MSE 5.442423373591299 Test RE 1.1150753666618836\n",
      "24 Train Loss 45310.984 Test MSE 5.419746020114209 Test RE 1.1127498075502227\n",
      "25 Train Loss 43220.95 Test MSE 5.412617801903127 Test RE 1.1120178052379726\n",
      "26 Train Loss 41493.24 Test MSE 5.40262666491472 Test RE 1.1109909957994815\n",
      "27 Train Loss 40058.94 Test MSE 5.394192643408688 Test RE 1.1101234750261362\n",
      "28 Train Loss 38413.918 Test MSE 5.387477355655474 Test RE 1.1094322575767266\n",
      "29 Train Loss 37097.066 Test MSE 5.38478089682594 Test RE 1.1091545846861683\n",
      "30 Train Loss 35628.156 Test MSE 5.382448969059019 Test RE 1.1089143939980615\n",
      "31 Train Loss 34142.402 Test MSE 5.38668976818358 Test RE 1.1093511614694391\n",
      "32 Train Loss 32943.434 Test MSE 5.385134549625896 Test RE 1.109191006705161\n",
      "33 Train Loss 32114.441 Test MSE 5.389045921717971 Test RE 1.1095937516327727\n",
      "34 Train Loss 31474.604 Test MSE 5.388423899377129 Test RE 1.1095297132083433\n",
      "35 Train Loss 30579.033 Test MSE 5.38649293491959 Test RE 1.1093308930658192\n",
      "36 Train Loss 29470.537 Test MSE 5.390137220731623 Test RE 1.1097060940852035\n",
      "37 Train Loss 28962.13 Test MSE 5.389832566212157 Test RE 1.1096747329398167\n",
      "38 Train Loss 28437.328 Test MSE 5.394931474873816 Test RE 1.110199498086916\n",
      "39 Train Loss 27683.375 Test MSE 5.387279745251936 Test RE 1.1094119106358442\n",
      "40 Train Loss 27287.203 Test MSE 5.38430878358932 Test RE 1.1091059607914204\n",
      "41 Train Loss 26874.771 Test MSE 5.38155047040239 Test RE 1.108821833930763\n",
      "42 Train Loss 26145.096 Test MSE 5.380187738384035 Test RE 1.1086814354812045\n",
      "43 Train Loss 25420.695 Test MSE 5.374046130611054 Test RE 1.1080484621403912\n",
      "44 Train Loss 25061.992 Test MSE 5.3684785106578685 Test RE 1.107474333145484\n",
      "45 Train Loss 24695.7 Test MSE 5.364873307629281 Test RE 1.1071024083667245\n",
      "46 Train Loss 24046.99 Test MSE 5.364356424985318 Test RE 1.1070490747863124\n",
      "47 Train Loss 23661.979 Test MSE 5.354798941278701 Test RE 1.10606244007838\n",
      "48 Train Loss 23130.287 Test MSE 5.353063179854569 Test RE 1.105883160133097\n",
      "49 Train Loss 22728.492 Test MSE 5.350826942840372 Test RE 1.1056521451887522\n",
      "50 Train Loss 22379.316 Test MSE 5.346665573710301 Test RE 1.1052221255241237\n",
      "51 Train Loss 21899.03 Test MSE 5.3433618367317814 Test RE 1.1048806110437988\n",
      "52 Train Loss 21583.719 Test MSE 5.340695355864887 Test RE 1.1046048941129212\n",
      "53 Train Loss 21099.432 Test MSE 5.3338574035716 Test RE 1.1038975279079406\n",
      "54 Train Loss 20612.244 Test MSE 5.330533835919877 Test RE 1.1035535507876673\n",
      "55 Train Loss 20472.484 Test MSE 5.330405818475507 Test RE 1.1035402993049956\n",
      "56 Train Loss 19911.086 Test MSE 5.323181840284193 Test RE 1.1027922649024433\n",
      "57 Train Loss 19690.658 Test MSE 5.321308090568457 Test RE 1.1025981574470454\n",
      "58 Train Loss 19283.42 Test MSE 5.317940563767353 Test RE 1.102249219140394\n",
      "59 Train Loss 18927.6 Test MSE 5.311591596128498 Test RE 1.1015910475683992\n",
      "60 Train Loss 18576.951 Test MSE 5.308787917056686 Test RE 1.101300276395749\n",
      "61 Train Loss 18320.562 Test MSE 5.304841236969801 Test RE 1.1008908337830305\n",
      "62 Train Loss 17915.676 Test MSE 5.29888122815323 Test RE 1.1002722325153558\n",
      "63 Train Loss 17712.365 Test MSE 5.294962538981777 Test RE 1.0998653143247095\n",
      "64 Train Loss 17390.48 Test MSE 5.288987809109142 Test RE 1.0992446061604724\n",
      "65 Train Loss 17223.75 Test MSE 5.284176669077233 Test RE 1.0987445272068883\n",
      "66 Train Loss 16935.574 Test MSE 5.280057822531022 Test RE 1.0983162256368715\n",
      "67 Train Loss 16684.982 Test MSE 5.276398487093125 Test RE 1.0979355665397574\n",
      "68 Train Loss 16371.654 Test MSE 5.270282372153529 Test RE 1.0972990483530385\n",
      "69 Train Loss 16148.565 Test MSE 5.267074139214001 Test RE 1.0969650124687305\n",
      "70 Train Loss 15870.898 Test MSE 5.266580020290961 Test RE 1.0969135565874186\n",
      "71 Train Loss 15620.316 Test MSE 5.261273891978925 Test RE 1.09636084203521\n",
      "72 Train Loss 15358.828 Test MSE 5.260648062738229 Test RE 1.0962956339608398\n",
      "73 Train Loss 15155.889 Test MSE 5.258215233067309 Test RE 1.0960421092105126\n",
      "74 Train Loss 14907.686 Test MSE 5.2548152878040515 Test RE 1.0956877032390742\n",
      "75 Train Loss 14730.551 Test MSE 5.252908212086242 Test RE 1.0954888618984513\n",
      "76 Train Loss 14630.719 Test MSE 5.25146156693216 Test RE 1.0953380032962852\n",
      "77 Train Loss 14502.489 Test MSE 5.2513058918318585 Test RE 1.0953217679954002\n",
      "78 Train Loss 14287.797 Test MSE 5.24969242717492 Test RE 1.0951534861655219\n",
      "79 Train Loss 14143.683 Test MSE 5.247252436620603 Test RE 1.0948989498504864\n",
      "80 Train Loss 14021.01 Test MSE 5.24393995304573 Test RE 1.094553301589915\n",
      "81 Train Loss 13892.247 Test MSE 5.242720889348598 Test RE 1.0944260682726228\n",
      "82 Train Loss 13684.199 Test MSE 5.240089020218317 Test RE 1.0941513304191606\n",
      "83 Train Loss 13610.738 Test MSE 5.239797712444577 Test RE 1.0941209168883144\n",
      "84 Train Loss 13506.763 Test MSE 5.240262257184494 Test RE 1.09416941655183\n",
      "85 Train Loss 13355.267 Test MSE 5.239143743472193 Test RE 1.0940526372048185\n",
      "86 Train Loss 13242.368 Test MSE 5.239970350557877 Test RE 1.0941389410015876\n",
      "87 Train Loss 13099.522 Test MSE 5.240125329083506 Test RE 1.0941551211299847\n",
      "88 Train Loss 13020.631 Test MSE 5.240600052270444 Test RE 1.094204681876144\n",
      "89 Train Loss 12864.747 Test MSE 5.239148124001131 Test RE 1.0940530945818696\n",
      "90 Train Loss 12740.102 Test MSE 5.238638959920517 Test RE 1.093999930779307\n",
      "91 Train Loss 12645.438 Test MSE 5.237543570550481 Test RE 1.0938855481549086\n",
      "92 Train Loss 12540.624 Test MSE 5.237309753954813 Test RE 1.0938611310358837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 12436.994 Test MSE 5.239261908046338 Test RE 1.094064974863543\n",
      "94 Train Loss 12338.491 Test MSE 5.23919292987439 Test RE 1.0940577728137435\n",
      "95 Train Loss 12240.309 Test MSE 5.237403593407153 Test RE 1.093870930615678\n",
      "96 Train Loss 12152.321 Test MSE 5.237842059822883 Test RE 1.0939167181533125\n",
      "97 Train Loss 12041.067 Test MSE 5.238997893327879 Test RE 1.0940374086814773\n",
      "98 Train Loss 11954.578 Test MSE 5.23927299980661 Test RE 1.0940661329560584\n",
      "99 Train Loss 11865.654 Test MSE 5.238339937049694 Test RE 1.0939687074338158\n",
      "Training time: 72.39\n",
      "KG_stan_tune22\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1154656.1 Test MSE 5.553709301568299 Test RE 1.1264181304722998\n",
      "1 Train Loss 832353.5 Test MSE 5.548781497771439 Test RE 1.1259182844159366\n",
      "2 Train Loss 722955.9 Test MSE 5.545441053832596 Test RE 1.1255793241293879\n",
      "3 Train Loss 637122.9 Test MSE 5.547617128102838 Test RE 1.1258001455162063\n",
      "4 Train Loss 562370.9 Test MSE 5.546454544122716 Test RE 1.1256821754254056\n",
      "5 Train Loss 510433.25 Test MSE 5.552682975116858 Test RE 1.1263140445294235\n",
      "6 Train Loss 467651.3 Test MSE 5.561485322825973 Test RE 1.1272064313179284\n",
      "7 Train Loss 440185.56 Test MSE 5.571422431192366 Test RE 1.1282130125447107\n",
      "8 Train Loss 416996.7 Test MSE 5.583086972252718 Test RE 1.1293934297773933\n",
      "9 Train Loss 387988.84 Test MSE 5.584487795908762 Test RE 1.1295351060414176\n",
      "10 Train Loss 378826.12 Test MSE 5.58602221502487 Test RE 1.1296902734698915\n",
      "11 Train Loss 354462.1 Test MSE 5.590449857728444 Test RE 1.1301378973730074\n",
      "12 Train Loss 340451.8 Test MSE 5.591256843632376 Test RE 1.1302194625838657\n",
      "13 Train Loss 331084.7 Test MSE 5.5954911493437 Test RE 1.1306473439297344\n",
      "14 Train Loss 327387.8 Test MSE 5.595171959410534 Test RE 1.1306150950719183\n",
      "15 Train Loss 321293.22 Test MSE 5.595725887892766 Test RE 1.1306710597865244\n",
      "16 Train Loss 315402.44 Test MSE 5.59985299852594 Test RE 1.131087944435716\n",
      "17 Train Loss 309273.25 Test MSE 5.600114916781944 Test RE 1.1311143959441616\n",
      "18 Train Loss 297042.34 Test MSE 5.600785012935158 Test RE 1.1311820671209512\n",
      "19 Train Loss 286665.75 Test MSE 5.597083033394683 Test RE 1.1308081637248089\n",
      "20 Train Loss 281235.38 Test MSE 5.594842222349125 Test RE 1.1305817796354594\n",
      "21 Train Loss 274066.88 Test MSE 5.58967082888591 Test RE 1.130059152306518\n",
      "22 Train Loss 267619.16 Test MSE 5.5864045716525865 Test RE 1.1297289357912563\n",
      "23 Train Loss 260816.53 Test MSE 5.581275454358915 Test RE 1.1292101904331473\n",
      "24 Train Loss 252481.16 Test MSE 5.577042135011566 Test RE 1.1287818641322442\n",
      "25 Train Loss 248689.44 Test MSE 5.576097731957075 Test RE 1.1286862874674202\n",
      "26 Train Loss 245169.8 Test MSE 5.576226099172681 Test RE 1.1286992791229766\n",
      "27 Train Loss 239465.45 Test MSE 5.577736986019999 Test RE 1.1288521801500178\n",
      "28 Train Loss 230398.9 Test MSE 5.586175987778111 Test RE 1.129705822493998\n",
      "29 Train Loss 226038.11 Test MSE 5.589399761747724 Test RE 1.1300317512641687\n",
      "30 Train Loss 219928.62 Test MSE 5.594877758212348 Test RE 1.1305853700973605\n",
      "31 Train Loss 213311.12 Test MSE 5.593666460425423 Test RE 1.1304629769238888\n",
      "32 Train Loss 209566.25 Test MSE 5.590770910527875 Test RE 1.1301703481359868\n",
      "33 Train Loss 206631.03 Test MSE 5.591021214393352 Test RE 1.1301956472266772\n",
      "34 Train Loss 201830.98 Test MSE 5.590121496461209 Test RE 1.13010470693477\n",
      "35 Train Loss 195384.77 Test MSE 5.59134044998387 Test RE 1.1302279126671886\n",
      "36 Train Loss 193639.72 Test MSE 5.591165703466248 Test RE 1.1302102509868814\n",
      "37 Train Loss 188711.31 Test MSE 5.588277550600725 Test RE 1.1299183045667986\n",
      "38 Train Loss 183420.69 Test MSE 5.585238016909704 Test RE 1.1296109744586065\n",
      "39 Train Loss 181260.7 Test MSE 5.58321006704511 Test RE 1.1294058800297517\n",
      "40 Train Loss 176707.78 Test MSE 5.583988887290068 Test RE 1.1294846495441537\n",
      "41 Train Loss 173829.56 Test MSE 5.590862909552436 Test RE 1.1301796468663\n",
      "42 Train Loss 172274.12 Test MSE 5.591500255919888 Test RE 1.1302440640570541\n",
      "43 Train Loss 169707.08 Test MSE 5.593550478747829 Test RE 1.1304512570910121\n",
      "44 Train Loss 165615.58 Test MSE 5.592693156884789 Test RE 1.1303646218027388\n",
      "45 Train Loss 162640.98 Test MSE 5.5962615139758105 Test RE 1.1307251727319483\n",
      "46 Train Loss 160548.66 Test MSE 5.598692374990835 Test RE 1.1309707239196682\n",
      "47 Train Loss 158337.02 Test MSE 5.602421724794946 Test RE 1.131347337155484\n",
      "48 Train Loss 156701.72 Test MSE 5.602841229008969 Test RE 1.13138969348946\n",
      "49 Train Loss 156300.33 Test MSE 5.60341240072559 Test RE 1.1314473607781121\n",
      "50 Train Loss 154473.94 Test MSE 5.602815478491292 Test RE 1.131387093567154\n",
      "51 Train Loss 151692.73 Test MSE 5.598493699170109 Test RE 1.1309506568651513\n",
      "52 Train Loss 150405.95 Test MSE 5.6002661172551536 Test RE 1.1311296656198806\n",
      "53 Train Loss 147427.73 Test MSE 5.598533281356381 Test RE 1.1309546548530782\n",
      "54 Train Loss 147114.94 Test MSE 5.598323855925876 Test RE 1.1309335017341637\n",
      "55 Train Loss 146002.4 Test MSE 5.599338406449859 Test RE 1.1310359732262931\n",
      "56 Train Loss 145099.55 Test MSE 5.600630877144803 Test RE 1.1311665017277828\n",
      "57 Train Loss 143887.05 Test MSE 5.602421290502237 Test RE 1.1313472933051698\n",
      "58 Train Loss 143313.92 Test MSE 5.600226191313866 Test RE 1.1311256335349613\n",
      "59 Train Loss 140668.78 Test MSE 5.598573195890296 Test RE 1.1309586863953773\n",
      "60 Train Loss 139709.9 Test MSE 5.5977397540795675 Test RE 1.1308745021483286\n",
      "61 Train Loss 139142.58 Test MSE 5.596870640109429 Test RE 1.1307867080542393\n",
      "62 Train Loss 138276.92 Test MSE 5.5958264219364455 Test RE 1.130681216683541\n",
      "63 Train Loss 135383.72 Test MSE 5.5967570070554515 Test RE 1.1307752288359847\n",
      "64 Train Loss 134848.23 Test MSE 5.598174032543626 Test RE 1.1309183685067592\n",
      "65 Train Loss 134705.45 Test MSE 5.598582758247946 Test RE 1.1309596522331407\n",
      "66 Train Loss 134293.95 Test MSE 5.5980093544454075 Test RE 1.1309017346137513\n",
      "67 Train Loss 132688.16 Test MSE 5.598316397879865 Test RE 1.1309327484232519\n",
      "68 Train Loss 131143.9 Test MSE 5.596791999588054 Test RE 1.1307787637962445\n",
      "69 Train Loss 130029.586 Test MSE 5.595246302188186 Test RE 1.130622606260853\n",
      "70 Train Loss 129422.9 Test MSE 5.5962464652109 Test RE 1.1307236524287334\n",
      "71 Train Loss 128699.63 Test MSE 5.595460130016028 Test RE 1.130644209980621\n",
      "72 Train Loss 127353.3 Test MSE 5.592728835000208 Test RE 1.1303682273299858\n",
      "73 Train Loss 126050.56 Test MSE 5.591872616963284 Test RE 1.1302816972353853\n",
      "74 Train Loss 125707.03 Test MSE 5.591572766961073 Test RE 1.130251392582891\n",
      "75 Train Loss 125407.4 Test MSE 5.590621668351723 Test RE 1.1301552634356369\n",
      "76 Train Loss 124669.94 Test MSE 5.589629627688141 Test RE 1.130054987492717\n",
      "77 Train Loss 123798.875 Test MSE 5.589041955552498 Test RE 1.1299955811162374\n",
      "78 Train Loss 122245.39 Test MSE 5.588593742569367 Test RE 1.1299502702338866\n",
      "79 Train Loss 121378.38 Test MSE 5.586957734653148 Test RE 1.1297848670052217\n",
      "80 Train Loss 120853.18 Test MSE 5.587568733530325 Test RE 1.1298466428809304\n",
      "81 Train Loss 120537.82 Test MSE 5.5881817639679925 Test RE 1.1299086207659792\n",
      "82 Train Loss 119549.38 Test MSE 5.587882304172503 Test RE 1.129878345557338\n",
      "83 Train Loss 118765.39 Test MSE 5.5867727355539385 Test RE 1.1297661617524828\n",
      "84 Train Loss 117768.086 Test MSE 5.585838912545145 Test RE 1.1296717382117711\n",
      "85 Train Loss 116706.61 Test MSE 5.585220363505008 Test RE 1.129609189262042\n",
      "86 Train Loss 116255.35 Test MSE 5.585922724624077 Test RE 1.129680213194958\n",
      "87 Train Loss 115825.75 Test MSE 5.5854096126435575 Test RE 1.129628326891462\n",
      "88 Train Loss 115387.84 Test MSE 5.584698496173138 Test RE 1.1295564142714076\n",
      "89 Train Loss 114692.77 Test MSE 5.583774174202578 Test RE 1.1294629341116385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 113617.83 Test MSE 5.584055829400898 Test RE 1.1294914197814794\n",
      "91 Train Loss 112728.38 Test MSE 5.582974620637234 Test RE 1.1293820660089842\n",
      "92 Train Loss 112407.11 Test MSE 5.582871242741306 Test RE 1.1293716097835762\n",
      "93 Train Loss 112255.21 Test MSE 5.581898346831907 Test RE 1.1292732008426845\n",
      "94 Train Loss 111891.39 Test MSE 5.58186754060204 Test RE 1.129270084636007\n",
      "95 Train Loss 111193.59 Test MSE 5.581855743687536 Test RE 1.1292688913158875\n",
      "96 Train Loss 110677.49 Test MSE 5.581336653832247 Test RE 1.1292163813907572\n",
      "97 Train Loss 110212.31 Test MSE 5.580116639828324 Test RE 1.129092957990821\n",
      "98 Train Loss 110050.25 Test MSE 5.579870895474347 Test RE 1.1290680954930998\n",
      "99 Train Loss 109696.77 Test MSE 5.58006022517735 Test RE 1.129087250444703\n",
      "Training time: 73.41\n",
      "KG_stan_tune22\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.87\n",
      "KG_stan_tune23\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.88\n",
      "KG_stan_tune24\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 0.82\n"
     ]
    }
   ],
   "source": [
    "#for tune_reps in range(25):\n",
    "nan_tune = []\n",
    "for tune_reps in range(25):\n",
    "  \n",
    "  max_reps = 10 #10\n",
    "  max_iter = 100 #100\n",
    "  label = \"KG_stan_tune\"+str(tune_reps)\n",
    "\n",
    "  train_loss_full = []\n",
    "  test_mse_full = []\n",
    "  test_re_full = []\n",
    "  alpha_full = []\n",
    "  elapsed_time= np.zeros((max_reps,1))\n",
    "  time_threshold = np.empty((max_reps,1))\n",
    "  time_threshold[:] = np.nan\n",
    "  epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "  N_I = 200  #Total number of data points for 'y'\n",
    "  N_B = 400\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "  n_val = lrn_tune[tune_reps,1]  \n",
    "\n",
    "  for reps in range(max_reps):\n",
    "      print(label)\n",
    "      print(reps)\n",
    "\n",
    "      train_loss = []\n",
    "      test_mse_loss = []\n",
    "      test_re_loss = []\n",
    "      alpha_val = []\n",
    "      \n",
    "      torch.manual_seed(reps*36)\n",
    "\n",
    "      layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "      PINN = Sequentialmodel(layers,n_val)\n",
    "    \n",
    "      PINN.to(device)\n",
    "\n",
    "      'Neural Network Summary'\n",
    "      print(PINN)\n",
    "\n",
    "      params = list(PINN.parameters())\n",
    "      \n",
    "\n",
    "      optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lrn_tune[tune_reps,0], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "      nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "      torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "      train_loss_full.append(train_loss)\n",
    "      test_mse_full.append(test_mse_loss)\n",
    "      test_re_full.append(test_re_loss)\n",
    "      #elapsed_time[reps] = time.time() - start_time\n",
    "      alpha_full.append(alpha_val)  \n",
    "    \n",
    "      if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "      \n",
    "      \n",
    "\n",
    "\n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "      \n",
    "  mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label}\n",
    "  savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KG_stan_tune24'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.6044690320820251\n",
      "1   1.1718666662308912\n",
      "2   [[nan]]\n",
      "3   [[nan]]\n",
      "4   [[nan]]\n",
      "5   0.6938622291656981\n",
      "6   [[nan]]\n",
      "7   [[nan]]\n",
      "8   [[nan]]\n",
      "9   [[nan]]\n",
      "10   0.4501623026603596\n",
      "11   [[nan]]\n",
      "12   [[nan]]\n",
      "13   [[nan]]\n",
      "14   [[nan]]\n",
      "15   0.5483568099981746\n",
      "16   [[nan]]\n",
      "17   [[nan]]\n",
      "18   nan\n",
      "19   nan\n",
      "20   0.5968319106190754\n",
      "21   [[nan]]\n",
      "22   [[nan]]\n",
      "23   nan\n",
      "24   nan\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(25):\n",
    "    label = \"KG_stan_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 1.  ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrn_tune[10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
